<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#19981;&#21516;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#23450;&#20041;&#21644;&#38543;&#26426;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;Lasso&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.10413</link><description>&lt;p&gt;
&#20351;&#29992;Lasso&#30340;&#31614;&#21517;&#19968;&#33268;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Consistency of Signatures Using Lasso. (arXiv:2305.10413v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#19981;&#21516;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#23450;&#20041;&#21644;&#38543;&#26426;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;Lasso&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31614;&#21517;&#21464;&#25442;&#26159;&#36830;&#32493;&#21644;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#36845;&#20195;&#36335;&#24452;&#31215;&#20998;&#65292;&#23427;&#20204;&#30340;&#26222;&#36941;&#38750;&#32447;&#24615;&#36890;&#36807;&#32447;&#24615;&#21270;&#29305;&#24449;&#36873;&#25321;&#38382;&#39064;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#21644;&#25968;&#20540;&#19978;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#26356;&#25509;&#36817;&#24067;&#26391;&#36816;&#21160;&#25110;&#20855;&#26377;&#36739;&#24369;&#36328;&#32500;&#24230;&#30456;&#20851;&#24615;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#31614;&#21517;&#23450;&#20041;&#20026;It\^o&#31215;&#20998;&#30340;Lasso&#22238;&#24402;&#26356;&#20855;&#19968;&#33268;&#24615;&#65307;&#23545;&#20110;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#20854;&#31614;&#21517;&#23450;&#20041;&#20026;Stratonovich&#31215;&#20998;&#22312;Lasso&#22238;&#24402;&#20013;&#20855;&#26377;&#26356;&#39640;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#32479;&#35745;&#25512;&#26029;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#21644;&#38543;&#26426;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signature transforms are iterated path integrals of continuous and discrete-time time series data, and their universal nonlinearity linearizes the problem of feature selection. This paper revisits the consistency issue of Lasso regression for the signature transform, both theoretically and numerically. Our study shows that, for processes and time series that are closer to Brownian motion or random walk with weaker inter-dimensional correlations, the Lasso regression is more consistent for their signatures defined by It\^o integrals; for mean reverting processes and time series, their signatures defined by Stratonovich integrals have more consistency in the Lasso regression. Our findings highlight the importance of choosing appropriate definitions of signatures and stochastic models in statistical inference and machine learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#23558;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#31232;&#30095;&#22270;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#26159;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#31639;&#27861;&#65292;&#24182;&#23558;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2305.10391</link><description>&lt;p&gt;
&#31232;&#30095;&#22270;&#30340;&#28040;&#24687;&#20256;&#36882;&#26550;&#26500;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimality of Message-Passing Architectures for Sparse Graphs. (arXiv:2305.10391v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#23558;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#24212;&#29992;&#20110;&#31232;&#30095;&#22270;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#26159;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#31639;&#27861;&#65292;&#24182;&#23558;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#35013;&#39280;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#65292;&#22312;&#31232;&#30095;&#35774;&#32622;&#19979;&#65292;&#21363;&#33410;&#28857;&#30340;&#39044;&#26399;&#24230;&#25968;&#20026;&#33410;&#28857;&#25968;&#30340;O(1)&#26102;&#12290;&#36825;&#26679;&#30340;&#22270;&#36890;&#24120;&#34987;&#31216;&#20026;&#26412;&#22320;&#26641;&#29366;&#22270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21483;&#20570;&#28176;&#36817;&#26412;&#22320;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#27010;&#24565;&#65292;&#24182;&#26681;&#25454;&#36825;&#20010;&#26631;&#20934;&#35745;&#31639;&#20102;&#20855;&#26377;&#20219;&#24847;&#33410;&#28857;&#29305;&#24449;&#21644;&#36793;&#36830;&#25509;&#20998;&#24067;&#30340;&#30456;&#24403;&#19968;&#33324;&#30340;&#32479;&#35745;&#25968;&#25454;&#27169;&#22411;&#30340;&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#35813;&#26368;&#20248;&#20998;&#31867;&#22120;&#21487;&#20197;&#20351;&#29992;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23454;&#29616;&#12290;&#28982;&#21518;&#25105;&#20204;&#35745;&#31639;&#20102;&#35813;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#22312;&#19968;&#20010;&#24050;&#32463;&#30740;&#31350;&#20805;&#20998;&#30340;&#32479;&#35745;&#27169;&#22411;&#19978;&#20174;&#29702;&#35770;&#19978;&#19982;&#29616;&#26377;&#30340;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#20302;&#22270;&#20449;&#21495;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20339;&#28040;&#24687;&#20256;&#36882;&#26550;&#26500;&#25554;&#20540;&#20110;&#26631;&#20934;MLP&#21644;&#19968;&#31181;&#20856;&#22411;&#30340;c&#26550;&#26500;&#20043;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the node classification problem on feature-decorated graphs in the sparse setting, i.e., when the expected degree of a node is $O(1)$ in the number of nodes. Such graphs are typically known to be locally tree-like. We introduce a notion of Bayes optimality for node classification tasks, called asymptotic local Bayes optimality, and compute the optimal classifier according to this criterion for a fairly general statistical data model with arbitrary distributions of the node features and edge connectivity. The optimal classifier is implementable using a message-passing graph neural network architecture. We then compute the generalization error of this classifier and compare its performance against existing learning methods theoretically on a well-studied statistical model with naturally identifiable signal-to-noise ratios (SNRs) in the data. We find that the optimal message-passing architecture interpolates between a standard MLP in the regime of low graph signal and a typical c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.10379</link><description>&lt;p&gt;
&#22522;&#20110;&#29289;&#29702;&#32422;&#26463;&#30340;&#31526;&#21495;&#22238;&#24402;&#20013;&#20027;&#21160;&#23398;&#20064;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Active Learning in Symbolic Regression Performance with Physical Constraints. (arXiv:2305.10379v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#65288;SR&#65289;&#26159;&#19968;&#31181;&#23558;&#31526;&#21495;&#26041;&#31243;&#25311;&#21512;&#21040;&#25968;&#25454;&#20013;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#31616;&#27905;&#26131;&#25026;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#25506;&#35752;&#20351;&#29992;SR&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#32771;&#34385;&#29289;&#29702;&#32422;&#26463;&#12290;&#22522;&#20110;&#20027;&#21160;&#23398;&#20064;&#30340;SR&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#25552;&#20986;&#19979;&#19968;&#27493;&#23454;&#39564;&#12290;&#29289;&#29702;&#32422;&#26463;&#21487;&#20197;&#22312;&#38750;&#24120;&#20302;&#30340;&#25968;&#25454;&#24773;&#20917;&#19979;&#25913;&#21892;&#25152;&#24314;&#35758;&#30340;&#26041;&#31243;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#20943;&#23569;SR&#25152;&#38656;&#30340;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evolutionary symbolic regression (SR) fits a symbolic equation to data, which gives a concise interpretable model. We explore using SR as a method to propose which data to gather in an active learning setting with physical constraints. SR with active learning proposes which experiments to do next. Active learning is done with query by committee, where the Pareto frontier of equations is the committee. The physical constraints improve proposed equations in very low data settings. These approaches reduce the data required for SR and achieves state of the art results in data required to rediscover known equations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#19977;&#38454;&#27573;&#28151;&#21512;RL&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#22870;&#21169;&#20449;&#24687;&#65292;&#26377;&#25928;&#22320;&#21033;&#29992;&#22312;&#32447;&#21644;&#31163;&#32447;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#32454;&#35843;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.10282</link><description>&lt;p&gt;
&#8220;&#26080;&#20219;&#20309;&#22870;&#21169;&#20449;&#24687;&#30340;&#32454;&#35843; Fine-tuning:&#22522;&#20110;&#28151;&#21512;&#22686;&#24378;&#23398;&#20064;&#30340;&#21487;&#35777;&#26126;&#32479;&#35745;&#20248;&#21183;&#8221;
&lt;/p&gt;
&lt;p&gt;
Reward-agnostic Fine-tuning: Provable Statistical Benefits of Hybrid Reinforcement Learning. (arXiv:2305.10282v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#19977;&#38454;&#27573;&#28151;&#21512;RL&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#22870;&#21169;&#20449;&#24687;&#65292;&#26377;&#25928;&#22320;&#21033;&#29992;&#22312;&#32447;&#21644;&#31163;&#32447;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#32454;&#35843;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#28151;&#21512;&#29615;&#22659;&#20013;&#36827;&#34892;&#34920;&#26684;&#24378;&#21270;&#23398;&#20064;(RL)&#65292;&#35813;&#29615;&#22659;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#31163;&#32447;&#25968;&#25454;&#38598;&#24182;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#36827;&#34892;&#22312;&#32447;&#20132;&#20114;&#12290;&#20854;&#20013;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#22312;&#20110;&#22914;&#20309;&#21033;&#29992;&#22312;&#32447;&#25968;&#25454;&#25910;&#38598;&#26469;&#21152;&#24378;&#21644;&#34917;&#20805;&#31163;&#32447;&#25968;&#25454;&#38598;&#65292;&#20174;&#32780;&#23454;&#29616;&#26377;&#25928;&#30340;&#31574;&#30053;&#32454;&#35843;&#12290;&#26412;&#25991;&#20511;&#37492;&#20102;&#26368;&#36817;&#30340;&#26080;&#22870;&#21169;&#25506;&#32034;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;RL &#30340;&#36827;&#23637;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#19977;&#38454;&#27573;&#30340;&#28151;&#21512;RL&#31639;&#27861;&#65292;&#20854;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#20248;&#20110;&#20165;&#20351;&#29992;&#31163;&#32447;RL &#21644;&#20165;&#20351;&#29992;&#22312;&#32447;RL &#30340;&#26368;&#20339;&#32467;&#26524;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#20013;&#19981;&#38656;&#35201;&#20219;&#20309;&#22870;&#21169;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#26159;&#22522;&#20110;&#19968;&#20010;&#26032;&#27010;&#24565;&#8212;&#8212;&#21333;&#31574;&#30053;&#23616;&#37096;&#38598;&#20013;&#24615;&#30340;&#65292;&#35813;&#27010;&#24565;&#25429;&#25417;&#20102;&#20998;&#24067;&#19981;&#21305;&#37197;&#21644;&#35206;&#30422;&#38169;&#35823;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25351;&#23548;&#31163;&#32447;&#21644;&#22312;&#32447;&#25968;&#25454;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies tabular reinforcement learning (RL) in the hybrid setting, which assumes access to both an offline dataset and online interactions with the unknown environment. A central question boils down to how to efficiently utilize online data collection to strengthen and complement the offline dataset and enable effective policy fine-tuning. Leveraging recent advances in reward-agnostic exploration and model-based offline RL, we design a three-stage hybrid RL algorithm that beats the best of both worlds -- pure offline RL and pure online RL -- in terms of sample complexities. The proposed algorithm does not require any reward information during data collection. Our theory is developed based on a new notion called single-policy partial concentrability, which captures the trade-off between distribution mismatch and miscoverage and guides the interplay between offline and online data.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#22312;&#23567;&#30340;&#30772;&#22351;&#33410;&#28857;&#27604;&#20363;&#19979;&#21363;&#21487;&#36798;&#21040;Kesten-Stigum&#20020;&#30028;&#28857;&#30340;&#24369;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2305.10227</link><description>&lt;p&gt;
&#22312;&#33410;&#28857;&#30772;&#22351;&#19979;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#36798;&#21040;Kesten-Stigum&#20020;&#30028;&#28857;
&lt;/p&gt;
&lt;p&gt;
Reaching Kesten-Stigum Threshold in the Stochastic Block Model under Node Corruptions. (arXiv:2305.10227v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10227
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#22312;&#23567;&#30340;&#30772;&#22351;&#33410;&#28857;&#27604;&#20363;&#19979;&#21363;&#21487;&#36798;&#21040;Kesten-Stigum&#20020;&#30028;&#28857;&#30340;&#24369;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#33410;&#28857;&#30772;&#22351;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#30340;&#24378;&#20581;&#31038;&#21306;&#26816;&#27979;&#65292;&#20854;&#20013;&#23545;&#20110;$n$&#20010;&#39030;&#28857;&#20013;&#30340;&#19968;&#20010;&#37096;&#20998;&#20855;&#26377;&#20219;&#24847;&#20462;&#25913;&#36793;&#32536;&#26435;&#37325;&#30340;&#25932;&#25163;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#22312;&#23567;&#30340;&#30772;&#22351;&#33410;&#28857;&#27604;&#20363;&#19979;&#21363;&#21487;&#36798;&#21040;Kesten-Stigum&#20020;&#30028;&#28857;&#30340;&#24369;&#24674;&#22797;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20043;&#21069;&#65292;&#21363;&#20351;&#26159;&#26368;&#20808;&#36827;&#30340;&#24378;&#20581;&#24615;&#31639;&#27861;&#65292;&#22312;&#25509;&#36817;Kesten-Stigum&#20020;&#30028;&#28857;&#26102;&#20063;&#20250;&#34987;&#33410;&#28857;&#30772;&#22351;&#25932;&#25163;&#25915;&#30772;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#25216;&#26415;&#25193;&#23637;&#21040;$Z_2$&#21516;&#27493;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#23384;&#22312;&#31867;&#20284;&#30340;&#24378;&#30772;&#22351;&#25932;&#25163;&#27874;&#21160;&#26102;&#20063;&#33021;&#36798;&#21040;&#26368;&#20248;&#24674;&#22797;&#38408;&#20540;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#21487;&#35782;&#21035;&#24615;&#35777;&#26126;&#65292;&#21033;&#29992;&#20027;&#23376;&#30697;&#38453;&#30340;Grothendieck&#33539;&#25968;&#25512;&#20986;&#30340;&#25512;&#20986;&#12288;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study robust community detection in the context of node-corrupted stochastic block model, where an adversary can arbitrarily modify all the edges incident to a fraction of the $n$ vertices. We present the first polynomial-time algorithm that achieves weak recovery at the Kesten-Stigum threshold even in the presence of a small constant fraction of corrupted nodes. Prior to this work, even state-of-the-art robust algorithms were known to break under such node corruption adversaries, when close to the Kesten-Stigum threshold.  We further extend our techniques to the $Z_2$ synchronization problem, where our algorithm reaches the optimal recovery threshold in the presence of similar strong adversarial perturbations.  The key ingredient of our algorithm is a novel identifiability proof that leverages the push-out effect of the Grothendieck norm of principal submatrices.
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#36890;&#36807;&#20998;&#26512;&#25968;&#25454;&#30340;&#21487;&#20998;&#24615;&#21644;&#31163;&#25955;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;S&amp;S&#27604;&#30340;&#26377;&#25928;SVM&#27491;&#21017;&#21270;&#21442;&#25968;&#12289;&#26680;&#20989;&#25968;&#21644;&#26680;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#65292;&#34920;&#29616;&#36739;&#20256;&#32479;&#26041;&#27861;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2305.10219</link><description>&lt;p&gt;
&#22522;&#20110;&#21487;&#20998;&#24615;&#21644;&#31163;&#25955;&#24230;&#27604;&#30340;SVM&#27491;&#21017;&#21270;&#21442;&#25968;&#12289;&#26680;&#20989;&#25968;&#21644;&#26680;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Separability and Scatteredness (S&amp;S) Ratio-Based Efficient SVM Regularization Parameter, Kernel, and Kernel Parameter Selection. (arXiv:2305.10219v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10219
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#36890;&#36807;&#20998;&#26512;&#25968;&#25454;&#30340;&#21487;&#20998;&#24615;&#21644;&#31163;&#25955;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;S&amp;S&#27604;&#30340;&#26377;&#25928;SVM&#27491;&#21017;&#21270;&#21442;&#25968;&#12289;&#26680;&#20989;&#25968;&#21644;&#26680;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#65292;&#34920;&#29616;&#36739;&#20256;&#32479;&#26041;&#27861;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#26159;&#19968;&#31181;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#20998;&#31867;&#12289;&#22238;&#24402;&#21644;&#24322;&#24120;&#20540;&#26816;&#27979;&#12290;SVM&#38656;&#35201;&#35843;&#25972;&#27491;&#21017;&#21270;&#21442;&#25968;&#65288;RP&#65289;&#26469;&#25511;&#21046;&#27169;&#22411;&#23481;&#37327;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;&#20256;&#32479;&#19978;&#65292;&#36890;&#36807;&#20132;&#21449;&#39564;&#35777;&#65288;CV&#65289;&#36807;&#31243;&#23545;&#19968;&#31995;&#21015;&#22791;&#36873;RP&#36827;&#34892;&#27604;&#36739;&#20197;&#25214;&#21040;&#26368;&#20339;RP&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#38750;&#32447;&#24615;&#21487;&#20998;&#25968;&#25454;&#65292;SVM&#20351;&#29992;&#26680;&#20989;&#25968;&#65292;&#22312;&#26680;&#20989;&#25968;&#30340;&#32593;&#26684;&#20013;&#36873;&#25321;&#19968;&#32452;&#20855;&#26377;&#19968;&#32452;&#21442;&#25968;&#30340;&#26680;&#20989;&#25968;&#12290;RP&#21644;&#26680;&#32593;&#26684;&#30340;&#26368;&#20339;&#36873;&#25321;&#26159;&#36890;&#36807;CV&#30340;&#32593;&#26684;&#25628;&#32034;&#33719;&#24471;&#30340;&#12290;&#36890;&#36807;&#38543;&#26426;&#20998;&#26512;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#34892;&#20026;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;SVM&#24615;&#33021;&#21487;&#20197;&#24314;&#27169;&#20026;&#25968;&#25454;&#30340;&#21487;&#20998;&#24615;&#21644;&#31163;&#25955;&#24230;&#65288;S&amp;S&#65289;&#30340;&#20989;&#25968;&#12290;&#21487;&#20998;&#24615;&#26159;&#31867;&#21035;&#20043;&#38388;&#36317;&#31163;&#30340;&#24230;&#37327;&#65292;&#31163;&#25955;&#24230;&#26159;&#25968;&#25454;&#28857;&#30340;&#20256;&#25773;&#27604;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#38128;&#38142;&#25439;&#22833;&#25104;&#26412;&#20989;&#25968;&#65292;S&amp;S&#27604;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#26368;&#20248;RP&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;S&amp;S&#27604;&#30340;&#39640;&#25928;&#36873;&#25321;&#26680;&#20989;&#25968;&#21450;&#20854;&#21442;&#25968;&#26041;&#27861;&#12290;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#27604;&#36739;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#19982;&#20256;&#32479;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#26041;&#27861;&#20855;&#26377;&#26356;&#23569;&#30340;&#38656;&#35201;&#35843;&#25972;&#30340;&#36229;&#21442;&#25968;&#19988;&#24615;&#33021;&#20248;&#24322;&#25110;&#21487;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Support Vector Machine (SVM) is a robust machine learning algorithm with broad applications in classification, regression, and outlier detection. SVM requires tuning the regularization parameter (RP) which controls the model capacity and the generalization performance. Conventionally, the optimum RP is found by comparison of a range of values through the Cross-Validation (CV) procedure. In addition, for non-linearly separable data, the SVM uses kernels where a set of kernels, each with a set of parameters, denoted as a grid of kernels, are considered. The optimal choice of RP and the grid of kernels is through the grid-search of CV. By stochastically analyzing the behavior of the regularization parameter, this work shows that the SVM performance can be modeled as a function of separability and scatteredness (S&amp;S) of the data. Separability is a measure of the distance between classes, and scatteredness is the ratio of the spread of data points. In particular, for the hinge loss cost fun
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#20195;&#27493;&#20849;&#20139;&#24179;&#21488;&#20013;&#21160;&#24577;&#26465;&#20214;&#20998;&#20301;&#27835;&#30103;&#25928;&#26524;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20010;&#20307;CQTE&#20043;&#21644;&#26469;&#31616;&#21270;&#21160;&#24577;CQTE&#30340;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2305.10187</link><description>&lt;p&gt;
&#35780;&#20272;&#20855;&#26377;&#24212;&#29992;&#20110;&#20195;&#27493;&#20849;&#20139;&#30340;&#21160;&#24577;&#26465;&#20214;&#20998;&#20301;&#27835;&#30103;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Evaluating Dynamic Conditional Quantile Treatment Effects with Applications in Ridesharing. (arXiv:2305.10187v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#20195;&#27493;&#20849;&#20139;&#24179;&#21488;&#20013;&#21160;&#24577;&#26465;&#20214;&#20998;&#20301;&#27835;&#30103;&#25928;&#26524;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20010;&#20307;CQTE&#20043;&#21644;&#26469;&#31616;&#21270;&#21160;&#24577;CQTE&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#20195;&#31185;&#25216;&#20844;&#21496;&#65292;&#22914;Google&#12289;Uber&#21644;Didi&#65292;&#21033;&#29992;&#22312;&#32447;&#23454;&#39564;&#65288;&#20063;&#31216;&#20026;A / B&#27979;&#35797;&#65289;&#35780;&#20272;&#26032;&#25919;&#31574;&#19982;&#29616;&#26377;&#25919;&#31574;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#30740;&#31350;&#38598;&#20013;&#22312;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#19978;&#65292;&#20294;&#20559;&#26012;&#21644;&#37325;&#23614;&#30340;&#32467;&#26524;&#20998;&#24067;&#24773;&#20917;&#21487;&#33021;&#20250;&#21463;&#30410;&#20110;&#20854;&#20182;&#26631;&#20934;&#65292;&#20363;&#22914;&#20998;&#20301;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#22788;&#29702;&#26469;&#33258;&#20195;&#27493;&#20849;&#20139;&#24179;&#21488;&#30340;&#25968;&#25454;&#26102;&#65292;&#35780;&#20272;&#21160;&#24577;&#20998;&#20301;&#27835;&#30103;&#25928;&#26524;&#65288;QTE&#65289;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#22240;&#20026;&#28041;&#21450;&#36328;&#26102;&#38388;&#21644;&#31354;&#38388;&#30340;&#39034;&#24207;&#20915;&#31574;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#27491;&#24335;&#26694;&#26550;&#26469;&#35745;&#31639;&#22312;&#27835;&#30103;&#29420;&#31435;&#20110;&#29305;&#24449;&#30340;&#26465;&#20214;&#19979;&#30340;QTE&#12290;&#22312;&#29305;&#23450;&#30340;&#27169;&#22411;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21160;&#24577;&#26465;&#20214;QTE&#65288;CQTE&#65289;&#31561;&#20110;&#26102;&#38388;&#19978;&#30340;&#20010;&#20307;CQTE&#20043;&#21644;&#65292;&#23613;&#31649;&#32047;&#31215;&#22870;&#21169;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#19981;&#19968;&#23450;&#31561;&#20110;&#20010;&#20307;&#22870;&#21169;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#20043;&#21644;&#12290;&#36825;&#19968;&#20851;&#38190;&#27934;&#23519;&#21147;&#26174;&#33879;&#31616;&#21270;&#20102;&#21160;&#24577;CQTE&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many modern tech companies, such as Google, Uber, and Didi, utilize online experiments (also known as A/B testing) to evaluate new policies against existing ones. While most studies concentrate on average treatment effects, situations with skewed and heavy-tailed outcome distributions may benefit from alternative criteria, such as quantiles. However, assessing dynamic quantile treatment effects (QTE) remains a challenge, particularly when dealing with data from ride-sourcing platforms that involve sequential decision-making across time and space. In this paper, we establish a formal framework to calculate QTE conditional on characteristics independent of the treatment. Under specific model assumptions, we demonstrate that the dynamic conditional QTE (CQTE) equals the sum of individual CQTEs across time, even though the conditional quantile of cumulative rewards may not necessarily equate to the sum of conditional quantiles of individual rewards. This crucial insight significantly strea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25972;&#25968;&#35268;&#21010;&#30340;&#20132;&#26367;&#20248;&#21270;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#24067;&#23572;&#30697;&#38453;&#20998;&#35299;&#30340;NP&#38590;&#39064;&#65292;&#24182;&#19988;&#20351;&#29992;&#21478;&#19968;&#20010;&#25972;&#25968;&#35268;&#21010;&#23558;&#22810;&#20010;&#35299;&#32452;&#21512;&#25104;&#26368;&#20248;&#35299;&#65292;&#23454;&#39564;&#34920;&#26126;&#31639;&#27861;&#22312;&#20013;&#31561;&#35268;&#27169;&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2305.10185</link><description>&lt;p&gt;
&#24067;&#23572;&#30697;&#38453;&#20998;&#35299;&#30340;&#25972;&#25968;&#35268;&#21010;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms for Boolean Matrix Factorization using Integer Programming. (arXiv:2305.10185v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25972;&#25968;&#35268;&#21010;&#30340;&#20132;&#26367;&#20248;&#21270;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#24067;&#23572;&#30697;&#38453;&#20998;&#35299;&#30340;NP&#38590;&#39064;&#65292;&#24182;&#19988;&#20351;&#29992;&#21478;&#19968;&#20010;&#25972;&#25968;&#35268;&#21010;&#23558;&#22810;&#20010;&#35299;&#32452;&#21512;&#25104;&#26368;&#20248;&#35299;&#65292;&#23454;&#39564;&#34920;&#26126;&#31639;&#27861;&#22312;&#20013;&#31561;&#35268;&#27169;&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24067;&#23572;&#30697;&#38453;&#20998;&#35299;&#65288;BMF&#65289;&#23558;&#19968;&#20010;&#32473;&#23450;&#30340;&#20108;&#36827;&#21046;&#36755;&#20837;&#30697;&#38453;&#36817;&#20284;&#34920;&#31034;&#20026;&#20004;&#20010;&#26356;&#23567;&#30340;&#20108;&#36827;&#21046;&#22240;&#23376;&#30340;&#20056;&#31215;&#12290;&#30456;&#23545;&#20110;&#20351;&#29992;&#26631;&#20934;&#31639;&#26415;&#30340;&#20108;&#36827;&#21046;&#30697;&#38453;&#20998;&#35299;&#65292;BMF&#20351;&#29992;&#24067;&#23572;OR&#21644;&#24067;&#23572;AND&#25805;&#20316;&#36827;&#34892;&#30697;&#38453;&#20056;&#31215;&#36816;&#31639;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#20302;&#30340;&#37325;&#26500;&#35823;&#24046;&#12290;BMF&#26159;&#19968;&#20010;NP&#38590;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#26367;&#20248;&#21270;&#65288;AO&#65289;&#31574;&#30053;&#65292;&#20351;&#29992;&#25972;&#25968;&#35268;&#21010;&#65288;IP&#65289;&#35299;&#20915;BMF&#20013;&#19968;&#20010;&#22240;&#23376;&#30697;&#38453;&#30340;&#23376;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20004;&#31181;&#21021;&#22987;&#21270;&#22240;&#23376;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#21478;&#19968;&#20010;IP&#23558;BMF&#30340;&#22810;&#20010;&#35299;&#32452;&#21512;&#21040;&#26368;&#20248;&#35299;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65306;&#20351;&#29992;AO&#29983;&#25104;&#22810;&#20010;&#35299;&#65292;&#28982;&#21518;&#23558;&#23427;&#20204;&#20197;&#26368;&#20248;&#30340;&#26041;&#24335;&#32452;&#21512;&#36215;&#26469;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#65288;&#21487;&#22312;GitLab&#19978;&#33719;&#24471;&#65289;&#22312;&#20013;&#31561;&#35268;&#27169;&#38382;&#39064;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#30340;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. As opposed to binary matrix factorization which uses standard arithmetic, BMF uses the Boolean OR and Boolean AND operations to perform matrix products, which leads to lower reconstruction errors. BMF is an NP-hard problem. In this paper, we first propose an alternating optimization (AO) strategy that solves the subproblem in one factor matrix in BMF using an integer program (IP). We also provide two ways to initialize the factors within AO. Then, we show how several solutions of BMF can be combined optimally using another IP. This allows us to come up with a new algorithm: it generates several solutions using AO and then combines them in an optimal way. Experiments show that our algorithms (available on gitlab) outperform the state of the art on medium-scale problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TwinGP&#30340;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;&#36817;&#20284;&#26694;&#26550;&#65292;&#20351;&#29992;&#23376;&#38598;&#25968;&#25454;&#26041;&#27861;&#65292;&#24182;&#23558;&#30456;&#20851;&#20989;&#25968;&#24314;&#27169;&#20026;&#20840;&#23616;&#21644;&#23616;&#37096;&#26680;&#30340;&#32452;&#21512;&#12290;TwinGP&#22312;&#35745;&#31639;&#25104;&#26412;&#30340;&#19968;&#23567;&#37096;&#20998;&#19979;&#34920;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;GP&#24314;&#27169;&#26041;&#27861;&#30456;&#24403;&#25110;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.10158</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#30340;&#20840;&#23616;-&#23616;&#37096;&#36817;&#20284;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Global-Local Approximation Framework for Large-Scale Gaussian Process Modeling. (arXiv:2305.10158v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TwinGP&#30340;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;&#36817;&#20284;&#26694;&#26550;&#65292;&#20351;&#29992;&#23376;&#38598;&#25968;&#25454;&#26041;&#27861;&#65292;&#24182;&#23558;&#30456;&#20851;&#20989;&#25968;&#24314;&#27169;&#20026;&#20840;&#23616;&#21644;&#23616;&#37096;&#26680;&#30340;&#32452;&#21512;&#12290;TwinGP&#22312;&#35745;&#31639;&#25104;&#26412;&#30340;&#19968;&#23567;&#37096;&#20998;&#19979;&#34920;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;GP&#24314;&#27169;&#26041;&#27861;&#30456;&#24403;&#25110;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#24314;&#27169;&#26694;&#26550;&#12290;&#19982;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#35299;&#20915;&#31934;&#30830;GP&#24314;&#27169;&#30340;&#20840;&#23616;&#21644;&#23616;&#37096;&#36817;&#20284;&#30456;&#21453;&#65292;&#25105;&#20204;&#22312;&#26500;&#24314;&#36817;&#20284;&#26102;&#37319;&#29992;&#20102;&#20840;&#23616;&#21644;&#23616;&#37096;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#23376;&#38598;&#25968;&#25454;&#26041;&#27861;&#65292;&#20854;&#20013;&#23376;&#38598;&#26159;&#19968;&#20010;&#26088;&#22312;&#25429;&#25417;&#25968;&#25454;&#20840;&#23616;&#36235;&#21183;&#30340;&#20840;&#23616;&#28857;&#38598;&#30340;&#24182;&#38598;&#65292;&#20197;&#21450;&#19968;&#20010;&#26088;&#22312;&#25429;&#25417;&#32473;&#23450;&#27979;&#35797;&#20301;&#32622;&#21608;&#22260;&#23616;&#37096;&#36235;&#21183;&#30340;&#23616;&#37096;&#28857;&#38598;&#12290;&#30456;&#20851;&#20989;&#25968;&#20063;&#34987;&#24314;&#27169;&#20026;&#20840;&#23616;&#21644;&#23616;&#37096;&#26680;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#24615;&#33021;&#65292;&#21363;TwinGP&#65292;&#22312;&#35745;&#31639;&#25104;&#26412;&#30340;&#19968;&#23567;&#37096;&#20998;&#19979;&#19982;&#26368;&#20808;&#36827;&#30340;GP&#24314;&#27169;&#26041;&#27861;&#30456;&#24403;&#25110;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a novel framework for large-scale Gaussian process (GP) modeling. Contrary to the global, and local approximations proposed in the literature to address the computational bottleneck with exact GP modeling, we employ a combined global-local approach in building the approximation. Our framework uses a subset-of-data approach where the subset is a union of a set of global points designed to capture the global trend in the data, and a set of local points specific to a given testing location to capture the local trend around the testing location. The correlation function is also modeled as a combination of a global, and a local kernel. The performance of our framework, which we refer to as TwinGP, is on par or better than the state-of-the-art GP modeling methods at a fraction of their computational cost.
&lt;/p&gt;</description></item><item><title>&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#20013;&#20351;&#29992;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35780;&#20272;&#31232;&#30095;&#30697;&#38453;&#20808;&#39564;&#20013;&#24402;&#19968;&#21270;&#22240;&#23376;&#30340;&#38646;&#28857;&#26469;&#36827;&#34892;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#26032;&#22411;&#25968;&#20540;&#26041;&#27861;&#65292;&#24182;&#22312;&#22320;&#38754;&#30495;&#23454;&#31232;&#30095;&#30697;&#38453;&#37325;&#24314;&#20013;&#34920;&#29616;&#20986;&#20248;&#24322;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.10114</link><description>&lt;p&gt;
&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#20013;&#30340;&#33258;&#21160;&#36229;&#21442;&#25968;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Automatic Hyperparameter Tuning in Sparse Matrix Factorization. (arXiv:2305.10114v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10114
&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#20013;&#20351;&#29992;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35780;&#20272;&#31232;&#30095;&#30697;&#38453;&#20808;&#39564;&#20013;&#24402;&#19968;&#21270;&#22240;&#23376;&#30340;&#38646;&#28857;&#26469;&#36827;&#34892;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#26032;&#22411;&#25968;&#20540;&#26041;&#27861;&#65292;&#24182;&#22312;&#22320;&#38754;&#30495;&#23454;&#31232;&#30095;&#30697;&#38453;&#37325;&#24314;&#20013;&#34920;&#29616;&#20986;&#20248;&#24322;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#20013;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#22522;&#20110;&#20960;&#20010;&#36817;&#20284;&#65292;&#36890;&#36807;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#24471;&#21040;&#20102;&#20855;&#26377;&#25289;&#26222;&#25289;&#26031;&#20808;&#39564;&#30340;&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#30340;&#20998;&#26512;&#35299;&#12290;&#22522;&#20110;&#27492;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35780;&#20272;&#31232;&#30095;&#30697;&#38453;&#20808;&#39564;&#20013;&#24402;&#19968;&#21270;&#22240;&#23376;&#30340;&#38646;&#28857;&#26469;&#36827;&#34892;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#26032;&#22411;&#25968;&#20540;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#19982;&#24191;&#27867;&#20351;&#29992;&#30340;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#31639;&#27861;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22320;&#38754;&#30495;&#23454;&#31232;&#30095;&#30697;&#38453;&#37325;&#24314;&#20013;&#34920;&#29616;&#20986;&#30340;&#20248;&#24322;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of hyperparameter tuning in sparse matrix factorization under Bayesian framework. In the prior work, an analytical solution of sparse matrix factorization with Laplace prior was obtained by variational Bayes method under several approximations. Based on this solution, we propose a novel numerical method of hyperparameter tuning by evaluating the zero point of normalization factor in sparse matrix prior. We also verify that our method shows excellent performance for ground-truth sparse matrix reconstruction by comparing it with the widely-used algorithm of sparse principal component analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#36866;&#29992;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#35753;&#23398;&#20064;&#32773;&#30340;&#22870;&#21169;&#20540;&#21644;&#26368;&#20248;&#35299;&#27169;&#20223;&#19987;&#23478;&#65292;&#20855;&#26377;&#19968;&#23450;&#30340;&#23454;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.10089</link><description>&lt;p&gt;
&#19968;&#31181;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
A proof of imitation of Wasserstein inverse reinforcement learning for multi-objective optimization. (arXiv:2305.10089v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#36866;&#29992;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#35753;&#23398;&#20064;&#32773;&#30340;&#22870;&#21169;&#20540;&#21644;&#26368;&#20248;&#35299;&#27169;&#20223;&#19987;&#23478;&#65292;&#20855;&#26377;&#19968;&#23450;&#30340;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#22312;&#26377;&#38480;&#27425;&#36845;&#20195;&#20013;&#35753;&#23398;&#20064;&#32773;&#30340;&#22870;&#21169;&#20540;&#27169;&#20223;&#19987;&#23478;&#30340;&#22870;&#21169;&#20540;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#35789;&#20856;&#24207;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#65292;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#35753;&#23398;&#20064;&#32773;&#30340;&#26368;&#20248;&#35299;&#27169;&#20223;&#19987;&#23478;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove Wasserstein inverse reinforcement learning enables the learner's reward values to imitate the expert's reward values in a finite iteration for multi-objective optimizations. Moreover, we prove Wasserstein inverse reinforcement learning enables the learner's optimal solutions to imitate the expert's optimal solutions for multi-objective optimizations with lexicographic order.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;RF&#31639;&#27861;&#30340;1&#27493;&#21644;2&#27493;&#26368;&#20248;&#21152;&#26435;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#26469;&#22788;&#29702;&#39044;&#27979;&#24615;&#33021;&#24046;&#24322;&#38382;&#39064;&#65292;&#35777;&#26126;&#28176;&#36817;&#26368;&#20248;&#65292;&#24182;&#36827;&#34892;&#20102;&#25968;&#25454;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2305.10042</link><description>&lt;p&gt;
&#26368;&#20248;&#21152;&#26435;&#38543;&#26426;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Optimal Weighted Random Forests. (arXiv:2305.10042v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10042
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;RF&#31639;&#27861;&#30340;1&#27493;&#21644;2&#27493;&#26368;&#20248;&#21152;&#26435;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#26469;&#22788;&#29702;&#39044;&#27979;&#24615;&#33021;&#24046;&#24322;&#38382;&#39064;&#65292;&#35777;&#26126;&#28176;&#36817;&#26368;&#20248;&#65292;&#24182;&#36827;&#34892;&#20102;&#25968;&#25454;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#38543;&#26426;&#26862;&#26519; (RF) &#31639;&#27861;&#30340;&#20248;&#21270;&#21152;&#26435;&#26041;&#27861;&#65292;&#38024;&#23545;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#27493;&#26368;&#20248;&#21152;&#26435;&#38543;&#26426;&#26862;&#26519; (1step-WRF$_\mathrm{opt}$) &#21644;&#20004;&#27493;&#26368;&#20248;&#21152;&#26435;&#38543;&#26426;&#26862;&#26519; (2steps-WRF$_\mathrm{opt}$)&#65292;&#36890;&#36807;&#21152;&#26435;&#36873;&#25321;&#20934;&#21017;&#26469;&#32452;&#21512;&#22522;&#26412;&#23398;&#20064;&#22120;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#20316;&#32773;&#35777;&#26126;&#20102;&#36825;&#20123;&#31639;&#27861;&#26159;&#28176;&#36817;&#26368;&#20248;&#30340;&#65292;&#21363;&#24471;&#21040;&#30340;&#24179;&#26041;&#25439;&#22833;&#21644;&#39118;&#38505;&#19982;&#19981;&#21487;&#34892;&#20294;&#26368;&#20339;&#27169;&#22411;&#24179;&#22343;&#20272;&#35745;&#37327;&#30340;&#30456;&#23545;&#24046;&#24322;&#28176;&#36817;&#31561;&#21516;&#12290;&#26368;&#21518;&#65292;&#20316;&#32773;&#20351;&#29992;&#25968;&#25454;&#30740;&#31350;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The random forest (RF) algorithm has become a very popular prediction method for its great flexibility and promising accuracy. In RF, it is conventional to put equal weights on all the base learners (trees) to aggregate their predictions. However, the predictive performances of different trees within the forest can be very different due to the randomization of the embedded bootstrap sampling and feature selection. In this paper, we focus on RF for regression and propose two optimal weighting algorithms, namely the 1 Step Optimal Weighted RF (1step-WRF$_\mathrm{opt}$) and 2 Steps Optimal Weighted RF (2steps-WRF$_\mathrm{opt}$), that combine the base learners through the weights determined by weight choice criteria. Under some regularity conditions, we show that these algorithms are asymptotically optimal in the sense that the resulting squared loss and risk are asymptotically identical to those of the infeasible but best possible model averaging estimator. Numerical studies conducted on
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2305.10015</link><description>&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#25928;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Utility Theory of Synthetic Data Generation. (arXiv:2305.10015v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#30340;&#25928;&#29992;&#23545;&#20110;&#34913;&#37327;&#21512;&#25104;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#32467;&#26524;&#20391;&#37325;&#20110;&#23545;&#21512;&#25104;&#25968;&#25454;&#25928;&#29992;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#32780;&#38024;&#23545;&#21512;&#25104;&#25968;&#25454;&#31639;&#27861;&#22914;&#20309;&#24433;&#21709;&#25928;&#29992;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#12290;&#35813;&#25351;&#26631;&#23450;&#20041;&#20026;&#22312;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#20043;&#38388;&#27867;&#21270;&#30340;&#32477;&#23545;&#24046;&#24322;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35813;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#26469;&#30740;&#31350;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#12290;&#19968;&#20010;&#26377;&#36259;&#30340;&#32467;&#26524;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#21017;&#35813;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;&#21478;&#19968;&#20010;&#37325;&#35201;&#30340;&#25928;&#29992;&#25351;&#26631;&#22522;&#20110;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#20043;&#38388;&#28508;&#22312;&#30340;&#22240;&#26524;&#26426;&#21046;&#19968;&#33268;&#24615;&#12290;&#35813;&#29702;&#35770;&#20351;&#29992;&#20960;&#31181;&#21512;&#25104;&#31639;&#27861;&#36827;&#34892;&#35828;&#26126;&#65292;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#25928;&#29992;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating the utility of synthetic data is critical for measuring the effectiveness and efficiency of synthetic algorithms. Existing results focus on empirical evaluations of the utility of synthetic data, whereas the theoretical understanding of how utility is affected by synthetic data algorithms remains largely unexplored. This paper establishes utility theory from a statistical perspective, aiming to quantitatively assess the utility of synthetic algorithms based on a general metric. The metric is defined as the absolute difference in generalization between models trained on synthetic and original datasets. We establish analytical bounds for this utility metric to investigate critical conditions for the metric to converge. An intriguing result is that the synthetic feature distribution is not necessarily identical to the original one for the convergence of the utility metric as long as the model specification in downstream learning tasks is correct. Another important utility metri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#29992;&#20110;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;</title><link>http://arxiv.org/abs/2305.09957</link><description>&lt;p&gt;
&#28145;&#24230;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#23545;&#24212;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep quantum neural networks form Gaussian processes. (arXiv:2305.09957v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#29992;&#20110;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#20808;&#39564;&#26465;&#20214;&#24320;&#22987;&#21021;&#22987;&#21270;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#38544;&#34255;&#23618;&#31070;&#32463;&#20803;&#25968;&#30446;&#36275;&#22815;&#22823;&#30340;&#26497;&#38480;&#19979;&#25910;&#25947;&#21040;&#39640;&#26031;&#36807;&#31243;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNNs&#65289;&#20063;&#23384;&#22312;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;QNNs&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#32500;&#24230;$d$&#36275;&#22815;&#22823;&#26102;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#30001;&#20110;&#36755;&#20837;&#29366;&#24577;&#12289;&#27979;&#37327;&#30340;&#21487;&#35266;&#27979;&#37327;&#20197;&#21450;&#37193;&#30697;&#38453;&#30340;&#20803;&#32032;&#19981;&#29420;&#31435;&#31561;&#22240;&#32032;&#30340;&#20316;&#29992;&#65292;&#26412;&#25991;&#23545;&#36825;&#19968;&#32467;&#26524;&#30340;&#25512;&#23548;&#27604;&#32463;&#20856;&#24773;&#24418;&#26356;&#21152;&#24494;&#22937;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#19968;&#20010;&#37325;&#35201;&#21518;&#26524;&#26159;&#65292;&#36825;&#20010;&#32467;&#26524;&#24471;&#21040;&#30340;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#22320;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;Haar&#38543;&#26426;QNNs&#20013;&#30340;&#27979;&#37327;&#29616;&#35937;&#27604;&#20197;&#21069;&#35748;&#20026;&#30340;&#35201;&#26356;&#20005;&#37325;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28436;&#21592;&#30340;&#38598;&#20013;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that artificial neural networks initialized from independent and identically distributed priors converge to Gaussian processes in the limit of large number of neurons per hidden layer. In this work we prove an analogous result for Quantum Neural Networks (QNNs). Namely, we show that the outputs of certain models based on Haar random unitary or orthogonal deep QNNs converge to Gaussian processes in the limit of large Hilbert space dimension $d$. The derivation of this result is more nuanced than in the classical case due the role played by the input states, the measurement observable, and the fact that the entries of unitary matrices are not independent. An important consequence of our analysis is that the ensuing Gaussian processes cannot be used to efficiently predict the outputs of the QNN via Bayesian statistics. Furthermore, our theorems imply that the concentration of measure phenomenon in Haar random QNNs is much worse than previously thought, as we prove that ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#27169;&#22411;&#39564;&#35777;&#20316;&#20026;&#27010;&#29575;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#22312;&#33258;&#20027;&#31995;&#32479;&#20013;&#20272;&#35745;&#25925;&#38556;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#34920;&#31034;&#25925;&#38556;&#36712;&#36857;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#33258;&#21160;&#24494;&#20998;&#35745;&#31639;&#36712;&#36857;&#26799;&#24230;&#12290;&#22312;&#22810;&#20010;&#22330;&#26223;&#19979;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#21442;&#25968;&#31354;&#38388;&#35206;&#30422;&#33539;&#22260;&#26041;&#38754;&#21462;&#24471;&#20102;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2305.09930</link><description>&lt;p&gt;
&#27169;&#22411;&#39564;&#35777;&#20316;&#20026;&#27010;&#29575;&#25512;&#26029;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model-based Validation as Probabilistic Inference. (arXiv:2305.09930v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09930
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#27169;&#22411;&#39564;&#35777;&#20316;&#20026;&#27010;&#29575;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#22312;&#33258;&#20027;&#31995;&#32479;&#20013;&#20272;&#35745;&#25925;&#38556;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#34920;&#31034;&#25925;&#38556;&#36712;&#36857;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#33258;&#21160;&#24494;&#20998;&#35745;&#31639;&#36712;&#36857;&#26799;&#24230;&#12290;&#22312;&#22810;&#20010;&#22330;&#26223;&#19979;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#21442;&#25968;&#31354;&#38388;&#35206;&#30422;&#33539;&#22260;&#26041;&#38754;&#21462;&#24471;&#20102;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22833;&#36133;&#20998;&#24067;&#26159;&#39564;&#35777;&#33258;&#20027;&#31995;&#32479;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20391;&#37325;&#20110;&#23547;&#25214;&#19968;&#23567;&#33539;&#22260;&#21021;&#22987;&#26465;&#20214;&#19979;&#30340;&#25925;&#38556;&#25110;&#23545;&#27979;&#35797;&#31995;&#32479;&#30340;&#23646;&#24615;&#20570;&#20986;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#23558;&#39034;&#24207;&#31995;&#32479;&#30340;&#25925;&#38556;&#36712;&#36857;&#20998;&#24067;&#20272;&#35745;&#35270;&#20026;&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#65292;&#24182;&#37319;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#21033;&#29992;&#31995;&#32479;&#21160;&#24577;&#30340;&#27169;&#25311;&#32467;&#26524;&#34920;&#31034;&#25925;&#38556;&#36712;&#36857;&#30340;&#20998;&#24067;&#12290;&#22312;&#35745;&#31639;&#36712;&#36857;&#26799;&#24230;&#26102;&#37319;&#29992;&#33258;&#21160;&#24494;&#20998;&#12290;&#25105;&#20204;&#22312;&#20498;&#31435;&#25670;&#25511;&#21046;&#31995;&#32479;&#12289;&#33258;&#20027;&#39550;&#39542;&#27773;&#36710;&#22330;&#26223;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#26376;&#29699;&#30528;&#38470;&#22120;&#20013;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#20351;&#29992;&#24320;&#31665;&#21363;&#29992;&#30340;Hamiltonian Monte Carlo&#36827;&#34892;&#37319;&#26679;&#65292;&#21516;&#26102;&#20351;&#29992;&#22810;&#38142;&#20197;&#25429;&#33719;&#22810;&#27169;&#24577;&#65292;&#24182;&#37319;&#29992;&#26799;&#24230;&#24179;&#28369;&#20197;&#23454;&#29616;&#23433;&#20840;&#36712;&#36857;&#12290;&#22312;&#25152;&#26377;&#23454;&#39564;&#20013;&#65292;&#19982;&#40657;&#30418;&#22522;&#32447;&#30456;&#27604;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#26679;&#26412;&#25928;&#29575;&#21644;&#21442;&#25968;&#31354;&#38388;&#35206;&#30422;&#33539;&#22260;&#30340;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the distribution over failures is a key step in validating autonomous systems. Existing approaches focus on finding failures for a small range of initial conditions or make restrictive assumptions about the properties of the system under test. We frame estimating the distribution over failure trajectories for sequential systems as Bayesian inference. Our model-based approach represents the distribution over failure trajectories using rollouts of system dynamics and computes trajectory gradients using automatic differentiation. Our approach is demonstrated in an inverted pendulum control system, an autonomous vehicle driving scenario, and a partially observable lunar lander. Sampling is performed using an off-the-shelf implementation of Hamiltonian Monte Carlo with multiple chains to capture multimodality and gradient smoothing for safe trajectories. In all experiments, we observed improvements in sample efficiency and parameter space coverage compared to black-box baseline a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SELO&#30340;&#38142;&#36335;&#31526;&#21495;&#39044;&#27979;&#27169;&#22411;&#65292;&#20351;&#29992;&#23376;&#22270;&#32534;&#30721;&#26041;&#27861;&#23398;&#20064;&#26377;&#21521;&#32593;&#32476;&#20013;&#30340;&#36793;&#23884;&#20837;&#12290;&#36890;&#36807;&#24341;&#20837;&#26377;&#31526;&#21495;&#23376;&#22270;&#32534;&#30721;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#32447;&#24615;&#20248;&#21270;&#26041;&#27861;&#23558;&#27599;&#20010;&#23376;&#22270;&#23884;&#20837;&#21040;&#20284;&#28982;&#30697;&#38453;&#20013;&#32780;&#38750;&#37051;&#25509;&#30697;&#38453;&#20013;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.09869</link><description>&lt;p&gt;
&#22522;&#20110;&#32447;&#24615;&#20248;&#21270;&#30340;&#26377;&#31526;&#21495;&#23376;&#22270;&#32534;&#30721;&#26041;&#27861;&#29992;&#20110;&#38142;&#36335;&#31526;&#21495;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Signed Subgraph Encoding Approach via Linear Optimization for Link Sign Prediction. (arXiv:2305.09869v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09869
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SELO&#30340;&#38142;&#36335;&#31526;&#21495;&#39044;&#27979;&#27169;&#22411;&#65292;&#20351;&#29992;&#23376;&#22270;&#32534;&#30721;&#26041;&#27861;&#23398;&#20064;&#26377;&#21521;&#32593;&#32476;&#20013;&#30340;&#36793;&#23884;&#20837;&#12290;&#36890;&#36807;&#24341;&#20837;&#26377;&#31526;&#21495;&#23376;&#22270;&#32534;&#30721;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#32447;&#24615;&#20248;&#21270;&#26041;&#27861;&#23558;&#27599;&#20010;&#23376;&#22270;&#23884;&#20837;&#21040;&#20284;&#28982;&#30697;&#38453;&#20013;&#32780;&#38750;&#37051;&#25509;&#30697;&#38453;&#20013;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#26377;&#38480;&#30340;&#26377;&#31526;&#21495;&#25968;&#25454;&#20013;&#26377;&#25928;&#22320;&#25512;&#26029;&#38142;&#36335;&#30340;&#31526;&#21495;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;SELO&#30340;&#38142;&#36335;&#31526;&#21495;&#39044;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#23376;&#22270;&#32534;&#30721;&#26041;&#27861;&#26469;&#23398;&#20064;&#26377;&#21521;&#32593;&#32476;&#20013;&#30340;&#36793;&#23884;&#20837;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#26041;&#27861;&#24341;&#20837;&#20102;&#26377;&#31526;&#21495;&#23376;&#22270;&#32534;&#30721;&#26041;&#27861;&#65292;&#23558;&#27599;&#20010;&#23376;&#22270;&#23884;&#20837;&#21040;&#20284;&#28982;&#30697;&#38453;&#20013;&#32780;&#19981;&#26159;&#37051;&#25509;&#30697;&#38453;&#20013;&#12290;&#22312;&#20845;&#20010;&#30495;&#23454;&#30340;&#26377;&#31526;&#21495;&#32593;&#32476;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#24182;&#20351;&#29992;AUC&#12289;F1&#12289;micro-F1&#21644;Macro-F1&#20316;&#20026;&#35780;&#20272;&#25351;&#26631;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;SELO&#27169;&#22411;&#22312;&#25152;&#26377;&#22235;&#20010;&#35780;&#20272;&#25351;&#26631;&#19978;&#22343;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of inferring the sign of a link based on limited sign data in signed networks. Regarding this link sign prediction problem, SDGNN (Signed Directed Graph Neural Networks) provides the best prediction performance currently to the best of our knowledge. In this paper, we propose a different link sign prediction architecture call SELO (Subgraph Encoding via Linear Optimization), which obtains overall leading prediction performances compared the state-of-the-art algorithm SDGNN. The proposed model utilizes a subgraph encoding approach to learn edge embeddings for signed directed networks. In particular, a signed subgraph encoding approach is introduced to embed each subgraph into a likelihood matrix instead of the adjacency matrix through a linear optimization method. Comprehensive experiments are conducted on six real-world signed networks with AUC, F1, micro-F1, and Macro-F1 as the evaluation metrics. The experiment results show that the proposed SEL
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#21517;&#20026;&#25311;&#24577;&#21021;&#22987;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20165;&#20165;&#35843;&#25972;&#33258;&#27880;&#24847;&#21147;&#23618;&#30340;&#26435;&#37325;&#21021;&#22987;&#21270;&#65292;&#21363;&#21487;&#22312;&#35270;&#35273;&#20219;&#21153;&#20013;&#22823;&#22823;&#25552;&#39640;Transformer&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.09828</link><description>&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#23618;&#30340;&#25311;&#24577;&#21021;&#22987;&#21270;
&lt;/p&gt;
&lt;p&gt;
Mimetic Initialization of Self-Attention Layers. (arXiv:2305.09828v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#21517;&#20026;&#25311;&#24577;&#21021;&#22987;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20165;&#20165;&#35843;&#25972;&#33258;&#27880;&#24847;&#21147;&#23618;&#30340;&#26435;&#37325;&#21021;&#22987;&#21270;&#65292;&#21363;&#21487;&#22312;&#35270;&#35273;&#20219;&#21153;&#20013;&#22823;&#22823;&#25552;&#39640;Transformer&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;Transformer&#21313;&#20998;&#22256;&#38590;&#12290;&#36890;&#24120;&#38656;&#35201;&#20197;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#27169;&#22411;&#20316;&#20026;&#36215;&#28857;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#36825;&#20123;&#39044;&#35757;&#32451;Transformer&#30340;&#26435;&#37325;&#65288;&#23588;&#20854;&#26159;&#29992;&#20110;&#35270;&#35273;&#20219;&#21153;&#65289;&#65292;&#35797;&#22270;&#25214;&#21040;&#36896;&#25104;&#36825;&#31181;&#24046;&#24322;&#30340;&#21407;&#22240;&#12290;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#20165;&#20165;&#36890;&#36807;&#21021;&#22987;&#21270;&#33258;&#27880;&#24847;&#21147;&#23618;&#30340;&#26435;&#37325;&#65292;&#20351;&#20854;&#8220;&#30475;&#36215;&#26469;&#8221;&#26356;&#20687;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#23601;&#33021;&#22815;&#26356;&#24555;&#19988;&#26356;&#39640;&#31934;&#24230;&#22320;&#35757;&#32451;&#26222;&#36890;Transformer&#65292;&#23588;&#20854;&#26159;&#22312;&#20687;CIFAR-10&#21644;ImageNet&#20998;&#31867;&#36825;&#26679;&#30340;&#35270;&#35273;&#20219;&#21153;&#19978;&#65292;&#25105;&#20204;&#30340;&#31934;&#24230;&#25552;&#39640;&#36229;&#36807;5&#65285;&#21644;4&#65285;&#12290;&#25105;&#20204;&#30340;&#21021;&#22987;&#21270;&#26041;&#26696;&#26159;&#38381;&#24335;&#30340;&#12289;&#26080;&#38656;&#23398;&#20064;&#30340;&#12289;&#38750;&#24120;&#31616;&#21333;&#65306;&#25105;&#20204;&#23558;&#26597;&#35810;&#21644;&#38190;&#26435;&#37325;&#30340;&#20056;&#31215;&#35774;&#32622;&#20026;&#36817;&#20284;&#20110;&#26631;&#35782;&#65292;&#23558;&#20540;&#21644;&#25237;&#24433;&#26435;&#37325;&#30340;&#20056;&#31215;&#36817;&#20284;&#20110;&#36127;&#26631;&#35782;&#12290;&#30001;&#20110;&#36825;&#31867;&#20284;&#20110;&#25105;&#20204;&#22312;&#39044;&#35757;&#32451;Transformer&#20013;&#30475;&#21040;&#30340;&#27169;&#24335;&#65292;&#25152;&#20197;&#25105;&#20204;&#31216;&#20026;&#8220;&#25311;&#24577;&#21021;&#22987;&#21270;&#8221;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is notoriously difficult to train Transformers on small datasets; typically, large pre-trained models are instead used as the starting point. We explore the weights of such pre-trained Transformers (particularly for vision) to attempt to find reasons for this discrepancy. Surprisingly, we find that simply initializing the weights of self-attention layers so that they "look" more like their pre-trained counterparts allows us to train vanilla Transformers faster and to higher final accuracies, particularly on vision tasks such as CIFAR-10 and ImageNet classification, where we see gains in accuracy of over 5% and 4%, respectively. Our initialization scheme is closed form, learning-free, and very simple: we set the product of the query and key weights to be approximately the identity, and the product of the value and projection weights to approximately the negative identity. As this mimics the patterns we saw in pre-trained Transformers, we call the technique "mimetic initialization".
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;&#22312;&#26080;&#27861;&#33719;&#24471;&#26410;&#26469;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#26102;&#65292;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#19981;&#21516;&#36164;&#28304;&#20998;&#37197;&#23545;&#24212;&#30340;&#22833;&#35823;&#27010;&#29575;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#29702;&#35770;&#26368;&#20248;&#12289;&#21487;&#35299;&#37322;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#32463;&#36807;&#27169;&#25311;&#39564;&#35777;&#20854;&#22312;&#22833;&#35823;&#27010;&#29575;&#12289;&#23398;&#20064;&#36895;&#24230;&#21644;&#25910;&#25947;&#31561;&#26041;&#38754;&#30340;&#34920;&#29616;&#20248;&#20110;&#19968;&#20123;&#24120;&#35265;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.09739</link><description>&lt;p&gt;
ML&#36741;&#21161;&#36164;&#28304;&#20998;&#37197;&#30340;&#22833;&#35823;&#24615;&#33021;&#21644;&#26032;&#22411;&#25439;&#22833;&#20989;&#25968;: &#19968;&#31181;&#31934;&#30830;&#20998;&#26512;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Outage Performance and Novel Loss Function for an ML-Assisted Resource Allocation: An Exact Analytical Framework. (arXiv:2305.09739v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#22312;&#26080;&#27861;&#33719;&#24471;&#26410;&#26469;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#26102;&#65292;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#19981;&#21516;&#36164;&#28304;&#20998;&#37197;&#23545;&#24212;&#30340;&#22833;&#35823;&#27010;&#29575;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#29702;&#35770;&#26368;&#20248;&#12289;&#21487;&#35299;&#37322;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#32463;&#36807;&#27169;&#25311;&#39564;&#35777;&#20854;&#22312;&#22833;&#35823;&#27010;&#29575;&#12289;&#23398;&#20064;&#36895;&#24230;&#21644;&#25910;&#25947;&#31561;&#26041;&#38754;&#30340;&#34920;&#29616;&#20248;&#20110;&#19968;&#20123;&#24120;&#35265;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26159;&#20351;6G&#21450;&#20197;&#19978;&#36890;&#20449;&#25104;&#20026;&#21487;&#33021;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#26412;&#25991;&#33268;&#21147;&#20110;&#23558;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#35299;&#20915;&#36825;&#20123;&#31995;&#32479;&#26222;&#36941;&#36935;&#21040;&#30340;&#22833;&#35823;&#27010;&#29575;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#21333;&#29992;&#25143;&#22810;&#36164;&#28304;&#36138;&#23146;&#20998;&#37197;&#31574;&#30053;&#65292;&#20854;&#20013;&#19968;&#20010;ML&#20108;&#20998;&#31867;&#39044;&#27979;&#22120;&#22312;&#36873;&#25321;&#20805;&#36275;&#36164;&#28304;&#26102;&#36827;&#34892;&#36741;&#21161;&#12290;&#24403;&#39044;&#27979;&#22120;&#36935;&#21040;&#30456;&#20449;&#20250;&#28385;&#24847;&#30340;&#36164;&#28304;&#26102;&#65292;&#23427;&#23558;&#20854;&#20998;&#37197;&#32473;&#29992;&#25143;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#24314;&#31435;&#20102;&#35813;&#31995;&#32479;&#22833;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#21644;&#28176;&#36827;&#34920;&#36798;&#24335;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#31181;&#29702;&#35770;&#26368;&#20248;&#30340;&#12289;&#21487;&#24494;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#35757;&#32451;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#27604;&#36739;&#20351;&#29992;&#27492;&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#30340;&#39044;&#27979;&#22120;&#21644;&#20351;&#29992;&#20854;&#20182;&#24120;&#29992;&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#30340;&#39044;&#27979;&#22120;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#23545;&#39044;&#27979;&#22120;&#36879;&#26126;&#24230;&#21644;&#26080;&#32447;&#20449;&#36947;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#22312;&#22833;&#35823;&#27010;&#29575;&#12289;&#31471;&#21040;&#31471;&#23398;&#20064;&#36895;&#24230;&#21644;&#25910;&#25947;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#20108;&#20803;&#20132;&#21449;&#29109;&#30340;&#25439;&#22833;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25439;&#22833;&#20989;&#25968;&#21046;&#23450;&#36171;&#20104;&#20102;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#22120;&#35757;&#32451;&#65292;&#33021;&#22815;&#31283;&#20581;&#22320;&#22788;&#29702;&#20449;&#36947;&#30340;&#26102;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) is a popular tool that will be pivotal in enabling 6G and beyond communications. This paper focuses on applying ML solutions to address outage probability issues commonly encountered in these systems. In particular, we consider a single-user multi-resource greedy allocation strategy, where an ML binary classification predictor assists in seizing an adequate resource. With no access to future channel state information, this predictor foresees each resource's likely future outage status. When the predictor encounters a resource it believes will be satisfactory, it allocates it to the user. Critically, the goal of the predictor is to ensure that a user avoids an unsatisfactory resource since this is likely to cause an outage. Our main result establishes exact and asymptotic expressions for this system's outage probability. With this, we formulate a theoretically optimal, differentiable loss function to train our predictor. We then compare predictors trained using thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#38544;&#31169;&#35201;&#27714;&#19979;&#30340;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#20004;&#32452;&#20855;&#26377;&#19981;&#21516;&#38544;&#31169;&#32423;&#21035;&#30340;&#29992;&#25143;&#26102;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#30340;&#65292;&#24182;&#25581;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#39281;&#21644;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2305.09668</link><description>&lt;p&gt;
&#24322;&#26500;&#38544;&#31169;&#19979;&#30340;&#22343;&#20540;&#20272;&#35745;: &#37096;&#20998;&#38544;&#31169;&#26159;&#21487;&#20197;&#20813;&#36153;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mean Estimation Under Heterogeneous Privacy: Some Privacy Can Be Free. (arXiv:2305.09668v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09668
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#38544;&#31169;&#35201;&#27714;&#19979;&#30340;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#20004;&#32452;&#20855;&#26377;&#19981;&#21516;&#38544;&#31169;&#32423;&#21035;&#30340;&#29992;&#25143;&#26102;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#30340;&#65292;&#24182;&#25581;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#39281;&#21644;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169; (DP) &#26159;&#19968;&#31181;&#34987;&#24191;&#27867;&#36816;&#29992;&#29992;&#20110;&#34913;&#37327;&#31639;&#27861;&#38544;&#31169;&#25439;&#22833;&#30340;&#26694;&#26550;&#12290;&#20256;&#32479;&#30340;DP&#24418;&#24335;&#23545;&#25152;&#26377;&#29992;&#25143;&#24378;&#21046;&#26045;&#21152;&#19968;&#33268;&#30340;&#38544;&#31169;&#35201;&#27714;&#65292;&#36825;&#19982;&#29616;&#23454;&#22330;&#26223;&#36890;&#24120;&#19981;&#19968;&#33268;&#65292;&#22240;&#20026;&#29992;&#25143;&#20010;&#20307;&#20915;&#23450;&#20182;&#20204;&#30340;&#38544;&#31169;&#20559;&#22909;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#24322;&#26500;DP&#32422;&#26463;&#19979;&#30340;&#24179;&#22343;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#29992;&#25143;&#21487;&#20197;&#26045;&#21152;&#33258;&#24049;&#29420;&#29305;&#30340;&#38544;&#31169;&#27700;&#24179;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#20004;&#32452;&#20855;&#26377;&#19981;&#21516;&#38544;&#31169;&#32423;&#21035;&#30340;&#29992;&#25143;&#26102;&#34987;&#35777;&#26126;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#39281;&#21644;&#29616;&#35937;&#65292;&#21363;&#22312;&#19968;&#32452;&#29992;&#25143;&#30340;&#38544;&#31169;&#27700;&#24179;&#34987;&#25918;&#23485;&#32780;&#21478;&#19968;&#32452;&#29992;&#25143;&#30340;&#38544;&#31169;&#27700;&#24179;&#20445;&#25345;&#19981;&#21464;&#26102;&#21457;&#29983;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22312;&#26576;&#20010;&#29305;&#23450;&#24773;&#24418;&#19979;&#65292;&#36827;&#19968;&#27493;&#25918;&#23485;&#21069;&#19968;&#32452;&#30340;&#38544;&#31169;&#35201;&#27714;&#24182;&#19981;&#20250;&#25913;&#21892;&#26368;&#23567;&#20108;&#20056;&#24179;&#22343;&#25968;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#20013;&#22830;&#26381;&#21153;&#22120;&#21487;&#20197;&#25552;&#20379;&#19968;&#23450;&#31243;&#24230;&#30340;&#38544;&#31169;&#32780;&#19981;&#20250;&#29306;&#29298;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy (DP) is a well-established framework to quantify privacy loss incurred by any algorithm. Traditional DP formulations impose a uniform privacy requirement for all users, which is often inconsistent with real-world scenarios in which users dictate their privacy preferences individually. This work considers the problem of mean estimation under heterogeneous DP constraints, where each user can impose their own distinct privacy level. The algorithm we propose is shown to be minimax optimal when there are two groups of users with distinct privacy levels. Our results elicit an interesting saturation phenomenon that occurs as one group's privacy level is relaxed, while the other group's privacy level remains constant. Namely, after a certain point, further relaxing the privacy requirement of the former group does not improve the performance of the minimax optimal mean estimator. Thus, the central server can offer a certain degree of privacy without any sacrifice in perform
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.08074</link><description>&lt;p&gt;
&#27491;&#20132;&#22810;&#39033;&#24335;&#36924;&#36817;&#21644;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#22312;&#28151;&#27788;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos. (arXiv:2305.08074v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#26159;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#21160;&#24577;&#30340;&#39044;&#27979;&#21644;&#27169;&#22411;&#31616;&#21270;&#65292;&#22312;&#29289;&#29702;&#31185;&#23398;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#24456;&#31616;&#21333;&#65292;&#20294;&#22312;&#30830;&#23450;&#24615;&#28151;&#27788;&#20013;&#65292;&#23427;&#30340;&#24615;&#36136;&#25110;&#32773;&#23427;&#30340;&#25910;&#25947;&#24615;&#36824;&#19981;&#28165;&#26970;&#12290;&#29305;&#21035;&#26159;&#65292;EDMD&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#22914;&#20309;&#22788;&#29702;&#38656;&#35201;&#25551;&#32472;&#28151;&#27788;&#21160;&#21147;&#23398;&#21547;&#20041;&#30340;&#27491;&#21017;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#20063;&#26159;&#19981;&#28165;&#26970;&#30340;&#12290;&#26412;&#25991;&#22312;&#20998;&#26512;&#19978;&#31616;&#21333;&#30340;&#19968;&#20010;&#22278;&#29615;&#23637;&#24320;&#26144;&#23556;&#30340;&#26368;&#31616;&#21333;&#20363;&#23376;&#19978;&#65292;&#21457;&#23637;&#20102;&#20851;&#20110;EDMD&#30340;&#19968;&#33324;&#30340;&#12289;&#20005;&#26684;&#30340;&#29702;&#35770;&#12290;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#20851;&#20110;&#22312;&#21333;&#20301;&#22278;&#19978;&#30340;&#27491;&#20132;&#22810;&#39033;&#24335;&#65288;OPUC&#65289;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#26102;&#65292;&#38024;&#23545;&#22810;&#39033;&#24335;&#30340;&#21487;&#35266;&#27979;&#23383;&#20856;&#30340;&#26368;&#23567;&#20108;&#20056;&#25237;&#24433;&#20855;&#26377;&#25351;&#25968;&#25928;&#29575;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#21040;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#30340;&#25351;&#25968;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extended Dynamic Mode Decomposition (EDMD) is a data-driven tool for forecasting and model reduction of dynamics, which has been extensively taken up in the physical sciences. While the method is conceptually simple, in deterministic chaos it is unclear what its properties are or even what it converges to. In particular, it is not clear how EDMD's least-squares approximation treats the classes of regular functions needed to make sense of chaotic dynamics.  In this paper we develop a general, rigorous theory of EDMD on the simplest examples of chaotic maps: analytic expanding maps of the circle. Proving a new result in the theory of orthogonal polynomials on the unit circle (OPUC), we show that in the infinite-data limit, the least-squares projection is exponentially efficient for polynomial observable dictionaries. As a result, we show that the forecasts and Koopman spectral data produced using EDMD in this setting converge to the physically meaningful limits, at an exponential rate.  
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29702;&#35770;&#23618;&#38754;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#21644;&#24120;&#35268;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.06137</link><description>&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A proof of convergence of inverse reinforcement learning for multi-objective optimization. (arXiv:2305.06137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29702;&#35770;&#23618;&#38754;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#21644;&#24120;&#35268;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#31561;&#25928;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;WIRL&#38382;&#39064;&#30340;&#36870;&#38382;&#39064;&#19982;&#25237;&#24433;&#27425;&#26799;&#24230;&#27861;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;WIRL&#65289;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;&#26368;&#22823;&#29109;&#36870;&#24378;&#21270;&#23398;&#20064;&#65292;&#23548;&#24341;&#25104;&#26412;&#23398;&#20064;&#65289;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show the convergence of Wasserstein inverse reinforcement learning (WIRL) for multi-objective optimizations with the projective subgradient method by formulating an inverse problem of the optimization problem that is equivalent to WIRL for multi-objective optimizations.  In addition, we prove convergence of inverse reinforcement learning (maximum entropy inverse reinforcement learning, guid cost learning) for multi-objective optimization with the projective subgradient method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;</title><link>http://arxiv.org/abs/2305.05465</link><description>&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#21160;&#24577;&#20013;&#30340;&#32858;&#31867;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
The emergence of clusters in self-attention dynamics. (arXiv:2305.05465v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;Transformer&#35270;&#20026;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24403;&#26435;&#37325;&#19981;&#38543;&#26102;&#38388;&#21464;&#21270;&#26102;&#65292;&#26412;&#25991;&#25551;&#36848;&#20102;&#23398;&#20064;&#34920;&#31034;&#30340;&#20960;&#20309;&#24418;&#29366;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20195;&#34920;token&#30340;&#31890;&#23376;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#32780;&#36235;&#21521;&#20110;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#12290;&#20986;&#29616;&#30340;&#26497;&#38480;&#23545;&#35937;&#31867;&#22411;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;&#27492;&#22806;&#65292;&#22312;&#19968;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#25105;&#27880;&#24847;&#21147;&#30697;&#38453;&#25910;&#25947;&#20110;&#20302;&#31209;&#24067;&#23572;&#30697;&#38453;&#12290;&#36825;&#20123;&#32467;&#26524;&#30340;&#32452;&#21512;&#22312;&#25968;&#23398;&#19978;&#35777;&#23454;&#20102;Vaswani&#31561;&#20154;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#20250;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Viewing Transformers as interacting particle systems, we describe the geometry of learned representations when the weights are not time dependent. We show that particles, representing tokens, tend to cluster toward particular limiting objects as time tends to infinity. The type of limiting object that emerges depends on the spectrum of the value matrix. Additionally, in the one-dimensional case we prove that the self-attention matrix converges to a low-rank Boolean matrix. The combination of these results mathematically confirms the empirical observation made by Vaswani et al. \cite{vaswani2017attention} that \emph{leaders} appear in a sequence of tokens when processed by Transformers.
&lt;/p&gt;</description></item><item><title>PED-ANOVA &#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#35745;&#31639;&#36229;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#26377;&#21161;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2304.10255</link><description>&lt;p&gt;
PED-ANOVA: &#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#37327;&#21270;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
PED-ANOVA: Efficiently Quantifying Hyperparameter Importance in Arbitrary Subspaces. (arXiv:2304.10255v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10255
&lt;/p&gt;
&lt;p&gt;
PED-ANOVA &#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#35745;&#31639;&#36229;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#26377;&#21161;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#27969;&#34892;&#20351;&#24471;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#23545;&#20110;&#35757;&#32451;&#24378;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#21448;&#20005;&#37325;&#20381;&#36182;&#20110;&#20102;&#35299;&#19981;&#21516;&#36229;&#21442;&#25968;&#30340;&#20316;&#29992;&#12290;&#36825;&#28608;&#21457;&#20102;&#20851;&#20110;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;&#30340;&#30740;&#31350;&#65292;&#20363;&#22914;&#20351;&#29992;&#21151;&#33021;&#26041;&#24046;&#20998;&#26512; (f-ANOVA) &#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#21407;&#22987;&#30340; f-ANOVA &#20844;&#24335;&#19981;&#36866;&#29992;&#20110;&#31639;&#27861;&#35774;&#35745;&#24072;&#26368;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#65292;&#20363;&#22914;&#30001;&#26368;&#20339;&#24615;&#33021;&#23450;&#20041;&#30340;&#23376;&#31354;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#26032;&#30340;&#38024;&#23545;&#20219;&#24847;&#23376;&#31354;&#38388;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#20351;&#29992; Pearson &#25955;&#24230; (PED) &#23454;&#29616;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;&#30340;&#38381;&#24335;&#35745;&#31639;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36825;&#20010;&#26032;&#31639;&#27861;&#65292;&#31216;&#20026; PED-ANOVA&#65292;&#33021;&#22815;&#25104;&#21151;&#22320;&#35782;&#21035;&#19981;&#21516;&#23376;&#31354;&#38388;&#20013;&#37325;&#35201;&#30340;&#36229;&#21442;&#25968;&#65292;&#21516;&#26102;&#35745;&#31639;&#25928;&#29575;&#26497;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent rise in popularity of Hyperparameter Optimization (HPO) for deep learning has highlighted the role that good hyperparameter (HP) space design can play in training strong models. In turn, designing a good HP space is critically dependent on understanding the role of different HPs. This motivates research on HP Importance (HPI), e.g., with the popular method of functional ANOVA (f-ANOVA). However, the original f-ANOVA formulation is inapplicable to the subspaces most relevant to algorithm designers, such as those defined by top performance. To overcome this problem, we derive a novel formulation of f-ANOVA for arbitrary subspaces and propose an algorithm that uses Pearson divergence (PED) to enable a closed-form computation of HPI. We demonstrate that this new algorithm, dubbed PED-ANOVA, is able to successfully identify important HPs in different subspaces while also being extremely computationally efficient.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#26679;&#26412;&#24179;&#22343;&#20272;&#35745;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#31561;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#19988;&#24615;&#33021;&#26356;&#20339;&#12290;</title><link>http://arxiv.org/abs/2304.06803</link><description>&lt;p&gt;
&#29992;&#20110;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#26679;&#26412;&#24179;&#22343;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample Average Approximation for Black-Box VI. (arXiv:2304.06803v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06803
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#26679;&#26412;&#24179;&#22343;&#20272;&#35745;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#31561;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#19988;&#24615;&#33021;&#26356;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#30340;&#22256;&#38590;&#65292;&#21253;&#25324;&#36873;&#25321;&#27493;&#38271;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#19968;&#31995;&#21015;&#26679;&#26412;&#24179;&#22343;&#20272;&#35745;&#38382;&#39064;&#65288;SAA&#65289;&#12290;&#36890;&#36807;&#23558;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;SAA&#36924;&#36817;&#20102;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#25311;&#29275;&#39039;&#26041;&#27861;&#21644;&#32447;&#24615;&#25628;&#32034;&#26469;&#35299;&#20915;&#27599;&#20010;&#30830;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21457;&#24335;&#31574;&#30053;&#26469;&#33258;&#21160;&#36873;&#25321;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#31616;&#21270;&#20102;&#21464;&#20998;&#25512;&#26029;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel approach for black-box VI that bypasses the difficulties of stochastic gradient ascent, including the task of selecting step-sizes. Our approach involves using a sequence of sample average approximation (SAA) problems. SAA approximates the solution of stochastic optimization problems by transforming them into deterministic ones. We use quasi-Newton methods and line search to solve each deterministic optimization problem and present a heuristic policy to automate hyperparameter selection. Our experiments show that our method simplifies the VI problem and achieves faster performance than existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.16822</link><description>&lt;p&gt;
&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#20284;&#36817;&#31471;&#31639;&#27861;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
An inexact linearized proximal algorithm for a class of DC composite optimization problems and applications. (arXiv:2303.16822v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#31867;&#38382;&#39064;&#36890;&#24120;&#30001;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#30340;&#40065;&#26834;&#20998;&#35299;&#27169;&#22411;&#25512;&#23548;&#32780;&#26469;&#65292;&#26159;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#21644;&#20855;&#26377;&#38750;&#20809;&#28369;&#20998;&#37327;&#30340;DC&#35268;&#21010;&#30340;&#25193;&#23637;&#12290;&#38024;&#23545;&#36825;&#31867;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65288;iLPA&#65289;&#12290;&#31639;&#27861;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#30446;&#26631;&#20989;&#25968;&#30340;&#37096;&#20998;&#32447;&#24615;&#21270;&#65292;&#35745;&#31639;&#24378;&#20984;&#20027;&#23548;&#30340;&#38750;&#31934;&#30830;&#26368;&#23567;&#21270;&#20540;&#12290;&#36845;&#20195;&#24207;&#21015;&#30340;&#29983;&#25104;&#25910;&#25947;&#20110;&#28508;&#22312;&#20989;&#25968;&#30340;Kurdyka-{\L}ojasiewicz&#65288;KL&#65289;&#24615;&#36136;&#65292;&#22914;&#26524;&#28508;&#22312;&#20989;&#25968;&#22312;&#26497;&#38480;&#28857;&#22788;&#20855;&#26377;KL&#25351;&#25968;$1/2$&#30340;KL&#24615;&#36136;&#65292;&#21017;&#25910;&#25947;&#20855;&#26377;&#23616;&#37096;R&#32447;&#24615;&#36895;&#29575;&#12290;&#23545;&#20110;&#21518;&#19968;&#31181;&#20551;&#35774;&#65292;&#25105;&#20204;&#21033;&#29992;&#22797;&#21512;&#32467;&#26500;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#39564;&#35777;&#30340;&#26465;&#20214;&#65292;&#24182;&#38416;&#26126;&#20102;&#19982;&#20984;&#22797;&#21512;&#20248;&#21270;&#25152;&#20351;&#29992;&#30340;&#27491;&#21017;&#24615;&#30340;&#20851;&#31995;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#31471;&#31639;&#27861;&#24212;&#29992;&#20110;&#35299;&#20915;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#24352;&#37327;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;TRPCA&#65289;&#21644;&#24352;&#37327;&#40065;&#26834;&#20302;&#31209;&#24352;&#37327;&#23436;&#25104;&#65288;TRLRTC&#65289;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#26032;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with a class of DC composite optimization problems which, as an extension of the convex composite optimization problem and the DC program with nonsmooth components, often arises from robust factorization models of low-rank matrix recovery. For this class of nonconvex and nonsmooth problems, we propose an inexact linearized proximal algorithm (iLPA) which in each step computes an inexact minimizer of a strongly convex majorization constructed by the partial linearization of their objective functions. The generated iterate sequence is shown to be convergent under the Kurdyka-{\L}ojasiewicz (KL) property of a potential function, and the convergence admits a local R-linear rate if the potential function has the KL property of exponent $1/2$ at the limit point. For the latter assumption, we provide a verifiable condition by leveraging the composite structure, and clarify its relation with the regularity used for the convex composite optimization. Finally, the propose
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#28145;&#24230;&#39640;&#26031;&#27169;&#22411;&#30340;&#29305;&#24449;&#21508;&#21521;&#24322;&#24615;&#23637;&#24320;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#31532;&#19968;&#23618;&#29305;&#24449;&#34892;&#20043;&#38388;&#20801;&#35768;&#23384;&#22312;&#30456;&#20851;&#24615;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#65292;&#32780;&#21518;&#32493;&#23618;&#30340;&#32467;&#26500;&#36890;&#24120;&#26159;&#19981;&#21033;&#30340;&#12290;</title><link>http://arxiv.org/abs/2303.00564</link><description>&lt;p&gt;
&#28145;&#24230;&#32467;&#26500;&#39640;&#26031;&#29305;&#24449;&#27169;&#22411;&#30340;&#23398;&#20064;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Learning curves for deep structured Gaussian feature models. (arXiv:2303.00564v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00564
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#28145;&#24230;&#39640;&#26031;&#27169;&#22411;&#30340;&#29305;&#24449;&#21508;&#21521;&#24322;&#24615;&#23637;&#24320;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#31532;&#19968;&#23618;&#29305;&#24449;&#34892;&#20043;&#38388;&#20801;&#35768;&#23384;&#22312;&#30456;&#20851;&#24615;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#65292;&#32780;&#21518;&#32493;&#23618;&#30340;&#32467;&#26500;&#36890;&#24120;&#26159;&#19981;&#21033;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#23545;&#20110;&#22810;&#23618;&#39640;&#26031;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#30740;&#31350;&#32771;&#34385;&#29305;&#24449;&#21508;&#21521;&#24322;&#24615;&#30340;&#24433;&#21709;&#65307;&#22823;&#22810;&#25968;&#27169;&#22411;&#37117;&#20551;&#35774;&#29305;&#24449;&#26159;&#20351;&#29992;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#26435;&#37325;&#29983;&#25104;&#30340;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#20855;&#26377;&#35768;&#22810;&#23618;&#32467;&#26500;&#39640;&#26031;&#29305;&#24449;&#30340;&#27169;&#22411;&#23548;&#20986;&#20102;&#23398;&#20064;&#26354;&#32447;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20801;&#35768;&#31532;&#19968;&#23618;&#29305;&#24449;&#30340;&#34892;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#21487;&#20419;&#36827;&#27867;&#21270;&#65292;&#32780;&#21518;&#32493;&#23618;&#30340;&#32467;&#26500;&#36890;&#24120;&#26159;&#19981;&#21033;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#26435;&#37325;&#32467;&#26500;&#22914;&#20309;&#24433;&#21709;&#21487;&#35299;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, significant attention in deep learning theory has been devoted to analyzing the generalization performance of models with multiple layers of Gaussian random features. However, few works have considered the effect of feature anisotropy; most assume that features are generated using independent and identically distributed Gaussian weights. Here, we derive learning curves for models with many layers of structured Gaussian features. We show that allowing correlations between the rows of the first layer of features can aid generalization, while structure in later layers is generally detrimental. Our results shed light on how weight structure affects generalization in a simple class of solvable models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31526;&#21512;&#24050;&#30693;&#30005;&#27969;&#29289;&#29702;&#29305;&#24615;&#30340;&#27169;&#22411;&#65292;&#22312;&#36890;&#36807;Helmholtz&#20998;&#35299;&#33719;&#24471;&#30340;&#21521;&#37327;&#22330;&#30340;&#21457;&#25955;&#21644;&#26080;&#26059;&#20998;&#37327;&#19978;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#39044;&#27979;&#28023;&#27969;&#12290;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#28014;&#26631;&#25968;&#25454;&#26041;&#38754;&#37117;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#26356;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2302.10364</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#36203;&#36203;&#23572;&#22982;&#38669;&#20857;&#20998;&#35299;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#31181;&#26356;&#27969;&#20307;&#30340;&#28023;&#27915;&#27668;&#27969;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes at the Helm(holtz): A more fluid model for ocean currents. (arXiv:2302.10364v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10364
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31526;&#21512;&#24050;&#30693;&#30005;&#27969;&#29289;&#29702;&#29305;&#24615;&#30340;&#27169;&#22411;&#65292;&#22312;&#36890;&#36807;Helmholtz&#20998;&#35299;&#33719;&#24471;&#30340;&#21521;&#37327;&#22330;&#30340;&#21457;&#25955;&#21644;&#26080;&#26059;&#20998;&#37327;&#19978;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#39044;&#27979;&#28023;&#27969;&#12290;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#28014;&#26631;&#25968;&#25454;&#26041;&#38754;&#37117;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28023;&#27915;&#23398;&#23478;&#26377;&#20852;&#36259;&#39044;&#27979;&#28023;&#27969;&#21644;&#22522;&#20110;&#28014;&#26631;&#36895;&#24230;&#30340;&#31232;&#30095;&#35266;&#27979;&#25968;&#25454;&#26469;&#35782;&#21035;&#24403;&#21069;&#30690;&#37327;&#22330;&#20013;&#30340;&#21457;&#25955;&#24615;&#12290;&#39640;&#26031;&#36807;&#31243;(GPs)&#22312;&#31354;&#38388;&#20301;&#32622;&#19978;&#20805;&#24403;&#36830;&#32493;&#20294;&#39640;&#24230;&#38750;&#32447;&#24615;&#21151;&#33021;&#30340;&#36895;&#24230;&#25552;&#20379;&#20102;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#27169;&#22411;&#12290;&#20294;&#25105;&#20204;&#34920;&#26126;&#65292;&#23558;&#20855;&#26377;&#26631;&#20934;&#24179;&#31283;&#26680;&#30340;GP&#30452;&#25509;&#24212;&#29992;&#20110;&#28014;&#26631;&#25968;&#25454;&#21487;&#33021;&#22312;&#24403;&#21069;&#39044;&#27979;&#21644;&#21457;&#25955;&#24615;&#35782;&#21035;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#8212;&#30001;&#20110;&#19968;&#20123;&#29289;&#29702;&#19978;&#19981;&#20999;&#23454;&#38469;&#30340;&#20808;&#39564;&#20551;&#35774;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#21453;&#26144;&#24050;&#30693;&#30340;&#30005;&#27969;&#29289;&#29702;&#29305;&#24615;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#26631;&#20934;&#24179;&#31283;&#26680;&#25918;&#22312;&#36890;&#36807;Helmholtz&#20998;&#35299;&#33719;&#24471;&#30340;&#21521;&#37327;&#22330;&#30340;&#21457;&#25955;&#21644;&#26080;&#26059;&#20998;&#37327;&#19978;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30001;&#20110;&#35813;&#20998;&#35299;&#20165;&#36890;&#36807;&#28151;&#21512;&#20559;&#23548;&#25968;&#19982;&#21407;&#22987;&#21521;&#37327;&#22330;&#30456;&#20851;&#65292;&#22240;&#27492;&#25105;&#20204;&#20173;&#28982;&#21487;&#20197;&#22312;&#21407;&#22987;&#25968;&#25454;&#32473;&#23450;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#25512;&#29702;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#39069;&#22806;&#36827;&#34892;&#23569;&#25968;&#35745;&#31639;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#28014;&#26631;&#25968;&#25454;&#35777;&#26126;&#20102;&#36825;&#31181;&#34746;&#26059;GP&#30340;&#26377;&#25928;&#24615;&#65292;&#20174;&#32780;&#22312;&#22343;&#26041;&#39044;&#27979;&#35823;&#24046;&#26041;&#38754;&#20248;&#20110;&#20808;&#21069;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oceanographers are interested in predicting ocean currents and identifying divergences in a current vector field based on sparse observations of buoy velocities. Since we expect current velocity to be a continuous but highly non-linear function of spatial location, Gaussian processes (GPs) offer an attractive model. But we show that applying a GP with a standard stationary kernel directly to buoy data can struggle at both current prediction and divergence identification -- due to some physically unrealistic prior assumptions. To better reflect known physical properties of currents, we propose to instead put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition. We show that, because this decomposition relates to the original vector field just via mixed partial derivatives, we can still perform inference given the original data with only a small constant multiple of additional computational expense. We illust
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20989;&#25968;&#22238;&#24402;&#23454;&#29616;&#39046;&#22495;&#27867;&#21270;&#65292;&#26500;&#24314;&#20102;&#32447;&#24615;&#31639;&#23376;&#23558;&#36755;&#20837;&#36793;&#32536;&#20998;&#24067;&#19982;&#36755;&#20986;&#26465;&#20214;&#20998;&#24067;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28304;&#20998;&#24067;&#20381;&#36182;&#24615;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#39044;&#27979;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.04724</link><description>&lt;p&gt;
&#20989;&#25968;&#22238;&#24402;&#30340;&#39046;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Domain Generalization by Functional Regression. (arXiv:2302.04724v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04724
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20989;&#25968;&#22238;&#24402;&#23454;&#29616;&#39046;&#22495;&#27867;&#21270;&#65292;&#26500;&#24314;&#20102;&#32447;&#24615;&#31639;&#23376;&#23558;&#36755;&#20837;&#36793;&#32536;&#20998;&#24067;&#19982;&#36755;&#20986;&#26465;&#20214;&#20998;&#24067;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28304;&#20998;&#24067;&#20381;&#36182;&#24615;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#39044;&#27979;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#27867;&#21270;&#38382;&#39064;&#26159;&#23398;&#20064;&#22914;&#20309;&#22312;&#32473;&#23450;&#22810;&#31181;&#19981;&#21516;&#28304;&#20998;&#24067;&#30340;&#25968;&#25454;&#26102;&#33719;&#24471;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#36866;&#29992;&#20110;&#21482;&#36890;&#36807;&#26410;&#26631;&#35760;&#26679;&#26412;&#35266;&#23519;&#21040;&#30340;&#26032;&#30446;&#26631;&#20998;&#24067;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#20197;&#20989;&#25968;&#22238;&#24402;&#30340;&#24418;&#24335;&#30740;&#31350;&#39046;&#22495;&#27867;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#26469;&#23398;&#20064;&#20174;&#36755;&#20837;&#30340;&#36793;&#32536;&#20998;&#24067;&#21040;&#32473;&#23450;&#36755;&#20837;&#30340;&#26465;&#20214;&#19979;&#36755;&#20986;&#30340;&#26465;&#20214;&#20998;&#24067;&#30340;&#32447;&#24615;&#31639;&#23376;&#12290;&#35813;&#31639;&#27861;&#20801;&#35768;&#22522;&#20110;&#28304;&#20998;&#24067;&#20381;&#36182;&#24615;&#26500;&#24314;&#39044;&#27979;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65292;&#24182;&#28385;&#36275;&#29702;&#24819;&#39118;&#38505;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;&#25968;&#20540;&#23454;&#29616;&#21644;&#28304;&#20195;&#30721;&#24050;&#32463;&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of domain generalization is to learn, given data from different source distributions, a model that can be expected to generalize well on new target distributions which are only seen through unlabeled samples. In this paper, we study domain generalization as a problem of functional regression. Our concept leads to a new algorithm for learning a linear operator from marginal distributions of inputs to the corresponding conditional distributions of outputs given inputs. Our algorithm allows a source distribution-dependent construction of reproducing kernel Hilbert spaces for prediction, and, satisfies finite sample error bounds for the idealized risk. Numerical implementations and source code are available.
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#31163;&#32447;&#28436;&#31034;&#25968;&#25454;&#22914;&#20309;&#25913;&#36827;&#22312;&#32447;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#31034;&#25968;&#25454;&#30340;TS&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20381;&#36182;&#20110;&#20808;&#39564;&#30693;&#35782;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65307;&#30740;&#31350;&#21457;&#29616;&#65292;&#39044;&#35757;&#32451;&#21487;&#20197;&#22823;&#24133;&#25552;&#39640;&#22312;&#32447;&#24615;&#33021;&#65292;&#25913;&#36827;&#31243;&#24230;&#38543;&#19987;&#23478;&#33021;&#21147;&#27700;&#24179;&#30340;&#25552;&#39640;&#32780;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2302.03319</link><description>&lt;p&gt;
&#21033;&#29992;&#28436;&#31034;&#25968;&#25454;&#25913;&#36827;&#22312;&#32447;&#23398;&#20064;:&#36136;&#37327;&#33267;&#20851;&#37325;&#35201;
&lt;/p&gt;
&lt;p&gt;
Leveraging Demonstrations to Improve Online Learning: Quality Matters. (arXiv:2302.03319v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03319
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#31163;&#32447;&#28436;&#31034;&#25968;&#25454;&#22914;&#20309;&#25913;&#36827;&#22312;&#32447;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#31034;&#25968;&#25454;&#30340;TS&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20381;&#36182;&#20110;&#20808;&#39564;&#30693;&#35782;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65307;&#30740;&#31350;&#21457;&#29616;&#65292;&#39044;&#35757;&#32451;&#21487;&#20197;&#22823;&#24133;&#25552;&#39640;&#22312;&#32447;&#24615;&#33021;&#65292;&#25913;&#36827;&#31243;&#24230;&#38543;&#19987;&#23478;&#33021;&#21147;&#27700;&#24179;&#30340;&#25552;&#39640;&#32780;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#31163;&#32447;&#28436;&#31034;&#25968;&#25454;&#21487;&#20197;&#22914;&#20309;&#25913;&#36827;&#22312;&#32447;&#23398;&#20064;&#65292;&#33258;&#28982;&#32780;&#28982;&#22320;&#26399;&#26395;&#20250;&#26377;&#19968;&#23450;&#30340;&#25913;&#36827;&#65292;&#20294;&#38382;&#39064;&#22312;&#20110;&#22914;&#20309;&#25913;&#36827;&#20197;&#21450;&#21487;&#20197;&#25913;&#36827;&#22810;&#23569;&#65311;&#25105;&#20204;&#34920;&#26126;&#65292;&#25913;&#36827;&#30340;&#31243;&#24230;&#24517;&#39035;&#21462;&#20915;&#20110;&#28436;&#31034;&#25968;&#25454;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#29983;&#25104;&#21487;&#31227;&#26893;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312;&#20102;&#20316;&#20026;&#20856;&#22411;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#21644;&#27169;&#22411;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#19978;&#24212;&#29992;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;TS&#65289;&#12290;&#28436;&#31034;&#25968;&#25454;&#26159;&#30001;&#20855;&#26377;&#32473;&#23450;&#33021;&#21147;&#27700;&#24179;&#30340;&#19987;&#23478;&#29983;&#25104;&#30340;&#65292;&#36825;&#26159;&#25105;&#20204;&#24341;&#20837;&#30340;&#19968;&#20010;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#24773;TS&#31639;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#23450;&#29702;&#20197;&#19968;&#33268;&#30340;&#26041;&#24335;&#21033;&#29992;&#28436;&#31034;&#25968;&#25454;&#24182;&#23548;&#20986;&#20381;&#36182;&#20110;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;&#36825;&#25552;&#20379;&#20102;&#27934;&#35265;&#65292;&#21363;&#39044;&#35757;&#32451;&#22914;&#20309;&#26497;&#22823;&#22320;&#25552;&#39640;&#22312;&#32447;&#24615;&#33021;&#65292;&#20197;&#21450;&#25913;&#36827;&#31243;&#24230;&#38543;&#19987;&#23478;&#33021;&#21147;&#27700;&#24179;&#30340;&#25552;&#39640;&#32780;&#22686;&#21152;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#36125;&#21494;&#26031;&#24341;&#23548;&#23454;&#29616;&#20102;&#23454;&#29992;&#30340;&#12289;&#36817;&#20284;&#30340;&#30693;&#24773;TS&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23454;&#29616;&#20102;&#23454;&#36136;&#24615;&#30340;&#36951;&#25022;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the extent to which offline demonstration data can improve online learning. It is natural to expect some improvement, but the question is how, and by how much? We show that the degree of improvement must depend on the quality of the demonstration data. To generate portable insights, we focus on Thompson sampling (TS) applied to a multi-armed bandit as a prototypical online learning algorithm and model. The demonstration data is generated by an expert with a given competence level, a notion we introduce. We propose an informed TS algorithm that utilizes the demonstration data in a coherent way through Bayes' rule and derive a prior-dependent Bayesian regret bound. This offers insight into how pretraining can greatly improve online performance and how the degree of improvement increases with the expert's competence level. We also develop a practical, approximate informed TS algorithm through Bayesian bootstrapping and show substantial empirical regret reduction through exp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#27010;&#29575;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#27491;&#30830;&#20272;&#35745;&#65292;&#36890;&#36807;&#25193;&#23637;InfoNCE&#30446;&#26631;&#21644;&#32534;&#30721;&#22120;&#20197;&#39044;&#27979;&#28508;&#21464;&#37327;&#20998;&#24067;&#26469;&#23454;&#29616;&#65292;&#22312;&#35745;&#31639;&#24050;&#30693;&#26597;&#35810;&#22270;&#20687;&#30340;&#21487;&#20449;&#21306;&#38388;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2302.02865</link><description>&lt;p&gt;
&#27010;&#29575;&#23545;&#27604;&#23398;&#20064;&#24674;&#22797;&#20102;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#27491;&#30830;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs. (arXiv:2302.02865v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#27010;&#29575;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#27491;&#30830;&#20272;&#35745;&#65292;&#36890;&#36807;&#25193;&#23637;InfoNCE&#30446;&#26631;&#21644;&#32534;&#30721;&#22120;&#20197;&#39044;&#27979;&#28508;&#21464;&#37327;&#20998;&#24067;&#26469;&#23454;&#29616;&#65292;&#22312;&#35745;&#31639;&#24050;&#30693;&#26597;&#35810;&#22270;&#20687;&#30340;&#21487;&#20449;&#21306;&#38388;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#27604;&#23398;&#20064;&#32534;&#30721;&#22120;&#34987;&#35777;&#26126;&#21487;&#20197;&#32763;&#36716;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65306;&#23427;&#20204;&#21487;&#20197;&#23558;&#27599;&#20010;&#36755;&#20837;&#65288;&#22914;&#22270;&#20687;&#65289;&#32534;&#30721;&#25104;&#29983;&#25104;&#35813;&#22270;&#20687;&#30340;&#30495;&#23454;&#28508;&#21464;&#37327;&#65288;Zimmermann&#31561;&#20154;&#65292;2021&#65289;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#35266;&#23519;&#32467;&#26524;&#36890;&#24120;&#23384;&#22312;&#20869;&#22312;&#30340;&#27169;&#31946;&#24615;&#12290;&#20363;&#22914;&#65292;&#22270;&#20687;&#21487;&#33021;&#27169;&#31946;&#25110;&#21482;&#26174;&#31034;3D&#29289;&#20307;&#30340;2D&#35270;&#22270;&#65292;&#22240;&#27492;&#21487;&#33021;&#26377;&#22810;&#20010;&#28508;&#21464;&#37327;&#29983;&#25104;&#23427;&#20204;&#12290;&#36825;&#20351;&#24471;&#28508;&#21464;&#37327;&#30340;&#30495;&#23454;&#21518;&#39564;&#27010;&#29575;&#20855;&#26377;&#24322;&#26041;&#24046;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#24120;&#35265;&#30340;InfoNCE&#30446;&#26631;&#21644;&#32534;&#30721;&#22120;&#65292;&#20197;&#39044;&#27979;&#28508;&#21464;&#37327;&#20998;&#24067;&#32780;&#19981;&#26159;&#28857;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20123;&#20998;&#24067;&#24674;&#22797;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#27491;&#30830;&#21518;&#39564;&#20998;&#24067;&#65292;&#21253;&#25324;&#20854;&#19981;&#30830;&#23450;&#24615;&#27700;&#24179;&#30340;&#20272;&#35745;&#65292;&#35813;&#20272;&#35745;&#23384;&#22312;&#28508;&#21464;&#37327;&#31354;&#38388;&#30340;&#26059;&#36716;&#12290;&#38500;&#20102;&#25552;&#20379;&#26657;&#20934;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20043;&#22806;&#65292;&#36825;&#20123;&#21518;&#39564;&#20998;&#24067;&#36824;&#20801;&#35768;&#22312;&#22270;&#20687;&#26816;&#32034;&#20013;&#35745;&#31639;&#21487;&#20449;&#21306;&#38388;&#12290;&#23427;&#20204;&#21253;&#25324;&#20855;&#26377;&#19982;&#32473;&#23450;&#26597;&#35810;&#30456;&#21516;&#30340;&#28508;&#21464;&#37327;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastively trained encoders have recently been proven to invert the data-generating process: they encode each input, e.g., an image, into the true latent vector that generated the image (Zimmermann et al., 2021). However, real-world observations often have inherent ambiguities. For instance, images may be blurred or only show a 2D view of a 3D object, so multiple latents could have generated them. This makes the true posterior for the latent vector probabilistic with heteroscedastic uncertainty. In this setup, we extend the common InfoNCE objective and encoders to predict latent distributions instead of points. We prove that these distributions recover the correct posteriors of the data-generating process, including its level of aleatoric uncertainty, up to a rotation of the latent space. In addition to providing calibrated uncertainty estimates, these posteriors allow the computation of credible intervals in image retrieval. They comprise images with the same latent as a given quer
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#30452;&#25509;&#19981;&#30830;&#23450;&#37327;&#21270;&#65288;DirectUQ&#65289;&#26041;&#27861;&#65292;&#23427;&#33021;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30452;&#25509;&#36755;&#20986;&#22343;&#20540;&#21644;&#26041;&#24046;&#65292;&#21516;&#26102;&#32467;&#21512;&#20102;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#28857;&#65292;&#26377;&#21161;&#20110;&#25913;&#36827;&#27169;&#22411;&#30340;&#27491;&#21017;&#21270;&#22120;&#21644;&#39118;&#38505;&#36793;&#30028;&#31561;&#26041;&#38754;&#12290;</title><link>http://arxiv.org/abs/2302.02420</link><description>&lt;p&gt;
&#30452;&#25509;&#19981;&#30830;&#23450;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Direct Uncertainty Quantification. (arXiv:2302.02420v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#30452;&#25509;&#19981;&#30830;&#23450;&#37327;&#21270;&#65288;DirectUQ&#65289;&#26041;&#27861;&#65292;&#23427;&#33021;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30452;&#25509;&#36755;&#20986;&#22343;&#20540;&#21644;&#26041;&#24046;&#65292;&#21516;&#26102;&#32467;&#21512;&#20102;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#28857;&#65292;&#26377;&#21161;&#20110;&#25913;&#36827;&#27169;&#22411;&#30340;&#27491;&#21017;&#21270;&#22120;&#21644;&#39118;&#38505;&#36793;&#30028;&#31561;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#26131;&#20110;&#35757;&#32451;&#65292;&#20294;&#20250;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#65307;&#32780;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#33391;&#22909;&#30340;&#19981;&#30830;&#23450;&#37327;&#21270;&#65292;&#20294;&#20248;&#21270;&#23427;&#20204;&#38656;&#35201;&#32791;&#36153;&#26102;&#38388;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#8212;&#8212;&#8220;&#30452;&#25509;&#19981;&#30830;&#23450;&#37327;&#21270;&#8221;&#65288;DirectUQ&#65289;&#65292;&#23427;&#32467;&#21512;&#20102;&#23427;&#20204;&#30340;&#20248;&#28857;&#65292;&#20854;&#20013;&#31070;&#32463;&#32593;&#32476;&#30452;&#25509;&#36755;&#20986;&#26368;&#21518;&#19968;&#23618;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#12290;DirectUQ&#21487;&#20197;&#23548;&#20986;&#20026;&#19968;&#20010;&#26367;&#20195;&#30340;&#21464;&#20998;&#19979;&#30028;&#65292;&#22240;&#27492;&#20174;&#33853;&#21333;&#21464;&#20998;&#25512;&#29702;&#20013;&#33719;&#30410;&#65292;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#27491;&#21017;&#21270;&#22120;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20687;&#38750;&#27010;&#29575;&#27169;&#22411;&#19968;&#26679;&#65292;DirectUQ&#20855;&#26377;&#31616;&#21333;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;Rademacher&#22797;&#26434;&#24615;&#20026;&#27169;&#22411;&#25552;&#20379;&#39118;&#38505;&#36793;&#30028;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;DirectUQ&#21644;DirectUQ&#38598;&#25104;&#25552;&#20379;&#20102;&#26102;&#38388;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#33391;&#22909;&#24179;&#34913;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20998;&#24067;&#20043;&#22806;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional neural networks are simple to train but they produce overconfident predictions, while Bayesian neural networks provide good uncertainty quantification but optimizing them is time consuming. This paper introduces a new approach, direct uncertainty quantification (DirectUQ), that combines their advantages where the neural network directly outputs the mean and variance of the last layer. DirectUQ can be derived as an alternative variational lower bound, and hence benefits from collapsed variational inference that provides improved regularizers. On the other hand, like non-probabilistic models, DirectUQ enjoys simple training and one can use Rademacher complexity to provide risk bounds for the model. Experiments show that DirectUQ and ensembles of DirectUQ provide a good tradeoff in terms of run time and uncertainty quantification, especially for out of distribution data.
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#33021;&#22815;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#23616;&#37096;&#21306;&#22495;&#65292;&#25913;&#21892;&#25972;&#20010;&#31995;&#32479;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2301.11375</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#21306;&#22495;
&lt;/p&gt;
&lt;p&gt;
Neural networks learn to magnify areas near decision boundaries. (arXiv:2301.11375v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11375
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#33021;&#22815;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#23616;&#37096;&#21306;&#22495;&#65292;&#25913;&#21892;&#25972;&#20010;&#31995;&#32479;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#35757;&#32451;&#22914;&#20309;&#22609;&#36896;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#22270;&#35825;&#23548;&#30340;&#40654;&#26364;&#20960;&#20309;&#12290;&#22312;&#23485;&#24230;&#20026;&#26080;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#38543;&#26426;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#36755;&#20837;&#31354;&#38388;&#19978;&#24341;&#23548;&#39640;&#24230;&#23545;&#31216;&#30340;&#24230;&#37327;&#12290;&#35757;&#32451;&#20998;&#31867;&#20219;&#21153;&#30340;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#23398;&#20064;&#25918;&#22823;&#20102;&#27839;&#20915;&#31574;&#36793;&#30028;&#30340;&#23616;&#37096;&#21306;&#22495;&#12290;&#36825;&#20123;&#21464;&#21270;&#19982;&#20808;&#21069;&#25552;&#20986;&#30340;&#29992;&#20110;&#25163;&#21160;&#35843;&#25972;&#26680;&#26041;&#27861;&#20197;&#25913;&#21892;&#27867;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how training molds the Riemannian geometry induced by neural network feature maps. At infinite width, neural networks with random parameters induce highly symmetric metrics on input space. Feature learning in networks trained to perform classification tasks magnifies local areas along decision boundaries. These changes are consistent with previously proposed geometric approaches for hand-tuning of kernel methods to improve generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;A-NeSI&#30340;&#26032;&#39062;PNL&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#20102;&#36817;&#20284;&#25512;&#29702;&#65292;&#33021;&#22815;&#20445;&#35777;&#27010;&#29575;&#36923;&#36753;&#35821;&#20041;&#30340;&#21516;&#26102;&#35299;&#20915;&#20102;PNL&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#20445;&#35777;&#36923;&#36753;&#32422;&#26463;&#30340;&#28385;&#36275;&#12290;</title><link>http://arxiv.org/abs/2212.12393</link><description>&lt;p&gt;
A-NeSI: &#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36817;&#20284;&#26041;&#27861;&#29992;&#20110;&#27010;&#29575;&#31070;&#32463;&#31526;&#21495;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference. (arXiv:2212.12393v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12393
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;A-NeSI&#30340;&#26032;&#39062;PNL&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#20102;&#36817;&#20284;&#25512;&#29702;&#65292;&#33021;&#22815;&#20445;&#35777;&#27010;&#29575;&#36923;&#36753;&#35821;&#20041;&#30340;&#21516;&#26102;&#35299;&#20915;&#20102;PNL&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#20445;&#35777;&#36923;&#36753;&#32422;&#26463;&#30340;&#28385;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#31070;&#32463;&#32593;&#32476;&#19982;&#31526;&#21495;&#25512;&#29702;&#30456;&#32467;&#21512;&#30340;&#38382;&#39064;&#12290;&#26368;&#36817;&#24341;&#20837;&#30340;&#27010;&#29575;&#31070;&#32463;&#31526;&#21495;&#23398;&#20064;&#65288;PNL&#65289;&#26694;&#26550;&#65292;&#22914;DeepProbLog&#65292;&#25191;&#34892;&#25351;&#25968;&#26102;&#38388;&#30340;&#31934;&#30830;&#25512;&#29702;&#65292;&#38480;&#21046;&#20102;PNL&#35299;&#20915;&#26041;&#26696;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#36817;&#20284;&#31070;&#32463;&#31526;&#21495;&#25512;&#29702;&#65288;A-NeSI&#65289;&#65306;&#19968;&#31181;&#26032;&#30340;PNL&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#21487;&#25193;&#23637;&#30340;&#36817;&#20284;&#25512;&#29702;&#12290;A-NeSI 1) &#22312;&#19981;&#25913;&#21464;&#27010;&#29575;&#36923;&#36753;&#35821;&#20041;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#22810;&#39033;&#24335;&#26102;&#38388;&#25191;&#34892;&#36817;&#20284;&#25512;&#29702;&#65307;2) &#20351;&#29992;&#30001;&#32972;&#26223;&#30693;&#35782;&#29983;&#25104;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65307;3) &#21487;&#20197;&#29983;&#25104;&#26377;&#20851;&#39044;&#27979;&#30340;&#31526;&#21495;&#35299;&#37322;&#65307;4) &#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#38388;&#20445;&#35777;&#36923;&#36753;&#32422;&#26463;&#30340;&#28385;&#36275;&#65292;&#36825;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;A-NeSI&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#35299;&#20915;&#20855;&#26377;&#25351;&#25968;&#32452;&#21512;&#25193;&#23637;&#30340;&#19977;&#31181;&#31070;&#32463;&#31526;&#21495;&#20219;&#21153;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;A-NeSI&#23454;&#29616;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#23433;&#20840;&#24615;&#65292;&#32780;&#27809;&#26377;&#24809;&#32602;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of combining neural networks with symbolic reasoning. Recently introduced frameworks for Probabilistic Neurosymbolic Learning (PNL), such as DeepProbLog, perform exponential-time exact inference, limiting the scalability of PNL solutions. We introduce Approximate Neurosymbolic Inference (A-NeSI): a new framework for PNL that uses neural networks for scalable approximate inference. A-NeSI 1) performs approximate inference in polynomial time without changing the semantics of probabilistic logics; 2) is trained using data generated by the background knowledge; 3) can generate symbolic explanations of predictions; and 4) can guarantee the satisfaction of logical constraints at test time, which is vital in safety-critical applications. Our experiments show that A-NeSI is the first end-to-end method to solve three neurosymbolic tasks with exponential combinatorial scaling. Finally, our experiments show that A-NeSI achieves explainability and safety without a penalty in p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38597;&#21487;&#27604;&#25511;&#21046;&#30340;&#24102;&#23485;&#36873;&#25321;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#38381;&#24335;&#12289;&#35745;&#31639;&#38750;&#24120;&#36731;&#30340;&#29305;&#28857;&#65292;&#24182;&#19988;&#22312;&#20851;&#27880;&#24102;&#23485;&#30340;&#21516;&#26102;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#27169;&#22411;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.11956</link><description>&lt;p&gt;
&#36890;&#36807;&#38597;&#21487;&#27604;&#25511;&#21046;&#36873;&#25321;&#39640;&#26031;&#26680;&#23725;&#22238;&#24402;&#24102;&#23485;
&lt;/p&gt;
&lt;p&gt;
Bandwidth Selection for Gaussian Kernel Ridge Regression via Jacobian Control. (arXiv:2205.11956v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11956
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38597;&#21487;&#27604;&#25511;&#21046;&#30340;&#24102;&#23485;&#36873;&#25321;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#38381;&#24335;&#12289;&#35745;&#31639;&#38750;&#24120;&#36731;&#30340;&#29305;&#28857;&#65292;&#24182;&#19988;&#22312;&#20851;&#27880;&#24102;&#23485;&#30340;&#21516;&#26102;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#27169;&#22411;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#38656;&#35201;&#35843;&#25972;&#36229;&#21442;&#25968;&#12290;&#23545;&#20110;&#39640;&#26031;&#26680;&#23725;&#22238;&#24402;&#65292;&#36229;&#21442;&#25968;&#26159;&#24102;&#23485;&#12290;&#24102;&#23485;&#25351;&#23450;&#26680;&#20989;&#25968;&#30340;&#38271;&#24230;&#23610;&#24230;&#65292;&#24517;&#39035;&#23567;&#24515;&#36873;&#25321;&#25165;&#33021;&#33719;&#24471;&#20855;&#26377;&#33391;&#22909;&#27867;&#21270;&#24615;&#33021;&#27169;&#22411;&#12290;&#24102;&#23485;&#36873;&#25321;&#30340;&#40664;&#35748;&#26041;&#27861;&#26159;&#20132;&#21449;&#39564;&#35777;&#21644;&#36793;&#32536;&#20284;&#28982;&#26368;&#22823;&#21270;&#65292;&#36825;&#36890;&#24120;&#20250;&#20135;&#29983;&#33391;&#22909;&#30340;&#32467;&#26524;&#65292;&#23613;&#31649;&#35745;&#31639;&#25104;&#26412;&#39640;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#25552;&#20379;&#30340;&#20272;&#35745;&#24448;&#24448;&#20855;&#26377;&#38750;&#24120;&#39640;&#30340;&#26041;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#35757;&#32451;&#25968;&#25454;&#19981;&#36275;&#26102;&#12290;&#21463;&#38597;&#21487;&#27604;&#27491;&#21017;&#21270;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#36817;&#20284;&#34920;&#36798;&#24335;&#65292;&#29992;&#20110;&#25551;&#36848;&#39640;&#26031;&#26680;&#23725;&#22238;&#24402;&#25512;&#26029;&#20989;&#25968;&#30340;&#23548;&#25968;&#22914;&#20309;&#21462;&#20915;&#20110;&#26680;&#24102;&#23485;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#34920;&#36798;&#24335;&#26469;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38597;&#21487;&#27604;&#25511;&#21046;&#30340;&#38381;&#24335;&#12289;&#35745;&#31639;&#38750;&#24120;&#36731;&#30340;&#24102;&#23485;&#36873;&#25321;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#38597;&#21487;&#27604;&#34920;&#36798;&#24335;&#34920;&#26126;&#20102;&#22312;&#26816;&#26597;&#24102;&#23485;&#36873;&#25321;&#30340;&#36136;&#37327;&#26102;&#24212;&#20851;&#27880;&#20160;&#20040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most machine learning methods require tuning of hyper-parameters. For kernel ridge regression with the Gaussian kernel, the hyper-parameter is the bandwidth. The bandwidth specifies the length-scale of the kernel and has to be carefully selected in order to obtain a model with good generalization. The default methods for bandwidth selection is cross-validation and marginal likelihood maximization, which often yields good results, albeit at high computational costs. Furthermore, the estimates provided by these methods tend to have very high variance, especially when training data are scarce. Inspired by Jacobian regularization, we formulate an approximate expression for how the derivatives of the functions inferred by kernel ridge regression with the Gaussian kernel depend on the kernel bandwidth. We then use this expression to propose a closed-form, computationally feather-light, bandwidth selection heuristic based on controlling the Jacobian. In addition, the Jacobian expression illum
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#23553;&#35013;&#20026;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#24182;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20351;&#29992;&#23376;&#37319;&#26679;&#23398;&#20064;&#30340;&#32593;&#32476;&#23884;&#20837;&#30340;&#28176;&#36817;&#20998;&#24067;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#28508;&#22312;&#21442;&#25968;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#31639;&#27861;&#36873;&#25321;&#19982;&#32479;&#35745;&#25928;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2107.02363</link><description>&lt;p&gt;
&#23376;&#37319;&#26679;&#23398;&#20064;&#30340;&#32593;&#32476;&#23884;&#20837;&#30340;&#28176;&#36817;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Asymptotics of Network Embeddings Learned via Subsampling. (arXiv:2107.02363v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.02363
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#23553;&#35013;&#20026;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#24182;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20351;&#29992;&#23376;&#37319;&#26679;&#23398;&#20064;&#30340;&#32593;&#32476;&#23884;&#20837;&#30340;&#28176;&#36817;&#20998;&#24067;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#28508;&#22312;&#21442;&#25968;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#31639;&#27861;&#36873;&#25321;&#19982;&#32479;&#35745;&#25928;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#25968;&#25454;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#26080;&#22788;&#19981;&#22312;&#65292;&#30456;&#20851;&#20219;&#21153;&#21253;&#25324;&#33410;&#28857;&#20998;&#31867;&#12289;&#33410;&#28857;&#32858;&#31867;&#21644;&#38142;&#25509;&#39044;&#27979;&#12290;&#19968;&#31181;&#24120;&#29992;&#30340;&#26041;&#27861;&#26159;&#39318;&#20808;&#23398;&#20064;&#32593;&#32476;&#30340;&#27431;&#20960;&#37324;&#24471;&#23884;&#20837;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#21521;&#37327;&#20540;&#25968;&#25454;&#24320;&#21457;&#30340;&#31639;&#27861;&#12290;&#23545;&#20110;&#22823;&#22411;&#32593;&#32476;&#65292;&#21487;&#20197;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#23398;&#20064;&#23884;&#20837;&#65292;&#20854;&#20013;&#23376;&#37319;&#26679;&#26041;&#26696;&#21487;&#20197;&#33258;&#30001;&#36873;&#25321;&#12290;&#23613;&#31649;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#29702;&#35299;&#36824;&#19981;&#22815;&#20805;&#20998;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#35832;&#22914;node2vec&#20043;&#31867;&#30340;&#34920;&#31034;&#26041;&#27861;&#23553;&#35013;&#21040;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#20013;&#12290;&#22312;&#20551;&#35774;&#22270;&#26159;&#21487;&#20132;&#25442;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#21521;&#37327;&#30340;&#20998;&#24067;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#20998;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#26681;&#25454;&#28508;&#22312;&#21442;&#25968;&#65292;&#21253;&#25324;&#25439;&#22833;&#20989;&#25968;&#21644;&#23884;&#20837;&#32500;&#25968;&#30340;&#36873;&#25321;&#65292;&#34920;&#24449;&#20102;&#28176;&#36817;&#20998;&#24067;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#12290;&#36825;&#20026;&#20351;&#29992;&#23376;&#37319;&#26679;&#23398;&#20064;&#30340;&#32593;&#32476;&#23884;&#20837;&#25552;&#20379;&#20102;&#22522;&#26412;&#35265;&#35299;&#65292;&#24182;&#38416;&#26126;&#20102;&#31639;&#27861;&#36873;&#25321;&#21644;&#32479;&#35745;&#25928;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network data are ubiquitous in modern machine learning, with tasks of interest including node classification, node clustering and link prediction. A frequent approach begins by learning an Euclidean embedding of the network, to which algorithms developed for vector-valued data are applied. For large networks, embeddings are learned using stochastic gradient methods where the sub-sampling scheme can be freely chosen. Despite the strong empirical performance of such methods, they are not well understood theoretically. Our work encapsulates representation methods using a subsampling approach, such as node2vec, into a single unifying framework. We prove, under the assumption that the graph is exchangeable, that the distribution of the learned embedding vectors asymptotically decouples. Moreover, we characterize the asymptotic distribution and provided rates of convergence, in terms of the latent parameters, which includes the choice of loss function and the embedding dimension. This provid
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#35757;&#32451;&#38598;&#19981;&#20855;&#20195;&#34920;&#24615;&#30340;&#21327;&#21464;&#37327;&#28418;&#31227;&#24773;&#20917;&#19979;&#25913;&#36827;&#30417;&#30563;&#24335;&#23398;&#20064;&#30340;&#20998;&#23618;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#22312;&#23431;&#23449;&#23398;&#39046;&#22495;&#30340;&#20004;&#20010;&#38382;&#39064;&#20013;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#22823;&#24133;&#25552;&#21319;&#20102;&#30446;&#26631;&#39044;&#27979;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2106.11211</link><description>&lt;p&gt;
&#20998;&#23618;&#23398;&#20064;&#65306;&#19968;&#31181;&#29992;&#20110;&#25913;&#21892;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#23398;&#20064;&#30340;&#19968;&#33324;&#24615;&#32479;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stratified Learning: A General-Purpose Statistical Method for Improved Learning under Covariate Shift. (arXiv:2106.11211v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.11211
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#35757;&#32451;&#38598;&#19981;&#20855;&#20195;&#34920;&#24615;&#30340;&#21327;&#21464;&#37327;&#28418;&#31227;&#24773;&#20917;&#19979;&#25913;&#36827;&#30417;&#30563;&#24335;&#23398;&#20064;&#30340;&#20998;&#23618;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#22312;&#23431;&#23449;&#23398;&#39046;&#22495;&#30340;&#20004;&#20010;&#38382;&#39064;&#20013;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#22823;&#24133;&#25552;&#21319;&#20102;&#30446;&#26631;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#20855;&#26377;&#32479;&#35745;&#23398;&#21407;&#29702;&#21644;&#29702;&#35770;&#22522;&#30784;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#35757;&#32451;&#38598;&#19981;&#20855;&#20195;&#34920;&#24615;&#30340;&#24773;&#20917;&#19979;&#25913;&#36827;&#30417;&#30563;&#23398;&#20064;&#65292;&#36825;&#31181;&#24773;&#20917;&#34987;&#31216;&#20026;&#21327;&#21464;&#37327;&#28418;&#31227;&#12290;&#25105;&#20204;&#24314;&#31435;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#19968;&#31181;&#25104;&#29087;&#30340;&#26041;&#27861;&#22522;&#30784;&#20043;&#19978;&#65292;&#34920;&#26126;&#21327;&#21464;&#37327;&#28418;&#31227;&#30340;&#24433;&#21709;&#21487;&#20197;&#36890;&#36807;&#22312;&#22240;&#27425;&#20998;&#25968;&#19978;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#26469;&#20943;&#23569;&#25110;&#28040;&#38500;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36890;&#36807;&#22312;&#20272;&#35745;&#30340;&#22240;&#27425;&#20998;&#25968;&#30340;&#22522;&#30784;&#19978;&#23545;&#25968;&#25454;&#36827;&#34892;&#20998;&#23618;&#26500;&#36896;&#65292;&#20174;&#32780;&#23454;&#29616;&#24179;&#34913;&#21327;&#21464;&#37327;&#65292;&#26174;&#33879;&#25552;&#39640;&#30446;&#26631;&#39044;&#27979;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#29616;&#20195;&#23431;&#23449;&#23398;&#30740;&#31350;&#38382;&#39064;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#36825;&#31181;&#19968;&#33324;&#24615;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#36229;&#36234;&#20102;&#26368;&#20808;&#36827;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#26356;&#26032;&#30340;&#8220;&#36229;&#26032;&#26143;&#20809;&#24230;&#20998;&#31867;&#25361;&#25112;&#8221;&#20013;&#33719;&#24471;&#20102;&#26368;&#22909;&#30340;AUC&#20540;&#65288;0.958&#65289;&#65292;&#24182;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;SDSS&#25968;&#25454;&#20013;&#30340;&#26143;&#31995;&#32418;&#31227;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a simple, statistically principled, and theoretically justified method to improve supervised learning when the training set is not representative, a situation known as covariate shift. We build upon a well-established methodology in causal inference, and show that the effects of covariate shift can be reduced or eliminated by conditioning on propensity scores. In practice, this is achieved by fitting learners within strata constructed by partitioning the data based on the estimated propensity scores, leading to approximately balanced covariates and much-improved target prediction. We demonstrate the effectiveness of our general-purpose method on two contemporary research questions in cosmology, outperforming state-of-the-art importance weighting methods. We obtain the best reported AUC (0.958) on the updated "Supernovae photometric classification challenge", and we improve upon existing conditional density estimation of galaxy redshift from Sloan Data Sky Survey (SDSS) data.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32858;&#31867;&#39564;&#35777;&#26631;&#20934;&#65292;&#22522;&#20110;&#32858;&#31867;&#31283;&#23450;&#24615;&#30340;&#20869;&#37096;&#39564;&#35777;&#21407;&#21017;&#65292;&#22312;&#32858;&#31867;&#31283;&#23450;&#24615;&#21644;&#32858;&#31867;&#36136;&#37327;&#26041;&#38754;&#32988;&#36807;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2006.08530</link><description>&lt;p&gt;
&#24102;&#26377;&#31283;&#23450;&#24615;&#25240;&#34935;&#30340;&#36873;&#25321;&#32858;&#31867;&#25968;&#30446; $K$&#65306;&#19968;&#31181;&#20869;&#37096;&#39564;&#35777;&#26631;&#20934;
&lt;/p&gt;
&lt;p&gt;
Selecting the Number of Clusters $K$ with a Stability Trade-off: an Internal Validation Criterion. (arXiv:2006.08530v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.08530
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32858;&#31867;&#39564;&#35777;&#26631;&#20934;&#65292;&#22522;&#20110;&#32858;&#31867;&#31283;&#23450;&#24615;&#30340;&#20869;&#37096;&#39564;&#35777;&#21407;&#21017;&#65292;&#22312;&#32858;&#31867;&#31283;&#23450;&#24615;&#21644;&#32858;&#31867;&#36136;&#37327;&#26041;&#38754;&#32988;&#36807;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#36873;&#25321;&#26159;&#38750;&#21442;&#25968;&#32858;&#31867;&#20013;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#12290;&#27627;&#26080;&#30097;&#38382;&#65292;&#27809;&#26377;&#21487;&#20197;&#20316;&#20026;&#26631;&#20934;&#31572;&#26696;&#30340;&#30495;&#23454;&#25968;&#25454;&#23384;&#22312;&#65292;&#22240;&#27492;&#35780;&#20215;&#32858;&#31867;&#32467;&#26524;&#30340;&#36890;&#29992;&#26041;&#27861;&#23578;&#26410;&#20986;&#29616;&#12290;&#32858;&#31867;&#30446;&#26631;&#30340;&#19981;&#30830;&#23450;&#24615;&#23548;&#33268;&#20102;&#26222;&#36941;&#25509;&#21463;&#30340;&#35780;&#20215;&#26631;&#20934;&#38590;&#20197;&#30830;&#23450;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#32858;&#31867;&#31283;&#23450;&#24615;&#20316;&#20026;&#19968;&#31181;&#33258;&#28982;&#19988;&#26080;&#38656;&#27169;&#22411;&#30340;&#21407;&#21017;&#32780;&#20986;&#29616;&#65306;&#32858;&#31867;&#31639;&#27861;&#24212;&#21457;&#29616;&#25968;&#25454;&#20013;&#31283;&#23450;&#30340;&#32467;&#26500;&#12290;&#22914;&#26524;&#25968;&#25454;&#38598;&#20174;&#30456;&#21516;&#30340;&#22522;&#30784;&#20998;&#24067;&#20013;&#37325;&#22797;&#37319;&#26679;&#65292;&#21017;&#31639;&#27861;&#24212;&#25214;&#21040;&#30456;&#20284;&#30340;&#20998;&#21306;&#12290;&#28982;&#32780;&#65292;&#21333;&#32431;&#30340;&#31283;&#23450;&#24615;&#24182;&#19981;&#36866;&#21512;&#30830;&#23450;&#32858;&#31867;&#25968;&#30446;&#12290;&#20363;&#22914;&#65292;&#23427;&#26080;&#27861;&#26816;&#27979;&#32858;&#31867;&#25968;&#30446;&#26159;&#21542;&#22826;&#23567;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#21407;&#21017;&#65306;&#19968;&#31181;&#22909;&#30340;&#32858;&#31867;&#24212;&#35813;&#26159;&#31283;&#23450;&#30340;&#65292;&#19988;&#22312;&#27599;&#20010;&#32858;&#31867;&#20869;&#37096;&#65292;&#19981;&#23384;&#22312;&#31283;&#23450;&#30340;&#23376;&#20998;&#21306;&#12290;&#36825;&#20010;&#21407;&#21017;&#24102;&#26469;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#31283;&#23450;&#24615;&#30340;&#26032;&#22411;&#32858;&#31867;&#39564;&#35777;&#26631;&#20934;&#65292;&#20811;&#26381;&#20102;&#20256;&#32479;&#22522;&#20110;&#31283;&#23450;&#24615;&#26631;&#20934;&#30340;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26631;&#20934;&#33021;&#22815;&#20197;&#39640;&#31934;&#24230;&#24674;&#22797;&#30495;&#23454;&#30340;&#32858;&#31867;&#25968;&#30446;&#65292;&#24182;&#19988;&#22312;&#32858;&#31867;&#31283;&#23450;&#24615;&#21644;&#32858;&#31867;&#36136;&#37327;&#26041;&#38754;&#32988;&#36807;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model selection is a major challenge in non-parametric clustering. There is no universally admitted way to evaluate clustering results for the obvious reason that no ground truth is available. The difficulty to find a universal evaluation criterion is a consequence of the ill-defined objective of clustering. In this perspective, clustering stability has emerged as a natural and model-agnostic principle: an algorithm should find stable structures in the data. If data sets are repeatedly sampled from the same underlying distribution, an algorithm should find similar partitions. However, stability alone is not well-suited to determine the number of clusters. For instance, it is unable to detect if the number of clusters is too small. We propose a new principle: a good clustering should be stable, and within each cluster, there should exist no stable partition. This principle leads to a novel clustering validation criterion based on between-cluster and within-cluster stability, overcoming 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#27491;&#20132;&#32534;&#30721;&#30697;&#38453;&#36827;&#34892;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#30340;&#23454;&#29616;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20195;&#30721;&#20013;&#19981;&#21253;&#21547;&#38646;&#20803;&#32032;&#30340;&#27491;&#20132;&#32534;&#30721;&#30697;&#38453;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#26041;&#27861;&#35299;&#20915;&#27010;&#29575;&#38382;&#39064;&#65292;&#21516;&#26102;&#27604;&#38543;&#26426;&#32534;&#30721;&#26356;&#20934;&#30830;&#12290;&#28982;&#32780;&#19982;1&#23545;1&#30456;&#27604;&#65292;&#27491;&#20132;&#32534;&#30721;&#30340;&#20934;&#30830;&#24615;&#20173;&#26377;&#24453;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/1801.09055</link><description>&lt;p&gt;
&#20351;&#29992;&#27491;&#20132;&#32534;&#30721;&#30697;&#38453;&#35299;&#20915;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving for multi-class using orthogonal coding matrices. (arXiv:1801.09055v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1801.09055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#27491;&#20132;&#32534;&#30721;&#30697;&#38453;&#36827;&#34892;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#30340;&#23454;&#29616;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20195;&#30721;&#20013;&#19981;&#21253;&#21547;&#38646;&#20803;&#32032;&#30340;&#27491;&#20132;&#32534;&#30721;&#30697;&#38453;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#26041;&#27861;&#35299;&#20915;&#27010;&#29575;&#38382;&#39064;&#65292;&#21516;&#26102;&#27604;&#38543;&#26426;&#32534;&#30721;&#26356;&#20934;&#30830;&#12290;&#28982;&#32780;&#19982;1&#23545;1&#30456;&#27604;&#65292;&#27491;&#20132;&#32534;&#30721;&#30340;&#20934;&#30830;&#24615;&#20173;&#26377;&#24453;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#20108;&#20803;&#20998;&#31867;&#25512;&#24191;&#21040;&#22810;&#31867;&#20998;&#31867;&#30340;&#24120;&#29992;&#26041;&#27861;&#26159;&#35823;&#24046;&#32416;&#27491;&#30721;&#65288;ECC&#65289;&#12290;ECC&#21487;&#20197;&#36890;&#36807;&#22810;&#31181;&#26041;&#24335;&#36827;&#34892;&#20248;&#21270;&#65292;&#20363;&#22914;&#36890;&#36807;&#20351;&#23427;&#20204;&#27491;&#20132;&#21270;&#12290;&#26412;&#25991;&#22312;&#19971;&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#19977;&#31181;&#20108;&#20803;&#20998;&#31867;&#22120;&#27979;&#35797;&#20102;&#20004;&#31181;&#27491;&#20132;ECC&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#20854;&#20182;&#19977;&#31181;&#22810;&#31867;&#21035;&#26041;&#27861;&#65306;1&#23545;1&#12289;&#19968;&#23545;&#20854;&#20313;&#21644;&#38543;&#26426;ECC&#36827;&#34892;&#27604;&#36739;&#12290;&#20195;&#30721;&#20013;&#19981;&#21253;&#21547;&#38646;&#20803;&#32032;&#30340;&#31532;&#19968;&#31181;&#27491;&#20132;ECC&#20801;&#35768;&#20351;&#29992;&#24555;&#36895;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#27010;&#29575;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#25991;&#29486;&#39044;&#27979;&#65292;&#19982;&#38543;&#26426;ECC&#30456;&#27604;&#65292;&#27491;&#20132;ECC&#22987;&#32456;&#26356;&#20934;&#30830;&#12290;&#19981;&#30830;&#23450;&#24615;&#31995;&#25968;&#65288;U.C.&#65289;&#30340;&#25552;&#39640;&#33539;&#22260;&#22312;0.4-17.5&#65285;&#65288;&#32477;&#23545;&#20540;&#20026;0.004-0.139&#65289;&#65292;&#32780;Brier&#20998;&#25968;&#30340;&#25552;&#39640;&#33539;&#22260;&#22312;0.7-10.7&#65285;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#27491;&#20132;ECC&#24456;&#23569;&#27604;1&#23545;1&#26356;&#20934;&#30830;&#12290;&#24403;&#23558;&#26041;&#27861;&#19982;&#36923;&#36753;&#22238;&#24402;&#37197;&#23545;&#26102;&#65292;&#24046;&#24322;&#26368;&#22823;&#65292;&#27491;&#20132;ECC&#20174;&#26410;&#20987;&#36133;&#36807;1&#23545;1&#12290;
&lt;/p&gt;
&lt;p&gt;
A common method of generalizing binary to multi-class classification is the error correcting code (ECC). ECCs may be optimized in a number of ways, for instance by making them orthogonal. Here we test two types of orthogonal ECCs on seven different datasets using three types of binary classifier and compare them with three other multi-class methods: 1 vs. 1, one-versus-the-rest and random ECCs. The first type of orthogonal ECC, in which the codes contain no zeros, admits a fast and simple method of solving for the probabilities. Orthogonal ECCs are always more accurate than random ECCs as predicted by recent literature. Improvments in uncertainty coefficient (U.C.) range between 0.4--17.5% (0.004--0.139, absolute), while improvements in Brier score between 0.7--10.7%. Unfortunately, orthogonal ECCs are rarely more accurate than 1 vs. 1. Disparities are worst when the methods are paired with logistic regression, with orthogonal ECCs never beating 1 vs. 1. When the methods are paired wit
&lt;/p&gt;</description></item></channel></rss>