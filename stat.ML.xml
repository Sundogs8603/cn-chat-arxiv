<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#36816;&#31639;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;MOOSE&#26694;&#26550;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#24555;&#36895;&#20934;&#30830;&#30340;&#20943;&#38454;&#27169;&#22411;&#65292;&#29992;&#20110;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#25511;&#21046;&#21644;&#20248;&#21270;&#36807;&#31243;&#65292;&#36890;&#36807;&#25913;&#21464;&#36807;&#31243;&#21464;&#37327;&#26469;&#23398;&#20064;&#24494;&#20998;&#26041;&#31243;&#65292;&#20351;&#29992;Fourier&#31070;&#32463;&#36816;&#31639;&#22120;&#21644;&#28145;&#24230;&#36816;&#31639;&#22120;&#32593;&#32476;&#24320;&#21457;&#20102;&#26102;&#38388;&#30456;&#20851;&#21709;&#24212;&#30340;&#20943;&#38454;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.02462</link><description>&lt;p&gt;
&#22522;&#20110;MOOSE&#26694;&#26550;&#30340;&#24555;&#36895;&#20934;&#30830;&#30340;&#20943;&#38454;&#24314;&#27169;&#22312;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#36816;&#31639;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Fast and Accurate Reduced-Order Modeling of a MOOSE-based Additive Manufacturing Model with Operator Learning. (arXiv:2308.02462v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#36816;&#31639;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;MOOSE&#26694;&#26550;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#24555;&#36895;&#20934;&#30830;&#30340;&#20943;&#38454;&#27169;&#22411;&#65292;&#29992;&#20110;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#25511;&#21046;&#21644;&#20248;&#21270;&#36807;&#31243;&#65292;&#36890;&#36807;&#25913;&#21464;&#36807;&#31243;&#21464;&#37327;&#26469;&#23398;&#20064;&#24494;&#20998;&#26041;&#31243;&#65292;&#20351;&#29992;Fourier&#31070;&#32463;&#36816;&#31639;&#22120;&#21644;&#28145;&#24230;&#36816;&#31639;&#22120;&#32593;&#32476;&#24320;&#21457;&#20102;&#26102;&#38388;&#30456;&#20851;&#21709;&#24212;&#30340;&#20943;&#38454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#22312;&#36816;&#34892;&#26102;&#36890;&#36807;&#35843;&#25972;&#21046;&#36896;&#36807;&#31243;&#21442;&#25968;&#26469;&#36798;&#21040;&#29305;&#23450;&#30340;&#26448;&#26009;&#23646;&#24615;&#12290;&#36825;&#31181;&#35843;&#25972;&#24448;&#24448;&#22686;&#21152;&#20102;&#29992;&#20110;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#29616;&#26377;&#27169;&#25311;&#24037;&#20855;&#30340;&#35745;&#31639;&#36127;&#33655;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#20026;&#22312;&#22810;&#29289;&#29702;&#38754;&#21521;&#23545;&#35937;&#27169;&#25311;&#29615;&#22659;&#65288;MOOSE&#65289;&#26694;&#26550;&#20013;&#24320;&#21457;&#30340;&#22686;&#26448;&#21046;&#36896;&#27169;&#22411;&#26500;&#24314;&#19968;&#20010;&#24555;&#36895;&#20934;&#30830;&#30340;&#20943;&#38454;&#27169;&#22411;&#65288;ROM&#65289;&#65292;&#20174;&#32780;&#26368;&#32456;&#20943;&#23569;&#22686;&#26448;&#21046;&#36896;&#25511;&#21046;&#21644;&#20248;&#21270;&#36807;&#31243;&#30340;&#26102;&#38388;/&#25104;&#26412;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#36816;&#31639;&#23398;&#20064;&#65288;OL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#21464;&#28608;&#20809;&#30340;&#39640;&#26031;&#28857;&#28909;&#28304;&#20013;&#30340;&#36807;&#31243;&#21464;&#37327;&#65292;&#23398;&#20064;&#20102;&#19968;&#31995;&#21015;&#24494;&#20998;&#26041;&#31243;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;Fourier&#31070;&#32463;&#36816;&#31639;&#22120;&#65288;FNO&#65289;&#21644;&#28145;&#24230;&#36816;&#31639;&#22120;&#32593;&#32476;&#65288;DeepONet&#65289;&#26469;&#24320;&#21457;&#26102;&#38388;&#30456;&#20851;&#21709;&#24212;&#30340;&#20943;&#38454;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;OL&#26041;&#27861;&#30340;&#24615;&#33021;&#19982;&#20256;&#32479;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
One predominant challenge in additive manufacturing (AM) is to achieve specific material properties by manipulating manufacturing process parameters during the runtime. Such manipulation tends to increase the computational load imposed on existing simulation tools employed in AM. The goal of the present work is to construct a fast and accurate reduced-order model (ROM) for an AM model developed within the Multiphysics Object-Oriented Simulation Environment (MOOSE) framework, ultimately reducing the time/cost of AM control and optimization processes. Our adoption of the operator learning (OL) approach enabled us to learn a family of differential equations produced by altering process variables in the laser's Gaussian point heat source. More specifically, we used the Fourier neural operator (FNO) and deep operator network (DeepONet) to develop ROMs for time-dependent responses. Furthermore, we benchmarked the performance of these OL methods against a conventional deep neural network (DNN
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#27169;&#22411;L&#233;vyGAN&#65292;&#29992;&#20110;&#29983;&#25104;&#26465;&#20214;&#20110;&#24067;&#26391;&#22686;&#37327;&#30340;L&#233;vy&#21306;&#22495;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#36890;&#36807;&#8220;&#26725;&#32763;&#36716;&#8221;&#25805;&#20316;&#65292;&#36755;&#20986;&#30340;&#26679;&#26412;&#21487;&#20197;&#31934;&#30830;&#21305;&#37197;&#25152;&#26377;&#22855;&#25968;&#38454;&#30697;&#65292;&#35299;&#20915;&#20102;&#38750;&#39640;&#26031;&#24615;&#36136;&#19979;&#30340;&#25277;&#26679;&#22256;&#38590;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02452</link><description>&lt;p&gt;
&#23545;&#39640;&#38454;SDE&#27169;&#25311;&#30340;L&#233;vy&#21306;&#22495;&#36827;&#34892;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modelling of L\'{e}vy Area for High Order SDE Simulation. (arXiv:2308.02452v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#27169;&#22411;L&#233;vyGAN&#65292;&#29992;&#20110;&#29983;&#25104;&#26465;&#20214;&#20110;&#24067;&#26391;&#22686;&#37327;&#30340;L&#233;vy&#21306;&#22495;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#36890;&#36807;&#8220;&#26725;&#32763;&#36716;&#8221;&#25805;&#20316;&#65292;&#36755;&#20986;&#30340;&#26679;&#26412;&#21487;&#20197;&#31934;&#30830;&#21305;&#37197;&#25152;&#26377;&#22855;&#25968;&#38454;&#30697;&#65292;&#35299;&#20915;&#20102;&#38750;&#39640;&#26031;&#24615;&#36136;&#19979;&#30340;&#25277;&#26679;&#22256;&#38590;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#24403;&#25968;&#20540;&#27169;&#25311;SDE&#30340;&#35299;&#26102;&#65292;&#35201;&#23454;&#29616;&#24378;&#25910;&#25947;&#36895;&#29575;&#36229;&#36807;O(\sqrt{h})&#65288;&#20854;&#20013;h&#20026;&#27493;&#38271;&#65289;&#65292;&#38656;&#35201;&#20351;&#29992;&#26576;&#20123;&#24067;&#26391;&#36816;&#21160;&#30340;&#36845;&#20195;&#31215;&#20998;&#65292;&#36890;&#24120;&#31216;&#20026;&#20854;&#8220;L&#233;vy&#21306;&#22495;&#8221;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#38750;&#39640;&#26031;&#24615;&#36136;&#65292;&#23545;&#20110;d&#32500;&#24067;&#26391;&#36816;&#21160;&#65288;d&gt;2&#65289;&#65292;&#30446;&#21069;&#27809;&#26377;&#24555;&#36895;&#36817;&#20284;&#25277;&#26679;&#31639;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;L&#233;vyGAN&#65292;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#29983;&#25104;&#26465;&#20214;&#20110;&#24067;&#26391;&#22686;&#37327;&#30340;L&#233;vy&#21306;&#22495;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#36890;&#36807;&#8220;&#26725;&#32763;&#36716;&#8221;&#25805;&#20316;&#65292;&#36755;&#20986;&#30340;&#26679;&#26412;&#21487;&#20197;&#31934;&#30830;&#21305;&#37197;&#25152;&#26377;&#22855;&#25968;&#38454;&#30697;&#12290;&#25105;&#20204;&#30340;&#29983;&#25104;&#22120;&#37319;&#29992;&#32463;&#36807;&#37327;&#36523;&#23450;&#21046;&#30340;GNN-inspired&#26550;&#26500;&#65292;&#24378;&#21046;&#36755;&#20986;&#20998;&#24067;&#19982;&#26465;&#20214;&#21464;&#37327;&#20043;&#38388;&#30340;&#27491;&#30830;&#20381;&#36182;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#32467;&#21512;&#20102;&#22522;&#20110;&#29305;&#24449;&#20989;&#25968;&#30340;&#25968;&#23398;&#21407;&#29702;&#30340;&#21028;&#21035;&#24615;&#24402;&#19968;&#21270;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that, when numerically simulating solutions to SDEs, achieving a strong convergence rate better than O(\sqrt{h}) (where h is the step size) requires the use of certain iterated integrals of Brownian motion, commonly referred to as its "L\'{e}vy areas". However, these stochastic integrals are difficult to simulate due to their non-Gaussian nature and for a d-dimensional Brownian motion with d &gt; 2, no fast almost-exact sampling algorithm is known.  In this paper, we propose L\'{e}vyGAN, a deep-learning-based model for generating approximate samples of L\'{e}vy area conditional on a Brownian increment. Due to our "Bridge-flipping" operation, the output samples match all joint and conditional odd moments exactly. Our generator employs a tailored GNN-inspired architecture, which enforces the correct dependency structure between the output distribution and the conditioning variable. Furthermore, we incorporate a mathematically principled characteristic-function based discrim
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20462;&#21098;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#29702;&#24819;&#30340;&#31232;&#30095;&#31243;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.02451</link><description>&lt;p&gt;
&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20462;&#21098;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Pruning a neural network using Bayesian inference. (arXiv:2308.02451v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02451
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20462;&#21098;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#29702;&#24819;&#30340;&#31232;&#30095;&#31243;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20462;&#21098;&#26159;&#19968;&#31181;&#38750;&#24120;&#26377;&#25928;&#30340;&#25216;&#26415;&#65292;&#26088;&#22312;&#20943;&#23569;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#22312;&#36825;&#31687;&#30740;&#31350;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20462;&#21098;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#26080;&#32541;&#22320;&#38598;&#25104;&#21040;&#35757;&#32451;&#36807;&#31243;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#20462;&#21098;&#21069;&#21518;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#27010;&#29575;&#65292;&#20174;&#32780;&#35745;&#31639;&#36125;&#21494;&#26031;&#22240;&#23376;&#12290;&#35745;&#31639;&#30340;&#36125;&#21494;&#26031;&#22240;&#23376;&#25351;&#23548;&#30528;&#36845;&#20195;&#20462;&#21098;&#36807;&#31243;&#12290;&#36890;&#36807;&#23545;&#22810;&#20010;&#22522;&#20934;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20445;&#25345;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#29702;&#24819;&#30340;&#31232;&#30095;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network pruning is a highly effective technique aimed at reducing the computational and memory demands of large neural networks. In this research paper, we present a novel approach to pruning neural networks utilizing Bayesian inference, which can seamlessly integrate into the training procedure. Our proposed method leverages the posterior probabilities of the neural network prior to and following pruning, enabling the calculation of Bayes factors. The calculated Bayes factors guide the iterative pruning. Through comprehensive evaluations conducted on multiple benchmarks, we demonstrate that our method achieves desired levels of sparsity while maintaining competitive accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36339;&#27493;&#38271;&#24230;&#21487;&#24494;&#20998;&#30340;&#30701;&#26102;&#20613;&#37324;&#21494;&#21464;&#25442;&#65292;&#36890;&#36807;&#20351;&#36339;&#27493;&#38271;&#24230;&#36830;&#32493;&#65292;&#23454;&#29616;&#20102;&#26799;&#24230;&#20248;&#21270;&#30340;&#26102;&#38388;&#23450;&#20301;&#25511;&#21046;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#20248;&#21270;&#25928;&#26524;&#21644;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#38598;&#25104;&#21040;&#29616;&#26377;&#31639;&#27861;&#21644;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;</title><link>http://arxiv.org/abs/2308.02421</link><description>&lt;p&gt;
&#22522;&#20110;&#36339;&#27493;&#38271;&#24230;&#21487;&#24494;&#20998;&#30340;&#30701;&#26102;&#20613;&#37324;&#21494;&#21464;&#25442;
&lt;/p&gt;
&lt;p&gt;
Differentiable short-time Fourier transform with respect to the hop length. (arXiv:2308.02421v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36339;&#27493;&#38271;&#24230;&#21487;&#24494;&#20998;&#30340;&#30701;&#26102;&#20613;&#37324;&#21494;&#21464;&#25442;&#65292;&#36890;&#36807;&#20351;&#36339;&#27493;&#38271;&#24230;&#36830;&#32493;&#65292;&#23454;&#29616;&#20102;&#26799;&#24230;&#20248;&#21270;&#30340;&#26102;&#38388;&#23450;&#20301;&#25511;&#21046;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#20248;&#21270;&#25928;&#26524;&#21644;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#38598;&#25104;&#21040;&#29616;&#26377;&#31639;&#27861;&#21644;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36339;&#27493;&#38271;&#24230;&#21487;&#24494;&#20998;&#30340;&#30701;&#26102;&#20613;&#37324;&#21494;&#21464;&#25442;&#65288;STFT&#65289;&#65292;&#36890;&#36807;&#20351;&#36825;&#20123;&#21442;&#25968;&#36830;&#32493;&#65292;&#20351;&#36339;&#27493;&#38271;&#24230;&#25110;&#24103;&#26102;&#38388;&#20301;&#32622;&#21487;&#20197;&#22522;&#20110;&#26799;&#24230;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#23545;&#24103;&#30340;&#26102;&#38388;&#23450;&#20301;&#26356;&#22909;&#30340;&#25511;&#21046;&#65292;&#22240;&#20026;&#36339;&#27493;&#38271;&#24230;&#30340;&#36830;&#32493;&#24615;&#20801;&#35768;&#36827;&#34892;&#26356;&#31934;&#32454;&#30340;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#36129;&#29486;&#36824;&#21487;&#20197;&#20351;&#29992;&#35832;&#22914;&#26799;&#24230;&#19979;&#38477;&#20043;&#31867;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#27604;&#20256;&#32479;&#30340;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;&#26356;&#21152;&#39640;&#25928;&#12290;&#25105;&#20204;&#30340;&#21487;&#24494;&#20998;STFT&#20063;&#21487;&#20197;&#36731;&#26494;&#38598;&#25104;&#21040;&#29616;&#26377;&#30340;&#31639;&#27861;&#21644;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#27169;&#25311;&#23454;&#20363;&#65292;&#20197;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#24341;&#36215;&#30740;&#31350;&#30028;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a differentiable version of the short-time Fourier transform (STFT) that allows for gradient-based optimization of the hop length or the frame temporal position by making these parameters continuous. Our approach provides improved control over the temporal positioning of frames, as the continuous nature of the hop length allows for a more finely-tuned optimization. Furthermore, our contribution enables the use of optimization methods such as gradient descent, which are more computationally efficient than conventional discrete optimization methods. Our differentiable STFT can also be easily integrated into existing algorithms and neural networks. We present a simulated illustration to demonstrate the efficacy of our approach and to garner interest from the research community.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#31454;&#25216;&#20307;&#32946;&#25216;&#33021;&#35780;&#32423;&#20027;&#35201;&#26041;&#27861;&#30340;&#20840;&#38754;&#22238;&#39038;&#65292;&#24182;&#25552;&#20986;&#20102;&#37319;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#30340;&#24314;&#35758;&#12290;&#36890;&#36807;&#20351;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#65292;&#29609;&#23478;&#30340;&#25216;&#33021;&#21487;&#20197;&#34920;&#31034;&#20026;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#21464;&#37327;&#65292;&#32780;&#27604;&#36187;&#32467;&#26524;&#21017;&#26159;&#21807;&#19968;&#30340;&#35266;&#27979;&#37327;&#12290;&#35813;&#35270;&#35282;&#26377;&#21161;&#20110;&#35299;&#32806;&#24314;&#27169;&#21644;&#25512;&#29702;&#65292;&#24182;&#20419;&#36827;&#36890;&#29992;&#25512;&#29702;&#24037;&#20855;&#30340;&#21457;&#23637;&#12290;&#22312;&#26500;&#24314;&#25216;&#33021;&#35780;&#32423;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#26041;&#38754;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#22522;&#26412;&#27493;&#39588;&#65292;&#21516;&#26102;&#36824;&#35752;&#35770;&#20102;&#28388;&#27874;&#12289;&#24179;&#28369;&#21644;&#21442;&#25968;&#20272;&#35745;&#31561;&#25512;&#29702;&#38454;&#27573;&#12290;&#22312;&#38754;&#23545;&#39640;&#32500;&#22330;&#26223;&#20013;&#30340;&#35745;&#31639;&#25361;&#25112;&#26102;&#65292;&#26412;&#25991;&#24378;&#35843;&#20102;&#25152;&#37319;&#29992;&#30340;&#36817;&#20284;&#21644;&#31616;&#21270;&#26041;&#27861;&#12290;&#35813;&#25991;&#25552;&#20379;&#20102;&#23545;&#35760;&#24405;&#30340;&#27969;&#34892;&#26041;&#27861;&#30340;&#31616;&#26126;&#24635;&#32467;&#12290;</title><link>http://arxiv.org/abs/2308.02414</link><description>&lt;p&gt;
&#23545;&#22312;&#32447;&#25216;&#33021;&#35780;&#32423;&#24314;&#27169;&#21644;&#25512;&#29702;&#30340;&#29366;&#24577;&#31354;&#38388;&#35270;&#35282;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A State-Space Perspective on Modelling and Inference for Online Skill Rating. (arXiv:2308.02414v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02414
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#31454;&#25216;&#20307;&#32946;&#25216;&#33021;&#35780;&#32423;&#20027;&#35201;&#26041;&#27861;&#30340;&#20840;&#38754;&#22238;&#39038;&#65292;&#24182;&#25552;&#20986;&#20102;&#37319;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#30340;&#24314;&#35758;&#12290;&#36890;&#36807;&#20351;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#65292;&#29609;&#23478;&#30340;&#25216;&#33021;&#21487;&#20197;&#34920;&#31034;&#20026;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#21464;&#37327;&#65292;&#32780;&#27604;&#36187;&#32467;&#26524;&#21017;&#26159;&#21807;&#19968;&#30340;&#35266;&#27979;&#37327;&#12290;&#35813;&#35270;&#35282;&#26377;&#21161;&#20110;&#35299;&#32806;&#24314;&#27169;&#21644;&#25512;&#29702;&#65292;&#24182;&#20419;&#36827;&#36890;&#29992;&#25512;&#29702;&#24037;&#20855;&#30340;&#21457;&#23637;&#12290;&#22312;&#26500;&#24314;&#25216;&#33021;&#35780;&#32423;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#26041;&#38754;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#22522;&#26412;&#27493;&#39588;&#65292;&#21516;&#26102;&#36824;&#35752;&#35770;&#20102;&#28388;&#27874;&#12289;&#24179;&#28369;&#21644;&#21442;&#25968;&#20272;&#35745;&#31561;&#25512;&#29702;&#38454;&#27573;&#12290;&#22312;&#38754;&#23545;&#39640;&#32500;&#22330;&#26223;&#20013;&#30340;&#35745;&#31639;&#25361;&#25112;&#26102;&#65292;&#26412;&#25991;&#24378;&#35843;&#20102;&#25152;&#37319;&#29992;&#30340;&#36817;&#20284;&#21644;&#31616;&#21270;&#26041;&#27861;&#12290;&#35813;&#25991;&#25552;&#20379;&#20102;&#23545;&#35760;&#24405;&#30340;&#27969;&#34892;&#26041;&#27861;&#30340;&#31616;&#26126;&#24635;&#32467;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#22238;&#39038;&#20102;&#29992;&#20110;&#31454;&#25216;&#20307;&#32946;&#25216;&#33021;&#35780;&#32423;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20513;&#37319;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#65292;&#23558;&#29609;&#23478;&#30340;&#25216;&#33021;&#34920;&#31034;&#20026;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#65292;&#27604;&#36187;&#32467;&#26524;&#20316;&#20026;&#21807;&#19968;&#30340;&#35266;&#27979;&#37327;&#12290;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#26377;&#21161;&#20110;&#35299;&#32806;&#24314;&#27169;&#21644;&#25512;&#29702;&#65292;&#20174;&#32780;&#20351;&#24471;&#26356;&#21152;&#27880;&#37325;&#27169;&#22411;&#20551;&#35774;&#30340;&#26041;&#27861;&#24471;&#20197;&#31361;&#20986;&#65292;&#24182;&#20419;&#36827;&#20102;&#36890;&#29992;&#25512;&#29702;&#24037;&#20855;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#26500;&#24314;&#25216;&#33021;&#35780;&#32423;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22522;&#26412;&#27493;&#39588;&#65292;&#24182;&#35752;&#35770;&#20102;&#25512;&#29702;&#30340;&#19977;&#20010;&#38454;&#27573;&#65306;&#28388;&#27874;&#12289;&#24179;&#28369;&#21644;&#21442;&#25968;&#20272;&#35745;&#12290;&#22312;&#25972;&#20010;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#28041;&#21450;&#22823;&#37327;&#29609;&#23478;&#21644;&#27604;&#36187;&#30340;&#39640;&#32500;&#22330;&#26223;&#20013;&#36827;&#34892;&#35268;&#27169;&#25193;&#23637;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#29992;&#20110;&#26377;&#25928;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#36817;&#20284;&#21644;&#31616;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25991;&#29486;&#20013;&#35760;&#24405;&#30340;&#27969;&#34892;&#26041;&#27861;&#30340;&#31616;&#26126;&#24635;&#32467;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper offers a comprehensive review of the main methodologies used for skill rating in competitive sports. We advocate for a state-space model perspective, wherein players' skills are represented as time-varying, and match results serve as the sole observed quantities. The state-space model perspective facilitates the decoupling of modeling and inference, enabling a more focused approach highlighting model assumptions, while also fostering the development of general-purpose inference tools. We explore the essential steps involved in constructing a state-space model for skill rating before turning to a discussion on the three stages of inference: filtering, smoothing and parameter estimation. Throughout, we examine the computational challenges of scaling up to high-dimensional scenarios involving numerous players and matches, highlighting approximations and reductions used to address these challenges effectively. We provide concise summaries of popular methods documented in the lit
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;d&#20998;&#31163;&#12289;e&#20998;&#31163;&#21644;&#19981;&#30456;&#23481;&#25903;&#25345;&#26469;&#26816;&#27979;&#19981;&#21516;&#30340;&#22240;&#26524;&#22330;&#26223;&#65292;&#20174;&#32780;&#23558;&#20855;&#26377;&#19981;&#31561;&#24335;&#32422;&#26463;&#21644;&#19981;&#20855;&#26377;&#19981;&#31561;&#24335;&#32422;&#26463;&#30340;&#22330;&#26223;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2308.02380</link><description>&lt;p&gt;
&#20998;&#31867;&#22240;&#26524;&#32467;&#26500;&#65306;&#30830;&#23450;&#32463;&#20856;&#30456;&#20851;&#24615;&#20309;&#26102;&#21463;&#19981;&#31561;&#24335;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Classifying Causal Structures: Ascertaining when Classical Correlations are Constrained by Inequalities. (arXiv:2308.02380v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;d&#20998;&#31163;&#12289;e&#20998;&#31163;&#21644;&#19981;&#30456;&#23481;&#25903;&#25345;&#26469;&#26816;&#27979;&#19981;&#21516;&#30340;&#22240;&#26524;&#22330;&#26223;&#65292;&#20174;&#32780;&#23558;&#20855;&#26377;&#19981;&#31561;&#24335;&#32422;&#26463;&#21644;&#19981;&#20855;&#26377;&#19981;&#31561;&#24335;&#32422;&#26463;&#30340;&#22330;&#26223;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#32452;&#21464;&#37327;&#20043;&#38388;&#30340;&#32463;&#20856;&#22240;&#26524;&#20851;&#31995;&#21487;&#20197;&#22312;&#35266;&#23519;&#21464;&#37327;&#21644;&#28508;&#22312;&#21464;&#37327;&#20043;&#38388;&#23548;&#33268;&#30456;&#31561;&#32422;&#26463;&#65288;&#36890;&#24120;&#26159;&#26465;&#20214;&#29420;&#31435;&#65289;&#21644;&#19981;&#31561;&#32422;&#26463;&#65288;&#20202;&#22120;&#19981;&#31561;&#24335;&#21644;&#36125;&#23572;&#19981;&#31561;&#24335;&#26159;&#20856;&#22411;&#31034;&#20363;&#65289;&#65292;&#20174;&#32780;&#20351;&#23427;&#20204;&#20043;&#38388;&#30340;&#20998;&#24067;&#22312;&#35266;&#23519;&#21464;&#37327;&#19978;&#20855;&#26377;&#19968;&#23450;&#30340;&#32422;&#26463;&#24615;&#12290;&#21015;&#20030;&#19968;&#20010;&#22240;&#26524;&#32467;&#26500;&#25152;&#38544;&#21547;&#30340;&#19981;&#31561;&#24335;&#32422;&#26463;&#36890;&#24120;&#27604;&#21015;&#20030;&#23427;&#30340;&#31561;&#24335;&#32422;&#26463;&#26356;&#22256;&#38590;&#12290;&#27492;&#22806;&#65292;&#21482;&#26377;&#19981;&#31561;&#24335;&#32422;&#26463;&#25165;&#33021;&#34987;&#37327;&#23376;&#30456;&#20851;&#24615;&#36829;&#21453;&#12290;&#30001;&#20110;&#36825;&#20004;&#20010;&#21407;&#22240;&#65292;&#23558;&#22240;&#26524;&#22330;&#26223;&#20998;&#31867;&#20026;&#20855;&#26377;&#19981;&#31561;&#24335;&#32422;&#26463;&#21644;&#19981;&#20855;&#26377;&#19981;&#31561;&#24335;&#32422;&#26463;&#30340;&#22330;&#26223;&#26159;&#37325;&#35201;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;d&#20998;&#31163;&#12289;e&#20998;&#31163;&#21644;&#19981;&#30456;&#23481;&#25903;&#25345;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#36825;&#20123;&#22330;&#26223;&#12290;&#35768;&#22810;&#65288;&#20063;&#35768;&#20840;&#37096;&#65311;&#65289;&#20165;&#20855;&#26377;&#31561;&#24335;&#32422;&#26463;&#30340;&#22330;&#26223;&#21487;&#20197;&#36890;&#36807;Henson&#65292;Lal&#21644;Pusey&#65288;HLP&#65289;&#25552;&#20986;&#30340;&#26465;&#20214;&#26469;&#26816;&#27979;&#12290;&#32771;&#34385;&#21040;&#26368;&#22810;4&#20010;&#34987;&#35266;&#23519;&#21040;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
The classical causal relations between a set of variables, some observed and some latent, can induce both equality constraints (typically conditional independences) as well as inequality constraints (Instrumental and Bell inequalities being prototypical examples) on their compatible distribution over the observed variables. Enumerating a causal structure's implied inequality constraints is generally far more difficult than enumerating its equalities. Furthermore, only inequality constraints ever admit violation by quantum correlations. For both those reasons, it is important to classify causal scenarios into those which impose inequality constraints versus those which do not. Here we develop methods for detecting such scenarios by appealing to d-separation, e-separation, and incompatible supports. Many (perhaps all?) scenarios with exclusively equality constraints can be detected via a condition articulated by Henson, Lal and Pusey (HLP). Considering all scenarios with up to 4 observed
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31215;&#20998;&#30340;&#26080;&#24378;&#24230;&#31215;&#20998;&#21270;&#23398;&#33021;&#30340;&#23398;&#20064;&#26694;&#26550;IFIB&#65292;&#29992;&#20110;&#24314;&#27169;&#31163;&#25955;&#20107;&#20214;&#20013;&#20855;&#26377;&#20998;&#31867;&#25110;&#25968;&#20540;&#23646;&#24615;&#30340;&#20107;&#20214;&#26631;&#35760;&#12290;</title><link>http://arxiv.org/abs/2308.02360</link><description>&lt;p&gt;
&#22522;&#20110;&#31215;&#20998;&#30340;&#26080;&#24378;&#24230;&#31215;&#20998;&#21270;&#23398;&#33021;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Intensity-free Integral-based Learning of Marked Temporal Point Processes. (arXiv:2308.02360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02360
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31215;&#20998;&#30340;&#26080;&#24378;&#24230;&#31215;&#20998;&#21270;&#23398;&#33021;&#30340;&#23398;&#20064;&#26694;&#26550;IFIB&#65292;&#29992;&#20110;&#24314;&#27169;&#31163;&#25955;&#20107;&#20214;&#20013;&#20855;&#26377;&#20998;&#31867;&#25110;&#25968;&#20540;&#23646;&#24615;&#30340;&#20107;&#20214;&#26631;&#35760;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26631;&#35760;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#65288;MTPP&#65289;&#20013;&#65292;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#20026;&#26465;&#20214;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;PDF&#65289;$p^*&#65288;m&#65292;t&#65289;$&#21442;&#25968;&#21270;&#25554;&#20540;&#26102;&#38388;t&#21644;&#26631;&#35760;m&#22312;&#21382;&#21490;&#26465;&#20214;&#19979;&#12290;&#29616;&#26377;&#30740;&#31350;&#22823;&#22810;&#39044;&#20808;&#23450;&#20041;&#24378;&#24230;&#20989;&#25968;&#12290;&#23427;&#20204;&#30340;&#23454;&#29992;&#24615;&#21463;&#21040;&#25351;&#23450;&#24378;&#24230;&#20989;&#25968;&#27491;&#30830;&#24418;&#24335;&#30340;&#25361;&#25112;&#65292;&#36825;&#23545;&#20110;&#24179;&#34913;&#34920;&#36798;&#33021;&#21147;&#21644;&#22788;&#29702;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#65292;&#26377;&#30740;&#31350;&#25670;&#33073;&#39044;&#23450;&#20041;&#24378;&#24230;&#20989;&#25968;&#65292;&#19968;&#20010;&#27169;&#22411;$p^*&#65288;t&#65289;$&#21644;$p^*&#65288;m&#65289;$&#20998;&#24320;&#65292;&#21478;&#19968;&#20010;&#20391;&#37325;&#20110;&#19981;&#32771;&#34385;&#26631;&#35760;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#65288;TPP&#65289;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#24320;&#21457;&#39640;&#20445;&#30495;&#24230;&#30340;$p^*&#65288;m&#65292;t&#65289;$&#65292;&#36866;&#29992;&#20110;&#20107;&#20214;&#26631;&#35760;&#22312;&#22810;&#32500;&#36830;&#32493;&#31354;&#38388;&#20013;&#20855;&#26377;&#20998;&#31867;&#25110;&#25968;&#20540;&#23646;&#24615;&#30340;&#31163;&#25955;&#20107;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#26694;&#26550;IFIB&#65288;&#26080;&#24378;&#24230;&#31215;&#20998;&#21270;&#23398;&#33021;&#36807;&#31243;&#65289;&#65292;&#30452;&#25509;&#24314;&#27169;&#26465;&#20214;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;$p^*&#65288;m&#65292;t&#65289;$&#12290;
&lt;/p&gt;
&lt;p&gt;
In the marked temporal point processes (MTPP), a core problem is to parameterize the conditional joint PDF (probability distribution function) $p^*(m,t)$ for inter-event time $t$ and mark $m$, conditioned on the history. The majority of existing studies predefine intensity functions. Their utility is challenged by specifying the intensity function's proper form, which is critical to balance expressiveness and processing efficiency. Recently, there are studies moving away from predefining the intensity function -- one models $p^*(t)$ and $p^*(m)$ separately, while the other focuses on temporal point processes (TPPs), which do not consider marks. This study aims to develop high-fidelity $p^*(m,t)$ for discrete events where the event marks are either categorical or numeric in a multi-dimensional continuous space. We propose a solution framework IFIB (\underline{I}ntensity-\underline{f}ree \underline{I}ntegral-\underline{b}ased process) that models conditional joint PDF $p^*(m,t)$ directly
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#37325;&#22797;&#27979;&#37327;&#30340;&#39640;&#26031;&#33258;&#30001;&#22330;&#20013;&#20272;&#35745;&#21152;&#26435;&#32593;&#32476;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#20998;&#24067;&#20613;&#37324;&#21494;&#20998;&#26512;&#29305;&#24615;&#30340;&#26032;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#26500;&#36896;&#30340;&#22797;&#25968;&#20540;&#32479;&#35745;&#37327;&#65292;&#20855;&#26377;&#30740;&#31350;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2308.02344</link><description>&lt;p&gt;
&#20174;&#39640;&#26031;&#22270;&#27169;&#22411;&#21644;&#39640;&#26031;&#33258;&#30001;&#22330;&#23398;&#20064;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Networks from Gaussian Graphical Models and Gaussian Free Fields. (arXiv:2308.02344v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02344
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#37325;&#22797;&#27979;&#37327;&#30340;&#39640;&#26031;&#33258;&#30001;&#22330;&#20013;&#20272;&#35745;&#21152;&#26435;&#32593;&#32476;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#20998;&#24067;&#20613;&#37324;&#21494;&#20998;&#26512;&#29305;&#24615;&#30340;&#26032;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#26500;&#36896;&#30340;&#22797;&#25968;&#20540;&#32479;&#35745;&#37327;&#65292;&#20855;&#26377;&#30740;&#31350;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#32593;&#32476;&#19978;&#30340;&#39640;&#26031;&#22270;&#27169;&#22411;&#65288;Gaussian Graphical Model&#65292;&#31616;&#31216;GGM&#65289;&#30340;&#37325;&#22797;&#27979;&#37327;&#20013;&#20272;&#35745;&#21152;&#26435;&#32593;&#32476;&#32467;&#26500;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#26041;&#38754;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19982;&#22522;&#20110;&#20854;&#19978;&#21152;&#26435;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#30456;&#19968;&#33268;&#30340;GGM&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#12290;&#36825;&#31181;GGM&#22312;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#19968;&#30452;&#21463;&#21040;&#20851;&#27880;&#65292;&#24182;&#34987;&#31216;&#20026;&#39640;&#26031;&#33258;&#30001;&#22330;&#65288;Gaussian Free Field&#65292;&#31616;&#31216;GFF&#65289;&#12290;&#36817;&#24180;&#26469;&#65292;&#23427;&#20204;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#29702;&#35770;&#35745;&#31639;&#26426;&#31185;&#23398;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#30340;&#20852;&#36259;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#20998;&#24067;&#30340;&#20613;&#37324;&#21494;&#20998;&#26512;&#29305;&#24615;&#30340;&#37325;&#22797;&#27979;&#37327;&#30340;GFF&#26469;&#20272;&#35745;&#21152;&#26435;&#32593;&#32476;&#65288;&#31561;&#20215;&#22320;&#65292;&#20854;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65289;&#30340;&#26032;&#22411;&#20272;&#35745;&#37327;&#12290;&#22312;&#36825;&#20010;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#26500;&#36896;&#30340;&#22797;&#25968;&#20540;&#32479;&#35745;&#37327;&#65292;&#36825;&#20123;&#32479;&#35745;&#37327;&#26412;&#36523;&#23601;&#20855;&#26377;&#30740;&#31350;&#20215;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#20855;&#20307;&#30340;&#24674;&#22797;&#20445;&#35777;&#21644;&#23545;&#25152;&#38656;&#37319;&#26679;&#30340;&#30028;&#38480;&#26469;&#35777;&#26126;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the problem of estimating the structure of a weighted network from repeated measurements of a Gaussian Graphical Model (GGM) on the network. In this vein, we consider GGMs whose covariance structures align with the geometry of the weighted network on which they are based. Such GGMs have been of longstanding interest in statistical physics, and are referred to as the Gaussian Free Field (GFF). In recent years, they have attracted considerable interest in the machine learning and theoretical computer science. In this work, we propose a novel estimator for the weighted network (equivalently, its Laplacian) from repeated measurements of a GFF on the network, based on the Fourier analytic properties of the Gaussian distribution. In this pursuit, our approach exploits complex-valued statistics constructed from observed data, that are of interest on their own right. We demonstrate the effectiveness of our estimator with concrete recovery guarantees and bounds on the required sa
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02293</link><description>&lt;p&gt;
&#29992;&#27491;&#21017;&#21270;&#39640;&#38454;&#24635;&#21464;&#24046;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02293
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#39640;&#24230;&#34920;&#36798;&#30340;&#21442;&#25968;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#24314;&#27169;&#22797;&#26434;&#27010;&#24565;&#65292;&#20294;&#35757;&#32451;&#36825;&#31181;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#24050;&#30693;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#19968;&#31181;k&#38454;&#24635;&#21464;&#24046;&#65288;k-TV&#65289;&#27491;&#21017;&#21270;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#35201;&#35757;&#32451;&#30340;&#21442;&#25968;&#27169;&#22411;&#30340;k&#38454;&#23548;&#25968;&#30340;&#24179;&#26041;&#31215;&#20998;&#65292;&#36890;&#36807;&#24809;&#32602;k-TV&#26469;&#20135;&#29983;&#19968;&#20010;&#26356;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;&#23613;&#31649;&#23558;k-TV&#39033;&#24212;&#29992;&#20110;&#19968;&#33324;&#30340;&#21442;&#25968;&#27169;&#22411;&#30001;&#20110;&#31215;&#20998;&#32780;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#65292;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#24102;&#26377;k-TV&#27491;&#21017;&#21270;&#30340;&#19968;&#33324;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#26174;&#24335;&#30340;&#25968;&#20540;&#31215;&#20998;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#32467;&#26500;&#20219;&#24847;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#36827;&#34892;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#20248;&#21270;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#65288;ProxGD&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;&#26354;&#29575;&#20449;&#24687;&#23436;&#20840;&#33258;&#36866;&#24212;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#24615;&#65292;&#19988;&#20801;&#35768;&#20351;&#29992;&#26356;&#22823;&#30340;&#27493;&#38271;&#12290;</title><link>http://arxiv.org/abs/2308.02261</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#30340;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Adaptive Proximal Gradient Method for Convex Optimization. (arXiv:2308.02261v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#65288;ProxGD&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;&#26354;&#29575;&#20449;&#24687;&#23436;&#20840;&#33258;&#36866;&#24212;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#24615;&#65292;&#19988;&#20801;&#35768;&#20351;&#29992;&#26356;&#22823;&#30340;&#27493;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#20984;&#20248;&#21270;&#20013;&#30340;&#20004;&#20010;&#22522;&#26412;&#19968;&#38454;&#31639;&#27861;&#65292;&#21363;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#36817;&#31471;&#26799;&#24230;&#26041;&#27861;&#65288;ProxGD&#65289;&#12290;&#25105;&#20204;&#30340;&#37325;&#28857;&#26159;&#36890;&#36807;&#21033;&#29992;&#24179;&#28369;&#20989;&#25968;&#30340;&#23616;&#37096;&#26354;&#29575;&#20449;&#24687;&#65292;&#20351;&#36825;&#20123;&#31639;&#27861;&#23436;&#20840;&#33258;&#36866;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#24046;&#24322;&#30340;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;GD&#21644;ProxGD&#65292;&#22240;&#27492;&#19981;&#20250;&#22686;&#21152;&#35745;&#31639;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#20165;&#20551;&#35774;&#26799;&#24230;&#30340;&#23616;&#37096;Lipschitz&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#21478;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#29256;&#26412;&#20801;&#35768;&#20351;&#29992;&#27604;[MM20]&#26368;&#21021;&#24314;&#35758;&#30340;&#26356;&#22823;&#30340;&#27493;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore two fundamental first-order algorithms in convex optimization, namely, gradient descent (GD) and proximal gradient method (ProxGD). Our focus is on making these algorithms entirely adaptive by leveraging local curvature information of smooth functions. We propose adaptive versions of GD and ProxGD that are based on observed gradient differences and, thus, have no added computational costs. Moreover, we prove convergence of our methods assuming only local Lipschitzness of the gradient. In addition, the proposed versions allow for even larger stepsizes than those initially suggested in [MM20].
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20284;&#28982;&#27604;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#26500;&#24314;&#19981;&#23545;&#31216;&#21306;&#38388;&#65292;&#32771;&#34385;&#20102;&#35757;&#32451;&#26102;&#38388;&#12289;&#32593;&#32476;&#26550;&#26500;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#31561;&#22240;&#32032;&#12290;&#23613;&#31649;&#26041;&#27861;&#23454;&#29616;&#26114;&#36149;&#65292;&#20294;&#22312;&#29305;&#23450;&#39046;&#22495;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.02221</link><description>&lt;p&gt;
&#22522;&#20110;&#20284;&#28982;&#27604;&#30340;&#32622;&#20449;&#21306;&#38388;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Likelihood-ratio-based confidence intervals for neural networks. (arXiv:2308.02221v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02221
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20284;&#28982;&#27604;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#26500;&#24314;&#19981;&#23545;&#31216;&#21306;&#38388;&#65292;&#32771;&#34385;&#20102;&#35757;&#32451;&#26102;&#38388;&#12289;&#32593;&#32476;&#26550;&#26500;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#31561;&#22240;&#32032;&#12290;&#23613;&#31649;&#26041;&#27861;&#23454;&#29616;&#26114;&#36149;&#65292;&#20294;&#22312;&#29305;&#23450;&#39046;&#22495;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20284;&#28982;&#27604;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21517;&#20026;DeepLR&#65292;&#20855;&#26377;&#35768;&#22810;&#20248;&#28857;&#65292;&#20854;&#20013;&#26368;&#37325;&#35201;&#30340;&#26159;&#33021;&#22815;&#26500;&#24314;&#22312;&#25968;&#25454;&#26377;&#38480;&#30340;&#21306;&#22495;&#20013;&#25193;&#23637;&#30340;&#19981;&#23545;&#31216;&#21306;&#38388;&#65292;&#24182;&#22266;&#26377;&#22320;&#32771;&#34385;&#20102;&#35757;&#32451;&#26102;&#38388;&#12289;&#32593;&#32476;&#26550;&#26500;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#31561;&#22240;&#32032;&#12290;&#23613;&#31649;&#25215;&#35748;&#30446;&#21069;&#30340;&#26041;&#27861;&#23454;&#29616;&#23545;&#20110;&#35768;&#22810;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#26469;&#35828;&#36807;&#20110;&#26114;&#36149;&#65292;&#20294;&#22312;&#35832;&#22914;&#21307;&#23398;&#39044;&#27979;&#25110;&#22825;&#20307;&#29289;&#29702;&#23398;&#31561;&#29305;&#23450;&#39046;&#22495;&#20013;&#65292;&#21487;&#38752;&#30340;&#21333;&#20010;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21487;&#33021;&#24050;&#32463;&#21512;&#29702;&#12290;&#36825;&#39033;&#24037;&#20316;&#31361;&#20986;&#20102;&#22522;&#20110;&#20284;&#28982;&#27604;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#37325;&#35201;&#28508;&#21147;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#24320;&#36767;&#20102;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a first implementation of a novel likelihood-ratio-based approach for constructing confidence intervals for neural networks. Our method, called DeepLR, offers several qualitative advantages: most notably, the ability to construct asymmetric intervals that expand in regions with a limited amount of data, and the inherent incorporation of factors such as the amount of training time, network architecture, and regularization techniques. While acknowledging that the current implementation of the method is prohibitively expensive for many deep-learning applications, the high cost may already be justified in specific fields like medical predictions or astrophysics, where a reliable uncertainty estimate for a single prediction is essential. This work highlights the significant potential of a likelihood-ratio-based uncertainty estimate and establishes a promising avenue for future research.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.02058</link><description>&lt;p&gt;
&#25972;&#21512;&#40065;&#33725;&#34892;&#20026;&#21040;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;
&lt;/p&gt;
&lt;p&gt;
Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21253;&#21547;&#21487;&#38752;&#24615;&#27979;&#37327;&#30340;&#25512;&#33616;&#31995;&#32479;&#24448;&#24448;&#22312;&#39044;&#27979;&#20013;&#26356;&#21152;&#20445;&#23432;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20445;&#25345;&#21487;&#38752;&#24615;&#12290;&#36825;&#23548;&#33268;&#20102;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#25552;&#20379;&#30340;&#35206;&#30422;&#33539;&#22260;&#21644;&#26032;&#39062;&#24615;&#30340;&#26174;&#33879;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#30697;&#38453;&#20998;&#35299;&#22411;&#25512;&#33616;&#31995;&#32479;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#21152;&#20837;&#19968;&#39033;&#26032;&#30340;&#39033;&#65292;&#31216;&#20026;&#40065;&#33725;&#34892;&#20026;&#65292;&#23427;&#21487;&#20197;&#25511;&#21046;&#22312;&#20570;&#20986;&#20851;&#20110;&#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#20915;&#31574;&#26102;&#25152;&#24076;&#26395;&#30340;&#39118;&#38505;&#27700;&#24179;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#40065;&#33725;&#34892;&#20026;&#19981;&#20165;&#20801;&#35768;&#36827;&#34892;&#39118;&#38505;&#35843;&#25511;&#65292;&#36824;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#30340;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#21516;&#27493;&#38543;&#26426;&#32447;&#24615;&#31995;&#32479;&#30340;&#40065;&#26834;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#38750;&#28176;&#36817;&#24615;&#20445;&#35777;&#30340;&#26174;&#33879;&#27700;&#24179;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#32622;&#20449;&#21306;&#38388;&#20272;&#35745;&#12289;&#25490;&#21015;&#26816;&#39564;&#20197;&#21450;&#19968;&#33324;&#30340;&#20381;&#36182;&#24230;&#37327;&#65292;&#20197;&#26816;&#27979;&#31995;&#32479;&#20043;&#38388;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2308.02054</link><description>&lt;p&gt;
&#38024;&#23545;&#21516;&#27493;&#38543;&#26426;&#32447;&#24615;&#31995;&#32479;&#30340;&#40065;&#26834;&#29420;&#31435;&#24615;&#26816;&#39564;&#21450;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Robust Independence Tests with Finite Sample Guarantees for Synchronous Stochastic Linear Systems. (arXiv:2308.02054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#21516;&#27493;&#38543;&#26426;&#32447;&#24615;&#31995;&#32479;&#30340;&#40065;&#26834;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#38750;&#28176;&#36817;&#24615;&#20445;&#35777;&#30340;&#26174;&#33879;&#27700;&#24179;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#32622;&#20449;&#21306;&#38388;&#20272;&#35745;&#12289;&#25490;&#21015;&#26816;&#39564;&#20197;&#21450;&#19968;&#33324;&#30340;&#20381;&#36182;&#24230;&#37327;&#65292;&#20197;&#26816;&#27979;&#31995;&#32479;&#20043;&#38388;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#38543;&#26426;&#32447;&#24615;&#26102;&#19981;&#21464;&#31995;&#32479;&#30340;&#40065;&#26834;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#20854;&#22312;&#35266;&#27979;&#21040;&#30340;&#36755;&#20986;&#26159;&#21516;&#27493;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#25552;&#20379;&#38750;&#28176;&#36817;&#24615;&#20445;&#35777;&#30340;&#26174;&#33879;&#27700;&#24179;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#20998;&#24067;&#26080;&#20851;&#30340;&#31532;&#19968;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#30028;&#38480;&#65292;&#21363;&#21019;&#26032;&#39033;&#21487;&#20197;&#20855;&#26377;&#20219;&#24847;&#20998;&#24067;&#12290;&#35813;&#31639;&#27861;&#32467;&#21512;&#20102;&#32622;&#20449;&#21306;&#38388;&#20272;&#35745;&#12289;&#25490;&#21015;&#26816;&#39564;&#20197;&#21450;&#19968;&#33324;&#30340;&#20381;&#36182;&#24230;&#37327;&#65292;&#22914;&#24076;&#23572;&#20271;&#29305;-&#26045;&#23494;&#29305;&#29420;&#31435;&#24615;&#20934;&#21017;&#21644;&#36317;&#31163;&#21327;&#26041;&#24046;&#65292;&#20197;&#26816;&#27979;&#35266;&#23519;&#21040;&#30340;&#31995;&#32479;&#20043;&#38388;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#20551;&#35774;&#26816;&#39564;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#36890;&#36807;&#33258;&#22238;&#24402;&#31995;&#32479;&#30340;&#31034;&#20363;&#28436;&#31034;&#20102;&#36825;&#20123;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper introduces robust independence tests with non-asymptotically guaranteed significance levels for stochastic linear time-invariant systems, assuming that the observed outputs are synchronous, which means that the systems are driven by jointly i.i.d. noises. Our method provides bounds for the type I error probabilities that are distribution-free, i.e., the innovations can have arbitrary distributions. The algorithm combines confidence region estimates with permutation tests and general dependence measures, such as the Hilbert-Schmidt independence criterion and the distance covariance, to detect any nonlinear dependence between the observed systems. We also prove the consistency of our hypothesis tests under mild assumptions and demonstrate the ideas through the example of autoregressive systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#22312;&#32447;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#20998;&#21035;&#22522;&#20110;&#36882;&#24402;&#26368;&#23567;&#20108;&#20056;&#21644;&#36882;&#24402;&#26680;&#26041;&#27861;&#12290;&#19982;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#25110;&#19981;&#31934;&#30830;&#36924;&#36817;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27599;&#20010;&#23454;&#20363;&#30340;&#20195;&#20215;&#19978;&#20855;&#26377;&#20108;&#27425;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#39118;&#21147;&#30701;&#26399;&#39044;&#27979;&#25361;&#25112;&#65292;&#24182;&#19982;&#20854;&#20182;&#31454;&#20105;&#32773;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2308.01938</link><description>&lt;p&gt;
&#22312;&#32447;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#22522;&#20110;&#36882;&#24402;&#26368;&#23567;&#20108;&#20056;&#21644;&#36882;&#24402;&#26680;&#26041;&#27861;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods. (arXiv:2308.01938v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#22312;&#32447;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#20998;&#21035;&#22522;&#20110;&#36882;&#24402;&#26368;&#23567;&#20108;&#20056;&#21644;&#36882;&#24402;&#26680;&#26041;&#27861;&#12290;&#19982;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#25110;&#19981;&#31934;&#30830;&#36924;&#36817;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27599;&#20010;&#23454;&#20363;&#30340;&#20195;&#20215;&#19978;&#20855;&#26377;&#20108;&#27425;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#39118;&#21147;&#30701;&#26399;&#39044;&#27979;&#25361;&#25112;&#65292;&#24182;&#19982;&#20854;&#20182;&#31454;&#20105;&#32773;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#37319;&#29992;&#39640;&#24615;&#33021;&#22522;&#20110;&#22270;&#30340;MTL&#20844;&#24335;&#65292;&#22522;&#20110;&#21152;&#26435;&#36882;&#24402;&#26368;&#23567;&#20108;&#20056;&#65288;WRLS&#65289;&#21644;&#22312;&#32447;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;OSLSSVR&#65289;&#24320;&#21457;&#20854;&#36882;&#24402;&#29256;&#26412;&#12290;&#37319;&#29992;&#20219;&#21153;&#22534;&#21472;&#36716;&#25442;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23384;&#22312;&#19968;&#20010;&#21333;&#30697;&#38453;&#65292;&#23427;&#34701;&#21512;&#20102;&#22810;&#20219;&#21153;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#20026;MT-WRLS&#26041;&#27861;&#30340;&#21021;&#22987;&#21270;&#36807;&#31243;&#21644;MT-OSLSSVR&#30340;&#22810;&#20219;&#21153;&#26680;&#20989;&#25968;&#25552;&#20379;&#32467;&#26500;&#20449;&#24687;&#12290;&#19982;&#29616;&#26377;&#22823;&#37096;&#20998;&#22522;&#20110;&#22312;&#32447;&#26799;&#24230;&#19979;&#38477;&#65288;OGD&#65289;&#25110;&#19981;&#31934;&#30830;&#31435;&#26041;&#36924;&#36817;&#26041;&#27861;&#30340;&#25991;&#29486;&#30456;&#27604;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#31934;&#30830;&#21644;&#36817;&#20284;&#36882;&#24402;&#65292;&#20854;&#27599;&#20010;&#23454;&#20363;&#30340;&#20195;&#20215;&#22312;&#36755;&#20837;&#31354;&#38388;&#30340;&#32500;&#24230;&#65288;MT-WRLS&#65289;&#25110;&#23454;&#20363;&#23383;&#20856;&#30340;&#22823;&#23567;&#19978;&#26159;&#20108;&#27425;&#30340;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#22312;&#32447;MTL&#26041;&#27861;&#19982;&#20854;&#20182;&#31454;&#20105;&#32773;&#22312;&#23454;&#38469;&#39118;&#30701;&#26399;&#39044;&#27979;&#25361;&#25112;&#19978;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces two novel approaches for Online Multi-Task Learning (MTL) Regression Problems. We employ a high performance graph-based MTL formulation and develop its recursive versions based on the Weighted Recursive Least Squares (WRLS) and the Online Sparse Least Squares Support Vector Regression (OSLSSVR). Adopting task-stacking transformations, we demonstrate the existence of a single matrix incorporating the relationship of multiple tasks and providing structural information to be embodied by the MT-WRLS method in its initialization procedure and by the MT-OSLSSVR in its multi-task kernel function. Contrasting the existing literature, which is mostly based on Online Gradient Descent (OGD) or cubic inexact approaches, we achieve exact and approximate recursions with quadratic per-instance cost on the dimension of the input space (MT-WRLS) or on the size of the dictionary of instances (MT-OSLSSVR). We compare our online MTL methods to other contenders in a real-world wind sp
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#19987;&#23478;&#24314;&#35758;&#21644;&#22810;&#33218;&#36172;&#21338;&#26159;&#20004;&#20010;&#32463;&#20856;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#32773;&#20043;&#38388;&#30340;&#25554;&#20540;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;$\mathbf{m}$-MAB&#30340;&#26497;&#23567;&#21518;&#24724;&#30028;&#24182;&#35774;&#35745;&#20102;$\mathbf{m}$-BAI&#30340;&#26368;&#20248;PAC&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26088;&#22312;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#36718;&#25968;&#30830;&#23450;&#25439;&#22833;&#26368;&#23567;&#30340;&#33218;&#12290;</title><link>http://arxiv.org/abs/2307.07264</link><description>&lt;p&gt;
&#20851;&#20110;&#25554;&#20540;&#19987;&#23478;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07264
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19987;&#23478;&#24314;&#35758;&#21644;&#22810;&#33218;&#36172;&#21338;&#26159;&#20004;&#20010;&#32463;&#20856;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#32773;&#20043;&#38388;&#30340;&#25554;&#20540;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;$\mathbf{m}$-MAB&#30340;&#26497;&#23567;&#21518;&#24724;&#30028;&#24182;&#35774;&#35745;&#20102;$\mathbf{m}$-BAI&#30340;&#26368;&#20248;PAC&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26088;&#22312;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#36718;&#25968;&#30830;&#23450;&#25439;&#22833;&#26368;&#23567;&#30340;&#33218;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19987;&#23478;&#24314;&#35758;&#21644;&#22810;&#33218;&#36172;&#21338;&#26159;&#20004;&#20010;&#32463;&#20856;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#65292;&#23427;&#20204;&#22312;&#27599;&#19968;&#36718;&#35266;&#23519;&#20449;&#24687;&#30340;&#26041;&#24335;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20004;&#32773;&#20043;&#38388;&#30340;&#25554;&#20540;&#38382;&#39064;&#12290;&#23545;&#20110;&#21521;&#37327;$\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$&#65292;$\mathbf{m}$-MAB&#30340;&#19968;&#20010;&#23454;&#20363;&#34920;&#31034;&#23558;&#33218;&#20998;&#25104;$K$&#32452;&#65292;&#31532;$i$&#32452;&#21253;&#21547;$m_i$&#20010;&#33218;&#12290;&#19968;&#26086;&#25289;&#21160;&#19968;&#20010;&#33218;&#65292;&#21516;&#19968;&#32452;&#20013;&#25152;&#26377;&#33218;&#30340;&#25439;&#22833;&#37117;&#34987;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$\mathbf{m}$-MAB&#30340;&#32039;&#33268;&#26497;&#23567;&#21518;&#24724;&#30028;&#65292;&#24182;&#20026;&#20854;&#32431;&#25506;&#32034;&#29256;&#26412;$\mathbf{m}$-BAI&#35774;&#35745;&#20102;&#19968;&#20010;&#26368;&#20248;&#30340;PAC&#31639;&#27861;&#65292;&#20854;&#20013;&#30446;&#26631;&#26159;&#29992;&#23613;&#21487;&#33021;&#23569;&#30340;&#36718;&#25968;&#26469;&#35782;&#21035;&#25439;&#22833;&#26368;&#23567;&#30340;&#33218;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$\mathbf{m}$-MAB&#30340;&#26497;&#23567;&#21518;&#24724;&#26159;$\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$&#65292;&#23545;&#20110;&#19968;&#20010;$(\epsilon,0.05)$-PAC&#31639;&#27861;&#30340;$\mathbf{m}$-BAI&#65292;&#25289;&#21160;&#33218;&#30340;&#26368;&#23567;&#27425;&#25968;&#26159;$\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning with expert advice and multi-armed bandit are two classic online decision problems which differ on how the information is observed in each round of the game. We study a family of problems interpolating the two. For a vector $\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$, an instance of $\mathbf{m}$-MAB indicates that the arms are partitioned into $K$ groups and the $i$-th group contains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same group are observed. We prove tight minimax regret bounds for $\mathbf{m}$-MAB and design an optimal PAC algorithm for its pure exploration version, $\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with as few rounds as possible. We show that the minimax regret of $\mathbf{m}$-MAB is $\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$ and the minimum number of pulls for an $(\epsilon,0.05)$-PAC algorithm of $\mathbf{m}$-BAI is $\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$. Bot
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#65292;&#22312;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#35299;&#20915;&#20102;&#21407;&#22987;&#26041;&#27861;&#20013;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.00048</link><description>&lt;p&gt;
&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Learned harmonic mean estimation of the marginal likelihood with normalizing flows. (arXiv:2307.00048v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#65292;&#22312;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#35299;&#20915;&#20102;&#21407;&#22987;&#26041;&#27861;&#20013;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#36793;&#32536;&#20284;&#28982;&#65288;&#20063;&#31216;&#20026;&#36125;&#21494;&#26031;&#27169;&#22411;&#35777;&#25454;&#65289;&#26159;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#19968;&#39033;&#37325;&#35201;&#20219;&#21153;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21407;&#21017;&#30340;&#23450;&#37327;&#27604;&#36739;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#23398;&#20064;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#22120;&#35299;&#20915;&#20102;&#21407;&#22987;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#36793;&#32536;&#20284;&#28982;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;&#23398;&#20064;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#22120;&#23398;&#20064;&#20102;&#19968;&#20010;&#37325;&#35201;&#24615;&#37319;&#26679;&#30446;&#26631;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#36817;&#20284;&#20110;&#26368;&#20248;&#20998;&#24067;&#12290;&#34429;&#28982;&#36817;&#20284;&#19981;&#24517;&#38750;&#24120;&#20934;&#30830;&#65292;&#20294;&#30830;&#20445;&#23398;&#20064;&#20998;&#24067;&#30340;&#27010;&#29575;&#36136;&#37327;&#21253;&#21547;&#22312;&#21518;&#39564;&#20998;&#24067;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20197;&#36991;&#20813;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20026;&#20102;&#30830;&#20445;&#28385;&#36275;&#36825;&#20010;&#24615;&#36136;&#65292;&#22312;&#35757;&#32451;&#27169;&#22411;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#19987;&#38376;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#26469;&#34920;&#31034;&#37325;&#35201;&#24615;&#37319;&#26679;&#30446;&#26631;&#20998;&#24067;&#12290;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#20174;&#21518;&#39564;&#26679;&#26412;&#20013;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing the marginal likelihood (also called the Bayesian model evidence) is an important task in Bayesian model selection, providing a principled quantitative way to compare models. The learned harmonic mean estimator solves the exploding variance problem of the original harmonic mean estimation of the marginal likelihood. The learned harmonic mean estimator learns an importance sampling target distribution that approximates the optimal distribution. While the approximation need not be highly accurate, it is critical that the probability mass of the learned distribution is contained within the posterior in order to avoid the exploding variance problem. In previous work a bespoke optimization problem is introduced when training models in order to ensure this property is satisfied. In the current article we introduce the use of normalizing flows to represent the importance sampling target distribution. A flow-based model is trained on samples from the posterior by maximum likelihood e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#23545;&#23725;&#30340;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20854;&#21487;&#20197;&#25913;&#36827;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#20197;&#21450;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05722</link><description>&lt;p&gt;
&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#20272;&#35745;&#23725;
&lt;/p&gt;
&lt;p&gt;
Estimation of Ridge Using Nonlinear Transformation on Density Function. (arXiv:2306.05722v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#23545;&#23725;&#30340;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20854;&#21487;&#20197;&#25913;&#36827;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#20197;&#21450;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23725;&#22312;&#20934;&#30830;&#36817;&#20284;&#27969;&#24418;&#30340;&#22522;&#30784;&#32467;&#26500;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#20985;&#38750;&#32447;&#24615;&#21464;&#25442;&#24212;&#29992;&#20110;&#23494;&#24230;&#20989;&#25968;&#20197;&#25506;&#32034;&#23725;&#30340;&#21464;&#21270;&#12290;&#36890;&#36807;&#23545;Hessian&#30697;&#38453;&#30340;&#25512;&#23548;&#21644;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#38750;&#32447;&#24615;&#21464;&#25442;&#20135;&#29983;&#20102;Hessian&#30697;&#38453;&#30340;&#31209;&#19968;&#20462;&#25913;&#12290;&#21033;&#29992;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#21464;&#20998;&#24615;&#36136;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30456;&#24212;&#23725;&#20043;&#38388;&#30340;&#20559;&#24207;&#21253;&#21547;&#20851;&#31995;&#12290;&#25105;&#20204;&#30452;&#35266;&#22320;&#21457;&#29616;&#65292;&#36890;&#36807;Hessian&#30697;&#38453;&#30340;&#31209;&#19968;&#20462;&#25913;&#65292;&#21464;&#25442;&#21487;&#20197;&#23548;&#33268;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#25913;&#36827;&#12290;&#20026;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#25968;&#20540;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#19982;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#21464;&#25442;&#26041;&#27861;&#24471;&#21040;&#30340;&#23725;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#26356;&#21152;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ridges play a vital role in accurately approximating the underlying structure of manifolds. In this paper, we explore the ridge's variation by applying a concave nonlinear transformation to the density function. Through the derivation of the Hessian matrix, we observe that nonlinear transformations yield a rank-one modification of the Hessian matrix. Leveraging the variational properties of eigenvalue problems, we establish a partial order inclusion relationship among the corresponding ridges. We intuitively discover that the transformation can lead to improved estimation of the tangent space via rank-one modification of the Hessian matrix. To validate our theories, we conduct extensive numerical experiments on synthetic and real-world datasets that demonstrate the superiority of the ridges obtained from our transformed approach in approximating the underlying truth manifold compared to other manifold fitting algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#27979;&#37327;&#22122;&#22768;&#30340;Ornstein-Uhlenbeck&#36807;&#31243;&#21442;&#25968;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#31639;&#27861;&#21644;&#26041;&#27861;&#33021;&#22815;&#20998;&#31163;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#25913;&#21892;&#25968;&#25454;&#20998;&#26512;&#30340;&#21442;&#25968;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.13498</link><description>&lt;p&gt;
&#29992;&#20110;&#24102;&#27979;&#37327;&#22122;&#22768;&#30340;Ornstein-Uhlenbeck&#36807;&#31243;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise. (arXiv:2305.13498v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#27979;&#37327;&#22122;&#22768;&#30340;Ornstein-Uhlenbeck&#36807;&#31243;&#21442;&#25968;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#31639;&#27861;&#21644;&#26041;&#27861;&#33021;&#22815;&#20998;&#31163;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#25913;&#21892;&#25968;&#25454;&#20998;&#26512;&#30340;&#21442;&#25968;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#22122;&#22768;&#23545;Ornstein-Uhlenbeck&#36807;&#31243;&#21442;&#25968;&#25311;&#21512;&#30340;&#24433;&#21709;&#65292;&#37325;&#28857;&#32771;&#23519;&#20102;&#20056;&#24615;&#22122;&#22768;&#21644;&#28909;&#22122;&#22768;&#23545;&#20449;&#21495;&#20998;&#31163;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26377;&#25928;&#21306;&#20998;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#12289;&#25913;&#21892;&#21442;&#25968;&#20272;&#35745;&#31934;&#24230;&#30340;&#31639;&#27861;&#21644;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20056;&#24615;&#21644;&#28909;&#22122;&#22768;&#23545;&#23454;&#38469;&#20449;&#21495;&#28151;&#28102;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#20998;&#31163;&#28909;&#22122;&#22768;&#30340;&#31639;&#27861;&#65292;&#20854;&#24615;&#33021;&#21487;&#19982;Hamilton Monte Carlo (HMC)&#30456;&#23218;&#32654;&#65292;&#20294;&#36895;&#24230;&#26174;&#33879;&#25552;&#39640;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#35777;&#26126;&#20102;HMC&#26080;&#27861;&#38548;&#31163;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#22312;&#39069;&#22806;&#20102;&#35299;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#20043;&#38388;&#27604;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#31934;&#30830;&#22320;&#20272;&#35745;&#21442;&#25968;&#21644;&#20998;&#31163;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article aims to investigate the impact of noise on parameter fitting for an Ornstein-Uhlenbeck process, focusing on the effects of multiplicative and thermal noise on the accuracy of signal separation. To address these issues, we propose algorithms and methods that can effectively distinguish between thermal and multiplicative noise and improve the precision of parameter estimation for optimal data analysis. Specifically, we explore the impact of both multiplicative and thermal noise on the obfuscation of the actual signal and propose methods to resolve them. Firstly, we present an algorithm that can effectively separate thermal noise with comparable performance to Hamilton Monte Carlo (HMC) but with significantly improved speed. Subsequently, we analyze multiplicative noise and demonstrate that HMC is insufficient for isolating thermal and multiplicative noise. However, we show that, with additional knowledge of the ratio between thermal and multiplicative noise, we can accuratel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#19978;&#19979;&#25991;&#35843;&#33410;&#23454;&#29616;&#36890;&#29992;&#24418;&#24577;&#25511;&#21046;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#20351;&#29992;&#36229;&#32593;&#32476;&#29983;&#25104;&#24418;&#24577;&#30456;&#20851;&#30340;&#25511;&#21046;&#21442;&#25968;&#20197;&#21450;&#21033;&#29992;&#22266;&#23450;&#30340;&#27880;&#24847;&#26426;&#21046;&#35843;&#33410;&#26426;&#22120;&#20154;&#20013;&#19981;&#21516;&#32930;&#20307;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#23398;&#20064;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2302.11070</link><description>&lt;p&gt;
&#36890;&#36807;&#19978;&#19979;&#25991;&#35843;&#25511;&#23454;&#29616;&#36890;&#29992;&#24418;&#24577;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Universal Morphology Control via Contextual Modulation. (arXiv:2302.11070v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#19978;&#19979;&#25991;&#35843;&#33410;&#23454;&#29616;&#36890;&#29992;&#24418;&#24577;&#25511;&#21046;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#20351;&#29992;&#36229;&#32593;&#32476;&#29983;&#25104;&#24418;&#24577;&#30456;&#20851;&#30340;&#25511;&#21046;&#21442;&#25968;&#20197;&#21450;&#21033;&#29992;&#22266;&#23450;&#30340;&#27880;&#24847;&#26426;&#21046;&#35843;&#33410;&#26426;&#22120;&#20154;&#20013;&#19981;&#21516;&#32930;&#20307;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#23398;&#20064;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#25511;&#21046;&#20013;&#65292;&#23398;&#20064;&#19968;&#31181;&#36866;&#29992;&#20110;&#19981;&#21516;&#26426;&#22120;&#20154;&#24418;&#24577;&#30340;&#36890;&#29992;&#31574;&#30053;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#23398;&#20064;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20250;&#24102;&#26469;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#22240;&#20026;&#26368;&#20248;&#31574;&#30053;&#21487;&#33021;&#22312;&#19981;&#21516;&#26426;&#22120;&#20154;&#20043;&#38388;&#26377;&#24456;&#22823;&#24046;&#24322;&#65292;&#24182;&#19988;&#20005;&#37325;&#20381;&#36182;&#20110;&#24418;&#24577;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25110;transformers&#26469;&#22788;&#29702;&#19981;&#21516;&#24418;&#24577;&#20043;&#38388;&#30340;&#24322;&#26500;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#65292;&#20294;&#23545;&#26426;&#22120;&#20154;&#30340;&#25511;&#21046;&#31574;&#30053;&#19982;&#24418;&#24577;&#19978;&#19979;&#25991;&#30340;&#20381;&#36182;&#24615;&#20851;&#27880;&#36739;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#26550;&#26500;&#65292;&#36890;&#36807;&#19978;&#19979;&#25991;&#35843;&#33410;&#26356;&#22909;&#22320;&#24314;&#27169;&#36825;&#31181;&#20381;&#36182;&#20851;&#31995;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#20851;&#38190;&#23376;&#27169;&#22359;&#65306;&#65288;1&#65289;&#25105;&#20204;&#20351;&#29992;&#36229;&#32593;&#32476;&#29983;&#25104;&#24418;&#24577;&#30456;&#20851;&#30340;&#25511;&#21046;&#21442;&#25968;&#65292;&#32780;&#19981;&#26159;&#23545;&#26426;&#22120;&#20154;&#20043;&#38388;&#24378;&#21046;&#36827;&#34892;&#30828;&#21442;&#25968;&#20849;&#20139;&#65307;&#65288;2&#65289;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22266;&#23450;&#30340;&#27880;&#24847;&#26426;&#21046;&#65292;&#20165;&#20381;&#36182;&#20110;&#24418;&#24577;&#65292;&#26469;&#35843;&#33410;&#26426;&#22120;&#20154;&#20013;&#19981;&#21516;&#32930;&#20307;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning a universal policy across different robot morphologies can significantly improve learning efficiency and generalization in continuous control. However, it poses a challenging multi-task reinforcement learning problem, as the optimal policy may be quite different across robots and critically depend on the morphology. Existing methods utilize graph neural networks or transformers to handle heterogeneous state and action spaces across different morphologies, but pay little attention to the dependency of a robot's control policy on its morphology context. In this paper, we propose a hierarchical architecture to better model this dependency via contextual modulation, which includes two key submodules: (1) Instead of enforcing hard parameter sharing across robots, we use hypernetworks to generate morphology-dependent control parameters; (2) We propose a fixed attention mechanism that solely depends on the morphology to modulate the interactions between different limbs in a robot. Ex
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#25552;&#20379;&#20102;&#20803;&#23398;&#20064;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#26368;&#20339;&#24615;&#33021;&#20445;&#35777;&#30340;&#38381;&#24335;&#20248;&#21270;&#36229;&#21518;&#39564;(PACOH)&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20445;&#35777;&#22312;&#20803;&#23398;&#20064;&#20013;&#30456;&#23545;&#20110;PAC-Bayesian&#27599;&#20010;&#20219;&#21153;&#23398;&#20064;&#30028;&#38480;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2211.07206</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;PAC-Bayesian&#20803;&#23398;&#20064;&#65306;&#20174;&#29702;&#35770;&#21040;&#23454;&#36341;&#30340;PAC-Optimal&#36229;&#21518;&#39564;
&lt;/p&gt;
&lt;p&gt;
Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior: From Theory to Practice. (arXiv:2211.07206v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07206
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#25552;&#20379;&#20102;&#20803;&#23398;&#20064;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#26368;&#20339;&#24615;&#33021;&#20445;&#35777;&#30340;&#38381;&#24335;&#20248;&#21270;&#36229;&#21518;&#39564;(PACOH)&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20445;&#35777;&#22312;&#20803;&#23398;&#20064;&#20013;&#30456;&#23545;&#20110;PAC-Bayesian&#27599;&#20010;&#20219;&#21153;&#23398;&#20064;&#30028;&#38480;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20803;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#20174;&#30456;&#20851;&#23398;&#20064;&#20219;&#21153;&#30340;&#25968;&#25454;&#38598;&#20013;&#33719;&#21462;&#26377;&#29992;&#30340;&#24402;&#32435;&#20559;&#22909;&#65292;&#21152;&#36895;&#23545;&#26032;&#20219;&#21153;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#21487;&#29992;&#30340;&#30456;&#20851;&#20219;&#21153;&#25968;&#37327;&#36890;&#24120;&#24456;&#23567;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20551;&#35774;&#20219;&#21153;&#25968;&#37327;&#20016;&#23500;&#65292;&#20351;&#23427;&#20204;&#19981;&#20999;&#23454;&#38469;&#19988;&#23481;&#26131;&#36807;&#25311;&#21512;&#12290;&#20803;&#23398;&#20064;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#22914;&#20309;&#36827;&#34892;&#27491;&#21017;&#21270;&#20197;&#30830;&#20445;&#23545;&#26410;&#35265;&#20219;&#21153;&#30340;&#27867;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#20803;&#23398;&#20064;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#26159;&#30001;Rothfuss&#31561;&#20154;&#65288;2021&#65289;&#39318;&#27425;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#20851;&#38190;&#26159;&#65292;&#35813;&#30028;&#38480;&#20351;&#25105;&#20204;&#33021;&#22815;&#24471;&#21040;&#26368;&#20339;&#24615;&#33021;&#20445;&#35777;&#30340;&#38381;&#24335;&#20248;&#21270;&#36229;&#21518;&#39564;&#65292;&#31216;&#20026;PACOH&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#26696;&#20363;&#30740;&#31350;&#65292;&#22312;&#21738;&#20123;&#26465;&#20214;&#19979;&#20197;&#21450;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#36825;&#20123;&#20803;&#23398;&#20064;&#30340;&#20445;&#35777;&#25913;&#36827;&#20102;PAC-Bayesian&#27599;&#20010;&#20219;&#21153;&#23398;&#20064;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning aims to speed up the learning process on new tasks by acquiring useful inductive biases from datasets of related learning tasks. While, in practice, the number of related tasks available is often small, most of the existing approaches assume an abundance of tasks; making them unrealistic and prone to overfitting. A central question in the meta-learning literature is how to regularize to ensure generalization to unseen tasks. In this work, we provide a theoretical analysis using the PAC-Bayesian theory and present a generalization bound for meta-learning, which was first derived by Rothfuss et al. (2021). Crucially, the bound allows us to derive the closed form of the optimal hyper-posterior, referred to as PACOH, which leads to the best performance guarantees. We provide a theoretical analysis and empirical case study under which conditions and to what extent these guarantees for meta-learning improve upon PAC-Bayesian per-task learning bounds. The closed-form PACOH inspi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#26088;&#22312;&#35299;&#20915;&#22269;&#38469;&#31354;&#38388;&#31449;&#19978;&#39063;&#31890;&#29289;&#23545;&#20202;&#22120;&#30340;&#21361;&#23475;&#38382;&#39064;&#65292;&#36890;&#36807;Bi-GRU&#31639;&#27861;&#26500;&#24314;&#26089;&#26399;&#39044;&#35686;&#31995;&#32479;&#65292;&#39044;&#27979;&#39063;&#31890;&#29289;&#27700;&#24179;&#65292;&#24182;&#20026;&#23431;&#33322;&#21592;&#25552;&#20379;&#20805;&#36275;&#30340;&#21453;&#24212;&#26102;&#38388;&#12290;&#36825;&#39033;&#30740;&#31350;&#36824;&#26377;&#28508;&#21147;&#21457;&#23637;&#20026;&#19982;&#28779;&#28798;&#30456;&#20851;&#30340;&#36965;&#24863;&#28895;&#38654;&#25253;&#35686;&#35013;&#32622;&#12290;</title><link>http://arxiv.org/abs/2210.08549</link><description>&lt;p&gt;
&#22269;&#38469;&#31354;&#38388;&#31449;&#33258;&#21160;&#32039;&#24613;&#26080;&#23576;&#35299;&#20915;&#26041;&#26696;: &#24102;&#26377;Bi-GRU&#30340;(AED-ISS)
&lt;/p&gt;
&lt;p&gt;
Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.08549
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#26088;&#22312;&#35299;&#20915;&#22269;&#38469;&#31354;&#38388;&#31449;&#19978;&#39063;&#31890;&#29289;&#23545;&#20202;&#22120;&#30340;&#21361;&#23475;&#38382;&#39064;&#65292;&#36890;&#36807;Bi-GRU&#31639;&#27861;&#26500;&#24314;&#26089;&#26399;&#39044;&#35686;&#31995;&#32479;&#65292;&#39044;&#27979;&#39063;&#31890;&#29289;&#27700;&#24179;&#65292;&#24182;&#20026;&#23431;&#33322;&#21592;&#25552;&#20379;&#20805;&#36275;&#30340;&#21453;&#24212;&#26102;&#38388;&#12290;&#36825;&#39033;&#30740;&#31350;&#36824;&#26377;&#28508;&#21147;&#21457;&#23637;&#20026;&#19982;&#28779;&#28798;&#30456;&#20851;&#30340;&#36965;&#24863;&#28895;&#38654;&#25253;&#35686;&#35013;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;PM2.5&#25110;PM0.3&#38382;&#39064;&#30340;&#20851;&#27880;&#19981;&#26029;&#22686;&#21152;&#65292;&#39063;&#31890;&#29289;&#19981;&#20165;&#23545;&#29615;&#22659;&#21644;&#20154;&#31867;&#26500;&#25104;&#28508;&#22312;&#23041;&#32961;&#65292;&#32780;&#19988;&#23545;&#22269;&#38469;&#31354;&#38388;&#31449;&#19978;&#30340;&#20202;&#22120;&#20063;&#20250;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#26412;&#30740;&#31350;&#22242;&#38431;&#26088;&#22312;&#23558;&#21508;&#31181;&#39063;&#31890;&#29289;&#27987;&#24230;&#19982;&#30913;&#22330;&#12289;&#28287;&#24230;&#12289;&#21152;&#36895;&#24230;&#12289;&#28201;&#24230;&#12289;&#21387;&#21147;&#21644;CO2&#27987;&#24230;&#20851;&#32852;&#36215;&#26469;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24314;&#31435;&#19968;&#20010;&#26089;&#26399;&#39044;&#35686;&#31995;&#32479;(EWS)&#65292;&#33021;&#22815;&#39044;&#27979;&#39063;&#31890;&#29289;&#27700;&#24179;&#65292;&#24182;&#20026;&#23431;&#33322;&#21592;&#25552;&#20379;&#20805;&#36275;&#30340;&#21453;&#24212;&#26102;&#38388;&#65292;&#20197;&#20445;&#25252;&#20182;&#20204;&#22312;&#26576;&#20123;&#23454;&#39564;&#20013;&#30340;&#20202;&#22120;&#65292;&#25110;&#32773;&#25552;&#39640;&#27979;&#37327;&#30340;&#20934;&#30830;&#24615;&#65307;&#27492;&#22806;&#65292;&#25152;&#26500;&#24314;&#30340;&#27169;&#22411;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#21457;&#23637;&#20026;&#19982;&#28779;&#28798;&#30456;&#20851;&#30340;&#36965;&#24863;&#28895;&#38654;&#25253;&#35686;&#35013;&#32622;&#30340;&#21407;&#22411;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#23454;&#29616;Bi-GRU(&#21452;&#21521;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;)&#31639;&#27861;&#65292;&#25910;&#38598;&#36807;&#21435;90&#20998;&#38047;&#30340;&#25968;&#25454;&#65292;&#24182;&#39044;&#27979;&#36229;&#36807;2.5&#24494;&#31859;&#30340;&#39063;&#31890;&#29289;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
With a rising attention for the issue of PM2.5 or PM0.3, particulate matters have become not only a potential threat to both the environment and human, but also a harming existence to instruments onboard International Space Station (ISS). Our team is aiming to relate various concentration of particulate matters to magnetic fields, humidity, acceleration, temperature, pressure and CO2 concentration. Our goal is to establish an early warning system (EWS), which is able to forecast the levels of particulate matters and provides ample reaction time for astronauts to protect their instruments in some experiments or increase the accuracy of the measurements; In addition, the constructed model can be further developed into a prototype of a remote-sensing smoke alarm for applications related to fires. In this article, we will implement the Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for past 90 minutes and predict the levels of particulates which over 2.5 micromete
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#38750;&#38646;&#26799;&#24230;&#30340;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#34892;&#20026;&#65292;&#24182;&#35777;&#26126;&#20102;&#25351;&#25968;&#32423;&#30340;&#38598;&#20013;&#24615;&#30028;&#38480;&#65292;&#36825;&#23545;&#20110;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2208.07243</link><description>&lt;p&gt;
&#38750;&#38646;&#26799;&#24230;&#30340;&#38543;&#26426;&#36924;&#36817;&#30340;&#25351;&#25968;&#38598;&#20013;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Exponential Concentration of Stochastic Approximation with Non-vanishing Gradient. (arXiv:2208.07243v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.07243
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#38750;&#38646;&#26799;&#24230;&#30340;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#34892;&#20026;&#65292;&#24182;&#35777;&#26126;&#20102;&#25351;&#25968;&#32423;&#30340;&#38598;&#20013;&#24615;&#30028;&#38480;&#65292;&#36825;&#23545;&#20110;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#34892;&#20026;&#65292;&#20854;&#20013;&#27599;&#19968;&#27493;&#36845;&#20195;&#65292;&#26399;&#26395;&#20013;&#21521;&#30446;&#26631;&#21462;&#24471;&#36827;&#23637;&#12290;&#24403;&#36827;&#23637;&#19982;&#31639;&#27861;&#30340;&#27493;&#38271;&#25104;&#27604;&#20363;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25351;&#25968;&#32423;&#30340;&#38598;&#20013;&#24615;&#30028;&#38480;&#12290;&#36825;&#20123;&#23614;&#37096;&#30028;&#38480;&#19982;&#26356;&#24120;&#35265;&#30340;&#38543;&#26426;&#36924;&#36817;&#30340;&#28176;&#36817;&#27491;&#24577;&#32467;&#26524;&#24418;&#25104;&#23545;&#27604;&#12290;&#25105;&#20204;&#24320;&#21457;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#20960;&#20309;&#38459;&#23612;&#24615;&#35777;&#26126;&#12290;&#36825;&#25193;&#23637;&#20102;Hajek&#65288;1982&#65289;&#23545;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#32467;&#26524;&#21040;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#39046;&#22495;&#12290;&#23545;&#20110;&#20855;&#26377;&#38750;&#38646;&#26799;&#24230;&#30340;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#21487;&#20197;&#29992;&#26469;&#35777;&#26126;$O(1/t)$&#21644;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the behavior of stochastic approximation algorithms where iterates, in expectation, make progress towards an objective at each step. When progress is proportional to the step size of the algorithm, we prove exponential concentration bounds. These tail-bounds contrast asymptotic normality results which are more frequently associated with stochastic approximation. The methods that we develop rely on a geometric ergodicity proof. This extends a result on Markov chains due to Hajek (1982) to the area of stochastic approximation algorithms. For Projected Stochastic Gradient Descent with a non-vanishing gradient, our results can be used to prove $O(1/t)$ and linear convergence rates.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25512;&#29702;&#30340;&#37327;&#23376;&#24863;&#30693;&#26041;&#26696;&#65292;&#21487;&#20197;&#36890;&#36807;&#27979;&#37327;&#31995;&#32479;&#21709;&#24212;&#26469;&#25512;&#26029;&#26410;&#30693;&#21442;&#25968;&#30340;&#20540;&#65292;&#24182;&#30830;&#23450;&#26041;&#26696;&#30340;&#25935;&#24863;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.09919</link><description>&lt;p&gt;
&#25512;&#29702;&#20026;&#22522;&#30784;&#30340;&#37327;&#23376;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Inference-Based Quantum Sensing. (arXiv:2206.09919v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.09919
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25512;&#29702;&#30340;&#37327;&#23376;&#24863;&#30693;&#26041;&#26696;&#65292;&#21487;&#20197;&#36890;&#36807;&#27979;&#37327;&#31995;&#32479;&#21709;&#24212;&#26469;&#25512;&#26029;&#26410;&#30693;&#21442;&#25968;&#30340;&#20540;&#65292;&#24182;&#30830;&#23450;&#26041;&#26696;&#30340;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26631;&#20934;&#30340;&#37327;&#23376;&#24863;&#30693;&#20219;&#21153;&#20013;&#65292;&#36890;&#36807;&#23545;&#31995;&#32479;&#30340;&#27979;&#37327;&#65292;&#30446;&#26631;&#26159;&#20272;&#35745;&#19968;&#20010;&#26410;&#30693;&#30340;&#21442;&#25968;&#952;&#65292;&#23558;&#20854;&#32534;&#30721;&#21040;&#19968;&#20010;n&#27604;&#29305;&#30340;&#25506;&#38024;&#24577;&#20013;&#12290;&#36825;&#20010;&#20219;&#21153;&#30340;&#25104;&#21151;&#21462;&#20915;&#20110;&#23558;&#21442;&#25968;&#30340;&#21464;&#21270;&#19982;&#31995;&#32479;&#21709;&#24212;&#929;&#65288;&#952;&#65289;&#30340;&#21464;&#21270;&#65288;&#21363;&#27979;&#37327;&#32467;&#26524;&#30340;&#21464;&#21270;&#65289;&#30456;&#20851;&#32852;&#30340;&#33021;&#21147;&#12290;&#23545;&#20110;&#31616;&#21333;&#24773;&#20917;&#65292;&#929;&#65288;&#952;&#65289;&#30340;&#24418;&#24335;&#26159;&#24050;&#30693;&#30340;&#65292;&#20294;&#23545;&#20110;&#29616;&#23454;&#22330;&#26223;&#26469;&#35828;&#65292;&#19968;&#33324;&#19981;&#23384;&#22312;&#38381;&#21512;&#24418;&#24335;&#30340;&#34920;&#36798;&#24335;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25512;&#29702;&#30340;&#37327;&#23376;&#24863;&#30693;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#19968;&#31867;&#24120;&#35268;&#30340;&#32534;&#30721;&#30340;&#37193;&#26063;&#31995;&#21015;&#65292;&#21482;&#38656;&#22312;2n+1&#20010;&#21442;&#25968;&#22788;&#27979;&#37327;&#31995;&#32479;&#21709;&#24212;&#65292;&#23601;&#21487;&#20197;&#23436;&#20840;&#34920;&#24449;&#929;&#65288;&#952;&#65289;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#27979;&#37327;&#30340;&#21709;&#24212;&#25512;&#26029;&#26410;&#30693;&#21442;&#25968;&#30340;&#20540;&#65292;&#20197;&#21450;&#30830;&#23450;&#35813;&#26041;&#26696;&#30340;&#25935;&#24863;&#24615;&#65292;&#20174;&#32780;&#34920;&#24449;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25512;&#29702;&#35823;&#24046;&#22312;&#39640;&#27010;&#29575;&#19979;&#23567;&#20110;...
&lt;/p&gt;
&lt;p&gt;
In a standard Quantum Sensing (QS) task one aims at estimating an unknown parameter $\theta$, encoded into an $n$-qubit probe state, via measurements of the system. The success of this task hinges on the ability to correlate changes in the parameter to changes in the system response $\mathcal{R}(\theta)$ (i.e., changes in the measurement outcomes). For simple cases the form of $\mathcal{R}(\theta)$ is known, but the same cannot be said for realistic scenarios, as no general closed-form expression exists. In this work we present an inference-based scheme for QS. We show that, for a general class of unitary families of encoding, $\mathcal{R}(\theta)$ can be fully characterized by only measuring the system response at $2n+1$ parameters. This allows us to infer the value of an unknown parameter given the measured response, as well as to determine the sensitivity of the scheme, which characterizes its overall performance. We show that inference error is, with high probability, smaller than 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#36951;&#25022;&#20998;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#39304;&#22270;&#21010;&#20998;&#30340;&#26032;&#31639;&#27861;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#32479;&#19968;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#23398;&#20064;&#19982;&#19987;&#23478;&#24314;&#35758;&#30340;&#26368;&#20248;&#31639;&#27861;&#65292;&#23545;&#21253;&#25324;&#35768;&#22810;&#22270;&#31867;&#26063;&#22312;&#20869;&#30340;&#33539;&#22260;&#26356;&#24191;&#30340;&#22270;&#23478;&#26063;&#24471;&#21040;&#20102;&#25913;&#36827;&#21644;&#26368;&#20248;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2205.15076</link><description>&lt;p&gt;
&#36890;&#36807;&#36951;&#25022;&#20998;&#35299;&#25913;&#36827;&#20102;&#24102;&#26377;&#22270;&#21453;&#39304;&#30340;&#36172;&#21338;&#26426;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improved Algorithms for Bandit with Graph Feedback via Regret Decomposition. (arXiv:2205.15076v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.15076
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36951;&#25022;&#20998;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#39304;&#22270;&#21010;&#20998;&#30340;&#26032;&#31639;&#27861;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#32479;&#19968;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#23398;&#20064;&#19982;&#19987;&#23478;&#24314;&#35758;&#30340;&#26368;&#20248;&#31639;&#27861;&#65292;&#23545;&#21253;&#25324;&#35768;&#22810;&#22270;&#31867;&#26063;&#22312;&#20869;&#30340;&#33539;&#22260;&#26356;&#24191;&#30340;&#22270;&#23478;&#26063;&#24471;&#21040;&#20102;&#25913;&#36827;&#21644;&#26368;&#20248;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#22270;&#21453;&#39304;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#36890;&#36807;&#22312;&#26377;&#21521;&#22270;&#20013;&#32534;&#30721;&#25439;&#22833;&#21521;&#37327;&#22312;&#27599;&#36718;&#28216;&#25103;&#20013;&#30340;&#35266;&#27979;&#26041;&#24335;&#65292;&#23558;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#21644;&#23398;&#20064;&#19982;&#19987;&#23478;&#24314;&#35758;&#38382;&#39064;&#36827;&#34892;&#20102;&#25512;&#24191;&#12290;&#26368;&#23567;&#26368;&#22823;&#36951;&#25022;&#19982;&#21453;&#39304;&#22270;&#30340;&#32467;&#26500;&#23494;&#20999;&#30456;&#20851;&#65292;&#20294;&#20108;&#32773;&#30340;&#20851;&#31995;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#39304;&#22270;&#21010;&#20998;&#30340;&#26032;&#31639;&#27861;&#26694;&#26550;&#12290;&#36890;&#36807;&#23558;&#36951;&#25022;&#20998;&#35299;&#20026;&#30001;&#23567;&#37096;&#20998;&#21644;&#23427;&#20204;&#20043;&#38388;&#30456;&#20114;&#20316;&#29992;&#24341;&#36215;&#30340;&#36951;&#25022;&#20043;&#21644;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#22270;&#30340;&#21508;&#20010;&#37096;&#20998;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#23398;&#20064;&#19982;&#19987;&#23478;&#24314;&#35758;&#30340;&#26368;&#20248;&#31639;&#27861;&#30340;&#25554;&#20540;&#21644;&#25512;&#24191;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#32479;&#19968;&#20102;&#20808;&#21069;&#38024;&#23545;&#24378;&#35266;&#27979;&#22270;&#21644;&#24369;&#35266;&#27979;&#22270;&#30340;&#31639;&#27861;&#65292;&#23545;&#21253;&#25324;&#35768;&#22810;&#22270;&#31867;&#26063;&#22312;&#20869;&#30340;&#33539;&#22260;&#26356;&#24191;&#30340;&#22270;&#23478;&#26063;&#24471;&#21040;&#20102;&#25913;&#36827;&#21644;&#26368;&#20248;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of bandit with graph feedback generalizes both the multi-armed bandit (MAB) problem and the learning with expert advice problem by encoding in a directed graph how the loss vector can be observed in each round of the game. The mini-max regret is closely related to the structure of the feedback graph and their connection is far from being fully understood. We propose a new algorithmic framework for the problem based on a partition of the feedback graph. Our analysis reveals the interplay between various parts of the graph by decomposing the regret to the sum of the regret caused by small parts and the regret caused by their interaction. As a result, our algorithm can be viewed as an interpolation and generalization of the optimal algorithms for MAB and learning with expert advice. Our framework unifies previous algorithms for both strongly observable graphs and weakly observable graphs, resulting in improved and optimal regret bounds on a wide range of graph families includi
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31561;&#24335;&#32422;&#26463;&#30340;&#38543;&#26426;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#33609;&#22270;&#30340;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#65288;StoSQP&#65289;&#36827;&#34892;&#27714;&#35299;&#65292;&#24182;&#19988;&#20801;&#35768;&#33258;&#36866;&#24212;&#36873;&#25321;&#38543;&#26426;&#27493;&#38271;&#21644;&#20351;&#29992;&#39640;&#25928;&#38543;&#26426;&#36845;&#20195;&#27714;&#35299;&#22120;&#26469;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2205.13687</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#33609;&#22270;&#30340;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#23545;&#32422;&#26463;&#30340;&#38543;&#26426;&#20248;&#21270;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming. (arXiv:2205.13687v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31561;&#24335;&#32422;&#26463;&#30340;&#38543;&#26426;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#33609;&#22270;&#30340;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#65288;StoSQP&#65289;&#36827;&#34892;&#27714;&#35299;&#65292;&#24182;&#19988;&#20801;&#35768;&#33258;&#36866;&#24212;&#36873;&#25321;&#38543;&#26426;&#27493;&#38271;&#21644;&#20351;&#29992;&#39640;&#25928;&#38543;&#26426;&#36845;&#20195;&#27714;&#35299;&#22120;&#26469;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23545;&#31561;&#24335;&#32422;&#26463;&#30340;&#38543;&#26426;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20840;&#22312;&#32447;&#38543;&#26426;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#65288;StoSQP&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#21487;&#20197;&#23558;&#20854;&#35270;&#20026;&#23558;&#29275;&#39039;&#27861;&#24212;&#29992;&#20110;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#65288;&#21363;KKT&#26465;&#20214;&#65289;&#12290;&#21463;&#26368;&#36817;&#25968;&#20540;&#20108;&#38454;&#26041;&#27861;&#35774;&#35745;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20801;&#35768;StoSQP&#33258;&#36866;&#24212;&#22320;&#36873;&#25321;&#20219;&#24847;&#38543;&#26426;&#27493;&#38271;$ \bar {\ alpha} _t $&#65292;&#21482;&#35201;$ \ beta _t \ leq \ bar {\ alpha} _t \ leq \ beta _t + \ chi _t $&#65292;&#20854;&#20013; $ \ beta_t $ &#21644; $ \ chi_t = o(\beta_t) $ &#26159;&#26576;&#20123;&#25511;&#21046;&#24207;&#21015;&#12290;&#20026;&#20102;&#38477;&#20302;&#20108;&#38454;&#26041;&#27861;&#30340;&#20027;&#35201;&#35745;&#31639;&#25104;&#26412;&#65292;&#25105;&#20204;&#36824;&#20801;&#35768;StoSQP&#36890;&#36807;&#20351;&#29992;&#33609;&#22270;&#25216;&#26415;&#30340;&#39640;&#25928;&#38543;&#26426;&#36845;&#20195;&#27714;&#35299;&#22120;&#26469;&#19981;&#31934;&#30830;&#22320;&#35299;&#20915;&#20108;&#27425;&#35268;&#21010;&#38382;&#39064;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#19981;&#35201;&#27714;&#36924;&#36817;&#35823;&#24046;&#38543;&#30528;&#36845;&#20195;&#30340;&#36827;&#34892;&#32780;&#20943;&#23567;&#12290;&#23545;&#20110;&#24320;&#21457;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#65288;i&#65289;&#19979;&#65292;&#23427;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#26368;&#22810;&#20026;$ O(1 / \ ep&#65289;$&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider statistical inference of equality-constrained stochastic nonlinear optimization problems. We develop a fully online stochastic sequential quadratic programming (StoSQP) method to solve the problems, which can be regarded as applying Newton's method to the first-order optimality conditions (i.e., the KKT conditions). Motivated by recent designs of numerical second-order methods, we allow StoSQP to adaptively select any random stepsize $\bar{\alpha}_t$, as long as $\beta_t\leq \bar{\alpha}_t \leq \beta_t+\chi_t$, for some control sequences $\beta_t$ and $\chi_t=o(\beta_t)$. To reduce the dominant computational cost of second-order methods, we additionally allow StoSQP to inexactly solve quadratic programs via efficient randomized iterative solvers that utilize sketching techniques. Notably, we do not require the approximation error to diminish as iteration proceeds. For the developed method, we show that under mild assumptions (i) computationally, it can take at most $O(1/\ep
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#27491;&#20132;&#26059;&#36716;&#26469;&#33719;&#24471;&#36817;&#20284;&#31232;&#30095;&#30340;&#29305;&#24449;&#20540;&#22522;&#12290;&#19982;&#20197;&#24448;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#31232;&#30095;&#25104;&#20998;&#19981;&#38656;&#35201;&#26159;&#20027;&#29305;&#24449;&#21521;&#37327;&#65292;&#32780;&#21487;&#20197;&#26159;&#23427;&#20204;&#30340;&#28151;&#21512;&#12290;&#36825;&#19968;&#26041;&#27861;&#19981;&#38656;&#35201;&#36827;&#34892;&#8220;&#32553;&#20943;&#8221;&#25805;&#20316;&#25110;&#20351;&#29992;&#22810;&#20010;&#35843;&#21442;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2007.00596</link><description>&lt;p&gt;
&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#26032;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
A New Basis for Sparse Principal Component Analysis. (arXiv:2007.00596v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.00596
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#27491;&#20132;&#26059;&#36716;&#26469;&#33719;&#24471;&#36817;&#20284;&#31232;&#30095;&#30340;&#29305;&#24449;&#20540;&#22522;&#12290;&#19982;&#20197;&#24448;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#31232;&#30095;&#25104;&#20998;&#19981;&#38656;&#35201;&#26159;&#20027;&#29305;&#24449;&#21521;&#37327;&#65292;&#32780;&#21487;&#20197;&#26159;&#23427;&#20204;&#30340;&#28151;&#21512;&#12290;&#36825;&#19968;&#26041;&#27861;&#19981;&#38656;&#35201;&#36827;&#34892;&#8220;&#32553;&#20943;&#8221;&#25805;&#20316;&#25110;&#20351;&#29992;&#22810;&#20010;&#35843;&#21442;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20043;&#21069;&#30340;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#20551;&#35774;&#29305;&#24449;&#20540;&#22522;&#65288;&#19968;&#20010;&#22823;&#23567;&#20026;$p \times k$&#30340;&#30697;&#38453;&#65289;&#36817;&#20284;&#31232;&#30095;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#20551;&#35774;&#22312;&#36827;&#34892;$k \times k$&#26059;&#36716;&#21518;&#65292;&#29305;&#24449;&#20540;&#22522;&#30340;&#31232;&#30095;&#24615;&#21464;&#24471;&#36817;&#20284;&#12290;&#31639;&#27861;&#30340;&#31616;&#21333;&#29256;&#26412;&#26159;&#20197;&#21069;$k$&#20010;&#20027;&#25104;&#20998;&#20026;&#21021;&#22987;&#20540;&#65292;&#28982;&#21518;&#20351;&#29992;$k \times k$&#27491;&#20132;&#26059;&#36716;&#20351;&#20027;&#25104;&#20998;&#36817;&#20284;&#31232;&#30095;&#65292;&#26368;&#21518;&#23545;&#26059;&#36716;&#21518;&#30340;&#20027;&#25104;&#20998;&#36827;&#34892;&#36719;&#38408;&#20540;&#22788;&#29702;&#12290;&#35813;&#26041;&#27861;&#19982;&#20197;&#24448;&#26041;&#27861;&#19981;&#21516;&#20043;&#22788;&#22312;&#20110;&#20351;&#29992;&#27491;&#20132;&#26059;&#36716;&#26469;&#36817;&#20284;&#31232;&#30095;&#22522;&#12290;&#19968;&#20010;&#32467;&#26524;&#26159;&#65292;&#31232;&#30095;&#25104;&#20998;&#19981;&#38656;&#35201;&#26159;&#20027;&#29305;&#24449;&#21521;&#37327;&#65292;&#32780;&#21487;&#20197;&#26159;&#23427;&#20204;&#30340;&#28151;&#21512;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#65288;&#26059;&#36716;&#21518;&#30340;&#65289;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#22522;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36991;&#20813;&#20102;&#8220;&#32553;&#20943;&#8221;&#21644;&#22810;&#20010;&#35843;&#21442;&#21442;&#25968;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#26694;&#26550;&#38750;&#24120;&#28789;&#27963;&#65292;&#24182;&#19988;&#21487;&#20197;&#25512;&#24191;&#33267;...
&lt;/p&gt;
&lt;p&gt;
Previous versions of sparse principal component analysis (PCA) have presumed that the eigen-basis (a $p \times k$ matrix) is approximately sparse. We propose a method that presumes the $p \times k$ matrix becomes approximately sparse after a $k \times k$ rotation. The simplest version of the algorithm initializes with the leading $k$ principal components. Then, the principal components are rotated with an $k \times k$ orthogonal rotation to make them approximately sparse. Finally, soft-thresholding is applied to the rotated principal components. This approach differs from prior approaches because it uses an orthogonal rotation to approximate a sparse basis. One consequence is that a sparse component need not to be a leading eigenvector, but rather a mixture of them. In this way, we propose a new (rotated) basis for sparse PCA. In addition, our approach avoids "deflation" and multiple tuning parameters required for that. Our sparse PCA framework is versatile; for example, it extends nat
&lt;/p&gt;</description></item></channel></rss>