<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#36951;&#25022;&#20026;$O(\log(T))$&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#36793;&#32536;&#26465;&#20214;&#26469;&#25551;&#36848;&#27425;&#20248;&#24615;&#24046;&#36317;&#23545;&#38382;&#39064;&#38590;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.03219</link><description>&lt;p&gt;
LC-Tsalis-INF: &#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
LC-Tsalis-INF: Generalized Best-of-Both-Worlds Linear Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03219
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#36951;&#25022;&#20026;$O(\log(T))$&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#36793;&#32536;&#26465;&#20214;&#26469;&#25551;&#36848;&#27425;&#20248;&#24615;&#24046;&#36317;&#23545;&#38382;&#39064;&#38590;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#32972;&#26223;&#30340;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#29616;&#26377;&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#20339;&#21452;&#36194;&#65288;BoBW&#65289;&#31639;&#27861;&#65292;&#20854;&#36951;&#25022;&#22312;&#38543;&#26426;&#21306;&#22495;&#20013;&#28385;&#36275;$O(\log^2(T))$&#65292;&#20854;&#20013;$T$&#20026;&#22238;&#21512;&#25968;&#65292;&#20854;&#27425;&#20248;&#24615;&#24046;&#36317;&#30001;&#27491;&#24120;&#25968;&#19979;&#30028;&#65292;&#21516;&#26102;&#22312;&#23545;&#25239;&#24615;&#21306;&#22495;&#20013;&#28385;&#36275;$O(\sqrt{T})$&#12290;&#28982;&#32780;&#65292;&#23545;$T$&#30340;&#20381;&#36182;&#20173;&#26377;&#25913;&#36827;&#31354;&#38388;&#65292;&#24182;&#19988;&#27425;&#20248;&#24615;&#24046;&#36317;&#30340;&#20551;&#35774;&#21487;&#20197;&#25918;&#23485;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#24403;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#65292;&#20854;&#36951;&#25022;&#28385;&#36275;$O(\log(T))$&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36793;&#32536;&#26465;&#20214;&#65292;&#21363;&#23545;&#27425;&#20248;&#24615;&#24046;&#36317;&#30340;&#19968;&#20010;&#26356;&#28201;&#21644;&#30340;&#20551;&#35774;&#12290;&#35813;&#26465;&#20214;&#20351;&#29992;&#21442;&#25968;$\beta \in (0, \infty]$&#34920;&#24449;&#19982;&#27425;&#20248;&#24615;&#24046;&#36317;&#30456;&#20851;&#30340;&#38382;&#39064;&#38590;&#24230;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#35813;&#31639;&#27861;&#30340;&#36951;&#25022;&#28385;&#36275;$O\left(\
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03219v1 Announce Type: new  Abstract: This study considers the linear contextual bandit problem with independent and identically distributed (i.i.d.) contexts. In this problem, existing studies have proposed Best-of-Both-Worlds (BoBW) algorithms whose regrets satisfy $O(\log^2(T))$ for the number of rounds $T$ in a stochastic regime with a suboptimality gap lower-bounded by a positive constant, while satisfying $O(\sqrt{T})$ in an adversarial regime. However, the dependency on $T$ has room for improvement, and the suboptimality-gap assumption can be relaxed. For this issue, this study proposes an algorithm whose regret satisfies $O(\log(T))$ in the setting when the suboptimality gap is lower-bounded. Furthermore, we introduce a margin condition, a milder assumption on the suboptimality gap. That condition characterizes the problem difficulty linked to the suboptimality gap using a parameter $\beta \in (0, \infty]$. We then show that the algorithm's regret satisfies $O\left(\
&lt;/p&gt;</description></item><item><title>&#20027;&#21160;&#25512;&#26029;&#26159;&#19968;&#31181;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30830;&#23450;&#26368;&#26377;&#21033;&#20110;&#26631;&#35760;&#30340;&#25968;&#25454;&#28857;&#26469;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#65292;&#23454;&#29616;&#27604;&#29616;&#26377;&#22522;&#32447;&#26356;&#23569;&#26679;&#26412;&#30340;&#30456;&#21516;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.03208</link><description>&lt;p&gt;
&#20027;&#21160;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Active Statistical Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03208
&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#25512;&#26029;&#26159;&#19968;&#31181;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30830;&#23450;&#26368;&#26377;&#21033;&#20110;&#26631;&#35760;&#30340;&#25968;&#25454;&#28857;&#26469;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#65292;&#23454;&#29616;&#27604;&#29616;&#26377;&#22522;&#32447;&#26356;&#23569;&#26679;&#26412;&#30340;&#30456;&#21516;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#20027;&#21160;&#23398;&#20064;&#27010;&#24565;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20027;&#21160;&#25512;&#26029;&#8212;&#8212;&#19968;&#31181;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#25968;&#25454;&#25910;&#38598;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#20551;&#35774;&#23545;&#21487;&#25910;&#38598;&#30340;&#26631;&#31614;&#25968;&#37327;&#26377;&#39044;&#31639;&#38480;&#21046;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30830;&#23450;&#21738;&#20123;&#25968;&#25454;&#28857;&#26368;&#26377;&#21033;&#20110;&#26631;&#35760;&#65292;&#20174;&#32780;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#12290;&#20854;&#36816;&#20316;&#26041;&#24335;&#22522;&#20110;&#19968;&#31181;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#30452;&#35273;&#65306;&#20248;&#20808;&#25910;&#38598;&#27169;&#22411;&#34920;&#29616;&#20986;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#28857;&#30340;&#26631;&#31614;&#65292;&#24182;&#22312;&#27169;&#22411;&#34920;&#29616;&#20986;&#33258;&#20449;&#26102;&#20381;&#36182;&#20110;&#20854;&#39044;&#27979;&#12290;&#20027;&#21160;&#25512;&#26029;&#26500;&#24314;&#20102;&#21487;&#35777;&#26126;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#20551;&#35774;&#26816;&#39564;&#65292;&#21516;&#26102;&#21033;&#29992;&#20219;&#20309;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24182;&#22788;&#29702;&#20219;&#20309;&#25968;&#25454;&#20998;&#24067;&#12290;&#20851;&#38190;&#28857;&#22312;&#20110;&#65292;&#23427;&#33021;&#20197;&#27604;&#20381;&#36182;&#20110;&#38750;&#33258;&#36866;&#24212;&#25910;&#38598;&#25968;&#25454;&#30340;&#29616;&#26377;&#22522;&#32447;&#26356;&#23569;&#30340;&#26679;&#26412;&#36798;&#21040;&#30456;&#21516;&#27700;&#24179;&#30340;&#20934;&#30830;&#24615;&#12290;&#36825;&#24847;&#21619;&#30528;&#23545;&#20110;&#30456;&#21516;&#25968;&#37327;&#30340;&#26679;&#26412;&#65292;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03208v1 Announce Type: cross  Abstract: Inspired by the concept of active learning, we propose active inference$\unicode{x2013}$a methodology for statistical inference with machine-learning-assisted data collection. Assuming a budget on the number of labels that can be collected, the methodology uses a machine learning model to identify which data points would be most beneficial to label, thus effectively utilizing the budget. It operates on a simple yet powerful intuition: prioritize the collection of labels for data points where the model exhibits uncertainty, and rely on the model's predictions where it is confident. Active inference constructs provably valid confidence intervals and hypothesis tests while leveraging any black-box machine learning model and handling any data distribution. The key point is that it achieves the same level of accuracy with far fewer samples than existing baselines relying on non-adaptively-collected data. This means that for the same number 
&lt;/p&gt;</description></item><item><title>Transformers&#33021;&#22815;&#23454;&#29616;&#39640;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#32447;&#24615;&#27880;&#24847;&#21147;Transformer&#21487;&#20197;&#22312; logistic &#22238;&#24402;&#20219;&#21153;&#20013;&#36817;&#20284;&#23454;&#29616;&#20108;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#21363;&#20351;&#26159;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;Transformer&#20063;&#21487;&#20197;&#23454;&#29616;&#30697;&#38453;&#27714;&#36870;&#30340;&#29275;&#39039;&#36845;&#20195;&#12290;</title><link>https://arxiv.org/abs/2403.03183</link><description>&lt;p&gt;
Transformers&#33021;&#22810;&#22909;&#22320;&#27169;&#25311; Newton &#26041;&#27861;&#19978;&#19979;&#25991;&#20013;&#30340;&#34920;&#29616;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Well Can Transformers Emulate In-context Newton's Method?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03183
&lt;/p&gt;
&lt;p&gt;
Transformers&#33021;&#22815;&#23454;&#29616;&#39640;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#32447;&#24615;&#27880;&#24847;&#21147;Transformer&#21487;&#20197;&#22312; logistic &#22238;&#24402;&#20219;&#21153;&#20013;&#36817;&#20284;&#23454;&#29616;&#20108;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#21363;&#20351;&#26159;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;Transformer&#20063;&#21487;&#20197;&#23454;&#29616;&#30697;&#38453;&#27714;&#36870;&#30340;&#29275;&#39039;&#36845;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#24341;&#21457;&#20102;&#23545;&#20854;&#22522;&#30784;&#26426;&#21046;&#30340;&#24191;&#27867;&#30740;&#31350;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;Transformers&#21487;&#20197;&#23454;&#29616;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#29978;&#33267;&#23545;&#20110;&#32447;&#24615;&#22238;&#24402;&#30340;&#24773;&#20917;&#65292;&#21487;&#20197;&#23454;&#29616;&#20108;&#38454;&#20248;&#21270;&#31639;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Transformer&#26159;&#21542;&#33021;&#22815;&#25191;&#34892;&#39640;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;&#32447;&#24615;&#22238;&#24402;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30830;&#23450;&#20855;&#26377;ReLU&#23618;&#30340;&#32447;&#24615;&#27880;&#24847;&#21147;Transformer&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#20108;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#36923;&#36753;&#22238;&#24402;&#20219;&#21153;&#65292;&#24182;&#19988;&#20165;&#20351;&#29992;&#23545;&#25968;&#21040;&#38169;&#35823;&#26356;&#22810;&#30340;&#23618;&#21487;&#20197;&#36798;&#21040;$\epsilon$&#35823;&#24046;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#26159;&#20165;&#20855;&#26377;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;Transformer&#20063;&#21487;&#20197;&#22312;&#20165;&#20004;&#23618;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#30697;&#38453;&#27714;&#36870;&#30340;&#29275;&#39039;&#36845;&#20195;&#30340;&#21333;&#27493;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#20102;Transformer&#26550;&#26500;&#23454;&#29616;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03183v1 Announce Type: cross  Abstract: Transformer-based models have demonstrated remarkable in-context learning capabilities, prompting extensive research into its underlying mechanisms. Recent studies have suggested that Transformers can implement first-order optimization algorithms for in-context learning and even second order ones for the case of linear regression. In this work, we study whether Transformers can perform higher order optimization methods, beyond the case of linear regression. We establish that linear attention Transformers with ReLU layers can approximate second order optimization algorithms for the task of logistic regression and achieve $\epsilon$ error with only a logarithmic to the error more layers. As a by-product we demonstrate the ability of even linear attention-only Transformers in implementing a single step of Newton's iteration for matrix inversion with merely two layers. These results suggest the ability of the Transformer architecture to im
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Brenier&#30340;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#31070;&#32463;&#23454;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#28508;&#22312;&#20989;&#25968;$u$&#65292;&#20174;&#26368;&#26032;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#36827;&#23637;&#20013;&#27762;&#21462;&#28789;&#24863;&#12290;</title><link>https://arxiv.org/abs/2403.03071</link><description>&lt;p&gt;
&#35770;Brenier&#30340;&#26497;&#20998;&#35299;&#30340;&#31070;&#32463;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
On a Neural Implementation of Brenier's Polar Factorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03071
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Brenier&#30340;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#31070;&#32463;&#23454;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#28508;&#22312;&#20989;&#25968;$u$&#65292;&#20174;&#26368;&#26032;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#36827;&#23637;&#20013;&#27762;&#21462;&#28789;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1991&#24180;&#65292;Brenier&#35777;&#26126;&#20102;&#19968;&#20010;&#23450;&#29702;&#65292;&#23558;$QR$&#20998;&#35299;&#65288;&#20998;&#20026;&#21322;&#27491;&#23450;&#30697;&#38453;$\times$&#37193;&#30697;&#38453;&#65289;&#25512;&#24191;&#21040;&#20219;&#24847;&#30690;&#37327;&#22330;$F:\mathbb{R}^d\rightarrow \mathbb{R}^d$&#12290;&#36825;&#20010;&#34987;&#31216;&#20026;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#20219;&#24847;&#22330;$F$&#37117;&#21487;&#20197;&#34920;&#31034;&#20026;&#20984;&#20989;&#25968;$u$&#30340;&#26799;&#24230;&#19982;&#20445;&#27979;&#24230;&#26144;&#23556;$M$&#30340;&#22797;&#21512;&#65292;&#21363;$F=\nabla u \circ M$&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#19968;&#20855;&#26377;&#28145;&#36828;&#29702;&#35770;&#24847;&#20041;&#30340;&#32467;&#26524;&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21487;&#33021;&#30340;&#24212;&#29992;&#12290;&#35813;&#23450;&#29702;&#19982;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#29702;&#35770;&#23494;&#20999;&#30456;&#20851;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23558;&#28508;&#22312;&#20989;&#25968;$u$&#21442;&#25968;&#21270;&#20026;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#12290;&#26144;&#23556;$M$&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;$u^*$&#65292;&#21363;$u$&#30340;&#20984;&#20849;&#36717;&#65292;&#36880;&#28857;&#35745;&#31639;&#24471;&#21040;&#65292;&#21363;$M=\nabla u^* \circ F$&#65292;&#25110;&#32773;&#20316;&#20026;&#36741;&#21161;&#32593;&#32476;&#23398;&#20064;&#24471;&#21040;&#12290;&#22240;&#20026;$M$&#22312;&#22522;&#22240;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03071v1 Announce Type: cross  Abstract: In 1991, Brenier proved a theorem that generalizes the $QR$ decomposition for square matrices -- factored as PSD $\times$ unitary -- to any vector field $F:\mathbb{R}^d\rightarrow \mathbb{R}^d$. The theorem, known as the polar factorization theorem, states that any field $F$ can be recovered as the composition of the gradient of a convex function $u$ with a measure-preserving map $M$, namely $F=\nabla u \circ M$. We propose a practical implementation of this far-reaching theoretical result, and explore possible uses within machine learning. The theorem is closely related to optimal transport (OT) theory, and we borrow from recent advances in the field of neural optimal transport to parameterize the potential $u$ as an input convex neural network. The map $M$ can be either evaluated pointwise using $u^*$, the convex conjugate of $u$, through the identity $M=\nabla u^* \circ F$, or learned as an auxiliary network. Because $M$ is, in gene
&lt;/p&gt;</description></item><item><title>&#32570;&#22833;&#25968;&#25454;&#22686;&#21152;&#20102;&#27169;&#22411;&#23545;&#28508;&#22312;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#8212;&#8212;&#22522;&#20110;&#26377;&#38480;&#21464;&#20998;&#28151;&#21512;&#21644;&#22522;&#20110;&#22635;&#34917;&#30340;&#21464;&#20998;&#28151;&#21512;&#20998;&#24067;&#65292;&#26377;&#25928;&#25913;&#21892;&#20102;&#20174;&#19981;&#23436;&#25972;&#25968;&#25454;&#20272;&#35745;VAE&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.03069</link><description>&lt;p&gt;
&#29992;&#28151;&#21512;&#21464;&#20998;&#23478;&#26063;&#25913;&#36827;&#20174;&#19981;&#23436;&#25972;&#25968;&#25454;&#20272;&#35745;&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Improving Variational Autoencoder Estimation from Incomplete Data with Mixture Variational Families
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03069
&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#22686;&#21152;&#20102;&#27169;&#22411;&#23545;&#28508;&#22312;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#8212;&#8212;&#22522;&#20110;&#26377;&#38480;&#21464;&#20998;&#28151;&#21512;&#21644;&#22522;&#20110;&#22635;&#34917;&#30340;&#21464;&#20998;&#28151;&#21512;&#20998;&#24067;&#65292;&#26377;&#25928;&#25913;&#21892;&#20102;&#20174;&#19981;&#23436;&#25972;&#25968;&#25454;&#20272;&#35745;VAE&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#35757;&#32451;&#25968;&#25454;&#19981;&#23436;&#25972;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32570;&#22833;&#25968;&#25454;&#20250;&#22686;&#21152;&#27169;&#22411;&#23545;&#28508;&#22312;&#21464;&#37327;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#65292;&#19982;&#23436;&#20840;&#35266;&#27979;&#30340;&#24773;&#20917;&#30456;&#27604;&#12290;&#22686;&#21152;&#30340;&#22797;&#26434;&#24615;&#21487;&#33021;&#20250;&#30001;&#20110;&#21464;&#20998;&#20998;&#24067;&#21644;&#27169;&#22411;&#21518;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#32780;&#23545;&#27169;&#22411;&#25311;&#21512;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#22522;&#20110;&#65288;i&#65289;&#26377;&#38480;&#21464;&#20998;&#28151;&#21512;&#21644;&#65288;ii&#65289;&#22522;&#20110;&#22635;&#34917;&#30340;&#21464;&#20998;&#28151;&#21512;&#20998;&#24067;&#30340;&#31574;&#30053;&#65292;&#20197;&#35299;&#20915;&#22686;&#21152;&#30340;&#21518;&#39564;&#22797;&#26434;&#24615;&#12290;&#36890;&#36807;&#23545;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#25105;&#20204;&#34920;&#26126;&#21464;&#20998;&#28151;&#21512;&#22312;&#25913;&#36827;&#20174;&#19981;&#23436;&#25972;&#25968;&#25454;&#20272;&#35745;VAE&#30340;&#20934;&#30830;&#24615;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03069v1 Announce Type: new  Abstract: We consider the task of estimating variational autoencoders (VAEs) when the training data is incomplete. We show that missing data increases the complexity of the model's posterior distribution over the latent variables compared to the fully-observed case. The increased complexity may adversely affect the fit of the model due to a mismatch between the variational and model posterior distributions. We introduce two strategies based on (i) finite variational-mixture and (ii) imputation-based variational-mixture distributions to address the increased posterior complexity. Through a comprehensive evaluation of the proposed approaches, we show that variational mixtures are effective at improving the accuracy of VAE estimation from incomplete data.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;&#65292;&#24182;&#22312;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#26041;&#38754;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.03058</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#25552;&#21319;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Machine Learning Assisted Adjustment Boosts Inferential Efficiency of Randomized Controlled Trials
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03058
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;&#65292;&#24182;&#22312;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#26041;&#38754;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#37319;&#29992;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#35843;&#25972;&#26041;&#27861;&#65292;&#29992;&#20110;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#12290;&#35813;&#26041;&#27861;&#26159;&#22312;&#32599;&#26862;&#40077;&#22982;&#30340;&#22522;&#20110;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#38543;&#26426;&#23454;&#39564;&#30340;&#30830;&#20999;&#26816;&#39564;&#26694;&#26550;&#19979;&#24320;&#21457;&#30340;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#27169;&#25311;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#31283;&#20581;&#22320;&#25511;&#21046;&#31532;&#19968;&#31867;&#38169;&#35823;&#65292;&#24182;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;(RCT)&#30340;&#25512;&#26029;&#25928;&#29575;&#12290;&#36825;&#19968;&#20248;&#21183;&#22312;&#19968;&#20010;&#30495;&#23454;&#26696;&#20363;&#20013;&#36827;&#19968;&#27493;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#31616;&#21333;&#24615;&#21644;&#31283;&#20581;&#24615;&#20351;&#20854;&#25104;&#20026;&#19968;&#31181;&#31454;&#20105;&#24615;&#20505;&#36873;&#20316;&#20026;RCT&#30340;&#24120;&#35268;&#25512;&#26029;&#31243;&#24207;&#65292;&#29305;&#21035;&#26159;&#24403;&#22522;&#32447;&#21327;&#21464;&#37327;&#30340;&#25968;&#37327;&#36739;&#22810;&#65292;&#19988;&#39044;&#35745;&#23384;&#22312;&#38750;&#32447;&#24615;&#20851;&#32852;&#25110;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#26102;&#12290;&#20854;&#24212;&#29992;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;RCT&#30340;&#25152;&#38656;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#65292;&#20363;&#22914;&#19977;&#26399;&#20020;&#24202;&#35797;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03058v1 Announce Type: cross  Abstract: In this work, we proposed a novel inferential procedure assisted by machine learning based adjustment for randomized control trials. The method was developed under the Rosenbaum's framework of exact tests in randomized experiments with covariate adjustments. Through extensive simulation experiments, we showed the proposed method can robustly control the type I error and can boost the inference efficiency for a randomized controlled trial (RCT). This advantage was further demonstrated in a real world example. The simplicity and robustness of the proposed method makes it a competitive candidate as a routine inference procedure for RCTs, especially when the number of baseline covariates is large, and when nonlinear association or interaction among covariates is expected. Its application may remarkably reduce the required sample size and cost of RCTs, such as phase III clinical trials.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#36890;&#29992;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#26102;&#30340;&#35745;&#31639;&#38590;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.03007</link><description>&lt;p&gt;
&#36890;&#29992;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Scalable Bayesian inference for the generalized linear mixed model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03007
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#36890;&#29992;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#26102;&#30340;&#35745;&#31639;&#38590;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#29992;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#65288;GLMM&#65289;&#26159;&#22788;&#29702;&#30456;&#20851;&#25968;&#25454;&#30340;&#19968;&#31181;&#27969;&#34892;&#32479;&#35745;&#26041;&#27861;&#65292;&#22312;&#21253;&#25324;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#31561;&#22823;&#25968;&#25454;&#24120;&#35265;&#30340;&#24212;&#29992;&#39046;&#22495;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#26412;&#25991;&#30340;&#37325;&#28857;&#26159;&#38024;&#23545;GLMM&#30340;&#21487;&#25193;&#23637;&#32479;&#35745;&#25512;&#26029;&#65292;&#25105;&#20204;&#23558;&#32479;&#35745;&#25512;&#26029;&#23450;&#20041;&#20026;&#65306;&#65288;i&#65289;&#23545;&#24635;&#20307;&#21442;&#25968;&#30340;&#20272;&#35745;&#20197;&#21450;&#65288;ii&#65289;&#22312;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#31185;&#23398;&#20551;&#35774;&#12290;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#23398;&#20064;&#31639;&#27861;&#25797;&#38271;&#21487;&#25193;&#23637;&#30340;&#32479;&#35745;&#20272;&#35745;&#65292;&#20294;&#24456;&#23569;&#21253;&#25324;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#25552;&#20379;&#23436;&#25972;&#30340;&#32479;&#35745;&#25512;&#26029;&#65292;&#22240;&#20026;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33258;&#21160;&#26469;&#33258;&#21518;&#39564;&#20998;&#24067;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#21253;&#25324;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#22312;&#20869;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#22312;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#21464;&#24471;&#38590;&#20197;&#35745;&#31639;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#35745;&#25512;&#26029;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03007v1 Announce Type: cross  Abstract: The generalized linear mixed model (GLMM) is a popular statistical approach for handling correlated data, and is used extensively in applications areas where big data is common, including biomedical data settings. The focus of this paper is scalable statistical inference for the GLMM, where we define statistical inference as: (i) estimation of population parameters, and (ii) evaluation of scientific hypotheses in the presence of uncertainty. Artificial intelligence (AI) learning algorithms excel at scalable statistical estimation, but rarely include uncertainty quantification. In contrast, Bayesian inference provides full statistical inference, since uncertainty quantification results automatically from the posterior distribution. Unfortunately, Bayesian inference algorithms, including Markov Chain Monte Carlo (MCMC), become computationally intractable in big data settings. In this paper, we introduce a statistical inference algorithm 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#19968;&#20010;&#29305;&#23450;&#30340;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#31361;&#20986;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#65292;&#21516;&#26102;&#20855;&#26377;&#24378;&#22823;&#29983;&#25104;&#22120;&#30340;&#29420;&#29305;&#35270;&#35282;&#12290;</title><link>https://arxiv.org/abs/2403.02957</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#28176;&#36817;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Asymptotic Mean Square Error Optimality of Diffusion Probabilistic Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#19968;&#20010;&#29305;&#23450;&#30340;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#31361;&#20986;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#65292;&#21516;&#26102;&#20855;&#26377;&#24378;&#22823;&#29983;&#25104;&#22120;&#30340;&#29420;&#29305;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPMs&#65289;&#22312;&#21435;&#22122;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;&#23613;&#31649;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24456;&#26377;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#29702;&#35299;&#23384;&#22312;&#26126;&#26174;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#29305;&#23450;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65288;CME&#65289;&#65292;&#20026;&#35813;&#39046;&#22495;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#35265;&#35299;&#12290;&#30740;&#31350;&#30340;&#22522;&#20110;DPM&#30340;&#21435;&#22122;&#22120;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#19982;DPMs&#20849;&#20139;&#65292;&#20294;&#22312;&#35757;&#32451;&#21518;&#30340;&#36870;&#25512;&#29702;&#36807;&#31243;&#20013;&#20165;&#20256;&#36882;&#26465;&#20214;&#22343;&#20540;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#30340;&#29420;&#29305;&#35270;&#35282;&#65292;&#21516;&#26102;&#36890;&#36807;&#22312;&#36870;&#36807;&#31243;&#20013;&#20999;&#25442;&#37325;&#26032;&#37319;&#26679;&#30340;&#26041;&#24335;&#32487;&#25215;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#29983;&#25104;&#22120;&#12290;&#36890;&#36807;&#25968;&#20540;&#32467;&#26524;&#39564;&#35777;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02957v1 Announce Type: new  Abstract: Diffusion probabilistic models (DPMs) have recently shown great potential for denoising tasks. Despite their practical utility, there is a notable gap in their theoretical understanding. This paper contributes novel theoretical insights by rigorously proving the asymptotic convergence of a specific DPM denoising strategy to the mean square error (MSE)-optimal conditional mean estimator (CME) over a large number of diffusion steps. The studied DPM-based denoiser shares the training procedure of DPMs but distinguishes itself by forwarding only the conditional mean during the reverse inference process after training. We highlight the unique perspective that DPMs are composed of an asymptotically optimal denoiser while simultaneously inheriting a powerful generator by switching re-sampling in the reverse process on and off. The theoretical findings are validated by numerical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;Koopman&#31639;&#23376;&#26694;&#26550;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;Nystro&#776;m&#36924;&#36817;&#23454;&#29616;&#20102;&#23545;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#26377;&#25928;&#25511;&#21046;&#65292;&#20854;&#29702;&#35770;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.02811</link><description>&lt;p&gt;
&#20855;&#26377;Koopman&#31639;&#23376;&#23398;&#20064;&#21644;Nystro&#776;m&#26041;&#27861;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#32447;&#24615;&#20108;&#27425;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Linear quadratic control of nonlinear systems with Koopman operator learning and the Nystr\"om method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;Koopman&#31639;&#23376;&#26694;&#26550;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;Nystro&#776;m&#36924;&#36817;&#23454;&#29616;&#20102;&#23545;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#26377;&#25928;&#25511;&#21046;&#65292;&#20854;&#29702;&#35770;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Koopman&#31639;&#23376;&#26694;&#26550;&#22914;&#20309;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#20197;&#26377;&#25928;&#25511;&#21046;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#12290;&#34429;&#28982;&#26680;&#26041;&#27861;&#36890;&#24120;&#20855;&#26377;&#24456;&#22823;&#30340;&#35745;&#31639;&#38656;&#27714;&#65292;&#20294;&#25105;&#20204;&#23637;&#31034;&#20102;&#38543;&#26426;&#23376;&#31354;&#38388;&#65288;Nystro&#776;m&#36924;&#36817;&#65289;&#22914;&#20309;&#23454;&#29616;&#24040;&#22823;&#30340;&#35745;&#31639;&#33410;&#32422;&#65292;&#21516;&#26102;&#20445;&#25345;&#31934;&#24230;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;&#20851;&#20110;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#30456;&#20851;&#35299;&#30340;&#36817;&#20284;Riccati&#31639;&#23376;&#21644;&#35843;&#33410;&#22120;&#30446;&#26631;&#37117;&#20197;$ m^{-1/2} $&#30340;&#36895;&#29575;&#25910;&#25947;&#65292;&#20854;&#20013;$ m $&#26159;&#38543;&#26426;&#23376;&#31354;&#38388;&#22823;&#23567;&#12290;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#25968;&#20540;&#23454;&#39564;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02811v1 Announce Type: cross  Abstract: In this paper, we study how the Koopman operator framework can be combined with kernel methods to effectively control nonlinear dynamical systems. While kernel methods have typically large computational requirements, we show how random subspaces (Nystr\"om approximation) can be used to achieve huge computational savings while preserving accuracy. Our main technical contribution is deriving theoretical guarantees on the effect of the Nystr\"om approximation. More precisely, we study the linear quadratic regulator problem, showing that both the approximated Riccati operator and the regulator objective, for the associated solution of the optimal control problem, converge at the rate $m^{-1/2}$, where $m$ is the random subspace size. Theoretical findings are complemented by numerical experiments corroborating our results.
&lt;/p&gt;</description></item><item><title>&#22122;&#22768;&#28155;&#21152;&#21518;&#65292;&#31232;&#30095;&#32447;&#24615;&#38382;&#39064;&#19978;&#30340;&#26059;&#36716;&#19981;&#21464;&#31639;&#27861;&#20173;&#28982;&#27425;&#20248;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;</title><link>https://arxiv.org/abs/2403.02697</link><description>&lt;p&gt;
&#22122;&#22768;&#35823;&#23548;&#31232;&#30095;&#30446;&#26631;&#19978;&#30340;&#26059;&#36716;&#19981;&#21464;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Noise misleads rotation invariant algorithms on sparse targets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02697
&lt;/p&gt;
&lt;p&gt;
&#22122;&#22768;&#28155;&#21152;&#21518;&#65292;&#31232;&#30095;&#32447;&#24615;&#38382;&#39064;&#19978;&#30340;&#26059;&#36716;&#19981;&#21464;&#31639;&#27861;&#20173;&#28982;&#27425;&#20248;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#21363;&#20351;&#23545;&#20110;&#23398;&#20064;&#31232;&#30095;&#32447;&#24615;&#38382;&#39064;&#65292;&#24403;&#26679;&#26412;&#25968;&#20302;&#20110;&#38382;&#39064;&#30340;&#8220;&#32500;&#24230;&#8221;&#26102;&#65292;&#26059;&#36716;&#19981;&#21464;&#31639;&#27861;&#20063;&#26159;&#27425;&#20248;&#30340;&#12290;&#36825;&#20010;&#31867;&#21035;&#21253;&#25324;&#20219;&#20309;&#20351;&#29992;&#20840;&#36830;&#25509;&#36755;&#20837;&#23618;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;&#21021;&#22987;&#21270;&#20026;&#26059;&#36716;&#23545;&#31216;&#20998;&#24067;&#65289;&#12290;&#26368;&#31616;&#21333;&#30340;&#31232;&#30095;&#38382;&#39064;&#26159;&#23398;&#20064;$d$&#20010;&#29305;&#24449;&#20013;&#30340;&#19968;&#20010;&#29305;&#24449;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20998;&#31867;&#35823;&#24046;&#25110;&#22238;&#24402;&#25439;&#22833;&#38543;&#30528;$1-k/n$&#22686;&#38271;&#65292;&#20854;&#20013;$k$&#26159;&#35266;&#23519;&#21040;&#30340;&#26679;&#26412;&#25968;&#12290;&#24403;&#26679;&#26412;&#25968;$k$&#36798;&#21040;&#32500;&#24230;$d$&#26102;&#65292;&#36825;&#20123;&#19979;&#30028;&#21464;&#24471;&#31354;&#27867;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#23558;&#22122;&#22768;&#28155;&#21152;&#21040;&#36825;&#20010;&#31232;&#30095;&#32447;&#24615;&#38382;&#39064;&#26102;&#65292;&#21363;&#20351;&#22312;&#35266;&#23519;&#21040;$d$&#20010;&#25110;&#26356;&#22810;&#26679;&#26412;&#21518;&#65292;&#26059;&#36716;&#19981;&#21464;&#31639;&#27861;&#20173;&#28982;&#26159;&#27425;&#20248;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#38024;&#23545;&#19968;&#20010;&#26059;&#36716;&#23545;&#31216;&#21270;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#30340;&#19968;&#20010;&#19979;&#30028;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30456;&#21516;&#38382;&#39064;&#30340;&#26356;&#20302;&#30340;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02697v1 Announce Type: cross  Abstract: It is well known that the class of rotation invariant algorithms are suboptimal even for learning sparse linear problems when the number of examples is below the "dimension" of the problem. This class includes any gradient descent trained neural net with a fully-connected input layer (initialized with a rotationally symmetric distribution). The simplest sparse problem is learning a single feature out of $d$ features. In that case the classification error or regression loss grows with $1-k/n$ where $k$ is the number of examples seen. These lower bounds become vacuous when the number of examples $k$ reaches the dimension $d$.   We show that when noise is added to this sparse linear problem, rotation invariant algorithms are still suboptimal after seeing $d$ or more examples. We prove this via a lower bound for the Bayes optimal algorithm on a rotationally symmetrized problem. We then prove much lower upper bounds on the same problem for 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#22238;&#22768;&#24577;&#24615;&#36136;&#30340;&#19981;&#21516;&#23618;&#27425;&#65292;&#21253;&#25324;&#38750;&#24179;&#31283;&#24615;ESP&#21644;&#23376;&#31995;&#32479;&#20855;&#26377;ESP&#30340;&#23376;&#31354;&#38388;/&#23376;&#38598;ESP&#12290;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#21644;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#20197;&#39564;&#35777;&#36825;&#20123;&#23450;&#20041;&#12290;</title><link>https://arxiv.org/abs/2403.02686</link><description>&lt;p&gt;
&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#30340;&#22238;&#22768;&#24577;&#24615;&#36136;&#31561;&#32423;
&lt;/p&gt;
&lt;p&gt;
Hierarchy of the echo state property in quantum reservoir computing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02686
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#22238;&#22768;&#24577;&#24615;&#36136;&#30340;&#19981;&#21516;&#23618;&#27425;&#65292;&#21253;&#25324;&#38750;&#24179;&#31283;&#24615;ESP&#21644;&#23376;&#31995;&#32479;&#20855;&#26377;ESP&#30340;&#23376;&#31354;&#38388;/&#23376;&#38598;ESP&#12290;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#21644;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#20197;&#39564;&#35777;&#36825;&#20123;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#22768;&#24577;&#24615;&#36136;&#65288;ESP&#65289;&#20195;&#34920;&#20102;&#20648;&#22791;&#35745;&#31639;&#65288;RC&#65289;&#26694;&#26550;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#27010;&#24565;&#65292;&#36890;&#36807;&#23545;&#21021;&#22987;&#29366;&#24577;&#21644;&#36828;&#26399;&#36755;&#20837;&#19981;&#21152;&#27495;&#35270;&#26469;&#30830;&#20445;&#20648;&#33988;&#32593;&#32476;&#30340;&#20165;&#36755;&#20986;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;ESP&#23450;&#20041;&#24182;&#26410;&#25551;&#36848;&#21487;&#33021;&#28436;&#21464;&#32479;&#35745;&#23646;&#24615;&#30340;&#38750;&#24179;&#31283;&#31995;&#32479;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31867;&#26032;&#30340;ESP&#65306;\textit{&#38750;&#24179;&#31283;ESP}&#65292;&#29992;&#20110;&#28508;&#22312;&#38750;&#24179;&#31283;&#31995;&#32479;&#65292;&#21644;\textit{&#23376;&#31354;&#38388;/&#23376;&#38598;ESP}&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;ESP&#30340;&#23376;&#31995;&#32479;&#30340;&#31995;&#32479;&#12290;&#26681;&#25454;&#36825;&#20123;&#23450;&#20041;&#65292;&#25105;&#20204;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#65288;QRC&#65289;&#26694;&#26550;&#20013;&#25968;&#20540;&#28436;&#31034;&#20102;&#38750;&#24179;&#31283;ESP&#19982;&#20856;&#22411;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#21644;&#20351;&#29992;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#31227;&#21160;&#24179;&#22343;&#65288;NARMA&#65289;&#20219;&#21153;&#30340;&#36755;&#20837;&#32534;&#30721;&#26041;&#27861;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#35745;&#31639;&#32447;&#24615;/&#38750;&#32447;&#24615;&#35760;&#24518;&#23481;&#37327;&#26469;&#30830;&#35748;&#36825;&#31181;&#23545;&#24212;&#20851;&#31995;&#65292;&#20197;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02686v1 Announce Type: cross  Abstract: The echo state property (ESP) represents a fundamental concept in the reservoir computing (RC) framework that ensures output-only training of reservoir networks by being agnostic to the initial states and far past inputs. However, the traditional definition of ESP does not describe possible non-stationary systems in which statistical properties evolve. To address this issue, we introduce two new categories of ESP: \textit{non-stationary ESP}, designed for potentially non-stationary systems, and \textit{subspace/subset ESP}, designed for systems whose subsystems have ESP. Following the definitions, we numerically demonstrate the correspondence between non-stationary ESP in the quantum reservoir computer (QRC) framework with typical Hamiltonian dynamics and input encoding methods using non-linear autoregressive moving-average (NARMA) tasks. We also confirm the correspondence by computing linear/non-linear memory capacities that quantify 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20803;&#23398;&#20064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#25512;&#36831;&#23545;&#20154;&#32676;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#36866;&#24212;&#21069;&#25152;&#26410;&#35265;&#30340;&#19987;&#23478;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#38754;&#23545;&#22256;&#38590;&#20915;&#31574;&#12290;</title><link>https://arxiv.org/abs/2403.02683</link><description>&lt;p&gt;
&#23398;&#20064;&#25512;&#36831;&#23545;&#20154;&#32676;&#30340;&#23398;&#20064;&#65306;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning to Defer to a Population: A Meta-Learning Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02683
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20803;&#23398;&#20064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#25512;&#36831;&#23545;&#20154;&#32676;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#36866;&#24212;&#21069;&#25152;&#26410;&#35265;&#30340;&#19987;&#23478;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#38754;&#23545;&#22256;&#38590;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02683v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032; &#25688;&#35201;&#65306;&#23398;&#20064;&#25512;&#36831;&#65288;L2D&#65289;&#26694;&#26550;&#20801;&#35768;&#33258;&#20027;&#31995;&#32479;&#36890;&#36807;&#23558;&#22256;&#38590;&#20915;&#31574;&#22996;&#25176;&#32473;&#20154;&#31867;&#19987;&#23478;&#26469;&#20445;&#25345;&#23433;&#20840;&#21644;&#20581;&#22766;&#12290;&#25152;&#26377;&#29616;&#26377;&#30340;&#20851;&#20110;L2D&#30340;&#24037;&#20316;&#37117;&#20551;&#35774;&#27599;&#20010;&#19987;&#23478;&#37117;&#21487;&#20197;&#24456;&#22909;&#22320;&#30830;&#23450;&#65292;&#24182;&#19988;&#22914;&#26524;&#20219;&#20309;&#19987;&#23478;&#21457;&#29983;&#21464;&#21270;&#65292;&#31995;&#32479;&#24212;&#35813;&#37325;&#26032;&#35757;&#32451;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20943;&#36731;&#20102;&#36825;&#19968;&#38480;&#21046;&#65292;&#21046;&#23450;&#20102;&#19968;&#20010;L2D&#31995;&#32479;&#65292;&#23427;&#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#24212;&#23545;&#21069;&#25152;&#26410;&#35265;&#30340;&#19987;&#23478;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20803;&#23398;&#20064;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#32771;&#34385;&#20102;&#22522;&#20110;&#20248;&#21270;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#21464;&#20307;&#12290;&#32473;&#23450;&#19968;&#20010;&#23567;&#30340;&#19978;&#19979;&#25991;&#38598;&#26469;&#25551;&#36848;&#24403;&#21069;&#21487;&#29992;&#30340;&#19987;&#23478;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#24555;&#36895;&#35843;&#25972;&#23427;&#30340;&#25512;&#36831;&#31574;&#30053;&#12290;&#23545;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#33021;&#22815;&#23547;&#25214;&#19978;&#19979;&#25991;&#38598;&#20013;&#19982;&#32473;&#23450;&#27979;&#35797;&#28857;&#30456;&#20284;&#30340;&#28857;&#65292;&#20174;&#32780;&#26356;&#31934;&#30830;&#22320;&#35780;&#20272;&#19987;&#23478;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02683v1 Announce Type: new  Abstract: The learning to defer (L2D) framework allows autonomous systems to be safe and robust by allocating difficult decisions to a human expert. All existing work on L2D assumes that each expert is well-identified, and if any expert were to change, the system should be re-trained. In this work, we alleviate this constraint, formulating an L2D system that can cope with never-before-seen experts at test-time. We accomplish this by using meta-learning, considering both optimization- and model-based variants. Given a small context set to characterize the currently available expert, our framework can quickly adapt its deferral policy. For the model-based approach, we employ an attention mechanism that is able to look for points in the context set that are similar to a given test point, leading to an even more precise assessment of the expert's abilities. In the experiments, we validate our methods on image recognition, traffic sign detection, and s
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Unlearning&#31639;&#27861;&#22312;&#32852;&#24819;&#35760;&#24518;&#27169;&#22411;&#21644;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#23558;&#20854;&#31616;&#21270;&#20026;&#32447;&#24615;&#24863;&#30693;&#22120;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36873;&#25321;&#32467;&#26500;&#21270;&#35757;&#32451;&#25968;&#25454;&#65292;&#20351;&#32593;&#32476;&#22312;&#36739;&#39640;&#35823;&#24046;&#23481;&#38480;&#19979;&#20381;&#28982;&#26377;&#25928;&#12290;</title><link>https://arxiv.org/abs/2403.02537</link><description>&lt;p&gt;
&#33258;&#26059;&#29627;&#29827;&#26679;&#31070;&#32463;&#32593;&#32476;&#20013;&#35760;&#24518;&#30340;&#25286;&#38500;&#21644;&#24378;&#21270;
&lt;/p&gt;
&lt;p&gt;
Demolition and Reinforcement of Memories in Spin-Glass-like Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02537
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Unlearning&#31639;&#27861;&#22312;&#32852;&#24819;&#35760;&#24518;&#27169;&#22411;&#21644;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#23558;&#20854;&#31616;&#21270;&#20026;&#32447;&#24615;&#24863;&#30693;&#22120;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36873;&#25321;&#32467;&#26500;&#21270;&#35757;&#32451;&#25968;&#25454;&#65292;&#20351;&#32593;&#32476;&#22312;&#36739;&#39640;&#35823;&#24046;&#23481;&#38480;&#19979;&#20381;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#21147;&#23398;&#36890;&#36807;&#23558;&#29983;&#29289;&#31070;&#32463;&#31995;&#32479;&#24314;&#27169;&#20026;&#20855;&#26377;&#21487;&#35843;&#20132;&#20114;&#20316;&#29992;&#30340;&#20114;&#32852;&#21333;&#20803;&#30340;&#24490;&#29615;&#32593;&#32476;&#65292;&#23545;&#30740;&#31350;&#29983;&#29289;&#31070;&#32463;&#31995;&#32479;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#31639;&#27861;&#26469;&#20248;&#21270;&#31070;&#32463;&#36830;&#25509;&#65292;&#20197;&#23454;&#29616;&#32593;&#32476;&#20219;&#21153;&#65292;&#22914;&#20449;&#24687;&#23384;&#20648;&#65288;&#21363;&#32852;&#24819;&#35760;&#24518;&#65289;&#21644;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#65288;&#21363;&#29983;&#25104;&#24314;&#27169;&#65289;&#12290;&#22312;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;&#19982;&#31361;&#35302;&#21487;&#22609;&#24615;&#26032;&#20852;&#29702;&#35770;&#20445;&#25345;&#19968;&#33268;&#65292;&#32422;&#32752;&#183;&#38669;&#26222;&#33778;&#23572;&#24503;&#21644;&#21512;&#20316;&#32773;&#24341;&#20837;&#20102;Unlearning&#31639;&#27861;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#20102;&#35299;Unlearning&#22312;&#32852;&#24819;&#35760;&#24518;&#27169;&#22411;&#21644;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#26368;&#21021;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Unlearning&#31639;&#27861;&#21487;&#20197;&#31616;&#21270;&#20026;&#20174;&#20855;&#26377;&#29305;&#23450;&#20869;&#37096;&#30456;&#20851;&#24615;&#30340;&#22122;&#22768;&#31034;&#20363;&#20013;&#23398;&#20064;&#30340;&#32447;&#24615;&#24863;&#30693;&#22120;&#27169;&#22411;&#12290;&#32467;&#26500;&#21270;&#35757;&#32451;&#25968;&#25454;&#30340;&#36873;&#25321;&#20351;&#24471;&#22312;&#24471;&#30410;&#20110;Unlearning&#30340;&#21516;&#26102;&#65292;&#32593;&#32476;&#20063;&#36973;&#36935;&#20102;&#36739;&#22823;&#30340;&#39640;&#35823;&#24046;&#23481;&#38480;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02537v1 Announce Type: cross  Abstract: Statistical mechanics has made significant contributions to the study of biological neural systems by modeling them as recurrent networks of interconnected units with adjustable interactions. Several algorithms have been proposed to optimize the neural connections to enable network tasks such as information storage (i.e. associative memory) and learning probability distributions from data (i.e. generative modeling). Among these methods, the Unlearning algorithm, aligned with emerging theories of synaptic plasticity, was introduced by John Hopfield and collaborators. The primary objective of this thesis is to understand the effectiveness of Unlearning in both associative memory models and generative models. Initially, we demonstrate that the Unlearning algorithm can be simplified to a linear perceptron model which learns from noisy examples featuring specific internal correlations. The selection of structured training data enables an as
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35013;&#37197;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20869;&#22312;&#32467;&#26500;&#21644;jets&#20960;&#20309;&#27010;&#24565;&#30340;&#20272;&#35745;Koopman&#31639;&#23376;&#30340;&#26032;&#26041;&#27861;JetDMD&#65292;&#36890;&#36807;&#26126;&#30830;&#30340;&#35823;&#24046;&#30028;&#21644;&#25910;&#25947;&#29575;&#35777;&#26126;&#20854;&#20248;&#36234;&#24615;&#65292;&#20026;Koopman&#31639;&#23376;&#30340;&#25968;&#20540;&#20272;&#35745;&#25552;&#20379;&#20102;&#26356;&#31934;&#30830;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#35013;&#37197;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#25193;&#23637;Koopman&#31639;&#23376;&#30340;&#27010;&#24565;&#65292;&#26377;&#21161;&#20110;&#28145;&#20837;&#29702;&#35299;&#20272;&#35745;&#30340;Koopman&#29305;&#24449;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.02524</link><description>&lt;p&gt;
&#22312;&#35013;&#37197;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20855;&#26377;&#20869;&#22312;&#21487;&#35266;&#27979;&#24615;&#30340;Koopman&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Koopman operators with intrinsic observables in rigged reproducing kernel Hilbert spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02524
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35013;&#37197;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20869;&#22312;&#32467;&#26500;&#21644;jets&#20960;&#20309;&#27010;&#24565;&#30340;&#20272;&#35745;Koopman&#31639;&#23376;&#30340;&#26032;&#26041;&#27861;JetDMD&#65292;&#36890;&#36807;&#26126;&#30830;&#30340;&#35823;&#24046;&#30028;&#21644;&#25910;&#25947;&#29575;&#35777;&#26126;&#20854;&#20248;&#36234;&#24615;&#65292;&#20026;Koopman&#31639;&#23376;&#30340;&#25968;&#20540;&#20272;&#35745;&#25552;&#20379;&#20102;&#26356;&#31934;&#30830;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#35013;&#37197;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#25193;&#23637;Koopman&#31639;&#23376;&#30340;&#27010;&#24565;&#65292;&#26377;&#21161;&#20110;&#28145;&#20837;&#29702;&#35299;&#20272;&#35745;&#30340;Koopman&#29305;&#24449;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#35013;&#37197;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#19978;&#23450;&#20041;&#30340;Koopman&#31639;&#23376;&#21450;&#20854;&#35889;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;Jet Dynamic Mode Decomposition&#65288;JetDMD&#65289;&#65292;&#21033;&#29992;RKHS&#30340;&#20869;&#22312;&#32467;&#26500;&#21644;&#31216;&#20026;jets&#30340;&#20960;&#20309;&#27010;&#24565;&#26469;&#22686;&#24378;Koopman&#31639;&#23376;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#31934;&#30830;&#24230;&#19978;&#20248;&#21270;&#20102;&#20256;&#32479;&#30340;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#65292;&#29305;&#21035;&#26159;&#22312;&#29305;&#24449;&#20540;&#30340;&#25968;&#20540;&#20272;&#35745;&#26041;&#38754;&#12290;&#26412;&#25991;&#36890;&#36807;&#26126;&#30830;&#30340;&#35823;&#24046;&#30028;&#21644;&#29305;&#27530;&#27491;&#23450;&#20869;&#26680;&#30340;&#25910;&#25947;&#29575;&#35777;&#26126;&#20102;JetDMD&#30340;&#20248;&#36234;&#24615;&#65292;&#20026;&#20854;&#24615;&#33021;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#25105;&#20204;&#36824;&#28145;&#20837;&#25506;&#35752;&#20102;Koopman&#31639;&#23376;&#30340;&#35889;&#20998;&#26512;&#65292;&#22312;&#35013;&#37197;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#25193;&#23637;Koopman&#31639;&#23376;&#30340;&#27010;&#24565;&#12290;&#36825;&#20010;&#27010;&#24565;&#26377;&#21161;&#20110;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#20272;&#35745;&#30340;Koopman&#29305;&#24449;&#20989;&#25968;&#24182;&#25429;&#25417;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02524v1 Announce Type: cross  Abstract: This paper presents a novel approach for estimating the Koopman operator defined on a reproducing kernel Hilbert space (RKHS) and its spectra. We propose an estimation method, what we call Jet Dynamic Mode Decomposition (JetDMD), leveraging the intrinsic structure of RKHS and the geometric notion known as jets to enhance the estimation of the Koopman operator. This method refines the traditional Extended Dynamic Mode Decomposition (EDMD) in accuracy, especially in the numerical estimation of eigenvalues. This paper proves JetDMD's superiority through explicit error bounds and convergence rate for special positive definite kernels, offering a solid theoretical foundation for its performance. We also delve into the spectral analysis of the Koopman operator, proposing the notion of extended Koopman operator within a framework of rigged Hilbert space. This notion leads to a deeper understanding of estimated Koopman eigenfunctions and captu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;Transformer&#27169;&#22411;&#24212;&#29992;&#20110;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#19968;&#20123;&#40723;&#33310;&#20154;&#24515;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.02523</link><description>&lt;p&gt;
&#21464;&#21387;&#22120;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#65306;&#20197;S&amp;P500&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Transformer for Times Series: an Application to the S&amp;P500
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02523
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;Transformer&#27169;&#22411;&#24212;&#29992;&#20110;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#19968;&#20123;&#40723;&#33310;&#20154;&#24515;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#21387;&#22120;&#27169;&#22411;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#21253;&#25324;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#22270;&#20687;&#29983;&#25104;&#31561;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#20004;&#31181;&#20856;&#22411;&#24773;&#20917;&#19979;&#30340;&#25968;&#25454;&#38598;&#26500;&#36896;&#65306;&#19968;&#31181;&#26159;&#22343;&#20540;&#22238;&#24402;&#30340;&#21512;&#25104;Ornstein-Uhlenbeck&#36807;&#31243;&#65292;&#21478;&#19968;&#31181;&#26159;&#30495;&#23454;&#30340;S&amp;P500&#25968;&#25454;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#25552;&#20986;&#30340;Transformer&#26550;&#26500;&#65292;&#26368;&#21518;&#35752;&#35770;&#20102;&#19968;&#20123;&#20196;&#20154;&#40723;&#33310;&#30340;&#32467;&#26524;&#12290;&#23545;&#20110;&#21512;&#25104;&#25968;&#25454;&#65292;&#25105;&#20204;&#33021;&#22815;&#30456;&#24403;&#20934;&#30830;&#22320;&#39044;&#27979;&#19979;&#19968;&#27493;&#30340;&#36208;&#21183;&#65292;&#32780;&#23545;&#20110;S&amp;P500&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20123;&#19982;&#20108;&#27425;&#21464;&#21160;&#21644;&#27874;&#21160;&#29575;&#39044;&#27979;&#30456;&#20851;&#30340;&#26377;&#36259;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02523v1 Announce Type: new  Abstract: The transformer models have been extensively used with good results in a wide area of machine learning applications including Large Language Models and image generation. Here, we inquire on the applicability of this approach to financial time series. We first describe the dataset construction for two prototypical situations: a mean reverting synthetic Ornstein-Uhlenbeck process on one hand and real S&amp;P500 data on the other hand. Then, we present in detail the proposed Transformer architecture and finally we discuss some encouraging results. For the synthetic data we predict rather accurately the next move, and for the S&amp;P500 we get some interesting results related to quadratic variation and volatility prediction.
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#26032;&#20852;&#34701;&#21512;&#65292;&#25506;&#35752;&#20102;&#32463;&#20856;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#19982;&#29616;&#20195;AI&#31561;&#20215;&#29289;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#28085;&#30422;&#20102;&#20351;&#29992;&#21452;&#37325;/&#21435;&#20559;&#31227;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#25512;&#26029;&#30340;&#20869;&#23481;&#12290;</title><link>https://arxiv.org/abs/2403.02467</link><description>&lt;p&gt;
&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#25512;&#21160;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Applied Causal Inference Powered by ML and AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#26032;&#20852;&#34701;&#21512;&#65292;&#25506;&#35752;&#20102;&#32463;&#20856;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#19982;&#29616;&#20195;AI&#31561;&#20215;&#29289;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#28085;&#30422;&#20102;&#20351;&#29992;&#21452;&#37325;/&#21435;&#20559;&#31227;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#25512;&#26029;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02467v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#20132;&#21449;&#25688;&#35201;&#65306;&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#26032;&#20852;&#34701;&#21512;&#12290;&#35813;&#20070;&#20171;&#32461;&#20102;&#32463;&#20856;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65288;SEMs&#65289;&#30340;&#24605;&#24819;&#21450;&#20854;&#29616;&#20195;&#20154;&#24037;&#26234;&#33021;&#31561;&#20215;&#29289;&#65292;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAGs&#65289;&#21644;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#65288;SCMs&#65289;&#65292;&#24182;&#28085;&#30422;&#20102;&#20351;&#29992;&#29616;&#20195;&#39044;&#27979;&#24037;&#20855;&#22312;&#36825;&#20123;&#27169;&#22411;&#20013;&#36827;&#34892;&#25512;&#26029;&#30340;&#21452;&#37325;/&#21435;&#20559;&#31227;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02467v1 Announce Type: cross  Abstract: An introduction to the emerging fusion of machine learning and causal inference. The book presents ideas from classical structural equation models (SEMs) and their modern AI equivalent, directed acyclical graphs (DAGs) and structural causal models (SCMs), and covers Double/Debiased Machine Learning methods to do inference in such models using modern predictive tools.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27979;&#24230;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#30740;&#31350;&#20102;&#21442;&#25968;ML&#27169;&#22411;&#21644;&#39046;&#22495;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#20013;&#23398;&#20064;&#20195;&#29702;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#20285;&#29595;&#25910;&#25947;&#30340;&#31867;&#20284;&#27861;&#22270;&#24341;&#29702;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.02432</link><description>&lt;p&gt;
&#20851;&#20110;&#27979;&#24230;&#39044;&#22788;&#29702;&#23545;&#36890;&#29992;&#21442;&#25968;ML&#27169;&#22411;&#21644;&#36890;&#36807;&#39046;&#22495;&#33258;&#36866;&#24212;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the impact of measure pre-conditionings on general parametric ML models and transfer learning via domain adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02432
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27979;&#24230;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#30740;&#31350;&#20102;&#21442;&#25968;ML&#27169;&#22411;&#21644;&#39046;&#22495;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#20013;&#23398;&#20064;&#20195;&#29702;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#20285;&#29595;&#25910;&#25947;&#30340;&#31867;&#20284;&#27861;&#22270;&#24341;&#29702;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#29992;&#20110;&#29702;&#35299;&#22312;&#25968;&#25454;&#30053;&#24494;&#20462;&#25913;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20195;&#29702;&#30340;&#25910;&#25947;&#24615;&#12290; &#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#25910;&#25947;&#21487;&#20197;&#36890;&#36807;&#19968;&#31181;&#31867;&#20284;&#20110;&#27861;&#22270;&#24341;&#29702;&#30340;&#27169;&#25311;&#29702;&#35299;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#20285;&#29595;&#25910;&#25947;&#12290; &#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#25216;&#26415;&#22312;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#21644;&#39046;&#22495;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#30456;&#20851;&#24615;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02432v1 Announce Type: cross  Abstract: We study a new technique for understanding convergence of learning agents under small modifications of data. We show that such convergence can be understood via an analogue of Fatou's lemma which yields gamma-convergence. We show it's relevance and applications in general machine learning tasks and domain adaptation transfer learning.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#27491;&#21017;&#21270;&#27969;&#30340;&#20272;&#35745;&#22120;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#23545;&#21407;&#22987;&#25968;&#25454;&#36827;&#34892;&#20114;&#20449;&#24687;&#20272;&#35745;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.02187</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;&#27969;&#36827;&#34892;&#20114;&#20449;&#24687;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mutual Information Estimation via Normalizing Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02187
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#27491;&#21017;&#21270;&#27969;&#30340;&#20272;&#35745;&#22120;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#23545;&#21407;&#22987;&#25968;&#25454;&#36827;&#34892;&#20114;&#20449;&#24687;&#20272;&#35745;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#20272;&#35745;&#38382;&#39064;&#65292;&#21363;&#24341;&#20837;&#22522;&#20110;&#27491;&#21017;&#21270;&#27969;&#30340;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#23558;&#21407;&#22987;&#25968;&#25454;&#26144;&#23556;&#21040;&#20855;&#26377;&#24050;&#30693;&#20114;&#20449;&#24687;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#20102;&#21407;&#22987;&#25968;&#25454;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#12290;&#36890;&#36807;&#39640;&#32500;&#25968;&#25454;&#30340;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#20272;&#35745;&#22120;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02187v1 Announce Type: new  Abstract: We propose a novel approach to the problem of mutual information (MI) estimation via introducing normalizing flows-based estimator. The estimator maps original data to the target distribution with known closed-form expression for MI. We demonstrate that our approach yields MI estimates for the original data. Experiments with high-dimensional data are provided to show the advantages of the proposed estimator.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#65292;&#26368;&#22823;&#21270;&#25928;&#29575;&#24182;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.13852</link><description>&lt;p&gt;
&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Neural Control System for Continuous Glucose Monitoring and Maintenance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13852
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#65292;&#26368;&#22823;&#21270;&#25928;&#29575;&#24182;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#30340;&#33889;&#33796;&#31958;&#27700;&#24179;&#31649;&#29702;&#23545;&#20110;&#31958;&#23615;&#30149;&#24739;&#32773;&#33267;&#20851;&#37325;&#35201;&#65292;&#21487;&#20197;&#36991;&#20813;&#20005;&#37325;&#24182;&#21457;&#30151;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#21033;&#29992;&#24494;&#20998;&#39044;&#27979;&#25511;&#21046;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#21463;&#21040;&#22797;&#26434;&#31070;&#32463;&#31574;&#30053;&#21644;&#21487;&#21306;&#20998;&#24314;&#27169;&#30340;&#25351;&#23548;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#12290;&#36825;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#26368;&#22823;&#21270;&#25928;&#29575;&#65292;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#21644;&#25913;&#21892;&#20581;&#24247;&#32467;&#26524;&#65292;&#22914;&#32463;&#39564;&#21457;&#29616;&#25152;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13852v1 Announce Type: cross  Abstract: Precise glucose level management is pivotal for individuals with diabetes, averting severe complications. In this work, we introduce a novel neural control system for continuous glucose monitoring and maintenance, utilizing differential predictive control. Our system, guided by a sophisticated neural policy and differentiable modeling, dynamically adjusts insulin delivery in real-time, enhancing glucose optimization. This end-to-end approach maximizes efficiency, ensuring personalized care and improved health outcomes, as affirmed by empirical findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#65292;&#21487;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#38598;&#25104;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#25913;&#21892;&#24403;&#21069;&#32858;&#31867;&#20808;&#39564;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28165;&#26224;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#32858;&#31867;&#24615;&#33021;&#65292;&#23558;VMM&#19982;scVI&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;</title><link>https://arxiv.org/abs/2402.04412</link><description>&lt;p&gt;
VampPrior&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The VampPrior Mixture Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#65292;&#21487;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#38598;&#25104;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#25913;&#21892;&#24403;&#21069;&#32858;&#31867;&#20808;&#39564;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28165;&#26224;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#32858;&#31867;&#24615;&#33021;&#65292;&#23558;VMM&#19982;scVI&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;DLVMs&#65289;&#30340;&#32858;&#31867;&#20808;&#39564;&#38656;&#35201;&#39044;&#20808;&#23450;&#20041;&#32858;&#31867;&#30340;&#25968;&#37327;&#65292;&#24182;&#19988;&#23481;&#26131;&#21463;&#21040;&#36739;&#24046;&#30340;&#21021;&#22987;&#21270;&#30340;&#24433;&#21709;&#12290;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#21487;&#20197;&#36890;&#36807;&#21516;&#26102;&#25191;&#34892;&#38598;&#25104;&#21644;&#32858;&#31867;&#30340;&#26041;&#24335;&#26497;&#22823;&#22320;&#25913;&#36827;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;scRNA-seq&#20998;&#26512;&#12290;&#25105;&#20204;&#23558;VampPrior&#65288;Tomczak&#21644;Welling&#65292;2018&#65289;&#35843;&#25972;&#20026;Dirichlet&#36807;&#31243;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#24471;&#21040;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25512;&#29702;&#36807;&#31243;&#65292;&#20132;&#26367;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#21644;&#32463;&#39564;&#36125;&#21494;&#26031;&#65292;&#20197;&#28165;&#26970;&#22320;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#33719;&#24471;&#20102;&#26497;&#20855;&#31454;&#20105;&#21147;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;&#23558;VMM&#19982;&#24191;&#21463;&#27426;&#36814;&#30340;scRNA-seq&#38598;&#25104;&#26041;&#27861;scVI&#65288;Lopez&#31561;&#65292;2018&#65289;&#30456;&#32467;&#21512;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current clustering priors for deep latent variable models (DLVMs) require defining the number of clusters a-priori and are susceptible to poor initializations. Addressing these deficiencies could greatly benefit deep learning-based scRNA-seq analysis by performing integration and clustering simultaneously. We adapt the VampPrior (Tomczak &amp; Welling, 2018) into a Dirichlet process Gaussian mixture model, resulting in the VampPrior Mixture Model (VMM), a novel prior for DLVMs. We propose an inference procedure that alternates between variational inference and Empirical Bayes to cleanly distinguish variational and prior parameters. Using the VMM in a Variational Autoencoder attains highly competitive clustering performance on benchmark datasets. Augmenting scVI (Lopez et al., 2018), a popular scRNA-seq integration method, with the VMM significantly improves its performance and automatically arranges cells into biologically meaningful clusters.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#21644;&#25674;&#38144;&#21464;&#20998;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#29992;&#20110;&#21333;&#33218;&#35797;&#39564;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#30340;&#21327;&#21464;&#37327;&#35266;&#23519;&#65292;&#23454;&#29616;&#24739;&#32773;&#21305;&#37197;&#25110;&#30452;&#25509;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2311.03002</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#21464;&#37327;&#24314;&#27169;&#20174;&#21333;&#33218;&#35797;&#39564;&#20013;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Estimating treatment effects from single-arm trials via latent-variable modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03002
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#21644;&#25674;&#38144;&#21464;&#20998;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#29992;&#20110;&#21333;&#33218;&#35797;&#39564;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#30340;&#21327;&#21464;&#37327;&#35266;&#23519;&#65292;&#23454;&#29616;&#24739;&#32773;&#21305;&#37197;&#25110;&#30452;&#25509;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65288;RCTs&#65289;&#34987;&#25509;&#21463;&#20026;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#30340;&#26631;&#20934;&#65292;&#20294;&#30001;&#20110;&#20262;&#29702;&#21407;&#22240;&#21644;&#25104;&#26412;&#36807;&#39640;&#32780;&#19981;&#21487;&#34892;&#12290;&#21333;&#33218;&#35797;&#39564;&#65292;&#25152;&#26377;&#24739;&#32773;&#23646;&#20110;&#27835;&#30103;&#32452;&#65292;&#21487;&#33021;&#26159;&#19968;&#20010;&#21487;&#34892;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#38656;&#35201;&#35775;&#38382;&#22806;&#37096;&#23545;&#29031;&#32452;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35782;&#21035;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21487;&#20197;&#29992;&#20110;&#36825;&#31181;&#24773;&#20917;&#65292;&#24182;&#19988;&#36824;&#21487;&#20197;&#36890;&#36807;&#24314;&#27169;&#32467;&#26500;&#21270;&#32570;&#22833;&#27169;&#24335;&#26469;&#32771;&#34385;&#32570;&#22833;&#30340;&#21327;&#21464;&#37327;&#35266;&#23519;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#25674;&#38144;&#21464;&#20998;&#25512;&#26029;&#26469;&#23398;&#20064;&#26082;&#29305;&#23450;&#20110;&#32452;&#21448;&#21487;&#35782;&#21035;&#30340;&#20849;&#20139;&#28508;&#22312;&#34920;&#31034;&#65292;&#38543;&#21518;&#21487;&#29992;&#20110;&#65288;i&#65289;&#24739;&#32773;&#21305;&#37197;&#65292;&#22914;&#26524;&#27835;&#30103;&#32452;&#30340;&#27835;&#30103;&#32467;&#26524;&#19981;&#21487;&#29992;&#65292;&#25110;&#29992;&#20110;&#65288;ii&#65289;&#20551;&#23450;&#20004;&#32452;&#22343;&#26377;&#32467;&#26524;&#21487;&#29992;&#30340;&#30452;&#25509;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#20844;&#20849;&#22522;&#20934;&#21644;&#19968;&#20010;&#30001;&#24050;&#21457;&#34920;&#30340;RCT&#32452;&#25104;&#30340;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#35813;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.03002v2 Announce Type: replace  Abstract: Randomized controlled trials (RCTs) are the accepted standard for treatment effect estimation but they can be infeasible due to ethical reasons and prohibitive costs. Single-arm trials, where all patients belong to the treatment group, can be a viable alternative but require access to an external control group. We propose an identifiable deep latent-variable model for this scenario that can also account for missing covariate observations by modeling their structured missingness patterns. Our method uses amortized variational inference to learn both group-specific and identifiable shared latent representations, which can subsequently be used for {\em (i)} patient matching if treatment outcomes are not available for the treatment group, or for {\em (ii)} direct treatment effect estimation assuming outcomes are available for both groups. We evaluate the model on a public benchmark as well as on a data set consisting of a published RCT s
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#24178;&#39044;&#30446;&#26631;&#23450;&#20301;&#26041;&#27861;&#65292;GIT&#65292;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#33021;&#22815;&#36890;&#36807;&#20449;&#21495;&#26799;&#24230;&#20272;&#35745;&#22120;&#38477;&#20302;&#24178;&#39044;&#27425;&#25968;&#65292;&#22312;&#20302;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#20248;&#20110;&#31454;&#20105;&#22522;&#32447;&#12290;</title><link>https://arxiv.org/abs/2211.13715</link><description>&lt;p&gt;
&#30456;&#20449;&#24744;&#30340; $\nabla$: &#22522;&#20110;&#26799;&#24230;&#30340;&#24178;&#39044;&#30446;&#26631;&#23450;&#20301;&#29992;&#20110;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal Discovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.13715
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#24178;&#39044;&#30446;&#26631;&#23450;&#20301;&#26041;&#27861;&#65292;GIT&#65292;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#33021;&#22815;&#36890;&#36807;&#20449;&#21495;&#26799;&#24230;&#20272;&#35745;&#22120;&#38477;&#20302;&#24178;&#39044;&#27425;&#25968;&#65292;&#22312;&#20302;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#20248;&#20110;&#31454;&#20105;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#26159;&#31185;&#23398;&#20013;&#19968;&#39033;&#20855;&#26377;&#22522;&#30784;&#37325;&#35201;&#24615;&#30340;&#25361;&#25112;&#24615;&#20219;&#21153;&#12290;&#35266;&#27979;&#25968;&#25454;&#36890;&#24120;&#19981;&#36275;&#20197;&#21807;&#19968;&#30830;&#23450;&#31995;&#32479;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#34429;&#28982;&#36827;&#34892;&#24178;&#39044;&#65288;&#21363;&#23454;&#39564;&#65289;&#21487;&#20197;&#25913;&#21892;&#21487;&#35782;&#21035;&#24615;&#65292;&#20294;&#36825;&#20123;&#26679;&#26412;&#36890;&#24120;&#38590;&#20197;&#33719;&#24471;&#19988;&#25104;&#26412;&#39640;&#26114;&#12290;&#22240;&#27492;&#65292;&#22240;&#26524;&#21457;&#29616;&#30340;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#20272;&#35745;&#26368;&#20855;&#20449;&#24687;&#24615;&#30340;&#24178;&#39044;&#30446;&#26631;&#26469;&#26368;&#23567;&#21270;&#24178;&#39044;&#27425;&#25968;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#24178;&#39044;&#30446;&#26631;&#23450;&#20301;&#26041;&#27861;&#65292;&#31616;&#31216;&#20026;GIT&#65292;&#23427;&#8216;&#30456;&#20449;&#8217;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#22240;&#26524;&#21457;&#29616;&#26694;&#26550;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#20197;&#25552;&#20379;&#24178;&#39044;&#37319;&#38598;&#20989;&#25968;&#30340;&#20449;&#21495;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#24182;&#35777;&#26126;GIT&#22312;&#20302;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#34920;&#29616;&#19982;&#31454;&#20105;&#22522;&#32447;&#30456;&#24403;&#65292;&#29978;&#33267;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.13715v4 Announce Type: replace-cross  Abstract: Inferring causal structure from data is a challenging task of fundamental importance in science. Observational data are often insufficient to identify a system's causal structure uniquely. While conducting interventions (i.e., experiments) can improve the identifiability, such samples are usually challenging and expensive to obtain. Hence, experimental design approaches for causal discovery aim to minimize the number of interventions by estimating the most informative intervention target. In this work, we propose a novel Gradient-based Intervention Targeting method, abbreviated GIT, that 'trusts' the gradient estimator of a gradient-based causal discovery framework to provide signals for the intervention acquisition function. We provide extensive experiments in simulated and real-world datasets and demonstrate that GIT performs on par with competitive baselines, surpassing them in the low-data regime.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#8220;&#35299;&#37322;&#20132;&#20114;&#23398;&#20064;&#8221;(XIL)&#23398;&#20064;&#35774;&#32622;&#65292;&#30740;&#31350;&#32773;&#21487;&#20197;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20132;&#20114;&#65292;&#26377;&#21161;&#20110;&#36991;&#20813;&#20854;&#21033;&#29992;&#28151;&#28102;&#22240;&#32032;&#32780;&#23548;&#33268;&#30340;&#39640;&#24615;&#33021;&#65292;&#21516;&#26102;&#22686;&#24378;&#23545;&#27169;&#22411;&#30340;&#20449;&#20219;&#12290;</title><link>https://arxiv.org/abs/2001.05371</link><description>&lt;p&gt;
&#36890;&#36807;&#19982;&#35299;&#37322;&#36827;&#34892;&#20132;&#20114;&#65292;&#20351;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20986;&#20110;&#27491;&#30830;&#30340;&#31185;&#23398;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
Making deep neural networks right for the right scientific reasons by interacting with their explanations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2001.05371
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#8220;&#35299;&#37322;&#20132;&#20114;&#23398;&#20064;&#8221;(XIL)&#23398;&#20064;&#35774;&#32622;&#65292;&#30740;&#31350;&#32773;&#21487;&#20197;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20132;&#20114;&#65292;&#26377;&#21161;&#20110;&#36991;&#20813;&#20854;&#21033;&#29992;&#28151;&#28102;&#22240;&#32032;&#32780;&#23548;&#33268;&#30340;&#39640;&#24615;&#33021;&#65292;&#21516;&#26102;&#22686;&#24378;&#23545;&#27169;&#22411;&#30340;&#20449;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#23427;&#20204;&#21487;&#33021;&#20250;&#34920;&#29616;&#20986;&#8220;&#32874;&#26126;&#30340;&#27721;&#26031;&#8221;&#24335;&#30340;&#34892;&#20026;&#65292;&#21033;&#29992;&#25968;&#25454;&#38598;&#20013;&#30340;&#28151;&#28102;&#22240;&#32032;&#20197;&#23454;&#29616;&#39640;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#8220;&#35299;&#37322;&#20132;&#20114;&#23398;&#20064;&#8221;(XIL)&#30340;&#26032;&#22411;&#23398;&#20064;&#35774;&#32622;&#65292;&#24182;&#22312;&#26893;&#29289;&#34920;&#22411;&#30740;&#31350;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#22909;&#22788;&#12290;XIL&#23558;&#31185;&#23398;&#23478;&#24341;&#20837;&#35757;&#32451;&#24490;&#29615;&#65292;&#20351;&#22905;&#36890;&#36807;&#23545;&#27169;&#22411;&#35299;&#37322;&#30340;&#21453;&#39304;&#36827;&#34892;&#20132;&#20114;&#24335;&#20462;&#35746;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;XIL&#21487;&#20197;&#24110;&#21161;&#36991;&#20813;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#8220;&#32874;&#26126;&#27721;&#26031;&#8221;&#26102;&#21051;&#65292;&#24182;&#40723;&#21169;&#65288;&#25110;&#40723;&#21169;&#65292;&#22914;&#26524;&#21512;&#36866;&#30340;&#35805;&#65289;&#23545;&#22522;&#30784;&#27169;&#22411;&#30340;&#20449;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2001.05371v4 Announce Type: replace-cross  Abstract: Deep neural networks have shown excellent performances in many real-world applications. Unfortunately, they may show "Clever Hans"-like behavior -- making use of confounding factors within datasets -- to achieve high performance. In this work, we introduce the novel learning setting of "explanatory interactive learning" (XIL) and illustrate its benefits on a plant phenotyping research task. XIL adds the scientist into the training loop such that she interactively revises the original model via providing feedback on its explanations. Our experimental results demonstrate that XIL can help avoiding Clever Hans moments in machine learning and encourages (or discourages, if appropriate) trust into the underlying model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#22914;&#26524;&#22270;&#26159;&#26681;&#25454;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23454;&#29616;Pair-Matching&#38382;&#39064;&#20013;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;</title><link>https://arxiv.org/abs/1905.07342</link><description>&lt;p&gt;
Pair-Matching: Links Prediction with Adaptive Queries
&lt;/p&gt;
&lt;p&gt;
Pair-Matching: Links Prediction with Adaptive Queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1905.07342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#22914;&#26524;&#22270;&#26159;&#26681;&#25454;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23454;&#29616;Pair-Matching&#38382;&#39064;&#20013;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Pair-Matching&#38382;&#39064;&#20986;&#29616;&#22312;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#20854;&#20013;&#19968;&#20010;&#24819;&#35201;&#21457;&#29616;&#23454;&#20307;&#25110;&#20010;&#20307;&#20043;&#38388;&#33391;&#22909;&#21305;&#37197;&#30340;&#24773;&#20917;&#12290;&#24418;&#24335;&#19978;&#65292;&#20010;&#20307;&#38598;&#21512;&#30001;&#22270;&#30340;&#33410;&#28857;&#34920;&#31034;&#65292;&#20854;&#20013;&#36793;&#65292;&#36215;&#21021;&#26410;&#34987;&#35266;&#23519;&#21040;&#65292;&#34920;&#31034;&#33391;&#22909;&#30340;&#21305;&#37197;&#12290;&#31639;&#27861;&#26597;&#35810;&#33410;&#28857;&#23545;&#24182;&#35266;&#23519;&#36793;&#30340;&#23384;&#22312;/&#19981;&#23384;&#22312;&#12290;&#20854;&#30446;&#26631;&#26159;&#22312;&#22266;&#23450;&#30340;&#26597;&#35810;&#39044;&#31639;&#19979;&#23613;&#21487;&#33021;&#22810;&#22320;&#21457;&#29616;&#36793;&#12290;Pair-Matching&#26159;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#30340;&#19968;&#20010;&#29305;&#27530;&#23454;&#20363;&#65292;&#20854;&#20013;&#25163;&#33218;&#26159;&#20010;&#20307;&#23545;&#65292;&#22870;&#21169;&#26159;&#36830;&#25509;&#36825;&#20123;&#23545;&#30340;&#36793;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#36825;&#20010;&#32769;&#34382;&#26426;&#38382;&#39064;&#26159;&#38750;&#26631;&#20934;&#30340;&#65292;&#22240;&#20026;&#27599;&#20010;&#25163;&#33218;&#21482;&#33021;&#29609;&#19968;&#27425;&#12290; &#37492;&#20110;&#36825;&#26368;&#21518;&#19968;&#20010;&#32422;&#26463;&#65292;&#21482;&#26377;&#22312;&#22270;&#20855;&#26377;&#19968;&#23450;&#30340;&#22522;&#26412;&#32467;&#26500;&#26102;&#25165;&#21487;&#20197;&#39044;&#26399;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#22312;&#22270;&#26681;&#25454;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23454;&#29616;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1905.07342v3 Announce Type: replace-cross  Abstract: The pair-matching problem appears in many applications where one wants to discover good matches between pairs of entities or individuals. Formally, the set of individuals is represented by the nodes of a graph where the edges, unobserved at first, represent the good matches. The algorithm queries pairs of nodes and observes the presence/absence of edges. Its goal is to discover as many edges as possible with a fixed budget of queries. Pair-matching is a particular instance of multi-armed bandit problem in which the arms are pairs of individuals and the rewards are edges linking these pairs. This bandit problem is non-standard though, as each arm can only be played once.   Given this last constraint, sublinear regret can be expected only if the graph presents some underlying structure. This paper shows that sublinear regret is achievable in the case where the graph is generated according to a Stochastic Block Model (SBM) with tw
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;FSFC&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#22312;&#20855;&#26377;&#20998;&#31867;&#21709;&#24212;&#21644;&#32437;&#21521;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#36827;&#34892;&#21151;&#33021;&#25968;&#25454;&#29305;&#24449;&#36873;&#25321;&#21644;&#20998;&#31867;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.05765</link><description>&lt;p&gt;
&#21151;&#33021;&#25968;&#25454;&#20998;&#31867;&#30340;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Feature Selection for Functional Data Classification. (arXiv:2401.05765v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;FSFC&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#22312;&#20855;&#26377;&#20998;&#31867;&#21709;&#24212;&#21644;&#32437;&#21521;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#36827;&#34892;&#21151;&#33021;&#25968;&#25454;&#29305;&#24449;&#36873;&#25321;&#21644;&#20998;&#31867;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21151;&#33021;&#25968;&#25454;&#20998;&#26512;&#24050;&#32463;&#25104;&#20026;&#35768;&#22810;&#38656;&#35201;&#25972;&#21512;&#21644;&#35299;&#37322;&#22797;&#26434;&#25968;&#25454;&#30340;&#24403;&#20195;&#31185;&#23398;&#39046;&#22495;&#20013;&#30340;&#20851;&#38190;&#24037;&#20855;&#12290;&#27492;&#22806;&#65292;&#26032;&#25216;&#26415;&#30340;&#20986;&#29616;&#20419;&#36827;&#20102;&#22823;&#37327;&#32437;&#21521;&#21464;&#37327;&#30340;&#25910;&#38598;&#65292;&#20351;&#24471;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#36991;&#20813;&#36807;&#25311;&#21512;&#21644;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;FSFC&#65288;&#21151;&#33021;&#20998;&#31867;&#29305;&#24449;&#36873;&#25321;&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#22312;&#20855;&#26377;&#20998;&#31867;&#21709;&#24212;&#21644;&#32437;&#21521;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#36827;&#34892;&#21151;&#33021;&#25968;&#25454;&#29305;&#24449;&#36873;&#25321;&#21644;&#20998;&#31867;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#19968;&#20010;&#26032;&#23450;&#20041;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#23558;&#36923;&#36753;&#25439;&#22833;&#21644;&#21151;&#33021;&#29305;&#24449;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35782;&#21035;&#29992;&#20110;&#20998;&#31867;&#30340;&#26368;&#20851;&#38190;&#29305;&#24449;&#12290;&#20026;&#20102;&#35299;&#20915;&#26368;&#23567;&#21270;&#36807;&#31243;&#65292;&#25105;&#20204;&#20351;&#29992;&#21151;&#33021;&#20027;&#25104;&#20998;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;&#21452;&#22686;&#24191;Lagrange&#31639;&#27861;&#65292;&#21033;&#29992;&#20102;&#12290;&#12290;&#12290;
&lt;/p&gt;
&lt;p&gt;
Functional data analysis has emerged as a crucial tool in many contemporary scientific domains that require the integration and interpretation of complex data. Moreover, the advent of new technologies has facilitated the collection of a large number of longitudinal variables, making feature selection pivotal for avoiding overfitting and improving prediction performance. This paper introduces a novel methodology called FSFC (Feature Selection for Functional Classification), that addresses the challenge of jointly performing feature selection and classification of functional data in scenarios with categorical responses and longitudinal features. Our approach tackles a newly defined optimization problem that integrates logistic loss and functional features to identify the most crucial features for classification. To address the minimization procedure, we employ functional principal components and develop a new adaptive version of the Dual Augmented Lagrangian algorithm that leverages the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#40065;&#26834;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#20445;&#25345;&#36951;&#25022;&#27425;&#32447;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.19794</link><description>&lt;p&gt;
&#32447;&#24615;&#27169;&#22411;&#30340;&#40065;&#26834;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Robust Causal Bandits for Linear Models. (arXiv:2310.19794v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19794
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#40065;&#26834;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#20445;&#25345;&#36951;&#25022;&#27425;&#32447;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#31995;&#32479;&#20013;&#65292;&#20248;&#21270;&#22238;&#25253;&#20989;&#25968;&#30340;&#39034;&#24207;&#23454;&#39564;&#35774;&#35745;&#21487;&#20197;&#26377;&#25928;&#22320;&#24314;&#27169;&#20026;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39034;&#24207;&#24178;&#39044;&#35774;&#35745;&#12290;&#22312;&#24050;&#26377;&#30340;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#25991;&#29486;&#20013;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#20551;&#35774;&#26159;&#22240;&#26524;&#27169;&#22411;&#22312;&#26102;&#38388;&#19978;&#20445;&#25345;&#19981;&#21464;&#12290;&#28982;&#32780;&#65292;&#22312;&#22797;&#26434;&#31995;&#32479;&#20013;&#65292;&#25968;&#23398;&#27169;&#22411;&#24120;&#24120;&#21457;&#29983;&#26102;&#38388;&#19978;&#30340;&#27874;&#21160;&#65292;&#36825;&#20010;&#20551;&#35774;&#19981;&#19968;&#23450;&#25104;&#31435;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#22312;&#27169;&#22411;&#27874;&#21160;&#23384;&#22312;&#19979;&#30340;&#40065;&#26834;&#24615;&#12290;&#37325;&#28857;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411; (SEMs) &#30340;&#22240;&#26524;&#31995;&#32479;&#12290;SEMs &#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#24178;&#39044;&#21069;&#21518;&#32479;&#35745;&#27169;&#22411;&#22343;&#20026;&#26410;&#30693;&#12290;&#20197;&#32047;&#35745;&#36951;&#25022;&#20026;&#35774;&#35745;&#25351;&#26631;&#65292;&#22312;&#30693;&#36947;&#25972;&#20010;&#22240;&#26524;&#27169;&#22411;&#21450;&#20854;&#27874;&#21160;&#24773;&#20917;&#30340;&#31070;&#35861;&#30340;&#22522;&#30784;&#19978;&#65292;&#35774;&#35745;&#19968;&#31995;&#21015;&#24178;&#39044;&#20351;&#24471;&#32047;&#35745;&#36951;&#25022;&#26368;&#23567;&#21270;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#20445;&#25345;&#36951;&#25022;&#27425;&#32447;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential design of experiments for optimizing a reward function in causal systems can be effectively modeled by the sequential design of interventions in causal bandits (CBs). In the existing literature on CBs, a critical assumption is that the causal models remain constant over time. However, this assumption does not necessarily hold in complex systems, which constantly undergo temporal model fluctuations. This paper addresses the robustness of CBs to such model fluctuations. The focus is on causal systems with linear structural equation models (SEMs). The SEMs and the time-varying pre- and post-interventional statistical models are all unknown. Cumulative regret is adopted as the design criteria, based on which the objective is to design a sequence of interventions that incur the smallest cumulative regret with respect to an oracle aware of the entire causal model and its fluctuations. First, it is established that the existing approaches fail to maintain regret sub-linearity with 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#21644;&#35760;&#24518;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#27169;&#25968;&#31639;&#26415;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;&#32593;&#32476;&#21487;&#20197;&#21516;&#26102;&#35760;&#20303;&#25439;&#22351;&#30340;&#26631;&#31614;&#24182;&#23454;&#29616;100%&#30340;&#27867;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#35782;&#21035;&#21644;&#21098;&#26525;&#35760;&#24518;&#21270;&#30340;&#31070;&#32463;&#20803;&#26469;&#38477;&#20302;&#23545;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#65292;&#25552;&#39640;&#23545;&#26410;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.13061</link><description>&lt;p&gt;
&#21040;&#24213;&#26159;&#29702;&#35299;&#36824;&#26159;&#35760;&#24518;&#65306;&#35299;&#26512;&#31639;&#27861;&#25968;&#25454;&#38598;&#19978;&#30340;&#27867;&#21270;&#21644;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
To grok or not to grok: Disentangling generalization and memorization on corrupted algorithmic datasets. (arXiv:2310.13061v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#21644;&#35760;&#24518;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#27169;&#25968;&#31639;&#26415;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;&#32593;&#32476;&#21487;&#20197;&#21516;&#26102;&#35760;&#20303;&#25439;&#22351;&#30340;&#26631;&#31614;&#24182;&#23454;&#29616;100%&#30340;&#27867;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#35782;&#21035;&#21644;&#21098;&#26525;&#35760;&#24518;&#21270;&#30340;&#31070;&#32463;&#20803;&#26469;&#38477;&#20302;&#23545;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#65292;&#25552;&#39640;&#23545;&#26410;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#21487;&#35757;&#32451;&#21442;&#25968;&#38750;&#24120;&#22823;&#30340;&#24773;&#20917;&#19979;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#24456;&#38590;&#30693;&#36947;&#32593;&#32476;&#26159;&#21542;&#24050;&#32463;&#35760;&#20303;&#20102;&#19968;&#32452;&#29305;&#23450;&#30340;&#26679;&#26412;&#65292;&#36824;&#26159;&#29702;&#35299;&#20102;&#20854;&#20013;&#30340;&#22522;&#26412;&#35268;&#24459;&#65288;&#25110;&#32773;&#20004;&#32773;&#37117;&#26377;&#65289;&#12290;&#21463;&#21040;&#36825;&#20010;&#25361;&#25112;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#30340;&#27867;&#21270;&#34920;&#31034;&#21487;&#20197;&#36890;&#36807;&#20998;&#26512;&#26469;&#29702;&#35299;&#65292;&#24182;&#19988;&#24456;&#23481;&#26131;&#19982;&#35760;&#24518;&#24615;&#34920;&#31034;&#21306;&#20998;&#24320;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#27169;&#25968;&#31639;&#26415;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#65292;&#65288;&#958;&#183;100%&#65289;&#30340;&#26631;&#31614;&#26159;&#34987;&#25439;&#22351;&#30340;&#65288;&#21363;&#35757;&#32451;&#38598;&#20013;&#30340;&#19968;&#20123;&#27169;&#25968;&#36816;&#31639;&#32467;&#26524;&#26159;&#38169;&#35823;&#30340;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65306;&#65288;i&#65289;&#32593;&#32476;&#21487;&#20197;&#21516;&#26102;&#35760;&#20303;&#25439;&#22351;&#30340;&#26631;&#31614;&#24182;&#23454;&#29616;100%&#30340;&#27867;&#21270;&#65307;&#65288;ii&#65289;&#21487;&#20197;&#35782;&#21035;&#21644;&#21098;&#26525;&#35760;&#24518;&#21270;&#30340;&#31070;&#32463;&#20803;&#65292;&#38477;&#20302;&#23545;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#65292;&#25552;&#39640;&#23545;&#26410;&#25439;&#22351;&#25968;&#25454;&#30340;&#20934;&#30830;&#29575;&#65307;&#65288;iii&#65289;&#27491;&#21017;&#21270;&#26041;&#27861;&#22914;w
&lt;/p&gt;
&lt;p&gt;
Robust generalization is a major challenge in deep learning, particularly when the number of trainable parameters is very large. In general, it is very difficult to know if the network has memorized a particular set of examples or understood the underlying rule (or both). Motivated by this challenge, we study an interpretable model where generalizing representations are understood analytically, and are easily distinguishable from the memorizing ones. Namely, we consider two-layer neural networks trained on modular arithmetic tasks where ($\xi \cdot 100\%$) of labels are corrupted (\emph{i.e.} some results of the modular operations in the training set are incorrect). We show that (i) it is possible for the network to memorize the corrupted labels \emph{and} achieve $100\%$ generalization at the same time; (ii) the memorizing neurons can be identified and pruned, lowering the accuracy on corrupted data and improving the accuracy on uncorrupted data; (iii) regularization methods such as w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#34920;&#26684;LLP&#22522;&#20934;&#65292;&#22635;&#34917;&#20102;&#34920;&#26684;LLP&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#22312;&#35813;&#22522;&#20934;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#21019;&#24314;&#29305;&#24449;bags&#65292;&#20854;&#20013;&#25152;&#26377;&#23454;&#20363;&#20855;&#26377;&#30456;&#21516;&#30340;&#29305;&#24449;&#20540;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#27169;&#25311;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2310.10096</link><description>&lt;p&gt;
LLP-Bench&#65306;&#19968;&#31181;&#29992;&#20110;&#20174;&#26631;&#31614;&#27604;&#20363;&#20013;&#23398;&#20064;&#30340;&#22823;&#35268;&#27169;&#34920;&#26684;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label Proportions. (arXiv:2310.10096v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#34920;&#26684;LLP&#22522;&#20934;&#65292;&#22635;&#34917;&#20102;&#34920;&#26684;LLP&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#22312;&#35813;&#22522;&#20934;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#21019;&#24314;&#29305;&#24449;bags&#65292;&#20854;&#20013;&#25152;&#26377;&#23454;&#20363;&#20855;&#26377;&#30456;&#21516;&#30340;&#29305;&#24449;&#20540;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#27169;&#25311;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#20174;&#26631;&#31614;&#27604;&#20363;&#20013;&#23398;&#20064;&#65288;LLP&#65289;&#20219;&#21153;&#20013;&#65292;&#27169;&#22411;&#36890;&#36807;&#23545;&#23454;&#20363;&#32452;&#65288;&#31216;&#20026;bags&#65289;&#21644;&#30456;&#24212;&#30340;&#26631;&#31614;&#27604;&#20363;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#39044;&#27979;&#20010;&#20307;&#23454;&#20363;&#30340;&#26631;&#31614;&#12290;LLP&#20027;&#35201;&#24212;&#29992;&#20110;&#22270;&#20687;&#21644;&#34920;&#26684;&#20004;&#31181;&#25968;&#25454;&#38598;&#12290;&#22312;&#22270;&#20687;LLP&#20013;&#65292;&#36890;&#36807;&#20174;&#24213;&#23618;&#25968;&#25454;&#38598;&#20013;&#38543;&#26426;&#25277;&#26679;&#23454;&#20363;&#26469;&#21019;&#24314;&#22266;&#23450;&#22823;&#23567;&#30340;bags&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#21019;&#24314;&#30340;bags&#31216;&#20026;&#38543;&#26426;bags&#12290;&#23545;&#22270;&#20687;LLP&#30340;&#23454;&#39564;&#20027;&#35201;&#38598;&#20013;&#22312;CIFAR-*&#21644;MNIST&#25968;&#25454;&#38598;&#30340;&#38543;&#26426;bags&#19978;&#12290;&#23613;&#31649;&#34920;&#26684;LLP&#22312;&#38544;&#31169;&#25935;&#24863;&#24212;&#29992;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#23578;&#32570;&#20047;&#19968;&#20010;&#24320;&#25918;&#30340;&#12289;&#22823;&#35268;&#27169;&#30340;&#34920;&#26684;LLP&#22522;&#20934;&#12290;&#34920;&#26684;LLP&#30340;&#19968;&#20010;&#29420;&#29305;&#29305;&#24615;&#26159;&#33021;&#22815;&#21019;&#24314;&#29305;&#24449;bags&#65292;&#20854;&#20013;bag&#20013;&#30340;&#25152;&#26377;&#23454;&#20363;&#23545;&#20110;&#32473;&#23450;&#30340;&#29305;&#24449;&#20855;&#26377;&#30456;&#21516;&#30340;&#20540;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#24449;bags&#22312;&#23454;&#38469;&#30340;&#29616;&#23454;&#24212;&#29992;&#20013;&#38750;&#24120;&#24120;&#35265;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#34920;&#26684;LLP&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#22823;&#35268;&#27169;&#34920;&#26684;LLP&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the task of Learning from Label Proportions (LLP), a model is trained on groups (a.k.a bags) of instances and their corresponding label proportions to predict labels for individual instances. LLP has been applied pre-dominantly on two types of datasets - image and tabular. In image LLP, bags of fixed size are created by randomly sampling instances from an underlying dataset. Bags created via this methodology are called random bags. Experimentation on Image LLP has been mostly on random bags on CIFAR-* and MNIST datasets. Despite being a very crucial task in privacy sensitive applications, tabular LLP does not yet have a open, large scale LLP benchmark. One of the unique properties of tabular LLP is the ability to create feature bags where all the instances in a bag have the same value for a given feature. It has been shown in prior research that feature bags are very common in practical, real world applications [Chen et. al '23, Saket et. al. '22].  In this paper, we address the lac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24178;&#39044;&#22806;&#25512;&#30340;&#20219;&#21153;&#65292;&#35777;&#26126;&#20102;&#21487;&#35782;&#21035;&#30340;&#34920;&#31034;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#21363;&#20351;&#24178;&#39044;&#23545;&#32467;&#26524;&#20135;&#29983;&#38750;&#32447;&#24615;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.04295</link><description>&lt;p&gt;
&#35782;&#21035;&#24178;&#39044;&#22806;&#25512;&#30340;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Identifying Representations for Intervention Extrapolation. (arXiv:2310.04295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24178;&#39044;&#22806;&#25512;&#30340;&#20219;&#21153;&#65292;&#35777;&#26126;&#20102;&#21487;&#35782;&#21035;&#30340;&#34920;&#31034;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#21363;&#20351;&#24178;&#39044;&#23545;&#32467;&#26524;&#20135;&#29983;&#38750;&#32447;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35782;&#21035;&#21644;&#22240;&#26524;&#20851;&#31995;&#34920;&#31034;&#23398;&#20064;&#30340;&#21069;&#25552;&#26159;&#25913;&#36827;&#24403;&#21069;&#30340;&#34920;&#31034;&#23398;&#20064;&#33539;&#24335;&#65292;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#25110;&#40065;&#26834;&#24615;&#12290;&#23613;&#31649;&#22312;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#36817;&#26399;&#30340;&#36827;&#23637;&#65292;&#20294;&#20173;&#38656;&#35201;&#26356;&#22810;&#29702;&#35770;&#32467;&#26524;&#26469;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#20855;&#20307;&#20248;&#21183;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#24178;&#39044;&#22806;&#25512;&#30340;&#20219;&#21153;&#65306;&#39044;&#27979;&#24178;&#39044;&#22914;&#20309;&#24433;&#21709;&#32467;&#26524;&#65292;&#21363;&#20351;&#36825;&#20123;&#24178;&#39044;&#22312;&#35757;&#32451;&#26102;&#27809;&#26377;&#35266;&#23519;&#21040;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#35782;&#21035;&#30340;&#34920;&#31034;&#33021;&#22815;&#20026;&#36825;&#20010;&#20219;&#21153;&#25552;&#20379;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;&#20351;&#24178;&#39044;&#23545;&#32467;&#26524;&#20135;&#29983;&#38750;&#32447;&#24615;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#21253;&#25324;&#19968;&#20010;&#32467;&#26524;Y&#65292;&#35266;&#23519;&#21040;&#30340;&#29305;&#24449;X&#65292;&#36825;&#20123;&#29305;&#24449;&#26159;&#28508;&#22312;&#29305;&#24449;Z&#30340;&#38750;&#32447;&#24615;&#36716;&#25442;&#65292;&#20197;&#21450;&#24433;&#21709;Z&#30340;&#22806;&#29983;&#34892;&#20026;&#21464;&#37327;A&#12290;&#24178;&#39044;&#22806;&#25512;&#30340;&#30446;&#26631;&#26159;&#39044;&#27979;&#20301;&#20110;&#35757;&#32451;&#25903;&#25345;&#20043;&#22806;&#30340;A&#19978;&#30340;&#24178;&#39044;&#22914;&#20309;&#24433;&#21709;Y&#12290;&#22312;&#36825;&#37324;&#65292;&#22806;&#25512;&#21464;&#24471;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
The premise of identifiable and causal representation learning is to improve the current representation learning paradigm in terms of generalizability or robustness. Despite recent progress in questions of identifiability, more theoretical results demonstrating concrete advantages of these methods for downstream tasks are needed. In this paper, we consider the task of intervention extrapolation: predicting how interventions affect an outcome, even when those interventions are not observed at training time, and show that identifiable representations can provide an effective solution to this task even if the interventions affect the outcome non-linearly. Our setup includes an outcome Y, observed features X, which are generated as a non-linear transformation of latent features Z, and exogenous action variables A, which influence Z. The objective of intervention extrapolation is to predict how interventions on A that lie outside the training support of A affect Y. Here, extrapolation becom
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;ReLU-Like&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#22312;&#32039;&#33268;&#22495;&#19978;&#23558;$L^p$&#20989;&#25968;&#20174;$[0,1]^{d_x}$&#36924;&#36817;&#21040;$\mathbb R^{d_y}$&#25152;&#38656;&#30340;&#26368;&#23567;&#23485;&#24230;&#20026;$\max\{d_x,d_y,2\}$&#65292;&#20174;&#32780;&#34920;&#26126;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36924;&#36817;&#27604;&#22312;${\mathbb R^{d_x}}$&#19978;&#30340;&#36924;&#36817;&#26356;&#23481;&#26131;&#12290;&#21516;&#26102;&#65292;&#21033;&#29992;&#21253;&#25324;ReLU&#22312;&#20869;&#30340;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19968;&#33268;&#36924;&#36817;&#30340;&#26368;&#23567;&#23485;&#24230;&#19979;&#30028;&#20026;$w_{\min}\ge d_y+1$&#65288;&#24403;$d_x&lt;d_y\le2d_x$&#65289;&#12290;</title><link>http://arxiv.org/abs/2309.10402</link><description>&lt;p&gt;
&#20351;&#29992;ReLU&#32593;&#32476;&#22312;&#32039;&#33268;&#22495;&#19978;&#36827;&#34892;&#36890;&#29992;&#36924;&#36817;&#30340;&#26368;&#23567;&#23485;&#24230;
&lt;/p&gt;
&lt;p&gt;
Minimum width for universal approximation using ReLU networks on compact domain. (arXiv:2309.10402v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;ReLU-Like&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#22312;&#32039;&#33268;&#22495;&#19978;&#23558;$L^p$&#20989;&#25968;&#20174;$[0,1]^{d_x}$&#36924;&#36817;&#21040;$\mathbb R^{d_y}$&#25152;&#38656;&#30340;&#26368;&#23567;&#23485;&#24230;&#20026;$\max\{d_x,d_y,2\}$&#65292;&#20174;&#32780;&#34920;&#26126;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36924;&#36817;&#27604;&#22312;${\mathbb R^{d_x}}$&#19978;&#30340;&#36924;&#36817;&#26356;&#23481;&#26131;&#12290;&#21516;&#26102;&#65292;&#21033;&#29992;&#21253;&#25324;ReLU&#22312;&#20869;&#30340;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19968;&#33268;&#36924;&#36817;&#30340;&#26368;&#23567;&#23485;&#24230;&#19979;&#30028;&#20026;$w_{\min}\ge d_y+1$&#65288;&#24403;$d_x&lt;d_y\le2d_x$&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#36807;&#30740;&#31350;&#65292;&#38480;&#21046;&#23485;&#24230;&#32593;&#32476;&#30340;&#36890;&#29992;&#36924;&#36817;&#24615;&#36136;&#24050;&#32463;&#20316;&#20026;&#28145;&#24230;&#38480;&#21046;&#32593;&#32476;&#30340;&#32463;&#20856;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#30340;&#23545;&#20598;&#36827;&#34892;&#30740;&#31350;&#12290;&#24050;&#32463;&#26377;&#20960;&#27425;&#23581;&#35797;&#26469;&#34920;&#24449;&#20351;&#24471;&#36890;&#29992;&#36924;&#36817;&#24615;&#36136;&#25104;&#31435;&#30340;&#26368;&#23567;&#23485;&#24230;$w_{\min}$&#65292;&#20294;&#21482;&#26377;&#24456;&#23569;&#20960;&#20010;&#25214;&#21040;&#20102;&#30830;&#20999;&#30340;&#20540;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20174;$[0,1]^{d_x}$&#21040;$\mathbb R^{d_y}$&#30340;$L^p$&#20989;&#25968;&#30340;&#36890;&#29992;&#36924;&#36817;&#30340;&#26368;&#23567;&#23485;&#24230;&#65292;&#22914;&#26524;&#28608;&#27963;&#20989;&#25968;&#26159;ReLU-Like&#65288;&#20363;&#22914;ReLU&#65292;GELU&#65292;Softplus&#65289;&#65292;&#37027;&#20040;&#23427;&#30340;&#30830;&#20999;&#20540;&#26159;$\max\{d_x,d_y,2\}$&#12290;&#19982;&#24050;&#30693;&#30340;&#32467;&#26524;$w_{\min}=\max\{d_x+1,d_y\}$&#30456;&#27604;&#65292;&#24403;&#22495;&#20026;${\mathbb R^{d_x}}$&#26102;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#39318;&#27425;&#34920;&#26126;&#65292;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36924;&#36817;&#35201;&#27714;&#27604;&#22312;${\mathbb R^{d_x}}$&#19978;&#30340;&#35201;&#27714;&#26356;&#23567;&#12290;&#25105;&#20204;&#25509;&#19979;&#26469;&#21033;&#29992;&#21253;&#25324;ReLU&#22312;&#20869;&#30340;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#36827;&#34892;&#19968;&#33268;&#36924;&#36817;&#30340;&#26368;&#23567;&#23485;&#24230;$w_{\min}$&#35777;&#26126;&#20102;&#19968;&#20010;&#19979;&#30028;&#65306;&#22914;&#26524;$d_x&lt;d_y\le2d_x$&#65292;&#21017;$w_{\min}\ge d_y+1$&#12290;&#32467;&#21512;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#32467;&#26524;&#65292;&#36825;&#34920;&#26126;&#20102;&#19968;&#20010;&#20108;&#20998;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The universal approximation property of width-bounded networks has been studied as a dual of the classical universal approximation theorem for depth-bounded ones. There were several attempts to characterize the minimum width $w_{\min}$ enabling the universal approximation property; however, only a few of them found the exact values. In this work, we show that the minimum width for the universal approximation of $L^p$ functions from $[0,1]^{d_x}$ to $\mathbb R^{d_y}$ is exactly $\max\{d_x,d_y,2\}$ if an activation function is ReLU-Like (e.g., ReLU, GELU, Softplus). Compared to the known result $w_{\min}=\max\{d_x+1,d_y\}$ when the domain is ${\mathbb R^{d_x}}$, our result first shows that approximation on a compact domain requires smaller width than on ${\mathbb R^{d_x}}$. We next prove a lower bound on $w_{\min}$ for uniform approximation using general activation functions including ReLU: $w_{\min}\ge d_y+1$ if $d_x&lt;d_y\le2d_x$. Together with our first result, this shows a dichotomy be
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE) &#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36755;&#20837;&#26799;&#24230;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.02775</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#38598;&#21512;&#30340;&#36755;&#20837;&#26799;&#24230;&#22810;&#26679;&#24615;
&lt;/p&gt;
&lt;p&gt;
Input gradient diversity for neural network ensembles. (arXiv:2306.02775v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE) &#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36755;&#20837;&#26799;&#24230;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#38598;&#25104; (DE) &#36890;&#36807;&#23427;&#20204;&#30340;&#21151;&#33021;&#22810;&#26679;&#24615;&#22312;&#20934;&#30830;&#24615;&#12289;&#26657;&#20934;&#24615;&#21644;&#25269;&#25239;&#24178;&#25200;&#26041;&#38754;&#34920;&#29616;&#20986;&#27604;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029; (ParVI) &#26041;&#27861;&#36890;&#36807;&#22522;&#20110;&#32593;&#32476;&#30456;&#20284;&#24615;&#20869;&#26680;&#30340;&#25490;&#26021;&#39033;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#65292;&#26435;&#37325;&#31354;&#38388;&#25490;&#26021;&#26159;&#20302;&#25928;&#30340;&#65292;&#32780;&#30452;&#25509;&#21151;&#33021;&#31354;&#38388;&#25490;&#26021;&#34987;&#21457;&#29616;&#23545; DE &#30340;&#25913;&#36827;&#24456;&#23567;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#20123;&#22256;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110; ParVI &#30340;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE)&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#36755;&#20837;&#26799;&#24230;&#30340;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#12290;&#30001;&#20110;&#36755;&#20837;&#26799;&#24230;&#21807;&#19968;&#22320;&#30830;&#23450;&#20102;&#19968;&#20010;&#20989;&#25968;&#24182;&#19988;&#27604;&#26435;&#37325;&#23567;&#24471;&#22810;&#65292;&#25152;&#20197;&#36825;&#31181;&#26041;&#27861;&#20445;&#35777;&#20102;&#38598;&#21512;&#25104;&#21592;&#22312;&#21151;&#33021;&#19978;&#26159;&#19981;&#21516;&#30340;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#22810;&#26679;&#21270;&#36755;&#20837;&#26799;&#24230;&#40723;&#21169;&#27599;&#20010;&#32593;&#32476;&#23398;&#20064;&#19981;&#21516;&#30340;&#29305;&#24449;&#65292;&#36825;&#26377;&#26395;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Ensembles (DEs) demonstrate improved accuracy, calibration and robustness to perturbations over single neural networks partly due to their functional diversity. Particle-based variational inference (ParVI) methods enhance diversity by formalizing a repulsion term based on a network similarity kernel. However, weight-space repulsion is inefficient due to over-parameterization, while direct function-space repulsion has been found to produce little improvement over DEs. To sidestep these difficulties, we propose First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based on ParVI, which performs repulsion in the space of first-order input gradients. As input gradients uniquely characterize a function up to translation and are much smaller in dimension than the weights, this method guarantees that ensemble members are functionally different. Intuitively, diversifying the input gradients encourages each network to learn different features, which is expected to improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#65292;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#25552;&#39640;&#20102;&#20854;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2212.14411</link><description>&lt;p&gt;
&#36817;&#20284;&#26368;&#20248;&#30340;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#20855;&#26377;&#21487;&#33021;&#30456;&#20851;&#35266;&#27979;&#30340;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Near-Optimal Non-Parametric Sequential Tests and Confidence Sequences with Possibly Dependent Observations. (arXiv:2212.14411v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14411
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#65292;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#25552;&#39640;&#20102;&#20854;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#26816;&#39564;&#21644;&#20854;&#38544;&#21547;&#30340;&#32622;&#20449;&#21306;&#38388;&#22312;&#20219;&#24847;&#20572;&#27490;&#26102;&#38388;&#19979;&#37117;&#33021;&#25552;&#20379;&#28789;&#27963;&#30340;&#32479;&#35745;&#25512;&#26029;&#21644;&#21363;&#26102;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#24378;&#26377;&#21147;&#30340;&#20445;&#35777;&#20165;&#36866;&#29992;&#20110;&#22312;&#23454;&#36341;&#20013;&#20302;&#20272;&#25110;&#27987;&#24230;&#30028;&#38480;&#20026;&#22522;&#30784;&#30340;&#39034;&#24207;&#24207;&#21015;&#65292;&#32780;&#36825;&#20123;&#24207;&#21015;&#20855;&#26377;&#27425;&#20248;&#30340;&#25298;&#32477;&#26102;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#32599;&#23486;&#26031;&#65288;Robbins&#65289;1970&#24180;&#30340;&#24310;&#36831;&#21551;&#21160;&#27491;&#24577;&#28151;&#21512;&#39034;&#24207;&#27010;&#29575;&#27604;&#26816;&#39564;&#65292;&#24182;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#39318;&#20010;&#28176;&#36817;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#20854;&#20013;&#28176;&#36817;&#24615;&#36136;&#30001;&#27979;&#35797;&#30340;&#28903;&#20837;&#26102;&#38388;&#30830;&#23450;&#12290;&#31867;&#22411;I&#38169;&#35823;&#30340;&#32467;&#26524;&#20027;&#35201;&#20381;&#36182;&#20110;&#38789;&#24378;&#19981;&#21464;&#21407;&#29702;&#65292;&#24182;&#35777;&#26126;&#36825;&#20123;&#26816;&#39564;&#65288;&#21450;&#20854;&#38544;&#21547;&#30340;&#32622;&#20449;&#21306;&#38388;&#65289;&#20855;&#26377;&#25509;&#36817;&#25152;&#38656;&#945;&#27700;&#24179;&#30340;&#31867;&#22411;I&#38169;&#35823;&#29575;&#12290;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#30340;&#32467;&#26524;&#20027;&#35201;&#21033;&#29992;&#20102;&#19968;&#31181;&#21463;&#20234;&#34276;&#24341;&#29702;&#21551;&#21457;&#30340;&#24658;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential tests and their implied confidence sequences, which are valid at arbitrary stopping times, promise flexible statistical inference and on-the-fly decision making. However, strong guarantees are limited to parametric sequential tests that under-cover in practice or concentration-bound-based sequences that over-cover and have suboptimal rejection times. In this work, we consider \cite{robbins1970boundary}'s delayed-start normal-mixture sequential probability ratio tests, and we provide the first asymptotic type-I-error and expected-rejection-time guarantees under general non-parametric data generating processes, where the asymptotics are indexed by the test's burn-in time. The type-I-error results primarily leverage a martingale strong invariance principle and establish that these tests (and their implied confidence sequences) have type-I error rates approaching a desired $\alpha$-level. The expected-rejection-time results primarily leverage an identity inspired by It\^o's lemm
&lt;/p&gt;</description></item></channel></rss>