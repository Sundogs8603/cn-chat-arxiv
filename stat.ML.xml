<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861; Iterative Markovian Fitting&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#24230; Schr\"odinger&#26725;&#65288;SBs&#65289;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#29616;&#20986;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#26174;&#33879;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2303.16852</link><description>&lt;p&gt;
&#25193;&#25955;Schr\"odinger&#26725;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Diffusion Schr\"odinger Bridge Matching. (arXiv:2303.16852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861; Iterative Markovian Fitting&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#24230; Schr\"odinger&#26725;&#65288;SBs&#65289;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#29616;&#20986;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#36816;&#36755;&#38382;&#39064;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26377;&#30528;&#35768;&#22810;&#24212;&#29992;&#65292;&#20363;&#22914;&#26032;&#22411;&#30340;&#36136;&#37327;&#20256;&#36755;&#26041;&#27861;&#65292;&#22914;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65288;DDMs&#65289;&#21644;&#27969;&#21305;&#37197;&#27169;&#22411;&#65288;FMMs&#65289;&#65292;&#36890;&#36807;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#25110;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#23454;&#29616;&#36825;&#26679;&#30340;&#20256;&#36755;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#36817;&#20284;&#30830;&#23450;&#24615;&#21160;&#24577;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#26144;&#23556;&#26159;&#21487;&#21462;&#30340;&#65292;&#22240;&#20026;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#24615;&#36136;&#65292;&#20294; DDMs &#21644; FMMs &#24182;&#19981;&#33021;&#20445;&#35777;&#25552;&#20379;&#25509;&#36817; OT &#26144;&#23556;&#30340;&#20256;&#36755;&#12290;&#30456;&#21453;&#65292;Schr\"odinger&#26725;&#65288;SBs&#65289;&#35745;&#31639;&#38543;&#26426;&#21160;&#24577;&#26144;&#23556;&#65292;&#21487;&#20197;&#24674;&#22797;&#27491;&#21017;&#29109;&#29256;&#26412;&#30340; OT&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#25968;&#20540;&#26041;&#27861;&#36817;&#20284; SBs &#30340;&#32500;&#24230;&#32553;&#25918;&#24046;&#25110;&#22312;&#36845;&#20195;&#20013;&#31215;&#32047;&#35823;&#24046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#36845;&#20195;&#39532;&#23572;&#31185;&#22827;&#25311;&#21512;&#65292;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230; SB &#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#26041;&#27861;&#35774;&#35745;&#20026;&#19968;&#20010;&#36845;&#20195;&#36807;&#31243;&#65292;&#23558;&#32622;&#20449;&#20256;&#25773;&#25193;&#23637;&#21040; KL &#25955;&#24230;&#65292;&#21033;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#30830;&#20445;&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#30456;&#23545;&#20110;&#29616;&#26377;&#25104;&#26524;&#26041;&#27861;&#65292;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#37117;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving transport problems, i.e. finding a map transporting one given distribution to another, has numerous applications in machine learning. Novel mass transport methods motivated by generative modeling have recently been proposed, e.g. Denoising Diffusion Models (DDMs) and Flow Matching Models (FMMs) implement such a transport through a Stochastic Differential Equation (SDE) or an Ordinary Differential Equation (ODE). However, while it is desirable in many applications to approximate the deterministic dynamic Optimal Transport (OT) map which admits attractive properties, DDMs and FMMs are not guaranteed to provide transports close to the OT map. In contrast, Schr\"odinger bridges (SBs) compute stochastic dynamic mappings which recover entropy-regularized versions of OT. Unfortunately, existing numerical methods approximating SBs either scale poorly with dimension or accumulate errors across iterations. In this work, we introduce Iterative Markovian Fitting, a new methodology for solv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25237;&#24433;&#20984;&#32858;&#31867;&#27169;&#22411;&#65292;&#20855;&#26377;&#31751;&#24674;&#22797;&#20445;&#35777;&#21644;&#33391;&#22909;&#30340;&#40065;&#26834;&#24615;&#65292;&#22312;&#32858;&#31867;&#31934;&#24230;&#21644;&#21487;&#20280;&#32553;&#24615;&#26041;&#38754;&#20248;&#20110;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.16841</link><description>&lt;p&gt;
&#38543;&#26426;&#25237;&#24433;&#30340;&#20984;&#32858;&#31867;&#27169;&#22411;&#65306;&#21160;&#26426;&#65292;&#23454;&#29616;&#21644;&#31751;&#24674;&#22797;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Randomly Projected Convex Clustering Model: Motivation, Realization, and Cluster Recovery Guarantees. (arXiv:2303.16841v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25237;&#24433;&#20984;&#32858;&#31867;&#27169;&#22411;&#65292;&#20855;&#26377;&#31751;&#24674;&#22797;&#20445;&#35777;&#21644;&#33391;&#22909;&#30340;&#40065;&#26834;&#24615;&#65292;&#22312;&#32858;&#31867;&#31934;&#24230;&#21644;&#21487;&#20280;&#32553;&#24615;&#26041;&#38754;&#20248;&#20110;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25237;&#24433;&#20984;&#32858;&#31867;&#27169;&#22411;&#65292;&#29992;&#20110;&#23545;$\mathbb{R}^d$&#20013;&#30340;$n$&#20010;&#39640;&#32500;&#25968;&#25454;&#28857;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#20551;&#35774;&#36825;&#20123;&#28857;&#23384;&#22312;$K$&#20010;&#38544;&#34255;&#30340;&#31751;&#12290;&#19982;&#29992;&#20110;&#32858;&#31867;&#21407;&#22987;&#25968;&#25454;&#30340;&#20984;&#32858;&#31867;&#27169;&#22411;&#30456;&#27604;($d$&#32500;)&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#22914;&#26524;&#23384;&#22312;&#20984;&#32858;&#31867;&#27169;&#22411;&#30340;&#23436;&#32654;&#25286;&#20998;&#65292;&#37027;&#20040;&#36890;&#36807;&#23884;&#20837;&#32500;&#24230;$m=O(\epsilon^{-2}\log(n))$&#30340;&#38543;&#26426;&#25237;&#24433;&#20984;&#32858;&#31867;&#27169;&#22411;&#21487;&#20197;&#20445;&#30041;&#25286;&#20998;&#32467;&#26524;&#65292;&#20854;&#20013;$0 &lt; \epsilon &lt; 1$&#26159;&#19968;&#20123;&#32473;&#23450;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#23884;&#20837;&#32500;&#24230;&#21487;&#20197;&#25913;&#36827;&#20026;$O(\epsilon^{-2}\log(K))$&#65292;&#19981;&#21463;&#25968;&#25454;&#28857;&#25968;&#37327;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#36824;&#36890;&#36807;&#24191;&#27867;&#30340;&#25968;&#23383;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;&#38543;&#26426;&#25237;&#24433;&#20984;&#32858;&#31867;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#21331;&#36234;&#24615;&#33021;&#12290;&#26412;&#25991;&#20013;&#21576;&#29616;&#30340;&#25968;&#23383;&#23454;&#39564;&#32467;&#26524;&#36824;&#34920;&#26126;&#65292;&#38543;&#26426;&#25237;&#24433;&#20984;&#32858;&#31867;&#27169;&#22411;&#22312;&#32858;&#31867;&#31934;&#24230;&#21644;&#21487;&#20280;&#32553;&#24615;&#26041;&#38754;&#20248;&#20110;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a randomly projected convex clustering model for clustering a collection of $n$ high dimensional data points in $\mathbb{R}^d$ with $K$ hidden clusters. Compared to the convex clustering model for clustering original data with dimension $d$, we prove that, under some mild conditions, the perfect recovery of the cluster membership assignments of the convex clustering model, if exists, can be preserved by the randomly projected convex clustering model with embedding dimension $m = O(\epsilon^{-2}\log(n))$, where $0 &lt; \epsilon &lt; 1$ is some given parameter. We further prove that the embedding dimension can be improved to be $O(\epsilon^{-2}\log(K))$, which is independent of the number of data points. Extensive numerical experiment results will be presented in this paper to demonstrate the robustness and superior performance of the randomly projected convex clustering model. The numerical results presented in this paper also demonstrate that the randomly projected 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.16822</link><description>&lt;p&gt;
&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#20284;&#36817;&#31471;&#31639;&#27861;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
An inexact linearized proximal algorithm for a class of DC composite optimization problems and applications. (arXiv:2303.16822v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#31867;&#38382;&#39064;&#36890;&#24120;&#30001;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#30340;&#40065;&#26834;&#20998;&#35299;&#27169;&#22411;&#25512;&#23548;&#32780;&#26469;&#65292;&#26159;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#21644;&#20855;&#26377;&#38750;&#20809;&#28369;&#20998;&#37327;&#30340;DC&#35268;&#21010;&#30340;&#25193;&#23637;&#12290;&#38024;&#23545;&#36825;&#31867;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65288;iLPA&#65289;&#12290;&#31639;&#27861;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#30446;&#26631;&#20989;&#25968;&#30340;&#37096;&#20998;&#32447;&#24615;&#21270;&#65292;&#35745;&#31639;&#24378;&#20984;&#20027;&#23548;&#30340;&#38750;&#31934;&#30830;&#26368;&#23567;&#21270;&#20540;&#12290;&#36845;&#20195;&#24207;&#21015;&#30340;&#29983;&#25104;&#25910;&#25947;&#20110;&#28508;&#22312;&#20989;&#25968;&#30340;Kurdyka-{\L}ojasiewicz&#65288;KL&#65289;&#24615;&#36136;&#65292;&#22914;&#26524;&#28508;&#22312;&#20989;&#25968;&#22312;&#26497;&#38480;&#28857;&#22788;&#20855;&#26377;KL&#25351;&#25968;$1/2$&#30340;KL&#24615;&#36136;&#65292;&#21017;&#25910;&#25947;&#20855;&#26377;&#23616;&#37096;R&#32447;&#24615;&#36895;&#29575;&#12290;&#23545;&#20110;&#21518;&#19968;&#31181;&#20551;&#35774;&#65292;&#25105;&#20204;&#21033;&#29992;&#22797;&#21512;&#32467;&#26500;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#39564;&#35777;&#30340;&#26465;&#20214;&#65292;&#24182;&#38416;&#26126;&#20102;&#19982;&#20984;&#22797;&#21512;&#20248;&#21270;&#25152;&#20351;&#29992;&#30340;&#27491;&#21017;&#24615;&#30340;&#20851;&#31995;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#31471;&#31639;&#27861;&#24212;&#29992;&#20110;&#35299;&#20915;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#24352;&#37327;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;TRPCA&#65289;&#21644;&#24352;&#37327;&#40065;&#26834;&#20302;&#31209;&#24352;&#37327;&#23436;&#25104;&#65288;TRLRTC&#65289;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#26032;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with a class of DC composite optimization problems which, as an extension of the convex composite optimization problem and the DC program with nonsmooth components, often arises from robust factorization models of low-rank matrix recovery. For this class of nonconvex and nonsmooth problems, we propose an inexact linearized proximal algorithm (iLPA) which in each step computes an inexact minimizer of a strongly convex majorization constructed by the partial linearization of their objective functions. The generated iterate sequence is shown to be convergent under the Kurdyka-{\L}ojasiewicz (KL) property of a potential function, and the convergence admits a local R-linear rate if the potential function has the KL property of exponent $1/2$ at the limit point. For the latter assumption, we provide a verifiable condition by leveraging the composite structure, and clarify its relation with the regularity used for the convex composite optimization. Finally, the propose
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25512;&#23548;&#20986;&#24212;&#29992;&#20110;&#26377;&#38480;&#25968;&#25454;&#28857;&#23398;&#20064;&#27169;&#22411;&#30340;PAC-Bayesian&#35823;&#24046;&#30028;&#38480;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#24191;&#27867;&#30340;&#23398;&#20064;/&#31995;&#32479;&#36776;&#35782;&#31639;&#27861;&#25552;&#20379;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2303.16816</link><description>&lt;p&gt;
&#20174;&#32463;&#39564;&#25439;&#22833;&#20013;&#23398;&#20064;LTI-ss&#31995;&#32479;&#30340;PAC-Bayesian&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian bounds for learning LTI-ss systems with input from empirical loss. (arXiv:2303.16816v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25512;&#23548;&#20986;&#24212;&#29992;&#20110;&#26377;&#38480;&#25968;&#25454;&#28857;&#23398;&#20064;&#27169;&#22411;&#30340;PAC-Bayesian&#35823;&#24046;&#30028;&#38480;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#24191;&#27867;&#30340;&#23398;&#20064;/&#31995;&#32479;&#36776;&#35782;&#31639;&#27861;&#25552;&#20379;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24102;&#36755;&#20837;&#30340;&#32447;&#24615;&#26102;&#19981;&#21464;&#31995;&#32479;&#65288;LTI&#65289;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#65292;&#25512;&#23548;&#20986;&#19968;&#31181;&#27010;&#29575;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;-Bayesian&#35823;&#24046;&#30028;&#38480;&#12290;&#35813;&#30028;&#38480;&#24191;&#27867;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#29992;&#20110;&#34920;&#24449;&#20174;&#26377;&#38480;&#25968;&#25454;&#28857;&#23398;&#20064;&#30340;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#29305;&#21035;&#22320;&#65292;&#26412;&#25991;&#23548;&#20986;&#30340;&#30028;&#38480;&#23558;&#26410;&#26469;&#30340;&#24179;&#22343;&#39044;&#27979;&#35823;&#24046;&#19982;&#27169;&#22411;&#22312;&#23398;&#20064;&#25968;&#25454;&#19978;&#29983;&#25104;&#30340;&#39044;&#27979;&#35823;&#24046;&#32852;&#31995;&#36215;&#26469;&#12290;&#22240;&#27492;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#24191;&#27867;&#30340;&#23398;&#20064;/&#31995;&#32479;&#36776;&#35782;&#31639;&#27861;&#25552;&#20379;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;LTI&#31995;&#32479;&#26159;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#30340;&#19968;&#20010;&#23376;&#31867;&#65292;&#22240;&#27492;&#36825;&#20123;&#35823;&#24046;&#30028;&#38480;&#21487;&#33021;&#26159;PAC-Bayesian&#30028;&#38480;&#36866;&#29992;&#20110;RNN&#30340;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we derive a Probably Approxilmately Correct(PAC)-Bayesian error bound for linear time-invariant (LTI) stochastic dynamical systems with inputs. Such bounds are widespread in machine learning, and they are useful for characterizing the predictive power of models learned from finitely many data points. In particular, with the bound derived in this paper relates future average prediction errors with the prediction error generated by the model on the data used for learning. In turn, this allows us to provide finite-sample error bounds for a wide class of learning/system identification algorithms. Furthermore, as LTI systems are a sub-class of recurrent neural networks (RNNs), these error bounds could be a first step towards PAC-Bayesian bounds for RNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;$C^k$&#65288;&#22312;&#23454;&#21464;&#37327;&#24847;&#20041;&#19979;&#65289;&#30340;&#20989;&#25968;&#65292;&#20351;&#29992;&#20855;&#26377;&#21333;&#23618;&#38544;&#34255;&#23618;&#21644;$m$&#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20197;&#38169;&#35823;&#29575;$m^{-k/(2n)}$&#23558;&#20854;&#36924;&#36817;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#36873;&#21462;&#26435;&#20540;$\sigma_j,b_j\in\mathbb{C}$&#21644;$\rho_j\in\mathbb{C}^n$&#23545;$f$&#36830;&#32493;&#65292;&#37027;&#20040;&#33719;&#24471;&#30340;&#36924;&#36817;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2303.16813</link><description>&lt;p&gt;
&#27973;&#23618;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#23545;$C^k$-&#20989;&#25968;&#30340;&#26368;&#20248;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Optimal approximation of $C^k$-functions using shallow complex-valued neural networks. (arXiv:2303.16813v1 [math.FA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;$C^k$&#65288;&#22312;&#23454;&#21464;&#37327;&#24847;&#20041;&#19979;&#65289;&#30340;&#20989;&#25968;&#65292;&#20351;&#29992;&#20855;&#26377;&#21333;&#23618;&#38544;&#34255;&#23618;&#21644;$m$&#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20197;&#38169;&#35823;&#29575;$m^{-k/(2n)}$&#23558;&#20854;&#36924;&#36817;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#36873;&#21462;&#26435;&#20540;$\sigma_j,b_j\in\mathbb{C}$&#21644;$\rho_j\in\mathbb{C}^n$&#23545;$f$&#36830;&#32493;&#65292;&#37027;&#20040;&#33719;&#24471;&#30340;&#36924;&#36817;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#20351;&#29992;&#27973;&#23618;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#23545;&#22797;&#31435;&#26041;&#20307;&#19978;$C^k$&#65288;&#22312;&#23454;&#21464;&#37327;&#24847;&#20041;&#19979;&#65289;&#30340;&#20989;&#25968;&#36827;&#34892;&#36924;&#36817;&#30340;&#37327;&#21270;&#32467;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#21333;&#23618;&#38544;&#34255;&#23618;&#21644;$m$&#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21363;&#24418;&#22914;$z \mapsto \sum_{j=1}^m \sigma_j \cdot \phi\big(\rho_j^T z + b_j\big)$&#30340;&#32593;&#32476;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#21487;&#20197;&#20351;&#29992;&#36825;&#31181;&#24418;&#24335;&#30340;&#20989;&#25968;&#36924;&#36817;$C^k \left(\Omega_n;\mathbb{C}\right)$&#20013;&#30340;&#20219;&#20309;&#20989;&#25968;&#65292;&#24403;$m\to\infty$&#26102;&#35823;&#24046;&#20026;$m^{-k/(2n)}$.&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#36873;&#21462;&#26435;&#20540;$\sigma_j,b_j\in\mathbb{C}$&#21644;$\rho_j\in\mathbb{C}^n$&#23545;$f$&#36830;&#32493;&#24182;&#19988;&#22312;&#36825;&#31181;&#36830;&#32493;&#24615;&#20551;&#35774;&#19979;&#33719;&#24471;&#30340;&#36924;&#36817;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a quantitative result for the approximation of functions of regularity $C^k$ (in the sense of real variables) defined on the complex cube $\Omega_n := [-1,1]^n +i[-1,1]^n\subseteq \mathbb{C}^n$ using shallow complex-valued neural networks. Precisely, we consider neural networks with a single hidden layer and $m$ neurons, i.e., networks of the form $z \mapsto \sum_{j=1}^m \sigma_j \cdot \phi\big(\rho_j^T z + b_j\big)$ and show that one can approximate every function in $C^k \left( \Omega_n; \mathbb{C}\right)$ using a function of that form with error of the order $m^{-k/(2n)}$ as $m \to \infty$, provided that the activation function $\phi: \mathbb{C} \to \mathbb{C}$ is smooth but not polyharmonic on some non-empty open set. Furthermore, we show that the selection of the weights $\sigma_j, b_j \in \mathbb{C}$ and $\rho_j \in \mathbb{C}^n$ is continuous with respect to $f$ and prove that the derived rate of approximation is optimal under this continuity assumption. We also discuss
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#26435;&#20449;&#24687;&#30340;&#37325;&#22797;&#22238;&#24402;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#26657;&#27491;&#36873;&#25321;&#20559;&#24046;&#21644;&#32570;&#22833;&#21709;&#24212;&#65292;&#36825;&#31181;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#19988;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2303.16800</link><description>&lt;p&gt;
&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#26657;&#27491;&#22238;&#24402;&#20013;&#30340;&#36873;&#25321;&#20559;&#24046;&#21644;&#32570;&#22833;&#21709;&#24212;
&lt;/p&gt;
&lt;p&gt;
Correcting for Selection Bias and Missing Response in Regression using Privileged Information. (arXiv:2303.16800v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16800
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#26435;&#20449;&#24687;&#30340;&#37325;&#22797;&#22238;&#24402;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#26657;&#27491;&#36873;&#25321;&#20559;&#24046;&#21644;&#32570;&#22833;&#21709;&#24212;&#65292;&#36825;&#31181;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#19988;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#36827;&#34892;&#22238;&#24402;&#27169;&#22411;&#20272;&#35745;&#26102;&#65292;&#21487;&#33021;&#20250;&#20986;&#29616;&#19968;&#20123;&#26631;&#31614;&#32570;&#22833;&#30340;&#25968;&#25454;&#65292;&#25110;&#32773;&#25105;&#20204;&#30340;&#25968;&#25454;&#21487;&#33021;&#20250;&#21463;&#21040;&#36873;&#25321;&#26426;&#21046;&#30340;&#20559;&#24046;&#24433;&#21709;&#12290;&#24403;&#21709;&#24212;&#25110;&#36873;&#25321;&#26426;&#21046;&#26159;&#21487;&#24573;&#30053;&#30340;&#65288;&#21363;&#65292;&#22312;&#32473;&#23450;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#65292;&#29420;&#31435;&#20110;&#21709;&#24212;&#21464;&#37327;&#65289;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#22238;&#24402;&#26041;&#27861;&#65307;&#22312;&#19981;&#21487;&#24573;&#30053;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#24120;&#24517;&#39035;&#36827;&#34892;&#20559;&#24046;&#35843;&#25972;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#29305;&#26435;&#25968;&#25454;&#65288;&#21363;&#21482;&#22312;&#35757;&#32451;&#26399;&#38388;&#21487;&#29992;&#30340;&#25968;&#25454;&#65289;&#21487;&#33021;&#20250;&#20351;&#19981;&#21487;&#24573;&#30053;&#30340;&#36873;&#25321;&#26426;&#21046;&#21487;&#24573;&#30053;&#65292;&#24182;&#23558;&#36825;&#31181;&#24773;&#20917;&#31216;&#20026;&#29305;&#26435;&#32570;&#22833;&#38543;&#26426;&#65288;PMAR&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#25554;&#34917;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#31216;&#20026;&#37325;&#22797;&#22238;&#24402;&#65292;&#36866;&#29992;&#20110;PMAR&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#19968;&#31181;&#37325;&#35201;&#24615;&#21152;&#26435;&#22238;&#24402;&#26041;&#27861;&#21644;&#20004;&#31181;&#26041;&#27861;&#30340;&#21452;&#37325;&#31283;&#20581;&#32452;&#21512;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26131;&#20110;&#20351;&#29992;&#22823;&#22810;&#25968;&#27969;&#34892;&#30340;&#29616;&#25104;&#22238;&#24402;&#31639;&#27861;&#36827;&#34892;&#23454;&#29616;&#12290;&#25105;&#20204;&#36890;&#36807;&#22823;&#37327;&#30340;&#27169;&#25311;&#23454;&#39564;&#21644;&#23545;Eye State&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#35780;&#20272;&#26469;&#35780;&#20272;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
When estimating a regression model, we might have data where some labels are missing, or our data might be biased by a selection mechanism. When the response or selection mechanism is ignorable (i.e., independent of the response variable given the features) one can use off-the-shelf regression methods; in the nonignorable case one typically has to adjust for bias. We observe that privileged data (i.e. data that is only available during training) might render a nonignorable selection mechanism ignorable, and we refer to this scenario as Privilegedly Missing at Random (PMAR). We propose a novel imputation-based regression method, named repeated regression, that is suitable for PMAR. We also consider an importance weighted regression method, and a doubly robust combination of the two. The proposed methods are easy to implement with most popular out-of-the-box regression algorithms. We empirically assess the performance of the proposed methods with extensive simulated experiments and on a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#20013;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#29702;&#35770;&#19978;&#20445;&#35777;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20851;&#27880; Kullback - Leibler &#25955;&#24230;&#20013;&#30340;&#35268;&#33539;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#39057;&#32321;&#25628;&#32034;&#27491;&#21017;&#21270;&#30340;&#36229;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.16721</link><description>&lt;p&gt;
&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#20877;&#25506;&#65306;Kullback - Leibler &#25955;&#24230;&#20013;&#30340;&#35268;&#33539;&#23545;&#31216;&#24615;&#21644;&#24615;&#33021;&#20445;&#35777;&#30340;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Maximum likelihood method revisited: Gauge symmetry in Kullback -- Leibler divergence and performance-guaranteed regularization. (arXiv:2303.16721v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#20013;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#29702;&#35770;&#19978;&#20445;&#35777;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20851;&#27880; Kullback - Leibler &#25955;&#24230;&#20013;&#30340;&#35268;&#33539;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#39057;&#32321;&#25628;&#32034;&#27491;&#21017;&#21270;&#30340;&#36229;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#26159;&#20272;&#35745;&#25968;&#25454;&#32972;&#21518;&#27010;&#29575;&#30340;&#26368;&#30693;&#21517;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#26041;&#27861;&#33719;&#24471;&#19982;&#32463;&#39564;&#20998;&#24067;&#26368;&#25509;&#36817;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#23548;&#33268;&#36807;&#24230;&#25311;&#21512;&#12290;&#28982;&#21518;&#65292;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#38450;&#27490;&#27169;&#22411;&#36807;&#24230;&#25509;&#36817;&#38169;&#35823;&#30340;&#27010;&#29575;&#65292;&#20294;&#26159;&#23545;&#23427;&#20204;&#30340;&#24615;&#33021;&#30693;&#20043;&#29978;&#23569;&#12290;&#27491;&#21017;&#21270;&#30340;&#24605;&#24819;&#31867;&#20284;&#20110;&#32416;&#38169;&#20195;&#30721;&#65292;&#36890;&#36807;&#23558;&#27425;&#20248;&#35299;&#19982;&#38169;&#35823;&#25509;&#25910;&#21040;&#30340;&#20195;&#30721;&#28151;&#21512;&#65292;&#33719;&#24471;&#26368;&#20248;&#35299;&#30721;&#12290;&#32416;&#38169;&#20195;&#30721;&#20013;&#30340;&#26368;&#20248;&#35299;&#30721;&#26159;&#22522;&#20110;&#35268;&#33539;&#23545;&#31216;&#24615;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#20851;&#27880; Kullback - Leibler &#25955;&#24230;&#20013;&#30340;&#35268;&#33539;&#23545;&#31216;&#24615;&#65292;&#25552;&#20986;&#20102;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#20013;&#30340;&#29702;&#35770;&#19978;&#20445;&#35777;&#30340;&#27491;&#21017;&#21270;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#39057;&#32321;&#25628;&#32034;&#27491;&#21017;&#21270;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#36229;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The maximum likelihood method is the best-known method for estimating the probabilities behind the data. However, the conventional method obtains the probability model closest to the empirical distribution, resulting in overfitting. Then regularization methods prevent the model from being excessively close to the wrong probability, but little is known systematically about their performance. The idea of regularization is similar to error-correcting codes, which obtain optimal decoding by mixing suboptimal solutions with an incorrectly received code. The optimal decoding in error-correcting codes is achieved based on gauge symmetry. We propose a theoretically guaranteed regularization in the maximum likelihood method by focusing on a gauge symmetry in Kullback -- Leibler divergence. In our approach, we obtain the optimal model without the need to search for hyperparameters frequently appearing in regularization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;Hilbert-Valued&#21442;&#25968;&#36827;&#34892;&#19968;&#27493;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#36866;&#29992;&#20110;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.16711</link><description>&lt;p&gt;
Hilbert-Valued&#21442;&#25968;&#30340;&#19968;&#27493;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
One-Step Estimation of Differentiable Hilbert-Valued Parameters. (arXiv:2303.16711v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;Hilbert-Valued&#21442;&#25968;&#36827;&#34892;&#19968;&#27493;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#36866;&#29992;&#20110;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20809;&#28369;Hilbert-Valued&#21442;&#25968;&#30340;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#20809;&#28369;&#24615;&#30001;&#36880;&#36335;&#24452;&#21487;&#24494;&#26465;&#20214;&#34920;&#24449;&#12290;&#24403;&#21442;&#25968;&#31354;&#38388;&#26159;&#37325;&#29616;&#26680;Hilbert&#31354;&#38388;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#33719;&#21462;&#39640;&#25928;&#21644;&#30456;&#20851;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#23545;&#24212;&#20110;&#22522;&#20110;Hilbert-Valued&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#30340;&#20132;&#21449;&#19968;&#27493;&#20272;&#35745;&#22120;&#30340;&#27010;&#25324;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#21363;&#20351;&#20351;&#29992;&#20219;&#24847;&#30340;&#36741;&#21161;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#21253;&#25324;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21363;&#20351;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#65292;&#21482;&#35201;&#21442;&#25968;&#20855;&#26377;&#39640;&#25928;&#30340;&#24433;&#21709;&#20989;&#25968;&#65292;&#36825;&#20123;&#32467;&#26524;&#33258;&#28982;&#22320;&#21487;&#20197;&#25193;&#23637;&#21040;&#35813;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20063;&#25581;&#31034;&#20102;&#19981;&#24184;&#30340;&#20107;&#23454;&#65292;&#24403;&#19981;&#23384;&#22312;&#37325;&#29616;&#26680;&#26102;&#65292;&#35768;&#22810;&#26377;&#36259;&#30340;&#21442;&#25968;&#21363;&#20351;&#23427;&#20204;&#22312;&#36335;&#24452;&#19978;&#26159;&#21487;&#24494;&#30340;&#65292;&#20063;&#32570;&#20047;&#26377;&#25928;&#30340;&#24433;&#21709;&#20989;&#25968;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present estimators for smooth Hilbert-valued parameters, where smoothness is characterized by a pathwise differentiability condition. When the parameter space is a reproducing kernel Hilbert space, we provide a means to obtain efficient, root-n rate estimators and corresponding confidence sets. These estimators correspond to generalizations of cross-fitted one-step estimators based on Hilbert-valued efficient influence functions. We give theoretical guarantees even when arbitrary estimators of nuisance functions are used, including those based on machine learning techniques. We show that these results naturally extend to Hilbert spaces that lack a reproducing kernel, as long as the parameter has an efficient influence function. However, we also uncover the unfortunate fact that, when there is no reproducing kernel, many interesting parameters fail to have an efficient influence function, even though they are pathwise differentiable. To handle these cases, we propose a regularized on
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#30340;&#23616;&#37096;&#32447;&#24615;&#21270;&#27010;&#29575;&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#29305;&#24449;&#21270;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#65292;&#24182;&#19988;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16698</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#32447;&#24615;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#30340;&#23616;&#37096;&#32447;&#24615;&#21270;&#27010;&#29575;&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Probabilistic inverse optimal control with local linearization for non-linear partially observable systems. (arXiv:2303.16698v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#30340;&#23616;&#37096;&#32447;&#24615;&#21270;&#27010;&#29575;&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#29305;&#24449;&#21270;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#65292;&#24182;&#19988;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#29305;&#24449;&#21270;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24037;&#20316;&#35201;&#27714;&#24050;&#30693;&#25511;&#21046;&#20449;&#21495;&#65292;&#25110;&#32773;&#20165;&#38480;&#20110;&#23436;&#20840;&#21487;&#35266;&#27979;&#25110;&#32447;&#24615;&#31995;&#32479;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#27010;&#29575;&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#32447;&#24615;&#38543;&#26426;&#31995;&#32479;&#30340;&#20002;&#22833;&#25511;&#21046;&#20449;&#21495;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#65292;&#35813;&#26041;&#27861;&#32479;&#19968;&#20102;&#29616;&#26377;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#20195;&#29702;&#30340;&#24863;&#35273;&#21644;&#25511;&#21046;&#31995;&#32479;&#30340;&#22122;&#22768;&#29305;&#24449;&#30340;&#26174;&#24335;&#27169;&#22411;&#20197;&#21450;&#23616;&#37096;&#32447;&#24615;&#21270;&#25216;&#26415;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#36817;&#20284;&#20284;&#28982;&#20989;&#25968;&#65292;&#21487;&#20197;&#22312;&#21333;&#20010;&#27491;&#21521;&#20256;&#36882;&#20013;&#35745;&#31639;&#12290;&#25105;&#20204;&#22312;&#38543;&#26426;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#29256;&#26412;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#65292;&#23548;&#33322;&#20219;&#21153;&#21644;&#25163;&#21160;&#36798;&#21040;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#21487;&#29992;&#20110;&#27169;&#20223;&#23398;&#20064;&#21040;&#24863;&#35273;&#36816;&#21160;&#31070;&#32463;&#31185;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse optimal control methods can be used to characterize behavior in sequential decision-making tasks. Most existing work, however, requires the control signals to be known, or is limited to fully-observable or linear systems. This paper introduces a probabilistic approach to inverse optimal control for stochastic non-linear systems with missing control signals and partial observability that unifies existing approaches. By using an explicit model of the noise characteristics of the sensory and control systems of the agent in conjunction with local linearization techniques, we derive an approximate likelihood for the model parameters, which can be computed within a single forward pass. We evaluate our proposed method on stochastic and partially observable version of classic control tasks, a navigation task, and a manual reaching task. The proposed method has broad applicability, ranging from imitation learning to sensorimotor neuroscience.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;FLANDERS&#65292;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#33258;&#22238;&#24402;&#30340;&#32852;&#37030;&#23398;&#20064;&#32858;&#21512;&#26041;&#26696;&#65292;&#21487;&#20197;&#35782;&#21035;&#24694;&#24847;&#23458;&#25143;&#31471;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#25308;&#21344;&#24237;&#25915;&#20987;&#38450;&#24481;&#12290;</title><link>http://arxiv.org/abs/2303.16668</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#33258;&#22238;&#24402;&#30340;&#32852;&#37030;&#23398;&#20064;&#25308;&#21344;&#24237;&#23481;&#38169;&#32858;&#21512;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
A Byzantine-Resilient Aggregation Scheme for Federated Learning via Matrix Autoregression on Client Updates. (arXiv:2303.16668v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16668
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;FLANDERS&#65292;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#33258;&#22238;&#24402;&#30340;&#32852;&#37030;&#23398;&#20064;&#32858;&#21512;&#26041;&#26696;&#65292;&#21487;&#20197;&#35782;&#21035;&#24694;&#24847;&#23458;&#25143;&#31471;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#25308;&#21344;&#24237;&#25915;&#20987;&#38450;&#24481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;FLANDERS&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#32858;&#21512;&#26041;&#26696;&#65292;&#21487;&#20197;&#25269;&#24481;&#25308;&#21344;&#24237;&#25915;&#20987;&#12290;FLANDERS&#23558;&#27599;&#20010;FL&#36718;&#27425;&#20013;&#30001;&#23458;&#25143;&#31471;&#21457;&#36865;&#30340;&#26412;&#22320;&#27169;&#22411;&#26356;&#26032;&#35270;&#20026;&#30697;&#38453;&#20540;&#26102;&#38388;&#24207;&#21015;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#23558;&#23454;&#38469;&#35266;&#27979;&#19982;&#30001;&#30697;&#38453;&#33258;&#22238;&#24402;&#39044;&#27979;&#27169;&#22411;&#20272;&#35745;&#30340;&#35266;&#27979;&#36827;&#34892;&#27604;&#36739;&#65292;&#35782;&#21035;&#24694;&#24847;&#23458;&#25143;&#31471;&#20316;&#20026;&#36825;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#24322;&#24120;&#20540;&#12290;&#22312;&#19981;&#21516;FL&#35774;&#32622;&#19979;&#23545;&#22810;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;FLANDERS&#22312;&#25269;&#24481;&#25308;&#21344;&#24237;&#25915;&#20987;&#26041;&#38754;&#19982;&#26368;&#24378;&#22823;&#30340;&#22522;&#32447;&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#19982;&#29616;&#26377;&#30340;&#38450;&#24481;&#31574;&#30053;&#30456;&#27604;&#65292; FLANDERS&#21363;&#20351;&#22312;&#26497;&#20854;&#20005;&#37325;&#30340;&#25915;&#20987;&#22330;&#26223;&#19979;&#20173;&#28982;&#38750;&#24120;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose FLANDERS, a novel federated learning (FL) aggregation scheme robust to Byzantine attacks. FLANDERS considers the local model updates sent by clients at each FL round as a matrix-valued time series. Then, it identifies malicious clients as outliers of this time series by comparing actual observations with those estimated by a matrix autoregressive forecasting model. Experiments conducted on several datasets under different FL settings demonstrate that FLANDERS matches the robustness of the most powerful baselines against Byzantine clients. Furthermore, FLANDERS remains highly effective even under extremely severe attack scenarios, as opposed to existing defense strategies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#25324;&#20102;&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#20013;&#22522;&#20110;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#21807;&#19968;&#24615;&#38382;&#39064;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#30340;&#25193;&#23637;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.16535</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#20013;&#22522;&#20110;&#38750;&#32447;&#24615;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#30340;&#21407;&#21017;&#20998;&#31163;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Independent Component Analysis for Principled Disentanglement in Unsupervised Deep Learning. (arXiv:2303.16535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#25324;&#20102;&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#20013;&#22522;&#20110;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#21807;&#19968;&#24615;&#38382;&#39064;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#30340;&#25193;&#23637;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#22914;&#20309;&#25214;&#21040;&#26377;&#29992;&#30340;&#39640;&#32500;&#25968;&#25454;&#34920;&#31034;&#65292;&#21363;&#25152;&#35859;&#30340;&#8220;&#20998;&#31163;&#8221;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#32570;&#20047;&#36866;&#24403;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#22312;&#32447;&#24615;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#65288;ICA&#65289;&#22312;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#24182;&#19988;&#20855;&#26377;&#22522;&#20110;&#33391;&#23450;&#20041;&#30340;&#27010;&#29575;&#27169;&#22411;&#30340;&#21407;&#21017;&#24615;&#12290; &#28982;&#32780;&#65292;&#23558;ICA&#25193;&#23637;&#21040;&#38750;&#32447;&#24615;&#24773;&#20917;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#26840;&#25163;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#30001;&#20110;&#32570;&#20047;&#21487;&#35782;&#21035;&#24615;&#65292;&#21363;&#34920;&#31034;&#30340;&#21807;&#19968;&#24615;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#20351;&#29992;&#26102;&#38388;&#32467;&#26500;&#25110;&#26576;&#20123;&#36741;&#21161;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#25193;&#23637;&#12290;&#36825;&#20123;&#27169;&#22411;&#23454;&#38469;&#19978;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#22240;&#27492;&#24050;&#32463;&#24320;&#21457;&#20986;&#36234;&#26469;&#36234;&#22810;&#30340;&#31639;&#27861;&#12290;&#29305;&#21035;&#26159;&#19968;&#20123;&#33258;&#30417;&#30563;&#31639;&#27861;&#21487;&#20197;&#26174;&#31034;&#20986;&#20272;&#35745;&#38750;&#32447;&#24615;ICA&#65292;&#21363;&#20351;&#26368;&#21021;&#26159;&#20174;&#21551;&#21457;&#24335;&#35282;&#24230;&#25552;&#20986;&#30340;&#12290;&#26412;&#25991;&#24635;&#32467;&#20102;&#38750;&#32447;&#24615;ICA&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
A central problem in unsupervised deep learning is how to find useful representations of high-dimensional data, sometimes called "disentanglement". Most approaches are heuristic and lack a proper theoretical foundation. In linear representation learning, independent component analysis (ICA) has been successful in many applications areas, and it is principled, i.e. based on a well-defined probabilistic model. However, extension of ICA to the nonlinear case has been problematic due to the lack of identifiability, i.e. uniqueness of the representation. Recently, nonlinear extensions that utilize temporal structure or some auxiliary information have been proposed. Such models are in fact identifiable, and consequently, an increasing number of algorithms have been developed. In particular, some self-supervised algorithms can be shown to estimate nonlinear ICA, even though they have initially been proposed from heuristic perspectives. This paper reviews the state-of-the-art of nonlinear ICA 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#36845;&#20195;&#30340;Landing&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24378;&#21046;&#25191;&#34892;&#27491;&#20132;&#32422;&#26463;&#30340;&#21516;&#26102;&#39034;&#30021;&#22320;&#21560;&#24341;&#21040;&#27491;&#20132;&#32422;&#26463;&#27969;&#24418;&#19978;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#31181;&#31639;&#27861;&#20197;&#25903;&#25345;&#26031;&#25176;&#33778;&#23572;&#65288;Stiefel&#65289;&#27969;&#24418;&#65292;&#24182;&#25552;&#20379;&#20102;&#38543;&#26426;&#21644;&#26041;&#24046;&#32422;&#20943;&#31639;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#19982;&#40654;&#26364;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30456;&#21516;&#20294;&#38656;&#35201;&#26356;&#23569;&#30340;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2303.16510</link><description>&lt;p&gt;
&#22312;&#27491;&#20132;&#32422;&#26463;&#19979;&#30340;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#19981;&#21487;&#34892;&#30830;&#23450;&#24615;&#12289;&#38543;&#26426;&#21644;&#26041;&#24046;&#32422;&#20943;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Infeasible Deterministic, Stochastic, and Variance-Reduction Algorithms for Optimization under Orthogonality Constraints. (arXiv:2303.16510v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#36845;&#20195;&#30340;Landing&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24378;&#21046;&#25191;&#34892;&#27491;&#20132;&#32422;&#26463;&#30340;&#21516;&#26102;&#39034;&#30021;&#22320;&#21560;&#24341;&#21040;&#27491;&#20132;&#32422;&#26463;&#27969;&#24418;&#19978;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#31181;&#31639;&#27861;&#20197;&#25903;&#25345;&#26031;&#25176;&#33778;&#23572;&#65288;Stiefel&#65289;&#27969;&#24418;&#65292;&#24182;&#25552;&#20379;&#20102;&#38543;&#26426;&#21644;&#26041;&#24046;&#32422;&#20943;&#31639;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#19982;&#40654;&#26364;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30456;&#21516;&#20294;&#38656;&#35201;&#26356;&#23569;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#20132;&#32422;&#26463;&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#37117;&#20250;&#33258;&#28982;&#22320;&#20986;&#29616;&#65292;&#20174;&#20027;&#25104;&#20998;&#20998;&#26512;&#21040;&#40065;&#26834;&#24615;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20123;&#38382;&#39064;&#38656;&#35201;&#20351;&#29992;&#40654;&#26364;&#20248;&#21270;&#31639;&#27861;&#26469;&#27714;&#35299;&#65292;&#35813;&#31639;&#27861;&#22312;&#24378;&#21046;&#25191;&#34892;&#32422;&#26463;&#26102;&#26368;&#32791;&#36153;&#26102;&#38388;&#12290;&#26368;&#36817;&#65292;Ablin&#65286;Peyr\'e&#65288;2022&#65289;&#25552;&#20986;&#20102;Landing&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#24265;&#20215;&#36845;&#20195;&#26041;&#27861;&#65292;&#23427;&#19981;&#24378;&#21046;&#25191;&#34892;&#27491;&#20132;&#32422;&#26463;&#65292;&#20294;&#20250;&#20197;&#24179;&#28369;&#30340;&#26041;&#24335;&#21560;&#24341;&#21040;&#27969;&#24418;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;Landing&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#23454;&#29992;&#21644;&#29702;&#35770;&#21457;&#23637;&#12290;&#39318;&#20808;&#65292;&#35813;&#26041;&#27861;&#34987;&#25193;&#23637;&#21040;&#26031;&#25176;&#33778;&#23572;&#27969;&#24418;&#65292;&#21363;&#30697;&#24418;&#27491;&#20132;&#30697;&#38453;&#30340;&#38598;&#21512;&#12290;&#24403;&#25104;&#26412;&#20989;&#25968;&#26159;&#35768;&#22810;&#20989;&#25968;&#30340;&#24179;&#22343;&#20540;&#26102;&#65292;&#25105;&#20204;&#36824;&#32771;&#34385;&#38543;&#26426;&#21644;&#26041;&#24046;&#32422;&#20943;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#26377;&#36825;&#20123;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#23427;&#20204;&#30340;&#40654;&#26364;&#20248;&#21270;&#31639;&#27861;&#30456;&#21516;&#65292;&#21516;&#26102;&#38656;&#35201;&#26356;&#23569;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Orthogonality constraints naturally appear in many machine learning problems, from Principal Components Analysis to robust neural network training. They are usually solved using Riemannian optimization algorithms, which minimize the objective function while enforcing the constraint. However, enforcing the orthogonality constraint can be the most time-consuming operation in such algorithms. Recently, Ablin &amp; Peyr\'e (2022) proposed the Landing algorithm, a method with cheap iterations that does not enforce the orthogonality constraint but is attracted towards the manifold in a smooth manner. In this article, we provide new practical and theoretical developments for the landing algorithm. First, the method is extended to the Stiefel manifold, the set of rectangular orthogonal matrices. We also consider stochastic and variance reduction algorithms when the cost function is an average of many functions. We demonstrate that all these methods have the same rate of convergence as their Rieman
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#25351;&#25968;&#28608;&#27963;&#20989;&#25968;&#23450;&#20041;&#30340;&#31070;&#32463;&#20989;&#25968;&#26469;&#23454;&#29616;&#36807;&#21442;&#25968;&#21270;&#25351;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2303.16504</link><description>&lt;p&gt;
&#19968;&#31181;&#36807;&#21442;&#25968;&#21270;&#25351;&#25968;&#22238;&#24402;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
An Over-parameterized Exponential Regression. (arXiv:2303.16504v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16504
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#25351;&#25968;&#28608;&#27963;&#20989;&#25968;&#23450;&#20041;&#30340;&#31070;&#32463;&#20989;&#25968;&#26469;&#23454;&#29616;&#36807;&#21442;&#25968;&#21270;&#25351;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#30740;&#31350;&#24341;&#21457;&#20102;&#35768;&#22810;&#20851;&#27880;&#65292;&#26088;&#22312;&#36890;&#36807;&#36807;&#21442;&#25968;&#21270;&#23454;&#29616;&#31070;&#32463;&#32593;&#32476;&#25910;&#25947;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLM) &#39046;&#22495;&#30340;&#21457;&#23637;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#25351;&#25968;&#28608;&#27963;&#20989;&#25968;&#30340;&#20852;&#36259;&#65292;&#29305;&#21035;&#26159;&#22312;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#30340;&#24212;&#29992;&#12290;&#22312;&#25968;&#23398;&#19978;&#65292;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#28608;&#27963;&#20989;&#25968;&#23450;&#20041;&#31070;&#32463;&#20989;&#25968; $F: \mathbb{R}^{d \times m} \times \mathbb{R}^d \rightarrow \mathbb{R}$&#12290;&#32473;&#23450;&#19968;&#32452;&#24102;&#26631;&#31614;&#30340;&#25968;&#25454;&#28857; $\{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\} \subset \mathbb{R}^d \times \mathbb{R}$&#65292;&#20854;&#20013; $n$ &#34920;&#31034;&#25968;&#25454;&#30340;&#25968;&#37327;&#12290;&#36825;&#37324; $F(W(t),x)$ &#21487;&#20197;&#29992; $F(W(t),x) := \sum_{r=1}^m a_r \exp(\langle w_r, x \rangle)$ &#34920;&#31034;&#65292;&#20854;&#20013; $m$ &#34920;&#31034;&#31070;&#32463;&#20803;&#30340;&#25968;&#37327;&#65292;$w_r(t)$ &#26159;&#26102;&#38388; $t$ &#19978;&#30340;&#26435;&#37325;&#12290;&#22266;&#23450;&#26435;&#37325; $a_r$ &#22312;&#35757;&#32451;&#26399;&#38388;&#19981;&#20250;&#25913;&#21464;&#65292;&#36825;&#26159;&#25991;&#29486;&#20013;&#30340;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past few years, there has been a significant amount of research focused on studying the ReLU activation function, with the aim of achieving neural network convergence through over-parametrization. However, recent developments in the field of Large Language Models (LLMs) have sparked interest in the use of exponential activation functions, specifically in the attention mechanism.  Mathematically, we define the neural function $F: \mathbb{R}^{d \times m} \times \mathbb{R}^d \rightarrow \mathbb{R}$ using an exponential activation function. Given a set of data points with labels $\{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\} \subset \mathbb{R}^d \times \mathbb{R}$ where $n$ denotes the number of the data. Here $F(W(t),x)$ can be expressed as $F(W(t),x) := \sum_{r=1}^m a_r \exp(\langle w_r, x \rangle)$, where $m$ represents the number of neurons, and $w_r(t)$ are weights at time $t$. It's standard in literature that $a_r$ are the fixed weights and it's never changed during the trai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#21644;&#24230;&#37327;&#38544;&#31169;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#24471;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;&#65292;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#65292;&#19988;&#25193;&#23637;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#38544;&#31169;&#20998;&#26512;</title><link>http://arxiv.org/abs/2303.16372</link><description>&lt;p&gt;
&#35757;&#32451;&#25968;&#25454;&#37325;&#26500;&#30340;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Non-Asymptotic Lower Bounds For Training Data Reconstruction. (arXiv:2303.16372v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#21644;&#24230;&#37327;&#38544;&#31169;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#24471;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;&#65292;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#65292;&#19988;&#25193;&#23637;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#38544;&#31169;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19987;&#19994;&#23545;&#25163;&#36827;&#34892;&#35757;&#32451;&#25968;&#25454;&#37325;&#26500;&#25915;&#20987;&#26102;&#31169;&#26377;&#23398;&#20064;&#31639;&#27861;&#30340;&#35821;&#20041;&#20445;&#35777;&#24378;&#24230;&#12290;&#25105;&#20204;&#36890;&#36807;&#23548;&#20986;&#38750;&#28176;&#36827;&#37327;&#32423;&#19979;&#30028;&#26469;&#30740;&#31350;&#20102;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#21644;&#24230;&#37327;&#38544;&#31169;&#65288;mDP&#65289;&#30340;&#23398;&#20064;&#22120;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#30340;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#23545;mDP&#30340;&#20998;&#26512;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#12290;&#26412;&#25991;&#36827;&#19968;&#27493;&#23545;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#22914;DP-SGD&#21644;Projected Noisy SGD&#36827;&#34892;&#20102;&#24230;&#37327;&#24046;&#20998;&#38544;&#31169;&#30340;&#25193;&#23637;&#38544;&#31169;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate semantic guarantees of private learning algorithms for their resilience to training Data Reconstruction Attacks (DRAs) by informed adversaries. To this end, we derive non-asymptotic minimax lower bounds on the adversary's reconstruction error against learners that satisfy differential privacy (DP) and metric differential privacy (mDP). Furthermore, we demonstrate that our lower bound analysis for the latter also covers the high dimensional regime, wherein, the input data dimensionality may be larger than the adversary's query budget. Motivated by the theoretical improvements conferred by metric DP, we extend the privacy analysis of popular deep learning algorithms such as DP-SGD and Projected Noisy SGD to cover the broader notion of metric differential privacy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#21487;&#20197;&#20174;&#38543;&#26426;&#29366;&#24577;&#31354;&#38388;&#31995;&#32479;&#30340;&#19981;&#23436;&#25972;&#20449;&#24687;/&#25968;&#25454;&#20013;&#36827;&#34892;&#26497;&#22823;&#20284;&#28982;&#65288;ML&#65289;&#24179;&#28369;&#20272;&#35745;&#65292;&#25152;&#24471;&#21040;&#30340;&#20272;&#35745;&#32467;&#26524;&#27604;&#20256;&#32479;&#26041;&#27861;&#31934;&#24230;&#26356;&#39640;&#12290;&#31639;&#27861;&#22522;&#20110;EM&#26799;&#24230;&#31890;&#23376;&#31639;&#27861;&#65292;&#36882;&#24402;&#22320;&#36827;&#34892;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2303.16364</link><description>&lt;p&gt;
&#38544;&#34255;&#20449;&#24687;&#19979;&#22522;&#20110;&#26497;&#22823;&#20284;&#28982;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#24179;&#28369;&#20272;&#35745;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Maximum likelihood smoothing estimation in state-space models: An incomplete-information based approach. (arXiv:2303.16364v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#21487;&#20197;&#20174;&#38543;&#26426;&#29366;&#24577;&#31354;&#38388;&#31995;&#32479;&#30340;&#19981;&#23436;&#25972;&#20449;&#24687;/&#25968;&#25454;&#20013;&#36827;&#34892;&#26497;&#22823;&#20284;&#28982;&#65288;ML&#65289;&#24179;&#28369;&#20272;&#35745;&#65292;&#25152;&#24471;&#21040;&#30340;&#20272;&#35745;&#32467;&#26524;&#27604;&#20256;&#32479;&#26041;&#27861;&#31934;&#24230;&#26356;&#39640;&#12290;&#31639;&#27861;&#22522;&#20110;EM&#26799;&#24230;&#31890;&#23376;&#31639;&#27861;&#65292;&#36882;&#24402;&#22320;&#36827;&#34892;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Rauch &#65288;1963&#24180;&#65289;&#21644;et al.&#65288;1965&#24180;&#65289;&#30340;&#32463;&#20856;&#20316;&#21697;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38543;&#26426;&#29366;&#24577;&#31354;&#38388;&#31995;&#32479;&#30340;&#19981;&#23436;&#25972;&#20449;&#24687;/&#25968;&#25454;&#20013;&#36827;&#34892;&#26497;&#22823;&#20284;&#28982;&#65288;ML&#65289;&#24179;&#28369;&#20272;&#35745;&#30340;&#26032;&#26041;&#27861;&#12290;&#20171;&#32461;&#20102;&#19981;&#23436;&#25972;&#25968;&#25454;&#30340;&#24471;&#20998;&#20989;&#25968;&#21644;&#26465;&#20214;&#35266;&#27979;&#20449;&#24687;&#30697;&#38453;&#65292;&#24182;&#24314;&#31435;&#20102;&#23427;&#20204;&#30340;&#20998;&#24067;&#24335;&#36523;&#20221;&#12290;&#21033;&#29992;&#36825;&#20123;&#36523;&#20221;&#65292;&#25552;&#20986;&#20102;ML smoother $\widehat{x}_{k\vert n}^s =\argmax_{x_k} \log f(x_k,\widehat{x}_{k+1\vert n}^s, y_{0:n}\vert\theta)$&#65292;$k\leq n-1$&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21644;ML&#29366;&#24577;&#20272;&#35745;$\widehat{x}_k=\argmax_{x_k} \log f(x_k,y_{0:k}\vert\theta)$&#30456;&#27604;&#65292;ML&#24179;&#28369;&#20272;&#35745;&#22120;&#32473;&#20986;&#30340;&#29366;&#24577;$x_k$&#20272;&#35745;&#20855;&#26377;&#26356;&#23569;&#30340;&#26631;&#20934;&#35823;&#24046;&#65292;&#24182;&#19988;&#26356;&#31526;&#21512;&#23545;&#25968;&#20284;&#28982;&#12290;zhi&#12290;&#22522;&#20110;EM&#26799;&#24230;&#31890;&#23376;&#31639;&#27861;&#32473;&#20986;&#36882;&#24402;&#20272;&#35745;&#65292;&#35813;&#31639;&#27861;&#25193;&#23637;&#20102;\cite{Lange}&#30340;ML&#24179;&#28369;&#20272;&#35745;&#24037;&#20316;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#26126;&#30830;&#30340;&#36845;&#20195;&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper revisits classical works of Rauch (1963, et al. 1965) and develops a novel method for maximum likelihood (ML) smoothing estimation from incomplete information/data of stochastic state-space systems. Score function and conditional observed information matrices of incomplete data are introduced and their distributional identities are established. Using these identities, the ML smoother $\widehat{x}_{k\vert n}^s =\argmax_{x_k} \log f(x_k,\widehat{x}_{k+1\vert n}^s, y_{0:n}\vert\theta)$, $k\leq n-1$, is presented. The result shows that the ML smoother gives an estimate of state $x_k$ with more adherence of loglikehood having less standard errors than that of the ML state estimator $\widehat{x}_k=\argmax_{x_k} \log f(x_k,y_{0:k}\vert\theta)$, with $\widehat{x}_{n\vert n}^s=\widehat{x}_n$. Recursive estimation is given in terms of an EM-gradient-particle algorithm which extends the work of \cite{Lange} for ML smoothing estimation. The algorithm has an explicit iteration update whi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#23637;&#20102;PCA-Net&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#24471;&#20986;&#20102;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#28508;&#22312;&#38556;&#30861;&#65306;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#21644;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16317</link><description>&lt;p&gt;
PCA-Net&#65306;&#25805;&#20316;&#23398;&#20064;&#30340;&#22797;&#26434;&#24615;&#19978;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Operator learning with PCA-Net: upper and lower complexity bounds. (arXiv:2303.16317v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16317
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#23637;&#20102;PCA-Net&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#24471;&#20986;&#20102;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#28508;&#22312;&#38556;&#30861;&#65306;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#21644;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#23376;&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#22791;&#21463;&#20851;&#27880;&#12290;PCA-Net&#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#65292;&#23427;&#23558;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#19982;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#20197;&#36924;&#36817;&#28508;&#22312;&#30340;&#31639;&#23376;&#12290;&#26412;&#25991;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#36817;&#20284;&#29702;&#35770;&#30340;&#21457;&#23637;&#65292;&#25913;&#36827;&#24182;&#26174;&#30528;&#25193;&#23637;&#20102;&#27492;&#26041;&#21521;&#30340;&#20197;&#21069;&#30340;&#24037;&#20316;&#12290;&#22312;&#23450;&#24615;&#30028;&#38480;&#26041;&#38754;&#65292;&#26412;&#25991;&#24471;&#20986;&#20102;&#26032;&#39062;&#30340;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#22312;&#23545;&#28508;&#22312;&#31639;&#23376;&#21644;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#26368;&#23567;&#20551;&#35774;&#30340;&#21069;&#25552;&#19979;&#12290;&#22312;&#23450;&#37327;&#38480;&#21046;&#26041;&#38754;&#65292;&#26412;&#25991;&#35782;&#21035;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#20004;&#20010;&#28508;&#22312;&#38556;&#30861;&#65292;&#36890;&#36807;&#23548;&#20986;&#19979;&#30028;&#36827;&#34892;&#20102;&#20005;&#26684;&#35777;&#26126;&#65292;&#31532;&#19968;&#20010;&#38556;&#30861;&#19982;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#26377;&#20851;&#65292;&#30001;PCA&#29305;&#24449;&#20540;&#30340;&#32531;&#24930;&#34928;&#20943;&#26469;&#34913;&#37327;&#65307;&#21478;&#19968;&#20010;&#38556;&#30861;&#28041;&#21450;&#26080;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#31354;&#38388;&#20043;&#38388;&#30340;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural operators are gaining attention in computational science and engineering. PCA-Net is a recently proposed neural operator architecture which combines principal component analysis (PCA) with neural networks to approximate an underlying operator. The present work develops approximation theory for this approach, improving and significantly extending previous work in this direction. In terms of qualitative bounds, this paper derives a novel universal approximation result, under minimal assumptions on the underlying operator and the data-generating distribution. In terms of quantitative bounds, two potential obstacles to efficient operator learning with PCA-Net are identified, and made rigorous through the derivation of lower complexity bounds; the first relates to the complexity of the output distribution, measured by a slow decay of the PCA eigenvalues. The other obstacle relates the inherent complexity of the space of operators between infinite-dimensional input and output spaces, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;&#20110;&#27969;&#25968;&#25454;&#19978;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#65292;&#20026;&#20351;&#29992;&#22266;&#23450;&#22823;&#23567;&#28369;&#21160;&#31383;&#21475;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#24378;&#31283;&#20581;&#24615;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2303.16308</link><description>&lt;p&gt;
&#28369;&#21160;&#31383;&#21475;&#27969;&#27169;&#22411;&#30340;&#21487;&#35777;&#26126;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Provable Robustness for Streaming Models with a Sliding Window. (arXiv:2303.16308v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#27969;&#25968;&#25454;&#19978;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#65292;&#20026;&#20351;&#29992;&#22266;&#23450;&#22823;&#23567;&#28369;&#21160;&#31383;&#21475;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#24378;&#31283;&#20581;&#24615;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#26377;&#20851;&#21487;&#35777;&#26126;&#30340;&#31283;&#20581;&#24615;&#30340;&#25991;&#29486;&#20027;&#35201;&#20851;&#27880;&#38745;&#24577;&#39044;&#27979;&#38382;&#39064;&#65292;&#22914;&#22270;&#20687;&#20998;&#31867;&#31561;&#65292;&#20854;&#20013;&#20551;&#23450;&#36755;&#20837;&#26679;&#26412;&#26159;&#29420;&#31435;&#30340;&#65292;&#24182;&#19988;&#27169;&#22411;&#24615;&#33021;&#26159;&#22312;&#36755;&#20837;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#12290;&#23545;&#20110;&#21333;&#20010;&#36755;&#20837;&#23454;&#20363;&#65292;&#21487;&#20197;&#24471;&#20986;&#31283;&#20581;&#24615;&#35777;&#26126;&#65292;&#20294;&#26159;&#20551;&#35774;&#35813;&#27169;&#22411;&#23545;&#27599;&#20010;&#23454;&#20363;&#21333;&#29420;&#36827;&#34892;&#35780;&#20272;&#30340;&#31283;&#20581;&#24615;&#35777;&#26126;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#35768;&#22810;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#12290;&#26412;&#25991;&#20851;&#27880;&#20110;&#25968;&#25454;&#27969;&#19978;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#65292;&#20854;&#20013;&#36755;&#20837;&#20316;&#20026;&#19968;&#31995;&#21015;&#21487;&#33021;&#30456;&#20851;&#30340;&#39033;&#21576;&#29616;&#12290;&#25105;&#20204;&#20026;&#20351;&#29992;&#22266;&#23450;&#22823;&#23567;&#30340;&#28369;&#21160;&#31383;&#21475;&#30340;&#27169;&#22411;&#25512;&#23548;&#20986;&#20102;&#24378;&#31283;&#20581;&#24615;&#35777;&#26126;&#65292;&#20445;&#35777;&#20102;&#25972;&#20010;&#36755;&#20837;&#24207;&#21015;&#65292;&#32780;&#19981;&#26159;&#21333;&#20010;&#26679;&#26412;&#65292;&#24182;&#20026;&#27969;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#24378;&#31283;&#20581;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
The literature on provable robustness in machine learning has primarily focused on static prediction problems, such as image classification, in which input samples are assumed to be independent and model performance is measured as an expectation over the input distribution. Robustness certificates are derived for individual input instances with the assumption that the model is evaluated on each instance separately. However, in many deep learning applications such as online content recommendation and stock market analysis, models use historical data to make predictions. Robustness certificates based on the assumption of independent input samples are not directly applicable in such scenarios. In this work, we focus on the provable robustness of machine learning models in the context of data streams, where inputs are presented as a sequence of potentially correlated items. We derive robustness certificates for models that use a fixed-size sliding window over the input stream. Our guarante
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#20010;&#35797;&#39564;&#20013;&#21033;&#29992;&#25968;&#25454;&#20272;&#35745;&#20010;&#20307;&#21270;&#27835;&#30103;&#25928;&#24212;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#27169;&#25311;&#34920;&#26126;&#30452;&#25509;&#20801;&#35768;&#35797;&#39564;&#38388;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#21333;&#19968;&#30740;&#31350;&#26041;&#27861;&#30340;&#36873;&#25321;&#21462;&#20915;&#20110;&#27835;&#30103;&#25928;&#24212;&#30340;&#21151;&#33021;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2303.16299</link><description>&lt;p&gt;
&#32467;&#21512;&#22810;&#20010;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#27604;&#36739;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Comparing Machine Learning Methods for Estimating Heterogeneous Treatment Effects by Combining Data from Multiple Randomized Controlled Trials. (arXiv:2303.16299v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16299
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#20010;&#35797;&#39564;&#20013;&#21033;&#29992;&#25968;&#25454;&#20272;&#35745;&#20010;&#20307;&#21270;&#27835;&#30103;&#25928;&#24212;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#27169;&#25311;&#34920;&#26126;&#30452;&#25509;&#20801;&#35768;&#35797;&#39564;&#38388;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#21333;&#19968;&#30740;&#31350;&#26041;&#27861;&#30340;&#36873;&#25321;&#21462;&#20915;&#20110;&#27835;&#30103;&#25928;&#24212;&#30340;&#21151;&#33021;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#27835;&#30103;&#20915;&#31574;&#21487;&#20197;&#25913;&#21892;&#20581;&#24247;&#32467;&#26524;&#65292;&#20294;&#26159;&#20351;&#29992;&#25968;&#25454;&#20197;&#21487;&#38752;&#12289;&#31934;&#30830;&#21644;&#26377;&#26222;&#36941;&#24847;&#20041;&#30340;&#26041;&#24335;&#36827;&#34892;&#36825;&#20123;&#20915;&#31574;&#22312;&#19968;&#20010;&#21333;&#19968;&#25968;&#25454;&#38598;&#20013;&#26159;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#21033;&#29992;&#22810;&#20010;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#21487;&#20197;&#32452;&#21512;&#20855;&#26377;&#38750;&#28151;&#26434;&#24615;&#27835;&#30103;&#20998;&#37197;&#30340;&#25968;&#25454;&#38598;&#65292;&#25552;&#39640;&#20272;&#35745;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#20960;&#31181;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#21033;&#29992;&#22810;&#20010;&#35797;&#39564;&#30340;&#25968;&#25454;&#20272;&#35745;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#21333;&#19968;&#30740;&#31350;&#30340;&#26041;&#27861;&#25193;&#23637;&#21040;&#22810;&#20010;&#35797;&#39564;&#30340;&#22330;&#26223;&#20013;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#25506;&#35752;&#23427;&#20204;&#30340;&#24615;&#33021;&#65292;&#25968;&#25454;&#29983;&#25104;&#24773;&#26223;&#20855;&#26377;&#19981;&#21516;&#27700;&#24179;&#30340;&#36328;&#35797;&#39564;&#24322;&#36136;&#24615;&#12290;&#27169;&#25311;&#34920;&#26126;&#65292;&#30452;&#25509;&#20801;&#35768;&#35797;&#39564;&#38388;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#27604;&#19981;&#20801;&#35768;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#24182;&#19988;&#21333;&#19968;&#30740;&#31350;&#26041;&#27861;&#30340;&#36873;&#25321;&#21462;&#20915;&#20110;&#27835;&#30103;&#25928;&#24212;&#30340;&#21151;&#33021;&#24418;&#24335;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#23545;&#20943;&#23569;&#20303;&#38498;&#37325;&#26032;&#20837;&#38498;&#24178;&#39044;&#30340;&#32593;&#32476;&#33631;&#33795;&#20998;&#26512;&#25968;&#25454;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#23454;&#36341;&#20013;&#30340;&#26041;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#23545;&#26410;&#26469;&#30740;&#31350;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individualized treatment decisions can improve health outcomes, but using data to make these decisions in a reliable, precise, and generalizable way is challenging with a single dataset. Leveraging multiple randomized controlled trials allows for the combination of datasets with unconfounded treatment assignment to improve the power to estimate heterogeneous treatment effects. This paper discusses several non-parametric approaches for estimating heterogeneous treatment effects using data from multiple trials. We extend single-study methods to a scenario with multiple trials and explore their performance through a simulation study, with data generation scenarios that have differing levels of cross-trial heterogeneity. The simulations demonstrate that methods that directly allow for heterogeneity of the treatment effect across trials perform better than methods that do not, and that the choice of single-study method matters based on the functional form of the treatment effect. Finally, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21547;&#26377;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#30001;&#20110;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#26799;&#24230;&#35745;&#31639;&#26041;&#27861;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#28040;&#32791;&#65292;&#21516;&#26102;&#20173;&#33021;&#20445;&#35777;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16241</link><description>&lt;p&gt;
&#37319;&#29992;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Momentum-Based Heavy Ball Method with Batch Updating and/or Approximate Gradients. (arXiv:2303.16241v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21547;&#26377;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#30001;&#20110;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#26799;&#24230;&#35745;&#31639;&#26041;&#27861;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#28040;&#32791;&#65292;&#21516;&#26102;&#20173;&#33021;&#20445;&#35777;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;1964&#24180;Polyak&#24341;&#20837;&#30340;&#20984;&#20248;&#21270;&#21644;&#38750;&#20984;&#20248;&#21270;&#20013;&#24191;&#20026;&#20154;&#30693;&#30340;&#8220;&#21160;&#37327;&#37325;&#29699;&#8221;&#27861;&#65292;&#24182;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#30830;&#31435;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;&#24403;&#35201;&#27714;&#35299;&#21442;&#25968;&#30340;&#32500;&#24230;&#38750;&#24120;&#39640;&#26102;&#65292;&#26356;&#26032;&#19968;&#37096;&#20998;&#32780;&#19981;&#26159;&#25152;&#26377;&#21442;&#25968;&#21487;&#20197;&#25552;&#39640;&#20248;&#21270;&#25928;&#29575;&#65292;&#31216;&#20043;&#20026;&#8220;&#25209;&#37327;&#26356;&#26032;&#8221;&#65292;&#33509;&#19982;&#26799;&#24230;&#27861;&#37197;&#21512;&#20351;&#29992;&#65292;&#21017;&#29702;&#35770;&#19978;&#21482;&#38656;&#35745;&#31639;&#38656;&#35201;&#26356;&#26032;&#30340;&#21442;&#25968;&#30340;&#26799;&#24230;&#65292;&#32780;&#22312;&#23454;&#38469;&#20013;&#65292;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#31561;&#26041;&#27861;&#20165;&#35745;&#31639;&#37096;&#20998;&#26799;&#24230;&#24182;&#19981;&#33021;&#20943;&#23569;&#35745;&#31639;&#37327;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#22312;&#27599;&#19968;&#27493;&#20013;&#20943;&#23569;CPU&#20351;&#29992;&#37327;&#65292;&#21487;&#20197;&#20351;&#29992;&#19968;&#38454;&#24494;&#20998;&#25110;&#36817;&#20284;&#26799;&#24230;&#20195;&#26367;&#30495;&#23454;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#20551;&#35774;&#19979;&#65292;&#37319;&#29992;&#36817;&#20284;&#26799;&#24230;&#20449;&#24687;&#21644;/&#25110;&#25209;&#37327;&#26356;&#26032;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#20173;&#28982;&#21487;&#20197;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the well-known "Heavy Ball" method for convex and nonconvex optimization introduced by Polyak in 1964, and establish its convergence under a variety of situations. Traditionally, most algorthms use "full-coordinate update," that is, at each step, very component of the argument is updated. However, when the dimension of the argument is very high, it is more efficient to update some but not all components of the argument at each iteration. We refer to this as "batch updating" in this paper.  When gradient-based algorithms are used together with batch updating, in principle it is sufficient to compute only those components of the gradient for which the argument is to be updated. However, if a method such as back propagation is used to compute these components, computing only some components of gradient does not offer much savings over computing the entire gradient. Therefore, to achieve a noticeable reduction in CPU usage at each step, one can use first-order diffe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#20219;&#20309;&#22312;&#22343;&#21248;&#20998;&#24067;&#19979;&#26377;&#25928;&#30340;PAC&#23398;&#20064;&#31639;&#27861;&#36716;&#25442;&#25104;&#19968;&#20010;&#22312;&#20219;&#24847;&#26410;&#30693;&#20998;&#24067;&#19979;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#32780;&#19988;&#23545;&#20110;&#21333;&#35843;&#20998;&#24067;&#65292;&#21482;&#38656;&#35201;&#29992;$\mathcal{D}$&#20013;&#30340;&#26679;&#26412;&#12290;&#31639;&#27861;&#30340;&#26680;&#24515;&#26159;&#36890;&#36807;&#19968;&#20010;&#31639;&#27861;&#23558;$\mathcal{D}$&#36924;&#36817;&#25104;&#30001;&#23376;&#31435;&#26041;&#20307;&#28151;&#21512;&#32780;&#25104;&#30340;&#28151;&#21512;&#22343;&#21248;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2303.16208</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#24067;&#20998;&#35299;&#25552;&#39640;&#22343;&#21248;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Lifting uniform learners via distributional decomposition. (arXiv:2303.16208v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#20219;&#20309;&#22312;&#22343;&#21248;&#20998;&#24067;&#19979;&#26377;&#25928;&#30340;PAC&#23398;&#20064;&#31639;&#27861;&#36716;&#25442;&#25104;&#19968;&#20010;&#22312;&#20219;&#24847;&#26410;&#30693;&#20998;&#24067;&#19979;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#32780;&#19988;&#23545;&#20110;&#21333;&#35843;&#20998;&#24067;&#65292;&#21482;&#38656;&#35201;&#29992;$\mathcal{D}$&#20013;&#30340;&#26679;&#26412;&#12290;&#31639;&#27861;&#30340;&#26680;&#24515;&#26159;&#36890;&#36807;&#19968;&#20010;&#31639;&#27861;&#23558;$\mathcal{D}$&#36924;&#36817;&#25104;&#30001;&#23376;&#31435;&#26041;&#20307;&#28151;&#21512;&#32780;&#25104;&#30340;&#28151;&#21512;&#22343;&#21248;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20219;&#20309;&#22312;&#22343;&#21248;&#20998;&#24067;&#19979;&#26377;&#25928;&#30340;PAC&#23398;&#20064;&#31639;&#27861;&#36716;&#25442;&#25104;&#19968;&#20010;&#22312;&#20219;&#24847;&#26410;&#30693;&#20998;&#24067;$\mathcal{D}$&#19979;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#36716;&#25442;&#25928;&#29575;&#38543;$\mathcal{D}$&#30340;&#22266;&#26377;&#22797;&#26434;&#24615;&#32780;&#21464;&#21270;&#65292;&#23545;&#20110;&#22312;$\{\pm 1\}^n$&#19978;&#30340;&#20998;&#24067;&#65292;&#20854;pmf&#30001;&#28145;&#24230;&#20026;$d$&#30340;&#20915;&#31574;&#26641;&#35745;&#31639;&#65292;&#21017;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;$\mathrm{poly}(n, (md)^d)$&#65292;&#20854;&#20013;$m$&#26159;&#21407;&#22987;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;&#21333;&#35843;&#20998;&#24067;&#65292;&#25105;&#20204;&#30340;&#36716;&#25442;&#20165;&#20351;&#29992;$\mathcal{D}$&#20013;&#30340;&#26679;&#26412;&#65292;&#32780;&#23545;&#20110;&#19968;&#33324;&#20998;&#24067;&#65292;&#25105;&#20204;&#20351;&#29992;&#23376;&#31435;&#26041;&#20307;&#26465;&#20214;&#26679;&#26412;&#12290;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#25216;&#26415;&#26159;&#19968;&#20010;&#31639;&#27861;&#65292;&#23427;&#22312;&#32473;&#20986;$\mathcal{D}$&#30340;&#35775;&#38382;&#26435;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#20135;&#29983;&#20102;&#19968;&#20010;&#26368;&#20248;&#20915;&#31574;&#26641;&#20998;&#35299;$\mathcal{D}$&#65306;&#19968;&#20010;&#36924;&#36817;&#20102;$\mathcal{D}$&#30340;&#28151;&#21512;&#22343;&#21248;&#20998;&#24067;&#30340;&#20998;&#31163;&#23376;&#31435;&#26041;&#20307;&#12290;&#36890;&#36807;&#36825;&#20010;&#20998;&#35299;&#65292;&#25105;&#20204;&#22312;&#27599;&#20010;&#23376;&#31435;&#26041;&#20307;&#19978;&#36816;&#34892;&#22343;&#21248;&#20998;&#24067;&#23398;&#20064;&#22120;&#65292;&#24182;&#23558;&#32467;&#26524;&#21512;&#24182;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how any PAC learning algorithm that works under the uniform distribution can be transformed, in a blackbox fashion, into one that works under an arbitrary and unknown distribution $\mathcal{D}$. The efficiency of our transformation scales with the inherent complexity of $\mathcal{D}$, running in $\mathrm{poly}(n, (md)^d)$ time for distributions over $\{\pm 1\}^n$ whose pmfs are computed by depth-$d$ decision trees, where $m$ is the sample complexity of the original algorithm. For monotone distributions our transformation uses only samples from $\mathcal{D}$, and for general ones it uses subcube conditioning samples.  A key technical ingredient is an algorithm which, given the aforementioned access to $\mathcal{D}$, produces an optimal decision tree decomposition of $\mathcal{D}$: an approximation of $\mathcal{D}$ as a mixture of uniform distributions over disjoint subcubes. With this decomposition in hand, we run the uniform-distribution learner on each subcube and combine the 
&lt;/p&gt;</description></item><item><title>FuNVol&#26159;&#19968;&#20010;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;&#65292;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#29983;&#25104;&#30495;&#23454;&#21382;&#21490;&#20215;&#26684;&#30340;IV&#34920;&#38754;&#24207;&#21015;&#65292;&#24182;&#22312;&#26080;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#20135;&#29983;&#19968;&#33268;&#30340;&#24066;&#22330;&#24773;&#26223;&#12290;&#21516;&#26102;&#65292;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#21487;&#20197;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2303.00859</link><description>&lt;p&gt;
FuNVol&#65306;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#30340;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;
&lt;/p&gt;
&lt;p&gt;
FuNVol: A Multi-Asset Implied Volatility Market Simulator using Functional Principal Components and Neural SDEs. (arXiv:2303.00859v2 [q-fin.CP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00859
&lt;/p&gt;
&lt;p&gt;
FuNVol&#26159;&#19968;&#20010;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;&#65292;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#29983;&#25104;&#30495;&#23454;&#21382;&#21490;&#20215;&#26684;&#30340;IV&#34920;&#38754;&#24207;&#21015;&#65292;&#24182;&#22312;&#26080;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#20135;&#29983;&#19968;&#33268;&#30340;&#24066;&#22330;&#24773;&#26223;&#12290;&#21516;&#26102;&#65292;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#21487;&#20197;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#21644;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#32467;&#21512;&#27010;&#29575;&#31215;&#20998;&#21464;&#25442;&#24809;&#32602;&#26469;&#29983;&#25104;&#22810;&#20010;&#36164;&#20135;&#30340;&#38544;&#21547;&#27874;&#21160;&#29575;&#34920;&#38754;&#24207;&#21015;&#65292;&#35813;&#26041;&#27861;&#24544;&#23454;&#20110;&#21382;&#21490;&#20215;&#26684;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23398;&#20064;IV&#34920;&#38754;&#21644;&#20215;&#26684;&#30340;&#32852;&#21512;&#21160;&#24577;&#20135;&#29983;&#30340;&#24066;&#22330;&#24773;&#26223;&#19982;&#21382;&#21490;&#29305;&#24449;&#19968;&#33268;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#20250;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Here, we introduce a new approach for generating sequences of implied volatility (IV) surfaces across multiple assets that is faithful to historical prices. We do so using a combination of functional data analysis and neural stochastic differential equations (SDEs) combined with a probability integral transform penalty to reduce model misspecification. We demonstrate that learning the joint dynamics of IV surfaces and prices produces market scenarios that are consistent with historical features and lie within the sub-manifold of surfaces that are essentially free of static arbitrage. Finally, we demonstrate that delta hedging using the simulated surfaces generates profit and loss (P&amp;L) distributions that are consistent with realised P&amp;Ls.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#8212;&#8212;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#29615;&#22659;&#20256;&#24863;&#22120;&#30340;&#25918;&#32622;&#25928;&#29575;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#36890;&#36807;&#23398;&#20064;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#38750;&#24179;&#31283;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.10381</link><description>&lt;p&gt;
&#24102;&#26377;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#30340;&#29615;&#22659;&#20256;&#24863;&#22120;&#25918;&#32622;
&lt;/p&gt;
&lt;p&gt;
Environmental Sensor Placement with Convolutional Gaussian Neural Processes. (arXiv:2211.10381v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10381
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#8212;&#8212;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#29615;&#22659;&#20256;&#24863;&#22120;&#30340;&#25918;&#32622;&#25928;&#29575;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#36890;&#36807;&#23398;&#20064;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#38750;&#24179;&#31283;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29615;&#22659;&#20256;&#24863;&#22120;&#23545;&#20110;&#30417;&#27979;&#22825;&#27668;&#21644;&#27668;&#20505;&#21464;&#21270;&#30340;&#24433;&#21709;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#20687;&#21335;&#26497;&#36825;&#26679;&#30340;&#20559;&#36828;&#22320;&#21306;&#65292;&#26368;&#22823;&#21270;&#27979;&#37327;&#20449;&#24687;&#21644;&#26377;&#25928;&#25918;&#32622;&#20256;&#24863;&#22120;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#39044;&#27979;&#26032;&#20256;&#24863;&#22120;&#25552;&#20379;&#30340;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#26469;&#35780;&#20272;&#25918;&#32622;&#20449;&#24687;&#12290;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#24191;&#27867;&#29992;&#20110;&#27492;&#30446;&#30340;&#65292;&#20294;&#38590;&#20197;&#25429;&#25417;&#22797;&#26434;&#30340;&#38750;&#24179;&#31283;&#34892;&#20026;&#24182;&#32553;&#25918;&#21040;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#20219;&#24847;&#30446;&#26631;&#20301;&#32622;&#30340;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;&#20351;&#29992;&#27169;&#25311;&#30340;&#21335;&#26497;&#22320;&#21306;&#22320;&#38754;&#28201;&#24230;&#24322;&#24120;&#20316;&#20026;&#30495;&#23454;&#25968;&#25454;&#65292;ConvGNP&#23398;&#20064;&#20102;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#24182;&#20248;&#20110;&#38750;&#24179;&#31283;GP&#22522;&#32447;&#12290;&#22312;&#27169;&#25311;&#30340;s&#20013;&#65292;
&lt;/p&gt;
&lt;p&gt;
Environmental sensors are crucial for monitoring weather conditions and the impacts of climate change. However, it is challenging to maximise measurement informativeness and place sensors efficiently, particularly in remote regions like Antarctica. Probabilistic machine learning models can evaluate placement informativeness by predicting the uncertainty reduction provided by a new sensor. Gaussian process (GP) models are widely used for this purpose, but they struggle with capturing complex non-stationary behaviour and scaling to large datasets. This paper proposes using a convolutional Gaussian neural process (ConvGNP) to address these issues. A ConvGNP uses neural networks to parameterise a joint Gaussian distribution at arbitrary target locations, enabling flexibility and scalability. Using simulated surface air temperature anomaly over Antarctica as ground truth, the ConvGNP learns spatial and seasonal non-stationarities, outperforming a non-stationary GP baseline. In a simulated s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#20915;&#20855;&#26377;&#19968;&#33324;&#24418;&#24335;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#28201;&#21551;&#21160;&#25216;&#26415;&#65292;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#36817;&#20284;&#22320;&#35299;&#20915;&#23376;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#30340;&#25910;&#25947;&#36895;&#24230;&#27604;&#20854;&#31934;&#30830;&#23545;&#24212;&#29289;&#26356;&#24555;&#12290;</title><link>http://arxiv.org/abs/2210.15659</link><description>&lt;p&gt;
&#35299;&#20915;&#20855;&#26377;&#19968;&#33324;&#24418;&#24335;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Primal-dual Approach for Solving Variational Inequalities with General-form Constraints. (arXiv:2210.15659v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#20915;&#20855;&#26377;&#19968;&#33324;&#24418;&#24335;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#28201;&#21551;&#21160;&#25216;&#26415;&#65292;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#36817;&#20284;&#22320;&#35299;&#20915;&#23376;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#30340;&#25910;&#25947;&#36895;&#24230;&#27604;&#20854;&#31934;&#30830;&#23545;&#24212;&#29289;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Yang&#31561;&#20154;&#26368;&#36817;&#36890;&#36807;&#19968;&#31181;&#19968;&#38454;&#26799;&#24230;&#26041;&#27861;&#35299;&#20915;&#20102;&#20855;&#26377;&#31561;&#24335;&#21644;&#19981;&#31561;&#24335;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#65288;VI&#65289;&#30340;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#25552;&#20986;&#30340;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#31216;&#20026;ACVI&#20165;&#36866;&#29992;&#20110;&#21487;&#20197;&#35745;&#31639;&#20854;&#23376;&#38382;&#39064;&#30340;&#35299;&#26512;&#35299;&#30340;&#24773;&#20917;&#65292;&#22240;&#27492;&#19968;&#33324;&#24773;&#20917;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#19968;&#31181;&#28201;&#21551;&#21160;&#25216;&#26415;&#65292;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#36817;&#20284;&#22320;&#35299;&#20915;&#23376;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#22312;&#20808;&#21069;&#36845;&#20195;&#20013;&#25214;&#21040;&#30340;&#36817;&#20284;&#35299;&#21021;&#22987;&#21270;&#21464;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#34920;&#26126;&#24403;&#31639;&#23376;&#20026;$L$-Lipschitz&#19988;&#21333;&#35843;&#26102;&#65292;&#36825;&#31181;&#19981;&#31934;&#30830;&#30340;ACVI&#26041;&#27861;&#30340;&#26368;&#21518;&#19968;&#27425;&#36845;&#20195;&#30340;&#38388;&#38553;&#20989;&#25968;&#19979;&#38477;&#30340;&#36895;&#24230;&#20026;$\mathcal{O}(\frac{1}{\sqrt{K}})$&#65292;&#21069;&#25552;&#26159;&#38169;&#35823;&#20197;&#36866;&#24403;&#30340;&#36895;&#24230;&#19979;&#38477;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#36890;&#24120;&#36825;&#31181;&#25216;&#26415;&#27604;&#20854;&#31934;&#30830;&#23545;&#24212;&#29289;&#25910;&#25947;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#19981;&#31561;&#24335;&#32422;&#26463;&#30340;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Yang et al. (2023) recently addressed the open problem of solving Variational Inequalities (VIs) with equality and inequality constraints through a first-order gradient method. However, the proposed primal-dual method called ACVI is applicable when we can compute analytic solutions of its subproblems; thus, the general case remains an open problem. In this paper, we adopt a warm-starting technique where we solve the subproblems approximately at each iteration and initialize the variables with the approximate solution found at the previous iteration. We prove its convergence and show that the gap function of the last iterate of this inexact-ACVI method decreases at a rate of $\mathcal{O}(\frac{1}{\sqrt{K}})$ when the operator is $L$-Lipschitz and monotone, provided that the errors decrease at appropriate rates. Interestingly, we show that often in numerical experiments, this technique converges faster than its exact counterpart. Furthermore, for the cases when the inequality constraints
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#39640;&#32500;&#29305;&#24449;&#19979;&#36827;&#34892;&#20108;&#20803;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#24191;&#20041;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#20272;&#35745;&#26368;&#20339;&#20998;&#31163;&#36229;&#24179;&#38754;&#30340;&#26041;&#21521;&#65292;&#24778;&#20154;&#22320;&#21457;&#29616;&#36229;&#24179;&#38754;&#30340;&#25554;&#20540;&#21462;&#20915;&#20110;&#26631;&#31614;&#30340;&#32534;&#30721;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2210.14347</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#39640;&#26031;&#28508;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#25554;&#20540;&#21028;&#21035;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Interpolating Discriminant Functions in High-Dimensional Gaussian Latent Mixtures. (arXiv:2210.14347v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#39640;&#32500;&#29305;&#24449;&#19979;&#36827;&#34892;&#20108;&#20803;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#24191;&#20041;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#20272;&#35745;&#26368;&#20339;&#20998;&#31163;&#36229;&#24179;&#38754;&#30340;&#26041;&#21521;&#65292;&#24778;&#20154;&#22320;&#21457;&#29616;&#36229;&#24179;&#38754;&#30340;&#25554;&#20540;&#21462;&#20915;&#20110;&#26631;&#31614;&#30340;&#32534;&#30721;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#20302;&#32500;&#28508;&#22312;&#39640;&#26031;&#28151;&#21512;&#32467;&#26500;&#21644;&#38750;&#38646;&#22122;&#22768;&#30340;&#20551;&#35774;&#27169;&#22411;&#19979;&#38024;&#23545;&#39640;&#32500;&#29305;&#24449;&#30340;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#12290;&#20351;&#29992;&#24191;&#20041;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#26469;&#20272;&#35745;&#26368;&#20339;&#20998;&#31163;&#36229;&#24179;&#38754;&#30340;&#26041;&#21521;&#12290;&#25152;&#20272;&#35745;&#30340;&#36229;&#24179;&#38754;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#34987;&#35777;&#26126;&#26159;&#25554;&#20540;&#30340;&#12290;&#34429;&#28982;&#27491;&#22914;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#36817;&#32467;&#26524;&#25152;&#39044;&#26399;&#30340;&#37027;&#26679;&#65292;&#26041;&#21521;&#21521;&#37327;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#20294;&#19968;&#20010;&#22825;&#30495;&#30340;&#25554;&#20214;&#20272;&#35745;&#26410;&#33021;&#19968;&#33268;&#22320;&#20272;&#35745;&#25318;&#25130;&#12290;&#19968;&#20010;&#31616;&#21333;&#30340;&#26657;&#27491;&#38656;&#35201;&#19968;&#20010;&#29420;&#31435;&#30340;&#20445;&#30041;&#26679;&#26412;&#65292;&#22312;&#35768;&#22810;&#22330;&#26223;&#20013;&#21487;&#20197;&#20351;&#36807;&#31243;&#20445;&#25345;&#26368;&#23567;&#21270;&#26368;&#22823;&#20540;&#26368;&#20248;&#12290;&#21518;&#32493;&#36807;&#31243;&#30340;&#25554;&#20540;&#24615;&#36136;&#21487;&#20197;&#20445;&#30041;&#65292;&#20294;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23427;&#21462;&#20915;&#20110;&#26631;&#31614;&#30340;&#32534;&#30721;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers binary classification of high-dimensional features under a postulated model with a low-dimensional latent Gaussian mixture structure and non-vanishing noise. A generalized least squares estimator is used to estimate the direction of the optimal separating hyperplane. The estimated hyperplane is shown to interpolate on the training data. While the direction vector can be consistently estimated as could be expected from recent results in linear regression, a naive plug-in estimate fails to consistently estimate the intercept. A simple correction, that requires an independent hold-out sample, renders the procedure minimax optimal in many scenarios. The interpolation property of the latter procedure can be retained, but surprisingly depends on the way the labels are encoded.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#24102;&#26377;&#22266;&#23450;&#27493;&#38271;&#30340;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#65288;LSA&#65289;&#31639;&#27861;&#30340;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;LSA&#21450;&#20854;Polyak-Ruppert&#24179;&#22343;&#21270;&#29256;&#26412;&#23450;&#20041;&#30340;&#36845;&#20195;&#30340;$p$&#38454;&#30697;&#21644;&#39640;&#27010;&#29575;&#20559;&#24046;&#30028;&#30340;&#25512;&#23548;&#12290;&#26412;&#25991;&#24471;&#21040;&#30340;&#26377;&#38480;&#26102;&#38388;&#23454;&#20363;&#30456;&#20851;&#30340;&#24179;&#22343;LSA&#36845;&#20195;&#30340;&#30028;&#38480;&#26159;&#23574;&#38160;&#30340;&#65292;&#24182;&#19982;&#23616;&#37096;&#28176;&#36817;&#26497;&#23567;&#26497;&#20540;&#38480;&#21046;&#30456;&#21516;&#65292;&#21516;&#26102;&#21097;&#20313;&#39033;&#23545;&#28151;&#21512;&#26102;&#38388;&#26377;&#30528;&#32039;&#23494;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2207.04475</link><description>&lt;p&gt;
&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#30340;Polyak-Ruppert&#24179;&#22343;&#36845;&#20195;&#30340;&#26377;&#38480;&#26102;&#38388;&#39640;&#27010;&#29575;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Finite-time High-probability Bounds for Polyak-Ruppert Averaged Iterates of Linear Stochastic Approximation. (arXiv:2207.04475v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.04475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#24102;&#26377;&#22266;&#23450;&#27493;&#38271;&#30340;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#65288;LSA&#65289;&#31639;&#27861;&#30340;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;LSA&#21450;&#20854;Polyak-Ruppert&#24179;&#22343;&#21270;&#29256;&#26412;&#23450;&#20041;&#30340;&#36845;&#20195;&#30340;$p$&#38454;&#30697;&#21644;&#39640;&#27010;&#29575;&#20559;&#24046;&#30028;&#30340;&#25512;&#23548;&#12290;&#26412;&#25991;&#24471;&#21040;&#30340;&#26377;&#38480;&#26102;&#38388;&#23454;&#20363;&#30456;&#20851;&#30340;&#24179;&#22343;LSA&#36845;&#20195;&#30340;&#30028;&#38480;&#26159;&#23574;&#38160;&#30340;&#65292;&#24182;&#19982;&#23616;&#37096;&#28176;&#36817;&#26497;&#23567;&#26497;&#20540;&#38480;&#21046;&#30456;&#21516;&#65292;&#21516;&#26102;&#21097;&#20313;&#39033;&#23545;&#28151;&#21512;&#26102;&#38388;&#26377;&#30528;&#32039;&#23494;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#24102;&#26377;&#22266;&#23450;&#27493;&#38271;&#30340;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#65288;LSA&#65289;&#31639;&#27861;&#30340;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#65292;&#36825;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#26041;&#27861;&#12290;LSA&#34987;&#29992;&#26469;&#35745;&#31639;$d$&#32500;&#32447;&#24615;&#31995;&#32479;$\bar{\mathbf{A}}\theta = \bar{\mathbf{b}}$&#30340;&#36817;&#20284;&#35299;&#65292;&#20854;&#20013;$(\bar{\mathbf{A}},\bar{\mathbf{b}})$&#20165;&#33021;&#36890;&#36807;&#65288;&#28176;&#36817;&#65289;&#26080;&#20559;&#35266;&#27979;$\{(\mathbf{A}(Z_n),\mathbf{b}(Z_n))\}_{n \in \mathbb{N}}$&#26469;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#32771;&#34385;&#30340;&#24773;&#20917;&#26159;$\{Z_n\}_{n \in \mathbb{N}}$&#26159;i.i.d.&#24207;&#21015;&#25110;&#22343;&#21248;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#23545;LSA&#21450;&#20854;Polyak-Ruppert&#24179;&#22343;&#21270;&#29256;&#26412;&#23450;&#20041;&#30340;&#36845;&#20195;&#36827;&#34892;$p$&#38454;&#30697;&#21644;&#39640;&#27010;&#29575;&#20559;&#24046;&#30028;&#30340;&#25512;&#23548;&#12290;&#25105;&#20204;&#33719;&#24471;&#30340;&#26377;&#38480;&#26102;&#38388;&#23454;&#20363;&#30456;&#20851;&#30340;&#24179;&#22343;LSA&#36845;&#20195;&#30340;&#30028;&#38480;&#26159;&#23574;&#38160;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#33719;&#24471;&#30340;&#20027;&#39033;&#19982;&#23616;&#37096;&#28176;&#36817;&#26497;&#23567;&#26497;&#20540;&#38480;&#21046;&#30456;&#21516;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#30340;&#21097;&#20313;&#39033;&#23545;&#28151;&#21512;&#26102;&#38388;&#26377;&#30528;&#32039;&#23494;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper provides a finite-time analysis of linear stochastic approximation (LSA) algorithms with fixed step size, a core method in statistics and machine learning. LSA is used to compute approximate solutions of a $d$-dimensional linear system $\bar{\mathbf{A}} \theta = \bar{\mathbf{b}}$ for which $(\bar{\mathbf{A}}, \bar{\mathbf{b}})$ can only be estimated by (asymptotically) unbiased observations $\{(\mathbf{A}(Z_n),\mathbf{b}(Z_n))\}_{n \in \mathbb{N}}$. We consider here the case where $\{Z_n\}_{n \in \mathbb{N}}$ is an i.i.d. sequence or a uniformly geometrically ergodic Markov chain. We derive $p$-th moment and high-probability deviation bounds for the iterates defined by LSA and its Polyak-Ruppert-averaged version. Our finite-time instance-dependent bounds for the averaged LSA iterates are sharp in the sense that the leading term we obtain coincides with the local asymptotic minimax limit. Moreover, the remainder terms of our bounds admit a tight dependence on the mixing time 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26032;&#39062;&#20272;&#35745;&#37327;&#21644;&#33258;&#26631;&#20934;&#21270;&#30028;&#38480;&#30340;&#32447;&#24615;&#19978;&#19979;&#25991;Bandit&#31639;&#27861;&#65292;&#20855;&#26377;$O(\sqrt{dT\log T})$&#36951;&#25022;&#30028;&#65292;&#32500;&#24230;&#30456;&#20851;&#30340;&#21152;&#27861;&#39033;&#20998;&#35299;&#36951;&#25022;&#32047;&#31215;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2206.05404</link><description>&lt;p&gt;
Squeeze All&#65306;&#32447;&#24615;&#19978;&#19979;&#25991;Bandit&#30340;&#26032;&#20272;&#35745;&#22120;&#21644;&#33258;&#26631;&#20934;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Squeeze All: Novel Estimator and Self-Normalized Bound for Linear Contextual Bandits. (arXiv:2206.05404v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05404
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26032;&#39062;&#20272;&#35745;&#37327;&#21644;&#33258;&#26631;&#20934;&#21270;&#30028;&#38480;&#30340;&#32447;&#24615;&#19978;&#19979;&#25991;Bandit&#31639;&#27861;&#65292;&#20855;&#26377;$O(\sqrt{dT\log T})$&#36951;&#25022;&#30028;&#65292;&#32500;&#24230;&#30456;&#20851;&#30340;&#21152;&#27861;&#39033;&#20998;&#35299;&#36951;&#25022;&#32047;&#31215;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;$O(\sqrt{dT\log T})$&#36951;&#25022;&#30028;&#30340;&#32447;&#24615;&#19978;&#19979;&#25991;Bandit&#31639;&#27861;&#65292;&#20854;&#20013;$d$&#26159;&#19978;&#19979;&#25991;&#30340;&#32500;&#25968;&#65292;$T$&#26159;&#26102;&#38388;&#36328;&#24230;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#19968;&#31181;&#26032;&#39062;&#30340;&#20272;&#35745;&#37327;&#65292;&#20854;&#20013;&#36890;&#36807;&#26174;&#24335;&#38543;&#26426;&#21270;&#23884;&#20837;&#20102;&#25506;&#32034;&#12290;&#26681;&#25454;&#38543;&#26426;&#24615;&#65292;&#25105;&#20204;&#30340;&#24314;&#35758;&#20272;&#35745;&#22120;&#21487;&#20197;&#20174;&#25152;&#26377;&#27494;&#22120;&#30340;&#19978;&#19979;&#25991;&#25110;&#20174;&#36873;&#23450;&#30340;&#19978;&#19979;&#25991;&#20013;&#33719;&#24471;&#36129;&#29486;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#24314;&#31435;&#20102;&#19968;&#20010;&#33258;&#26631;&#20934;&#21270;&#30028;&#38480;&#65292;&#23427;&#20801;&#35768;&#23558;&#32047;&#31215;&#36951;&#25022;&#20998;&#35299;&#20026;&#22522;&#20110;&#32500;&#24230;&#30340;\textit{&#21487;&#21152;}&#39033;&#65292;&#32780;&#19981;&#26159;&#20056;&#27861;&#39033;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#25105;&#20204;&#30340;&#38382;&#39064;&#35774;&#32622;&#19979;&#30340;$\Omega(\sqrt{dT})$&#30340;&#26032;&#30340;&#19979;&#38480;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#36951;&#25022;&#21305;&#37197;&#19979;&#38480;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#12290;&#25968;&#20540;&#23454;&#39564;&#25903;&#25345;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#32447;&#24615;Bandit&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a linear contextual bandit algorithm with $O(\sqrt{dT\log T})$ regret bound, where $d$ is the dimension of contexts and $T$ isthe time horizon. Our proposed algorithm is equipped with a novel estimator in which exploration is embedded through explicit randomization. Depending on the randomization, our proposed estimator takes contributions either from contexts of all arms or from selected contexts. We establish a self-normalized bound for our estimator, which allows a novel decomposition of the cumulative regret into \textit{additive} dimension-dependent terms instead of multiplicative terms. We also prove a novel lower bound of $\Omega(\sqrt{dT})$ under our problem setting. Hence, the regret of our proposed algorithm matches the lower bound up to logarithmic factors. The numerical experiments support the theoretical guarantees and show that our proposed method outperforms the existing linear bandit algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#25552;&#20986;&#21807;&#19968;&#24179;&#34913;&#28857;&#22987;&#32456;&#23384;&#22312;&#19988;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#29575;&#20026;&#32447;&#24615;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#21487;&#36890;&#36807;&#36731;&#24494;&#36807;&#21442;&#25968;&#21270;&#24471;&#21040;&#28385;&#36275;&#12290;</title><link>http://arxiv.org/abs/2205.13814</link><description>&lt;p&gt;
&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#20840;&#23616;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Global Convergence of Over-parameterized Deep Equilibrium Models. (arXiv:2205.13814v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#25552;&#20986;&#21807;&#19968;&#24179;&#34913;&#28857;&#22987;&#32456;&#23384;&#22312;&#19988;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#29575;&#20026;&#32447;&#24615;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#21487;&#36890;&#36807;&#36731;&#24494;&#36807;&#21442;&#25968;&#21270;&#24471;&#21040;&#28385;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#65288;DEQ&#65289;&#36890;&#36807;&#26080;&#38480;&#28145;&#24230;&#30340;&#21152;&#26435;-&#32465;&#23450;&#27169;&#22411;&#20013;&#30340;&#24179;&#34913;&#28857;&#19982;&#36755;&#20837;&#27880;&#20837;&#26469;&#38544;&#24335;&#23450;&#20041;&#12290;&#23427;&#36890;&#36807;&#26681;&#26597;&#25214;&#30452;&#25509;&#27714;&#35299;&#24179;&#34913;&#28857;&#65292;&#24182;&#36890;&#36807;&#38544;&#24335;&#24494;&#20998;&#35745;&#31639;&#26799;&#24230;&#65292;&#36991;&#20813;&#20102;&#26080;&#38480;&#36816;&#31639;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#36807;&#21442;&#25968;&#21270;DEQ&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#36890;&#36807;&#23545;&#21021;&#22987;&#24179;&#34913;&#28857;&#26045;&#21152;&#19968;&#23450;&#26465;&#20214;&#65292;&#25105;&#20204;&#34920;&#26126;&#21807;&#19968;&#24179;&#34913;&#28857;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#22987;&#32456;&#23384;&#22312;&#65292;&#24182;&#19988;&#38024;&#23545;&#20108;&#27425;&#25439;&#22833;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#29575;&#35777;&#26126;&#20026;&#32447;&#24615;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#20026;&#20102;&#23637;&#31034;&#25152;&#38656;&#36215;&#22987;&#26465;&#20214;&#36890;&#36807;&#36731;&#24494;&#36807;&#21442;&#25968;&#21270;&#24471;&#21040;&#28385;&#36275;&#65292;&#25105;&#20204;&#22312;&#38543;&#26426;DEQ&#19978;&#36827;&#34892;&#20102;&#32454;&#31890;&#24230;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#20197;&#20811;&#26381;&#38750;&#28176;&#36817;&#20998;&#26512;&#26080;&#38480;&#28145;&#24230;&#21152;&#26435;&#32465;&#23450;&#27169;&#22411;&#30340;&#25216;&#26415;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
A deep equilibrium model (DEQ) is implicitly defined through an equilibrium point of an infinite-depth weight-tied model with an input-injection. Instead of infinite computations, it solves an equilibrium point directly with root-finding and computes gradients with implicit differentiation. The training dynamics of over-parameterized DEQs are investigated in this study. By supposing a condition on the initial equilibrium point, we show that the unique equilibrium point always exists during the training process, and the gradient descent is proved to converge to a globally optimal solution at a linear convergence rate for the quadratic loss function. In order to show that the required initial condition is satisfied via mild over-parameterization, we perform a fine-grained analysis on random DEQs. We propose a novel probabilistic framework to overcome the technical difficulty in the non-asymptotic analysis of infinite-depth weight-tied models.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#25968;&#25454;&#27969;&#24418;&#20013;&#23398;&#20064;&#20445;&#25345;&#36523;&#20221;&#30340;&#21464;&#25442;&#65292;&#32780;&#26080;&#38656;&#22312;&#35757;&#32451;&#26399;&#38388;&#26631;&#35760;&#21464;&#25442;&#25968;&#25454;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#21487;&#20197;&#23398;&#20064;&#19968;&#32452;&#26412;&#22320;&#33258;&#36866;&#24212;&#30340;&#20445;&#25345;&#36523;&#20221;&#30340;&#21464;&#25442;&#65292;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#20998;&#31867;&#21644;&#23569;&#26679;&#26412;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#25512;&#24191;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2106.12096</link><description>&lt;p&gt;
&#23398;&#20064;&#25968;&#25454;&#27969;&#24418;&#19978;&#30340;&#20445;&#25345;&#36523;&#20221;&#30340;&#21464;&#25442;
&lt;/p&gt;
&lt;p&gt;
Learning Identity-Preserving Transformations on Data Manifolds. (arXiv:2106.12096v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.12096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;&#25968;&#25454;&#27969;&#24418;&#20013;&#23398;&#20064;&#20445;&#25345;&#36523;&#20221;&#30340;&#21464;&#25442;&#65292;&#32780;&#26080;&#38656;&#22312;&#35757;&#32451;&#26399;&#38388;&#26631;&#35760;&#21464;&#25442;&#25968;&#25454;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#21487;&#20197;&#23398;&#20064;&#19968;&#32452;&#26412;&#22320;&#33258;&#36866;&#24212;&#30340;&#20445;&#25345;&#36523;&#20221;&#30340;&#21464;&#25442;&#65292;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#20998;&#31867;&#21644;&#23569;&#26679;&#26412;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#25512;&#24191;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23558;&#20445;&#25345;&#36523;&#20221;&#30340;&#21464;&#25442;&#32435;&#20837;&#20854;&#27169;&#22411;&#20013;&#65292;&#20197;&#23558;&#20854;&#24615;&#33021;&#25512;&#24191;&#21040;&#20197;&#21069;&#26410;&#35265;&#36807;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#21464;&#25442;&#36890;&#24120;&#26159;&#20174;&#19968;&#32452;&#24050;&#30693;&#21487;&#20197;&#32500;&#25345;&#36755;&#20837;&#36523;&#20221;&#30340;&#20989;&#25968;&#20013;&#36873;&#25321;&#30340;&#65288;&#20363;&#22914;&#26059;&#36716;&#12289;&#24179;&#31227;&#12289;&#32763;&#36716;&#21644;&#32553;&#25918;&#65289;&#12290;&#28982;&#32780;&#65292;&#26377;&#35768;&#22810;&#33258;&#28982;&#21464;&#21270;&#26080;&#27861;&#36827;&#34892;&#26631;&#35760;&#30417;&#30563;&#25110;&#36890;&#36807;&#25968;&#25454;&#26816;&#26597;&#26469;&#23450;&#20041;&#12290;&#22914;&#28024;&#20837;&#24335;&#23398;&#20064;&#20551;&#35774;&#25152;&#31034;&#65292;&#35768;&#22810;&#36825;&#20123;&#33258;&#28982;&#21464;&#21270;&#23384;&#22312;&#20110;&#25110;&#38752;&#36817;&#20302;&#32500;&#38750;&#32447;&#24615;&#27969;&#24418;&#19978;&#12290;&#20960;&#31181;&#25216;&#26415;&#36890;&#36807;&#19968;&#32452;&#23398;&#20064;&#30340;&#26446;&#32676;&#31639;&#23376;&#26469;&#34920;&#31034;&#27969;&#24418;&#21464;&#21270;&#65292;&#36825;&#20123;&#31639;&#23376;&#23450;&#20041;&#20102;&#27969;&#24418;&#19978;&#30340;&#36816;&#21160;&#26041;&#21521;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#23616;&#38480;&#22312;&#20110;&#23427;&#20204;&#22312;&#35757;&#32451;&#20854;&#27169;&#22411;&#26102;&#38656;&#35201;&#21464;&#25442;&#26631;&#31614;&#65292;&#24182;&#19988;&#32570;&#20047;&#19968;&#31181;&#30830;&#23450;&#27599;&#20010;&#29305;&#23450;&#31639;&#23376;&#36866;&#29992;&#20110;&#27969;&#24418;&#30340;&#21738;&#20123;&#21306;&#22495;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#35813;&#26041;&#27861;&#30452;&#25509;&#20174;&#25968;&#25454;&#27969;&#24418;&#20013;&#23398;&#20064;&#20445;&#25345;&#36523;&#20221;&#30340;&#21464;&#25442;&#65292;&#32780;&#26080;&#38656;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26631;&#35760;&#21464;&#25442;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#31181;&#20462;&#25913;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#35813;&#33258;&#32534;&#30721;&#22120;&#22312;&#31471;&#21040;&#31471;&#35757;&#32451;&#20013;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#21644;&#19968;&#32452;&#26412;&#22320;&#33258;&#36866;&#24212;&#30340;&#20445;&#25345;&#36523;&#20221;&#30340;&#21464;&#25442;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#26377;&#29992;&#30340;&#21464;&#25442;&#65292;&#20174;&#32780;&#25913;&#21892;&#27169;&#22411;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#20998;&#31867;&#21644;&#23569;&#26679;&#26412;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#25512;&#24191;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning techniques incorporate identity-preserving transformations into their models to generalize their performance to previously unseen data. These transformations are typically selected from a set of functions that are known to maintain the identity of an input when applied (e.g., rotation, translation, flipping, and scaling). However, there are many natural variations that cannot be labeled for supervision or defined through examination of the data. As suggested by the manifold hypothesis, many of these natural variations live on or near a low-dimensional, nonlinear manifold. Several techniques represent manifold variations through a set of learned Lie group operators that define directions of motion on the manifold. However, these approaches are limited because they require transformation labels when training their models and they lack a method for determining which regions of the manifold are appropriate for applying each specific operator. We address these limitati
&lt;/p&gt;</description></item></channel></rss>