<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;$f$-&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($f$-MIP)&#27010;&#24565;&#65292;&#24182;&#20998;&#26512;&#20102;&#20284;&#28982;&#27604;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;$\mu$-&#39640;&#26031;&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($\mu$-GMIP)&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#20998;&#26512;&#24615;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;&#35757;&#32451;&#22823;&#37327;&#24433;&#23376;&#27169;&#22411;&#12290;&#24378;&#35843;&#20102;&#26041;&#24046;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07273</link><description>&lt;p&gt;
&#39640;&#26031;&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Gaussian Membership Inference Privacy. (arXiv:2306.07273v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07273
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;$f$-&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($f$-MIP)&#27010;&#24565;&#65292;&#24182;&#20998;&#26512;&#20102;&#20284;&#28982;&#27604;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;$\mu$-&#39640;&#26031;&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($\mu$-GMIP)&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#20998;&#26512;&#24615;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;&#35757;&#32451;&#22823;&#37327;&#24433;&#23376;&#27169;&#22411;&#12290;&#24378;&#35843;&#20102;&#26041;&#24046;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#38544;&#31169;&#27010;&#24565;&#65292;&#31216;&#20026;$f$-&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($f$-MIP)&#65292;&#23427;&#26126;&#30830;&#32771;&#34385;&#20102;&#22312;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#23041;&#32961;&#27169;&#22411;&#19979;&#29616;&#23454;&#23545;&#25163;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;$f$-MIP&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#25913;&#36827;&#30340;&#25928;&#29992;(&#20363;&#22914;&#26356;&#22909;&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;)&#12290;&#25105;&#20204;&#23545;&#22122;&#22768;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#20284;&#28982;&#27604;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#36827;&#34892;&#20102;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#21442;&#25968;&#21270;&#30340;$f$-MIP&#20445;&#35777;&#26063;&#65292;&#31216;&#20026;$\mu$-&#39640;&#26031;&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($\mu$-GMIP)&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#20135;&#29983;&#20102;&#19968;&#31181;&#20998;&#26512;&#24615;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#39318;&#20808;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#25915;&#20987;&#19981;&#38656;&#35201;&#35757;&#32451;&#25968;&#30334;&#20010;&#24433;&#23376;&#27169;&#22411;&#26469;&#36924;&#36817;&#20284;&#28982;&#27604;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25915;&#20987;&#20351;&#24471;$f$-MIP&#30340;&#31616;&#21333;&#23457;&#35745;&#25104;&#20026;&#21487;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#24378;&#35843;&#20102;&#26041;&#24046;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new privacy notion called $f$-Membership Inference Privacy ($f$-MIP), which explicitly considers the capabilities of realistic adversaries under the membership inference attack threat model. By doing so $f$-MIP offers interpretable privacy guarantees and improved utility (e.g., better classification accuracy). Our novel theoretical analysis of likelihood ratio-based membership inference attacks on noisy stochastic gradient descent (SGD) results in a parametric family of $f$-MIP guarantees that we refer to as $\mu$-Gaussian Membership Inference Privacy ($\mu$-GMIP). Our analysis additionally yields an analytical membership inference attack that offers distinct advantages over previous approaches. First, unlike existing methods, our attack does not require training hundreds of shadow models to approximate the likelihood ratio. Second, our analytical attack enables straightforward auditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes the importance of vario
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20026;&#35299;&#20915;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#21464;&#37327;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31934;&#24230;&#30697;&#38453;&#30340;$l_p$&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#39057;&#29575;&#23398;&#27966;&#21644;&#36125;&#21494;&#26031;&#23398;&#27966;&#30340;&#20248;&#28857;&#34701;&#21512;&#22312;&#21464;&#20998;&#25512;&#29702;&#20013;&#65292;&#24182;&#24341;&#20837;&#20102;&#30697;&#38453;&#21464;&#37327;&#26631;&#20934;&#21270;&#27969;&#31243;&#26469;&#36924;&#36817;&#21518;&#39564;&#12290;</title><link>http://arxiv.org/abs/2306.07255</link><description>&lt;p&gt;
&#38024;&#23545;&#39640;&#26031;&#22270;&#27169;&#22411;&#30340;&#26465;&#20214;&#30697;&#38453;&#27969;
&lt;/p&gt;
&lt;p&gt;
Conditional Matrix Flows for Gaussian Graphical Models. (arXiv:2306.07255v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;&#35299;&#20915;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#21464;&#37327;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31934;&#24230;&#30697;&#38453;&#30340;$l_p$&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#39057;&#29575;&#23398;&#27966;&#21644;&#36125;&#21494;&#26031;&#23398;&#27966;&#30340;&#20248;&#28857;&#34701;&#21512;&#22312;&#21464;&#20998;&#25512;&#29702;&#20013;&#65292;&#24182;&#24341;&#20837;&#20102;&#30697;&#38453;&#21464;&#37327;&#26631;&#20934;&#21270;&#27969;&#31243;&#26469;&#36924;&#36817;&#21518;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23569;&#25968;&#35266;&#27979;&#21464;&#37327;&#20013;&#30740;&#31350;&#35768;&#22810;&#21464;&#37327;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#39640;&#26031;&#22270;&#27169;&#22411;&#36890;&#36807;&#22312;$l_p$&#27491;&#21017;&#21270;&#20013;&#40723;&#21169;&#31934;&#24230;&#30697;&#38453;&#30340;&#31232;&#30095;&#24615;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#65292;&#20854;&#20013;$p \leq1$&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20122;-$l_1$&#20266;&#33539;&#25968;&#20351;&#30446;&#26631;&#39640;&#24230;&#38750;&#20984;&#65292;&#22240;&#27492;&#22823;&#22810;&#25968;&#26041;&#27861;&#20381;&#36182;&#20110;$l_1$&#33539;&#25968;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#20801;&#35768;&#20248;&#38597;&#22320;&#35745;&#31639;&#20316;&#20026;&#25910;&#32553;&#21442;&#25968;$\lambda$&#20989;&#25968;&#30340;&#35299;&#20915;&#26041;&#26696;&#36335;&#24452;&#12290;&#36125;&#21494;&#26031;&#20844;&#24335;&#20026;&#31934;&#24230;&#30697;&#38453;&#24341;&#20837;&#20102;&#25289;&#26222;&#25289;&#26031;&#20808;&#39564;&#65292;&#20294;&#26159;&#19981;&#21516;$\lambda$&#20540;&#30340;&#21518;&#39564;&#25512;&#26029;&#38656;&#35201;&#22810;&#27425;&#36816;&#34892;&#26114;&#36149;&#30340;&#21513;&#24067;&#26031;&#37319;&#26679;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#24120;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;GGM&#30340;&#21464;&#20998;&#25512;&#29702;&#65292;&#23427;&#32479;&#19968;&#20102;&#39057;&#29575;&#23398;&#27966;&#21644;&#36125;&#21494;&#26031;&#23398;&#27966;&#30340;&#20248;&#28857;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#35758;&#29992;&#23450;&#20041;&#22312;s&#31354;&#38388;&#19978;&#30340;&#30697;&#38453;&#21464;&#37327;&#26631;&#20934;&#21270;&#27969;&#31243;&#26469;&#36924;&#36817;&#21518;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Studying conditional independence structure among many variables with few observations is a challenging task. Gaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through an $l_p$ regularization with $p\leq1$. However, since the objective is highly non-convex for sub-$l_1$ pseudo-norms, most approaches rely on the $l_1$ norm. In this case frequentist approaches allow to elegantly compute the solution path as a function of the shrinkage parameter $\lambda$. Instead of optimizing the penalized likelihood, the Bayesian formulation introduces a Laplace prior on the precision matrix. However, posterior inference for different $\lambda$ values requires repeated runs of expensive Gibbs samplers. We propose a very general framework for variational inference in GGMs that unifies the benefits of frequentist and Bayesian frameworks. Specifically, we propose to approximate the posterior with a matrix-variate Normalizing Flow defined on the space of s
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#37327;&#21270;&#26041;&#27861;&#20197;&#21450;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07254</link><description>&lt;p&gt;
&#20851;&#20110;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#26399;&#26395;&#22823;&#23567;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Expected Size of Conformal Prediction Sets. (arXiv:2306.07254v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07254
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#37327;&#21270;&#26041;&#27861;&#20197;&#21450;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#36866;&#24212;&#24615;&#39044;&#27979;&#22120;&#22312;&#35823;&#24046;&#39057;&#29575;&#26041;&#38754;&#20855;&#26377;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#20294;&#20854;&#39044;&#27979;&#38598;&#22823;&#23567;&#23545;&#20854;&#23454;&#38469;&#25928;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30446;&#21069;&#32570;&#20047;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#21644;&#39044;&#27979;&#38598;&#22823;&#23567;&#30340;&#20445;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#20998;&#35010;&#36866;&#24212;&#24615;&#39044;&#27979;&#26694;&#26550;&#19979;&#29702;&#35770;&#37327;&#21270;&#39044;&#27979;&#38598;&#30340;&#26399;&#26395;&#22823;&#23567;&#12290;&#22240;&#20026;&#36825;&#31181;&#31934;&#30830;&#30340;&#35745;&#31639;&#36890;&#24120;&#26080;&#27861;&#30452;&#25509;&#35745;&#31639;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25512;&#23548;&#20986;&#21487;&#36731;&#26494;&#35745;&#31639;&#30340;&#28857;&#20272;&#35745;&#21644;&#39640;&#27010;&#29575;&#21306;&#38388;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#25551;&#36848;&#27979;&#35797;&#21644;&#26657;&#20934;&#25968;&#25454;&#19981;&#21516;&#21487;&#33021;&#23454;&#29616;&#30340;&#26399;&#26395;&#39044;&#27979;&#38598;&#22823;&#23567;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#22238;&#24402;&#21644;&#20998;&#31867;&#38382;&#39064;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While conformal predictors reap the benefits of rigorous statistical guarantees for their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction set under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high probability intervals that can be easily computed, providing a practical method for characterizing the expected prediction set size across different possible realizations of the test and calibration data. Additionally, we corroborate the efficacy of our results with experiments on real-world datasets, for both regression and classification problems.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#32780;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;</title><link>http://arxiv.org/abs/2306.07252</link><description>&lt;p&gt;
&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07252
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#32780;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#24120;&#35265;&#38750;&#20195;&#34920;&#24615;&#33410;&#28857;&#37319;&#26679;&#26426;&#21046;&#19979;&#30340;&#32593;&#32476;&#25968;&#25454;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#24615;&#36136;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#37319;&#26679;&#26426;&#21046;&#35299;&#37322;&#20026;&#24212;&#29992;&#20110;&#36229;&#24635;&#20307;&#30340;&#36873;&#25321;&#35268;&#21017;&#65292;&#24182;&#22312;&#36866;&#24403;&#30340;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#30740;&#31350;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#37319;&#26679;&#23376;&#38453;&#21015;&#22312;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#26159;&#21487;&#20132;&#25442;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#24403;&#25968;&#25454;&#36890;&#36807;&#22270;&#19978;&#30340;&#38543;&#26426;&#28216;&#36208;&#26469;&#37319;&#26679;&#26102;&#65292;&#21152;&#26435;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#21464;&#20307;&#21487;&#20197;&#23545;&#20154;&#21475;&#29420;&#31435;&#36873;&#25321;&#33410;&#28857;&#30340;&#39044;&#27979;&#38598;&#36827;&#34892;&#28176;&#36817;&#26377;&#25928;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the properties of conformal prediction for network data under various sampling mechanisms that commonly arise in practice but often result in a non-representative sample of nodes. We interpret these sampling mechanisms as selection rules applied to a superpopulation and study the validity of conformal prediction conditional on an appropriate selection event. We show that the sampled subarray is exchangeable conditional on the selection event if the selection rule satisfies a permutation invariance property and a joint exchangeability condition holds for the superpopulation. Our result implies the finite-sample validity of conformal prediction for certain selection events related to ego networks and snowball sampling. We also show that when data are sampled via a random walk on a graph, a variant of weighted conformal prediction yields asymptotically valid prediction sets for an independently selected node from the population.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28145;&#24230;&#39640;&#26031;&#28151;&#21512;&#38598;&#21512;&#27169;&#22411;&#65292;&#21487;&#36924;&#36817;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#33021;&#22815;&#20934;&#30830;&#37327;&#21270;&#20808;&#39564;&#35823;&#24046;&#21644;&#21518;&#39564;&#35823;&#24046;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.07235</link><description>&lt;p&gt;
&#28145;&#24230;&#39640;&#26031;&#28151;&#21512;&#38598;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Deep Gaussian Mixture Ensembles. (arXiv:2306.07235v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07235
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28145;&#24230;&#39640;&#26031;&#28151;&#21512;&#38598;&#21512;&#27169;&#22411;&#65292;&#21487;&#36924;&#36817;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#33021;&#22815;&#20934;&#30830;&#37327;&#21270;&#20808;&#39564;&#35823;&#24046;&#21644;&#21518;&#39564;&#35823;&#24046;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#31216;&#20026;&#28145;&#24230;&#39640;&#26031;&#28151;&#21512;&#38598;&#21512; (DGMEs)&#65292;&#21487;&#23454;&#29616;&#23545;&#20808;&#39564;&#35823;&#24046;&#21644;&#21518;&#39564;&#35823;&#24046;&#30340;&#20934;&#30830;&#37327;&#21270;&#12290;&#36890;&#36807;&#20551;&#35774;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#31526;&#21512;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65292;DGMEs &#33021;&#22815;&#36924;&#36817;&#22797;&#26434;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#20363;&#22914;&#37325;&#23614;&#25110;&#22810;&#23792;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#25512;&#23548;&#20986;&#29992;&#20110;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270; (EM) &#31639;&#27861;&#65292;&#36825;&#23558;&#24471;&#21040;&#23545;&#26631;&#20934;&#28145;&#24230;&#38598;&#21512;&#30340;&#35757;&#32451;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#30340;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340; EM &#35757;&#32451;&#36807;&#31243;&#20801;&#35768;&#23398;&#20064;&#28151;&#21512;&#26435;&#37325;&#65292;&#36825;&#22312;&#38598;&#21512;&#20013;&#36890;&#24120;&#19981;&#20250;&#20570;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;DGMEs &#22312;&#22788;&#29702;&#22797;&#26434;&#39044;&#27979;&#23494;&#24230;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces a novel probabilistic deep learning technique called deep Gaussian mixture ensembles (DGMEs), which enables accurate quantification of both epistemic and aleatoric uncertainty. By assuming the data generating process follows that of a Gaussian mixture, DGMEs are capable of approximating complex probability distributions, such as heavy-tailed or multimodal distributions. Our contributions include the derivation of an expectation-maximization (EM) algorithm used for learning the model parameters, which results in an upper-bound on the log-likelihood of training data over that of standard deep ensembles. Additionally, the proposed EM training procedure allows for learning of mixture weights, which is not commonly done in ensembles. Our experimental results demonstrate that DGMEs outperform state-of-the-art uncertainty quantifying deep learning models in handling complex predictive densities.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#36890;&#36807;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#35777;&#26126;&#20102;&#32771;&#34385;&#21040;&#26377;&#38480;&#31890;&#23376;&#36924;&#36817;&#35823;&#24046;&#12289;&#26102;&#38388;&#31163;&#25955;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#36924;&#36817;&#30340; MFLD &#22312;&#26102;&#38388;&#19978;&#19968;&#33268;&#25910;&#25947;&#65292;&#20026;&#31070;&#32463;&#32593;&#32476;&#21644; MMD &#26368;&#23567;&#21270;&#31561;&#24191;&#27867;&#23398;&#20064;&#38382;&#39064;&#25552;&#20379;&#20102;&#37327;&#21270;&#25910;&#25947;&#36895;&#29575;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.07221</link><description>&lt;p&gt;
&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#24615;: &#26102;&#38388;&#21644;&#31354;&#38388;&#31163;&#25955;&#21270;&#65292;&#38543;&#26426;&#26799;&#24230;&#21644;&#26041;&#24046;&#20943;&#23569;
&lt;/p&gt;
&lt;p&gt;
Convergence of mean-field Langevin dynamics: Time and space discretization, stochastic gradient, and variance reduction. (arXiv:2306.07221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07221
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#36890;&#36807;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#35777;&#26126;&#20102;&#32771;&#34385;&#21040;&#26377;&#38480;&#31890;&#23376;&#36924;&#36817;&#35823;&#24046;&#12289;&#26102;&#38388;&#31163;&#25955;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#36924;&#36817;&#30340; MFLD &#22312;&#26102;&#38388;&#19978;&#19968;&#33268;&#25910;&#25947;&#65292;&#20026;&#31070;&#32463;&#32593;&#32476;&#21644; MMD &#26368;&#23567;&#21270;&#31561;&#24191;&#27867;&#23398;&#20064;&#38382;&#39064;&#25552;&#20379;&#20102;&#37327;&#21270;&#25910;&#25947;&#36895;&#29575;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#65288;MFLD&#65289;&#26159; Langevin &#21160;&#21147;&#23398;&#30340;&#38750;&#32447;&#24615;&#25512;&#24191;&#65292;&#23427;&#21253;&#21547;&#19968;&#20010;&#20998;&#24067;&#30456;&#20851;&#30340;&#28418;&#31227;&#65292;&#24182;&#36890;&#36807;&#65288;&#24102;&#22122;&#65289;&#26799;&#24230;&#19979;&#38477;&#20174;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#20013;&#33258;&#28982;&#20135;&#29983;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;MFLD &#22312;&#27979;&#24230;&#31354;&#38388;&#20013;&#20840;&#23616;&#26368;&#23567;&#21270;&#29109;&#27491;&#21017;&#21270;&#30340;&#20984;&#27867;&#20989;&#12290;&#28982;&#32780;&#65292;&#20197;&#21069;&#30340;&#25152;&#26377;&#20998;&#26512;&#37117;&#20551;&#35774;&#20102;&#26080;&#38480;&#31890;&#23376;&#25110;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;&#65292;&#24182;&#19988;&#26080;&#27861;&#22788;&#29702;&#38543;&#26426;&#26799;&#24230;&#26356;&#26032;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#32771;&#34385;&#21040;&#26377;&#38480;&#31890;&#23376;&#36924;&#36817;&#35823;&#24046;&#12289;&#26102;&#38388;&#31163;&#25955;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#36924;&#36817;&#30340; MFLD &#22312;&#26102;&#38388;&#19978;&#19968;&#33268;&#25910;&#25947;&#12290;&#20026;&#20102;&#23637;&#31034;&#35813;&#26694;&#26550;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#37327;&#21270;&#25910;&#25947;&#36895;&#29575;&#20445;&#35777;&#65292;&#20197;&#33719;&#24471;&#65288;i&#65289;&#20687;&#22312;&#22343;&#22330;&#21306;&#22495;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644; MMD &#26368;&#23567;&#21270;&#36825;&#26679;&#30340;&#24191;&#27867;&#23398;&#20064;&#38382;&#39064;&#30340;&#27491;&#21017;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#20197;&#21450;&#65288;ii&#65289;
&lt;/p&gt;
&lt;p&gt;
The mean-field Langevin dynamics (MFLD) is a nonlinear generalization of the Langevin dynamics that incorporates a distribution-dependent drift, and it naturally arises from the optimization of two-layer neural networks via (noisy) gradient descent. Recent works have shown that MFLD globally minimizes an entropy-regularized convex functional in the space of measures. However, all prior analyses assumed the infinite-particle or continuous-time limit, and cannot handle stochastic gradient updates. We provide an general framework to prove a uniform-in-time propagation of chaos for MFLD that takes into account the errors due to finite-particle approximation, time-discretization, and stochastic gradient approximation. To demonstrate the wide applicability of this framework, we establish quantitative convergence rate guarantees to the regularized global optimal solution under (i) a wide range of learning problems such as neural network in the mean-field regime and MMD minimization, and (ii) 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#31639;&#27861;&#22522;&#20934;&#27979;&#35797;&#20013;&#23384;&#22312;&#30340;&#19977;&#20010;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#65292;&#20197;&#20419;&#36827;&#35757;&#32451;&#31639;&#27861;&#25928;&#29575;&#30340;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2306.07179</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#31639;&#27861;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Neural Network Training Algorithms. (arXiv:2306.07179v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07179
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#31639;&#27861;&#22522;&#20934;&#27979;&#35797;&#20013;&#23384;&#22312;&#30340;&#19977;&#20010;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#65292;&#20197;&#20419;&#36827;&#35757;&#32451;&#31639;&#27861;&#25928;&#29575;&#30340;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#31639;&#27861;&#26159;&#27599;&#20010;&#28145;&#24230;&#23398;&#20064;&#27969;&#31243;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#25552;&#39640;&#35757;&#32451;&#31639;&#27861;&#30340;&#25928;&#29575;&#21487;&#20197;&#33410;&#30465;&#26102;&#38388;&#12289;&#35745;&#31639;&#36164;&#28304;&#65292;&#24182;&#24102;&#26469;&#26356;&#22909;&#12289;&#26356;&#20934;&#30830;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30446;&#21069;&#36824;&#26080;&#27861;&#21487;&#38752;&#22320;&#30830;&#23450;&#26368;&#20808;&#36827;&#30340;&#35757;&#32451;&#31639;&#27861;&#12290;&#26412;&#25991;&#36890;&#36807;&#20855;&#20307;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#21152;&#36895;&#35757;&#32451;&#30340;&#30495;&#27491;&#36827;&#23637;&#38656;&#35201;&#35299;&#20915;&#19977;&#20010;&#22522;&#26412;&#25361;&#25112;&#65306;&#22914;&#20309;&#30830;&#23450;&#35757;&#32451;&#20309;&#26102;&#32467;&#26463;&#24182;&#31934;&#30830;&#27979;&#37327;&#35757;&#32451;&#26102;&#38388;&#65292;&#22914;&#20309;&#22788;&#29702;&#27979;&#37327;&#23545;&#30830;&#20999;&#24037;&#20316;&#36127;&#36733;&#35814;&#24773;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#20844;&#24179;&#27604;&#36739;&#38656;&#35201;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#31639;&#27861;&#12290;&#20026;&#20102;&#22686;&#21152;&#23545;&#35757;&#32451;&#31639;&#27861;&#25928;&#29575;&#30340;&#20102;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#35774;&#35745;&#20102;&#19968;&#20123;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training algorithms, broadly construed, are an essential part of every deep learning pipeline. Training algorithm improvements that speed up training across a wide variety of workloads (e.g., better update rules, tuning protocols, learning rate schedules, or data selection schemes) could save time, save computational resources, and lead to better, more accurate, models. Unfortunately, as a community, we are currently unable to reliably identify training algorithm improvements, or even determine the state-of-the-art training algorithm. In this work, using concrete experiments, we argue that real progress in speeding up training requires new benchmarks that resolve three basic challenges faced by empirical comparisons of training algorithms: (1) how to decide when training is complete and precisely measure training time, (2) how to handle the sensitivity of measurements to exact workload details, and (3) how to fairly compare algorithms that require hyperparameter tuning. In order to add
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#36716;&#25442;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#36716;&#25442;&#20026;&#20855;&#26377;&#20302;&#949;-&#36817;&#20284;&#36951;&#25022;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#22810;&#31181;&#38382;&#39064;&#24182;&#23454;&#29616;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#36817;&#20284;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.07163</link><description>&lt;p&gt;
&#19968;&#33324;&#36716;&#25442;&#26500;&#24314;&#19968;&#33268;&#30340;&#22312;&#32447;&#36817;&#20284;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
General Transformation for Consistent Online Approximation Algorithms. (arXiv:2306.07163v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07163
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#36716;&#25442;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#36716;&#25442;&#20026;&#20855;&#26377;&#20302;&#949;-&#36817;&#20284;&#36951;&#25022;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#22810;&#31181;&#38382;&#39064;&#24182;&#23454;&#29616;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#36817;&#20284;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36716;&#25442;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#20174;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#20013;&#24320;&#21457;&#20855;&#26377;&#20302;&#949;-&#36817;&#20284;&#36951;&#25022;&#30340;&#22312;&#32447;&#31639;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#20102;&#19968;&#20010;&#23558;&#20855;&#26377;&#20302;&#24179;&#22343;&#25935;&#24863;&#24230;&#30340;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#36716;&#25442;&#20026;&#20855;&#26377;&#20302;&#949;-&#36817;&#20284;&#36951;&#25022;&#30340;&#22312;&#32447;&#31639;&#27861;&#30340;&#36890;&#29992;&#32422;&#31616;&#23450;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;coreset&#26500;&#36896;&#26041;&#27861;&#23558;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#36716;&#25442;&#20026;&#20302;&#25935;&#24863;&#24230;&#29256;&#26412;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#22810;&#26679;&#24615;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#65292;&#21253;&#25324;&#22312;&#32447;(k&#65292;z)-&#32858;&#31867;&#12289;&#22312;&#32447;&#30697;&#38453;&#36924;&#36817;&#21644;&#22312;&#32447;&#22238;&#24402;&#65292;&#24182;&#25104;&#21151;&#22320;&#20026;&#27599;&#20010;&#38382;&#39064;&#23454;&#29616;&#20102;&#23545;&#25968;&#22810;&#39033;&#24335;&#949;-&#36817;&#20284;&#36951;&#25022;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#25152;&#26377;&#19977;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20063;&#20139;&#26377;&#20302;&#19981;&#19968;&#33268;&#24615;&#65292;&#36825;&#21487;&#33021;&#26159;&#26576;&#20123;&#22312;&#32447;&#24212;&#29992;&#31243;&#24207;&#25152;&#38656;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a transformation framework that can be utilized to develop online algorithms with low $\epsilon$-approximate regret in the random-order model from offline approximation algorithms. We first give a general reduction theorem that transforms an offline approximation algorithm with low average sensitivity to an online algorithm with low $\epsilon$-approximate regret. We then demonstrate that offline approximation algorithms can be transformed into a low-sensitivity version using a coreset construction method. To showcase the versatility of our approach, we apply it to various problems, including online $(k,z)$-clustering, online matrix approximation, and online regression, and successfully achieve polylogarithmic $\epsilon$-approximate regret for each problem. Moreover, we show that in all three cases, our algorithm also enjoys low inconsistency, which may be desired in some online applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#24230;&#37327;&#30340;&#31616;&#21333;&#21442;&#25968;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#26041;&#27861;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#23545;&#20808;&#39564;&#36873;&#25321;&#19981;&#36807;&#24230;&#25935;&#24863;&#65292;&#21487;&#20197;&#36739;&#22909;&#22320;&#25913;&#21892;&#20256;&#32479;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.07158</link><description>&lt;p&gt;
&#22522;&#20110;&#40654;&#26364;&#27969;&#24418;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Riemannian Laplace approximations for Bayesian neural networks. (arXiv:2306.07158v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#24230;&#37327;&#30340;&#31616;&#21333;&#21442;&#25968;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#26041;&#27861;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#23545;&#20808;&#39564;&#36873;&#25321;&#19981;&#36807;&#24230;&#25935;&#24863;&#65292;&#21487;&#20197;&#36739;&#22909;&#22320;&#25913;&#21892;&#20256;&#32479;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#29992;&#39640;&#26031;&#20998;&#24067;&#26469;&#36817;&#20284;&#26435;&#20540;&#21518;&#39564;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#21518;&#39564;&#20998;&#24067;&#24448;&#24448;&#26159;&#39640;&#24230;&#38750;&#39640;&#26031;&#30340;&#65292;&#21363;&#20351;&#26159;&#22312;&#23616;&#37096;&#24773;&#20917;&#19979;&#65292;&#27169;&#22411;&#34920;&#29616;&#20063;&#20250;&#24694;&#21270;&#12290;&#22312;&#26412;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21442;&#25968;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#26041;&#27861;&#65292;&#36890;&#36807;&#29992;&#40654;&#26364;&#24230;&#37327;&#26469;&#30830;&#23450;&#23545;&#25968;&#21518;&#39564;&#26799;&#24230;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#65292;&#22312;&#36825;&#31181;&#36924;&#36817;&#19979;&#65292;&#26679;&#26412;&#20250;&#33258;&#28982;&#22320;&#33853;&#20837;&#36127;&#23545;&#25968;&#21518;&#39564;&#23567;&#30340;&#26435;&#20540;&#21306;&#22495;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#20123;&#26679;&#26412;&#21487;&#20197;&#36890;&#36807;&#35299;&#19968;&#32452;&#24120;&#24494;&#20998;&#26041;&#31243;&#26469;&#25277;&#21462;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#40654;&#26364;&#24230;&#37327;&#21644;&#33258;&#21160;&#24494;&#20998;&#30340;&#32467;&#26500;&#26469;&#39640;&#25928;&#22320;&#23436;&#25104;&#12290;&#22312;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#22343;&#27604;&#20256;&#32479;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#34920;&#29616;&#26356;&#22909;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#65292;&#19982;&#20256;&#32479;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20808;&#39564;&#36873;&#25321;&#19981;&#36807;&#24230;&#25935;&#24863;&#65292;&#36825;&#32531;&#35299;&#20102;&#20808;&#39564;&#36873;&#25321;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian neural networks often approximate the weight-posterior with a Gaussian distribution. However, practical posteriors are often, even locally, highly non-Gaussian, and empirical performance deteriorates. We propose a simple parametric approximate posterior that adapts to the shape of the true posterior through a Riemannian metric that is determined by the log-posterior gradient. We develop a Riemannian Laplace approximation where samples naturally fall into weight-regions with low negative log-posterior. We show that these samples can be drawn by solving a system of ordinary differential equations, which can be done efficiently by leveraging the structure of the Riemannian metric and automatic differentiation. Empirically, we demonstrate that our approach consistently improves over the conventional Laplace approximation across tasks. We further show that, unlike the conventional Laplace approximation, our method is not overly sensitive to the choice of prior, which alleviates a p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#22810;&#26679;&#25237;&#24433;&#38598;&#21512;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#38598;&#21512;&#24046;&#24322;&#24230;&#37327;&#30340;&#31639;&#27861;&#65292;&#20197;&#20419;&#36827;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.07124</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#30340;&#22810;&#26679;&#25237;&#24433;&#38598;&#21512;
&lt;/p&gt;
&lt;p&gt;
Diverse Projection Ensembles for Distributional Reinforcement Learning. (arXiv:2306.07124v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07124
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#22810;&#26679;&#25237;&#24433;&#38598;&#21512;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#38598;&#21512;&#24046;&#24322;&#24230;&#37327;&#30340;&#31639;&#27861;&#65292;&#20197;&#20419;&#36827;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20256;&#32479;&#30340;&#24378;&#21270;&#23398;&#20064;&#19981;&#21516;&#65292;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26088;&#22312;&#23398;&#20064;&#22238;&#25253;&#30340;&#20998;&#24067;&#32780;&#19981;&#26159;&#20854;&#26399;&#26395;&#20540;&#12290;&#30001;&#20110;&#22238;&#25253;&#20998;&#24067;&#30340;&#24615;&#36136;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#25110;&#36807;&#20110;&#22797;&#26434;&#65292;&#22240;&#27492;&#36890;&#24120;&#37319;&#29992;&#23558;&#26410;&#32422;&#26463;&#30340;&#20998;&#24067;&#25237;&#24433;&#21040;&#21487;&#34920;&#31034;&#30340;&#21442;&#25968;&#20998;&#24067;&#38598;&#21512;&#20013;&#30340;&#26041;&#27861;&#36827;&#34892;&#36924;&#36817;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#24403;&#23558;&#36825;&#31181;&#25237;&#24433;&#27493;&#39588;&#19982;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#19979;&#38477;&#30456;&#32467;&#21512;&#26102;&#65292;&#36825;&#31181;&#25237;&#24433;&#27493;&#39588;&#20250;&#20135;&#29983;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#35265;&#65292;&#20174;&#32780;&#28145;&#21051;&#24433;&#21709;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#34892;&#20026;&#12290;&#20026;&#20102;&#36890;&#36807;&#22810;&#26679;&#24615;&#20419;&#36827;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#38598;&#21512;&#20013;&#22810;&#20010;&#19981;&#21516;&#30340;&#25237;&#24433;&#21644;&#34920;&#31034;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#31181;&#25237;&#24433;&#38598;&#21512;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#31181;&#20351;&#29992;&#38598;&#21512;&#24046;&#24322;&#24230;&#37327;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In contrast to classical reinforcement learning, distributional reinforcement learning algorithms aim to learn the distribution of returns rather than their expected value. Since the nature of the return distribution is generally unknown a priori or arbitrarily complex, a common approach finds approximations within a set of representable, parametric distributions. Typically, this involves a projection of the unconstrained distribution onto the set of simplified distributions. We argue that this projection step entails a strong inductive bias when coupled with neural networks and gradient descent, thereby profoundly impacting the generalization behavior of learned models. In order to facilitate reliable uncertainty estimation through diversity, this work studies the combination of several different projections and representations in a distributional ensemble. We establish theoretical properties of such projection ensembles and derive an algorithm that uses ensemble disagreement, measure
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#30456;&#23545;&#29109;&#27491;&#21017;&#21270;&#20013;&#30340;&#19981;&#23545;&#31216;&#24615;&#23545;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#24433;&#21709;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;Type-II&#27491;&#21017;&#21270;&#26469;&#20801;&#35768;&#35299;&#20915;&#26041;&#26696;&#26356;&#24191;&#27867;&#12290;&#35813;&#20998;&#26512;&#25581;&#31034;&#20986;&#30456;&#23545;&#29109;&#23558;&#22312;ERM-RER&#38382;&#39064;&#20013;&#24341;&#20837;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.07123</link><description>&lt;p&gt;
&#30456;&#23545;&#29109;&#19981;&#23545;&#31216;&#24615;&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#27491;&#21017;&#21270;&#20013;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of the Relative Entropy Asymmetry in the Regularization of Empirical Risk Minimization. (arXiv:2306.07123v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#30456;&#23545;&#29109;&#27491;&#21017;&#21270;&#20013;&#30340;&#19981;&#23545;&#31216;&#24615;&#23545;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#24433;&#21709;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;Type-II&#27491;&#21017;&#21270;&#26469;&#20801;&#35768;&#35299;&#20915;&#26041;&#26696;&#26356;&#24191;&#27867;&#12290;&#35813;&#20998;&#26512;&#25581;&#31034;&#20986;&#30456;&#23545;&#29109;&#23558;&#22312;ERM-RER&#38382;&#39064;&#20013;&#24341;&#20837;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#30456;&#23545;&#29109;&#19981;&#23545;&#31216;&#24615;&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30456;&#23545;&#29109;&#27491;&#21017;&#21270;&#65288;ERM-RER&#65289;&#38382;&#39064;&#20013;&#30340;&#24433;&#21709;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#22411;&#27491;&#21017;&#21270;&#65292;&#31216;&#20026;Type-II&#27491;&#21017;&#21270;&#65292;&#20801;&#35768;ERM-RER&#38382;&#39064;&#30340;&#35299;&#22312;&#36229;&#20986;&#21442;&#32771;&#24230;&#37327;&#25903;&#25345;&#30340;&#25903;&#25345;&#19979;&#24471;&#21040;&#35299;&#20915;&#12290;&#26032;ERM-RER Type-II&#38382;&#39064;&#30340;&#35299;&#20197;&#21442;&#32771;&#24230;&#37327;&#19982;&#35299;&#20043;&#38388;&#30340;Radon-Nikodym&#23548;&#25968;&#20026;&#29305;&#24449;&#36827;&#34892;&#20998;&#26512;&#12290;&#35299;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#30456;&#23545;&#29109;&#22312;ERM-RER&#38382;&#39064;&#20013;&#20316;&#20026;&#27491;&#21017;&#21270;&#22120;&#26102;&#30340;&#20197;&#19979;&#29305;&#24615;&#65306;i&#65289;&#30456;&#23545;&#29109;&#23558;Type-II&#35299;&#30340;&#25903;&#25345;&#24378;&#21046;&#32553;&#23567;&#21040;&#21442;&#32771;&#24230;&#37327;&#30340;&#25903;&#25345;&#33539;&#22260;&#20869;&#65292;&#24341;&#20837;&#20102;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#20027;&#23548;&#20102;&#35757;&#32451;&#25968;&#25454;&#25552;&#20379;&#30340;&#35777;&#25454;; ii&#65289;Type-II&#27491;&#21017;&#21270;&#31561;&#25928;&#20110;&#20351;&#29992;&#36866;&#24403;&#30340;&#21464;&#25442;&#36827;&#34892;&#32463;&#20856;&#30340;&#30456;&#23545;&#29109;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The effect of the relative entropy asymmetry is analyzed in the empirical risk minimization with relative entropy regularization (ERM-RER) problem. A novel regularization is introduced, coined Type-II regularization, that allows for solutions to the ERM-RER problem with a support that extends outside the support of the reference measure. The solution to the new ERM-RER Type-II problem is analytically characterized in terms of the Radon-Nikodym derivative of the reference measure with respect to the solution. The analysis of the solution unveils the following properties of relative entropy when it acts as a regularizer in the ERM-RER problem: i) relative entropy forces the support of the Type-II solution to collapse into the support of the reference measure, which introduces a strong inductive bias that dominates the evidence provided by the training data; ii) Type-II regularization is equivalent to classical relative entropy regularization with an appropriate transformation of the empi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#65292;&#25552;&#39640;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07119</link><description>&lt;p&gt;
&#22522;&#20110;&#8220;&#24179;&#22343;&#8221;&#30340;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#30340;&#25913;&#36827;&#65292;&#20197;&#39135;&#21697;&#38656;&#27714;&#39044;&#27979;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Improving Forecasts for Heterogeneous Time Series by "Averaging", with Application to Food Demand Forecast. (arXiv:2306.07119v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07119
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#65292;&#25552;&#39640;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24120;&#35265;&#39044;&#27979;&#22330;&#26223;&#26159;&#32771;&#34385;&#19968;&#32452;&#21487;&#33021;&#24322;&#36136;&#24615;&#30340;&#30456;&#21516;&#39046;&#22495;&#26102;&#38388;&#24207;&#21015;&#12290;&#30001;&#20110;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#19981;&#21516;&#29305;&#24615;&#65292;&#22914;&#38271;&#24230;&#31561;&#65292;&#30452;&#25509;&#23545;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#39044;&#27979;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#20013;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#25214;&#21040;&#30456;&#20284;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#20197;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#25552;&#20986;&#20102;&#20960;&#31181;&#25191;&#34892;&#24179;&#22343;&#30340;&#26041;&#27861;&#65292;&#24182;&#29702;&#35770;&#35777;&#26126;&#20102;&#24179;&#22343;&#23545;&#20110;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#35786;&#26029;&#24037;&#20855;&#65292;&#20801;&#35768;&#28145;&#20837;&#29702;&#35299;&#35813;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common forecasting setting in real world applications considers a set of possibly heterogeneous time series of the same domain. Due to different properties of each time series such as length, obtaining forecasts for each individual time series in a straight-forward way is challenging. This paper proposes a general framework utilizing a similarity measure in Dynamic Time Warping to find similar time series to build neighborhoods in a k-Nearest Neighbor fashion, and improve forecasts of possibly simple models by averaging. Several ways of performing the averaging are suggested, and theoretical arguments underline the usefulness of averaging for forecasting. Additionally, diagnostics tools are proposed allowing a deep understanding of the procedure.
&lt;/p&gt;</description></item><item><title>Hessian&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#25551;&#36848;&#20102;&#31070;&#32463;&#32593;&#32476;&#23398;&#21040;&#30340;&#20915;&#31574;&#36793;&#30028;&#65292;&#24322;&#24120;&#20540;&#25968;&#37327;&#19982;&#20915;&#31574;&#36793;&#30028;&#30340;&#22797;&#26434;&#24615;&#25104;&#27491;&#27604;&#65292;&#36825;&#21551;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#27867;&#21270;&#24230;&#37327;&#21644;&#36793;&#30028;&#20272;&#35745;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2306.07104</link><description>&lt;p&gt;
&#25581;&#31034;Hessian&#19982;&#20915;&#31574;&#36793;&#30028;&#30340;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;
Unveiling the Hessian's Connection to the Decision Boundary. (arXiv:2306.07104v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07104
&lt;/p&gt;
&lt;p&gt;
Hessian&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#25551;&#36848;&#20102;&#31070;&#32463;&#32593;&#32476;&#23398;&#21040;&#30340;&#20915;&#31574;&#36793;&#30028;&#65292;&#24322;&#24120;&#20540;&#25968;&#37327;&#19982;&#20915;&#31574;&#36793;&#30028;&#30340;&#22797;&#26434;&#24615;&#25104;&#27491;&#27604;&#65292;&#36825;&#21551;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#27867;&#21270;&#24230;&#37327;&#21644;&#36793;&#30028;&#20272;&#35745;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#33391;&#22909;&#27867;&#21270;&#26368;&#23567;&#20540;&#30340;&#23646;&#24615;&#26159;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#30340;&#26680;&#24515;&#12290;&#19968;&#26041;&#38754;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#19982;&#20915;&#31574;&#36793;&#30028;&#22797;&#26434;&#24615;&#26377;&#20851;&#65292;&#32780;&#22312;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#38590;&#20197;&#30740;&#31350;&#12290;&#30456;&#21453;&#65292;&#26368;&#23567;&#20540;&#30340;&#24179;&#22374;&#24615;&#24050;&#25104;&#20026;&#27867;&#21270;&#30340;&#26377;&#20105;&#35758;&#30340;&#20195;&#29702;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#32570;&#22833;&#38142;&#25509;&#65292;&#24182;&#23637;&#31034;&#20102;Hessian&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#25551;&#36848;&#20102;&#31070;&#32463;&#32593;&#32476;&#23398;&#21040;&#30340;&#20915;&#31574;&#36793;&#30028;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;Hessian&#35889;&#20013;&#30340;&#24322;&#24120;&#20540;&#25968;&#37327;&#19982;&#20915;&#31574;&#36793;&#30028;&#30340;&#22797;&#26434;&#24615;&#25104;&#27491;&#27604;&#12290;&#22522;&#20110;&#27492;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#30740;&#31350;&#39640;&#32500;&#20915;&#31574;&#36793;&#30028;&#22797;&#26434;&#24615;&#30340;&#26032;&#32780;&#31616;&#21333;&#30340;&#26041;&#27861;; &#34920;&#26126;&#35813;&#36830;&#25509;&#33258;&#28982;&#22320;&#21551;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#27867;&#21270;&#24230;&#37327;; &#26368;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#36793;&#30028;&#20272;&#35745;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#19982;&#27867;&#21270;&#24230;&#37327;&#32467;&#21512;&#20351;&#29992;&#65292;&#31934;&#30830;&#22320;&#30830;&#23450;&#21508;&#31181;&#27169;&#22411;&#30340;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the properties of well-generalizing minima is at the heart of deep learning research. On the one hand, the generalization of neural networks has been connected to the decision boundary complexity, which is hard to study in the high-dimensional input space. Conversely, the flatness of a minimum has become a controversial proxy for generalization. In this work, we provide the missing link between the two approaches and show that the Hessian top eigenvectors characterize the decision boundary learned by the neural network. Notably, the number of outliers in the Hessian spectrum is proportional to the complexity of the decision boundary. Based on this finding, we provide a new and straightforward approach to studying the complexity of a high-dimensional decision boundary; show that this connection naturally inspires a new generalization measure; and finally, we develop a novel margin estimation technique which, in combination with the generalization measure, precisely identif
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411; LDIDPs&#65292;&#21033;&#29992;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;&#20174;&#21160;&#24577;&#28508;&#22312;&#36807;&#31243;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#28982;&#21518;&#29983;&#25104;&#30456;&#24212;&#30340;&#39034;&#24207;&#35266;&#23519;&#26679;&#26412;&#65292;&#30456;&#36739;&#20110;&#26368;&#20808;&#36827;&#30340;&#39034;&#24207;&#29983;&#25104;&#27169;&#22411;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.07077</link><description>&lt;p&gt;
&#28508;&#22312;&#21160;&#24577;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Latent Dynamical Implicit Diffusion Processes. (arXiv:2306.07077v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411; LDIDPs&#65292;&#21033;&#29992;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;&#20174;&#21160;&#24577;&#28508;&#22312;&#36807;&#31243;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#28982;&#21518;&#29983;&#25104;&#30456;&#24212;&#30340;&#39034;&#24207;&#35266;&#23519;&#26679;&#26412;&#65292;&#30456;&#36739;&#20110;&#26368;&#20808;&#36827;&#30340;&#39034;&#24207;&#29983;&#25104;&#27169;&#22411;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#21160;&#24577;&#27169;&#22411;&#24120;&#34987;&#29992;&#26469;&#23398;&#20064;&#20195;&#34920;&#19968;&#31995;&#21015;&#22122;&#22768;&#25968;&#25454;&#26679;&#26412;&#30340;&#28508;&#22312;&#21160;&#24577;&#36807;&#31243;&#30340;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#28508;&#22312;&#30340;&#21644;&#35266;&#27979;&#21160;&#24577;&#30340;&#22797;&#26434;&#24615;&#21644;&#21464;&#24322;&#24615;&#65292;&#20135;&#29983;&#20855;&#26377;&#39640;&#20445;&#30495;&#24230;&#30340;&#26679;&#26412;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26368;&#36817;&#65292;&#22312;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;DDPM&#21644;NCSN&#65289;&#26041;&#38754;&#21462;&#24471;&#30340;&#36827;&#23637;&#65292;&#23637;&#31034;&#20102;&#19968;&#20123;&#26377;&#21069;&#26223;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20174;&#20808;&#39564;&#20998;&#24067;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#24207;&#21015;&#26679;&#26412;&#65292;&#30456;&#36739;&#20110;&#20808;&#36827;&#30340;&#28508;&#22312;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#31070;&#32463;ODE&#12289;RNN&#21644;&#27491;&#21017;&#21270;&#27969;&#32593;&#32476;&#65289;&#12290;&#28982;&#32780;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;&#28508;&#22312;&#21160;&#24577;&#27169;&#22411;&#30340;&#24207;&#21015;&#25968;&#25454;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#21160;&#24577;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;&#65288;LDIDPs&#65289;&#30340;&#26032;&#22411;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;&#20174;&#21160;&#24577;&#28508;&#22312;&#36807;&#31243;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#28982;&#21518;&#29983;&#25104;&#30456;&#24212;&#30340;&#39034;&#24207;&#35266;&#23519;&#26679;&#26412;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#27169;&#25311;&#31070;&#32463;&#25968;&#25454;&#19978;&#27979;&#35797;&#20102;LDIDPs&#65292;&#24182;&#35777;&#26126;&#23427;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#39034;&#24207;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent dynamical models are commonly used to learn the distribution of a latent dynamical process that represents a sequence of noisy data samples. However, producing samples from such models with high fidelity is challenging due to the complexity and variability of latent and observation dynamics. Recent advances in diffusion-based generative models, such as DDPM and NCSN, have shown promising alternatives to state-of-the-art latent generative models, such as Neural ODEs, RNNs, and Normalizing flow networks, for generating high-quality sequential samples from a prior distribution. However, their application in modeling sequential data with latent dynamical models is yet to be explored. Here, we propose a novel latent variable model named latent dynamical implicit diffusion processes (LDIDPs), which utilizes implicit diffusion processes to sample from dynamical latent processes and generate sequential observation samples accordingly. We tested LDIDPs on synthetic and simulated neural d
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#969;-UCB&#30340;&#26032;&#19978;&#32622;&#20449;&#21306;&#38388;&#25277;&#26679;&#31574;&#30053;&#65292;&#20351;&#29992;&#19981;&#23545;&#31216;&#32622;&#20449;&#21306;&#38388;&#20197;&#26356;&#20934;&#30830;&#12289;&#26356;&#32039;&#23494;&#22320;&#20272;&#35745;&#22870;&#21169;&#25104;&#26412;&#27604;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#31574;&#30053;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2306.07071</link><description>&lt;p&gt;
&#20855;&#26377;&#19981;&#23545;&#31216;&#32622;&#20449;&#21306;&#38388;&#30340;&#26377;&#38480;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals. (arXiv:2306.07071v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07071
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#969;-UCB&#30340;&#26032;&#19978;&#32622;&#20449;&#21306;&#38388;&#25277;&#26679;&#31574;&#30053;&#65292;&#20351;&#29992;&#19981;&#23545;&#31216;&#32622;&#20449;&#21306;&#38388;&#20197;&#26356;&#20934;&#30830;&#12289;&#26356;&#32039;&#23494;&#22320;&#20272;&#35745;&#22870;&#21169;&#25104;&#26412;&#27604;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#31574;&#30053;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#65288;MAB&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#29609;&#23478;&#36873;&#25321;&#20855;&#26377;&#26410;&#30693;&#26399;&#26395;&#22870;&#21169;&#21644;&#25104;&#26412;&#30340;K&#20010;&#33218;&#12290;&#30446;&#26631;&#26159;&#22312;&#39044;&#31639;&#32422;&#26463;&#19979;&#26368;&#22823;&#21270;&#24635;&#22870;&#21169;&#12290;&#22240;&#27492;&#65292;&#29609;&#23478;&#35797;&#22270;&#23613;&#21487;&#33021;&#32463;&#24120;&#22320;&#36873;&#25321;&#20855;&#26377;&#26368;&#39640;&#22870;&#21169;&#25104;&#26412;&#27604;&#30340;&#33218;&#12290;&#24403;&#21069;&#38024;&#23545;&#27492;&#38382;&#39064;&#30340;&#26368;&#20808;&#36827;&#31574;&#30053;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20104;&#20197;&#35828;&#26126;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#32622;&#20449;&#21306;&#38388;&#65288;UCB&#65289;&#25277;&#26679;&#31574;&#30053;&#65292;&#31216;&#20026;&#969;-UCB&#65292;&#24182;&#20351;&#29992;&#19981;&#23545;&#31216;&#32622;&#20449;&#21306;&#38388;&#12290;&#36825;&#20123;&#21306;&#38388;&#23610;&#24230;&#38543;&#30528;&#26679;&#26412;&#22343;&#20540;&#21644;&#38543;&#26426;&#21464;&#37327;&#36793;&#30028;&#20043;&#38388;&#30340;&#36317;&#31163;&#32780;&#21464;&#21270;&#65292;&#30456;&#23545;&#20110;&#25105;&#20204;&#30340;&#31454;&#20105;&#23545;&#25163;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#12289;&#26356;&#32039;&#23494;&#22320;&#20272;&#35745;&#22870;&#21169;&#25104;&#26412;&#27604;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#23545;&#25968;&#21518;&#24724;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#29615;&#22659;&#20013;&#22987;&#32456;&#20248;&#20110;&#29616;&#26377;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the stochastic Budgeted Multi-Armed Bandit (MAB) problem, where a player chooses from $K$ arms with unknown expected rewards and costs. The goal is to maximize the total reward under a budget constraint. A player thus seeks to choose the arm with the highest reward-cost ratio as often as possible. Current state-of-the-art policies for this problem have several issues, which we illustrate. To overcome them, we propose a new upper confidence bound (UCB) sampling policy, $\omega$-UCB, that uses asymmetric confidence intervals. These intervals scale with the distance between the sample mean and the bounds of a random variable, yielding a more accurate and tight estimation of the reward-cost ratio compared to our competitors. We show that our approach has logarithmic regret and consistently outperforms existing policies in synthetic and real settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20915;&#31574;&#26641;&#20316;&#20026;&#25968;&#25454;&#35266;&#23519;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#26368;&#20248;&#39044;&#27979;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#27169;&#22411;&#35299;&#20915;&#20102;&#27714;&#35299;&#20998;&#21106;&#36724;&#32452;&#21512;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.07060</link><description>&lt;p&gt;
&#22522;&#20110;&#20915;&#31574;&#26641;&#20316;&#20026;&#25968;&#25454;&#35266;&#23519;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#26368;&#20248;&#39044;&#27979;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction Algorithms Achieving Bayesian Decision Theoretical Optimality Based on Decision Trees as Data Observation Processes. (arXiv:2306.07060v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20915;&#31574;&#26641;&#20316;&#20026;&#25968;&#25454;&#35266;&#23519;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#26368;&#20248;&#39044;&#27979;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#27169;&#22411;&#35299;&#20915;&#20102;&#27714;&#35299;&#20998;&#21106;&#36724;&#32452;&#21512;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20915;&#31574;&#26641;&#39046;&#22495;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#30740;&#31350;&#38590;&#20197;&#30830;&#20445;&#39044;&#27979;&#26032;&#25968;&#25454;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#24182;&#19988;&#23481;&#26131;&#20986;&#29616;&#36807;&#25311;&#21512;&#65292;&#22240;&#20026;&#20915;&#31574;&#26641;&#36890;&#24120;&#20165;&#29992;&#20110;&#34920;&#31034;&#35201;&#20174;&#32473;&#23450;&#25968;&#25454;&#26500;&#24314;&#30340;&#39044;&#27979;&#21151;&#33021;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#21253;&#25324;&#26412;&#25991;&#22312;&#20869;&#30340;&#20854;&#20182;&#19968;&#20123;&#30740;&#31350;&#20351;&#29992;&#26641;&#26469;&#34920;&#31034;&#32473;&#23450;&#25968;&#25454;&#32972;&#21518;&#30340;&#38543;&#26426;&#25968;&#25454;&#35266;&#23519;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#20182;&#20204;&#26681;&#25454;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#20551;&#35774;&#26641;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#24471;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#32479;&#35745;&#26368;&#20248;&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#25269;&#24481;&#36807;&#25311;&#21512;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#20173;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#65292;&#22240;&#20026;&#35745;&#31639;&#36825;&#31181;&#36125;&#21494;&#26031;&#26368;&#20248;&#39044;&#27979;&#38656;&#35201;&#23545;&#29305;&#24449;&#31354;&#38388;&#30340;&#25152;&#26377;&#21010;&#20998;&#27169;&#24335;&#65288;&#30001;&#26641;&#21644;&#19968;&#20123;&#21442;&#25968;&#34920;&#31034;&#65289;&#36827;&#34892;&#24635;&#21644;&#65292;&#36825;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#29305;&#21035;&#26159;&#65292;&#36824;&#23384;&#22312;&#19968;&#31181;&#30456;&#23545;&#20110;&#20998;&#21106;&#36724;&#30340;&#32452;&#21512;&#36827;&#34892;&#27714;&#21644;&#30340;&#38382;&#39064;&#65292;&#21363;&#23558;&#29305;&#24449;&#20998;&#37197;&#32473;&#26641;&#30340;&#20869;&#37096;&#33410;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#38142;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#22522;&#20110;&#29305;&#24449;&#31354;&#38388;&#30340;&#26641;&#24418;&#20998;&#21106;&#27169;&#24335;&#25512;&#23548;&#20986;&#35745;&#31639;&#36125;&#21494;&#26031;&#26368;&#20248;&#39044;&#27979;&#30340;&#36882;&#24402;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the field of decision trees, most previous studies have difficulty ensuring the statistical optimality of a prediction of new data and suffer from overfitting because trees are usually used only to represent prediction functions to be constructed from given data. In contrast, some studies, including this paper, used the trees to represent stochastic data observation processes behind given data. Moreover, they derived the statistically optimal prediction, which is robust against overfitting, based on the Bayesian decision theory by assuming a prior distribution for the trees. However, these studies still have a problem in computing this Bayes optimal prediction because it involves an infeasible summation for all division patterns of a feature space, which is represented by the trees and some parameters. In particular, an open problem is a summation with respect to combinations of division axes, i.e., the assignment of features to inner nodes of the tree. We solve this by a Markov cha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#20248;&#21270;&#26694;&#26550;&#65292;&#20351;&#29992;&#20004;&#31181;&#22522;&#20110;&#32463;&#39564;&#20998;&#24067;&#30340;&#20272;&#35745;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#21508;&#31181;&#39118;&#38505;&#24230;&#37327;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2306.07059</link><description>&lt;p&gt;
&#39118;&#38505;&#24230;&#37327;&#30340;&#32622;&#20449;&#21306;&#38388;&#20248;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Distribution Optimization Framework for Confidence Bounds of Risk Measures. (arXiv:2306.07059v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#20248;&#21270;&#26694;&#26550;&#65292;&#20351;&#29992;&#20004;&#31181;&#22522;&#20110;&#32463;&#39564;&#20998;&#24067;&#30340;&#20272;&#35745;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#21508;&#31181;&#39118;&#38505;&#24230;&#37327;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#20248;&#21270;&#26694;&#26550;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#21508;&#31181;&#39118;&#38505;&#24230;&#37327;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#27969;&#34892;&#30340;&#39118;&#38505;&#24230;&#37327;&#65292;&#20363;&#22914;&#29109;&#39118;&#38505;&#24230;&#37327;&#12289;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;&#65288;CVaR&#65289;&#12289;&#20809;&#35889;&#39118;&#38505;&#24230;&#37327;&#12289;&#22833;&#30495;&#39118;&#38505;&#24230;&#37327;&#12289;&#31561;&#20215;&#30830;&#23450;&#24615;&#21644;&#20998;&#20301;&#25968;&#26399;&#26395;&#25928;&#29992;&#65292;&#36825;&#20123;&#39118;&#38505;&#24230;&#37327;&#22312;&#39118;&#38505;&#25935;&#24863;&#20915;&#31574;&#26041;&#38754;&#30340;&#25991;&#29486;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30830;&#35748;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#22522;&#20110;&#32463;&#39564;&#20998;&#24067;&#30340;&#38598;&#20013;&#30028;&#38480;&#30340;&#20272;&#35745;&#26041;&#26696;&#65292;&#20855;&#20307;&#20351;&#29992;Wasserstein&#36317;&#31163;&#25110;&#26368;&#39640;&#36317;&#31163;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#20174;&#32463;&#39564;&#39118;&#38505;&#24230;&#37327;&#20013;&#28155;&#21152;&#25110;&#20943;&#21435;&#32622;&#20449;&#21322;&#24452;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#26696;&#35780;&#20272;&#22522;&#20110;&#36317;&#31163;&#30340;&#32463;&#39564;&#20998;&#24067;&#30340;&#29305;&#23450;&#36716;&#25442;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#32622;&#20449;&#21306;&#38388;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#22987;&#32456;&#20135;&#29983;&#26356;&#32039;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a distribution optimization framework that significantly improves confidence bounds for various risk measures compared to previous methods. Our framework encompasses popular risk measures such as the entropic risk measure, conditional value at risk (CVaR), spectral risk measure, distortion risk measure, equivalent certainty, and rank-dependent expected utility, which are well established in risk-sensitive decision-making literature. To achieve this, we introduce two estimation schemes based on concentration bounds derived from the empirical distribution, specifically using either the Wasserstein distance or the supremum distance. Unlike traditional approaches that add or subtract a confidence radius from the empirical risk measures, our proposed schemes evaluate a specific transformation of the empirical distribution based on the distance. Consequently, our confidence bounds consistently yield tighter results compared to previous methods. We further verify the efficacy of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.07056</link><description>&lt;p&gt;
&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#29992;&#20110;&#31163;&#32676;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Kernel Random Projection Depth for Outlier Detection. (arXiv:2306.07056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#65288;RPD&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26694;&#26550;&#20013;&#65292;RPD&#22312;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#35745;&#31639;&#12290;&#20511;&#21161;&#20869;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#25105;&#20204;&#26399;&#26395;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#19978;&#36848;&#22810;&#31181;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;RPD&#65292;&#24182;&#21487;&#19982;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#29616;&#26377;&#30340;&#26816;&#27979;&#27169;&#22411;&#30456;&#23218;&#32654;&#65292;&#20851;&#20110;&#25509;&#25910;&#25805;&#20316;&#29305;&#24449;&#26354;&#32447;&#65288;ROC&#65289;&#19979;&#30340;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27169;&#22411;&#39537;&#21160;&#30340;&#21452;&#37325;&#31639;&#27861;OptAug-CMDP&#65292;&#29992;&#20110;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#65292;&#35299;&#20915;&#20102;&#21407;&#20808;&#31639;&#27861;&#20013;&#23433;&#20840;&#24615;&#38382;&#39064;&#30340;&#32570;&#38519;&#65292;&#35777;&#26126;&#20102;&#20854;&#36951;&#25022;&#20540;&#20248;&#31168;&#12290;</title><link>http://arxiv.org/abs/2306.07001</link><description>&lt;p&gt;
&#22522;&#20110;Lagrangian&#26041;&#27861;&#30340;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#26080;&#38656;&#21462;&#28040;&#24809;&#32602;&#30340;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Cancellation-Free Regret Bounds for Lagrangian Approaches in Constrained Markov Decision Processes. (arXiv:2306.07001v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27169;&#22411;&#39537;&#21160;&#30340;&#21452;&#37325;&#31639;&#27861;OptAug-CMDP&#65292;&#29992;&#20110;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#65292;&#35299;&#20915;&#20102;&#21407;&#20808;&#31639;&#27861;&#20013;&#23433;&#20840;&#24615;&#38382;&#39064;&#30340;&#32570;&#38519;&#65292;&#35777;&#26126;&#20102;&#20854;&#36951;&#25022;&#20540;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#26159;&#24314;&#27169;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#24120;&#35265;&#26041;&#27861;&#65292;&#20854;&#20013;&#23433;&#20840;&#30446;&#26631;&#30001;&#32422;&#26463;&#20989;&#25968;&#24314;&#27169;&#12290;&#22522;&#20110;Lagrangian&#30340;&#21452;&#37325;&#25110;&#21407;&#22987;&#21452;&#37325;&#31639;&#27861;&#20026;CMDPs&#20013;&#30340;&#23398;&#20064;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#24403;&#21069;&#24050;&#30693;&#30340;&#26377;&#38480;&#26102;&#38388;&#27573;&#36951;&#25022;&#30028;&#38480;&#20801;&#35768;&#8220;&#21462;&#28040;&#38169;&#35823;&#8221;&#65292;&#36825;&#24847;&#21619;&#30528;&#21487;&#20197;&#36890;&#36807;&#21478;&#19968;&#31181;&#22330;&#26223;&#20013;&#30340;&#20005;&#26684;&#32422;&#26463;&#28385;&#36275;&#26469;&#34917;&#20607;&#19968;&#20010;&#22330;&#26223;&#20013;&#30340;&#32422;&#26463;&#36829;&#35268;&#34892;&#20026;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27169;&#22411;&#39537;&#21160;&#30340;&#21452;&#37325;&#31639;&#27861;OptAug-CMDP&#65292;&#35813;&#31639;&#27861;&#21463;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#21551;&#21457;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#22320;&#25191;&#34892;&#26469;&#24357;&#34917;&#36825;&#31181;&#32570;&#38519;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;$K$&#20010;&#25506;&#32034;CMDP&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;$\tilde{O}(\sqrt{K})$&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#30446;&#26631;&#21644;&#32422;&#26463;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constrained Markov Decision Processes (CMDPs) are one of the common ways to model safe reinforcement learning problems, where the safety objectives are modeled by constraint functions. Lagrangian-based dual or primal-dual algorithms provide efficient methods for learning in CMDPs. For these algorithms, the currently known regret bounds in the finite-horizon setting allow for a \textit{cancellation of errors}; that is, one can compensate for a constraint violation in one episode with a strict constraint satisfaction in another episode. However, in practical applications, we do not consider such a behavior safe.  In this paper, we overcome this weakness by proposing a novel model-based dual algorithm \textsc{OptAug-CMDP} for tabular finite-horizon CMDPs. Our algorithm is motivated by the augmented Lagrangian method and can be performed efficiently. We show that during $K$ episodes of exploring the CMDP, our algorithm obtains a regret of $\tilde{O}(\sqrt{K})$ for both the objective and th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#20174;&#23567;&#22411;&#23616;&#37096;&#36741;&#21161;&#32593;&#32476;&#21453;&#39304;&#20013;&#33719;&#24471;&#30340;&#26799;&#24230;&#20559;&#21521;&#26356;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#65292;&#25552;&#39640;&#20102;&#21069;&#21521;&#26799;&#24230;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.06968</link><description>&lt;p&gt;
&#21069;&#21521;&#26799;&#24230;&#31639;&#27861;&#26159;&#21542;&#33021;&#22815;&#21462;&#20195;&#21453;&#21521;&#20256;&#25773;&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Forward Gradient Match Backpropagation?. (arXiv:2306.06968v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#20174;&#23567;&#22411;&#23616;&#37096;&#36741;&#21161;&#32593;&#32476;&#21453;&#39304;&#20013;&#33719;&#24471;&#30340;&#26799;&#24230;&#20559;&#21521;&#26356;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#65292;&#25552;&#39640;&#20102;&#21069;&#21521;&#26799;&#24230;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#21069;&#21521;&#26799;&#24230;&#31639;&#27861;&#8212;&#8212;&#21033;&#29992;&#27491;&#21521;&#24494;&#20998;&#27169;&#24335;&#20013;&#30340;&#26041;&#21521;&#23548;&#25968;&#30340;&#24819;&#27861;&#8212;&#8212;&#24050;&#34987;&#35777;&#26126;&#21487;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#36890;&#24120;&#19982;&#21453;&#21521;&#20256;&#25773;&#26799;&#24230;&#35745;&#31639;&#30456;&#20851;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#38145;&#23450;&#21644;&#35760;&#24518;&#35201;&#27714;&#12290;&#20195;&#20215;&#26159;&#38656;&#35201;&#29468;&#27979;&#27493;&#39588;&#26041;&#21521;&#65292;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#24456;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#22312;&#26356;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#19978;&#24378;&#28872;&#20559;&#21521;&#25105;&#20204;&#30340;&#26799;&#24230;&#29468;&#27979;&#26041;&#21521;&#65292;&#20363;&#22914;&#26469;&#33258;&#23567;&#22411;&#23616;&#37096;&#36741;&#21161;&#32593;&#32476;&#30340;&#21453;&#39304;&#12290;&#38024;&#23545;&#26631;&#20934;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#20005;&#26684;&#30340;&#30740;&#31350;&#65292;&#31995;&#32479;&#22320;&#28085;&#30422;&#20102;&#21508;&#31181;&#26799;&#24230;&#30446;&#26631;&#21644;&#26799;&#24230;&#29468;&#27979;&#30340;&#32452;&#21512;&#65292;&#21253;&#25324;&#20197;&#21069;&#22312;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20351;&#29992;&#20174;&#26412;&#22320;&#25439;&#22833;&#33719;&#24471;&#30340;&#26799;&#24230;&#20316;&#20026;&#20505;&#36873;&#26041;&#21521;&#65292;&#27604;&#22312;&#21069;&#21521;&#26799;&#24230;&#31639;&#27861;&#20013;&#20351;&#29992;&#38543;&#26426;&#22122;&#22768;&#65292;&#20855;&#26377;&#26126;&#26174;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forward Gradients - the idea of using directional derivatives in forward differentiation mode - have recently been shown to be utilizable for neural network training while avoiding problems generally associated with backpropagation gradient computation, such as locking and memorization requirements. The cost is the requirement to guess the step direction, which is hard in high dimensions. While current solutions rely on weighted averages over isotropic guess vector distributions, we propose to strongly bias our gradient guesses in directions that are much more promising, such as feedback obtained from small, local auxiliary networks. For a standard computer vision neural network, we conduct a rigorous study systematically covering a variety of combinations of gradient targets and gradient guesses, including those previously presented in the literature. We find that using gradients obtained from a local loss as a candidate direction drastically improves on random noise in Forward Gradie
&lt;/p&gt;</description></item><item><title>&#19968;&#31181;&#39640;&#25928;&#12289;&#20934;&#30830;&#12289;&#36866;&#29992;&#20110;&#24658;&#26143;&#27169;&#22411;&#22823;&#27668;&#30340;&#25554;&#20540;&#26041;&#27861;&#65292;&#37319;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#19968;&#32500;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#25216;&#26415;&#65292;&#33021;&#22815;&#25552;&#21462;&#38750;&#32447;&#24615;&#20851;&#31995;&#20174;&#32780;&#23454;&#29616;&#26356;&#21152;&#31934;&#32454;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2306.06938</link><description>&lt;p&gt;
&#29992;&#19968;&#32500;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#29305;&#24449;&#25552;&#21462;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#24658;&#26143;&#22823;&#27668;&#39640;&#31934;&#24230;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
High-precision interpolation of stellar atmospheres with a deep neural network using a 1D convolutional auto encoder for feature extraction. (arXiv:2306.06938v1 [astro-ph.IM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06938
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#39640;&#25928;&#12289;&#20934;&#30830;&#12289;&#36866;&#29992;&#20110;&#24658;&#26143;&#27169;&#22411;&#22823;&#27668;&#30340;&#25554;&#20540;&#26041;&#27861;&#65292;&#37319;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#19968;&#32500;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#25216;&#26415;&#65292;&#33021;&#22815;&#25552;&#21462;&#38750;&#32447;&#24615;&#20851;&#31995;&#20174;&#32780;&#23454;&#29616;&#26356;&#21152;&#31934;&#32454;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#24658;&#26143;&#22823;&#27668;&#27169;&#22411;&#32593;&#26684;&#30340;&#24191;&#27867;&#21487;&#29992;&#24615;&#65292;&#38656;&#35201;&#37319;&#29992;&#36229;&#36234;&#31616;&#21333;&#32447;&#24615;&#25554;&#20540;&#24182;&#25429;&#25417;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#30340;&#20934;&#30830;&#25216;&#26415;&#65292;&#20197;&#36890;&#36807;&#31934;&#30830;&#25216;&#26415;&#24674;&#22797;&#20013;&#38388;&#22823;&#27668;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24314;&#31435;&#19968;&#31181;&#21487;&#38752;&#12289;&#31934;&#30830;&#12289;&#36731;&#37327;&#32423;&#19988;&#24555;&#36895;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24674;&#22797;&#24658;&#26143;&#27169;&#22411;&#22823;&#27668;&#65292;&#20063;&#23601;&#26159;&#36136;&#37327;&#26609;&#12289;&#28201;&#24230;&#12289;&#27668;&#20307;&#21387;&#21147;&#21644;&#30005;&#23376;&#23494;&#24230;&#30340;&#20998;&#23618;&#65292;&#32473;&#20986;&#23450;&#20041;&#22823;&#27668;&#29305;&#23450;&#21442;&#25968;&#30340;&#20219;&#20309;&#32452;&#21512;&#65306;&#37329;&#23646;&#20016;&#24230;&#12289;&#26377;&#25928;&#28201;&#24230;&#21644;&#34920;&#38754;&#37325;&#21147;&#65292;&#20197;&#21450;&#20854;&#20182;&#20851;&#38190;&#21270;&#23398;&#20803;&#32032;&#30340;&#20016;&#24230;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#23436;&#20840;&#36830;&#25509;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#31070;&#32463;&#32593;&#32476;&#20351;&#29992;&#19968;&#32500;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#20174;ATLAS9&#21644;MARCS&#27169;&#22411;&#22823;&#27668;&#20013;&#25552;&#21462;&#38750;&#32447;&#24615;&#20851;&#31995;&#12290;&#36825;&#31181;&#31216;&#20026;iNNterpol&#30340;&#26032;&#26041;&#27861;&#26377;&#25928;&#32771;&#34385;&#20102;&#25968;&#25454;&#20851;&#31995;&#20013;&#30340;&#38750;&#32447;&#24615;&#24615;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given the widespread availability of grids of models for stellar atmospheres, it is necessary to recover intermediate atmospheric models by means of accurate techniques that go beyond simple linear interpolation and capture the intricacies of the data. Our goal is to establish a reliable, precise, lightweight, and fast method for recovering stellar model atmospheres, that is to say the stratification of mass column, temperature, gas pressure, and electronic density with optical depth given any combination of the defining atmospheric specific parameters: metallicity, effective temperature, and surface gravity, as well as the abundances of other key chemical elements. We employed a fully connected deep neural network which in turn uses a 1D convolutional auto-encoder to extract the nonlinearities of a grid using the ATLAS9 and MARCS model atmospheres. This new method we call iNNterpol effectively takes into account the nonlinearities in the relationships of the data as opposed to traditi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MPPN&#30340;&#26032;&#22411;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#65292;&#20854;&#36890;&#36807;&#26500;&#24314;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#22810;&#20998;&#36776;&#29575;&#35821;&#20041;&#21333;&#20803;&#21644;&#37319;&#29992;&#22810;&#21608;&#26399;&#27169;&#24335;&#25366;&#25496;&#26469;&#25429;&#33719;&#20851;&#38190;&#27169;&#24335;&#65292;&#28982;&#21518;&#20351;&#29992;&#36890;&#36947;&#33258;&#36866;&#24212;&#27169;&#22359;&#20197;&#32771;&#34385;&#22810;&#21464;&#37327;&#23545;&#19981;&#21516;&#27169;&#24335;&#30340;&#24863;&#30693;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2306.06895</link><description>&lt;p&gt;
MPPN: &#22810;&#20998;&#36776;&#29575;&#21608;&#26399;&#27169;&#24335;&#32593;&#32476;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time Series Forecasting. (arXiv:2306.06895v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06895
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MPPN&#30340;&#26032;&#22411;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#65292;&#20854;&#36890;&#36807;&#26500;&#24314;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#22810;&#20998;&#36776;&#29575;&#35821;&#20041;&#21333;&#20803;&#21644;&#37319;&#29992;&#22810;&#21608;&#26399;&#27169;&#24335;&#25366;&#25496;&#26469;&#25429;&#33719;&#20851;&#38190;&#27169;&#24335;&#65292;&#28982;&#21518;&#20351;&#29992;&#36890;&#36947;&#33258;&#36866;&#24212;&#27169;&#22359;&#20197;&#32771;&#34385;&#22810;&#21464;&#37327;&#23545;&#19981;&#21516;&#27169;&#24335;&#30340;&#24863;&#30693;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22312;&#21508;&#31181;&#29616;&#23454;&#22330;&#26223;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#26368;&#36817;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20542;&#21521;&#20110;&#36890;&#36807;&#20998;&#35299;&#25110;&#37319;&#26679;&#26041;&#27861;&#25429;&#33719;&#26102;&#38388;&#24207;&#21015;&#30340;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#25552;&#21462;&#20986;&#30340;&#27169;&#24335;&#21487;&#33021;&#21253;&#21547;&#38590;&#20197;&#39044;&#27979;&#30340;&#22122;&#22768;&#65292;&#24182;&#19988;&#32570;&#20047;&#33391;&#22909;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#27492;&#22806;&#65292;&#22810;&#21464;&#37327;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#36890;&#24120;&#24573;&#30053;&#27599;&#20010;&#21464;&#37327;&#30340;&#20010;&#20307;&#29305;&#24449;&#65292;&#21487;&#33021;&#20250;&#24433;&#21709;&#39044;&#27979;&#31934;&#24230;&#12290;&#20026;&#20102;&#25429;&#25417;&#26102;&#24207;&#30340;&#20869;&#22312;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; Multi-resolution Periodic Pattern Network&#65288;MPPN&#65289;&#30340;&#26032;&#22411;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#26550;&#26500;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#25105;&#20204;&#39318;&#20808;&#26500;&#24314;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#22810;&#20998;&#36776;&#29575;&#35821;&#20041;&#21333;&#20803;&#65292;&#24182;&#37319;&#29992;&#22810;&#21608;&#26399;&#27169;&#24335;&#25366;&#25496;&#26469;&#25429;&#33719;&#26102;&#38388;&#24207;&#21015;&#30340;&#20851;&#38190;&#27169;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36947;&#33258;&#36866;&#24212;&#27169;&#22359;&#65292;&#20197;&#25429;&#25417;&#22810;&#21464;&#37327;&#23545;&#19981;&#21516;&#27169;&#24335;&#30340;&#24863;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;
Long-term time series forecasting plays an important role in various real-world scenarios. Recent deep learning methods for long-term series forecasting tend to capture the intricate patterns of time series by decomposition-based or sampling-based methods. However, most of the extracted patterns may include unpredictable noise and lack good interpretability. Moreover, the multivariate series forecasting methods usually ignore the individual characteristics of each variate, which may affecting the prediction accuracy. To capture the intrinsic patterns of time series, we propose a novel deep learning network architecture, named Multi-resolution Periodic Pattern Network (MPPN), for long-term series forecasting. We first construct context-aware multi-resolution semantic units of time series and employ multi-periodic pattern mining to capture the key patterns of time series. Then, we propose a channel adaptive module to capture the perceptions of multivariate towards different patterns. In 
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#24182;&#19988;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#32473;&#20986;&#20272;&#35745;&#26631;&#31614;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#12290;&#24182;&#19988;&#65292;&#21333;&#27493;&#35889;&#31639;&#27861;&#21487;&#20197;&#22312;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#30340;&#26631;&#31614;&#12290;</title><link>http://arxiv.org/abs/2306.06845</link><description>&lt;p&gt;
&#23545;&#31216;&#20108;&#20803;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#19982;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Strong consistency and optimality of spectral clustering in symmetric binary non-uniform Hypergraph Stochastic Block Model. (arXiv:2306.06845v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06845
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#24182;&#19988;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#32473;&#20986;&#20272;&#35745;&#26631;&#31614;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#12290;&#24182;&#19988;&#65292;&#21333;&#27493;&#35889;&#31639;&#27861;&#21487;&#20197;&#22312;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#30340;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32771;&#34385;&#20102;&#22312;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#65292;&#20004;&#20010;&#31561;&#22823;&#23567;&#30340;&#31038;&#21306;&#65288;n/2&#65289;&#20013;&#30340;&#38543;&#26426;&#36229;&#22270;&#19978;&#30340;&#26080;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#36793;&#21482;&#20381;&#36182;&#20110;&#20854;&#39030;&#28857;&#30340;&#26631;&#31614;&#65292;&#36793;&#20197;&#19968;&#23450;&#27010;&#29575;&#29420;&#31435;&#20986;&#29616;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#24314;&#31435;&#20102;&#24378;&#19968;&#33268;&#24615;&#30340;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#65292;&#20219;&#20309;&#31639;&#27861;&#37117;&#26377;&#24456;&#39640;&#27010;&#29575;&#20250;&#35823;&#20998;&#31867;&#33267;&#23569;&#20004;&#20010;&#39030;&#28857;&#65292;&#32780;&#29305;&#24449;&#21521;&#37327;&#20272;&#35745;&#37327;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#20026;$n$&#30340;&#38408;&#20540;&#30340;&#36127;&#25351;&#25968;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#24403;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#65292;&#23613;&#31649;&#24352;&#37327;&#25910;&#32553;&#24341;&#36215;&#20102;&#20449;&#24687;&#25439;&#22833;&#65292;&#20294;&#21333;&#27493;&#35889;&#31639;&#27861;&#20165;&#22312;&#32473;&#23450;&#25910;&#32553;&#30340;&#37051;&#25509;&#30697;&#38453;&#26102;&#65292;&#21363;&#20351;SDP&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22833;&#36133;&#65292;&#20063;&#21487;&#20197;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#20998;&#37197;&#26631;&#31614;&#12290;&#27492;&#22806;&#65292;&#24378;&#19968;&#33268;&#24615;&#21487;&#20197;&#36890;&#36807;&#23545;&#25152;&#26377;&#27425;&#20248;&#32858;&#21512;&#20449;&#24687;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the unsupervised classification problem in random hypergraphs under the non-uniform \emph{Hypergraph Stochastic Block Model} (HSBM) with two equal-sized communities ($n/2$), where each edge appears independently with some probability depending only on the labels of its vertices. In this paper, an \emph{information-theoretical} threshold for strong consistency is established. Below the threshold, every algorithm would misclassify at least two vertices with high probability, and the expected \emph{mismatch ratio} of the eigenvector estimator is upper bounded by $n$ to the power of minus the threshold. On the other hand, when above the threshold, despite the information loss induced by tensor contraction, one-stage spectral algorithms assign every vertex correctly with high probability when only given the contracted adjacency matrix, even if \emph{semidefinite programming} (SDP) fails in some scenarios. Moreover, strong consistency is achievable by aggregating information from al
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24120;&#35265;&#30340;&#25968;&#25454;&#20559;&#24046;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#22312;&#26080;&#38656;&#20107;&#20808;&#30693;&#36947;&#30495;&#23454;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#25216;&#26415;&#21521;BO&#36807;&#31243;&#20013;&#28155;&#21152;&#38543;&#26426;&#25968;&#25454;&#28857;&#65292;&#37319;&#29992;&#26032;&#30340;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#36229;&#21442;&#25968;&#20272;&#35745;&#65292;&#20197;&#36798;&#21040;&#27425;&#32447;&#24615;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.06844</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#20559;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#20272;&#35745;&#30340;&#21487;&#35777;&#26126;&#39640;&#25928;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient Bayesian Optimization with Unbiased Gaussian Process Hyperparameter Estimation. (arXiv:2306.06844v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06844
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24120;&#35265;&#30340;&#25968;&#25454;&#20559;&#24046;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#22312;&#26080;&#38656;&#20107;&#20808;&#30693;&#36947;&#30495;&#23454;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#25216;&#26415;&#21521;BO&#36807;&#31243;&#20013;&#28155;&#21152;&#38543;&#26426;&#25968;&#25454;&#28857;&#65292;&#37319;&#29992;&#26032;&#30340;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#36229;&#21442;&#25968;&#20272;&#35745;&#65292;&#20197;&#36798;&#21040;&#27425;&#32447;&#24615;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#26377;&#25928;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#30340;&#23454;&#38469;&#24615;&#33021;&#21644;&#29702;&#35770;&#20445;&#35777;&#65292;&#21462;&#20915;&#20110;&#27491;&#30830;&#20272;&#35745;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#20540;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#30001;&#20110;&#24120;&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25968;&#25454;&#37319;&#26679;&#31574;&#30053;&#21487;&#33021;&#20250;&#24341;&#36215;&#25968;&#25454;&#20559;&#24046;&#65292;&#20174;&#32780;&#23548;&#33268;&#36229;&#21442;&#25968;&#20272;&#35745;&#38169;&#35823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#20107;&#20808;&#19981;&#30693;&#36947;&#30495;&#23454;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#24182;&#38656;&#35201;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#36827;&#34892;&#20272;&#35745;&#26102;&#65292;&#35813;&#26041;&#27861;&#20063;&#33021;&#22815;&#27425;&#32447;&#24615;&#25910;&#25947;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#25216;&#26415;(EXP3)&#21521;BO&#36807;&#31243;&#20013;&#28155;&#21152;&#38543;&#26426;&#25968;&#25454;&#28857;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#20272;&#35745;&#36807;&#31243;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process (GP) based Bayesian optimization (BO) is a powerful method for optimizing black-box functions efficiently. The practical performance and theoretical guarantees associated with this approach depend on having the correct GP hyperparameter values, which are usually unknown in advance and need to be estimated from the observed data. However, in practice, these estimations could be incorrect due to biased data sampling strategies commonly used in BO. This can lead to degraded performance and break the sub-linear global convergence guarantee of BO. To address this issue, we propose a new BO method that can sub-linearly converge to the global optimum of the objective function even when the true GP hyperparameters are unknown in advance and need to be estimated from the observed data. Our method uses a multi-armed bandit technique (EXP3) to add random data points to the BO process, and employs a novel training loss function for the GP hyperparameter estimation process that ens
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24403;&#22870;&#21169;&#21576;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#23454;&#20363;&#30456;&#20851;&#31639;&#27861;&#65292;&#24182;&#24471;&#21040;&#20102;&#26497;&#23567;&#26368;&#22823;&#21270;&#30340;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.06836</link><description>&lt;p&gt;
&#29992;&#20989;&#25968;&#36924;&#36817;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#37325;&#23614;&#22870;&#21169;&#38382;&#39064;&#30340;&#26497;&#23567;&#26368;&#22823;&#21270;&#31639;&#27861;&#21644;&#23454;&#20363;&#30456;&#20851;&#36951;&#25022;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds. (arXiv:2306.06836v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24403;&#22870;&#21169;&#21576;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#23454;&#20363;&#30456;&#20851;&#31639;&#27861;&#65292;&#24182;&#24471;&#21040;&#20102;&#26497;&#23567;&#26368;&#22823;&#21270;&#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26377;&#35768;&#22810;&#24037;&#20316;&#37117;&#19987;&#27880;&#20110;&#20026;&#26377;&#30028;&#22870;&#21169;&#30340;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#26377;&#25928;&#31639;&#27861;&#65292;&#20294;&#24403;&#22870;&#21169;&#21576;&#29616;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#8212;&#8212;&#21363;&#23384;&#22312;&#26576;&#20010; $\epsilon\in(0,1]$ &#20351;&#24471;&#20165;&#26377;&#26377;&#38480;&#30340;$(1+\epsilon)$-&#38454;&#30697;&#8212;&#8212;&#26159;&#21542;&#23384;&#22312;&#23545;&#22823;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#36827;&#34892;&#37319;&#26679;&#25110;&#26102;&#25928;&#24615;&#31639;&#27861;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340; RL &#20013;&#30340;&#36825;&#31181;&#22870;&#21169;&#26426;&#21046;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;&#37325;&#23614;&#32447;&#24615;&#36172;&#33218;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#8212;&#8212;\textsc{Heavy-OFUL}&#65292;&#20854;&#23454;&#29616;&#20102;&#19968;&#31181;&#23454;&#20363;&#30456;&#20851;&#30340; $T$-round &#36951;&#25022;&#24230;&#37327;&#65292;&#20026; $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$&#65292;&#36825;&#26159;&#36825;&#31181;&#31867;&#22411;&#30340;\emph{&#31532;&#19968;&#31687;}&#25991;&#31456;&#12290;$\nu_t^{1+\epsilon}$&#26159;&#31532; $t$ &#36718;&#22870;&#21169;&#30340; $(1+\epsilon)$-&#38454;&#20013;&#24515;&#30697;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#22312;&#24212;&#29992;&#20110; st &#30340;&#26368;&#22351;&#24773;&#20917;&#26102;&#65292;&#19978;&#36848;&#30028;&#26159;&#26497;&#23567;&#20540;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \emph{heavy-tailed}, i.e., with only finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-round regret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the \emph{first} of this kind. Here, $d$ is the feature dimension, and $\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in st
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20026;&#32654;&#27954;&#22303;&#33879;&#35821;&#35328;&#21019;&#24314;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#38754;&#20020;&#30340;&#25361;&#25112;&#20197;&#21450;&#26368;&#26032;&#30340;&#36827;&#23637;&#21644;&#21457;&#29616;&#12290;&#32570;&#20047;&#24179;&#34892;&#21644;&#21333;&#35821;&#25968;&#25454;&#26159;&#20854;&#20013;&#30340;&#20027;&#35201;&#38590;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.06804</link><description>&lt;p&gt;
&#32654;&#27954;&#22303;&#33879;&#35821;&#35328;&#30340;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction. (arXiv:2306.06804v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06804
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20026;&#32654;&#27954;&#22303;&#33879;&#35821;&#35328;&#21019;&#24314;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#38754;&#20020;&#30340;&#25361;&#25112;&#20197;&#21450;&#26368;&#26032;&#30340;&#36827;&#23637;&#21644;&#21457;&#29616;&#12290;&#32570;&#20047;&#24179;&#34892;&#21644;&#21333;&#35821;&#25968;&#25454;&#26159;&#20854;&#20013;&#30340;&#20027;&#35201;&#38590;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#27169;&#22411;&#24050;&#32463;&#26174;&#33879;&#25552;&#39640;&#20102;&#39640;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#26426;&#22120;&#32763;&#35793;&#65288;MT&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20123;&#27169;&#22411;&#20381;&#36182;&#20110;&#22823;&#37327;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#20294;&#35768;&#22810;&#35821;&#35328;&#23545;&#32570;&#20047;&#36825;&#20123;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#19990;&#30028;&#19978;&#35821;&#35328;&#30340;&#37325;&#35201;&#37096;&#20998;&#32570;&#20047;&#36825;&#26679;&#30340;&#25968;&#25454;&#37327;&#65292;&#20854;&#20013;&#32654;&#27954;&#30340;&#22823;&#22810;&#25968;&#35821;&#35328;&#20063;&#26159;&#22914;&#27492;&#65292;&#20165;&#26377;&#19968;&#23450;&#37327;&#30340;&#24179;&#34892;&#21644;&#21333;&#35821;&#25968;&#25454;&#12290;&#26412;&#25991;&#21521;&#35835;&#32773;&#20171;&#32461;&#20102;&#20026;&#36825;&#20123;&#35821;&#35328;&#21019;&#24314;MT&#31995;&#32479;&#25152;&#28041;&#21450;&#30340;&#22522;&#26412;&#25361;&#25112;&#12289;&#27010;&#24565;&#21644;&#25216;&#26415;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#26368;&#36817;&#30340;&#36827;&#23637;&#21644;&#21457;&#29616;&#20197;&#21450;&#24320;&#25918;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#21457;&#29616;&#26159;NLP&#31038;&#21306;&#23545;&#36825;&#20123;&#35821;&#35328;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural models have drastically advanced state of the art for machine translation (MT) between high-resource languages. Traditionally, these models rely on large amounts of training data, but many language pairs lack these resources. However, an important part of the languages in the world do not have this amount of data. Most languages from the Americas are among them, having a limited amount of parallel and monolingual data, if any. Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#36827;&#34892;&#21327;&#21464;&#37327;&#25928;&#24212;&#20272;&#35745;&#26102;&#38750;&#24120;&#39640;&#25928;&#65292;&#19981;&#38656;&#35201;&#24378;&#28872;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#22343;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#20449;&#24230;&#20445;&#35777;&#21644;&#25928;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.06756</link><description>&lt;p&gt;
&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#39640;&#32500;&#21322;&#21442;&#25968;&#25512;&#29702;&#30340;&#24809;&#32602;&#27850;&#26494;&#20284;&#28982;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Penalized Poisson Likelihood Approach to High-Dimensional Semi-Parametric Inference for Doubly-Stochastic Point Processes. (arXiv:2306.06756v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#36827;&#34892;&#21327;&#21464;&#37327;&#25928;&#24212;&#20272;&#35745;&#26102;&#38750;&#24120;&#39640;&#25928;&#65292;&#19981;&#38656;&#35201;&#24378;&#28872;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#22343;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#20449;&#24230;&#20445;&#35777;&#21644;&#25928;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#23558;&#31354;&#38388;&#22495;&#20869;&#20107;&#20214;&#30340;&#21457;&#29983;&#24314;&#27169;&#20026;&#22312;&#23454;&#29616;&#38543;&#26426;&#24378;&#24230;&#20989;&#25968;&#30340;&#26465;&#20214;&#19979;&#65292;&#19981;&#22343;&#21248;&#27850;&#26494;&#36807;&#31243;&#12290;&#23427;&#20204;&#26159;&#25429;&#25417;&#31354;&#38388;&#24322;&#36136;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#28789;&#27963;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#21452;&#38543;&#26426;&#31354;&#38388;&#27169;&#22411;&#30340;&#23454;&#29616;&#22312;&#35745;&#31639;&#19978;&#26159;&#26377;&#35201;&#27714;&#30340;&#65292;&#24448;&#24448;&#20855;&#26377;&#26377;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;/&#25110;&#20381;&#36182;&#20110;&#20855;&#26377;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#20013;&#30340;&#21327;&#21464;&#37327;&#25928;&#24212;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#19988;&#19981;&#38656;&#35201;&#22522;&#30784;&#24378;&#24230;&#30340;&#21442;&#25968;&#24418;&#24335;&#25110;&#24179;&#31283;&#24615;&#12290;&#25105;&#20204;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#23548;&#33268;&#20445;&#23432;&#30340;&#32479;&#35745;&#25512;&#26029;&#31243;&#24207;&#12290;&#27169;&#25311;&#30740;&#31350;&#26174;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#38480;&#21046;&#24615;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19988;&#22312;&#35199;&#38597;&#22270;&#29359;&#32618;&#20107;&#20214;&#30340;&#24212;&#29992;&#20013;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Doubly-stochastic point processes model the occurrence of events over a spatial domain as an inhomogeneous Poisson process conditioned on the realization of a random intensity function. They are flexible tools for capturing spatial heterogeneity and dependence. However, implementations of doubly-stochastic spatial models are computationally demanding, often have limited theoretical guarantee, and/or rely on restrictive assumptions. We propose a penalized regression method for estimating covariate effects in doubly-stochastic point processes that is computationally efficient and does not require a parametric form or stationarity of the underlying intensity. We establish the consistency and asymptotic normality of the proposed estimator, and develop a covariance estimator that leads to a conservative statistical inference procedure. A simulation study shows the validity of our approach under less restrictive assumptions on the data generating mechanism, and an application to Seattle crim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#20010;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#36866;&#29992;&#20110;Z&#20026;&#36830;&#32493;&#20540;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2306.06721</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Conditional Independence Testing. (arXiv:2306.06721v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#20010;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#36866;&#29992;&#20110;Z&#20026;&#36830;&#32493;&#20540;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;CI&#65289;&#26816;&#39564;&#22312;&#32479;&#35745;&#25968;&#25454;&#20998;&#26512;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20363;&#22914;&#65292;&#23427;&#20204;&#26159;&#35768;&#22810;&#22240;&#26524;&#22270;&#21457;&#29616;&#31639;&#27861;&#30340;&#26500;&#24314;&#22359;&#12290;CI&#27979;&#35797;&#26088;&#22312;&#25509;&#21463;&#25110;&#25298;&#32477;$X \perp \!\!\! \perp Y \mid Z$&#30340;&#38646;&#20551;&#35774;&#65292;&#20854;&#20013;$X \in \mathbb{R}&#65292;Y \in \mathbb{R}&#65292;Z \in \mathbb{R}^d$&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#22522;&#20110;Shah&#21644;Peters&#65288;2020&#65289;&#30340;&#19968;&#33324;&#21270;&#21327;&#26041;&#24046;&#27979;&#37327;&#21644;&#22522;&#20110;Cand\`es&#31561;&#20154;&#30340;&#26465;&#20214;&#38543;&#26426;&#21270;&#26816;&#39564;&#30340;&#20004;&#31181;&#31169;&#20154;CI&#27979;&#35797;&#36807;&#31243;&#65288;&#22312;&#27169;&#22411;-X&#20551;&#35774;&#19979;&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#25105;&#20204;&#27979;&#35797;&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#35777;&#19978;&#39564;&#35777;&#23427;&#20204;&#12290;&#36825;&#20123;&#26159;&#31532;&#19968;&#20010;&#36866;&#29992;&#20110;Z&#20026;&#36830;&#32493;&#30340;&#19968;&#33324;&#24773;&#20917;&#30340;&#31169;&#20154;CI&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional independence (CI) tests are widely used in statistical data analysis, e.g., they are the building block of many algorithms for causal graph discovery. The goal of a CI test is to accept or reject the null hypothesis that $X \perp \!\!\! \perp Y \mid Z$, where $X \in \mathbb{R}, Y \in \mathbb{R}, Z \in \mathbb{R}^d$. In this work, we investigate conditional independence testing under the constraint of differential privacy. We design two private CI testing procedures: one based on the generalized covariance measure of Shah and Peters (2020) and another based on the conditional randomization test of Cand\`es et al. (2016) (under the model-X assumption). We provide theoretical guarantees on the performance of our tests and validate them empirically. These are the first private CI tests that work for the general case when $Z$ is continuous.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38416;&#26126;&#20102;&#22312;&#29983;&#29289;&#31561;&#25928;&#24615;&#27979;&#35797;&#20013;&#65292;&#29992;$100(1-2\alpha)\%$&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#36827;&#34892;&#26816;&#39564;&#21482;&#26377;&#22312;TOST&#20013;&#20004;&#20010;&#21333;&#20391;&#26816;&#39564;&#8220;&#31561;&#23614;&#8221;&#26102;&#25165;&#33021;&#24471;&#21040;&#27491;&#30830;&#32467;&#26524;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#26631;&#20934;&#26041;&#27861;&#26356;&#35814;&#32454;&#30340;&#26816;&#39564;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.06698</link><description>&lt;p&gt;
&#20851;&#20110;&#29983;&#29289;&#31561;&#25928;&#24615;&#30740;&#31350;&#20013;&#30340;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
On the Confidence Intervals in Bioequivalence Studies. (arXiv:2306.06698v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38416;&#26126;&#20102;&#22312;&#29983;&#29289;&#31561;&#25928;&#24615;&#27979;&#35797;&#20013;&#65292;&#29992;$100(1-2\alpha)\%$&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#36827;&#34892;&#26816;&#39564;&#21482;&#26377;&#22312;TOST&#20013;&#20004;&#20010;&#21333;&#20391;&#26816;&#39564;&#8220;&#31561;&#23614;&#8221;&#26102;&#25165;&#33021;&#24471;&#21040;&#27491;&#30830;&#32467;&#26524;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#26631;&#20934;&#26041;&#27861;&#26356;&#35814;&#32454;&#30340;&#26816;&#39564;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#31561;&#25928;&#24615;&#30740;&#31350;&#26159;&#19968;&#31181;&#27604;&#36739;&#20004;&#31181;&#19981;&#21516;&#33647;&#29289;&#37197;&#26041;&#29983;&#29289;&#31561;&#25928;&#24615;&#30340;&#20020;&#24202;&#35797;&#39564;&#12290;&#22312;&#27492;&#31867;&#30740;&#31350;&#20013;&#65292;&#36890;&#24120;&#20250;&#23545;&#38543;&#26426;&#20998;&#37197;&#32473;&#25509;&#21463;&#20004;&#31181;&#37197;&#26041;&#30340;&#20154;&#20307;&#35797;&#39564;&#23545;&#35937;&#30340;&#33647;&#29289;&#21160;&#21147;&#23398;&#29305;&#24449;&#36827;&#34892;&#27604;&#36739;&#12290;&#26681;&#25454;&#32654;&#22269;&#39135;&#21697;&#21644;&#33647;&#21697;&#31649;&#29702;&#23616;&#65288;FDA&#65289;&#30340;&#25351;&#23548;&#65292;&#23545;&#20110;&#19968;&#20010;&#22823;&#23567;&#20026;$\alpha$&#30340;&#29983;&#29289;&#31561;&#20215;&#24615;&#26816;&#39564;&#65292;&#26631;&#20934;&#20570;&#27861;&#26159;&#26500;&#24314;&#19968;&#20010;$100(1-2\alpha)\%$&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#39564;&#35777;&#32622;&#20449;&#21306;&#38388;&#26159;&#21542;&#33853;&#22312;&#20851;&#38190;&#21306;&#38388;&#20869;&#12290;&#26412;&#25991;&#38416;&#26126;&#20102;&#22312;TOST&#20013;&#20004;&#20010;&#21333;&#20391;&#26816;&#39564;&#8220;&#31561;&#23614;&#8221;&#26102;&#65292;&#29992;$100(1-2\alpha)\%$&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#36827;&#34892;&#29983;&#29289;&#31561;&#25928;&#24615;&#26816;&#39564;&#21482;&#33021;&#24471;&#21040;&#19968;&#20010;&#22823;&#23567;&#20026;$\alpha$&#30340;&#26816;&#39564;&#12290;&#27492;&#22806;&#65292;&#22312;&#29983;&#29289;&#31561;&#25928;&#24615;&#27979;&#35797;&#29615;&#22659;&#20013;&#65292;&#36824;&#35752;&#35770;&#20102;&#19968;&#31181;$100(1-\alpha)\%$&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#27604;&#26631;&#20934;&#26041;&#27861;&#26356;&#35814;&#32454;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
A bioequivalence study is a type of clinical trial designed to compare the biological equivalence of two different formulations of a drug. Such studies are typically conducted in controlled clinical settings with human subjects, who are randomly assigned to receive two formulations. The two formulations are then compared with respect to their pharmacokinetic profiles, which encompass the absorption, distribution, metabolism, and elimination of the drug. Under the guidance from Food and Drug Administration (FDA), for a size-$\alpha$ bioequivalence test, the standard approach is to construct a $100(1-2\alpha)\%$ confidence interval and verify if the confidence interval falls with the critical region. In this work, we clarify that $100(1-2\alpha)\%$ confidence interval approach for bioequivalence testing yields a size-$\alpha$ test only when the two one-sided tests in TOST are ``equal-tailed''. Furthermore, a $100(1-\alpha)\%$ confidence interval approach is also discussed in the bioequiv
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#25968;&#25454;&#20013;&#30340;&#26497;&#23567;&#21270;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#26377;&#25928;&#23398;&#20064;&#31639;&#27861;&#65292;&#20855;&#26377;&#29305;&#24449;&#36873;&#25321;&#21644;&#25552;&#20379;&#26377;&#20851;&#20998;&#31867;&#22120;&#24615;&#33021;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38169;&#35823;&#27010;&#29575;&#30340;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.06649</link><description>&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#19978;&#30340;&#26497;&#23567;&#21270;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#26377;&#25928;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Efficient Learning of Minimax Risk Classifiers in High Dimensions. (arXiv:2306.06649v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06649
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#25968;&#25454;&#20013;&#30340;&#26497;&#23567;&#21270;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#26377;&#25928;&#23398;&#20064;&#31639;&#27861;&#65292;&#20855;&#26377;&#29305;&#24449;&#36873;&#25321;&#21644;&#25552;&#20379;&#26377;&#20851;&#20998;&#31867;&#22120;&#24615;&#33021;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38169;&#35823;&#27010;&#29575;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#22312;&#35768;&#22810;&#39046;&#22495;&#38750;&#24120;&#26222;&#36941;&#65292;&#27604;&#22914;&#21307;&#30103;&#20445;&#20581;&#21644;&#22522;&#22240;&#32452;&#23398;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29305;&#24449;&#30340;&#25968;&#37327;&#24448;&#24448;&#20250;&#23548;&#33268;&#23398;&#20064;&#25928;&#29575;&#20302;&#19979;&#12290;&#26368;&#36817;&#65292;&#32422;&#26463;&#29983;&#25104;&#26041;&#27861;&#24050;&#32463;&#20351;&#24471;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#30340;L1&#27491;&#21017;&#21270;&#30340;&#26377;&#25928;&#23398;&#20064;&#25104;&#20026;&#21487;&#33021;&#12290;&#26412;&#25991;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#33719;&#21462;&#20102;&#19968;&#31181;&#26377;&#25928;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#26497;&#23567;&#21270;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;MRC&#65289;&#12290;&#25152;&#25552;&#20986;&#30340;&#36845;&#20195;&#31639;&#27861;&#36824;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38169;&#35823;&#27010;&#29575;&#24182;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#12290;&#23545;&#22810;&#20010;&#39640;&#32500;&#24230;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#39640;&#32500;&#24230;&#22330;&#26223;&#19979;&#26159;&#26377;&#25928;&#30340;&#12290;&#27492;&#22806;&#65292;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38169;&#35823;&#27010;&#29575;&#25552;&#20379;&#20102;&#20851;&#20110;&#20998;&#31867;&#22120;&#24615;&#33021;&#30340;&#26377;&#29992;&#20449;&#24687;&#65292;&#31639;&#27861;&#36873;&#25321;&#30340;&#29305;&#24449;&#20063;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional data is common in multiple areas, such as health care and genomics, where the number of features can be tens of thousands. In such scenarios, the large number of features often leads to inefficient learning. Constraint generation methods have recently enabled efficient learning of L1-regularized support vector machines (SVMs). In this paper, we leverage such methods to obtain an efficient learning algorithm for the recently proposed minimax risk classifiers (MRCs). The proposed iterative algorithm also provides a sequence of worst-case error probabilities and performs feature selection. Experiments on multiple high-dimensional datasets show that the proposed algorithm is efficient in high-dimensional scenarios. In addition, the worst-case error probability provides useful information about the classifier performance, and the features selected by the algorithm are competitive with the state-of-the-art.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#39640;&#26031;&#27010;&#29575;&#36335;&#24452;&#30340;&#21160;&#21147;&#23398;&#26368;&#20339;&#25104;&#21592;&#65292;&#21457;&#29616;&#21160;&#33021;&#22312;&#36825;&#26679;&#30340;&#36335;&#24452;&#31354;&#38388;&#19978;&#21487;&#20197;&#36890;&#36807;&#21333;&#19968;&#30340;&#19968;&#32500;&#26631;&#37327;&#20989;&#25968;&#26469;&#25972;&#21512;&#25968;&#25454;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#25552;&#39640;&#30740;&#31350;&#25152;&#38656;&#30340;&#31890;&#23376;&#36712;&#36857;&#31616;&#21333;&#24615;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.06626</link><description>&lt;p&gt;
&#20851;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#21160;&#21147;&#23398;&#26368;&#20339;&#27010;&#29575;&#36335;&#24452;
&lt;/p&gt;
&lt;p&gt;
On Kinetic Optimal Probability Paths for Generative Models. (arXiv:2306.06626v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#39640;&#26031;&#27010;&#29575;&#36335;&#24452;&#30340;&#21160;&#21147;&#23398;&#26368;&#20339;&#25104;&#21592;&#65292;&#21457;&#29616;&#21160;&#33021;&#22312;&#36825;&#26679;&#30340;&#36335;&#24452;&#31354;&#38388;&#19978;&#21487;&#20197;&#36890;&#36807;&#21333;&#19968;&#30340;&#19968;&#32500;&#26631;&#37327;&#20989;&#25968;&#26469;&#25972;&#21512;&#25968;&#25454;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#25552;&#39640;&#30740;&#31350;&#25152;&#38656;&#30340;&#31890;&#23376;&#36712;&#36857;&#31616;&#21333;&#24615;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25104;&#21151;&#30340;&#29983;&#25104;&#27169;&#22411;&#36890;&#36807;&#23558;&#31070;&#32463;&#32593;&#32476;&#25311;&#21512;&#21040;&#20107;&#20808;&#23450;&#20041;&#30340;&#21487;&#22788;&#29702;&#30340;&#27010;&#29575;&#23494;&#24230;&#36335;&#24452;&#19978;&#26469;&#35757;&#32451;&#12290;&#26412;&#25991;&#30740;&#31350;&#39640;&#26031;&#27010;&#29575;&#36335;&#24452;&#31354;&#38388;&#65292;&#21253;&#21547;&#25193;&#25955;&#36335;&#24452;&#20316;&#20026;&#19968;&#31181;&#20363;&#23376;&#65292;&#24182;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#23547;&#25214;&#19968;&#20010;&#26368;&#20248;&#25104;&#21592;&#12290;&#29305;&#21035;&#26159;&#65292;&#26368;&#23567;&#21270;&#36335;&#24452;&#30340;&#21160;&#33021;&#24050;&#30693;&#21487;&#20197;&#20351;&#31890;&#23376;&#30340;&#36712;&#36857;&#31616;&#21333;&#65292;&#22240;&#27492;&#26356;&#26131;&#20110;&#37319;&#26679;&#65292;&#24182;&#22312;&#26410;&#30475;&#21040;&#25968;&#25454;&#21644;&#26679;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#22312;&#32463;&#39564;&#19978;&#24471;&#21040;&#25552;&#39640;&#12290;&#25105;&#20204;&#30740;&#31350;&#21160;&#21147;&#23398;&#26368;&#20339;&#39640;&#26031;&#36335;&#24452;&#65292;&#24182;&#25552;&#20379;&#20197;&#19979;&#35266;&#23519;&#65306;&#65288;i&#65289;&#25105;&#20204;&#23637;&#31034;&#20102;&#21160;&#33021;&#22312;&#39640;&#26031;&#36335;&#24452;&#31354;&#38388;&#19978;&#37319;&#21462;&#31616;&#21270;&#24418;&#24335;&#65292;&#20854;&#20013;&#20165;&#36890;&#36807;&#31216;&#20026;&#8220;&#25968;&#25454;&#20998;&#31163;&#20989;&#25968;&#8221;&#30340;&#21333;&#19968;&#19968;&#32500;&#26631;&#37327;&#20989;&#25968;&#26469;&#32435;&#20837;&#25968;&#25454;&#12290;&#65288;ii&#65289;&#25105;&#20204;&#29992;&#19968;&#32500;ODE&#25551;&#36848;&#20102;KO&#35299;&#12290;&#65288;iii&#65289;&#25105;&#20204;&#36890;&#36807;&#36924;&#36817;&#34920;&#31034;&#25968;&#25454;&#30456;&#20851;&#30340;KO&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent successful generative models are trained by fitting a neural network to an a-priori defined tractable probability density path taking noise to training examples. In this paper we investigate the space of Gaussian probability paths, which includes diffusion paths as an instance, and look for an optimal member in some useful sense. In particular, minimizing the Kinetic Energy (KE) of a path is known to make particles' trajectories simple, hence easier to sample, and empirically improve performance in terms of likelihood of unseen data and sample generation quality. We investigate Kinetic Optimal (KO) Gaussian paths and offer the following observations: (i) We show the KE takes a simplified form on the space of Gaussian paths, where the data is incorporated only through a single, one dimensional scalar function, called the \emph{data separation function}. (ii) We characterize the KO solutions with a one dimensional ODE. (iii) We approximate data-dependent KO paths by approximating 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.06599</link><description>&lt;p&gt;
&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;(Variational Imbalanced Regression)
&lt;/p&gt;
&lt;p&gt;
Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;Probabilistic Reweighting&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#33258;&#28982;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26631;&#31614;&#20998;&#24067;&#19981;&#24179;&#34913;&#26102;&#65292;&#29616;&#26377;&#30340;&#22238;&#24402;&#27169;&#22411;&#24448;&#24448;&#22312;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21464;&#20998;&#19981;&#24179;&#34913;&#22238;&#24402;&#65288;VIR&#65289;&#65292;&#23427;&#19981;&#20165;&#22312;&#19981;&#24179;&#34913;&#22238;&#24402;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;&#19988;&#33258;&#28982;&#22320;&#20135;&#29983;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#19982;&#20856;&#22411;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20551;&#35774;I.I.D.&#34920;&#31034;&#65288;&#25968;&#25454;&#28857;&#30340;&#34920;&#31034;&#19981;&#30452;&#25509;&#21463;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;VIR&#20511;&#29992;&#20855;&#26377;&#31867;&#20284;&#22238;&#24402;&#26631;&#31614;&#30340;&#25968;&#25454;&#26469;&#35745;&#31639;&#28508;&#22312;&#34920;&#31034;&#30340;&#21464;&#20998;&#20998;&#24067;&#65307;&#27492;&#22806;&#65292;&#19981;&#21516;&#20110;&#20135;&#29983;&#28857;&#20272;&#35745;&#30340;&#30830;&#23450;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292; VIR&#39044;&#27979;&#25972;&#20010;&#27491;&#24577;&#21453;-&#20285;&#29595;&#20998;&#24067;&#24182;&#35843;&#33410;&#30456;&#20851;&#32852;&#30340;&#20849;&#36717;&#20998;&#24067;&#65292;&#23545;&#19981;&#24179;&#34913;&#25968;&#25454;&#26045;&#21152;&#27010;&#29575;&#37325;&#26032;&#21152;&#26435;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#22312;&#20960;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#39044;&#27979;&#25512;&#26029;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#25968;&#25454;&#20570;&#20986;&#20998;&#24067;&#20551;&#35774;&#12290;&#23545;&#20110;&#20132;&#25442;&#25968;&#25454;&#65292;&#36890;&#36807;&#20351;&#29992;$(\epsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#24182;&#22260;&#32469;&#24046;&#21035;&#31169;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#36827;&#34892;&#32447;&#24615;&#36924;&#36817;&#65292;&#35813;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#20005;&#26684;&#30340;&#35206;&#30422;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.06582</link><description>&lt;p&gt;
&#20855;&#26377;&#35206;&#30422;&#20445;&#35777;&#30340;&#31070;&#32463;&#32593;&#32476;&#26080;&#20998;&#24067;&#39044;&#27979;&#25512;&#26029;&#30340;&#24555;&#36895;&#35745;&#31639;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast, Distribution-free Predictive Inference for Neural Networks with Coverage Guarantees. (arXiv:2306.06582v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06582
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#39044;&#27979;&#25512;&#26029;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#25968;&#25454;&#20570;&#20986;&#20998;&#24067;&#20551;&#35774;&#12290;&#23545;&#20110;&#20132;&#25442;&#25968;&#25454;&#65292;&#36890;&#36807;&#20351;&#29992;$(\epsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#24182;&#22260;&#32469;&#24046;&#21035;&#31169;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#36827;&#34892;&#32447;&#24615;&#36924;&#36817;&#65292;&#35813;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#20005;&#26684;&#30340;&#35206;&#30422;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#39044;&#27979;&#25512;&#26029;(PI)&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#23545;&#25968;&#25454;&#20570;&#20986;&#20998;&#24067;&#20551;&#35774;&#65292;&#19988;&#27604;&#29616;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#24341;&#23548;&#24335;&#26041;&#27861;&#26356;&#24555;&#22320;&#35745;&#31639;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22914;&#26524;&#26377;$n$&#20010;&#35757;&#32451;&#26679;&#26412;&#65292;&#24341;&#23548;&#24335;&#26041;&#27861;&#38656;&#35201;&#22312;&#22823;&#23567;&#20026;$n-1$&#30340;$n$&#20010;&#23376;&#26679;&#26412;&#19978;&#35757;&#32451;&#19968;&#20010;&#27169;&#22411;&#65307;&#23545;&#20110;&#20687;&#31070;&#32463;&#32593;&#32476;&#36825;&#26679;&#30340;&#22823;&#27169;&#22411;&#65292;&#36825;&#20010;&#36807;&#31243;&#21487;&#33021;&#35745;&#31639;&#19978;&#19981;&#20999;&#23454;&#38469;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#23436;&#25972;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;$(\epsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;(DP)&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#28982;&#21518;&#20351;&#29992;&#32447;&#24615;&#36924;&#36817;&#26469;&#39640;&#25928;&#22320;&#36817;&#20284;&#27599;&#20010;&#30041;&#19968;&#20986;&#27169;&#22411;&#65292;&#35813;&#36924;&#36817;&#26159;&#22260;&#32469;&#24046;&#21035;&#31169;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#26469;&#36827;&#34892;&#30340;&#12290;&#23545;&#20110;&#20132;&#25442;&#25968;&#25454;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20005;&#26684;&#30340;&#35206;&#30422;&#20445;&#35777;&#65292;&#36825;&#21462;&#20915;&#20110;&#39044;&#35774;&#30340;&#38544;&#31169;&#21442;&#25968;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#65292;&#32780;&#19981;&#21462;&#20915;&#20110;&#25968;&#25454;&#20998;&#24067;&#12290;&#27169;&#25311;&#21644;&#23454;&#39564;&#25968;&#25454;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#22522;&#20110;&#24341;&#23548;&#24335;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel, computationally-efficient algorithm for predictive inference (PI) that requires no distributional assumptions on the data and can be computed faster than existing bootstrap-type methods for neural networks. Specifically, if there are $n$ training samples, bootstrap methods require training a model on each of the $n$ subsamples of size $n-1$; for large models like neural networks, this process can be computationally prohibitive. In contrast, our proposed method trains one neural network on the full dataset with $(\epsilon, \delta)$-differential privacy (DP) and then approximates each leave-one-out model efficiently using a linear approximation around the differentially-private neural network estimate. With exchangeable data, we prove that our approach has a rigorous coverage guarantee that depends on the preset privacy parameters and the stability of the neural network, regardless of the data distribution. Simulations and experiments on real data demonstra
&lt;/p&gt;</description></item><item><title>Spar-Sink&#26159;&#19968;&#31181;&#37325;&#35201;&#24615;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#36817;&#20284;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#20256;&#36755;&#21644;&#19981;&#24179;&#34913;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.06581</link><description>&lt;p&gt;
Sinkhorn&#31639;&#27861;&#30340;&#37325;&#35201;&#24615;&#31232;&#30095;&#21270;
&lt;/p&gt;
&lt;p&gt;
Importance Sparsification for Sinkhorn Algorithm. (arXiv:2306.06581v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06581
&lt;/p&gt;
&lt;p&gt;
Spar-Sink&#26159;&#19968;&#31181;&#37325;&#35201;&#24615;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#36817;&#20284;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#20256;&#36755;&#21644;&#19981;&#24179;&#34913;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sinkhorn&#31639;&#27861;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#36817;&#20284;&#27714;&#35299;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#21644;&#19981;&#24179;&#34913;&#26368;&#20248;&#20256;&#36755;&#65288;UOT&#65289;&#38382;&#39064;&#12290;&#20294;&#30001;&#20110;&#39640;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#20854;&#23454;&#38469;&#24212;&#29992;&#21463;&#21040;&#38480;&#21046;&#12290;&#20026;&#20943;&#36731;&#35745;&#31639;&#36127;&#25285;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37325;&#35201;&#24615;&#31232;&#30095;&#21270;&#26041;&#27861;Spar-Sink&#65292;&#29992;&#20110;&#39640;&#25928;&#36817;&#20284;&#29109;&#27491;&#21017;&#21270;OT&#21644;UOT&#35299;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#26410;&#30693;&#26368;&#20248;&#20256;&#36755;&#35745;&#21010;&#30340;&#33258;&#28982;&#19978;&#30028;&#30830;&#23450;&#26377;&#25928;&#30340;&#37319;&#26679;&#27010;&#29575;&#65292;&#24182;&#26500;&#24314;&#31232;&#30095;&#30340;&#26680;&#30697;&#38453;&#20197;&#21152;&#36895;Sinkhorn&#36845;&#20195;&#65292;&#23558;&#27599;&#27425;&#36845;&#20195;&#30340;&#35745;&#31639;&#25104;&#26412;&#20174;$ O&#65288;n ^ 2&#65289;$&#38477;&#20302;&#21040;$\widetilde {O&#65288;n&#65289;}$&#36866;&#29992;&#20110;&#26679;&#26412;&#22823;&#23567;&#20026;$ n $&#30340;&#24773;&#20917;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#28201;&#21644;&#27491;&#21017;&#24615;&#26465;&#20214;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;OT&#21644;UOT&#38382;&#39064;&#30340;&#20272;&#35745;&#37327;&#26159;&#19968;&#33268;&#30340;&#12290;&#22312;&#21508;&#31181;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#20272;&#35745;&#35823;&#24046;&#26041;&#38754;&#65292;Spar-Sink&#20248;&#20110;&#20027;&#27969;&#31454;&#20105;&#23545;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sinkhorn algorithm has been used pervasively to approximate the solution to optimal transport (OT) and unbalanced optimal transport (UOT) problems. However, its practical application is limited due to the high computational complexity. To alleviate the computational burden, we propose a novel importance sparsification method, called Spar-Sink, to efficiently approximate entropy-regularized OT and UOT solutions. Specifically, our method employs natural upper bounds for unknown optimal transport plans to establish effective sampling probabilities, and constructs a sparse kernel matrix to accelerate Sinkhorn iterations, reducing the computational cost of each iteration from $O(n^2)$ to $\widetilde{O}(n)$ for a sample of size $n$. Theoretically, we show the proposed estimators for the regularized OT and UOT problems are consistent under mild regularity conditions. Experiments on various synthetic data demonstrate Spar-Sink outperforms mainstream competitors in terms of both estimation erro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23616;&#37096;&#21040;&#20840;&#23616;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21253;&#25324;&#19981;&#21464;&#22270;&#32593;&#32476;&#12289;&#23616;&#37096;&#20449;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;&#20840;&#23616;&#22270;&#21464;&#25442;&#22120;&#65292;&#24182;&#30740;&#31350;&#20854;&#25910;&#25947;&#24615;&#36136;&#21644;&#22312;&#22270;&#31895;&#21270;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.06547</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#23616;&#37096;&#21040;&#20840;&#23616;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Local-to-global Perspectives on Graph Neural Networks. (arXiv:2306.06547v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06547
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23616;&#37096;&#21040;&#20840;&#23616;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21253;&#25324;&#19981;&#21464;&#22270;&#32593;&#32476;&#12289;&#23616;&#37096;&#20449;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;&#20840;&#23616;&#22270;&#21464;&#25442;&#22120;&#65292;&#24182;&#30740;&#31350;&#20854;&#25910;&#25947;&#24615;&#36136;&#21644;&#22312;&#22270;&#31895;&#21270;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#23616;&#37096;&#21040;&#20840;&#23616;&#30340;&#35270;&#35282;&#65292;&#20854;&#20013;&#20998;&#20026;&#23616;&#37096;&#20449;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#21644;&#20840;&#23616;&#22270;&#21464;&#25442;&#22120;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#24037;&#20316;&#65306;1&#65289;&#30740;&#31350;&#19968;&#31181;&#20840;&#23616; GNN&#65292;&#19981;&#21464;&#22270;&#32593;&#32476;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;2&#65289;&#36830;&#25509;&#23616;&#37096; MPNN &#21644;&#20840;&#23616;&#22270;&#21464;&#25442;&#22120;&#65292;3&#65289;&#22312;&#20840;&#23616;&#24314;&#27169;&#20013;&#65292;&#20351;&#29992;&#23616;&#37096; MPNN &#36827;&#34892;&#22270;&#31895;&#21270;&#65292;&#36825;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#23376;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a local-to-global perspective on graph neural networks (GNN), which are categorized as local Message Passing Neural Networks (MPNN) and global Graph Transformer. We present three pieces of work: 1) study the convergence property of a type of global GNN, Invariant Graph Networks, 2) connect the local MPNN and global Graph Transformer, and 3) use local MPNN for graph coarsening, a common subroutine used in global modeling.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PICLE&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#27010;&#29575;&#27169;&#22411;&#24555;&#36895;&#35745;&#31639;&#27599;&#20010;&#32452;&#21512;&#30340;&#36866;&#24212;&#24230;&#26469;&#21152;&#36895;&#25628;&#32034;&#65292;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#36716;&#31227;&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.06545</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#26694;&#26550;&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Framework for Modular Continual Learning. (arXiv:2306.06545v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PICLE&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#27010;&#29575;&#27169;&#22411;&#24555;&#36895;&#35745;&#31639;&#27599;&#20010;&#32452;&#21512;&#30340;&#36866;&#24212;&#24230;&#26469;&#21152;&#36895;&#25628;&#32034;&#65292;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#36716;&#31227;&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22359;&#21270;&#26041;&#27861;&#26159;&#22686;&#37327;&#23398;&#20064;&#39046;&#22495;&#30340;&#26377;&#21069;&#36884;&#26041;&#21521;&#65292;&#27599;&#20010;&#38382;&#39064;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22359;&#32452;&#21512;&#19988;&#36991;&#20813;&#36951;&#24536;&#12290;&#28982;&#32780;&#65292;&#25628;&#32034;&#21487;&#33021;&#30340;&#27169;&#22359;&#32452;&#21512;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#22240;&#20026;&#35780;&#20272;&#32452;&#21512;&#24615;&#33021;&#38656;&#35201;&#19968;&#36718;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31181;&#21517;&#20026;PICLE&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#27010;&#29575;&#27169;&#22411;&#26469;&#24555;&#36895;&#35745;&#31639;&#27599;&#20010;&#32452;&#21512;&#30340;&#36866;&#24212;&#24230;&#26469;&#21152;&#36895;&#25628;&#32034;&#12290;&#27169;&#22411;&#32467;&#21512;&#20808;&#21069;&#20851;&#20110;&#33391;&#22909;&#27169;&#22359;&#32452;&#21512;&#30340;&#30693;&#35782;&#19982;&#25968;&#25454;&#38598;&#29305;&#23450;&#20449;&#24687;&#12290;&#23427;&#30340;&#20351;&#29992;&#34987;&#20998;&#20026;&#24863;&#30693;&#21644;&#28508;&#22312;&#23376;&#38598;&#31561;&#23376;&#38598;&#30340;&#25628;&#32034;&#31354;&#38388;&#21152;&#20197;&#34917;&#20805;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;PICLE&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#36716;&#31227;&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#31639;&#27861;&#65292;&#21516;&#26102;&#36824;&#33021;&#25193;&#23637;&#21040;&#22823;&#22411;&#25628;&#32034;&#31354;&#38388;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#22522;&#20934;&#22871;&#20214;&#19978;&#23545;&#20854;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#20123;&#22871;&#20214;&#26088;&#22312;&#25429;&#25417;&#22686;&#37327;&#23398;&#20064;&#25216;&#26415;&#30340;&#19981;&#21516;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modular approaches, which use a different composition of modules for each problem and avoid forgetting by design, have been shown to be a promising direction in continual learning (CL). However, searching through the large, discrete space of possible module compositions is a challenge because evaluating a composition's performance requires a round of neural network training. To address this challenge, we develop a modular CL framework, called PICLE, that accelerates search by using a probabilistic model to cheaply compute the fitness of each composition. The model combines prior knowledge about good module compositions with dataset-specific information. Its use is complemented by splitting up the search space into subsets, such as perceptual and latent subsets. We show that PICLE is the first modular CL algorithm to achieve different types of transfer while scaling to large search spaces. We evaluate it on two benchmark suites designed to capture different desiderata of CL techniques. 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#20381;&#36182;&#36328;&#22495;&#22240;&#26524;&#26426;&#21046;&#30340;&#26368;&#23567;&#25913;&#21464;&#23646;&#24615;&#65292;&#22312;&#20445;&#25345;&#29305;&#23450;&#32452;&#20998;&#36328;&#22495;&#19981;&#21464;&#30340;&#21069;&#25552;&#19979;&#26368;&#23567;&#21270;&#20998;&#24067;&#36716;&#31227;&#30340;&#19981;&#24517;&#35201;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.06510</link><description>&lt;p&gt;
&#38024;&#23545;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Partial Identifiability for Domain Adaptation. (arXiv:2306.06510v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#20381;&#36182;&#36328;&#22495;&#22240;&#26524;&#26426;&#21046;&#30340;&#26368;&#23567;&#25913;&#21464;&#23646;&#24615;&#65292;&#22312;&#20445;&#25345;&#29305;&#23450;&#32452;&#20998;&#36328;&#22495;&#19981;&#21464;&#30340;&#21069;&#25552;&#19979;&#26368;&#23567;&#21270;&#20998;&#24067;&#36716;&#31227;&#30340;&#19981;&#24517;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#23545;&#20110;&#35768;&#22810;&#27809;&#26377;&#30446;&#26631;&#22495;&#26631;&#31614;&#20449;&#24687;&#30340;&#23454;&#38469;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#22914;&#26524;&#27809;&#26377;&#36827;&#19968;&#27493;&#30340;&#20551;&#35774;&#65292;&#29305;&#24449;&#21644;&#26631;&#31614;&#30340;&#32852;&#21512;&#20998;&#24067;&#22312;&#30446;&#26631;&#22495;&#20013;&#26159;&#19981;&#21487;&#35782;&#21035;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20381;&#36182;&#36328;&#22495;&#22240;&#26524;&#26426;&#21046;&#30340;&#26368;&#23567;&#25913;&#21464;&#23646;&#24615;&#65292;&#20197;&#26368;&#23567;&#21270;&#20998;&#24067;&#36716;&#31227;&#30340;&#19981;&#24517;&#35201;&#24433;&#21709;&#12290;&#20026;&#20102;&#32534;&#30721;&#36825;&#20010;&#23646;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#19968;&#20010;&#24102;&#26377;&#20004;&#20010;&#20998;&#21306;&#28508;&#21464;&#37327;&#23376;&#31354;&#38388;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26469;&#21046;&#23450;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65306;&#19981;&#21464;&#37096;&#20998;&#30340;&#20998;&#24067;&#22312;&#36328;&#22495;&#26102;&#20445;&#25345;&#19981;&#21464;&#65292;&#32780;&#31232;&#30095;&#30340;&#21487;&#21464;&#37096;&#20998;&#20250;&#22312;&#19981;&#21516;&#30340;&#22495;&#20013;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#38480;&#21046;&#20102;&#22495;&#31227;&#20301;&#23545;&#21487;&#21464;&#37096;&#20998;&#30340;&#24433;&#21709;&#12290;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#37096;&#20998;&#21487;&#35782;&#21035;&#30340;&#28508;&#21464;&#37327;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;&#30446;&#26631;&#22495;&#20013;&#25968;&#25454;&#21644;&#26631;&#31614;&#30340;&#32852;&#21512;&#20998;&#24067;&#20063;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain adaptation is critical to many real-world applications where label information is unavailable in the target domain. In general, without further assumptions, the joint distribution of the features and the label is not identifiable in the target domain. To address this issue, we rely on the property of minimal changes of causal mechanisms across domains to minimize unnecessary influences of distribution shifts. To encode this property, we first formulate the data-generating process using a latent variable model with two partitioned latent subspaces: invariant components whose distributions stay the same across domains and sparse changing components that vary across domains. We further constrain the domain shift to have a restrictive influence on the changing components. Under mild conditions, we show that the latent variables are partially identifiable, from which it follows that the joint distribution of data and labels in the target domain is also identifiable. Give
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#38024;&#23545;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#38382;&#39064;&#36827;&#34892;&#30740;&#31350;&#65292;&#22312;&#26356;&#21152;&#28789;&#27963;&#30340;&#20551;&#35774;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#23545;&#23436;&#25972;&#25968;&#25454;&#30340;&#20805;&#20998;&#35782;&#21035;&#26465;&#20214;&#21644;&#21322;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.06443</link><description>&lt;p&gt;
&#32570;&#22833;&#38750;&#38543;&#26426;&#26426;&#21046;&#19979;&#30340;&#20805;&#20998;&#35782;&#21035;&#26465;&#20214;&#21644;&#21322;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Sufficient Identification Conditions and Semiparametric Estimation under Missing Not at Random Mechanisms. (arXiv:2306.06443v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06443
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#38382;&#39064;&#36827;&#34892;&#30740;&#31350;&#65292;&#22312;&#26356;&#21152;&#28789;&#27963;&#30340;&#20551;&#35774;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#23545;&#23436;&#25972;&#25968;&#25454;&#30340;&#20805;&#20998;&#35782;&#21035;&#26465;&#20214;&#21644;&#21322;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#32570;&#22833;&#38750;&#38543;&#26426;&#65288;MNAR&#65289;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#26377;&#25928;&#30340;&#32479;&#35745;&#20998;&#26512;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#32570;&#22833;&#26426;&#21046;&#20381;&#36182;&#20110;&#32570;&#22833;&#20540;&#26412;&#36523;&#65292;&#21363;&#20351;&#24050;&#30693;&#35266;&#27979;&#25968;&#25454;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;MNAR&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#20004;&#31181;&#26041;&#24335;&#25512;&#24191;&#20102;&#20960;&#20010;&#20808;&#21069;&#27969;&#34892;&#30340;MNAR&#27169;&#22411;&#65306;&#39318;&#20808;&#65292;&#22312;&#38543;&#26426;&#29420;&#31435;&#24615;&#20551;&#35774;&#26041;&#38754;&#26356;&#21152;&#28789;&#27963;&#65292;&#20854;&#27425;&#65292;&#23427;&#20801;&#35768;&#35266;&#23519;&#26679;&#26412;&#20013;&#30340;&#25152;&#26377;&#21464;&#37327;&#37117;&#20855;&#26377;&#32570;&#22833;&#20540;&#12290;&#36825;&#20010;MNAR&#27169;&#22411;&#23545;&#24212;&#20110;&#22312;&#32570;&#22833;&#25968;&#25454;&#30340;&#22270;&#24418;&#27169;&#22411;&#20013;&#32771;&#34385;&#30340;&#25152;&#35859;criss-cross&#32467;&#26500;&#65292;&#23427;&#38459;&#27490;&#20102;&#25972;&#20010;&#32570;&#22833;&#25968;&#25454;&#27169;&#22411;&#30340;&#38750;&#21442;&#25968;&#35782;&#21035;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#23436;&#25972;&#25968;&#25454;&#20998;&#24067;&#30340;&#19968;&#37096;&#20998;&#20173;&#28982;&#21487;&#20197;&#34987;&#38750;&#21442;&#25968;&#35782;&#21035;&#12290;&#36890;&#36807;&#21033;&#29992;&#36825;&#20010;&#20107;&#23454;&#65292;&#24182;&#32771;&#34385;&#19968;&#20010;&#20016;&#23500;&#30340;&#25351;&#25968;&#23478;&#26063;&#20998;&#24067;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#23436;&#25972;&#25968;&#25454;&#30340;&#20805;&#20998;&#35782;&#21035;&#26465;&#20214;&#21644;&#21322;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conducting valid statistical analyses is challenging in the presence of missing-not-at-random (MNAR) data, where the missingness mechanism is dependent on the missing values themselves even conditioned on the observed data. Here, we consider a MNAR model that generalizes several prior popular MNAR models in two ways: first, it is less restrictive in terms of statistical independence assumptions imposed on the underlying joint data distribution, and second, it allows for all variables in the observed sample to have missing values. This MNAR model corresponds to a so-called criss-cross structure considered in the literature on graphical models of missing data that prevents nonparametric identification of the entire missing data model. Nonetheless, part of the complete-data distribution remains nonparametrically identifiable. By exploiting this fact and considering a rich class of exponential family distributions, we establish sufficient conditions for identification of the complete-data 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#21151;&#33021;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;fCBO&#65289;&#26041;&#27861;&#29992;&#20110;&#24050;&#30693;&#22240;&#26524;&#22270;&#20013;&#20248;&#21270;&#30446;&#26631;&#21464;&#37327;&#30340;&#24178;&#39044;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#25193;&#23637;&#20102;CBO&#26041;&#27861;&#26063;&#65292;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#23545;&#26410;&#30693;&#30446;&#26631;&#36827;&#34892;&#24314;&#27169;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23450;&#20041;&#36755;&#20837;&#24182;&#35745;&#31639;&#21521;&#37327;&#20540;&#20989;&#25968;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#28436;&#31034;&#20102;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#22312;&#32447;&#24191;&#21578;&#27963;&#21160;&#21644;&#21512;&#25104;&#24212;&#29992;&#20013;&#35813;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.06409</link><description>&lt;p&gt;
&#21151;&#33021;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Functional Causal Bayesian Optimization. (arXiv:2306.06409v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06409
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#21151;&#33021;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;fCBO&#65289;&#26041;&#27861;&#29992;&#20110;&#24050;&#30693;&#22240;&#26524;&#22270;&#20013;&#20248;&#21270;&#30446;&#26631;&#21464;&#37327;&#30340;&#24178;&#39044;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#25193;&#23637;&#20102;CBO&#26041;&#27861;&#26063;&#65292;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#23545;&#26410;&#30693;&#30446;&#26631;&#36827;&#34892;&#24314;&#27169;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23450;&#20041;&#36755;&#20837;&#24182;&#35745;&#31639;&#21521;&#37327;&#20540;&#20989;&#25968;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#28436;&#31034;&#20102;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#22312;&#32447;&#24191;&#21578;&#27963;&#21160;&#21644;&#21512;&#25104;&#24212;&#29992;&#20013;&#35813;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#21151;&#33021;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#8221;&#65288;fCBO&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23547;&#25214;&#22312;&#24050;&#30693;&#22240;&#26524;&#22270;&#20013;&#20248;&#21270;&#30446;&#26631;&#21464;&#37327;&#30340;&#24178;&#39044;&#26041;&#27861;&#12290;fCBO&#25193;&#23637;&#20102;CBO&#26041;&#27861;&#26063;&#65292;&#20197;&#23454;&#29616;&#21151;&#33021;&#24615;&#24178;&#39044;&#65292;&#21363;&#23558;&#21464;&#37327;&#35774;&#32622;&#20026;&#20854;&#20182;&#21464;&#37327;&#30340;&#30830;&#23450;&#24615;&#20989;&#25968;&#12290;fCBO&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#23545;&#26410;&#30693;&#30446;&#26631;&#36827;&#34892;&#24314;&#27169;&#65292;&#20854;&#36755;&#20837;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23450;&#20041;&#65292;&#20174;&#32780;&#21487;&#20197;&#35745;&#31639;&#21521;&#37327;&#20540;&#20989;&#25968;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#21453;&#36807;&#26469;&#65292;&#36825;&#20351;&#24471;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#21270;&#39044;&#26399;&#25913;&#36827;&#33719;&#21462;&#25910;&#36141;&#25910;&#30410;&#65292;&#21516;&#26102;&#20445;&#25345;&#26631;&#20934;BO&#35774;&#32622;&#30340;&#20856;&#22411;&#35745;&#31639;&#21487;&#34892;&#24615;&#65292;&#20197;&#20415;&#39034;&#24207;&#36873;&#25321;&#35201;&#25506;&#32034;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#22270;&#24418;&#26631;&#20934;&#65292;&#20197;&#30830;&#23450;&#32771;&#34385;&#21151;&#33021;&#24178;&#39044;&#26159;&#21542;&#20801;&#35768;&#23454;&#29616;&#26356;&#22909;&#30340;&#30446;&#26631;&#25928;&#26524;&#65292;&#24182;&#30830;&#23450;&#36873;&#25321;&#30340;&#24178;&#39044;&#26159;&#21542;&#20063;&#36866;&#29992;&#20110;&#26465;&#20214;&#30446;&#26631;&#25928;&#26524;&#30340;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#22312;&#32447;&#24191;&#21578;&#27963;&#21160;&#21644;&#21512;&#25104;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose functional causal Bayesian optimization (fCBO), a method for finding interventions that optimize a target variable in a known causal graph. fCBO extends the CBO family of methods to enable functional interventions, which set a variable to be a deterministic function of other variables in the graph. fCBO models the unknown objectives with Gaussian processes whose inputs are defined in a reproducing kernel Hilbert space, thus allowing to compute distances among vector-valued functions. In turn, this enables to sequentially select functions to explore by maximizing an expected improvement acquisition functional while keeping the typical computational tractability of standard BO settings. We introduce graphical criteria that establish when considering functional interventions allows attaining better target effects, and conditions under which selected interventions are also optimal for conditional target effects. We demonstrate the benefits of the method in a synthetic and in a r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#20010;&#24615;&#21270;&#22270;&#20687;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#23427;&#33021;&#22815;&#21327;&#21516;&#23398;&#20064;&#35774;&#22791;&#25110;&#38598;&#32676;&#29305;&#23450;&#30340;&#27169;&#22411;&#65292;&#20445;&#25252;&#27599;&#20010;&#35774;&#22791;&#30340;&#38544;&#31169;&#24182;&#25552;&#39640;&#23398;&#20064;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.06399</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#20010;&#24615;&#21270;&#22270;&#20687;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Personalized Graph Federated Learning with Differential Privacy. (arXiv:2306.06399v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#20010;&#24615;&#21270;&#22270;&#20687;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#23427;&#33021;&#22815;&#21327;&#21516;&#23398;&#20064;&#35774;&#22791;&#25110;&#38598;&#32676;&#29305;&#23450;&#30340;&#27169;&#22411;&#65292;&#20445;&#25252;&#27599;&#20010;&#35774;&#22791;&#30340;&#38544;&#31169;&#24182;&#25552;&#39640;&#23398;&#20064;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#22270;&#20687;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#20854;&#20013;&#20998;&#24067;&#24335;&#36830;&#25509;&#30340;&#26381;&#21153;&#22120;&#21644;&#23427;&#20204;&#21508;&#33258;&#30340;&#36793;&#32536;&#35774;&#22791;&#22312;&#20445;&#25345;&#27599;&#20010;&#21333;&#29420;&#35774;&#22791;&#38544;&#31169;&#30340;&#21516;&#26102;&#65292;&#21327;&#21516;&#23398;&#20064;&#35774;&#22791;&#25110;&#38598;&#32676;&#29305;&#23450;&#30340;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21516;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#20026;&#27599;&#20010;&#35774;&#22791;&#25552;&#20379;&#26356;&#30456;&#20851;&#30340;&#20307;&#39564;&#65292;&#21363;&#20351;&#22312;&#25968;&#25454;&#20998;&#24067;&#19981;&#22343;&#21644;&#25968;&#25454;&#38598;&#19981;&#25104;&#27604;&#20363;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#30830;&#20445;&#23433;&#20840;&#21644;&#39640;&#25928;&#30340;&#21327;&#20316;&#24335;&#20010;&#24615;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#21033;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;PGFL&#23454;&#29616;&#21464;&#20307;&#65292;&#20855;&#20307;&#32780;&#35328;&#23601;&#26159;&#20351;&#29992;&#20102;&#38646;&#32858;&#28966;&#24046;&#20998;&#38544;&#31169;&#65292;&#20854;&#20013;&#22122;&#22768;&#24207;&#21015;&#25200;&#21160;&#20102;&#27169;&#22411;&#20132;&#25442;&#12290;&#25105;&#20204;&#30340;&#25968;&#23398;&#20998;&#26512;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#20855;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;PGFL&#31639;&#27861;&#22312;&#32447;&#24615;&#26102;&#38388;&#20869;&#25910;&#25947;&#20110;&#27599;&#20010;&#31751;&#30340;&#26368;&#20248;&#31751;&#29305;&#23450;&#35299;&#12290;&#21516;&#26102;&#65292;&#21033;&#29992;&#31751;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#20063;&#33021;&#22815;&#23548;&#33268;&#21478;&#19968;&#31181;&#20248;&#31168;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a personalized graph federated learning (PGFL) framework in which distributedly connected servers and their respective edge devices collaboratively learn device or cluster-specific models while maintaining the privacy of every individual device. The proposed approach exploits similarities among different models to provide a more relevant experience for each device, even in situations with diverse data distributions and disproportionate datasets. Furthermore, to ensure a secure and efficient approach to collaborative personalized learning, we study a variant of the PGFL implementation that utilizes differential privacy, specifically zero-concentrated differential privacy, where a noise sequence perturbs model exchanges. Our mathematical analysis shows that the proposed privacy-preserving PGFL algorithm converges to the optimal cluster-specific solution for each cluster in linear time. It also shows that exploiting similarities among clusters leads to an alternative o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20195;&#25968;&#25299;&#25169;&#20013;&#30340;&#34920;&#31034;&#31283;&#23450;&#24615;&#65292;&#21487;&#20197;&#23450;&#20041;&#20986;&#19968;&#20010;&#21487;&#20197;&#20197;&#20219;&#24847;&#32500;&#24230;&#20026;&#36755;&#20837;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#29992;&#26041;&#20415;&#65292;&#21482;&#38656;&#25351;&#23450;&#32593;&#32476;&#26550;&#26500;&#21644;&#31561;&#21464;&#24615;&#30340;&#32452;&#65292;&#19988;&#22312;&#20219;&#20309;&#35757;&#32451;&#36807;&#31243;&#20013;&#37117;&#21487;&#20197;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.06327</link><description>&lt;p&gt;
&#20219;&#24847;&#32500;&#24230;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Any-dimensional equivariant neural networks. (arXiv:2306.06327v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06327
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20195;&#25968;&#25299;&#25169;&#20013;&#30340;&#34920;&#31034;&#31283;&#23450;&#24615;&#65292;&#21487;&#20197;&#23450;&#20041;&#20986;&#19968;&#20010;&#21487;&#20197;&#20197;&#20219;&#24847;&#32500;&#24230;&#20026;&#36755;&#20837;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#29992;&#26041;&#20415;&#65292;&#21482;&#38656;&#25351;&#23450;&#32593;&#32476;&#26550;&#26500;&#21644;&#31561;&#21464;&#24615;&#30340;&#32452;&#65292;&#19988;&#22312;&#20219;&#20309;&#35757;&#32451;&#36807;&#31243;&#20013;&#37117;&#21487;&#20197;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#30417;&#30563;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#23558;&#20989;&#25968;&#25311;&#21512;&#21040;&#19968;&#32452;&#20855;&#26377;&#22266;&#23450;&#32500;&#24230;&#30340;&#36755;&#20837;/&#36755;&#20986;&#23545;&#26469;&#23398;&#20064;&#26410;&#30693;&#26144;&#23556;&#12290;&#28982;&#21518;&#65292;&#22312;&#30456;&#21516;&#32500;&#24230;&#30340;&#36755;&#20837;&#19978;&#23450;&#20041;&#25311;&#21512;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#26410;&#30693;&#26144;&#23556;&#20197;&#20219;&#24847;&#32500;&#24230;&#30340;&#36755;&#20837;&#20316;&#20026;&#36755;&#20837;&#65307;&#20363;&#22914;&#65292;&#23450;&#20041;&#22312;&#20219;&#24847;&#22823;&#23567;&#30340;&#22270;&#24418;&#19978;&#30340;&#22270;&#24418;&#21442;&#25968;&#21644;&#23450;&#20041;&#22312;&#20219;&#24847;&#25968;&#37327;&#31890;&#23376;&#19978;&#30340;&#29289;&#29702;&#37327;&#12290;&#25105;&#20204;&#21033;&#29992;&#20195;&#25968;&#25299;&#25169;&#20013;&#30340;&#26032;&#29616;&#35937;&#8212;&#8212;&#34920;&#31034;&#31283;&#23450;&#24615;&#65292;&#26469;&#23450;&#20041;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#20351;&#29992;&#22266;&#23450;&#32500;&#24230;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#25193;&#23637;&#25509;&#21463;&#36755;&#20837;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#20351;&#29992;&#65292;&#21482;&#38656;&#35201;&#32593;&#32476;&#26550;&#26500;&#21644;&#31561;&#21464;&#24615;&#30340;&#32452;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#20219;&#20309;&#35757;&#32451;&#36807;&#31243;&#32467;&#21512;&#20351;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#31616;&#21333;&#24320;&#28304;&#23454;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#21021;&#27493;&#30340;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20197;&#32852;&#37030;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#24046;&#20998;&#38544;&#31169;&#20999;&#29255;&#36870;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#21327;&#20316;&#20272;&#35745;&#36275;&#22815;&#32500;&#25968;&#30340;&#38477;&#32500;&#23376;&#31354;&#38388;&#20197;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;&#19981;&#34987;&#26292;&#38706;&#65292;&#21516;&#26102;&#37319;&#29992;&#22810;&#31181;&#25200;&#21160;&#31574;&#30053;&#20445;&#38556;&#24046;&#20998;&#38544;&#31169;&#65292;&#36824;&#33021;&#33258;&#28982;&#22320;&#32467;&#21512;&#21327;&#20316;&#21464;&#37327;&#31579;&#36873;&#27493;&#39588;&#20197;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2306.06324</link><description>&lt;p&gt;
&#20197;&#32852;&#37030;&#23398;&#20064;&#33539;&#24335;&#20026;&#22522;&#30784;&#30340;&#24046;&#20998;&#38544;&#31169;&#20999;&#29255;&#36870;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Differentially private sliced inverse regression in the federated paradigm. (arXiv:2306.06324v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06324
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20197;&#32852;&#37030;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#24046;&#20998;&#38544;&#31169;&#20999;&#29255;&#36870;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#21327;&#20316;&#20272;&#35745;&#36275;&#22815;&#32500;&#25968;&#30340;&#38477;&#32500;&#23376;&#31354;&#38388;&#20197;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;&#19981;&#34987;&#26292;&#38706;&#65292;&#21516;&#26102;&#37319;&#29992;&#22810;&#31181;&#25200;&#21160;&#31574;&#30053;&#20445;&#38556;&#24046;&#20998;&#38544;&#31169;&#65292;&#36824;&#33021;&#33258;&#28982;&#22320;&#32467;&#21512;&#21327;&#20316;&#21464;&#37327;&#31579;&#36873;&#27493;&#39588;&#20197;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#24191;&#21463;&#27426;&#36814;&#30340;&#20999;&#29255;&#36870;&#22238;&#24402;&#25193;&#23637;&#21040;&#21435;&#35299;&#20915;&#20998;&#25955;&#24335;&#25968;&#25454;&#12289;&#20248;&#20808;&#20445;&#25252;&#38544;&#31169;&#21644;&#36890;&#20449;&#25928;&#29575;&#31561;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#34987;&#31216;&#20026;&#32852;&#37030;&#20999;&#29255;&#36870;&#22238;&#24402;&#65288;FSIR&#65289;&#65292;&#20415;&#20110;&#22810;&#20010;&#23458;&#25143;&#31471;&#20043;&#38388;&#21327;&#20316;&#20272;&#35745;&#36275;&#22815;&#32500;&#25968;&#30340;&#38477;&#32500;&#23376;&#31354;&#38388;&#65292;&#21482;&#20849;&#20139;&#26412;&#22320;&#20272;&#35745;&#65292;&#20197;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;&#19981;&#34987;&#26292;&#38706;&#12290;&#20026;&#20102;&#38450;&#33539;&#28508;&#22312;&#30340;&#25915;&#20987;&#65292;FSIR&#36824;&#37319;&#29992;&#20102;&#22810;&#31181;&#25200;&#21160;&#31574;&#30053;&#65292;&#21253;&#25324;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20803;&#39640;&#26031;&#26426;&#21046;&#65292;&#20197;&#20302;&#25104;&#26412;&#30340;&#32479;&#35745;&#31934;&#24230;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;&#12290;&#27492;&#22806;&#65292;FSIR&#33258;&#28982;&#22320;&#32467;&#21512;&#20102;&#21327;&#20316;&#21464;&#37327;&#31579;&#36873;&#27493;&#39588;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#23458;&#25143;&#31471;&#25968;&#25454;&#12290;FSIR&#30340;&#29702;&#35770;&#24615;&#36136;&#22312;&#20302;&#32500;&#21644;&#39640;&#32500;&#35774;&#32622;&#20013;&#24471;&#21040;&#20102;&#35777;&#23454;&#65292;&#24182;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#25968;&#23383;&#23454;&#39564;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend the celebrated sliced inverse regression to address the challenges of decentralized data, prioritizing privacy and communication efficiency. Our approach, federated sliced inverse regression (FSIR), facilitates collaborative estimation of the sufficient dimension reduction subspace among multiple clients, solely sharing local estimates to protect sensitive datasets from exposure. To guard against potential adversary attacks, FSIR further employs diverse perturbation strategies, including a novel multivariate Gaussian mechanism that guarantees differential privacy at a low cost of statistical accuracy. Additionally, FSIR naturally incorporates a collaborative variable screening step, enabling effective handling of high-dimensional client data. Theoretical properties of FSIR are established for both low-dimensional and high-dimensional settings, supported by extensive numerical experiments and real data analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;MOLAR&#65292;&#23427;&#21033;&#29992;&#21327;&#21516;&#32447;&#24615;&#22238;&#24402;&#21644;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#20013;&#30340;&#31232;&#30095;&#24322;&#36136;&#24615;&#26469;&#25552;&#39640;&#20272;&#35745;&#31934;&#24230;&#65292;&#24182;&#19988;&#30456;&#27604;&#29420;&#31435;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.06291</link><description>&lt;p&gt;
&#26368;&#20248;&#24322;&#26500;&#21327;&#21516;&#32447;&#24615;&#22238;&#24402;&#21644;&#19978;&#19979;&#25991;&#33218;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Optimal Heterogeneous Collaborative Linear Regression and Contextual Bandits. (arXiv:2306.06291v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06291
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;MOLAR&#65292;&#23427;&#21033;&#29992;&#21327;&#21516;&#32447;&#24615;&#22238;&#24402;&#21644;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#20013;&#30340;&#31232;&#30095;&#24322;&#36136;&#24615;&#26469;&#25552;&#39640;&#20272;&#35745;&#31934;&#24230;&#65292;&#24182;&#19988;&#30456;&#27604;&#29420;&#31435;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#21644;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#24448;&#24448;&#26469;&#33258;&#20110;&#20960;&#20010;&#21487;&#33021;&#26159;&#24322;&#26500;&#30340;&#26469;&#28304;&#12290;&#21327;&#21516;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#20849;&#24615;&#25552;&#39640;&#25928;&#29575;&#65292;&#21516;&#26102;&#32771;&#34385;&#21487;&#33021;&#20986;&#29616;&#30340;&#24046;&#24322;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#21327;&#21516;&#32447;&#24615;&#22238;&#24402;&#21644;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#23454;&#20363;&#30340;&#30456;&#20851;&#21442;&#25968;&#31561;&#20110;&#20840;&#23616;&#21442;&#25968;&#21152;&#19978;&#19968;&#20010;&#31232;&#30095;&#30340;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MOLAR&#30340;&#26032;&#22411;&#20108;&#38454;&#27573;&#20272;&#35745;&#22120;&#65292;&#23427;&#36890;&#36807;&#39318;&#20808;&#26500;&#24314;&#23454;&#20363;&#32447;&#24615;&#22238;&#24402;&#20272;&#35745;&#30340;&#36880;&#39033;&#20013;&#20301;&#25968;&#65292;&#28982;&#21518;&#23558;&#23454;&#20363;&#29305;&#23450;&#20272;&#35745;&#20540;&#25910;&#32553;&#21040;&#20013;&#20301;&#25968;&#38468;&#36817;&#26469;&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#12290;&#19982;&#29420;&#31435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30456;&#27604;&#65292;MOLAR&#25552;&#39640;&#20102;&#20272;&#35745;&#35823;&#24046;&#23545;&#25968;&#25454;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;MOLAR&#24212;&#29992;&#20110;&#24320;&#21457;&#29992;&#20110;&#31232;&#30095;&#24322;&#26500;&#21327;&#21516;&#19978;&#19979;&#25991;&#33218;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#30456;&#27604;&#29420;&#31435;&#33218;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#36129;&#29486;&#20248;&#20110;&#20808;&#21069;&#22312;&#25991;&#29486;&#20013;&#25253;&#36947;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large and complex datasets are often collected from several, possibly heterogeneous sources. Collaborative learning methods improve efficiency by leveraging commonalities across datasets while accounting for possible differences among them. Here we study collaborative linear regression and contextual bandits, where each instance's associated parameters are equal to a global parameter plus a sparse instance-specific term. We propose a novel two-stage estimator called MOLAR that leverages this structure by first constructing an entry-wise median of the instances' linear regression estimates, and then shrinking the instance-specific estimates towards the median. MOLAR improves the dependence of the estimation error on the data dimension, compared to independent least squares estimates. We then apply MOLAR to develop methods for sparsely heterogeneous collaborative contextual bandits, which lead to improved regret guarantees compared to independent bandit methods. We further show that our 
&lt;/p&gt;</description></item><item><title>&#33021;&#37327;&#32791;&#25955;&#36827;&#21270;&#28145;&#24230;&#31639;&#23376;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#36816;&#31639;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20026;&#19968;&#31867;&#20559;&#24494;&#20998;&#26041;&#31243;&#25552;&#20379;&#25968;&#20540;&#35299;&#24182;&#20445;&#30041;&#20854;&#29289;&#29702;&#29305;&#24615;&#65292;&#36890;&#36807;&#25903;&#36335;&#32593;&#32476;&#32534;&#30721;&#19981;&#21516;&#30340;&#36755;&#20837;&#20989;&#25968;&#65292;&#24178;&#32447;&#32593;&#32476;&#35780;&#20272;&#36755;&#20986;&#20989;&#25968;&#65292;&#32463;&#36807;&#35757;&#32451;&#21487;&#29983;&#25104;&#36816;&#31639;&#31526;&#36817;&#20284;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.06281</link><description>&lt;p&gt;
&#33021;&#37327;&#32791;&#25955;&#36827;&#21270;&#28145;&#24230;&#31639;&#23376;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Energy-Dissipative Evolutionary Deep Operator Neural Networks. (arXiv:2306.06281v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06281
&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#32791;&#25955;&#36827;&#21270;&#28145;&#24230;&#31639;&#23376;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#36816;&#31639;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20026;&#19968;&#31867;&#20559;&#24494;&#20998;&#26041;&#31243;&#25552;&#20379;&#25968;&#20540;&#35299;&#24182;&#20445;&#30041;&#20854;&#29289;&#29702;&#29305;&#24615;&#65292;&#36890;&#36807;&#25903;&#36335;&#32593;&#32476;&#32534;&#30721;&#19981;&#21516;&#30340;&#36755;&#20837;&#20989;&#25968;&#65292;&#24178;&#32447;&#32593;&#32476;&#35780;&#20272;&#36755;&#20986;&#20989;&#25968;&#65292;&#32463;&#36807;&#35757;&#32451;&#21487;&#29983;&#25104;&#36816;&#31639;&#31526;&#36817;&#20284;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#32791;&#25955;&#36827;&#21270;&#28145;&#24230;&#31639;&#23376;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#36816;&#31639;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#65292;&#26088;&#22312;&#20026;&#19968;&#31867;&#20559;&#24494;&#20998;&#26041;&#31243;&#31181;&#23376;&#25552;&#20379;&#25968;&#20540;&#35299;&#65292;&#32780;&#19981;&#26159;&#21333;&#20010;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#20363;&#22914;&#24102;&#26377;&#19981;&#21516;&#21442;&#25968;&#25110;&#19981;&#21516;&#21021;&#22987;&#26465;&#20214;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#32593;&#32476;&#30001;&#20004;&#20010;&#23376;&#32593;&#32476;&#32452;&#25104;&#65306;&#25903;&#36335;&#32593;&#32476;&#21644;&#24178;&#32447;&#32593;&#32476;&#12290;&#23545;&#20110;&#30446;&#26631;&#36816;&#31639;&#31526; G&#65292;&#25903;&#36335;&#32593;&#32476;&#22312;&#30456;&#21516;&#25968;&#37327;&#30340;&#20256;&#24863;&#22120;&#19978;&#32534;&#30721;&#19981;&#21516;&#30340;&#36755;&#20837;&#20989;&#25968; u&#65292;&#32780;&#24178;&#32447;&#32593;&#32476;&#35780;&#20272;&#20219;&#20309;&#20301;&#32622;&#30340;&#36755;&#20986;&#20989;&#25968;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;&#35780;&#20272;&#30340;&#36755;&#20986; q &#21644;&#39044;&#26399;&#36755;&#20986; G(u)(y) &#20043;&#38388;&#30340;&#35823;&#24046;&#65292;DeepONet &#29983;&#25104; G &#36816;&#31639;&#31526;&#30340;&#33391;&#22909;&#36817;&#20284;&#12290;&#20026;&#20102;&#20445;&#30041;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#37325;&#35201;&#29289;&#29702;&#29305;&#24615;&#65292;&#22914;&#33021;&#37327;&#32791;&#25955;&#23450;&#24459;&#65292;&#25105;&#20204;&#37319;&#29992;&#26631;&#37327;&#36741;&#21161;&#21464;&#37327;&#27861;&#29983;&#25104;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#23427;&#24341;&#20837;&#20102;&#20462;&#25913;&#21518;&#30340;&#33021;&#37327;&#24182;&#23454;&#29616;&#20102;&#26080;&#26465;&#20214;&#30340;&#33021;&#37327;&#32791;&#25955;&#23450;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Dissipative Evolutionary Deep Operator Neural Network is an operator learning neural network. It is designed to seed numerical solutions for a class of partial differential equations instead of a single partial differential equation, such as partial differential equations with different parameters or different initial conditions. The network consists of two sub-networks, the Branch net and the Trunk net. For an objective operator G, the Branch net encodes different input functions u at the same number of sensors, and the Trunk net evaluates the output function at any location. By minimizing the error between the evaluated output q and the expected output G(u)(y), DeepONet generates a good approximation of the operator G. In order to preserve essential physical properties of PDEs, such as the Energy Dissipation Law, we adopt a scalar auxiliary variable approach to generate the minimization problem. It introduces a modified energy and enables unconditional energy dissipation law a
&lt;/p&gt;</description></item><item><title>A/B&#27979;&#35797;&#30340;&#23567;&#26679;&#26412;&#21644;&#22788;&#29702;&#25928;&#26524;&#36807;&#23567;&#23548;&#33268;&#25928;&#24212;&#20272;&#35745;&#36807;&#20110;&#19981;&#31934;&#23494;&#65292;&#26412;&#30740;&#31350;&#21033;&#29992;&#21382;&#21490;&#29992;&#25143;&#30340;&#20016;&#23500;&#26085;&#24535;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#25552;&#39640;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;A/B&#27979;&#35797;&#30340;&#33021;&#21147;&#21644;&#32479;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.06273</link><description>&lt;p&gt;
&#21033;&#29992;&#36741;&#21161;&#25968;&#25454;&#25552;&#39640;&#22312;&#32447;&#25945;&#32946;&#24179;&#21488;A/B&#27979;&#35797;&#20998;&#26512;&#30340;&#31934;&#24230;&#65306;&#26032;&#25968;&#25454;&#21644;&#26032;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Using Auxiliary Data to Boost Precision in the Analysis of A/B Tests on an Online Educational Platform: New Data and New Results. (arXiv:2306.06273v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06273
&lt;/p&gt;
&lt;p&gt;
A/B&#27979;&#35797;&#30340;&#23567;&#26679;&#26412;&#21644;&#22788;&#29702;&#25928;&#26524;&#36807;&#23567;&#23548;&#33268;&#25928;&#24212;&#20272;&#35745;&#36807;&#20110;&#19981;&#31934;&#23494;&#65292;&#26412;&#30740;&#31350;&#21033;&#29992;&#21382;&#21490;&#29992;&#25143;&#30340;&#20016;&#23500;&#26085;&#24535;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#25552;&#39640;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;A/B&#27979;&#35797;&#30340;&#33021;&#21147;&#21644;&#32479;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#24179;&#21488;&#19978;&#30340;&#38543;&#26426;A/B&#27979;&#35797;&#20195;&#34920;&#30528;&#23398;&#20064;&#31185;&#23398;&#20013;&#19968;&#20010;&#28608;&#21160;&#20154;&#24515;&#30340;&#26041;&#21521;&#12290;&#20182;&#20204;&#20960;&#20046;&#27809;&#26377;&#20219;&#20309;&#20551;&#35774;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#28151;&#26434;&#20559;&#24046;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#21644;&#31934;&#30830;&#30340;&#32479;&#35745;&#25512;&#26029;&#21363;&#20351;&#22312;&#23567;&#26679;&#26412;&#19979;&#12290;&#28982;&#32780;&#65292;&#32463;&#24120;&#30001;&#20110;&#23454;&#39564;&#26679;&#26412;&#21644;/&#25110;&#22788;&#29702;&#25928;&#26524;&#36807;&#23567;&#65292;A/B&#27979;&#35797;&#32570;&#20047;&#21160;&#21147;&#65292;&#25928;&#24212;&#20272;&#35745;&#36807;&#20110;&#19981;&#31934;&#23494;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#35770;&#36827;&#23637;&#34920;&#26126;&#65292;&#36890;&#36807;&#23558;&#22522;&#20110;&#35774;&#35745;&#30340;&#22240;&#26524;&#20272;&#35745;&#19982;&#21382;&#21490;&#29992;&#25143;&#30340;&#20016;&#23500;&#26085;&#24535;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#23454;&#29616;&#22823;&#24133;&#25552;&#39640;&#33021;&#21147;&#21644;&#32479;&#35745;&#31934;&#24230;&#12290;&#21363;&#20351;&#27809;&#26377;&#20219;&#20309;&#20854;&#20182;&#20551;&#35774;&#65292;&#20351;&#29992;&#36825;&#20123;&#25216;&#26415;&#24471;&#20986;&#30340;&#20272;&#35745;&#20173;&#28982;&#20445;&#25345;&#19981;&#20559;&#65292;&#25512;&#26029;&#20173;&#28982;&#31934;&#30830;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#36825;&#20123;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#21253;&#25324;&#22312;&#22312;&#32447;&#23398;&#20064;&#24179;&#21488;ASSISTments&#20869;&#36827;&#34892;&#30340;250&#22810;&#20010;&#38543;&#26426;A/B&#27604;&#36739;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#20351;&#29992;&#22235;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#27604;&#36739;&#19981;&#21516;&#23454;&#39564;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized A/B tests within online learning platforms represent an exciting direction in learning sciences. With minimal assumptions, they allow causal effect estimation without confounding bias and exact statistical inference even in small samples. However, often experimental samples and/or treatment effects are small, A/B tests are underpowered, and effect estimates are overly imprecise. Recent methodological advances have shown that power and statistical precision can be substantially boosted by coupling design-based causal estimation to machine-learning models of rich log data from historical users who were not in the experiment. Estimates using these techniques remain unbiased and inference remains exact without any additional assumptions. This paper reviews those methods and applies them to a new dataset including over 250 randomized A/B comparisons conducted within ASSISTments, an online learning platform. We compare results across experiments using four novel deep-learning mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#23454;&#29616;&#20445;&#23432;&#25506;&#32034;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21517;&#20026;StepMix&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#29616;&#26377;&#30340;&#23433;&#20840;&#22522;&#32447;&#31574;&#30053;&#24179;&#34913;&#24320;&#21457;&#21644;&#25506;&#32034;&#65292;&#21516;&#26102;&#20445;&#35777;&#27599;&#20010;&#22238;&#21512;&#19981;&#36829;&#21453;&#20445;&#23432;&#38480;&#21046;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#19981;&#21463;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#21518;&#24724;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2306.06265</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#22522;&#20110;&#22238;&#21512;&#38480;&#21046;&#30340;&#36817;&#20248;&#20445;&#23432;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Near-optimal Conservative Exploration in Reinforcement Learning under Episode-wise Constraints. (arXiv:2306.06265v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06265
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#23454;&#29616;&#20445;&#23432;&#25506;&#32034;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21517;&#20026;StepMix&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#29616;&#26377;&#30340;&#23433;&#20840;&#22522;&#32447;&#31574;&#30053;&#24179;&#34913;&#24320;&#21457;&#21644;&#25506;&#32034;&#65292;&#21516;&#26102;&#20445;&#35777;&#27599;&#20010;&#22238;&#21512;&#19981;&#36829;&#21453;&#20445;&#23432;&#38480;&#21046;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#19981;&#21463;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#21518;&#24724;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#23454;&#29616;&#20445;&#23432;&#25506;&#32034;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#23398;&#20064;&#20195;&#29702;&#30340;&#24615;&#33021;&#22312;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20013;&#20445;&#35777;&#39640;&#20110;&#26576;&#20010;&#29305;&#23450;&#38408;&#20540;&#12290;&#30740;&#31350;&#38024;&#23545;&#26377;&#38480;&#29366;&#24577;&#21644;&#21160;&#20316;&#30340;&#26631;&#31614;&#24335;&#22238;&#21512;&#24335;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#29615;&#22659;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;StepMix&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#29616;&#26377;&#30340;&#23433;&#20840;&#22522;&#32447;&#31574;&#30053;&#22312;&#20445;&#35777;&#27599;&#20010;&#22238;&#21512;&#19981;&#36829;&#21453;&#20445;&#23432;&#38480;&#21046;&#30340;&#21069;&#25552;&#19979;&#65292;&#24179;&#34913;&#24320;&#21457;&#21644;&#25506;&#32034;&#12290;StepMix&#20855;&#26377;&#29420;&#29305;&#30340;&#28151;&#21512;&#31574;&#30053;&#35774;&#35745;&#65292;&#33258;&#36866;&#24212;&#22320;&#12289;&#24179;&#28369;&#22320;&#25554;&#20540;&#22522;&#32447;&#31574;&#30053;&#21644;&#20048;&#35266;&#31574;&#30053;&#20043;&#38388;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;StepMix&#22312;&#19981;&#21463;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#30340;&#21518;&#24724;&#37327;&#32423;&#65292;&#35828;&#26126;&#36981;&#23432;&#20005;&#26684;&#30340;&#22238;&#21512;&#38480;&#21046;&#19981;&#20250;&#25439;&#23475;&#23398;&#20064;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#38543;&#26426;&#21270;&#30340;EpsMix&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates conservative exploration in reinforcement learning where the performance of the learning agent is guaranteed to be above a certain threshold throughout the learning process. It focuses on the tabular episodic Markov Decision Process (MDP) setting that has finite states and actions. With the knowledge of an existing safe baseline policy, an algorithm termed as StepMix is proposed to balance the exploitation and exploration while ensuring that the conservative constraint is never violated in each episode with high probability. StepMix features a unique design of a mixture policy that adaptively and smoothly interpolates between the baseline policy and the optimistic policy. Theoretical analysis shows that StepMix achieves near-optimal regret order as in the constraint-free setting, indicating that obeying the stringent episode-wise conservative constraint does not compromise the learning performance. Besides, a randomization-based EpsMix algorithm is also proposed
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30028;&#23450;&#20102;Poisson loss&#21644;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#20004;&#31181;&#24352;&#37327;&#34917;&#20840;&#26041;&#27861;&#30340;&#35299;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#25552;&#20379;&#20102;&#26356;&#32039;&#30340;&#30028;&#38480;&#65292;&#38024;&#23545;$r$&#30340;&#20381;&#36182;&#24615;&#20174;&#20043;&#21069;&#30340;$r^{2(t-1)(t^2-t-1)}$&#25913;&#36827;&#20026;$r^{2(t-1)(3t-5)}$&#12290;&#26681;&#25454;&#37319;&#26679;&#31232;&#30095;&#27169;&#24335;&#30340;&#35889;&#38388;&#38548;&#25511;&#21046;&#35823;&#24046;&#30028;&#38480;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#21407;&#23376;&#24352;&#37327;&#33539;&#25968;&#30340;&#20960;&#20010;&#26032;&#23646;&#24615;&#65292;&#20294;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#23384;&#22312;&#35745;&#31639;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.06262</link><description>&lt;p&gt;
&#22522;&#20110;&#35889;&#38388;&#38548;&#30340;&#30830;&#23450;&#24615;&#24352;&#37327;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Spectral gap-based deterministic tensor completion. (arXiv:2306.06262v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30028;&#23450;&#20102;Poisson loss&#21644;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#20004;&#31181;&#24352;&#37327;&#34917;&#20840;&#26041;&#27861;&#30340;&#35299;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#25552;&#20379;&#20102;&#26356;&#32039;&#30340;&#30028;&#38480;&#65292;&#38024;&#23545;$r$&#30340;&#20381;&#36182;&#24615;&#20174;&#20043;&#21069;&#30340;$r^{2(t-1)(t^2-t-1)}$&#25913;&#36827;&#20026;$r^{2(t-1)(3t-5)}$&#12290;&#26681;&#25454;&#37319;&#26679;&#31232;&#30095;&#27169;&#24335;&#30340;&#35889;&#38388;&#38548;&#25511;&#21046;&#35823;&#24046;&#30028;&#38480;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#21407;&#23376;&#24352;&#37327;&#33539;&#25968;&#30340;&#20960;&#20010;&#26032;&#23646;&#24615;&#65292;&#20294;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#23384;&#22312;&#35745;&#31639;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#34917;&#20840;&#26159;&#19968;&#20010;&#26680;&#24515;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#21644;&#20854;&#20182;&#24102;&#26377;&#32570;&#22833;&#25968;&#25454;&#30340;&#39046;&#22495;&#12290;&#34429;&#28982;&#23545;&#20110;&#30697;&#38453;&#24773;&#20917;&#24050;&#26377;&#28145;&#20837;&#30740;&#31350;&#65292;&#20294;&#38024;&#23545;&#24352;&#37327;&#38382;&#39064;&#30340;&#29702;&#35770;&#32467;&#26524;&#20173;&#28982;&#26377;&#38480;&#65292;&#29305;&#21035;&#26159;&#24403;&#37319;&#26679;&#27169;&#24335;&#26159;&#30830;&#23450;&#24615;&#30340;&#26102;&#20505;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#20004;&#31181;&#24352;&#37327;&#34917;&#20840;&#26041;&#27861;&#30340;&#35299;&#30340;&#27867;&#21270;&#35823;&#24046;&#36827;&#34892;&#20102;&#30028;&#23450;&#65292;&#20998;&#21035;&#26159;Poisson loss&#21644;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#65292;&#29992;&#30446;&#26631;&#24352;&#37327;&#31209;&#20316;&#20026;&#21028;&#26029;&#20381;&#25454;&#65292;&#25552;&#20379;&#20102;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;&#22914;&#26524;&#30446;&#26631;&#24352;&#37327;&#30340;&#38454;&#25968;&#20026;$t$&#65292;CP&#31209;&#20026;$r$&#65292;&#21017;&#25105;&#20204;&#30340;&#30028;&#38480;&#20013;&#38024;&#23545;$r$&#30340;&#20381;&#36182;&#24615;&#20174;arXiv:1910.10692&#30340;$r^{2(t-1)(t^2-t-1)}$&#25913;&#36827;&#20026;$r^{2(t-1)(3t-5)}$&#12290;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#26159;&#30001;&#37319;&#26679;&#31232;&#30095;&#27169;&#24335;&#30340;&#35889;&#38388;&#38548;&#20915;&#23450;&#30340;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#21407;&#23376;&#24352;&#37327;&#33539;&#25968;&#30340;&#20960;&#20010;&#26032;&#23646;&#24615;&#65292;&#22312;&#38543;&#26426;&#37319;&#26679;&#26041;&#26696;&#19979;&#23558;&#31209;&#30340;&#20381;&#36182;&#24615;&#20174;arXiv:1711.04965&#30340;$r^{3t-3}$&#20943;&#23569;&#21040;$r^{3t-5}$&#12290;&#28982;&#32780;&#65292;&#21407;&#23376;&#33539;&#25968;&#26368;&#23567;&#21270;&#30340;&#19968;&#20010;&#23616;&#38480;&#24615;&#26159;&#65292;&#34429;&#28982;&#22312;&#29702;&#35770;&#19978;&#24456;&#26377;&#36259;&#65292;&#20294;&#20250;&#23548;&#33268;&#35745;&#31639;&#19978;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor completion is a core machine learning algorithm used in recommender systems and other domains with missing data. While the matrix case is well-understood, theoretical results for tensor problems are limited, particularly when the sampling patterns are deterministic. Here we bound the generalization error of the solutions of two tensor completion methods, Poisson loss and atomic norm minimization, providing tighter bounds in terms of the target tensor rank. If the ground-truth tensor is order $t$ with CP-rank $r$, the dependence on $r$ is improved from $r^{2(t-1)(t^2-t-1)}$ in arXiv:1910.10692 to $r^{2(t-1)(3t-5)}$. The error in our bounds is deterministically controlled by the spectral gap of the sampling sparsity pattern. We also prove several new properties for the atomic tensor norm, reducing the rank dependence from $r^{3t-3}$ in arXiv:1711.04965 to $r^{3t-5}$ under random sampling schemes. A limitation is that atomic norm minimization, while theoretically interesting, leads
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22522;&#20110;&#25490;&#21015;&#30340;&#20551;&#35774;&#26816;&#39564;&#65292;&#25552;&#20986;&#20102;&#25345;&#20037;&#22270;&#21521;&#37327;&#25688;&#35201;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.06257</link><description>&lt;p&gt;
&#22522;&#20110;&#25490;&#21015;&#30340;&#20551;&#35774;&#26816;&#39564;&#30340;&#25345;&#20037;&#22270;&#21521;&#37327;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
Vector Summaries of Persistence Diagrams for Permutation-based Hypothesis Testing. (arXiv:2306.06257v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06257
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22522;&#20110;&#25490;&#21015;&#30340;&#20551;&#35774;&#26816;&#39564;&#65292;&#25552;&#20986;&#20102;&#25345;&#20037;&#22270;&#21521;&#37327;&#25688;&#35201;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#25216;&#26415;&#65288;TDA&#65289;&#24050;&#32463;&#25104;&#20026;&#25551;&#36848;&#25968;&#25454;&#24418;&#29366;&#30340;&#37325;&#35201;&#26041;&#27861;&#12290;&#36817;&#24180;&#26469;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#24320;&#22987;&#20851;&#27880;&#24320;&#21457;&#32479;&#35745;&#23398;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;TDA&#30340;&#20551;&#35774;&#26816;&#39564;&#31243;&#24207;&#12290;&#22312;&#32479;&#35745;&#23398;&#35282;&#24230;&#19979;&#65292;&#25345;&#20037;&#22270;&#26159;&#30001;TDA&#25552;&#20379;&#30340;&#25968;&#25454;&#30340;&#20013;&#24515;&#22810;&#23610;&#24230;&#25299;&#25169;&#25551;&#36848;&#31526;&#65292;&#34987;&#35270;&#20026;&#20174;&#26576;&#20010;&#20154;&#32676;&#25110;&#36807;&#31243;&#20013;&#38543;&#26426;&#25277;&#26679;&#30340;&#35266;&#23519;&#20540;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#26089;&#20851;&#20110;&#20551;&#35774;&#26816;&#39564;&#30340;&#24037;&#20316;&#20043;&#19968;&#20415;&#26159;&#19987;&#27880;&#20110;&#20004;&#32452;&#25490;&#21015;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#36890;&#36807;&#32452;&#20869;&#20004;&#20004;&#29942;&#39048;&#25110;Wasserstein&#36317;&#31163;&#26469;&#23450;&#20041;&#30340;(Robinson&#21644;Turner&#65292;2017)&#12290;&#28982;&#32780;&#65292;&#22312;&#25345;&#20037;&#22270;&#25968;&#37327;&#24222;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;&#35201;&#24212;&#29992;&#20110;&#25152;&#32771;&#34385;&#38382;&#39064;&#30340;&#25490;&#21015;&#27979;&#35797;&#35745;&#31639;&#25104;&#26412;&#23558;&#21464;&#24471;&#26356;&#39640;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#32771;&#34385;&#25345;&#20037;&#22270;&#20043;&#38388;&#30340;&#25104;&#23545;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past decade, the techniques of topological data analysis (TDA) have grown into prominence to describe the shape of data. In recent years, there has been increasing interest in developing statistical methods and in particular hypothesis testing procedures for TDA. Under the statistical perspective, persistence diagrams -- the central multi-scale topological descriptors of data provided by TDA -- are viewed as random observations sampled from some population or process. In this context, one of the earliest works on hypothesis testing focuses on the two-group permutation-based approach where the associated loss function is defined in terms of within-group pairwise bottleneck or Wasserstein distances between persistence diagrams (Robinson and Turner, 2017). However, in situations where persistence diagrams are large in size and number, the permutation test in question gets computationally more costly to apply. To address this limitation, we instead consider pairwise distances betw
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#24449;&#32534;&#31243;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26694;&#26550;&#65292;&#33021;&#22815;&#29983;&#25104;&#22823;&#37327;&#39044;&#27979;&#29305;&#24449;&#65292;&#21516;&#26102;&#20801;&#35768;&#29992;&#25143;&#20197;&#26368;&#23567;&#30340;&#24037;&#20316;&#37327;&#32467;&#21512;&#20182;&#20204;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#32454;&#31890;&#24230;&#30340;&#36712;&#36857;&#22686;&#37327;&#65292;&#24341;&#20837;&#20102;&#26032;&#22411;&#33258;&#26059;&#27668;&#20307;&#21160;&#21147;&#23398;&#20234;&#36763;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#32422;&#30340;&#31639;&#23376;&#38598;&#26469;&#24635;&#32467;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#12290;</title><link>http://arxiv.org/abs/2306.06252</link><description>&lt;p&gt;
&#22522;&#20110;&#29305;&#24449;&#32534;&#31243;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Feature Programming for Multivariate Time Series Prediction. (arXiv:2306.06252v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06252
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#24449;&#32534;&#31243;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26694;&#26550;&#65292;&#33021;&#22815;&#29983;&#25104;&#22823;&#37327;&#39044;&#27979;&#29305;&#24449;&#65292;&#21516;&#26102;&#20801;&#35768;&#29992;&#25143;&#20197;&#26368;&#23567;&#30340;&#24037;&#20316;&#37327;&#32467;&#21512;&#20182;&#20204;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#32454;&#31890;&#24230;&#30340;&#36712;&#36857;&#22686;&#37327;&#65292;&#24341;&#20837;&#20102;&#26032;&#22411;&#33258;&#26059;&#27668;&#20307;&#21160;&#21147;&#23398;&#20234;&#36763;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#32422;&#30340;&#31639;&#23376;&#38598;&#26469;&#24635;&#32467;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#21487;&#32534;&#31243;&#29305;&#24449;&#24037;&#31243;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#29305;&#24449;&#32534;&#31243;&#26694;&#26550;&#65292;&#20026;&#22024;&#26434;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#22823;&#37327;&#39044;&#27979;&#29305;&#24449;&#65292;&#21516;&#26102;&#20801;&#35768;&#29992;&#25143;&#20197;&#26368;&#23567;&#30340;&#24037;&#20316;&#37327;&#32467;&#21512;&#20182;&#20204;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#20851;&#38190;&#21160;&#26426;&#26159;&#23558;&#20219;&#20309;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#35270;&#20026;&#32454;&#31890;&#24230;&#36712;&#36857;&#22686;&#37327;&#30340;&#32047;&#31215;&#24635;&#21644;&#65292;&#20854;&#20013;&#27599;&#20010;&#22686;&#37327;&#30001;&#19968;&#31181;&#26032;&#22411;&#33258;&#26059;&#27668;&#20307;&#21160;&#21147;&#23398;&#20234;&#36763;&#27169;&#22411;&#25511;&#21046;&#12290;&#36825;&#31181;&#32454;&#31890;&#24230;&#30340;&#35270;&#35282;&#28608;&#21457;&#20102;&#21457;&#23637;&#19968;&#20010;&#31616;&#32422;&#30340;&#31639;&#23376;&#38598;&#65292;&#20197;&#25277;&#35937;&#30340;&#26041;&#24335;&#24635;&#32467;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#65292;&#20026;&#22823;&#35268;&#27169;&#30340;&#33258;&#21160;&#29305;&#24449;&#24037;&#31243;&#25552;&#20379;&#22522;&#30784;&#12290;&#25968;&#20540;&#19978;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the concept of programmable feature engineering for time series modeling and propose a feature programming framework. This framework generates large amounts of predictive features for noisy multivariate time series while allowing users to incorporate their inductive bias with minimal effort. The key motivation of our framework is to view any multivariate time series as a cumulative sum of fine-grained trajectory increments, with each increment governed by a novel spin-gas dynamical Ising model. This fine-grained perspective motivates the development of a parsimonious set of operators that summarize multivariate time series in an abstract fashion, serving as the foundation for large-scale automated feature engineering. Numerically, we validate the efficacy of our method on several synthetic and real-world noisy time series datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#22312;&#23454;&#29616;&#35774;&#32622;&#19979;&#19981;&#31561;&#20215;&#65292;&#24182;&#23558;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#20316;&#20026;&#20854;&#29305;&#23450;&#23454;&#20363;&#12290;</title><link>http://arxiv.org/abs/2306.06247</link><description>&lt;p&gt;
&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Learning with Set-Valued Feedback. (arXiv:2306.06247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#22312;&#23454;&#29616;&#35774;&#32622;&#19979;&#19981;&#31561;&#20215;&#65292;&#24182;&#23558;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#20316;&#20026;&#20854;&#29305;&#23450;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#20854;&#20013;&#23398;&#20064;&#22120;&#39044;&#27979;&#21333;&#20010;&#26631;&#31614;&#65292;&#20294;&#25509;&#25910;&#21040;&#19968;&#20010;&#26631;&#31614;&#30340;&#38598;&#21512;&#20316;&#20026;&#21453;&#39304;&#12290;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#22914;&#26524;&#23398;&#20064;&#22120;&#27809;&#26377;&#36755;&#20986;&#21253;&#21547;&#22312;&#21453;&#39304;&#38598;&#21512;&#20013;&#30340;&#26631;&#31614;&#65292;&#21017;&#20250;&#21463;&#21040;&#24809;&#32602;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#19982;&#20855;&#26377;&#21333;&#26631;&#31614;&#21453;&#39304;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#19981;&#21516;&#65292;&#22312;&#23454;&#29616;&#35774;&#32622;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#26102;&#65292;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#21270;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;\textit{&#19981;&#31561;&#20215;}&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#20998;&#21035;&#21629;&#21517;&#20026;&#38598;&#21512;&#23567;&#30707;&#21644;&#24230;&#37327;&#30772;&#35010;&#32500;&#24230;&#65292;&#20005;&#26684;&#25551;&#36848;&#20102;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#21270;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#24230;&#37327;&#30772;&#35010;&#32500;&#24230;&#22312;&#24735;&#24615;&#35774;&#32622;&#19979;&#20005;&#26684;&#25551;&#36848;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#26159;&#25105;&#20204;&#36890;&#29992;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#30340;&#20855;&#20307;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a variant of online multiclass classification where the learner predicts a single label but receives a \textit{set of labels} as feedback. In this model, the learner is penalized for not outputting a label contained in the revealed set. We show that unlike online multiclass learning with single-label feedback, deterministic and randomized online learnability are \textit{not equivalent} even in the realizable setting with set-valued feedback. Accordingly, we give two new combinatorial dimensions, named the Set Littlestone and Measure Shattering dimension, that tightly characterize deterministic and randomized online learnability respectively in the realizable setting. In addition, we show that the Measure Shattering dimension tightly characterizes online learnability in the agnostic setting. Finally, we show that practical learning settings like online multilabel ranking and online multilabel classification are specific instances of our general online learning framework.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20132;&#20114;&#24335;&#20272;&#35745;&#30340;&#32479;&#19968;&#23398;&#20064;&#26694;&#26550;&#65292;&#24341;&#20837;&#32452;&#21512;&#24230;&#37327;&#24046;&#24322;&#32500;&#24230;&#26469;&#25429;&#25417;&#27169;&#22411;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#25552;&#20986;&#20102;&#22810;&#39033;&#24335;&#30340;&#36951;&#25022;&#21644;PAC&#27867;&#21270;&#30028;&#38480;&#30340;&#31639;&#27861;&#65292;&#24182;&#32479;&#19968;&#20102;&#32479;&#35745;&#26597;&#35810;&#23398;&#20064;&#21644;&#32467;&#26500;&#21270;&#36172;&#21338;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.06184</link><description>&lt;p&gt;
&#20132;&#20114;&#24335;&#20272;&#35745;&#30340;&#32479;&#19968;&#27169;&#22411;&#21644;&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
A Unified Model and Dimension for Interactive Estimation. (arXiv:2306.06184v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06184
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20132;&#20114;&#24335;&#20272;&#35745;&#30340;&#32479;&#19968;&#23398;&#20064;&#26694;&#26550;&#65292;&#24341;&#20837;&#32452;&#21512;&#24230;&#37327;&#24046;&#24322;&#32500;&#24230;&#26469;&#25429;&#25417;&#27169;&#22411;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#25552;&#20986;&#20102;&#22810;&#39033;&#24335;&#30340;&#36951;&#25022;&#21644;PAC&#27867;&#21270;&#30028;&#38480;&#30340;&#31639;&#27861;&#65292;&#24182;&#32479;&#19968;&#20102;&#32479;&#35745;&#26597;&#35810;&#23398;&#20064;&#21644;&#32467;&#26500;&#21270;&#36172;&#21338;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31216;&#20026;"&#20132;&#20114;&#24335;&#20272;&#35745;"&#30340;&#25277;&#35937;&#23398;&#20064;&#26694;&#26550;&#65292;&#20854;&#30446;&#26631;&#26159;&#26681;&#25454;&#23398;&#20064;&#32773;&#26597;&#35810;&#21040;&#30340;&#26679;&#26412;&#28857;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;"&#30456;&#20284;&#24615;"&#26469;&#20272;&#35745;&#30446;&#26631;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#24046;&#24322;&#32500;&#24230;&#30340;&#32452;&#21512;&#24230;&#37327;&#65292;&#23427;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#25429;&#25417;&#20102;&#25105;&#20204;&#27169;&#22411;&#20013;&#30340;&#21487;&#23398;&#20064;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#36890;&#29992;&#19988;&#24191;&#27867;&#36866;&#29992;&#30340;&#31639;&#27861;&#65292;&#23545;&#20110;&#36825;&#20010;&#31639;&#27861;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#22312;&#26032;&#30340;&#32500;&#24230;&#19978;&#22810;&#39033;&#24335;&#30340;&#36951;&#25022;&#21644;PAC&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#34920;&#26126;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#21547;&#20102;&#24182;&#22240;&#27492;&#32479;&#19968;&#20102;&#20004;&#20010;&#32463;&#20856;&#30340;&#23398;&#20064;&#27169;&#22411;&#65306;&#32479;&#35745;&#26597;&#35810;&#23398;&#20064;&#21644;&#32467;&#26500;&#21270;&#36172;&#21338;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#35828;&#26126;&#20102;&#24046;&#24322;&#32500;&#24230;&#22914;&#20309;&#19982;&#36825;&#20004;&#20010;&#26694;&#26550;&#20013;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#21442;&#25968;&#30456;&#20851;&#65292;&#26377;&#26102;&#21487;&#20197;&#33719;&#24471;&#26174;&#33879;&#25913;&#36827;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study an abstract framework for interactive learning called interactive estimation in which the goal is to estimate a target from its "similarity'' to points queried by the learner. We introduce a combinatorial measure called dissimilarity dimension which largely captures learnability in our model. We present a simple, general, and broadly-applicable algorithm, for which we obtain both regret and PAC generalization bounds that are polynomial in the new dimension. We show that our framework subsumes and thereby unifies two classic learning models: statistical-query learning and structured bandits. We also delineate how the dissimilarity dimension is related to well-known parameters for both frameworks, in some cases yielding significantly improved analyses.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#28085;&#30422;&#26680;&#24179;&#28369;&#30340;&#24378;&#24230;&#20989;&#25968;&#20272;&#35745;&#12289;&#26368;&#23567;&#21270;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#23398;&#20064;&#21644;&#24402;&#32435;&#26500;&#36896;&#33410;&#28857;&#34920;&#31034;&#12290;&#36825;&#31181;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#32467;&#26500;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.06155</link><description>&lt;p&gt;
&#24378;&#24230;&#36718;&#24275;&#25237;&#24433;&#65306;&#29992;&#20110;&#21160;&#24577;&#32593;&#32476;&#30340;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks. (arXiv:2306.06155v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06155
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#28085;&#30422;&#26680;&#24179;&#28369;&#30340;&#24378;&#24230;&#20989;&#25968;&#20272;&#35745;&#12289;&#26368;&#23567;&#21270;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#23398;&#20064;&#21644;&#24402;&#32435;&#26500;&#36896;&#33410;&#28857;&#34920;&#31034;&#12290;&#36825;&#31181;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#32467;&#26500;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#24378;&#24230;&#36718;&#24275;&#25237;&#24433;&#8221;&#30340;&#26032;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#21160;&#24577;&#32593;&#32476;&#33410;&#28857;&#30340;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#65292;&#35813;&#21160;&#24577;&#32593;&#32476;&#30001;&#33410;&#28857;&#38598;&#21644;&#22312;&#36830;&#32493;&#26102;&#38388;&#20869;&#21457;&#29983;&#30340;&#30636;&#26102;&#20132;&#20114;&#20107;&#20214;&#30340;&#38598;&#21512;&#25152;&#29305;&#24449;&#21270;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65306;&#36890;&#36807;&#26680;&#24179;&#28369;&#31561;&#26041;&#27861;&#20272;&#35745;&#33410;&#28857;&#23545;&#20043;&#38388;&#20132;&#20114;&#30340;&#24378;&#24230;&#20989;&#25968;&#65307;&#23398;&#20064;&#19968;&#20010;&#26368;&#23567;&#21270;&#26576;&#31181;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#65307;&#36890;&#36807;&#23398;&#20064;&#30340;&#25237;&#24433;&#24402;&#32435;&#26500;&#36896;&#20986;&#19981;&#26029;&#21457;&#23637;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#30340;&#22522;&#26412;&#32467;&#26500;&#65292;&#24182;&#20855;&#26377;&#26102;&#38388;&#19968;&#33268;&#24615;&#65292;&#36825;&#24847;&#21619;&#30528;&#33410;&#28857;&#34920;&#31034;&#21487;&#20197;&#22312;&#19981;&#21516;&#30340;&#26102;&#38388;&#28857;&#19978;&#36827;&#34892;&#26377;&#24847;&#20041;&#30340;&#27604;&#36739;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#20063;&#26500;&#24314;&#20102;&#20272;&#35745;&#29702;&#35770;&#26469;&#38416;&#26126;&#24179;&#28369;&#20316;&#20026;&#20559;&#24046;&#26041;&#24046;&#25240;&#34935;&#30340;&#20316;&#29992;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#38543;&#30528;&#20449;&#22122;&#27604;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#24179;&#28369;&#31243;&#24230;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new algorithmic framework, Intensity Profile Projection, for learning continuous-time representations of the nodes of a dynamic network, characterised by a node set and a collection of instantaneous interaction events which occur in continuous time. Our framework consists of three stages: estimating the intensity functions underlying the interactions between pairs of nodes, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and inductively constructing evolving node representations via the learned projection. We show that our representations preserve the underlying structure of the network, and are temporally coherent, meaning that node representations can be meaningfully compared at different points in time. We develop estimation theory which elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce smoothing as the signal-to-noise ratio increases on account of the algorithm `borrow
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#34892;&#20026;&#21046;&#23450;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21033;&#29992;&#26234;&#24935;&#20986;&#34892;&#25968;&#25454;&#25361;&#25112;&#24320;&#21457;&#20998;&#23618;&#39044;&#27979;&#26041;&#27861;&#26469;&#39044;&#27979;EV&#20805;&#30005;&#31449;&#21344;&#29992;&#29575;&#65292;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#65292;&#20026;&#30005;&#21160;&#20986;&#34892;&#30340;&#33021;&#28304;&#20379;&#24212;&#21830;&#21644;&#29992;&#25143;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2306.06142</link><description>&lt;p&gt;
&#39044;&#27979;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;&#21344;&#29992;&#29575;: &#26234;&#24935;&#20986;&#34892;&#25968;&#25454;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Forecasting Electric Vehicle Charging Station Occupancy: Smarter Mobility Data Challenge. (arXiv:2306.06142v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06142
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#34892;&#20026;&#21046;&#23450;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21033;&#29992;&#26234;&#24935;&#20986;&#34892;&#25968;&#25454;&#25361;&#25112;&#24320;&#21457;&#20998;&#23618;&#39044;&#27979;&#26041;&#27861;&#26469;&#39044;&#27979;EV&#20805;&#30005;&#31449;&#21344;&#29992;&#29575;&#65292;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#65292;&#20026;&#30005;&#21160;&#20986;&#34892;&#30340;&#33021;&#28304;&#20379;&#24212;&#21830;&#21644;&#29992;&#25143;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#19994;&#26159;&#27431;&#27954;&#28201;&#23460;&#27668;&#20307;&#25490;&#25918;&#30340;&#20027;&#35201;&#36129;&#29486;&#32773;&#12290;&#36716;&#21521;&#20351;&#29992;&#20302;&#30899;&#33021;&#28304;&#30340;&#30005;&#21160;&#27773;&#36710;&#65288;EV&#65289;&#21487;&#20197;&#20943;&#23569;&#30899;&#25490;&#25918;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#25903;&#25345;&#30005;&#21160;&#20986;&#34892;&#30340;&#21457;&#23637;&#65292;&#25105;&#20204;&#38656;&#35201;&#26356;&#22909;&#22320;&#29702;&#35299;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#34892;&#20026;&#21644;&#21046;&#23450;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#26234;&#24935;&#20986;&#34892;&#25968;&#25454;&#25361;&#25112;&#32858;&#28966;&#20110;&#24320;&#21457;&#39044;&#27979;&#27169;&#22411;&#20197;&#39044;&#27979;EV&#20805;&#30005;&#31449;&#21344;&#29992;&#29575;&#12290;&#36825;&#20010;&#25361;&#25112;&#28041;&#21450;&#23545;2020-2021&#24180;7&#20010;&#26376;&#20869;4&#20010;&#22320;&#29702;&#21306;&#22495;&#30340;91&#20010;&#20805;&#30005;&#31449;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#12290;&#39044;&#27979;&#32467;&#26524;&#22312;&#19977;&#20010;&#19981;&#21516;&#32423;&#21035;&#65288;&#21333;&#20010;&#20805;&#30005;&#31449;&#12289;&#21306;&#22495;&#21644;&#25972;&#20307;&#65289;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#20197;&#25429;&#25417;&#25968;&#25454;&#30340;&#23618;&#27425;&#32467;&#26500;&#12290;&#32467;&#26524;&#20984;&#26174;&#20986;&#20998;&#23618;&#39044;&#27979;&#26041;&#27861;&#22312;&#20934;&#30830;&#39044;&#27979;EV&#20805;&#30005;&#31449;&#21344;&#29992;&#29575;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#20026;&#33021;&#28304;&#20379;&#24212;&#21830;&#21644;EV&#29992;&#25143;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;&#36825;&#20010;&#24320;&#25918;&#25968;&#25454;&#38598;&#35299;&#20915;&#20102;&#30005;&#21160;&#20986;&#34892;&#22686;&#38271;&#20013;&#26368;&#20851;&#38190;&#30340;&#38382;&#39064;&#65292;&#32467;&#26524;&#20196;&#20154;&#40723;&#33310;&#12290;
&lt;/p&gt;
&lt;p&gt;
The transport sector is a major contributor to greenhouse gas emissions in Europe. Shifting to electric vehicles (EVs) powered by a low-carbon energy mix would reduce carbon emissions. However, to support the development of electric mobility, a better understanding of EV charging behaviours and more accurate forecasting models are needed. To fill that gap, the Smarter Mobility Data Challenge has focused on the development of forecasting models to predict EV charging station occupancy. This challenge involved analysing a dataset of 91 charging stations across four geographical areas over seven months in 2020-2021. The forecasts were evaluated at three levels of aggregation (individual stations, areas and global) to capture the inherent hierarchical structure of the data. The results highlight the potential of hierarchical forecasting approaches to accurately predict EV charging station occupancy, providing valuable insights for energy providers and EV users alike. This open dataset addr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#8220;&#25237;&#30707;&#26426;&#8221;&#20248;&#21270;&#29616;&#35937;&#65292;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#35777;&#26126;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#21487;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.04815</link><description>&lt;p&gt;
SGD&#20013;&#30340;&#25237;&#30707;&#26426;&#65306;&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#21450;&#20854;&#36890;&#36807;&#29305;&#24449;&#23398;&#20064;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning. (arXiv:2306.04815v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#8220;&#25237;&#30707;&#26426;&#8221;&#20248;&#21270;&#29616;&#35937;&#65292;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#35777;&#26126;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#21487;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#35299;&#37322;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#36827;&#34892;&#35757;&#32451;&#26102;&#20026;&#20160;&#20040;&#32463;&#24120;&#20986;&#29616;&#35757;&#32451;&#25439;&#22833;&#23574;&#23792;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;SGD&#35757;&#32451;&#25439;&#22833;&#20013;&#30340;&#23574;&#23792;&#26159;&#8220;&#25237;&#30707;&#26426;&#8221;&#65292;&#36825;&#26159;&#19968;&#31181;&#20248;&#21270;&#29616;&#35937;&#65292;&#26368;&#21021;&#22312;[Lewkowycz&#31561;&#20154;&#65292;2020&#24180;]&#30340;&#22823;&#23398;&#20064;&#29575;GD&#20013;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#25237;&#30707;&#26426;&#20986;&#29616;&#22312;&#30001;&#27491;&#20999;&#20869;&#26680;&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#25152;&#24352;&#25104;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#65292;&#36866;&#29992;&#20110;GD&#21644;SGD&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#37322;&#65292;&#21363;&#25237;&#30707;&#26426;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#19982;&#30495;&#23454;&#39044;&#27979;&#22120;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#65288;AGOP&#65289;&#23545;&#40784;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;SGD&#20013;&#65292;&#26356;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#20250;&#23548;&#33268;&#26356;&#22810;&#30340;&#25237;&#30707;&#26426;&#20986;&#29616;&#65292;&#20174;&#32780;&#25552;&#39640;AGOP&#23545;&#40784;&#21644;&#27979;&#35797;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we first present an explanation regarding the common occurrence of spikes in the training loss when neural networks are trained with stochastic gradient descent (SGD). We provide evidence that the spikes in the training loss of SGD are "catapults", an optimization phenomenon originally observed in GD with large learning rates in [Lewkowycz et al. 2020]. We empirically show that these catapults occur in a low-dimensional subspace spanned by the top eigenvectors of the tangent kernel, for both GD and SGD. Second, we posit an explanation for how catapults lead to better generalization by demonstrating that catapults promote feature learning by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor. Furthermore, we demonstrate that a smaller batch size in SGD induces a larger number of catapults, thereby improving AGOP alignment and test performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#38543;&#26426;&#20248;&#21270;&#31471;&#21040;&#31471;&#23398;&#20064;&#26041;&#27861;&#65292;&#20026;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#25552;&#20379;&#26032;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#65292;&#26041;&#24335;&#20027;&#35201;&#26159;&#35757;&#32451;&#20915;&#31574;&#26144;&#23556;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#30340;newsvendor&#38382;&#39064;&#21644;&#32463;&#27982;&#20998;&#37197;&#38382;&#39064;&#19978;&#22343;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25928;&#26524;&#65292;&#21516;&#26102;&#20063;&#21457;&#29616;&#20915;&#31574;&#26144;&#23556;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23545;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#24456;&#22823;&#12290;</title><link>http://arxiv.org/abs/2306.04174</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#38543;&#26426;&#20248;&#21270;&#31471;&#21040;&#31471;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
End-to-End Learning for Stochastic Optimization: A Bayesian Perspective. (arXiv:2306.04174v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04174
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#38543;&#26426;&#20248;&#21270;&#31471;&#21040;&#31471;&#23398;&#20064;&#26041;&#27861;&#65292;&#20026;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#25552;&#20379;&#26032;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#65292;&#26041;&#24335;&#20027;&#35201;&#26159;&#35757;&#32451;&#20915;&#31574;&#26144;&#23556;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#30340;newsvendor&#38382;&#39064;&#21644;&#32463;&#27982;&#20998;&#37197;&#38382;&#39064;&#19978;&#22343;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25928;&#26524;&#65292;&#21516;&#26102;&#20063;&#21457;&#29616;&#20915;&#31574;&#26144;&#23556;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23545;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#24456;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#38543;&#26426;&#20248;&#21270;&#31471;&#21040;&#31471;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#26631;&#20934;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#30340;&#24605;&#24819;&#65292;&#35757;&#32451;&#20102;&#19968;&#20010;&#21518;&#39564;&#36125;&#21494;&#26031;&#34892;&#21160;&#26144;&#23556;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#20026;&#35299;&#20915;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#25552;&#20986;&#20102;&#26032;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#12290;&#36890;&#36807;&#21512;&#25104;&#30340;newsvendor&#38382;&#39064;&#21644;&#22522;&#20110;&#30495;&#23454;&#25968;&#25454;&#30340;&#32463;&#27982;&#20998;&#37197;&#38382;&#39064;&#30340;&#25968;&#20540;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#35757;&#32451;&#26041;&#26696;&#20043;&#38388;&#30340;&#20851;&#38190;&#24046;&#24322;&#20197;&#21450;&#20915;&#31574;&#26144;&#23556;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23545;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a principled approach to end-to-end learning in stochastic optimization. First, we show that the standard end-to-end learning algorithm admits a Bayesian interpretation and trains a posterior Bayes action map. Building on the insights of this analysis, we then propose new end-to-end learning algorithms for training decision maps that output solutions of empirical risk minimization and distributionally robust optimization problems, two dominant modeling paradigms in optimization under uncertainty. Numerical results for a synthetic newsvendor problem illustrate the key differences between alternative training schemes. We also investigate an economic dispatch problem based on real data to showcase the impact of the neural network architecture of the decision maps on their test performance.
&lt;/p&gt;</description></item><item><title>&#20998;&#25955;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;&#65292;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#21644;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32780;&#19988;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;</title><link>http://arxiv.org/abs/2306.02913</link><description>&lt;p&gt;
&#20998;&#25955;&#21270;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;
&lt;/p&gt;
&lt;p&gt;
Decentralized SGD and Average-direction SAM are Asymptotically Equivalent. (arXiv:2306.02913v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02913
&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;&#65292;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#21644;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32780;&#19988;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;D-SGD&#65289;&#20801;&#35768;&#22312;&#27809;&#26377;&#20013;&#22830;&#26381;&#21153;&#22120;&#30340;&#25511;&#21046;&#19979;&#65292;&#22823;&#37327;&#35774;&#22791;&#21516;&#26102;&#36827;&#34892;&#21327;&#20316;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#29702;&#35770;&#35748;&#20026;&#65292;&#20998;&#25955;&#21270;&#19981;&#21487;&#36991;&#20813;&#22320;&#21066;&#24369;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#25361;&#25112;&#20256;&#32479;&#20449;&#24565;&#65292;&#25552;&#20986;&#20102;&#23436;&#20840;&#26032;&#30340;&#35282;&#24230;&#26469;&#29702;&#35299;&#20998;&#25955;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#38750;&#20984;&#38750;-$\beta$-&#24179;&#28369;&#35774;&#32622;&#19979;&#65292;D-SGD&#38544;&#24335;&#22320;&#26368;&#23567;&#21270;&#20102;&#24179;&#22343;&#26041;&#21521;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#31639;&#27861;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#36825;&#31181;&#24778;&#20154;&#30340;&#28176;&#36817;&#31561;&#20215;&#25581;&#31034;&#20102;&#20869;&#22312;&#30340;&#27491;&#21017;&#21270;-&#20248;&#21270;&#26435;&#34913;&#20197;&#21450;&#20998;&#25955;&#21270;&#30340;&#19977;&#20010;&#20248;&#28857;&#65306;&#65288;1&#65289;D-SGD&#20013;&#23384;&#22312;&#19968;&#20010;&#33258;&#30001;&#30340;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#26426;&#21046;&#65292;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#20272;&#35745;&#65307;&#65288;2&#65289;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#65307;&#65288;3&#65289;D-SGD&#30340;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#19981;&#20250;&#38543;&#30528;&#24635;&#25209;&#22788;&#29702;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#36825;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization b
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#65292;&#21487;&#20197;&#29992;&#20110;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#39069;&#22806;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2306.00986</link><description>&lt;p&gt;
&#21487;&#25511;&#22270;&#20687;&#29983;&#25104;&#30340;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Diffusion Self-Guidance for Controllable Image Generation. (arXiv:2306.00986v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#65292;&#21487;&#20197;&#29992;&#20110;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#39069;&#22806;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#33021;&#22815;&#20174;&#35814;&#32454;&#25991;&#26412;&#25551;&#36848;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#12290;&#28982;&#32780;&#65292;&#22270;&#20687;&#30340;&#35768;&#22810;&#26041;&#38754;&#24456;&#38590;&#25110;&#19981;&#21487;&#33021;&#36890;&#36807;&#25991;&#26412;&#26469;&#20256;&#36798;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20174;&#36825;&#20123;&#34920;&#31034;&#20013;&#25552;&#21462;&#20986;&#23545;&#35937;&#30340;&#24418;&#29366;&#12289;&#20301;&#32622;&#21644;&#22806;&#35266;&#31561;&#23646;&#24615;&#24182;&#29992;&#20110;&#25351;&#23548;&#37319;&#26679;&#12290;&#33258;&#23548;&#31867;&#20284;&#20110;&#20998;&#31867;&#22120;&#24341;&#23548;&#65292;&#20294;&#26159;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26412;&#36523;&#20013;&#23384;&#22312;&#30340;&#20449;&#21495;&#65292;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#32452;&#21512;&#19968;&#32452;&#31616;&#21333;&#30340;&#23646;&#24615;&#26469;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#20363;&#22914;&#20462;&#25913;&#23545;&#35937;&#30340;&#20301;&#32622;&#25110;&#22823;&#23567;&#65292;&#23558;&#19968;&#20010;&#22270;&#20687;&#20013;&#30340;&#23545;&#35937;&#22806;&#35266;&#19982;&#21478;&#19968;&#20010;&#22270;&#20687;&#30340;&#24067;&#23616;&#30456;&#32467;&#21512;&#65292;&#23558;&#22810;&#20010;&#22270;&#20687;&#30340;&#23545;&#35937;&#32452;&#21512;&#25104;&#19968;&#20010;&#65292;&#31561;&#31561;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#33258;&#23548;&#21487;&#20197;&#29992;&#20110;&#32534;&#36753;&#30495;&#23454;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale generative models are capable of producing high-quality images from detailed text descriptions. However, many aspects of an image are difficult or impossible to convey through text. We introduce self-guidance, a method that provides greater control over generated images by guiding the internal representations of diffusion models. We demonstrate that properties such as the shape, location, and appearance of objects can be extracted from these representations and used to steer sampling. Self-guidance works similarly to classifier guidance, but uses signals present in the pretrained model itself, requiring no additional models or training. We show how a simple set of properties can be composed to perform challenging image manipulations, such as modifying the position or size of objects, merging the appearance of objects in one image with the layout of another, composing objects from many images into one, and more. We also show that self-guidance can be used to edit real images
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;ERM&#35757;&#32451;&#27169;&#22411;&#23545;&#25239;&#24378;&#22823;&#40657;&#30418;&#25915;&#20987;&#30340;&#23433;&#20840;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#25351;&#26631;&#37327;&#21270;&#27169;&#22411;&#23433;&#20840;&#24615;&#65306;&#21333;&#20010;&#26679;&#26412;&#30340;&#31283;&#23450;&#24615;&#21644;&#26597;&#35810;&#19982;&#21407;&#22987;&#25968;&#25454;&#29305;&#24449;&#30340;&#23545;&#40784;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#30740;&#31350;RF&#21644;NTK&#22238;&#24402;&#65292;&#35777;&#26126;&#38543;&#30528;&#27867;&#21270;&#33021;&#21147;&#30340;&#25552;&#39640;&#65292;&#38544;&#31169;&#20445;&#25252;&#21487;&#20197;&#24471;&#21040;&#21152;&#24378;&#12290;</title><link>http://arxiv.org/abs/2305.12100</link><description>&lt;p&gt;
&#31283;&#23450;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#65306;&#23545;&#20110;&#38543;&#26426;&#29305;&#24449;&#21644;NTK&#29305;&#24449;&#30340;&#31934;&#30830;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Stability, Generalization and Privacy: Precise Analysis for Random and NTK Features. (arXiv:2305.12100v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12100
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;ERM&#35757;&#32451;&#27169;&#22411;&#23545;&#25239;&#24378;&#22823;&#40657;&#30418;&#25915;&#20987;&#30340;&#23433;&#20840;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#25351;&#26631;&#37327;&#21270;&#27169;&#22411;&#23433;&#20840;&#24615;&#65306;&#21333;&#20010;&#26679;&#26412;&#30340;&#31283;&#23450;&#24615;&#21644;&#26597;&#35810;&#19982;&#21407;&#22987;&#25968;&#25454;&#29305;&#24449;&#30340;&#23545;&#40784;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#30740;&#31350;RF&#21644;NTK&#22238;&#24402;&#65292;&#35777;&#26126;&#38543;&#30528;&#27867;&#21270;&#33021;&#21147;&#30340;&#25552;&#39640;&#65292;&#38544;&#31169;&#20445;&#25252;&#21487;&#20197;&#24471;&#21040;&#21152;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#24674;&#22797;&#25915;&#20987;&#65292;&#24341;&#36215;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#30340;&#25285;&#24551;&#12290;&#38024;&#23545;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#31561;&#24120;&#35265;&#31639;&#27861;&#36890;&#24120;&#19981;&#33021;&#30452;&#25509;&#23454;&#26045;&#23433;&#20840;&#20445;&#38556;&#30340;&#38382;&#39064;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;ERM&#35757;&#32451;&#27169;&#22411;&#23545;&#25239;&#29305;&#23450;&#24378;&#22823;&#40657;&#30418;&#23376;&#25915;&#20987;&#30340;&#23433;&#20840;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36890;&#36807;&#20004;&#20010;&#30475;&#20284;&#19981;&#21516;&#20294;&#26377;&#32852;&#31995;&#30340;&#25351;&#26631;&#26469;&#37327;&#21270;&#27169;&#22411;&#23433;&#20840;&#24615;&#65306;&#19968;&#26159;&#30456;&#23545;&#20110;&#21333;&#20010;&#35757;&#32451;&#26679;&#26412;&#30340;&#27169;&#22411;&#31283;&#23450;&#24615;&#65292;&#21478;&#19968;&#20010;&#26159;&#25915;&#20987;&#26597;&#35810;&#21644;&#21407;&#22987;&#25968;&#25454;&#29305;&#24449;&#30340;&#29305;&#24449;&#23545;&#40784;&#12290;&#34429;&#28982;&#21069;&#32773;&#22312;&#23398;&#20064;&#29702;&#35770;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#38416;&#36848;&#65292;&#24182;&#19982;&#32463;&#20856;&#24037;&#20316;&#20013;&#30340;&#27867;&#21270;&#35823;&#24046;&#30456;&#20851;&#65292;&#20294;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#31532;&#20108;&#31181;&#29305;&#24615;&#26159;&#26032;&#39062;&#30340;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#32467;&#26524;&#20026;&#20004;&#31181;&#21407;&#22411;&#35774;&#32622;&#25552;&#20379;&#20102;&#29305;&#24449;&#23545;&#40784;&#30340;&#31934;&#30830;&#21051;&#30011;&#65306;&#38543;&#26426;&#29305;&#24449;&#65288;RF&#65289;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#22238;&#24402;&#12290;&#36825;&#35777;&#26126;&#65292;&#38543;&#30528;&#27867;&#21270;&#33021;&#21147;&#30340;&#25552;&#39640;&#65292;&#38544;&#31169;&#20445;&#25252;&#33021;&#22815;&#24471;&#21040;&#21152;&#24378;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#20854;&#20182;&#26377;&#36259;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models can be vulnerable to recovery attacks, raising privacy concerns to users, and widespread algorithms such as empirical risk minimization (ERM) often do not directly enforce safety guarantees. In this paper, we study the safety of ERM-trained models against a family of powerful black-box attacks. Our analysis quantifies this safety via two separate terms: (i) the model stability with respect to individual training samples, and (ii) the feature alignment between the attacker query and the original data. While the first term is well established in learning theory and it is connected to the generalization error in classical work, the second one is, to the best of our knowledge, novel. Our key technical result provides a precise characterization of the feature alignment for the two prototypical settings of random features (RF) and neural tangent kernel (NTK) regression. This proves that privacy strengthens with an increase in the generalization capability, unveiling also
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#21644;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.06094</link><description>&lt;p&gt;
&#33021;&#37327;&#24341;&#23548;&#30340;&#29109;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Energy-guided Entropic Neural Optimal Transport. (arXiv:2304.06094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#21644;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#65288;EBMs&#65289;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#24050;&#32463;&#26377;&#25968;&#21313;&#24180;&#30340;&#21382;&#21490;&#12290;&#33258;&#20004;&#21315;&#24180;&#20195;&#36215;&#65292;&#19968;&#30452;&#26377;&#24456;&#22810;&#39640;&#25928;&#30340;&#26041;&#27861;&#36890;&#36807;&#33021;&#37327;&#21183;&#65288;&#38750;&#24402;&#19968;&#21270;&#30340;&#20284;&#28982;&#20989;&#25968;&#65289;&#26469;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#39046;&#22495;&#65292;&#23588;&#20854;&#26159;&#31070;&#32463;OT&#27714;&#35299;&#22120;&#65292;&#21463;&#21040;&#30340;&#25506;&#32034;&#35201;&#23569;&#24471;&#22810;&#65292;&#20165;&#26377;&#19968;&#20123;&#36817;&#26399;&#30340;&#30740;&#31350;&#65288;&#19981;&#21253;&#25324;&#21033;&#29992;OT&#20316;&#20026;&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#38382;&#39064;&#30340;WGAN&#26041;&#27861;&#65289;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24357;&#21512;&#20102;EBMs&#21644;&#29109;&#27491;&#21017;&#21270;OT&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#21033;&#29992;&#21069;&#32773;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#25216;&#26415;&#25913;&#36827;&#26469;&#20016;&#23500;&#21518;&#32773;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#26631;&#20934;&#30340;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#31616;&#21333;&#36215;&#35265;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;&#31616;&#30701;&#21644;&#38271;&#36305;&#30340;EBMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) are known in the Machine Learning community for the decades. Since the seminal works devoted to EBMs dating back to the noughties there have been appearing a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present the novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. We validate the applicability of our method on toy 2D scenarios as well as standard unpaired image-to-image translation problems. For the sake of simplicity, we choose simple short- and long- run EBMs as a 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#26435;&#20449;&#24687;&#30340;&#37325;&#22797;&#22238;&#24402;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#26657;&#27491;&#36873;&#25321;&#20559;&#24046;&#21644;&#32570;&#22833;&#21709;&#24212;&#65292;&#36825;&#31181;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#19988;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2303.16800</link><description>&lt;p&gt;
&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#26657;&#27491;&#22238;&#24402;&#20013;&#30340;&#36873;&#25321;&#20559;&#24046;&#21644;&#32570;&#22833;&#21709;&#24212;
&lt;/p&gt;
&lt;p&gt;
Correcting for Selection Bias and Missing Response in Regression using Privileged Information. (arXiv:2303.16800v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16800
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#26435;&#20449;&#24687;&#30340;&#37325;&#22797;&#22238;&#24402;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22312;&#22238;&#24402;&#27169;&#22411;&#20013;&#26657;&#27491;&#36873;&#25321;&#20559;&#24046;&#21644;&#32570;&#22833;&#21709;&#24212;&#65292;&#36825;&#31181;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#19988;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#36827;&#34892;&#22238;&#24402;&#27169;&#22411;&#20272;&#35745;&#26102;&#65292;&#21487;&#33021;&#20250;&#20986;&#29616;&#19968;&#20123;&#26631;&#31614;&#32570;&#22833;&#30340;&#25968;&#25454;&#65292;&#25110;&#32773;&#25105;&#20204;&#30340;&#25968;&#25454;&#21487;&#33021;&#20250;&#21463;&#21040;&#36873;&#25321;&#26426;&#21046;&#30340;&#20559;&#24046;&#24433;&#21709;&#12290;&#24403;&#21709;&#24212;&#25110;&#36873;&#25321;&#26426;&#21046;&#26159;&#21487;&#24573;&#30053;&#30340;&#65288;&#21363;&#65292;&#22312;&#32473;&#23450;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#65292;&#29420;&#31435;&#20110;&#21709;&#24212;&#21464;&#37327;&#65289;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#22238;&#24402;&#26041;&#27861;&#65307;&#22312;&#19981;&#21487;&#24573;&#30053;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#24120;&#24517;&#39035;&#36827;&#34892;&#20559;&#24046;&#35843;&#25972;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#29305;&#26435;&#25968;&#25454;&#65288;&#21363;&#21482;&#22312;&#35757;&#32451;&#26399;&#38388;&#21487;&#29992;&#30340;&#25968;&#25454;&#65289;&#21487;&#33021;&#20250;&#20351;&#19981;&#21487;&#24573;&#30053;&#30340;&#36873;&#25321;&#26426;&#21046;&#21487;&#24573;&#30053;&#65292;&#24182;&#23558;&#36825;&#31181;&#24773;&#20917;&#31216;&#20026;&#29305;&#26435;&#32570;&#22833;&#38543;&#26426;&#65288;PMAR&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#25554;&#34917;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#31216;&#20026;&#37325;&#22797;&#22238;&#24402;&#65292;&#36866;&#29992;&#20110;PMAR&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#19968;&#31181;&#37325;&#35201;&#24615;&#21152;&#26435;&#22238;&#24402;&#26041;&#27861;&#21644;&#20004;&#31181;&#26041;&#27861;&#30340;&#21452;&#37325;&#31283;&#20581;&#32452;&#21512;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26131;&#20110;&#20351;&#29992;&#22823;&#22810;&#25968;&#27969;&#34892;&#30340;&#29616;&#25104;&#22238;&#24402;&#31639;&#27861;&#36827;&#34892;&#23454;&#29616;&#12290;&#25105;&#20204;&#36890;&#36807;&#22823;&#37327;&#30340;&#27169;&#25311;&#23454;&#39564;&#21644;&#23545;Eye State&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#35780;&#20272;&#26469;&#35780;&#20272;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
When estimating a regression model, we might have data where some labels are missing, or our data might be biased by a selection mechanism. When the response or selection mechanism is ignorable (i.e., independent of the response variable given the features) one can use off-the-shelf regression methods; in the nonignorable case one typically has to adjust for bias. We observe that privileged data (i.e. data that is only available during training) might render a nonignorable selection mechanism ignorable, and we refer to this scenario as Privilegedly Missing at Random (PMAR). We propose a novel imputation-based regression method, named repeated regression, that is suitable for PMAR. We also consider an importance weighted regression method, and a doubly robust combination of the two. The proposed methods are easy to implement with most popular out-of-the-box regression algorithms. We empirically assess the performance of the proposed methods with extensive simulated experiments and on a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21547;&#26377;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#30001;&#20110;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#26799;&#24230;&#35745;&#31639;&#26041;&#27861;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#28040;&#32791;&#65292;&#21516;&#26102;&#20173;&#33021;&#20445;&#35777;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16241</link><description>&lt;p&gt;
&#37319;&#29992;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Momentum-Based Heavy Ball Method with Batch Updating and/or Approximate Gradients. (arXiv:2303.16241v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21547;&#26377;&#25209;&#37327;&#26356;&#26032;&#21644;/&#25110;&#36817;&#20284;&#26799;&#24230;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#30001;&#20110;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#26799;&#24230;&#35745;&#31639;&#26041;&#27861;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#28040;&#32791;&#65292;&#21516;&#26102;&#20173;&#33021;&#20445;&#35777;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;1964&#24180;Polyak&#24341;&#20837;&#30340;&#20984;&#20248;&#21270;&#21644;&#38750;&#20984;&#20248;&#21270;&#20013;&#24191;&#20026;&#20154;&#30693;&#30340;&#8220;&#21160;&#37327;&#37325;&#29699;&#8221;&#27861;&#65292;&#24182;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#30830;&#31435;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;&#24403;&#35201;&#27714;&#35299;&#21442;&#25968;&#30340;&#32500;&#24230;&#38750;&#24120;&#39640;&#26102;&#65292;&#26356;&#26032;&#19968;&#37096;&#20998;&#32780;&#19981;&#26159;&#25152;&#26377;&#21442;&#25968;&#21487;&#20197;&#25552;&#39640;&#20248;&#21270;&#25928;&#29575;&#65292;&#31216;&#20043;&#20026;&#8220;&#25209;&#37327;&#26356;&#26032;&#8221;&#65292;&#33509;&#19982;&#26799;&#24230;&#27861;&#37197;&#21512;&#20351;&#29992;&#65292;&#21017;&#29702;&#35770;&#19978;&#21482;&#38656;&#35745;&#31639;&#38656;&#35201;&#26356;&#26032;&#30340;&#21442;&#25968;&#30340;&#26799;&#24230;&#65292;&#32780;&#22312;&#23454;&#38469;&#20013;&#65292;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#31561;&#26041;&#27861;&#20165;&#35745;&#31639;&#37096;&#20998;&#26799;&#24230;&#24182;&#19981;&#33021;&#20943;&#23569;&#35745;&#31639;&#37327;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#22312;&#27599;&#19968;&#27493;&#20013;&#20943;&#23569;CPU&#20351;&#29992;&#37327;&#65292;&#21487;&#20197;&#20351;&#29992;&#19968;&#38454;&#24494;&#20998;&#25110;&#36817;&#20284;&#26799;&#24230;&#20195;&#26367;&#30495;&#23454;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#20551;&#35774;&#19979;&#65292;&#37319;&#29992;&#36817;&#20284;&#26799;&#24230;&#20449;&#24687;&#21644;/&#25110;&#25209;&#37327;&#26356;&#26032;&#30340;&#21160;&#37327;&#37325;&#29699;&#27861;&#20173;&#28982;&#21487;&#20197;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the well-known "Heavy Ball" method for convex and nonconvex optimization introduced by Polyak in 1964, and establish its convergence under a variety of situations. Traditionally, most algorthms use "full-coordinate update," that is, at each step, very component of the argument is updated. However, when the dimension of the argument is very high, it is more efficient to update some but not all components of the argument at each iteration. We refer to this as "batch updating" in this paper.  When gradient-based algorithms are used together with batch updating, in principle it is sufficient to compute only those components of the gradient for which the argument is to be updated. However, if a method such as back propagation is used to compute these components, computing only some components of gradient does not offer much savings over computing the entire gradient. Therefore, to achieve a noticeable reduction in CPU usage at each step, one can use first-order diffe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#20989;&#25968;&#37325;&#26500;&#38543;&#26426;&#21464;&#37327;X&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#25968;&#25454;&#31232;&#21270;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#65292;&#24182;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.12931</link><description>&lt;p&gt;
&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#24191;&#20041;&#25968;&#25454;&#31232;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalized Data Thinning Using Sufficient Statistics. (arXiv:2303.12931v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#20989;&#25968;&#37325;&#26500;&#38543;&#26426;&#21464;&#37327;X&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#25968;&#25454;&#31232;&#21270;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#65292;&#24182;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;&#19968;&#31181;&#23558;&#38543;&#26426;&#21464;&#37327;X&#20998;&#35299;&#20026;&#22810;&#20010;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#32780;&#19981;&#20250;&#20002;&#22833;&#20219;&#20309;&#26377;&#20851;&#26410;&#30693;&#21442;&#25968;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#19968;&#20123;&#24050;&#30693;&#30340;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#30340;&#20989;&#25968;&#23436;&#20840;&#37325;&#26500;X&#26469;&#25512;&#24191;&#20102;&#26368;&#36817;&#19968;&#31687;&#35770;&#25991;&#30340;&#36807;&#31243;&#12290;&#35813;&#36807;&#31243;&#30340;&#25512;&#24191;&#26377;&#20004;&#20010;&#30446;&#30340;&#12290;&#39318;&#20808;&#65292;&#23427;&#26497;&#22823;&#22320;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#12290;&#20854;&#27425;&#65292;&#23427;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#65292;&#23427;&#20204;&#22312;&#34920;&#38754;&#19978;&#20284;&#20046;&#38750;&#24120;&#19981;&#21516;&#65292;&#20294;&#24212;&#29992;&#20102;&#21516;&#26679;&#30340;&#21407;&#29702;&#12290;&#36825;&#20010;&#20849;&#21516;&#30340;&#21407;&#29702;&#26159;&#20805;&#20998;&#24615;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#35748;&#35782;&#23545;&#21508;&#31181;&#19981;&#21516;&#30340;&#23478;&#26063;&#36827;&#34892;&#24191;&#20041;&#31232;&#30095;&#21270;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our goal is to develop a general strategy to decompose a random variable $X$ into multiple independent random variables, without sacrificing any information about unknown parameters. A recent paper showed that for some well-known natural exponential families, $X$ can be "thinned" into independent random variables $X^{(1)}, \ldots, X^{(K)}$, such that $X = \sum_{k=1}^K X^{(k)}$. In this paper, we generalize their procedure by relaxing this summation requirement and simply asking that some known function of the independent random variables exactly reconstruct $X$. This generalization of the procedure serves two purposes. First, it greatly expands the families of distributions for which thinning can be performed. Second, it unifies sample splitting and data thinning, which on the surface seem to be very different, as applications of the same principle. This shared principle is sufficiency. We use this insight to perform generalized thinning operations for a diverse set of families.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#23398;&#20064;&#25298;&#32477;&#8221;&#26694;&#26550;&#26469;&#35299;&#20915;&#39046;&#22495;&#27867;&#21270;&#20013;&#30340;&#40664;&#40664;&#22833;&#36133;&#38382;&#39064;&#12290;&#36890;&#36807;&#39044;&#27979;&#21487;&#20449;&#24230;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#25509;&#21463;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#65292;&#20197;&#35782;&#21035;&#33021;&#21147;&#21306;&#22495;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#19981;&#21516;&#30340;&#23398;&#20064;&#34920;&#31034;&#34913;&#37327;&#26080;&#33021;&#65292;&#22686;&#21152;&#26080;&#33021;&#24471;&#20998;&#20250;&#39044;&#31034;&#30528;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.09989</link><description>&lt;p&gt;
&#22312;&#39046;&#22495;&#27867;&#21270;&#20013;&#25214;&#21040;&#33021;&#21147;&#21306;&#22495;
&lt;/p&gt;
&lt;p&gt;
Finding Competence Regions in Domain Generalization. (arXiv:2303.09989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09989
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#23398;&#20064;&#25298;&#32477;&#8221;&#26694;&#26550;&#26469;&#35299;&#20915;&#39046;&#22495;&#27867;&#21270;&#20013;&#30340;&#40664;&#40664;&#22833;&#36133;&#38382;&#39064;&#12290;&#36890;&#36807;&#39044;&#27979;&#21487;&#20449;&#24230;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#25509;&#21463;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#65292;&#20197;&#35782;&#21035;&#33021;&#21147;&#21306;&#22495;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#19981;&#21516;&#30340;&#23398;&#20064;&#34920;&#31034;&#34913;&#37327;&#26080;&#33021;&#65292;&#22686;&#21152;&#26080;&#33021;&#24471;&#20998;&#20250;&#39044;&#31034;&#30528;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#23398;&#20064;&#25298;&#32477;&#8221;&#26694;&#26550;&#26469;&#35299;&#20915;&#39046;&#22495;&#27867;&#21270;&#20013;&#40664;&#40664;&#22833;&#36133;&#30340;&#38382;&#39064;&#65292;&#21363;&#27979;&#35797;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#20551;&#35774;&#26377;&#19968;&#20010;&#28201;&#21644;&#30340;&#20998;&#24067;&#20559;&#31227;&#65292;&#25105;&#20204;&#24076;&#26395;&#22312;&#27169;&#22411;&#20272;&#35745;&#30340;&#33021;&#21147;&#39044;&#31034;&#30528;&#21487;&#20449;&#21709;&#24212;&#26102;&#25509;&#21463;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#30452;&#25509;&#25298;&#32477;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#12290;&#21487;&#20449;&#24230;&#36890;&#36807;&#19982;&#20998;&#31867;&#22120;&#24615;&#33021;&#23494;&#20999;&#30456;&#20851;&#30340;&#20195;&#29702;&#26080;&#33021;&#20998;&#25968;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#23545;&#20998;&#31867;&#30340;&#26080;&#33021;&#24471;&#20998;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#35780;&#20272;&#65292;&#24182;&#24378;&#35843;&#20102;&#25298;&#32477;&#29575;&#19982;&#20934;&#30830;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#20026;&#20102;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;&#26631;&#20934;&#39046;&#22495;&#27867;&#21270;&#22522;&#20934;&#65292;&#24182;&#32771;&#34385;&#22312;&#38381;&#21512;&#21644;&#24320;&#25918;&#19990;&#30028;&#29615;&#22659;&#19979;&#36890;&#36807;&#19981;&#21516;&#30340;&#23398;&#20064;&#34920;&#31034;&#26469;&#34913;&#37327;&#26080;&#33021;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22686;&#21152;&#26080;&#33021;&#20998;&#25968;&#30830;&#23454;&#39044;&#31034;&#30528;&#38477;&#20302;&#20934;&#30830;&#24615;&#65292;&#20174;&#32780;&#23548;&#33268;&#26174;&#30528;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We propose a "learning to reject" framework to address the problem of silent failures in Domain Generalization (DG), where the test distribution differs from the training distribution. Assuming a mild distribution shift, we wish to accept out-of-distribution (OOD) data whenever a model's estimated competence foresees trustworthy responses, instead of rejecting OOD data outright. Trustworthiness is then predicted via a proxy incompetence score that is tightly linked to the performance of a classifier. We present a comprehensive experimental evaluation of incompetence scores for classification and highlight the resulting trade-offs between rejection rate and accuracy gain. For comparability with prior work, we focus on standard DG benchmarks and consider the effect of measuring incompetence via different learned representations in a closed versus an open world setting. Our results suggest that increasing incompetence scores are indeed predictive of reduced accuracy, leading to significan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#21521;&#37327;&#21270;&#25216;&#26415;&#20013;&#30340;&#40065;&#26834;&#24615;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#27969;&#34892;&#30340;&#23884;&#20837;&#26041;&#26696;&#20855;&#26377;Hamming&#36317;&#31163;&#24847;&#20041;&#19978;&#30340;&#40065;&#26834;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#23450;&#37327;&#36793;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20013;&#30340;&#24120;&#25968;&#21463;&#25991;&#26723;&#38271;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2303.07203</link><description>&lt;p&gt;
&#20851;&#20110;&#25991;&#26412;&#21521;&#37327;&#21270;&#25216;&#26415;&#30340;&#40065;&#26834;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Robustness of Text Vectorizers. (arXiv:2303.07203v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07203
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#21521;&#37327;&#21270;&#25216;&#26415;&#20013;&#30340;&#40065;&#26834;&#24615;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#27969;&#34892;&#30340;&#23884;&#20837;&#26041;&#26696;&#20855;&#26377;Hamming&#36317;&#31163;&#24847;&#20041;&#19978;&#30340;&#40065;&#26834;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#23450;&#37327;&#36793;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20013;&#30340;&#24120;&#25968;&#21463;&#25991;&#26723;&#38271;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#27169;&#22411;&#23545;&#36755;&#20837;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#65292;&#27169;&#22411;&#36890;&#24120;&#21253;&#21547;&#31532;&#19968;&#23618;&#23884;&#20837;&#65292;&#23558;&#35789;&#27719;&#24207;&#21015;&#36716;&#25442;&#20026;&#21521;&#37327;&#34920;&#31034;&#12290;&#34429;&#28982;&#36830;&#32493;&#36755;&#20837;&#30340;&#31283;&#20581;&#24615;&#24050;&#32463;&#34987;&#24456;&#22909;&#22320;&#29702;&#35299;&#65292;&#20294;&#32771;&#34385;&#21040;&#31163;&#25955;&#21464;&#21270;(&#27604;&#22914;&#26367;&#25442;&#21477;&#23376;&#20013;&#30340;&#19968;&#20010;&#35789;)&#65292;&#24773;&#20917;&#23601;&#19981;&#37027;&#20040;&#26126;&#30830;&#20102;&#12290;&#26412;&#25991;&#27491;&#24335;&#35777;&#26126;&#20102;&#27969;&#34892;&#30340;&#23884;&#20837;&#26041;&#26696;(&#22914;&#25340;&#25509;&#12289;TF-IDF&#12289;&#27573;&#33853;&#21521;&#37327;)&#22312;Hamming&#36317;&#31163;&#24847;&#20041;&#19979;&#34920;&#29616;&#20986;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#20026;&#36825;&#20123;&#26041;&#27861;&#25552;&#20379;&#20102;&#23450;&#37327;&#36793;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20013;&#30340;&#24120;&#25968;&#22914;&#20309;&#21463;&#25991;&#26723;&#38271;&#24230;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#36890;&#36807;&#19968;&#31995;&#21015;&#25968;&#20540;&#23454;&#20363;&#21152;&#20197;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
A fundamental issue in machine learning is the robustness of the model with respect to changes in the input. In natural language processing, models typically contain a first embedding layer, transforming a sequence of tokens into vector representations. While the robustness with respect to changes of continuous inputs is well-understood, the situation is less clear when considering discrete changes, for instance replacing a word by another in an input sentence. Our work formally proves that popular embedding schemes, such as concatenation, TF-IDF, and Paragraph Vector (a.k.a. doc2vec), exhibit robustness in the H\"older or Lipschitz sense with respect to the Hamming distance. We provide quantitative bounds for these schemes and demonstrate how the constants involved are affected by the length of the document. These findings are exemplified through a series of numerical examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DP-Fast MH&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20855;&#26377;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2303.06171</link><description>&lt;p&gt;
DP-Fast MH: &#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#31169;&#26377;&#12289;&#24555;&#36895;&#12289;&#20934;&#30830;&#30340;Metropolis-Hastings&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference. (arXiv:2303.06171v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DP-Fast MH&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20855;&#26377;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#38544;&#31169;&#20445;&#25252;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new DP-Fast MH algorithm for large-scale Bayesian inference, which is accurate, fast, and privacy-preserving.
&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#22797;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#21644;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#25512;&#29702;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#12290;&#23427;&#24050;&#32463;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#22914;&#21307;&#23398;&#35786;&#26029;&#12289;&#33647;&#29289;&#35774;&#35745;&#21644;&#25919;&#31574;&#21046;&#23450;&#12290;&#22312;&#36825;&#20123;&#24120;&#35265;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#21487;&#33021;&#38750;&#24120;&#25935;&#24863;&#12290;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#25552;&#20379;&#20102;&#20855;&#26377;&#24378;&#22823;&#26368;&#22351;&#24773;&#20917;&#38544;&#31169;&#20445;&#35777;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#65292;&#24182;&#24050;&#21457;&#23637;&#25104;&#20026;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Metropolis-Hastings&#65288;MH&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#26368;&#22522;&#26412;&#30340;MCMC&#26041;&#27861;&#20043;&#19968;&#65292;&#29992;&#20110;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#31169;&#26377;MCMC&#31639;&#27861;&#20026;&#20102;&#33719;&#24471;&#38544;&#31169;&#32780;&#29306;&#29298;&#20102;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#31934;&#30830;&#19988;&#24555;&#36895;&#30340;DP MH&#31639;&#27861;&#65292;&#22823;&#22810;&#25968;&#36845;&#20195;&#20013;&#20165;&#20351;&#29992;&#19968;&#20010;&#23567;&#25209;&#37327;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#38544;&#31169;&#12289;&#21487;&#25193;&#23637;&#24615;&#65288;&#21363;&#25209;&#37327;&#22823;&#23567;&#65289;&#21644;&#25928;&#29575;&#65288;&#21363;&#25910;&#25947;&#36895;&#24230;&#65289;&#20043;&#38388;&#30340;&#19977;&#37325;&#26435;&#34913;&#65292;&#20174;&#29702;&#35770;&#19978;&#35828;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference provides a principled framework for learning from complex data and reasoning under uncertainty. It has been widely applied in machine learning tasks such as medical diagnosis, drug design, and policymaking. In these common applications, the data can be highly sensitive. Differential privacy (DP) offers data analysis tools with powerful worst-case privacy guarantees and has been developed as the leading approach in privacy-preserving data analysis. In this paper, we study Metropolis-Hastings (MH), one of the most fundamental MCMC methods, for large-scale Bayesian inference under differential privacy. While most existing private MCMC algorithms sacrifice accuracy and efficiency to obtain privacy, we provide the first exact and fast DP MH algorithm, using only a minibatch of data in most iterations. We further reveal, for the first time, a three-way trade-off among privacy, scalability (i.e. the batch size), and efficiency (i.e. the convergence rate), theoretically char
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#25193;&#23637;&#20102;VAE&#27169;&#22411;&#23481;&#37327;&#65292;&#37319;&#29992;&#26080;&#38480;&#28151;&#21512;&#30340;&#38750;&#23545;&#31216;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#20316;&#20026;&#35299;&#30721;&#22120;&#65292;&#20855;&#26377;&#20998;&#24067;&#25311;&#21512;&#33021;&#21147;&#21644;&#35843;&#25972;&#25968;&#25454;&#38544;&#31169;&#32423;&#21035;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.11294</link><description>&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#65306;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation. (arXiv:2302.11294v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11294
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#25193;&#23637;&#20102;VAE&#27169;&#22411;&#23481;&#37327;&#65292;&#37319;&#29992;&#26080;&#38480;&#28151;&#21512;&#30340;&#38750;&#23545;&#31216;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#20316;&#20026;&#35299;&#30721;&#22120;&#65292;&#20855;&#26377;&#20998;&#24067;&#25311;&#21512;&#33021;&#21147;&#21644;&#35843;&#25972;&#25968;&#25454;&#38544;&#31169;&#32423;&#21035;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#22312;&#35745;&#31639;&#24314;&#27169;&#26041;&#38754;&#24456;&#39640;&#25928;&#65292;&#20294;&#39640;&#26031;&#20551;&#35774;&#19968;&#30452;&#34987;&#35748;&#20026;&#26159;&#23427;&#30340;&#20027;&#35201;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#27169;&#22411;&#23481;&#37327;&#65288;&#21363;&#20998;&#24067;&#26063;&#30340;&#34920;&#36798;&#33021;&#21147;&#65289;&#65292;&#32780;&#19981;&#20250;&#29306;&#29298;VAE&#26694;&#26550;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;VAE&#27169;&#22411;&#30340;&#35299;&#30721;&#22120;&#30001;&#26080;&#38480;&#32452;&#21512;&#30340;&#38750;&#23545;&#31216;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#26500;&#25104;&#65292;&#20855;&#26377;&#36830;&#32493;&#21464;&#37327;&#30340;&#20998;&#24067;&#25311;&#21512;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#30001;&#20272;&#35745;&#19968;&#33324;&#20998;&#20301;&#20989;&#25968;&#30340;&#38750;&#21442;&#25968;M-estimator&#30340;&#29305;&#27530;&#24418;&#24335;&#34920;&#31034;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#27169;&#22411;&#19982;&#20998;&#20301;&#25968;&#20272;&#35745;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#24212;&#29992;&#20110;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#65292;&#29305;&#21035;&#26159;&#22312;&#36731;&#26494;&#35843;&#25972;&#25968;&#25454;&#38544;&#31169;&#32423;&#21035;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23637;&#29616;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Gaussianity assumption has been consistently criticized as a main limitation of the Variational Autoencoder (VAE), despite its efficiency in computational modeling. In this paper, we propose a new approach that expands the model capacity (i.e., expressive power of distributional family) without sacrificing the computational advantages of the VAE framework. Our VAE model's decoder is composed of an infinite mixture of asymmetric Laplacian distribution, which possesses general distribution fitting capabilities for continuous variables. Our model is represented by a special form of a nonparametric M-estimator for estimating general quantile functions, and we theoretically establish the relevance between the proposed model and quantile estimation. We apply the proposed model to synthetic data generation, and particularly, our model demonstrates superiority in easily adjusting the level of data privacy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#38024;&#23545; AdaGrad &#27493;&#24133;&#19979;&#30340;SGD&#31639;&#27861;&#30340;&#26356;&#21152;&#20840;&#38754;&#19988;&#26080;&#38480;&#21046;&#24615;&#30340;&#20998;&#26512;&#65292;&#25903;&#25345;&#22810;&#31181;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#39640;&#27010;&#29575;&#19979;&#22788;&#29702;&#26410;&#30693;&#21442;&#25968;&#21644;&#26080;&#30028;&#26799;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.08783</link><description>&lt;p&gt;
AdaGrad &#27493;&#24133;&#19979;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65306;&#23545;&#26410;&#30693;&#21442;&#25968;&#12289;&#26080;&#30028;&#26799;&#24230;&#21644;&#20223;&#23556;&#26041;&#24046;&#30340;&#20840;&#36866;&#24212;&#24615;&#39640;&#27010;&#29575;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
SGD with AdaGrad Stepsizes: Full Adaptivity with High Probability to Unknown Parameters, Unbounded Gradients and Affine Variance. (arXiv:2302.08783v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08783
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#38024;&#23545; AdaGrad &#27493;&#24133;&#19979;&#30340;SGD&#31639;&#27861;&#30340;&#26356;&#21152;&#20840;&#38754;&#19988;&#26080;&#38480;&#21046;&#24615;&#30340;&#20998;&#26512;&#65292;&#25903;&#25345;&#22810;&#31181;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#39640;&#27010;&#29575;&#19979;&#22788;&#29702;&#26410;&#30693;&#21442;&#25968;&#21644;&#26080;&#30028;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102; AdaGrad &#27493;&#24133;&#19979;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65306;&#36825;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#33258;&#36866;&#24212; (&#33258;&#35843;&#33410;) &#30340;&#19968;&#38454;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#12290;&#23613;&#31649;&#32463;&#36807;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#29616;&#26377;&#30340;&#20998;&#26512;&#26041;&#27861;&#23384;&#22312;&#21508;&#31181;&#32570;&#38519;&#65306;&#23427;&#20204;&#35201;&#20040;&#20551;&#23450;&#23545;&#38382;&#39064;&#21442;&#25968;&#26377;&#19968;&#23450;&#30340;&#20102;&#35299;&#65292;&#35201;&#20040;&#35774;&#23450;&#24378;&#30340;&#20840;&#23616;&#21033;&#26222;&#24076;&#33576;&#26465;&#20214;&#65292;&#25110;&#32773;&#19981;&#33021;&#32473;&#20986;&#39640;&#27010;&#29575;&#21487;&#38752;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#22312;&#20984;&#21644;&#38750;&#20984; (&#24179;&#28369;) &#24773;&#20917;&#19979;&#65292;&#23545;&#36825;&#31181;&#22522;&#26412;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#26080;&#20219;&#20309;&#38480;&#21046;&#22320;&#20998;&#26512;&#65292;&#21478;&#22806;&#25903;&#25345;&#19968;&#33324;&#30340;&#8220;&#20223;&#23556;&#26041;&#24046;&#8221;&#22122;&#22768;&#27169;&#22411;&#65292;&#24182;&#22312;&#20302;&#22122;&#22768;&#21644;&#39640;&#22122;&#22768;&#21306;&#22495;&#20013;&#25552;&#20379;&#38160;&#21033;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study Stochastic Gradient Descent with AdaGrad stepsizes: a popular adaptive (self-tuning) method for first-order stochastic optimization. Despite being well studied, existing analyses of this method suffer from various shortcomings: they either assume some knowledge of the problem parameters, impose strong global Lipschitz conditions, or fail to give bounds that hold with high probability. We provide a comprehensive analysis of this basic method without any of these limitations, in both the convex and non-convex (smooth) cases, that additionally supports a general ``affine variance'' noise model and provides sharp rates of convergence in both the low-noise and high-noise~regimes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19978;&#19979;&#25991;Bandits&#20013;&#23398;&#20064;&#30340;&#22522;&#26412;&#26497;&#38480;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#21487;&#23398;&#20064;&#30340;&#19978;&#19979;&#25991;&#36807;&#31243;&#21644;&#36890;&#29992;&#19968;&#33268;&#24615;&#31639;&#27861;&#30340;&#29305;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#23545;&#25239;&#22870;&#21169;&#19979;&#30340;&#20048;&#35266;&#36890;&#29992;&#19968;&#33268;&#24615;&#23398;&#20064;&#30340;&#19981;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.07186</link><description>&lt;p&gt;
&#36890;&#29992;&#23398;&#20064;&#20013;&#23545;&#25239;&#22870;&#21169;&#22312;&#19978;&#19979;&#25991;Bandits&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Adversarial Rewards in Universal Learning for Contextual Bandits. (arXiv:2302.07186v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19978;&#19979;&#25991;Bandits&#20013;&#23398;&#20064;&#30340;&#22522;&#26412;&#26497;&#38480;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#21487;&#23398;&#20064;&#30340;&#19978;&#19979;&#25991;&#36807;&#31243;&#21644;&#36890;&#29992;&#19968;&#33268;&#24615;&#31639;&#27861;&#30340;&#29305;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#23545;&#25239;&#22870;&#21169;&#19979;&#30340;&#20048;&#35266;&#36890;&#29992;&#19968;&#33268;&#24615;&#23398;&#20064;&#30340;&#19981;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;Bandits&#20013;&#23398;&#20064;&#30340;&#22522;&#26412;&#26497;&#38480;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#30340;&#22870;&#21169;&#21462;&#20915;&#20110;&#20854;&#34892;&#20026;&#21644;&#24050;&#30693;&#19978;&#19979;&#25991;&#65292;&#36825;&#25193;&#23637;&#20102;&#32463;&#20856;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#65292;&#22312;&#26377;&#38468;&#21152;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#23545;&#33021;&#22815;&#23454;&#29616;&#20122;&#32447;&#24615;&#36951;&#25022;&#30340;&#36890;&#29992;&#19968;&#33268;&#24615;&#31639;&#27861;&#24863;&#20852;&#36259;&#65292;&#30456;&#23545;&#20110;&#20219;&#20309;&#21487;&#27979;&#23450;&#30340;&#22266;&#23450;&#31574;&#30053;&#65292;&#26080;&#38656;&#20219;&#20309;&#21151;&#33021;&#31867;&#38480;&#21046;&#12290;&#28982;&#32780;&#65292;&#22870;&#21169;&#26426;&#21046;&#21487;&#20197;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#21457;&#29983;&#21464;&#21270;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23545;&#25239;&#22870;&#21169;&#19979;&#65292;&#19978;&#19979;&#25991;Bandits&#30340;&#20048;&#35266;&#36890;&#29992;&#19968;&#33268;&#24615;&#23398;&#20064;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the fundamental limits of learning in contextual bandits, where a learner's rewards depend on their actions and a known context, which extends the canonical multi-armed bandit to the case where side-information is available. We are interested in universally consistent algorithms, which achieve sublinear regret compared to any measurable fixed policy, without any function class restriction. For stationary contextual bandits, when the underlying reward mechanism is time-invariant, Blanchard et. al (2022) characterized learnable context processes for which universal consistency is achievable; and further gave algorithms ensuring universal consistency whenever this is achievable, a property known as optimistic universal consistency. It is well understood, however, that reward mechanisms can evolve over time, possibly adversarially, and depending on the learner's actions. We show that optimistic universal learning for contextual bandits with adversarial rewards is impossible in gen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#65292;&#23427;&#20351;&#29992;&#27985;&#25311;&#22278;&#20915;&#31574;&#36793;&#30028;&#21487;&#20197;&#20248;&#21270;&#27979;&#22320;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#31454;&#20105;&#24615;&#33021;&#20248;&#36234;&#12290;</title><link>http://arxiv.org/abs/2302.06807</link><description>&lt;p&gt;
&#36229;&#20284;&#26354;&#31354;&#38388;&#30340;&#22823;&#38388;&#38548;&#20998;&#31867;&#30340;&#27985;&#25311;&#22278;&#20915;&#31574;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space. (arXiv:2302.06807v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#65292;&#23427;&#20351;&#29992;&#27985;&#25311;&#22278;&#20915;&#31574;&#36793;&#30028;&#21487;&#20197;&#20248;&#21270;&#27979;&#22320;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#31454;&#20105;&#24615;&#33021;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29992;&#36229;&#20284;&#26354;&#31354;&#38388;&#34920;&#31034;&#23618;&#27425;&#32467;&#26500;&#21270;&#25968;&#25454;&#24050;&#32463;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#21516;&#26102;&#65292;&#25991;&#29486;&#20013;&#20063;&#25552;&#20986;&#20102;&#20960;&#20010;&#38024;&#23545;&#36825;&#20123;&#31354;&#38388;&#20013;&#25968;&#25454;&#20998;&#31867;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#20027;&#35201;&#20351;&#29992;&#36229;&#24179;&#38754;&#25110;&#27979;&#22320;&#32447;&#20316;&#20026;&#20915;&#31574;&#36793;&#30028;&#65292;&#20351;&#29992;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#35774;&#32622;&#65292;&#20174;&#32780;&#23548;&#33268;&#19968;&#20010;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27985;&#25311;&#22278;&#20915;&#31574;&#36793;&#30028;&#30340;&#26032;&#22411;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#65292;&#23427;&#21487;&#20197;&#23548;&#33268;&#19968;&#20010;&#27979;&#22320;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#20219;&#20309;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#25216;&#26415;&#26469;&#20248;&#21270;&#65292;&#20445;&#35777;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20998;&#31867;&#22120;&#30456;&#27604;&#20110; SOTA &#30340;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hyperbolic spaces have been quite popular in the recent past for representing hierarchically organized data. Further, several classification algorithms for data in these spaces have been proposed in the literature. These algorithms mainly use either hyperplanes or geodesics for decision boundaries in a large margin classifiers setting leading to a non-convex optimization problem. In this paper, we propose a novel large margin classifier based on horospherical decision boundaries that leads to a geodesically convex optimization problem that can be optimized using any Riemannian gradient descent technique guaranteeing a globally optimal solution. We present several experiments depicting the competitive performance of our classifier in comparison to SOTA.
&lt;/p&gt;</description></item><item><title>XPER&#26041;&#27861;&#33021;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#65292;&#24182;&#21487;&#29992;&#20110;&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#26500;&#24314;&#21516;&#36136;&#21270;&#20010;&#20307;&#32676;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2212.05866</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#24615;&#33021;&#65306;&#34913;&#37327;&#39044;&#27979;&#24615;&#33021;&#30340;&#39537;&#21160;&#21147;
&lt;/p&gt;
&lt;p&gt;
Explainable Performance: Measuring the Driving Forces of Predictive Performance. (arXiv:2212.05866v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05866
&lt;/p&gt;
&lt;p&gt;
XPER&#26041;&#27861;&#33021;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#65292;&#24182;&#21487;&#29992;&#20110;&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#26500;&#24314;&#21516;&#36136;&#21270;&#20010;&#20307;&#32676;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;XPER&#65288;eXplainable PERformance&#65289;&#26041;&#27861;&#26469;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#22522;&#20110;Shapley&#20540;&#65292;&#26082;&#19981;&#20381;&#36182;&#20110;&#27169;&#22411;&#65292;&#20063;&#19981;&#20381;&#36182;&#20110;&#24615;&#33021;&#24230;&#37327;&#12290;&#27492;&#22806;&#65292;XPER&#21487;&#22312;&#27169;&#22411;&#32423;&#21035;&#25110;&#20010;&#20307;&#32423;&#21035;&#23454;&#29616;&#12290;&#25105;&#20204;&#35777;&#26126;XPER&#20855;&#26377;&#26631;&#20934;&#35299;&#37322;&#24615;&#26041;&#27861;&#65288;SHAP&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;&#22312;&#36151;&#27454;&#36829;&#32422;&#39044;&#27979;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;XPER&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#22806;&#24615;&#33021;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#20010;&#20307;XPER&#20540;&#23545;&#20182;&#20204;&#36827;&#34892;&#32858;&#31867;&#26469;&#26500;&#24314;&#21516;&#36136;&#21270;&#30340;&#20010;&#20307;&#32676;&#20307;&#12290;&#25105;&#20204;&#21457;&#29616;&#20272;&#35745;&#32676;&#20307;&#29305;&#23450;&#30340;&#27169;&#22411;&#27604;&#19968;&#20010;&#27169;&#22411;&#36866;&#29992;&#20110;&#25152;&#26377;&#20010;&#20307;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the XPER (eXplainable PERformance) methodology to measure the specific contribution of the input features to the predictive performance of a model. Our methodology is theoretically grounded on Shapley values and is both model-agnostic and performance metric-agnostic. Furthermore, XPER can be implemented either at the model level or at the individual level. We demonstrate that XPER has as a special case the standard explainability method in machine learning (SHAP). In a loan default forecasting application, we show how XPER can be used to deal with heterogeneity issues and significantly boost out-of-sample performance. To do so, we build homogeneous groups of individuals by clustering them based on their individual XPER values. We find that estimating group-specific models yields a much higher predictive accuracy than with a one-fits-all model.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21333;&#20010;&#26799;&#24230;&#26597;&#35810;&#21487;&#37325;&#26500;&#35757;&#32451;&#25968;&#25454;&#65292;&#23384;&#22312;&#38544;&#31169;&#27844;&#38706;&#23041;&#32961;&#12290;</title><link>http://arxiv.org/abs/2212.03714</link><description>&lt;p&gt;
&#20174;&#27169;&#22411;&#26799;&#24230;&#37325;&#26500;&#35757;&#32451;&#25968;&#25454;&#65292;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reconstructing Training Data from Model Gradient, Provably. (arXiv:2212.03714v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.03714
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21333;&#20010;&#26799;&#24230;&#26597;&#35810;&#21487;&#37325;&#26500;&#35757;&#32451;&#25968;&#25454;&#65292;&#23384;&#22312;&#38544;&#31169;&#27844;&#38706;&#23041;&#32961;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38544;&#31169;&#26041;&#38754;&#65292;&#29702;&#35299;&#27169;&#22411;&#26799;&#24230;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#27844;&#38706;&#26377;&#20851;&#35757;&#32451;&#26679;&#26412;&#30340;&#20449;&#24687;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#65306;&#21363;&#20351;&#27809;&#26377;&#35757;&#32451;&#25110;&#35760;&#24518;&#25968;&#25454;&#65292;&#25105;&#20204;&#20063;&#21487;&#20197;&#20174;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#21442;&#25968;&#20540;&#22788;&#36827;&#34892;&#30340;&#21333;&#20010;&#26799;&#24230;&#26597;&#35810;&#20013;&#23436;&#20840;&#37325;&#26500;&#35757;&#32451;&#26679;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#21487;&#35782;&#21035;&#24615;&#65306;&#20351;&#29992;&#27973;&#23618;&#25110;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21508;&#31181;&#28608;&#27963;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#39640;&#25928;&#31639;&#27861;&#26469;&#37325;&#26500;&#35757;&#32451;&#25968;&#25454;&#12290;&#20316;&#20026;&#25581;&#31034;&#25935;&#24863;&#35757;&#32451;&#25968;&#25454;&#30340;&#21487;&#35777;&#26126;&#25915;&#20987;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#20102;&#23545;&#38544;&#31169;&#30340;&#28508;&#22312;&#20005;&#37325;&#23041;&#32961;&#65292;&#23588;&#20854;&#26159;&#22312;&#32852;&#21512;&#23398;&#20064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding when and how much a model gradient leaks information about the training sample is an important question in privacy. In this paper, we present a surprising result: even without training or memorizing the data, we can fully reconstruct the training samples from a single gradient query at a randomly chosen parameter value. We prove the identifiability of the training data under mild conditions: with shallow or deep neural networks and a wide range of activation functions. We also present a statistically and computationally efficient algorithm based on tensor decomposition to reconstruct the training data. As a provable attack that reveals sensitive training data, our findings suggest potential severe threats to privacy, especially in federated learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#32447;&#24615;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20013;&#30340;&#22240;&#26524;&#20998;&#31163;&#38382;&#39064;&#65292;&#25351;&#20986;&#23545;&#20110;&#35782;&#21035;&#24615;&#24178;&#39044;&#25968;&#25454;&#26159;&#24517;&#35201;&#30340;&#65292;&#32780;&#27599;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#21333;&#19968;&#24178;&#39044;&#23601;&#36275;&#22815;&#20102;&#12290;</title><link>http://arxiv.org/abs/2211.16467</link><description>&lt;p&gt;
&#32447;&#24615;&#24178;&#39044;&#19979;&#30340;&#22240;&#26524;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Linear Causal Disentanglement via Interventions. (arXiv:2211.16467v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#32447;&#24615;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20013;&#30340;&#22240;&#26524;&#20998;&#31163;&#38382;&#39064;&#65292;&#25351;&#20986;&#23545;&#20110;&#35782;&#21035;&#24615;&#24178;&#39044;&#25968;&#25454;&#26159;&#24517;&#35201;&#30340;&#65292;&#32780;&#27599;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#21333;&#19968;&#24178;&#39044;&#23601;&#36275;&#22815;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#20998;&#31163;&#26088;&#22312;&#36890;&#36807;&#19968;&#20010;&#22240;&#26524;&#27169;&#22411;&#26469;&#34920;&#31034;&#28041;&#21450;&#30340;&#28508;&#22312;&#21464;&#37327;&#12290;&#22914;&#26524;&#28508;&#22312;&#27169;&#22411;&#21644;&#20174;&#28508;&#22312;&#21464;&#37327;&#21040;&#35266;&#27979;&#21464;&#37327;&#30340;&#36716;&#25442;&#37117;&#26159;&#21807;&#19968;&#30340;&#65292;&#21017;&#34920;&#31034;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#35266;&#27979;&#21464;&#37327;&#26159;&#32447;&#24615;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32447;&#24615;&#36716;&#25442;&#12290;&#23545;&#20110;&#35782;&#21035;&#24615;&#65292;&#24178;&#39044;&#25968;&#25454;&#26159;&#24517;&#35201;&#30340;&#65306;&#22914;&#26524;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#32570;&#23569;&#24178;&#39044;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#23384;&#22312;&#26080;&#27861;&#21306;&#20998;&#30340;&#19981;&#21516;&#27169;&#22411;&#12290;&#21453;&#20043;&#65292;&#25105;&#20204;&#23637;&#31034;&#27599;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#21333;&#19968;&#24178;&#39044;&#23601;&#36275;&#22815;&#20102;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20351;&#29992;&#20102;&#19968;&#20010;&#30697;&#38453;&#30340;RQ&#20998;&#35299;&#30340;&#25512;&#24191;&#65292;&#21462;&#20195;&#20102;&#36890;&#24120;&#30340;&#27491;&#20132;&#21644;&#19978;&#19977;&#35282;&#26465;&#20214;&#65292;&#32780;&#26159;&#29992;&#22522;&#20110;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#30830;&#23450;&#30340;&#34892;&#30340;&#20559;&#24207;&#30340;&#31867;&#20284;&#26465;&#20214;&#12290;&#25105;&#20204;&#21033;&#29992;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#20998;&#31163;&#30340;&#26041;&#27861;&#26469;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal disentanglement seeks a representation of data involving latent variables that relate to one another via a causal model. A representation is identifiable if both the latent model and the transformation from latent to observed variables are unique. In this paper, we study observed variables that are a linear transformation of a linear latent causal model. Data from interventions are necessary for identifiability: if one latent variable is missing an intervention, we show that there exist distinct models that cannot be distinguished. Conversely, we show that a single intervention on each latent variable is sufficient for identifiability. Our proof uses a generalization of the RQ decomposition of a matrix that replaces the usual orthogonal and upper triangular conditions with analogues depending on a partial order on the rows of the matrix, with partial order determined by a latent causal model. We corroborate our theoretical results with a method for causal disentanglement that ac
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#26377;&#36164;&#28304;&#32447;&#24615;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#36739;&#20302;&#30340;&#21518;&#24724;&#12290;&#27492;&#22806;&#65292;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#31639;&#27861;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2211.07484</link><description>&lt;p&gt;
&#24102;&#35013;&#36733;&#21644;&#35206;&#30422;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#65306;&#22522;&#20110;&#22238;&#24402;&#30340;&#27169;&#22359;&#21270;Lagrangian&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression. (arXiv:2211.07484v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07484
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#26377;&#36164;&#28304;&#32447;&#24615;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#36739;&#20302;&#30340;&#21518;&#24724;&#12290;&#27492;&#22806;&#65292;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#31639;&#27861;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#20854;&#20013;&#31639;&#27861;&#22312;&#24635;&#28040;&#36153;&#30340;&#32447;&#24615;&#32422;&#26463;&#19979;&#20351;&#29992;&#22810;&#20010;&#36164;&#28304;&#12290;&#36825;&#20010;&#38382;&#39064;&#25512;&#24191;&#20102;&#24102;&#32972;&#21253;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;(CBwK)&#65292;&#20801;&#35768;&#35013;&#36733;&#21644;&#35206;&#30422;&#32422;&#26463;&#65292;&#20197;&#21450;&#27491;&#36127;&#36164;&#28304;&#28040;&#32791;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#33021;&#22815;&#23454;&#29616;&#36864;&#21270;&#30340;&#21518;&#24724;&#12290;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#23545;&#20110;CBwK&#65292;&#23427;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;LagrangianBwK(Immorlica&#31561;&#20154;&#65292;FOCS 2019)&#65292;&#36825;&#26159;&#19968;&#31181;&#38754;&#21521;CBwK&#30340;Lagrangian&#25216;&#26415;&#65292;&#20197;&#21450;SquareCB(Foster&#21644;Rakhlin&#65292;ICML 2020)&#65292;&#36825;&#26159;&#19968;&#31181;&#38754;&#21521;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#30340;&#22238;&#24402;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21033;&#29992;&#20102;&#20004;&#31181;&#25216;&#26415;&#26412;&#36136;&#19978;&#30340;&#27169;&#22359;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We present a new algorithm that is simple, computationally efficient, and admits vanishing regret. It is statistically optimal for CBwK when an algorithm must stop once some constraint is violated. Our algorithm builds on LagrangeBwK (Immorlica et al., FOCS 2019) , a Lagrangian-based technique for CBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#25191;&#34892;&#25512;&#29702;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#25351;&#23450;&#39640;&#32500;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26063;&#26102;&#30340;&#38480;&#21046;&#65292;&#21487;&#20197;&#26080;&#32541;&#33719;&#21462;&#21644;&#34920;&#31034;&#22797;&#26434;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2210.13319</link><description>&lt;p&gt;
MARS: &#20989;&#25968;&#31354;&#38388;&#20013;&#22522;&#20110;&#20998;&#25968;&#21305;&#37197;&#30340;&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MARS: Meta-Learning as Score Matching in the Function Space. (arXiv:2210.13319v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13319
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#25191;&#34892;&#25512;&#29702;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#25351;&#23450;&#39640;&#32500;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26063;&#26102;&#30340;&#38480;&#21046;&#65292;&#21487;&#20197;&#26080;&#32541;&#33719;&#21462;&#21644;&#34920;&#31034;&#22797;&#26434;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20803;&#23398;&#20064;&#26088;&#22312;&#20174;&#19968;&#32452;&#30456;&#20851;&#30340;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#26377;&#29992;&#30340;&#24402;&#32435;&#20559;&#32622;&#12290;&#22312;&#36125;&#21494;&#26031;&#20803;&#23398;&#20064;&#20013;&#65292;&#36890;&#24120;&#36890;&#36807;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#28982;&#32780;&#65292;&#25351;&#23450;&#19968;&#32452;&#21487;&#34892;&#30340;&#39640;&#32500;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26063;&#26159;&#22256;&#38590;&#30340;&#12290;&#22240;&#27492;&#65292;&#29616;&#26377;&#26041;&#27861;&#37319;&#29992;&#20803;&#23398;&#20064;&#38480;&#21046;&#24615;&#30340;&#23545;&#35282;&#39640;&#26031;&#20808;&#39564;&#65292;&#20005;&#37325;&#38480;&#21046;&#20102;&#20854;&#34920;&#36798;&#33021;&#21147;&#21644;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#36890;&#36807;&#20989;&#25968;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25512;&#29702;&#30340;&#35270;&#35282;&#26469;&#30475;&#24453;&#20803;&#23398;&#20064;&#65292;&#23558;&#20808;&#39564;&#35270;&#20026;&#38543;&#26426;&#36807;&#31243;&#65292;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#25191;&#34892;&#25512;&#29702;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#20803;&#35757;&#32451;&#20219;&#21153;&#35270;&#20026;&#20174;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#26679;&#26412;&#65292;&#24182;&#23558;&#20803;&#23398;&#20064;&#24418;&#24335;&#21270;&#20026;&#32463;&#39564;&#20272;&#35745;&#36825;&#20010;&#38543;&#26426;&#36807;&#31243;&#30340;&#23450;&#24459;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#20803;&#23398;&#20064;&#20998;&#25968;&#20989;&#25968;&#65292;&#26080;&#32541;&#33719;&#21462;&#21644;&#34920;&#31034;&#22797;&#26434;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meta-learning aims to extract useful inductive biases from a set of related datasets. In Bayesian meta-learning, this is typically achieved by constructing a prior distribution over neural network parameters. However, specifying families of computationally viable prior distributions over the high-dimensional neural network parameters is difficult. As a result, existing approaches resort to meta-learning restrictive diagonal Gaussian priors, severely limiting their expressiveness and performance. To circumvent these issues, we approach meta-learning through the lens of functional Bayesian neural network inference, which views the prior as a stochastic process and performs inference in the function space. Specifically, we view the meta-training tasks as samples from the data-generating process and formalize meta-learning as empirically estimating the law of this stochastic process. Our approach can seamlessly acquire and represent complex prior knowledge by meta-learning the score functi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#28608;&#27963;&#22270;&#30340;&#31232;&#30095;&#29616;&#35937;&#65292;&#21457;&#29616;&#22312;&#19981;&#21516;&#23618;&#25968;&#30340;&#21464;&#21387;&#22120;&#37197;&#32622;&#21644;&#20854;&#20182;&#20307;&#31995;&#32467;&#26500;&#20013;&#37117;&#20986;&#29616;&#20102;&#31232;&#30095;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2210.06313</link><description>&lt;p&gt;
&#24608;&#24816;&#31070;&#32463;&#20803;&#29616;&#35937;&#65306;&#21464;&#21387;&#22120;&#27169;&#22411;&#28608;&#27963;&#31232;&#30095;&#24615;&#30340;&#20986;&#29616;
&lt;/p&gt;
&lt;p&gt;
The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers. (arXiv:2210.06313v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#28608;&#27963;&#22270;&#30340;&#31232;&#30095;&#29616;&#35937;&#65292;&#21457;&#29616;&#22312;&#19981;&#21516;&#23618;&#25968;&#30340;&#21464;&#21387;&#22120;&#37197;&#32622;&#21644;&#20854;&#20182;&#20307;&#31995;&#32467;&#26500;&#20013;&#37117;&#20986;&#29616;&#20102;&#31232;&#30095;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21464;&#21387;&#22120;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#28608;&#27963;&#22270;&#31232;&#30095;&#30340;&#22855;&#29305;&#29616;&#35937;&#12290;&#25105;&#20204;&#36890;&#36807;&#20013;&#38388;&#23618;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#36755;&#20986;&#26469;&#34920;&#31034;&#28608;&#27963;&#22270;&#65292;&#31232;&#30095;&#26159;&#25351;&#24179;&#22343;&#24773;&#20917;&#19979;&#27599;&#20010;&#36755;&#20837;&#21040;MLP&#30340;&#38750;&#38646;&#20803;&#32032;&#38750;&#24120;&#23569;&#65288;&#20363;&#22914;&#65292;T5-Base&#20026;3.0&#65285;&#65292;ViT-B16&#20026;6.3&#65285;&#65289;&#12290;&#27492;&#22806;&#65292;&#36739;&#22823;&#30340;&#21464;&#21387;&#22120;&#21644;&#26356;&#23485;&#30340;MLP&#38544;&#34255;&#23618;&#32500;&#24230;&#20250;&#20135;&#29983;&#26356;&#31232;&#30095;&#30340;&#28608;&#27963;&#22270;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#31232;&#30095;&#30340;&#20986;&#29616;&#26159;&#19968;&#31181;&#26222;&#36941;&#29616;&#35937;&#65292;&#23427;&#20986;&#29616;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35270;&#35273;&#20219;&#21153;&#20013;&#65292;&#20986;&#29616;&#22312;&#35757;&#32451;&#21644;&#35780;&#20272;&#25968;&#25454;&#20013;&#65292;&#22312;&#19981;&#21516;&#23618;&#25968;&#30340;&#21464;&#21387;&#22120;&#37197;&#32622;&#21644;&#20854;&#20182;&#20307;&#31995;&#32467;&#26500;&#20013;&#65292;&#20063;&#21253;&#25324;MLP-&#28151;&#21512;&#22120;&#21644;2&#23618;MLP&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#20351;&#29992;&#20855;&#26377;&#38543;&#26426;&#26631;&#31614;&#25110;&#38543;&#26426;&#36755;&#20837;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#20063;&#20250;&#20986;&#29616;&#31232;&#30095;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the curious phenomenon for machine learning models with Transformer architectures that their activation maps are sparse. By activation map we refer to the intermediate output of the multi-layer perceptrons (MLPs) after a ReLU activation function, and by sparse we mean that on average very few entries (e.g., 3.0% for T5-Base and 6.3% for ViT-B16) are nonzero for each input to MLP. Moreover, larger Transformers with more layers and wider MLP hidden dimensions are sparser as measured by the percentage of nonzero entries. Through extensive experiments we demonstrate that the emergence of sparsity is a prevalent phenomenon that occurs for both natural language processing and vision tasks, on both training and evaluation data, for Transformers of various configurations, at layers of all depth levels, as well as for other architectures including MLP-mixers and 2-layer MLPs. We show that sparsity also emerges using training datasets with random labels, or with random inputs,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#36890;&#36807;&#20803;&#23398;&#20064;&#20808;&#39564;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#23454;&#29616;&#23433;&#20840;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21516;&#26102;&#24320;&#21457;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#36873;&#25321;&#31526;&#21512;&#23433;&#20840;&#35201;&#27714;&#30340;&#20808;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20934;&#26041;&#27861;&#65292;&#20803;&#23398;&#20064;&#20808;&#39564;&#21152;&#24555;&#20102;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24182;&#25913;&#36827;&#20102;&#25972;&#20307;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.00762</link><description>&lt;p&gt;
&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#20803;&#23398;&#20064;&#20808;&#39564;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Priors for Safe Bayesian Optimization. (arXiv:2210.00762v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#36890;&#36807;&#20803;&#23398;&#20064;&#20808;&#39564;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#23454;&#29616;&#23433;&#20840;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21516;&#26102;&#24320;&#21457;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#36873;&#25321;&#31526;&#21512;&#23433;&#20840;&#35201;&#27714;&#30340;&#20808;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20934;&#26041;&#27861;&#65292;&#20803;&#23398;&#20064;&#20808;&#39564;&#21152;&#24555;&#20102;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24182;&#25913;&#36827;&#20102;&#25972;&#20307;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#20154;&#23398;&#20013;&#65292;&#20248;&#21270;&#25511;&#21046;&#22120;&#21442;&#25968;&#24182;&#28385;&#36275;&#23433;&#20840;&#32422;&#26463;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#37327;&#21270;&#30446;&#26631;&#21644;&#32422;&#26463;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#23433;&#20840;&#22320;&#25351;&#23548;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#22312;&#23384;&#22312;&#26410;&#30693;&#23433;&#20840;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#36873;&#25321;&#21487;&#38752;&#30340;&#27169;&#22411;&#36229;&#21442;&#25968;&#20197;&#36991;&#20813;&#23433;&#20840;&#36829;&#35268;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#20154;&#24037;&#35774;&#35745;&#36866;&#21512;&#30340;&#27010;&#29575;&#27169;&#22411;&#21487;&#33021;&#24456;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20803;&#23398;&#20064;&#20808;&#39564;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#23454;&#29616;&#23433;&#20840;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#25105;&#20204;&#20511;&#21161;&#20803;&#23398;&#20064;&#31639;&#27861; F-PACOH&#65292;&#22312;&#25968;&#25454;&#31232;&#32570;&#24615;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#21516;&#26102;&#65292;&#22312;&#22522;&#20934;&#20989;&#25968;&#21644;&#39640;&#31934;&#24230;&#36816;&#21160;&#31995;&#32479;&#19978;&#65292;&#25105;&#20204;&#36890;&#36807;&#32463;&#39564;&#19981;&#30830;&#23450;&#24230;&#24230;&#37327;&#21644;&#21069;&#27839;&#25628;&#32034;&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#36873;&#25321;&#31526;&#21512;&#23433;&#20840;&#35201;&#27714;&#30340;&#20808;&#39564;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#20803;&#23398;&#20064;&#20808;&#39564;&#21152;&#24555;&#20102;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24182;&#25913;&#36827;&#20102;&#25972;&#20307;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In robotics, optimizing controller parameters under safety constraints is an important challenge. Safe Bayesian optimization (BO) quantifies uncertainty in the objective and constraints to safely guide exploration in such settings. Hand-designing a suitable probabilistic model can be challenging, however. In the presence of unknown safety constraints, it is crucial to choose reliable model hyper-parameters to avoid safety violations. Here, we propose a data-driven approach to this problem by meta-learning priors for safe BO from offline data. We build on a meta-learning algorithm, F-PACOH, capable of providing reliable uncertainty quantification in settings of data scarcity. As core contribution, we develop a novel framework for choosing safety-compliant priors in a data-riven manner via empirical uncertainty metrics and a frontier search algorithm. On benchmark functions and a high-precision motion system, we demonstrate that our meta-learned priors accelerate the convergence of safe 
&lt;/p&gt;</description></item><item><title>SoccerCPD&#26159;&#19968;&#20010;&#26032;&#30340;&#36275;&#29699;&#27604;&#36187;&#21464;&#28857;&#26816;&#27979;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;&#36275;&#29699;&#27604;&#36187;&#20013;&#30340;&#31574;&#30053;&#24847;&#22270;&#38453;&#22411;&#21644;&#35282;&#33394;&#21464;&#21270;&#19982;&#20020;&#26102;&#21464;&#21270;&#21306;&#20998;&#24320;&#26469;&#12290;&#35813;&#26694;&#26550;&#30340;&#20004;&#27493;&#21464;&#28857;&#26816;&#27979;&#22312;&#39046;&#22495;&#19987;&#23478;&#27880;&#37322;&#22522;&#30784;&#19978;&#36827;&#34892;&#39564;&#35777;&#65292;&#32467;&#26524;&#26174;&#31034;&#23427;&#21487;&#20197;&#20934;&#30830;&#26816;&#27979;&#25112;&#26415;&#21464;&#21270;&#24182;&#20272;&#35745;&#27599;&#31186;&#30340;&#38453;&#22411;&#21644;&#35282;&#33394;&#20998;&#37197;&#12290;</title><link>http://arxiv.org/abs/2206.10926</link><description>&lt;p&gt;
&#22522;&#20110;&#26102;&#31354;&#36319;&#36394;&#25968;&#25454;&#30340;&#36275;&#29699;&#27604;&#36187;&#20013;&#38453;&#22411;&#21644;&#35282;&#33394;&#21464;&#21270;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
SoccerCPD: Formation and Role Change-Point Detection in Soccer Matches Using Spatiotemporal Tracking Data. (arXiv:2206.10926v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10926
&lt;/p&gt;
&lt;p&gt;
SoccerCPD&#26159;&#19968;&#20010;&#26032;&#30340;&#36275;&#29699;&#27604;&#36187;&#21464;&#28857;&#26816;&#27979;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;&#36275;&#29699;&#27604;&#36187;&#20013;&#30340;&#31574;&#30053;&#24847;&#22270;&#38453;&#22411;&#21644;&#35282;&#33394;&#21464;&#21270;&#19982;&#20020;&#26102;&#21464;&#21270;&#21306;&#20998;&#24320;&#26469;&#12290;&#35813;&#26694;&#26550;&#30340;&#20004;&#27493;&#21464;&#28857;&#26816;&#27979;&#22312;&#39046;&#22495;&#19987;&#23478;&#27880;&#37322;&#22522;&#30784;&#19978;&#36827;&#34892;&#39564;&#35777;&#65292;&#32467;&#26524;&#26174;&#31034;&#23427;&#21487;&#20197;&#20934;&#30830;&#26816;&#27979;&#25112;&#26415;&#21464;&#21270;&#24182;&#20272;&#35745;&#27599;&#31186;&#30340;&#38453;&#22411;&#21644;&#35282;&#33394;&#20998;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35832;&#22914;&#36275;&#29699;&#21644;&#31726;&#29699;&#31561;&#27969;&#20307;&#22242;&#38431;&#36816;&#21160;&#20013;&#65292;&#20998;&#26512;&#22242;&#38431;&#38453;&#23481;&#26159;&#20174;&#39046;&#22495;&#21442;&#19982;&#32773;&#30340;&#35282;&#24230;&#29702;&#35299;&#25112;&#26415;&#26368;&#30452;&#35266;&#30340;&#26041;&#24335;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#20551;&#23450;&#22242;&#38431;&#38453;&#22411;&#22312;&#27604;&#36187;&#20013;&#22987;&#32456;&#20445;&#25345;&#19968;&#33268;&#65292;&#35201;&#20040;&#25353;&#24103;&#20998;&#37197;&#38453;&#22411;&#65292;&#36825;&#19982;&#23454;&#38469;&#24773;&#20917;&#19981;&#31526;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;SoccerCPD&#30340;&#21464;&#28857;&#26816;&#27979;&#26694;&#26550;&#65292;&#21487;&#23558;&#36275;&#29699;&#27604;&#36187;&#20013;&#30340;&#31574;&#30053;&#24847;&#22270;&#38453;&#22411;&#21644;&#35282;&#33394;&#21464;&#21270;&#19982;&#20020;&#26102;&#21464;&#21270;&#21306;&#20998;&#24320;&#26469;&#12290;&#25105;&#20204;&#39318;&#20808;&#25353;&#24103;&#20998;&#37197;&#29699;&#21592;&#35282;&#33394;&#65292;&#28982;&#21518;&#25191;&#34892;&#20004;&#27493;&#21464;&#28857;&#26816;&#27979;&#65306;&#65288;1&#65289;&#22522;&#20110;&#35282;&#33394;&#37051;&#25509;&#30697;&#38453;&#24207;&#21015;&#30340;&#38453;&#22411;&#21464;&#28857;&#26816;&#27979;&#65292;&#65288;2&#65289;&#22522;&#20110;&#35282;&#33394;&#25490;&#21015;&#24207;&#21015;&#30340;&#35282;&#33394;&#21464;&#28857;&#26816;&#27979;&#12290;&#20351;&#29992;&#39046;&#22495;&#19987;&#23478;&#27880;&#37322;&#30340;&#22522;&#26412;&#23454;&#20917;&#35780;&#20272;SoccerCPD&#65292;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#26816;&#27979;&#21040;&#25112;&#26415;&#21464;&#21270;&#28857;&#24182;&#20272;&#35745;&#27599;&#31186;&#30340;&#38453;&#22411;&#21644;&#35282;&#33394;&#20998;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
In fluid team sports such as soccer and basketball, analyzing team formation is one of the most intuitive ways to understand tactics from domain participants' point of view. However, existing approaches either assume that team formation is consistent throughout a match or assign formations frame-by-frame, which disagree with real situations. To tackle this issue, we propose a change-point detection framework named SoccerCPD that distinguishes tactically intended formation and role changes from temporary changes in soccer matches. We first assign roles to players frame-by-frame and perform two-step change-point detections: (1) formation change-point detection based on the sequence of role-adjacency matrices and (2) role change-point detection based on the sequence of role permutations. The evaluation of SoccerCPD using the ground truth annotated by domain experts shows that our method accurately detects the points of tactical changes and estimates the formation and role assignment per s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#65292;&#20351;&#29992;&#23567;&#25209;&#37327;&#21644;&#37325;&#29699;&#21160;&#37327;&#36827;&#34892;&#21152;&#36895;&#65292;&#22312;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#20013;&#20445;&#25345;&#24555;&#36895;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.07553</link><description>&lt;p&gt;
&#35770;&#23567;&#25209;&#37327;&#37325;&#29699;&#21160;&#37327;&#27861;&#30340;&#24555;&#36895;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the fast convergence of minibatch heavy ball momentum. (arXiv:2206.07553v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.07553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#65292;&#20351;&#29992;&#23567;&#25209;&#37327;&#21644;&#37325;&#29699;&#21160;&#37327;&#36827;&#34892;&#21152;&#36895;&#65292;&#22312;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#20013;&#20445;&#25345;&#24555;&#36895;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31616;&#21333;&#30340;&#38543;&#26426;&#21160;&#37327;&#26041;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20248;&#21270;&#20013;&#65292;&#20294;&#30001;&#20110;&#36824;&#27809;&#26377;&#21152;&#36895;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36825;&#19982;&#23427;&#20204;&#22312;&#23454;&#36341;&#20013;&#30340;&#33391;&#22909;&#24615;&#33021;&#24182;&#19981;&#30456;&#31526;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#23637;&#31034;&#65292;&#38543;&#26426;&#37325;&#29699;&#21160;&#37327;&#22312;&#20108;&#27425;&#26368;&#20248;&#21270;&#38382;&#39064;&#20013;&#20445;&#25345;&#65288;&#30830;&#23450;&#24615;&#65289;&#37325;&#29699;&#21160;&#37327;&#30340;&#24555;&#36895;&#32447;&#24615;&#29575;&#65292;&#33267;&#23569;&#22312;&#20351;&#29992;&#36275;&#22815;&#22823;&#30340;&#25209;&#37327;&#22823;&#23567;&#36827;&#34892;&#23567;&#25209;&#37327;&#22788;&#29702;&#26102;&#12290;&#25105;&#20204;&#25152;&#30740;&#31350;&#30340;&#31639;&#27861;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#24102;&#23567;&#25209;&#37327;&#22788;&#29702;&#21644;&#37325;&#29699;&#21160;&#37327;&#30340;&#21152;&#36895;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#12290;&#35813;&#20998;&#26512;&#20381;&#36182;&#20110;&#20180;&#32454;&#20998;&#35299;&#21160;&#37327;&#36716;&#31227;&#30697;&#38453;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#29420;&#31435;&#38543;&#26426;&#30697;&#38453;&#20056;&#31215;&#30340;&#35889;&#33539;&#22260;&#38598;&#20013;&#30028;&#38480;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#28436;&#31034;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#30456;&#24403;&#23574;&#38160;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simple stochastic momentum methods are widely used in machine learning optimization, but their good practical performance is at odds with an absence of theoretical guarantees of acceleration in the literature. In this work, we aim to close the gap between theory and practice by showing that stochastic heavy ball momentum retains the fast linear rate of (deterministic) heavy ball momentum on quadratic optimization problems, at least when minibatching with a sufficiently large batch size. The algorithm we study can be interpreted as an accelerated randomized Kaczmarz algorithm with minibatching and heavy ball momentum. The analysis relies on carefully decomposing the momentum transition matrix, and using new spectral norm concentration bounds for products of independent random matrices. We provide numerical illustrations demonstrating that our bounds are reasonably sharp.
&lt;/p&gt;</description></item><item><title>D-Struct&#26159;&#19968;&#31181;&#21487;&#24494;&#21644;&#21487;&#20256;&#36755;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#26550;&#26500;&#21644;&#25439;&#22833;&#20989;&#25968;&#20351;&#24471;&#32467;&#26500;&#21487;&#20197;&#22312;&#21516;&#19968;&#39046;&#22495;&#30340;&#19981;&#21516;&#25968;&#25454;&#38598;&#20013;&#20256;&#36755;&#65292;&#27604;NOTEARS&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2206.06354</link><description>&lt;p&gt;
&#21487;&#24494;&#21644;&#21487;&#20256;&#36755;&#30340;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentiable and Transportable Structure Learning. (arXiv:2206.06354v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.06354
&lt;/p&gt;
&lt;p&gt;
D-Struct&#26159;&#19968;&#31181;&#21487;&#24494;&#21644;&#21487;&#20256;&#36755;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#26550;&#26500;&#21644;&#25439;&#22833;&#20989;&#25968;&#20351;&#24471;&#32467;&#26500;&#21487;&#20197;&#22312;&#21516;&#19968;&#39046;&#22495;&#30340;&#19981;&#21516;&#25968;&#25454;&#38598;&#20013;&#20256;&#36755;&#65292;&#27604;NOTEARS&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#21521;&#26080;&#29615;&#22270;&#22312;&#23427;&#20204;&#30340;&#32467;&#26500;&#20013;&#32534;&#30721;&#20102;&#20851;&#20110;&#29305;&#23450;&#20998;&#24067;&#30340;&#22823;&#37327;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#25512;&#26029;&#36825;&#20123;&#32467;&#26500;&#25152;&#38656;&#30340;&#35745;&#31639;&#36890;&#24120;&#26159;&#21464;&#37327;&#25968;&#30340;&#36229;&#25351;&#25968;&#65292;&#22240;&#20026;&#25512;&#26029;&#38656;&#35201;&#25195;&#25551;&#19968;&#20010;&#32452;&#21512;&#25968;&#37327;&#24040;&#22823;&#30340;&#28508;&#22312;&#32467;&#26500;&#31354;&#38388;&#12290;&#30452;&#21040;&#26368;&#36817;&#30340;&#36827;&#23637;&#25165;&#20351;&#24471;&#20351;&#29992;&#21487;&#24494;&#24230;&#37327;&#25628;&#32034;&#36825;&#20010;&#31354;&#38388;&#25104;&#20026;&#21487;&#33021;&#65292;&#20174;&#32780;&#26497;&#22823;&#22320;&#20943;&#23569;&#20102;&#25628;&#32034;&#26102;&#38388;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;D-Struct&#65292;&#23427;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#26550;&#26500;&#21644;&#25439;&#22833;&#20989;&#25968;&#24674;&#22797;&#20102;&#21457;&#29616;&#32467;&#26500;&#22312;&#21516;&#19968;&#39046;&#22495;&#20013;&#30340;&#20256;&#36755;&#24615;&#65292;&#21516;&#26102;&#20173;&#28982;&#23436;&#20840;&#21487;&#24494;&#12290;&#22240;&#20026;D-Struct&#20173;&#28982;&#26159;&#21487;&#24494;&#30340;&#65292;&#25152;&#20197;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#22320;&#24212;&#29992;&#20110;&#29616;&#26377;&#30340;&#21487;&#24494;&#26694;&#26550;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Directed acyclic graphs (DAGs) encode a lot of information about a particular distribution in their structure. However, compute required to infer these structures is typically super-exponential in the number of variables, as inference requires a sweep of a combinatorially large space of potential structures. That is, until recent advances made it possible to search this space using a differentiable metric, drastically reducing search time. While this technique -- named NOTEARS -- is widely considered a seminal work in DAG-discovery, it concedes an important property in favour of differentiability: transportability. To be transportable, the structures discovered on one dataset must apply to another dataset from the same domain. We introduce D-Struct which recovers transportability in the discovered structures through a novel architecture and loss function while remaining fully differentiable. Because D-Struct remains differentiable, our method can be easily adopted in existing different
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#21307;&#30103;&#26426;&#26500;&#38388;&#25968;&#25454;&#20849;&#20139;&#30340;&#38544;&#31169;&#38480;&#21046;&#21644;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36890;&#20449;&#25928;&#29575;&#21644;&#38544;&#31169;&#20445;&#25252;&#24615;&#12290;&#35813;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#35777;&#26126;&#20197;&#21450;&#22312;&#29616;&#23454;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#30340;&#27169;&#25311;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.05581</link><description>&lt;p&gt;
&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Offline Reinforcement Learning. (arXiv:2206.05581v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05581
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#21307;&#30103;&#26426;&#26500;&#38388;&#25968;&#25454;&#20849;&#20139;&#30340;&#38544;&#31169;&#38480;&#21046;&#21644;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36890;&#20449;&#25928;&#29575;&#21644;&#38544;&#31169;&#20445;&#25252;&#24615;&#12290;&#35813;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#35777;&#26126;&#20197;&#21450;&#22312;&#29616;&#23454;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#30340;&#27169;&#25311;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35777;&#25454;&#25110;&#25968;&#25454;&#30340;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#23545;&#20110;&#20010;&#24615;&#21270;&#21307;&#30103;&#33267;&#20851;&#37325;&#35201;&#65292;&#21487;&#20197;&#21463;&#30410;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#12290;&#34429;&#28982;&#21307;&#30103;&#26426;&#26500;&#38388;&#26377;&#22823;&#37327;&#20581;&#24247;&#25968;&#25454;&#21487;&#29992;&#65292;&#20294;&#30001;&#20110;&#38544;&#31169;&#38480;&#21046;&#65292;&#23427;&#20204;&#26080;&#27861;&#20849;&#20139;&#12290;&#27492;&#22806;&#65292;&#19981;&#21516;&#31449;&#28857;&#23384;&#22312;&#24322;&#36136;&#24615;&#12290;&#22240;&#27492;&#65292;&#32852;&#37030;&#31163;&#32447;RL&#31639;&#27861;&#26159;&#24517;&#35201;&#30340;&#19988;&#26377;&#21069;&#36884;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#31449;&#28857;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#27169;&#22411;&#65292;&#20801;&#35768;&#31449;&#28857;&#20043;&#38388;&#30340;&#21516;&#36136;&#24615;&#21644;&#24322;&#36136;&#24615;&#25928;&#24212;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#21487;&#20197;&#20998;&#26512;&#31449;&#28857;&#32423;&#29305;&#24449;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31163;&#32447;RL&#32852;&#37030;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20855;&#26377;&#36890;&#20449;&#25928;&#29575;&#21644;&#38544;&#31169;&#20445;&#25252;&#24615;&#65292;&#20165;&#38656;&#35201;&#36890;&#36807;&#20132;&#25442;&#25688;&#35201;&#32479;&#35745;&#37327;&#36827;&#34892;&#19968;&#36718;&#36890;&#20449;&#20132;&#20114;&#12290;&#25105;&#20204;&#20026;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#26080;&#38656;&#20551;&#35774;&#31449;&#28857;&#20043;&#38388;&#20855;&#26377;&#30456;&#21516;&#30340;&#36716;&#25442;&#21160;&#24577;&#12290;&#25105;&#20204;&#22312;&#29616;&#23454;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27169;&#25311;&#65292;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evidence-based or data-driven dynamic treatment regimes are essential for personalized medicine, which can benefit from offline reinforcement learning (RL). Although massive healthcare data are available across medical institutions, they are prohibited from sharing due to privacy constraints. Besides, heterogeneity exists in different sites. As a result, federated offline RL algorithms are necessary and promising to deal with the problems. In this paper, we propose a multi-site Markov decision process model which allows both homogeneous and heterogeneous effects across sites. The proposed model makes the analysis of the site-level features possible. We design the first federated policy optimization algorithm for offline RL with sample complexity. The proposed algorithm is communication-efficient and privacy-preserving, which requires only a single round of communication interaction by exchanging summary statistics. We give a theoretical guarantee for the proposed algorithm without the 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;Beyond the Imitation Game&#22522;&#20934;&#27979;&#35797;&#65288;BIG-bench&#65289;&#65292;&#35813;&#27979;&#35797;&#38598;&#21253;&#21547;&#20102;204&#20010;&#21508;&#39046;&#22495;&#30340;&#38590;&#39064;&#65292;&#26088;&#22312;&#35780;&#20272;&#24403;&#21069;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20449;&#24687;&#21644;&#20934;&#22791;&#12290;</title><link>http://arxiv.org/abs/2206.04615</link><description>&lt;p&gt;
&#36229;&#36234;&#27169;&#20223;&#28216;&#25103;&#65306;&#37327;&#21270;&#21644;&#25299;&#23637;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. (arXiv:2206.04615v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.04615
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;Beyond the Imitation Game&#22522;&#20934;&#27979;&#35797;&#65288;BIG-bench&#65289;&#65292;&#35813;&#27979;&#35797;&#38598;&#21253;&#21547;&#20102;204&#20010;&#21508;&#39046;&#22495;&#30340;&#38590;&#39064;&#65292;&#26088;&#22312;&#35780;&#20272;&#24403;&#21069;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20449;&#24687;&#21644;&#20934;&#22791;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35268;&#27169;&#30340;&#22686;&#22823;&#65292;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#25968;&#37327;&#19978;&#30340;&#25552;&#21319;&#21644;&#26032;&#30340;&#23450;&#24615;&#33021;&#21147;&#12290;&#23613;&#31649;&#20855;&#26377;&#28508;&#22312;&#30340;&#36716;&#21464;&#24615;&#24433;&#21709;&#65292;&#20294;&#36825;&#20123;&#26032;&#30340;&#33021;&#21147;&#30446;&#21069;&#23578;&#26410;&#34987;&#20805;&#20998;&#25551;&#36848;&#12290;&#20026;&#20102;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20449;&#24687;&#65292;&#20026;&#21095;&#21464;&#30340;&#26032;&#22411;&#27169;&#22411;&#33021;&#21147;&#20570;&#20934;&#22791;&#65292;&#24182;&#32531;&#35299;&#31038;&#20250;&#26377;&#23475;&#24433;&#21709;&#65292;&#25105;&#20204;&#24517;&#39035;&#20102;&#35299;&#35821;&#35328;&#27169;&#22411;&#30340;&#29616;&#26377;&#21644;&#36817;&#26399;&#33021;&#21147;&#21644;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Beyond the Imitation Game&#22522;&#20934;&#27979;&#35797;&#65288;BIG-bench&#65289;&#12290;BIG-bench&#30446;&#21069;&#21253;&#25324;204&#20010;&#20219;&#21153;&#65292;&#30001;132&#20010;&#26426;&#26500;&#30340;450&#21517;&#20316;&#32773;&#36129;&#29486;&#12290;&#20219;&#21153;&#20027;&#39064;&#22810;&#26679;&#65292;&#28085;&#30422;&#20102;&#35821;&#35328;&#23398;&#12289;&#20799;&#31461;&#21457;&#23637;&#12289;&#25968;&#23398;&#12289;&#24120;&#35782;&#25512;&#29702;&#12289;&#29983;&#29289;&#23398;&#12289;&#29289;&#29702;&#23398;&#12289;&#31038;&#20250;&#20559;&#35265;&#12289;&#36719;&#20214;&#24320;&#21457;&#31561;&#31561;&#12290;BIG-bench&#19987;&#27880;&#20110;&#37027;&#20123;&#34987;&#35748;&#20026;&#36229;&#20986;&#20102;&#24403;&#21069;&#35821;&#35328;&#27169;&#22411;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;OpenAI&#30340;GPT&#27169;&#22411;&#21644;&#35895;&#27468;&#20869;&#37096;&#30340;&#23494;&#38598;&#36716;&#25442;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transform
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32454;&#33268;&#30740;&#31350;&#20102;&#28857;&#31215;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#38024;&#23545; $m\propto d^r$ &#39640;&#38454;&#26631;&#24230;&#20851;&#31995;&#25552;&#20986;&#20102;&#31934;&#30830;&#30340;&#27979;&#35797;&#35823;&#24046;&#12289;&#20559;&#24046;&#21644;&#26041;&#24046;&#20844;&#24335;&#12290;</title><link>http://arxiv.org/abs/2205.14846</link><description>&lt;p&gt;
&#28857;&#31215;&#26680;&#22238;&#24402;&#30340;&#31934;&#30830;&#23398;&#20064;&#26354;&#32447;&#21644;&#39640;&#38454;&#26631;&#24230;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression. (arXiv:2205.14846v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32454;&#33268;&#30740;&#31350;&#20102;&#28857;&#31215;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#38024;&#23545; $m\propto d^r$ &#39640;&#38454;&#26631;&#24230;&#20851;&#31995;&#25552;&#20986;&#20102;&#31934;&#30830;&#30340;&#27979;&#35797;&#35823;&#24046;&#12289;&#20559;&#24046;&#21644;&#26041;&#24046;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19981;&#26029;&#25512;&#36827;&#35745;&#31639;&#21069;&#27839;&#65292;&#24320;&#21457;&#23545;&#19981;&#21516;&#27169;&#22411;&#21644;&#25968;&#25454;&#32553;&#25918;&#26041;&#26696;&#19979;&#39044;&#26399;&#24615;&#33021;&#25552;&#39640;&#30340;&#31934;&#30830;&#20272;&#35745;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#30446;&#21069;&#65292;&#20851;&#20110;&#25551;&#36848;&#39044;&#27979;&#35823;&#24046;&#22914;&#20309;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#32780;&#21464;&#21270;&#30340;&#23398;&#20064;&#26354;&#32447;&#30340;&#29702;&#35770;&#29702;&#35299;&#21463;&#38480;&#20110;&#22823;&#26679;&#26412;&#28176;&#36817;&#24615; ($m\to\infty$) &#25110;&#23545;&#20110;&#26576;&#20123;&#31616;&#21333;&#25968;&#25454;&#20998;&#24067;&#30340;&#39640;&#32500;&#28176;&#36817;&#24615;&#65292;&#20854;&#20013;&#26679;&#26412;&#25968;&#37327;&#19982;&#32500;&#25968;&#25104;&#32447;&#24615;&#27604;&#20363; ($m\propto d$)&#12290;&#36825;&#20004;&#20010;&#33539;&#30068;&#20043;&#38388;&#23384;&#22312;&#24456;&#22823;&#24046;&#36317;&#65292;&#21253;&#25324;&#25152;&#26377;&#39640;&#38454;&#26631;&#24230;&#20851;&#31995; $m\propto d^r$&#65292;&#36825;&#26159;&#26412;&#25991;&#30340;&#30740;&#31350;&#23545;&#35937;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#28857;&#31215;&#26680;&#23725;&#22238;&#24402;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312; $m/d\rightarrow2r$ &#30340; $r$ &#38454;&#28176;&#36817;&#26631;&#24230;&#19979;&#65288;&#20854;&#20013; $m\to\infty$&#65289;&#65292;&#23545;&#20110;&#20174;&#29699;&#38754;&#19978;&#22343;&#21248;&#25277;&#21462;&#30340;&#25968;&#25454;&#65292;&#27979;&#35797;&#35823;&#24046;&#12289;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#31934;&#30830;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
As modern machine learning models continue to advance the computational frontier, it has become increasingly important to develop precise estimates for expected performance improvements under different model and data scaling regimes. Currently, theoretical understanding of the learning curves that characterize how the prediction error depends on the number of samples is restricted to either large-sample asymptotics ($m\to\infty$) or, for certain simple data distributions, to the high-dimensional asymptotics in which the number of samples scales linearly with the dimension ($m\propto d$). There is a wide gulf between these two regimes, including all higher-order scaling relations $m\propto d^r$, which are the subject of the present paper. We focus on the problem of kernel ridge regression for dot-product kernels and present precise formulas for the test error, bias, and variance, for data drawn uniformly from the sphere in the $r$th-order asymptotic scaling regime $m\to\infty$ with $m/d
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#20108;&#27425;&#27169;&#22411;&#21487;&#20197;&#23637;&#31034;&#20986;&#31070;&#32463;&#32593;&#32476;&#22312;&#22823;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#30340;&#8220;&#24377;&#24339;&#38454;&#27573;&#8221;&#65292;&#24182;&#19988;&#22312;&#27867;&#21270;&#29305;&#24615;&#19978;&#19982;&#31070;&#32463;&#32593;&#32476;&#26377;&#30456;&#20284;&#20043;&#22788;&#65292;&#26159;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2205.11787</link><description>&lt;p&gt;
&#29992;&#20110;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#21160;&#24577;&#30340;&#20108;&#27425;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Quadratic models for understanding neural network dynamics. (arXiv:2205.11787v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11787
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20108;&#27425;&#27169;&#22411;&#21487;&#20197;&#23637;&#31034;&#20986;&#31070;&#32463;&#32593;&#32476;&#22312;&#22823;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#30340;&#8220;&#24377;&#24339;&#38454;&#27573;&#8221;&#65292;&#24182;&#19988;&#22312;&#27867;&#21270;&#29305;&#24615;&#19978;&#19982;&#31070;&#32463;&#32593;&#32476;&#26377;&#30456;&#20284;&#20043;&#22788;&#65292;&#26159;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#31070;&#32463;&#32593;&#32476;&#30340;&#23485;&#24230;&#22686;&#21152;&#26102;&#65292;&#21487;&#20197;&#29992;&#32447;&#24615;&#27169;&#22411;&#26469;&#36924;&#36817;&#31070;&#32463;&#32593;&#32476;&#65292;&#20294;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#29305;&#24615;&#19981;&#33021;&#34987;&#32447;&#24615;&#27169;&#22411;&#25429;&#25417;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#31070;&#32463;&#20108;&#27425;&#27169;&#22411;&#21487;&#20197;&#23637;&#31034;&#8220;&#24377;&#24339;&#38454;&#27573;&#8221;[Lewkowycz&#31561;&#20154;&#65292;2020]&#65292;&#24403;&#20351;&#29992;&#22823;&#23398;&#20064;&#29575;&#35757;&#32451;&#27492;&#31867;&#27169;&#22411;&#26102;&#20250;&#20986;&#29616;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#65292;&#31070;&#32463;&#20108;&#27425;&#27169;&#22411;&#30340;&#34892;&#20026;&#19982;&#31070;&#32463;&#32593;&#32476;&#22312;&#27867;&#21270;&#29305;&#24615;&#19978;&#26377;&#30456;&#20284;&#20043;&#22788;&#65292;&#23588;&#20854;&#26159;&#22312;&#24377;&#24339;&#38454;&#27573;&#33539;&#22260;&#20869;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#20108;&#27425;&#27169;&#22411;&#21487;&#20197;&#25104;&#20026;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
While neural networks can be approximated by linear models as their width increases, certain properties of wide neural networks cannot be captured by linear models. In this work we show that recently proposed Neural Quadratic Models can exhibit the "catapult phase" [Lewkowycz et al. 2020] that arises when training such models with large learning rates. We then empirically show that the behaviour of neural quadratic models parallels that of neural networks in generalization, especially in the catapult phase regime. Our analysis further demonstrates that quadratic models can be an effective tool for analysis of neural networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38416;&#26126;&#20855;&#26377;&#20219;&#24847;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#23485;&#24230;&#26080;&#38480;&#22686;&#22823;&#30340;&#24773;&#20917;&#19979;&#26377;&#32447;&#24615;&#36716;&#21270;&#30340;&#36235;&#21183;&#12290;&#32467;&#26524;&#25581;&#31034;&#20102;&#36716;&#21270;&#20026;&#32447;&#24615;&#30340;&#25968;&#23398;&#32467;&#26500;&#65292;&#24182;&#25512;&#24191;&#20102;&#19968;&#31995;&#21015;&#20851;&#20110;&#26631;&#20934;&#26550;&#26500;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#32447;&#24615;&#36716;&#21270;&#25110;&#24658;&#23450;&#24615;&#30340;&#26368;&#26032;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2205.11786</link><description>&lt;p&gt;
&#20855;&#26377;&#26377;&#21521;&#26080;&#29615;&#22270;&#26550;&#26500;&#30340;&#26222;&#36890;&#31070;&#32463;&#32593;&#32476;&#30340;&#32447;&#24615;&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
Transition to Linearity of General Neural Networks with Directed Acyclic Graph Architecture. (arXiv:2205.11786v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38416;&#26126;&#20855;&#26377;&#20219;&#24847;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#23485;&#24230;&#26080;&#38480;&#22686;&#22823;&#30340;&#24773;&#20917;&#19979;&#26377;&#32447;&#24615;&#36716;&#21270;&#30340;&#36235;&#21183;&#12290;&#32467;&#26524;&#25581;&#31034;&#20102;&#36716;&#21270;&#20026;&#32447;&#24615;&#30340;&#25968;&#23398;&#32467;&#26500;&#65292;&#24182;&#25512;&#24191;&#20102;&#19968;&#31995;&#21015;&#20851;&#20110;&#26631;&#20934;&#26550;&#26500;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#32447;&#24615;&#36716;&#21270;&#25110;&#24658;&#23450;&#24615;&#30340;&#26368;&#26032;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#65292;&#38543;&#30528;&#20854;&#8220;&#23485;&#24230;&#8221;&#25509;&#36817;&#26080;&#31351;&#22823;&#65292;&#19982;&#20219;&#24847;&#26377;&#21521;&#26080;&#29615;&#22270;&#30456;&#20851;&#30340;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20250;&#21457;&#29983;&#32447;&#24615;&#36716;&#25442;&#12290;&#36825;&#20123;&#26222;&#36890;&#32593;&#32476;&#30340;&#23485;&#24230;&#30001;&#20854;&#31070;&#32463;&#20803;&#30340;&#26368;&#23567;&#20837;&#24230;&#65288;&#38500;&#20102;&#36755;&#20837;&#21644;&#31532;&#19968;&#23618;&#20043;&#22806;&#65289;&#26469;&#21051;&#30011;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#30830;&#23450;&#20102;&#36716;&#25442;&#21040;&#32447;&#24615;&#25152;&#22522;&#20110;&#30340;&#25968;&#23398;&#32467;&#26500;&#65292;&#24182;&#27010;&#25324;&#20102;&#19968;&#20123;&#26088;&#22312;&#34920;&#24449;&#26631;&#20934;&#26550;&#26500;&#19979;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#32447;&#24615;&#36716;&#25442;&#25110;&#24658;&#23450;&#24615;&#30340;&#26368;&#36817;&#30740;&#31350;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we show that feedforward neural networks corresponding to arbitrary directed acyclic graphs undergo transition to linearity as their "width" approaches infinity. The width of these general networks is characterized by the minimum in-degree of their neurons, except for the input and first layers. Our results identify the mathematical structure underlying transition to linearity and generalize a number of recent works aimed at characterizing transition to linearity or constancy of the Neural Tangent Kernel for standard architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;SINFONY&#65292;&#23427;&#36890;&#36807;&#23545;&#28040;&#24687;&#36827;&#34892;&#25968;&#25454;&#20943;&#23569;&#21644;&#21487;&#38752;&#20256;&#36755;&#26469;&#26368;&#22909;&#22320;&#20445;&#30041;&#35821;&#20041;&#65292;&#20174;&#32780;&#23454;&#29616;&#26080;&#32447;&#32593;&#32476;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2204.13366</link><description>&lt;p&gt;
&#26080;&#32447;&#32593;&#32476;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Semantic Information Recovery in Wireless Networks. (arXiv:2204.13366v4 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.13366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;SINFONY&#65292;&#23427;&#36890;&#36807;&#23545;&#28040;&#24687;&#36827;&#34892;&#25968;&#25454;&#20943;&#23569;&#21644;&#21487;&#38752;&#20256;&#36755;&#26469;&#26368;&#22909;&#22320;&#20445;&#30041;&#35821;&#20041;&#65292;&#20174;&#32780;&#23454;&#29616;&#26080;&#32447;&#32593;&#32476;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#22312;&#26080;&#32447;&#36890;&#20449;&#20013;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;1949&#24180;Weaver&#25552;&#20986;&#30340;&#35821;&#20041;&#36890;&#20449;&#24605;&#24819;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290; &#23427;&#25171;&#30772;&#20102;Shannon&#30340;&#32463;&#20856;&#35774;&#35745;&#33539;&#20363;&#65292;&#26088;&#22312;&#20256;&#36882;&#28040;&#24687;&#30340;&#21547;&#20041;&#65292;&#21363;&#35821;&#20041;&#65292;&#32780;&#19981;&#26159;&#20854;&#30830;&#20999;&#29256;&#26412;&#65292;&#20174;&#32780;&#20801;&#35768;&#33410;&#30465;&#20449;&#24687;&#36895;&#29575;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;Basu&#31561;&#20154;&#30340;&#24314;&#27169;&#35821;&#20041;&#30340;&#22522;&#26412;&#26041;&#27861;&#25193;&#23637;&#21040;&#23436;&#25972;&#36890;&#20449;&#39532;&#23572;&#21487;&#22827;&#38142;&#12290; &#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#38544;&#21547;&#30340;&#38543;&#26426;&#21464;&#37327;&#26469;&#24314;&#27169;&#35821;&#20041;&#65292;&#24182;&#23558;&#35821;&#20041;&#36890;&#20449;&#20219;&#21153;&#23450;&#20041;&#20026;&#36890;&#36807;&#36890;&#20449;&#20449;&#36947;&#23545;&#28040;&#24687;&#36827;&#34892;&#25968;&#25454;&#20943;&#23569;&#21644;&#21487;&#38752;&#20256;&#36755;&#65292;&#20174;&#32780;&#26368;&#22909;&#22320;&#20445;&#30041;&#35821;&#20041;&#12290; &#25105;&#20204;&#23558;&#27492;&#20219;&#21153;&#20316;&#20026;&#31471;&#21040;&#31471;&#20449;&#24687;&#29942;&#39048;&#38382;&#39064;&#36827;&#34892;&#24314;&#27169;&#65292;&#20801;&#35768;&#22312;&#20445;&#30041;&#30456;&#20851;&#20449;&#24687;&#30340;&#21516;&#26102;&#36827;&#34892;&#21387;&#32553;&#12290; &#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;ML&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;SINFONY&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#20998;&#24067;&#24335;&#22810;&#28857;&#22330;&#26223;&#65306;SIN&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the recent success of Machine Learning (ML) tools in wireless communications, the idea of semantic communication by Weaver from 1949 has gained attention. It breaks with Shannon's classic design paradigm by aiming to transmit the meaning of a message, i.e., semantics, rather than its exact version and thus allows for savings in information rate. In this work, we extend the fundamental approach from Basu et al. for modeling semantics to the complete communications Markov chain. Thus, we model semantics by means of hidden random variables and define the semantic communication task as the data-reduced and reliable transmission of messages over a communication channel such that semantics is best preserved. We cast this task as an end-to-end Information Bottleneck problem, allowing for compression while preserving relevant information most. As a solution approach, we propose the ML-based semantic communication system SINFONY and use it for a distributed multipoint scenario: SIN
&lt;/p&gt;</description></item><item><title>&#37319;&#29992;&#20984;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#30340;&#39118;&#38505;&#39044;&#31639;&#32452;&#21512;&#26041;&#27861;&#65292;&#33021;&#22815;&#20135;&#29983;&#21487;&#20197;&#35299;&#37322;&#30340;&#22810;&#22836;&#25237;&#36164;&#32452;&#21512;&#65292;&#20855;&#26377;&#20248;&#24322;&#30340;&#22810;&#26679;&#21270;&#21644;&#39118;&#38505;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2204.02757</link><description>&lt;p&gt;
&#39118;&#38505;&#39044;&#31639;&#32452;&#21512;&#21644;&#20984;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Risk budget portfolios with convex Non-negative Matrix Factorization. (arXiv:2204.02757v2 [q-fin.PM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.02757
&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#20984;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#30340;&#39118;&#38505;&#39044;&#31639;&#32452;&#21512;&#26041;&#27861;&#65292;&#33021;&#22815;&#20135;&#29983;&#21487;&#20197;&#35299;&#37322;&#30340;&#22810;&#22836;&#25237;&#36164;&#32452;&#21512;&#65292;&#20855;&#26377;&#20248;&#24322;&#30340;&#22810;&#26679;&#21270;&#21644;&#39118;&#38505;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#22240;&#23376;&#39044;&#31639;&#30340;&#25237;&#36164;&#32452;&#21512;&#20998;&#37197;&#26041;&#27861;&#65292;&#20351;&#29992;&#20984;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#12290;&#19982;&#32463;&#20856;&#22240;&#23376;&#20998;&#26512;&#12289;PCA&#25110;ICA&#19981;&#21516;&#65292;NMF&#30830;&#20445;&#27491;&#22240;&#23376;&#36733;&#33655;&#20197;&#33719;&#24471;&#21487;&#35299;&#37322;&#30340;&#20165;&#22810;&#22836;&#22836;&#23544;&#32452;&#21512;&#12290;&#30001;&#20110;NMF&#22240;&#23376;&#20195;&#34920;&#19981;&#21516;&#30340;&#39118;&#38505;&#26469;&#28304;&#65292;&#23427;&#20204;&#20855;&#26377;&#20934;&#23545;&#35282;&#32447;&#30456;&#20851;&#30697;&#38453;&#65292;&#20419;&#36827;&#20102;&#22810;&#26679;&#21270;&#30340;&#25237;&#36164;&#32452;&#21512;&#20998;&#37197;&#12290;&#25105;&#20204;&#22312;&#21152;&#23494;&#36135;&#24065;&#21644;&#20256;&#32479;&#36164;&#20135;&#30340;&#20004;&#20010;&#20165;&#22810;&#22836;&#20840;&#29699;&#32452;&#21512;&#30340;&#27874;&#21160;&#29575;&#23450;&#20301;&#32972;&#26223;&#19979;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#26679;&#21270;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#30340;&#25237;&#36164;&#32452;&#21512;&#20998;&#37197;&#65292;&#24182;&#21576;&#29616;&#20986;&#27604;&#20998;&#23618;&#39118;&#38505;&#24179;&#20215;&#65288;HRP&#65289;&#26356;&#22909;&#30340;&#39118;&#38505;&#29305;&#24449;&#12290;&#25105;&#20204;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#35780;&#20272;&#20102;&#25105;&#20204;&#21457;&#29616;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a portfolio allocation method based on risk factor budgeting using convex Nonnegative Matrix Factorization (NMF). Unlike classical factor analysis, PCA, or ICA, NMF ensures positive factor loadings to obtain interpretable long-only portfolios. As the NMF factors represent separate sources of risk, they have a quasi-diagonal correlation matrix, promoting diversified portfolio allocations. We evaluate our method in the context of volatility targeting on two long-only global portfolios of cryptocurrencies and traditional assets. Our method outperforms classical portfolio allocations regarding diversification and presents a better risk profile than hierarchical risk parity (HRP). We assess the robustness of our findings using Monte Carlo simulation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.11740</link><description>&lt;p&gt;
&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#23545;&#20851;&#38190;&#26399;&#30340;&#31070;&#32463;&#21487;&#22609;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#23454;&#29616;&#31361;&#35302;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#12290;&#65288;arXiv: 2203.11740v12 [cs.NE] UPDATED&#65289;
&lt;/p&gt;
&lt;p&gt;
Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#31361;&#35302;&#20849;&#20139;&#36830;&#25509;&#26435;&#37325;&#20043;&#22806;&#65292;PNN&#36824;&#21253;&#25324;&#31361;&#35302;&#26377;&#25928;&#33539;&#22260;&#30340;&#26435;&#37325;[14-25]&#12290;PNN&#32771;&#34385;&#31361;&#35302;&#24378;&#24230;&#24179;&#34913;&#22312;&#31361;&#35302;&#21534;&#22124;&#30340;&#21160;&#24577;&#21644;&#38271;&#24230;&#24120;&#25968;&#20043;&#21644;&#30340;&#38745;&#24577;&#20013;[14]&#65292;&#24182;&#21253;&#21547;&#20102;&#40060;&#32676;&#34892;&#20026;&#30340;&#20808;&#23548;&#34892;&#20026;&#12290;&#31361;&#35302;&#24418;&#25104;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#20250;&#25233;&#21046;&#26641;&#31361;&#29983;&#25104;[15]&#12290;&#31867;&#20284;&#20110;Spring Boot&#20013;&#30340;&#24378;&#21046;&#38887;&#24615;&#65292;&#21453;&#21521;&#22238;&#36335;&#30340;&#35760;&#24518;&#25345;&#20037;&#24230;&#26799;&#24230;&#20063;&#23384;&#22312;&#12290;&#30456;&#23545;&#36739;&#22909;&#21644;&#36739;&#24046;&#30340;&#26799;&#24230;&#20449;&#24687;&#23384;&#20648;&#22312;&#31867;&#20284;&#20110;&#33041;&#35126;&#30340;&#35760;&#24518;&#30165;&#36857;&#32454;&#32990;&#20013;&#65292;&#22312;&#21453;&#21521;&#22238;&#36335;&#30340;&#31361;&#35302;&#24418;&#25104;&#20013;&#12290;&#20105;&#35758;&#35748;&#20026;&#20154;&#31867;&#28023;&#39532;&#31070;&#32463;&#20803;&#30340;&#20877;&#29983;&#33021;&#21147;&#26159;&#21542;&#25345;&#32493;&#21040;&#32769;&#24180;&#65292;&#24182;&#21487;&#33021;&#22312;&#21518;&#26399;&#36845;&#20195;&#20013;&#24418;&#25104;&#26032;&#30340;&#26356;&#38271;&#30340;&#22238;&#36335;[17,18]&#12290;&#20851;&#38381;&#20851;&#38190;&#26399;&#20250;&#23548;&#33268;&#31070;&#32463;&#32010;&#20081;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;[19]&#12290;&#32771;&#34385;&#21040;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#28608;&#27963;&#31361;&#35302;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#22238;&#24402;&#31639;&#27861;&#65292;&#21487;&#38024;&#23545;&#22823;&#31867;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#23454;&#20363;&#24207;&#21015;&#30340;&#23545;&#25239;&#24615;&#22238;&#24212;&#65292;&#22312;&#36890;&#29992;&#21487;&#20998;&#31163;&#25351;&#26631;&#31354;&#38388;&#19978;&#23454;&#29616;&#24378;&#19968;&#33268;&#24615;&#30340;&#36890;&#29992;&#19968;&#33268;&#24615;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2203.05067</link><description>&lt;p&gt;
&#20855;&#26377;&#23545;&#25239;&#22238;&#24212;&#30340;&#36890;&#29992;&#22238;&#24402;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Universal Regression with Adversarial Responses. (arXiv:2203.05067v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.05067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#22238;&#24402;&#31639;&#27861;&#65292;&#21487;&#38024;&#23545;&#22823;&#31867;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#23454;&#20363;&#24207;&#21015;&#30340;&#23545;&#25239;&#24615;&#22238;&#24212;&#65292;&#22312;&#36890;&#29992;&#21487;&#20998;&#31163;&#25351;&#26631;&#31354;&#38388;&#19978;&#23454;&#29616;&#24378;&#19968;&#33268;&#24615;&#30340;&#36890;&#29992;&#19968;&#33268;&#24615;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#36890;&#29992;&#21487;&#20998;&#31163;&#25351;&#26631;&#31354;&#38388;&#19978;&#65292;&#23545;&#20110;&#22823;&#31867;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#23454;&#20363;&#24207;&#21015;&#30340;&#23545;&#25239;&#22238;&#24402;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20851;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#29305;&#24449;&#35828;&#26126;&#12290;&#25105;&#20204;&#32771;&#34385;&#24378;&#19968;&#33268;&#24615;&#30340;&#36890;&#29992;&#19968;&#33268;&#24615;&#23398;&#20064;&#65292;&#26080;&#38656;&#23545;&#20540;&#22238;&#24212;&#36827;&#34892;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65306;&#36825;&#31181;&#30446;&#26631;&#21487;&#22312;&#27604;&#24179;&#31283;&#36807;&#31243;&#26356;&#22823;&#30340;&#23454;&#20363;&#24207;&#21015;&#31867;&#20013;&#23454;&#29616;&#65292;&#24182;&#25581;&#31034;&#20102;&#20540;&#31354;&#38388;&#20043;&#38388;&#30340;&#26681;&#26412;&#20108;&#20998;&#27861;&#65306;&#26159;&#21542;&#21487;&#20197;&#23454;&#29616;&#26377;&#38480;&#26102;&#38388;&#27573;&#22343;&#20540;&#20272;&#35745;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#20048;&#35266;&#30340;&#36890;&#29992;&#24615;&#23398;&#20064;&#35268;&#21017;&#65292;&#21363;&#22914;&#26524;&#23427;&#20204;&#26410;&#33021;&#23454;&#29616;&#36890;&#29992;&#19968;&#33268;&#24615;&#65292;&#21017;&#20854;&#20182;&#20219;&#20309;&#31639;&#27861;&#20063;&#23558;&#22833;&#36133;&#12290;&#23545;&#20110;&#26410;&#30028;&#38480;&#25439;&#22833;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28201;&#21644;&#30340;&#21487;&#31215;&#26465;&#20214;&#65292;&#20854;&#19979;&#26377;&#23545;&#25239;&#24615;&#22238;&#24402;&#30340;&#31639;&#27861;&#32467;&#35770;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#30456;&#21516;&#30340;&#24037;&#20855;&#24212;&#29992;&#20110;&#24102;&#26377;&#23545;&#25239;&#24615;&#35823;&#24046;&#30340;&#36890;&#29992;&#39044;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide algorithms for regression with adversarial responses under large classes of non-i.i.d. instance sequences, on general separable metric spaces, with provably minimal assumptions. We also give characterizations of learnability in this regression context. We consider universal consistency which asks for strong consistency of a learner without restrictions on the value responses. Our analysis shows that such an objective is achievable for a significantly larger class of instance sequences than stationary processes, and unveils a fundamental dichotomy between value spaces: whether finite-horizon mean estimation is achievable or not. We further provide optimistically universal learning rules, i.e., such that if they fail to achieve universal consistency, any other algorithms will fail as well. For unbounded losses, we propose a mild integrability condition under which there exist algorithms for adversarial regression under large classes of non-i.i.d. instance sequences. In additio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#28418;&#31227;&#26816;&#27979;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#29616;&#23454;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.04769</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#28418;&#31227;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Autoregressive based Drift Detection Method. (arXiv:2203.04769v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.04769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#28418;&#31227;&#26816;&#27979;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#29616;&#23454;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#20013;&#65292;&#27169;&#22411;&#26159;&#22312;&#21382;&#21490;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#28982;&#21518;&#29992;&#20110;&#39044;&#27979;&#26410;&#26469;&#20540;&#12290;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#22312;&#26102;&#38388;&#19978;&#19981;&#21457;&#29983;&#21464;&#21270;&#65288;&#24179;&#31283;&#24615;&#65289;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#65292;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#38543;&#26102;&#38388;&#32780;&#21464;&#21270;&#65292;&#27169;&#22411;&#24517;&#39035;&#36866;&#24212;&#26032;&#30340;&#36755;&#20837;&#25968;&#25454;&#12290;&#36825;&#31181;&#29616;&#35937;&#31216;&#20026;&#27010;&#24565;&#28418;&#31227;&#65292;&#23548;&#33268;&#39044;&#27979;&#27169;&#22411;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#26032;&#27010;&#24565;&#28418;&#31227;&#26816;&#27979;&#26041;&#27861;&#65292;&#31216;&#20026;ADDM&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#19982;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#38598;&#25104;&#65292;&#20174;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21040;&#31616;&#21333;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26032;&#30340;&#27010;&#24565;&#28418;&#31227;&#26816;&#27979;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#27010;&#24565;&#28418;&#31227;&#26816;&#27979;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#20445;&#35777;&#65292;&#24182;&#22312;&#26816;&#27979;&#21508;&#31181;&#27010;&#24565;&#28418;&#31227;&#26041;&#38754;&#20855;&#26377;&#32463;&#39564;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the classic machine learning framework, models are trained on historical data and used to predict future values. It is assumed that the data distribution does not change over time (stationarity). However, in real-world scenarios, the data generation process changes over time and the model has to adapt to the new incoming data. This phenomenon is known as concept drift and leads to a decrease in the predictive model's performance. In this study, we propose a new concept drift detection method based on autoregressive models called ADDM. This method can be integrated into any machine learning algorithm from deep neural networks to simple linear regression model. Our results show that this new concept drift detection method outperforms the state-of-the-art drift detection methods, both on synthetic data sets and real-world data sets. Our approach is theoretically guaranteed as well as empirical and effective for the detection of various concept drifts. In addition to the drift detector,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#32570;&#22833;&#25968;&#25454;&#22270;&#27169;&#22411;&#30340;&#21487;&#26816;&#39564;&#24615;&#21644;&#35774;&#35745;&#25311;&#21512;&#20248;&#24230;&#27979;&#35797;&#30340;&#26032;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2203.00132</link><description>&lt;p&gt;
&#35770;&#32570;&#22833;&#25968;&#25454;&#27169;&#22411;&#20013;&#30340;&#21487;&#26816;&#39564;&#24615;&#21644;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
On Testability and Goodness of Fit Tests in Missing Data Models. (arXiv:2203.00132v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#32570;&#22833;&#25968;&#25454;&#22270;&#27169;&#22411;&#30340;&#21487;&#26816;&#39564;&#24615;&#21644;&#35774;&#35745;&#25311;&#21512;&#20248;&#24230;&#27979;&#35797;&#30340;&#26032;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25551;&#36848;&#26377;&#21521;&#26080;&#29615;&#22270;&#21487;&#20197;&#25551;&#36848;&#24314;&#27169;&#20551;&#35774;&#30340;&#32570;&#22833;&#25968;&#25454;&#38382;&#39064;&#20013;&#65292;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#20351;&#29992;&#36825;&#20123;&#25216;&#26415;&#24471;&#21040;&#30340;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#22270;&#25152;&#32534;&#30721;&#30340;&#20551;&#35774;&#26159;&#21542;&#25104;&#31435;&#65292;&#28982;&#32780;&#65292;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#23545;&#36825;&#20123;&#20551;&#35774;&#30340;&#39564;&#35777;&#27809;&#26377;&#24471;&#21040;&#36275;&#22815;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#19977;&#31867;&#32570;&#22833;&#25968;&#25454;&#22270;&#27169;&#22411;&#30340;&#21487;&#26816;&#39564;&#24615;&#21644;&#35774;&#35745;&#25311;&#21512;&#20248;&#24230;&#27979;&#35797;&#30340;&#26032;&#35265;&#35299;&#12290;&#25506;&#35752;&#30340;&#27169;&#22411;&#31867;&#21035;&#21253;&#25324;&#65306;&#21487;&#20197;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;&#36864;&#20986;/&#25130;&#23614;&#30340;&#32437;&#21521;&#30740;&#31350;&#30340;&#24207;&#36143;&#32570;&#22833;&#38543;&#26426;&#27169;&#22411;&#21644;&#32570;&#22833;&#38750;&#38543;&#26426;&#27169;&#22411;&#65292;&#20197;&#21450;&#21487;&#20197;&#24212;&#29992;&#20110;&#27178;&#25130;&#38754;&#30740;&#31350;&#21644;&#35843;&#26597;&#30340;&#38750;&#33258;&#25105;&#25130;&#26029;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Significant progress has been made in developing identification and estimation techniques for missing data problems where modeling assumptions can be described via a directed acyclic graph. The validity of results using such techniques rely on the assumptions encoded by the graph holding true; however, verification of these assumptions has not received sufficient attention in prior work. In this paper, we provide new insights on the testable implications of three broad classes of missing data graphical models, and design goodness-of-fit tests for them. The classes of models explored are: sequential missing-at-random and missing-not-at-random models which can be used for modeling longitudinal studies with dropout/censoring, and a no self-censoring model which can be applied to cross-sectional studies and surveys.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;-&#23545;&#20598;&#34920;&#36848;&#26041;&#27861;&#65292;&#32467;&#21512;&#26032;&#30340;&#25554;&#20540;&#24230;&#37327;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#36895;&#25910;&#25947;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#26041;&#27861;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#24615;&#33021;&#20248;&#36234;&#12290;</title><link>http://arxiv.org/abs/2202.10506</link><description>&lt;p&gt;
&#21152;&#36895;&#27491;-&#23545;&#20598;&#26041;&#27861;&#27714;&#35299;&#27491;&#21017;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Accelerating Primal-dual Methods for Regularized Markov Decision Processes. (arXiv:2202.10506v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.10506
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;-&#23545;&#20598;&#34920;&#36848;&#26041;&#27861;&#65292;&#32467;&#21512;&#26032;&#30340;&#25554;&#20540;&#24230;&#37327;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#36895;&#25910;&#25947;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#26041;&#27861;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#24615;&#33021;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29109;&#27491;&#21017;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#26412;&#25991;&#20851;&#27880;&#29109;&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#27491;-&#23545;&#20598;&#34920;&#36848;&#12290;&#30001;&#20110;&#32570;&#20047;&#20005;&#26684;&#30340;&#20984;&#24615;&#21644;&#20985;&#24615;&#65292;&#26631;&#20934;&#30340;&#19968;&#38454;&#26041;&#27861;&#25910;&#25947;&#32531;&#24930;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#20108;&#27425;&#20984;&#21270;&#30340;&#27491;-&#23545;&#20598;&#34920;&#36848;&#12290;&#26032;&#34920;&#36848;&#30340;&#33258;&#28982;&#26799;&#24230;&#19978;&#21319;&#19979;&#38477;&#20855;&#26377;&#20840;&#23616;&#25910;&#25947;&#20445;&#35777;&#21644;&#25351;&#25968;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25554;&#20540;&#24230;&#37327;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#36895;&#25910;&#25947;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#37117;&#24456;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entropy regularized Markov decision processes have been widely used in reinforcement learning. This paper is concerned with the primal-dual formulation of the entropy regularized problems. Standard first-order methods suffer from slow convergence due to the lack of strict convexity and concavity. To address this issue, we first introduce a new quadratically convexified primal-dual formulation. The natural gradient ascent descent of the new formulation enjoys global convergence guarantee and exponential convergence rate. We also propose a new interpolating metric that further accelerates the convergence significantly. Numerical results are provided to demonstrate the performance of the proposed methods under multiple settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#20445;&#38505;&#34892;&#19994;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#25968;&#25454;&#20013;&#21457;&#29616;&#30340;&#20559;&#35265;&#21644;&#27495;&#35270;&#65292;&#25552;&#20986;&#20102;&#20844;&#24179;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#23454;&#29616;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#21516;&#26102;&#20445;&#35777;&#25968;&#25454;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2112.09466</link><description>&lt;p&gt;
&#20844;&#24179;&#20027;&#21160;&#23398;&#20064;&#65306;&#35299;&#20915;&#20445;&#38505;&#34892;&#19994;&#20013;&#30340;&#26631;&#27880;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fair Active Learning: Solving the Labeling Problem in Insurance. (arXiv:2112.09466v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.09466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#20445;&#38505;&#34892;&#19994;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#25968;&#25454;&#20013;&#21457;&#29616;&#30340;&#20559;&#35265;&#21644;&#27495;&#35270;&#65292;&#25552;&#20986;&#20102;&#20844;&#24179;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#23454;&#29616;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#21516;&#26102;&#20445;&#35777;&#25968;&#25454;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22312;&#20445;&#38505;&#34892;&#19994;&#24191;&#27867;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25152;&#38754;&#20020;&#30340;&#37325;&#22823;&#38556;&#30861;&#65292;&#29305;&#21035;&#20851;&#27880;&#20419;&#36827;&#20844;&#24179;&#24615;&#12290;&#26368;&#21021;&#30340;&#25361;&#25112;&#22312;&#20110;&#26377;&#25928;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#20445;&#38505;&#25968;&#25454;&#65292;&#36890;&#36807;&#20027;&#21160;&#23398;&#20064;&#25216;&#26415;&#38477;&#20302;&#26631;&#27880;&#30340;&#24037;&#20316;&#37327;&#65292;&#24182;&#24378;&#35843;&#25968;&#25454;&#30456;&#20851;&#24615;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#21508;&#31181;&#20027;&#21160;&#23398;&#20064;&#25277;&#26679;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#23427;&#20204;&#23545;&#21512;&#25104;&#21644;&#23454;&#38469;&#20445;&#38505;&#25968;&#25454;&#38598;&#30340;&#24433;&#21709;&#12290;&#35813;&#20998;&#26512;&#24378;&#35843;&#20102;&#23454;&#29616;&#20844;&#27491;&#27169;&#22411;&#25512;&#26029;&#30340;&#22256;&#38590;&#65292;&#22240;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#33021;&#20250;&#22797;&#21046;&#24213;&#23618;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#20559;&#35265;&#21644;&#27495;&#35270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#30456;&#20114;&#20851;&#32852;&#30340;&#25361;&#25112;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#20844;&#24179;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#37319;&#26679;&#20449;&#24687;&#37327;&#20805;&#36275;&#19988;&#20844;&#24179;&#30340;&#23454;&#20363;&#65292;&#22312;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#65292;&#36825;&#19968;&#28857;&#22312;&#20445;&#38505;&#25968;&#25454;&#38598;&#19978;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses significant obstacles that arise from the widespread use of machine learning models in the insurance industry, with a specific focus on promoting fairness. The initial challenge lies in effectively leveraging unlabeled data in insurance while reducing the labeling effort and emphasizing data relevance through active learning techniques. The paper explores various active learning sampling methodologies and evaluates their impact on both synthetic and real insurance datasets. This analysis highlights the difficulty of achieving fair model inferences, as machine learning models may replicate biases and discrimination found in the underlying data. To tackle these interconnected challenges, the paper introduces an innovative fair active learning method. The proposed approach samples informative and fair instances, achieving a good balance between model predictive performance and fairness, as confirmed by numerical experiments on insurance datasets.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;SubseasonalClimateUSA&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35757;&#32451;&#21644;&#22522;&#20934;&#27979;&#35797;&#32654;&#22269;&#30340;&#20122;&#23395;&#33410;&#39044;&#27979;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#12290;&#20316;&#32773;&#20351;&#29992;&#35813;&#25968;&#25454;&#38598;&#23545;&#22810;&#31181;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2109.10399</link><description>&lt;p&gt;
SubseasonalClimateUSA: &#29992;&#20110;&#20122;&#23395;&#33410;&#39044;&#27979;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking. (arXiv:2109.10399v3 [physics.ao-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.10399
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;SubseasonalClimateUSA&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35757;&#32451;&#21644;&#22522;&#20934;&#27979;&#35797;&#32654;&#22269;&#30340;&#20122;&#23395;&#33410;&#39044;&#27979;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#12290;&#20316;&#32773;&#20351;&#29992;&#35813;&#25968;&#25454;&#38598;&#23545;&#22810;&#31181;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22825;&#27668;&#30340;&#20122;&#23395;&#33410;&#39044;&#27979;&#23545;&#36164;&#28304;&#37197;&#32622;&#21644;&#27668;&#20505;&#36866;&#24212;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#23545;&#39044;&#27979;&#31038;&#21306;&#25552;&#20986;&#20102;&#35768;&#22810;&#25361;&#25112;&#12290;&#22312;&#36825;&#20010;&#39044;&#27979;&#26102;&#38388;&#33539;&#22260;&#20869;&#65292;&#22522;&#20110;&#29289;&#29702;&#30340;&#21160;&#21147;&#23398;&#27169;&#22411;&#30340;&#25216;&#33021;&#26377;&#38480;&#65292;&#24182;&#19988;&#39044;&#27979;&#30446;&#26631;&#20197;&#19968;&#31181;&#22797;&#26434;&#30340;&#26041;&#24335;&#20381;&#36182;&#20110;&#26412;&#22320;&#22825;&#27668;&#21644;&#20840;&#29699;&#27668;&#20505;&#21464;&#37327;&#12290;&#26368;&#36817;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26174;&#31034;&#20986;&#25512;&#36827;&#25216;&#26415;&#30340;&#28508;&#21147;&#65292;&#20294;&#38656;&#35201;&#22797;&#26434;&#30340;&#25968;&#25454;&#25972;&#29702;&#65292;&#23558;&#19987;&#23478;&#30693;&#35782;&#19982;&#22810;&#20010;&#30456;&#20851;&#25968;&#25454;&#26469;&#28304;&#12289;&#25991;&#20214;&#26684;&#24335;&#21644;&#26102;&#38388;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#32858;&#21512;&#36827;&#34892;&#25972;&#21512;&#12290;&#20026;&#20102;&#31616;&#21270;&#36825;&#20010;&#36807;&#31243;&#24182;&#21152;&#36895;&#26410;&#26469;&#30340;&#21457;&#23637;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;SubseasonalClimateUSA&#65292;&#36825;&#26159;&#19968;&#20010;&#32463;&#36807;&#31574;&#21010;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35757;&#32451;&#21644;&#22522;&#20934;&#27979;&#35797;&#32654;&#22269;&#30340;&#20122;&#23395;&#33410;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#25968;&#25454;&#38598;&#26469;&#23545;&#21508;&#31181;&#19981;&#21516;&#30340;&#20122;&#23395;&#33410;&#27169;&#22411;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#25805;&#20316;&#24615;&#21160;&#21147;&#23398;&#27169;&#22411;&#12289;&#21476;&#20856;&#30340;&#27668;&#35937;&#22522;&#32447;&#20197;&#21450;&#21313;&#20010;&#32479;&#35745;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Subseasonal forecasting of the weather two to six weeks in advance is critical for resource allocation and climate adaptation but poses many challenges for the forecasting community. At this forecast horizon, physics-based dynamical models have limited skill, and the targets for prediction depend in a complex manner on both local weather and global climate variables. Recently, machine learning methods have shown promise in advancing the state of the art but only at the cost of complex data curation, integrating expert knowledge with aggregation across multiple relevant data sources, file formats, and temporal and spatial resolutions. To streamline this process and accelerate future development, we introduce SubseasonalClimateUSA, a curated dataset for training and benchmarking subseasonal forecasting models in the United States. We use this dataset to benchmark a diverse suite of subseasonal models, including operational dynamical models, classical meteorological baselines, and ten sta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#20998;&#24067;&#20048;&#35266;&#20248;&#21270;&#65288;DOO&#65289;&#27169;&#22411;&#65292;&#22312;&#22806;&#25512;&#38382;&#39064;&#19978;&#22987;&#32456;&#33021;&#22815;&#36229;&#36234;&#26679;&#26412;&#24179;&#22343;&#36924;&#36817;&#65288;SAA&#65289;&#65307;&#28982;&#32780;&#65292;&#20048;&#35266;&#35299;&#30340;&#40065;&#26834;&#24615;&#36739;&#24046;&#19988;&#26356;&#23481;&#26131;&#21463;&#21040;&#27169;&#22411;&#38169;&#35823;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2105.12342</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#20987;&#36133;SAA&#65288;&#26679;&#26412;&#24179;&#22343;&#36924;&#36817;&#65289;&#30340;&#22806;&#25512;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A data-driven approach to beating SAA out-of-sample. (arXiv:2105.12342v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.12342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#20998;&#24067;&#20048;&#35266;&#20248;&#21270;&#65288;DOO&#65289;&#27169;&#22411;&#65292;&#22312;&#22806;&#25512;&#38382;&#39064;&#19978;&#22987;&#32456;&#33021;&#22815;&#36229;&#36234;&#26679;&#26412;&#24179;&#22343;&#36924;&#36817;&#65288;SAA&#65289;&#65307;&#28982;&#32780;&#65292;&#20048;&#35266;&#35299;&#30340;&#40065;&#26834;&#24615;&#36739;&#24046;&#19988;&#26356;&#23481;&#26131;&#21463;&#21040;&#27169;&#22411;&#38169;&#35823;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#30340;&#35299;&#26377;&#26102;&#21487;&#33021;&#27604;&#26679;&#26412;&#24179;&#22343;&#36924;&#36817;&#65288;SAA&#65289;&#30340;&#39044;&#26399;&#22870;&#21169;&#35201;&#39640;&#65292;&#20294;&#24182;&#19981;&#20445;&#35777;&#24635;&#26159;&#36825;&#26679;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31867;&#20998;&#24067;&#20048;&#35266;&#20248;&#21270;&#65288;DOO&#65289;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#22914;&#26524;&#25105;&#20204;&#32771;&#34385;&#26368;&#20248;&#24773;&#20917;&#65288;DOO&#65289;&#21644;&#26368;&#22351;&#24773;&#20917;&#65288;DRO&#65289;&#27169;&#22411;&#65292;&#37027;&#20040;&#24635;&#26159;&#21487;&#20197;&#8220;&#20987;&#36133;&#8221;SAA&#30340;&#22806;&#25512;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20063;&#35777;&#26126;&#65292;&#36825;&#26159;&#26377;&#20195;&#20215;&#30340;&#65306;&#20048;&#35266;&#35299;&#27604;&#26368;&#22351;&#24773;&#20917;&#25110;SAA&#20248;&#21270;&#22120;&#26356;&#25935;&#24863;&#20110;&#27169;&#22411;&#38169;&#35823;&#65292;&#22240;&#27492;&#19981;&#22826;&#40065;&#26834;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#26377;&#38480;&#26102;&#24456;&#38590;&#26657;&#20934;&#26368;&#22351;&#25110;&#26368;&#20248;&#24773;&#20917;&#27169;&#22411;&#20197;&#36229;&#36234;SAA&#12290;
&lt;/p&gt;
&lt;p&gt;
While solutions of Distributionally Robust Optimization (DRO) problems can sometimes have a higher out-of-sample expected reward than the Sample Average Approximation (SAA), there is no guarantee. In this paper, we introduce a class of Distributionally Optimistic Optimization (DOO) models, and show that it is always possible to ``beat" SAA out-of-sample if we consider not just worst-case (DRO) models but also best-case (DOO) ones. We also show, however, that this comes at a cost: Optimistic solutions are more sensitive to model error than either worst-case or SAA optimizers, and hence are less robust and calibrating the worst- or best-case model to outperform SAA may be difficult when data is limited.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#38543;&#26426;&#27169;&#25311;&#22120;&#65292;&#32467;&#21512;&#20102;&#32463;&#20856;&#30340;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#22120;&#21644;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#22120;&#65292;&#29992;&#20110;&#24314;&#27169;&#12289;&#20272;&#35745;&#21644;&#27169;&#25311;&#20855;&#26377;&#19968;&#33324;&#38750;&#24179;&#31283;&#21644;&#22810;&#32500;&#38543;&#26426;&#21040;&#36798;&#36895;&#29575;&#30340;&#21040;&#36798;&#36807;&#31243;&#65292;&#24182;&#22312;&#39640;&#36895;&#20844;&#36335;&#20132;&#36890;&#21644;&#33322;&#31354;&#20132;&#36890;&#24314;&#27169;&#21644;&#20223;&#30495;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2012.13940</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#24212;&#29992;&#20110;&#21040;&#36798;&#27169;&#25311;&#21644;&#24314;&#27169;&#30340;&#21452;&#37325;&#38543;&#26426;&#27169;&#25311;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Doubly Stochastic Simulator with Applications in Arrivals Modeling and Simulation. (arXiv:2012.13940v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.13940
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#38543;&#26426;&#27169;&#25311;&#22120;&#65292;&#32467;&#21512;&#20102;&#32463;&#20856;&#30340;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#22120;&#21644;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#22120;&#65292;&#29992;&#20110;&#24314;&#27169;&#12289;&#20272;&#35745;&#21644;&#27169;&#25311;&#20855;&#26377;&#19968;&#33324;&#38750;&#24179;&#31283;&#21644;&#22810;&#32500;&#38543;&#26426;&#21040;&#36798;&#36895;&#29575;&#30340;&#21040;&#36798;&#36807;&#31243;&#65292;&#24182;&#22312;&#39640;&#36895;&#20844;&#36335;&#20132;&#36890;&#21644;&#33322;&#31354;&#20132;&#36890;&#24314;&#27169;&#21644;&#20223;&#30495;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#38598;&#25104;&#20102;&#32463;&#20856;&#30340;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#22120;&#21644;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20197;&#27169;&#25311;&#12289;&#20272;&#35745;&#21644;&#27169;&#25311;&#20855;&#26377;&#19968;&#33324;&#38750;&#24179;&#31283;&#21644;&#22810;&#32500;&#38543;&#26426;&#21040;&#36798;&#36895;&#29575;&#30340;&#24191;&#27867;&#21040;&#36798;&#36807;&#31243;&#30340;&#31867;&#21035;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#37325;&#38543;&#26426;&#27169;&#25311;&#22120;&#65292;&#23427;&#38598;&#25104;&#20102;&#38543;&#26426;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#21644;&#32463;&#20856;&#30340;&#33945;&#29305;&#21345;&#32599;&#27850;&#26494;&#27169;&#25311;&#22120;&#65292;&#21033;&#29992;&#20102;&#20004;&#32773;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#21508;&#31181;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#39640;&#36895;&#20844;&#36335;&#20132;&#36890;&#21644;&#33322;&#31354;&#20132;&#36890;&#24314;&#27169;&#21644;&#20223;&#30495;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a framework that integrates classical Monte Carlo simulators and Wasserstein generative adversarial networks to model, estimate, and simulate a broad class of arrival processes with general non-stationary and multi-dimensional random arrival rates. Classical Monte Carlo simulators have advantages at capturing the interpretable "physics" of a stochastic object, whereas neural-network-based simulators have advantages at capturing less-interpretable complicated dependence within a high-dimensional distribution. We propose a doubly stochastic simulator that integrates a stochastic generative neural network and a classical Monte Carlo Poisson simulator, to utilize both advantages. Such integration brings challenges to both theoretical reliability and computational tractability for the estimation of the simulator given real data, where the estimation is done through minimizing the Wasserstein distance between the distribution of the simulation output and the distribution of real d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#26469;&#23398;&#20064;&#28385;&#36275;&#26410;&#30693;&#32422;&#26463;&#26465;&#20214;&#30340;&#25511;&#21046;&#35774;&#35745;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#25910;&#38598;&#30340;&#25968;&#25454;&#25913;&#36827;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#20272;&#35745;&#65292;&#20351;&#29992;MPC&#25511;&#21046;&#22120;&#24378;&#20581;&#22320;&#28385;&#36275;&#20272;&#35745;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#31283;&#20581;&#24615;&#21644;&#27010;&#29575;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2006.05054</link><description>&lt;p&gt;
&#36845;&#20195;MPC&#20013;&#23398;&#20064;&#28385;&#36275;&#26410;&#30693;&#32422;&#26463;&#26465;&#20214;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning to Satisfy Unknown Constraints in Iterative MPC. (arXiv:2006.05054v3 [eess.SY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.05054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#26469;&#23398;&#20064;&#28385;&#36275;&#26410;&#30693;&#32422;&#26463;&#26465;&#20214;&#30340;&#25511;&#21046;&#35774;&#35745;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#25910;&#38598;&#30340;&#25968;&#25454;&#25913;&#36827;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#20272;&#35745;&#65292;&#20351;&#29992;MPC&#25511;&#21046;&#22120;&#24378;&#20581;&#22320;&#28385;&#36275;&#20272;&#35745;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#31283;&#20581;&#24615;&#21644;&#27010;&#29575;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32447;&#24615;&#23450;&#24120;&#31995;&#32479;&#30340;&#25511;&#21046;&#35774;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#36845;&#20195;&#23398;&#20064;&#28385;&#36275;&#26410;&#30693;&#22810;&#38754;&#20307;&#29366;&#24577;&#32422;&#26463;&#26465;&#20214;&#12290;&#22312;&#37325;&#22797;&#20219;&#21153;&#30340;&#27599;&#20010;&#36845;&#20195;&#20013;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#25910;&#38598;&#30340;&#38381;&#29615;&#36712;&#36857;&#25968;&#25454;&#26500;&#24314;&#26410;&#30693;&#29615;&#22659;&#32422;&#26463;&#26465;&#20214;&#30340;&#20272;&#35745;&#12290;&#22312;&#25910;&#38598;&#21040;&#26356;&#22810;&#25968;&#25454;&#21518;&#65292;&#36825;&#20010;&#20272;&#35745;&#30340;&#32422;&#26463;&#38598;&#21512;&#20250;&#24471;&#21040;&#36845;&#20195;&#25913;&#36827;&#12290;&#25509;&#30528;&#65292;MPC&#25511;&#21046;&#22120;&#34987;&#35774;&#35745;&#25104;&#21487;&#20197;&#24378;&#20581;&#22320;&#28385;&#36275;&#36825;&#20010;&#20272;&#35745;&#30340;&#32422;&#26463;&#38598;&#21512;&#12290;&#26412;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#32454;&#33410;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#32422;&#26463;&#28385;&#36275;&#30340;&#31283;&#20581;&#24615;&#21644;&#27010;&#29575;&#20445;&#35777;&#65292;&#36825;&#21462;&#20915;&#20110;&#25191;&#34892;&#20219;&#21153;&#36845;&#20195;&#30340;&#27425;&#25968;&#12290;&#25105;&#20204;&#22312;&#35814;&#32454;&#30340;&#25968;&#20540;&#20363;&#23376;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26694;&#26550;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#25506;&#32034;&#20102;&#23433;&#20840;&#24615;&#19982;&#24615;&#33021;&#20043;&#38388;&#30340;&#25240;&#34935;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a control design method for linear time-invariant systems that iteratively learns to satisfy unknown polyhedral state constraints. At each iteration of a repetitive task, the method constructs an estimate of the unknown environment constraints using collected closed-loop trajectory data. This estimated constraint set is improved iteratively upon collection of additional data. An MPC controller is then designed to robustly satisfy the estimated constraint set. This paper presents the details of the proposed approach, and provides robust and probabilistic guarantees of constraint satisfaction as a function of the number of executed task iterations. We demonstrate the safety of the proposed framework and explore the safety vs. performance trade-off in a detailed numerical example.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#25366;&#25496;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;&#19968;&#31181;&#22522;&#20110;GRASP&#30340;&#26368;&#23567;&#24310;&#36831;&#38382;&#39064;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#65292;&#21305;&#37197;&#25110;&#20248;&#20110;&#35299;&#30340;&#36136;&#37327;&#65292;&#22312;&#22823;&#22823;&#32553;&#30701;&#35745;&#31639;&#26102;&#38388;&#30340;&#21516;&#26102;&#65292;&#36824;&#25104;&#21151;&#22320;&#24341;&#20837;&#20102;88&#20010;&#26032;&#30340;&#35299;&#25104;&#26412;&#20540;&#12290;</title><link>http://arxiv.org/abs/1908.10705</link><description>&lt;p&gt;
&#36816;&#29992;&#25968;&#25454;&#25366;&#25496;&#25913;&#36827;&#26368;&#23567;&#24310;&#36831;&#38382;&#39064;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improving a State-of-the-Art Heuristic for the Minimum Latency Problem with Data Mining. (arXiv:1908.10705v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1908.10705
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#25366;&#25496;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;&#19968;&#31181;&#22522;&#20110;GRASP&#30340;&#26368;&#23567;&#24310;&#36831;&#38382;&#39064;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#65292;&#21305;&#37197;&#25110;&#20248;&#20110;&#35299;&#30340;&#36136;&#37327;&#65292;&#22312;&#22823;&#22823;&#32553;&#30701;&#35745;&#31639;&#26102;&#38388;&#30340;&#21516;&#26102;&#65292;&#36824;&#25104;&#21151;&#22320;&#24341;&#20837;&#20102;88&#20010;&#26032;&#30340;&#35299;&#25104;&#26412;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#22312;&#36816;&#31609;&#23398;&#20013;&#36234;&#26469;&#36234;&#27969;&#34892;&#12290;&#20854;&#20013;&#19968;&#31181;&#25104;&#21151;&#30340;&#26041;&#27861;&#26159;&#23558;&#36138;&#24515;&#38543;&#26426;&#33258;&#36866;&#24212;&#25628;&#32034;&#31243;&#24207;&#65288;GRASP&#65289;&#19982;&#25968;&#25454;&#25366;&#25496;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#21033;&#29992;&#39640;&#36136;&#37327;&#35299;&#20013;&#21457;&#29616;&#30340;&#39057;&#32321;&#27169;&#24335;&#65292;&#22312;&#20445;&#35777;&#25628;&#32034;&#33539;&#22260;&#30340;&#21516;&#26102;&#26174;&#33879;&#20943;&#23569;&#35745;&#31639;&#26102;&#38388;&#12290;&#26412;&#25991;&#21033;&#29992;&#25968;&#25454;&#25366;&#25496;&#25216;&#26415;&#25913;&#36827;&#20102;&#19968;&#20010;&#22522;&#20110;GRASP&#30340;&#26368;&#23567;&#24310;&#36831;&#38382;&#39064;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#20004;&#20010;&#38382;&#39064;&#21464;&#20307;&#12290;&#35745;&#31639;&#23454;&#39564;&#35777;&#26126;&#65292;&#25968;&#25454;&#25366;&#25496;&#26041;&#27861;&#33021;&#22815;&#22312;&#36739;&#22823;&#25968;&#37327;&#30340;&#23454;&#20363;&#19978;&#21305;&#37197;&#25110;&#25913;&#21892;&#35299;&#30340;&#36136;&#37327;&#65292;&#21516;&#26102;&#22823;&#22823;&#20943;&#23569;&#36816;&#34892;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#24341;&#20837;&#20102;88&#20010;&#26032;&#30340;&#35299;&#25104;&#26412;&#20540;&#12290;&#20026;&#20102;&#25903;&#25345;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#32479;&#35745;&#26174;&#33879;&#24615;&#26816;&#39564;&#12289;&#25366;&#25496;&#27169;&#24335;&#30340;&#24433;&#21709;&#12289;&#31561;&#26102;&#38388;&#27604;&#36739;&#21644;&#26102;&#38388;&#21040;&#30446;&#26631;&#26354;&#32447;&#30340;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, hybrid metaheuristics have become a trend in operations research. A successful example combines the Greedy Randomized Adaptive Search Procedures (GRASP) and data mining techniques, where frequent patterns found in high-quality solutions can lead to an efficient exploration of the search space, along with a significant reduction of computational time. In this work, a GRASP-based state-of-the-art heuristic for the Minimum Latency Problem (MLP) is improved by means of data mining techniques for two MLP variants. Computational experiments showed that the approaches with data mining were able to match or improve the solution quality for a large number of instances, together with a substantial reduction of running time. In addition, 88 new cost values of solutions are introduced into the literature. To support our results, tests of statistical significance, impact of using mined patterns, equal time comparisons and time-to-target plots are provided.
&lt;/p&gt;</description></item></channel></rss>