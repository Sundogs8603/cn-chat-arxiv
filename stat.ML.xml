<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#21021;&#20540;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31283;&#23450;&#21487;&#25193;&#23637;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#20840;&#23616;&#26368;&#23567;&#21270;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20013;&#30340; PDE &#27531;&#24046;&#20013;&#36935;&#21040;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#21644; ODE &#26041;&#27861;&#20013;&#38543;&#30528;&#25968;&#37327;&#21576;&#31435;&#26041;&#32423;&#21035;&#25193;&#23637;&#31561;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.14994</link><description>&lt;p&gt;
&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#21021;&#20540;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31283;&#23450;&#21487;&#25193;&#23637;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks. (arXiv:2304.14994v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#21021;&#20540;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31283;&#23450;&#21487;&#25193;&#23637;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#20840;&#23616;&#26368;&#23567;&#21270;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20013;&#30340; PDE &#27531;&#24046;&#20013;&#36935;&#21040;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#21644; ODE &#26041;&#27861;&#20013;&#38543;&#30528;&#25968;&#37327;&#21576;&#31435;&#26041;&#32423;&#21035;&#25193;&#23637;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20256;&#32479;&#30340;&#32593;&#26684;&#21644;&#22522;&#20110;&#32593;&#26684;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#31070;&#32463;&#32593;&#32476;&#26377;&#21487;&#33021;&#25171;&#30772;&#32500;&#25968;&#28798;&#38590;&#65292;&#22312;&#20351;&#29992;&#32463;&#20856;&#27714;&#35299;&#22120;&#22256;&#38590;&#25110;&#19981;&#21487;&#33021;&#30340;&#38382;&#39064;&#20013;&#25552;&#20379;&#36817;&#20284;&#35299;&#12290;&#20840;&#23616;&#26368;&#23567;&#21270;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20013;&#30340; PDE &#27531;&#24046;&#23545;&#20110;&#36793;&#30028;&#20540;&#38382;&#39064;&#25928;&#26524;&#33391;&#22909;&#65292;&#20294;&#26159;&#28798;&#38590;&#24615;&#24536;&#21364;&#25439;&#23475;&#20102;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#21021;&#20540;&#38382;&#39064;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#26367;&#20195;&#30340;&#23616;&#37096;&#26102;&#38388;&#26041;&#27861;&#20013;&#65292;&#21487;&#20197;&#23558;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#32593;&#32476;&#21442;&#25968;&#19978;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#65292;&#24182;&#23558;&#35299;&#21521;&#21069;&#20256;&#25773;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30446;&#21069;&#22522;&#20110;&#36825;&#31181;&#26041;&#27861;&#30340;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#36981;&#24490; ODE &#20250;&#23548;&#33268;&#38382;&#39064;&#26465;&#20214;&#22686;&#38271;&#26080;&#27861;&#25511;&#21046;&#65292;&#26368;&#32456;&#23548;&#33268;&#19981;&#21487;&#25509;&#21463;&#30340;&#22823;&#25968;&#20540;&#35823;&#24046;&#12290;&#20854;&#27425;&#65292;&#38543;&#30528; ODE &#26041;&#27861;&#38543;&#30528; m &#30340;&#25968;&#37327;&#21576;&#31435;&#26041;&#32423;&#21035;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unlike conventional grid and mesh based methods for solving partial differential equations (PDEs), neural networks have the potential to break the curse of dimensionality, providing approximate solutions to problems where using classical solvers is difficult or impossible. While global minimization of the PDE residual over the network parameters works well for boundary value problems, catastrophic forgetting impairs the applicability of this approach to initial value problems (IVPs). In an alternative local-in-time approach, the optimization problem can be converted into an ordinary differential equation (ODE) on the network parameters and the solution propagated forward in time; however, we demonstrate that current methods based on this approach suffer from two key issues. First, following the ODE produces an uncontrolled growth in the conditioning of the problem, ultimately leading to unacceptably large numerical errors. Second, as the ODE methods scale cubically with the number of m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Kullback-Leibler Maillard Sampling (KL-MS)&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#23454;&#29616;KL&#31354;&#38388;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.14989</link><description>&lt;p&gt;
Kullback-Leibler Maillard&#37319;&#26679;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards. (arXiv:2304.14989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Kullback-Leibler Maillard Sampling (KL-MS)&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#23454;&#29616;KL&#31354;&#38388;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22870;&#21169;&#20998;&#24067;&#38598;&#20013;&#22312;&#21306;&#38388;$[0,1]$&#20869;&#30340;$K$&#33218;&#25968;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Kullback-Leibler Maillard Sampling (KL-MS)&#30340;&#26032;&#31639;&#27861;&#65292;&#23427;&#26159;Maillard&#37319;&#26679;&#22312;KL&#31354;&#38388;&#30340;&#33258;&#28982;&#25193;&#23637;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;KL-MS&#22312;Bernoulli&#22870;&#21169;&#26102;&#20855;&#26377;&#28176;&#36817;&#26368;&#20248;&#24615;&#33021;&#65292;&#20854;&#26368;&#22351;&#24773;&#20917;&#36951;&#25022;&#24230;&#19978;&#30028;&#20026;$O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$&#65292;&#20854;&#20013;$\mu^*$&#26159;&#26368;&#20248;&#33218;&#30340;&#26399;&#26395;&#22870;&#21169;&#65292;$T$&#26159;&#26102;&#27573;&#38271;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study $K$-armed bandit problems where the reward distributions of the arms are all supported on the $[0,1]$ interval. It has been a challenge to design regret-efficient randomized exploration algorithms in this setting. Maillard sampling~\cite{maillard13apprentissage}, an attractive alternative to Thompson sampling, has recently been shown to achieve competitive regret guarantees in the sub-Gaussian reward setting~\cite{bian2022maillard} while maintaining closed-form action probabilities, which is useful for offline policy evaluation. In this work, we propose the Kullback-Leibler Maillard Sampling (KL-MS) algorithm, a natural extension of Maillard sampling for achieving KL-style gap-dependent regret bound. We show that KL-MS enjoys the asymptotic optimality when the rewards are Bernoulli and has a worst-case regret bound of the form $O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$, where $\mu^*$ is the expected reward of the optimal arm, and $T$ is the time horizon length.
&lt;/p&gt;</description></item><item><title>PAM&#27169;&#22411;&#26159;&#22522;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#30340;&#20998;&#32452;&#25968;&#25454;&#20998;&#26512;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;&#38646;&#22686;&#24378;&#36125;&#22612;&#65288;ZAB&#65289;&#20998;&#24067;&#23454;&#29616;&#20102;&#22810;&#32452;&#38388;&#30340;&#21407;&#23376;&#20849;&#20139;&#21644;&#29420;&#29305;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.14954</link><description>&lt;p&gt;
PAM&#65306;&#22522;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#30340;&#20998;&#32452;&#25968;&#25454;&#20998;&#26512;&#30340;&#26684;&#23376;&#21407;&#23376;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
PAM: Plaid Atoms Model for Bayesian Nonparametric Analysis of Grouped Data. (arXiv:2304.14954v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14954
&lt;/p&gt;
&lt;p&gt;
PAM&#27169;&#22411;&#26159;&#22522;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#30340;&#20998;&#32452;&#25968;&#25454;&#20998;&#26512;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;&#38646;&#22686;&#24378;&#36125;&#22612;&#65288;ZAB&#65289;&#20998;&#24067;&#23454;&#29616;&#20102;&#22810;&#32452;&#38388;&#30340;&#21407;&#23376;&#20849;&#20139;&#21644;&#29420;&#29305;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23545;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#30456;&#20851;&#32858;&#31867;&#30340;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#31216;&#20026;&#26684;&#23376;&#21407;&#23376;&#27169;&#22411;&#65288;PAM&#65289;&#65292;&#23545;&#20110;&#27599;&#20010;&#32452;&#20272;&#35745;&#19968;&#32452;&#32858;&#31867;&#65292;&#24182;&#20801;&#35768;&#19968;&#20123;&#32858;&#31867;&#19982;&#20854;&#20182;&#32452;&#20849;&#20139;&#25110;&#20165;&#20026;&#35813;&#32452;&#25152;&#25317;&#26377;&#12290;PAM&#22522;&#20110;&#23545;&#20247;&#25152;&#21608;&#30693;&#30340;&#31896;&#24615;&#30772;&#35010;&#36807;&#31243;&#30340;&#25193;&#23637;&#65292;&#36890;&#36807;&#23558;&#38646;&#28155;&#21152;&#20026;&#32858;&#31867;&#26435;&#37325;&#30340;&#21487;&#33021;&#20540;&#20043;&#19968;&#65292;&#20174;&#32780;&#22312;&#27169;&#22411;&#20013;&#20135;&#29983;&#38646;&#22686;&#24378;&#36125;&#22612;&#65288;ZAB&#65289;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;ZAB&#20801;&#35768;&#22312;&#22810;&#20010;&#32452;&#20013;&#19968;&#20123;&#32858;&#31867;&#30340;&#26435;&#37325;&#24688;&#22909;&#20026;&#38646;&#65292;&#20174;&#32780;&#23454;&#29616;&#32452;&#38388;&#20849;&#20139;&#21644;&#29420;&#29305;&#30340;&#21407;&#23376;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;PAM&#30340;&#29702;&#35770;&#23646;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#24050;&#30693;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20999;&#29255;&#21462;&#26679;&#22120;&#29992;&#20110;&#21518;&#39564;&#25512;&#26029;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#22810;&#20803;&#25110;&#35745;&#25968;&#25968;&#25454;&#25552;&#20986;&#20102;&#25152;&#25552;&#20986;&#27169;&#22411;&#30340;&#36731;&#24494;&#25193;&#23637;&#12290;&#36890;&#36807;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#24212;&#29992;&#35828;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider dependent clustering of observations in groups. The proposed model, called the plaid atoms model (PAM), estimates a set of clusters for each group and allows some clusters to be either shared with other groups or uniquely possessed by the group. PAM is based on an extension to the well-known stick-breaking process by adding zero as a possible value for the cluster weights, resulting in a zero-augmented beta (ZAB) distribution in the model. As a result, ZAB allows some cluster weights to be exactly zero in multiple groups, thereby enabling shared and unique atoms across groups. We explore theoretical properties of PAM and show its connection to known Bayesian nonparametric models. We propose an efficient slice sampler for posterior inference. Minor extensions of the proposed model for multivariate or count data are presented. Simulation studies and applications using real-world datasets illustrate the model's desirable performance.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#29420;&#31435;&#30340;&#20301;&#32622;-&#27604;&#20363;&#20998;&#24067;&#30340;1-Wasserstein&#36317;&#31163;&#30340;&#35745;&#31639;&#20844;&#24335;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#32447;&#24615;&#19978;&#30028;&#21644;&#39640;&#26031;&#24773;&#20917;&#19979;&#30340;&#28176;&#36817;&#30028;&#38480;&#24182;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.14869</link><description>&lt;p&gt;
&#20851;&#20110;&#20301;&#32622;-&#27604;&#20363;&#20998;&#24067;&#30340;1-Wasserstein&#36317;&#31163;&#21450;&#24046;&#20998;&#38544;&#31169;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the 1-Wasserstein Distance between Location-Scale Distributions and the Effect of Differential Privacy. (arXiv:2304.14869v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14869
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#29420;&#31435;&#30340;&#20301;&#32622;-&#27604;&#20363;&#20998;&#24067;&#30340;1-Wasserstein&#36317;&#31163;&#30340;&#35745;&#31639;&#20844;&#24335;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#32447;&#24615;&#19978;&#30028;&#21644;&#39640;&#26031;&#24773;&#20917;&#19979;&#30340;&#28176;&#36817;&#30028;&#38480;&#24182;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#29420;&#31435;&#20110;&#20301;&#32622;-&#27604;&#20363;&#20998;&#24067;&#30340;1-Wasserstein&#36317;&#31163;&#30340;&#20934;&#30830;&#35745;&#31639;&#20844;&#24335;&#12290; &#36825;&#20123;&#20844;&#24335;&#26159;&#29992;&#20301;&#32622;&#21644;&#27604;&#20363;&#21442;&#25968;&#20197;&#21450;&#29305;&#27530;&#20989;&#25968;(&#22914;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#25110;&#20285;&#39532;&#20989;&#25968;)&#34920;&#31034;&#30340;&#12290; &#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#29420;&#31435;&#20110;&#20301;&#32622;-&#27604;&#20363;&#20998;&#24067;&#30340;&#19968;&#32500;1-&#30697;&#37327;&#36317;&#31163;&#31561;&#20110;&#21516;&#19968;&#26063;&#20013;&#25240;&#21472;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#20854;&#22522;&#30784;&#20301;&#32622;&#21644;&#27604;&#20363;&#31561;&#20110;&#21407;&#22987;&#20998;&#24067;&#30340;&#20301;&#32622;&#21644;&#27604;&#20363;&#20043;&#24046;&#12290; &#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#32447;&#24615;&#19978;&#30028;&#21644;&#39640;&#26031;&#24773;&#20917;&#19979;&#30340;&#28176;&#36817;&#30028;&#38480;&#12290; &#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#38381;&#21512;&#30340;&#20844;&#24335;&#21644;&#30028;&#38480;&#26469;&#30740;&#31350;&#25289;&#26222;&#25289;&#26031;&#21644;&#39640;&#26031;&#26426;&#21046;&#23545;1-Wasserstein&#36317;&#31163;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide an exact expressions for the 1-Wasserstein distance between independent location-scale distributions. The expressions are represented using location and scale parameters and special functions such as the standard Gaussian CDF or the Gamma function. Specifically, we find that the 1-Wasserstein distance between independent univariate location-scale distributions is equivalent to the mean of a folded distribution within the same family whose underlying location and scale are equal to the difference of the locations and scales of the original distributions. A new linear upper bound on the 1-Wasserstein distance is presented and the asymptotic bounds of the 1-Wasserstein distance are detailed in the Gaussian case. The effect of differential privacy using the Laplace and Gaussian mechanisms on the 1-Wasserstein distance is studied using the closed-form expressions and bounds.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#35757;&#32451;&#25968;&#25454;&#21644;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20998;&#21306;&#30340;&#26041;&#27861;&#65292;&#23558;&#27599;&#20010;&#20998;&#21306;&#19982;&#29305;&#23450;&#30340;&#25968;&#25454;&#29255;&#27573;&#20851;&#32852;&#24182;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#20248;&#21270;&#36825;&#20123;&#20998;&#21306;&#30340;&#23376;&#32593;&#32476;&#30340;&#8220;&#35757;&#32451;&#20043;&#22806;&#30340;&#26679;&#26412;&#8221;&#25439;&#22833;&#65292;&#23454;&#29616;&#20102;&#22312;&#21333;&#27425;&#35757;&#32451;&#36816;&#34892;&#20013;&#38477;&#20302;&#36229;&#21442;&#25968;&#20248;&#21270;&#20195;&#20215;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.14766</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#20998;&#21106;&#36827;&#34892;&#36229;&#21442;&#25968;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Hyperparameter Optimization through Neural Network Partitioning. (arXiv:2304.14766v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#35757;&#32451;&#25968;&#25454;&#21644;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20998;&#21306;&#30340;&#26041;&#27861;&#65292;&#23558;&#27599;&#20010;&#20998;&#21306;&#19982;&#29305;&#23450;&#30340;&#25968;&#25454;&#29255;&#27573;&#20851;&#32852;&#24182;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#20248;&#21270;&#36825;&#20123;&#20998;&#21306;&#30340;&#23376;&#32593;&#32476;&#30340;&#8220;&#35757;&#32451;&#20043;&#22806;&#30340;&#26679;&#26412;&#8221;&#25439;&#22833;&#65292;&#23454;&#29616;&#20102;&#22312;&#21333;&#27425;&#35757;&#32451;&#36816;&#34892;&#20013;&#38477;&#20302;&#36229;&#21442;&#25968;&#20248;&#21270;&#20195;&#20215;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35843;&#25972;&#24688;&#24403;&#30340;&#36229;&#21442;&#23545;&#20110;&#33719;&#24471;&#31070;&#32463;&#32593;&#32476;&#20013;&#33391;&#22909;&#30340;&#27867;&#21270;&#34892;&#20026;&#33267;&#20851;&#37325;&#35201;&#12290;&#23427;&#20204;&#21487;&#20197;&#24378;&#21046;&#36866;&#24403;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#27491;&#21017;&#21270;&#27169;&#22411;&#24182;&#25552;&#39640;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#26377;&#38480;&#30340;&#25968;&#25454;&#24773;&#20917;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#20248;&#21270;&#36229;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#21463;&#36793;&#32536;&#20284;&#28982;&#30340;&#21551;&#21457;&#65292;&#36825;&#26159;&#19968;&#31181;&#19981;&#38656;&#35201;&#39564;&#35777;&#25968;&#25454;&#30340;&#20248;&#21270;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#35757;&#32451;&#25968;&#25454;&#21644;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20998;&#20026; K &#20010;&#25968;&#25454;&#20998;&#29255;&#21644;&#21442;&#25968;&#20998;&#21306;&#12290;&#27599;&#20010;&#20998;&#21306;&#20165;&#19982;&#29305;&#23450;&#30340;&#25968;&#25454;&#29255;&#27573;&#20851;&#32852;&#24182;&#36827;&#34892;&#20248;&#21270;&#12290;&#23558;&#36825;&#20123;&#20998;&#21306;&#32452;&#21512;&#25104;&#23376;&#32593;&#32476;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#23376;&#32593;&#32476;&#30340;&#8220;&#35757;&#32451;&#20043;&#22806;&#30340;&#26679;&#26412;&#8221;&#25439;&#22833;&#23450;&#20041;&#20026;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#30446;&#26631;&#65292;&#21363;&#22312;&#23376;&#32593;&#32476;&#30475;&#19981;&#21040;&#30340;&#25968;&#25454;&#29255;&#27573;&#19978;&#35745;&#31639;&#25439;&#22833;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#36825;&#20010;&#30446;&#26631;&#24212;&#29992;&#21040;&#21333;&#27425;&#35757;&#32451;&#36816;&#34892;&#20013;&#65292;&#21516;&#26102;&#26174;&#30528;&#38477;&#20302;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
Well-tuned hyperparameters are crucial for obtaining good generalization behavior in neural networks. They can enforce appropriate inductive biases, regularize the model and improve performance -- especially in the presence of limited data. In this work, we propose a simple and efficient way for optimizing hyperparameters inspired by the marginal likelihood, an optimization objective that requires no validation data. Our method partitions the training data and a neural network model into $K$ data shards and parameter partitions, respectively. Each partition is associated with and optimized only on specific data shards. Combining these partitions into subnetworks allows us to define the ``out-of-training-sample" loss of a subnetwork, i.e., the loss on data shards unseen by the subnetwork, as the objective for hyperparameter optimization. We demonstrate that we can apply this objective to optimize a variety of different hyperparameters in a single training run while being significantly c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22312;&#26679;&#26412;&#20013;&#24341;&#20837;&#25200;&#21160;&#65292;&#25913;&#36827;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#21516;&#36136;&#20294;&#28151;&#21512;&#27604;&#20363;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#23454;&#39564;&#35777;&#25454;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2304.14762</link><description>&lt;p&gt;
&#21033;&#29992;&#25200;&#21160;&#26469;&#25913;&#21892;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized Stein Discrepancy. (arXiv:2304.14762v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22312;&#26679;&#26412;&#20013;&#24341;&#20837;&#25200;&#21160;&#65292;&#25913;&#36827;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#21516;&#36136;&#20294;&#28151;&#21512;&#27604;&#20363;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#23454;&#39564;&#35777;&#25454;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#21270;&#26031;&#22374;&#36317;&#65288;KSD&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#24046;&#24322;&#24230;&#37327;&#12290;&#21363;&#20351;&#30446;&#26631;&#20998;&#24067;&#20855;&#26377;&#26410;&#30693;&#30340;&#26631;&#20934;&#21270;&#22240;&#23376;&#65292;&#20363;&#22914;&#22312;&#36125;&#21494;&#26031;&#20998;&#26512;&#20013;&#65292;&#20063;&#21487;&#20197;&#24212;&#29992;&#23427;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#30446;&#26631;&#20998;&#24067;&#21644;&#26367;&#20195;&#20998;&#24067;&#20855;&#26377;&#30456;&#21516;&#19988;&#30456;&#36317;&#36739;&#36828;&#30340;&#27169;&#24335;&#20294;&#22312;&#28151;&#21512;&#27604;&#20363;&#19978;&#26377;&#25152;&#19981;&#21516;&#26102;&#65292;KSD&#26816;&#39564;&#21487;&#33021;&#20250;&#20986;&#29616;&#20302;&#21151;&#29575;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#36716;&#31227;&#26680;&#23545;&#35266;&#27979;&#26679;&#26412;&#36827;&#34892;&#25200;&#21160;&#65292;&#20351;&#20854;&#30456;&#23545;&#20110;&#30446;&#26631;&#20998;&#24067;&#19981;&#21464;&#12290;&#36825;&#20351;&#25105;&#20204;&#21487;&#20197;&#22312;&#25200;&#21160;&#26679;&#26412;&#19978;&#20351;&#29992;KSD&#26816;&#39564;&#12290;&#25105;&#20204;&#25552;&#20379;&#30340;&#25968;&#20540;&#35777;&#25454;&#34920;&#26126;&#65292;&#20351;&#29992;&#36866;&#24403;&#36873;&#25321;&#30340;&#26680;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#27604;KSD&#26816;&#39564;&#20855;&#26377;&#26356;&#39640;&#30340;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernelized Stein discrepancy (KSD) is a score-based discrepancy widely used in goodness-of-fit tests. It can be applied even when the target distribution has an unknown normalising factor, such as in Bayesian analysis. We show theoretically and empirically that the KSD test can suffer from low power when the target and the alternative distribution have the same well-separated modes but differ in mixing proportions. We propose to perturb the observed sample via Markov transition kernels, with respect to which the target distribution is invariant. This allows us to then employ the KSD test on the perturbed sample. We provide numerical evidence that with suitably chosen kernels the proposed approach can lead to a substantially higher power than the KSD test.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35782;&#21035;&#20449;&#24687;&#29942;&#39048;&#65288;RIB&#65289;&#65292;&#20854;&#36890;&#36807;&#21487;&#35782;&#21035;&#24615;&#35780;&#35770;&#23478;&#26469;&#35268;&#33539;&#34920;&#31034;&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#25512;&#24191;&#26041;&#24335;&#65292;&#30456;&#27604;&#29616;&#26377;&#30340;&#20449;&#24687;&#29942;&#39048;&#33021;&#22815;&#26356;&#22909;&#22320;&#20445;&#35777;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.14618</link><description>&lt;p&gt;
&#21487;&#35782;&#21035;&#20449;&#24687;&#29942;&#39048;
&lt;/p&gt;
&lt;p&gt;
Recognizable Information Bottleneck. (arXiv:2304.14618v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14618
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35782;&#21035;&#20449;&#24687;&#29942;&#39048;&#65288;RIB&#65289;&#65292;&#20854;&#36890;&#36807;&#21487;&#35782;&#21035;&#24615;&#35780;&#35770;&#23478;&#26469;&#35268;&#33539;&#34920;&#31034;&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#25512;&#24191;&#26041;&#24335;&#65292;&#30456;&#27604;&#29616;&#26377;&#30340;&#20449;&#24687;&#29942;&#39048;&#33021;&#22815;&#26356;&#22909;&#22320;&#20445;&#35777;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#29942;&#39048;&#65288;IB&#65289;&#36890;&#36807;&#20449;&#24687;&#21387;&#32553;&#23398;&#20064;&#34920;&#31034;&#65292;&#20174;&#32780;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#34394;&#26080;&#30340;&#25512;&#24191;&#36793;&#30028;&#65292;&#29616;&#26377;&#30340;IB&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#26080;&#27861;&#20445;&#35777;&#25512;&#24191;&#24615;&#12290;&#26368;&#36817;&#30340;PAC-Bayes IB&#20351;&#29992;&#20449;&#24687;&#22797;&#26434;&#24230;&#32780;&#19981;&#26159;&#20449;&#24687;&#21387;&#32553;&#26469;&#24314;&#31435;&#19982;&#30456;&#20114;&#20449;&#24687;&#25512;&#24191;&#30028;&#38480;&#30340;&#32852;&#31995;&#12290;&#28982;&#32780;&#65292;&#23427;&#38656;&#35201;&#35745;&#31639;&#26114;&#36149;&#30340;&#20108;&#38454;&#26354;&#29575;&#65292;&#38459;&#30861;&#20102;&#20854;&#23454;&#38469;&#24212;&#29992;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#34920;&#31034;&#30340;&#21487;&#35782;&#21035;&#24615;&#19982;&#36817;&#26399;&#30340;&#20989;&#25968;&#26465;&#20214;&#20114;&#20449;&#24687;&#65288;f-CMI&#65289;&#25512;&#24191;&#36793;&#30028;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#35813;&#36793;&#30028;&#30340;&#20272;&#35745;&#35201;&#31616;&#21333;&#24471;&#22810;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35782;&#21035;&#20449;&#24687;&#29942;&#39048;&#65288;RIB&#65289;&#65292;&#36890;&#36807;&#22522;&#20110;Bregman&#25955;&#24230;&#19979;&#30340;&#23494;&#24230;&#27604;&#21305;&#37197;&#20248;&#21270;&#30340;&#21487;&#35782;&#21035;&#24615;&#35780;&#35770;&#23478;&#26469;&#35268;&#33539;&#34920;&#31034;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;&#22312;&#22810;&#20010;&#26631;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information Bottlenecks (IBs) learn representations that generalize to unseen data by information compression. However, existing IBs are practically unable to guarantee generalization in real-world scenarios due to the vacuous generalization bound. The recent PAC-Bayes IB uses information complexity instead of information compression to establish a connection with the mutual information generalization bound. However, it requires the computation of expensive second-order curvature, which hinders its practical application. In this paper, we establish the connection between the recognizability of representations and the recent functional conditional mutual information (f-CMI) generalization bound, which is significantly easier to estimate. On this basis we propose a Recognizable Information Bottleneck (RIB) which regularizes the recognizability of representations through a recognizability critic optimized by density ratio matching under the Bregman divergence. Extensive experiments on sev
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65288;CEPIA&#65289;&#65292;&#21487;&#20197;&#22788;&#29702;&#25968;&#25454;&#20013;&#30340;&#32570;&#22833;&#20540;&#65292;&#20351;&#24471;&#29992;&#25143;&#21487;&#20197;&#33719;&#24471;&#26377;&#25928;&#30340;&#34892;&#21160;&#24314;&#35758;&#24182;&#20102;&#35299;&#32570;&#22833;&#20540;&#23545;&#24314;&#35758;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.14606</link><description>&lt;p&gt;
&#32570;&#22833;&#20540;&#19979;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Explanation with Missing Values. (arXiv:2304.14606v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65288;CEPIA&#65289;&#65292;&#21487;&#20197;&#22788;&#29702;&#25968;&#25454;&#20013;&#30340;&#32570;&#22833;&#20540;&#65292;&#20351;&#24471;&#29992;&#25143;&#21487;&#20197;&#33719;&#24471;&#26377;&#25928;&#30340;&#34892;&#21160;&#24314;&#35758;&#24182;&#20102;&#35299;&#32570;&#22833;&#20540;&#23545;&#24314;&#35758;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#35299;&#37322;&#26159;&#19968;&#31181;&#25552;&#20379;&#25200;&#21160;&#20197;&#25913;&#21464;&#20998;&#31867;&#22120;&#39044;&#27979;&#32467;&#26524;&#30340;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#12290;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#23436;&#25972;&#20449;&#24687;&#30340;&#36755;&#20837;&#65292;&#20294;&#23454;&#38469;&#24773;&#20917;&#20013;&#24448;&#24448;&#20250;&#26377;&#32570;&#22833;&#20540;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;CE&#26694;&#26550;&#65288;&#31216;&#20026;CEPIA&#65289;&#65292;&#20351;&#29992;&#25143;&#21487;&#20197;&#22312;&#26377;&#32570;&#22833;&#20540;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#26377;&#25928;&#30340;&#25805;&#20316;&#65292;&#24182;&#38416;&#26126;&#32570;&#22833;&#20540;&#23545;&#25805;&#20316;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Explanation (CE) is a post-hoc explanation method that provides a perturbation for altering the prediction result of a classifier. Users can interpret the perturbation as an "action" to obtain their desired decision results. Existing CE methods require complete information on the features of an input instance. However, we often encounter missing values in a given instance, and the previous methods do not work in such a practical situation. In this paper, we first empirically and theoretically show the risk that missing value imputation methods affect the validity of an action, as well as the features that the action suggests changing. Then, we propose a new framework of CE, named Counterfactual Explanation by Pairs of Imputation and Action (CEPIA), that enables users to obtain valid actions even with missing values and clarifies how actions are affected by imputation of the missing values. Specifically, our CEPIA provides a representative set of pairs of an imputation ca
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#65292;&#24182;&#23558;&#20854;&#31561;&#21516;&#20110;&#22522;&#20110;&#20869;&#26680;&#23725;&#22238;&#24402;&#30340;&#21333;&#20010;&#27424;&#24179;&#28369;&#23725;&#22238;&#24402;&#65292;&#36827;&#19968;&#27493;&#23558;&#36825;&#31181;&#26041;&#27861;&#25512;&#24191;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;</title><link>http://arxiv.org/abs/2304.14545</link><description>&lt;p&gt;
&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#20316;&#20026;&#32447;&#24615;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Augmented balancing weights as linear regression. (arXiv:2304.14545v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#65292;&#24182;&#23558;&#20854;&#31561;&#21516;&#20110;&#22522;&#20110;&#20869;&#26680;&#23725;&#22238;&#24402;&#30340;&#21333;&#20010;&#27424;&#24179;&#28369;&#23725;&#22238;&#24402;&#65292;&#36827;&#19968;&#27493;&#23558;&#36825;&#31181;&#26041;&#27861;&#25512;&#24191;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20110;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;(AutoDML)&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#12290;&#36825;&#20123;&#20272;&#31639;&#22120;&#23558;&#32467;&#26524;&#24314;&#27169;&#19982;&#37325;&#37197;&#30456;&#32467;&#21512;&#65292;&#30452;&#25509;&#20272;&#35745;&#21453;&#21521;&#20542;&#21521;&#31215;&#20998;&#26435;&#37325;&#12290;&#24403;&#32467;&#26524;&#19982;&#26435;&#37325;&#27169;&#22411;&#37117;&#26159;&#26576;&#20123;&#65288;&#21487;&#33021;&#26159;&#26080;&#38480;&#30340;&#65289;&#22522;&#30784;&#20013;&#30340;&#32447;&#24615;&#26102;&#65292;&#25105;&#20204;&#34920;&#26126;&#22686;&#24378;&#30340;&#20272;&#31639;&#22120;&#31561;&#21516;&#20110;&#20855;&#26377;&#23558;&#21407;&#22987;&#32467;&#26524;&#27169;&#22411;&#31995;&#25968;&#21644;OLS&#30456;&#32467;&#21512;&#30340;&#31995;&#25968;&#30340;&#21333;&#20010;&#32447;&#24615;&#27169;&#22411;&#65307;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#65292;&#22686;&#24378;&#20272;&#31639;&#22120;&#21512;&#24182;&#20026;&#20165;&#20351;&#29992;OLS. &#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#25193;&#23637;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;&#25105;&#20204;&#39318;&#20808;&#34920;&#26126;&#65292;&#20351;&#29992;(&#20869;&#26680;)&#23725;&#22238;&#24402;&#20316;&#20026;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#30340;&#32852;&#21512;&#20272;&#31639;&#22120;&#31561;&#21516;&#20110;&#21333;&#20010;&#12289;&#27424;&#24179;&#28369;(&#20869;&#26680;)&#23725;&#22238;&#24402;&#65307;&#24403;&#32771;&#34385;&#21040;&#28176;&#36817;&#36895;&#29575;&#26102;&#65292;&#36825;&#19968;&#32467;&#26524;&#20063;&#25104;&#31435;&#12290;&#24403;&#20195;&#26367;&#26435;&#37325;&#27169;&#22411;&#20026;&#22871;&#32034;&#22238;&#24402;&#26102;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#29305;&#27530;&#24773;&#20917;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#24182;&#19988;&#28436;&#31034;&#20102;&#8230;
&lt;/p&gt;
&lt;p&gt;
We provide a novel characterization of augmented balancing weights, also known as Automatic Debiased Machine Learning (AutoDML). These estimators combine outcome modeling with balancing weights, which estimate inverse propensity score weights directly. When the outcome and weighting models are both linear in some (possibly infinite) basis, we show that the augmented estimator is equivalent to a single linear model with coefficients that combine the original outcome model coefficients and OLS; in many settings, the augmented estimator collapses to OLS alone. We then extend these results to specific choices of outcome and weighting models. We first show that the combined estimator that uses (kernel) ridge regression for both outcome and weighting models is equivalent to a single, undersmoothed (kernel) ridge regression; this also holds when considering asymptotic rates. When the weighting model is instead lasso regression, we give closed-form expressions for special cases and demonstrate
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24471;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#20271;&#21162;&#21033;&#36807;&#31243;&#26399;&#26395;&#26368;&#22823;&#20540;&#30340;&#19978;&#38480;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#30001;&#25351;&#25968;&#38598;&#22312;&#22343;&#21248;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#31867;&#19979;&#30340;&#23646;&#24615;&#21644;&#20989;&#25968;&#31867;&#24471;&#20986;&#12290;</title><link>http://arxiv.org/abs/2304.14474</link><description>&lt;p&gt;
&#19968;&#39033;&#38024;&#23545;&#20271;&#21162;&#21033;&#36807;&#31243;&#26399;&#26395;&#26368;&#22823;&#20540;&#30340;&#38142;&#24335;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Chain Rule for the Expected Suprema of Bernoulli Processes. (arXiv:2304.14474v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14474
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24471;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#20271;&#21162;&#21033;&#36807;&#31243;&#26399;&#26395;&#26368;&#22823;&#20540;&#30340;&#19978;&#38480;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#30001;&#25351;&#25968;&#38598;&#22312;&#22343;&#21248;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#31867;&#19979;&#30340;&#23646;&#24615;&#21644;&#20989;&#25968;&#31867;&#24471;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#20271;&#21162;&#21033;&#36807;&#31243;&#26399;&#26395;&#26368;&#22823;&#20540;&#30340;&#19978;&#38480;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#30001;&#25351;&#25968;&#38598;&#22312;&#22343;&#21248;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#31867;&#19979;&#30340;&#23646;&#24615;&#21644;&#20989;&#25968;&#31867;&#24471;&#20986;&#65292;&#25299;&#23637;&#20102;Maurer&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#30340;&#26089;&#26399;&#32467;&#26524;&#12290;&#35777;&#26126;&#24517;&#39035;&#22522;&#20110;Bednorz&#21644;Latala&#38024;&#23545;&#20271;&#21162;&#21033;&#36807;&#31243;&#26377;&#30028;&#24615;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We obtain an upper bound on the expected supremum of a Bernoulli process indexed by the image of an index set under a uniformly Lipschitz function class in terms of properties of the index set and the function class, extending an earlier result of Maurer for Gaussian processes. The proof makes essential use of recent results of Bednorz and Latala on the boundedness of Bernoulli processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#27493;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#65288;OS-DistrRL&#65289;&#26694;&#26550;&#65292;&#20165;&#28085;&#30422;&#29615;&#22659;&#19968;&#27493;&#21160;&#24577;&#24341;&#20837;&#30340;&#38543;&#26426;&#24615;&#65292;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#29702;&#35770;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.14421</link><description>&lt;p&gt;
&#19968;&#27493;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
One-Step Distributional Reinforcement Learning. (arXiv:2304.14421v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#27493;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#65288;OS-DistrRL&#65289;&#26694;&#26550;&#65292;&#20165;&#28085;&#30422;&#29615;&#22659;&#19968;&#27493;&#21160;&#24577;&#24341;&#20837;&#30340;&#38543;&#26426;&#24615;&#65292;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#29702;&#35770;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;Reinforcement Learning&#65292;RL&#65289;&#20801;&#35768;&#19968;&#20010;&#33021;&#20195;&#29702;&#19982;&#29615;&#22659;&#36827;&#34892;&#36830;&#32493;&#20132;&#20114;&#30340;&#31995;&#32479;&#26368;&#22823;&#21270;&#39044;&#26399;&#25910;&#30410;&#12290;&#22312;&#20998;&#24067;&#24335;RL&#65288;DistrRL&#65289;&#33539;&#24335;&#19979;&#65292;&#20195;&#29702;&#19981;&#20165;&#23616;&#38480;&#20110;&#26399;&#26395;&#20540;&#65292;&#32780;&#26159;&#25429;&#25417;&#36328;&#36234;&#25152;&#26377;&#26102;&#38388;&#27493;&#39588;&#30340;&#22238;&#25253;&#27010;&#29575;&#20998;&#24067;&#12290;DistrRL&#31639;&#27861;&#30340;&#38598;&#21512;&#25552;&#39640;&#20102;&#32463;&#39564;&#24615;&#33021;&#65292;&#20294;DistrRL&#30340;&#29702;&#35770;&#20173;&#26410;&#23436;&#20840;&#29702;&#35299;&#65292;&#23588;&#20854;&#22312;&#25511;&#21046;&#26696;&#20363;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#31616;&#21333;&#30340;&#19968;&#27493;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#65288;OS-DistrRL&#65289;&#26694;&#26550;&#65292;&#20165;&#28085;&#30422;&#29615;&#22659;&#19968;&#27493;&#21160;&#24577;&#24341;&#20837;&#30340;&#38543;&#26426;&#24615;&#12290;&#19982;DistrRL&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#38024;&#23545;&#31574;&#30053;&#35780;&#20272;&#21644;&#25511;&#21046;&#37117;&#20855;&#26377;&#32479;&#19968;&#30340;&#29702;&#35770;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;OS-DistrRL&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#20046;&#30830;&#23450;&#30340;&#25910;&#25947;&#20998;&#26512;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22810;&#31181;&#29615;&#22659;&#20013;&#27604;&#20998;&#31867;DistrRL&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) allows an agent interacting sequentially with an environment to maximize its long-term expected return. In the distributional RL (DistrRL) paradigm, the agent goes beyond the limit of the expected value, to capture the underlying probability distribution of the return across all time steps. The set of DistrRL algorithms has led to improved empirical performance. Nevertheless, the theory of DistrRL is still not fully understood, especially in the control case. In this paper, we present the simpler one-step distributional reinforcement learning (OS-DistrRL) framework encompassing only the randomness induced by the one-step dynamics of the environment. Contrary to DistrRL, we show that our approach comes with a unified theory for both policy evaluation and control. Indeed, we propose two OS-DistrRL algorithms for which we provide an almost sure convergence analysis. The proposed approach compares favorably with categorical DistrRL on various environments.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#32422;&#26463;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#20197;&#20462;&#25913;&#36755;&#30005;&#32447;&#36335;&#20445;&#25252;&#35774;&#32622;&#20026;&#25932;&#23545;&#25915;&#20987;&#30340;&#20505;&#36873;&#26041;&#26696;&#65292;&#25506;&#35752;&#20102;&#26368;&#22823;&#21270;&#32423;&#32852;&#32593;&#32476;&#36864;&#21270;&#30340;&#20445;&#25252;&#35774;&#32622;&#35268;&#24459;&#65292;&#21457;&#29616;&#23558;&#25152;&#26377;&#30005;&#32593;&#32447;&#36335;&#30340;&#20445;&#25252;&#35774;&#32622;&#26368;&#22823;&#22833;&#37197;&#24182;&#19981;&#20250;&#23548;&#33268;&#26368;&#22810;&#30340;&#32423;&#32852;&#12290;</title><link>http://arxiv.org/abs/2304.14420</link><description>&lt;p&gt;
&#20351;&#29992;&#32422;&#26463;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32593;&#32476;&#32423;&#32852;&#28431;&#27934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Network Cascade Vulnerability using Constrained Bayesian Optimization. (arXiv:2304.14420v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#32422;&#26463;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#20197;&#20462;&#25913;&#36755;&#30005;&#32447;&#36335;&#20445;&#25252;&#35774;&#32622;&#20026;&#25932;&#23545;&#25915;&#20987;&#30340;&#20505;&#36873;&#26041;&#26696;&#65292;&#25506;&#35752;&#20102;&#26368;&#22823;&#21270;&#32423;&#32852;&#32593;&#32476;&#36864;&#21270;&#30340;&#20445;&#25252;&#35774;&#32622;&#35268;&#24459;&#65292;&#21457;&#29616;&#23558;&#25152;&#26377;&#30005;&#32593;&#32447;&#36335;&#30340;&#20445;&#25252;&#35774;&#32622;&#26368;&#22823;&#22833;&#37197;&#24182;&#19981;&#20250;&#23548;&#33268;&#26368;&#22810;&#30340;&#32423;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#30005;&#32593;&#30340;&#33030;&#24369;&#24615;&#24120;&#24120;&#26159;&#36890;&#36807;&#25932;&#25163;&#33021;&#22815;&#23545;&#32593;&#32476;&#36896;&#25104;&#30340;&#25439;&#23475;&#37327;&#26469;&#34913;&#37327;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#25915;&#20987;&#30340;&#32423;&#32852;&#24433;&#21709;&#36890;&#24120;&#34987;&#24573;&#35270;&#65292;&#23613;&#31649;&#32423;&#32852;&#26159;&#22823;&#35268;&#27169;&#20572;&#30005;&#30340;&#20027;&#35201;&#21407;&#22240;&#20043;&#19968;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#36755;&#30005;&#32447;&#36335;&#20445;&#25252;&#35774;&#32622;&#20462;&#25913;&#20026;&#25932;&#23545;&#25915;&#20987;&#30340;&#20505;&#36873;&#26041;&#26696;&#65292;&#21482;&#35201;&#32593;&#32476;&#24179;&#34913;&#29366;&#24577;&#19981;&#25913;&#21464;&#65292;&#25915;&#20987;&#23601;&#21487;&#20197;&#20445;&#25345;&#19981;&#34987;&#26816;&#27979;&#21040;&#12290;&#36825;&#26500;&#25104;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#40657;&#30418;&#23376;&#20989;&#25968;&#22522;&#30784;&#65292;&#20854;&#30446;&#26631;&#26159;&#25214;&#21040;&#26368;&#22823;&#21270;&#32423;&#32852;&#32593;&#32476;&#36864;&#21270;&#30340;&#20445;&#25252;&#35774;&#32622;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#24120;&#35782;&#30456;&#21453;&#65292;&#23558;&#25152;&#26377;&#32593;&#32476;&#32447;&#36335;&#30340;&#20445;&#25252;&#35774;&#32622;&#26368;&#22823;&#22833;&#37197;&#24182;&#19981;&#20250;&#23548;&#33268;&#26368;&#22810;&#30340;&#32423;&#32852;&#12290;&#26356;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#21487;&#20197;&#25214;&#21040;&#33021;&#22815;&#20135;&#29983;&#19982;&#23454;&#20363;&#30456;&#24403;&#20005;&#37325;&#30340;&#32423;&#32852;&#30340;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measures of power grid vulnerability are often assessed by the amount of damage an adversary can exact on the network. However, the cascading impact of such attacks is often overlooked, even though cascades are one of the primary causes of large-scale blackouts. This paper explores modifications of transmission line protection settings as candidates for adversarial attacks, which can remain undetectable as long as the network equilibrium state remains unaltered. This forms the basis of a black-box function in a Bayesian optimization procedure, where the objective is to find protection settings that maximize network degradation due to cascading. Extensive experiments reveal that, against conventional wisdom, maximally misconfiguring the protection settings of all network lines does not cause the most cascading. More surprisingly, even when the degree of misconfiguration is resource constrained, it is still possible to find settings that produce cascades comparable in severity to instanc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#35782;&#21035;&#21160;&#21147;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#19981;&#23545;&#25968;&#25454;&#36827;&#34892;&#20462;&#25913;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#25968;&#20540;&#31215;&#20998;&#21644;&#37096;&#20998;&#24050;&#30693;&#29289;&#29702;&#23398;&#65292;&#33021;&#22815;&#20174;&#20219;&#24847;&#26102;&#38388;&#28857;&#30340;&#37319;&#26679;&#25968;&#25454;&#20013;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2304.14214</link><description>&lt;p&gt;
&#35770;&#25991;&#26631;&#39064;&#65306;&#26576;&#20123;&#21464;&#37327;&#65292;&#26576;&#20123;&#21442;&#25968;&#65292;&#26576;&#20123;&#26102;&#38388;&#65292;&#26576;&#20123;&#24050;&#30693;&#29289;&#29702;&#23398;&#65306;&#24102;&#26377;&#37096;&#20998;&#20449;&#24687;&#30340;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Some of the variables, some of the parameters, some of the times, with some physics known: Identification with partial information. (arXiv:2304.14214v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#35782;&#21035;&#21160;&#21147;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#19981;&#23545;&#25968;&#25454;&#36827;&#34892;&#20462;&#25913;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#25968;&#20540;&#31215;&#20998;&#21644;&#37096;&#20998;&#24050;&#30693;&#29289;&#29702;&#23398;&#65292;&#33021;&#22815;&#20174;&#20219;&#24847;&#26102;&#38388;&#28857;&#30340;&#37319;&#26679;&#25968;&#25454;&#20013;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#39564;&#25968;&#25454;&#36890;&#24120;&#30001;&#29420;&#31435;&#27979;&#37327;&#30340;&#21464;&#37327;&#32452;&#25104;&#65292;&#22312;&#19981;&#21516;&#30340;&#37319;&#26679;&#29575;(&#36830;&#32493;&#27979;&#37327;&#20043;&#38388;&#30340;&#38750;&#22343;&#21248;${\Delta}$t)&#19979;&#65292;&#20165;&#22312;&#29305;&#23450;&#26102;&#38388;&#28857;&#25165;&#23545;&#25152;&#26377;&#21464;&#37327;&#30340;&#23376;&#38598;&#36827;&#34892;&#37319;&#26679;&#12290;&#20174;&#36825;&#26679;&#30340;&#25968;&#25454;&#20013;&#35782;&#21035;&#21160;&#21147;&#31995;&#32479;&#30340;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#25554;&#20540;&#12289;&#25554;&#20540;&#25110;&#23376;&#37319;&#26679;&#26469;&#37325;&#26032;&#32452;&#32455;&#25110;&#20462;&#25913;&#35757;&#32451;&#25968;&#25454;$ \textit {prior}$ &#23398;&#20064;&#12290;&#37096;&#20998;&#29289;&#29702;&#30693;&#35782;&#20063;&#21487;&#33021;&#22312;$\textit {a priori}$&#65288;&#31934;&#30830;&#25110;&#36817;&#20284;&#65289;&#20013;&#21487;&#29992;&#65292;&#24182;&#19988;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#21487;&#20197;&#34917;&#20805;&#27492;&#30693;&#35782;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#21033;&#29992;&#22522;&#20110;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;&#21644;$\textit {a priori}$&#29289;&#29702;&#30693;&#35782;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#35782;&#21035;&#22522;&#26412;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#30340;&#21491;&#25163;&#36793;&#12290;&#36825;&#31181;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#36845;&#20195;&#20801;&#35768;&#20174;&#22312;&#20219;&#24847;&#26102;&#38388;&#28857;&#37319;&#26679;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;$\textit {without}$&#25968;&#25454;&#20462;&#25913;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#23558;&#32593;&#32476;&#19982;&#21487;&#29992;&#30340;&#37096;&#20998;&#29289;&#29702;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Experimental data is often comprised of variables measured independently, at different sampling rates (non-uniform ${\Delta}$t between successive measurements); and at a specific time point only a subset of all variables may be sampled. Approaches to identifying dynamical systems from such data typically use interpolation, imputation or subsampling to reorganize or modify the training data $\textit{prior}$ to learning. Partial physical knowledge may also be available $\textit{a priori}$ (accurately or approximately), and data-driven techniques can complement this knowledge. Here we exploit neural network architectures based on numerical integration methods and $\textit{a priori}$ physical knowledge to identify the right-hand side of the underlying governing differential equations. Iterates of such neural-network models allow for learning from data sampled at arbitrary time points $\textit{without}$ data modification. Importantly, we integrate the network with available partial physical
&lt;/p&gt;</description></item><item><title>TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;</title><link>http://arxiv.org/abs/2304.08424</link><description>&lt;p&gt;
&#29992;TiDE&#36827;&#34892;&#38271;&#26399;&#39044;&#27979;&#65306;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Long-term Forecasting with TiDE: Time-series Dense Encoder. (arXiv:2304.08424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08424
&lt;/p&gt;
&lt;p&gt;
TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#65292;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#22312;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#23618;&#24863;&#30693;&#26426;(MLP)&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#21363;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;(TiDE)&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20139;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#26368;&#31616;&#32447;&#24615;&#31867;&#27604;&#22312;&#19968;&#20123;&#20551;&#35774;&#19979;&#21487;&#20197;&#36798;&#21040;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;(LDS)&#30340;&#36817;&#20046;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22522;&#20934;&#27979;&#35797;&#20013;&#21305;&#37197;&#25110;&#32988;&#36807;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#27604;&#26368;&#20339;&#30340;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, Time-series Dense Encoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.
&lt;/p&gt;</description></item><item><title>Data-OOB&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;out-of-bag&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.07718</link><description>&lt;p&gt;
Data-OOB:&#20197;&#26080;&#38656;&#39069;&#22806;&#35745;&#31639;&#30340;Out-of-bag&#20272;&#35745;&#20026;&#20934;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value. (arXiv:2304.07718v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07718
&lt;/p&gt;
&lt;p&gt;
Data-OOB&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;out-of-bag&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#35780;&#20272;&#26159;&#19968;&#20010;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20026;&#27169;&#22411;&#35757;&#32451;&#25552;&#20379;&#32479;&#35745;&#27934;&#23519;&#21147;&#65292;&#20197;&#21306;&#20998;&#21738;&#20123;&#25968;&#25454;&#23545;&#20110;&#27169;&#22411;&#35757;&#32451;&#26159;&#26377;&#30410;&#30340;&#65292;&#21738;&#20123;&#26159;&#26377;&#23475;&#30340;&#12290;&#32437;&#35266;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#35768;&#22810;&#20197;Shapley&#20026;&#22522;&#30784;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#22343;&#26174;&#31034;&#20986;&#20102;&#24456;&#26377;&#21069;&#36884;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#38656;&#35201;&#35757;&#32451;&#22823;&#37327;&#30340;&#27169;&#22411;&#65292;&#22240;&#27492;&#20247;&#25152;&#21608;&#30693;&#65292;&#36825;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22240;&#27492;&#65292;&#23558;&#27492;&#24212;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Data-OOB&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#38024;&#23545;bagging&#27169;&#22411;&#65292;&#23427;&#21033;&#29992;&#20102;out-of-bag&#20272;&#35745;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#26159;&#39640;&#25928;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#24369;&#23398;&#20064;&#22120;&#26469;&#25193;&#23637;&#21040;&#25968;&#30334;&#19975;&#20010;&#25968;&#25454;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#24403;&#35780;&#20272;100&#20010;&#36755;&#20837;&#32500;&#24230;&#19988;&#23384;&#22312;$10^6$&#20010;&#26679;&#26412;&#26102;&#65292;Data-OOB&#20165;&#38656;&#35201;&#22312;&#21333;&#20010;CPU&#22788;&#29702;&#22120;&#19978;&#25191;&#34892;&#19981;&#21040;2.25&#20010;&#23567;&#26102;&#12290;&#27492;&#22806;&#65292;Data-OOB&#22312;&#29702;&#35770;&#19978;&#26377;&#22362;&#23454;&#30340;&#35299;&#37322;&#65292;&#24403;&#20004;&#20010;&#31163;&#24046;&#20540;&#20989;&#25968;&#30456;&#21516;&#26102;&#65292;&#20854;&#35782;&#21035;&#20855;&#26377;&#30456;&#21516;&#37325;&#35201;&#24615;&#30340;&#25968;&#25454;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data valuation is a powerful framework for providing statistical insights into which data are beneficial or detrimental to model training. Many Shapley-based data valuation methods have shown promising results in various downstream tasks, however, they are well known to be computationally challenging as it requires training a large number of models. As a result, it has been recognized as infeasible to apply to large datasets. To address this issue, we propose Data-OOB, a new data valuation method for a bagging model that utilizes the out-of-bag estimate. The proposed method is computationally efficient and can scale to millions of data by reusing trained weak learners. Specifically, Data-OOB takes less than 2.25 hours on a single CPU processor when there are $10^6$ samples to evaluate and the input dimension is 100. Furthermore, Data-OOB has solid theoretical interpretations in that it identifies the same important data point as the infinitesimal jackknife influence function when two d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22635;&#34917;&#20102;&#27969;&#34892;&#30340;SPCA&#31639;&#27861;&#30340;&#29702;&#35770;&#20445;&#35777;&#30340;&#31354;&#30333;&#65292;&#35777;&#26126;&#20102;&#22312;&#31232;&#30095;&#23792;&#20540;&#21327;&#26041;&#24046;&#27169;&#22411;&#19979;&#65292;&#35813;&#31639;&#27861;&#19968;&#33268;&#22320;&#24674;&#22797;&#20102;&#20027;&#23376;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2212.14194</link><description>&lt;p&gt;
&#22522;&#20110;&#24377;&#24615;&#32593;&#30340;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees for Sparse Principal Component Analysis based on the Elastic Net. (arXiv:2212.14194v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14194
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22635;&#34917;&#20102;&#27969;&#34892;&#30340;SPCA&#31639;&#27861;&#30340;&#29702;&#35770;&#20445;&#35777;&#30340;&#31354;&#30333;&#65292;&#35777;&#26126;&#20102;&#22312;&#31232;&#30095;&#23792;&#20540;&#21327;&#26041;&#24046;&#27169;&#22411;&#19979;&#65292;&#35813;&#31639;&#27861;&#19968;&#33268;&#22320;&#24674;&#22797;&#20102;&#20027;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;SPCA&#65289;&#22312;&#39640;&#32500;&#25968;&#25454;&#20998;&#26512;&#20013;&#24191;&#27867;&#29992;&#20110;&#38477;&#32500;&#21644;&#29305;&#24449;&#25552;&#21462;&#12290;&#23613;&#31649;&#22312;&#36807;&#21435;&#30340;&#20108;&#21313;&#24180;&#20013;&#20986;&#29616;&#20102;&#35768;&#22810;&#26041;&#27861;&#35770;&#21644;&#29702;&#35770;&#21457;&#23637;&#65292;&#20294;&#27969;&#34892;&#30340;SPCA&#31639;&#27861;&#65288;&#30001;Zou&#12289;Hastie&#21644;Tibshirani&#20110;2006&#24180;&#25552;&#20986;&#65289;&#30340;&#29702;&#35770;&#20445;&#35777;&#20173;&#28982;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#20851;&#38190;&#24046;&#36317;&#12290;&#25105;&#20204;&#39318;&#20808;&#37325;&#26032;&#23457;&#35270;&#20102;Zou&#31561;&#20154;&#65288;2006&#24180;&#65289;&#30340;SPCA&#31639;&#27861;&#24182;&#21576;&#29616;&#20102;&#25105;&#20204;&#30340;&#23454;&#29616;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;Zou&#31561;&#20154;&#65288;2006&#24180;&#65289;&#20013;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;SPCA&#30340;&#26497;&#38480;&#24773;&#20917;&#30340;&#35745;&#31639;&#26356;&#26377;&#25928;&#30340;&#21464;&#20307;&#12290;&#25105;&#20204;&#20026;&#20004;&#31181;&#31639;&#27861;&#25552;&#20379;&#20102;&#21040;&#36798;&#31283;&#23450;&#28857;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#20102;&#65292;&#22312;&#31232;&#30095;&#23792;&#20540;&#21327;&#26041;&#24046;&#27169;&#22411;&#19979;&#65292;&#22312;&#28201;&#21644;&#30340;&#27491;&#21017;&#26465;&#20214;&#19979;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#37117;&#21487;&#20197;&#19968;&#33268;&#22320;&#24674;&#22797;&#20027;&#23376;&#31354;&#38388;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#23427;&#20204;&#30340;&#20272;&#35745;&#35823;&#24046;&#36793;&#30028;&#19982;&#29616;&#26377;&#24037;&#20316;&#30340;&#26368;&#20339;&#36793;&#30028;&#25110;&#26368;&#23567;&#26497;&#38480;&#36895;&#29575;&#21305;&#37197;&#65292;&#30452;&#21040;&#26576;&#20123;&#23545;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse principal component analysis (SPCA) is widely used for dimensionality reduction and feature extraction in high-dimensional data analysis. Despite many methodological and theoretical developments in the past two decades, the theoretical guarantees of the popular SPCA algorithm proposed by Zou, Hastie &amp; Tibshirani (2006) are still unknown. This paper aims to address this critical gap. We first revisit the SPCA algorithm of Zou et al. (2006) and present our implementation. We also study a computationally more efficient variant of the SPCA algorithm in Zou et al. (2006) that can be considered as the limiting case of SPCA. We provide the guarantees of convergence to a stationary point for both algorithms and prove that, under a sparse spiked covariance model, both algorithms can recover the principal subspace consistently under mild regularity conditions. We show that their estimation error bounds match the best available bounds of existing works or the minimax rates up to some logar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#20026;&#22522;&#30784;&#30340;&#36890;&#29992;&#31283;&#23450;&#27169;&#22411;&#33976;&#39311;&#26041;&#27861;&#65292;&#33021;&#22815;&#20174;&#20505;&#36873;&#23398;&#29983;&#27169;&#22411;&#20013;&#25628;&#32034;&#19982;&#32769;&#24072;&#27169;&#22411;&#30456;&#19968;&#33268;&#30340;&#21512;&#29702;&#27169;&#22411;&#65292;&#20351;&#29992;&#19968;&#20010;&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#26469;&#36873;&#25321;&#19968;&#32452;&#36275;&#22815;&#22823;&#30340;&#20266;&#25968;&#25454;&#38598;&#65292;&#20197;&#36873;&#20986;&#19968;&#33268;&#30340;&#23398;&#29983;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.12631</link><description>&lt;p&gt;
&#21487;&#22797;&#29616;&#27169;&#22411;&#33976;&#39311;&#30340;&#36890;&#29992;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Generic Approach for Reproducible Model Distillation. (arXiv:2211.12631v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.12631
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#20026;&#22522;&#30784;&#30340;&#36890;&#29992;&#31283;&#23450;&#27169;&#22411;&#33976;&#39311;&#26041;&#27861;&#65292;&#33021;&#22815;&#20174;&#20505;&#36873;&#23398;&#29983;&#27169;&#22411;&#20013;&#25628;&#32034;&#19982;&#32769;&#24072;&#27169;&#22411;&#30456;&#19968;&#33268;&#30340;&#21512;&#29702;&#27169;&#22411;&#65292;&#20351;&#29992;&#19968;&#20010;&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#26469;&#36873;&#25321;&#19968;&#32452;&#36275;&#22815;&#22823;&#30340;&#20266;&#25968;&#25454;&#38598;&#65292;&#20197;&#36873;&#20986;&#19968;&#33268;&#30340;&#23398;&#29983;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#33976;&#39311;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#29983;&#25104;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#23427;&#20351;&#29992;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#8220;&#23398;&#29983;&#8221;&#27169;&#22411;&#21435;&#27169;&#20223;&#40657;&#30418;&#8220;&#32769;&#24072;&#8221;&#27169;&#22411;&#20135;&#29983;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#24403;&#23398;&#29983;&#27169;&#22411;&#23545;&#20110;&#29992;&#20110;&#35757;&#32451;&#30340;&#25968;&#25454;&#38598;&#30340;&#21464;&#24322;&#24615;&#25935;&#24863;&#26102;&#65292;&#20851;&#20110;&#23398;&#29983;&#27169;&#22411;&#30340;&#35299;&#37322;&#23601;&#19981;&#21487;&#38752;&#20102;&#12290;&#29616;&#26377;&#30340;&#31283;&#23450;&#27169;&#22411;&#33976;&#39311;&#31574;&#30053;&#36890;&#36807;&#26816;&#26597;&#26159;&#21542;&#29983;&#25104;&#20102;&#36275;&#22815;&#22823;&#30340;&#20266;&#25968;&#25454;&#26469;&#31283;&#23450;&#27169;&#22411;&#33976;&#39311;&#65292;&#20294;&#30446;&#21069;&#20026;&#27490;&#65292;&#36825;&#20123;&#26041;&#27861;&#21482;&#36866;&#29992;&#20110;&#29305;&#23450;&#30340;&#23398;&#29983;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#30340;&#36890;&#29992;&#31283;&#23450;&#27169;&#22411;&#33976;&#39311;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#20505;&#36873;&#30340;&#23398;&#29983;&#27169;&#22411;&#38598;&#21512;&#24320;&#22987;&#65292;&#25628;&#32034;&#19982;&#32769;&#24072;&#27169;&#22411;&#30456;&#19968;&#33268;&#30340;&#21512;&#29702;&#20505;&#36873;&#27169;&#22411;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26500;&#24314;&#19968;&#20010;&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#65292;&#36873;&#25321;&#19968;&#32452;&#21487;&#20197;&#20351;&#24471;&#19968;&#33268;&#30340;&#23398;&#29983;&#27169;&#22411;&#34987;&#36873;&#20013;&#30340;&#20266;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model distillation has been a popular method for producing interpretable machine learning. It uses an interpretable "student" model to mimic the predictions made by the black box "teacher" model. However, when the student model is sensitive to the variability of the data sets used for training even when keeping the teacher fixed, the corresponded interpretation is not reliable. Existing strategies stabilize model distillation by checking whether a large enough corpus of pseudo-data is generated to reliably reproduce student models, but methods to do so have so far been developed for a specific student model. In this paper, we develop a generic approach for stable model distillation based on central limit theorem for the average loss. We start with a collection of candidate student models and search for candidates that reasonably agree with the teacher. Then we construct a multiple testing framework to select a corpus size such that the consistent student model would be selected under d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#26469;&#26816;&#27979;&#21464;&#28857;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2210.17312</link><description>&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#26102;&#24207;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Training Neural Networks for Sequential Change-point Detection. (arXiv:2210.17312v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#26469;&#26816;&#27979;&#21464;&#28857;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#31361;&#21464;&#20998;&#24067;&#36716;&#25442;&#65292;&#21363;&#25152;&#35859;&#30340;&#21464;&#28857;&#26816;&#27979;&#65292;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#65292;&#24403;&#21457;&#29983;&#21464;&#28857;&#26102;&#65292;&#35813;&#37327;&#20250;&#26174;&#33879;&#21464;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26816;&#27979;&#21464;&#28857;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting an abrupt distributional shift of a data stream, known as change-point detection, is a fundamental problem in statistics and machine learning. We introduce a novel approach for online change-point detection using neural networks. To be specific, our approach is training neural networks to compute the cumulative sum of a detection statistic sequentially, which exhibits a significant change when a change-point occurs. We demonstrated the superiority and potential of the proposed method in detecting change-point using both synthetic and real-world data.
&lt;/p&gt;</description></item><item><title>LogGENE&#37319;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26694;&#26550;&#39044;&#27979;&#22522;&#22240;&#34920;&#36798;&#27700;&#24179;&#30340;&#23436;&#25972;&#26465;&#20214;&#20998;&#20301;&#25968;&#65292;&#20174;&#32780;&#20026;&#39640;&#36890;&#37327;&#22522;&#22240;&#32452;&#23398;&#25552;&#20379;&#20102;&#19968;&#31181;&#33021;&#25552;&#20379;&#35299;&#37322;&#21644;&#25253;&#21578;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12289;&#40065;&#26834;&#24615;&#24378;&#30340;&#25512;&#26029;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2206.09333</link><description>&lt;p&gt;
LogGENE: &#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#21307;&#30103;&#25512;&#29702;&#20219;&#21153;&#30340;&#24179;&#28369;&#26816;&#26597;&#25439;&#22833;&#26367;&#20195;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
LogGENE: A smooth alternative to check loss for Deep Healthcare Inference Tasks. (arXiv:2206.09333v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.09333
&lt;/p&gt;
&lt;p&gt;
LogGENE&#37319;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26694;&#26550;&#39044;&#27979;&#22522;&#22240;&#34920;&#36798;&#27700;&#24179;&#30340;&#23436;&#25972;&#26465;&#20214;&#20998;&#20301;&#25968;&#65292;&#20174;&#32780;&#20026;&#39640;&#36890;&#37327;&#22522;&#22240;&#32452;&#23398;&#25552;&#20379;&#20102;&#19968;&#31181;&#33021;&#25552;&#20379;&#35299;&#37322;&#21644;&#25253;&#21578;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12289;&#40065;&#26834;&#24615;&#24378;&#30340;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21487;&#38752;&#30340;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#25366;&#25496;&#22823;&#22411;&#25968;&#25454;&#38598;&#24182;&#20174;&#20013;&#33719;&#24471;&#26657;&#20934;&#30340;&#39044;&#27979;&#20855;&#26377;&#21363;&#26102;&#30456;&#20851;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22522;&#22240;&#34920;&#36798;&#31561;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#19982;&#20856;&#22411;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#25512;&#26029;&#25216;&#26415;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#36824;&#33021;&#25552;&#20379;&#35299;&#37322;&#21644;&#25253;&#21578;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#37319;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26694;&#26550;&#26469;&#39044;&#27979;&#32473;&#23450;&#19968;&#32452;&#22522;&#22240;&#34920;&#36798;&#30340;&#23436;&#25972;&#26465;&#20214;&#20998;&#20301;&#25968;&#12290;&#26465;&#20214;&#20998;&#20301;&#25968;&#38500;&#20102;&#26377;&#21161;&#20110;&#25552;&#20379;&#39044;&#27979;&#30340;&#20016;&#23500;&#35299;&#37322;&#22806;&#65292;&#36824;&#33021;&#22815;&#25269;&#25239;&#27979;&#37327;&#22122;&#22768;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;&#39640;&#36890;&#37327;&#22522;&#22240;&#32452;&#23398;&#20013;&#29305;&#21035;&#37325;&#35201;&#65292;&#36825;&#26159;&#19968;&#20010;&#27491;&#22312;&#24341;&#39046;&#20010;&#24615;&#21270;&#21307;&#30103;&#12289;&#38774;&#21521;&#33647;&#29289;&#35774;&#35745;&#21644;&#20256;&#36882;&#30340;&#26032;&#26102;&#20195;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#39537;&#21160;&#20272;&#35745;&#36807;&#31243;&#30340;&#26816;&#26597;&#25439;&#22833;&#65292;&#22312;&#20998;&#20301;&#25968;&#22238;&#24402;&#20013;&#24182;&#26080;&#19981;&#21516;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mining large datasets and obtaining calibrated predictions from tem is of immediate relevance and utility in reliable deep learning. In our work, we develop methods for Deep neural networks based inferences in such datasets like the Gene Expression. However, unlike typical Deep learning methods, our inferential technique, while achieving state-of-the-art performance in terms of accuracy, can also provide explanations, and report uncertainty estimates. We adopt the Quantile Regression framework to predict full conditional quantiles for a given set of housekeeping gene expressions. Conditional quantiles, in addition to being useful in providing rich interpretations of the predictions, are also robust to measurement noise. Our technique is particularly consequential in High-throughput Genomics, an area which is ushering a new era in personalized health care, and targeted drug design and delivery. However, check loss, used in quantile regression to drive the estimation process is not diffe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#22312;&#20449;&#21495;&#19982;&#32972;&#26223;&#39640;&#24230;&#37325;&#21472;&#30340;&#24773;&#20917;&#19979;&#22686;&#24378;LHC&#26032;&#29289;&#29702;&#25506;&#27979;&#30340;&#28789;&#25935;&#24230;&#12290;&#20351;&#29992;XGBoost&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26469;&#21033;&#29992;&#21487;&#35266;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#27604;&#20256;&#32479;&#30340;&#21066;&#20943;-&#35745;&#25968;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#24182;&#37319;&#29992;&#27169;&#26495;&#25311;&#21512;&#26041;&#27861;&#20998;&#26512;&#27169;&#22411;&#36755;&#20986;&#12290;</title><link>http://arxiv.org/abs/2108.03125</link><description>&lt;p&gt;
&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#25552;&#39640;Sneutrino&#25506;&#27979;&#25928;&#29575;&#8212;&#8212;&#22312;&#23567;&#20449;&#21495;&#22330;&#26223;&#20013;&#36229;&#36234;&#21066;&#20943;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Beyond Cuts in Small Signal Scenarios -- Enhanced Sneutrino Detectability Using Machine Learning. (arXiv:2108.03125v3 [hep-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.03125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#22312;&#20449;&#21495;&#19982;&#32972;&#26223;&#39640;&#24230;&#37325;&#21472;&#30340;&#24773;&#20917;&#19979;&#22686;&#24378;LHC&#26032;&#29289;&#29702;&#25506;&#27979;&#30340;&#28789;&#25935;&#24230;&#12290;&#20351;&#29992;XGBoost&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26469;&#21033;&#29992;&#21487;&#35266;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#27604;&#20256;&#32479;&#30340;&#21066;&#20943;-&#35745;&#25968;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#24182;&#37319;&#29992;&#27169;&#26495;&#25311;&#21512;&#26041;&#27861;&#20998;&#26512;&#27169;&#22411;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;LHC&#26032;&#29289;&#29702;&#25628;&#32034;&#28789;&#25935;&#24230;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#32972;&#26223;&#25903;&#37197;&#21644;&#20449;&#21495;&#19982;&#32972;&#26223;&#22312;&#21487;&#35266;&#27979;&#37327;&#19978;&#23384;&#22312;&#39640;&#24230;&#37325;&#21472;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#27169;&#22411;&#65292;XGBoost&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#21487;&#35266;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#23558;&#36825;&#31181;&#26041;&#27861;&#19982;&#20256;&#32479;&#30340;&#21066;&#20943;-&#35745;&#25968;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#24182;&#21457;&#29616;&#27169;&#26495;&#25311;&#21512;&#36890;&#24120;&#27604;&#31616;&#21333;&#30340;&#21066;&#20943;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#36890;&#36807;Shapley&#20998;&#35299;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#23545;&#20107;&#20214;&#36816;&#21160;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36755;&#20986;&#20043;&#38388;&#20851;&#31995;&#30340;&#39069;&#22806;&#27934;&#23519;&#12290;&#25105;&#20204;&#20197;&#20855;&#20307;&#30340;&#20122;&#31283;Sneutrino&#36229;&#23545;&#31216;&#24773;&#26223;&#20026;&#20363;&#65292;&#20294;&#35813;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#27169;&#22411;&#31867;&#21035;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate enhancing the sensitivity of new physics searches at the LHC by machine learning in the case of background dominance and a high degree of overlap between the observables for signal and background. We use two different models, XGBoost and a deep neural network, to exploit correlations between observables and compare this approach to the traditional cut-and-count method. We consider different methods to analyze the models' output, finding that a template fit generally performs better than a simple cut. By means of a Shapley decomposition, we gain additional insight into the relationship between event kinematics and the machine learning model output. We consider a supersymmetric scenario with a metastable sneutrino as a concrete example, but the methodology can be applied to a much wider class of models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#21033;&#29992;&#35268;&#33539;&#31354;&#38388;&#35777;&#26126;&#23398;&#20064;&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#30340;&#30446;&#26631;&#20989;&#25968;&#22312;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#26102;&#26159;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#20351;&#29992;&#28857;&#32447;&#24615;&#36716;&#25442;&#30340;&#26041;&#27861;&#24314;&#31435;&#21407;&#22987;NN&#27169;&#22411;&#31354;&#38388;&#21644;&#35268;&#33539;&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#35777;&#26126;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#21482;&#35201;&#24046;&#24322;&#30697;&#38453;&#20445;&#25345;&#23436;&#25972;&#31209;&#65292;&#23601;&#19968;&#23450;&#33021;&#25910;&#25947;&#21040;&#38646;&#25439;&#22833;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#22823;&#35268;&#27169;NN&#20855;&#26377;&#22855;&#24322;&#30340;&#24046;&#24322;&#30697;&#38453;&#30340;&#27010;&#29575;&#38750;&#24120;&#23567;&#12290;</title><link>http://arxiv.org/abs/1903.02140</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20026;&#20160;&#20040;&#34892;&#20026;&#31867;&#20284;&#20110;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Why Learning of Large-Scale Neural Networks Behaves Like Convex Optimization. (arXiv:1903.02140v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1903.02140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#21033;&#29992;&#35268;&#33539;&#31354;&#38388;&#35777;&#26126;&#23398;&#20064;&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#30340;&#30446;&#26631;&#20989;&#25968;&#22312;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#26102;&#26159;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#20351;&#29992;&#28857;&#32447;&#24615;&#36716;&#25442;&#30340;&#26041;&#27861;&#24314;&#31435;&#21407;&#22987;NN&#27169;&#22411;&#31354;&#38388;&#21644;&#35268;&#33539;&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#35777;&#26126;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#21482;&#35201;&#24046;&#24322;&#30697;&#38453;&#20445;&#25345;&#23436;&#25972;&#31209;&#65292;&#23601;&#19968;&#23450;&#33021;&#25910;&#25947;&#21040;&#38646;&#25439;&#22833;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#22823;&#35268;&#27169;NN&#20855;&#26377;&#22855;&#24322;&#30340;&#24046;&#24322;&#30697;&#38453;&#30340;&#27010;&#29575;&#38750;&#24120;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20123;&#29702;&#35770;&#24037;&#20316;&#65292;&#20197;&#35299;&#37322;&#20026;&#20160;&#20040;&#31616;&#21333;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#22312;&#35299;&#20915;&#23398;&#20064;&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#22914;&#27492;&#25104;&#21151;&#12290;&#22312;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#35268;&#33539;&#31354;&#38388;&#30340;&#25968;&#23398;&#24037;&#20855;&#20043;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35268;&#33539;&#27169;&#22411;&#31354;&#38388;&#20013;&#30340;&#23398;&#20064;NN&#30446;&#26631;&#20989;&#25968;&#26159;&#20984;&#30340;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#38416;&#26126;&#20102;&#21407;&#22987;NN&#27169;&#22411;&#31354;&#38388;&#21644;&#35268;&#33539;&#31354;&#38388;&#20043;&#38388;&#30340;&#26799;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#26159;&#36890;&#36807;&#25152;&#35859;&#30340;&#24046;&#24322;&#30697;&#38453;&#34920;&#31034;&#30340;&#36880;&#28857;&#32447;&#24615;&#21464;&#25442;&#30456;&#20851;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24050;&#32463;&#35777;&#26126;&#65292;&#22914;&#26524;&#24046;&#24322;&#30697;&#38453;&#20445;&#25345;&#23436;&#25972;&#31209;&#65292;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#19968;&#23450;&#20250;&#25910;&#25947;&#21040;&#38646;&#25439;&#22833;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#22914;&#26524;&#36825;&#20010;&#23436;&#25972;&#31209;&#26465;&#20214;&#25104;&#31435;&#65292;&#22312;NN&#30340;&#23398;&#20064;&#20013;&#30340;&#34892;&#20026;&#19982;&#27491;&#24120;&#30340;&#20984;&#20248;&#21270;&#30456;&#21516;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22823;&#35268;&#27169;NN&#20855;&#26377;&#22855;&#24322;&#30340;&#24046;&#24322;&#30697;&#38453;&#30340;&#27010;&#29575;&#38750;&#24120;&#23567;&#12290;&#29305;&#21035;&#26159;&#65292;&#24403;&#36229;&#21442;&#25968;&#21270;&#30340;NN&#26159;...
&lt;/p&gt;
&lt;p&gt;
In this paper, we present some theoretical work to explain why simple gradient descent methods are so successful in solving non-convex optimization problems in learning large-scale neural networks (NN). After introducing a mathematical tool called canonical space, we have proved that the objective functions in learning NNs are convex in the canonical model space. We further elucidate that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so-called disparity matrix. Furthermore, we have proved that gradient descent methods surely converge to a global minimum of zero loss provided that the disparity matrices maintain full rank. If this full-rank condition holds, the learning of NNs behaves in the same way as normal convex optimization. At last, we have shown that the chance to have singular disparity matrices is extremely slim in large NNs. In particular, when over-parameterized NNs are 
&lt;/p&gt;</description></item></channel></rss>