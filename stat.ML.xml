<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#29109;&#36825;&#19968;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24357;&#34917;&#20102;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#25552;&#20986;&#20102;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;(SEDD)&#24182;&#22312;GPT-2&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.16834</link><description>&lt;p&gt;
&#36890;&#36807;&#20272;&#35745;&#25968;&#25454;&#20998;&#24067;&#27604;&#20363;&#30340;&#31163;&#25955;&#25193;&#25955;&#35821;&#35328;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution. (arXiv:2310.16834v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16834
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#29109;&#36825;&#19968;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24357;&#34917;&#20102;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#25552;&#20986;&#20102;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;(SEDD)&#24182;&#22312;GPT-2&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#22312;&#35768;&#22810;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#20013;&#20855;&#26377;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#33258;&#28982;&#35821;&#35328;&#31561;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#21364;&#34920;&#29616;&#19981;&#20339;&#12290;&#20851;&#38190;&#26159;&#65292;&#26631;&#20934;&#30340;&#25193;&#25955;&#27169;&#22411;&#20381;&#36182;&#20110;&#25104;&#29087;&#30340;&#24471;&#20998;&#21305;&#37197;&#29702;&#35770;&#65292;&#20294;&#26159;&#23558;&#20854;&#25512;&#24191;&#21040;&#31163;&#25955;&#32467;&#26500;&#24182;&#27809;&#26377;&#21462;&#24471;&#30456;&#21516;&#30340;&#32463;&#39564;&#25910;&#30410;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#24471;&#20998;&#29109;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#26469;&#24357;&#34917;&#36825;&#20010;&#24046;&#36317;&#65292;&#23427;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#31283;&#23450;&#65292;&#21487;&#20197;&#24418;&#25104;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#30340;ELBO&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#21435;&#22122;&#21464;&#20307;&#39640;&#25928;&#20248;&#21270;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65288;SEDD&#65289;&#25193;&#23637;&#21040;GPT-2&#30340;&#23454;&#39564;&#35774;&#32622;&#20013;&#65292;&#23454;&#29616;&#20102;&#26497;&#20855;&#31454;&#20105;&#21147;&#30340;&#20284;&#28982;&#24230;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#29420;&#29305;&#30340;&#31639;&#27861;&#20248;&#21183;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#27604;&#36739;&#22823;&#23567;&#30456;&#20284;&#30340;SEDD&#21644;GPT-2&#27169;&#22411;&#26102;&#65292;SEDD&#36798;&#21040;&#20102;&#21487;&#27604;&#36739;&#30340;&#22256;&#24785;&#24230;&#65288;&#36890;&#24120;&#22312;&#22522;&#32447;&#30340;+$10\%$&#20869;&#65292;&#24182;&#19988;&#26377;&#26102;&#36229;&#36807;&#22522;&#32447;&#65289;&#12290;&#27492;&#22806;&#65292;SEDD&#27169;&#22411;&#23398;&#21040;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel discrete score matching loss that is more stable than existing methods, forms an ELBO for maximum likelihood training, and can be efficiently optimized with a denoising variant. We scale our Score Entropy Discrete Diffusion models (SEDD) to the experimental setting of GPT-2, achieving highly competitive likelihoods while also introducing distinct algorithmic advantages. In particular, when comparing similarly sized SEDD and GPT-2 models, SEDD attains comparable perplexities (normally within $+10\%$ of and sometimes outperforming the baseline). Furthermore, SEDD models lear
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#19979;&#19968;&#33268;&#20272;&#35745;&#26377;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#21442;&#25968;&#38750;&#31232;&#30095;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#33719;&#24471;&#33391;&#22909;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#28508;&#22312;&#32467;&#26524;&#20013;&#30340;&#32447;&#24615;&#27169;&#22411;&#21442;&#25968;&#21487;&#20998;&#20026;&#29305;&#23450;&#20110;&#27835;&#30103;&#26041;&#27861;&#21644;&#20844;&#20849;&#21442;&#25968;&#65292;&#24182;&#36890;&#36807;&#19968;&#20010;&#31216;&#20026;&#38544;&#24335;&#31232;&#30095;&#24615;&#30340;&#36739;&#24369;&#20551;&#35774;&#23454;&#29616;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2310.16819</link><description>&lt;p&gt;
CATE Lasso: &#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#19979;&#30340;&#26377;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
CATE Lasso: Conditional Average Treatment Effect Estimation with High-Dimensional Linear Regression. (arXiv:2310.16819v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#19979;&#19968;&#33268;&#20272;&#35745;&#26377;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#21442;&#25968;&#38750;&#31232;&#30095;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#33719;&#24471;&#33391;&#22909;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#28508;&#22312;&#32467;&#26524;&#20013;&#30340;&#32447;&#24615;&#27169;&#22411;&#21442;&#25968;&#21487;&#20998;&#20026;&#29305;&#23450;&#20110;&#27835;&#30103;&#26041;&#27861;&#21644;&#20844;&#20849;&#21442;&#25968;&#65292;&#24182;&#36890;&#36807;&#19968;&#20010;&#31216;&#20026;&#38544;&#24335;&#31232;&#30095;&#24615;&#30340;&#36739;&#24369;&#20551;&#35774;&#23454;&#29616;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26377;&#20851;&#20004;&#31181;&#27835;&#30103;&#26041;&#27861;&#30340;&#22240;&#26524;&#25512;&#26029;&#20013;&#65292;&#26377;&#26465;&#20214;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#20316;&#20026;&#34920;&#31034;&#20010;&#24615;&#21270;&#22240;&#26524;&#25928;&#24212;&#30340;&#37325;&#35201;&#25351;&#26631;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#22312;&#21327;&#21464;&#37327;&#26465;&#20214;&#19979;&#20004;&#31181;&#27835;&#30103;&#26041;&#27861;&#30340;&#39044;&#26399;&#32467;&#26524;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#26412;&#30740;&#31350;&#20551;&#35774;&#20004;&#20010;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#28508;&#22312;&#32467;&#26524;&#19982;&#20004;&#31181;&#27835;&#30103;&#26041;&#27861;&#30340;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#23558;CATE&#23450;&#20041;&#20026;&#20004;&#20010;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#24230;&#21644;&#38750;&#31232;&#30095;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#19968;&#33268;&#22320;&#20272;&#35745;CATE&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#19981;&#26174;&#24335;&#20551;&#35774;&#31232;&#30095;&#24615;&#65292;&#20173;&#28982;&#21487;&#20197;&#33719;&#24471;&#22914;&#19968;&#33268;&#24615;&#31561;&#29702;&#35770;&#24615;&#36136;&#65292;&#21482;&#35201;&#25105;&#20204;&#20551;&#35774;CATE&#30340;&#23450;&#20041;&#28304;&#33258;&#19968;&#20010;&#31216;&#20026;&#38544;&#24335;&#31232;&#30095;&#24615;&#30340;&#36739;&#24369;&#20551;&#35774;&#12290;&#22312;&#36825;&#20010;&#20551;&#35774;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#28508;&#22312;&#32467;&#26524;&#20013;&#32447;&#24615;&#27169;&#22411;&#30340;&#21442;&#25968;&#21487;&#20197;&#20998;&#20026;&#29305;&#23450;&#20110;&#27835;&#30103;&#26041;&#27861;&#21644;&#20844;&#20849;&#21442;&#25968;&#65292;&#20854;&#20013;&#29305;&#23450;&#20110;&#27835;&#30103;&#26041;&#27861;&#30340;&#21442;&#25968;&#21487;&#34987;&#23454;&#29616;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
In causal inference about two treatments, Conditional Average Treatment Effects (CATEs) play an important role as a quantity representing an individualized causal effect, defined as a difference between the expected outcomes of the two treatments conditioned on covariates. This study assumes two linear regression models between a potential outcome and covariates of the two treatments and defines CATEs as a difference between the linear regression models. Then, we propose a method for consistently estimating CATEs even under high-dimensional and non-sparse parameters. In our study, we demonstrate that desirable theoretical properties, such as consistency, remain attainable even without assuming sparsity explicitly if we assume a weaker assumption called implicit sparsity originating from the definition of CATEs. In this assumption, we suppose that parameters of linear models in potential outcomes can be divided into treatment-specific and common parameters, where the treatment-specific 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#35843;&#25972;&#20197;&#23454;&#29616;&#24179;&#28369;&#20998;&#31867;&#22120;&#40065;&#26834;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.16779</link><description>&lt;p&gt;
&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;
&lt;/p&gt;
&lt;p&gt;
Multi-scale Diffusion Denoised Smoothing. (arXiv:2310.16779v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#35843;&#25972;&#20197;&#23454;&#29616;&#24179;&#28369;&#20998;&#31867;&#22120;&#40065;&#26834;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26368;&#36817;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#38543;&#26426;&#24179;&#28369;&#24050;&#25104;&#20026;&#23569;&#25968;&#20960;&#20010;&#20999;&#23454;&#21487;&#34892;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;&#20026;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#27169;&#22411;&#25552;&#20379;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#8220;&#21435;&#22122;&#21644;&#20998;&#31867;&#8221;&#27969;&#31243;&#65292;&#21363;&#25152;&#35859;&#30340;&#21435;&#22122;&#24179;&#28369;&#65292;&#22312;&#20219;&#20309;&#20998;&#31867;&#22120;&#19978;&#25191;&#34892;&#38543;&#26426;&#24179;&#28369;&#65292;&#21069;&#25552;&#26159;&#26377;&#19968;&#20010;&#20934;&#30830;&#30340;&#21435;&#22122;&#22120;&#21487;&#29992;&#65292;&#27604;&#22914;&#25193;&#25955;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#36136;&#30097;&#21738;&#31181;&#25193;&#25955;&#27169;&#22411;&#30340;&#34920;&#31034;&#24418;&#24335;&#33021;&#22815;&#26368;&#22823;&#21270;&#21435;&#22122;&#24179;&#28369;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26032;&#30340;&#30446;&#26631;&#65292;&#26088;&#22312;&#23454;&#29616;&#20849;&#21516;&#22122;&#22768;&#27700;&#24179;&#19979;&#24179;&#28369;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#65292;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#36827;&#34892;&#31934;&#32454;&#35843;&#25972;&#65292;&#21516;&#26102;&#20063;&#20026;&#20854;&#35748;&#35777;&#40065;&#26834;&#24615;&#34917;&#20607;&#20934;&#30830;&#24230;&#30340;&#25104;&#26412;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple "denoise-and-classify" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we investigate the trade-off between accuracy and certified robustness of denoised smoothing: for example, we question on which representation of diffusion model would maximize the certified robustness of denoised smoothing. We consider a new objective that aims collective robustness of smoothed classifiers across multiple noise levels at a shared diffusion model, which also suggests a new way to compensate the cost of accuracy in randomized smoothing for its certified robustness. This objective motivates us to fine-tune diffusion model (a) to perform consistent de
&lt;/p&gt;</description></item><item><title>MixerFlow&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;MLP-Mixer&#26550;&#26500;&#30340;&#27491;&#21017;&#21270;&#27969;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#20379;&#26377;&#25928;&#30340;&#26435;&#37325;&#20849;&#20139;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#22270;&#20687;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#21644;&#26356;&#20016;&#23500;&#30340;&#23884;&#20837;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.16777</link><description>&lt;p&gt;
&#22270;&#20687;&#24314;&#27169;&#30340;MixerFlow
&lt;/p&gt;
&lt;p&gt;
MixerFlow for Image Modelling. (arXiv:2310.16777v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16777
&lt;/p&gt;
&lt;p&gt;
MixerFlow&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;MLP-Mixer&#26550;&#26500;&#30340;&#27491;&#21017;&#21270;&#27969;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#20379;&#26377;&#25928;&#30340;&#26435;&#37325;&#20849;&#20139;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#22270;&#20687;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#21644;&#26356;&#20016;&#23500;&#30340;&#23884;&#20837;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#27969;&#26159;&#19968;&#31181;&#32479;&#35745;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#21452;&#23556;&#21464;&#25442;&#23558;&#22797;&#26434;&#23494;&#24230;&#36716;&#25442;&#20026;&#31616;&#21333;&#23494;&#24230;&#65292;&#23454;&#29616;&#20102;&#23494;&#24230;&#20272;&#35745;&#21644;&#20174;&#21333;&#20010;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#30340;&#21151;&#33021;&#12290;&#22312;&#22270;&#20687;&#24314;&#27169;&#30340;&#32972;&#26223;&#19979;&#65292;&#20027;&#35201;&#36873;&#25321;&#30340;&#26159;&#22522;&#20110;Glow&#30340;&#26550;&#26500;&#65292;&#32780;&#20854;&#20182;&#26550;&#26500;&#22312;&#30740;&#31350;&#30028;&#23578;&#26410;&#24471;&#21040;&#24191;&#27867;&#25506;&#32034;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;MLP-Mixer&#26550;&#26500;&#30340;&#26032;&#22411;&#26550;&#26500;MixerFlow&#65292;&#36827;&#19968;&#27493;&#32479;&#19968;&#20102;&#29983;&#25104;&#24615;&#21644;&#21028;&#21035;&#24615;&#24314;&#27169;&#26550;&#26500;&#12290;MixerFlow&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26435;&#37325;&#20849;&#20139;&#26426;&#21046;&#65292;&#36866;&#29992;&#20110;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22266;&#23450;&#35745;&#31639;&#39044;&#31639;&#19979;&#65292;MixerFlow&#22312;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#26356;&#22909;&#30340;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#65292;&#24182;&#19988;&#38543;&#30528;&#22270;&#20687;&#20998;&#36776;&#29575;&#30340;&#22686;&#21152;&#65292;&#20854;&#24615;&#33021;&#20063;&#24471;&#21040;&#20102;&#33391;&#22909;&#30340;&#25193;&#23637;&#65292;&#20351;&#24471;MixerFlow&#25104;&#20026;Glow-based&#26550;&#26500;&#30340;&#19968;&#20010;&#24378;&#22823;&#32780;&#31616;&#21333;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;MixerFlow&#25552;&#20379;&#20102;&#27604;Glow-based&#26550;&#26500;&#26356;&#20016;&#23500;&#30340;&#23884;&#20837;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalising flows are statistical models that transform a complex density into a simpler density through the use of bijective transformations enabling both density estimation and data generation from a single model. In the context of image modelling, the predominant choice has been the Glow-based architecture, whereas alternative architectures remain largely unexplored in the research community. In this work, we propose a novel architecture called MixerFlow, based on the MLP-Mixer architecture, further unifying the generative and discriminative modelling architectures. MixerFlow offers an effective mechanism for weight sharing for flow-based models. Our results demonstrate better density estimation on image datasets under a fixed computational budget and scales well as the image resolution increases, making MixeFlow a powerful yet simple alternative to the Glow-based architectures. We also show that MixerFlow provides more informative embeddings than Glow-based architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;</title><link>http://arxiv.org/abs/2310.16705</link><description>&lt;p&gt;
&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#27969;&#22312;&#21464;&#20998;&#25512;&#26029;&#30340;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gradient Flow over Variational Parameter Space for Variational Inference. (arXiv:2310.16705v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#21464;&#20998;&#21442;&#25968;&#34987;&#35843;&#25972;&#20197;&#20351;&#21464;&#20998;&#20998;&#24067;&#19982;&#30495;&#23454;&#21518;&#39564;&#23613;&#21487;&#33021;&#25509;&#36817;&#12290;&#21487;&#20197;&#36890;&#36807;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#26222;&#36890;&#26799;&#24230;&#19979;&#38477;&#25110;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#26469;&#35299;&#20915;&#20248;&#21270;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#19968;&#20010;&#8220;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#8221;&#20013;&#23450;&#20041;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#20248;&#21270;&#25216;&#26415;&#65292;&#21363;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#21644;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#65292;&#21487;&#20197;&#37325;&#26032;&#35299;&#37322;&#20026;&#25152;&#25552;&#20986;&#30340;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#30340;&#29305;&#23450;&#23454;&#20363;&#12290;&#20026;&#20102;&#25552;&#39640;&#20248;&#21270;&#25928;&#29575;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#23454;&#29992;&#30340;&#26041;&#27861;&#26469;&#25968;&#20540;&#27714;&#35299;&#31163;&#25955;&#26799;&#24230;&#27969;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference (VI) can be cast as an optimization problem in which the variational parameters are tuned to closely align a variational distribution with the true posterior. The optimization task can be approached through vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient VI. In this work, we reframe VI as the optimization of an objective that concerns probability distributions defined over a \textit{variational parameter space}. Subsequently, we propose Wasserstein gradient descent for tackling this optimization problem. Notably, the optimization techniques, namely black-box VI and natural-gradient VI, can be reinterpreted as specific instances of the proposed Wasserstein gradient descent. To enhance the efficiency of optimization, we develop practical methods for numerically solving the discrete gradient flows. We validate the effectiveness of the proposed methods through empirical experiments on a synthetic dataset, supplemented by theore
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21093;&#31163;&#31639;&#27861;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#30340;&#26032;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20998;&#26512;&#22810;&#31181;&#31867;&#22411;&#30340;&#32467;&#26524;&#12290;&#26041;&#27861;&#36890;&#36807;&#20004;&#31181;&#21093;&#31163;&#31639;&#27861;&#26469;&#30830;&#23450;&#22240;&#26524;&#20851;&#31995;&#21644;&#26377;&#25928;&#30340;&#24037;&#20855;&#21464;&#37327;&#65292;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.16698</link><description>&lt;p&gt;
&#36890;&#36807;&#21093;&#31163;&#31639;&#27861;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery with Generalized Linear Models through Peeling Algorithms. (arXiv:2310.16698v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21093;&#31163;&#31639;&#27861;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#30340;&#26032;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20998;&#26512;&#22810;&#31181;&#31867;&#22411;&#30340;&#32467;&#26524;&#12290;&#26041;&#27861;&#36890;&#36807;&#20004;&#31181;&#21093;&#31163;&#31639;&#27861;&#26469;&#30830;&#23450;&#22240;&#26524;&#20851;&#31995;&#21644;&#26377;&#25928;&#30340;&#24037;&#20855;&#21464;&#37327;&#65292;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36866;&#29992;&#20110;&#20998;&#26512;&#22810;&#31181;&#31867;&#22411;&#30340;&#32467;&#26524;&#30340;&#24191;&#20041;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#65292;&#21253;&#25324;&#31163;&#25955;&#12289;&#36830;&#32493;&#21644;&#28151;&#21512;&#25968;&#25454;&#12290;&#22240;&#26524;&#21457;&#29616;&#24120;&#24120;&#38754;&#20020;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#25361;&#25112;&#65292;&#36825;&#38459;&#30861;&#20102;&#22240;&#26524;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36890;&#36807;&#24320;&#21457;&#20004;&#31181;&#21093;&#31163;&#31639;&#27861;&#65288;&#33258;&#19979;&#32780;&#19978;&#21644;&#33258;&#19978;&#32780;&#19979;&#65289;&#26469;&#30830;&#23450;&#22240;&#26524;&#20851;&#31995;&#21644;&#26377;&#25928;&#30340;&#24037;&#20855;&#21464;&#37327;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#21033;&#29992;&#22522;&#20110;&#33410;&#28857;&#21270;GLM&#22238;&#24402;&#30340;&#21093;&#31163;&#31639;&#27861;&#37325;&#26500;&#36229;&#22270;&#65292;&#34920;&#31034;&#21464;&#37327;&#20043;&#38388;&#30340;&#31062;&#20808;&#20851;&#31995;&#65292;&#21033;&#29992;&#20027;&#35201;&#21644;&#20202;&#22120;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#21478;&#19968;&#20010;&#21093;&#31163;&#31639;&#27861;&#20174;&#31062;&#20808;&#20851;&#31995;&#20013;&#20272;&#35745;&#29238;&#27597;-&#23376;&#22899;&#25928;&#24212;&#65292;&#21516;&#26102;&#36890;&#36807;&#20174;&#29238;&#27597;&#30340;&#27169;&#22411;&#20511;&#29992;&#20449;&#24687;&#26469;&#35299;&#20915;&#23376;&#22899;&#27169;&#22411;&#30340;&#28151;&#28102;&#38382;&#39064;&#12290;&#26412;&#25991;&#23545;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#30456;&#20851;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article presents a novel method for causal discovery with generalized structural equation models suited for analyzing diverse types of outcomes, including discrete, continuous, and mixed data. Causal discovery often faces challenges due to unmeasured confounders that hinder the identification of causal relationships. The proposed approach addresses this issue by developing two peeling algorithms (bottom-up and top-down) to ascertain causal relationships and valid instruments. This approach first reconstructs a super-graph to represent ancestral relationships between variables, using a peeling algorithm based on nodewise GLM regressions that exploit relationships between primary and instrumental variables. Then, it estimates parent-child effects from the ancestral relationships using another peeling algorithm while deconfounding a child's model with information borrowed from its parents' models. The article offers a theoretical analysis of the proposed approach, which establishes c
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21305;&#37197;&#30446;&#26631;&#21644;&#24314;&#35758;&#20998;&#24067;&#30340;&#35703;&#33322;&#30697;&#65292;&#26368;&#23567;&#21270;$\alpha$-&#25955;&#24230;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#20415;&#22312;&#22788;&#29702;&#37325;&#23614;&#20998;&#24067;&#26102;&#33719;&#24471;&#26356;&#20934;&#30830;&#21644;&#26356;&#24555;&#36895;&#30340;&#20272;&#35745;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.16653</link><description>&lt;p&gt;
&#36890;&#36807;$\alpha$-&#25955;&#24230;&#26368;&#23567;&#21270;&#23454;&#29616;&#37325;&#23614;&#20998;&#24067;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Adaptive importance sampling for heavy-tailed distributions via $\alpha$-divergence minimization. (arXiv:2310.16653v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16653
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21305;&#37197;&#30446;&#26631;&#21644;&#24314;&#35758;&#20998;&#24067;&#30340;&#35703;&#33322;&#30697;&#65292;&#26368;&#23567;&#21270;$\alpha$-&#25955;&#24230;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#20415;&#22312;&#22788;&#29702;&#37325;&#23614;&#20998;&#24067;&#26102;&#33719;&#24471;&#26356;&#20934;&#30830;&#21644;&#26356;&#24555;&#36895;&#30340;&#20272;&#35745;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#65288;AIS&#65289;&#31639;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#36924;&#36817;&#22797;&#26434;&#30446;&#26631;&#27010;&#29575;&#20998;&#24067;&#30340;&#26399;&#26395;&#12290;&#24403;&#30446;&#26631;&#20998;&#24067;&#20855;&#26377;&#37325;&#23614;&#29305;&#24615;&#26102;&#65292;&#29616;&#26377;&#30340;AIS&#31639;&#27861;&#21487;&#33021;&#25552;&#20379;&#19981;&#19968;&#33268;&#30340;&#20272;&#35745;&#25110;&#25910;&#25947;&#32531;&#24930;&#65292;&#22240;&#20026;&#23427;&#20204;&#24120;&#24120;&#24573;&#30053;&#30446;&#26631;&#30340;&#23614;&#37096;&#34892;&#20026;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;Student-t&#24314;&#35758;&#20998;&#24067;&#26469;&#36924;&#36817;&#30446;&#26631;&#30340;AIS&#31639;&#27861;&#12290;&#36890;&#36807;&#21305;&#37197;&#30446;&#26631;&#21644;&#24314;&#35758;&#20998;&#24067;&#30340;&#35703;&#33322;&#30697;&#65288;&#22312;&#37325;&#23614;&#20998;&#24067;&#19979;&#20063;&#21487;&#23450;&#20041;&#65289;&#65292;&#25105;&#20204;&#36866;&#24212;&#20102;&#20301;&#32622;&#21644;&#23610;&#24230;&#21442;&#25968;&#12290;&#36825;&#20123;&#26356;&#26032;&#36890;&#36807;&#26368;&#23567;&#21270;&#30446;&#26631;&#21644;&#24314;&#35758;&#20998;&#24067;&#20043;&#38388;&#30340;$\alpha$-&#25955;&#24230;&#26469;&#19982;&#21464;&#20998;&#25512;&#26029;&#30456;&#32852;&#31995;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;$\alpha$-&#25955;&#24230;&#21487;&#20197;&#36890;&#36807;&#24191;&#20041;&#30340;&#26377;&#25928;&#26679;&#26412;&#22823;&#23567;&#30340;&#27010;&#24565;&#26469;&#36924;&#36817;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#26032;&#30340;&#35270;&#35282;&#26469;&#36890;&#36807;&#36125;&#21494;&#26031;&#20248;&#21270;&#26469;&#36866;&#24212;&#23614;&#37096;&#21442;&#25968;&#12290;&#36890;&#36807;&#24212;&#29992;&#23454;&#20363;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adaptive importance sampling (AIS) algorithms are widely used to approximate expectations with respect to complicated target probability distributions. When the target has heavy tails, existing AIS algorithms can provide inconsistent estimators or exhibit slow convergence, as they often neglect the target's tail behaviour. To avoid this pitfall, we propose an AIS algorithm that approximates the target by Student-t proposal distributions. We adapt location and scale parameters by matching the escort moments - which are defined even for heavy-tailed distributions - of the target and the proposal. These updates minimize the $\alpha$-divergence between the target and the proposal, thereby connecting with variational inference. We then show that the $\alpha$-divergence can be approximated by a generalized notion of effective sample size and leverage this new perspective to adapt the tail parameter with Bayesian optimization. We demonstrate the efficacy of our approach through applications t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21253;&#21547;&#32570;&#22833;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#27491;&#21017;&#21270;&#32534;&#30721;&#22120;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#21518;&#39564;&#19968;&#33268;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#32570;&#22833;&#20540;&#35774;&#32622;&#19979;&#21487;&#20197;&#25552;&#39640;&#37325;&#24314;&#36136;&#37327;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.16648</link><description>&lt;p&gt;
&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#20013;&#32570;&#22833;&#25968;&#25454;&#30340;&#21518;&#39564;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Posterior Consistency for Missing Data in Variational Autoencoders. (arXiv:2310.16648v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16648
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21253;&#21547;&#32570;&#22833;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#27491;&#21017;&#21270;&#32534;&#30721;&#22120;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#21518;&#39564;&#19968;&#33268;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#32570;&#22833;&#20540;&#35774;&#32622;&#19979;&#21487;&#20197;&#25552;&#39640;&#37325;&#24314;&#36136;&#37327;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#21253;&#21547;&#32570;&#22833;&#20540;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#65292;&#21363;&#19968;&#31181;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#30001;&#20110;&#23436;&#25972;&#25968;&#25454;&#36890;&#24120;&#26080;&#27861;&#33719;&#24471;&#25110;&#25104;&#26412;&#22826;&#39640;&#65292;&#36825;&#31181;&#25968;&#25454;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#29616;&#23454;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#25913;&#36827;VAE&#30340;&#25674;&#38144;&#21518;&#39564;&#25512;&#26029;&#65292;&#21363;&#22312;&#32570;&#22833;&#25968;&#25454;&#24773;&#20917;&#19979;&#21487;&#20197;&#23398;&#20064;&#21040;&#19981;&#19968;&#33268;&#21518;&#39564;&#20998;&#24067;&#30340;&#32534;&#30721;&#22120;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21518;&#39564;&#19968;&#33268;&#24615;&#30340;&#27491;&#24335;&#23450;&#20041;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#27491;&#21017;&#21270;&#32534;&#30721;&#22120;&#21518;&#39564;&#20998;&#24067;&#20197;&#20419;&#36827;&#19968;&#33268;&#24615;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#25152;&#25552;&#20986;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#38754;&#23545;&#32570;&#22833;&#20540;&#26102;&#24314;&#35758;&#20102;&#19982;&#25991;&#29486;&#20013;&#36890;&#24120;&#32771;&#34385;&#30340;&#35757;&#32451;&#30446;&#26631;&#19981;&#21516;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#37325;&#26500;&#36136;&#37327;&#21644;d&#26041;&#38754;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#25552;&#39640;&#20102;&#32570;&#22833;&#20540;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning Variational Autoencoders (VAEs), i.e., a type of deep generative model, from data with missing values. Such data is omnipresent in real-world applications of machine learning because complete data is often impossible or too costly to obtain. We particularly focus on improving a VAE's amortized posterior inference, i.e., the encoder, which in the case of missing data can be susceptible to learning inconsistent posterior distributions regarding the missingness. To this end, we provide a formal definition of posterior consistency and propose an approach for regularizing an encoder's posterior distribution which promotes this consistency. We observe that the proposed regularization suggests a different training objective than that typically considered in the literature when facing missing values. Furthermore, we empirically demonstrate that our regularization leads to improved performance in missing value settings in terms of reconstruction quality and d
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#32597;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#26041;&#27861;&#26469;&#20943;&#36731;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20559;&#24046;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.16638</link><description>&lt;p&gt;
&#36866;&#24212;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Covariate Shift Adaptation Robust to Density-Ratio Estimation. (arXiv:2310.16638v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16638
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#32597;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#26041;&#27861;&#26469;&#20943;&#36731;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20559;&#24046;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#20855;&#26377;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#32780;&#27979;&#35797;&#25968;&#25454;&#21482;&#21253;&#21547;&#21327;&#21464;&#37327;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#39044;&#27979;&#27979;&#35797;&#25968;&#25454;&#20013;&#32570;&#22833;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#35757;&#32451;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#20998;&#24067;&#19981;&#21516;&#12290;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#30740;&#31350;&#25552;&#20986;&#20102;&#36890;&#36807;&#20351;&#29992;&#23494;&#24230;&#27604;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#26469;&#36827;&#34892;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#35757;&#32451;&#25968;&#25454;&#25439;&#22833;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#27599;&#20010;&#26435;&#37325;&#26159;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#23494;&#24230;&#27604;&#30340;&#20272;&#35745;&#65292;&#20197;&#36817;&#20284;&#27979;&#35797;&#25968;&#25454;&#30340;&#39118;&#38505;&#12290;&#23613;&#31649;&#23427;&#20801;&#35768;&#25105;&#20204;&#33719;&#24471;&#19968;&#20010;&#26368;&#23567;&#21270;&#27979;&#35797;&#25968;&#25454;&#39118;&#38505;&#30340;&#27169;&#22411;&#65292;&#20294;&#20854;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#23494;&#24230;&#27604;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#23494;&#24230;&#27604;&#30340;&#20272;&#35745;&#35823;&#24046;&#20063;&#20250;&#23548;&#33268;&#22238;&#24402;&#27169;&#22411;&#30340;&#20272;&#35745;&#22120;&#20135;&#29983;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model's 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35757;&#32451;&#36807;&#31243;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#37327;&#36716;&#25442;&#20844;&#24335;&#26799;&#24230;&#30340;&#39640;&#25928;&#20272;&#35745;&#22120;&#65292;&#20811;&#26381;&#20102;&#24402;&#19968;&#21270;&#27969;&#35774;&#35745;&#22312;&#35299;&#26512;&#36870;&#21464;&#25442;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;&#36825;&#20351;&#24471;&#20219;&#20309;&#20445;&#25345;&#32500;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#21487;&#20197;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#65292;&#24182;&#22312;&#20998;&#23376;&#29983;&#25104;&#21644;&#21453;&#38382;&#39064;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20248;&#31168;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.16624</link><description>&lt;p&gt;
&#33258;&#30001;&#24418;&#24335;&#27969;&#21160;&#65306;&#20351;&#20219;&#20309;&#26550;&#26500;&#25104;&#20026;&#24402;&#19968;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Free-form Flows: Make Any Architecture a Normalizing Flow. (arXiv:2310.16624v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16624
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35757;&#32451;&#36807;&#31243;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#37327;&#36716;&#25442;&#20844;&#24335;&#26799;&#24230;&#30340;&#39640;&#25928;&#20272;&#35745;&#22120;&#65292;&#20811;&#26381;&#20102;&#24402;&#19968;&#21270;&#27969;&#35774;&#35745;&#22312;&#35299;&#26512;&#36870;&#21464;&#25442;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;&#36825;&#20351;&#24471;&#20219;&#20309;&#20445;&#25345;&#32500;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#21487;&#20197;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#65292;&#24182;&#22312;&#20998;&#23376;&#29983;&#25104;&#21644;&#21453;&#38382;&#39064;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20248;&#31168;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#30452;&#25509;&#26368;&#22823;&#21270;&#21487;&#33021;&#24615;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#20197;&#21069;&#65292;&#24402;&#19968;&#21270;&#27969;&#30340;&#35774;&#35745;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21463;&#21040;&#23545;&#35299;&#26512;&#36870;&#21464;&#25442;&#30340;&#38656;&#35201;&#38480;&#21046;&#12290;&#36890;&#36807;&#20351;&#29992;&#23545;&#21464;&#37327;&#36716;&#25442;&#20844;&#24335;&#30340;&#26799;&#24230;&#30340;&#39640;&#25928;&#20272;&#35745;&#22120;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#12290;&#36825;&#20351;&#24471;&#20219;&#20309;&#20445;&#25345;&#32500;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#23558;&#37325;&#28857;&#25918;&#22312;&#31934;&#30830;&#35843;&#25972;&#24402;&#32435;&#20559;&#35265;&#20197;&#36866;&#24212;&#25163;&#22836;&#30340;&#20219;&#21153;&#19978;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#20998;&#23376;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#21033;&#29992;$E(n)$-&#31561;&#21464;&#32593;&#32476;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#20010;&#21453;&#38382;&#39064;&#22522;&#20934;&#27979;&#35797;&#20013;&#20063;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#21516;&#26102;&#37319;&#29992;&#29616;&#25104;&#30340;ResNet&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing Flows are generative models that directly maximize the likelihood. Previously, the design of normalizing flows was largely constrained by the need for analytical invertibility. We overcome this constraint by a training procedure that uses an efficient estimator for the gradient of the change of variables formula. This enables any dimension-preserving neural network to serve as a generative model through maximum likelihood training. Our approach allows placing the emphasis on tailoring inductive biases precisely to the task at hand. Specifically, we achieve excellent results in molecule generation benchmarks utilizing $E(n)$-equivariant networks. Moreover, our method is competitive in an inverse problem benchmark, while employing off-the-shelf ResNet architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#30740;&#31350;&#65292;&#23558;&#35777;&#26126;&#30340;&#33539;&#22260;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#25193;&#23637;&#21040;&#20102;&#26356;&#22823;&#30340;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(PSEUDO-IID)&#65292;&#21253;&#25324;&#20302;&#31209;&#21644;&#31232;&#30095;&#35774;&#32622;&#12290;&#20316;&#32773;&#21457;&#29616;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#36827;&#34892;&#24615;&#33021;&#35843;&#20248;&#12290;</title><link>http://arxiv.org/abs/2310.16597</link><description>&lt;p&gt;
&#36229;&#36234;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#65306;&#31232;&#30095;&#21644;&#20302;&#31209;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20063;&#26159;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes. (arXiv:2310.16597v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#30740;&#31350;&#65292;&#23558;&#35777;&#26126;&#30340;&#33539;&#22260;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#25193;&#23637;&#21040;&#20102;&#26356;&#22823;&#30340;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(PSEUDO-IID)&#65292;&#21253;&#25324;&#20302;&#31209;&#21644;&#31232;&#30095;&#35774;&#32622;&#12290;&#20316;&#32773;&#21457;&#29616;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#36827;&#34892;&#24615;&#33021;&#35843;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#38480;&#23485;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#19968;&#20010;&#26377;&#29992;&#19988;&#21487;&#31649;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#35768;&#22810;&#29616;&#35937;&#12290;&#20854;&#20013;&#19968;&#20010;&#20363;&#23376;&#26159;&#38543;&#26426;&#28145;&#23618;&#32593;&#32476;&#25910;&#25947;&#21040;&#39640;&#26031;&#36807;&#31243;&#65292;&#20174;&#32780;&#33021;&#22815;&#23545;&#28608;&#27963;&#20989;&#25968;&#21644;&#32593;&#32476;&#26435;&#37325;&#36873;&#25321;&#23545;&#35757;&#32451;&#21160;&#24577;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#20998;&#26512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;Matthews&#31561;&#20154;(2018)&#30340;&#24320;&#21019;&#24615;&#35777;&#26126;&#25193;&#23637;&#21040;&#26356;&#22823;&#30340;&#21021;&#22987;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(&#25105;&#20204;&#31216;&#20043;&#20026;PSEUDO-IID)&#65292;&#20854;&#20013;&#21253;&#25324;&#29420;&#31435;&#21516;&#20998;&#24067;&#21644;&#27491;&#20132;&#26435;&#37325;&#30340;&#24050;&#26377;&#24773;&#20917;&#65292;&#20197;&#21450;&#22240;&#20854;&#35745;&#31639;&#21152;&#36895;&#20248;&#21183;&#32780;&#21463;&#21040;&#36190;&#35465;&#30340;&#26032;&#20852;&#20302;&#31209;&#21644;&#32467;&#26500;&#31232;&#30095;&#35774;&#32622;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#21487;&#20197;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#35843;&#25972;&#23427;&#20204;&#30340;&#20020;&#30028;&#24615;&#65292;&#20197;&#22686;&#24378;&#35757;&#32451;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The infinitely wide neural network has been proven a useful and manageable mathematical model that enables the understanding of many phenomena appearing in deep learning. One example is the convergence of random deep networks to Gaussian processes that allows a rigorous analysis of the way the choice of activation function and network weights impacts the training dynamics. In this paper, we extend the seminal proof of Matthews et al. (2018) to a larger class of initial weight distributions (which we call PSEUDO-IID), including the established cases of IID and orthogonal weights, as well as the emerging low-rank and structured sparse settings celebrated for their computational speed-up benefits. We show that fully-connected and convolutional networks initialized with PSEUDO-IID distributions are all effectively equivalent up to their variance. Using our results, one can identify the Edge-of-Chaos for a broader class of neural networks and tune them at criticality in order to enhance the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#30913;&#21147;&#35745;&#38453;&#21015;&#36827;&#34892;&#30913;&#22330;&#26144;&#23556;&#65292;&#36890;&#36807;&#26032;&#39062;&#26041;&#27861;&#23558;&#30913;&#21147;&#35745;&#30340;&#20301;&#32622;&#20449;&#24687;&#32435;&#20837;&#65292;&#25552;&#39640;&#20102;&#22320;&#22270;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.16577</link><description>&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#22122;&#22768;&#36755;&#20837;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#30913;&#21147;&#35745;&#38453;&#21015;&#36827;&#34892;&#30913;&#22330;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Mapping the magnetic field using a magnetometer array with noisy input Gaussian process regression. (arXiv:2310.16577v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#30913;&#21147;&#35745;&#38453;&#21015;&#36827;&#34892;&#30913;&#22330;&#26144;&#23556;&#65292;&#36890;&#36807;&#26032;&#39062;&#26041;&#27861;&#23558;&#30913;&#21147;&#35745;&#30340;&#20301;&#32622;&#20449;&#24687;&#32435;&#20837;&#65292;&#25552;&#39640;&#20102;&#22320;&#22270;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23460;&#20869;&#29615;&#22659;&#20013;&#30340;&#38081;&#30913;&#26448;&#26009;&#20250;&#20135;&#29983;&#29615;&#22659;&#30913;&#22330;&#30340;&#25200;&#21160;&#12290;&#36890;&#36807;&#20351;&#29992;&#30913;&#21147;&#35745;&#27979;&#37327;&#21644;&#26377;&#20851;&#30913;&#21147;&#35745;&#20301;&#32622;&#30340;&#20449;&#24687;&#65292;&#21487;&#20197;&#23398;&#20064;&#30913;&#22330;&#30340;&#31354;&#38388;&#21464;&#21270;&#24133;&#24230;&#12290;&#28982;&#32780;&#65292;&#30913;&#21147;&#35745;&#30340;&#20301;&#32622;&#36890;&#24120;&#21482;&#26159;&#22823;&#33268;&#24050;&#30693;&#65292;&#36825;&#23545;&#30913;&#22330;&#22320;&#22270;&#30340;&#36136;&#37327;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#30913;&#21147;&#35745;&#38453;&#21015;&#26469;&#25552;&#39640;&#30913;&#22330;&#22320;&#22270;&#30340;&#36136;&#37327;&#12290;&#38453;&#21015;&#30340;&#20301;&#32622;&#22823;&#33268;&#24050;&#30693;&#65292;&#20294;&#26159;&#38453;&#21015;&#19978;&#30913;&#21147;&#35745;&#30340;&#30456;&#23545;&#20301;&#32622;&#24050;&#30693;&#12290;&#25105;&#20204;&#22312;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#20013;&#21253;&#21547;&#20102;&#36825;&#20123;&#20449;&#24687;&#65292;&#20197;&#21046;&#20316;&#29615;&#22659;&#30913;&#22330;&#30340;&#22320;&#22270;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#36136;&#65292;&#24182;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#22320;&#22270;&#36136;&#37327;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ferromagnetic materials in indoor environments give rise to disturbances in the ambient magnetic field. Maps of these magnetic disturbances can be used for indoor localisation. A Gaussian process can be used to learn the spatially varying magnitude of the magnetic field using magnetometer measurements and information about the position of the magnetometer. The position of the magnetometer, however, is frequently only approximately known. This negatively affects the quality of the magnetic field map. In this paper, we investigate how an array of magnetometers can be used to improve the quality of the magnetic field map. The position of the array is approximately known, but the relative locations of the magnetometers on the array are known. We include this information in a novel method to make a map of the ambient magnetic field. We study the properties of our method in simulation and show that our method improves the map quality. We also demonstrate the efficacy of our method with exper
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#23460;&#20869;&#29615;&#22659;&#20013;&#29983;&#25104;&#22823;&#35268;&#27169;&#30913;&#22330;&#22320;&#22270;&#12290;&#36890;&#36807;&#23558;&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#19982;&#23548;&#25968;&#30456;&#32467;&#21512;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24230;&#20869;&#35745;&#31639;&#39044;&#27979;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;&#27169;&#25311;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.16574</link><description>&lt;p&gt;
&#20351;&#29992;&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#22312;&#22823;&#35268;&#27169;&#29615;&#22659;&#20013;&#29983;&#25104;&#30913;&#22330;&#22320;&#22270;
&lt;/p&gt;
&lt;p&gt;
Large-scale magnetic field maps using structured kernel interpolation for Gaussian process regression. (arXiv:2310.16574v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#23460;&#20869;&#29615;&#22659;&#20013;&#29983;&#25104;&#22823;&#35268;&#27169;&#30913;&#22330;&#22320;&#22270;&#12290;&#36890;&#36807;&#23558;&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#19982;&#23548;&#25968;&#30456;&#32467;&#21512;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24230;&#20869;&#35745;&#31639;&#39044;&#27979;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;&#27169;&#25311;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26144;&#23556;&#31639;&#27861;&#65292;&#20351;&#29992;&#36817;&#20284;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#22238;&#24402;&#35745;&#31639;&#23460;&#20869;&#29615;&#22659;&#20013;&#30340;&#22823;&#35268;&#27169;&#30913;&#22330;&#22320;&#22270;&#12290;&#26144;&#23556;&#29615;&#22659;&#20013;&#29615;&#22659;&#30913;&#22330;&#30340;&#31354;&#38388;&#21464;&#21270;&#21487;&#20197;&#29992;&#20110;&#23460;&#20869;&#23450;&#20301;&#31639;&#27861;&#12290;&#20026;&#20102;&#35745;&#31639;&#36825;&#26679;&#30340;&#22320;&#22270;&#65292;GP&#22238;&#24402;&#26159;&#19968;&#31181;&#36866;&#21512;&#30340;&#24037;&#20855;&#65292;&#22240;&#20026;&#23427;&#25552;&#20379;&#20102;&#22312;&#26032;&#20301;&#32622;&#30340;&#30913;&#22330;&#39044;&#27979;&#20197;&#21450;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#30001;&#20110;&#20840;GP&#22238;&#24402;&#30340;&#22797;&#26434;&#24230;&#38543;&#30528;&#25968;&#25454;&#28857;&#30340;&#25968;&#37327;&#21576;&#31435;&#26041;&#22686;&#38271;&#65292;&#22240;&#27492;&#23545;&#20110;GP&#30340;&#36817;&#20284;&#26041;&#27861;&#24050;&#34987;&#24191;&#27867;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#65288;SKI&#65289;&#26694;&#26550;&#19978;&#26500;&#24314;&#65292;&#36890;&#36807;&#21033;&#29992;&#39640;&#25928;&#30340;Krylov&#23376;&#31354;&#38388;&#26041;&#27861;&#21152;&#36895;&#25512;&#26029;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#24102;&#23548;&#25968;&#30340;SKI&#65288;D-SKI&#65289;&#32435;&#20837;&#20102;&#29992;&#20110;&#30913;&#22330;&#24314;&#27169;&#30340;&#26631;&#37327;&#21183;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#32447;&#24615;&#25968;&#25454;&#28857;&#22797;&#26434;&#24230;&#35745;&#31639;&#39044;&#27979;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#12290;&#22312;&#25105;&#20204;&#30340;&#27169;&#25311;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a mapping algorithm to compute large-scale magnetic field maps in indoor environments with approximate Gaussian process (GP) regression. Mapping the spatial variations in the ambient magnetic field can be used for localization algorithms in indoor areas. To compute such a map, GP regression is a suitable tool because it provides predictions of the magnetic field at new locations along with uncertainty quantification. Because full GP regression has a complexity that grows cubically with the number of data points, approximations for GPs have been extensively studied. In this paper, we build on the structured kernel interpolation (SKI) framework, speeding up inference by exploiting efficient Krylov subspace methods. More specifically, we incorporate SKI with derivatives (D-SKI) into the scalar potential model for magnetic field modeling and compute both predictive mean and covariance with a complexity that is linear in the data points. In our simulations, we show that our metho
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;Wasserstein&#26799;&#24230;&#27969;&#30340;ParVI&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#20984;&#20989;&#25968;&#24341;&#23548;&#30340;&#26356;&#24191;&#27867;&#31867;&#21035;&#30340;&#27491;&#21017;&#21270;&#22120;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#26041;&#27861;&#35774;&#35745;&#22256;&#38590;&#21644;&#38480;&#21046;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20855;&#26377;&#24378;&#22823;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#21644;&#39640;&#25928;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.16516</link><description>&lt;p&gt;
&#22522;&#20110;&#31890;&#23376;&#30340;&#24191;&#20041;Wasserstein&#26799;&#24230;&#27969;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Particle-based Variational Inference with Generalized Wasserstein Gradient Flow. (arXiv:2310.16516v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16516
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;Wasserstein&#26799;&#24230;&#27969;&#30340;ParVI&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#20984;&#20989;&#25968;&#24341;&#23548;&#30340;&#26356;&#24191;&#27867;&#31867;&#21035;&#30340;&#27491;&#21017;&#21270;&#22120;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#26041;&#27861;&#35774;&#35745;&#22256;&#38590;&#21644;&#38480;&#21046;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20855;&#26377;&#24378;&#22823;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#21644;&#39640;&#25928;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#65288;ParVIs&#65289;&#65292;&#22914;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#65292;&#36890;&#36807;&#22522;&#20110;&#26680;&#21270;&#30340;Wasserstein&#26799;&#24230;&#27969;&#26356;&#26032;&#31890;&#23376;&#65292;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#12290;&#28982;&#32780;&#65292;&#26680;&#20989;&#25968;&#30340;&#35774;&#35745;&#36890;&#24120;&#26159;&#38750;&#24179;&#20961;&#30340;&#65292;&#24182;&#19988;&#21487;&#33021;&#23545;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#26377;&#38480;&#21046;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20855;&#26377;&#20108;&#27425;&#24418;&#24335;&#27491;&#21017;&#21270;&#39033;&#30340;&#21151;&#33021;&#26799;&#24230;&#27969;&#36924;&#36817;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;Wasserstein&#26799;&#24230;&#27969;&#30340;ParVI&#26694;&#26550;&#65292;&#31216;&#20026;&#24191;&#20041;Wasserstein&#26799;&#24230;&#19979;&#38477;&#65288;GWG&#65289;&#65292;&#20854;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#31181;&#20855;&#26377;&#20984;&#20989;&#25968;&#24341;&#23548;&#30340;&#26356;&#24191;&#27867;&#31867;&#21035;&#30340;&#27491;&#21017;&#21270;&#22120;&#30340;&#21151;&#33021;&#26799;&#24230;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;GWG&#20855;&#26377;&#24378;&#22823;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#29256;&#26412;&#65292;&#21487;&#20197;&#33258;&#21160;&#36873;&#25321;Wasserstein&#24230;&#37327;&#26469;&#21152;&#36895;&#25910;&#25947;&#12290;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Particle-based variational inference methods (ParVIs) such as Stein variational gradient descent (SVGD) update the particles based on the kernelized Wasserstein gradient flow for the Kullback-Leibler (KL) divergence. However, the design of kernels is often non-trivial and can be restrictive for the flexibility of the method. Recent works show that functional gradient flow approximations with quadratic form regularization terms can improve performance. In this paper, we propose a ParVI framework, called generalized Wasserstein gradient descent (GWG), based on a generalized Wasserstein gradient flow of the KL divergence, which can be viewed as a functional gradient method with a broader class of regularizers induced by convex functions. We show that GWG exhibits strong convergence guarantees. We also provide an adaptive version that automatically chooses Wasserstein metric to accelerate convergence. In experiments, we demonstrate the effectiveness and efficiency of the proposed framework
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35780;&#20272;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#24182;&#35782;&#21035;&#20986;&#20855;&#26377;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.16502</link><description>&lt;p&gt;
&#35780;&#20272;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#25972;&#20307;&#21644;&#37096;&#20998;&#22240;&#26524;&#33391;&#22909;&#35268;&#33539;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing the overall and partial causal well-specification of nonlinear additive noise models. (arXiv:2310.16502v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16502
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35780;&#20272;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#24182;&#35782;&#21035;&#20986;&#20855;&#26377;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#26816;&#27979;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#21487;&#33021;&#21253;&#25324;&#24322;&#26041;&#24046;&#24615;&#12290;&#25105;&#20204;&#26088;&#22312;&#35782;&#21035;&#37027;&#20123;&#21363;&#20351;&#22312;&#36825;&#31181;&#27169;&#22411;&#35268;&#33539;&#38382;&#39064;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20173;&#28982;&#21487;&#20197;&#25512;&#26029;&#20986;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;&#25105;&#20204;&#22522;&#20110;&#23545;&#22810;&#20803;&#35266;&#27979;&#25968;&#25454;&#20998;&#24067;&#30340;&#20102;&#35299;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#28982;&#21518;&#38024;&#23545;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35752;&#35770;&#20102;&#20854;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20854;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a method to detect model misspecifications in nonlinear causal additive and potentially heteroscedastic noise models. We aim to identify predictor variables for which we can infer the causal effect even in cases of such misspecification. We develop a general framework based on knowledge of the multivariate observational data distribution and we then propose an algorithm for finite sample data, discuss its asymptotic properties, and illustrate its performance on simulated and real data.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#19987;&#23478;&#31574;&#30053;&#36827;&#34892;&#20915;&#31574;&#25351;&#23548;&#30340;&#32534;&#25490;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23545;&#25239;&#24615;&#35774;&#32622;&#20013;&#30340;&#21518;&#24724;&#36793;&#30028;&#32467;&#26524;&#36716;&#31227;&#21040;&#34920;&#26684;&#35774;&#32622;&#19979;&#30340;&#32534;&#25490;&#20013;&#65292;&#25512;&#24191;&#20102;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#27934;&#23519;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#20851;&#38190;&#28857;&#22312;&#20110;&#20854;&#36879;&#26126;&#30340;&#35777;&#26126;&#12290;&#22312;&#38543;&#26426;&#21305;&#37197;&#29609;&#20855;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#27169;&#25311;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2310.16473</link><description>&lt;p&gt;
&#19987;&#23478;&#30340;&#20132;&#21709;&#26354;&#65306;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#36816;&#29992;&#23545;&#25239;&#24615;&#27934;&#23519;&#21147;&#30340;&#32534;&#25490;
&lt;/p&gt;
&lt;p&gt;
Symphony of experts: orchestration with adversarial insights in reinforcement learning. (arXiv:2310.16473v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16473
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#19987;&#23478;&#31574;&#30053;&#36827;&#34892;&#20915;&#31574;&#25351;&#23548;&#30340;&#32534;&#25490;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23545;&#25239;&#24615;&#35774;&#32622;&#20013;&#30340;&#21518;&#24724;&#36793;&#30028;&#32467;&#26524;&#36716;&#31227;&#21040;&#34920;&#26684;&#35774;&#32622;&#19979;&#30340;&#32534;&#25490;&#20013;&#65292;&#25512;&#24191;&#20102;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#27934;&#23519;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#20851;&#38190;&#28857;&#22312;&#20110;&#20854;&#36879;&#26126;&#30340;&#35777;&#26126;&#12290;&#22312;&#38543;&#26426;&#21305;&#37197;&#29609;&#20855;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#27169;&#25311;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#21270;&#24378;&#21270;&#23398;&#20064;&#21033;&#29992;&#20855;&#26377;&#20248;&#21183;&#29305;&#24615;&#30340;&#31574;&#30053;&#20197;&#36798;&#21040;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#25506;&#32034;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#32534;&#25490;&#30340;&#27010;&#24565;&#26469;&#25506;&#32034;&#36825;&#19968;&#39046;&#22495;&#65292;&#20854;&#20013;&#19968;&#32452;&#65288;&#23569;&#37327;&#65289;&#19987;&#23478;&#31574;&#30053;&#25351;&#23548;&#20915;&#31574;&#65307;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#24314;&#31435;&#20102;&#27492;&#24314;&#27169;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20174;&#23545;&#25239;&#24615;&#35774;&#32622;&#20013;&#36716;&#31227;&#21518;&#24724;&#36793;&#30028;&#32467;&#26524;&#65292;&#22312;&#34920;&#26684;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#32534;&#25490;&#30340;&#20215;&#20540;&#20989;&#25968;&#21518;&#24724;&#36793;&#30028;&#12290;&#25105;&#20204;&#23558;&#23545; Agarwal &#31561;&#20154; [2021, &#31532;5.3&#33410;] &#20013;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#20998;&#26512;&#25512;&#24191;&#24182;&#25193;&#23637;&#21040;&#20219;&#24847;&#23545;&#25239;&#24615;&#32858;&#21512;&#31574;&#30053;&#12290;&#25105;&#20204;&#36824;&#23558;&#20854;&#25193;&#23637;&#21040;&#20272;&#35745;&#20248;&#21183;&#20989;&#25968;&#30340;&#24773;&#20917;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#26399;&#26395;&#20540;&#21644;&#39640;&#27010;&#29575;&#19979;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#27934;&#23519;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#28857;&#22312;&#20110;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#32780;&#35328;&#35777;&#26126;&#36739;&#20026;&#36879;&#26126;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#38024;&#23545;&#38543;&#26426;&#21305;&#37197;&#29609;&#20855;&#27169;&#22411;&#36827;&#34892;&#20102;&#27169;&#25311;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structured reinforcement learning leverages policies with advantageous properties to reach better performance, particularly in scenarios where exploration poses challenges. We explore this field through the concept of orchestration, where a (small) set of expert policies guides decision-making; the modeling thereof constitutes our first contribution. We then establish value-functions regret bounds for orchestration in the tabular setting by transferring regret-bound results from adversarial settings. We generalize and extend the analysis of natural policy gradient in Agarwal et al. [2021, Section 5.3] to arbitrary adversarial aggregation strategies. We also extend it to the case of estimated advantage functions, providing insights into sample complexity both in expectation and high probability. A key point of our approach lies in its arguably more transparent proofs compared to existing methods. Finally, we present simulations for a stochastic matching toy model.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25581;&#31034;&#20102;&#22312;&#32447;&#24615;&#32593;&#32476;&#20013;&#30340;&#39046;&#24735;&#29616;&#35937;&#65292;&#30740;&#31350;&#20102;&#39046;&#24735;&#26102;&#38388;&#19982;&#36755;&#20837;&#36755;&#20986;&#32500;&#24230;&#12289;&#35757;&#32451;&#26679;&#26412;&#37327;&#12289;&#27491;&#21017;&#21270;&#21644;&#32593;&#32476;&#21021;&#22987;&#21270;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#27867;&#21270;&#20934;&#30830;&#24615;&#30340;&#22823;&#24133;&#25552;&#21319;&#24182;&#19981;&#19968;&#23450;&#24847;&#21619;&#30528;&#20174;&#8220;&#35760;&#24518;&#8221;&#21040;&#8220;&#29702;&#35299;&#8221;&#30340;&#36716;&#21464;&#12290;</title><link>http://arxiv.org/abs/2310.16441</link><description>&lt;p&gt;
&#22312;&#32447;&#24615;&#20272;&#35745;&#22120;&#20013;&#30340;&#39046;&#24735;&#8212;&#8212;&#19968;&#20010;&#21487;&#35299;&#30340;&#27169;&#22411;&#22312;&#19981;&#29702;&#35299;&#30340;&#24773;&#20917;&#19979;&#39046;&#24735;&#12290; &#65288;arXiv&#65306;2310.16441v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
Grokking in Linear Estimators -- A Solvable Model that Groks without Understanding. (arXiv:2310.16441v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16441
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25581;&#31034;&#20102;&#22312;&#32447;&#24615;&#32593;&#32476;&#20013;&#30340;&#39046;&#24735;&#29616;&#35937;&#65292;&#30740;&#31350;&#20102;&#39046;&#24735;&#26102;&#38388;&#19982;&#36755;&#20837;&#36755;&#20986;&#32500;&#24230;&#12289;&#35757;&#32451;&#26679;&#26412;&#37327;&#12289;&#27491;&#21017;&#21270;&#21644;&#32593;&#32476;&#21021;&#22987;&#21270;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#27867;&#21270;&#20934;&#30830;&#24615;&#30340;&#22823;&#24133;&#25552;&#21319;&#24182;&#19981;&#19968;&#23450;&#24847;&#21619;&#30528;&#20174;&#8220;&#35760;&#24518;&#8221;&#21040;&#8220;&#29702;&#35299;&#8221;&#30340;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#24735;&#26159;&#19968;&#20010;&#26377;&#36259;&#30340;&#29616;&#35937;&#65292;&#25351;&#30340;&#26159;&#27169;&#22411;&#22312;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#21518;&#20173;&#33021;&#27867;&#21270;&#12290;&#25105;&#20204;&#36890;&#36807;&#35299;&#26512;&#21644;&#25968;&#20540;&#26041;&#27861;&#34920;&#26126;&#65292;&#21363;&#20351;&#22312;&#31616;&#21333;&#30340;&#24072;&#29983;&#35774;&#32622;&#20013;&#65292;&#20855;&#26377;&#39640;&#26031;&#36755;&#20837;&#30340;&#32447;&#24615;&#32593;&#32476;&#25191;&#34892;&#32447;&#24615;&#20219;&#21153;&#26102;&#65292;&#39046;&#24735;&#20063;&#20250;&#20986;&#29616;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#23436;&#25972;&#30340;&#35757;&#32451;&#21160;&#21147;&#23398;&#65292;&#20197;&#35757;&#32451;&#21644;&#27867;&#21270;&#25968;&#25454;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#39046;&#24735;&#26102;&#38388;&#22914;&#20309;&#21462;&#20915;&#20110;&#36755;&#20837;&#21644;&#36755;&#20986;&#32500;&#24230;&#65292;&#35757;&#32451;&#26679;&#26412;&#37327;&#65292;&#27491;&#21017;&#21270;&#21644;&#32593;&#32476;&#21021;&#22987;&#21270;&#30340;&#31934;&#30830;&#39044;&#27979;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#27867;&#21270;&#20934;&#30830;&#24615;&#30340;&#24613;&#21095;&#22686;&#21152;&#21487;&#33021;&#24182;&#19981;&#24847;&#21619;&#30528;&#20174;&#8220;&#35760;&#24518;&#8221;&#21040;&#8220;&#29702;&#35299;&#8221;&#30340;&#36716;&#21464;&#65292;&#32780;&#21482;&#26159;&#20934;&#30830;&#24615;&#24230;&#37327;&#30340;&#20135;&#29289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#25105;&#20204;&#35745;&#31639;&#30340;&#32463;&#39564;&#35777;&#23454;&#65292;&#24182;&#21021;&#27493;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#26576;&#20123;&#39044;&#27979;&#20063;&#36866;&#29992;&#20110;&#20855;&#26377;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#26356;&#28145;&#23618;&#27425;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Grokking is the intriguing phenomenon where a model learns to generalize long after it has fit the training data. We show both analytically and numerically that grokking can surprisingly occur in linear networks performing linear tasks in a simple teacher-student setup with Gaussian inputs. In this setting, the full training dynamics is derived in terms of the training and generalization data covariance matrix. We present exact predictions on how the grokking time depends on input and output dimensionality, train sample size, regularization, and network initialization. We demonstrate that the sharp increase in generalization accuracy may not imply a transition from "memorization" to "understanding", but can simply be an artifact of the accuracy measure. We provide empirical verification for our calculations, along with preliminary results indicating that some predictions also hold for deeper networks, with non-linear activations.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;AlphaZero&#20013;&#25552;&#21462;&#26032;&#30340;&#22269;&#38469;&#35937;&#26827;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#36825;&#20123;&#27010;&#24565;&#21487;&#20197;&#34987;&#39030;&#32423;&#22269;&#38469;&#35937;&#26827;&#22823;&#24072;&#25152;&#23398;&#20064;&#21644;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.16410</link><description>&lt;p&gt;
&#24357;&#21512;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#30693;&#35782;&#30340;&#24046;&#36317;&#65306;&#22312;AlphaZero&#20013;&#36827;&#34892;&#27010;&#24565;&#21457;&#29616;&#21644;&#20256;&#36882;
&lt;/p&gt;
&lt;p&gt;
Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in AlphaZero. (arXiv:2310.16410v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;AlphaZero&#20013;&#25552;&#21462;&#26032;&#30340;&#22269;&#38469;&#35937;&#26827;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#36825;&#20123;&#27010;&#24565;&#21487;&#20197;&#34987;&#39030;&#32423;&#22269;&#38469;&#35937;&#26827;&#22823;&#24072;&#25152;&#23398;&#20064;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#36229;&#20154;&#31867;&#27700;&#24179;&#30340;&#34920;&#29616;&#65292;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#36827;&#19968;&#27493;&#25552;&#21319;&#20154;&#31867;&#30693;&#35782;&#21644;&#25552;&#39640;&#20154;&#31867;&#19987;&#23478;&#34920;&#29616;&#30340;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#39640;&#25928;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#25152;&#21253;&#21547;&#30340;&#30693;&#35782;&#24448;&#24448;&#38590;&#20197;&#25552;&#21462;&#65292;&#20063;&#21487;&#33021;&#38590;&#20197;&#29702;&#35299;&#25110;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;AlphaZero&#20013;&#25552;&#21462;&#26032;&#30340;&#22269;&#38469;&#35937;&#26827;&#27010;&#24565;&#65292;AlphaZero&#26159;&#19968;&#20010;&#36890;&#36807;&#33258;&#25105;&#23545;&#24328;&#32780;&#25484;&#25569;&#22269;&#38469;&#35937;&#26827;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;AlphaZero&#21487;&#33021;&#32534;&#30721;&#20102;&#36229;&#36234;&#29616;&#26377;&#20154;&#31867;&#30693;&#35782;&#30340;&#30693;&#35782;&#65292;&#20294;&#36825;&#20123;&#30693;&#35782;&#26368;&#32456;&#24182;&#19981;&#36229;&#20986;&#20154;&#31867;&#30340;&#29702;&#35299;&#33539;&#22260;&#65292;&#24182;&#19988;&#21487;&#20197;&#25104;&#21151;&#22320;&#23398;&#20064;&#12290;&#22312;&#20154;&#31867;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#27010;&#24565;&#26159;&#21487;&#20197;&#34987;&#39030;&#32423;&#22269;&#38469;&#35937;&#26827;&#22823;&#24072;&#25152;&#23398;&#20064;&#30340;&#65292;&#22240;&#20026;&#22235;&#21517;&#39030;&#32423;&#22269;&#38469;&#35937;&#26827;&#22823;&#24072;&#22312;&#35299;&#20915;&#25152;&#21576;&#29616;&#30340;&#27010;&#24565;&#21407;&#22411;&#20301;&#32622;&#26102;&#26174;&#31034;&#20986;&#20102;&#36827;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence (AI) systems have made remarkable progress, attaining super-human performance across various domains. This presents us with an opportunity to further human knowledge and improve human expert performance by leveraging the hidden knowledge encoded within these highly performant AI systems. Yet, this knowledge is often hard to extract, and may be hard to understand or learn from. Here, we show that this is possible by proposing a new method that allows us to extract new chess concepts in AlphaZero, an AI system that mastered the game of chess via self-play without human supervision. Our analysis indicates that AlphaZero may encode knowledge that extends beyond the existing human knowledge, but knowledge that is ultimately not beyond human grasp, and can be successfully learned from. In a human study, we show that these concepts are learnable by top human experts, as four top chess grandmasters show improvements in solving the presented concept prototype positions. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#20811;&#25289;&#40664;&#27779;&#23572;&#24503;&#36317;&#31163;&#27491;&#21017;&#21270;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#38598;&#21644;&#35266;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#22797;&#26434;&#30456;&#20851;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#20004;&#27493;&#23398;&#20064;&#26041;&#27861;&#25552;&#39640;&#20102;&#20808;&#39564;&#24314;&#27169;&#30340;&#28789;&#27963;&#24615;&#21644;&#32858;&#21512;&#21518;&#39564;&#19982;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#23545;&#40784;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.16374</link><description>&lt;p&gt;
&#36890;&#36807;&#20811;&#25289;&#40664;&#27779;&#23572;&#24503;&#36317;&#31163;&#36827;&#34892;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Joint Distributional Learning via Cramer-Wold Distance. (arXiv:2310.16374v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16374
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#20811;&#25289;&#40664;&#27779;&#23572;&#24503;&#36317;&#31163;&#27491;&#21017;&#21270;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#38598;&#21644;&#35266;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#22797;&#26434;&#30456;&#20851;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#20004;&#27493;&#23398;&#20064;&#26041;&#27861;&#25552;&#39640;&#20102;&#20808;&#39564;&#24314;&#27169;&#30340;&#28789;&#27963;&#24615;&#21644;&#32858;&#21512;&#21518;&#39564;&#19982;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#23545;&#40784;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#38598;&#25110;&#35266;&#27979;&#21464;&#37327;&#20043;&#38388;&#22797;&#26434;&#30456;&#20851;&#32467;&#26500;&#26102;&#65292;&#22522;&#20110;&#26465;&#20214;&#29420;&#31435;&#24615;&#30340;&#20551;&#35774;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#35299;&#30721;&#22120;&#24314;&#27169;&#20013;&#20855;&#26377;&#23616;&#38480;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20811;&#25289;&#40664;&#27779;&#23572;&#24503;&#36317;&#31163;&#27491;&#21017;&#21270;&#65292;&#21487;&#20197;&#36890;&#36807;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#65292;&#20197;&#20419;&#36827;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20004;&#27493;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#28789;&#27963;&#30340;&#20808;&#39564;&#24314;&#27169;&#65292;&#24182;&#25552;&#39640;&#32858;&#21512;&#21518;&#39564;&#19982;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#23545;&#40784;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#23545;&#35813;&#31867;&#21035;&#20013;&#30340;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20102;&#21306;&#20998;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#22312;&#20855;&#26377;&#22810;&#20010;&#31867;&#21035;&#21464;&#37327;&#30340;&#39640;&#32500;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#32771;&#34385;&#21040;&#35768;&#22810;&#29616;&#26377;&#30340;&#25968;&#25454;&#38598;&#21644;&#25968;&#25454;&#31185;&#23398;&#24212;&#29992;&#28041;&#21450;&#27492;&#31867;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#26377;&#30528;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
The assumption of conditional independence among observed variables, primarily used in the Variational Autoencoder (VAE) decoder modeling, has limitations when dealing with high-dimensional datasets or complex correlation structures among observed variables. To address this issue, we introduced the Cramer-Wold distance regularization, which can be computed in a closed-form, to facilitate joint distributional learning for high-dimensional datasets. Additionally, we introduced a two-step learning method to enable flexible prior modeling and improve the alignment between the aggregated posterior and the prior distribution. Furthermore, we provide theoretical distinctions from existing methods within this category. To evaluate the synthetic data generation performance of our proposed approach, we conducted experiments on high-dimensional datasets with multiple categorical variables. Given that many readily available datasets and data science applications involve such datasets, our experime
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;SMURF-THP&#26041;&#27861;&#26469;&#23398;&#20064;Transformer Hawkes&#36807;&#31243;&#24182;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#23398;&#20064;&#21040;&#30340;&#20998;&#25968;&#20989;&#25968;&#65292;&#21487;&#20197;&#20174;&#39044;&#27979;&#20998;&#24067;&#20013;&#37319;&#26679;&#20107;&#20214;&#21040;&#36798;&#26102;&#38388;&#65292;&#24182;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#26469;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16336</link><description>&lt;p&gt;
SMURF-THP&#65306;&#22522;&#20110;&#20998;&#25968;&#21305;&#37197;&#30340;Transformer Hawkes&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
SMURF-THP: Score Matching-based UnceRtainty quantiFication for Transformer Hawkes Process. (arXiv:2310.16336v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16336
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;SMURF-THP&#26041;&#27861;&#26469;&#23398;&#20064;Transformer Hawkes&#36807;&#31243;&#24182;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#23398;&#20064;&#21040;&#30340;&#20998;&#25968;&#20989;&#25968;&#65292;&#21487;&#20197;&#20174;&#39044;&#27979;&#20998;&#24067;&#20013;&#37319;&#26679;&#20107;&#20214;&#21040;&#36798;&#26102;&#38388;&#65292;&#24182;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#26469;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer Hawkes&#36807;&#31243;&#27169;&#22411;&#22312;&#24314;&#27169;&#20107;&#20214;&#24207;&#21015;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#30340;&#35757;&#32451;&#26041;&#27861;&#37117;&#20381;&#36182;&#20110;&#26368;&#22823;&#21270;&#20107;&#20214;&#24207;&#21015;&#30340;&#20284;&#28982;&#24615;&#65292;&#36825;&#28041;&#21450;&#21040;&#19968;&#20123;&#38590;&#20197;&#35745;&#31639;&#30340;&#31215;&#20998;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#20026;&#27169;&#22411;&#39044;&#27979;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20363;&#22914;&#23545;&#39044;&#27979;&#20107;&#20214;&#21040;&#36798;&#26102;&#38388;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SMURF-THP&#65292;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;Transformer Hawkes&#36807;&#31243;&#24182;&#37327;&#21270;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SMURF-THP&#36890;&#36807;&#36991;&#20813;&#38590;&#20197;&#35745;&#31639;&#30340;&#31215;&#20998;&#65292;&#23398;&#20064;&#20107;&#20214;&#21040;&#36798;&#26102;&#38388;&#30340;&#20998;&#25968;&#20989;&#25968;&#12290;&#36890;&#36807;&#36825;&#26679;&#19968;&#20010;&#23398;&#20064;&#30340;&#20998;&#25968;&#20989;&#25968;&#65292;&#25105;&#20204;&#21487;&#20197;&#20174;&#39044;&#27979;&#20998;&#24067;&#20013;&#37319;&#26679;&#20107;&#20214;&#21040;&#36798;&#26102;&#38388;&#12290;&#36825;&#33258;&#28982;&#22320;&#36890;&#36807;&#35745;&#31639;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#23454;&#29616;&#20102;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#12290;&#25105;&#20204;&#22312;&#20107;&#20214;&#31867;&#22411;&#39044;&#27979;&#26041;&#38754;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer Hawkes process models have shown to be successful in modeling event sequence data. However, most of the existing training methods rely on maximizing the likelihood of event sequences, which involves calculating some intractable integral. Moreover, the existing methods fail to provide uncertainty quantification for model predictions, e.g., confidence intervals for the predicted event's arrival time. To address these issues, we propose SMURF-THP, a score-based method for learning Transformer Hawkes process and quantifying prediction uncertainty. Specifically, SMURF-THP learns the score function of events' arrival time based on a score-matching objective that avoids the intractable computation. With such a learned score function, we can sample arrival time of events from the predictive distribution. This naturally allows for the quantification of uncertainty by computing confidence intervals over the generated samples. We conduct extensive experiments in both event type predic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20010;&#24615;&#21270;&#30340;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;PF-PNE&#31639;&#27861;&#65292;&#36890;&#36807;&#21452;&#37325;&#28120;&#27760;&#31574;&#30053;&#21644;&#26377;&#25928;&#30340;&#26412;&#22320;&#30446;&#26631;&#35780;&#20272;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#21516;&#26102;&#20248;&#21270;&#24322;&#36136;&#26412;&#22320;&#30446;&#26631;&#21644;&#40723;&#21169;&#32852;&#37030;&#21512;&#20316;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#22522;&#32447;&#31639;&#27861;&#21644;&#23454;&#39564;&#25968;&#25454;&#38598;&#19978;&#37117;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.16323</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Personalized Federated X -armed Bandit. (arXiv:2310.16323v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16323
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20010;&#24615;&#21270;&#30340;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;PF-PNE&#31639;&#27861;&#65292;&#36890;&#36807;&#21452;&#37325;&#28120;&#27760;&#31574;&#30053;&#21644;&#26377;&#25928;&#30340;&#26412;&#22320;&#30446;&#26631;&#35780;&#20272;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#21516;&#26102;&#20248;&#21270;&#24322;&#36136;&#26412;&#22320;&#30446;&#26631;&#21644;&#40723;&#21169;&#32852;&#37030;&#21512;&#20316;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#22522;&#32447;&#31639;&#27861;&#21644;&#23454;&#39564;&#25968;&#25454;&#38598;&#19978;&#37117;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#30340;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#22312;&#32852;&#37030;&#23398;&#20064;&#33539;&#24335;&#20013;&#21516;&#26102;&#20248;&#21270;&#20102;&#23458;&#25143;&#31471;&#30340;&#24322;&#36136;&#26412;&#22320;&#30446;&#26631;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#29420;&#29305;&#21452;&#37325;&#28120;&#27760;&#31574;&#30053;&#30340;PF-PNE&#31639;&#27861;&#65292;&#36890;&#36807;&#20559;&#24046;&#20294;&#26377;&#25928;&#30340;&#26412;&#22320;&#30446;&#26631;&#35780;&#20272;&#65292;&#23433;&#20840;&#22320;&#28040;&#38500;&#38750;&#26368;&#20248;&#21306;&#22495;&#21516;&#26102;&#40723;&#21169;&#32852;&#37030;&#21512;&#20316;&#12290;&#25152;&#25552;&#20986;&#30340;PF-PNE&#31639;&#27861;&#33021;&#22815;&#20248;&#21270;&#20855;&#26377;&#20219;&#24847;&#24322;&#36136;&#24615;&#27700;&#24179;&#30340;&#26412;&#22320;&#30446;&#26631;&#65292;&#24182;&#19988;&#20854;&#26377;&#38480;&#36890;&#20449;&#20445;&#25252;&#20102;&#23458;&#25143;&#31471;&#22870;&#21169;&#25968;&#25454;&#30340;&#26426;&#23494;&#24615;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#21333;&#23458;&#25143;&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;PF-PNE&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#37117;&#20248;&#20110;&#22810;&#20010;&#22522;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study the personalized federated $\mathcal{X}$-armed bandit problem, where the heterogeneous local objectives of the clients are optimized simultaneously in the federated learning paradigm. We propose the \texttt{PF-PNE} algorithm with a unique double elimination strategy, which safely eliminates the non-optimal regions while encouraging federated collaboration through biased but effective evaluations of the local objectives. The proposed \texttt{PF-PNE} algorithm is able to optimize local objectives with arbitrary levels of heterogeneity, and its limited communications protects the confidentiality of the client-wise reward data. Our theoretical analysis shows the benefit of the proposed algorithm over single-client algorithms. Experimentally, \texttt{PF-PNE} outperforms multiple baselines on both synthetic and real life datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20302;&#31934;&#24230;&#21644;&#20840;&#31934;&#24230;&#26799;&#24230;&#32047;&#21152;&#22120;&#30340;&#38543;&#26426;&#26799;&#24230;Hamiltonian Monte Carlo (SGHMC)&#22312;&#20302;&#31934;&#24230;&#37319;&#26679;&#20013;&#30340;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#65292;&#20302;&#31934;&#24230;SGHMC&#30456;&#23545;&#20110;&#20302;&#31934;&#24230;&#37319;&#26679;&#22120;&#65288;SGLD&#65289;&#23454;&#29616;&#20102;&#20108;&#27425;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2310.16320</link><description>&lt;p&gt;
&#22686;&#24378;&#20302;&#31934;&#24230;&#37319;&#26679;&#65306;&#38543;&#26426;&#26799;&#24230;Hamiltonian Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Enhancing Low-Precision Sampling via Stochastic Gradient Hamiltonian Monte Carlo. (arXiv:2310.16320v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20302;&#31934;&#24230;&#21644;&#20840;&#31934;&#24230;&#26799;&#24230;&#32047;&#21152;&#22120;&#30340;&#38543;&#26426;&#26799;&#24230;Hamiltonian Monte Carlo (SGHMC)&#22312;&#20302;&#31934;&#24230;&#37319;&#26679;&#20013;&#30340;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#65292;&#20302;&#31934;&#24230;SGHMC&#30456;&#23545;&#20110;&#20302;&#31934;&#24230;&#37319;&#26679;&#22120;&#65288;SGLD&#65289;&#23454;&#29616;&#20102;&#20108;&#27425;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31934;&#24230;&#35757;&#32451;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#20302;&#25104;&#26412;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#19981;&#29306;&#29298;&#22826;&#22810;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290;&#20854;&#36125;&#21494;&#26031;&#23545;&#24212;&#29289;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#25913;&#36827;&#30340;&#27867;&#21270;&#20934;&#30830;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#23545;&#25968;&#20985;&#21644;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#65292;&#20351;&#29992;&#20302;&#31934;&#24230;&#21644;&#20840;&#31934;&#24230;&#26799;&#24230;&#32047;&#21152;&#22120;&#30340;&#38543;&#26426;&#26799;&#24230;Hamiltonian Monte Carlo (SGHMC)&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#22312;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#23454;&#29616;2-Wasserstein&#36317;&#31163;&#30340;&#949;&#35823;&#24046;&#65292;&#20302;&#31934;&#24230;SGHMC&#30456;&#23545;&#20110;&#20302;&#31934;&#24230;&#37319;&#26679;&#22120;&#65288;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#65292;SGLD&#65289;&#23454;&#29616;&#20102;&#20108;&#27425;&#25913;&#36827;&#65288;$\widetilde{\mathbf{O}}\left({\epsilon^{-2}{\mu^*}^{-2}\log^2\left({\epsilon^{-1}}\right)}\right)$ vs $\widetilde{\mathbf{O}}\left({{\epsilon}^{-4}{\lambda^{*}}^{-1}\log^5\left({\epsilon^{-1}}\right)}\right)$&#65289;&#12290;&#21478;&#22806;&#65292;&#22522;&#20110;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#20302;&#31934;&#24230;SGHMC&#30456;&#23545;&#20110;SGLD&#22312;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-precision training has emerged as a promising low-cost technique to enhance the training efficiency of deep neural networks without sacrificing much accuracy. Its Bayesian counterpart can further provide uncertainty quantification and improved generalization accuracy. This paper investigates low-precision sampling via Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) with low-precision and full-precision gradient accumulators for both strongly log-concave and non-log-concave distributions. Theoretically, our results show that, to achieve $\epsilon$-error in the 2-Wasserstein distance for non-log-concave distributions, low-precision SGHMC achieves quadratic improvement ($\widetilde{\mathbf{O}}\left({\epsilon^{-2}{\mu^*}^{-2}\log^2\left({\epsilon^{-1}}\right)}\right)$) compared to the state-of-the-art low-precision sampler, Stochastic Gradient Langevin Dynamics (SGLD) ($\widetilde{\mathbf{O}}\left({{\epsilon}^{-4}{\lambda^{*}}^{-1}\log^5\left({\epsilon^{-1}}\right)}\right)$). Moreo
&lt;/p&gt;</description></item><item><title>&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16221</link><description>&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16221
&lt;/p&gt;
&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#26159;&#22797;&#26434;&#30340;&#65292;&#36890;&#24120;&#30001;&#21487;&#20998;&#35299;&#20026;&#22810;&#20010;&#23454;&#20307;&#30340;&#23545;&#35937;&#32452;&#25104;&#65288;&#20363;&#22914;&#65292;&#23558;&#22270;&#20687;&#20998;&#35299;&#20026;&#20687;&#32032;&#65292;&#23558;&#22270;&#24418;&#20998;&#35299;&#20026;&#30456;&#20114;&#36830;&#25509;&#30340;&#33410;&#28857;&#65289;&#12290;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#27169;&#22411;&#22312;&#20854;&#36755;&#20837;&#30340;&#24494;&#23567;&#21464;&#21270;&#19978;&#20855;&#26377;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;-&#36890;&#36807;&#22312;&#20998;&#31867;&#20043;&#21069;&#38543;&#26426;&#28155;&#21152;&#22122;&#22768;&#26469;&#20445;&#35777;&#22810;&#25968;&#25237;&#31080;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#23545;&#25163;&#19981;&#26159;&#20219;&#24847;&#24178;&#25200;&#25972;&#20010;&#23545;&#35937;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#65292;&#32780;&#26159;&#23545;&#35937;&#30340;&#26576;&#20010;&#23454;&#20307;&#30340;&#23376;&#38598;&#65288;&#20363;&#22914;&#20687;&#32032;&#65289;&#26102;&#65292;&#36890;&#36807;&#38543;&#26426;&#24179;&#28369;&#23545;&#36825;&#31181;&#22797;&#26434;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#65306;&#25105;&#20204;&#36890;&#36807;&#20165;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#23454;&#20307;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#26469;&#37096;&#20998;&#24179;&#28369;&#23545;&#35937;&#12290;&#36890;&#36807;&#20197;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#28155;&#21152;&#22122;&#22768;&#65292;&#25105;&#20204;&#33719;&#24471;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#22122;&#22768;&#20998;&#24067;&#21021;&#22987;&#21270;&#20998;&#23618;&#24179;&#28369;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#22343;&#34913;&#31574;&#30053;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#19979;&#25991;&#24378;&#30423;&#30340;&#31639;&#27861;&#26469;&#35780;&#20272;&#21644;&#25913;&#36827;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#65292;&#36825;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#30740;&#31350;&#20013;&#24471;&#21040;&#20102;&#26377;&#21033;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.16096</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#24378;&#30423;&#29992;&#20110;&#35780;&#20272;&#21644;&#25913;&#36827;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Contextual Bandits for Evaluating and Improving Inventory Control Policies. (arXiv:2310.16096v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16096
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#22343;&#34913;&#31574;&#30053;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#19979;&#25991;&#24378;&#30423;&#30340;&#31639;&#27861;&#26469;&#35780;&#20272;&#21644;&#25913;&#36827;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#65292;&#36825;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#30740;&#31350;&#20013;&#24471;&#21040;&#20102;&#26377;&#21033;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#36890;&#24120;&#28041;&#21450;&#23545;&#38750;&#24179;&#31283;&#38543;&#26426;&#38656;&#27714;&#12289;&#22833;&#21435;&#38144;&#21806;&#21644;&#20855;&#26377;&#38543;&#26426;&#20379;&#24212;&#21830;&#20132;&#36135;&#26102;&#38388;&#30340;&#21608;&#26399;&#24615;&#26816;&#26597;&#30340;&#21160;&#21147;&#23398;&#36827;&#34892;&#24378;&#20551;&#35774;&#30340;&#36924;&#36817;&#25110;&#27169;&#25311;&#65292;&#24182;&#24212;&#29992;&#20248;&#21270;&#12289;&#21160;&#24577;&#35268;&#21010;&#25110;&#24378;&#21270;&#23398;&#20064;&#31561;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#20998;&#26512;&#21644;&#35780;&#20272;&#20219;&#20309;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#26159;&#37325;&#35201;&#30340;&#65292;&#29305;&#21035;&#26159;&#30475;&#26159;&#21542;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22343;&#34913;&#31574;&#30053;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#19968;&#20010;&#31574;&#30053;&#30340;&#29702;&#24819;&#29305;&#24615;&#65292;&#30452;&#35266;&#22320;&#24847;&#21619;&#30528;&#20107;&#21518;&#21482;&#25913;&#21464;&#23569;&#37096;&#20998;&#25805;&#20316;&#19981;&#20250;&#20135;&#29983;&#23454;&#36136;&#19978;&#26356;&#22810;&#30340;&#22238;&#25253;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#24378;&#30423;&#31639;&#27861;&#26469;&#35780;&#20272;&#21644;&#20598;&#23572;&#24494;&#35843;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#30740;&#31350;&#20013;&#22343;&#21462;&#24471;&#20102;&#26377;&#21033;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solutions to address the periodic review inventory control problem with nonstationary random demand, lost sales, and stochastic vendor lead times typically involve making strong assumptions on the dynamics for either approximation or simulation, and applying methods such as optimization, dynamic programming, or reinforcement learning. Therefore, it is important to analyze and evaluate any inventory control policy, in particular to see if there is room for improvement. We introduce the concept of an equilibrium policy, a desirable property of a policy that intuitively means that, in hindsight, changing only a small fraction of actions does not result in materially more reward. We provide a light-weight contextual bandit-based algorithm to evaluate and occasionally tweak policies, and show that this method achieves favorable guarantees, both theoretically and in empirical studies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#39640;&#32500;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.15932</link><description>&lt;p&gt;
&#22312;&#32447;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Online Robust Mean Estimation. (arXiv:2310.15932v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15932
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#39640;&#32500;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#35774;&#32622;&#20013;&#39640;&#32500;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#22330;&#26223;&#65292;&#22312;&#36825;&#20010;&#22330;&#26223;&#20013;&#65292;n&#20010;&#20256;&#24863;&#22120;&#27491;&#22312;&#27979;&#37327;&#26576;&#20010;&#20849;&#21516;&#30340;&#25345;&#32493;&#29616;&#35937;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;t=1,2,...,T&#65292;&#31532;i&#20010;&#20256;&#24863;&#22120;&#25253;&#21578;&#20854;&#22312;&#35813;&#26102;&#38388;&#27493;&#30340;&#35835;&#25968;x^(i)_t&#12290;&#28982;&#21518;&#65292;&#31639;&#27861;&#24517;&#39035;&#23545;&#35813;&#26102;&#21051;&#30340;&#30495;&#23454;&#22343;&#20540;&#956;_t&#36827;&#34892;&#20272;&#35745;&#12290;&#25105;&#20204;&#20551;&#35774;&#22823;&#37096;&#20998;&#20256;&#24863;&#22120;&#35266;&#27979;&#21040;&#20102;&#26469;&#33258;&#26576;&#20010;&#20844;&#20849;&#20998;&#24067;X&#30340;&#29420;&#31435;&#26679;&#26412;&#65292;&#20294;&#26159;&#20854;&#20013;&#19968;&#20010;&#949;&#20998;&#25968;&#30340;&#20256;&#24863;&#22120;&#21487;&#33021;&#34920;&#29616;&#20986;&#24694;&#24847;&#34892;&#20026;&#12290;&#31639;&#27861;&#24076;&#26395;&#35745;&#31639;&#20986;&#23545;&#30495;&#23454;&#22343;&#20540;&#956;*:=E[X]&#30340;&#33391;&#22909;&#36817;&#20284;&#20540;&#956;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#65292;&#22914;&#26524;&#20801;&#35768;&#31639;&#27861;&#31561;&#24453;&#21040;&#26102;&#38388;T&#25165;&#25253;&#21578;&#20854;&#20272;&#35745;&#20540;&#65292;&#37027;&#20040;&#36825;&#23601;&#21464;&#25104;&#20102;&#19968;&#20010;&#24050;&#32463;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#35201;&#27714;&#22312;&#25968;&#25454;&#36827;&#26469;&#26102;&#29983;&#25104;&#37096;&#20998;&#20272;&#35745;&#20540;&#65292;&#36825;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20351;&#24773;&#20917;&#21464;&#24471;&#22797;&#26434;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20851;&#20110;&#36825;&#20010;&#38382;&#39064;&#30340;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of high-dimensional robust mean estimation in an online setting. Specifically, we consider a scenario where $n$ sensors are measuring some common, ongoing phenomenon. At each time step $t=1,2,\ldots,T$, the $i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step. The algorithm must then commit to its estimate $\mu_t$ for the true mean value of the process at time $t$. We assume that most of the sensors observe independent samples from some common distribution $X$, but an $\epsilon$-fraction of them may instead behave maliciously. The algorithm wishes to compute a good approximation $\mu$ to the true mean $\mu^\ast := \mathbf{E}[X]$. We note that if the algorithm is allowed to wait until time $T$ to report its estimate, this reduces to the well-studied problem of robust mean estimation. However, the requirement that our algorithm produces partial estimates as the data is coming in substantially complicates the situation.  We prove two main results about 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#33021;&#22815;&#21516;&#26102;&#36827;&#34892;&#26368;&#20248;&#25506;&#32034;&#21644;&#21482;&#38656;&#35201;&#30456;&#21516;&#35745;&#31639;&#25805;&#20316;&#30340;&#31639;&#27861;&#65311;</title><link>http://arxiv.org/abs/2310.06069</link><description>&lt;p&gt;
&#26368;&#20248;&#25506;&#32034;&#19981;&#27604;&#27748;&#26222;&#26862;&#37319;&#26679;&#26356;&#22256;&#38590;
&lt;/p&gt;
&lt;p&gt;
Optimal Exploration is no harder than Thompson Sampling. (arXiv:2310.06069v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06069
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#33021;&#22815;&#21516;&#26102;&#36827;&#34892;&#26368;&#20248;&#25506;&#32034;&#21644;&#21482;&#38656;&#35201;&#30456;&#21516;&#35745;&#31639;&#25805;&#20316;&#30340;&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32473;&#23450;&#19968;&#32452;&#33218;$\mathcal{Z}\subset \mathbb{R}^d$&#21644;&#26410;&#30693;&#21442;&#25968;&#21521;&#37327;$\theta_\ast\in\mathbb{R}^d$&#30340;&#24773;&#20917;&#19979;&#65292;&#32431;&#25506;&#32034;&#32447;&#24615;&#33218;&#38382;&#39064;&#26088;&#22312;&#36890;&#36807;&#23545;$x^{\top}\theta_{\ast}$&#30340;&#22122;&#22768;&#27979;&#37327;&#65292;&#36820;&#22238;$\arg\max_{z\in \mathcal{Z}} z^{\top}\theta_{\ast}$&#65292;&#24182;&#20197;&#39640;&#27010;&#29575;&#25214;&#21040;&#27491;&#30830;&#35299;&#12290;&#29616;&#26377;&#30340;&#65288;&#28176;&#36817;&#65289;&#26368;&#20248;&#26041;&#27861;&#35201;&#27714;&#35201;&#20040;&#20026;&#27599;&#20010;&#33218;$z\in \mathcal{Z}$&#36827;&#34892;&#28508;&#22312;&#26114;&#36149;&#30340;&#25237;&#24433;&#65292;&#35201;&#20040;&#22312;&#27599;&#20010;&#26102;&#38388;&#28857;&#26126;&#30830;&#22320;&#32500;&#25252;&#19968;&#37096;&#20998;&#27491;&#22312;&#32771;&#34385;&#30340;$\mathcal{Z}$&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#19982;&#27969;&#34892;&#19988;&#31616;&#21333;&#30340;&#27748;&#26222;&#26862;&#37319;&#26679;&#31639;&#27861;&#29992;&#20110;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#24773;&#20917;&#23436;&#20840;&#30456;&#21453;&#65292;&#21518;&#32773;&#21482;&#38656;&#35201;&#35775;&#38382;&#21518;&#39564;&#37319;&#26679;&#21644;argmax oracle&#65292;&#24182;&#19988;&#22312;&#20219;&#20309;&#26102;&#38388;&#28857;&#37117;&#19981;&#38656;&#35201;&#26522;&#20030;$\mathcal{Z}$&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24050;&#30693;&#27748;&#26222;&#26862;&#37319;&#26679;&#23545;&#20110;&#32431;&#25506;&#32034;&#26159;&#27425;&#20248;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#31639;&#27861;&#33021;&#22815;&#36827;&#34892;&#26368;&#20248;&#25506;&#32034;&#65292;&#32780;&#19988;&#21482;&#38656;&#35201;&#30456;&#21516;&#30340;&#35745;&#31639;&#25805;&#20316;&#65311;
&lt;/p&gt;
&lt;p&gt;
Given a set of arms $\mathcal{Z}\subset \mathbb{R}^d$ and an unknown parameter vector $\theta_\ast\in\mathbb{R}^d$, the pure exploration linear bandit problem aims to return $\arg\max_{z\in \mathcal{Z}} z^{\top}\theta_{\ast}$, with high probability through noisy measurements of $x^{\top}\theta_{\ast}$ with $x\in \mathcal{X}\subset \mathbb{R}^d$. Existing (asymptotically) optimal methods require either a) potentially costly projections for each arm $z\in \mathcal{Z}$ or b) explicitly maintaining a subset of $\mathcal{Z}$ under consideration at each time. This complexity is at odds with the popular and simple Thompson Sampling algorithm for regret minimization, which just requires access to a posterior sampling and argmax oracle, and does not need to enumerate $\mathcal{Z}$ at any point. Unfortunately, Thompson sampling is known to be sub-optimal for pure exploration. In this work, we pose a natural question: is there an algorithm that can explore optimally and only needs the same comput
&lt;/p&gt;</description></item><item><title>&#22312;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#19979;&#19981;&#22343;&#34913;&#25968;&#25454;&#30340;&#31070;&#32463;&#22604;&#32553;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2309.09725</link><description>&lt;p&gt;
&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#20013;&#30340;&#20132;&#21449;&#29109;&#25439;&#22833;&#19979;&#19981;&#21463;&#38480;&#30340;&#31070;&#32463;&#22604;&#32553;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Neural Collapse for Unconstrained Feature Model under Cross-entropy Loss with Imbalanced Data. (arXiv:2309.09725v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09725
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#19979;&#19981;&#22343;&#34913;&#25968;&#25454;&#30340;&#31070;&#32463;&#22604;&#32553;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#25991;&#26412;&#22788;&#29702;&#30340;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#20123;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;DNNs&#22312;&#35757;&#32451;&#30340;&#26411;&#26399;&#38454;&#27573;&#65288;TPT&#65289;&#30340;&#29305;&#24449;&#34920;&#31034;&#21644;&#26411;&#23618;&#20998;&#31867;&#22120;&#20855;&#26377;&#30456;&#20284;&#30340;&#32467;&#26500;&#29305;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22914;&#26524;&#35757;&#32451;&#25968;&#25454;&#26159;&#24179;&#34913;&#30340;&#65288;&#27599;&#20010;&#31867;&#21035;&#20855;&#26377;&#30456;&#21516;&#25968;&#37327;&#30340;&#26679;&#26412;&#65289;&#65292;&#35266;&#23519;&#21040;&#26469;&#33258;&#21516;&#19968;&#31867;&#21035;&#30340;&#26679;&#26412;&#30340;&#29305;&#24449;&#21521;&#37327;&#25910;&#25947;&#21040;&#30456;&#24212;&#30340;&#31867;&#20869;&#22343;&#20540;&#29305;&#24449;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#25104;&#23545;&#35282;&#24230;&#30456;&#21516;&#12290;&#36825;&#19968;&#36855;&#20154;&#30340;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#22604;&#32553;&#65288;NC&#65289;&#65292;&#30001;Papyan&#65292;Han&#21644;Donoho&#22312;2019&#24180;&#39318;&#27425;&#25552;&#20986;&#12290;&#26368;&#36817;&#30340;&#35768;&#22810;&#24037;&#20316;&#36890;&#36807;&#37319;&#29992;&#25152;&#35859;&#30340;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#65288;UFM&#65289;&#22312;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;&#36825;&#19968;&#29616;&#35937;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#24357;&#34917;&#20102;NC&#29616;&#35937;&#23545;&#19981;&#22343;&#34913;&#25968;&#25454;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#19979;&#30340;&#25299;&#23637;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;
&lt;/p&gt;
&lt;p&gt;
Recent years have witnessed the huge success of deep neural networks (DNNs) in various tasks of computer vision and text processing. Interestingly, these DNNs with massive number of parameters share similar structural properties on their feature representation and last-layer classifier at terminal phase of training (TPT). Specifically, if the training data are balanced (each class shares the same number of samples), it is observed that the feature vectors of samples from the same class converge to their corresponding in-class mean features and their pairwise angles are the same. This fascinating phenomenon is known as Neural Collapse (N C), first termed by Papyan, Han, and Donoho in 2019. Many recent works manage to theoretically explain this phenomenon by adopting so-called unconstrained feature model (UFM). In this paper, we study the extension of N C phenomenon to the imbalanced data under cross-entropy loss function in the context of unconstrained feature model. Our contribution is
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.06399</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#23398;&#20064;&#20855;&#26377;&#24322;&#26500;&#20892;&#19994;&#25968;&#25454;&#38598;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering. (arXiv:2308.06399v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28041;&#21450;&#22810;&#26679;&#20294;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#20013;&#65292;&#20854;&#20013;&#21327;&#21464;&#37327;&#19982;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#32852;&#21487;&#33021;&#20250;&#26377;&#25152;&#19981;&#21516;&#65292;&#22312;&#21253;&#25324;&#20892;&#23398;&#30740;&#31350;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#37117;&#24456;&#26222;&#36941;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24120;&#24120;&#20351;&#29992;&#23618;&#27425;&#27169;&#22411;&#65292;&#20063;&#34987;&#31216;&#20026;&#22810;&#23618;&#27169;&#22411;&#65292;&#26469;&#34701;&#21512;&#26469;&#33258;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;&#24182;&#36866;&#24212;&#23427;&#20204;&#30340;&#19981;&#21516;&#29305;&#28857;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#32467;&#26500;&#36229;&#20986;&#20102;&#31616;&#21333;&#30340;&#24322;&#36136;&#24615;&#65292;&#22240;&#20026;&#21464;&#37327;&#36890;&#24120;&#24418;&#25104;&#22797;&#26434;&#30340;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#12290;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BNs&#65289;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#26469;&#27169;&#25311;&#36825;&#31181;&#20851;&#31995;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38543;&#26426;&#25928;&#24212;&#25972;&#21512;&#21040;BN&#23398;&#20064;&#20013;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22788;&#29702;&#23618;&#27425;&#25968;&#25454;&#12290;&#26469;&#33258;&#30495;&#23454;&#20892;&#23398;&#35797;&#39564;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#37319;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22686;&#24378;&#32467;&#26500;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.  Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#20248;&#21270;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz&#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#36827;&#34892;&#20102;&#35299;&#20915;&#12290;&#26174;&#24335;&#20248;&#21270;&#21644;&#38544;&#24335;&#20248;&#21270;&#26159;&#20004;&#31181;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#30340;&#19981;&#21516;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2306.09338</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#20248;&#21270;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Understanding Optimization of Deep Learning. (arXiv:2306.09338v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09338
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#20248;&#21270;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz&#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#36827;&#34892;&#20102;&#35299;&#20915;&#12290;&#26174;&#24335;&#20248;&#21270;&#21644;&#38544;&#24335;&#20248;&#21270;&#26159;&#20004;&#31181;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#30340;&#19981;&#21516;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#20248;&#21270;&#29702;&#35770;&#65292;&#20027;&#35201;&#20851;&#27880;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#38382;&#39064;&#25152;&#24102;&#26469;&#30340;&#27169;&#22411;&#34920;&#31034;&#33021;&#21147;&#38477;&#20302;&#21644;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#31561;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz &#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#26469;&#20998;&#26512;&#36825;&#20004;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#24110;&#21161;&#29702;&#35299;&#24403;&#21069;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#20854;&#20998;&#20026;&#26174;&#24335;&#20248;&#21270;&#26041;&#27861;&#21644;&#38544;&#24335;&#20248;&#21270;&#26041;&#27861;&#12290;&#26174;&#24335;&#20248;&#21270;&#26041;&#27861;&#28041;&#21450;&#30452;&#25509;&#25805;&#20316;&#20248;&#21270;&#22120;&#21442;&#25968;&#65292;&#21253;&#25324;&#26435;&#37325;&#12289;&#26799;&#24230;&#12289;&#23398;&#20064;&#29575;&#21644;&#26435;&#37325;&#34928;&#20943;&#31561;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38544;&#24335;&#20248;&#21270;&#26041;&#27861;&#20391;&#37325;&#20110;&#36890;&#36807;&#22686;&#24378;&#32593;&#32476;&#27169;&#22359;&#65288;&#22914;&#27531;&#24046;&#24555;&#25463;&#26041;&#24335;&#12289;&#26631;&#20934;&#21270;&#26041;&#27861;&#12289;&#27880;&#24847;&#26426;&#21046;&#21644;&#28608;&#27963;&#65289;&#26469;&#25913;&#21892;&#32593;&#32476;&#25972;&#20307;&#24418;&#21183;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#21644;&#23454;&#39564;&#65292;&#20197;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#26356;&#22909;&#22320;&#20102;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article provides a comprehensive understanding of optimization in deep learning, with a primary focus on the challenges of gradient vanishing and gradient exploding, which normally lead to diminished model representational ability and training instability, respectively. We analyze these two challenges through several strategic measures, including the improvement of gradient flow and the imposition of constraints on a network's Lipschitz constant. To help understand the current optimization methodologies, we categorize them into two classes: explicit optimization and implicit optimization. Explicit optimization methods involve direct manipulation of optimizer parameters, including weight, gradient, learning rate, and weight decay. Implicit optimization methods, by contrast, focus on improving the overall landscape of a network by enhancing its modules, such as residual shortcuts, normalization methods, attention mechanisms, and activations. In this article, we provide an in-depth a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36870;&#38382;&#39064;&#30340;&#30452;&#25509;&#25193;&#25955;&#38142;&#26725;&#31639;&#27861;&#65292;&#25552;&#39640;&#20102;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#25968;&#25454;&#19968;&#33268;&#24615;&#35299;&#20915;&#20102;&#24403;&#21069;DDB&#26694;&#26550;&#23384;&#22312;&#30340;&#20851;&#38190;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.19809</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#19968;&#33268;&#24615;&#30340;&#30452;&#25509;&#25193;&#25955;&#38142;&#26725;&#35299;&#20915;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Direct Diffusion Bridge using Data Consistency for Inverse Problems. (arXiv:2305.19809v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36870;&#38382;&#39064;&#30340;&#30452;&#25509;&#25193;&#25955;&#38142;&#26725;&#31639;&#27861;&#65292;&#25552;&#39640;&#20102;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#25968;&#25454;&#19968;&#33268;&#24615;&#35299;&#20915;&#20102;&#24403;&#21069;DDB&#26694;&#26550;&#23384;&#22312;&#30340;&#20851;&#38190;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#34920;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#20294;&#36895;&#24230;&#21463;&#38480;&#65292;&#20027;&#35201;&#26159;&#22240;&#20026;&#38656;&#35201;&#20174;&#22122;&#22768;&#24320;&#22987;&#36827;&#34892;&#21453;&#21521;&#25193;&#25955;&#37319;&#26679;&#12290;&#36817;&#26399;&#30340;&#19968;&#20123;&#24037;&#20316;&#23581;&#35797;&#36890;&#36807;&#26500;&#24314;&#25193;&#25955;&#36807;&#31243;&#26469;&#30452;&#25509;&#26725;&#25509;&#29305;&#23450;&#36870;&#38382;&#39064;&#30340;&#28165;&#27905;&#21644;&#27745;&#26579;&#25968;&#25454;&#20197;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#36825;&#20123;&#29616;&#26377;&#24037;&#20316;&#32479;&#19968;&#21629;&#21517;&#20026;&#30452;&#25509;&#25193;&#25955;&#38142;&#26725;&#65288;DDB&#65289;&#65292;&#35777;&#26126;&#23613;&#31649;&#21463;&#19981;&#21516;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#20294;&#30001;&#27492;&#20135;&#29983;&#30340;&#31639;&#27861;&#22312;&#21442;&#25968;&#36873;&#25321;&#19978;&#30340;&#19981;&#21516;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24378;&#35843;&#24403;&#21069;DDB&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#38480;&#21046;&#65292;&#21363;&#23427;&#19981;&#33021;&#20445;&#35777;&#25968;&#25454;&#19968;&#33268;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#23427;&#22312;&#19981;&#38656;&#35201;&#31934;&#32454;&#35843;&#25972;&#30340;&#24773;&#20917;&#19979;&#24378;&#21046;&#25968;&#25454;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#23558;&#24471;&#21040;&#30340;&#26041;&#27861;&#31216;&#20026;&#25968;&#25454;&#19968;&#33268;&#30340;DDB&#65288;CDDB&#65289;&#65292;&#23427;&#22312;&#24863;&#30693;&#21644;&#22833;&#30495;&#25351;&#26631;&#26041;&#38754;&#37117;&#20248;&#20110;&#19981;&#19968;&#33268;&#30340;&#23545;&#24212;&#29289;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#25512;&#21160;&#20102;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion model-based inverse problem solvers have shown impressive performance, but are limited in speed, mostly as they require reverse diffusion sampling starting from noise. Several recent works have tried to alleviate this problem by building a diffusion process, directly bridging the clean and the corrupted for specific inverse problems. In this paper, we first unify these existing works under the name Direct Diffusion Bridges (DDB), showing that while motivated by different theories, the resulting algorithms only differ in the choice of parameters. Then, we highlight a critical limitation of the current DDB framework, namely that it does not ensure data consistency. To address this problem, we propose a modified inference procedure that imposes data consistency without the need for fine-tuning. We term the resulting method data Consistent DDB (CDDB), which outperforms its inconsistent counterpart in terms of both perception and distortion metrics, thereby effectively pushing the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;Maximize to Explore (MEX)&#65292;&#21482;&#38656;&#20248;&#21270;&#19968;&#20010;&#26080;&#32422;&#26463;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#33258;&#21160;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#23454;&#29616;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2305.18258</link><description>&lt;p&gt;
&#19968;&#31181;&#34701;&#21512;&#20272;&#35745;&#21644;&#35268;&#21010;&#23454;&#29616;&#25506;&#32034;&#30340;&#26368;&#22823;&#21270;&#30446;&#26631;&#20989;&#25968;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
One Objective to Rule Them All: A Maximization Objective Fusing Estimation and Planning for Exploration. (arXiv:2305.18258v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18258
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;Maximize to Explore (MEX)&#65292;&#21482;&#38656;&#20248;&#21270;&#19968;&#20010;&#26080;&#32422;&#26463;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#33258;&#21160;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#23454;&#29616;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#23545;&#20110;&#20197;&#26377;&#25928;&#30340;&#26041;&#24335;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#29616;&#26377;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#21253;&#25324;&#19977;&#20010;&#32452;&#25104;&#37096;&#20998;&#65306;&#20272;&#35745;&#12289;&#35268;&#21010;&#21644;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#24212;&#23545;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#37117;&#38656;&#35201;&#20351;&#29992;&#19981;&#20999;&#23454;&#38469;&#30340;&#31639;&#27861;&#32452;&#20214;&#26469;&#28608;&#21169;&#25506;&#32034;&#65292;&#20363;&#22914;&#25968;&#25454;&#30456;&#20851;&#30340;&#32423;&#21035;&#38598;&#20869;&#20248;&#21270;&#25110;&#32321;&#29712;&#30340;&#37319;&#26679;&#36807;&#31243;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#29616;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#31216;&#20026;Maximize to Explore (MEX) &#65292;&#23427;&#21482;&#38656;&#35201;&#26080;&#32422;&#26463;&#22320;&#20248;&#21270;&#19968;&#20010;&#38598;&#25104;&#20102;&#20272;&#35745;&#21644;&#35268;&#21010;&#32452;&#20214;&#30340;&#21333;&#19968;&#30446;&#26631;&#20989;&#25968;&#65292;&#21516;&#26102;&#33258;&#21160;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#65292;MEX&#23454;&#29616;&#20102;&#19968;&#20010;&#27425;&#32447;&#24615;&#30340;&#36951;&#25022;&#65292;&#36827;&#19968;&#27493;&#65306;
&lt;/p&gt;
&lt;p&gt;
In online reinforcement learning (online RL), balancing exploration and exploitation is crucial for finding an optimal policy in a sample-efficient way. To achieve this, existing sample-efficient online RL algorithms typically consist of three components: estimation, planning, and exploration. However, in order to cope with general function approximators, most of them involve impractical algorithmic components to incentivize exploration, such as optimization within data-dependent level-sets or complicated sampling procedures. To address this challenge, we propose an easy-to-implement RL framework called \textit{Maximize to Explore} (\texttt{MEX}), which only needs to optimize \emph{unconstrainedly} a single objective that integrates the estimation and planning components while balancing exploration and exploitation automatically. Theoretically, we prove that \texttt{MEX} achieves a sublinear regret with general function approximations for Markov decision processes (MDP) and is further 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#30340;PTAS&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#35823;&#24046;&#21644;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#26159;&#21487;&#23398;&#20064;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.16508</link><description>&lt;p&gt;
&#22823;&#37096;&#20998;&#31070;&#32463;&#32593;&#32476;&#20960;&#20046;&#26159;&#21487;&#23398;&#20064;&#30340;
&lt;/p&gt;
&lt;p&gt;
Most Neural Networks Are Almost Learnable. (arXiv:2305.16508v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#30340;PTAS&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#35823;&#24046;&#21644;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#26159;&#21487;&#23398;&#20064;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;PTAS&#26469;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#30340;$\epsilon&gt;0$&#21644;&#28145;&#24230;$i$&#65292;&#23384;&#22312;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#23545;&#20110;$\sqrt{d} \cdot \mathbb{S}^{d-1}$&#19978;&#30340;&#20219;&#20309;&#20998;&#24067;&#65292;&#23398;&#20064;&#38543;&#26426;Xavier&#32593;&#32476;&#30340;&#28145;&#24230;$i$&#65292;&#35823;&#24046;&#20026;$\epsilon$&#12290;&#35813;&#31639;&#27861;&#30340;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$(\bar{d})^{\mathrm{poly}(\epsilon^{-1})}$&#65292;&#20854;&#20013;$\bar d$&#26159;&#32593;&#32476;&#30340;&#22823;&#23567;&#12290;&#23545;&#20110;&#26576;&#20123;&#31867;&#20284;&#20110;Sigmoid&#21644;ReLU&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#21487;&#20197;&#23558;&#35823;&#24046;&#30028;&#38480;&#25913;&#36827;&#20026;$(\bar{d})^{\mathrm{polylog}(\epsilon^{-1})}$&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#31181;&#20960;&#20046;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#23398;&#20064;&#24120;&#25968;&#28145;&#24230;&#38543;&#26426;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a PTAS for learning random constant-depth networks. We show that for any fixed $\epsilon&gt;0$ and depth $i$, there is a poly-time algorithm that for any distribution on $\sqrt{d} \cdot \mathbb{S}^{d-1}$ learns random Xavier networks of depth $i$, up to an additive error of $\epsilon$. The algorithm runs in time and sample complexity of $(\bar{d})^{\mathrm{poly}(\epsilon^{-1})}$, where $\bar d$ is the size of the network. For some cases of sigmoid and ReLU-like activations the bound can be improved to $(\bar{d})^{\mathrm{polylog}(\epsilon^{-1})}$, resulting in a quasi-poly-time algorithm for learning constant depth random networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26032;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#19968;&#20123;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#26032;&#30340;&#20984;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#21487;&#20197;&#34987;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2305.16475</link><description>&lt;p&gt;
&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#21270;&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Initialization-Dependent Sample Complexity of Linear Predictors and Neural Networks. (arXiv:2305.16475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26032;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#19968;&#20123;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#26032;&#30340;&#20984;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#21487;&#20197;&#34987;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#21521;&#37327;&#20540;&#32447;&#24615;&#39044;&#27979;&#22120;(&#30001;&#30697;&#38453;&#21442;&#25968;&#21270;)&#12289;&#26356;&#19968;&#33324;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#26032;&#32467;&#26524;&#12290;&#19987;&#27880;&#20110;&#22823;&#23567;&#26080;&#20851;&#30340;&#30028;&#38480;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20165;&#25511;&#21046;&#20174;&#26576;&#20010;&#22266;&#23450;&#21442;&#32771;&#30697;&#38453;$W_0$&#30340;&#21442;&#25968;&#30340;Frobenius&#33539;&#25968;&#36317;&#31163;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#34892;&#20026;&#21487;&#20197;&#20986;&#20154;&#24847;&#26009;&#22320;&#19981;&#21516;&#20110;&#25105;&#20204;&#22312;&#30740;&#31350;&#26631;&#37327;&#20540;&#32447;&#24615;&#39044;&#27979;&#22120;&#26041;&#38754;&#25152;&#26399;&#26395;&#30340;&#12290;&#36825;&#36824;&#23548;&#33268;&#20102;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#35299;&#20915;&#20102;&#19968;&#20123;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#30830;&#31435;&#20102;&#19968;&#20010;&#26032;&#30340;&#20984;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23427;&#21487;&#20197;&#22312;&#27809;&#26377;&#32479;&#19968;&#25910;&#25947;&#30340;&#24773;&#20917;&#19979;&#34987;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide several new results on the sample complexity of vector-valued linear predictors (parameterized by a matrix), and more generally neural networks. Focusing on size-independent bounds, where only the Frobenius norm distance of the parameters from some fixed reference matrix $W_0$ is controlled, we show that the sample complexity behavior can be surprisingly different than what we may expect considering the well-studied setting of scalar-valued linear predictors. This also leads to new sample complexity bounds for feed-forward neural networks, tackling some open questions in the literature, and establishing a new convex linear prediction problem that is provably learnable without uniform convergence.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#21508;&#31181;&#20551;&#35774;&#19979;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20250;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#32500;&#24230;&#22312;&#31070;&#32463;&#32593;&#32476;&#36807;&#25311;&#21512;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.15141</link><description>&lt;p&gt;
&#20174;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#32531;&#21644;&#36807;&#25311;&#21512;&#21040;&#33391;&#24615;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
From Tempered to Benign Overfitting in ReLU Neural Networks. (arXiv:2305.15141v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#21508;&#31181;&#20551;&#35774;&#19979;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20250;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#32500;&#24230;&#22312;&#31070;&#32463;&#32593;&#32476;&#36807;&#25311;&#21512;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#34987;&#35266;&#23519;&#21040;&#21363;&#20351;&#35757;&#32451;&#27169;&#22411;&#26469;&#23436;&#32654;&#22320;&#36866;&#24212;&#22024;&#26434;&#30340;&#25968;&#25454;&#20063;&#33021;&#24456;&#22909;&#22320;&#25512;&#24191;&#12290;&#36825;&#19968;&#29616;&#35937;&#24341;&#21457;&#20102;&#22823;&#37327;&#20851;&#20110;&#8220;&#33391;&#24615;&#36807;&#25311;&#21512;&#8221;&#30340;&#24037;&#20316;&#65292;&#20854;&#20013;&#20869;&#25554;&#39044;&#27979;&#22120;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#24615;&#33021;&#12290;&#26368;&#36817;&#65292;&#26377;&#20154;&#29468;&#27979;&#24182;&#32463;&#39564;&#24615;&#22320;&#35266;&#23519;&#21040;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#36890;&#24120;&#26356;&#22909;&#22320;&#25551;&#36848;&#20026;&#8220;&#32531;&#21644;&#36807;&#25311;&#21512;&#8221;&#65292;&#20854;&#20013;&#24615;&#33021;&#26082;&#38750;&#26368;&#20248;&#65292;&#20063;&#38750;&#24494;&#19981;&#36275;&#36947;&#65292;&#24182;&#38543;&#22122;&#22768;&#27700;&#24179;&#30340;&#21464;&#21270;&#32780;&#38477;&#20302;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#36825;&#19968;&#20027;&#24352;&#23578;&#32570;&#20047;&#20851;&#20110;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#30340;&#35777;&#26126;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20960;&#20010;&#32467;&#26524;&#65292;&#26088;&#22312;&#24357;&#21512;&#36825;&#20123;&#20114;&#34917;&#30340;&#35266;&#28857;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#31867;&#35774;&#32622;&#65292;&#20351;&#29992;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#35777;&#26126;&#22312;&#21508;&#31181;&#20551;&#35774;&#19979;&#65292;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35777;&#26126;&#36755;&#20837;&#32500;&#24230;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26377;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparameterized neural networks (NNs) are observed to generalize well even when trained to perfectly fit noisy data. This phenomenon motivated a large body of work on "benign overfitting", where interpolating predictors achieve near-optimal performance. Recently, it was conjectured and empirically observed that the behavior of NNs is often better described as "tempered overfitting", where the performance is non-optimal yet also non-trivial, and degrades as a function of the noise level. However, a theoretical justification of this claim for non-linear NNs has been lacking so far. In this work, we provide several results that aim at bridging these complementing views. We study a simple classification setting with 2-layer ReLU NNs, and prove that under various assumptions, the type of overfitting transitions from tempered in the extreme case of one-dimensional data, to benign in high dimensions. Thus, we show that the input dimension has a crucial role on the type of overfitting in thi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#31209;&#21327;&#21464;&#37327;&#36924;&#36817;&#30340;&#35823;&#24046;&#21464;&#37327;Frechet&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#24182;&#23454;&#29616;&#22312;&#39640;&#32500;&#24230;&#21644;&#35823;&#24046;&#21464;&#37327;&#22238;&#24402;&#35774;&#32622;&#20013;&#26356;&#21152;&#26377;&#25928;&#30340;&#24314;&#27169;&#21644;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2305.09282</link><description>&lt;p&gt;
&#20302;&#31209;&#21327;&#21464;&#37327;&#36924;&#36817;&#30340;&#35823;&#24046;&#21464;&#37327;Frechet&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Errors-in-variables Fr\'echet Regression with Low-rank Covariate Approximation. (arXiv:2305.09282v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#31209;&#21327;&#21464;&#37327;&#36924;&#36817;&#30340;&#35823;&#24046;&#21464;&#37327;Frechet&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#24182;&#23454;&#29616;&#22312;&#39640;&#32500;&#24230;&#21644;&#35823;&#24046;&#21464;&#37327;&#22238;&#24402;&#35774;&#32622;&#20013;&#26356;&#21152;&#26377;&#25928;&#30340;&#24314;&#27169;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Frechet&#22238;&#24402;&#24050;&#25104;&#20026;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24471;&#21709;&#24212;&#21464;&#37327;&#30340;&#22238;&#24402;&#20998;&#26512;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#20381;&#36182;&#20110;&#29702;&#24819;&#24773;&#20917;&#19979;&#20016;&#23500;&#21644;&#26080;&#22122;&#22768;&#30340;&#21327;&#21464;&#37327;&#25968;&#25454;&#65292;&#22240;&#27492;&#20854;&#23454;&#38469;&#24212;&#29992;&#21463;&#21040;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21327;&#21464;&#37327;&#30697;&#38453;&#20013;&#22266;&#26377;&#30340;&#20302;&#31209;&#32467;&#26500;&#26469;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#26694;&#26550;&#32467;&#21512;&#20102;&#20840;&#23616;Frechet&#22238;&#24402;&#21644;&#20027;&#25104;&#20998;&#22238;&#24402;&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#25552;&#39640;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#32435;&#20837;&#20302;&#31209;&#32467;&#26500;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;&#22312;&#39640;&#32500;&#24230;&#21644;&#35823;&#24046;&#21464;&#37327;&#22238;&#24402;&#35774;&#32622;&#20013;&#26356;&#21152;&#26377;&#25928;&#30340;&#24314;&#27169;&#21644;&#20272;&#35745;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#23545;&#25552;&#35758;&#30340;&#20272;&#35745;&#22120;&#30340;&#22823;&#26679;&#26412;&#24615;&#36136;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#21253;&#25324;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#30001;&#20110;&#27979;&#37327;&#35823;&#24046;&#24341;&#36215;&#30340;&#20854;&#20182;&#21464;&#21270;&#30340;&#20840;&#38754;&#29575;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fr\'echet regression has emerged as a promising approach for regression analysis involving non-Euclidean response variables. However, its practical applicability has been hindered by its reliance on ideal scenarios with abundant and noiseless covariate data. In this paper, we present a novel estimation method that tackles these limitations by leveraging the low-rank structure inherent in the covariate matrix. Our proposed framework combines the concepts of global Fr\'echet regression and principal component regression, aiming to improve the efficiency and accuracy of the regression estimator. By incorporating the low-rank structure, our method enables more effective modeling and estimation, particularly in high-dimensional and errors-in-variables regression settings. We provide a theoretical analysis of the proposed estimator's large-sample properties, including a comprehensive rate analysis of bias, variance, and additional variations due to measurement errors. Furthermore, our numeri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.01094</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#23398;&#20064;&#23454;&#29616;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Performative Prediction with Bandit Feedback: Learning through Reparameterization. (arXiv:2305.01094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#25968;&#25454;&#20998;&#24067;&#30001;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#30340;&#24773;&#24418;&#19979;&#39044;&#27979;&#30340;&#19968;&#20010;&#26694;&#26550;&#8212;&#8212;&#23454;&#29616;&#24335;&#39044;&#27979;&#12290;&#29616;&#26377;&#30740;&#31350;&#30340;&#37325;&#28857;&#22312;&#20110;&#20248;&#21270;&#20934;&#30830;&#24615;&#65292;&#20294;&#26159;&#20854;&#20551;&#35774;&#24448;&#24448;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#24471;&#21040;&#28385;&#36275;&#12290;&#26412;&#25991;&#38024;&#23545;&#36825;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#23618;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#23454;&#29616;&#24335;&#39044;&#27979;&#30446;&#26631;&#65292;&#20174;&#32780;&#23558;&#38750;&#20984;&#30340;&#30446;&#26631;&#36716;&#21270;&#20026;&#20984;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performative prediction, as introduced by Perdomo et al. (2020), is a framework for studying social prediction in which the data distribution itself changes in response to the deployment of a model. Existing work on optimizing accuracy in this setting hinges on two assumptions that are easily violated in practice: that the performative risk is convex over the deployed model, and that the mapping from the model to the data distribution is known to the model designer in advance. In this paper, we initiate the study of tractable performative prediction problems that do not require these assumptions. To tackle this more challenging setting, we develop a two-level zeroth-order optimization algorithm, where one level aims to compute the distribution map, and the other level reparameterizes the performative prediction objective as a function of the induced data distribution. Under mild conditions, this reparameterization allows us to transform the non-convex objective into a convex one and ac
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#19979;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#26080;&#38656;&#31070;&#32463;&#20803;&#25968;&#37327;&#36235;&#20110;&#26080;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2304.09576</link><description>&lt;p&gt;
&#21033;&#29992;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Leveraging the two timescale regime to demonstrate convergence of neural networks. (arXiv:2304.09576v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09576
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#19979;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#26080;&#38656;&#31070;&#32463;&#20803;&#25968;&#37327;&#36235;&#20110;&#26080;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#22312;&#20869;&#23618;&#27493;&#38271;&#36828;&#23567;&#20110;&#22806;&#23618;&#27493;&#38271;&#30340;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#19979;&#12290;&#22312;&#36825;&#20010;&#21046;&#24230;&#19979;&#65292;&#22312;&#31616;&#21333;&#30340;&#21333;&#21464;&#37327;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#25910;&#25947;&#20110;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#38656;&#35201;&#31070;&#32463;&#20803;&#25968;&#37327;&#36235;&#20110;&#26080;&#38480;&#65292;&#36825;&#20351;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#21516;&#20110;&#26368;&#36817;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#22914;&#31070;&#32463;&#20999;&#21521;&#26680;&#25110;&#24179;&#22343;&#22330;&#21046;&#24230;&#12290;&#25105;&#20204;&#25552;&#20379;&#23454;&#39564;&#35828;&#26126;&#65292;&#26174;&#31034;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25353;&#29031;&#25105;&#20204;&#23545;&#26799;&#24230;&#27969;&#30340;&#25551;&#36848;&#36827;&#34892;&#34892;&#20026;&#65292;&#24182;&#22240;&#27492;&#22312;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#19979;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#20294;&#22312;&#27492;&#21046;&#24230;&#20043;&#22806;&#21487;&#33021;&#22833;&#36133;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the training dynamics of shallow neural networks, in a two-timescale regime in which the stepsizes for the inner layer are much smaller than those for the outer layer. In this regime, we prove convergence of the gradient flow to a global optimum of the non-convex optimization problem in a simple univariate setting. The number of neurons need not be asymptotically large for our result to hold, distinguishing our result from popular recent approaches such as the neural tangent kernel or mean-field regimes. Experimental illustration is provided, showing that the stochastic gradient descent behaves according to our description of the gradient flow and thus converges to a global optimum in the two-timescale regime, but can fail outside of this regime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#28145;&#24230;&#38750;&#21442;&#25968;&#20272;&#35745;&#20869;&#37096;&#25968;&#25454;&#32467;&#26500;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24191;&#20041;&#35823;&#24046;&#20445;&#35777;&#21644;&#21435;&#22122;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.09863</link><description>&lt;p&gt;
&#36890;&#36807;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#20869;&#37096;&#25968;&#25454;&#32467;&#26500;&#30340;&#28145;&#24230;&#38750;&#21442;&#25968;&#20272;&#35745;&#65306;&#24191;&#20041;&#35823;&#24046;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Nonparametric Estimation of Intrinsic Data Structures by Chart Autoencoders: Generalization Error and Robustness. (arXiv:2303.09863v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09863
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#28145;&#24230;&#38750;&#21442;&#25968;&#20272;&#35745;&#20869;&#37096;&#25968;&#25454;&#32467;&#26500;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24191;&#20041;&#35823;&#24046;&#20445;&#35777;&#21644;&#21435;&#22122;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#32534;&#30721;&#22120;&#22312;&#23398;&#20064;&#39640;&#32500;&#25968;&#25454;&#30340;&#20302;&#32500;&#28508;&#22312;&#29305;&#24449;&#26041;&#38754;&#24050;&#32463;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23637;&#29616;&#20986;&#20102;&#26174;&#30528;&#30340;&#25104;&#21151;&#12290;&#20551;&#35774;&#25968;&#25454;&#22312;&#20302;&#32500;&#27969;&#24418;&#38468;&#36817;&#37319;&#26679;&#65292;&#25105;&#20204;&#37319;&#29992;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#65292;&#23558;&#25968;&#25454;&#32534;&#30721;&#20026;&#19968;&#32452;&#22270;&#34920;&#19978;&#30340;&#20302;&#32500;&#28508;&#22312;&#29305;&#24449;&#65292;&#20174;&#32780;&#20445;&#30041;&#20102;&#25968;&#25454;&#27969;&#24418;&#30340;&#25299;&#25169;&#21644;&#20960;&#20309;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#20026;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#30340;&#24191;&#20041;&#35823;&#24046;&#24314;&#31435;&#20102;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#19988;&#36890;&#36807;&#32771;&#34385;$d$&#32500;&#27969;&#24418;&#19978;$n$&#20010;&#24102;&#22122;&#22768;&#35757;&#32451;&#26679;&#26412;&#21450;&#20854;&#26080;&#22122;&#22768;&#23545;&#24212;&#29289;&#26469;&#23637;&#31034;&#23427;&#20204;&#30340;&#21435;&#22122;&#33021;&#21147;&#12290;&#36890;&#36807;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#33021;&#22815;&#26377;&#25928;&#22320;&#21435;&#22122;&#36755;&#20837;&#25968;&#25454;&#21644;&#27491;&#24577;&#20998;&#24067;&#22122;&#22768;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#32593;&#32476;&#26550;&#26500;&#19979;&#65292;&#22270;&#34920;&#33258;&#32534;&#30721;&#22120;&#23454;&#29616;&#20102;&#19968;&#20010;&#22823;&#33268;&#20026;$\displaystyle n^{-\frac{2}{d+2}}\log^4 n$&#38454;&#30340;&#24179;&#26041;&#24191;&#20041;&#35823;&#24046;&#65292;&#35813;&#35823;&#24046;&#21462;&#20915;&#20110;&#27969;&#24418;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#19988;&#20165;&#24369;&#20381;&#36182;&#20110;&#26679;&#26412;&#25968;&#37327;$n$&#12290;
&lt;/p&gt;
&lt;p&gt;
Autoencoders have demonstrated remarkable success in learning low-dimensional latent features of high-dimensional data across various applications. Assuming that data are sampled near a low-dimensional manifold, we employ chart autoencoders, which encode data into low-dimensional latent features on a collection of charts, preserving the topology and geometry of the data manifold. Our paper establishes statistical guarantees on the generalization error of chart autoencoders, and we demonstrate their denoising capabilities by considering $n$ noisy training samples, along with their noise-free counterparts, on a $d$-dimensional manifold. By training autoencoders, we show that chart autoencoders can effectively denoise the input data with normal noise. We prove that, under proper network architectures, chart autoencoders achieve a squared generalization error in the order of $\displaystyle n^{-\frac{2}{d+2}}\log^4 n$, which depends on the intrinsic dimension of the manifold and only weakly
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#22810;&#26679;&#21270;&#20998;&#24067;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#38024;&#23545;&#24615;&#22320;&#35774;&#35745;&#20102;&#25968;&#25454;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#20998;&#24067;&#36716;&#25442;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.13875</link><description>&lt;p&gt;
&#22312;&#32467;&#26500;&#20998;&#24067;&#20559;&#31227;&#26465;&#20214;&#19979;&#35780;&#20272;&#22270;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating Robustness and Uncertainty of Graph Models Under Structural Distributional Shifts. (arXiv:2302.13875v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13875
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#22810;&#26679;&#21270;&#20998;&#24067;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#38024;&#23545;&#24615;&#22320;&#35774;&#35745;&#20102;&#25968;&#25454;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#20998;&#24067;&#36716;&#25442;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21487;&#38752;&#20915;&#31574;&#31995;&#32479;&#20013;&#65292;&#27169;&#22411;&#24517;&#39035;&#23545;&#20998;&#24067;&#20559;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#25110;&#25552;&#20379;&#20854;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#22270;&#23398;&#20064;&#30340;&#33410;&#28857;&#32423;&#38382;&#39064;&#20013;&#65292;&#20998;&#24067;&#20559;&#31227;&#21487;&#33021;&#23588;&#20026;&#22797;&#26434;&#65292;&#22240;&#20026;&#26679;&#26412;&#26159;&#30456;&#20114;&#20381;&#36182;&#30340;&#12290;&#20026;&#20102;&#35780;&#20272;&#22270;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#37325;&#35201;&#30340;&#26159;&#22312;&#21508;&#31181;&#26377;&#24847;&#20041;&#30340;&#20998;&#24067;&#20559;&#31227;&#19979;&#23545;&#23427;&#20204;&#36827;&#34892;&#27979;&#35797;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#32771;&#34385;&#33410;&#28857;&#32423;&#20998;&#24067;&#20559;&#31227;&#30340;&#22270;&#22522;&#20934;&#20027;&#35201;&#20851;&#27880;&#33410;&#28857;&#29305;&#24449;&#65292;&#32780;&#32467;&#26500;&#23646;&#24615;&#23545;&#22270;&#38382;&#39064;&#20063;&#24456;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#24341;&#20986;&#22810;&#26679;&#21270;&#20998;&#24067;&#20559;&#31227;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#26681;&#25454;&#20960;&#20010;&#33410;&#28857;&#30340;&#32467;&#26500;&#23646;&#24615;&#65306;&#27969;&#34892;&#24230;&#12289;&#23616;&#37096;&#24615;&#21644;&#23494;&#24230;&#26469;&#21019;&#24314;&#25968;&#25454;&#20998;&#21106;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#20840;&#38754;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#20998;&#24067;&#20559;&#31227;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#21487;&#33021;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#36824;&#20462;&#35746;&#20102;&#19968;&#20123;&#20851;&#20110;&#22522;&#20934;&#27979;&#35797;&#22270;&#27169;&#22411;&#30340;&#20808;&#21069;&#24037;&#20316;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#32452;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#32771;&#34385;&#20102;&#32467;&#26500;&#20998;&#24067;&#20559;&#31227;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reliable decision-making systems based on machine learning, models have to be robust to distributional shifts or provide the uncertainty of their predictions. In node-level problems of graph learning, distributional shifts can be especially complex since the samples are interdependent. To evaluate the performance of graph models, it is important to test them on diverse and meaningful distributional shifts. However, most graph benchmarks considering distributional shifts for node-level problems focus mainly on node features, while structural properties are also essential for graph problems. In this work, we propose a general approach for inducing diverse distributional shifts based on graph structure. We use this approach to create data splits according to several structural node properties: popularity, locality, and density. In our experiments, we thoroughly evaluate the proposed distributional shifts and show that they can be quite challenging for existing graph models. We also rev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23545;&#35282;&#32447;&#32447;&#24615;&#32593;&#32476;&#19978;&#65292;&#38543;&#26426;&#24615;&#21644;&#22823;&#27493;&#38271;&#23545;&#26799;&#24230;&#19979;&#38477;(GD)&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22823;&#27493;&#38271;&#23545;&#31232;&#30095;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;SGD&#26377;&#30410;&#22788;&#65292;&#20294;&#23545;GD&#21487;&#33021;&#26377;&#23475;&#12290;&#36825;&#31181;&#24433;&#21709;&#22312;&#25509;&#36817;&#21457;&#25955;&#38408;&#20540;&#30340;&#32039;&#23494;&#27493;&#38271;&#19979;&#34987;&#25918;&#22823;&#12290;</title><link>http://arxiv.org/abs/2302.08982</link><description>&lt;p&gt;
(S)GD&#22312;&#23545;&#35282;&#32447;&#32447;&#24615;&#32593;&#32476;&#19978;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#12289;&#22823;&#27493;&#38271;&#21644;&#31283;&#23450;&#36793;&#32536;&#30340;&#24433;&#21709;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
(S)GD over Diagonal Linear Networks: Implicit Regularisation, Large Stepsizes and Edge of Stability. (arXiv:2302.08982v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23545;&#35282;&#32447;&#32447;&#24615;&#32593;&#32476;&#19978;&#65292;&#38543;&#26426;&#24615;&#21644;&#22823;&#27493;&#38271;&#23545;&#26799;&#24230;&#19979;&#38477;(GD)&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22823;&#27493;&#38271;&#23545;&#31232;&#30095;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;SGD&#26377;&#30410;&#22788;&#65292;&#20294;&#23545;GD&#21487;&#33021;&#26377;&#23475;&#12290;&#36825;&#31181;&#24433;&#21709;&#22312;&#25509;&#36817;&#21457;&#25955;&#38408;&#20540;&#30340;&#32039;&#23494;&#27493;&#38271;&#19979;&#34987;&#25918;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#24615;&#21644;&#22823;&#27493;&#38271;&#23545;&#26799;&#24230;&#19979;&#38477;(GD)&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#22312;&#23545;&#35282;&#32447;&#32447;&#24615;&#32593;&#32476;&#19978;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#20351;&#29992;&#23439;&#35266;&#27493;&#38271;&#30340;GD&#21644;SGD&#25910;&#25947;&#65292;&#24182;&#36890;&#36807;&#38544;&#24335;&#27491;&#21017;&#21270;&#38382;&#39064;&#25551;&#36848;&#23427;&#20204;&#30340;&#35299;&#12290;&#25105;&#20204;&#30340;&#28165;&#26224;&#25551;&#36848;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#38543;&#26426;&#24615;&#21644;&#27493;&#38271;&#23545;&#24674;&#22797;&#35299;&#30340;&#24433;&#21709;&#30340;&#23450;&#24615;&#35265;&#35299;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#34920;&#26126;&#22312;&#31232;&#30095;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#22823;&#27493;&#38271;&#23545;SGD&#26377;&#31283;&#23450;&#30340;&#22909;&#22788;&#65292;&#20294;&#23545;GD&#30340;&#31232;&#30095;&#35299;&#24674;&#22797;&#21487;&#33021;&#20135;&#29983;&#38459;&#30861;&#12290;&#36825;&#20123;&#25928;&#24212;&#22312;&#32039;&#23494;&#31383;&#21475;&#20869;&#30340;&#27493;&#38271;&#19979;&#34987;&#25918;&#22823;&#65292;&#20301;&#20110;&#8220;&#31283;&#23450;&#36793;&#32536;&#8221;&#21306;&#22495;&#30340;&#27493;&#38271;&#12290;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the impact of stochasticity and large stepsizes on the implicit regularisation of gradient descent (GD) and stochastic gradient descent (SGD) over diagonal linear networks. We prove the convergence of GD and SGD with macroscopic stepsizes in an overparametrised regression setting and characterise their solutions through an implicit regularisation problem. Our crisp characterisation leads to qualitative insights about the impact of stochasticity and stepsizes on the recovered solution. Specifically, we show that large stepsizes consistently benefit SGD for sparse regression problems, while they can hinder the recovery of sparse solutions for GD. These effects are magnified for stepsizes in a tight window just below the divergence threshold, in the "edge of stability" regime. Our findings are supported by experimental results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#26356;&#39640;&#38454;&#28151;&#21512;&#25104;&#21592;&#20851;&#31995;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;$\ell_{2,\infty}$&#24352;&#37327;&#25200;&#21160;&#30028;&#38480;&#65292;&#36890;&#36807;&#24352;&#37327;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;&#23545;&#22810;&#26679;&#21270;&#25968;&#25454;&#30340;&#31038;&#21306;&#32467;&#26500;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#20351;&#29992;&#39640;&#38454;&#27491;&#20132;&#36845;&#20195;&#31639;&#27861;&#36827;&#34892;&#20272;&#35745;&#36807;&#31243;&#12290;&#36890;&#36807;&#25552;&#20379;&#27599;&#20010;&#33410;&#28857;&#30340;&#35823;&#24046;&#30028;&#38480;&#26469;&#35777;&#26126;&#20102;&#20272;&#35745;&#36807;&#31243;&#30340;&#19968;&#33268;&#24615;&#65292;&#23637;&#31034;&#20102;&#39640;&#38454;&#32467;&#26500;&#23545;&#20272;&#35745;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2212.08642</link><description>&lt;p&gt;
&#36890;&#36807;$\ell_{2,\infty}$&#24352;&#37327;&#25200;&#21160;&#30028;&#38480;&#20272;&#35745;&#26356;&#39640;&#38454;&#28151;&#21512;&#25104;&#21592;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Estimating Higher-Order Mixed Memberships via the $\ell_{2,\infty}$ Tensor Perturbation Bound. (arXiv:2212.08642v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#26356;&#39640;&#38454;&#28151;&#21512;&#25104;&#21592;&#20851;&#31995;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;$\ell_{2,\infty}$&#24352;&#37327;&#25200;&#21160;&#30028;&#38480;&#65292;&#36890;&#36807;&#24352;&#37327;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;&#23545;&#22810;&#26679;&#21270;&#25968;&#25454;&#30340;&#31038;&#21306;&#32467;&#26500;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#20351;&#29992;&#39640;&#38454;&#27491;&#20132;&#36845;&#20195;&#31639;&#27861;&#36827;&#34892;&#20272;&#35745;&#36807;&#31243;&#12290;&#36890;&#36807;&#25552;&#20379;&#27599;&#20010;&#33410;&#28857;&#30340;&#35823;&#24046;&#30028;&#38480;&#26469;&#35777;&#26126;&#20102;&#20272;&#35745;&#36807;&#31243;&#30340;&#19968;&#33268;&#24615;&#65292;&#23637;&#31034;&#20102;&#39640;&#38454;&#32467;&#26500;&#23545;&#20272;&#35745;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26356;&#39640;&#38454;&#30340;&#22810;&#26679;&#21270;&#25968;&#25454;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#20013;&#38750;&#24120;&#26222;&#36941;&#65292;&#24182;&#32463;&#24120;&#34920;&#29616;&#20986;&#31867;&#20284;&#31038;&#21306;&#30340;&#32467;&#26500;&#65292;&#20854;&#20013;&#27599;&#20010;&#20998;&#37327;&#65288;&#33410;&#28857;&#65289;&#22312;&#27599;&#20010;&#19981;&#21516;&#30340;&#27169;&#24335;&#19978;&#37117;&#26377;&#19968;&#20010;&#19982;&#20043;&#20851;&#32852;&#30340;&#31038;&#21306;&#25104;&#21592;&#36164;&#26684;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#24352;&#37327;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;&#65292;&#36825;&#26159;&#24352;&#37327;&#22359;&#27169;&#22411;&#30340;&#19968;&#20010;&#25512;&#24191;&#65292;&#20854;&#20551;&#35774;&#25104;&#21592;&#20851;&#31995;&#19981;&#38656;&#35201;&#26159;&#31163;&#25955;&#30340;&#65292;&#32780;&#26159;&#28508;&#22312;&#31038;&#21306;&#30340;&#20984;&#32452;&#21512;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#38454;&#27491;&#20132;&#36845;&#20195;&#31639;&#27861;&#65288;HOOI&#65289;&#19982;&#21333;&#32431;&#24418;&#35282;&#28857;&#23547;&#25214;&#31639;&#27861;&#32452;&#21512;&#30340;&#35745;&#31639;&#25928;&#29575;&#20272;&#35745;&#36807;&#31243;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20379;&#27599;&#20010;&#33410;&#28857;&#30340;&#35823;&#24046;&#30028;&#38480;&#26469;&#35777;&#26126;&#25105;&#20204;&#30340;&#20272;&#35745;&#36807;&#31243;&#30340;&#19968;&#33268;&#24615;&#65292;&#36825;&#23637;&#31034;&#20102;&#39640;&#38454;&#32467;&#26500;&#23545;&#20272;&#35745;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#30340;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#29420;&#31435;&#30340;&#12289;&#21487;&#33021;&#24322;&#26041;&#24046;&#30340;$\ell_{2,\infty}$&#24352;&#37327;&#25200;&#21160;&#30028;&#38480;&#30340;HOOI&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Higher-order multiway data is ubiquitous in machine learning and statistics and often exhibits community-like structures, where each component (node) along each different mode has a community membership associated with it. In this paper we propose the tensor mixed-membership blockmodel, a generalization of the tensor blockmodel positing that memberships need not be discrete, but instead are convex combinations of latent communities. We establish the identifiability of our model and propose a computationally efficient estimation procedure based on the higher-order orthogonal iteration algorithm (HOOI) for tensor SVD composed with a simplex corner-finding algorithm. We then demonstrate the consistency of our estimation procedure by providing a per-node error bound, which showcases the effect of higher-order structures on estimation accuracy. To prove our consistency result, we develop the $\ell_{2,\infty}$ tensor perturbation bound for HOOI under independent, possibly heteroskedastic, su
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;Bagging&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#36890;&#29992;&#31574;&#30053;&#26469;&#20998;&#26512;Bagging&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#20855;&#20307;&#21270;&#31574;&#30053;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;Bagging Ridge&#21644;Ridgeless&#39044;&#27979;&#22120;&#30340;&#31934;&#30830;&#28176;&#36817;&#39118;&#38505;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20132;&#21449;&#39564;&#35777;&#36807;&#31243;&#26469;&#36873;&#25321;Bagging&#30340;&#26368;&#20339;&#23376;&#26679;&#26412;&#22823;&#23567;&#65292;&#20197;&#28040;&#38500;&#39118;&#38505;&#30340;&#38750;&#21333;&#35843;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2210.11445</link><description>&lt;p&gt;
Bagging&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;&#30340;&#39118;&#38505;&#21051;&#30011;&#21644;&#39118;&#38505;&#21333;&#35843;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bagging in overparameterized learning: Risk characterization and risk monotonization. (arXiv:2210.11445v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;Bagging&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#36890;&#29992;&#31574;&#30053;&#26469;&#20998;&#26512;Bagging&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#20855;&#20307;&#21270;&#31574;&#30053;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;Bagging Ridge&#21644;Ridgeless&#39044;&#27979;&#22120;&#30340;&#31934;&#30830;&#28176;&#36817;&#39118;&#38505;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20132;&#21449;&#39564;&#35777;&#36807;&#31243;&#26469;&#36873;&#25321;Bagging&#30340;&#26368;&#20339;&#23376;&#26679;&#26412;&#22823;&#23567;&#65292;&#20197;&#28040;&#38500;&#39118;&#38505;&#30340;&#38750;&#21333;&#35843;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bagging&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;&#38598;&#25104;&#25216;&#26415;&#65292;&#29992;&#20110;&#25552;&#39640;&#39044;&#27979;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27604;&#20363;&#28176;&#36817;&#24773;&#20917;&#19979;&#65292;&#21508;&#31181;&#21464;&#20307;&#30340;Bagging&#39044;&#27979;&#22120;&#30340;&#39044;&#27979;&#39118;&#38505;&#65292;&#20854;&#20013;&#29305;&#24449;&#25968;&#19982;&#35266;&#27979;&#25968;&#30340;&#27604;&#20540;&#25910;&#25947;&#21040;&#24120;&#25968;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;Bagging&#39044;&#27979;&#22120;&#22312;&#24179;&#26041;&#35823;&#24046;&#25439;&#22833;&#19979;&#30340;&#39044;&#27979;&#39118;&#38505;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#21033;&#29992;&#31616;&#21333;&#38543;&#26426;&#25277;&#26679;&#30340;&#32463;&#20856;&#32467;&#26524;&#12290;&#36890;&#36807;&#29305;&#27530;&#21270;&#35813;&#31574;&#30053;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#20855;&#26377;&#20219;&#24847;&#25968;&#37327;&#30340;&#21253;&#30340;Bagging Ridge&#21644;Ridgeless&#39044;&#27979;&#22120;&#22312;&#20855;&#26377;&#20219;&#24847;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#21644;&#20449;&#21495;&#21521;&#37327;&#30340;&#33391;&#22909;&#25351;&#23450;&#32447;&#24615;&#27169;&#22411;&#19979;&#30340;&#31934;&#30830;&#28176;&#36817;&#39118;&#38505;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#20132;&#21449;&#39564;&#35777;&#36807;&#31243;&#65292;&#29992;&#20110;&#36873;&#25321;Bagging&#30340;&#26368;&#20339;&#23376;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#35752;&#35770;&#20854;&#22312;&#28040;&#38500;&#26679;&#26412;&#22823;&#23567;&#30340;&#39118;&#38505;&#30340;&#38750;&#21333;&#35843;&#34892;&#20026;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bagging is a commonly used ensemble technique in statistics and machine learning to improve the performance of prediction procedures. In this paper, we study the prediction risk of variants of bagged predictors under the proportional asymptotics regime, in which the ratio of the number of features to the number of observations converges to a constant. Specifically, we propose a general strategy to analyze the prediction risk under squared error loss of bagged predictors using classical results on simple random sampling. Specializing the strategy, we derive the exact asymptotic risk of the bagged ridge and ridgeless predictors with an arbitrary number of bags under a well-specified linear model with arbitrary feature covariance matrices and signal vectors. Furthermore, we prescribe a generic cross-validation procedure to select the optimal subsample size for bagging and discuss its utility to eliminate the non-monotonic behavior of the limiting risk in the sample size (i.e., double or m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26032;&#39062;&#26816;&#27979;&#26041;&#27861;AdaDetect&#65292;&#33021;&#22815;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#25511;&#21046;&#20551;&#21457;&#29616;&#29575;&#65292;&#32780;&#26080;&#38656;&#20998;&#24067;&#20551;&#35774;&#12290;&#26041;&#27861;&#28789;&#27963;&#36866;&#29992;&#20110;&#20219;&#20309;&#27010;&#29575;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#25968;&#25454;&#33258;&#36866;&#24212;&#23398;&#20064;&#21464;&#25442;&#65292;&#23558;&#21151;&#29575;&#38598;&#20013;&#22312;&#21306;&#20998;&#20869;&#28857;&#21644;&#22806;&#28857;&#30340;&#26041;&#21521;&#19978;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#36866;&#24212;&#20110;&#31354;&#20540;&#27604;&#20363;&#30340;AdaDetect&#21464;&#20307;&#12290;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;</title><link>http://arxiv.org/abs/2208.06685</link><description>&lt;p&gt;
&#20855;&#26377;&#20551;&#21457;&#29616;&#29575;&#20445;&#35777;&#30340;&#33258;&#36866;&#24212;&#26032;&#39062;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Adaptive novelty detection with false discovery rate guarantee. (arXiv:2208.06685v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26032;&#39062;&#26816;&#27979;&#26041;&#27861;AdaDetect&#65292;&#33021;&#22815;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#25511;&#21046;&#20551;&#21457;&#29616;&#29575;&#65292;&#32780;&#26080;&#38656;&#20998;&#24067;&#20551;&#35774;&#12290;&#26041;&#27861;&#28789;&#27963;&#36866;&#29992;&#20110;&#20219;&#20309;&#27010;&#29575;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#25968;&#25454;&#33258;&#36866;&#24212;&#23398;&#20064;&#21464;&#25442;&#65292;&#23558;&#21151;&#29575;&#38598;&#20013;&#22312;&#21306;&#20998;&#20869;&#28857;&#21644;&#22806;&#28857;&#30340;&#26041;&#21521;&#19978;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#36866;&#24212;&#20110;&#31354;&#20540;&#27604;&#20363;&#30340;AdaDetect&#21464;&#20307;&#12290;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21322;&#30417;&#30563;&#30340;&#26032;&#39062;&#26816;&#27979;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#33719;&#24471;&#19968;&#32452;&#8220;&#20856;&#22411;&#8221;&#27979;&#37327;&#25968;&#25454;&#12290;&#21463;&#21040;&#22810;&#37325;&#26816;&#39564;&#21644;&#31526;&#21512;&#25512;&#26029;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AdaDetect&#65292;&#19968;&#31181;&#28789;&#27963;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36866;&#29992;&#20110;&#20219;&#20309;&#27010;&#29575;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#25511;&#21046;&#26816;&#27979;&#21040;&#30340;&#26032;&#39062;&#24615;&#30340;&#20551;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#65292;&#32780;&#26080;&#38656;&#38500;&#20102;&#21487;&#20132;&#25442;&#24615;&#20197;&#22806;&#30340;&#20219;&#20309;&#20998;&#24067;&#20551;&#35774;&#12290;&#19982;&#36890;&#24120;&#39044;&#20808;&#25351;&#23450;p&#20540;&#20989;&#25968;&#30340;&#32463;&#20856;FDR&#25511;&#21046;&#26041;&#27861;&#19981;&#21516;&#65292;AdaDetect&#20197;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#26041;&#24335;&#23398;&#20064;&#21464;&#25442;&#65292;&#23558;&#21151;&#29575;&#38598;&#20013;&#22312;&#21306;&#20998;&#20869;&#28857;&#21644;&#22806;&#28857;&#30340;&#26041;&#21521;&#19978;&#12290;&#21463;&#22810;&#37325;&#26816;&#39564;&#25991;&#29486;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#36866;&#24212;&#20110;&#31354;&#20540;&#27604;&#20363;&#30340;AdaDetect&#21464;&#20307;&#65292;&#21516;&#26102;&#20445;&#25345;&#26377;&#38480;&#26679;&#26412;&#30340;FDR&#25511;&#21046;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#21253;&#25324;&#19968;&#20010;&#24212;&#29992;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the semi-supervised novelty detection problem where a set of "typical" measurements is available to the researcher. Motivated by recent advances in multiple testing and conformal inference, we propose AdaDetect, a flexible method that is able to wrap around any probabilistic classification algorithm and control the false discovery rate (FDR) on detected novelties in finite samples without any distributional assumption other than exchangeability. In contrast to classical FDR-controlling procedures that are often committed to a pre-specified p-value function, AdaDetect learns the transformation in a data-adaptive manner to focus the power on the directions that distinguish between inliers and outliers. Inspired by the multiple testing literature, we further propose variants of AdaDetect that are adaptive to the proportion of nulls while maintaining the finite-sample FDR control. The methods are illustrated on synthetic datasets and real-world datasets, including an app
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#36755;&#20986;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#27169;&#25311;&#21644;&#26426;&#22120;&#23398;&#20064;&#36755;&#20986;&#36827;&#34892;&#20998;&#26512;&#65292;&#33021;&#22815;&#38750;&#21442;&#25968;&#21270;&#22320;&#37327;&#21270;&#36755;&#20986;&#30340;&#26041;&#24046;&#21644;&#20559;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2207.13612</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#36755;&#20986;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Robust Output Analysis with Monte-Carlo Methodology. (arXiv:2207.13612v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.13612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#36755;&#20986;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#27169;&#25311;&#21644;&#26426;&#22120;&#23398;&#20064;&#36755;&#20986;&#36827;&#34892;&#20998;&#26512;&#65292;&#33021;&#22815;&#38750;&#21442;&#25968;&#21270;&#22320;&#37327;&#21270;&#36755;&#20986;&#30340;&#26041;&#24046;&#21644;&#20559;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20351;&#29992;&#27169;&#25311;&#25110;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#39044;&#27979;&#24314;&#27169;&#26102;&#65292;&#20934;&#30830;&#35780;&#20272;&#20272;&#35745;&#20540;&#30340;&#36136;&#37327;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#34892;&#36755;&#20986;&#20998;&#26512;&#12290;&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#36755;&#20986;&#20998;&#26512;&#26041;&#27861;&#24050;&#32463;&#24471;&#21040;&#20102;&#20016;&#23500;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#37327;&#21270;&#36755;&#20837;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#65292;&#20197;&#22686;&#21152;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#26159;&#22522;&#20110;&#20551;&#35774;&#36755;&#20837;&#25968;&#25454;&#31526;&#21512;&#21442;&#25968;&#20998;&#24067;&#26063;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#36755;&#20986;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#30340;&#26041;&#24335;&#23545;&#27169;&#25311;&#21644;&#26426;&#22120;&#23398;&#20064;&#36755;&#20986;&#36827;&#34892;&#20998;&#26512;&#12290;&#35813;&#26694;&#26550;&#21487;&#20197;&#23545;&#36755;&#20986;&#20013;&#24341;&#20837;&#30340;&#26041;&#24046;&#21644;&#20559;&#24046;&#36827;&#34892;&#38750;&#21442;&#25968;&#21270;&#30340;&#37327;&#21270;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#38454;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25193;&#23637;&#24555;&#36895;&#36845;&#20195;&#33258;&#20030;&#25277;&#26679;&#21644;&#39640;&#38454;&#24433;&#21709;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20174;&#27169;&#22411;&#36755;&#20986;&#20013;&#26657;&#27491;&#20559;&#24046;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;&#20026;&#20102;&#25552;&#39640;&#25152;&#25552;&#26041;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#39044;&#31639;&#26368;&#20248;&#35268;&#21017;&#65292;&#24182;&#21033;&#29992;&#25511;&#21046;&#21464;&#37327;&#20943;&#23569;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In predictive modeling with simulation or machine learning, it is critical to accurately assess the quality of estimated values through output analysis. In recent decades output analysis has become enriched with methods that quantify the impact of input data uncertainty in the model outputs to increase robustness. However, most developments are applicable assuming that the input data adheres to a parametric family of distributions. We propose a unified output analysis framework for simulation and machine learning outputs through the lens of Monte Carlo sampling. This framework provides nonparametric quantification of the variance and bias induced in the outputs with higher-order accuracy. Our new bias-corrected estimation from the model outputs leverages the extension of fast iterative bootstrap sampling and higher-order influence functions. For the scalability of the proposed estimation methods, we devise budget-optimal rules and leverage control variates for variance reduction. Our t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#27835;&#30103;&#31038;&#21306;&#20013;&#30340;&#21516;&#20276;&#24433;&#21709;&#25110;&#35282;&#33394;&#27169;&#22411;&#25928;&#24212;&#23545;&#20110;&#25104;&#21151;&#27605;&#19994;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20998;&#26512;&#19977;&#20010;&#27835;&#30103;&#31038;&#21306;&#30340;&#35266;&#23519;&#25968;&#25454;&#65292;&#25105;&#20204;&#21457;&#29616;&#32943;&#23450;&#30340;&#21516;&#20276;&#20132;&#27969;&#23545;&#20110;&#23621;&#27665;&#22312;&#33258;&#24049;&#31163;&#24320;&#20043;&#21069;&#25104;&#21151;&#27605;&#19994;&#19982;&#21542;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.14223</link><description>&lt;p&gt;
&#22312;&#27835;&#30103;&#31038;&#21306;&#20013;&#35782;&#21035;&#21516;&#20276;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Identifying Peer Influence in Therapeutic Communities. (arXiv:2203.14223v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.14223
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#27835;&#30103;&#31038;&#21306;&#20013;&#30340;&#21516;&#20276;&#24433;&#21709;&#25110;&#35282;&#33394;&#27169;&#22411;&#25928;&#24212;&#23545;&#20110;&#25104;&#21151;&#27605;&#19994;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20998;&#26512;&#19977;&#20010;&#27835;&#30103;&#31038;&#21306;&#30340;&#35266;&#23519;&#25968;&#25454;&#65292;&#25105;&#20204;&#21457;&#29616;&#32943;&#23450;&#30340;&#21516;&#20276;&#20132;&#27969;&#23545;&#20110;&#23621;&#27665;&#22312;&#33258;&#24049;&#31163;&#24320;&#20043;&#21069;&#25104;&#21151;&#27605;&#19994;&#19982;&#21542;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22312;&#27835;&#30103;&#31038;&#21306;&#20013;&#26159;&#21542;&#23384;&#22312;&#21516;&#20276;&#24433;&#21709;&#25110;&#35282;&#33394;&#27169;&#22411;&#25928;&#24212;&#23545;&#20110;&#25104;&#21151;&#27605;&#19994;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;3&#20010;&#20445;&#30041;&#20102;&#23621;&#27665;&#20043;&#38388;&#30830;&#35748;&#21644;&#20462;&#27491;&#20132;&#27969;&#35760;&#24405;&#20197;&#21450;&#20182;&#20204;&#20837;&#20303;&#21644;&#31163;&#24320;&#26085;&#26399;&#30340;&#27835;&#30103;&#31038;&#21306;&#30340;&#21311;&#21517;&#20010;&#20307;&#35266;&#23519;&#25968;&#25454;&#12290;&#36825;&#20123;&#30830;&#35748;&#20132;&#27969;&#20351;&#25105;&#20204;&#33021;&#22815;&#24418;&#25104;&#21516;&#20276;&#32593;&#32476;&#65292;&#32780;&#20837;&#20303;&#21644;&#31163;&#24320;&#26085;&#26399;&#20351;&#25105;&#20204;&#33021;&#22815;&#23450;&#20041;&#24863;&#20852;&#36259;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#22240;&#26524;&#35282;&#33394;&#27169;&#22411;&#25928;&#24212;&#27010;&#24565;&#21270;&#20026;&#23621;&#27665;&#65288;&#33258;&#25105;&#65289;&#35266;&#23519;&#21040;&#20182;&#20204;&#30340;&#26576;&#20010;&#31038;&#20132;&#32852;&#31995;&#20154;&#65288;&#20363;&#22914;&#65292;&#32473;&#20104;&#32943;&#23450;&#30340;&#21516;&#20276;&#65289;&#22312;&#33258;&#25105;&#31163;&#24320;&#20043;&#21069;&#25104;&#21151;&#27605;&#19994;&#19982;&#19981;&#25104;&#21151;&#27605;&#19994;&#30340;&#39044;&#26399;&#32467;&#26524;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#30001;&#20110;&#21516;&#20276;&#24433;&#21709;&#36890;&#24120;&#19982;&#35266;&#23519;&#25968;&#25454;&#20013;&#26410;&#35266;&#23519;&#21040;&#30340;&#21516;&#36136;&#24615;&#28151;&#28102;&#65292;&#25105;&#20204;&#20351;&#29992;&#28508;&#21464;&#37327;&#27169;&#22411;&#23545;&#32593;&#32476;&#36827;&#34892;&#24314;&#27169;&#20197;&#20272;&#35745;&#21516;&#36136;&#24615;&#24182;&#23558;&#20854;&#21253;&#21547;&#22312;&#32467;&#26524;&#26041;&#31243;&#20013;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#20445;&#35777;&#65292;&#23427;&#21487;&#20197;&#35299;&#20915;&#32593;&#32476;&#20013;&#30340;&#20869;&#29983;&#24615;&#38382;&#39064;&#24182;&#25552;&#20379;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate if there is a peer influence or role model effect on successful graduation from Therapeutic Communities (TCs). We analyze anonymized individual-level observational data from 3 TCs that kept records of written exchanges of affirmations and corrections among residents, and their precise entry and exit dates. The affirmations allow us to form peer networks, and the entry and exit dates allow us to define a causal effect of interest. We conceptualize the causal role model effect as measuring the difference in the expected outcome of a resident (ego) who can observe one of their social contacts (e.g., peers who gave affirmations), to be successful in graduating before the ego's exit vs not successfully graduating before the ego's exit. Since peer influence is usually confounded with unobserved homophily in observational data, we model the network with a latent variable model to estimate homophily and include it in the outcome equation. We provide a theoretical guarantee that 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28151;&#21512;&#27169;&#22411;&#26694;&#26550;&#20013;&#37325;&#26032;&#23457;&#35270;&#20102;&#26080;&#30417;&#30563;&#32858;&#31867;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#33021;&#22815;&#20445;&#35777;&#34394;&#20551;&#25104;&#21592;&#29575;&#19981;&#36229;&#36807;&#32473;&#23450;&#30340;&#38408;&#20540;&#945;&#12290;</title><link>http://arxiv.org/abs/2203.02597</link><description>&lt;p&gt;
&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#34394;&#20551;&#25104;&#21592;&#29575;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
False membership rate control in mixture models. (arXiv:2203.02597v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.02597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28151;&#21512;&#27169;&#22411;&#26694;&#26550;&#20013;&#37325;&#26032;&#23457;&#35270;&#20102;&#26080;&#30417;&#30563;&#32858;&#31867;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#33021;&#22815;&#20445;&#35777;&#34394;&#20551;&#25104;&#21592;&#29575;&#19981;&#36229;&#36807;&#32473;&#23450;&#30340;&#38408;&#20540;&#945;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#20219;&#21153;&#26159;&#23558;&#26679;&#26412;&#20803;&#32032;&#21010;&#20998;&#20026;&#21516;&#36136;&#32676;&#32452;&#30340;&#20219;&#21153;&#12290;&#22823;&#22810;&#25968;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#27169;&#31946;&#19988;&#26412;&#36136;&#19978;&#38590;&#20197;&#24402;&#23646;&#20110;&#26576;&#20010;&#32676;&#32452;&#30340;&#20010;&#20307;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#23558;&#20010;&#20307;&#38169;&#35823;&#20998;&#31867;&#21487;&#33021;&#26159;&#28798;&#38590;&#24615;&#30340;&#65292;&#24212;&#35813;&#23613;&#37327;&#36991;&#20813;&#12290;&#20026;&#20102;&#20445;&#25345;&#38169;&#35823;&#20998;&#31867;&#29575;&#36739;&#20302;&#65292;&#21487;&#20197;&#20915;&#23450;&#21482;&#23545;&#37096;&#20998;&#26679;&#26412;&#36827;&#34892;&#20998;&#31867;&#12290;&#22312;&#30417;&#30563;&#30340;&#24773;&#22659;&#20013;&#65292;&#36825;&#31181;&#26041;&#27861;&#34987;&#31216;&#20026;&#20855;&#26377;&#25918;&#24323;&#36873;&#25321;&#30340;&#20998;&#31867;&#12290;&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#35813;&#26041;&#27861;&#22312;&#26080;&#30417;&#30563;&#28151;&#21512;&#27169;&#22411;&#26694;&#26550;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#26088;&#22312;&#24320;&#21457;&#19968;&#31181;&#26041;&#27861;&#65292;&#20197;&#20445;&#35777;&#34394;&#20551;&#25104;&#21592;&#29575;&#65288;FMR&#65289;&#19981;&#36229;&#36807;&#39044;&#23450;&#30340;&#21517;&#20041;&#27700;&#24179;&#945;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#34917;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#26126;&#30830;&#30340;&#21097;&#20313;&#39033;&#37327;&#21270;FMR&#19982;&#30446;&#26631;&#27700;&#24179;&#945;&#20043;&#38388;&#30340;&#20559;&#24046;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#20998;&#26512;&#12290;&#31243;&#24207;&#36824;&#25552;&#20379;&#20102;&#33258;&#20030;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
The clustering task consists in partitioning elements of a sample into homogeneous groups. Most datasets contain individuals that are ambiguous and intrinsically difficult to attribute to one or another cluster. However, in practical applications, misclassifying individuals is potentially disastrous and should be avoided. To keep the misclassification rate small, one can decide to classify only a part of the sample. In the supervised setting, this approach is well known and referred to as classification with an abstention option. In this paper the approach is revisited in an unsupervised mixture model framework and the purpose is to develop a method that comes with the guarantee that the false membership rate (FMR) does not exceed a pre-defined nominal level $\alpha$. A plug-in procedure is proposed, for which a theoretical analysis is provided, by quantifying the FMR deviation with respect to the target level $\alpha$ with explicit remainder terms. Bootstrap versions of the procedure 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#24494;&#35843;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#39044;&#35757;&#32451;&#30340;&#38477;&#22122;&#33258;&#32534;&#30721;&#22120;&#26469;&#20445;&#30041;&#36755;&#20986;&#32467;&#26500;&#65292;&#20174;&#32780;&#26174;&#33879;&#38477;&#20302;&#39044;&#27979;&#22120;&#30340;&#22797;&#26434;&#24615;&#24182;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2006.16205</link><description>&lt;p&gt;
&#32452;&#21512;&#24494;&#35843;&#65306;&#20923;&#32467;&#39044;&#35757;&#32451;&#30340;&#38477;&#22122;&#33258;&#32534;&#30721;&#22120;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization. (arXiv:2006.16205v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.16205
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#24494;&#35843;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#39044;&#35757;&#32451;&#30340;&#38477;&#22122;&#33258;&#32534;&#30721;&#22120;&#26469;&#20445;&#30041;&#36755;&#20986;&#32467;&#26500;&#65292;&#20174;&#32780;&#26174;&#33879;&#38477;&#20302;&#39044;&#27979;&#22120;&#30340;&#22797;&#26434;&#24615;&#24182;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#21463;&#36755;&#20986;&#26377;&#25928;&#24615;&#32422;&#26463;&#30340;&#32467;&#26500;&#21270;&#36755;&#20986;&#30340;&#39044;&#27979;&#38382;&#39064;&#65292;&#20363;&#22914;&#23558;&#20266;&#20195;&#30721;&#32763;&#35793;&#20026;&#20195;&#30721;&#26102;&#65292;&#20195;&#30721;&#24517;&#39035;&#33021;&#22815;&#32534;&#35793;&#12290;&#34429;&#28982;&#26631;&#35760;&#30340;&#36755;&#20837;-&#36755;&#20986;&#23545;&#24456;&#38590;&#33719;&#21462;&#65292;&#20294;&#26159;&#8220;&#26080;&#26631;&#31614;&#8221;&#30340;&#36755;&#20986;&#65292;&#21363;&#27809;&#26377;&#23545;&#24212;&#36755;&#20837;&#30340;&#36755;&#20986;&#65292;&#26159;&#20813;&#36153;&#25552;&#20379;&#30340;&#65288;&#20363;&#22914;GitHub&#19978;&#30340;&#20195;&#30721;&#65289;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#26377;&#20851;&#36755;&#20986;&#26377;&#25928;&#24615;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#39044;&#35757;&#32451;&#38477;&#22122;&#22120;&#26469;&#25429;&#25417;&#36755;&#20986;&#32467;&#26500;&#65292;&#35813;&#38477;&#22122;&#22120;&#29992;&#20110;&#21435;&#22122;&#26080;&#26631;&#31614;&#36755;&#20986;&#30340;&#25439;&#22351;&#29256;&#26412;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#39044;&#35757;&#32451;&#20043;&#21518;&#36827;&#34892;&#26631;&#20934;&#24494;&#35843;&#20250;&#30772;&#22351;&#37096;&#20998;&#36755;&#20986;&#32467;&#26500;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32452;&#21512;&#24494;&#35843;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#39044;&#35757;&#32451;&#30340;&#38477;&#22122;&#22120;&#19982;&#39044;&#27979;&#22120;&#32452;&#21512;&#36827;&#34892;&#24494;&#35843;&#65292;&#20854;&#20013;&#38477;&#22122;&#22120;&#34987;&#20923;&#32467;&#20197;&#20445;&#30041;&#36755;&#20986;&#32467;&#26500;&#12290;&#23545;&#20110;&#20004;&#23618;ReLU&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32452;&#21512;&#24494;&#35843;&#26174;&#33879;&#38477;&#20302;&#20102;&#39044;&#27979;&#22120;&#30340;&#22797;&#26434;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32452;&#21512;&#24494;&#35843;&#22312;&#20004;&#20010;&#20266;&#20195;&#30721;&#21040;&#20195;&#30721;&#32763;&#35793;&#20219;&#21153;&#19978;&#20248;&#20110;&#26631;&#20934;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;
We focus on prediction problems with structured outputs that are subject to output validity constraints, e.g. pseudocode-to-code translation where the code must compile. While labeled input-output pairs are expensive to obtain, "unlabeled" outputs, i.e. outputs without corresponding inputs, are freely available (e.g. code on GitHub) and provide information about output validity. We can capture the output structure by pre-training a denoiser to denoise corrupted versions of unlabeled outputs. We first show that standard fine-tuning after pre-training destroys some of this structure. We then propose composed fine-tuning, which fine-tunes a predictor composed with the pre-trained denoiser, which is frozen to preserve output structure. For two-layer ReLU networks, we prove that composed fine-tuning significantly reduces the complexity of the predictor, thus improving generalization. Empirically, we show that composed fine-tuning improves over standard fine-tuning on two pseudocode-to-code 
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31070;&#32463;&#35745;&#31639;&#26694;&#26550;&#19979;&#30340;&#24847;&#35782;&#29702;&#35770;&#65292;&#31216;&#20026;&#8220;&#30446;&#26631;&#23545;&#40784;&#30340;&#20869;&#37096;&#34920;&#31034;&#25805;&#20316;&#8221;&#65288;GARIM&#65289;&#12290;&#35813;&#29702;&#35770;&#35748;&#20026;&#24847;&#35782;&#25903;&#25345;&#23545;&#30446;&#26631;&#30456;&#20851;&#30340;&#20869;&#37096;&#34920;&#31034;&#36827;&#34892;&#20027;&#21160;&#25805;&#20316;&#65292;&#20351;&#20854;&#19982;&#36861;&#27714;&#30340;&#30446;&#26631;&#26356;&#21152;&#23545;&#40784;&#65292;&#20174;&#32780;&#22686;&#21152;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/1912.13490</link><description>&lt;p&gt;
&#24847;&#35782;&#30340;&#31070;&#32463;&#35745;&#31639;&#27169;&#22411;&#65306;&#30446;&#26631;&#23545;&#40784;&#30340;&#20869;&#37096;&#34920;&#31034;&#25805;&#20316;&#29702;&#35770;&#65288;GARIM&#65289;
&lt;/p&gt;
&lt;p&gt;
A Neurocomputational Account of Consciousness: The Goal-Aligning Representation Internal Manipulation Theory (GARIM). (arXiv:1912.13490v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1912.13490
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31070;&#32463;&#35745;&#31639;&#26694;&#26550;&#19979;&#30340;&#24847;&#35782;&#29702;&#35770;&#65292;&#31216;&#20026;&#8220;&#30446;&#26631;&#23545;&#40784;&#30340;&#20869;&#37096;&#34920;&#31034;&#25805;&#20316;&#8221;&#65288;GARIM&#65289;&#12290;&#35813;&#29702;&#35770;&#35748;&#20026;&#24847;&#35782;&#25903;&#25345;&#23545;&#30446;&#26631;&#30456;&#20851;&#30340;&#20869;&#37096;&#34920;&#31034;&#36827;&#34892;&#20027;&#21160;&#25805;&#20316;&#65292;&#20351;&#20854;&#19982;&#36861;&#27714;&#30340;&#30446;&#26631;&#26356;&#21152;&#23545;&#40784;&#65292;&#20174;&#32780;&#22686;&#21152;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24847;&#35782;&#20316;&#20026;&#20154;&#31867;&#35748;&#30693;&#30340;&#26680;&#24515;&#35201;&#32032;&#65292;&#24050;&#32463;&#36890;&#36807;&#31070;&#32463;&#31185;&#23398;&#12289;&#24515;&#29702;&#23398;&#12289;&#20154;&#24037;&#26234;&#33021;&#21644;&#26426;&#22120;&#20154;&#25216;&#26415;&#31561;&#22810;&#31181;&#31185;&#23398;&#26041;&#27861;&#36827;&#34892;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#39046;&#22495;&#20043;&#38388;&#30340;&#19981;&#33391;&#25972;&#21512;&#38480;&#21046;&#20102;&#23545;&#24847;&#35782;&#30340;&#23436;&#25972;&#21644;&#28165;&#26224;&#29702;&#35299;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#31070;&#32463;&#35745;&#31639;&#26694;&#26550;&#19979;&#30340;&#8220;&#30446;&#26631;&#23545;&#40784;&#30340;&#20869;&#37096;&#34920;&#31034;&#25805;&#20316;&#8221;&#65288;GARIM&#65289;&#24847;&#35782;&#29702;&#35770;&#65292;&#20026;&#25913;&#21892;&#36825;&#31181;&#25972;&#21512;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;GARIM&#29702;&#35770;&#30340;&#26680;&#24515;&#24605;&#24819;&#26159;&#65292;&#24847;&#35782;&#25903;&#25345;&#23545;&#30446;&#26631;&#30456;&#20851;&#30340;&#20869;&#37096;&#34920;&#31034;&#65288;&#22914;&#19990;&#30028;&#29366;&#24577;&#12289;&#23545;&#35937;&#21644;&#34892;&#20026;&#24207;&#21015;&#65289;&#36827;&#34892;&#20027;&#21160;&#25805;&#20316;&#65292;&#20351;&#23427;&#20204;&#19982;&#36861;&#27714;&#30340;&#30446;&#26631;&#26356;&#21152;&#23545;&#40784;&#12290;&#36825;&#20123;&#25805;&#20316;&#20351;&#24471;&#24847;&#35782;&#20195;&#29702;&#33021;&#22815;&#22312;&#20869;&#37096;&#20135;&#29983;&#20854;&#25152;&#32570;&#20047;&#30340;&#30693;&#35782;&#65292;&#20197;&#24212;&#23545;&#26032;&#26465;&#20214;&#21644;&#30446;&#26631;&#65292;&#20174;&#32780;&#22686;&#21152;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#28789;&#27963;&#24615;&#12290;&#34920;&#31034;&#30340;&#25805;&#20316;&#30001;&#22235;&#20010;&#31070;&#32463;&#21151;&#33021;&#23439;&#31995;&#32479;&#65288;Hierarc...
&lt;/p&gt;
&lt;p&gt;
Consciousness, a central element of human cognition, has been studied with multiple scientific approaches spanning neuroscience, psychology, artificial intelligence and robotics. Unfortunately, poor integration between these fields limits a full and clear understanding of consciousness. Here we contribute to improving this integration by proposing, within a neurocomputational framework, the `Goal-Aligning Representations Internal Manipulation' (GARIM) theory of consciousness. The central idea of the GARIM theory is that consciousness supports the active manipulation of goal-relevant internal representations (e.g., world states, objects, and action sequences), making them more aligned with the goals pursued. These manipulations allow the conscious agent to internally produce the knowledge it lacks to cope with novel conditions and goals, increasing the flexibility of goal-directed behaviour. The manipulation of representations is supported by four neuro-functional macro-systems (hierarc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#20013;&#31038;&#21306;&#25506;&#27979;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#21253;&#25324;&#31934;&#30830;&#12289;&#37096;&#20998;&#21644;&#24369;&#24674;&#22797;&#31561;&#21508;&#31181;&#24674;&#22797;&#35201;&#27714;&#65292;&#24182;&#25506;&#35752;&#20102;&#30456;&#21464;&#38408;&#20540;&#12289;SNR-&#20114;&#20449;&#24687;&#26435;&#34913;&#20197;&#21450;&#20449;&#24687;&#35770;&#21644;&#35745;&#31639;&#38408;&#20540;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/1703.10146</link><description>&lt;p&gt;
&#31038;&#21306;&#25506;&#27979;&#21644;&#38543;&#26426;&#22359;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Community Detection and Stochastic Block Models. (arXiv:1703.10146v3 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1703.10146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#20013;&#31038;&#21306;&#25506;&#27979;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#21253;&#25324;&#31934;&#30830;&#12289;&#37096;&#20998;&#21644;&#24369;&#24674;&#22797;&#31561;&#21508;&#31181;&#24674;&#22797;&#35201;&#27714;&#65292;&#24182;&#25506;&#35752;&#20102;&#30456;&#21464;&#38408;&#20540;&#12289;SNR-&#20114;&#20449;&#24687;&#26435;&#34913;&#20197;&#21450;&#20449;&#24687;&#35770;&#21644;&#35745;&#31639;&#38408;&#20540;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#26159;&#19968;&#20010;&#38543;&#26426;&#22270;&#27169;&#22411;&#65292;&#20854;&#20013;&#19981;&#21516;&#32452;&#30340;&#39030;&#28857;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#36830;&#25509;&#12290;&#23427;&#34987;&#24191;&#27867;&#24212;&#29992;&#20316;&#20026;&#30740;&#31350;&#32858;&#31867;&#21644;&#31038;&#21306;&#25506;&#27979;&#30340;&#19968;&#20010;&#20856;&#22411;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#30740;&#31350;&#32452;&#21512;&#32479;&#35745;&#23398;&#21644;&#26356;&#19968;&#33324;&#30340;&#25968;&#25454;&#31185;&#23398;&#20013;&#20986;&#29616;&#30340;&#20449;&#24687;&#29702;&#35770;&#21644;&#35745;&#31639;&#26435;&#34913;&#30340;&#32933;&#27779;&#39046;&#22495;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#36817;&#26399;&#20851;&#20110;SBM&#20013;&#31038;&#21306;&#25506;&#27979;&#30340;&#22522;&#26412;&#38480;&#21046;&#30340;&#21457;&#23637;&#65292;&#21253;&#25324;&#20449;&#24687;&#35770;&#21644;&#35745;&#31639;&#26435;&#34913;&#65292;&#20197;&#21450;&#31934;&#30830;&#12289;&#37096;&#20998;&#21644;&#24369;&#24674;&#22797;&#31561;&#21508;&#31181;&#24674;&#22797;&#35201;&#27714;&#12290;&#35752;&#35770;&#30340;&#20027;&#35201;&#32467;&#26524;&#21253;&#25324;Chernoff-Hellinger&#38408;&#20540;&#19979;&#30340;&#31934;&#30830;&#24674;&#22797;&#30340;&#30456;&#21464;&#65292;Kesten-Stigum&#38408;&#20540;&#19979;&#30340;&#24369;&#24674;&#22797;&#30340;&#30456;&#21464;&#65292;&#37096;&#20998;&#24674;&#22797;&#30340;&#26368;&#20339;SNR-&#20114;&#20449;&#24687;&#26435;&#34913;&#65292;&#20197;&#21450;&#20449;&#24687;&#35770;&#21644;&#35745;&#31639;&#38408;&#20540;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic block model (SBM) is a random graph model with different group of vertices connecting differently. It is widely employed as a canonical model to study clustering and community detection, and provides a fertile ground to study the information-theoretic and computational tradeoffs that arise in combinatorial statistics and more generally data science.  This monograph surveys the recent developments that establish the fundamental limits for community detection in the SBM, both with respect to information-theoretic and computational tradeoffs, and for various recovery requirements such as exact, partial and weak recovery. The main results discussed are the phase transitions for exact recovery at the Chernoff-Hellinger threshold, the phase transition for weak recovery at the Kesten-Stigum threshold, the optimal SNR-mutual information tradeoff for partial recovery, and the gap between information-theoretic and computational thresholds.  The monograph gives a principled derivat
&lt;/p&gt;</description></item></channel></rss>