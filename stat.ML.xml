<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#20302;&#22352;&#26631;&#24230;&#20989;&#25968;&#22312;&#39640;&#32500;&#27010;&#29575;&#27979;&#24230;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;&#26222;&#36941;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#35299;&#26041;&#27861;&#26469;&#20351;&#20854;&#26356;&#24191;&#27867;&#36866;&#29992;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#36890;&#36807;&#22122;&#22768;&#20449;&#36947;&#36827;&#34892;&#38543;&#26426;&#20449;&#21495;&#23384;&#22312;&#26816;&#27979;&#20013;&#30340;&#25104;&#21151;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.07862</link><description>&lt;p&gt;
&#20302;&#22352;&#26631;&#24230;&#31639;&#27861; I&#65306;&#20551;&#35774;&#26816;&#39564;&#30340;&#35745;&#31639;&#38376;&#38480;&#30340;&#26222;&#36866;&#24615;
&lt;/p&gt;
&lt;p&gt;
Low coordinate degree algorithms I: Universality of computational thresholds for hypothesis testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07862
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#20302;&#22352;&#26631;&#24230;&#20989;&#25968;&#22312;&#39640;&#32500;&#27010;&#29575;&#27979;&#24230;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;&#26222;&#36941;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#35299;&#26041;&#27861;&#26469;&#20351;&#20854;&#26356;&#24191;&#27867;&#36866;&#29992;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#36890;&#36807;&#22122;&#22768;&#20449;&#36947;&#36827;&#34892;&#38543;&#26426;&#20449;&#21495;&#23384;&#22312;&#26816;&#27979;&#20013;&#30340;&#25104;&#21151;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20302;&#22352;&#26631;&#24230;&#20989;&#25968;&#65288;LCDF&#65289;&#20309;&#26102;&#21487;&#20197;&#22312;&#39640;&#32500;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#36827;&#34892;&#20551;&#35774;&#26816;&#39564; -- LCDF&#26159;&#20381;&#36182;&#20110;&#21521;&#37327;&#30340;&#19968;&#20010;&#23567;&#23376;&#38598;&#30340;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#21512;&#65292;&#36825;&#26159;&#23545;&#20302;&#27425;&#22810;&#39033;&#24335;&#65288;LDP&#65289;&#30340;&#19968;&#20010;&#25512; generalization&#65292;LDP&#26159;&#26368;&#36817;&#25991;&#29486;&#20013;&#24191;&#27867;&#29992;&#20110;&#20316;&#20026;&#25152;&#26377;&#32479;&#35745;&#23398;&#21644;&#20248;&#21270;&#20219;&#21153;&#20013;&#26377;&#25928;&#31639;&#27861;&#30340;&#20195;&#29702;&#30340;&#19968;&#20010;&#31867;&#12290;&#25105;&#20204;&#30340;LCDF&#20998;&#26512;&#19981;&#21516;&#20110;LDP&#35745;&#31639;&#20013;&#20351;&#29992;&#30340;&#27491;&#20132;&#22810;&#39033;&#24335;&#20998;&#35299;&#65292;&#32780;&#26159;&#22522;&#20110;Efron-Stein&#25110;ANOVA&#20998;&#35299;&#65292;&#20351;&#20854;&#36866;&#29992;&#33539;&#22260;&#26356;&#24191;&#27867;&#12290;&#20316;&#20026;&#31034;&#20363;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36947;&#26222;&#36866;&#24615;&#65292;&#25351;&#20986;LCDF&#22312;&#36890;&#36807;&#22122;&#22768;&#20449;&#36947;&#36827;&#34892;&#20805;&#20998;&#8220;&#31232;&#30095;&#8221;&#38543;&#26426;&#20449;&#21495;&#23384;&#22312;&#20551;&#35774;&#26816;&#39564;&#26102;&#30340;&#25104;&#21151;&#65306;LCDF&#30340;&#21151;&#25928;&#20165;&#20165;&#21462;&#20915;&#20110;&#36890;&#36947;&#65292;&#23545;&#20110;&#21253;&#25324;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07862v1 Announce Type: cross  Abstract: We study when low coordinate degree functions (LCDF) -- linear combinations of functions depending on small subsets of entries of a vector -- can hypothesis test between high-dimensional probability measures. These functions are a generalization, proposed in Hopkins' 2018 thesis but seldom studied since, of low degree polynomials (LDP), a class widely used in recent literature as a proxy for all efficient algorithms for tasks in statistics and optimization. Instead of the orthogonal polynomial decompositions used in LDP calculations, our analysis of LCDF is based on the Efron-Stein or ANOVA decomposition, making it much more broadly applicable. By way of illustration, we prove channel universality for the success of LCDF in testing for the presence of sufficiently "dilute" random signals through noisy channels: the efficacy of LCDF depends on the channel only through the scalar Fisher information for a class of channels including nearl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FairRR&#30340;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38543;&#26426;&#21709;&#24212;&#26694;&#26550;&#20013;&#20462;&#25913;&#21709;&#24212;&#21464;&#37327;&#30340;&#26368;&#20248;&#35774;&#35745;&#30697;&#38453;&#65292;&#30452;&#25509;&#25511;&#21046;&#32676;&#20307;&#20844;&#24179;&#24615;&#30340;&#24230;&#37327;&#65292;&#20174;&#32780;&#20135;&#29983;&#20986;&#33394;&#30340;&#19979;&#28216;&#27169;&#22411;&#25928;&#29992;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.07780</link><description>&lt;p&gt;
&#20844;&#24179;RR&#65306;&#36890;&#36807;&#38543;&#26426;&#21709;&#24212;&#23454;&#29616;&#32676;&#20307;&#20844;&#24179;&#30340;&#39044;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
FairRR: Pre-Processing for Group Fairness through Randomized Response
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FairRR&#30340;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38543;&#26426;&#21709;&#24212;&#26694;&#26550;&#20013;&#20462;&#25913;&#21709;&#24212;&#21464;&#37327;&#30340;&#26368;&#20248;&#35774;&#35745;&#30697;&#38453;&#65292;&#30452;&#25509;&#25511;&#21046;&#32676;&#20307;&#20844;&#24179;&#24615;&#30340;&#24230;&#37327;&#65292;&#20174;&#32780;&#20135;&#29983;&#20986;&#33394;&#30340;&#19979;&#28216;&#27169;&#22411;&#25928;&#29992;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#37325;&#35201;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#20351;&#29992;&#26085;&#30410;&#22686;&#22810;&#65292;&#36825;&#20419;&#20351;&#20154;&#20204;&#24320;&#22987;&#30740;&#31350;&#36825;&#20123;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#12290;&#34429;&#28982;&#22312;&#22788;&#29702;&#36807;&#31243;&#21644;&#21518;&#22788;&#29702;&#35774;&#32622;&#20013;&#24050;&#32463;&#36827;&#34892;&#20102;&#22823;&#37327;&#24037;&#20316;&#26469;&#30740;&#31350;&#32676;&#20307;&#20844;&#24179;&#24615;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#33021;&#22815;&#20174;&#29702;&#35770;&#19978;&#23558;&#36825;&#20123;&#32467;&#26524;&#19982;&#39044;&#22788;&#29702;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#12290;&#26412;&#25991;&#25552;&#20986;&#65292;&#23454;&#29616;&#19979;&#28216;&#27169;&#22411;&#20013;&#30340;&#32676;&#20307;&#20844;&#24179;&#24615;&#21487;&#20197;&#34987;&#24418;&#24335;&#21270;&#20026;&#22312;&#38543;&#26426;&#21709;&#24212;&#26694;&#26550;&#20013;&#20462;&#25913;&#21709;&#24212;&#21464;&#37327;&#30340;&#26368;&#20248;&#35774;&#35745;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#32676;&#20307;&#20844;&#24179;&#24615;&#30340;&#24230;&#37327;&#21487;&#20197;&#36890;&#36807;&#26368;&#20248;&#27169;&#22411;&#25928;&#29992;&#30452;&#25509;&#25511;&#21046;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FairRR&#30340;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20135;&#29983;&#20986;&#33394;&#30340;&#19979;&#28216;&#27169;&#22411;&#25928;&#29992;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07780v1 Announce Type: cross  Abstract: The increasing usage of machine learning models in consequential decision-making processes has spurred research into the fairness of these systems. While significant work has been done to study group fairness in the in-processing and post-processing setting, there has been little that theoretically connects these results to the pre-processing domain. This paper proposes that achieving group fairness in downstream models can be formulated as finding the optimal design matrix in which to modify a response variable in a Randomized Response framework. We show that measures of group fairness can be directly controlled for with optimal model utility, proposing a pre-processing algorithm called FairRR that yields excellent downstream model utility and fairness.
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Probabilistic Easy Variational Causal Effect (PEACE)&#30340;&#20989;&#25968;&#65292;&#21487;&#20197;&#27979;&#37327;X&#23545;Y&#30340;&#30452;&#25509;&#22240;&#26524;&#25928;&#24212;&#65292;&#36866;&#29992;&#20110;&#36830;&#32493;&#21644;&#31163;&#25955;&#24773;&#20917;&#65292;&#36890;&#36807;&#31649;&#29702;&#27010;&#29575;&#23494;&#24230;&#20540;&#24378;&#24230;$d\ge 0$&#26469;&#23454;&#29616;&#24178;&#39044;&#12290;</title><link>https://arxiv.org/abs/2403.07745</link><description>&lt;p&gt;
&#27010;&#29575;&#26131;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Easy Variational Causal Effect
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07745
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Probabilistic Easy Variational Causal Effect (PEACE)&#30340;&#20989;&#25968;&#65292;&#21487;&#20197;&#27979;&#37327;X&#23545;Y&#30340;&#30452;&#25509;&#22240;&#26524;&#25928;&#24212;&#65292;&#36866;&#29992;&#20110;&#36830;&#32493;&#21644;&#31163;&#25955;&#24773;&#20917;&#65292;&#36890;&#36807;&#31649;&#29702;&#27010;&#29575;&#23494;&#24230;&#20540;&#24378;&#24230;$d\ge 0$&#26469;&#23454;&#29616;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#38543;&#26426;&#21521;&#37327;$X$&#21644;$Z$&#65292;&#20197;&#21450;$Y=g(X,Z)$&#30340;&#24773;&#20917;&#12290;&#19968;&#26041;&#38754;&#65292;&#23545;&#20110;&#36830;&#32493;&#30340;$X$&#21644;$Z$&#65292;&#36890;&#36807;&#20351;&#29992;&#24635;&#21464;&#24046;&#21644;$g$&#30340;&#36890;&#37327;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#20010;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#33021;&#22815;&#22788;&#29702;&#24191;&#27867;&#22240;&#26524;&#38382;&#39064;&#39046;&#22495;&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#20851;&#27880;&#19968;&#20010;&#31216;&#20026;Probabilistic Easy Variational Causal Effect (PEACE)&#30340;&#20989;&#25968;&#65292;&#23427;&#21487;&#20197;&#27979;&#37327;$X$&#23545;$Y$&#30340;&#30452;&#25509;&#22240;&#26524;&#25928;&#24212;&#65292;&#32780;&#21516;&#26102;&#25913;&#21464;$X$&#30340;&#20540;&#65292;&#20294;&#20445;&#25345;$Z$&#30340;&#20540;&#19981;&#21464;&#12290;PEACE&#26159;&#20851;&#20110;$d\ge 0$&#30340;&#19968;&#20010;&#20989;&#25968;&#65292;&#31649;&#29702;&#30528;&#27010;&#29575;&#23494;&#24230;&#20540;$f(x|z)$&#30340;&#24378;&#24230;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#23558;&#19978;&#36848;&#24605;&#24819;&#25512;&#24191;&#21040;&#31163;&#25955;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20854;&#19982;&#36830;&#32493;&#24773;&#20917;&#30340;&#20860;&#23481;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#27979;&#24230;&#35770;&#27010;&#24565;&#30740;&#31350;&#20102;PEACE&#30340;&#19968;&#20123;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#21487;&#36776;&#35782;&#24615;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07745v1 Announce Type: cross  Abstract: Let $X$ and $Z$ be random vectors, and $Y=g(X,Z)$. In this paper, on the one hand, for the case that $X$ and $Z$ are continuous, by using the ideas from the total variation and the flux of $g$, we develop a point of view in causal inference capable of dealing with a broad domain of causal problems. Indeed, we focus on a function, called Probabilistic Easy Variational Causal Effect (PEACE), which can measure the direct causal effect of $X$ on $Y$ with respect to continuously and interventionally changing the values of $X$ while keeping the value of $Z$ constant. PEACE is a function of $d\ge 0$, which is a degree managing the strengths of probability density values $f(x|z)$. On the other hand, we generalize the above idea for the discrete case and show its compatibility with the continuous case. Further, we investigate some properties of PEACE using measure theoretical concepts. Furthermore, we provide some identifiability criteria and s
&lt;/p&gt;</description></item><item><title>HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;</title><link>https://arxiv.org/abs/2403.07735</link><description>&lt;p&gt;
HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;
&lt;/p&gt;
&lt;p&gt;
The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07735
&lt;/p&gt;
&lt;p&gt;
HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kernel&#25216;&#26415;&#26159;&#25968;&#25454;&#31185;&#23398;&#21644;&#32479;&#35745;&#23398;&#20013;&#26368;&#26377;&#24433;&#21709;&#21147;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#19982;&#26680;&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#33021;&#22815;&#32534;&#30721;$M\ge 2$&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#12290;&#22312;&#26680;&#19978;&#20381;&#36182;&#30340;&#26368;&#26222;&#36941;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#21487;&#33021;&#26159;&#25152;&#35859;&#30340;Hilbert-Schmidt&#29420;&#31435;&#24615;&#20934;&#21017;(HSIC; &#22312;&#32479;&#35745;&#25991;&#29486;&#20013;&#20063;&#31216;&#20026;&#36317;&#31163;&#21327;&#26041;&#24046;)&#12290;&#23613;&#31649;&#33258;&#36817;&#20108;&#21313;&#24180;&#21069;&#24341;&#20837;&#20197;&#26469;&#24050;&#32463;&#26377;&#21508;&#31181;&#29616;&#26377;&#30340;&#35774;&#35745;&#30340;HSIC&#20272;&#35745;&#37327;&#65292;HSIC&#21487;&#20197;&#34987;&#20272;&#35745;&#30340;&#36895;&#24230;&#30340;&#22522;&#26412;&#38382;&#39064;&#20173;&#28982;&#26159;&#24320;&#25918;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#21253;&#21547;&#20855;&#26377;&#36830;&#32493;&#26377;&#30028;&#24179;&#31227;&#19981;&#21464;&#29305;&#24449;&#26680;&#30340;&#39640;&#26031;Borel&#27979;&#24230;&#22312;$\mathbb R^d$&#19978;&#30340;HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#26368;&#20248;&#36895;&#29575;&#26159;$\mathcal O\!\left(n^{-1/2}\right)$&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#35768;&#22810;&#26041;&#38754;&#22312;&#26497;&#23567;&#21270;&#24847;&#20041;&#19978;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07735v1 Announce Type: cross  Abstract: Kernel techniques are among the most influential approaches in data science and statistics. Under mild conditions, the reproducing kernel Hilbert space associated to a kernel is capable of encoding the independence of $M\ge 2$ random variables. Probably the most widespread independence measure relying on kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also referred to as distance covariance in the statistics literature). Despite various existing HSIC estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which HSIC can be estimated is still open. In this work, we prove that the minimax optimal rate of HSIC estimation on $\mathbb R^d$ for Borel measures containing the Gaussians with continuous bounded translation-invariant characteristic kernels is $\mathcal O\!\left(n^{-1/2}\right)$. Specifically, our result implies the optimality in the minimax sense of many 
&lt;/p&gt;</description></item><item><title>CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;</title><link>https://arxiv.org/abs/2403.07728</link><description>&lt;p&gt;
CAS: &#19968;&#31181;&#20855;&#26377;FCR&#25511;&#21046;&#30340;&#22312;&#32447;&#36873;&#25321;&#24615;&#31526;&#21512;&#39044;&#27979;&#30340;&#36890;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
CAS: A General Algorithm for Online Selective Conformal Prediction with FCR Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07728
&lt;/p&gt;
&lt;p&gt;
CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#26041;&#24335;&#19979;&#21518;&#36873;&#25321;&#39044;&#27979;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#23558;&#36164;&#28304;&#32791;&#36153;&#22312;&#19981;&#37325;&#35201;&#30340;&#21333;&#20301;&#19978;&#65292;&#22312;&#25253;&#21578;&#20854;&#39044;&#27979;&#21306;&#38388;&#20043;&#21069;&#23545;&#24403;&#21069;&#20010;&#20307;&#36827;&#34892;&#21021;&#27493;&#36873;&#25321;&#22312;&#22312;&#32447;&#39044;&#27979;&#20219;&#21153;&#20013;&#26159;&#24120;&#35265;&#19988;&#26377;&#24847;&#20041;&#30340;&#12290;&#30001;&#20110;&#22312;&#32447;&#36873;&#25321;&#23548;&#33268;&#25152;&#36873;&#39044;&#27979;&#21306;&#38388;&#20013;&#23384;&#22312;&#26102;&#38388;&#22810;&#37325;&#24615;&#65292;&#22240;&#27492;&#25511;&#21046;&#23454;&#26102;&#35823;&#35206;&#30422;&#38472;&#36848;&#29575;&#65288;FCR&#65289;&#26469;&#27979;&#37327;&#24179;&#22343;&#35823;&#35206;&#30422;&#35823;&#24046;&#26159;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;CAS&#65288;&#36866;&#24212;&#24615;&#36873;&#25321;&#21518;&#26657;&#20934;&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#21253;&#35065;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#21644;&#22312;&#32447;&#36873;&#25321;&#35268;&#21017;&#65292;&#20197;&#36755;&#20986;&#21518;&#36873;&#25321;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#22914;&#26524;&#36873;&#25321;&#20102;&#24403;&#21069;&#20010;&#20307;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#21382;&#21490;&#25968;&#25454;&#36827;&#34892;&#33258;&#36866;&#24212;&#36873;&#25321;&#26469;&#26500;&#24314;&#26657;&#20934;&#38598;&#65292;&#28982;&#21518;&#20026;&#26410;&#35266;&#23519;&#21040;&#30340;&#26631;&#31614;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#20026;&#26657;&#20934;&#38598;&#25552;&#20379;&#20102;&#21487;&#34892;&#30340;&#26500;&#36896;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07728v1 Announce Type: cross  Abstract: We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) to measure the averaged miscoverage error. We develop a general framework named CAS (Calibration after Adaptive Selection) that can wrap around any prediction model and online selection rule to output post-selection prediction intervals. If the current individual is selected, we first perform an adaptive selection on historical data to construct a calibration set, then output a conformal prediction interval for the unobserved label. We provide tractable constructions for the calibration set for 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#30452;&#25509;&#20998;&#26512;&#26368;&#20248;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#30340;&#34892;&#20026;&#65292;&#20197;&#24179;&#34913;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.07724</link><description>&lt;p&gt;
&#22312;&#25968;&#25454;&#38480;&#21046;&#30340;&#20108;&#20998;&#31867;&#20013;&#24179;&#34913;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Balancing Fairness and Accuracy in Data-Restricted Binary Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07724
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#30452;&#25509;&#20998;&#26512;&#26368;&#20248;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#30340;&#34892;&#20026;&#65292;&#20197;&#24179;&#34913;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22788;&#29702;&#25935;&#24863;&#20449;&#24687;&#30340;&#24212;&#29992;&#21487;&#33021;&#23545;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20998;&#31867;&#22120;&#21487;&#29992;&#25968;&#25454;&#35774;&#32622;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#26694;&#26550;&#65292;&#27169;&#25311;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#22312;&#22235;&#31181;&#23454;&#38469;&#24773;&#26223;&#19979;&#25506;&#35752;&#21487;&#29992;&#20110;&#20998;&#26512;&#30340;&#25968;&#25454;&#31867;&#22411;&#12290;&#19982;&#20808;&#21069;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#32463;&#35757;&#32451;&#20197;&#38544;&#24335;&#23398;&#20064;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#12289;&#31867;&#21035;&#26631;&#31614;&#21644;&#25935;&#24863;&#23646;&#24615;&#30340;&#28508;&#22312;&#20998;&#24067;&#30340;&#35780;&#20998;&#20989;&#25968;&#30340;&#36755;&#20986;&#26469;&#32771;&#34385;&#36825;&#31181;&#26435;&#34913;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#30452;&#25509;&#36890;&#36807;&#20174;&#25968;&#25454;&#38598;&#26412;&#36523;&#26500;&#24314;&#30340;&#31163;&#25955;&#36817;&#20284;&#26469;&#20998;&#26512;&#26368;&#20248;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#22312;&#36825;&#20010;&#28508;&#22312;&#20998;&#24067;&#19978;&#30340;&#34892;&#20026;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#21046;&#23450;&#22810;&#20010;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20197;&#26356;&#22909;&#22320;&#24179;&#34913;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07724v1 Announce Type: cross  Abstract: Applications that deal with sensitive information may have restrictions placed on the data available to a machine learning (ML) classifier. For example, in some applications, a classifier may not have direct access to sensitive attributes, affecting its ability to produce accurate and fair decisions. This paper proposes a framework that models the trade-off between accuracy and fairness under four practical scenarios that dictate the type of data available for analysis. Prior works examine this trade-off by analyzing the outputs of a scoring function that has been trained to implicitly learn the underlying distribution of the feature vector, class label, and sensitive attribute of a dataset. In contrast, our framework directly analyzes the behavior of the optimal Bayesian classifier on this underlying distribution by constructing a discrete approximation it from the dataset itself. This approach enables us to formulate multiple convex 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#30340;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24357;&#21512;&#20102;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#19982;&#29616;&#26377;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.07723</link><description>&lt;p&gt;
&#20851;&#20110;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Last-Iterate Convergence of Shuffling Gradient Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07723
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#30340;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24357;&#21512;&#20102;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#19982;&#29616;&#26377;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#65292;&#20063;&#34987;&#31216;&#20026;&#26080;&#26367;&#25442;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#65292;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#29305;&#21035;&#21253;&#25324;&#19977;&#31181;&#27969;&#34892;&#31639;&#27861;&#65306;Random Reshuffle&#65288;RR&#65289;&#12289;Shuffle Once&#65288;SO&#65289;&#21644;Incremental Gradient&#65288;IG&#65289;&#12290;&#19982;&#32463;&#39564;&#25104;&#21151;&#30456;&#27604;&#65292;&#38271;&#26399;&#20197;&#26469;&#23545;&#20110;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#30340;&#29702;&#35770;&#20445;&#35777;&#24182;&#19981;&#20805;&#20998;&#20102;&#35299;&#12290;&#26368;&#36817;&#65292;&#21482;&#20026;&#20984;&#20989;&#25968;&#30340;&#24179;&#22343;&#36845;&#20195;&#21644;&#24378;&#20984;&#38382;&#39064;&#30340;&#26368;&#21518;&#36845;&#20195;&#65288;&#20197;&#24179;&#26041;&#36317;&#31163;&#20026;&#24230;&#37327;&#65289;&#24314;&#31435;&#20102;&#25910;&#25947;&#36895;&#29575;&#12290;&#28982;&#32780;&#65292;&#24403;&#23558;&#20989;&#25968;&#20540;&#24046;&#20316;&#20026;&#25910;&#25947;&#20934;&#21017;&#26102;&#65292;&#29616;&#26377;&#29702;&#35770;&#26080;&#27861;&#35299;&#37322;&#22312;&#19981;&#21516;&#35774;&#32622;&#20013;&#65288;&#20363;&#22914;&#21463;&#32422;&#26463;&#30340;&#20248;&#21270;&#65289;&#26368;&#21518;&#36845;&#20195;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#31181;&#23454;&#36341;&#19982;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#38024;&#23545;&#30446;&#26631;&#20989;&#25968;&#35777;&#26126;&#20102;&#27927;&#29260;&#26799;&#24230;&#26041;&#27861;&#26368;&#21518;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07723v1 Announce Type: new  Abstract: Shuffling gradient methods, which are also known as stochastic gradient descent (SGD) without replacement, are widely implemented in practice, particularly including three popular algorithms: Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG). Compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understanding for a long time. Until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). However, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). To bridge this gap between practice and theory, we prove last-iterate convergence rates for shuffling gradient methods with respect to the objectiv
&lt;/p&gt;</description></item><item><title>ISG&#26041;&#27861;&#30456;&#23545;&#20110;&#22522;&#20934;&#26041;&#27861;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#37319;&#26679;&#25928;&#29575;&#65292;&#29305;&#21035;&#26159;&#22312;&#20855;&#26377;&#24378;&#30456;&#20851;&#24615;&#25110;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>https://arxiv.org/abs/2403.07495</link><description>&lt;p&gt;
&#20026;HMC&#35843;&#25972;&#23545;&#35282;&#27604;&#20363;&#30697;&#38453;
&lt;/p&gt;
&lt;p&gt;
Tuning diagonal scale matrices for HMC
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07495
&lt;/p&gt;
&lt;p&gt;
ISG&#26041;&#27861;&#30456;&#23545;&#20110;&#22522;&#20934;&#26041;&#27861;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#37319;&#26679;&#25928;&#29575;&#65292;&#29305;&#21035;&#26159;&#22312;&#20855;&#26377;&#24378;&#30456;&#20851;&#24615;&#25110;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35752;&#35770;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#33258;&#36866;&#24212;&#35843;&#25972;HMC&#23545;&#35282;&#27604;&#20363;&#30697;&#38453;&#30340;&#26041;&#27861;&#12290;&#23558;&#26681;&#25454;&#20272;&#35745;&#36793;&#38469;&#26631;&#20934;&#24046;&#36827;&#34892;&#32553;&#25918;&#30340;&#24120;&#35265;&#20570;&#27861;&#20316;&#20026;&#22522;&#20934;&#12290;&#26681;&#25454;&#24179;&#22343;&#23545;&#25968;&#30446;&#26631;&#26799;&#24230;&#65288;ISG&#65289;&#36827;&#34892;&#32553;&#25918;&#65292;&#20197;&#21450;&#19968;&#20010;&#26088;&#22312;&#20351;&#24213;&#23618;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#31359;&#36234;&#21508;&#33258;&#20013;&#20301;&#25968;&#30340;&#39057;&#29575;&#22312;&#32500;&#24230;&#19978;&#22343;&#21248;&#30340;&#32553;&#25918;&#26041;&#27861;&#34987;&#35270;&#20026;&#26367;&#20195;&#26041;&#26696;&#12290;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;&#65292;ISG&#26041;&#27861;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#27604;&#22522;&#20934;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#29305;&#21035;&#26159;&#22312;&#23384;&#22312;&#24378;&#30456;&#20851;&#24615;&#25110;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#12290;ISG&#26041;&#27861;&#20063;&#26131;&#20110;&#23454;&#29616;&#65292;&#35745;&#31639;&#25104;&#26412;&#20302;&#65292;&#30456;&#23545;&#31616;&#21333;&#22320;&#21253;&#21547;&#22312;&#33258;&#21160;&#35843;&#25972;&#20195;&#30721;&#20013;&#20316;&#20026;&#22522;&#20934;&#20570;&#27861;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07495v1 Announce Type: cross  Abstract: Three approaches for adaptively tuning diagonal scale matrices for HMC are discussed and compared. The common practice of scaling according to estimated marginal standard deviations is taken as a benchmark. Scaling according to the mean log-target gradient (ISG), and a scaling method targeting that the frequency of when the underlying Hamiltonian dynamics crosses the respective medians should be uniform across dimensions, are taken as alternatives. Numerical studies suggest that the ISG method leads in many cases to more efficient sampling than the benchmark, in particular in cases with strong correlations or non-linear dependencies. The ISG method is also easy to implement, computationally cheap and would be relatively simple to include in automatically tuned codes as an alternative to the benchmark practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#25512;&#36827;&#32422;&#26463;&#30340;&#38750;&#20984;&#24615;&#30340;&#29702;&#35770;&#35265;&#35299;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#23545;&#30456;&#20851;&#23398;&#20064;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.07471</link><description>&lt;p&gt;
&#26377;&#20851;&#26576;&#20123;&#25512;&#36827;&#32422;&#26463;&#30340;&#38750;&#20984;&#24615;&#21450;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the nonconvexity of some push-forward constraints and its consequences in machine learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#25512;&#36827;&#32422;&#26463;&#30340;&#38750;&#20984;&#24615;&#30340;&#29702;&#35770;&#35265;&#35299;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#23545;&#30456;&#20851;&#23398;&#20064;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
push-forward&#25805;&#20316;&#20351;&#20154;&#33021;&#22815;&#36890;&#36807;&#30830;&#23450;&#24615;&#26144;&#23556;&#37325;&#26032;&#20998;&#37197;&#27010;&#29575;&#27979;&#24230;&#12290;&#23427;&#22312;&#32479;&#35745;&#21644;&#20248;&#21270;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65306;&#35768;&#22810;&#23398;&#20064;&#38382;&#39064;&#65288;&#29305;&#21035;&#26159;&#26469;&#33258;&#26368;&#20248;&#36755;&#36816;&#12289;&#29983;&#25104;&#24314;&#27169;&#21644;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#65289;&#21253;&#25324;&#20316;&#20026;&#27169;&#22411;&#19978;&#30340;&#25512;&#36827;&#26465;&#20214;&#25110;&#22788;&#32602;&#30340;&#32422;&#26463;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#32570;&#20047;&#20851;&#20110;&#36825;&#20123;&#32422;&#26463;&#30340;&#65288;&#38750;&#65289;&#20984;&#24615;&#21450;&#20854;&#23545;&#30456;&#20851;&#23398;&#20064;&#38382;&#39064;&#30340;&#24433;&#21709;&#30340;&#19968;&#33324;&#29702;&#35770;&#35265;&#35299;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#22312;&#31532;&#19968;&#37096;&#20998;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#32452;&#20989;&#25968;&#65288;&#23558;&#19968;&#20010;&#27010;&#29575;&#27979;&#24230;&#20256;&#36755;&#21040;&#21478;&#19968;&#20010;&#30340;&#26144;&#23556;&#65307;&#35825;&#23548;&#19981;&#21516;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30456;&#31561;&#36755;&#20986;&#20998;&#24067;&#30340;&#26144;&#23556;&#65289;&#30340;&#65288;&#38750;&#65289;&#20984;&#24615;&#30340;&#19968;&#31995;&#21015;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12290;&#36825;&#31361;&#20986;&#20102;&#23545;&#20110;&#22823;&#22810;&#25968;&#27010;&#29575;&#27979;&#24230;&#32780;&#35328;&#65292;&#36825;&#20123;&#25512;&#36827;&#32422;&#26463;&#26159;&#38750;&#20984;&#30340;&#12290;&#22312;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#19968;&#32467;&#26524;&#22914;&#20309;&#26263;&#31034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07471v1 Announce Type: cross  Abstract: The push-forward operation enables one to redistribute a probability measure through a deterministic map. It plays a key role in statistics and optimization: many learning problems (notably from optimal transport, generative modeling, and algorithmic fairness) include constraints or penalties framed as push-forward conditions on the model. However, the literature lacks general theoretical insights on the (non)convexity of such constraints and its consequences on the associated learning problems. This paper aims at filling this gap. In a first part, we provide a range of sufficient and necessary conditions for the (non)convexity of two sets of functions: the maps transporting one probability measure to another; the maps inducing equal output distributions across distinct probability measures. This highlights that for most probability measures, these push-forward constraints are not convex. In a second time, we show how this result impli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25490;&#21517;&#30340;&#26032;&#30340;&#38750;&#21442;&#25968;&#26694;&#26550;&#26469;&#27979;&#35797;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;ROC&#20998;&#26512;&#21644;&#20108;&#37096;&#25490;&#21517;&#65292;&#20855;&#26377;&#36229;&#36234;&#31454;&#20105;&#23545;&#25163;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2403.07464</link><description>&lt;p&gt;
&#22522;&#20110;&#25490;&#21517;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
On Ranking-based Tests of Independence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25490;&#21517;&#30340;&#26032;&#30340;&#38750;&#21442;&#25968;&#26694;&#26550;&#26469;&#27979;&#35797;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;ROC&#20998;&#26512;&#21644;&#20108;&#37096;&#25490;&#21517;&#65292;&#20855;&#26377;&#36229;&#36234;&#31454;&#20105;&#23545;&#25163;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#26694;&#26550;&#65292;&#29992;&#20110;&#22522;&#20110;&#8220;&#25509;&#25910;&#22120;&#25805;&#20316;&#29305;&#24615;&#8221;&#65288;ROC&#65289;&#20998;&#26512;&#21644;&#20108;&#37096;&#25490;&#21517;&#26469;&#27979;&#35797;&#20855;&#26377;&#26410;&#30693;&#36793;&#38469;&#20998;&#24067;H(dx)&#21644;G(dy)&#20197;&#21450;&#32852;&#21512;&#20998;&#24067;F(dx dy)&#30340;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;X&#21644;Y&#30340;&#29420;&#31435;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#22522;&#26412;&#21407;&#29702;&#22312;&#20110;&#65292;&#29420;&#31435;&#24615;&#20551;&#35774;H_0&#22312;&#20174;&#20108;&#37096;&#25490;&#21517;&#31639;&#27861;&#24471;&#21040;&#30340;&#19982;&#20998;&#24067;&#23545;(H &#8855; G&#65292;F)&#30456;&#20851;&#32852;&#30340;&#26368;&#20339;&#35780;&#20998;&#20989;&#25968;&#20855;&#26377;&#20559;&#31163;&#21333;&#20301;&#27491;&#26041;&#24418;&#20027;&#23545;&#35282;&#32447;&#30340;ROC&#26354;&#32447;&#26102;&#24517;&#28982;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;&#31209;&#32479;&#35745;&#37327;&#65292;&#28085;&#30422;&#20102;&#22312;ROC&#31354;&#38388;&#20013;&#20559;&#31163;&#23545;&#35282;&#32447;&#30340;&#35768;&#22810;&#26041;&#24335;&#65292;&#20197;&#26500;&#24314;&#29420;&#31435;&#24615;&#26816;&#39564;&#12290;&#38500;&#20102;&#20854;&#26497;&#22823;&#30340;&#28789;&#27963;&#24615;&#22806;&#65292;&#36825;&#31181;&#26032;&#26041;&#27861;&#20855;&#26377;&#36828;&#36229;&#20854;&#31454;&#20105;&#23545;&#25163;&#30340;&#29702;&#35770;&#29305;&#24615;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#22312;&#38750;&#28176;&#36817;&#24773;&#20917;&#19979;&#30340;&#20004;&#20010;t
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07464v1 Announce Type: cross  Abstract: In this paper we develop a novel nonparametric framework to test the independence of two random variables $\mathbf{X}$ and $\mathbf{Y}$ with unknown respective marginals $H(dx)$ and $G(dy)$ and joint distribution $F(dx dy)$, based on {\it Receiver Operating Characteristic} (ROC) analysis and bipartite ranking. The rationale behind our approach relies on the fact that, the independence hypothesis $\mathcal{H}\_0$ is necessarily false as soon as the optimal scoring function related to the pair of distributions $(H\otimes G,\; F)$, obtained from a bipartite ranking algorithm, has a ROC curve that deviates from the main diagonal of the unit square.We consider a wide class of rank statistics encompassing many ways of deviating from the diagonal in the ROC space to build tests of independence. Beyond its great flexibility, this new method has theoretical properties that far surpass those of its competitors. Nonasymptotic bounds for the two t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#22810;&#35270;&#22270;&#33258;&#32534;&#30721;&#22120;&#25968;&#23398;&#26694;&#26550;&#65292;&#25972;&#21512;&#20102;&#21508;&#31181;&#20844;&#24335;&#65292;&#24182;&#25299;&#23637;&#20102; \texttt{multi-view-AE} &#24211;&#30340;&#25991;&#26723;&#21644;&#21151;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.07456</link><description>&lt;p&gt;
&#20351;&#29992; multi-view-AE &#24211;&#30340;&#22810;&#35270;&#22270;&#33258;&#32534;&#30721;&#22120;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
A tutorial on multi-view autoencoders using the multi-view-AE library
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07456
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#22810;&#35270;&#22270;&#33258;&#32534;&#30721;&#22120;&#25968;&#23398;&#26694;&#26550;&#65292;&#25972;&#21512;&#20102;&#21508;&#31181;&#20844;&#24335;&#65292;&#24182;&#25299;&#23637;&#20102; \texttt{multi-view-AE} &#24211;&#30340;&#25991;&#26723;&#21644;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#24314;&#27169;&#25968;&#25454;&#30340;&#22810;&#20010;&#27169;&#24577;&#65288;&#25110;&#35270;&#22270;&#65289;&#20197;&#20415;&#29702;&#35299;&#27169;&#24577;&#20043;&#38388;&#30340;&#20851;&#31995;&#25110;&#29983;&#25104;&#32570;&#22833;&#25968;&#25454;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22810;&#35270;&#22270;&#33258;&#32534;&#30721;&#22120;&#22240;&#20854;&#33021;&#22815;&#36866;&#24212;&#21644;&#28789;&#27963;&#24314;&#27169;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#33021;&#21147;&#32780;&#22791;&#21463;&#20851;&#27880;&#65292;&#34920;&#26126;&#20854;&#20855;&#26377;&#26681;&#25454;&#25163;&#22836;&#25968;&#25454;&#29305;&#24449;&#35843;&#25972;&#26041;&#27861;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#22810;&#35270;&#22270;&#33258;&#32534;&#30721;&#22120;&#23384;&#22312;&#19968;&#33268;&#24615;&#31526;&#21495;&#26631;&#27880;&#19981;&#19968;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#36890;&#24120;&#20351;&#29992;&#19981;&#21516;&#30340;&#32534;&#30721;&#26694;&#26550;&#23454;&#29616;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#22810;&#35270;&#22270;&#33258;&#32534;&#30721;&#22120;&#25968;&#23398;&#26694;&#26550;&#65292;&#25972;&#21512;&#20102;&#23427;&#20204;&#30340;&#20844;&#24335;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#27599;&#20010;&#27169;&#22411;&#21160;&#26426;&#21644;&#29702;&#35770;&#20248;&#21183;&#30340;&#35265;&#35299;&#12290;&#20026;&#20102;&#26041;&#20415;&#35775;&#38382;&#21644;&#23454;&#38469;&#20351;&#29992;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#20808;&#21069;&#20171;&#32461;&#30340; multi-view-AE &#24211;&#30340;&#25991;&#26723;&#21644;&#21151;&#33021;&#12290;&#35813;&#24211;&#25552;&#20379;&#20102; Python &#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07456v1 Announce Type: new  Abstract: There has been a growing interest in recent years in modelling multiple modalities (or views) of data to for example, understand the relationship between modalities or to generate missing data. Multi-view autoencoders have gained significant traction for their adaptability and versatility in modelling multi-modal data, demonstrating an ability to tailor their approach to suit the characteristics of the data at hand. However, most multi-view autoencoders have inconsistent notation and are often implemented using different coding frameworks. To address this, we present a unified mathematical framework for multi-view autoencoders, consolidating their formulations. Moreover, we offer insights into the motivation and theoretical advantages of each model. To facilitate accessibility and practical use, we extend the documentation and functionality of the previously introduced \texttt{multi-view-AE} library. This library offers Python implementa
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#32467;&#26500;&#28151;&#21512;&#27010;&#29575;&#20998;&#24067;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;SBI&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.07454</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#23616;&#37096;&#32447;&#24615;&#26144;&#23556;&#36827;&#34892;&#24555;&#36895;&#12289;&#20934;&#30830;&#21644;&#36731;&#37327;&#32423;&#30340;&#39034;&#24207;&#20223;&#30495;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07454
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#32467;&#26500;&#28151;&#21512;&#27010;&#29575;&#20998;&#24067;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;SBI&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07454v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#38024;&#23545;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#22797;&#26434;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21487;&#20197;&#20351;&#29992;&#22810;&#27425;&#35843;&#29992;&#35745;&#31639;&#27169;&#25311;&#22120;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#12290; &#36825;&#20123;&#26041;&#27861;&#34987;&#32479;&#31216;&#20026;&#8220;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#8221;&#65288;SBI&#65289;&#12290; &#26368;&#36817;&#30340;SBI&#26041;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#25552;&#20379;&#36817;&#20284;&#20294;&#34920;&#36798;&#20016;&#23500;&#30340;&#26500;&#36896;&#65292;&#29992;&#20110;&#19981;&#21487;&#29992;&#30340;&#20284;&#28982;&#20989;&#25968;&#21644;&#21518;&#39564;&#20998;&#24067;&#12290; &#28982;&#32780;&#65292;&#23427;&#20204;&#36890;&#24120;&#26080;&#27861;&#23454;&#29616;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#38656;&#27714;&#20043;&#38388;&#30340;&#26368;&#20339;&#25240;&#34935;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#20379;&#20284;&#28982;&#20989;&#25968;&#21644;&#21518;&#39564;&#20998;&#24067;&#36817;&#20284;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#20351;&#29992;&#32467;&#26500;&#21270;&#30340;&#27010;&#29575;&#20998;&#24067;&#28151;&#21512;&#29289;&#12290; &#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;NN&#30340;SBI&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20135;&#29983;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#30340;&#21516;&#26102;&#65292;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#12290; &#25105;&#20204;&#22312;SBI&#25991;&#29486;&#20013;&#30340;&#20960;&#20010;&#22522;&#20934;&#27169;&#22411;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07454v1 Announce Type: cross  Abstract: Bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. These approaches are collectively known as "simulation-based inference" (SBI). Recent SBI methods have made use of neural networks (NN) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. However, they do not generally achieve an optimal trade-off between accuracy and computational demand. In this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. Our approach produces accurate posterior inference when compared to state-of-the-art NN-based SBI methods, while exhibiting a much smaller computational footprint. We illustrate our results on several benchmark models from the SBI literature.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#30340;&#20195;&#29702;&#26041;&#27861;&#65292;&#21033;&#29992;&#36817;&#31471;&#22240;&#26524;&#23398;&#20064;&#25216;&#26415;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#22312;&#19981;&#24674;&#22797;&#25110;&#24314;&#27169;&#28508;&#22312;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#36890;&#36807;&#20195;&#29702;&#21464;&#37327;&#23454;&#29616;&#20102;&#23545;&#20998;&#24067;&#36716;&#31227;&#30340;&#36866;&#24212;&#12290;</title><link>https://arxiv.org/abs/2403.07442</link><description>&lt;p&gt;
&#38024;&#23545;&#22495;&#33258;&#36866;&#24212;&#30340;&#20195;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Proxy Methods for Domain Adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07442
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#30340;&#20195;&#29702;&#26041;&#27861;&#65292;&#21033;&#29992;&#36817;&#31471;&#22240;&#26524;&#23398;&#20064;&#25216;&#26415;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#22312;&#19981;&#24674;&#22797;&#25110;&#24314;&#27169;&#28508;&#22312;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#36890;&#36807;&#20195;&#29702;&#21464;&#37327;&#23454;&#29616;&#20102;&#23545;&#20998;&#24067;&#36716;&#31227;&#30340;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#65292;&#36825;&#31181;&#36716;&#31227;&#26159;&#30001;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#28508;&#22312;&#21464;&#37327;&#20998;&#24067;&#21457;&#29983;&#25913;&#21464;&#65292;&#23548;&#33268;&#21327;&#21464;&#37327;&#21644;&#26631;&#31614;&#37117;&#34987;&#28151;&#28102;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26082;&#19981;&#36866;&#29992;&#21327;&#21464;&#37327;&#36716;&#31227;&#20063;&#19981;&#36866;&#29992;&#26631;&#31614;&#36716;&#31227;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;&#37319;&#29992;&#20102;&#36817;&#31471;&#22240;&#26524;&#23398;&#20064;&#65292;&#19968;&#31181;&#22312;&#21487;&#33719;&#24471;&#26410;&#35266;&#23519;&#28151;&#28102;&#21464;&#37327;&#20195;&#29702;&#30340;&#35774;&#32622;&#20013;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20195;&#29702;&#21464;&#37327;&#20801;&#35768;&#36866;&#24212;&#20998;&#24067;&#36716;&#31227;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#24674;&#22797;&#25110;&#24314;&#27169;&#28508;&#22312;&#21464;&#37327;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#24773;&#20917;&#65292;(i) &#27010;&#24565;&#29942;&#39048;&#65306;&#35266;&#23519;&#21040;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#27010;&#24565;&#8221;&#21464;&#37327;&#65292;&#23427;&#22312;&#21327;&#21464;&#37327;&#21644;&#26631;&#31614;&#20043;&#38388;&#36215;&#21040;&#20013;&#20171;&#20316;&#29992;&#65307;(ii) &#22810;&#39046;&#22495;&#65306;&#21487;&#29992;&#26469;&#33258;&#22810;&#20010;&#28304;&#39046;&#22495;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#20854;&#20013;&#27599;&#20010;&#28304;&#39046;&#22495;&#23637;&#31034;&#20102;&#23545;&#28508;&#22312;&#28151;&#26434;&#21464;&#37327;&#30340;&#19981;&#21516;&#20998;&#24067;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340; k
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07442v1 Announce Type: new  Abstract: We study the problem of domain adaptation under distribution shift, where the shift is due to a change in the distribution of an unobserved, latent variable that confounds both the covariates and the labels. In this setting, neither the covariate shift nor the label shift assumptions apply. Our approach to adaptation employs proximal causal learning, a technique for estimating causal effects in settings where proxies of unobserved confounders are available. We demonstrate that proxy variables allow for adaptation to distribution shift without explicitly recovering or modeling latent variables. We consider two settings, (i) Concept Bottleneck: an additional ''concept'' variable is observed that mediates the relationship between the covariates and labels; (ii) Multi-domain: training data from multiple source domains is available, where each source domain exhibits a different distribution over the latent confounder. We develop a two-stage k
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#22810;&#20010;&#20027;&#25104;&#20998;&#20998;&#26512;&#30740;&#31350;&#30340;&#30693;&#35782;&#36716;&#31227;&#31639;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#22810;&#20010;&#30740;&#31350;&#20013;&#20849;&#20139;&#30340;&#23376;&#31354;&#38388;&#20449;&#24687;&#26469;&#22686;&#24378;&#30446;&#26631;PCA&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.07431</link><description>&lt;p&gt;
&#36328;&#22810;&#20010;&#20027;&#25104;&#20998;&#20998;&#26512;&#30740;&#31350;&#30340;&#30693;&#35782;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Knowledge Transfer across Multiple Principal Component Analysis Studies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07431
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#22810;&#20010;&#20027;&#25104;&#20998;&#20998;&#26512;&#30740;&#31350;&#30340;&#30693;&#35782;&#36716;&#31227;&#31639;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#22810;&#20010;&#30740;&#31350;&#20013;&#20849;&#20139;&#30340;&#23376;&#31354;&#38388;&#20449;&#24687;&#26469;&#22686;&#24378;&#30446;&#26631;PCA&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transfer learning&#22312;&#32479;&#35745;&#39046;&#22495;&#24341;&#36215;&#20102;&#26497;&#22823;&#20852;&#36259;&#12290;&#26412;&#25991;&#20851;&#27880;&#20110;&#26080;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#30340;&#30693;&#35782;&#36716;&#31227;&#65292;&#19982;&#25991;&#29486;&#20013;&#30340;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#30456;&#23545;&#27604;&#12290;&#22312;&#32473;&#23450;&#21487;&#36716;&#31227;&#30340;&#28304;&#20154;&#21475;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#27493;&#30340;&#36716;&#31227;&#23398;&#20064;&#31639;&#27861;&#65292;&#20174;&#22810;&#20010;&#28304;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#30740;&#31350;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#65292;&#20174;&#32780;&#22686;&#24378;&#30446;&#26631;PCA&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#12290;&#31532;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#21517;&#20026;Grassmannian barycenter&#30340;&#26041;&#27861;&#65292;&#25972;&#21512;&#36328;&#22810;&#20010;&#30740;&#31350;&#20849;&#20139;&#30340;&#23376;&#31354;&#38388;&#20449;&#24687;&#65292;&#32780;&#19981;&#26159;&#30452;&#25509;&#22312;&#27719;&#24635;&#25968;&#25454;&#38598;&#19978;&#25191;&#34892;PCA&#12290;&#25552;&#20986;&#30340;Grassmannian barycenter&#26041;&#27861;&#22312;&#26356;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#35745;&#31639;&#20248;&#21183;&#12290;&#28982;&#21518;&#65292;&#31532;&#19968;&#27493;&#24471;&#21040;&#30340;&#20849;&#20139;&#23376;&#31354;&#38388;&#30340;&#20272;&#35745;&#22120;&#36827;&#19968;&#27493;&#29992;&#20110;&#20272;&#35745;&#31532;&#20108;&#27493;&#20013;&#30340;&#30446;&#26631;&#31169;&#26377;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07431v1 Announce Type: cross  Abstract: Transfer learning has aroused great interest in the statistical community. In this article, we focus on knowledge transfer for unsupervised learning tasks in contrast to the supervised learning tasks in the literature. Given the transferable source populations, we propose a two-step transfer learning algorithm to extract useful information from multiple source principal component analysis (PCA) studies, thereby enhancing estimation accuracy for the target PCA task. In the first step, we integrate the shared subspace information across multiple studies by a proposed method named as Grassmannian barycenter, instead of directly performing PCA on the pooled dataset. The proposed Grassmannian barycenter method enjoys robustness and computational advantages in more general cases. Then the resulting estimator for the shared subspace from the first step is further utilized to estimate the target private subspace in the second step. Our theoret
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#22797;&#26434;&#24615;&#65292;&#25581;&#31034;&#20102;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#21253;&#25324;&#26041;&#21521;&#25506;&#32034;&#21644;&#26041;&#21521;&#27491;&#21017;&#21270;&#12290;</title><link>https://arxiv.org/abs/2403.07379</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#29305;&#24449;&#65306;&#38271;&#24230;&#12289;&#25296;&#28857;&#21644;&#27515;&#32993;&#21516;
&lt;/p&gt;
&lt;p&gt;
Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07379
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#22797;&#26434;&#24615;&#65292;&#25581;&#31034;&#20102;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#21253;&#25324;&#26041;&#21521;&#25506;&#32034;&#21644;&#26041;&#21521;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#26032;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#26426;&#21046;&#65292;&#36890;&#36807;&#20998;&#26512;&#20854;&#20248;&#21270;&#36712;&#36857;&#20013;&#21253;&#21547;&#30340;&#20016;&#23500;&#21442;&#25968;&#32467;&#26500;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20123;&#20851;&#20110;&#20248;&#21270;&#36712;&#36857;&#22797;&#26434;&#24615;&#30340;&#33258;&#28982;&#27010;&#24565;&#65292;&#26082;&#23450;&#24615;&#21448;&#23450;&#37327;&#22320;&#25581;&#31034;&#20102;&#21508;&#31181;&#20248;&#21270;&#36873;&#25321;&#65288;&#22914;&#21160;&#37327;&#12289;&#26435;&#37325;&#34928;&#20943;&#21644;&#25209;&#22823;&#23567;&#65289;&#20043;&#38388;&#25152;&#28041;&#21450;&#30340;&#20869;&#22312;&#24494;&#22937;&#21644;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#27010;&#24565;&#26469;&#25552;&#20379;&#20851;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26412;&#36136;&#30340;&#20851;&#38190;&#29305;&#24449;&#65306;&#20309;&#26102;&#39034;&#21033;&#36827;&#34892;&#65292;&#20309;&#26102;&#38519;&#20837;&#27515;&#32993;&#21516;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#25105;&#20204;&#30340;&#36712;&#36857;&#35270;&#35282;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#21160;&#37327;&#21644;&#26435;&#37325;&#34928;&#20943;&#20043;&#38388;&#20419;&#36827;&#26041;&#21521;&#25506;&#32034;&#30340;&#20132;&#32455;&#34892;&#20026;&#65292;&#20197;&#21450;&#20854;&#20182;&#19968;&#20123;&#34892;&#20026;&#30340;&#26041;&#21521;&#27491;&#21017;&#21270;&#34892;&#20026;&#12290;&#25105;&#20204;&#22312;&#22823;&#35268;&#27169;&#35270;&#35273;&#21644;&#35821;&#35328;&#35774;&#32622;&#20013;&#36827;&#34892;&#23454;&#39564;&#65292;&#21253;&#25324;&#20855;&#26377;&#26368;&#22810;120&#20159;&#20010;&#21442;&#25968;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07379v1 Announce Type: cross  Abstract: We propose a fresh take on understanding the mechanisms of neural networks by analyzing the rich structure of parameters contained within their optimization trajectories. Towards this end, we introduce some natural notions of the complexity of optimization trajectories, both qualitative and quantitative, which reveal the inherent nuance and interplay involved between various optimization choices, such as momentum, weight decay, and batch size. We use them to provide key hallmarks about the nature of optimization in deep neural networks: when it goes right, and when it finds itself in a dead end. Further, thanks to our trajectory perspective, we uncover an intertwined behaviour of momentum and weight decay that promotes directional exploration, as well as a directional regularization behaviour of some others. We perform experiments over large-scale vision and language settings, including large language models (LLMs) with up to 12 billio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#37327;&#21270;&#20102;&#32676;&#20307;&#19981;&#24179;&#34913;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#12289;&#25910;&#25947;&#36895;&#29575;&#21644;&#24179;&#22343;&#20197;&#21450;&#32676;&#20307;&#32423;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#39318;&#27425;&#25552;&#20379;&#20102;ERM&#22312;&#32676;&#20307;&#32423;&#27867;&#21270;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2403.07310</link><description>&lt;p&gt;
&#25512;&#21160;&#23569;&#25968;&#32676;&#20307;&#20221;&#39069;&#22914;&#20309;&#24433;&#21709;&#27867;&#21270;&#65311;&#20851;&#20110;&#19968;&#23618;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#32676;&#20307;&#19981;&#24179;&#34913;&#19978;&#30340;&#29702;&#35770;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How does promoting the minority fraction affect generalization? A theoretical study of the one-hidden-layer neural network on group imbalance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#37327;&#21270;&#20102;&#32676;&#20307;&#19981;&#24179;&#34913;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#12289;&#25910;&#25947;&#36895;&#29575;&#21644;&#24179;&#22343;&#20197;&#21450;&#32676;&#20307;&#32423;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#39318;&#27425;&#25552;&#20379;&#20102;ERM&#22312;&#32676;&#20307;&#32423;&#27867;&#21270;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32676;&#20307;&#19981;&#24179;&#34913;&#19968;&#30452;&#26159;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#20013;&#24050;&#30693;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#21462;&#24471;&#30340;&#39640;&#24179;&#22343;&#20934;&#30830;&#29575;&#20276;&#38543;&#30528;&#23569;&#25968;&#32676;&#20307;&#30340;&#20302;&#20934;&#30830;&#29575;&#12290;&#23613;&#31649;&#26377;&#31639;&#27861;&#21162;&#21147;&#25913;&#21892;&#23569;&#25968;&#32676;&#20307;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#20851;&#20110;ERM&#22312;&#21508;&#20010;&#32676;&#20307;&#19978;&#30340;&#29702;&#35770;&#27867;&#21270;&#20998;&#26512;&#20173;&#28982;&#38590;&#20197;&#23454;&#29616;&#12290;&#36890;&#36807;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#34920;&#36798;&#32676;&#20307;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#26412;&#25991;&#37327;&#21270;&#20102;&#21508;&#20010;&#32676;&#20307;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#12289;&#25910;&#25947;&#36895;&#29575;&#20197;&#21450;&#24179;&#22343;&#21644;&#32676;&#20307;&#32423;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#29702;&#35770;&#26694;&#26550;&#38598;&#20013;&#22312;&#20351;&#29992;&#19968;&#23618;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20108;&#20998;&#31867;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;ERM&#22312;&#32676;&#20307;&#32423;&#27867;&#21270;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#38500;&#20102;&#36890;&#24120;&#30740;&#31350;&#30340;&#24179;&#22343;&#27867;&#21270;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#30340;&#19968;&#20123;&#35265;&#35299;&#21253;&#25324;&#24403;&#25152;&#26377;&#32676;&#20307;&#32423;&#21327;&#26041;&#24046;&#37117;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07310v1 Announce Type: cross  Abstract: Group imbalance has been a known problem in empirical risk minimization (ERM), where the achieved high average accuracy is accompanied by low accuracy in a minority group. Despite algorithmic efforts to improve the minority group accuracy, a theoretical generalization analysis of ERM on individual groups remains elusive. By formulating the group imbalance problem with the Gaussian Mixture Model, this paper quantifies the impact of individual groups on the sample complexity, the convergence rate, and the average and group-level testing performance. Although our theoretical framework is centered on binary classification using a one-hidden-layer neural network, to the best of our knowledge, we provide the first theoretical analysis of the group-level generalization of ERM in addition to the commonly studied average generalization performance. Sample insights of our theoretical results include that when all group-level co-variance is in th
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#20960;&#20046;&#25554;&#20540;&#32447;&#24615;&#22238;&#24402;&#22120;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#33539;&#25968;&#22686;&#38271;&#36805;&#36895;&#19988;&#25554;&#20540;&#19982;&#27867;&#21270;&#20043;&#38388;&#23384;&#22312;&#26126;&#30830;&#30340;&#26435;&#34913;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.07264</link><description>&lt;p&gt;
&#36817;&#25554;&#20540;&#22120;&#65306;&#24555;&#36895;&#33539;&#25968;&#22686;&#38271;&#19982;&#25554;&#20540;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Near-Interpolators: Rapid Norm Growth and the Trade-Off between Interpolation and Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07264
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20960;&#20046;&#25554;&#20540;&#32447;&#24615;&#22238;&#24402;&#22120;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#33539;&#25968;&#22686;&#38271;&#36805;&#36895;&#19988;&#25554;&#20540;&#19982;&#27867;&#21270;&#20043;&#38388;&#23384;&#22312;&#26126;&#30830;&#30340;&#26435;&#34913;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20960;&#20046;&#25554;&#20540;&#32447;&#24615;&#22238;&#24402;&#22120;&#30340;&#27867;&#21270;&#33021;&#21147;&#65306;&#20854;&#35757;&#32451;&#35823;&#24046;&#964;&#20026;&#27491;&#20294;&#24456;&#23567;&#65292;&#21363;&#20302;&#20110;&#22122;&#22768;&#27700;&#24179;&#12290;&#22312;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#20551;&#35774;&#21644;&#23545;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#931;&#36827;&#34892;&#29305;&#24449;&#34928;&#20943;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#36817;&#25554;&#20540;&#22120;&#37117;&#34920;&#29616;&#20986;&#24555;&#36895;&#30340;&#33539;&#25968;&#22686;&#38271;&#65306;&#23545;&#20110;&#22266;&#23450;&#30340;&#964;&#65292;&#946;&#30340;&#24179;&#26041;&#8741;&#946;&#8741;2 &#30340;&#22686;&#38271;&#29575;&#20026;&#937;(n^&#945;)&#65292;&#20854;&#20013;n&#20026;&#26679;&#26412;&#25968;&#37327;&#65292;&#945;&gt;1&#26159;&#29305;&#24449;&#34928;&#20943;&#30340;&#25351;&#25968;&#65292;&#21363;&#955;_i(&#931;)&#8764;i^(-&#945;)&#12290;&#36825;&#24847;&#21619;&#30528;&#29616;&#26377;&#30340;&#29420;&#31435;&#20110;&#25968;&#25454;&#30340;&#33539;&#25968;&#30028;&#38480;&#24517;&#23450;&#26494;&#24347;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22312;&#30456;&#21516;&#30340;&#21306;&#38388;&#20869;&#65292;&#25105;&#20204;&#31934;&#30830;&#22320;&#21051;&#30011;&#20102;&#25554;&#20540;&#21644;&#27867;&#21270;&#20043;&#38388;&#30340;&#28176;&#36817;&#26435;&#34913;&#12290;&#25105;&#20204;&#30340;&#34920;&#24449;&#25581;&#31034;&#20986;&#20102;&#22823;&#22810;&#25968;&#29616;&#26377;&#33539;&#25968;&#30028;&#38480;&#26159;&#23485;&#26494;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07264v1 Announce Type: cross  Abstract: We study the generalization capability of nearly-interpolating linear regressors: $\boldsymbol{\beta}$'s whose training error $\tau$ is positive but small, i.e., below the noise floor. Under a random matrix theoretic assumption on the data distribution and an eigendecay assumption on the data covariance matrix $\boldsymbol{\Sigma}$, we demonstrate that any near-interpolator exhibits rapid norm growth: for $\tau$ fixed, $\boldsymbol{\beta}$ has squared $\ell_2$-norm $\mathbb{E}[\|{\boldsymbol{\beta}}\|_{2}^{2}] = \Omega(n^{\alpha})$ where $n$ is the number of samples and $\alpha &gt;1$ is the exponent of the eigendecay, i.e., $\lambda_i(\boldsymbol{\Sigma}) \sim i^{-\alpha}$. This implies that existing data-independent norm-based bounds are necessarily loose. On the other hand, in the same regime we precisely characterize the asymptotic trade-off between interpolation and generalization. Our characterization reveals that larger norm scalin
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#26041;&#27861;&#65292;&#26412;&#25991;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#65292;&#20445;&#35777;&#20102;&#23545;&#35937;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;&#65292;&#21253;&#25324;&#20102;&#38169;&#35823;&#20998;&#31867;&#30340;&#23545;&#35937;&#65292;&#21516;&#26102;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.07263</link><description>&lt;p&gt;
&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#23454;&#29616;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Adaptive Bounding Box Uncertainties via Two-Step Conformal Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07263
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#26041;&#27861;&#65292;&#26412;&#25991;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#65292;&#20445;&#35777;&#20102;&#23545;&#35937;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;&#65292;&#21253;&#25324;&#20102;&#38169;&#35823;&#20998;&#31867;&#30340;&#23545;&#35937;&#65292;&#21516;&#26102;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#20687;&#33258;&#21160;&#39550;&#39542;&#36825;&#26679;&#30340;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#32771;&#34385;&#20026;&#22810;&#29289;&#20307;&#26816;&#27979;&#37327;&#21270;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#24418;&#24335;&#39044;&#27979;&#26469;&#33719;&#24471;&#20855;&#26377;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#29289;&#20307;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#12290;&#36825;&#26679;&#20570;&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#36793;&#30028;&#26694;&#30340;&#39044;&#27979;&#21462;&#20915;&#20110;&#29289;&#20307;&#30340;&#31867;&#21035;&#26631;&#31614;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#27493;&#24418;&#24335;&#26041;&#27861;&#65292;&#23558;&#23545;&#39044;&#27979;&#31867;&#21035;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#21040;&#36793;&#30028;&#26694;&#30340;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#20013;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#30340;&#24418;&#24335;&#35206;&#30422;&#20445;&#35777;&#30340;&#26377;&#25928;&#24615;&#26356;&#24191;&#27867;&#65292;&#21253;&#25324;&#20102;&#34987;&#38169;&#35823;&#20998;&#31867;&#30340;&#29289;&#20307;&#65292;&#30830;&#20445;&#23427;&#20204;&#22312;&#38656;&#35201;&#26368;&#22823;&#23433;&#20840;&#20445;&#35777;&#26102;&#30340;&#23454;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26032;&#39062;&#30340;&#38598;&#25104;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#24418;&#24335;&#65292;&#20197;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07263v1 Announce Type: cross  Abstract: Quantifying a model's predictive uncertainty is essential for safety-critical applications such as autonomous driving. We consider quantifying such uncertainty for multi-object detection. In particular, we leverage conformal prediction to obtain uncertainty intervals with guaranteed coverage for object bounding boxes. One challenge in doing so is that bounding box predictions are conditioned on the object's class label. Thus, we develop a novel two-step conformal approach that propagates uncertainty in predicted class labels into the uncertainty intervals for the bounding boxes. This broadens the validity of our conformal coverage guarantees to include incorrectly classified objects, ensuring their usefulness when maximal safety assurances are required. Moreover, we investigate novel ensemble and quantile regression formulations to ensure the bounding box intervals are adaptive to object size, leading to a more balanced coverage across
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#25910;&#25947;&#24847;&#35782;&#30340;&#22686;&#37327;&#26102;&#38388;&#33218;&#22312;&#32447;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#26102;&#24179;&#34913;&#20219;&#21153;&#22870;&#21169;&#21644;&#25506;&#32034;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2403.07213</link><description>&lt;p&gt;
&#36873;&#25321;&#21738;&#20010;LLM&#65311;&#20855;&#26377;&#25910;&#25947;&#24847;&#35782;&#30340;&#22686;&#37327;&#26102;&#38388;&#33218;&#30340;&#22312;&#32447;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Which LLM to Play? Convergence-Aware Online Model Selection with Time-Increasing Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07213
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#25910;&#25947;&#24847;&#35782;&#30340;&#22686;&#37327;&#26102;&#38388;&#33218;&#22312;&#32447;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#26102;&#24179;&#34913;&#20219;&#21153;&#22870;&#21169;&#21644;&#25506;&#32034;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Web-based&#24212;&#29992;&#65292;&#22914;&#32842;&#22825;&#26426;&#22120;&#20154;&#12289;&#25628;&#32034;&#24341;&#25806;&#21644;&#26032;&#38395;&#25512;&#33616;&#65292;&#38543;&#30528;LLMs&#30340;&#26085;&#30410;&#26222;&#21450;&#65292;&#22312;&#35268;&#27169;&#21644;&#22797;&#26434;&#24615;&#19978;&#32487;&#32493;&#22686;&#38271;&#12290;&#22312;&#32447;&#27169;&#22411;&#36873;&#25321;&#22240;&#38656;&#35201;&#22312;&#24179;&#34913;&#20219;&#21153;&#22870;&#21169;&#21644;&#25506;&#32034;&#25104;&#26412;&#30340;&#21516;&#26102;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#32780;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#20256;&#32479;&#30340;&#36873;&#25321;&#26041;&#27861;&#36890;&#24120;&#22312;&#36873;&#25321;&#19968;&#20010;&#27169;&#22411;&#20043;&#21069;&#35780;&#20272;&#27599;&#20010;&#20505;&#36873;&#27169;&#22411;&#65292;&#38543;&#30528;&#35757;&#32451;&#21644;&#24494;&#35843;LLMs&#25104;&#26412;&#30340;&#19978;&#21319;&#65292;&#36825;&#20123;&#26041;&#27861;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#12290;&#27492;&#22806;&#65292;&#20998;&#37197;&#36807;&#22810;&#36164;&#28304;&#21435;&#25506;&#32034;&#34920;&#29616;&#19981;&#20339;&#30340;&#27169;&#22411;&#26159;&#19981;&#21487;&#21462;&#30340;&#12290;&#23613;&#31649;&#19968;&#20123;&#26368;&#26032;&#30340;&#24037;&#20316;&#21033;&#29992;&#22312;&#32447;&#33218;&#31639;&#27861;&#26469;&#31649;&#29702;&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#36825;&#31181;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#24573;&#35270;&#20102;&#22686;&#38271;&#28982;&#21518;&#25910;&#25947;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07213v1 Announce Type: new  Abstract: Web-based applications such as chatbots, search engines and news recommendations continue to grow in scale and complexity with the recent surge in the adoption of LLMs. Online model selection has thus garnered increasing attention due to the need to choose the best model among a diverse set while balancing task reward and exploration cost. Organizations faces decisions like whether to employ a costly API-based LLM or a locally finetuned small LLM, weighing cost against performance. Traditional selection methods often evaluate every candidate model before choosing one, which are becoming impractical given the rising costs of training and finetuning LLMs. Moreover, it is undesirable to allocate excessive resources towards exploring poor-performing models. While some recent works leverage online bandit algorithm to manage such exploration-exploitation trade-off in model selection, they tend to overlook the increasing-then-converging trend i
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#29702;&#35770;&#19978;&#23545;&#28369;&#21160;&#31383;&#21475;&#39640;&#26031;&#26680;&#23494;&#24230;&#20272;&#35745;&#22120;&#36827;&#34892;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#36873;&#25321;&#26368;&#20248;&#26435;&#37325;&#24207;&#21015;&#30340;&#21407;&#21017;&#25351;&#21335;&#65292;&#36890;&#36807;&#23454;&#35777;&#35777;&#25454;&#34920;&#26126;&#35813;&#21152;&#26435;&#26041;&#26696;&#30456;&#27604;&#21551;&#21457;&#24335;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#36319;&#36394;&#24615;&#33021;</title><link>https://arxiv.org/abs/2403.07207</link><description>&lt;p&gt;
&#20351;&#29992;&#29702;&#35770;&#19978;&#26368;&#20248;&#30340;&#28369;&#21160;&#31383;&#21475;&#26041;&#27861;&#36319;&#36394;&#21160;&#24577;&#39640;&#26031;&#23494;&#24230;
&lt;/p&gt;
&lt;p&gt;
Tracking Dynamic Gaussian Density with a Theoretically Optimal Sliding Window Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07207
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29702;&#35770;&#19978;&#23545;&#28369;&#21160;&#31383;&#21475;&#39640;&#26031;&#26680;&#23494;&#24230;&#20272;&#35745;&#22120;&#36827;&#34892;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#36873;&#25321;&#26368;&#20248;&#26435;&#37325;&#24207;&#21015;&#30340;&#21407;&#21017;&#25351;&#21335;&#65292;&#36890;&#36807;&#23454;&#35777;&#35777;&#25454;&#34920;&#26126;&#35813;&#21152;&#26435;&#26041;&#26696;&#30456;&#27604;&#21551;&#21457;&#24335;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#36319;&#36394;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#23494;&#24230;&#20272;&#35745;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#21253;&#25324;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#20449;&#21495;&#22788;&#29702;&#12290;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#19968;&#31181;&#27969;&#34892;&#26041;&#27861;&#26159;&#8220;&#28369;&#21160;&#31383;&#21475;&#8221;&#26680;&#23494;&#24230;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#23384;&#22312;&#22810;&#31181;&#19981;&#21516;&#30340;&#23454;&#29616;&#65292;&#36825;&#20123;&#23454;&#29616;&#20351;&#29992;&#21551;&#21457;&#24335;&#23450;&#20041;&#30340;&#21152;&#26435;&#24207;&#21015;&#29992;&#20110;&#35266;&#27979;&#25968;&#25454;&#12290;&#20294;&#26159;&#65292;&#26435;&#37325;&#24207;&#21015;&#26159;&#24433;&#21709;&#20272;&#35745;&#22120;&#36319;&#36394;&#24615;&#33021;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#19981;&#26029;&#28436;&#21464;&#30340;&#39640;&#26031;&#23494;&#24230;&#30340;&#8220;&#28369;&#21160;&#31383;&#21475;&#8221;&#39640;&#26031;&#26680;&#23494;&#24230;&#20272;&#35745;&#22120;&#30340;&#31934;&#30830;&#22343;&#26041;&#38598;&#25104;&#35823;&#24046;&#65288;MISE&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#19978;&#34920;&#24449;&#20934;&#30830;MISE&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#36873;&#25321;&#26368;&#20248;&#26435;&#37325;&#24207;&#21015;&#30340;&#21407;&#21017;&#25351;&#21335;&#65292;&#23427;&#21487;&#20197;&#34987;&#26500;&#24314;&#20026;&#21463;&#38480;&#20108;&#27425;&#35268;&#21010;&#12290;&#25105;&#20204;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#38598;&#25552;&#20379;&#23454;&#35777;&#35777;&#25454;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#21152;&#26435;&#26041;&#26696;&#30830;&#23454;&#25552;&#39640;&#20102;&#36319;&#36394;&#24615;&#33021;&#65292;&#19982;&#21551;&#21457;&#24335;&#26041;&#27861;&#30456;&#27604;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07207v1 Announce Type: cross  Abstract: Dynamic density estimation is ubiquitous in many applications, including computer vision and signal processing. One popular method to tackle this problem is the "sliding window" kernel density estimator. There exist various implementations of this method that use heuristically defined weight sequences for the observed data. The weight sequence, however, is a key aspect of the estimator affecting the tracking performance significantly. In this work, we study the exact mean integrated squared error (MISE) of "sliding window" Gaussian Kernel Density Estimators for evolving Gaussian densities. We provide a principled guide for choosing the optimal weight sequence by theoretically characterizing the exact MISE, which can be formulated as constrained quadratic programming. We present empirical evidence with synthetic datasets to show that our weighting scheme indeed improves the tracking performance compared to heuristic approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#26088;&#22312;&#20840;&#38754;&#27010;&#36848;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#22914;&#20309;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#26469;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644; GNN &#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#35266;&#28857;&#12290;</title><link>https://arxiv.org/abs/2403.07185</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Uncertainty in Graph Neural Networks: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#26088;&#22312;&#20840;&#38754;&#27010;&#36848;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#22914;&#20309;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#26469;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644; GNN &#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#12290;&#28982;&#32780;&#65292;GNNs&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#28304;&#33258;&#25968;&#25454;&#20013;&#30340;&#22266;&#26377;&#38543;&#26426;&#24615;&#21644;&#27169;&#22411;&#35757;&#32451;&#35823;&#24046;&#31561;&#22810;&#31181;&#22240;&#32032;&#65292;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#21644;&#38169;&#35823;&#30340;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644;GNN&#39044;&#27979;&#30340;&#21487;&#38752;&#24615;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#26412;&#35843;&#26597;&#26088;&#22312;&#20174;&#19981;&#30830;&#23450;&#24615;&#30340;&#35282;&#24230;&#20840;&#38754;&#27010;&#36848;GNNs&#65292;&#24182;&#24378;&#35843;&#20854;&#22312;&#22270;&#23398;&#20064;&#20013;&#30340;&#25972;&#21512;&#12290;&#25105;&#20204;&#27604;&#36739;&#21644;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#22270;&#19981;&#30830;&#23450;&#24615;&#29702;&#35770;&#21644;&#26041;&#27861;&#65292;&#20197;&#21450;&#30456;&#24212;&#30340;&#19979;&#28216;&#20219;&#21153;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#24357;&#21512;&#20102;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#21516;&#26102;&#36830;&#25509;&#19981;&#21516;&#30340;GNN&#31038;&#21306;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#36825;&#19968;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07185v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have been extensively used in various real-world applications. However, the predictive uncertainty of GNNs stemming from diverse sources such as inherent randomness in data and model training errors can lead to unstable and erroneous predictions. Therefore, identifying, quantifying, and utilizing uncertainty are essential to enhance the performance of the model for the downstream tasks as well as the reliability of the GNN predictions. This survey aims to provide a comprehensive overview of the GNNs from the perspective of uncertainty with an emphasis on its integration in graph learning. We compare and summarize existing graph uncertainty theory and methods, alongside the corresponding downstream tasks. Thereby, we bridge the gap between theory and practice, meanwhile connecting different GNN communities. Moreover, our work provides valuable insights into promising directions in this field.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#19977;&#31867;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#25552;&#20986;&#20102;&#20855;&#26377;&#38543;&#26426;&#37325;&#25490;&#30340;&#38543;&#26426;&#22806;&#25512;&#27861;&#65288;SEG-RR&#65289;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#21333;&#35843;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#27604;&#22343;&#21248;&#26367;&#25442;&#37319;&#26679;SEG&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.07148</link><description>&lt;p&gt;
&#20855;&#26377;&#38543;&#26426;&#37325;&#25490;&#30340;&#38543;&#26426;&#22806;&#25512;&#27861;&#65306;&#25913;&#36827;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07148
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#19977;&#31867;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#25552;&#20986;&#20102;&#20855;&#26377;&#38543;&#26426;&#37325;&#25490;&#30340;&#38543;&#26426;&#22806;&#25512;&#27861;&#65288;SEG-RR&#65289;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#21333;&#35843;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#27604;&#22343;&#21248;&#26367;&#25442;&#37319;&#26679;SEG&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22806;&#25512;&#27861;&#65288;SEG&#65289;&#26041;&#27861;&#26159;&#35299;&#20915;&#20986;&#29616;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#26377;&#38480;&#27714;&#21644;&#26497;&#23567;-&#26497;&#22823;&#20248;&#21270;&#21644;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#65288;VIPs&#65289;&#30340;&#26368;&#27969;&#34892;&#31639;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;SEG&#25910;&#25947;&#20998;&#26512;&#19987;&#27880;&#20110;&#20854;&#24102;&#26367;&#25442;&#21464;&#20307;&#65292;&#32780;&#26041;&#27861;&#30340;&#23454;&#38469;&#23454;&#29616;&#20250;&#38543;&#26426;&#37325;&#26032;&#25490;&#21015;&#20998;&#37327;&#24182;&#25353;&#39034;&#24207;&#20351;&#29992;&#23427;&#20204;&#12290;&#19982;&#24191;&#20026;&#30740;&#31350;&#30340;&#24102;&#26367;&#25442;&#21464;&#20307;&#19981;&#21516;&#65292;&#20855;&#26377;&#38543;&#26426;&#37325;&#25490;&#30340;SEG&#65288;SEG-RR&#65289;&#32570;&#20047;&#24050;&#24314;&#31435;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#19977;&#31867;VIPs&#65288;i&#65289;&#24378;&#21333;&#35843;&#65292;&#65288;ii&#65289;&#20223;&#23556;&#21644;&#65288;iii&#65289;&#21333;&#35843;&#25552;&#20379;&#20102;SEG-RR&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;SEG-RR&#23454;&#29616;&#27604;&#22343;&#21248;&#24102;&#26367;&#25442;&#37319;&#26679;SEG&#20855;&#26377;&#26356;&#24555;&#25910;&#25947;&#36895;&#24230;&#30340;&#26465;&#20214;&#12290;&#22312;&#21333;&#35843;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;SEG-RR&#20998;&#26512;&#20445;&#35777;&#20102;&#25910;&#25947;&#21040;&#20219;&#24847;&#31934;&#24230;&#32780;&#26080;&#38656;&#22823;&#25209;&#37327;&#22823;&#23567;&#65292;&#36825;&#26159;&#23545;&#22823;&#25209;&#37327;&#22823;&#23567;&#32780;&#35328;&#30340;&#24378;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07148v1 Announce Type: cross  Abstract: The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (VIPs) appearing in various machine learning tasks. However, existing convergence analyses of SEG focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. Unlike the well-studied with-replacement variants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical guarantees. In this work, we provide a convergence analysis of SEG-RR for three classes of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We derive conditions under which SEG-RR achieves a faster convergence rate than the uniform with-replacement sampling SEG. In the monotone setting, our analysis of SEG-RR guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#22522;&#20110;&#20540;&#20989;&#25968;&#30340;&#34920;&#24449;&#33021;&#21147;&#26377;&#38480;&#65292;&#23548;&#33268;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22522;&#20110;&#20540;&#20989;&#25968;&#30340;&#26041;&#27861;&#22312;&#32479;&#35745;&#19978;&#20302;&#25928;&#29575;&#65292;&#36825;&#25581;&#31034;&#20102;&#20215;&#20540;&#20989;&#25968;&#21644;&#32479;&#35745;&#25928;&#29575;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;</title><link>https://arxiv.org/abs/2403.07136</link><description>&lt;p&gt;
&#20215;&#20540;&#20989;&#25968;&#30340;&#26377;&#38480;&#34920;&#24449;&#33021;&#21147;&#21450;&#20854;&#19982;&#32479;&#35745;(&#19981;)&#25928;&#29575;&#30340;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
On the Limited Representational Power of Value Functions and its Links to Statistical (In)Efficiency
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07136
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#22522;&#20110;&#20540;&#20989;&#25968;&#30340;&#34920;&#24449;&#33021;&#21147;&#26377;&#38480;&#65292;&#23548;&#33268;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22522;&#20110;&#20540;&#20989;&#25968;&#30340;&#26041;&#27861;&#22312;&#32479;&#35745;&#19978;&#20302;&#25928;&#29575;&#65292;&#36825;&#25581;&#31034;&#20102;&#20215;&#20540;&#20989;&#25968;&#21644;&#32479;&#35745;&#25928;&#29575;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#35782;&#21035;&#22522;&#20110;&#27169;&#22411;&#21644;&#26080;&#27169;&#22411;&#26041;&#27861;&#20043;&#38388;&#30340;&#26435;&#34913;&#26159;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290; &#22522;&#20110;&#20540;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#32479;&#35745;&#19978;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#19968;&#26679;&#26377;&#25928;&#12290; &#28982;&#32780;&#65292;&#24403;&#20851;&#27880;&#31574;&#30053;&#35780;&#20272;&#30340;&#26680;&#24515;&#38382;&#39064;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#20851;&#20110;&#36716;&#31227;&#21160;&#24577;&#30340;&#20449;&#24687;&#21487;&#33021;&#26080;&#27861;&#22312;&#20215;&#20540;&#20989;&#25968;&#31354;&#38388;&#20013;&#34920;&#31034;&#12290; &#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#30528;&#37325;&#20110;&#35768;&#22810;&#37325;&#35201;&#38382;&#39064;&#20013;&#20986;&#29616;&#30340;&#32467;&#26500;&#30340;&#26696;&#20363;&#30740;&#31350;&#26469;&#25506;&#31350;&#36825;&#19968;&#28857;&#12290; &#22312;&#20854;&#20013;&#20960;&#31181;&#24773;&#20917;&#20013;&#65292;&#27809;&#26377;&#20449;&#24687;&#20002;&#22833;&#65292;&#22522;&#20110;&#20540;&#30340;&#26041;&#27861;&#19982;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#22312;&#32479;&#35745;&#25928;&#29575;&#19978;&#30456;&#24403;&#12290; &#22312;&#20854;&#20182;&#30456;&#20851;&#31034;&#20363;&#20013;&#65292;&#20449;&#24687;&#20002;&#22833;&#20005;&#37325;&#65292;&#22522;&#20110;&#20540;&#30340;&#26041;&#27861;&#24615;&#33021;&#20005;&#37325;&#19981;&#21450;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290; &#26356;&#28145;&#20837;&#30340;&#30740;&#31350;&#25351;&#20986;&#20102;&#34920;&#24449;&#33021;&#21147;&#30340;&#38480;&#21046;&#20316;&#20026;&#20302;&#25928;&#24615;&#30340;&#39537;&#21160;&#22240;&#32032;&#65292;&#32780;&#38750;&#31639;&#27861;&#35774;&#35745;&#19978;&#30340;&#22833;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07136v1 Announce Type: cross  Abstract: Identifying the trade-offs between model-based and model-free methods is a central question in reinforcement learning. Value-based methods offer substantial computational advantages and are sometimes just as statistically efficient as model-based methods. However, focusing on the core problem of policy evaluation, we show information about the transition dynamics may be impossible to represent in the space of value functions. We explore this through a series of case studies focused on structures that arises in many important problems. In several, there is no information loss and value-based methods are as statistically efficient as model based ones. In other closely-related examples, information loss is severe and value-based methods are severely outperformed. A deeper investigation points to the limitations of the representational power as the driver of the inefficiency, as opposed to failure in algorithm design.
&lt;/p&gt;</description></item><item><title>Cram&#26041;&#27861;&#26159;&#19968;&#31181;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21033;&#29992;&#25972;&#20010;&#26679;&#26412;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#65292;&#27604;&#20256;&#32479;&#30340;&#26679;&#26412;&#20998;&#21106;&#31574;&#30053;&#26356;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2403.07031</link><description>&lt;p&gt;
&#29992;&#20110;&#39640;&#25928;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#30340;Cram&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
The Cram Method for Efficient Simultaneous Learning and Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07031
&lt;/p&gt;
&lt;p&gt;
Cram&#26041;&#27861;&#26159;&#19968;&#31181;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21033;&#29992;&#25972;&#20010;&#26679;&#26412;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#65292;&#27604;&#20256;&#32479;&#30340;&#26679;&#26412;&#20998;&#21106;&#31574;&#30053;&#26356;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#8220;Cram&#8221;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#29992;&#19988;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#36827;&#34892;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#12290;&#22312;&#25209;&#22788;&#29702;&#25968;&#25454;&#30340;&#21333;&#27425;&#20256;&#36882;&#20013;&#65292;&#35813;&#26041;&#27861;&#21453;&#22797;&#35757;&#32451;ML&#31639;&#27861;&#24182;&#27979;&#35797;&#20854;&#32463;&#39564;&#24615;&#33021;&#12290;&#30001;&#20110;&#23427;&#21516;&#26102;&#21033;&#29992;&#20102;&#25972;&#20010;&#26679;&#26412;&#36827;&#34892;&#23398;&#20064;&#21644;&#35780;&#20272;&#65292;&#25152;&#20197;Cram&#26041;&#27861;&#27604;&#26679;&#26412;&#20998;&#21106;&#35201;&#39640;&#25928;&#24471;&#22810;&#12290;Cram&#26041;&#27861;&#36824;&#33258;&#28982;&#22320;&#36866;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20351;&#20854;&#23454;&#26045;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#12290;&#20026;&#20102;&#23637;&#31034;Cram&#26041;&#27861;&#30340;&#24378;&#22823;&#20043;&#22788;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#26631;&#20934;&#31574;&#30053;&#23398;&#20064;&#35774;&#32622;&#65292;&#20854;&#20013;&#23558;Cram&#24212;&#29992;&#20110;&#30456;&#21516;&#25968;&#25454;&#20197;&#24320;&#21457;&#20010;&#24615;&#21270;&#27835;&#30103;&#35268;&#21017;&#65288;ITR&#65289;&#24182;&#20272;&#35745;&#22914;&#26524;&#23398;&#20064;&#30340;ITR&#34987;&#37096;&#32626;&#23558;&#20250;&#20135;&#29983;&#30340;&#24179;&#22343;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26368;&#23567;&#19968;&#32452;&#20551;&#35774;&#19979;&#65292;&#30001;&#27492;&#20135;&#29983;&#30340;Cram&#35780;&#20272;&#20272;&#35745;&#22120;&#26159;&#19968;&#33268;&#19988;&#28176;&#36817;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07031v1 Announce Type: new  Abstract: We introduce the "cram" method, a general and efficient approach to simultaneous learning and evaluation using a generic machine learning (ML) algorithm. In a single pass of batched data, the proposed method repeatedly trains an ML algorithm and tests its empirical performance. Because it utilizes the entire sample for both learning and evaluation, cramming is significantly more data-efficient than sample-splitting. The cram method also naturally accommodates online learning algorithms, making its implementation computationally efficient. To demonstrate the power of the cram method, we consider the standard policy learning setting where cramming is applied to the same data to both develop an individualized treatment rule (ITR) and estimate the average outcome that would result if the learned ITR were to be deployed. We show that under a minimal set of assumptions, the resulting crammed evaluation estimator is consistent and asymptoticall
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#20123;&#20984;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#20250;&#25910;&#25947;&#21040;&#22266;&#23450;&#28857;&#65292;&#24182;&#22312;&#19968;&#23450;&#36845;&#20195;&#27425;&#25968;&#20869;&#36798;&#21040;&#29305;&#23450;&#31934;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.07004</link><description>&lt;p&gt;
&#19968;&#20123;&#20984;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#25910;&#25947;&#21040;&#22266;&#23450;&#28857;
&lt;/p&gt;
&lt;p&gt;
Convergence of Some Convex Message Passing Algorithms to a Fixed Point
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07004
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#20123;&#20984;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#20250;&#25910;&#25947;&#21040;&#22266;&#23450;&#28857;&#65292;&#24182;&#22312;&#19968;&#23450;&#36845;&#20195;&#27425;&#25968;&#20869;&#36798;&#21040;&#29305;&#23450;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22270;&#27169;&#22411;&#20013;&#35299;&#20915;MAP&#25512;&#26029;&#38382;&#39064;&#30340;&#19968;&#31181;&#27969;&#34892;&#26041;&#27861;&#26159;&#36890;&#36807;&#65288;&#22359;&#29366;&#65289;&#22352;&#26631;&#19979;&#38477;&#26368;&#23567;&#21270;&#20174;&#23545;&#20598;&#32447;&#24615;&#35268;&#21010;&#25110;Lagrange&#26494;&#24347;&#20013;&#33719;&#24471;&#30340;&#19968;&#20010;&#19978;&#30028;&#12290;&#36825;&#26679;&#30340;&#31639;&#27861;&#21253;&#25324;&#26368;&#22823;&#21644;&#25193;&#25955;&#20197;&#21450;&#39034;&#24207;&#26641;&#37325;&#26032;&#21152;&#26435;&#28040;&#24687;&#20256;&#36882;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#30446;&#21069;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#23427;&#20204;&#24050;&#34987;&#35777;&#26126;&#20250;&#25910;&#25947;&#21040;&#30001;&#27963;&#36291;&#32422;&#26463;&#30340;&#23616;&#37096;&#19968;&#33268;&#24615;&#25152;&#34920;&#24449;&#30340;&#38598;&#21512;&#65292;&#20294;&#25910;&#25947;&#36895;&#24230;&#26410;&#30693;&#65307;&#28982;&#32780;&#65292;&#23578;&#19981;&#28165;&#26970;&#36845;&#20195;&#26159;&#21542;&#20250;&#25910;&#25947;&#65288;&#21040;&#20219;&#20309;&#19968;&#20010;&#21333;&#19968;&#28857;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#26356;&#24378;&#30340;&#32467;&#26524;&#65288;&#20043;&#21069;&#26377;&#29468;&#24819;&#20294;&#20174;&#26410;&#35777;&#26126;&#36807;&#65289;&#65306;&#36845;&#20195;&#20250;&#25910;&#25947;&#21040;&#31639;&#27861;&#30340;&#19968;&#20010;&#22266;&#23450;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#23427;&#20204;&#22312;$\mathcal{O}(1/\varepsilon)$&#27425;&#36845;&#20195;&#20013;&#36798;&#21040;&#20102;&#31934;&#24230;$\varepsilon&gt;0$&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07004v1 Announce Type: new  Abstract: A popular approach to the MAP inference problem in graphical models is to minimize an upper bound obtained from a dual linear programming or Lagrangian relaxation by (block-)coordinate descent. Examples of such algorithms are max-sum diffusion and sequential tree-reweighted message passing. Convergence properties of these methods are currently not fully understood. They have been proved to converge to the set characterized by local consistency of active constraints, with unknown convergence rate; however, it was not clear if the iterates converge at all (to any single point). We prove a stronger result (which was conjectured before but never proved): the iterates converge to a fixed point of the algorithm. Moreover, we show that they achieve precision $\varepsilon&gt;0$ in $\mathcal{O}(1/\varepsilon)$ iterations.   We first prove this for a version of coordinate descent applied to a general piecewise-affine convex objective, using a novel p
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2312.08531</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.08531
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#37324;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#65292;&#22240;&#20026;&#23427;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#20294;&#32570;&#20047;&#29702;&#35770;&#29702;&#35299;&#12290;&#23545;&#20110;Lipschitz&#20984;&#20989;&#25968;&#65292;&#19981;&#21516;&#30340;&#30740;&#31350;&#24314;&#31435;&#20102;&#26368;&#20339;&#30340;$O(\log(1/\delta)\log T/\sqrt{T})$&#25110;$O(\sqrt{\log(1/\delta)/T})$&#26368;&#32456;&#36845;&#20195;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36895;&#29575;&#65292;&#20854;&#20013;$T$&#26159;&#26102;&#38388;&#36328;&#24230;&#65292;$\delta$&#26159;&#22833;&#36133;&#27010;&#29575;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#35777;&#26126;&#36825;&#20123;&#30028;&#38480;&#65292;&#25152;&#26377;&#29616;&#26377;&#30340;&#24037;&#20316;&#35201;&#20040;&#23616;&#38480;&#20110;&#32039;&#33268;&#22495;&#65292;&#35201;&#20040;&#38656;&#35201;&#20960;&#20046;&#32943;&#23450;&#26377;&#30028;&#30340;&#22122;&#22768;&#12290;&#24456;&#33258;&#28982;&#22320;&#20250;&#38382;&#65292;&#19981;&#38656;&#35201;&#36825;&#20004;&#20010;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;SGD&#30340;&#26368;&#32456;&#36845;&#20195;&#26159;&#21542;&#20173;&#28982;&#21487;&#20197;&#20445;&#35777;&#26368;&#20339;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#38500;&#20102;&#36825;&#20010;&#37325;&#35201;&#38382;&#39064;&#22806;&#65292;&#36824;&#26377;&#24456;&#22810;&#29702;&#35770;&#38382;&#39064;&#20173;&#28982;&#27809;&#26377;&#31572;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.08531v2 Announce Type: replace  Abstract: In the past several years, the last-iterate convergence of the Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due to its good performance in practice but lack of theoretical understanding. For Lipschitz convex functions, different works have established the optimal $O(\log(1/\delta)\log T/\sqrt{T})$ or $O(\sqrt{\log(1/\delta)/T})$ high-probability convergence rates for the final iterate, where $T$ is the time horizon and $\delta$ is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noises. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smoot
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#26032;&#25351;&#26631;&#65292;&#35777;&#26126;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#22312;&#36136;&#37327;&#19978;&#20248;&#20110;&#32463;&#20856;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#37327;&#23376;&#27874;&#21160;&#23450;&#29702;&#25581;&#31034;&#20102;&#20854;&#29289;&#29702;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2311.12163</link><description>&lt;p&gt;
&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;
&lt;/p&gt;
&lt;p&gt;
Quantum Inception Score
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12163
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#26032;&#25351;&#26631;&#65292;&#35777;&#26126;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#22312;&#36136;&#37327;&#19978;&#20248;&#20110;&#32463;&#20856;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#37327;&#23376;&#27874;&#21160;&#23450;&#29702;&#25581;&#31034;&#20102;&#20854;&#29289;&#29702;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#32463;&#20856;&#29983;&#25104;&#27169;&#22411;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21462;&#24471;&#24040;&#22823;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#36817;&#26399;&#24320;&#22987;&#20102;&#23545;&#23427;&#20204;&#37327;&#23376;&#29256;&#26412;&#30340;&#28909;&#20999;&#25506;&#32034;&#12290;&#20026;&#20102;&#24320;&#22987;&#36825;&#19968;&#25506;&#32034;&#20043;&#26053;&#65292;&#24320;&#21457;&#19968;&#20010;&#30456;&#20851;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#35780;&#20272;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#26159;&#24456;&#37325;&#35201;&#30340;&#65307;&#22312;&#32463;&#20856;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#36825;&#26679;&#30340;&#20363;&#23376;&#20415;&#26159;&#21551;&#33945;&#20998;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;&#65292;&#23427;&#23558;&#36136;&#37327;&#19982;&#29992;&#20110;&#23545;&#32473;&#23450;&#25968;&#25454;&#38598;&#36827;&#34892;&#20998;&#31867;&#30340;&#37327;&#23376;&#36890;&#36947;&#30340;Holevo&#20449;&#24687;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36825;&#20010;&#25552;&#20986;&#30340;&#24230;&#37327;&#26631;&#20934;&#19979;&#65292;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#27604;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#24212;&#29289;&#26356;&#22909;&#30340;&#36136;&#37327;&#65292;&#22240;&#20026;&#23384;&#22312;&#30528;&#30001;&#19981;&#23545;&#31216;&#24615;&#30340;&#36164;&#28304;&#29702;&#35770;&#21644;&#32416;&#32544;&#25152;&#34920;&#24449;&#30340;&#37327;&#23376;&#30456;&#24178;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#37327;&#23376;&#27874;&#21160;&#23450;&#29702;&#26469;&#34920;&#24449;&#38480;&#21046;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#29289;&#29702;&#38480;&#21046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24212;&#29992;&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;&#26469;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.12163v2 Announce Type: replace-cross  Abstract: Motivated by the great success of classical generative models in machine learning, enthusiastic exploration of their quantum version has recently started. To depart on this journey, it is important to develop a relevant metric to evaluate the quality of quantum generative models; in the classical case, one such example is the inception score. In this paper, we propose the quantum inception score, which relates the quality to the Holevo information of the quantum channel that classifies a given dataset. We prove that, under this proposed measure, the quantum generative models provide better quality than their classical counterparts because of the presence of quantum coherence, characterized by the resource theory of asymmetry, and entanglement. Furthermore, we harness the quantum fluctuation theorem to characterize the physical limitation of the quality of quantum generative models. Finally, we apply the quantum inception score 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#28145;&#24230;&#27169;&#22411;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21387;&#32553;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20302;&#32500;&#19981;&#21464;&#23376;&#31354;&#38388;&#20869;&#26356;&#26032;&#26435;&#37325;&#30697;&#38453;&#26469;&#21387;&#32553;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#65292;&#24182;&#22312;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#26377;&#25928;&#24615;&#35780;&#20272;</title><link>https://arxiv.org/abs/2311.05061</link><description>&lt;p&gt;
&#36890;&#36807;&#20302;&#32500;&#23398;&#20064;&#21160;&#24577;&#23454;&#29616;&#36229;&#21442;&#25968;&#21270;&#28145;&#24230;&#27169;&#22411;&#30340;&#39640;&#25928;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Efficient Compression of Overparameterized Deep Models through Low-Dimensional Learning Dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.05061
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#28145;&#24230;&#27169;&#22411;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21387;&#32553;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20302;&#32500;&#19981;&#21464;&#23376;&#31354;&#38388;&#20869;&#26356;&#26032;&#26435;&#37325;&#30697;&#38453;&#26469;&#21387;&#32553;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#65292;&#24182;&#22312;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#26377;&#25928;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#24050;&#34987;&#35777;&#26126;&#26159;&#35299;&#20915;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#36807;&#24230;&#21442;&#25968;&#21270;&#24448;&#24448;&#23548;&#33268;&#35745;&#31639;&#21644;&#20869;&#23384;&#25104;&#26412;&#22823;&#24133;&#22686;&#21152;&#65292;&#36827;&#32780;&#38656;&#35201;&#22823;&#37327;&#36164;&#28304;&#26469;&#35757;&#32451;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#21387;&#32553;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#36890;&#36807;&#30740;&#31350;&#23427;&#20204;&#30340;&#23398;&#20064;&#21160;&#24577;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#23545;&#20110;&#35768;&#22810;&#28145;&#24230;&#27169;&#22411;&#65292;&#26435;&#37325;&#30697;&#38453;&#30340;&#26356;&#26032;&#21457;&#29983;&#22312;&#20302;&#32500;&#19981;&#21464;&#23376;&#31354;&#38388;&#20869;&#12290;&#23545;&#20110;&#28145;&#24230;&#32447;&#24615;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#20204;&#30340;&#20027;&#35201;&#25104;&#20998;&#22312;&#19968;&#20010;&#23567;&#23376;&#31354;&#38388;&#20869;&#36880;&#28176;&#36866;&#37197;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#35265;&#35299;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30340;&#21387;&#32553;&#31639;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#20943;&#23567;&#20854;&#20013;&#38388;&#23618;&#30340;&#23485;&#24230;&#12290;&#25105;&#20204;&#20174;&#23454;&#39564;&#35282;&#24230;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#21387;&#32553;&#25216;&#26415;&#22312;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.05061v2 Announce Type: replace  Abstract: Overparameterized models have proven to be powerful tools for solving various machine learning tasks. However, overparameterization often leads to a substantial increase in computational and memory costs, which in turn requires extensive resources to train. In this work, we present a novel approach for compressing overparameterized models, developed through studying their learning dynamics. We observe that for many deep models, updates to the weight matrices occur within a low-dimensional invariant subspace. For deep linear models, we demonstrate that their principal components are fitted incrementally within a small subspace, and use these insights to propose a compression algorithm for deep linear networks that involve decreasing the width of their intermediate layers. We empirically evaluate the effectiveness of our compression technique on matrix recovery problems. Remarkably, by using an initialization that exploits the structur
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;The Attention Patch&#65288;TAP&#65289;&#31070;&#32463;&#32593;&#32476;&#38468;&#21152;&#32452;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#20174;&#26410;&#26631;&#35760;&#30340;&#27425;&#35201;&#27169;&#24577;&#23454;&#29616;&#36328;&#27169;&#24577;&#30340;&#25968;&#25454;&#32423;&#30693;&#35782;&#20256;&#36882;&#12290;</title><link>https://arxiv.org/abs/2302.02224</link><description>&lt;p&gt;
TAP: &#36328;&#27169;&#24577;&#30693;&#35782;&#20256;&#36882;&#20013;&#30340;&#27880;&#24847;&#21147;&#34917;&#19969;
&lt;/p&gt;
&lt;p&gt;
TAP: The Attention Patch for Cross-Modal Knowledge Transfer from Unlabeled Modality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.02224
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;The Attention Patch&#65288;TAP&#65289;&#31070;&#32463;&#32593;&#32476;&#38468;&#21152;&#32452;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#20174;&#26410;&#26631;&#35760;&#30340;&#27425;&#35201;&#27169;&#24577;&#23454;&#29616;&#36328;&#27169;&#24577;&#30340;&#25968;&#25454;&#32423;&#30693;&#35782;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#36328;&#27169;&#24577;&#23398;&#20064;&#26694;&#26550;&#65292;&#20854;&#30446;&#26631;&#26159;&#36890;&#36807;&#26410;&#26631;&#35760;&#12289;&#19981;&#37197;&#23545;&#30340;&#27425;&#35201;&#27169;&#24577;&#65292;&#22686;&#24378;&#20027;&#35201;&#27169;&#24577;&#20013;&#30417;&#30563;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;&#37319;&#29992;&#27010;&#29575;&#26041;&#27861;&#36827;&#34892;&#32570;&#22833;&#20449;&#24687;&#20272;&#35745;&#65292;&#25105;&#20204;&#34920;&#26126;&#27425;&#35201;&#27169;&#24577;&#20013;&#21253;&#21547;&#30340;&#39069;&#22806;&#20449;&#24687;&#21487;&#20197;&#36890;&#36807;Nadaraya-Watson&#65288;NW&#65289;&#26680;&#22238;&#24402;&#36827;&#34892;&#20272;&#35745;&#65292;&#20854;&#21487;&#20197;&#36827;&#19968;&#27493;&#34920;&#31034;&#20026;&#32463;&#36807;&#32447;&#24615;&#21464;&#25442;&#30340;&#26680;&#20132;&#21449;&#27880;&#24847;&#21147;&#27169;&#22359;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#24341;&#20837;The Attention Patch&#65288;TAP&#65289;&#22880;&#23450;&#20102;&#22522;&#30784;&#65292;&#36825;&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#31070;&#32463;&#32593;&#32476;&#38468;&#21152;&#32452;&#20214;&#65292;&#20801;&#35768;&#20174;&#26410;&#26631;&#35760;&#30340;&#27169;&#24577;&#36827;&#34892;&#25968;&#25454;&#32423;&#30693;&#35782;&#20256;&#36882;&#12290;&#25105;&#20204;&#20351;&#29992;&#22235;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22823;&#37327;&#25968;&#20540;&#27169;&#25311;&#65292;&#32467;&#26524;&#34920;&#26126;TAP&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#36328;&#19981;&#21516;&#39046;&#22495;&#21644;&#19981;&#21516;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21033;&#29992;&#30475;&#20284;&#26080;&#29992;&#30340;&#26410;&#26631;&#35760;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.02224v2 Announce Type: replace  Abstract: This paper addresses a cross-modal learning framework, where the objective is to enhance the performance of supervised learning in the primary modality using an unlabeled, unpaired secondary modality. Taking a probabilistic approach for missing information estimation, we show that the extra information contained in the secondary modality can be estimated via Nadaraya-Watson (NW) kernel regression, which can further be expressed as a kernelized cross-attention module (under linear transformation). Our results lay the foundations for introducing The Attention Patch (TAP), a simple neural network add-on that allows data-level knowledge transfer from the unlabeled modality. We provide extensive numerical simulations using four real-world datasets to show that TAP can provide statistically significant improvement in generalization across different domains and different neural network architectures, making use of seemingly unusable unlabel
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21333;&#35843;&#21464;&#20998;&#19981;&#31561;&#24335;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#25910;&#25947;&#24182;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#25552;&#20379;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2202.08876</link><description>&lt;p&gt;
&#20351;&#29992;&#21333;&#35843;&#21464;&#20998;&#19981;&#31561;&#24335;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#21478;&#19968;&#31181;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An alternative approach to train neural networks using monotone variational inequality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.08876
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21333;&#35843;&#21464;&#20998;&#19981;&#31561;&#24335;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#25910;&#25947;&#24182;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#25552;&#20379;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#35843;&#30690;&#37327;&#22330;&#30340;&#26367;&#20195;&#26041;&#27861;&#26469;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#36825;&#20010;&#24819;&#27861;&#21463;&#21040;Juditsky&#21644;Nemirovski&#30340;&#24320;&#21019;&#24615;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#26368;&#21021;&#26159;&#20026;&#20102;&#35299;&#20915;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#21407;&#22987;&#38750;&#20984;&#38382;&#39064;&#31616;&#21270;&#20026;&#35299;&#20915;&#21333;&#35843;&#21464;&#20998;&#19981;&#31561;&#24335;&#65288;VI&#65289;&#30340;&#20984;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23548;&#33268;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#22312;&#26576;&#20123;&#29305;&#27530;&#24773;&#20917;&#19979;&#25910;&#25947;&#24555;&#36895;&#24182;&#25552;&#20379;&#20102;&#20445;&#35777;&#65292;&#20363;&#22914;&#35757;&#32451;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#25110;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#26356;&#39640;&#25928;&#22320;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#21516;&#26102;&#20923;&#32467;&#24213;&#23618;&#65292;&#36825;&#26159;&#37096;&#32626;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65288;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;LLM&#65289;&#30340;&#37325;&#35201;&#27493;&#39588;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#22312;&#35757;&#32451;&#20840;&#36830;&#25509;&#65288;FC&#65289;&#31070;&#32463;&#32593;&#32476;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.08876v4 Announce Type: replace-cross  Abstract: We propose an alternative approach to neural network training using the monotone vector field, an idea inspired by the seminal work of Juditsky and Nemirovski [Juditsky &amp; Nemirovsky, 2019] developed originally to solve parameter estimation problems for generalized linear models (GLM) by reducing the original non-convex problem to a convex problem of solving a monotone variational inequality (VI). Our approach leads to computationally efficient procedures that converge fast and offer guarantee in some special cases, such as training a single-layer neural network or fine-tuning the last layer of the pre-trained model. Our approach can be used for more efficient fine-tuning of a pre-trained model while freezing the bottom layers, an essential step for deploying many machine learning models such as large language models (LLM). We demonstrate its applicability in training fully-connected (FC) neural networks, graph neural networks (
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39318;&#20808;&#23450;&#20041;&#19968;&#20010;&#34913;&#37327;&#22522;&#20110;&#25968;&#25454;&#20844;&#24335;&#36136;&#37327;&#30340;&#26631;&#23610;&#65292;&#28982;&#21518;&#23547;&#25214;&#26368;&#20248;&#20844;&#24335;&#65292;&#20351;&#20854;&#22312;&#20445;&#35777;&#26679;&#26412;&#22806;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#26356;&#21152;&#25509;&#36817;&#30495;&#23454;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2109.06911</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#21644;&#20915;&#31574;&#65306;&#26368;&#20248;&#20844;&#24335;&#19982;&#30456;&#21464;
&lt;/p&gt;
&lt;p&gt;
Learning and Decision-Making with Data: Optimal Formulations and Phase Transitions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2109.06911
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39318;&#20808;&#23450;&#20041;&#19968;&#20010;&#34913;&#37327;&#22522;&#20110;&#25968;&#25454;&#20844;&#24335;&#36136;&#37327;&#30340;&#26631;&#23610;&#65292;&#28982;&#21518;&#23547;&#25214;&#26368;&#20248;&#20844;&#24335;&#65292;&#20351;&#20854;&#22312;&#20445;&#35777;&#26679;&#26412;&#22806;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#26356;&#21152;&#25509;&#36817;&#30495;&#23454;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#21482;&#26377;&#21382;&#21490;&#25968;&#25454;&#21487;&#29992;&#26102;&#35774;&#35745;&#26368;&#20248;&#23398;&#20064;&#21644;&#20915;&#31574;&#20844;&#24335;&#30340;&#38382;&#39064;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#20250;&#33268;&#21147;&#20110;&#26576;&#19968;&#31867;&#22522;&#20110;&#25968;&#25454;&#30340;&#20844;&#24335;&#65292;&#28982;&#21518;&#35797;&#22270;&#24314;&#31435;&#26679;&#26412;&#22806;&#24615;&#33021;&#20445;&#35777;&#12290;&#25105;&#20204;&#36825;&#37324;&#37319;&#21462;&#20102;&#30456;&#21453;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#23450;&#20041;&#19968;&#20010;&#21512;&#29702;&#30340;&#26631;&#23610;&#26469;&#34913;&#37327;&#20219;&#20309;&#22522;&#20110;&#25968;&#25454;&#30340;&#20844;&#24335;&#30340;&#36136;&#37327;&#65292;&#28982;&#21518;&#23547;&#27714;&#25214;&#21040;&#19968;&#20010;&#26368;&#20248;&#30340;&#36825;&#26679;&#30340;&#20844;&#24335;&#12290;&#19981;&#27491;&#24335;&#22320;&#35828;&#65292;&#20219;&#20309;&#22522;&#20110;&#25968;&#25454;&#30340;&#20844;&#24335;&#21487;&#20197;&#34987;&#35270;&#20026;&#22312;&#20445;&#35777;&#26679;&#26412;&#22806;&#24615;&#33021;&#27700;&#24179;&#30340;&#21516;&#26102;&#24179;&#34913;&#20272;&#35745;&#25104;&#26412;&#19982;&#23454;&#38469;&#25104;&#26412;&#30340;&#25509;&#36817;&#24230;&#30340;&#24230;&#37327;&#12290;&#22312;&#32473;&#23450;&#19968;&#20010;&#21487;&#25509;&#21463;&#30340;&#26679;&#26412;&#22806;&#24615;&#33021;&#27700;&#24179;&#21518;&#65292;&#25105;&#20204;&#26174;&#24335;&#26500;&#36896;&#20102;&#19968;&#20010;&#22522;&#20110;&#25968;&#25454;&#30340;&#20844;&#24335;&#65292;&#35813;&#20844;&#24335;&#22312;&#19982;&#21516;&#26679;&#20855;&#26377;&#26679;&#26412;&#22806;&#24615;&#33021;&#30340;&#20854;&#20182;&#20844;&#24335;&#30456;&#27604;&#26159;&#32479;&#19968;&#26356;&#25509;&#36817;&#30495;&#23454;&#25104;&#26412;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#26679;&#26412;&#22806;&#25191;&#34892;
&lt;/p&gt;
&lt;p&gt;
arXiv:2109.06911v3 Announce Type: replace-cross  Abstract: We study the problem of designing optimal learning and decision-making formulations when only historical data is available. Prior work typically commits to a particular class of data-driven formulation and subsequently tries to establish out-of-sample performance guarantees. We take here the opposite approach. We define first a sensible yard stick with which to measure the quality of any data-driven formulation and subsequently seek to find an optimal such formulation. Informally, any data-driven formulation can be seen to balance a measure of proximity of the estimated cost to the actual cost while guaranteeing a level of out-of-sample performance. Given an acceptable level of out-of-sample performance, we construct explicitly a data-driven formulation that is uniformly closer to the true cost than any other formulation enjoying the same out-of-sample performance. We show the existence of three distinct out-of-sample performan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;&#23616;&#37096;&#20027;&#21160;&#23376;&#31354;&#38388;&#65288;LAS&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#20027;&#21160;&#23376;&#31354;&#38388;&#19982;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#30340;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26356;&#26377;&#25928;&#30340;&#21442;&#25968;&#31354;&#38388;&#32500;&#24230;&#32553;&#20943;&#65292;&#23588;&#20854;&#22312;&#39640;&#32500;&#21442;&#25968;&#21270;&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>https://arxiv.org/abs/2107.10867</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#30340;&#21442;&#25968;&#31354;&#38388;&#32553;&#20943;&#30340;&#26412;&#22320;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A local approach to parameter space reduction for regression and classification tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2107.10867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;&#23616;&#37096;&#20027;&#21160;&#23376;&#31354;&#38388;&#65288;LAS&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#20027;&#21160;&#23376;&#31354;&#38388;&#19982;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#30340;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26356;&#26377;&#25928;&#30340;&#21442;&#25968;&#31354;&#38388;&#32500;&#24230;&#32553;&#20943;&#65292;&#23588;&#20854;&#22312;&#39640;&#32500;&#21442;&#25968;&#21270;&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21442;&#25968;&#31354;&#38388;&#32553;&#20943;&#24050;&#34987;&#35777;&#26126;&#26159;&#21152;&#36895;&#35768;&#22810;&#25968;&#20540;&#20219;&#21153;&#25191;&#34892;&#30340;&#20851;&#38190;&#24037;&#20855;&#65292;&#20363;&#22914;&#20248;&#21270;&#12289;&#36870;&#38382;&#39064;&#12289;&#25935;&#24863;&#24615;&#20998;&#26512;&#21644;&#20195;&#29702;&#27169;&#22411;&#35774;&#35745;&#65292;&#29305;&#21035;&#26159;&#22312;&#23384;&#22312;&#39640;&#32500;&#21442;&#25968;&#21270;&#31995;&#32479;&#26102;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#23616;&#37096;&#20027;&#21160;&#23376;&#31354;&#38388;&#65288;LAS&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#25506;&#32034;&#20102;&#20027;&#21160;&#23376;&#31354;&#38388;&#19982;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#30340;&#21327;&#21516;&#20316;&#29992;&#65292;&#20197;&#22312;&#21442;&#25968;&#31354;&#38388;&#20013;&#36827;&#34892;&#26356;&#26377;&#25928;&#30340;&#32500;&#24230;&#32553;&#20943;&#12290;&#36890;&#36807;&#24341;&#20837;&#30001;&#20840;&#23616;&#20027;&#21160;&#23376;&#31354;&#38388;&#24341;&#36215;&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#32858;&#31867;&#26159;&#22312;&#19981;&#20002;&#22833;&#36755;&#20837;&#36755;&#20986;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#25191;&#34892;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#21487;&#33021;&#30340;&#32858;&#31867;&#31639;&#27861;&#65306;K-medoids&#21644;&#19968;&#31181;&#33258;&#19978;&#32780;&#19979;&#30340;&#23618;&#27425;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26045;&#21152;&#19968;&#31995;&#21015;&#29305;&#21035;&#20026;&#21442;&#25968;&#31354;&#38388;&#32553;&#20943;&#20219;&#21153;&#37327;&#36523;&#23450;&#21046;&#30340;&#32454;&#20998;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#20174;&#20107;&#20195;&#29702;&#27169;&#22411;&#35774;&#35745;&#24037;&#20316;&#30340;&#31038;&#21306;&#29305;&#21035;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2107.10867v3 Announce Type: replace  Abstract: Parameter space reduction has been proved to be a crucial tool to speed-up the execution of many numerical tasks such as optimization, inverse problems, sensitivity analysis, and surrogate models' design, especially when in presence of high-dimensional parametrized systems. In this work we propose a new method called local active subspaces (LAS), which explores the synergies of active subspaces with supervised clustering techniques in order to carry out a more efficient dimension reduction in the parameter space. The clustering is performed without losing the input-output relations by introducing a distance metric induced by the global active subspace. We present two possible clustering algorithms: K-medoids and a hierarchical top-down approach, which is able to impose a variety of subdivision criteria specifically tailored for parameter space reduction tasks. This method is particularly useful for the community working on surrogate 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GPGL&#30340;epoch-evolving Gaussian Process Guided Learning&#23398;&#20064;&#26041;&#26696;&#65292;&#36890;&#36807;&#19978;&#19979;&#25991;&#26631;&#31614;&#21644;&#22320;&#38754;&#30495;&#23454;&#26631;&#31614;&#25351;&#23548;&#27169;&#22411;&#21442;&#25968;&#26356;&#26032;&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#24182;&#24212;&#29992;&#20110;&#24403;&#21069;&#28145;&#24230;&#27169;&#22411;&#65292;&#22312;&#20027;&#27969;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#22522;&#20110;&#25209;&#27425;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;</title><link>https://arxiv.org/abs/2006.14347</link><description>&lt;p&gt;
&#19981;&#26029;&#28436;&#21464;&#30340;&#39640;&#26031;&#36807;&#31243;&#24341;&#23548;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Epoch-evolving Gaussian Process Guided Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2006.14347
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GPGL&#30340;epoch-evolving Gaussian Process Guided Learning&#23398;&#20064;&#26041;&#26696;&#65292;&#36890;&#36807;&#19978;&#19979;&#25991;&#26631;&#31614;&#21644;&#22320;&#38754;&#30495;&#23454;&#26631;&#31614;&#25351;&#23548;&#27169;&#22411;&#21442;&#25968;&#26356;&#26032;&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#24182;&#24212;&#29992;&#20110;&#24403;&#21069;&#28145;&#24230;&#27169;&#22411;&#65292;&#22312;&#20027;&#27969;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#22522;&#20110;&#25209;&#27425;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#19981;&#26029;&#28436;&#21464;&#30340;&#39640;&#26031;&#36807;&#31243;&#24341;&#23548;&#23398;&#20064;&#65288;GPGL&#65289;&#30340;&#26032;&#39062;&#23398;&#20064;&#26041;&#26696;&#65292;&#26088;&#22312;&#25551;&#36848;&#25209;&#32423;&#20998;&#24067;&#19982;&#20840;&#23616;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#30456;&#20851;&#20449;&#24687;&#12290;&#36825;&#31181;&#30456;&#20851;&#20449;&#24687;&#34987;&#32534;&#30721;&#20026;&#19978;&#19979;&#25991;&#26631;&#31614;&#65292;&#38656;&#35201;&#27599;&#20010;&#26102;&#26399;&#36827;&#34892;&#26356;&#26032;&#12290;&#22312;&#19978;&#19979;&#25991;&#26631;&#31614;&#21644;&#22320;&#38754;&#30495;&#23454;&#26631;&#31614;&#30340;&#25351;&#23548;&#19979;&#65292;GPGL&#26041;&#26696;&#36890;&#36807;&#20351;&#29992;&#19977;&#35282;&#19968;&#33268;&#24615;&#25439;&#22833;&#26469;&#26356;&#26032;&#27169;&#22411;&#21442;&#25968;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#39640;&#25928;&#30340;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;GPGL&#26041;&#26696;&#21487;&#20197;&#36827;&#19968;&#27493;&#25512;&#24191;&#24182;&#33258;&#28982;&#24212;&#29992;&#20110;&#24403;&#21069;&#30340;&#28145;&#24230;&#27169;&#22411;&#65292;&#22312;&#20027;&#27969;&#25968;&#25454;&#38598;&#65288;CIFAR-10&#12289;CIFAR-100&#21644;Tiny-ImageNet&#65289;&#19978;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#22522;&#20110;&#25209;&#27425;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2006.14347v2 Announce Type: replace  Abstract: In this paper, we propose a novel learning scheme called epoch-evolving Gaussian Process Guided Learning (GPGL), which aims at characterizing the correlation information between the batch-level distribution and the global data distribution. Such correlation information is encoded as context labels and needs renewal every epoch. With the guidance of the context label and ground truth label, GPGL scheme provides a more efficient optimization through updating the model parameters with a triangle consistency loss. Furthermore, our GPGL scheme can be further generalized and naturally applied to the current deep models, outperforming the existing batch-based state-of-the-art models on mainstream datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet) remarkably.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.15879</link><description>&lt;p&gt;
&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#31639;&#27861;: lil'HDoC
&lt;/p&gt;
&lt;p&gt;
lil'HDoC: An Algorithm for Good Arm Identification under Small Threshold Gap. (arXiv:2401.15879v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22909;&#33218;&#35782;&#21035;&#65288;GAI&#65289;&#26159;&#19968;&#20010;&#32431;&#25506;&#32034;&#24615;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#19968;&#20010;&#21333;&#29420;&#30340;&#23398;&#20064;&#22120;&#20250;&#22312;&#30830;&#23450;&#19968;&#20010;&#33218;&#26159;&#22909;&#33218;&#26102;&#31435;&#21363;&#36755;&#20986;&#35813;&#33218;&#12290;&#22909;&#33218;&#34987;&#23450;&#20041;&#20026;&#26399;&#26395;&#22238;&#25253;&#22823;&#20110;&#31561;&#20110;&#32473;&#23450;&#38408;&#20540;&#30340;&#33218;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;GAI&#38382;&#39064;&#65292;&#35813;&#38388;&#38553;&#25351;&#30340;&#26159;&#33218;&#30340;&#26399;&#26395;&#22238;&#25253;&#19982;&#32473;&#23450;&#38408;&#20540;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#26032;&#31639;&#27861;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;HDoC&#31639;&#27861;&#30340;&#24635;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#65292;lil'HDoC&#31639;&#27861;&#36755;&#20986;&#30340;&#31532;&#19968;&#20010;&#955;&#33218;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#21407;&#22987;HDoC&#31639;&#27861;&#30456;&#27604;&#20165;&#26377;&#24494;&#23567;&#30340;&#24046;&#24322;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Good arm identification (GAI) is a pure-exploration bandit problem in which a single learner outputs an arm as soon as it is identified as a good arm. A good arm is defined as an arm with an expected reward greater than or equal to a given threshold. This paper focuses on the GAI problem under a small threshold gap, which refers to the distance between the expected rewards of arms and the given threshold. We propose a new algorithm called lil'HDoC to significantly improve the total sample complexity of the HDoC algorithm. We demonstrate that the sample complexity of the first $\lambda$ output arm in lil'HDoC is bounded by the original HDoC algorithm, except for one negligible term, when the distance between the expected reward and threshold is small. Extensive experiments confirm that our algorithm outperforms the state-of-the-art algorithms in both synthetic and real-world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21487;&#20197;&#27604;&#36739;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#22312;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#26102;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.01981</link><description>&lt;p&gt;
&#36229;&#36234;&#36951;&#25022;&#65306;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#20960;&#20309;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Beyond Regrets: Geometric Metrics for Bayesian Optimization. (arXiv:2401.01981v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21487;&#20197;&#27604;&#36739;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#22312;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#26102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#38024;&#23545;&#40657;&#30418;&#23376;&#30446;&#26631;&#20989;&#25968;&#30340;&#21407;&#21017;&#24615;&#20248;&#21270;&#31574;&#30053;&#12290;&#23427;&#22312;&#31185;&#23398;&#21457;&#29616;&#21644;&#23454;&#39564;&#35774;&#35745;&#31561;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#25928;&#26524;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#36890;&#24120;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#22522;&#20110;&#36951;&#25022;&#30340;&#24230;&#37327;&#26469;&#35780;&#20272;&#30340;&#65292;&#22914;&#30636;&#26102;&#36951;&#25022;&#12289;&#31616;&#21333;&#36951;&#25022;&#21644;&#32047;&#31215;&#36951;&#25022;&#12290;&#36825;&#20123;&#24230;&#37327;&#20165;&#20381;&#36182;&#20110;&#20989;&#25968;&#35780;&#20272;&#65292;&#22240;&#27492;&#23427;&#20204;&#19981;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#35299;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#65292;&#20063;&#19981;&#32771;&#34385;&#26597;&#35810;&#28857;&#26412;&#36523;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#20204;&#19981;&#33021;&#21306;&#20998;&#26159;&#21542;&#25104;&#21151;&#25214;&#21040;&#20102;&#22810;&#20010;&#20840;&#23616;&#35299;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#20063;&#19981;&#33021;&#35780;&#20272;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#32473;&#23450;&#25628;&#32034;&#31354;&#38388;&#20013;&#21033;&#29992;&#21644;&#25506;&#32034;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21363;&#31934;&#30830;&#24230;&#12289;&#21484;&#22238;&#29575;&#12289;&#24179;&#22343;&#24230;&#21644;&#24179;&#22343;&#36317;&#31163;&#12290;&#36825;&#20123;&#24230;&#37327;&#20351;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a principled optimization strategy for a black-box objective function. It shows its effectiveness in a wide variety of real-world applications such as scientific discovery and experimental design. In general, the performance of Bayesian optimization is assessed by regret-based metrics such as instantaneous, simple, and cumulative regrets. These metrics only rely on function evaluations, so that they do not consider geometric relationships between query points and global solutions, or query points themselves. Notably, they cannot discriminate if multiple global solutions are successfully found. Moreover, they do not evaluate Bayesian optimization's abilities to exploit and explore a search space given. To tackle these issues, we propose four new geometric metrics, i.e., precision, recall, average degree, and average distance. These metrics allow us to compare Bayesian optimization algorithms considering the geometry of both query points and global optima, or que
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;(ID-ExpO)&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21487;&#21306;&#20998;&#30340;&#39044;&#27979;&#22120;&#26469;&#25552;&#39640;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#24182;&#20445;&#25345;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ID-ExpO&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2310.12553</link><description>&lt;p&gt;
&#21033;&#29992;&#21487;&#21306;&#20998;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#27491;&#21017;&#21270;&#36827;&#34892;&#35299;&#37322;&#24615;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers. (arXiv:2310.12553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12553
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;(ID-ExpO)&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21487;&#21306;&#20998;&#30340;&#39044;&#27979;&#22120;&#26469;&#25552;&#39640;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#24182;&#20445;&#25345;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ID-ExpO&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#22120;&#30340;&#35299;&#37322;&#36136;&#37327;&#36890;&#24120;&#20351;&#29992;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#36827;&#34892;&#34913;&#37327;&#65292;&#36825;&#20123;&#25351;&#26631;&#35780;&#20272;&#35299;&#37322;&#30340;&#24544;&#23454;&#24230;&#65292;&#21363;&#35299;&#37322;&#27491;&#30830;&#22320;&#21453;&#26144;&#20102;&#39044;&#27979;&#22120;&#30340;&#34892;&#20026;&#31243;&#24230;&#12290;&#20026;&#20102;&#25552;&#39640;&#24544;&#23454;&#24230;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25554;&#20837;/&#21024;&#38500;&#25351;&#26631;&#24863;&#30693;&#30340;&#22522;&#20110;&#35299;&#37322;&#30340;&#20248;&#21270;&#65288;ID-ExpO&#65289;&#65292;&#35813;&#20248;&#21270;&#33021;&#22815;&#25913;&#21892;&#35299;&#37322;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#24471;&#20998;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#30001;&#20110;&#21407;&#22987;&#30340;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#23545;&#20110;&#35299;&#37322;&#26469;&#35828;&#26159;&#19981;&#21487;&#21306;&#20998;&#30340;&#65292;&#24182;&#19988;&#26080;&#27861;&#30452;&#25509;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#20123;&#25351;&#26631;&#20197;&#20351;&#20854;&#21487;&#21306;&#20998;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#24418;&#24335;&#21270;&#25554;&#20837;&#21644;&#21024;&#38500;&#25351;&#26631;&#30340;&#27491;&#21017;&#21270;&#12290;&#22312;&#22270;&#20687;&#21644;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;ID-ExpO&#36827;&#34892;&#24494;&#35843;&#30340;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#22120;&#33021;&#22815;&#20351;&#27969;&#34892;&#30340;&#20107;&#21518;&#35299;&#37322;&#22120;&#20135;&#29983;&#26356;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quality of explanations for the predictions of complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how correctly the explanations reflect the predictor's behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both insertion and deletion scores of the explanations while keeping their predictive accuracy. Since the original insertion and deletion metrics are indifferentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics to be differentiable and use them to formalize insertion and deletion metric-based regularizers. The experimental results on image and tabular datasets show that the deep neural networks-based predictors fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;time-dependent Cox&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#36827;&#34892;&#24615;&#30524;&#37096;&#30142;&#30149;&#24180;&#40836;&#30456;&#20851;&#24615;&#40644;&#26001;&#21464;&#24615;&#65288;AMD&#65289;&#30340;&#36827;&#23637;&#12290;&#36890;&#36807;&#20351;&#29992;&#32437;&#21521;&#30524;&#24213;&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#24314;&#31435;&#19968;&#20010;&#20010;&#20307;&#21270;&#30340;&#39118;&#38505;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.05881</link><description>&lt;p&gt;
&#21160;&#24577;&#39044;&#27979;&#20351;&#29992;&#26102;&#21464;Cox&#29983;&#23384;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Dynamic Prediction using Time-Dependent Cox Survival Neural Network. (arXiv:2307.05881v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05881
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;time-dependent Cox&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#36827;&#34892;&#24615;&#30524;&#37096;&#30142;&#30149;&#24180;&#40836;&#30456;&#20851;&#24615;&#40644;&#26001;&#21464;&#24615;&#65288;AMD&#65289;&#30340;&#36827;&#23637;&#12290;&#36890;&#36807;&#20351;&#29992;&#32437;&#21521;&#30524;&#24213;&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#24314;&#31435;&#19968;&#20010;&#20010;&#20307;&#21270;&#30340;&#39118;&#38505;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#39044;&#27979;&#30340;&#30446;&#26631;&#26159;&#22312;&#19981;&#26029;&#26356;&#26032;&#30340;&#26032;&#25968;&#25454;&#21487;&#29992;&#26102;&#25552;&#20379;&#20010;&#20307;&#21270;&#30340;&#39118;&#38505;&#39044;&#27979;&#12290;&#21463;&#21040;&#24314;&#31435;&#19968;&#20010;&#38024;&#23545;&#36827;&#34892;&#24615;&#30524;&#37096;&#30142;&#30149;&#65292;&#24180;&#40836;&#30456;&#20851;&#24615;&#40644;&#26001;&#21464;&#24615;&#65288;AMD&#65289;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26102;&#21464;Cox&#27169;&#22411;&#30340;&#29983;&#23384;&#31070;&#32463;&#32593;&#32476;&#65288;tdCoxSNN&#65289;&#26469;&#39044;&#27979;&#20854;&#22312;&#25345;&#32493;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#36827;&#23637;&#65292;&#20351;&#29992;&#32437;&#21521;&#30524;&#24213;&#22270;&#20687;&#12290;tdCoxSNN&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#27169;&#25311;&#26102;&#21464;&#21327;&#21464;&#37327;&#23545;&#29983;&#23384;&#32467;&#26524;&#30340;&#38750;&#32447;&#24615;&#24433;&#21709;&#25193;&#23637;&#20102;&#26102;&#21464;Cox&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#32467;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#65292;tdCoxSNN&#21487;&#20197;&#20197;&#32437;&#21521;&#21407;&#22987;&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#12290;&#25105;&#20204;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#65292;&#20351;&#29992;&#20004;&#20010;&#26102;&#21464;&#31934;&#24230;&#24230;&#37327;&#26631;&#20934;&#65292;Brier&#20998;&#25968;&#21644;&#21160;&#24577;AUC&#27604;&#36739;&#21644;&#35780;&#20272;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#32852;&#21512;&#24314;&#27169;&#21644;&#37324;&#31243;&#30865;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;&#19968;&#20010;&#26159;&#19968;&#20010;&#22823;&#22411;AMD&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
The target of dynamic prediction is to provide individualized risk predictions over time which can be updated as new data become available. Motivated by establishing a dynamic prediction model for the progressive eye disease, age-related macular degeneration (AMD), we proposed a time-dependent Cox model-based survival neural network (tdCoxSNN) to predict its progression on a continuous time scale using longitudinal fundus images. tdCoxSNN extends the time-dependent Cox model by utilizing a neural network to model the non-linear effect of the time-dependent covariates on the survival outcome. Additionally, by incorporating the convolutional neural network (CNN), tdCoxSNN can take the longitudinal raw images as input. We evaluate and compare our proposed method with joint modeling and landmarking approaches through comprehensive simulations using two time-dependent accuracy metrics, the Brier Score and dynamic AUC. We applied the proposed approach to two real datasets. One is a large AMD
&lt;/p&gt;</description></item><item><title>&#26032;&#25552;&#20986;&#30340;&#26041;&#27861; UACQR &#23558;&#26465;&#20214;&#20998;&#20301;&#20272;&#35745;&#21644;&#25972;&#21512;&#25512;&#26029;&#32467;&#21512;&#65292;&#20197;&#21306;&#20998;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#35782;&#24615;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#30456;&#24212;&#22320;&#26500;&#36896;&#39044;&#27979;&#21306;&#38388;&#65292;&#21487;&#20197;&#22312;&#37327;&#23376;&#22238;&#24402;&#22120;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#19981;&#21516;&#23376;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340; CQR &#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08693</link><description>&lt;p&gt;
&#23558;&#19981;&#30830;&#23450;&#24615;&#24847;&#35782;&#25972;&#21512;&#21040; Conformalized Quantile Regression &#20013;
&lt;/p&gt;
&lt;p&gt;
Integrating Uncertainty Awareness into Conformalized Quantile Regression. (arXiv:2306.08693v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08693
&lt;/p&gt;
&lt;p&gt;
&#26032;&#25552;&#20986;&#30340;&#26041;&#27861; UACQR &#23558;&#26465;&#20214;&#20998;&#20301;&#20272;&#35745;&#21644;&#25972;&#21512;&#25512;&#26029;&#32467;&#21512;&#65292;&#20197;&#21306;&#20998;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#35782;&#24615;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#30456;&#24212;&#22320;&#26500;&#36896;&#39044;&#27979;&#21306;&#38388;&#65292;&#21487;&#20197;&#22312;&#37327;&#23376;&#22238;&#24402;&#22120;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#19981;&#21516;&#23376;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340; CQR &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Conformalized Quantile Regression (CQR) &#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#19981;&#20570;&#20998;&#24067;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#32473;&#23450;&#21327;&#21464;&#37327; X &#30340;&#21709;&#24212; Y &#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#29616;&#26377;&#30340; CQR &#26500;&#36896;&#26041;&#27861;&#22312;&#37327;&#23376;&#22238;&#24402;&#22120;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#26576;&#20123;&#37096;&#20998;&#34920;&#29616;&#26356;&#22909;&#30340;&#38382;&#39064;&#19978;&#21487;&#33021;&#26080;&#25928;&#12290;&#20854;&#21407;&#22240;&#22312;&#20110; CQR &#30340;&#39044;&#27979;&#21306;&#38388;&#19981;&#21306;&#20998;&#20004;&#31181;&#19981;&#30830;&#23450;&#24615;&#24418;&#24335;&#65306;&#31532;&#19968;&#31181;&#26159;&#32473;&#23450; X &#30340;&#26465;&#20214;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#65288;&#21363;&#65292;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#65289;&#65292;&#31532;&#20108;&#31181;&#26159;&#25105;&#20204;&#20272;&#35745;&#36825;&#31181;&#26465;&#20214;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#65288;&#21363;&#65292;&#35748;&#35782;&#24615;&#19981;&#30830;&#23450;&#24615;&#65289;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#19981;&#22343;&#21248;&#30340;&#35206;&#30422;&#33539;&#22260;&#65292;&#22312;&#35748;&#35782;&#24615;&#19981;&#30830;&#23450;&#24615;&#20302;&#65288;&#25110;&#39640;&#65289;&#30340;&#21306;&#22495;&#20013;&#36807;&#24230;&#23485;&#65288;&#25110;&#36807;&#24230;&#31364;&#65289;&#30340;&#21306;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; Conformalized Quantile Regression &#30340;&#26032;&#21464;&#20307;&#65292;&#21363; Uncertainty-Aware CQR (UACQR)&#65292;&#35813;&#26041;&#27861;&#26126;&#30830;&#22320;&#20998;&#31163;&#36825;&#20004;&#31181;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#65292;&#24182;&#30456;&#24212;&#22320;&#26500;&#36896;&#39044;&#27979;&#21306;&#38388;&#12290;UACQR &#26041;&#27861;&#20351;&#29992;&#25972;&#21512;&#25512;&#26029;&#26469;&#37327;&#21270;&#20272;&#35745;&#32473;&#23450; X &#30340; Y &#30340;&#26465;&#20214;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21516;&#26102;&#36824;&#23558;&#26377;&#30028;&#30340;&#26465;&#20214;&#20998;&#20301;&#20272;&#35745;&#24182;&#20837;&#20854;&#20013;&#65292;&#20197;&#25429;&#25417;&#35813;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;UACQR &#22312;&#37327;&#23376;&#22238;&#24402;&#22120;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#23376;&#38598;&#19978;&#34920;&#29616;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#21487;&#20197;&#20248;&#20110;&#29616;&#26377;&#30340; CQR &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformalized Quantile Regression (CQR) is a recently proposed method for constructing prediction intervals for a response $Y$ given covariates $X$, without making distributional assumptions. However, as we demonstrate empirically, existing constructions of CQR can be ineffective for problems where the quantile regressors perform better in certain parts of the feature space than others. The reason is that the prediction intervals of CQR do not distinguish between two forms of uncertainty: first, the variability of the conditional distribution of $Y$ given $X$ (i.e., aleatoric uncertainty), and second, our uncertainty in estimating this conditional distribution (i.e., epistemic uncertainty). This can lead to uneven coverage, with intervals that are overly wide (or overly narrow) in regions where epistemic uncertainty is low (or high). To address this, we propose a new variant of the CQR methodology, Uncertainty-Aware CQR (UACQR), that explicitly separates these two sources of uncertaint
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Wasserstein&#36317;&#31163;&#23545;&#19977;&#32500;&#29289;&#20307;&#36827;&#34892;&#23545;&#40784;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#20248;&#21270;&#23454;&#29616;&#35745;&#31639;&#12290;&#22312;&#23545;&#40784;&#30495;&#23454;&#34507;&#30333;&#36136;&#20998;&#23376;&#26041;&#38754;&#65292;&#35813;&#31639;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#24182;&#38416;&#26126;&#20102;&#23545;&#26032;&#36317;&#31163;&#20989;&#25968;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2305.12310</link><description>&lt;p&gt;
&#20351;&#29992;Wasserstein&#36317;&#31163;&#23545;&#23494;&#24230;&#22320;&#22270;&#36827;&#34892;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Alignment of Density Maps in Wasserstein Distance. (arXiv:2305.12310v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Wasserstein&#36317;&#31163;&#23545;&#19977;&#32500;&#29289;&#20307;&#36827;&#34892;&#23545;&#40784;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#20248;&#21270;&#23454;&#29616;&#35745;&#31639;&#12290;&#22312;&#23545;&#40784;&#30495;&#23454;&#34507;&#30333;&#36136;&#20998;&#23376;&#26041;&#38754;&#65292;&#35813;&#31639;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#24182;&#38416;&#26126;&#20102;&#23545;&#26032;&#36317;&#31163;&#20989;&#25968;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#23558;&#19977;&#32500;&#29289;&#20307;&#34920;&#31034;&#20026;&#23494;&#24230;&#22320;&#22270;&#24182;&#36827;&#34892;&#23545;&#40784;&#65292;&#35813;&#31639;&#27861;&#30340;&#21160;&#26426;&#26159;&#22312;&#20919;&#20923;&#30005;&#23376;&#26174;&#24494;&#38236;&#20013;&#30340;&#24212;&#29992;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#22312;&#21018;&#24615;&#21464;&#25442;&#21518;&#23494;&#24230;&#22320;&#22270;&#20043;&#38388;&#26368;&#23567;&#21270;1-Wasserstein&#36317;&#31163;&#12290;&#24341;&#20837;&#30340;&#25439;&#22833;&#20989;&#25968;&#27604;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#22330;&#20855;&#26377;&#26356;&#22909;&#30340;&#29305;&#24615;&#65292;&#24182;&#20351;&#29992;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#35745;&#31639;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#30495;&#23454;&#34507;&#30333;&#36136;&#20998;&#23376;&#30340;&#23545;&#40784;&#26041;&#38754;&#65292;&#35813;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#22312;&#23545;&#40784;&#24322;&#36136;&#23545;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#26032;&#36317;&#31163;&#20989;&#25968;&#30340;&#28508;&#22312;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we propose an algorithm for aligning three-dimensional objects when represented as density maps, motivated by applications in cryogenic electron microscopy. The algorithm is based on minimizing the 1-Wasserstein distance between the density maps after a rigid transformation. The induced loss function enjoys a more benign landscape than its Euclidean counterpart and Bayesian optimization is employed for computation. Numerical experiments show improved accuracy and efficiency over existing algorithms on the alignment of real protein molecules. In the context of aligning heterogeneous pairs, we illustrate a potential need for new distance functions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2305.10015</link><description>&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#25928;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Utility Theory of Synthetic Data Generation. (arXiv:2305.10015v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#30340;&#25928;&#29992;&#23545;&#20110;&#34913;&#37327;&#21512;&#25104;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#32467;&#26524;&#20391;&#37325;&#20110;&#23545;&#21512;&#25104;&#25968;&#25454;&#25928;&#29992;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#32780;&#38024;&#23545;&#21512;&#25104;&#25968;&#25454;&#31639;&#27861;&#22914;&#20309;&#24433;&#21709;&#25928;&#29992;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#12290;&#35813;&#25351;&#26631;&#23450;&#20041;&#20026;&#22312;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#20043;&#38388;&#27867;&#21270;&#30340;&#32477;&#23545;&#24046;&#24322;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35813;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#26469;&#30740;&#31350;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#12290;&#19968;&#20010;&#26377;&#36259;&#30340;&#32467;&#26524;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#21017;&#35813;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;&#21478;&#19968;&#20010;&#37325;&#35201;&#30340;&#25928;&#29992;&#25351;&#26631;&#22522;&#20110;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#20043;&#38388;&#28508;&#22312;&#30340;&#22240;&#26524;&#26426;&#21046;&#19968;&#33268;&#24615;&#12290;&#35813;&#29702;&#35770;&#20351;&#29992;&#20960;&#31181;&#21512;&#25104;&#31639;&#27861;&#36827;&#34892;&#35828;&#26126;&#65292;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#25928;&#29992;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating the utility of synthetic data is critical for measuring the effectiveness and efficiency of synthetic algorithms. Existing results focus on empirical evaluations of the utility of synthetic data, whereas the theoretical understanding of how utility is affected by synthetic data algorithms remains largely unexplored. This paper establishes utility theory from a statistical perspective, aiming to quantitatively assess the utility of synthetic algorithms based on a general metric. The metric is defined as the absolute difference in generalization between models trained on synthetic and original datasets. We establish analytical bounds for this utility metric to investigate critical conditions for the metric to converge. An intriguing result is that the synthetic feature distribution is not necessarily identical to the original one for the convergence of the utility metric as long as the model specification in downstream learning tasks is correct. Another important utility metri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411; (N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#21487;&#20197;&#23545;&#36830;&#32493;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17823</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#36830;&#32493;&#22238;&#24212;&#26377;&#24207;&#22238;&#24402;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response. (arXiv:2303.17823v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17823
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411; (N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#21487;&#20197;&#23545;&#36830;&#32493;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411;&#65288;N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#20854;&#20013;&#21453;&#24212;&#21464;&#37327;&#19981;&#20165;&#21487;&#20197;&#21462;&#31163;&#25955;&#20540;&#65292;&#20063;&#21487;&#20197;&#21462;&#36830;&#32493;&#20540;&#65292;&#32780;&#22238;&#24402;&#31995;&#25968;&#26681;&#25454;&#39044;&#27979;&#39034;&#24207;&#21453;&#24212;&#20063;&#19981;&#21516;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30452;&#25509;&#20174;&#31163;&#25955;&#21453;&#24212;&#20272;&#35745;&#32447;&#24615;&#31995;&#25968;&#19981;&#21516;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#20197;&#21453;&#24212;&#20026;&#36755;&#20837;&#20135;&#29983;&#32447;&#24615;&#31995;&#25968;&#12290;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#65292;N$^3$POM&#21487;&#20197;&#22312;&#20445;&#30041;&#20256;&#32479;&#26377;&#24207;&#22238;&#24402;&#30340;&#21487;&#35299;&#37322;&#24615;&#30340;&#21516;&#26102;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20805;&#20998;&#30340;&#26465;&#20214;&#65292;&#20351;&#24471;&#22312;&#25351;&#23450;&#30340;&#29992;&#25143;&#21306;&#22495;&#20869;&#65292;&#39044;&#27979;&#30340;&#26465;&#20214;&#32047;&#31215;&#27010;&#29575;&#65288;CCP&#65289;&#28385;&#36275;&#23616;&#37096;&#21333;&#35843;&#24615;&#32422;&#26463;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#20445;&#25345;&#21333;&#35843;&#24615;&#30340;&#38543;&#26426;&#65288;MPS&#65289;&#31639;&#27861;&#26469;&#20805;&#20998;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an interpretable neural network-based non-proportional odds model (N$^3$POM) for ordinal regression, where the response variable can take not only discrete but also continuous values, and the regression coefficients vary depending on the predicting ordinal response. In contrast to conventional approaches estimating the linear coefficients of regression directly from the discrete response, we train a non-linear neural network that outputs the linear coefficients by taking the response as its input. By virtue of the neural network, N$^3$POM may have flexibility while preserving the interpretability of the conventional ordinal regression. We show a sufficient condition so that the predicted conditional cumulative probability~(CCP) satisfies the monotonicity constraint locally over a user-specified region in the covariate space; we also provide a monotonicity-preserving stochastic (MPS) algorithm for training the neural network adequately.
&lt;/p&gt;</description></item></channel></rss>