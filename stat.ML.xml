<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#23558;&#25968;&#25454;&#32422;&#26463;&#21407;&#21017;&#24615;&#22320;&#25972;&#21512;&#21040;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#20197;&#21462;&#20195;&#20043;&#21069;&#37319;&#29992;&#30340;&#23548;&#33268;&#19981;&#33258;&#28982;&#26679;&#26412;&#30340;&#38408;&#20540;&#22788;&#29702;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2304.04740</link><description>&lt;p&gt;
&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Reflected Diffusion Models. (arXiv:2304.04740v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#23558;&#25968;&#25454;&#32422;&#26463;&#21407;&#21017;&#24615;&#22320;&#25972;&#21512;&#21040;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#20197;&#21462;&#20195;&#20043;&#21069;&#37319;&#29992;&#30340;&#23548;&#33268;&#19981;&#33258;&#28982;&#26679;&#26412;&#30340;&#38408;&#20540;&#22788;&#29702;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#22122;&#22768;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21453;&#21521;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22797;&#26434;&#20219;&#21153;&#65292;&#25968;&#20540;&#35823;&#24046;&#21487;&#20197;&#32047;&#31215;&#24182;&#23548;&#33268;&#39640;&#24230;&#19981;&#33258;&#28982;&#30340;&#26679;&#26412;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#38408;&#20540;&#22788;&#29702;&#26469;&#32531;&#35299;&#28418;&#31227;&#65292;&#27599;&#27425;&#25193;&#25955;&#27493;&#39588;&#21518;&#25237;&#24433;&#21040;&#33258;&#28982;&#25968;&#25454;&#22495;&#65288;&#20363;&#22914;&#22270;&#20687;&#30340;&#20687;&#32032;&#31354;&#38388;&#65289;&#65292;&#20294;&#36825;&#23548;&#33268;&#35757;&#32451;&#21644;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#23384;&#22312;&#19981;&#21305;&#37197;&#12290;&#20026;&#20102;&#20197;&#19968;&#31181;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#21512;&#24182;&#25968;&#25454;&#32422;&#26463;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21453;&#21521;&#28436;&#21270;&#22312;&#25968;&#25454;&#25903;&#25345;&#30340;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#19978;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#19968;&#33324;&#21270;&#30340;&#20998;&#25968;&#21305;&#37197;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#24182;&#25193;&#23637;&#20102;&#26631;&#20934;&#25193;&#25955;&#27169;&#22411;&#30340;&#20851;&#38190;&#32452;&#20214;&#65292;&#21253;&#25324;&#25193;&#25955;&#24341;&#23548;&#12289;&#22522;&#20110;&#20284;&#28982;&#30340;&#35757;&#32451;&#21644;ODE&#37319;&#26679;&#12290;&#25105;&#20204;&#36824;&#24357;&#21512;&#20102;&#38408;&#20540;&#22788;&#29702;&#30340;&#29702;&#35770;&#24046;&#36317;:&#36825;&#26679;&#30340;&#26041;&#26696;&#21482;&#26159;&#21453;&#23556;SDE&#30340;&#31163;&#25955;&#21270;&#12290;&#22312;&#26631;&#20934;&#22270;&#20687;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#30340;
&lt;/p&gt;
&lt;p&gt;
Score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. However, for complex tasks, numerical error can compound and result in highly unnatural samples. Previous work mitigates this drift with thresholding, which projects to the natural data domain (such as pixel space for images) after each diffusion step, but this leads to a mismatch between the training and generative processes. To incorporate data constraints in a principled manner, we present Reflected Diffusion Models, which instead reverse a reflected stochastic differential equation evolving on the support of the data. Our approach learns the perturbed score function through a generalize score matching loss and extends key components of standard diffusion models including diffusion guidance, likelihood-based training, and ODE sampling. We also bridge the theoretical gap with thresholding: such schemes are just discretizations of reflected SDEs. On standard image benchmarks, our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#65292;&#20174;&#39640;&#32500;&#24179;&#28369;&#30446;&#26631;&#20998;&#24067;&#37319;&#26679;&#26102;&#65292;Metropolized Hamiltonian Monte Carlo (HMC)&#27604;Metropolis-adjusted Langevin&#31639;&#27861;&#65288;MALA&#65289;&#26356;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2304.04724</link><description>&lt;p&gt;
Metropolized Hamiltonian Monte Carlo&#20309;&#26102;&#33021;&#35777;&#26126;&#20248;&#20110;Metropolis-adjusted Langevin&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
When does Metropolized Hamiltonian Monte Carlo provably outperform Metropolis-adjusted Langevin algorithm?. (arXiv:2304.04724v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#65292;&#20174;&#39640;&#32500;&#24179;&#28369;&#30446;&#26631;&#20998;&#24067;&#37319;&#26679;&#26102;&#65292;Metropolized Hamiltonian Monte Carlo (HMC)&#27604;Metropolis-adjusted Langevin&#31639;&#27861;&#65288;MALA&#65289;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;Metropolized Hamiltonian Monte Carlo (HMC)&#30340;&#28151;&#21512;&#26102;&#38388;&#65292;&#20351;&#29992;leapfrog&#31215;&#20998;&#22120;&#20174;$\mathbb{R}^d$&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#35813;&#20998;&#24067;&#30340;&#23545;&#25968;&#23494;&#24230;&#24179;&#28369;&#65292;&#20855;&#26377;Frobenius&#33539;&#25968;&#19978;&#30340;&#26446;&#26222;&#24076;&#33576;&#40657;&#22622;&#65292;&#24182;&#28385;&#36275;&#31561;&#21608;&#24615;&#12290;&#25105;&#20204;&#23558;&#26799;&#24230;&#22797;&#26434;&#24230;&#38480;&#21046;&#20026;&#20174;&#19968;&#20010;&#26262;&#21551;&#21160;&#36798;&#21040;$\epsilon$&#35823;&#24046;&#30340;&#24635;&#21464;&#24322;&#36317;&#31163;&#25152;&#38656;&#30340;$\tilde O(d^{1/4}\text{polylog}(1/\epsilon))$&#65292;&#24182;&#23637;&#31034;&#20102;&#36873;&#25321;&#27604;1&#26356;&#22823;&#30340;leapfrog&#27493;&#25968;&#30340;&#22909;&#22788;&#12290;&#20026;&#20102;&#36229;&#36234;Wu&#31561;&#20154;&#65288;2022&#65289;&#23545;Metropolis-adjusted Langevin algorithm (MALA)&#30340;&#20998;&#26512;&#65292;&#20854;&#22312;&#32500;&#24230;&#20381;&#36182;&#24615;&#19978;&#26159;$\tilde{O}(d^{1/2}\text{polylog}(1/\epsilon))$&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#35777;&#26126;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24449;&#65306;&#36830;&#32493;HMC&#21160;&#24577;&#30340;&#20301;&#32622;&#21644;&#36895;&#24230;&#21464;&#37327;&#30340;&#31163;&#25955;&#21270;&#30340;&#32852;&#21512;&#20998;&#24067;&#36817;&#20284;&#19981;&#21464;&#12290;&#24403;&#36890;&#36807;leapfrog&#27493;&#25968;&#30340;&#24402;&#32435;&#26469;&#23637;&#31034;&#36825;&#20010;&#20851;&#38190;&#29305;&#24449;&#26102;&#65292;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#21508;&#31181;&#37327;&#30340;&#30697;&#30340;&#20272;&#35745;&#65292;&#36825;&#20123;&#37327;&#22312;&#38480;&#21046;Metropolized HMC&#30340;&#28151;&#21512;&#26102;&#38388;&#26102;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#32780;&#22312;MALA&#20013;&#24050;&#30693;&#30340;&#31867;&#20284;&#32467;&#26524;&#26159;&#38169;&#35823;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#37319;&#26679;&#39640;&#32500;&#24179;&#28369;&#30446;&#26631;&#20998;&#24067;&#26102;&#65292;&#20351;&#29992;&#20855;&#26377;&#22823;&#37327;leapfrog&#27493;&#39588;&#30340;Metropolized HMC&#21487;&#33021;&#27604;&#20351;&#29992;MALA&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the mixing time of Metropolized Hamiltonian Monte Carlo (HMC) with the leapfrog integrator to sample from a distribution on $\mathbb{R}^d$ whose log-density is smooth, has Lipschitz Hessian in Frobenius norm and satisfies isoperimetry. We bound the gradient complexity to reach $\epsilon$ error in total variation distance from a warm start by $\tilde O(d^{1/4}\text{polylog}(1/\epsilon))$ and demonstrate the benefit of choosing the number of leapfrog steps to be larger than 1. To surpass previous analysis on Metropolis-adjusted Langevin algorithm (MALA) that has $\tilde{O}(d^{1/2}\text{polylog}(1/\epsilon))$ dimension dependency in Wu et al. (2022), we reveal a key feature in our proof that the joint distribution of the location and velocity variables of the discretization of the continuous HMC dynamics stays approximately invariant. This key feature, when shown via induction over the number of leapfrog steps, enables us to obtain estimates on moments of various quantities tha
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#21487;&#20280;&#32553;&#30340;&#38543;&#26426;&#26680;&#26041;&#27861;&#65292;&#21487;&#20197;&#32852;&#21512;&#22810;&#20010;&#26469;&#28304;&#30340;&#25968;&#25454;&#65292;&#35782;&#21035;&#22810;&#35270;&#35282;&#25968;&#25454;&#20043;&#38388;&#38750;&#32447;&#24615;&#20851;&#31995;&#20013;&#26368;&#26377;&#25928;&#30340;&#36129;&#29486;&#22240;&#32032;&#65292;&#24182;&#39044;&#27979;&#20020;&#24202;&#32467;&#26524;&#12290;&#22312;COVID-19&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#21457;&#29616;&#20102;&#30456;&#20851;&#30340;&#20998;&#23376;&#26631;&#24535;&#12290;</title><link>http://arxiv.org/abs/2304.04692</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#38543;&#26426;&#26680;&#26041;&#27861;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#38598;&#25104;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Scalable Randomized Kernel Methods for Multiview Data Integration and Prediction. (arXiv:2304.04692v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04692
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#21487;&#20280;&#32553;&#30340;&#38543;&#26426;&#26680;&#26041;&#27861;&#65292;&#21487;&#20197;&#32852;&#21512;&#22810;&#20010;&#26469;&#28304;&#30340;&#25968;&#25454;&#65292;&#35782;&#21035;&#22810;&#35270;&#35282;&#25968;&#25454;&#20043;&#38388;&#38750;&#32447;&#24615;&#20851;&#31995;&#20013;&#26368;&#26377;&#25928;&#30340;&#36129;&#29486;&#22240;&#32032;&#65292;&#24182;&#39044;&#27979;&#20020;&#24202;&#32467;&#26524;&#12290;&#22312;COVID-19&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#21457;&#29616;&#20102;&#30456;&#20851;&#30340;&#20998;&#23376;&#26631;&#24535;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#38543;&#26426;&#26680;&#26041;&#27861;&#65292;&#29992;&#20110;&#32852;&#21512;&#22810;&#20010;&#26469;&#28304;&#30340;&#25968;&#25454;&#65292;&#21516;&#26102;&#39044;&#27979;&#32467;&#26524;&#25110;&#23558;&#21333;&#20803;&#20998;&#31867;&#20026;&#20004;&#20010;&#25110;&#22810;&#20010;&#31867;&#21035;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#27169;&#25311;&#22810;&#35270;&#35282;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#39044;&#27979;&#20020;&#24202;&#32467;&#26524;&#65292;&#33021;&#22815;&#35782;&#21035;&#26368;&#26377;&#21161;&#20110;&#35270;&#22270;&#20043;&#38388;&#20851;&#31995;&#30340;&#21464;&#37327;&#25110;&#21464;&#37327;&#32452;&#12290;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#20613;&#37324;&#21494;&#22522;&#20989;&#25968;&#36817;&#20284;&#24179;&#31227;&#19981;&#21464;&#30340;&#26680;&#20989;&#25968;&#26469;&#26500;&#36896;&#27599;&#20010;&#35270;&#22270;&#30340;&#38750;&#32447;&#24615;&#26144;&#23556;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#26144;&#23556;&#21644;&#32467;&#26524;&#21464;&#37327;&#26469;&#23398;&#20064;&#35270;&#22270;&#26080;&#20851;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22810;&#35270;&#35282;&#25968;&#25454;&#38598;&#25104;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#20960;&#31181;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#26041;&#27861;&#12290;&#24403;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#28041;&#21450;COVID-19&#30340;&#22522;&#22240;&#34920;&#36798;&#12289;&#20195;&#35874;&#32452;&#23398;&#12289;&#34507;&#30333;&#32452;&#23398;&#21644;&#33026;&#36136;&#32452;&#23398;&#25968;&#25454;&#26102;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#20960;&#31181;COVID-19&#20005;&#37325;&#31243;&#24230;&#21644;&#39044;&#21518;&#30340;&#20998;&#23376;&#26631;&#24535;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop scalable randomized kernel methods for jointly associating data from multiple sources and simultaneously predicting an outcome or classifying a unit into one of two or more classes. The proposed methods model nonlinear relationships in multiview data together with predicting a clinical outcome and are capable of identifying variables or groups of variables that best contribute to the relationships among the views. We use the idea that random Fourier bases can approximate shift-invariant kernel functions to construct nonlinear mappings of each view and we use these mappings and the outcome variable to learn view-independent low-dimensional representations. Through simulation studies, we show that the proposed methods outperform several other linear and nonlinear methods for multiview data integration. When the proposed methods were applied to gene expression, metabolomics, proteomics, and lipidomics data pertaining to COVID-19, we identified several molecular signatures forCO
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#29983;&#25104;&#30340;&#36807;&#31243;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#36882;&#24402;&#26144;&#23556;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#22810;&#20010;&#24212;&#29992;&#21450;&#30456;&#20851;&#39046;&#22495;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.04657</link><description>&lt;p&gt;
&#35770;&#38543;&#26426;&#36941;&#21382;&#30340;&#24378;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the strong stability of ergodic iterations. (arXiv:2304.04657v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#29983;&#25104;&#30340;&#36807;&#31243;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#36882;&#24402;&#26144;&#23556;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#22810;&#20010;&#24212;&#29992;&#21450;&#30456;&#20851;&#39046;&#22495;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#30001;&#38543;&#26426;&#20989;&#25968;&#36845;&#20195;&#29983;&#25104;&#30340;&#36807;&#31243;&#65292;&#36825;&#20123;&#20989;&#25968;&#30001;&#19968;&#20010;&#24179;&#31283;&#19988;&#31526;&#21512;&#36941;&#21382;&#26465;&#20214;&#30340;&#24207;&#21015;&#39537;&#21160;&#12290;&#22914;&#26524;&#23384;&#22312;&#19968;&#20010;&#38543;&#26426;&#21021;&#22987;&#21270;&#20351;&#24471;&#35813;&#36807;&#31243;&#26159;&#31283;&#23450;&#21644;&#36941;&#21382;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;&#20219;&#20309;&#20854;&#20182;&#21021;&#22987;&#21270;&#65292;&#20004;&#20010;&#36807;&#31243;&#20043;&#38388;&#30340;&#24046;&#24322;&#20960;&#20046;&#32943;&#23450;&#25910;&#25947;&#20110;&#38646;&#65292;&#37027;&#20040;&#36825;&#26679;&#30340;&#36807;&#31243;&#34987;&#31216;&#20026;&#24378;&#31283;&#23450;&#12290;&#22312;&#23545;&#24212;&#36882;&#24402;&#26144;&#23556;&#19978;&#26045;&#21152;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#65292;&#32780;&#19981;&#22312;&#39537;&#21160;&#24207;&#21015;&#19978;&#26045;&#21152;&#20219;&#20309;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36845;&#20195;&#30340;&#24378;&#31283;&#23450;&#24615;&#12290;&#22810;&#20010;&#24212;&#29992;&#34987;&#30740;&#31350;&#65292;&#22914;&#38543;&#26426;&#36924;&#36817;&#21644;&#25490;&#38431;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20855;&#26377;&#20381;&#36182;&#22122;&#22768;&#30340; Langevin &#22411;&#36845;&#20195;&#21644;&#22810;&#22411;&#20998;&#25903;&#36807;&#31243;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit processes generated by iterated random functions driven by a stationary and ergodic sequence. Such a process is called strongly stable if a random initialization exists, for which the process is stationary and ergodic, and for any other initialization, the difference of the two processes converges to zero almost surely. Under some mild conditions on the corresponding recursive map, without any condition on the driving sequence, we show the strong stability of iterations. Several applications are surveyed such as stochastic approximation and queuing. Furthermore, new results are deduced for Langevin-type iterations with dependent noise and for multitype branching processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#26368;&#36817;&#20851;&#20110;&#24072;&#29983;&#23398;&#20064;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#37325;&#28857;&#35752;&#35770;&#20102;&#30693;&#35782;&#33976;&#39311;&#30340;&#21464;&#20307;&#65292;&#22914;&#25945;&#23398;&#21161;&#29702;&#33976;&#39311;&#12289;&#35838;&#31243;&#33976;&#39311;&#12289;&#25513;&#30721;&#33976;&#39311;&#21644;&#35299;&#32806;&#33976;&#39311;&#31561;&#65292;&#36825;&#20123;&#21464;&#20307;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#20214;&#25110;&#25913;&#21464;&#23398;&#20064;&#36807;&#31243;&#26469;&#25552;&#39640;&#30693;&#35782;&#33976;&#39311;&#30340;&#24615;&#33021;&#65292;&#24050;&#32463;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.04615</link><description>&lt;p&gt;
&#26368;&#36817;&#20851;&#20110;&#24072;&#29983;&#23398;&#20064;&#30340;&#30740;&#31350;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Recent Teacher-student Learning Studies. (arXiv:2304.04615v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04615
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#26368;&#36817;&#20851;&#20110;&#24072;&#29983;&#23398;&#20064;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#37325;&#28857;&#35752;&#35770;&#20102;&#30693;&#35782;&#33976;&#39311;&#30340;&#21464;&#20307;&#65292;&#22914;&#25945;&#23398;&#21161;&#29702;&#33976;&#39311;&#12289;&#35838;&#31243;&#33976;&#39311;&#12289;&#25513;&#30721;&#33976;&#39311;&#21644;&#35299;&#32806;&#33976;&#39311;&#31561;&#65292;&#36825;&#20123;&#21464;&#20307;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#20214;&#25110;&#25913;&#21464;&#23398;&#20064;&#36807;&#31243;&#26469;&#25552;&#39640;&#30693;&#35782;&#33976;&#39311;&#30340;&#24615;&#33021;&#65292;&#24050;&#32463;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#33976;&#39311;&#26159;&#19968;&#31181;&#23558;&#22797;&#26434;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#30693;&#35782;&#20256;&#36882;&#32473;&#26356;&#23567;&#26356;&#24555;&#30340;DNN&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#20934;&#30830;&#24615;&#12290;&#26368;&#36817;&#30340;&#30693;&#35782;&#33976;&#39311;&#21464;&#20307;&#21253;&#25324;&#25945;&#23398;&#21161;&#29702;&#33976;&#39311;&#65292;&#35838;&#31243;&#33976;&#39311;&#65292;&#25513;&#30721;&#33976;&#39311;&#21644;&#35299;&#32806;&#33976;&#39311;&#65292;&#26088;&#22312;&#36890;&#36807;&#24341;&#20837;&#38468;&#21152;&#32452;&#20214;&#25110;&#26356;&#25913;&#23398;&#20064;&#36807;&#31243;&#26469;&#25913;&#21892;&#30693;&#35782;&#33976;&#39311;&#30340;&#24615;&#33021;&#12290;&#25945;&#23398;&#21161;&#29702;&#33976;&#39311;&#28041;&#21450;&#20013;&#38388;&#27169;&#22411;&#25945;&#23398;&#21161;&#29702;&#65292;&#32780;&#35838;&#31243;&#33976;&#39311;&#21017;&#36981;&#24490;&#31867;&#20284;&#20110;&#20154;&#31867;&#25945;&#32946;&#30340;&#35838;&#31243;&#12290;&#25513;&#30721;&#33976;&#39311;&#19987;&#27880;&#20110;&#20256;&#36882;&#32769;&#24072;&#23398;&#21040;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#32780;&#35299;&#32806;&#33976;&#39311;&#23558;&#33976;&#39311;&#25439;&#22833;&#19982;&#20219;&#21153;&#25439;&#22833;&#20998;&#31163;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#36825;&#20123;&#30693;&#35782;&#33976;&#39311;&#30340;&#21464;&#20307;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#25913;&#21892;&#30693;&#35782;&#33976;&#39311;&#24615;&#33021;&#26041;&#38754;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge distillation is a method of transferring the knowledge from a complex deep neural network (DNN) to a smaller and faster DNN, while preserving its accuracy. Recent variants of knowledge distillation include teaching assistant distillation, curriculum distillation, mask distillation, and decoupling distillation, which aim to improve the performance of knowledge distillation by introducing additional components or by changing the learning process. Teaching assistant distillation involves an intermediate model called the teaching assistant, while curriculum distillation follows a curriculum similar to human education. Mask distillation focuses on transferring the attention mechanism learned by the teacher, and decoupling distillation decouples the distillation loss from the task loss. Overall, these variants of knowledge distillation have shown promising results in improving the performance of knowledge distillation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28145;&#24230;ReLU&#32593;&#32476;&#36924;&#36817;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#20351;&#29992;&#31616;&#21333;&#30340;&#19977;&#35282;&#21078;&#20998;&#19979;&#26500;&#24314;&#20102;&#36830;&#32493;&#20998;&#27573;&#32447;&#24615;&#25554;&#20540;&#65292;&#23454;&#29616;&#20102;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.04443</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;ReLU&#32593;&#32476;&#36924;&#36817;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Approximation of Nonlinear Functionals Using Deep ReLU Networks. (arXiv:2304.04443v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04443
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28145;&#24230;ReLU&#32593;&#32476;&#36924;&#36817;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#20351;&#29992;&#31616;&#21333;&#30340;&#19977;&#35282;&#21078;&#20998;&#19979;&#26500;&#24314;&#20102;&#36830;&#32493;&#20998;&#27573;&#32447;&#24615;&#25554;&#20540;&#65292;&#23454;&#29616;&#20102;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#20154;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#36924;&#36817;&#22312;L^p([-1,1]^s)&#19978;&#23450;&#20041;&#30340;&#38750;&#32447;&#24615;&#36830;&#32493;&#20989;&#25968;&#65292;&#20854;&#20013;s&#8805;1&#65292;1&#8804;p&lt;&#8734;&#12290;&#28982;&#32780;&#65292;&#38500;&#36924;&#36817;&#30340;&#26222;&#36941;&#24615;&#22806;&#65292;&#23427;&#20204;&#30340;&#29702;&#35770;&#24615;&#36136;&#22823;&#22810;&#25968;&#36824;&#26159;&#26410;&#30693;&#30340;&#65292;&#25110;&#32773;&#29616;&#26377;&#30340;&#20998;&#26512;&#19981;&#36866;&#29992;&#20110;&#20462;&#27491;&#30340;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#28608;&#27963;&#20989;&#25968;&#12290;&#20026;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#22312;&#27492;&#36890;&#36807;&#22312;&#31616;&#21333;&#30340;&#19977;&#35282;&#21078;&#20998;&#19979;&#26500;&#24314;&#36830;&#32493;&#20998;&#27573;&#32447;&#24615;&#25554;&#20540;&#65292;&#30740;&#31350;&#20102;&#19982;ReLU&#28608;&#27963;&#20989;&#25968;&#30456;&#20851;&#30340;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#22312;&#28201;&#21644;&#30340;&#27491;&#21017;&#26465;&#20214;&#19979;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#30340;&#20989;&#25968;&#28145;&#24230;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#36895;&#29575;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20063;&#21487;&#33021;&#26377;&#21161;&#20110;&#29702;&#35299;&#20989;&#25968;&#25968;&#25454;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, functional neural networks have been proposed and studied in order to approximate nonlinear continuous functionals defined on $L^p([-1, 1]^s)$ for integers $s\ge1$ and $1\le p&lt;\infty$. However, their theoretical properties are largely unknown beyond universality of approximation or the existing analysis does not apply to the rectified linear unit (ReLU) activation function. To fill in this void, we investigate here the approximation power of functional deep neural networks associated with the ReLU activation function by constructing a continuous piecewise linear interpolation under a simple triangulation. In addition, we establish rates of approximation of the proposed functional deep ReLU networks under mild regularity conditions. Finally, our study may also shed some light on the understanding of functional data learning algorithms.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#23427;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#65292;&#29992;&#20110;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#65292;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2304.04374</link><description>&lt;p&gt;
&#21033;&#29992;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#22240;&#26524;&#25928;&#24212;&#37096;&#20998;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Partial Identification of Causal Effects Using Proxy Variables. (arXiv:2304.04374v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04374
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#23427;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#65292;&#29992;&#20110;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#65292;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#34987;&#25552;&#20986;&#20026;&#19968;&#31181;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#30340;&#26694;&#26550;&#12290;&#20854;&#20013;&#21033;&#29992;&#26410;&#34987;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#28857;&#20272;&#35745;&#65292;&#21069;&#25552;&#26159;&#36825;&#26679;&#30340;&#20195;&#29702;&#21464;&#37327;&#23545;&#28151;&#28102;&#22240;&#32032;&#30456;&#24403;&#26377;&#20851;&#65292;&#28982;&#32780;&#36825;&#31181;&#23436;&#22791;&#24615;&#21364;&#26159;&#32463;&#39564;&#19981;&#21487;&#26816;&#39564;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#35201;&#27714;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#24182;&#20026;&#24863;&#20852;&#36259;&#30340;&#22240;&#26524;&#25928;&#24212;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#24314;&#31435;&#22312;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#22522;&#30784;&#19978;&#65292;&#24182;&#19988;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#20195;&#29702;&#21464;&#37327;&#30340;&#26041;&#27861;&#35201;&#27714;&#26356;&#24369;&#12290;&#36825;&#39033;&#24037;&#20316;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#29616;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Proximal causal inference is a recently proposed framework for evaluating the causal effect of a treatment on an outcome variable in the presence of unmeasured confounding (Miao et al., 2018a; Tchetgen Tchetgen et al., 2020). For nonparametric point identification, the framework leverages proxy variables of unobserved confounders, provided that such proxies are sufficiently relevant for the latter, a requirement that has previously been formalized as a completeness condition. Completeness is key to connecting the observed proxy data to hidden factors via a so-called confounding bridge function, identification of which is an important step towards proxy-based point identification of causal effects. However, completeness is well-known not to be empirically testable, therefore potentially restricting the application of the proximal causal framework. In this paper, we propose partial identification methods that do not require completeness and obviate the need for identification of a bridge
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#22914;&#20309;&#22312;&#26399;&#26395;&#21644;&#23614;&#37096;&#39118;&#38505;&#20043;&#38388;&#20570;&#20986;&#26368;&#20248;&#26435;&#34913;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#33021;&#22815;&#23454;&#29616;&#26368;&#22351;&#21644;&#23454;&#20363;&#30456;&#20851;&#30340;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#19988;&#33021;&#22815;&#26368;&#23567;&#21270;&#36951;&#25022;&#23614;&#37096;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.04341</link><description>&lt;p&gt;
&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#30340;&#36951;&#25022;&#20998;&#24067;&#65306;&#26399;&#26395;&#21644;&#23614;&#37096;&#39118;&#38505;&#20043;&#38388;&#30340;&#26368;&#20248;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Regret Distribution in Stochastic Bandits: Optimal Trade-off between Expectation and Tail Risk. (arXiv:2304.04341v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04341
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#22914;&#20309;&#22312;&#26399;&#26395;&#21644;&#23614;&#37096;&#39118;&#38505;&#20043;&#38388;&#20570;&#20986;&#26368;&#20248;&#26435;&#34913;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#33021;&#22815;&#23454;&#29616;&#26368;&#22351;&#21644;&#23454;&#20363;&#30456;&#20851;&#30340;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#19988;&#33021;&#22815;&#26368;&#23567;&#21270;&#36951;&#25022;&#23614;&#37096;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#36951;&#25022;&#20998;&#24067;&#30340;&#26399;&#26395;&#21644;&#23614;&#37096;&#39118;&#38505;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#25105;&#20204;&#23436;&#20840;&#21051;&#30011;&#20102;&#31574;&#30053;&#35774;&#35745;&#20013;&#19977;&#20010;&#26399;&#26395;&#24615;&#36136;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65306;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26368;&#20248;&#24615;&#65292;&#23454;&#20363;&#30456;&#20851;&#30340;&#19968;&#33268;&#24615;&#21644;&#36731;&#23614;&#39118;&#38505;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26399;&#26395;&#36951;&#25022;&#30340;&#39034;&#24207;&#22914;&#20309;&#24433;&#21709;&#36951;&#25022;&#23614;&#37096;&#27010;&#29575;&#30340;&#34928;&#20943;&#29575;&#65292;&#21516;&#26102;&#21253;&#25324;&#20102;&#26368;&#22351;&#24773;&#20917;&#21644;&#23454;&#20363;&#30456;&#20851;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20197;&#34920;&#24449;&#23545;&#20110;&#20219;&#20309;&#36951;&#25022;&#38408;&#20540;&#30340;&#26368;&#20248;&#36951;&#25022;&#23614;&#37096;&#27010;&#29575;&#12290;&#20855;&#20307;&#22320;&#65292;&#23545;&#20110;&#20219;&#20309;&#32473;&#23450;&#30340;$\alpha \in [1/2, 1)$&#21644;$\beta \in [0, \alpha]$&#65292;&#25105;&#20204;&#30340;&#31574;&#30053;&#21487;&#20197;&#23454;&#29616;&#24179;&#22343;&#26399;&#26395;&#36951;&#25022;$\tilde O(T^\alpha)$&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;$\alpha$-&#26368;&#20248;&#21644;&#26399;&#26395;&#36951;&#25022;$\tilde O(T^\beta)$&#30340;&#23454;&#20363;&#30456;&#20851;&#30340;$\beta$-&#19968;&#33268;&#24615;&#65292;&#24182;&#19988;&#20139;&#26377;&#19968;&#23450;&#30340;&#27010;&#29575;&#21487;&#20197;&#36991;&#20813;$\tilde O(T^\delta)$&#30340;&#36951;&#25022;($\delta \geq \alpha$&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#21644;$\delta \geq \beta$&#22312;&#23454;&#20363;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;)&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the trade-off between expectation and tail risk for regret distribution in the stochastic multi-armed bandit problem. We fully characterize the interplay among three desired properties for policy design: worst-case optimality, instance-dependent consistency, and light-tailed risk. We show how the order of expected regret exactly affects the decaying rate of the regret tail probability for both the worst-case and instance-dependent scenario. A novel policy is proposed to characterize the optimal regret tail probability for any regret threshold. Concretely, for any given $\alpha\in[1/2, 1)$ and $\beta\in[0, \alpha]$, our policy achieves a worst-case expected regret of $\tilde O(T^\alpha)$ (we call it $\alpha$-optimal) and an instance-dependent expected regret of $\tilde O(T^\beta)$ (we call it $\beta$-consistent), while enjoys a probability of incurring an $\tilde O(T^\delta)$ regret ($\delta\geq\alpha$ in the worst-case scenario and $\delta\geq\beta$ in the instance-dependent s
&lt;/p&gt;</description></item><item><title>PriorCVAE &#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564; MCMC &#21442;&#25968;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#26032;&#26041;&#27861;&#65292;&#21487;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#22788;&#29702;&#36229;&#21442;&#25968;&#25512;&#26029;&#19982;&#23398;&#20064;&#20808;&#39564;&#20043;&#38388;&#30340;&#20449;&#24687;&#27969;&#26029;&#35010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.04307</link><description>&lt;p&gt;
PriorCVAE: &#22522;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#30340;&#21487;&#25193;&#23637; MCMC &#21442;&#25968;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling. (arXiv:2304.04307v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04307
&lt;/p&gt;
&lt;p&gt;
PriorCVAE &#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564; MCMC &#21442;&#25968;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#26032;&#26041;&#27861;&#65292;&#21487;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#22788;&#29702;&#36229;&#21442;&#25968;&#25512;&#26029;&#19982;&#23398;&#20064;&#20808;&#39564;&#20043;&#38388;&#30340;&#20449;&#24687;&#27969;&#26029;&#35010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#25512;&#29702;&#36895;&#24230;&#21644;&#27169;&#22411;&#28789;&#27963;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#20855;&#26377;&#38543;&#26426;&#36807;&#31243;&#20808;&#39564;&#30340;&#27169;&#22411;&#20013;&#65288;&#22914;&#39640;&#26031;&#36807;&#31243;&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#31561;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#32534;&#30721;&#30001; GP &#20808;&#39564;&#25110;&#20854;&#26377;&#38480;&#23454;&#29616;&#24341;&#36215;&#30340;&#35745;&#31639;&#29942;&#39048;&#65292;&#24182;&#19988;&#25152;&#23398;&#29983;&#25104;&#22120;&#21487;&#20197;&#20195;&#26367; MCMC &#25512;&#26029;&#20013;&#30340;&#21407;&#22987;&#20808;&#39564;&#12290;&#34429;&#28982;&#27492;&#26041;&#27861;&#23454;&#29616;&#20102;&#24555;&#36895;&#32780;&#39640;&#25928;&#30340;&#25512;&#29702;&#65292;&#20294;&#23427;&#20002;&#22833;&#20102;&#20851;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#20449;&#24687;&#65292;&#23548;&#33268;&#36229;&#21442;&#25968;&#25512;&#26029;&#19981;&#21487;&#33021;&#21644;&#23398;&#21040;&#30340;&#20808;&#39564;&#27169;&#31946;&#19981;&#28165;&#12290;&#25105;&#20204;&#24314;&#35758;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#65292;&#20197;&#20415;&#36229;&#21442;&#25968;&#19982; GP &#23454;&#29616;&#19968;&#36215;&#36827;&#34892;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
In applied fields where the speed of inference and model flexibility are crucial, the use of Bayesian inference for models with a stochastic process as their prior, e.g. Gaussian processes (GPs) is ubiquitous. Recent literature has demonstrated that the computational bottleneck caused by GP priors or their finite realizations can be encoded using deep generative models such as variational autoencoders (VAEs), and the learned generators can then be used instead of the original priors during Markov chain Monte Carlo (MCMC) inference in a drop-in manner. While this approach enables fast and highly efficient inference, it loses information about the stochastic process hyperparameters, and, as a consequence, makes inference over hyperparameters impossible and the learned priors indistinct. We propose to resolve the aforementioned issue and disentangle the learned priors by conditioning the VAE on stochastic process hyperparameters. This way, the hyperparameters are encoded alongside GP real
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#21644;&#21487;&#35299;&#37322;&#30340;&#25928;&#29992;&#20989;&#25968;&#65292;&#26356;&#22909;&#22320;&#21453;&#26144;&#20102;KNN&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#25552;&#20379;&#20102;&#30456;&#24212;&#35745;&#31639;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#34987;&#31216;&#20026;&#36719;&#26631;&#31614;KNN-SV&#65292;&#19982;&#21407;&#22987;&#26041;&#27861;&#20855;&#26377;&#30456;&#21516;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.04258</link><description>&lt;p&gt;
&#20851;&#20110;&#8220;&#26368;&#36817;&#37051;&#31639;&#27861;&#30340;&#20219;&#21153;&#29305;&#23450;&#25968;&#25454;&#26377;&#25928;&#24615;&#8221;&#30340;&#27880;&#35760;&#65288;arXiv&#65306;2304.04258v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
A Note on "Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms". (arXiv:2304.04258v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#21644;&#21487;&#35299;&#37322;&#30340;&#25928;&#29992;&#20989;&#25968;&#65292;&#26356;&#22909;&#22320;&#21453;&#26144;&#20102;KNN&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#25552;&#20379;&#20102;&#30456;&#24212;&#35745;&#31639;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#34987;&#31216;&#20026;&#36719;&#26631;&#31614;KNN-SV&#65292;&#19982;&#21407;&#22987;&#26041;&#27861;&#20855;&#26377;&#30456;&#21516;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#26377;&#25928;&#24615;&#26159;&#19968;&#20010;&#30740;&#31350;&#21333;&#20010;&#25968;&#25454;&#28857;&#23545;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#24433;&#21709;&#30340;&#26085;&#30410;&#22686;&#38271;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#22522;&#20110;&#21512;&#20316;&#21338;&#24328;&#35770;&#21644;&#32463;&#27982;&#23398;&#65292;&#25968;&#25454; Shapley &#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#26377;&#25928;&#24615;&#35745;&#31639;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20154;&#20204;&#37117;&#30693;&#36947; Shapley &#20540;&#65288;SV&#65289;&#30340;&#35745;&#31639;&#21487;&#33021;&#38750;&#24120;&#26114;&#36149;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;Jia &#31561;&#20154;&#65288;2019&#65289;&#34920;&#26126;&#65292;&#23545;&#20110; K &#26368;&#36817;&#37051;&#65288;KNN&#65289;&#27169;&#22411;&#65292;&#35745;&#31639; Data Shapley &#31455;&#28982;&#38750;&#24120;&#31616;&#21333;&#21644;&#39640;&#25928;&#12290;&#22312;&#26412;&#31508;&#35760;&#20013;&#65292;&#25105;&#20204;&#37325;&#23457;&#20102; Jia &#31561;&#20154;&#65288;2019&#65289;&#30340;&#24037;&#20316;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#21644;&#21487;&#35299;&#37322;&#30340;&#25928;&#29992;&#20989;&#25968;&#65292;&#26356;&#22909;&#22320;&#21453;&#26144;&#20102; KNN &#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20855;&#26377;&#26032;&#25928;&#29992;&#20989;&#25968;&#30340; KNN &#20998;&#31867;&#22120;/&#22238;&#24402;&#22120;&#30340; Data Shapley &#30340;&#30456;&#24212;&#35745;&#31639;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#34987;&#31216;&#20026;&#36719;&#26631;&#31614; KNN-SV&#65292;&#19982;&#21407;&#22987;&#26041;&#27861;&#20855;&#26377;&#30456;&#21516;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#65288;LSH&#65289;&#30340;&#36719;&#26631;&#31614; KNN-SV &#30340;&#39640;&#25928;&#36817;&#20284;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data valuation is a growing research field that studies the influence of individual data points for machine learning (ML) models. Data Shapley, inspired by cooperative game theory and economics, is an effective method for data valuation. However, it is well-known that the Shapley value (SV) can be computationally expensive. Fortunately, Jia et al. (2019) showed that for K-Nearest Neighbors (KNN) models, the computation of Data Shapley is surprisingly simple and efficient.  In this note, we revisit the work of Jia et al. (2019) and propose a more natural and interpretable utility function that better reflects the performance of KNN models. We derive the corresponding calculation procedure for the Data Shapley of KNN classifiers/regressors with the new utility functions. Our new approach, dubbed soft-label KNN-SV, achieves the same time complexity as the original method. We further provide an efficient approximation algorithm for soft-label KNN-SV based on locality sensitive hashing (LSH
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21152;&#24378;&#20102;&#19968;&#20123;&#20808;&#21069;&#24369;&#19968;&#20123;&#30340;&#38543;&#26426;&#26862;&#26519;&#21464;&#20307;&#30340;&#35777;&#26126;&#26041;&#27861;&#24182;&#25552;&#39640;&#20102;&#36825;&#20123;&#21464;&#20307;&#30340;&#25968;&#25454;&#21033;&#29992;&#29575;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35770;&#24615;&#33021;&#21644;&#23454;&#39564;&#24615;&#33021;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#65292;&#20854;&#22797;&#26434;&#24230;&#20302;&#19988;&#28385;&#36275;&#24378;&#19968;&#33268;&#24615;&#65292;&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#24182;&#36229;&#36807;&#20102;&#26631;&#20934;&#38543;&#26426;&#26862;&#26519;&#12290;</title><link>http://arxiv.org/abs/2304.04240</link><description>&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Data-driven multinomial random forest. (arXiv:2304.04240v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04240
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21152;&#24378;&#20102;&#19968;&#20123;&#20808;&#21069;&#24369;&#19968;&#20123;&#30340;&#38543;&#26426;&#26862;&#26519;&#21464;&#20307;&#30340;&#35777;&#26126;&#26041;&#27861;&#24182;&#25552;&#39640;&#20102;&#36825;&#20123;&#21464;&#20307;&#30340;&#25968;&#25454;&#21033;&#29992;&#29575;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35770;&#24615;&#33021;&#21644;&#23454;&#39564;&#24615;&#33021;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#65292;&#20854;&#22797;&#26434;&#24230;&#20302;&#19988;&#28385;&#36275;&#24378;&#19968;&#33268;&#24615;&#65292;&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#24182;&#36229;&#36807;&#20102;&#26631;&#20934;&#38543;&#26426;&#26862;&#26519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21152;&#24378;&#20102;&#19968;&#20123;&#20808;&#21069;&#24369;&#19968;&#20123;&#30340;&#38543;&#26426;&#26862;&#26519;&#21464;&#20307;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#20351;&#20854;&#25104;&#20026;&#24378;&#19968;&#33268;&#24615;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#24182;&#25552;&#39640;&#20102;&#36825;&#20123;&#21464;&#20307;&#30340;&#25968;&#25454;&#21033;&#29992;&#29575;&#65292;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35770;&#24615;&#33021;&#21644;&#23454;&#39564;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;&#65288;MRF&#65289;&#21644;&#20271;&#21162;&#21033;&#38543;&#26426;&#26862;&#26519;&#65288;BRF&#65289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;&#65288;DMRF&#65289;&#31639;&#27861;&#65292;&#20854;&#27604;MRF&#30340;&#22797;&#26434;&#24230;&#26356;&#20302;&#65292;&#27604;BRF&#30340;&#22797;&#26434;&#24230;&#26356;&#39640;&#65292;&#21516;&#26102;&#28385;&#36275;&#24378;&#19968;&#33268;&#24615;&#12290;&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#19978;&#65292;&#23427;&#27604;&#20043;&#21069;&#21482;&#28385;&#36275;&#24369;&#19968;&#33268;&#24615;&#30340;RF&#21464;&#20307;&#34920;&#29616;&#26356;&#22909;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#26631;&#20934;&#38543;&#26426;&#26862;&#26519;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;DMRF&#26159;&#30446;&#21069;&#26368;&#20986;&#33394;&#30340;&#20302;&#31639;&#27861;&#22797;&#26434;&#24615;&#30340;&#24378;&#38543;&#26426;&#26862;&#26519;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article, we strengthen the proof methods of some previously weakly consistent variants of random forests into strongly consistent proof methods, and improve the data utilization of these variants, in order to obtain better theoretical properties and experimental performance. In addition, based on the multinomial random forest (MRF) and Bernoulli random forest (BRF), we propose a data-driven multinomial random forest (DMRF) algorithm, which has lower complexity than MRF and higher complexity than BRF while satisfying strong consistency. It has better performance in classification and regression problems than previous RF variants that only satisfy weak consistency, and in most cases even surpasses standard random forest. To the best of our knowledge, DMRF is currently the most excellent strongly consistent RF variant with low algorithm complexity
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#65292;&#22312;&#20809;&#28369;&#21644;&#31561;&#21608;&#26465;&#20214;&#19979;&#65292;MALA&#30340;&#28151;&#21512;&#26102;&#38388;&#20165;&#19982;Hessian&#30697;&#38453;&#30340;trace&#26377;&#20851;&#65292;&#32780;&#19982;&#20854;&#31639;&#23376;&#33539;&#25968;&#21644;log-concave&#27809;&#26377;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2304.04095</link><description>&lt;p&gt;
&#20803;&#21345;&#27931;&#35843;&#25972;&#26391;&#20043;&#19975;(MALA)&#22312;&#20809;&#28369;&#19988;&#31561;&#21608;&#26465;&#20214;&#19979;&#30340;&#28151;&#21512;&#31616;&#21333;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry. (arXiv:2304.04095v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#65292;&#22312;&#20809;&#28369;&#21644;&#31561;&#21608;&#26465;&#20214;&#19979;&#65292;MALA&#30340;&#28151;&#21512;&#26102;&#38388;&#20165;&#19982;Hessian&#30697;&#38453;&#30340;trace&#26377;&#20851;&#65292;&#32780;&#19982;&#20854;&#31639;&#23376;&#33539;&#25968;&#21644;log-concave&#27809;&#26377;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\mathbb{R}^d$&#19978;&#26679;&#26412;&#30446;&#26631;&#23494;&#24230;&#30340;&#20803;&#21345;&#27931;&#35843;&#25972;&#26391;&#20043;&#19975;&#65288;MALA&#65289;&#30340;&#28151;&#21512;&#26102;&#38388;&#12290;&#25105;&#20204;&#20551;&#35774;&#30446;&#26631;&#23494;&#24230;&#28385;&#36275;$\psi_\mu$-&#31561;&#21608;&#21644;&#23427;&#30340;&#40657;&#22622;&#30697;&#38453;&#30340;trace&#21644;&#31639;&#23376;&#33539;&#25968;&#20998;&#21035;&#21463;$L$&#21644;$\Upsilon$&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#35770;&#26159;&#65292;&#20174;&#28909;&#21551;&#21160;&#24320;&#22987;&#65292;&#20026;&#20102;&#36798;&#21040;$\epsilon$&#24635;&#21464;&#24046;&#36317;&#31163;&#65292;MALA&#22312;$O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$&#27425;&#36845;&#20195;&#20013;&#28151;&#21512;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#35813;&#32467;&#26524;&#19981;&#20165;&#36866;&#29992;&#20110;&#23545;&#25968;&#20985;&#37319;&#26679;&#35774;&#32622;&#65292;&#32780;&#19988;&#28151;&#21512;&#26102;&#38388;&#20165;&#21462;&#20915;&#20110;$\Upsilon$&#65292;&#32780;&#19981;&#26159;&#20854;&#19978;&#30028;$Ld$&#12290;&#22312;$m$-&#24378;&#23545;&#25968;&#20985;&#21644;$L$-&#20809;&#28369;&#37319;&#26679;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#24674;&#22797;&#20102;&#20197;&#21069;&#30340;MALA&#30340;&#26368;&#23567;&#20540;&#28151;&#21512;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for sampling a target density on $\mathbb{R}^d$. We assume that the target density satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its Hessian are bounded by $L$ and $\Upsilon$ respectively. Our main result establishes that, from a warm start, to achieve $\epsilon$-total variation distance to the target density, MALA mixes in $O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$ iterations. Notably, this result holds beyond the log-concave sampling setting and the mixing time depends on only $\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly logconcave and $L$-log-smooth sampling setting, our bound recovers the previous minimax mixing bound of MALA~\cite{wu2021minimax}.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#19968;&#20010;&#26377;&#20851;&#26368;&#20248;&#33218;&#35782;&#21035;&#30340;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#35201;&#27714;&#25152;&#36873;&#33218;&#24517;&#39035;&#23545;&#25152;&#26377;&#20122;&#32676;&#37117;&#20844;&#24179;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#24182;&#35777;&#26126;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.04091</link><description>&lt;p&gt;
&#20855;&#26377;&#20122;&#32676;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Best Arm Identification with Fairness Constraints on Subpopulations. (arXiv:2304.04091v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#19968;&#20010;&#26377;&#20851;&#26368;&#20248;&#33218;&#35782;&#21035;&#30340;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#35201;&#27714;&#25152;&#36873;&#33218;&#24517;&#39035;&#23545;&#25152;&#26377;&#20122;&#32676;&#37117;&#20844;&#24179;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#24182;&#35777;&#26126;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#12289;&#20998;&#26512;&#21644;&#35299;&#20915;&#20102;&#19968;&#20010;&#20855;&#26377;&#20122;&#32676;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#65288;BAICS&#65289;&#12290;&#26631;&#20934;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#26088;&#22312;&#36873;&#25321;&#19968;&#20010;&#26399;&#26395;&#22870;&#21169;&#26368;&#22823;&#30340;&#33218;&#65292;&#20854;&#20013;&#26399;&#26395;&#26159;&#38024;&#23545;&#25972;&#20010;&#20154;&#32676;&#35745;&#31639;&#30340;&#12290;BAICS&#38382;&#39064;&#35201;&#27714;&#25152;&#36873;&#33218;&#24517;&#39035;&#23545;&#25152;&#26377;&#20122;&#32676;&#65288;&#20363;&#22914;&#65292;&#19981;&#21516;&#30340;&#26063;&#32676;&#12289;&#24180;&#40836;&#32452;&#25110;&#23458;&#25143;&#31867;&#22411;&#65289;&#37117;&#20844;&#24179;&#65292;&#36890;&#36807;&#28385;&#36275;&#27599;&#20010;&#20122;&#32676;&#26465;&#20214;&#19979;&#30340;&#26399;&#26395;&#22870;&#21169;&#22823;&#20110;&#19968;&#20123;&#38408;&#20540;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290;BAICS&#38382;&#39064;&#26088;&#22312;&#20197;&#39640;&#32622;&#20449;&#24230;&#27491;&#30830;&#37492;&#23450;&#20986;&#25152;&#26377;&#31526;&#21512;&#20122;&#32676;&#32422;&#26463;&#26465;&#20214;&#30340;&#33218;&#20013;&#26399;&#26395;&#22870;&#21169;&#26368;&#22823;&#30340;&#33218;&#12290;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#26368;&#23567;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26368;&#20339;&#23454;&#29616;&#19979;&#30028;&#30340;&#38381;&#24335;&#34920;&#31034;&#26469;&#20998;&#26512;BAICS&#38382;&#39064;&#30340;&#22797;&#26434;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#35813;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#19979;&#30028;&#30340;&#38454;&#25968;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
We formulate, analyze and solve the problem of best arm identification with fairness constraints on subpopulations (BAICS). Standard best arm identification problems aim at selecting an arm that has the largest expected reward where the expectation is taken over the entire population. The BAICS problem requires that an selected arm must be fair to all subpopulations (e.g., different ethnic groups, age groups, or customer types) by satisfying constraints that the expected reward conditional on every subpopulation needs to be larger than some thresholds. The BAICS problem aims at correctly identify, with high confidence, the arm with the largest expected reward from all arms that satisfy subpopulation constraints. We analyze the complexity of the BAICS problem by proving a best achievable lower bound on the sample complexity with closed-form representation. We then design an algorithm and prove that the algorithm's sample complexity matches with the lower bound in terms of order. A brief
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#21517;&#20026;BSDE-Gen&#65292;&#23427;&#23558;&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#28789;&#27963;&#24615;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24378;&#22823;&#33021;&#21147;&#32467;&#21512;&#65292;&#29992;&#20110;&#29983;&#25104;&#39640;&#32500;&#22797;&#26434;&#30446;&#26631;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#22312;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#12290;BSDE-Gen&#30340;&#29983;&#25104;&#24314;&#27169;&#36807;&#31243;&#20013;&#24341;&#20837;&#20102;&#38543;&#26426;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#26159;&#19968;&#31181;&#26377;&#25928;&#32780;&#33258;&#28982;&#30340;&#29983;&#25104;&#39640;&#32500;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.04049</link><description>&lt;p&gt;
&#24102;&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Deep Generative Modeling with Backward Stochastic Differential Equations. (arXiv:2304.04049v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04049
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#21517;&#20026;BSDE-Gen&#65292;&#23427;&#23558;&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#28789;&#27963;&#24615;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24378;&#22823;&#33021;&#21147;&#32467;&#21512;&#65292;&#29992;&#20110;&#29983;&#25104;&#39640;&#32500;&#22797;&#26434;&#30446;&#26631;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#22312;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#12290;BSDE-Gen&#30340;&#29983;&#25104;&#24314;&#27169;&#36807;&#31243;&#20013;&#24341;&#20837;&#20102;&#38543;&#26426;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#26159;&#19968;&#31181;&#26377;&#25928;&#32780;&#33258;&#28982;&#30340;&#29983;&#25104;&#39640;&#32500;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#21517;&#20026;BSDE-Gen&#65292;&#23427;&#23558;&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;BSDEs&#65289;&#30340;&#28789;&#27963;&#24615;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24378;&#22823;&#33021;&#21147;&#30456;&#32467;&#21512;&#65292;&#20197;&#29983;&#25104;&#39640;&#32500;&#22797;&#26434;&#30446;&#26631;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#22312;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#12290;&#22312;&#29983;&#25104;&#24314;&#27169;&#36807;&#31243;&#20013;&#24341;&#20837;&#38543;&#26426;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#20351;BSDE-Gen&#25104;&#20026;&#19968;&#31181;&#26377;&#25928;&#32780;&#33258;&#28982;&#30340;&#29983;&#25104;&#39640;&#32500;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;BSDE-Gen&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#25551;&#36848;&#20102;&#20854;&#27169;&#22411;&#26550;&#26500;&#65292;&#32473;&#20986;&#20102;&#29992;&#20110;&#35757;&#32451;&#30340;&#26368;&#22823;&#24179;&#22343;&#20559;&#24046;&#65288;MMD&#65289;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#25253;&#21578;&#20102;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel deep generative model, called BSDE-Gen, which combines the flexibility of backward stochastic differential equations (BSDEs) with the power of deep neural networks for generating high-dimensional complex target data, particularly in the field of image generation. The incorporation of stochasticity and uncertainty in the generative modeling process makes BSDE-Gen an effective and natural approach for generating high-dimensional data. The paper provides a theoretical framework for BSDE-Gen, describes its model architecture, presents the maximum mean discrepancy (MMD) loss function used for training, and reports experimental results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#39640;&#38454;&#24352;&#37327;&#25968;&#25454;&#38598;&#20013;&#33719;&#24471;&#21487;&#33021;&#20855;&#26377;&#39640;&#31209;&#20449;&#21495;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#39640;&#31209;&#21644;&#20302;&#31209;&#27169;&#22411;&#12290;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#32467;&#26524;&#12290;&#21457;&#29616;&#39640;&#32500;&#28508;&#21464;&#37327;&#24352;&#37327;&#20855;&#26377;&#23545;&#25968;&#31209;&#65292;&#24182;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#30340;&#26368;&#20248;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.04043</link><description>&lt;p&gt;
&#39640;&#38454;&#24352;&#37327;&#20272;&#35745;&#20013;&#30340;&#32479;&#35745;&#19982;&#35745;&#31639;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Statistical and computational rates in high rank tensor estimation. (arXiv:2304.04043v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#39640;&#38454;&#24352;&#37327;&#25968;&#25454;&#38598;&#20013;&#33719;&#24471;&#21487;&#33021;&#20855;&#26377;&#39640;&#31209;&#20449;&#21495;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#39640;&#31209;&#21644;&#20302;&#31209;&#27169;&#22411;&#12290;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#32467;&#26524;&#12290;&#21457;&#29616;&#39640;&#32500;&#28508;&#21464;&#37327;&#24352;&#37327;&#20855;&#26377;&#23545;&#25968;&#31209;&#65292;&#24182;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#30340;&#26368;&#20248;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#38454;&#24352;&#37327;&#25968;&#25454;&#38598;&#22312;&#25512;&#33616;&#31995;&#32479;&#12289;&#31070;&#32463;&#24433;&#20687;&#21644;&#31038;&#20132;&#32593;&#32476;&#31561;&#39046;&#22495;&#20013;&#24120;&#35265;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#33021;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#22122;&#22768;&#35266;&#23519;&#20013;&#20272;&#35745;&#21487;&#33021;&#20855;&#26377;&#39640;&#31209;&#20449;&#21495;&#30340;&#24352;&#37327;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#21253;&#25324;&#39640;&#31209;&#21644;&#20302;&#31209;&#27169;&#22411;&#30340;&#29983;&#25104;&#28508;&#21464;&#37327;&#24352;&#37327;&#27169;&#22411;&#65292;&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;&#31616;&#21333;&#30340;&#36229;&#22270;&#27169;&#22411;&#12289;&#21333;&#25351;&#26631;&#27169;&#22411;&#12289;&#20302;&#31209;CP&#27169;&#22411;&#21644;&#20302;&#31209;Tucker&#27169;&#22411;&#12290;&#22312;&#20449;&#21495;&#24352;&#37327;&#20272;&#35745;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;&#39640;&#32500;&#28508;&#21464;&#37327;&#24352;&#37327;&#20855;&#26377;&#23545;&#25968;&#31209;&#65307;&#36825;&#19968;&#20107;&#23454;&#35299;&#37322;&#20102;&#20302;&#31209;&#24352;&#37327;&#22312;&#24212;&#29992;&#20013;&#30340;&#26222;&#36941;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#39033;&#24335;&#26102;&#38388;&#35889;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#30340;&#26368;&#20248;&#36895;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#32479;&#35745;&#35745;&#31639;&#24046;&#36317;&#20165;&#20986;&#29616;&#22312;&#19977;&#38454;&#25110;&#26356;&#39640;&#38454;&#30340;&#28508;&#21464;&#37327;&#24352;&#37327;&#20013;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#39564;&#21644;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Higher-order tensor datasets arise commonly in recommendation systems, neuroimaging, and social networks. Here we develop probable methods for estimating a possibly high rank signal tensor from noisy observations. We consider a generative latent variable tensor model that incorporates both high rank and low rank models, including but not limited to, simple hypergraphon models, single index models, low-rank CP models, and low-rank Tucker models. Comprehensive results are developed on both the statistical and computational limits for the signal tensor estimation. We find that high-dimensional latent variable tensors are of log-rank; the fact explains the pervasiveness of low-rank tensors in applications. Furthermore, we propose a polynomial-time spectral algorithm that achieves the computationally optimal rate. We show that the statistical-computational gap emerges only for latent variable tensors of order 3 or higher. Numerical experiments and two real data applications are presented to
&lt;/p&gt;</description></item><item><title>DiscoVars&#26159;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#21019;&#24314;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#32593;&#32476;&#24182;&#26681;&#25454;&#22270;&#20013;&#24515;&#24615;&#24230;&#37327;&#25490;&#21517;&#23427;&#20204;&#26469;&#30830;&#23450;&#21464;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#36866;&#29992;&#20110;&#32858;&#31867;&#31561;&#23398;&#20064;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2304.03983</link><description>&lt;p&gt;
DiscoVars: &#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20998;&#26512;&#35270;&#35282;-&#24212;&#29992;&#20110;&#32858;&#31867;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
DiscoVars: A New Data Analysis Perspective -- Application in Variable Selection for Clustering. (arXiv:2304.03983v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03983
&lt;/p&gt;
&lt;p&gt;
DiscoVars&#26159;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#21019;&#24314;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#32593;&#32476;&#24182;&#26681;&#25454;&#22270;&#20013;&#24515;&#24615;&#24230;&#37327;&#25490;&#21517;&#23427;&#20204;&#26469;&#30830;&#23450;&#21464;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#36866;&#29992;&#20110;&#32858;&#31867;&#31561;&#23398;&#20064;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20998;&#26512;&#35270;&#35282;&#26469;&#30830;&#23450;&#21464;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#32780;&#19981;&#32771;&#34385;&#24213;&#23618;&#30340;&#23398;&#20064;&#20219;&#21153;&#12290;&#20256;&#32479;&#19978;&#65292;&#26080;&#35770;&#26159;&#20998;&#31867;&#38382;&#39064;&#36824;&#26159;&#22238;&#24402;&#38382;&#39064;&#65292;&#21464;&#37327;&#36873;&#25321;&#37117;&#34987;&#35748;&#20026;&#26159;&#30417;&#30563;&#23398;&#20064;&#30340;&#37325;&#35201;&#27493;&#39588;&#12290;&#24403;&#19982;&#25968;&#25454;&#25910;&#38598;&#21644;&#23384;&#20648;&#30456;&#20851;&#30340;&#25104;&#26412;&#30456;&#24403;&#39640;&#26102;&#65292;&#22914;&#36965;&#24863;&#25968;&#25454;&#65292;&#21464;&#37327;&#36873;&#25321;&#20063;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39318;&#20808;&#21019;&#24314;&#25152;&#26377;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#32593;&#32476;&#65292;&#28982;&#21518;&#36890;&#36807;&#22270;&#20013;&#24515;&#24615;&#24230;&#37327;&#26469;&#25490;&#21517;&#23427;&#20204;&#65288;&#21363;&#33410;&#28857;&#65289;&#65292;&#20174;&#32780;&#20174;&#25968;&#25454;&#20013;&#36873;&#25321;&#37325;&#35201;&#21464;&#37327;&#12290;&#26681;&#25454;&#39318;&#36873;&#20013;&#24515;&#24230;&#37327;&#36873;&#25321;&#21069;n&#20010;&#21464;&#37327;&#23558;&#24471;&#21040;&#19968;&#20010;&#24378;&#26377;&#21147;&#30340;&#20505;&#36873;&#21464;&#37327;&#23376;&#38598;&#65292;&#20379;&#36827;&#19968;&#27493;&#23398;&#20064;&#20219;&#21153;&#20351;&#29992;&#65292;&#20363;&#22914;&#32858;&#31867;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#24037;&#20855;&#23637;&#31034;&#20026;Shiny&#24212;&#29992;&#31243;&#24207;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#25509;&#21475;&#24320;&#21457;&#29615;&#22659;&#12290;&#25105;&#20204;&#36824;&#25193;&#23637;&#20102;&#29992;&#25143;&#30028;&#38754;&#65292;&#29992;&#20110;&#20004;&#31181;&#25991;&#29486;&#20013;&#30693;&#21517;&#30340;&#26080;&#30417;&#30563;&#21464;&#37327;&#36873;&#25321;&#26041;&#27861;&#30340;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new data analysis perspective to determine variable importance regardless of the underlying learning task. Traditionally, variable selection is considered an important step in supervised learning for both classification and regression problems. The variable selection also becomes critical when costs associated with the data collection and storage are considerably high for cases like remote sensing. Therefore, we propose a new methodology to select important variables from the data by first creating dependency networks among all variables and then ranking them (i.e. nodes) by graph centrality measures. Selecting Top-$n$ variables according to preferred centrality measure will yield a strong candidate subset of variables for further learning tasks e.g. clustering. We present our tool as a Shiny app which is a user-friendly interface development environment. We also extend the user interface for two well-known unsupervised variable selection methods from literature for compar
&lt;/p&gt;</description></item><item><title>&#37319;&#26679;&#39640;&#32500;&#20998;&#24067;&#26159;&#19968;&#20010;&#22522;&#26412;&#30340;&#38382;&#39064;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#36755;&#36816;&#30340;&#37319;&#26679;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;TemperFlow&#36890;&#36807;&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#28201;&#24230;&#20998;&#24067;&#65292;&#35299;&#20915;&#20102;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.03933</link><description>&lt;p&gt;
&#36890;&#36807;&#28201;&#24230;&#20998;&#24067;&#27969;&#23454;&#29616;&#39640;&#25928;&#22810;&#27169;&#24577;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Efficient Multimodal Sampling via Tempered Distribution Flow. (arXiv:2304.03933v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03933
&lt;/p&gt;
&lt;p&gt;
&#37319;&#26679;&#39640;&#32500;&#20998;&#24067;&#26159;&#19968;&#20010;&#22522;&#26412;&#30340;&#38382;&#39064;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#36755;&#36816;&#30340;&#37319;&#26679;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;TemperFlow&#36890;&#36807;&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#28201;&#24230;&#20998;&#24067;&#65292;&#35299;&#20915;&#20102;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#39640;&#32500;&#20998;&#24067;&#20013;&#37319;&#26679;&#26159;&#32479;&#35745;&#30740;&#31350;&#21644;&#23454;&#36341;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#24403;&#30446;&#26631;&#23494;&#24230;&#20989;&#25968;&#19981;&#35268;&#33539;&#21270;&#19988;&#21253;&#21547;&#23396;&#31435;&#27169;&#24335;&#26102;&#65292;&#23601;&#20250;&#20986;&#29616;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36890;&#36807;&#25311;&#21512;&#19968;&#20010;&#34987;&#31216;&#20026;&#36755;&#36816;&#26144;&#23556;&#30340;&#21487;&#36870;&#21464;&#25442;&#26144;&#23556;&#65288;&#22312;&#21442;&#32771;&#27010;&#29575;&#27979;&#37327;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#65289;&#65292;&#20351;&#24471;&#36890;&#36807;&#36755;&#36816;&#26144;&#23556;&#23558;&#21442;&#32771;&#26679;&#26412;&#25512;&#21521;&#21069;&#27839;&#21363;&#21487;&#23454;&#29616;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;Wasserstein&#26799;&#24230;&#27969;&#29702;&#35770;&#29702;&#35770;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#22522;&#20110;&#36755;&#36816;&#30340;&#37319;&#26679;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TemperFlow&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#22810;&#27169;&#24577;&#38382;&#39064;&#12290;TemperFlow&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#19968;&#31995;&#21015;&#28201;&#24230;&#20998;&#24067;&#65292;&#20197;&#36880;&#27493;&#25509;&#36817;&#30446;&#26631;&#20998;&#24067;&#65292;&#24182;&#35777;&#26126;&#23427;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;&#21508;&#31181;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#22411;&#37319;&#26679;&#22120;&#30456;&#23545;&#20110;&#29616;&#26377;&#37319;&#26679;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling from high-dimensional distributions is a fundamental problem in statistical research and practice. However, great challenges emerge when the target density function is unnormalized and contains isolated modes. We tackle this difficulty by fitting an invertible transformation mapping, called a transport map, between a reference probability measure and the target distribution, so that sampling from the target distribution can be achieved by pushing forward a reference sample through the transport map. We theoretically analyze the limitations of existing transport-based sampling methods using the Wasserstein gradient flow theory, and propose a new method called TemperFlow that addresses the multimodality issue. TemperFlow adaptively learns a sequence of tempered distributions to progressively approach the target distribution, and we prove that it overcomes the limitations of existing methods. Various experiments demonstrate the superior performance of this novel sampler compared 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;OFTER&#65292;&#19968;&#31181;&#19987;&#38376;&#38024;&#23545;&#20013;&#31561;&#35268;&#27169;&#22810;&#31181;&#26102;&#38388;&#24207;&#21015;&#30340;&#22312;&#32447;&#39044;&#27979;&#31649;&#32447;&#65292;&#33021;&#22815;&#32988;&#36807;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#26041;&#27861;&#12290;OFTER&#26159;&#37329;&#34701;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#30340;&#29702;&#24819;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2304.03877</link><description>&lt;p&gt;
OFTER&#65306;&#19968;&#31181;&#19987;&#38376;&#38024;&#23545;&#20013;&#31561;&#35268;&#27169;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#30340;&#22312;&#32447;&#39044;&#27979;&#31649;&#32447;
&lt;/p&gt;
&lt;p&gt;
OFTER: An Online Pipeline for Time Series Forecasting. (arXiv:2304.03877v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;OFTER&#65292;&#19968;&#31181;&#19987;&#38376;&#38024;&#23545;&#20013;&#31561;&#35268;&#27169;&#22810;&#31181;&#26102;&#38388;&#24207;&#21015;&#30340;&#22312;&#32447;&#39044;&#27979;&#31649;&#32447;&#65292;&#33021;&#22815;&#32988;&#36807;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#26041;&#27861;&#12290;OFTER&#26159;&#37329;&#34701;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#30340;&#29702;&#24819;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;OFTER&#65292;&#19968;&#31181;&#19987;&#38376;&#38024;&#23545;&#20013;&#31561;&#35268;&#27169;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#31649;&#32447;&#12290;OFTER&#21033;&#29992;kNN&#21644;&#24191;&#20041;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#27169;&#22411;&#65292;&#24182;&#19982;&#38477;&#32500;&#32452;&#20214;&#38598;&#25104;&#22312;&#19968;&#36215;&#12290;&#20026;&#20102;&#36991;&#20813;&#39640;&#32500;&#24230;&#30340;&#22256;&#22659;&#65292;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#20462;&#25913;&#21518;&#30340;&#26368;&#22823;&#30456;&#20851;&#31995;&#25968;&#30340;&#21152;&#26435;&#33539;&#25968;&#12290;&#25105;&#20204;&#20171;&#32461;&#30340;&#31649;&#32447;&#19987;&#38376;&#38024;&#23545;&#22312;&#32447;&#20219;&#21153;&#36827;&#34892;&#35774;&#35745;&#65292;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#33021;&#22815;&#32988;&#36807;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#26041;&#27861;&#12290;&#31639;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#12289;&#22312;&#32447;&#24615;&#36136;&#20197;&#21450;&#22312;&#20302;&#20449;&#22122;&#27604;&#29615;&#22659;&#19979;&#36816;&#34892;&#30340;&#33021;&#21147;&#20351;OFTER&#25104;&#20026;&#37329;&#34701;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#30340;&#29702;&#24819;&#35299;&#20915;&#26041;&#26696;&#65292;&#20363;&#22914;&#27599;&#26085;&#32929;&#31080;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce OFTER, a time series forecasting pipeline tailored for mid-sized multivariate time series. OFTER utilizes the non-parametric models of k-nearest neighbors and Generalized Regression Neural Networks, integrated with a dimensionality reduction component. To circumvent the curse of dimensionality, we employ a weighted norm based on a modified version of the maximal correlation coefficient. The pipeline we introduce is specifically designed for online tasks, has an interpretable output, and is able to outperform several state-of-the art baselines. The computational efficacy of the algorithm, its online nature, and its ability to operate in low signal-to-noise regimes, render OFTER an ideal approach for financial multivariate time series problems, such as daily equity forecasting. Our work demonstrates that while deep learning models hold significant promise for time series forecasting, traditional methods carefully integrating mainstream tools remain very competitive alternati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#31163;&#32447;&#22522;&#20110;&#27169;&#22411;&#30340;&#20248;&#21270;&#20013;&#65292;&#20445;&#23432;&#30340;&#23458;&#35266;&#27169;&#22411;&#65288;COMs&#65289;&#26159;&#19968;&#31181;&#29305;&#27530;&#30340;&#22522;&#20110;&#23545;&#27604;&#25955;&#24230;&#33021;&#37327;&#27169;&#22411;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;Langevin MCMC&#37319;&#26679;&#22120;&#26367;&#25442;&#26799;&#24230;&#19978;&#21319;&#37319;&#26679;&#22120;&#65292;&#20197;&#25552;&#39640;&#26679;&#26412;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.03866</link><description>&lt;p&gt;
&#20445;&#23432;&#30340;&#23458;&#35266;&#27169;&#22411;&#26159;&#19968;&#31181;&#29305;&#27530;&#30340;&#22522;&#20110;&#23545;&#27604;&#25955;&#24230;&#33021;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conservative objective models are a special kind of contrastive divergence-based energy model. (arXiv:2304.03866v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#31163;&#32447;&#22522;&#20110;&#27169;&#22411;&#30340;&#20248;&#21270;&#20013;&#65292;&#20445;&#23432;&#30340;&#23458;&#35266;&#27169;&#22411;&#65288;COMs&#65289;&#26159;&#19968;&#31181;&#29305;&#27530;&#30340;&#22522;&#20110;&#23545;&#27604;&#25955;&#24230;&#33021;&#37327;&#27169;&#22411;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;Langevin MCMC&#37319;&#26679;&#22120;&#26367;&#25442;&#26799;&#24230;&#19978;&#21319;&#37319;&#26679;&#22120;&#65292;&#20197;&#25552;&#39640;&#26679;&#26412;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20445;&#23432;&#30340;&#23458;&#35266;&#27169;&#22411;&#65288;COMs&#65289;&#29992;&#20110;&#31163;&#32447;&#22522;&#20110;&#27169;&#22411;&#30340;&#20248;&#21270;&#65288;MBO&#65289;&#26159;&#19968;&#31181;&#29305;&#27530;&#30340;&#22522;&#20110;&#23545;&#27604;&#25955;&#24230;&#33021;&#37327;&#27169;&#22411;&#65292;&#20854;&#20013;&#33021;&#37327;&#20989;&#25968;&#26082;&#34920;&#31034;&#36755;&#20837;&#30340;&#26080;&#26465;&#20214;&#27010;&#29575;&#65292;&#20063;&#34920;&#31034;&#22870;&#21169;&#21464;&#37327;&#30340;&#26465;&#20214;&#27010;&#29575;&#12290;&#34429;&#28982;&#26368;&#21021;&#30340;&#20844;&#24335;&#21482;&#20174;&#20854;&#23398;&#20064;&#20998;&#24067;&#20013;&#25277;&#26679;&#27169;&#22411;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20462;&#22797;&#26041;&#27861;&#65292;&#29992;Langevin MCMC&#37319;&#26679;&#22120;&#26367;&#25442;&#26799;&#24230;&#19978;&#21319;&#37319;&#26679;&#22120;&#12290;&#36825;&#20135;&#29983;&#20102;&#19968;&#31181;&#29305;&#27530;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#20854;&#20013;&#37319;&#26679;&#36755;&#20837;&#30340;&#27010;&#29575;&#19982;&#20854;&#39044;&#27979;&#30340;&#22870;&#21169;&#25104;&#27604;&#20363;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#23558;&#27169;&#22411;&#20998;&#35299;&#65292;&#20351;&#26080;&#26465;&#20214;&#27010;&#29575;&#21644;&#26465;&#20214;&#27010;&#29575;&#20998;&#21035;&#24314;&#27169;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we theoretically show that conservative objective models (COMs) for offline model-based optimisation (MBO) are a special kind of contrastive divergence-based energy model, one where the energy function represents both the unconditional probability of the input and the conditional probability of the reward variable. While the initial formulation only samples modes from its learned distribution, we propose a simple fix that replaces its gradient ascent sampler with a Langevin MCMC sampler. This gives rise to a special probabilistic model where the probability of sampling an input is proportional to its predicted reward. Lastly, we show that better samples can be obtained if the model is decoupled so that the unconditional and conditional probabilities are modelled separately.
&lt;/p&gt;</description></item><item><title>StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#21333;&#27493;&#21644;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#24110;&#21161;&#20174;&#19994;&#20154;&#21592;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2304.03853</link><description>&lt;p&gt;
StepMix: &#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;
&lt;/p&gt;
&lt;p&gt;
StepMix: A Python Package for Pseudo-Likelihood Estimation of Generalized Mixture Models with External Variables. (arXiv:2304.03853v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03853
&lt;/p&gt;
&lt;p&gt;
StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#21333;&#27493;&#21644;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#24110;&#21161;&#20174;&#19994;&#20154;&#21592;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#24191;&#20041;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;(&#28508;&#22312;&#21078;&#38754;&#21644;&#28508;&#22312;&#31867;&#20998;&#26512;)&#19982;&#22806;&#37096;&#21464;&#37327;(&#21327;&#21464;&#37327;&#21644;&#36828;&#31243;&#32467;&#26524;)&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;(&#21333;&#27493;&#12289;&#20004;&#27493;&#21644;&#19977;&#27493;&#26041;&#27861;)&#30340;&#24320;&#28304;&#36719;&#20214;&#21253;&#12290;&#22312;&#35768;&#22810;&#31038;&#20250;&#31185;&#23398;&#30340;&#24212;&#29992;&#20013;&#65292;&#20027;&#35201;&#30446;&#26631;&#19981;&#20165;&#26159;&#23558;&#20010;&#20307;&#32858;&#31867;&#25104;&#28508;&#22312;&#31867;&#21035;&#65292;&#36824;&#21253;&#25324;&#20351;&#29992;&#36825;&#20123;&#31867;&#21035;&#26469;&#24320;&#21457;&#26356;&#22797;&#26434;&#30340;&#32479;&#35745;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20998;&#20026;&#19968;&#20010;&#23558;&#28508;&#22312;&#31867;&#21035;&#19982;&#35266;&#23519;&#25351;&#26631;&#30456;&#20851;&#32852;&#30340;&#27979;&#37327;&#27169;&#22411;&#21644;&#19968;&#20010;&#23558;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#21464;&#37327;&#19982;&#28508;&#22312;&#31867;&#21035;&#30456;&#20851;&#32852;&#30340;&#32467;&#26500;&#27169;&#22411;&#12290;&#27979;&#37327;&#21644;&#32467;&#26500;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;&#25152;&#35859;&#30340;&#19968;&#27493;&#27861;&#20849;&#21516;&#20272;&#35745;&#65292;&#20063;&#21487;&#20197;&#20351;&#29992;&#36880;&#27493;&#26041;&#27861;&#36880;&#27493;&#20272;&#35745;&#65292;&#23545;&#20110;&#20174;&#19994;&#20154;&#21592;&#26469;&#35828;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20272;&#35745;&#28508;&#22312;&#31867;&#21035;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#38500;&#20102;&#19968;&#27493;&#27861;&#65292;StepMix&#36824;&#23454;&#29616;&#20102;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#26368;&#37325;&#35201;&#30340;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#29992;&#25143;&#21451;&#22909;&#30340;&#30028;&#38754;&#65292;&#26041;&#20415;&#27169;&#22411;&#30340;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
StepMix is an open-source software package for the pseudo-likelihood estimation (one-, two- and three-step approaches) of generalized finite mixture models (latent profile and latent class analysis) with external variables (covariates and distal outcomes). In many applications in social sciences, the main objective is not only to cluster individuals into latent classes, but also to use these classes to develop more complex statistical models. These models generally divide into a measurement model that relates the latent classes to observed indicators, and a structural model that relates covariates and outcome variables to the latent classes. The measurement and structural models can be estimated jointly using the so-called one-step approach or sequentially using stepwise methods, which present significant advantages for practitioners regarding the interpretability of the estimated latent classes. In addition to the one-step approach, StepMix implements the most important stepwise estim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#29289;&#24207;&#21015;&#26680;&#30340;&#25968;&#23398;&#25361;&#25112;&#65292;&#25506;&#35752;&#20102;&#29983;&#29289;&#24207;&#21015;&#31354;&#38388;&#32467;&#26500;&#21644;&#29983;&#29289;&#24207;&#21015;&#30456;&#20284;&#24615;&#30340;&#29305;&#27530;&#24615;&#23545;&#20110;&#26680;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.03775</link><description>&lt;p&gt;
&#20855;&#26377;&#20445;&#35777;&#28789;&#27963;&#24615;&#30340;&#29983;&#29289;&#24207;&#21015;&#26680;
&lt;/p&gt;
&lt;p&gt;
Biological Sequence Kernels with Guaranteed Flexibility. (arXiv:2304.03775v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#29289;&#24207;&#21015;&#26680;&#30340;&#25968;&#23398;&#25361;&#25112;&#65292;&#25506;&#35752;&#20102;&#29983;&#29289;&#24207;&#21015;&#31354;&#38388;&#32467;&#26500;&#21644;&#29983;&#29289;&#24207;&#21015;&#30456;&#20284;&#24615;&#30340;&#29305;&#27530;&#24615;&#23545;&#20110;&#26680;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#29983;&#29289;&#24207;&#21015;&#65288;DNA&#65292;RNA&#21644;&#34507;&#30333;&#36136;&#65289;&#20855;&#26377;&#25512;&#21160;&#20154;&#31867;&#20581;&#24247;&#12289;&#29615;&#22659;&#21487;&#25345;&#32493;&#24615;&#21644;&#22522;&#30784;&#29983;&#29289;&#23398;&#29702;&#35299;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#36825;&#20010;&#38382;&#39064;&#22495;&#20013;&#26159;&#26080;&#25928;&#25110;&#19981;&#21487;&#38752;&#30340;&#12290;&#26412;&#25991;&#36890;&#36807;&#26680;&#30340;&#35270;&#35282;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#36825;&#20123;&#25361;&#25112;&#12290;&#23613;&#31649;&#27809;&#26377;&#26174;&#24335;&#20351;&#29992;&#26680;&#30340;&#26041;&#27861;&#20173;&#28982;&#22312;&#38544;&#21547;&#22320;&#20381;&#36182;&#23427;&#20204;&#65292;&#21253;&#25324;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#25216;&#26415;&#12290;&#34429;&#28982;&#20854;&#20182;&#31867;&#22411;&#25968;&#25454;&#30340;&#26680;&#24050;&#34987;&#29702;&#35770;&#19978;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#29983;&#29289;&#24207;&#21015;&#31354;&#38388;&#30340;&#32467;&#26500;&#65288;&#31163;&#25955;&#12289;&#21487;&#21464;&#38271;&#24230;&#24207;&#21015;&#65289;&#20197;&#21450;&#29983;&#29289;&#24207;&#21015;&#30456;&#20284;&#24615;&#30340;&#29305;&#27530;&#25968;&#23398;&#25361;&#25112;&#29420;&#19968;&#26080;&#20108;&#12290;&#25105;&#20204;&#27491;&#24335;&#20998;&#26512;&#29983;&#29289;&#24207;&#21015;&#26680;&#33021;&#22815;&#22810;&#22909;&#22320;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
Applying machine learning to biological sequences - DNA, RNA and protein has enormous potential to advance human health, environmental sustainability, and fundamental biological understanding. However, many existing machine learning methods are ineffective or unreliable in this problem domain. We study these challenges theoretically, through the lens of kernels. Methods based on kernels are ubiquitous: they are used to predict molecular phenotypes, design novel proteins, compare sequence distributions, and more. Many methods that do not use kernels explicitly still rely on them implicitly, including a wide variety of both deep learning and physics-based techniques. While kernels for other types of data are well-studied theoretically, the structure of biological sequence space (discrete, variable length sequences), as well as biological notions of sequence similarity, present unique mathematical challenges. We formally analyze how well kernels for biological sequences can approximate 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#35777;&#26126;&#36825;&#20123;&#32593;&#32476;&#33021;&#22815;&#36924;&#36817;&#20219;&#20309;&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#65292;&#36824;&#35752;&#35770;&#20102;&#26377;&#38480;&#20010;&#22266;&#23450;&#20013;&#24515;&#30340;RBF&#32593;&#32476;&#30340;&#36924;&#36817;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2304.02220</link><description>&lt;p&gt;
&#20851;&#20110;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#26222;&#36866;&#36924;&#36817;&#24615;&#36136;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the universal approximation property of radial basis function neural networks. (arXiv:2304.02220v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02220
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#35777;&#26126;&#36825;&#20123;&#32593;&#32476;&#33021;&#22815;&#36924;&#36817;&#20219;&#20309;&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#65292;&#36824;&#35752;&#35770;&#20102;&#26377;&#38480;&#20010;&#22266;&#23450;&#20013;&#24515;&#30340;RBF&#32593;&#32476;&#30340;&#36924;&#36817;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#20854;&#20013;&#24179;&#28369;&#22240;&#23376;&#34987;&#26367;&#25442;&#20026;&#20301;&#31227;&#12290;&#25105;&#20204;&#22312;&#28608;&#27963;&#20989;&#25968;&#30340;&#19968;&#23450;&#26465;&#20214;&#19979;&#35777;&#26126;&#20102;&#36825;&#20123;&#32593;&#32476;&#33021;&#22815;&#36924;&#36817;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;d&#32500;&#32039;&#33268;&#23376;&#38598;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#12290;&#23545;&#20110;&#26377;&#38480;&#20010;&#22266;&#23450;&#20013;&#24515;&#30340;RBF&#32593;&#32476;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#20445;&#35777;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider a new class of RBF (Radial Basis Function) neural networks, in which smoothing factors are replaced with shifts. We prove under certain conditions on the activation function that these networks are capable of approximating any continuous multivariate function on any compact subset of the $d$-dimensional Euclidean space. For RBF networks with finitely many fixed centroids we describe conditions guaranteeing approximation with arbitrary precision.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#20957;&#32858;&#30340;&#30456;&#22270;&#65292;&#26088;&#22312;&#25552;&#20379;&#23545;&#31070;&#32463;&#32593;&#32476;&#21160;&#21147;&#23398;&#21306;&#22495;&#21450;&#20854;&#19982;&#21021;&#22987;&#21270;&#30456;&#20851;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#32508;&#21512;&#29702;&#35299;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35814;&#32454;&#35299;&#37322;&#20102;&#23567;&#21021;&#22987;&#21270;&#23548;&#33268;&#22312;&#21021;&#22987;&#35757;&#32451;&#38454;&#27573;&#20986;&#29616;&#20957;&#32858;&#30340;&#22522;&#26412;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2303.06561</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#20957;&#32858;&#30340;&#30456;&#22270;
&lt;/p&gt;
&lt;p&gt;
Phase Diagram of Initial Condensation for Two-layer Neural Networks. (arXiv:2303.06561v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#20957;&#32858;&#30340;&#30456;&#22270;&#65292;&#26088;&#22312;&#25552;&#20379;&#23545;&#31070;&#32463;&#32593;&#32476;&#21160;&#21147;&#23398;&#21306;&#22495;&#21450;&#20854;&#19982;&#21021;&#22987;&#21270;&#30456;&#20851;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#32508;&#21512;&#29702;&#35299;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35814;&#32454;&#35299;&#37322;&#20102;&#23567;&#21021;&#22987;&#21270;&#23548;&#33268;&#22312;&#21021;&#22987;&#35757;&#32451;&#38454;&#27573;&#20986;&#29616;&#20957;&#32858;&#30340;&#22522;&#26412;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#21516;&#21021;&#22987;&#21270;&#27604;&#20363;&#19979;&#21576;&#29616;&#20986;&#19981;&#21516;&#34892;&#20026;&#30340;&#29616;&#35937;&#19968;&#30452;&#26159;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#38590;&#39064;&#12290;&#26412;&#25991;&#22522;&#20110;Luo&#31561;&#20154;&#26089;&#26399;&#30340;&#24037;&#20316;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#20957;&#32858;&#30340;&#30456;&#22270;&#12290;&#20957;&#32858;&#26159;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26435;&#37325;&#21521;&#37327;&#38598;&#20013;&#20110;&#29420;&#31435;&#26041;&#21521;&#30340;&#29616;&#35937;&#65292;&#22312;&#38750;&#32447;&#24615;&#23398;&#20064;&#36807;&#31243;&#20013;&#26159;&#19968;&#31181;&#29305;&#24615;&#65292;&#20351;&#31070;&#32463;&#32593;&#32476;&#25317;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30456;&#22270;&#26088;&#22312;&#25552;&#20379;&#23545;&#31070;&#32463;&#32593;&#32476;&#21160;&#21147;&#23398;&#21306;&#22495;&#21450;&#20854;&#19982;&#21021;&#22987;&#21270;&#30456;&#20851;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#32508;&#21512;&#29702;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35814;&#32454;&#23637;&#31034;&#20102;&#23567;&#21021;&#22987;&#21270;&#23548;&#33268;&#22312;&#21021;&#22987;&#35757;&#32451;&#38454;&#27573;&#20986;&#29616;&#20957;&#32858;&#30340;&#22522;&#26412;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The phenomenon of distinct behaviors exhibited by neural networks under varying scales of initialization remains an enigma in deep learning research. In this paper, based on the earlier work by Luo et al.~\cite{luo2021phase}, we present a phase diagram of initial condensation for two-layer neural networks. Condensation is a phenomenon wherein the weight vectors of neural networks concentrate on isolated orientations during the training process, and it is a feature in non-linear learning process that enables neural networks to possess better generalization abilities. Our phase diagram serves to provide a comprehensive understanding of the dynamical regimes of neural networks and their dependence on the choice of hyperparameters related to initialization. Furthermore, we demonstrate in detail the underlying mechanisms by which small initialization leads to condensation at the initial training stage.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#29702;&#35770;&#30340;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#26041;&#26696;&#65292;&#23558;&#20302;&#36136;&#37327;&#30340;&#38750;&#26174;&#24494;&#34425;&#33180;&#35270;&#32593;&#33180;&#24425;&#29031;&#36716;&#25442;&#25104;&#39640;&#36136;&#37327;&#30340;&#23545;&#24212;&#29031;&#29255;&#65292;&#24182;&#36890;&#36807;&#22686;&#24378;&#27491;&#21017;&#21270;&#26041;&#27861;&#25913;&#36827;&#20102;&#27969;&#31243;&#30340;&#28789;&#27963;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#36866;&#29992;&#24615;&#12290;&#22312;&#19977;&#20010;&#20844;&#24320;&#30340;&#35270;&#32593;&#33180;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2302.03003</link><description>&lt;p&gt;
OTRE: &#22312;&#20248;&#21270;&#20256;&#36755;&#24341;&#23548;&#19979;&#30340;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20013;&#32467;&#21512;&#22686;&#24378;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
OTRE: Where Optimal Transport Guided Unpaired Image-to-Image Translation Meets Regularization by Enhancing. (arXiv:2302.03003v4 [eess.IV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03003
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#29702;&#35770;&#30340;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#26041;&#26696;&#65292;&#23558;&#20302;&#36136;&#37327;&#30340;&#38750;&#26174;&#24494;&#34425;&#33180;&#35270;&#32593;&#33180;&#24425;&#29031;&#36716;&#25442;&#25104;&#39640;&#36136;&#37327;&#30340;&#23545;&#24212;&#29031;&#29255;&#65292;&#24182;&#36890;&#36807;&#22686;&#24378;&#27491;&#21017;&#21270;&#26041;&#27861;&#25913;&#36827;&#20102;&#27969;&#31243;&#30340;&#28789;&#27963;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#36866;&#29992;&#24615;&#12290;&#22312;&#19977;&#20010;&#20844;&#24320;&#30340;&#35270;&#32593;&#33180;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#26174;&#24494;&#34425;&#33180;&#35270;&#32593;&#33180;&#24425;&#29031;&#20316;&#22270; (CFP) &#30001;&#20110;&#19981;&#38656;&#35201;&#30643;&#23380;&#25193;&#24352;&#30340;&#20248;&#28857;&#32780;&#24191;&#27867;&#21487;&#29992;&#65292;&#28982;&#32780;&#30001;&#20110;&#25805;&#20316;&#21592;&#65292;&#31995;&#32479;&#32570;&#38519;&#25110;&#24739;&#32773;&#30456;&#20851;&#21407;&#22240;&#32780;&#23481;&#26131;&#23548;&#33268;&#36136;&#37327;&#36739;&#24046;&#12290;&#31934;&#30830;&#30340;&#21307;&#23398;&#35786;&#26029;&#21644;&#33258;&#21160;&#20998;&#26512;&#38656;&#35201;&#26368;&#20339;&#35270;&#32593;&#33180;&#22270;&#20687;&#36136;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#29702;&#35770;&#25552;&#20986;&#20102;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#26041;&#26696;&#65292;&#23558;&#20302;&#36136;&#37327;&#30340;&#35270;&#32593;&#33180; CFP &#26144;&#23556;&#21040;&#39640;&#36136;&#37327;&#30340;&#23545;&#24212;&#29289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#25554;&#20837;&#22312; OT &#24341;&#23548;&#19979;&#35757;&#32451;&#30340;&#20808;&#39564;&#30693;&#35782;&#12289;&#23558;&#22522;&#20110;&#27169;&#22411;&#30340;&#22270;&#20687;&#37325;&#24314;&#26041;&#27861;&#65292;&#21363;&#21435;&#22122;&#27491;&#21017;&#21270;&#65292;&#36827;&#34892;&#20102;&#27867;&#21270;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25105;&#20204;&#30340;&#22270;&#20687;&#22686;&#24378;&#27969;&#31243;&#22312;&#20020;&#24202;&#23454;&#36341;&#20013;&#30340;&#28789;&#27963;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#23558;&#27492;&#31216;&#20026;&#22686;&#24378;&#27491;&#21017;&#21270; (RE)&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#20844;&#24320;&#30340;&#35270;&#32593;&#33180;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#38598;&#25104;&#26694;&#26550; OTRE &#30340;&#36136;&#37327;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-mydriatic retinal color fundus photography (CFP) is widely available due to the advantage of not requiring pupillary dilation, however, is prone to poor quality due to operators, systemic imperfections, or patient-related causes. Optimal retinal image quality is mandated for accurate medical diagnoses and automated analyses. Herein, we leveraged the Optimal Transport (OT) theory to propose an unpaired image-to-image translation scheme for mapping low-quality retinal CFPs to high-quality counterparts. Furthermore, to improve the flexibility, robustness, and applicability of our image enhancement pipeline in the clinical practice, we generalized a state-of-the-art model-based image reconstruction method, regularization by denoising, by plugging in priors learned by our OT-guided image-to-image translation network. We named it as regularization by enhancing (RE). We validated the integrated framework, OTRE, on three publicly available retinal image datasets by assessing the quality af
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#19982;&#26426;&#20250;&#65292;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#28304;&#29305;&#23450;&#21644;&#38745;&#24577;&#35266;&#27979;&#25968;&#25454;&#19978;&#65292;&#23454;&#38469;&#38382;&#39064;&#22312;&#20110;&#35266;&#27979;&#25968;&#25454;&#21482;&#33021;&#36880;&#27493;&#33719;&#24471;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.01026</link><description>&lt;p&gt;
&#36830;&#32493;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65306;&#25361;&#25112;&#19982;&#26426;&#20250;
&lt;/p&gt;
&lt;p&gt;
Continual Causal Effect Estimation: Challenges and Opportunities. (arXiv:2301.01026v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.01026
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#19982;&#26426;&#20250;&#65292;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#28304;&#29305;&#23450;&#21644;&#38745;&#24577;&#35266;&#27979;&#25968;&#25454;&#19978;&#65292;&#23454;&#38469;&#38382;&#39064;&#22312;&#20110;&#35266;&#27979;&#25968;&#25454;&#21482;&#33021;&#36880;&#27493;&#33719;&#24471;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#39046;&#22495;&#65292;&#22914;&#32463;&#27982;&#23398;&#12289;&#21307;&#30103;&#20445;&#20581;&#12289;&#20844;&#20849;&#25919;&#31574;&#12289;&#32593;&#32476;&#25366;&#25496;&#12289;&#22312;&#32447;&#24191;&#21578;&#21644;&#33829;&#38144;&#27963;&#21160;&#20013;&#65292;&#29702;&#35299;&#35266;&#23519;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#20851;&#31995;&#38750;&#24120;&#20851;&#38190;&#12290;&#23613;&#31649;&#22312;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#22914;&#22788;&#29702;&#32570;&#22833;&#30340;&#23545;&#29031;&#32467;&#26524;&#21644;&#27835;&#30103;&#19982;&#25511;&#21046;&#32452;&#20043;&#38388;&#30340;&#36873;&#25321;&#20559;&#24046;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#28304;&#29305;&#23450;&#21644;&#38745;&#24577;&#35266;&#27979;&#25968;&#25454;&#19978;&#12290;&#36825;&#20123;&#23398;&#20064;&#31574;&#30053;&#20551;&#35774;&#25152;&#26377;&#35266;&#27979;&#25968;&#25454;&#24050;&#32463;&#22312;&#35757;&#32451;&#38454;&#27573;&#21487;&#29992;&#19988;&#20165;&#26469;&#33258;&#20110;&#19968;&#20010;&#26469;&#28304;&#12290;&#36825;&#31181;&#21487;&#35775;&#38382;&#24615;&#30340;&#23454;&#38469;&#38382;&#39064;&#22312;&#21508;&#31181;&#23398;&#26415;&#21644;&#24037;&#19994;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#22312;&#22823;&#25968;&#25454;&#26102;&#20195;&#65292;&#25105;&#20204;&#38754;&#20020;&#30528;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26032;&#25361;&#25112;&#65292;&#21363;&#38024;&#23545;&#36880;&#27493;&#21487;&#29992;&#30340;&#35266;&#27979;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#39069;&#22806;&#39046;&#22495;&#36866;&#24212;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A further understanding of cause and effect within observational data is critical across many domains, such as economics, health care, public policy, web mining, online advertising, and marketing campaigns. Although significant advances have been made to overcome the challenges in causal effect estimation with observational data, such as missing counterfactual outcomes and selection bias between treatment and control groups, the existing methods mainly focus on source-specific and stationary observational data. Such learning strategies assume that all observational data are already available during the training phase and from only one source. This practical concern of accessibility is ubiquitous in various academic and industrial applications. That's what it boiled down to: in the era of big data, we face new challenges in causal inference with observational data, i.e., the extensibility for incrementally available observational data, the adaptability for extra domain adaptation proble
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21322;&#30417;&#30563;&#33258;&#32534;&#30721;&#22120;&#20197;&#21450;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#26631;&#35760;&#26679;&#26412;&#26469;&#24320;&#21457;&#36719;&#27979;&#37327;&#20256;&#24863;&#22120;&#65292;&#20174;&#32780;&#26174;&#33879;&#38477;&#20302;&#20102;&#25104;&#26412;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#20316;&#32773;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#21462;&#24471;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2212.13067</link><description>&lt;p&gt;
&#20351;&#29992;&#21322;&#30417;&#30563;&#33258;&#32534;&#30721;&#22120;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#36827;&#34892;&#36719;&#27979;&#37327;&#24320;&#21457;
&lt;/p&gt;
&lt;p&gt;
Online Active Learning for Soft Sensor Development using Semi-Supervised Autoencoders. (arXiv:2212.13067v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.13067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21322;&#30417;&#30563;&#33258;&#32534;&#30721;&#22120;&#20197;&#21450;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#26631;&#35760;&#26679;&#26412;&#26469;&#24320;&#21457;&#36719;&#27979;&#37327;&#20256;&#24863;&#22120;&#65292;&#20174;&#32780;&#26174;&#33879;&#38477;&#20302;&#20102;&#25104;&#26412;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#20316;&#32773;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#21462;&#24471;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#36719;&#27979;&#37327;&#22312;&#24037;&#19994;&#21644;&#21270;&#23398;&#36807;&#31243;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20197;&#39044;&#27979;&#38590;&#20197;&#27979;&#37327;&#30340;&#36807;&#31243;&#21464;&#37327;&#12290;&#36825;&#20123;&#20256;&#24863;&#22120;&#20351;&#29992;&#30340;&#22238;&#24402;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#26631;&#35760;&#30340;&#26679;&#26412;&#65292;&#28982;&#32780;&#65292;&#30001;&#20110;&#36136;&#37327;&#26816;&#26597;&#38656;&#35201;&#39640;&#26114;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#65292;&#33719;&#21462;&#26631;&#31614;&#20449;&#24687;&#21487;&#33021;&#38750;&#24120;&#26114;&#36149;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#38750;&#24120;&#26377;&#30410;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#24314;&#35758;&#26597;&#35810;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#26631;&#31614;&#12290;&#28982;&#32780;&#65292;&#20026;&#22238;&#24402;&#25552;&#20986;&#30340;&#22823;&#22810;&#25968;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#37117;&#38598;&#20013;&#22312;&#31163;&#32447;&#22330;&#26223;&#12290;&#26412;&#25991;&#23558;&#20854;&#20013;&#19968;&#20123;&#26041;&#27861;&#36866;&#24212;&#20110;&#27969;&#24335;&#22330;&#26223;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#22522;&#20110;&#27491;&#20132;&#33258;&#32534;&#30721;&#22120;&#30340;&#21322;&#30417;&#30563;&#26550;&#26500;&#23398;&#20064;&#20302;&#32500;&#31354;&#38388;&#20013;&#30340;&#26174;&#33879;&#29305;&#24449;&#12290;&#25105;&#20204;&#20063;&#28436;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#30000;&#32435;&#35199;&#19996;&#26364;&#36807;&#31243;&#27604;&#36739;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven soft sensors are extensively used in industrial and chemical processes to predict hard-to-measure process variables whose real value is difficult to track during routine operations. The regression models used by these sensors often require a large number of labeled examples, yet obtaining the label information can be very expensive given the high time and cost required by quality inspections. In this context, active learning methods can be highly beneficial as they can suggest the most informative labels to query. However, most of the active learning strategies proposed for regression focus on the offline setting. In this work, we adapt some of these approaches to the stream-based scenario and show how they can be used to select the most informative data points. We also demonstrate how to use a semi-supervised architecture based on orthogonal autoencoders to learn salient features in a lower dimensional space. The Tennessee Eastman Process is used to compare the predictive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#24433;&#21709;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#27169;&#22411;&#36873;&#25321;&#23545;&#23398;&#20064;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2211.14699</link><description>&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#29702;&#35770;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Study of Inductive Biases in Contrastive Learning. (arXiv:2211.14699v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14699
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#24433;&#21709;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#27169;&#22411;&#36873;&#25321;&#23545;&#23398;&#20064;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#33258;&#30417;&#30563;&#23398;&#20064;&#26159;&#37325;&#35201;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20043;&#21069;&#30340;&#29702;&#35770;&#30740;&#31350;&#23545;&#39044;&#35757;&#32451;&#25439;&#22833;&#30340;&#20316;&#29992;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#23558;&#31070;&#32463;&#32593;&#32476;&#35270;&#20026;&#26222;&#36890;&#30340;&#40657;&#30418;&#23376;&#12290;&#28982;&#32780;&#65292;Saunshi&#31561;&#20154;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#27169;&#22411;&#32467;&#26500;&#8212;&#8212;&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#24456;&#23569;&#20851;&#27880;&#30340;&#19968;&#20010;&#32452;&#25104;&#37096;&#20998;&#8212;&#8212;&#23545;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#19979;&#28216;&#24615;&#33021;&#20063;&#26377;&#26174;&#33879;&#30340;&#24433;&#21709;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#23558;&#28304;&#20110;&#27169;&#22411;&#31867;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#24433;&#21709;&#32435;&#20837;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20851;&#27880;&#23545;&#20110;&#35270;&#35273;&#39046;&#22495;&#26222;&#36941;&#20351;&#29992;&#30340;&#19968;&#31181;&#27969;&#34892;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#8212;&#8212;&#23545;&#27604;&#23398;&#20064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#27169;&#22411;&#20855;&#26377;&#26377;&#38480;&#30340;&#23481;&#37327;&#26102;&#65292;&#23545;&#27604;&#34920;&#31034;&#20250;&#24674;&#22797;&#19982;&#27169;&#22411;&#32467;&#26500;&#20860;&#23481;&#30340;&#26576;&#20123;&#29305;&#27530;&#32858;&#31867;&#32467;&#26500;&#65292;&#20294;&#20250;&#24573;&#30053;&#25968;&#25454;&#20998;&#24067;&#20013;&#30340;&#35768;&#22810;&#20854;&#20182;&#32858;&#31867;&#32467;&#26500;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#21487;&#20197;&#25429;&#25417;&#23545;&#27604;&#23398;&#20064;&#26356;&#20026;&#22797;&#26434;&#30340;&#34892;&#20026;&#65292;&#25552;&#20379;&#20102;&#26377;&#20851;&#27169;&#22411;&#32467;&#26500;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;&#23398;&#20064;&#36807;&#31243;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of Saunshi et al. argues that the model architecture -- a component largely ignored by previous works -- also has significant influences on the downstream performance of self-supervised learning. In this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning -- a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26435;&#37325;&#38598;&#25104;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#20801;&#35768;&#25968;&#25454;&#30456;&#20851;&#30340;&#21152;&#26435;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#25552;&#39640;&#26368;&#36817;&#33258;&#30417;&#30563;&#23398;&#20064;&#25216;&#26415;&#30340;&#24615;&#33021;&#65292;&#32780;&#19981;&#38656;&#35201;&#25913;&#21464;&#21407;&#26377;&#30340;&#26550;&#26500;&#65292;&#20854;&#22312; ImageNet-1K &#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340; DINO &#21644; MSN &#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#23567;&#26679;&#26412;&#35774;&#32622;&#20013;&#34920;&#29616;&#26368;&#20339;&#12290;</title><link>http://arxiv.org/abs/2211.09981</link><description>&lt;p&gt;
&#24102;&#26435;&#37325;&#38598;&#25104;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Weighted Ensemble Self-Supervised Learning. (arXiv:2211.09981v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26435;&#37325;&#38598;&#25104;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#20801;&#35768;&#25968;&#25454;&#30456;&#20851;&#30340;&#21152;&#26435;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#25552;&#39640;&#26368;&#36817;&#33258;&#30417;&#30563;&#23398;&#20064;&#25216;&#26415;&#30340;&#24615;&#33021;&#65292;&#32780;&#19981;&#38656;&#35201;&#25913;&#21464;&#21407;&#26377;&#30340;&#26550;&#26500;&#65292;&#20854;&#22312; ImageNet-1K &#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340; DINO &#21644; MSN &#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#23567;&#26679;&#26412;&#35774;&#32622;&#20013;&#34920;&#29616;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#24050;&#34987;&#35777;&#26126;&#26159;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12289;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#20581;&#22766;&#24615;&#30340;&#26377;&#25928;&#25216;&#26415;&#12290;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#36827;&#23637;&#20351;&#24471;&#21033;&#29992;&#22823;&#35268;&#27169;&#26410;&#26631;&#35760;&#35821;&#26009;&#24211;&#36827;&#34892;&#26368;&#20808;&#36827;&#30340;&#23567;&#26679;&#26412;&#21644;&#30417;&#30563;&#23398;&#20064;&#25104;&#20026;&#21487;&#33021;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#20801;&#35768;&#25968;&#25454;&#30456;&#20851;&#30340;&#21152;&#26435;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26694;&#26550;&#26469;&#25913;&#36827;&#26368;&#36817;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#25216;&#26415;&#12290;&#25105;&#20204;&#36991;&#20813;&#23545;&#34920;&#31034;&#39592;&#24178;&#36827;&#34892;&#38598;&#25104;&#65307;&#36825;&#20010;&#36873;&#25321;&#20135;&#29983;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#23427;&#30340;&#35757;&#32451;&#25104;&#26412;&#24456;&#23567;&#65292;&#23545;&#19979;&#28216;&#35780;&#20272;&#19981;&#38656;&#35201;&#36827;&#34892;&#26550;&#26500;&#25913;&#21464;&#25110;&#35745;&#31639;&#24320;&#38144;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312; ImageNet-1K &#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#20102;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861; DINO (Caron &#31561;&#20154;&#65292;2021) &#21644; MSN (Assran &#31561;&#20154;&#65292;2022)&#65292;&#22312;&#22810;&#20010;&#35780;&#20272;&#25351;&#26631;&#19978;&#22343;&#20248;&#20110;&#23427;&#20204;&#65292;&#23588;&#20854;&#22312;&#23567;&#26679;&#26412;&#35774;&#32622;&#20013;&#34920;&#29616;&#26368;&#20339;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#20960;&#31181;&#21152;&#26435;&#26041;&#26696;&#65292;&#24182;&#21457;&#29616;&#8230;&#65288;&#26410;&#23436;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Ensembling has proven to be a powerful technique for boosting model performance, uncertainty estimation, and robustness in supervised learning. Advances in self-supervised learning (SSL) enable leveraging large unlabeled corpora for state-of-the-art few-shot and supervised learning performance. In this paper, we explore how ensemble methods can improve recent SSL techniques by developing a framework that permits data-dependent weighted cross-entropy losses. We refrain from ensembling the representation backbone; this choice yields an efficient ensemble method that incurs a small training cost and requires no architectural changes or computational overhead to downstream evaluation. The effectiveness of our method is demonstrated with two state-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al., 2022). Our method outperforms both in multiple evaluation metrics on ImageNet-1K, particularly in the few-shot setting. We explore several weighting schemes and find that th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;GFlowNets&#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#32852;&#21512;&#23398;&#20064;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#26426;&#21046;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#65292;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#20063;&#33021;&#19982;&#20960;&#20010;&#22522;&#32447;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;</title><link>http://arxiv.org/abs/2211.02763</link><description>&lt;p&gt;
GFlowNets&#19982;&#21464;&#20998;&#36125;&#21494;&#26031;&#30340;&#22240;&#26524;&#32467;&#26500;&#21644;&#26426;&#21046;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian learning of Causal Structure and Mechanisms with GFlowNets and Variational Bayes. (arXiv:2211.02763v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;GFlowNets&#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#32852;&#21512;&#23398;&#20064;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#26426;&#21046;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#65292;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#20063;&#33021;&#19982;&#20960;&#20010;&#22522;&#32447;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#26088;&#22312;&#23398;&#20064;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#19978;&#30340;&#21518;&#39564;&#20998;&#24067;&#21644;&#23450;&#20041;&#29238;&#21464;&#37327;&#21644;&#23376;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#26426;&#21046;&#12290;&#26412;&#25991;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21464;&#20998;&#36125;&#21494;&#26031;&#32852;&#21512;&#23398;&#20064;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#26426;&#21046;&#65292;&#31216;&#20026;&#21464;&#20998;&#36125;&#21494;&#26031;DAG-GFlowNet&#65288;VBG&#65289;&#12290;&#25105;&#20204;&#20351;&#29992;GFlowNets&#25193;&#23637;&#20102;&#36125;&#21494;&#26031;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#19981;&#20165;&#23398;&#20064;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#36824;&#23398;&#20064;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;VBG&#22312;&#24314;&#27169;DAG&#21644;&#26426;&#21046;&#30340;&#21518;&#39564;&#20998;&#24067;&#26102;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#65292;&#32780;&#19988;&#36824;&#33021;&#19982;&#20960;&#20010;&#22522;&#32447;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian causal structure learning aims to learn a posterior distribution over directed acyclic graphs (DAGs), and the mechanisms that define the relationship between parent and child variables. By taking a Bayesian approach, it is possible to reason about the uncertainty of the causal model. The notion of modelling the uncertainty over models is particularly crucial for causal structure learning since the model could be unidentifiable when given only a finite amount of observational data. In this paper, we introduce a novel method to jointly learn the structure and mechanisms of the causal model using Variational Bayes, which we call Variational Bayes-DAG-GFlowNet (VBG). We extend the method of Bayesian causal structure learning using GFlowNets to learn not only the posterior distribution over the structure, but also the parameters of a linear-Gaussian model. Our results on simulated data suggest that VBG is competitive against several baselines in modelling the posterior over DAGs an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#24335;&#24352;&#37327;&#20998;&#35299;&#30697;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#26080;&#38656;&#23545;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#36890;&#36807;&#24320;&#21457;&#39640;&#25928;&#30340;&#26080;&#24352;&#37327;&#25805;&#20316;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#30340;&#21487;&#34892;&#24615;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#31454;&#20105;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#28151;&#21512;&#29289;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.14386</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#30340;&#38544;&#24335;&#24352;&#37327;&#20998;&#35299;&#30697;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Moment Estimation for Nonparametric Mixture Models Through Implicit Tensor Decomposition. (arXiv:2210.14386v2 [math.NA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#24335;&#24352;&#37327;&#20998;&#35299;&#30697;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#26080;&#38656;&#23545;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#36890;&#36807;&#24320;&#21457;&#39640;&#25928;&#30340;&#26080;&#24352;&#37327;&#25805;&#20316;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#30340;&#21487;&#34892;&#24615;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#31454;&#20105;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#28151;&#21512;&#29289;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#22411;&#30340;&#25968;&#20540;&#20248;&#21270;&#26041;&#26696;&#29992;&#20110;&#22312; $\mathbb{R}^n$ &#20013;&#20272;&#35745;&#26465;&#20214;&#29420;&#31435;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#26080;&#38656;&#23545;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#26681;&#25454;&#30697;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19968;&#20010;&#19981;&#23436;&#25972;&#30340;&#24352;&#37327;&#20998;&#35299;&#38382;&#39064;&#20197;&#23398;&#20064;&#28151;&#21512;&#26435;&#37325;&#21644;&#21508;&#20998;&#37327;&#30340;&#22343;&#20540;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#32447;&#24615;&#27714;&#35299;&#65292;&#35745;&#31639;&#20998;&#37327;&#20998;&#24067;&#30340;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#12289;&#39640;&#38454;&#30697;&#21644;&#20854;&#20182;&#32479;&#35745;&#37327;&#12290;&#36890;&#36807;&#24320;&#21457;&#39640;&#25928;&#30340;&#26080;&#24352;&#37327;&#25805;&#20316;&#65292;&#36991;&#20813;&#20102;&#39640;&#38454;&#24352;&#37327;&#25152;&#24102;&#26469;&#30340;&#39640;&#25104;&#26412;&#38382;&#39064;&#65292;&#20351;&#24471;&#35745;&#31639;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#26356;&#21152;&#21487;&#34892;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#31454;&#20105;&#24615;&#33021;&#65292;&#24182;&#19988;&#23427;&#36866;&#29992;&#20110;&#35768;&#22810;&#27169;&#22411;&#21644;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#20174;&#28151;&#21512;&#29289;&#30340;&#20302;&#38454;&#30697;&#20013;&#24314;&#31435;&#20102;&#21487;&#35782;&#21035;&#24615;&#65292;&#24182;&#20445;&#35777;&#20102; ALS &#31639;&#27861;&#30340;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an alternating least squares type numerical optimization scheme to estimate conditionally-independent mixture models in $\mathbb{R}^n$, without parameterizing the distributions. Following the method of moments, we tackle an incomplete tensor decomposition problem to learn the mixing weights and componentwise means. Then we compute the cumulative distribution functions, higher moments and other statistics of the component distributions through linear solves. Crucially for computations in high dimensions, the steep costs associated with high-order tensors are evaded, via the development of efficient tensor-free operations. Numerical experiments demonstrate the competitive performance of the algorithm, and its applicability to many models and applications. Furthermore we provide theoretical analyses, establishing identifiability from low-order moments of the mixture and guaranteeing local linear convergence of the ALS algorithm.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#36275;&#22815;&#24179;&#28369;&#20984;&#30340;&#28608;&#27963;&#20989;&#25968;&#26102;&#65292;SGD&#21487;&#20197;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#35777;&#26126;&#36807;&#31243;&#20013;&#24341;&#20837;Frobenius&#33539;&#25968;&#27491;&#21017;&#21270;&#19982;&#24688;&#24403;&#20998;&#24067;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#65292;&#21516;&#26102;&#25299;&#23637;&#20102;&#36830;&#32493;&#26102;&#38388;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.11452</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;SGD&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Global Convergence of SGD On Two Layer Neural Nets. (arXiv:2210.11452v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11452
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#36275;&#22815;&#24179;&#28369;&#20984;&#30340;&#28608;&#27963;&#20989;&#25968;&#26102;&#65292;SGD&#21487;&#20197;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#35777;&#26126;&#36807;&#31243;&#20013;&#24341;&#20837;Frobenius&#33539;&#25968;&#27491;&#21017;&#21270;&#19982;&#24688;&#24403;&#20998;&#24067;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#65292;&#21516;&#26102;&#25299;&#23637;&#20102;&#36830;&#32493;&#26102;&#38388;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#28145;&#24230;&#20026;2&#30340;&#32593;&#32476;&#37319;&#29992;&#36275;&#22815;&#24179;&#28369;&#19988;&#26377;&#36793;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#65288;&#27604;&#22914;sigmoid&#21644;tanh&#65289;&#26102;&#65292;SGD&#21487;&#20197;&#35777;&#26126;&#24615;&#22320;&#25910;&#25947;&#21040;&#36866;&#24403;&#27491;&#21017;&#21270;&#30340;$\ell_2-$&#32463;&#39564;&#39118;&#38505;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;--&#23545;&#20110;&#20219;&#24847;&#25968;&#25454;&#21644;&#20219;&#24847;&#25968;&#37327;&#30340;&#38376;&#12290;&#25105;&#20204;&#22312;[1]&#30340;&#30740;&#31350;&#25104;&#26524;&#19978;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#24182;&#22312;&#26435;&#37325;&#19978;&#28155;&#21152;&#20102;&#24658;&#23450;&#37327;&#30340;Frobenius&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#21516;&#26102;&#36873;&#21462;&#20102;&#24688;&#24403;&#30340;&#20998;&#24067;&#23545;&#21021;&#22987;&#26435;&#37325;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#30340;SGD&#25910;&#25947;&#32467;&#26524;&#65292;&#21516;&#26679;&#36866;&#29992;&#20110;&#22914;SoftPlus&#36825;&#26679;&#30340;&#24179;&#28369;&#26080;&#36793;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24819;&#27861;&#26159;&#23637;&#31034;&#20102;&#23384;&#22312;&#20110;&#22266;&#23450;&#22823;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23427;&#20204;&#26159;&#8220;Villani&#20989;&#25968;&#8221;[1] Bin Shi, Weijie J. Su, and Michael I. Jordan. On learning rates and schr\"odinger operators, 2020. arXiv:2004.06977
&lt;/p&gt;
&lt;p&gt;
In this note we demonstrate provable convergence of SGD to the global minima of appropriately regularized $\ell_2-$empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates, if they are using adequately smooth and bounded activations like sigmoid and tanh. We build on the results in [1] and leverage a constant amount of Frobenius norm regularization on the weights, along with sampling of the initial weights from an appropriate distribution. We also give a continuous time SGD convergence result that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence loss functions on constant sized neural nets which are "Villani Functions". [1] Bin Shi, Weijie J. Su, and Michael I. Jordan. On learning rates and schr\"odinger operators, 2020. arXiv:2004.06977
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24369;&#30417;&#30563;&#20449;&#24687;&#30340;&#26631;&#31614;&#20256;&#25773;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#19978;&#30340;&#27010;&#29575;&#20551;&#35774;&#26631;&#31614;&#65292;&#32467;&#21512;&#23616;&#37096;&#20960;&#20309;&#29305;&#24615;&#21644;&#20808;&#39564;&#20449;&#24687;&#30340;&#36136;&#37327;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#35823;&#24046;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#22810;&#20010;&#22122;&#22768;&#20449;&#24687;&#28304;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#24369;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#33021;&#21147;&#65292;&#26174;&#31034;&#20986;&#23545;&#29616;&#26377;&#21322;&#30417;&#30563;&#21644;&#24369;&#30417;&#30563;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2210.03594</link><description>&lt;p&gt;
&#24369;&#30417;&#30563;&#19979;&#30340;&#26631;&#31614;&#20256;&#25773;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Label Propagation with Weak Supervision. (arXiv:2210.03594v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.03594
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24369;&#30417;&#30563;&#20449;&#24687;&#30340;&#26631;&#31614;&#20256;&#25773;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#19978;&#30340;&#27010;&#29575;&#20551;&#35774;&#26631;&#31614;&#65292;&#32467;&#21512;&#23616;&#37096;&#20960;&#20309;&#29305;&#24615;&#21644;&#20808;&#39564;&#20449;&#24687;&#30340;&#36136;&#37327;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#35823;&#24046;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#22810;&#20010;&#22122;&#22768;&#20449;&#24687;&#28304;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#24369;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#33021;&#21147;&#65292;&#26174;&#31034;&#20986;&#23545;&#29616;&#26377;&#21322;&#30417;&#30563;&#21644;&#24369;&#30417;&#30563;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a label propagation algorithm that utilizes weak supervision information, specifically probabilistic hypothesized labels on the unlabeled data, and provides an error bound that exploits both the local geometric properties of the underlying graph and the quality of the prior information. The approach is demonstrated on multiple benchmark weakly supervised classification tasks, showing improvements upon existing semi-supervised and weakly supervised methods.
&lt;/p&gt;
&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#24369;&#30417;&#30563;&#23398;&#20064;&#26159;&#24403;&#21069;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#26088;&#22312;&#20943;&#23569;&#26631;&#35760;&#25968;&#25454;&#38656;&#27714;&#30340;&#37325;&#35201;&#33539;&#24335;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#32463;&#20856;&#26631;&#31614;&#20256;&#25773;&#31639;&#27861;&#65288;LPA&#65289;&#65288;Zhu&#65286;Ghahramani&#65292;2002&#65289;&#30340;&#20998;&#26512;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;&#26377;&#29992;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#29305;&#21035;&#26159;&#26410;&#26631;&#35760;&#25968;&#25454;&#19978;&#30340;&#27010;&#29575;&#20551;&#35774;&#26631;&#31614;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#35823;&#24046;&#30028;&#65292;&#21033;&#29992;&#20102;&#24213;&#23618;&#22270;&#24418;&#30340;&#23616;&#37096;&#20960;&#20309;&#29305;&#24615;&#21644;&#20808;&#39564;&#20449;&#24687;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#22810;&#20010;&#22122;&#22768;&#20449;&#24687;&#28304;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24369;&#30417;&#30563;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#25105;&#20204;&#30340;&#20449;&#24687;&#26469;&#28304;&#26159;&#24369;&#26631;&#35760;&#32773;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#24369;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#33021;&#21147;&#65292;&#26174;&#31034;&#20986;&#23545;&#29616;&#26377;&#21322;&#30417;&#30563;&#21644;&#24369;&#30417;&#30563;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning and weakly supervised learning are important paradigms that aim to reduce the growing demand for labeled data in current machine learning applications. In this paper, we introduce a novel analysis of the classical label propagation algorithm (LPA) (Zhu &amp; Ghahramani, 2002) that moreover takes advantage of useful prior information, specifically probabilistic hypothesized labels on the unlabeled data. We provide an error bound that exploits both the local geometric properties of the underlying graph and the quality of the prior information. We also propose a framework to incorporate multiple sources of noisy information. In particular, we consider the setting of weak supervision, where our sources of information are weak labelers. We demonstrate the ability of our approach on multiple benchmark weakly supervised classification tasks, showing improvements upon existing semi-supervised and weakly supervised methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#22522;&#20110;&#29305;&#24449;&#31526;&#21512;&#39044;&#27979;&#30340;&#39044;&#27979;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#34920;&#31034;&#23398;&#20064;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#25193;&#23637;&#20102;&#31526;&#21512;&#39044;&#27979;&#21040;&#35821;&#20041;&#29305;&#24449;&#31354;&#38388;&#12290;&#20174;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#26469;&#30475;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#24120;&#35268;&#31526;&#21512;&#39044;&#27979;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#23637;&#29616;&#20102;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.00173</link><description>&lt;p&gt;
&#22522;&#20110;&#29305;&#24449;&#31526;&#21512;&#39044;&#27979;&#30340;&#39044;&#27979;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Predictive Inference with Feature Conformal Prediction. (arXiv:2210.00173v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#22522;&#20110;&#29305;&#24449;&#31526;&#21512;&#39044;&#27979;&#30340;&#39044;&#27979;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#34920;&#31034;&#23398;&#20064;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#25193;&#23637;&#20102;&#31526;&#21512;&#39044;&#27979;&#21040;&#35821;&#20041;&#29305;&#24449;&#31354;&#38388;&#12290;&#20174;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#26469;&#30475;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#24120;&#35268;&#31526;&#21512;&#39044;&#27979;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#20219;&#21153;&#19978;&#23637;&#29616;&#20102;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#39044;&#27979;&#26159;&#19968;&#31181;&#26080;&#20998;&#24067;&#25216;&#26415;&#65292;&#29992;&#20110;&#24314;&#31435;&#26377;&#25928;&#30340;&#39044;&#27979;&#38388;&#38548;&#12290;&#34429;&#28982;&#20256;&#32479;&#19978;&#20154;&#20204;&#22312;&#36755;&#20986;&#31354;&#38388;&#20013;&#36827;&#34892;&#31526;&#21512;&#39044;&#27979;&#65292;&#20294;&#36825;&#24182;&#19981;&#26159;&#21807;&#19968;&#30340;&#21487;&#33021;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#31526;&#21512;&#39044;&#27979;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#34920;&#31034;&#23398;&#20064;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#25193;&#23637;&#20102;&#31526;&#21512;&#39044;&#27979;&#23545;&#35821;&#20041;&#29305;&#24449;&#31354;&#38388;&#30340;&#33539;&#22260;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#31526;&#21512;&#39044;&#27979;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#21487;&#20197;&#35777;&#26126;&#20248;&#20110;&#24120;&#35268;&#31526;&#21512;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#21487;&#20197;&#19982;&#26222;&#36890;&#31526;&#21512;&#39044;&#27979;&#32467;&#21512;&#20351;&#29992;&#65292;&#32780;&#19988;&#21487;&#20197;&#19982;&#20854;&#20182;&#33258;&#36866;&#24212;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#12290;&#38500;&#20102;&#29616;&#26377;&#39044;&#27979;&#25512;&#26029;&#22522;&#20934;&#27979;&#35797;&#30340;&#23454;&#39564;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#22823;&#35268;&#27169;&#20219;&#21153;&#65288;&#22914;ImageNet&#20998;&#31867;&#21644;Cityscapes&#22270;&#20687;&#20998;&#21106;&#65289;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on large-scale tasks such as ImageNet classification and Cityscapes image segmentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#26102;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#21457;&#29616;&#20854;&#25439;&#22833;&#38160;&#24230;&#36981;&#24490;&#38750;&#20809;&#28369;&#30340;&#20108;&#27425;&#26354;&#32447;&#65292;&#24403;&#31070;&#32463;&#32593;&#32476;&#30340;&#22797;&#26434;&#24230;&#36880;&#28176;&#22686;&#21152;&#26102;&#65292;&#27979;&#35797;&#35823;&#24046;&#20250;&#20808;&#38477;&#21518;&#21319;&#65288;&#21363;&#8220;&#21452;&#19979;&#38477;&#8221;&#29616;&#35937;&#65289;&#12290;</title><link>http://arxiv.org/abs/2209.10080</link><description>&lt;p&gt;
&#22522;&#20110;&#24179;&#28369;&#25554;&#20540;&#30340;&#28145;&#24230;&#21452;&#37325;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Deep Double Descent via Smooth Interpolation. (arXiv:2209.10080v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10080
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#26102;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#21457;&#29616;&#20854;&#25439;&#22833;&#38160;&#24230;&#36981;&#24490;&#38750;&#20809;&#28369;&#30340;&#20108;&#27425;&#26354;&#32447;&#65292;&#24403;&#31070;&#32463;&#32593;&#32476;&#30340;&#22797;&#26434;&#24230;&#36880;&#28176;&#22686;&#21152;&#26102;&#65292;&#27979;&#35797;&#35823;&#24046;&#20250;&#20808;&#38477;&#21518;&#21319;&#65288;&#21363;&#8220;&#21452;&#19979;&#38477;&#8221;&#29616;&#35937;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30740;&#31350;&#34920;&#26126;&#65292;&#36229;&#21442;&#25968;&#21270;&#28145;&#24230;&#32593;&#32476;&#20855;&#26377;&#25554;&#20540;&#22122;&#22768;&#25968;&#25454;&#21644;&#34920;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#30340;&#33021;&#21147;&#65292;&#36825;&#31181;&#29616;&#35937;&#36890;&#36807;&#27979;&#35797;&#35823;&#24046;&#30340;&#21452;&#37325;&#19979;&#38477;&#26354;&#32447;&#24471;&#21040;&#20102;&#34920;&#24449;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#28145;&#24230;&#32593;&#32476;&#25554;&#20540;&#21644;&#27867;&#21270;&#20043;&#38388;&#30340;&#31934;&#30830;&#20851;&#31995;&#36824;&#27809;&#26377;&#24471;&#21040;&#26126;&#30830;&#30340;&#23450;&#37327;&#25551;&#36848;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#26102;&#19982;&#27599;&#20010;&#35757;&#32451;&#28857;&#21608;&#22260;&#30340;&#36755;&#20837;&#21464;&#37327;&#30456;&#20851;&#32852;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#23450;&#37327;&#34913;&#37327;&#35757;&#32451;&#25968;&#25454;&#30340;&#25311;&#21512;&#38160;&#24230;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#25439;&#22833;&#38160;&#24230;&#36981;&#24490;&#19968;&#20010;&#38750;&#20809;&#28369;&#30340;&#20108;&#27425;&#26354;&#32447;&#65292;&#36825;&#19982;&#20256;&#32479;&#30340;&#22810;&#39033;&#24335;&#22238;&#24402;&#30340;&#20998;&#26512;&#32467;&#35770;&#26377;&#19968;&#23450;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#24403;&#31070;&#32463;&#32593;&#32476;&#30340;&#22797;&#26434;&#24230;&#36880;&#28176;&#22686;&#21152;&#26102;&#65292;&#27979;&#35797;&#35823;&#24046;&#20250;&#20808;&#38477;&#21518;&#21319;&#65288;&#21363;&#8220;&#21452;&#19979;&#38477;&#8221;&#29616;&#35937;&#65289;&#65292;&#36825;&#19982;&#20043;&#21069;&#30740;&#31350;&#30340;&#32467;&#35770;&#26377;&#25152;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability of overparameterized deep networks to interpolate noisy data, while at the same time showing good generalization performance, has been recently characterized in terms of the double descent curve for the test error. Common intuition from polynomial regression suggests that overparameterized networks are able to sharply interpolate noisy data, without considerably deviating from the ground-truth signal, thus preserving generalization ability. At present, a precise characterization of the relationship between interpolation and generalization for deep networks is missing. In this work, we quantify sharpness of fit of the training data interpolated by neural network functions, by studying the loss landscape w.r.t. to the input variable locally to each training point, over volumes around cleanly- and noisily-labelled training samples, as we systematically increase the number of model parameters and training epochs. Our findings show that loss sharpness in the input space follows 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#39640;&#32500;&#25968;&#25454;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#36138;&#24515;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#65292;&#33021;&#22815;&#36890;&#36807;&#21033;&#29992;&#27169;&#22411;&#30340;&#32467;&#26500;&#24615;&#36136;&#65292;&#22312;&#24191;&#27867;&#30340;&#38382;&#39064;&#33539;&#22260;&#20869;&#23454;&#29616;&#23545;&#32500;&#24230;&#30340;&#23545;&#25968;&#20381;&#36182;&#24615;&#12290;</title><link>http://arxiv.org/abs/2207.01560</link><description>&lt;p&gt;
&#36138;&#24515;&#22352;&#26631;&#19979;&#38477;&#23454;&#29616;&#39640;&#32500;&#31169;&#26377;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Private Empirical Risk Minimization by Greedy Coordinate Descent. (arXiv:2207.01560v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.01560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#39640;&#32500;&#25968;&#25454;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#36138;&#24515;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#65292;&#33021;&#22815;&#36890;&#36807;&#21033;&#29992;&#27169;&#22411;&#30340;&#32467;&#26500;&#24615;&#36136;&#65292;&#22312;&#24191;&#27867;&#30340;&#38382;&#39064;&#33539;&#22260;&#20869;&#23454;&#29616;&#23545;&#32500;&#24230;&#30340;&#23545;&#25968;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;DP-ERM&#65289;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;DP-ERM&#30340;&#26368;&#22351;&#24773;&#20917;&#25928;&#29992;&#20250;&#22810;&#39033;&#24335;&#38477;&#20302;&#12290;&#36825;&#26159;&#31169;&#26377;&#23398;&#20064;&#22823;&#22411;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20027;&#35201;&#38556;&#30861;&#12290;&#22312;&#39640;&#32500;&#20013;&#65292;&#19968;&#20123;&#27169;&#22411;&#21442;&#25968;&#25658;&#24102;&#30340;&#20449;&#24687;&#27604;&#20854;&#20182;&#21442;&#25968;&#26356;&#22810;&#26159;&#24456;&#24120;&#35265;&#30340;&#12290;&#20026;&#20102;&#21033;&#29992;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#36138;&#24515;&#22352;&#26631;&#19979;&#38477;&#65288;DP-GCD&#65289;&#31639;&#27861;&#12290;&#22312;&#27599;&#20010;&#36845;&#20195;&#27493;&#39588;&#20013;&#65292;DP-GCD&#27839;&#30528;&#26799;&#24230;(&#22823;&#33268;&#22320;)&#26368;&#22823;&#30340;&#26465;&#30446;&#36827;&#34892;&#22352;&#26631;&#26799;&#24230;&#27493;&#39588;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;DP-GCD&#21487;&#20197;&#36890;&#36807;&#33258;&#28982;&#22320;&#21033;&#29992;&#20854;&#32467;&#26500;&#24615;&#36136;&#65288;&#20363;&#22914;&#25311;&#31232;&#30095;&#35299;&#65289;&#22312;&#24191;&#27867;&#30340;&#38382;&#39064;&#33539;&#22260;&#20869;&#23454;&#29616;&#23545;&#32500;&#24230;&#30340;&#23545;&#25968;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#35745;&#31639;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#26469;&#35828;&#26126;&#36825;&#31181;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study differentially private empirical risk minimization (DP-ERM). It has been shown that the worst-case utility of DP-ERM reduces polynomially as the dimension increases. This is a major obstacle to privately learning large machine learning models. In high dimension, it is common for some model's parameters to carry more information than others. To exploit this, we propose a differentially private greedy coordinate descent (DP-GCD) algorithm. At each iteration, DP-GCD privately performs a coordinate-wise gradient step along the gradients' (approximately) greatest entry. We show theoretically that DP-GCD can achieve a logarithmic dependence on the dimension for a wide range of problems by naturally exploiting their structural properties (such as quasi-sparse solutions). We illustrate this behavior numerically, both on synthetic and real datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#22240;&#26524;&#32422;&#26463;&#30340;&#20998;&#24067;&#40065;&#26834;&#39118;&#38505;&#35780;&#20272;&#26041;&#27861;&#65292;&#24182;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#27979;&#35797;&#20989;&#25968;&#12290;&#22312;&#32467;&#26500;&#20449;&#24687;&#26377;&#38480;&#21046;&#26102;&#65292;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.10571</link><description>&lt;p&gt;
&#20855;&#26377;&#22240;&#26524;&#32422;&#26463;&#21644;&#32467;&#26500;&#20449;&#24687;&#30340;&#20998;&#24067;&#40065;&#26834;&#39118;&#38505;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Distributionally robust risk evaluation with a causality constraint and structural information. (arXiv:2203.10571v3 [q-fin.MF] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.10571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#22240;&#26524;&#32422;&#26463;&#30340;&#20998;&#24067;&#40065;&#26834;&#39118;&#38505;&#35780;&#20272;&#26041;&#27861;&#65292;&#24182;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#27979;&#35797;&#20989;&#25968;&#12290;&#22312;&#32467;&#26500;&#20449;&#24687;&#26377;&#38480;&#21046;&#26102;&#65292;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26102;&#38388;&#25968;&#25454;&#30340;&#26399;&#26395;&#20989;&#25968;&#20540;&#30340;&#20998;&#24067;&#40065;&#26834;&#35780;&#20272;&#12290;&#19968;&#32452;&#22791;&#36873;&#24230;&#37327;&#36890;&#36807;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#34920;&#24449;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24378;&#23545;&#20598;&#24615;&#65292;&#24182;&#23558;&#22240;&#26524;&#32422;&#26463;&#37325;&#26500;&#20026;&#26080;&#38480;&#32500;&#27979;&#35797;&#20989;&#25968;&#31354;&#38388;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#27979;&#35797;&#20989;&#25968;&#65292;&#24182;&#29992;Rademacher&#22797;&#26434;&#24230;&#35777;&#26126;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#24403;&#32467;&#26500;&#20449;&#24687;&#21487;&#29992;&#20110;&#36827;&#19968;&#27493;&#38480;&#21046;&#27169;&#31946;&#38598;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20598;&#24418;&#24335;&#24182;&#25552;&#20379;&#39640;&#25928;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;&#23545;&#23454;&#29616;&#27874;&#21160;&#29575;&#21644;&#32929;&#25351;&#30340;&#32463;&#39564;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20026;&#32463;&#20856;&#26368;&#20248;&#20256;&#36755;&#20844;&#24335;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies distributionally robust evaluation of expected function values over temporal data. A set of alternative measures is characterized by the causal optimal transport. We prove the strong duality and recast the causality constraint as minimization over an infinite-dimensional test function space. We approximate test functions by neural networks and prove the sample complexity with Rademacher complexity. Moreover, when structural information is available to further restrict the ambiguity set, we prove the dual formulation and provide efficient optimization methods. Empirical analysis of realized volatility and stock indices demonstrates that our framework offers an attractive alternative to the classic optimal transport formulation.
&lt;/p&gt;</description></item><item><title>&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30740;&#31350;&#21457;&#29616;&#21307;&#30103;&#34917;&#21161;&#23545;&#24613;&#35786;&#21033;&#29992;&#29575;&#20855;&#26377;&#24322;&#36136;&#24615;&#24433;&#21709;&#65292;&#21482;&#26377;&#23569;&#25968;&#32676;&#20307;&#39537;&#21160;&#20102;&#25972;&#20307;&#25928;&#24212;&#65292;&#24378;&#24230;&#36793;&#38469;&#25928;&#24212;&#26159;&#20854;&#37325;&#35201;&#39537;&#21160;&#22240;&#32032;&#65292;&#36866;&#24403;&#30830;&#23450;&#20248;&#20808;&#32676;&#20307;&#23558;&#26377;&#25928;&#25511;&#21046;&#24613;&#35786;&#21033;&#29992;&#29575;&#12290;</title><link>http://arxiv.org/abs/2201.07072</link><description>&lt;p&gt;
&#12298;&#35841;&#22686;&#21152;&#20102;&#32039;&#24613;&#35786;&#25152;&#30340;&#20351;&#29992;&#29575;&#65311;&#26469;&#33258;&#20420;&#21202;&#20872;&#21307;&#30103;&#20445;&#38505;&#23454;&#39564;&#30340;&#26032;&#35265;&#35299;&#12299;
&lt;/p&gt;
&lt;p&gt;
Who Increases Emergency Department Use? New Insights from the Oregon Health Insurance Experiment. (arXiv:2201.07072v4 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.07072
&lt;/p&gt;
&lt;p&gt;
&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30740;&#31350;&#21457;&#29616;&#21307;&#30103;&#34917;&#21161;&#23545;&#24613;&#35786;&#21033;&#29992;&#29575;&#20855;&#26377;&#24322;&#36136;&#24615;&#24433;&#21709;&#65292;&#21482;&#26377;&#23569;&#25968;&#32676;&#20307;&#39537;&#21160;&#20102;&#25972;&#20307;&#25928;&#24212;&#65292;&#24378;&#24230;&#36793;&#38469;&#25928;&#24212;&#26159;&#20854;&#37325;&#35201;&#39537;&#21160;&#22240;&#32032;&#65292;&#36866;&#24403;&#30830;&#23450;&#20248;&#20808;&#32676;&#20307;&#23558;&#26377;&#25928;&#25511;&#21046;&#24613;&#35786;&#21033;&#29992;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#39033;&#26032;&#35265;&#35299;&#65292;&#38024;&#23545;&#21307;&#30103;&#20445;&#38505;&#23454;&#39564;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#32467;&#26524;&#65306;&#21307;&#30103;&#34917;&#21161;&#22686;&#21152;&#20102;&#32039;&#24613;&#35786;&#25152;&#30340;&#20351;&#29992;&#29575;&#12290;&#25105;&#20204;&#21457;&#29616;&#21307;&#30103;&#20445;&#38505;&#23545;&#32039;&#24613;&#35786;&#25152;&#20351;&#29992;&#29575;&#30340;&#24433;&#21709;&#23384;&#22312;&#26377;&#24847;&#20041;&#30340;&#24322;&#36136;&#24615;&#12290;&#20010;&#24615;&#21270;&#30340;&#27835;&#30103;&#25928;&#24212;&#20998;&#24067;&#21253;&#25324;&#20102;&#19968;&#31995;&#21015;&#27491;&#36127;&#20540;&#65292;&#34920;&#26126;&#24179;&#22343;&#25928;&#24212;&#25513;&#30422;&#20102;&#30456;&#24403;&#22823;&#30340;&#24322;&#36136;&#24615;&#12290;&#19968;&#20010;&#26497;&#23567;&#30340;&#32676;&#20307;&#65288;&#32422;14%&#30340;&#21442;&#19982;&#32773;&#65289;&#22312;&#27835;&#30103;&#25928;&#24212;&#20998;&#24067;&#30340;&#21491;&#23614;&#39537;&#21160;&#20102;&#25972;&#20307;&#25928;&#24212;&#12290;&#25105;&#20204;&#26681;&#25454;&#20154;&#21475;&#32479;&#35745;&#23398;&#21644;&#20197;&#24448;&#30340;&#21033;&#29992;&#24773;&#20917;&#30830;&#23450;&#20102;&#20855;&#26377;&#32463;&#27982;&#37325;&#35201;&#24615;&#30340;&#22686;&#21152;&#24613;&#35786;&#20351;&#29992;&#30340;&#20248;&#20808;&#32676;&#20307;&#12290;&#24378;&#24230;&#36793;&#38469;&#25928;&#24212;&#26159;&#24613;&#35786;&#21033;&#29992;&#29575;&#22686;&#21152;&#30340;&#37325;&#35201;&#39537;&#21160;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide new insights regarding the headline result that Medicaid increased emergency department (ED) use from the Oregon experiment. We find meaningful heterogeneous impacts of Medicaid on ED use using causal machine learning methods. The individualized treatment effect distribution includes a wide range of negative and positive values, suggesting the average effect masks substantial heterogeneity. A small group-about 14% of participants-in the right tail of the distribution drives the overall effect. We identify priority groups with economically significant increases in ED usage based on demographics and previous utilization. Intensive margin effects are an important driver of increases in ED utilization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#24179;&#26041;&#26681;&#36895;&#24230;&#20989;&#25968;&#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#21644;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#27604;&#36739;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#29289;&#20307;&#24418;&#29366;&#24046;&#24322;&#35745;&#31639;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2110.08693</link><description>&lt;p&gt;
&#23398;&#20064;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#30340;&#20960;&#20309;&#21644;&#25299;&#25169;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Generative Models of the Geometry and Topology of Tree-like 3D Objects. (arXiv:2110.08693v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.08693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#24179;&#26041;&#26681;&#36895;&#24230;&#20989;&#25968;&#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#21644;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#27604;&#36739;&#26641;&#29366;&#19977;&#32500;&#29289;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#29289;&#20307;&#24418;&#29366;&#24046;&#24322;&#35745;&#31639;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#20998;&#26512;&#23637;&#29616;&#20986;&#22797;&#26434;&#20960;&#20309;&#21644;&#25299;&#25169;&#21464;&#21270;&#30340;&#35814;&#32454;&#19977;&#32500;&#29983;&#29289;&#29289;&#20307;&#65292;&#20363;&#22914;&#31070;&#32463;&#20803;&#21644;&#26893;&#29289;&#26641;&#65311;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#65292;&#29992;&#20110;&#34920;&#31034;&#12289;&#27604;&#36739;&#21644;&#35745;&#31639;&#36825;&#20123;&#26641;&#29366;&#19977;&#32500;&#23545;&#35937;&#30340;&#24418;&#29366;&#24046;&#24322;&#65292;&#24182;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#26469;&#37327;&#21270;&#23558;&#19968;&#20010;&#26641;&#29366;&#29289;&#20307;&#21464;&#24418;&#20026;&#21478;&#19968;&#20010;&#29289;&#20307;&#25152;&#38656;&#30340;&#24367;&#26354;&#12289;&#25289;&#20280;&#21644;&#20998;&#25903;&#28369;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can one analyze detailed 3D biological objects, such as neurons and botanical trees, that exhibit complex geometrical and topological variation? In this paper, we develop a novel mathematical framework for representing, comparing, and computing geodesic deformations between the shapes of such tree-like 3D objects. A hierarchical organization of subtrees characterizes these objects -- each subtree has the main branch with some side branches attached -- and one needs to match these structures across objects for meaningful comparisons. We propose a novel representation that extends the Square-Root Velocity Function (SRVF), initially developed for Euclidean curves, to tree-shaped 3D objects. We then define a new metric that quantifies the bending, stretching, and branch sliding needed to deform one tree-shaped object into the other. Compared to the current metrics, such as the Quotient Euclidean Distance (QED) and the Tree Edit Distance (TED), the proposed representation and metric cap
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#32447;&#24615;&#21306;&#22495;&#30340;&#33258;&#36866;&#24212;&#25554;&#20540;&#26041;&#27861;&#25512;&#24191;&#21040;&#27425;&#32447;&#24615;&#21306;&#22495;&#65292;&#24314;&#31435;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#24402;&#19968;&#21270;&#20114;&#20449;&#24687;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#34920;&#36798;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#36817;&#20284;&#20449;&#24687;&#20256;&#36882;&#31639;&#27861;&#20197;&#25509;&#36817;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#22522;&#26412;&#26497;&#38480;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2101.11156</link><description>&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#22522;&#26412;&#26497;&#38480;&#21644;&#31639;&#27861;&#19982;&#27425;&#32447;&#24615;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fundamental limits and algorithms for sparse linear regression with sublinear sparsity. (arXiv:2101.11156v6 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2101.11156
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#32447;&#24615;&#21306;&#22495;&#30340;&#33258;&#36866;&#24212;&#25554;&#20540;&#26041;&#27861;&#25512;&#24191;&#21040;&#27425;&#32447;&#24615;&#21306;&#22495;&#65292;&#24314;&#31435;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#24402;&#19968;&#21270;&#20114;&#20449;&#24687;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#34920;&#36798;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#36817;&#20284;&#20449;&#24687;&#20256;&#36882;&#31639;&#27861;&#20197;&#25509;&#36817;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#22522;&#26412;&#26497;&#38480;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#27425;&#32447;&#24615;&#31232;&#30095;&#24615;&#21306;&#38388;&#24314;&#31435;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#24402;&#19968;&#21270;&#20114;&#20449;&#24687;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#65288;MMSE&#65289;&#30340;&#31934;&#30830;&#28176;&#36817;&#34920;&#36798;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#32447;&#24615;&#21306;&#22495;&#30340;&#33258;&#36866;&#24212;&#25554;&#20540;&#26041;&#27861;&#25512;&#24191;&#21040;&#27425;&#32447;&#24615;&#21306;&#22495;&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30528;&#21517;&#30340;&#36817;&#20284;&#20449;&#24687;&#20256;&#36882;&#31639;&#27861;&#20197;&#25509;&#36817;MMSE&#22522;&#26412;&#26497;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#23545;&#20854;&#29366;&#24577;&#28436;&#21270;&#36827;&#34892;&#20102;&#20005;&#26684;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#31232;&#30095;&#20449;&#21495;&#65292;&#22797;&#21046;&#21644;&#33258;&#36866;&#24212;&#25554;&#20540;&#26041;&#27861;&#20013;&#20449;&#21495;&#32500;&#25968;&#21644;&#35266;&#27979;&#20010;&#25968;&#20043;&#38388;&#30340;&#20256;&#32479;&#32447;&#24615;&#20551;&#35774;&#26159;&#19981;&#24517;&#35201;&#30340;&#12290;&#23427;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#29616;&#26377;&#30340;&#30528;&#21517;&#30340;&#32447;&#24615;&#21306;&#22495;&#30340;AMP&#31639;&#27861;&#20462;&#25913;&#20026;&#27425;&#32447;&#24615;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish exact asymptotic expressions for the normalized mutual information and minimum mean-square-error (MMSE) of sparse linear regression in the sub-linear sparsity regime. Our result is achieved by a generalization of the adaptive interpolation method in Bayesian inference for linear regimes to sub-linear ones. A modification of the well-known approximate message passing algorithm to approach the MMSE fundamental limit is also proposed, and its state evolution is rigorously analyzed. Our results show that the traditional linear assumption between the signal dimension and number of observations in the replica and adaptive interpolation methods is not necessary for sparse signals. They also show how to modify the existing well-known AMP algorithms for linear regimes to sub-linear ones.
&lt;/p&gt;</description></item></channel></rss>