<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23376;&#32452;&#28151;&#21512;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#32676;&#20307;&#20844;&#24179;&#24615;&#12290;&#36890;&#36807;&#28155;&#21152;&#20195;&#34920;&#20302;&#27604;&#20363;&#32676;&#20307;&#30340;&#26032;&#26679;&#26412;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#25968;&#25454;&#30340;&#24179;&#34913;&#65292;&#24182;&#19988;&#21033;&#29992;&#35813;&#26041;&#27861;&#25552;&#39640;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.07110</link><description>&lt;p&gt;
&#36890;&#36807;&#23376;&#32452;&#28151;&#21512;&#23454;&#29616;&#25968;&#25454;&#22686;&#24378;&#20197;&#25552;&#39640;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Data Augmentation via Subgroup Mixup for Improving Fairness. (arXiv:2309.07110v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07110
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23376;&#32452;&#28151;&#21512;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#32676;&#20307;&#20844;&#24179;&#24615;&#12290;&#36890;&#36807;&#28155;&#21152;&#20195;&#34920;&#20302;&#27604;&#20363;&#32676;&#20307;&#30340;&#26032;&#26679;&#26412;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#25968;&#25454;&#30340;&#24179;&#34913;&#65292;&#24182;&#19988;&#21033;&#29992;&#35813;&#26041;&#27861;&#25552;&#39640;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#23376;&#32452;&#38388;&#28151;&#21512;&#26469;&#22686;&#24378;&#25968;&#25454;&#20197;&#25552;&#39640;&#32676;&#20307;&#20844;&#24179;&#24615;&#12290;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#24212;&#29992;&#37117;&#23384;&#22312;&#30528;&#26576;&#20123;&#32676;&#20307;&#30340;&#20559;&#35265;&#65292;&#36825;&#26159;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#30340;&#19981;&#24179;&#34913;&#25110;&#21453;&#26144;&#20102;&#31038;&#20250;&#20559;&#35265;&#12290;&#21463;&#21040;mixup&#22312;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#26041;&#38754;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#23545;&#25968;&#25454;&#36827;&#34892;&#20004;&#20004;&#28151;&#21512;&#30340;&#26041;&#26696;&#65292;&#20197;&#22686;&#24378;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#40723;&#21169;&#20026;&#25152;&#26377;&#23376;&#32452;&#23454;&#29616;&#20844;&#24179;&#21644;&#20934;&#30830;&#30340;&#20915;&#31574;&#36793;&#30028;&#12290;&#38024;&#23545;&#32676;&#20307;&#20844;&#24179;&#24615;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#20801;&#35768;&#25105;&#20204;&#28155;&#21152;&#26032;&#30340;&#20195;&#34920;&#20302;&#27604;&#20363;&#32676;&#20307;&#30340;&#26679;&#26412;&#65292;&#20197;&#24179;&#34913;&#20122;&#32676;&#20307;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#21033;&#29992;mixup&#30340;&#27867;&#21270;&#33021;&#21147;&#26469;&#25552;&#39640;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#28151;&#21512;&#26041;&#27861;&#19982;&#29616;&#26377;&#30340;&#25968;&#25454;&#22686;&#24378;&#21644;&#20559;&#35265;&#32531;&#35299;&#26041;&#27861;&#22312;&#21512;&#25104;&#27169;&#25311;&#21644;&#23454;&#38469;&#22522;&#20934;&#20844;&#24179;&#20998;&#31867;&#25968;&#25454;&#19978;&#36827;&#34892;&#27604;&#36739;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#33021;&#22815;&#23454;&#29616;&#20844;&#24179;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#22312;&#20934;&#30830;&#24615;&#19978;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#29978;&#33267;&#26377;&#25152;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose data augmentation via pairwise mixup across subgroups to improve group fairness. Many real-world applications of machine learning systems exhibit biases across certain groups due to under-representation or training data that reflects societal biases. Inspired by the successes of mixup for improving classification performance, we develop a pairwise mixup scheme to augment training data and encourage fair and accurate decision boundaries for all subgroups. Data augmentation for group fairness allows us to add new samples of underrepresented groups to balance subpopulations. Furthermore, our method allows us to use the generalization ability of mixup to improve both fairness and accuracy. We compare our proposed mixup to existing data augmentation and bias mitigation approaches on both synthetic simulations and real-world benchmark fair classification data, demonstrating that we are able to achieve fair outcomes with robust if not improved accuracy.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#29289;&#29702;&#20449;&#24687;&#19982;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#26029;&#32463;&#20856;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#20013;&#22810;&#31890;&#23376;&#31995;&#32479;&#30340;&#22806;&#37096;&#21183;&#33021;&#12290;&#35813;&#26694;&#26550;&#22312;&#20855;&#26377;&#25490;&#38500;&#20307;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#21463;&#38480;&#20960;&#20309;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2309.07065</link><description>&lt;p&gt;
&#32463;&#20856;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#20013;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22806;&#37096;&#21183;&#33021;
&lt;/p&gt;
&lt;p&gt;
Physics-informed Bayesian inference of external potentials in classical density-functional theory. (arXiv:2309.07065v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07065
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#29289;&#29702;&#20449;&#24687;&#19982;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#26029;&#32463;&#20856;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#20013;&#22810;&#31890;&#23376;&#31995;&#32479;&#30340;&#22806;&#37096;&#21183;&#33021;&#12290;&#35813;&#26694;&#26550;&#22312;&#20855;&#26377;&#25490;&#38500;&#20307;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#21463;&#38480;&#20960;&#20309;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#32479;&#35745;&#21147;&#23398;&#39046;&#22495;&#20013;&#24050;&#32463;&#21462;&#24471;&#20102;&#24555;&#36895;&#21457;&#23637;&#12290;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21560;&#24341;&#20102;&#32463;&#20856;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65288;DFT&#65289;&#31038;&#21306;&#30340;&#27880;&#24847;&#65292;&#22240;&#20026;&#23427;&#20204;&#33021;&#22815;&#21457;&#29616;&#33258;&#30001;&#33021;&#27867;&#20989;&#65292;&#20197;&#30830;&#23450;&#22810;&#31890;&#23376;&#31995;&#32479;&#30340;&#24179;&#34913;&#23494;&#24230;&#20998;&#24067;&#12290;&#22312;DFT&#20013;&#65292;&#22806;&#37096;&#21183;&#33021;&#32771;&#34385;&#20102;&#22810;&#31890;&#23376;&#31995;&#32479;&#19982;&#22806;&#37096;&#22330;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#24433;&#21709;&#23494;&#24230;&#20998;&#24067;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#26029;&#20316;&#29992;&#20110;&#22810;&#31890;&#23376;&#31995;&#32479;&#30340;&#22806;&#37096;&#21183;&#33021;&#12290;&#25105;&#20204;&#23558;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#19982;&#32463;&#20856;&#30340;DFT&#24037;&#20855;&#32467;&#21512;&#36215;&#26469;&#65292;&#37325;&#26500;&#22806;&#37096;&#21183;&#33021;&#65292;&#24471;&#21040;&#20855;&#26377;&#20869;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#22806;&#37096;&#21183;&#33021;&#30340;&#27010;&#29575;&#25551;&#36848;&#24418;&#24335;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20197;&#22312;&#21463;&#38480;&#20960;&#20309;&#20013;&#20855;&#26377;&#25490;&#38500;&#20307;&#31215;&#30456;&#20114;&#20316;&#29992;&#30340;&#24040;&#27491;&#21017;&#19968;&#32500;&#31890;&#23376;&#38598;&#21512;&#20026;&#20363;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
The swift progression of machine learning (ML) have not gone unnoticed in the realm of statistical mechanics. ML techniques have attracted attention by the classical density-functional theory (DFT) community, as they enable discovery of free-energy functionals to determine the equilibrium-density profile of a many-particle system. Within DFT, the external potential accounts for the interaction of the many-particle system with an external field, thus, affecting the density distribution. In this context, we introduce a statistical-learning framework to infer the external potential exerted on a many-particle system. We combine a Bayesian inference approach with the classical DFT apparatus to reconstruct the external potential, yielding a probabilistic description of the external potential functional form with inherent uncertainty quantification. Our framework is exemplified with a grand-canonical one-dimensional particle ensemble with excluded volume interactions in a confined geometry. T
&lt;/p&gt;</description></item><item><title>&#26080;&#30417;&#30563;&#30340;&#23545;&#27604;&#19968;&#33268;&#25490;&#24207;&#19982;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#21463;&#36923;&#36753;&#32422;&#26463;&#24341;&#23548;&#30340;&#25506;&#27979;&#27169;&#22411;&#65292;&#23454;&#29616;&#22312;&#22810;&#20010;&#35821;&#21477;&#20013;&#22987;&#32456;&#26144;&#23556;&#21040;&#23545;&#27604;&#30340;&#30495;-&#20551;&#26497;&#28857;&#30340;&#25490;&#24207;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2309.06991</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#23545;&#27604;&#19968;&#33268;&#25490;&#24207;&#19982;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Contrast-Consistent Ranking with Language Models. (arXiv:2309.06991v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06991
&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#23545;&#27604;&#19968;&#33268;&#25490;&#24207;&#19982;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#21463;&#36923;&#36753;&#32422;&#26463;&#24341;&#23548;&#30340;&#25506;&#27979;&#27169;&#22411;&#65292;&#23454;&#29616;&#22312;&#22810;&#20010;&#35821;&#21477;&#20013;&#22987;&#32456;&#26144;&#23556;&#21040;&#23545;&#27604;&#30340;&#30495;-&#20551;&#26497;&#28857;&#30340;&#25490;&#24207;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#21253;&#21547;&#22522;&#20110;&#25490;&#24207;&#30340;&#30693;&#35782;&#65292;&#24182;&#19988;&#26159;&#22788;&#29702;&#19978;&#19979;&#25991;&#25490;&#21517;&#20219;&#21153;&#30340;&#24378;&#22823;&#35299;&#20915;&#32773;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20851;&#27880;&#20110;&#37197;&#23545;&#12289;&#28857;&#23545;&#21644;&#21015;&#34920;&#25552;&#31034;&#25216;&#26415;&#65292;&#20197;&#25581;&#31034;&#35821;&#35328;&#27169;&#22411;&#30340;&#25490;&#24207;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#21363;&#20351;&#22312;&#20180;&#32454;&#26657;&#20934;&#21644;&#38480;&#21046;&#35299;&#30721;&#30340;&#24773;&#20917;&#19979;&#65292;&#22522;&#20110;&#25552;&#31034;&#30340;&#25216;&#26415;&#22312;&#20135;&#29983;&#30340;&#25490;&#24207;&#20013;&#20063;&#19981;&#24635;&#26159;&#33258;&#27965;&#30340;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#25506;&#32034;&#19968;&#31181;&#21463;&#26080;&#30417;&#30563;&#25506;&#27979;&#26041;&#27861;Contrast-Consistent Search&#65288;CCS&#65289;&#21551;&#21457;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#36825;&#20010;&#24819;&#27861;&#26159;&#35757;&#32451;&#19968;&#20010;&#21463;&#36923;&#36753;&#32422;&#26463;&#24341;&#23548;&#30340;&#25506;&#27979;&#27169;&#22411;&#65306;&#27169;&#22411;&#23545;&#19968;&#20010;&#35821;&#21477;&#21450;&#20854;&#21542;&#23450;&#30340;&#34920;&#31034;&#24517;&#39035;&#22312;&#22810;&#20010;&#35821;&#21477;&#20013;&#22987;&#32456;&#26144;&#23556;&#21040;&#23545;&#27604;&#30340;&#30495;-&#20551;&#26497;&#28857;&#12290;&#25105;&#20204;&#20551;&#35774;&#31867;&#20284;&#30340;&#32422;&#26463;&#36866;&#29992;&#20110;&#25152;&#26377;&#39033;&#36890;&#36807;&#19968;&#33268;&#24615;&#23545;&#30456;&#20851;&#25490;&#24207;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks. For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank reviews by sentiment. Recent work focuses on pairwise, pointwise, and listwise prompting techniques to elicit a language model's ranking knowledge. However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce. This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS). The idea is to train a probing model guided by a logical constraint: a model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements. We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent pair
&lt;/p&gt;</description></item><item><title>CARE&#26041;&#27861;&#36890;&#36807;&#31934;&#30830;&#25351;&#23450;&#32452;&#25104;&#25968;&#25454;&#30340;&#31934;&#30830;&#30697;&#38453;&#65292;&#24182;&#21033;&#29992;&#20854;&#19982;&#22522;&#30784;&#30697;&#38453;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#31232;&#30095;&#22522;&#30784;&#30697;&#38453;&#30340;&#32452;&#25104;&#25968;&#25454;&#20272;&#35745;&#26041;&#27861;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#36275;&#22815;&#39640;&#30340;&#32500;&#24230;&#19979;&#65292;CARE&#20272;&#35745;&#22120;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#39118;&#38505;&#30340;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.06985</link><description>&lt;p&gt;
CARE: &#22823;&#35268;&#27169;&#31934;&#30830;&#30697;&#38453;&#20272;&#35745;&#29992;&#20110;&#32452;&#25104;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
CARE: Large Precision Matrix Estimation for Compositional Data. (arXiv:2309.06985v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06985
&lt;/p&gt;
&lt;p&gt;
CARE&#26041;&#27861;&#36890;&#36807;&#31934;&#30830;&#25351;&#23450;&#32452;&#25104;&#25968;&#25454;&#30340;&#31934;&#30830;&#30697;&#38453;&#65292;&#24182;&#21033;&#29992;&#20854;&#19982;&#22522;&#30784;&#30697;&#38453;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#31232;&#30095;&#22522;&#30784;&#30697;&#38453;&#30340;&#32452;&#25104;&#25968;&#25454;&#20272;&#35745;&#26041;&#27861;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#36275;&#22815;&#39640;&#30340;&#32500;&#24230;&#19979;&#65292;CARE&#20272;&#35745;&#22120;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#39118;&#38505;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#32452;&#25104;&#25968;&#25454;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#12290;&#31616;&#21333;&#24418;&#24335;&#30340;&#32422;&#26463;&#23545;&#20110;&#25512;&#26029;&#32452;&#25104;&#25968;&#25454;&#20013;&#30340;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#65292;&#21363;&#22823;&#35268;&#27169;&#31934;&#30830;&#30697;&#38453;&#25152;&#32534;&#30721;&#30340;&#32452;&#20998;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24102;&#26469;&#20102;&#22266;&#26377;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32452;&#25104;&#31934;&#30830;&#30697;&#38453;&#30340;&#31934;&#30830;&#23450;&#20041;&#65292;&#24182;&#23558;&#20854;&#19982;&#20854;&#22522;&#30784;&#23545;&#24212;&#29289;&#32852;&#31995;&#36215;&#26469;&#65292;&#22312;&#36866;&#24403;&#30340;&#31232;&#30095;&#24615;&#20551;&#35774;&#19979;&#24471;&#21040;&#28176;&#36817;&#21487;&#36776;&#35748;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#36825;&#31181;&#32852;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#21512;&#20272;&#35745;&#31232;&#30095;&#22522;&#30784;&#31934;&#30830;&#30697;&#38453;&#30340;&#32452;&#25104;&#36866;&#24212;&#27491;&#21017;&#21270;&#20272;&#35745;&#65288;CARE&#65289;&#26041;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#25903;&#25345;&#24674;&#22797;&#21644;&#25968;&#25454;&#39537;&#21160;&#21442;&#25968;&#35843;&#25972;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#25581;&#31034;&#20102;&#37492;&#23450;&#21644;&#20272;&#35745;&#20043;&#38388;&#30340;&#26377;&#36259;&#26435;&#34913;&#65292;&#20174;&#32780;&#31361;&#26174;&#20102;&#32500;&#24230;&#22312;&#32452;&#25104;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#20248;&#21183;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#36275;&#22815;&#39640;&#30340;&#32500;&#24230;&#19979;&#65292;CARE&#20272;&#35745;&#22120;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#39118;&#38505;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional compositional data are prevalent in many applications. The simplex constraint poses intrinsic challenges to inferring the conditional dependence relationships among the components forming a composition, as encoded by a large precision matrix. We introduce a precise specification of the compositional precision matrix and relate it to its basis counterpart, which is shown to be asymptotically identifiable under suitable sparsity assumptions. By exploiting this connection, we propose a composition adaptive regularized estimation (CARE) method for estimating the sparse basis precision matrix. We derive rates of convergence for the estimator and provide theoretical guarantees on support recovery and data-driven parameter tuning. Our theory reveals an intriguing trade-off between identification and estimation, thereby highlighting the blessing of dimensionality in compositional data analysis. In particular, in sufficiently high dimensions, the CARE estimator achieves minimax
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35780;&#20272;&#20102;&#38543;&#26426;&#26862;&#26519;&#20013;&#36229;&#21442;&#25968;&#23545;&#21464;&#37327;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#22312;&#39640;&#32500;&#32452;&#23398;&#30740;&#31350;&#20013;&#65292;&#36866;&#24403;&#35774;&#32622;RF&#36229;&#21442;&#25968;&#23545;&#36873;&#25321;&#37325;&#35201;&#21464;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2309.06943</link><description>&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#20013;&#36229;&#21442;&#25968;&#23545;&#21464;&#37327;&#36873;&#25321;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Effect of hyperparameters on variable selection in random forests. (arXiv:2309.06943v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06943
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35780;&#20272;&#20102;&#38543;&#26426;&#26862;&#26519;&#20013;&#36229;&#21442;&#25968;&#23545;&#21464;&#37327;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#22312;&#39640;&#32500;&#32452;&#23398;&#30740;&#31350;&#20013;&#65292;&#36866;&#24403;&#35774;&#32622;RF&#36229;&#21442;&#25968;&#23545;&#36873;&#25321;&#37325;&#35201;&#21464;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#65288;RF&#65289;&#22312;&#39640;&#32500;&#32452;&#23398;&#30740;&#31350;&#20013;&#36866;&#29992;&#20110;&#39044;&#27979;&#24314;&#27169;&#21644;&#21464;&#37327;&#36873;&#25321;&#12290;&#20808;&#21069;&#30740;&#31350;&#20102;RF&#31639;&#27861;&#30340;&#36229;&#21442;&#25968;&#23545;&#39044;&#27979;&#24615;&#33021;&#21644;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#30340;&#24433;&#21709;&#65292;&#20294;&#36229;&#21442;&#25968;&#23545;&#22522;&#20110;RF&#30340;&#21464;&#37327;&#36873;&#25321;&#30340;&#24433;&#21709;&#23578;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#21033;&#29992;&#29702;&#35770;&#20998;&#24067;&#21644;&#23454;&#35777;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#36827;&#34892;&#20102;&#20004;&#20010;&#27169;&#25311;&#30740;&#31350;&#65292;&#35780;&#20272;&#20102;Vita&#21644;Boruta&#21464;&#37327;&#36873;&#25321; procedures &#22312;&#36873;&#25321;&#37325;&#35201;&#21464;&#37327;&#65288;&#25935;&#24863;&#24615;&#65289;&#30340;&#21516;&#26102;&#25511;&#21046;&#34394;&#35686;&#29575;&#65288;FDR&#65289;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#65292;&#35201;&#27604;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#25277;&#21462;&#31574;&#30053;&#21644;&#26368;&#23567;&#32456;&#31471;&#33410;&#28857;&#22823;&#23567;&#26356;&#33021;&#24433;&#21709;&#36873;&#25321; procedures&#12290;RF&#36229;&#21442;&#25968;&#30340;&#21512;&#36866;&#35774;&#32622;&#21462;&#20915;&#20110;
&lt;/p&gt;
&lt;p&gt;
Random forests (RFs) are well suited for prediction modeling and variable selection in high-dimensional omics studies. The effect of hyperparameters of the RF algorithm on prediction performance and variable importance estimation have previously been investigated. However, how hyperparameters impact RF-based variable selection remains unclear. We evaluate the effects on the Vita and the Boruta variable selection procedures based on two simulation studies utilizing theoretical distributions and empirical gene expression data. We assess the ability of the procedures to select important variables (sensitivity) while controlling the false discovery rate (FDR). Our results show that the proportion of splitting candidate variables (mtry.prop) and the sample fraction (sample.fraction) for the training dataset influence the selection procedures more than the drawing strategy of the training datasets and the minimal terminal node size. A suitable setting of the RF hyperparameters depends on the
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#25605;&#25292;&#25705;&#25830;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#23792;&#20540;&#28201;&#24230;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38598;&#25104;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20013;&#34920;&#29616;&#20986;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#26368;&#20339;&#30340;SML&#26041;&#27861;&#20026;&#26799;&#24230;&#25552;&#21319;&#27861;&#65292;&#26368;&#20302;&#30340;&#22343;&#26041;&#35823;&#24046;&#20026;165.78&#12290;</title><link>http://arxiv.org/abs/2309.06838</link><description>&lt;p&gt;
&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#39044;&#27979;&#38109;&#21512;&#37329;&#25605;&#25292;&#25705;&#25830;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#23792;&#20540;&#28201;&#24230;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Supervised Machine Learning and Physics based Machine Learning approach for prediction of peak temperature distribution in Additive Friction Stir Deposition of Aluminium Alloy. (arXiv:2309.06838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#25605;&#25292;&#25705;&#25830;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#23792;&#20540;&#28201;&#24230;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38598;&#25104;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20013;&#34920;&#29616;&#20986;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#26368;&#20339;&#30340;SML&#26041;&#27861;&#20026;&#26799;&#24230;&#25552;&#21319;&#27861;&#65292;&#26368;&#20302;&#30340;&#22343;&#26041;&#35823;&#24046;&#20026;165.78&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22686;&#26448;&#25605;&#25292;&#25705;&#25830;&#27785;&#31215;&#65288;AFSD&#65289;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#22266;&#24577;&#22686;&#26448;&#21046;&#36896;&#25216;&#26415;&#65292;&#23427;&#35299;&#20915;&#20102;&#20256;&#32479;&#31881;&#26411;&#24202;&#29076;&#28860;&#21644;&#23450;&#21521;&#33021;&#37327;&#27785;&#31215;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#23380;&#38553;&#29575;&#12289;&#24320;&#35010;&#21644;&#24615;&#33021;&#21508;&#21521;&#24322;&#24615;&#31561;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;AFSD&#20013;&#30340;&#24037;&#33402;&#21442;&#25968;&#12289;&#28909;&#37327;&#20998;&#24067;&#21644;&#24471;&#21040;&#30340;&#26174;&#24494;&#32467;&#26500;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20173;&#28982;&#19981;&#22815;&#28165;&#26970;&#65292;&#36825;&#22952;&#30861;&#20102;&#24615;&#33021;&#30340;&#24037;&#33402;&#20248;&#21270;&#12290;&#26412;&#30740;&#31350;&#36816;&#29992;&#20102;&#19968;&#31181;&#20808;&#36827;&#30340;&#26694;&#26550;&#65292;&#23558;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65288;SML&#65289;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#30456;&#32467;&#21512;&#65292;&#20197;&#20174;&#24037;&#33402;&#21442;&#25968;&#39044;&#27979;AFSD&#20013;&#30340;&#23792;&#20540;&#28201;&#24230;&#20998;&#24067;&#12290;&#23545;&#20110;SML&#24314;&#27169;&#65292;&#20351;&#29992;&#20102;&#20843;&#31181;&#22238;&#24402;&#31639;&#27861;&#65292;&#32780;&#23545;&#20110;PINNs&#65292;&#20351;&#29992;&#20102;&#36816;&#36755;&#12289;&#27874;&#20256;&#25773;&#12289;&#28909;&#20256;&#23548;&#21644;&#37327;&#23376;&#21147;&#23398;&#30340;&#25511;&#21046;&#26041;&#31243;&#12290;&#22312;&#22810;&#20010;&#32479;&#35745;&#25351;&#26631;&#19978;&#65292;&#38598;&#25104;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#34920;&#29616;&#20986;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#26799;&#24230;&#25552;&#21319;&#27861;&#26159;&#26368;&#20339;&#30340;SML&#26041;&#27861;&#65292;&#26368;&#20302;&#30340;&#22343;&#26041;&#35823;&#24046;&#20026;165.78&#12290;
&lt;/p&gt;
&lt;p&gt;
Additive friction stir deposition (AFSD) is a novel solid-state additive manufacturing technique that circumvents issues of porosity, cracking, and properties anisotropy that plague traditional powder bed fusion and directed energy deposition approaches. However, correlations between process parameters, thermal profiles, and resulting microstructure in AFSD remain poorly understood. This hinders process optimization for properties. This work employs a cutting-edge framework combining supervised machine learning (SML) and physics-informed neural networks (PINNs) to predict peak temperature distribution in AFSD from process parameters. Eight regression algorithms were implemented for SML modeling, while four PINNs leveraged governing equations for transport, wave propagation, heat transfer, and quantum mechanics. Across multiple statistical measures, ensemble techniques like gradient boosting proved superior for SML, with lowest MSE of 165.78. The integrated ML approach was also applied 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#65292;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#30828;&#20214;&#22788;&#29702;&#22120;&#30340;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#21462;&#24471;&#20102;&#30495;&#23454;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.06782</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21644;&#21315;&#20806;&#32423;&#25968;&#25454;&#38598;&#29992;&#20110;&#31890;&#23376;&#27969;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable neural network models and terascale datasets for particle-flow reconstruction. (arXiv:2309.06782v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#65292;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#30828;&#20214;&#22788;&#29702;&#22120;&#30340;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#21462;&#24471;&#20102;&#30495;&#23454;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#22522;&#20110;&#39640;&#24230;&#31890;&#24230;&#25506;&#27979;&#22120;&#27169;&#25311;&#30340;&#23436;&#25972;&#20107;&#20214;&#37325;&#24314;&#65292;&#30740;&#31350;&#20102;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#31890;&#23376;&#27969;&#65288;PF&#65289;&#37325;&#24314;&#21487;&#36890;&#36807;&#36319;&#36394;&#21644;&#37327;&#33021;&#22120;&#22242;&#31751;&#25110;&#20987;&#20013;&#26469;&#26500;&#24314;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#20869;&#26680;&#30340;&#21464;&#25442;&#22120;&#65292;&#24182;&#35777;&#26126;&#20004;&#32773;&#37117;&#36991;&#20813;&#20102;&#20108;&#27425;&#20869;&#23384;&#20998;&#37197;&#21644;&#35745;&#31639;&#25104;&#26412;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#30495;&#23454;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36229;&#32423;&#35745;&#31639;&#26426;&#19978;&#36827;&#34892;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25152;&#24471;&#27169;&#22411;&#22312;&#30828;&#20214;&#22788;&#29702;&#22120;&#19978;&#20855;&#26377;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#25903;&#25345;NVIDIA, AMD&#21644;&#33521;&#29305;&#23572; Habana&#21345;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#27169;&#22411;&#21487;&#20197;&#22312;&#30001;&#36319;&#36394;&#21644;&#37327;&#33021;&#22120;&#20987;&#20013;&#32452;&#25104;&#30340;&#39640;&#31890;&#24230;&#36755;&#20837;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#33719;&#24471;&#19982;&#22522;&#20934;&#30456;&#31454;&#20105;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;&#26377;&#20851;&#22797;&#29616;&#30740;&#31350;&#30340;&#25968;&#25454;&#38598;&#21644;&#36719;&#20214;&#24050;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study scalable machine learning models for full event reconstruction in high-energy electron-positron collisions based on a highly granular detector simulation. Particle-flow (PF) reconstruction can be formulated as a supervised learning task using tracks and calorimeter clusters or hits. We compare a graph neural network and kernel-based transformer and demonstrate that both avoid quadratic memory allocation and computational cost while achieving realistic PF reconstruction. We show that hyperparameter tuning on a supercomputer significantly improves the physics performance of the models. We also demonstrate that the resulting model is highly portable across hardware processors, supporting Nvidia, AMD, and Intel Habana cards. Finally, we demonstrate that the model can be trained on highly granular inputs consisting of tracks and calorimeter hits, resulting in a competitive physics performance with the baseline. Datasets and software to reproduce the studies are published following 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#38750;&#21442;&#25968;&#20984;&#21270;&#28388;&#27874;&#65288;DNCF&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35745;&#31639;&#25668;&#24433;&#39046;&#22495;&#20013;&#30340;&#22270;&#20687;&#24674;&#22797;&#12290;DNCF&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#22788;&#29702;&#30340;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#23454;&#26102;&#30340;&#23545;&#25239;&#24615;&#22270;&#20687;&#20998;&#31867;&#32593;&#32476;&#38450;&#24481;&#12290;</title><link>http://arxiv.org/abs/2309.06724</link><description>&lt;p&gt;
&#28145;&#24230;&#38750;&#21442;&#25968;&#20984;&#21270;&#28388;&#27874;&#22312;&#35745;&#31639;&#25668;&#24433;&#65292;&#22270;&#20687;&#21512;&#25104;&#21644;&#23545;&#25239;&#24615;&#38450;&#24481;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense. (arXiv:2309.06724v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06724
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#38750;&#21442;&#25968;&#20984;&#21270;&#28388;&#27874;&#65288;DNCF&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35745;&#31639;&#25668;&#24433;&#39046;&#22495;&#20013;&#30340;&#22270;&#20687;&#24674;&#22797;&#12290;DNCF&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#22788;&#29702;&#30340;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#23454;&#26102;&#30340;&#23545;&#25239;&#24615;&#22270;&#20687;&#20998;&#31867;&#32593;&#32476;&#38450;&#24481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26088;&#22312;&#25552;&#20379;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#20174;&#19981;&#23436;&#32654;&#30340;&#22270;&#20687;&#20013;&#24674;&#22797;&#30495;&#23454;&#22330;&#26223;&#30340;&#35745;&#31639;&#25668;&#24433;&#65292;&#36890;&#36807;&#28145;&#24230;&#38750;&#21442;&#25968;&#20984;&#21270;&#28388;&#27874;&#65288;DNCF&#65289;&#12290;&#23427;&#30001;&#19968;&#20010;&#38750;&#21442;&#25968;&#28145;&#24230;&#32593;&#32476;&#32452;&#25104;&#65292;&#20197;&#27169;&#25311;&#22270;&#20687;&#24418;&#25104;&#32972;&#21518;&#30340;&#29289;&#29702;&#26041;&#31243;&#65292;&#22914;&#38477;&#22122;&#12289;&#36229;&#20998;&#36776;&#29575;&#12289;&#20462;&#22797;&#21644;&#38378;&#20809;&#12290;DNCF&#27809;&#26377;&#20381;&#36182;&#20110;&#35757;&#32451;&#25968;&#25454;&#30340;&#21442;&#25968;&#21270;&#65292;&#22240;&#27492;&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#22270;&#20687;&#22788;&#29702;&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36824;&#40723;&#21169;&#32593;&#32476;&#21442;&#25968;&#20026;&#38750;&#36127;&#65292;&#24182;&#22312;&#36755;&#20837;&#21644;&#21442;&#25968;&#19978;&#21019;&#24314;&#19968;&#20010;&#21452;&#20984;&#20989;&#25968;&#65292;&#36825;&#36866;&#24212;&#20110;&#36816;&#34892;&#26102;&#38388;&#19981;&#36275;&#30340;&#20108;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#30456;&#23545;&#20110;Deep Image Prior&#26377;10&#20493;&#30340;&#21152;&#36895;&#12290;&#36890;&#36807;&#36825;&#20123;&#24037;&#20855;&#65292;&#25105;&#20204;&#22312;&#23454;&#26102;&#20013;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#23545;&#25239;&#22270;&#20687;&#20998;&#31867;&#28145;&#24230;&#32593;&#32476;&#25915;&#20987;&#31639;&#27861;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We aim to provide a general framework of for computational photography that recovers the real scene from imperfect images, via the Deep Nonparametric Convexified Filtering (DNCF). It is consists of a nonparametric deep network to resemble the physical equations behind the image formation, such as denoising, super-resolution, inpainting, and flash. DNCF has no parameterization dependent on training data, therefore has a strong generalization and robustness to adversarial image manipulation. During inference, we also encourage the network parameters to be nonnegative and create a bi-convex function on the input and parameters, and this adapts to second-order optimization algorithms with insufficient running time, having 10X acceleration over Deep Image Prior. With these tools, we empirically verify its capability to defend image classification deep networks against adversary attack algorithms in real-time.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#37327;&#23376;&#25968;&#25454;&#20013;&#24515;(QDC)&#30340;&#27010;&#24565;&#65292;&#23427;&#26159;&#29616;&#26377;&#32463;&#20856;&#25968;&#25454;&#20013;&#24515;&#30340;&#37327;&#23376;&#29256;&#26412;&#65292;&#36890;&#36807;&#32467;&#21512;&#37327;&#23376;&#38543;&#26426;&#35775;&#38382;&#23384;&#20648;&#22120;(QRAM)&#21644;&#37327;&#23376;&#32593;&#32476;&#65292;QDC&#21487;&#20197;&#25552;&#20379;&#23458;&#25143;&#22312;&#25928;&#29575;&#12289;&#23433;&#20840;&#24615;&#21644;&#31934;&#24230;&#26041;&#38754;&#30340;&#26174;&#33879;&#20248;&#21183;&#65292;&#23545;&#20110;&#37327;&#23376;&#35745;&#31639;&#12289;&#36890;&#20449;&#21644;&#20256;&#24863;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#30828;&#20214;&#23454;&#29616;&#21644;&#29305;&#23450;&#24212;&#29992;&#26041;&#38754;&#30340;&#28508;&#22312;&#31185;&#23398;&#21644;&#21830;&#19994;&#26426;&#20250;&#65292;&#24182;&#23637;&#31034;&#20102;QDC&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#22823;&#25968;&#25454;&#34892;&#19994;&#31561;&#39046;&#22495;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.06641</link><description>&lt;p&gt;
&#37327;&#23376;&#25968;&#25454;&#20013;&#24515;: &#23637;&#26395;
&lt;/p&gt;
&lt;p&gt;
Quantum Data Center: Perspectives. (arXiv:2309.06641v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06641
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#37327;&#23376;&#25968;&#25454;&#20013;&#24515;(QDC)&#30340;&#27010;&#24565;&#65292;&#23427;&#26159;&#29616;&#26377;&#32463;&#20856;&#25968;&#25454;&#20013;&#24515;&#30340;&#37327;&#23376;&#29256;&#26412;&#65292;&#36890;&#36807;&#32467;&#21512;&#37327;&#23376;&#38543;&#26426;&#35775;&#38382;&#23384;&#20648;&#22120;(QRAM)&#21644;&#37327;&#23376;&#32593;&#32476;&#65292;QDC&#21487;&#20197;&#25552;&#20379;&#23458;&#25143;&#22312;&#25928;&#29575;&#12289;&#23433;&#20840;&#24615;&#21644;&#31934;&#24230;&#26041;&#38754;&#30340;&#26174;&#33879;&#20248;&#21183;&#65292;&#23545;&#20110;&#37327;&#23376;&#35745;&#31639;&#12289;&#36890;&#20449;&#21644;&#20256;&#24863;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#30828;&#20214;&#23454;&#29616;&#21644;&#29305;&#23450;&#24212;&#29992;&#26041;&#38754;&#30340;&#28508;&#22312;&#31185;&#23398;&#21644;&#21830;&#19994;&#26426;&#20250;&#65292;&#24182;&#23637;&#31034;&#20102;QDC&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#22823;&#25968;&#25454;&#34892;&#19994;&#31561;&#39046;&#22495;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#29256;&#26412;&#30340;&#25968;&#25454;&#20013;&#24515;&#21487;&#33021;&#22312;&#37327;&#23376;&#26102;&#20195;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#37327;&#23376;&#25968;&#25454;&#20013;&#24515;(QDC)&#65292;&#36825;&#26159;&#29616;&#26377;&#32463;&#20856;&#25968;&#25454;&#20013;&#24515;&#30340;&#37327;&#23376;&#29256;&#26412;&#65292;&#29305;&#21035;&#24378;&#35843;&#20102;&#37327;&#23376;&#38543;&#26426;&#35775;&#38382;&#23384;&#20648;&#22120;(QRAM)&#21644;&#37327;&#23376;&#32593;&#32476;&#30340;&#32467;&#21512;&#12290;&#25105;&#20204;&#35748;&#20026;QDC&#23558;&#20026;&#23458;&#25143;&#25552;&#20379;&#22312;&#25928;&#29575;&#12289;&#23433;&#20840;&#24615;&#21644;&#31934;&#24230;&#26041;&#38754;&#30340;&#26174;&#33879;&#22909;&#22788;&#65292;&#24182;&#23545;&#37327;&#23376;&#35745;&#31639;&#12289;&#36890;&#20449;&#21644;&#20256;&#24863;&#26041;&#38754;&#20855;&#26377;&#24110;&#21161;&#12290;&#36890;&#36807;&#30828;&#20214;&#23454;&#29616;&#21644;&#21487;&#33021;&#30340;&#29305;&#23450;&#24212;&#29992;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#19968;&#26032;&#39062;&#30740;&#31350;&#26041;&#21521;&#30340;&#28508;&#22312;&#31185;&#23398;&#21644;&#21830;&#19994;&#26426;&#20250;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;QDC&#22312;&#21830;&#19994;&#21644;&#31185;&#23398;&#39046;&#22495;&#30340;&#28508;&#22312;&#24433;&#21709;&#65292;&#23588;&#20854;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#22823;&#25968;&#25454;&#34892;&#19994;&#12290;
&lt;/p&gt;
&lt;p&gt;
A quantum version of data centers might be significant in the quantum era. In this paper, we introduce Quantum Data Center (QDC), a quantum version of existing classical data centers, with a specific emphasis on combining Quantum Random Access Memory (QRAM) and quantum networks. We argue that QDC will provide significant benefits to customers in terms of efficiency, security, and precision, and will be helpful for quantum computing, communication, and sensing. We investigate potential scientific and business opportunities along this novel research direction through hardware realization and possible specific applications. We show the possible impacts of QDCs in business and science, especially the machine learning and big data industries.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#21644;&#32858;&#31867;&#31639;&#27861;&#30340;&#20248;&#21270;Mapper&#22270;&#35206;&#30422;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#21106;&#35206;&#30422;&#36873;&#25321;&#29983;&#25104;&#20102;&#20445;&#30041;&#25968;&#25454;&#38598;&#26412;&#36136;&#30340;Mapper&#22270;&#12290;</title><link>http://arxiv.org/abs/2309.06634</link><description>&lt;p&gt;
$G$-Mapper&#65306;&#23398;&#20064;Mapper&#26500;&#36896;&#20013;&#30340;&#35206;&#30422;
&lt;/p&gt;
&lt;p&gt;
$G$-Mapper: Learning a Cover in the Mapper Construction. (arXiv:2309.06634v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06634
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#21644;&#32858;&#31867;&#31639;&#27861;&#30340;&#20248;&#21270;Mapper&#22270;&#35206;&#30422;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#21106;&#35206;&#30422;&#36873;&#25321;&#29983;&#25104;&#20102;&#20445;&#30041;&#25968;&#25454;&#38598;&#26412;&#36136;&#30340;Mapper&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Mapper&#31639;&#27861;&#26159;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;(TDA)&#20013;&#19968;&#31181;&#21453;&#26144;&#32473;&#23450;&#25968;&#25454;&#38598;&#32467;&#26500;&#30340;&#21487;&#35270;&#21270;&#25216;&#26415;&#12290;Mapper&#31639;&#27861;&#38656;&#35201;&#35843;&#25972;&#22810;&#20010;&#21442;&#25968;&#20197;&#29983;&#25104;&#19968;&#20010;"&#22909;&#30475;&#30340;"Mapper&#22270;&#12290;&#35813;&#35770;&#25991;&#20851;&#27880;&#20110;&#36873;&#25321;&#35206;&#30422;&#21442;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26681;&#25454;&#27491;&#24577;&#24615;&#30340;&#32479;&#35745;&#26816;&#39564;&#21453;&#22797;&#20998;&#21106;&#35206;&#30422;&#26469;&#20248;&#21270;Mapper&#22270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;$G$-means&#32858;&#31867;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#36827;&#34892;Anderson-Darling&#26816;&#39564;&#26469;&#23547;&#25214;$k$-means&#20013;&#26368;&#20339;&#30340;&#31751;&#25968;&#12290;&#25105;&#20204;&#30340;&#20998;&#21106;&#36807;&#31243;&#21033;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#26681;&#25454;&#32473;&#23450;&#25968;&#25454;&#30340;&#20998;&#24067;&#31934;&#24515;&#36873;&#25321;&#35206;&#30422;&#12290;&#23545;&#20110;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#29983;&#25104;&#30340;&#35206;&#30422;&#20351;Mapper&#22270;&#20445;&#30041;&#20102;&#25968;&#25454;&#38598;&#30340;&#26412;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Mapper algorithm is a visualization technique in topological data analysis (TDA) that outputs a graph reflecting the structure of a given dataset. The Mapper algorithm requires tuning several parameters in order to generate a "nice" Mapper graph. The paper focuses on selecting the cover parameter. We present an algorithm that optimizes the cover of a Mapper graph by splitting a cover repeatedly according to a statistical test for normality. Our algorithm is based on $G$-means clustering which searches for the optimal number of clusters in $k$-means by conducting iteratively the Anderson-Darling test. Our splitting procedure employs a Gaussian mixture model in order to choose carefully the cover based on the distribution of a given data. Experiments for synthetic and real-world datasets demonstrate that our algorithm generates covers so that the Mapper graphs retain the essence of the datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#26694;&#26550;&#26469;&#36880;&#27493;&#23454;&#29616;&#23545;&#22810;&#20010;&#25935;&#24863;&#29305;&#24449;&#30340;&#20844;&#24179;&#24615;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#36793;&#38469;Wasserstein&#37325;&#24515;&#25193;&#23637;&#20102;&#26631;&#20934;&#30340;&#24378;&#20154;&#21475;&#24179;&#31561;&#27010;&#24565;&#65292;&#24182;&#25552;&#20379;&#20102;&#38381;&#24335;&#35299;&#26469;&#35299;&#37322;&#25935;&#24863;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.06627</link><description>&lt;p&gt;
&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#30340;&#39034;&#24207;&#20844;&#24179;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
A Sequentially Fair Mechanism for Multiple Sensitive Attributes. (arXiv:2309.06627v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#26694;&#26550;&#26469;&#36880;&#27493;&#23454;&#29616;&#23545;&#22810;&#20010;&#25935;&#24863;&#29305;&#24449;&#30340;&#20844;&#24179;&#24615;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#36793;&#38469;Wasserstein&#37325;&#24515;&#25193;&#23637;&#20102;&#26631;&#20934;&#30340;&#24378;&#20154;&#21475;&#24179;&#31561;&#27010;&#24565;&#65292;&#24182;&#25552;&#20379;&#20102;&#38381;&#24335;&#35299;&#26469;&#35299;&#37322;&#25935;&#24863;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#26631;&#20934;&#29992;&#20363;&#20013;&#65292;&#30446;&#26631;&#26159;&#28040;&#38500;&#25935;&#24863;&#21464;&#37327;&#21644;&#30456;&#24212;&#20998;&#25968;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#22312;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#24037;&#20855;&#21644;&#23450;&#20041;&#30340;&#36866;&#29992;&#24615;&#21644;&#26377;&#25928;&#24615;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#26694;&#26550;&#65292;&#21487;&#20197;&#36880;&#27493;&#23454;&#29616;&#23545;&#19968;&#32452;&#25935;&#24863;&#29305;&#24449;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#22810;&#36793;&#38469;Wasserstein&#37325;&#24515;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#23558;&#26631;&#20934;&#30340;&#24378;&#20154;&#21475;&#24179;&#31561;&#27010;&#24565;&#25193;&#23637;&#21040;&#20855;&#26377;&#22810;&#20010;&#25935;&#24863;&#29305;&#24449;&#30340;&#24773;&#20917;&#12290;&#36825;&#31181;&#26041;&#27861;&#36824;&#20026;&#26368;&#20248;&#30340;&#39034;&#24207;&#20844;&#24179;&#39044;&#27979;&#22120;&#25552;&#20379;&#20102;&#38381;&#24335;&#35299;&#65292;&#21487;&#20197;&#28165;&#26970;&#22320;&#35299;&#37322;&#25935;&#24863;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#21487;&#20197;&#26080;&#32541;&#25193;&#23637;&#21040;&#36817;&#20284;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the standard use case of Algorithmic Fairness, the goal is to eliminate the relationship between a sensitive variable and a corresponding score. Throughout recent years, the scientific community has developed a host of definitions and tools to solve this task, which work well in many practical applications. However, the applicability and effectivity of these tools and definitions becomes less straightfoward in the case of multiple sensitive attributes. To tackle this issue, we propose a sequential framework, which allows to progressively achieve fairness across a set of sensitive features. We accomplish this by leveraging multi-marginal Wasserstein barycenters, which extends the standard notion of Strong Demographic Parity to the case with multiple sensitive characteristics. This method also provides a closed-form solution for the optimal, sequentially fair predictor, permitting a clear interpretation of inter-sensitive feature correlations. Our approach seamlessly extends to approx
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#19982;Schr\"{o}dinger&#31995;&#32479;&#30340;&#25910;&#25947;&#24615;&#30456;&#20851;&#30340;&#25910;&#32553;&#31995;&#25968;&#36827;&#34892;&#20102;&#20808;&#39564;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#30340;&#20960;&#20309;&#21644;&#25511;&#21046;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#25351;&#20986;&#36890;&#36807;&#39044;&#26465;&#20214;&#21270;&#32456;&#28857;&#25903;&#25345;&#38598;&#21487;&#20197;&#25913;&#21892;&#32447;&#24615;SBPs&#30340;&#26368;&#22351;&#24773;&#20917;&#25910;&#32553;&#31995;&#25968;&#30340;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2309.06622</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#32447;&#24615;&#31995;&#32479;Schr\"odinger&#26725;&#25910;&#32553;&#31995;&#25968;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Contraction Coefficient of the Schr\"odinger Bridge for Stochastic Linear Systems. (arXiv:2309.06622v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#19982;Schr\"{o}dinger&#31995;&#32479;&#30340;&#25910;&#25947;&#24615;&#30456;&#20851;&#30340;&#25910;&#32553;&#31995;&#25968;&#36827;&#34892;&#20102;&#20808;&#39564;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#30340;&#20960;&#20309;&#21644;&#25511;&#21046;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#25351;&#20986;&#36890;&#36807;&#39044;&#26465;&#20214;&#21270;&#32456;&#28857;&#25903;&#25345;&#38598;&#21487;&#20197;&#25913;&#21892;&#32447;&#24615;SBPs&#30340;&#26368;&#22351;&#24773;&#20917;&#25910;&#32553;&#31995;&#25968;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Schr\"{o}dinger&#26725;&#26159;&#19968;&#20010;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#30446;&#30340;&#26159;&#22312;&#25511;&#21046;&#25193;&#25955;&#21644;&#25130;&#27490;&#32422;&#26463;&#26465;&#20214;&#19979;&#23558;&#32473;&#23450;&#30340;&#21021;&#22987;&#29366;&#24577;&#23494;&#24230;&#36716;&#21464;&#20026;&#21478;&#19968;&#20010;&#29366;&#24577;&#23494;&#24230;&#12290;&#22312;&#32463;&#20856;&#21644;&#32447;&#24615;&#31995;&#32479;&#35774;&#32622;&#20013;&#65292;&#35299;&#20915;Schr\"{o}dinger&#26725;&#38382;&#39064;&#30340;&#19968;&#31181;&#24120;&#29992;&#26041;&#27861;&#26159;&#36890;&#36807;&#25910;&#32553;&#19981;&#21160;&#28857;&#36882;&#24402;&#36827;&#34892;&#25968;&#20540;&#35745;&#31639;&#12290;&#36825;&#20123;&#36882;&#24402;&#21487;&#20197;&#30475;&#20316;&#26159;&#33879;&#21517;&#30340;Sinkhorn&#36845;&#20195;&#30340;&#21160;&#24577;&#29256;&#26412;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#23427;&#20204;&#35299;&#20915;&#20102;&#25152;&#35859;&#30340;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#30340;Schr\"{o}dinger&#31995;&#32479;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19982;Schr\"{o}dinger&#31995;&#32479;&#30340;&#25910;&#25947;&#24615;&#30456;&#20851;&#30340;&#25910;&#32553;&#31995;&#25968;&#30340;&#20808;&#39564;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25910;&#32553;&#31995;&#25968;&#30340;&#26032;&#20960;&#20309;&#21644;&#25511;&#21046;&#29702;&#35770;&#35299;&#37322;&#12290;&#22522;&#20110;&#36825;&#20123;&#26032;&#21457;&#29616;&#30340;&#35299;&#37322;&#65292;&#25105;&#20204;&#25351;&#20986;&#36890;&#36807;&#39044;&#26465;&#20214;&#21270;&#32456;&#28857;&#25903;&#25345;&#38598;&#21487;&#20197;&#25913;&#21892;&#32447;&#24615;SBPs&#30340;&#26368;&#22351;&#24773;&#20917;&#25910;&#32553;&#31995;&#25968;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Schr\"{o}dinger bridge is a stochastic optimal control problem to steer a given initial state density to another, subject to controlled diffusion and deadline constraints. A popular method to numerically solve the Schr\"{o}dinger bridge problems, in both classical and in the linear system settings, is via contractive fixed point recursions. These recursions can be seen as dynamic versions of the well-known Sinkhorn iterations, and under mild assumptions, they solve the so-called Schr\"{o}dinger systems with guaranteed linear convergence. In this work, we study a priori estimates for the contraction coefficients associated with the convergence of respective Schr\"{o}dinger systems. We provide new geometric and control-theoretic interpretations for the same. Building on these newfound interpretations, we point out the possibility of improved computation for the worst-case contraction coefficients of linear SBPs by preconditioning the endpoint support sets.
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#26080;&#38480;&#32500;&#32447;&#24615;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#65292;&#32447;&#24615;&#31639;&#23376;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#65292;&#32780;&#22312;&#21478;&#19968;&#20123;&#26465;&#20214;&#19979;&#21017;&#19981;&#21487;&#20197;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#65292;&#24182;&#22312;PAC&#35774;&#32622;&#19979;&#24471;&#21040;&#20102;&#30456;&#21516;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.06548</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#32447;&#24615;&#31639;&#23376;&#30340;&#26080;&#38480;&#32500;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Online Infinite-Dimensional Regression: Learning Linear Operators. (arXiv:2309.06548v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06548
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#26080;&#38480;&#32500;&#32447;&#24615;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#65292;&#32447;&#24615;&#31639;&#23376;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#65292;&#32780;&#22312;&#21478;&#19968;&#20123;&#26465;&#20214;&#19979;&#21017;&#19981;&#21487;&#20197;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#65292;&#24182;&#22312;PAC&#35774;&#32622;&#19979;&#24471;&#21040;&#20102;&#30456;&#21516;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#20004;&#20010;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20043;&#38388;&#30340;&#32447;&#24615;&#31639;&#23376;&#38382;&#39064;&#65292;&#36890;&#36807;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$p \in [1, \infty)$&#33539;&#22260;&#20869;&#65292;&#20855;&#26377;&#22343;&#21248;&#26377;&#30028;$p$-Schatten&#33539;&#25968;&#30340;&#32447;&#24615;&#31639;&#23376;&#31867;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#22343;&#21248;&#26377;&#30028;&#31639;&#23376;&#33539;&#25968;&#30340;&#32447;&#24615;&#31639;&#23376;&#31867;\textit{&#19981;}&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#25214;&#21040;&#19968;&#31867;&#26377;&#30028;&#32447;&#24615;&#31639;&#23376;&#65292;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#21644;&#22343;&#19968;&#25910;&#25947;&#19982;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#22312;PAC&#35774;&#32622;&#19979;&#21516;&#26679;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning linear operators under squared loss between two infinite-dimensional Hilbert spaces in the online setting. We show that the class of linear operators with uniformly bounded $p$-Schatten norm is online learnable for any $p \in [1, \infty)$. On the other hand, we prove an impossibility result by showing that the class of uniformly bounded linear operators with respect to the operator norm is \textit{not} online learnable. Moreover, we show a separation between online uniform convergence and online learnability by identifying a class of bounded linear operators that is online learnable but uniform convergence does not hold. Finally, we prove that the impossibility result and the separation between uniform convergence and learnability also hold in the agnostic PAC setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#37319;&#26679;&#19968;&#31995;&#21015;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#36890;&#36807;&#22312;&#19981;&#26029;&#22024;&#26434;&#21270;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#23450;&#20041;&#19981;&#21516;&#22122;&#22768;&#27700;&#24179;&#30340;EBMs&#65292;&#24182;&#19982;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#21327;&#21516;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20851;&#38381;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#20043;&#38388;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2309.05153</link><description>&lt;p&gt;
&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#23398;&#20064;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood. (arXiv:2309.05153v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05153
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#37319;&#26679;&#19968;&#31995;&#21015;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#36890;&#36807;&#22312;&#19981;&#26029;&#22024;&#26434;&#21270;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#23450;&#20041;&#19981;&#21516;&#22122;&#22768;&#27700;&#24179;&#30340;EBMs&#65292;&#24182;&#19982;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#21327;&#21516;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20851;&#38381;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#20043;&#38388;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#25968;&#25454;&#19978;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#35757;&#32451;&#33021;&#37327;&#22522;&#20934;&#27169;&#22411;&#65288;EBMs&#65289;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#19988;&#32791;&#26102;&#36739;&#38271;&#12290;&#22240;&#27492;&#65292;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#65288;&#22914;GANs&#21644;&#25193;&#25955;&#27169;&#22411;&#65289;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#21463;&#26368;&#36817;&#36890;&#36807;&#26368;&#22823;&#21270;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;DRL&#65289;&#26469;&#23398;&#20064;EBMs&#30340;&#21162;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#65292;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#21487;&#34892;&#22320;&#23398;&#20064;&#21644;&#20174;&#19968;&#31995;&#21015;EBMs&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#20123;EBMs&#23450;&#20041;&#22312;&#36234;&#26469;&#36234;&#22024;&#26434;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#65292;&#24182;&#19982;&#27599;&#20010;EBM&#30340;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#12290;&#22312;&#27599;&#20010;&#22122;&#22768;&#27700;&#24179;&#19978;&#65292;&#21021;&#22987;&#21270;&#27169;&#22411;&#23398;&#20064;&#22312;EBM&#30340;&#37319;&#26679;&#36807;&#31243;&#20013;&#20998;&#25674;&#65292;&#32780;&#20004;&#20010;&#27169;&#22411;&#22312;&#21327;&#21516;&#35757;&#32451;&#26694;&#26550;&#20869;&#20849;&#21516;&#20272;&#35745;&#12290;&#21021;&#22987;&#21270;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#20316;&#20026;&#36215;&#22987;&#28857;&#65292;&#32463;&#36807;EBM&#30340;&#20960;&#20010;&#37319;&#26679;&#27493;&#39588;&#36827;&#34892;&#25913;&#36827;&#12290;&#36890;&#36807;&#25913;&#36827;&#21518;&#30340;&#26679;&#26412;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#24674;&#22797;&#20284;&#28982;&#26469;&#20248;&#21270;EBM&#12290;
&lt;/p&gt;
&lt;p&gt;
Training energy-based models (EBMs) with maximum likelihood estimation on high-dimensional data can be both challenging and time-consuming. As a result, there a noticeable gap in sample quality between EBMs and other generative frameworks like GANs and diffusion models. To close this gap, inspired by the recent efforts of learning EBMs by maximimizing diffusion recovery likelihood (DRL), we propose cooperative diffusion recovery likelihood (CDRL), an effective approach to tractably learn and sample from a series of EBMs defined on increasingly noisy versons of a dataset, paired with an initializer model for each EBM. At each noise level, the initializer model learns to amortize the sampling process of the EBM, and the two models are jointly estimated within a cooperative training framework. Samples from the initializer serve as starting points that are refined by a few sampling steps from the EBM. With the refined samples, the EBM is optimized by maximizing recovery likelihood, while t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#32500;&#24230;&#21644;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#31561;&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#24471;&#21040;&#20102;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2309.05077</link><description>&lt;p&gt;
&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization error bounds for iterative learning algorithms with bounded updates. (arXiv:2309.05077v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#32500;&#24230;&#21644;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#31561;&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#24471;&#21040;&#20102;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#37319;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#38024;&#23545;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#36229;&#20986;&#20102;&#20197;&#21069;&#21482;&#20851;&#27880;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#33539;&#22260;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#20004;&#20010;&#20027;&#35201;&#30340;&#21019;&#26032;&#20043;&#22788;&#65306;1&#65289;&#25105;&#20204;&#23558;&#20114;&#20449;&#24687;&#37325;&#26032;&#23450;&#20041;&#20026;&#26356;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65307;2&#65289;&#25105;&#20204;&#19981;&#20351;&#29992;&#20114;&#20449;&#24687;&#30340;&#38142;&#24335;&#27861;&#21017;&#65292;&#32780;&#26159;&#37319;&#29992;&#26041;&#24046;&#20998;&#35299;&#25216;&#26415;&#26469;&#23558;&#20449;&#24687;&#20998;&#35299;&#21040;&#36845;&#20195;&#20013;&#65292;&#20174;&#32780;&#20801;&#35768;&#31616;&#21270;&#30340;&#20195;&#29702;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#22312;&#27169;&#22411;&#32500;&#24230;&#20197;&#19982;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#21516;&#30340;&#36895;&#29575;&#22686;&#21152;&#26102;&#23637;&#31034;&#20102;&#25913;&#36827;&#30340;&#30028;&#38480;&#12290;&#20026;&#20102;&#24357;&#21512;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#20808;&#21069;&#35266;&#23519;&#21040;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the generalization characteristics of iterative learning algorithms with bounded updates for non-convex loss functions, employing information-theoretic techniques. Our key contribution is a novel bound for the generalization error of these algorithms with bounded updates, extending beyond the scope of previous works that only focused on Stochastic Gradient Descent (SGD). Our approach introduces two main novelties: 1) we reformulate the mutual information as the uncertainty of updates, providing a new perspective, and 2) instead of using the chaining rule of mutual information, we employ a variance decomposition technique to decompose information across iterations, allowing for a simpler surrogate process. We analyze our generalization bound under various settings and demonstrate improved bounds when the model dimension increases at the same rate as the number of training data samples. To bridge the gap between theory and practice, we also examine the previously obse
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#25512;&#24191;&#21040;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#65292;&#21516;&#26102;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2309.02422</link><description>&lt;p&gt;
&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#36935;&#19978;&#31070;&#32463;&#32593;&#32476;&#65306;Radon-Kolmogorov-Smirnov&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test. (arXiv:2309.02422v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#25512;&#24191;&#21040;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#65292;&#21516;&#26102;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#65288;MMD&#65289;&#26159;&#19968;&#31867;&#22522;&#20110;&#26368;&#22823;&#21270;&#20004;&#20010;&#20998;&#24067;$P$&#21644;$Q$&#20043;&#38388;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26816;&#39564;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#25152;&#26377;&#22312;&#26576;&#20010;&#20989;&#25968;&#31354;&#38388;$\mathcal{F}$&#20013;&#30340;&#25968;&#25454;&#21464;&#25442;$f$&#30340;&#36873;&#25321;&#12290;&#21463;&#21040;&#26368;&#36817;&#23558;&#25152;&#35859;&#30340;Radon&#26377;&#30028;&#21464;&#24046;&#20989;&#25968;&#65288;RBV&#65289;&#21644;&#31070;&#32463;&#32593;&#32476;&#32852;&#31995;&#36215;&#26469;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65288;Parhi&#21644;Nowak, 2021, 2023&#65289;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23558;$\mathcal{F}$&#21462;&#20026;&#32473;&#23450;&#24179;&#28369;&#24230;&#39034;&#24207;$k \geq 0$&#19979;&#30340;RBV&#31354;&#38388;&#20013;&#30340;&#21333;&#20301;&#29699;&#30340;MMD&#12290;&#36825;&#20010;&#26816;&#39564;&#34987;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#23545;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#30340;&#32463;&#20856;Kolmogorov-Smirnov&#65288;KS&#65289;&#26816;&#39564;&#30340;&#19968;&#33324;&#21270;&#12290;&#23427;&#36824;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#65306;&#25105;&#20204;&#35777;&#26126;RKS&#26816;&#39564;&#20013;&#30340;&#35777;&#25454;&#20989;&#25968;$f$&#65292;&#21363;&#36798;&#21040;&#26368;&#22823;&#22343;&#24046;&#30340;&#20989;&#25968;&#65292;&#24635;&#26159;&#19968;&#20010;&#20108;&#27425;&#26679;&#26465;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) refers to a general class of nonparametric two-sample tests that are based on maximizing the mean difference over samples from one distribution $P$ versus another $Q$, over all choices of data transformations $f$ living in some function space $\mathcal{F}$. Inspired by recent work that connects what are known as functions of $\textit{Radon bounded variation}$ (RBV) and neural networks (Parhi and Nowak, 2021, 2023), we study the MMD defined by taking $\mathcal{F}$ to be the unit ball in the RBV space of a given smoothness order $k \geq 0$. This test, which we refer to as the $\textit{Radon-Kolmogorov-Smirnov}$ (RKS) test, can be viewed as a generalization of the well-known and classical Kolmogorov-Smirnov (KS) test to multiple dimensions and higher orders of smoothness. It is also intimately connected to neural networks: we prove that the witness in the RKS test -- the function $f$ achieving the maximum mean difference -- is always a ridge spline of degree
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#26041;&#27861;&#23545;&#20855;&#26377;&#26102;&#31354;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#22312;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26497;&#23567;&#21270;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#20197;&#24448;&#26410;&#26366;&#25506;&#32034;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.16172</link><description>&lt;p&gt;
&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#36827;&#34892;&#26102;&#31354;&#27169;&#22411;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Temporal-spatial model via Trend Filtering. (arXiv:2308.16172v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16172
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#26041;&#27861;&#23545;&#20855;&#26377;&#26102;&#31354;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#22312;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26497;&#23567;&#21270;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#20197;&#24448;&#26410;&#26366;&#25506;&#32034;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#23545;&#20855;&#26377;&#21516;&#26102;&#26102;&#38388;&#21644;&#31354;&#38388;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36235;&#21183;&#28388;&#27874;&#65292;&#36825;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#30001;Mammen&#21644;Rudin&#25552;&#20986;&#12290;&#22312;&#21333;&#21464;&#37327;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#30340;&#20449;&#21495;&#20551;&#35774;&#20855;&#26377;&#26377;&#30028;&#24635;&#21464;&#24322;&#24230;&#30340;k&#27425;&#24369;&#23548;&#25968;&#65292;&#20801;&#35768;&#19968;&#23450;&#31243;&#24230;&#30340;&#24179;&#28369;&#24615;&#12290;&#22312;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Padilla&#31561;&#20154;&#30340;K&#26368;&#36817;&#37051;&#34701;&#21512;&#22871;&#32034;&#20272;&#35745;&#22120;&#65292;&#37319;&#29992;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#21464;&#24322;&#24230;&#19988;&#31526;&#21512;&#20998;&#27573;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#20934;&#21017;&#30340;&#20449;&#21495;&#30340;ADMM&#31639;&#27861;&#12290;&#36890;&#36807;&#19982;&#19979;&#30028;&#23545;&#40784;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#26497;&#23567;&#21270;&#24615;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#20197;&#24448;&#36235;&#21183;&#28388;&#27874;&#30740;&#31350;&#20013;&#26410;&#26366;&#25506;&#32034;&#36807;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#12290;&#20223;&#30495;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#37117;&#31361;&#20986;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research focuses on the estimation of a non-parametric regression function designed for data with simultaneous time and space dependencies. In such a context, we study the Trend Filtering, a nonparametric estimator introduced by \cite{mammen1997locally} and \cite{rudin1992nonlinear}. For univariate settings, the signals we consider are assumed to have a kth weak derivative with bounded total variation, allowing for a general degree of smoothness. In the multivariate scenario, we study a $K$-Nearest Neighbor fused lasso estimator as in \cite{padilla2018adaptive}, employing an ADMM algorithm, suitable for signals with bounded variation that adhere to a piecewise Lipschitz continuity criterion. By aligning with lower bounds, the minimax optimality of our estimators is validated. A unique phase transition phenomenon, previously uncharted in Trend Filtering studies, emerges through our analysis. Both Simulation studies and real data applications underscore the superior performance of o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#39038;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20854;&#32479;&#35745;&#29305;&#24615;&#24182;&#25552;&#20379;&#20102;&#26368;&#20339;&#23454;&#36341;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2306.01198</link><description>&lt;p&gt;
&#21305;&#37197;&#20219;&#21153;&#30340;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#65306;&#20851;&#38190;&#32508;&#36848;&#19982;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Confidence Intervals for Error Rates in Matching Tasks: Critical Review and Recommendations. (arXiv:2306.01198v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20854;&#32479;&#35745;&#29305;&#24615;&#24182;&#25552;&#20379;&#20102;&#26368;&#20339;&#23454;&#36341;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21305;&#37197;&#31639;&#27861;&#36890;&#24120;&#29992;&#20110;&#39044;&#27979;&#25910;&#38598;&#20013;&#39033;&#30446;&#20043;&#38388;&#30340;&#21305;&#37197;&#12290;&#20363;&#22914;&#65292;&#22312;1&#65306;1&#30340;&#20154;&#33080;&#39564;&#35777;&#20013;&#65292;&#21305;&#37197;&#31639;&#27861;&#39044;&#27979;&#20004;&#24352;&#20154;&#33080;&#22270;&#20687;&#26159;&#21542;&#25551;&#32472;&#21516;&#19968;&#20010;&#20154;&#12290;&#24403;&#25968;&#25454;&#30456;&#20851;&#19988;&#35823;&#24046;&#29575;&#20302;&#26102;&#65292;&#20934;&#30830;&#35780;&#20272;&#27492;&#31867;&#31639;&#27861;&#35823;&#24046;&#29575;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#36825;&#26159;&#25991;&#29486;&#20013;&#32463;&#24120;&#34987;&#24573;&#30053;&#30340;&#20004;&#20010;&#26041;&#38754;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#26500;&#24314;1:1&#20154;&#33080;&#39564;&#35777;&#31561;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#21644;&#26816;&#39564;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#24182;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#28436;&#31034;&#20102;&#35206;&#30422;&#29575;&#21644;&#21306;&#38388;&#23485;&#24230;&#22914;&#20309;&#38543;&#30528;&#26679;&#26412;&#37327;&#12289;&#35823;&#24046;&#29575;&#21644;&#25968;&#25454;&#30456;&#20851;&#31243;&#24230;&#21464;&#21270;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#26368;&#20339;&#23454;&#36341;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matching algorithms are commonly used to predict matches between items in a collection. For example, in 1:1 face verification, a matching algorithm predicts whether two face images depict the same person. Accurately assessing the uncertainty of the error rates of such algorithms can be challenging when data are dependent and error rates are low, two aspects that have been often overlooked in the literature. In this work, we review methods for constructing confidence intervals for error rates in matching tasks such as 1:1 face verification. We derive and examine the statistical properties of these methods and demonstrate how coverage and interval width vary with sample size, error rates, and degree of data dependence using both synthetic and real-world datasets. Based on our findings, we provide recommendations for best practices for constructing confidence intervals for error rates in matching tasks.
&lt;/p&gt;</description></item><item><title>&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(IBNNs)&#12290;&#36825;&#31181;&#31639;&#27861;&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#38598;&#21512;&#21644;&#20284;&#28982;&#20998;&#24067;&#38598;&#21512;&#36827;&#34892;&#35757;&#32451;&#65292;&#30456;&#27604;&#26631;&#20934;&#30340;BNNs&#65292;&#21487;&#20197;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#20063;&#26356;&#21152;&#40065;&#26834;&#12290;</title><link>http://arxiv.org/abs/2302.09656</link><description>&lt;p&gt;
&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Imprecise Bayesian Neural Networks. (arXiv:2302.09656v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09656
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(IBNNs)&#12290;&#36825;&#31181;&#31639;&#27861;&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#38598;&#21512;&#21644;&#20284;&#28982;&#20998;&#24067;&#38598;&#21512;&#36827;&#34892;&#35757;&#32451;&#65292;&#30456;&#27604;&#26631;&#20934;&#30340;BNNs&#65292;&#21487;&#20197;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#20063;&#26356;&#21152;&#40065;&#26834;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20013;, &#30830;&#23450;&#19981;&#30830;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#26159;&#37325;&#35201;&#30340;&#30446;&#26631;&#12290;&#34429;&#28982;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20351;&#24471;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#33021;&#22815;&#34987;&#35780;&#20272;&#65292;&#19981;&#21516;&#26469;&#28304;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#26080;&#27861;&#21306;&#20998;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;IBNNs&#65289;&#65292;&#23427;&#20204;&#21487;&#20197;&#27010;&#25324;&#21644;&#20811;&#26381;&#26631;&#20934;BNNs&#30340;&#26576;&#20123;&#32570;&#28857;&#12290;&#26631;&#20934;BNNs&#20351;&#29992;&#21333;&#19968;&#30340;&#20808;&#39564;&#20998;&#24067;&#21644;&#20284;&#28982;&#20998;&#24067;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;IBNNs&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#21644;&#20284;&#28982;&#20998;&#24067;&#36827;&#34892;&#35757;&#32451;&#12290;&#23427;&#20204;&#20801;&#35768;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#27604;&#26631;&#20934;BNNs&#26356;&#21152;&#40065;&#26834;&#12290;&#23427;&#20204;&#36824;&#21487;&#20197;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;PAC&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#32467;&#26524;&#38598;&#12290;&#25105;&#20204;&#23558;IBNNs&#24212;&#29992;&#20110;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#65306;&#19968;&#20010;&#26159;&#20026;&#20102;&#20154;&#24037;&#33008;&#33146;&#25511;&#21046;&#27169;&#25311;&#34880;&#31958;&#21644;&#33008;&#23707;&#32032;&#21160;&#21147;&#23398;&#65292;&#21478;&#19968;&#20010;&#26159;&#36816;&#21160;&#35268;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification and robustness to distribution shifts are important goals in machine learning and artificial intelligence. Although Bayesian neural networks (BNNs) allow for uncertainty in the predictions to be assessed, different sources of uncertainty are indistinguishable. We present imprecise Bayesian neural networks (IBNNs); they generalize and overcome some of the drawbacks of standard BNNs. These latter are trained using a single prior and likelihood distributions, whereas IBNNs are trained using credal prior and likelihood sets. They allow to distinguish between aleatoric and epistemic uncertainties, and to quantify them. In addition, IBNNs are robust in the sense of Bayesian sensitivity analysis, and are more robust than BNNs to distribution shift. They can also be used to compute sets of outcomes that enjoy PAC-like properties. We apply IBNNs to two case studies. One, to model blood glucose and insulin dynamics for artificial pancreas control, and two, for motion p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#31639;&#27861;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2302.05185</link><description>&lt;p&gt;
&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Penalty-based Bilevel Gradient Descent Method. (arXiv:2302.05185v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#31639;&#27861;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a penalty-based bilevel gradient descent algorithm to solve the constrained bilevel problem without lower-level strong convexity, and experiments show its efficiency.
&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#26159;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#38590;&#20197;&#35299;&#20915;&#12290;&#26368;&#36817;&#30340;&#21487;&#25193;&#23637;&#21452;&#23618;&#31639;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#19979;&#23618;&#30446;&#26631;&#20989;&#25968;&#26159;&#24378;&#20984;&#25110;&#26080;&#32422;&#26463;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24809;&#32602;&#26041;&#27861;&#26469;&#35299;&#20915;&#21452;&#23618;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#24809;&#32602;&#37325;&#26500;&#21487;&#20197;&#24674;&#22797;&#21407;&#22987;&#21452;&#23618;&#38382;&#39064;&#30340;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#65288;PBGD&#65289;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#19978;&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#24615;&#12290;&#23454;&#39564;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;PBGD&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization enjoys a wide range of applications in hyper-parameter optimization, meta-learning and reinforcement learning. However, bilevel optimization problems are difficult to solve. Recent progress on scalable bilevel algorithms mainly focuses on bilevel optimization problems where the lower-level objective is either strongly convex or unconstrained. In this work, we tackle the bilevel problem through the lens of the penalty method. We show that under certain conditions, the penalty reformulation recovers the solutions of the original bilevel problem. Further, we propose the penalty-based bilevel gradient descent (PBGD) algorithm and establish its finite-time convergence for the constrained bilevel problem without lower-level strong convexity. Experiments showcase the efficiency of the proposed PBGD algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#20247;&#21253;&#30340;&#24037;&#20154;-&#20219;&#21153;&#29305;&#21270;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#35299;&#20915;&#20102;&#22312;&#22810;&#20010;&#19981;&#20934;&#30830;&#31572;&#26696;&#20013;&#25512;&#26029;&#27491;&#30830;&#26631;&#31614;&#30340;&#38382;&#39064;&#65292;&#24182;&#32771;&#34385;&#20102;&#20219;&#21153;&#21644;&#24037;&#20154;&#30340;&#29305;&#21270;&#31867;&#22411;&#20197;&#21450;&#20854;&#21487;&#38752;&#24615;&#21464;&#21270;&#12290;&#29992;&#20110;&#20272;&#35745;&#32416;&#27491;&#31572;&#26696;&#36798;&#21040;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2111.12550</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#20247;&#21253;&#30340;&#24037;&#20154;-&#20219;&#21153;&#29305;&#21270;&#27169;&#22411;&#65306;&#39640;&#25928;&#25512;&#26029;&#19982;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
A Worker-Task Specialization Model for Crowdsourcing: Efficient Inference and Fundamental Limits. (arXiv:2111.12550v3 [cs.HC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.12550
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#20247;&#21253;&#30340;&#24037;&#20154;-&#20219;&#21153;&#29305;&#21270;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#35299;&#20915;&#20102;&#22312;&#22810;&#20010;&#19981;&#20934;&#30830;&#31572;&#26696;&#20013;&#25512;&#26029;&#27491;&#30830;&#26631;&#31614;&#30340;&#38382;&#39064;&#65292;&#24182;&#32771;&#34385;&#20102;&#20219;&#21153;&#21644;&#24037;&#20154;&#30340;&#29305;&#21270;&#31867;&#22411;&#20197;&#21450;&#20854;&#21487;&#38752;&#24615;&#21464;&#21270;&#12290;&#29992;&#20110;&#20272;&#35745;&#32416;&#27491;&#31572;&#26696;&#36798;&#21040;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#21253;&#31995;&#32479;&#24050;&#25104;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#24179;&#21488;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#19987;&#23478;&#24037;&#20154;&#20197;&#30456;&#23545;&#36739;&#20302;&#30340;&#25104;&#26412;&#20026;&#25968;&#25454;&#26631;&#27880;&#12290;&#28982;&#32780;&#65292;&#20174;&#22810;&#20010;&#19981;&#20934;&#30830;&#31572;&#26696;&#20013;&#25512;&#26029;&#27491;&#30830;&#30340;&#26631;&#31614;&#19968;&#30452;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#31572;&#26696;&#30340;&#36136;&#37327;&#22312;&#20219;&#21153;&#21644;&#24037;&#20154;&#20043;&#38388;&#24046;&#24322;&#36739;&#22823;&#12290;&#35768;&#22810;&#29616;&#26377;&#24037;&#20316;&#20551;&#35774;&#24037;&#20154;&#30340;&#25216;&#33021;&#27700;&#24179;&#23384;&#22312;&#22266;&#23450;&#30340;&#25490;&#24207;&#65292;&#24182;&#30528;&#37325;&#20110;&#20272;&#35745;&#24037;&#20154;&#25216;&#33021;&#20197;&#27719;&#24635;&#26469;&#33258;&#20855;&#26377;&#19981;&#21516;&#26435;&#37325;&#30340;&#24037;&#20154;&#30340;&#31572;&#26696;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#29305;&#21035;&#26159;&#22312;&#20219;&#21153;&#24322;&#36136;&#24615;&#24456;&#22823;&#26102;&#65292;&#24037;&#20154;&#30340;&#25216;&#33021;&#22312;&#20219;&#21153;&#38388;&#21464;&#21270;&#24456;&#22823;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#26032;&#27169;&#22411;&#65292;&#31216;&#20026;$d$-type&#29305;&#21270;&#27169;&#22411;&#65292;&#20854;&#20013;&#27599;&#20010;&#20219;&#21153;&#21644;&#24037;&#20154;&#37117;&#26377;&#33258;&#24049;&#30340;&#65288;&#26410;&#30693;&#65289;&#31867;&#22411;&#65292;&#24182;&#19988;&#27599;&#20010;&#24037;&#20154;&#30340;&#21487;&#38752;&#24615;&#21487;&#20197;&#22312;&#32473;&#23450;&#20219;&#21153;&#30340;&#31867;&#22411;&#21644;&#24037;&#20154;&#30340;&#31867;&#22411;&#19978;&#21464;&#21270;&#12290;&#25105;&#20204;&#20801;&#35768;&#31867;&#22411;&#25968;$d$&#38543;&#30528;&#20219;&#21153;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#25193;&#23637;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#20351;&#32416;&#27491;&#31572;&#26696;&#36798;&#21040;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Crowdsourcing system has emerged as an effective platform for labeling data with relatively low cost by using non-expert workers. Inferring correct labels from multiple noisy answers on data, however, has been a challenging problem, since the quality of the answers varies widely across tasks and workers. Many existing works have assumed that there is a fixed ordering of workers in terms of their skill levels, and focused on estimating worker skills to aggregate the answers from workers with different weights. In practice, however, the worker skill changes widely across tasks, especially when the tasks are heterogeneous. In this paper, we consider a new model, called $d$-type specialization model, in which each task and worker has its own (unknown) type and the reliability of each worker can vary in the type of a given task and that of a worker. We allow that the number $d$ of types can scale in the number of tasks. In this model, we characterize the optimal sample complexity to correct
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#19981;&#21160;&#28857;&#29702;&#35770;&#20998;&#26512;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;&#38750;&#36127;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#23384;&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#32500;&#24230;&#30456;&#21516;&#30340;&#19981;&#21160;&#28857;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19981;&#21160;&#28857;&#38598;&#24418;&#29366;&#20026;&#21306;&#38388;&#12290;&#36825;&#20123;&#32467;&#26524;&#26377;&#21161;&#20110;&#23545;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2106.16239</link><description>&lt;p&gt;
&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#21160;&#28857;
&lt;/p&gt;
&lt;p&gt;
Fixed points of nonnegative neural networks. (arXiv:2106.16239v7 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.16239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#19981;&#21160;&#28857;&#29702;&#35770;&#20998;&#26512;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;&#38750;&#36127;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#23384;&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#32500;&#24230;&#30456;&#21516;&#30340;&#19981;&#21160;&#28857;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19981;&#21160;&#28857;&#38598;&#24418;&#29366;&#20026;&#21306;&#38388;&#12290;&#36825;&#20123;&#32467;&#26524;&#26377;&#21161;&#20110;&#23545;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#19981;&#21160;&#28857;&#29702;&#35770;&#20998;&#26512;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#65292;&#23558;&#20854;&#23450;&#20041;&#20026;&#23558;&#38750;&#36127;&#21521;&#37327;&#26144;&#23556;&#20026;&#38750;&#36127;&#21521;&#37327;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#20855;&#26377;&#38750;&#36127;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#38750;&#32447;&#24615;Perron-Frobenius&#29702;&#35770;&#26694;&#26550;&#19979;&#34987;&#35748;&#20026;&#26159;&#21333;&#35843;&#19988;(&#24369;)&#21487;&#25193;&#23637;&#30340;&#20989;&#25968;&#12290;&#36825;&#20010;&#20107;&#23454;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20379;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#23384;&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#32500;&#24230;&#30456;&#21516;&#30340;&#19981;&#21160;&#28857;&#30340;&#26465;&#20214;&#65292;&#36825;&#20123;&#26465;&#20214;&#27604;&#26368;&#36817;&#22312;&#20984;&#20998;&#26512;&#20013;&#20351;&#29992;&#30340;&#35770;&#35777;&#35201;&#24369;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#38750;&#36127;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#21160;&#28857;&#38598;&#30340;&#24418;&#29366;&#26159;&#19968;&#20010;&#21306;&#38388;&#65292;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#36864;&#21270;&#20026;&#19968;&#20010;&#28857;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#24471;&#21040;&#26356;&#19968;&#33324;&#30340;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#23384;&#22312;&#19981;&#21160;&#28857;&#30340;&#32467;&#35770;&#12290;&#20174;&#23454;&#38469;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26377;&#21161;&#20110;&#23545;&#38750;&#36127;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We use fixed point theory to analyze nonnegative neural networks, which we define as neural networks that map nonnegative vectors to nonnegative vectors. We first show that nonnegative neural networks with nonnegative weights and biases can be recognized as monotonic and (weakly) scalable functions within the framework of nonlinear Perron-Frobenius theory. This fact enables us to provide conditions for the existence of fixed points of nonnegative neural networks having inputs and outputs of the same dimension, and these conditions are weaker than those recently obtained using arguments in convex analysis. Furthermore, we prove that the shape of the fixed point set of nonnegative neural networks with nonnegative weights and biases is an interval, which under mild conditions degenerates to a point. These results are then used to obtain the existence of fixed points of more general nonnegative neural networks. From a practical perspective, our results contribute to the understanding of th
&lt;/p&gt;</description></item></channel></rss>