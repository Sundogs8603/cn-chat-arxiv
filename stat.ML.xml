<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TDS&#30340;&#25197;&#36716;&#24335;&#25193;&#25955;&#37319;&#26679;&#22120;&#65292;&#23427;&#26159;&#19968;&#31181;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#25197;&#36716;&#25216;&#26415;&#32467;&#21512;&#21551;&#21457;&#24335;&#36817;&#20284;&#65292;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#29305;&#23450;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#22312;&#24191;&#27867;&#30340;&#26465;&#20214;&#20998;&#24067;&#19978;&#25552;&#20379;&#31934;&#30830;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.17775</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#23454;&#29992;&#21644;&#28176;&#36827;&#31934;&#30830;&#26465;&#20214;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Practical and Asymptotically Exact Conditional Sampling in Diffusion Models. (arXiv:2306.17775v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TDS&#30340;&#25197;&#36716;&#24335;&#25193;&#25955;&#37319;&#26679;&#22120;&#65292;&#23427;&#26159;&#19968;&#31181;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#25197;&#36716;&#25216;&#26415;&#32467;&#21512;&#21551;&#21457;&#24335;&#36817;&#20284;&#65292;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#29305;&#23450;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#22312;&#24191;&#27867;&#30340;&#26465;&#20214;&#20998;&#24067;&#19978;&#25552;&#20379;&#31934;&#30830;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#20998;&#23376;&#35774;&#35745;&#21644;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#31561;&#26465;&#20214;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25104;&#23601;&#20027;&#35201;&#20381;&#36182;&#20110;&#20219;&#21153;&#29305;&#23450;&#30340;&#26465;&#20214;&#35757;&#32451;&#25110;&#23481;&#26131;&#20986;&#38169;&#30340;&#21551;&#21457;&#24335;&#36817;&#20284;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#26465;&#20214;&#29983;&#25104;&#26041;&#27861;&#24212;&#35813;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#29305;&#23450;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20026;&#24191;&#27867;&#30340;&#26465;&#20214;&#20998;&#24067;&#25552;&#20379;&#31934;&#30830;&#30340;&#26679;&#26412;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#25197;&#36716;&#24335;&#25193;&#25955;&#37319;&#26679;&#22120;(TDS)&#12290;TDS&#26159;&#19968;&#31181;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;(SMC)&#31639;&#27861;&#12290;&#20854;&#20027;&#35201;&#24605;&#24819;&#26159;&#20351;&#29992;&#25197;&#36716;&#65292;&#19968;&#31181;&#20855;&#26377;&#33391;&#22909;&#35745;&#31639;&#25928;&#29575;&#30340;SMC&#25216;&#26415;&#65292;&#26469;&#32467;&#21512;&#21551;&#21457;&#24335;&#36817;&#20284;&#32780;&#19981;&#24433;&#21709;&#28176;&#36827;&#31934;&#30830;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#27169;&#25311;&#23454;&#39564;&#21644;MNIST&#22270;&#20687;&#20462;&#22797;&#20197;&#21450;&#31867;&#26465;&#20214;&#29983;&#25104;&#20219;&#21153;&#20013;&#21457;&#29616;&#65292;TDS&#25552;&#20379;&#20102;&#35745;&#31639;&#32479;&#35745;&#26435;&#34913;&#65292;&#20351;&#29992;&#26356;&#22810;&#31890;&#23376;&#24471;&#21040;&#26356;&#20934;&#30830;&#30340;&#36817;&#20284;&#32467;&#26524;&#65292;&#20294;&#21516;&#26102;&#38656;&#35201;&#26356;&#22810;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have been successful on a range of conditional generation tasks including molecular design and text-to-image generation. However, these achievements have primarily depended on task-specific conditional training or error-prone heuristic approximations. Ideally, a conditional generation method should provide exact samples for a broad range of conditional distributions without requiring task-specific training. To this end, we introduce the Twisted Diffusion Sampler, or TDS. TDS is a sequential Monte Carlo (SMC) algorithm that targets the conditional distributions of diffusion models. The main idea is to use twisting, an SMC technique that enjoys good computational efficiency, to incorporate heuristic approximations without compromising asymptotic exactness. We first find in simulation and on MNIST image inpainting and class-conditional generation tasks that TDS provides a computational statistical trade-off, yielding more accurate approximations with many particles but wi
&lt;/p&gt;</description></item><item><title>&#22312;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#27604;&#20363;&#26497;&#38480;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#20462;&#25913;Softmax-based&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;Transformer&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#26497;&#38480;&#20998;&#24067;&#21487;&#20197;&#29992;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#12290;&#36890;&#36807;&#20462;&#25913;&#27880;&#24847;&#21147;&#26426;&#21046;&#24182;&#20351;&#29992;&#27531;&#24046;&#36830;&#25509;&#65292;&#25105;&#20204;&#21487;&#20197;&#25511;&#21046;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#21644;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.17759</link><description>&lt;p&gt;
&#21463;&#24418;&#29366;&#25913;&#21464;&#30340;Transformer&#65306;&#22312;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#26497;&#38480;&#20013;&#30340;&#27880;&#24847;&#21147;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The Shaped Transformer: Attention Models in the Infinite Depth-and-Width Limit. (arXiv:2306.17759v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17759
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#27604;&#20363;&#26497;&#38480;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#20462;&#25913;Softmax-based&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;Transformer&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#26497;&#38480;&#20998;&#24067;&#21487;&#20197;&#29992;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#12290;&#36890;&#36807;&#20462;&#25913;&#27880;&#24847;&#21147;&#26426;&#21046;&#24182;&#20351;&#29992;&#27531;&#24046;&#36830;&#25509;&#65292;&#25105;&#20204;&#21487;&#20197;&#25511;&#21046;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#21644;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#29992;&#20316;&#26816;&#26597;&#32593;&#32476;&#21487;&#35757;&#32451;&#24615;&#30340;&#20195;&#29702;&#12290;&#21463;Transformer&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#27604;&#20363;&#26497;&#38480;&#19979;&#65292;&#24102;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#20462;&#25913;Softmax-based&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#26497;&#38480;&#20998;&#24067;&#21487;&#20197;&#29992;&#28145;&#24230;&#19982;&#23485;&#24230;&#27604;&#29575;&#20026;&#32034;&#24341;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#26469;&#25551;&#36848;&#12290;&#20026;&#20102;&#23454;&#29616;&#33391;&#23450;&#20041;&#30340;&#38543;&#26426;&#26497;&#38480;&#65292;Transformer&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#23558;Softmax&#36755;&#20986;&#23621;&#20013;&#22312;&#21333;&#20301;&#30697;&#38453;&#19978;&#65292;&#24182;&#36890;&#36807;&#23485;&#24230;&#30456;&#20851;&#30340;&#28201;&#24230;&#21442;&#25968;&#23545;Softmax logits&#36827;&#34892;&#32553;&#25918;&#26469;&#36827;&#34892;&#20462;&#25913;&#12290;&#25105;&#20204;&#36890;&#36807;&#30456;&#24212;&#30340;SDE&#30740;&#31350;&#20102;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#27531;&#24046;&#36830;&#25509;&#20248;&#38597;&#22320;&#25511;&#21046;&#28418;&#31227;&#21644;&#25193;&#25955;&#30340;&#23610;&#24230;&#12290;&#31283;&#23450;SDE&#30340;&#23384;&#22312;&#24847;&#21619;&#30528;&#21327;&#26041;&#24046;&#32467;&#26500;&#26159;&#33391; behaved &#30340;&#65292;&#21363;&#20351;&#23545;&#20110;&#38750;&#24120;&#22823;&#30340;&#28145;&#24230;&#21644;&#23485;&#24230;&#20063;&#26159;&#22914;&#27492;&#12290;
&lt;/p&gt;
&lt;p&gt;
In deep learning theory, the covariance matrix of the representations serves as a proxy to examine the network's trainability. Motivated by the success of Transformers, we study the covariance matrix of a modified Softmax-based attention model with skip connections in the proportional limit of infinite-depth-and-width. We show that at initialization the limiting distribution can be described by a stochastic differential equation (SDE) indexed by the depth-to-width ratio. To achieve a well-defined stochastic limit, the Transformer's attention mechanism is modified by centering the Softmax output at identity, and scaling the Softmax logits by a width-dependent temperature parameter. We examine the stability of the network through the corresponding SDE, showing how the scale of both the drift and diffusion can be elegantly controlled with the aid of residual connections. The existence of a stable SDE implies that the covariance structure is well-behaved, even for very large depth and widt
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27867;&#21270;&#26102;&#38388;&#25197;&#26354;&#19981;&#21464;&#23383;&#20856;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#27169;&#24335;&#35782;&#21035;&#21644;&#20998;&#31867;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#22522;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#26500;&#24314;&#27867;&#21270;&#26102;&#38388;&#25197;&#26354;&#31639;&#23376;&#65292;&#20197;&#23454;&#29616;&#36830;&#32493;&#30340;&#26102;&#38388;&#25197;&#26354;&#12290;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#25197;&#26354;&#36335;&#24452;&#12289;&#23383;&#20856;&#21644;&#31232;&#30095;&#31995;&#25968;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#32858;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.17690</link><description>&lt;p&gt;
&#27867;&#21270;&#26102;&#38388;&#25197;&#26354;&#19981;&#21464;&#23383;&#20856;&#23398;&#20064;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Generalized Time Warping Invariant Dictionary Learning for Time Series Classification and Clustering. (arXiv:2306.17690v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17690
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27867;&#21270;&#26102;&#38388;&#25197;&#26354;&#19981;&#21464;&#23383;&#20856;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#27169;&#24335;&#35782;&#21035;&#21644;&#20998;&#31867;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#22522;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#26500;&#24314;&#27867;&#21270;&#26102;&#38388;&#25197;&#26354;&#31639;&#23376;&#65292;&#20197;&#23454;&#29616;&#36830;&#32493;&#30340;&#26102;&#38388;&#25197;&#26354;&#12290;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#25197;&#26354;&#36335;&#24452;&#12289;&#23383;&#20856;&#21644;&#31232;&#30095;&#31995;&#25968;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#32858;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23383;&#20856;&#23398;&#20064;&#26159;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#27169;&#24335;&#35782;&#21035;&#21644;&#20998;&#31867;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;&#22312;&#21508;&#31181;&#23383;&#20856;&#23398;&#20064;&#25216;&#26415;&#20013;&#65292;&#21160;&#24577;&#26102;&#38388;&#25197;&#26354;&#65288;DTW&#65289;&#36890;&#24120;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#24310;&#36831;&#12289;&#32553;&#25918;&#12289;&#36716;&#25442;&#21644;&#20854;&#20182;&#21508;&#31181;&#26102;&#38388;&#19981;&#20934;&#30830;&#24615;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;DTW&#22312;&#23545;&#40784;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26102;&#26159;&#31163;&#25955;&#30340;&#24615;&#36136;&#65292;&#22240;&#27492;&#23481;&#26131;&#20986;&#29616;&#36807;&#25311;&#21512;&#25110;&#20449;&#24687;&#25439;&#22833;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27867;&#21270;&#26102;&#38388;&#25197;&#26354;&#19981;&#21464;&#23383;&#20856;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#20102;&#27867;&#21270;&#26102;&#38388;&#25197;&#26354;&#31639;&#23376;&#65292;&#35813;&#31639;&#23376;&#30001;&#36830;&#32493;&#22522;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#21512;&#26500;&#25104;&#65292;&#20197;&#20415;&#23454;&#29616;&#36830;&#32493;&#30340;&#26102;&#38388;&#25197;&#26354;&#12290;&#23558;&#25152;&#25552;&#20986;&#30340;&#31639;&#23376;&#19982;&#23383;&#20856;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#23558;&#20854;&#24314;&#27169;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#37319;&#29992;&#22359;&#22352;&#26631;&#19979;&#38477;&#27861;&#26469;&#32852;&#21512;&#20248;&#21270;&#25197;&#26354;&#36335;&#24452;&#12289;&#23383;&#20856;&#21644;&#31232;&#30095;&#31995;&#25968;&#12290;&#20248;&#21270;&#32467;&#26524;&#34987;&#29992;&#20316;&#29305;&#24449;&#25552;&#21462;&#21644;&#20998;&#31867;&#30340;&#25552;&#21462;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#32858;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dictionary learning is an effective tool for pattern recognition and classification of time series data. Among various dictionary learning techniques, the dynamic time warping (DTW) is commonly used for dealing with temporal delays, scaling, transformation, and many other kinds of temporal misalignments issues. However, the DTW suffers overfitting or information loss due to its discrete nature in aligning time series data. To address this issue, we propose a generalized time warping invariant dictionary learning algorithm in this paper. Our approach features a generalized time warping operator, which consists of linear combinations of continuous basis functions for facilitating continuous temporal warping. The integration of the proposed operator and the dictionary learning is formulated as an optimization problem, where the block coordinate descent method is employed to jointly optimize warping paths, dictionaries, and sparseness coefficients. The optimized results are then used as hy
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#20284;&#28982;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35266;&#27979;&#27169;&#22411;&#19979;&#35299;&#20915;A-&#26368;&#20248;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#26080;&#38656;&#23545;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#25110;&#31215;&#20998;&#12290;</title><link>http://arxiv.org/abs/2306.17615</link><description>&lt;p&gt;
&#26080;&#38656;&#23545;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Scalable method for Bayesian experimental design without integrating over posterior distribution. (arXiv:2306.17615v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17615
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#20284;&#28982;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35266;&#27979;&#27169;&#22411;&#19979;&#35299;&#20915;A-&#26368;&#20248;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#26080;&#38656;&#23545;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#25110;&#31215;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35266;&#27979;&#27169;&#22411;&#20013;&#27714;&#35299;A-&#26368;&#20248;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#26102;&#30340;&#35745;&#31639;&#25928;&#29575;&#38382;&#39064;&#65292;&#30001;&#20110;&#38656;&#35201;&#35745;&#31639;&#22797;&#26434;&#65292;A-&#26368;&#20248;&#24615;&#26159;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#12289;&#26131;&#20110;&#35299;&#37322;&#30340;&#26631;&#20934;&#12290;&#35813;&#26631;&#20934;&#36890;&#36807;&#26368;&#23567;&#21270;&#39044;&#26399;&#26465;&#20214;&#26041;&#24046;&#65292;&#20063;&#31216;&#20026;&#39044;&#26399;&#21518;&#39564;&#26041;&#24046;&#65292;&#26469;&#23547;&#27714;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#12290;&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#20284;&#28982;&#26041;&#27861;&#65292;&#29992;&#20110;&#23547;&#25214;A-&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#65292;&#32780;&#26080;&#38656;&#23545;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#25110;&#31215;&#20998;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#24635;&#26041;&#24046;&#23450;&#29702;&#65292;&#36890;&#36807;&#26465;&#20214;&#26399;&#26395;&#30340;&#26041;&#24046;&#26469;&#33719;&#24471;&#39044;&#26399;&#26465;&#20214;&#26041;&#24046;&#65292;&#21516;&#26102;&#21033;&#29992;&#27491;&#20132;&#25237;&#24433;&#24615;&#36136;&#26469;&#36817;&#20284;&#26465;&#20214;&#26399;&#26395;&#12290;&#36890;&#36807;&#28176;&#36817;&#35823;&#24046;&#20272;&#35745;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21518;&#39564;&#19981;&#21487;&#35745;&#31639;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the computational efficiency in solving the A-optimal Bayesian design of experiments problems for which the observational model is based on partial differential equations and, consequently, is computationally expensive to evaluate. A-optimality is a widely used and easy-to-interpret criterion for the Bayesian design of experiments. The criterion seeks the optimal experiment design by minimizing the expected conditional variance, also known as the expected posterior variance. This work presents a novel likelihood-free method for seeking the A-optimal design of experiments without sampling or integrating the Bayesian posterior distribution. In our approach, the expected conditional variance is obtained via the variance of the conditional expectation using the law of total variance, while we take advantage of the orthogonal projection property to approximate the conditional expectation. Through an asymptotic error estimation, we show that the intractability of the posterior doe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20026;&#26426;&#22120;&#23398;&#20064;&#30340;&#23494;&#24230;&#27867;&#20989;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35268;&#33539;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#38750;&#30456;&#20114;&#20316;&#29992;&#21160;&#33021;&#27867;&#20989;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23494;&#24230;&#27867;&#20989;&#35757;&#32451;&#65292;&#21462;&#24471;&#20102;&#22312;&#19968;&#32500;&#31995;&#32479;&#19978;&#30340;&#20248;&#31168;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.17587</link><description>&lt;p&gt;
&#29992;&#21464;&#20998;&#21407;&#29702;&#26469;&#35268;&#33539;&#26426;&#22120;&#23398;&#20064;&#30340;&#23494;&#24230;&#27867;&#20989;&#65306;&#38750;&#30456;&#20114;&#20316;&#29992;&#21160;&#33021;&#27867;&#20989;
&lt;/p&gt;
&lt;p&gt;
Variational principle to regularize machine-learned density functionals: the non-interacting kinetic-energy functional. (arXiv:2306.17587v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;&#26426;&#22120;&#23398;&#20064;&#30340;&#23494;&#24230;&#27867;&#20989;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35268;&#33539;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#38750;&#30456;&#20114;&#20316;&#29992;&#21160;&#33021;&#27867;&#20989;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23494;&#24230;&#27867;&#20989;&#35757;&#32451;&#65292;&#21462;&#24471;&#20102;&#22312;&#19968;&#32500;&#31995;&#32479;&#19978;&#30340;&#20248;&#31168;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770; (DFT) &#30340;&#25104;&#21151;&#24402;&#21151;&#20110; Kohn &#21644; Sham &#30340;&#24320;&#21019;&#24615;&#24037;&#20316;&#65292;&#20182;&#20204;&#24341;&#20837;&#20102;&#20351;&#29992;&#36741;&#21161;&#22343;&#22330;&#31995;&#32479;&#35745;&#31639;&#38750;&#30456;&#20114;&#20316;&#29992;&#21160;&#33021;&#30340;&#20934;&#30830;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;DFT &#30340;&#20840;&#37096;&#28508;&#21147;&#23558;&#26080;&#27861;&#37322;&#25918;&#65292;&#30452;&#21040;&#25214;&#21040;&#30005;&#23376;&#23494;&#24230;&#19982;&#38750;&#30456;&#20114;&#20316;&#29992;&#21160;&#33021;&#20043;&#38388;&#30340;&#20934;&#30830;&#20851;&#31995;&#12290;&#24050;&#32463;&#23581;&#35797;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#36817;&#20284;&#36825;&#20010;&#27867;&#20989;&#65292;&#31867;&#20284;&#20110;&#20132;&#25442;&#20851;&#32852;&#27867;&#20989;&#65292;&#20294;&#30001;&#20110;&#21160;&#33021;&#30340;&#36129;&#29486;&#26356;&#22823;&#19988;&#26356;&#38750;&#23616;&#22495;&#65292;&#25104;&#21151;&#31243;&#24230;&#36739;&#20302;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#35268;&#33539;&#26041;&#27861;&#65292;&#20197;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20026;&#22522;&#30784;&#26469;&#35757;&#32451;&#23494;&#24230;&#27867;&#20989;&#65292;&#23588;&#20854;&#26159;&#21160;&#33021;&#27867;&#20989;&#12290;&#35813;&#26041;&#27861;&#22312;&#65288;&#26377;&#25928;&#30340;&#65289;&#19968;&#32500;&#31995;&#32479;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#21253;&#25324;&#27682;&#38142;&#12289;&#38750;&#30456;&#20114;&#20316;&#29992;&#30005;&#23376;&#21644;&#21069;&#20004;&#20010;&#21608;&#26399;&#20803;&#32032;&#30340;&#21407;&#23376;&#65292;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Practical density functional theory (DFT) owes its success to the groundbreaking work of Kohn and Sham that introduced the exact calculation of the non-interacting kinetic energy of the electrons using an auxiliary mean-field system. However, the full power of DFT will not be unleashed until the exact relationship between the electron density and the non-interacting kinetic energy is found. Various attempts have been made to approximate this functional, similar to the exchange--correlation functional, with much less success due to the larger contribution of kinetic energy and its more non-local nature. In this work we propose a new and efficient regularization method to train density functionals based on deep neural networks, with particular interest in the kinetic-energy functional. The method is tested on (effectively) one-dimensional systems, including the hydrogen chain, non-interacting electrons, and atoms of the first two periods, with excellent results. For the atomic systems, t
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#22240;&#26524;&#19981;&#20805;&#20998;&#30340;&#24773;&#20917;&#19979;&#30340;&#20849;&#21516;&#21407;&#22240;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#24191;&#20041;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#26469;&#35782;&#21035;&#20849;&#21516;&#21407;&#22240;C&#65292;&#19982;&#26368;&#22823;&#29109;&#21407;&#21017;&#23494;&#20999;&#30456;&#20851;&#12290;&#23545;&#20110;&#20004;&#20010;&#20108;&#20803;&#23545;&#31216;&#21464;&#37327;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#31867;&#20284;&#20110;&#20108;&#38454;&#30456;&#21464;&#30340;&#26465;&#20214;&#27010;&#29575;&#38750;&#35299;&#26512;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.17557</link><description>&lt;p&gt;
&#26368;&#21487;&#33021;&#30340;&#20849;&#21516;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
The most likely common cause. (arXiv:2306.17557v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17557
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22240;&#26524;&#19981;&#20805;&#20998;&#30340;&#24773;&#20917;&#19979;&#30340;&#20849;&#21516;&#21407;&#22240;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#24191;&#20041;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#26469;&#35782;&#21035;&#20849;&#21516;&#21407;&#22240;C&#65292;&#19982;&#26368;&#22823;&#29109;&#21407;&#21017;&#23494;&#20999;&#30456;&#20851;&#12290;&#23545;&#20110;&#20004;&#20010;&#20108;&#20803;&#23545;&#31216;&#21464;&#37327;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#31867;&#20284;&#20110;&#20108;&#38454;&#30456;&#21464;&#30340;&#26465;&#20214;&#27010;&#29575;&#38750;&#35299;&#26512;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;A&#21644;B&#30340;&#20849;&#21516;&#21407;&#22240;&#21407;&#21017;&#22312;&#22240;&#26524;&#19981;&#20805;&#20998;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24403;&#23427;&#20204;&#30340;&#20849;&#21516;&#21407;&#22240;C&#34987;&#35748;&#20026;&#24050;&#32463;&#23384;&#22312;&#65292;&#20294;&#21482;&#35266;&#27979;&#21040;&#20102;A&#21644;B&#30340;&#32852;&#21512;&#27010;&#29575;&#12290;&#22240;&#27492;&#65292;C&#19981;&#33021;&#34987;&#21807;&#19968;&#30830;&#23450;&#65288;&#28508;&#22312;&#28151;&#26434;&#22240;&#23376;&#38382;&#39064;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24191;&#20041;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#36825;&#31181;&#24773;&#20917;&#65292;&#24182;&#19988;&#20801;&#35768;&#35782;&#21035;&#19982;&#20849;&#21516;&#21407;&#22240;&#21407;&#21017;&#19968;&#33268;&#30340;C&#12290;&#23427;&#19982;&#26368;&#22823;&#29109;&#21407;&#21017;&#23494;&#20999;&#30456;&#20851;&#12290;&#23545;&#20004;&#20010;&#20108;&#20803;&#23545;&#31216;&#21464;&#37327;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#26465;&#20214;&#27010;&#29575;&#30340;&#38750;&#35299;&#26512;&#34892;&#20026;&#65292;&#31867;&#20284;&#20110;&#20108;&#38454;&#30456;&#21464;&#12290;&#36825;&#21457;&#29983;&#22312;&#35266;&#23519;&#21040;&#30340;&#27010;&#29575;&#20998;&#24067;&#20174;&#30456;&#20851;&#21040;&#21453;&#30456;&#20851;&#30340;&#36807;&#28193;&#26399;&#38388;&#12290;&#35752;&#35770;&#20102;&#24191;&#20041;&#20284;&#28982;&#26041;&#27861;&#19982;&#20854;&#20182;&#26041;&#27861;&#65288;&#22914;&#39044;&#27979;&#20284;&#28982;&#21644;&#26368;&#23567;&#20849;&#21516;&#21407;&#22240;&#29109;&#65289;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
The common cause principle for two random variables $A$ and $B$ is examined in the case of causal insufficiency, when their common cause $C$ is known to exist, but only the joint probability of $A$ and $B$ is observed. As a result, $C$ cannot be uniquely identified (the latent confounder problem). We show that the generalized maximum likelihood method can be applied to this situation and allows identification of $C$ that is consistent with the common cause principle. It closely relates to the maximum entropy principle. Investigation of the two binary symmetric variables reveals a non-analytic behavior of conditional probabilities reminiscent of a second-order phase transition. This occurs during the transition from correlation to anti-correlation in the observed probability distribution. The relation between the generalized likelihood approach and alternative methods, such as predictive likelihood and the minimum common cause entropy, is discussed. The consideration of the common cause
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#36830;&#25509;&#32593;&#32476;&#36827;&#34892;&#39640;&#25928;&#32479;&#19968;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;RVFL&#32593;&#32476;&#21487;&#20197;&#36924;&#36817;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#20989;&#25968;&#65292;&#21069;&#25552;&#26159;&#38544;&#34255;&#23618;&#30456;&#23545;&#20110;&#36755;&#20837;&#32500;&#24230;&#26159;&#25351;&#25968;&#32423;&#23485;&#24230;&#30340;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#35777;&#26126;&#20102;$L_\infty$&#36924;&#36817;&#35823;&#24046;&#21644;&#39640;&#26031;&#20869;&#37096;&#26435;&#37325;&#26465;&#20214;&#19979;&#30340;&#32467;&#26524;&#65292;&#32473;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#30340;&#38544;&#34255;&#23618;&#33410;&#28857;&#25968;&#37327;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.17501</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#36830;&#25509;&#32593;&#32476;&#36827;&#34892;&#39640;&#25928;&#32479;&#19968;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Efficient uniform approximation using Random Vector Functional Link networks. (arXiv:2306.17501v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17501
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#36830;&#25509;&#32593;&#32476;&#36827;&#34892;&#39640;&#25928;&#32479;&#19968;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;RVFL&#32593;&#32476;&#21487;&#20197;&#36924;&#36817;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#20989;&#25968;&#65292;&#21069;&#25552;&#26159;&#38544;&#34255;&#23618;&#30456;&#23545;&#20110;&#36755;&#20837;&#32500;&#24230;&#26159;&#25351;&#25968;&#32423;&#23485;&#24230;&#30340;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#35777;&#26126;&#20102;$L_\infty$&#36924;&#36817;&#35823;&#24046;&#21644;&#39640;&#26031;&#20869;&#37096;&#26435;&#37325;&#26465;&#20214;&#19979;&#30340;&#32467;&#26524;&#65292;&#32473;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#30340;&#38544;&#34255;&#23618;&#33410;&#28857;&#25968;&#37327;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#36830;&#25509;(RVFL)&#32593;&#32476;&#26159;&#19968;&#20010;&#20855;&#26377;&#38543;&#26426;&#20869;&#37096;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20108;&#23618;&#31070;&#32463;&#32593;&#32476;&#12290;&#30001;&#20110;&#36825;&#31181;&#26550;&#26500;&#21482;&#38656;&#35201;&#23398;&#20064;&#22806;&#37096;&#26435;&#37325;&#65292;&#23398;&#20064;&#36807;&#31243;&#21487;&#20197;&#31616;&#21270;&#20026;&#32447;&#24615;&#20248;&#21270;&#20219;&#21153;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#22256;&#25200;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;RVFL&#32593;&#32476;&#21487;&#20197;&#36924;&#36817;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#20989;&#25968;&#65292;&#21069;&#25552;&#26159;&#20854;&#38544;&#34255;&#23618;&#30456;&#23545;&#20110;&#36755;&#20837;&#32500;&#24230;&#26159;&#25351;&#25968;&#32423;&#23485;&#24230;&#30340;&#12290;&#23613;&#31649;&#20043;&#21069;&#24050;&#32463;&#35777;&#26126;&#20102;&#20197;$L_2$&#26041;&#24335;&#21487;&#20197;&#23454;&#29616;&#36825;&#26679;&#30340;&#36924;&#36817;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$L_\infty$&#36924;&#36817;&#35823;&#24046;&#21644;&#39640;&#26031;&#20869;&#37096;&#26435;&#37325;&#24773;&#20917;&#19979;&#30340;&#21487;&#34892;&#24615;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36825;&#26679;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#30340;&#38544;&#34255;&#23618;&#33410;&#28857;&#25968;&#37327;&#30340;&#19979;&#30028;&#65292;&#21462;&#20915;&#20110;&#30446;&#26631;&#20989;&#25968;&#30340;&#21033;&#26222;&#24076;&#33576;&#24120;&#25968;&#12289;&#26399;&#26395;&#30340;&#20934;&#30830;&#24230;&#21644;&#36755;&#20837;&#32500;&#24230;&#31561;&#22240;&#32032;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#26041;&#27861;&#26681;&#26893;&#20110;&#27010;&#29575;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Random Vector Functional Link (RVFL) network is a depth-2 neural network with random inner weights and biases. As only the outer weights of such architectures need to be learned, the learning process boils down to a linear optimization task, allowing one to sidestep the pitfalls of nonconvex optimization problems. In this paper, we prove that an RVFL with ReLU activation functions can approximate Lipschitz continuous functions provided its hidden layer is exponentially wide in the input dimension. Although it has been established before that such approximation can be achieved in $L_2$ sense, we prove it for $L_\infty$ approximation error and Gaussian inner weights. To the best of our knowledge, our result is the first of this kind. We give a nonasymptotic lower bound for the number of hidden layer nodes, depending on, among other things, the Lipschitz constant of the target function, the desired accuracy, and the input dimension. Our method of proof is rooted in probability theory an
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#38024;&#23545;&#38750;&#20809;&#28369;&#21644;&#20809;&#28369;&#30446;&#26631;&#30340;&#26080;&#35270;&#35273;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.17470</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#29305;&#24449;&#20540;&#20248;&#21270;&#38382;&#39064;&#30340;&#26080;&#35270;&#35273;&#38543;&#26426;&#22797;&#21512;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Oblivious Stochastic Composite Optimization Algorithm for Eigenvalue Optimization Problems. (arXiv:2306.17470v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#38024;&#23545;&#38750;&#20809;&#28369;&#21644;&#20809;&#28369;&#30446;&#26631;&#30340;&#26080;&#35270;&#35273;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20351;&#29992;&#38543;&#26426;&#21270;&#19968;&#38454;&#26041;&#27861;&#21644;&#38543;&#26426;&#24179;&#28369;&#35299;&#20915;&#22823;&#35268;&#27169;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#22522;&#20110;&#20114;&#34917;&#22797;&#21512;&#35774;&#32622;&#30340;&#26080;&#35270;&#35273;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#12290;&#19968;&#31181;&#31639;&#27861;&#35774;&#35745;&#29992;&#20110;&#38750;&#20809;&#28369;&#30446;&#26631;&#65292;&#32780;&#21152;&#36895;&#29256;&#26412;&#21017;&#36866;&#29992;&#20110;&#20809;&#28369;&#30446;&#26631;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#37117;&#19981;&#38656;&#35201;&#23545;&#30446;&#26631;&#20989;&#25968;&#30340;Lipschitz&#24120;&#25968;&#25110;&#20809;&#28369;&#24230;&#26377;&#20808;&#39564;&#30693;&#35782;&#12290;&#23545;&#20110;&#20855;&#26377;$\mathcal{M}-$&#26377;&#30028;&#39044;&#35328;&#30340;&#38750;&#20809;&#28369;&#24773;&#20917;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#20026;$ O( {\mathcal{M}}/{\sqrt{T}} ) $&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#23545;&#20110;&#20855;&#26377;&#30001;$D$&#38480;&#21046;&#30340;&#21487;&#34892;&#38598;&#30340;$L$-&#20809;&#28369;&#24773;&#20917;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#20026;$ O( {L^2 D^2}/{(T^{2}\sqrt{T})} + {(D_0^2+\sigma^2)}/{\sqrt{T}} )$&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$D_0$&#26159;&#21040;&#26368;&#20248;&#35299;&#30340;&#36215;&#22987;&#36317;&#31163;&#65292;$ \sigma^2$&#26159;&#38543;&#26426;&#39044;&#35328;&#26041;&#24046;&#12290;&#30446;&#21069;&#21482;&#26377;&#22312;&#20551;&#35774;&#20808;&#39564;&#30693;&#35782;&#30340;Lipschitz&#24120;&#25968;&#25110;t&#24773;&#20917;&#19979;&#25165;&#33021;&#24471;&#21040;&#36825;&#20123;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we revisit the problem of solving large-scale semidefinite programs using randomized first-order methods and stochastic smoothing. We introduce two oblivious stochastic mirror descent algorithms based on a complementary composite setting. One algorithm is designed for non-smooth objectives, while an accelerated version is tailored for smooth objectives. Remarkably, both algorithms work without prior knowledge of the Lipschitz constant or smoothness of the objective function. For the non-smooth case with $\mathcal{M}-$bounded oracles, we prove a convergence rate of $ O( {\mathcal{M}}/{\sqrt{T}} ) $. For the $L$-smooth case with a feasible set bounded by $D$, we derive a convergence rate of $ O( {L^2 D^2}/{(T^{2}\sqrt{T})} + {(D_0^2+\sigma^2)}/{\sqrt{T}} )$, where $D_0$ is the starting distance to an optimal solution, and $ \sigma^2$ is the stochastic oracle variance. These rates had only been obtained so far by either assuming prior knowledge of the Lipschitz constant or t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21452;&#21464;&#37327;&#22522;&#20110;&#26799;&#24230;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#35777;&#26126;&#19968;&#31181;&#36335;&#24452;&#36319;&#36394;&#20248;&#21270;&#31639;&#27861;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#25552;&#20379;&#20102;&#35813;&#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.17378</link><description>&lt;p&gt;
&#21452;&#21464;&#37327;&#22522;&#20110;&#26799;&#24230;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#23398;&#20064;&#20013;&#30340;&#20840;&#23616;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Global Optimality in Bivariate Gradient-based DAG Learning. (arXiv:2306.17378v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21452;&#21464;&#37327;&#22522;&#20110;&#26799;&#24230;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#35777;&#26126;&#19968;&#31181;&#36335;&#24452;&#36319;&#36394;&#20248;&#21270;&#31639;&#27861;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#25552;&#20379;&#20102;&#35813;&#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#19968;&#31867;&#26032;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#21463;&#21040;&#20102;&#23398;&#26415;&#30028;&#30340;&#20851;&#27880;&#65292;&#23427;&#28304;&#20110;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#26080;&#29615;&#26377;&#21521;&#22270;&#27169;&#22411;&#30340;&#32479;&#35745;&#38382;&#39064;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#26041;&#27861;&#20351;&#29992;&#26631;&#20934;&#30340;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#30340;&#20840;&#23616;&#26368;&#20248;&#24615;&#19968;&#30452;&#26159;&#22256;&#38590;&#30340;&#12290;&#38382;&#39064;&#30340;&#38590;&#28857;&#22312;&#20110;&#65292;&#19982;&#25991;&#29486;&#20013;&#30340;&#20854;&#20182;&#38750;&#20984;&#38382;&#39064;&#19981;&#21516;&#65292;&#36825;&#20010;&#38382;&#39064;&#24182;&#19981;&#26159;"&#33391;&#24615;"&#30340;&#65292;&#24182;&#19988;&#23384;&#22312;&#30528;&#22810;&#20010;&#34394;&#20551;&#35299;&#65292;&#26631;&#20934;&#26041;&#27861;&#24456;&#23481;&#26131;&#38519;&#20837;&#20854;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36335;&#24452;&#36319;&#36394;&#20248;&#21270;&#31639;&#27861;&#22312;&#21452;&#21464;&#37327;&#24773;&#20917;&#19979;&#20250;&#20840;&#23616;&#25910;&#25947;&#21040;&#24635;&#20307;&#25439;&#22833;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, a new class of non-convex optimization problems motivated by the statistical problem of learning an acyclic directed graphical model from data has attracted significant interest. While existing work uses standard first-order optimization schemes to solve this problem, proving the global optimality of such approaches has proven elusive. The difficulty lies in the fact that unlike other non-convex problems in the literature, this problem is not "benign", and possesses multiple spurious solutions that standard approaches can easily get trapped in. In this paper, we prove that a simple path-following optimization scheme globally converges to the global minimum of the population loss in the bivariate setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;R-PLS&#30340;&#25216;&#26415;&#65292;&#23427;&#26159;PLS&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#29992;&#20110;&#20998;&#26512;&#21151;&#33021;&#36830;&#25509;&#32452;&#65292;&#24182;&#32771;&#34385;&#20102;&#21151;&#33021;&#36830;&#25509;&#30697;&#38453;&#30340;&#27491;&#23450;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2306.17371</link><description>&lt;p&gt;
&#20351;&#29992;Riemannian&#20559;&#26368;&#23567;&#20108;&#20056;&#27861;&#25429;&#33719;&#21151;&#33021;&#36830;&#25509;&#32452;&#23398;
&lt;/p&gt;
&lt;p&gt;
Capturing functional connectomics using Riemannian partial least squares. (arXiv:2306.17371v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17371
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;R-PLS&#30340;&#25216;&#26415;&#65292;&#23427;&#26159;PLS&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#29992;&#20110;&#20998;&#26512;&#21151;&#33021;&#36830;&#25509;&#32452;&#65292;&#24182;&#32771;&#34385;&#20102;&#21151;&#33021;&#36830;&#25509;&#30697;&#38453;&#30340;&#27491;&#23450;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#31070;&#32463;&#23398;&#30142;&#30149;&#21644;&#30142;&#30149;&#65292;&#20154;&#33041;&#30340;&#21151;&#33021;&#21644;&#35299;&#21078;&#36830;&#25509;&#32452;&#21487;&#20197;&#29992;&#20110;&#26356;&#22909;&#22320;&#25351;&#23548;&#26377;&#38024;&#23545;&#24615;&#30340;&#24178;&#39044;&#21644;&#27835;&#30103;&#31574;&#30053;&#12290;&#21151;&#33021;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;fMRI&#65289;&#26159;&#19968;&#31181;&#38750;&#20405;&#20837;&#24615;&#30340;&#31070;&#32463;&#25104;&#20687;&#25216;&#26415;&#65292;&#21487;&#20197;&#36890;&#36807;&#26102;&#38388;&#20869;&#30340;&#34880;&#27969;&#26469;&#25429;&#25417;&#33041;&#21151;&#33021;&#30340;&#26102;&#31354;&#29305;&#24449;&#12290;fMRI&#21487;&#20197;&#36890;&#36807;&#21151;&#33021;&#36830;&#25509;&#30697;&#38453;&#26469;&#30740;&#31350;&#21151;&#33021;&#36830;&#25509;&#32452;&#65292;&#21363;fMRI&#22270;&#20687;&#20013;&#24863;&#20852;&#36259;&#21306;&#22495;&#30340;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;Pearson&#30456;&#20851;&#31995;&#25968;&#30697;&#38453;&#12290;&#20998;&#26512;&#21151;&#33021;&#36830;&#25509;&#30340;&#19968;&#31181;&#26041;&#27861;&#26159;&#20351;&#29992;&#20559;&#26368;&#23567;&#20108;&#20056;&#27861;&#65288;PLS&#65289;&#65292;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#39044;&#27979;&#21464;&#37327;&#30340;&#22810;&#20803;&#22238;&#24402;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;PLS&#20998;&#26512;&#21151;&#33021;&#36830;&#25509;&#24573;&#30053;&#20102;&#21151;&#33021;&#36830;&#25509;&#30697;&#38453;&#30340;&#19968;&#20010;&#37325;&#35201;&#23646;&#24615;&#65292;&#21363;&#36825;&#20123;&#30697;&#38453;&#26159;&#27491;&#23450;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Riemannian&#27969;&#24418;&#19978;&#30340;PLS&#30340;&#25512;&#24191;&#65292;&#31216;&#20026;R-PLS&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30340;&#36830;&#25509;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
For neurological disorders and diseases, functional and anatomical connectomes of the human brain can be used to better inform targeted interventions and treatment strategies. Functional magnetic resonance imaging (fMRI) is a non-invasive neuroimaging technique that captures spatio-temporal brain function through blood flow over time. FMRI can be used to study the functional connectome through the functional connectivity matrix; that is, Pearson's correlation matrix between time series from the regions of interest of an fMRI image. One approach to analysing functional connectivity is using partial least squares (PLS), a multivariate regression technique designed for high-dimensional predictor data. However, analysing functional connectivity with PLS ignores a key property of the functional connectivity matrix; namely, these matrices are positive definite. To account for this, we introduce a generalisation of PLS to Riemannian manifolds, called R-PLS, and apply it to symmetric positive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35782;&#21035;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#22240;&#26524;&#26426;&#21046;&#36716;&#21464;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19987;&#27880;&#20110;&#22312;&#30456;&#20851;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35782;&#21035;&#21151;&#33021;&#26426;&#21046;&#30340;&#21464;&#21270;&#65292;&#32780;&#19981;&#38656;&#35201;&#20272;&#35745;&#25972;&#20010;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2306.17361</link><description>&lt;p&gt;
iSCAN&#65306;&#35782;&#21035;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#30340;&#22240;&#26524;&#26426;&#21046;&#36716;&#21464;
&lt;/p&gt;
&lt;p&gt;
iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models. (arXiv:2306.17361v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35782;&#21035;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#22240;&#26524;&#26426;&#21046;&#36716;&#21464;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19987;&#27880;&#20110;&#22312;&#30456;&#20851;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35782;&#21035;&#21151;&#33021;&#26426;&#21046;&#30340;&#21464;&#21270;&#65292;&#32780;&#19981;&#38656;&#35201;&#20272;&#35745;&#25972;&#20010;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#65292;&#20197;&#34920;&#31034;&#22797;&#26434;&#31995;&#32479;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#30495;&#27491;&#30340;&#24213;&#23618;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#32467;&#26500;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#65292;&#24182;&#19988;&#20174;&#35266;&#27979;&#25968;&#25454;&#25110;&#24178;&#39044;&#25968;&#25454;&#20013;&#30830;&#23450;&#23427;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#26159;&#35782;&#21035;&#30456;&#20851;SCM&#20043;&#38388;&#30340;&#22240;&#26524;&#26426;&#21046;&#30340;&#21464;&#21270;(&#36716;&#21464;)&#32780;&#19981;&#26159;&#24674;&#22797;&#25972;&#20010;&#24213;&#23618;DAG&#32467;&#26500;&#12290;&#20363;&#23376;&#21253;&#25324;&#20998;&#26512;&#20581;&#24247;&#21644;&#30284;&#30151;&#24739;&#32773;&#20043;&#38388;&#30340;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#32467;&#26500;&#21464;&#21270;&#65292;&#25110;&#32773;&#22312;&#19981;&#21516;&#32454;&#32990;&#29615;&#22659;&#19979;&#29702;&#35299;&#29983;&#29289;&#36884;&#24452;&#30340;&#21464;&#21270;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#22312;&#30456;&#21516;&#30340;&#21464;&#37327;&#38598;&#19978;&#35782;&#21035;&#20004;&#20010;&#25110;&#22810;&#20010;&#30456;&#20851;SCM&#20013;&#30340;$\textit{&#21151;&#33021;}$&#26426;&#21046;&#36716;&#21464;&#65292;&#32780;&#19981;&#38656;&#35201;&#20272;&#35745;&#27599;&#20010;SCM&#30340;&#25972;&#20010;DAG&#32467;&#26500;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#20551;&#35774;&#20351;&#29992;&#20102;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#30340;&#32447;&#24615;&#27169;&#22411;&#65307;&#32780;&#26412;&#25991;&#20013;&#25105;&#20204;&#21017;&#32771;&#34385;&#20102;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structural causal models (SCMs) are widely used in various disciplines to represent causal relationships among variables in complex systems. Unfortunately, the true underlying directed acyclic graph (DAG) structure is often unknown, and determining it from observational or interventional data remains a challenging task. However, in many situations, the end goal is to identify changes (shifts) in causal mechanisms between related SCMs rather than recovering the entire underlying DAG structure. Examples include analyzing gene regulatory network structure changes between healthy and cancerous individuals or understanding variations in biological pathways under different cellular contexts. This paper focuses on identifying $\textit{functional}$ mechanism shifts in two or more related SCMs over the same set of variables -$\textit{without estimating the entire DAG structure of each SCM}$. Prior work under this setting assumed linear models with Gaussian noises; instead, in this work we ass
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#24212;&#29992;&#20110;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#23454;&#29616;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#20381;&#36182;&#20110;RKHS&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.17329</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#22312;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Kernel $\epsilon$-Greedy for Contextual Bandits. (arXiv:2306.17329v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17329
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#24212;&#29992;&#20110;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#23454;&#29616;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#20381;&#36182;&#20110;RKHS&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#33218;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35748;&#20026;&#24179;&#22343;&#22870;&#21169;&#20989;&#25968;&#20301;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22870;&#21169;&#20989;&#25968;&#30340;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#12290;&#22312;&#23545;&#25506;&#32034;&#27010;&#29575;&#24207;&#21015;$\{\epsilon_t\}_t$&#21644;&#27491;&#21017;&#21270;&#21442;&#25968;$\{\lambda_t\}_t$&#30340;&#19968;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#26680;&#21644;&#30456;&#24212;&#30340;RKHS&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#20381;&#36182;&#20110;RKHS&#20869;&#22312;&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#12290;&#27492;&#22806;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;$\sqrt{T}$&#30340;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a kernelized version of the $\epsilon$-greedy strategy for contextual bandits. More precisely, in a setting with finitely many arms, we consider that the mean reward functions lie in a reproducing kernel Hilbert space (RKHS). We propose an online weighted kernel ridge regression estimator for the reward functions. Under some conditions on the exploration probability sequence, $\{\epsilon_t\}_t$, and choice of the regularization parameter, $\{\lambda_t\}_t$, we show that the proposed estimator is consistent. We also show that for any choice of kernel and the corresponding RKHS, we achieve a sub-linear regret rate depending on the intrinsic dimensionality of the RKHS. Furthermore, we achieve the optimal regret rate of $\sqrt{T}$ under a margin condition for finite-dimensional RKHS.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#25506;&#35752;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#37325;&#28857;&#26159;&#36890;&#36807;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#30340;&#35889;&#20998;&#26512;&#26469;&#29702;&#35299;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2306.17301</link><description>&lt;p&gt;
&#27973;&#23618;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65306;&#19968;&#20010;&#25968;&#20540;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Why Shallow Networks Struggle with Approximating and Learning High Frequency: A Numerical Study. (arXiv:2306.17301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#25506;&#35752;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#37325;&#28857;&#26159;&#36890;&#36807;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#30340;&#35889;&#20998;&#26512;&#26469;&#29702;&#35299;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#20998;&#26512;&#21644;&#23454;&#39564;&#30340;&#32508;&#21512;&#25968;&#20540;&#30740;&#31350;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#26426;&#22120;&#31934;&#24230;&#21644;&#35745;&#31639;&#25104;&#26412;&#31561;&#23454;&#38469;&#22240;&#32032;&#20013;&#65292;&#22788;&#29702;&#39640;&#39057;&#29575;&#30340;&#36924;&#36817;&#21644;&#23398;&#20064;&#23384;&#22312;&#22256;&#38590;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30740;&#31350;&#20102;&#20197;&#19979;&#22522;&#26412;&#35745;&#31639;&#38382;&#39064;&#65306;&#65288;1&#65289;&#22312;&#26377;&#38480;&#30340;&#26426;&#22120;&#31934;&#24230;&#19979;&#21487;&#20197;&#36798;&#21040;&#30340;&#26368;&#20339;&#31934;&#24230;&#65292;&#65288;2&#65289;&#23454;&#29616;&#32473;&#23450;&#31934;&#24230;&#25152;&#38656;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#20197;&#21450;&#65288;3&#65289;&#23545;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#30740;&#31350;&#30340;&#20851;&#38190;&#26159;&#30456;&#24212;&#28608;&#27963;&#20989;&#25968;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#30340;&#35889;&#20998;&#26512;&#65292;&#35813;&#20998;&#26512;&#36824;&#26174;&#31034;&#20102;&#28608;&#27963;&#20989;&#25968;&#23646;&#24615;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, a comprehensive numerical study involving analysis and experiments shows why a two-layer neural network has difficulties handling high frequencies in approximation and learning when machine precision and computation cost are important factors in real practice. In particular, the following fundamental computational issues are investigated: (1) the best accuracy one can achieve given a finite machine precision, (2) the computation cost to achieve a given accuracy, and (3) stability with respect to perturbations. The key to the study is the spectral analysis of the corresponding Gram matrix of the activation functions which also shows how the properties of the activation function play a role in the picture.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#20855;&#26377;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#25910;&#25947;&#36895;&#24230;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16932</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
A Quantitative Functional Central Limit Theorem for Shallow Neural Networks. (arXiv:2306.16932v1 [math.PR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16932
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#20855;&#26377;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#25910;&#25947;&#36895;&#24230;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20855;&#26377;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#25105;&#20204;&#24314;&#31435;&#30340;&#25910;&#25947;&#36895;&#24230;&#20005;&#37325;&#20381;&#36182;&#20110;&#28608;&#27963;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#65292;&#20174;&#38750;&#21487;&#24494;&#30340;&#24773;&#20917;&#65288;&#22914;Relu&#65289;&#30340;&#23545;&#25968;&#32423;&#21035;&#21040;&#38750;&#24120;&#35268;&#21017;&#28608;&#27963;&#20989;&#25968;&#30340;$\sqrt{n}$&#32423;&#21035;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#24037;&#20855;&#26159;Stein-Malliavin&#26041;&#27861;&#30340;&#20989;&#25968;&#29256;&#26412;&#65307;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#22823;&#37327;&#21033;&#29992;&#20102;Bourguin&#21644;Campese&#65288;2020&#65289;&#26368;&#36817;&#24314;&#31435;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a Quantitative Functional Central Limit Theorem for one-hidden-layer neural networks with generic activation function. The rates of convergence that we establish depend heavily on the smoothness of the activation function, and they range from logarithmic in non-differentiable cases such as the Relu to $\sqrt{n}$ for very regular activations. Our main tools are functional versions of the Stein-Malliavin approach; in particular, we exploit heavily a quantitative functional central limit theorem which has been recently established by Bourguin and Campese (2020).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#22312;&#23454;&#29616;&#35774;&#32622;&#19979;&#19981;&#31561;&#20215;&#65292;&#24182;&#23558;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#20316;&#20026;&#20854;&#29305;&#23450;&#23454;&#20363;&#12290;</title><link>http://arxiv.org/abs/2306.06247</link><description>&lt;p&gt;
&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Learning with Set-Valued Feedback. (arXiv:2306.06247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#22312;&#23454;&#29616;&#35774;&#32622;&#19979;&#19981;&#31561;&#20215;&#65292;&#24182;&#23558;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#20316;&#20026;&#20854;&#29305;&#23450;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#20854;&#20013;&#23398;&#20064;&#22120;&#39044;&#27979;&#21333;&#20010;&#26631;&#31614;&#65292;&#20294;&#25509;&#25910;&#21040;&#19968;&#20010;&#26631;&#31614;&#30340;&#38598;&#21512;&#20316;&#20026;&#21453;&#39304;&#12290;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#22914;&#26524;&#23398;&#20064;&#22120;&#27809;&#26377;&#36755;&#20986;&#21253;&#21547;&#22312;&#21453;&#39304;&#38598;&#21512;&#20013;&#30340;&#26631;&#31614;&#65292;&#21017;&#20250;&#21463;&#21040;&#24809;&#32602;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#19982;&#20855;&#26377;&#21333;&#26631;&#31614;&#21453;&#39304;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#19981;&#21516;&#65292;&#22312;&#23454;&#29616;&#35774;&#32622;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#26102;&#65292;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#21270;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;\textit{&#19981;&#31561;&#20215;}&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#20998;&#21035;&#21629;&#21517;&#20026;&#38598;&#21512;&#23567;&#30707;&#21644;&#24230;&#37327;&#30772;&#35010;&#32500;&#24230;&#65292;&#20005;&#26684;&#25551;&#36848;&#20102;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#21270;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#24230;&#37327;&#30772;&#35010;&#32500;&#24230;&#22312;&#24735;&#24615;&#35774;&#32622;&#19979;&#20005;&#26684;&#25551;&#36848;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#26159;&#25105;&#20204;&#36890;&#29992;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#30340;&#20855;&#20307;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a variant of online multiclass classification where the learner predicts a single label but receives a \textit{set of labels} as feedback. In this model, the learner is penalized for not outputting a label contained in the revealed set. We show that unlike online multiclass learning with single-label feedback, deterministic and randomized online learnability are \textit{not equivalent} even in the realizable setting with set-valued feedback. Accordingly, we give two new combinatorial dimensions, named the Set Littlestone and Measure Shattering dimension, that tightly characterize deterministic and randomized online learnability respectively in the realizable setting. In addition, we show that the Measure Shattering dimension tightly characterizes online learnability in the agnostic setting. Finally, we show that practical learning settings like online multilabel ranking and online multilabel classification are specific instances of our general online learning framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ReLU&#21333;&#20803;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#30340;&#35268;&#33539;&#21270;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#20248;&#21270;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15912</link><description>&lt;p&gt;
&#25913;&#36827;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#30340;&#31070;&#32463;&#29305;&#24449;&#28608;&#27963;&#20540;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning. (arXiv:2305.15912v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ReLU&#21333;&#20803;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#30340;&#35268;&#33539;&#21270;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#20248;&#21270;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#21333;&#20010;ReLU&#21333;&#20803;&#30340;&#29305;&#24449;&#28608;&#27963;&#20540;&#12290;&#25105;&#20204;&#23558;ReLU&#21333;&#20803;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#23545;&#24212;&#30340;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#31216;&#20026;ReLU&#21333;&#20803;&#30340;&#29305;&#24449;&#28608;&#27963;&#38598;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#29305;&#24449;&#28608;&#27963;&#38598;&#19982;ReLU&#32593;&#32476;&#20013;&#23398;&#20064;&#29305;&#24449;&#20043;&#38388;&#30340;&#26126;&#30830;&#32852;&#31995;&#65292;&#24182;&#25581;&#31034;&#20102;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#20351;&#29992;&#30340;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#35268;&#33539;&#21270;&#25216;&#26415;&#22914;&#20309;&#35268;&#33539;&#21270;&#21644;&#31283;&#23450;SGD&#20248;&#21270;&#12290;&#21033;&#29992;&#36825;&#20123;&#27934;&#35265;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20960;&#20309;&#26041;&#27861;&#26469;&#21442;&#25968;&#21270;ReLU&#32593;&#32476;&#20197;&#25913;&#36827;&#29305;&#24449;&#23398;&#20064;&#12290;&#25105;&#20204;&#32463;&#39564;&#24615;&#22320;&#39564;&#35777;&#20102;&#20854;&#26377;&#29992;&#24615;&#65292;&#20351;&#29992;&#20102;&#19981;&#37027;&#20040;&#31934;&#24515;&#36873;&#25321;&#30340;&#21021;&#22987;&#21270;&#26041;&#26696;&#21644;&#26356;&#22823;&#30340;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#26356;&#22909;&#30340;&#20248;&#21270;&#31283;&#23450;&#24615;&#65292;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the characteristic activation values of individual ReLU units in neural networks. We refer to the corresponding set for such characteristic activation values in the input space as the characteristic activation set of a ReLU unit. We draw an explicit connection between the characteristic activation set and learned features in ReLU networks. This connection leads to new insights into why various neural network normalization techniques used in modern deep learning architectures regularize and stabilize SGD optimization. Utilizing these insights, we propose a geometric approach to parameterize ReLU networks for improved feature learning. We empirically verify its usefulness with less carefully chosen initialization schemes and larger learning rates. We report improved optimization stability, faster convergence speed, and better generalization performance.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#27169;&#22411;&#36873;&#25321;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#20854;&#36716;&#31227;&#36317;&#31163;&#20250;&#24433;&#21709;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21487;&#33021;&#23548;&#33268;&#36895;&#29575;&#36739;&#24930;&#12290;</title><link>http://arxiv.org/abs/2305.00152</link><description>&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#19979;&#30340;&#27169;&#22411;&#36873;&#25321;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#27169;&#22411;&#36873;&#25321;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#20854;&#36716;&#31227;&#36317;&#31163;&#20250;&#24433;&#21709;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21487;&#33021;&#23548;&#33268;&#36895;&#29575;&#36739;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#20851;&#20110;&#36716;&#31227;&#23398;&#20064;&#25110;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#29702;&#35770;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#24050;&#30693;&#20551;&#35774;&#31867;&#25110;&#27169;&#22411;&#30340;&#24773;&#20917;&#65307;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36890;&#24120;&#28041;&#21450;&#19968;&#23450;&#31243;&#24230;&#30340;&#27169;&#22411;&#36873;&#25321;&#65292;&#36825;&#32463;&#24120;&#20986;&#29616;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#24635;&#20307;&#33539;&#30068;&#19979;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#21487;&#20197;&#32771;&#34385;&#35843;&#25972;&#38024;&#23545;&#30446;&#26631;&#20219;&#21153;&#30340;&#27491;&#30830;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#21033;&#29992;&#26469;&#33258;&#30456;&#20851;&#28304;&#20219;&#21153;&#30340;&#25968;&#25454;&#12290;&#38500;&#20102;&#19982;&#27169;&#22411;&#36873;&#25321;&#26377;&#20851;&#30340;&#36817;&#20284;&#19982;&#20272;&#35745;&#35823;&#24046;&#30340;&#36890;&#24120;&#26435;&#34913;&#20043;&#22806;&#65292;&#36825;&#20010;&#38382;&#39064;&#36824;&#24102;&#26469;&#20102;&#26032;&#30340;&#22797;&#26434;&#24230;&#65292;&#21363;&#28304;&#20998;&#24067;&#19982;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#36716;&#31227;&#36317;&#31163;&#65292;&#36825;&#20010;&#36317;&#31163;&#38543;&#30528;&#20551;&#35774;&#31867;&#30340;&#36873;&#25321;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#20998;&#31867;&#38382;&#39064;&#12290;&#29305;&#21035;&#30340;&#65292;&#20998;&#26512;&#25581;&#31034;&#20102;&#19968;&#20123;&#24341;&#20154;&#27880;&#30446;&#30340;&#29616;&#35937;&#65306;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21363;&#27809;&#26377;&#20998;&#24067;&#24335;&#20449;&#24687;&#26102;&#21487;&#36798;&#21040;&#30340;&#36895;&#29575;&#65292;&#21487;&#20197;&#20219;&#24847;&#24930;&#20110;oracle&#36895;&#29575;&#65292;&#21363;&#22312;&#32473;&#23450;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical studies on transfer learning or domain adaptation have so far focused on situations with a known hypothesis class or model; however in practice, some amount of model selection is usually involved, often appearing under the umbrella term of hyperparameter-tuning: for example, one may think of the problem of tuning for the right neural network architecture towards a target task, while leveraging data from a related source task.  Now, in addition to the usual tradeoffs on approximation vs estimation errors involved in model selection, this problem brings in a new complexity term, namely, the transfer distance between source and target distributions, which is known to vary with the choice of hypothesis class.  We present a first study of this problem, focusing on classification; in particular, the analysis reveals some remarkable phenomena: adaptive rates, i.e., those achievable with no distributional information, can be arbitrarily slower than oracle rates, i.e., when given kn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2304.05294</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#36873;&#25321;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#24378;&#20581;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Selecting Robust Features for Machine Learning Applications using Multidata Causal Discovery. (arXiv:2304.05294v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#20581;&#30340;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#21019;&#24314;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#39046;&#22495;&#30693;&#35782;&#26377;&#38480;&#12289;&#28508;&#22312;&#20132;&#20114;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#35774;&#35745;&#32479;&#35745;&#39044;&#27979;&#27169;&#22411;&#26102;&#65292;&#36873;&#25321;&#26368;&#20248;&#29305;&#24449;&#38598;&#36890;&#24120;&#24456;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#65288;M&#65289;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#24182;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;Tigramite Python&#21253;&#20013;&#23454;&#29616;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;PC1&#25110;PCMCI&#12290;&#36825;&#20123;&#31639;&#27861;&#21033;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#25512;&#26029;&#22240;&#26524;&#22270;&#30340;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#23558;&#21097;&#20313;&#22240;&#26524;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#20256;&#36882;&#32473;ML&#27169;&#22411;&#65288;&#22810;&#20803;&#32447;&#24615;&#22238;&#24402;&#65292;&#38543;&#26426;&#26862;&#26519;&#65289;&#39044;&#27979;&#30446;&#26631;&#20043;&#21069;&#65292;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#12290;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#39044;&#27979;&#35199;&#22826;&#24179;&#27915;&#28909;&#24102;&#22320;&#21306;&#30340;&#22320;&#38663;&#24378;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust feature selection is vital for creating reliable and interpretable Machine Learning (ML) models. When designing statistical prediction models in cases where domain knowledge is limited and underlying interactions are unknown, choosing the optimal set of features is often difficult. To mitigate this issue, we introduce a Multidata (M) causal feature selection approach that simultaneously processes an ensemble of time series datasets and produces a single set of causal drivers. This approach uses the causal discovery algorithms PC1 or PCMCI that are implemented in the Tigramite Python package. These algorithms utilize conditional independence tests to infer parts of the causal graph. Our causal feature selection approach filters out causally-spurious links before passing the remaining causal features as inputs to ML models (Multiple linear regression, Random Forest) that predict the targets. We apply our framework to the statistical intensity prediction of Western Pacific Tropical
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22266;&#23450;&#39044;&#31639;&#36172;&#21338;&#26426;&#26631;&#35782;&#20013;&#22797;&#26434;&#24230;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#35299;&#20915;Bernoulli&#20998;&#24067;&#26368;&#20339;&#33218;&#35782;&#21035;&#31561;&#20219;&#21153;&#26102;&#26080;&#27861;&#23454;&#29616;&#32479;&#19968;&#26368;&#20339;&#21487;&#36798;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.09468</link><description>&lt;p&gt;
&#22266;&#23450;&#39044;&#31639;&#36172;&#21338;&#26426;&#26631;&#35782;&#20013;&#30340;&#22797;&#26434;&#24230;&#23384;&#22312;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On the Existence of a Complexity in Fixed Budget Bandit Identification. (arXiv:2303.09468v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09468
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22266;&#23450;&#39044;&#31639;&#36172;&#21338;&#26426;&#26631;&#35782;&#20013;&#22797;&#26434;&#24230;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#35299;&#20915;Bernoulli&#20998;&#24067;&#26368;&#20339;&#33218;&#35782;&#21035;&#31561;&#20219;&#21153;&#26102;&#26080;&#27861;&#23454;&#29616;&#32479;&#19968;&#26368;&#20339;&#21487;&#36798;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22266;&#23450;&#39044;&#31639;&#36172;&#21338;&#26426;&#26631;&#35782;&#20013;&#65292;&#31639;&#27861;&#25353;&#39034;&#24207;&#35266;&#23519;&#26469;&#33258;&#22810;&#20010;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#30452;&#21040;&#32473;&#23450;&#26368;&#32456;&#26102;&#38388;&#12290;&#28982;&#21518;&#65292;&#23427;&#22238;&#31572;&#20851;&#20110;&#20998;&#24067;&#38598;&#30340;&#26597;&#35810;&#12290;&#19968;&#20010;&#22909;&#30340;&#31639;&#27861;&#23558;&#26377;&#23567;&#30340;&#38169;&#35823;&#27010;&#29575;&#12290;&#34429;&#28982;&#36825;&#20010;&#27010;&#29575;&#38543;&#30528;&#26368;&#32456;&#26102;&#38388;&#30340;&#22686;&#21152;&#21576;&#25351;&#25968;&#32423;&#19979;&#38477;&#65292;&#20294;&#23545;&#20110;&#22823;&#22810;&#25968;&#26631;&#35782;&#20219;&#21153;&#65292;&#26368;&#20339;&#21487;&#36798;&#29575;&#24182;&#38750;&#31934;&#30830;&#24050;&#30693;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#26524;&#22266;&#23450;&#39044;&#31639;&#20219;&#21153;&#25509;&#21463;&#22797;&#26434;&#24230;&#65288;&#23450;&#20041;&#20026;&#21333;&#20010;&#31639;&#27861;&#22312;&#25152;&#26377;&#36172;&#21338;&#38382;&#39064;&#20013;&#23454;&#29616;&#30340;&#38169;&#35823;&#27010;&#29575;&#30340;&#19979;&#38480;&#65289;&#65292;&#21017;&#35813;&#22797;&#26434;&#24230;&#30001;&#35813;&#38382;&#39064;&#30340;&#26368;&#20339;&#38750;&#33258;&#36866;&#24212;&#25277;&#26679;&#36807;&#31243;&#30830;&#23450;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20960;&#20010;&#22266;&#23450;&#39044;&#31639;&#35782;&#21035;&#20219;&#21153;&#65292;&#21253;&#25324;&#20855;&#26377;&#20004;&#20010;&#33218;&#30340;&#20271;&#21162;&#21033;&#26368;&#20339;&#33218;&#35782;&#21035;&#65292;&#19981;&#23384;&#22312;&#36825;&#26679;&#30340;&#22797;&#26434;&#24230;&#65306;&#27809;&#26377;&#21333;&#20010;&#31639;&#27861;&#33021;&#22815;&#38543;&#22788;&#23454;&#29616;&#26368;&#20339;&#21487;&#33021;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In fixed budget bandit identification, an algorithm sequentially observes samples from several distributions up to a given final time. It then answers a query about the set of distributions. A good algorithm will have a small probability of error. While that probability decreases exponentially with the final time, the best attainable rate is not known precisely for most identification tasks. We show that if a fixed budget task admits a complexity, defined as a lower bound on the probability of error which is attained by a single algorithm on all bandit problems, then that complexity is determined by the best non-adaptive sampling procedure for that problem. We show that there is no such complexity for several fixed budget identification tasks including Bernoulli best arm identification with two arms: there is no single algorithm that attains everywhere the best possible rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Fisher&#20449;&#24687;&#30340;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#26679;&#26412;&#20294;&#27880;&#37322;&#20026;one-hot&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35777;&#25454;&#23398;&#20064;&#36807;&#31243;&#34987;&#36807;&#24230;&#24809;&#32602;&#24182;&#21463;&#21040;&#38459;&#30861;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.02045</link><description>&lt;p&gt;
&#22522;&#20110;Fisher&#20449;&#24687;&#30340;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Estimation by Fisher Information-based Evidential Deep Learning. (arXiv:2303.02045v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Fisher&#20449;&#24687;&#30340;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#26679;&#26412;&#20294;&#27880;&#37322;&#20026;one-hot&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35777;&#25454;&#23398;&#20064;&#36807;&#31243;&#34987;&#36807;&#24230;&#24809;&#32602;&#24182;&#21463;&#21040;&#38459;&#30861;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a Fisher Information-based Evidential Deep Learning method to address the problem of over-penalization and hindrance in evidence learning for high data uncertainty samples annotated with one-hot labels.
&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26159;&#20351;&#28145;&#24230;&#23398;&#20064;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21487;&#38752;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#26368;&#36817;&#25552;&#20986;&#30340;&#35777;&#25454;&#31070;&#32463;&#32593;&#32476;&#36890;&#36807;&#23558;&#32593;&#32476;&#36755;&#20986;&#35270;&#20026;&#35777;&#25454;&#26469;&#21442;&#25968;&#21270;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#65292;&#26126;&#30830;&#32771;&#34385;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#22312;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#38754;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#26679;&#26412;&#20294;&#27880;&#37322;&#20026;one-hot&#26631;&#31614;&#30340;&#24773;&#20917;&#65292;&#36825;&#20123;&#38169;&#35823;&#26631;&#35760;&#30340;&#31867;&#21035;&#30340;&#35777;&#25454;&#23398;&#20064;&#36807;&#31243;&#20250;&#34987;&#36807;&#24230;&#24809;&#32602;&#24182;&#21463;&#21040;&#38459;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;Fisher&#20449;&#24687;&#30340;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;$\mathcal{I}$-EDL&#65289;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;Fisher&#20449;&#24687;&#30697;&#38453;&#65288;FIM&#65289;&#26469;&#34913;&#37327;&#27599;&#20010;&#26679;&#26412;&#25152;&#25658;&#24102;&#30340;&#35777;&#25454;&#30340;&#20449;&#24687;&#37327;&#65292;&#26681;&#25454;&#36825;&#20010;&#20449;&#24687;&#37327;&#65292;&#25105;&#20204;&#21487;&#20197;&#21160;&#24577;&#22320;&#37325;&#26032;&#21152;&#26435;&#30446;&#26631;&#25439;&#22833;&#39033;&#65292;&#20351;&#32593;&#32476;&#26356;&#21152;&#19987;&#27880;&#20110;&#19981;&#30830;&#23450;&#31867;&#21035;&#30340;&#34920;&#31034;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#36890;&#36807;&#20248;&#21270;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty estimation is a key factor that makes deep learning reliable in practical applications. Recently proposed evidential neural networks explicitly account for different uncertainties by treating the network's outputs as evidence to parameterize the Dirichlet distribution, and achieve impressive performance in uncertainty estimation. However, for high data uncertainty samples but annotated with the one-hot label, the evidence-learning process for those mislabeled classes is over-penalized and remains hindered. To address this problem, we propose a novel method, Fisher Information-based Evidential Deep Learning ($\mathcal{I}$-EDL). In particular, we introduce Fisher Information Matrix (FIM) to measure the informativeness of evidence carried by each sample, according to which we can dynamically reweight the objective loss terms to make the network more focused on the representation learning of uncertain classes. The generalization ability of our network is further improved by opt
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#23384;&#22312;&#26550;&#26500;&#35823;&#25351;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#21021;&#38454;ANIL&#21487;&#20197;&#25104;&#21151;&#23398;&#20064;&#21040;&#32447;&#24615;&#30340;&#20849;&#20139;&#34920;&#31034;&#12290;&#36825;&#20010;&#32467;&#26524;&#26159;&#22522;&#20110;&#23545;&#26080;&#38480;&#25968;&#37327;&#20219;&#21153;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#30340;&#25512;&#23548;&#12290;</title><link>http://arxiv.org/abs/2303.01335</link><description>&lt;p&gt;
&#21021;&#38454;ANIL&#22312;&#23384;&#22312;&#35823;&#25351;&#23450;&#30340;&#28508;&#22312;&#32500;&#24230;&#24773;&#20917;&#19979;&#23398;&#20064;&#32447;&#24615;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
First-order ANIL learns linear representations despite misspecified latent dimension. (arXiv:2303.01335v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#23384;&#22312;&#26550;&#26500;&#35823;&#25351;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#21021;&#38454;ANIL&#21487;&#20197;&#25104;&#21151;&#23398;&#20064;&#21040;&#32447;&#24615;&#30340;&#20849;&#20139;&#34920;&#31034;&#12290;&#36825;&#20010;&#32467;&#26524;&#26159;&#22522;&#20110;&#23545;&#26080;&#38480;&#25968;&#37327;&#20219;&#21153;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#30340;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#22312;&#23569;&#26679;&#26412;&#20998;&#31867;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#32463;&#39564;&#25104;&#21151;&#65292;&#20803;&#23398;&#20064;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20851;&#27880;&#12290;&#20803;&#23398;&#20064;&#26041;&#27861;&#21033;&#29992;&#26469;&#33258;&#20197;&#21069;&#20219;&#21153;&#30340;&#25968;&#25454;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#23398;&#20064;&#26032;&#20219;&#21153;&#12290;&#29305;&#21035;&#26159;&#65292;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#23547;&#25214;&#36215;&#22987;&#28857;&#65292;&#20174;&#35813;&#36215;&#22987;&#28857;&#24320;&#22987;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36805;&#36895;&#36866;&#24212;&#20219;&#20309;&#26032;&#20219;&#21153;&#12290;&#23613;&#31649;&#32463;&#39564;&#19978;&#24314;&#35758;&#36825;&#26679;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#26399;&#38388;&#23398;&#20064;&#20849;&#20139;&#34920;&#31034;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#23545;&#20110;&#36825;&#31181;&#34892;&#20026;&#30340;&#29702;&#35770;&#35777;&#25454;&#26377;&#38480;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#24182;&#27809;&#26377;&#20005;&#26684;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#22312;&#23384;&#22312;&#26550;&#26500;&#35823;&#25351;&#23450;&#30340;&#24773;&#20917;&#19979;&#20173;&#20250;&#23398;&#20064;&#21040;&#20849;&#20139;&#32467;&#26500;&#12290;&#22312;&#36825;&#20010;&#26041;&#21521;&#19978;&#65292;&#26412;&#25991;&#22312;&#26080;&#38480;&#25968;&#37327;&#30340;&#20219;&#21153;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#23637;&#31034;&#20102;&#65292;&#20351;&#29992;&#32447;&#24615;&#21452;&#23618;&#32593;&#32476;&#32467;&#26500;&#30340;&#21021;&#38454;ANIL&#25104;&#21151;&#22320;&#23398;&#20064;&#21040;&#20102;&#32447;&#24615;&#30340;&#20849;&#20139;&#34920;&#31034;&#12290;&#21363;&#20351;&#26159;&#22312;&#21442;&#25968;&#21270;&#35823;&#25351;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#32467;&#26524;&#20173;&#28982;&#25104;&#31435;&#65292;&#21363;&#32593;&#32476;&#30340;&#23485;&#24230;&#22823;&#20110;
&lt;/p&gt;
&lt;p&gt;
Due to its empirical success in few-shot classification and reinforcement learning, meta-learning has recently received significant interest. Meta-learning methods leverage data from previous tasks to learn a new task in a sample-efficient manner. In particular, model-agnostic methods look for initialisation points from which gradient descent quickly adapts to any new task. Although it has been empirically suggested that such methods perform well by learning shared representations during pretraining, there is limited theoretical evidence of such behavior. More importantly, it has not been rigorously shown that these methods still learn a shared structure, despite architectural misspecifications. In this direction, this work shows, in the limit of an infinite number of tasks, that first-order ANIL with a linear two-layer network architecture successfully learns linear shared representations. This result even holds with a misspecified network parameterisation; having a width larger than 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26679;&#26412;&#22806;&#20445;&#35777;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32771;&#34385;&#27169;&#22411;&#37197;&#32622;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#35266;&#23519;&#25968;&#25454;&#23545;&#20915;&#31574;&#31574;&#30053;&#30340;&#24615;&#33021;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2301.08649</link><description>&lt;p&gt;
&#20855;&#26377;&#26679;&#26412;&#22806;&#20445;&#35777;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation with Out-of-Sample Guarantees. (arXiv:2301.08649v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08649
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26679;&#26412;&#22806;&#20445;&#35777;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32771;&#34385;&#27169;&#22411;&#37197;&#32622;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#35266;&#23519;&#25968;&#25454;&#23545;&#20915;&#31574;&#31574;&#30053;&#30340;&#24615;&#33021;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#36807;&#21435;&#30340;&#35266;&#23519;&#25968;&#25454;&#35780;&#20272;&#20915;&#31574;&#31574;&#30053;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;&#31574;&#30053;&#30340;&#32467;&#26524;&#20197;&#25439;&#22833;&#65288;&#21363;&#22833;&#25928;&#25110;&#36127;&#22870;&#21169;&#65289;&#26469;&#34913;&#37327;&#65292;&#20027;&#35201;&#38382;&#39064;&#26159;&#22312;&#20197;&#19981;&#21516;&#19988;&#21487;&#33021;&#26410;&#30693;&#30340;&#31574;&#30053;&#19979;&#35266;&#23519;&#21040;&#36807;&#21435;&#25968;&#25454;&#26102;&#23545;&#20854;&#26679;&#26412;&#22806;&#25439;&#22833;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#20351;&#29992;&#26679;&#26412;&#20998;&#21106;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#32472;&#21046;&#36825;&#26679;&#30340;&#25512;&#26029;&#65292;&#24182;&#23545;&#25972;&#20010;&#25439;&#22833;&#20998;&#24067;&#32780;&#19981;&#20165;&#20165;&#26159;&#20854;&#22343;&#20540;&#36827;&#34892;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#20445;&#35777;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#23545;&#36807;&#21435;&#31574;&#30053;&#30340;&#27169;&#22411;&#37197;&#32622;&#38169;&#35823;&#65292;&#21253;&#25324;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#12290;&#35813;&#35780;&#20272;&#26041;&#27861;&#21487;&#29992;&#20110;&#22312;&#19968;&#23450;&#21487;&#20449;&#27169;&#22411;&#20551;&#35774;&#33539;&#22260;&#20869;&#20351;&#29992;&#35266;&#23519;&#25968;&#25454;&#23545;&#31574;&#30053;&#30340;&#24615;&#33021;&#36827;&#34892;&#35748;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of evaluating the performance of a decision policy using past observational data. The outcome of a policy is measured in terms of a loss (aka. disutility or negative reward) and the main problem is making valid inferences about its out-of-sample loss when the past data was observed under a different and possibly unknown policy. Using a sample-splitting method, we show that it is possible to draw such inferences with finite-sample coverage guarantees about the entire loss distribution, rather than just its mean. Importantly, the method takes into account model misspecifications of the past policy - including unmeasured confounding. The evaluation method can be used to certify the performance of a policy using observational data under a specified range of credible model assumptions.
&lt;/p&gt;</description></item><item><title>&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2301.06535</link><description>&lt;p&gt;
&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65306;&#20855;&#26377;&#26102;&#38388;&#21464;&#21270;&#30340;&#39640;&#38454;&#20132;&#20114;&#30340;&#29983;&#23384;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Case-Base Neural Networks: survival analysis with time-varying, higher-order interactions. (arXiv:2301.06535v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.06535
&lt;/p&gt;
&lt;p&gt;
&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22522;&#20110;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#21487;&#20197;&#27169;&#25311;&#25968;&#25454;&#39537;&#21160;&#30340;&#21327;&#21464;&#37327;&#20132;&#20114;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#27604;&#22238;&#24402;&#26041;&#27861;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#24182;&#19981;&#26159;&#25152;&#26377;&#30340;&#26041;&#27861;&#37117;&#21487;&#20197;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#23558;&#26696;&#20363;&#22522;&#30784;&#25277;&#26679;&#26694;&#26550;&#19982;&#28789;&#27963;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25277;&#26679;&#26041;&#26696;&#21644;&#25968;&#25454;&#22686;&#24378;&#26469;&#33258;&#28982;&#22320;&#32771;&#34385;&#21040;&#25130;&#23614;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21487;&#20197;&#25509;&#21463;&#26102;&#38388;&#36755;&#20837;&#30340;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#12290;CBNNs&#36890;&#36807;&#39044;&#27979;&#22312;&#32473;&#23450;&#26102;&#21051;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#26469;&#20272;&#35745;&#21361;&#38505;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#21644;&#19977;&#20010;&#26696;&#20363;&#30740;&#31350;&#20351;&#29992;&#20004;&#20010;&#26102;&#38388;&#20381;&#36182;&#25351;&#26631;&#27604;&#36739;CBNNs&#19982;&#22238;&#24402;&#21644;&#31070;&#32463;&#32593;&#32476;&#22522;&#20110;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#28041;&#21450;&#22797;&#26434;&#22522;&#32447;&#39118;&#38505;&#21644;&#26102;&#38388;&#21464;&#21270;&#20132;&#20114;&#30340;&#27169;&#25311;&#26469;&#35780;&#20272;&#25152;&#26377;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;CBNNs&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network-based survival methods can model data-driven covariate interactions. While these methods can provide better predictive performance than regression-based approaches, not all can model time-varying interactions and complex baseline hazards. To address this, we propose Case-Base Neural Networks (CBNNs) as a new approach that combines the case-base sampling framework with flexible neural network architectures. Using a novel sampling scheme and data augmentation to naturally account for censoring, we construct a feed-forward neural network that may take time as an input. CBNNs predict the probability of an event occurring at a given moment to estimate the hazard function. We compare the performance of CBNNs to regression and neural network-based survival methods in a simulation and three case studies using two time-dependent metrics. First, we examine performance on a simulation involving a complex baseline hazard and time-varying interactions to assess all methods, with CBNN
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#20132;&#20114;&#24335;&#20915;&#31574;&#30340;&#26694;&#26550;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;GEC&#65292;&#29992;&#20110;&#26679;&#26412;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25429;&#25417;&#21040;&#25506;&#32034;&#21644;&#24320;&#21457;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#23558;RL&#38382;&#39064;&#21010;&#20998;&#20026;&#20302;GEC&#21644;&#39640;GEC&#20004;&#20010;&#31867;&#21035;&#65292;&#24182;&#23637;&#31034;&#20102;&#20302;GEC&#31867;&#21035;&#30340;&#20016;&#23500;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2211.01962</link><description>&lt;p&gt;
GEC: &#19968;&#31181;&#22312;MDP&#12289;POMDP&#21644;&#26356;&#22810;&#24773;&#20917;&#19979;&#20132;&#20114;&#24335;&#20915;&#31574;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond. (arXiv:2211.01962v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01962
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#20132;&#20114;&#24335;&#20915;&#31574;&#30340;&#26694;&#26550;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;GEC&#65292;&#29992;&#20110;&#26679;&#26412;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25429;&#25417;&#21040;&#25506;&#32034;&#21644;&#24320;&#21457;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#23558;RL&#38382;&#39064;&#21010;&#20998;&#20026;&#20302;GEC&#21644;&#39640;GEC&#20004;&#20010;&#31867;&#21035;&#65292;&#24182;&#23637;&#31034;&#20102;&#20302;GEC&#31867;&#21035;&#30340;&#20016;&#23500;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20132;&#20114;&#24335;&#20915;&#31574;&#30340;&#26222;&#36941;&#26694;&#26550;&#19979;&#30340;&#26679;&#26412;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#65292;&#35813;&#26694;&#26550;&#21253;&#25324;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#12289;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#21644;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSR&#65289;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#12290;&#20026;&#20102;&#25214;&#21040;&#36171;&#20104;&#26679;&#26412;&#39640;&#25928;&#23398;&#20064;&#30340;&#26368;&#23567;&#20551;&#35774;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#24191;&#20041;eluder&#31995;&#25968;&#65288;GEC&#65289;&#65292;&#23427;&#34920;&#24449;&#20102;&#22312;&#32447;&#20132;&#20114;&#24335;&#20915;&#31574;&#20013;&#25506;&#32034;&#21644;&#24320;&#21457;&#20043;&#38388;&#30340;&#22522;&#26412;&#26435;&#34913;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;GEC&#36890;&#36807;&#27604;&#36739;&#39044;&#27979;&#26356;&#26032;&#31574;&#30053;&#24615;&#33021;&#30340;&#35823;&#24046;&#19982;&#22522;&#20110;&#21382;&#21490;&#25968;&#25454;&#35780;&#20272;&#30340;&#26679;&#26412;&#20869;&#35757;&#32451;&#35823;&#24046;&#65292;&#26469;&#34913;&#37327;&#25506;&#32034;&#30340;&#38590;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20302;GEC&#30340;RL&#38382;&#39064;&#24418;&#25104;&#20102;&#19968;&#20010;&#38750;&#24120;&#20016;&#23500;&#30340;&#31867;&#21035;&#65292;&#20854;&#20013;&#21253;&#25324;&#20302;Bellman eluder&#32500;&#24230;&#38382;&#39064;&#12289;&#21452;&#32447;&#24615;&#31867;&#12289;&#20302;&#35777;&#20154;&#31209;&#38382;&#39064;&#12289;PO-&#21452;&#32447;&#24615;&#31867;&#21644;&#24191;&#20041;&#27491;&#21017;PSR&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study sample efficient reinforcement learning (RL) under the general framework of interactive decision making, which includes Markov decision process (MDP), partially observable Markov decision process (POMDP), and predictive state representation (PSR) as special cases. Toward finding the minimum assumption that empowers sample efficient learning, we propose a novel complexity measure, generalized eluder coefficient (GEC), which characterizes the fundamental tradeoff between exploration and exploitation in online interactive decision making. In specific, GEC captures the hardness of exploration by comparing the error of predicting the performance of the updated policy with the in-sample training error evaluated on the historical data. We show that RL problems with low GEC form a remarkably rich class, which subsumes low Bellman eluder dimension problems, bilinear class, low witness rank problems, PO-bilinear class, and generalized regular PSR, where generalized regular PSR, a new tr
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22312;&#32447;&#39044;&#27979;&#20174;&#19987;&#23478;&#20013;&#35299;&#20915;&#38544;&#31169;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#24182;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#32431;&#24046;&#20998;&#38544;&#31169;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#19979;&#65292;&#23545;&#20110;&#24858;&#34850;&#25932;&#25163;&#65292;&#22312;&#39640;&#32500;&#33539;&#22260;&#20869;&#30340;&#36951;&#25022;&#21487;&#20197;&#36798;&#21040;&#20122;&#32447;&#24615;&#27700;&#24179;&#65292;&#19982;&#33258;&#36866;&#24212;&#23545;&#25163;&#21644;&#38750;&#33258;&#36866;&#24212;&#23545;&#25163;&#20043;&#38388;&#23384;&#22312;&#30528;&#36739;&#24378;&#30340;&#36951;&#25022;&#26368;&#20248;&#24615;&#20998;&#31163;&#12290;</title><link>http://arxiv.org/abs/2210.13537</link><description>&lt;p&gt;
&#20174;&#19987;&#23478;&#36827;&#34892;&#31169;&#23494;&#22312;&#32447;&#39044;&#27979;: &#20998;&#31163;&#21644;&#26356;&#24555;&#30340;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Private Online Prediction from Experts: Separations and Faster Rates. (arXiv:2210.13537v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13537
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22312;&#32447;&#39044;&#27979;&#20174;&#19987;&#23478;&#20013;&#35299;&#20915;&#38544;&#31169;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#24182;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#32431;&#24046;&#20998;&#38544;&#31169;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#19979;&#65292;&#23545;&#20110;&#24858;&#34850;&#25932;&#25163;&#65292;&#22312;&#39640;&#32500;&#33539;&#22260;&#20869;&#30340;&#36951;&#25022;&#21487;&#20197;&#36798;&#21040;&#20122;&#32447;&#24615;&#27700;&#24179;&#65292;&#19982;&#33258;&#36866;&#24212;&#23545;&#25163;&#21644;&#38750;&#33258;&#36866;&#24212;&#23545;&#25163;&#20043;&#38388;&#23384;&#22312;&#30528;&#36739;&#24378;&#30340;&#36951;&#25022;&#26368;&#20248;&#24615;&#20998;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#39044;&#27979;&#20174;&#19987;&#23478;&#20013;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#22522;&#26412;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#24050;&#32463;&#26377;&#20960;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#30340;&#26032;&#31639;&#27861;&#65292;&#25913;&#36827;&#20102;&#38750;&#33258;&#36866;&#24212;&#23545;&#25163;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#23545;&#20110;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#38543;&#26426;&#35774;&#32622;&#19979;&#23454;&#29616;&#20102;&#36951;&#25022;&#30028;&#38480;&#20026;$\tilde{O}(\sqrt{T \log d} + \log d/\varepsilon)$&#65292;&#23545;&#20110;&#24858;&#34850;&#25932;&#25163;&#23454;&#29616;&#20102;&#36951;&#25022;&#30028;&#38480;&#20026;$\tilde{O}(\sqrt{T \log d} + T^{1/3} \log d/\varepsilon)$&#65288;&#20854;&#20013;$d$&#26159;&#19987;&#23478;&#25968;&#37327;&#65289;&#12290;&#23545;&#20110;&#32431;DP&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#22312;&#39640;&#32500;&#33539;&#22260;$d \ge T$ &#30340;&#24858;&#34850;&#25932;&#25163;&#20013;&#33719;&#24471;&#20122;&#32447;&#24615;&#36951;&#25022;&#30340;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#36866;&#24212;&#23545;&#25163;&#30340;&#26032;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#38750;&#31169;&#23494;&#35774;&#32622;&#19981;&#21516;&#65292;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#33258;&#36866;&#24212;&#23545;&#25163;&#21644;&#38750;&#33258;&#36866;&#24212;&#23545;&#25163;&#20043;&#38388;&#23384;&#22312;&#30528;&#36739;&#24378;&#30340;&#36951;&#25022;&#26368;&#20248;&#24615;&#20998;&#31163;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#20063;&#23637;&#31034;&#20102;&#19968;&#31181;&#22312;&#33258;&#36866;&#24212;&#23545;&#25163;&#21644;&#38750;&#33258;&#36866;&#24212;&#23545;&#25163;&#20043;&#38388;&#30340;&#20998;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online prediction from experts is a fundamental problem in machine learning and several works have studied this problem under privacy constraints. We propose and analyze new algorithms for this problem that improve over the regret bounds of the best existing algorithms for non-adaptive adversaries. For approximate differential privacy, our algorithms achieve regret bounds of $\tilde{O}(\sqrt{T \log d} + \log d/\varepsilon)$ for the stochastic setting and $\tilde{O}(\sqrt{T \log d} + T^{1/3} \log d/\varepsilon)$ for oblivious adversaries (where $d$ is the number of experts). For pure DP, our algorithms are the first to obtain sub-linear regret for oblivious adversaries in the high-dimensional regime $d \ge T$. Moreover, we prove new lower bounds for adaptive adversaries. Our results imply that unlike the non-private setting, there is a strong separation between the optimal regret for adaptive and non-adaptive adversaries for this problem. Our lower bounds also show a separation between 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#33258;&#21160;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65292;&#36890;&#36807;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#26500;&#24314;&#30340;&#26631;&#31614;&#39044;&#27979;&#38598;&#21512;&#65292;&#31934;&#30830;&#22320;&#26435;&#34913;&#20102;&#30495;&#23454;&#26631;&#31614;&#19981;&#22312;&#39044;&#27979;&#38598;&#21512;&#20013;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2201.12006</link><description>&lt;p&gt;
&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#25913;&#36827;&#19987;&#23478;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Improving Expert Predictions with Conformal Prediction. (arXiv:2201.12006v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.12006
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#33258;&#21160;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65292;&#36890;&#36807;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#26500;&#24314;&#30340;&#26631;&#31614;&#39044;&#27979;&#38598;&#21512;&#65292;&#31934;&#30830;&#22320;&#26435;&#34913;&#20102;&#30495;&#23454;&#26631;&#31614;&#19981;&#22312;&#39044;&#27979;&#38598;&#21512;&#20013;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#25215;&#35834;&#24110;&#21161;&#19987;&#23478;&#26356;&#39640;&#25928;&#20934;&#30830;&#22320;&#35299;&#20915;&#22810;&#31867;&#20998;&#31867;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#31995;&#32479;&#36890;&#24120;&#35201;&#27714;&#19987;&#23478;&#29702;&#35299;&#20309;&#26102;&#25918;&#24323;&#33258;&#24049;&#30340;&#20915;&#31574;&#26435;&#20197;&#21450;&#20309;&#26102;&#34892;&#20351;&#33258;&#24049;&#30340;&#20915;&#31574;&#26435;&#12290;&#21542;&#21017;&#65292;&#19987;&#23478;&#21487;&#33021;&#26356;&#36866;&#21512;&#33258;&#34892;&#35299;&#20915;&#20998;&#31867;&#20219;&#21153;&#12290;&#22312;&#27492;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#33258;&#21160;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65292;&#23427;&#19981;&#38656;&#35201;&#19987;&#23478;&#29702;&#35299;&#20309;&#26102;&#20449;&#20219;&#31995;&#32479;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#19981;&#25552;&#20379;&#21333;&#19968;&#30340;&#26631;&#31614;&#39044;&#27979;&#24182;&#35753;&#19987;&#23478;&#20915;&#23450;&#20309;&#26102;&#20449;&#20219;&#36825;&#20123;&#39044;&#27979;&#65292;&#32780;&#26159;&#25552;&#20379;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#26500;&#24314;&#30340;&#26631;&#31614;&#39044;&#27979;&#38598;&#21512;&#65292;&#24182;&#24378;&#21046;&#35201;&#27714;&#19987;&#23478;&#20174;&#36825;&#20123;&#38598;&#21512;&#20013;&#39044;&#27979;&#26631;&#31614;&#12290;&#36890;&#36807;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#65292;&#25105;&#20204;&#30340;&#31995;&#32479;&#21487;&#20197;&#31934;&#30830;&#22320;&#26435;&#34913;&#30495;&#23454;&#26631;&#31614;&#19981;&#22312;&#39044;&#27979;&#38598;&#21512;&#20013;&#30340;&#27010;&#29575;&#65292;&#20174;&#32780;&#30830;&#23450;&#36755;&#20986;&#39044;&#27979;&#30340;&#39057;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated decision support systems promise to help human experts solve multiclass classification tasks more efficiently and accurately. However, existing systems typically require experts to understand when to cede agency to the system or when to exercise their own agency. Otherwise, the experts may be better off solving the classification tasks on their own. In this work, we develop an automated decision support system that, by design, does not require experts to understand when to trust the system to improve performance. Rather than providing (single) label predictions and letting experts decide when to trust these predictions, our system provides sets of label predictions constructed using conformal prediction$\unicode{x2014}$prediction sets$\unicode{x2014}$and forcefully asks experts to predict labels from these sets. By using conformal prediction, our system can precisely trade-off the probability that the true label is not in the prediction set, which determines how frequently ou
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#35299;&#20915;AMP&#31867;&#22411;&#31639;&#27861;&#25910;&#25947;&#24615;&#38382;&#39064;&#30340;&#20805;&#20998;&#32479;&#35745;&#35760;&#24518;&#22411;AMP&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#20805;&#20998;&#32479;&#35745;&#32422;&#26463;&#21644;&#29305;&#23450;&#26465;&#20214;&#19979;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#24615;&#36136;&#65292;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#20449;&#21495;&#37325;&#26500;&#12290;</title><link>http://arxiv.org/abs/2112.15327</link><description>&lt;p&gt;
&#20805;&#20998;&#32479;&#35745;&#35760;&#24518;&#22411;AMP&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sufficient-Statistic Memory AMP. (arXiv:2112.15327v4 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.15327
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#35299;&#20915;AMP&#31867;&#22411;&#31639;&#27861;&#25910;&#25947;&#24615;&#38382;&#39064;&#30340;&#20805;&#20998;&#32479;&#35745;&#35760;&#24518;&#22411;AMP&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#20805;&#20998;&#32479;&#35745;&#32422;&#26463;&#21644;&#29305;&#23450;&#26465;&#20214;&#19979;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#24615;&#36136;&#65292;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#20449;&#21495;&#37325;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#31867;&#22411;&#30340;&#31639;&#27861;&#22312;&#26576;&#20123;&#22823;&#22411;&#38543;&#26426;&#32447;&#24615;&#31995;&#32479;&#30340;&#20449;&#21495;&#37325;&#26500;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;AMP&#31867;&#22411;&#31639;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#28857;&#26159;&#23427;&#20204;&#30340;&#21160;&#24577;&#21487;&#20197;&#36890;&#36807;&#29366;&#24577;&#28436;&#21270;&#27491;&#30830;&#22320;&#25551;&#36848;&#12290;&#34429;&#28982;&#29366;&#24577;&#28436;&#21270;&#26159;&#19968;&#20010;&#26377;&#29992;&#30340;&#20998;&#26512;&#24037;&#20855;&#65292;&#20294;&#20854;&#25910;&#25947;&#24615;&#24182;&#19981;&#20445;&#35777;&#12290;&#20026;&#20102;&#22312;&#21407;&#21017;&#19978;&#35299;&#20915;AMP&#31867;&#22411;&#31639;&#27861;&#30340;&#29366;&#24577;&#28436;&#21270;&#30340;&#25910;&#25947;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27491;&#30830;&#21333;&#20301;&#19981;&#21464;&#30340;&#24863;&#30693;&#30697;&#38453;&#12289;Lipschitz&#36830;&#32493;&#30340;&#26412;&#22320;&#22788;&#29702;&#22120;&#21644;&#20805;&#20998;&#32479;&#35745;&#32422;&#26463;&#19979;&#30340;&#20805;&#20998;&#32479;&#35745;&#35760;&#24518;&#22411;AMP&#65288;SS-MAMP&#65289;&#31639;&#27861;&#26694;&#26550;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SS-MAMP&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#26159;L&#24102;&#29366;&#30340;&#19988;&#25910;&#25947;&#65292;&#36825;&#26159;&#19968;&#20010;&#26368;&#20248;&#30340;&#26694;&#26550;&#65288;&#20174;&#26412;&#22320;MMSE/LMMSE&#35282;&#24230;&#65289;&#32473;&#23450;Lipschitz&#36830;&#32493;&#30340;AMP&#31867;&#22411;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approximate message passing (AMP) type algorithms have been widely used in the signal reconstruction of certain large random linear systems. A key feature of the AMP-type algorithms is that their dynamics can be correctly described by state evolution. While state evolution is a useful analytic tool, its convergence is not guaranteed. To solve the convergence problem of the state evolution of AMP-type algorithms in principle, this paper proposes a sufficient-statistic memory AMP (SS-MAMP) algorithm framework under the conditions of right-unitarily invariant sensing matrices, Lipschitz-continuous local processors and the sufficient-statistic constraint (i.e., the current message of each local processor is a sufficient statistic of the signal vector given the current and all preceding messages). We show that the covariance matrices of SS-MAMP are L-banded and convergent, which is an optimal framework (from the local MMSE/LMMSE perspective) for AMP-type algorithms given the Lipschitz-conti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24322;&#36136;&#20998;&#24067;&#28382;&#21518;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#20272;&#35745;&#23381;&#22919;&#26292;&#38706;&#20110;&#32454;&#39063;&#31890;&#29289;&#30340;&#20851;&#38190;&#26102;&#26399;&#21644;&#26032;&#29983;&#20799;&#20307;&#37325;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20851;&#38190;&#26102;&#26399;&#21644;&#20851;&#32852;&#24133;&#24230;&#22312;&#19981;&#21516;&#30340;&#20010;&#20307;&#12289;&#23478;&#24237;&#21644;&#31038;&#21306;&#29305;&#24449;&#27700;&#24179;&#19978;&#34920;&#29616;&#20986;&#24322;&#36136;&#24615;&#12290;</title><link>http://arxiv.org/abs/2109.13763</link><description>&lt;p&gt;
&#24322;&#36136;&#20998;&#24067;&#28382;&#21518;&#27169;&#22411;&#29992;&#20110;&#20272;&#35745;&#23381;&#22919;&#26292;&#38706;&#20110;&#31354;&#27668;&#27745;&#26579;&#29289;&#30340;&#20010;&#24615;&#21270;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous Distributed Lag Models to Estimate Personalized Effects of Maternal Exposures to Air Pollution. (arXiv:2109.13763v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.13763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24322;&#36136;&#20998;&#24067;&#28382;&#21518;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#20272;&#35745;&#23381;&#22919;&#26292;&#38706;&#20110;&#32454;&#39063;&#31890;&#29289;&#30340;&#20851;&#38190;&#26102;&#26399;&#21644;&#26032;&#29983;&#20799;&#20307;&#37325;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20851;&#38190;&#26102;&#26399;&#21644;&#20851;&#32852;&#24133;&#24230;&#22312;&#19981;&#21516;&#30340;&#20010;&#20307;&#12289;&#23478;&#24237;&#21644;&#31038;&#21306;&#29305;&#24449;&#27700;&#24179;&#19978;&#34920;&#29616;&#20986;&#24322;&#36136;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20799;&#31461;&#20581;&#24247;&#30740;&#31350;&#25903;&#25345;&#23381;&#22919;&#29615;&#22659;&#26292;&#38706;&#19982;&#20799;&#31461;&#20986;&#29983;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#19968;&#20010;&#20849;&#21516;&#30446;&#26631;&#26159;&#30830;&#23450;&#26131;&#24863;&#24615;&#30340;&#20851;&#38190;&#26102;&#26399;-&#23381;&#26399;&#20869;&#27597;&#20307;&#26292;&#38706;&#19982;&#26410;&#26469;&#32467;&#26524;&#20043;&#38388;&#20851;&#32852;&#22686;&#24378;&#30340;&#26102;&#26399;&#12290;&#20851;&#38190;&#26102;&#26399;&#30340;&#26102;&#26426;&#21644;&#20851;&#32852;&#24133;&#24230;&#22312;&#20010;&#20307;&#12289;&#23478;&#24237;&#21644;&#31038;&#21306;&#29305;&#24449;&#30340;&#19981;&#21516;&#27700;&#24179;&#19978;&#21487;&#33021;&#26159;&#24322;&#36136;&#30340;&#12290;&#20351;&#29992;&#31185;&#32599;&#25289;&#22810;&#24030;&#30340;&#20986;&#29983;&#38431;&#21015;&#65292;&#25105;&#20204;&#20272;&#35745;&#20102;&#23381;&#26399;&#27599;&#21608;&#23545;&#32454;&#39063;&#31890;&#29289;&#65288;PM$_{2.5}$&#65289;&#30340;&#20010;&#24615;&#21270;&#20851;&#31995;&#19982;&#26032;&#29983;&#20799;&#20307;&#37325;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#23398;&#20064;&#26041;&#27861;&#65292;&#32467;&#21512;&#20998;&#24067;&#28382;&#21518;&#27169;&#22411;&#21644;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#65292;&#20197;&#20010;&#20307;&#27700;&#24179;&#20272;&#35745;&#20851;&#38190;&#26102;&#26399;&#65292;&#24182;&#20174;&#19968;&#32452;&#28508;&#22312;&#30340;&#20462;&#25913;&#22240;&#32032;&#20013;&#35782;&#21035;&#24341;&#36215;&#24322;&#36136;&#24615;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#21457;&#29616;PM$_{2.5}$&#30340;&#24322;&#36136;&#24615;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Children's health studies support an association between maternal environmental exposures and children's birth outcomes. A common goal is to identify critical windows of susceptibility--periods during gestation with increased association between maternal exposures and a future outcome. The timing of the critical windows and magnitude of the associations are likely heterogeneous across different levels of individual, family, and neighborhood characteristics. Using an administrative Colorado birth cohort we estimate the individualized relationship between weekly exposures to fine particulate matter (PM$_{2.5}$) during gestation and birth weight. To achieve this goal, we propose a statistical learning method combining distributed lag models and Bayesian additive regression trees to estimate critical windows at the individual level and identify characteristics that induce heterogeneity from a high-dimensional set of potential modifying factors. We find evidence of heterogeneity in the PM$_
&lt;/p&gt;</description></item><item><title>&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#37117;&#21487;&#20197;&#24402;&#32467;&#20026;&#36125;&#21494;&#26031;&#23398;&#20064;&#35268;&#21017;&#65292;&#35813;&#35268;&#21017;&#36890;&#36807;&#21033;&#29992;&#33258;&#28982;&#26799;&#24230;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#24471;&#21040;&#24191;&#27867;&#30340;&#31639;&#27861;&#24212;&#29992;&#12290;&#36825;&#19968;&#24037;&#20316;&#19981;&#20165;&#32479;&#19968;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;&#36824;&#24110;&#21161;&#25105;&#20204;&#35774;&#35745;&#26032;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2107.04562</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#23398;&#20064;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
The Bayesian Learning Rule. (arXiv:2107.04562v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.04562
&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#37117;&#21487;&#20197;&#24402;&#32467;&#20026;&#36125;&#21494;&#26031;&#23398;&#20064;&#35268;&#21017;&#65292;&#35813;&#35268;&#21017;&#36890;&#36807;&#21033;&#29992;&#33258;&#28982;&#26799;&#24230;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#24471;&#21040;&#24191;&#27867;&#30340;&#31639;&#27861;&#24212;&#29992;&#12290;&#36825;&#19968;&#24037;&#20316;&#19981;&#20165;&#32479;&#19968;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;&#36824;&#24110;&#21161;&#25105;&#20204;&#35774;&#35745;&#26032;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26159;&#19968;&#20010;&#31216;&#20026;&#36125;&#21494;&#26031;&#23398;&#20064;&#35268;&#21017;&#30340;&#21333;&#19968;&#31639;&#27861;&#30340;&#29305;&#20363;&#12290;&#36825;&#20010;&#35268;&#21017;&#26159;&#20174;&#36125;&#21494;&#26031;&#21407;&#29702;&#25512;&#23548;&#20986;&#26469;&#30340;&#65292;&#21487;&#20197;&#20174;&#20248;&#21270;&#12289;&#28145;&#24230;&#23398;&#20064;&#21644;&#22270;&#24418;&#27169;&#22411;&#31561;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#30340;&#31639;&#27861;&#12290;&#36825;&#21253;&#25324;&#32463;&#20856;&#31639;&#27861;&#22914;&#23725;&#22238;&#24402;&#12289;&#29275;&#39039;&#27861;&#21644;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65292;&#20197;&#21450;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#12289;RMSprop&#21644;Dropout&#12290;&#25512;&#23548;&#36825;&#20123;&#31639;&#27861;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#20272;&#35745;&#30340;&#20505;&#36873;&#20998;&#24067;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#12290;&#19981;&#21516;&#30340;&#20505;&#36873;&#20998;&#24067;&#20250;&#23548;&#33268;&#19981;&#21516;&#30340;&#31639;&#27861;&#65292;&#23545;&#33258;&#28982;&#26799;&#24230;&#30340;&#36827;&#19968;&#27493;&#36924;&#36817;&#21017;&#20250;&#20135;&#29983;&#36825;&#20123;&#31639;&#27861;&#30340;&#21464;&#31181;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#19981;&#20165;&#32479;&#19968;&#12289;&#27867;&#21270;&#21644;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;&#36824;&#24110;&#21161;&#25105;&#20204;&#35774;&#35745;&#26032;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that many machine-learning algorithms are specific instances of a single algorithm called the Bayesian learning rule. The rule, derived from Bayesian principles, yields a wide-range of algorithms from fields such as optimization, deep learning, and graphical models. This includes classical algorithms such as ridge regression, Newton's method, and Kalman filter, as well as modern deep-learning algorithms such as stochastic-gradient descent, RMSprop, and Dropout. The key idea in deriving such algorithms is to approximate the posterior using candidate distributions estimated by using natural gradients. Different candidate distributions result in different algorithms and further approximations to natural gradients give rise to variants of those algorithms. Our work not only unifies, generalizes, and improves existing algorithms, but also helps us design new ones.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;WGANs&#65289;&#65292;&#24182;&#20351;&#29992;GroupSort&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#37492;&#21035;&#22120;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#30340;&#23481;&#37327;&#23545;&#30446;&#26631;&#20998;&#24067;&#30340;&#36924;&#36817;&#35823;&#24046;&#26377;&#24433;&#21709;&#65292;&#24182;&#19988;WGANs&#23545;&#37492;&#21035;&#22120;&#30340;&#23481;&#37327;&#35201;&#27714;&#39640;&#20110;&#29983;&#25104;&#22120;&#12290;&#27492;&#22806;&#65292;&#22312;&#37492;&#21035;&#22120;&#19981;&#36275;&#22815;&#24378;&#22823;&#26102;&#65292;&#20302;&#23481;&#37327;&#30340;&#29983;&#25104;&#22120;&#21487;&#33021;&#27604;&#36807;&#24230;&#28145;&#23618;&#21644;&#23485;&#24230;&#30340;&#29983;&#25104;&#22120;&#25928;&#26524;&#26356;&#22909;&#12290;&#25968;&#20540;&#32467;&#26524;&#35777;&#23454;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2103.10060</link><description>&lt;p&gt;
&#20351;&#29992;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36817;&#20284;&#27010;&#29575;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Approximating Probability Distributions by using Wasserstein Generative Adversarial Networks. (arXiv:2103.10060v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.10060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;WGANs&#65289;&#65292;&#24182;&#20351;&#29992;GroupSort&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#37492;&#21035;&#22120;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#30340;&#23481;&#37327;&#23545;&#30446;&#26631;&#20998;&#24067;&#30340;&#36924;&#36817;&#35823;&#24046;&#26377;&#24433;&#21709;&#65292;&#24182;&#19988;WGANs&#23545;&#37492;&#21035;&#22120;&#30340;&#23481;&#37327;&#35201;&#27714;&#39640;&#20110;&#29983;&#25104;&#22120;&#12290;&#27492;&#22806;&#65292;&#22312;&#37492;&#21035;&#22120;&#19981;&#36275;&#22815;&#24378;&#22823;&#26102;&#65292;&#20302;&#23481;&#37327;&#30340;&#29983;&#25104;&#22120;&#21487;&#33021;&#27604;&#36807;&#24230;&#28145;&#23618;&#21644;&#23485;&#24230;&#30340;&#29983;&#25104;&#22120;&#25928;&#26524;&#26356;&#22909;&#12290;&#25968;&#20540;&#32467;&#26524;&#35777;&#23454;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;GroupSort&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#37492;&#21035;&#22120;&#30340;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;WGANs&#65289;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#30446;&#26631;&#20998;&#24067;&#30340;&#36924;&#36817;&#35823;&#24046;&#30028;&#38480;&#21462;&#20915;&#20110;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#30340;&#23485;&#24230;&#21644;&#28145;&#24230;&#65288;&#23481;&#37327;&#65289;&#20197;&#21450;&#35757;&#32451;&#20013;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;&#38024;&#23545;&#29983;&#25104;&#30340;&#20998;&#24067;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#24314;&#31435;&#20102;&#37327;&#21270;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#26681;&#25454;&#29702;&#35770;&#32467;&#26524;&#65292;WGANs&#23545;&#37492;&#21035;&#22120;&#30340;&#23481;&#37327;&#35201;&#27714;&#27604;&#29983;&#25104;&#22120;&#26356;&#39640;&#65292;&#36825;&#19982;&#19968;&#20123;&#24050;&#26377;&#32467;&#26524;&#19968;&#33268;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#22914;&#26524;&#37492;&#21035;&#22120;&#19981;&#36275;&#22815;&#24378;&#22823;&#65292;&#19982;&#36807;&#24230;&#28145;&#23618;&#21644;&#23485;&#24230;&#65288;&#39640;&#23481;&#37327;&#65289;&#30340;&#29983;&#25104;&#22120;&#30456;&#27604;&#65292;&#20302;&#23481;&#37327;&#30340;&#29983;&#25104;&#22120;&#30340;&#32467;&#26524;&#21487;&#33021;&#26356;&#24046;&#12290;&#20351;&#29992;Swiss roll&#21644;MNIST&#25968;&#25454;&#38598;&#24471;&#21040;&#30340;&#25968;&#20540;&#32467;&#26524;&#35777;&#23454;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Studied here are Wasserstein generative adversarial networks (WGANs) with GroupSort neural networks as their discriminators. It is shown that the error bound of the approximation for the target distribution depends on the width and depth (capacity) of the generators and discriminators and the number of samples in training. A quantified generalization bound is established for the Wasserstein distance between the generated and target distributions. According to the theoretical results, WGANs have a higher requirement for the capacity of discriminators than that of generators, which is consistent with some existing results. More importantly, the results with overly deep and wide (high-capacity) generators may be worse than those with low-capacity generators if discriminators are insufficiently strong. Numerical results obtained using Swiss roll and MNIST datasets confirm the theoretical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#30340;&#20219;&#24847;&#22495;&#20869;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#30456;&#20851;&#27010;&#29575;&#23494;&#24230;&#21644;&#32479;&#35745;&#25351;&#26631;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23545;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#21644;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#30340;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2012.14331</link><description>&lt;p&gt;
&#19968;&#31181;&#25972;&#21512;&#21644;&#20998;&#31867;&#27491;&#24577;&#20998;&#24067;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A method to integrate and classify normal distributions. (arXiv:2012.14331v8 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.14331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#30340;&#20219;&#24847;&#22495;&#20869;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#30456;&#20851;&#27010;&#29575;&#23494;&#24230;&#21644;&#32479;&#35745;&#25351;&#26631;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23545;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#21644;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#27491;&#24577;&#27010;&#29575;&#20998;&#24067;&#22312;&#27169;&#25311;&#19981;&#30830;&#23450;&#24615;&#20915;&#31574;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#38656;&#35201;&#22312;&#29305;&#23450;&#21306;&#22495;&#20869;&#23545;&#36825;&#20123;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#65292;&#36825;&#22312;&#19981;&#21516;&#30340;&#27169;&#22411;&#20013;&#21487;&#20197;&#26377;&#24456;&#22823;&#30340;&#24046;&#24322;&#12290;&#38500;&#20102;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#65292;&#30446;&#21069;&#19981;&#23384;&#22312;&#36890;&#29992;&#30340;&#20998;&#26512;&#34920;&#36798;&#24335;&#12289;&#26631;&#20934;&#25968;&#20540;&#26041;&#27861;&#25110;&#36719;&#20214;&#26469;&#35745;&#31639;&#36825;&#20123;&#31215;&#20998;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25968;&#23398;&#32467;&#26524;&#21644;&#24320;&#28304;&#36719;&#20214;&#65292;&#21487;&#20197;&#25552;&#20379;&#20197;&#19979;&#20869;&#23481;&#65306;&#65288;i&#65289;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#20219;&#24847;&#22495;&#20869;&#27861;&#21521;&#30340;&#27010;&#29575;&#65292;&#65288;ii&#65289;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#27010;&#29575;&#23494;&#24230;&#12289;&#32047;&#31215;&#20998;&#24067;&#21644;&#36870;&#32047;&#31215;&#20998;&#24067;&#65292;&#65288;iii&#65289;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#31867;&#35823;&#24046;&#12289;&#36125;&#21494;&#26031;&#26368;&#20248;&#36776;&#21035;&#25351;&#25968;&#20197;&#21450;&#20854;&#19982;&#24037;&#20316;&#29305;&#24449;&#26354;&#32447;&#30340;&#20851;&#31995;&#65292;&#65288;iv&#65289;&#27492;&#31867;&#38382;&#39064;&#30340;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#65288;v&#65289;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#36825;&#20123;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#27979;&#35797;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#20855;&#20307;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#37329;&#34701;&#12289;&#29983;&#29289;&#21644;&#24515;&#29702;&#23398;&#26469;&#28436;&#31034;&#36825;&#20123;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Univariate and multivariate normal probability distributions are widely used when modeling decisions under uncertainty. Computing the performance of such models requires integrating these distributions over specific domains, which can vary widely across models. Besides some special cases, there exist no general analytical expressions, standard numerical methods or software for these integrals. Here we present mathematical results and open-source software that provide (i) the probability in any domain of a normal in any dimensions with any parameters, (ii) the probability density, cumulative distribution, and inverse cumulative distribution of any function of a normal vector, (iii) the classification errors among any number of normal distributions, the Bayes-optimal discriminability index and relation to the operating characteristic, (iv) dimension reduction and visualizations for such problems, and (v) tests for how reliably these methods may be used on given data. We demonstrate these
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#35268;&#21017;&#38598;&#21512;(CRE)&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#26641;&#30340;&#26041;&#24335;&#65292;&#21487;&#35299;&#37322;&#30340;&#21457;&#29616;&#21644;&#20272;&#35745;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;(HTE)&#65292;&#20855;&#26377;&#31283;&#23450;&#24615;&#21644;&#23545;&#22797;&#26434;&#24322;&#36136;&#24615;&#27169;&#24335;&#30340;&#25506;&#32034;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2009.09036</link><description>&lt;p&gt;
&#22240;&#26524;&#35268;&#21017;&#38598;&#21512;: &#21487;&#35299;&#37322;&#30340;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#30340;&#21457;&#29616;&#21644;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Causal Rule Ensemble: Interpretable Discovery and Inference of Heterogeneous Treatment Effects. (arXiv:2009.09036v5 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.09036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#35268;&#21017;&#38598;&#21512;(CRE)&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#26641;&#30340;&#26041;&#24335;&#65292;&#21487;&#35299;&#37322;&#30340;&#21457;&#29616;&#21644;&#20272;&#35745;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;(HTE)&#65292;&#20855;&#26377;&#31283;&#23450;&#24615;&#21644;&#23545;&#22797;&#26434;&#24322;&#36136;&#24615;&#27169;&#24335;&#30340;&#25506;&#32034;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20581;&#24247;&#21644;&#31038;&#20250;&#31185;&#23398;&#20013;&#65292;&#30830;&#23450;&#30740;&#31350;&#20154;&#32676;&#20013;&#23384;&#22312;&#26126;&#26174;&#30340;&#27835;&#30103;&#25928;&#24212;&#24322;&#36136;&#24615;(HTE)&#30340;&#20122;&#32676;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#30001;&#20110;&#20854;&#39640;&#24230;&#21487;&#35299;&#37322;&#24615;&#65292;&#20915;&#31574;&#26641;&#24050;&#34987;&#25552;&#20986;&#24182;&#24191;&#27867;&#24212;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;HTE&#21457;&#29616;&#12290;&#28982;&#32780;&#65292;&#21333;&#19968;&#20915;&#31574;&#26641;&#21457;&#29616;HTE&#21487;&#33021;&#19981;&#31283;&#23450;&#19988;&#36807;&#20110;&#31616;&#21270;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;HTE&#21457;&#29616;&#21644;&#20272;&#35745;&#26041;&#27861;&#8212;&#8212;&#22240;&#26524;&#35268;&#21017;&#38598;&#21512;(CRE)&#65292;&#37319;&#29992;&#38598;&#25104;&#26641;&#26041;&#27861;&#12290;CRE&#20855;&#26377;&#20197;&#19979;&#20960;&#20010;&#20851;&#38190;&#29305;&#28857;: 1) &#21487;&#35299;&#37322;&#30340;HTE&#34920;&#31034;; 2) &#25506;&#32034;&#22797;&#26434;&#30340;&#24322;&#36136;&#24615;&#27169;&#24335;&#30340;&#33021;&#21147;; 3) &#22312;&#20122;&#32676;&#21457;&#29616;&#20013;&#20855;&#26377;&#39640;&#31283;&#23450;&#24615;&#12290;&#25152;&#21457;&#29616;&#30340;&#20122;&#32676;&#26159;&#36890;&#36807;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#35268;&#21017;&#23450;&#20041;&#30340;&#12290;&#20122;&#32676;&#29305;&#23450;&#22240;&#26524;&#25928;&#24212;&#30340;&#20272;&#35745;&#36890;&#36807;&#20004;&#38454;&#27573;&#26041;&#27861;&#36827;&#34892;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#65292;CRE&#26041;&#27861;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In health and social sciences, it is critically important to identify subgroups of the study population where there is notable heterogeneity of treatment effects (HTE) with respect to the population average. Decision trees have been proposed and commonly adopted for data-driven discovery of HTE due to their high level of interpretability. However, single-tree discovery of HTE can be unstable and oversimplified. This paper introduces Causal Rule Ensemble (CRE), a new method for HTE discovery and estimation through an ensemble-of-trees approach. CRE offers several key features, including 1) an interpretable representation of the HTE; 2) the ability to explore complex heterogeneity patterns; and 3) high stability in subgroups discovery. The discovered subgroups are defined in terms of interpretable decision rules. Estimation of subgroup-specific causal effects is performed via a two-stage approach for which we provide theoretical guarantees. Via simulations, we show that the CRE method is
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#26469;&#22788;&#29702;&#22810;&#36830;&#25509;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#31216;&#20026;&#25968;&#25454;&#20016;&#23500;/&#20849;&#20139;&#12290;&#25105;&#20204;&#36890;&#36807;&#20984;&#20989;&#25968;&#26469;&#25551;&#36848;&#20844;&#20849;&#21442;&#25968;&#21644;&#20010;&#20307;&#21442;&#25968;&#30340;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20960;&#20309;&#25910;&#25947;&#36895;&#24230;&#30340;&#36845;&#20195;&#20272;&#35745;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/1806.04047</link><description>&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#20016;&#23500;&#21270;&#65306;&#21487;&#35299;&#37322;&#12289;&#24555;&#36895;&#21644;&#25968;&#25454;&#26377;&#25928;
&lt;/p&gt;
&lt;p&gt;
High Dimensional Data Enrichment: Interpretable, Fast, and Data-Efficient. (arXiv:1806.04047v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1806.04047
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#26469;&#22788;&#29702;&#22810;&#36830;&#25509;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#31216;&#20026;&#25968;&#25454;&#20016;&#23500;/&#20849;&#20139;&#12290;&#25105;&#20204;&#36890;&#36807;&#20984;&#20989;&#25968;&#26469;&#25551;&#36848;&#20844;&#20849;&#21442;&#25968;&#21644;&#20010;&#20307;&#21442;&#25968;&#30340;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20960;&#20309;&#25910;&#25947;&#36895;&#24230;&#30340;&#36845;&#20195;&#20272;&#35745;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#22312;&#22810;&#20010;&#36830;&#25509;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#29305;&#24615;&#65292;&#35813;&#38382;&#39064;&#34987;&#31216;&#20026;&#25968;&#25454;&#20016;&#23500;/&#20849;&#20139;&#12290;&#20219;&#21153;&#38388;&#30340;&#36830;&#25509;&#30001;&#36328;&#20219;&#21153;&#30340;&#8220;&#20844;&#20849;&#21442;&#25968;&#8221;&#25429;&#25417;&#65292;&#35813;&#21442;&#25968;&#36890;&#36807;&#20219;&#21153;&#32423;&#30340;&#8220;&#20010;&#20307;&#21442;&#25968;&#8221;&#36827;&#34892;&#32454;&#21270;&#12290;&#20219;&#20309;&#20984;&#20989;&#25968;&#65292;&#22914;&#33539;&#25968;&#65292;&#37117;&#21487;&#20197;&#34920;&#24449;&#20844;&#20849;&#21442;&#25968;&#21644;&#20010;&#20307;&#21442;&#25968;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#21246;&#21202;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#20960;&#20309;&#26465;&#20214;&#19979;&#20026;&#25152;&#26377;&#21442;&#25968;&#30340;&#20272;&#35745;&#35823;&#24046;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30340;&#38750;&#28176;&#36827;&#36793;&#30028;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20174;&#27719;&#38598;&#26679;&#26412;&#20013;&#21463;&#30410;&#20110;&#20844;&#20849;&#21442;&#25968;&#30340;&#24674;&#22797;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20960;&#20309;&#25910;&#25947;&#36895;&#24230;&#30340;&#36845;&#20195;&#20272;&#35745;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#30340;&#23454;&#39564;&#34917;&#20805;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#20840;&#38754;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#20998;&#26512;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#25968;&#25454;&#20016;&#23500;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of multi-task learning in the high dimensional setting. In particular, we introduce an estimator and investigate its statistical and computational properties for the problem of multiple connected linear regressions known as Data Enrichment/Sharing. The between-tasks connections are captured by a cross-tasks \emph{common parameter}, which gets refined by per-task \emph{individual parameters}. Any convex function, e.g., norm, can characterize the structure of both common and individual parameters. We delineate the sample complexity of our estimator and provide a high probability non-asymptotic bound for estimation error of all parameters under a geometric condition. We show that the recovery of the common parameter benefits from \emph{all} of the pooled samples. We propose an iterative estimation algorithm with a geometric convergence rate and supplement our theoretical analysis with experiments on synthetic data. Overall, we present a first thorough statistical a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#31639;&#27861;&#65292;&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#27493;&#39588;&#22788;&#29702;&#28151;&#21512;&#39033;&#25968;&#37327;&#30340;&#25351;&#25968;&#22686;&#38271;&#65292;&#24182;&#25552;&#20986;&#20102;&#32479;&#19968;&#31639;&#27861;&#30340;&#24179;&#26041;&#26681;&#23454;&#29616;&#12290;&#35813;&#31639;&#27861;&#22312;&#20960;&#20010;&#27169;&#25311;&#31995;&#32479;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/1705.05495</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Filtering Algorithm for Gaussian Mixture Models. (arXiv:1705.05495v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1705.05495
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#31639;&#27861;&#65292;&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#27493;&#39588;&#22788;&#29702;&#28151;&#21512;&#39033;&#25968;&#37327;&#30340;&#25351;&#25968;&#22686;&#38271;&#65292;&#24182;&#25552;&#20986;&#20102;&#32479;&#19968;&#31639;&#27861;&#30340;&#24179;&#26041;&#26681;&#23454;&#29616;&#12290;&#35813;&#31639;&#27861;&#22312;&#20960;&#20010;&#27169;&#25311;&#31995;&#32479;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#19968;&#31867;&#21487;&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#24314;&#27169;&#30340;&#29366;&#24577;&#31354;&#38388;&#31995;&#32479;&#24320;&#21457;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#28388;&#27874;&#31639;&#27861;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#36825;&#20010;&#28388;&#27874;&#38382;&#39064;&#30340;&#31934;&#30830;&#35299;&#28041;&#21450;&#21040;&#28151;&#21512;&#39033;&#25968;&#37327;&#30340;&#25351;&#25968;&#22686;&#38271;&#65292;&#22312;&#27492;&#36890;&#36807;&#22312;&#26102;&#38388;&#26356;&#26032;&#21644;&#27979;&#37327;&#26356;&#26032;&#20043;&#21518;&#21033;&#29992;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#27493;&#39588;&#22788;&#29702;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#32479;&#19968;&#31639;&#27861;&#30340;&#24179;&#26041;&#26681;&#23454;&#29616;&#65292;&#24182;&#22312;&#20960;&#20010;&#27169;&#25311;&#31995;&#32479;&#19978;&#36827;&#34892;&#20102;&#27010;&#35201;&#20998;&#26512;&#12290;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#29366;&#24577;&#20272;&#35745;&#65292;&#36825;&#20123;&#31995;&#32479;&#20005;&#26684;&#22806;&#20110;&#26412;&#25991;&#32771;&#34385;&#30340;&#31867;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Bayesian filtering algorithm is developed for a class of state-space systems that can be modelled via Gaussian mixtures. In general, the exact solution to this filtering problem involves an exponential growth in the number of mixture terms and this is handled here by utilising a Gaussian mixture reduction step after both the time and measurement updates. In addition, a square-root implementation of the unified algorithm is presented and this algorithm is profiled on several simulated systems. This includes the state estimation for two non-linear systems that are strictly outside the class considered in this paper.
&lt;/p&gt;</description></item></channel></rss>