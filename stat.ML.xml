<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#32467;&#21512;&#39034;&#24207;&#21270;&#30340;MCMC&#32467;&#26500;&#23398;&#20064;&#25216;&#26415;&#21644;&#26799;&#24230;&#22270;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#23558;&#22240;&#26524;&#32467;&#26500;&#25512;&#26029;&#38382;&#39064;&#20998;&#35299;&#20026;&#21464;&#37327;&#25299;&#25169;&#39034;&#24207;&#25512;&#26029;&#21644;&#21464;&#37327;&#29238;&#33410;&#28857;&#38598;&#21512;&#25512;&#26029;&#65292;&#21516;&#26102;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#22240;&#26524;&#26426;&#21046;&#24314;&#27169;&#23454;&#29616;&#31934;&#30830;&#36793;&#32536;&#21270;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;Rao-Blackwell&#21270;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.14781</link><description>&lt;p&gt;
Rao-Blackwellising Bayesian Causal Inference
&lt;/p&gt;
&lt;p&gt;
Rao-Blackwellising Bayesian Causal Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32467;&#21512;&#39034;&#24207;&#21270;&#30340;MCMC&#32467;&#26500;&#23398;&#20064;&#25216;&#26415;&#21644;&#26799;&#24230;&#22270;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#23558;&#22240;&#26524;&#32467;&#26500;&#25512;&#26029;&#38382;&#39064;&#20998;&#35299;&#20026;&#21464;&#37327;&#25299;&#25169;&#39034;&#24207;&#25512;&#26029;&#21644;&#21464;&#37327;&#29238;&#33410;&#28857;&#38598;&#21512;&#25512;&#26029;&#65292;&#21516;&#26102;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#22240;&#26524;&#26426;&#21046;&#24314;&#27169;&#23454;&#29616;&#31934;&#30830;&#36793;&#32536;&#21270;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;Rao-Blackwell&#21270;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#65292;&#21363;&#25512;&#26029;&#29992;&#20110;&#19979;&#28216;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#22240;&#26524;&#27169;&#22411;&#30340;&#21518;&#39564;&#27010;&#29575;&#65292;&#26500;&#25104;&#20102;&#19968;&#20010;&#22312;&#25991;&#29486;&#20013;&#40092;&#26377;&#25506;&#35752;&#30340;&#38590;&#35299;&#30340;&#35745;&#31639;&#25512;&#26029;&#38382;&#39064;&#12290;&#26412;&#25991;&#23558;&#22522;&#20110;&#39034;&#24207;&#30340;MCMC&#32467;&#26500;&#23398;&#20064;&#25216;&#26415;&#19982;&#26368;&#36817;&#26799;&#24230;&#22270;&#23398;&#20064;&#30340;&#36827;&#23637;&#30456;&#32467;&#21512;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#30340;&#38382;&#39064;&#20998;&#35299;&#20026;(i)&#25512;&#26029;&#21464;&#37327;&#20043;&#38388;&#30340;&#25299;&#25169;&#39034;&#24207;&#20197;&#21450;(ii)&#25512;&#26029;&#27599;&#20010;&#21464;&#37327;&#30340;&#29238;&#33410;&#28857;&#38598;&#21512;&#12290;&#24403;&#38480;&#21046;&#27599;&#20010;&#21464;&#37327;&#30340;&#29238;&#33410;&#28857;&#25968;&#37327;&#26102;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#23436;&#20840;&#36793;&#32536;&#21270;&#29238;&#33410;&#28857;&#38598;&#21512;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#24314;&#27169;&#26410;&#30693;&#30340;&#22240;&#26524;&#26426;&#21046;&#65292;&#20174;&#32780;&#20801;&#35768;&#20854;&#31934;&#30830;&#36793;&#32536;&#21270;&#12290;&#36825;&#24341;&#20837;&#20102;&#19968;&#20010;Rao-Blackwell&#21270;&#26041;&#26696;&#65292;&#20854;&#20013;&#38500;&#20102;&#22240;&#26524;&#39034;&#24207;&#20043;&#22806;&#65292;&#27169;&#22411;&#20013;&#30340;&#25152;&#26377;&#32452;&#20214;&#37117;&#34987;&#28040;&#38500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14781v1 Announce Type: cross  Abstract: Bayesian causal inference, i.e., inferring a posterior over causal models for the use in downstream causal reasoning tasks, poses a hard computational inference problem that is little explored in literature. In this work, we combine techniques from order-based MCMC structure learning with recent advances in gradient-based graph learning into an effective Bayesian causal inference framework. Specifically, we decompose the problem of inferring the causal structure into (i) inferring a topological order over variables and (ii) inferring the parent sets for each variable. When limiting the number of parents per variable, we can exactly marginalise over the parent sets in polynomial time. We further use Gaussian processes to model the unknown causal mechanisms, which also allows their exact marginalisation. This introduces a Rao-Blackwellization scheme, where all components are eliminated from the model, except for the causal order, for whi
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;SCM&#30340;&#27169;&#22411;&#31867;&#65292;&#29992;&#20110;&#22240;&#26524;&#25554;&#34917;&#20219;&#21153;&#65292;&#23558;&#32467;&#26524;&#34920;&#31034;&#20026;&#21453;&#20107;&#23454;&#65292;&#25805;&#20316;&#34920;&#31034;&#20026;&#23545;&#24037;&#20855;&#21464;&#37327;&#36827;&#34892;&#24178;&#39044;&#65292;&#29615;&#22659;&#22522;&#20110;&#21021;&#22987;&#23450;&#20041;&#12290;</title><link>https://arxiv.org/abs/2402.14777</link><description>&lt;p&gt;
&#22240;&#26524;&#25554;&#34917;&#29992;&#20110;&#21453;&#20107;&#23454;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65306;&#26725;&#25509;&#22270;&#21644;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Causal Imputation for Counterfactual SCMs: Bridging Graphs and Latent Factor Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14777
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;SCM&#30340;&#27169;&#22411;&#31867;&#65292;&#29992;&#20110;&#22240;&#26524;&#25554;&#34917;&#20219;&#21153;&#65292;&#23558;&#32467;&#26524;&#34920;&#31034;&#20026;&#21453;&#20107;&#23454;&#65292;&#25805;&#20316;&#34920;&#31034;&#20026;&#23545;&#24037;&#20855;&#21464;&#37327;&#36827;&#34892;&#24178;&#39044;&#65292;&#29615;&#22659;&#22522;&#20110;&#21021;&#22987;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22240;&#26524;&#25554;&#34917;&#20219;&#21153;&#65292;&#26088;&#22312;&#39044;&#27979;&#19968;&#31995;&#21015;&#25805;&#20316;&#22312;&#21508;&#31181;&#21487;&#33021;&#29615;&#22659;&#19979;&#30340;&#32467;&#26524;&#12290;&#20197;&#39044;&#27979;&#19981;&#21516;&#33647;&#29289;&#22914;&#20309;&#24433;&#21709;&#19981;&#21516;&#32454;&#32990;&#31867;&#22411;&#20026;&#36816;&#34892;&#31034;&#20363;&#12290;&#25105;&#20204;&#30740;&#31350;&#25351;&#26631;&#21807;&#19968;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#25805;&#20316;&#21644;&#29615;&#22659;&#26159;&#20855;&#26377;&#26377;&#38480;&#21487;&#33021;&#20540;&#30340;&#20998;&#31867;&#21464;&#37327;&#12290;&#21363;&#20351;&#22312;&#36825;&#31181;&#31616;&#21333;&#35774;&#32622;&#20013;&#65292;&#30001;&#20110;&#36890;&#24120;&#21482;&#26377;&#24456;&#23569;&#21487;&#33021;&#30340;&#25805;&#20316;-&#29615;&#22659;&#23545;&#24471;&#21040;&#30740;&#31350;&#65292;&#22240;&#27492;&#23384;&#22312;&#23454;&#38469;&#25361;&#25112;&#12290;&#27169;&#22411;&#24517;&#39035;&#23545;&#26032;&#39062;&#30340;&#25805;&#20316;-&#29615;&#22659;&#23545;&#36827;&#34892;&#22806;&#25512;&#65292;&#36825;&#21487;&#20197;&#34987;&#26500;&#36896;&#20026;&#34892;&#30001;&#25805;&#20316;&#32034;&#24341;&#12289;&#21015;&#30001;&#29615;&#22659;&#32034;&#24341;&#12289;&#30697;&#38453;&#26465;&#30446;&#23545;&#24212;&#32467;&#26524;&#30340;&#19968;&#31181;&#30697;&#38453;&#34917;&#20840;&#24418;&#24335;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;SCM&#30340;&#27169;&#22411;&#31867;&#65292;&#20854;&#20013;&#32467;&#26524;&#34920;&#31034;&#20026;&#21453;&#20107;&#23454;&#65292;&#25805;&#20316;&#34920;&#31034;&#20026;&#23545;&#24037;&#20855;&#21464;&#37327;&#36827;&#34892;&#24178;&#39044;&#65292;&#29615;&#22659;&#22522;&#20110;&#21021;&#22987;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14777v1 Announce Type: cross  Abstract: We consider the task of causal imputation, where we aim to predict the outcomes of some set of actions across a wide range of possible contexts. As a running example, we consider predicting how different drugs affect cells from different cell types. We study the index-only setting, where the actions and contexts are categorical variables with a finite number of possible values. Even in this simple setting, a practical challenge arises, since often only a small subset of possible action-context pairs have been studied. Thus, models must extrapolate to novel action-context pairs, which can be framed as a form of matrix completion with rows indexed by actions, columns indexed by contexts, and matrix entries corresponding to outcomes. We introduce a novel SCM-based model class, where the outcome is expressed as a counterfactual, actions are expressed as interventions on an instrumental variable, and contexts are defined based on the initia
&lt;/p&gt;</description></item><item><title>BaM&#26159;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#30340;BBVI&#26367;&#20195;&#26041;&#27861;&#65292;&#38024;&#23545;&#39640;&#26041;&#24046;&#26799;&#24230;&#20272;&#35745;&#24930;&#25910;&#25947;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#39640;&#26031;&#21464;&#20998;&#26063;&#20013;&#36890;&#36807;&#23553;&#38381;&#24418;&#24335;&#30340;&#36817;&#31471;&#26356;&#26032;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#26102;&#65292;&#25209;&#22788;&#29702;&#22823;&#23567;&#36235;&#20110;&#26080;&#31351;&#26102;&#21464;&#20998;&#21442;&#25968;&#26356;&#26032;&#23558;&#25351;&#25968;&#24555;&#36895;&#25910;&#25947;&#21040;&#30446;&#26631;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#65292;BaM&#22312;&#22810;&#31181;&#29983;&#25104;&#27169;&#22411;&#25512;&#26029;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#24615;&#33021;</title><link>https://arxiv.org/abs/2402.14758</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;&#21644;&#21305;&#37197;&#65306;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#30340;&#40657;&#21283;&#23376;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Batch and match: black-box variational inference with a score-based divergence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14758
&lt;/p&gt;
&lt;p&gt;
BaM&#26159;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#30340;BBVI&#26367;&#20195;&#26041;&#27861;&#65292;&#38024;&#23545;&#39640;&#26041;&#24046;&#26799;&#24230;&#20272;&#35745;&#24930;&#25910;&#25947;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#39640;&#26031;&#21464;&#20998;&#26063;&#20013;&#36890;&#36807;&#23553;&#38381;&#24418;&#24335;&#30340;&#36817;&#31471;&#26356;&#26032;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#26102;&#65292;&#25209;&#22788;&#29702;&#22823;&#23567;&#36235;&#20110;&#26080;&#31351;&#26102;&#21464;&#20998;&#21442;&#25968;&#26356;&#26032;&#23558;&#25351;&#25968;&#24555;&#36895;&#25910;&#25947;&#21040;&#30446;&#26631;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#65292;BaM&#22312;&#22810;&#31181;&#29983;&#25104;&#27169;&#22411;&#25512;&#26029;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#20027;&#35201;&#30340;&#40657;&#21283;&#23376;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#23454;&#29616;&#37117;&#26159;&#22522;&#20110;&#20248;&#21270;&#38543;&#26426;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#12290;&#20294;&#26159;&#65292;&#36825;&#31181;BBVI&#26041;&#27861;&#36890;&#24120;&#30001;&#20110;&#20854;&#26799;&#24230;&#20272;&#35745;&#30340;&#39640;&#26041;&#24046;&#32780;&#25910;&#25947;&#32531;&#24930;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25209;&#22788;&#29702;&#21644;&#21305;&#37197;&#65288;BaM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#30340;BBVI&#26367;&#20195;&#26041;&#27861;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#21487;&#20197;&#36890;&#36807;&#23545;&#20855;&#26377;&#20840;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#21464;&#20998;&#26063;&#20351;&#29992;&#23553;&#38381;&#24418;&#24335;&#30340;&#36817;&#31471;&#26356;&#26032;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#24403;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;BaM&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#22312;&#25209;&#37327;&#22823;&#23567;&#36235;&#20110;&#26080;&#31351;&#26102;&#21464;&#20998;&#21442;&#25968;&#26356;&#26032;&#20250;&#25351;&#25968;&#25910;&#25947;&#21040;&#30446;&#26631;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;BaM&#22312;&#28304;&#33258;&#23618;&#27425;&#21644;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21518;&#39564;&#25512;&#26029;&#30340;&#39640;&#26031;&#21644;&#38750;&#39640;&#26031;&#30446;&#26631;&#20998;&#24067;&#19978;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#20123;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;BaM&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14758v1 Announce Type: cross  Abstract: Most leading implementations of black-box variational inference (BBVI) are based on optimizing a stochastic evidence lower bound (ELBO). But such approaches to BBVI often converge slowly due to the high variance of their gradient estimates. In this work, we propose batch and match (BaM), an alternative approach to BBVI based on a score-based divergence. Notably, this score-based divergence can be optimized by a closed-form proximal update for Gaussian variational families with full covariance matrices. We analyze the convergence of BaM when the target distribution is Gaussian, and we prove that in the limit of infinite batch size the variational parameter updates converge exponentially quickly to the target mean and covariance. We also evaluate the performance of BaM on Gaussian and non-Gaussian target distributions that arise from posterior inference in hierarchical and deep generative models. In these experiments, we find that BaM ty
&lt;/p&gt;</description></item><item><title>Transformers&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#30340;&#36807;&#31243;&#20013;&#65292;&#20851;&#38190;&#30340;&#35777;&#25454;&#26159;&#27880;&#24847;&#21147;&#30697;&#38453;&#30340;&#26799;&#24230;&#32534;&#30721;&#20102;token&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;</title><link>https://arxiv.org/abs/2402.14735</link><description>&lt;p&gt;
Transformers&#22914;&#20309;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
How Transformers Learn Causal Structure with Gradient Descent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14735
&lt;/p&gt;
&lt;p&gt;
Transformers&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#30340;&#36807;&#31243;&#20013;&#65292;&#20851;&#38190;&#30340;&#35777;&#25454;&#26159;&#27880;&#24847;&#21147;&#30697;&#38453;&#30340;&#26799;&#24230;&#32534;&#30721;&#20102;token&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformers&#22312;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#38590;&#20197;&#32622;&#20449;&#30340;&#25104;&#21151;&#65292;&#36825;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24402;&#21151;&#20110;&#33258;&#27880;&#24847;&#26426;&#21046;&#65292;&#23427;&#20801;&#35768;&#20449;&#24687;&#22312;&#24207;&#21015;&#30340;&#19981;&#21516;&#37096;&#20998;&#20043;&#38388;&#20256;&#36882;&#12290;&#33258;&#27880;&#24847;&#26426;&#21046;&#20351;&#24471;transformers&#33021;&#22815;&#32534;&#30721;&#22240;&#26524;&#32467;&#26500;&#65292;&#20174;&#32780;&#20351;&#20854;&#29305;&#21035;&#36866;&#21512;&#24207;&#21015;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;transformers&#36890;&#36807;&#26799;&#24230;&#35757;&#32451;&#31639;&#27861;&#23398;&#20064;&#36825;&#31181;&#22240;&#26524;&#32467;&#26500;&#30340;&#36807;&#31243;&#20173;&#28982;&#19981;&#22826;&#28165;&#26970;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#20010;&#36807;&#31243;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38656;&#35201;&#23398;&#20064;&#28508;&#22312;&#22240;&#26524;&#32467;&#26500;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#20219;&#21153;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31616;&#21270;&#30340;&#20004;&#23618;transformer&#19978;&#30340;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#23398;&#20250;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#36890;&#36807;&#22312;&#31532;&#19968;&#23618;&#27880;&#24847;&#21147;&#20013;&#32534;&#30721;&#28508;&#22312;&#22240;&#26524;&#22270;&#26469;&#23436;&#25104;&#12290;&#25105;&#20204;&#35777;&#26126;&#30340;&#20851;&#38190;&#27934;&#23519;&#26159;&#27880;&#24847;&#21147;&#30697;&#38453;&#30340;&#26799;&#24230;&#32534;&#30721;&#20102;token&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#30001;&#20110;&#25968;&#25454;&#22788;&#29702;&#19981;&#31561;&#24335;&#30340;&#32467;&#26524;&#65292;&#27880;&#24847;&#21147;&#30697;&#38453;&#20013;&#26368;&#22823;&#30340;&#26465;&#30446;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14735v1 Announce Type: new  Abstract: The incredible success of transformers on sequence modeling tasks can be largely attributed to the self-attention mechanism, which allows information to be transferred between different parts of a sequence. Self-attention allows transformers to encode causal structure which makes them particularly suitable for sequence modeling. However, the process by which transformers learn such causal structure via gradient-based training algorithms remains poorly understood. To better understand this process, we introduce an in-context learning task that requires learning latent causal structure. We prove that gradient descent on a simplified two-layer transformer learns to solve this task by encoding the latent causal graph in the first attention layer. The key insight of our proof is that the gradient of the attention matrix encodes the mutual information between tokens. As a consequence of the data processing inequality, the largest entries of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#19987;&#23478;&#35268;&#21017;&#34701;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24418;&#25104;&#32422;&#26463;&#21644;&#20351;&#29992;&#20984;&#22810;&#38754;&#20307;&#26469;&#20445;&#35777;&#36755;&#20986;&#27010;&#29575;&#19981;&#36829;&#21453;&#19987;&#23478;&#35268;&#21017;&#65292;&#23454;&#29616;&#20102;&#24402;&#32435;&#19982;&#28436;&#32462;&#23398;&#20064;&#30340;&#32467;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.14726</link><description>&lt;p&gt;
&#22312;&#27010;&#24565;&#23398;&#20064;&#26694;&#26550;&#20013;&#23558;&#19987;&#23478;&#35268;&#21017;&#34701;&#20837;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Incorporating Expert Rules into Neural Networks in the Framework of Concept-Based Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#19987;&#23478;&#35268;&#21017;&#34701;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24418;&#25104;&#32422;&#26463;&#21644;&#20351;&#29992;&#20984;&#22810;&#38754;&#20307;&#26469;&#20445;&#35777;&#36755;&#20986;&#27010;&#29575;&#19981;&#36829;&#21453;&#19987;&#23478;&#35268;&#21017;&#65292;&#23454;&#29616;&#20102;&#24402;&#32435;&#19982;&#28436;&#32462;&#23398;&#20064;&#30340;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38416;&#36848;&#20102;&#23558;&#19987;&#23478;&#35268;&#21017;&#34701;&#20837;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#20197;&#25193;&#23637;&#22522;&#20110;&#27010;&#24565;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#22914;&#20309;&#23558;&#36923;&#36753;&#35268;&#21017;&#21644;&#39044;&#27979;&#27010;&#24565;&#27010;&#29575;&#30340;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#12290;&#35813;&#32452;&#21512;&#32972;&#21518;&#30340;&#31532;&#19968;&#20010;&#24819;&#27861;&#26159;&#24418;&#25104;&#32422;&#26463;&#65292;&#20197;&#28385;&#36275;&#19987;&#23478;&#35268;&#21017;&#30340;&#25152;&#26377;&#27010;&#24565;&#20540;&#32452;&#21512;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#31532;&#20108;&#20010;&#24819;&#27861;&#26159;&#20197;&#20984;&#22810;&#38754;&#20307;&#30340;&#24418;&#24335;&#34920;&#31034;&#27010;&#29575;&#20998;&#24067;&#30340;&#21487;&#34892;&#38598;&#65292;&#24182;&#20351;&#29992;&#20854;&#39030;&#28857;&#25110;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14726v1 Announce Type: cross  Abstract: A problem of incorporating the expert rules into machine learning models for extending the concept-based learning is formulated in the paper. It is proposed how to combine logical rules and neural networks predicting the concept probabilities. The first idea behind the combination is to form constraints for a joint probability distribution over all combinations of concept values to satisfy the expert rules. The second idea is to represent a feasible set of probability distributions in the form of a convex polytope and to use its vertices or faces. We provide several approaches for solving the stated problem and for training neural networks which guarantee that the output probabilities of concepts would not violate the expert rules. The solution of the problem can be viewed as a way for combining the inductive and deductive learning. Expert rules are used in a broader sense when any logical function that connects concepts and class labe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;POMDP&#32467;&#26500;&#30340;&#26032;&#39062;&#35206;&#30422;&#20551;&#35774;&#65292;&#20197;&#35299;&#20915;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#26041;&#27861;&#20013;&#30340;&#38271;&#24230;&#25351;&#25968;&#22686;&#38271;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.14703</link><description>&lt;p&gt;
&#22312;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#20013;&#25506;&#35752;&#26410;&#26469;&#21644;&#21382;&#21490;&#30340;&#35781;&#21650;&#22312;&#31163;&#32447;&#35780;&#20272;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;POMDP&#32467;&#26500;&#30340;&#26032;&#39062;&#35206;&#30422;&#20551;&#35774;&#65292;&#20197;&#35299;&#20915;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#26041;&#27861;&#20013;&#30340;&#38271;&#24230;&#25351;&#25968;&#22686;&#38271;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#22797;&#26434;&#35266;&#27979;&#30340;&#31163;&#32447;&#35780;&#20272;(OPE)&#65292;&#26088;&#22312;&#24320;&#21457;&#33021;&#22815;&#36991;&#20813;&#23545;&#26102;&#38388;&#36328;&#24230;&#25351;&#25968;&#20381;&#36182;&#30340;&#20272;&#35745;&#22120;&#12290;&#26368;&#36817;&#65292;Uehara&#31561;&#20154;&#65288;2022&#24180;&#65289;&#25552;&#20986;&#20102;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#20316;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#35813;&#26694;&#26550;&#20063;&#21462;&#20915;&#20110;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#30340;&#26377;&#30028;&#24615;&#20197;&#21450;&#20854;&#20182;&#30456;&#20851;&#25968;&#37327;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;&#25968;&#37327;&#21487;&#33021;&#20250;&#38543;&#30528;&#38271;&#24230;&#21576;&#25351;&#25968;&#22686;&#38271;&#65292;&#20174;&#32780;&#25273;&#21435;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#38024;&#23545;POMDP&#32467;&#26500;&#30340;&#26032;&#39062;&#35206;&#30422;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14703v1 Announce Type: cross  Abstract: We study off-policy evaluation (OPE) in partially observable environments with complex observations, with the goal of developing estimators whose guarantee avoids exponential dependence on the horizon. While such estimators exist for MDPs and POMDPs can be converted to history-based MDPs, their estimation errors depend on the state-density ratio for MDPs which becomes history ratios after conversion, an exponential object. Recently, Uehara et al. (2022) proposed future-dependent value functions as a promising framework to address this issue, where the guarantee for memoryless policies depends on the density ratio over the latent state space. However, it also depends on the boundedness of the future-dependent value function and other related quantities, which we show could be exponential-in-length and thus erasing the advantage of the method. In this paper, we discover novel coverage assumptions tailored to the structure of POMDPs, such
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#26041;&#24046;&#20999;&#25442;&#30340;&#33258;&#36866;&#24212;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#29702;&#35770;&#21644;&#19987;&#23478;&#32858;&#21512;&#26041;&#27861;&#26469;&#23398;&#20064;&#26041;&#24046;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#22312;&#30005;&#37327;&#36127;&#33655;&#39044;&#27979;&#38382;&#39064;&#20013;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>https://arxiv.org/abs/2402.14684</link><description>&lt;p&gt;
&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#26041;&#24046;&#20999;&#25442;&#30340;&#33258;&#36866;&#24212;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Adaptive time series forecasting with markovian variance switching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14684
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#26041;&#24046;&#20999;&#25442;&#30340;&#33258;&#36866;&#24212;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#29702;&#35770;&#21644;&#19987;&#23478;&#32858;&#21512;&#26041;&#27861;&#26469;&#23398;&#20064;&#26041;&#24046;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#22312;&#30005;&#37327;&#36127;&#33655;&#39044;&#27979;&#38382;&#39064;&#20013;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#23545;&#20110;&#22312;&#21046;&#24230;&#21464;&#21270;&#19979;&#36827;&#34892;&#39044;&#27979;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#35768;&#22810;&#20256;&#32479;&#26041;&#27861;&#20551;&#35774;&#20855;&#26377;&#22312;&#26102;&#38388;&#19978;&#24658;&#23450;&#30340;&#26041;&#24046;&#30340;&#32447;&#24615;&#39640;&#26031;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;LGSSM&#65289;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#36807;&#31243;&#19981;&#33021;&#34987;&#36825;&#26679;&#30340;&#27169;&#22411;&#25429;&#25417;&#12290;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#20999;&#25442;&#26041;&#24046;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#12290;&#36825;&#26679;&#30340;&#21160;&#24577;&#31995;&#32479;&#36890;&#24120;&#26159;&#26080;&#27861;&#35299;&#20915;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38543;&#26102;&#38388;&#21576;&#25351;&#25968;&#22686;&#38271;&#65307;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;VB&#65289;&#25216;&#26415;&#24050;&#34987;&#24212;&#29992;&#20110;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#29702;&#35770;&#30340;&#26032;&#30340;&#20272;&#35745;&#26041;&#24046;&#30340;&#26041;&#27861;&#65307;&#25105;&#20204;&#35843;&#25972;&#19987;&#23478;&#32858;&#21512;&#26041;&#27861;&#26469;&#38543;&#26102;&#38388;&#23398;&#20064;&#26041;&#24046;&#12290;&#25105;&#20204;&#23558;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#21512;&#25104;&#25968;&#25454;&#20197;&#21450;&#29992;&#20110;&#30005;&#37327;&#36127;&#33655;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#35823;&#24046;&#20272;&#35745;&#30340;&#31283;&#20581;&#24615;&#65292;&#24182;&#20248;&#20110;&#20256;&#32479;&#30340;&#19987;&#23478;&#32858;&#21512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14684v1 Announce Type: cross  Abstract: Adaptive time series forecasting is essential for prediction under regime changes. Several classical methods assume linear Gaussian state space model (LGSSM) with variances constant in time. However, there are many real-world processes that cannot be captured by such models. We consider a state-space model with Markov switching variances. Such dynamical systems are usually intractable because of their computational complexity increasing exponentially with time; Variational Bayes (VB) techniques have been applied to this problem. In this paper, we propose a new way of estimating variances based on online learning theory; we adapt expert aggregation methods to learn the variances over time. We apply the proposed method to synthetic data and to the problem of electricity load forecasting. We show that this method is robust to misspecification and outperforms traditional expert aggregation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#26500;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#20808;&#39564;&#25429;&#25417;&#21160;&#20316;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#31163;&#31574;&#30053;&#35780;&#20272;&#21644;&#23398;&#20064;&#30340;&#36890;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;sDM&#65292;&#24182;&#24341;&#20837;&#20102;&#33021;&#35780;&#20272;&#31639;&#27861;&#22312;&#22810;&#38382;&#39064;&#23454;&#20363;&#20013;&#24179;&#22343;&#34920;&#29616;&#30340;&#36125;&#21494;&#26031;&#25351;&#26631;&#65292;&#20998;&#26512;&#20102;sDM&#22312;OPE&#21644;OPL&#20013;&#21033;&#29992;&#21160;&#20316;&#30456;&#20851;&#24615;&#30340;&#20248;&#21183;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#24378;&#22823;&#24615;&#33021;</title><link>https://arxiv.org/abs/2402.14664</link><description>&lt;p&gt;
&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#36125;&#21494;&#26031;&#31163;&#31574;&#30053;&#35780;&#20272;&#19982;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian Off-Policy Evaluation and Learning for Large Action Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14664
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#26500;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#20808;&#39564;&#25429;&#25417;&#21160;&#20316;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#31163;&#31574;&#30053;&#35780;&#20272;&#21644;&#23398;&#20064;&#30340;&#36890;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;sDM&#65292;&#24182;&#24341;&#20837;&#20102;&#33021;&#35780;&#20272;&#31639;&#27861;&#22312;&#22810;&#38382;&#39064;&#23454;&#20363;&#20013;&#24179;&#22343;&#34920;&#29616;&#30340;&#36125;&#21494;&#26031;&#25351;&#26631;&#65292;&#20998;&#26512;&#20102;sDM&#22312;OPE&#21644;OPL&#20013;&#21033;&#29992;&#21160;&#20316;&#30456;&#20851;&#24615;&#30340;&#20248;&#21183;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#24378;&#22823;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20132;&#20114;&#24335;&#31995;&#32479;&#20013;&#65292;&#21160;&#20316;&#32463;&#24120;&#26159;&#30456;&#20851;&#30340;&#65292;&#36825;&#20026;&#22823;&#21160;&#20316;&#31354;&#38388;&#20013;&#26356;&#26377;&#25928;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#21644;&#23398;&#20064;&#65288;OPL&#65289;&#25552;&#20379;&#20102;&#26426;&#20250;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#26500;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#20808;&#39564;&#26469;&#25429;&#25417;&#36825;&#20123;&#30456;&#20851;&#24615;&#12290;&#22312;&#35813;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;sDM&#65292;&#19968;&#20010;&#20026;OPE&#21644;OPL&#35774;&#35745;&#30340;&#36890;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#26082;&#26377;&#31639;&#27861;&#22522;&#30784;&#21448;&#26377;&#29702;&#35770;&#22522;&#30784;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;sDM&#21033;&#29992;&#21160;&#20316;&#30456;&#20851;&#24615;&#32780;&#19981;&#20250;&#24433;&#21709;&#35745;&#31639;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#21463;&#22312;&#32447;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#35780;&#20272;&#31639;&#27861;&#22312;&#22810;&#20010;&#38382;&#39064;&#23454;&#20363;&#20013;&#24179;&#22343;&#24615;&#33021;&#30340;&#36125;&#21494;&#26031;&#25351;&#26631;&#65292;&#20559;&#31163;&#20256;&#32479;&#30340;&#26368;&#22351;&#24773;&#20917;&#35780;&#20272;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;sDM&#22312;OPE&#21644;OPL&#20013;&#30340;&#34920;&#29616;&#65292;&#20984;&#26174;&#20102;&#21033;&#29992;&#21160;&#20316;&#30456;&#20851;&#24615;&#30340;&#22909;&#22788;&#12290;&#23454;&#35777;&#35777;&#25454;&#23637;&#31034;&#20102;sDM&#30340;&#24378;&#22823;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14664v1 Announce Type: cross  Abstract: In interactive systems, actions are often correlated, presenting an opportunity for more sample-efficient off-policy evaluation (OPE) and learning (OPL) in large action spaces. We introduce a unified Bayesian framework to capture these correlations through structured and informative priors. In this framework, we propose sDM, a generic Bayesian approach designed for OPE and OPL, grounded in both algorithmic and theoretical foundations. Notably, sDM leverages action correlations without compromising computational efficiency. Moreover, inspired by online Bayesian bandits, we introduce Bayesian metrics that assess the average performance of algorithms across multiple problem instances, deviating from the conventional worst-case assessments. We analyze sDM in OPE and OPL, highlighting the benefits of leveraging action correlations. Empirical evidence showcases the strong performance of sDM.
&lt;/p&gt;</description></item><item><title>CoLoRA&#36890;&#36807;&#36830;&#32493;&#20302;&#31209;&#33258;&#36866;&#24212;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#39044;&#27979;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#35299;&#28436;&#21464;&#30340;&#31616;&#21270;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.14646</link><description>&lt;p&gt;
CoLoRA:&#29992;&#20110;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#31616;&#21270;&#38544;&#24335;&#31070;&#32463;&#24314;&#27169;&#30340;&#36830;&#32493;&#20302;&#31209;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
CoLoRA: Continuous low-rank adaptation for reduced implicit neural modeling of parameterized partial differential equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14646
&lt;/p&gt;
&lt;p&gt;
CoLoRA&#36890;&#36807;&#36830;&#32493;&#20302;&#31209;&#33258;&#36866;&#24212;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#39044;&#27979;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#35299;&#28436;&#21464;&#30340;&#31616;&#21270;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36830;&#32493;&#20302;&#31209;&#33258;&#36866;&#24212;&#65288;CoLoRA&#65289;&#30340;&#31616;&#21270;&#27169;&#22411;&#65292;&#23427;&#39044;&#20808;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36866;&#29992;&#20110;&#32473;&#23450;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#28982;&#21518;&#22312;&#26102;&#38388;&#19978;&#36830;&#32493;&#22320;&#35843;&#25972;&#20302;&#31209;&#26435;&#37325;&#65292;&#20197;&#24555;&#36895;&#39044;&#27979;&#26032;&#29289;&#29702;&#21442;&#25968;&#21644;&#26032;&#21021;&#22987;&#26465;&#20214;&#19979;&#35299;&#22330;&#30340;&#28436;&#21464;&#12290;&#33258;&#36866;&#24212;&#21487;&#20197;&#26159;&#32431;&#31929;&#25968;&#25454;&#39537;&#21160;&#30340;&#65292;&#20063;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#26041;&#31243;&#39537;&#21160;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#25552;&#20379;Galerkin&#26368;&#20248;&#30340;&#36924;&#36817;&#12290;&#30001;&#20110;CoLoRA&#22312;&#26102;&#38388;&#19978;&#23616;&#37096;&#36924;&#36817;&#35299;&#22330;&#65292;&#26435;&#37325;&#30340;&#31209;&#21487;&#20197;&#20445;&#25345;&#36739;&#23567;&#65292;&#36825;&#24847;&#21619;&#30528;&#21482;&#38656;&#35201;&#31163;&#32447;&#35757;&#32451;&#20960;&#26465;&#36712;&#36857;&#65292;&#22240;&#27492;CoLoRA&#38750;&#24120;&#36866;&#29992;&#20110;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;CoLoRA&#30340;&#39044;&#27979;&#36895;&#24230;&#24555;&#19978;&#20960;&#20010;&#25968;&#37327;&#32423;&#65292;&#20854;&#20934;&#30830;&#24230;&#21644;&#21442;&#25968;&#25928;&#29575;&#20063;&#27604;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14646v1 Announce Type: new  Abstract: This work introduces reduced models based on Continuous Low Rank Adaptation (CoLoRA) that pre-train neural networks for a given partial differential equation and then continuously adapt low-rank weights in time to rapidly predict the evolution of solution fields at new physics parameters and new initial conditions. The adaptation can be either purely data-driven or via an equation-driven variational approach that provides Galerkin-optimal approximations. Because CoLoRA approximates solution fields locally in time, the rank of the weights can be kept small, which means that only few training trajectories are required offline so that CoLoRA is well suited for data-scarce regimes. Predictions with CoLoRA are orders of magnitude faster than with classical methods and their accuracy and parameter efficiency is higher compared to other neural network approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#22312;&#25152;&#26377;&#39640;&#25928;&#31639;&#27861;&#30340;&#24179;&#22343;&#24773;&#20917;&#22256;&#38590;&#24615;&#30340;&#35777;&#25454;&#65292;&#20551;&#35774;&#26684;&#38382;&#39064;&#30340;&#26368;&#22351;&#24773;&#20917;&#22256;&#38590;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14645</link><description>&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#26684;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Sparse Linear Regression and Lattice Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14645
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#22312;&#25152;&#26377;&#39640;&#25928;&#31639;&#27861;&#30340;&#24179;&#22343;&#24773;&#20917;&#22256;&#38590;&#24615;&#30340;&#35777;&#25454;&#65292;&#20551;&#35774;&#26684;&#38382;&#39064;&#30340;&#26368;&#22351;&#24773;&#20917;&#22256;&#38590;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#65288;SLR&#65289;&#26159;&#32479;&#35745;&#23398;&#20013;&#19968;&#20010;&#30740;&#31350;&#33391;&#22909;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#32473;&#23450;&#35774;&#35745;&#30697;&#38453; $X\in\mathbb{R}^{m\times n}$ &#21644;&#21709;&#24212;&#21521;&#37327; $y=X\theta^*+w$&#65292;&#20854;&#20013; $\theta^*$ &#26159; $k$-&#31232;&#30095;&#21521;&#37327;&#65288;&#21363;&#65292;$\|\theta^*\|_0\leq k$&#65289;&#65292;$w$ &#26159;&#23567;&#30340;&#12289;&#20219;&#24847;&#30340;&#22122;&#22768;&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010; $k$-&#31232;&#30095;&#30340; $\widehat{\theta} \in \mathbb{R}^n$&#65292;&#20351;&#24471;&#22343;&#26041;&#39044;&#27979;&#35823;&#24046; $\frac{1}{m}\|X\widehat{\theta}-X\theta^*\|^2_2$ &#26368;&#23567;&#21270;&#12290;&#34429;&#28982; $\ell_1$-&#26494;&#24347;&#26041;&#27861;&#22914;&#22522; Pursuit&#12289;Lasso &#21644; Dantzig &#36873;&#25321;&#22120;&#22312;&#35774;&#35745;&#30697;&#38453;&#26465;&#20214;&#33391;&#22909;&#26102;&#35299;&#20915;&#20102; SLR&#65292;&#20294;&#27809;&#26377;&#24050;&#30693;&#36890;&#29992;&#31639;&#27861;&#65292;&#20063;&#27809;&#26377;&#20219;&#20309;&#20851;&#20110;&#22312;&#25152;&#26377;&#39640;&#25928;&#31639;&#27861;&#30340;&#24179;&#22343;&#24773;&#20917;&#35774;&#32622;&#20013;&#30340;&#22256;&#38590;&#24615;&#30340;&#27491;&#24335;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14645v1 Announce Type: new  Abstract: Sparse linear regression (SLR) is a well-studied problem in statistics where one is given a design matrix $X\in\mathbb{R}^{m\times n}$ and a response vector $y=X\theta^*+w$ for a $k$-sparse vector $\theta^*$ (that is, $\|\theta^*\|_0\leq k$) and small, arbitrary noise $w$, and the goal is to find a $k$-sparse $\widehat{\theta} \in \mathbb{R}^n$ that minimizes the mean squared prediction error $\frac{1}{m}\|X\widehat{\theta}-X\theta^*\|^2_2$. While $\ell_1$-relaxation methods such as basis pursuit, Lasso, and the Dantzig selector solve SLR when the design matrix is well-conditioned, no general algorithm is known, nor is there any formal evidence of hardness in an average-case setting with respect to all efficient algorithms.   We give evidence of average-case hardness of SLR w.r.t. all efficient algorithms assuming the worst-case hardness of lattice problems. Specifically, we give an instance-by-instance reduction from a variant of the bo
&lt;/p&gt;</description></item><item><title>latrend&#26694;&#26550;&#20026;&#32437;&#21521;&#25968;&#25454;&#32858;&#31867;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26041;&#27861;&#24212;&#29992;&#26694;&#26550;&#65292;&#26041;&#20415;&#30740;&#31350;&#20154;&#21592;&#27604;&#36739;&#19981;&#21516;&#26041;&#27861;&#65292;&#23454;&#29616;&#24555;&#36895;&#21407;&#22411;&#35774;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.14621</link><description>&lt;p&gt;
latrend: &#29992;&#20110;&#32858;&#31867;&#32437;&#21521;&#25968;&#25454;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
latrend: A Framework for Clustering Longitudinal Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14621
&lt;/p&gt;
&lt;p&gt;
latrend&#26694;&#26550;&#20026;&#32437;&#21521;&#25968;&#25454;&#32858;&#31867;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26041;&#27861;&#24212;&#29992;&#26694;&#26550;&#65292;&#26041;&#20415;&#30740;&#31350;&#20154;&#21592;&#27604;&#36739;&#19981;&#21516;&#26041;&#27861;&#65292;&#23454;&#29616;&#24555;&#36895;&#21407;&#22411;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32437;&#21521;&#25968;&#25454;&#30340;&#32858;&#31867;&#29992;&#20110;&#25506;&#32034;&#19981;&#21516;&#20027;&#39064;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#20849;&#21516;&#36235;&#21183;&#65292;&#20197;&#25968;&#20540;&#27979;&#37327;&#20026;&#20852;&#36259;&#12290;&#22810;&#24180;&#26469;&#24341;&#20837;&#20102;&#21508;&#31181;R&#21253;&#65292;&#29992;&#20110;&#35782;&#21035;&#32437;&#21521;&#27169;&#24335;&#30340;&#32858;&#31867;&#65292;&#20197;&#19968;&#31181;&#25110;&#22810;&#31181;&#36235;&#21183;&#26469;&#24635;&#32467;&#20027;&#39064;&#20043;&#38388;&#36712;&#36857;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;R&#21253;"latrend"&#20316;&#20026;&#32437;&#21521;&#32858;&#31867;&#26041;&#27861;&#30340;&#32479;&#19968;&#24212;&#29992;&#26694;&#26550;&#65292;&#20351;&#24471;&#21487;&#20197;&#22312;&#26368;&#23567;&#32534;&#30721;&#37327;&#24773;&#20917;&#19979;&#27604;&#36739;&#21508;&#31181;&#26041;&#27861;&#12290;&#35813;&#21253;&#36824;&#20316;&#20026;&#24120;&#29992;&#21253;"dtwclust"&#12289;"flexmix"&#12289;"kml"&#12289;"lcmm"&#12289;"mclust"&#12289;"mixAK"&#21644;"mixtools"&#30340;&#25509;&#21475;&#65292;&#36825;&#20351;&#24471;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#36731;&#26494;&#27604;&#36739;&#19981;&#21516;&#26041;&#27861;&#12289;&#23454;&#29616;&#21644;&#26041;&#27861;&#35268;&#33539;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20154;&#21592;&#36824;&#21487;&#20197;&#21033;&#29992;&#26694;&#26550;&#25552;&#20379;&#30340;&#26631;&#20934;&#24037;&#20855;&#26469;&#24555;&#36895;&#23454;&#29616;&#26032;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#24555;&#36895;&#21407;&#22411;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14621v1 Announce Type: new  Abstract: Clustering of longitudinal data is used to explore common trends among subjects over time for a numeric measurement of interest. Various R packages have been introduced throughout the years for identifying clusters of longitudinal patterns, summarizing the variability in trajectories between subject in terms of one or more trends. We introduce the R package "latrend" as a framework for the unified application of methods for longitudinal clustering, enabling comparisons between methods with minimal coding. The package also serves as an interface to commonly used packages for clustering longitudinal data, including "dtwclust", "flexmix", "kml", "lcmm", "mclust", "mixAK", and "mixtools". This enables researchers to easily compare different approaches, implementations, and method specifications. Furthermore, researchers can build upon the standard tools provided by the framework to quickly implement new cluster methods, enabling rapid protot
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;CBA&#31639;&#27861;&#65292;&#20854;&#21033;&#29992;&#25918;&#24323;&#21442;&#19982;&#28216;&#25103;&#30340;&#20551;&#35774;&#33719;&#24471;&#20102;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#32463;&#20856;Exp4&#31639;&#27861;&#30340;&#22870;&#21169;&#30028;&#38480;&#65292;&#25104;&#20026;&#39318;&#20010;&#23545;&#19968;&#33324;&#32622;&#20449;&#35780;&#32423;&#39044;&#27979;&#22120;&#30340;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#23454;&#29616;&#30028;&#38480;&#30340;&#30740;&#31350;&#32773;&#65292;&#24182;&#22312;&#19987;&#23478;&#26696;&#20363;&#20013;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22870;&#21169;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.14585</link><description>&lt;p&gt;
&#20855;&#26377;&#24323;&#26435;&#36873;&#39033;&#30340;&#19987;&#23478;&#24314;&#35758;&#19979;&#30340;&#36172;&#24466;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Bandits with Abstention under Expert Advice
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14585
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;CBA&#31639;&#27861;&#65292;&#20854;&#21033;&#29992;&#25918;&#24323;&#21442;&#19982;&#28216;&#25103;&#30340;&#20551;&#35774;&#33719;&#24471;&#20102;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#32463;&#20856;Exp4&#31639;&#27861;&#30340;&#22870;&#21169;&#30028;&#38480;&#65292;&#25104;&#20026;&#39318;&#20010;&#23545;&#19968;&#33324;&#32622;&#20449;&#35780;&#32423;&#39044;&#27979;&#22120;&#30340;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#23454;&#29616;&#30028;&#38480;&#30340;&#30740;&#31350;&#32773;&#65292;&#24182;&#22312;&#19987;&#23478;&#26696;&#20363;&#20013;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22870;&#21169;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36172;&#24466;&#21453;&#39304;&#19979;&#21033;&#29992;&#19987;&#23478;&#24314;&#35758;&#36827;&#34892;&#39044;&#27979;&#30340;&#32463;&#20856;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20551;&#35774;&#19968;&#31181;&#34892;&#21160;&#65292;&#21363;&#23398;&#20064;&#32773;&#25918;&#24323;&#21442;&#19982;&#28216;&#25103;&#65292;&#22312;&#27599;&#27425;&#35797;&#39564;&#20013;&#37117;&#27809;&#26377;&#22870;&#21169;&#25110;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;CBA&#31639;&#27861;&#65292;&#21033;&#29992;&#36825;&#19968;&#20551;&#35774;&#33719;&#24471;&#20102;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#32463;&#20856;Exp4&#31639;&#27861;&#30340;&#22870;&#21169;&#30028;&#38480;&#12290;&#25105;&#20204;&#21487;&#20197;&#23558;&#25105;&#20204;&#30340;&#38382;&#39064;&#35270;&#20026;&#22312;&#23398;&#20064;&#32773;&#26377;&#25918;&#24323;&#21442;&#19982;&#28216;&#25103;&#36873;&#39033;&#26102;&#23545;&#32622;&#20449;&#35780;&#32423;&#39044;&#27979;&#22120;&#36827;&#34892;&#32858;&#21512;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#26159;&#31532;&#19968;&#20010;&#23545;&#19968;&#33324;&#32622;&#20449;&#35780;&#32423;&#39044;&#27979;&#22120;&#30340;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#23454;&#29616;&#30028;&#38480;&#30340;&#30740;&#31350;&#32773;&#12290;&#22312;&#19987;&#23478;&#26696;&#20363;&#20013;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22870;&#21169;&#30028;&#38480;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;&#20043;&#21069;&#22312;&#19987;&#23478;Exp&#65288;&#23558;&#24323;&#26435;&#35270;&#20026;&#21478;&#19968;&#31181;&#34892;&#21160;&#65289;&#30340;&#36793;&#30028;&#12290;&#20316;&#20026;&#19968;&#20010;&#31034;&#20363;&#24212;&#29992;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#22312;&#26377;&#38480;&#24230;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#29699;&#30340;&#24182;&#38598;&#12290;&#22312;&#36825;&#20010;&#19978;&#19979;&#25991;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;CBA&#30340;&#26377;&#25928;&#23454;&#29616;&#65292;re
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14585v1 Announce Type: new  Abstract: We study the classic problem of prediction with expert advice under bandit feedback. Our model assumes that one action, corresponding to the learner's abstention from play, has no reward or loss on every trial. We propose the CBA algorithm, which exploits this assumption to obtain reward bounds that can significantly improve those of the classical Exp4 algorithm. We can view our problem as the aggregation of confidence-rated predictors when the learner has the option of abstention from play. Importantly, we are the first to achieve bounds on the expected cumulative reward for general confidence-rated predictors. In the special case of specialists we achieve a novel reward bound, significantly improving previous bounds of SpecialistExp (treating abstention as another action). As an example application, we discuss learning unions of balls in a finite metric space. In this contextual setting, we devise an efficient implementation of CBA, re
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;MultiVAW&#26041;&#27861;&#65292;&#23558;Vovk-Azoury-Warmuth&#31639;&#27861;&#25193;&#23637;&#21040;&#22810;&#20803;&#35774;&#32622;&#65292;&#21516;&#26102;&#24212;&#29992;&#20110;&#22312;&#32447;&#23618;&#27425;&#39044;&#27979;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#25918;&#23485;&#20256;&#32479;&#20998;&#26512;&#25152;&#20570;&#30340;&#20551;&#35774;</title><link>https://arxiv.org/abs/2402.14578</link><description>&lt;p&gt;
&#29992;&#20110;&#23618;&#27425;&#39044;&#27979;&#30340;&#22810;&#20803;&#22312;&#32447;&#32447;&#24615;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Multivariate Online Linear Regression for Hierarchical Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14578
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;MultiVAW&#26041;&#27861;&#65292;&#23558;Vovk-Azoury-Warmuth&#31639;&#27861;&#25193;&#23637;&#21040;&#22810;&#20803;&#35774;&#32622;&#65292;&#21516;&#26102;&#24212;&#29992;&#20110;&#22312;&#32447;&#23618;&#27425;&#39044;&#27979;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#25918;&#23485;&#20256;&#32479;&#20998;&#26512;&#25152;&#20570;&#30340;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#30830;&#23450;&#24615;&#30340;&#22312;&#32447;&#22810;&#20803;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#20801;&#35768;&#21709;&#24212;&#26159;&#22810;&#20803;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MultiVAW&#65292;&#19968;&#31181;&#23558;&#33879;&#21517;&#30340;Vovk-Azoury-Warmuth&#31639;&#27861;&#25193;&#23637;&#21040;&#22810;&#20803;&#35774;&#32622;&#30340;&#26041;&#27861;&#65292;&#24182;&#34920;&#26126;&#23427;&#22312;&#26102;&#38388;&#19978;&#20063;&#20855;&#26377;&#23545;&#25968;&#36951;&#25022;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#24212;&#29992;&#20110;&#22312;&#32447;&#23618;&#27425;&#39044;&#27979;&#38382;&#39064;&#65292;&#24182;&#23558;&#36825;&#20010;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#31639;&#27861;&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#21152;&#20197;&#24674;&#22797;&#65292;&#20174;&#32780;&#25918;&#23485;&#20102;&#36890;&#24120;&#29992;&#20110;&#20854;&#20998;&#26512;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14578v1 Announce Type: cross  Abstract: In this paper, we consider a deterministic online linear regression model where we allow the responses to be multivariate. To address this problem, we introduce MultiVAW, a method that extends the well-known Vovk-Azoury-Warmuth algorithm to the multivariate setting, and show that it also enjoys logarithmic regret in time. We apply our results to the online hierarchical forecasting problem and recover an algorithm from this literature as a special case, allowing us to relax the hypotheses usually made for its analysis.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#24322;&#26041;&#24046;Aleatoric&#21644;&#35748;&#30693;&#26041;&#24046;&#23884;&#20837;&#21040;&#23398;&#20064;BNN&#21442;&#25968;&#30340;&#26041;&#24046;&#20013;&#65292;&#25913;&#21892;&#20102;&#36731;&#37327;&#32423;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.14532</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#24322;&#26041;&#24046;&#19981;&#30830;&#23450;&#24615;&#30340;&#36731;&#37327;&#32423;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21464;&#20998;&#25512;&#26029;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Framework for Variational Inference of Lightweight Bayesian Neural Networks with Heteroscedastic Uncertainties
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14532
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#24322;&#26041;&#24046;Aleatoric&#21644;&#35748;&#30693;&#26041;&#24046;&#23884;&#20837;&#21040;&#23398;&#20064;BNN&#21442;&#25968;&#30340;&#26041;&#24046;&#20013;&#65292;&#25913;&#21892;&#20102;&#36731;&#37327;&#32423;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#20013;&#33719;&#24471;&#24322;&#26041;&#24046;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23545;&#35768;&#22810;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#24120;&#65292;&#38500;&#20102;&#39044;&#27979;&#22343;&#20540;&#22806;&#65292;&#24322;&#26041;&#24046;Aleatoric&#19981;&#30830;&#23450;&#24615;&#20316;&#20026;BNN&#30340;&#36755;&#20986;&#36827;&#34892;&#23398;&#20064;&#65292;&#28982;&#32780;&#36825;&#26679;&#20570;&#21487;&#33021;&#38656;&#35201;&#21521;&#32593;&#32476;&#20013;&#28155;&#21152;&#26356;&#22810;&#21487;&#23398;&#20064;&#21442;&#25968;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24322;&#26041;&#24046;Aleatoric&#21644;&#35748;&#30693;&#26041;&#24046;&#22343;&#21487;&#20197;&#23884;&#20837;&#21040;&#23398;&#20064;BNN&#21442;&#25968;&#30340;&#26041;&#24046;&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#36731;&#37327;&#32423;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#36890;&#36807;&#23558;&#36825;&#31181;&#26041;&#27861;&#19982;&#30697;&#20256;&#25773;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#36731;&#37327;&#32423;BNNs&#30340;&#26080;&#38656;&#21462;&#26679;&#30340;&#21464;&#20998;&#25512;&#26029;&#30456;&#23545;&#31616;&#21333;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14532v1 Announce Type: new  Abstract: Obtaining heteroscedastic predictive uncertainties from a Bayesian Neural Network (BNN) is vital to many applications. Often, heteroscedastic aleatoric uncertainties are learned as outputs of the BNN in addition to the predictive means, however doing so may necessitate adding more learnable parameters to the network. In this work, we demonstrate that both the heteroscedastic aleatoric and epistemic variance can be embedded into the variances of learned BNN parameters, improving predictive performance for lightweight networks. By complementing this approach with a moment propagation approach to inference, we introduce a relatively simple framework for sampling-free variational inference suitable for lightweight BNNs.
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30740;&#31350;&#20102;&#39057;&#35889;&#30340;&#26497;&#22823;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#31867;&#27169;&#22411;&#20013;&#23384;&#22312;&#26497;&#22823;&#32467;&#26524;&#65292;&#20197;&#21450;&#22312;&#19968;&#20123;&#26465;&#20214;&#19979;&#23384;&#22312;&#20445;&#25345;&#39057;&#35889;&#30340;&#20809;&#35889;&#19981;&#21464;&#24615;&#65292;&#35299;&#37322;&#20102;&#25991;&#29486;&#20013;&#35266;&#23519;&#21040;&#30340;&#32467;&#26524;&#23545;&#31216;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14515</link><description>&lt;p&gt;
&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#39057;&#35889;&#30340;&#20809;&#35889;&#19981;&#21464;&#24615;&#21644;&#26497;&#22823;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Spectral invariance and maximality properties of the frequency spectrum of quantum neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14515
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30740;&#31350;&#20102;&#39057;&#35889;&#30340;&#26497;&#22823;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#31867;&#27169;&#22411;&#20013;&#23384;&#22312;&#26497;&#22823;&#32467;&#26524;&#65292;&#20197;&#21450;&#22312;&#19968;&#20123;&#26465;&#20214;&#19979;&#23384;&#22312;&#20445;&#25345;&#39057;&#35889;&#30340;&#20809;&#35889;&#19981;&#21464;&#24615;&#65292;&#35299;&#37322;&#20102;&#25991;&#29486;&#20013;&#35266;&#23519;&#21040;&#30340;&#32467;&#26524;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNNs&#65289;&#26159;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#28909;&#38376;&#26041;&#27861;&#65292;&#30001;&#20110;&#20854;&#19982;&#21464;&#20998;&#37327;&#23376;&#30005;&#36335;&#30340;&#23494;&#20999;&#32852;&#31995;&#65292;&#20351;&#20854;&#25104;&#20026;&#22312;&#22122;&#22768;&#20013;&#38388;&#23610;&#24230;&#37327;&#23376;&#65288;NISQ&#65289;&#35774;&#22791;&#19978;&#36827;&#34892;&#23454;&#38469;&#24212;&#29992;&#30340;&#26377;&#21069;&#36884;&#30340;&#20505;&#36873;&#26041;&#27861;&#12290;QNN&#21487;&#20197;&#34920;&#31034;&#20026;&#26377;&#38480;&#20613;&#37324;&#21494;&#32423;&#25968;&#65292;&#20854;&#20013;&#39057;&#29575;&#38598;&#34987;&#31216;&#20026;&#39057;&#35889;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36825;&#20010;&#39057;&#35889;&#24182;&#35777;&#26126;&#65292;&#23545;&#20110;&#19968;&#22823;&#31867;&#27169;&#22411;&#65292;&#23384;&#22312;&#21508;&#31181;&#26497;&#22823;&#24615;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#19968;&#20123;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#23384;&#22312;&#19968;&#20010;&#20445;&#25345;&#39057;&#35889;&#30340;&#20855;&#26377;&#30456;&#21516;&#38754;&#31215;$A = RL$&#30340;&#27169;&#22411;&#31867;&#20043;&#38388;&#30340;&#21452;&#23556;&#65292;&#20854;&#20013;$R$&#34920;&#31034;&#37327;&#23376;&#27604;&#29305;&#25968;&#37327;&#65292;$L$&#34920;&#31034;&#23618;&#25968;&#65292;&#25105;&#20204;&#22240;&#27492;&#31216;&#20043;&#20026;&#38754;&#31215;&#20445;&#25345;&#21464;&#25442;&#19979;&#30340;&#20809;&#35889;&#19981;&#21464;&#24615;&#12290;&#36890;&#36807;&#36825;&#20010;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#25991;&#29486;&#20013;&#32463;&#24120;&#35266;&#23519;&#21040;&#30340;&#22312;&#32467;&#26524;&#20013;$R$&#21644;$L$&#30340;&#23545;&#31216;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#26368;&#22823;&#39057;&#35889;&#30340;&#20381;&#36182;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14515v1 Announce Type: cross  Abstract: Quantum Neural Networks (QNNs) are a popular approach in Quantum Machine Learning due to their close connection to Variational Quantum Circuits, making them a promising candidate for practical applications on Noisy Intermediate-Scale Quantum (NISQ) devices. A QNN can be expressed as a finite Fourier series, where the set of frequencies is called the frequency spectrum. We analyse this frequency spectrum and prove, for a large class of models, various maximality results. Furthermore, we prove that under some mild conditions there exists a bijection between classes of models with the same area $A = RL$ that preserves the frequency spectrum, where $R$ denotes the number of qubits and $L$ the number of layers, which we consequently call spectral invariance under area-preserving transformations. With this we explain the symmetry in $R$ and $L$ in the results often observed in the literature and show that the maximal frequency spectrum depen
&lt;/p&gt;</description></item><item><title>Equilibrium K-Means&#65288;EKM&#65289;&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#32858;&#31867;&#20013;&#24515;&#22312;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.14490</link><description>&lt;p&gt;
&#20351;&#29992;Equilibrium K-Means&#36827;&#34892;&#19981;&#24179;&#34913;&#25968;&#25454;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Imbalanced Data Clustering using Equilibrium K-Means
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14490
&lt;/p&gt;
&lt;p&gt;
Equilibrium K-Means&#65288;EKM&#65289;&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#32858;&#31867;&#20013;&#24515;&#22312;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#24179;&#34913;&#25968;&#25454;&#25351;&#30340;&#26159;&#25968;&#25454;&#28857;&#22312;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#20998;&#24067;&#19981;&#22343;&#34913;&#65292;&#36825;&#32473;&#20256;&#32479;&#30340;&#30828;&#32858;&#31867;&#31639;&#27861;&#21644;&#27169;&#31946;&#32858;&#31867;&#31639;&#27861;&#65288;&#22914;&#30828;K&#22343;&#20540;&#65288;HKM&#65292;&#25110;&#32773;Lloyd&#31639;&#27861;&#65289;&#21644;&#27169;&#31946;K&#22343;&#20540;&#65288;FKM&#65292;&#25110;&#32773;Bezdek&#31639;&#27861;&#65289;&#65289;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;K&#22343;&#20540;&#31867;&#22411;&#31639;&#27861;&#8212;&#8212;Equilibrium K-Means&#65288;EKM&#65289;&#65292;&#23427;&#22312;&#20004;&#20010;&#27493;&#39588;&#20043;&#38388;&#20132;&#26367;&#36827;&#34892;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26524;&#65292;&#20943;&#23569;&#20102;&#32858;&#31867;&#20013;&#24515;&#21521;&#22823;&#31867;&#31751;&#20013;&#24515;&#32858;&#38598;&#30340;&#20542;&#21521;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#23545;HKM&#12289;FKM&#21644;EKM&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#34920;&#26126;&#23427;&#20204;&#26412;&#36136;&#19978;&#26159;&#20855;&#26377;&#26126;&#30830;&#20851;&#31995;&#30340;&#29275;&#39039;&#26041;&#27861;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;EKM&#20855;&#26377;&#19982;FKM&#30456;&#21516;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#65292;&#20294;&#23545;&#20854;&#25104;&#21592;&#23450;&#20041;&#25552;&#20379;&#20102;&#26356;&#28165;&#26224;&#30340;&#29289;&#29702;&#24847;&#20041;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#21313;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;EKM&#30340;&#24615;&#33021;&#65292;&#24182;&#23558;&#20854;&#19982;&#21508;&#31181;&#32858;&#31867;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14490v1 Announce Type: new  Abstract: Imbalanced data, characterized by an unequal distribution of data points across different clusters, poses a challenge for traditional hard and fuzzy clustering algorithms, such as hard K-means (HKM, or Lloyd's algorithm) and fuzzy K-means (FKM, or Bezdek's algorithm). This paper introduces equilibrium K-means (EKM), a novel and simple K-means-type algorithm that alternates between just two steps, yielding significantly improved clustering results for imbalanced data by reducing the tendency of centroids to crowd together in the center of large clusters. We also present a unifying perspective for HKM, FKM, and EKM, showing they are essentially gradient descent algorithms with an explicit relationship to Newton's method. EKM has the same time and space complexity as FKM but offers a clearer physical meaning for its membership definition. We illustrate the performance of EKM on two synthetic and ten real datasets, comparing it to various cl
&lt;/p&gt;</description></item><item><title>&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#29983;&#25104;&#22810;&#20010;&#21453;&#20107;&#23454;&#31034;&#20363;&#20197;&#25429;&#33719;&#24322;&#24120;&#30340;&#22810;&#26679;&#27010;&#24565;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#23545;&#35302;&#21457;&#24322;&#24120;&#26816;&#27979;&#22120;&#26426;&#21046;&#30340;&#39640;&#32423;&#35821;&#20041;&#35299;&#37322;&#65292;&#20801;&#35768;&#25506;&#32034;&#8220;&#20551;&#35774;&#24773;&#26223;&#8221;&#12290;</title><link>https://arxiv.org/abs/2402.14469</link><description>&lt;p&gt;
&#37325;&#26032;&#26500;&#24819;&#24322;&#24120;&#65306;&#22914;&#26524;&#24322;&#24120;&#26159;&#27491;&#24120;&#30340;&#21602;&#65311;
&lt;/p&gt;
&lt;p&gt;
Reimagining Anomalies: What If Anomalies Were Normal?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14469
&lt;/p&gt;
&lt;p&gt;
&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#29983;&#25104;&#22810;&#20010;&#21453;&#20107;&#23454;&#31034;&#20363;&#20197;&#25429;&#33719;&#24322;&#24120;&#30340;&#22810;&#26679;&#27010;&#24565;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#23545;&#35302;&#21457;&#24322;&#24120;&#26816;&#27979;&#22120;&#26426;&#21046;&#30340;&#39640;&#32423;&#35821;&#20041;&#35299;&#37322;&#65292;&#20801;&#35768;&#25506;&#32034;&#8220;&#20551;&#35774;&#24773;&#26223;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#22312;&#22270;&#20687;&#24322;&#24120;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#31361;&#30772;&#65292;&#20294;&#20854;&#22797;&#26434;&#24615;&#32473;&#29702;&#35299;&#20026;&#20309;&#23454;&#20363;&#34987;&#39044;&#27979;&#20026;&#24322;&#24120;&#24102;&#26469;&#20102;&#30456;&#24403;&#22823;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#20026;&#27599;&#20010;&#24322;&#24120;&#29983;&#25104;&#22810;&#20010;&#21453;&#20107;&#23454;&#31034;&#20363;&#65292;&#25429;&#33719;&#24322;&#24120;&#30340;&#22810;&#26679;&#27010;&#24565;&#12290;&#21453;&#20107;&#23454;&#31034;&#20363;&#26159;&#23545;&#24322;&#24120;&#30340;&#20462;&#25913;&#65292;&#34987;&#24322;&#24120;&#26816;&#27979;&#22120;&#35270;&#20026;&#27491;&#24120;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#35302;&#21457;&#24322;&#24120;&#26816;&#27979;&#22120;&#26426;&#21046;&#30340;&#39640;&#32423;&#35821;&#20041;&#35299;&#37322;&#65292;&#20801;&#35768;&#29992;&#25143;&#25506;&#32034;&#8220;&#20551;&#35774;&#24773;&#26223;&#8221;&#12290;&#23545;&#19981;&#21516;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#20998;&#26512;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#26368;&#20808;&#36827;&#30340;&#24322;&#24120;&#26816;&#27979;&#22120;&#21487;&#20197;&#23454;&#29616;&#23545;&#26816;&#27979;&#22120;&#30340;&#39640;&#36136;&#37327;&#35821;&#20041;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14469v1 Announce Type: cross  Abstract: Deep learning-based methods have achieved a breakthrough in image anomaly detection, but their complexity introduces a considerable challenge to understanding why an instance is predicted to be anomalous. We introduce a novel explanation method that generates multiple counterfactual examples for each anomaly, capturing diverse concepts of anomalousness. A counterfactual example is a modification of the anomaly that is perceived as normal by the anomaly detector. The method provides a high-level semantic explanation of the mechanism that triggered the anomaly detector, allowing users to explore "what-if scenarios." Qualitative and quantitative analyses across various image datasets show that the method applied to state-of-the-art anomaly detectors can achieve high-quality semantic explanations of detectors.
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#31995;&#32479;&#22312;&#19968;&#33324;&#35201;&#27714;&#19979;&#36981;&#24490;&#19968;&#31181;&#25200;&#20081;&#29256;&#26412;&#30340;&#26799;&#24230;&#19979;&#38477;&#27169;&#22411;&#65292;&#23398;&#20064;&#36807;&#31243;&#21463;&#21040;&#37327;&#23376;&#31995;&#32479;&#33258;&#32452;&#32455;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.14423</link><description>&lt;p&gt;
&#23431;&#23449;&#20316;&#20026;&#19968;&#20010;&#23398;&#20064;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
The Universe as a Learning System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14423
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#31995;&#32479;&#22312;&#19968;&#33324;&#35201;&#27714;&#19979;&#36981;&#24490;&#19968;&#31181;&#25200;&#20081;&#29256;&#26412;&#30340;&#26799;&#24230;&#19979;&#38477;&#27169;&#22411;&#65292;&#23398;&#20064;&#36807;&#31243;&#21463;&#21040;&#37327;&#23376;&#31995;&#32479;&#33258;&#32452;&#32455;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20854;&#24494;&#35266;&#27700;&#24179;&#19978;&#65292;&#23431;&#23449;&#36981;&#24490;&#37327;&#23376;&#21147;&#23398;&#23450;&#24459;&#12290;&#36890;&#36807;&#20851;&#27880;&#20174;&#37327;&#23376;&#21147;&#23398;&#30340;&#27969;&#20307;&#21147;&#23398;&#34920;&#36848;&#20013;&#36319;&#38543;&#30340;&#31890;&#23376;&#30340;&#37327;&#23376;&#36712;&#36857;&#65292;&#25105;&#20204;&#25552;&#20986;&#22312;&#19968;&#33324;&#35201;&#27714;&#19979;&#65292;&#37327;&#23376;&#31995;&#32479;&#36981;&#24490;&#19968;&#31181;&#25200;&#20081;&#29256;&#26412;&#30340;&#26799;&#24230;&#19979;&#38477;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#26412;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#20854;&#20013;&#23398;&#20064;&#30001;&#20110;&#37327;&#23376;&#31995;&#32479;&#30340;&#33258;&#32452;&#32455;&#36807;&#31243;&#32780;&#22833;&#30495;&#12290;&#24403;&#25105;&#20204;&#20551;&#35774;&#32791;&#25955;&#21363;&#37327;&#23376;&#31995;&#32479;&#26159;&#24320;&#25918;&#30340;&#26102;&#65292;&#36825;&#26679;&#30340;&#23398;&#20064;&#36807;&#31243;&#25165;&#26377;&#21487;&#33021;&#12290;&#23398;&#20064;&#21442;&#25968;&#26159;&#36807;&#31243;&#30340;&#26102;&#38388;&#22686;&#37327;&#38500;&#20197;&#37327;&#23376;&#31890;&#23376;&#30340;&#36136;&#37327;&#65292;&#19968;&#20010;&#25705;&#25830;&#21442;&#25968;&#30830;&#23450;&#20102;&#37327;&#23376;&#31995;&#32479;&#30340;&#38750;&#32447;&#24615;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#25552;&#20986;&#27169;&#22411;&#30340;&#23454;&#35777;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14423v1 Announce Type: cross  Abstract: At its microscopic level, the universe follows the laws of quantum mechanics. Focusing on the quantum trajectories of particles as followed from the hydrodynamical formulation of quantum mechanics, we propose that under general requirements, quantum systems follow a disrupted version of the gradient descent model, a basic machine learning algorithm, where the learning is distorted due to the self-organizing process of the quantum system. Such a learning process is possible only when we assume dissipation, i.e., that the quantum system is open. The learning parameter is the time increment of the process over the mass of the quantum particle, and a friction parameter determines the nonlinearity of the quantum system. We then provide an empirical demonstration of the proposed model.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#30340;&#20840;&#23616;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#39044;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#26469;&#20943;&#23569;&#39069;&#22806;&#30340;&#35745;&#31639;&#36127;&#36733;&#12290;</title><link>https://arxiv.org/abs/2402.14402</link><description>&lt;p&gt;
&#20840;&#23616;&#23433;&#20840;&#39034;&#24207;&#23398;&#20064;&#36890;&#36807;&#39640;&#25928;&#30693;&#35782;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Global Safe Sequential Learning via Efficient Knowledge Transfer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14402
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#30340;&#20840;&#23616;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#39044;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#26469;&#20943;&#23569;&#39069;&#22806;&#30340;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14402v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#25688;&#35201;: &#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#20363;&#22914;&#20027;&#21160;&#23398;&#20064;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#26469;&#23398;&#20064;&#19968;&#20010;&#20219;&#21153;&#12290;&#22312;&#35768;&#22810;&#21307;&#23398;&#25110;&#24037;&#31243;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#36873;&#25321;&#21463;&#20808;&#39564;&#26410;&#30693;&#30340;&#23433;&#20840;&#26465;&#20214;&#38480;&#21046;&#12290;&#19968;&#26465;&#26377;&#21069;&#36884;&#30340;&#23433;&#20840;&#23398;&#20064;&#26041;&#27861;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26469;&#24314;&#27169;&#23433;&#20840;&#27010;&#29575;&#65292;&#24182;&#22312;&#20855;&#26377;&#36739;&#39640;&#23433;&#20840;&#32622;&#20449;&#24230;&#30340;&#21306;&#22495;&#20013;&#36827;&#34892;&#25968;&#25454;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#20934;&#30830;&#30340;&#23433;&#20840;&#24314;&#27169;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#28040;&#32791;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#23433;&#20840;&#32622;&#20449;&#24230;&#38598;&#20013;&#22312;&#32473;&#23450;&#30340;&#35266;&#27979;&#20540;&#21608;&#22260;&#65292;&#23548;&#33268;&#23616;&#37096;&#25506;&#32034;&#12290;&#30001;&#20110;&#22312;&#23433;&#20840;&#20851;&#38190;&#23454;&#39564;&#20013;&#36890;&#24120;&#23384;&#22312;&#21487;&#36716;&#31227;&#30340;&#28304;&#30693;&#35782;&#65292;&#25105;&#20204;&#25552;&#20986;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#39034;&#24207;&#23398;&#20064;&#26469;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#32771;&#34385;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#65292;&#20197;&#20943;&#23569;&#24341;&#20837;&#28304;&#25968;&#25454;&#24102;&#26469;&#30340;&#39069;&#22806;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14402v1 Announce Type: new  Abstract: Sequential learning methods such as active learning and Bayesian optimization select the most informative data to learn about a task. In many medical or engineering applications, the data selection is constrained by a priori unknown safety conditions. A promissing line of safe learning methods utilize Gaussian processes (GPs) to model the safety probability and perform data selection in areas with high safety confidence. However, accurate safety modeling requires prior knowledge or consumes data. In addition, the safety confidence centers around the given observations which leads to local exploration. As transferable source knowledge is often available in safety critical experiments, we propose to consider transfer safe sequential learning to accelerate the learning of safety. We further consider a pre-computation of source components to reduce the additional computational load that is introduced by incorporating source data. In this pap
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#33258;&#21160;&#28145;&#24230;&#23398;&#20064;&#32467;&#21512;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#39118;&#36895;&#22270;&#65292;WindDragon&#31995;&#32479;&#22312;&#20840;&#22269;&#33539;&#22260;&#20869;&#23454;&#29616;&#20102;&#30701;&#26399;&#39118;&#21147;&#39044;&#27979;&#65292;&#20026;&#30005;&#32593;&#36816;&#33829;&#21644;&#31995;&#32479;&#24179;&#34913;&#25552;&#20379;&#20851;&#38190;&#25903;&#25345;&#12290;</title><link>https://arxiv.org/abs/2402.14385</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#21160;&#28145;&#24230;&#23398;&#20064;&#25913;&#36827;&#39118;&#21147;&#21457;&#30005;&#39044;&#27979;&#30340;WindDragon&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
WindDragon: Enhancing wind power forecasting with Automated Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14385
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#33258;&#21160;&#28145;&#24230;&#23398;&#20064;&#32467;&#21512;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#39118;&#36895;&#22270;&#65292;WindDragon&#31995;&#32479;&#22312;&#20840;&#22269;&#33539;&#22260;&#20869;&#23454;&#29616;&#20102;&#30701;&#26399;&#39118;&#21147;&#39044;&#27979;&#65292;&#20026;&#30005;&#32593;&#36816;&#33829;&#21644;&#31995;&#32479;&#24179;&#34913;&#25552;&#20379;&#20851;&#38190;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#21040;2050&#24180;&#38646;&#30899;&#25490;&#25918;&#30340;&#30446;&#26631;&#38656;&#35201;&#23558;&#22823;&#37327;&#39118;&#21147;&#32435;&#20837;&#30005;&#32593;&#20013;&#12290;&#36825;&#31181;&#33021;&#28304;&#30001;&#20110;&#20854;&#21464;&#21270;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#23545;&#31995;&#32479;&#36816;&#33829;&#21830;&#26500;&#25104;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#20934;&#30830;&#39044;&#27979;&#39118;&#21147;&#21457;&#30005;&#23545;&#20110;&#30005;&#32593;&#36816;&#33829;&#21644;&#31995;&#32479;&#24179;&#34913;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20840;&#22269;&#33539;&#22260;&#20869;&#36827;&#34892;&#30701;&#26399;&#65288;1&#33267;6&#23567;&#26102;&#65289;&#39118;&#21147;&#39044;&#27979;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#33258;&#21160;&#28145;&#24230;&#23398;&#20064;&#32467;&#21512;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#39118;&#36895;&#22270;&#26469;&#20934;&#30830;&#39044;&#27979;&#39118;&#21147;&#21457;&#30005;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14385v1 Announce Type: new  Abstract: Achieving net zero carbon emissions by 2050 requires the integration of increasing amounts of wind power into power grids. This energy source poses a challenge to system operators due to its variability and uncertainty. Therefore, accurate forecasting of wind power is critical for grid operation and system balancing. This paper presents an innovative approach to short-term (1 to 6 hour horizon) windpower forecasting at a national level. The method leverages Automated Deep Learning combined with Numerical Weather Predictions wind speed maps to accurately forecast wind power.
&lt;/p&gt;</description></item><item><title>HyperFast&#26159;&#19968;&#20010;&#38024;&#23545;&#34920;&#26684;&#25968;&#25454;&#30340;&#21363;&#26102;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#29983;&#25104;&#29305;&#23450;&#20219;&#21153;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#20102;&#38656;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#29616;&#20986;&#39640;&#24230;&#31454;&#20105;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.14335</link><description>&lt;p&gt;
&#36229;&#24555;&#36895;&#65306;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#30340;&#21363;&#26102;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
HyperFast: Instant Classification for Tabular Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14335
&lt;/p&gt;
&lt;p&gt;
HyperFast&#26159;&#19968;&#20010;&#38024;&#23545;&#34920;&#26684;&#25968;&#25454;&#30340;&#21363;&#26102;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#29983;&#25104;&#29305;&#23450;&#20219;&#21153;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#20102;&#38656;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#29616;&#20986;&#39640;&#24230;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#36827;&#34892;&#36229;&#21442;&#25968;&#35843;&#25972;&#21487;&#33021;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#21644;&#26102;&#38388;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#20256;&#32479;&#30340;&#26799;&#24230;&#25552;&#21319;&#31639;&#27861;&#31561;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20173;&#28982;&#26159;&#22823;&#22810;&#25968;&#34920;&#26684;&#25968;&#25454;&#24212;&#29992;&#30340;&#39318;&#36873;&#65292;&#32780;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#36827;&#34892;&#22823;&#37327;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#35201;&#20040;&#20165;&#36866;&#29992;&#20110;&#22312;&#26377;&#38480;&#35774;&#32622;&#19979;&#30340;&#29609;&#20855;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;HyperFast&#65292;&#19968;&#20010;&#20026;&#22312;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#31435;&#21363;&#20998;&#31867;&#34920;&#26684;&#25968;&#25454;&#32780;&#35774;&#35745;&#30340;&#20803;&#35757;&#32451;&#30340;&#36229;&#32593;&#32476;&#12290;HyperFast&#29983;&#25104;&#19968;&#20010;&#38024;&#23545;&#26410;&#35265;&#25968;&#25454;&#38598;&#23450;&#21046;&#30340;&#29305;&#23450;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#30452;&#25509;&#29992;&#20110;&#20998;&#31867;&#25512;&#26029;&#65292;&#26080;&#38656;&#35757;&#32451;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;OpenML&#21644;&#22522;&#22240;&#32452;&#25968;&#25454;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#23558;HyperFast&#19982;&#31454;&#20105;&#24615;&#34920;&#26684;&#25968;&#25454;&#31070;&#32463;&#32593;&#32476;&#12289;&#20256;&#32479;ML&#26041;&#27861;&#12289;AutoML&#31995;&#32479;&#21644;&#25552;&#21319;&#26426;&#22120;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;HyperFast&#23637;&#29616;&#20986;&#26497;&#20855;&#31454;&#20105;&#21147;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14335v1 Announce Type: cross  Abstract: Training deep learning models and performing hyperparameter tuning can be computationally demanding and time-consuming. Meanwhile, traditional machine learning methods like gradient-boosting algorithms remain the preferred choice for most tabular data applications, while neural network alternatives require extensive hyperparameter tuning or work only in toy datasets under limited settings. In this paper, we introduce HyperFast, a meta-trained hypernetwork designed for instant classification of tabular data in a single forward pass. HyperFast generates a task-specific neural network tailored to an unseen dataset that can be directly used for classification inference, removing the need for training a model. We report extensive experiments with OpenML and genomic data, comparing HyperFast to competing tabular data neural networks, traditional ML methods, AutoML systems, and boosting machines. HyperFast shows highly competitive results, wh
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#23610;&#23544;&#27867;&#21270;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#30340;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#23567;&#23454;&#20363;&#19978;&#20445;&#35777;&#20934;&#30830;&#24230;&#26368;&#39640;&#30340;&#31639;&#27861;&#20063;&#23558;&#22312;&#21407;&#22987;&#22823;&#23454;&#20363;&#19978;&#25317;&#26377;&#26368;&#39640;&#20934;&#30830;&#24230;&#30340;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.14332</link><description>&lt;p&gt;
&#20174;&#22823;&#35268;&#27169;&#21040;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#65306;&#29992;&#20110;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#30340;&#23610;&#23544;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
From Large to Small Datasets: Size Generalization for Clustering Algorithm Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14332
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#23610;&#23544;&#27867;&#21270;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#30340;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#23567;&#23454;&#20363;&#19978;&#20445;&#35777;&#20934;&#30830;&#24230;&#26368;&#39640;&#30340;&#31639;&#27861;&#20063;&#23558;&#22312;&#21407;&#22987;&#22823;&#23454;&#20363;&#19978;&#25317;&#26377;&#26368;&#39640;&#20934;&#30830;&#24230;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#20013;&#65292;&#25105;&#20204;&#20250;&#24471;&#21040;&#19968;&#20010;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#24182;&#35201;&#26377;&#25928;&#22320;&#36873;&#25321;&#35201;&#20351;&#29992;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#26377;&#19968;&#20010;&#26410;&#30693;&#30340;&#22522;&#20934;&#32858;&#31867;&#65292;&#25105;&#20204;&#21482;&#33021;&#36890;&#36807;&#26114;&#36149;&#30340;oracle&#26597;&#35810;&#26469;&#35775;&#38382;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#32858;&#31867;&#31639;&#27861;&#30340;&#36755;&#20986;&#23558;&#19982;&#22522;&#26412;&#20107;&#23454;&#32467;&#26500;&#19978;&#25509;&#36817;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#32858;&#31867;&#31639;&#27861;&#20934;&#30830;&#24615;&#30340;&#23610;&#23544;&#27867;&#21270;&#27010;&#24565;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30830;&#23450;&#22312;&#21738;&#20123;&#26465;&#20214;&#19979;&#25105;&#20204;&#21487;&#20197;&#65288;1&#65289;&#23545;&#22823;&#35268;&#27169;&#32858;&#31867;&#23454;&#20363;&#36827;&#34892;&#23376;&#37319;&#26679;&#65292;&#65288;2&#65289;&#22312;&#36739;&#23567;&#23454;&#20363;&#19978;&#35780;&#20272;&#19968;&#32452;&#20505;&#36873;&#31639;&#27861;&#65292;&#65288;3&#65289;&#20445;&#35777;&#22312;&#23567;&#23454;&#20363;&#19978;&#20934;&#30830;&#24230;&#26368;&#39640;&#30340;&#31639;&#27861;&#23558;&#22312;&#21407;&#22987;&#22823;&#23454;&#20363;&#19978;&#25317;&#26377;&#26368;&#39640;&#30340;&#20934;&#30830;&#24230;&#12290;&#25105;&#20204;&#20026;&#19977;&#31181;&#32463;&#20856;&#32858;&#31867;&#31639;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#23610;&#23544;&#27867;&#21270;&#20445;&#35777;&#65306;&#21333;&#38142;&#25509;&#12289;k-means++&#21644;Gonzalez&#30340;k&#20013;&#24515;&#21551;&#21457;&#24335;&#65288;&#19968;&#31181;&#24179;&#28369;&#30340;&#21464;&#31181;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14332v1 Announce Type: new  Abstract: In clustering algorithm selection, we are given a massive dataset and must efficiently select which clustering algorithm to use. We study this problem in a semi-supervised setting, with an unknown ground-truth clustering that we can only access through expensive oracle queries. Ideally, the clustering algorithm's output will be structurally close to the ground truth. We approach this problem by introducing a notion of size generalization for clustering algorithm accuracy. We identify conditions under which we can (1) subsample the massive clustering instance, (2) evaluate a set of candidate algorithms on the smaller instance, and (3) guarantee that the algorithm with the best accuracy on the small instance will have the best accuracy on the original big instance. We provide theoretical size generalization guarantees for three classic clustering algorithms: single-linkage, k-means++, and (a smoothed variant of) Gonzalez's k-centers heuris
&lt;/p&gt;</description></item><item><title>&#37319;&#29992;&#32467;&#26500;&#19981;&#21487;&#30693;&#30340;&#32479;&#35745;&#19979;&#30028;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#22312;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#26041;&#38754;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;</title><link>https://arxiv.org/abs/2402.14264</link><description>&lt;p&gt;
&#21452;&#31283;&#20581;&#23398;&#20064;&#22312;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#32467;&#26500;&#19981;&#21487;&#30693;&#24615;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Structure-agnostic Optimality of Doubly Robust Learning for Treatment Effect Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14264
&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#32467;&#26500;&#19981;&#21487;&#30693;&#30340;&#32479;&#35745;&#19979;&#30028;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#22312;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#26041;&#38754;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#26368;&#26680;&#24515;&#30340;&#38382;&#39064;&#65292;&#24212;&#29992;&#24191;&#27867;&#12290;&#34429;&#28982;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#20272;&#35745;&#31574;&#30053;&#65292;&#26368;&#36817;&#36824;&#32435;&#20837;&#20102;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#37319;&#29992;&#26368;&#36817;&#24341;&#20837;&#30340;&#32479;&#35745;&#19979;&#30028;&#32467;&#26500;&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23545;&#24178;&#25200;&#20989;&#25968;&#27809;&#26377;&#32467;&#26500;&#24615;&#36136;&#20551;&#35774;&#65292;&#38500;&#20102;&#35775;&#38382;&#40657;&#30418;&#20272;&#35745;&#22120;&#20197;&#36798;&#21040;&#23567;&#35823;&#24046;&#65307;&#24403;&#21482;&#24895;&#24847;&#32771;&#34385;&#20351;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#20998;&#31867;&#31070;&#35861;&#20316;&#20026;&#40657;&#30418;&#23376;&#36807;&#31243;&#30340;&#20272;&#35745;&#31574;&#30053;&#26102;&#65292;&#36825;&#19968;&#28857;&#23588;&#20854;&#21560;&#24341;&#20154;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21452;&#31283;&#20581;&#20272;&#35745;&#22120;&#23545;&#20110;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#21644;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14264v1 Announce Type: cross  Abstract: Average treatment effect estimation is the most central problem in causal inference with application to numerous disciplines. While many estimation strategies have been proposed in the literature, recently also incorporating generic machine learning estimators, the statistical optimality of these methods has still remained an open area of investigation. In this paper, we adopt the recently introduced structure-agnostic framework of statistical lower bounds, which poses no structural properties on the nuisance functions other than access to black-box estimators that attain small errors; which is particularly appealing when one is only willing to consider estimation strategies that use non-parametric regression and classification oracles as a black-box sub-process. Within this framework, we prove the statistical optimality of the celebrated and widely used doubly robust estimators for both the Average Treatment Effect (ATE) and the Avera
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#35814;&#32454;&#30340;&#21464;&#37327;&#32423;&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#37327;&#21270;&#27599;&#20010;&#21464;&#37327;&#23545;&#24615;&#33021;&#24046;&#24322;&#30340;&#24433;&#21709;&#65292;&#20026;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#24178;&#39044;&#25514;&#26045;&#25552;&#20379;&#26356;&#28145;&#20837;&#30340;&#29702;&#35299;</title><link>https://arxiv.org/abs/2402.14254</link><description>&lt;p&gt;
&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#24615;&#33021;&#24046;&#24322;&#30340;&#20998;&#23618;&#20998;&#35299;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A hierarchical decomposition for explaining ML performance discrepancies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14254
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#35814;&#32454;&#30340;&#21464;&#37327;&#32423;&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#37327;&#21270;&#27599;&#20010;&#21464;&#37327;&#23545;&#24615;&#33021;&#24046;&#24322;&#30340;&#24433;&#21709;&#65292;&#20026;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#24178;&#39044;&#25514;&#26045;&#25552;&#20379;&#26356;&#28145;&#20837;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#24615;&#33021;&#24448;&#24448;&#26377;&#25152;&#19981;&#21516;&#12290;&#20102;&#35299;&#23427;&#20204;&#30340;&#24615;&#33021;&#24046;&#24322;&#30340;&#21407;&#22240;&#23545;&#20110;&#30830;&#23450;&#20309;&#31181;&#24178;&#39044;&#25514;&#26045;&#65288;&#20363;&#22914;&#31639;&#27861;&#25110;&#36816;&#33829;&#65289;&#26368;&#26377;&#25928;&#20197;&#32553;&#23567;&#24615;&#33021;&#24046;&#36317;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#26041;&#27861;&#20391;&#37325;&#20110;&#23558;&#24635;&#24615;&#33021;&#24046;&#24322;&#20998;&#35299;&#20026;&#29305;&#24449;&#20998;&#24067;$p(X)$&#21464;&#21270;&#30340;&#24433;&#21709;&#19982;&#32467;&#26524;&#26465;&#20214;&#20998;&#24067;$p(Y|X)$&#21464;&#21270;&#30340;&#24433;&#21709;&#30340;$\textit{&#27719;&#24635;&#20998;&#35299;}$&#65307;&#28982;&#32780;&#65292;&#36825;&#26679;&#31895;&#31961;&#30340;&#35299;&#37322;&#21482;&#25552;&#20379;&#20102;&#24456;&#23569;&#30340;&#26041;&#27861;&#26469;&#32553;&#23567;&#24615;&#33021;&#24046;&#36317;&#12290;$\textit{&#35814;&#32454;&#30340;&#21464;&#37327;&#32423;&#20998;&#35299;}$&#21487;&#20197;&#37327;&#21270;&#27599;&#20010;&#21464;&#37327;&#23545;&#27719;&#24635;&#20998;&#35299;&#20013;&#27599;&#20010;&#39033;&#30340;&#37325;&#35201;&#24615;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#28145;&#20837;&#30340;&#29702;&#35299;&#65292;&#24182;&#25552;&#20986;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20551;&#35774;&#26377;&#20851;&#20840;&#22240;&#26524;&#22270;&#30340;&#23436;&#25972;&#30693;&#35782;&#25110;&#36827;&#34892;&#24378;&#21442;&#25968;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14254v1 Announce Type: new  Abstract: Machine learning (ML) algorithms can often differ in performance across domains. Understanding $\textit{why}$ their performance differs is crucial for determining what types of interventions (e.g., algorithmic or operational) are most effective at closing the performance gaps. Existing methods focus on $\textit{aggregate decompositions}$ of the total performance gap into the impact of a shift in the distribution of features $p(X)$ versus the impact of a shift in the conditional distribution of the outcome $p(Y|X)$; however, such coarse explanations offer only a few options for how one can close the performance gap. $\textit{Detailed variable-level decompositions}$ that quantify the importance of each variable to each term in the aggregate decomposition can provide a much deeper understanding and suggest much more targeted interventions. However, existing methods assume knowledge of the full causal graph or make strong parametric assumpti
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36229;&#20960;&#20309;&#20284;&#28982;&#35299;&#20915;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#25361;&#25112;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#23384;&#22312;&#20005;&#37325;&#30340;&#27424;&#37319;&#26679;&#65292;&#20063;&#33021;&#23454;&#29616;&#65292;&#19988;&#22312;&#20154;&#21475;&#35268;&#27169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.14220</link><description>&lt;p&gt;
&#20351;&#29992;&#36229;&#20960;&#20309;&#20998;&#24067;&#20272;&#35745;&#26410;&#30693;&#20154;&#21475;&#35268;&#27169;
&lt;/p&gt;
&lt;p&gt;
Estimating Unknown Population Sizes Using the Hypergeometric Distribution
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14220
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36229;&#20960;&#20309;&#20284;&#28982;&#35299;&#20915;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#25361;&#25112;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#23384;&#22312;&#20005;&#37325;&#30340;&#27424;&#37319;&#26679;&#65292;&#20063;&#33021;&#23454;&#29616;&#65292;&#19988;&#22312;&#20154;&#21475;&#35268;&#27169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#36229;&#20960;&#20309;&#20998;&#24067;&#25551;&#36848;&#20174;&#21010;&#20998;&#20026;&#22810;&#20010;&#31867;&#21035;&#30340;&#31163;&#25955;&#20803;&#32032;&#24635;&#20307;&#20013;&#36827;&#34892;&#26080;&#25918;&#22238;&#25277;&#26679;&#12290;&#22312;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#19968;&#20010;&#31354;&#30333;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#30340;&#25361;&#25112;&#65292;&#24403;&#24635;&#20307;&#35268;&#27169;&#21644;&#20854;&#26500;&#25104;&#31867;&#21035;&#30340;&#22823;&#23567;&#22343;&#26410;&#30693;&#26102;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36229;&#20960;&#20309;&#20284;&#28982;&#35299;&#20915;&#36825;&#19968;&#20272;&#35745;&#25361;&#25112;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#23384;&#22312;&#20005;&#37325;&#30340;&#27424;&#37319;&#26679;&#20063;&#33021;&#23454;&#29616;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#37322;&#19968;&#20010;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#20854;&#20013;&#22320;&#38754;&#30495;&#23454;&#20540;&#26159;&#26377;&#26465;&#20214;&#30340;&#36830;&#32493;&#28508;&#21464;&#37327;&#28151;&#21512;&#20998;&#24067;&#65292;&#27604;&#22914;&#21327;&#21516;&#36807;&#28388;&#65292;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26694;&#26550;&#12290;&#23454;&#35777;&#25968;&#25454;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#21475;&#35268;&#27169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#22343;&#20248;&#20110;&#20854;&#20182;&#29992;&#20110;&#24314;&#27169;&#35745;&#25968;&#25968;&#25454;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14220v1 Announce Type: new  Abstract: The multivariate hypergeometric distribution describes sampling without replacement from a discrete population of elements divided into multiple categories. Addressing a gap in the literature, we tackle the challenge of estimating discrete distributions when both the total population size and the sizes of its constituent categories are unknown. Here, we propose a novel solution using the hypergeometric likelihood to solve this estimation challenge, even in the presence of severe under-sampling. We develop our approach to account for a data generating process where the ground-truth is a mixture of distributions conditional on a continuous latent variable, such as with collaborative filtering, using the variational autoencoder framework. Empirical data simulation demonstrates that our method outperforms other likelihood functions used to model count data, both in terms of accuracy of population size estimate and in its ability to learn an 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#30340;&#20056;&#24130;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#20013;&#27599;&#20010;&#20010;&#20307;&#37096;&#20998;&#30340;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#22312;&#27979;&#35797;&#39118;&#38505;&#19978;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.14145</link><description>&lt;p&gt;
&#24102;&#26377;&#22810;&#20010;&#39046;&#22495;&#30340;&#26412;&#22320;&#20998;&#24067;&#20559;&#31227;&#30340;&#20056;&#24130;&#31283;&#20581;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Multiply Robust Estimation for Local Distribution Shifts with Multiple Domains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14145
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#30340;&#20056;&#24130;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#20013;&#27599;&#20010;&#20010;&#20307;&#37096;&#20998;&#30340;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#22312;&#27979;&#35797;&#39118;&#38505;&#19978;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#32473;&#22312;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#25512;&#24191;&#21040;&#21478;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;&#24102;&#26469;&#25361;&#25112;&#12290;&#26412;&#25991;&#19987;&#27880;&#20110;&#25968;&#25454;&#20998;&#24067;&#38543;&#25972;&#20010;&#24635;&#20307;&#30340;&#22810;&#20010;&#37096;&#20998;&#21464;&#21270;&#30340;&#24773;&#24418;&#65292;&#24182;&#20165;&#22312;&#27599;&#20010;&#37096;&#20998;&#20869;&#23545;&#35757;&#32451;&#19982;&#27979;&#35797;&#65288;&#37096;&#32626;&#65289;&#25968;&#25454;&#20998;&#24067;&#30340;&#24046;&#24322;&#36827;&#34892;&#23616;&#37096;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#30340;&#20056;&#24130;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#20013;&#27599;&#20010;&#20010;&#20307;&#37096;&#20998;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#25311;&#21512;&#22522;&#20110;&#20174;&#22810;&#20010;&#37096;&#20998;&#30340;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#21040;&#30340;&#27169;&#22411;&#30340;&#32447;&#24615;&#32452;&#21512;&#65292;&#28982;&#21518;&#23545;&#27599;&#20010;&#37096;&#20998;&#36827;&#34892;&#32454;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#19982;&#24120;&#29992;&#30340;&#29616;&#25104;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19968;&#36215;&#23454;&#26045;&#12290;&#25105;&#20204;&#22312;&#27979;&#35797;&#39118;&#38505;&#19978;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#27867;&#21270;&#30028;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14145v1 Announce Type: cross  Abstract: Distribution shifts are ubiquitous in real-world machine learning applications, posing a challenge to the generalization of models trained on one data distribution to another. We focus on scenarios where data distributions vary across multiple segments of the entire population and only make local assumptions about the differences between training and test (deployment) distributions within each segment. We propose a two-stage multiply robust estimation method to improve model performance on each individual segment for tabular data analysis. The method involves fitting a linear combination of the based models, learned using clusters of training data from multiple segments, followed by a refinement step for each segment. Our method is designed to be implemented with commonly used off-the-shelf machine learning models. We establish theoretical guarantees on the generalization bound of the method on the test risk. With extensive experiments
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#38382;&#39064;&#65292;&#20026;&#20102;&#39640;&#25928;&#22320;&#25214;&#21040;&#21487;&#20197;&#22312;&#26679;&#26412;&#19978;&#23454;&#29616;&#38750;&#24179;&#20961;&#39044;&#27979;&#35823;&#24046;&#30340;&#28508;&#22312;&#23494;&#38598;&#20272;&#35745;&#30340;&#22238;&#24402;&#21521;&#37327;&#65292;&#38656;&#35201;&#33267;&#23569; $\Omega(k \log (d/k))$ &#20010;&#26679;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.14103</link><description>&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#19981;&#24403;&#23398;&#20064;&#30340;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Computational-Statistical Gaps for Improper Learning in Sparse Linear Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14103
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#38382;&#39064;&#65292;&#20026;&#20102;&#39640;&#25928;&#22320;&#25214;&#21040;&#21487;&#20197;&#22312;&#26679;&#26412;&#19978;&#23454;&#29616;&#38750;&#24179;&#20961;&#39044;&#27979;&#35823;&#24046;&#30340;&#28508;&#22312;&#23494;&#38598;&#20272;&#35745;&#30340;&#22238;&#24402;&#21521;&#37327;&#65292;&#38656;&#35201;&#33267;&#23569; $\Omega(k \log (d/k))$ &#20010;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#19981;&#24403;&#23398;&#20064;&#30340;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#32473;&#23450;&#26469;&#33258;&#32500;&#24230;&#20026; $d$ &#30340; $k$-&#31232;&#30095;&#32447;&#24615;&#27169;&#22411;&#30340; $n$ &#20010;&#26679;&#26412;&#65292;&#25105;&#20204;&#35810;&#38382;&#20102;&#22312;&#26102;&#38388;&#22810;&#39033;&#24335;&#20013;&#30340;&#26368;&#23567;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20197;&#20415;&#39640;&#25928;&#22320;&#25214;&#21040;&#19968;&#20010;&#23545;&#36825; $n$ &#20010;&#26679;&#26412;&#36798;&#21040;&#38750;&#24179;&#20961;&#39044;&#27979;&#35823;&#24046;&#30340;&#28508;&#22312;&#23494;&#38598;&#20272;&#35745;&#30340;&#22238;&#24402;&#21521;&#37327;&#12290;&#20449;&#24687;&#29702;&#35770;&#19978;&#65292;&#36825;&#21487;&#20197;&#29992; $\Theta(k \log (d/k))$ &#20010;&#26679;&#26412;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#25991;&#29486;&#20013;&#24456;&#26174;&#33879;&#65292;&#20294;&#27809;&#26377;&#24050;&#30693;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#21487;&#20197;&#22312;&#19981;&#38468;&#21152;&#23545;&#27169;&#22411;&#30340;&#20854;&#20182;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#23569;&#20110; $\Theta(d)$ &#20010;&#26679;&#26412;&#36798;&#21040;&#30456;&#21516;&#30340;&#20445;&#35777;&#12290;&#31867;&#20284;&#22320;&#65292;&#29616;&#26377;&#30340;&#22256;&#38590;&#32467;&#26524;&#35201;&#20040;&#20165;&#38480;&#20110;&#36866;&#24403;&#35774;&#32622;&#65292;&#22312;&#35813;&#35774;&#32622;&#20013;&#20272;&#35745;&#20540;&#20063;&#24517;&#39035;&#26159;&#31232;&#30095;&#30340;&#65292;&#35201;&#20040;&#20165;&#36866;&#29992;&#20110;&#29305;&#23450;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14103v1 Announce Type: new  Abstract: We study computational-statistical gaps for improper learning in sparse linear regression. More specifically, given $n$ samples from a $k$-sparse linear model in dimension $d$, we ask what is the minimum sample complexity to efficiently (in time polynomial in $d$, $k$, and $n$) find a potentially dense estimate for the regression vector that achieves non-trivial prediction error on the $n$ samples. Information-theoretically this can be achieved using $\Theta(k \log (d/k))$ samples. Yet, despite its prominence in the literature, there is no polynomial-time algorithm known to achieve the same guarantees using less than $\Theta(d)$ samples without additional restrictions on the model. Similarly, existing hardness results are either restricted to the proper setting, in which the estimate must be sparse as well, or only apply to specific algorithms.   We give evidence that efficient algorithms for this task require at least (roughly) $\Omega(
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#36890;&#36807;AI&#27169;&#25311;&#31995;&#32479;&#20998;&#26512;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#65292;&#24182;&#24378;&#35843;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.14090</link><description>&lt;p&gt;
&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Social Environment Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14090
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#36890;&#36807;AI&#27169;&#25311;&#31995;&#32479;&#20998;&#26512;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#65292;&#24182;&#24378;&#35843;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#25913;&#21892;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#21046;&#23450;&#30340;&#25216;&#26415;&#20855;&#26377;&#28508;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#19982;&#24378;&#21270;&#23398;&#20064;&#12289;&#32463;&#27982;&#19982;&#35745;&#31639;&#31038;&#20250;&#36873;&#25321;&#31038;&#21306;&#30456;&#36830;&#25509;&#12290;&#35813;&#26694;&#26550;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#21253;&#25324;&#23545;&#25919;&#31574;&#30446;&#26631;&#30340;&#25237;&#31080;&#65292;&#24182;&#20026;&#36890;&#36807;AI&#27169;&#25311;&#23545;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#36827;&#34892;&#31995;&#32479;&#20998;&#26512;&#25552;&#20379;&#25351;&#23548;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#24320;&#25918;&#38382;&#39064;&#12290;&#36890;&#36807;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24076;&#26395;&#23454;&#29616;&#21508;&#31181;&#31038;&#20250;&#31119;&#21033;&#30446;&#26631;&#65292;&#20174;&#32780;&#20419;&#36827;&#26356;&#20855;&#36947;&#24503;&#21644;&#36127;&#36131;&#20219;&#30340;&#20915;&#31574;&#21046;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14090v1 Announce Type: new  Abstract: Artificial Intelligence (AI) holds promise as a technology that can be used to improve government and economic policy-making. This paper proposes a new research agenda towards this end by introducing Social Environment Design, a general framework for the use of AI for automated policy-making that connects with the Reinforcement Learning, EconCS, and Computational Social Choice communities. The framework seeks to capture general economic environments, includes voting on policy objectives, and gives a direction for the systematic analysis of government and economic policy through AI simulation. We highlight key open problems for future research in AI-based policy-making. By solving these challenges, we hope to achieve various social welfare objectives, thereby promoting more ethical and responsible decision making.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#65292;&#38024;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.14081</link><description>&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#36816;&#21160;&#20195;&#30721;&#30340;&#38543;&#26426;&#36807;&#31243;&#27169;&#22411;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Robust Learning of Noisy Time Series Collections Using Stochastic Process Models with Motion Codes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14081
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#65292;&#38024;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#39044;&#27979;&#38382;&#39064;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#20855;&#26377;&#20219;&#24847;&#26102;&#38388;&#24207;&#21015;&#38271;&#24230;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#24773;&#20917;&#20173;&#20855;&#25361;&#25112;&#24615;&#12290;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#23454;&#20363;&#21487;&#20197;&#30475;&#20316;&#26159;&#22024;&#26434;&#21160;&#24577;&#27169;&#22411;&#30340;&#19968;&#20010;&#26679;&#26412;&#23454;&#29616;&#65292;&#20854;&#29305;&#28857;&#26159;&#36830;&#32493;&#38543;&#26426;&#36807;&#31243;&#12290;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#65292;&#25968;&#25454;&#26159;&#28151;&#21512;&#30340;&#65292;&#30001;&#22810;&#20010;&#38543;&#26426;&#36807;&#31243;&#24314;&#27169;&#30340;&#20960;&#31181;&#31867;&#22411;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#24207;&#21015;&#32452;&#25104;&#65292;&#20351;&#24471;&#39044;&#27979;&#21644;&#20998;&#31867;&#20219;&#21153;&#21464;&#24471;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#19981;&#26159;&#31616;&#21333;&#22320;&#23558;&#25968;&#25454;&#22238;&#24402;&#21040;&#27599;&#31181;&#26102;&#38388;&#24207;&#21015;&#31867;&#22411;&#65292;&#32780;&#26159;&#37319;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#20026;&#27599;&#31181;&#31867;&#22411;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#33258;&#21160;&#20998;&#37197;&#19968;&#20010;&#31216;&#20026;&#20854;&#36816;&#21160;&#20195;&#30721;&#30340;&#31614;&#21517;&#21521;&#37327;&#12290;&#28982;&#21518;&#65292;&#22312;&#27599;&#20010;&#20998;&#37197;&#30340;&#36816;&#21160;&#20195;&#30721;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25512;&#26029;&#20986;&#30456;&#20851;&#24615;&#30340;&#31232;&#30095;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14081v1 Announce Type: cross  Abstract: While time series classification and forecasting problems have been extensively studied, the cases of noisy time series data with arbitrary time sequence lengths have remained challenging. Each time series instance can be thought of as a sample realization of a noisy dynamical model, which is characterized by a continuous stochastic process. For many applications, the data are mixed and consist of several types of noisy time series sequences modeled by multiple stochastic processes, making the forecasting and classification tasks even more challenging. Instead of regressing data naively and individually to each time series type, we take a latent variable model approach using a mixtured Gaussian processes with learned spectral kernels. More specifically, we auto-assign each type of noisy time series data a signature vector called its motion code. Then, conditioned on each assigned motion code, we infer a sparse approximation of the corr
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28145;&#24230;&#22238;&#24402;&#26862;&#26519;&#35745;&#31639;&#26679;&#26412;&#26041;&#24046;&#65292;&#25552;&#39640;&#20102;&#25239;&#30284;&#33647;&#29289;&#25935;&#24863;&#24615;&#39044;&#27979;&#20013;&#30340;&#35268;&#33539;&#21270;&#32622;&#20449;&#39044;&#27979;&#25928;&#29575;&#21644;&#35206;&#30422;&#29575;</title><link>https://arxiv.org/abs/2402.14080</link><description>&lt;p&gt;
&#39640;&#25928;&#30340;&#35268;&#33539;&#21270;&#32622;&#20449;&#39044;&#27979;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65306;&#22522;&#20110;&#28145;&#24230;&#22238;&#24402;&#26862;&#26519;&#30340;&#25239;&#30284;&#33647;&#29289;&#25935;&#24863;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Efficient Normalized Conformal Prediction and Uncertainty Quantification for Anti-Cancer Drug Sensitivity Prediction with Deep Regression Forests
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14080
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#22238;&#24402;&#26862;&#26519;&#35745;&#31639;&#26679;&#26412;&#26041;&#24046;&#65292;&#25552;&#39640;&#20102;&#25239;&#30284;&#33647;&#29289;&#25935;&#24863;&#24615;&#39044;&#27979;&#20013;&#30340;&#35268;&#33539;&#21270;&#32622;&#20449;&#39044;&#27979;&#25928;&#29575;&#21644;&#35206;&#30422;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#27491;&#22312;&#34987;&#24212;&#29992;&#20110;&#21508;&#31181;&#20851;&#38190;&#20915;&#31574;&#20219;&#21153;&#65292;&#28982;&#32780;&#23427;&#20204;&#34987;&#35757;&#32451;&#20026;&#25552;&#20379;&#28857;&#39044;&#27979;&#32780;&#27809;&#26377;&#25552;&#20379;&#20449;&#24515;&#24230;&#12290;&#22914;&#26524;&#19982;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#32467;&#21512;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#21487;&#20197;&#24471;&#21040;&#25552;&#39640;&#12290;&#32622;&#20449;&#39044;&#27979;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19982;&#39044;&#27979;&#21306;&#38388;&#37197;&#23545;&#65292;&#20174;&#32780;&#21487;&#20197;&#30475;&#21040;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#24120;&#35265;&#30340;&#29992;&#20110;&#32622;&#20449;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#26410;&#33021;&#25552;&#20379;&#23545;&#25152;&#26377;&#26679;&#26412;&#21516;&#26679;&#20934;&#30830;&#30340;&#24322;&#26041;&#24046;&#38388;&#38548;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#28145;&#24230;&#22238;&#24402;&#26862;&#26519;&#33719;&#24471;&#30340;&#26041;&#24046;&#26469;&#20272;&#35745;&#27599;&#20010;&#26679;&#26412;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;&#22238;&#24402;&#26862;&#26519;&#30340;&#26041;&#24046;&#22914;&#20309;&#25552;&#39640;&#33647;&#29289;&#21453;&#24212;&#39044;&#27979;&#20219;&#21153;&#19978;&#35268;&#33539;&#21270;&#35825;&#23548;&#32622;&#20449;&#39044;&#27979;&#30340;&#25928;&#29575;&#21644;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14080v1 Announce Type: cross  Abstract: Deep learning models are being adopted and applied on various critical decision-making tasks, yet they are trained to provide point predictions without providing degrees of confidence. The trustworthiness of deep learning models can be increased if paired with uncertainty estimations. Conformal Prediction has emerged as a promising method to pair machine learning models with prediction intervals, allowing for a view of the model's uncertainty. However, popular uncertainty estimation methods for conformal prediction fail to provide heteroskedastic intervals that are equally accurate for all samples. In this paper, we propose a method to estimate the uncertainty of each sample by calculating the variance obtained from a Deep Regression Forest. We show that the deep regression forest variance improves the efficiency and coverage of normalized inductive conformal prediction on a drug response prediction task.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#20572;&#27490;&#36807;&#31243;&#24182;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#19968;&#31995;&#21015;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#30340;&#20998;&#26512;&#65292;&#20174;&#32780;&#21019;&#36896;&#20102;&#23545;Johnson-Lindenstrauss&#24341;&#29702;&#30340;&#38750;&#24179;&#20961;&#38789;&#25193;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.14026</link><description>&lt;p&gt;
&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Probability Tools for Sequential Random Projection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14026
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#20572;&#27490;&#36807;&#31243;&#24182;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#19968;&#31995;&#21015;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#30340;&#20998;&#26512;&#65292;&#20174;&#32780;&#21019;&#36896;&#20102;&#23545;Johnson-Lindenstrauss&#24341;&#29702;&#30340;&#38750;&#24179;&#20961;&#38789;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#19987;&#20026;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#23450;&#21046;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36825;&#31181;&#26041;&#27861;&#26893;&#26681;&#20110;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#39034;&#24207;&#20915;&#31574;&#30340;&#25361;&#25112;&#12290;&#20998;&#26512;&#21463;&#21040;&#38543;&#26426;&#21464;&#37327;&#30340;&#39034;&#24207;&#20381;&#36182;&#21644;&#39640;&#32500;&#24615;&#36136;&#30340;&#24433;&#21709;&#65292;&#36825;&#26159;&#39034;&#24207;&#20915;&#31574;&#36807;&#31243;&#20013;&#22266;&#26377;&#30340;&#33258;&#36866;&#24212;&#26426;&#21046;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#29305;&#28857;&#26159;&#26500;&#24314;&#20102;&#19968;&#20010;&#20572;&#27490;&#36807;&#31243;&#65292;&#20415;&#20110;&#20998;&#26512;&#19968;&#31995;&#21015;&#20197;&#39034;&#24207;&#26041;&#24335;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#12290;&#36890;&#36807;&#22312;&#20174;&#20572;&#27490;&#36807;&#31243;&#24471;&#20986;&#30340;&#33258;&#35268;&#33539;&#36807;&#31243;&#20869;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#25152;&#38656;&#30340;&#38750;&#28176;&#36817;&#27010;&#29575;&#30028;&#38480;&#12290;&#35813;&#30028;&#38480;&#20195;&#34920;&#20102;&#23545;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#38789;&#25193;&#23637;&#65292;&#26631;&#24535;&#30528;&#23545;&#38543;&#26426;&#25237;&#24433;&#21644;&#39034;&#24207;&#20998;&#26512;&#30340;&#25991;&#29486;&#20570;&#20986;&#20102;&#24320;&#21019;&#24615;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14026v1 Announce Type: cross  Abstract: We introduce the first probabilistic framework tailored for sequential random projection, an approach rooted in the challenges of sequential decision-making under uncertainty. The analysis is complicated by the sequential dependence and high-dimensional nature of random variables, a byproduct of the adaptive mechanisms inherent in sequential decision processes. Our work features a novel construction of a stopped process, facilitating the analysis of a sequence of concentration events that are interconnected in a sequential manner. By employing the method of mixtures within a self-normalized process, derived from the stopped process, we achieve a desired non-asymptotic probability bound. This bound represents a non-trivial martingale extension of the Johnson-Lindenstrauss (JL) lemma, marking a pioneering contribution to the literature on random projection and sequential analysis.
&lt;/p&gt;</description></item><item><title>&#37325;&#26032;&#23457;&#35270;&#20102;AdaGrad&#22312;&#38750;&#20984;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#22122;&#22768;&#27169;&#22411;&#65292;&#24471;&#20986;&#20102;&#27010;&#29575;&#25910;&#25947;&#36895;&#24230;&#65292;&#26080;&#38656;&#20808;&#39564;&#30693;&#35782;&#65292;&#19988;&#21487;&#20197;&#22312;&#22122;&#22768;&#21442;&#25968;&#36275;&#22815;&#23567;&#26102;&#21152;&#36895;&#33267;&#26356;&#24555;&#30340;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.13794</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;AdaGrad&#22312;&#23485;&#26494;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Revisiting Convergence of AdaGrad with Relaxed Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13794
&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#20102;AdaGrad&#22312;&#38750;&#20984;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#22122;&#22768;&#27169;&#22411;&#65292;&#24471;&#20986;&#20102;&#27010;&#29575;&#25910;&#25947;&#36895;&#24230;&#65292;&#26080;&#38656;&#20808;&#39564;&#30693;&#35782;&#65292;&#19988;&#21487;&#20197;&#22312;&#22122;&#22768;&#21442;&#25968;&#36275;&#22815;&#23567;&#26102;&#21152;&#36895;&#33267;&#26356;&#24555;&#30340;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;AdaGrad&#22312;&#38750;&#20984;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;AdaGrad&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#20854;&#20013;&#22122;&#22768;&#30340;&#22823;&#23567;&#30001;&#20989;&#25968;&#20540;&#24046;&#21644;&#26799;&#24230;&#22823;&#23567;&#25511;&#21046;&#12290;&#36825;&#20010;&#27169;&#22411;&#28085;&#30422;&#20102;&#24191;&#27867;&#33539;&#22260;&#30340;&#22122;&#22768;&#65292;&#21253;&#25324;&#26377;&#30028;&#22122;&#22768;&#12289;&#27425;&#39640;&#26031;&#22122;&#22768;&#12289;&#20223;&#23556;&#26041;&#24046;&#22122;&#22768;&#21644;&#39044;&#26399;&#20809;&#28369;&#24230;&#65292;&#24182;&#19988;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#34987;&#35777;&#26126;&#26356;&#21152;&#29616;&#23454;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24471;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#25910;&#25947;&#36895;&#24230;&#65292;&#26681;&#25454;&#36890;&#29992;&#22122;&#22768;&#65292;&#21487;&#20197;&#36798;&#21040;( \tilde{\mathcal{O}}(1/\sqrt{T}))&#12290;&#36825;&#20010;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#20808;&#21069;&#23545;&#38382;&#39064;&#21442;&#25968;&#30340;&#20102;&#35299;&#65292;&#24403;&#19982;&#20989;&#25968;&#20540;&#24046;&#21644;&#22122;&#22768;&#27700;&#24179;&#30456;&#20851;&#30340;&#21442;&#25968;&#36275;&#22815;&#23567;&#26102;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;&#21040;(\tilde{\mathcal{O}}(1/T))&#65292;&#20854;&#20013;(T)&#34920;&#31034;&#24635;&#36845;&#20195;&#27425;&#25968;&#12290;&#25910;&#25947;&#36895;&#24230;&#22240;&#27492;&#21305;&#37197;&#20102;&#19979;&#38480;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13794v1 Announce Type: cross  Abstract: In this study, we revisit the convergence of AdaGrad with momentum (covering AdaGrad as a special case) on non-convex smooth optimization problems. We consider a general noise model where the noise magnitude is controlled by the function value gap together with the gradient magnitude. This model encompasses a broad range of noises including bounded noise, sub-Gaussian noise, affine variance noise and the expected smoothness, and it has been shown to be more realistic in many practical applications. Our analysis yields a probabilistic convergence rate which, under the general noise, could reach at (\tilde{\mathcal{O}}(1/\sqrt{T})). This rate does not rely on prior knowledge of problem-parameters and could accelerate to (\tilde{\mathcal{O}}(1/T)) where (T) denotes the total number iterations, when the noise parameters related to the function value gap and noise level are sufficiently small. The convergence rate thus matches the lower rat
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#19978;&#19979;&#30028;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#32622;&#29305;&#23450;&#30340;&#20989;&#25968;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#19978;&#19979;&#30028;&#38480;&#65292;&#24182;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#32852;&#31995;</title><link>https://arxiv.org/abs/2402.13662</link><description>&lt;p&gt;
&#19968;&#31181;&#30028;&#23450;&#23614;&#37096;&#27010;&#29575;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Method For Bounding Tail Probabilities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13662
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#19978;&#19979;&#30028;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#32622;&#29305;&#23450;&#30340;&#20989;&#25968;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#19978;&#19979;&#30028;&#38480;&#65292;&#24182;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#19978;&#19979;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#65288;RVs&#65289;&#30340;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#12290;&#23545;&#20110;&#20855;&#26377;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;$f_X(x)$&#30340;RV $X$&#30340;&#21491;&#23614;&#27010;&#29575;&#65292;&#35813;&#26041;&#27861;&#39318;&#20808;&#35201;&#27714;&#35774;&#32622;&#19968;&#20010;&#36830;&#32493;&#30340;&#12289;&#27491;&#30340;&#12289;&#20005;&#26684;&#36882;&#20943;&#30340;&#20989;&#25968;$g_X(x)$&#65292;&#20351;&#24471;$-f_X(x)/g'_X(x)$&#26159;&#19968;&#20010;&#36882;&#20943;&#19988;&#36882;&#22686;&#30340;&#20989;&#25968;&#65292;$\forall x&gt;x_0$&#65292;&#20998;&#21035;&#32473;&#20986;&#24418;&#24335;&#20026;$-f_X(x) g_X(x)/g'_X(x)$&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;$\forall x&gt;x_0$&#65292;&#20854;&#20013;$x_0$&#26159;&#26576;&#20010;&#28857;&#12290;&#31867;&#20284;&#22320;&#65292;&#23545;&#20110;$X$&#30340;&#24038;&#23614;&#27010;&#29575;&#30340;&#19978;&#19979;&#30028;&#65292;&#35813;&#26041;&#27861;&#39318;&#20808;&#35201;&#27714;&#35774;&#32622;&#19968;&#20010;&#36830;&#32493;&#30340;&#12289;&#27491;&#30340;&#12289;&#20005;&#26684;&#36882;&#22686;&#30340;&#20989;&#25968;$g_X(x)$&#65292;&#20351;&#24471;$f_X(x)/g'_X(x)$&#26159;&#19968;&#20010;&#22686;&#21152;&#19988;&#36882;&#20943;&#30340;&#20989;&#25968;&#65292;$\forall x&lt;x_0$&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#20989;&#25968;$g_X(x)$&#30340;&#33391;&#22909;&#20505;&#36873;&#31034;&#20363;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#26032;&#30028;&#38480;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13662v1 Announce Type: cross  Abstract: We present a method for upper and lower bounding the right and the left tail probabilities of continuous random variables (RVs). For the right tail probability of RV $X$ with probability density function $f_X(x)$, this method requires first setting a continuous, positive, and strictly decreasing function $g_X(x)$ such that $-f_X(x)/g'_X(x)$ is a decreasing and increasing function, $\forall x&gt;x_0$, which results in upper and lower bounds, respectively, given in the form $-f_X(x) g_X(x)/g'_X(x)$, $\forall x&gt;x_0$, where $x_0$ is some point. Similarly, for the upper and lower bounds on the left tail probability of $X$, this method requires first setting a continuous, positive, and strictly increasing function $g_X(x)$ such that $f_X(x)/g'_X(x)$ is an increasing and decreasing function, $\forall x&lt;x_0$. We provide some examples of good candidates for the function $g_X(x)$. We also establish connections between the new bounds and Markov's in
&lt;/p&gt;</description></item><item><title>LS&#20449;&#24687;&#20934;&#21017;&#26088;&#22312;&#22686;&#24378;WBIC&#21644;sBIC&#30340;&#21151;&#33021;&#65292;&#26377;&#25928;&#22788;&#29702;&#38750;&#27491;&#21017;&#24773;&#20917;&#65292;&#20855;&#26377;&#31283;&#23450;&#24615;&#65292;&#20026;&#22855;&#24322;&#24773;&#20917;&#19979;&#30340;&#20449;&#24687;&#20934;&#21017;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.12762</link><description>&lt;p&gt;
&#22312;&#22855;&#24322;&#24615;&#19979;&#30340;&#23398;&#20064;&#65306;&#25913;&#36827;WBIC&#21644;sBIC&#30340;&#20449;&#24687;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Learning under Singularity: An Information Criterion improving WBIC and sBIC
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12762
&lt;/p&gt;
&lt;p&gt;
LS&#20449;&#24687;&#20934;&#21017;&#26088;&#22312;&#22686;&#24378;WBIC&#21644;sBIC&#30340;&#21151;&#33021;&#65292;&#26377;&#25928;&#22788;&#29702;&#38750;&#27491;&#21017;&#24773;&#20917;&#65292;&#20855;&#26377;&#31283;&#23450;&#24615;&#65292;&#20026;&#22855;&#24322;&#24773;&#20917;&#19979;&#30340;&#20449;&#24687;&#20934;&#21017;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#20934;&#21017;&#65288;IC&#65289;&#65292;&#31216;&#20026;&#22312;&#22855;&#24322;&#24615;&#19979;&#30340;&#23398;&#20064;&#65288;LS&#65289;&#65292;&#26088;&#22312;&#22686;&#24378;&#24191;&#27867;&#36866;&#29992;&#30340;&#36125;&#21494;&#26031;&#20449;&#24687;&#20934;&#21017;&#65288;WBIC&#65289;&#21644;&#22855;&#24322;&#36125;&#21494;&#26031;&#20449;&#24687;&#20934;&#21017;&#65288;sBIC&#65289;&#30340;&#21151;&#33021;&#12290; LS&#22312;&#27809;&#26377;&#27491;&#21017;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#26159;&#26377;&#25928;&#30340;&#65292;&#24182;&#34920;&#29616;&#20986;&#31283;&#23450;&#24615;&#12290;Watanabe&#23450;&#20041;&#20102;&#19968;&#20010;&#32479;&#35745;&#27169;&#22411;&#25110;&#23398;&#20064;&#26426;&#22120;&#20026;&#27491;&#21017;&#65292;&#22914;&#26524;&#20174;&#21442;&#25968;&#21040;&#27010;&#29575;&#20998;&#24067;&#30340;&#26144;&#23556;&#26159;&#19968;&#23545;&#19968;&#30340;&#65292;&#24182;&#19988;&#20854;Fisher&#20449;&#24687;&#30697;&#38453;&#26159;&#27491;&#23450;&#30340;&#12290;&#30456;&#21453;&#65292;&#19981;&#31526;&#21512;&#36825;&#20123;&#26465;&#20214;&#30340;&#27169;&#22411;&#34987;&#31216;&#20026;&#22855;&#24322;&#12290; &#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#22855;&#24322;&#24773;&#20917;&#19979;&#30340;&#20449;&#24687;&#20934;&#21017;&#65292;&#21253;&#25324;WBIC&#21644;sBIC&#12290; WBIC&#36866;&#29992;&#20110;&#38750;&#27491;&#21017;&#24773;&#20917;&#65292;&#20294;&#22312;&#26679;&#26412;&#37327;&#24456;&#22823;&#19988;&#24050;&#30693;&#23398;&#20064;&#31995;&#25968;&#20272;&#35745;&#20887;&#20313;&#26102;&#38754;&#20020;&#25361;&#25112;&#12290; &#30456;&#21453;&#65292;sBIC&#22312;&#24191;&#27867;&#24212;&#29992;&#26041;&#38754;&#23384;&#22312;&#38480;&#21046;&#65292;&#22240;&#20026;&#23427;&#20381;&#36182;&#20110;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12762v1 Announce Type: cross  Abstract: We introduce a novel Information Criterion (IC), termed Learning under Singularity (LS), designed to enhance the functionality of the Widely Applicable Bayes Information Criterion (WBIC) and the Singular Bayesian Information Criterion (sBIC). LS is effective without regularity constraints and demonstrates stability. Watanabe defined a statistical model or a learning machine as regular if the mapping from a parameter to a probability distribution is one-to-one and its Fisher information matrix is positive definite. In contrast, models not meeting these conditions are termed singular. Over the past decade, several information criteria for singular cases have been proposed, including WBIC and sBIC. WBIC is applicable in non-regular scenarios but faces challenges with large sample sizes and redundant estimation of known learning coefficients. Conversely, sBIC is limited in its broader application due to its dependence on maximum likelihood
&lt;/p&gt;</description></item><item><title>BlackJAX&#26159;&#19968;&#20010;&#23454;&#29616;&#22312;JAX&#20013;&#32452;&#21512;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#24211;&#65292;&#37319;&#29992;&#20989;&#25968;&#24335;&#26041;&#27861;&#25552;&#39640;&#26131;&#29992;&#24615;&#12289;&#36895;&#24230;&#21644;&#27169;&#22359;&#21270;&#65292;&#36866;&#29992;&#20110;&#38656;&#35201;&#23574;&#31471;&#26041;&#27861;&#12289;&#30740;&#31350;&#20154;&#21592;&#21644;&#24819;&#35201;&#20102;&#35299;&#24037;&#20316;&#21407;&#29702;&#30340;&#20154;&#12290;</title><link>https://arxiv.org/abs/2402.10797</link><description>&lt;p&gt;
BlackJAX: JAX&#20013;&#30340;&#32452;&#21512;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
BlackJAX: Composable Bayesian inference in JAX
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10797
&lt;/p&gt;
&lt;p&gt;
BlackJAX&#26159;&#19968;&#20010;&#23454;&#29616;&#22312;JAX&#20013;&#32452;&#21512;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#24211;&#65292;&#37319;&#29992;&#20989;&#25968;&#24335;&#26041;&#27861;&#25552;&#39640;&#26131;&#29992;&#24615;&#12289;&#36895;&#24230;&#21644;&#27169;&#22359;&#21270;&#65292;&#36866;&#29992;&#20110;&#38656;&#35201;&#23574;&#31471;&#26041;&#27861;&#12289;&#30740;&#31350;&#20154;&#21592;&#21644;&#24819;&#35201;&#20102;&#35299;&#24037;&#20316;&#21407;&#29702;&#30340;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
BlackJAX&#26159;&#19968;&#20010;&#24211;&#65292;&#23454;&#29616;&#20102;&#22312;&#36125;&#21494;&#26031;&#35745;&#31639;&#20013;&#24120;&#29992;&#30340;&#25277;&#26679;&#21644;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#12290;&#23427;&#36890;&#36807;&#37319;&#29992;&#20989;&#25968;&#24335;&#26041;&#27861;&#23454;&#29616;&#31639;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#26131;&#29992;&#24615;&#12289;&#36895;&#24230;&#21644;&#27169;&#22359;&#21270;&#12290;BlackJAX&#20351;&#29992;Python&#32534;&#20889;&#65292;&#21033;&#29992;JAX&#22312;CPU&#12289;GPU&#21644;TPU&#19978;&#32534;&#35793;&#21644;&#36816;&#34892;&#31867;&#20284;Numpy&#30340;&#25277;&#26679;&#22120;&#21644;&#21464;&#20998;&#26041;&#27861;&#12290;&#35813;&#24211;&#36890;&#36807;&#30452;&#25509;&#22788;&#29702;&#65288;&#38750;&#27491;&#21017;&#21270;&#65289;&#30446;&#26631;&#23545;&#25968;&#23494;&#24230;&#20989;&#25968;&#65292;&#19982;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#24456;&#22909;&#22320;&#38598;&#25104;&#12290;BlackJAX&#26088;&#22312;&#25104;&#20026;&#22522;&#26412;&#32479;&#35745;&#8220;&#22522;&#20803;&#8221;&#30340;&#20302;&#32423;&#21487;&#32452;&#21512;&#23454;&#29616;&#30340;&#38598;&#21512;&#65292;&#21487;&#32452;&#21512;&#25191;&#34892;&#23450;&#20041;&#33391;&#22909;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#39640;&#32423;&#20363;&#31243;&#20197;&#25552;&#39640;&#26131;&#29992;&#24615;&#12290;&#23427;&#38754;&#21521;&#38656;&#35201;&#23574;&#31471;&#26041;&#27861;&#30340;&#29992;&#25143;&#12289;&#24076;&#26395;&#21019;&#24314;&#22797;&#26434;&#25277;&#26679;&#26041;&#27861;&#30340;&#30740;&#31350;&#20154;&#21592;&#65292;&#20197;&#21450;&#24819;&#35201;&#20102;&#35299;&#36825;&#20123;&#26041;&#27861;&#24037;&#20316;&#21407;&#29702;&#30340;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10797v1 Announce Type: cross  Abstract: BlackJAX is a library implementing sampling and variational inference algorithms commonly used in Bayesian computation. It is designed for ease of use, speed, and modularity by taking a functional approach to the algorithms' implementation. BlackJAX is written in Python, using JAX to compile and run NumpPy-like samplers and variational methods on CPUs, GPUs, and TPUs. The library integrates well with probabilistic programming languages by working directly with the (un-normalized) target log density function. BlackJAX is intended as a collection of low-level, composable implementations of basic statistical 'atoms' that can be combined to perform well-defined Bayesian inference, but also provides high-level routines for ease of use. It is designed for users who need cutting-edge methods, researchers who want to create complex sampling methods, and people who want to learn how these work.
&lt;/p&gt;</description></item><item><title>EduGym&#26159;&#19968;&#22871;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#25945;&#32946;&#30340;&#29615;&#22659;&#21644;&#31508;&#35760;&#26412;&#22871;&#20214;&#65292;&#26088;&#22312;&#35299;&#20915;&#23398;&#29983;&#22312;&#36716;&#25442;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#36935;&#21040;&#30340;&#22256;&#38590;&#12290;</title><link>https://arxiv.org/abs/2311.10590</link><description>&lt;p&gt;
EduGym: &#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#25945;&#32946;&#30340;&#29615;&#22659;&#21644;&#31508;&#35760;&#26412;&#22871;&#20214;
&lt;/p&gt;
&lt;p&gt;
EduGym: An Environment and Notebook Suite for Reinforcement Learning Education
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.10590
&lt;/p&gt;
&lt;p&gt;
EduGym&#26159;&#19968;&#22871;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#25945;&#32946;&#30340;&#29615;&#22659;&#21644;&#31508;&#35760;&#26412;&#22871;&#20214;&#65292;&#26088;&#22312;&#35299;&#20915;&#23398;&#29983;&#22312;&#36716;&#25442;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#36935;&#21040;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#32463;&#39564;&#25104;&#21151;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#23398;&#29983;&#22312;&#23398;&#20064;&#36825;&#20010;&#35838;&#39064;&#12290;&#28982;&#32780;&#65292;&#26681;&#25454;&#25105;&#20204;&#30340;&#23454;&#38469;&#25945;&#23398;&#32463;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;&#23398;&#29983;&#22312;&#36827;&#20837;&#36825;&#20010;&#39046;&#22495;&#65288;&#26412;&#31185;&#29983;&#12289;&#30805;&#22763;&#29983;&#21644;&#26089;&#26399;&#21338;&#22763;&#29983;&#65289;&#26102;&#24120;&#24120;&#36935;&#21040;&#22256;&#38590;&#12290;&#19968;&#26041;&#38754;&#65292;&#25945;&#31185;&#20070;&#21644;&#65288;&#22312;&#32447;&#65289;&#35762;&#24231;&#25552;&#20379;&#20102;&#22522;&#30784;&#30693;&#35782;&#65292;&#20294;&#23398;&#29983;&#21457;&#29616;&#24456;&#38590;&#22312;&#26041;&#31243;&#24335;&#21644;&#20195;&#30721;&#20043;&#38388;&#36827;&#34892;&#36716;&#25442;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20844;&#20849;&#20195;&#30721;&#24211;&#25552;&#20379;&#20102;&#23454;&#38469;&#30340;&#20363;&#23376;&#65292;&#20294;&#23454;&#29616;&#30340;&#31639;&#27861;&#24448;&#24448;&#22797;&#26434;&#65292;&#24182;&#19988;&#22522;&#30784;&#27979;&#35797;&#29615;&#22659;&#21516;&#26102;&#21253;&#21547;&#22810;&#20010;&#24378;&#21270;&#23398;&#20064;&#25361;&#25112;&#12290;&#23613;&#31649;&#36825;&#22312;&#30740;&#31350;&#35282;&#24230;&#19978;&#26159;&#29616;&#23454;&#30340;&#65292;&#20294;&#23427;&#32463;&#24120;&#38459;&#30861;&#20102;&#25945;&#32946;&#27010;&#24565;&#30340;&#29702;&#35299;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25512;&#20986;&#20102;EduGym&#65292;&#36825;&#26159;&#19968;&#32452;&#19987;&#38376;&#38024;&#23545;&#25945;&#32946;&#30340;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#21644;&#30456;&#20851;&#20132;&#20114;&#24335;&#31508;&#35760;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.10590v2 Announce Type: replace-cross  Abstract: Due to the empirical success of reinforcement learning, an increasing number of students study the subject. However, from our practical teaching experience, we see students entering the field (bachelor, master and early PhD) often struggle. On the one hand, textbooks and (online) lectures provide the fundamentals, but students find it hard to translate between equations and code. On the other hand, public codebases do provide practical examples, but the implemented algorithms tend to be complex, and the underlying test environments contain multiple reinforcement learning challenges at once. Although this is realistic from a research perspective, it often hinders educational conceptual understanding. To solve this issue we introduce EduGym, a set of educational reinforcement learning environments and associated interactive notebooks tailored for education. Each EduGym environment is specifically designed to illustrate a certain 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;Prob-GNN&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#37327;&#21270;&#20986;&#34892;&#38656;&#27714;&#30340;&#26102;&#31354;&#19981;&#30830;&#23450;&#24615;&#65292;&#23454;&#35777;&#24212;&#29992;&#34920;&#26126;&#27010;&#29575;&#20551;&#35774;&#23545;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#24433;&#21709;&#22823;&#20110;&#30830;&#23450;&#24615;&#20551;&#35774;&#12290;</title><link>https://arxiv.org/abs/2303.04040</link><description>&lt;p&gt;
&#20351;&#29992;&#27010;&#29575;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#26102;&#31354;&#20986;&#34892;&#38656;&#27714;&#30340;&#19981;&#30830;&#23450;&#24615;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification of Spatiotemporal Travel Demand with Probabilistic Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2303.04040
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;Prob-GNN&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#37327;&#21270;&#20986;&#34892;&#38656;&#27714;&#30340;&#26102;&#31354;&#19981;&#30830;&#23450;&#24615;&#65292;&#23454;&#35777;&#24212;&#29992;&#34920;&#26126;&#27010;&#29575;&#20551;&#35774;&#23545;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#24433;&#21709;&#22823;&#20110;&#30830;&#23450;&#24615;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#26174;&#33879;&#25552;&#39640;&#20102;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#20986;&#34892;&#38656;&#27714;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#30053;&#20102;&#20986;&#34892;&#38656;&#27714;&#39044;&#27979;&#20013;&#19981;&#21487;&#36991;&#20813;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;Prob-GNN&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#37327;&#21270;&#20986;&#34892;&#38656;&#27714;&#30340;&#26102;&#31354;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#20010;Prob-GNN&#26694;&#26550;&#22522;&#20110;&#30830;&#23450;&#24615;&#21644;&#27010;&#29575;&#20551;&#35774;&#65292;&#24182;&#22312;&#33437;&#21152;&#21733;&#24066;&#39044;&#27979;&#20844;&#20849;&#20132;&#36890;&#21644;&#25340;&#36710;&#38656;&#27714;&#30340;&#20219;&#21153;&#19978;&#24471;&#21040;&#20102;&#23454;&#35777;&#24212;&#29992;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#27010;&#29575;&#20551;&#35774;&#65288;&#22914;&#20998;&#24067;&#23614;&#37096;&#12289;&#25903;&#25345;&#65289;&#23545;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#30340;&#24433;&#21709;&#22823;&#20110;&#30830;&#23450;&#24615;&#20551;&#35774;&#65288;&#22914;&#28145;&#24230;&#27169;&#22359;&#12289;&#28145;&#24230;&#65289;&#12290;&#22312;Prob-GNN&#23478;&#26063;&#20013;&#65292;&#37319;&#29992;&#25130;&#26029;&#39640;&#26031;&#21644;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#30340;GNN&#22312;&#20844;&#20849;&#20132;&#36890;&#21644;&#25340;&#36710;&#25968;&#25454;&#20013;&#34920;&#29616;&#26368;&#20339;&#12290;&#21363;&#20351;&#22312;&#23384;&#22312;&#26126;&#26174;&#22495;&#20559;&#31227;&#24773;&#20917;&#19979;&#65292;Prob-GNNs
&lt;/p&gt;
&lt;p&gt;
arXiv:2303.04040v2 Announce Type: replace  Abstract: Recent studies have significantly improved the prediction accuracy of travel demand using graph neural networks. However, these studies largely ignored uncertainty that inevitably exists in travel demand prediction. To fill this gap, this study proposes a framework of probabilistic graph neural networks (Prob-GNN) to quantify the spatiotemporal uncertainty of travel demand. This Prob-GNN framework is substantiated by deterministic and probabilistic assumptions, and empirically applied to the task of predicting the transit and ridesharing demand in Chicago. We found that the probabilistic assumptions (e.g. distribution tail, support) have a greater impact on uncertainty prediction than the deterministic ones (e.g. deep modules, depth). Among the family of Prob-GNNs, the GNNs with truncated Gaussian and Laplace distributions achieve the highest performance in transit and ridesharing data. Even under significant domain shifts, Prob-GNNs
&lt;/p&gt;</description></item><item><title>TBAL&#31995;&#32479;&#21487;&#20197;&#36890;&#36807;&#39564;&#35777;&#25968;&#25454;&#33258;&#21160;&#26631;&#27880;&#26410;&#26631;&#27880;&#25968;&#25454;&#65292;&#20943;&#23569;&#25163;&#21160;&#26631;&#27880;&#30340;&#20381;&#36182;&#65307;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#21363;&#20351;&#27169;&#22411;&#34920;&#29616;&#19981;&#20339;&#20063;&#21487;&#20197;&#20934;&#30830;&#33258;&#21160;&#26631;&#35760;&#25968;&#25454;&#65292;&#24182;&#25581;&#31034;&#20102;TBAL&#31995;&#32479;&#30340;&#28508;&#22312;&#32570;&#38519;</title><link>https://arxiv.org/abs/2211.12620</link><description>&lt;p&gt;
&#22522;&#20110;&#38408;&#20540;&#30340;&#33258;&#21160;&#26631;&#27880;&#30340;&#20248;&#21183;&#19982;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Promises and Pitfalls of Threshold-based Auto-labeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.12620
&lt;/p&gt;
&lt;p&gt;
TBAL&#31995;&#32479;&#21487;&#20197;&#36890;&#36807;&#39564;&#35777;&#25968;&#25454;&#33258;&#21160;&#26631;&#27880;&#26410;&#26631;&#27880;&#25968;&#25454;&#65292;&#20943;&#23569;&#25163;&#21160;&#26631;&#27880;&#30340;&#20381;&#36182;&#65307;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#21363;&#20351;&#27169;&#22411;&#34920;&#29616;&#19981;&#20339;&#20063;&#21487;&#20197;&#20934;&#30830;&#33258;&#21160;&#26631;&#35760;&#25968;&#25454;&#65292;&#24182;&#25581;&#31034;&#20102;TBAL&#31995;&#32479;&#30340;&#28508;&#22312;&#32570;&#38519;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21019;&#24314;&#22823;&#35268;&#27169;&#39640;&#36136;&#37327;&#26631;&#35760;&#25968;&#25454;&#38598;&#26159;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#24037;&#20316;&#27969;&#31243;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#29942;&#39048;&#12290;&#38408;&#20540;&#33258;&#21160;&#26631;&#27880;&#65288;TBAL&#65289;&#36890;&#36807;&#20351;&#29992;&#20154;&#31867;&#33719;&#21462;&#30340;&#39564;&#35777;&#25968;&#25454;&#26469;&#23547;&#25214;&#19968;&#20010;&#32622;&#20449;&#38408;&#20540;&#65292;&#39640;&#20110;&#35813;&#38408;&#20540;&#30340;&#25968;&#25454;&#23558;&#30001;&#26426;&#22120;&#26631;&#35760;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#23545;&#25163;&#21160;&#27880;&#37322;&#30340;&#20381;&#36182;&#12290;TBAL&#27491;&#36880;&#28176;&#25104;&#20026;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#37319;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#37492;&#20110;&#25152;&#24471;&#25968;&#25454;&#30340;&#38271;&#26399;&#26377;&#25928;&#24615;&#21644;&#22810;&#26679;&#21270;&#20351;&#29992;&#65292;&#29702;&#35299;&#36825;&#31181;&#33258;&#21160;&#26631;&#27880;&#31995;&#32479;&#33719;&#21462;&#30340;&#25968;&#25454;&#20309;&#26102;&#21487;&#20197;&#34987;&#20381;&#36182;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#36825;&#26159;&#31532;&#19968;&#39033;&#20998;&#26512;TBAL&#31995;&#32479;&#24182;&#25512;&#23548;&#38656;&#35201;&#20445;&#35777;&#26426;&#22120;&#26631;&#35760;&#25968;&#25454;&#36136;&#37327;&#30340;&#20154;&#24037;&#26631;&#35760;&#39564;&#35777;&#25968;&#25454;&#37327;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#20004;&#20010;&#20851;&#38190;&#35265;&#35299;&#12290;&#39318;&#20808;&#65292;&#34920;&#38754;&#19978;&#31967;&#31957;&#30340;&#27169;&#22411;&#21487;&#20197;&#33258;&#21160;&#12289;&#20934;&#30830;&#22320;&#26631;&#35760;&#21512;&#29702;&#25968;&#37327;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#12290;&#20854;&#27425;&#65292;TBAL&#31995;&#32479;&#30340;&#19968;&#20010;&#38544;&#34255;&#30340;&#32570;&#28857;&#26159;&#28508;&#22312;&#22320;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.12620v2 Announce Type: replace-cross  Abstract: Creating large-scale high-quality labeled datasets is a major bottleneck in supervised machine learning workflows. Threshold-based auto-labeling (TBAL), where validation data obtained from humans is used to find a confidence threshold above which the data is machine-labeled, reduces reliance on manual annotation. TBAL is emerging as a widely-used solution in practice. Given the long shelf-life and diverse usage of the resulting datasets, understanding when the data obtained by such auto-labeling systems can be relied on is crucial. This is the first work to analyze TBAL systems and derive sample complexity bounds on the amount of human-labeled validation data required for guaranteeing the quality of machine-labeled data. Our results provide two crucial insights. First, reasonable chunks of unlabeled data can be automatically and accurately labeled by seemingly bad models. Second, a hidden downside of TBAL systems is potentially
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;PAC-Bayes&#30028;&#38480;&#65292;&#33021;&#22815;&#21516;&#26102;&#25511;&#21046;&#22810;&#20010;&#38169;&#35823;&#65292;&#24182;&#25552;&#20379;&#20016;&#23500;&#30340;&#20449;&#24687;&#65292;&#36866;&#29992;&#20110;&#22238;&#24402;&#20013;&#27979;&#35797;&#25439;&#22833;&#20998;&#24067;&#25110;&#20998;&#31867;&#20013;&#19981;&#21516;&#38169;&#35823;&#20998;&#31867;&#30340;&#27010;&#29575;&#12290;</title><link>https://arxiv.org/abs/2202.05560</link><description>&lt;p&gt;
&#20351;&#29992;PAC-Bayes&#30028;&#38480;&#21516;&#26102;&#25511;&#21046;&#22810;&#20010;&#38169;&#35823;
&lt;/p&gt;
&lt;p&gt;
Controlling Multiple Errors Simultaneously with a PAC-Bayes Bound
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.05560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;PAC-Bayes&#30028;&#38480;&#65292;&#33021;&#22815;&#21516;&#26102;&#25511;&#21046;&#22810;&#20010;&#38169;&#35823;&#65292;&#24182;&#25552;&#20379;&#20016;&#23500;&#30340;&#20449;&#24687;&#65292;&#36866;&#29992;&#20110;&#22238;&#24402;&#20013;&#27979;&#35797;&#25439;&#22833;&#20998;&#24067;&#25110;&#20998;&#31867;&#20013;&#19981;&#21516;&#38169;&#35823;&#20998;&#31867;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;PAC-Bayes&#27867;&#21270;&#30028;&#38480;&#20165;&#38480;&#20110;&#24615;&#33021;&#30340;&#26631;&#37327;&#24230;&#37327;&#65292;&#22914;&#25439;&#22833;&#25110;&#38169;&#35823;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#25552;&#20379;&#20016;&#23500;&#20449;&#24687;&#30340;PAC-Bayes&#30028;&#38480;&#65292;&#36890;&#36807;&#30028;&#23450;&#19968;&#32452;M&#31181;&#38169;&#35823;&#31867;&#22411;&#30340;&#32463;&#39564;&#27010;&#29575;&#19982;&#30495;&#23454;&#27010;&#29575;&#20043;&#38388;&#30340;Kullback-Leibler&#24046;&#24322;&#26469;&#25511;&#21046;&#21487;&#33021;&#32467;&#26524;&#30340;&#25972;&#20010;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.05560v2 Announce Type: replace-cross  Abstract: Current PAC-Bayes generalisation bounds are restricted to scalar metrics of performance, such as the loss or error rate. However, one ideally wants more information-rich certificates that control the entire distribution of possible outcomes, such as the distribution of the test loss in regression, or the probabilities of different mis classifications. We provide the first PAC-Bayes bound capable of providing such rich information by bounding the Kullback-Leibler divergence between the empirical and true probabilities of a set of M error types, which can either be discretized loss values for regression, or the elements of the confusion matrix (or a partition thereof) for classification. We transform our bound into a differentiable training objective. Our bound is especially useful in cases where the severity of different mis-classifications may change over time; existing PAC-Bayes bounds can only bound a particular pre-decided w
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#30340;&#25551;&#36848;-&#24207;&#21015;&#20219;&#21153;&#65292;&#23454;&#29616;&#20102;&#22312;&#20840;&#23616;&#27700;&#24179;&#19978;&#23545;&#29983;&#25104;&#38899;&#20048;&#30340;&#32454;&#31890;&#24230;&#21487;&#25511;&#65292;&#36890;&#36807;&#32467;&#21512;&#39640;&#32423;&#29305;&#24449;&#21644;&#39046;&#22495;&#30693;&#35782;&#65292;&#22312;&#31526;&#21495;&#38899;&#20048;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#25104;&#26524;</title><link>https://arxiv.org/abs/2201.10936</link><description>&lt;p&gt;
FIGARO&#65306;&#20855;&#26377;&#32454;&#31890;&#24230;&#33402;&#26415;&#25511;&#21046;&#30340;&#31526;&#21495;&#38899;&#20048;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
FIGARO: Generating Symbolic Music with Fine-Grained Artistic Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2201.10936
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#30340;&#25551;&#36848;-&#24207;&#21015;&#20219;&#21153;&#65292;&#23454;&#29616;&#20102;&#22312;&#20840;&#23616;&#27700;&#24179;&#19978;&#23545;&#29983;&#25104;&#38899;&#20048;&#30340;&#32454;&#31890;&#24230;&#21487;&#25511;&#65292;&#36890;&#36807;&#32467;&#21512;&#39640;&#32423;&#29305;&#24449;&#21644;&#39046;&#22495;&#30693;&#35782;&#65292;&#22312;&#31526;&#21495;&#38899;&#20048;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#25104;&#26524;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#38899;&#20048;&#36817;&#24180;&#26469;&#19968;&#30452;&#26159;&#19968;&#20010;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#34429;&#28982;&#29983;&#25104;&#26679;&#26412;&#30340;&#36136;&#37327;&#19981;&#26029;&#25552;&#39640;&#65292;&#20294;&#22823;&#22810;&#25968;&#26041;&#27861;&#21482;&#33021;&#23545;&#29983;&#25104;&#30340;&#24207;&#21015;&#26045;&#21152;&#26368;&#23567;&#30340;&#25511;&#21046;&#65292;&#29978;&#33267;&#27809;&#26377;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#30417;&#30563;&#30340;&#25551;&#36848;-&#24207;&#21015;&#20219;&#21153;&#65292;&#23427;&#20801;&#35768;&#22312;&#20840;&#23616;&#27700;&#24179;&#19978;&#36827;&#34892;&#32454;&#31890;&#24230;&#21487;&#25511;&#29983;&#25104;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#21462;&#26377;&#20851;&#30446;&#26631;&#24207;&#21015;&#30340;&#39640;&#32423;&#29305;&#24449;&#65292;&#20197;&#21450;&#23398;&#20064;&#32473;&#23450;&#30456;&#24212;&#39640;&#32423;&#25551;&#36848;&#26102;&#24207;&#21015;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25551;&#36848;-&#24207;&#21015;&#24314;&#27169;&#24212;&#29992;&#21040;&#31526;&#21495;&#38899;&#20048;&#20013;&#26469;&#35757;&#32451;FIGARO&#65288;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#12289;&#40065;&#26834;&#25511;&#21046;&#30340;&#32454;&#31890;&#24230;&#38899;&#20048;&#29983;&#25104;&#65289;&#12290;&#36890;&#36807;&#23558;&#23398;&#20064;&#21040;&#30340;&#39640;&#32423;&#29305;&#24449;&#19982;&#39046;&#22495;&#30693;&#35782;&#32467;&#21512;&#65292;&#20316;&#20026;&#24378;&#24402;&#32435;&#20559;&#24046;&#65292;&#35813;&#27169;&#22411;&#22312;&#21487;&#25511;&#31526;&#21495;&#38899;&#20048;&#29983;&#25104;&#26041;&#38754;&#23454;&#29616;&#20102;&#26368;&#26032;&#30340;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2201.10936v4 Announce Type: replace-cross  Abstract: Generating music with deep neural networks has been an area of active research in recent years. While the quality of generated samples has been steadily increasing, most methods are only able to exert minimal control over the generated sequence, if any. We propose the self-supervised description-to-sequence task, which allows for fine-grained controllable generation on a global level. We do so by extracting high-level features about the target sequence and learning the conditional distribution of sequences given the corresponding high-level description in a sequence-to-sequence modelling setup. We train FIGARO (FIne-grained music Generation via Attention-based, RObust control) by applying description-to-sequence modelling to symbolic music. By combining learned high level features with domain knowledge, which acts as a strong inductive bias, the model achieves state-of-the-art results in controllable symbolic music generation a
&lt;/p&gt;</description></item><item><title>AML&#26088;&#22312;&#20445;&#25252;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20813;&#21463;&#23433;&#20840;&#23041;&#32961;&#65292;&#36125;&#21494;&#26031;&#35270;&#35282;&#20026;&#38450;&#24481;&#25552;&#20379;&#20102;&#26032;&#30340;&#22909;&#22788;</title><link>https://arxiv.org/abs/2003.03546</link><description>&lt;p&gt;
&#23545;&#25239;&#26426;&#22120;&#23398;&#20064;&#65306;&#36125;&#21494;&#26031;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Adversarial Machine Learning: Bayesian Perspectives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2003.03546
&lt;/p&gt;
&lt;p&gt;
AML&#26088;&#22312;&#20445;&#25252;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20813;&#21463;&#23433;&#20840;&#23041;&#32961;&#65292;&#36125;&#21494;&#26031;&#35270;&#35282;&#20026;&#38450;&#24481;&#25552;&#20379;&#20102;&#26032;&#30340;&#22909;&#22788;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#26426;&#22120;&#23398;&#20064;(AML)&#27491;&#22312;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#39046;&#22495;&#65292;&#26088;&#22312;&#20445;&#25252;&#26426;&#22120;&#23398;&#20064;(ML)&#31995;&#32479;&#20813;&#21463;&#23433;&#20840;&#23041;&#32961;&#65306;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21487;&#33021;&#23384;&#22312;&#25932;&#23545;&#26041;&#31215;&#26497;&#25805;&#32437;&#36755;&#20837;&#25968;&#25454;&#20197;&#27450;&#39575;&#23398;&#20064;&#31995;&#32479;&#12290; &#36825;&#21019;&#36896;&#20102;&#19968;&#31867;&#26032;&#30340;&#23433;&#20840;&#28431;&#27934;&#65292;ML&#31995;&#32479;&#21487;&#33021;&#20250;&#38754;&#20020;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#34987;&#31216;&#20026;&#25932;&#23545;&#31283;&#20581;&#24615;&#30340;&#21487;&#20449;&#25805;&#20316;&#25152;&#24517;&#38656;&#30340;&#24615;&#36136;&#12290; &#22823;&#37096;&#20998;AML&#24037;&#20316;&#37117;&#24314;&#31435;&#22312;&#23545;&#25239;&#23398;&#20064;&#31995;&#32479;&#21644;&#20934;&#22791;&#25805;&#32437;&#36755;&#20837;&#25968;&#25454;&#30340;&#23545;&#25163;&#20043;&#38388;&#20914;&#31361;&#30340;&#21338;&#24328;&#35770;&#24314;&#27169;&#20043;&#19978;&#12290; &#36825;&#20551;&#35774;&#27599;&#20010;&#20195;&#29702;&#37117;&#20102;&#35299;&#23545;&#25163;&#30340;&#20852;&#36259;&#21644;&#19981;&#30830;&#23450;&#24615;&#21028;&#26029;&#65292;&#20174;&#32780;&#20419;&#36827;&#22522;&#20110;Nash&#22343;&#34913;&#30340;&#25512;&#29702;&#12290; &#28982;&#32780;&#65292;&#22312;AML&#20856;&#22411;&#30340;&#23433;&#20840;&#26041;&#26696;&#20013;&#65292;&#36825;&#31181;&#20849;&#21516;&#30693;&#35782;&#20551;&#35774;&#24182;&#19981;&#29616;&#23454;&#12290; &#22312;&#22238;&#39038;&#20102;&#36825;&#31181;&#21338;&#24328;&#35770;&#26041;&#27861;&#20043;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#36125;&#21494;&#26031;&#35270;&#35282;&#22312;&#38450;&#24481;&#20013;&#25552;&#20379;&#30340;&#22909;&#22788;
&lt;/p&gt;
&lt;p&gt;
arXiv:2003.03546v2 Announce Type: replace  Abstract: Adversarial Machine Learning (AML) is emerging as a major field aimed at protecting machine learning (ML) systems against security threats: in certain scenarios there may be adversaries that actively manipulate input data to fool learning systems. This creates a new class of security vulnerabilities that ML systems may face, and a new desirable property called adversarial robustness essential to trust operations based on ML outputs. Most work in AML is built upon a game-theoretic modelling of the conflict between a learning system and an adversary, ready to manipulate input data. This assumes that each agent knows their opponent's interests and uncertainty judgments, facilitating inferences based on Nash equilibria. However, such common knowledge assumption is not realistic in the security scenarios typical of AML. After reviewing such game-theoretic approaches, we discuss the benefits that Bayesian perspectives provide when defendin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#30340;&#39640;&#25928;&#37319;&#26679;&#35757;&#32451;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#21508;&#31181;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.19608</link><description>&lt;p&gt;
&#35770;&#36153;&#26364;-&#21345;&#20811;&#35757;&#32451;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
On Feynman--Kac training of partial Bayesian neural networks. (arXiv:2310.19608v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#30340;&#39640;&#25928;&#37319;&#26679;&#35757;&#32451;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#21508;&#31181;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(pBNNs)&#34987;&#35777;&#26126;&#19982;&#20840;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;pBNNs&#22312;&#28508;&#21464;&#37327;&#31354;&#38388;&#20013;&#24448;&#24448;&#26159;&#22810;&#23792;&#30340;&#65292;&#22240;&#27492;&#29992;&#21442;&#25968;&#27169;&#22411;&#26469;&#36817;&#20284;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#21363;&#23558;pBNN&#30340;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#24207;&#36143;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#22120;&#30340;&#21464;&#31181;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20197;&#21487;&#34892;&#30340;&#35745;&#31639;&#25104;&#26412;&#21516;&#26102;&#20272;&#35745;&#21442;&#25968;&#21644;&#35813;&#27169;&#22411;&#30340;&#28508;&#22312;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#35757;&#32451;&#26041;&#26696;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, partial Bayesian neural networks (pBNNs), which only consider a subset of the parameters to be stochastic, were shown to perform competitively with full Bayesian neural networks. However, pBNNs are often multi-modal in the latent-variable space and thus challenging to approximate with parametric models. To address this problem, we propose an efficient sampling-based training strategy, wherein the training of a pBNN is formulated as simulating a Feynman--Kac model. We then describe variations of sequential Monte Carlo samplers that allow us to simultaneously estimate the parameters and the latent posterior distribution of this model at a tractable computational cost. We show on various synthetic and real-world datasets that our proposed training scheme outperforms the state of the art in terms of predictive performance.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#27969;&#27169;&#22411;&#21644;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19253</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Flow-based Distributionally Robust Optimization. (arXiv:2310.19253v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19253
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#27969;&#27169;&#22411;&#21644;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#35201;&#27714;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#65288;&#20063;&#31216;&#20026;&#26368;&#19981;&#21033;&#20998;&#24067;&#65292;LFD&#65289;&#26159;&#36830;&#32493;&#30340;&#65292;&#20174;&#32780;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#21487;&#25193;&#23637;&#21040;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#23545;&#35825;&#23548;&#30340;&#40065;&#26834;&#31639;&#27861;&#30340;&#26356;&#22909;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#21033;&#29992;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#65292;&#22312;&#25968;&#25454;&#20998;&#24067;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#36827;&#34892;&#36830;&#32493;&#26102;&#38388;&#21487;&#36870;&#20256;&#36755;&#26144;&#23556;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36880;&#27493;&#35757;&#32451;&#22359;&#20869;&#30340;&#31070;&#32463;&#32593;&#32476;&#24207;&#21015;&#26469;&#21442;&#25968;&#21270;&#20256;&#36755;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#35745;&#31639;&#26694;&#26550;&#36890;&#29992;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#21644;&#22823;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#21487;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a computationally efficient framework, called \texttt{FlowDRO}, for solving flow-based distributionally robust optimization (DRO) problems with Wasserstein uncertainty sets, when requiring the worst-case distribution (also called the Least Favorable Distribution, LFD) to be continuous so that the algorithm can be scalable to problems with larger sample sizes and achieve better generalization capability for the induced robust algorithms. To tackle the computationally challenging infinitely dimensional optimization problem, we leverage flow-based models, continuous-time invertible transport maps between the data distribution and the target distribution, and develop a Wasserstein proximal gradient flow type of algorithm. In practice, we parameterize the transport maps by a sequence of neural networks progressively trained in blocks by gradient descent. Our computational framework is general, can handle high-dimensional data with large sample sizes, and can be useful for various
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#30340;&#22806;&#37096;&#26377;&#25928;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#39564;&#35777;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14763</link><description>&lt;p&gt;
&#22806;&#37096;&#39564;&#35777;&#31574;&#30053;&#35780;&#20272;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Externally Valid Policy Evaluation Combining Trial and Observational Data. (arXiv:2310.14763v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14763
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#30340;&#22806;&#37096;&#26377;&#25928;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#39564;&#35777;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#35797;&#39564;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#35780;&#20272;&#20915;&#31574;&#31574;&#30053;&#24433;&#21709;&#30340;&#37329; standard&#12290;&#28982;&#32780;&#65292;&#35797;&#39564;&#25968;&#25454;&#26469;&#33258;&#21487;&#33021;&#19982;&#30446;&#26631;&#20154;&#32676;&#19981;&#21516;&#30340;&#20154;&#32676;&#65292;&#36825;&#24341;&#21457;&#20102;&#22806;&#37096;&#25928;&#24230;&#65288;&#20063;&#31216;&#20026;&#27867;&#21270;&#33021;&#21147;&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#30446;&#26631;&#20154;&#32676;&#30340;&#39069;&#22806;&#21327;&#21464;&#37327;&#25968;&#25454;&#29992;&#20110;&#27169;&#25311;&#35797;&#39564;&#30740;&#31350;&#20013;&#20010;&#20307;&#30340;&#25277;&#26679;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#25351;&#23450;&#30340;&#27169;&#22411;&#26410;&#26657;&#20934;&#33539;&#22260;&#20869;&#20135;&#29983;&#21487;&#39564;&#35777;&#30340;&#22522;&#20110;&#35797;&#39564;&#30340;&#25919;&#31574;&#35780;&#20272;&#12290;&#35813;&#26041;&#27861;&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#21363;&#20351;&#26679;&#26412;&#26159;&#26377;&#38480;&#30340;&#65292;&#26377;&#25928;&#24615;&#20063;&#24471;&#21040;&#20445;&#35777;&#12290;&#20351;&#29992;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#35828;&#26126;&#20102;&#35748;&#35777;&#30340;&#25919;&#31574;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized trials are widely considered as the gold standard for evaluating the effects of decision policies. Trial data is, however, drawn from a population which may differ from the intended target population and this raises a problem of external validity (aka. generalizability). In this paper we seek to use trial data to draw valid inferences about the outcome of a policy on the target population. Additional covariate data from the target population is used to model the sampling of individuals in the trial study. We develop a method that yields certifiably valid trial-based policy evaluations under any specified range of model miscalibrations. The method is nonparametric and the validity is assured even with finite samples. The certified policy evaluations are illustrated using both simulated and real data.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#25552;&#39640;&#20102;&#33258;&#36866;&#24212;&#22312;&#32447;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#23558;&#26799;&#24230;&#26041;&#24046;&#30340;&#20381;&#36182;&#24615;&#20174;&#27425;&#20248;&#30340;$O(\sqrt{V_T\log V_T})$&#25913;&#36827;&#21040;&#26368;&#20248;&#36895;&#29575;$O(\sqrt{V_T})$&#65292;&#24182;&#21487;&#36866;&#29992;&#20110;&#26410;&#30693;Lipschitz&#24120;&#25968;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2309.16044</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#31934;&#32454;&#31163;&#25955;&#21270;&#26041;&#27861;&#25552;&#39640;&#33258;&#36866;&#24212;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improving Adaptive Online Learning Using Refined Discretization. (arXiv:2309.16044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16044
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#25552;&#39640;&#20102;&#33258;&#36866;&#24212;&#22312;&#32447;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#23558;&#26799;&#24230;&#26041;&#24046;&#30340;&#20381;&#36182;&#24615;&#20174;&#27425;&#20248;&#30340;$O(\sqrt{V_T\log V_T})$&#25913;&#36827;&#21040;&#26368;&#20248;&#36895;&#29575;$O(\sqrt{V_T})$&#65292;&#24182;&#21487;&#36866;&#29992;&#20110;&#26410;&#30693;Lipschitz&#24120;&#25968;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;Lipschitz&#25439;&#22833;&#30340;&#38750;&#32422;&#26463;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#12290;&#30446;&#26631;&#26159;&#21516;&#26102;&#36798;&#21040;&#65288;i&#65289;&#20108;&#38454;&#26799;&#24230;&#33258;&#36866;&#24212;&#24615;&#65307;&#21644;&#65288;ii&#65289;&#27604;&#36739;&#22120;&#33539;&#25968;&#33258;&#36866;&#24212;&#24615;&#65292;&#20063;&#34987;&#31216;&#20026;&#25991;&#29486;&#20013;&#30340;&#8220;&#21442;&#25968;&#33258;&#30001;&#24615;&#8221;&#12290;&#29616;&#26377;&#30340;&#36951;&#25022;&#30028;&#65288;Cutkosky&#21644;Orabona&#65292;2018&#65307;Mhammedi&#21644;Koolen&#65292;2020&#65307;Jacobsen&#21644;Cutkosky&#65292;2022&#65289;&#23545;&#20110;&#26799;&#24230;&#26041;&#24046;$V_T$&#26377;&#27425;&#20248;&#30340;$O(\sqrt{V_T\log V_T})$&#20381;&#36182;&#24615;&#65292;&#32780;&#26412;&#24037;&#20316;&#21033;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#21551;&#21457;&#24335;&#31639;&#27861;&#23558;&#20854;&#25913;&#36827;&#20026;&#26368;&#20248;&#36895;&#29575;$O(\sqrt{V_T})$&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#19981;&#20999;&#23454;&#38469;&#30340;&#21152;&#20493;&#25216;&#24039;&#12290;&#36825;&#19968;&#32467;&#26524;&#21487;&#20197;&#25512;&#24191;&#21040;&#26410;&#30693;Lipschitz&#24120;&#25968;&#30340;&#24773;&#20917;&#65292;&#28040;&#38500;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#33539;&#22260;&#27604;&#29575;&#38382;&#39064;&#65288;Mhammedi&#21644;Koolen&#65292;2020&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#38382;&#39064;&#30340;&#36830;&#32493;&#26102;&#38388;&#31867;&#27604;&#20013;&#21487;&#20197;&#30456;&#24403;&#23481;&#26131;&#22320;&#23454;&#29616;&#30446;&#26631;&#30340;&#21516;&#26102;&#36866;&#24212;&#24615;&#65292;&#20854;&#20013;&#29615;&#22659;&#30001;&#20219;&#24847;&#36830;&#32493;&#21322;&#38808;&#24335;&#24314;&#27169;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30340;&#20851;&#38190;&#21019;&#26032;&#26159;
&lt;/p&gt;
&lt;p&gt;
We study unconstrained Online Linear Optimization with Lipschitz losses. The goal is to simultaneously achieve ($i$) second order gradient adaptivity; and ($ii$) comparator norm adaptivity also known as "parameter freeness" in the literature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and Koolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\sqrt{V_T\log V_T})$ dependence on the gradient variance $V_T$, while the present work improves it to the optimal rate $O(\sqrt{V_T})$ using a novel continuous-time-inspired algorithm, without any impractical doubling trick. This result can be extended to the setting with unknown Lipschitz constant, eliminating the range ratio problem from prior works (Mhammedi and Koolen, 2020).  Concretely, we first show that the aimed simultaneous adaptivity can be achieved fairly easily in a continuous time analogue of the problem, where the environment is modeled by an arbitrary continuous semimartingale. Then, our key innovation 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#20197;&#20960;&#20309;&#36895;&#24230;&#25910;&#25947;&#65292;&#20026;BBVI&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#23545;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25913;&#36827;&#65292;&#23545;&#27604;&#20102;STL&#20272;&#35745;&#22120;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.14642</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65306;&#25105;&#20204;&#24212;&#35813;&#22362;&#25345;&#21040;&#24213;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#20197;&#20960;&#20309;&#36895;&#24230;&#25910;&#25947;&#65292;&#20026;BBVI&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#23545;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25913;&#36827;&#65292;&#23545;&#27604;&#20102;STL&#20272;&#35745;&#22120;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#65292;&#29305;&#21035;&#26159;&#30528;&#38470;&#31283;&#23450;&#65288;STL&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#25910;&#25947;&#20110;&#20960;&#20309;&#65288;&#20256;&#32479;&#19978;&#31216;&#20026;&#8220;&#32447;&#24615;&#8221;&#65289;&#36895;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;STL&#20272;&#35745;&#22120;&#30340;&#26799;&#24230;&#26041;&#24046;&#30340;&#20108;&#27425;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#21253;&#25324;&#20102;&#35823;&#25351;&#23450;&#30340;&#21464;&#20998;&#26063;&#12290;&#32467;&#21512;&#20808;&#21069;&#20851;&#20110;&#20108;&#27425;&#26041;&#24046;&#26465;&#20214;&#30340;&#24037;&#20316;&#65292;&#36825;&#30452;&#25509;&#26263;&#31034;&#20102;&#22312;&#20351;&#29992;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24773;&#20917;&#19979;BBVI&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#25913;&#36827;&#20102;&#29616;&#26377;&#23545;&#20110;&#27491;&#24120;&#23553;&#38381;&#24418;&#24335;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#20998;&#26512;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23558;&#20854;&#19982;STL&#20272;&#35745;&#22120;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#20026;&#20004;&#32773;&#25552;&#20379;&#26126;&#30830;&#30340;&#38750;&#28176;&#36827;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called "linear") rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator and provides explicit non-asymptotic complexity guarantees for both.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#21161;&#32858;&#21512;&#21644;&#32622;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#20351;&#24471;&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;&#33021;&#22815;&#25552;&#20379;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#24230;&#37327;&#12290;&#22312;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#22240;&#26524;&#21457;&#29616;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.08946</link><description>&lt;p&gt;
&#33258;&#21161;&#32858;&#21512;&#21644;&#32622;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#29992;&#20110;&#25913;&#36827;&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Bootstrap aggregation and confidence measures to improve time series causal discovery. (arXiv:2306.08946v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#21161;&#32858;&#21512;&#21644;&#32622;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#20351;&#24471;&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;&#33021;&#22815;&#25552;&#20379;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#24230;&#37327;&#12290;&#22312;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#22240;&#26524;&#21457;&#29616;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#24050;&#32463;&#23637;&#31034;&#20102;&#35782;&#21035;&#34920;&#31034;&#21160;&#24577;&#31995;&#32479;&#30340;&#22240;&#26524;&#26102;&#38388;&#20381;&#36182;&#32467;&#26500;&#30340;&#26102;&#24207;&#22270;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#19981;&#21253;&#25324;&#23545;&#20272;&#35745;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#30340;&#27979;&#37327;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#21161;&#32858;&#21512;&#65288;Bagging&#65289;&#21644;&#32622;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#23427;&#19982;&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;&#30456;&#32467;&#21512;&#12290;&#35813;&#26041;&#27861;&#20801;&#35768;&#36890;&#36807;&#22312;&#20445;&#30041;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#23545;&#21407;&#22987;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#36827;&#34892;&#33258;&#21161;&#37325;&#37319;&#26679;&#26469;&#27979;&#37327;&#30001;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#35745;&#31639;&#20986;&#30340;&#26102;&#24207;&#22270;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#12290;&#38500;&#20102;&#32622;&#20449;&#24230;&#37327;&#65292;&#32858;&#21512;&#24341;&#23548;&#22270;&#36890;&#36807;&#22810;&#25968;&#25237;&#31080;&#24471;&#20986;&#26368;&#32456;&#32858;&#21512;&#36755;&#20986;&#22270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26465;&#20214;&#29420;&#31435;&#24615;&#31639;&#27861;PCMCI+&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#23454;&#39564;&#24615;&#22320;&#23637;&#31034;&#20102;Bagged-PCMCI+&#38500;&#20102;&#25552;&#20379;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#24230;&#37327;&#22806;&#65292;&#36824;&#21487;&#20197;&#25552;&#39640;&#22240;&#26524;&#21457;&#29616;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery methods have demonstrated the ability to identify the time series graphs representing the causal temporal dependency structure of dynamical systems. However, they do not include a measure of the confidence of the estimated links. Here, we introduce a novel bootstrap aggregation (bagging) and confidence measure method that is combined with time series causal discovery. This new method allows measuring confidence for the links of the time series graphs calculated by causal discovery methods. This is done by bootstrapping the original times series data set while preserving temporal dependencies. Next to confidence measures, aggregating the bootstrapped graphs by majority voting yields a final aggregated output graph. In this work, we combine our approach with the state-of-the-art conditional-independence-based algorithm PCMCI+. With extensive numerical experiments we empirically demonstrate that, in addition to providing confidence measures for links, Bagged-PCMCI+ improv
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;cSOBER&#65292;&#19968;&#31181;&#22788;&#29702;&#22810;&#26679;&#21270;&#32422;&#26463;&#26465;&#20214;&#12289;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#12289;&#26410;&#30693;&#32422;&#26463;&#20197;&#21450;&#26597;&#35810;&#25298;&#32477;&#38382;&#39064;&#30340;&#39046;&#22495;&#26080;&#20851;&#22411;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05843</link><description>&lt;p&gt;
&#26080;&#39046;&#22495;&#20559;&#35265;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#31215;&#20998;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;
Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via Bayesian Quadrature. (arXiv:2306.05843v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;cSOBER&#65292;&#19968;&#31181;&#22788;&#29702;&#22810;&#26679;&#21270;&#32422;&#26463;&#26465;&#20214;&#12289;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#12289;&#26410;&#30693;&#32422;&#26463;&#20197;&#21450;&#26597;&#35810;&#25298;&#32477;&#38382;&#39064;&#30340;&#39046;&#22495;&#26080;&#20851;&#22411;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#30340;&#20248;&#21270;&#38382;&#39064;&#36890;&#24120;&#20855;&#26377;&#22810;&#26679;&#30340;&#32422;&#26463;&#26465;&#20214;&#12289;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#12289;&#39640;&#24230;&#21487;&#24182;&#34892;&#21270;&#31561;&#29305;&#28857;&#12290;&#21516;&#26102;&#65292;&#24403;&#23384;&#22312;&#26410;&#30693;&#32422;&#26463;&#26102;&#65292;&#20363;&#22914;&#22312;&#33647;&#29289;&#21457;&#29616;&#21644;&#21160;&#29289;&#23454;&#39564;&#23433;&#20840;&#24615;&#31561;&#39046;&#22495;&#65292;&#24517;&#39035;&#30830;&#31435;&#26410;&#30693;&#32422;&#26463;&#20043;&#21518;&#25165;&#33021;&#26597;&#35810;&#30446;&#26631;&#20989;&#25968;&#12290;&#29616;&#26377;&#24037;&#20316;&#36890;&#24120;&#20165;&#38024;&#23545;&#19978;&#36848;&#26576;&#20123;&#29305;&#24449;&#32780;&#24182;&#38750;&#32508;&#21512;&#32771;&#34385;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;cSOBER&#65292;&#19968;&#31181;&#22522;&#20110;SOBER&#31639;&#27861;&#30340;&#39046;&#22495;&#26080;&#20851;&#22411;&#35880;&#24910;&#24182;&#34892;&#20027;&#21160;&#37319;&#26679;&#22120;&#65292;&#32771;&#34385;&#21040;&#20102;&#26410;&#30693;&#32422;&#26463;&#24773;&#20917;&#19979;&#30340;&#38598;&#25104;&#35823;&#24046;&#30340;&#24433;&#21709;&#24182;&#25552;&#20986;&#20102;&#22788;&#29702;&#26041;&#27861;&#65292;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#26465;&#20214;&#21644;&#26410;&#30693;&#32422;&#26463;&#26597;&#35810;&#25298;&#32477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world optimisation problems often feature complex combinations of (1) diverse constraints, (2) discrete and mixed spaces, and are (3) highly parallelisable. (4) There are also cases where the objective function cannot be queried if unknown constraints are not satisfied, e.g. in drug discovery, safety on animal experiments (unknown constraints) must be established before human clinical trials (querying objective function) may proceed. However, most existing works target each of the above three problems in isolation and do not consider (4) unknown constraints with query rejection. For problems with diverse constraints and/or unconventional input spaces, it is difficult to apply these techniques as they are often mutually incompatible. We propose cSOBER, a domain-agnostic prudent parallel active sampler for Bayesian optimisation, based on SOBER of Adachi et al. (2023). We consider infeasibility under unknown constraints as a type of integration error that we can estimate. We propose 
&lt;/p&gt;</description></item><item><title>&#32858;&#21512;&#21464;&#37327;&#19978;&#30340;&#22240;&#26524;&#24615;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20250;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#30340;&#20107;&#23454;&#12290;</title><link>http://arxiv.org/abs/2304.11625</link><description>&lt;p&gt;
&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#32858;&#21512;&#21644;&#24726;&#35770;&#24615;&#28151;&#28102;
&lt;/p&gt;
&lt;p&gt;
Meaningful Causal Aggregation and Paradoxical Confounding. (arXiv:2304.11625v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11625
&lt;/p&gt;
&lt;p&gt;
&#32858;&#21512;&#21464;&#37327;&#19978;&#30340;&#22240;&#26524;&#24615;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20250;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#30340;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32858;&#21512;&#21464;&#37327;&#20013;&#65292;&#24178;&#39044;&#30340;&#24433;&#21709;&#36890;&#24120;&#26159;&#19981;&#30830;&#23450;&#30340;&#65292;&#22240;&#20026;&#30456;&#21516;&#30340;&#23439;&#35266;&#24178;&#39044;&#30340;&#19981;&#21516;&#24494;&#35266;&#23454;&#29616;&#21487;&#33021;&#20250;&#23548;&#33268;&#19979;&#28216;&#23439;&#35266;&#21464;&#37327;&#30340;&#19981;&#21516;&#21464;&#21270;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23545;&#20110;&#32858;&#21512;&#21464;&#37327;&#65292;&#22240;&#26524;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#24182;&#19988;&#21453;&#20043;&#20134;&#28982;&#65292;&#36825;&#19968;&#28857;&#21462;&#20915;&#20110;&#30456;&#24212;&#30340;&#24494;&#35266;&#23454;&#29616;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#21482;&#26377;&#22312;&#32858;&#21512;&#22240;&#26524;&#31995;&#32479;&#27809;&#26377;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25165;&#21487;&#20197;&#23454;&#38469;&#24212;&#29992;&#36825;&#31181;&#26041;&#27861;&#12290;&#21542;&#21017;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#19968;&#28857;&#65292;&#23601;&#26159;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#12290;&#22312;&#31215;&#26497;&#26041;&#38754;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#23439;&#35266;&#24178;&#39044;&#30340;&#20998;&#24067;&#19982;&#35266;&#27979;&#20998;&#24067;&#20013;&#24494;&#35266;&#29366;&#24577;&#30340;&#20998;&#24067;&#30456;&#21516;&#26102;&#65292;&#22240;&#26524;&#20851;&#31995;&#21487;&#20197;&#36827;&#34892;&#32858;&#21512;&#65292;&#24182;&#35752;&#35770;&#20102;&#27492;&#35266;&#23519;&#30340;&#27010;&#25324;&#12290;
&lt;/p&gt;
&lt;p&gt;
In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness. Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution and also discuss generalizations of this observation.
&lt;/p&gt;</description></item><item><title>&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(IBNNs)&#12290;&#36825;&#31181;&#31639;&#27861;&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#38598;&#21512;&#21644;&#20284;&#28982;&#20998;&#24067;&#38598;&#21512;&#36827;&#34892;&#35757;&#32451;&#65292;&#30456;&#27604;&#26631;&#20934;&#30340;BNNs&#65292;&#21487;&#20197;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#20063;&#26356;&#21152;&#40065;&#26834;&#12290;</title><link>http://arxiv.org/abs/2302.09656</link><description>&lt;p&gt;
&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Imprecise Bayesian Neural Networks. (arXiv:2302.09656v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09656
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(IBNNs)&#12290;&#36825;&#31181;&#31639;&#27861;&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#38598;&#21512;&#21644;&#20284;&#28982;&#20998;&#24067;&#38598;&#21512;&#36827;&#34892;&#35757;&#32451;&#65292;&#30456;&#27604;&#26631;&#20934;&#30340;BNNs&#65292;&#21487;&#20197;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#20063;&#26356;&#21152;&#40065;&#26834;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20013;, &#30830;&#23450;&#19981;&#30830;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#26159;&#37325;&#35201;&#30340;&#30446;&#26631;&#12290;&#34429;&#28982;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20351;&#24471;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#33021;&#22815;&#34987;&#35780;&#20272;&#65292;&#19981;&#21516;&#26469;&#28304;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#26080;&#27861;&#21306;&#20998;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;IBNNs&#65289;&#65292;&#23427;&#20204;&#21487;&#20197;&#27010;&#25324;&#21644;&#20811;&#26381;&#26631;&#20934;BNNs&#30340;&#26576;&#20123;&#32570;&#28857;&#12290;&#26631;&#20934;BNNs&#20351;&#29992;&#21333;&#19968;&#30340;&#20808;&#39564;&#20998;&#24067;&#21644;&#20284;&#28982;&#20998;&#24067;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;IBNNs&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#21644;&#20284;&#28982;&#20998;&#24067;&#36827;&#34892;&#35757;&#32451;&#12290;&#23427;&#20204;&#20801;&#35768;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#27604;&#26631;&#20934;BNNs&#26356;&#21152;&#40065;&#26834;&#12290;&#23427;&#20204;&#36824;&#21487;&#20197;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;PAC&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#32467;&#26524;&#38598;&#12290;&#25105;&#20204;&#23558;IBNNs&#24212;&#29992;&#20110;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#65306;&#19968;&#20010;&#26159;&#20026;&#20102;&#20154;&#24037;&#33008;&#33146;&#25511;&#21046;&#27169;&#25311;&#34880;&#31958;&#21644;&#33008;&#23707;&#32032;&#21160;&#21147;&#23398;&#65292;&#21478;&#19968;&#20010;&#26159;&#36816;&#21160;&#35268;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification and robustness to distribution shifts are important goals in machine learning and artificial intelligence. Although Bayesian neural networks (BNNs) allow for uncertainty in the predictions to be assessed, different sources of uncertainty are indistinguishable. We present imprecise Bayesian neural networks (IBNNs); they generalize and overcome some of the drawbacks of standard BNNs. These latter are trained using a single prior and likelihood distributions, whereas IBNNs are trained using credal prior and likelihood sets. They allow to distinguish between aleatoric and epistemic uncertainties, and to quantify them. In addition, IBNNs are robust in the sense of Bayesian sensitivity analysis, and are more robust than BNNs to distribution shift. They can also be used to compute sets of outcomes that enjoy PAC-like properties. We apply IBNNs to two case studies. One, to model blood glucose and insulin dynamics for artificial pancreas control, and two, for motion p
&lt;/p&gt;</description></item></channel></rss>