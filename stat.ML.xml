<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20146;&#21644;&#24230;&#35780;&#20998;&#36861;&#36394;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38750;&#32447;&#24615;&#20256;&#25773;&#65292;&#23588;&#20854;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#23545;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.11439</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#32447;&#24615;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Understanding deep neural networks through the lens of their non-linearity. (arXiv:2310.11439v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11439
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20146;&#21644;&#24230;&#35780;&#20998;&#36861;&#36394;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38750;&#32447;&#24615;&#20256;&#25773;&#65292;&#23588;&#20854;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#23545;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#30340;&#26174;&#33879;&#25104;&#21151;&#24120;&#24120;&#24402;&#22240;&#20110;&#23427;&#20204;&#30340;&#39640;&#34920;&#36798;&#33021;&#21147;&#21644;&#36817;&#20284;&#20219;&#24847;&#22797;&#26434;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#20107;&#23454;&#19978;&#65292;DNN&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#24341;&#20837;&#30340;&#28608;&#27963;&#20989;&#25968;&#22312;&#20854;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#36817;&#20284;&#33021;&#21147;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;DNN&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#37327;&#21270;DNN&#25110;&#20010;&#21035;&#28608;&#27963;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#20855;&#20307;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#20013;&#36861;&#36394;&#38750;&#32447;&#24615;&#20256;&#25773;&#30340;&#29702;&#35770;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20146;&#21644;&#24230;&#35780;&#20998;&#20801;&#35768;&#25105;&#20204;&#28145;&#20837;&#20102;&#35299;&#21508;&#31181;&#19981;&#21516;&#20307;&#31995;&#32467;&#26500;&#21644;&#23398;&#20064;&#33539;&#24335;&#30340;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#31361;&#20986;&#20102;&#25152;&#25552;&#20986;&#30340;&#20146;&#21644;&#24230;&#35780;&#20998;&#30340;&#23454;&#38469;&#25928;&#29992;&#21644;&#28508;&#22312;&#24212;&#29992;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable success of deep neural networks (DNN) is often attributed to their high expressive power and their ability to approximate functions of arbitrary complexity. Indeed, DNNs are highly non-linear models, and activation functions introduced into them are largely responsible for this. While many works studied the expressive power of DNNs through the lens of their approximation capabilities, quantifying the non-linearity of DNNs or of individual activation functions remains an open problem. In this paper, we propose the first theoretically sound solution to track non-linearity propagation in deep neural networks with a specific focus on computer vision applications. Our proposed affinity score allows us to gain insights into the inner workings of a wide range of different architectures and learning paradigms. We provide extensive experimental results that highlight the practical utility of the proposed affinity score and its potential for long-reaching applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#21270;&#35270;&#35273;&#21487;&#35299;&#37322;&#24615;&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#24182;&#25214;&#21040;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#24847;&#20041;&#30340;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2310.11431</link><description>&lt;p&gt;
&#22312;&#20154;&#24037;&#21644;&#29983;&#29289;&#31070;&#32463;&#31995;&#32479;&#20013;&#35782;&#21035;&#21487;&#35299;&#37322;&#30340;&#35270;&#35273;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Identifying Interpretable Visual Features in Artificial and Biological Neural Systems. (arXiv:2310.11431v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#21270;&#35270;&#35273;&#21487;&#35299;&#37322;&#24615;&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#24182;&#25214;&#21040;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#24847;&#20041;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21333;&#20010;&#31070;&#32463;&#20803;&#36890;&#24120;&#26159;&#8220;&#21487;&#35299;&#37322;&#30340;&#8221;&#65292;&#22240;&#20026;&#23427;&#20204;&#20195;&#34920;&#20010;&#21035;&#30452;&#35266;&#26377;&#24847;&#20041;&#30340;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#31070;&#32463;&#20803;&#34920;&#29616;&#20986;&#8220;&#28151;&#21512;&#36873;&#25321;&#24615;&#8221;&#65292;&#21363;&#23427;&#20204;&#20195;&#34920;&#22810;&#20010;&#19981;&#30456;&#20851;&#30340;&#29305;&#24449;&#12290;&#26368;&#36817;&#30340;&#20551;&#35774;&#35748;&#20026;&#65292;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#21487;&#33021;&#20197;&#8220;&#21472;&#21152;&#8221;&#30340;&#26041;&#24335;&#34920;&#31034;&#65292;&#21363;&#30001;&#22810;&#20010;&#31070;&#32463;&#20803;&#27839;&#38750;&#27491;&#20132;&#36724;&#34920;&#31034;&#65292;&#22240;&#20026;&#33258;&#28982;&#25968;&#25454;&#20013;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#25968;&#36890;&#24120;&#22823;&#20110;&#32473;&#23450;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#20803;&#25968;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24212;&#35813;&#33021;&#22815;&#22312;&#28608;&#27963;&#31354;&#38388;&#20013;&#25214;&#21040;&#19982;&#20010;&#21035;&#31070;&#32463;&#20803;&#19981;&#23545;&#40784;&#30340;&#26377;&#24847;&#20041;&#30340;&#26041;&#21521;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#65288;1&#65289;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26041;&#27861;&#26469;&#37327;&#21270;&#35270;&#35273;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#36890;&#36807;&#19982;&#22823;&#37327;&#20154;&#31867;&#24515;&#29702;&#29289;&#29702;&#23398;&#23545;&#31070;&#32463;&#20803;&#21487;&#35299;&#37322;&#24615;&#30340;&#21028;&#26029;&#36827;&#34892;&#39564;&#35777;&#65292;&#20197;&#21450;&#65288;2&#65289;&#19968;&#31181;&#22312;&#32593;&#32476;&#28608;&#27963;&#31354;&#38388;&#20013;&#23547;&#25214;&#26377;&#24847;&#20041;&#26041;&#21521;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#21457;&#29616;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Single neurons in neural networks are often ``interpretable'' in that they represent individual, intuitively meaningful features. However, many neurons exhibit $\textit{mixed selectivity}$, i.e., they represent multiple unrelated features. A recent hypothesis proposes that features in deep networks may be represented in $\textit{superposition}$, i.e., on non-orthogonal axes by multiple neurons, since the number of possible interpretable features in natural data is generally larger than the number of neurons in a given network. Accordingly, we should be able to find meaningful directions in activation space that are not aligned with individual neurons. Here, we propose (1) an automated method for quantifying visual interpretability that is validated against a large database of human psychophysics judgments of neuron interpretability, and (2) an approach for finding meaningful directions in network activation space. We leverage these methods to discover directions in convolutional neural
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#31350;&#20102;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#34892;&#20026;&#20811;&#38534;&#35757;&#32451;&#26102;&#20986;&#29616;&#30340;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#29616;&#35937;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#23567;&#25209;&#37327;SGD&#26356;&#26032;&#23545;&#20110;&#34892;&#20026;&#20811;&#38534;&#25439;&#22833;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#65292;&#20294;&#23427;&#20250;&#23548;&#33268;&#38271;&#26399;&#22870;&#21169;&#30340;&#21095;&#28872;&#25391;&#33633;&#12290;&#25105;&#20204;&#31216;&#36825;&#31181;&#25928;&#24212;&#20026;&#26799;&#24230;&#26041;&#24046;&#25918;&#22823;&#65288;GVA&#65289;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65288;EMA&#65289;&#21487;&#20197;&#26377;&#25928;&#20943;&#32531;&#36825;&#31181;&#25928;&#24212;&#12290;&#36825;&#19968;&#29616;&#35937;&#22312;&#36830;&#32493;&#25511;&#21046;&#21644;&#33258;&#22238;&#24402;&#31561;&#39046;&#22495;&#20855;&#26377;&#26222;&#36941;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.11428</link><description>&lt;p&gt;
SGD&#22122;&#22768;&#30340;&#34676;&#34678;&#25928;&#24212;&#65306;&#34892;&#20026;&#20811;&#38534;&#21644;&#33258;&#22238;&#24402;&#20013;&#30340;&#35823;&#24046;&#25918;&#22823;
&lt;/p&gt;
&lt;p&gt;
Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning and Autoregression. (arXiv:2310.11428v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11428
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#31350;&#20102;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#34892;&#20026;&#20811;&#38534;&#35757;&#32451;&#26102;&#20986;&#29616;&#30340;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#29616;&#35937;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#23567;&#25209;&#37327;SGD&#26356;&#26032;&#23545;&#20110;&#34892;&#20026;&#20811;&#38534;&#25439;&#22833;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#65292;&#20294;&#23427;&#20250;&#23548;&#33268;&#38271;&#26399;&#22870;&#21169;&#30340;&#21095;&#28872;&#25391;&#33633;&#12290;&#25105;&#20204;&#31216;&#36825;&#31181;&#25928;&#24212;&#20026;&#26799;&#24230;&#26041;&#24046;&#25918;&#22823;&#65288;GVA&#65289;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65288;EMA&#65289;&#21487;&#20197;&#26377;&#25928;&#20943;&#32531;&#36825;&#31181;&#25928;&#24212;&#12290;&#36825;&#19968;&#29616;&#35937;&#22312;&#36830;&#32493;&#25511;&#21046;&#21644;&#33258;&#22238;&#24402;&#31561;&#39046;&#22495;&#20855;&#26377;&#26222;&#36941;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#34892;&#20026;&#20811;&#38534;&#30340;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#23613;&#31649;&#23545;&#20110;&#34892;&#20026;&#20811;&#38534;&#25439;&#22833;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#65292;&#20294;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#23545;&#31574;&#30053;&#32593;&#32476;&#30340;&#23567;&#25209;&#37327;SGD&#26356;&#26032;&#23548;&#33268;&#20102;&#38271;&#26399;&#22870;&#21169;&#30340;&#21095;&#28872;&#25391;&#33633;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#25391;&#33633;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#21407;&#22240;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#28304;&#20110;&#23567;&#25209;&#37327;SGD&#22122;&#22768;&#22312;&#19981;&#31283;&#23450;&#30340;&#38381;&#29615;&#21160;&#21147;&#23398;&#20013;&#30340;&#28151;&#27788;&#20256;&#25773;&#12290;&#34429;&#28982;SGD&#22122;&#22768;&#23545;&#20110;&#21333;&#27493;&#21160;&#20316;&#39044;&#27979;&#30446;&#26631;&#26159;&#26080;&#23475;&#30340;&#65292;&#20294;&#22312;&#38271;&#26399;&#35270;&#37326;&#19978;&#23427;&#23548;&#33268;&#20102;&#28798;&#38590;&#24615;&#30340;&#35823;&#24046;&#32047;&#31215;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#26799;&#24230;&#26041;&#24046;&#25918;&#22823;&#65288;GVA&#65289;&#25928;&#24212;&#12290;&#25105;&#20204;&#21457;&#29616;&#35768;&#22810;&#26631;&#20934;&#30340;&#32531;&#35299;&#25216;&#26415;&#19981;&#33021;&#32531;&#35299;GVA&#65292;&#20294;&#26159;&#21457;&#29616;&#36845;&#20195;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65288;EMA&#65289;&#22312;&#32531;&#35299;GVA&#26041;&#38754;&#38750;&#24120;&#26377;&#25928;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#36830;&#32493;&#25511;&#21046;&#21644;&#33258;&#22238;&#24402;&#20013;GVA&#30340;&#23384;&#22312;&#20197;&#21450;EMA&#20943;&#32531;GVA&#30340;&#24773;&#20917;&#65292;&#35828;&#26126;&#20102;&#36825;&#19968;&#29616;&#35937;&#30340;&#26222;&#36941;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies training instabilities of behavior cloning with deep neural networks. We observe that minibatch SGD updates to the policy network during training result in sharp oscillations in long-horizon rewards, despite negligibly affecting the behavior cloning loss. We empirically disentangle the statistical and computational causes of these oscillations, and find them to stem from the chaotic propagation of minibatch SGD noise through unstable closed-loop dynamics. While SGD noise is benign in the single-step action prediction objective, it results in catastrophic error accumulation over long horizons, an effect we term gradient variance amplification (GVA). We show that many standard mitigation techniques do not alleviate GVA, but find an exponential moving average (EMA) of iterates to be surprisingly effective at doing so. We illustrate the generality of this phenomenon by showing the existence of GVA and its amelioration by EMA in both continuous control and autoregressive l
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#26356;&#24555;&#36895;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#24191;&#20041;&#24179;&#22343;&#23494;&#38598;&#23376;&#22270;&#38382;&#39064;&#65292;&#20854;&#20013;&#23545;&#20110;$0&lt;p&lt;1$&#30340;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#21093;&#31163;&#31639;&#27861;&#21487;&#20197;&#24471;&#21040;$2^{1/p}$&#30340;&#36817;&#20284;&#35299;&#12290;&#21478;&#22806;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24191;&#20041;&#21093;&#31163;&#31639;&#27861;&#65288;GENPEEL&#65289;&#65292;&#23545;&#20110;$p \geq 1$&#65292;&#20854;&#36817;&#20284;&#20445;&#35777;&#29575;&#20026;$(p+1)^{1/p}$&#12290;</title><link>http://arxiv.org/abs/2310.11377</link><description>&lt;p&gt;
&#26356;&#24555;&#30340;&#24191;&#20041;&#24179;&#22343;&#23494;&#38598;&#23376;&#22270;&#38382;&#39064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Faster Algorithms for Generalized Mean Densest Subgraph Problem. (arXiv:2310.11377v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11377
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#26356;&#24555;&#36895;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#24191;&#20041;&#24179;&#22343;&#23494;&#38598;&#23376;&#22270;&#38382;&#39064;&#65292;&#20854;&#20013;&#23545;&#20110;$0&lt;p&lt;1$&#30340;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#21093;&#31163;&#31639;&#27861;&#21487;&#20197;&#24471;&#21040;$2^{1/p}$&#30340;&#36817;&#20284;&#35299;&#12290;&#21478;&#22806;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24191;&#20041;&#21093;&#31163;&#31639;&#27861;&#65288;GENPEEL&#65289;&#65292;&#23545;&#20110;$p \geq 1$&#65292;&#20854;&#36817;&#20284;&#20445;&#35777;&#29575;&#20026;$(p+1)^{1/p}$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22270;&#30340;&#26368;&#23494;&#23376;&#22270;&#36890;&#24120;&#25351;&#30340;&#26159;&#20855;&#26377;&#26368;&#39640;&#24179;&#22343;&#24230;&#30340;&#19968;&#20123;&#23376;&#22270;&#65292;&#36825;&#24050;&#32463;&#34987;Veldt&#31561;&#20154;&#25193;&#23637;&#21040;&#20102;$p$-&#24179;&#22343;&#23494;&#38598;&#23376;&#22270;&#30446;&#26631;&#30340;&#23478;&#26063;&#19978;&#12290;$p$-&#24179;&#22343;&#23494;&#38598;&#23376;&#22270;&#38382;&#39064;&#23547;&#25214;&#20855;&#26377;&#26368;&#39640;&#24179;&#22343;$p$&#27425;&#24130;&#24230;&#30340;&#23376;&#22270;&#65292;&#32780;&#26631;&#20934;&#26368;&#23494;&#23376;&#22270;&#38382;&#39064;&#23547;&#25214;&#20855;&#26377;&#26368;&#39640;&#24179;&#22343;&#24230;&#30340;&#23376;&#22270;&#12290;&#24050;&#32463;&#35777;&#26126;&#20102;&#24403;$p&gt;1$&#26102;&#65292;&#26631;&#20934;&#21093;&#31163;&#31639;&#27861;&#22312;&#24191;&#20041;&#30446;&#26631;&#19978;&#21487;&#20197;&#34920;&#29616;&#24471;&#20219;&#24847;&#24046;&#65292;&#20294;&#24403;$0&lt;p&lt;1$&#26102;&#19981;&#30830;&#23450;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#35777;&#26126;&#20102;&#26631;&#20934;&#21093;&#31163;&#31639;&#27861;&#22312;$0&lt;p&lt;1$&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#21487;&#20197;&#24471;&#21040;$2^{1/p}$&#30340;&#36817;&#20284;&#35299;&#12290;Veldt&#31561;&#20154;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24191;&#20041;&#21093;&#31163;&#31639;&#27861;&#65288;GENPEEL&#65289;&#65292;&#23545;&#20110;$p \geq 1$&#65292;&#20854;&#36817;&#20284;&#20445;&#35777;&#29575;&#20026;$(p+1)^{1/p}$&#65292;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;$O(mn)$&#65292;&#20854;&#20013;$m$&#21644;$n$&#20998;&#21035;&#34920;&#31034;&#22270;&#20013;&#30340;&#36793;&#25968;&#21644;&#33410;&#28857;&#25968;&#12290;&#22312;&#31639;&#27861;&#36129;&#29486;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The densest subgraph of a large graph usually refers to some subgraph with the highest average degree, which has been extended to the family of $p$-means dense subgraph objectives by~\citet{veldt2021generalized}. The $p$-mean densest subgraph problem seeks a subgraph with the highest average $p$-th-power degree, whereas the standard densest subgraph problem seeks a subgraph with a simple highest average degree. It was shown that the standard peeling algorithm can perform arbitrarily poorly on generalized objective when $p&gt;1$ but uncertain when $0&lt;p&lt;1$. In this paper, we are the first to show that a standard peeling algorithm can still yield $2^{1/p}$-approximation for the case $0&lt;p &lt; 1$. (Veldt 2021) proposed a new generalized peeling algorithm (GENPEEL), which for $p \geq 1$ has an approximation guarantee ratio $(p+1)^{1/p}$, and time complexity $O(mn)$, where $m$ and $n$ denote the number of edges and nodes in graph respectively. In terms of algorithmic contributions, we propose a ne
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Lie&#32676;&#32467;&#26500;&#21644;&#20960;&#20309;&#29305;&#24615;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#38750;&#32039;&#33268;&#38750;&#38463;&#36125;&#23572;&#30340;Lie&#32676;&#65292;&#29305;&#21035;&#20851;&#27880;&#20110;$\text{GL}^{+}(n, \mathbb{R})$&#21644;$\text{SL}(n, \mathbb{R})$&#36825;&#20004;&#20010;Lie&#32676;&#12290;</title><link>http://arxiv.org/abs/2310.11366</link><description>&lt;p&gt;
Lie Group Decompositions for Equivariant Neural Networks. (arXiv:2310.11366v1 [cs.LG]) (&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;Lie&#32676;&#20998;&#35299;)
&lt;/p&gt;
&lt;p&gt;
Lie Group Decompositions for Equivariant Neural Networks. (arXiv:2310.11366v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Lie&#32676;&#32467;&#26500;&#21644;&#20960;&#20309;&#29305;&#24615;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#38750;&#32039;&#33268;&#38750;&#38463;&#36125;&#23572;&#30340;Lie&#32676;&#65292;&#29305;&#21035;&#20851;&#27880;&#20110;$\text{GL}^{+}(n, \mathbb{R})$&#21644;$\text{SL}(n, \mathbb{R})$&#36825;&#20004;&#20010;Lie&#32676;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#65288;&#21367;&#31215;&#65289;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26102;&#65292;&#23545;&#20960;&#20309;&#21464;&#25442;&#30340;&#19981;&#21464;&#24615;&#21644;&#31561;&#21464;&#24615;&#34987;&#35777;&#26126;&#26159;&#38750;&#24120;&#26377;&#29992;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#19979;&#12290;&#22823;&#37096;&#20998;&#30740;&#31350;&#38598;&#20013;&#22312;&#20351;&#29992;&#30340;&#23545;&#31216;&#32676;&#20026;&#32039;&#33268;&#25110;&#38463;&#36125;&#23572;&#32676;&#65292;&#25110;&#32773;&#20004;&#32773;&#37117;&#26159;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25299;&#23637;&#20102;&#20351;&#29992;&#30340;&#21464;&#25442;&#31867;&#21035;&#21040;Lie&#32676;&#30340;&#24773;&#20917;&#65292;&#20027;&#35201;&#36890;&#36807;&#20351;&#29992;&#20854;Lie&#20195;&#25968;&#20197;&#21450;&#32676;&#30340;&#25351;&#25968;&#21644;&#23545;&#25968;&#26144;&#23556;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#26041;&#27861;&#22312;&#36866;&#29992;&#20110;&#26356;&#22823;&#30340;&#21464;&#25442;&#32676;&#26102;&#21463;&#21040;&#38480;&#21046;&#65292;&#22240;&#20026;&#26681;&#25454;&#25152;&#20851;&#24515;&#30340;&#32676;$G$&#30340;&#19981;&#21516;&#65292;&#25351;&#25968;&#26144;&#23556;&#21487;&#33021;&#19981;&#28385;&#23556;&#12290;&#24403;$G$&#26082;&#19981;&#26159;&#32039;&#33268;&#32676;&#20063;&#19981;&#26159;&#38463;&#36125;&#23572;&#32676;&#26102;&#65292;&#36824;&#20250;&#36935;&#21040;&#36827;&#19968;&#27493;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#21033;&#29992;Lie&#32676;&#21450;&#20854;&#40784;&#27425;&#31354;&#38388;&#30340;&#32467;&#26500;&#21644;&#20960;&#20309;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#22788;&#29702;&#36825;&#31867;&#32676;&#30340;&#26694;&#26550;&#65292;&#20027;&#35201;&#20851;&#27880;Lie&#32676;$G = \text{GL}^{+}(n, \mathbb{R})$&#21644;$G = \text{SL}(n, \mathbb{R}$&#12290;
&lt;/p&gt;
&lt;p&gt;
Invariance and equivariance to geometrical transformations have proven to be very useful inductive biases when training (convolutional) neural network models, especially in the low-data regime. Much work has focused on the case where the symmetry group employed is compact or abelian, or both. Recent work has explored enlarging the class of transformations used to the case of Lie groups, principally through the use of their Lie algebra, as well as the group exponential and logarithm maps. The applicability of such methods to larger transformation groups is limited by the fact that depending on the group of interest $G$, the exponential map may not be surjective. Further limitations are encountered when $G$ is neither compact nor abelian. Using the structure and geometry of Lie groups and their homogeneous spaces, we present a framework by which it is possible to work with such groups primarily focusing on the Lie groups $G = \text{GL}^{+}(n, \mathbb{R})$ and $G = \text{SL}(n, \mathbb{R}
&lt;/p&gt;</description></item><item><title>&#19978;&#19979;&#25991;&#21270;&#26426;&#22120;&#23398;&#20064;&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#24322;&#36136;&#21644;&#19978;&#19979;&#25991;&#30456;&#20851;&#25928;&#24212;&#30340;&#26032;&#33539;&#24335;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#21644;&#20803;&#20851;&#31995;&#20272;&#35745;&#24322;&#36136;&#20989;&#25968;&#65292;&#24182;&#24341;&#20837;&#19978;&#19979;&#25991;&#32534;&#30721;&#22120;&#21644;&#26679;&#26412;&#29305;&#23450;&#27169;&#22411;&#26469;&#32479;&#19968;&#29616;&#26377;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2310.11340</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#21270;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextualized Machine Learning. (arXiv:2310.11340v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11340
&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#21270;&#26426;&#22120;&#23398;&#20064;&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#24322;&#36136;&#21644;&#19978;&#19979;&#25991;&#30456;&#20851;&#25928;&#24212;&#30340;&#26032;&#33539;&#24335;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#21644;&#20803;&#20851;&#31995;&#20272;&#35745;&#24322;&#36136;&#20989;&#25968;&#65292;&#24182;&#24341;&#20837;&#19978;&#19979;&#25991;&#32534;&#30721;&#22120;&#21644;&#26679;&#26412;&#29305;&#23450;&#27169;&#22411;&#26469;&#32479;&#19968;&#29616;&#26377;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#24322;&#36136;&#21644;&#19978;&#19979;&#25991;&#30456;&#20851;&#25928;&#24212;&#30340;&#33539;&#24335;&#12290;&#19978;&#19979;&#25991;&#21270;ML&#36890;&#36807;&#23558;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20110;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#19978;&#19979;&#25991;&#29305;&#23450;&#21442;&#25968;&#27169;&#22411;&#20043;&#38388;&#30340;&#20803;&#20851;&#31995;&#26469;&#20272;&#35745;&#24322;&#36136;&#20989;&#25968;&#12290;&#36825;&#26159;&#19968;&#31181;&#32479;&#19968;&#29616;&#26377;&#26694;&#26550;&#30340;&#21464;&#31995;&#25968;&#24314;&#27169;&#26041;&#27861;&#65292;&#21253;&#25324;&#32858;&#31867;&#20998;&#26512;&#21644;&#38431;&#21015;&#24314;&#27169;&#65292;&#24341;&#20837;&#20102;&#20004;&#20010;&#21487;&#37325;&#29992;&#30340;&#27010;&#24565;&#65306;&#19978;&#19979;&#25991;&#32534;&#30721;&#22120;&#23558;&#26679;&#26412;&#19978;&#19979;&#25991;&#36716;&#21270;&#20026;&#27169;&#22411;&#21442;&#25968;&#65292;&#20197;&#21450;&#22522;&#20110;&#26679;&#26412;&#39044;&#27979;&#23376;&#30340;&#26679;&#26412;&#29305;&#23450;&#27169;&#22411;&#12290;&#25105;&#20204;&#22238;&#39038;&#20102;&#24320;&#21457;&#19978;&#19979;&#25991;&#21270;&#27169;&#22411;&#30340;&#36807;&#31243;&#65292;&#20174;&#19978;&#19979;&#25991;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#38750;&#21442;&#25968;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20197;&#21450;&#19978;&#19979;&#25991;&#21270;&#27169;&#22411;&#30340;&#21487;&#36776;&#35748;&#26465;&#20214;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24320;&#28304;&#30340;PyTorch&#36719;&#20214;&#21253;ContextualizedML&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine Contextualized Machine Learning (ML), a paradigm for learning heterogeneous and context-dependent effects. Contextualized ML estimates heterogeneous functions by applying deep learning to the meta-relationship between contextual information and context-specific parametric models. This is a form of varying-coefficient modeling that unifies existing frameworks including cluster analysis and cohort modeling by introducing two reusable concepts: a context encoder which translates sample context into model parameters, and sample-specific model which operates on sample predictors. We review the process of developing contextualized models, nonparametric inference from contextualized models, and identifiability conditions of contextualized models. Finally, we present the open-source PyTorch package ContextualizedML.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#35774;&#35745;&#31354;&#38388;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#35757;&#32451;&#24341;&#23548;&#26041;&#26696;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#25104;&#30340;&#20998;&#31867;&#22120;&#26469;&#24341;&#23548;&#25193;&#25955;&#29983;&#25104;&#65292;&#22312;&#20445;&#25345;&#28789;&#27963;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2310.11311</link><description>&lt;p&gt;
&#25581;&#31034;&#20998;&#31867;&#22120;&#24341;&#23548;&#25193;&#25955;&#29983;&#25104;&#30340;&#35774;&#35745;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Elucidating The Design Space of Classifier-Guided Diffusion Generation. (arXiv:2310.11311v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#35774;&#35745;&#31354;&#38388;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#35757;&#32451;&#24341;&#23548;&#26041;&#26696;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#25104;&#30340;&#20998;&#31867;&#22120;&#26469;&#24341;&#23548;&#25193;&#25955;&#29983;&#25104;&#65292;&#22312;&#20445;&#25345;&#28789;&#27963;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#25193;&#25955;&#29983;&#25104;&#20013;&#30340;&#24341;&#23548;&#23545;&#20110;&#26679;&#26412;&#36136;&#37327;&#21644;&#21487;&#25511;&#24615;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24341;&#23548;&#26041;&#26696;&#36824;&#26377;&#24453;&#25913;&#36827;&#12290;&#19968;&#26041;&#38754;&#65292;&#20027;&#27969;&#26041;&#27861;&#22914;&#20998;&#31867;&#22120;&#24341;&#23548;&#21644;&#26080;&#20998;&#31867;&#22120;&#24341;&#23548;&#37117;&#38656;&#35201;&#39069;&#22806;&#30340;&#26631;&#27880;&#25968;&#25454;&#35757;&#32451;&#65292;&#36825;&#26082;&#32791;&#26102;&#21448;&#19981;&#33021;&#36866;&#24212;&#26032;&#30340;&#26465;&#20214;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#26080;&#35757;&#32451;&#26041;&#27861;&#22914;&#36890;&#29992;&#24341;&#23548;&#34429;&#28982;&#26356;&#21152;&#28789;&#27963;&#65292;&#20294;&#23578;&#26410;&#35777;&#26126;&#20855;&#26377;&#21487;&#27604;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#35774;&#35745;&#31354;&#38388;&#36827;&#34892;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;&#36890;&#36807;&#20197;&#26080;&#35757;&#32451;&#30340;&#26041;&#24335;&#21033;&#29992;&#29616;&#25104;&#30340;&#20998;&#31867;&#22120;&#65292;&#21487;&#20197;&#22312;&#29616;&#26377;&#24341;&#23548;&#26041;&#26696;&#30340;&#22522;&#30784;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#20351;&#24471;&#20004;&#32773;&#30342;&#21487;&#20860;&#24471;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#26657;&#20934;&#20026;&#25351;&#23548;&#21407;&#21017;&#65292;&#36890;&#36807;&#20960;&#31181;&#39044;&#20808;&#35843;&#25972;&#30340;&#25216;&#26415;&#26469;&#26356;&#22909;&#22320;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#29616;&#25104;&#20998;&#31867;&#22120;&#26469;&#24341;&#23548;&#25193;&#25955;&#29983;&#25104;&#12290;&#22312;ImageNet&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Guidance in conditional diffusion generation is of great importance for sample quality and controllability. However, existing guidance schemes are to be desired. On one hand, mainstream methods such as classifier guidance and classifier-free guidance both require extra training with labeled data, which is time-consuming and unable to adapt to new conditions. On the other hand, training-free methods such as universal guidance, though more flexible, have yet to demonstrate comparable performance. In this work, through a comprehensive investigation into the design space, we show that it is possible to achieve significant performance improvements over existing guidance schemes by leveraging off-the-shelf classifiers in a training-free fashion, enjoying the best of both worlds. Employing calibration as a general guideline, we propose several pre-conditioning techniques to better exploit pretrained off-the-shelf classifiers for guiding diffusion generation. Extensive experiments on ImageNet 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#65292;&#20998;&#21035;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#21644;&#25512;&#23548;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.11256</link><description>&lt;p&gt;
&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#24341;&#20837;&#20102;&#31867;&#20284;&#20110;Gromov-Wassertein&#30340;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space. (arXiv:2310.11256v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#65292;&#20998;&#21035;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#21644;&#25512;&#23548;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#38598;&#21512;&#19978;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#12290;&#31532;&#19968;&#31181;&#36317;&#31163;&#26159;&#22312;&#39640;&#26031;&#27979;&#24230;&#31354;&#38388;&#19978;&#20004;&#20010;&#31163;&#25955;&#20998;&#24067;&#30340;Gromov-Wasserstein&#36317;&#31163;&#12290;&#35813;&#36317;&#31163;&#21487;&#20197;&#20316;&#20026;Gromov-Wasserstein&#30340;&#26367;&#20195;&#65292;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#20294;&#19981;&#33021;&#30452;&#25509;&#25512;&#23548;&#20986;&#26368;&#20248;&#30340;&#36816;&#36755;&#26041;&#26696;&#12290;&#20026;&#20102;&#35774;&#35745;&#20986;&#36825;&#26679;&#30340;&#36816;&#36755;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21478;&#19968;&#31181;&#22312;&#19981;&#21487;&#27604;&#36739;&#30340;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#35813;&#36317;&#31163;&#19982;Gromov-Wasserstein&#23494;&#20999;&#30456;&#20851;&#12290;&#24403;&#23558;&#20801;&#35768;&#30340;&#36816;&#36755;&#32806;&#21512;&#38480;&#21046;&#20026;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26102;&#65292;&#36825;&#23450;&#20041;&#20102;&#21478;&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#21487;&#20197;&#20316;&#20026;Gromov-Wasserstein&#30340;&#21478;&#19968;&#31181;&#26367;&#20195;&#65292;&#24182;&#20801;&#35768;&#25512;&#23548;&#20986;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce two Gromov-Wasserstein-type distances on the set of Gaussian mixture models. The first one takes the form of a Gromov-Wasserstein distance between two discrete distributionson the space of Gaussian measures. This distance can be used as an alternative to Gromov-Wasserstein for applications which only require to evaluate how far the distributions are from each other but does not allow to derive directly an optimal transportation plan between clouds of points. To design a way to define such a transportation plan, we introduce another distance between measures living in incomparable spaces that turns out to be closely related to Gromov-Wasserstein. When restricting the set of admissible transportation couplings to be themselves Gaussian mixture models in this latter, this defines another distance between Gaussian mixture models that can be used as another alternative to Gromov-Wasserstein and which allows to derive an optimal assignment between points. Finally,
&lt;/p&gt;</description></item><item><title>&#26412;&#35838;&#31243;&#20171;&#32461;&#20102;&#22522;&#20110;&#21160;&#24577;&#36755;&#36816;&#27979;&#24230;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#37325;&#28857;&#35762;&#36848;&#20102;&#22914;&#20309;&#36890;&#36807;&#25968;&#25454;&#23398;&#20064;&#36825;&#20123;&#26144;&#23556;&#65292;&#24182;&#36890;&#36807;&#27491;&#21453;&#39304;&#24490;&#29615;&#25913;&#36827;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.11232</link><description>&lt;p&gt;
&#23398;&#20064;&#26356;&#22909;&#30340;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning to Sample Better. (arXiv:2310.11232v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35838;&#31243;&#20171;&#32461;&#20102;&#22522;&#20110;&#21160;&#24577;&#36755;&#36816;&#27979;&#24230;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#37325;&#28857;&#35762;&#36848;&#20102;&#22914;&#20309;&#36890;&#36807;&#25968;&#25454;&#23398;&#20064;&#36825;&#20123;&#26144;&#23556;&#65292;&#24182;&#36890;&#36807;&#27491;&#21453;&#39304;&#24490;&#29615;&#25913;&#36827;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20123;&#35762;&#20041;&#20171;&#32461;&#20102;&#22522;&#20110;&#21160;&#24577;&#36755;&#36816;&#27979;&#24230;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#31616;&#21333;&#22522;&#30784;&#27979;&#24230;&#30340;&#26679;&#26412;&#34987;&#26144;&#23556;&#21040;&#24863;&#20852;&#36259;&#30446;&#26631;&#27979;&#24230;&#30340;&#26679;&#26412;&#12290;&#29305;&#21035;&#24378;&#35843;&#36825;&#20123;&#26041;&#27861;&#22312;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#25216;&#26415;&#20013;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#37325;&#35201;&#24615;&#37319;&#26679;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35762;&#20041;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;MC&#37319;&#26679;&#29983;&#25104;&#30340;&#25968;&#25454;&#21464;&#20998;&#23398;&#20064;&#36825;&#20123;&#26144;&#23556;&#65292;&#24182;&#22914;&#20309;&#21033;&#29992;&#23427;&#20204;&#36890;&#36807;&#27491;&#21453;&#39304;&#24490;&#29615;&#25913;&#36827;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
These lecture notes provide an introduction to recent advances in generative modeling methods based on the dynamical transportation of measures, by means of which samples from a simple base measure are mapped to samples from a target measure of interest. Special emphasis is put on the applications of these methods to Monte-Carlo (MC) sampling techniques, such as importance sampling and Markov Chain Monte-Carlo (MCMC) schemes. In this context, it is shown how the maps can be learned variationally using data generated by MC sampling, and how they can in turn be used to improve such sampling in a positive feedback loop.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#35757;&#32451;&#38543;&#26426;&#39044;&#27979;&#22120;&#65292;&#36890;&#36807;&#20445;&#25252;&#27599;&#20010;&#33410;&#28857;&#30340;&#38544;&#31169;&#24182;&#19988;&#20855;&#26377;&#25968;&#20540;&#19978;&#38750;&#31354;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#30340;&#21516;&#26102;&#23454;&#29616;&#25968;&#25454;&#20849;&#20139;&#21644;&#20445;&#25252;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2310.11203</link><description>&lt;p&gt;
&#20855;&#26377;&#38750;&#31354;&#27867;&#21270;&#30028;&#38480;&#30340;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Learning with Nonvacuous Generalisation Bounds. (arXiv:2310.11203v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11203
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#35757;&#32451;&#38543;&#26426;&#39044;&#27979;&#22120;&#65292;&#36890;&#36807;&#20445;&#25252;&#27599;&#20010;&#33410;&#28857;&#30340;&#38544;&#31169;&#24182;&#19988;&#20855;&#26377;&#25968;&#20540;&#19978;&#38750;&#31354;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#30340;&#21516;&#26102;&#23454;&#29616;&#25968;&#25454;&#20849;&#20139;&#21644;&#20445;&#25252;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#35757;&#32451;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#38543;&#26426;&#39044;&#27979;&#22120;&#65292;&#22312;&#36825;&#31181;&#31574;&#30053;&#20013;&#65292;&#32593;&#32476;&#30340;&#27599;&#20010;&#33410;&#28857;&#36890;&#36807;&#21457;&#24067;&#26412;&#22320;&#39044;&#27979;&#22120;&#20294;&#23545;&#20854;&#20182;&#33410;&#28857;&#20445;&#23494;&#20854;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#26041;&#24335;&#26469;&#20445;&#25252;&#20854;&#38544;&#31169;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26500;&#24314;&#19968;&#20010;&#20840;&#23616;&#30340;&#38543;&#26426;&#39044;&#27979;&#22120;&#65292;&#23427;&#22312;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#24847;&#20041;&#19978;&#32487;&#25215;&#20102;&#26412;&#22320;&#31169;&#26377;&#39044;&#27979;&#22120;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#21516;&#27493;&#24773;&#20917;&#65292;&#21363;&#25152;&#26377;&#33410;&#28857;&#20849;&#20139;&#30456;&#21516;&#30340;&#35757;&#32451;&#30446;&#26631;&#65288;&#20174;&#27867;&#21270;&#30028;&#38480;&#23548;&#20986;&#65289;&#65292;&#20197;&#21450;&#24322;&#27493;&#24773;&#20917;&#65292;&#21363;&#27599;&#20010;&#33410;&#28857;&#21487;&#20197;&#26377;&#33258;&#24049;&#30340;&#20010;&#24615;&#21270;&#35757;&#32451;&#30446;&#26631;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#19982;&#23558;&#25152;&#26377;&#25968;&#25454;&#38598;&#20849;&#20139;&#32473;&#25152;&#26377;&#33410;&#28857;&#30340;&#25209;&#22788;&#29702;&#26041;&#27861;&#30456;&#24403;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#39044;&#27979;&#22120;&#25903;&#25345;&#30528;&#22312;&#20445;&#25252;&#27599;&#20010;&#33410;&#28857;&#38544;&#31169;&#30340;&#21516;&#26102;&#20855;&#26377;&#25968;&#20540;&#19978;&#38750;&#31354;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#26126;&#30830;&#22320;&#35745;&#31639;&#20102;&#39044;&#27979;&#24615;&#33021;&#30340;&#22686;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel strategy to train randomised predictors in federated learning, where each node of the network aims at preserving its privacy by releasing a local predictor but keeping secret its training dataset with respect to the other nodes. We then build a global randomised predictor which inherits the properties of the local private predictors in the sense of a PAC-Bayesian generalisation bound. We consider the synchronous case where all nodes share the same training objective (derived from a generalisation bound), and the asynchronous case where each node may have its own personalised training objective. We show through a series of numerical experiments that our approach achieves a comparable predictive performance to that of the batch approach where all datasets are shared across nodes. Moreover the predictors are supported by numerically nonvacuous generalisation bounds while preserving privacy for each node. We explicitly compute the increment on predictive performance an
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.11143</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#30340;&#24503;&#22269;&#39640;&#20998;&#36776;&#29575;&#23460;&#20869;&#27681;&#27668;&#22320;&#22270;
&lt;/p&gt;
&lt;p&gt;
A new high-resolution indoor radon map for Germany using a machine learning based probabilistic exposure model. (arXiv:2310.11143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23460;&#20869;&#27681;&#27668;&#26159;&#19968;&#31181;&#33268;&#30284;&#30340;&#25918;&#23556;&#24615;&#27668;&#20307;&#65292;&#21487;&#20197;&#22312;&#23460;&#20869;&#31215;&#32047;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#20840;&#22269;&#33539;&#22260;&#20869;&#30340;&#23460;&#20869;&#27681;&#26292;&#38706;&#26159;&#22522;&#20110;&#24191;&#27867;&#30340;&#27979;&#37327;&#27963;&#21160;&#20272;&#35745;&#24471;&#26469;&#30340;&#12290;&#28982;&#32780;&#65292;&#26679;&#26412;&#30340;&#29305;&#24449;&#24448;&#24448;&#19982;&#20154;&#21475;&#29305;&#24449;&#19981;&#21516;&#65292;&#36825;&#26159;&#30001;&#20110;&#35768;&#22810;&#30456;&#20851;&#22240;&#32032;&#65292;&#22914;&#22320;&#36136;&#28304;&#27681;&#27668;&#30340;&#21487;&#29992;&#24615;&#25110;&#27004;&#23618;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#26679;&#26412;&#22823;&#23567;&#36890;&#24120;&#19981;&#20801;&#35768;&#20197;&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#36827;&#34892;&#26292;&#38706;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#27604;&#32431;&#25968;&#25454;&#26041;&#27861;&#26356;&#21152;&#29616;&#23454;&#22320;&#20272;&#35745;&#23460;&#20869;&#27681;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#38454;&#27573;&#24314;&#27169;&#26041;&#27861;&#65306;1&#65289;&#24212;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#65292;&#20351;&#29992;&#29615;&#22659;&#21644;&#24314;&#31569;&#25968;&#25454;&#20316;&#20026;&#39044;&#27979;&#22240;&#23376;&#65292;&#20272;&#35745;&#20102;&#24503;&#22269;&#27599;&#20010;&#20303;&#23429;&#27004;&#30340;&#27599;&#20010;&#27004;&#23618;&#30340;&#23460;&#20869;&#27681;&#27010;&#29575;&#20998;&#24067;&#20989;&#25968;&#65307;2&#65289;&#20351;&#29992;&#27010;&#29575;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#25216;&#26415;&#20351;&#23427;&#20204;&#32452;&#21512;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor radon exposure at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sample often differ from the characteristics of the population due to the large number of relevant factors such as the availability of geogenic radon or floor level. Furthermore, the sample size usually does not allow exposure estimation with high spatial resolution. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. We applied a two-stage modelling approach: 1) a quantile regression forest using environmental and building data as predictors was applied to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany; (2) a probabilistic Monte Carlo sampling technique enabled the combination and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#37325;&#20849;&#20139;&#21644;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#30340;&#35757;&#32451;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#25200;&#21160;&#21644;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.11122</link><description>&lt;p&gt;
&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Sensitivity-Aware Amortized Bayesian Inference. (arXiv:2310.11122v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#37325;&#20849;&#20139;&#21644;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#30340;&#35757;&#32451;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#25200;&#21160;&#21644;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#26159;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#36827;&#34892;&#27010;&#29575;&#25512;&#29702;&#21644;&#20915;&#31574;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#29616;&#20195;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#20013;&#30340;&#22522;&#26412;&#36873;&#25321;&#28041;&#21450;&#20284;&#28982;&#20989;&#25968;&#21644;&#20808;&#39564;&#20998;&#24067;&#30340;&#35268;&#33539;&#12289;&#21518;&#39564;&#36924;&#36817;&#22120;&#21644;&#25968;&#25454;&#12290;&#27599;&#20010;&#36873;&#25321;&#37117;&#21487;&#20197;&#26174;&#30528;&#24433;&#21709;&#22522;&#20110;&#27169;&#22411;&#30340;&#25512;&#26029;&#21644;&#21518;&#32493;&#20915;&#31574;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#34892;&#25935;&#24863;&#24615;&#20998;&#26512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26041;&#38754;&#30340;&#26041;&#27861;&#65292;&#23558;&#25935;&#24863;&#24615;&#20998;&#26512;&#25972;&#21512;&#21040;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#65288;ABI&#65292;&#21363;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#25311;&#25512;&#26029;&#65289;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;&#26435;&#37325;&#20849;&#20139;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#32534;&#30721;&#26367;&#20195;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#20043;&#38388;&#30340;&#32467;&#26500;&#30456;&#20284;&#24615;&#65292;&#20197;&#26368;&#23567;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#25512;&#26029;&#26469;&#35780;&#20272;&#23545;&#21508;&#31181;&#25968;&#25454;&#25200;&#21160;&#25110;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#12290;&#19982;&#22823;&#22810;&#25968;&#20854;&#20182;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#27604;&#65292;&#36825;&#20004;&#20010;&#27493;&#39588;&#37117;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference is a powerful framework for making probabilistic inferences and decisions under uncertainty. Fundamental choices in modern Bayesian workflows concern the specification of the likelihood function and prior distributions, the posterior approximator, and the data. Each choice can significantly influence model-based inference and subsequent decisions, thereby necessitating sensitivity analysis. In this work, we propose a multifaceted approach to integrate sensitivity analyses into amortized Bayesian inference (ABI, i.e., simulation-based inference with neural networks). First, we utilize weight sharing to encode the structural similarities between alternative likelihood and prior specifications in the training process with minimal computational overhead. Second, we leverage the rapid inference of neural networks to assess sensitivity to various data perturbations or pre-processing procedures. In contrast to most other Bayesian approaches, both steps circumvent the costly
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#22312;&#21482;&#26377;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#19968;&#20123;&#26368;&#23567;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#21487;&#20197;&#35745;&#31639;&#20986;&#31934;&#30830;&#30340;LDA&#25237;&#24433;&#21521;&#37327;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#31181;&#26368;&#23567;&#20449;&#24687;&#30340;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;MILDA&#65289;&#27169;&#22411;&#19982;&#26377;&#30417;&#30563;&#30340;LDA&#27169;&#22411;&#30340;&#24615;&#33021;&#25509;&#36817;&#12290;</title><link>http://arxiv.org/abs/2310.11110</link><description>&lt;p&gt;
&#26368;&#23567;&#20449;&#24687;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65306;&#20351;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#35757;&#32451;LDA&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Minimally Informed Linear Discriminant Analysis: training an LDA model with unlabelled data. (arXiv:2310.11110v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11110
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22312;&#21482;&#26377;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#19968;&#20123;&#26368;&#23567;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#21487;&#20197;&#35745;&#31639;&#20986;&#31934;&#30830;&#30340;LDA&#25237;&#24433;&#21521;&#37327;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#31181;&#26368;&#23567;&#20449;&#24687;&#30340;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;MILDA&#65289;&#27169;&#22411;&#19982;&#26377;&#30417;&#30563;&#30340;LDA&#27169;&#22411;&#30340;&#24615;&#33021;&#25509;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#26159;&#26368;&#21476;&#32769;&#19988;&#26368;&#27969;&#34892;&#30340;&#32447;&#24615;&#26041;&#27861;&#20043;&#19968;&#65292;&#29992;&#20110;&#26377;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#12290;&#26412;&#25991;&#35777;&#26126;&#65292;&#22914;&#26524;&#26377;&#19968;&#20123;&#26368;&#23567;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#37027;&#20040;&#21487;&#20197;&#22522;&#20110;&#26410;&#26631;&#35760;&#25968;&#25454;&#35745;&#31639;&#20986;LDA&#27169;&#22411;&#30340;&#31934;&#30830;&#25237;&#24433;&#21521;&#37327;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21482;&#38656;&#35201;&#20197;&#19979;&#19977;&#20010;&#20449;&#24687;&#20013;&#30340;&#20219;&#24847;&#19968;&#20010;&#21363;&#21487;&#35745;&#31639;LDA&#25237;&#24433;&#21521;&#37327;&#65292;&#22914;&#26524;&#21482;&#26377;&#26410;&#26631;&#35760;&#25968;&#25454;&#21487;&#29992;&#65306;&#65288;1&#65289;&#20004;&#20010;&#31867;&#21035;&#20013;&#20219;&#24847;&#19968;&#20010;&#30340;&#31867;&#21035;&#24179;&#22343;&#20540;&#65292;&#65288;2&#65289;&#20004;&#20010;&#31867;&#21035;&#24179;&#22343;&#20540;&#20043;&#38388;&#30340;&#24046;&#24322;&#65288;&#32463;&#36807;&#32553;&#25918;&#65289;&#65292;&#25110;&#32773;&#65288;3&#65289;&#31867;&#21035;&#21327;&#26041;&#24046;&#30697;&#38453;&#65288;&#32463;&#36807;&#32553;&#25918;&#65289;&#12290;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#35777;&#26126;&#36825;&#31181;&#26368;&#23567;&#20449;&#24687;&#30340;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;MILDA&#65289;&#27169;&#22411;&#19982;&#26377;&#30417;&#30563;&#30340;LDA&#27169;&#22411;&#30340;&#24615;&#33021;&#38750;&#24120;&#25509;&#36817;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;MILDA&#25237;&#24433;&#21521;&#37327;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#23553;&#38381;&#24418;&#24335;&#35745;&#31639;&#20986;&#26469;&#65292;&#24182;&#19988;&#35745;&#31639;&#25104;&#26412;&#19982;LDA&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear Discriminant Analysis (LDA) is one of the oldest and most popular linear methods for supervised classification problems. In this paper, we demonstrate that it is possible to compute the exact projection vector from LDA models based on unlabelled data, if some minimal prior information is available. More precisely, we show that only one of the following three pieces of information is actually sufficient to compute the LDA projection vector if only unlabelled data are available: (1) the class average of one of the two classes, (2) the difference between both class averages (up to a scaling), or (3) the class covariance matrices (up to a scaling). These theoretical results are validated in numerical experiments, demonstrating that this minimally informed Linear Discriminant Analysis (MILDA) model closely matches the performance of a supervised LDA model. Furthermore, we show that the MILDA projection vector can be computed in a closed form with a computational cost comparable to LD
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#20302;&#25104;&#26412;&#37325;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35299;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#36825;&#19968;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#20943;&#23569;&#35745;&#31639;&#24037;&#20316;&#37327;&#65292;&#24182;&#32469;&#36807;&#29616;&#26377;&#26041;&#27861;&#20013;&#30340;&#28151;&#21512;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.11065</link><description>&lt;p&gt;
&#20302;&#25104;&#26412;&#37325;&#37319;&#26679;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#29992;&#20110;&#39640;&#25928;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Resampling Stochastic Gradient Descent Cheaply for Efficient Uncertainty Quantification. (arXiv:2310.11065v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#20302;&#25104;&#26412;&#37325;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35299;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#36825;&#19968;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#20943;&#23569;&#35745;&#31639;&#24037;&#20316;&#37327;&#65292;&#24182;&#32469;&#36807;&#29616;&#26377;&#26041;&#27861;&#20013;&#30340;&#28151;&#21512;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25110;&#38543;&#26426;&#36924;&#36817;&#22312;&#27169;&#22411;&#35757;&#32451;&#21644;&#38543;&#26426;&#20248;&#21270;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#34429;&#28982;&#26377;&#22823;&#37327;&#20851;&#20110;&#20854;&#25910;&#25947;&#24615;&#20998;&#26512;&#30340;&#25991;&#29486;&#65292;&#20294;&#23545;&#20174;SGD&#33719;&#24471;&#30340;&#35299;&#36827;&#34892;&#25512;&#26029;&#30340;&#30740;&#31350;&#21482;&#26159;&#26368;&#36817;&#25165;&#24320;&#22987;&#65292;&#20294;&#30001;&#20110;&#23545;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26085;&#30410;&#38656;&#27714;&#32780;&#21464;&#24471;&#37325;&#35201;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#35745;&#31639;&#19978;&#24265;&#20215;&#30340;&#22522;&#20110;&#37325;&#37319;&#26679;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;SGD&#35299;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#19968;&#20010;&#26041;&#27861;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#36827;&#34892;&#26367;&#25442;&#37325;&#37319;&#26679;&#26469;&#20351;&#29992;&#22810;&#20010;&#20294;&#23569;&#37327;&#30340;SGD&#24182;&#34892;&#36827;&#34892;&#25805;&#20316;&#65292;&#21478;&#19968;&#20010;&#26041;&#27861;&#20197;&#22312;&#32447;&#26041;&#24335;&#36827;&#34892;&#25805;&#20316;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#34987;&#35270;&#20026;&#23545;&#24050;&#24314;&#31435;&#30340;Bootstrap&#26041;&#26696;&#36827;&#34892;&#22686;&#24378;&#65292;&#20197;&#26174;&#30528;&#20943;&#23569;&#37325;&#37319;&#26679;&#38656;&#27714;&#26041;&#38754;&#30340;&#35745;&#31639;&#24037;&#20316;&#37327;&#65292;&#21516;&#26102;&#32469;&#36807;&#29616;&#26377;&#25209;&#22788;&#29702;&#26041;&#27861;&#20013;&#22797;&#26434;&#30340;&#28151;&#21512;&#26465;&#20214;&#12290;&#25105;&#20204;&#36890;&#36807;&#26368;&#36817;&#30340;&#25152;&#35859;&#20302;&#25104;&#26412;bootstrap&#24605;&#24819;&#21644;SGD&#30340;Berry-Esseen&#22411;&#36793;&#30028;&#26469;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient descent (SGD) or stochastic approximation has been widely used in model training and stochastic optimization. While there is a huge literature on analyzing its convergence, inference on the obtained solutions from SGD has only been recently studied, yet is important due to the growing need for uncertainty quantification. We investigate two computationally cheap resampling-based methods to construct confidence intervals for SGD solutions. One uses multiple, but few, SGDs in parallel via resampling with replacement from the data, and another operates this in an online fashion. Our methods can be regarded as enhancements of established bootstrap schemes to substantially reduce the computation effort in terms of resampling requirements, while at the same time bypassing the intricate mixing conditions in existing batching methods. We achieve these via a recent so-called cheap bootstrap idea and Berry-Esseen-type bound for SGD.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#38543;&#26426;&#21270;&#30340;&#20302;&#31209;&#21644;&#20302;&#31934;&#24230;&#22240;&#24335;&#20998;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30697;&#38453;&#21387;&#32553;&#31639;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20943;&#23567;&#23384;&#20648;&#21644;&#22788;&#29702;&#22823;&#22411;&#30697;&#38453;&#25152;&#38656;&#30340;&#35745;&#31639;&#36164;&#28304;&#21644;&#20869;&#23384;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.11028</link><description>&lt;p&gt;
&#30697;&#38453;&#21387;&#32553;&#36890;&#36807;&#38543;&#26426;&#20302;&#31209;&#20302;&#31934;&#24230;&#22240;&#24335;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Matrix Compression via Randomized Low Rank and Low Precision Factorization. (arXiv:2310.11028v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11028
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#21270;&#30340;&#20302;&#31209;&#21644;&#20302;&#31934;&#24230;&#22240;&#24335;&#20998;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30697;&#38453;&#21387;&#32553;&#31639;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20943;&#23567;&#23384;&#20648;&#21644;&#22788;&#29702;&#22823;&#22411;&#30697;&#38453;&#25152;&#38656;&#30340;&#35745;&#31639;&#36164;&#28304;&#21644;&#20869;&#23384;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#22312;&#21508;&#20010;&#30740;&#31350;&#39046;&#22495;&#20013;&#37117;&#38750;&#24120;&#26377;&#29992;&#65292;&#22240;&#20026;&#23427;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26041;&#20415;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20197;&#32467;&#26500;&#21270;&#30340;&#26041;&#24335;&#32452;&#32455;&#21644;&#25805;&#20316;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#29616;&#20195;&#30697;&#38453;&#21487;&#33021;&#21253;&#21547;&#25968;&#21313;&#20159;&#20010;&#20803;&#32032;&#65292;&#20351;&#24471;&#23427;&#20204;&#30340;&#23384;&#20648;&#21644;&#22788;&#29702;&#23545;&#35745;&#31639;&#36164;&#28304;&#21644;&#20869;&#23384;&#20351;&#29992;&#35201;&#27714;&#24456;&#39640;&#12290;&#34429;&#28982;&#36825;&#20123;&#30697;&#38453;&#38750;&#24120;&#22823;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#26159;&#36817;&#20284;&#20302;&#31209;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#26469;&#33719;&#24471;&#20219;&#20309;&#30697;&#38453; $\mathbf{A}$ &#30340;&#20302;&#31209;&#20998;&#35299;&#65292;&#21363; $\mathbf{A} \approx \mathbf{L}\mathbf{R}$&#65292;&#20854;&#20013; $\mathbf{L}$ &#21644; $\mathbf{R}$ &#26159;&#20302;&#31209;&#22240;&#23376;&#12290;$\mathbf{L}$ &#21644; $\mathbf{R}$ &#20013;&#30340;&#20803;&#32032;&#24635;&#25968;&#21487;&#20197;&#26174;&#33879;&#23569;&#20110; $\mathbf{A}$ &#20013;&#30340;&#20803;&#32032;&#24635;&#25968;&#12290;&#27492;&#22806;&#65292;$\mathbf{L}$ &#21644; $\mathbf{R}$ &#30340;&#26465;&#30446;&#34987;&#37327;&#21270;&#20026;&#20302;&#31934;&#24230;&#26684;&#24335; $--$ &#36890;&#36807;&#32473;&#20986;&#20302;&#31209;&#21644;&#20302;&#31934;&#24230;&#22240;&#24335;&#20998;&#35299;&#26469;&#21387;&#32553; $\mathbf{A}$&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#39318;&#20808;&#35745;&#31639; $\mathbf$
&lt;/p&gt;
&lt;p&gt;
Matrices are exceptionally useful in various fields of study as they provide a convenient framework to organize and manipulate data in a structured manner. However, modern matrices can involve billions of elements, making their storage and processing quite demanding in terms of computational resources and memory usage. Although prohibitively large, such matrices are often approximately low rank. We propose an algorithm that exploits this structure to obtain a low rank decomposition of any matrix $\mathbf{A}$ as $\mathbf{A} \approx \mathbf{L}\mathbf{R}$, where $\mathbf{L}$ and $\mathbf{R}$ are the low rank factors. The total number of elements in $\mathbf{L}$ and $\mathbf{R}$ can be significantly less than that in $\mathbf{A}$. Furthermore, the entries of $\mathbf{L}$ and $\mathbf{R}$ are quantized to low precision formats $--$ compressing $\mathbf{A}$ by giving us a low rank and low precision factorization. Our algorithm first computes an approximate basis of the range space of $\mathb
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22240;&#26524;&#29983;&#25104;&#24314;&#27169;&#30340;&#25216;&#26415;&#65292;&#20854;&#20013;&#20998;&#20026;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21644;&#21487;&#25511;&#21453;&#20107;&#23454;&#29983;&#25104;&#20004;&#20010;&#37096;&#20998;&#65292;&#36825;&#20123;&#27169;&#22411;&#34701;&#21512;&#20102;&#22240;&#26524;&#29702;&#35770;&#65292;&#35299;&#20915;&#20102;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#19968;&#20123;&#26681;&#26412;&#24615;&#32570;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#20998;&#24067;&#20559;&#31227;&#40065;&#26834;&#24615;&#12289;&#20844;&#24179;&#24615;&#21644;&#20114;&#25805;&#20316;&#24615;&#31561;&#26377;&#30410;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.11011</link><description>&lt;p&gt;
&#20174;&#21487;&#35782;&#21035;&#30340;&#22240;&#26524;&#34920;&#31034;&#21040;&#21487;&#25511;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#65306;&#22240;&#26524;&#29983;&#25104;&#24314;&#27169;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
From Identifiable Causal Representations to Controllable Counterfactual Generation: A Survey on Causal Generative Modeling. (arXiv:2310.11011v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11011
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22240;&#26524;&#29983;&#25104;&#24314;&#27169;&#30340;&#25216;&#26415;&#65292;&#20854;&#20013;&#20998;&#20026;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21644;&#21487;&#25511;&#21453;&#20107;&#23454;&#29983;&#25104;&#20004;&#20010;&#37096;&#20998;&#65292;&#36825;&#20123;&#27169;&#22411;&#34701;&#21512;&#20102;&#22240;&#26524;&#29702;&#35770;&#65292;&#35299;&#20915;&#20102;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#19968;&#20123;&#26681;&#26412;&#24615;&#32570;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#20998;&#24067;&#20559;&#31227;&#40065;&#26834;&#24615;&#12289;&#20844;&#24179;&#24615;&#21644;&#20114;&#25805;&#20316;&#24615;&#31561;&#26377;&#30410;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#25968;&#25454;&#23494;&#24230;&#20272;&#35745;&#21644;&#20174;&#26377;&#38480;&#26679;&#26412;&#20013;&#29983;&#25104;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#23384;&#22312;&#19968;&#20123;&#26681;&#26412;&#24615;&#30340;&#32570;&#28857;&#65292;&#22914;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#12289;&#24341;&#20837;&#34394;&#20551;&#30456;&#20851;&#24615;&#21644;&#24046;&#21170;&#30340;&#36229;&#20986;&#20998;&#24067;&#30340;&#22806;&#25512;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#21487;&#20197;&#23558;&#22240;&#26524;&#29702;&#35770;&#34701;&#20837;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#20013;&#12290;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#25551;&#36848;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#24182;&#23545;&#31995;&#32479;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#22797;&#26434;&#22240;&#26524;&#20851;&#31995;&#21644;&#26426;&#21046;&#36827;&#34892;&#24314;&#27169;&#12290;&#22240;&#27492;&#65292;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#21487;&#20197;&#19982;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#33258;&#28982;&#22320;&#32467;&#21512;&#12290;&#22240;&#26524;&#27169;&#22411;&#20026;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#20102;&#20960;&#20010;&#26377;&#30410;&#30340;&#23646;&#24615;&#65292;&#22914;&#20998;&#24067;&#20559;&#31227;&#40065;&#26834;&#24615;&#12289;&#20844;&#24179;&#24615;&#21644;&#20114;&#25805;&#20316;&#24615;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#29983;&#25104;&#24314;&#27169;&#30340;&#25216;&#26415;&#32508;&#36848;&#65292;&#20998;&#20026;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21644;&#21487;&#25511;&#21453;&#20107;&#23454;&#29983;&#25104;&#20004;&#20010;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep generative models have shown tremendous success in data density estimation and data generation from finite samples. While these models have shown impressive performance by learning correlations among features in the data, some fundamental shortcomings are their lack of explainability, the tendency to induce spurious correlations, and poor out-of-distribution extrapolation. In an effort to remedy such challenges, one can incorporate the theory of causality in deep generative modeling. Structural causal models (SCMs) describe data-generating processes and model complex causal relationships and mechanisms among variables in a system. Thus, SCMs can naturally be combined with deep generative models. Causal models offer several beneficial properties to deep generative models, such as distribution shift robustness, fairness, and interoperability. We provide a technical survey on causal generative modeling categorized into causal representation learning and controllable counterfactual ge
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21152;&#26435;&#25104;&#21592;&#32423;&#21035;&#65288;WGoM&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#20998;&#31867;&#25968;&#25454;&#30340;&#28508;&#22312;&#31867;&#21035;&#25512;&#26029;&#38382;&#39064;&#12290;&#19982;&#29616;&#26377;&#27169;&#22411;&#30456;&#27604;&#65292;WGoM&#26356;&#36890;&#29992;&#19988;&#36866;&#29992;&#20110;&#20855;&#26377;&#36830;&#32493;&#25110;&#36127;&#21709;&#24212;&#30340;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;&#31639;&#27861;&#65292;&#25105;&#20204;&#33021;&#22815;&#20934;&#30830;&#39640;&#25928;&#22320;&#20272;&#35745;&#28508;&#22312;&#28151;&#21512;&#25104;&#21592;&#21644;&#20854;&#20182;WGoM&#21442;&#25968;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#21644;&#23454;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.10989</link><description>&lt;p&gt;
WGoM&#65306;&#19968;&#31181;&#36866;&#29992;&#20110;&#24102;&#21152;&#26435;&#21709;&#24212;&#30340;&#20998;&#31867;&#25968;&#25454;&#30340;&#26032;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
WGoM: A novel model for categorical data with weighted responses. (arXiv:2310.10989v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21152;&#26435;&#25104;&#21592;&#32423;&#21035;&#65288;WGoM&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#20998;&#31867;&#25968;&#25454;&#30340;&#28508;&#22312;&#31867;&#21035;&#25512;&#26029;&#38382;&#39064;&#12290;&#19982;&#29616;&#26377;&#27169;&#22411;&#30456;&#27604;&#65292;WGoM&#26356;&#36890;&#29992;&#19988;&#36866;&#29992;&#20110;&#20855;&#26377;&#36830;&#32493;&#25110;&#36127;&#21709;&#24212;&#30340;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;&#31639;&#27861;&#65292;&#25105;&#20204;&#33021;&#22815;&#20934;&#30830;&#39640;&#25928;&#22320;&#20272;&#35745;&#28508;&#22312;&#28151;&#21512;&#25104;&#21592;&#21644;&#20854;&#20182;WGoM&#21442;&#25968;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#21644;&#23454;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Graded of Membership&#65288;GoM&#65289;&#27169;&#22411;&#26159;&#19968;&#31181;&#29992;&#20110;&#25512;&#26029;&#20998;&#31867;&#25968;&#25454;&#20013;&#28508;&#22312;&#31867;&#21035;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#20351;&#24471;&#20010;&#20307;&#21487;&#20197;&#23646;&#20110;&#22810;&#20010;&#28508;&#22312;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#35813;&#27169;&#22411;&#20165;&#36866;&#29992;&#20110;&#20855;&#26377;&#38750;&#36127;&#25972;&#25968;&#21709;&#24212;&#30340;&#20998;&#31867;&#25968;&#25454;&#65292;&#20351;&#24471;&#23427;&#26080;&#27861;&#24212;&#29992;&#20110;&#20855;&#26377;&#36830;&#32493;&#25110;&#36127;&#21709;&#24212;&#30340;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21152;&#26435;&#25104;&#21592;&#32423;&#21035;&#65288;WGoM&#65289;&#27169;&#22411;&#30340;&#26032;&#27169;&#22411;&#12290;&#19982;GoM&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;WGoM&#22312;&#21709;&#24212;&#30697;&#38453;&#30340;&#29983;&#25104;&#19978;&#25918;&#23485;&#20102;GoM&#30340;&#20998;&#24067;&#32422;&#26463;&#65292;&#24182;&#19988;&#27604;GoM&#26356;&#36890;&#29992;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#28508;&#22312;&#28151;&#21512;&#25104;&#21592;&#21644;&#20854;&#20182;WGoM&#21442;&#25968;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20272;&#35745;&#21442;&#25968;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#32479;&#35745;&#19968;&#33268;&#24615;&#12290;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#20934;&#30830;&#39640;&#25928;&#65292;&#20855;&#26377;&#24456;&#39640;&#30340;&#23454;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Graded of Membership (GoM) model is a powerful tool for inferring latent classes in categorical data, which enables subjects to belong to multiple latent classes. However, its application is limited to categorical data with nonnegative integer responses, making it inappropriate for datasets with continuous or negative responses. To address this limitation, this paper proposes a novel model named the Weighted Grade of Membership (WGoM) model. Compared with GoM, our WGoM relaxes GoM's distribution constraint on the generation of a response matrix and it is more general than GoM. We then propose an algorithm to estimate the latent mixed memberships and the other WGoM parameters. We derive the error bounds of the estimated parameters and show that the algorithm is statistically consistent. The algorithmic performance is validated in both synthetic and real-world datasets. The results demonstrate that our algorithm is accurate and efficient, indicating its high potential for practical a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#21363;&#21152;&#26435;&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#65288;WLCM&#65289;&#65292;&#21487;&#20197;&#29992;&#20110;&#23545;&#20855;&#26377;&#36830;&#32493;&#25110;&#36127;&#21709;&#24212;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.10984</link><description>&lt;p&gt;
&#20855;&#26377;&#21152;&#26435;&#21709;&#24212;&#30340;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Latent class analysis with weighted responses. (arXiv:2310.10984v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10984
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#21363;&#21152;&#26435;&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#65288;WLCM&#65289;&#65292;&#21487;&#20197;&#29992;&#20110;&#23545;&#20855;&#26377;&#36830;&#32493;&#25110;&#36127;&#21709;&#24212;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#34987;&#25552;&#35758;&#20316;&#20026;&#23545;&#31038;&#20250;&#12289;&#24515;&#29702;&#12289;&#34892;&#20026;&#21644;&#29983;&#29289;&#31185;&#23398;&#31561;&#21508;&#20010;&#39046;&#22495;&#20013;&#30340;&#20998;&#31867;&#25968;&#25454;&#36827;&#34892;&#32858;&#31867;&#20998;&#26512;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#30340;&#19968;&#20010;&#37325;&#35201;&#38480;&#21046;&#26159;&#23427;&#21482;&#36866;&#29992;&#20110;&#20855;&#26377;&#20108;&#36827;&#21046;&#21709;&#24212;&#30340;&#25968;&#25454;&#65292;&#20351;&#20854;&#26080;&#27861;&#23545;&#20855;&#26377;&#36830;&#32493;&#25110;&#36127;&#21709;&#24212;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#24573;&#35270;&#26435;&#37325;&#20250;&#20002;&#22833;&#25481;&#22312;&#26435;&#37325;&#20013;&#21253;&#21547;&#30340;&#35768;&#22810;&#28508;&#22312;&#26377;&#20215;&#20540;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#21363;&#21152;&#26435;&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#65288;WLCM&#65289;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20801;&#35768;&#36890;&#36807;&#28508;&#22312;&#31867;&#21035;&#32467;&#26500;&#20174;&#20219;&#24847;&#20998;&#24067;&#29983;&#25104;&#25968;&#25454;&#30340;&#21709;&#24212;&#30697;&#38453;&#12290;&#19982;&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;WLCM&#26356;&#21152;&#30495;&#23454;&#21644;&#36890;&#29992;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;WLCM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20855;&#26377;&#21152;&#26435;&#21709;&#24212;&#30340;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#35813;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The latent class model has been proposed as a powerful tool for cluster analysis of categorical data in various fields such as social, psychological, behavioral, and biological sciences. However, one important limitation of the latent class model is that it is only suitable for data with binary responses, making it fail to model real-world data with continuous or negative responses. In many applications, ignoring the weights throws out a lot of potentially valuable information contained in the weights. To address this limitation, we propose a novel generative model, the weighted latent class model (WLCM). Our model allows data's response matrix to be generated from an arbitrary distribution with a latent class structure. In comparison to the latent class model, our WLCM is more realistic and more general. To our knowledge, our WLCM is the first model for latent class analysis with weighted responses. We investigate the identifiability of the model and propose an efficient algorithm for
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#26680;&#23383;&#20856;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#32479;&#35745;&#29305;&#24449;&#21521;&#37327;&#21644;&#30456;&#20851;&#24615;&#26679;&#26412;&#36873;&#25321;&#25216;&#26415;&#65292;&#22312;MRI&#20013;&#23454;&#29616;&#20102;&#33041;&#32959;&#30244;&#30340;&#26377;&#25928;&#20998;&#21106;&#12290;</title><link>http://arxiv.org/abs/2310.10963</link><description>&lt;p&gt;
&#20351;&#29992;&#20449;&#24687;&#29305;&#24449;&#21521;&#37327;&#21644;&#26680;&#23383;&#20856;&#23398;&#20064;&#30340;MRI&#33041;&#32959;&#30244;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
MRI brain tumor segmentation using informative feature vectors and kernel dictionary learning. (arXiv:2310.10963v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#26680;&#23383;&#20856;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#32479;&#35745;&#29305;&#24449;&#21521;&#37327;&#21644;&#30456;&#20851;&#24615;&#26679;&#26412;&#36873;&#25321;&#25216;&#26415;&#65292;&#22312;MRI&#20013;&#23454;&#29616;&#20102;&#33041;&#32959;&#30244;&#30340;&#26377;&#25928;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23383;&#20856;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;MRI&#65289;&#20013;&#20998;&#21106;&#33041;&#32959;&#30244;&#21306;&#22495;&#12290;&#20174;&#33041;MRI&#25195;&#25551;&#20013;&#30340;&#20687;&#32032;&#21608;&#22260;&#22823;&#23567;&#20026;3&#215;3&#30340;&#34917;&#19969;&#20013;&#25552;&#21462;&#19968;&#32452;&#19968;&#38454;&#21644;&#20108;&#38454;&#32479;&#35745;&#29305;&#24449;&#21521;&#37327;&#12290;&#21033;&#29992;&#36825;&#20123;&#29305;&#24449;&#21521;&#37327;&#20998;&#21035;&#35757;&#32451;&#20004;&#20010;&#26680;&#23383;&#20856;&#65292;&#29992;&#20110;&#20581;&#24247;&#21644;&#32959;&#30244;&#32452;&#32455;&#30340;&#20998;&#21106;&#12290;&#20026;&#20102;&#25552;&#39640;&#23383;&#20856;&#30340;&#25928;&#29575;&#21644;&#20943;&#23569;&#35757;&#32451;&#26102;&#38388;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#26679;&#26412;&#36873;&#25321;&#25216;&#26415;&#65292;&#29992;&#20110;&#35782;&#21035;&#26368;&#20855;&#20449;&#24687;&#37327;&#21644;&#21306;&#20998;&#24230;&#30340;&#29305;&#24449;&#21521;&#37327;&#23376;&#38598;&#12290;&#35813;&#25216;&#26415;&#26088;&#22312;&#36890;&#36807;&#36873;&#25321;&#19968;&#32452;&#29305;&#24449;&#21521;&#37327;&#26469;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#20998;&#21106;&#20219;&#21153;&#20449;&#24687;&#65292;&#20174;&#32780;&#25913;&#21892;&#23383;&#20856;&#30340;&#24615;&#33021;&#12290;&#38543;&#21518;&#65292;&#21033;&#29992;&#32447;&#24615;&#20998;&#31867;&#22120;&#22522;&#20110;&#23398;&#20064;&#21040;&#30340;&#23383;&#20856;&#26469;&#21306;&#20998;&#20581;&#24247;&#20687;&#32032;&#21644;&#24322;&#24120;&#20687;&#32032;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a method based on a kernel dictionary learning algorithm for segmenting brain tumor regions in magnetic resonance images (MRI). A set of first-order and second-order statistical feature vectors are extracted from patches of size 3 * 3 around pixels in the brain MRI scans. These feature vectors are utilized to train two kernel dictionaries separately for healthy and tumorous tissues. To enhance the efficiency of the dictionaries and reduce training time, a correlation-based sample selection technique is developed to identify the most informative and discriminative subset of feature vectors. This technique aims to improve the performance of the dictionaries by selecting a subset of feature vectors that provide valuable information for the segmentation task. Subsequently, a linear classifier is utilized to distinguish between healthy and unhealthy pixels based on the learned dictionaries. The results demonstrate that the proposed method outperforms other existing metho
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23616;&#37096;&#22270;&#30028;&#38480;&#30340;&#35757;&#32451;&#22823;&#22411;&#36755;&#20837;&#22270;&#30340;&#37319;&#26679;&#22411;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#23567;&#26679;&#26412;&#30340;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#19982;&#25972;&#20010;&#22270;&#35757;&#32451;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#36825;&#20026;&#20351;&#29992;&#37319;&#26679;&#35757;&#32451;GNN&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#12289;&#36229;&#21442;&#25968;&#21644;&#37319;&#26679;&#31639;&#27861;&#26041;&#38754;&#26356;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.10953</link><description>&lt;p&gt;
&#22522;&#20110;&#23616;&#37096;&#22270;&#30028;&#38480;&#30340;&#37319;&#26679;&#22411;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Local Graph Limits Perspective on Sampling-Based GNNs. (arXiv:2310.10953v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10953
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23616;&#37096;&#22270;&#30028;&#38480;&#30340;&#35757;&#32451;&#22823;&#22411;&#36755;&#20837;&#22270;&#30340;&#37319;&#26679;&#22411;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#23567;&#26679;&#26412;&#30340;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#19982;&#25972;&#20010;&#22270;&#35757;&#32451;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#36825;&#20026;&#20351;&#29992;&#37319;&#26679;&#35757;&#32451;GNN&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#12289;&#36229;&#21442;&#25968;&#21644;&#37319;&#26679;&#31639;&#27861;&#26041;&#38754;&#26356;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#22823;&#22411;&#36755;&#20837;&#22270;&#20013;&#30340;&#23567;&#22411;&#22266;&#23450;&#22823;&#23567;&#30340;&#37319;&#26679;&#23376;&#22270;&#36827;&#34892;&#35757;&#32451;&#65292;&#26469;&#35757;&#32451;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#12290;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#21508;&#31181;&#27169;&#22411;&#65292;&#21253;&#25324;&#24120;&#29992;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;GNN&#65292;&#22914;GraphSAGE&#21644;FastGCN&#12290;&#20511;&#21161;&#22270;&#30340;&#23616;&#37096;&#30028;&#38480;&#29702;&#35770;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#36890;&#36807;&#23545;&#22823;&#22411;&#36755;&#20837;&#22270;&#30340;&#23567;&#26679;&#26412;&#36827;&#34892;&#37319;&#26679;&#35757;&#32451;&#30340;&#21442;&#25968;&#19982;&#22312;&#25972;&#20010;&#22270;&#19978;&#35757;&#32451;&#30456;&#21516;&#32467;&#26500;&#30340;&#21442;&#25968;&#22312;&#949;-&#37051;&#22495;&#20869;&#12290;&#25105;&#20204;&#20197;&#949;&#30340;&#20989;&#25968;&#25512;&#23548;&#20986;&#26679;&#26412;&#25968;&#37327;&#12289;&#22270;&#30340;&#22823;&#23567;&#21644;&#35757;&#32451;&#27493;&#39588;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35757;&#32451;GNN&#26102;&#20351;&#29992;&#37319;&#26679;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#23427;&#20204;&#36824;&#26263;&#31034;&#65292;&#36890;&#36807;&#23545;&#36755;&#20837;&#22270;&#30340;&#23567;&#26679;&#26412;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#19994;&#32773;&#21487;&#20197;&#26356;&#39640;&#25928;&#22320;&#35782;&#21035;&#21644;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#12289;&#36229;&#21442;&#25968;&#21644;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a theoretical framework for training Graph Neural Networks (GNNs) on large input graphs via training on small, fixed-size sampled subgraphs. This framework is applicable to a wide range of models, including popular sampling-based GNNs, such as GraphSAGE and FastGCN. Leveraging the theory of graph local limits, we prove that, under mild assumptions, parameters learned from training sampling-based GNNs on small samples of a large input graph are within an $\epsilon$-neighborhood of the outcome of training the same architecture on the whole graph. We derive bounds on the number of samples, the size of the graph, and the training steps required as a function of $\epsilon$. Our results give a novel theoretical understanding for using sampling in training GNNs. They also suggest that by training GNNs on small samples of the input graph, practitioners can identify and select the best models, hyperparameters, and sampling algorithms more efficiently. We empirically illustrate our re
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#30001;&#38750;&#36127;&#38646;&#33192;&#32960;&#36830;&#32493;&#36793;&#26435;&#32452;&#25104;&#30340;&#37051;&#25509;&#30697;&#38453;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#27169;&#25311;&#22269;&#38469;&#36152;&#26131;&#32593;&#32476;&#12290;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;&#33410;&#28857;&#20449;&#24687;&#21644;&#21160;&#24577;&#25928;&#24212;&#65292;&#24182;&#19988;&#21487;&#20197;&#29420;&#31435;&#20110;&#31038;&#21306;&#26631;&#31614;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#12290;&#19968;&#20010;&#39640;&#25928;&#30340;&#20004;&#27493;&#31639;&#27861;&#34987;&#24320;&#21457;&#29992;&#20110;&#20272;&#35745;&#21327;&#21464;&#25928;&#24212;&#21644;&#31038;&#21306;&#26631;&#31614;&#12290;</title><link>http://arxiv.org/abs/2310.10952</link><description>&lt;p&gt;
&#38480;&#21046;&#30340;Tweedie&#38543;&#26426;&#22359;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Restricted Tweedie Stochastic Block Models. (arXiv:2310.10952v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10952
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#30001;&#38750;&#36127;&#38646;&#33192;&#32960;&#36830;&#32493;&#36793;&#26435;&#32452;&#25104;&#30340;&#37051;&#25509;&#30697;&#38453;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#27169;&#25311;&#22269;&#38469;&#36152;&#26131;&#32593;&#32476;&#12290;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;&#33410;&#28857;&#20449;&#24687;&#21644;&#21160;&#24577;&#25928;&#24212;&#65292;&#24182;&#19988;&#21487;&#20197;&#29420;&#31435;&#20110;&#31038;&#21306;&#26631;&#31614;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#12290;&#19968;&#20010;&#39640;&#25928;&#30340;&#20004;&#27493;&#31639;&#27861;&#34987;&#24320;&#21457;&#29992;&#20110;&#20272;&#35745;&#21327;&#21464;&#25928;&#24212;&#21644;&#31038;&#21306;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22359;&#27169;&#22411; (SBM) &#26159;&#22312;&#32593;&#32476;&#20013;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#24191;&#27867;&#24212;&#29992;&#26694;&#26550;&#65292;&#20854;&#20013;&#32593;&#32476;&#32467;&#26500;&#36890;&#24120;&#30001;&#37051;&#25509;&#30697;&#38453;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;SBM&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#30001;&#38750;&#36127;&#30340;&#38646;&#33192;&#32960;&#36830;&#32493;&#36793;&#26435;&#32452;&#25104;&#30340;&#37051;&#25509;&#30697;&#38453;&#12290;&#20026;&#20102;&#27169;&#25311;&#22269;&#38469;&#36152;&#26131;&#32593;&#32476;&#65292;&#20854;&#20013;&#36793;&#26435;&#34920;&#31034;&#22269;&#23478;&#20043;&#38388;&#30340;&#36152;&#26131;&#20215;&#20540;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38480;&#21046;Tweedie&#20998;&#24067;&#30340;&#21019;&#26032;SBM&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#32467;&#21512;&#20102;&#33410;&#28857;&#20449;&#24687;&#65292;&#22914;&#22269;&#23478;&#20043;&#38388;&#30340;&#22320;&#29702;&#36317;&#31163;&#65292;&#24182;&#32771;&#34385;&#20854;&#23545;&#36793;&#26435;&#30340;&#21160;&#24577;&#24433;&#21709;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#33410;&#28857;&#25968;&#36275;&#22815;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;&#20272;&#35745;&#36825;&#20010;&#21327;&#21464;&#25928;&#24212;&#26102;&#65292;&#21487;&#20197;&#29420;&#31435;&#20110;&#27599;&#20010;&#33410;&#28857;&#30340;&#31038;&#21306;&#26631;&#31614;&#65292;&#22312;&#35745;&#31639;&#25105;&#20204;&#27169;&#22411;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#26102;&#12290;&#36825;&#20010;&#32467;&#26524;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#24320;&#21457;&#19968;&#31181;&#39640;&#25928;&#30340;&#20004;&#27493;&#31639;&#27861;&#65292;&#23558;&#21327;&#21464;&#25928;&#24212;&#30340;&#20272;&#35745;&#19982;&#31038;&#21306;&#26631;&#31614;&#30340;&#20272;&#35745;&#20998;&#31163;&#24320;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic block model (SBM) is a widely used framework for community detection in networks, where the network structure is typically represented by an adjacency matrix. However, conventional SBMs are not directly applicable to an adjacency matrix that consists of non-negative zero-inflated continuous edge weights. To model the international trading network, where edge weights represent trading values between countries, we propose an innovative SBM based on a restricted Tweedie distribution. Additionally, we incorporate nodal information, such as the geographical distance between countries, and account for its dynamic effect on edge weights. Notably, we show that given a sufficiently large number of nodes, estimating this covariate effect becomes independent of community labels of each node when computing the maximum likelihood estimator of parameters in our model. This result enables the development of an efficient two-step algorithm that separates the estimation of covariate effe
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#19981;&#36830;&#32493;&#20989;&#25968;&#30340;&#26367;&#20195;&#20027;&#21160;&#23376;&#31354;&#38388;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.10907</link><description>&lt;p&gt;
&#38024;&#23545;&#36339;&#36291;&#19981;&#36830;&#32493;&#20989;&#25968;&#30340;&#26367;&#20195;&#20027;&#21160;&#23376;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Surrogate Active Subspaces for Jump-Discontinuous Functions. (arXiv:2310.10907v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10907
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#19981;&#36830;&#32493;&#20989;&#25968;&#30340;&#26367;&#20195;&#20027;&#21160;&#23376;&#31354;&#38388;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26367;&#20195;&#24314;&#27169;&#21644;&#27963;&#36291;&#23376;&#31354;&#38388;&#24050;&#32463;&#25104;&#20026;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#30340;&#24378;&#22823;&#33539;&#20363;&#12290;&#23558;&#36825;&#20123;&#25216;&#26415;&#24212;&#29992;&#20110;&#31038;&#20250;&#31185;&#23398;&#20013;&#30340;&#35745;&#31639;&#27169;&#22411;&#65292;&#31361;&#26174;&#20102;&#23427;&#20204;&#22312;&#22788;&#29702;&#31163;&#25955;&#36755;&#20986;&#30340;Agent-Based&#27169;&#22411;&#31561;&#19981;&#36830;&#32493;&#27169;&#25311;&#22120;&#26102;&#30340;&#23616;&#38480;&#24615;&#12290;&#28982;&#32780;&#65292;&#20043;&#21069;&#30340;&#24212;&#29992;&#30740;&#31350;&#24050;&#32463;&#34920;&#26126;&#65292;&#23545;&#20110;&#36825;&#31867;&#20272;&#35745;&#22120;&#65292;&#26367;&#20195;&#35745;&#31639;&#30340;&#27963;&#36291;&#23376;&#31354;&#38388;&#21487;&#20197;&#20135;&#29983;&#26377;&#36259;&#30340;&#32467;&#26524;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#27963;&#36291;&#23376;&#31354;&#38388;&#26159;&#36890;&#36807;&#26799;&#24230;&#23450;&#20041;&#30340;&#65292;&#24403;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#19981;&#36830;&#32493;&#27169;&#25311;&#22120;&#26102;&#65292;&#20272;&#35745;&#30340;&#26159;&#20160;&#20040;&#37327;&#36824;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#36827;&#34892;&#27492;&#31867;&#20998;&#26512;&#26102;&#21487;&#33021;&#20986;&#29616;&#30340;&#19968;&#20123;&#30149;&#24577;&#24773;&#20917;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#23558;&#27963;&#36291;&#23376;&#31354;&#38388;&#25193;&#23637;&#21040;&#19981;&#36830;&#32493;&#20989;&#25968;&#19978;&#65292;&#28548;&#28165;&#20102;&#22312;&#27492;&#31867;&#20998;&#26512;&#20013;&#23454;&#38469;&#20272;&#35745;&#30340;&#20869;&#23481;&#12290;&#25105;&#20204;&#36824;&#23545;&#21512;&#25104;&#27979;&#35797;&#20989;&#25968;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#27604;&#36739;&#20102;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#39640;&#26031;&#36807;&#31243;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Surrogate modeling and active subspaces have emerged as powerful paradigms in computational science and engineering. Porting such techniques to computational models in the social sciences brings into sharp relief their limitations in dealing with discontinuous simulators, such as Agent-Based Models, which have discrete outputs. Nevertheless, prior applied work has shown that surrogate estimates of active subspaces for such estimators can yield interesting results. But given that active subspaces are defined by way of gradients, it is not clear what quantity is being estimated when this methodology is applied to a discontinuous simulator. We begin this article by showing some pathologies that can arise when conducting such an analysis. This motivates an extension of active subspaces to discontinuous functions, clarifying what is actually being estimated in such analyses. We also conduct numerical experiments on synthetic test functions to compare Gaussian process estimates of active sub
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#30340;&#20999;&#29255;&#21305;&#37197;&#31639;&#27861;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#28304;&#24230;&#37327;&#12289;&#30446;&#26631;&#24230;&#37327;&#21644;&#20999;&#29255;&#26041;&#21521;&#30456;&#20851;&#30340;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#21253;&#25324;&#19982;&#28304;&#24230;&#37327;&#30456;&#20851;&#30340;&#19981;&#21464;&#24615;&#23646;&#24615;&#12289;&#19982;&#30446;&#26631;&#24230;&#37327;&#30456;&#20851;&#30340;&#31561;&#21464;&#24615;&#23646;&#24615;&#20197;&#21450;&#19982;&#20999;&#29255;&#26041;&#21521;&#30456;&#20851;&#30340;Lipschitz&#36830;&#32493;&#24615;&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#36890;&#36807;&#19968;&#27493;&#20999;&#29255;&#21305;&#37197;&#26041;&#26696;&#36924;&#36817;&#30446;&#26631;&#24230;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#20102;&#20999;&#29255;&#21305;&#37197;&#31639;&#23376;&#24674;&#22797;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2310.10869</link><description>&lt;p&gt;
&#36817;&#20284;&#24615;&#36136;&#30340;&#20999;&#29255;&#21305;&#37197;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Approximation properties of slice-matching operators. (arXiv:2310.10869v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10869
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#30340;&#20999;&#29255;&#21305;&#37197;&#31639;&#27861;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#28304;&#24230;&#37327;&#12289;&#30446;&#26631;&#24230;&#37327;&#21644;&#20999;&#29255;&#26041;&#21521;&#30456;&#20851;&#30340;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#21253;&#25324;&#19982;&#28304;&#24230;&#37327;&#30456;&#20851;&#30340;&#19981;&#21464;&#24615;&#23646;&#24615;&#12289;&#19982;&#30446;&#26631;&#24230;&#37327;&#30456;&#20851;&#30340;&#31561;&#21464;&#24615;&#23646;&#24615;&#20197;&#21450;&#19982;&#20999;&#29255;&#26041;&#21521;&#30456;&#20851;&#30340;Lipschitz&#36830;&#32493;&#24615;&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#36890;&#36807;&#19968;&#27493;&#20999;&#29255;&#21305;&#37197;&#26041;&#26696;&#36924;&#36817;&#30446;&#26631;&#24230;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#20102;&#20999;&#29255;&#21305;&#37197;&#31639;&#23376;&#24674;&#22797;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36845;&#20195;&#30340;&#20999;&#29255;&#21305;&#37197;&#31639;&#27861;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#23558;&#28304;&#24230;&#37327;&#36716;&#25442;&#20026;&#30446;&#26631;&#24230;&#37327;&#30340;&#26041;&#27861;&#65292;&#23588;&#20854;&#36866;&#29992;&#20110;&#39640;&#32500;&#24773;&#20917;&#12290;&#36825;&#20123;&#31639;&#27861;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#39068;&#33394;&#36716;&#25442;&#21644;&#24418;&#29366;&#26816;&#32034;&#31561;&#39046;&#22495;&#65292;&#24182;&#19988;&#22312;&#27491;&#21017;&#24615;&#20551;&#35774;&#19979;&#20445;&#35777;&#25910;&#25947;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#19982;&#28304;&#24230;&#37327;&#12289;&#30446;&#26631;&#24230;&#37327;&#21644;&#20999;&#29255;&#26041;&#21521;&#26377;&#20851;&#30340;&#19968;&#20010;&#30456;&#20851;&#30340;&#20999;&#29255;&#21305;&#37197;&#31639;&#23376;&#65292;&#25506;&#35752;&#20102;&#36825;&#20123;&#36845;&#20195;&#26041;&#26696;&#30340;&#21333;&#27493;&#36817;&#20284;&#24615;&#36136;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;&#28304;&#24230;&#37327;&#30456;&#20851;&#30340;&#19981;&#21464;&#24615;&#23646;&#24615;&#65292;&#19982;&#30446;&#26631;&#24230;&#37327;&#30456;&#20851;&#30340;&#31561;&#21464;&#24615;&#23646;&#24615;&#20197;&#21450;&#19982;&#20999;&#29255;&#26041;&#21521;&#30456;&#20851;&#30340;Lipschitz&#36830;&#32493;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#36890;&#36807;&#19968;&#27493;&#20999;&#29255;&#21305;&#37197;&#26041;&#26696;&#36924;&#36817;&#30446;&#26631;&#24230;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#34920;&#24449;&#20102;&#20999;&#29255;&#21305;&#37197;&#31639;&#23376;&#22312;&#24674;&#22797;&#20004;&#20010;&#24230;&#37327;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Iterative slice-matching procedures are efficient schemes for transferring a source measure to a target measure, especially in high dimensions. These schemes have been successfully used in applications such as color transfer and shape retrieval, and are guaranteed to converge under regularity assumptions. In this paper, we explore approximation properties related to a single step of such iterative schemes by examining an associated slice-matching operator, depending on a source measure, a target measure, and slicing directions. In particular, we demonstrate an invariance property with respect to the source measure, an equivariance property with respect to the target measure, and Lipschitz continuity concerning the slicing directions. We furthermore establish error bounds corresponding to approximating the target measure by one step of the slice-matching scheme and characterize situations in which the slice-matching operator recovers the optimal transport map between two measures. We al
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#36827;&#34892;&#27010;&#29575;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#33945;&#29305;&#21345;&#27931;&#33258;&#22238;&#24402;&#27969;&#23545;&#25968;&#25454;&#30340;&#20284;&#28982;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#30340;&#20998;&#31867;&#22120;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#22522;&#20110;&#32852;&#21512;&#23494;&#24230;&#20272;&#35745;&#30340;&#20854;&#20182;&#27010;&#29575;&#20998;&#31867;&#22120;&#30340;&#25552;&#20986;&#24320;&#36767;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2310.10843</link><description>&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#33945;&#29305;&#21345;&#27931;&#33258;&#22238;&#24402;&#27969;&#36827;&#34892;&#27010;&#29575;&#20998;&#31867;&#30340;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Classification by Density Estimation Using Gaussian Mixture Model and Masked Autoregressive Flow. (arXiv:2310.10843v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#36827;&#34892;&#27010;&#29575;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#33945;&#29305;&#21345;&#27931;&#33258;&#22238;&#24402;&#27969;&#23545;&#25968;&#25454;&#30340;&#20284;&#28982;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#30340;&#20998;&#31867;&#22120;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#22522;&#20110;&#32852;&#21512;&#23494;&#24230;&#20272;&#35745;&#30340;&#20854;&#20182;&#27010;&#29575;&#20998;&#31867;&#22120;&#30340;&#25552;&#20986;&#24320;&#36767;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#24230;&#20272;&#35745;&#26159;&#19968;&#31867;&#37325;&#35201;&#30340;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#65292;&#23427;&#29992;&#20110;&#20272;&#35745;&#25968;&#25454;&#30340;&#20998;&#24067;&#12290;&#20854;&#20013;&#19968;&#31867;&#23494;&#24230;&#20272;&#35745;&#22120;&#26159;&#28151;&#21512;&#27169;&#22411;&#65292;&#22914;&#36890;&#36807;&#26399;&#26395;&#26368;&#22823;&#21270;&#24471;&#21040;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#12290;&#21478;&#19968;&#31867;&#23494;&#24230;&#20272;&#35745;&#22120;&#26159;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#20204;&#20174;&#36755;&#20837;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#25968;&#25454;&#12290;&#20854;&#20013;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#26159;&#33945;&#29305;&#21345;&#27931;&#33258;&#22238;&#24402;&#27969;&#65288;MAF&#65289;&#65292;&#23427;&#21033;&#29992;&#24402;&#19968;&#21270;&#27969;&#21644;&#33258;&#22238;&#24402;&#32593;&#32476;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#23494;&#24230;&#20272;&#35745;&#22120;&#29992;&#20110;&#20998;&#31867;&#65292;&#23613;&#31649;&#23427;&#20204;&#36890;&#24120;&#29992;&#20110;&#20272;&#35745;&#25968;&#25454;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#22120;&#65288;&#20855;&#20307;&#26469;&#35828;&#26159;GMM&#21644;MAF&#65289;&#23545;&#25968;&#25454;&#30340;&#31867;&#21035;&#30340;&#20284;&#28982;&#36827;&#34892;&#24314;&#27169;&#12290;&#25152;&#25552;&#20986;&#30340;&#20998;&#31867;&#22120;&#20248;&#20110;&#20165;&#20351;&#29992;&#21333;&#20010;&#39640;&#26031;&#20998;&#24067;&#23545;&#20284;&#28982;&#36827;&#34892;&#24314;&#27169;&#30340;&#36739;&#31616;&#21333;&#30340;&#20998;&#31867;&#22120;&#65292;&#22914;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#25552;&#20986;&#22522;&#20110;&#32852;&#21512;&#23494;&#24230;&#20272;&#35745;&#30340;&#20854;&#20182;&#27010;&#29575;&#20998;&#31867;&#22120;&#24320;&#36767;&#20102;&#30740;&#31350;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Density estimation, which estimates the distribution of data, is an important category of probabilistic machine learning. A family of density estimators is mixture models, such as Gaussian Mixture Model (GMM) by expectation maximization. Another family of density estimators is the generative models which generate data from input latent variables. One of the generative models is the Masked Autoregressive Flow (MAF) which makes use of normalizing flows and autoregressive networks. In this paper, we use the density estimators for classification, although they are often used for estimating the distribution of data. We model the likelihood of classes of data by density estimation, specifically using GMM and MAF. The proposed classifiers outperform simpler classifiers such as linear discriminant analysis which model the likelihood using only a single Gaussian distribution. This work opens the research door for proposing other probabilistic classifiers based on joint density estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#23545;&#25239;&#35757;&#32451;&#32447;&#24615;&#22238;&#24402;&#30340;&#27491;&#21017;&#21270;&#24615;&#36136;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#23545;&#25239;&#35757;&#32451;&#21487;&#20197;&#24471;&#21040;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#35299;&#65292;&#36825;&#19968;&#21457;&#29616;&#23545;&#29702;&#35299;&#23545;&#25239;&#35757;&#32451;&#30340;&#25928;&#26524;&#21644;&#24212;&#29992;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.10807</link><description>&lt;p&gt;
&#23545;&#23545;&#25239;&#35757;&#32451;&#32447;&#24615;&#22238;&#24402;&#30340;&#27491;&#21017;&#21270;&#24615;&#36136;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Regularization properties of adversarially-trained linear regression. (arXiv:2310.10807v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#23545;&#25239;&#35757;&#32451;&#32447;&#24615;&#22238;&#24402;&#30340;&#27491;&#21017;&#21270;&#24615;&#36136;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#23545;&#25239;&#35757;&#32451;&#21487;&#20197;&#24471;&#21040;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#35299;&#65292;&#36825;&#19968;&#21457;&#29616;&#23545;&#29702;&#35299;&#23545;&#25239;&#35757;&#32451;&#30340;&#25928;&#26524;&#21644;&#24212;&#29992;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#20110;&#30001;&#23545;&#25163;&#26500;&#36896;&#30340;&#38750;&#24120;&#23567;&#30340;&#36755;&#20837;&#25200;&#21160;&#21487;&#33021;&#23384;&#22312;&#28431;&#27934;&#12290;&#23545;&#25239;&#35757;&#32451;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#38450;&#24481;&#26041;&#27861;&#12290;&#23427;&#23558;&#38382;&#39064;&#24314;&#27169;&#20026;&#19968;&#20010;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#21463;&#21040;&#26368;&#22351;&#24773;&#20917;&#25915;&#20987;&#26102;&#23547;&#25214;&#26368;&#20339;&#35299;&#20915;&#26041;&#26696;&#12290;&#32447;&#24615;&#27169;&#22411;&#26159;&#21487;&#20197;&#35266;&#23519;&#21040;&#28431;&#27934;&#30340;&#31616;&#21333;&#27169;&#22411;&#65292;&#20063;&#26159;&#25105;&#20204;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23545;&#25239;&#35757;&#32451;&#23548;&#33268;&#19968;&#20010;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#24418;&#24335;&#21270;&#20026;&#26377;&#38480;&#21644;&#30340;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#23545;&#32447;&#24615;&#22238;&#24402;&#20013;&#23545;&#25239;&#35757;&#32451;&#30340;&#35299;&#19982;&#20854;&#20182;&#27491;&#21017;&#21270;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21457;&#29616;&#26159;&#65306;&#65288;A&#65289;&#21482;&#35201;&#26368;&#22823;&#25200;&#21160;&#21322;&#24452;&#23567;&#20110;&#38408;&#20540;&#65292;&#23545;&#25239;&#35757;&#32451;&#21487;&#20197;&#24471;&#21040;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65288;&#21442;&#25968;&#25968;&#30446;&#22823;&#20110;&#25968;&#25454;&#25968;&#30446;&#65289;&#30340;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#35299;&#65307;&#30456;&#21453;&#65292;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#22120;&#23601;&#26159;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#24471;&#21040;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art machine learning models can be vulnerable to very small input perturbations that are adversarially constructed. Adversarial training is an effective approach to defend against it. Formulated as a min-max problem, it searches for the best solution when the training data were corrupted by the worst-case attacks. Linear models are among the simple models where vulnerabilities can be observed and are the focus of our study. In this case, adversarial training leads to a convex optimization problem which can be formulated as the minimization of a finite sum. We provide a comparative analysis between the solution of adversarial training in linear regression and other regularization methods. Our main findings are that: (A) Adversarial training yields the minimum-norm interpolating solution in the overparameterized regime (more parameters than data), as long as the maximum disturbance radius is smaller than a threshold. And, conversely, the minimum-norm interpolator is the solu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#20999;&#21521;&#26680;&#20989;&#25968;&#65288;NTKs&#65289;&#22312;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#21457;&#29616;&#20248;&#21270;&#23545;&#40784;&#31561;&#20215;&#20110;&#20248;&#21270;GNN&#20013;&#30340;&#22270;&#34920;&#31034;&#25110;&#22270;&#31227;&#20301;&#36816;&#31639;&#31526;&#65292;&#24182;&#24314;&#31435;&#20102;&#23545;&#20110;&#20004;&#23618;GNN&#23545;&#40784;&#30340;&#26368;&#20248;&#24615;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10791</link><description>&lt;p&gt;
&#31070;&#32463;&#20999;&#21521;&#26680;&#20989;&#25968;&#20026;&#20855;&#26377;&#20132;&#21449;&#21327;&#26041;&#24046;&#22270;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Neural Tangent Kernels Motivate Graph Neural Networks with Cross-Covariance Graphs. (arXiv:2310.10791v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#20999;&#21521;&#26680;&#20989;&#25968;&#65288;NTKs&#65289;&#22312;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#21457;&#29616;&#20248;&#21270;&#23545;&#40784;&#31561;&#20215;&#20110;&#20248;&#21270;GNN&#20013;&#30340;&#22270;&#34920;&#31034;&#25110;&#22270;&#31227;&#20301;&#36816;&#31639;&#31526;&#65292;&#24182;&#24314;&#31435;&#20102;&#23545;&#20110;&#20004;&#23618;GNN&#23545;&#40784;&#30340;&#26368;&#20248;&#24615;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20999;&#21521;&#26680;&#20989;&#25968;&#65288;NTKs&#65289;&#25552;&#20379;&#20102;&#20998;&#26512;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21644;&#27867;&#21270;&#34892;&#20026;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#23545;&#20110;&#26377;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#65292;NTK&#26680;&#20989;&#25968;&#30340;&#29305;&#24449;&#21521;&#37327;&#19982;&#32473;&#23450;&#25968;&#25454;&#20043;&#38388;&#30340;&#20851;&#32852;&#65288;&#22312;&#26412;&#25991;&#20013;&#31216;&#20026;&#23545;&#40784;&#65289;&#21487;&#20197;&#25511;&#21046;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#20197;&#21450;&#23545;&#26410;&#35265;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#36825;&#20010;&#27010;&#24565;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;NTKs&#21644;&#23545;&#40784;&#22312;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#32972;&#26223;&#19979;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#20248;&#21270;&#23545;&#40784;&#31561;&#20215;&#20110;&#20248;&#21270;GNN&#20013;&#30340;&#22270;&#34920;&#31034;&#25110;&#22270;&#31227;&#20301;&#36816;&#31639;&#31526;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36827;&#19968;&#27493;&#24314;&#31435;&#20102;&#23545;&#20110;&#20004;&#23618;GNN&#23545;&#40784;&#30340;&#26368;&#20248;&#24615;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#30001;&#22270;&#31227;&#20301;&#36816;&#31639;&#31526;&#20316;&#20026;&#36755;&#20837;&#21644;&#36755;&#20986;&#25968;&#25454;&#20043;&#38388;&#30340;&#20132;&#21449;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#20989;&#25968;&#25152;&#20915;&#23450;&#12290;&#36890;&#36807;&#23545;NTKs&#30340;&#20998;&#26512;&#24471;&#20986;&#30340;&#29702;&#35770;&#27934;&#23519;&#21147;&#65292;&#36890;&#36807;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#20123;&#27934;&#23519;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural tangent kernels (NTKs) provide a theoretical regime to analyze the learning and generalization behavior of over-parametrized neural networks. For a supervised learning task, the association between the eigenvectors of the NTK kernel and given data (a concept referred to as alignment in this paper) can govern the rate of convergence of gradient descent, as well as generalization to unseen data. Building upon this concept, we investigate NTKs and alignment in the context of graph neural networks (GNNs), where our analysis reveals that optimizing alignment translates to optimizing the graph representation or the graph shift operator in a GNN. Our results further establish the theoretical guarantees on the optimality of the alignment for a two-layer GNN and these guarantees are characterized by the graph shift operator being a function of the cross-covariance between the input and the output data. The theoretical insights drawn from the analysis of NTKs are validated by our experime
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#24191;&#20041;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#21457;&#29616;&#20855;&#26377;&#26080;&#38480;&#28145;&#24230;&#23618;&#24182;&#19988;&#23485;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#65292;&#25581;&#31034;&#20102;&#24191;&#20041;&#31070;&#32463;&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2310.10767</link><description>&lt;p&gt;
&#24191;&#20041;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#39640;&#26031;&#36807;&#31243;&#65306;&#26469;&#33258;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#30340;&#21551;&#31034;
&lt;/p&gt;
&lt;p&gt;
Wide Neural Networks as Gaussian Processes: Lessons from Deep Equilibrium Models. (arXiv:2310.10767v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#24191;&#20041;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#21457;&#29616;&#20855;&#26377;&#26080;&#38480;&#28145;&#24230;&#23618;&#24182;&#19988;&#23485;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#65292;&#25581;&#31034;&#20102;&#24191;&#20041;&#31070;&#32463;&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#23485;&#24230;&#23618;&#30340;&#31070;&#32463;&#32593;&#32476;&#30001;&#20110;&#19982;&#39640;&#26031;&#36807;&#31243;&#30340;&#31561;&#20215;&#24615;&#32780;&#21463;&#21040;&#26497;&#22823;&#20851;&#27880;&#65292;&#22312;&#20445;&#25345;&#27867;&#21270;&#24615;&#33021;&#30340;&#21516;&#26102;&#23436;&#32654;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#65292;&#36825;&#34987;&#31216;&#20026;&#33391;&#24615;&#36807;&#25311;&#21512;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#32467;&#26524;&#20027;&#35201;&#38598;&#20013;&#22312;&#27973;&#23618;&#25110;&#26377;&#38480;&#28145;&#24230;&#30340;&#32593;&#32476;&#19978;&#65292;&#38656;&#35201;&#23545;&#20855;&#26377;&#26080;&#38480;&#28145;&#24230;&#23618;&#30340;&#24191;&#20041;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20840;&#38754;&#20998;&#26512;&#65292;&#20363;&#22914;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;(ODE)&#21644;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;(DEQ)&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#29305;&#21035;&#30740;&#31350;&#20102;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;(DEQ)&#65292;&#23427;&#26159;&#19968;&#20010;&#20855;&#26377;&#20849;&#20139;&#26435;&#37325;&#30697;&#38453;&#30340;&#26080;&#38480;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#24403;DEQ&#23618;&#30340;&#23485;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#23427;&#25910;&#25947;&#21040;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#25152;&#35859;&#30340;&#31070;&#32463;&#32593;&#32476;&#19982;&#39640;&#26031;&#36807;&#31243;(NNGP)&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#21363;&#20351;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#26497;&#38480;&#20114;&#25442;&#65292;&#22312;&#20856;&#22411;&#30340;&#26080;&#38480;&#28145;&#24230;&#22810;&#23618;&#32593;&#32476;&#20013;&#20063;&#19981;&#20250;&#35266;&#23519;&#21040;&#36825;&#31181;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks with wide layers have attracted significant attention due to their equivalence to Gaussian processes, enabling perfect fitting of training data while maintaining generalization performance, known as benign overfitting. However, existing results mainly focus on shallow or finite-depth networks, necessitating a comprehensive analysis of wide neural networks with infinite-depth layers, such as neural ordinary differential equations (ODEs) and deep equilibrium models (DEQs). In this paper, we specifically investigate the deep equilibrium model (DEQ), an infinite-depth neural network with shared weight matrices across layers. Our analysis reveals that as the width of DEQ layers approaches infinity, it converges to a Gaussian process, establishing what is known as the Neural Network and Gaussian Process (NNGP) correspondence. Remarkably, this convergence holds even when the limits of depth and width are interchanged, which is not observed in typical infinite-depth Multilayer 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Mori-Zwanzig&#33258;&#32534;&#30721;&#22120;&#65288;MZ-AE&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20302;&#32500;&#31354;&#38388;&#20013;&#31283;&#20581;&#22320;&#36924;&#36817;Koopman&#31639;&#23376;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#33258;&#32534;&#30721;&#22120;&#21644;Mori-Zwanzig&#24418;&#24335;&#20027;&#20041;&#30340;&#38598;&#25104;&#23454;&#29616;&#23545;&#26377;&#38480;&#19981;&#21464;Koopman&#23376;&#31354;&#38388;&#30340;&#36924;&#36817;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#31934;&#30830;&#24615;&#21644;&#20934;&#30830;&#39044;&#27979;&#22797;&#26434;&#31995;&#32479;&#34892;&#20026;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.10745</link><description>&lt;p&gt;
Mori-Zwanzig&#28508;&#21464;&#31354;&#38388;Koopman&#38381;&#21253;&#29992;&#20110;&#38750;&#32447;&#24615;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Mori-Zwanzig latent space Koopman closure for nonlinear autoencoder. (arXiv:2310.10745v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Mori-Zwanzig&#33258;&#32534;&#30721;&#22120;&#65288;MZ-AE&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20302;&#32500;&#31354;&#38388;&#20013;&#31283;&#20581;&#22320;&#36924;&#36817;Koopman&#31639;&#23376;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#33258;&#32534;&#30721;&#22120;&#21644;Mori-Zwanzig&#24418;&#24335;&#20027;&#20041;&#30340;&#38598;&#25104;&#23454;&#29616;&#23545;&#26377;&#38480;&#19981;&#21464;Koopman&#23376;&#31354;&#38388;&#30340;&#36924;&#36817;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#31934;&#30830;&#24615;&#21644;&#20934;&#30830;&#39044;&#27979;&#22797;&#26434;&#31995;&#32479;&#34892;&#20026;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Koopman&#31639;&#23376;&#25552;&#20379;&#20102;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#20840;&#23616;&#32447;&#24615;&#21270;&#65292;&#20351;&#20854;&#25104;&#20026;&#31616;&#21270;&#22797;&#26434;&#21160;&#21147;&#23398;&#29702;&#35299;&#30340;&#23453;&#36149;&#26041;&#27861;&#12290;&#34429;&#28982;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#22312;&#36924;&#36817;&#26377;&#38480;Koopman&#31639;&#23376;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#28508;&#21147;&#65292;&#20294;&#23427;&#20204;&#38754;&#20020;&#30528;&#21508;&#31181;&#25361;&#25112;&#65292;&#20363;&#22914;&#36873;&#25321;&#21512;&#36866;&#30340;&#21487;&#35266;&#23519;&#37327;&#12289;&#38477;&#32500;&#21644;&#20934;&#30830;&#39044;&#27979;&#22797;&#26434;&#31995;&#32479;&#34892;&#20026;&#30340;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Mori-Zwanzig&#33258;&#32534;&#30721;&#22120;&#65288;MZ-AE&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20302;&#32500;&#31354;&#38388;&#20013;&#31283;&#20581;&#22320;&#36924;&#36817;Koopman&#31639;&#23376;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#38750;&#32447;&#24615;&#33258;&#32534;&#30721;&#22120;&#25552;&#21462;&#20851;&#38190;&#21487;&#35266;&#23519;&#37327;&#26469;&#36924;&#36817;&#26377;&#38480;&#19981;&#21464;Koopman&#23376;&#31354;&#38388;&#65292;&#24182;&#21033;&#29992;Mori-Zwanzig&#24418;&#24335;&#20027;&#20041;&#38598;&#25104;&#38750;&#39532;&#23572;&#21487;&#22827;&#26657;&#27491;&#26426;&#21046;&#12290;&#22240;&#27492;&#65292;&#35813;&#26041;&#27861;&#22312;&#38750;&#32447;&#24615;&#33258;&#32534;&#30721;&#22120;&#30340;&#28508;&#21464;&#27969;&#24418;&#20013;&#20135;&#29983;&#20102;&#21160;&#21147;&#23398;&#30340;&#23553;&#38381;&#34920;&#31034;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#31934;&#30830;&#24615;&#21644;...
&lt;/p&gt;
&lt;p&gt;
The Koopman operator presents an attractive approach to achieve global linearization of nonlinear systems, making it a valuable method for simplifying the understanding of complex dynamics. While data-driven methodologies have exhibited promise in approximating finite Koopman operators, they grapple with various challenges, such as the judicious selection of observables, dimensionality reduction, and the ability to predict complex system behaviours accurately. This study presents a novel approach termed Mori-Zwanzig autoencoder (MZ-AE) to robustly approximate the Koopman operator in low-dimensional spaces. The proposed method leverages a nonlinear autoencoder to extract key observables for approximating a finite invariant Koopman subspace and integrates a non-Markovian correction mechanism using the Mori-Zwanzig formalism. Consequently, this approach yields a closed representation of dynamics within the latent manifold of the nonlinear autoencoder, thereby enhancing the precision and s
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;TacticAI&#65292;&#19968;&#31181;&#19982;&#21033;&#29289;&#28006;&#36275;&#29699;&#20465;&#20048;&#37096;&#30340;&#39046;&#22495;&#19987;&#23478;&#23494;&#20999;&#21512;&#20316;&#24320;&#21457;&#21644;&#35780;&#20215;&#30340;AI&#36275;&#29699;&#25112;&#26415;&#21161;&#25163;&#12290;TacticAI&#33021;&#22815;&#36890;&#36807;&#39044;&#27979;&#21644;&#29983;&#25104;&#30340;&#26041;&#24335;&#24110;&#21161;&#25945;&#32451;&#20204;&#20998;&#26512;&#35282;&#29699;&#24773;&#20917;&#65292;&#24182;&#20026;&#27599;&#20010;&#35282;&#29699;&#24815;&#20363;&#36873;&#25321;&#25104;&#21151;&#21487;&#33021;&#24615;&#26368;&#39640;&#30340;&#29699;&#21592;&#37197;&#32622;&#12290;</title><link>http://arxiv.org/abs/2310.10553</link><description>&lt;p&gt;
TacticAI:&#19968;&#31181;&#36275;&#29699;&#25112;&#26415;&#30340;&#20154;&#24037;&#26234;&#33021;&#21161;&#25163;
&lt;/p&gt;
&lt;p&gt;
TacticAI: an AI assistant for football tactics. (arXiv:2310.10553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10553
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;TacticAI&#65292;&#19968;&#31181;&#19982;&#21033;&#29289;&#28006;&#36275;&#29699;&#20465;&#20048;&#37096;&#30340;&#39046;&#22495;&#19987;&#23478;&#23494;&#20999;&#21512;&#20316;&#24320;&#21457;&#21644;&#35780;&#20215;&#30340;AI&#36275;&#29699;&#25112;&#26415;&#21161;&#25163;&#12290;TacticAI&#33021;&#22815;&#36890;&#36807;&#39044;&#27979;&#21644;&#29983;&#25104;&#30340;&#26041;&#24335;&#24110;&#21161;&#25945;&#32451;&#20204;&#20998;&#26512;&#35282;&#29699;&#24773;&#20917;&#65292;&#24182;&#20026;&#27599;&#20010;&#35282;&#29699;&#24815;&#20363;&#36873;&#25321;&#25104;&#21151;&#21487;&#33021;&#24615;&#26368;&#39640;&#30340;&#29699;&#21592;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36776;&#21035;&#23545;&#25163;&#22242;&#38431;&#23454;&#26045;&#30340;&#25112;&#26415;&#20851;&#38190;&#27169;&#24335;&#24182;&#24320;&#21457;&#26377;&#25928;&#30340;&#24212;&#23545;&#26041;&#27861;&#26159;&#29616;&#20195;&#36275;&#29699;&#30340;&#26680;&#24515;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20197;&#31639;&#27861;&#30340;&#26041;&#24335;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#20173;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#30740;&#31350;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TacticAI&#65292;&#19968;&#31181;&#19982;&#21033;&#29289;&#28006;&#36275;&#29699;&#20465;&#20048;&#37096;&#30340;&#39046;&#22495;&#19987;&#23478;&#23494;&#20999;&#21512;&#20316;&#24320;&#21457;&#21644;&#35780;&#20215;&#30340;AI&#36275;&#29699;&#25112;&#26415;&#21161;&#25163;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20998;&#26512;&#35282;&#29699;&#65292;&#22240;&#20026;&#23427;&#20204;&#32473;&#25945;&#32451;&#20204;&#25552;&#20379;&#20102;&#30452;&#25509;&#30340;&#24178;&#39044;&#21644;&#25913;&#36827;&#26426;&#20250;&#12290;TacticAI&#21253;&#21547;&#20102;&#19968;&#20010;&#39044;&#27979;&#21644;&#29983;&#25104;&#30340;&#32452;&#20214;&#65292;&#20351;&#25945;&#32451;&#33021;&#22815;&#26377;&#25928;&#22320;&#37319;&#26679;&#21644;&#25506;&#32034;&#27599;&#20010;&#35282;&#29699;&#24815;&#20363;&#30340;&#26367;&#20195;&#29699;&#21592;&#37197;&#32622;&#65292;&#24182;&#36873;&#25321;&#37027;&#20123;&#39044;&#27979;&#25104;&#21151;&#21487;&#33021;&#24615;&#26368;&#39640;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20123;&#30456;&#20851;&#30340;&#22522;&#20934;&#20219;&#21153;&#23545;TacticAI&#36827;&#34892;&#20102;&#39564;&#35777;&#65306;&#39044;&#27979;&#25509;&#25910;&#29699;&#21592;&#21644;&#23556;&#38376;&#23581;&#35797;&#20197;&#21450;&#25512;&#33616;&#29699;&#21592;&#20301;&#32622;&#35843;&#25972;&#12290;TacticAI&#30340;&#23454;&#29992;&#24615;&#36890;&#36807;&#19982;&#21033;&#29289;&#28006;&#36275;&#29699;&#39046;&#22495;&#19987;&#23478;&#36827;&#34892;&#30340;&#23450;&#24615;&#30740;&#31350;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying key patterns of tactics implemented by rival teams, and developing effective responses, lies at the heart of modern football. However, doing so algorithmically remains an open research challenge. To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC. We focus on analysing corner kicks, as they offer coaches the most direct opportunities for interventions and improvements. TacticAI incorporates both a predictive and a generative component, allowing the coaches to effectively sample and explore alternative player setups for each corner kick routine and to select those with the highest predicted likelihood of success. We validate TacticAI on a number of relevant benchmark tasks: predicting receivers and shot attempts and recommending player position adjustments. The utility of TacticAI is validated by a qualitative study conducted with football domain experts at Liv
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39046;&#22495;&#20013;&#20174;&#25945;&#24072;&#21040;&#23398;&#29983;&#20998;&#31867;&#22120;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21457;&#29616;&#29305;&#26435;&#20449;&#24687;&#20250;&#21152;&#36895;&#20256;&#36882;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25439;&#22833;&#20989;&#25968;&#36798;&#21040;&#20102;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.07838</link><description>&lt;p&gt;
&#25506;&#32034;&#26377;&#38480;&#39046;&#22495;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Towards the Fundamental Limits of Knowledge Transfer over Finite Domains. (arXiv:2310.07838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39046;&#22495;&#20013;&#20174;&#25945;&#24072;&#21040;&#23398;&#29983;&#20998;&#31867;&#22120;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21457;&#29616;&#29305;&#26435;&#20449;&#24687;&#20250;&#21152;&#36895;&#20256;&#36882;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25439;&#22833;&#20989;&#25968;&#36798;&#21040;&#20102;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#36890;&#36807;&#20174;&#25945;&#24072;&#21040;&#27010;&#29575;&#21270;&#23398;&#29983;&#20998;&#31867;&#22120;&#30340;n&#20010;&#26679;&#26412;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20854;&#20013;&#36755;&#20837;&#31354;&#38388;S&#21644;&#26631;&#31614;A&#20026;&#26377;&#38480;&#22495;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19977;&#20010;&#28176;&#36827;&#32423;&#21035;&#19978;&#30340;&#29305;&#26435;&#20449;&#24687;&#21487;&#20197;&#21152;&#24555;&#20256;&#36882;&#30340;&#36895;&#24230;&#12290;&#22312;&#31532;&#19968;&#32423;&#21035;&#19978;&#65292;&#21482;&#26377;&#20855;&#26377;&#22256;&#38590;&#26631;&#31614;&#30340;&#26679;&#26412;&#26159;&#24050;&#30693;&#30340;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#33021;&#22815;&#36798;&#21040;&#26368;&#23567;&#21270;&#36895;&#29575;sqrt(|S||A|/n)&#12290;&#31532;&#20108;&#32423;&#21035;&#19978;&#65292;&#38500;&#20102;&#24050;&#30693;&#30340;&#22256;&#38590;&#26631;&#31614;&#26679;&#26412;&#22806;&#65292;&#36824;&#26377;&#37319;&#26679;&#26631;&#31614;&#30340;&#25945;&#24072;&#27010;&#29575;&#21487;&#29992;&#65292;&#36825;&#23558;&#25910;&#25947;&#36895;&#24230;&#30340;&#19979;&#30028;&#25552;&#39640;&#21040;|S||A|/n&#12290;&#28982;&#32780;&#65292;&#22312;&#31532;&#20108;&#20010;&#25968;&#25454;&#37319;&#38598;&#21327;&#35758;&#19979;&#65292;&#26368;&#23567;&#21270;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26420;&#32032;&#36866;&#24212;&#20250;&#23548;&#33268;&#28176;&#36817;&#20559;&#24046;&#30340;&#23398;&#29983;&#12290;&#25105;&#20204;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#32463;&#39564;&#21464;&#20307;&#30340;&#24179;&#26041;&#35823;&#24046;&#36923;&#36753;&#25439;&#22833;&#26469;&#23454;&#29616;&#20102;&#22522;&#26412;&#38480;&#21046;&#12290;&#31532;&#19977;&#32423;&#21035;&#36827;&#19968;&#27493;&#36171;&#20104;&#23398;&#29983;&#36719;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterize the statistical efficiency of knowledge transfer through $n$ samples from a teacher to a probabilistic student classifier with input space $\mathcal S$ over labels $\mathcal A$. We show that privileged information at three progressive levels accelerates the transfer. At the first level, only samples with hard labels are known, via which the maximum likelihood estimator attains the minimax rate $\sqrt{{|{\mathcal S}||{\mathcal A}|}/{n}}$. The second level has the teacher probabilities of sampled labels available in addition, which turns out to boost the convergence rate lower bound to ${{|{\mathcal S}||{\mathcal A}|}/{n}}$. However, under this second data acquisition protocol, minimizing a naive adaptation of the cross-entropy loss results in an asymptotically biased student. We overcome this limitation and achieve the fundamental limit by using a novel empirical variant of the squared error logit loss. The third level further equips the student with the soft labels (com
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.14872</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#24179;&#34913;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#20960;&#20309;&#24863;&#30693;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14872
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21463;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#34920;&#29616;&#33391;&#22909;&#30340;&#23454;&#35777;&#24615;&#33021;&#19982;&#24754;&#35266;&#29702;&#35770;&#21518;&#24724;&#30028;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#21551;&#21457;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#21253;&#25324;&#36138;&#24515;&#12289;OFUL&#21644;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#22312;&#20869;&#30340;&#24191;&#27867;&#31639;&#27861;&#31867;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#22312;&#20445;&#30041;&#22522;&#26412;&#31639;&#27861;&#22823;&#37096;&#20998;&#20248;&#33391;&#29305;&#24615;&#30340;&#21516;&#26102;&#8220;&#26657;&#27491;&#8221;&#22522;&#26412;&#31639;&#27861;&#22312;&#26576;&#20123;&#23454;&#20363;&#20013;&#34920;&#29616;&#24046;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#28176;&#36817;&#26368;&#20248;&#21518;&#24724;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#31639;&#27861;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#36798;&#21040;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#30340;&#21516;&#26102;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2306.03955</link><description>&lt;p&gt;
&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Kernel Quadrature with Randomly Pivoted Cholesky. (arXiv:2306.03955v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03955
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#31639;&#27861;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#36798;&#21040;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#30340;&#21516;&#26102;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#37319;&#26679;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20989;&#25968;&#27714;&#31215;&#35268;&#21017;&#12290;&#25152;&#24471;&#30340;&#35745;&#31639;&#36807;&#31243;&#19982;&#26082;&#26377;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#31934;&#24230;&#21644;&#27714;&#35299;&#22797;&#26434;&#24230;&#26041;&#38754;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#24555;&#36895;&#19988;&#20855;&#26377;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#65292;&#19982;&#22522;&#20110;&#36830;&#32493;&#20307;&#31215;&#37319;&#26679;&#12289;&#31232;&#30095;&#21270;&#21644;&#37325;&#32452;&#30340;&#26356;&#20026;&#26114;&#36149;&#30340;&#27714;&#31215;&#26041;&#26696;&#30456;&#21305;&#37197;&#12290;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#26131;&#20110;&#36866;&#24212;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#65292;&#20026;&#26680;&#27714;&#31215;&#24320;&#36767;&#20102;&#26032;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents new quadrature rules for functions in a reproducing kernel Hilbert space using nodes drawn by a sampling algorithm known as randomly pivoted Cholesky. The resulting computational procedure compares favorably to previous kernel quadrature methods, which either achieve low accuracy or require solving a computationally challenging sampling problem. Theoretical and numerical results show that randomly pivoted Cholesky is fast and achieves comparable quadrature error rates to more computationally expensive quadrature schemes based on continuous volume sampling, thinning, and recombination. Randomly pivoted Cholesky is easily adapted to complicated geometries with arbitrary kernels, unlocking new potential for kernel quadrature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#19979;&#30028;&#65292;&#25506;&#35752;&#20102;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#26102;&#38656;&#35201;&#30340;&#26679;&#26412;&#25968;&#37327;&#21450;&#20854;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.16014</link><description>&lt;p&gt;
&#24403;&#21069;&#26426;&#22120;&#23398;&#20064;&#38656;&#35201;&#22810;&#23569;&#26679;&#26412;&#25165;&#33021;&#21033;&#29992;&#24179;&#28369;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
How many samples are needed to leverage smoothness?. (arXiv:2305.16014v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#19979;&#30028;&#65292;&#25506;&#35752;&#20102;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#26102;&#38656;&#35201;&#30340;&#26679;&#26412;&#25968;&#37327;&#21450;&#20854;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#30340;&#26680;&#24515;&#21407;&#21017;&#20043;&#19968;&#26159;&#65292;&#30446;&#26631;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#21487;&#20197;&#25171;&#30772;&#32500;&#24230;&#28798;&#38590;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#27888;&#21202;&#23637;&#24320;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#38656;&#35201;&#36275;&#22815;&#25509;&#36817;&#19968;&#36215;&#30340;&#26679;&#26412;&#26469;&#33719;&#24471;&#39640;&#38454;&#23548;&#25968;&#30340;&#26377;&#24847;&#20041;&#20272;&#35745;&#65292;&#36825;&#22312;&#25968;&#25454;&#37327;&#30456;&#23545;&#36739;&#23567;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#20284;&#20046;&#24456;&#22256;&#38590;&#12290;&#26412;&#25991;&#36890;&#36807;&#25512;&#23548;&#24191;&#20041;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#30340;&#19979;&#30028;&#65292;&#30740;&#31350;&#20102;&#24120;&#25968;&#21644;&#30636;&#24577;&#21306;&#22495;&#22312;&#23454;&#36341;&#20013;&#36890;&#24120;&#34987;&#24573;&#30053;&#21364;&#21457;&#25381;&#20102;&#20027;&#23548;&#20316;&#29992;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A core principle in statistical learning is that smoothness of target functions allows to break the curse of dimensionality. However, learning a smooth function through Taylor expansions requires enough samples close to one another to get meaningful estimate of high-order derivatives, which seems hard in machine learning problems where the ratio between number of data and input dimension is relatively small. Should we really hope to break the curse of dimensionality based on Taylor expansion estimation? What happens if Taylor expansions are replaced by Fourier or wavelet expansions? By deriving a new lower bound on the generalization error, this paper investigates the role of constants and transitory regimes which are usually not depicted beyond classical learning theory statements while that play a dominant role in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#36827;&#34892;&#20851;&#20110;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#26435;&#37325;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#24182;&#34920;&#26126;&#21518;&#39564;&#20998;&#24067;&#38598;&#20013;&#22312;&#20855;&#26377;&#38750;&#26631;&#20934;&#36229;&#21442;&#25968;&#20381;&#36182;&#24615;&#30340;&#31232;&#30095;&#20419;&#36827;&#21644;&#22343;&#20540;&#25910;&#32553;&#20808;&#39564;&#21608;&#22260;&#12290;</title><link>http://arxiv.org/abs/2305.10664</link><description>&lt;p&gt;
&#26435;&#37325;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26080;&#38480;&#23485;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Posterior Inference on Infinitely Wide Bayesian Neural Networks under Weights with Unbounded Variance. (arXiv:2305.10664v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#36827;&#34892;&#20851;&#20110;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#26435;&#37325;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#24182;&#34920;&#26126;&#21518;&#39564;&#20998;&#24067;&#38598;&#20013;&#22312;&#20855;&#26377;&#38750;&#26631;&#20934;&#36229;&#21442;&#25968;&#20381;&#36182;&#24615;&#30340;&#31232;&#30095;&#20419;&#36827;&#21644;&#22343;&#20540;&#25910;&#32553;&#20808;&#39564;&#21608;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;Neal&#65288;1996&#65289;&#30340;&#32463;&#20856;&#32780;&#26377;&#24433;&#21709;&#21147;&#30340;&#20316;&#21697;&#24050;&#30693;&#65292;&#20855;&#26377;&#19968;&#23618;&#38544;&#34255;&#23618;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#38480;&#23485;&#24230;&#26631;&#24230;&#26497;&#38480;&#26159;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#65292;&#24403;&#32593;&#32476;&#26435;&#37325;&#20855;&#26377;&#26377;&#30028;&#20808;&#39564;&#26041;&#24046;&#26102;&#12290;Neal&#30340;&#32467;&#26524;&#24050;&#25193;&#23637;&#21040;&#20855;&#26377;&#22810;&#20010;&#38544;&#34255;&#23618;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#32593;&#32476;&#65292;&#20063;&#20855;&#26377;&#39640;&#26031;&#36807;&#31243;&#26631;&#24230;&#26497;&#38480;&#12290;&#39640;&#26031;&#36807;&#31243;&#30340;&#26131;&#22788;&#29702;&#23646;&#24615;&#20801;&#35768;&#30452;&#25509;&#30340;&#21518;&#39564;&#25512;&#26029;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#30456;&#27604;&#26377;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#65292;&#26497;&#22823;&#22320;&#31616;&#21270;&#20102;&#26497;&#38480;&#36807;&#31243;&#30340;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#38754;&#20020;&#30528;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#32463;&#20856;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#22833;&#25928;&#65292;&#25454;&#36866;&#24403;&#26465;&#20214;&#19979;&#30340;&#31283;&#23450;$\alpha$&#36807;&#31243;&#30340;&#26631;&#24230;&#26497;&#38480;&#30340;&#25991;&#29486;&#36739;&#22810;&#30340;&#26159;&#21069;&#21521;&#27169;&#25311;&#65292;&#32780;&#22312;&#36825;&#20123;&#26435;&#37325;&#19979;&#30340;&#21518;&#39564;&#25512;&#26029;&#38382;&#39064;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#20110;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#26435;&#37325;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#25512;&#26029;&#30340;&#26032;&#29702;&#35770;&#27934;&#23519;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;&#32467;&#26524;&#65292;&#24182;&#34920;&#26126;&#21518;&#39564;&#20998;&#24067;&#38598;&#20013;&#22312;&#20855;&#26377;&#38750;&#26631;&#20934;&#36229;&#21442;&#25968;&#20381;&#36182;&#24615;&#30340;&#31232;&#30095;&#20419;&#36827;&#21644;&#22343;&#20540;&#25910;&#32553;&#20808;&#39564;&#21608;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
From the classical and influential works of Neal (1996), it is known that the infinite width scaling limit of a Bayesian neural network with one hidden layer is a Gaussian process, \emph{when the network weights have bounded prior variance}. Neal's result has been extended to networks with multiple hidden layers and to convolutional neural networks, also with Gaussian process scaling limits. The tractable properties of Gaussian processes then allow straightforward posterior inference and uncertainty quantification, considerably simplifying the study of the limit process compared to a network of finite width. Neural network weights with unbounded variance, however, pose unique challenges. In this case, the classical central limit theorem breaks down and it is well known that the scaling limit is an $\alpha$-stable process under suitable conditions. However, current literature is primarily limited to forward simulations under these processes and the problem of posterior inference under s
&lt;/p&gt;</description></item><item><title>HINT&#26159;&#19968;&#31181;&#29992;&#20110;&#27010;&#29575;&#39044;&#27979;&#30340;&#26032;&#22411;&#27169;&#22411;&#26063;&#65292;&#33021;&#22815;&#26377;&#25928;&#12289;&#20934;&#30830;&#22320;&#36827;&#34892;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#36890;&#36807;&#24341;&#20837;Bootstrap&#26041;&#27861;&#24182;&#20026;&#32593;&#32476;&#21152;&#20837;&#35268;&#33539;&#21270;&#29305;&#24449;&#25552;&#21462;&#21644;&#36755;&#20986;&#35268;&#33539;&#21270;&#26469;&#20445;&#35777;&#20854;&#24615;&#33021;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#39044;&#27979;&#31934;&#24230;&#27604;&#29616;&#26377;&#25216;&#26415;&#26356;&#39640;&#12290;</title><link>http://arxiv.org/abs/2305.07089</link><description>&lt;p&gt;
HINT:&#23618;&#27425;&#28151;&#21512;&#32593;&#32476;&#29992;&#20110;&#19968;&#33268;&#27010;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
HINT: Hierarchical Mixture Networks For Coherent Probabilistic Forecasting. (arXiv:2305.07089v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07089
&lt;/p&gt;
&lt;p&gt;
HINT&#26159;&#19968;&#31181;&#29992;&#20110;&#27010;&#29575;&#39044;&#27979;&#30340;&#26032;&#22411;&#27169;&#22411;&#26063;&#65292;&#33021;&#22815;&#26377;&#25928;&#12289;&#20934;&#30830;&#22320;&#36827;&#34892;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#36890;&#36807;&#24341;&#20837;Bootstrap&#26041;&#27861;&#24182;&#20026;&#32593;&#32476;&#21152;&#20837;&#35268;&#33539;&#21270;&#29305;&#24449;&#25552;&#21462;&#21644;&#36755;&#20986;&#35268;&#33539;&#21270;&#26469;&#20445;&#35777;&#20854;&#24615;&#33021;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#39044;&#27979;&#31934;&#24230;&#27604;&#29616;&#26377;&#25216;&#26415;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;"Hierarchical Mixture Networks"&#65288;HINT&#65289;&#30340;&#27169;&#22411;&#26063;&#65292;&#29992;&#20110;&#26377;&#25928;&#32780;&#20934;&#30830;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#22810;&#20803;&#28151;&#21512;&#24182;&#20351;&#29992;&#22797;&#21512;&#20284;&#28982;&#20989;&#25968;&#36827;&#34892;&#20248;&#21270;&#26469;&#19987;&#38376;&#38024;&#23545;&#35813;&#20219;&#21153;&#36827;&#34892;&#32593;&#32476;&#29305;&#21270;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;Bootstrap&#26041;&#27861;&#21152;&#20197;&#21327;&#35843;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#32593;&#32476;&#20013;&#24341;&#20837;&#20102;&#35268;&#33539;&#21270;&#29305;&#24449;&#25552;&#21462;&#21644;&#36755;&#20986;&#35268;&#33539;&#21270;&#65292;&#20197;&#24212;&#23545;&#26102;&#38388;&#24207;&#21015;&#23610;&#24230;&#21464;&#21270;&#12290;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#25216;&#26415;&#30456;&#27604;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;8&#65285; sCRPS&#22686;&#24378;&#31934;&#24230;&#12290;&#25105;&#20204;&#23545;&#27169;&#22411;&#37096;&#20214;&#36827;&#34892;&#20102;&#28040;&#34701;&#30740;&#31350;&#24182;&#24191;&#27867;&#30740;&#31350;&#20102;&#22810;&#20803;&#28151;&#21512;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290; HINT&#30340;&#20195;&#30721;&#21487;&#20197;&#22312;https://github.com/Nixtla/neuralforecast&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the Hierarchical Mixture Networks (HINT), a model family for efficient and accurate coherent forecasting. We specialize the networks on the task via a multivariate mixture optimized with composite likelihood and made coherent via bootstrap reconciliation. Additionally, we robustify the networks to stark time series scale variations, incorporating normalized feature extraction and recomposition of output scales within their architecture. We demonstrate 8% sCRPS improved accuracy across five datasets compared to the existing state-of-the-art. We conduct ablation studies on our model's components and extensively investigate the theoretical properties of the multivariate mixture. HINT's code is available at this https://github.com/Nixtla/neuralforecast.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;</title><link>http://arxiv.org/abs/2305.05465</link><description>&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#21160;&#24577;&#20013;&#30340;&#32858;&#31867;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
The emergence of clusters in self-attention dynamics. (arXiv:2305.05465v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;Transformer&#35270;&#20026;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24403;&#26435;&#37325;&#19981;&#38543;&#26102;&#38388;&#21464;&#21270;&#26102;&#65292;&#26412;&#25991;&#25551;&#36848;&#20102;&#23398;&#20064;&#34920;&#31034;&#30340;&#20960;&#20309;&#24418;&#29366;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20195;&#34920;token&#30340;&#31890;&#23376;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#32780;&#36235;&#21521;&#20110;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#12290;&#20986;&#29616;&#30340;&#26497;&#38480;&#23545;&#35937;&#31867;&#22411;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;&#27492;&#22806;&#65292;&#22312;&#19968;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#25105;&#27880;&#24847;&#21147;&#30697;&#38453;&#25910;&#25947;&#20110;&#20302;&#31209;&#24067;&#23572;&#30697;&#38453;&#12290;&#36825;&#20123;&#32467;&#26524;&#30340;&#32452;&#21512;&#22312;&#25968;&#23398;&#19978;&#35777;&#23454;&#20102;Vaswani&#31561;&#20154;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#20250;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Viewing Transformers as interacting particle systems, we describe the geometry of learned representations when the weights are not time dependent. We show that particles, representing tokens, tend to cluster toward particular limiting objects as time tends to infinity. The type of limiting object that emerges depends on the spectrum of the value matrix. Additionally, in the one-dimensional case we prove that the self-attention matrix converges to a low-rank Boolean matrix. The combination of these results mathematically confirms the empirical observation made by Vaswani et al. \cite{vaswani2017attention} that \emph{leaders} appear in a sequence of tokens when processed by Transformers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22810;&#20803;&#27010;&#29575;CRPS&#23398;&#20064;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#26085;&#21069;&#30005;&#20215;&#39044;&#27979;&#20013;&#65292;&#30456;&#27604;&#20110;&#32479;&#19968;&#32452;&#21512;&#22312;CRPS&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2303.10019</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;CRPS&#23398;&#20064;&#21450;&#20854;&#22312;&#26085;&#21069;&#30005;&#20215;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multivariate Probabilistic CRPS Learning with an Application to Day-Ahead Electricity Prices. (arXiv:2303.10019v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22810;&#20803;&#27010;&#29575;CRPS&#23398;&#20064;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#26085;&#21069;&#30005;&#20215;&#39044;&#27979;&#20013;&#65292;&#30456;&#27604;&#20110;&#32479;&#19968;&#32452;&#21512;&#22312;CRPS&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#20998;&#20301;&#25968;&#21644;&#21327;&#21464;&#37327;&#20381;&#36182;&#20851;&#31995;&#30340;&#22810;&#20803;&#27010;&#29575;&#39044;&#27979;&#30340;&#32467;&#21512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24179;&#28369;&#36807;&#31243;&#20801;&#35768;&#22312;&#32447;&#23398;&#20064;&#12290;&#36890;&#36807;&#32500;&#25968;&#38477;&#20302;&#21644;&#32602;&#20989;&#25968;&#24179;&#28369;&#31561;&#20004;&#31181;&#24179;&#28369;&#26041;&#27861;&#26469;&#23558;&#26631;&#20934;CRPS&#23398;&#20064;&#26694;&#26550;&#25512;&#24191;&#21040;&#22810;&#20803;&#32500;&#24230;&#20013;&#12290;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#39044;&#27979;&#26085;&#21069;&#30005;&#20215;&#65292;&#30456;&#27604;&#20110;&#32479;&#19968;&#32452;&#21512;&#65292;&#22312;CRPS&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new method for combining (or aggregating or ensembling) multivariate probabilistic forecasts, taking into account dependencies between quantiles and covariates through a smoothing procedure that allows for online learning. Two smoothing methods are discussed: dimensionality reduction using Basis matrices and penalized smoothing. The new online learning algorithm generalizes the standard CRPS learning framework into multivariate dimensions. It is based on Bernstein Online Aggregation (BOA) and yields optimal asymptotic learning properties. We provide an in-depth discussion on possible extensions of the algorithm and several nested cases related to the existing literature on online forecast combination. The methodology is applied to forecasting day-ahead electricity prices, which are 24-dimensional distributional forecasts. The proposed method yields significant improvements over uniform combination in terms of continuous ranked probability score (CRPS). We discuss 
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;&#21069;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;/&#25110;&#21518;&#22788;&#29702;&#30340;&#26102;&#38388;&#28857;&#23581;&#35797;&#23558;&#31354;&#38388;&#20449;&#24687;&#32435;&#20837;&#22238;&#24402;&#38543;&#26426;&#26862;&#26519;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#31995;&#32479;&#22238;&#39038;&#24182;&#20998;&#31867;&#26368;&#26032;&#37319;&#29992;&#30340;&#35843;&#25972;&#22238;&#24402;&#38543;&#26426;&#26862;&#26519;&#20197;&#36866;&#24212;&#31354;&#38388;&#30456;&#20851;&#25968;&#25454;&#30340;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2303.04693</link><description>&lt;p&gt;
&#22312;&#22238;&#24402;&#38543;&#26426;&#26862;&#26519;&#20013;&#23547;&#25214;&#31354;&#38388;&#20381;&#36182;&#30340;&#36335;&#24452;&#65306;&#20998;&#31867;&#21644;&#31995;&#32479;&#22238;&#39038;
&lt;/p&gt;
&lt;p&gt;
A path in regression Random Forest looking for spatial dependence: a taxonomy and a systematic review. (arXiv:2303.04693v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04693
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;&#21069;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;/&#25110;&#21518;&#22788;&#29702;&#30340;&#26102;&#38388;&#28857;&#23581;&#35797;&#23558;&#31354;&#38388;&#20449;&#24687;&#32435;&#20837;&#22238;&#24402;&#38543;&#26426;&#26862;&#26519;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#31995;&#32479;&#22238;&#39038;&#24182;&#20998;&#31867;&#26368;&#26032;&#37319;&#29992;&#30340;&#35843;&#25972;&#22238;&#24402;&#38543;&#26426;&#26862;&#26519;&#20197;&#36866;&#24212;&#31354;&#38388;&#30456;&#20851;&#25968;&#25454;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#65288;RF&#65289;&#26159;&#19968;&#31181;&#33879;&#21517;&#30340;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#24212;&#29992;&#24191;&#27867;&#65292;&#22240;&#20026;&#23427;&#22312;&#24314;&#27169;&#21709;&#24212;&#21464;&#37327;&#21644;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#26102;&#20855;&#26377;&#24456;&#22823;&#30340;&#28789;&#27963;&#24615;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#24378;&#38750;&#32447;&#24615;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#20063;&#36866;&#29992;&#12290;&#22312;&#29615;&#22659;&#24212;&#29992;&#20013;&#65292;&#24120;&#24120;&#20986;&#29616;&#24863;&#20852;&#36259;&#30340;&#29616;&#35937;&#21487;&#33021;&#23384;&#22312;&#31354;&#38388;&#21644;/&#25110;&#26102;&#38388;&#20381;&#36182;&#24615;&#65292;&#36825;&#22312;RF&#30340;&#26631;&#20934;&#29256;&#26412;&#20013;&#27809;&#26377;&#26126;&#30830;&#32771;&#34385;&#21040;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;&#23427;&#20204;&#22312;&#20309;&#26102;&#65288;&#21069;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;/&#25110;&#21518;&#22788;&#29702;&#65289;&#23581;&#35797;&#23558;&#31354;&#38388;&#20449;&#24687;&#32435;&#20837;&#22238;&#24402;RF&#20013;&#26469;&#23545;&#31574;&#30053;&#36827;&#34892;&#20998;&#31867;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#26681;&#25454;&#12298;&#31995;&#32479;&#22238;&#39038;&#21644;Meta&#20998;&#26512;&#39318;&#36873;&#25253;&#21578;&#39033;&#30446;&#12299;&#65288;PRISMA&#65289;&#25552;&#20379;&#30340;&#26631;&#20934;&#65292;&#23545;&#26368;&#36817;&#37319;&#29992;&#30340;&#35843;&#25972;&#22238;&#24402;RF&#20197;&#36866;&#24212;&#31354;&#38388;&#30456;&#20851;&#25968;&#25454;&#30340;&#31574;&#30053;&#36827;&#34892;&#31995;&#32479;&#22238;&#39038;&#21644;&#20998;&#31867;&#12290;&#21518;&#32773;&#26159;&#19968;&#31181;&#21487;&#37325;&#22797;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25910;&#38598;&#21644;&#22788;&#29702;&#20851;&#20110;&#29305;&#23450;&#20027;&#39064;&#30340;&#19981;&#21516;&#26469;&#28304;&#30340;&#29616;&#26377;&#25991;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Forest (RF) is a well-known data-driven algorithm applied in several fields thanks to its flexibility in modeling the relationship between the response variable and the predictors, also in case of strong non-linearities. In environmental applications, it often occurs that the phenomenon of interest may present spatial and/or temporal dependence that is not taken explicitly into account by RF in its standard version. In this work, we propose a taxonomy to classify strategies according to when (Pre-, In- and/or Post-processing) they try to include the spatial information into regression RF. Moreover, we provide a systematic review and classify the most recent strategies adopted to "adjust" regression RF to spatially dependent data, based on the criteria provided by the Preferred Reporting Items for Systematic reviews and Meta-Analysis (PRISMA). The latter consists of a reproducible methodology for collecting and processing existing literature on a specified topic from different so
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#24102;&#31526;&#21495;&#25490;&#21015;&#34920;&#31034;&#30340;&#23494;&#38598;&#36830;&#25509;$G$-&#19981;&#21464;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;($G$-DNN)&#26550;&#26500;&#65292;&#36890;&#36807;&#32806;&#21512;&#26435;&#37325;&#65292;&#20351;&#24471;&#32593;&#32476;&#30340;&#21069;&#28608;&#27963;&#33021;&#22815;&#36890;&#36807;$G$&#30340;&#24102;&#31526;&#21495;&#25490;&#21015;&#34920;&#31034;&#36827;&#34892;&#21464;&#25442;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#26063;&#26356;&#20016;&#23500;&#30340;$G$-&#19981;&#21464;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2303.04614</link><description>&lt;p&gt;
&#20855;&#26377;&#24102;&#31526;&#21495;&#25490;&#21015;&#34920;&#31034;&#30340;&#23494;&#38598;&#36830;&#25509;&#30340;$G$-&#19981;&#21464;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Densely Connected $G$-invariant Deep Neural Networks with Signed Permutation Representations. (arXiv:2303.04614v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#24102;&#31526;&#21495;&#25490;&#21015;&#34920;&#31034;&#30340;&#23494;&#38598;&#36830;&#25509;$G$-&#19981;&#21464;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;($G$-DNN)&#26550;&#26500;&#65292;&#36890;&#36807;&#32806;&#21512;&#26435;&#37325;&#65292;&#20351;&#24471;&#32593;&#32476;&#30340;&#21069;&#28608;&#27963;&#33021;&#22815;&#36890;&#36807;$G$&#30340;&#24102;&#31526;&#21495;&#25490;&#21015;&#34920;&#31034;&#36827;&#34892;&#21464;&#25442;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#26063;&#26356;&#20016;&#23500;&#30340;$G$-&#19981;&#21464;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#23545;&#20110;&#26377;&#38480;&#32676;$G$&#65292;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#23494;&#38598;&#36830;&#25509;$G$-&#19981;&#21464;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;($G$-DNN)&#26550;&#26500;&#12290;&#19982;&#25991;&#29486;&#20013;&#20854;&#20182;$G$-&#19981;&#21464;&#26550;&#26500;&#19981;&#21516;&#65292;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;$G$-DNN&#30340;&#21069;&#28608;&#27963;&#33021;&#22815;&#36890;&#36807;$G$&#30340;&#24102;&#31526;&#21495;&#25490;&#21015;&#34920;&#31034;(signed perm-reps)&#36827;&#34892;&#21464;&#25442;&#12290;&#27492;&#22806;&#65292;$G$-DNN&#30340;&#21508;&#20010;&#23618;&#19981;&#35201;&#27714;&#26159;$G$-&#31561;&#21464;&#30340;&#65307;&#32780;&#26159;&#36890;&#36807;&#23558;&#36755;&#20837;&#32593;&#32476;&#30340;&#21069;&#28608;&#27963;&#20989;&#25968;&#38480;&#21046;&#20026;$G$-&#31561;&#21464;&#20989;&#25968;&#30340;&#26041;&#24335;&#65292;&#22312;&#25152;&#26377;&#23618;&#20043;&#38388;&#32806;&#21512;&#26435;&#37325;&#12290;&#32467;&#26524;&#26159;&#19968;&#26063;&#26356;&#20016;&#23500;&#30340;$G$-&#19981;&#21464;&#26550;&#26500;&#65292;&#36825;&#22312;&#20197;&#21069;&#20174;&#26410;&#35265;&#36807;&#12290;&#25105;&#20204;&#36890;&#36807;&#26435;&#37325;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#25512;&#23548;&#20102;$G$-DNN&#30340;&#39640;&#25928;&#23454;&#29616;&#65292;&#24182;&#24471;&#20986;&#20102;&#19968;&#20010;&#26550;&#26500;&#8220;&#21487;&#25509;&#21463;&#8221;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#8212;&#8212;&#21363;&#38750;&#36864;&#21270;&#19988;&#19982;&#26356;&#23567;&#30340;&#26550;&#26500;&#19981;&#30456;&#21516;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#30456;&#20851;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce and investigate, for finite groups $G$, $G$-invariant deep neural network ($G$-DNN) architectures with ReLU activation that are densely connected-- i.e., include all possible skip connections. In contrast to other $G$-invariant architectures in the literature, the preactivations of the$G$-DNNs presented here are able to transform by \emph{signed} permutation representations (signed perm-reps) of $G$. Moreover, the individual layers of the $G$-DNNs are not required to be $G$-equivariant; instead, the preactivations are constrained to be $G$-equivariant functions of the network input in a way that couples weights across all layers. The result is a richer family of $G$-invariant architectures never seen previously. We derive an efficient implementation of $G$-DNNs after a reparameterization of weights, as well as necessary and sufficient conditions for an architecture to be ``admissible''-- i.e., nondegenerate and inequivalent to smaller architectures. We include code that al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#20165;&#20855;&#26377;&#23545;&#27491;&#24120;&#26680;&#24515;&#30340;&#29983;&#25104;&#27169;&#22411;&#35775;&#38382;&#26435;&#38480;&#26102;&#65292;&#33719;&#24471;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;sa&#65288;s-&#65289;&#30697;&#24418;&#19981;&#30830;&#23450;&#38598;&#21512;&#65292;&#24050;&#30693;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|&#65289;&#65288;&#21709;&#24212;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|^2&#65289;&#65289;&#65292;&#23545;&#20110;&#29305;&#23450;&#31639;&#27861;&#21644;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#12289;KL&#25110;&#21345;&#26041;&#25955;&#24230;&#30340;&#19981;&#30830;&#23450;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2302.05372</link><description>&lt;p&gt;
&#36808;&#21521;&#27169;&#22411;&#22522;&#30784;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Towards Minimax Optimality of Model-based Robust Reinforcement Learning. (arXiv:2302.05372v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#20165;&#20855;&#26377;&#23545;&#27491;&#24120;&#26680;&#24515;&#30340;&#29983;&#25104;&#27169;&#22411;&#35775;&#38382;&#26435;&#38480;&#26102;&#65292;&#33719;&#24471;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;sa&#65288;s-&#65289;&#30697;&#24418;&#19981;&#30830;&#23450;&#38598;&#21512;&#65292;&#24050;&#30693;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|&#65289;&#65288;&#21709;&#24212;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|^2&#65289;&#65289;&#65292;&#23545;&#20110;&#29305;&#23450;&#31639;&#27861;&#21644;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#12289;KL&#25110;&#21345;&#26041;&#25955;&#24230;&#30340;&#19981;&#30830;&#23450;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21482;&#26377;&#23545;&#27491;&#24120;&#26680;&#24515;&#30340;&#29983;&#25104;&#27169;&#22411;&#35775;&#38382;&#26435;&#38480;&#26102;&#65292;&#33719;&#24471;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#37319;&#26679;&#22797;&#26434;&#24230;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#38750;&#40065;&#26834;&#24773;&#20917;&#19979;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#24182;&#19988;&#24050;&#30693;&#20219;&#20309;&#24212;&#29992;&#20110;&#32463;&#39564;MDP&#30340;&#35268;&#21010;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;&#29992;&#949;^2/&#65288;H^3 * |S| * |A|&#65289;&#20010;&#26679;&#26412;&#26469;&#20272;&#35745;&#65292;&#22343;&#21487;&#25552;&#20379;&#949;-&#26368;&#20248;&#31574;&#30053;&#65292;&#20174;&#32780;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#12290;&#40065;&#26834;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#26356;&#21152;&#23569;&#35265;&#12290;&#23545;&#20110;sa&#65288;s-&#65289;&#30697;&#24418;&#19981;&#30830;&#23450;&#38598;&#21512;&#65292;&#24050;&#30693;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|&#65289;&#65288;&#21709;&#24212;&#20026;&#949;^2/&#65288;H^4 * |S|^2 * |A|^2&#65289;&#65289;&#65292;&#23545;&#20110;&#29305;&#23450;&#31639;&#27861;&#21644;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#12289;KL&#25110;&#21345;&#26041;&#25955;&#24230;&#30340;&#19981;&#30830;&#23450;&#38598;&#21512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#29992;Lp&#29699;&#23450;&#20041;&#30340;&#19981;&#30830;&#23450;&#38598;&#21512;&#65288;&#22238;&#22797;&#21040;TV&#24773;&#20917;&#65289;&#65292;&#24182;&#19988;...
&lt;/p&gt;
&lt;p&gt;
We study the sample complexity of obtaining an $\epsilon$-optimal policy in \emph{Robust} discounted Markov Decision Processes (RMDPs), given only access to a generative model of the nominal kernel. This problem is widely studied in the non-robust case, and it is known that any planning approach applied to an empirical MDP estimated with $\tilde{\mathcal{O}}(\frac{H^3 \mid S \mid\mid A \mid}{\epsilon^2})$ samples provides an $\epsilon$-optimal policy, which is minimax optimal. Results in the robust case are much more scarce. For $sa$(resp $s$-)rectangular uncertainty sets, the best known sample complexity is $\tilde{\mathcal{O}}(\frac{H^4 \mid S \mid^2\mid A \mid}{\epsilon^2})$ (resp. $\tilde{\mathcal{O}}(\frac{H^4 \mid S \mid^2\mid A \mid^2}{\epsilon^2})$), for specific algorithms and when the uncertainty set is based on the total variation (TV), the KL or the Chi-square divergences. In this paper, we consider uncertainty sets defined with an $L_p$-ball (recovering the TV case), and
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#39057;&#32321;&#26041;&#21521;&#33609;&#31295;&#26469;&#38477;&#20302;&#30697;&#38453;&#39044;&#22788;&#29702;&#22120;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#38656;&#27714;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20445;&#25345;&#24615;&#33021;&#30340;&#21516;&#26102;&#38477;&#20302;&#36164;&#28304;&#30340;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2302.03764</link><description>&lt;p&gt;
Sketchy: &#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#26041;&#27861;&#19982;&#39057;&#32321;&#26041;&#21521;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sketchy: Memory-efficient Adaptive Regularization with Frequent Directions. (arXiv:2302.03764v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#39057;&#32321;&#26041;&#21521;&#33609;&#31295;&#26469;&#38477;&#20302;&#30697;&#38453;&#39044;&#22788;&#29702;&#22120;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#38656;&#27714;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20445;&#25345;&#24615;&#33021;&#30340;&#21516;&#26102;&#38477;&#20302;&#36164;&#28304;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#20869;&#23384;&#21644;&#36816;&#34892;&#26102;&#38388;&#26041;&#38754;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;Kronecker&#22240;&#23376;&#26799;&#24230;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#35889;&#32858;&#28966;&#22312;&#19968;&#20010;&#21464;&#21270;&#30340;&#23567;&#30340;&#20027;&#29305;&#24449;&#31354;&#38388;&#19978;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#37319;&#29992;&#20302;&#31209;&#30340;&#33609;&#31295;&#26041;&#27861;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#65292;&#20351;&#29992;&#39057;&#32321;&#26041;&#21521;&#65288;FD&#65289;&#33609;&#31295;&#26469;&#20943;&#23569;&#32500;&#25252;&#30697;&#38453;&#39044;&#22788;&#29702;&#22120;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#38656;&#27714;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;&#26041;&#27861;&#24050;&#32463;&#25506;&#32034;&#20102;&#22312;&#20108;&#38454;&#20248;&#21270;&#20013;&#24212;&#29992;FD&#30340;&#26041;&#27861;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#20801;&#35768;&#22312;&#36164;&#28304;&#38656;&#27714;&#21644;&#36951;&#25022;&#20445;&#35777;&#30340;&#36864;&#21270;&#20043;&#38388;&#36827;&#34892;&#39640;&#25928;&#25554;&#20540;: &#22312;&#22312;&#32447;&#20984;&#20248;&#21270;&#65288;OCO&#65289;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20165;$dk$&#30340;&#20869;&#23384;&#19982;&#23436;&#25972;&#30697;&#38453;$d^2$&#30340;&#20869;&#23384;&#36951;&#25022;&#21305;&#37197;&#65292;&#30452;&#21040;&#22312;&#24213;&#37096;$d-k$&#30340;&#29305;&#24449;&#20540;&#19978;&#28155;&#21152;&#35823;&#24046;&#20026;&#27490;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adaptive regularization methods that exploit more than the diagonal entries exhibit state of the art performance for many tasks, but can be prohibitive in terms of memory and running time. We find the spectra of the Kronecker-factored gradient covariance matrix in deep learning (DL) training tasks are concentrated on a small leading eigenspace that changes throughout training, motivating a low-rank sketching approach. We describe a generic method for reducing memory and compute requirements of maintaining a matrix preconditioner using the Frequent Directions (FD) sketch. While previous approaches have explored applying FD for second-order optimization, we present a novel analysis which allows efficient interpolation between resource requirements and the degradation in regret guarantees with rank $k$: in the online convex optimization (OCO) setting over dimension $d$, we match full-matrix $d^2$ memory regret using only $dk$ memory up to additive error in the bottom $d-k$ eigenvalues of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#21644;&#25512;&#26029;&#26102;&#39044;&#27979;&#32622;&#20449;&#24230;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.04900</link><description>&lt;p&gt;
&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Recipe for Well-behaved Graph Neural Approximations of Complex Dynamics. (arXiv:2301.04900v2 [cond-mat.stat-mech] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#21644;&#25512;&#26029;&#26102;&#39044;&#27979;&#32622;&#20449;&#24230;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#36817;&#20284;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#26469;&#21457;&#29616;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#32570;&#20047;&#26126;&#30830;&#21407;&#29702;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#26412;&#25991;&#30528;&#37325;&#30740;&#31350;&#20102;&#19968;&#31867;&#30001;&#32593;&#32476;&#37051;&#25509;&#30697;&#38453;&#32806;&#21512;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#25551;&#36848;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#31995;&#32479;&#65292;&#21253;&#25324;&#37329;&#34701;&#12289;&#31038;&#20132;&#21644;&#31070;&#32463;&#31995;&#32479;&#65292;&#23646;&#20110;&#36825;&#31867;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#36825;&#31181;&#21160;&#21147;&#31995;&#32479;&#30340;&#20851;&#38190;&#35201;&#32032;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;&#24378;&#35843;&#19982;&#38745;&#24577;&#30417;&#30563;&#23398;&#20064;&#30340;&#21306;&#21035;&#65292;&#25105;&#20204;&#25552;&#20513;&#22312;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#32463;&#20856;&#20551;&#35774;&#20043;&#22806;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#22312;&#25512;&#26029;&#26102;&#20272;&#35745;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#19987;&#29992;&#30340;&#31354;&#27169;&#22411;&#12290;&#36890;&#36807;&#30740;&#31350;&#21508;&#31181;&#22797;&#26434;&#32593;&#32476;&#21160;&#21147;&#23398;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven approximations of ordinary differential equations offer a promising alternative to classical methods in discovering a dynamical system model, particularly in complex systems lacking explicit first principles. This paper focuses on a complex system whose dynamics is described with a system of ordinary differential equations, coupled via a network adjacency matrix. Numerous real-world systems, including financial, social, and neural systems, belong to this class of dynamical models. We propose essential elements for approximating such dynamical systems using neural networks, including necessary biases and an appropriate neural architecture. Emphasizing the differences from static supervised learning, we advocate for evaluating generalization beyond classical assumptions of statistical learning theory. To estimate confidence in prediction during inference time, we introduce a dedicated null model. By studying various complex network dynamics, we demonstrate the neural network'
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#28145;&#24230;&#23398;&#20064;&#20013;&#38543;&#26426;&#26799;&#24230;&#30340;&#32467;&#26500;&#36827;&#34892;&#20102;&#27491;&#24335;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#21457;&#29616;&#36880;&#32500;&#26799;&#24230;&#36890;&#24120;&#21576;&#29616;&#24130;&#24459;&#37325;&#23614;&#65292;&#32780;&#36880;&#27425;&#36845;&#20195;&#30340;&#26799;&#24230;&#21644;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#36890;&#24120;&#19981;&#21576;&#29616;&#24130;&#24459;&#37325;&#23614;&#12290;</title><link>http://arxiv.org/abs/2212.02083</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#34987;&#24573;&#35270;&#30340;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
On the Overlooked Structure of Stochastic Gradients. (arXiv:2212.02083v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.02083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#28145;&#24230;&#23398;&#20064;&#20013;&#38543;&#26426;&#26799;&#24230;&#30340;&#32467;&#26500;&#36827;&#34892;&#20102;&#27491;&#24335;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#21457;&#29616;&#36880;&#32500;&#26799;&#24230;&#36890;&#24120;&#21576;&#29616;&#24130;&#24459;&#37325;&#23614;&#65292;&#32780;&#36880;&#27425;&#36845;&#20195;&#30340;&#26799;&#24230;&#21644;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#36890;&#24120;&#19981;&#21576;&#29616;&#24130;&#24459;&#37325;&#23614;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#20248;&#21270;&#21644;&#27867;&#21270;&#23494;&#20999;&#30456;&#20851;&#12290;&#19968;&#20123;&#30740;&#31350;&#35797;&#22270;&#36890;&#36807;&#26799;&#24230;&#22122;&#22768;&#30340;&#37325;&#23614;&#24615;&#36136;&#26469;&#35299;&#37322;&#38543;&#26426;&#20248;&#21270;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25104;&#21151;&#65292;&#32780;&#20854;&#20182;&#30740;&#31350;&#21017;&#25552;&#20986;&#20102;&#23545;&#26799;&#24230;&#22122;&#22768;&#30340;&#37325;&#23614;&#20551;&#35774;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#29992;&#20110;&#20998;&#26512;&#38543;&#26426;&#26799;&#24230;&#32467;&#26500;&#21644;&#37325;&#23614;&#30340;&#27491;&#24335;&#32479;&#35745;&#26816;&#39564;&#36824;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#24320;&#21457;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20027;&#35201;&#20570;&#20986;&#20004;&#20010;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;&#38543;&#26426;&#26799;&#24230;&#21644;&#26799;&#24230;&#22122;&#22768;&#22312;&#21442;&#25968;&#21644;&#36845;&#20195;&#20013;&#30340;&#20998;&#24067;&#36827;&#34892;&#20102;&#27491;&#24335;&#30340;&#32479;&#35745;&#26816;&#39564;&#12290;&#25105;&#20204;&#30340;&#32479;&#35745;&#26816;&#39564;&#21457;&#29616;&#65292;&#36880;&#32500;&#26799;&#24230;&#36890;&#24120;&#34920;&#29616;&#20986;&#24130;&#24459;&#37325;&#23614;&#65292;&#32780;&#36880;&#27425;&#36845;&#20195;&#30340;&#26799;&#24230;&#21644;&#30001;&#23567;&#25209;&#37327;&#35757;&#32451;&#24341;&#36215;&#30340;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#36890;&#24120;&#19981;&#34920;&#29616;&#20986;&#24130;&#24459;&#37325;&#23614;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#21327;&#26041;&#24046;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradients closely relate to both optimization and generalization of deep neural networks (DNNs). Some works attempted to explain the success of stochastic optimization for deep learning by the arguably heavy-tail properties of gradient noise, while other works presented theoretical and empirical evidence against the heavy-tail hypothesis on gradient noise. Unfortunately, formal statistical tests for analyzing the structure and heavy tails of stochastic gradients in deep learning are still under-explored. In this paper, we mainly make two contributions. First, we conduct formal statistical tests on the distribution of stochastic gradients and gradient noise across both parameters and iterations. Our statistical tests reveal that dimension-wise gradients usually exhibit power-law heavy tails, while iteration-wise gradients and stochastic gradient noise caused by minibatch training usually do not exhibit power-law heavy tails. Second, we further discover that the covariance spe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#23558;&#29420;&#31435;&#24615;&#39537;&#21160;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#31639;&#27861;&#35299;&#37322;&#20026;&#29305;&#24449;&#36873;&#25321;&#36807;&#31243;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#27867;&#21270;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.02355</link><description>&lt;p&gt;
&#23545;&#20110;&#21327;&#21464;&#37327;&#20559;&#31227;&#27867;&#21270;&#30340;&#22522;&#20110;&#29420;&#31435;&#24615;&#39537;&#21160;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#31639;&#27861;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis on Independence-driven Importance Weighting for Covariate-shift Generalization. (arXiv:2111.02355v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.02355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#23558;&#29420;&#31435;&#24615;&#39537;&#21160;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#31639;&#27861;&#35299;&#37322;&#20026;&#29305;&#24449;&#36873;&#25321;&#36807;&#31243;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#27867;&#21270;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21464;&#37327;&#20559;&#31227;&#27867;&#21270;&#26159;&#20998;&#24067;&#20043;&#22806;&#65288;OOD&#65289;&#27867;&#21270;&#20013;&#30340;&#20856;&#22411;&#24773;&#20917;&#65292;&#35201;&#27714;&#22312;&#26410;&#30693;&#30340;&#27979;&#35797;&#20998;&#24067;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#35813;&#20998;&#24067;&#19982;&#21487;&#35775;&#38382;&#30340;&#35757;&#32451;&#20998;&#24067;&#20197;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#24418;&#24335;&#26377;&#25152;&#19981;&#21516;&#12290;&#26368;&#36817;&#65292;&#31283;&#23450;&#23398;&#20064;&#25991;&#29486;&#20013;&#30340;&#29420;&#31435;&#24615;&#39537;&#21160;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#31639;&#27861;&#22312;&#22788;&#29702;&#21253;&#25324;&#22238;&#24402;&#31639;&#27861;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#22810;&#20010;&#23398;&#20064;&#27169;&#22411;&#19978;&#26174;&#31034;&#20986;&#20102;&#32463;&#39564;&#26377;&#25928;&#24615;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#23578;&#32570;&#22833;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#23427;&#20204;&#35299;&#37322;&#20026;&#29305;&#24449;&#36873;&#25321;&#36807;&#31243;&#65292;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#25351;&#23450;&#20102;&#19968;&#32452;&#21464;&#37327;&#65292;&#31216;&#20026;&#26368;&#23567;&#31283;&#23450;&#21464;&#37327;&#38598;&#65292;&#35813;&#38598;&#21512;&#26159;&#22788;&#29702;&#21327;&#21464;&#37327;&#20559;&#31227;&#27867;&#21270;&#30340;&#24120;&#35265;&#25439;&#22833;&#20989;&#25968;&#65288;&#22914;&#22343;&#26041;&#25439;&#22833;&#21644;&#20108;&#20803;&#20132;&#21449;&#29109;&#25439;&#22833;&#65289;&#30340;&#26368;&#23567;&#26368;&#20248;&#21464;&#37327;&#38598;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#29702;&#24819;&#26465;&#20214;&#19979;&#65292;&#22312;&#36825;&#20123;&#31639;&#27861;&#19979;&#65292;&#29420;&#31435;&#24615;&#39537;&#21160;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#36825;&#20010;&#26368;&#23567;&#31283;&#23450;&#21464;&#37327;&#38598;&#30340;&#26377;&#25928;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Covariate-shift generalization, a typical case in out-of-distribution (OOD) generalization, requires a good performance on the unknown test distribution, which varies from the accessible training distribution in the form of covariate shift. Recently, independence-driven importance weighting algorithms in stable learning literature have shown empirical effectiveness to deal with covariate-shift generalization on several learning models, including regression algorithms and deep neural networks, while their theoretical analyses are missing. In this paper, we theoretically prove the effectiveness of such algorithms by explaining them as feature selection processes. We first specify a set of variables, named minimal stable variable set, that is the minimal and optimal set of variables to deal with covariate-shift generalization for common loss functions, such as the mean squared loss and binary cross-entropy loss. Afterward, we prove that under ideal conditions, independence-driven importan
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#19978;&#19979;&#25991;&#25512;&#26029;&#35774;&#32622;&#20013;&#65292;&#38024;&#23545;&#32047;&#35745;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#26368;&#20248;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#28176;&#22686;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#36882;&#20943;&#36793;&#38469;&#25910;&#30410;&#26465;&#20214;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#39062;&#35823;&#37197;&#27979;&#35797;&#30340;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#27169;&#22411;&#36873;&#25321;&#22312;&#22870;&#21169;&#20272;&#35745;&#20013;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2106.06483</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#35768;&#22810;&#31867;&#21035;&#30340;&#19978;&#19979;&#25991;&#25512;&#26029;&#20013;&#36890;&#36807;&#31163;&#32447;&#31070;&#35861;&#36827;&#34892;&#26368;&#20248;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Optimal Model Selection in Contextual Bandits with Many Classes via Offline Oracles. (arXiv:2106.06483v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.06483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#19978;&#19979;&#25991;&#25512;&#26029;&#35774;&#32622;&#20013;&#65292;&#38024;&#23545;&#32047;&#35745;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#26368;&#20248;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#28176;&#22686;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#36882;&#20943;&#36793;&#38469;&#25910;&#30410;&#26465;&#20214;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#39062;&#35823;&#37197;&#27979;&#35797;&#30340;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#27169;&#22411;&#36873;&#25321;&#22312;&#22870;&#21169;&#20272;&#35745;&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#36873;&#25321;&#25552;&#20379;&#20102;&#19968;&#31181;&#26080;&#25104;&#26412;&#30340;&#20445;&#35777;&#65292;&#23601;&#22909;&#20687;&#26368;&#20248;&#24179;&#34913;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#27169;&#22411;&#26159;&#20808;&#39564;&#24050;&#30693;&#30340;&#19968;&#26679;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#19978;&#19979;&#25991;&#25512;&#26029;&#35774;&#32622;&#20013;&#23454;&#29616;&#31867;&#20284;&#20445;&#35777;&#30340;&#21487;&#34892;&#24615;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350; [Marinov and Zimmert, 2021] &#37492;&#21035;&#20986;&#27809;&#26377;&#31639;&#27861;&#33021;&#22815;&#20445;&#35777;&#26080;&#25104;&#26412;&#30340;&#36951;&#25022;&#30028;&#38480;&#30340;&#24773;&#20917;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#28176;&#22686;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#38543;&#30528;&#31867;&#21035;&#22797;&#26434;&#24615;&#22686;&#21152;&#26368;&#20339;&#31574;&#30053;&#20215;&#20540;&#36793;&#38469;&#25910;&#30410;&#36882;&#20943;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#26080;&#25104;&#26412;&#27169;&#22411;&#36873;&#25321;&#26159;&#21487;&#34892;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#19968;&#31181;&#26032;&#39062;&#30340;&#35823;&#37197;&#27979;&#35797;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#23637;&#31034;&#20102;&#27169;&#22411;&#36873;&#25321;&#22312;&#22870;&#21169;&#20272;&#35745;&#20013;&#30340;&#20248;&#21183;&#12290;&#19982;&#20808;&#21069;&#20851;&#20110;&#19978;&#19979;&#25991;&#25512;&#26029;&#20013;&#27169;&#22411;&#36873;&#25321;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#25910;&#38598;&#26356;&#22810;&#25968;&#25454;&#26102;&#20250;&#20180;&#32454;&#22320;&#36866;&#24212;&#36880;&#28176;&#28436;&#21464;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#20998;&#26512;&#36229;&#36234;&#20102;&#36866;&#24212;&#26102;&#38388;&#22797;&#26434;&#24615;&#30340;&#33539;&#30068;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model selection in supervised learning provides costless guarantees as if the model that best balances bias and variance was known a priori. We study the feasibility of similar guarantees for cumulative regret minimization in the stochastic contextual bandit setting. Recent work [Marinov and Zimmert, 2021] identifies instances where no algorithm can guarantee costless regret bounds. Nevertheless, we identify benign conditions where costless model selection is feasible: gradually increasing class complexity, and diminishing marginal returns for best-in-class policy value with increasing class complexity. Our algorithm is based on a novel misspecification test, and our analysis demonstrates the benefits of using model selection for reward estimation. Unlike prior work on model selection in contextual bandits, our algorithm carefully adapts to the evolving bias-variance trade-off as more data is collected. In particular, our algorithm and analysis go beyond adapting to the complexity of t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#21512;&#20256;&#36755;&#25955;&#24230;&#30340;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#26031;&#28151;&#21512;&#22312;&#36882;&#24402;&#26356;&#26032;&#20013;&#38454;&#25968;&#25351;&#25968;&#22686;&#21152;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2002.08410</link><description>&lt;p&gt;
&#29992;&#22797;&#21512;&#20256;&#36755;&#25955;&#24230;&#36827;&#34892;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;
&lt;/p&gt;
&lt;p&gt;
Gaussian Mixture Reduction with Composite Transportation Divergence. (arXiv:2002.08410v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.08410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#21512;&#20256;&#36755;&#25955;&#24230;&#30340;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#26031;&#28151;&#21512;&#22312;&#36882;&#24402;&#26356;&#26032;&#20013;&#38454;&#25968;&#25351;&#25968;&#22686;&#21152;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#22312;&#23494;&#24230;&#20272;&#35745;&#12289;&#20449;&#24565;&#20256;&#25773;&#21644;&#36125;&#21494;&#26031;&#28388;&#27874;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#34987;&#24191;&#27867;&#29992;&#20110;&#36924;&#36817;&#23494;&#24230;&#20989;&#25968;&#12290;&#36825;&#20123;&#24212;&#29992;&#36890;&#24120;&#21033;&#29992;&#39640;&#26031;&#28151;&#21512;&#20316;&#20026;&#36882;&#24402;&#26356;&#26032;&#30340;&#21021;&#22987;&#36817;&#20284;&#12290;&#36825;&#20123;&#36882;&#24402;&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#28304;&#20110;&#28151;&#21512;&#38454;&#25968;&#30340;&#25351;&#25968;&#22686;&#21152;&#65292;&#23548;&#33268;&#38590;&#20197;&#27714;&#35299;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#22256;&#38590;&#65292;&#21487;&#20197;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#65288;GMR&#65289;&#23558;&#39640;&#38454;&#39640;&#26031;&#28151;&#21512;&#36817;&#20284;&#20026;&#20302;&#38454;&#28151;&#21512;&#12290;&#23613;&#31649;&#29616;&#26377;&#30340;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;&#22312;&#24615;&#33021;&#21644;&#35745;&#31639;&#25928;&#29575;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#36136;&#21644;&#26368;&#20248;&#30446;&#26631;&#20173;&#28982;&#26410;&#30693;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#21512;&#20256;&#36755;&#25955;&#24230;&#30340;&#26032;&#22411;&#20248;&#21270;GMR&#26041;&#27861;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20027;&#20803;&#26368;&#23567;&#21270;&#31639;&#27861;&#26469;&#35745;&#31639;&#31616;&#21270;&#30340;&#28151;&#21512;&#65292;&#24182;&#22312;g&#20013;&#24314;&#31435;&#20102;&#20854;&#29702;&#35770;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian mixtures are widely used for approximating density functions in various applications such as density estimation, belief propagation, and Bayesian filtering. These applications often utilize Gaussian mixtures as initial approximations that are updated recursively. A key challenge in these recursive processes stems from the exponential increase in the mixture's order, resulting in intractable inference. To overcome the difficulty, the Gaussian mixture reduction (GMR), which approximates a high order Gaussian mixture by one with a lower order, can be used. Although existing clustering-based methods are known for their satisfactory performance and computational efficiency, their convergence properties and optimal targets remain unknown. In this paper, we propose a novel optimization-based GMR method based on composite transportation divergence (CTD). We develop a majorization-minimization algorithm for computing the reduced mixture and establish its theoretical convergence under g
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22823;&#35268;&#27169;&#20107;&#20214;&#23884;&#20837;&#21644;&#24490;&#29615;&#32593;&#32476;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;CTR&#39044;&#27979;&#26041;&#27861;&#65292;&#22312;&#21407;&#29983;&#24191;&#21578;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/1804.09133</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#35268;&#27169;&#20107;&#20214;&#23884;&#20837;&#21644;&#24490;&#29615;&#32593;&#32476;&#25552;&#39640;&#21407;&#29983;&#24191;&#21578;&#30340;CTR&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Improving Native Ads CTR Prediction by Large Scale Event Embedding and Recurrent Networks. (arXiv:1804.09133v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1804.09133
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22823;&#35268;&#27169;&#20107;&#20214;&#23884;&#20837;&#21644;&#24490;&#29615;&#32593;&#32476;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;CTR&#39044;&#27979;&#26041;&#27861;&#65292;&#22312;&#21407;&#29983;&#24191;&#21578;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#23545;&#20110;&#21407;&#29983;&#24191;&#21578;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#30001;&#20110;&#27809;&#26377;&#30452;&#25509;&#30340;&#26597;&#35810;&#24847;&#22270;&#65292;&#22240;&#27492;&#24456;&#38590;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22823;&#35268;&#27169;&#20107;&#20214;&#23884;&#20837;&#26041;&#26696;&#65292;&#36890;&#36807;&#23545;&#29992;&#25143;&#36830;&#32493;&#20107;&#20214;&#36827;&#34892;&#24369;&#30417;&#30563;&#35757;&#32451;&#30340;&#23402;&#29983;&#32593;&#32476;&#26469;&#32534;&#30721;&#27599;&#20010;&#29992;&#25143;&#27983;&#35272;&#20107;&#20214;&#12290;CTR&#39044;&#27979;&#38382;&#39064;&#34987;&#24314;&#27169;&#20026;&#19968;&#20010;&#30417;&#30563;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65292;&#33258;&#28982;&#22320;&#23558;&#29992;&#25143;&#21382;&#21490;&#24314;&#27169;&#20026;&#20107;&#20214;&#24207;&#21015;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#24490;&#29615;&#27169;&#22411;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#20107;&#20214;&#23884;&#20837;&#21521;&#37327;&#21644;&#27880;&#24847;&#23618;&#23545;&#29992;&#25143;&#21382;&#21490;&#36827;&#34892;&#24314;&#27169;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#26126;&#26174;&#20248;&#20110;&#22522;&#32447;&#27169;&#22411;&#21644;&#19968;&#20123;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Click through rate (CTR) prediction is very important for Native advertisement but also hard as there is no direct query intent. In this paper we propose a large-scale event embedding scheme to encode the each user browsing event by training a Siamese network with weak supervision on the users' consecutive events. The CTR prediction problem is modeled as a supervised recurrent neural network, which naturally model the user history as a sequence of events. Our proposed recurrent models utilizing pretrained event embedding vectors and an attention layer to model the user history. Our experiments demonstrate that our model significantly outperforms the baseline and some variants.
&lt;/p&gt;</description></item></channel></rss>