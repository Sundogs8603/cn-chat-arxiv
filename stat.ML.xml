<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#20998;&#21035;&#36866;&#29992;&#20110;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#20004;&#31867;&#24615;&#33021;&#24230;&#37327;&#65292;&#24182;&#22522;&#20110;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#22122;&#22768;&#26657;&#27491;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01055</link><description>&lt;p&gt;
&#20174;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#20998;&#21035;&#36866;&#29992;&#20110;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#20004;&#31867;&#24615;&#33021;&#24230;&#37327;&#65292;&#24182;&#22522;&#20110;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#22122;&#22768;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23398;&#20064;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#24471;&#21040;&#33391;&#22909;&#20998;&#31867;&#22120;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#22823;&#22810;&#25968;&#20851;&#20110;&#20174;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#30340;&#24037;&#20316;&#37117;&#38598;&#20013;&#22312;&#26631;&#20934;&#30340;&#22522;&#20110;&#25439;&#22833;&#30340;&#24615;&#33021;&#24230;&#37327;&#19978;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#38656;&#35201;&#20351;&#29992;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#65292;&#36825;&#20123;&#24230;&#37327;&#19981;&#33021;&#34920;&#31034;&#20026;&#21333;&#20010;&#31034;&#20363;&#19978;&#30340;&#25439;&#22833;&#30340;&#26399;&#26395;&#25110;&#24635;&#21644;&#65307;&#20854;&#20013;&#21253;&#25324;&#31867;&#19981;&#24179;&#34913;&#35774;&#32622;&#20013;&#30340;H-mean&#65292;Q-mean&#21644;G-mean&#65292;&#20197;&#21450;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;Micro F1&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20004;&#31867;&#24191;&#27867;&#30340;&#22810;&#31867;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#65292;&#21363;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#65292;&#23427;&#20204;&#21253;&#25324;&#19978;&#36848;&#25152;&#26377;&#31034;&#20363;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22522;&#20110;Narasimhan&#31561;&#20154;&#30340;Frank-Wolfe&#21644;Bisection&#31639;&#27861;(2015)&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22312;&#24191;&#27867;&#30740;&#31350;&#30340;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#23478;&#26063;&#19979;&#24320;&#21457;&#20102;&#31639;&#27861;&#30340;&#22122;&#22768;&#26657;&#27491;&#29256;&#26412;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36951;&#25022;(&#36229;&#39069;&#39118;&#38505;)&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been much interest in recent years in learning good classifiers from data with noisy labels. Most work on learning from noisy labels has focused on standard loss-based performance measures. However, many machine learning problems require using non-decomposable performance measures which cannot be expressed as the expectation or sum of a loss on individual examples; these include for example the H-mean, Q-mean and G-mean in class imbalance settings, and the Micro $F_1$ in information retrieval. In this paper, we design algorithms to learn from noisy labels for two broad classes of multiclass non-decomposable performance measures, namely, monotonic convex and ratio-of-linear, which encompass all the above examples. Our work builds on the Frank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In both cases, we develop noise-corrected versions of the algorithms under the widely studied family of class-conditional noise models. We provide regret (excess risk) bounds 
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#65292;&#38024;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.14081</link><description>&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#36816;&#21160;&#20195;&#30721;&#30340;&#38543;&#26426;&#36807;&#31243;&#27169;&#22411;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Robust Learning of Noisy Time Series Collections Using Stochastic Process Models with Motion Codes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14081
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#65292;&#38024;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#39044;&#27979;&#38382;&#39064;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#20855;&#26377;&#20219;&#24847;&#26102;&#38388;&#24207;&#21015;&#38271;&#24230;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#24773;&#20917;&#20173;&#20855;&#25361;&#25112;&#24615;&#12290;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#23454;&#20363;&#21487;&#20197;&#30475;&#20316;&#26159;&#22024;&#26434;&#21160;&#24577;&#27169;&#22411;&#30340;&#19968;&#20010;&#26679;&#26412;&#23454;&#29616;&#65292;&#20854;&#29305;&#28857;&#26159;&#36830;&#32493;&#38543;&#26426;&#36807;&#31243;&#12290;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#65292;&#25968;&#25454;&#26159;&#28151;&#21512;&#30340;&#65292;&#30001;&#22810;&#20010;&#38543;&#26426;&#36807;&#31243;&#24314;&#27169;&#30340;&#20960;&#31181;&#31867;&#22411;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#24207;&#21015;&#32452;&#25104;&#65292;&#20351;&#24471;&#39044;&#27979;&#21644;&#20998;&#31867;&#20219;&#21153;&#21464;&#24471;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#19981;&#26159;&#31616;&#21333;&#22320;&#23558;&#25968;&#25454;&#22238;&#24402;&#21040;&#27599;&#31181;&#26102;&#38388;&#24207;&#21015;&#31867;&#22411;&#65292;&#32780;&#26159;&#37319;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#20026;&#27599;&#31181;&#31867;&#22411;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#33258;&#21160;&#20998;&#37197;&#19968;&#20010;&#31216;&#20026;&#20854;&#36816;&#21160;&#20195;&#30721;&#30340;&#31614;&#21517;&#21521;&#37327;&#12290;&#28982;&#21518;&#65292;&#22312;&#27599;&#20010;&#20998;&#37197;&#30340;&#36816;&#21160;&#20195;&#30721;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25512;&#26029;&#20986;&#30456;&#20851;&#24615;&#30340;&#31232;&#30095;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14081v1 Announce Type: cross  Abstract: While time series classification and forecasting problems have been extensively studied, the cases of noisy time series data with arbitrary time sequence lengths have remained challenging. Each time series instance can be thought of as a sample realization of a noisy dynamical model, which is characterized by a continuous stochastic process. For many applications, the data are mixed and consist of several types of noisy time series sequences modeled by multiple stochastic processes, making the forecasting and classification tasks even more challenging. Instead of regressing data naively and individually to each time series type, we take a latent variable model approach using a mixtured Gaussian processes with learned spectral kernels. More specifically, we auto-assign each type of noisy time series data a signature vector called its motion code. Then, conditioned on each assigned motion code, we infer a sparse approximation of the corr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35757;&#32451;&#36807;&#31243;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#37327;&#36716;&#25442;&#20844;&#24335;&#26799;&#24230;&#30340;&#39640;&#25928;&#20272;&#35745;&#22120;&#65292;&#20811;&#26381;&#20102;&#24402;&#19968;&#21270;&#27969;&#35774;&#35745;&#22312;&#35299;&#26512;&#36870;&#21464;&#25442;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;&#36825;&#20351;&#24471;&#20219;&#20309;&#20445;&#25345;&#32500;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#21487;&#20197;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#65292;&#24182;&#22312;&#20998;&#23376;&#29983;&#25104;&#21644;&#21453;&#38382;&#39064;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20248;&#31168;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.16624</link><description>&lt;p&gt;
&#33258;&#30001;&#24418;&#24335;&#27969;&#21160;&#65306;&#20351;&#20219;&#20309;&#26550;&#26500;&#25104;&#20026;&#24402;&#19968;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Free-form Flows: Make Any Architecture a Normalizing Flow. (arXiv:2310.16624v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16624
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35757;&#32451;&#36807;&#31243;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#37327;&#36716;&#25442;&#20844;&#24335;&#26799;&#24230;&#30340;&#39640;&#25928;&#20272;&#35745;&#22120;&#65292;&#20811;&#26381;&#20102;&#24402;&#19968;&#21270;&#27969;&#35774;&#35745;&#22312;&#35299;&#26512;&#36870;&#21464;&#25442;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;&#36825;&#20351;&#24471;&#20219;&#20309;&#20445;&#25345;&#32500;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#21487;&#20197;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#65292;&#24182;&#22312;&#20998;&#23376;&#29983;&#25104;&#21644;&#21453;&#38382;&#39064;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20248;&#31168;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#30452;&#25509;&#26368;&#22823;&#21270;&#21487;&#33021;&#24615;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#20197;&#21069;&#65292;&#24402;&#19968;&#21270;&#27969;&#30340;&#35774;&#35745;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21463;&#21040;&#23545;&#35299;&#26512;&#36870;&#21464;&#25442;&#30340;&#38656;&#35201;&#38480;&#21046;&#12290;&#36890;&#36807;&#20351;&#29992;&#23545;&#21464;&#37327;&#36716;&#25442;&#20844;&#24335;&#30340;&#26799;&#24230;&#30340;&#39640;&#25928;&#20272;&#35745;&#22120;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#12290;&#36825;&#20351;&#24471;&#20219;&#20309;&#20445;&#25345;&#32500;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#23558;&#37325;&#28857;&#25918;&#22312;&#31934;&#30830;&#35843;&#25972;&#24402;&#32435;&#20559;&#35265;&#20197;&#36866;&#24212;&#25163;&#22836;&#30340;&#20219;&#21153;&#19978;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#20998;&#23376;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#21033;&#29992;$E(n)$-&#31561;&#21464;&#32593;&#32476;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#20010;&#21453;&#38382;&#39064;&#22522;&#20934;&#27979;&#35797;&#20013;&#20063;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#21516;&#26102;&#37319;&#29992;&#29616;&#25104;&#30340;ResNet&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing Flows are generative models that directly maximize the likelihood. Previously, the design of normalizing flows was largely constrained by the need for analytical invertibility. We overcome this constraint by a training procedure that uses an efficient estimator for the gradient of the change of variables formula. This enables any dimension-preserving neural network to serve as a generative model through maximum likelihood training. Our approach allows placing the emphasis on tailoring inductive biases precisely to the task at hand. Specifically, we achieve excellent results in molecule generation benchmarks utilizing $E(n)$-equivariant networks. Moreover, our method is competitive in an inverse problem benchmark, while employing off-the-shelf ResNet architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#26041;&#27861;&#65292;&#20998;&#21035;&#36890;&#36807;&#26367;&#25442;Lai&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.03722</link><description>&lt;p&gt;
&#26410;&#30693;&#26041;&#24046;&#19979;&#30340;&#39640;&#26031;&#22343;&#20540;&#30340;&#20219;&#24847;&#26377;&#25928;T&#26816;&#39564;&#21644;&#32622;&#20449;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#26041;&#27861;&#65292;&#20998;&#21035;&#36890;&#36807;&#26367;&#25442;Lai&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1976&#24180;&#65292;Lai&#26500;&#36896;&#20102;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#22343;&#20540;$\mu$&#30340;&#39640;&#26031;&#20998;&#24067;&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#35813;&#20998;&#24067;&#30340;&#26041;&#24046;$\sigma$&#26159;&#26410;&#30693;&#30340;&#12290;&#20182;&#20351;&#29992;&#20102;&#20851;&#20110;$\sigma$&#30340;&#19981;&#36866;&#24403;&#65288;&#21491;Haar&#65289;&#28151;&#21512;&#21644;&#20851;&#20110;$\mu$&#30340;&#19981;&#36866;&#24403;&#65288;&#24179;&#22374;&#65289;&#28151;&#21512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#35828;&#26126;&#20102;&#20182;&#26500;&#24314;&#30340;&#32454;&#33410;&#65292;&#20854;&#20013;&#20351;&#29992;&#20102;&#24191;&#20041;&#30340;&#19981;&#21487;&#31215;&#20998;&#38789;&#21644;&#25193;&#23637;&#30340;&#32500;&#23572;&#19981;&#31561;&#24335;&#12290;&#23613;&#31649;&#36825;&#30830;&#23454;&#20135;&#29983;&#20102;&#19968;&#20010;&#39034;&#24207;T&#26816;&#39564;&#65292;&#20294;&#30001;&#20110;&#20182;&#30340;&#38789;&#19981;&#21487;&#31215;&#20998;&#65292;&#23427;&#24182;&#27809;&#26377;&#20135;&#29983;&#19968;&#20010;&#8220;e-process&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#30456;&#21516;&#30340;&#35774;&#32622;&#24320;&#21457;&#20102;&#20004;&#20010;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#65306;&#19968;&#20010;&#26159;&#22312;&#32553;&#20943;&#28388;&#27874;&#22120;&#20013;&#30340;&#27979;&#35797;&#38789;&#65292;&#21478;&#19968;&#20010;&#26159;&#22312;&#35268;&#33539;&#25968;&#25454;&#28388;&#27874;&#22120;&#20013;&#30340;&#8220;e-process&#8221;&#12290;&#36825;&#20123;&#20998;&#21035;&#26159;&#36890;&#36807;&#23558;Lai&#30340;&#24179;&#22374;&#28151;&#21512;&#26367;&#25442;&#20026;&#39640;&#26031;&#28151;&#21512;&#65292;&#24182;&#23558;&#23545;$\sigma$&#30340;&#21491;Haar&#28151;&#21512;&#26367;&#25442;&#20026;&#22312;&#38646;&#31354;&#38388;&#19979;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#23601;&#20687;&#22312;&#36890;&#29992;&#25512;&#26029;&#20013;&#19968;&#26679;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$ of a Gaussian distribution with unknown variance $\sigma$. Curiously, he employed both an improper (right Haar) mixture over $\sigma$ and an improper (flat) mixture over $\mu$. Here, we elaborate carefully on the details of his construction, which use generalized nonintegrable martingales and an extended Ville's inequality. While this does yield a sequential t-test, it does not yield an ``e-process'' (due to the nonintegrability of his martingale). In this paper, we develop two new e-processes and confidence sequences for the same setting: one is a test martingale in a reduced filtration, while the other is an e-process in the canonical data filtration. These are respectively obtained by swapping Lai's flat mixture for a Gaussian mixture, and swapping the right Haar mixture over $\sigma$ with the maximum likelihood estimate under the null, as done in universal inference. We also analyze the width of resulting 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#30740;&#31350;R-learner&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#24456;&#22909;&#22320;&#20272;&#35745;&#22810;&#30740;&#31350;&#20013;&#30340;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#22312;&#29616;&#23454;&#30284;&#30151;&#25968;&#25454;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26356;&#23567;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.01086</link><description>&lt;p&gt;
&#22810;&#30740;&#31350;R-learner&#29992;&#20110;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Multi-study R-learner for Heterogeneous Treatment Effect Estimation. (arXiv:2306.01086v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#30740;&#31350;R-learner&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#24456;&#22909;&#22320;&#20272;&#35745;&#22810;&#30740;&#31350;&#20013;&#30340;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#22312;&#29616;&#23454;&#30284;&#30151;&#25968;&#25454;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26356;&#23567;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#31639;&#27861;&#31867;&#26469;&#20272;&#35745;&#22810;&#20010;&#30740;&#31350;&#20013;&#30340;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#31216;&#20026;&#22810;&#30740;&#31350;R-learner&#65292;&#21487;&#20197;&#27010;&#25324;R-learner&#20197;&#32771;&#34385;&#30740;&#31350;&#38388;&#30340;&#24322;&#36136;&#24615;&#24182;&#23454;&#29616;&#35843;&#25972;&#28151;&#28102;&#30340;&#36328;&#30740;&#31350;&#40065;&#26834;&#24615;&#12290;&#22810;&#30740;&#31350;R-learner&#33021;&#22815;&#28789;&#27963;&#22320;&#34701;&#21512;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#20272;&#35745;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#12289;&#22256;&#25200;&#20989;&#25968;&#21644;&#25104;&#21592;&#27010;&#29575;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22810;&#30740;&#31350;R-learner&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#22312;&#24207;&#21015;&#20272;&#35745;&#26694;&#26550;&#20869;&#26159;&#28176;&#36817;&#27491;&#24120;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#29616;&#23454;&#30284;&#30151;&#25968;&#25454;&#23454;&#39564;&#35777;&#26126;&#65292;&#38543;&#30528;&#30740;&#31350;&#38388;&#30340;&#24322;&#36136;&#24615;&#22686;&#21152;&#65292;&#19982;R-learner&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20272;&#35745;&#35823;&#24046;&#26356;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a general class of algorithms for estimating heterogeneous treatment effects on multiple studies. Our approach, called the multi-study R-learner, generalizes the R-learner to account for between-study heterogeneity and achieves cross-study robustness of confounding adjustment. The multi-study R-learner is flexible in its ability to incorporate many machine learning techniques for estimating heterogeneous treatment effects, nuisance functions, and membership probabilities. We show that the multi-study R-learner treatment effect estimator is asymptotically normal within the series estimation framework. Moreover, we illustrate via realistic cancer data experiments that our approach results in lower estimation error than the R-learner as between-study heterogeneity increases.
&lt;/p&gt;</description></item></channel></rss>