<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#22312;&#20998;&#24067;&#23618;&#38754;&#19978;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#27745;&#26579;&#27169;&#22411;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#20998;&#26512;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#36125;&#21494;&#26031;&#39118;&#38505;&#30340;&#21464;&#21270;&#23637;&#31034;&#20102;&#36825;&#20123;&#27745;&#26579;&#23545;&#26631;&#20934;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#36827;&#19968;&#27493;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#21521;&#21644;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2307.08643</link><description>&lt;p&gt;
&#19968;&#20010;&#23398;&#20064;&#21463;&#21040;&#27745;&#26579;&#30340;&#36890;&#29992;&#26694;&#26550;&#65306;&#26631;&#31614;&#22122;&#22768;&#12289;&#23646;&#24615;&#22122;&#22768;&#31561;&#31561;
&lt;/p&gt;
&lt;p&gt;
A General Framework for Learning under Corruption: Label Noise, Attribute Noise, and Beyond. (arXiv:2307.08643v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08643
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#22312;&#20998;&#24067;&#23618;&#38754;&#19978;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#27745;&#26579;&#27169;&#22411;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#20998;&#26512;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#36125;&#21494;&#26031;&#39118;&#38505;&#30340;&#21464;&#21270;&#23637;&#31034;&#20102;&#36825;&#20123;&#27745;&#26579;&#23545;&#26631;&#20934;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#36827;&#19968;&#27493;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#21521;&#21644;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#30340;&#27745;&#26579;&#29616;&#35937;&#24456;&#24120;&#35265;&#65292;&#24182;&#19988;&#24050;&#32463;&#22312;&#19981;&#21516;&#30340;&#27745;&#26579;&#27169;&#22411;&#19979;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#28982;&#20102;&#35299;&#26377;&#38480;&#65292;&#32570;&#20047;&#23545;&#27745;&#26579;&#21450;&#20854;&#23545;&#23398;&#20064;&#30340;&#24433;&#21709;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#26680;&#30340;&#19968;&#33324;&#24615;&#21644;&#35814;&#23613;&#30340;&#26694;&#26550;&#65292;&#22312;&#20998;&#24067;&#23618;&#38754;&#19978;&#27491;&#24335;&#20998;&#26512;&#20102;&#27745;&#26579;&#27169;&#22411;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#26631;&#31614;&#21644;&#23646;&#24615;&#19978;&#23384;&#22312;&#30340;&#22797;&#26434;&#32852;&#21512;&#21644;&#20381;&#36182;&#24615;&#27745;&#26579;&#65292;&#36825;&#22312;&#29616;&#26377;&#30740;&#31350;&#20013;&#24456;&#23569;&#35302;&#21450;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#36125;&#21494;&#26031;&#39118;&#38505;&#21464;&#21270;&#26469;&#23637;&#31034;&#36825;&#20123;&#27745;&#26579;&#22914;&#20309;&#24433;&#21709;&#26631;&#20934;&#30340;&#30417;&#30563;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25552;&#20379;&#20102;&#23545;&#20110;&#8220;&#26356;&#22797;&#26434;&#8221;&#27745;&#26579;&#23545;&#23398;&#20064;&#38382;&#39064;&#24433;&#21709;&#30340;&#23450;&#24615;&#27934;&#23519;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#23450;&#37327;&#27604;&#36739;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;&#35813;&#26694;&#26550;&#30340;&#24212;&#29992;&#21253;&#25324;&#27745;&#26579;&#26657;&#27491;&#23398;&#20064;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#20010;&#23376;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Corruption is frequently observed in collected data and has been extensively studied in machine learning under different corruption models. Despite this, there remains a limited understanding of how these models relate such that a unified view of corruptions and their consequences on learning is still lacking. In this work, we formally analyze corruption models at the distribution level through a general, exhaustive framework based on Markov kernels. We highlight the existence of intricate joint and dependent corruptions on both labels and attributes, which are rarely touched by existing research. Further, we show how these corruptions affect standard supervised learning by analyzing the resulting changes in Bayes Risk. Our findings offer qualitative insights into the consequences of "more complex" corruptions on the learning problem, and provide a foundation for future quantitative comparisons. Applications of the framework include corruption-corrected learning, a subcase of which we 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37325;&#21472;&#25209;&#27425;&#30340;&#32622;&#20449;&#21306;&#38388;&#36807;&#31243;&#65292;&#36866;&#29992;&#20110;&#26500;&#24314;&#32479;&#35745;&#21151;&#33021;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#20998;&#20301;&#25968;&#12289;&#20248;&#21270;&#21644;&#20272;&#35745;&#31561;&#22810;&#31181;&#39046;&#22495;&#12290;&#36890;&#36807;&#20551;&#35774;&#32479;&#35745;&#21151;&#33021;&#30340;&#28857;&#20272;&#35745;&#28385;&#36275;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#26412;&#26041;&#27861;&#33021;&#22815;&#35782;&#21035;&#25209;&#27425;&#23398;&#29983;&#21270;&#32479;&#35745;&#37327;&#30340;&#24369;&#28176;&#36817;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.08609</link><description>&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#26500;&#24314;&#30340;&#32479;&#35745;&#21151;&#33021;&#30340;&#37325;&#21472;&#25209;&#27425;&#32622;&#20449;&#21306;&#38388;&#65306;&#24212;&#29992;&#20110;&#20998;&#20301;&#25968;&#12289;&#20248;&#21270;&#21644;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Overlapping Batch Confidence Intervals on Statistical Functionals Constructed from Time Series: Application to Quantiles, Optimization, and Estimation. (arXiv:2307.08609v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08609
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37325;&#21472;&#25209;&#27425;&#30340;&#32622;&#20449;&#21306;&#38388;&#36807;&#31243;&#65292;&#36866;&#29992;&#20110;&#26500;&#24314;&#32479;&#35745;&#21151;&#33021;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#20998;&#20301;&#25968;&#12289;&#20248;&#21270;&#21644;&#20272;&#35745;&#31561;&#22810;&#31181;&#39046;&#22495;&#12290;&#36890;&#36807;&#20551;&#35774;&#32479;&#35745;&#21151;&#33021;&#30340;&#28857;&#20272;&#35745;&#28385;&#36275;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#26412;&#26041;&#27861;&#33021;&#22815;&#35782;&#21035;&#25209;&#27425;&#23398;&#29983;&#21270;&#32479;&#35745;&#37327;&#30340;&#24369;&#28176;&#36817;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26500;&#24314;&#30340;&#32479;&#35745;&#21151;&#33021;&#30340;&#36890;&#29992;&#32622;&#20449;&#21306;&#38388;&#36807;&#31243;&#65288;CIP&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#25512;&#23548;&#20986;&#30340;$\chi^2$&#21644;&#23398;&#29983;t&#20998;&#24067;&#30340;&#32479;&#35745;&#21151;&#33021;&#19978;&#30340;&#26080;&#20998;&#24067;&#27169;&#25311;&#30340;&#21464;&#37327;&#65292;&#22240;&#27492;&#36866;&#29992;&#20110;&#21253;&#25324;&#20998;&#20301;&#25968;&#20272;&#35745;&#12289;&#26799;&#24230;&#20272;&#35745;&#12289;M&#20272;&#35745;&#12289;CVAR&#20272;&#35745;&#21644;&#21040;&#36798;&#36807;&#31243;&#36895;&#29575;&#20272;&#35745;&#22312;&#20869;&#30340;&#21508;&#31181;&#35774;&#32622;&#65292;&#38500;&#20102;&#20256;&#32479;&#30340;&#32479;&#35745;&#35774;&#32622;&#12290;&#19982;&#27425;&#25277;&#26679;&#26041;&#27861;&#31867;&#20284;&#65292;&#25105;&#20204;&#20351;&#29992;&#37325;&#21472;&#30340;&#26102;&#38388;&#24207;&#21015;&#25209;&#27425;&#26469;&#20272;&#35745;&#28508;&#22312;&#30340;&#26041;&#24046;&#21442;&#25968;&#65307;&#28982;&#32780;&#65292;&#19982;&#27425;&#25277;&#26679;&#21644;&#33258;&#21161;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#20551;&#35774;&#32479;&#35745;&#21151;&#33021;&#30340;&#26263;&#25351;&#28857;&#20272;&#35745;&#31526;&#21512;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65288;CLT&#65289;&#65292;&#20197;&#24110;&#21161;&#35782;&#21035;&#25209;&#37327;&#23398;&#29983;&#21270;&#32479;&#35745;&#37327;&#30340;&#24369;&#28176;&#36817;&#24615;&#65288;&#31216;&#20026;OB-x&#26497;&#38480;&#65292;x=I,II,III&#65289;&#12290;OB-x&#26497;&#38480;&#26159;&#30001;Wiener&#36807;&#31243;&#30340;&#26576;&#20123;&#21151;&#33021;&#21442;&#25968;&#21270;&#25152;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a general purpose confidence interval procedure (CIP) for statistical functionals constructed using data from a stationary time series. The procedures we propose are based on derived distribution-free analogues of the $\chi^2$ and Student's $t$ random variables for the statistical functional context, and hence apply in a wide variety of settings including quantile estimation, gradient estimation, M-estimation, CVAR-estimation, and arrival process rate estimation, apart from more traditional statistical settings. Like the method of subsampling, we use overlapping batches of time series data to estimate the underlying variance parameter; unlike subsampling and the bootstrap, however, we assume that the implied point estimator of the statistical functional obeys a central limit theorem (CLT) to help identify the weak asymptotics (called OB-x limits, x=I,II,III) of batched Studentized statistics. The OB-x limits, certain functionals of the Wiener process parameterized by the siz
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37319;&#29992;&#22768;&#23398;&#20998;&#36776;&#29575;&#20809;&#22768;&#26174;&#24494;&#38236;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#32467;&#30452;&#32928;&#32452;&#32455;&#20998;&#31867;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23558;&#33391;&#24615;&#21644;&#24694;&#24615;&#32452;&#32455;&#21306;&#20998;&#24320;&#26469;&#12290;</title><link>http://arxiv.org/abs/2307.08556</link><description>&lt;p&gt;
&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#22768;&#23398;&#20998;&#36776;&#29575;&#20809;&#22768;&#26174;&#24494;&#38236;&#30340;&#32467;&#30452;&#32928;&#32452;&#32455;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Machine-Learning-based Colorectal Tissue Classification via Acoustic Resolution Photoacoustic Microscopy. (arXiv:2307.08556v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08556
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37319;&#29992;&#22768;&#23398;&#20998;&#36776;&#29575;&#20809;&#22768;&#26174;&#24494;&#38236;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#32467;&#30452;&#32928;&#32452;&#32455;&#20998;&#31867;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23558;&#33391;&#24615;&#21644;&#24694;&#24615;&#32452;&#32455;&#21306;&#20998;&#24320;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#30452;&#32928;&#30284;&#26159;&#19968;&#31181;&#33268;&#21629;&#30340;&#30142;&#30149;&#65292;&#22312;&#36817;&#24180;&#26469;&#26085;&#30410;&#26222;&#36941;&#12290;&#26089;&#26399;&#26816;&#27979;&#23545;&#20110;&#25405;&#25937;&#29983;&#21629;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#20256;&#32479;&#30340;&#35786;&#26029;&#26041;&#27861;&#22914;&#32467;&#32928;&#38236;&#26816;&#26597;&#21644;&#27963;&#26816;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#32467;&#32928;&#38236;&#26080;&#27861;&#25552;&#20379;&#30284;&#30151;&#24433;&#21709;&#32452;&#32455;&#20869;&#35814;&#32454;&#20449;&#24687;&#65292;&#32780;&#27963;&#26816;&#28041;&#21450;&#32452;&#32455;&#20999;&#38500;&#65292;&#21487;&#33021;&#24341;&#36215;&#30140;&#30171;&#21644;&#20405;&#34989;&#24615;&#12290;&#20026;&#20102;&#25552;&#39640;&#35786;&#26029;&#25928;&#29575;&#21644;&#20943;&#23569;&#24739;&#32773;&#30171;&#33510;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#22768;&#23398;&#20998;&#36776;&#29575;&#20809;&#22768;&#26174;&#24494;&#38236; (ARPAM) &#30340;&#32467;&#30452;&#32928;&#32452;&#32455;&#20998;&#31867;&#26041;&#27861;&#12290;&#20351;&#29992;&#36825;&#31181;&#24037;&#20855;&#65292;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23545;&#33391;&#24615;&#21644;&#24694;&#24615;&#32452;&#32455;&#36827;&#34892;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36890;&#36807;&#23450;&#37327;&#21644;&#23450;&#24615;&#20998;&#26512;&#65292;&#35780;&#20272;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Colorectal cancer is a deadly disease that has become increasingly prevalent in recent years. Early detection is crucial for saving lives, but traditional diagnostic methods such as colonoscopy and biopsy have limitations. Colonoscopy cannot provide detailed information within the tissues affected by cancer, while biopsy involves tissue removal, which can be painful and invasive. In order to improve diagnostic efficiency and reduce patient suffering, we studied machine-learningbased approach for colorectal tissue classification that uses acoustic resolution photoacoustic microscopy (ARPAM). With this tool, we were able to classify benign and malignant tissue using multiple machine learning methods. Our results were analyzed both quantitatively and qualitatively to evaluate the effectiveness of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#20854;&#23450;&#20041;&#12289;&#20851;&#31995;&#21450;&#22270;&#24418;&#24847;&#20041;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#34164;&#21547;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#32780;&#26465;&#20214;&#29420;&#31435;&#24615;&#23545;&#28385;&#36275;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#30340;&#31243;&#24230;&#25110;&#21487;&#33021;&#24615;&#27809;&#26377;&#24433;&#21709;&#12290;&#31163;&#25955;&#22240;&#26524;&#27169;&#22411;&#20013;&#30340;&#21453;&#20107;&#23454;&#19981;&#21464;&#20989;&#25968;&#36890;&#24120;&#21463;&#21040;&#29305;&#23450;&#21464;&#37327;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.08519</link><description>&lt;p&gt;
&#20851;&#20110;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#30340;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Results on Counterfactual Invariance. (arXiv:2307.08519v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08519
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#20854;&#23450;&#20041;&#12289;&#20851;&#31995;&#21450;&#22270;&#24418;&#24847;&#20041;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#34164;&#21547;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#32780;&#26465;&#20214;&#29420;&#31435;&#24615;&#23545;&#28385;&#36275;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#30340;&#31243;&#24230;&#25110;&#21487;&#33021;&#24615;&#27809;&#26377;&#24433;&#21709;&#12290;&#31163;&#25955;&#22240;&#26524;&#27169;&#22411;&#20013;&#30340;&#21453;&#20107;&#23454;&#19981;&#21464;&#20989;&#25968;&#36890;&#24120;&#21463;&#21040;&#29305;&#23450;&#21464;&#37327;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#21508;&#31181;&#29616;&#26377;&#23450;&#20041;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#20197;&#21450;&#23427;&#20204;&#30340;&#22270;&#24418;&#24847;&#20041;&#12290;&#28982;&#21518;&#25105;&#20204;&#36716;&#21521;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#22260;&#32469;&#30340;&#20027;&#35201;&#38382;&#39064;&#65292;&#21363;&#23427;&#19982;&#26465;&#20214;&#29420;&#31435;&#24615;&#30340;&#20851;&#31995;&#22914;&#20309;&#65311;&#25105;&#20204;&#26174;&#31034;&#65292;&#34429;&#28982;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#34164;&#21547;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#20294;&#26465;&#20214;&#29420;&#31435;&#24615;&#23545;&#28385;&#36275;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#30340;&#31243;&#24230;&#25110;&#21487;&#33021;&#24615;&#27809;&#26377;&#20219;&#20309;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#26174;&#31034;&#23545;&#20110;&#31163;&#25955;&#22240;&#26524;&#27169;&#22411;&#65292;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#20989;&#25968;&#36890;&#24120;&#21463;&#21040;&#29305;&#23450;&#21464;&#37327;&#30340;&#38480;&#21046;&#65292;&#29978;&#33267;&#26159;&#24120;&#25968;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we provide a theoretical analysis of counterfactual invariance. We present a variety of existing definitions, study how they relate to each other and what their graphical implications are. We then turn to the current major question surrounding counterfactual invariance, how does it relate to conditional independence? We show that whilst counterfactual invariance implies conditional independence, conditional independence does not give any implications about the degree or likelihood of satisfying counterfactual invariance. Furthermore, we show that for discrete causal models counterfactually invariant functions are often constrained to be functions of particular variables, or even constant.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#25193;&#23637;&#26368;&#36817;&#30340;&#38750;&#21442;&#25968;&#25910;&#25947;&#36895;&#24230;&#32467;&#26524;&#65292;&#30740;&#31350;&#20102;&#39532;&#23572;&#21487;&#22827;&#35774;&#35745;&#19979;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#21327;&#21464;&#37327;&#20559;&#31227;&#12290;&#20316;&#32773;&#35777;&#26126;&#20102;&#22312;&#22238;&#24402;&#20989;&#25968;&#20855;&#26377;H\"older&#24179;&#28369;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;Nadaraya-Watson&#26680;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#39118;&#38505;&#30340;&#25910;&#25947;&#36895;&#24230;&#21462;&#20915;&#20110;&#28304;&#21644;&#30446;&#26631;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#22266;&#26377;&#20998;&#24067;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#23485;&#30456;&#20851;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#26469;&#25429;&#25417;&#36825;&#31181;&#30456;&#20284;&#24615;&#12290;&#20316;&#32773;&#36824;&#23548;&#20986;&#20102;&#26377;&#38480;&#39532;&#23572;&#21487;&#22827;&#38142;&#21644;&#35889;&#38388;&#38553;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#31934;&#30830;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.08517</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#35774;&#35745;&#30340;&#21327;&#21464;&#37327;&#20559;&#31227;
&lt;/p&gt;
&lt;p&gt;
Covariate shift in nonparametric regression with Markovian design. (arXiv:2307.08517v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08517
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#25193;&#23637;&#26368;&#36817;&#30340;&#38750;&#21442;&#25968;&#25910;&#25947;&#36895;&#24230;&#32467;&#26524;&#65292;&#30740;&#31350;&#20102;&#39532;&#23572;&#21487;&#22827;&#35774;&#35745;&#19979;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#21327;&#21464;&#37327;&#20559;&#31227;&#12290;&#20316;&#32773;&#35777;&#26126;&#20102;&#22312;&#22238;&#24402;&#20989;&#25968;&#20855;&#26377;H\"older&#24179;&#28369;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;Nadaraya-Watson&#26680;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#39118;&#38505;&#30340;&#25910;&#25947;&#36895;&#24230;&#21462;&#20915;&#20110;&#28304;&#21644;&#30446;&#26631;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#22266;&#26377;&#20998;&#24067;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#23485;&#30456;&#20851;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#26469;&#25429;&#25417;&#36825;&#31181;&#30456;&#20284;&#24615;&#12290;&#20316;&#32773;&#36824;&#23548;&#20986;&#20102;&#26377;&#38480;&#39532;&#23572;&#21487;&#22827;&#38142;&#21644;&#35889;&#38388;&#38553;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#31934;&#30830;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#21327;&#21464;&#37327;&#20559;&#31227;&#21644;&#35757;&#32451;&#25968;&#25454;&#19982;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#21305;&#37197;&#26159;&#19968;&#31181;&#24120;&#35265;&#29616;&#35937;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#26368;&#36817;&#20851;&#20110;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#38750;&#21442;&#25968;&#25910;&#25947;&#36895;&#24230;&#32467;&#26524;&#25193;&#23637;&#21040;&#39532;&#23572;&#21487;&#22827;&#20381;&#36182;&#32467;&#26500;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#23545;&#22238;&#24402;&#20989;&#25968;&#36827;&#34892;H\"older&#24179;&#28369;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;Nadaraya-Watson&#26680;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#39118;&#38505;&#30340;&#25910;&#25947;&#36895;&#24230;&#30001;&#28304;&#21644;&#30446;&#26631;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#22266;&#26377;&#20998;&#24067;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#20915;&#23450;&#12290;&#36825;&#31181;&#30456;&#20284;&#24615;&#21487;&#20197;&#26126;&#30830;&#22320;&#29992;&#26368;&#36817;Pathak&#12289;Ma&#21644;Wainwright [ICML&#65292;2022]&#20013;&#24341;&#20837;&#30340;&#19968;&#20010;&#20381;&#36182;&#20110;&#24102;&#23485;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#26469;&#25429;&#25417;&#12290;&#23545;&#20110;&#26377;&#38480;&#39532;&#23572;&#21487;&#22827;&#38142;&#21644;&#35889;&#38388;&#38553;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#23548;&#20986;&#20102;&#31934;&#30830;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;&#20854;&#22266;&#26377;&#20998;&#24067;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#38543;&#30528;&#24102;&#23485;&#30340;&#20943;&#23567;&#32780;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#23545;&#20110;&#21518;&#32773;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Covariate shift in regression problems and the associated distribution mismatch between training and test data is a commonly encountered phenomenon in machine learning. In this paper, we extend recent results on nonparametric convergence rates for i.i.d. data to Markovian dependence structures. We demonstrate that under H\"older smoothness assumptions on the regression function, convergence rates for the generalization risk of a Nadaraya-Watson kernel estimator are determined by the similarity between the invariant distributions associated to source and target Markov chains. The similarity is explicitly captured in terms of a bandwidth-dependent similarity measure recently introduced in Pathak, Ma and Wainwright [ICML, 2022]. Precise convergence rates are derived for the particular cases of finite Markov chains and spectral gap Markov chains for which the similarity measure between their invariant distributions grows polynomially with decreasing bandwidth. For the latter, we extend the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#27979;&#35797;&#26694;&#26550;&#65292;&#21487;&#20197;&#38750;&#32447;&#24615;&#27604;&#36739;&#22797;&#26434;&#30340;&#32454;&#32990;&#38388;&#20998;&#23376;&#29305;&#24449;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#26680;&#23884;&#20837;&#30340;&#21464;&#24322;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#32454;&#32990;&#32676;&#20307;&#20013;&#38544;&#34109;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26680;&#27979;&#35797;&#22914;&#20309;&#20811;&#26381;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#24212;&#29992;&#20110;&#30740;&#31350;&#20998;&#21270;&#36870;&#36716;&#30340;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2307.08509</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Kernel-Based Testing for Single-Cell Differential Analysis. (arXiv:2307.08509v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#27979;&#35797;&#26694;&#26550;&#65292;&#21487;&#20197;&#38750;&#32447;&#24615;&#27604;&#36739;&#22797;&#26434;&#30340;&#32454;&#32990;&#38388;&#20998;&#23376;&#29305;&#24449;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#26680;&#23884;&#20837;&#30340;&#21464;&#24322;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#32454;&#32990;&#32676;&#20307;&#20013;&#38544;&#34109;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26680;&#27979;&#35797;&#22914;&#20309;&#20811;&#26381;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#24212;&#29992;&#20110;&#30740;&#31350;&#20998;&#21270;&#36870;&#36716;&#30340;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#32454;&#32990;&#25216;&#26415;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#22522;&#22240;&#34920;&#36798;&#21644;&#34920;&#35266;&#36951;&#20256;&#20462;&#39280;&#31561;&#20998;&#23376;&#29305;&#24449;&#30340;&#23453;&#36149;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20197;&#25511;&#21046;&#21644;&#24378;&#26377;&#21147;&#30340;&#26041;&#24335;&#27604;&#36739;&#36825;&#20123;&#22797;&#26434;&#20998;&#24067;&#38754;&#20020;&#30528;&#26041;&#27861;&#35770;&#19978;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#22522;&#20110;&#26680;&#23884;&#20837;&#30340;&#26680;&#27979;&#35797;&#26694;&#26550;&#26469;&#38750;&#32447;&#24615;&#27604;&#36739;&#32454;&#32990;&#38388;&#22797;&#26434;&#20998;&#23376;&#29305;&#24449;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#19981;&#20165;&#20801;&#35768;&#23545;&#29305;&#24449;&#36827;&#34892;&#20998;&#26512;&#65292;&#36824;&#33021;&#22312;&#32771;&#34385;&#20102;&#23427;&#20204;&#20043;&#38388;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#36716;&#24405;&#32452;&#25110;&#34920;&#35266;&#32452;&#30340;&#20840;&#23616;&#27604;&#36739;&#12290;&#36890;&#36807;&#20351;&#29992;&#20998;&#31867;&#22120;&#22522;&#20110;&#26680;&#23884;&#20837;&#30340;&#21464;&#24322;&#24615;&#26469;&#21306;&#20998;&#32454;&#32990;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#21457;&#29616;&#22312;&#32454;&#32990;&#32676;&#20307;&#20013;&#21407;&#26412;&#26080;&#27861;&#23519;&#35273;&#21040;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26680;&#27979;&#35797;&#26041;&#27861;&#22914;&#20309;&#20811;&#26381;&#19987;&#38376;&#29992;&#20110;&#21333;&#32454;&#32990;&#30340;&#24046;&#24322;&#20998;&#26512;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#36824;&#23558;&#26680;&#27979;&#35797;&#24212;&#29992;&#20110;&#30740;&#31350;&#20998;&#21270;&#36870;&#36716;&#30340;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Single-cell technologies have provided valuable insights into the distribution of molecular features, such as gene expression and epigenomic modifications. However, comparing these complex distributions in a controlled and powerful manner poses methodological challenges. Here we propose to benefit from the kernel-testing framework to compare the complex cell-wise distributions of molecular features in a non-linear manner based on their kernel embedding. Our framework not only allows for feature-wise analyses but also enables global comparisons of transcriptomes or epigenomes, considering their intricate dependencies. By using a classifier to discriminate cells based on the variability of their embedding, our method uncovers heterogeneities in cell populations that would otherwise go undetected. We show that kernel testing overcomes the limitations of differential analysis methods dedicated to single-cell. Kernel testing is applied to investigate the reversion process of differentiating
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#25935;&#24863;&#30340;&#31181;&#26063;&#21644;&#26063;&#35028;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#31181;&#26063;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#35757;&#32451;&#20102;&#19968;&#20010;&#21452;&#21521;&#38271;&#30701;&#26102;&#35760;&#24518;&#65288;BiLSTM&#65289;&#27169;&#22411;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#38598;&#25104;&#27169;&#22411;&#65292;&#20854;&#22312;&#22806;&#26679;&#26412;&#65288;OOS&#65289;F1&#24471;&#20998;&#19978;&#27604;&#25991;&#29486;&#20013;&#34920;&#29616;&#26368;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39640;&#20986;36.8%&#12290;&#27492;&#22806;&#65292;&#36824;&#26500;&#24314;&#20102;&#32654;&#22269;&#26368;&#20840;&#38754;&#30340;&#22995;&#27663;&#21644;&#21517;&#23383;&#20998;&#24067;&#25968;&#25454;&#24211;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20197;&#20844;&#27491;&#27604;&#36739;&#29616;&#26377;&#27169;&#22411;&#65292;&#24182;&#24110;&#21161;&#26410;&#26469;&#30340;&#27169;&#22411;&#24320;&#21457;&#32773;&#12290;</title><link>http://arxiv.org/abs/2307.08496</link><description>&lt;p&gt;
&#25105;&#20204;&#33021;&#30456;&#20449;&#31181;&#26063;&#39044;&#27979;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can We Trust Race Prediction?. (arXiv:2307.08496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#25935;&#24863;&#30340;&#31181;&#26063;&#21644;&#26063;&#35028;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#31181;&#26063;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#35757;&#32451;&#20102;&#19968;&#20010;&#21452;&#21521;&#38271;&#30701;&#26102;&#35760;&#24518;&#65288;BiLSTM&#65289;&#27169;&#22411;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#38598;&#25104;&#27169;&#22411;&#65292;&#20854;&#22312;&#22806;&#26679;&#26412;&#65288;OOS&#65289;F1&#24471;&#20998;&#19978;&#27604;&#25991;&#29486;&#20013;&#34920;&#29616;&#26368;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39640;&#20986;36.8%&#12290;&#27492;&#22806;&#65292;&#36824;&#26500;&#24314;&#20102;&#32654;&#22269;&#26368;&#20840;&#38754;&#30340;&#22995;&#27663;&#21644;&#21517;&#23383;&#20998;&#24067;&#25968;&#25454;&#24211;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20197;&#20844;&#27491;&#27604;&#36739;&#29616;&#26377;&#27169;&#22411;&#65292;&#24182;&#24110;&#21161;&#26410;&#26469;&#30340;&#27169;&#22411;&#24320;&#21457;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27809;&#26377;&#25935;&#24863;&#30340;&#31181;&#26063;&#21644;&#26063;&#35028;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20154;&#21592;&#12289;&#30417;&#31649;&#26426;&#26500;&#21644;&#20844;&#21496;&#37117;&#20511;&#21161;&#20195;&#29702;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20351;&#29992;&#26469;&#33258;&#32654;&#22269;50&#20010;&#24030;&#30340;&#36873;&#27665;&#27880;&#20876;&#25968;&#25454;&#35757;&#32451;&#20102;&#19968;&#20010;&#21452;&#21521;&#38271;&#30701;&#26102;&#35760;&#24518;&#65288;BiLSTM&#65289;&#27169;&#22411;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#38598;&#25104;&#27169;&#22411;&#65292;&#20854;&#22312;&#22806;&#26679;&#26412;&#65288;OOS&#65289;F1&#24471;&#20998;&#19978;&#27604;&#25991;&#29486;&#20013;&#34920;&#29616;&#26368;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39640;&#20986;36.8%&#12290;&#27492;&#22806;&#65292;&#25105;&#26500;&#24314;&#20102;&#32654;&#22269;&#26368;&#20840;&#38754;&#30340;&#22995;&#27663;&#21644;&#21517;&#23383;&#20998;&#24067;&#25968;&#25454;&#24211;&#65292;&#20197;&#25913;&#36827;&#36125;&#21494;&#26031;&#25913;&#36827;&#22995;&#27663;&#22320;&#29702;&#32534;&#30721;&#65288;BISG&#65289;&#21644;&#36125;&#21494;&#26031;&#25913;&#36827;&#21517;&#23383;&#22995;&#27663;&#22320;&#29702;&#32534;&#30721;&#65288;BIFSG&#65289;&#30340;&#35206;&#30422;&#21644;&#20934;&#30830;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20197;&#20844;&#27491;&#27604;&#36739;&#29616;&#26377;&#27169;&#22411;&#65292;&#24182;&#24110;&#21161;&#26410;&#26469;&#30340;&#27169;&#22411;&#24320;&#21457;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the absence of sensitive race and ethnicity data, researchers, regulators, and firms alike turn to proxies. In this paper, I train a Bidirectional Long Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data from all 50 US states and create an ensemble that achieves up to 36.8% higher out of sample (OOS) F1 scores than the best performing machine learning models in the literature. Additionally, I construct the most comprehensive database of first and surname distributions in the US in order to improve the coverage and accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved Firstname Surname Geocoding (BIFSG). Finally, I provide the first high-quality benchmark dataset in order to fairly compare existing models and aid future model developers.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#21449;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#20197;&#28040;&#38500;&#21487;&#35299;&#37322;&#24615;&#22686;&#24378;&#26426;&#22120;&#20013;&#30340;&#34394;&#20551;&#30456;&#20114;&#20316;&#29992;&#21644;&#21333;&#20010;&#29305;&#24449;&#20027;&#23548;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.08485</link><description>&lt;p&gt;
&#20132;&#21449;&#29305;&#24449;&#36873;&#25321;&#20197;&#28040;&#38500;&#34394;&#20551;&#30456;&#20114;&#20316;&#29992;&#21644;&#21333;&#20010;&#29305;&#24449;&#20027;&#23548;&#30340;&#21487;&#35299;&#37322;&#24615;&#22686;&#24378;&#26426;&#22120;
&lt;/p&gt;
&lt;p&gt;
Cross Feature Selection to Eliminate Spurious Interactions and Single Feature Dominance Explainable Boosting Machines. (arXiv:2307.08485v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08485
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#21449;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#20197;&#28040;&#38500;&#21487;&#35299;&#37322;&#24615;&#22686;&#24378;&#26426;&#22120;&#20013;&#30340;&#34394;&#20551;&#30456;&#20114;&#20316;&#29992;&#21644;&#21333;&#20010;&#29305;&#24449;&#20027;&#23548;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#24615;&#26159;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#19968;&#20010;&#37325;&#35201;&#26041;&#38754;&#65292;&#23427;&#20351;&#20154;&#20204;&#33021;&#22815;&#29702;&#35299;&#21644;&#20449;&#20219;&#36825;&#20123;&#27169;&#22411;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#65292;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#23545;&#20110;&#27861;&#24459;&#12289;&#36947;&#24503;&#21644;&#23454;&#38469;&#21407;&#22240;&#26469;&#35828;&#37117;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20363;&#22914;&#65292;&#22312;&#38134;&#34892;&#39046;&#22495;&#65292;&#35299;&#37322;&#24615;&#23545;&#20110;&#20511;&#27454;&#20154;&#21644;&#36151;&#27454;&#20154;&#26469;&#29702;&#35299;&#36151;&#27454;&#30003;&#35831;&#30340;&#25509;&#21463;&#25110;&#25298;&#32477;&#32972;&#21518;&#30340;&#21407;&#22240;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#36825;&#28041;&#21450;&#21040;&#20844;&#24179;&#36151;&#27454;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#22797;&#26434;&#30340;&#39640;&#24615;&#33021;&#27169;&#22411;&#20013;&#23454;&#29616;&#35299;&#37322;&#24615;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22240;&#27492;&#65292;&#21487;&#35299;&#37322;&#24615;&#22686;&#24378;&#26426;&#22120;&#65288;EBM&#65289;&#30001;&#20110;&#20854;&#21487;&#35299;&#37322;&#24615;&#21644;&#39640;&#24615;&#33021;&#22312;&#21508;&#31181;&#39044;&#27979;&#20219;&#21153;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#23384;&#22312;&#19982;&#20887;&#20313;&#29305;&#24449;&#30340;&#34394;&#20551;&#30456;&#20114;&#20316;&#29992;&#21644;&#21333;&#20010;&#29305;&#24449;&#22312;&#25152;&#26377;&#30456;&#20114;&#20316;&#29992;&#20013;&#30340;&#20027;&#23548;&#22320;&#20301;&#31561;&#38382;&#39064;&#65292;&#36825;&#21487;&#33021;&#24433;&#21709;&#27169;&#22411;&#39044;&#27979;&#30340;&#35299;&#37322;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretability is a crucial aspect of machine learning models that enables humans to understand and trust the decision-making process of these models. In many real-world applications, the interpretability of models is essential for legal, ethical, and practical reasons. For instance, in the banking domain, interpretability is critical for lenders and borrowers to understand the reasoning behind the acceptance or rejection of loan applications as per fair lending laws. However, achieving interpretability in machine learning models is challenging, especially for complex high-performance models. Hence Explainable Boosting Machines (EBMs) have been gaining popularity due to their interpretable and high-performance nature in various prediction tasks. However, these models can suffer from issues such as spurious interactions with redundant features and single-feature dominance across all interactions, which can affect the interpretability and reliability of the model's predictions. In this
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#26031;&#20998;&#24067;&#19979;&#23398;&#20064;&#20855;&#26377;&#38543;&#26426;&#20998;&#31867;&#22122;&#22768;&#30340;&#19968;&#33324;&#21322;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20046;&#26368;&#20248;&#30340;&#31639;&#27861;&#21644;&#32479;&#35745;&#26597;&#35810;&#30340;&#19979;&#30028;&#65292;&#21457;&#29616;&#20102;&#35813;&#38382;&#39064;&#20013;&#30340;&#20449;&#24687;&#35745;&#31639;&#38388;&#38553;&#65292;&#24182;&#32473;&#20986;&#20102;&#20855;&#26377;&#20004;&#39033;&#24179;&#26041;&#20381;&#36182;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.08438</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#38543;&#26426;&#20998;&#31867;&#22122;&#22768;&#30340;&#39640;&#26031;&#21322;&#31354;&#38388;&#30340;&#36817;&#20284;&#26368;&#20248;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Near-Optimal Bounds for Learning Gaussian Halfspaces with Random Classification Noise. (arXiv:2307.08438v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08438
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#26031;&#20998;&#24067;&#19979;&#23398;&#20064;&#20855;&#26377;&#38543;&#26426;&#20998;&#31867;&#22122;&#22768;&#30340;&#19968;&#33324;&#21322;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20046;&#26368;&#20248;&#30340;&#31639;&#27861;&#21644;&#32479;&#35745;&#26597;&#35810;&#30340;&#19979;&#30028;&#65292;&#21457;&#29616;&#20102;&#35813;&#38382;&#39064;&#20013;&#30340;&#20449;&#24687;&#35745;&#31639;&#38388;&#38553;&#65292;&#24182;&#32473;&#20986;&#20102;&#20855;&#26377;&#20004;&#39033;&#24179;&#26041;&#20381;&#36182;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39640;&#26031;&#20998;&#24067;&#19979;&#23398;&#20064;&#19968;&#33324;&#65288;&#19981;&#19968;&#23450;&#26159;&#40784;&#27425;&#30340;&#65289;&#20855;&#26377;&#38543;&#26426;&#20998;&#31867;&#22122;&#22768;&#30340;&#21322;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#33268;&#30340;&#31639;&#27861;&#24615;&#21644;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#19979;&#30028;&#32467;&#26524;&#65292;&#25581;&#31034;&#20102;&#36825;&#20010;&#22522;&#26412;&#38382;&#39064;&#20013;&#20196;&#20154;&#24778;&#35766;&#30340;&#20449;&#24687;&#35745;&#31639;&#38388;&#38553;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36825;&#20010;&#23398;&#20064;&#38382;&#39064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#26159;$\widetilde{\Theta}(d/\epsilon)$&#65292;&#20854;&#20013;$d$&#26159;&#32500;&#24230;&#65292;$\epsilon$&#26159;&#36807;&#37327;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#27491;&#38754;&#32467;&#26524;&#26159;&#19968;&#20010;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d/\epsilon + d/(\max\{p, \epsilon\})^2)$&#65292;&#20854;&#20013;$p$&#37327;&#21270;&#20102;&#30446;&#26631;&#21322;&#31354;&#38388;&#30340;&#20559;&#24046;&#12290;&#22312;&#19979;&#30028;&#26041;&#38754;&#65292;&#25105;&#20204;&#34920;&#26126;&#20219;&#20309;&#26377;&#25928;&#30340;SQ&#31639;&#27861;&#65288;&#25110;&#20302;&#27425;&#26816;&#39564;&#65289;&#23545;&#20110;&#35813;&#38382;&#39064;&#33267;&#23569;&#38656;&#35201;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\Omega(d^{1/2}/(\max\{p, \epsilon\})^2)$&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#23545;$1/\epsilon$&#30340;&#20108;&#27425;&#20381;&#36182;&#24615;&#22312;&#26377;&#25928;&#31639;&#27861;&#20013;&#26159;&#22266;&#26377;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning general (i.e., not necessarily homogeneous) halfspaces with Random Classification Noise under the Gaussian distribution. We establish nearly-matching algorithmic and Statistical Query (SQ) lower bound results revealing a surprising information-computation gap for this basic problem. Specifically, the sample complexity of this learning problem is $\widetilde{\Theta}(d/\epsilon)$, where $d$ is the dimension and $\epsilon$ is the excess error. Our positive result is a computationally efficient learning algorithm with sample complexity $\tilde{O}(d/\epsilon + d/(\max\{p, \epsilon\})^2)$, where $p$ quantifies the bias of the target halfspace. On the lower bound side, we show that any efficient SQ algorithm (or low-degree test) for the problem requires sample complexity at least $\Omega(d^{1/2}/(\max\{p, \epsilon\})^2)$. Our lower bound suggests that this quadratic dependence on $1/\epsilon$ is inherent for efficient algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#21462;&#26089;&#26399;&#23551;&#21629;&#20013;&#30340;&#23481;&#37327;-&#30005;&#21387;&#25968;&#25454;&#30340;&#26032;&#29305;&#24449;&#65292;&#25104;&#21151;&#39044;&#27979;&#20102;&#22312;&#19981;&#21516;&#20351;&#29992;&#26465;&#20214;&#19979;&#30340;&#30005;&#27744;&#23551;&#21629;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26089;&#26399;&#29305;&#24449;&#33021;&#22815;&#24456;&#22909;&#22320;&#25429;&#25417;&#30005;&#27744;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;&#32769;&#21270;&#27169;&#24335;&#30340;&#21464;&#21270;&#36895;&#29575;&#65292;&#20026;&#30005;&#27744;&#23551;&#21629;&#39044;&#27979;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2307.08382</link><description>&lt;p&gt;
&#20174;&#26089;&#26399;&#32769;&#21270;&#25968;&#25454;&#20013;&#39044;&#27979;&#19981;&#21516;&#20351;&#29992;&#26465;&#20214;&#19979;&#30340;&#30005;&#27744;&#23551;&#21629;
&lt;/p&gt;
&lt;p&gt;
Predicting Battery Lifetime Under Varying Usage Conditions from Early Aging Data. (arXiv:2307.08382v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#21462;&#26089;&#26399;&#23551;&#21629;&#20013;&#30340;&#23481;&#37327;-&#30005;&#21387;&#25968;&#25454;&#30340;&#26032;&#29305;&#24449;&#65292;&#25104;&#21151;&#39044;&#27979;&#20102;&#22312;&#19981;&#21516;&#20351;&#29992;&#26465;&#20214;&#19979;&#30340;&#30005;&#27744;&#23551;&#21629;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26089;&#26399;&#29305;&#24449;&#33021;&#22815;&#24456;&#22909;&#22320;&#25429;&#25417;&#30005;&#27744;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;&#32769;&#21270;&#27169;&#24335;&#30340;&#21464;&#21270;&#36895;&#29575;&#65292;&#20026;&#30005;&#27744;&#23551;&#21629;&#39044;&#27979;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#30340;&#30005;&#27744;&#23551;&#21629;&#39044;&#27979;&#23545;&#20110;&#39044;&#38450;&#24615;&#32500;&#25252;&#12289;&#20445;&#20462;&#21644;&#25913;&#36827;&#30340;&#30005;&#27744;&#35774;&#35745;&#21644;&#21046;&#36896;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#21046;&#36896;&#21487;&#21464;&#24615;&#21644;&#20351;&#29992;&#20381;&#36182;&#24615;&#38477;&#35299;&#20351;&#24471;&#23551;&#21629;&#39044;&#27979;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#20174;&#26089;&#26399;&#23551;&#21629;&#20013;&#25552;&#21462;&#30340;&#23481;&#37327;-&#30005;&#21387;&#25968;&#25454;&#30340;&#26032;&#29305;&#24449;&#26469;&#39044;&#27979;&#22312;&#20805;&#30005;&#36895;&#29575;&#12289;&#25918;&#30005;&#36895;&#29575;&#21644;&#25918;&#30005;&#28145;&#24230;&#24046;&#24322;&#36739;&#22823;&#30340;&#30005;&#27744;&#30340;&#23551;&#21629;&#12290;&#36825;&#20123;&#29305;&#24449;&#26159;&#20174;&#23450;&#26399;&#23433;&#25490;&#30340;&#21442;&#32771;&#24615;&#33021;&#27979;&#35797;&#20013;&#25552;&#21462;&#30340;&#65288;&#21363;&#20302;&#36895;&#23436;&#20840;&#24490;&#29615;&#65289;&#12290;&#26089;&#26399;&#29983;&#21629;&#21608;&#26399;&#29305;&#24449;&#25429;&#25417;&#21040;&#20102;&#30005;&#27744;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;&#21508;&#32452;&#20214;&#32423;&#21035;&#32769;&#21270;&#27169;&#24335;&#30340;&#21464;&#21270;&#36895;&#29575;&#65292;&#20854;&#20013;&#19968;&#20123;&#19982;&#30005;&#27744;&#23551;&#21629;&#21576;&#24378;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#23545;&#30001;225&#20010;&#38221;-&#38192;-&#38068;/&#30707;&#22696;&#38146;&#31163;&#23376;&#30005;&#27744;&#22312;&#24191;&#27867;&#26465;&#20214;&#19979;&#32769;&#21270;&#20135;&#29983;&#30340;&#26032;&#25968;&#25454;&#38598;&#30340;&#20351;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20998;&#24067;&#20869;&#30340;&#30005;&#27744;&#30340;&#23551;&#21629;&#39044;&#27979;&#33021;&#22815;&#36798;&#21040;15.1%&#30340;&#24179;&#22343;&#32477;&#23545;&#30334;&#20998;&#27604;&#35823;&#24046;&#65292;&#24182;&#19988;&#21482;&#20351;&#29992;&#20102;&#21069;15%&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate battery lifetime prediction is important for preventative maintenance, warranties, and improved cell design and manufacturing. However, manufacturing variability and usage-dependent degradation make life prediction challenging. Here, we investigate new features derived from capacity-voltage data in early life to predict the lifetime of cells cycled under widely varying charge rates, discharge rates, and depths of discharge. Features were extracted from regularly scheduled reference performance tests (i.e., low rate full cycles) during cycling. The early-life features capture a cell's state of health and the rate of change of component-level degradation modes, some of which correlate strongly with cell lifetime. Using a newly generated dataset from 225 nickel-manganese-cobalt/graphite Li-ion cells aged under a wide range of conditions, we demonstrate a lifetime prediction of in-distribution cells with 15.1% mean absolute percentage error using no more than the first 15% of data
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22238;&#22768;&#23454;&#29616;&#24322;&#32852;&#24819;&#23398;&#20064;&#30340;&#32479;&#35745;&#21147;&#23398;&#22270;&#20687;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#38408;&#20540;&#21644;&#22522;&#24577;&#22270;&#20687;&#30340;&#35299;&#26512;&#30456;&#22270;&#65292;&#24674;&#22797;&#20102;Kosko&#30340;&#23384;&#20648;&#35268;&#21017;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.08365</link><description>&lt;p&gt;
&#36890;&#36807;&#22238;&#22768;&#22312;&#21452;&#21521;&#20851;&#32852;&#35760;&#24518;&#20013;&#23398;&#20064;&#30340;&#32479;&#35745;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Statistical Mechanics of Learning via Reverberation in Bidirectional Associative Memories. (arXiv:2307.08365v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08365
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22238;&#22768;&#23454;&#29616;&#24322;&#32852;&#24819;&#23398;&#20064;&#30340;&#32479;&#35745;&#21147;&#23398;&#22270;&#20687;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#38408;&#20540;&#21644;&#22522;&#24577;&#22270;&#20687;&#30340;&#35299;&#26512;&#30456;&#22270;&#65292;&#24674;&#22797;&#20102;Kosko&#30340;&#23384;&#20648;&#35268;&#21017;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21452;&#21521;&#20851;&#32852;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#26292;&#38706;&#20110;&#22823;&#37327;&#38543;&#26426;&#21407;&#22411;&#30340;&#22122;&#22768;&#31034;&#20363;&#26102;&#65292;&#23398;&#20064;&#36825;&#20123;&#21407;&#22411;&#65288;&#26377;&#25110;&#26080;&#25945;&#24072;&#30340;&#24773;&#20917;&#19979;&#65289;&#26102;&#65292;&#24403;&#25552;&#20379;&#30340;&#20449;&#24687;&#36275;&#22815;&#26102;&#65306;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#23398;&#20064;&#26159;&#24322;&#32852;&#24819;&#30340; - &#21253;&#25324;&#27169;&#24335;&#23545; - &#24182;&#36890;&#36807;&#23558;&#20174;&#31034;&#20363;&#20013;&#25551;&#32472;&#30340;&#20449;&#24687;&#36890;&#36807;&#32593;&#32476;&#30340;&#23618;&#27425;&#36827;&#34892;&#22238;&#22768;&#23454;&#29616;&#12290;&#36890;&#36807;&#35843;&#25972;Guerra&#30340;&#25554;&#20540;&#25216;&#26415;&#65292;&#25105;&#20204;&#22312;&#22797;&#21046;&#23545;&#31216;&#30340;&#25551;&#36848;&#32423;&#21035;&#19978;&#25552;&#20379;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#32479;&#35745;&#21147;&#23398;&#22270;&#20687;&#65292;&#33719;&#24471;&#20102;&#35299;&#26512;&#30456;&#22270;&#12289;&#23398;&#20064;&#30340;&#38408;&#20540;&#12289;&#19982;Monte Carlo&#27169;&#25311;&#21644;&#20449;&#22122;&#27604;&#32467;&#26524;&#23436;&#20840;&#19968;&#33268;&#30340;&#22522;&#24577;&#22270;&#20687;&#12290;&#22312;&#22823;&#25968;&#25454;&#38598;&#38480;&#21046;&#19979;&#65292;Kosko&#30340;&#23384;&#20648;&#35268;&#21017;&#20197;&#21450;Kurchan&#12289;Peliti&#21644;Saber&#22312;80&#24180;&#20195;&#25552;&#20379;&#30340;&#32479;&#35745;&#21147;&#23398;&#22270;&#20687;&#24471;&#21040;&#20102;&#23436;&#20840;&#24674;&#22797;&#12290;&#35745;&#31639;&#20248;&#21183;&#22312;...
&lt;/p&gt;
&lt;p&gt;
We study bi-directional associative neural networks that, exposed to noisy examples of an extensive number of random archetypes, learn the latter (with or without the presence of a teacher) when the supplied information is enough: in this setting, learning is heteroassociative -- involving couples of patterns -and it is achieved by reverberating the information depicted from the examples through the layers of the network. By adapting Guerra's interpolation technique, we provide a full statistical mechanical picture of supervised and unsupervised learning processes (at the replica symmetric level of description) obtaining analytically phase diagrams, thresholds for learning, a picture of the ground-state in plain agreement with Monte Carlo simulations and signal-to-noise outcomes. In the large dataset limit, the Kosko storage prescription as well as its statistical mechanical picture provided by Kurchan, Peliti, and Saber in the eighties is fully recovered. Computational advantages in
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#32423;&#21035;&#33258;&#36866;&#24212;&#24615;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;&#65292;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#22810;&#31181;&#36951;&#25022;&#30028;&#65292;&#24182;&#22312;&#20998;&#26512;&#20013;&#30452;&#25509;&#24212;&#29992;&#20110;&#23567;&#25439;&#22833;&#30028;&#12290;&#21516;&#26102;&#65292;&#23427;&#19982;&#23545;&#25239;&#24615;/&#38543;&#26426;&#20984;&#20248;&#21270;&#21644;&#21338;&#24328;&#35770;&#26377;&#30528;&#28145;&#21051;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.08360</link><description>&lt;p&gt;
&#20855;&#26377;&#36880;&#28176;&#21464;&#21270;&#30340;&#36890;&#29992;&#22312;&#32447;&#23398;&#20064;&#65306;&#19968;&#31181;&#22810;&#23618;&#22312;&#32447;&#38598;&#25104;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Universal Online Learning with Gradual Variations: A Multi-layer Online Ensemble Approach. (arXiv:2307.08360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08360
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#32423;&#21035;&#33258;&#36866;&#24212;&#24615;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;&#65292;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#22810;&#31181;&#36951;&#25022;&#30028;&#65292;&#24182;&#22312;&#20998;&#26512;&#20013;&#30452;&#25509;&#24212;&#29992;&#20110;&#23567;&#25439;&#22833;&#30028;&#12290;&#21516;&#26102;&#65292;&#23427;&#19982;&#23545;&#25239;&#24615;/&#38543;&#26426;&#20984;&#20248;&#21270;&#21644;&#21338;&#24328;&#35770;&#26377;&#30528;&#28145;&#21051;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#32423;&#21035;&#33258;&#36866;&#24212;&#24615;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;&#12290;&#22312;&#26356;&#39640;&#32423;&#21035;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#20855;&#20307;&#31867;&#22411;&#21644;&#26354;&#29575;&#19981;&#30693;&#24773;&#65292;&#32780;&#22312;&#26356;&#20302;&#32423;&#21035;&#19978;&#65292;&#23427;&#21487;&#20197;&#21033;&#29992;&#29615;&#22659;&#30340;&#33391;&#22909;&#24615;&#36136;&#24182;&#33719;&#24471;&#38382;&#39064;&#30456;&#20851;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#24378;&#20984;&#12289;&#25351;&#25968;&#20985;&#21644;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#20998;&#21035;&#33719;&#24471;&#20102;$O(\ln V_T)$&#12289;$O(d \ln V_T)$&#21644;$\hat{O}(\sqrt{V_T})$&#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;$d$&#26159;&#32500;&#24230;&#65292;$V_T$&#34920;&#31034;&#38382;&#39064;&#30456;&#20851;&#30340;&#26799;&#24230;&#21464;&#21270;&#65292;$\hat{O}(\cdot)$&#34920;&#31034;&#22312;$V_T$&#19978;&#30465;&#30053;&#23545;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20855;&#26377;&#24191;&#27867;&#30340;&#24433;&#21709;&#21644;&#24212;&#29992;&#12290;&#23427;&#19981;&#20165;&#20445;&#35777;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#36824;&#30452;&#25509;&#23548;&#20986;&#20102;&#20998;&#26512;&#20013;&#30340;&#23567;&#25439;&#22833;&#30028;&#12290;&#27492;&#22806;&#65292;&#23427;&#19982;&#23545;&#25239;&#24615;/&#38543;&#26426;&#20984;&#20248;&#21270;&#21644;&#21338;&#24328;&#35770;&#26377;&#30528;&#28145;&#21051;&#30340;&#32852;&#31995;&#65292;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#20854;&#23454;&#38469;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;...
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose an online convex optimization method with two different levels of adaptivity. On a higher level, our method is agnostic to the specific type and curvature of the loss functions, while at a lower level, it can exploit the niceness of the environments and attain problem-dependent guarantees. To be specific, we obtain $\mathcal{O}(\ln V_T)$, $\mathcal{O}(d \ln V_T)$ and $\hat{\mathcal{O}}(\sqrt{V_T})$ regret bounds for strongly convex, exp-concave and convex loss functions, respectively, where $d$ is the dimension, $V_T$ denotes problem-dependent gradient variations and $\hat{\mathcal{O}}(\cdot)$-notation omits logarithmic factors on $V_T$. Our result finds broad implications and applications. It not only safeguards the worst-case guarantees, but also implies the small-loss bounds in analysis directly. Besides, it draws deep connections with adversarial/stochastic convex optimization and game theory, further validating its practical potential. Our method is based
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#38024;&#23545;Softmax&#20248;&#21270;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#35745;&#31639;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#26799;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.08352</link><description>&lt;p&gt;
&#38024;&#23545;Softmax&#27880;&#24847;&#21147;&#20248;&#21270;&#30340;&#38646;&#38454;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Zero-th Order Algorithm for Softmax Attention Optimization. (arXiv:2307.08352v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08352
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#38024;&#23545;Softmax&#20248;&#21270;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#35745;&#31639;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#20154;&#31867;&#31038;&#20250;&#20013;&#24102;&#26469;&#20102;&#37325;&#22823;&#30340;&#21464;&#38761;&#12290;&#22312;LLMs&#20013;&#65292;softmax&#21333;&#20803;&#30340;&#35745;&#31639;&#38750;&#24120;&#37325;&#35201;&#12290;&#23427;&#24110;&#21161;&#27169;&#22411;&#22312;&#19968;&#31995;&#21015;&#36755;&#20837;&#21333;&#35789;&#20013;&#29983;&#25104;&#28508;&#22312;&#30340;&#19979;&#19968;&#20010;&#21333;&#35789;&#25110;&#30701;&#35821;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#36825;&#20010;&#20998;&#24067;&#65292;&#27169;&#22411;&#26681;&#25454;&#20998;&#37197;&#30340;&#27010;&#29575;&#36873;&#25321;&#26368;&#26377;&#21487;&#33021;&#30340;&#19979;&#19968;&#20010;&#21333;&#35789;&#25110;&#30701;&#35821;&#12290;softmax&#21333;&#20803;&#22312;LLM&#35757;&#32451;&#20013;&#36215;&#21040;&#20851;&#38190;&#20316;&#29992;&#65292;&#22240;&#20026;&#23427;&#36890;&#36807;&#35843;&#25972;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#21644;&#20559;&#24046;&#26469;&#23454;&#29616;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#12290;&#38543;&#30528;LLMs&#30340;&#35268;&#27169;&#30340;&#21457;&#23637;&#65292;&#35745;&#31639;&#26799;&#24230;&#21464;&#24471;&#26114;&#36149;&#12290;&#28982;&#32780;&#65292;&#38646;&#38454;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#20165;&#36827;&#34892;&#21069;&#21521;&#20256;&#36882;&#26469;&#36817;&#20284;&#35745;&#31639;&#26799;&#24230;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;Softmax&#20248;&#21270;&#30340;&#38646;&#38454;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#24378;&#35843;&#20854;&#22312;&#39640;&#25928;&#35745;&#31639;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#26799;&#24230;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have brought about significant transformations in human society. Among the crucial computations in LLMs, the softmax unit holds great importance. Its helps the model generating a probability distribution on potential subsequent words or phrases, considering a series of input words. By utilizing this distribution, the model selects the most probable next word or phrase, based on the assigned probabilities. The softmax unit assumes a vital function in LLM training as it facilitates learning from data through the adjustment of neural network weights and biases.  With the development of the size of LLMs, computing the gradient becomes expensive. However, Zero-th Order method can approximately compute the gradient with only forward passes. In this paper, we present a Zero-th Order algorithm specifically tailored for Softmax optimization. We demonstrate the convergence of our algorithm, highlighting its effectiveness in efficiently computing gradients for large-s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#39640;&#26031;&#20195;&#29702;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#25299;&#23637;&#20102;Raissi&#31561;&#20154;&#65288;2017&#65289;&#30340;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#20381;&#36182;&#26041;&#31243;&#20449;&#24687;&#30340;&#39640;&#26031;&#20808;&#39564;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#22312;&#36125;&#21494;&#26031;&#21453;&#28436;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.08343</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#19982;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes for Bayesian inverse problems associated with linear partial differential equations. (arXiv:2307.08343v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#39640;&#26031;&#20195;&#29702;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#25299;&#23637;&#20102;Raissi&#31561;&#20154;&#65288;2017&#65289;&#30340;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#20381;&#36182;&#26041;&#31243;&#20449;&#24687;&#30340;&#39640;&#26031;&#20808;&#39564;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#22312;&#36125;&#21494;&#26031;&#21453;&#28436;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19982;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#20351;&#29992;&#39640;&#26031;&#20195;&#29702;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#30340;&#26159;&#22312;&#21482;&#26377;&#23569;&#37327;&#35757;&#32451;&#25968;&#25454;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#39640;&#26031;&#20808;&#39564;&#30340;&#31867;&#22411;&#23545;&#20110;&#29992;&#20110;&#36125;&#21494;&#26031;&#21453;&#28436;&#30340;&#20195;&#29702;&#27169;&#22411;&#30340;&#24615;&#33021;&#30340;&#20851;&#38190;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;Raissi&#31561;&#20154;&#65288;2017&#65289;&#30340;&#26694;&#26550;&#65292;&#20197;&#26500;&#24314;PDE-informed&#39640;&#26031;&#20808;&#39564;&#65292;&#24182;&#29992;&#23427;&#20204;&#26500;&#24314;&#19981;&#21516;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#12290;&#22810;&#20010;&#19981;&#21516;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;PDE-informed&#39640;&#26031;&#20808;&#39564;&#22312;&#20256;&#32479;&#20808;&#39564;&#19978;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work is concerned with the use of Gaussian surrogate models for Bayesian inverse problems associated with linear partial differential equations. A particular focus is on the regime where only a small amount of training data is available. In this regime the type of Gaussian prior used is of critical importance with respect to how well the surrogate model will perform in terms of Bayesian inversion. We extend the framework of Raissi et. al. (2017) to construct PDE-informed Gaussian priors that we then use to construct different approximate posteriors. A number of different numerical experiments illustrate the superiority of the PDE-informed Gaussian priors over more traditional priors.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20174;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#29983;&#25104;&#24314;&#27169;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28508;&#22312;&#19982;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#8220;&#36317;&#31163;&#8221;&#65292;&#24182;&#36890;&#36807;&#35813;&#36317;&#31163;&#30340;&#26368;&#23567;&#21270;&#26469;&#20248;&#21270;&#29983;&#25104;&#22120;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.08283</link><description>&lt;p&gt;
&#22797;&#26434;&#24615;&#33267;&#20851;&#37325;&#35201;&#65306;&#37325;&#26032;&#24605;&#32771;&#29983;&#25104;&#24314;&#27169;&#30340;&#28508;&#22312;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Complexity Matters: Rethinking the Latent Space for Generative Modeling. (arXiv:2307.08283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#29983;&#25104;&#24314;&#27169;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28508;&#22312;&#19982;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#8220;&#36317;&#31163;&#8221;&#65292;&#24182;&#36890;&#36807;&#35813;&#36317;&#31163;&#30340;&#26368;&#23567;&#21270;&#26469;&#20248;&#21270;&#29983;&#25104;&#22120;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#65292;&#35768;&#22810;&#25104;&#21151;&#30340;&#26041;&#27861;&#21033;&#29992;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#65292;&#20363;&#22914;&#65292;&#31283;&#23450;&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#32534;&#30721;&#22120;&#24341;&#23548;&#30340;&#28508;&#22312;&#31354;&#38388;&#29983;&#25104;&#22270;&#20687;&#65292;&#24182;&#36890;&#36807;&#37197;&#23545;&#30340;&#35299;&#30721;&#22120;&#36827;&#34892;&#29983;&#25104;&#12290;&#23613;&#31649;&#28508;&#22312;&#31354;&#38388;&#30340;&#36873;&#25321;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#30830;&#23450;&#26368;&#20248;&#36873;&#25321;&#21644;&#35782;&#21035;&#36807;&#31243;&#20173;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20174;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#28508;&#22312;&#31354;&#38388;&#65292;&#26469;&#25581;&#31034;&#36825;&#20010;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#35805;&#39064;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#20174;&#32463;&#20856;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#24320;&#22987;&#12290;&#21463;&#21040;GAN&#35757;&#32451;&#30446;&#26631;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28508;&#22312;&#19982;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#8220;&#36317;&#31163;&#8221;&#65292;&#20854;&#26368;&#23567;&#21270;&#19982;&#29983;&#25104;&#22120;&#30340;&#22797;&#26434;&#24615;&#26368;&#23567;&#21270;&#30456;&#19968;&#33268;&#12290;&#36825;&#20010;&#36317;&#31163;&#30340;&#26368;&#23567;&#21270;&#32773;&#34987;&#25551;&#36848;&#20026;&#33021;&#22815;&#26368;&#26377;&#25928;&#22320;&#21033;&#29992;&#29983;&#25104;&#22120;&#23481;&#37327;&#30340;&#26368;&#20339;&#25968;&#25454;&#30456;&#20851;&#30340;&#28508;&#22312;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#36890;&#36807;&#32534;&#30721;&#22120;&#32593;&#32476;&#23545;&#36825;&#26679;&#30340;&#28508;&#22312;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26041;&#27861;...
&lt;/p&gt;
&lt;p&gt;
In generative modeling, numerous successful approaches leverage a low-dimensional latent space, e.g., Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder. Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear. In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity. Our investigation starts with the classic generative adversarial networks (GANs). Inspired by the GAN training objective, we propose a novel "distance" between the latent and data distributions, whose minimization coincides with that of the generator complexity. The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity. Then, we consider parameterizing such a latent distribution by an encoder network and propo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#20013;&#32416;&#32544;&#27835;&#30103;&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#20272;&#35745;&#25509;&#35302;&#23545;MRSA&#24863;&#26579;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20197;&#24448;&#30340;&#35266;&#23519;&#24615;&#30740;&#31350;&#26041;&#27861;&#24573;&#30053;&#20102;&#32416;&#32544;&#27835;&#30103;&#21487;&#33021;&#23548;&#33268;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#38169;&#35823;&#12290;</title><link>http://arxiv.org/abs/2307.08237</link><description>&lt;p&gt;
&#28145;&#20837;&#25506;&#31350;&#22270;&#20013;&#32416;&#32544;&#27835;&#30103;&#30340;&#22240;&#26524;&#25928;&#24212;&#65306;&#30740;&#31350;&#25509;&#35302;&#23545;MRSA&#24863;&#26579;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
A Look into Causal Effects under Entangled Treatment in Graphs: Investigating the Impact of Contact on MRSA Infection. (arXiv:2307.08237v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#20013;&#32416;&#32544;&#27835;&#30103;&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#20272;&#35745;&#25509;&#35302;&#23545;MRSA&#24863;&#26579;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20197;&#24448;&#30340;&#35266;&#23519;&#24615;&#30740;&#31350;&#26041;&#27861;&#24573;&#30053;&#20102;&#32416;&#32544;&#27835;&#30103;&#21487;&#33021;&#23548;&#33268;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30002;&#27687;&#35199;&#26519;&#32784;&#33647;&#37329;&#40644;&#33394;&#33889;&#33796;&#29699;&#33740;&#65288;MRSA&#65289;&#26159;&#19968;&#31181;&#23545;&#26576;&#20123;&#25239;&#29983;&#32032;&#20855;&#26377;&#32784;&#33647;&#24615;&#30340;&#32454;&#33740;&#65292;&#20351;&#24471;&#39044;&#38450;MRSA&#24863;&#26579;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#25968;&#21313;&#24180;&#30340;&#21162;&#21147;&#20013;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#30740;&#31350;&#20197;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#20272;&#35745;&#20146;&#23494;&#25509;&#35302;&#65288;&#27835;&#30103;&#65289;&#23545;MRSA&#24863;&#26579;&#65288;&#32467;&#26524;&#65289;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#27835;&#30103;&#20998;&#37197;&#26426;&#21046;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#22240;&#20026;&#23427;&#20915;&#23450;&#20102;&#32570;&#22833;&#21453;&#20107;&#23454;&#30340;&#27169;&#24335;&#65292;&#36825;&#26159;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#22522;&#26412;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#29992;&#20110;&#22240;&#26524;&#25928;&#24212;&#23398;&#20064;&#30340;&#35266;&#23519;&#24615;&#30740;&#31350;&#20551;&#35774;&#27599;&#20010;&#21333;&#20301;&#30340;&#27835;&#30103;&#37117;&#26159;&#20010;&#20307;&#20998;&#37197;&#30340;&#12290;&#20294;&#26159;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#27835;&#30103;&#26159;&#23545;&#22270;&#20013;&#36830;&#25509;&#30340;&#21333;&#20301;&#36827;&#34892;&#25104;&#23545;&#20998;&#37197;&#30340;&#65292;&#21363;&#19981;&#21516;&#21333;&#20301;&#30340;&#27835;&#30103;&#26159;&#32416;&#32544;&#30340;&#12290;&#24573;&#35270;&#32416;&#32544;&#30340;&#27835;&#30103;&#21487;&#33021;&#22952;&#30861;&#22240;&#26524;&#25928;&#24212;&#30340;&#20272;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22270;&#20013;&#32416;&#32544;&#27835;&#30103;&#30340;&#24773;&#20917;&#19979;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Methicillin-resistant Staphylococcus aureus (MRSA) is a type of bacteria resistant to certain antibiotics, making it difficult to prevent MRSA infections. Among decades of efforts to conquer infectious diseases caused by MRSA, many studies have been proposed to estimate the causal effects of close contact (treatment) on MRSA infection (outcome) from observational data. In this problem, the treatment assignment mechanism plays a key role as it determines the patterns of missing counterfactuals -- the fundamental challenge of causal effect estimation. Most existing observational studies for causal effect learning assume that the treatment is assigned individually for each unit. However, on many occasions, the treatments are pairwisely assigned for units that are connected in graphs, i.e., the treatments of different units are entangled. Neglecting the entangled treatments can impede the causal effect estimation. In this paper, we study the problem of causal effect estimation with treatme
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#23398;&#20064;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#12290;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#20808;&#39564;&#20154;&#31867;&#30693;&#35782;&#26469;&#23454;&#29616;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#65292;&#20294;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#33719;&#21462;&#36825;&#26679;&#30340;&#30693;&#35782;&#24448;&#24448;&#38750;&#24120;&#22256;&#38590;&#12290;&#36825;&#39033;&#30740;&#31350;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2307.08232</link><description>&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#23398;&#20064;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning for Counterfactual Fairness from Observational Data. (arXiv:2307.08232v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08232
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#23398;&#20064;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#12290;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#20808;&#39564;&#20154;&#31867;&#30693;&#35782;&#26469;&#23454;&#29616;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#65292;&#20294;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#33719;&#21462;&#36825;&#26679;&#30340;&#30693;&#35782;&#24448;&#24448;&#38750;&#24120;&#22256;&#38590;&#12290;&#36825;&#39033;&#30740;&#31350;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#24179;&#24615;&#24863;&#30693;&#26426;&#22120;&#23398;&#20064;&#22312;&#35768;&#22810;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22914;&#22312;&#32447;&#24191;&#21578;&#12289;&#20010;&#24615;&#21270;&#25512;&#33616;&#21644;&#31038;&#20132;&#23186;&#20307;&#20998;&#26512;&#12290;&#20844;&#24179;&#24615;&#24863;&#30693;&#26426;&#22120;&#23398;&#20064;&#26088;&#22312;&#28040;&#38500;&#23398;&#20064;&#27169;&#22411;&#23545;&#29305;&#23450;&#23376;&#32676;&#20307;&#30340;&#20559;&#35265;&#65292;&#36825;&#20123;&#23376;&#32676;&#20307;&#30001;&#29305;&#23450;&#30340;&#20445;&#25252;&#65288;&#25935;&#24863;&#65289;&#23646;&#24615;&#25551;&#36848;&#65292;&#20363;&#22914;&#31181;&#26063;&#12289;&#24615;&#21035;&#21644;&#24180;&#40836;&#12290;&#22312;&#35768;&#22810;&#29616;&#26377;&#30340;&#20844;&#24179;&#24615;&#27010;&#24565;&#20013;&#65292;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#26159;&#20174;&#22240;&#26524;&#36879;&#35270;&#23450;&#20041;&#30340;&#19968;&#31181;&#27969;&#34892;&#27010;&#24565;&#12290;&#23427;&#36890;&#36807;&#27604;&#36739;&#21407;&#22987;&#19990;&#30028;&#20013;&#27599;&#20010;&#20010;&#20307;&#30340;&#39044;&#27979;&#21644;&#22312;&#20462;&#25913;&#25935;&#24863;&#23646;&#24615;&#20540;&#30340;&#21453;&#20107;&#23454;&#19990;&#30028;&#20013;&#30340;&#39044;&#27979;&#26469;&#34913;&#37327;&#39044;&#27979;&#22120;&#30340;&#20844;&#24179;&#24615;&#12290;&#29616;&#26377;&#26041;&#27861;&#23454;&#29616;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#30340;&#20808;&#20915;&#26465;&#20214;&#26159;&#25484;&#25569;&#20851;&#20110;&#25968;&#25454;&#30340;&#22240;&#26524;&#27169;&#22411;&#30340;&#20808;&#39564;&#20154;&#31867;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#65292;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#65292;&#24182;&#19988;&#33719;&#21462;&#36825;&#26679;&#30340;&#20154;&#31867;&#30693;&#35782;&#21487;&#33021;&#38750;&#24120;&#22256;&#38590;&#12290;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#26159;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fairness-aware machine learning has attracted a surge of attention in many domains, such as online advertising, personalized recommendation, and social media analysis in web applications. Fairness-aware machine learning aims to eliminate biases of learning models against certain subgroups described by certain protected (sensitive) attributes such as race, gender, and age. Among many existing fairness notions, counterfactual fairness is a popular notion defined from a causal perspective. It measures the fairness of a predictor by comparing the prediction of each individual in the original world and that in the counterfactual worlds in which the value of the sensitive attribute is modified. A prerequisite for existing methods to achieve counterfactual fairness is the prior human knowledge of the causal model for the data. However, in real-world scenarios, the underlying causal model is often unknown, and acquiring such human knowledge could be very difficult. In these scenarios, it is ri
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20248;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#23558;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#35270;&#20026;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#26694;&#26550;&#29983;&#25104;&#20102;&#21516;&#26102;&#20855;&#26377;&#39640;&#24615;&#33021;&#21644;&#26131;&#35299;&#37322;&#24615;&#26435;&#34913;&#30340;&#22810;&#26679;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2307.08175</link><description>&lt;p&gt;
&#22312;&#34920;&#26684;&#21270;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#22810;&#30446;&#26631;&#20248;&#21270;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Multi-Objective Optimization of Performance and Interpretability of Tabular Supervised Machine Learning Models. (arXiv:2307.08175v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08175
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20248;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#23558;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#35270;&#20026;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#26694;&#26550;&#29983;&#25104;&#20102;&#21516;&#26102;&#20855;&#26377;&#39640;&#24615;&#33021;&#21644;&#26131;&#35299;&#37322;&#24615;&#26435;&#34913;&#30340;&#22810;&#26679;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#21516;&#26102;&#20248;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#21487;&#35299;&#37322;&#24615;&#36890;&#36807;&#19977;&#20010;&#25351;&#26631;&#36827;&#34892;&#37327;&#21270;&#65306;&#29305;&#24449;&#31232;&#30095;&#24615;&#12289;&#29305;&#24449;&#20132;&#20114;&#31232;&#30095;&#24615;&#21644;&#38750;&#21333;&#35843;&#29305;&#24449;&#24433;&#21709;&#30340;&#31232;&#30095;&#24615;&#12290;&#36890;&#36807;&#23558;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#35270;&#20026;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#22312;&#21333;&#27425;&#20248;&#21270;&#36816;&#34892;&#20013;&#29983;&#25104;&#39640;&#24615;&#33021;&#21644;&#26131;&#35299;&#37322;&#24615;&#26435;&#34913;&#30340;&#22810;&#26679;&#27169;&#22411;&#12290;&#36890;&#36807;&#23558;&#29305;&#24449;&#36873;&#25321;&#12289;&#20132;&#20114;&#21644;&#21333;&#35843;&#24615;&#32422;&#26463;&#38598;&#25104;&#21040;&#36229;&#21442;&#25968;&#25628;&#32034;&#31354;&#38388;&#20013;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20248;&#21270;&#38382;&#39064;&#26377;&#25928;&#22320;&#36716;&#21270;&#20026;&#25214;&#21040;&#34987;&#20801;&#35768;&#22312;&#27169;&#22411;&#20013;&#20132;&#20114;&#30340;&#36873;&#23450;&#29305;&#24449;&#32452;&#30340; Pareto &#26368;&#20248;&#38598;&#65292;&#24182;&#25214;&#21040;&#23427;&#20204;&#30340;&#26368;&#20339;&#21333;&#35843;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a model-agnostic framework for jointly optimizing the predictive performance and interpretability of supervised machine learning models for tabular data. Interpretability is quantified via three measures: feature sparsity, interaction sparsity of features, and sparsity of non-monotone feature effects. By treating hyperparameter optimization of a machine learning algorithm as a multi-objective optimization problem, our framework allows for generating diverse models that trade off high performance and ease of interpretability in a single optimization run. Efficient optimization is achieved via augmentation of the search space of the learning algorithm by incorporating feature selection, interaction and monotonicity constraints into the hyperparameter search space. We demonstrate that the optimization problem effectively translates to finding the Pareto optimal set of groups of selected features that are allowed to interact in a model, along with finding their optimal monotonic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#20013;&#65292;&#21487;&#20197;&#28789;&#27963;&#12289;&#39640;&#25928;&#22320;&#27169;&#25311;&#20855;&#26377;&#38750;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#26497;&#31471;&#20107;&#20214;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26102;&#38388;&#25928;&#29575;&#21644;&#24615;&#33021;&#19978;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#35768;&#22810;&#20855;&#26377;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2307.08079</link><description>&lt;p&gt;
&#36890;&#36807;&#21464;&#20998;&#33258;&#21160; &#32534;&#30721;&#22120;&#23454;&#29616;&#28789;&#27963;&#39640;&#25928;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#20013;&#65292;&#21487;&#20197;&#28789;&#27963;&#12289;&#39640;&#25928;&#22320;&#27169;&#25311;&#20855;&#26377;&#38750;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#26497;&#31471;&#20107;&#20214;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26102;&#38388;&#25928;&#29575;&#21644;&#24615;&#33021;&#19978;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#35768;&#22810;&#20855;&#26377;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#36807;&#31243;&#20855;&#26377;&#22797;&#26434;&#30340;&#23614;&#20381;&#36182;&#32467;&#26500;&#65292;&#36825;&#31181;&#32467;&#26500;&#26080;&#27861;&#20351;&#29992;&#20256;&#32479;&#30340;&#39640;&#26031;&#36807;&#31243;&#26469;&#25551;&#36848;&#12290;&#26356;&#28789;&#27963;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292; &#22914;&#39640;&#26031;&#23610;&#24230;&#28151;&#21512;&#27169;&#22411;&#21644;&#21333;&#31449;&#28857;&#35843;&#33410;&#27169;&#22411;&#65292;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#26497;&#31471;&#20381;&#36182;&#24615;&#36136;&#65292;&#20294;&#24448;&#24448;&#38590;&#20197;&#25311;&#21512;&#21644;&#27169;&#25311;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#20855;&#26377;&#28789;&#27963;&#21644;&#38750;&#24179;&#31283;&#30340;&#30456;&#20851;&#24615;&#23646;&#24615;&#65292;&#24182;&#23558;&#20854;&#38598;&#25104;&#21040;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120; (extVAE) &#30340;&#32534;&#30721;-&#35299;&#30721;&#32467;&#26500;&#20013;&#12290; extVAE &#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#26102;&#31354;&#27169;&#25311;&#22120;&#65292;&#23545;&#28508;&#22312;&#30340;&#26426;&#21046;&#27169;&#22411;&#36755;&#20986;&#29366;&#24577;&#30340;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#20135;&#29983;&#20855;&#26377;&#19982;&#36755;&#20837;&#30456;&#21516;&#23646;&#24615;&#30340;&#36755;&#20986;&#65292;&#23588;&#20854;&#26159;&#22312;&#23614;&#37096;&#21306;&#22495;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;extVAE&#27604;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26356;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377; &#24179;&#31283;&#30456;&#20851;&#24615;&#32467;&#26500;&#30340;&#35768;&#22810;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#20013;&#34920;&#29616; &#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world processes have complex tail dependence structures that cannot be characterized using classical Gaussian processes. More flexible spatial extremes models such as Gaussian scale mixtures and single-station conditioning models exhibit appealing extremal dependence properties but are often exceedingly prohibitive to fit and simulate from. In this paper, we develop a new spatial extremes model that has flexible and non-stationary dependence properties, and we integrate it in the encoding-decoding structure of a variational autoencoder (extVAE). The extVAE can be used as a spatio-temporal emulator that characterizes the distribution of potential mechanistic model output states and produces outputs that have the same properties as the inputs, especially in the tail. Through extensive simulation studies, we show that our extVAE is vastly more time-efficient than traditional Bayesian inference while also outperforming many spatial extremes models with a stationary dependence str
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;AFT&#25490;&#21517;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#28789;&#27963;&#22320;&#36827;&#34892;&#26102;&#38388;&#20107;&#20214;&#24314;&#27169;&#65292;&#20174;&#32780;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#24182;&#20943;&#36731;&#20005;&#26684;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2307.08044</link><description>&lt;p&gt;
&#26580;&#24615;&#26102;&#38388;&#20107;&#20214;&#24314;&#27169;&#65306;&#36890;&#36807;&#25490;&#21517;&#22238;&#24402;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression. (arXiv:2307.08044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;AFT&#25490;&#21517;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#28789;&#27963;&#22320;&#36827;&#34892;&#26102;&#38388;&#20107;&#20214;&#24314;&#27169;&#65292;&#20174;&#32780;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#24182;&#20943;&#36731;&#20005;&#26684;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#20107;&#20214;&#20998;&#26512;&#65292;&#20063;&#34987;&#31216;&#20026;&#29983;&#23384;&#20998;&#26512;&#65292;&#26088;&#22312;&#26681;&#25454;&#19968;&#32452;&#29305;&#24449;&#39044;&#27979;&#20107;&#20214;&#21457;&#29983;&#30340;&#26102;&#38388;&#12290;&#36825;&#20010;&#39046;&#22495;&#38754;&#20020;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#22788;&#29702;&#34987;&#25130;&#23614;&#30340;&#25968;&#25454;&#65292;&#36825;&#21487;&#33021;&#20351;&#23398;&#20064;&#31639;&#27861;&#26356;&#21152;&#22797;&#26434;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#21644;&#21152;&#36895;&#22833;&#25928;&#26102;&#38388;&#65288;AFT&#65289;&#27169;&#22411;&#22312;&#36825;&#20010;&#39046;&#22495;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#38656;&#35201;&#19968;&#20123;&#20551;&#35774;&#65292;&#22914;&#27604;&#20363;&#39118;&#38505;&#21644;&#32447;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;AFT&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#30340;&#21442;&#25968;&#20998;&#24067;&#20551;&#35774;&#12290;&#20026;&#20102;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#21644;&#20943;&#36731;&#20005;&#26684;&#30340;&#20551;&#35774;&#65292;&#36817;&#24180;&#26469;&#20986;&#29616;&#20102;&#35768;&#22810;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#21361;&#38505;&#27169;&#22411;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#31070;&#32463;&#32593;&#32476;&#25991;&#29486;&#20013;&#23545;&#20110;AFT&#30340;&#34920;&#31034;&#23398;&#20064;&#23578;&#26410;&#24191;&#27867;&#25506;&#32034;&#65292;&#23613;&#31649;&#30456;&#23545;&#20110;&#20197;&#21361;&#38505;&#20026;&#37325;&#28857;&#30340;&#26041;&#27861;&#32780;&#35328;&#65292;&#23427;&#26356;&#21152;&#31616;&#21333;&#21644;&#21487;&#35299;&#37322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#28145;&#24230;AFT&#25490;&#21517;&#22238;&#24402;&#27169;&#22411;&#26469;&#36827;&#34892;&#26102;&#38388;&#20107;&#20214;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions. To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods. In this work, we introduce the Deep AFT Rank-regression model for Time-to-event predic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#20197;&#21450;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#30340;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#39044;&#27979;&#21644;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2307.08038</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind Fields. (arXiv:2307.08038v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08038
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#20197;&#21450;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#30340;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#39044;&#27979;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#39118;&#22330;&#25968;&#25454;&#23545;&#20110;&#27668;&#20505;&#12289;&#28023;&#27915;&#21644;&#27668;&#35937;&#30740;&#31350;&#20013;&#30340;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#20110;&#39118;&#25968;&#25454;&#24448;&#24448;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#39640;&#31354;&#38388;&#21464;&#24322;&#24615;&#21644;&#24322;&#36136;&#24615;&#65292;&#22240;&#27492;&#23545;&#20855;&#26377;&#20004;&#20010;&#32500;&#24230;&#36895;&#24230;&#30340;&#21452;&#21464;&#37327;&#39118;&#22330;&#36827;&#34892;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#25110;&#19979;&#32553;&#25918;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#31354;&#38388;&#32479;&#35745;&#23398;&#20013;&#65292;&#24120;&#29992;cokriging&#26469;&#39044;&#27979;&#21452;&#21464;&#37327;&#31354;&#38388;&#22330;&#12290;&#28982;&#32780;&#65292;cokriging&#39044;&#27979;&#22120;&#38500;&#20102;&#23545;&#39640;&#26031;&#36807;&#31243;&#26377;&#25928;&#22806;&#65292;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;cokriging&#35745;&#31639;&#37327;&#24040;&#22823;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#26159;&#19968;&#20010;&#30001;&#31354;&#38388;&#24452;&#21521;&#22522;&#20989;&#25968;&#26500;&#24314;&#30340;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#65292;&#29992;&#20110;&#21452;&#21464;&#37327;&#31354;&#38388;&#25968;&#25454;&#39044;&#27979;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#30340;cokriging&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
High spatial resolution wind data are essential for a wide range of applications in climate, oceanographic and meteorological studies. Large-scale spatial interpolation or downscaling of bivariate wind fields having velocity in two dimensions is a challenging task because wind data tend to be non-Gaussian with high spatial variability and heterogeneity. In spatial statistics, cokriging is commonly used for predicting bivariate spatial fields. However, the cokriging predictor is not optimal except for Gaussian processes. Additionally, cokriging is computationally prohibitive for large datasets. In this paper, we propose a method, called bivariate DeepKriging, which is a spatially dependent deep neural network (DNN) with an embedding layer constructed by spatial radial basis functions for bivariate spatial data prediction. We then develop a distribution-free uncertainty quantification method based on bootstrap and ensemble DNN. Our proposed approach outperforms the traditional cokriging 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#39640;&#26031;&#35780;&#20998;&#21305;&#37197;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#21464;&#20998;&#25512;&#29702;&#65292;&#36890;&#36807;&#36845;&#20195;&#31639;&#27861;&#23558;&#21464;&#20998;&#36817;&#20284;&#19982;&#31934;&#30830;&#21518;&#39564;&#30340;&#35780;&#20998;&#21305;&#37197;&#12290;&#24403;&#21464;&#20998;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#26102;&#65292;&#20869;&#37096;&#20248;&#21270;&#38382;&#39064;&#26377;&#38381;&#24335;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.07849</link><description>&lt;p&gt;
&#29992;&#39640;&#26031;&#35780;&#20998;&#21305;&#37197;&#36827;&#34892;&#21464;&#20998;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Variational Inference with Gaussian Score Matching. (arXiv:2307.07849v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07849
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#39640;&#26031;&#35780;&#20998;&#21305;&#37197;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#21464;&#20998;&#25512;&#29702;&#65292;&#36890;&#36807;&#36845;&#20195;&#31639;&#27861;&#23558;&#21464;&#20998;&#36817;&#20284;&#19982;&#31934;&#30830;&#21518;&#39564;&#30340;&#35780;&#20998;&#21305;&#37197;&#12290;&#24403;&#21464;&#20998;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#26102;&#65292;&#20869;&#37096;&#20248;&#21270;&#38382;&#39064;&#26377;&#38381;&#24335;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#29702;&#65288;VI&#65289;&#26159;&#19968;&#31181;&#36924;&#36817;&#36125;&#21494;&#26031;&#32479;&#35745;&#20013;&#30340;&#35745;&#31639;&#22256;&#38590;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;&#36890;&#24120;&#65292;VI&#36890;&#36807;&#26368;&#23567;&#21270;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#65288;&#20363;&#22914;&#35777;&#25454;&#19979;&#30028;ELBO&#65289;&#23558;&#31616;&#21333;&#30340;&#21442;&#25968;&#20998;&#24067;&#25311;&#21512;&#21040;&#30446;&#26631;&#21518;&#39564;&#20998;&#24067;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35780;&#20998;&#21305;&#37197;&#21407;&#29702;&#30340;&#26032;&#22411;VI&#26041;&#27861;&#65292;&#21363;&#22914;&#26524;&#20004;&#20010;&#20998;&#24067;&#30456;&#31561;&#65292;&#21017;&#23427;&#20204;&#30340;&#35780;&#20998;&#20989;&#25968;&#65288;&#21363;&#23545;&#25968;&#23494;&#24230;&#30340;&#26799;&#24230;&#65289;&#22312;&#20854;&#25903;&#25345;&#38598;&#30340;&#27599;&#20010;&#28857;&#19978;&#37117;&#30456;&#31561;&#12290;&#22522;&#20110;&#36825;&#19968;&#21407;&#29702;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#35780;&#20998;&#21305;&#37197;VI&#65292;&#36825;&#26159;&#19968;&#20010;&#36845;&#20195;&#31639;&#27861;&#65292;&#26088;&#22312;&#21305;&#37197;&#21464;&#20998;&#36817;&#20284;&#19982;&#31934;&#30830;&#21518;&#39564;&#20043;&#38388;&#30340;&#35780;&#20998;&#12290;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#35780;&#20998;&#21305;&#37197;VI&#35299;&#20915;&#20102;&#19968;&#20010;&#20869;&#37096;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#26368;&#23567;&#35843;&#25972;&#24403;&#21069;&#21464;&#20998;&#20272;&#35745;&#65292;&#20351;&#20854;&#19982;&#26032;&#25277;&#21462;&#30340;&#28508;&#21464;&#37327;&#20540;&#22788;&#30340;&#35780;&#20998;&#21305;&#37197;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24403;&#21464;&#20998;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#26102;&#65292;&#36825;&#20010;&#20869;&#37096;&#20248;&#21270;&#38382;&#39064;&#26377;&#19968;&#20010;&#38381;&#24335;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference (VI) is a method to approximate the computationally intractable posterior distributions that arise in Bayesian statistics. Typically, VI fits a simple parametric distribution to the target posterior by minimizing an appropriate objective such as the evidence lower bound (ELBO). In this work, we present a new approach to VI based on the principle of score matching, that if two distributions are equal then their score functions (i.e., gradients of the log density) are equal at every point on their support. With this, we develop score matching VI, an iterative algorithm that seeks to match the scores between the variational approximation and the exact posterior. At each iteration, score matching VI solves an inner optimization, one that minimally adjusts the current variational estimate to match the scores at a newly sampled value of the latent variables. We show that when the variational family is a Gaussian, this inner optimization enjoys a closed form solution, wh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#38543;&#26426;&#32534;&#30721;&#23398;&#20064;&#65288;MIRACLE&#65289;&#30340;&#20004;&#20010;&#21464;&#20307;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;Mean-KL&#65292;&#22312;&#21387;&#32553;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#21644;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.07816</link><description>&lt;p&gt;
&#24102;&#26377;Mean-KL&#21442;&#25968;&#21270;&#30340;&#26368;&#23567;&#38543;&#26426;&#32534;&#30721;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimal Random Code Learning with Mean-KL Parameterization. (arXiv:2307.07816v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#38543;&#26426;&#32534;&#30721;&#23398;&#20064;&#65288;MIRACLE&#65289;&#30340;&#20004;&#20010;&#21464;&#20307;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;Mean-KL&#65292;&#22312;&#21387;&#32553;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#21644;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#38543;&#26426;&#32534;&#30721;&#23398;&#20064;&#65288;MIRACLE&#65289;&#30340;&#20004;&#20010;&#21464;&#20307;&#22312;&#21387;&#32553;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23450;&#24615;&#34892;&#20026;&#21644;&#40065;&#26834;&#24615;&#12290;MIRACLE&#23454;&#29616;&#20102;&#24378;&#22823;&#30340;&#26465;&#20214;&#39640;&#26031;&#21464;&#20998;&#36817;&#20284;&#26435;&#37325;&#21518;&#39564;$Q_{\mathbf{w}}$&#65292;&#24182;&#20351;&#29992;&#30456;&#23545;&#29109;&#32534;&#30721;&#26469;&#21387;&#32553;&#20174;&#21518;&#39564;&#20013;&#25277;&#26679;&#30340;&#26435;&#37325;&#65292;&#20351;&#29992;&#39640;&#26031;&#32534;&#30721;&#20998;&#24067;$P_{\mathbf{w}}$&#12290;&#20026;&#20102;&#36798;&#21040;&#25152;&#38656;&#30340;&#21387;&#32553;&#29575;&#65292;&#24517;&#39035;&#23545;$Q_{\mathbf{w}} \Vert P_{\mathbf{w}}$&#36827;&#34892;&#32422;&#26463;&#65292;&#36825;&#38656;&#35201;&#22312;&#20256;&#32479;&#30340;&#22343;&#20540;-&#26041;&#24046;&#65288;Mean-Var&#65289;&#21442;&#25968;&#21270;&#19979;&#36827;&#34892;&#35745;&#31639;&#19978;&#26114;&#36149;&#30340;&#36864;&#28779;&#36807;&#31243;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36890;&#36807;&#20854;&#24179;&#22343;&#20540;&#21644;KL&#25955;&#24230;&#26469;&#21442;&#25968;&#21270;$Q_{\mathbf{w}}$&#65292;&#20197;&#36890;&#36807;&#26500;&#36896;&#23558;&#21387;&#32553;&#25104;&#26412;&#32422;&#26463;&#20026;&#25152;&#38656;&#20540;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;Mean-KL&#21442;&#25968;&#21270;&#30340;&#21464;&#20998;&#35757;&#32451;&#25910;&#25947;&#36895;&#24230;&#26159;&#20256;&#32479;&#26041;&#27861;&#30340;&#20004;&#20493;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#21518;&#20445;&#25345;&#20102;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the qualitative behavior and robustness of two variants of Minimal Random Code Learning (MIRACLE) used to compress variational Bayesian neural networks. MIRACLE implements a powerful, conditionally Gaussian variational approximation for the weight posterior $Q_{\mathbf{w}}$ and uses relative entropy coding to compress a weight sample from the posterior using a Gaussian coding distribution $P_{\mathbf{w}}$. To achieve the desired compression rate, $D_{\mathrm{KL}}[Q_{\mathbf{w}} \Vert P_{\mathbf{w}}]$ must be constrained, which requires a computationally expensive annealing procedure under the conventional mean-variance (Mean-Var) parameterization for $Q_{\mathbf{w}}$. Instead, we parameterize $Q_{\mathbf{w}}$ by its mean and KL divergence from $P_{\mathbf{w}}$ to constrain the compression cost to the desired value by construction. We demonstrate that variational training with Mean-KL parameterization converges twice as fast and maintains predictive performance after 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#22270;&#33258;&#21516;&#24577;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#65292;&#25214;&#21040;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;&#23618;&#20989;&#25968;&#20043;&#38388;&#30340;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#12290;</title><link>http://arxiv.org/abs/2307.07810</link><description>&lt;p&gt;
&#22270;&#33258;&#21516;&#24577;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Graph Automorphism Group Equivariant Neural Networks. (arXiv:2307.07810v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07810
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#22270;&#33258;&#21516;&#24577;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#65292;&#25214;&#21040;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;&#23618;&#20989;&#25968;&#20043;&#38388;&#30340;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20219;&#20309;&#20855;&#26377;n&#20010;&#39030;&#28857;&#21644;&#20854;&#33258;&#21516;&#24577;&#32676;Aut(G)&#30340;&#22270;G&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;&#21487;&#33021;&#30340;Aut(G)-&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#65292;&#20854;&#23618;&#26159;n&#32500;&#23454;&#25968;&#24352;&#37327;&#30340;&#26576;&#20123;&#24352;&#37327;&#24130;&#27425;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22312;n&#32500;&#23454;&#25968;&#31354;&#38388;&#30340;&#26631;&#20934;&#22522;&#19979;&#25214;&#21040;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;Aut(G)-&#31561;&#21464;&#23618;&#20989;&#25968;&#20043;&#38388;&#30340;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
For any graph $G$ having $n$ vertices and its automorphism group $\textrm{Aut}(G)$, we provide a full characterisation of all of the possible $\textrm{Aut}(G)$-equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. In particular, we find a spanning set of matrices for the learnable, linear, $\textrm{Aut}(G)$-equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25554;&#20540;&#20449;&#24687;&#20934;&#21017;&#65292;&#29992;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#24314;&#31435;&#36125;&#21494;&#26031;&#23545;&#20598;&#24418;&#24335;&#65292;&#35813;&#20934;&#21017;&#23558;&#20808;&#39564;&#36873;&#25321;&#32435;&#20837;&#27169;&#22411;&#35780;&#20272;&#65292;&#24182;&#32771;&#34385;&#20102;&#20808;&#39564;&#35823;&#35774;&#12289;&#27169;&#22411;&#30340;&#20960;&#20309;&#21644;&#35889;&#29305;&#24615;&#12290;&#35813;&#20934;&#21017;&#22312;&#23454;&#35777;&#21644;&#29702;&#35770;&#34892;&#20026;&#26041;&#38754;&#19982;&#24050;&#30693;&#32467;&#26524;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2307.07785</link><description>&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#25554;&#20540;&#20449;&#24687;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
The Interpolating Information Criterion for Overparameterized Models. (arXiv:2307.07785v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25554;&#20540;&#20449;&#24687;&#20934;&#21017;&#65292;&#29992;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#24314;&#31435;&#36125;&#21494;&#26031;&#23545;&#20598;&#24418;&#24335;&#65292;&#35813;&#20934;&#21017;&#23558;&#20808;&#39564;&#36873;&#25321;&#32435;&#20837;&#27169;&#22411;&#35780;&#20272;&#65292;&#24182;&#32771;&#34385;&#20102;&#20808;&#39564;&#35823;&#35774;&#12289;&#27169;&#22411;&#30340;&#20960;&#20309;&#21644;&#35889;&#29305;&#24615;&#12290;&#35813;&#20934;&#21017;&#22312;&#23454;&#35777;&#21644;&#29702;&#35770;&#34892;&#20026;&#26041;&#38754;&#19982;&#24050;&#30693;&#32467;&#26524;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#36807;&#21442;&#25968;&#21270;&#20272;&#35745;&#22120;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#65292;&#20854;&#20013;&#27169;&#22411;&#21442;&#25968;&#30340;&#25968;&#37327;&#36229;&#36807;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#12290;&#20256;&#32479;&#30340;&#20449;&#24687;&#20934;&#21017;&#36890;&#24120;&#32771;&#34385;&#22823;&#25968;&#25454;&#26497;&#38480;&#65292;&#23545;&#27169;&#22411;&#22823;&#23567;&#36827;&#34892;&#24809;&#32602;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#20195;&#35774;&#32622;&#20013;&#65292;&#36825;&#20123;&#20934;&#21017;&#19981;&#36866;&#29992;&#65292;&#22240;&#20026;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#24448;&#24448;&#34920;&#29616;&#33391;&#22909;&#12290;&#23545;&#20110;&#20219;&#20309;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#25105;&#20204;&#35777;&#26126;&#23384;&#22312;&#19968;&#20010;&#23545;&#20598;&#30340;&#27424;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#20855;&#26377;&#30456;&#21516;&#30340;&#36793;&#32536;&#20284;&#28982;&#24615;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#36125;&#21494;&#26031;&#23545;&#20598;&#24418;&#24335;&#12290;&#36825;&#20351;&#24471;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#21487;&#20197;&#20351;&#29992;&#26356;&#22810;&#32463;&#20856;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#25554;&#20540;&#20449;&#24687;&#20934;&#21017;&#65292;&#19968;&#31181;&#33258;&#28982;&#22320;&#23558;&#20808;&#39564;&#36873;&#25321;&#32435;&#20837;&#27169;&#22411;&#36873;&#25321;&#30340;&#27169;&#22411;&#36136;&#37327;&#24230;&#37327;&#12290;&#25105;&#20204;&#30340;&#26032;&#20449;&#24687;&#20934;&#21017;&#32771;&#34385;&#20102;&#20808;&#39564;&#35823;&#35774;&#12289;&#27169;&#22411;&#30340;&#20960;&#20309;&#21644;&#35889;&#29305;&#24615;&#65292;&#24182;&#19988;&#22312;&#35813;&#21306;&#22495;&#19982;&#24050;&#30693;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#34892;&#20026;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of model selection is considered for the setting of interpolating estimators, where the number of model parameters exceeds the size of the dataset. Classical information criteria typically consider the large-data limit, penalizing model size. However, these criteria are not appropriate in modern settings where overparameterized models tend to perform well. For any overparameterized model, we show that there exists a dual underparameterized model that possesses the same marginal likelihood, thus establishing a form of Bayesian duality. This enables more classical methods to be used in the overparameterized setting, revealing the Interpolating Information Criterion, a measure of model quality that naturally incorporates the choice of prior into the model selection. Our new information criterion accounts for prior misspecification, geometric and spectral properties of the model, and is numerically consistent with known empirical and theoretical behavior in this regime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20808;&#39564;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#25193;&#23637;&#21644;&#32467;&#26500;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20316;&#20026;&#25512;&#24191;&#30340;&#20449;&#24687;&#20808;&#39564;&#65292;&#25552;&#39640;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#24191;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22823;&#35268;&#27169;&#19978;&#25552;&#20379;&#20102;&#34920;&#36798;&#24615;&#30340;&#27010;&#29575;&#34920;&#31034;&#65292;&#24182;&#20135;&#29983;&#20102;&#38750;&#31354;&#25512;&#24191;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#36129;&#29486;&#26159;&#25512;&#23548;&#20986;&#21487;&#22788;&#29702;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#25512;&#24191;&#30028;&#38480;&#35745;&#31639;&#26041;&#27861;&#12290;&#22312;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#25512;&#24191;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.07753</link><description>&lt;p&gt;
&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#34920;&#36798;&#24615;&#20808;&#39564;&#65292;&#25552;&#39640;&#25512;&#24191;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks. (arXiv:2307.07753v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07753
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20808;&#39564;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#25193;&#23637;&#21644;&#32467;&#26500;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20316;&#20026;&#25512;&#24191;&#30340;&#20449;&#24687;&#20808;&#39564;&#65292;&#25552;&#39640;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#24191;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22823;&#35268;&#27169;&#19978;&#25552;&#20379;&#20102;&#34920;&#36798;&#24615;&#30340;&#27010;&#29575;&#34920;&#31034;&#65292;&#24182;&#20135;&#29983;&#20102;&#38750;&#31354;&#25512;&#24191;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#36129;&#29486;&#26159;&#25512;&#23548;&#20986;&#21487;&#22788;&#29702;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#25512;&#24191;&#30028;&#38480;&#35745;&#31639;&#26041;&#27861;&#12290;&#22312;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#25512;&#24191;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20808;&#39564;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25512;&#24191;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#21033;&#29992;&#21487;&#25193;&#23637;&#21644;&#32467;&#26500;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20316;&#20026;&#20855;&#26377;&#25512;&#24191;&#20445;&#35777;&#30340;&#20449;&#24687;&#20808;&#39564;&#12290;&#25105;&#20204;&#23398;&#20064;&#21040;&#30340;&#20808;&#39564;&#22312;&#22823;&#35268;&#27169;&#19978;&#25552;&#20379;&#20102;&#34920;&#36798;&#24615;&#30340;&#27010;&#29575;&#34920;&#31034;&#65292;&#31867;&#20284;&#20110;&#22312;ImageNet&#19978;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#23545;&#24212;&#29289;&#65292;&#24182;&#36827;&#19968;&#27493;&#20135;&#29983;&#20102;&#38750;&#31354;&#25512;&#24191;&#30028;&#38480;&#12290;&#25105;&#20204;&#36824;&#23558;&#36825;&#20010;&#24819;&#27861;&#25193;&#23637;&#21040;&#36830;&#32493;&#23398;&#20064;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#30340;&#20808;&#39564;&#30340;&#26377;&#21033;&#29305;&#24615;&#26159;&#21487;&#21462;&#30340;&#12290;&#20027;&#35201;&#30340;&#25512;&#21160;&#22240;&#32032;&#26159;&#25105;&#20204;&#30340;&#25216;&#26415;&#36129;&#29486;&#65306;(1) Kronecker&#31215;&#27714;&#21644;&#30340;&#35745;&#31639;&#65292;(2) &#25512;&#23548;&#21644;&#20248;&#21270;&#21487;&#22788;&#29702;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20174;&#32780;&#23548;&#33268;&#25913;&#36827;&#30340;&#25512;&#24191;&#30028;&#38480;&#12290;&#22312;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#35814;&#23613;&#22320;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#25512;&#24191;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#20108;&#27425;&#35268;&#21010;&#36755;&#20837;&#35268;&#27169;&#21644;&#35299;&#20915;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.07735</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Nearly-Linear Time Algorithm for Structured Support Vector Machines. (arXiv:2307.07735v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07735
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#20108;&#27425;&#35268;&#21010;&#36755;&#20837;&#35268;&#27169;&#21644;&#35299;&#20915;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#27425;&#35268;&#21010;&#26159;&#20984;&#20248;&#21270;&#39046;&#22495;&#20013;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#35768;&#22810;&#23454;&#38469;&#20219;&#21153;&#21487;&#20197;&#34920;&#31034;&#20026;&#20108;&#27425;&#35268;&#21010;&#65292;&#20363;&#22914;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30427;&#34892;&#20043;&#21069;&#65292;&#32447;&#24615;SVM&#26159;&#36807;&#21435;&#19977;&#21313;&#24180;&#26469;&#26368;&#27969;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#20043;&#19968;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#19968;&#20010;&#20108;&#27425;&#35268;&#21010;&#30340;&#36755;&#20837;&#35268;&#27169;&#20026;&#920;(n^2)&#65288;&#20854;&#20013;n&#26159;&#21464;&#37327;&#30340;&#25968;&#37327;&#65289;&#65292;&#22240;&#27492;&#35299;&#20915;&#35813;&#38382;&#39064;&#38656;&#35201;&#937;(n^2)&#30340;&#26102;&#38388;&#12290;&#28982;&#32780;&#65292;SVM&#20135;&#29983;&#30340;&#20108;&#27425;&#35268;&#21010;&#30340;&#36755;&#20837;&#35268;&#27169;&#20026;O(n)&#65292;&#36825;&#20351;&#24471;&#35774;&#35745;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#25104;&#20026;&#21487;&#33021;&#12290;&#20004;&#20010;&#37325;&#35201;&#30340;SVM&#31867;&#21035;&#26159;&#20855;&#26377;&#20302;&#31209;&#26680;&#22240;&#24335;&#20998;&#35299;&#21644;&#20302;&#26641;&#23485;&#35268;&#27169;&#30340;&#31243;&#24207;&#12290;&#20302;&#26641;&#23485;&#20984;&#20248;&#21270;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65288;&#20363;&#22914;&#32447;&#24615;&#35268;&#21010;[Dong, Lee and Ye 2021]&#21644;&#21322;&#23450;&#35268;&#21010;[Gu and Song 2022]&#65289;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#24320;&#25918;&#38382;&#39064;&#26159;&#26159;&#21542;&#23384;&#22312;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quadratic programming is a fundamental problem in the field of convex optimization. Many practical tasks can be formulated as quadratic programming, for example, the support vector machine (SVM). Linear SVM is one of the most popular tools over the last three decades in machine learning before deep learning method dominating.  In general, a quadratic program has input size $\Theta(n^2)$ (where $n$ is the number of variables), thus takes $\Omega(n^2)$ time to solve. Nevertheless, quadratic programs coming from SVMs has input size $O(n)$, allowing the possibility of designing nearly-linear time algorithms. Two important classes of SVMs are programs admitting low-rank kernel factorizations and low-treewidth programs. Low-treewidth convex optimization has gained increasing interest in the past few years (e.g.~linear programming [Dong, Lee and Ye 2021] and semidefinite programming [Gu and Song 2022]). Therefore, an important open question is whether there exist nearly-linear time algorithms
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25581;&#31034;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26500;&#24314;&#20013;&#30340;&#26679;&#26412;&#25286;&#20998;&#26041;&#27861;&#30340;&#22885;&#31192;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20174;&#26679;&#26412;&#25286;&#20998;&#20013;&#24471;&#21040;&#30340;&#26368;&#20248;&#36229;&#21442;&#25968;&#21487;&#20197;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26368;&#23567;&#21270;&#39044;&#27979;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2307.07726</link><description>&lt;p&gt;
&#36808;&#21521;&#26368;&#20248;&#31070;&#32463;&#32593;&#32476;&#65306;&#26679;&#26412;&#25286;&#20998;&#22312;&#36229;&#21442;&#25968;&#36873;&#25321;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection. (arXiv:2307.07726v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25581;&#31034;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26500;&#24314;&#20013;&#30340;&#26679;&#26412;&#25286;&#20998;&#26041;&#27861;&#30340;&#22885;&#31192;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20174;&#26679;&#26412;&#25286;&#20998;&#20013;&#24471;&#21040;&#30340;&#26368;&#20248;&#36229;&#21442;&#25968;&#21487;&#20197;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26368;&#23567;&#21270;&#39044;&#27979;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#20010;&#39046;&#22495;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#23454;&#36341;&#25104;&#21151;&#26102;&#65292;&#20851;&#20110;&#23427;&#20204;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#22914;&#36924;&#36817;&#33021;&#21147;&#12289;&#32479;&#35745;&#24615;&#36136;&#21644;&#27867;&#21270;&#24615;&#33021;&#31561;&#30340;&#30740;&#31350;&#20063;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25581;&#31034;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26500;&#24314;&#20013;&#19968;&#31181;&#24120;&#35265;&#23454;&#36341;&#32972;&#21518;&#30340;&#22885;&#31192;&#65306;&#26679;&#26412;&#25286;&#20998;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29702;&#35770;&#26469;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#35777;&#26126;&#65292;&#20174;&#26679;&#26412;&#25286;&#20998;&#20013;&#24471;&#21040;&#30340;&#26368;&#20248;&#36229;&#21442;&#25968;&#21487;&#20197;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#28176;&#36827;&#22320;&#26368;&#23567;&#21270;&#39044;&#27979;&#39118;&#38505;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#21644;&#32593;&#32476;&#32467;&#26500;&#20013;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
When artificial neural networks have demonstrated exceptional practical success in a variety of domains, investigations into their theoretical characteristics, such as their approximation power, statistical properties, and generalization performance, have made significant strides. In this paper, we construct a novel theory for understanding the effectiveness of neural networks by discovering the mystery underlying a common practice during neural network model construction: sample splitting. Our theory demonstrates that, the optimal hyperparameters derived from sample splitting can enable a neural network model that asymptotically minimizes the prediction risk. We conduct extensive experiments across different application scenarios and network architectures, and the results manifest our theory's effectiveness.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#21319;&#29616;&#26377;&#30340;&#19979;&#30028;&#26469;&#21305;&#37197;&#26368;&#20339;&#19978;&#30028;&#65292;&#23545;&#21305;&#37197;&#36861;&#36394;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#31934;&#30830;&#25551;&#36848;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#26368;&#22351;&#24773;&#20917;&#30340;&#23383;&#20856;&#26469;&#35777;&#26126;&#29616;&#26377;&#19978;&#30028;&#30340;&#26080;&#27861;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2307.07679</link><description>&lt;p&gt;
&#21305;&#37197;&#36861;&#36394;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sharp Convergence Rates for Matching Pursuit. (arXiv:2307.07679v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#21319;&#29616;&#26377;&#30340;&#19979;&#30028;&#26469;&#21305;&#37197;&#26368;&#20339;&#19978;&#30028;&#65292;&#23545;&#21305;&#37197;&#36861;&#36394;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#31934;&#30830;&#25551;&#36848;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#26368;&#22351;&#24773;&#20917;&#30340;&#23383;&#20856;&#26469;&#35777;&#26126;&#29616;&#26377;&#19978;&#30028;&#30340;&#26080;&#27861;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21305;&#37197;&#36861;&#36394;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21363;&#36890;&#36807;&#23383;&#20856;&#20013;&#30340;&#20803;&#32032;&#30340;&#31232;&#30095;&#32447;&#24615;&#32452;&#21512;&#26469;&#36817;&#20284;&#30446;&#26631;&#20989;&#25968;&#30340;&#32431;&#36138;&#23146;&#31639;&#27861;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21253;&#21547;&#22312;&#23545;&#24212;&#20110;&#23383;&#20856;&#30340;&#21464;&#21270;&#31354;&#38388;&#20013;&#26102;&#65292;&#35768;&#22810;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#30740;&#31350;&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#33719;&#24471;&#20102;&#21305;&#37197;&#36861;&#36394;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;&#20294;&#23427;&#20204;&#24182;&#19981;&#21305;&#37197;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#24182;&#33719;&#24471;&#21305;&#37197;&#36861;&#36394;&#24615;&#33021;&#30340;&#31934;&#30830;&#25551;&#36848;&#12290;&#25105;&#20204;&#36890;&#36807;&#25913;&#36827;&#29616;&#26377;&#30340;&#19979;&#30028;&#20197;&#21305;&#37197;&#26368;&#20339;&#19978;&#30028;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#26368;&#22351;&#24773;&#20917;&#30340;&#23383;&#20856;&#65292;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#19978;&#30028;&#19981;&#33021;&#25913;&#36827;&#12290;&#20107;&#23454;&#35777;&#26126;&#65292;&#19982;&#20854;&#20182;&#36138;&#23146;&#31639;&#27861;&#21464;&#20307;&#19981;&#21516;&#65292;&#25910;&#25947;&#36895;&#24230;&#26159;&#27425;&#20248;&#30340;&#65292;&#24182;&#19988;&#30001;&#35299;&#26576;&#20010;&#38750;&#32447;&#24615;&#26041;&#31243;&#30340;&#35299;&#20915;&#26041;&#26696;&#20915;&#23450;&#12290;&#36825;&#20351;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#20219;&#24847;&#31243;&#24230;&#30340;&#25910;&#32553;&#37117;&#20250;&#25913;&#21892;&#21305;&#37197;&#36861;&#36394;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the fundamental limits of matching pursuit, or the pure greedy algorithm, for approximating a target function by a sparse linear combination of elements from a dictionary. When the target function is contained in the variation space corresponding to the dictionary, many impressive works over the past few decades have obtained upper and lower bounds on the convergence rate of matching pursuit, but they do not match. The main contribution of this paper is to close this gap and obtain a sharp characterization of the performance of matching pursuit. We accomplish this by improving the existing lower bounds to match the best upper bound. Specifically, we construct a worst case dictionary which proves that the existing upper bound cannot be improved. It turns out that, unlike other greedy algorithm variants, the converge rate is suboptimal and is determined by the solution to a certain non-linear equation. This enables us to conclude that any amount of shrinkage improves matching pu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#22810;Agent&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#21046;&#20013;&#65292;&#26368;&#31361;&#20986;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;$\epsilon$-greedy&#21487;&#20197;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#35299;&#20915;&#21516;&#26102;&#23384;&#22312;&#30340;&#28608;&#21169;&#22240;&#32032;&#12289;&#19978;&#19979;&#25991;&#21644;&#25439;&#22351;&#38382;&#39064;</title><link>http://arxiv.org/abs/2307.07675</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#33410;&#28857;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#21046;&#20013;Epoch-Greedy&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms. (arXiv:2307.07675v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07675
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#22810;Agent&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#21046;&#20013;&#65292;&#26368;&#31361;&#20986;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;$\epsilon$-greedy&#21487;&#20197;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#35299;&#20915;&#21516;&#26102;&#23384;&#22312;&#30340;&#28608;&#21169;&#22240;&#32032;&#12289;&#19978;&#19979;&#25991;&#21644;&#25439;&#22351;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20687;&#28857;&#20987;&#20184;&#36153;(Pay-Per-Click)&#25293;&#21334;&#36825;&#26679;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#21046;&#20013;&#36827;&#34892;&#39640;&#25928;&#23398;&#20064;&#36890;&#24120;&#28041;&#21450;&#19977;&#20010;&#25361;&#25112;&#65306;1)&#24341;&#23548;&#30495;&#23454;&#20986;&#20215;&#34892;&#20026;(&#28608;&#21169;&#22240;&#32032;)&#65292;2)&#22312;&#29992;&#25143;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#20013;&#20351;&#29992;&#20010;&#24615;&#21270;(&#19978;&#19979;&#25991;)&#65292;3)&#35268;&#36991;&#28857;&#20987;&#27169;&#24335;&#20013;&#30340;&#25805;&#32437;(&#25439;&#22351;&#34892;&#20026;)&#12290;&#36807;&#21435;&#25991;&#29486;&#20013;&#27599;&#20010;&#25361;&#25112;&#37117;&#34987;&#29420;&#31435;&#30740;&#31350;&#36807;&#65307;&#28608;&#21169;&#22240;&#32032;&#24050;&#22312;&#19968;&#31995;&#21015;&#30740;&#31350;&#20013;&#24471;&#21040;&#35299;&#20915;&#65292;&#19978;&#19979;&#25991;&#38382;&#39064;&#24050;&#36890;&#36807;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#24471;&#21040;&#24191;&#27867;&#35299;&#20915;&#65292;&#32780;&#25439;&#22351;&#38382;&#39064;&#21017;&#36890;&#36807;&#26368;&#36817;&#30340;&#20851;&#20110;&#20855;&#26377;&#23545;&#25239;&#24615;&#25439;&#22351;&#30340;&#36172;&#21338;&#26426;&#21046;&#24037;&#20316;&#36827;&#34892;&#35752;&#35770;&#12290;&#30001;&#20110;&#36825;&#20123;&#25361;&#25112;&#21516;&#26102;&#23384;&#22312;&#65292;&#37325;&#35201;&#30340;&#26159;&#20102;&#35299;&#27599;&#31181;&#26041;&#27861;&#22312;&#35299;&#20915;&#20854;&#20182;&#25361;&#25112;&#26102;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20379;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#25152;&#26377;&#25361;&#25112;&#30340;&#31639;&#27861;&#65292;&#24182;&#31361;&#20986;&#36825;&#31181;&#32452;&#21512;&#20013;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#31361;&#20986;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;$\epsilon$-greedy&#21487;&#20197;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#35299;&#20915;&#21516;&#26102;&#23384;&#22312;&#30340;&#28608;&#21169;&#22240;&#32032;&#12289;&#19978;&#19979;&#25991;&#21644;&#25439;&#22351;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). Each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. Since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. In this work, we show that the most prominent contextual bandit algorithm, $\epsilon$-greedy can be extended to
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26494;&#24347;&#21644;&#24377;&#24615;&#20108;&#20803;&#27491;&#21017;&#21270;&#22120;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#26377;&#25928;&#22320;&#20998;&#35299;&#24067;&#23572;&#30697;&#38453;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#24555;&#36895;&#25910;&#25947;&#21644;&#20934;&#30830;&#24615;&#65292;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#32467;&#26524;&#26131;&#20110;&#35299;&#37322;&#21644;&#35821;&#20041;&#26377;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2307.07615</link><description>&lt;p&gt;
&#29992;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#26377;&#25928;&#22320;&#20998;&#35299;&#24067;&#23572;&#30697;&#38453;
&lt;/p&gt;
&lt;p&gt;
Efficiently Factorizing Boolean Matrices using Proximal Gradient Descent. (arXiv:2307.07615v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07615
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26494;&#24347;&#21644;&#24377;&#24615;&#20108;&#20803;&#27491;&#21017;&#21270;&#22120;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#26377;&#25928;&#22320;&#20998;&#35299;&#24067;&#23572;&#30697;&#38453;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#24555;&#36895;&#25910;&#25947;&#21644;&#20934;&#30830;&#24615;&#65292;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#32467;&#26524;&#26131;&#20110;&#35299;&#37322;&#21644;&#35821;&#20041;&#26377;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#22312;&#24067;&#23572;&#25968;&#25454;&#19978;&#30340;&#21487;&#35299;&#37322;&#24615;&#38382;&#39064;&#65292;&#24067;&#23572;&#30697;&#38453;&#20998;&#35299;&#65288;BMF&#65289;&#20351;&#29992;&#24067;&#23572;&#20195;&#25968;&#23558;&#36755;&#20837;&#20998;&#35299;&#20026;&#20302;&#31209;&#24067;&#23572;&#22240;&#23376;&#30697;&#38453;&#12290;&#36825;&#20123;&#30697;&#38453;&#20855;&#26377;&#24456;&#39640;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#26377;&#29992;&#65292;&#20294;&#38656;&#35201;&#35299;&#20915;&#19968;&#20010;NP&#38590;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#35745;&#31639;&#25104;&#26412;&#36739;&#39640;&#12290;&#20026;&#20102;&#20943;&#36731;&#35745;&#31639;&#36127;&#25285;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36830;&#32493;&#26494;&#24347;BMF&#30340;&#26032;&#22411;&#24377;&#24615;&#20108;&#20803;&#27491;&#21017;&#21270;&#22120;&#65292;&#20174;&#20013;&#25512;&#23548;&#20986;&#19968;&#31181;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#65306;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#24555;&#36895;&#25910;&#25947;&#65292;&#31934;&#30830;&#24674;&#22797;&#20102;&#30495;&#23454;&#20540;&#65292;&#24182;&#20934;&#30830;&#20272;&#35745;&#20102;&#27169;&#25311;&#31209;&#12290;&#22312;&#23454;&#38469;&#25968;&#25454;&#19978;&#65292;&#25105;&#20204;&#22312;&#21484;&#22238;&#29575;&#12289;&#25439;&#22833;&#21644;&#36816;&#34892;&#26102;&#38388;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#24182;&#19988;&#26469;&#33258;&#21307;&#23398;&#39046;&#22495;&#30340;&#26696;&#20363;&#30740;&#31350;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#26131;&#20110;&#35299;&#37322;&#21644;&#35821;&#20041;&#26377;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Addressing the interpretability problem of NMF on Boolean data, Boolean Matrix Factorization (BMF) uses Boolean algebra to decompose the input into low-rank Boolean factor matrices. These matrices are highly interpretable and very useful in practice, but they come at the high computational cost of solving an NP-hard combinatorial optimization problem. To reduce the computational burden, we propose to relax BMF continuously using a novel elastic-binary regularizer, from which we derive a proximal gradient algorithm. Through an extensive set of experiments, we demonstrate that our method works well in practice: On synthetic data, we show that it converges quickly, recovers the ground truth precisely, and estimates the simulated rank exactly. On real-world data, we improve upon the state of the art in recall, loss, and runtime, and a case study from the medical domain confirms that our results are easily interpretable and semantically meaningful.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#33021;&#37327;&#24046;&#24322;&#35757;&#32451;&#31163;&#25955;&#33021;&#37327;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#37319;&#26679;&#31574;&#30053;&#65292;&#36890;&#36807;&#35780;&#20272;&#25968;&#25454;&#28857;&#21450;&#20854;&#25200;&#21160;&#23545;&#24212;&#28857;&#30340;&#33021;&#37327;&#20989;&#25968;&#26469;&#23454;&#29616;&#65292;&#33021;&#22815;&#20026;&#21508;&#31181;&#25200;&#21160;&#36807;&#31243;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#30456;&#23545;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.07595</link><description>&lt;p&gt;
&#29992;&#33021;&#37327;&#24046;&#24322;&#35757;&#32451;&#31163;&#25955;&#33021;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Training Discrete Energy-Based Models with Energy Discrepancy. (arXiv:2307.07595v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07595
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#33021;&#37327;&#24046;&#24322;&#35757;&#32451;&#31163;&#25955;&#33021;&#37327;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#37319;&#26679;&#31574;&#30053;&#65292;&#36890;&#36807;&#35780;&#20272;&#25968;&#25454;&#28857;&#21450;&#20854;&#25200;&#21160;&#23545;&#24212;&#28857;&#30340;&#33021;&#37327;&#20989;&#25968;&#26469;&#23454;&#29616;&#65292;&#33021;&#22815;&#20026;&#21508;&#31181;&#25200;&#21160;&#36807;&#31243;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#30456;&#23545;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31163;&#25955;&#31354;&#38388;&#19978;&#35757;&#32451;&#33021;&#37327;&#27169;&#22411;&#65288;EBMs&#65289;&#20805;&#28385;&#25361;&#25112;&#65292;&#22240;&#20026;&#23545;&#36825;&#26679;&#30340;&#31354;&#38388;&#36827;&#34892;&#37319;&#26679;&#21487;&#33021;&#24456;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#33021;&#37327;&#24046;&#24322;&#65288;ED&#65289;&#26469;&#35757;&#32451;&#31163;&#25955;EBMs&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#65292;&#21482;&#38656;&#35201;&#35780;&#20272;&#25968;&#25454;&#28857;&#21450;&#20854;&#25200;&#21160;&#23545;&#24212;&#28857;&#30340;&#33021;&#37327;&#20989;&#25968;&#65292;&#22240;&#27492;&#19981;&#20381;&#36182;&#20110;&#20687;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#36825;&#26679;&#30340;&#37319;&#26679;&#31574;&#30053;&#12290;&#33021;&#37327;&#24046;&#24322;&#20026;&#19968;&#31867;&#24191;&#27867;&#30340;&#25200;&#21160;&#36807;&#31243;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#25200;&#21160;&#65306;&#22522;&#20110;&#20271;&#21162;&#21033;&#22122;&#22768;&#30340;&#25200;&#21160;&#65292;&#22522;&#20110;&#30830;&#23450;&#24615;&#21464;&#25442;&#30340;&#25200;&#21160;&#65292;&#20197;&#21450;&#22522;&#20110;&#37051;&#22495;&#32467;&#26500;&#30340;&#25200;&#21160;&#12290;&#25105;&#20204;&#22312;&#26230;&#26684;&#20234;&#36763;&#27169;&#22411;&#12289;&#20108;&#20540;&#21512;&#25104;&#25968;&#25454;&#21644;&#31163;&#25955;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#23427;&#20204;&#30340;&#30456;&#23545;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training energy-based models (EBMs) on discrete spaces is challenging because sampling over such spaces can be difficult. We propose to train discrete EBMs with energy discrepancy (ED), a novel type of contrastive loss functional which only requires the evaluation of the energy function at data points and their perturbed counter parts, thus not relying on sampling strategies like Markov chain Monte Carlo (MCMC). Energy discrepancy offers theoretical guarantees for a broad class of perturbation processes of which we investigate three types: perturbations based on Bernoulli noise, based on deterministic transforms, and based on neighbourhood structures. We demonstrate their relative performance on lattice Ising models, binary synthetic data, and discrete image data sets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#21270;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#36890;&#36807;&#23558;&#26576;&#20123;&#21306;&#38388;&#30340;&#19978;&#19979;&#30028;&#25910;&#32553;&#20026;&#38646;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#30830;&#23450;&#19981;&#37325;&#35201;&#30340;&#21327;&#21464;&#37327;&#24182;&#23558;&#20854;&#25490;&#38500;&#22312;&#26368;&#32456;&#27169;&#22411;&#20043;&#22806;&#65292;&#21516;&#26102;&#36890;&#36807;&#20854;&#20182;&#21306;&#38388;&#21028;&#26029;&#20986;&#21487;&#20449;&#21644;&#26174;&#33879;&#30340;&#21327;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.07574</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#30340;&#31232;&#30095;&#21270;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Sparsified Simultaneous Confidence Intervals for High-Dimensional Linear Models. (arXiv:2307.07574v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07574
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#21270;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#36890;&#36807;&#23558;&#26576;&#20123;&#21306;&#38388;&#30340;&#19978;&#19979;&#30028;&#25910;&#32553;&#20026;&#38646;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#30830;&#23450;&#19981;&#37325;&#35201;&#30340;&#21327;&#21464;&#37327;&#24182;&#23558;&#20854;&#25490;&#38500;&#22312;&#26368;&#32456;&#27169;&#22411;&#20043;&#22806;&#65292;&#21516;&#26102;&#36890;&#36807;&#20854;&#20182;&#21306;&#38388;&#21028;&#26029;&#20986;&#21487;&#20449;&#21644;&#26174;&#33879;&#30340;&#21327;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#27169;&#22411;&#36873;&#25321;&#36807;&#31243;&#24341;&#20837;&#30340;&#19981;&#30830;&#23450;&#24615;&#38590;&#20197;&#32771;&#34385;&#65292;&#23545;&#39640;&#32500;&#22238;&#24402;&#31995;&#25968;&#30340;&#32479;&#35745;&#25512;&#26029;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#26410;&#35299;&#20915;&#65292;&#21363;&#26159;&#21542;&#21487;&#33021;&#20197;&#21450;&#22914;&#20309;&#23558;&#27169;&#22411;&#30340;&#25512;&#26029;&#23884;&#20837;&#21040;&#31995;&#25968;&#30340;&#21516;&#26102;&#25512;&#26029;&#20013;&#65311;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#31232;&#30095;&#21270;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#21306;&#38388;&#22312;&#26576;&#20123;&#19978;&#19979;&#30028;&#19978;&#36827;&#34892;&#20102;&#31232;&#30095;&#65292;&#21363;&#32553;&#23567;&#20026;&#38646;&#65288;&#20363;&#22914;&#65292;$[0,0]$&#65289;&#65292;&#34920;&#31034;&#30456;&#24212;&#21327;&#21464;&#37327;&#30340;&#19981;&#37325;&#35201;&#24615;&#12290;&#36825;&#20123;&#21327;&#21464;&#37327;&#24212;&#35813;&#20174;&#26368;&#32456;&#27169;&#22411;&#20013;&#25490;&#38500;&#12290;&#20854;&#20313;&#30340;&#21306;&#38388;&#65292;&#26080;&#35770;&#26159;&#21253;&#21547;&#38646;&#65288;&#20363;&#22914;&#65292;$[-1,1]$&#25110;$[0,1]$&#65289;&#36824;&#26159;&#19981;&#21253;&#21547;&#38646;&#65288;&#20363;&#22914;&#65292;$[2,3]$&#65289;&#65292;&#20998;&#21035;&#34920;&#31034;&#21487;&#20449;&#21644;&#26174;&#33879;&#30340;&#21327;&#21464;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#19982;&#21508;&#31181;&#36873;&#25321;&#36807;&#31243;&#30456;&#32467;&#21512;&#65292;&#20351;&#20854;&#38750;&#24120;&#36866;&#21512;&#27604;&#36739;&#23427;&#20204;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical inference of the high-dimensional regression coefficients is challenging because the uncertainty introduced by the model selection procedure is hard to account for. A critical question remains unsettled; that is, is it possible and how to embed the inference of the model into the simultaneous inference of the coefficients? To this end, we propose a notion of simultaneous confidence intervals called the sparsified simultaneous confidence intervals. Our intervals are sparse in the sense that some of the intervals' upper and lower bounds are shrunken to zero (i.e., $[0,0]$), indicating the unimportance of the corresponding covariates. These covariates should be excluded from the final model. The rest of the intervals, either containing zero (e.g., $[-1,1]$ or $[0,1]$) or not containing zero (e.g., $[2,3]$), indicate the plausible and significant covariates, respectively. The proposed method can be coupled with various selection procedures, making it ideal for comparing their u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#21464;&#20998;&#39044;&#27979;&#36825;&#19968;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#30028;&#30452;&#25509;&#23398;&#20064;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#36991;&#20813;&#20102;&#36793;&#32536;&#21270;&#25104;&#26412;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#29609;&#20855;&#20363;&#23376;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.07568</link><description>&lt;p&gt;
&#21464;&#20998;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Variational Prediction. (arXiv:2307.07568v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#21464;&#20998;&#39044;&#27979;&#36825;&#19968;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#30028;&#30452;&#25509;&#23398;&#20064;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#36991;&#20813;&#20102;&#36793;&#32536;&#21270;&#25104;&#26412;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#29609;&#20855;&#20363;&#23376;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#30456;&#27604;&#26368;&#22823;&#20284;&#28982;&#20855;&#26377;&#20248;&#21183;&#65292;&#20294;&#20063;&#20276;&#38543;&#30528;&#35745;&#31639;&#25104;&#26412;&#12290;&#35745;&#31639;&#21518;&#39564;&#36890;&#24120;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#65292;&#32780;&#23558;&#21518;&#39564;&#36793;&#32536;&#21270;&#24418;&#25104;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#20063;&#26159;&#22914;&#27492;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21464;&#20998;&#39044;&#27979;&#65292;&#19968;&#31181;&#20351;&#29992;&#21464;&#20998;&#30028;&#30452;&#25509;&#23398;&#20064;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#30340;&#25216;&#26415;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#27809;&#26377;&#27979;&#35797;&#26102;&#38388;&#36793;&#32536;&#21270;&#25104;&#26412;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#33391;&#22909;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#35828;&#26126;&#24615;&#30340;&#29609;&#20855;&#20363;&#23376;&#19978;&#28436;&#31034;&#20102;&#21464;&#20998;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference offers benefits over maximum likelihood, but it also comes with computational costs. Computing the posterior is typically intractable, as is marginalizing that posterior to form the posterior predictive distribution. In this paper, we present variational prediction, a technique for directly learning a variational approximation to the posterior predictive distribution using a variational bound. This approach can provide good predictive distributions without test time marginalization costs. We demonstrate Variational Prediction on an illustrative toy example.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;GP-UCB&#31639;&#27861;&#36827;&#34892;&#25913;&#36827;&#65292;&#20351;&#20854;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#24182;&#35299;&#20915;&#20102;&#20851;&#20110;&#36951;&#25022;&#20998;&#26512;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.07539</link><description>&lt;p&gt;
&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#25913;&#36827;&#33258;&#26631;&#20934;&#21270;&#27987;&#24230;&#65306;&#23545;GP-UCB&#31639;&#27861;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Improved Self-Normalized Concentration in Hilbert Spaces: Sublinear Regret for GP-UCB. (arXiv:2307.07539v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;GP-UCB&#31639;&#27861;&#36827;&#34892;&#25913;&#36827;&#65292;&#20351;&#20854;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#24182;&#35299;&#20915;&#20102;&#20851;&#20110;&#36951;&#25022;&#20998;&#26512;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26680;&#21270;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#22120;&#26088;&#22312;&#36890;&#36807;&#20165;&#22312;&#39034;&#24207;&#36873;&#25321;&#30340;&#28857;&#22788;&#36827;&#34892;&#22122;&#22768;&#35780;&#20272;&#65292;&#39034;&#24207;&#35745;&#31639;&#20301;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;&#29305;&#21035;&#22320;&#65292;&#23398;&#20064;&#22120;&#26088;&#22312;&#26368;&#23567;&#21270;&#36951;&#25022;&#65292;&#36951;&#25022;&#26159;&#25152;&#20570;&#36873;&#25321;&#30340;&#27425;&#20248;&#24615;&#24230;&#37327;&#12290;&#21487;&#20197;&#35828;&#26368;&#21463;&#27426;&#36814;&#30340;&#31639;&#27861;&#26159;&#39640;&#26031;&#36807;&#31243;&#19978;&#30028;&#32622;&#20449;&#21306;&#38388;&#65288;GP-UCB&#65289;&#31639;&#27861;&#65292;&#23427;&#28041;&#21450;&#26681;&#25454;&#26410;&#30693;&#20989;&#25968;&#30340;&#31616;&#21333;&#32447;&#24615;&#20272;&#35745;&#22120;&#36827;&#34892;&#34892;&#21160;&#12290;&#23613;&#31649;&#23427;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#29616;&#26377;&#30340;GP-UCB&#36951;&#25022;&#20998;&#26512;&#32473;&#20986;&#20102;&#27425;&#20248;&#36951;&#25022;&#29575;&#65292;&#23545;&#20110;&#35768;&#22810;&#24120;&#29992;&#30340;&#20869;&#26680;&#65288;&#22914;Mat&#233;rn&#20869;&#26680;&#65289;&#32780;&#35328;&#65292;&#36951;&#25022;&#29575;&#24182;&#19981;&#27425;&#32447;&#24615;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65306;&#29616;&#26377;&#30340;GP-UCB&#36951;&#25022;&#20998;&#26512;&#26159;&#21542;&#32039;&#23494;&#65292;&#25110;&#32773;&#26159;&#21542;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#26356;&#22797;&#26434;&#30340;&#20998;&#26512;&#25216;&#26415;&#25913;&#36827;&#30028;&#38480;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;GP-UCB&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#30452;&#25509;&#26263;&#31034;&#20102;&#27425;&#32447;&#24615;&#36951;&#25022;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the kernelized bandit problem, a learner aims to sequentially compute the optimum of a function lying in a reproducing kernel Hilbert space given only noisy evaluations at sequentially chosen points. In particular, the learner aims to minimize regret, which is a measure of the suboptimality of the choices made. Arguably the most popular algorithm is the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm, which involves acting based on a simple linear estimator of the unknown function. Despite its popularity, existing analyses of GP-UCB give a suboptimal regret rate, which fails to be sublinear for many commonly used kernels such as the Mat\'ern kernel. This has led to a longstanding open question: are existing regret analyses for GP-UCB tight, or can bounds be improved by using more sophisticated analytical techniques? In this work, we resolve this open question and show that GP-UCB enjoys nearly optimal regret. In particular, our results directly imply sublinear regret rate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Newell&#29702;&#35770;&#30340;&#29305;&#24449;&#36716;&#25442;&#26041;&#27861;&#29992;&#20110;&#26102;&#31354;&#20132;&#36890;&#39044;&#27979;&#65292;&#29992;&#20110;&#25913;&#21892;&#27169;&#22411;&#22312;&#19981;&#21516;&#20301;&#32622;&#30340;&#36801;&#31227;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.05949</link><description>&lt;p&gt;
&#22522;&#20110;Newell&#29702;&#35770;&#30340;&#29305;&#24449;&#36716;&#25442;&#29992;&#20110;&#26102;&#31354;&#20132;&#36890;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Newell's theory based feature transformations for spatio-temporal traffic prediction. (arXiv:2307.05949v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Newell&#29702;&#35770;&#30340;&#29305;&#24449;&#36716;&#25442;&#26041;&#27861;&#29992;&#20110;&#26102;&#31354;&#20132;&#36890;&#39044;&#27979;&#65292;&#29992;&#20110;&#25913;&#21892;&#27169;&#22411;&#22312;&#19981;&#21516;&#20301;&#32622;&#30340;&#36801;&#31227;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#26102;&#31354;&#20132;&#36890;&#27969;&#39044;&#27979;&#20013;&#20351;&#29992;&#21367;&#31215;&#25110;&#22270;&#21367;&#31215;&#36807;&#28388;&#22120;&#20197;&#21450;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26469;&#25429;&#25417;&#20132;&#36890;&#25968;&#25454;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#12290;&#36825;&#20123;&#27169;&#22411;, &#22914;CNN-LSTM, &#21033;&#29992;&#37051;&#36817;&#26816;&#27979;&#31449;&#30340;&#20132;&#36890;&#27969;&#26469;&#39044;&#27979;&#29305;&#23450;&#20301;&#32622;&#30340;&#27969;&#37327;&#12290;&#28982;&#32780;, &#36825;&#20123;&#27169;&#22411;&#22312;&#25429;&#25417;&#20132;&#36890;&#31995;&#32479;&#30340;&#26356;&#24191;&#27867;&#21160;&#24577;&#26041;&#38754;&#20855;&#26377;&#23616;&#38480;&#24615;, &#22240;&#20026;&#23427;&#20204;&#20027;&#35201;&#23398;&#20064;&#29305;&#23450;&#20110;&#26816;&#27979;&#37197;&#32622;&#21644;&#30446;&#26631;&#20301;&#32622;&#20132;&#36890;&#29305;&#24449;&#30340;&#29305;&#24449;&#12290;&#22240;&#27492;, &#24403;&#22312;&#26032;&#30340;&#20301;&#32622;&#32570;&#23569;&#29992;&#20110;&#27169;&#22411;&#35757;&#32451;&#30340;&#25968;&#25454;&#26102;, &#36825;&#20123;&#27169;&#22411;&#30340;&#21487;&#36801;&#31227;&#24615;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;, &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20132;&#36890;&#27969;&#29289;&#29702;&#23398;&#30340;&#29305;&#24449;&#36716;&#25442;&#26041;&#27861;&#29992;&#20110;&#26102;&#31354;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning (DL) models for spatio-temporal traffic flow forecasting employ convolutional or graph-convolutional filters along with recurrent neural networks to capture spatial and temporal dependencies in traffic data. These models, such as CNN-LSTM, utilize traffic flows from neighboring detector stations to predict flows at a specific location of interest. However, these models are limited in their ability to capture the broader dynamics of the traffic system, as they primarily learn features specific to the detector configuration and traffic characteristics at the target location. Hence, the transferability of these models to different locations becomes challenging, particularly when data is unavailable at the new location for model training. To address this limitation, we propose a traffic flow physics-based feature transformation for spatio-temporal DL models. This transformation incorporates Newell's uncongested and congested-state estimators of traffic flows at the target loc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28151;&#21512;&#38544;&#39532;&#23572;&#21487;&#22827;LSTM&#27169;&#22411;&#65292;&#29992;&#20110;&#30701;&#26399;&#20132;&#36890;&#27969;&#37327;&#39044;&#27979;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20132;&#36890;&#21464;&#37327;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#30340;&#21442;&#25968;&#27169;&#22411;&#12290;&#36825;&#31181;&#27169;&#22411;&#32467;&#21512;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#20248;&#21183;&#65292;&#33021;&#22815;&#25429;&#25417;&#20132;&#36890;&#31995;&#32479;&#30340;&#22797;&#26434;&#21160;&#24577;&#27169;&#24335;&#21644;&#38750;&#24179;&#31283;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.04954</link><description>&lt;p&gt;
&#28151;&#21512;&#38544;&#39532;&#23572;&#21487;&#22827;LSTM&#29992;&#20110;&#30701;&#26399;&#20132;&#36890;&#27969;&#37327;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Hybrid hidden Markov LSTM for short-term traffic flow prediction. (arXiv:2307.04954v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04954
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28151;&#21512;&#38544;&#39532;&#23572;&#21487;&#22827;LSTM&#27169;&#22411;&#65292;&#29992;&#20110;&#30701;&#26399;&#20132;&#36890;&#27969;&#37327;&#39044;&#27979;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20132;&#36890;&#21464;&#37327;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#30340;&#21442;&#25968;&#27169;&#22411;&#12290;&#36825;&#31181;&#27169;&#22411;&#32467;&#21512;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#20248;&#21183;&#65292;&#33021;&#22815;&#25429;&#25417;&#20132;&#36890;&#31995;&#32479;&#30340;&#22797;&#26434;&#21160;&#24577;&#27169;&#24335;&#21644;&#38750;&#24179;&#31283;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20132;&#36890;&#21464;&#37327;&#30340;&#30701;&#26399;&#21644;&#36817;&#30701;&#26399;&#26410;&#26469;&#26041;&#38754;&#24050;&#32463;&#20248;&#20110;&#21442;&#25968;&#27169;&#22411;&#65292;&#22914;&#21382;&#21490;&#24179;&#22343;&#12289;ARIMA&#21644;&#20854;&#21464;&#20307;&#65292;&#36825;&#23545;&#20110;&#20132;&#36890;&#31649;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21450;&#20854;&#21464;&#20307;&#65288;&#20363;&#22914;&#38271;&#30701;&#26399;&#35760;&#24518;&#65289;&#34987;&#35774;&#35745;&#29992;&#20110;&#20445;&#30041;&#38271;&#26399;&#26102;&#24207;&#30456;&#20851;&#24615;&#65292;&#22240;&#27492;&#38750;&#24120;&#36866;&#29992;&#20110;&#24314;&#27169;&#24207;&#21015;&#12290;&#28982;&#32780;&#65292;&#22810;&#21046;&#24230;&#27169;&#22411;&#20551;&#35774;&#20132;&#36890;&#31995;&#32479;&#20197;&#19981;&#21516;&#29305;&#24449;&#30340;&#22810;&#20010;&#29366;&#24577;&#65288;&#20363;&#22914;&#30021;&#36890;&#12289;&#25317;&#22581;&#65289;&#28436;&#21464;&#65292;&#22240;&#27492;&#38656;&#35201;&#35757;&#32451;&#19981;&#21516;&#27169;&#22411;&#20197;&#34920;&#24449;&#27599;&#20010;&#21046;&#24230;&#20869;&#30340;&#20132;&#36890;&#21160;&#24577;&#12290;&#20363;&#22914;&#65292;&#20351;&#29992;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#21046;&#24230;&#35782;&#21035;&#30340;&#39532;&#23572;&#21487;&#22827;&#20999;&#25442;&#27169;&#22411;&#33021;&#22815;&#25429;&#25417;&#22797;&#26434;&#30340;&#21160;&#24577;&#27169;&#24335;&#21644;&#38750;&#24179;&#31283;&#24615;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#21644;LSTM&#37117;&#21487;&#20197;&#29992;&#20110;&#24314;&#27169;&#20174;&#19968;&#32452;&#28508;&#22312;&#30340;&#25110;&#38544;&#34255;&#29366;&#24577;&#21464;&#37327;&#20013;&#30340;&#35266;&#23519;&#24207;&#21015;&#12290;&#22312;LSTM&#20013;&#65292;&#28508;&#22312;&#21464;&#37327;&#21487;&#20197;&#20174;&#19978;&#19968;&#20010;&#26102;&#38388;&#27493;&#30340;&#38544;&#34255;&#29366;&#24577;&#21464;&#37327;&#20256;&#36882;&#36807;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning (DL) methods have outperformed parametric models such as historical average, ARIMA and variants in predicting traffic variables into short and near-short future, that are critical for traffic management. Specifically, recurrent neural network (RNN) and its variants (e.g. long short-term memory) are designed to retain long-term temporal correlations and therefore are suitable for modeling sequences. However, multi-regime models assume the traffic system to evolve through multiple states (say, free-flow, congestion in traffic) with distinct characteristics, and hence, separate models are trained to characterize the traffic dynamics within each regime. For instance, Markov-switching models with a hidden Markov model (HMM) for regime identification is capable of capturing complex dynamic patterns and non-stationarity. Interestingly, both HMM and LSTM can be used for modeling an observation sequence from a set of latent or, hidden state variables. In LSTM, the latent variable 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;&#39640;&#26031;&#36807;&#31243;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#24314;&#31435;&#19968;&#20010;&#31283;&#20581;&#19988;&#26126;&#30830;&#30340;&#27169;&#22411;&#12290;&#36890;&#36807;&#23545;&#26680;&#20989;&#25968;&#35774;&#35745;&#21644;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#36873;&#39033;&#30340;&#25351;&#23548;&#65292;&#35813;&#26694;&#26550;&#22312;&#20912;&#24029;&#39640;&#31243;&#21464;&#21270;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#23454;&#29616;&#20102;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.03093</link><description>&lt;p&gt;
&#36229;&#36234;&#30452;&#35273;&#65292;&#23558;&#39640;&#26031;&#36807;&#31243;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Beyond Intuition, a Framework for Applying GPs to Real-World Data. (arXiv:2307.03093v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03093
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;&#39640;&#26031;&#36807;&#31243;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#24314;&#31435;&#19968;&#20010;&#31283;&#20581;&#19988;&#26126;&#30830;&#30340;&#27169;&#22411;&#12290;&#36890;&#36807;&#23545;&#26680;&#20989;&#25968;&#35774;&#35745;&#21644;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#36873;&#39033;&#30340;&#25351;&#23548;&#65292;&#35813;&#26694;&#26550;&#22312;&#20912;&#24029;&#39640;&#31243;&#21464;&#21270;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#23454;&#29616;&#20102;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#29992;&#20110;&#23567;&#22411;&#12289;&#32467;&#26500;&#21270;&#21644;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#22238;&#24402;&#30340;&#21560;&#24341;&#20154;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24212;&#29992;&#21463;&#21040;&#35745;&#31639;&#25104;&#26412;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#23545;&#20110;&#22914;&#20309;&#23558;GPs&#24212;&#29992;&#20110;&#22797;&#26434;&#30340;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#25351;&#23548;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;GPs&#22312;&#32473;&#23450;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#20197;&#21450;&#22914;&#20309;&#24314;&#31435;&#19968;&#20010;&#24378;&#22823;&#19988;&#26126;&#30830;&#30340;GP&#27169;&#22411;&#12290;&#25351;&#23548;&#26041;&#38024;&#24418;&#24335;&#21270;&#20102;&#32463;&#39564;&#20016;&#23500;&#30340;GP&#23454;&#36341;&#32773;&#30340;&#20915;&#31574;&#65292;&#29305;&#21035;&#24378;&#35843;&#20102;&#26680;&#20989;&#25968;&#35774;&#35745;&#21644;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#36873;&#39033;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#20912;&#24029;&#39640;&#31243;&#21464;&#21270;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#22312;&#27979;&#35797;&#26102;&#20135;&#29983;&#20102;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian Processes (GPs) offer an attractive method for regression over small, structured and correlated datasets. However, their deployment is hindered by computational costs and limited guidelines on how to apply GPs beyond simple low-dimensional datasets. We propose a framework to identify the suitability of GPs to a given problem and how to set up a robust and well-specified GP model. The guidelines formalise the decisions of experienced GP practitioners, with an emphasis on kernel design and options for computational scalability. The framework is then applied to a case study of glacier elevation change yielding more accurate results at test time.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#36951;&#25022;&#30340;&#24230;&#37327;&#65292;&#20197;&#34913;&#37327;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#35813;&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#38797;&#28857;&#20248;&#21270;&#31639;&#27861;&#65292;&#21363;&#20351;&#22312;&#27809;&#26377;&#26377;&#24847;&#20041;&#30340;&#26354;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#33021;&#22815;&#22312;&#26080;&#30028;&#39046;&#22495;&#20013;&#25910;&#25947;&#20110;&#23545;&#20598;&#38388;&#38553;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#38750;&#24179;&#20961;&#30340;&#21160;&#24577;&#36951;&#25022;&#65292;&#20197;&#21450;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.04923</link><description>&lt;p&gt;
&#26080;&#32422;&#26463;&#22312;&#32447;&#23398;&#20064;&#21644;&#26080;&#30028;&#25439;&#22833;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unconstrained Online Learning with Unbounded Losses. (arXiv:2306.04923v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04923
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#36951;&#25022;&#30340;&#24230;&#37327;&#65292;&#20197;&#34913;&#37327;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#35813;&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#38797;&#28857;&#20248;&#21270;&#31639;&#27861;&#65292;&#21363;&#20351;&#22312;&#27809;&#26377;&#26377;&#24847;&#20041;&#30340;&#26354;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#33021;&#22815;&#22312;&#26080;&#30028;&#39046;&#22495;&#20013;&#25910;&#25947;&#20110;&#23545;&#20598;&#38388;&#38553;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#38750;&#24179;&#20961;&#30340;&#21160;&#24577;&#36951;&#25022;&#65292;&#20197;&#21450;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#38656;&#35201;&#19968;&#20010;&#25110;&#22810;&#20010;&#26377;&#30028;&#24615;&#20551;&#35774;&#65306;&#21363;&#22495;&#26159;&#26377;&#30028;&#30340;&#65292;&#25439;&#22833;&#26159;Lipschitz&#30340;&#25110;&#20004;&#32773;&#37117;&#26377;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#20855;&#26377;&#26080;&#30028;&#22495;&#21644;&#38750;Lipschitz&#25439;&#22833;&#30340;&#22312;&#32447;&#23398;&#20064;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#35774;&#32622;&#12290;&#38024;&#23545;&#35813;&#22330;&#26223;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#22312;&#20219;&#20309;&#28385;&#36275;&#23376;&#26799;&#24230;&#28385;&#36275;$\|g_{t}\|\le G+L\|w_{t}\|$&#30340;&#38382;&#39064;&#20013;&#65292;&#20854;&#36951;&#25022;&#30340;&#24230;&#37327;&#20540;$R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$&#65292;&#24182;&#19988;&#34920;&#26126;&#38500;&#38750;&#26377;&#36827;&#19968;&#27493; &#20551;&#35774;&#65292;&#21542;&#21017;&#35813;&#30028;&#38480;&#26159;&#19981;&#33021;&#36827;&#19968;&#27493;&#25913;&#36827;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms for online learning typically require one or more boundedness assumptions: that the domain is bounded, that the losses are Lipschitz, or both. In this paper, we develop a new setting for online learning with unbounded domains and non-Lipschitz losses. For this setting we provide an algorithm which guarantees $R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$ regret on any problem where the subgradients satisfy $\|g_{t}\|\le G+L\|w_{t}\|$, and show that this bound is unimprovable without further assumptions. We leverage this algorithm to develop new saddle-point optimization algorithms that converge in duality gap in unbounded domains, even in the absence of meaningful curvature. Finally, we provide the first algorithm achieving non-trivial dynamic regret in an unbounded domain for non-Lipschitz losses, as well as a matching lower bound. The regret of our dynamic regret algorithm automatically improves to a novel $L^{*}$ bound when the losses are smooth.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#26144;&#23556;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#25968;&#25454;&#65292;&#24182;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.19779</link><description>&lt;p&gt;
&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#20197;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#65306;&#20197;&#32943;&#23612;&#20122;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya. (arXiv:2305.19779v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#26144;&#23556;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#25968;&#25454;&#65292;&#24182;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#30142;&#30149;&#26144;&#23556;&#26159;&#20844;&#20849;&#21355;&#29983;&#21644;&#30142;&#30149;&#30417;&#27979;&#20013;&#22522;&#26412;&#30340;&#25919;&#31574;&#20449;&#24687;&#24037;&#20855;&#65292;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#26159;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#24403;&#22788;&#29702;&#21306;&#22495;&#25968;&#25454;&#65292;&#22914;&#34892;&#25919;&#21306;&#21010;&#21333;&#20301;&#65288;&#20363;&#22914;&#21439;&#25110;&#30465;&#65289;&#30340;&#32858;&#21512;&#25968;&#25454;&#26102;&#65292;&#24120;&#29992;&#30340;&#27169;&#22411;&#20381;&#36182;&#20110;&#21306;&#22495;&#21333;&#20803;&#30340;&#30456;&#37051;&#32467;&#26500;&#20197;&#32771;&#34385;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#30142;&#30149;&#30417;&#27979;&#31995;&#32479;&#30340;&#30446;&#26631;&#26159;&#38543;&#26102;&#38388;&#36319;&#36394;&#30142;&#30149;&#32467;&#26524;&#65292;&#20294;&#22312;&#21361;&#26426;&#24773;&#20917;&#19979;&#65288;&#20363;&#22914;&#25919;&#27835;&#21464;&#21270;&#23548;&#33268;&#34892;&#25919;&#36793;&#30028;&#26356;&#25913;&#65289;&#65292;&#36825;&#23558;&#24102;&#26469;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#12289;&#23454;&#29992;&#21644;&#26131;&#20110;&#23454;&#26045;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#20381;&#36182;&#20110;&#32452;&#21512;&#28145;&#23618;&#29983;&#25104;&#27169;&#22411;&#21644;&#20840;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#25105;&#20204;&#24314;&#31435;&#22312;&#29616;&#26377;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAE) &#24037;&#20316;&#19978;&#65292;&#24182;&#23637;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#32858;&#21512;VAE(aggVAE)&#20307;&#31995;&#32467;&#26500;&#21487;&#29992;&#20110;&#22312;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#22788;&#29702;&#25968;&#25454;&#65292;&#20197;&#26144;&#23556;&#32943;&#23612;&#20122;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#20197;&#36830;&#32493;&#30340;&#26041;&#24335;&#32771;&#34385;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#30456;&#37051;&#24615;&#20551;&#35774;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#20934;&#30830;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based disease mapping remains a fundamental policy-informing tool in public health and disease surveillance with hierarchical Bayesian models being the current state-of-the-art approach. When working with areal data, e.g. aggregates at the administrative unit level such as district or province, routinely used models rely on the adjacency structure of areal units to account for spatial correlations. The goal of disease surveillance systems is to track disease outcomes over time, but this provides challenging in situations of crises, such as political changes, leading to changes of administrative boundaries. Kenya is an example of such country. Moreover, adjacency-based approach ignores the continuous nature of spatial processes and cannot solve the change-of-support problem, i.e. when administrative boundaries change. We present a novel, practical, and easy to implement solution relying on a methodology combining deep generative modelling and fully Bayesian inference. We build on 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#19988;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.14442</link><description>&lt;p&gt;
&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Optimal Preconditioning and Fisher Adaptive Langevin Sampling. (arXiv:2305.14442v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14442
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#19988;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#26368;&#22823;&#21270;&#39044;&#26399;&#24179;&#26041;&#36339;&#36291;&#36317;&#31163;&#65292;&#20026; Langevin &#25193;&#25955;&#23450;&#20041;&#20102;&#26368;&#20248;&#39044;&#26465;&#20214;&#12290;&#36825;&#23548;&#33268;&#26368;&#20248;&#39044;&#26465;&#20214;&#20026;&#21453;&#36153;&#33293;&#23572;&#20449;&#24687;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#20854;&#20013;&#21327;&#26041;&#24046;&#30697;&#38453;&#26159;&#22312;&#30446;&#26631;&#19979;&#24179;&#22343;&#23545;&#25968;&#30446;&#26631;&#26799;&#24230;&#30340;&#22806;&#31215;&#12290;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#24212;&#29992;&#20110; Metropolis &#35843;&#25972; Langevin &#31639;&#27861; (MALA)&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#31181;&#20174;&#31639;&#27861;&#36816;&#34892;&#20135;&#29983;&#30340;&#26799;&#24230;&#21382;&#21490;&#20013;&#23398;&#20064;&#39044;&#26465;&#20214;&#30340;&#35745;&#31639;&#26377;&#25928;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#65292;&#24182;&#19988;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#21253;&#25324;&#20351;&#29992;&#26631;&#20934;&#33258;&#36866;&#24212; MCMC &#23398;&#20064;&#39044;&#26465;&#20214;&#21644;&#20301;&#32622;&#30456;&#20851;&#30340; Riemann &#27969;&#24418; MALA &#37319;&#26679;&#22120;&#30340;&#23494;&#20999;&#30456;&#20851;&#30340;&#33258;&#36866;&#24212; MALA &#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We define an optimal preconditioning for the Langevin diffusion by analytically maximizing the expected squared jumped distance. This yields as the optimal preconditioning an inverse Fisher information covariance matrix, where the covariance matrix is computed as the outer product of log target gradients averaged under the target. We apply this result to the Metropolis adjusted Langevin algorithm (MALA) and derive a computationally efficient adaptive MCMC scheme that learns the preconditioning from the history of gradients produced as the algorithm runs. We show in several experiments that the proposed algorithm is very robust in high dimensions and significantly outperforms other methods, including a closely related adaptive MALA scheme that learns the preconditioning with standard adaptive MCMC as well as the position-dependent Riemannian manifold MALA sampler.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#37327;&#33258;&#36866;&#24212;&#21160;&#24577;&#26089;&#26399;&#36864;&#20986;&#26426;&#21046;&#65292;&#36890;&#36807;&#33021;&#37327;&#24863;&#30693;&#30340;&#31574;&#30053;&#65292;&#22312;EH&#36793;&#32536;&#35774;&#22791;&#20013;&#23454;&#29616;&#20102;&#39640;&#25928;&#20934;&#30830;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2305.14094</link><description>&lt;p&gt;
&#36890;&#36807;&#33021;&#37327;&#24863;&#30693;&#30340;&#26089;&#26399;&#36864;&#20986;&#23454;&#29616;&#21487;&#25345;&#32493;&#30340;&#36793;&#32536;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
Sustainable Edge Intelligence Through Energy-Aware Early Exiting. (arXiv:2305.14094v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#37327;&#33258;&#36866;&#24212;&#21160;&#24577;&#26089;&#26399;&#36864;&#20986;&#26426;&#21046;&#65292;&#36890;&#36807;&#33021;&#37327;&#24863;&#30693;&#30340;&#31574;&#30053;&#65292;&#22312;EH&#36793;&#32536;&#35774;&#22791;&#20013;&#23454;&#29616;&#20102;&#39640;&#25928;&#20934;&#30830;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#24050;&#25104;&#20026;&#29289;&#32852;&#32593;&#24212;&#29992;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#28040;&#32791;&#22823;&#37327;&#33021;&#37327;&#65292;&#36825;&#21487;&#33021;&#20250;&#24555;&#36895;&#32791;&#23613;&#30005;&#27744;&#24182;&#24433;&#21709;&#29289;&#32852;&#32593;&#35774;&#22791;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#23454;&#29616;&#21487;&#25345;&#32493;&#36816;&#34892;&#65292;&#26412;&#25991;&#32771;&#34385;&#19968;&#20010;&#24102;&#26377;&#21487;&#20805;&#30005;&#30005;&#27744;&#21644;&#33021;&#37327;&#25910;&#33719;&#33021;&#21147;&#30340;&#36793;&#32536;&#35774;&#22791;&#12290;&#38500;&#20102;&#29615;&#22659;&#33021;&#28304;&#30340;&#38543;&#26426;&#24615;&#22806;&#65292;&#25910;&#33719;&#36895;&#29575;&#36890;&#24120;&#19981;&#36275;&#20197;&#28385;&#36275;&#25512;&#29702;&#33021;&#28304;&#38656;&#27714;&#65292;&#22312;&#33021;&#28304;&#19981;&#21487;&#30693;&#30340;&#35774;&#22791;&#20013;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#24615;&#33021;&#38477;&#20302;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33021;&#37327;&#33258;&#36866;&#24212;&#21160;&#24577;&#26089;&#26399;&#36864;&#20986;&#26426;&#21046;&#65292;&#20197;&#23454;&#29616;&#22312;&#20805;&#28385;&#29615;&#22659;&#33021;&#28304;&#24773;&#20917;&#19979;&#30340;&#39640;&#25928;&#20934;&#30830;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning (DL) models have emerged as a promising solution for Internet of Things (IoT) applications. However, due to their computational complexity, DL models consume significant amounts of energy, which can rapidly drain the battery and compromise the performance of IoT devices. For sustainable operation, we consider an edge device with a rechargeable battery and energy harvesting (EH) capabilities. In addition to the stochastic nature of the ambient energy source, the harvesting rate is often insufficient to meet the inference energy requirements, leading to drastic performance degradation in energy-agnostic devices. To mitigate this problem, we propose energy-adaptive dynamic early exiting (EE) to enable efficient and accurate inference in an EH edge intelligence system. Our approach derives an energy-aware EE policy that determines the optimal amount of computational processing on a per-sample basis. The proposed policy balances the energy consumption to match the limited inco
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#27604;&#20363;&#28176;&#36817;&#24773;&#24418;&#19979;&#30340;&#23376;&#37319;&#26679;&#23725;&#22238;&#24402;&#38598;&#25104;&#65292;&#35777;&#26126;&#20102;&#26368;&#20248;&#20840;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#39118;&#38505;&#19982;&#26368;&#20248;&#23725;&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#30456;&#21305;&#37197;&#65292;&#24182;&#35777;&#26126;&#20102;GCV&#22312;&#20272;&#35745;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#26041;&#38754;&#30340;&#24378;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13016</link><description>&lt;p&gt;
&#23376;&#37319;&#26679;&#23725;&#22238;&#24402;&#38598;&#25104;&#65306;&#31561;&#25928;&#24615;&#21644;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Subsample Ridge Ensembles: Equivalences and Generalized Cross-Validation. (arXiv:2304.13016v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13016
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#27604;&#20363;&#28176;&#36817;&#24773;&#24418;&#19979;&#30340;&#23376;&#37319;&#26679;&#23725;&#22238;&#24402;&#38598;&#25104;&#65292;&#35777;&#26126;&#20102;&#26368;&#20248;&#20840;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#39118;&#38505;&#19982;&#26368;&#20248;&#23725;&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#30456;&#21305;&#37197;&#65292;&#24182;&#35777;&#26126;&#20102;GCV&#22312;&#20272;&#35745;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#26041;&#38754;&#30340;&#24378;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27604;&#20363;&#28176;&#36817;&#24773;&#24418;&#19979;&#30340;&#23376;&#37319;&#26679;&#23725;&#22238;&#24402;&#38598;&#25104;&#65292;&#20854;&#20013;&#29305;&#24449;&#22823;&#23567;&#19982;&#26679;&#26412;&#22823;&#23567;&#25104;&#27604;&#20363;&#22686;&#38271;&#65292;&#20351;&#24471;&#23427;&#20204;&#30340;&#27604;&#29575;&#25910;&#25947;&#21040;&#19968;&#20010;&#24120;&#25968;&#12290;&#36890;&#36807;&#20998;&#26512;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#24179;&#26041;&#39044;&#27979;&#39118;&#38505;&#20316;&#20026;&#26174;&#24335;&#24809;&#32602;$\lambda$&#21644;&#26497;&#38480;&#23376;&#26679;&#26412;&#26041;&#38754;&#27604;$\phi_s$&#65288;&#29305;&#24449;&#22823;&#23567;&#19982;&#23376;&#26679;&#26412;&#22823;&#23567;&#30340;&#27604;&#29575;&#65289;&#30340;&#20989;&#25968;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#22312;&#20219;&#20309;&#21487;&#36798;&#39118;&#38505;&#19979;&#30340;$(\lambda, \phi_s)$-&#24179;&#38754;&#19978;&#30340;&#36718;&#24275;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35777;&#26126;&#26368;&#20248;&#20840;&#23725;&#22238;&#24402;&#38598;&#25104;&#65288;&#36866;&#21512;&#20110;&#25152;&#26377;&#21487;&#33021;&#30340;&#23376;&#26679;&#26412;&#65289;&#30340;&#39118;&#38505;&#19982;&#26368;&#20248;&#23725;&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#23545;&#20110;&#20272;&#35745;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#65292;&#22522;&#20110;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#30340;&#23376;&#26679;&#26412;&#22823;&#23567;&#24378;&#19968;&#33268;&#24615;&#12290;&#36825;&#20801;&#35768;&#26080;&#38656;&#26679;&#26412;&#25286;&#20998;&#22522;&#20110;GCV&#20248;&#21270;&#20840;&#23616;&#23725;&#22238;&#24402;&#38598;&#25104;&#65292;&#24182;&#20135;&#29983;&#19968;&#20010;&#39118;&#38505;&#19982;&#26368;&#20248;&#23725;&#22238;&#24402;&#39118;&#38505;&#30456;&#21305;&#37197;&#30340;&#39044;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study subsampling-based ridge ensembles in the proportional asymptotics regime, where the feature size grows proportionally with the sample size such that their ratio converges to a constant. By analyzing the squared prediction risk of ridge ensembles as a function of the explicit penalty $\lambda$ and the limiting subsample aspect ratio $\phi_s$ (the ratio of the feature size to the subsample size), we characterize contours in the $(\lambda, \phi_s)$-plane at any achievable risk. As a consequence, we prove that the risk of the optimal full ridgeless ensemble (fitted on all possible subsamples) matches that of the optimal ridge predictor. In addition, we prove strong uniform consistency of generalized cross-validation (GCV) over the subsample sizes for estimating the prediction risk of ridge ensembles. This allows for GCV-based tuning of full ridgeless ensembles without sample splitting and yields a predictor whose risk matches optimal ridge risk.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2303.17765</link><description>&lt;p&gt;
&#23398;&#20064;&#30456;&#20284;&#30340;&#32447;&#24615;&#34920;&#31034;&#65306;&#36866;&#24212;&#24615;&#12289;&#26497;&#23567;&#21270;&#12289;&#20197;&#21450;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness. (arXiv:2303.17765v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#28982;&#32780;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#27424;&#32570;&#12290;&#26412;&#25991;&#26088;&#22312;&#29702;&#35299;&#20174;&#20855;&#26377;&#30456;&#20284;&#20294;&#24182;&#38750;&#23436;&#20840;&#30456;&#21516;&#30340;&#32447;&#24615;&#34920;&#31034;&#30340;&#20219;&#21153;&#20013;&#23398;&#20064;&#65292;&#21516;&#26102;&#22788;&#29702;&#24322;&#24120;&#20540;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21333;&#20219;&#21153;&#25110;&#20165;&#30446;&#26631;&#23398;&#20064;&#26102;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \textit{adaptive} to the similarity structure and \textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26356;&#39640;&#25928;&#30340;&#25209;&#37327;&#26356;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20803;&#26641;&#19978;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2303.09705</link><description>&lt;p&gt;
&#22312;&#20803;&#26641;&#19978;&#25209;&#37327;&#26356;&#26032;&#21518;&#39564;&#26641;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Batch Updating of a Posterior Tree Distribution over a Meta-Tree. (arXiv:2303.09705v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26356;&#39640;&#25928;&#30340;&#25209;&#37327;&#26356;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20803;&#26641;&#19978;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#21069;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#30001;&#19981;&#21487;&#35266;&#23519;&#30340;&#26641;&#21644;&#19968;&#20010;&#24207;&#21015;&#26356;&#26032;&#26041;&#27861;&#34920;&#31034;&#30340;&#27010;&#29575;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#35745;&#31639;&#19968;&#32452;&#26641;&#19978;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#38598;&#21512;&#31216;&#20026;&#20803;&#26641;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#25209;&#37327;&#26356;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previously, we proposed a probabilistic data generation model represented by an unobservable tree and a sequential updating method to calculate a posterior distribution over a set of trees. The set is called a meta-tree. In this paper, we propose a more efficient batch updating method.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;SSBM&#65292;&#23427;&#21482;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#25506;&#32034;&#20102;&#20174;&#19981;&#23436;&#25972;&#30340;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#12290;&#36825;&#20026;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#24674;&#22797;&#20449;&#21495;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;SSBM&#30340;&#21331;&#36234;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.08691</link><description>&lt;p&gt;
&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#23398;&#20064;&#20449;&#21495;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Learning to Reconstruct Signals From Binary Measurements. (arXiv:2303.08691v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08691
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;SSBM&#65292;&#23427;&#21482;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#25506;&#32034;&#20102;&#20174;&#19981;&#23436;&#25972;&#30340;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#12290;&#36825;&#20026;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#24674;&#22797;&#20449;&#21495;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;SSBM&#30340;&#21331;&#36234;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#31361;&#20986;&#20102;&#20165;&#20174;&#22122;&#22768;&#21644;&#19981;&#23436;&#25972;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#23398;&#20064;&#20449;&#21495;&#37325;&#26500;&#30340;&#21487;&#33021;&#24615;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21307;&#23398;&#21644;&#31185;&#23398;&#25104;&#20687;&#20197;&#21450;&#20256;&#24863;&#20013;&#36215;&#21040;&#20851;&#38190;&#20316;&#29992;&#65292;&#20854;&#20013;&#22320;&#38754;&#30495;&#23454;&#25968;&#25454;&#32463;&#24120;&#31232;&#32570;&#25110;&#38590;&#20197;&#33719;&#24471;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#27979;&#37327;&#19981;&#20165;&#22122;&#22768;&#21644;&#19981;&#23436;&#25972;&#65292;&#32780;&#19988;&#36824;&#34987;&#37327;&#21270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25506;&#32034;&#20174;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#20174;&#19981;&#23436;&#25972;&#20108;&#36827;&#21046;&#25968;&#25454;&#20013;&#35782;&#21035;&#19968;&#32452;&#20449;&#21495;&#25152;&#38656;&#30340;&#27979;&#37327;&#25968;&#37327;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#23545;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#20449;&#21495;&#24674;&#22797;&#29616;&#26377;&#30028;&#38480;&#30340;&#34917;&#20805;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;&#8220;SSBM&#8221;&#65292;&#23427;&#20165;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;SSBM&#19982;&#30417;&#30563;&#23398;&#20064;&#30456;&#24403;&#65292;&#24182;&#20248;&#20110;&#31232;&#30095;&#37325;&#26500;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in unsupervised learning have highlighted the possibility of learning to reconstruct signals from noisy and incomplete linear measurements alone. These methods play a key role in medical and scientific imaging and sensing, where ground truth data is often scarce or difficult to obtain. However, in practice, measurements are not only noisy and incomplete but also quantized. Here we explore the extreme case of learning from binary observations and provide necessary and sufficient conditions on the number of measurements required for identifying a set of signals from incomplete binary data. Our results are complementary to existing bounds on signal recovery from binary measurements. Furthermore, we introduce a novel self-supervised learning approach, which we name SSBM, that only requires binary data for training. We demonstrate in a series of experiments with real datasets that SSBM performs on par with supervised learning and outperforms sparse reconstruction methods wit
&lt;/p&gt;</description></item><item><title>&#21464;&#35843;&#31070;&#32463;ODEs &#65288;MoNODEs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#21160;&#21147;&#23398;&#29366;&#24577;&#19982;&#22522;&#30784;&#38745;&#24577;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#65292;&#24182;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#31070;&#32463;ODE&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#19981;&#21464;&#30340;&#35843;&#21046;&#21464;&#37327;&#26469;&#25429;&#25417;&#36712;&#36857;&#38388;&#30340;&#21464;&#21270;&#65292;&#24182;&#22312;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#22312;&#25391;&#33633;&#31995;&#32479;&#12289;&#35270;&#39057;&#21644;&#20154;&#31867;&#34892;&#36208;&#36712;&#36857;&#31561;&#26041;&#38754;&#20855;&#26377;&#25552;&#39640;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.13262</link><description>&lt;p&gt;
&#21464;&#35843;&#31070;&#32463;ODEs
&lt;/p&gt;
&lt;p&gt;
Modulated Neural ODEs. (arXiv:2302.13262v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13262
&lt;/p&gt;
&lt;p&gt;
&#21464;&#35843;&#31070;&#32463;ODEs &#65288;MoNODEs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#21160;&#21147;&#23398;&#29366;&#24577;&#19982;&#22522;&#30784;&#38745;&#24577;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#65292;&#24182;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#31070;&#32463;ODE&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#19981;&#21464;&#30340;&#35843;&#21046;&#21464;&#37327;&#26469;&#25429;&#25417;&#36712;&#36857;&#38388;&#30340;&#21464;&#21270;&#65292;&#24182;&#22312;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#22312;&#25391;&#33633;&#31995;&#32479;&#12289;&#35270;&#39057;&#21644;&#20154;&#31867;&#34892;&#36208;&#36712;&#36857;&#31561;&#26041;&#38754;&#20855;&#26377;&#25552;&#39640;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;NODEs&#65289;&#24050;&#34987;&#35777;&#26126;&#23545;&#20110;&#23398;&#20064;&#20219;&#24847;&#36712;&#36857;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#24456;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;NODE&#26041;&#27861;&#20165;&#36890;&#36807;&#21021;&#22987;&#29366;&#24577;&#20540;&#25110;&#33258;&#22238;&#24402;&#32534;&#30721;&#22120;&#26356;&#26032;&#26469;&#25429;&#25417;&#36712;&#36857;&#38388;&#30340;&#21464;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21464;&#35843;&#31070;&#32463;ODEs&#65288;MoNODEs&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#23558;&#21160;&#21147;&#23398;&#29366;&#24577;&#19982;&#22522;&#30784;&#38745;&#24577;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#24182;&#25913;&#36827;&#29616;&#26377;NODE&#26041;&#27861;&#30340;&#26032;&#26694;&#26550;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#8220;&#26102;&#38388;&#19981;&#21464;&#35843;&#21046;&#21464;&#37327;&#8221;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#32467;&#21512;&#21040;&#22235;&#31181;&#29616;&#26377;&#30340;NODE&#21464;&#20307;&#20013;&#12290;&#25105;&#20204;&#22312;&#25391;&#33633;&#31995;&#32479;&#12289;&#35270;&#39057;&#21644;&#20154;&#31867;&#34892;&#36208;&#36712;&#36857;&#19978;&#23545;MoNODE&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#20854;&#20013;&#27599;&#20010;&#36712;&#36857;&#37117;&#20855;&#26377;&#36712;&#36857;&#29305;&#23450;&#30340;&#35843;&#21046;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22987;&#32456;&#25552;&#39640;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20351;&#20854;&#33021;&#22815;&#36866;&#24212;&#26032;&#30340;&#21160;&#24577;&#21442;&#25968;&#21270;&#24182;&#36827;&#34892;&#36828;&#26399;&#39044;&#27979;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25552;&#20986;&#30340;&#35843;&#21046;&#21464;&#37327;&#30340;&#20449;&#24687;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural ordinary differential equations (NODEs) have been proven useful for learning non-linear dynamics of arbitrary trajectories. However, current NODE methods capture variations across trajectories only via the initial state value or by auto-regressive encoder updates. In this work, we introduce Modulated Neural ODEs (MoNODEs), a novel framework that sets apart dynamics states from underlying static factors of variation and improves the existing NODE methods. In particular, we introduce $\textit{time-invariant modulator variables}$ that are learned from the data. We incorporate our proposed framework into four existing NODE variants. We test MoNODE on oscillating systems, videos and human walking trajectories, where each trajectory has trajectory-specific modulation. Our framework consistently improves the existing model ability to generalize to new dynamic parameterizations and to perform far-horizon forecasting. In addition, we verify that the proposed modulator variables are infor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#22312;&#20449;&#21495;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#38750;&#38543;&#26426;&#26799;&#24230;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#32479;&#19968;&#29616;&#26377;&#30340;SA&#29702;&#35770;&#65292;&#21253;&#25324;&#38750;&#28176;&#36817;&#21644;&#28176;&#36817;&#25910;&#25947;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.11147</link><description>&lt;p&gt;
&#20449;&#21495;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#36229;&#36234;&#26799;&#24230;&#30340;&#38543;&#26426;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Stochastic Approximation Beyond Gradient for Signal Processing and Machine Learning. (arXiv:2302.11147v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11147
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#22312;&#20449;&#21495;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#38750;&#38543;&#26426;&#26799;&#24230;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#32479;&#19968;&#29616;&#26377;&#30340;SA&#29702;&#35770;&#65292;&#21253;&#25324;&#38750;&#28176;&#36817;&#21644;&#28176;&#36817;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#26159;&#19968;&#20010;&#32463;&#20856;&#30340;&#31639;&#27861;&#65292;&#22312;&#20449;&#21495;&#22788;&#29702;&#26041;&#38754;&#20174;&#26089;&#26399;&#23601;&#20135;&#29983;&#20102;&#24040;&#22823;&#30340;&#24433;&#21709;&#65292;&#29616;&#22312;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20063;&#22240;&#22788;&#29702;&#22823;&#37327;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#32780;&#21464;&#24471;&#37325;&#35201;&#12290;&#19968;&#20010;&#20856;&#22411;&#30340;SA&#29305;&#20363;&#26159;&#27969;&#34892;&#30340;&#38543;&#26426;&#65288;&#23376;&#65289;&#26799;&#24230;&#31639;&#27861;&#65292;&#23427;&#26159;&#35768;&#22810;&#37325;&#35201;&#24212;&#29992;&#30340;&#20851;&#38190;&#12290;&#19968;&#20010;&#36739;&#23569;&#20154;&#30693;&#36947;&#30340;&#20107;&#23454;&#26159;&#65292;SA&#26041;&#26696;&#20063;&#36866;&#29992;&#20110;&#38750;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#65292;&#22914;&#21387;&#32553;&#38543;&#26426;&#26799;&#24230;&#12289;&#38543;&#26426;&#26399;&#26395;&#26368;&#22823;&#21270;&#21644;&#19968;&#20123;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#26412;&#25991;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#25552;&#20379;&#25903;&#25345;&#29702;&#35770;&#30340;SA&#31639;&#27861;&#35774;&#35745;&#25351;&#21335;&#65292;&#27010;&#36848;&#21644;&#20171;&#32461;SA&#30340;&#38750;&#38543;&#26426;&#26799;&#24230;&#35270;&#35282;&#65292;&#20197;&#20415;&#21560;&#24341;&#20449;&#21495;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#32773;&#30340;&#27880;&#24847;&#12290;&#25105;&#20204;&#30340;&#26680;&#24515;&#20027;&#39064;&#26159;&#25552;&#20986;&#19968;&#20010;&#32479;&#19968;&#29616;&#26377;SA&#29702;&#35770;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21253;&#25324;&#20854;&#38750;&#28176;&#36817;&#21644;&#28176;&#36817;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Approximation (SA) is a classical algorithm that has had since the early days a huge impact on signal processing, and nowadays on machine learning, due to the necessity to deal with a large amount of data observed with uncertainties. An exemplar special case of SA pertains to the popular stochastic (sub)gradient algorithm which is the working horse behind many important applications. A lesser-known fact is that the SA scheme also extends to non-stochastic-gradient algorithms such as compressed stochastic gradient, stochastic expectation-maximization, and a number of reinforcement learning algorithms. The aim of this article is to overview and introduce the non-stochastic-gradient perspectives of SA to the signal processing and machine learning audiences through presenting a design guideline of SA algorithms backed by theories. Our central theme is to propose a general framework that unifies existing theories of SA, including its non-asymptotic and asymptotic convergence resu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30001;&#24418;&#24335;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;GPSSMs&#65289;&#12290;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20197;&#21069;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#25512;&#26029;&#20934;&#30830;&#24615;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2302.09921</link><description>&lt;p&gt;
&#33258;&#30001;&#24418;&#24335;&#30340;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Free-Form Variational Inference for Gaussian Process State-Space Models. (arXiv:2302.09921v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09921
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30001;&#24418;&#24335;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;GPSSMs&#65289;&#12290;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20197;&#21069;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#25512;&#26029;&#20934;&#30830;&#24615;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;GPSSMs&#65289;&#20026;&#24314;&#27169;&#28508;&#22312;&#29366;&#24577;&#30340;&#21160;&#24577;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21407;&#21017;&#21644;&#28789;&#27963;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20284;&#28982;&#27169;&#22411;&#20197;&#31163;&#25955;&#26102;&#38388;&#28857;&#35266;&#27979;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#27169;&#22411;&#20013;&#28508;&#22312;&#21464;&#37327;&#30340;&#25968;&#37327;&#36739;&#22823;&#19988;&#23427;&#20204;&#20043;&#38388;&#23384;&#22312;&#24378;&#26102;&#24207;&#20381;&#36182;&#24615;&#65292;&#22240;&#27492;&#22312; GPSSMs &#20013;&#36827;&#34892;&#25512;&#26029;&#26159;&#35745;&#31639;&#19978;&#21644;&#32479;&#35745;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031; GPSSMs &#20013;&#36827;&#34892;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#20811;&#26381;&#20102;&#20197;&#21069;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#21363;&#36807;&#20110;&#31616;&#21270;&#30340;&#20551;&#35774;&#21644;&#39640;&#35745;&#31639;&#35201;&#27714;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22312;&#35825;&#23548;&#21464;&#37327;&#24418;&#24335;&#20027;&#20041;&#20869;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#32599;&#36827;&#34892;&#33258;&#30001;&#24418;&#24335;&#30340;&#21464;&#20998;&#25512;&#26029;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#21033;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;&#21464;&#20998;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#25240;&#21472;&#25193;&#23637;&#26041;&#27861;&#65292;&#20854;&#20013;&#35825;&#23548;&#21464;&#37327;&#22312;&#35299;&#26512;&#19978;&#36827;&#34892;&#36793;&#38469;&#21270;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#19982;&#31890;&#23376; MCMC &#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;s&#19978;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#25512;&#26029;&#20934;&#30830;&#24615;&#19978;&#37117;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process state-space models (GPSSMs) provide a principled and flexible approach to modeling the dynamics of a latent state, which is observed at discrete-time points via a likelihood model. However, inference in GPSSMs is computationally and statistically challenging due to the large number of latent variables in the model and the strong temporal dependencies between them. In this paper, we propose a new method for inference in Bayesian GPSSMs, which overcomes the drawbacks of previous approaches, namely over-simplified assumptions, and high computational requirements. Our method is based on free-form variational inference via stochastic gradient Hamiltonian Monte Carlo within the inducing-variable formalism. Furthermore, by exploiting our proposed variational distribution, we provide a collapsed extension of our method where the inducing variables are marginalized analytically. We also showcase results when combining our framework with particle MCMC methods. We show that, on s
&lt;/p&gt;</description></item><item><title>&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#27867;&#21270;&#30028;&#65292;&#20026;Wasserstein GAN&#21644;Energy-Based GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20986;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;</title><link>http://arxiv.org/abs/2302.08942</link><description>&lt;p&gt;
&#38754;&#21521;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian Generalization Bounds for Adversarial Generative Models. (arXiv:2302.08942v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08942
&lt;/p&gt;
&lt;p&gt;
&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#27867;&#21270;&#30028;&#65292;&#20026;Wasserstein GAN&#21644;Energy-Based GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20986;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#24320;&#21457;&#20102;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#31532;&#19968;&#20010;&#20851;&#20110;Wasserstein&#36317;&#31163;&#30340;&#32467;&#26524;&#20551;&#35774;&#23454;&#20363;&#31354;&#38388;&#26159;&#26377;&#30028;&#30340;&#65292;&#32780;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#32467;&#26524;&#21033;&#29992;&#20102;&#38477;&#32500;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#33258;&#28982;&#36866;&#29992;&#20110;Wasserstein GAN&#21644;Energy-Based GAN&#65292;&#32780;&#25105;&#20204;&#30340;&#30028;&#38480;&#20026;&#36825;&#20004;&#31181;GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#12290;&#23613;&#31649;&#25105;&#20204;&#30340;&#24037;&#20316;&#20027;&#35201;&#26159;&#29702;&#35770;&#24615;&#30340;&#65292;&#20294;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;Wasserstein GAN&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38646;&#26679;&#26412;&#25552;&#31034;&#21152;&#26435;&#25216;&#26415;&#65292;&#36890;&#36807;&#25552;&#31034;&#38598;&#25104;&#26469;&#33258;&#21160;&#21270;&#25552;&#31034;&#24037;&#31243;&#65292;&#20174;&#32780;&#25552;&#39640;&#25991;&#26412;-&#22270;&#20687;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.06235</link><description>&lt;p&gt;
&#19968;&#31181;&#31616;&#21333;&#30340;&#38646;&#26679;&#26412;&#25552;&#31034;&#21152;&#26435;&#25216;&#26415;&#65292;&#20197;&#25913;&#21892;&#25991;&#26412;-&#22270;&#20687;&#27169;&#22411;&#20013;&#30340;&#25552;&#31034;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models. (arXiv:2302.06235v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06235
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38646;&#26679;&#26412;&#25552;&#31034;&#21152;&#26435;&#25216;&#26415;&#65292;&#36890;&#36807;&#25552;&#31034;&#38598;&#25104;&#26469;&#33258;&#21160;&#21270;&#25552;&#31034;&#24037;&#31243;&#65292;&#20174;&#32780;&#25552;&#39640;&#25991;&#26412;-&#22270;&#20687;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#35757;&#32451;&#30340;&#25991;&#26412;-&#22270;&#20687;&#27169;&#22411;&#20855;&#26377;&#26174;&#33879;&#30340;&#38646;&#26679;&#26412;&#20998;&#31867;&#33021;&#21147;&#65292;&#21363;&#23558;&#20197;&#21069;&#26410;&#35265;&#36807;&#30340;&#22270;&#20687;&#20998;&#31867;&#20026;&#27169;&#22411;&#20174;&#26410;&#26126;&#30830;&#35757;&#32451;&#36807;&#30340;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#38646;&#26679;&#26412;&#20998;&#31867;&#22120;&#38656;&#35201;&#25552;&#31034;&#24037;&#31243;&#26469;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#12290;&#25552;&#31034;&#24037;&#31243;&#36890;&#24120;&#38656;&#35201;&#25163;&#24037;&#21019;&#24314;&#19968;&#32452;&#29992;&#20110;&#20010;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#25552;&#31034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#25552;&#31034;&#38598;&#25104;&#26469;&#33258;&#21160;&#21270;&#36825;&#20010;&#25552;&#31034;&#24037;&#31243;&#65292;&#24182;&#25552;&#39640;&#38646;&#26679;&#26412;&#20934;&#30830;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#8220;&#32473;&#23450;&#22823;&#37327;&#30340;&#25552;&#31034;&#65292;&#25105;&#20204;&#26159;&#21542;&#21487;&#20197;&#33258;&#21160;&#35780;&#20998;&#25552;&#31034;&#24182;&#38598;&#25104;&#37027;&#20123;&#23545;&#29305;&#23450;&#19979;&#28216;&#25968;&#25454;&#38598;&#26368;&#21512;&#36866;&#30340;&#25552;&#31034;&#65292;&#32780;&#26080;&#38656;&#35775;&#38382;&#26377;&#26631;&#31614;&#30340;&#39564;&#35777;&#25968;&#25454;&#65311;&#8221;&#25105;&#20204;&#35777;&#26126;&#36825;&#26159;&#21487;&#33021;&#30340;&#12290;&#22312;&#36825;&#26679;&#20570;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#22825;&#30495;&#30340;&#25552;&#31034;&#35780;&#20998;&#26041;&#27861;&#20013;&#30340;&#20960;&#20010;&#30149;&#29702;&#38382;&#39064;&#65292;&#20854;&#20013;&#20998;&#25968;&#24456;&#23481;&#26131;&#22240;&#39044;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#32780;&#36807;&#20110;&#33258;&#20449;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25552;&#31034;&#35780;&#20998;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastively trained text-image models have the remarkable ability to perform zero-shot classification, that is, classifying previously unseen images into categories that the model has never been explicitly trained to identify. However, these zero-shot classifiers need prompt engineering to achieve high accuracy. Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks. In this work, we aim to automate this prompt engineering and improve zero-shot accuracy through prompt ensembling. In particular, we ask "Given a large pool of prompts, can we automatically score the prompts and ensemble those that are most suitable for a particular downstream dataset, without needing access to labeled validation data?". We demonstrate that this is possible. In doing so, we identify several pathologies in a naive prompt scoring method where the score can be easily overconfident due to biases in pre-training and test data, and we propose a novel prompt scoring
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26032;&#30340;&#29275;&#39039;&#26041;&#27861;&#21464;&#31181;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#26367;&#25442;&#26799;&#24230;&#21644;&#28023;&#26862;&#30697;&#38453;&#65292;&#35777;&#26126;&#20102;&#36830;&#32493;&#36845;&#20195;&#25910;&#25947;&#21040;&#31181;&#32676;&#27700;&#24179;&#26368;&#23567;&#21270;&#22120;&#21608;&#22260;&#23567;&#29699;&#12290;&#35813;&#26041;&#27861;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#20855;&#26377;&#28508;&#22312;&#30340;&#20248;&#21183;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20849;&#36717;&#26799;&#24230;&#26041;&#27861;&#30340;&#31639;&#27861;&#26469;&#33719;&#21462;&#40065;&#26834;&#29275;&#39039;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2301.13192</link><description>&lt;p&gt;
&#36890;&#36807;&#29275;&#39039;&#26041;&#27861;&#23454;&#29616;&#40065;&#26834;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Robust empirical risk minimization via Newton's method. (arXiv:2301.13192v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13192
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26032;&#30340;&#29275;&#39039;&#26041;&#27861;&#21464;&#31181;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#26367;&#25442;&#26799;&#24230;&#21644;&#28023;&#26862;&#30697;&#38453;&#65292;&#35777;&#26126;&#20102;&#36830;&#32493;&#36845;&#20195;&#25910;&#25947;&#21040;&#31181;&#32676;&#27700;&#24179;&#26368;&#23567;&#21270;&#22120;&#21608;&#22260;&#23567;&#29699;&#12290;&#35813;&#26041;&#27861;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#20855;&#26377;&#28508;&#22312;&#30340;&#20248;&#21183;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20849;&#36717;&#26799;&#24230;&#26041;&#27861;&#30340;&#31639;&#27861;&#26469;&#33719;&#21462;&#40065;&#26834;&#29275;&#39039;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#29275;&#39039;&#26041;&#27861;&#21464;&#31181;&#65292;&#29992;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#12290;&#22312;&#20248;&#21270;&#31639;&#27861;&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#30446;&#26631;&#20989;&#25968;&#30340;&#26799;&#24230;&#21644;&#28023;&#26862;&#30697;&#38453;&#34987;&#26367;&#25442;&#20026;&#29616;&#26377;&#25991;&#29486;&#20013;&#38024;&#23545;&#22810;&#21464;&#37327;&#25968;&#25454;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#12290;&#22312;&#35777;&#26126;&#20102;&#36830;&#32493;&#36845;&#20195;&#25910;&#25947;&#21040;&#31181;&#32676;&#27700;&#24179;&#26368;&#23567;&#21270;&#22120;&#21608;&#22260;&#23567;&#29699;&#30340;&#19968;&#33324;&#23450;&#29702;&#20043;&#21518;&#65292;&#30740;&#31350;&#20102;&#24403;&#25968;&#25454;&#26469;&#33258;Huber&#30340;epsilon&#27745;&#26579;&#27169;&#22411;&#21644;/&#25110;&#37325;&#23614;&#20998;&#24067;&#26102;&#65292;&#35813;&#29702;&#35770;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#21518;&#26524;&#12290;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20849;&#36717;&#26799;&#24230;&#26041;&#27861;&#33719;&#21462;&#40065;&#26834;&#29275;&#39039;&#26041;&#21521;&#30340;&#31639;&#27861;&#65292;&#36825;&#21487;&#33021;&#26356;&#36866;&#29992;&#20110;&#39640;&#32500;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#32467;&#26524;&#31639;&#27861;&#25910;&#25947;&#24615;&#30340;&#29468;&#24819;&#12290;&#19982;&#40065;&#26834;&#26799;&#24230;&#19979;&#38477;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#33021;&#22815;&#23454;&#29616;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
A new variant of Newton's method for empirical risk minimization is studied, where at each iteration of the optimization algorithm, the gradient and Hessian of the objective function are replaced by robust estimators taken from existing literature on robust mean estimation for multivariate data. After proving a general theorem about the convergence of successive iterates to a small ball around the population-level minimizer, consequences of the theory in generalized linear models are studied when data are generated from Huber's epsilon-contamination model and/or heavytailed distributions. An algorithm for obtaining robust Newton directions based on the conjugate gradient method is also proposed, which may be more appropriate for high-dimensional settings, and conjectures about the convergence of the resulting algorithm are offered. Compared to robust gradient descent, the proposed algorithm enjoys the faster rates of convergence for successive iterates often achieved by second-order al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#24615;&#36136;&#65292;&#36890;&#36807;&#30740;&#31350;&#27531;&#24046;&#21270;&#29305;&#24449;&#21644;&#34394;&#20551;&#25237;&#24433;&#30340;&#22797;&#26434;&#24615;&#26469;&#25581;&#31034;&#27169;&#22411;&#19968;&#33268;&#24615;&#30340;&#36793;&#30028;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2301.06259</link><description>&lt;p&gt;
&#20102;&#35299;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;: &#20004;&#31181;&#22797;&#26434;&#24615;&#30340;&#25925;&#20107;
&lt;/p&gt;
&lt;p&gt;
Understanding Best Subset Selection: A Tale of Two C(omplex)ities. (arXiv:2301.06259v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.06259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#24615;&#36136;&#65292;&#36890;&#36807;&#30740;&#31350;&#27531;&#24046;&#21270;&#29305;&#24449;&#21644;&#34394;&#20551;&#25237;&#24433;&#30340;&#22797;&#26434;&#24615;&#26469;&#25581;&#31034;&#27169;&#22411;&#19968;&#33268;&#24615;&#30340;&#36793;&#30028;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#21313;&#24180;&#26469;&#65292;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;(BSS)&#20027;&#35201;&#30001;&#20110;&#35745;&#31639;&#29942;&#39048;&#32780;&#22256;&#25200;&#32479;&#35745;&#23398;&#23478;&#12290;&#28982;&#32780;&#65292;&#30452;&#21040;&#26368;&#36817;&#65292;&#29616;&#20195;&#35745;&#31639;&#31361;&#30772;&#37325;&#26032;&#28857;&#29123;&#20102;&#23545;BSS&#30340;&#29702;&#35770;&#20852;&#36259;&#24182;&#23548;&#33268;&#20102;&#26032;&#30340;&#21457;&#29616;&#12290;&#26368;&#36817;&#65292;Guo&#31561;&#20154;&#34920;&#26126;&#65292;BSS&#30340;&#27169;&#22411;&#36873;&#25321;&#24615;&#33021;&#21463;&#21040;&#20102;&#40065;&#26834;&#24615;&#35774;&#35745;&#20381;&#36182;&#30340;&#36793;&#30028;&#37327;&#30340;&#25511;&#21046;&#65292;&#19981;&#20687;LASSO&#12289;SCAD&#12289;MCP&#31561;&#29616;&#20195;&#26041;&#27861;&#12290;&#22312;&#20182;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#30340;&#28608;&#21169;&#19979;&#65292;&#26412;&#25991;&#36824;&#30740;&#31350;&#20102;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#19979;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#21464;&#37327;&#36873;&#25321;&#24615;&#36136;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#38500;&#20102;&#21487;&#36776;&#35782;&#24615;&#36793;&#30028;&#20197;&#22806;&#65292;&#19979;&#21015;&#20004;&#31181;&#22797;&#26434;&#24615;&#24230;&#37327;&#22312;&#34920;&#24449;&#27169;&#22411;&#19968;&#33268;&#24615;&#36793;&#30028;&#26465;&#20214;&#20013;&#36215;&#30528;&#22522;&#26412;&#30340;&#20316;&#29992;&#65306;(a)&#8220;&#27531;&#24046;&#21270;&#29305;&#24449;&#8221;&#30340;&#22797;&#26434;&#24615;&#65292;(b)&#8220;&#34394;&#20551;&#25237;&#24433;&#8221;&#30340;&#22797;&#26434;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#20165;&#20381;&#36182;&#20110;&#21487;&#36776;&#35782;&#24615;&#36793;&#30028;&#30340;&#31616;&#21333;&#36793;&#30028;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
For decades, best subset selection (BSS) has eluded statisticians mainly due to its computational bottleneck. However, until recently, modern computational breakthroughs have rekindled theoretical interest in BSS and have led to new findings. Recently, \cite{guo2020best} showed that the model selection performance of BSS is governed by a margin quantity that is robust to the design dependence, unlike modern methods such as LASSO, SCAD, MCP, etc. Motivated by their theoretical results, in this paper, we also study the variable selection properties of best subset selection for high-dimensional sparse linear regression setup. We show that apart from the identifiability margin, the following two complexity measures play a fundamental role in characterizing the margin condition for model consistency: (a) complexity of \emph{residualized features}, (b) complexity of \emph{spurious projections}. In particular, we establish a simple margin condition that depends only on the identifiability mar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#65292;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#25552;&#39640;&#20102;&#20854;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2212.14411</link><description>&lt;p&gt;
&#36817;&#20284;&#26368;&#20248;&#30340;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#20855;&#26377;&#21487;&#33021;&#30456;&#20851;&#35266;&#27979;&#30340;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Near-Optimal Non-Parametric Sequential Tests and Confidence Sequences with Possibly Dependent Observations. (arXiv:2212.14411v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14411
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#39034;&#24207;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#65292;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#25552;&#39640;&#20102;&#20854;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#26816;&#39564;&#21644;&#20854;&#38544;&#21547;&#30340;&#32622;&#20449;&#21306;&#38388;&#22312;&#20219;&#24847;&#20572;&#27490;&#26102;&#38388;&#19979;&#37117;&#33021;&#25552;&#20379;&#28789;&#27963;&#30340;&#32479;&#35745;&#25512;&#26029;&#21644;&#21363;&#26102;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#24378;&#26377;&#21147;&#30340;&#20445;&#35777;&#20165;&#36866;&#29992;&#20110;&#22312;&#23454;&#36341;&#20013;&#20302;&#20272;&#25110;&#27987;&#24230;&#30028;&#38480;&#20026;&#22522;&#30784;&#30340;&#39034;&#24207;&#24207;&#21015;&#65292;&#32780;&#36825;&#20123;&#24207;&#21015;&#20855;&#26377;&#27425;&#20248;&#30340;&#25298;&#32477;&#26102;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#32599;&#23486;&#26031;&#65288;Robbins&#65289;1970&#24180;&#30340;&#24310;&#36831;&#21551;&#21160;&#27491;&#24577;&#28151;&#21512;&#39034;&#24207;&#27010;&#29575;&#27604;&#26816;&#39564;&#65292;&#24182;&#22312;&#19968;&#33324;&#38750;&#21442;&#25968;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#25552;&#20379;&#20102;&#39318;&#20010;&#28176;&#36817;&#31867;&#22411;I&#38169;&#35823;&#21644;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#20445;&#35777;&#65292;&#20854;&#20013;&#28176;&#36817;&#24615;&#36136;&#30001;&#27979;&#35797;&#30340;&#28903;&#20837;&#26102;&#38388;&#30830;&#23450;&#12290;&#31867;&#22411;I&#38169;&#35823;&#30340;&#32467;&#26524;&#20027;&#35201;&#20381;&#36182;&#20110;&#38789;&#24378;&#19981;&#21464;&#21407;&#29702;&#65292;&#24182;&#35777;&#26126;&#36825;&#20123;&#26816;&#39564;&#65288;&#21450;&#20854;&#38544;&#21547;&#30340;&#32622;&#20449;&#21306;&#38388;&#65289;&#20855;&#26377;&#25509;&#36817;&#25152;&#38656;&#945;&#27700;&#24179;&#30340;&#31867;&#22411;I&#38169;&#35823;&#29575;&#12290;&#26399;&#26395;&#25298;&#32477;&#26102;&#38388;&#30340;&#32467;&#26524;&#20027;&#35201;&#21033;&#29992;&#20102;&#19968;&#31181;&#21463;&#20234;&#34276;&#24341;&#29702;&#21551;&#21457;&#30340;&#24658;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential tests and their implied confidence sequences, which are valid at arbitrary stopping times, promise flexible statistical inference and on-the-fly decision making. However, strong guarantees are limited to parametric sequential tests that under-cover in practice or concentration-bound-based sequences that over-cover and have suboptimal rejection times. In this work, we consider \cite{robbins1970boundary}'s delayed-start normal-mixture sequential probability ratio tests, and we provide the first asymptotic type-I-error and expected-rejection-time guarantees under general non-parametric data generating processes, where the asymptotics are indexed by the test's burn-in time. The type-I-error results primarily leverage a martingale strong invariance principle and establish that these tests (and their implied confidence sequences) have type-I error rates approaching a desired $\alpha$-level. The expected-rejection-time results primarily leverage an identity inspired by It\^o's lemm
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;PAC-Bayes&#22312;Bandit&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20379;&#20102;&#30028;&#38480;&#30340;&#27010;&#36848;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#39564;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;PAC-Bayes&#30028;&#38480;&#26159;&#35774;&#35745;&#20855;&#26377;&#24615;&#33021;&#20445;&#35777;&#30340;&#31163;&#32447;Bandit&#31639;&#27861;&#30340;&#26377;&#29992;&#24037;&#20855;&#65292;&#20294;&#22312;&#32447;Bandit&#31639;&#27861;&#32570;&#20047;&#36275;&#22815;&#30340;&#25968;&#25454;&#20197;&#20135;&#29983;&#24378;&#22823;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2211.16110</link><description>&lt;p&gt;
PAC-Bayes&#23450;&#29702;&#22312;Bandit&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#39033;&#35843;&#26597;&#19982;&#23454;&#39564;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayes Bounds for Bandit Problems: A Survey and Experimental Comparison. (arXiv:2211.16110v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16110
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;PAC-Bayes&#22312;Bandit&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20379;&#20102;&#30028;&#38480;&#30340;&#27010;&#36848;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#39564;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;PAC-Bayes&#30028;&#38480;&#26159;&#35774;&#35745;&#20855;&#26377;&#24615;&#33021;&#20445;&#35777;&#30340;&#31163;&#32447;Bandit&#31639;&#27861;&#30340;&#26377;&#29992;&#24037;&#20855;&#65292;&#20294;&#22312;&#32447;Bandit&#31639;&#27861;&#32570;&#20047;&#36275;&#22815;&#30340;&#25968;&#25454;&#20197;&#20135;&#29983;&#24378;&#22823;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PAC-Bayes&#26368;&#36817;&#37325;&#26032;&#20986;&#29616;&#20316;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#29702;&#35770;&#65292;&#21487;&#20197;&#29992;&#26469;&#25512;&#23548;&#20986;&#20855;&#26377;&#32039;&#23494;&#24615;&#33021;&#20445;&#35777;&#30340;&#26377;&#21407;&#21017;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;PAC-Bayes&#22312;Bandit&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#30456;&#23545;&#36739;&#23569;&#65292;&#36825;&#26159;&#19968;&#20010;&#24456;&#22823;&#30340;&#36951;&#25022;&#12290;&#22312;&#21307;&#30103;&#20445;&#20581;&#12289;&#37329;&#34701;&#21644;&#33258;&#28982;&#31185;&#23398;&#31561;&#35768;&#22810;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#37117;&#21487;&#20197;&#23558;&#20854;&#24314;&#27169;&#20026;Bandit&#38382;&#39064;&#12290;&#22312;&#35768;&#22810;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#24102;&#26377;&#24378;&#22823;&#24615;&#33021;&#20445;&#35777;&#30340;&#26377;&#21407;&#21017;&#31639;&#27861;&#23558;&#20250;&#21463;&#21040;&#24456;&#39640;&#30340;&#36190;&#36175;&#12290;&#26412;&#35843;&#26597;&#25552;&#20379;&#20102;&#20851;&#20110;Bandit&#38382;&#39064;&#30340;PAC-Bayes&#30028;&#38480;&#30340;&#27010;&#36848;&#65292;&#24182;&#36827;&#34892;&#20102;&#36825;&#20123;&#30028;&#38480;&#30340;&#23454;&#39564;&#27604;&#36739;&#12290;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#21457;&#29616;PAC-Bayes&#30028;&#38480;&#26159;&#35774;&#35745;&#20855;&#26377;&#24615;&#33021;&#20445;&#35777;&#30340;&#31163;&#32447;Bandit&#31639;&#27861;&#30340;&#26377;&#29992;&#24037;&#20855;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#19968;&#31181;PAC-Bayesian&#31163;&#32447;&#19978;&#19979;&#25991;Bandit&#31639;&#27861;&#33021;&#22815;&#23398;&#20064;&#20855;&#26377;&#31454;&#20105;&#24615;&#39044;&#26399;&#22870;&#21169;&#21644;&#38750;&#31354;&#24615;&#33021;&#20445;&#35777;&#30340;&#38543;&#26426;&#21270;&#31070;&#32463;&#32593;&#32476;&#31574;&#30053;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;PAC-Bayesian&#22312;&#32447;Bandit&#31639;&#27861;&#21017;&#32570;&#20047;&#36275;&#22815;&#30340;&#25968;&#25454;&#20197;&#20135;&#29983;&#24378;&#22823;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayes has recently re-emerged as an effective theory with which one can derive principled learning algorithms with tight performance guarantees. However, applications of PAC-Bayes to bandit problems are relatively rare, which is a great misfortune. Many decision-making problems in healthcare, finance and natural sciences can be modelled as bandit problems. In many of these applications, principled algorithms with strong performance guarantees would be very much appreciated. This survey provides an overview of PAC-Bayes bounds for bandit problems and an experimental comparison of these bounds. On the one hand, we found that PAC-Bayes bounds are a useful tool for designing offline bandit algorithms with performance guarantees. In our experiments, a PAC-Bayesian offline contextual bandit algorithm was able to learn randomised neural network polices with competitive expected reward and non-vacuous performance guarantees. On the other hand, the PAC-Bayesian online bandit algorithms that
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;Sobolev&#21644;Besov&#31354;&#38388;&#20013;&#65292;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#20197;&#24590;&#26679;&#30340;&#21442;&#25968;&#25928;&#29575;&#36924;&#36817;&#20989;&#25968;&#65292;&#21253;&#25324;$L_p(\Omega)$&#33539;&#25968;&#19979;&#30340;&#35823;&#24046;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;$1\leq p,q \leq \infty$&#21644;$s&gt;0$&#30340;&#23436;&#25972;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26469;&#33719;&#24471;&#23574;&#38160;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2211.14400</link><description>&lt;p&gt;
&#22312;Sobolev&#21644;Besov&#31354;&#38388;&#19978;&#65292;&#20851;&#20110;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20339;&#36924;&#36817;&#36895;&#29575;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and Besov Spaces. (arXiv:2211.14400v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14400
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;Sobolev&#21644;Besov&#31354;&#38388;&#20013;&#65292;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#20197;&#24590;&#26679;&#30340;&#21442;&#25968;&#25928;&#29575;&#36924;&#36817;&#20989;&#25968;&#65292;&#21253;&#25324;$L_p(\Omega)$&#33539;&#25968;&#19979;&#30340;&#35823;&#24046;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;$1\leq p,q \leq \infty$&#21644;$s&gt;0$&#30340;&#23436;&#25972;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26469;&#33719;&#24471;&#23574;&#38160;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;Sobolev&#31354;&#38388;$W^s(L_q(\Omega))$&#21644;Besov&#31354;&#38388;$B^s_r(L_q(\Omega))$&#20013;&#20197;$L_p(\Omega)$&#33539;&#25968;&#24230;&#37327;&#35823;&#24046;&#30340;&#21442;&#25968;&#25928;&#29575;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#23545;&#20110;&#22312;&#31185;&#23398;&#35745;&#31639;&#21644;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#20013;&#24212;&#29992;&#31070;&#32463;&#32593;&#32476;&#38750;&#24120;&#37325;&#35201;&#65292;&#22312;&#36807;&#21435;&#21482;&#26377;&#24403;$p=q=\infty$&#26102;&#25165;&#23436;&#20840;&#35299;&#20915;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#25552;&#20379;&#20102;&#25152;&#26377;$1\leq p,q\leq \infty$&#21644;$s&gt;0$&#30340;&#23436;&#25972;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#28176;&#36817;&#21305;&#37197;&#30340;&#19978;&#19979;&#30028;&#12290;&#20851;&#38190;&#30340;&#25216;&#26415;&#24037;&#20855;&#26159;&#19968;&#31181;&#26032;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#65292;&#23427;&#25552;&#20379;&#20102;&#31232;&#30095;&#21521;&#37327;&#30340;&#26368;&#20339;&#32534;&#30721;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;$p&gt;q$&#30340;&#38750;&#32447;&#24615;&#21306;&#22495;&#33719;&#24471;&#23574;&#38160;&#30340;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#30340;$L_p$&#36924;&#36817;&#19979;&#30028;&#25512;&#23548;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Let $\Omega = [0,1]^d$ be the unit cube in $\mathbb{R}^d$. We study the problem of how efficiently, in terms of the number of parameters, deep neural networks with the ReLU activation function can approximate functions in the Sobolev spaces $W^s(L_q(\Omega))$ and Besov spaces $B^s_r(L_q(\Omega))$, with error measured in the $L_p(\Omega)$ norm. This problem is important when studying the application of neural networks in a variety of fields, including scientific computing and signal processing, and has previously been completely solved only when $p=q=\infty$. Our contribution is to provide a complete solution for all $1\leq p,q\leq \infty$ and $s &gt; 0$, including asymptotically matching upper and lower bounds. The key technical tool is a novel bit-extraction technique which gives an optimal encoding of sparse vectors. This enables us to obtain sharp upper bounds in the non-linear regime where $p &gt; q$. We also provide a novel method for deriving $L_p$-approximation lower bounds based upon
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#35270;&#35282;&#26469;&#29702;&#35299;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36827;&#34892;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;VIPS&#21644;iBayes-GMM&#36825;&#20004;&#31181;&#30446;&#21069;&#26368;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#22312;&#26356;&#26032;&#21508;&#20010;&#32452;&#20214;&#21644;&#26435;&#37325;&#26102;&#20351;&#29992;&#30340;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#26159;&#31561;&#20215;&#30340;&#65292;&#20294;&#20854;&#23454;&#29616;&#21644;&#29702;&#35770;&#20445;&#35777;&#23384;&#22312;&#24046;&#24322;&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#22312;&#26679;&#26412;&#36873;&#25321;&#12289;&#33258;&#28982;&#26799;&#24230;&#20272;&#35745;&#12289;&#27493;&#38271;&#36866;&#24212;&#20197;&#21450;&#21487;&#20449;&#21306;&#22495;&#25110;&#32452;&#20214;&#25968;&#37327;&#30340;&#35843;&#25972;&#31561;&#35774;&#35745;&#36873;&#25321;&#19978;&#23384;&#22312;&#21306;&#21035;&#65292;&#23545;&#20110;&#23398;&#20064;&#36817;&#20284;&#30340;&#36136;&#37327;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2209.11533</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#30340;&#32479;&#19968;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Unified Perspective on Natural Gradient Variational Inference with Gaussian Mixture Models. (arXiv:2209.11533v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.11533
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#35270;&#35282;&#26469;&#29702;&#35299;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36827;&#34892;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;VIPS&#21644;iBayes-GMM&#36825;&#20004;&#31181;&#30446;&#21069;&#26368;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#22312;&#26356;&#26032;&#21508;&#20010;&#32452;&#20214;&#21644;&#26435;&#37325;&#26102;&#20351;&#29992;&#30340;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#26159;&#31561;&#20215;&#30340;&#65292;&#20294;&#20854;&#23454;&#29616;&#21644;&#29702;&#35770;&#20445;&#35777;&#23384;&#22312;&#24046;&#24322;&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#22312;&#26679;&#26412;&#36873;&#25321;&#12289;&#33258;&#28982;&#26799;&#24230;&#20272;&#35745;&#12289;&#27493;&#38271;&#36866;&#24212;&#20197;&#21450;&#21487;&#20449;&#21306;&#22495;&#25110;&#32452;&#20214;&#25968;&#37327;&#30340;&#35843;&#25972;&#31561;&#35774;&#35745;&#36873;&#25321;&#19978;&#23384;&#22312;&#21306;&#21035;&#65292;&#23545;&#20110;&#23398;&#20064;&#36817;&#20284;&#30340;&#36136;&#37327;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#33021;&#22815;&#20197;&#39640;&#24230;&#21487;&#34892;&#20294;&#22810;&#27169;&#24577;&#30340;&#26041;&#24335;&#23398;&#20064;&#38590;&#20197;&#22788;&#29702;&#30340;&#30446;&#26631;&#20998;&#24067;&#65292;&#20855;&#26377;&#26368;&#22810;&#20960;&#30334;&#20010;&#32500;&#24230;&#12290;&#30446;&#21069;&#23545;&#20110;&#22522;&#20110;GMM&#30340;&#21464;&#20998;&#25512;&#26029;&#26469;&#35828;&#65292;VIPS&#21644;iBayes-GMM&#26159;&#26368;&#26377;&#25928;&#30340;&#20004;&#31181;&#26041;&#27861;&#65292;&#23427;&#20204;&#37117;&#20351;&#29992;&#29420;&#31435;&#30340;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#26469;&#26356;&#26032;&#21508;&#20010;&#32452;&#20214;&#21450;&#20854;&#26435;&#37325;&#12290;&#25105;&#20204;&#39318;&#27425;&#35777;&#26126;&#20102;&#23427;&#20204;&#27966;&#29983;&#30340;&#26356;&#26032;&#26159;&#31561;&#20215;&#30340;&#65292;&#23613;&#31649;&#23427;&#20204;&#30340;&#23454;&#38469;&#23454;&#29616;&#21644;&#29702;&#35770;&#20445;&#35777;&#26377;&#25152;&#19981;&#21516;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#20960;&#20010;&#21306;&#20998;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#35774;&#35745;&#36873;&#25321;&#65292;&#21253;&#25324;&#26679;&#26412;&#36873;&#25321;&#12289;&#33258;&#28982;&#26799;&#24230;&#20272;&#35745;&#12289;&#27493;&#38271;&#36866;&#24212;&#20197;&#21450;&#26159;&#21542;&#24378;&#21046;&#23454;&#26045;&#21487;&#20449;&#21306;&#22495;&#25110;&#35843;&#25972;&#32452;&#20214;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23545;&#20110;&#36825;&#20004;&#31181;&#26041;&#27861;&#65292;&#25152;&#23398;&#36817;&#20284;&#30340;&#36136;&#37327;&#21487;&#33021;&#20250;&#21463;&#21040;&#30456;&#24212;&#35774;&#35745;&#36873;&#25321;&#30340;&#20005;&#37325;&#24433;&#21709;&#65306;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#26679;&#26412;&#26469;&#26356;&#26032;&#21508;&#20010;&#32452;&#20214;&#65292;iBayes-GMM&#30340;&#23398;&#20064;&#36817;&#20284;&#36136;&#37327;&#21487;&#33021;&#21463;&#21040;&#26356;&#20005;&#37325;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference with Gaussian mixture models (GMMs) enables learning of highly tractable yet multi-modal approximations of intractable target distributions with up to a few hundred dimensions. The two currently most effective methods for GMM-based variational inference, VIPS and iBayes-GMM, both employ independent natural gradient updates for the individual components and their weights. We show for the first time, that their derived updates are equivalent, although their practical implementations and theoretical guarantees differ. We identify several design choices that distinguish both approaches, namely with respect to sample selection, natural gradient estimation, stepsize adaptation, and whether trust regions are enforced or the number of components adapted. We argue that for both approaches, the quality of the learned approximations can heavily suffer from the respective design choices: By updating the individual components using samples from the mixture model, iBayes-GMM of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#20855;&#26377;&#32467;&#26500;&#21270;&#38750;&#24179;&#31283;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#26469;&#27169;&#25311;&#19978;&#28216;&#21360;&#24230;&#27827;&#27969;&#22495;&#30340;&#38477;&#27700;&#27169;&#24335;&#65292;&#35299;&#20915;&#20102;&#23545;&#35813;&#22320;&#21306;&#22797;&#26434;&#26102;&#31354;&#38477;&#27700;&#20998;&#24067;&#30340;&#29702;&#35299;&#19981;&#36275;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2209.04947</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#27668;&#20505;&#31185;&#23398;&#30340;&#26680;&#24515;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Kernel Learning for Explainable Climate Science. (arXiv:2209.04947v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#20855;&#26377;&#32467;&#26500;&#21270;&#38750;&#24179;&#31283;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#26469;&#27169;&#25311;&#19978;&#28216;&#21360;&#24230;&#27827;&#27969;&#22495;&#30340;&#38477;&#27700;&#27169;&#24335;&#65292;&#35299;&#20915;&#20102;&#23545;&#35813;&#22320;&#21306;&#22797;&#26434;&#26102;&#31354;&#38477;&#27700;&#20998;&#24067;&#30340;&#29702;&#35299;&#19981;&#36275;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21916;&#39532;&#25289;&#38597;&#23665;&#19978;&#28216;&#21360;&#24230;&#27827;&#27969;&#22495;&#20026;2.7&#20159;&#20154;&#21475;&#21644;&#26080;&#25968;&#29983;&#24577;&#31995;&#32479;&#25552;&#20379;&#27700;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#38477;&#27700;&#20316;&#20026;&#27700;&#25991;&#27169;&#25311;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#22312;&#36825;&#20010;&#22320;&#21306;&#30340;&#29702;&#35299;&#36824;&#24456;&#26377;&#38480;&#12290;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#22260;&#32469;&#22312;&#27827;&#27969;&#22495;&#30340;&#22797;&#26434;&#26102;&#31354;&#38477;&#27700;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#20855;&#26377;&#32467;&#26500;&#21270;&#38750;&#24179;&#31283;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#26469;&#27169;&#25311;&#19978;&#28216;&#21360;&#24230;&#27827;&#27969;&#22495;&#30340;&#38477;&#27700;&#27169;&#24335;&#12290;&#20197;&#24448;&#22312;&#21360;&#24230;&#21916;&#39532;&#25289;&#38597;&#23665;&#21306;&#37327;&#21270;&#25110;&#27169;&#25311;&#38477;&#27700;&#30340;&#23581;&#35797;&#24448;&#24448;&#26159;&#23450;&#24615;&#30340;&#65292;&#21253;&#25324;&#20102;&#31895;&#31961;&#30340;&#20551;&#35774;&#21644;&#31616;&#21270;&#65292;&#26080;&#27861;&#35299;&#20915;&#20302;&#20998;&#36776;&#29575;&#19979;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#30740;&#31350;&#20960;&#20046;&#27809;&#26377;&#32771;&#34385;&#35823;&#24046;&#20256;&#25773;&#12290;&#25105;&#20204;&#21033;&#29992;&#38750;&#24179;&#31283;&#30340;&#21513;&#24067;&#26031;&#26680;&#21644;&#20381;&#36182;&#36755;&#20837;&#30340;&#38271;&#24230;&#21442;&#25968;&#26469;&#32771;&#34385;&#38477;&#27700;&#30340;&#31354;&#38388;&#21464;&#21270;&#65292;&#20351;&#24471;&#21518;&#39564;&#20989;&#25968;&#26679;&#26412;&#33021;&#22815;&#36866;&#24212;&#36825;&#19968;&#21306;&#22495;&#22266;&#26377;&#30340;&#38477;&#27700;&#27169;&#24335;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Upper Indus Basin, Himalayas provides water for 270 million people and countless ecosystems. However, precipitation, a key component to hydrological modelling, is poorly understood in this area. A key challenge surrounding this uncertainty comes from the complex spatial-temporal distribution of precipitation across the basin. In this work we propose Gaussian processes with structured non-stationary kernels to model precipitation patterns in the UIB. Previous attempts to quantify or model precipitation in the Hindu Kush Karakoram Himalayan region have often been qualitative or include crude assumptions and simplifications which cannot be resolved at lower resolutions. This body of research also provides little to no error propagation. We account for the spatial variation in precipitation with a non-stationary Gibbs kernel parameterised with an input dependent lengthscale. This allows the posterior function samples to adapt to the varying precipitation patterns inherent in the distin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;Bradley-Terry&#27169;&#22411;&#65292;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#36125;&#21494;&#26031;&#26041;&#27861;&#33021;&#25552;&#20379;&#26356;&#32454;&#33268;&#30340;&#31639;&#27861;&#20043;&#38388;&#24046;&#24322;&#25551;&#36848;&#65292;&#24182;&#20801;&#35768;&#23545;&#31561;&#25928;&#24615;&#36827;&#34892;&#23450;&#20041;&#12290;</title><link>http://arxiv.org/abs/2208.04935</link><description>&lt;p&gt;
&#19968;&#31181;&#27604;&#36739;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#36125;&#21494;&#26031;Bradley-Terry&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Bradley-Terry model to compare multiple ML algorithms on multiple data sets. (arXiv:2208.04935v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.04935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;Bradley-Terry&#27169;&#22411;&#65292;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#36125;&#21494;&#26031;&#26041;&#27861;&#33021;&#25552;&#20379;&#26356;&#32454;&#33268;&#30340;&#31639;&#27861;&#20043;&#38388;&#24046;&#24322;&#25551;&#36848;&#65292;&#24182;&#20801;&#35768;&#23545;&#31561;&#25928;&#24615;&#36827;&#34892;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#31639;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;&#35813;&#27169;&#22411;&#22522;&#20110;Bradley-Terry&#27169;&#22411;&#65292;&#32479;&#35745;&#20102;&#19968;&#20010;&#31639;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#21478;&#19968;&#20010;&#31639;&#27861;&#30340;&#27425;&#25968;&#12290;&#19982;&#39057;&#29575;&#27966;&#26041;&#27861;&#65288;&#22914;Demsar&#65288;2006&#65289;&#30340;&#24179;&#22343;&#25490;&#21517;&#27604;&#36739;&#27979;&#35797;&#21644;Benavoli&#31561;&#20154;&#65288;2016&#65289;&#30340;&#22810;&#20010;&#37197;&#23545;Wilcoxon&#27979;&#35797;&#19982;p&#35843;&#25972;&#36807;&#31243;&#65289;&#30456;&#27604;&#65292;&#22522;&#20110;&#36125;&#21494;&#26031;&#30340;Bradley-Terry&#27169;&#22411;&#65288;BBT&#65289;&#20855;&#26377;&#19981;&#21516;&#30340;&#29305;&#28857;&#12290;&#29305;&#21035;&#26159;&#65292;&#36125;&#21494;&#26031;&#26041;&#27861;&#20801;&#35768;&#23545;&#31639;&#27861;&#36827;&#34892;&#26356;&#21152;&#32454;&#33268;&#30340;&#25551;&#36848;&#65292;&#32780;&#19981;&#20165;&#20165;&#22768;&#31216;&#24046;&#24322;&#20855;&#26377;&#25110;&#19981;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#36824;&#20801;&#35768;&#23450;&#20041;&#20004;&#20010;&#31639;&#27861;&#22312;&#23454;&#38469;&#30446;&#30340;&#19979;&#26159;&#21542;&#31561;&#25928;&#65292;&#25110;&#23454;&#38469;&#31561;&#25928;&#21306;&#22495;&#65288;ROPE&#65289;&#12290;&#19982;Benavoli&#31561;&#20154;&#65288;2017&#65289;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#31526;&#21495;&#31209;&#27604;&#36739;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#19968;&#20123;&#29420;&#29305;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a Bayesian model to compare multiple algorithms on multiple data sets, on any metric. The model is based on the Bradley-Terry model, that counts the number of times one algorithm performs better than another on different data sets. Because of its Bayesian foundations, the Bayesian Bradley Terry model (BBT) has different characteristics than frequentist approaches to comparing multiple algorithms on multiple data sets, such as Demsar (2006) tests on mean rank, and Benavoli et al. (2016) multiple pairwise Wilcoxon tests with p-adjustment procedures. In particular, a Bayesian approach allows for more nuanced statements regarding the algorithms beyond claiming that the difference is or it is not statistically significant. Bayesian approaches also allow to define when two algorithms are equivalent for practical purposes, or the region of practical equivalence (ROPE). Different than a Bayesian signed rank comparison procedure proposed by Benavoli et al. (2017), our approa
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#37327;&#20998;&#31867;&#22120;&#36755;&#20986;&#22312;&#23616;&#37096;&#36716;&#25442;&#37051;&#22495;&#20013;&#19981;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25551;&#36848;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#19981;&#20381;&#36182;&#20110;&#25968;&#25454;&#20998;&#24067;&#25110;&#27169;&#22411;&#20551;&#35774;&#65292;&#21487;&#24212;&#29992;&#20110;&#22495;&#22806;&#29615;&#22659;&#12290;</title><link>http://arxiv.org/abs/2207.02093</link><description>&lt;p&gt;
&#20351;&#29992;&#37051;&#22495;&#19981;&#21464;&#24615;&#39044;&#27979;&#22495;&#22806;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Predicting Out-of-Domain Generalization with Neighborhood Invariance. (arXiv:2207.02093v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.02093
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#37327;&#20998;&#31867;&#22120;&#36755;&#20986;&#22312;&#23616;&#37096;&#36716;&#25442;&#37051;&#22495;&#20013;&#19981;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25551;&#36848;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#19981;&#20381;&#36182;&#20110;&#25968;&#25454;&#20998;&#24067;&#25110;&#27169;&#22411;&#20551;&#35774;&#65292;&#21487;&#24212;&#29992;&#20110;&#22495;&#22806;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#22320;&#24320;&#21457;&#21644;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21462;&#20915;&#20110;&#23545;&#20854;&#27867;&#21270;&#33021;&#21147;&#22312;&#26032;&#29615;&#22659;&#20013;&#30340;&#29305;&#24449;&#21644;&#27604;&#36739;&#33021;&#21147;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#21487;&#20197;&#30452;&#25509;&#39044;&#27979;&#25110;&#29702;&#35770;&#19978;&#38480;&#21046;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#37117;&#20381;&#36182;&#20110;&#21305;&#37197;&#30340;&#35757;&#32451;/&#27979;&#35797;&#20998;&#24067;&#21644;&#35775;&#38382;&#27169;&#22411;&#26799;&#24230;&#31561;&#24378;&#20551;&#35774;&#12290;&#20026;&#20102;&#22312;&#36825;&#20123;&#20551;&#35774;&#19981;&#28385;&#36275;&#26102;&#25551;&#36848;&#27867;&#21270;&#33021;&#21147;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37051;&#22495;&#19981;&#21464;&#24615;&#65292;&#19968;&#31181;&#20998;&#31867;&#22120;&#22312;&#23616;&#37096;&#36716;&#25442;&#37051;&#22495;&#20013;&#36755;&#20986;&#19981;&#21464;&#30340;&#24230;&#37327;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37319;&#26679;&#19968;&#32452;&#36716;&#25442;&#65292;&#23545;&#20110;&#19968;&#20010;&#36755;&#20837;&#27979;&#35797;&#28857;&#65292;&#35745;&#31639;&#19981;&#21464;&#24615;&#20316;&#20026;&#34987;&#20998;&#31867;&#20026;&#21516;&#19968;&#31867;&#21035;&#30340;&#36716;&#25442;&#28857;&#30340;&#26368;&#22823;&#27604;&#20363;&#12290;&#20851;&#38190;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#24230;&#37327;&#26041;&#27861;&#31616;&#21333;&#26131;&#35745;&#31639;&#65292;&#19981;&#20381;&#36182;&#20110;&#27979;&#35797;&#28857;&#30340;&#30495;&#23454;&#26631;&#31614;&#65292;&#19981;&#23545;&#25968;&#25454;&#20998;&#24067;&#25110;&#27169;&#22411;&#20570;&#20219;&#20309;&#20551;&#35774;&#65292;&#29978;&#33267;&#21487;&#20197;&#22312;&#22495;&#22806;&#29615;&#22659;&#19979;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Developing and deploying machine learning models safely depends on the ability to characterize and compare their abilities to generalize to new environments. Although recent work has proposed a variety of methods that can directly predict or theoretically bound the generalization capacity of a model, they rely on strong assumptions such as matching train/test distributions and access to model gradients. In order to characterize generalization when these assumptions are not satisfied, we propose neighborhood invariance, a measure of a classifier's output invariance in a local transformation neighborhood. Specifically, we sample a set of transformations and given an input test point, calculate the invariance as the largest fraction of transformed points classified into the same class. Crucially, our measure is simple to calculate, does not depend on the test point's true label, makes no assumptions about the data distribution or model, and can be applied even in out-of-domain (OOD) setti
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#36739;&#23567;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#26435;&#37325;&#34928;&#20943;&#26102;&#26356;&#20026;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#26102;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2206.05794</link><description>&lt;p&gt;
SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#34987;&#35777;&#26126;&#20250;&#24341;&#20837;&#20302;&#31209;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks. (arXiv:2206.05794v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05794
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#36739;&#23567;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#26435;&#37325;&#34928;&#20943;&#26102;&#26356;&#20026;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#26102;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#26102;&#23398;&#20064;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#23567;&#25209;&#37327;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#26469;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#20351;&#29992;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#30340;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#30340;&#26435;&#37325;&#34928;&#20943;&#26102;&#65292;&#36825;&#31181;&#20559;&#24046;&#26356;&#21152;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#39044;&#27979;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#26435;&#37325;&#34928;&#20943;&#26159;&#23454;&#29616;&#36825;&#31181;&#20559;&#24046;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#19982;&#20808;&#21069;&#30340;&#25991;&#29486;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#19981;&#20381;&#36182;&#20110;&#20851;&#20110;&#25968;&#25454;&#12289;&#25910;&#25947;&#24615;&#25110;&#26435;&#37325;&#30697;&#38453;&#20248;&#21270;&#30340;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#23427;&#36866;&#29992;&#20110;&#20219;&#24847;&#23485;&#24230;&#25110;&#28145;&#24230;&#30340;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the bias of Stochastic Gradient Descent (SGD) to learn low-rank weight matrices when training deep ReLU neural networks. Our results show that training neural networks with mini-batch SGD and weight decay causes a bias towards rank minimization over the weight matrices. Specifically, we show, both theoretically and empirically, that this bias is more pronounced when using smaller batch sizes, higher learning rates, or increased weight decay. Additionally, we predict and observe empirically that weight decay is necessary to achieve this bias. In addition, we show that in the presence of intermediate neural collapse, the learned weights are particularly low-rank. Unlike previous literature, our analysis does not rely on assumptions about the data, convergence, or optimality of the weight matrices. Furthermore, it applies to a wide range of neural network architectures of any width or depth. Finally, we empirically investigate the connection between this bias and generalization, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#26368;&#20339;k&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#23548;&#21521;&#36873;&#25321;&#30340;&#31639;&#27861;&#65288;IDS&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;&#19982;IDS&#38598;&#25104;&#30340;&#39030;&#37096;&#20004;&#20010;&#27748;&#22982;&#36874;&#37319;&#26679;&#22312;&#39640;&#26031;&#26368;&#20339;&#33218;&#35782;&#21035;&#20013;&#36798;&#21040;&#20102;&#26368;&#20248;&#12290;</title><link>http://arxiv.org/abs/2205.12086</link><description>&lt;p&gt;
&#20449;&#24687;&#23548;&#21521;&#36873;&#25321;&#30340;&#21069;&#20004;&#20010;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Information-Directed Selection for Top-Two Algorithms. (arXiv:2205.12086v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#26368;&#20339;k&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#23548;&#21521;&#36873;&#25321;&#30340;&#31639;&#27861;&#65288;IDS&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;&#19982;IDS&#38598;&#25104;&#30340;&#39030;&#37096;&#20004;&#20010;&#27748;&#22982;&#36874;&#37319;&#26679;&#22312;&#39640;&#26031;&#26368;&#20339;&#33218;&#35782;&#21035;&#20013;&#36798;&#21040;&#20102;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#26368;&#20339;k&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#36890;&#36807;&#39034;&#24207;&#20998;&#37197;&#27979;&#37327;&#21162;&#21147;&#26469;&#36873;&#25321;&#20855;&#26377;&#26368;&#39640;&#24179;&#22343;&#22870;&#21169;&#30340;k&#33218;&#20934;&#30830;&#38598;&#21512;&#12290;&#25105;&#20204;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#26469;&#34920;&#24449;&#26368;&#20248;&#20998;&#37197;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#26368;&#20248;&#24615;&#26465;&#20214;&#23548;&#33268;&#20102;&#39030;&#37096;&#20004;&#20010;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65288;Russo, 2020&#65289;&#30340;&#25193;&#23637;&#65292;&#36825;&#26368;&#21021;&#26159;&#20026;&#20102;&#26368;&#20339;&#33218;&#35782;&#21035;&#32780;&#25552;&#20986;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26368;&#20248;&#24615;&#26465;&#20214;&#24341;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#36873;&#25321;&#35268;&#21017;&#65292;&#31216;&#20026;&#20449;&#24687;&#23548;&#21521;&#36873;&#25321;&#65288;IDS&#65289;&#65292;&#23427;&#26681;&#25454;&#20449;&#24687;&#22686;&#30410;&#30340;&#24230;&#37327;&#36873;&#25321;&#21069;&#20004;&#20010;&#20505;&#36873;&#20013;&#30340;&#19968;&#20010;&#12290;&#20316;&#20026;&#29702;&#35770;&#20445;&#35777;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;IDS&#38598;&#25104;&#30340;&#39030;&#37096;&#20004;&#20010;&#27748;&#22982;&#36874;&#37319;&#26679;&#22312;&#39640;&#26031;&#26368;&#20339;&#33218;&#35782;&#21035;&#20013;&#65288;&#28176;&#36817;&#22320;&#65289;&#36798;&#21040;&#20102;&#26368;&#20248;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#32431;&#25506;&#32034;&#25991;&#29486;&#20013;&#31361;&#20986;&#30340;&#19968;&#20010;&#26410;&#35299;&#20915;&#38382;&#39064;&#65288;Russo, 2020&#65289;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#23545;&#20110;k &gt; 1&#65292;&#39030;&#37096;&#20004;&#20010;&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#26368;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the best-k-arm identification problem for multi-armed bandits, where the objective is to select the exact set of k arms with the highest mean rewards by sequentially allocating measurement effort. We characterize the necessary and sufficient conditions for the optimal allocation using dual variables. Remarkably these optimality conditions lead to the extension of top-two algorithm design principle (Russo, 2020), initially proposed for best-arm identification. Furthermore, our optimality conditions induce a simple and effective selection rule dubbed information-directed selection (IDS) that selects one of the top-two candidates based on a measure of information gain. As a theoretical guarantee, we prove that integrated with IDS, top-two Thompson sampling is (asymptotically) optimal for Gaussian best-arm identification, solving a glaring open problem in the pure exploration literature (Russo, 2020). As a by-product, we show that for k &gt; 1, top-two algorithms cannot achieve op
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#32771;&#34385;&#20102;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#19979;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25214;&#21040;&#20102;&#23454;&#20363;&#30456;&#20851;&#30340;&#23545;&#25968;&#36951;&#25022;&#19979;&#30028;&#65292;&#24182;&#35774;&#35745;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#23545;&#25968;&#22686;&#38271;&#36895;&#29575;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2205.11168</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#24179;&#22343;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#23545;&#25968;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Logarithmic regret bounds for continuous-time average-reward Markov decision processes. (arXiv:2205.11168v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11168
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#32771;&#34385;&#20102;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#19979;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25214;&#21040;&#20102;&#23454;&#20363;&#30456;&#20851;&#30340;&#23545;&#25968;&#36951;&#25022;&#19979;&#30028;&#65292;&#24182;&#35774;&#35745;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#23545;&#25968;&#22686;&#38271;&#36895;&#29575;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#26080;&#38480;&#26102;&#38388;&#36328;&#24230;&#12289;&#24179;&#22343;&#22870;&#21169;&#35774;&#23450;&#19979;&#30340;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#19982;&#31163;&#25955;&#26102;&#38388;MDPs&#19981;&#21516;&#65292;&#36830;&#32493;&#26102;&#38388;&#36807;&#31243;&#22312;&#37319;&#21462;&#34892;&#21160;&#21518;&#20250;&#31227;&#21160;&#21040;&#19968;&#20010;&#29366;&#24577;&#24182;&#22312;&#27492;&#20572;&#30041;&#19968;&#20010;&#38543;&#26426;&#25345;&#32493;&#26102;&#38388;&#12290;&#22312;&#26410;&#30693;&#30340;&#36716;&#31227;&#27010;&#29575;&#21644;&#25351;&#25968;&#25345;&#32493;&#26102;&#38388;&#21464;&#21270;&#29575;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#19982;&#26102;&#38388;&#36328;&#24230;&#23545;&#25968;&#30456;&#20851;&#30340;&#23454;&#20363;&#30456;&#20851;&#36951;&#25022;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#26377;&#38480;&#26102;&#38388;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#33021;&#22815;&#23454;&#29616;&#23545;&#25968;&#22686;&#38271;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24314;&#31435;&#22312;&#19978;&#38480;&#32622;&#20449;&#22686;&#24378;&#23398;&#20064;&#12289;&#22343;&#20540;&#25345;&#32493;&#26102;&#38388;&#30340;&#31934;&#32454;&#20272;&#35745;&#20197;&#21450;&#28857;&#36807;&#31243;&#30340;&#38543;&#26426;&#27604;&#36739;&#20043;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider reinforcement learning for continuous-time Markov decision processes (MDPs) in the infinite-horizon, average-reward setting. In contrast to discrete-time MDPs, a continuous-time process moves to a state and stays there for a random holding time after an action is taken. With unknown transition probabilities and rates of exponential holding times, we derive instance-dependent regret lower bounds that are logarithmic in the time horizon. Moreover, we design a learning algorithm and establish a finite-time regret bound that achieves the logarithmic growth rate. Our analysis builds upon upper confidence reinforcement learning, a delicate estimation of the mean holding times, and stochastic comparison of point processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#25277;&#26679;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#31283;&#36172;&#21338;&#26426;&#23398;&#20064;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#38477;&#20302;&#33719;&#21462;&#20449;&#24687;&#30340;&#20248;&#20808;&#32423;&#65292;&#35299;&#20915;&#20102;Thompson&#25277;&#26679;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#34920;&#29616;&#19981;&#20339;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#25152;&#26377;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#20248;&#20110;Thompson&#25277;&#26679;&#12290;</title><link>http://arxiv.org/abs/2205.01970</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#36172;&#21338;&#26426;&#23398;&#20064;&#30340;&#39044;&#27979;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Non-Stationary Bandit Learning via Predictive Sampling. (arXiv:2205.01970v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.01970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#25277;&#26679;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#31283;&#36172;&#21338;&#26426;&#23398;&#20064;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#38477;&#20302;&#33719;&#21462;&#20449;&#24687;&#30340;&#20248;&#20808;&#32423;&#65292;&#35299;&#20915;&#20102;Thompson&#25277;&#26679;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#34920;&#29616;&#19981;&#20339;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#25152;&#26377;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#20248;&#20110;Thompson&#25277;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a predictive sampling algorithm to solve the non-stationary bandit learning problem. By deprioritizing the acquisition of information that quickly loses usefulness, the algorithm outperforms Thompson sampling in all non-stationary environments examined.
&lt;/p&gt;
&lt;p&gt;
Thompson&#25277;&#26679;&#24050;&#32463;&#22312;&#24191;&#27867;&#30340;&#24179;&#31283;&#36172;&#21338;&#26426;&#29615;&#22659;&#20013;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#25152;&#23637;&#31034;&#30340;&#65292;&#24403;&#24212;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#26102;&#65292;&#23427;&#30340;&#34920;&#29616;&#21487;&#33021;&#24456;&#24046;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#26679;&#30340;&#22833;&#36133;&#26159;&#30001;&#20110;&#22312;&#25506;&#32034;&#26102;&#65292;&#31639;&#27861;&#27809;&#26377;&#26681;&#25454;&#30001;&#20110;&#38750;&#24179;&#31283;&#24615;&#23548;&#33268;&#20449;&#24687;&#24555;&#36895;&#22833;&#21435;&#26377;&#29992;&#24615;&#30340;&#36895;&#24230;&#21306;&#20998;&#34892;&#21160;&#12290;&#22522;&#20110;&#36825;&#19968;&#27934;&#35265;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39044;&#27979;&#25277;&#26679;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#38477;&#20302;&#20102;&#33719;&#21462;&#20449;&#24687;&#30340;&#20248;&#20808;&#32423;&#65292;&#36825;&#20123;&#20449;&#24687;&#30001;&#20110;&#24555;&#36895;&#22833;&#21435;&#26377;&#29992;&#24615;&#32780;&#19981;&#20877;&#37325;&#35201;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#39044;&#27979;&#25277;&#26679;&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#39044;&#27979;&#25277;&#26679;&#30340;&#29256;&#26412;&#65292;&#20854;&#35745;&#31639;&#21487;&#25193;&#23637;&#21040;&#23454;&#38469;&#24863;&#20852;&#36259;&#30340;&#22797;&#26434;&#36172;&#21338;&#26426;&#29615;&#22659;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#39044;&#27979;&#25277;&#26679;&#22312;&#25152;&#26377;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#37117;&#20248;&#20110;Thompson&#25277;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thompson sampling has proven effective across a wide range of stationary bandit environments. However, as we demonstrate in this paper, it can perform poorly when applied to non-stationary environments. We show that such failures are attributed to the fact that, when exploring, the algorithm does not differentiate actions based on how quickly the information acquired loses its usefulness due to non-stationarity. Building upon this insight, we propose predictive sampling, an algorithm that deprioritizes acquiring information that quickly loses usefulness. Theoretical guarantee on the performance of predictive sampling is established through a Bayesian regret bound. We provide versions of predictive sampling for which computations tractably scale to complex bandit environments of practical interest. Through numerical simulations, we demonstrate that predictive sampling outperforms Thompson sampling in all non-stationary environments examined.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20851;&#32852;&#32447;&#24615;&#28909;&#26041;&#31243;&#30340;&#35299;&#65292;&#24471;&#21040;&#20102;&#23545;&#31216;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;minmax&#26368;&#20248;&#36951;&#25022;&#21644;&#20266;&#36951;&#25022;&#30340;&#39046;&#20808;&#39033;&#12290;&#26032;&#30340;&#32467;&#26524;&#25913;&#36827;&#20102;&#20808;&#21069;&#30340;&#30740;&#31350;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#30340;&#38750;&#28176;&#36817;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2202.05767</link><description>&lt;p&gt;
&#22522;&#20110;PDE&#30340;&#23545;&#31216;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit. (arXiv:2202.05767v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20851;&#32852;&#32447;&#24615;&#28909;&#26041;&#31243;&#30340;&#35299;&#65292;&#24471;&#21040;&#20102;&#23545;&#31216;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;minmax&#26368;&#20248;&#36951;&#25022;&#21644;&#20266;&#36951;&#25022;&#30340;&#39046;&#20808;&#39033;&#12290;&#26032;&#30340;&#32467;&#26524;&#25913;&#36827;&#20102;&#20808;&#21069;&#30340;&#30740;&#31350;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#30340;&#38750;&#28176;&#36817;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#20010;&#29256;&#26412;&#30340;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;&#20004;&#20010;&#33218;&#30340;&#24179;&#22343;&#20540;&#20043;&#21644;&#20026;1&#65288;&#21363;&#23545;&#31216;&#30340;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#65289;&#12290;&#22312;&#33218;&#20043;&#38388;&#30340;&#24046;&#36317;&#36235;&#36817;&#20110;&#38646;&#19988;&#39044;&#27979;&#26399;&#25968;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#27599;&#20010;&#35299;&#19982;&#32447;&#24615;&#28909;&#26041;&#31243;&#30340;&#35299;&#20851;&#32852;&#65292;&#24471;&#21040;&#20102;&#35813;&#38382;&#39064;&#30340;minmax&#26368;&#20248;&#36951;&#25022;&#21644;&#20266;&#36951;&#25022;&#30340;&#39046;&#20808;&#39033;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25913;&#36827;&#20102;&#20808;&#21069;&#24050;&#30693;&#30340;&#32467;&#26524;&#65307;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#24046;&#36317;&#32553;&#25918;&#27169;&#24335;&#19979;&#65292;&#25105;&#20204;&#26126;&#30830;&#35745;&#31639;&#20102;&#36825;&#20123;&#39046;&#20808;&#39033;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#20219;&#20309;&#32473;&#23450;&#26102;&#38388;&#33539;&#22260;&#30340;&#26032;&#30340;&#38750;&#28176;&#36817;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work addresses a version of the two-armed Bernoulli bandit problem where the sum of the means of the arms is one (the symmetric two-armed Bernoulli bandit). In a regime where the gap between these means goes to zero and the number of prediction periods approaches infinity, we obtain the leading order terms of the minmax optimal regret and pseudoregret for this problem by associating each of them with a solution of a linear heat equation. Our results improve upon the previously known results; specifically, we explicitly compute these leading order terms in three different scaling regimes for the gap. Additionally, we obtain new non-asymptotic bounds for any given time horizon.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29468;&#24819;&#30340;&#25968;&#25454;&#27169;&#24335;&#21457;&#29616;&#26041;&#27861;&#65292;&#22312;&#25968;&#20540;&#29305;&#24449;&#21644;&#20998;&#31867;&#29305;&#24449;&#20043;&#38388;&#24314;&#31435;&#20102;&#38750;&#32447;&#24615;&#21644;&#24067;&#23572;&#20851;&#31995;&#65292;&#24182;&#24212;&#29992;&#20110;COVID-19&#24739;&#32773;&#32423;&#21035;&#25968;&#25454;&#65292;&#25581;&#31034;&#20102;&#21487;&#33021;&#30340;&#39118;&#38505;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2011.11576</link><description>&lt;p&gt;
&#22522;&#20110;&#29468;&#24819;&#30340;&#25968;&#25454;&#27169;&#24335;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Conjecturing-Based Discovery of Patterns in Data. (arXiv:2011.11576v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.11576
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29468;&#24819;&#30340;&#25968;&#25454;&#27169;&#24335;&#21457;&#29616;&#26041;&#27861;&#65292;&#22312;&#25968;&#20540;&#29305;&#24449;&#21644;&#20998;&#31867;&#29305;&#24449;&#20043;&#38388;&#24314;&#31435;&#20102;&#38750;&#32447;&#24615;&#21644;&#24067;&#23572;&#20851;&#31995;&#65292;&#24182;&#24212;&#29992;&#20110;COVID-19&#24739;&#32773;&#32423;&#21035;&#25968;&#25454;&#65292;&#25581;&#31034;&#20102;&#21487;&#33021;&#30340;&#39118;&#38505;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29468;&#24819;&#26426;&#22120;&#65292;&#23427;&#20197;&#38750;&#32447;&#24615;&#39033;&#30340;&#36793;&#30028;&#20197;&#21450;&#20998;&#31867;&#29305;&#24449;&#30340;&#24067;&#23572;&#34920;&#36798;&#24335;&#30340;&#24418;&#24335;&#24314;&#35758;&#29305;&#24449;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25152;&#25552;&#20986;&#30340;&#29468;&#24819;&#26694;&#26550;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#24674;&#22797;&#24050;&#30693;&#30340;&#38750;&#32447;&#24615;&#21644;&#24067;&#23572;&#20851;&#31995;&#12290;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#30495;&#23454;&#30340;&#22522;&#30784;&#20851;&#31995;&#34987;&#25581;&#31034;&#20986;&#26469;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#19982;&#20808;&#21069;&#25552;&#20986;&#30340;&#31526;&#21495;&#22238;&#24402;&#26694;&#26550;&#36827;&#34892;&#27604;&#36739;&#65292;&#20197;&#30830;&#23450;&#22312;&#25968;&#25454;&#38598;&#20013;&#28385;&#36275;&#30340;&#26041;&#31243;&#24674;&#22797;&#30340;&#33021;&#21147;&#12290;&#28982;&#21518;&#65292;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;COVID-19&#32467;&#26524;&#30340;&#24739;&#32773;&#32423;&#21035;&#25968;&#25454;&#65292;&#20197;&#25552;&#20379;&#21487;&#33021;&#19982;&#21307;&#23398;&#25991;&#29486;&#20013;&#30830;&#35748;&#30340;&#39118;&#38505;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose the use of a conjecturing machine that suggests feature relationships in the form of bounds involving nonlinear terms for numerical features and boolean expressions for categorical features. The proposed Conjecturing framework recovers known nonlinear and boolean relationships among features from data. In both settings, true underlying relationships are revealed. We then compare the method to a previously-proposed framework for symbolic regression on the ability to recover equations that are satisfied among features in a dataset. The framework is then applied to patient-level data regarding COVID-19 outcomes to suggest possible risk factors that are confirmed in the medical literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#26410;&#26631;&#35760;&#25968;&#25454;&#19982;&#26631;&#35760;&#25968;&#25454;&#22312;&#23398;&#20064;&#36895;&#24230;&#26041;&#38754;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#26410;&#26631;&#35760;&#25968;&#25454;&#22312;&#23398;&#20064;&#36895;&#24230;&#19978;&#21516;&#26679;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2005.11018</link><description>&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#65306;&#24403;&#26410;&#26631;&#35760;&#25968;&#25454;&#21516;&#26679;&#26377;&#29992;&#26102;&#30340;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Learning: the Case When Unlabeled Data is Equally Useful. (arXiv:2005.11018v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.11018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#26410;&#26631;&#35760;&#25968;&#25454;&#19982;&#26631;&#35760;&#25968;&#25454;&#22312;&#23398;&#20064;&#36895;&#24230;&#26041;&#38754;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#26410;&#26631;&#35760;&#25968;&#25454;&#22312;&#23398;&#20064;&#36895;&#24230;&#19978;&#21516;&#26679;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#35797;&#22270;&#21033;&#29992;&#36739;&#20415;&#23452;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#26469;&#25552;&#39640;&#23398;&#20064;&#24615;&#33021;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#25968;&#25454;&#20998;&#24067;&#21487;&#20197;&#30001;&#36830;&#32493;&#21442;&#25968;&#26469;&#25551;&#36848;&#30340;&#32479;&#35745;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20998;&#24067;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#26410;&#26631;&#35760;&#25968;&#25454;&#22312;&#23398;&#20064;&#36895;&#24230;&#26041;&#38754;&#19982;&#26631;&#35760;&#25968;&#25454;&#21516;&#26679;&#26377;&#29992;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35774;$n&#65292;m$&#20998;&#21035;&#20026;&#26631;&#35760;&#21644;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#25968;&#37327;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;$m\sim n$&#65292;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#36895;&#24230;&#25353;$O(1/n)$&#32553;&#25918;&#65307;&#22914;&#26524;$m\sim n^{1+\gamma}$&#65292;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#36895;&#24230;&#25353;$O(1/n^{1+\gamma})$&#32553;&#25918;&#65292;&#20854;&#20013;$\gamma&gt;0$&#65292;&#32780;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#36895;&#24230;&#25353;$O(1/n)$&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning algorithms attempt to take advantage of relatively inexpensive unlabeled data to improve learning performance. In this work, we consider statistical models where the data distributions can be characterized by continuous parameters. We show that under certain conditions on the distribution, unlabeled data is equally useful as labeled date in terms of learning rate. Specifically, let $n, m$ be the number of labeled and unlabeled data, respectively. It is shown that the learning rate of semi-supervised learning scales as $O(1/n)$ if $m\sim n$, and scales as $O(1/n^{1+\gamma})$ if $m\sim n^{1+\gamma}$ for some $\gamma&gt;0$, whereas the learning rate of supervised learning scales as $O(1/n)$.
&lt;/p&gt;</description></item><item><title>MDP Playground&#26159;&#19968;&#20010;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#27979;&#35797;&#24179;&#21488;&#65292;&#21487;&#20197;&#26681;&#25454;&#19981;&#21516;&#32500;&#24230;&#30340;&#38590;&#24230;&#25511;&#21046;&#26041;&#24335;&#65292;&#25361;&#25112;&#20195;&#29702;&#22312;&#21508;&#31181;&#29615;&#22659;&#20013;&#30340;&#34920;&#29616;&#12290;&#23427;&#25552;&#20379;&#20102;&#21442;&#25968;&#21270;&#30340;&#29609;&#20855;&#29615;&#22659;&#38598;&#21512;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#25581;&#31034;&#20102;&#36825;&#20123;&#29615;&#22659;&#23545;&#20195;&#29702;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/1909.07750</link><description>&lt;p&gt;
MDP Playground: &#19968;&#31181;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#26512;&#21644;&#35843;&#35797;&#27979;&#35797;&#24179;&#21488;
&lt;/p&gt;
&lt;p&gt;
MDP Playground: An Analysis and Debug Testbed for Reinforcement Learning. (arXiv:1909.07750v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1909.07750
&lt;/p&gt;
&lt;p&gt;
MDP Playground&#26159;&#19968;&#20010;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#27979;&#35797;&#24179;&#21488;&#65292;&#21487;&#20197;&#26681;&#25454;&#19981;&#21516;&#32500;&#24230;&#30340;&#38590;&#24230;&#25511;&#21046;&#26041;&#24335;&#65292;&#25361;&#25112;&#20195;&#29702;&#22312;&#21508;&#31181;&#29615;&#22659;&#20013;&#30340;&#34920;&#29616;&#12290;&#23427;&#25552;&#20379;&#20102;&#21442;&#25968;&#21270;&#30340;&#29609;&#20855;&#29615;&#22659;&#38598;&#21512;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#25581;&#31034;&#20102;&#36825;&#20123;&#29615;&#22659;&#23545;&#20195;&#29702;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;MDP Playground&#65292;&#19968;&#20010;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#30340;&#27979;&#35797;&#24179;&#21488;&#65292;&#21487;&#20197;&#26681;&#25454;&#38590;&#24230;&#30340;&#19981;&#21516;&#32500;&#24230;&#36827;&#34892;&#25511;&#21046;&#65292;&#20197;&#25361;&#25112;&#20195;&#29702;&#24182;&#22312;&#29609;&#20855;&#21644;&#22797;&#26434;&#30340;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#33719;&#24471;&#19981;&#21516;&#31243;&#24230;&#30340;&#38590;&#24230;&#12290;&#25105;&#20204;&#32771;&#34385;&#24182;&#20801;&#35768;&#23545;&#21508;&#31181;&#32500;&#24230;&#36827;&#34892;&#25511;&#21046;&#65292;&#21253;&#25324;&#24310;&#36831;&#22870;&#21169;&#12289;&#24207;&#21015;&#38271;&#24230;&#12289;&#22870;&#21169;&#23494;&#24230;&#12289;&#38543;&#26426;&#24615;&#12289;&#22270;&#20687;&#34920;&#31034;&#12289;&#26080;&#20851;&#29305;&#24449;&#12289;&#26102;&#38388;&#21333;&#20301;&#12289;&#21160;&#20316;&#33539;&#22260;&#31561;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;OpenAI Gym&#20013;&#21464;&#21270;&#36825;&#20123;&#32500;&#24230;&#26469;&#23450;&#20041;&#19968;&#20010;&#21442;&#25968;&#21270;&#30340;&#24555;&#36895;&#36816;&#34892;&#30340;&#29609;&#20855;&#29615;&#22659;&#38598;&#21512;&#65292;&#24182;&#24314;&#35758;&#20351;&#29992;&#36825;&#20123;&#29615;&#22659;&#26469;&#26356;&#22909;&#22320;&#20102;&#35299;&#20195;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;MDP Playground&#35774;&#35745;&#23454;&#39564;&#65292;&#20197;&#28145;&#20837;&#20102;&#35299;&#29609;&#20855;&#29615;&#22659;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23558;&#35768;&#22810;&#36825;&#20123;&#32500;&#24230;&#27880;&#20837;&#21040;&#20219;&#20309;Gym&#29615;&#22659;&#20013;&#30340;&#21253;&#35013;&#22120;&#12290;&#25105;&#20204;&#22312;Atari&#21644;Mujoco&#19978;&#20351;&#29992;&#36825;&#20123;&#21253;&#35013;&#22120;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#20102;&#35299;&#36825;&#20123;&#32500;&#24230;&#23545;&#27604;&#29609;&#20855;&#29615;&#22659;&#26356;&#22797;&#26434;&#30340;&#29615;&#22659;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present MDP Playground, a testbed for Reinforcement Learning (RL) agents with dimensions of hardness that can be controlled independently to challenge agents in different ways and obtain varying degrees of hardness in toy and complex RL environments. We consider and allow control over a wide variety of dimensions, including delayed rewards, sequence lengths, reward density, stochasticity, image representations, irrelevant features, time unit, action range and more. We define a parameterised collection of fast-to-run toy environments in OpenAI Gym by varying these dimensions and propose to use these to understand agents better. We then show how to design experiments using MDP Playground to gain insights on the toy environments. We also provide wrappers that can inject many of these dimensions into any Gym environment. We experiment with these wrappers on Atari and Mujoco to allow for understanding the effects of these dimensions on environments that are more complex than the toy envi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;MCMC&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#26041;&#27861;&#65292;&#21033;&#29992;&#31890;&#23376;&#32531;&#20914;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#37327;&#35299;&#20915;&#20102;&#38271;&#26102;&#38388;&#24207;&#21015;&#19979;&#35745;&#31639;&#21644;&#31890;&#23376;&#36864;&#21270;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/1901.10568</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;MCMC&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient MCMC for Nonlinear State Space Models. (arXiv:1901.10568v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1901.10568
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;MCMC&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#26041;&#27861;&#65292;&#21033;&#29992;&#31890;&#23376;&#32531;&#20914;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#37327;&#35299;&#20915;&#20102;&#38271;&#26102;&#38388;&#24207;&#21015;&#19979;&#35745;&#31639;&#21644;&#31890;&#23376;&#36864;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;SSM&#65289;&#36890;&#36807;&#28508;&#22312;&#30340;&#38543;&#26426;&#36807;&#31243;&#25552;&#20379;&#20102;&#24314;&#27169;&#22797;&#26434;&#26102;&#38388;&#24207;&#21015;&#30340;&#28789;&#27963;&#26694;&#26550;&#12290;&#23545;&#20110;&#38750;&#32447;&#24615;&#12289;&#38750;&#39640;&#26031;&#30340;SSM&#25512;&#26029;&#36890;&#24120;&#20351;&#29992;&#31890;&#23376;&#26041;&#27861;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#22312;&#22788;&#29702;&#38271;&#26102;&#38388;&#24207;&#21015;&#26102;&#19981;&#20855;&#22791;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25361;&#25112;&#26377;&#20004;&#26041;&#38754;&#65306;&#35745;&#31639;&#19982;&#26102;&#38388;&#32447;&#24615;&#25193;&#23637;&#65292;&#31890;&#23376;&#28388;&#27874;&#22120;&#22312;&#38271;&#24207;&#21015;&#20013;&#36824;&#20250;&#20986;&#29616;&#36880;&#28176;&#36864;&#21270;&#30340;&#38382;&#39064;&#12290;&#24050;&#32463;&#24320;&#21457;&#20102;&#20351;&#29992;&#32531;&#20914;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#37327;&#26469;&#24212;&#23545;&#26102;&#24207;&#20381;&#36182;&#24615;&#30340;&#26377;&#38480;&#29366;&#24577;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#21644;&#32447;&#24615;SSM&#30340;&#38543;&#26426;&#26799;&#24230;MCMC&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#25193;&#23637;&#21040;&#20102;&#38750;&#32447;&#24615;SSM&#65292;&#24182;&#25552;&#20986;&#20102;&#35823;&#24046;&#30028;&#38480;&#65292;&#32771;&#34385;&#20102;&#32531;&#20914;&#35823;&#24046;&#21644;&#31890;&#23376;&#35823;&#24046;&#65292;&#36866;&#29992;&#20110;&#22312;&#28508;&#22312;&#36807;&#31243;&#20013;&#20855;&#26377;&#23545;&#25968;&#20985;&#24615;&#30340;&#38750;&#32447;&#24615;SSM&#24773;&#20917;&#12290;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;MCMC&#26041;&#27861;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31890;&#23376;&#32531;&#20914;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
State space models (SSMs) provide a flexible framework for modeling complex time series via a latent stochastic process. Inference for nonlinear, non-Gaussian SSMs is often tackled with particle methods that do not scale well to long time series. The challenge is two-fold: not only do computations scale linearly with time, as in the linear case, but particle filters additionally suffer from increasing particle degeneracy with longer series. Stochastic gradient MCMC methods have been developed to scale Bayesian inference for finite-state hidden Markov models and linear SSMs using buffered stochastic gradient estimates to account for temporal dependencies. We extend these stochastic gradient estimators to nonlinear SSMs using particle methods. We present error bounds that account for both buffering error and particle error in the case of nonlinear SSMs that are log-concave in the latent process. We evaluate our proposed particle buffered stochastic gradient using stochastic gradient MCMC
&lt;/p&gt;</description></item></channel></rss>