<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.18784</link><description>&lt;p&gt;
&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#19979;&#30340;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#22312;&#37325;&#23614;&#22122;&#22768;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise. (arXiv:2310.18784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#20010;&#30740;&#31350;&#24037;&#20316;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21450;&#20854;&#21098;&#20999;&#21464;&#20307;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#12290;&#19982;&#26222;&#36890;&#30340;SGD&#30456;&#27604;&#65292;&#21098;&#20999;SGD&#22312;&#23454;&#38469;&#20013;&#26356;&#21152;&#31283;&#23450;&#65292;&#24182;&#19988;&#22312;&#29702;&#35770;&#19978;&#26377;&#23545;&#25968;&#20381;&#36182;&#20110;&#22833;&#36133;&#27010;&#29575;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;&#28982;&#32780;&#65292;&#20854;&#20182;&#23454;&#38469;&#38750;&#32447;&#24615;SGD&#21464;&#20307;&#65288;&#22914;&#31526;&#21495;SGD&#12289;&#37327;&#21270;SGD&#21644;&#24402;&#19968;&#21270;SGD&#65289;&#30340;&#25910;&#25947;&#24615;&#29702;&#35299;&#35201;&#23569;&#24471;&#22810;&#65292;&#36825;&#20123;&#26041;&#27861;&#23454;&#29616;&#20102;&#25913;&#36827;&#30340;&#36890;&#20449;&#25928;&#29575;&#25110;&#21152;&#36895;&#25910;&#25947;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#20041;&#38750;&#32447;&#24615;SGD&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#19982;&#21098;&#20999;SGD&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26356;&#20026;&#19968;&#33324;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#20989;&#25968;&#65292;&#22914;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent works have studied the convergence \textit{in high probability} of stochastic gradient descent (SGD) and its clipped variant. Compared to vanilla SGD, clipped SGD is practically more stable and has the additional theoretical benefit of logarithmic dependence on the failure probability. However, the convergence of other practical nonlinear variants of SGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved communication efficiency or accelerated convergence is much less understood. In this work, we study the convergence bounds \textit{in high probability} of a broad class of nonlinear SGD methods. For strongly convex loss functions with Lipschitz continuous gradients, we prove a logarithmic dependence on the failure probability, even when the noise is heavy-tailed. Strictly more general than the results for clipped SGD, our results hold for any nonlinearity with bounded (component-wise or joint) outputs, such as clipping, normalization, and quantizati
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#23558;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#20379;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.11479</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#28201;&#24230;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On the Temperature of Bayesian Graph Neural Networks for Conformal Prediction. (arXiv:2310.11479v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11479
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#23558;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#20379;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#20013;&#32463;&#24120;&#20351;&#29992;GNNs&#30340;&#24773;&#20917;&#19979;&#12290;&#19968;&#33268;&#39044;&#27979;(CP)&#20026;&#20219;&#20309;&#40657;&#30418;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#21069;&#36884;&#30340;&#26694;&#26550;&#12290;CP&#20445;&#35777;&#20102;&#19968;&#20010;&#39044;&#27979;&#38598;&#20197;&#25152;&#38656;&#30340;&#27010;&#29575;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#30340;&#24418;&#24335;&#30340;&#23448;&#26041;&#27010;&#29575;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#38598;&#30340;&#22823;&#23567;&#65292;&#21363;"&#20302;&#25928;&#29575;"&#65292;&#21463;&#21040;&#24213;&#23618;&#27169;&#22411;&#21644;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36125;&#21494;&#26031;&#23398;&#20064;&#36824;&#22522;&#20110;&#20272;&#35745;&#30340;&#21518;&#39564;&#20998;&#24067;&#25552;&#20379;&#19968;&#20010;&#21487;&#20449;&#21306;&#22495;&#65292;&#20294;&#21482;&#26377;&#22312;&#27169;&#22411;&#27491;&#30830;&#25351;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#21306;&#22495;&#25165;&#26159;"&#33391;&#22909;&#26657;&#20934;"&#30340;&#12290;&#22312;&#19968;&#20010;&#26368;&#36817;&#30340;&#24037;&#20316;&#30340;&#22522;&#30784;&#19978;&#65292;&#35813;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#20010;&#32553;&#25918;&#21442;&#25968;&#65292;&#29992;&#20110;&#20174;&#21518;&#39564;&#20272;&#35745;&#20013;&#26500;&#24314;&#26377;&#25928;&#30340;&#21487;&#20449;&#21306;&#22495;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;CP&#26694;&#26550;&#20013;&#23558;&#19968;&#20010;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;GNNs&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate uncertainty quantification in graph neural networks (GNNs) is essential, especially in high-stakes domains where GNNs are frequently employed. Conformal prediction (CP) offers a promising framework for quantifying uncertainty by providing $\textit{valid}$ prediction sets for any black-box model. CP ensures formal probabilistic guarantees that a prediction set contains a true label with a desired probability. However, the size of prediction sets, known as $\textit{inefficiency}$, is influenced by the underlying model and data generating process. On the other hand, Bayesian learning also provides a credible region based on the estimated posterior distribution, but this region is $\textit{well-calibrated}$ only when the model is correctly specified. Building on a recent work that introduced a scaling parameter for constructing valid credible regions from posterior estimate, our study explores the advantages of incorporating a temperature parameter into Bayesian GNNs within CP fra
&lt;/p&gt;</description></item><item><title>&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#30740;&#31350;&#20102;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#22312;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25506;&#31350;&#20102;&#24403;&#21069;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;QML&#23454;&#29616;&#30340;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#12290;&#19982;&#32463;&#20856;&#23545;&#24212;&#29289;&#30456;&#27604;&#36739;&#65292;&#36825;&#20123;QML&#23454;&#29616;&#30340;&#24615;&#33021;&#24471;&#21040;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2307.00908</link><description>&lt;p&gt;
&#36817;&#26399;&#37327;&#23376;&#35013;&#32622;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;: &#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#25216;&#26415;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#30340;&#29616;&#29366;
&lt;/p&gt;
&lt;p&gt;
Quantum Machine Learning on Near-Term Quantum Devices: Current State of Supervised and Unsupervised Techniques for Real-World Applications. (arXiv:2307.00908v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00908
&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#30740;&#31350;&#20102;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#22312;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25506;&#31350;&#20102;&#24403;&#21069;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;QML&#23454;&#29616;&#30340;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#12290;&#19982;&#32463;&#20856;&#23545;&#24212;&#29289;&#30456;&#27604;&#36739;&#65292;&#36825;&#20123;QML&#23454;&#29616;&#30340;&#24615;&#33021;&#24471;&#21040;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#37327;&#23376;&#30828;&#20214;&#22312;&#36895;&#24230;&#12289;&#37327;&#23376;&#27604;&#29305;&#25968;&#37327;&#21644;&#37327;&#23376;&#20307;&#31215;&#26041;&#38754;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#36827;&#23637;&#65292;&#37327;&#23376;&#20307;&#31215;&#34987;&#23450;&#20041;&#20026;&#22312;&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#21487;&#20197;&#26377;&#25928;&#23454;&#29616;&#30340;&#37327;&#23376;&#30005;&#36335;&#30340;&#26368;&#22823;&#35268;&#27169;&#12290;&#22240;&#27492;&#65292;&#22312;&#23454;&#38469;&#30828;&#20214;&#19978;&#24212;&#29992;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;(QML)&#20197;&#23454;&#29616;&#37327;&#23376;&#20248;&#21183;&#24050;&#32463;&#26377;&#20102;&#24456;&#22823;&#30340;&#22686;&#38271;&#12290;&#22312;&#36825;&#31687;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#23454;&#29616;&#30340;&#36873;&#23450;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#24212;&#29992;&#65292;&#29305;&#21035;&#38024;&#23545;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#12290;&#25105;&#20204;&#25506;&#35752;&#24182;&#24378;&#35843;&#20102;QML&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;&#24403;&#21069;&#38480;&#21046;&#12290;&#25105;&#20204;&#28145;&#20837;&#35752;&#35770;&#20102;&#21508;&#31181;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#65292;&#22914;&#32534;&#30721;&#25216;&#26415;&#12289;&#22522;&#24577;&#32467;&#26500;&#12289;&#35823;&#24046;&#34917;&#20607;&#21644;&#26799;&#24230;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#36825;&#20123;QML&#23454;&#29616;&#19982;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#24212;&#29289;&#20043;&#38388;&#30340;&#24615;&#33021;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
The past decade has seen considerable progress in quantum hardware in terms of the speed, number of qubits and quantum volume which is defined as the maximum size of a quantum circuit that can be effectively implemented on a near-term quantum device. Consequently, there has also been a rise in the number of works based on the applications of Quantum Machine Learning (QML) on real hardware to attain quantum advantage over their classical counterparts. In this survey, our primary focus is on selected supervised and unsupervised learning applications implemented on quantum hardware, specifically targeting real-world scenarios. Our survey explores and highlights the current limitations of QML implementations on quantum hardware. We delve into various techniques to overcome these limitations, such as encoding techniques, ansatz structure, error mitigation, and gradient methods. Additionally, we assess the performance of these QML implementations in comparison to their classical counterparts
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#23384;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.15498</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#30693;&#27979;&#37327;&#22122;&#22768;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks with unknown measurement noise. (arXiv:2211.15498v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15498
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#23384;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;(PINNs)&#26159;&#19968;&#31181;&#26082;&#33021;&#25214;&#21040;&#35299;&#20915;&#26041;&#26696;&#21448;&#33021;&#35782;&#21035;&#20559;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#30340;&#28789;&#27963;&#26041;&#27861;&#12290;&#22823;&#22810;&#25968;&#30456;&#20851;&#30340;&#30740;&#31350;&#37117;&#20551;&#35774;&#25968;&#25454;&#26159;&#26080;&#22122;&#22768;&#30340;&#65292;&#25110;&#32773;&#26159;&#21463;&#24369;&#39640;&#26031;&#22122;&#22768;&#27745;&#26579;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;PINN&#26694;&#26550;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#36825;&#20010;&#26681;&#26412;&#24615;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;(Energy-Based Model, EBM)&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#25105;&#20204;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks (PINNs) constitute a flexible approach to both finding solutions and identifying parameters of partial differential equations. Most works on the topic assume noiseless data, or data contaminated by weak Gaussian noise. We show that the standard PINN framework breaks down in case of non-Gaussian noise. We give a way of resolving this fundamental issue and we propose to jointly train an energy-based model (EBM) to learn the correct noise distribution. We illustrate the improved performance of our approach using multiple examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;Grassmann&#27969;&#24418;&#23398;&#20064;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20197;&#29983;&#25104;&#31283;&#23450;&#30340;&#24418;&#29366;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2211.02900</link><description>&lt;p&gt;
Grassmann&#27969;&#24418;&#27969;&#29992;&#20110;&#31283;&#23450;&#24418;&#29366;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Grassmann Manifold Flows for Stable Shape Generation. (arXiv:2211.02900v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;Grassmann&#27969;&#24418;&#23398;&#20064;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20197;&#29983;&#25104;&#31283;&#23450;&#30340;&#24418;&#29366;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#26426;&#22120;&#23398;&#20064;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#21033;&#29992;&#29305;&#23450;&#27969;&#24418;&#20013;&#30340;&#23545;&#31216;&#24615;&#20316;&#20026;&#24402;&#32435;&#20559;&#24046;&#30340;&#26041;&#27861;&#19978;&#12290;Grassmann&#27969;&#24418;&#25552;&#20379;&#20102;&#22788;&#29702;&#20197;&#24418;&#29366;&#31354;&#38388;&#34920;&#31034;&#30340;&#22522;&#26412;&#24418;&#29366;&#30340;&#33021;&#21147;&#65292;&#23454;&#29616;&#20102;&#31283;&#23450;&#30340;&#24418;&#29366;&#20998;&#26512;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36830;&#32493;&#30340;&#24402;&#19968;&#21270;&#27969;&#22312;Grassmann&#27969;&#24418;&#19978;&#24314;&#31435;&#23398;&#20064;&#20998;&#24067;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#26126;&#30830;&#30340;&#30446;&#26631;&#26159;&#29983;&#25104;&#31283;&#23450;&#30340;&#24418;&#29366;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;Grassmann&#27969;&#24418;&#20869;&#23398;&#20064;&#21644;&#29983;&#25104;&#65292;&#26377;&#25928;&#22320;&#28040;&#38500;&#20102;&#26059;&#36716;&#21644;&#32763;&#36716;&#31561;&#22806;&#37096;&#21464;&#25442;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#31283;&#20581;&#30340;&#29983;&#25104;&#65292;&#20197;&#36866;&#24212;&#23545;&#35937;&#30340;&#22522;&#26412;&#24418;&#29366;&#20449;&#24687;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#36890;&#36807;&#25429;&#25417;&#25968;&#25454;&#32467;&#26500;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;t&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, studies on machine learning have focused on methods that use symmetry implicit in a specific manifold as an inductive bias. Grassmann manifolds provide the ability to handle fundamental shapes represented as shape spaces, enabling stable shape analysis. In this paper, we present a novel approach in which we establish the theoretical foundations for learning distributions on the Grassmann manifold via continuous normalization flows, with the explicit goal of generating stable shapes. Our approach facilitates more robust generation by effectively eliminating the influence of extraneous transformations, such as rotations and inversions, through learning and generating within a Grassmann manifolds designed to accommodate the essential shape information of the object. The experimental results indicated that the proposed method can generate high-quality samples by capturing the data structure. Furthermore, the proposed method significantly outperformed state-of-the-art methods in t
&lt;/p&gt;</description></item></channel></rss>