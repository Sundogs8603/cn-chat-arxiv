<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#30005;&#21147;&#20132;&#26131;&#20013;&#20351;&#29992;&#27010;&#29575;&#20215;&#26684;&#39044;&#27979;&#21644;&#32467;&#21512;&#39044;&#27979;&#20998;&#24067;&#30340;&#25216;&#26415;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#22686;&#21152;&#38598;&#21512;&#30340;&#22810;&#26679;&#24615;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#20294;&#20351;&#29992;&#26368;&#23567;&#21270;CRPS&#30340;&#26435;&#37325;&#25216;&#26415;&#24182;&#19981;&#33021;&#24102;&#26469;&#26356;&#39640;&#30340;&#21033;&#28070;&#12290;</title><link>http://arxiv.org/abs/2308.15443</link><description>&lt;p&gt;
&#32467;&#21512;&#30005;&#20215;&#30340;&#39044;&#27979;&#20998;&#24067;&#65306;&#26368;&#23567;&#21270;CRPS&#26159;&#21542;&#22312;&#25552;&#21069;&#31454;&#26631;&#20013;&#23548;&#33268;&#26368;&#20339;&#20915;&#31574;&#65311;
&lt;/p&gt;
&lt;p&gt;
Combining predictive distributions of electricity prices: Does minimizing the CRPS lead to optimal decisions in day-ahead bidding?. (arXiv:2308.15443v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15443
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#30005;&#21147;&#20132;&#26131;&#20013;&#20351;&#29992;&#27010;&#29575;&#20215;&#26684;&#39044;&#27979;&#21644;&#32467;&#21512;&#39044;&#27979;&#20998;&#24067;&#30340;&#25216;&#26415;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#22686;&#21152;&#38598;&#21512;&#30340;&#22810;&#26679;&#24615;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#20294;&#20351;&#29992;&#26368;&#23567;&#21270;CRPS&#30340;&#26435;&#37325;&#25216;&#26415;&#24182;&#19981;&#33021;&#24102;&#26469;&#26356;&#39640;&#30340;&#21033;&#28070;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#27010;&#29575;&#30340;&#20215;&#26684;&#39044;&#27979;&#22312;&#30005;&#21147;&#20132;&#26131;&#20013;&#24341;&#36215;&#20102;&#20851;&#27880;&#65292;&#22240;&#20026;&#22522;&#20110;&#36825;&#31181;&#39044;&#27979;&#30340;&#20915;&#31574;&#21487;&#20197;&#27604;&#20165;&#20165;&#22522;&#20110;&#28857;&#39044;&#27979;&#33719;&#24471;&#26174;&#33879;&#26356;&#39640;&#30340;&#21033;&#28070;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#27491;&#22312;&#24320;&#21457;&#26041;&#27861;&#26469;&#32467;&#21512;&#39044;&#27979;&#20998;&#24067;&#65292;&#22240;&#20026;&#27809;&#26377;&#19968;&#20010;&#27169;&#22411;&#26159;&#23436;&#32654;&#30340;&#65292;&#24179;&#22343;&#36890;&#24120;&#21487;&#20197;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#20351;&#29992;CRPS&#23398;&#20064;&#30340;&#26435;&#37325;&#25216;&#26415;&#65288;&#26368;&#23567;&#21270;&#36830;&#32493;&#25490;&#21517;&#27010;&#29575;&#35780;&#20998;&#65289;&#26159;&#21542;&#22312;&#25552;&#21069;&#31454;&#26631;&#20013;&#23548;&#33268;&#26368;&#20339;&#20915;&#31574;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#23454;&#35777;&#30740;&#31350;&#65292;&#20351;&#29992;&#20102;&#26469;&#33258;&#24503;&#22269;EPEX&#24066;&#22330;&#30340;&#23567;&#26102;&#32423;&#25552;&#21069;&#30005;&#21147;&#20215;&#26684;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22686;&#21152;&#38598;&#21512;&#30340;&#22810;&#26679;&#24615;&#21487;&#20197;&#23545;&#20934;&#30830;&#24615;&#20135;&#29983;&#31215;&#26497;&#24433;&#21709;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#19982;&#31561;&#26435;&#37325;&#32858;&#21512;&#20998;&#24067;&#30456;&#27604;&#65292;&#20351;&#29992;CRPS&#23398;&#20064;&#30340;&#36739;&#39640;&#35745;&#31639;&#25104;&#26412;&#19981;&#33021;&#36890;&#36807;&#26356;&#39640;&#30340;&#21033;&#28070;&#26469;&#25269;&#28040;&#65292;&#23613;&#31649;&#39044;&#27979;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic price forecasting has recently gained attention in power trading because decisions based on such predictions can yield significantly higher profits than those made with point forecasts alone. At the same time, methods are being developed to combine predictive distributions, since no model is perfect and averaging generally improves forecasting performance. In this article we address the question of whether using CRPS learning, a novel weighting technique minimizing the continuous ranked probability score (CRPS), leads to optimal decisions in day-ahead bidding. To this end, we conduct an empirical study using hourly day-ahead electricity prices from the German EPEX market. We find that increasing the diversity of an ensemble can have a positive impact on accuracy. At the same time, the higher computational cost of using CRPS learning compared to an equal-weighted aggregation of distributions is not offset by higher profits, despite significantly more accurate predictions.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#29305;&#24449;&#36924;&#36817;&#22312;&#19968;&#33324;&#35889;&#26041;&#27861;&#20013;&#30340;&#24212;&#29992;&#65292;&#20998;&#26512;&#20102;&#19982;&#38543;&#26426;&#29305;&#24449;&#30456;&#32467;&#21512;&#30340;&#35889;&#27491;&#21017;&#21270;&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#24182;&#33719;&#24471;&#20102;&#22312;&#19981;&#21516;&#27491;&#21017;&#24615;&#31867;&#21035;&#20013;&#30340;&#26368;&#20339;&#23398;&#20064;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.15434</link><description>&lt;p&gt;
&#38024;&#23545;&#19968;&#33324;&#35889;&#26041;&#27861;&#30340;&#38543;&#26426;&#29305;&#24449;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Random feature approximation for general spectral methods. (arXiv:2308.15434v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#29305;&#24449;&#36924;&#36817;&#22312;&#19968;&#33324;&#35889;&#26041;&#27861;&#20013;&#30340;&#24212;&#29992;&#65292;&#20998;&#26512;&#20102;&#19982;&#38543;&#26426;&#29305;&#24449;&#30456;&#32467;&#21512;&#30340;&#35889;&#27491;&#21017;&#21270;&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#24182;&#33719;&#24471;&#20102;&#22312;&#19981;&#21516;&#27491;&#21017;&#24615;&#31867;&#21035;&#20013;&#30340;&#26368;&#20339;&#23398;&#20064;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#36924;&#36817;&#34987;&#35748;&#20026;&#26159;&#22312;&#22823;&#35268;&#27169;&#31639;&#27861;&#20013;&#21152;&#36895;&#26680;&#26041;&#27861;&#30340;&#26368;&#27969;&#34892;&#25216;&#26415;&#20043;&#19968;&#65292;&#24182;&#19988;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19982;&#38543;&#26426;&#29305;&#24449;&#30456;&#32467;&#21512;&#30340;&#19968;&#22823;&#31867;&#35889;&#27491;&#21017;&#21270;&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#20854;&#20013;&#21253;&#25324;&#20351;&#29992;&#38544;&#24335;&#27491;&#21017;&#21270;&#65288;&#22914;&#26799;&#24230;&#19979;&#38477;&#65289;&#25110;&#26174;&#24335;&#26041;&#27861;&#65288;&#22914;Tikhonov&#27491;&#21017;&#21270;&#65289;&#30340;&#26680;&#26041;&#27861;&#12290;&#23545;&#20110;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#22312;&#36866;&#24403;&#30340;&#28304;&#26465;&#20214;&#19979;&#23450;&#20041;&#20102;&#27491;&#21017;&#24615;&#31867;&#21035;&#65292;&#20174;&#32780;&#33719;&#24471;&#20102;&#26368;&#20339;&#30340;&#23398;&#20064;&#36895;&#29575;&#12290;&#36825;&#25913;&#36827;&#25110;&#23436;&#21892;&#20102;&#20197;&#21069;&#22312;&#29305;&#23450;&#26680;&#31639;&#27861;&#30456;&#20851;&#35774;&#32622;&#20013;&#33719;&#24471;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random feature approximation is arguably one of the most popular techniques to speed up kernel methods in large scale algorithms and provides a theoretical approach to the analysis of deep neural networks. We analyze generalization properties for a large class of spectral regularization methods combined with random features, containing kernel methods with implicit regularization such as gradient descent or explicit methods like Tikhonov regularization. For our estimators we obtain optimal learning rates over regularity classes (even for classes that are not included in the reproducing kernel Hilbert space), which are defined through appropriate source conditions. This improves or completes previous results obtained in related settings for specific kernel algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#21709;&#24212;&#24322;&#26041;&#24046;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#22238;&#24402;&#12289;&#20998;&#31867;&#21644;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#36817;&#20284;&#21518;&#39564;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#22312;&#25429;&#25417;&#20989;&#25968;&#24179;&#28369;&#24615;&#30340;&#31361;&#21464;&#21644;&#36866;&#24212;&#24322;&#26041;&#24046;&#38169;&#35823;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.15370</link><description>&lt;p&gt;
&#22810;&#21709;&#24212;&#24322;&#26041;&#24046;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#21450;&#20854;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Multi-Response Heteroscedastic Gaussian Process Models and Their Inference. (arXiv:2308.15370v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#21709;&#24212;&#24322;&#26041;&#24046;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#22238;&#24402;&#12289;&#20998;&#31867;&#21644;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#36817;&#20284;&#21518;&#39564;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#22312;&#25429;&#25417;&#20989;&#25968;&#24179;&#28369;&#24615;&#30340;&#31361;&#21464;&#21644;&#36866;&#24212;&#24322;&#26041;&#24046;&#38169;&#35823;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#34987;&#24191;&#27867;&#29992;&#20110;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#24314;&#27169;&#65292;&#20294;&#23427;&#20204;&#22312;&#26377;&#25928;&#25429;&#25417;&#20989;&#25968;&#24179;&#28369;&#24615;&#30340;&#31361;&#21464;&#21644;&#36866;&#24212;&#24322;&#26041;&#24046;&#38169;&#35823;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24322;&#26041;&#24046;&#39640;&#26031;&#36807;&#31243;&#65288;HeGP&#65289;&#22238;&#24402;&#26088;&#22312;&#36890;&#36807;&#25215;&#35748;&#22238;&#24402;&#27169;&#22411;&#20013;&#21327;&#21464;&#37327;&#38388;&#27531;&#24046;&#26041;&#24046;&#30340;&#21487;&#21464;&#24615;&#26469;&#24341;&#20837;&#28789;&#27963;&#24615;&#12290;&#26412;&#25991;&#23558;HeGP&#27010;&#24565;&#25193;&#23637;&#21040;&#20998;&#31867;&#21644;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#39640;&#26031;&#36807;&#31243;&#19982;&#21327;&#21464;&#37327;&#35825;&#23548;&#30340;&#31934;&#24230;&#30697;&#38453;&#36807;&#31243;&#30456;&#32467;&#21512;&#65292;&#37319;&#29992;&#28151;&#21512;&#24418;&#24335;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#24471;&#21487;&#20197;&#23545;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#24322;&#26041;&#24046;&#21327;&#26041;&#24046;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#12290;&#20026;&#20102;&#35299;&#20915;&#37319;&#26679;&#24102;&#26469;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#25105;&#20204;&#37319;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#36817;&#20284;&#21518;&#39564;&#24182;&#20415;&#21033;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the widespread utilization of Gaussian process models for versatile nonparametric modeling, they exhibit limitations in effectively capturing abrupt changes in function smoothness and accommodating relationships with heteroscedastic errors. Addressing these shortcomings, the heteroscedastic Gaussian process (HeGP) regression seeks to introduce flexibility by acknowledging the variability of residual variances across covariates in the regression model. In this work, we extend the HeGP concept, expanding its scope beyond regression tasks to encompass classification and state-space models. To achieve this, we propose a novel framework where the Gaussian process is coupled with a covariate-induced precision matrix process, adopting a mixture formulation. This approach enables the modeling of heteroscedastic covariance functions across covariates. To mitigate the computational challenges posed by sampling, we employ variational inference to approximate the posterior and facilitate p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32852;&#21512;&#24314;&#27169;&#22810;&#20010;&#24322;&#26500;&#30456;&#20851;&#20219;&#21153;&#30340;&#25193;&#23637;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#65288;MOGP&#65289;&#20419;&#36827;&#20219;&#21153;&#20043;&#38388;&#30340;&#20449;&#24687;&#20849;&#20139;&#21644;&#38750;&#21442;&#25968;&#21442;&#25968;&#20272;&#35745;&#65292;&#24182;&#24212;&#29992;&#25968;&#25454;&#22686;&#24191;&#25216;&#26415;&#26469;&#35299;&#20915;&#38750;&#20849;&#36717;&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.15364</link><description>&lt;p&gt;
&#24322;&#26500;&#22810;&#20219;&#21153;&#39640;&#26031;Cox&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous Multi-Task Gaussian Cox Processes. (arXiv:2308.15364v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32852;&#21512;&#24314;&#27169;&#22810;&#20010;&#24322;&#26500;&#30456;&#20851;&#20219;&#21153;&#30340;&#25193;&#23637;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#65288;MOGP&#65289;&#20419;&#36827;&#20219;&#21153;&#20043;&#38388;&#30340;&#20449;&#24687;&#20849;&#20139;&#21644;&#38750;&#21442;&#25968;&#21442;&#25968;&#20272;&#35745;&#65292;&#24182;&#24212;&#29992;&#25968;&#25454;&#22686;&#24191;&#25216;&#26415;&#26469;&#35299;&#20915;&#38750;&#20849;&#36717;&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;Cox&#36807;&#31243;&#30340;&#25193;&#23637;&#65292;&#29992;&#20110;&#32852;&#21512;&#24314;&#27169;&#22810;&#20010;&#24322;&#26500;&#30456;&#20851;&#20219;&#21153;&#65292;&#20363;&#22914;&#20998;&#31867;&#21644;&#22238;&#24402;&#65292;&#36890;&#36807;&#22810;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#65288;MOGP&#65289;&#12290;&#36890;&#36807;&#23545;&#20998;&#31867;&#12289;&#22238;&#24402;&#21644;&#28857;&#36807;&#31243;&#20219;&#21153;&#30340;&#19987;&#29992;&#20284;&#28982;&#21442;&#25968;&#24341;&#20837;MOGP&#20808;&#39564;&#65292;&#21487;&#20197;&#20419;&#36827;&#24322;&#26500;&#20219;&#21153;&#20043;&#38388;&#30340;&#20449;&#24687;&#20849;&#20139;&#65292;&#21516;&#26102;&#20801;&#35768;&#38750;&#21442;&#25968;&#21442;&#25968;&#20272;&#35745;&#12290;&#20026;&#20102;&#20811;&#26381;MOGP&#35843;&#21046;&#30340;&#24322;&#26500;&#22810;&#20219;&#21153;&#26694;&#26550;&#20013;&#30340;&#38750;&#20849;&#36717;&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#29992;&#25968;&#25454;&#22686;&#24191;&#25216;&#26415;&#65292;&#24182;&#23548;&#20986;&#22343;&#22330;&#36817;&#20284;&#26469;&#23454;&#29616;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#38381;&#24335;&#36845;&#20195;&#26356;&#26032;&#12290;&#25105;&#20204;&#22312;1D&#21512;&#25104;&#25968;&#25454;&#21644;&#28201;&#21733;&#21326;&#30340;2D&#22478;&#24066;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#24615;&#33021;&#21644;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel extension of multi-task Gaussian Cox processes for modeling multiple heterogeneous correlated tasks jointly, e.g., classification and regression, via multi-output Gaussian processes (MOGP). A MOGP prior over the parameters of the dedicated likelihoods for classification, regression and point process tasks can facilitate sharing of information between heterogeneous tasks, while allowing for nonparametric parameter estimation. To circumvent the non-conjugate Bayesian inference in the MOGP modulated heterogeneous multi-task framework, we employ the data augmentation technique and derive a mean-field approximation to realize closed-form iterative updates for estimating model parameters. We demonstrate the performance and inference on both 1D synthetic data as well as 2D urban data of Vancouver.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;(SSMs)&#21644;&#33258;&#30417;&#30563;&#23398;&#20064;&#26469;&#25913;&#21892;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#33258;&#21160;&#24515;&#30005;&#22270;&#20998;&#26512;&#20013;&#30340;&#23450;&#37327;&#20934;&#30830;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;SSMs&#21487;&#20197;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#19988;&#22312;&#26631;&#20934;&#35786;&#26029;&#20219;&#21153;&#20013;&#65292;&#36739;&#39640;&#30340;&#37319;&#26679;&#29575;&#21644;&#25193;&#22823;&#36755;&#20837;&#23610;&#23544;&#24182;&#27809;&#26377;&#26126;&#26174;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.15291</link><description>&lt;p&gt;
&#36808;&#21521;&#24515;&#30005;&#22270;&#20998;&#26512;&#30340;&#23450;&#37327;&#31934;&#30830;&#24615;&#65306;&#21033;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#12289;&#33258;&#30417;&#30563;&#23398;&#20064;&#21644;&#24739;&#32773;&#20803;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Towards quantitative precision for ECG analysis: Leveraging state space models, self-supervision and patient metadata. (arXiv:2308.15291v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15291
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;(SSMs)&#21644;&#33258;&#30417;&#30563;&#23398;&#20064;&#26469;&#25913;&#21892;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#33258;&#21160;&#24515;&#30005;&#22270;&#20998;&#26512;&#20013;&#30340;&#23450;&#37327;&#20934;&#30830;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;SSMs&#21487;&#20197;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#19988;&#22312;&#26631;&#20934;&#35786;&#26029;&#20219;&#21153;&#20013;&#65292;&#36739;&#39640;&#30340;&#37319;&#26679;&#29575;&#21644;&#25193;&#22823;&#36755;&#20837;&#23610;&#23544;&#24182;&#27809;&#26377;&#26126;&#26174;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#24050;&#25104;&#20026;&#33258;&#21160;&#24515;&#30005;&#22270;&#20998;&#26512;&#30340;&#39318;&#36873;&#24314;&#27169;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19977;&#20010;&#26088;&#22312;&#25552;&#39640;&#36825;&#31181;&#31995;&#32479;&#23450;&#37327;&#20934;&#30830;&#24615;&#30340;&#35201;&#32032;&#12290;&#36825;&#20123;&#32452;&#20214;&#22987;&#32456;&#36229;&#36234;&#20102;&#22522;&#20110;&#21367;&#31215;&#27169;&#22411;&#30340;&#29616;&#26377;&#26368;&#20808;&#36827;&#25216;&#26415;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;(SSMs)&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#38271;&#26399;&#20381;&#36182;&#26041;&#38754;&#26174;&#31034;&#20102;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;&#36890;&#36807;&#23558;SSMs&#32435;&#20837;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#19981;&#20165;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#36824;&#23545;&#35813;&#39046;&#22495;&#30340;&#38271;&#26399;&#30456;&#20851;&#38382;&#39064;&#26377;&#20102;&#26356;&#28145;&#30340;&#29702;&#35299;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#26631;&#20934;&#35786;&#26029;&#20219;&#21153;&#65292;&#25105;&#20204;&#21457;&#29616;&#19982;100Hz&#30456;&#27604;&#65292;&#20351;&#29992;500Hz&#31561;&#26356;&#39640;&#37319;&#26679;&#29575;&#27809;&#26377;&#20248;&#21183;&#12290;&#31867;&#20284;&#22320;&#65292;&#23558;&#27169;&#22411;&#30340;&#36755;&#20837;&#23610;&#23544;&#25193;&#22823;&#21040;3&#31186;&#20197;&#19978;&#20063;&#27809;&#26377;&#24102;&#26469;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#23545;&#27604;&#39044;&#27979;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#33021;&#22815;&#22686;&#24378;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#36825;&#26159;&#31532;&#20108;&#20010;&#35201;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has emerged as the preferred modeling approach for automatic ECG analysis. In this study, we investigate three elements aimed at improving the quantitative accuracy of such systems. These components consistently enhance performance beyond the existing state-of-the-art, which is predominantly based on convolutional models. Firstly, we explore more expressive architectures by exploiting structured state space models (SSMs). These models have shown promise in capturing long-term dependencies in time series data. By incorporating SSMs into our approach, we not only achieve better performance, but also gain insights into long-standing questions in the field. Specifically, for standard diagnostic tasks, we find no advantage in using higher sampling rates such as 500Hz compared to 100Hz. Similarly, extending the input size of the model beyond 3 seconds does not lead to significant improvements. Secondly, we demonstrate that self-supervised learning using contrastive predictive c
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#21644;LASSO&#30340;&#23567;&#21306;&#22495;&#20272;&#35745;&#26041;&#27861;&#65292;&#22312;&#21482;&#26377;&#37096;&#20998;&#21306;&#22495;&#26377;&#37319;&#26679;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21033;&#29992;&#36741;&#21161;&#21464;&#37327;&#23545;&#32467;&#26524;&#36827;&#34892;&#39044;&#27979;&#12290;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#26041;&#27861;&#30340;&#25928;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#25286;&#20998;&#21512;&#35268;&#31243;&#24207;&#65292;&#25918;&#23485;&#20102;&#25968;&#25454;&#20998;&#24067;&#30340;&#20551;&#35774;&#12290;&#35813;&#30740;&#31350;&#20197;&#21152;&#32435;&#30340;&#25968;&#25454;&#20026;&#20363;&#65292;&#20272;&#35745;&#20102;&#23478;&#24237;&#28040;&#36153;&#30340;&#22343;&#20540;&#12290;</title><link>http://arxiv.org/abs/2308.15180</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#21644;LASSO&#30340;&#23567;&#21306;&#22495;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Small Area Estimation with Random Forests and the LASSO. (arXiv:2308.15180v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15180
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#21644;LASSO&#30340;&#23567;&#21306;&#22495;&#20272;&#35745;&#26041;&#27861;&#65292;&#22312;&#21482;&#26377;&#37096;&#20998;&#21306;&#22495;&#26377;&#37319;&#26679;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21033;&#29992;&#36741;&#21161;&#21464;&#37327;&#23545;&#32467;&#26524;&#36827;&#34892;&#39044;&#27979;&#12290;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#26041;&#27861;&#30340;&#25928;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#25286;&#20998;&#21512;&#35268;&#31243;&#24207;&#65292;&#25918;&#23485;&#20102;&#25968;&#25454;&#20998;&#24067;&#30340;&#20551;&#35774;&#12290;&#35813;&#30740;&#31350;&#20197;&#21152;&#32435;&#30340;&#25968;&#25454;&#20026;&#20363;&#65292;&#20272;&#35745;&#20102;&#23478;&#24237;&#28040;&#36153;&#30340;&#22343;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38656;&#35201;&#20272;&#35745;&#30340;&#24635;&#21306;&#22495;&#20013;&#65292;&#20165;&#26377;&#37096;&#20998;&#21306;&#22495;&#20855;&#26377;&#37319;&#26679;&#25968;&#25454;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#21644;LASSO&#26041;&#27861;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#23567;&#21306;&#22495;&#20272;&#35745;&#12290;&#37319;&#26679;&#21306;&#22495;&#26377;&#22823;&#37327;&#30340;&#36741;&#21161;&#20449;&#24687;&#26469;&#33258;&#35843;&#26597;&#65292;&#32780;&#25152;&#26377;&#21306;&#22495;&#37117;&#26377;&#26469;&#33258;&#22806;&#37096;&#26469;&#28304;&#30340;&#36741;&#21161;&#20449;&#24687;&#65292;&#24182;&#19988;&#30446;&#26631;&#26159;&#20351;&#29992;&#36741;&#21161;&#21464;&#37327;&#26469;&#39044;&#27979;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#21306;&#22495;&#32423;&#21035;&#30340;&#38543;&#26426;&#26862;&#26519;&#21644;LASSO&#26041;&#27861;&#19982;&#39057;&#29575;&#20027;&#20041;&#30340;&#21069;&#21521;&#21464;&#37327;&#36873;&#25321;&#26041;&#27861;&#21644;&#36125;&#21494;&#26031;&#25910;&#32553;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#34913;&#37327;&#20174;&#38543;&#26426;&#26862;&#26519;&#21644;LASSO&#33719;&#24471;&#30340;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#25286;&#20998;&#21512;&#35268;&#31243;&#24207;&#65292;&#25918;&#23485;&#20102;&#25968;&#25454;&#30456;&#21516;&#20998;&#24067;&#30340;&#20551;&#35774;&#12290;&#36825;&#39033;&#24037;&#20316;&#21463;&#21040;&#20102;&#26469;&#33258;&#21152;&#32435;&#31532;&#20845;&#27425;&#29983;&#27963;&#26631;&#20934;&#35843;&#26597;&#65288;GLSS&#65289;&#21644;2010&#24180;&#20154;&#21475;&#21644;&#20303;&#25151;&#26222;&#26597;&#30340;&#25968;&#25454;&#30340;&#21551;&#21457;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20004;&#20010;&#25968;&#25454;&#38598;&#20272;&#35745;&#20102;&#21306;&#22495;&#30340;&#23478;&#24237;&#23545;&#25968;&#28040;&#36153;&#30340;&#22343;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider random forests and LASSO methods for model-based small area estimation when the number of areas with sampled data is a small fraction of the total areas for which estimates are required. Abundant auxiliary information is available for the sampled areas, from the survey, and for all areas, from an exterior source, and the goal is to use auxiliary variables to predict the outcome of interest. We compare areal-level random forests and LASSO approaches to a frequentist forward variable selection approach and a Bayesian shrinkage method. Further, to measure the uncertainty of estimates obtained from random forests and the LASSO, we propose a modification of the split conformal procedure that relaxes the assumption of identically distributed data. This work is motivated by Ghanaian data available from the sixth Living Standard Survey (GLSS) and the 2010 Population and Housing Census. We estimate the areal mean household log consumption using both datasets. The outcome variable is
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#20301;&#25968;&#22238;&#24402;&#26657;&#20934;&#23454;&#29616;&#22522;&#20110;&#32676;&#20307;&#26465;&#20214;&#30340;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#39044;&#27979;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#24212;&#29992;&#20110;&#23454;&#38469;&#20892;&#19994;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#30340;&#20316;&#29289;&#19982;&#26434;&#33609;&#20998;&#31867;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.15094</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#20301;&#25968;&#22238;&#24402;&#26657;&#20934;&#23454;&#29616;&#22522;&#20110;&#32676;&#20307;&#26465;&#20214;&#30340;&#31526;&#21512;&#39044;&#27979;&#65292;&#29992;&#20110;&#20316;&#29289;&#19982;&#26434;&#33609;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Group-Conditional Conformal Prediction via Quantile Regression Calibration for Crop and Weed Classification. (arXiv:2308.15094v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15094
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#20301;&#25968;&#22238;&#24402;&#26657;&#20934;&#23454;&#29616;&#22522;&#20110;&#32676;&#20307;&#26465;&#20214;&#30340;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#39044;&#27979;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#24212;&#29992;&#20110;&#23454;&#38469;&#20892;&#19994;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#30340;&#20316;&#29289;&#19982;&#26434;&#33609;&#20998;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#39044;&#27979;&#27169;&#22411;&#25104;&#20026;&#31934;&#20934;&#20892;&#19994;&#31995;&#32479;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#19968;&#37096;&#20998;&#65292;&#19968;&#20010;&#38459;&#30861;&#37319;&#29992;&#36825;&#20123;&#33258;&#21160;&#21270;&#35299;&#20915;&#26041;&#26696;&#30340;&#38556;&#30861;&#26159;&#29992;&#25143;&#23545;&#36825;&#20123;&#39640;&#24230;&#22797;&#26434;&#12289;&#19981;&#36879;&#26126;&#21644;&#19981;&#30830;&#23450;&#30340;&#27169;&#22411;&#32570;&#20047;&#20449;&#20219;&#12290;&#23454;&#38469;&#19978;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27809;&#26377;&#20219;&#20309;&#26126;&#30830;&#30340;&#20445;&#35777;&#65292;&#21487;&#20197;&#29992;&#26469;&#35777;&#26126;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#22312;&#39640;&#24230;&#21464;&#21270;&#30340;&#20197;&#21450;&#26080;&#27861;&#25511;&#21046;&#30340;&#29615;&#22659;&#20013;&#65292;&#27604;&#22914;&#20856;&#22411;&#30340;&#20892;&#19994;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#25152;&#38754;&#20020;&#30340;&#29615;&#22659;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#20854;&#20182;&#39046;&#22495;&#24320;&#21457;&#30340;&#26576;&#20123;&#26041;&#27861;&#23545;&#20892;&#19994;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23545;&#20219;&#20309;&#40657;&#30418;&#23376;&#39044;&#27979;&#26426;&#22120;&#30340;&#39044;&#27979;&#24615;&#33021;&#25552;&#20379;&#26377;&#25928;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#20960;&#20046;&#19981;&#38656;&#35201;&#20219;&#20309;&#20551;&#35774;&#65292;&#24212;&#29992;&#20110;&#23454;&#38469;&#26465;&#20214;&#19979;&#30340;&#28145;&#24230;&#21487;&#35270;&#21270;&#26434;&#33609;&#21644;&#20316;&#29289;&#20998;&#31867;&#38382;&#39064;&#12290;&#26412;&#25991;&#37325;&#28857;&#20171;&#32461;&#20102;&#26694;&#26550;&#30340;&#23454;&#38469;&#26041;&#38754;&#65292;&#24182;&#29305;&#21035;&#27880;&#24847;&#20102;&#32454;&#33410;&#12290;
&lt;/p&gt;
&lt;p&gt;
As deep learning predictive models become an integral part of a large spectrum of precision agricultural systems, a barrier to the adoption of such automated solutions is the lack of user trust in these highly complex, opaque and uncertain models. Indeed, deep neural networks are not equipped with any explicit guarantees that can be used to certify the system's performance, especially in highly varying uncontrolled environments such as the ones typically faced in computer vision for agriculture.Fortunately, certain methods developed in other communities can prove to be important for agricultural applications. This article presents the conformal prediction framework that provides valid statistical guarantees on the predictive performance of any black box prediction machine, with almost no assumptions, applied to the problem of deep visual classification of weeds and crops in real-world conditions. The framework is exposed with a focus on its practical aspects and special attention accor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#24230;&#26657;&#27491;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;(DCMM)&#26469;&#24314;&#27169;&#32593;&#32476;&#65292;&#25512;&#23548;&#20102;&#25104;&#21592;&#28151;&#21512;&#27010;&#29575;&#30340;&#26377;&#38480;&#26679;&#26412;&#25193;&#23637;&#65292;&#22635;&#34917;&#20102;&#20851;&#20110;&#25104;&#21592;&#37197;&#32622;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#37325;&#35201;&#31354;&#30333;&#12290;&#21516;&#26102;&#65292;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#25104;&#21592;&#28151;&#21512;&#27010;&#29575;&#30340;&#39030;&#28857;&#25490;&#21517;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2308.14988</link><description>&lt;p&gt;
&#20851;&#20110;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;&#20013;&#28151;&#21512;&#27010;&#29575;&#21644;&#25490;&#21517;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inferences on Mixing Probabilities and Ranking in Mixed-Membership Models. (arXiv:2308.14988v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#24230;&#26657;&#27491;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;(DCMM)&#26469;&#24314;&#27169;&#32593;&#32476;&#65292;&#25512;&#23548;&#20102;&#25104;&#21592;&#28151;&#21512;&#27010;&#29575;&#30340;&#26377;&#38480;&#26679;&#26412;&#25193;&#23637;&#65292;&#22635;&#34917;&#20102;&#20851;&#20110;&#25104;&#21592;&#37197;&#32622;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#37325;&#35201;&#31354;&#30333;&#12290;&#21516;&#26102;&#65292;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#25104;&#21592;&#28151;&#21512;&#27010;&#29575;&#30340;&#39030;&#28857;&#25490;&#21517;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#25968;&#25454;&#22312;&#35768;&#22810;&#22823;&#25968;&#25454;&#24212;&#29992;&#20013;&#38750;&#24120;&#24120;&#35265;&#65292;&#21253;&#25324;&#32463;&#27982;&#21644;&#20581;&#24247;&#32593;&#32476;&#65292;&#20102;&#35299;&#32593;&#32476;&#30340;&#28508;&#22312;&#32467;&#26500;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#20351;&#29992;&#24230;&#26657;&#27491;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;(DCMM)&#26469;&#24314;&#27169;&#32593;&#32476;&#12290;&#22312;DCMM&#27169;&#22411;&#20013;&#65292;&#23545;&#20110;&#27599;&#20010;&#33410;&#28857;$i$&#65292;&#23384;&#22312;&#19968;&#20010;&#25104;&#21592;&#21521;&#37327;$\boldsymbol{\pi}_ i = (\boldsymbol{\pi}_i(1), \boldsymbol{\pi}_i(2),\ldots, \boldsymbol{\pi}_i(K))$&#65292;&#20854;&#20013;$\boldsymbol{\pi}_i(k)$&#34920;&#31034;&#33410;&#28857;$i$&#22312;&#31038;&#21306;$k$&#20013;&#30340;&#26435;&#37325;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20851;&#20110;$\boldsymbol{\pi}_i(k)$&#30340;&#26032;&#39062;&#30340;&#26377;&#38480;&#26679;&#26412;&#25193;&#23637;&#65292;&#20174;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#25104;&#21592;&#28151;&#21512;&#27010;&#29575;&#21644;&#20854;&#20182;&#30456;&#20851;&#24635;&#20307;&#25968;&#37327;&#30340;&#28176;&#36817;&#20998;&#24067;&#21644;&#32622;&#20449;&#21306;&#38388;&#12290;&#36825;&#22635;&#34917;&#20102;&#20851;&#20110;&#25104;&#21592;&#37197;&#32622;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#37325;&#35201;&#31354;&#30333;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#22522;&#20110;&#29305;&#23450;&#31038;&#21306;&#20013;&#30340;&#25104;&#21592;&#28151;&#21512;&#27010;&#29575;&#24320;&#21457;&#20102;&#19968;&#20010;&#39030;&#28857;&#25490;&#21517;&#26041;&#26696;&#65292;&#24182;&#36827;&#34892;&#30456;&#20851;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network data is prevalent in numerous big data applications including economics and health networks where it is of prime importance to understand the latent structure of network. In this paper, we model the network using the Degree-Corrected Mixed Membership (DCMM) model. In DCMM model, for each node $i$, there exists a membership vector $\boldsymbol{\pi}_ i = (\boldsymbol{\pi}_i(1), \boldsymbol{\pi}_i(2),\ldots, \boldsymbol{\pi}_i(K))$, where $\boldsymbol{\pi}_i(k)$ denotes the weight that node $i$ puts in community $k$. We derive novel finite-sample expansion for the $\boldsymbol{\pi}_i(k)$s which allows us to obtain asymptotic distributions and confidence interval of the membership mixing probabilities and other related population quantities. This fills an important gap on uncertainty quantification on the membership profile. We further develop a ranking scheme of the vertices based on the membership mixing probabilities on certain communities and perform relevant statistical infere
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximal&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#32473;&#23450;&#30340;&#28508;&#21183;&#20989;&#25968;&#30830;&#23450;&#24615;&#22320;&#36827;&#34892;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#25552;&#20379;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#21644;&#36895;&#24230;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.14945</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximals&#23454;&#29616;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Noise-Free Sampling Algorithms via Regularized Wasserstein Proximals. (arXiv:2308.14945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximal&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#32473;&#23450;&#30340;&#28508;&#21183;&#20989;&#25968;&#30830;&#23450;&#24615;&#22320;&#36827;&#34892;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#25552;&#20379;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#21644;&#36895;&#24230;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#30001;&#28508;&#21183;&#20989;&#25968;&#25511;&#21046;&#30340;&#20998;&#24067;&#25277;&#26679;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26174;&#24335;&#30340;&#22522;&#20110;&#35780;&#20998;&#30340;&#30830;&#23450;&#24615;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#20351;&#24471;&#31890;&#23376;&#30340;&#28436;&#21270;&#21464;&#20026;&#30830;&#23450;&#24615;&#30340;&#65292;&#32780;&#19981;&#26159;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#28436;&#21270;&#12290;&#35780;&#20998;&#39033;&#30001;&#27491;&#21017;&#21270;&#30340;Wasserstein proximal&#20197;&#38381;&#21512;&#24418;&#24335;&#32473;&#20986;&#65292;&#20351;&#29992;&#37319;&#26679;&#26469;&#36817;&#20284;&#26680;&#21367;&#31215;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#24555;&#36895;&#25910;&#25947;&#65292;&#24182;&#19988;&#19982;&#26410;&#35843;&#25972;Langevin&#31639;&#27861;&#21644;Metropolis&#35843;&#25972;Langevin&#31639;&#27861;&#30456;&#27604;&#65292;&#26174;&#31034;&#20102;&#39640;&#26031;&#20998;&#24067;&#30340;&#28151;&#21512;&#26102;&#38388;&#36793;&#30028;&#30340;&#25913;&#21892;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#20108;&#27425;&#28508;&#21183;&#20989;&#25968;&#27599;&#27425;&#36845;&#20195;&#30340;&#20998;&#24067;&#30340;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#65292;&#34920;&#24449;&#20102;&#26041;&#24046;&#38477;&#20302;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#31890;&#23376;&#30340;&#34892;&#20026;&#26159;&#26377;&#32452;&#32455;&#30340;&#65292;&#20301;&#20110;&#28508;&#21183;&#30340;&#31561;&#20540;&#32447;&#19978;&#12290;&#27492;&#22806;&#65292;&#21518;&#39564;&#22343;&#20540;&#20272;&#35745;&#32467;&#26524;&#26174;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sampling from a distribution governed by a potential function. This work proposes an explicit score-based MCMC method that is deterministic, resulting in a deterministic evolution for particles rather than a stochastic differential equation evolution. The score term is given in closed form by a regularized Wasserstein proximal, using a kernel convolution that is approximated by sampling. We demonstrate fast convergence on various problems and show improved dimensional dependence of mixing time bounds for the case of Gaussian distributions compared to the unadjusted Langevin algorithm (ULA) and the Metropolis-adjusted Langevin algorithm (MALA). We additionally derive closed form expressions for the distributions at each iterate for quadratic potential functions, characterizing the variance reduction. Empirical results demonstrate that the particles behave in an organized manner, lying on level set contours of the potential. Moreover, the posterior mean estimat
&lt;/p&gt;</description></item><item><title>BayOTIDE&#26159;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#22312;&#32447;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#19982;&#20989;&#25968;&#20998;&#35299;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#35270;&#20026;&#20302;&#31209;&#26102;&#24207;&#22240;&#23376;&#32452;&#30340;&#21152;&#26435;&#32452;&#21512;&#26469;&#36827;&#34892;&#25554;&#34917;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#20840;&#23616;&#36235;&#21183;&#21644;&#21608;&#26399;&#24615;&#27169;&#24335;&#30340;&#24573;&#30053;&#20197;&#21450;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#22788;&#29702;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.14906</link><description>&lt;p&gt;
BayOTIDE: &#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#22312;&#32447;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#19982;&#20989;&#25968;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition. (arXiv:2308.14906v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14906
&lt;/p&gt;
&lt;p&gt;
BayOTIDE&#26159;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#22312;&#32447;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#19982;&#20989;&#25968;&#20998;&#35299;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#35270;&#20026;&#20302;&#31209;&#26102;&#24207;&#22240;&#23376;&#32452;&#30340;&#21152;&#26435;&#32452;&#21512;&#26469;&#36827;&#34892;&#25554;&#34917;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#20840;&#23616;&#36235;&#21183;&#21644;&#21608;&#26399;&#24615;&#27169;&#24335;&#30340;&#24573;&#30053;&#20197;&#21450;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#22788;&#29702;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#65292;&#22914;&#20132;&#36890;&#21644;&#33021;&#28304;&#65292;&#32463;&#24120;&#35266;&#23519;&#21040;&#20855;&#26377;&#32570;&#22833;&#20540;&#21644;&#22122;&#22768;&#30340;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#29978;&#33267;&#26159;&#19981;&#35268;&#21017;&#37319;&#26679;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#25554;&#34917;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#22823;&#22810;&#25968;&#21482;&#36866;&#29992;&#20110;&#23616;&#37096;&#35270;&#35282;&#65292;&#21363;&#23558;&#38271;&#24207;&#21015;&#25286;&#20998;&#20026;&#36866;&#24403;&#22823;&#23567;&#30340;&#25209;&#27425;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#31181;&#23616;&#37096;&#35270;&#35282;&#21487;&#33021;&#20351;&#27169;&#22411;&#24573;&#30053;&#20840;&#23616;&#36235;&#21183;&#25110;&#21608;&#26399;&#24615;&#27169;&#24335;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#20960;&#20046;&#25152;&#26377;&#26041;&#27861;&#37117;&#20551;&#35774;&#35266;&#27979;&#20540;&#22312;&#35268;&#21017;&#30340;&#26102;&#38388;&#38388;&#38548;&#36827;&#34892;&#37319;&#26679;&#65292;&#24182;&#19988;&#26080;&#27861;&#22788;&#29702;&#26469;&#33258;&#19981;&#21516;&#24212;&#29992;&#30340;&#22797;&#26434;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#37117;&#26159;&#22312;&#31163;&#32447;&#29366;&#24577;&#19979;&#36827;&#34892;&#23398;&#20064;&#30340;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#37027;&#20123;&#26377;&#24555;&#36895;&#21040;&#36798;&#30340;&#27969;&#25968;&#25454;&#30340;&#24212;&#29992;&#26469;&#35828;&#65292;&#23427;&#20204;&#24182;&#19981;&#21512;&#36866;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;BayOTIDE&#65306;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#22312;&#32447;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#19982;&#20989;&#25968;&#20998;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world scenarios like traffic and energy, massive time-series data with missing values and noises are widely observed, even sampled irregularly. While many imputation methods have been proposed, most of them work with a local horizon, which means models are trained by splitting the long sequence into batches of fit-sized patches. This local horizon can make models ignore global trends or periodic patterns. More importantly, almost all methods assume the observations are sampled at regular time stamps, and fail to handle complex irregular sampled time series arising from different applications. Thirdly, most existing methods are learned in an offline manner. Thus, it is not suitable for many applications with fast-arriving streaming data. To overcome these limitations, we propose \ours: Bayesian Online Multivariate Time series Imputation with functional decomposition. We treat the multivariate time series as the weighted combination of groups of low-rank temporal factors with dif
&lt;/p&gt;</description></item><item><title>NAS-X&#26159;&#19968;&#31181;&#22522;&#20110;&#25197;&#26354;&#30340;&#31070;&#32463;&#33258;&#36866;&#24212;&#24179;&#28369;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#26469;&#23398;&#20064;&#21644;&#25512;&#26029;&#39034;&#24207;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20248;&#20110;&#20808;&#21069;&#26041;&#27861;&#30340;&#25512;&#26029;&#21644;&#21442;&#25968;&#24674;&#22797;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.14864</link><description>&lt;p&gt;
NAS-X: &#22522;&#20110;&#25197;&#26354;&#30340;&#31070;&#32463;&#33258;&#36866;&#24212;&#24179;&#28369;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
NAS-X: Neural Adaptive Smoothing via Twisting. (arXiv:2308.14864v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14864
&lt;/p&gt;
&lt;p&gt;
NAS-X&#26159;&#19968;&#31181;&#22522;&#20110;&#25197;&#26354;&#30340;&#31070;&#32463;&#33258;&#36866;&#24212;&#24179;&#28369;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#26469;&#23398;&#20064;&#21644;&#25512;&#26029;&#39034;&#24207;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20248;&#20110;&#20808;&#21069;&#26041;&#27861;&#30340;&#25512;&#26029;&#21644;&#21442;&#25968;&#24674;&#22797;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NAS-X&#30340;&#31070;&#32463;&#33258;&#36866;&#24212;&#24179;&#28369;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#37325;&#26032;&#21152;&#26435;&#30340;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#36827;&#34892;&#39034;&#24207;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#23398;&#20064;&#21644;&#25512;&#26029;&#12290;NAS-X&#36866;&#29992;&#20110;&#31163;&#25955;&#21644;&#36830;&#32493;&#28508;&#21464;&#37327;&#65292;&#24182;&#21033;&#29992;&#24179;&#28369;SMC&#26041;&#27861;&#26469;&#25311;&#21512;&#27604;&#20256;&#32479;&#30340;&#37325;&#26032;&#21152;&#26435;&#21796;&#37266;-&#30561;&#30496;&#26041;&#27861;&#26356;&#24191;&#27867;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#20219;&#21153;&#19978;&#27979;&#35797;&#20102;NAS-X&#65292;&#24182;&#21457;&#29616;&#22312;&#25512;&#26029;&#21644;&#21442;&#25968;&#24674;&#22797;&#26041;&#38754;&#65292;&#23427;&#26126;&#26174;&#20248;&#20110;&#20808;&#21069;&#30340;&#21464;&#20998;&#21644;&#22522;&#20110;&#37325;&#26032;&#21152;&#26435;&#21796;&#37266;-&#30561;&#30496;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Neural Adaptive Smoothing via Twisting (NAS-X), a method for learning and inference in sequential latent variable models based on reweighted wake-sleep (RWS). NAS-X works with both discrete and continuous latent variables, and leverages smoothing SMC to fit a broader range of models than traditional RWS methods. We test NAS-X on discrete and continuous tasks and find that it substantially outperforms previous variational and RWS-based methods in inference and parameter recovery.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#32771;&#34385;&#20102;&#22312;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#26102;&#21487;&#33021;&#23384;&#22312;&#30340;&#22810;&#20010;&#36873;&#39033;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#19982;&#29616;&#26377;&#25351;&#26631;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2308.14785</link><description>&lt;p&gt;
&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#19982;&#27425;&#35201;&#36873;&#39033;&#26816;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
A correlation-based fuzzy cluster validity index with secondary options detector. (arXiv:2308.14785v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#32771;&#34385;&#20102;&#22312;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#26102;&#21487;&#33021;&#23384;&#22312;&#30340;&#22810;&#20010;&#36873;&#39033;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#19982;&#29616;&#26377;&#25351;&#26631;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24212;&#29992;&#32858;&#31867;&#20998;&#26512;&#26102;&#65292;&#26368;&#20339;&#32858;&#31867;&#25968;&#37327;&#26159;&#20027;&#35201;&#20851;&#27880;&#28857;&#20043;&#19968;&#12290;&#24050;&#32463;&#24341;&#20837;&#20102;&#22810;&#20010;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#26377;&#22810;&#20010;&#36873;&#39033;&#21487;&#20197;&#20316;&#20026;&#26368;&#32456;&#30340;&#32858;&#31867;&#25968;&#37327;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#22312;&#36825;&#20010;&#39046;&#22495;&#24573;&#35270;&#20102;&#36825;&#19968;&#26041;&#38754;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#31216;&#20026;Wiroonsri-Preedasawakul&#65288;WP&#65289;&#25351;&#26631;&#12290;&#35813;&#25351;&#26631;&#26681;&#25454;&#19968;&#23545;&#25968;&#25454;&#28857;&#30340;&#23454;&#38469;&#36317;&#31163;&#19982;&#30456;&#24212;&#23545;&#30340;&#35843;&#25972;&#36136;&#24515;&#20043;&#38388;&#30340;&#36317;&#31163;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26469;&#23450;&#20041;&#12290;&#25105;&#20204;&#35780;&#20272;&#24182;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#25351;&#26631;&#19982;Xie-Beni&#65292;Pakhira-Bandyopadhyay-Maulik&#65292;Tang&#65292;Wu-Li&#65292;&#24191;&#20041;C&#21644;Kwon2&#31561;&#20960;&#20010;&#29616;&#26377;&#25351;&#26631;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65306;&#20154;&#24037;&#25968;&#25454;&#38598;&#65292;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65292;&#24102;&#26377;&#31561;&#32423;&#30340;&#27169;&#25311;&#25968;&#25454;&#38598;&#21644;&#22270;&#20687;&#25968;&#25454;&#38598;&#65292;&#20351;&#29992;&#27169;&#31946;c-mea&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The optimal number of clusters is one of the main concerns when applying cluster analysis. Several cluster validity indexes have been introduced to address this problem. However, in some situations, there is more than one option that can be chosen as the final number of clusters. This aspect has been overlooked by most of the existing works in this area. In this study, we introduce a correlation-based fuzzy cluster validity index known as the Wiroonsri-Preedasawakul (WP) index. This index is defined based on the correlation between the actual distance between a pair of data points and the distance between adjusted centroids with respect to that pair. We evaluate and compare the performance of our index with several existing indexes, including Xie-Beni, Pakhira-Bandyopadhyay-Maulik, Tang, Wu-Li, generalized C, and Kwon2. We conduct this evaluation on four types of datasets: artificial datasets, real-world datasets, simulated datasets with ranks, and image datasets, using the fuzzy c-mea
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.06399</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#23398;&#20064;&#20855;&#26377;&#24322;&#26500;&#20892;&#19994;&#25968;&#25454;&#38598;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering. (arXiv:2308.06399v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28041;&#21450;&#22810;&#26679;&#20294;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#20013;&#65292;&#20854;&#20013;&#21327;&#21464;&#37327;&#19982;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#32852;&#21487;&#33021;&#20250;&#26377;&#25152;&#19981;&#21516;&#65292;&#22312;&#21253;&#25324;&#20892;&#23398;&#30740;&#31350;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#37117;&#24456;&#26222;&#36941;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24120;&#24120;&#20351;&#29992;&#23618;&#27425;&#27169;&#22411;&#65292;&#20063;&#34987;&#31216;&#20026;&#22810;&#23618;&#27169;&#22411;&#65292;&#26469;&#34701;&#21512;&#26469;&#33258;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;&#24182;&#36866;&#24212;&#23427;&#20204;&#30340;&#19981;&#21516;&#29305;&#28857;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#32467;&#26500;&#36229;&#20986;&#20102;&#31616;&#21333;&#30340;&#24322;&#36136;&#24615;&#65292;&#22240;&#20026;&#21464;&#37327;&#36890;&#24120;&#24418;&#25104;&#22797;&#26434;&#30340;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#12290;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BNs&#65289;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#26469;&#27169;&#25311;&#36825;&#31181;&#20851;&#31995;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38543;&#26426;&#25928;&#24212;&#25972;&#21512;&#21040;BN&#23398;&#20064;&#20013;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22788;&#29702;&#23618;&#27425;&#25968;&#25454;&#12290;&#26469;&#33258;&#30495;&#23454;&#20892;&#23398;&#35797;&#39564;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#37319;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22686;&#24378;&#32467;&#26500;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.  Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#36890;&#30417;&#27979;&#30340;&#22810;&#30446;&#26631;&#36319;&#36394;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#20809;&#23398;&#21644;&#28909;&#24863;&#25668;&#20687;&#22836;&#33719;&#21462;&#22270;&#20687;&#19978;&#30340;&#29289;&#20307;&#26816;&#27979;&#65292;&#24182;&#20351;&#29992;&#36712;&#36857;&#27850;&#26494;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#22120;&#26469;&#20272;&#35745;&#36710;&#36742;&#30340;&#36712;&#36857;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#39564;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16890</link><description>&lt;p&gt;
&#20351;&#29992;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#36890;&#30417;&#27979;&#30340;&#36712;&#36857;&#27850;&#26494;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Trajectory Poisson multi-Bernoulli mixture filter for traffic monitoring using a drone. (arXiv:2306.16890v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#36890;&#30417;&#27979;&#30340;&#22810;&#30446;&#26631;&#36319;&#36394;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#20809;&#23398;&#21644;&#28909;&#24863;&#25668;&#20687;&#22836;&#33719;&#21462;&#22270;&#20687;&#19978;&#30340;&#29289;&#20307;&#26816;&#27979;&#65292;&#24182;&#20351;&#29992;&#36712;&#36857;&#27850;&#26494;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#22120;&#26469;&#20272;&#35745;&#36710;&#36742;&#30340;&#36712;&#36857;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#39564;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37197;&#22791;&#26377;&#20809;&#23398;&#21644;&#28909;&#24863;&#25668;&#20687;&#22836;&#30340;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#36890;&#30417;&#27979;&#30340;&#22810;&#30446;&#26631;&#36319;&#36394;&#65288;MOT&#65289;&#31639;&#27861;&#12290;&#22270;&#20687;&#19978;&#30340;&#29289;&#20307;&#26816;&#27979;&#26159;&#20351;&#29992;&#27599;&#31181;&#31867;&#22411;&#25668;&#20687;&#22836;&#30340;&#31070;&#32463;&#32593;&#32476;&#33719;&#24471;&#30340;&#12290;&#25668;&#20687;&#22836;&#34987;&#24314;&#27169;&#20026;&#21040;&#36798;&#26041;&#21521;&#65288;DOA&#65289;&#20256;&#24863;&#22120;&#12290;&#27599;&#20010;DOA&#26816;&#27979;&#37117;&#36981;&#24490;von-Mises Fisher&#20998;&#24067;&#65292;&#20854;&#24179;&#22343;&#26041;&#21521;&#26159;&#36890;&#36807;&#23558;&#36710;&#36742;&#20301;&#32622;&#25237;&#24433;&#21040;&#22320;&#38754;&#19978;&#30340;&#25668;&#20687;&#26426;&#33719;&#24471;&#30340;&#12290;&#28982;&#21518;&#25105;&#20204;&#20351;&#29992;&#36712;&#36857;&#27850;&#26494;&#22810;&#20271;&#21162;&#21033;&#28151;&#21512;&#28388;&#27874;&#22120;&#65288;TPMBM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36125;&#21494;&#26031;&#22810;&#30446;&#26631;&#36319;&#36394;&#31639;&#27861;&#65292;&#26469;&#26368;&#20248;&#20272;&#35745;&#19968;&#32452;&#36710;&#36742;&#36712;&#36857;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#27979;&#37327;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#23454;&#39564;&#25968;&#25454;&#38598;&#20013;&#27979;&#35797;&#20102;&#25152;&#24471;&#21040;&#30340;TPMBM&#28388;&#27874;&#22120;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a multi-object tracking (MOT) algorithm for traffic monitoring using a drone equipped with optical and thermal cameras. Object detections on the images are obtained using a neural network for each type of camera. The cameras are modelled as direction-of-arrival (DOA) sensors. Each DOA detection follows a von-Mises Fisher distribution, whose mean direction is obtain by projecting a vehicle position on the ground to the camera. We then use the trajectory Poisson multi-Bernoulli mixture filter (TPMBM), which is a Bayesian MOT algorithm, to optimally estimate the set of vehicle trajectories. We have also developed a parameter estimation algorithm for the measurement model. We have tested the accuracy of the resulting TPMBM filter in synthetic and experimental data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#32531;&#23384;&#19982;&#27169;&#22411;&#22797;&#29992;&#20004;&#31181;&#26041;&#27861;&#26469;&#32531;&#35299;&#22823;&#22411;&#27169;&#22411;&#25512;&#29702;&#20013;&#36164;&#28304;&#28040;&#32791;&#21644;&#24310;&#36831;&#25361;&#25112;&#65292;&#32463;&#36807;&#23454;&#35777;&#27169;&#25311;&#21457;&#29616;&#36825;&#31181;&#32452;&#21512;&#22823;&#22823;&#25552;&#39640;&#20102;&#20256;&#32479;&#27169;&#22411;&#25512;&#29702;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02003</link><description>&lt;p&gt;
&#20851;&#20110;&#22823;&#22411;&#27169;&#22411;&#25512;&#29702;&#20013;&#30340;&#26368;&#20248;&#32531;&#23384;&#19982;&#27169;&#22411;&#22797;&#29992;
&lt;/p&gt;
&lt;p&gt;
On Optimal Caching and Model Multiplexing for Large Model Inference. (arXiv:2306.02003v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#32531;&#23384;&#19982;&#27169;&#22411;&#22797;&#29992;&#20004;&#31181;&#26041;&#27861;&#26469;&#32531;&#35299;&#22823;&#22411;&#27169;&#22411;&#25512;&#29702;&#20013;&#36164;&#28304;&#28040;&#32791;&#21644;&#24310;&#36831;&#25361;&#25112;&#65292;&#32463;&#36807;&#23454;&#35777;&#27169;&#25311;&#21457;&#29616;&#36825;&#31181;&#32452;&#21512;&#22823;&#22823;&#25552;&#39640;&#20102;&#20256;&#32479;&#27169;&#22411;&#25512;&#29702;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#20854;&#20182;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#20854;&#23610;&#23544;&#21152;&#21095;&#20102;&#29616;&#26377;&#30340;&#36164;&#28304;&#28040;&#32791;&#21644;&#24310;&#36831;&#25361;&#25112;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#32531;&#35299;&#36825;&#20123;&#25361;&#25112;&#65306;&#21033;&#29992;&#32531;&#23384;&#23384;&#20648;&#20808;&#21069;&#30340;&#26597;&#35810;&#21644;&#23398;&#20064;&#27169;&#22411;&#22797;&#29992;&#22120;&#26469;&#36873;&#25321;&#29992;&#20110;&#26597;&#35810;&#22788;&#29702;&#30340;&#27169;&#22411;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26368;&#20248;&#31639;&#27861;&#26469;&#32852;&#21512;&#20248;&#21270;&#36825;&#20004;&#31181;&#26041;&#27861;&#65292;&#20174;&#32780;&#20943;&#23569;&#31163;&#32447;&#21644;&#22312;&#32447;&#21046;&#34920;&#29615;&#22659;&#20013;&#30340;&#25512;&#29702;&#25104;&#26412;&#12290;&#36890;&#36807;&#23558;&#32531;&#23384;&#31639;&#27861;&#21644;&#27169;&#22411;&#22797;&#29992;&#22120;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#37117;&#23454;&#29616;&#20102;&#26368;&#20248;&#24615;&#33021;&#12290;&#23454;&#35777;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#32531;&#23384;&#21644;&#27169;&#22411;&#22797;&#29992;&#31639;&#27861;&#30340;&#32452;&#21512;&#22823;&#22823;&#25552;&#39640;&#20102;&#20256;&#32479;&#27169;&#22411;&#25512;&#29702;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) and other large foundation models have achieved noteworthy success, but their size exacerbates existing resource consumption and latency challenges. In particular, the large-scale deployment of these models is hindered by the significant resource requirements during inference. In this paper, we study two approaches for mitigating these challenges: employing a cache to store previous queries and learning a model multiplexer to choose from an ensemble of models for query processing.  Theoretically, we provide an optimal algorithm for jointly optimizing both approaches to reduce the inference cost in both offline and online tabular settings. By combining a caching algorithm, namely Greedy Dual Size with Frequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we achieve optimal rates in both offline and online settings. Empirically, simulations show that the combination of our caching and model multiplexing algorithms greatly improves over the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2305.15786</link><description>&lt;p&gt;
&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#30340;&#29702;&#35770;&#20445;&#35777;&#21450;&#20854;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting. (arXiv:2305.15786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#21512;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#24037;&#20855;&#20043;&#19968;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#26377;&#25928;&#22320;&#20943;&#23569;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#38024;&#23545;&#40657;&#30418;&#22522;&#23398;&#20064;&#22120;&#30340;&#22823;&#22810;&#25968;&#38598;&#21512;&#26041;&#27861;&#37117;&#23646;&#20110;&#8220;&#21472;&#21152;&#27867;&#21270;&#8221;&#33539;&#30068;&#65292;&#21363;&#35757;&#32451;&#19968;&#20010;&#25509;&#21463;&#22522;&#23398;&#20064;&#22120;&#25512;&#29702;&#20316;&#20026;&#36755;&#20837;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#34429;&#28982;&#21472;&#21152;&#27867;&#21270;&#22312;&#23454;&#36341;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#20173;&#28982;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#8220;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#8221;&#21472;&#21152;&#27867;&#21270;&#20013;&#30340;&#26368;&#20339;&#21472;&#21152;&#27867;&#21270;&#24182;&#19981;&#27604;&#26368;&#20248;&#35299;&#34920;&#29616;&#8220;&#24046;&#24471;&#22810;&#8221;&#12290;&#36825;&#19968;&#32467;&#26524;&#21152;&#24378;&#21644;&#22823;&#22823;&#25193;&#23637;&#20102;Van der Laan&#31561;&#20154;&#65288;2007&#24180;&#65289;&#30340;&#32467;&#26524;&#12290;&#21463;&#21040;&#29702;&#35770;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#27010;&#29575;&#39044;&#27979;&#30340;&#32972;&#26223;&#19979;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#19981;&#21516;&#25935;&#24863;&#24615;&#30340;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling is among the most popular tools in machine learning (ML) due to its effectiveness in minimizing variance and thus improving generalization. Most ensembling methods for black-box base learners fall under the umbrella of "stacked generalization," namely training an ML algorithm that takes the inferences from the base learners as input. While stacking has been widely applied in practice, its theoretical properties are poorly understood. In this paper, we prove a novel result, showing that choosing the best stacked generalization from a (finite or finite-dimensional) family of stacked generalizations based on cross-validated performance does not perform "much worse" than the oracle best. Our result strengthens and significantly extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis, we further propose a particular family of stacked generalizations in the context of probabilistic forecasting, each one with a different sensitivity for how much the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20957;&#32858;&#27010;&#24565;&#65292;&#26500;&#24314;&#22312;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#22522;&#30784;&#19978;&#65292;&#25193;&#23637;&#20102;&#26089;&#26399;&#32467;&#26524;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#30340;&#31038;&#21306;&#21457;&#29616;&#20013;&#12290;</title><link>http://arxiv.org/abs/2303.10167</link><description>&lt;p&gt;
&#24191;&#20041;&#21010;&#20998;&#23616;&#37096;&#28145;&#24230;
&lt;/p&gt;
&lt;p&gt;
Generalized partitioned local depth. (arXiv:2303.10167v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10167
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20957;&#32858;&#27010;&#24565;&#65292;&#26500;&#24314;&#22312;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#22522;&#30784;&#19978;&#65292;&#25193;&#23637;&#20102;&#26089;&#26399;&#32467;&#26524;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#30340;&#31038;&#21306;&#21457;&#29616;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26368;&#36817;&#30001;Berenhaut&#12289;Moore&#21644;Melvin [Proccedings of the National Academy of Sciences, 119 (4) (2022)]&#25552;&#20986;&#30340;&#20957;&#32858;&#27010;&#24565;&#30340;&#27010;&#25324;&#12290;&#25152;&#25552;&#20986;&#30340;&#34920;&#36848;&#22522;&#20110;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#24182;&#25552;&#28860;&#20102;&#20004;&#20010;&#20851;&#38190;&#27010;&#29575;&#27010;&#24565;&#65306;&#23616;&#37096;&#30456;&#20851;&#24615;&#21644;&#25903;&#25345;&#20998;&#21106;&#12290;&#26089;&#26399;&#32467;&#26524;&#22312;&#26032;&#30340;&#32972;&#26223;&#19979;&#24471;&#21040;&#25193;&#23637;&#65292;&#24182;&#21253;&#25324;&#22312;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#20013;&#25581;&#31034;&#31038;&#21306;&#30340;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we provide a generalization of the concept of cohesion as introduced recently by Berenhaut, Moore and Melvin [Proceedings of the National Academy of Sciences, 119 (4) (2022)]. The formulation presented builds on the technique of partitioned local depth by distilling two key probabilistic concepts: local relevance and support division. Earlier results are extended within the new context, and examples of applications to revealing communities in data with uncertainty are included.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#38543;&#26426;&#27493;&#38271;&#21644;&#24490;&#29615;&#27493;&#38271;&#30456;&#23545;&#20110;&#24120;&#25968;&#27493;&#38271;&#30340;&#20248;&#21183;&#65292;&#36890;&#36807;&#32771;&#34385;&#23614;&#37096;&#25351;&#25968;&#22914;&#20309;&#38543;&#27493;&#38271;&#35843;&#24230;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#26469;&#25512;&#21160;&#29702;&#35770;&#30740;&#31350;&#65292;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#23427;&#20204;&#23545;&#20110;&#27867;&#21270;&#24615;&#33021;&#30340;&#25913;&#21892;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2302.05516</link><description>&lt;p&gt;
&#38543;&#26426;&#27493;&#38271;&#21644;&#24490;&#29615;&#27493;&#38271;&#24341;&#21457;&#20102;&#27604;&#24120;&#25968;&#27493;&#38271;&#26356;&#37325;&#30340;SGD&#23614;&#37096;
&lt;/p&gt;
&lt;p&gt;
Cyclic and Randomized Stepsizes Invoke Heavier Tails in SGD than Constant Stepsize. (arXiv:2302.05516v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05516
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#38543;&#26426;&#27493;&#38271;&#21644;&#24490;&#29615;&#27493;&#38271;&#30456;&#23545;&#20110;&#24120;&#25968;&#27493;&#38271;&#30340;&#20248;&#21183;&#65292;&#36890;&#36807;&#32771;&#34385;&#23614;&#37096;&#25351;&#25968;&#22914;&#20309;&#38543;&#27493;&#38271;&#35843;&#24230;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#26469;&#25512;&#21160;&#29702;&#35770;&#30740;&#31350;&#65292;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#23427;&#20204;&#23545;&#20110;&#27867;&#21270;&#24615;&#33021;&#30340;&#25913;&#21892;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#27493;&#38271;&#21644;&#24490;&#29615;&#27493;&#38271;&#22312;&#28145;&#24230;&#23398;&#20064;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#24182;&#19988;&#36890;&#24120;&#21487;&#20197;&#32988;&#36807;&#24120;&#25968;&#27493;&#38271;&#36873;&#25321;&#65292;&#22914;SGD&#20013;&#30340;&#24120;&#25968;&#27493;&#38271;&#12290;&#23613;&#31649;&#23427;&#20204;&#22312;&#32463;&#39564;&#19978;&#33719;&#24471;&#25104;&#21151;&#65292;&#20294;&#30446;&#21069;&#23545;&#20110;&#23427;&#20204;&#20309;&#26102;&#20197;&#21450;&#20026;&#20160;&#20040;&#33021;&#22312;&#29702;&#35770;&#19978;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#30340;&#20102;&#35299;&#36824;&#19981;&#22815;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#20851;&#20110;&#23398;&#20064;&#30340;&#39532;&#23572;&#21487;&#22827;&#27493;&#38271;&#65292;&#20854;&#20013;&#21253;&#21547;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#38543;&#26426;&#27493;&#38271;&#12289;&#24490;&#29615;&#27493;&#38271;&#20197;&#21450;&#24120;&#25968;&#27493;&#38271;&#31561;&#29305;&#27530;&#24773;&#20917;&#12290;&#21463;&#21040;&#25991;&#29486;&#20013;&#26174;&#31034;&#30340;SGD&#36845;&#20195;&#30340;&#23614;&#37096;&#65288;&#36890;&#36807;&#25152;&#35859;&#30340;&#8220;&#23614;&#37096;&#25351;&#25968;&#8221;&#26469;&#34913;&#37327;&#65289;&#30340;&#37325;&#23614;&#29616;&#35937;&#19982;&#27867;&#21270;&#30340;&#30456;&#20851;&#24615;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23614;&#37096;&#25351;&#25968;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#23614;&#37096;&#25351;&#25968;&#22312;&#27493;&#38271;&#35843;&#24230;&#19978;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#20174;&#23614;&#37096;&#34892;&#20026;&#30340;&#35282;&#24230;&#19978;&#35752;&#35770;&#24490;&#29615;&#21644;&#38543;&#26426;&#27493;&#38271;&#30456;&#23545;&#20110;&#24120;&#25968;&#27493;&#38271;&#30340;&#22909;&#22788;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#22238;&#24402;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#24182;&#23637;&#31034;&#20102;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cyclic and randomized stepsizes are widely used in the deep learning practice and can often outperform standard stepsize choices such as constant stepsize in SGD. Despite their empirical success, not much is currently known about when and why they can theoretically improve the generalization performance. We consider a general class of Markovian stepsizes for learning, which contain i.i.d. random stepsize, cyclic stepsize as well as the constant stepsize as special cases, and motivated by the literature which shows that heaviness of the tails (measured by the so-called "tail-index") in the SGD iterates is correlated with generalization, we study tail-index and provide a number of theoretical results that demonstrate how the tail-index varies on the stepsize scheduling. Our results bring a new understanding of the benefits of cyclic and randomized stepsizes compared to constant stepsize in terms of the tail behavior. We illustrate our theory on linear regression experiments and show thro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#20013;&#20351;&#29992;&#38750;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#23545;&#22823;&#22411;&#25237;&#36164;&#32452;&#21512;&#20013;&#36164;&#20135;&#22238;&#25253;&#30340;&#31934;&#30830;&#30697;&#38453;&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#36866;&#29992;&#20110;&#37329;&#34701;&#24066;&#22330;&#20856;&#22411;&#30340;&#20302;&#20449;&#22122;&#27604;&#29615;&#22659;&#65292;&#36824;&#19982;&#24369;&#22240;&#23376;&#20860;&#23481;&#65292;&#24182;&#19988;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#19968;&#33268;&#35823;&#24046;&#21327;&#26041;&#24046;&#20272;&#35745;&#26041;&#27861;&#12290;&#27169;&#25311;&#21644;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2209.04512</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#38750;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#27531;&#24046;&#65306;&#20302;&#20449;&#22122;&#27604;&#19979;&#36164;&#20135;&#22238;&#25253;&#30340;&#31934;&#30830;&#30697;&#38453;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio. (arXiv:2209.04512v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04512
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#20013;&#20351;&#29992;&#38750;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#23545;&#22823;&#22411;&#25237;&#36164;&#32452;&#21512;&#20013;&#36164;&#20135;&#22238;&#25253;&#30340;&#31934;&#30830;&#30697;&#38453;&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#36866;&#29992;&#20110;&#37329;&#34701;&#24066;&#22330;&#20856;&#22411;&#30340;&#20302;&#20449;&#22122;&#27604;&#29615;&#22659;&#65292;&#36824;&#19982;&#24369;&#22240;&#23376;&#20860;&#23481;&#65292;&#24182;&#19988;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#19968;&#33268;&#35823;&#24046;&#21327;&#26041;&#24046;&#20272;&#35745;&#26041;&#27861;&#12290;&#27169;&#25311;&#21644;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#20013;&#20351;&#29992;&#38750;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#23545;&#22823;&#22411;&#25237;&#36164;&#32452;&#21512;&#20013;&#36164;&#20135;&#22238;&#25253;&#30340;&#31934;&#30830;&#30697;&#38453;&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#26041;&#27861;&#21363;&#20351;&#22312;&#37329;&#34701;&#24066;&#22330;&#20856;&#22411;&#30340;&#20449;&#22122;&#27604;&#20302;&#30340;&#29615;&#22659;&#20013;&#20173;&#28982;&#26377;&#25928;&#65292;&#24182;&#19988;&#19982;&#24369;&#22240;&#23376;&#20860;&#23481;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#23545;&#20110;&#19981;&#26029;&#22686;&#21152;&#30340;&#36164;&#20135;&#25968;&#37327;&#65292;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#26399;&#20272;&#35745;&#39118;&#38505;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#22522;&#20110;&#25968;&#25454;&#30340;&#19968;&#33268;&#35823;&#24046;&#21327;&#26041;&#24046;&#20272;&#35745;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#24191;&#27867;&#30340;&#27169;&#25311;&#21644;&#23454;&#35777;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a consistent estimator and rate of convergence for the precision matrix of asset returns in large portfolios using a non-linear factor model within the deep learning framework. Our estimator remains valid even in low signal-to-noise ratio environments typical for financial markets and is compatible with weak factors. Our theoretical analysis establishes uniform bounds on expected estimation risk based on deep neural networks for an expanding number of assets. Additionally, we provide a new consistent data-dependent estimator of error covariance in deep neural networks. Our models demonstrate superior accuracy in extensive simulations and the empirics.
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;Bayes&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#23384;&#22312;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#33324;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#21487;&#20197;&#20026;&#30740;&#31350;&#23545;&#25239;&#24615;&#20195;&#29702;&#25439;&#22833;&#21644;&#20854;&#19968;&#33268;&#24615;&#23646;&#24615;&#25552;&#20379;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2112.01694</link><description>&lt;p&gt;
&#20851;&#20110;&#23545;&#25239;&#24615;Bayes&#20998;&#31867;&#22120;&#23384;&#22312;&#24615;&#30340;&#30740;&#31350;&#65288;&#25193;&#23637;&#29256;&#65289;
&lt;/p&gt;
&lt;p&gt;
On the Existence of the Adversarial Bayes Classifier (Extended Version). (arXiv:2112.01694v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.01694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;Bayes&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#23384;&#22312;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#33324;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#21487;&#20197;&#20026;&#30740;&#31350;&#23545;&#25239;&#24615;&#20195;&#29702;&#25439;&#22833;&#21644;&#20854;&#19968;&#33268;&#24615;&#23646;&#24615;&#25552;&#20379;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#26368;&#36817;&#24050;&#32463;&#26377;&#22810;&#39033;&#29702;&#35770;&#30740;&#31350;&#65292;&#20294;&#19982;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#30456;&#20851;&#30340;&#35768;&#22810;&#37325;&#35201;&#38382;&#39064;&#20173;&#28982;&#26410;&#34987;&#35299;&#20915;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#20851;&#20110;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;Bayes&#26368;&#20248;&#20998;&#31867;&#22120;&#23384;&#22312;&#24615;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#33324;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20197;&#20445;&#35777;&#23384;&#22312;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;&#30340;Bayes&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21487;&#20197;&#20026;&#23545;&#21518;&#32493;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;&#20195;&#29702;&#25439;&#22833;&#21644;&#23427;&#20204;&#30340;&#19968;&#33268;&#24615;&#23646;&#24615;&#30340;&#30740;&#31350;&#25552;&#20379;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#26412;&#25991;&#26159;&#8220;&#20851;&#20110;&#23545;&#25239;&#24615;Bayes&#20998;&#31867;&#22120;&#23384;&#22312;&#24615;&#8221;&#30340;&#30699;&#27491;&#21644;&#25193;&#23637;&#29256;&#26412;&#65292;&#35813;&#31295;&#20214;&#24050;&#21457;&#34920;&#22312;NeurIPS 2021&#19978;&#12290;&#21407;&#22987;&#35770;&#25991;&#20013;&#26377;&#20004;&#22788;&#23450;&#29702;&#38169;&#35823;&#65292;&#19968;&#22788;&#26159;&#23545;&#20266;&#21487;&#35777;&#20581;&#22766;&#24615;&#30340;&#23450;&#20041;&#65292;&#21478;&#19968;&#22788;&#26159;&#38024;&#23545;&#20219;&#24847;&#24230;&#37327;&#31354;&#38388;&#30340;$A^\e$&#21487;&#27979;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial robustness is a critical property in a variety of modern machine learning applications. While it has been the subject of several recent theoretical studies, many important questions related to adversarial robustness are still open. In this work, we study a fundamental question regarding Bayes optimality for adversarial robustness. We provide general sufficient conditions under which the existence of a Bayes optimal classifier can be guaranteed for adversarial robustness. Our results can provide a useful tool for a subsequent study of surrogate losses in adversarial robustness and their consistency properties. This manuscript is the extended and corrected version of the paper \emph{On the Existence of the Adversarial Bayes Classifier} published in NeurIPS 2021. There were two errors in theorem statements in the original paper -- one in the definition of pseudo-certifiable robustness and the other in the measurability of $A^\e$ for arbitrary metric spaces. In this version we 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#24403;&#36755;&#20837;&#21442;&#25968;&#19981;&#30830;&#23450;&#25110;&#26368;&#21021;&#26410;&#30693;&#26102;&#65292;&#36890;&#36807;&#20840;&#24102;&#22238;&#39304;&#30340;&#32452;&#21512;&#32431;&#25506;&#32034;&#65288;CPE&#65289;&#26469;&#35299;&#20915;&#35813;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#21322;&#36172;&#21338;&#26426;&#21453;&#39304;&#25110;&#20551;&#35774;&#27599;&#20010;&#36793;&#30340;&#32467;&#26524;&#22987;&#32456;&#21487;&#20197;&#35775;&#38382;&#65292;&#32780;&#36825;&#31687;&#35770;&#25991;&#32771;&#34385;&#20102;&#24378;&#21453;&#39304;&#20449;&#24687;&#19981;&#19968;&#23450;&#21487;&#29992;&#30340;&#23454;&#38469;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2012.15584</link><description>&lt;p&gt;
&#36890;&#36807;&#20840;&#24102;&#22238;&#39304;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65306;&#32452;&#21512;&#32431;&#25506;&#32034;&#21644;&#26356;&#22810;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Combinatorial Pure Exploration with Full-bandit Feedback and Beyond: Solving Combinatorial Optimization under Uncertainty with Limited Observation. (arXiv:2012.15584v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.15584
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#24403;&#36755;&#20837;&#21442;&#25968;&#19981;&#30830;&#23450;&#25110;&#26368;&#21021;&#26410;&#30693;&#26102;&#65292;&#36890;&#36807;&#20840;&#24102;&#22238;&#39304;&#30340;&#32452;&#21512;&#32431;&#25506;&#32034;&#65288;CPE&#65289;&#26469;&#35299;&#20915;&#35813;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#21322;&#36172;&#21338;&#26426;&#21453;&#39304;&#25110;&#20551;&#35774;&#27599;&#20010;&#36793;&#30340;&#32467;&#26524;&#22987;&#32456;&#21487;&#20197;&#35775;&#38382;&#65292;&#32780;&#36825;&#31687;&#35770;&#25991;&#32771;&#34385;&#20102;&#24378;&#21453;&#39304;&#20449;&#24687;&#19981;&#19968;&#23450;&#21487;&#29992;&#30340;&#23454;&#38469;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32452;&#21512;&#20248;&#21270;&#26159;&#29702;&#35770;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#36816;&#31609;&#23398;&#20013;&#24191;&#27867;&#30740;&#31350;&#30340;&#22522;&#30784;&#30740;&#31350;&#39046;&#22495;&#20043;&#19968;&#12290;&#22312;&#24320;&#21457;&#32452;&#21512;&#20248;&#21270;&#31639;&#27861;&#26102;&#65292;&#36890;&#24120;&#20551;&#35774;&#36755;&#20837;&#30340;&#21442;&#25968;&#65288;&#20363;&#22914;&#36793;&#26435;&#37325;&#65289;&#26159;&#20934;&#30830;&#24050;&#30693;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#24456;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#20363;&#22914;&#25512;&#33616;&#31995;&#32479;&#12289;&#20247;&#21253;&#12289;&#36890;&#20449;&#32593;&#32476;&#21644;&#22312;&#32447;&#24191;&#21578;&#65292;&#36755;&#20837;&#21442;&#25968;&#24448;&#24448;&#26159;&#19981;&#30830;&#23450;&#30340;&#25110;&#32773;&#26368;&#21021;&#26410;&#30693;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#26679;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#65288;CPE&#65289;&#21450;&#20854;&#21464;&#31181;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#26089;&#26399;&#20851;&#20110;CPE&#30340;&#30740;&#31350;&#20027;&#35201;&#26159;&#30740;&#31350;&#21322;&#36172;&#21338;&#26426;&#21453;&#39304;&#25110;&#32773;&#20551;&#35774;&#27599;&#20010;&#36793;&#30340;&#32467;&#26524;&#22312;&#27599;&#36718;&#20013;&#37117;&#26159;&#21487;&#20197;&#35775;&#38382;&#30340;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23454;&#38469;&#32422;&#26463;&#65288;&#20363;&#22914;&#39044;&#31639;&#38480;&#21046;&#25110;&#38544;&#31169;&#38382;&#39064;&#65289;&#65292;&#36817;&#26399;&#30340;&#24212;&#29992;&#20013;&#24182;&#19981;&#24635;&#26159;&#26377;&#36825;&#20040;&#24378;&#30340;&#21453;&#39304;&#20449;&#24687;&#21487;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combinatorial optimization is one of the fundamental research fields that has been extensively studied in theoretical computer science and operations research. When developing an algorithm for combinatorial optimization, it is commonly assumed that parameters such as edge weights are exactly known as inputs. However, this assumption may not be fulfilled since input parameters are often uncertain or initially unknown in many applications such as recommender systems, crowdsourcing, communication networks, and online advertisement. To resolve such uncertainty, the problem of combinatorial pure exploration of multi-armed bandits (CPE) and its variants have recieved increasing attention. Earlier work on CPE has studied the semi-bandit feedback or assumed that the outcome from each individual edge is always accessible at all rounds. However, due to practical constraints such as a budget ceiling or privacy concern, such strong feedback is not always available in recent applications. In this a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#32852;&#21512;&#20998;&#20301;&#25968;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#12290;&#27169;&#22411;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#26681;&#25454;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#38656;&#35201;&#36827;&#34892;&#29305;&#24449;&#30340;&#36873;&#25321;&#65292;&#24182;&#19988;&#20801;&#35768;&#36827;&#34892;&#21363;&#26102;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2010.01654</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#29305;&#24449;&#36873;&#25321;&#22312;&#32852;&#21512;&#20998;&#20301;&#25968;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Bayesian Feature Selection in Joint Quantile Time Series Analysis. (arXiv:2010.01654v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.01654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#32852;&#21512;&#20998;&#20301;&#25968;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#12290;&#27169;&#22411;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#26681;&#25454;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#38656;&#35201;&#36827;&#34892;&#29305;&#24449;&#30340;&#36873;&#25321;&#65292;&#24182;&#19988;&#20801;&#35768;&#36827;&#34892;&#21363;&#26102;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#30456;&#20851;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#20998;&#20301;&#25968;&#29305;&#24449;&#36873;&#25321;&#19968;&#30452;&#26159;&#19968;&#31181;&#26041;&#27861;&#19978;&#30340;&#25361;&#25112;&#21644;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#36125;&#21494;&#26031;&#38477;&#32500;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#32852;&#21512;&#20998;&#20301;&#25968;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#30340;&#29305;&#24449;&#36873;&#25321;&#65292;&#35813;&#26041;&#27861;&#34987;&#31216;&#20026;&#20998;&#20301;&#25968;&#29305;&#24449;&#36873;&#25321;&#26102;&#38388;&#24207;&#21015;&#65288;QFSTS&#65289;&#27169;&#22411;&#12290;QFSTS&#27169;&#22411;&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#32467;&#26500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65292;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#23545;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20135;&#29983;&#20102;&#21487;&#30452;&#25509;&#35299;&#37322;&#30340;&#21152;&#24615;&#36129;&#29486;&#12290;&#20854;&#28789;&#27963;&#24615;&#20307;&#29616;&#22312;&#29992;&#25143;&#21487;&#20197;&#20026;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#28155;&#21152;/&#20943;&#23569;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#19988;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#21487;&#20197;&#20855;&#26377;&#19981;&#21516;&#22823;&#23567;&#30340;&#29305;&#23450;&#20540;&#32452;&#25104;&#37096;&#20998;&#12290;&#29305;&#24449;&#36873;&#25321;&#26159;&#22312;&#20998;&#20301;&#25968;&#22238;&#24402;&#32452;&#20214;&#20013;&#36827;&#34892;&#30340;&#65292;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#37117;&#26377;&#33258;&#24049;&#30340;&#21516;&#26102;&#22806;&#37096;&#39044;&#27979;&#21464;&#37327;&#27744;&#65292;&#20801;&#35768;&#36827;&#34892;&#21363;&#26102;&#39044;&#27979;&#12290;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#23558;&#29305;&#24449;&#36873;&#25321;&#25193;&#23637;&#21040;&#20998;&#20301;&#25968;&#26102;&#38388;&#24207;&#21015;&#30740;&#31350;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantile feature selection over correlated multivariate time series data has always been a methodological challenge and is an open problem. In this paper, we propose a general Bayesian dimension reduction methodology for feature selection in high-dimensional joint quantile time series analysis, under the name of the quantile feature selection time series (QFSTS) model. The QFSTS model is a general structural time series model, where each component yields an additive contribution to the time series modeling with direct interpretations. Its flexibility is compound in the sense that users can add/deduct components for each time series and each time series can have its own specific valued components of different sizes. Feature selection is conducted in the quantile regression component, where each time series has its own pool of contemporaneous external predictors allowing nowcasting. Bayesian methodology in extending feature selection to the quantile time series research area is developed
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;</title><link>http://arxiv.org/abs/2002.08907</link><description>&lt;p&gt;
&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;
&lt;/p&gt;
&lt;p&gt;
Second-order Conditional Gradient Sliding. (arXiv:2002.08907v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.08907
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#38656;&#35201;&#39640;&#31934;&#24230;&#35299;&#20915;&#38382;&#39064;&#26102;&#65292;&#32422;&#26463;&#20108;&#38454;&#20984;&#20248;&#21270;&#31639;&#27861;&#26159;&#39318;&#36873;&#65292;&#22240;&#20026;&#23427;&#20204;&#20855;&#26377;&#23616;&#37096;&#20108;&#27425;&#25910;&#25947;&#24615;&#12290;&#36825;&#20123;&#31639;&#27861;&#22312;&#27599;&#27425;&#36845;&#20195;&#26102;&#38656;&#35201;&#35299;&#20915;&#19968;&#20010;&#32422;&#26463;&#20108;&#27425;&#23376;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;\emph{&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;}&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#19968;&#31181;&#26080;&#25237;&#24433;&#31639;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#23376;&#38382;&#39064;&#12290;&#24403;&#21487;&#34892;&#22495;&#26159;&#19968;&#20010;&#22810;&#38754;&#20307;&#26102;&#65292;&#35813;&#31639;&#27861;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;&#36827;&#20837;&#20108;&#27425;&#25910;&#25947;&#38454;&#27573;&#21518;&#65292;SOCGS&#31639;&#27861;&#38656;&#36890;&#36807;$\mathcal{O}(\log(\log 1/\varepsilon))$&#27425;&#19968;&#38454;&#21644;Hessian&#27491;&#20132;&#35843;&#29992;&#20197;&#21450;$\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$&#27425;&#32447;&#24615;&#26368;&#23567;&#21270;&#27491;&#20132;&#35843;&#29992;&#26469;&#23454;&#29616;$\varepsilon$-&#26368;&#20248;&#35299;&#12290;&#24403;&#21487;&#34892;&#22495;&#21482;&#33021;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#27491;&#20132;&#35843;&#29992;&#39640;&#25928;&#35775;&#38382;&#26102;&#65292;&#27492;&#31639;&#27861;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constrained second-order convex optimization algorithms are the method of choice when a high accuracy solution to a problem is needed, due to their local quadratic convergence. These algorithms require the solution of a constrained quadratic subproblem at every iteration. We present the \emph{Second-Order Conditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free algorithm to solve the constrained quadratic subproblems inexactly. When the feasible region is a polytope the algorithm converges quadratically in primal gap after a finite number of linearly convergent iterations. Once in the quadratic regime the SOCGS algorithm requires $\mathcal{O}(\log(\log 1/\varepsilon))$ first-order and Hessian oracle calls and $\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$ linear minimization oracle calls to achieve an $\varepsilon$-optimal solution. This algorithm is useful when the feasible region can only be accessed efficiently through a linear optimization oracle, 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21322;&#30417;&#30563;&#30690;&#37327;&#20540;&#23398;&#20064;&#30340;&#25913;&#36827;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;Rademacher&#22797;&#26434;&#24230;&#21644;&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#24471;&#20986;&#20102;&#26356;&#31934;&#30830;&#30340;&#36229;&#20986;&#39118;&#38505;&#30028;&#38480;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/1909.04883</link><description>&lt;p&gt;
&#21322;&#30417;&#30563;&#30690;&#37327;&#20540;&#23398;&#20064;&#65306;&#25913;&#36827;&#30340;&#30028;&#38480;&#19982;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised Vector-valued Learning: Improved Bounds and Algorithms. (arXiv:1909.04883v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1909.04883
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21322;&#30417;&#30563;&#30690;&#37327;&#20540;&#23398;&#20064;&#30340;&#25913;&#36827;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;Rademacher&#22797;&#26434;&#24230;&#21644;&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#24471;&#20986;&#20102;&#26356;&#31934;&#30830;&#30340;&#36229;&#20986;&#39118;&#38505;&#30028;&#38480;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30690;&#37327;&#20540;&#23398;&#20064;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#65292;&#20854;&#36755;&#20986;&#31354;&#38388;&#20855;&#26377;&#30690;&#37327;&#20540;&#32467;&#26500;&#65292;&#28085;&#30422;&#20102;&#35768;&#22810;&#37325;&#35201;&#39046;&#22495;&#65292;&#22914;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#12290;&#25105;&#20204;&#21033;&#29992;&#23616;&#37096;Rademacher&#22797;&#26434;&#24230;&#21644;&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#20174;&#26680;&#20989;&#25968;&#21644;&#32447;&#24615;&#26041;&#27861;&#30340;&#35282;&#24230;&#20026;&#19968;&#33324;&#30690;&#37327;&#20540;&#23398;&#20064;&#23548;&#20986;&#20102;&#26032;&#30340;&#21322;&#30417;&#30563;&#36229;&#20986;&#39118;&#38505;&#30028;&#38480;&#12290;&#36825;&#20123;&#30028;&#38480;&#27604;&#29616;&#26377;&#30340;&#30028;&#38480;&#26356;&#31934;&#30830;&#65292;&#25910;&#25947;&#36895;&#24230;&#20174;&#26631;&#35760;&#26679;&#26412;&#22823;&#23567;&#30340;&#24179;&#26041;&#26681;&#25913;&#36827;&#20026;&#24635;&#26679;&#26412;&#22823;&#23567;&#30340;&#24179;&#26041;&#26681;&#25110;&#30452;&#25509;&#20381;&#36182;&#20110;&#26631;&#35760;&#26679;&#26412;&#22823;&#23567;&#12290;&#22312;&#29702;&#35770;&#20998;&#26512;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#21322;&#30417;&#30563;&#31639;&#27861;&#26469;&#39640;&#25928;&#23398;&#20064;&#30690;&#37327;&#20540;&#20989;&#25968;&#65292;&#32467;&#21512;&#20102;&#23616;&#37096;Rademacher&#22797;&#26434;&#24230;&#21644;&#25289;&#26222;&#25289;&#26031;&#27491;&#21017;&#21270;&#12290;&#22823;&#37327;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#24182;&#19982;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#30456;&#21563;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vector-valued learning, where the output space admits a vector-valued structure, is an important problem that covers a broad family of important domains, e.g. multi-task learning and transfer learning. Using local Rademacher complexity and unlabeled data, we derive novel semi-supervised excess risk bounds for general vector-valued learning from both kernel perspective and linear perspective. The derived bounds are much sharper than existing ones and the convergence rates are improved from the square root of labeled sample size to the square root of total sample size or directly dependent on labeled sample size. Motivated by our theoretical analysis, we propose a general semi-supervised algorithm for efficiently learning vector-valued functions, incorporating both local Rademacher complexity and Laplacian regularization. Extensive experimental results illustrate the proposed algorithm significantly outperforms the compared methods, which coincides with our theoretical findings.
&lt;/p&gt;</description></item></channel></rss>