<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#21033;&#29992;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20174;&#20462;&#27491;&#24341;&#21147;&#27169;&#25311;&#20013;&#25552;&#21462;&#23431;&#23449;&#23398;&#21442;&#25968;&#65292;&#24182;&#23545;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2309.00612</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#23431;&#23449;&#23610;&#24230;&#20013;&#30340;&#20462;&#27491;&#24341;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Bayesian deep learning for cosmic volumes with modified gravity. (arXiv:2309.00612v1 [astro-ph.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00612
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21033;&#29992;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20174;&#20462;&#27491;&#24341;&#21147;&#27169;&#25311;&#20013;&#25552;&#21462;&#23431;&#23449;&#23398;&#21442;&#25968;&#65292;&#24182;&#23545;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#19968;&#20195;&#30340;&#26143;&#31995;&#35843;&#26597;&#23558;&#25552;&#20379;&#21069;&#25152;&#26410;&#26377;&#30340;&#25968;&#25454;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#23431;&#23449;&#23610;&#24230;&#19978;&#27979;&#35797;&#24341;&#21147;&#12290;&#23545;&#22823;&#23610;&#24230;&#32467;&#26500;&#30340;&#20581;&#22766;&#23431;&#23449;&#23398;&#20998;&#26512;&#38656;&#35201;&#21033;&#29992;&#32534;&#30721;&#22312;&#23431;&#23449;&#32593;&#20013;&#30340;&#38750;&#32447;&#24615;&#20449;&#24687;&#12290;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#25552;&#20379;&#20102;&#36825;&#26679;&#30340;&#24037;&#20855;&#65292;&#28982;&#32780;&#21364;&#19981;&#33021;&#25552;&#20379;&#20808;&#39564;&#30340;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20174;&#20462;&#27491;&#24341;&#21147;&#65288;MG&#65289;&#27169;&#25311;&#20013;&#25552;&#21462;&#23431;&#23449;&#23398;&#21442;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#23454;&#29616;&#20102;&#19968;&#20010;&#20016;&#23500;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#65292;&#20998;&#21035;&#32771;&#34385;&#20102;&#19968;&#20010;&#24102;&#26377;&#21333;&#19968;&#36125;&#21494;&#26031;&#26368;&#21518;&#19968;&#23618;&#65288;BLL&#65289;&#30340;&#24773;&#20917;&#65292;&#21644;&#19968;&#20010;&#22312;&#25152;&#26377;&#23618;&#38754;&#19978;&#37117;&#20855;&#26377;&#36125;&#21494;&#26031;&#23618;&#65288;FullB&#65289;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#20351;&#29992;&#23454;&#31354;&#38388;&#23494;&#24230;&#22330;&#21644;&#19968;&#22871;2000&#20010;&#20165;&#21253;&#21547;&#26263;&#29289;&#36136;&#31890;&#23376;&#32593;&#26684;$ N $-&#20307;&#27169;&#25311;&#30340;&#21151;&#29575;&#35889;&#23545;&#36825;&#20004;&#20010;BNN&#36827;&#34892;&#35757;&#32451;&#65292;&#36825;&#20123;&#27169;&#25311;&#21253;&#25324;&#22522;&#20110;MG-PICOLA&#30340;&#20462;&#27491;&#24341;&#21147;&#27169;&#22411;&#65292;&#35206;&#30422;&#20102;&#36793;&#38271;&#20026;256 $h^{-1}$ Mpc&#30340;&#31435;&#26041;&#20307;&#20307;&#31215;&#65292;&#20854;&#20013;&#21253;&#21547;128$&#12290;
&lt;/p&gt;
&lt;p&gt;
The new generation of galaxy surveys will provide unprecedented data allowing us to test gravity at cosmological scales. A robust cosmological analysis of the large-scale structure demands exploiting the nonlinear information encoded in the cosmic web. Machine Learning techniques provide such tools, however, do not provide a priori assessment of uncertainties. This study aims at extracting cosmological parameters from modified gravity (MG) simulations through deep neural networks endowed with uncertainty estimations. We implement Bayesian neural networks (BNNs) with an enriched approximate posterior distribution considering two cases: one with a single Bayesian last layer (BLL), and another one with Bayesian layers at all levels (FullB). We train both BNNs with real-space density fields and power-spectra from a suite of 2000 dark matter only particle mesh $N$-body simulations including modified gravity models relying on MG-PICOLA covering 256 $h^{-1}$ Mpc side cubical volumes with 128$
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; ROBAI &#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#35813;&#31639;&#27861;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#19979;&#22343;&#23454;&#29616;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#24182;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log^2 T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#12290;</title><link>http://arxiv.org/abs/2309.00591</link><description>&lt;p&gt;
&#24555;&#36895;&#21644;&#36951;&#25022;&#26368;&#23567;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#22522;&#26412;&#38480;&#21046;&#21644;&#20302;&#22797;&#26434;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast and Regret Optimal Best Arm Identification: Fundamental Limits and Low-Complexity Algorithms. (arXiv:2309.00591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; ROBAI &#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#35813;&#31639;&#27861;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#19979;&#22343;&#23454;&#29616;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#24182;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log^2 T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20855;&#26377;&#21452;&#37325;&#30446;&#26631;&#30340;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;(MAB)&#38382;&#39064;&#65306;(i) &#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#20197;&#21450;(ii) &#22312;&#19968;&#31995;&#21015;T&#20010;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#23613;&#31649;&#27599;&#20010;&#30446;&#26631;&#37117;&#24050;&#32463;&#24471;&#21040;&#20102;&#29420;&#31435;&#30340;&#28145;&#20837;&#30740;&#31350;&#65292;&#21363;(i)&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#21644;(ii)&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#65292;&#20294;&#26159;&#21516;&#26102;&#23454;&#29616;&#36825;&#20004;&#20010;&#30446;&#26631;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#65292;&#23613;&#31649;&#23427;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#8220;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#8221;(ROBAI)&#65292;&#26088;&#22312;&#23454;&#29616;&#36825;&#20004;&#20010;&#21452;&#37325;&#30446;&#26631;&#12290;&#20026;&#20102;&#35299;&#20915;&#20855;&#26377;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#30340;ROBAI&#65292;&#25105;&#20204;&#20998;&#21035;&#25552;&#20986;&#20102;$\mathsf{EOCP}$&#31639;&#27861;&#21450;&#20854;&#21464;&#20307;&#65292;&#19981;&#20165;&#22312;&#39640;&#26031;&#32769;&#34382;&#26426;&#21644;&#19968;&#33324;&#32769;&#34382;&#26426;&#20013;&#36798;&#21040;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#32780;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#65292;&#22312;$\mathcal{O}(\log T)$&#22238;&#21512;&#20869;&#36873;&#25321;&#20102;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#65292;&#36873;&#25321;&#20102;&#26368;&#20339;&#33218;&#22312;$\mathcal{O}(\log^2 T)$&#22238;&#21512;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers a stochastic multi-armed bandit (MAB) problem with dual objectives: (i) quick identification and commitment to the optimal arm, and (ii) reward maximization throughout a sequence of $T$ consecutive rounds. Though each objective has been individually well-studied, i.e., best arm identification for (i) and regret minimization for (ii), the simultaneous realization of both objectives remains an open problem, despite its practical importance. This paper introduces \emph{Regret Optimal Best Arm Identification} (ROBAI) which aims to achieve these dual objectives. To solve ROBAI with both pre-determined stopping time and adaptive stopping time requirements, we present the $\mathsf{EOCP}$ algorithm and its variants respectively, which not only achieve asymptotic optimal regret in both Gaussian and general bandits, but also commit to the optimal arm in $\mathcal{O}(\log T)$ rounds with pre-determined stopping time and $\mathcal{O}(\log^2 T)$ rounds with adaptive stopping ti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20174;&#22270;&#20687;&#25968;&#25454;&#20013;&#23398;&#20064;&#29305;&#24449;&#30340;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#21367;&#31215;&#31070;&#32463;&#29305;&#24449;&#20551;&#35774;&#12290;&#36890;&#36807;&#23454;&#35777;&#20998;&#26512;&#21644;&#29702;&#35770;&#35777;&#26126;&#65292;&#35770;&#25991;&#23637;&#31034;&#20102;&#28388;&#27874;&#22120;&#30340;&#21327;&#26041;&#24046;&#19982;&#36755;&#20837;&#34917;&#19969;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#20043;&#38388;&#30340;&#39640;&#24230;&#30456;&#20851;&#24615;&#65292;&#20197;&#21450;&#36890;&#36807;&#22522;&#20110;&#34917;&#19969;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#23454;&#29616;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#26222;&#36941;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.00570</link><description>&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#23398;&#20064;&#30340;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Mechanism of feature learning in convolutional neural networks. (arXiv:2309.00570v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00570
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20174;&#22270;&#20687;&#25968;&#25454;&#20013;&#23398;&#20064;&#29305;&#24449;&#30340;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#21367;&#31215;&#31070;&#32463;&#29305;&#24449;&#20551;&#35774;&#12290;&#36890;&#36807;&#23454;&#35777;&#20998;&#26512;&#21644;&#29702;&#35770;&#35777;&#26126;&#65292;&#35770;&#25991;&#23637;&#31034;&#20102;&#28388;&#27874;&#22120;&#30340;&#21327;&#26041;&#24046;&#19982;&#36755;&#20837;&#34917;&#19969;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#20043;&#38388;&#30340;&#39640;&#24230;&#30456;&#20851;&#24615;&#65292;&#20197;&#21450;&#36890;&#36807;&#22522;&#20110;&#34917;&#19969;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#23454;&#29616;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#26222;&#36941;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#20174;&#22270;&#20687;&#25968;&#25454;&#20013;&#23398;&#20064;&#29305;&#24449;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#36825;&#26679;&#19968;&#20010;&#26426;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21367;&#31215;&#31070;&#32463;&#29305;&#24449;&#20551;&#35774;&#65292;&#23427;&#25351;&#20986;&#20219;&#20309;&#21367;&#31215;&#23618;&#20013;&#28388;&#27874;&#22120;&#30340;&#21327;&#26041;&#24046;&#19982;&#35813;&#23618;&#36755;&#20837;&#30340;&#34917;&#19969;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#20551;&#35774;&#25552;&#20379;&#20102;&#22823;&#37327;&#30340;&#23454;&#35777;&#35777;&#25454;&#65292;&#21253;&#25324;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65288;&#22914;AlexNet&#65292;VGG&#21644;&#22312;ImageNet&#19978;&#39044;&#35757;&#32451;&#30340;ResNets&#65289;&#30340;&#21367;&#31215;&#23618;&#20013;&#65292;&#21457;&#29616;&#28388;&#27874;&#22120;&#30340;&#21327;&#26041;&#24046;&#19982;&#22522;&#20110;&#34917;&#19969;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#20043;&#38388;&#23384;&#22312;&#39640;&#24230;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#25903;&#25345;&#29702;&#35770;&#30340;&#35777;&#25454;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#34917;&#19969;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#26469;&#23637;&#31034;&#25105;&#20204;&#32467;&#26524;&#30340;&#26222;&#36941;&#24615;&#65292;&#23454;&#29616;&#20102;&#22312;&#21367;&#31215;&#26680;&#26426;&#22120;&#20013;&#30340;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#12290;&#25105;&#20204;&#23558;&#24471;&#21040;&#30340;&#31639;&#27861;&#31216;&#20026;(Deep) ConvRFM&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#24674;&#22797;&#20986;&#31867;&#20284;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the mechanism of how convolutional neural networks learn features from image data is a fundamental problem in machine learning and computer vision. In this work, we identify such a mechanism. We posit the Convolutional Neural Feature Ansatz, which states that covariances of filters in any convolutional layer are proportional to the average gradient outer product (AGOP) taken with respect to patches of the input to that layer. We present extensive empirical evidence for our ansatz, including identifying high correlation between covariances of filters and patch-based AGOPs for convolutional layers in standard neural architectures, such as AlexNet, VGG, and ResNets pre-trained on ImageNet. We also provide supporting theoretical evidence. We then demonstrate the generality of our result by using the patch-based AGOP to enable deep feature learning in convolutional kernel machines. We refer to the resulting algorithm as (Deep) ConvRFM and show that our algorithm recovers simil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#22312;&#35299;&#37322;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#21457;&#29616;&#31354;&#38388;&#38646;&#20540;&#21644;&#27491;&#21017;&#21270;&#23545;&#22238;&#24402;&#31995;&#25968;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#20844;&#24335;&#26469;&#27604;&#36739;&#22238;&#24402;&#31995;&#25968;&#19982;&#29289;&#29702;&#24037;&#31243;&#30693;&#35782;&#24471;&#21040;&#30340;&#31995;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#35299;&#37322;&#24615;&#30340;&#22238;&#24402;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.00564</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#35299;&#37322;&#65306;&#31354;&#38388;&#38646;&#20540;&#21644;&#27491;&#21017;&#21270;&#22312;&#30005;&#27744;&#25968;&#25454;&#19978;&#30340;&#24433;&#21709;&#30340;&#28436;&#31034;
&lt;/p&gt;
&lt;p&gt;
Interpretation of High-Dimensional Linear Regression: Effects of Nullspace and Regularization Demonstrated on Battery Data. (arXiv:2309.00564v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#22312;&#35299;&#37322;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#21457;&#29616;&#31354;&#38388;&#38646;&#20540;&#21644;&#27491;&#21017;&#21270;&#23545;&#22238;&#24402;&#31995;&#25968;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#20844;&#24335;&#26469;&#27604;&#36739;&#22238;&#24402;&#31995;&#25968;&#19982;&#29289;&#29702;&#24037;&#31243;&#30693;&#35782;&#24471;&#21040;&#30340;&#31995;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#35299;&#37322;&#24615;&#30340;&#22238;&#24402;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#32771;&#34385;&#21040;&#20174;&#21270;&#23398;&#25110;&#29983;&#29289;&#31995;&#32479;&#20013;&#32463;&#24120;&#24471;&#21040;&#30340;&#22522;&#30784;&#24179;&#28369;&#28508;&#22312;&#36807;&#31243;&#30340;&#31163;&#25955;&#27979;&#37327;&#25968;&#25454;&#12290;&#22312;&#39640;&#32500;&#24230;&#20013;&#35299;&#37322;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#31354;&#38388;&#38646;&#20540;&#21450;&#20854;&#19982;&#27491;&#21017;&#21270;&#30340;&#30456;&#20114;&#20316;&#29992;&#20250;&#22609;&#36896;&#22238;&#24402;&#31995;&#25968;&#12290;&#25968;&#25454;&#30340;&#31354;&#38388;&#38646;&#20540;&#21253;&#21547;&#25152;&#26377;&#28385;&#36275;$\mathbf{Xw}=\mathbf{0}$&#30340;&#31995;&#25968;&#65292;&#20174;&#32780;&#20801;&#35768;&#38750;&#24120;&#19981;&#21516;&#30340;&#31995;&#25968;&#20135;&#29983;&#30456;&#21516;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20248;&#21270;&#20844;&#24335;&#26469;&#27604;&#36739;&#22238;&#24402;&#31995;&#25968;&#21644;&#36890;&#36807;&#29289;&#29702;&#24037;&#31243;&#30693;&#35782;&#24471;&#21040;&#30340;&#31995;&#25968;&#65292;&#20197;&#20102;&#35299;&#31995;&#25968;&#24046;&#24322;&#30340;&#21738;&#20123;&#37096;&#20998;&#25509;&#36817;&#20110;&#31354;&#38388;&#38646;&#20540;&#12290;&#36825;&#31181;&#31354;&#38388;&#38646;&#20540;&#26041;&#27861;&#22312;&#19968;&#20010;&#21512;&#25104;&#31034;&#20363;&#21644;&#38146;&#31163;&#23376;&#30005;&#27744;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#26696;&#20363;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#26681;&#25454;&#20808;&#21069;&#30340;&#29289;&#29702;&#30693;&#35782;&#36873;&#25321;&#21512;&#36866;&#30340;&#27491;&#21017;&#21270;&#21644;z-score&#22788;&#29702;&#65292;&#21487;&#20197;&#24471;&#21040;&#21487;&#35299;&#37322;&#30340;&#22238;&#24402;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional linear regression is important in many scientific fields. This article considers discrete measured data of underlying smooth latent processes, as is often obtained from chemical or biological systems. Interpretation in high dimensions is challenging because the nullspace and its interplay with regularization shapes regression coefficients. The data's nullspace contains all coefficients that satisfy $\mathbf{Xw}=\mathbf{0}$, thus allowing very different coefficients to yield identical predictions. We developed an optimization formulation to compare regression coefficients and coefficients obtained by physical engineering knowledge to understand which part of the coefficient differences are close to the nullspace. This nullspace method is tested on a synthetic example and lithium-ion battery data. The case studies show that regularization and z-scoring are design choices that, if chosen corresponding to prior physical knowledge, lead to interpretable regression results. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#20114;&#23398;&#20064;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#38544;&#31169;&#20445;&#25252;&#30340;Bandit&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#38544;&#31169;&#39044;&#31639;&#19979;&#30340;&#38590;&#24230;&#21306;&#22495;&#65292;&#24182;&#21457;&#29616;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#21487;&#20197;&#27604;&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#26356;&#26377;&#25928;&#22320;&#20445;&#25252;&#38544;&#31169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.00557</link><description>&lt;p&gt;
&#20132;&#20114;&#24335;&#21644;&#38598;&#20013;&#24335;&#24046;&#20998;&#38544;&#31169;&#22312;Bandit&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Interactive and Concentrated Differential Privacy for Bandits. (arXiv:2309.00557v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#20114;&#23398;&#20064;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#38544;&#31169;&#20445;&#25252;&#30340;Bandit&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#38544;&#31169;&#39044;&#31639;&#19979;&#30340;&#38590;&#24230;&#21306;&#22495;&#65292;&#24182;&#21457;&#29616;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#21487;&#20197;&#27604;&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#26356;&#26377;&#25928;&#22320;&#20445;&#25252;&#38544;&#31169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bandit&#38382;&#39064;&#22312;&#20132;&#20114;&#24335;&#23398;&#20064;&#26041;&#26696;&#21644;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#36890;&#24120;&#20381;&#36182;&#20110;&#25935;&#24863;&#30340;&#29992;&#25143;&#25968;&#25454;&#65292;&#22240;&#27492;&#38544;&#31169;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20132;&#20114;&#24335;&#24046;&#20998;&#38544;&#31169;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22522;&#20110;&#21487;&#20449;&#38598;&#20013;&#24335;&#20915;&#31574;&#32773;&#30340;Bandit&#38382;&#39064;&#30340;&#38544;&#31169;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#23545;&#32431;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#30340;Bandit&#38382;&#39064;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#25105;&#20204;&#22312;&#29702;&#35299;&#38646;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;(zCDP)&#30340;Bandit&#38382;&#39064;&#26041;&#38754;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#38024;&#23545;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36951;&#25022;&#30340;&#26368;&#23567;&#26368;&#22823;&#21644;&#38382;&#39064;&#30456;&#20851;&#19979;&#30028;&#65292;&#20174;&#32780;&#37327;&#21270;&#20102;&#36825;&#20123;&#24773;&#20917;&#19979;&#961;-&#20840;&#23616;zCDP&#30340;&#20195;&#20215;&#12290;&#36825;&#20123;&#19979;&#30028;&#25581;&#31034;&#20102;&#22522;&#20110;&#38544;&#31169;&#39044;&#31639;&#961;&#30340;&#20004;&#20010;&#22256;&#38590;&#21306;&#22495;&#65292;&#24182;&#34920;&#26126;&#961;-&#20840;&#23616;zCDP&#27604;&#32431;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#20135;&#29983;&#30340;&#36951;&#25022;&#26356;&#23567;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#30340;&#961;-&#20840;&#23616;zCDP&#31639;&#27861;&#65292;&#21363;AdaC-UCB&#21644;AdaC-GOPE&#12290;&#36825;&#20004;&#20010;&#31639;&#27861;&#37117;&#20351;&#29992;&#20102;&#39640;&#26031;&#26426;&#21046;&#30340;&#20849;&#21516;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bandits play a crucial role in interactive learning schemes and modern recommender systems. However, these systems often rely on sensitive user data, making privacy a critical concern. This paper investigates privacy in bandits with a trusted centralized decision-maker through the lens of interactive Differential Privacy (DP). While bandits under pure $\epsilon$-global DP have been well-studied, we contribute to the understanding of bandits under zero Concentrated DP (zCDP). We provide minimax and problem-dependent lower bounds on regret for finite-armed and linear bandits, which quantify the cost of $\rho$-global zCDP in these settings. These lower bounds reveal two hardness regimes based on the privacy budget $\rho$ and suggest that $\rho$-global zCDP incurs less regret than pure $\epsilon$-global DP. We propose two $\rho$-global zCDP bandit algorithms, AdaC-UCB and AdaC-GOPE, for finite-armed and linear bandits respectively. Both algorithms use a common recipe of Gaussian mechanism 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#21512;&#22238;&#24402;&#30340;&#26465;&#20214;&#29983;&#23384;&#39044;&#27979;&#26041;&#27861;&#65292;&#20854;&#20013;&#20351;&#29992;&#38754;&#31215;&#20316;&#20026;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#36890;&#36807;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#21464;&#37327;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.00417</link><description>&lt;p&gt;
&#26465;&#20214;&#29983;&#23384;&#39044;&#27979;&#20013;&#30340;&#38754;&#31215;&#35268;&#33539;COBRA
&lt;/p&gt;
&lt;p&gt;
Area-norm COBRA on Conditional Survival Prediction. (arXiv:2309.00417v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#21512;&#22238;&#24402;&#30340;&#26465;&#20214;&#29983;&#23384;&#39044;&#27979;&#26041;&#27861;&#65292;&#20854;&#20013;&#20351;&#29992;&#38754;&#31215;&#20316;&#20026;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#36890;&#36807;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#21464;&#37327;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#32452;&#21512;&#22238;&#24402;&#31574;&#30053;&#26469;&#35745;&#31639;&#26465;&#20214;&#29983;&#23384;&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22238;&#24402;&#30340;&#24369;&#23398;&#20064;&#22120;&#26469;&#21019;&#24314;&#25152;&#25552;&#20986;&#30340;&#38598;&#25104;&#25216;&#26415;&#12290;&#25152;&#25552;&#20986;&#30340;&#32452;&#21512;&#22238;&#24402;&#31574;&#30053;&#20351;&#29992;&#30456;&#20284;&#24230;&#24230;&#37327;&#20316;&#20026;&#20004;&#20010;&#29983;&#23384;&#26354;&#32447;&#20043;&#38388;&#30340;&#38754;&#31215;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#34920;&#26126;&#20854;&#34920;&#29616;&#20248;&#20110;&#38543;&#26426;&#29983;&#23384;&#26862;&#26519;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#19968;&#31181;&#22312;&#32452;&#21512;&#22238;&#24402;&#35774;&#32622;&#20013;&#36873;&#25321;&#26368;&#37325;&#35201;&#21464;&#37327;&#30340;&#26032;&#25216;&#26415;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#27169;&#25311;&#30740;&#31350;&#65292;&#34920;&#26126;&#25105;&#20204;&#23545;&#21464;&#37327;&#30456;&#20851;&#24615;&#30340;&#25552;&#35758;&#25928;&#26524;&#24456;&#22909;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#26469;&#35828;&#26126;&#35813;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper explores a different variation of combined regression strategy to calculate the conditional survival function. We use regression based weak learners to create the proposed ensemble technique. The proposed combined regression strategy uses proximity measure as area between two survival curves. The proposed model shows a construction which ensures that it performs better than the Random Survival Forest. The paper discusses a novel technique to select the most important variable in the combined regression setup. We perform a simulation study to show that our proposition for finding relevance of the variables works quite well. We also use three real-life datasets to illustrate the model.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#20010;&#24615;&#21270;&#12289;&#38544;&#31169;&#20445;&#35777;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#35299;&#20915;&#20102;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#30340;&#19977;&#20803;&#20132;&#20114;&#20316;&#29992;&#12290;&#24046;&#20998;&#38544;&#31169;&#21450;&#20854;&#21464;&#20307;&#34987;&#24212;&#29992;&#20026;&#25552;&#20379;&#27491;&#24335;&#38544;&#31169;&#20445;&#35777;&#30340;&#21069;&#27839;&#26631;&#20934;&#12290;&#22312;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#38598;&#20013;&#23547;&#27714;&#20844;&#24179;&#24615;&#21464;&#24471;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2309.00416</link><description>&lt;p&gt;
&#25512;&#36827;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#65306;&#22242;&#20307;&#38544;&#31169;&#12289;&#20844;&#24179;&#24615;&#31561;&#26041;&#38754;&#30340;&#31361;&#30772;
&lt;/p&gt;
&lt;p&gt;
Advancing Personalized Federated Learning: Group Privacy, Fairness, and Beyond. (arXiv:2309.00416v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00416
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#20010;&#24615;&#21270;&#12289;&#38544;&#31169;&#20445;&#35777;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#35299;&#20915;&#20102;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#30340;&#19977;&#20803;&#20132;&#20114;&#20316;&#29992;&#12290;&#24046;&#20998;&#38544;&#31169;&#21450;&#20854;&#21464;&#20307;&#34987;&#24212;&#29992;&#20026;&#25552;&#20379;&#27491;&#24335;&#38544;&#31169;&#20445;&#35777;&#30340;&#21069;&#27839;&#26631;&#20934;&#12290;&#22312;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#38598;&#20013;&#23547;&#27714;&#20844;&#24179;&#24615;&#21464;&#24471;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064; (FL) &#26159;&#19968;&#31181;&#22312;&#20998;&#24067;&#24335;&#21644;&#21327;&#20316;&#26041;&#24335;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26694;&#26550;&#12290;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#19968;&#32452;&#21442;&#19982;&#30340;&#23458;&#25143;&#31471;&#22788;&#29702;&#26412;&#22320;&#23384;&#20648;&#30340;&#25968;&#25454;&#65292;&#20165;&#20849;&#20139;&#36890;&#36807;&#26368;&#23567;&#21270;&#20854;&#26412;&#22320;&#36755;&#20837;&#30340;&#25104;&#26412;&#20989;&#25968;&#33719;&#24471;&#30340;&#27169;&#22411;&#26356;&#26032;&#12290;FL&#34987;&#25552;&#20986;&#20316;&#20026;&#38544;&#31169;&#20445;&#25252;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#31181;&#36884;&#24452;&#65292;&#20294;&#24050;&#34987;&#35777;&#26126;&#26131;&#21463;&#31169;&#20154;&#20449;&#24687;&#27844;&#38706;&#12289;&#27169;&#22411;&#20010;&#24615;&#21270;&#32570;&#22833;&#20197;&#21450;&#21487;&#33021;&#23548;&#33268;&#26576;&#20123;&#32676;&#20307;&#27604;&#20854;&#20182;&#32676;&#20307;&#26356;&#20844;&#24179;&#30340;&#35757;&#32451;&#27169;&#22411;&#31561;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;FL&#26694;&#26550;&#20013;&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#20010;&#24615;&#21270;&#12289;&#38544;&#31169;&#20445;&#35777;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#19977;&#20803;&#20132;&#20114;&#20316;&#29992;&#12290;&#24046;&#20998;&#38544;&#31169;&#21450;&#20854;&#21464;&#20307;&#24050;&#34987;&#30740;&#31350;&#21644;&#24212;&#29992;&#20026;&#25552;&#20379;&#27491;&#24335;&#38544;&#31169;&#20445;&#35777;&#30340;&#21069;&#27839;&#26631;&#20934;&#12290;&#28982;&#32780;&#65292;FL&#20013;&#30340;&#23458;&#25143;&#31471;&#24448;&#24448;&#25317;&#26377;&#38750;&#24120;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#38598;&#65292;&#20195;&#34920;&#30528;&#24322;&#36136;&#30340;&#31038;&#21306;&#65292;&#36825;&#20351;&#24471;&#20445;&#35777;&#20844;&#24179;&#24615;&#21464;&#24471;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) is a framework for training machine learning models in a distributed and collaborative manner. During training, a set of participating clients process their data stored locally, sharing only the model updates obtained by minimizing a cost function over their local inputs. FL was proposed as a stepping-stone towards privacy-preserving machine learning, but it has been shown vulnerable to issues such as leakage of private information, lack of personalization of the model, and the possibility of having a trained model that is fairer to some groups than to others. In this paper, we address the triadic interaction among personalization, privacy guarantees, and fairness attained by models trained within the FL framework. Differential privacy and its variants have been studied and applied as cutting-edge standards for providing formal privacy guarantees. However, clients in FL often hold very diverse datasets representing heterogeneous communities, making it important 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32534;&#30721;&#29305;&#24449;&#32858;&#21512;&#26041;&#26696;&#65292;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#12290;</title><link>http://arxiv.org/abs/2309.00380</link><description>&lt;p&gt;
&#29992;&#25490;&#24207;&#19981;&#21464;&#30340;&#32534;&#30721;&#22120;&#21644;&#26356;&#32039;&#30340;&#21464;&#20998;&#36793;&#30028;&#23398;&#20064;&#22810;&#27169;&#24577;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning multi-modal generative models with permutation-invariant encoders and tighter variational bounds. (arXiv:2309.00380v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32534;&#30721;&#29305;&#24449;&#32858;&#21512;&#26041;&#26696;&#65292;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#19968;&#30452;&#26159;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#20027;&#39064;&#12290;&#22810;&#27169;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120; (VAE) &#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#29983;&#25104;&#27169;&#22411;&#31867;&#21035;&#65292;&#23427;&#23398;&#20064;&#33021;&#22815;&#20849;&#21516;&#35299;&#37322;&#22810;&#31181;&#27169;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#21508;&#31181;&#23458;&#35266;&#20989;&#25968;&#24050;&#34987;&#25552;&#20986;&#29992;&#20110;&#36825;&#26679;&#30340;&#27169;&#22411;&#65292;&#24448;&#24448;&#20197;&#22810;&#27169;&#24577;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#30340;&#19979;&#30028;&#20197;&#21450;&#20449;&#24687;&#35770;&#26041;&#38754;&#30340;&#32771;&#34385;&#20026;&#21160;&#26426;&#12290;&#20026;&#20102;&#23545;&#19981;&#21516;&#27169;&#24577;&#23376;&#38598;&#36827;&#34892;&#32534;&#30721;&#65292;&#25105;&#20204;&#32463;&#24120;&#20351;&#29992;&#24182;&#23637;&#31034;&#20102;&#20135;&#21697;&#22411;&#19987;&#23478; (PoE) &#25110;&#32773;&#28151;&#21512;&#22411;&#19987;&#23478; (MoE) &#32858;&#21512;&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#22312;&#29983;&#25104;&#36136;&#37327;&#25110;&#32773;&#22810;&#27169;&#24577;&#19968;&#33268;&#24615;&#31561;&#26041;&#38754;&#20855;&#26377;&#19981;&#21516;&#30340;&#26435;&#34913;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#30340;&#21464;&#20998;&#36793;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#19981;&#21516;&#27169;&#24577;&#30340;&#32534;&#30721;&#29305;&#24449;&#32452;&#21512;&#36215;&#26469;&#65292;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32858;&#21512;&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#25512;&#24191;&#20102; PoE &#25110;&#32773; MoE &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Devising deep latent variable models for multi-modal data has been a long-standing theme in machine learning research. Multi-modal Variational Autoencoders (VAEs) have been a popular generative model class that learns latent representations which jointly explain multiple modalities. Various objective functions for such models have been suggested, often motivated as lower bounds on the multi-modal data log-likelihood or from information-theoretic considerations. In order to encode latent variables from different modality subsets, Product-of-Experts (PoE) or Mixture-of-Experts (MoE) aggregation schemes have been routinely used and shown to yield different trade-offs, for instance, regarding their generative quality or consistency across multiple modalities. In this work, we consider a variational bound that can tightly lower bound the data log-likelihood. We develop more flexible aggregation schemes that generalise PoE or MoE approaches by combining encoded features from different modali
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#20989;&#25968;&#24615;&#25688;&#35201;&#26426;&#21046;&#65292;&#36890;&#36807;&#20351;&#29992;&#29420;&#31435;&#20998;&#37327;&#25289;&#26222;&#25289;&#26031;&#36807;&#31243;&#23545;&#26080;&#38480;&#32500;&#30340;&#20989;&#25968;&#24615;&#25688;&#35201;&#36827;&#34892;&#25200;&#21160;&#65292;&#25918;&#23485;&#20102;&#23545;&#25968;&#25454;&#36712;&#36857;&#30340;&#20551;&#35774;&#65292;&#24182;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#26377;&#38480;&#32500;&#23376;&#31354;&#38388;&#23884;&#20837;&#26041;&#27861;&#20445;&#30041;&#20102;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.00125</link><description>&lt;p&gt;
&#36890;&#36807;&#29420;&#31435;&#20998;&#37327;&#25289;&#26222;&#25289;&#26031;&#36807;&#31243;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#30340;&#20989;&#25968;&#24615;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Functional Summaries via the Independent Component Laplace Process. (arXiv:2309.00125v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#20989;&#25968;&#24615;&#25688;&#35201;&#26426;&#21046;&#65292;&#36890;&#36807;&#20351;&#29992;&#29420;&#31435;&#20998;&#37327;&#25289;&#26222;&#25289;&#26031;&#36807;&#31243;&#23545;&#26080;&#38480;&#32500;&#30340;&#20989;&#25968;&#24615;&#25688;&#35201;&#36827;&#34892;&#25200;&#21160;&#65292;&#25918;&#23485;&#20102;&#23545;&#25968;&#25454;&#36712;&#36857;&#30340;&#20551;&#35774;&#65292;&#24182;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#26377;&#38480;&#32500;&#23376;&#31354;&#38388;&#23884;&#20837;&#26041;&#27861;&#20445;&#30041;&#20102;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#29420;&#31435;&#20998;&#37327;&#25289;&#26222;&#25289;&#26031;&#36807;&#31243;&#65288;ICLP&#65289;&#26426;&#21046;&#30340;&#24046;&#20998;&#38544;&#31169;&#20989;&#25968;&#24615;&#25688;&#35201;&#30340;&#26032;&#26426;&#21046;&#12290;&#36890;&#36807;&#23558;&#24863;&#20852;&#36259;&#30340;&#20989;&#25968;&#24615;&#25688;&#35201;&#35270;&#20026;&#30495;&#27491;&#26080;&#38480;&#32500;&#23545;&#35937;&#65292;&#24182;&#20351;&#29992;ICLP&#22122;&#22768;&#26469;&#25200;&#21160;&#23427;&#20204;&#65292;&#35813;&#26032;&#26426;&#21046;&#25918;&#23485;&#20102;&#20851;&#20110;&#25968;&#25454;&#36712;&#36857;&#30340;&#20551;&#35774;&#65292;&#24182;&#30456;&#23545;&#20110;&#25991;&#29486;&#20013;&#30340;&#32463;&#20856;&#26377;&#38480;&#32500;&#23376;&#31354;&#38388;&#23884;&#20837;&#26041;&#27861;&#20445;&#30041;&#20102;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#20989;&#25968;&#31354;&#38388;&#20013;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20960;&#20010;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36731;&#24494;&#36807;&#24179;&#28369;&#25688;&#35201;&#26469;&#35777;&#26126;&#38544;&#31169;&#25104;&#26412;&#19981;&#20250;&#20027;&#23548;&#32479;&#35745;&#35823;&#24046;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#21487;&#20197;&#24573;&#30053;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26426;&#21046;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a new mechanism for releasing differentially private functional summaries called the Independent Component Laplace Process, or ICLP, mechanism. By treating the functional summaries of interest as truly infinite-dimensional objects and perturbing them with the ICLP noise, this new mechanism relaxes assumptions on data trajectories and preserves higher utility compared to classical finite-dimensional subspace embedding approaches in the literature. We establish the feasibility of the proposed mechanism in multiple function spaces. Several statistical estimation problems are considered, and we demonstrate by slightly over-smoothing the summary, the privacy cost will not dominate the statistical error and is asymptotically negligible. Numerical experiments on synthetic and real datasets demonstrate the efficacy of the proposed mechanism.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#23384;&#22312;&#38544;&#24335;&#35268;&#33539;&#21270;&#20316;&#29992;&#65292;&#20854;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.00079</link><description>&lt;p&gt;
&#20851;&#20110;Adam&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
On the Implicit Bias of Adam. (arXiv:2309.00079v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#23384;&#22312;&#38544;&#24335;&#35268;&#33539;&#21270;&#20316;&#29992;&#65292;&#20854;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20197;&#21069;&#30340;&#25991;&#29486;&#20013;&#65292;&#21518;&#21521;&#35823;&#24046;&#20998;&#26512;&#34987;&#29992;&#26469;&#25214;&#21040;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#36712;&#36857;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#12290;&#21457;&#29616;&#26377;&#38480;&#27493;&#38271;&#20250;&#38544;&#24335;&#22320;&#35268;&#33539;&#21270;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#20986;&#29616;&#22312;ODE&#20013;&#30340;&#39033;&#20250;&#24809;&#32602;&#25439;&#22833;&#26799;&#24230;&#30340;&#20108;&#33539;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#20013;&#26159;&#21542;&#23384;&#22312;&#31867;&#20284;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#21462;&#20915;&#20110;&#23427;&#20204;&#30340;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#20294;&#28041;&#21450;&#30340;&#8220;&#33539;&#25968;&#8221;&#19981;&#21516;&#65306;&#23545;&#24212;&#30340;ODE&#39033;&#35201;&#20040;&#24809;&#32602;&#65288;&#25200;&#21160;&#30340;&#65289;&#25439;&#22833;&#26799;&#24230;&#30340;&#19968;&#33539;&#25968;&#65292;&#35201;&#20040;&#30456;&#21453;&#22320;&#38459;&#27490;&#20854;&#20943;&#23567;&#65288;&#21518;&#19968;&#31181;&#24773;&#20917;&#26159;&#20856;&#22411;&#30340;&#65289;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#22914;&#20309;&#24433;&#21709;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In previous literature, backward error analysis was used to find ordinary differential equations (ODEs) approximating the gradient descent trajectory. It was found that finite step sizes implicitly regularize solutions because terms appearing in the ODEs penalize the two-norm of the loss gradients. We prove that the existence of similar implicit regularization in RMSProp and Adam depends on their hyperparameters and the training stage, but with a different "norm" involved: the corresponding ODE terms either penalize the (perturbed) one-norm of the loss gradients or, on the contrary, hinder its decrease (the latter case being typical). We also conduct numerical experiments and discuss how the proven facts can influence generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#22238;&#24402;&#38382;&#39064;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35299;&#37322;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#21487;&#20197;&#37327;&#21270;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16245</link><description>&lt;p&gt;
&#22238;&#24402;&#38382;&#39064;&#30340;&#26657;&#20934;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16245
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#22238;&#24402;&#38382;&#39064;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35299;&#37322;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#21487;&#20197;&#37327;&#21270;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#36890;&#24120;&#26159;&#29616;&#20195;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;DSS&#65289;&#30340;&#19968;&#37096;&#20998;&#12290;&#22312;&#22522;&#20110;AI&#30340;DSS&#20013;&#20351;&#29992;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#32570;&#20047;&#36879;&#26126;&#24230;&#12290;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26088;&#22312;&#21019;&#24314;&#33021;&#22815;&#21521;&#20154;&#31867;&#29992;&#25143;&#35299;&#37322;&#20854;&#29702;&#30001;&#30340;AI&#31995;&#32479;&#12290;XAI&#20013;&#30340;&#23616;&#37096;&#35299;&#37322;&#21487;&#20197;&#25552;&#20379;&#20851;&#20110;&#20010;&#21035;&#39044;&#27979;&#30340;&#21407;&#22240;&#30340;&#20449;&#24687;&#65292;&#21363;&#29305;&#24449;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#23616;&#37096;&#35299;&#37322;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#32570;&#28857;&#26159;&#26080;&#27861;&#37327;&#21270;&#19982;&#29305;&#24449;&#37325;&#35201;&#24615;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#29305;&#24449;&#37325;&#35201;&#24615;&#35299;&#37322;&#26041;&#27861;Calibrated Explanations&#65288;CE&#65289;&#30340;&#25193;&#23637;&#65292;&#20043;&#21069;&#21482;&#25903;&#25345;&#20998;&#31867;&#65292;&#29616;&#22312;&#25903;&#25345;&#26631;&#20934;&#22238;&#24402;&#21644;&#27010;&#29575;&#22238;&#24402;&#65292;&#21363;&#30446;&#26631;&#36229;&#36807;&#20219;&#24847;&#38408;&#20540;&#30340;&#27010;&#29575;&#12290;&#22238;&#24402;&#38382;&#39064;&#30340;&#25193;&#23637;&#20445;&#30041;&#20102;CE&#30340;&#25152;&#26377;&#20248;&#28857;&#65292;&#20363;&#22914;&#23558;&#24213;&#23618;&#27169;&#22411;&#30340;&#39044;&#27979;&#19982;&#32622;&#20449;&#24230;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence (AI) is often an integral part of modern decision support systems (DSSs). The best-performing predictive models used in AI-based DSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance. However, a critical drawback of existing local explanation methods is their inability to quantify the uncertainty associated with a feature's importance. This paper introduces an extension of a feature importance explanation method, Calibrated Explanations (CE), previously only supporting classification, with support for standard regression and probabilistic regression, i.e., the probability that the target is above an arbitrary threshold. The extension for regression keeps all the benefits of CE, such as calibration of the prediction from the underlying model with confidenc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#21161;&#22521;&#35757;&#20307;&#21046;&#65292;&#21033;&#29992;&#29420;&#31435;&#23376;&#32593;&#32476;&#30340;&#38598;&#25104;&#21644;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#25552;&#39640;&#33258;&#21161;&#30340;&#40065;&#26834;&#24615;&#34920;&#31034;&#23398;&#20064;&#30340;&#25928;&#29575;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.14705</link><description>&lt;p&gt;
&#33258;&#21161;&#30340;&#40065;&#26834;&#24615;&#34920;&#31034;&#23398;&#20064;&#30340;&#29420;&#31435;&#23376;&#32593;&#32476;&#22810;&#26679;&#21270;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning. (arXiv:2308.14705v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#21161;&#22521;&#35757;&#20307;&#21046;&#65292;&#21033;&#29992;&#29420;&#31435;&#23376;&#32593;&#32476;&#30340;&#38598;&#25104;&#21644;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#25552;&#39640;&#33258;&#21161;&#30340;&#40065;&#26834;&#24615;&#34920;&#31034;&#23398;&#20064;&#30340;&#25928;&#29575;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#31070;&#32463;&#32593;&#32476;&#26159;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12289;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#21644;&#25913;&#21892;&#28145;&#24230;&#26377;&#30417;&#30563;&#23398;&#20064;&#40065;&#26834;&#24615;&#30340;&#24191;&#27867;&#25215;&#35748;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#28145;&#23618;&#38598;&#25104;&#36890;&#24120;&#20855;&#26377;&#39640;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#27492;&#22806;&#65292;&#28145;&#24230;&#38598;&#25104;&#30340;&#25928;&#29575;&#19982;&#38598;&#25104;&#25104;&#21592;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#26377;&#20851;&#65292;&#36825;&#23545;&#20110;&#22823;&#22411;&#30340;&#36807;&#21442;&#25968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#35828;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#32780;&#19988;&#65292;&#38598;&#25104;&#23398;&#20064;&#23578;&#26410;&#24471;&#21040;&#22914;&#27492;&#24191;&#27867;&#30340;&#37319;&#29992;&#65292;&#24182;&#19988;&#23545;&#20110;&#33258;&#21161;&#30340;&#25110;&#26080;&#30417;&#30563;&#30340;&#34920;&#31034;&#23398;&#20064;&#26469;&#35828;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24037;&#20316;&#12290;&#22312;&#36825;&#20123;&#25361;&#25112;&#30340;&#25512;&#21160;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#33258;&#21161;&#22521;&#35757;&#20307;&#21046;&#65292;&#21033;&#29992;&#29420;&#31435;&#23376;&#32593;&#32476;&#30340;&#38598;&#25104;&#65292;&#36741;&#20197;&#19968;&#20010;&#26088;&#22312;&#40723;&#21169;&#22810;&#26679;&#24615;&#30340;&#26032;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20197;&#39640;&#22810;&#26679;&#24615;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#23376;&#27169;&#22411;&#38598;&#25104;&#65292;&#20174;&#32780;&#33719;&#24471;&#20102;&#33391;&#22909;&#26657;&#20934;&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#35745;&#31639;&#24320;&#38144;&#26368;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling a neural network is a widely recognized approach to enhance model performance, estimate uncertainty, and improve robustness in deep supervised learning. However, deep ensembles often come with high computational costs and memory demands. In addition, the efficiency of a deep ensemble is related to diversity among the ensemble members which is challenging for large, over-parameterized deep neural networks. Moreover, ensemble learning has not yet seen such widespread adoption, and it remains a challenging endeavor for self-supervised or unsupervised representation learning. Motivated by these challenges, we present a novel self-supervised training regime that leverages an ensemble of independent sub-networks, complemented by a new loss function designed to encourage diversity. Our method efficiently builds a sub-model ensemble with high diversity, leading to well-calibrated estimates of model uncertainty, all achieved with minimal computational overhead compared to traditional
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2303.00848</link><description>&lt;p&gt;
&#20197;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#29702;&#35299;&#25193;&#25955;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#37319;&#29992;&#19981;&#21516;&#30340;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#37117;&#26159;&#21152;&#26435;&#25439;&#22833;&#30340;&#29305;&#20363;&#65292;&#20854;&#20013;&#21152;&#26435;&#20989;&#25968;&#25351;&#23450;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#30340;&#26435;&#37325;&#12290;&#22343;&#21248;&#21152;&#26435;&#23545;&#24212;&#20110;&#26368;&#22823;&#20284;&#28982;&#30340;&#21407;&#21017;&#24615;&#36817;&#20284;ELBO&#30340;&#26368;&#22823;&#21270;&#12290;&#20294;&#26159;&#23454;&#38469;&#19978;&#65292;&#30001;&#20110;&#26356;&#22909;&#30340;&#26679;&#26412;&#36136;&#37327;&#65292;&#30446;&#21069;&#30340;&#25193;&#25955;&#27169;&#22411;&#20351;&#29992;&#38750;&#22343;&#21248;&#21152;&#26435;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#65288;&#24102;&#26377;&#20219;&#20309;&#21152;&#26435;&#65289;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21487;&#20197;&#34987;&#20889;&#25104;&#19968;&#31181;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#24418;&#24335;&#65292;&#20854;&#20013;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#37117;&#26377;&#19968;&#20010;ELBO&#12290;&#22914;&#26524;&#26435;&#37325;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#65292;&#37027;&#20040;&#21152;&#26435;&#25439;&#22833;&#26159;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#30340;&#30446;&#26631;&#65306;&#23427;&#22312;&#31616;&#21333;&#30340;&#25968;&#25454;&#22686;&#24378;&#19979;&#65288;&#21363;&#39640;&#26031;&#22122;&#22768;&#25200;&#21160;&#65289;&#19979;&#26368;&#22823;&#21270;ELBO&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#20294;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#27604;&#36739;&#21333;&#35843;&#21644;&#38750;&#21333;&#35843;&#26435;&#37325;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#31639;&#27861;&#22312;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#23398;&#20064;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22797;&#26434;&#24230;&#24230;&#37327;&#31216;&#20026;&#36291;&#36801;&#65292;&#35777;&#26126;&#20102;&#22312;&#39640;&#26031;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#21644;&#20108;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#30740;&#31350;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#35757;&#32451;&#36807;&#31243;&#20013;&#20989;&#25968;&#25903;&#25345;&#30340;&#21160;&#24577;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.11055</link><description>&lt;p&gt;
SGD&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;: &#36291;&#36801;&#22797;&#26434;&#24230;&#19982;&#38797;&#21040;&#38797;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
SGD learning on neural networks: leap complexity and saddle-to-saddle dynamics. (arXiv:2302.11055v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11055
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#31639;&#27861;&#22312;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#23398;&#20064;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22797;&#26434;&#24230;&#24230;&#37327;&#31216;&#20026;&#36291;&#36801;&#65292;&#35777;&#26126;&#20102;&#22312;&#39640;&#26031;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#21644;&#20108;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#30740;&#31350;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#35757;&#32451;&#36807;&#31243;&#20013;&#20989;&#25968;&#25903;&#25345;&#30340;&#21160;&#24577;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#23398;&#20064;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22797;&#26434;&#24230;&#24230;&#37327;&#8212;&#8212;&#36291;&#36801;&#65292;&#29992;&#26469;&#24230;&#37327;&#30446;&#26631;&#20989;&#25968;&#30340;"&#23618;&#32423;"&#31243;&#24230;&#12290;&#23545;&#20110;$d$&#32500;&#22343;&#21248;&#24067;&#23572;&#25110;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#25968;&#25454;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#29468;&#24819;&#26159;&#23398;&#20064;&#19968;&#20010;&#20302;&#32500;&#25903;&#25345;&#20989;&#25968;$f$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;$\tilde\Theta (d^{\max(\mathrm{Leap}(f),2)})$&#12290;&#25105;&#20204;&#22312;&#39069;&#22806;&#23545;SGD&#30340;&#25216;&#26415;&#20551;&#35774;&#19979;&#65292;&#35777;&#26126;&#20102;&#36825;&#20010;&#29468;&#24819;&#22312;&#39640;&#26031;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#21644;&#20108;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#19968;&#20010;&#29256;&#26412;&#12290;&#25105;&#20204;&#23637;&#31034;&#20986;&#35757;&#32451;&#36807;&#31243;&#20197;&#38797;&#28857;&#21040;&#38797;&#28857;&#30340;&#21160;&#24577;&#26041;&#24335;&#36880;&#28176;&#23398;&#20064;&#20102;&#20989;&#25968;&#30340;&#25903;&#25345;&#12290;&#19982;[Abbe et al. 2022]&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36229;&#36234;&#20102;&#36291;&#36801;1(&#21512;&#24182;&#38454;&#26799;&#20989;&#25968;)&#30340;&#38480;&#21046;&#65292;&#24182;&#36229;&#36234;&#20102;&#22343;&#22330;&#21644;&#26799;&#24230;&#27969;&#36817;&#20284;&#65292;&#22312;&#36825;&#37324;&#21487;&#20197;&#33719;&#24471;&#23436;&#20840;&#30340;&#22797;&#26434;&#24230;&#25511;&#21046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;&#36825;&#32473;&#20986;&#20102;&#23436;&#25972;&#35757;&#32451;&#30340;SGD&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the time complexity of SGD learning on fully-connected neural networks with isotropic data. We put forward a complexity measure -- the leap -- which measures how "hierarchical" target functions are. For $d$-dimensional uniform Boolean or isotropic Gaussian data, our main conjecture states that the time complexity to learn a function $f$ with low-dimensional support is $\tilde\Theta (d^{\max(\mathrm{Leap}(f),2)})$. We prove a version of this conjecture for a class of functions on Gaussian isotropic data and 2-layer neural networks, under additional technical assumptions on how SGD is run. We show that the training sequentially learns the function support with a saddle-to-saddle dynamic. Our result departs from [Abbe et al. 2022] by going beyond leap 1 (merged-staircase functions), and by going beyond the mean-field and gradient flow approximations that prohibit the full complexity control obtained here. Finally, we note that this gives an SGD complexity for the full train
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#33258;&#36866;&#24212;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;Hawkes&#36807;&#31243;&#30340;&#20381;&#36182;&#20851;&#31995;&#21644;&#38750;&#21442;&#25968;&#25512;&#26029;&#12290;&#36890;&#36807;&#20998;&#26512;&#20808;&#39564;&#12289;&#21464;&#20998;&#31867;&#21644;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#26465;&#20214;&#65292;&#25105;&#20204;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#28176;&#36817;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2212.00293</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#21644;&#33258;&#36866;&#24212;&#30340;Hawkes&#36807;&#31243;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Scalable and adaptive variational Bayes methods for Hawkes processes. (arXiv:2212.00293v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.00293
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#33258;&#36866;&#24212;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;Hawkes&#36807;&#31243;&#30340;&#20381;&#36182;&#20851;&#31995;&#21644;&#38750;&#21442;&#25968;&#25512;&#26029;&#12290;&#36890;&#36807;&#20998;&#26512;&#20808;&#39564;&#12289;&#21464;&#20998;&#31867;&#21644;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#26465;&#20214;&#65292;&#25105;&#20204;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Hawkes&#36807;&#31243;&#24120;&#29992;&#20110;&#24314;&#27169;&#22810;&#20803;&#20107;&#20214;&#25968;&#25454;&#38598;&#20013;&#30340;&#20381;&#36182;&#21644;&#30456;&#20114;&#20316;&#29992;&#29616;&#35937;&#65292;&#22914;&#31070;&#32463;&#23574;&#23792;&#24207;&#21015;&#12289;&#31038;&#20132;&#20114;&#21160;&#21644;&#37329;&#34701;&#20132;&#26131;&#12290;&#22312;&#38750;&#21442;&#25968;&#35774;&#32622;&#20013;&#65292;&#23398;&#20064;Hawkes&#36807;&#31243;&#30340;&#26102;&#38388;&#20381;&#36182;&#32467;&#26500;&#36890;&#24120;&#26159;&#19968;&#39033;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#30340;&#20219;&#21153;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;&#24191;&#20041;&#38750;&#32447;&#24615;Hawkes&#36807;&#31243;&#65292;&#24212;&#29992;&#20110;&#35745;&#31639;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#26080;&#27861;&#25193;&#23637;&#21040;&#39640;&#32500;&#36807;&#31243;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#21518;&#39564;&#20998;&#24067;&#24179;&#22343;&#22330;&#21464;&#20998;&#36924;&#36817;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#20010;&#36890;&#29992;&#30340;&#38750;&#21442;&#25968;&#25512;&#26029;&#26694;&#26550;&#19979;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#20808;&#39564;&#12289;&#21464;&#20998;&#31867;&#21644;&#38750;&#32447;&#24615;&#27169;&#22411;&#19978;&#30340;&#26131;&#20110;&#39564;&#35777;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hawkes processes are often applied to model dependence and interaction phenomena in multivariate event data sets, such as neuronal spike trains, social interactions, and financial transactions. In the nonparametric setting, learning the temporal dependence structure of Hawkes processes is generally a computationally expensive task, all the more with Bayesian estimation methods. In particular, for generalised nonlinear Hawkes processes, Monte-Carlo Markov Chain methods applied to compute the doubly intractable posterior distribution are not scalable to high-dimensional processes in practice. Recently, efficient algorithms targeting a mean-field variational approximation of the posterior distribution have been proposed. In this work, we first unify existing variational Bayes approaches under a general nonparametric inference framework, and analyse the asymptotic properties of these methods under easily verifiable conditions on the prior, the variational class, and the nonlinear model. Se
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21033;&#29992;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2211.02039</link><description>&lt;p&gt;
&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#30340;&#25237;&#24433;&#21327;&#26041;&#24046;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
The Projected Covariance Measure for assumption-lean variable significance testing. (arXiv:2211.02039v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02039
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21033;&#29992;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#20013;&#65292;&#23545;&#20110;&#32473;&#23450;&#38468;&#21152;&#21327;&#21464;&#37327;Z&#65292;&#27979;&#35797;&#21464;&#37327;&#25110;&#21464;&#37327;&#32452;X&#23545;&#20110;&#39044;&#27979;&#21709;&#24212;Y&#30340;&#37325;&#35201;&#24615;&#26159;&#19968;&#39033;&#26222;&#36941;&#20219;&#21153;&#12290;&#19968;&#31181;&#31616;&#21333;&#20294;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#25351;&#23450;&#19968;&#20010;&#32447;&#24615;&#27169;&#22411;&#65292;&#28982;&#21518;&#27979;&#35797;X&#30340;&#22238;&#24402;&#31995;&#25968;&#26159;&#21542;&#20026;&#38750;&#38646;&#12290;&#28982;&#32780;&#65292;&#24403;&#27169;&#22411;&#38169;&#35823;&#25351;&#23450;&#26102;&#65292;&#27979;&#35797;&#30340;&#21151;&#25928;&#21487;&#33021;&#24456;&#24046;&#65292;&#20363;&#22914;&#24403;X&#21442;&#19982;&#22797;&#26434;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#25110;&#32773;&#23548;&#33268;&#35768;&#22810;&#38169;&#35823;&#25298;&#32477;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27979;&#35797;&#26465;&#20214;&#22343;&#20540;&#29420;&#31435;&#30340;&#26080;&#27169;&#22411;&#20551;&#35774;&#65292;&#21363;&#32473;&#23450;X&#21644;Z&#65292;Y&#30340;&#26465;&#20214;&#22343;&#20540;&#19981;&#20381;&#36182;&#20110;X&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#21033;&#29992;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#21152;&#27861;&#27169;&#22411;&#25110;&#38543;&#26426;&#26862;&#26519;&#65292;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;&#35813;&#36807;&#31243;&#21253;&#25324;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#22238;&#24402;&#65292;&#39318;&#20808;&#20351;&#29992;&#19968;&#21322;&#30340;&#25968;&#25454;&#20272;&#35745;&#20197;X&#21644;Z&#20026;&#22522;&#30784;&#30340;Y&#30340;&#19968;&#31181;&#25237;&#24433;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Testing the significance of a variable or group of variables $X$ for predicting a response $Y$, given additional covariates $Z$, is a ubiquitous task in statistics. A simple but common approach is to specify a linear model, and then test whether the regression coefficient for $X$ is non-zero. However, when the model is misspecified, the test may have poor power, for example when $X$ is involved in complex interactions, or lead to many false rejections. In this work we study the problem of testing the model-free null of conditional mean independence, i.e. that the conditional mean of $Y$ given $X$ and $Z$ does not depend on $X$. We propose a simple and general framework that can leverage flexible nonparametric or machine learning methods, such as additive models or random forests, to yield both robust error control and high power. The procedure involves using these methods to perform regressions, first to estimate a form of projection of $Y$ on $X$ and $Z$ using one half of the data, an
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#28151;&#21512;&#29289;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#30495;&#23454;&#26143;&#31995;&#19978;&#24674;&#22797;&#20986;&#26080;&#20559;&#20272;&#35745;&#30340;&#21098;&#20999;&#65292;&#35299;&#20915;&#20102;&#20313;&#36745;&#21069;&#21521;&#24314;&#27169;&#20013;&#30340;&#27169;&#22411;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2210.16243</link><description>&lt;p&gt;
&#35299;&#20915;&#20313;&#36745;&#21069;&#21521;&#24314;&#27169;&#20013;&#30340;&#27169;&#22411;&#20559;&#24046;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Towards solving model bias in cosmic shear forward modeling. (arXiv:2210.16243v2 [astro-ph.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.16243
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#28151;&#21512;&#29289;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#30495;&#23454;&#26143;&#31995;&#19978;&#24674;&#22797;&#20986;&#26080;&#20559;&#20272;&#35745;&#30340;&#21098;&#20999;&#65292;&#35299;&#20915;&#20102;&#20313;&#36745;&#21069;&#21521;&#24314;&#27169;&#20013;&#30340;&#27169;&#22411;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29616;&#20195;&#26143;&#31995;&#35843;&#26597;&#30340;&#35268;&#27169;&#21644;&#36136;&#37327;&#22686;&#21152;&#65292;&#27979;&#37327;&#23884;&#20837;&#26143;&#31995;&#24418;&#29366;&#20013;&#30340;&#23431;&#23449;&#23398;&#20449;&#21495;&#30340;&#38590;&#24230;&#20063;&#22686;&#21152;&#12290;&#30001;&#23431;&#23449;&#20013;&#26368;&#24222;&#22823;&#32467;&#26500;&#24341;&#21457;&#30340;&#24369;&#24341;&#21147;&#36879;&#38236;&#25928;&#24212;&#20250;&#20135;&#29983;&#24494;&#23567;&#30340;&#26143;&#31995;&#24418;&#24577;&#21098;&#20999;&#65292;&#31216;&#20026;&#20313;&#36745;&#65292;&#26159;&#30740;&#31350;&#23431;&#23449;&#27169;&#22411;&#30340;&#37325;&#35201;&#25506;&#27979;&#25163;&#27573;&#12290;&#22522;&#20110;&#26925;&#22278;&#24230;&#27979;&#37327;&#32479;&#35745;&#30340;&#29616;&#20195;&#21098;&#20999;&#20272;&#35745;&#25216;&#26415;&#23384;&#22312;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;&#26925;&#22278;&#24230;&#23545;&#20110;&#20219;&#24847;&#26143;&#31995;&#20809;&#24230;&#36718;&#24275;&#24182;&#19981;&#26159;&#19968;&#20010;&#26126;&#30830;&#23450;&#20041;&#30340;&#37327;&#65292;&#20174;&#32780;&#20135;&#29983;&#21098;&#20999;&#20272;&#35745;&#20559;&#24046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#28151;&#21512;&#29289;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#22312;&#36825;&#31181;&#27169;&#22411;&#20013;&#65292;&#29983;&#25104;&#27169;&#22411;&#25429;&#25417;&#20102;&#26143;&#31995;&#30340;&#24418;&#24577;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#30495;&#23454;&#26143;&#31995;&#19978;&#24674;&#22797;&#20986;&#26080;&#20559;&#20272;&#35745;&#30340;&#21098;&#20999;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27169;&#22411;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the volume and quality of modern galaxy surveys increase, so does the difficulty of measuring the cosmological signal imprinted in galaxy shapes. Weak gravitational lensing sourced by the most massive structures in the Universe generates a slight shearing of galaxy morphologies called cosmic shear, key probe for cosmological models. Modern techniques of shear estimation based on statistics of ellipticity measurements suffer from the fact that the ellipticity is not a well-defined quantity for arbitrary galaxy light profiles, biasing the shear estimation. We show that a hybrid physical and deep learning Hierarchical Bayesian Model, where a generative model captures the galaxy morphology, enables us to recover an unbiased estimate of the shear on realistic galaxies, thus solving the model bias.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#31163;&#25955;&#38590;&#22788;&#29702;&#20284;&#28982;&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#31163;&#25955;Fisher&#25955;&#24230;&#26356;&#26032;&#21442;&#25968;&#20449;&#24565;&#26469;&#36991;&#20813;&#35745;&#31639;&#22256;&#38590;&#65292;&#24182;&#24471;&#21040;&#19968;&#20010;&#21487;&#20197;&#29992;&#26631;&#20934;&#35745;&#31639;&#24037;&#20855;&#36827;&#34892;&#37319;&#26679;&#30340;&#24191;&#20041;&#21518;&#39564;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2206.08420</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#31163;&#25955;&#38590;&#22788;&#29702;&#20284;&#28982;&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Generalised Bayesian Inference for Discrete Intractable Likelihood. (arXiv:2206.08420v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.08420
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#31163;&#25955;&#38590;&#22788;&#29702;&#20284;&#28982;&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#31163;&#25955;Fisher&#25955;&#24230;&#26356;&#26032;&#21442;&#25968;&#20449;&#24565;&#26469;&#36991;&#20813;&#35745;&#31639;&#22256;&#38590;&#65292;&#24182;&#24471;&#21040;&#19968;&#20010;&#21487;&#20197;&#29992;&#26631;&#20934;&#35745;&#31639;&#24037;&#20855;&#36827;&#34892;&#37319;&#26679;&#30340;&#24191;&#20041;&#21518;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#23545;&#32479;&#35745;&#25512;&#26029;&#26469;&#35828;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#22240;&#20026;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#35745;&#31639;&#38656;&#35201;&#23545;&#22823;&#22411;&#25110;&#21487;&#33021;&#26080;&#38480;&#30340;&#38598;&#21512;&#27714;&#21644;&#65292;&#36825;&#21487;&#33021;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#26412;&#25991;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26032;&#39062;&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#26469;&#24212;&#23545;&#36825;&#19968;&#35745;&#31639;&#25361;&#25112;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#31163;&#25955;&#38590;&#22788;&#29702;&#20284;&#28982;&#12290;&#21463;&#21040;&#36817;&#26399;&#36830;&#32493;&#25968;&#25454;&#26041;&#27861;&#30340;&#26041;&#27861;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#20027;&#35201;&#24605;&#24819;&#26159;&#20351;&#29992;&#31163;&#25955;Fisher&#25955;&#24230;&#26356;&#26032;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#24565;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#26377;&#38382;&#39064;&#30340;&#38590;&#22788;&#29702;&#20284;&#28982;&#12290;&#32467;&#26524;&#26159;&#24471;&#21040;&#19968;&#20010;&#24191;&#20041;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#30340;&#35745;&#31639;&#24037;&#20855;&#65288;&#22914;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65289;&#26469;&#36827;&#34892;&#37319;&#26679;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#38590;&#22788;&#29702;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#12290;&#23545;&#24191;&#20041;&#21518;&#39564;&#30340;&#32479;&#35745;&#24615;&#36136;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#21518;&#39564;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#36890;&#29992;&#30340;&#26657;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrete state spaces represent a major computational challenge to statistical inference, since the computation of normalisation constants requires summation over large or possibly infinite sets, which can be impractical. This paper addresses this computational challenge through the development of a novel generalised Bayesian inference procedure suitable for discrete intractable likelihood. Inspired by recent methodological advances for continuous data, the main idea is to update beliefs about model parameters using a discrete Fisher divergence, in lieu of the problematic intractable likelihood. The result is a generalised posterior that can be sampled from using standard computational tools, such as Markov chain Monte Carlo, circumventing the intractable normalising constant. The statistical properties of the generalised posterior are analysed, with sufficient conditions for posterior consistency and asymptotic normality established. In addition, a novel and general approach to calibr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;&#65292;&#21457;&#29616;&#37027;&#20123;&#22312;&#19981;&#20351;&#29992;SSL&#26102;&#20855;&#26377;&#26356;&#39640;&#22522;&#20934;&#20934;&#30830;&#24615;&#30340;&#23376;&#26063;&#32676;&#26356;&#23481;&#26131;&#20174;SSL&#20013;&#33719;&#30410;&#65292;&#32780;&#37027;&#20123;&#22522;&#20934;&#20934;&#30830;&#24615;&#36739;&#20302;&#30340;&#23376;&#26063;&#32676;&#22312;&#28155;&#21152;SSL&#27169;&#22359;&#21518;&#21487;&#33021;&#20250;&#35266;&#23519;&#21040;&#24615;&#33021;&#19979;&#38477;&#12290;</title><link>http://arxiv.org/abs/2110.06282</link><description>&lt;p&gt;
&#23500;&#32773;&#24840;&#23500;: &#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Rich Get Richer: Disparate Impact of Semi-Supervised Learning. (arXiv:2110.06282v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.06282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;&#65292;&#21457;&#29616;&#37027;&#20123;&#22312;&#19981;&#20351;&#29992;SSL&#26102;&#20855;&#26377;&#26356;&#39640;&#22522;&#20934;&#20934;&#30830;&#24615;&#30340;&#23376;&#26063;&#32676;&#26356;&#23481;&#26131;&#20174;SSL&#20013;&#33719;&#30410;&#65292;&#32780;&#37027;&#20123;&#22522;&#20934;&#20934;&#30830;&#24615;&#36739;&#20302;&#30340;&#23376;&#26063;&#32676;&#22312;&#28155;&#21152;SSL&#27169;&#22359;&#21518;&#21487;&#33021;&#20250;&#35266;&#23519;&#21040;&#24615;&#33021;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#22312;&#39640;&#36136;&#37327;&#30417;&#30563;&#25968;&#25454;&#20005;&#37325;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#24050;&#32463;&#23637;&#31034;&#20102;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#28508;&#21147;&#12290;&#23613;&#31649;&#24448;&#24448;&#21487;&#20197;&#30830;&#31435;&#25972;&#20010;&#25968;&#25454;&#26063;&#32676;&#30340;&#24179;&#22343;&#20934;&#30830;&#24615;&#24471;&#21040;&#25913;&#21892;&#65292;&#20294;SSL&#22312;&#19981;&#21516;&#23376;&#26063;&#32676;&#20013;&#30340;&#34920;&#29616;&#23578;&#19981;&#28165;&#26970;&#12290;&#24403;&#25105;&#20204;&#24076;&#26395;&#20844;&#24179;&#23545;&#24453;&#30340;&#20154;&#21475;&#32676;&#20307;&#30001;&#20154;&#21475;&#32479;&#35745;&#23398;&#20998;&#32452;&#23450;&#20041;&#26102;&#65292;&#29702;&#35299;&#19978;&#36848;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#30340;&#20844;&#24179;&#24615;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#37096;&#32626;SSL&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;&#65306;&#37027;&#20123;&#22312;&#19981;&#20351;&#29992;SSL&#26102;&#20855;&#26377;&#26356;&#39640;&#22522;&#20934;&#20934;&#30830;&#24615;&#30340;&#23376;&#26063;&#32676;&#65288;"&#23500;&#35029;"&#23376;&#26063;&#32676;&#65289;&#24448;&#24448;&#20174;SSL&#20013;&#33719;&#30410;&#26356;&#22810;&#65307;&#32780;&#37027;&#20123;&#22312;&#22522;&#20934;&#20934;&#30830;&#24615;&#36739;&#20302;&#65288;"&#36139;&#31351;"&#65289;&#30340;&#23376;&#26063;&#32676;&#22312;&#28155;&#21152;SSL&#27169;&#22359;&#21518;&#29978;&#33267;&#21487;&#33021;&#35266;&#23519;&#21040;&#24615;&#33021;&#19979;&#38477;&#12290;&#25105;&#20204;&#22312;&#19968;&#31867;&#24191;&#27867;&#30340;SSL&#31639;&#27861;&#19978;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#35777;&#23454;&#20102;&#19978;&#36848;&#35266;&#23519;&#65292;&#36825;&#20123;&#31639;&#27861;&#26126;&#30830;&#25110;&#38544;&#21547;&#22320;&#20351;&#29992;&#20102;&#19968;&#20010;...
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning (SSL) has demonstrated its potential to improve the model accuracy for a variety of learning tasks when the high-quality supervised data is severely limited. Although it is often established that the average accuracy for the entire population of data is improved, it is unclear how SSL fares with different sub-populations. Understanding the above question has substantial fairness implications when different sub-populations are defined by the demographic groups that we aim to treat fairly. In this paper, we reveal the disparate impacts of deploying SSL: the sub-population who has a higher baseline accuracy without using SSL (the "rich" one) tends to benefit more from SSL; while the sub-population who suffers from a low baseline accuracy (the "poor" one) might even observe a performance drop after adding the SSL module. We theoretically and empirically establish the above observation for a broad family of SSL algorithms, which either explicitly or implicitly use a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27169;&#25311;&#27604;&#36739;&#20102;&#36125;&#21494;&#26031;&#26041;&#27861;&#21644;&#21435;&#20559;&#20272;&#35745;&#22120;&#22312;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#34920;&#26126;&#21435;&#20559;&#20272;&#35745;&#22120;&#19982;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#19968;&#26679;&#22909;&#65292;&#22312;&#26679;&#26412;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#36125;&#21494;&#26031;&#26041;&#27861;&#26356;&#31283;&#23450;&#12290;</title><link>http://arxiv.org/abs/2103.11749</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#19982;&#21435;&#20559;&#20272;&#35745;&#22120;&#22312;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#20013;&#30340;&#27169;&#25311;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Simulation comparisons between Bayesian and de-biased estimators in low-rank matrix completion. (arXiv:2103.11749v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.11749
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27169;&#25311;&#27604;&#36739;&#20102;&#36125;&#21494;&#26031;&#26041;&#27861;&#21644;&#21435;&#20559;&#20272;&#35745;&#22120;&#22312;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#34920;&#26126;&#21435;&#20559;&#20272;&#35745;&#22120;&#19982;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#19968;&#26679;&#22909;&#65292;&#22312;&#26679;&#26412;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#36125;&#21494;&#26031;&#26041;&#27861;&#26356;&#31283;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#65292;&#36825;&#26159;&#19968;&#31867;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#65292;&#26088;&#22312;&#39044;&#27979;&#37096;&#20998;&#35266;&#23519;&#30697;&#38453;&#20013;&#30340;&#32570;&#22833;&#26465;&#30446;&#12290;&#36825;&#31867;&#38382;&#39064;&#22312;&#21327;&#21516;&#36807;&#28388;&#12289;&#22270;&#20687;&#22788;&#29702;&#21644;&#22522;&#22240;&#22411;&#25554;&#34917;&#31561;&#22810;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24212;&#29992;&#20013;&#20986;&#29616;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#36125;&#21494;&#26031;&#26041;&#27861;&#21644;&#26368;&#36817;&#24341;&#20837;&#30340;&#21435;&#20559;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#29992;&#30340;&#26041;&#24335;&#26469;&#26500;&#24314;&#24863;&#20852;&#36259;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#20174;&#29702;&#35770;&#35282;&#24230;&#26469;&#30475;&#65292;&#21435;&#20559;&#20272;&#35745;&#22120;&#20855;&#26377;&#23574;&#38160;&#30340;&#26497;&#23567;&#26368;&#20248;&#20272;&#35745;&#35823;&#24046;&#36895;&#29575;&#65292;&#32780;&#36125;&#21494;&#26031;&#26041;&#27861;&#36890;&#36807;&#39069;&#22806;&#30340;&#23545;&#25968;&#22240;&#23376;&#36798;&#21040;&#20102;&#36825;&#19968;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#30740;&#31350;&#26174;&#31034;&#20102;&#26377;&#36259;&#30340;&#32467;&#26524;&#65292;&#21363;&#21435;&#20559;&#20272;&#35745;&#22120;&#19982;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#19968;&#26679;&#22909;&#12290;&#27492;&#22806;&#65292;&#36125;&#21494;&#26031;&#26041;&#27861;&#26356;&#21152;&#31283;&#23450;&#65292;&#22312;&#26679;&#26412;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#20248;&#20110;&#21435;&#20559;&#20272;&#35745;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#32622;&#20449;&#21306;&#38388;&#30340;&#32463;&#39564;&#35206;&#30422;&#29575;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the low-rank matrix completion problem, a class of machine learning problems, that aims at the prediction of missing entries in a partially observed matrix. Such problems appear in several challenging applications such as collaborative filtering, image processing, and genotype imputation. We compare the Bayesian approaches and a recently introduced de-biased estimator which provides a useful way to build confidence intervals of interest. From a theoretical viewpoint, the de-biased estimator comes with a sharp minimax-optimal rate of estimation error whereas the Bayesian approach reaches this rate with an additional logarithmic factor. Our simulation studies show originally interesting results that the de-biased estimator is just as good as the Bayesian estimators. Moreover, Bayesian approaches are much more stable and can outperform the de-biased estimator in the case of small samples. In addition, we also find that the empirical coverage rate of the confidence 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#23545;&#25239;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#22312;&#19968;&#32452;&#19982;&#21487;&#29992;&#30693;&#35782;&#30456;&#23481;&#30340;&#20808;&#39564;&#20998;&#24067;&#20013;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#30340; Bayes &#39118;&#38505;&#30340; Gamma-Minimax &#20272;&#35745;&#22120;&#65292;&#25991;&#20013;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#31867;&#29992;&#20110;&#25552;&#20379;&#20272;&#35745;&#22120;&#31867;&#65292;&#20197;&#21450;&#20004;&#20010;&#23454;&#39564;&#29615;&#33410;&#29992;&#20110;&#35828;&#26126;&#35813;&#26041;&#27861;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2012.05465</link><description>&lt;p&gt;
&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#30340; Gamma-Minimax &#20272;&#35745;&#22120;&#30340;&#23545;&#25239;&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarial Meta-Learning of Gamma-Minimax Estimators That Leverage Prior Knowledge. (arXiv:2012.05465v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.05465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#23545;&#25239;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#22312;&#19968;&#32452;&#19982;&#21487;&#29992;&#30693;&#35782;&#30456;&#23481;&#30340;&#20808;&#39564;&#20998;&#24067;&#20013;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#30340; Bayes &#39118;&#38505;&#30340; Gamma-Minimax &#20272;&#35745;&#22120;&#65292;&#25991;&#20013;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#31867;&#29992;&#20110;&#25552;&#20379;&#20272;&#35745;&#22120;&#31867;&#65292;&#20197;&#21450;&#20004;&#20010;&#23454;&#39564;&#29615;&#33410;&#29992;&#20110;&#35828;&#26126;&#35813;&#26041;&#27861;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20272;&#35745;&#25552;&#20379;&#20102;&#19968;&#31181;&#23558;&#33021;&#22815;&#20197;&#21333;&#20010;&#20808;&#39564;&#20998;&#24067;&#30340;&#24418;&#24335;&#34920;&#36798;&#30340;&#20808;&#39564;&#30693;&#35782;&#32467;&#21512;&#36215;&#26469;&#30340;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#24403;&#36825;&#31181;&#30693;&#35782;&#22826;&#27169;&#31946;&#65292;&#26080;&#27861;&#29992;&#21333;&#20010;&#20808;&#39564;&#34920;&#31034;&#26102;&#65292;&#23601;&#38656;&#35201;&#21478;&#19968;&#31181;&#26041;&#27861;&#12290;Gamma-minimax &#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#36825;&#26679;&#19968;&#31181;&#26041;&#27861;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#23558;&#22312;&#19982;&#21487;&#29992;&#30693;&#35782;&#30456;&#23481;&#30340;&#19968;&#32452;&#20808;&#39564;&#20998;&#24067; $\Gamma$ &#19978;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#30340; Bayes &#39118;&#38505;&#12290;&#20256;&#32479;&#19978;&#65292;Gamma-minimax &#24615;&#36136;&#26159;&#20026;&#21442;&#25968;&#27169;&#22411;&#23450;&#20041;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#19968;&#33324;&#27169;&#22411;&#23450;&#20041; Gamma-minimax &#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20986;&#20102;&#21033;&#29992;&#19968;&#33324;&#21270;&#30697;&#38480;&#21046;&#30340;&#23545;&#25239;&#20803;&#23398;&#20064;&#31639;&#27861;&#26469;&#35745;&#31639;&#23427;&#20204;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#31867;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#20016;&#23500;&#20294;&#26377;&#38480;&#32500;&#24230;&#30340;&#20272;&#35745;&#22120;&#31867;&#65292;&#21487;&#20197;&#20174;&#20013;&#36873;&#25321; Gamma-minimax &#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#29615;&#33410;&#20013;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21363;&#20272;&#35745;&#26410;&#30693;&#25903;&#25345;&#20998;&#24067;&#30340;&#26679;&#26412;&#29109;&#21644;&#21518;&#20998;&#23618;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayes estimators are well known to provide a means to incorporate prior knowledge that can be expressed in terms of a single prior distribution. However, when this knowledge is too vague to express with a single prior, an alternative approach is needed. Gamma-minimax estimators provide such an approach. These estimators minimize the worst-case Bayes risk over a set $\Gamma$ of prior distributions that are compatible with the available knowledge. Traditionally, Gamma-minimaxity is defined for parametric models. In this work, we define Gamma-minimax estimators for general models and propose adversarial meta-learning algorithms to compute them when the set of prior distributions is constrained by generalized moments. Accompanying convergence guarantees are also provided. We also introduce a neural network class that provides a rich, but finite-dimensional, class of estimators from which a Gamma-minimax estimator can be selected. We illustrate our method in two settings, namely entropy est
&lt;/p&gt;</description></item></channel></rss>