<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#35889;&#31639;&#27861;&#26469;&#35299;&#20915;&#21015;&#21487;&#35793;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#24471;&#21040;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#40065;&#26834;&#24615;&#37096;&#20998;&#32858;&#31867;&#30340;&#26377;&#25928;&#35889;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.00966</link><description>&lt;p&gt;
&#21015;&#21487;&#35793;&#21327;&#26041;&#24046;&#20272;&#35745;&#30340;&#35889;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Spectral Algorithm for List-Decodable Covariance Estimation in Relative Frobenius Norm. (arXiv:2305.00966v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#35889;&#31639;&#27861;&#26469;&#35299;&#20915;&#21015;&#21487;&#35793;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#24471;&#21040;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#40065;&#26834;&#24615;&#37096;&#20998;&#32858;&#31867;&#30340;&#26377;&#25928;&#35889;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21015;&#21487;&#35793;&#39640;&#26031;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#12290;&#32473;&#23450;&#19968;&#20010;&#30001;$n$&#20010;&#20301;&#20110;$\mathbb R^d$&#20013;&#30340;&#28857;&#32452;&#25104;&#30340;&#22810;&#37325;&#38598;$T$&#65292;&#20854;&#20013;$\alpha&lt;1/2$&#20010;&#28857;&#26159;&#20174;&#19968;&#20010;&#26410;&#30693;&#30340;&#39640;&#26031;$\mathcal {N}(\mu&#65292;\Sigma)$&#20013;&#29420;&#31435;&#21516;&#20998;&#24067;&#37319;&#26679;&#24471;&#21040;&#30340;&#65292;&#26088;&#22312;&#36755;&#20986;&#19968;&#20010;$O(1/\alpha)$&#30340;&#20551;&#35774;&#21015;&#34920;&#65292;&#20854;&#20013;&#33267;&#23569;&#26377;&#19968;&#20010;&#22312;&#30456;&#23545;Frobenius&#33539;&#25968;&#19979;&#25509;&#36817;$\Sigma$&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#38024;&#23545;&#36825;&#20010;&#20219;&#21153;&#30340;$\mathrm{poly}(d,1/\alpha)$&#26679;&#26412;&#21644;&#26102;&#38388;&#31639;&#27861;&#65292;&#23427;&#20445;&#35777;&#20102;$\mathrm{poly}(1/\alpha)$&#30340;&#30456;&#23545;Frobenius&#33539;&#25968;&#35823;&#24046;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#32431;&#31929;&#20381;&#36182;&#20110;&#35889;&#25216;&#26415;&#12290;&#20316;&#20026;&#19968;&#20010;&#25512;&#35770;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;(GMMs)&#40065;&#26834;&#24615;&#37096;&#20998;&#32858;&#31867;&#30340;&#26377;&#25928;&#35889;&#31639;&#27861;&#8212;&#8212;&#36825;&#26159;[BMD+22]&#26368;&#26032;&#24037;&#20316;&#20013;&#40065;&#26834;&#24615;&#23398;&#20064;&#20219;&#24847;GMMs&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#32467;&#21512;[BMD+22]&#20013;&#30340;&#20854;&#20182;&#32452;&#25104;&#37096;&#20998;&#65292;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#26080;&#21644;&#24179;&#26041;&#39033;&#31639;&#27861;&#26469;&#40065;&#26834;&#22320;&#23398;&#20064;GMMs&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of list-decodable Gaussian covariance estimation. Given a multiset $T$ of $n$ points in $\mathbb R^d$ such that an unknown $\alpha&lt;1/2$ fraction of points in $T$ are i.i.d. samples from an unknown Gaussian $\mathcal{N}(\mu, \Sigma)$, the goal is to output a list of $O(1/\alpha)$ hypotheses at least one of which is close to $\Sigma$ in relative Frobenius norm. Our main result is a $\mathrm{poly}(d,1/\alpha)$ sample and time algorithm for this task that guarantees relative Frobenius norm error of $\mathrm{poly}(1/\alpha)$. Importantly, our algorithm relies purely on spectral techniques. As a corollary, we obtain an efficient spectral algorithm for robust partial clustering of Gaussian mixture models (GMMs) -- a key ingredient in the recent work of [BDJ+22] on robustly learning arbitrary GMMs. Combined with the other components of [BDJ+22], our new method yields the first Sum-of-Squares-free algorithm for robustly learning GMMs. At the technical level, we develop a no
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#23558;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#24212;&#29992;&#20110;BNNs&#20013;&#30340;&#32467;&#26500;&#23398;&#20064;&#20013;&#24182;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#32435;&#20837;&#20102;&#27169;&#22411;&#31354;&#38388;&#32422;&#26463;&#65292;&#20197;&#22312;&#27169;&#22411;&#21644;&#21442;&#25968;&#30340;&#32852;&#21512;&#31354;&#38388;&#20013;&#36827;&#34892;&#25512;&#26029;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2305.00934</link><description>&lt;p&gt;
&#27169;&#22411;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21464;&#20998;&#25512;&#26029;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Variational Inference for Bayesian Neural Networks under Model and Parameter Uncertainty. (arXiv:2305.00934v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#23558;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#24212;&#29992;&#20110;BNNs&#20013;&#30340;&#32467;&#26500;&#23398;&#20064;&#20013;&#24182;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#32435;&#20837;&#20102;&#27169;&#22411;&#31354;&#38388;&#32422;&#26463;&#65292;&#20197;&#22312;&#27169;&#22411;&#21644;&#21442;&#25968;&#30340;&#32852;&#21512;&#31354;&#38388;&#20013;&#36827;&#34892;&#25512;&#26029;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#21487;&#25193;&#23637;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#25216;&#26415;&#30340;&#21457;&#23637;&#65292;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#26368;&#36817;&#37325;&#26032;&#24341;&#36215;&#28145;&#24230;&#23398;&#20064;&#31038;&#21306;&#30340;&#22823;&#37327;&#20851;&#27880;&#12290;&#20351;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#26377;&#20960;&#20010;&#20248;&#28857;&#65306;&#21442;&#25968;&#21644;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#21464;&#24471;&#23481;&#26131;&#33719;&#24471;&#65292;&#20174;&#32780;&#20415;&#20110;&#36827;&#34892;&#20005;&#26684;&#30340;&#32479;&#35745;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#21487;&#20197;&#21152;&#20837;&#20808;&#39564;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#36824;&#27809;&#26377;&#21487;&#25193;&#23637;&#30340;&#25216;&#26415;&#33021;&#22815;&#32452;&#21512;&#32467;&#26500;&#21644;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#23558;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#27010;&#24565;&#24212;&#29992;&#20110;BNNs&#20013;&#30340;&#32467;&#26500;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#22240;&#27492;&#22312;&#32467;&#26500;/&#27169;&#22411;&#21644;&#21442;&#25968;&#30340;&#32852;&#21512;&#31354;&#38388;&#20013;&#36827;&#34892;&#25512;&#26029;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#35758;&#37319;&#29992;&#20855;&#26377;&#36793;&#38469;&#21253;&#21547;&#27010;&#29575;&#37325;&#21442;&#25968;&#21270;&#30340;&#21487;&#25193;&#23637;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#26469;&#32435;&#20837;&#27169;&#22411;&#31354;&#38388;&#32422;&#26463;&#12290;&#22312;&#19968;&#31995;&#21015;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian neural networks (BNNs) have recently regained a significant amount of attention in the deep learning community due to the development of scalable approximate Bayesian inference techniques. There are several advantages of using a Bayesian approach: Parameter and prediction uncertainties become easily available, facilitating rigorous statistical analysis. Furthermore, prior knowledge can be incorporated. However, so far, there have been no scalable techniques capable of combining both structural and parameter uncertainty. In this paper, we apply the concept of model uncertainty as a framework for structural learning in BNNs and hence make inference in the joint space of structures/models and parameters. Moreover, we suggest an adaptation of a scalable variational inference approach with reparametrization of marginal inclusion probabilities to incorporate the model space constraints. Experimental results on a range of benchmark datasets show that we obtain comparable accuracy res
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#26426;&#26800;&#27169;&#22411;&#21644;&#32479;&#35745;&#27169;&#22411;&#30340;&#30701;&#26399;COVID-19&#39044;&#27979;&#65292;&#21457;&#29616;&#24179;&#22343;&#32780;&#35328;&#65292;&#22522;&#20110;&#32479;&#35745;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#27010;&#29575;&#39044;&#27979;&#33267;&#23569;&#19982;&#26426;&#26800;&#27169;&#22411;&#30340;&#39044;&#27979;&#19968;&#26679;&#20934;&#30830;&#65292;&#21516;&#26102;&#26356;&#22909;&#22320;&#25429;&#25417;&#27874;&#21160;&#24615;&#12290;&#36825;&#34920;&#26126;&#23558;&#39046;&#22495;&#30693;&#35782;&#25972;&#21512;&#21040;&#26426;&#26800;&#27169;&#22411;&#20013;&#19981;&#33021;&#25913;&#21892;&#30142;&#30149;&#21457;&#29983;&#29575;&#30340;&#30701;&#26399;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2305.00933</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#26426;&#26800;&#21644;&#32479;&#35745;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;COVID-19&#30701;&#26399;&#27010;&#29575;&#39044;&#27979;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
A comparison of short-term probabilistic forecasts for the incidence of COVID-19 using mechanistic and statistical time series models. (arXiv:2305.00933v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#26426;&#26800;&#27169;&#22411;&#21644;&#32479;&#35745;&#27169;&#22411;&#30340;&#30701;&#26399;COVID-19&#39044;&#27979;&#65292;&#21457;&#29616;&#24179;&#22343;&#32780;&#35328;&#65292;&#22522;&#20110;&#32479;&#35745;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#27010;&#29575;&#39044;&#27979;&#33267;&#23569;&#19982;&#26426;&#26800;&#27169;&#22411;&#30340;&#39044;&#27979;&#19968;&#26679;&#20934;&#30830;&#65292;&#21516;&#26102;&#26356;&#22909;&#22320;&#25429;&#25417;&#27874;&#21160;&#24615;&#12290;&#36825;&#34920;&#26126;&#23558;&#39046;&#22495;&#30693;&#35782;&#25972;&#21512;&#21040;&#26426;&#26800;&#27169;&#22411;&#20013;&#19981;&#33021;&#25913;&#21892;&#30142;&#30149;&#21457;&#29983;&#29575;&#30340;&#30701;&#26399;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30142;&#30149;&#20256;&#25773;&#30340;&#30701;&#26399;&#39044;&#27979;&#26159;&#39118;&#38505;&#35780;&#20272;&#21644;&#20844;&#20849;&#21355;&#29983;&#20915;&#31574;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;&#34429;&#28982;&#24050;&#32463;&#24320;&#21457;&#20102;&#19981;&#21516;&#30340;&#30701;&#26399;&#39044;&#27979;&#27169;&#22411;&#65292;&#20294;&#20854;&#30456;&#23545;&#24615;&#33021;&#20173;&#26377;&#30097;&#38382;&#12290;&#26412;&#25991;&#27604;&#36739;&#22522;&#20110;&#26356;&#26032;&#26041;&#31243;&#30340;&#27969;&#34892;&#30149;&#23398;&#26426;&#26800;&#27169;&#22411;&#21644;&#26102;&#38388;&#24207;&#21015;&#32479;&#35745;&#27169;&#22411;&#30340;&#30701;&#26399;&#27010;&#29575;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#32463;&#39564;&#27604;&#36739;&#22522;&#20110;&#32654;&#22269;&#20845;&#20010;&#22823;&#24030;&#22312;&#31532;&#19968;&#24180;&#30340;COVID-19&#27599;&#26085;&#21457;&#30149;&#29575;&#25968;&#25454;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24179;&#22343;&#32780;&#35328;&#65292;&#26469;&#33258;&#32479;&#35745;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#27010;&#29575;&#39044;&#27979;&#24635;&#20307;&#19978;&#33267;&#23569;&#19982;&#26426;&#26800;&#27169;&#22411;&#30340;&#39044;&#27979;&#19968;&#26679;&#20934;&#30830;&#12290;&#27492;&#22806;&#65292;&#32479;&#35745;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#26356;&#22909;&#22320;&#25429;&#25417;&#27874;&#21160;&#24615;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#36890;&#36807;&#23545;&#30142;&#30149;&#21160;&#24577;&#20570;&#20986;&#20551;&#35774;&#23558;&#39046;&#22495;&#30693;&#35782;&#25972;&#21512;&#21040;&#26426;&#26800;&#27169;&#22411;&#20013;&#24182;&#19981;&#33021;&#25913;&#21892;&#30142;&#30149;&#21457;&#29983;&#29575;&#30340;&#30701;&#26399;&#39044;&#27979;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#25351;&#20986;&#65292;&#39044;&#27979;&#31934;&#24230;&#22312;&#19981;&#21516;&#24030;&#21644;&#26102;&#38388;&#27573;&#20013;&#26377;&#25152;&#21464;&#21270;&#65292;&#34920;&#26126;&#21487;&#33021;&#23384;&#22312;&#26426;&#26800;&#27169;&#22411;&#30340;&#34920;&#29616;&#20248;&#20110;&#32479;&#35745;&#27169;&#22411;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Short-term forecasts of infectious disease spread are a critical component in risk evaluation and public health decision making. While different models for short-term forecasting have been developed, open questions about their relative performance remain. Here, we compare short-term probabilistic forecasts of popular mechanistic models based on the renewal equation with forecasts of statistical time series models. Our empirical comparison is based on data of the daily incidence of COVID-19 across six large US states over the first pandemic year. We find that, on average, probabilistic forecasts from statistical time series models are overall at least as accurate as forecasts from mechanistic models. Moreover, statistical time series models better capture volatility. Our findings suggest that domain knowledge, which is integrated into mechanistic models by making assumptions about disease dynamics, does not improve short-term forecasts of disease incidence. We note, however, that foreca
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#35823;&#24046;&#32039;&#30830;&#30028;&#65292;&#23545;&#20110;&#20856;&#22411;&#30340;&#20108;&#27425;&#39640;&#26031;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#23427;&#26159;&#23436;&#20840;&#32039;&#30830;&#30340;&#12290;&#19982;&#29616;&#26377;&#30340;&#30028;&#19981;&#21516;&#65292;&#36825;&#20010;&#26032;&#30028;&#21033;&#29992;&#20102;&#20010;&#20307;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#24182;&#23545;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#36827;&#34892;&#20102;&#27979;&#37327;&#21464;&#25442;&#19981;&#31561;&#24335;&#21644;&#26465;&#20214;&#23548;&#20986;&#12290;</title><link>http://arxiv.org/abs/2305.00876</link><description>&lt;p&gt;
&#20108;&#27425;&#39640;&#26031;&#38382;&#39064;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#35823;&#24046;&#30340;&#23436;&#20840;&#32039;&#30830;&#30028;
&lt;/p&gt;
&lt;p&gt;
Exactly Tight Information-Theoretic Generalization Error Bound for the Quadratic Gaussian Problem. (arXiv:2305.00876v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00876
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#35823;&#24046;&#32039;&#30830;&#30028;&#65292;&#23545;&#20110;&#20856;&#22411;&#30340;&#20108;&#27425;&#39640;&#26031;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#23427;&#26159;&#23436;&#20840;&#32039;&#30830;&#30340;&#12290;&#19982;&#29616;&#26377;&#30340;&#30028;&#19981;&#21516;&#65292;&#36825;&#20010;&#26032;&#30028;&#21033;&#29992;&#20102;&#20010;&#20307;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#24182;&#23545;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#36827;&#34892;&#20102;&#27979;&#37327;&#21464;&#25442;&#19981;&#31561;&#24335;&#21644;&#26465;&#20214;&#23548;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#35823;&#24046;&#32039;&#30830;&#30028;&#65292;&#23545;&#20110;&#20856;&#22411;&#30340;&#20108;&#27425;&#39640;&#26031;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#23427;&#26159;&#23436;&#20840;&#32039;&#30830;&#30340;&#65288;&#21363;&#21305;&#37197;&#24120;&#25968;&#65289;&#12290;&#23613;&#31649;&#22312;&#25512;&#23548;&#20449;&#24687;&#35770;&#27867;&#21270;&#35823;&#24046;&#30028;&#26041;&#38754;&#36827;&#34892;&#20102;&#30456;&#24403;&#22810;&#30340;&#21162;&#21147;&#65292;&#20294;&#23558;&#20854;&#24212;&#29992;&#20110;&#20351;&#29992;&#26679;&#26412;&#24179;&#22343;&#20316;&#20026;&#39640;&#26031;&#25968;&#25454;&#22343;&#20540;&#20272;&#35745;&#30340;&#31616;&#21333;&#35774;&#32622;&#24182;&#27809;&#26377;&#20135;&#29983;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#20107;&#23454;&#19978;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#30028;&#37117;&#26159;&#26494;&#25955;&#30340;&#65292;&#36825;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#20110;&#20449;&#24687;&#29702;&#35770;&#30028;&#22312;&#25512;&#29702;&#26426;&#22120;&#23398;&#20064;&#30340;&#27867;&#21270;&#34892;&#20026;&#26041;&#38754;&#30340;&#22522;&#26412;&#33021;&#21147;&#30340;&#20851;&#27880;&#12290;&#25552;&#20986;&#30340;&#26032;&#30340;&#30028;&#37319;&#29992;&#20102;Bu&#31561;&#20154;&#25552;&#20986;&#30340;&#22522;&#20110;&#21333;&#20010;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#20294;&#20063;&#26377;&#20960;&#20010;&#20851;&#38190;&#30340;&#26032;&#32452;&#25104;&#37096;&#20998;&#12290; &#39318;&#20808;&#65292;&#25105;&#20204;&#19981;&#26159;&#23558;&#27979;&#37327;&#21464;&#25442;&#19981;&#31561;&#24335;&#24212;&#29992;&#20110;&#25439;&#22833;&#20989;&#25968;&#65292;&#32780;&#26159;&#24212;&#29992;&#20110;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#26412;&#36523;&#65307;&#20854;&#27425;&#65292;&#30028;&#26159;&#26377;&#26465;&#20214;&#22320;&#23548;&#20986;&#30340;&#65307; &#26368;&#21518;&#65292;
&lt;/p&gt;
&lt;p&gt;
We provide a new information-theoretic generalization error bound that is exactly tight (i.e., matching even the constant) for the canonical quadratic Gaussian mean estimation problem. Despite considerable existing efforts in deriving information-theoretic generalization error bounds, applying them to this simple setting where sample average is used as the estimate of the mean value of Gaussian data has not yielded satisfying results. In fact, most existing bounds are order-wise loose in this setting, which has raised concerns about the fundamental capability of information-theoretic bounds in reasoning the generalization behavior for machine learning. The proposed new bound adopts the individual-sample-based approach proposed by Bu et al., but also has several key new ingredients. Firstly, instead of applying the change of measure inequality on the loss function, we apply it to the generalization error function itself; secondly, the bound is derived in a conditional manner; lastly, a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#36827;&#34892;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#19981;&#21463;&#20998;&#24067;&#20559;&#31227;&#24433;&#21709;&#65292;&#23545;&#20110;&#23494;&#24230;&#20998;&#31163;&#33391;&#22909;&#30340;&#24773;&#20917;&#34920;&#29616;&#26356;&#22909;&#65292;&#36890;&#36807;&#24341;&#20837;&#36741;&#21161;&#23494;&#24230;&#26500;&#36896;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#20934;&#30830;&#30340;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2305.00869</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#39033;&#36923;&#36753;&#22238;&#24402;&#20272;&#31639;&#39640;&#31163;&#24046;&#20998;&#24067;&#30340;&#23494;&#24230;&#27604;
&lt;/p&gt;
&lt;p&gt;
Estimating the Density Ratio between Distributions with High Discrepancy using Multinomial Logistic Regression. (arXiv:2305.00869v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00869
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#36827;&#34892;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#19981;&#21463;&#20998;&#24067;&#20559;&#31227;&#24433;&#21709;&#65292;&#23545;&#20110;&#23494;&#24230;&#20998;&#31163;&#33391;&#22909;&#30340;&#24773;&#20917;&#34920;&#29616;&#26356;&#22909;&#65292;&#36890;&#36807;&#24341;&#20837;&#36741;&#21161;&#23494;&#24230;&#26500;&#36896;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#20934;&#30830;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23494;&#24230;&#27604;$p/q$&#30340;&#20989;&#25968;&#34987;&#24191;&#27867;&#29992;&#20110;&#37327;&#21270;&#20004;&#20010;&#20998;&#24067;$p$&#21644;$q$&#20043;&#38388;&#30340;&#31163;&#24046;&#12290;&#23545;&#20110;&#39640;&#32500;&#20998;&#24067;&#65292;&#22522;&#20110;&#20108;&#20803;&#20998;&#31867;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#22120;&#34920;&#29616;&#20986;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#23494;&#24230;&#20998;&#31163;&#33391;&#22909;&#26102;&#65292;&#20351;&#29992;&#20108;&#20803;&#20998;&#31867;&#22120;&#20272;&#31639;&#23494;&#24230;&#27604;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#26368;&#26032;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#22120;&#22312;&#23494;&#24230;&#20998;&#31163;&#33391;&#22909;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#24046;&#65292;&#24182;&#35777;&#26126;&#36825;&#26159;&#30001;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#26102;&#21457;&#29983;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21478;&#31867;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#31867;&#20998;&#31867;&#36827;&#34892;&#23494;&#24230;&#27604;&#20272;&#35745;&#65292;&#24182;&#19988;&#19981;&#21463;&#21040;&#20998;&#24067;&#20559;&#31227;&#30340;&#24433;&#21709;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#19968;&#32452;&#36741;&#21161;&#23494;&#24230;$\{m_k\}_{k=1}^K$&#65292;&#24182;&#35757;&#32451;&#19968;&#20010;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#23545;&#26679;&#26412;&#20174;$p&#65292;q$&#21644;$\{m_k\}_{k=1}^K$&#20998;&#31867;&#25104;$K+2$&#31867;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#36825;&#20123;&#36741;&#21161;&#23494;&#24230;&#34987;&#26500;&#36896;&#20026;&#28385;&#36275;&#26368;&#22823;&#23494;&#24230;&#27604;&#20540;&#26465;&#20214;&#65292;&#21017;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#23494;&#24230;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Functions of the ratio of the densities $p/q$ are widely used in machine learning to quantify the discrepancy between the two distributions $p$ and $q$. For high-dimensional distributions, binary classification-based density ratio estimators have shown great promise. However, when densities are well separated, estimating the density ratio with a binary classifier is challenging. In this work, we show that the state-of-the-art density ratio estimators perform poorly on well-separated cases and demonstrate that this is due to distribution shifts between training and evaluation time. We present an alternative method that leverages multi-class classification for density ratio estimation and does not suffer from distribution shift issues. The method uses a set of auxiliary densities $\{m_k\}_{k=1}^K$ and trains a multi-class logistic regression to classify the samples from $p, q$, and $\{m_k\}_{k=1}^K$ into $K+2$ classes. We show that if these auxiliary densities are constructed such that t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20801;&#35768;$k$&#20010;&#33218;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#30340;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#24773;&#22659;&#12290;&#22312;&#20551;&#35774;&#29615;&#22659;&#36739;&#20026;&#28201;&#21644;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20851;&#20110;Learner's Losses $V_T$&#30340;&#20108;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#21644;&#20851;&#20110;&#26368;&#20339;&#31574;&#30053;$L_T^*$&#30340;&#19968;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#30340;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.00832</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
First- and Second-Order Bounds for Adversarial Linear Contextual Bandits. (arXiv:2305.00832v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00832
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20801;&#35768;$k$&#20010;&#33218;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#30340;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#24773;&#22659;&#12290;&#22312;&#20551;&#35774;&#29615;&#22659;&#36739;&#20026;&#28201;&#21644;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20851;&#20110;Learner's Losses $V_T$&#30340;&#20108;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#21644;&#20851;&#20110;&#26368;&#20339;&#31574;&#30053;$L_T^*$&#30340;&#19968;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#30340;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#30340;&#24773;&#22659;&#65292;&#35813;&#24773;&#22659;&#20801;&#35768;&#19982;K&#20010;&#33218;&#30456;&#20851;&#32852;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#12290; &#20551;&#35774;d&#32500;&#19978;&#19979;&#25991;&#20174;&#24050;&#30693;&#20998;&#24067;&#20013;&#32472;&#21046;&#65292;&#37027;&#20040;&#22312;T&#36718;&#28216;&#25103;&#26399;&#38388;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#39044;&#26399;&#36951;&#25022;&#23558;&#20197;$\tilde O(\sqrt{Kd T})$&#30340;&#36895;&#24230;&#22686;&#38271;&#12290;&#22312;&#20551;&#35774;&#19978;&#19979;&#25991;&#30340;&#23494;&#24230;&#26159;&#23545;&#25968;&#20985;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20108;&#38454;&#30028;&#65292;&#20854;&#22312;&#32047;&#31215;&#25439;&#22833;&#30340;&#20108;&#27425;&#30697;$V_T$&#26041;&#38754;&#30340;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#65292;&#20197;&#21450;&#19968;&#20010;&#19982;&#20043;&#23494;&#20999;&#30456;&#20851;&#30340;&#19968;&#38454;&#30028;&#65292;&#20854;&#22312;&#26368;&#20339;&#31574;&#30053;&#30340;&#32047;&#31215;&#25439;&#22833;$L_T^*$&#26041;&#38754;&#30340;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#12290;&#30001;&#20110;$V_T$&#25110;$L_T^*$&#21487;&#33021;&#26126;&#26174;&#23567;&#20110;$T$&#65292;&#22240;&#27492;&#27599;&#24403;&#29615;&#22659;&#30456;&#23545;&#28201;&#21644;&#26102;&#65292;&#20415;&#20250;&#25913;&#21892;&#26368;&#22351;&#24773;&#20917;&#30340;&#36951;&#25022;&#12290;&#26412;&#25991;&#20351;&#29992;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#36830;&#32493;&#25351;&#25968;&#26435;&#37325;&#31639;&#27861;&#30340;&#25130;&#26029;&#29256;&#26412;&#26469;&#33719;&#24471;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
We consider the adversarial linear contextual bandit setting, which allows for the loss functions associated with each of $K$ arms to change over time without restriction. Assuming the $d$-dimensional contexts are drawn from a fixed known distribution, the worst-case expected regret over the course of $T$ rounds is known to scale as $\tilde O(\sqrt{Kd T})$. Under the additional assumption that the density of the contexts is log-concave, we obtain a second-order bound of order $\tilde O(K\sqrt{d V_T})$ in terms of the cumulative second moment of the learner's losses $V_T$, and a closely related first-order bound of order $\tilde O(K\sqrt{d L_T^*})$ in terms of the cumulative loss of the best policy $L_T^*$. Since $V_T$ or $L_T^*$ may be significantly smaller than $T$, these improve over the worst-case regret whenever the environment is relatively benign. Our results are obtained using a truncated version of the continuous exponential weights algorithm over the probability simplex, which
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#24207;&#21015;&#31038;&#20132;&#22256;&#22659;&#20013;&#65292;&#24322;&#36136;&#24615;SVO&#23548;&#33268;&#22810;&#26679;&#21270;&#30340;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#26368;&#20339;&#24212;&#31572;&#31574;&#30053;&#23454;&#29616;&#26356;&#22909;&#30340;&#38646;&#26679;&#26412;&#25512;&#24191;&#12290;</title><link>http://arxiv.org/abs/2305.00768</link><description>&lt;p&gt;
&#24322;&#36136;&#24615;&#31038;&#20132;&#20215;&#20540;&#21462;&#21521;&#22312;&#24207;&#21015;&#31038;&#20132;&#22256;&#22659;&#20013;&#23548;&#33268;&#26377;&#24847;&#20041;&#30340;&#22810;&#26679;&#24615;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous Social Value Orientation Leads to Meaningful Diversity in Sequential Social Dilemmas. (arXiv:2305.00768v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00768
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#24207;&#21015;&#31038;&#20132;&#22256;&#22659;&#20013;&#65292;&#24322;&#36136;&#24615;SVO&#23548;&#33268;&#22810;&#26679;&#21270;&#30340;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#26368;&#20339;&#24212;&#31572;&#31574;&#30053;&#23454;&#29616;&#26356;&#22909;&#30340;&#38646;&#26679;&#26412;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20250;&#24515;&#29702;&#23398;&#20013;&#65292;&#31038;&#20132;&#20215;&#20540;&#21462;&#21521;&#65288;SVO&#65289;&#25551;&#36848;&#20102;&#20010;&#20154;&#22312;&#33258;&#25105;&#21644;&#20182;&#20154;&#20043;&#38388;&#20998;&#37197;&#36164;&#28304;&#30340;&#20542;&#21521;&#24615;&#12290;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;SVO&#34987;&#23454;&#20363;&#21270;&#20026;&#19968;&#31181;&#20869;&#22312;&#21160;&#26426;&#65292;&#26681;&#25454;&#29305;&#23450;&#30340;&#30446;&#26631;&#20998;&#37197;&#32452;&#22870;&#21169;&#65292;&#37325;&#26032;&#26144;&#23556;&#20195;&#29702;&#30340;&#22870;&#21169;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20855;&#26377;&#24322;&#36136;&#24615;SVO&#30340;&#20195;&#29702;&#32452;&#22312;&#31867;&#20284;&#22234;&#24466;&#22256;&#22659;&#30340;&#28608;&#21169;&#32467;&#26500;&#19979;&#23398;&#20064;&#20102;&#22810;&#26679;&#21270;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25193;&#23637;&#20102;&#36825;&#19968;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;(1)&#24322;&#36136;&#24615;SVO&#22312;&#24207;&#21015;&#31038;&#20132;&#22256;&#22659;&#20013;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#22870;&#21169;&#32467;&#26500;&#23548;&#33268;&#31574;&#30053;&#30340;&#22810;&#26679;&#24615;&#65292;&#22914;&#20219;&#21153;&#29305;&#23450;&#30340;&#22810;&#26679;&#24615;&#25351;&#26631;&#25152;&#27979;&#37327;&#30340;&#37027;&#26679;&#65307;(2)&#38024;&#23545;&#36825;&#31181;&#31574;&#30053;&#22810;&#26679;&#24615;&#23398;&#20064;&#26368;&#20339;&#24212;&#31572;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#26356;&#22909;&#22320;&#36827;&#34892;&#38646;&#26679;&#26412;&#25512;&#24191;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#26368;&#20339;&#24212;&#31572;&#20195;&#29702;&#23398;&#20064;&#30340;&#31574;&#30053;&#26159;&#20197;&#20182;&#20204;&#30340;&#32852;&#21512;&#29609;&#23478;&#20026;&#26465;&#20214;&#30340;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#26159;&#25913;&#36827;&#38646;&#26679;&#26412;&#25512;&#24191;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
In social psychology, Social Value Orientation (SVO) describes an individual's propensity to allocate resources between themself and others. In reinforcement learning, SVO has been instantiated as an intrinsic motivation that remaps an agent's rewards based on particular target distributions of group reward. Prior studies show that groups of agents endowed with heterogeneous SVO learn diverse policies in settings that resemble the incentive structure of Prisoner's dilemma. Our work extends this body of results and demonstrates that (1) heterogeneous SVO leads to meaningfully diverse policies across a range of incentive structures in sequential social dilemmas, as measured by task-specific diversity metrics; and (2) learning a best response to such policy diversity leads to better zero-shot generalization in some situations. We show that these best-response agents learn policies that are conditioned on their co-players, which we posit is the reason for improved zero-shot generalization 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.00700</link><description>&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#21452;&#37325;&#21644;&#21333;&#19968;&#19979;&#38477;&#29616;&#35937;&#65292;&#21450;&#20854;&#22312;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control. (arXiv:2305.00700v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00700
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21452;&#37325;&#19979;&#38477;&#29616;&#35937;&#65292;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#21253;&#25324;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#21512;&#25104;&#25511;&#21046;&#12290;&#22312;&#36825;&#31181;&#27169;&#22411;&#20013;&#65292;&#21487;&#33021;&#23384;&#22312;&#22826;&#22810;&#30340;&#33258;&#30001;&#21442;&#25968;&#65292;&#20197;&#33267;&#20110;&#27169;&#22411;&#21487;&#20197;&#23436;&#32654;&#22320;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#12290;&#26412;&#25991;&#39318;&#20808;&#20197;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20026;&#20363;&#65292;&#30740;&#31350;&#34218;&#36164;&#25968;&#25454;&#30340;&#22635;&#20805;&#65292;&#21457;&#29616;&#27604;&#31616;&#21333;&#27169;&#22411;&#26356;&#22810;&#30340;&#21327;&#21464;&#37327;&#23545;&#20110;&#27169;&#22411;&#24615;&#33021;&#30340;&#25552;&#21319;&#24456;&#26377;&#25928;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#29702;&#35770;&#35270;&#35282;&#26469;&#35299;&#37322;&#36825;&#20123;&#39640;&#32500;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21363;&#23558;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#35270;&#20026;&#23545;&#31616;&#21333;&#27169;&#22411;&#30340;&#27169;&#22411;&#24179;&#22343;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider highly over-parametrized models in causal inference, including synthetic control with many control units. In such models, there may be so many free parameters that the model fits the training data perfectly. As a motivating example, we first investigate high-dimensional linear regression for imputing wage data, where we find that models with many more covariates than sample size can outperform simple ones. As our main contribution, we document the performance of high-dimensional synthetic control estimators with many control units. We find that adding control units can help improve imputation performance even beyond the point where the pre-treatment fit is perfect. We then provide a unified theoretical perspective on the performance of these high-dimensional models. Specifically, we show that more complex models can be interpreted as model-averaging estimators over simpler ones, which we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#20915;&#31574;&#21046;&#23450;&#30340;&#26679;&#26412;&#26377;&#25928;&#12289;&#22343;&#34913;&#35745;&#31639;&#21644;&#23616;&#37096;&#30417;&#25511;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22797;&#26434;&#24230;&#19978;&#19979;&#30028;&#21644;&#31639;&#27861;&#65292;&#24182;&#21457;&#29616;&#22810;&#26234;&#33021;&#20307;&#24773;&#20917;&#19979;&#21487;&#33021;&#21576;&#25351;&#25968;&#32423;&#38590;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.00684</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#26234;&#33021;&#20307;&#20915;&#31574;&#21046;&#23450;&#30340;&#22797;&#26434;&#24615;&#65306;&#20174;&#28216;&#25103;&#23398;&#20064;&#21040;&#23616;&#37096;&#30417;&#25511;&#12290;
&lt;/p&gt;
&lt;p&gt;
On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring. (arXiv:2305.00684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00684
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#20915;&#31574;&#21046;&#23450;&#30340;&#26679;&#26412;&#26377;&#25928;&#12289;&#22343;&#34913;&#35745;&#31639;&#21644;&#23616;&#37096;&#30417;&#25511;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22797;&#26434;&#24230;&#19978;&#19979;&#30028;&#21644;&#31639;&#27861;&#65292;&#24182;&#21457;&#29616;&#22810;&#26234;&#33021;&#20307;&#24773;&#20917;&#19979;&#21487;&#33021;&#21576;&#25351;&#25968;&#32423;&#38590;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#29702;&#35299;&#32467;&#26500;&#26465;&#20214;&#21644;&#31639;&#27861;&#21407;&#21017;&#20250;&#23548;&#33268;&#21738;&#20123;&#26679;&#26412;&#26377;&#25928;&#30340;&#23398;&#20064;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#25105;&#20204;&#20174;&#23569;&#25968;&#26234;&#33021;&#20307;&#36716;&#31227;&#21040;&#22810;&#25968;&#26234;&#33021;&#20307;&#26102;&#65292;&#36825;&#20123;&#32771;&#34385;&#22914;&#20309;&#21457;&#29983;&#21464;&#21270;&#12290;&#26412;&#25991;&#22312;&#22810;&#26234;&#33021;&#20307;&#20114;&#21160;&#20915;&#31574;&#30340;&#19968;&#33324;&#26694;&#26550;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#21253;&#25324;&#20855;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#21644;&#24102;&#26377;&#36172;&#24466;&#21453;&#39304;&#30340;&#27491;&#21017;&#24335;&#21338;&#24328;&#12290;&#25105;&#20204;&#20851;&#27880;&#22343;&#34913;&#35745;&#31639;&#65292;&#20854;&#20013;&#38598;&#20013;&#24335;&#23398;&#20064;&#31639;&#27861;&#26088;&#22312;&#36890;&#36807;&#25511;&#21046;&#19982;&#26410;&#30693;&#29615;&#22659;&#20132;&#20114;&#30340;&#22810;&#20010;&#26234;&#33021;&#20307;&#26469;&#35745;&#31639;&#22343;&#34913;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#65306;1. &#25105;&#20204;&#22522;&#20110;&#30001;Foster&#31561;&#20154;&#65288;2021&#65289;&#22312;&#21333;&#26234;&#33021;&#20307;&#24773;&#20917;&#19979;&#24341;&#20837;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#27861;&#8212;&#20915;&#31574;-&#20272;&#35745;&#31995;&#25968;&#65292;&#20026;&#22810;&#26234;&#33021;&#20307;&#20915;&#31574;&#21046;&#23450;&#20102;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#12290;&#19982;&#21333;&#26234;&#33021;&#20307;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#32467;&#26524;&#30456;&#27604;&#65292;&#25105;&#20204;&#34920;&#26126;&#22810;&#26234;&#33021;&#20307;&#24773;&#20917;&#19979;&#30340;&#38382;&#39064;&#22312;&#26234;&#33021;&#20307;&#25968;&#37327;&#26041;&#38754;&#21487;&#33021;&#21576;&#25351;&#25968;&#32423;&#38590;&#24230;&#12290;2. &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#20855;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#22823;&#22411;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#36827;&#34892;&#39640;&#25928;&#30340;&#22343;&#34913;&#35745;&#31639;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#20048;&#35266;&#38236;&#20687;&#19979;&#38477;&#27861;&#30340;&#21407;&#29702;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#25913;&#36827;&#20102;&#20808;&#21069;&#22312;&#24102;&#26377;&#36172;&#24466;&#21453;&#39304;&#30340;&#28216;&#25103;&#20013;&#30340;&#24037;&#20316;&#12290;3. &#25105;&#20204;&#32771;&#34385;&#23616;&#37096;&#30417;&#25511;&#65292;&#36825;&#26159;&#19968;&#31181;&#21453;&#39304;&#31867;&#22411;&#65292;&#20854;&#20013;&#20915;&#31574;&#21046;&#23450;&#32773;&#21482;&#35266;&#23519;&#26234;&#33021;&#20307;&#21160;&#20316;&#30340;&#25688;&#35201;&#20449;&#24687;&#32780;&#19981;&#26159;&#20840;&#37096;&#20449;&#24687;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#19968;&#20010;&#21464;&#20307;&#65292;&#35813;&#31639;&#27861;&#23454;&#29616;&#20102;&#27492;&#35774;&#32622;&#30340;&#25910;&#25947;&#36895;&#24230;&#26368;&#20248;&#65292;&#19982;&#20808;&#21069;&#24037;&#20316;&#24314;&#31435;&#30340;&#19979;&#30028;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
A central problem in the theory of multi-agent reinforcement learning (MARL) is to understand what structural conditions and algorithmic principles lead to sample-efficient learning guarantees, and how these considerations change as we move from few to many agents. We study this question in a general framework for interactive decision making with multiple agents, encompassing Markov games with function approximation and normal-form games with bandit feedback. We focus on equilibrium computation, in which a centralized learning algorithm aims to compute an equilibrium by controlling multiple agents that interact with an unknown environment. Our main contributions are:  - We provide upper and lower bounds on the optimal sample complexity for multi-agent decision making based on a multi-agent generalization of the Decision-Estimation Coefficient, a complexity measure introduced by Foster et al. (2021) in the single-agent counterpart to our setting. Compared to the best results for the sin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#65292;&#23558;&#27785;&#31215;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#27969;&#32467;&#21512;&#36215;&#26469;&#20197;&#30740;&#31350;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#39044;&#27979;&#21644;&#21160;&#21147;&#23398;&#34892;&#20026;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#38271;&#26399;&#28436;&#21270;&#24182;&#22797;&#21046;&#20102;&#21160;&#21147;&#23398;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2305.00669</link><description>&lt;p&gt;
&#24102;&#35823;&#24046;&#26657;&#27491;&#30340;&#27785;&#31215;&#35745;&#31639;&#65306;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#38271;&#26399;&#34892;&#20026;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Reservoir Computing with Error Correction: Long-term Behaviors of Stochastic Dynamical Systems. (arXiv:2305.00669v1 [math.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#65292;&#23558;&#27785;&#31215;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#27969;&#32467;&#21512;&#36215;&#26469;&#20197;&#30740;&#31350;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#39044;&#27979;&#21644;&#21160;&#21147;&#23398;&#34892;&#20026;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#38271;&#26399;&#28436;&#21270;&#24182;&#22797;&#21046;&#20102;&#21160;&#21147;&#23398;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#39044;&#27979;&#21644;&#21160;&#21147;&#23398;&#34892;&#20026;&#30340;&#25429;&#25417;&#26159;&#19968;&#20010;&#28145;&#21051;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26694;&#26550;&#65292;&#23558;&#27785;&#31215;&#35745;&#31639;&#21644;&#24402;&#19968;&#21270;&#27969;&#32467;&#21512;&#36215;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#23427;&#27169;&#20223;&#35823;&#24046;&#24314;&#27169;&#26469;&#25552;&#39640;&#20256;&#32479;&#27785;&#31215;&#35745;&#31639;&#30340;&#24615;&#33021;&#65292;&#24182;&#20805;&#20998;&#21033;&#29992;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;&#36825;&#31181;&#26080;&#27169;&#22411;&#26041;&#27861;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#38271;&#26399;&#28436;&#21270;&#65292;&#24182;&#22797;&#21046;&#20102;&#21160;&#21147;&#23398;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
The prediction of stochastic dynamical systems and the capture of dynamical behaviors are profound problems. In this article, we propose a data-driven framework combining Reservoir Computing and Normalizing Flow to study this issue, which mimics error modeling to improve the traditional Reservoir Computing performance and takes advantage of both approaches. This model-free method successfully predicts the long-term evolution of stochastic dynamical systems and replicates dynamical behaviors. With few assumptions about the underlying stochastic dynamical systems, we deal with Markov/non-Markov and stationary/non-stationary stochastic processes defined by linear/nonlinear stochastic differential equations or stochastic delay differential equations. We verify the effectiveness of the proposed framework in five experiments, including the Ornstein-Uhlenbeck process, Double-Well system, El Ni\~no Southern Oscillation simplified model, and stochastic Lorenz system. Additionally, we explore th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#21516;&#26102;&#24314;&#31435;&#20102;&#19979;&#38480;&#35823;&#24046;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#27492;&#22806;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.00608</link><description>&lt;p&gt;
&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65306;&#22312;&#24471;&#20998;&#20272;&#35745;&#21644;&#20445;&#24207;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression. (arXiv:2305.00608v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00608
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#21516;&#26102;&#24314;&#31435;&#20102;&#19979;&#38480;&#35823;&#24046;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#27492;&#22806;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#30001;&#20462;&#27491;&#21518;&#30340;&#24130;&#21333;&#20803;&#65288;RePU&#65289;&#20989;&#25968;&#28608;&#27963;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;RePU&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#23548;&#25968;&#21487;&#20197;&#30001;&#28151;&#21512;&#28608;&#27963;RePU&#32593;&#32476;&#26469;&#34920;&#31034;&#65292;&#24182;&#25512;&#23548;&#20102;&#23548;&#25968;RePU&#32593;&#32476;&#20989;&#25968;&#31867;&#30340;&#22797;&#26434;&#24230;&#30340;&#19978;&#30028;&#12290;&#22312;&#20351;&#29992;RePU&#28608;&#27963;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#21516;&#26102;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#35823;&#24046;&#30028;&#12290;&#27492;&#22806;&#65292;&#24403;&#25968;&#25454;&#20855;&#26377;&#36817;&#20284;&#20302;&#32500;&#25903;&#25345;&#26102;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#25913;&#36827;&#30340;&#36924;&#36817;&#35823;&#24046;&#30028;&#65292;&#35777;&#26126;&#20102;RePU&#32593;&#32476;&#20943;&#32531;&#32500;&#24230;&#28798;&#38590;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35828;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#28145;&#24230;&#24471;&#20998;&#21305;&#37197;&#20272;&#35745;&#22120;(DSME)&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#12290;&#25105;&#20204;&#22312;&#20551;&#23450;&#30446;&#26631;&#20989;&#25968;&#23646;&#20110;$C^s$&#24179;&#28369;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#20026;DSME&#21644;PDIR&#24314;&#31435;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the properties of differentiable neural networks activated by rectified power unit (RePU) functions. We show that the partial derivatives of RePU neural networks can be represented by RePUs mixed-activated networks and derive upper bounds for the complexity of the function class of derivatives of RePUs networks. We establish error bounds for simultaneously approximating $C^s$ smooth functions and their derivatives using RePU-activated deep neural networks. Furthermore, we derive improved approximation error bounds when data has an approximate low-dimensional support, demonstrating the ability of RePU networks to mitigate the curse of dimensionality. To illustrate the usefulness of our results, we consider a deep score matching estimator (DSME) and propose a penalized deep isotonic regression (PDIR) using RePU networks. We establish non-asymptotic excess risk bounds for DSME and PDIR under the assumption that the target functions belong to a class of $C^s$ smooth functions. We 
&lt;/p&gt;</description></item><item><title>ISAAC Newton&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36873;&#25321;&#30340;&#20108;&#38454;&#20449;&#24687;&#35843;&#25972;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#36873;&#25321;&#25209;&#37327;&#22823;&#23567;&#23567;&#20110;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#35745;&#31639;&#24320;&#38144;&#28040;&#22833;&#65292;&#33021;&#22815;&#22312;&#23567;&#25209;&#37327;&#38543;&#26426;&#24773;&#20917;&#19979;&#26377;&#25928;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2305.00604</link><description>&lt;p&gt;
ISAAC Newton&#65306;&#29275;&#39039;&#27861;&#30340;&#22522;&#20110;&#36755;&#20837;&#30340;&#36817;&#20284;&#26354;&#29575;
&lt;/p&gt;
&lt;p&gt;
ISAAC Newton: Input-based Approximate Curvature for Newton's Method. (arXiv:2305.00604v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00604
&lt;/p&gt;
&lt;p&gt;
ISAAC Newton&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36873;&#25321;&#30340;&#20108;&#38454;&#20449;&#24687;&#35843;&#25972;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#36873;&#25321;&#25209;&#37327;&#22823;&#23567;&#23567;&#20110;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#35745;&#31639;&#24320;&#38144;&#28040;&#22833;&#65292;&#33021;&#22815;&#22312;&#23567;&#25209;&#37327;&#38543;&#26426;&#24773;&#20917;&#19979;&#26377;&#25928;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ISAAC&#65288;Input-baSed ApproximAte Curvature&#65289;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#36873;&#25321;&#30340;&#20108;&#38454;&#20449;&#24687;&#26469;&#35843;&#25972;&#26799;&#24230;&#65292;&#24182;&#19988;&#22312;&#25209;&#37327;&#22823;&#23567;&#23567;&#20110;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#28176;&#36817;&#28040;&#22833;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20165;&#22522;&#20110;&#30456;&#24212;&#23618;&#30340;&#36755;&#20837;&#32780;&#19981;&#38656;&#35201;&#23454;&#36136;&#24615;&#35745;&#31639;&#24320;&#38144;&#30340;&#24773;&#20917;&#19979;&#65292;&#35745;&#31639;&#20986;&#19968;&#20010;&#33391;&#22909;&#30340;&#35843;&#33410;&#22120;&#26159;&#21487;&#33021;&#30340;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20801;&#35768;&#22312;&#23567;&#25209;&#37327;&#38543;&#26426;&#24773;&#20917;&#19979;&#26377;&#25928;&#35757;&#32451;&#65292;&#36825;&#20351;&#23427;&#19982;&#19968;&#38454;&#20197;&#21450;&#20108;&#38454;&#26041;&#27861;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present ISAAC (Input-baSed ApproximAte Curvature), a novel method that conditions the gradient using selected second-order information and has an asymptotically vanishing computational overhead, assuming a batch size smaller than the number of neurons. We show that it is possible to compute a good conditioner based on only the input to a respective layer without a substantial computational overhead. The proposed method allows effective training even in small-batch stochastic regimes, which makes it competitive to first-order as well as second-order methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#31283;&#20581;&#36716;&#31227;&#23398;&#20064;&#65288;ART&#65289;&#31649;&#36947;&#65292;&#20351;&#29992;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23454;&#29616;&#36716;&#31227;&#23398;&#20064;&#65292;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#23398;&#20064;&#29702;&#35770;&#65292;&#21516;&#26102;&#38450;&#27490;&#36127;&#38754;&#36716;&#31227;&#65292;&#24182;&#28436;&#31034;&#20102;&#23427;&#22312;&#22238;&#24402;&#12289;&#20998;&#31867;&#21644;&#31232;&#30095;&#23398;&#20064;&#19978;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.00520</link><description>&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#33402;&#26415;&#65306;&#19968;&#31181;&#33258;&#36866;&#24212;&#21644;&#31283;&#20581;&#30340;&#31649;&#36947;
&lt;/p&gt;
&lt;p&gt;
The ART of Transfer Learning: An Adaptive and Robust Pipeline. (arXiv:2305.00520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#31283;&#20581;&#36716;&#31227;&#23398;&#20064;&#65288;ART&#65289;&#31649;&#36947;&#65292;&#20351;&#29992;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23454;&#29616;&#36716;&#31227;&#23398;&#20064;&#65292;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#23398;&#20064;&#29702;&#35770;&#65292;&#21516;&#26102;&#38450;&#27490;&#36127;&#38754;&#36716;&#31227;&#65292;&#24182;&#28436;&#31034;&#20102;&#23427;&#22312;&#22238;&#24402;&#12289;&#20998;&#31867;&#21644;&#31232;&#30095;&#23398;&#20064;&#19978;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#26159;&#21033;&#29992;&#36741;&#21161;&#25968;&#25454;&#36164;&#28304;&#26469;&#25552;&#39640;&#20027;&#35201;&#20219;&#21153;&#24615;&#33021;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#33258;&#36866;&#24212;&#31283;&#20581;&#36716;&#31227;&#23398;&#20064;&#65288;ART&#65289;&#65292;&#19968;&#31181;&#20351;&#29992;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#36716;&#31227;&#23398;&#20064;&#30340;&#28789;&#27963;&#31649;&#36947;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;ART&#30340;&#38750;&#28176;&#36817;&#23398;&#20064;&#29702;&#35770;&#65292;&#20026;&#23454;&#29616;&#33258;&#36866;&#24212;&#36716;&#31227;&#24182;&#38450;&#27490;&#36127;&#38754;&#36716;&#31227;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;ART&#38598;&#25104;&#32858;&#21512;&#26426;&#21046;&#65292;&#29992;&#20110;&#22312;&#32771;&#34385;&#22810;&#20010;&#20505;&#36873;&#31639;&#27861;&#26102;&#20135;&#29983;&#21333;&#20010;&#26368;&#32456;&#27169;&#22411;&#12290;&#36890;&#36807;&#22238;&#24402;&#12289;&#20998;&#31867;&#21644;&#31232;&#30095;&#23398;&#20064;&#30340;&#24191;&#27867;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ART&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#28041;&#21450;&#27515;&#20129;&#29575;&#30740;&#31350;&#30340;&#30495;&#23454;&#25968;&#25454;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning is an essential tool for improving the performance of primary tasks by leveraging information from auxiliary data resources. In this work, we propose Adaptive Robust Transfer Learning (ART), a flexible pipeline of performing transfer learning with generic machine learning algorithms. We establish the non-asymptotic learning theory of ART, providing a provable theoretical guarantee for achieving adaptive transfer while preventing negative transfer. Additionally, we introduce an ART-integrated-aggregating machine that produces a single final model when multiple candidate algorithms are considered. We demonstrate the promising performance of ART through extensive empirical studies on regression, classification, and sparse learning. We further present a real-data analysis for a mortality study.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500; DAFNO&#65292;&#21487;&#20197;&#23398;&#20064;&#24102;&#26377;&#19981;&#35268;&#21017;&#20960;&#20309;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#22495;&#30340;&#20195;&#29702;&#12290;&#36890;&#36807;&#23558;&#24179;&#28369;&#21270;&#30340;&#29305;&#24449;&#20989;&#25968;&#32435;&#20837; FNOs &#30340;&#31215;&#20998;&#23618;&#26550;&#26500;&#20013;&#65292;&#24182;&#21033;&#29992; FFT &#26469;&#23454;&#29616;&#24555;&#36895;&#35745;&#31639;&#65292;&#20197;&#26126;&#30830;&#30340;&#26041;&#24335;&#23558;&#20960;&#20309;&#20449;&#24687;&#32534;&#30721;&#21040;&#26550;&#26500;&#20013;&#65292;DAFNO &#30456;&#23545;&#20110;&#22522;&#32447;&#31070;&#32463;&#31639;&#23376;&#27169;&#22411;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.00478</link><description>&lt;p&gt;
&#22495;&#19981;&#21487;&#30693;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Domain Agnostic Fourier Neural Operators. (arXiv:2305.00478v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00478
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500; DAFNO&#65292;&#21487;&#20197;&#23398;&#20064;&#24102;&#26377;&#19981;&#35268;&#21017;&#20960;&#20309;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#22495;&#30340;&#20195;&#29702;&#12290;&#36890;&#36807;&#23558;&#24179;&#28369;&#21270;&#30340;&#29305;&#24449;&#20989;&#25968;&#32435;&#20837; FNOs &#30340;&#31215;&#20998;&#23618;&#26550;&#26500;&#20013;&#65292;&#24182;&#21033;&#29992; FFT &#26469;&#23454;&#29616;&#24555;&#36895;&#35745;&#31639;&#65292;&#20197;&#26126;&#30830;&#30340;&#26041;&#24335;&#23558;&#20960;&#20309;&#20449;&#24687;&#32534;&#30721;&#21040;&#26550;&#26500;&#20013;&#65292;DAFNO &#30456;&#23545;&#20110;&#22522;&#32447;&#31070;&#32463;&#31639;&#23376;&#27169;&#22411;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#65288;FNOs&#65289;&#33021;&#22815;&#23398;&#20064;&#22312;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#26144;&#23556;&#65292;&#26368;&#36817;&#24050;&#25104;&#20026;&#23398;&#20064;&#22797;&#26434;&#29289;&#29702;&#31995;&#32479;&#21709;&#24212;&#30340;&#28909;&#38376;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#23454;&#29616;&#33391;&#22909;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#65292;FNOs &#20381;&#36182;&#20110;&#24555;&#36895;&#20613;&#37324;&#21494;&#21464;&#25442; (FFT)&#65292;&#35813;&#21464;&#25442;&#20165;&#38480;&#20110;&#30697;&#24418;&#22495;&#19978;&#30340;&#24314;&#27169;&#38382;&#39064;&#12290;&#20026;&#20102;&#28040;&#38500;&#36825;&#26679;&#30340;&#38480;&#21046;&#65292;&#20801;&#35768; FFT &#22312;&#19981;&#35268;&#21017;&#20960;&#20309;&#20197;&#21450;&#25299;&#25169;&#21464;&#21270;&#20013;&#20351;&#29992;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22495;&#19981;&#21487;&#30693;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376; (DAFNO)&#65292;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#24102;&#26377;&#19981;&#35268;&#21017;&#20960;&#20309;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#22495;&#30340;&#20195;&#29702;&#30340;&#26032;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#24179;&#28369;&#21270;&#30340;&#29305;&#24449;&#20989;&#25968;&#32435;&#20837; FNOs &#30340;&#31215;&#20998;&#23618;&#26550;&#26500;&#20013;&#65292;&#24182;&#21033;&#29992; FFT &#26469;&#23454;&#29616;&#24555;&#36895;&#35745;&#31639;&#65292;&#20197;&#20415;&#20197;&#26126;&#30830;&#30340;&#26041;&#24335;&#23558;&#20960;&#20309;&#20449;&#24687;&#32534;&#30721;&#21040;&#26550;&#26500;&#20013;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#35777;&#35780;&#20272;&#20013;&#65292;DAFNO &#30456;&#23545;&#20110;&#22522;&#32447;&#31070;&#32463;&#31639;&#23376;&#27169;&#22411;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fourier neural operators (FNOs) can learn highly nonlinear mappings between function spaces, and have recently become a popular tool for learning responses of complex physical systems. However, to achieve good accuracy and efficiency, FNOs rely on the Fast Fourier transform (FFT), which is restricted to modeling problems on rectangular domains. To lift such a restriction and permit FFT on irregular geometries as well as topology changes, we introduce domain agnostic Fourier neural operator (DAFNO), a novel neural operator architecture for learning surrogates with irregular geometries and evolving domains. The key idea is to incorporate a smoothed characteristic function in the integral layer architecture of FNOs, and leverage FFT to achieve rapid computations, in such a way that the geometric information is explicitly encoded in the architecture. In our empirical evaluation, DAFNO has achieved state-of-the-art accuracy as compared to baseline neural operator models on two benchmark dat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#26102;&#38388;&#24207;&#21015;&#32858;&#31867;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#36873;&#25321;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#24211;&#20013;&#30340;&#32858;&#31867;&#25968;&#65292;&#24182;&#19988;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.00473</link><description>&lt;p&gt;
&#22522;&#20110;&#20840;&#23616;&#39044;&#27979;&#27169;&#22411;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#26102;&#38388;&#24207;&#21015;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Time series clustering based on prediction accuracy of global forecasting models. (arXiv:2305.00473v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00473
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#26102;&#38388;&#24207;&#21015;&#32858;&#31867;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#36873;&#25321;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#24211;&#20013;&#30340;&#32858;&#31867;&#25968;&#65292;&#24182;&#19988;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#32858;&#31867;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#20004;&#20010;&#36845;&#20195;&#27493;&#39588;&#65306;&#65288;i&#65289;&#36890;&#36807;&#32771;&#34385;&#27599;&#20010;&#31751;&#25152;&#28041;&#21450;&#30340;&#26102;&#24207;&#65292;&#24182;&#30001; pooling&#65288;&#38598;&#20013;&#65289;&#25311;&#21512; K &#20010;&#20840;&#23616;&#39044;&#27979;&#27169;&#22411;&#65307;&#65288;ii&#65289;&#27599;&#20010;&#24207;&#21015;&#34987;&#20998;&#37197;&#21040;&#20135;&#29983;&#26368;&#20339;&#39044;&#27979;&#30340;&#27169;&#22411;&#20851;&#32852;&#30340;&#32452;&#12290;&#19982;&#25991;&#29486;&#20013;&#22823;&#22810;&#25968;&#25216;&#26415;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#23558;&#39044;&#27979;&#20934;&#30830;&#24615;&#20316;&#20026;&#26500;&#24314;&#32858;&#31867;&#20998;&#21306;&#30340;&#20027;&#35201;&#20803;&#32032;&#65292;&#20854;&#20013;&#21253;&#21547;&#20849;&#21516;&#26368;&#23567;&#21270;&#24635;&#20307;&#39044;&#27979;&#35823;&#24046;&#30340;&#32452;&#12290;&#22240;&#27492;&#65292;&#35813;&#26041;&#27861;&#23548;&#33268;&#20102;&#19968;&#20010;&#26032;&#30340;&#32858;&#31867;&#33539;&#24335;&#65292;&#20854;&#20013;&#32858;&#31867;&#35299;&#30340;&#36136;&#37327;&#26159;&#36890;&#36807;&#20854;&#39044;&#27979;&#33021;&#21147;&#26469;&#34913;&#37327;&#30340;&#12290;&#27492;&#22806;&#65292;&#35813;&#36807;&#31243;&#36824;&#24341;&#36215;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#24211;&#20013;&#36873;&#25321;&#32858;&#31867;&#25968;&#30340;&#26377;&#25928;&#26426;&#21046;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#20219;&#20309;&#22238;&#24402;&#27169;&#22411;&#31867;&#32467;&#21512;&#20351;&#29992;&#12290;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#26159;&#35201;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#21152;&#22909;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, a novel method to perform model-based clustering of time series is proposed. The procedure relies on two iterative steps: (i) K global forecasting models are fitted via pooling by considering the series pertaining to each cluster and (ii) each series is assigned to the group associated with the model producing the best forecasts according to a particular criterion. Unlike most techniques proposed in the literature, the method considers the predictive accuracy as the main element for constructing the clustering partition, which contains groups jointly minimizing the overall forecasting error. Thus, the approach leads to a new clustering paradigm where the quality of the clustering solution is measured in terms of its predictive capability. In addition, the procedure gives rise to an effective mechanism for selecting the number of clusters in a time series database and can be used in combination with any class of regression model. An extensive simulation study shows that o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#29992;&#20110;&#27979;&#35797;&#20004;&#20010;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#36807;&#31243;&#24179;&#31561;&#24615;&#30340;&#33258;&#21161;&#27861;&#12290;&#36890;&#36807;&#20998;&#26512;&#19977;&#31181;&#26041;&#27861;&#30340;&#31561;&#20540;&#24615;&#21644;&#24046;&#24322;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#23427;&#20204;&#22312;&#19981;&#21516;&#22797;&#26434;&#24230;&#31243;&#24230;&#30340;&#20998;&#31867;&#27169;&#22411;&#19979;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.00465</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;&#30340;&#26032;&#33258;&#21161;&#27861;&#26816;&#39564;&#12290;&#19968;&#39033;&#27604;&#36739;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
New bootstrap tests for categorical time series. A comparative study. (arXiv:2305.00465v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#29992;&#20110;&#27979;&#35797;&#20004;&#20010;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#36807;&#31243;&#24179;&#31561;&#24615;&#30340;&#33258;&#21161;&#27861;&#12290;&#36890;&#36807;&#20998;&#26512;&#19977;&#31181;&#26041;&#27861;&#30340;&#31561;&#20540;&#24615;&#21644;&#24046;&#24322;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#23427;&#20204;&#22312;&#19981;&#21516;&#22797;&#26434;&#24230;&#31243;&#24230;&#30340;&#20998;&#31867;&#27169;&#22411;&#19979;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#27979;&#35797;&#20004;&#20010;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#36807;&#31243;&#24179;&#31561;&#24615;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#30340;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#22522;&#20110;&#20998;&#31867;&#36807;&#31243;&#20043;&#38388;&#24046;&#24322;&#30340;&#27979;&#35797;&#26041;&#27861;&#12290;&#32771;&#34385;&#21040;&#20004;&#20010;&#24207;&#21015;&#30340;&#36793;&#38469;&#20998;&#24067;&#21644;&#24207;&#21015;&#20381;&#36182;&#27169;&#24335;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#29305;&#23450;&#29256;&#26412;&#30340;&#36825;&#20123;&#27979;&#35797;&#26041;&#27861;&#12290;&#26500;&#24314;&#30340;&#27979;&#35797;&#26041;&#27861;&#30340;&#37325;&#35201;&#37096;&#20998;&#26159;&#36825;&#20123;&#24046;&#24322;&#30340;&#36866;&#24403;&#20272;&#35745;&#65292;&#36825;&#20123;&#20272;&#35745;&#26159;&#22522;&#20110;&#33258;&#21161;&#27861;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20551;&#35774;&#30495;&#26159;&#29983;&#25104;&#27169;&#22411;&#30340;&#21442;&#25968;&#33258;&#21161;&#27861;&#65292;&#20197;&#21450;&#31227;&#21160;&#22359;&#33258;&#21161;&#27861;&#21644;&#38745;&#24577;&#33258;&#21161;&#27861;&#30340;&#25193;&#23637;&#12290;&#25105;&#20204;&#22312;&#21253;&#25324;&#20855;&#26377;&#19981;&#21516;&#22797;&#26434;&#24230;&#31243;&#24230;&#30340;&#22810;&#31181;&#20998;&#31867;&#27169;&#22411;&#30340;&#24191;&#27867;&#27169;&#25311;&#30740;&#31350;&#20013;&#35780;&#20272;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#26681;&#25454;&#23427;&#20204;&#22312;&#38646;&#20551;&#35774;&#21644;&#22791;&#25321;&#20551;&#35774;&#19979;&#20197;&#21450;&#21151;&#29575;&#19979;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#36866;&#24403;&#22320;&#35752;&#35770;&#20102;&#27599;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of testing the equality of the generating processes of two categorical time series is addressed in this work. To this aim, we propose three tests relying on a dissimilarity measure between categorical processes. Particular versions of these tests are constructed by considering three specific distances evaluating discrepancy between the marginal distributions and the serial dependence patterns of both processes. Proper estimates of these dissimilarities are an essential element of the constructed tests, which are based on the bootstrap. Specifically, a parametric bootstrap method assuming the true generating models and extensions of the moving blocks bootstrap and the stationary bootstrap are considered. The approaches are assessed in a broad simulation study including several types of categorical models with different degrees of complexity. Advantages and disadvantages of each one of the methods are properly discussed according to their behavior under the null and the alter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#38480;&#29366;&#24577;&#19981;&#24819;&#38745;&#27490;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;rollout&#31574;&#30053;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#21333;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#19978;&#23637;&#31034;&#20102;&#32467;&#26500;&#32467;&#26524;&#21644;&#21487;&#32034;&#24341;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.00410</link><description>&lt;p&gt;
&#26377;&#38480;&#29366;&#24577;&#19981;&#24819;&#38745;&#27490;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;Rollout&#31574;&#30053;&#30340;&#21487;&#32034;&#24341;&#24615;
&lt;/p&gt;
&lt;p&gt;
Indexability of Finite State Restless Multi-Armed Bandit and Rollout Policy. (arXiv:2305.00410v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#38480;&#29366;&#24577;&#19981;&#24819;&#38745;&#27490;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;rollout&#31574;&#30053;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#21333;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#19978;&#23637;&#31034;&#20102;&#32467;&#26500;&#32467;&#26524;&#21644;&#21487;&#32034;&#24341;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#38480;&#29366;&#24577;&#19981;&#24819;&#38745;&#27490;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#20915;&#31574;&#32773;&#21487;&#20197;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#20013;&#36873;&#25321;M&#20010;&#33218;&#20013;&#30340;&#20219;&#24847;&#19968;&#20010;&#65292;&#33218;&#30340;&#25773;&#25918;&#20135;&#29983;&#22522;&#20110;&#21160;&#20316;&#30340;&#29366;&#24577;&#30456;&#20851;&#22870;&#21169;&#65292;&#24403;&#33218;&#27809;&#26377;&#34987;&#25773;&#25918;&#26102;&#65292;&#23427;&#36824;&#25552;&#20379;&#22522;&#20110;&#29366;&#24577;&#21644;&#21160;&#20316;&#30340;&#22870;&#21169;&#12290;&#20915;&#31574;&#32773;&#30340;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#26080;&#38480;&#26102;&#38388;&#38271;&#24230;&#30340;&#25240;&#25187;&#22870;&#21169;&#12290;&#20256;&#32479;&#30340;&#19981;&#24819;&#38745;&#27490;&#36172;&#21338;&#26426;&#26041;&#27861;&#26159;&#20351;&#29992; Whittle &#32034;&#24341;&#31574;&#30053;&#12290;&#22312;&#36825;&#31181;&#31574;&#30053;&#20013;&#65292;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#25773;&#25918;&#20855;&#26377;&#26368;&#39640;&#25351;&#25968;&#30340;M&#20010;&#33218;&#12290;&#25105;&#20204;&#23558;&#19981;&#24819;&#38745;&#27490;&#36172;&#21338;&#26426;&#38382;&#39064;&#20998;&#31163;&#25104;&#20998;&#26512;&#26494;&#24347;&#32422;&#26463;&#19981;&#24819;&#38745;&#27490;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#28982;&#21518;&#36890;&#36807;&#25289;&#26684;&#26391;&#26085;&#26494;&#24347;&#38382;&#39064;&#65292;&#23558;&#19981;&#24819;&#38745;&#27490;&#36172;&#21338;&#26426;&#38382;&#39064;&#20998;&#31163;&#25104;N&#20010;&#21333;&#33218;&#19981;&#24819;&#38745;&#27490;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#33218;&#19981;&#24819;&#38745;&#27490;&#36172;&#21338;&#26426;&#12290;&#20026;&#20102;&#30740;&#31350; Whittle &#32034;&#24341;&#31574;&#30053;&#65292;&#25105;&#20204;&#22312;&#21333;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#19978;&#23637;&#31034;&#20102;&#32467;&#26500;&#32467;&#26524;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#21487;&#32034;&#24341;&#24615;&#65292;&#24182;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#23637;&#31034;&#20102;&#21487;&#32034;&#24341;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;rollout&#31574;&#30053;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider finite state restless multi-armed bandit problem. The decision maker can act on M bandits out of N bandits in each time step. The play of arm (active arm) yields state dependent rewards based on action and when the arm is not played, it also provides rewards based on the state and action. The objective of the decision maker is to maximize the infinite horizon discounted reward. The classical approach to restless bandits is Whittle index policy. In such policy, the M arms with highest indices are played at each time step. Here, one decouples the restless bandits problem by analyzing relaxed constrained restless bandits problem. Then by Lagrangian relaxation problem, one decouples restless bandits problem into N single-armed restless bandit problems. We analyze the single-armed restless bandit. In order to study the Whittle index policy, we show structural results on the single armed bandit model. We define indexability and show indexability in special cases. We propose an al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22522;&#20110;&#39034;&#24207;&#23454;&#39564;&#30340;&#26368;&#20248;&#26816;&#39564;&#26041;&#27861;&#65292;&#37325;&#35201;&#21457;&#29616;&#26159;&#20219;&#20309;&#26816;&#39564;&#30340;&#28176;&#36817;&#21151;&#29575;&#20989;&#25968;&#37117;&#21487;&#20197;&#19982;&#19968;&#31181;&#26497;&#38480;&#23454;&#39564;&#20013;&#21305;&#37197;&#30340;&#26816;&#39564;&#30456;&#21305;&#37197;&#65292;&#36825;&#20010;&#32467;&#26524;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#65292;&#21253;&#25324;&#19968;&#20010;&#24378;&#22823;&#30340;&#20805;&#20998;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.00403</link><description>&lt;p&gt;
&#22522;&#20110;&#39034;&#24207;&#23454;&#39564;&#30340;&#26368;&#20248;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal tests following sequential experiments. (arXiv:2305.00403v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22522;&#20110;&#39034;&#24207;&#23454;&#39564;&#30340;&#26368;&#20248;&#26816;&#39564;&#26041;&#27861;&#65292;&#37325;&#35201;&#21457;&#29616;&#26159;&#20219;&#20309;&#26816;&#39564;&#30340;&#28176;&#36817;&#21151;&#29575;&#20989;&#25968;&#37117;&#21487;&#20197;&#19982;&#19968;&#31181;&#26497;&#38480;&#23454;&#39564;&#20013;&#21305;&#37197;&#30340;&#26816;&#39564;&#30456;&#21305;&#37197;&#65292;&#36825;&#20010;&#32467;&#26524;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#65292;&#21253;&#25324;&#19968;&#20010;&#24378;&#22823;&#30340;&#20805;&#20998;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#39034;&#24207;&#23454;&#39564;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#21462;&#24471;&#20102;&#24040;&#22823;&#36827;&#23637;&#12290;&#34429;&#28982;&#36825;&#20123;&#23454;&#39564;&#19981;&#19968;&#23450;&#26159;&#20026;&#20102;&#36827;&#34892;&#20551;&#35774;&#26816;&#39564;&#32780;&#35774;&#35745;&#30340;&#65292;&#20294;&#30740;&#31350;&#20154;&#21592;&#20173;&#28982;&#21487;&#33021;&#23545;&#23454;&#39564;&#23436;&#25104;&#21518;&#30340;&#26816;&#39564;&#24863;&#20852;&#36259;&#12290;&#26412;&#25991;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#20998;&#26512;&#23427;&#20204;&#30340;&#28176;&#36817;&#24615;&#36136;&#26469;&#24110;&#21161;&#21457;&#23637;&#39034;&#24207;&#23454;&#39564;&#30340;&#26368;&#20248;&#26816;&#39564;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#21457;&#29616;&#26159;&#65292;&#20219;&#20309;&#26816;&#39564;&#30340;&#28176;&#36817;&#21151;&#29575;&#20989;&#25968;&#37117;&#21487;&#20197;&#19982;&#26497;&#38480;&#23454;&#39564;&#20013;&#21305;&#37197;&#30340;&#26816;&#39564;&#30456;&#21305;&#37197;&#65292;&#22312;&#36825;&#20010;&#26497;&#38480;&#23454;&#39564;&#20013;&#65292;&#23545;&#20110;&#27599;&#31181;&#22788;&#29702;&#65292;&#35266;&#23519;&#20135;&#29983;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#23545;&#36825;&#20123;&#36807;&#31243;&#30340;&#28418;&#31227;&#36827;&#34892;&#25512;&#26029;&#12290;&#36825;&#20010;&#32467;&#26524;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#65292;&#21253;&#25324;&#19968;&#20010;&#24378;&#22823;&#30340;&#20805;&#20998;&#24615;&#32467;&#26524;&#65306;&#20219;&#20309;&#20505;&#36873;&#26816;&#39564;&#26041;&#27861;&#21482;&#38656;&#35201;&#20381;&#36182;&#20110;&#19968;&#32452;&#22266;&#23450;&#30340;&#32479;&#35745;&#37327;&#65292;&#32780;&#19981;&#26159;&#39034;&#24207;&#23454;&#39564;&#30340;&#31867;&#22411;&#12290;&#36825;&#20123;&#32479;&#35745;&#37327;&#26159;&#27599;&#31181;&#22788;&#29702;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#34987;&#37319;&#26679;&#30340;&#27425;&#25968;&#65292;&#20197;&#21450;&#24471;&#20998;&#30340;&#26368;&#32456;&#20540;&#65288;&#23545;&#20110;&#21442;&#25968;&#27169;&#22411;&#65289;
&lt;/p&gt;
&lt;p&gt;
Recent years have seen tremendous advances in the theory and application of sequential experiments. While these experiments are not always designed with hypothesis testing in mind, researchers may still be interested in performing tests after the experiment is completed. The purpose of this paper is to aid in the development of optimal tests for sequential experiments by analyzing their asymptotic properties. Our key finding is that the asymptotic power function of any test can be matched by a test in a limit experiment where a Gaussian process is observed for each treatment, and inference is made for the drifts of these processes. This result has important implications, including a powerful sufficiency result: any candidate test only needs to rely on a fixed set of statistics, regardless of the type of sequential experiment. These statistics are the number of times each treatment has been sampled by the end of the experiment, along with final value of the score (for parametric models)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#31034;&#30340;&#26080;&#30417;&#30563;&#24494;&#35843;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#26410;&#26631;&#35760;&#30340;&#30446;&#26631;&#25968;&#25454;&#19978;&#24494;&#35843;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#20197;&#36866;&#24212;&#19979;&#28216;&#20219;&#21153;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#20998;&#31867;&#12289;&#24773;&#24863;&#20998;&#26512;&#21644;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#31561;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.00350</link><description>&lt;p&gt;
POUF: &#38754;&#21521;&#25552;&#31034;&#30340;&#26080;&#30417;&#30563;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained models. (arXiv:2305.00350v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00350
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#31034;&#30340;&#26080;&#30417;&#30563;&#24494;&#35843;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#26410;&#26631;&#35760;&#30340;&#30446;&#26631;&#25968;&#25454;&#19978;&#24494;&#35843;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#20197;&#36866;&#24212;&#19979;&#28216;&#20219;&#21153;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#20998;&#31867;&#12289;&#24773;&#24863;&#20998;&#26512;&#21644;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#31561;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#31034;&#65292;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#36817;&#24180;&#26469;&#21464;&#24471;&#26356;&#21152;&#34920;&#29616;&#20986;&#33394;&#21644;&#24378;&#22823;&#12290;&#34429;&#28982;&#36825;&#20123;&#22823;&#22411;&#27169;&#22411;&#20855;&#26377;&#38646;-shot &#33021;&#21147;&#65292;&#20294;&#36890;&#24120;&#20173;&#38656;&#35201;&#26377;&#26631;&#31614;&#30340;&#25968;&#25454;&#26469;&#36866;&#24212;&#19979;&#28216;&#20219;&#21153;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#20851;&#38190;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#24494;&#35843;&#26694;&#26550;&#65292;&#30452;&#25509;&#22312;&#26410;&#26631;&#35760;&#30340;&#30446;&#26631;&#25968;&#25454;&#19978;&#24494;&#35843;&#27169;&#22411;&#25110;&#25552;&#31034;&#12290;&#25105;&#20204;&#28436;&#31034;&#22914;&#20309;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#35821;&#35328;&#22686;&#24378;&#30340;&#35270;&#35273;&#21644;&#25513;&#34109;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#40784;&#20174;&#25552;&#31034;&#21644;&#30446;&#26631;&#25968;&#25454;&#20013;&#25552;&#21462;&#30340;&#31163;&#25955;&#20998;&#24067;&#26469;&#23454;&#29616;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#65292;&#25105;&#20204;&#23545;&#22270;&#20687;&#20998;&#31867;&#12289;&#24773;&#24863;&#20998;&#26512;&#21644;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20219;&#21153;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#12290;&#22312; 13 &#20010;&#19982;&#22270;&#20687;&#30456;&#20851;&#30340;&#20219;&#21153;&#21644; 15 &#20010;&#19982;&#35821;&#35328;&#30456;&#20851;&#30340;&#20219;&#21153;&#20013;&#65292;&#35813;&#26041;&#27861;&#22343;&#27604;&#22522;&#32447;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Through prompting, large-scale pre-trained models have become more expressive and powerful, gaining significant attention in recent years. Though these big models have zero-shot capabilities, in general, labeled data are still required to adapt them to downstream tasks. To overcome this critical limitation, we propose an unsupervised fine-tuning framework to directly fine-tune the model or prompt on the unlabeled target data. We demonstrate how to apply our method to both language-augmented vision and masked-language models by aligning the discrete distributions extracted from the prompts and target data. To verify our approach's applicability, we conduct extensive experiments on image classification, sentiment analysis, and natural language inference tasks. Across 13 image-related tasks and 15 language-related ones, the proposed approach achieves consistent improvements over the baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#23545;&#20110;&#21152;&#24615;Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#65292;&#36890;&#36807;&#31232;&#30095;&#30697;&#38453;&#21644;&#21521;&#37327;&#30340;&#20844;&#24335;&#21487;&#20197;&#26377;&#25928;&#22320;&#35745;&#31639;&#21518;&#39564;&#22343;&#20540;&#12289;&#21518;&#39564;&#26041;&#24046;&#12289;&#23545;&#25968;&#20284;&#28982;&#21644;&#26799;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.00324</link><description>&lt;p&gt;
&#29992;&#31232;&#30095;&#30697;&#38453;&#34920;&#31034;&#21152;&#24615;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Representing Additive Gaussian Processes by Sparse Matrices. (arXiv:2305.00324v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00324
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#23545;&#20110;&#21152;&#24615;Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#65292;&#36890;&#36807;&#31232;&#30095;&#30697;&#38453;&#21644;&#21521;&#37327;&#30340;&#20844;&#24335;&#21487;&#20197;&#26377;&#25928;&#22320;&#35745;&#31639;&#21518;&#39564;&#22343;&#20540;&#12289;&#21518;&#39564;&#26041;&#24046;&#12289;&#23545;&#25968;&#20284;&#28982;&#21644;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#20041;&#30456;&#21152;&#27169;&#22411;&#20013;&#65292;&#21152;&#24615;Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#26159;&#26368;&#21463;&#27426;&#36814;&#30340;&#21487;&#25193;&#23637;&#39640;&#32500;&#38382;&#39064;&#20043;&#19968;&#12290;&#30001;&#20110;&#23427;&#20204;&#30340;&#21152;&#24615;&#32467;&#26500;&#21644;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#34920;&#31034;&#65292;&#22522;&#20110;&#22238;&#24402;&#30340;&#31639;&#27861;&#21487;&#20197;&#23558;&#35745;&#31639;&#21518;&#39564;&#22343;&#20540;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;$O&#65288;n^3&#65289;$&#20943;&#23569;&#21040;$O&#65288;nlogn&#65289;$&#26102;&#38388;&#65292;&#20854;&#20013;$n$&#26159;&#25968;&#25454;&#22823;&#23567;&#12290;&#20294;&#26159;&#65292;&#23558;&#36825;&#20123;&#31639;&#27861;&#25512;&#24191;&#21040;&#26377;&#25928;&#35745;&#31639;&#21518;&#39564;&#26041;&#24046;&#21644;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#21152;&#24615;Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#65292;&#19981;&#20165;&#21518;&#39564;&#22343;&#20540;&#65292;&#32780;&#19988;&#21518;&#39564;&#26041;&#24046;&#12289;&#23545;&#25968;&#20284;&#28982;&#21644;&#36825;&#19977;&#20010;&#20989;&#25968;&#30340;&#26799;&#24230;&#21487;&#20197;&#29992;&#20165;&#28041;&#21450;&#31232;&#30095;&#30697;&#38453;&#21644;&#31232;&#30095;&#21521;&#37327;&#30340;&#20844;&#24335;&#34920;&#31034;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#36825;&#20123;&#31232;&#30095;&#20844;&#24335;&#26469;&#25512;&#24191;&#22238;&#24402;&#31639;&#27861;&#65292;&#20197;&#26377;&#25928;&#35745;&#31639;&#36825;&#19977;&#20010;&#20989;&#25968;&#30340;&#21518;&#39564;&#22343;&#20540;&#12289;&#21518;&#39564;&#26041;&#24046;&#12289;&#23545;&#25968;&#20284;&#28982;&#21644;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Among generalized additive models, additive Mat\'ern Gaussian Processes (GPs) are one of the most popular for scalable high-dimensional problems. Thanks to their additive structure and stochastic differential equation representation, back-fitting-based algorithms can reduce the time complexity of computing the posterior mean from $O(n^3)$ to $O(n\log n)$ time where $n$ is the data size. However, generalizing these algorithms to efficiently compute the posterior variance and maximum log-likelihood remains an open problem. In this study, we demonstrate that for Additive Mat\'ern GPs, not only the posterior mean, but also the posterior variance, log-likelihood, and gradient of these three functions can be represented by formulas involving only sparse matrices and sparse vectors. We show how to use these sparse formulas to generalize back-fitting-based algorithms to efficiently compute the posterior mean, posterior variance, log-likelihood, and gradient of these three functions for additiv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;Coupled Flow Imitation Learning&#65288;CFIL&#65289;&#65292;&#20351;&#29992;&#27491;&#21017;&#27969;&#27169;&#22411;&#30340;&#20998;&#24067;&#21305;&#37197;&#26469;&#24314;&#27169;&#29366;&#24577;&#20998;&#24067;&#21644;&#29366;&#24577;&#34892;&#20026;&#20998;&#24067;&#12290;&#22312;&#22522;&#20934;&#20219;&#21153;&#20013;&#20855;&#26377;&#21333;&#20010;&#19987;&#23478;&#36712;&#36857;&#34920;&#29616;&#20986;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.00303</link><description>&lt;p&gt;
&#19968;&#31181;&#32806;&#21512;&#27969;&#26041;&#27861;&#29992;&#20110;&#27169;&#20223;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
A Coupled Flow Approach to Imitation Learning. (arXiv:2305.00303v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;Coupled Flow Imitation Learning&#65288;CFIL&#65289;&#65292;&#20351;&#29992;&#27491;&#21017;&#27969;&#27169;&#22411;&#30340;&#20998;&#24067;&#21305;&#37197;&#26469;&#24314;&#27169;&#29366;&#24577;&#20998;&#24067;&#21644;&#29366;&#24577;&#34892;&#20026;&#20998;&#24067;&#12290;&#22312;&#22522;&#20934;&#20219;&#21153;&#20013;&#20855;&#26377;&#21333;&#20010;&#19987;&#23478;&#36712;&#36857;&#34920;&#29616;&#20986;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#20013;&#65292;&#31574;&#30053;&#24341;&#36215;&#30340;&#29366;&#24577;&#20998;&#24067;&#26159;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#23545;&#35937;&#12290;&#23427;&#22312;&#31574;&#30053;&#26799;&#24230;&#23450;&#29702;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#24182;&#19988;&#19982;&#30456;&#20851;&#30340;&#29366;&#24577;&#34892;&#20026;&#20998;&#24067;&#19968;&#36215;&#34987;&#24191;&#27867;&#24341;&#29992;&#12290;&#23613;&#31649;&#29366;&#24577;&#20998;&#24067;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#23427;&#22823;&#22810;&#26159;&#38388;&#25509;&#22320;&#21644;&#29702;&#35770;&#19978;&#35752;&#35770;&#65292;&#32780;&#19981;&#26159;&#26126;&#30830;&#22320;&#24314;&#27169;&#12290;&#21407;&#22240;&#26159;&#32570;&#20047;&#36866;&#24403;&#30340;&#23494;&#24230;&#20272;&#35745;&#24037;&#20855;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#27491;&#21017;&#27969;&#27169;&#22411;&#30340;&#19978;&#36848;&#20998;&#24067;&#24212;&#29992;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20351;&#29992;&#36890;&#36807;Donsker-Varadhan&#34920;&#31034;&#30340;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#26368;&#20248;&#28857;&#32806;&#21512;&#30340;&#19968;&#23545;&#27969;&#36827;&#34892;&#20998;&#24067;&#21305;&#37197;&#30340;&#27169;&#20223;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;Coupled Flow Imitation Learning&#65288;CFIL&#65289;&#22312;&#20855;&#26377;&#21333;&#20010;&#19987;&#23478;&#36712;&#36857;&#30340;&#22522;&#20934;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#21508;&#31181;&#24418;&#24335;&#30340;&#19987;&#23478;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reinforcement learning and imitation learning, an object of central importance is the state distribution induced by the policy. It plays a crucial role in the policy gradient theorem, and references to it--along with the related state-action distribution--can be found all across the literature. Despite its importance, the state distribution is mostly discussed indirectly and theoretically, rather than being modeled explicitly. The reason being an absence of appropriate density estimation tools. In this work, we investigate applications of a normalizing flow-based model for the aforementioned distributions. In particular, we use a pair of flows coupled through the optimality point of the Donsker-Varadhan representation of the Kullback-Leibler (KL) divergence, for distribution matching based imitation learning. Our algorithm, Coupled Flow Imitation Learning (CFIL), achieves state-of-the-art performance on benchmark tasks with a single expert trajectory and extends naturally to a varie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;EBLIME&#26041;&#27861;&#65292;&#20351;&#29992;&#36125;&#21494;&#26031;&#23725;&#22238;&#24402;&#27169;&#22411;&#20174;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#35299;&#37322;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#20998;&#24067;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35299;&#37322;&#33021;&#21147;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.00213</link><description>&lt;p&gt;
EBLIME: &#22686;&#24378;&#30340;&#36125;&#21494;&#26031;&#26412;&#22320;&#21487;&#35299;&#37322;&#27169;&#22411;&#26080;&#20851;&#35299;&#37322;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
EBLIME: Enhanced Bayesian Local Interpretable Model-agnostic Explanations. (arXiv:2305.00213v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;EBLIME&#26041;&#27861;&#65292;&#20351;&#29992;&#36125;&#21494;&#26031;&#23725;&#22238;&#24402;&#27169;&#22411;&#20174;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#35299;&#37322;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#20998;&#24067;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35299;&#37322;&#33021;&#21147;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;EBLIME&#26469;&#35299;&#37322;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#36125;&#21494;&#26031;&#23725;&#22238;&#24402;&#27169;&#22411;&#33719;&#24471;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36125;&#21494;&#26031;&#26694;&#26550;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21253;&#25324;&#23725;&#21442;&#25968;&#30340;&#26174;&#33879;&#24615;&#12290;&#25105;&#20204;&#23545;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#23454;&#38469;&#24037;&#19994;&#24212;&#29992;&#26696;&#20363;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#65292;&#28041;&#21450;&#23450;&#20301;&#21046;&#36896;&#20135;&#21697;&#20869;&#37096;&#32570;&#38519;&#12290;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;EBLIME&#20135;&#29983;&#26356;&#30452;&#35266;&#21644;&#20934;&#30830;&#30340;&#32467;&#26524;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#65292;&#21253;&#25324;&#29983;&#25104;&#21518;&#39564;&#20998;&#24067;&#12289;&#21487;&#20449;&#21306;&#38388;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose EBLIME to explain black-box machine learning models and obtain the distribution of feature importance using Bayesian ridge regression models. We provide mathematical expressions of the Bayesian framework and theoretical outcomes including the significance of ridge parameter. Case studies were conducted on benchmark datasets and a real-world industrial application of locating internal defects in manufactured products. Compared to the state-of-the-art methods, EBLIME yields more intuitive and accurate results, with better uncertainty quantification in terms of deriving the posterior distribution, credible intervals, and rankings of the feature importance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#30340;DDGroup&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35782;&#21035;&#20855;&#26377;&#29305;&#24449;&#19982;&#26631;&#31614;&#20043;&#38388;&#32479;&#19968;&#32447;&#24615;&#20851;&#31995;&#30340;&#23376;&#32676;&#65292;&#20026;&#21307;&#23398;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2305.00195</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#32447;&#24615;&#22238;&#24402;&#23376;&#32676;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Data-Driven Subgroup Identification for Linear Regression. (arXiv:2305.00195v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00195
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#30340;DDGroup&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35782;&#21035;&#20855;&#26377;&#29305;&#24449;&#19982;&#26631;&#31614;&#20043;&#38388;&#32479;&#19968;&#32447;&#24615;&#20851;&#31995;&#30340;&#23376;&#32676;&#65292;&#20026;&#21307;&#23398;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#23398;&#30740;&#31350;&#24120;&#24120;&#38656;&#35201;&#25552;&#21462;&#27599;&#20010;&#21327;&#21464;&#37327;&#19982;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#20351;&#29992;&#32479;&#35745;&#32622;&#20449;&#24230;&#27979;&#37327;&#12290;&#20026;&#27492;&#65292;&#36890;&#24120;&#20351;&#29992;&#31616;&#21333;&#30340;&#21442;&#25968;&#27169;&#22411;&#65288;&#20363;&#22914;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#65289;&#65292;&#20294;&#36890;&#24120;&#26159;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#25311;&#21512;&#12290;&#28982;&#32780;&#65292;&#21327;&#21464;&#37327;&#21487;&#33021;&#22312;&#25972;&#20010;&#20154;&#21475;&#20013;&#27809;&#26377;&#32479;&#19968;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#32479;&#19968;&#30340;&#31616;&#21333;&#27169;&#22411;&#21487;&#33021;&#20250;&#28431;&#25481;&#24322;&#36136;&#20449;&#21495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#30340;DDGroup (data-driven group discovery)&#65292;&#20197;&#26377;&#25928;&#35782;&#21035;&#25968;&#25454;&#20013;&#20855;&#26377;&#29305;&#24449;&#19982;&#26631;&#31614;&#20043;&#38388;&#32479;&#19968;&#32447;&#24615;&#20851;&#31995;&#30340;&#23376;&#32676;&#12290;DDGroup&#36755;&#20986;&#30340;&#21306;&#22495;&#26159;&#21487;&#20197;&#35299;&#37322;&#30340;&#65292;&#32780;&#19988;&#22312;&#35745;&#31639;&#19978;&#26131;&#20110;&#23454;&#29616;&#65292;&#36866;&#29992;&#20110;&#20351;&#29992;&#12290;&#29702;&#35770;&#19978;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#32473;&#23450;&#36275;&#22815;&#22823;&#30340;&#26679;&#26412;&#65292;DDGroup&#20445;&#35777;&#21487;&#20197;&#25214;&#21040;&#20855;&#26377;&#32479;&#19968;&#32447;&#24615;&#20851;&#31995;&#30340;&#23376;&#32676;&#12290;&#25105;&#20204;&#36824;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#30340;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;DDGroup&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Medical studies frequently require to extract the relationship between each covariate and the outcome with statistical confidence measures. To do this, simple parametric models are frequently used (e.g. coefficients of linear regression) but usually fitted on the whole dataset. However, it is common that the covariates may not have a uniform effect over the whole population and thus a unified simple model can miss the heterogeneous signal. For example, a linear model may be able to explain a subset of the data but fail on the rest due to the nonlinearity and heterogeneity in the data. In this paper, we propose DDGroup (data-driven group discovery), a data-driven method to effectively identify subgroups in the data with a uniform linear relationship between the features and the label. DDGroup outputs an interpretable region in which the linear model is expected to hold. It is simple to implement and computationally tractable for use. We show theoretically that, given a large enough samp
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#27169;&#22411;&#36873;&#25321;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#20854;&#36716;&#31227;&#36317;&#31163;&#20250;&#24433;&#21709;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21487;&#33021;&#23548;&#33268;&#36895;&#29575;&#36739;&#24930;&#12290;</title><link>http://arxiv.org/abs/2305.00152</link><description>&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#19979;&#30340;&#27169;&#22411;&#36873;&#25321;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#27169;&#22411;&#36873;&#25321;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#20854;&#36716;&#31227;&#36317;&#31163;&#20250;&#24433;&#21709;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21487;&#33021;&#23548;&#33268;&#36895;&#29575;&#36739;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#20851;&#20110;&#36716;&#31227;&#23398;&#20064;&#25110;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#29702;&#35770;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#24050;&#30693;&#20551;&#35774;&#31867;&#25110;&#27169;&#22411;&#30340;&#24773;&#20917;&#65307;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36890;&#24120;&#28041;&#21450;&#19968;&#23450;&#31243;&#24230;&#30340;&#27169;&#22411;&#36873;&#25321;&#65292;&#36825;&#32463;&#24120;&#20986;&#29616;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#24635;&#20307;&#33539;&#30068;&#19979;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#21487;&#20197;&#32771;&#34385;&#35843;&#25972;&#38024;&#23545;&#30446;&#26631;&#20219;&#21153;&#30340;&#27491;&#30830;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#21033;&#29992;&#26469;&#33258;&#30456;&#20851;&#28304;&#20219;&#21153;&#30340;&#25968;&#25454;&#12290;&#38500;&#20102;&#19982;&#27169;&#22411;&#36873;&#25321;&#26377;&#20851;&#30340;&#36817;&#20284;&#19982;&#20272;&#35745;&#35823;&#24046;&#30340;&#36890;&#24120;&#26435;&#34913;&#20043;&#22806;&#65292;&#36825;&#20010;&#38382;&#39064;&#36824;&#24102;&#26469;&#20102;&#26032;&#30340;&#22797;&#26434;&#24230;&#65292;&#21363;&#28304;&#20998;&#24067;&#19982;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#36716;&#31227;&#36317;&#31163;&#65292;&#36825;&#20010;&#36317;&#31163;&#38543;&#30528;&#20551;&#35774;&#31867;&#30340;&#36873;&#25321;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#20998;&#31867;&#38382;&#39064;&#12290;&#29305;&#21035;&#30340;&#65292;&#20998;&#26512;&#25581;&#31034;&#20102;&#19968;&#20123;&#24341;&#20154;&#27880;&#30446;&#30340;&#29616;&#35937;&#65306;&#33258;&#36866;&#24212;&#36895;&#29575;&#65292;&#21363;&#27809;&#26377;&#20998;&#24067;&#24335;&#20449;&#24687;&#26102;&#21487;&#36798;&#21040;&#30340;&#36895;&#29575;&#65292;&#21487;&#20197;&#20219;&#24847;&#24930;&#20110;oracle&#36895;&#29575;&#65292;&#21363;&#22312;&#32473;&#23450;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical studies on transfer learning or domain adaptation have so far focused on situations with a known hypothesis class or model; however in practice, some amount of model selection is usually involved, often appearing under the umbrella term of hyperparameter-tuning: for example, one may think of the problem of tuning for the right neural network architecture towards a target task, while leveraging data from a related source task.  Now, in addition to the usual tradeoffs on approximation vs estimation errors involved in model selection, this problem brings in a new complexity term, namely, the transfer distance between source and target distributions, which is known to vary with the choice of hypothesis class.  We present a first study of this problem, focusing on classification; in particular, the analysis reveals some remarkable phenomena: adaptive rates, i.e., those achievable with no distributional information, can be arbitrarily slower than oracle rates, i.e., when given kn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#30340;&#36172;&#21338;&#31574;&#30053;&#26469;&#35299;&#20915;&#39640;&#32500;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#19979;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#26816;&#39564;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.00143</link><description>&lt;p&gt;
&#39034;&#24207;&#39044;&#27979;&#21452;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Sequential Predictive Two-Sample and Independence Testing. (arXiv:2305.00143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#30340;&#36172;&#21338;&#31574;&#30053;&#26469;&#35299;&#20915;&#39640;&#32500;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#19979;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#26816;&#39564;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39034;&#24207;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#38382;&#39064;&#12290;&#39034;&#24207;&#26816;&#39564;&#22312;&#32447;&#22788;&#29702;&#25968;&#25454;&#65292;&#20801;&#35768;&#20351;&#29992;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#26469;&#20915;&#23450;&#26159;&#21542;&#20572;&#27490;&#24182;&#25298;&#32477;&#21407;&#20551;&#35774;&#65292;&#25110;&#22312;&#20445;&#25345;&#31867;&#22411;I&#38169;&#35823;&#25511;&#21046;&#30340;&#21516;&#26102;&#25910;&#38598;&#26356;&#22810;&#25968;&#25454;&#12290;&#25105;&#20204;&#24314;&#31435;&#22312;(&#38750;&#21442;&#25968;)&#27979;&#35797;&#36172;&#21338;&#21407;&#21017;&#20043;&#19978;&#65292;&#20854;&#20013;&#36172;&#24466;&#22312;&#26410;&#26469;&#35266;&#23519;&#20013;&#19979;&#27880;&#65292;&#20182;&#20204;&#30340;&#36130;&#23500;&#23545;&#35777;&#25454;&#21453;&#23545;&#21407;&#20551;&#35774;&#36827;&#34892;&#34913;&#37327;&#12290;&#26368;&#36817;&#24320;&#21457;&#30340;&#22522;&#20110;&#26680;&#30340;&#36172;&#21338;&#31574;&#30053;&#22312;&#31616;&#21333;&#20998;&#24067;&#19978;&#36890;&#24120;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#23545;&#20110;&#39640;&#32500;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#65289;&#36873;&#25321;&#21512;&#36866;&#30340;&#26680;&#36890;&#24120;&#26159;&#26840;&#25163;&#30340;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22522;&#20110;&#39044;&#27979;&#30340;&#36172;&#21338;&#31574;&#30053;&#65292;&#20381;&#36182;&#20110;&#20197;&#19979;&#20107;&#23454;&#65306;&#22914;&#26524;&#19968;&#20010;&#39034;&#24207;&#26356;&#26032;&#30340;&#39044;&#27979;&#22120;&#24320;&#22987;&#19968;&#33268;&#22320;&#30830;&#23450;(a)&#19968;&#20010;&#23454;&#20363;&#20174;&#21738;&#20010;&#20998;&#24067;&#20013;&#32472;&#21046;&#65292;&#25110;&#32773;(b)&#19968;&#20010;&#23454;&#20363;&#26159;&#20174;&#32852;&#21512;&#20998;&#24067;&#36824;&#26159;&#20174;&#36793;&#32536;&#20998;&#24067;&#30340;&#20056;&#31215;&#20013;&#32472;&#21046;&#30340;&#65292;&#21017;&#20998;&#24067;&#26159;&#19981;&#21516;&#25110;&#30456;&#20851;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28789;&#27963;&#65292;&#24182;&#23545;&#22522;&#30784;&#25968;&#25454;&#20998;&#24067;&#21644;&#32500;&#24230;&#19981;&#21487;&#30693;&#65292;&#21516;&#26102;&#20445;&#25345;&#19968;&#23450;&#30340;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#39034;&#24207;&#27979;&#35797;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problems of sequential nonparametric two-sample and independence testing. Sequential tests process data online and allow using observed data to decide whether to stop and reject the null hypothesis or to collect more data while maintaining type I error control. We build upon the principle of (nonparametric) testing by betting, where a gambler places bets on future observations and their wealth measures evidence against the null hypothesis. While recently developed kernel-based betting strategies often work well on simple distributions, selecting a suitable kernel for high-dimensional or structured data, such as text and images, is often nontrivial. To address this drawback, we design prediction-based betting strategies that rely on the following fact: if a sequentially updated predictor starts to consistently determine (a) which distribution an instance is drawn from, or (b) whether an instance is drawn from the joint distribution or the product of the marginal distributio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#31867;&#20998;&#31867;&#20013;&#25932;&#23545;&#35757;&#32451;&#30340;&#40065;&#26834;&#35299;&#23384;&#22312;&#24615;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#27599;&#20010;&#27169;&#22411;&#20013;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#40065;&#26834;&#20998;&#31867;&#22120;&#65292;&#24182;&#19982;&#26368;&#20248;&#20256;&#36755;&#21644;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#22312;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#23545;&#19981;&#21487;&#30693;&#20998;&#31867;&#22120;&#30340;&#25932;&#23545;&#35757;&#32451;&#38382;&#39064;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.00075</link><description>&lt;p&gt;
&#22810;&#31867;&#20998;&#31867;&#20013;&#25932;&#23545;&#35757;&#32451;&#35299;&#30340;&#23384;&#22312;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the existence of solutions to adversarial training in multiclass classification. (arXiv:2305.00075v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#31867;&#20998;&#31867;&#20013;&#25932;&#23545;&#35757;&#32451;&#30340;&#40065;&#26834;&#35299;&#23384;&#22312;&#24615;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#27599;&#20010;&#27169;&#22411;&#20013;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#40065;&#26834;&#20998;&#31867;&#22120;&#65292;&#24182;&#19982;&#26368;&#20248;&#20256;&#36755;&#21644;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#22312;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#23545;&#19981;&#21487;&#30693;&#20998;&#31867;&#22120;&#30340;&#25932;&#23545;&#35757;&#32451;&#38382;&#39064;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25932;&#23545;&#35757;&#32451;&#22312;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#19977;&#31181;&#27169;&#22411;&#65292;&#26088;&#22312;&#26500;&#24314;&#23545;&#25239;&#25200;&#21160;&#19979;&#40065;&#26834;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#27599;&#20010;&#27169;&#22411;&#20013;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#40065;&#26834;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#25932;&#23545;&#35757;&#32451;&#38382;&#39064;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#25299;&#23637;&#20102;&#20316;&#32773;&#20043;&#21069;&#30340;&#26368;&#20248;&#20256;&#36755;&#32852;&#31995;&#65292;&#24182;&#22312;&#22810;&#31867;&#24773;&#20917;&#19979;&#25932;&#23545;&#35757;&#32451;&#21644;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#20043;&#38388;&#24314;&#31435;&#20102;&#26032;&#30340;&#32852;&#31995;&#12290;&#20316;&#20026;&#25105;&#20204;&#32467;&#26524;&#30340;&#25512;&#35770;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20108;&#20803;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;&#23545;&#19981;&#21487;&#30693;&#20998;&#31867;&#22120;&#30340;&#25932;&#23545;&#35757;&#32451;&#38382;&#39064;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#35299;&#65292;&#36825;&#19968;&#32467;&#26524;&#25913;&#36827;&#20102;&#20851;&#20110;&#25932;&#23545;&#35757;&#32451;&#30340;&#25991;&#29486;&#65292;&#25991;&#29486;&#20013;&#20165;&#24050;&#30693;&#21482;&#26377;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#25193;&#22823;&#36890;&#29992; $&#963;$-&#20195;&#25968;&#20869;&#23384;&#22312;&#40065;&#26834;&#30340;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study three models of the problem of adversarial training in multiclass classification designed to construct robust classifiers against adversarial perturbations of data in the agnostic-classifier setting. We prove the existence of Borel measurable robust classifiers in each model and provide a unified perspective of the adversarial training problem, expanding the connections with optimal transport initiated by the authors in previous work and developing new connections between adversarial training in the multiclass setting and total variation regularization. As a corollary of our results, we prove the existence of Borel measurable solutions to the agnostic adversarial training problem in the binary classification setting, a result that improves results in the literature of adversarial training, where robust classifiers were only known to exist within the enlarged universal $\sigma$-algebra of the feature space.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;&#65292;&#20854;&#29702;&#35770;&#22522;&#30784;&#24378;&#22823;&#65292;&#21487;&#20197;&#22788;&#29702;&#20998;&#24067;&#28418;&#31227;&#21644;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.00070</link><description>&lt;p&gt;
&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;&#65292;&#20854;&#29702;&#35770;&#22522;&#30784;&#24378;&#22823;&#65292;&#21487;&#20197;&#22788;&#29702;&#20998;&#24067;&#28418;&#31227;&#21644;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21518;&#26657;&#20934;&#26041;&#27861;&#65292;&#31216;&#20026;&#22312;&#32447;Platt&#32553;&#25918;(OPS)&#65292;&#23427;&#23558;Platt&#32553;&#25918;&#25216;&#26415;&#19982;&#22312;&#32447;&#36923;&#36753;&#22238;&#24402;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;OPS&#22914;&#20309;&#22312;&#20998;&#24067;&#28418;&#31227;&#30340;i.i.d.&#21644;&#38750;i.i.d.&#24773;&#20917;&#19979;&#24179;&#31283;&#36866;&#24212;&#12290;&#27492;&#22806;&#65292;&#24403;&#26368;&#20339;&#30340;Platt&#32553;&#25918;&#27169;&#22411;&#26412;&#36523;&#34987;&#38169;&#35823;&#26657;&#20934;&#26102;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#26368;&#36817;&#24320;&#21457;&#30340;&#31216;&#20026;calibeating&#30340;&#25216;&#26415;&#26469;&#22686;&#24378;OPS&#65292;&#20351;&#20854;&#26356;&#21152;&#40065;&#26834;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#24471;&#21040;&#30340;OPS+calibeating&#26041;&#27861;&#23545;&#20110;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#26159;&#20445;&#35777;&#26657;&#20934;&#30340;&#12290;&#22312;&#23454;&#39564;&#19978;&#65292;&#23427;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#22343;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25152;&#26377;OPS&#24605;&#24819;&#25193;&#23637;&#21040;beta&#32553;&#25918;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.
&lt;/p&gt;</description></item><item><title>LAVA&#26159;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#26080;&#20851;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36890;&#36807;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#26469;&#23454;&#29616;&#12290;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2305.00054</link><description>&lt;p&gt;
LAVA: &#26080;&#38656;&#39044;&#23450;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
LAVA: Data Valuation without Pre-Specified Learning Algorithms. (arXiv:2305.00054v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00054
&lt;/p&gt;
&lt;p&gt;
LAVA&#26159;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#26080;&#20851;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36890;&#36807;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#26469;&#23454;&#29616;&#12290;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38382;&#39064;&#26159;&#22914;&#20309;&#20844;&#24179;&#22320;&#20998;&#37197;&#23398;&#20064;&#31639;&#27861;&#30340;&#39564;&#35777;&#24615;&#33021;&#65292;&#33268;&#20351;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#25454;&#20215;&#20540;&#20381;&#36182;&#20110;&#24213;&#23618;&#23398;&#20064;&#31639;&#27861;&#30340;&#35768;&#22810;&#35774;&#35745;&#36873;&#25321;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;LAVA&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#65292;&#20351;&#20854;&#26080;&#35270;&#19979;&#28216;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#23427;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable for many use cases of data valuation, such as setting priorities over different data sources in a data acquisition process and informing pricing mechanisms in a data marketplace. In these scenarios, data needs to be valued before the actual analysis and the choice of the learning algorithm is still undetermined then. Another side-effect of the dependence is that to assess the value of individual points, one needs to re-run the learning algorithm with and without a point, which incurs a large computation burden.  This work leapfrogs over the current limits of data valuation methods by introducing a new framework that can value training data in a way that is oblivious to the downstream learning
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#20004;&#31181;&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#20998;&#21035;&#35299;&#20915;&#20102;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#21644;&#38480;&#21046;&#29256;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#24448;&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2304.12465</link><description>&lt;p&gt;
&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#26041;&#27861;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Robust, randomized preconditioning for kernel ridge regression. (arXiv:2304.12465v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12465
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#20004;&#31181;&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#20998;&#21035;&#35299;&#20915;&#20102;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#21644;&#38480;&#21046;&#29256;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#24448;&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#29992;&#20110;&#24378;&#20581;&#22320;&#35299;&#20915;&#20855;&#26377;&#20013;&#22823;&#35268;&#27169;&#25968;&#25454;&#28857;&#65288;$10^4 \leq N \leq 10^7$&#65289;&#30340;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#65292;RPCholesky&#39044;&#22788;&#29702;&#65292;&#33021;&#22815;&#22312;&#20551;&#35774;&#26680;&#30697;&#38453;&#29305;&#24449;&#20540;&#26377;&#36275;&#22815;&#24555;&#36895;&#30340;&#22810;&#39033;&#24335;&#34928;&#20943;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;$O&#65288;N ^ 2&#65289;$&#31639;&#27861;&#25805;&#20316;&#20934;&#30830;&#22320;&#35299;&#20915;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#65292;KRILL&#39044;&#22788;&#29702;&#65292;&#20197;$O&#65288;&#65288;N + k ^ 2&#65289;k \ logk&#65289;$&#30340;&#20195;&#20215;&#65292;&#20026;KRR&#38382;&#39064;&#30340;&#38480;&#21046;&#29256;&#26412;&#25552;&#20379;&#20934;&#30830;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#29256;&#26412;&#28041;&#21450;$k \ll N$&#36873;&#25321;&#30340;&#25968;&#25454;&#20013;&#24515;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#24191;&#27867;&#30340;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#21069;&#30340;KRR&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#65292;&#20351;&#23427;&#20204;&#25104;&#20026;&#23454;&#38469;&#24212;&#29992;&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces two randomized preconditioning techniques for robustly solving kernel ridge regression (KRR) problems with a medium to large number of data points ($10^4 \leq N \leq 10^7$). The first method, RPCholesky preconditioning, is capable of accurately solving the full-data KRR problem in $O(N^2)$ arithmetic operations, assuming sufficiently rapid polynomial decay of the kernel matrix eigenvalues. The second method, KRILL preconditioning, offers an accurate solution to a restricted version of the KRR problem involving $k \ll N$ selected data centers at a cost of $O((N + k^2) k \log k)$ operations. The proposed methods solve a broad range of KRR problems and overcome the failure modes of previous KRR preconditioners, making them ideal for practical applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#26080;&#38480;&#32500;&#24230;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#27700;&#24179;&#19978;&#30340;&#31163;&#25955;&#21270;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#22810;&#32423;&#25193;&#25955;&#31639;&#27861;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#19978;&#39640;&#25928;&#22320;&#23398;&#20064;&#12290;&#23454;&#35777;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#30456;&#21516;&#25110;&#26356;&#39640;&#20998;&#36776;&#29575;&#19979;&#20135;&#29983;&#27604;&#20256;&#32479;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#29983;&#25104;&#19981;&#21516;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#24182;&#22788;&#29702;&#30697;&#24418;&#22495;&#12290;</title><link>http://arxiv.org/abs/2303.04772</link><description>&lt;p&gt;
&#22810;&#32423;&#25193;&#25955;&#65306;&#22270;&#20687;&#29983;&#25104;&#30340;&#26080;&#38480;&#32500;&#24230;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models for Image Generation. (arXiv:2303.04772v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#26080;&#38480;&#32500;&#24230;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#27700;&#24179;&#19978;&#30340;&#31163;&#25955;&#21270;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#22810;&#32423;&#25193;&#25955;&#31639;&#27861;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#19978;&#39640;&#25928;&#22320;&#23398;&#20064;&#12290;&#23454;&#35777;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#30456;&#21516;&#25110;&#26356;&#39640;&#20998;&#36776;&#29575;&#19979;&#20135;&#29983;&#27604;&#20256;&#32479;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#29983;&#25104;&#19981;&#21516;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#24182;&#22788;&#29702;&#30697;&#24418;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26159;&#36817;&#24180;&#26469;&#22270;&#20687;&#29983;&#25104;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#20043;&#19968;&#12290;&#29616;&#26377;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#36890;&#24120;&#22312;&#26377;&#38480;&#32500;&#24230;&#35774;&#32622;&#20013;&#34920;&#36848;&#65292;&#20854;&#20013;&#22270;&#20687;&#34987;&#35270;&#20026;&#20855;&#26377;&#26377;&#38480;&#23610;&#23544;&#30340;&#24352;&#37327;&#12290;&#26412;&#25991;&#22312;&#26080;&#38480;&#32500;&#24230;&#35774;&#32622;&#20013;&#24320;&#21457;&#20102;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#21363;&#25105;&#20204;&#23558;&#35757;&#32451;&#25968;&#25454;&#24314;&#27169;&#20026;&#25903;&#25745;&#22312;&#30697;&#24418;&#22495;&#19978;&#30340;&#20989;&#25968;&#12290;&#38500;&#20102;&#36861;&#27714;&#22312;&#26356;&#39640;&#20998;&#36776;&#29575;&#19979;&#29983;&#25104;&#22270;&#20687;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#21160;&#26426;&#26159;&#21019;&#24314;&#19968;&#20010;&#33391;&#22909;&#23450;&#20041;&#30340;&#26080;&#38480;&#32500;&#24230;&#23398;&#20064;&#38382;&#39064;&#65292;&#20197;&#20415;&#21487;&#20197;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#27700;&#24179;&#19978;&#19968;&#33268;&#22320;&#31163;&#25955;&#21270;&#23427;&#12290;&#25105;&#20204;&#24076;&#26395;&#33719;&#24471;&#33021;&#22815;&#27178;&#36328;&#19981;&#21516;&#20998;&#36776;&#29575;&#32423;&#21035;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#39640;&#35757;&#32451;&#36807;&#31243;&#30340;&#25928;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20811;&#26381;&#24403;&#21069;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#22312;&#26080;&#38480;&#32500;&#24230;&#35774;&#32622;&#20013;&#23384;&#22312;&#30340;&#20004;&#20010;&#32570;&#28857;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#21069;&#21521;&#36807;&#31243;&#20197;&#30830;&#20445;&#22312;&#26080;&#38480;&#32500;&#24230;&#35774;&#32622;&#20013;&#28508;&#22312;&#20998;&#24067;&#26159;&#33391;&#22909;&#23450;&#20041;&#30340;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#32423;&#25193;&#25955;&#31639;&#27861;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#19978;&#39640;&#25928;&#22320;&#23398;&#20064;&#12290;&#25105;&#20204;&#23454;&#35777;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#22810;&#32423;&#27169;&#22411;&#22312;&#30456;&#21516;&#25110;&#26356;&#39640;&#20998;&#36776;&#29575;&#19979;&#20135;&#29983;&#27604;&#20256;&#32479;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26080;&#32541;&#22320;&#29983;&#25104;&#19981;&#21516;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#24182;&#22788;&#29702;&#30697;&#24418;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based diffusion models (SBDM) have recently emerged as state-of-the-art approaches for image generation. Existing SBDMs are typically formulated in a finite-dimensional setting, where images are considered as tensors of a finite size. This papers develops SBDMs in the infinite-dimensional setting, that is, we model the training data as functions supported on a rectangular domain. Besides the quest for generating images at ever higher resolution our primary motivation is to create a well-posed infinite-dimensional learning problem so that we can discretize it consistently on multiple resolution levels. We thereby hope to obtain diffusion models that generalize across different resolution levels and improve the efficiency of the training process. We demonstrate how to overcome two shortcomings of current SBDM approaches in the infinite-dimensional setting. First, we modify the forward process to ensure that the latent distribution is well-defined in the infinite-dimensional setting
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#35889;&#23398;&#20064;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#25552;&#20379;&#20102;SHMM&#20284;&#28982;&#20272;&#35745;&#30340;&#35823;&#24046;&#28176;&#36817;&#20998;&#24067;&#12289;&#25552;&#20986;&#25237;&#24433;SHMM&#31639;&#27861;&#21487;&#20197;&#20943;&#36731;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#12289;&#24182;&#24320;&#21457;&#20102;SHMM&#21644;PSHMM&#30340;&#22312;&#32447;&#23398;&#20064;&#21464;&#20307;&#20197;&#36866;&#24212;&#28508;&#22312;&#30340;&#38750;&#24179;&#31283;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;PSHMM&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2302.07437</link><description>&lt;p&gt;
&#32553;&#23567;&#21487;&#29992;&#24615;&#24046;&#36317;&#65306;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#35889;&#23398;&#20064;&#30340;&#29702;&#35770;&#19982;&#26041;&#27861;&#23398;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Bridging the Usability Gap: Theoretical and Methodological Advances for Spectral Learning of Hidden Markov Models. (arXiv:2302.07437v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07437
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#35889;&#23398;&#20064;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#25552;&#20379;&#20102;SHMM&#20284;&#28982;&#20272;&#35745;&#30340;&#35823;&#24046;&#28176;&#36817;&#20998;&#24067;&#12289;&#25552;&#20986;&#25237;&#24433;SHMM&#31639;&#27861;&#21487;&#20197;&#20943;&#36731;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#12289;&#24182;&#24320;&#21457;&#20102;SHMM&#21644;PSHMM&#30340;&#22312;&#32447;&#23398;&#20064;&#21464;&#20307;&#20197;&#36866;&#24212;&#28508;&#22312;&#30340;&#38750;&#24179;&#31283;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;PSHMM&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Baum-Welch&#65288;B-W&#65289;&#31639;&#27861;&#26159;&#25512;&#26029;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;(HMM)&#26368;&#24191;&#27867;&#25509;&#21463;&#30340;&#26041;&#27861;&#12290; &#28982;&#32780;&#65292;&#23427;&#24456;&#23481;&#26131;&#38519;&#20837;&#23616;&#37096;&#26368;&#20248;&#65292;&#32780;&#19988;&#23545;&#20110;&#35768;&#22810;&#23454;&#26102;&#24212;&#29992;&#26469;&#35828;&#36895;&#24230;&#22826;&#24930;&#12290;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30697;&#27861;&#65288;MOM&#65289;&#30340;HMM&#30340;&#35889;&#23398;&#20064;&#65288;SHMM&#65289;&#65292;&#26088;&#22312;&#20811;&#26381;&#36825;&#20123;&#38556;&#30861;&#12290;&#23613;&#31649;&#26377;&#36825;&#26679;&#30340;&#25215;&#35834;&#65292;&#20294;SHMM&#30340;&#28176;&#36817;&#29702;&#35770;&#19968;&#30452;&#24456;&#38590;&#24471;&#21040;&#65292;&#32780;SHMM&#30340;&#38271;&#26399;&#24615;&#33021;&#21487;&#33021;&#20250;&#30001;&#20110;&#35823;&#24046;&#30340;&#26080;&#38480;&#20256;&#25773;&#32780;&#38477;&#20302;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;(1)&#25552;&#20379;&#20102;SHMM&#20284;&#28982;&#20272;&#35745;&#30340;&#36817;&#20284;&#35823;&#24046;&#30340;&#28176;&#36817;&#20998;&#24067;&#65292;(2)&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#31216;&#20026;&#25237;&#24433;SHMM&#65288;PSHMM&#65289;&#65292;&#23427;&#21487;&#20197;&#20943;&#36731;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#65292;(3)&#24320;&#21457;&#20102;SHMM&#21644;PSHMM&#30340;&#22312;&#32447;&#23398;&#20064;&#21464;&#20307;&#65292;&#20197;&#36866;&#24212;&#28508;&#22312;&#30340;&#38750;&#24179;&#31283;&#24615;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#26469;&#33258;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#30340;&#25968;&#25454;&#19978;&#27604;&#36739;&#20102;SHMM&#12289;PSHMM&#21644;B-W&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Baum-Welch (B-W) algorithm is the most widely accepted method for inferring hidden Markov models (HMM). However, it is prone to getting stuck in local optima, and can be too slow for many real-time applications. Spectral learning of HMMs (SHMM), based on the method of moments (MOM) has been proposed in the literature to overcome these obstacles. Despite its promises, asymptotic theory for SHMM has been elusive, and the long-run performance of SHMM can degrade due to unchecked propagation of error. In this paper, we (1) provide an asymptotic distribution for the approximate error of the likelihood estimated by SHMM, (2) propose a novel algorithm called projected SHMM (PSHMM) that mitigates the problem of error propagation, and (3) develop online learning variants of both SHMM and PSHMM that accommodate potential nonstationarity. We compare the performance of SHMM with PSHMM and estimation through the B-W algorithm on both simulated data and data from real world applications, and fin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#36890;&#36807;&#26410;&#30693;&#32447;&#24615;&#36716;&#25442;&#38388;&#25509;&#35266;&#23519;&#26102;&#30340;&#22240;&#26524;&#34920;&#24449;&#23398;&#20064;&#38382;&#39064;&#12290;&#20854;&#20805;&#20998;&#26465;&#20214;&#30830;&#20445;&#20102;&#24178;&#39044;&#25928;&#26524;&#21487;&#20197;&#20174;&#20998;&#25968;&#30340;&#21464;&#21270;&#20013;&#27491;&#30830;&#26816;&#27979;&#20986;&#26469;&#65292;&#24182;&#21033;&#29992;&#26368;&#23567;&#21270;&#20998;&#25968;&#20989;&#25968;&#21464;&#21270;&#30340;&#20851;&#38190;&#29305;&#24615;&#23436;&#32654;&#24674;&#22797;&#26377;&#25928;&#21464;&#25442;&#12290;</title><link>http://arxiv.org/abs/2301.08230</link><description>&lt;p&gt;
&#24102;&#24178;&#39044;&#30340;&#22522;&#20110;&#20998;&#25968;&#30340;&#22240;&#26524;&#34920;&#24449;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Score-based Causal Representation Learning with Interventions. (arXiv:2301.08230v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#36890;&#36807;&#26410;&#30693;&#32447;&#24615;&#36716;&#25442;&#38388;&#25509;&#35266;&#23519;&#26102;&#30340;&#22240;&#26524;&#34920;&#24449;&#23398;&#20064;&#38382;&#39064;&#12290;&#20854;&#20805;&#20998;&#26465;&#20214;&#30830;&#20445;&#20102;&#24178;&#39044;&#25928;&#26524;&#21487;&#20197;&#20174;&#20998;&#25968;&#30340;&#21464;&#21270;&#20013;&#27491;&#30830;&#26816;&#27979;&#20986;&#26469;&#65292;&#24182;&#21033;&#29992;&#26368;&#23567;&#21270;&#20998;&#25968;&#20989;&#25968;&#21464;&#21270;&#30340;&#20851;&#38190;&#29305;&#24615;&#23436;&#32654;&#24674;&#22797;&#26377;&#25928;&#21464;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#36890;&#36807;&#26410;&#30693;&#32447;&#24615;&#36716;&#25442;&#38388;&#25509;&#35266;&#23519;&#26102;&#30340;&#22240;&#26524;&#34920;&#24449;&#23398;&#20064;&#38382;&#39064;&#12290;&#24314;&#31435;&#20102;DAG&#37325;&#26500;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#34920;&#26126;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#22823;&#31867;&#38750;&#32447;&#24615;&#27169;&#22411;&#28385;&#36275;&#36825;&#20123;&#26465;&#20214;&#65292;&#30830;&#20445;&#20102;&#24178;&#39044;&#25928;&#26524;&#21487;&#20197;&#20174;&#20998;&#25968;&#30340;&#21464;&#21270;&#20013;&#27491;&#30830;&#26816;&#27979;&#20986;&#26469;&#12290;&#21033;&#29992;&#26368;&#23567;&#21270;&#20998;&#25968;&#20989;&#25968;&#21464;&#21270;&#30340;&#20851;&#38190;&#29305;&#24615;&#65292;&#21487;&#20197;&#23436;&#32654;&#24674;&#22797;&#26377;&#25928;&#21464;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the causal representation learning problem when the latent causal variables are observed indirectly through an unknown linear transformation. The objectives are: (i) recovering the unknown linear transformation (up to scaling) and (ii) determining the directed acyclic graph (DAG) underlying the latent variables. Sufficient conditions for DAG recovery are established, and it is shown that a large class of non-linear models in the latent space (e.g., causal mechanisms parameterized by two-layer neural networks) satisfy these conditions. These sufficient conditions ensure that the effect of an intervention can be detected correctly from changes in the score. Capitalizing on this property, recovering a valid transformation is facilitated by the following key property: any valid transformation renders latent variables' score function to necessarily have the minimal variations across different interventional environments. This property is leveraged for perfect recovery of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22312;&#22122;&#22768;&#29615;&#22659;&#19979;&#20174;&#26679;&#26412;&#20013;&#23398;&#20064;&#21333;&#32431;&#24418;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#21482;&#35201;&#20449;&#22122;&#27604;&#36739;&#39640;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26080;&#22122;&#22768;&#24773;&#20917;&#20855;&#26377;&#30456;&#21516;&#30340;&#38454;&#12290;</title><link>http://arxiv.org/abs/2209.05953</link><description>&lt;p&gt;
&#23398;&#20064;&#39640;&#32500;&#21333;&#32431;&#24418;&#22312;&#22122;&#22768;&#29615;&#22659;&#19979;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity Bounds for Learning High-dimensional Simplices in Noisy Regimes. (arXiv:2209.05953v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.05953
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22312;&#22122;&#22768;&#29615;&#22659;&#19979;&#20174;&#26679;&#26412;&#20013;&#23398;&#20064;&#21333;&#32431;&#24418;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#21482;&#35201;&#20449;&#22122;&#27604;&#36739;&#39640;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26080;&#22122;&#22768;&#24773;&#20917;&#20855;&#26377;&#30456;&#21516;&#30340;&#38454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#21547;&#26377;&#22122;&#22768;&#30340;&#26679;&#26412;&#20013;&#23398;&#20064;&#21333;&#32431;&#24418;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20551;&#35774;&#32473;&#23450;&#19968;&#20010;&#22823;&#23567;&#20026;$n$&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#20174;$\mathbb{R}^K$&#20013;&#30340;&#26410;&#30693;&#21333;&#32431;&#24418;&#19978;&#22343;&#21248;&#20998;&#24067;&#20013;&#29420;&#31435;&#21516;&#20998;&#24067;&#25277;&#26679;&#30340;&#26679;&#26412;&#65292;&#20551;&#35774;&#36825;&#20123;&#26679;&#26412;&#34987;&#19968;&#20010;&#20219;&#24847;&#24133;&#24230;&#30340;&#22810;&#20803;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#25152;&#27745;&#26579;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#31181;&#31639;&#27861;&#65292;&#20197;&#39640;&#27010;&#29575;&#36755;&#20986;&#19968;&#20010;&#19982;&#30495;&#23454;&#21333;&#32431;&#24418;&#30340;$\ell_2$&#36317;&#31163;&#26368;&#22823;&#20026;$\varepsilon$&#30340;&#21333;&#32431;&#24418;&#65288;&#23545;&#20110;&#20219;&#24847;$\varepsilon&gt;0$&#65289;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30028;&#38480;&#65292;&#38656;&#35201;&#26377; $n\ge\left(K^2/\varepsilon^2\right)e^{\Omega\left(K/\mathrm{SNR}^2\right)}$ &#20010;&#26679;&#26412;&#65292;&#20854;&#20013; $\mathrm{SNR}$ &#20195;&#34920;&#20449;&#22122;&#27604;&#12290;&#36825;&#20010;&#32467;&#26524;&#35299;&#20915;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#21482;&#35201; $\mathrm{SNR}\ge\Omega\left(K^{1/2}\right)$&#65292;&#22312;&#22122;&#22768;&#29615;&#22659;&#19979;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26080;&#22122;&#22768;&#24773;&#20917;&#20855;&#26377;&#30456;&#21516;&#30340;&#38454;&#12290;&#26412;&#25991;&#30340;&#35777;&#26126;&#26159;&#21508;&#31181;&#24037;&#20855;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we find a sample complexity bound for learning a simplex from noisy samples. Assume a dataset of size $n$ is given which includes i.i.d. samples drawn from a uniform distribution over an unknown simplex in $\mathbb{R}^K$, where samples are assumed to be corrupted by a multi-variate additive Gaussian noise of an arbitrary magnitude. We prove the existence of an algorithm that with high probability outputs a simplex having a $\ell_2$ distance of at most $\varepsilon$ from the true simplex (for any $\varepsilon&gt;0$). Also, we theoretically show that in order to achieve this bound, it is sufficient to have $n\ge\left(K^2/\varepsilon^2\right)e^{\Omega\left(K/\mathrm{SNR}^2\right)}$ samples, where $\mathrm{SNR}$ stands for the signal-to-noise ratio. This result solves an important open problem and shows as long as $\mathrm{SNR}\ge\Omega\left(K^{1/2}\right)$, the sample complexity of the noisy regime has the same order to that of the noiseless case. Our proofs are a combination 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20013;&#24515;&#21270;&#21098;&#35009;&#22312;&#38754;&#23545;&#19981;&#21516;&#24694;&#24847;&#20195;&#29702;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22810;&#24341;&#29992;&#28857;&#21098;&#35009; (MRPC) &#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;MRPC &#26694;&#26550;&#21033;&#29992;&#22810;&#20010;&#21442;&#32771;&#28857;&#26377;&#25928;&#22320;&#20013;&#21644;&#19987;&#38376;&#35774;&#35745;&#30340; Byzantine attacks&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#31867;&#22411;&#30340; Byzantine attacks &#19979;&#65292;MRPC &#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340; FL &#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2208.09894</link><description>&lt;p&gt;
&#25308;&#21344;&#24237;&#20154;&#20063;&#33021;&#20174;&#21382;&#21490;&#20013;&#23398;&#20064;&#65306;&#32852;&#37030;&#23398;&#20064;&#20013;&#24515;&#21270;&#21098;&#35009;&#30340;&#34928;&#33853;
&lt;/p&gt;
&lt;p&gt;
Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning. (arXiv:2208.09894v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.09894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20013;&#24515;&#21270;&#21098;&#35009;&#22312;&#38754;&#23545;&#19981;&#21516;&#24694;&#24847;&#20195;&#29702;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22810;&#24341;&#29992;&#28857;&#21098;&#35009; (MRPC) &#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;MRPC &#26694;&#26550;&#21033;&#29992;&#22810;&#20010;&#21442;&#32771;&#28857;&#26377;&#25928;&#22320;&#20013;&#21644;&#19987;&#38376;&#35774;&#35745;&#30340; Byzantine attacks&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#31867;&#22411;&#30340; Byzantine attacks &#19979;&#65292;MRPC &#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340; FL &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064; (FL) &#26694;&#26550;&#30001;&#20110;&#22312;&#24191;&#27867;&#30340;&#21327;&#20316;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#32780;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#20294;&#20063;&#24341;&#36215;&#20102;&#26576;&#20123;&#23433;&#20840;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#25308;&#21344;&#24237;&#25915;&#20987;&#30340;&#39118;&#38505;&#26159;&#29305;&#21035;&#20851;&#27880;&#30340;&#38382;&#39064;&#65292;&#36825;&#25351;&#30340;&#26159;&#24694;&#24847;&#23458;&#25143;&#21442;&#19982;&#23398;&#20064;&#36807;&#31243;&#30340;&#21487;&#33021;&#24615;&#12290;&#22240;&#27492;&#65292;FL &#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#30446;&#26631;&#26159;&#28040;&#38500; Byzantine attacks &#30340;&#28508;&#22312;&#24433;&#21709;&#65292;&#30830;&#20445;&#26368;&#32456;&#27169;&#22411;&#26159;&#21487;&#20449;&#30340;&#12290;&#24050;&#32463;&#35266;&#23519;&#21040;&#65292;&#23458;&#25143;&#31471;&#30340;&#27169;&#22411;/&#26356;&#26032;&#20043;&#38388;&#30340;&#26041;&#24046;&#36234;&#22823;&#65292;&#38544;&#34255; Byzantine attacks &#30340;&#31354;&#38388;&#23601;&#36234;&#22823;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#20351;&#29992;&#21160;&#37327;&#65292;&#20174;&#32780;&#20943;&#23569;&#26041;&#24046;&#65292;&#21487;&#20197;&#21066;&#24369;&#24050;&#30693; Byzantine attacks &#30340;&#21147;&#37327;&#12290;&#20013;&#24515;&#21270;&#21098;&#35009; (CC) &#26694;&#26550;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#19978;&#19968;&#27425;&#30340;&#21160;&#37327;&#39033;&#38500;&#20102;&#20943;&#23569;&#26041;&#24046;&#22806;&#65292;&#36824;&#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#21442;&#32771;&#28857;&#26356;&#22909;&#22320;&#28040;&#38500; Byzantine attacks&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#30340;&#24694;&#24847;&#20195;&#29702;&#26377;&#19981;&#21516;&#30446;&#26631;&#26102; CC &#30340;&#33030;&#24369;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#21098;&#35009;&#31639;&#27861;&#31216;&#20026;&#22810;&#24341;&#29992;&#28857;&#21098;&#35009; (MRPC)&#65292;&#20197;&#20811;&#26381;&#36825;&#31181;&#33030;&#24369;&#24615;&#12290;MRPC &#26694;&#26550;&#26377;&#25928;&#22320;&#21033;&#29992;&#22810;&#20010;&#21442;&#32771;&#28857;&#26469;&#28040;&#38500;&#19987;&#38376;&#35774;&#35745;&#20197;&#32469;&#36807; CC &#26041;&#27861;&#30340; Byzantine attacks&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#31867;&#22411;&#30340; Byzantine attacks &#19979;&#65292;MRPC &#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340; FL &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing popularity of the federated learning (FL) framework due to its success in a wide range of collaborative learning tasks also induces certain security concerns. Among many vulnerabilities, the risk of Byzantine attacks is of particular concern, which refers to the possibility of malicious clients participating in the learning process. Hence, a crucial objective in FL is to neutralize the potential impact of Byzantine attacks, and to ensure that the final model is trustable. It has been observed that the higher the variance among the clients' models/updates, the more space there is for Byzantine attacks to be hidden. As a consequence, by utilizing momentum, and thus, reducing the variance, it is possible to weaken the strength of known Byzantine attacks. The centered clipping (CC) framework has further shown that, the momentum term from the previous iteration, besides reducing the variance, can be used as a reference point to neutralize Byzantine attacks better. In this wor
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#65292;&#31034;&#20363;&#35777;&#26126;&#20854;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20855;&#26377;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2208.02814</link><description>&lt;p&gt;
&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal Risk Control. (arXiv:2208.02814v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.02814
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#65292;&#31034;&#20363;&#35777;&#26126;&#20854;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20855;&#26377;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#25512;&#24191;&#33267;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;&#35813;&#31639;&#27861;&#23558;&#20998;&#35010;&#31526;&#21512;&#24615;&#39044;&#27979;&#21450;&#20854;&#35206;&#30422;&#20445;&#35777;&#36827;&#34892;&#20102;&#27867;&#21270;&#12290;&#31867;&#20284;&#20110;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#22312;$\mathcal{O}(1/n)$&#22240;&#23376;&#20869;&#20445;&#25345;&#32039;&#23494;&#24615;&#12290;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#31034;&#20363;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#22312;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\mathcal{O}(1/n)$ factor. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#30340;&#25968;&#25454;&#19978;&#26045;&#21152;&#26356;&#22810;&#27491;&#21017;&#21270;&#20197;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#24471;&#21040;&#20102;&#22312;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#22343;&#20026;&#26368;&#20248;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2206.03353</link><description>&lt;p&gt;
&#22312;&#19981;&#31283;&#20581;&#26679;&#26412;&#19978;&#26045;&#21152;&#26356;&#22810;&#27491;&#21017;&#21270;&#20197;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving adversarial robustness by putting more regularizations on less robust samples. (arXiv:2206.03353v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#30340;&#25968;&#25454;&#19978;&#26045;&#21152;&#26356;&#22810;&#27491;&#21017;&#21270;&#20197;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#24471;&#21040;&#20102;&#22312;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#22343;&#20026;&#26368;&#20248;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#35757;&#32451;&#26159;&#25552;&#39640;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#20154;&#31867;&#35270;&#35273;&#26080;&#27861;&#23519;&#35273;&#30340;&#25968;&#25454;&#25200;&#21160;&#19979;&#65292;&#20351;&#32473;&#23450;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20135;&#29983;&#35823;&#21028;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#31639;&#27861;&#65292;&#23427;&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#24456;&#22909;&#30340;&#35777;&#26126;&#65292;&#24182;&#19988;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#30340;&#19968;&#20010;&#26032;&#30340;&#29305;&#28857;&#26159;&#65306;&#23545;&#20110;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#30340;&#25968;&#25454;&#65292;&#27604;&#20854;&#20182;&#29616;&#26377;&#30340;&#27491;&#21017;&#21270;&#31639;&#27861;&#26356;&#22810;&#22320;&#24212;&#29992;&#27491;&#21017;&#21270;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#34987;&#29702;&#35299;&#20026;&#19968;&#20010;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#30340;&#27491;&#21017;&#21270;&#31639;&#27861;&#65292;&#23427;&#26469;&#33258;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#39118;&#38505;&#19978;&#30028;&#30340;&#21160;&#26426;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21516;&#26102;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;(&#22312;&#20363;&#23376;&#19978;&#30340;&#20934;&#30830;&#24615;)&#21644;&#40065;&#26834;&#24615;(&#22312;&#23545;&#25239;&#25915;&#20987;&#19978;&#30340;&#20934;&#30830;&#24615;)&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training, which is to enhance robustness against adversarial attacks, has received much attention because it is easy to generate human-imperceptible perturbations of data to deceive a given deep neural network. In this paper, we propose a new adversarial training algorithm that is theoretically well motivated and empirically superior to other existing algorithms. A novel feature of the proposed algorithm is to apply more regularization to data vulnerable to adversarial attacks than other existing regularization algorithms do. Theoretically, we show that our algorithm can be understood as an algorithm of minimizing the regularized empirical risk motivated from a newly derived upper bound of the robust risk. Numerical experiments illustrate that our proposed algorithm improves the generalization (accuracy on examples) and robustness (accuracy on adversarial attacks) simultaneously to achieve the state-of-the-art performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;Complex-to-Real&#33609;&#22270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22797;&#21512;&#23454;&#24352;&#37327;&#20056;&#31215;&#65292;&#21462;&#24471;&#20102;&#22312;&#22810;&#39033;&#24335;&#26680;&#19978;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2202.02031</link><description>&lt;p&gt;
&#22797;&#21512;&#23454;&#24352;&#37327;&#20056;&#31215;&#30340;&#33609;&#22270;&#21450;&#20854;&#22312;&#22810;&#39033;&#24335;&#26680;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Complex-to-Real Sketches for Tensor Products with Applications to the Polynomial Kernel. (arXiv:2202.02031v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.02031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;Complex-to-Real&#33609;&#22270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22797;&#21512;&#23454;&#24352;&#37327;&#20056;&#31215;&#65292;&#21462;&#24471;&#20102;&#22312;&#22810;&#39033;&#24335;&#26680;&#19978;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;$p$&#20010;&#21521;&#37327;&#30340;&#24352;&#37327;&#31215;&#30340;&#38543;&#26426;&#33609;&#22270;&#36981;&#24490;&#32479;&#35745;&#25928;&#29575;&#21644;&#35745;&#31639;&#21152;&#36895;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#36890;&#24120;&#20351;&#29992;&#30340;&#26041;&#27861;&#36991;&#20813;&#26174;&#24335;&#35745;&#31639;&#39640;&#32500;&#24352;&#37327;&#31215;&#65292;&#23548;&#33268;&#22312;&#23884;&#20837;&#32500;&#24230;&#19978;&#20855;&#26377;&#20122;&#26368;&#20248;&#30340;$\mathcal{O}(3^p)$&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;Complex-to-Real (CtR)&#20462;&#25913;&#26082;&#26377;&#30340;&#33609;&#22270;&#65292;&#36890;&#36807;&#29992;&#22797;&#25968;&#26367;&#25442;&#23454;&#25968;&#38543;&#26426;&#25237;&#24433;&#65292;&#22312;&#23884;&#20837;&#32500;&#24230;&#19978;&#21482;&#38656;&#35201;&#36739;&#20302;&#30340;$\mathcal{O}(2^p)$&#22240;&#23376;&#12290;&#25105;&#20204;&#33609;&#22270;&#30340;&#36755;&#20986;&#26159;&#23454;&#20540;&#30340;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#30340;&#19979;&#28216;&#29992;&#36884;&#21464;&#24471;&#31616;&#21333;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#33609;&#22270;&#24212;&#29992;&#20110;$p$&#20493;&#33258;&#24352;&#37327;&#36755;&#20837;&#65292;&#36825;&#20123;&#36755;&#20837;&#23545;&#24212;&#20110;&#22810;&#39033;&#24335;&#20869;&#26680;&#30340;&#29305;&#24449;&#26144;&#23556;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#25991;&#29486;&#20013;&#20854;&#20182;&#38543;&#26426;&#36924;&#36817;&#30456;&#27604;&#65292;&#22312;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#26041;&#38754;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized sketches of a tensor product of $p$ vectors follow a tradeoff between statistical efficiency and computational acceleration. Commonly used approaches avoid computing the high-dimensional tensor product explicitly, resulting in a suboptimal dependence of $\mathcal{O}(3^p)$ in the embedding dimension. We propose a simple Complex-to-Real (CtR) modification of well-known sketches that replaces real random projections by complex ones, incurring a lower $\mathcal{O}(2^p)$ factor in the embedding dimension. The output of our sketches is real-valued, which renders their downstream use straightforward. In particular, we apply our sketches to $p$-fold self-tensored inputs corresponding to the feature maps of the polynomial kernel. We show that our method achieves state-of-the-art performance in terms of accuracy and speed compared to other randomized approximations from the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#38754;&#21521;&#29289;&#32852;&#32593;&#30340;&#20998;&#24067;&#24335;&#21151;&#33021;&#21387;&#32553;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#37319;&#29992;&#20102;&#33021;&#22815;&#20219;&#24847;&#35745;&#31639;IoT&#25152;&#38656;&#20989;&#25968;&#21387;&#32553;&#20219;&#21153;&#30340;Kolmogorov-Arnold&#34920;&#31034;&#23450;&#29702;&#65292;&#35299;&#20915;&#20102;&#22522;&#20110;&#20113;&#30340;&#26041;&#27861;&#22312;&#20256;&#36755;&#25968;&#25454;&#26102;&#32473;&#32593;&#32476;&#36164;&#28304;&#24102;&#26469;&#30340;&#21387;&#21147;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2201.09483</link><description>&lt;p&gt;
&#19968;&#31181;&#38754;&#21521;&#29289;&#32852;&#32593;&#30340;&#20998;&#24067;&#24335;&#21151;&#33021;&#21387;&#32553;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Machine Learning Framework for Distributed Functional Compression over Wireless Channels in IoT. (arXiv:2201.09483v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.09483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#38754;&#21521;&#29289;&#32852;&#32593;&#30340;&#20998;&#24067;&#24335;&#21151;&#33021;&#21387;&#32553;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#37319;&#29992;&#20102;&#33021;&#22815;&#20219;&#24847;&#35745;&#31639;IoT&#25152;&#38656;&#20989;&#25968;&#21387;&#32553;&#20219;&#21153;&#30340;Kolmogorov-Arnold&#34920;&#31034;&#23450;&#29702;&#65292;&#35299;&#20915;&#20102;&#22522;&#20110;&#20113;&#30340;&#26041;&#27861;&#22312;&#20256;&#36755;&#25968;&#25454;&#26102;&#32473;&#32593;&#32476;&#36164;&#28304;&#24102;&#26469;&#30340;&#21387;&#21147;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#32852;&#32593;&#35774;&#22791;&#20135;&#29983;&#30340;&#28023;&#37327;&#25968;&#25454;&#21644;&#26368;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23558;&#20849;&#21516;&#38761;&#26032;&#29289;&#29702;&#31995;&#32479;&#12290;&#22312;&#35768;&#22810;&#19981;&#21516;&#30340;&#39046;&#22495;&#20013;&#65292;&#20174;&#33258;&#21160;&#39550;&#39542;&#21040;&#22686;&#24378;&#29616;&#23454;&#65292;&#20998;&#24067;&#24335;&#29289;&#32852;&#32593;&#35774;&#22791;&#35745;&#31639;&#29305;&#23450;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#32780;&#36825;&#20123;&#30446;&#26631;&#20989;&#25968;&#24182;&#19981;&#20687;&#38556;&#30861;&#29289;&#26816;&#27979;&#12289;&#29289;&#20307;&#35782;&#21035;&#31561;&#20855;&#26377;&#31616;&#21333;&#24418;&#24335;&#12290;&#20256;&#32479;&#30340;&#22522;&#20110;&#20113;&#30340;&#26041;&#27861;&#19987;&#27880;&#20110;&#23558;&#25968;&#25454;&#20256;&#36755;&#21040;&#20013;&#24515;&#20301;&#32622;&#36827;&#34892;&#35757;&#32451;&#25110;&#25512;&#29702;&#65292;&#36825;&#32473;&#32593;&#32476;&#36164;&#28304;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#21387;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#30446;&#21069;&#20026;&#27490;&#25105;&#20204;&#25152;&#30693;&#36947;&#30340;&#31532;&#19968;&#20010;&#38754;&#21521;&#29289;&#32852;&#32593;&#30340;&#20998;&#24067;&#24335;&#21151;&#33021;&#21387;&#32553;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#39640;&#26031;&#22810;&#36335;&#35775;&#38382;&#20449;&#36947;&#65288;GMAC&#65289;&#21644;&#27491;&#20132;AWGN&#20449;&#36947;&#19978;&#36827;&#34892;&#12290;&#30001;&#20110;Kolmogorov-Arnold&#34920;&#31034;&#23450;&#29702;&#65292;&#25105;&#20204;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#21487;&#20197;&#36890;&#36807;&#35774;&#35745;&#20026;IoT&#30340;&#25152;&#38656;&#20989;&#25968;&#21387;&#32553;&#20219;&#21153;&#35745;&#31639;&#20219;&#24847;&#20219;&#24847;&#20989;&#25968;&#12290;&#37325;&#35201;&#30340;&#26159;&#21407;&#22987;&#24863;&#23448;&#25968;&#25454;&#27704;&#36828;&#19981;&#20250;&#20256;&#36755;&#21040;&#20013;&#24515;&#33410;&#28857;&#36827;&#34892;&#35757;&#32451;&#25110;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
IoT devices generating enormous data and state-of-the-art machine learning techniques together will revolutionize cyber-physical systems. In many diverse fields, from autonomous driving to augmented reality, distributed IoT devices compute specific target functions without simple forms like obstacle detection, object recognition, etc. Traditional cloud-based methods that focus on transferring data to a central location either for training or inference place enormous strain on network resources. To address this, we develop, to the best of our knowledge, the first machine learning framework for distributed functional compression over both the Gaussian Multiple Access Channel (GMAC) and orthogonal AWGN channels. Due to the Kolmogorov-Arnold representation theorem, our machine learning framework can, by design, compute any arbitrary function for the desired functional compression task in IoT. Importantly the raw sensory data are never transferred to a central node for training or inference
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#31232;&#30095;&#23637;&#24320;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#20351;&#24471;&#27169;&#22411;&#26356;&#21152;&#31232;&#30095;&#12290;</title><link>http://arxiv.org/abs/2112.05888</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#30340;&#31232;&#30095;&#23637;&#24320;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Sparse Expansion For Deep Gaussian Processes. (arXiv:2112.05888v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.05888
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#31232;&#30095;&#23637;&#24320;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#20351;&#24471;&#27169;&#22411;&#26356;&#21152;&#31232;&#30095;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#22797;&#26434;&#20998;&#24067;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#37319;&#29992;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65288;DGP&#65289;&#20316;&#20026;&#32479;&#35745;&#26367;&#20195;&#21697;&#12290;&#20256;&#32479;&#30340;DGP&#27169;&#22411;&#25512;&#26029;&#26041;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#24456;&#39640;&#65292;&#22240;&#20026;&#38656;&#35201;&#20351;&#29992;&#26680;&#30697;&#38453;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#35757;&#32451;&#21644;&#25512;&#26029;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19968;&#31995;&#21015;&#39640;&#26031;&#36807;&#31243;&#65288;TMGP&#65289;&#30340;&#20934;&#30830;&#25512;&#26029;&#21644;&#39640;&#25928;&#35757;&#32451;&#26041;&#26696;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;&#20998;&#23618;&#23637;&#24320;&#30340;TMGP&#35825;&#23548;&#36817;&#20284;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#23558;&#22810;&#20010;TMGP&#30340;&#20998;&#23618;&#23637;&#24320;&#32452;&#21512;&#25104;&#19968;&#31181;&#31216;&#20026;&#28145;&#24230;TMGP&#65288;DTMGP&#65289;&#30340;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#20197;&#19979;&#29305;&#24615;&#65306;&#65288;1&#65289;&#27599;&#20010;&#28608;&#27963;&#20989;&#25968;&#30340;&#36755;&#20986;&#37117;&#26159;&#30830;&#23450;&#24615;&#30340;&#65292;&#32780;&#26435;&#37325;&#26159;&#20174;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#20013;&#29420;&#31435;&#36873;&#25321;&#30340;&#65307;&#65288;2&#65289;&#22312;&#35757;&#32451;&#25110;&#39044;&#27979;&#20013;&#65292;&#21482;&#26377;polylog&#65288;M&#65289;&#65288;M&#20010;&#20013;&#30340;&#19968;&#37096;&#20998;&#65289;&#20010;&#28608;&#27963;&#20989;&#25968;&#20855;&#26377;&#38750;&#38646;&#36755;&#20986;&#65292;&#36825;&#20351;&#24471;&#27169;&#22411;&#21464;&#24471;&#26356;&#21152;&#31232;&#30095;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we use Deep Gaussian Processes (DGPs) as statistical surrogates for stochastic processes with complex distributions. Conventional inferential methods for DGP models can suffer from high computational complexity as they require large-scale operations with kernel matrices for training and inference. In this work, we propose an efficient scheme for accurate inference and efficient training based on a range of Gaussian Processes, called the Tensor Markov Gaussian Processes (TMGP). We construct an induced approximation of TMGP referred to as the hierarchical expansion. Next, we develop a deep TMGP (DTMGP) model as the composition of multiple hierarchical expansion of TMGPs. The proposed DTMGP model has the following properties: (1) the outputs of each activation function are deterministic while the weights are chosen independently from standard Gaussian distribution; (2) in training or prediction, only polylog(M) (out of M) activation functions have non-zero outputs, which sig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35268;&#27169;&#19979;&#22914;&#20309;&#25915;&#20987;&#21644;&#38450;&#24481;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#25552;&#20986;&#20102;&#31232;&#30095;&#24863;&#30693;&#30340;&#19968;&#38454;&#20248;&#21270;&#25915;&#20987;&#21644;&#40065;&#26834;&#24615;&#32858;&#21512;&#20989;&#25968;Soft Median&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;GNNs&#30340;&#21487;&#38752;&#24615;&#21644;&#25915;&#20987;&#21147;&#12290;</title><link>http://arxiv.org/abs/2110.14038</link><description>&lt;p&gt;
&#35268;&#27169;&#19979;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Robustness of Graph Neural Networks at Scale. (arXiv:2110.14038v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.14038
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35268;&#27169;&#19979;&#22914;&#20309;&#25915;&#20987;&#21644;&#38450;&#24481;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#25552;&#20986;&#20102;&#31232;&#30095;&#24863;&#30693;&#30340;&#19968;&#38454;&#20248;&#21270;&#25915;&#20987;&#21644;&#40065;&#26834;&#24615;&#32858;&#21512;&#20989;&#25968;Soft Median&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;GNNs&#30340;&#21487;&#38752;&#24615;&#21644;&#25915;&#20987;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30001;&#20110;&#20854;&#24191;&#27867;&#30340;&#24212;&#29992;&#21644;&#21463;&#27426;&#36814;&#31243;&#24230;&#32780;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#38024;&#23545;&#23545;&#25239;&#25915;&#20987;&#30340;&#29616;&#26377;&#30740;&#31350;&#21482;&#20381;&#36182;&#20110;&#30456;&#23545;&#36739;&#23567;&#30340;&#22270;&#24418;&#12290;&#26412;&#25991;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#35268;&#27169;&#19979;&#25915;&#20987;&#21644;&#38450;&#24481;GNNs&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31232;&#30095;&#24863;&#30693;&#30340;&#19968;&#38454;&#20248;&#21270;&#25915;&#20987;&#65292;&#23613;&#31649;&#20248;&#21270;&#21442;&#25968;&#25968;&#37327;&#19982;&#33410;&#28857;&#25968;&#37327;&#20108;&#27425;&#20851;&#32852;&#65292;&#20294;&#20173;&#20445;&#25345;&#39640;&#25928;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#21457;&#29616;&#20844;&#20849;&#20195;&#29702;&#25439;&#22833;&#19981;&#36866;&#21512;&#29992;&#20110;&#20840;&#23616;&#25915;&#20987;GNNs&#65292;&#32780;&#25105;&#20204;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#23558;&#25915;&#20987;&#21147;&#32763;&#20493;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#25552;&#39640;GNNs&#30340;&#21487;&#38752;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#40065;&#26834;&#24615;&#32858;&#21512;&#20989;&#25968;&#65292;Soft Median&#65292;&#24471;&#21040;&#20102;&#22312;&#25152;&#26377;&#35268;&#27169;&#19979;&#30340;&#26377;&#25928;&#38450;&#24481;&#12290;&#25105;&#20204;&#20197;&#26631;&#20934;GNNs&#20026;&#22522;&#30784;&#65292;&#23545;&#27604;&#20197;&#21069;&#30340;&#30740;&#31350;&#65292;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#25915;&#20987;&#21644;&#38450;&#24481;&#26041;&#27861;&#22312;100&#20493;&#20197;&#19978;&#30340;&#22270;&#24418;&#19978;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#29978;&#33267;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;&#25216;&#26415;&#25193;&#23637;&#21040;&#21487;&#25193;&#23637;&#30340;GNN&#65292;&#23558;&#35268;&#27169;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are increasingly important given their popularity and the diversity of applications. Yet, existing studies of their vulnerability to adversarial attacks rely on relatively small graphs. We address this gap and study how to attack and defend GNNs at scale. We propose two sparsity-aware first-order optimization attacks that maintain an efficient representation despite optimizing over a number of parameters which is quadratic in the number of nodes. We show that common surrogate losses are not well-suited for global attacks on GNNs. Our alternatives can double the attack strength. Moreover, to improve GNNs' reliability we design a robust aggregation function, Soft Median, resulting in an effective defense at all scales. We evaluate our attacks and defense with standard GNNs on graphs more than 100 times larger compared to previous work. We even scale one order of magnitude further by extending our techniques to a scalable GNN.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21508;&#31181;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#21518;&#19968;&#20010;&#38544;&#34255;&#23618;&#20013;&#30340;&#34920;&#31034;&#65292;&#21457;&#29616;&#22914;&#26524;&#26368;&#21518;&#19968;&#20010;&#38544;&#34255;&#34920;&#31034;&#36275;&#22815;&#23485;&#65292;&#21017;&#20854;&#31070;&#32463;&#20803;&#20542;&#21521;&#20110;&#20998;&#25104;&#25658;&#24102;&#30456;&#21516;&#20449;&#24687;&#30340;&#32452;&#65292;&#32780;&#20887;&#20313;&#34920;&#31034;&#26377;&#21161;&#20110;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2106.03485</link><description>&lt;p&gt;
&#20887;&#20313;&#34920;&#31034;&#23545;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#26377;&#24110;&#21161;
&lt;/p&gt;
&lt;p&gt;
Redundant representations help generalization in wide neural networks. (arXiv:2106.03485v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03485
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21508;&#31181;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#21518;&#19968;&#20010;&#38544;&#34255;&#23618;&#20013;&#30340;&#34920;&#31034;&#65292;&#21457;&#29616;&#22914;&#26524;&#26368;&#21518;&#19968;&#20010;&#38544;&#34255;&#34920;&#31034;&#36275;&#22815;&#23485;&#65292;&#21017;&#20854;&#31070;&#32463;&#20803;&#20542;&#21521;&#20110;&#20998;&#25104;&#25658;&#24102;&#30456;&#21516;&#20449;&#24687;&#30340;&#32452;&#65292;&#32780;&#20887;&#20313;&#34920;&#31034;&#26377;&#21161;&#20110;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#25171;&#30772;&#20102;&#32463;&#20856;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#65306;&#20026;DNN&#28155;&#21152;&#21442;&#25968;&#20197;&#25554;&#20540;&#20854;&#35757;&#32451;&#25968;&#25454;&#36890;&#24120;&#20250;&#25913;&#21892;&#20854;&#27867;&#21270;&#24615;&#33021;&#12290;&#35299;&#37322;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#8220;&#33391;&#24615;&#36807;&#25311;&#21512;&#8221;&#30340;&#26426;&#21046;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21508;&#31181;&#26368;&#20808;&#36827;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#21518;&#19968;&#20010;&#38544;&#34255;&#23618;&#34920;&#31034;&#65292;&#24182;&#21457;&#29616;&#22914;&#26524;&#26368;&#21518;&#19968;&#20010;&#38544;&#34255;&#34920;&#31034;&#36275;&#22815;&#23485;&#65292;&#21017;&#20854;&#31070;&#32463;&#20803;&#20542;&#21521;&#20110;&#20998;&#25104;&#25658;&#24102;&#30456;&#21516;&#20449;&#24687;&#30340;&#32452;&#65292;&#20165;&#30001;&#32479;&#35745;&#29420;&#31435;&#22122;&#22768;&#21306;&#20998;&#24444;&#27492;&#12290;&#36825;&#31181;&#32452;&#30340;&#25968;&#37327;&#38543;&#23618;&#30340;&#23485;&#24230;&#21576;&#32447;&#24615;&#22686;&#21152;&#65292;&#20294;&#20165;&#22312;&#23485;&#24230;&#39640;&#20110;&#20020;&#30028;&#20540;&#26102;&#25165;&#20250;&#22686;&#21152;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20887;&#20313;&#31070;&#32463;&#20803;&#20165;&#22312;&#35757;&#32451;&#36807;&#31243;&#36798;&#21040;&#25554;&#20540;&#19988;&#35757;&#32451;&#35823;&#24046;&#20026;&#38646;&#26102;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) defy the classical bias-variance trade-off: adding parameters to a DNN that interpolates its training data will typically improve its generalization performance. Explaining the mechanism behind this ``benign overfitting'' in deep networks remains an outstanding challenge. Here, we study the last hidden layer representations of various state-of-the-art convolutional neural networks and find that if the last hidden representation is wide enough, its neurons tend to split into groups that carry identical information, and differ from each other only by statistically independent noise. The number of such groups increases linearly with the width of the layer, but only if the width is above a critical value. We show that redundant neurons appear only when the training process reaches interpolation and the training error is zero.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#22810;&#33218;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#21452;&#37325;&#31283;&#20581;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;DR Thompson Sampling&#65289;&#65292;&#36890;&#36807;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#65292;&#35299;&#20915;&#20102;&#36807;&#21435;&#30340;&#19978;&#19979;&#25991;&#21644;&#22870;&#21169;&#23545;&#36873;&#25321;&#20381;&#36182;&#24615;&#23548;&#33268;&#30340;&#25439;&#22833;&#20998;&#35299;&#22797;&#26434;&#31561;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31616;&#21270;&#19988;&#25913;&#36827;&#30340;&#25439;&#22833;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2102.01229</link><description>&lt;p&gt;
&#32447;&#24615;&#22238;&#25253;&#30340;&#21452;&#37325;&#31283;&#20581;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Doubly robust Thompson sampling for linear payoffs. (arXiv:2102.01229v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.01229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#22810;&#33218;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#21452;&#37325;&#31283;&#20581;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;DR Thompson Sampling&#65289;&#65292;&#36890;&#36807;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#65292;&#35299;&#20915;&#20102;&#36807;&#21435;&#30340;&#19978;&#19979;&#25991;&#21644;&#22870;&#21169;&#23545;&#36873;&#25321;&#20381;&#36182;&#24615;&#23548;&#33268;&#30340;&#25439;&#22833;&#20998;&#35299;&#22797;&#26434;&#31561;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31616;&#21270;&#19988;&#25913;&#36827;&#30340;&#25439;&#22833;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27748;&#26222;&#26862;&#25277;&#26679;&#22312;&#22810;&#33218;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#38754;&#20020;&#19968;&#20123;&#25361;&#25112;&#65292;&#22914;&#20309;&#26681;&#25454;&#36807;&#21435;&#30340;&#19978;&#19979;&#25991;&#21644;&#22870;&#21169;&#23545;&#36827;&#34892;&#36873;&#25321;&#30340;&#20381;&#36182;&#24615;&#20351;&#24471;&#21518;&#24724;&#20998;&#26512;&#30340;&#22797;&#26434;&#24615;&#22686;&#21152;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#37325;&#31283;&#20581;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;DR Thompson Sampling&#65289;&#30340;&#26032;&#22411;&#22810;&#33218;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#65292;&#37319;&#29992;&#22312;&#32570;&#22833;&#25968;&#25454;&#39046;&#22495;&#20013;&#20351;&#29992;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#29992;&#20110;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;LinTS&#65289;&#12290;&#21452;&#37325;&#31283;&#20581;&#27748;&#26222;&#26862;&#25277;&#26679;&#35753;&#25439;&#22833;&#20998;&#35299;&#26356;&#21152;&#31616;&#21333;&#65292;&#20174;&#32780;&#20351;&#24471;&#25913;&#36827;&#21518;&#30340;&#25439;&#22833;&#30028;&#38480;&#38477;&#21040;&#20102; $\tilde{O}(\phi^{-2}\sqrt{T})$&#65292;&#20854;&#20013; $\phi^2$ &#26159;&#19978;&#19979;&#25991;&#21327;&#26041;&#24046;&#30697;&#38453;&#20013;&#30340;&#26368;&#23567;&#29305;&#24449;&#20540;&#12290;&#36825;&#26159; \texttt{LinTS} &#31532;&#19968;&#20010;&#19981;&#22522;&#20110;&#19978;&#19979;&#25991;&#32500;&#24230; $d$&#65292;&#32780;&#26159;&#20351;&#29992; $\phi^2$ &#30340;&#25439;&#22833;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
A challenging aspect of the bandit problem is that a stochastic reward is observed only for the chosen arm and the rewards of other arms remain missing. The dependence of the arm choice on the past context and reward pairs compounds the complexity of regret analysis. We propose a novel multi-armed contextual bandit algorithm called Doubly Robust (DR) Thompson Sampling employing the doubly-robust estimator used in missing data literature to Thompson Sampling with contexts (\texttt{LinTS}). Different from previous works relying on missing data techniques (\citet{dimakopoulou2019balanced}, \citet{kim2019doubly}), the proposed algorithm is designed to allow a novel additive regret decomposition leading to an improved regret bound with the order of $\tilde{O}(\phi^{-2}\sqrt{T})$, where $\phi^2$ is the minimum eigenvalue of the covariance matrix of contexts. This is the first regret bound of \texttt{LinTS} using $\phi^2$ without the dimension of the context, $d$. Applying the relationship be
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25972;&#25968;&#35268;&#21010;&#26041;&#27861;&#21644;&#36830;&#32493;&#26494;&#24347;&#31639;&#27861;&#26469;&#35299;&#20915;&#26368;&#22823;&#29109;&#37319;&#26679;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#25928;&#29575;&#26356;&#39640;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#24050;&#26377;&#30340;&#36817;&#20284;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#23616;&#37096;&#25628;&#32034;&#31639;&#27861;&#30340;&#31532;&#19968;&#20010;&#36817;&#20284;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2001.08537</link><description>&lt;p&gt;
&#26368;&#22823;&#29109;&#37319;&#26679;&#38382;&#39064;&#30340;&#26368;&#20339;&#20027;&#23376;&#30697;&#38453;&#36873;&#25321;&#65306;&#21487;&#25193;&#23637;&#31639;&#27861;&#21644;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Best Principal Submatrix Selection for the Maximum Entropy Sampling Problem: Scalable Algorithms and Performance Guarantees. (arXiv:2001.08537v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2001.08537
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25972;&#25968;&#35268;&#21010;&#26041;&#27861;&#21644;&#36830;&#32493;&#26494;&#24347;&#31639;&#27861;&#26469;&#35299;&#20915;&#26368;&#22823;&#29109;&#37319;&#26679;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#25928;&#29575;&#26356;&#39640;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#24050;&#26377;&#30340;&#36817;&#20284;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#23616;&#37096;&#25628;&#32034;&#31639;&#27861;&#30340;&#31532;&#19968;&#20010;&#36817;&#20284;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#32463;&#20856;&#30340;&#26368;&#22823;&#29109;&#37319;&#26679;&#38382;&#39064;&#65288;MESP&#65289;&#65292;&#23427;&#26088;&#22312;&#20174;&#21327;&#26041;&#24046;&#30697;&#38453;&#20013;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#20027;&#23376;&#30697;&#38453;&#12290;&#36890;&#36807;&#30740;&#31350;&#20854;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#21644;&#21407;&#22987;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;MESP&#25972;&#25968;&#35268;&#21010;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#36830;&#32493;&#26494;&#24347;&#21487;&#24471;&#36817;&#20284;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#35828;&#26126;&#20854;&#22312;&#36817;&#20284;&#30028;&#26041;&#38754;&#20248;&#20110;&#24050;&#26377;&#25991;&#29486;&#20013;&#30340;&#26368;&#20339;&#30028;&#38480;&#12290;&#36890;&#36807;&#23545;&#22855;&#24322;&#30697;&#38453;&#24320;&#21457;&#26032;&#30340;&#25968;&#23398;&#24037;&#20855;&#21644;&#20998;&#26512;&#25152;&#25552;&#20986;&#30340;&#20984;&#25972;&#25968;&#35268;&#21010;&#30340;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;&#23616;&#37096;&#25628;&#32034;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#39318;&#20010;&#36817;&#20284;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies a classic maximum entropy sampling problem (MESP), which aims to select the most informative principal submatrix of a prespecified size from a covariance matrix. MESP has been widely applied to many areas, including healthcare, power system, manufacturing and data science. By investigating its Lagrangian dual and primal characterization, we derive a novel convex integer program for MESP and show that its continuous relaxation yields a near-optimal solution. The results motivate us to study an efficient sampling algorithm and develop its approximation bound for MESP, which improves the best-known bound in literature. We then provide an efficient deterministic implementation of the sampling algorithm with the same approximation bound. By developing new mathematical tools for the singular matrices and analyzing the Lagrangian dual of the proposed convex integer program, we investigate the widely-used local search algorithm and prove its first-known approximation bound f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;IMAE&#27169;&#22411;&#29992;&#20110;&#30072;&#24418;&#35757;&#32451;&#25968;&#25454;&#30340;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;&#65292;&#36890;&#36807;&#23454;&#36341;&#35777;&#23454;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#22312;&#22788;&#29702;&#31034;&#20363;&#26102;&#23384;&#22312;&#27424;&#25311;&#21512;&#38382;&#39064;&#65292;&#21033;&#29992;&#21152;&#26435;&#26041;&#24046;&#35843;&#25972;&#25552;&#39640;&#20102;&#25311;&#21512;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/1903.12141</link><description>&lt;p&gt;
IMAE&#29992;&#20110;&#22122;&#22768;&#40065;&#26834;&#23398;&#20064;&#65306;&#32477;&#23545;&#20540;&#35823;&#24046;&#19981;&#24179;&#31561;&#23545;&#24453;&#31034;&#20363;&#65292;&#26799;&#24230;&#22823;&#23567;&#30340;&#26041;&#24046;&#24456;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters. (arXiv:1903.12141v10 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1903.12141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;IMAE&#27169;&#22411;&#29992;&#20110;&#30072;&#24418;&#35757;&#32451;&#25968;&#25454;&#30340;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;&#65292;&#36890;&#36807;&#23454;&#36341;&#35777;&#23454;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#22312;&#22788;&#29702;&#31034;&#20363;&#26102;&#23384;&#22312;&#27424;&#25311;&#21512;&#38382;&#39064;&#65292;&#21033;&#29992;&#21152;&#26435;&#26041;&#24046;&#35843;&#25972;&#25552;&#39640;&#20102;&#25311;&#21512;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#31034;&#20363;&#21152;&#26435;&#35282;&#24230;&#65292;&#21363;&#19982;&#23545;&#25968;&#30340;&#26799;&#24230;&#22823;&#23567;&#26469;&#30475;&#24453;&#30072;&#24418;&#35757;&#32451;&#25968;&#25454;&#30340;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;&#12290;&#25105;&#20204;&#26377;&#20004;&#20010;&#20851;&#38190;&#21457;&#29616;&#65306;&#65288;1&#65289;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#19981;&#24179;&#31561;&#22320;&#22788;&#29702;&#31034;&#20363;&#12290;&#25105;&#20204;&#38024;&#23545;MAE&#36827;&#34892;&#20102;&#26032;&#30340;&#35266;&#23519;&#21644;&#28145;&#20837;&#20998;&#26512;&#65292;&#29702;&#35770;&#35777;&#26126;&#20854;&#40065;&#26834;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20854;&#22312;&#23454;&#36341;&#20013;&#30340;&#27424;&#25311;&#21512;&#38382;&#39064;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;MAE&#30340;&#40065;&#26834;&#24615;&#26159;&#36890;&#36807;&#24378;&#35843;&#19981;&#30830;&#23450;&#31034;&#20363;&#32780;&#19981;&#26159;&#20687;&#21069;&#20154;&#30740;&#31350;&#20013;&#25152;&#22768;&#31216;&#30340;&#37027;&#26679;&#23545;&#24453;&#35757;&#32451;&#26679;&#26412;&#26469;&#23454;&#29616;&#30340;&#12290;&#65288;2&#65289;&#26799;&#24230;&#22823;&#23567;&#30340;&#26041;&#24046;&#24456;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#32780;&#31616;&#21333;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#22686;&#24378;MAE&#30340;&#25311;&#21512;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#40065;&#26834;&#24615;&#12290;&#22312;&#19981;&#25913;&#21464;MAE&#30340;&#25972;&#20307;&#21152;&#26435;&#26041;&#26696;&#65288;&#21363;&#21738;&#20123;&#31034;&#20363;&#33719;&#24471;&#26356;&#39640;&#30340;&#26435;&#37325;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20165;&#36890;&#36807;&#38750;&#32447;&#24615;&#22320;&#25913;&#21464;&#20854;&#21152;&#26435;&#26041;&#24046;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study robust deep learning against abnormal training data from the perspective of example weighting built in empirical loss functions, i.e., gradient magnitude with respect to logits, an angle that is not thoroughly studied so far. Consequently, we have two key findings: (1) Mean Absolute Error (MAE) Does Not Treat Examples Equally. We present new observations and insightful analysis about MAE, which is theoretically proved to be noise-robust. First, we reveal its underfitting problem in practice. Second, we analyse that MAE's noise-robustness is from emphasising on uncertain examples instead of treating training samples equally, as claimed in prior work. (2) The Variance of Gradient Magnitude Matters. We propose an effective and simple solution to enhance MAE's fitting ability while preserving its noise-robustness. Without changing MAE's overall weighting scheme, i.e., what examples get higher weights, we simply change its weighting variance non-linearly so that the i
&lt;/p&gt;</description></item></channel></rss>