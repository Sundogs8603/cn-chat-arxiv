<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;&#65292;&#21487;&#20197;&#21450;&#26102;&#24536;&#35760;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01401</link><description>&lt;p&gt;
&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#22312;&#35268;&#27169;&#19978;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Machine Unlearning at Scale via Lipschitz Regularization
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01401
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;&#65292;&#21487;&#20197;&#21450;&#26102;&#24536;&#35760;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36981;&#23432;&#20154;&#24037;&#26234;&#33021;&#21644;&#25968;&#25454;&#35268;&#23450;&#65292;&#20174;&#35757;&#32451;&#24471;&#21040;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#36951;&#24536;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#30340;&#38656;&#27714;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#36951;&#24536;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#21450;&#26102;&#24536;&#35760;&#24517;&#35201;&#30340;&#25968;&#25454;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#38646;&#26679;&#26412;&#36951;&#24536;&#30340;&#22330;&#26223;&#65292;&#21363;&#21482;&#26377;&#19968;&#20010;&#32463;&#36807;&#35757;&#32451;&#30340;&#27169;&#22411;&#21644;&#35201;&#36951;&#24536;&#30340;&#25968;&#25454;&#65292;&#36951;&#24536;&#31639;&#27861;&#24517;&#39035;&#33021;&#22815;&#31227;&#38500;&#25968;&#25454;&#12290;&#26681;&#25454;&#36825;&#26679;&#23450;&#20041;&#65292;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26159;&#19981;&#22815;&#30340;&#12290;&#22522;&#20110;Lipschitz&#36830;&#32493;&#24615;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26679;&#26412;&#25200;&#21160;&#30340;&#36755;&#20986;&#36827;&#34892;&#24179;&#28369;&#22788;&#29702;&#26469;&#35825;&#23548;&#36951;&#24536;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#24179;&#28369;&#24615;&#25104;&#21151;&#22320;&#23454;&#29616;&#20102;&#36951;&#24536;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#24635;&#20307;&#27169;&#22411;&#24615;&#33021;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#21253;&#25324;&#19968;&#31995;&#21015;&#24403;&#20195;&#22522;&#20934;&#27979;&#35797;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20005;&#26684;&#30340;&#38646;&#26679;&#26412;&#32422;&#26463;&#19979;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
To comply with AI and data regulations, the need to forget private or copyrighted information from trained machine learning models is increasingly important. The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance. In this work, we address the zero-shot unlearning scenario, whereby an unlearning algorithm must be able to remove data given only a trained model and the data to be forgotten. Under such a definition, existing state-of-the-art methods are insufficient. Building on the concepts of Lipschitz continuity, we present a method that induces smoothing of the forget sample's output, with respect to perturbations of that sample. We show this smoothing successfully results in forgetting while preserving general model performance. We perform extensive empirical evaluation of our method over a range of contemporary benchmarks, verifying that our method achieves state-of-the-art performance under the strict constraints of ze
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#26680;&#30697;&#38453;&#30340;&#29305;&#24449;&#25968;&#30028;&#38480;&#65292;&#22686;&#24378;&#20102;&#26680;&#23725;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#25351;&#25968;&#35889;&#34928;&#20943;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38750;&#24179;&#20961;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#24449;&#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#30340;&#26680;&#22238;&#24402;&#22120;&#21017;&#20855;&#26377;&#28798;&#38590;&#24615;&#30340;&#36807;&#25311;&#21512;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01297</link><description>&lt;p&gt;
&#36890;&#36807;&#29305;&#24449;&#35889;&#34920;&#24449;&#26680;&#23725;&#22238;&#24402;&#30340;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Characterizing Overfitting in Kernel Ridgeless Regression Through the Eigenspectrum
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01297
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#26680;&#30697;&#38453;&#30340;&#29305;&#24449;&#25968;&#30028;&#38480;&#65292;&#22686;&#24378;&#20102;&#26680;&#23725;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#25351;&#25968;&#35889;&#34928;&#20943;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38750;&#24179;&#20961;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#24449;&#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#30340;&#26680;&#22238;&#24402;&#22120;&#21017;&#20855;&#26377;&#28798;&#38590;&#24615;&#30340;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#20102;&#26680;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#30340;&#26032;&#30028;&#38480;&#65292;&#28982;&#21518;&#21033;&#29992;&#36825;&#20123;&#30028;&#38480;&#22686;&#24378;&#20102;&#22312;&#22266;&#23450;&#36755;&#20837;&#32500;&#24230;&#30340;&#36807;&#21442;&#25968;&#21270;&#21306;&#22495;&#20013;&#26680;&#23725;&#22238;&#24402;&#30340;&#29616;&#26377;&#38750;&#28176;&#36817;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#20855;&#26377;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#24037;&#20316;&#30340;&#30028;&#38480;&#65307;&#23545;&#20110;&#25351;&#25968;&#34928;&#20943;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#38750;&#24179;&#20961;&#21644;&#26032;&#39062;&#30340;&#12290;&#25105;&#20204;&#23545;&#36807;&#25311;&#21512;&#30340;&#32467;&#35770;&#26159;&#21452;&#37325;&#30340;&#65306;(i) &#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#24517;&#39035;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#24471;&#21040;&#24456;&#22909;&#30340;&#27867;&#21270;&#65307;&#36825;&#20123;&#27169;&#22411;&#34920;&#29616;&#20986;&#25152;&#35859;&#30340;&#28201;&#21644;&#36807;&#25311;&#21512;&#65307;(ii) &#22914;&#26524;&#20219;&#20309;&#26680;&#23725;&#22238;&#24402;&#22120;&#30340;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#65292;&#21017;&#20854;&#27867;&#21270;&#24046;&#65292;&#21363;&#34920;&#29616;&#20986;&#28798;&#38590;&#24615;&#36807;&#25311;&#21512;&#12290;&#36825;&#22686;&#21152;&#20102;&#26680;&#23725;&#22238;&#24402;&#22120;&#34920;&#29616;&#20986;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#21487;&#29992;&#29305;&#24449;&#35889;&#34928;&#20943;&#27425;&#22810;&#39033;&#24335;&#30340;&#26497;&#31471;&#24773;&#20917;&#30340;&#34920;&#24449;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#21512;&#20102;&#26032;&#30340;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;(RMT)&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive new bounds for the condition number of kernel matrices, which we then use to enhance existing non-asymptotic test error bounds for kernel ridgeless regression in the over-parameterized regime for a fixed input dimension. For kernels with polynomial spectral decay, we recover the bound from previous work; for exponential decay, our bound is non-trivial and novel.   Our conclusion on overfitting is two-fold: (i) kernel regressors whose eigenspectrum decays polynomially must generalize well, even in the presence of noisy labeled training data; these models exhibit so-called tempered overfitting; (ii) if the eigenspectrum of any kernel ridge regressor decays exponentially, then it generalizes poorly, i.e., it exhibits catastrophic overfitting. This adds to the available characterization of kernel ridge regressors exhibiting benign overfitting as the extremal case where the eigenspectrum of the kernel decays sub-polynomially. Our analysis combines new random matrix theory (RMT) te
&lt;/p&gt;</description></item><item><title>Ginger&#26159;&#19968;&#31181;&#29992;&#20110;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#26354;&#29575;&#36817;&#20284;&#26041;&#27861;&#65292;&#20855;&#26377;&#32447;&#24615;&#22797;&#26434;&#24230;&#12290;&#23427;&#36890;&#36807;&#29305;&#24449;&#20998;&#35299;&#26469;&#36870;&#21521;&#35745;&#31639;&#24191;&#20041;&#39640;&#26031;&#29275;&#39039;&#30697;&#38453;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#39640;&#20869;&#23384;&#21644;&#39640;&#26102;&#38388;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.03295</link><description>&lt;p&gt;
Ginger: &#19968;&#31181;&#29992;&#20110;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#32447;&#24615;&#22797;&#26434;&#24230;&#39640;&#25928;&#26354;&#29575;&#36817;&#20284;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Ginger: An Efficient Curvature Approximation with Linear Complexity for General Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03295
&lt;/p&gt;
&lt;p&gt;
Ginger&#26159;&#19968;&#31181;&#29992;&#20110;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#26354;&#29575;&#36817;&#20284;&#26041;&#27861;&#65292;&#20855;&#26377;&#32447;&#24615;&#22797;&#26434;&#24230;&#12290;&#23427;&#36890;&#36807;&#29305;&#24449;&#20998;&#35299;&#26469;&#36870;&#21521;&#35745;&#31639;&#24191;&#20041;&#39640;&#26031;&#29275;&#39039;&#30697;&#38453;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#39640;&#20869;&#23384;&#21644;&#39640;&#26102;&#38388;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#22914;&#24191;&#20041;&#39640;&#26031;&#29275;&#39039;&#27861;&#65292;&#30001;&#20110;&#21033;&#29992;&#20102;&#30446;&#26631;&#20989;&#25968;&#30340;&#26354;&#29575;&#20449;&#24687;&#21644;&#39044;&#22788;&#29702;&#30697;&#38453;&#65292;&#34987;&#35748;&#20026;&#26356;&#21152;&#24378;&#22823;&#12290;&#23613;&#31649;&#22312;&#29702;&#35770;&#19978;&#20855;&#26377;&#35825;&#20154;&#30340;&#20248;&#21183;&#65292;&#20294;&#23427;&#20204;&#19981;&#26131;&#24212;&#29992;&#20110;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#12290;&#20027;&#35201;&#21407;&#22240;&#26159;&#35745;&#31639;&#30697;&#38453;&#30340;&#36870;&#25152;&#38656;&#30340;&#20108;&#27425;&#20869;&#23384;&#21644;&#19977;&#27425;&#26102;&#38388;&#22797;&#26434;&#24230;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#21363;&#20351;&#20351;&#29992;&#20808;&#36827;&#30340;&#30828;&#20214;&#20063;&#19981;&#34892;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Ginger&#65292;&#19968;&#31181;&#29992;&#20110;&#24191;&#20041;&#39640;&#26031;&#29275;&#39039;&#30697;&#38453;&#36870;&#30340;&#29305;&#24449;&#20998;&#35299;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#20855;&#26377;&#39640;&#25928;&#30340;&#32447;&#24615;&#20869;&#23384;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30452;&#25509;&#32500;&#25252;&#26465;&#20214;&#30697;&#38453;&#30340;&#36870;&#65292;&#20197;&#20351;&#36817;&#20284;&#26356;&#21152;&#20934;&#30830;&#65292;&#32780;&#19981;&#26159;&#36817;&#20284;&#26465;&#20214;&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;Ginger&#22312;&#38750;&#20984;&#30446;&#26631;&#19978;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#20219;&#21153;&#21644;&#19981;&#21516;&#27169;&#22411;&#26550;&#26500;&#19978;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;...
&lt;/p&gt;
&lt;p&gt;
Second-order optimization approaches like the generalized Gauss-Newton method are considered more powerful as they utilize the curvature information of the objective function with preconditioning matrices. Albeit offering tempting theoretical benefits, they are not easily applicable to modern deep learning. The major reason is due to the quadratic memory and cubic time complexity to compute the inverse of the matrix. These requirements are infeasible even with state-of-the-art hardware. In this work, we propose Ginger, an eigendecomposition for the inverse of the generalized Gauss-Newton matrix. Our method enjoys efficient linear memory and time complexity for each iteration. Instead of approximating the conditioning matrix, we directly maintain its inverse to make the approximation more accurate. We provide the convergence result of Ginger for non-convex objectives. Our experiments on different tasks with different model architectures verify the effectiveness of our method. Our code i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20302;&#31209;&#36866;&#37197;&#22120;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#25237;&#24433;&#30340;&#26041;&#27861;Flora&#65292;&#36890;&#36807;&#37325;&#26032;&#37319;&#26679;&#25237;&#24433;&#30697;&#38453;&#23454;&#29616;&#39640;&#31209;&#26356;&#26032;&#65292;&#21516;&#26102;&#20943;&#23569;&#20248;&#21270;&#29366;&#24577;&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.03293</link><description>&lt;p&gt;
Flora: &#20302;&#31209;&#36866;&#37197;&#22120;&#26159;&#24708;&#24708;&#30340;&#26799;&#24230;&#21387;&#32553;&#22120;
&lt;/p&gt;
&lt;p&gt;
Flora: Low-Rank Adapters Are Secretly Gradient Compressors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03293
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20302;&#31209;&#36866;&#37197;&#22120;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#25237;&#24433;&#30340;&#26041;&#27861;Flora&#65292;&#36890;&#36807;&#37325;&#26032;&#37319;&#26679;&#25237;&#24433;&#30697;&#38453;&#23454;&#29616;&#39640;&#31209;&#26356;&#26032;&#65292;&#21516;&#26102;&#20943;&#23569;&#20248;&#21270;&#29366;&#24577;&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#23637;&#31034;&#20102;&#23436;&#25104;&#19981;&#21516;&#20219;&#21153;&#30340;&#26174;&#30528;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#38656;&#35201;&#36807;&#22810;&#30340;&#20869;&#23384;&#20351;&#29992;&#26469;&#23384;&#20648;&#35757;&#32451;&#30340;&#20248;&#21270;&#29366;&#24577;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20302;&#31209;&#36866;&#37197;&#65288;LoRA&#65289;&#26469;&#36890;&#36807;&#35757;&#32451;&#26356;&#23569;&#30340;&#21442;&#25968;&#26469;&#20943;&#23569;&#20248;&#21270;&#29366;&#24577;&#12290;&#28982;&#32780;&#65292;LoRA&#23558;&#25972;&#20307;&#26435;&#37325;&#26356;&#26032;&#30697;&#38453;&#38480;&#21046;&#20026;&#20302;&#31209;&#65292;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LoRA&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#30830;&#23450;&#23427;&#21487;&#20197;&#36817;&#20284;&#20026;&#38543;&#26426;&#25237;&#24433;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Flora&#65292;&#23427;&#33021;&#22815;&#36890;&#36807;&#37325;&#26032;&#37319;&#26679;&#25237;&#24433;&#30697;&#38453;&#23454;&#29616;&#39640;&#31209;&#26356;&#26032;&#65292;&#21516;&#26102;&#20139;&#21463;&#20248;&#21270;&#29366;&#24577;&#30340;&#27425;&#32447;&#24615;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#20219;&#21153;&#21644;&#27169;&#22411;&#26550;&#26500;&#19978;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite large neural networks demonstrating remarkable abilities to complete different tasks, they require excessive memory usage to store the optimization states for training. To alleviate this, the low-rank adaptation (LoRA) is proposed to reduce the optimization states by training fewer parameters. However, LoRA restricts overall weight update matrices to be low-rank, limiting the model performance. In this work, we investigate the dynamics of LoRA and identify that it can be approximated by a random projection. Based on this observation, we propose Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states. We conduct experiments across different tasks and model architectures to verify the effectiveness of our approach.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;RLHF&#30340;&#26694;&#26550;&#65292;&#22312;&#20854;&#20013;&#32771;&#34385;&#20102;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#22870;&#21169;&#29366;&#24577;&#65292;&#24182;&#36890;&#36807;&#23558;&#22522;&#25968;&#21453;&#39304;&#21644;&#20915;&#26007;&#21453;&#39304;&#32553;&#20943;&#20026;PORRL&#24418;&#24335;&#36827;&#34892;&#20102;&#24314;&#27169;&#21644;&#31639;&#27861;&#24320;&#21457;&#12290;</title><link>https://arxiv.org/abs/2402.03282</link><description>&lt;p&gt;
&#19968;&#20010;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#22870;&#21169;&#29366;&#24577;&#22312;RLHF&#20013;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Framework for Partially Observed Reward-States in RLHF
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03282
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;RLHF&#30340;&#26694;&#26550;&#65292;&#22312;&#20854;&#20013;&#32771;&#34385;&#20102;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#22870;&#21169;&#29366;&#24577;&#65292;&#24182;&#36890;&#36807;&#23558;&#22522;&#25968;&#21453;&#39304;&#21644;&#20915;&#26007;&#21453;&#39304;&#32553;&#20943;&#20026;PORRL&#24418;&#24335;&#36827;&#34892;&#20102;&#24314;&#27169;&#21644;&#31639;&#27861;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#26469;&#65292;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#30340;&#30740;&#31350;&#22240;&#20854;&#22312;LLMs&#30340;&#21457;&#23637;&#20013;&#36215;&#21040;&#30340;&#20316;&#29992;&#32780;&#21464;&#24471;&#37325;&#35201;&#12290;&#31070;&#32463;&#31185;&#23398;&#30740;&#31350;&#34920;&#26126;&#65292;&#20154;&#31867;&#23545;&#21050;&#28608;&#30340;&#21453;&#24212;&#24050;&#30693;&#20381;&#36182;&#20110;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#8220;&#20869;&#37096;&#29366;&#24577;&#8221;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24403;&#21069;&#30340;RLHF&#27169;&#22411;&#27809;&#26377;&#32771;&#34385;&#21040;&#36825;&#19968;&#28857;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;RLHF&#27169;&#22411;&#27809;&#26377;&#32771;&#34385;&#21040;&#20013;&#38388;&#21453;&#39304;&#65292;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#26679;&#26412;&#22797;&#26434;&#24615;&#21644;&#23545;&#40784;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#23558;RLHF&#24314;&#27169;&#20026;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#22870;&#21169;&#29366;&#24577;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;PORRL&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20174;RLHF&#20013;&#20004;&#31181;&#20027;&#35201;&#24418;&#24335;&#30340;&#20154;&#31867;&#21453;&#39304; - &#22522;&#25968;&#21453;&#39304;&#21644;&#20915;&#26007;&#21453;&#39304;&#21040;PORRL&#30340;&#32553;&#20943;&#12290;&#23545;&#20110;&#22522;&#25968;&#21453;&#39304;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36890;&#29992;&#30340;&#32479;&#35745;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#23558;&#23427;&#20204;&#23454;&#20363;&#21270;&#20026;POR-UCRL&#21644;POR-UCBVI&#12290;&#23545;&#20110;&#20915;&#26007;&#21453;&#39304;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#31616;&#21333;&#30340;&#22522;&#25968;&#21453;&#39304;&#32553;&#20943;&#19981;&#33021;&#36798;&#21040;&#20122;&#32447;&#24615;&#30340;&#20915;&#26007;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
The study of reinforcement learning from human feedback (RLHF) has gained prominence in recent years due to its role in the development of LLMs. Neuroscience research shows that human responses to stimuli are known to depend on partially-observed "internal states." Unfortunately current models of RLHF do not take take this into consideration. Moreover most RLHF models do not account for intermediate feedback, which is gaining importance in empirical work and can help improve both sample complexity and alignment. To address these limitations, we model RLHF as reinforcement learning with partially observed reward-states (PORRL). We show reductions from the the two dominant forms of human feedback in RLHF - cardinal and dueling feedback to PORRL. For cardinal feedback, we develop generic statistically efficient algorithms and instantiate them to present POR-UCRL and POR-UCBVI. For dueling feedback, we show that a naive reduction to cardinal feedback fails to achieve sublinear dueling regr
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20915;&#31574;&#24863;&#30693;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#65292;&#29992;&#20110;predict-then-optimize&#26694;&#26550;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#35777;&#25454;&#35777;&#23454;&#20102;&#20854;&#22312;&#35823;&#35774;&#32622;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03256</link><description>&lt;p&gt;
&#23398;&#20064;Predict-then-Optimize&#26694;&#26550;&#20013;&#30340;&#26368;&#20248;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Learning Best-in-Class Policies for the Predict-then-Optimize Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03256
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20915;&#31574;&#24863;&#30693;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#65292;&#29992;&#20110;predict-then-optimize&#26694;&#26550;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#35777;&#25454;&#35777;&#23454;&#20102;&#20854;&#22312;&#35823;&#35774;&#32622;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20915;&#31574;&#24863;&#30693;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#65292;&#31216;&#20026;Perturbation Gradient&#65288;PG&#65289;&#25439;&#22833;&#65292;&#29992;&#20110;predict-then-optimize&#26694;&#26550;&#12290;&#36825;&#20123;&#25439;&#22833;&#30452;&#25509;&#36817;&#20284;&#20102;&#19979;&#28216;&#20915;&#31574;&#25439;&#22833;&#65292;&#24182;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#36827;&#34892;&#20248;&#21270;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#19982;&#29616;&#26377;&#30340;&#26367;&#20195;&#25439;&#22833;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;PG&#25439;&#22833;&#30340;&#36817;&#20284;&#35823;&#24046;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#28040;&#22833;&#12290;&#36825;&#24847;&#21619;&#30528;&#20248;&#21270;&#25105;&#20204;&#30340;&#26367;&#20195;&#25439;&#22833;&#21487;&#20197;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#24471;&#21040;&#26368;&#20339;&#31574;&#30053;&#65292;&#21363;&#20351;&#22312;&#35823;&#35774;&#32622;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#35823;&#35774;&#32622;&#19979;&#30340;&#36825;&#26679;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#35777;&#25454;&#35777;&#23454;&#20102;&#24403;&#22522;&#30784;&#27169;&#22411;&#35823;&#35774;&#32622;&#19988;&#22122;&#22768;&#19981;&#26159;&#20013;&#24515;&#23545;&#31216;&#26102;&#65292;&#25105;&#20204;&#30340;PG&#25439;&#22833;&#22312;&#23454;&#36341;&#20013;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#30340;&#25552;&#26696;&#12290;&#37492;&#20110;&#22312;&#23454;&#36341;&#20013;&#35823;&#35774;&#32622;&#24456;&#24120;&#35265;--&#29305;&#21035;&#26159;&#24403;&#25105;&#20204;&#21487;&#33021;&#26356;&#21916;&#27426;&#19968;&#20010;&#26356;&#31616;&#21333;&#12289;&#26356;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#26102;--PG&#25439;&#22833;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#29702;&#35770;&#19978;&#26377;&#20381;&#25454;&#30340;&#12289;&#21487;&#35745;&#31639;&#30340;&#20915;&#31574;&#24863;&#30693;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. These losses directly approximate the downstream decision loss and can be optimized using off-the-shelf gradient-based methods. Importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. This implies that optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified and the noise is not centrally symmetric. Insofar as misspecification is commonplace in practice -- especially when we might prefer a simpler, more interpretable model -- PG losses offer a novel, theoretically justified, method for computationally tractable decision-aware 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#21387;&#32553;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#31639;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#29702;&#35770;&#27867;&#21270;&#20445;&#35777;&#30340;&#26032;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.03254</link><description>&lt;p&gt;
&#34920;&#31034;&#23398;&#20064;&#30340;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#21644;&#27867;&#21270;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Minimum Description Length and Generalization Guarantees for Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#21387;&#32553;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#31639;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#29702;&#35770;&#27867;&#21270;&#20445;&#35777;&#30340;&#26032;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#39640;&#25928;&#30340;&#32479;&#35745;&#26377;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#25214;&#21040;&#19981;&#20165;&#22312;&#21487;&#29992;&#35757;&#32451;&#26679;&#26412;&#19978;&#34920;&#29616;&#33391;&#22909;&#32780;&#19988;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#20063;&#34920;&#29616;&#33391;&#22909;&#30340;&#34920;&#31034;&#24418;&#24335;&#12290;&#23613;&#31649;&#34920;&#31034;&#23398;&#20064;&#30340;&#30740;&#31350;&#24341;&#21457;&#20102;&#35768;&#22810;&#20852;&#36259;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#37117;&#26159;&#21551;&#21457;&#24335;&#30340;&#65307;&#23545;&#20110;&#29702;&#35770;&#19978;&#30340;&#27867;&#21270;&#20445;&#35777;&#20960;&#20046;&#27809;&#26377;&#20160;&#20040;&#20102;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#21487;&#21387;&#32553;&#24615;&#26694;&#26550;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#26631;&#31614;&#25110;&#28508;&#22312;&#21464;&#37327;&#65288;&#34920;&#31034;&#24418;&#24335;&#65289;&#30340;"&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;"&#65288;MDL&#65289;&#26469;&#25512;&#23548;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#12290;&#19982;&#36890;&#24120;&#34987;&#35748;&#20026;&#21453;&#26144;&#31639;&#27861;&#27867;&#21270;&#33021;&#21147;&#30340;&#32534;&#30721;&#22120;&#36755;&#20837;&#21644;&#34920;&#31034;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26032;&#30028;&#38480;&#28041;&#21450;&#34920;&#31034;&#65288;&#25110;&#26631;&#31614;&#65289;&#20998;&#24067;&#20043;&#38388;&#30340;"&#22810;&#23383;&#27597;"&#30456;&#23545;&#29109;&#65292;&#22312;&#30456;&#20851;&#25991;&#29486;&#20013;&#23545;&#31639;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#30340;&#21453;&#26144;&#36824;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
A major challenge in designing efficient statistical supervised learning algorithms is finding representations that perform well not only on available training samples but also on unseen data. While the study of representation learning has spurred much interest, most existing such approaches are heuristic; and very little is known about theoretical generalization guarantees.   In this paper, we establish a compressibility framework that allows us to derive upper bounds on the generalization error of a representation learning algorithm in terms of the "Minimum Description Length" (MDL) of the labels or the latent variables (representations). Rather than the mutual information between the encoder's input and the representation, which is often believed to reflect the algorithm's generalization capability in the related literature but in fact, falls short of doing so, our new bounds involve the "multi-letter" relative entropy between the distribution of the representations (or labels) of t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#19982;&#21333;&#27425;GD&#30456;&#27604;&#65292;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#38480;&#21046;&#65292;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#23454;&#29616;&#32593;&#32476;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#30340;&#37325;&#21472;&#65292;&#23637;&#31034;&#20102;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#24191;&#27867;&#20989;&#25968;&#31867;&#12290;&#36825;&#20123;&#32467;&#26524;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.03220</link><description>&lt;p&gt;
&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#22312;&#20004;&#23618;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#22909;&#22788;&#65306;&#25171;&#30772;&#20449;&#24687;&#21644;&#36339;&#36291;&#25351;&#25968;&#30340;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
The Benefits of Reusing Batches for Gradient Descent in Two-Layer Networks: Breaking the Curse of Information and Leap Exponents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03220
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#19982;&#21333;&#27425;GD&#30456;&#27604;&#65292;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#38480;&#21046;&#65292;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#23454;&#29616;&#32593;&#32476;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#30340;&#37325;&#21472;&#65292;&#23637;&#31034;&#20102;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#24191;&#27867;&#20989;&#25968;&#31867;&#12290;&#36825;&#20123;&#32467;&#26524;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#25105;&#20204;&#20851;&#27880;&#37325;&#22797;&#22810;&#27425;&#20351;&#29992;&#25209;&#27425;&#30340;&#22810;&#27425;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#65292;&#24182;&#23637;&#31034;&#23427;&#19982;&#21333;&#27425;&#26799;&#24230;&#19979;&#38477;&#30456;&#27604;&#65292;&#26174;&#33879;&#25913;&#21464;&#20102;&#23545;&#20110;&#21738;&#20123;&#20989;&#25968;&#26159;&#21487;&#23398;&#20064;&#30340;&#30340;&#32467;&#35770;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21457;&#29616;&#20855;&#26377;&#26377;&#38480;&#27493;&#38271;&#30340;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#20449;&#24687;&#25351;&#25968;&#65288;Ben Arous&#31561;&#20154;&#65292;2021&#65289;&#21644;&#36339;&#36291;&#25351;&#25968;&#65288;Abbe&#31561;&#20154;&#65292;2023&#65289;&#25152;&#32473;&#20986;&#30340;&#26799;&#24230;&#27969;&#21644;&#21333;&#27425;GD&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#65292;&#32593;&#32476;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#36798;&#25104;&#37325;&#21472;&#65292;&#21363;&#20351;&#20989;&#25968;&#19981;&#28385;&#36275;&#38454;&#26799;&#24615;&#36136;&#65288;Abbe&#31561;&#20154;&#65292;2021&#65289;&#12290;&#25105;&#20204;&#23545;&#33021;&#22815;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#65288;&#24191;&#27867;&#30340;&#65289;&#20989;&#25968;&#31867;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#26126;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#21160;&#24577;&#30340;&#38381;&#24335;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the training dynamics of two-layer neural networks when learning multi-index target functions. We focus on multi-pass gradient descent (GD) that reuses the batches multiple times and show that it significantly changes the conclusion about which functions are learnable compared to single-pass gradient descent. In particular, multi-pass GD with finite stepsize is found to overcome the limitations of gradient flow and single-pass GD given by the information exponent (Ben Arous et al., 2021) and leap exponent (Abbe et al., 2023) of the target function. We show that upon re-using batches, the network achieves in just two time steps an overlap with the target subspace even for functions not satisfying the staircase property (Abbe et al., 2021). We characterize the (broad) class of functions efficiently learned in finite time. The proof of our results is based on the analysis of the Dynamical Mean-Field Theory (DMFT). We further provide a closed-form description of the dynamica
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#37319;&#29992;&#38543;&#26426;&#30697;&#38453;&#26041;&#27861;&#65292;&#22312;&#20302;&#22810;&#32447;&#24615;&#31209;&#24352;&#37327;&#36924;&#36817;&#20013;&#23637;&#31034;&#20102;&#23545;&#31181;&#26893;&#30340;&#20302;&#31209;&#20449;&#21495;&#30340;&#20272;&#35745;&#65292;&#24182;&#26681;&#25454;&#22823;&#32500;&#35889;&#34892;&#20026;&#21644;&#20449;&#22122;&#27604;&#20934;&#30830;&#39044;&#27979;&#20102;&#37325;&#24314;&#24615;&#33021;&#65292;&#24182;&#32473;&#20986;&#20102;HOOI&#25910;&#25947;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.03169</link><description>&lt;p&gt;
&#20302;&#22810;&#32447;&#24615;&#31209;&#24352;&#37327;&#36924;&#36817;&#30340;&#38543;&#26426;&#30697;&#38453;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Random Matrix Approach to Low-Multilinear-Rank Tensor Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03169
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#37319;&#29992;&#38543;&#26426;&#30697;&#38453;&#26041;&#27861;&#65292;&#22312;&#20302;&#22810;&#32447;&#24615;&#31209;&#24352;&#37327;&#36924;&#36817;&#20013;&#23637;&#31034;&#20102;&#23545;&#31181;&#26893;&#30340;&#20302;&#31209;&#20449;&#21495;&#30340;&#20272;&#35745;&#65292;&#24182;&#26681;&#25454;&#22823;&#32500;&#35889;&#34892;&#20026;&#21644;&#20449;&#22122;&#27604;&#20934;&#30830;&#39044;&#27979;&#20102;&#37325;&#24314;&#24615;&#33021;&#65292;&#24182;&#32473;&#20986;&#20102;HOOI&#25910;&#25947;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#35745;&#31639;&#38408;&#20540;&#38468;&#36817;&#30340;&#19968;&#33324;&#23574;&#23792;&#24352;&#37327;&#27169;&#22411;&#65292;&#23545;&#31181;&#26893;&#30340;&#20302;&#31209;&#20449;&#21495;&#20272;&#35745;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35748;&#35782;&#12290;&#20381;&#38752;&#22823;&#22411;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#26631;&#20934;&#24037;&#20855;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#25968;&#25454;&#24352;&#37327;&#30340;&#23637;&#24320;&#30340;&#22823;&#32500;&#35889;&#34892;&#20026;&#65292;&#24182;&#23637;&#31034;&#20102;&#20915;&#23450;&#20027;&#35201;&#20449;&#21495;&#26041;&#21521;&#21487;&#26816;&#27979;&#24615;&#30340;&#30456;&#20851;&#20449;&#22122;&#27604;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#20934;&#30830;&#22320;&#39044;&#27979;&#22312;&#38750;&#24179;&#20961;&#21306;&#22495;&#30340;&#25130;&#26029;&#22810;&#32447;&#24615;&#22855;&#24322;&#20540;&#20998;&#35299;(MLSVD)&#30340;&#37325;&#24314;&#24615;&#33021;&#12290;&#36825;&#19968;&#28857;&#23588;&#20854;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#20316;&#20026;&#26356;&#39640;&#38454;&#27491;&#20132;&#36845;&#20195;(HOOI)&#26041;&#26696;&#30340;&#21021;&#22987;&#21270;&#65292;&#20854;&#25910;&#25947;&#21040;&#26368;&#20339;&#20302;&#22810;&#32447;&#24615;&#31209;&#36924;&#36817;&#23436;&#20840;&#21462;&#20915;&#20110;&#20854;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;HOOI&#25910;&#25947;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#35777;&#26126;&#22312;&#22823;&#32500;&#26497;&#38480;&#19979;&#25910;&#25947;&#21069;&#30340;&#36845;&#20195;&#27425;&#25968;&#36235;&#20110;1&#12290;
&lt;/p&gt;
&lt;p&gt;
This work presents a comprehensive understanding of the estimation of a planted low-rank signal from a general spiked tensor model near the computational threshold. Relying on standard tools from the theory of large random matrices, we characterize the large-dimensional spectral behavior of the unfoldings of the data tensor and exhibit relevant signal-to-noise ratios governing the detectability of the principal directions of the signal. These results allow to accurately predict the reconstruction performance of truncated multilinear SVD (MLSVD) in the non-trivial regime. This is particularly important since it serves as an initialization of the higher-order orthogonal iteration (HOOI) scheme, whose convergence to the best low-multilinear-rank approximation depends entirely on its initialization. We give a sufficient condition for the convergence of HOOI and show that the number of iterations before convergence tends to $1$ in the large-dimensional limit.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;&#31639;&#27861;&#65288;D-SOBA&#65289;&#65292;&#39318;&#27425;&#38416;&#26126;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#22312;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2402.03167</link><description>&lt;p&gt;
&#22270;&#19978;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;: &#26080;&#29615;&#31639;&#27861;&#26356;&#26032;&#21644;&#30636;&#24577;&#36845;&#20195;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Decentralized Bilevel Optimization over Graphs: Loopless Algorithmic Update and Transient Iteration Complexity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03167
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;&#31639;&#27861;&#65288;D-SOBA&#65289;&#65292;&#39318;&#27425;&#38416;&#26126;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#22312;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21452;&#32423;&#20248;&#21270;&#65288;SBO&#65289;&#22312;&#22788;&#29702;&#23884;&#22871;&#32467;&#26500;&#26041;&#38754;&#30340;&#22810;&#26679;&#24615;&#20351;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#22823;&#35268;&#27169;SBO&#65292;&#21435;&#20013;&#24515;&#21270;&#26041;&#27861;&#20316;&#20026;&#26377;&#25928;&#30340;&#33539;&#20363;&#20986;&#29616;&#65292;&#20854;&#20013;&#33410;&#28857;&#19982;&#30452;&#25509;&#30456;&#37051;&#33410;&#28857;&#36827;&#34892;&#36890;&#20449;&#65292;&#26080;&#38656;&#20013;&#22830;&#26381;&#21153;&#22120;&#65292;&#20174;&#32780;&#25552;&#39640;&#36890;&#20449;&#25928;&#29575;&#21644;&#22686;&#24378;&#31639;&#27861;&#30340;&#31283;&#20581;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#21435;&#20013;&#24515;&#21270;SBO&#31639;&#27861;&#38754;&#20020;&#25361;&#25112;&#65292;&#21253;&#25324;&#26114;&#36149;&#30340;&#20869;&#37096;&#24490;&#29615;&#26356;&#26032;&#21644;&#23545;&#32593;&#32476;&#25299;&#25169;&#12289;&#25968;&#25454;&#24322;&#26500;&#24615;&#21644;&#23884;&#22871;&#21452;&#32423;&#31639;&#27861;&#32467;&#26500;&#30340;&#24433;&#21709;&#19981;&#26126;&#30830;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;SBO&#65288;D-SOBA&#65289;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#20854;&#30636;&#24577;&#36845;&#20195;&#22797;&#26434;&#24615;&#65292;&#39318;&#27425;&#28548;&#28165;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic bilevel optimization (SBO) is becoming increasingly essential in machine learning due to its versatility in handling nested structures. To address large-scale SBO, decentralized approaches have emerged as effective paradigms in which nodes communicate with immediate neighbors without a central server, thereby improving communication efficiency and enhancing algorithmic robustness. However, current decentralized SBO algorithms face challenges, including expensive inner-loop updates and unclear understanding of the influence of network topology, data heterogeneity, and the nested bilevel algorithmic structures. In this paper, we introduce a single-loop decentralized SBO (D-SOBA) algorithm and establish its transient iteration complexity, which, for the first time, clarifies the joint influence of network topology and data heterogeneity on decentralized bilevel algorithms. D-SOBA achieves the state-of-the-art asymptotic rate, asymptotic gradient/Hessian complexity, and transien
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31283;&#20581;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#30340;&#22810;&#27493;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#21152;&#26435;&#24179;&#22343;&#22343;&#26041;&#35823;&#24046;&#25439;&#22833;&#22312;&#19981;&#21516;&#26410;&#26469;&#26102;&#38388;&#28857;&#19978;&#26469;&#35757;&#32451;&#21333;&#27493;&#27169;&#22411;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#23588;&#20026;&#26377;&#25928;&#65292;&#24182;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#39044;&#27979;&#25913;&#21892;&#12290;</title><link>https://arxiv.org/abs/2402.03146</link><description>&lt;p&gt;
&#29992;&#20110;&#31283;&#20581;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#30340;&#22810;&#27493;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
A Multi-step Loss Function for Robust Learning of the Dynamics in Model-based Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31283;&#20581;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#30340;&#22810;&#27493;&#25439;&#22833;&#20989;&#25968;&#65292;&#36890;&#36807;&#21152;&#26435;&#24179;&#22343;&#22343;&#26041;&#35823;&#24046;&#25439;&#22833;&#22312;&#19981;&#21516;&#26410;&#26469;&#26102;&#38388;&#28857;&#19978;&#26469;&#35757;&#32451;&#21333;&#27493;&#27169;&#22411;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#23588;&#20026;&#26377;&#25928;&#65292;&#24182;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#39044;&#27979;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#22823;&#22810;&#25968;&#31639;&#27861;&#20381;&#36182;&#20110;&#20174;&#25968;&#25454;&#23398;&#21040;&#30340;&#21333;&#27493;&#21160;&#21147;&#23398;&#27169;&#22411;&#27169;&#25311;&#36712;&#36857;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#38543;&#30528;&#36712;&#36857;&#38271;&#24230;&#30340;&#22686;&#21152;&#65292;&#21333;&#27493;&#39044;&#27979;&#35823;&#24046;&#30340;&#32047;&#31215;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#22810;&#27493;&#30446;&#26631;&#26469;&#35757;&#32451;&#21333;&#27493;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#19981;&#21516;&#30340;&#26410;&#26469;&#26102;&#38388;&#28857;&#19978;&#21152;&#26435;&#24179;&#22343;&#30340;&#22343;&#26041;&#35823;&#24046;(MSE)&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36825;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#22312;&#25968;&#25454;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#29305;&#21035;&#26377;&#29992;&#65288;&#35266;&#27979;&#19978;&#30340;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#65289;&#65292;&#32780;&#36825;&#31181;&#24773;&#20917;&#22312;&#29616;&#23454;&#29615;&#22659;&#20013;&#32463;&#24120;&#20986;&#29616;&#12290;&#20026;&#20102;&#25903;&#25345;&#22810;&#27493;&#25439;&#22833;&#20989;&#25968;&#65292;&#39318;&#20808;&#25105;&#20204;&#22312;&#20004;&#31181;&#21487;&#22788;&#29702;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#23427;&#30340;&#24615;&#36136;&#65306;i&#65289;&#19968;&#32500;&#32447;&#24615;&#31995;&#32479;&#65292;&#21644;ii&#65289;&#20004;&#21442;&#25968;&#38750;&#32447;&#24615;&#31995;&#32479;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#20219;&#21153;&#65288;&#29615;&#22659;&#25110;&#25968;&#25454;&#38598;&#65289;&#20013;&#23637;&#31034;&#20102;&#20351;&#29992;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#26410;&#26469;&#39044;&#27979;&#20013;&#30340;&#24179;&#22343;R2&#24471;&#20998;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
In model-based reinforcement learning, most algorithms rely on simulating trajectories from one-step models of the dynamics learned on data. A critical challenge of this approach is the compounding of one-step prediction errors as the length of the trajectory grows. In this paper we tackle this issue by using a multi-step objective to train one-step models. Our objective is a weighted sum of the mean squared error (MSE) loss at various future horizons. We find that this new loss is particularly useful when the data is noisy (additive Gaussian noise in the observations), which is often the case in real-life environments. To support the multi-step loss, first we study its properties in two tractable cases: i) uni-dimensional linear system, and ii) two-parameter non-linear system. Second, we show in a variety of tasks (environments or datasets) that the models learned with this loss achieve a significant improvement in terms of the averaged R2-score on future prediction horizons. Finally,
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#22312;&#38750;&#20984;&#21644;&#20984;&#35774;&#32622;&#19979;&#37117;&#33021;&#21462;&#24471;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#25351;&#20986;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.03126</link><description>&lt;p&gt;
&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#33258;&#30001;&#24230;&#26377;&#22810;&#39640;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Free is Parameter-Free Stochastic Optimization?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03126
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#22312;&#38750;&#20984;&#21644;&#20984;&#35774;&#32622;&#19979;&#37117;&#33021;&#21462;&#24471;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#25351;&#20986;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#22312;&#20160;&#20040;&#26465;&#20214;&#19979;&#21487;&#20197;&#23384;&#22312;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65306;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#36798;&#21040;&#19982;&#26368;&#20248;&#35843;&#21442;&#26041;&#27861;&#30456;&#31454;&#20105;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#32780;&#19981;&#38656;&#35201;&#23545;&#30495;&#23454;&#38382;&#39064;&#21442;&#25968;&#26377;&#24456;&#22810;&#30693;&#35782;&#12290;&#29616;&#26377;&#30340;&#26080;&#21442;&#26041;&#27861;&#21482;&#33021;&#34987;&#35270;&#20026;&#8220;&#37096;&#20998;&#8221;&#26080;&#21442;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#23545;&#30495;&#23454;&#38382;&#39064;&#21442;&#25968;&#26377;&#19968;&#20123;&#38750;&#24179;&#20961;&#30340;&#30693;&#35782;&#65292;&#27604;&#22914;&#38543;&#26426;&#26799;&#24230;&#33539;&#25968;&#30340;&#19978;&#30028;&#12289;&#21040;&#26368;&#23567;&#20540;&#30340;&#36317;&#31163;&#30340;&#19978;&#30028;&#31561;&#12290;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#22312;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#26356;&#22797;&#26434;&#30340;&#20808;&#36827;&#31639;&#27861;&#12290;&#22312;&#20855;&#26377;&#22122;&#22768;&#20989;&#25968;&#20540;&#30340;&#20984;&#35774;&#32622;&#19979;&#65292;&#22312;&#36739;&#23567;&#30340;&#22122;&#22768;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20063;&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#20551;&#35774;&#21482;&#33021;&#35775;&#38382;&#38543;&#26426;&#26799;&#24230;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#20351;&#24471;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#26080;&#27861;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters. Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc. In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms. We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions. Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#21327;&#26041;&#24046;&#30697;&#38453;&#36866;&#24212;&#31574;&#30053;&#23450;&#20041;&#23616;&#37096;&#25628;&#32034;&#21306;&#22495;&#65292;&#33021;&#22815;&#35299;&#20915;&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#24212;&#29992;&#20110;&#39640;&#32500;&#20248;&#21270;&#38382;&#39064;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.03104</link><description>&lt;p&gt;
&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#21327;&#26041;&#24046;&#30697;&#38453;&#36866;&#24212;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Bayesian Optimization via Covariance Matrix Adaptation Strategy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03104
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#21327;&#26041;&#24046;&#30697;&#38453;&#36866;&#24212;&#31574;&#30053;&#23450;&#20041;&#23616;&#37096;&#25628;&#32034;&#21306;&#22495;&#65292;&#33021;&#22815;&#35299;&#20915;&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#24212;&#29992;&#20110;&#39640;&#32500;&#20248;&#21270;&#38382;&#39064;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#26159;&#19968;&#31181;&#23547;&#25214;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#23558;BO&#24212;&#29992;&#20110;&#39640;&#32500;&#20248;&#21270;&#38382;&#39064;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#20351;&#29992;&#23616;&#37096;&#25628;&#32034;&#31574;&#30053;&#23558;&#25628;&#32034;&#22495;&#21010;&#20998;&#25104;&#21253;&#21547;&#20840;&#23616;&#26368;&#20248;&#35299;&#21487;&#33021;&#24615;&#36739;&#39640;&#30340;&#23616;&#37096;&#21306;&#22495;&#65292;&#28982;&#21518;&#22312;&#36825;&#20123;&#21306;&#22495;&#20869;&#20351;&#29992;BO&#20248;&#21270;&#30446;&#26631;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21327;&#26041;&#24046;&#30697;&#38453;&#36866;&#24212;&#65288;CMA&#65289;&#31574;&#30053;&#23450;&#20041;&#23616;&#37096;&#21306;&#22495;&#30340;&#26032;&#25216;&#26415;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20351;&#29992;CMA&#26469;&#23398;&#20064;&#19968;&#20010;&#33021;&#22815;&#20272;&#35745;&#25968;&#25454;&#28857;&#20316;&#20026;&#30446;&#26631;&#20989;&#25968;&#20840;&#23616;&#26368;&#20248;&#35299;&#27010;&#29575;&#30340;&#25628;&#32034;&#20998;&#24067;&#12290;&#22522;&#20110;&#36825;&#20010;&#25628;&#32034;&#20998;&#24067;&#65292;&#25105;&#20204;&#23450;&#20041;&#30001;&#39640;&#27010;&#29575;&#25968;&#25454;&#28857;&#32452;&#25104;&#30340;&#23616;&#37096;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20316;&#20026;&#19968;&#20010;&#20803;&#31639;&#27861;&#65292;&#21487;&#20197;&#25972;&#21512;&#29616;&#26377;&#30340;&#40657;&#30418;BO&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) is an effective method for finding the global optimum of expensive black-box functions. However, it is well known that applying BO to high-dimensional optimization problems is challenging. To address this issue, a promising solution is to use a local search strategy that partitions the search domain into local regions with high likelihood of containing the global optimum, and then use BO to optimize the objective function within these regions. In this paper, we propose a novel technique for defining the local regions using the Covariance Matrix Adaptation (CMA) strategy. Specifically, we use CMA to learn a search distribution that can estimate the probabilities of data points being the global optimum of the objective function. Based on this search distribution, we then define the local regions consisting of data points with high probabilities of being the global optimum. Our approach serves as a meta-algorithm as it can incorporate existing black-box BO optim
&lt;/p&gt;</description></item><item><title>&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#25193;&#25955;&#27169;&#22411;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#65292;&#26377;&#25928;&#22320;&#20174;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.03008</link><description>&lt;p&gt;
&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Diffusive Gibbs Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03008
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#25193;&#25955;&#27169;&#22411;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#65292;&#26377;&#25928;&#22320;&#20174;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#26041;&#27861;&#22312;&#22810;&#27169;&#24577;&#20998;&#24067;&#30340;&#28151;&#21512;&#19981;&#36275;&#26041;&#38754;&#23384;&#22312;&#30528;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#20998;&#23376;&#21160;&#21147;&#23398;&#31561;&#23454;&#38469;&#24212;&#29992;&#20013;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#8212;&#8212;&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#65288;DiGS&#65289;&#65292;&#29992;&#20110;&#26377;&#25928;&#37319;&#26679;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#12290;DiGS&#38598;&#25104;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#21033;&#29992;&#39640;&#26031;&#21367;&#31215;&#21019;&#24314;&#19968;&#20010;&#36741;&#21161;&#22122;&#22768;&#20998;&#24067;&#65292;&#20197;&#22312;&#21407;&#22987;&#31354;&#38388;&#20013;&#36830;&#25509;&#23396;&#31435;&#30340;&#27169;&#24577;&#65292;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#20174;&#20004;&#20010;&#31354;&#38388;&#20013;&#20132;&#26367;&#25277;&#21462;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#37319;&#26679;&#22810;&#27169;&#24577;&#20998;&#24067;&#26041;&#38754;&#34920;&#29616;&#20986;&#27604;&#24182;&#34892;&#28201;&#24230;&#27861;&#31561;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#12290;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#37319;&#26679;&#22120;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#65292;&#21253;&#25324;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12289;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21644;&#20998;&#23376;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
The inadequate mixing of conventional Markov Chain Monte Carlo (MCMC) methods for multi-modal distributions presents a significant challenge in practical applications such as Bayesian inference and molecular dynamics. Addressing this, we propose Diffusive Gibbs Sampling (DiGS), an innovative family of sampling methods designed for effective sampling from distributions characterized by distant and disconnected modes. DiGS integrates recent developments in diffusion models, leveraging Gaussian convolution to create an auxiliary noisy distribution that bridges isolated modes in the original space and applying Gibbs sampling to alternately draw samples from both spaces. Our approach exhibits a better mixing property for sampling multi-modal distributions than state-of-the-art methods such as parallel tempering. We demonstrate that our sampler attains substantially improved results across various tasks, including mixtures of Gaussians, Bayesian neural networks and molecular dynamics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#21463;&#29615;&#22659;&#26465;&#20214;&#21464;&#21270;&#24433;&#21709;&#30340;&#26114;&#36149;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#65292;&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#25512;&#24191;&#21040;&#21253;&#21547;&#21487;&#25511;&#21644;&#19981;&#21487;&#25511;&#21442;&#25968;&#30340;&#31995;&#32479;&#20248;&#21270;&#20013;&#65292;&#36890;&#36807;&#22312;&#25152;&#26377;&#21464;&#37327;&#19978;&#25311;&#21512;&#20840;&#23616;&#20195;&#29702;&#27169;&#22411;&#65292;&#20294;&#21482;&#22312;&#23545;&#19981;&#21487;&#25511;&#21464;&#37327;&#30340;&#27979;&#37327;&#26465;&#20214;&#19979;&#20248;&#21270;&#21487;&#25511;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.03006</link><description>&lt;p&gt;
&#24320;&#21457;&#19968;&#31181;&#36866;&#29992;&#20110;&#21463;&#29615;&#22659;&#26465;&#20214;&#21464;&#21270;&#24433;&#21709;&#30340;&#26114;&#36149;&#23454;&#39564;&#21644;&#27169;&#25311;&#30340;&#23454;&#29992;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
On the development of a practical Bayesian optimisation algorithm for expensive experiments and simulations with changing environmental conditions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03006
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#21463;&#29615;&#22659;&#26465;&#20214;&#21464;&#21270;&#24433;&#21709;&#30340;&#26114;&#36149;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#65292;&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#25512;&#24191;&#21040;&#21253;&#21547;&#21487;&#25511;&#21644;&#19981;&#21487;&#25511;&#21442;&#25968;&#30340;&#31995;&#32479;&#20248;&#21270;&#20013;&#65292;&#36890;&#36807;&#22312;&#25152;&#26377;&#21464;&#37327;&#19978;&#25311;&#21512;&#20840;&#23616;&#20195;&#29702;&#27169;&#22411;&#65292;&#20294;&#21482;&#22312;&#23545;&#19981;&#21487;&#25511;&#21464;&#37327;&#30340;&#27979;&#37327;&#26465;&#20214;&#19979;&#20248;&#21270;&#21487;&#25511;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#31243;&#23454;&#39564;&#36890;&#24120;&#22312;&#21463;&#25511;&#29615;&#22659;&#20013;&#36827;&#34892;&#65292;&#21487;&#20197;&#23558;&#21442;&#25968;&#35774;&#32622;&#20026;&#20219;&#20309;&#25152;&#38656;&#20540;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#29615;&#22659;&#20013;&#65292;&#36890;&#24120;&#20551;&#35774;&#30456;&#21516;&#26465;&#20214;&#19981;&#25104;&#31435;&#65292;&#22240;&#20026;&#35768;&#22810;&#23454;&#39564;&#21463;&#19981;&#21487;&#25511;&#21046;&#30340;&#29615;&#22659;&#26465;&#20214;&#65288;&#22914;&#28201;&#24230;&#12289;&#28287;&#24230;&#21644;&#39118;&#36895;&#65289;&#30340;&#24433;&#21709;&#12290;&#22312;&#20248;&#21270;&#36825;&#20123;&#23454;&#39564;&#26102;&#65292;&#24212;&#35813;&#37325;&#28857;&#20851;&#27880;&#22312;&#32473;&#23450;&#19981;&#21487;&#25511;&#21464;&#37327;&#26465;&#20214;&#19979;&#25214;&#21040;&#26368;&#20248;&#20540;&#12290;&#26412;&#25991;&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#25512;&#24191;&#21040;&#22312;&#21253;&#21547;&#21487;&#25511;&#21644;&#19981;&#21487;&#25511;&#21442;&#25968;&#30340;&#21464;&#21270;&#29615;&#22659;&#20013;&#36827;&#34892;&#31995;&#32479;&#20248;&#21270;&#12290;&#35813;&#25512;&#24191;&#36890;&#36807;&#22312;&#25152;&#26377;&#21487;&#25511;&#21644;&#29615;&#22659;&#21464;&#37327;&#19978;&#25311;&#21512;&#20840;&#23616;&#20195;&#29702;&#27169;&#22411;&#65292;&#20294;&#21482;&#22312;&#23545;&#19981;&#21487;&#25511;&#21464;&#37327;&#30340;&#27979;&#37327;&#26465;&#20214;&#19979;&#20248;&#21270;&#21487;&#25511;&#21442;&#25968;&#12290;&#35813;&#26041;&#27861;&#22312;&#20004;&#20010;&#21512;&#25104;&#27979;&#35797;&#20989;&#25968;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#65292;&#30740;&#31350;&#20102;&#22122;&#22768;&#27700;&#24179;&#12289;&#29615;&#22659;&#21442;&#25968;&#25968;&#37327;&#21644;&#21442;&#25968;&#27874;&#21160;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Experiments in engineering are typically conducted in controlled environments where parameters can be set to any desired value. This assumes that the same applies in a real-world setting -- an assumption that is often incorrect as many experiments are influenced by uncontrollable environmental conditions such as temperature, humidity and wind speed. When optimising such experiments, the focus should lie on finding optimal values conditionally on these uncontrollable variables. This article extends Bayesian optimisation to the optimisation of systems in changing environments that include controllable and uncontrollable parameters. The extension fits a global surrogate model over all controllable and environmental variables but optimises only the controllable parameters conditional on measurements of the uncontrollable variables. The method is validated on two synthetic test functions and the effects of the noise level, the number of the environmental parameters, the parameter fluctuatio
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23558;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#21644;&#36741;&#21161;&#26799;&#24230;&#22312;&#35757;&#32451;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#27491;&#20132;&#25237;&#24433;&#32467;&#21512;&#36215;&#26469;&#65292;&#20351;&#29992;EMA&#65288;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65289;&#21487;&#20197;&#25913;&#36827;&#26799;&#24230;&#25163;&#26415;&#65292;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#20272;&#35745;&#31649;&#36947;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02998</link><description>&lt;p&gt;
&#23567;&#24515;&#20351;&#29992;&#25163;&#26415;&#20992;&#65306;&#20351;&#29992;EMA&#25913;&#36827;&#26799;&#24230;&#25163;&#26415;
&lt;/p&gt;
&lt;p&gt;
Careful with that Scalpel: Improving Gradient Surgery with an EMA
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02998
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#21644;&#36741;&#21161;&#26799;&#24230;&#22312;&#35757;&#32451;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#27491;&#20132;&#25237;&#24433;&#32467;&#21512;&#36215;&#26469;&#65292;&#20351;&#29992;EMA&#65288;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65289;&#21487;&#20197;&#25913;&#36827;&#26799;&#24230;&#25163;&#26415;&#65292;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#20272;&#35745;&#31649;&#36947;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20272;&#35745;&#31649;&#36947;&#20013;&#65292;&#38500;&#20102;&#26368;&#23567;&#21270;&#21333;&#19968;&#30340;&#35757;&#32451;&#25439;&#22833;&#22806;&#65292;&#36824;&#20381;&#36182;&#20110;&#36741;&#21161;&#30446;&#26631;&#26469;&#37327;&#21270;&#21644;&#40723;&#21169;&#27169;&#22411;&#30340;&#21487;&#21462;&#23646;&#24615;&#65288;&#20363;&#22914;&#22312;&#21478;&#19968;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#65292;&#40065;&#26834;&#24615;&#65292;&#19982;&#20808;&#21069;&#30340;&#19968;&#33268;&#24615;&#65289;&#12290;&#34429;&#28982;&#23558;&#36741;&#21161;&#25439;&#22833;&#19982;&#35757;&#32451;&#25439;&#22833;&#30456;&#21152;&#20316;&#20026;&#27491;&#21017;&#21270;&#30340;&#26368;&#31616;&#21333;&#26041;&#27861;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#28151;&#21512;&#26799;&#24230;&#32780;&#19981;&#20165;&#20165;&#26159;&#31616;&#21333;&#30456;&#21152;&#65292;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#65307;&#36825;&#34987;&#31216;&#20026;&#26799;&#24230;&#25163;&#26415;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#30475;&#20316;&#26159;&#19968;&#20010;&#32422;&#26463;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#36741;&#21161;&#30446;&#26631;&#22312;&#35757;&#32451;&#25439;&#22833;&#30340;&#26368;&#23567;&#21270;&#38598;&#21512;&#20013;&#34987;&#26368;&#23567;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#21452;&#23618;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#21442;&#25968;&#26356;&#26032;&#26041;&#21521;&#65292;&#23427;&#23558;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#21644;&#36741;&#21161;&#26799;&#24230;&#22312;&#35757;&#32451;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#27491;&#20132;&#25237;&#24433;&#32467;&#21512;&#36215;&#26469;&#12290;&#22312;&#26799;&#24230;&#26469;&#33258;&#23567;&#25209;&#27425;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#22914;&#20309;&#20351;&#29992;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#30340;&#31227;&#21160;&#24179;&#22343;&#26469;&#32500;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
Beyond minimizing a single training loss, many deep learning estimation pipelines rely on an auxiliary objective to quantify and encourage desirable properties of the model (e.g. performance on another dataset, robustness, agreement with a prior). Although the simplest approach to incorporating an auxiliary loss is to sum it with the training loss as a regularizer, recent works have shown that one can improve performance by blending the gradients beyond a simple sum; this is known as gradient surgery. We cast the problem as a constrained minimization problem where the auxiliary objective is minimized among the set of minimizers of the training loss. To solve this bilevel problem, we follow a parameter update direction that combines the training loss gradient and the orthogonal projection of the auxiliary gradient to the training gradient. In a setting where gradients come from mini-batches, we explain how, using a moving average of the training loss gradients, we can carefully maintain
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25552;&#21319;&#31639;&#27861;&#26469;&#35299;&#20915;&#20256;&#32479;&#25552;&#21319;&#31639;&#27861;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#23558;&#26679;&#26412;&#21387;&#32553;&#26041;&#27861;&#25193;&#23637;&#21040;&#25903;&#25345;&#38543;&#26426;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#26679;&#26412;&#22823;&#23567;&#19978;&#20855;&#26377;&#21333;&#23545;&#25968;&#20381;&#36182;&#30340;&#27867;&#21270;&#38169;&#35823;&#12290;</title><link>https://arxiv.org/abs/2402.02976</link><description>&lt;p&gt;
&#25552;&#21319;&#65292;&#25237;&#31080;&#20998;&#31867;&#22120;&#21644;&#38543;&#26426;&#37319;&#26679;&#21387;&#32553;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Boosting, Voting Classifiers and Randomized Sample Compression Schemes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02976
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25552;&#21319;&#31639;&#27861;&#26469;&#35299;&#20915;&#20256;&#32479;&#25552;&#21319;&#31639;&#27861;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#23558;&#26679;&#26412;&#21387;&#32553;&#26041;&#27861;&#25193;&#23637;&#21040;&#25903;&#25345;&#38543;&#26426;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#26679;&#26412;&#22823;&#23567;&#19978;&#20855;&#26377;&#21333;&#23545;&#25968;&#20381;&#36182;&#30340;&#27867;&#21270;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25552;&#21319;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#21033;&#29992;&#22810;&#20010;&#24369;&#23398;&#20064;&#22120;&#26469;&#20135;&#29983;&#19968;&#20010;&#24378;&#23398;&#20064;&#22120;&#12290;&#36825;&#20010;&#33539;&#24335;&#30340;&#26680;&#24515;&#26159;&#23558;&#24378;&#23398;&#20064;&#22120;&#24314;&#27169;&#20026;&#19968;&#20010;&#25237;&#31080;&#20998;&#31867;&#22120;&#65292;&#23427;&#36755;&#20986;&#24369;&#23398;&#20064;&#22120;&#30340;&#21152;&#26435;&#22810;&#25968;&#25237;&#31080;&#12290;&#23613;&#31649;&#35768;&#22810;&#25104;&#21151;&#30340;&#25552;&#21319;&#31639;&#27861;&#65292;&#22914;&#26631;&#24535;&#24615;&#30340;AdaBoost&#65292;&#20135;&#29983;&#25237;&#31080;&#20998;&#31867;&#22120;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#24615;&#33021;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#19981;&#22815;&#20248;&#21270;&#65306;&#36804;&#20170;&#20026;&#27490;&#65292;&#24050;&#30693;&#30340;&#20351;&#25237;&#31080;&#20998;&#31867;&#22120;&#36798;&#21040;&#32473;&#23450;&#20934;&#30830;&#24615;&#25152;&#38656;&#30340;&#35757;&#32451;&#26679;&#26412;&#25968;&#30340;&#26368;&#20339;&#30028;&#38480;&#24635;&#26159;&#33267;&#23569;&#21253;&#21547;&#33267;&#22810;&#20004;&#20010;&#23545;&#25968;&#22240;&#23376;&#65292;&#32780;&#36825;&#24050;&#32463;&#36229;&#36807;&#20102;&#19968;&#33324;&#30340;&#24369;&#21040;&#24378;&#23398;&#20064;&#22120;&#25152;&#33021;&#23454;&#29616;&#30340;&#33539;&#22260;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#38543;&#26426;&#25552;&#21319;&#31639;&#27861;&#25171;&#30772;&#36825;&#19968;&#38556;&#30861;&#65292;&#35813;&#31639;&#27861;&#36755;&#20986;&#30340;&#25237;&#31080;&#20998;&#31867;&#22120;&#22312;&#26679;&#26412;&#22823;&#23567;&#19978;&#21253;&#21547;&#21333;&#23545;&#25968;&#20381;&#36182;&#30340;&#27867;&#21270;&#38169;&#35823;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#23558;&#26679;&#26412;&#21387;&#32553;&#26041;&#27861;&#25193;&#23637;&#21040;&#25903;&#25345;&#38543;&#26426;&#23398;&#20064;&#31639;&#27861;&#26469;&#33719;&#24471;&#36825;&#20010;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In boosting, we aim to leverage multiple weak learners to produce a strong learner. At the center of this paradigm lies the concept of building the strong learner as a voting classifier, which outputs a weighted majority vote of the weak learners. While many successful boosting algorithms, such as the iconic AdaBoost, produce voting classifiers, their theoretical performance has long remained sub-optimal: the best known bounds on the number of training examples necessary for a voting classifier to obtain a given accuracy has so far always contained at least two logarithmic factors above what is known to be achievable by general weak-to-strong learners. In this work, we break this barrier by proposing a randomized boosting algorithm that outputs voting classifiers whose generalization error contains a single logarithmic dependency on the sample size. We obtain this result by building a general framework that extends sample compression methods to support randomized learning algorithms ba
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#29305;&#24449;&#65292;&#25105;&#20204;&#21457;&#29616;&#27880;&#24847;&#21147;&#23618;&#20855;&#26377;&#36739;&#39640;&#30340;&#35789;&#25935;&#24863;&#24615;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;transformers&#30340;&#25104;&#21151;&#20197;&#21450;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#30340;&#19978;&#19979;&#25991;&#21547;&#20041;&#38750;&#24120;&#37325;&#35201;&#12290;</title><link>https://arxiv.org/abs/2402.02969</link><description>&lt;p&gt;
&#20851;&#20110;&#27880;&#24847;&#21147;&#23618;&#30340;&#35789;&#25935;&#24863;&#24615;&#30340;&#29702;&#35299;&#65306;&#36890;&#36807;&#38543;&#26426;&#29305;&#24449;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding the Word Sensitivity of Attention Layers: A Study via Random Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02969
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#29305;&#24449;&#65292;&#25105;&#20204;&#21457;&#29616;&#27880;&#24847;&#21147;&#23618;&#20855;&#26377;&#36739;&#39640;&#30340;&#35789;&#25935;&#24863;&#24615;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;transformers&#30340;&#25104;&#21151;&#20197;&#21450;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#30340;&#19978;&#19979;&#25991;&#21547;&#20041;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25581;&#31034;transformers&#24322;&#24120;&#25104;&#21151;&#32972;&#21518;&#21407;&#22240;&#38656;&#35201;&#26356;&#22909;&#22320;&#29702;&#35299;&#20026;&#20160;&#20040;&#27880;&#24847;&#21147;&#23618;&#36866;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20123;&#20219;&#21153;&#35201;&#27714;&#39044;&#27979;&#27169;&#22411;&#25429;&#25417;&#19978;&#19979;&#25991;&#21547;&#20041;&#65292;&#21363;&#20351;&#21477;&#23376;&#24456;&#38271;&#65292;&#36825;&#24448;&#24448;&#21462;&#20915;&#20110;&#19968;&#20010;&#25110;&#20960;&#20010;&#35789;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#38543;&#26426;&#29305;&#24449;&#30340;&#20856;&#22411;&#35774;&#32622;&#20013;&#30740;&#31350;&#20102;&#36825;&#19968;&#20851;&#38190;&#23646;&#24615;&#65292;&#31216;&#20026;&#35789;&#25935;&#24863;&#24615;&#65288;WS&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27880;&#24847;&#21147;&#23618;&#20855;&#26377;&#36739;&#39640;&#30340;WS&#65292;&#21363;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#23384;&#22312;&#19968;&#20010;&#21521;&#37327;&#65292;&#33021;&#22815;&#22823;&#24133;&#25200;&#21160;&#38543;&#26426;&#27880;&#24847;&#21147;&#29305;&#24449;&#26144;&#23556;&#12290;&#36825;&#20010;&#35770;&#28857;&#20851;&#38190;&#22320;&#21033;&#29992;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;softmax&#30340;&#20316;&#29992;&#65292;&#31361;&#26174;&#20102;&#23427;&#30456;&#23545;&#20110;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;ReLU&#65289;&#30340;&#20248;&#21183;&#12290;&#30456;&#21453;&#65292;&#26631;&#20934;&#38543;&#26426;&#29305;&#24449;&#30340;WS&#26159;$1/\sqrt{n}$&#38454;&#30340;&#65292;$n$&#26159;&#25991;&#26412;&#26679;&#26412;&#20013;&#30340;&#21333;&#35789;&#25968;&#65292;&#22240;&#27492;&#23427;&#38543;&#19978;&#19979;&#25991;&#30340;&#38271;&#24230;&#32780;&#34928;&#20943;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#20851;&#20110;&#35789;&#25935;&#24863;&#24615;&#30340;&#32467;&#26524;&#36716;&#21270;&#20026;&#27867;&#21270;&#30028;&#65306;&#30001;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Unveiling the reasons behind the exceptional success of transformers requires a better understanding of why attention layers are suitable for NLP tasks. In particular, such tasks require predictive models to capture contextual meaning which often depends on one or few words, even if the sentence is long. Our work studies this key property, dubbed word sensitivity (WS), in the prototypical setting of random features. We show that attention layers enjoy high WS, namely, there exists a vector in the space of embeddings that largely perturbs the random attention features map. The argument critically exploits the role of the softmax in the attention layer, highlighting its benefit compared to other activations (e.g., ReLU). In contrast, the WS of standard random features is of order $1/\sqrt{n}$, $n$ being the number of words in the textual sample, and thus it decays with the length of the context. We then translate these results on the word sensitivity into generalization bounds: due to th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#30830;&#23450;&#24615;MoE&#27169;&#22411;&#19979;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#24378;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#26469;&#25551;&#36848;&#19981;&#21516;&#31867;&#22411;&#19987;&#23478;&#20989;&#25968;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;</title><link>https://arxiv.org/abs/2402.02952</link><description>&lt;p&gt;
&#20851;&#20110;Softmax Gating&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Least Squares Estimation in Softmax Gating Mixture of Experts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#30830;&#23450;&#24615;MoE&#27169;&#22411;&#19979;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#24378;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#26469;&#25551;&#36848;&#19981;&#21516;&#31867;&#22411;&#19987;&#23478;&#20989;&#25968;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#23478;&#27169;&#22411;&#26159;&#19968;&#31181;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#35774;&#35745;&#65292;&#20351;&#29992;Softmax Gating&#20989;&#25968;&#32858;&#21512;&#22810;&#20010;&#19987;&#23478;&#32593;&#32476;&#65292;&#20197;&#24418;&#25104;&#19968;&#20010;&#26356;&#22797;&#26434;&#21644;&#34920;&#36798;&#21147;&#26356;&#24378;&#30340;&#27169;&#22411;&#12290;&#23613;&#31649;&#30001;&#20110;&#21487;&#25193;&#23637;&#24615;&#32780;&#22312;&#22810;&#20010;&#24212;&#29992;&#39046;&#22495;&#20013;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;MoE&#27169;&#22411;&#30340;&#25968;&#23398;&#21644;&#32479;&#35745;&#24615;&#36136;&#22797;&#26434;&#19988;&#38590;&#20197;&#20998;&#26512;&#12290;&#22240;&#27492;&#65292;&#20197;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#27010;&#29575;MoE&#27169;&#22411;&#19978;&#65292;&#36825;&#20123;&#27169;&#22411;&#20551;&#35774;&#25968;&#25454;&#26159;&#30001;&#39640;&#26031;MoE&#27169;&#22411;&#29983;&#25104;&#30340;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#30830;&#23450;&#24615;MoE&#27169;&#22411;&#19979;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65288;LSE&#65289;&#30340;&#24615;&#33021;&#65292;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#25968;&#25454;&#26681;&#25454;&#22238;&#24402;&#27169;&#22411;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#26159;&#19968;&#20010;&#23578;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#31216;&#20026;&#24378;&#21487;&#35782;&#21035;&#24615;&#30340;&#26465;&#20214;&#65292;&#20197;&#34920;&#24449;&#19981;&#21516;&#31867;&#22411;&#19987;&#23478;&#20989;&#25968;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#24378;&#21487;&#35782;&#21035;&#19987;&#23478;&#30340;&#20272;&#35745;&#36895;&#24230;&#65292;&#21363;
&lt;/p&gt;
&lt;p&gt;
Mixture of experts (MoE) model is a statistical machine learning design that aggregates multiple expert networks using a softmax gating function in order to form a more intricate and expressive model. Despite being commonly used in several applications owing to their scalability, the mathematical and statistical properties of MoE models are complex and difficult to analyze. As a result, previous theoretical works have primarily focused on probabilistic MoE models by imposing the impractical assumption that the data are generated from a Gaussian MoE model. In this work, we investigate the performance of the least squares estimators (LSE) under a deterministic MoE model where the data are sampled according to a regression model, a setting that has remained largely unexplored. We establish a condition called strong identifiability to characterize the convergence behavior of various types of expert functions. We demonstrate that the rates for estimating strongly identifiable experts, namel
&lt;/p&gt;</description></item><item><title>$\textsf{DynaBRO}$&#26159;&#19968;&#31181;&#21160;&#24577;&#25308;&#21344;&#24237;-&#24378;&#40065;&#26834;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36866;&#24212;&#20999;&#25442;&#25308;&#21344;&#24237;&#24037;&#20316;&#26426;&#21046;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#19978;&#19982;&#38745;&#24577;&#24773;&#20917;&#30456;&#21305;&#37197;&#12290;&#36890;&#36807;&#22810;&#32423;&#33945;&#29305;&#21345;&#27931;&#28176;&#21464;&#20272;&#35745;&#25216;&#26415;&#12289;&#24378;&#40065;&#26834;&#24037;&#20316;&#26426;&#21046;&#26356;&#26032;&#30340;&#32858;&#21512;&#21644;&#25925;&#38556;&#23433;&#20840;&#36807;&#28388;&#22120;&#30340;&#24341;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#32463;&#21463;&#20303;$\mathcal{O}(\sqrt{T})$&#36718;&#25308;&#21344;&#24237;&#36523;&#20221;&#30340;&#25913;&#21464;&#12290;&#21478;&#22806;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#28040;&#38500;&#20102;&#23545;&#30334;&#20998;&#27604;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.02951</link><description>&lt;p&gt;
&#21160;&#24577;&#25308;&#21344;&#24237;-&#24378;&#40065;&#26834;&#23398;&#20064;&#65306;&#36866;&#24212;&#20999;&#25442;&#25308;&#21344;&#24237;&#24037;&#20316;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Dynamic Byzantine-Robust Learning: Adapting to Switching Byzantine Workers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02951
&lt;/p&gt;
&lt;p&gt;
$\textsf{DynaBRO}$&#26159;&#19968;&#31181;&#21160;&#24577;&#25308;&#21344;&#24237;-&#24378;&#40065;&#26834;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36866;&#24212;&#20999;&#25442;&#25308;&#21344;&#24237;&#24037;&#20316;&#26426;&#21046;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#19978;&#19982;&#38745;&#24577;&#24773;&#20917;&#30456;&#21305;&#37197;&#12290;&#36890;&#36807;&#22810;&#32423;&#33945;&#29305;&#21345;&#27931;&#28176;&#21464;&#20272;&#35745;&#25216;&#26415;&#12289;&#24378;&#40065;&#26834;&#24037;&#20316;&#26426;&#21046;&#26356;&#26032;&#30340;&#32858;&#21512;&#21644;&#25925;&#38556;&#23433;&#20840;&#36807;&#28388;&#22120;&#30340;&#24341;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#32463;&#21463;&#20303;$\mathcal{O}(\sqrt{T})$&#36718;&#25308;&#21344;&#24237;&#36523;&#20221;&#30340;&#25913;&#21464;&#12290;&#21478;&#22806;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#28040;&#38500;&#20102;&#23545;&#30334;&#20998;&#27604;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25308;&#21344;&#24237;-&#24378;&#40065;&#26834;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#31361;&#20986;&#30340;&#23481;&#38169;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#24050;&#32463;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#25216;&#26415;&#32771;&#34385;&#30340;&#26159;&#38745;&#24577;&#24773;&#20917;&#65292;&#20854;&#20013;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#25308;&#21344;&#24237;&#26426;&#22120;&#30340;&#36523;&#20221;&#20445;&#25345;&#19981;&#21464;&#12290;&#36825;&#31181;&#20551;&#35774;&#19981;&#33021;&#25429;&#25417;&#21040;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#21160;&#24577;&#25308;&#21344;&#24237;&#34892;&#20026;&#65292;&#21487;&#33021;&#21253;&#25324;&#30701;&#26242;&#25925;&#38556;&#25110;&#26377;&#38024;&#23545;&#24615;&#30340;&#26102;&#38388;&#25915;&#20987;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;$\textsf{DynaBRO}$&#65292;&#23427;&#33021;&#22815;&#32463;&#21463;&#20303;$\mathcal{O}(\sqrt{T})$&#36718;&#25308;&#21344;&#24237;&#36523;&#20221;&#30340;&#25913;&#21464;&#65288;&#20854;&#20013;$T$&#26159;&#24635;&#35757;&#32451;&#36718;&#25968;&#65289;&#65292;&#21516;&#26102;&#19982;&#38745;&#24577;&#24773;&#20917;&#19979;&#30340;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#22810;&#32423;&#33945;&#29305;&#21345;&#27931;&#65288;MLMC&#65289;&#28176;&#21464;&#20272;&#35745;&#25216;&#26415;&#19982;&#24037;&#20316;&#26426;&#21046;&#26356;&#26032;&#30340;&#24378;&#40065;&#26834;&#32858;&#21512;&#30456;&#32467;&#21512;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#25925;&#38556;&#23433;&#20840;&#36807;&#28388;&#22120;&#26469;&#38480;&#21046;&#21160;&#24577;&#25308;&#21344;&#24237;&#31574;&#30053;&#30340;&#20559;&#24046;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#21033;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#28040;&#38500;&#20102;&#23545;&#30334;&#20998;&#27604;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Byzantine-robust learning has emerged as a prominent fault-tolerant distributed machine learning framework. However, most techniques consider the static setting, wherein the identity of Byzantine machines remains fixed during the learning process. This assumption does not capture real-world dynamic Byzantine behaviors, which may include transient malfunctions or targeted temporal attacks. Addressing this limitation, we propose $\textsf{DynaBRO}$ -- a new method capable of withstanding $\mathcal{O}(\sqrt{T})$ rounds of Byzantine identity alterations (where $T$ is the total number of training rounds), while matching the asymptotic convergence rate of the static setting. Our method combines a multi-level Monte Carlo (MLMC) gradient estimation technique with robust aggregation of worker updates and incorporates a fail-safe filter to limit bias from dynamic Byzantine strategies. Additionally, by leveraging an adaptive learning rate, our approach eliminates the need for knowing the percentag
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#19981;&#21516;&#20013;&#24515;&#20998;&#21035;&#20998;&#26512;&#26412;&#22320;&#25968;&#25454;&#65292;&#24182;&#23558;&#32479;&#35745;&#25512;&#26029;&#32467;&#26524;&#32452;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#26679;&#26412;&#37327;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#24182;&#20934;&#30830;&#20272;&#35745;&#22238;&#24402;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.02898</link><description>&lt;p&gt;
&#20855;&#26377;&#24322;&#36136;&#22810;&#20013;&#24515;&#20154;&#32676;&#30340;&#22238;&#24402;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Bayesian Federated Inference for regression models with heterogeneous multi-center populations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02898
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#19981;&#21516;&#20013;&#24515;&#20998;&#21035;&#20998;&#26512;&#26412;&#22320;&#25968;&#25454;&#65292;&#24182;&#23558;&#32479;&#35745;&#25512;&#26029;&#32467;&#26524;&#32452;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#26679;&#26412;&#37327;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#24182;&#20934;&#30830;&#20272;&#35745;&#22238;&#24402;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20934;&#30830;&#20272;&#35745;&#22238;&#24402;&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;&#26679;&#26412;&#37327;&#24517;&#39035;&#30456;&#23545;&#20110;&#21487;&#33021;&#30340;&#39044;&#27979;&#21464;&#37327;&#20010;&#25968;&#36275;&#22815;&#22823;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#32570;&#20047;&#36275;&#22815;&#30340;&#25968;&#25454;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#36807;&#25311;&#21512;&#65292;&#24182;&#22240;&#27492;&#26080;&#27861;&#23545;&#26032;&#24739;&#32773;&#30340;&#32467;&#26524;&#36827;&#34892;&#21487;&#38752;&#39044;&#27979;&#12290;&#21512;&#24182;&#26469;&#33258;&#19981;&#21516;&#65288;&#21307;&#30103;&#65289;&#20013;&#24515;&#25910;&#38598;&#30340;&#25968;&#25454;&#21487;&#20197;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#36890;&#24120;&#30001;&#20110;&#38544;&#31169;&#27861;&#35268;&#25110;&#29289;&#27969;&#38382;&#39064;&#32780;&#19981;&#21487;&#34892;&#12290;&#21478;&#19968;&#31181;&#26041;&#27861;&#26159;&#20998;&#26512;&#21508;&#20010;&#20013;&#24515;&#30340;&#26412;&#22320;&#25968;&#25454;&#65292;&#28982;&#21518;&#20351;&#29992;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#65288;BFI&#65289;&#26041;&#27861;&#23558;&#32479;&#35745;&#25512;&#26029;&#32467;&#26524;&#36827;&#34892;&#32452;&#21512;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#30446;&#26631;&#26159;&#20174;&#21508;&#20010;&#20013;&#24515;&#30340;&#25512;&#26029;&#32467;&#26524;&#20013;&#35745;&#31639;&#20986;&#22914;&#26524;&#23545;&#32452;&#21512;&#25968;&#25454;&#36827;&#34892;&#20102;&#32479;&#35745;&#20998;&#26512;&#21518;&#20250;&#24471;&#21040;&#20160;&#20040;&#32467;&#26524;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#21516;&#36136;&#21644;&#24322;&#36136;&#20013;&#24515;&#20154;&#32676;&#19979;&#30340;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#30495;&#23454;&#30340;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
To estimate accurately the parameters of a regression model, the sample size must be large enough relative to the number of possible predictors for the model. In practice, sufficient data is often lacking, which can lead to overfitting of the model and, as a consequence, unreliable predictions of the outcome of new patients. Pooling data from different data sets collected in different (medical) centers would alleviate this problem, but is often not feasible due to privacy regulation or logistic problems. An alternative route would be to analyze the local data in the centers separately and combine the statistical inference results with the Bayesian Federated Inference (BFI) methodology. The aim of this approach is to compute from the inference results in separate centers what would have been found if the statistical analysis was performed on the combined data. We explain the methodology under homogeneity and heterogeneity across the populations in the separate centers, and give real lif
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#22270;&#31070;&#32463;&#26426;&#22120;&#65288;GNM&#65289;&#65292;&#29992;&#20110;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#12290;GNM&#20351;&#29992;&#21516;&#27493;&#28040;&#24687;&#20256;&#36882;&#26041;&#26696;&#65292;&#24182;&#29992;&#20960;&#20046;&#23436;&#20840;&#22270;&#20195;&#26367;&#20102;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#65292;GNM&#27169;&#22411;&#30340;&#24615;&#33021;&#20248;&#20110;MLP&#26550;&#26500;&#12290;</title><link>https://arxiv.org/abs/2402.02862</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#26426;&#22120;&#65306;&#19968;&#31181;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#30340;&#26032;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Machine: A New Model for Learning with Tabular Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02862
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#22270;&#31070;&#32463;&#26426;&#22120;&#65288;GNM&#65289;&#65292;&#29992;&#20110;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#12290;GNM&#20351;&#29992;&#21516;&#27493;&#28040;&#24687;&#20256;&#36882;&#26041;&#26696;&#65292;&#24182;&#29992;&#20960;&#20046;&#23436;&#20840;&#22270;&#20195;&#26367;&#20102;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#65292;GNM&#27169;&#22411;&#30340;&#24615;&#33021;&#20248;&#20110;MLP&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#23545;&#23558;&#19981;&#21516;&#39046;&#22495;&#30340;&#25968;&#25454;&#26144;&#23556;&#21040;&#22270;&#32467;&#26500;&#30340;&#26041;&#27861;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#12290;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#22914;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#21487;&#20197;&#34987;&#24314;&#27169;&#20026;&#22270;&#12290;&#20107;&#23454;&#19978;&#65292;MLP&#21487;&#20197;&#34920;&#31034;&#20026;&#26377;&#21521;&#26080;&#29615;&#22270;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26368;&#36817;&#24050;&#25104;&#20026;&#22312;&#22270;&#19978;&#25191;&#34892;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#30340;&#26631;&#20934;&#24037;&#20855;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MLP&#31561;&#20215;&#20110;&#19968;&#20010;&#22522;&#20110;&#24322;&#27493;&#28040;&#24687;&#20256;&#36882;&#30340;GNN&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;MLP&#30340;&#22270;&#34920;&#31034;&#19978;&#25805;&#20316;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;&#22270;&#31070;&#32463;&#26426;&#22120;&#65288;GNM&#65289;&#65292;&#23427;&#29992;&#19968;&#20010;&#20960;&#20046;&#23436;&#20840;&#22270;&#21462;&#20195;&#20102;MLP&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65292;&#24182;&#37319;&#29992;&#21516;&#27493;&#28040;&#24687;&#20256;&#36882;&#26041;&#26696;&#12290;&#25105;&#20204;&#34920;&#26126;&#21333;&#20010;GNM&#27169;&#22411;&#21487;&#20197;&#27169;&#25311;&#22810;&#20010;MLP&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#20998;&#31867;&#21644;&#22238;&#24402;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#12290;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;GNM&#27169;&#22411;&#20248;&#20110;MLP&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been a growing interest in mapping data from different domains to graph structures. Among others, neural network models such as the multi-layer perceptron (MLP) can be modeled as graphs. In fact, MLPs can be represented as directed acyclic graphs. Graph neural networks (GNNs) have recently become the standard tool for performing machine learning tasks on graphs. In this work, we show that an MLP is equivalent to an asynchronous message passing GNN model which operates on the MLP's graph representation. We then propose a new machine learning model for tabular data, the so-called Graph Neural Machine (GNM), which replaces the MLP's directed acyclic graph with a nearly complete graph and which employs a synchronous message passing scheme. We show that a single GNM model can simulate multiple MLP models. We evaluate the proposed model in several classification and regression datasets. In most cases, the GNM model outperforms the MLP architecture.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38646;&#21644;&#28216;&#25103;&#20013;&#21033;&#29992;&#22024;&#26434;&#35266;&#23519;&#30340;&#20248;&#21183;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#23545;&#32473;&#23450;&#27010;&#29575;&#27979;&#24230;&#36827;&#34892;&#37319;&#26679;&#65292;&#39046;&#23548;&#32773;&#25215;&#35834;&#23545;&#25163;&#36873;&#25321;&#34892;&#21160;&#65292;&#32780;&#36861;&#38543;&#32773;&#26681;&#25454;&#20854;&#24403;&#21069;&#20449;&#24687;&#36873;&#25321;&#34892;&#21160;&#12290;&#35777;&#26126;&#20102;&#24102;&#26377;&#22024;&#26434;&#34892;&#21160;&#21487;&#35266;&#27979;&#24615;&#30340;&#21338;&#24328;&#24635;&#26159;&#23384;&#22312;&#22343;&#34913;&#65292;&#19988;&#37492;&#23450;&#20102;&#20854;&#21807;&#19968;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#22024;&#26434;&#35266;&#23519;&#23545;&#36861;&#38543;&#32773;&#30340;&#26368;&#20339;&#21709;&#24212;&#38598;&#21512;&#30340;&#22522;&#25968;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.02861</link><description>&lt;p&gt;
&#21033;&#29992;&#22024;&#26434;&#35266;&#23519;&#22312;&#38646;&#21644;&#28216;&#25103;&#20013;&#30340;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Leveraging Noisy Observations in Zero-Sum Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38646;&#21644;&#28216;&#25103;&#20013;&#21033;&#29992;&#22024;&#26434;&#35266;&#23519;&#30340;&#20248;&#21183;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#23545;&#32473;&#23450;&#27010;&#29575;&#27979;&#24230;&#36827;&#34892;&#37319;&#26679;&#65292;&#39046;&#23548;&#32773;&#25215;&#35834;&#23545;&#25163;&#36873;&#25321;&#34892;&#21160;&#65292;&#32780;&#36861;&#38543;&#32773;&#26681;&#25454;&#20854;&#24403;&#21069;&#20449;&#24687;&#36873;&#25321;&#34892;&#21160;&#12290;&#35777;&#26126;&#20102;&#24102;&#26377;&#22024;&#26434;&#34892;&#21160;&#21487;&#35266;&#27979;&#24615;&#30340;&#21338;&#24328;&#24635;&#26159;&#23384;&#22312;&#22343;&#34913;&#65292;&#19988;&#37492;&#23450;&#20102;&#20854;&#21807;&#19968;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#22024;&#26434;&#35266;&#23519;&#23545;&#36861;&#38543;&#32773;&#30340;&#26368;&#20339;&#21709;&#24212;&#38598;&#21512;&#30340;&#22522;&#25968;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#38646;&#21644;&#28216;&#25103;&#30340;&#23454;&#20363;&#65292;&#20854;&#20013;&#19968;&#20301;&#29609;&#23478;&#65288;&#39046;&#23548;&#32773;&#65289;&#25215;&#35834;&#23545;&#25163;&#65288;&#36861;&#38543;&#32773;&#65289;&#36890;&#36807;&#23545;&#32473;&#23450;&#27010;&#29575;&#27979;&#24230;&#65288;&#31574;&#30053;&#65289;&#36827;&#34892;&#37319;&#26679;&#26469;&#36873;&#25321;&#34892;&#21160;&#12290;&#39046;&#23548;&#32773;&#30340;&#34892;&#21160;&#30001;&#36861;&#38543;&#32773;&#20316;&#20026;&#20219;&#24847;&#20449;&#36947;&#30340;&#36755;&#20986;&#35266;&#23519;&#21040;&#12290;&#20316;&#20026;&#22238;&#24212;&#65292;&#36861;&#38543;&#32773;&#26681;&#25454;&#20854;&#24403;&#21069;&#20449;&#24687;&#36873;&#25321;&#34892;&#21160;&#65292;&#21363;&#39046;&#23548;&#32773;&#30340;&#25215;&#35834;&#21644;&#30456;&#24212;&#34892;&#21160;&#30340;&#22024;&#26434;&#35266;&#23519;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35777;&#26126;&#20102;&#24102;&#26377;&#22024;&#26434;&#34892;&#21160;&#21487;&#35266;&#27979;&#24615;&#30340;&#21338;&#24328;&#24635;&#26159;&#23384;&#22312;&#22343;&#34913;&#65292;&#24182;&#19988;&#30830;&#23450;&#20102;&#20854;&#21807;&#19968;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22024;&#26434;&#35266;&#23519;&#23545;&#36861;&#38543;&#32773;&#30340;&#26368;&#20339;&#21709;&#24212;&#38598;&#21512;&#30340;&#22522;&#25968;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#36825;&#26679;&#30340;&#26368;&#20339;&#21709;&#24212;&#38598;&#21512;&#20960;&#20046;&#24517;&#28982;&#26159;&#21333;&#20363;&#38598;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#21487;&#20197;&#25429;&#25417;&#21040;&#19982;&#21202;&#36125;&#26684;&#27979;&#24230;&#30456;&#23545;&#30340;&#20219;&#20309;&#20449;&#36947;&#22122;&#22768;&#12290;&#20316;&#20026;&#20363;&#23376;&#65292;&#32771;&#34385;&#20102;&#20449;&#36947;&#22122;&#22768;&#19982;Lebesgue&#27979;&#24230;&#30340;&#23494;&#24230;&#26377;&#20851;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies an instance of zero-sum games in which one player (the leader) commits to its opponent (the follower) to choose its actions by sampling a given probability measure (strategy). The actions of the leader are observed by the follower as the output of an arbitrary channel. In response to that, the follower chooses its action based on its current information, that is, the leader's commitment and the corresponding noisy observation of its action. Within this context, the equilibrium of the game with noisy action observability is shown to always exist and the necessary conditions for its uniqueness are identified. Interestingly, the noisy observations have important impact on the cardinality of the follower's set of best responses. Under particular conditions, such a set of best responses is proved to be a singleton almost surely. The proposed model captures any channel noise with a density with respect to the Lebesgue measure. As an example, the case in which the channel i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20013;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#24179;&#28369;&#20998;&#24067;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#22312;&#31163;&#32447;&#21644;&#30495;&#27491;&#30340;&#22312;&#32447;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02859</link><description>&lt;p&gt;
&#22312;&#32447;&#21464;&#20998;&#23398;&#20064;&#20013;&#30340;&#37325;&#35201;&#24615;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Importance sampling for online variational learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20013;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#24179;&#28369;&#20998;&#24067;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#22312;&#31163;&#32447;&#21644;&#30495;&#27491;&#30340;&#22312;&#32447;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20013;&#30340;&#22312;&#32447;&#21464;&#20998;&#20272;&#35745;&#38382;&#39064;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#23398;&#20064;&#24179;&#28369;&#20998;&#24067;&#65292;&#21363;&#32473;&#23450;&#35266;&#27979;&#30340;&#28508;&#22312;&#29366;&#24577;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#37319;&#29992;&#21464;&#20998;&#26041;&#27861;&#21644;&#33945;&#29305;&#21345;&#32599;&#37325;&#35201;&#24615;&#37319;&#26679;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27969;&#25968;&#25454;&#24773;&#20917;&#19979;&#35745;&#31639;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#26799;&#24230;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#20854;&#20013;&#35266;&#27979;&#20540;&#25353;&#39034;&#24207;&#21040;&#36798;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#22312;&#32447;ELBO&#20272;&#35745;&#22120;&#65292;&#22312;&#31163;&#32447;&#21644;&#30495;&#27491;&#30340;&#22312;&#32447;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#24615;&#33021;&#65292;&#24182;&#36866;&#29992;&#20110;&#35745;&#31639;&#20851;&#20110;&#32852;&#21512;&#24179;&#28369;&#20998;&#24067;&#30340;&#19968;&#33324;&#26399;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article addresses online variational estimation in state-space models. We focus on learning the smoothing distribution, i.e. the joint distribution of the latent states given the observations, using a variational approach together with Monte Carlo importance sampling.  We propose an efficient algorithm for computing the gradient of the evidence lower bound (ELBO) in the context of streaming data, where observations arrive sequentially.  Our contributions include a computationally efficient online ELBO estimator, demonstrated performance in offline and true online settings, and adaptability for computing general expectations under joint smoothing distributions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#27604;&#20102;&#22312;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#20351;&#29992;&#28145;&#24230;&#33258;&#22238;&#24402;&#23494;&#24230;&#32593;&#32476;&#21644;&#31070;&#32463;&#38598;&#21512;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#22312;D4RL&#22522;&#20934;&#27979;&#35797;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#36136;&#30097;&#20102;&#20351;&#29992;&#31070;&#32463;&#38598;&#21512;&#30340;&#26222;&#36941;&#35266;&#28857;&#65292;&#24182;&#21457;&#29616;&#21333;&#20010;&#33391;&#22909;&#26657;&#20934;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#27169;&#22411;&#23398;&#20064;&#30340;&#38745;&#24577;&#25351;&#26631;&#65292;&#24182;&#24471;&#20986;&#20102;&#20851;&#20110;&#20195;&#29702;&#26368;&#32456;&#24615;&#33021;&#30340;&#37325;&#35201;&#27169;&#22411;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02858</link><description>&lt;p&gt;
&#28145;&#24230;&#33258;&#22238;&#24402;&#23494;&#24230;&#32593;&#32476;&#19982;&#31070;&#32463;&#38598;&#21512;&#22312;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23545;&#27604;
&lt;/p&gt;
&lt;p&gt;
Deep autoregressive density nets vs neural ensembles for model-based offline reinforcement learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#27604;&#20102;&#22312;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#20351;&#29992;&#28145;&#24230;&#33258;&#22238;&#24402;&#23494;&#24230;&#32593;&#32476;&#21644;&#31070;&#32463;&#38598;&#21512;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#22312;D4RL&#22522;&#20934;&#27979;&#35797;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#36136;&#30097;&#20102;&#20351;&#29992;&#31070;&#32463;&#38598;&#21512;&#30340;&#26222;&#36941;&#35266;&#28857;&#65292;&#24182;&#21457;&#29616;&#21333;&#20010;&#33391;&#22909;&#26657;&#20934;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#27169;&#22411;&#23398;&#20064;&#30340;&#38745;&#24577;&#25351;&#26631;&#65292;&#24182;&#24471;&#20986;&#20102;&#20851;&#20110;&#20195;&#29702;&#26368;&#32456;&#24615;&#33021;&#30340;&#37325;&#35201;&#27169;&#22411;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20165;&#26377;&#31995;&#32479;&#36716;&#25442;&#38598;&#21512;&#21487;&#29992;&#20110;&#31574;&#30053;&#20248;&#21270;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#36827;&#23637;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20174;&#21487;&#29992;&#25968;&#25454;&#20013;&#25512;&#26029;&#31995;&#32479;&#21160;&#24577;&#65292;&#24182;&#22312;&#27169;&#22411;&#25512;&#28436;&#19978;&#36827;&#34892;&#31574;&#30053;&#20248;&#21270;&#12290;&#36825;&#31181;&#26041;&#27861;&#23481;&#26131;&#21463;&#21040;&#27169;&#22411;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#22312;&#30495;&#23454;&#31995;&#32479;&#19978;&#30340;&#28798;&#38590;&#24615;&#22833;&#36133;&#12290;&#26631;&#20934;&#35299;&#20915;&#26041;&#26696;&#26159;&#20381;&#38752;&#38598;&#21512;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#21551;&#21457;&#24335;&#65292;&#24182;&#36991;&#20813;&#22312;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#22826;&#22823;&#26102;&#21033;&#29992;&#27169;&#22411;&#12290;&#36890;&#36807;&#23637;&#31034;&#22312;D4RL&#22522;&#20934;&#27979;&#35797;&#19978;&#20351;&#29992;&#21333;&#20010;&#33391;&#22909;&#26657;&#20934;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#36136;&#30097;&#20102;&#24517;&#39035;&#20351;&#29992;&#38598;&#21512;&#30340;&#26222;&#36941;&#35266;&#28857;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#19982;&#27169;&#22411;&#23398;&#20064;&#26377;&#20851;&#30340;&#38745;&#24577;&#25351;&#26631;&#65292;&#24182;&#24471;&#20986;&#20102;&#20851;&#20110;&#20195;&#29702;&#30340;&#26368;&#32456;&#24615;&#33021;&#30340;&#37325;&#35201;&#27169;&#22411;&#29305;&#24615;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of offline reinforcement learning where only a set of system transitions is made available for policy optimization. Following recent advances in the field, we consider a model-based reinforcement learning algorithm that infers the system dynamics from the available data and performs policy optimization on imaginary model rollouts. This approach is vulnerable to exploiting model errors which can lead to catastrophic failures on the real system. The standard solution is to rely on ensembles for uncertainty heuristics and to avoid exploiting the model where it is too uncertain. We challenge the popular belief that we must resort to ensembles by showing that better performance can be obtained with a single well-calibrated autoregressive model on the D4RL benchmark. We also analyze static metrics of model-learning and conclude on the important model properties for the final performance of the agent.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20110;&#20855;&#26377;&#20559;&#24577;&#26799;&#24230;&#21644;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;SGD&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;Adagrad&#21644;RMSProp&#31639;&#27861;&#22312;&#25910;&#25947;&#36895;&#24230;&#19978;&#19982;&#26080;&#20559;&#24773;&#20917;&#30456;&#20284;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25910;&#25947;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#38477;&#20302;&#20559;&#24046;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.02857</link><description>&lt;p&gt;
&#20559;&#24577;&#33258;&#36866;&#24212;&#38543;&#26426;&#36924;&#36817;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic Analysis of Biased Adaptive Stochastic Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20110;&#20855;&#26377;&#20559;&#24577;&#26799;&#24230;&#21644;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;SGD&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;Adagrad&#21644;RMSProp&#31639;&#27861;&#22312;&#25910;&#25947;&#36895;&#24230;&#19978;&#19982;&#26080;&#20559;&#24773;&#20917;&#30456;&#20284;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25910;&#25947;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#38477;&#20302;&#20559;&#24046;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#29616;&#22312;&#24191;&#27867;&#29992;&#20110;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#22823;&#22810;&#25968;&#29702;&#35770;&#32467;&#26524;&#20551;&#35774;&#21487;&#20197;&#33719;&#24471;&#26080;&#20559;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#28982;&#32780;&#22312;&#19968;&#20123;&#26368;&#36817;&#30340;&#28145;&#24230;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#20351;&#29992;&#20102;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#21364;&#26080;&#27861;&#28385;&#36275;&#36825;&#19968;&#20551;&#35774;&#12290;&#26412;&#25991;&#23545;&#20855;&#26377;&#20559;&#24577;&#26799;&#24230;&#21644;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;SGD&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#38750;&#28176;&#36827;&#24615;&#20998;&#26512;&#65292;&#38024;&#23545;&#20984;&#21644;&#38750;&#20984;&#24179;&#28369;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21253;&#25324;&#26102;&#21464;&#20559;&#24046;&#65292;&#24182;&#24378;&#35843;&#25511;&#21046;&#20559;&#24046;&#21644;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#26799;&#24230;&#20272;&#35745;&#30340;&#37325;&#35201;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#20559;&#24577;&#26799;&#24230;&#30340;Adagrad&#21644;RMSProp&#31639;&#27861;&#23545;&#20110;&#38750;&#20984;&#24179;&#28369;&#20989;&#25968;&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#25991;&#29486;&#20013;&#26080;&#20559;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#30456;&#20284;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36866;&#24403;&#30340;&#26041;&#27861;&#38477;&#20302;&#20559;&#24046;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent (SGD) with adaptive steps is now widely used for training deep neural networks. Most theoretical results assume access to unbiased gradient estimators, which is not the case in several recent deep learning and reinforcement learning applications that use Monte Carlo methods. This paper provides a comprehensive non-asymptotic analysis of SGD with biased gradients and adaptive steps for convex and non-convex smooth functions. Our study incorporates time-dependent bias and emphasizes the importance of controlling the bias and Mean Squared Error (MSE) of the gradient estimator. In particular, we establish that Adagrad and RMSProp with biased gradients converge to critical points for smooth non-convex functions at a rate similar to existing results in the literature for the unbiased case. Finally, we provide experimental results using Variational Autoenconders (VAE) that illustrate our convergence results and show how the effect of bias can be reduced by appropri
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32452;&#21512;&#29305;&#24449;&#23545;&#40784;&#65292;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#32452;&#21512;&#36890;&#29992;&#24615;&#65292;&#20351;&#20854;&#33021;&#22815;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30340;&#39046;&#22495;-&#31867;&#21035;&#32452;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.02851</link><description>&lt;p&gt;
&#36890;&#36807;&#32452;&#21512;&#29305;&#24449;&#23545;&#40784;&#22686;&#24378;&#32452;&#21512;&#36890;&#29992;&#24615;
&lt;/p&gt;
&lt;p&gt;
Enhancing Compositional Generalization via Compositional Feature Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02851
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32452;&#21512;&#29305;&#24449;&#23545;&#40784;&#65292;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#32452;&#21512;&#36890;&#29992;&#24615;&#65292;&#20351;&#20854;&#33021;&#22815;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30340;&#39046;&#22495;-&#31867;&#21035;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#32463;&#24120;&#38754;&#20020;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#38382;&#39064;&#65292;&#21363;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#12290;&#22312;&#24120;&#35265;&#30340;&#22810;&#39046;&#22495;&#22810;&#31867;&#21035;&#35774;&#32622;&#20013;&#65292;&#38543;&#30528;&#31867;&#21035;&#21644;&#39046;&#22495;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#24456;&#38590;&#20026;&#27599;&#20010;&#39046;&#22495;-&#31867;&#21035;&#32452;&#21512;&#25910;&#38598;&#35757;&#32451;&#25968;&#25454;&#12290;&#36825;&#20010;&#25361;&#25112;&#33258;&#28982;&#22320;&#24341;&#21457;&#20102;&#23545;&#20855;&#22791;&#32452;&#21512;&#36890;&#29992;&#24615;&#65288;CG&#65289;&#33021;&#21147;&#30340;&#27169;&#22411;&#30340;&#25506;&#32034;&#65292;&#21363;&#27169;&#22411;&#21487;&#20197;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30340;&#39046;&#22495;-&#31867;&#21035;&#32452;&#21512;&#12290;&#20026;&#20102;&#28145;&#20837;&#30740;&#31350;CG&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;CG-Bench&#65292;&#36825;&#26159;&#19968;&#22871;&#20174;&#29616;&#26377;&#23454;&#38469;&#22270;&#20687;&#25968;&#25454;&#38598;&#27966;&#29983;&#30340;CG&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#35266;&#23519;&#21040;&#30446;&#21069;&#22312;&#22522;&#30784;&#27169;&#22411;&#65288;&#22914;CLIP&#21644;DINOv2&#65289;&#19978;&#27969;&#34892;&#30340;&#39044;&#35757;&#32451;-&#24494;&#35843;&#33539;&#24335;&#22312;&#36825;&#20010;&#25361;&#25112;&#20013;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32452;&#21512;&#29305;&#24449;&#23545;&#40784;&#65288;CFA&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#24494;&#35843;&#25216;&#26415;&#65292;&#23427;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#32534;&#30721;&#22120;&#19978;&#23398;&#20064;&#20004;&#20010;&#27491;&#20132;&#32447;&#24615;&#22836;&#37096;&#26469;&#23545;&#40784;&#31867;&#21035;&#21644;&#39046;&#22495;&#30340;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world applications of machine learning models often confront data distribution shifts, wherein discrepancies exist between the training and test data distributions. In the common multi-domain multi-class setup, as the number of classes and domains scales up, it becomes infeasible to gather training data for every domain-class combination. This challenge naturally leads the quest for models with Compositional Generalization (CG) ability, where models can generalize to unseen domain-class combinations. To delve into the CG challenge, we develop CG-Bench, a suite of CG benchmarks derived from existing real-world image datasets, and observe that the prevalent pretraining-finetuning paradigm on foundational models, such as CLIP and DINOv2, struggles with the challenge. To address this challenge, we propose Compositional Feature Alignment (CFA), a simple two-stage finetuning technique that i) learns two orthogonal linear heads on a pretrained encoder with respect to class and domain lab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#26469;&#26368;&#23567;&#21270;&#20998;&#31867;&#38169;&#35823;&#65292;&#24182;&#22312;&#32473;&#23450;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#12290;&#35813;&#26041;&#27861;&#24341;&#20837;&#20102;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#30340;&#27010;&#24565;&#65292;&#24182;&#25214;&#21040;&#20102;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#30340;&#24418;&#24335;&#12290;&#26412;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#22810;&#20010;&#20844;&#24179;&#24615;&#32422;&#26463;&#21644;&#24120;&#35265;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2402.02817</link><description>&lt;p&gt;
&#22522;&#20110;&#20808;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#30340;&#32447;&#24615;&#24046;&#24322;&#32422;&#26463;&#19979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Bayes-Optimal Fair Classification with Linear Disparity Constraints via Pre-, In-, and Post-processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#22788;&#29702;&#12289;&#20013;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#26469;&#26368;&#23567;&#21270;&#20998;&#31867;&#38169;&#35823;&#65292;&#24182;&#22312;&#32473;&#23450;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#12290;&#35813;&#26041;&#27861;&#24341;&#20837;&#20102;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#30340;&#27010;&#24565;&#65292;&#24182;&#25214;&#21040;&#20102;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#30340;&#24418;&#24335;&#12290;&#26412;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#22810;&#20010;&#20844;&#24179;&#24615;&#32422;&#26463;&#21644;&#24120;&#35265;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#33021;&#23545;&#21463;&#20445;&#25252;&#30340;&#32676;&#20307;&#20135;&#29983;&#19981;&#20844;&#24179;&#30340;&#24433;&#21709;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#32473;&#23450;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#26368;&#23567;&#21270;&#20998;&#31867;&#38169;&#35823;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#30340;&#27010;&#24565;&#65292;&#23427;&#20204;&#26159;&#27010;&#29575;&#20998;&#31867;&#22120;&#30340;&#32447;&#24615;&#20989;&#25968;&#65307;&#20197;&#21450;&#21452;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#65292;&#23427;&#20204;&#22312;&#32676;&#20307;&#22238;&#24402;&#20989;&#25968;&#26041;&#38754;&#20063;&#26159;&#32447;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20960;&#31181;&#24120;&#35265;&#30340;&#24046;&#24322;&#24230;&#37327;&#65288;&#22914;&#20154;&#21475;&#24179;&#31561;&#12289;&#26426;&#20250;&#24179;&#31561;&#21644;&#39044;&#27979;&#24179;&#31561;&#65289;&#37117;&#26159;&#21452;&#32447;&#24615;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#25581;&#31034;&#19982;Neyman-Pearson&#24341;&#29702;&#30340;&#36830;&#25509;&#65292;&#25214;&#21040;&#20102;&#22312;&#21333;&#19968;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#19979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#30340;&#24418;&#24335;&#12290;&#23545;&#20110;&#21452;&#32447;&#24615;&#24046;&#24322;&#24230;&#37327;&#65292;&#36125;&#21494;&#26031;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#21464;&#25104;&#20102;&#32676;&#20307;&#38408;&#20540;&#35268;&#21017;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#22788;&#29702;&#22810;&#20010;&#20844;&#24179;&#24615;&#32422;&#26463;&#65288;&#22914;&#24179;&#31561;&#30340;&#20960;&#29575;&#65289;&#21644;&#21463;&#20445;&#25252;&#23646;&#24615;&#24120;&#35265;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning algorithms may have disparate impacts on protected groups. To address this, we develop methods for Bayes-optimal fair classification, aiming to minimize classification error subject to given group fairness constraints. We introduce the notion of \emph{linear disparity measures}, which are linear functions of a probabilistic classifier; and \emph{bilinear disparity measures}, which are also linear in the group-wise regression functions. We show that several popular disparity measures -- the deviations from demographic parity, equality of opportunity, and predictive equality -- are bilinear.   We find the form of Bayes-optimal fair classifiers under a single linear disparity measure, by uncovering a connection with the Neyman-Pearson lemma. For bilinear disparity measures, Bayes-optimal fair classifiers become group-wise thresholding rules. Our approach can also handle multiple fairness constraints (such as equalized odds), and the common scenario when the protected attr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;Koopman&#31639;&#23376;&#30340;&#20840;&#23616;&#36229;&#26799;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#36229;&#26799;&#24230;&#30340;&#36712;&#36857;&#26469;&#39640;&#25928;&#22320;&#36817;&#20284;&#20840;&#23616;&#36229;&#26799;&#24230;&#65292;&#23454;&#29616;&#20102;&#36229;&#21442;&#25968;&#30340;&#36138;&#23146;&#20248;&#21270;&#65292;&#20860;&#20855;&#21487;&#38752;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.02741</link><description>&lt;p&gt;
&#20855;&#26377;Koopman&#31639;&#23376;&#30340;&#20840;&#23616;&#36229;&#26799;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Glocal Hypergradient Estimation with Koopman Operator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02741
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;Koopman&#31639;&#23376;&#30340;&#20840;&#23616;&#36229;&#26799;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#36229;&#26799;&#24230;&#30340;&#36712;&#36857;&#26469;&#39640;&#25928;&#22320;&#36817;&#20284;&#20840;&#23616;&#36229;&#26799;&#24230;&#65292;&#23454;&#29616;&#20102;&#36229;&#21442;&#25968;&#30340;&#36138;&#23146;&#20248;&#21270;&#65292;&#20860;&#20855;&#21487;&#38752;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26799;&#24230;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#20351;&#29992;&#36229;&#26799;&#24230;&#26469;&#26356;&#26032;&#36229;&#21442;&#25968;&#65292;&#21363;&#20803;&#26631;&#20934;&#30340;&#26799;&#24230;&#19982;&#36229;&#21442;&#25968;&#30340;&#20851;&#31995;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20351;&#29992;&#20004;&#31181;&#19981;&#21516;&#30340;&#26356;&#26032;&#31574;&#30053;&#65306;&#19968;&#31181;&#26159;&#20351;&#29992;&#27169;&#22411;&#35757;&#32451;&#23436;&#25104;&#21518;&#24471;&#21040;&#30340;&#20840;&#23616;&#36229;&#26799;&#24230;&#26469;&#20248;&#21270;&#36229;&#21442;&#25968;&#65292;&#21478;&#19968;&#31181;&#26159;&#20351;&#29992;&#27599;&#20010;&#27169;&#22411;&#26356;&#26032;&#20043;&#21518;&#24471;&#21040;&#30340;&#23616;&#37096;&#36229;&#26799;&#24230;&#12290;&#34429;&#28982;&#20840;&#23616;&#36229;&#26799;&#24230;&#20855;&#26377;&#21487;&#38752;&#24615;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#26174;&#33879;&#65307;&#30456;&#21453;&#65292;&#23616;&#37096;&#36229;&#26799;&#24230;&#36895;&#24230;&#24555;&#20294;&#24120;&#24120;&#19981;&#26159;&#26368;&#20248;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;glocal&#36229;&#26799;&#24230;&#20272;&#35745;&#65292;&#23558;&#8220;&#20840;&#23616;&#8221;&#30340;&#36136;&#37327;&#19982;&#8220;&#23616;&#37096;&#8221;&#30340;&#25928;&#29575;&#32467;&#21512;&#36215;&#26469;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;Koopman&#31639;&#23376;&#29702;&#35770;&#26469;&#32447;&#24615;&#21270;&#36229;&#26799;&#24230;&#30340;&#21160;&#24577;&#65292;&#20197;&#20415;&#21487;&#20197;&#20165;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#36229;&#26799;&#24230;&#30340;&#36712;&#36857;&#26469;&#39640;&#25928;&#22320;&#36817;&#20284;&#20840;&#23616;&#36229;&#26799;&#24230;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#20272;&#35745;&#30340;&#20840;&#23616;&#36229;&#26799;&#24230;&#36138;&#23146;&#22320;&#20248;&#21270;&#36229;&#21442;&#25968;&#65292;&#21516;&#26102;&#23454;&#29616;&#21487;&#38752;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-based hyperparameter optimization methods update hyperparameters using hypergradients, gradients of a meta criterion with respect to hyperparameters. Previous research used two distinct update strategies: optimizing hyperparameters using global hypergradients obtained after completing model training or local hypergradients derived after every few model updates. While global hypergradients offer reliability, their computational cost is significant; conversely, local hypergradients provide speed but are often suboptimal. In this paper, we propose glocal hypergradient estimation, blending "global" quality with "local" efficiency. To this end, we use the Koopman operator theory to linearize the dynamics of hypergradients so that the global hypergradients can be efficiently approximated only by using a trajectory of local hypergradients. Consequently, we can optimize hyperparameters greedily using estimated global hypergradients, achieving both reliability and efficiency simultaneo
&lt;/p&gt;</description></item><item><title>InVA&#26159;&#19968;&#31181;&#32508;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#27169;&#24577;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20013;&#19981;&#21516;&#26469;&#28304;&#30340;&#22810;&#20010;&#22270;&#20687;&#26469;&#36827;&#34892;&#39044;&#27979;&#25512;&#29702;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;VAE&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.02734</link><description>&lt;p&gt;
InVA: &#32508;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#22810;&#27169;&#24577;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#30340;&#21327;&#35843;
&lt;/p&gt;
&lt;p&gt;
InVA: Integrative Variational Autoencoder for Harmonization of Multi-modal Neuroimaging Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02734
&lt;/p&gt;
&lt;p&gt;
InVA&#26159;&#19968;&#31181;&#32508;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#27169;&#24577;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20013;&#19981;&#21516;&#26469;&#28304;&#30340;&#22810;&#20010;&#22270;&#20687;&#26469;&#36827;&#34892;&#39044;&#27979;&#25512;&#29702;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;VAE&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25506;&#32034;&#22810;&#20010;&#26469;&#33258;&#19981;&#21516;&#25104;&#20687;&#27169;&#24335;&#30340;&#22270;&#20687;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#32852;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#23613;&#31649;&#26377;&#36234;&#26469;&#36234;&#22810;&#30340;&#25991;&#29486;&#30740;&#31350;&#22522;&#20110;&#22810;&#20010;&#22270;&#20687;&#26469;&#25512;&#26029;&#22270;&#20687;&#30340;&#39044;&#27979;&#25512;&#29702;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#22312;&#26377;&#25928;&#20511;&#29992;&#22810;&#20010;&#25104;&#20687;&#27169;&#24335;&#20043;&#38388;&#30340;&#20449;&#24687;&#26469;&#39044;&#27979;&#22270;&#20687;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#12290;&#26412;&#25991;&#24314;&#31435;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#25991;&#29486;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#32508;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;InVA&#65289;&#26041;&#27861;&#65292;&#23427;&#20174;&#19981;&#21516;&#26469;&#28304;&#33719;&#24471;&#30340;&#22810;&#20010;&#22270;&#20687;&#20013;&#20511;&#29992;&#20449;&#24687;&#26469;&#32472;&#21046;&#22270;&#20687;&#30340;&#39044;&#27979;&#25512;&#29702;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25429;&#25417;&#20102;&#32467;&#26524;&#22270;&#20687;&#19982;&#36755;&#20837;&#22270;&#20687;&#20043;&#38388;&#30340;&#22797;&#26434;&#38750;&#32447;&#24615;&#20851;&#32852;&#65292;&#24182;&#20801;&#35768;&#24555;&#36895;&#35745;&#31639;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;InVA&#30456;&#23545;&#20110;&#36890;&#24120;&#19981;&#20801;&#35768;&#20511;&#29992;&#36755;&#20837;&#22270;&#20687;&#20043;&#38388;&#20449;&#24687;&#30340;VAE&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a significant interest in exploring non-linear associations among multiple images derived from diverse imaging modalities. While there is a growing literature on image-on-image regression to delineate predictive inference of an image based on multiple images, existing approaches have limitations in efficiently borrowing information between multiple imaging modalities in the prediction of an image. Building on the literature of Variational Auto Encoders (VAEs), this article proposes a novel approach, referred to as Integrative Variational Autoencoder (\texttt{InVA}) method, which borrows information from multiple images obtained from different sources to draw predictive inference of an image. The proposed approach captures complex non-linear association between the outcome image and input images, while allowing rapid computation. Numerical results demonstrate substantial advantages of \texttt{InVA} over VAEs, which typically do not allow borrowing information between input imag
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25240;&#25187;&#33258;&#36866;&#24212;&#22312;&#32447;&#39044;&#27979;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36866;&#24212;&#20110;&#22797;&#26434;&#30340;&#25439;&#22833;&#24207;&#21015;&#21644;&#27604;&#36739;&#22120;&#65292;&#24182;&#25913;&#36827;&#20102;&#38750;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;&#31639;&#27861;&#20855;&#26377;&#26080;&#38656;&#32467;&#26500;&#24615;&#20551;&#35774;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#22312;&#32447;&#31526;&#21512;&#39044;&#27979;&#20219;&#21153;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#22909;&#22788;&#12290;</title><link>https://arxiv.org/abs/2402.02720</link><description>&lt;p&gt;
&#25240;&#25187;&#33258;&#36866;&#24212;&#22312;&#32447;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Discounted Adaptive Online Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25240;&#25187;&#33258;&#36866;&#24212;&#22312;&#32447;&#39044;&#27979;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36866;&#24212;&#20110;&#22797;&#26434;&#30340;&#25439;&#22833;&#24207;&#21015;&#21644;&#27604;&#36739;&#22120;&#65292;&#24182;&#25913;&#36827;&#20102;&#38750;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;&#31639;&#27861;&#20855;&#26377;&#26080;&#38656;&#32467;&#26500;&#24615;&#20551;&#35774;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#22312;&#32447;&#31526;&#21512;&#39044;&#27979;&#20219;&#21153;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#24182;&#19981;&#24635;&#26159;&#35201;&#35760;&#20303;&#19968;&#20999;&#12290;&#30001;&#20110;&#26410;&#26469;&#22312;&#32479;&#35745;&#19978;&#21487;&#33021;&#19982;&#36807;&#21435;&#26377;&#24456;&#22823;&#30340;&#19981;&#21516;&#65292;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#26159;&#22312;&#26032;&#25968;&#25454;&#21040;&#26469;&#26102;&#20248;&#38597;&#22320;&#24536;&#35760;&#21382;&#21490;&#12290;&#20026;&#20102;&#24418;&#24335;&#21270;&#36825;&#31181;&#30452;&#35273;&#65292;&#25105;&#20204;&#36816;&#29992;&#26368;&#36817;&#21457;&#23637;&#30340;&#33258;&#36866;&#24212;&#22312;&#32447;&#23398;&#20064;&#25216;&#26415;&#37325;&#26032;&#24605;&#32771;&#20102;&#32463;&#20856;&#30340;&#25240;&#25187;&#36951;&#25022;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#19968;&#20010;&#26032;&#30340;&#31639;&#27861;&#65292;&#23427;&#36866;&#24212;&#20110;&#25439;&#22833;&#24207;&#21015;&#21644;&#27604;&#36739;&#22120;&#30340;&#22797;&#26434;&#24615;&#65292;&#25913;&#36827;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;&#38750;&#33258;&#36866;&#24212;&#31639;&#27861;-&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#19988;&#20855;&#26377;&#24658;&#23450;&#30340;&#23398;&#20064;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#19981;&#38656;&#35201;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#65292;&#21482;&#35201;&#27714;&#20984;&#24615;&#65292;&#24182;&#19988;&#35813;&#31639;&#27861;&#32463;&#36807;&#35777;&#26126;&#23545;&#27425;&#20248;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#22312;&#32447;&#31526;&#21512;&#39044;&#27979;&#26469;&#23637;&#31034;&#36825;&#20123;&#22909;&#22788;&#65292;&#32780;&#22312;&#32447;&#31526;&#21512;&#39044;&#27979;&#26159;&#19968;&#20010;&#24102;&#26377;&#38598;&#21512;&#25104;&#21592;&#20915;&#31574;&#30340;&#19979;&#28216;&#22312;&#32447;&#23398;&#20064;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online learning is not always about memorizing everything. Since the future can be statistically very different from the past, a critical challenge is to gracefully forget the history while new data comes in. To formalize this intuition, we revisit the classical notion of discounted regret using recently developed techniques in adaptive online learning. Our main result is a new algorithm that adapts to the complexity of both the loss sequence and the comparator, improving the widespread non-adaptive algorithm - gradient descent with a constant learning rate. In particular, our theoretical guarantee does not require any structural assumption beyond convexity, and the algorithm is provably robust to suboptimal hyperparameter tuning. We further demonstrate such benefits through online conformal prediction, a downstream online learning task with set-membership decisions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#26159;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#26368;&#20851;&#38190;&#30340;&#22240;&#32032;&#12290;</title><link>https://arxiv.org/abs/2402.02701</link><description>&lt;p&gt;
&#29702;&#35299;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#22240;&#32032;&#65306;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
Understanding What Affects Generalization Gap in Visual Reinforcement Learning: Theory and Empirical Evidence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#26159;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#26368;&#20851;&#38190;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#26377;&#35768;&#22810;&#21162;&#21147;&#33268;&#21147;&#20110;&#22312;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#23398;&#20064;&#23545;&#36830;&#32493;&#25511;&#21046;&#26377;&#29992;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#31181;&#22330;&#26223;&#19979;&#65292;&#23398;&#20064;&#19968;&#20010;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#30340;&#31574;&#30053;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#27979;&#35797;&#29615;&#22659;&#21487;&#33021;&#19982;&#35757;&#32451;&#29615;&#22659;&#19981;&#21516;&#65292;&#20363;&#22914;&#22312;&#37096;&#32626;&#36807;&#31243;&#20013;&#23384;&#22312;&#24178;&#25200;&#22240;&#32032;&#12290;&#35768;&#22810;&#23454;&#38469;&#31639;&#27861;&#34987;&#25552;&#20986;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20204;&#20013;&#27809;&#26377;&#19968;&#31181;&#31639;&#27861;&#33021;&#22815;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#27867;&#21270;&#24046;&#36317;&#30340;&#24433;&#21709;&#22240;&#32032;&#20197;&#21450;&#20026;&#20160;&#20040;&#20182;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#29702;&#35770;&#19978;&#22238;&#31572;&#24433;&#21709;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#65288;&#19982;&#20154;&#31867;&#30452;&#35273;&#19968;&#33268;&#65289;&#23545;&#20110;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#30340;&#25928;&#30410;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;DM&#25968;&#25454;&#30340;&#23454;&#35777;&#35777;&#25454;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there are many efforts attempting to learn useful policies for continuous control in visual reinforcement learning (RL). In this scenario, it is important to learn a generalizable policy, as the testing environment may differ from the training environment, e.g., there exist distractors during deployment. Many practical algorithms are proposed to handle this problem. However, to the best of our knowledge, none of them provide a theoretical understanding of what affects the generalization gap and why their proposed methods work. In this paper, we bridge this issue by theoretically answering the key factors that contribute to the generalization gap when the testing environment has distractors. Our theories indicate that minimizing the representation distance between training and testing environments, which aligns with human intuition, is the most critical for the benefit of reducing the generalization gap. Our theoretical results are supported by the empirical evidence in the DM
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#19978;&#19979;&#25991;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#34920;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#27169;&#22411;&#30340;&#26032;&#39062;&#31639;&#27861;&#65292;&#35777;&#26126;&#23427;&#20204;&#20855;&#26377;&#25152;&#38656;&#30340;&#22810;&#39033;&#24335;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20854;&#20013;&#65292;&#23545;&#20110;&#31532;&#19968;&#20010;&#27169;&#22411;&#65292;&#36890;&#36807;&#21435;&#38500;&#21487;&#36798;&#24615;&#20551;&#35774;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.02700</link><description>&lt;p&gt;
&#32447;&#24615;&#19978;&#19979;&#25991;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#34920;&#24449;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity Characterization for Linear Contextual MDPs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02700
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#19978;&#19979;&#25991;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#34920;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#27169;&#22411;&#30340;&#26032;&#39062;&#31639;&#27861;&#65292;&#35777;&#26126;&#23427;&#20204;&#20855;&#26377;&#25152;&#38656;&#30340;&#22810;&#39033;&#24335;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20854;&#20013;&#65292;&#23545;&#20110;&#31532;&#19968;&#20010;&#27169;&#22411;&#65292;&#36890;&#36807;&#21435;&#38500;&#21487;&#36798;&#24615;&#20551;&#35774;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#25551;&#36848;&#20102;&#19968;&#31867;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#36716;&#31227;&#20869;&#26680;&#21644;&#22870;&#21169;&#20989;&#25968;&#21487;&#20197;&#38543;&#26102;&#38388;&#21464;&#21270;&#65292;&#24182;&#30001;&#19968;&#20010;&#19978;&#19979;&#25991;&#21464;&#37327;&#32034;&#24341;&#30340;&#19981;&#21516;MDPs&#12290;&#34429;&#28982;CMDPs&#20316;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#27169;&#25311;&#20855;&#26377;&#26102;&#21464;&#29615;&#22659;&#30340;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#23427;&#20204;&#22312;&#29702;&#35770;&#19978;&#24456;&#23569;&#26377;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#27169;&#22411;&#19979;&#30340;CMDPs&#65306;&#27169;&#22411;I&#20855;&#26377;&#19978;&#19979;&#25991;&#21464;&#21270;&#34920;&#31034;&#21644;&#25152;&#26377;&#19978;&#19979;&#25991;&#20844;&#20849;&#32447;&#24615;&#26435;&#37325;&#65307;&#20197;&#21450;&#27169;&#22411;II&#20855;&#26377;&#25152;&#26377;&#19978;&#19979;&#25991;&#30340;&#20844;&#20849;&#34920;&#31034;&#21644;&#19978;&#19979;&#25991;&#21464;&#21270;&#30340;&#32447;&#24615;&#26435;&#37325;&#12290;&#23545;&#20110;&#36825;&#20004;&#20010;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#20855;&#26377;&#25152;&#38656;&#22810;&#39033;&#24335;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#20445;&#35777;&#30340;&#949;-&#27425;&#20248;&#38388;&#38553;&#12290;&#29305;&#21035;&#26159;&#65292;&#23558;&#25105;&#20204;&#23545;&#31532;&#19968;&#20010;&#27169;&#22411;&#30340;&#32467;&#26524;&#23454;&#20363;&#21270;&#20026;&#34920;&#26684;CMDP&#65292;&#36890;&#36807;&#21435;&#38500;&#21487;&#36798;&#24615;&#20551;&#35774;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#12290;&#25105;&#20204;&#23545;&#31532;&#20108;&#20010;&#27169;&#22411;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contextual Markov decision processes (CMDPs) describe a class of reinforcement learning problems in which the transition kernels and reward functions can change over time with different MDPs indexed by a context variable. While CMDPs serve as an important framework to model many real-world applications with time-varying environments, they are largely unexplored from theoretical perspective. In this paper, we study CMDPs under two linear function approximation models: Model I with context-varying representations and common linear weights for all contexts; and Model II with common representations for all contexts and context-varying linear weights. For both models, we propose novel model-based algorithms and show that they enjoy guaranteed $\epsilon$-suboptimality gap with desired polynomial sample complexity. In particular, instantiating our result for the first model to the tabular CMDP improves the existing result by removing the reachability assumption. Our result for the second mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#21644;&#26174;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#35774;&#35745;&#27973;&#26174;&#24335;&#32593;&#32476;&#26469;&#23454;&#29616;&#19982;&#32473;&#23450;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#30456;&#21516;&#30340;&#29305;&#24449;&#20809;&#35889;&#34892;&#20026;&#12290;</title><link>https://arxiv.org/abs/2402.02697</link><description>&lt;p&gt;
&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#19982;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#19981;&#22826;&#28145;&#30340;&#26174;&#24335;&#27169;&#22411;&#20960;&#20046;&#31561;&#20215;
&lt;/p&gt;
&lt;p&gt;
Deep Equilibrium Models are Almost Equivalent to Not-so-deep Explicit Models for High-dimensional Gaussian Mixtures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#21644;&#26174;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#35774;&#35745;&#27973;&#26174;&#24335;&#32593;&#32476;&#26469;&#23454;&#29616;&#19982;&#32473;&#23450;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#30456;&#21516;&#30340;&#29305;&#24449;&#20809;&#35889;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#65288;DEQs&#65289;&#20316;&#20026;&#20856;&#22411;&#30340;&#38544;&#24335;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#38544;&#24335;DEQ&#21644;&#26174;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20043;&#38388;&#30340;&#36830;&#25509;&#21644;&#24046;&#24322;&#32570;&#20047;&#29702;&#35770;&#19978;&#30340;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20511;&#37492;&#26368;&#36817;&#22312;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#23545;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36755;&#20837;&#25968;&#25454;&#19979;&#65292;&#38544;&#24335;DEQ&#30340;&#20849;&#36717;&#26680;&#65288;CK&#65289;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#30697;&#38453;&#30340;&#29305;&#24449;&#20809;&#35889;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#35777;&#26126;&#20102;&#36825;&#20123;&#38544;&#24335;-CKs&#21644;NTKs&#30340;&#20809;&#35889;&#34892;&#20026;&#21462;&#20915;&#20110;DEQ&#28608;&#27963;&#20989;&#25968;&#21644;&#21021;&#22987;&#26435;&#37325;&#26041;&#24046;&#65292;&#20294;&#20165;&#36890;&#36807;&#19968;&#32452;&#22235;&#20010;&#38750;&#32447;&#24615;&#26041;&#31243;&#12290;&#20316;&#20026;&#36825;&#19968;&#29702;&#35770;&#32467;&#26524;&#30340;&#30452;&#25509;&#24433;&#21709;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#31934;&#24515;&#35774;&#35745;&#19968;&#20010;&#27973;&#26174;&#24335;&#32593;&#32476;&#26469;&#20135;&#29983;&#19982;&#32473;&#23450;DEQ&#30456;&#21516;&#30340;CK&#25110;NTK&#12290;&#23613;&#31649;&#36825;&#37324;&#26159;&#38024;&#23545;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#25512;&#23548;&#30340;&#65292;&#32463;&#39564;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
Deep equilibrium models (DEQs), as a typical implicit neural network, have demonstrated remarkable success on various tasks. There is, however, a lack of theoretical understanding of the connections and differences between implicit DEQs and explicit neural network models. In this paper, leveraging recent advances in random matrix theory (RMT), we perform an in-depth analysis on the eigenspectra of the conjugate kernel (CK) and neural tangent kernel (NTK) matrices for implicit DEQs, when the input data are drawn from a high-dimensional Gaussian mixture. We prove, in this setting, that the spectral behavior of these Implicit-CKs and NTKs depend on the DEQ activation function and initial weight variances, but only via a system of four nonlinear equations. As a direct consequence of this theoretical result, we demonstrate that a shallow explicit network can be carefully designed to produce the same CK or NTK as a given DEQ. Despite derived here for Gaussian mixture data, empirical results 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;LG-GNN&#65289;&#26550;&#26500;&#65292;&#36890;&#36807;&#35745;&#31639;&#36793;&#32536;&#27010;&#29575;&#26469;&#39044;&#27979;&#22270;&#20013;&#30340;&#38142;&#25509;&#65292;&#24182;&#25512;&#23548;&#20102;&#20854;&#22312;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#32479;&#35745;&#20445;&#35777;&#12290;&#36825;&#31181;&#26550;&#26500;&#23545;&#20110;&#31232;&#30095;&#21644;&#31264;&#23494;&#22270;&#37117;&#36866;&#29992;&#65292;&#24182;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.02692</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38142;&#25509;&#39044;&#27979;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical Guarantees for Link Prediction using Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;LG-GNN&#65289;&#26550;&#26500;&#65292;&#36890;&#36807;&#35745;&#31639;&#36793;&#32536;&#27010;&#29575;&#26469;&#39044;&#27979;&#22270;&#20013;&#30340;&#38142;&#25509;&#65292;&#24182;&#25512;&#23548;&#20102;&#20854;&#22312;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#32479;&#35745;&#20445;&#35777;&#12290;&#36825;&#31181;&#26550;&#26500;&#23545;&#20110;&#31232;&#30095;&#21644;&#31264;&#23494;&#22270;&#37117;&#36866;&#29992;&#65292;&#24182;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#30001;&#22270;&#19978;&#29983;&#25104;&#30340;&#22270;&#32593;&#32476;&#20013;&#30340;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#65292;&#25512;&#23548;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#24615;&#33021;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32447;&#24615;GNN&#26550;&#26500;&#65288;LG-GNN&#65289;&#65292;&#21487;&#20197;&#20135;&#29983;&#23545;&#28508;&#22312;&#36793;&#32536;&#27010;&#29575;&#30340;&#19968;&#33268;&#20272;&#35745;&#12290;&#25105;&#20204;&#23545;&#22343;&#26041;&#35823;&#24046;&#36827;&#34892;&#20102;&#30028;&#23450;&#65292;&#24182;&#23545;LG-GNN&#22312;&#26816;&#27979;&#39640;&#27010;&#29575;&#36793;&#32536;&#30340;&#33021;&#21147;&#32473;&#20986;&#20102;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#20445;&#35777;&#36866;&#29992;&#20110;&#31232;&#30095;&#21644;&#31264;&#23494;&#22270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32463;&#20856;GCN&#26550;&#26500;&#30340;&#19968;&#20123;&#32570;&#28857;&#65292;&#24182;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper derives statistical guarantees for the performance of Graph Neural Networks (GNNs) in link prediction tasks on graphs generated by a graphon. We propose a linear GNN architecture (LG-GNN) that produces consistent estimators for the underlying edge probabilities. We establish a bound on the mean squared error and give guarantees on the ability of LG-GNN to detect high-probability edges. Our guarantees hold for both sparse and dense graphs. Finally, we demonstrate some of the shortcomings of the classical GCN architecture, as well as verify our results on real and synthetic datasets.
&lt;/p&gt;</description></item><item><title>&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;&#65306;&#25991;&#31456;&#25506;&#35752;&#20102;&#22240;&#26524;&#27010;&#24565;&#19982;&#32431;&#31929;&#27010;&#29575;&#27010;&#24565;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#21457;&#29616;&#35745;&#31639;&#19978;&#30340;&#20844;&#27491;&#24182;&#19981;&#31561;&#21516;&#20110;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#30340;&#24179;&#31561;&#12290;&#21516;&#26102;&#36824;&#32416;&#27491;&#20102;&#19968;&#20123;&#26377;&#20851;&#35745;&#31639;&#19978;&#30340;&#20844;&#27491;&#30340;&#35823;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.02663</link><description>&lt;p&gt;
&#35745;&#31639;&#19978;&#30340;&#20844;&#27491;&#24182;&#38750;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#30340;&#24179;&#31561;&#65292;&#20197;&#21450;&#20854;&#20182;&#35266;&#23519;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Fairness Is Not Demographic Parity, and Other Observations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02663
&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;&#65306;&#25991;&#31456;&#25506;&#35752;&#20102;&#22240;&#26524;&#27010;&#24565;&#19982;&#32431;&#31929;&#27010;&#29575;&#27010;&#24565;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#21457;&#29616;&#35745;&#31639;&#19978;&#30340;&#20844;&#27491;&#24182;&#19981;&#31561;&#21516;&#20110;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#30340;&#24179;&#31561;&#12290;&#21516;&#26102;&#36824;&#32416;&#27491;&#20102;&#19968;&#20123;&#26377;&#20851;&#35745;&#31639;&#19978;&#30340;&#20844;&#27491;&#30340;&#35823;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38656;&#35201;&#35880;&#24910;&#23545;&#24453;&#22312;&#22240;&#26524;&#27010;&#24565;&#19982;&#32431;&#31929;&#27010;&#29575;&#27010;&#24565;&#20043;&#38388;&#36827;&#34892;&#31561;&#20215;&#24615;&#30340;&#26029;&#35328;&#12290;&#22312;&#26412;&#31616;&#30701;&#30340;&#25991;&#31456;&#20013;&#65292;&#25105;&#23545;&#26368;&#36817;&#19968;&#20010;&#22768;&#31216;&#35745;&#31639;&#19978;&#30340;&#20844;&#27491;&#31561;&#21516;&#20110;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#30340;&#24179;&#31561;&#30340;&#20027;&#24352;&#36827;&#34892;&#20102;&#23457;&#26597;&#12290;&#20180;&#32454;&#30740;&#31350;&#21518;&#21457;&#29616;&#35813;&#20027;&#24352;&#19981;&#25104;&#31435;&#12290;&#25105;&#23558;&#20511;&#27492;&#26426;&#20250;&#35299;&#20915;&#19968;&#20123;&#20851;&#20110;&#35745;&#31639;&#19978;&#30340;&#20844;&#27491;&#30340;&#26356;&#24191;&#27867;&#35823;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Blanket statements of equivalence between causal concepts and purely probabilistic concepts should be approached with care. In this short note, I examine a recent claim that counterfactual fairness is equivalent to demographic parity. The claim fails to hold up upon closer examination. I will take the opportunity to address some broader misunderstandings about counterfactual fairness.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;&#30340;&#26041;&#27861;&#21487;&#20197;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#65292;&#20174;&#32780;&#22312;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#26041;&#38754;&#21462;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02644</link><description>&lt;p&gt;
&#36890;&#36807;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#30340;&#26041;&#27861;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Variational DAG Estimation via State Augmentation With Stochastic Permutations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02644
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;&#30340;&#26041;&#27861;&#21487;&#20197;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#65292;&#20174;&#32780;&#22312;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#26041;&#38754;&#21462;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#65292;&#21363;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#65292;&#26159;&#19968;&#20010;&#22312;&#32479;&#35745;&#21644;&#35745;&#31639;&#19978;&#37117;&#24456;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#22312;&#22240;&#26524;&#21457;&#29616;&#31561;&#39046;&#22495;&#26377;&#30528;&#37325;&#35201;&#24212;&#29992;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#22312;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#26041;&#38754;&#26159;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#22788;&#29702;&#20247;&#25152;&#21608;&#30693;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#12290;&#20174;&#27010;&#29575;&#25512;&#26029;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#20027;&#35201;&#30340;&#25361;&#25112;&#26159;&#65288;i&#65289;&#34920;&#31034;&#28385;&#36275;DAG&#32422;&#26463;&#30340;&#22270;&#30340;&#20998;&#24067;&#21644;&#65288;ii&#65289;&#20272;&#35745;&#24213;&#23618;&#32452;&#21512;&#31354;&#38388;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;DAG&#21644;&#25490;&#21015;&#30340;&#25193;&#23637;&#31354;&#38388;&#19978;&#26500;&#24314;&#32852;&#21512;&#20998;&#24067;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#21518;&#39564;&#20272;&#35745;&#65292;&#22312;&#20854;&#20013;&#21033;&#29992;&#20102;&#31163;&#25955;&#20998;&#24067;&#30340;&#36830;&#32493;&#26494;&#24347;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#33021;&#22815;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the structure of a Bayesian network, in the form of a directed acyclic graph (DAG), from observational data is a statistically and computationally hard problem with essential applications in areas such as causal discovery. Bayesian approaches are a promising direction for solving this task, as they allow for uncertainty quantification and deal with well-known identifiability issues. From a probabilistic inference perspective, the main challenges are (i) representing distributions over graphs that satisfy the DAG constraint and (ii) estimating a posterior over the underlying combinatorial space. We propose an approach that addresses these challenges by formulating a joint distribution on an augmented space of DAGs and permutations. We carry out posterior estimation via variational inference, where we exploit continuous relaxations of discrete distributions. We show that our approach can outperform competitive Bayesian and non-Bayesian benchmarks on a range of synthetic and re
&lt;/p&gt;</description></item><item><title>$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#26159;&#23558;$C^*$-&#20195;&#25968;&#19982;&#26426;&#22120;&#23398;&#20064;&#32467;&#21512;&#30340;&#26032;&#30740;&#31350;&#26041;&#21521;&#65292;&#23427;&#36890;&#36807;&#32479;&#19968;&#29616;&#26377;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#24182;&#26500;&#24314;&#26356;&#22810;&#20803;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#65292;&#20026;&#26426;&#22120;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.02637</link><description>&lt;p&gt;
$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#65306;&#36808;&#21521;&#26032;&#30340;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
$C^*$-Algebraic Machine Learning: Moving in a New Direction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02637
&lt;/p&gt;
&lt;p&gt;
$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#26159;&#23558;$C^*$-&#20195;&#25968;&#19982;&#26426;&#22120;&#23398;&#20064;&#32467;&#21512;&#30340;&#26032;&#30740;&#31350;&#26041;&#21521;&#65292;&#23427;&#36890;&#36807;&#32479;&#19968;&#29616;&#26377;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#24182;&#26500;&#24314;&#26356;&#22810;&#20803;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#65292;&#20026;&#26426;&#22120;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#19982;&#25968;&#23398;&#30340;&#20960;&#20010;&#39046;&#22495;&#65288;&#22914;&#32479;&#35745;&#23398;&#12289;&#27010;&#29575;&#35770;&#21644;&#32447;&#24615;&#20195;&#25968;&#65289;&#26377;&#30528;&#38271;&#26399;&#30340;&#21512;&#20316;&#20256;&#32479;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#30340;&#19968;&#20010;&#26032;&#26041;&#21521;&#65306;$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#65292;&#36825;&#26159;$C^*$-&#20195;&#25968;&#21644;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#30340;&#20132;&#27969;&#21644;&#30456;&#20114;&#28363;&#20859;&#12290;$C^*$-&#20195;&#25968;&#26159;&#22797;&#25968;&#31354;&#38388;&#30340;&#33258;&#28982;&#25512;&#24191;&#30340;&#25968;&#23398;&#27010;&#24565;&#65292;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#32479;&#19968;&#29616;&#26377;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#24182;&#26500;&#24314;&#19968;&#20010;&#26356;&#22810;&#20803;&#21270;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20351;&#29992;$C^*$-&#20195;&#25968;&#30340;&#21407;&#22240;&#21644;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#26680;&#26041;&#27861;&#21644;&#31070;&#32463;&#32593;&#32476;&#32972;&#26223;&#19979;&#35774;&#35745;$C^*$-&#20195;&#25968;&#23398;&#20064;&#27169;&#22411;&#30340;&#25216;&#26415;&#32771;&#34385;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;$C^*$-&#20195;&#25968;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#21644;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#25105;&#20204;&#23545;&#26410;&#26469;&#21457;&#23637;&#21644;&#24212;&#29992;&#30340;&#24605;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning has a long collaborative tradition with several fields of mathematics, such as statistics, probability and linear algebra. We propose a new direction for machine learning research: $C^*$-algebraic ML $-$ a cross-fertilization between $C^*$-algebra and machine learning. The mathematical concept of $C^*$-algebra is a natural generalization of the space of complex numbers. It enables us to unify existing learning strategies, and construct a new framework for more diverse and information-rich data models. We explain why and how to use $C^*$-algebras in machine learning, and provide technical considerations that go into the design of $C^*$-algebraic learning models in the contexts of kernel methods and neural networks. Furthermore, we discuss open questions and challenges in $C^*$-algebraic ML and give our thoughts for future development and applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21306;&#38388;&#27010;&#29575;&#27979;&#24230;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#34920;&#31034;&#19981;&#30830;&#23450;&#24615;&#27010;&#29575;&#12290;&#36890;&#36807;&#29305;&#24449;&#21270;&#19968;&#31867;&#24191;&#27867;&#30340;&#21306;&#38388;&#27010;&#29575;&#27979;&#24230;&#65292;&#24314;&#31435;&#20102;&#26356;&#26032;&#35268;&#21017;&#65292;&#24182;&#25552;&#20986;&#20102;&#38543;&#26426;&#20248;&#21183;&#30340;&#23450;&#20041;&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#20975;&#24681;&#26031;-&#20848;&#22982;&#40784;&#20105;&#35770;&#30340;&#27491;&#24335;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02556</link><description>&lt;p&gt;
&#19968;&#31181;&#26032;&#30340;&#22788;&#29702;&#19981;&#30830;&#23450;&#24615;&#27010;&#29575;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A new approach for imprecise probabilities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21306;&#38388;&#27010;&#29575;&#27979;&#24230;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#34920;&#31034;&#19981;&#30830;&#23450;&#24615;&#27010;&#29575;&#12290;&#36890;&#36807;&#29305;&#24449;&#21270;&#19968;&#31867;&#24191;&#27867;&#30340;&#21306;&#38388;&#27010;&#29575;&#27979;&#24230;&#65292;&#24314;&#31435;&#20102;&#26356;&#26032;&#35268;&#21017;&#65292;&#24182;&#25552;&#20986;&#20102;&#38543;&#26426;&#20248;&#21183;&#30340;&#23450;&#20041;&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#20975;&#24681;&#26031;-&#20848;&#22982;&#40784;&#20105;&#35770;&#30340;&#27491;&#24335;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21306;&#38388;&#27010;&#29575;&#27979;&#24230;&#30340;&#27010;&#24565;&#65292;&#20197;&#19968;&#31181;&#33258;&#28982;&#21644;&#36830;&#36143;&#30340;&#26041;&#24335;&#34920;&#31034;&#19981;&#30830;&#23450;&#24615;&#25110;&#19981;&#31934;&#30830;&#27010;&#29575;&#12290;&#22312;&#19968;&#20010;&#38598;&#21512;&#30340;&#20195;&#25968;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24369;&#34917;&#20805;&#30340;&#27010;&#24565;&#65292;&#35760;&#20026;$\psi$&#12290;&#20107;&#20214;$H$&#30340;&#21306;&#38388;&#27010;&#29575;&#27979;&#24230;&#23450;&#20041;&#20026;&#19982;&#19981;&#30830;&#23450;&#24615;&#20107;&#20214;&#38598;&#21512;$(\psi(H))^c$&#30456;&#20851;&#30340;&#26631;&#20934;&#34917;&#38598;$H^c$&#12290;&#25105;&#20204;&#23545;&#19968;&#31867;&#24191;&#27867;&#30340;&#21306;&#38388;&#27010;&#29575;&#27979;&#24230;&#36827;&#34892;&#20102;&#29305;&#24449;&#21270;&#65292;&#24182;&#23450;&#20041;&#20102;&#23427;&#20204;&#30340;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#26356;&#26032;&#35268;&#21017;&#65292;&#32771;&#34385;&#20102;&#32479;&#35745;&#29420;&#31435;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#38543;&#26426;&#21464;&#37327;&#30340;&#21306;&#38388;&#20998;&#24067;&#30340;&#20844;&#24335;&#65292;&#24341;&#20837;&#20102;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#38543;&#26426;&#20248;&#21183;&#30340;&#30456;&#24212;&#23450;&#20041;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#20975;&#24681;&#26031;-&#20848;&#22982;&#40784;&#20105;&#35770;&#30340;&#27491;&#24335;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel concept of interval probability measures that enables the representation of imprecise probabilities, or uncertainty, in a natural and coherent manner. Within an algebra of sets, we introduce a notion of weak complementation denoted as $\psi$. The interval probability measure of an event $H$ is defined with respect to the set of indecisive eventualities $(\psi(H))^c$, which is included in the standard complement $H^c$.   We characterize a broad class of interval probability measures and define their properties. Additionally, we establish an updating rule with respect to $H$, incorporating concepts of statistical independence and dependence. The interval distribution of a random variable is formulated, and a corresponding definition of stochastic dominance between two random variables is introduced. As a byproduct, a formal solution to the century-old Keynes-Ramsey controversy is presented.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35299;&#20915;Lasso&#21644;Logistic Lasso&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#29992;&#20027;&#21160;&#38598;&#26041;&#27861;&#21644;&#36866;&#24403;&#30340;&#27714;&#35299;&#22120;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#21152;&#36895;&#12290;&#22312;&#21387;&#32553;&#24863;&#30693;&#12289;Lasso&#22238;&#24402;&#21644;Logistic Lasso&#22238;&#24402;&#23454;&#39564;&#20013;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#33021;&#25552;&#39640;&#32422;30&#20493;&#30340;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.02463</link><description>&lt;p&gt;
&#19968;&#31181;&#24555;&#36895;&#30340;Lasso&#21644;Logistic Lasso&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Fast Method for Lasso and Logistic Lasso
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35299;&#20915;Lasso&#21644;Logistic Lasso&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#29992;&#20027;&#21160;&#38598;&#26041;&#27861;&#21644;&#36866;&#24403;&#30340;&#27714;&#35299;&#22120;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#21152;&#36895;&#12290;&#22312;&#21387;&#32553;&#24863;&#30693;&#12289;Lasso&#22238;&#24402;&#21644;Logistic Lasso&#22238;&#24402;&#23454;&#39564;&#20013;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#33021;&#25552;&#39640;&#32422;30&#20493;&#30340;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35299;&#20915;&#21387;&#32553;&#24863;&#30693;&#12289;Lasso&#22238;&#24402;&#21644;Logistic Lasso&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20027;&#21160;&#38598;&#26041;&#27861;&#36845;&#20195;&#36816;&#34892;&#36866;&#24403;&#30340;&#27714;&#35299;&#22120;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26356;&#26032;&#20027;&#21160;&#38598;&#30340;&#31574;&#30053;&#65292;&#30456;&#27604;&#20110;&#21333;&#27425;&#35843;&#29992;&#22810;&#20010;&#27714;&#35299;&#22120;&#65288;&#21253;&#25324;Matlab&#30340;lassoglm&#21644;glmnet&#20197;&#21450;&#29992;&#20110;&#31232;&#30095;&#37325;&#26500;&#30340;&#26799;&#24230;&#25237;&#24433;&#31639;&#27861;GPSR&#65289;&#65292;&#33021;&#22815;&#23454;&#29616;&#22823;&#24133;&#21152;&#36895;&#12290;&#23545;&#20110;&#21387;&#32553;&#24863;&#30693;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;GPSR&#30340;&#28151;&#21512;&#24179;&#22343;&#36895;&#24230;&#25552;&#39640;&#20102;31.41&#20493;&#65288;&#23545;&#20110;&#39640;&#26031;&#31995;&#21015;&#65289;&#21644;25.64&#20493;&#65288;&#23545;&#20110;&#20108;&#36827;&#21046;&#31995;&#21015;&#65289;&#12290;&#22312;Lasso&#22238;&#24402;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;GPSR&#30340;&#28151;&#21512;&#24179;&#22343;&#36895;&#24230;&#25552;&#39640;&#20102;30.67&#20493;&#12290;&#22312;Logistic Lasso&#22238;&#24402;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;lassoglm&#30340;&#28151;&#21512;&#24179;&#22343;&#36895;&#24230;&#25552;&#39640;&#20102;11.95&#20493;&#65292;&#19982;glmnet&#30340;&#28151;&#21512;&#24179;&#22343;&#36895;&#24230;&#25552;&#39640;&#20102;1.40&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a fast method for solving compressed sensing, Lasso regression, and Logistic Lasso regression problems that iteratively runs an appropriate solver using an active set approach. We design a strategy to update the active set that achieves a large speedup over a single call of several solvers, including gradient projection for sparse reconstruction (GPSR), lassoglm of Matlab, and glmnet. For compressed sensing, the hybrid of our method and GPSR is 31.41 times faster than GPSR on average for Gaussian ensembles and 25.64 faster on average for binary ensembles. For Lasso regression, the hybrid of our method and GPSR achieves a 30.67-fold average speedup in our experiments. In our experiments on Logistic Lasso regression, the hybrid of our method and lassoglm gives an 11.95-fold average speedup, and the hybrid of our method and glmnet gives a 1.40-fold average speedup.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#36857;&#22240;&#23376;&#20998;&#26512;&#65288;MTFA&#65289;&#30340;&#25918;&#26494;&#29256;&#26412;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#38477;&#20302;&#22240;&#24322;&#26041;&#24046;&#22122;&#22768;&#36896;&#25104;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#22240;&#23376;&#20998;&#26512;&#21644;&#35889;&#26041;&#27861;&#20013;&#24120;&#35265;&#30340;&#24322;&#24120;&#24773;&#20917;&#21644;&#30149;&#24577;&#35781;&#21650;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.02459</link><description>&lt;p&gt;
&#22312;&#26368;&#23567;&#21270;&#36857;&#22240;&#23376;&#20998;&#26512;&#20013; - &#36825;&#39318;&#32769;&#27468;&#20197;&#26032;&#30340;&#26041;&#24335;&#28436;&#21809;
&lt;/p&gt;
&lt;p&gt;
On Minimum Trace Factor Analysis - An Old Song Sung to a New Tune
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02459
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#36857;&#22240;&#23376;&#20998;&#26512;&#65288;MTFA&#65289;&#30340;&#25918;&#26494;&#29256;&#26412;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#38477;&#20302;&#22240;&#24322;&#26041;&#24046;&#22122;&#22768;&#36896;&#25104;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#22240;&#23376;&#20998;&#26512;&#21644;&#35889;&#26041;&#27861;&#20013;&#24120;&#35265;&#30340;&#24322;&#24120;&#24773;&#20917;&#21644;&#30149;&#24577;&#35781;&#21650;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#24230;&#38477;&#20302;&#26041;&#27861;&#65292;&#20363;&#22914;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#22240;&#23376;&#20998;&#26512;&#65292;&#22312;&#25968;&#25454;&#31185;&#23398;&#20013;&#26159;&#24456;&#24120;&#29992;&#30340;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20855;&#26377;&#26174;&#33879;&#24322;&#26041;&#24046;&#22122;&#22768;&#30340;&#25968;&#25454;&#65292;&#23547;&#25214;&#31283;&#20581;&#30340;&#20302;&#32500;&#36924;&#36817;&#23384;&#22312;&#26126;&#26174;&#19988;&#34987;&#24191;&#27867;&#25509;&#21463;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#26368;&#23567;&#21270;&#36857;&#22240;&#23376;&#20998;&#26512;&#65288;MTFA&#65289;&#30340;&#25918;&#26494;&#29256;&#26412;&#65292;&#36825;&#26159;&#19968;&#31181;&#20984;&#20248;&#21270;&#26041;&#27861;&#65292;&#20854;&#26681;&#28304;&#21487;&#20197;&#36861;&#28335;&#21040;1940&#24180;Ledermann&#30340;&#24037;&#20316;&#12290;&#36825;&#31181;&#25918;&#26494;&#26041;&#27861;&#22312;&#19981;&#36807;&#24230;&#25311;&#21512;&#24322;&#26041;&#24046;&#25200;&#21160;&#26041;&#38754;&#29305;&#21035;&#26377;&#25928;&#65292;&#35299;&#20915;&#20102;&#22240;&#32032;&#20998;&#26512;&#20013;&#32463;&#24120;&#34987;&#25552;&#21040;&#30340;Heywood&#26696;&#20363;&#21644;&#26368;&#36817;&#21457;&#29616;&#30340;&#29616;&#26377;&#35889;&#26041;&#27861;&#20013;"&#30149;&#24577;&#35781;&#21650;"&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#25152;&#24471;&#20302;&#31209;&#23376;&#31354;&#38388;&#30340;&#31934;&#30830;&#24230;&#21644;&#25152;&#25552;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#65288;&#21253;&#25324;HeteroPCA&#65292;Lasso&#21644;Soft-Impute&#65289;&#30340;&#19968;&#20123;&#26377;&#36259;&#32852;&#31995;&#65292;&#20197;&#22635;&#34917;&#19968;&#20123;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dimensionality reduction methods, such as principal component analysis (PCA) and factor analysis, are central to many problems in data science. There are, however, serious and well-understood challenges to finding robust low dimensional approximations for data with significant heteroskedastic noise. This paper introduces a relaxed version of Minimum Trace Factor Analysis (MTFA), a convex optimization method with roots dating back to the work of Ledermann in 1940. This relaxation is particularly effective at not overfitting to heteroskedastic perturbations and addresses the commonly cited Heywood cases in factor analysis and the recently identified "curse of ill-conditioning" for existing spectral methods. We provide theoretical guarantees on the accuracy of the resulting low rank subspace and the convergence rate of the proposed algorithm to compute that matrix. We develop a number of interesting connections to existing methods, including HeteroPCA, Lasso, and Soft-Impute, to fill an i
&lt;/p&gt;</description></item><item><title>FreDF&#26159;&#19968;&#31181;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#26631;&#31614;&#24207;&#21015;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;</title><link>https://arxiv.org/abs/2402.02399</link><description>&lt;p&gt;
FreDF: &#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
FreDF: Learning to Forecast in Frequency Domain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02399
&lt;/p&gt;
&lt;p&gt;
FreDF&#26159;&#19968;&#31181;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#26631;&#31614;&#24207;&#21015;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#22312;&#21382;&#21490;&#24207;&#21015;&#21644;&#26631;&#31614;&#24207;&#21015;&#20013;&#37117;&#38754;&#20020;&#33258;&#30456;&#20851;&#30340;&#25361;&#25112;&#12290;&#24403;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22788;&#29702;&#21382;&#21490;&#24207;&#21015;&#20013;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#20294;&#24448;&#24448;&#24573;&#35270;&#20102;&#26631;&#31614;&#24207;&#21015;&#20013;&#30340;&#33258;&#30456;&#20851;&#23384;&#22312;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#26032;&#20852;&#30340;&#39044;&#27979;&#27169;&#22411;&#20027;&#35201;&#36981;&#24490;&#30452;&#25509;&#39044;&#27979;&#65288;DF&#65289;&#33539;&#24335;&#65292;&#22312;&#26631;&#31614;&#24207;&#21015;&#20013;&#20551;&#35774;&#26465;&#20214;&#29420;&#31435;&#24615;&#19979;&#29983;&#25104;&#22810;&#27493;&#39044;&#27979;&#12290;&#36825;&#31181;&#20551;&#35774;&#24573;&#35270;&#20102;&#26631;&#31614;&#24207;&#21015;&#20013;&#22266;&#26377;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#22522;&#20110;DF&#30340;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#38024;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#39057;&#22495;&#22686;&#24378;&#30452;&#25509;&#39044;&#27979;&#65288;FreDF&#65289;&#65292;&#36890;&#36807;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#26469;&#36991;&#20813;&#26631;&#31614;&#33258;&#30456;&#20851;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;FreDF&#22312;&#24615;&#33021;&#19978;&#22823;&#22823;&#36229;&#36807;&#20102;&#21253;&#25324;iTransformer&#22312;&#20869;&#30340;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series modeling is uniquely challenged by the presence of autocorrelation in both historical and label sequences. Current research predominantly focuses on handling autocorrelation within the historical sequence but often neglects its presence in the label sequence. Specifically, emerging forecast models mainly conform to the direct forecast (DF) paradigm, generating multi-step forecasts under the assumption of conditional independence within the label sequence. This assumption disregards the inherent autocorrelation in the label sequence, thereby limiting the performance of DF-based models. In response to this gap, we introduce the Frequency-enhanced Direct Forecast (FreDF), which bypasses the complexity of label autocorrelation by learning to forecast in the frequency domain. Our experiments demonstrate that FreDF substantially outperforms existing state-of-the-art methods including iTransformer and is compatible with a variety of forecast models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#24230;&#24182;&#34892;&#30340;&#29992;&#20110;&#27604;&#36739;&#29699;&#24418;&#27979;&#24230;&#30340;&#36317;&#31163;&#65292;&#20351;&#29992;&#20102;&#31435;&#20307;&#25237;&#24433;&#21644;&#24191;&#20041;Radon&#21464;&#25442;&#65292;&#31216;&#20043;&#20026;&#31435;&#20307;&#25237;&#24433;&#29699;&#38754;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;S3W&#65289;&#36317;&#31163;&#12290;&#36890;&#36807;&#20180;&#32454;&#22788;&#29702;&#31435;&#20307;&#25237;&#24433;&#24341;&#36215;&#30340;&#36317;&#31163;&#30072;&#21464;&#65292;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#25928;&#26524;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.02345</link><description>&lt;p&gt;
Stereographic Spherical Sliced Wasserstein Distances - &#24212;&#29992;&#20110;&#29699;&#24418;&#27010;&#29575;&#20998;&#24067;&#27604;&#36739;&#30340;&#31435;&#20307;&#25237;&#24433;&#29699;&#38754;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Stereographic Spherical Sliced Wasserstein Distances
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#24230;&#24182;&#34892;&#30340;&#29992;&#20110;&#27604;&#36739;&#29699;&#24418;&#27979;&#24230;&#30340;&#36317;&#31163;&#65292;&#20351;&#29992;&#20102;&#31435;&#20307;&#25237;&#24433;&#21644;&#24191;&#20041;Radon&#21464;&#25442;&#65292;&#31216;&#20043;&#20026;&#31435;&#20307;&#25237;&#24433;&#29699;&#38754;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;S3W&#65289;&#36317;&#31163;&#12290;&#36890;&#36807;&#20180;&#32454;&#22788;&#29702;&#31435;&#20307;&#25237;&#24433;&#24341;&#36215;&#30340;&#36317;&#31163;&#30072;&#21464;&#65292;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#25928;&#26524;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22320;&#36136;&#23398;&#12289;&#21307;&#23398;&#39046;&#22495;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#28145;&#24230;&#34920;&#31034;&#23398;&#20064;&#31561;&#21508;&#20010;&#39046;&#22495;&#65292;&#27604;&#36739;&#29699;&#24418;&#27010;&#29575;&#20998;&#24067;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#12290;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#36317;&#31163;&#65292;&#27604;&#22914;&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#65292;&#23545;&#20110;&#27604;&#36739;&#27010;&#29575;&#27979;&#24230;&#24050;&#32463;&#24341;&#21457;&#20102;&#27963;&#36291;&#30340;&#30740;&#31350;&#65292;&#20197;&#24320;&#21457;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#29699;&#24418;&#27010;&#29575;&#27979;&#24230;&#30340;&#21464;&#20307;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#36895;&#19988;&#39640;&#24230;&#24182;&#34892;&#21270;&#30340;&#29992;&#20110;&#27604;&#36739;&#29699;&#24418;&#27979;&#24230;&#30340;&#36317;&#31163;&#65292;&#20351;&#29992;&#20102;&#31435;&#20307;&#25237;&#24433;&#21644;&#24191;&#20041;Radon&#21464;&#25442;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#31435;&#20307;&#25237;&#24433;&#29699;&#38754;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;S3W&#65289;&#36317;&#31163;&#12290;&#25105;&#20204;&#20180;&#32454;&#22788;&#29702;&#20102;&#31435;&#20307;&#25237;&#24433;&#24341;&#36215;&#30340;&#36317;&#31163;&#30072;&#21464;&#65292;&#24182;&#23545;&#25105;&#20204;&#25552;&#20986;&#30340;&#24230;&#37327;&#21450;&#20854;&#20855;&#26377;&#26059;&#36716;&#19981;&#21464;&#24615;&#30340;&#21464;&#20307;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#24230;&#37327;&#30340;&#24615;&#33021;&#65292;&#24182;&#23558;&#20854;&#19982;&#26368;&#36817;&#30340;&#22522;&#32447;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#20174;&#36965;&#24863;&#21644;&#22788;&#29702;&#25928;&#29575;&#20004;&#20010;&#26041;&#38754;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Comparing spherical probability distributions is of great interest in various fields, including geology, medical domains, computer vision, and deep representation learning. The utility of optimal transport-based distances, such as the Wasserstein distance, for comparing probability measures has spurred active research in developing computationally efficient variations of these distances for spherical probability measures. This paper introduces a high-speed and highly parallelizable distance for comparing spherical measures using the stereographic projection and the generalized Radon transform, which we refer to as the Stereographic Spherical Sliced Wasserstein (S3W) distance. We carefully address the distance distortion caused by the stereographic projection and provide an extensive theoretical analysis of our proposed metric and its rotationally invariant variation. Finally, we evaluate the performance of the proposed metrics and compare them with recent baselines in terms of both spe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#12290;&#23427;&#37319;&#29992;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#26469;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#20197;&#38477;&#20302;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#24341;&#36215;&#30340;&#20559;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.02306</link><description>&lt;p&gt;
&#24377;&#24615;&#36125;&#21494;&#26031;g&#24418;&#24335;&#22312;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A flexible Bayesian g-formula for causal survival analyses with time-dependent confounding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#12290;&#23427;&#37319;&#29992;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#26469;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#20197;&#38477;&#20302;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#24341;&#36215;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#26102;&#38388;&#33267;&#20107;&#20214;&#32467;&#26524;&#30340;&#32437;&#21521;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#65292;&#22240;&#26524;&#20998;&#26512;&#30340;&#24120;&#35265;&#30446;&#26631;&#26159;&#22312;&#30740;&#31350;&#32676;&#20307;&#20013;&#20272;&#35745;&#22312;&#20551;&#35774;&#24178;&#39044;&#24773;&#26223;&#19979;&#30340;&#22240;&#26524;&#29983;&#23384;&#26354;&#32447;&#12290;g&#24418;&#24335;&#26159;&#36825;&#31181;&#20998;&#26512;&#30340;&#19968;&#20010;&#29305;&#21035;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#20026;&#20102;&#22686;&#24378;&#20256;&#32479;&#30340;&#21442;&#25968;&#21270;g&#24418;&#24335;&#26041;&#27861;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#21516;&#26102;&#25903;&#25345;&#32437;&#21521;&#39044;&#27979;&#21644;&#22240;&#26524;&#25512;&#26029;&#12290;&#23427;&#22312;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#30340;&#24314;&#27169;&#20013;&#24341;&#20837;&#20102;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#65292;&#26088;&#22312;&#20943;&#36731;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#36896;&#25104;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#26356;&#36890;&#29992;&#30340;&#31163;&#25955;&#29983;&#23384;&#25968;&#25454;g&#24418;&#24335;&#12290;&#36825;&#20123;&#20844;&#24335;&#21487;&#20197;&#24341;&#20837;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#65292;&#36825;&#22312;&#22788;&#29702;&#36234;&#26469;&#36234;&#22810;&#30340;&#26102;&#21464;&#28151;&#26434;&#22240;&#32032;&#26102;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#38477;&#32500;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In longitudinal observational studies with a time-to-event outcome, a common objective in causal analysis is to estimate the causal survival curve under hypothetical intervention scenarios within the study cohort. The g-formula is a particularly useful tool for this analysis. To enhance the traditional parametric g-formula approach, we developed a more adaptable Bayesian g-formula estimator. This estimator facilitates both longitudinal predictive and causal inference. It incorporates Bayesian additive regression trees in the modeling of the time-evolving generative components, aiming to mitigate bias due to model misspecification. Specifically, we introduce a more general class of g-formulas for discrete survival data. These formulas can incorporate the longitudinal balancing scores, which serve as an effective method for dimension reduction and are vital when dealing with an expanding array of time-varying confounders. The minimum sufficient formulation of these longitudinal balancing
&lt;/p&gt;</description></item><item><title>QuadratiK&#36719;&#20214;&#21253;&#26159;&#19968;&#20010;&#22312;R&#21644;Python&#20013;&#23454;&#29616;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#22871;&#20840;&#38754;&#30340;&#25311;&#21512;&#24230;&#27979;&#35797;&#21644;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#32858;&#31867;&#25216;&#26415;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22788;&#29702;&#29699;&#24418;&#25968;&#25454;&#12290;</title><link>https://arxiv.org/abs/2402.02290</link><description>&lt;p&gt;
&#29699;&#24418;&#25968;&#25454;&#30340;&#25311;&#21512;&#24230;&#21644;&#32858;&#31867;&#65306;R&#21644;Python&#20013;&#30340;QuadratiK&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
Goodness-of-Fit and Clustering of Spherical Data: the QuadratiK package in R and Python
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02290
&lt;/p&gt;
&lt;p&gt;
QuadratiK&#36719;&#20214;&#21253;&#26159;&#19968;&#20010;&#22312;R&#21644;Python&#20013;&#23454;&#29616;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#22871;&#20840;&#38754;&#30340;&#25311;&#21512;&#24230;&#27979;&#35797;&#21644;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#32858;&#31867;&#25216;&#26415;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22788;&#29702;&#29699;&#24418;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;QuadratiK&#36719;&#20214;&#21253;&#65292;&#35813;&#36719;&#20214;&#21253;&#21253;&#21547;&#20102;&#21019;&#26032;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#12290;&#35813;&#36719;&#20214;&#21253;&#22312;R&#21644;Python&#20013;&#23454;&#29616;&#65292;&#25552;&#20379;&#20102;&#19968;&#22871;&#20840;&#38754;&#30340;&#36866;&#24212;&#24230;&#25311;&#21512;&#27979;&#35797;&#21644;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#20108;&#27425;&#36317;&#31163;&#30340;&#32858;&#31867;&#25216;&#26415;&#65292;&#20174;&#32780;&#24357;&#21512;&#20102;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#30340;&#36719;&#20214;&#23454;&#29616;&#20102;&#21333;&#26679;&#26412;&#12289;&#21452;&#26679;&#26412;&#21644;k&#26679;&#26412;&#36866;&#24212;&#24230;&#25311;&#21512;&#27979;&#35797;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#25968;&#23398;&#19978;&#21512;&#29702;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#27010;&#29575;&#20998;&#24067;&#30340;&#25311;&#21512;&#24230;&#12290;&#25105;&#20204;&#30340;&#36719;&#20214;&#25193;&#23637;&#20102;&#21151;&#33021;&#65292;&#21253;&#25324;&#22522;&#20110;&#27850;&#26494;&#26680;&#23494;&#24230;&#30340;$d$&#32500;&#29699;&#19978;&#22343;&#21248;&#24615;&#27979;&#35797;&#65292;&#20197;&#21450;&#20174;&#27850;&#26494;&#26680;&#23494;&#24230;&#20013;&#29983;&#25104;&#38543;&#26426;&#26679;&#26412;&#30340;&#31639;&#27861;&#12290;&#29305;&#21035;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#36719;&#20214;&#36824;&#21253;&#25324;&#19968;&#31181;&#38024;&#23545;&#29699;&#24418;&#25968;&#25454;&#32780;&#29305;&#21035;&#37327;&#36523;&#23450;&#21046;&#30340;&#29420;&#29305;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;&#29699;&#38754;&#19978;&#22522;&#20110;&#27850;&#26494;&#26680;&#23494;&#24230;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#30340;&#36719;&#20214;&#36824;&#21253;&#25324;&#20854;&#20182;&#22270;&#24418;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the QuadratiK package that incorporates innovative data analysis methodologies. The presented software, implemented in both R and Python, offers a comprehensive set of goodness-of-fit tests and clustering techniques using kernel-based quadratic distances, thereby bridging the gap between the statistical and machine learning literatures. Our software implements one, two and k-sample tests for goodness of fit, providing an efficient and mathematically sound way to assess the fit of probability distributions. Expanded capabilities of our software include supporting tests for uniformity on the $d$-dimensional Sphere based on Poisson kernel densities, and algorithms for generating random samples from Poisson kernel densities. Particularly noteworthy is the incorporation of a unique clustering algorithm specifically tailored for spherical data that leverages a mixture of Poisson-kernel-based densities on the sphere. Alongside this, our software includes additional graphical func
&lt;/p&gt;</description></item><item><title>&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#24212;&#35813;&#26159;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#29702;&#35770;&#65292;&#20174;&#26356;&#23436;&#25972;&#30340;&#35282;&#24230;&#25506;&#31350;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.02287</link><description>&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#22522;&#30784;&#30340;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Future Directions in Foundations of Graph Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02287
&lt;/p&gt;
&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#24212;&#35813;&#26159;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#29702;&#35770;&#65292;&#20174;&#26356;&#23436;&#25972;&#30340;&#35282;&#24230;&#25506;&#31350;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22270;&#25968;&#25454;&#22312;&#19981;&#21516;&#23398;&#31185;&#65288;&#20174;&#29983;&#21629;&#31185;&#23398;&#21040;&#31038;&#20250;&#31185;&#23398;&#21644;&#24037;&#31243;&#31185;&#23398;&#65289;&#19978;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#22270;&#26426;&#22120;&#23398;&#20064;&#65292;&#23588;&#20854;&#26159;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#24341;&#36215;&#20102;&#20154;&#20204;&#27987;&#21402;&#30340;&#20852;&#36259;&#12290;&#23613;&#31649;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#25105;&#20204;&#23545;GNNs&#24615;&#36136;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#38750;&#24120;&#19981;&#23436;&#25972;&#12290;&#26368;&#36817;&#30340;&#29702;&#35770;&#21457;&#23637;&#20027;&#35201;&#38598;&#20013;&#22312;&#38416;&#26126;GNNs&#31895;&#31890;&#24230;&#34920;&#36798;&#33021;&#21147;&#26041;&#38754;&#65292;&#20027;&#35201;&#37319;&#29992;&#32452;&#21512;&#25216;&#24039;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#19982;&#23454;&#36341;&#24182;&#19981;&#23436;&#20840;&#19968;&#33268;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#38543;&#26426;&#19968;&#38454;&#20248;&#21270;&#25216;&#26415;&#35757;&#32451;GNNs&#26102;&#65292;&#23545;GNNs&#30340;&#27867;&#21270;&#34892;&#20026;&#30340;&#29702;&#35299;&#12290;&#22312;&#36825;&#31687;&#23450;&#20301;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#38656;&#35201;&#23558;&#27880;&#24847;&#21147;&#36716;&#31227;&#21040;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#22270;&#26426;&#22120;&#23398;&#20064;&#29702;&#35770;&#19978;&#26469;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#30340;&#30456;&#20114;&#20851;&#31995;&#30340;&#26356;&#20840;&#38754;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning on graphs, especially using graph neural networks (GNNs), has seen a surge in interest due to the wide availability of graph data across a broad spectrum of disciplines, from life to social and engineering sciences. Despite their practical success, our theoretical understanding of the properties of GNNs remains highly incomplete. Recent theoretical advancements primarily focus on elucidating the coarse-grained expressive power of GNNs, predominantly employing combinatorial techniques. However, these studies do not perfectly align with practice, particularly in understanding the generalization behavior of GNNs when trained with stochastic first-order optimization techniques. In this position paper, we argue that the graph machine learning community needs to shift its attention to developing a more balanced theory of graph machine learning, focusing on a more thorough understanding of the interplay of expressive power, generalization, and optimization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#24182;&#23558;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#22240;&#26524;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02277</link><description>&lt;p&gt;
&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#22806;&#28304;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Bayesian Optimization via Exogenous Distribution Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#24182;&#23558;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#22240;&#26524;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#20013;&#65292;&#23558;&#30446;&#26631;&#21464;&#37327;&#26368;&#22823;&#21270;&#20316;&#20026;&#25805;&#20316;&#30446;&#26631;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CBO&#65289;&#26041;&#27861;&#35201;&#20040;&#20381;&#36182;&#20110;&#25913;&#21464;&#22240;&#26524;&#32467;&#26500;&#20197;&#26368;&#22823;&#21270;&#22870;&#21169;&#30340;&#30828;&#24178;&#39044;&#65292;&#35201;&#20040;&#24341;&#20837;&#21160;&#20316;&#33410;&#28857;&#21040;&#20869;&#29983;&#21464;&#37327;&#20013;&#65292;&#20197;&#35843;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#20197;&#23454;&#29616;&#30446;&#26631;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#36825;&#22312;&#29616;&#26377;&#26041;&#27861;&#20013;&#36890;&#24120;&#34987;&#24573;&#30053;&#25110;&#36890;&#36807;&#26399;&#26395;&#36827;&#34892;&#36793;&#32536;&#21270;&#12290;&#22806;&#28304;&#20998;&#24067;&#23398;&#20064;&#25552;&#39640;&#20102;&#36890;&#24120;&#36890;&#36807;&#26377;&#38480;&#35266;&#27979;&#25968;&#25454;&#35757;&#32451;&#30340;&#20195;&#29702;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#12290;&#27492;&#22806;&#65292;&#23398;&#20064;&#21040;&#30340;&#22806;&#28304;&#20998;&#24067;&#23558;&#29616;&#26377;&#30340;CBO&#25193;&#23637;&#21040;&#36229;&#20986;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65288;ANM&#65289;&#30340;&#19968;&#33324;&#22240;&#26524;&#26041;&#26696;&#12290;&#24674;&#22797;&#22806;&#28304;&#21464;&#37327;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#22122;&#22768;&#25110;&#26410;&#35266;&#27979;&#21040;&#30340;&#38544;&#34255;&#21464;&#37327;&#20351;&#29992;&#26356;&#28789;&#27963;&#30340;&#20808;&#39564;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;CBO&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximizing a target variable as an operational objective in a structured causal model is an important problem. Existing Causal Bayesian Optimization (CBO) methods either rely on hard interventions that alter the causal structure to maximize the reward; or introduce action nodes to endogenous variables so that the data generation mechanisms are adjusted to achieve the objective. In this paper, a novel method is introduced to learn the distribution of exogenous variables, which is typically ignored or marginalized through expectation by existing methods.   Exogenous distribution learning improves the approximation accuracy of structured causal models in a surrogate model that is usually trained with limited observational data. Moreover, the learned exogenous distribution extends existing CBO to general causal schemes beyond Additive Noise Models (ANM). The recovery of exogenous variables allows us to use a more flexible prior for noise or unobserved hidden variables. A new CBO method is 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#20110;&#20855;&#26377;&#20219;&#24847;&#24230;&#37327;&#30340;&#26377;&#38480;&#36890;&#36947;&#20013;&#30340;&#22833;&#30495;&#24863;&#30693;&#26435;&#34913;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#35745;&#31639;&#22833;&#30495;&#24863;&#30693;&#20989;&#25968;&#21644;&#26368;&#20248;&#37325;&#24314;&#30456;&#24403;&#20110;&#27714;&#35299;&#19968;&#32452;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#22833;&#30495;&#24863;&#30693;&#26435;&#34913;&#30340;&#32467;&#26500;&#29305;&#24449;&#21270;&#21644;&#20108;&#36827;&#21046;&#28304;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;</title><link>https://arxiv.org/abs/2402.02265</link><description>&lt;p&gt;
&#23545;&#20110;&#20855;&#26377;&#20219;&#24847;&#24230;&#37327;&#30340;&#26377;&#38480;&#36890;&#36947;&#65292;&#22833;&#30495;&#24863;&#30693;&#26435;&#34913;&#30340;&#29305;&#24449;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Characterization of the Distortion-Perception Tradeoff for Finite Channels with Arbitrary Metrics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02265
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#20110;&#20855;&#26377;&#20219;&#24847;&#24230;&#37327;&#30340;&#26377;&#38480;&#36890;&#36947;&#20013;&#30340;&#22833;&#30495;&#24863;&#30693;&#26435;&#34913;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#35745;&#31639;&#22833;&#30495;&#24863;&#30693;&#20989;&#25968;&#21644;&#26368;&#20248;&#37325;&#24314;&#30456;&#24403;&#20110;&#27714;&#35299;&#19968;&#32452;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#22833;&#30495;&#24863;&#30693;&#26435;&#34913;&#30340;&#32467;&#26500;&#29305;&#24449;&#21270;&#21644;&#20108;&#36827;&#21046;&#28304;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#31867;&#26816;&#26597;&#26102;&#65292;&#37325;&#24314;&#20449;&#21495;&#19982;&#30495;&#23454;&#20449;&#21495;&#19981;&#24212;&#26377;&#21306;&#21035;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#39640;&#24863;&#30693;&#36136;&#37327;&#30340;&#23454;&#29616;&#38656;&#35201;&#20184;&#20986;&#39640;&#37325;&#24314;&#35823;&#24046;&#30340;&#20195;&#20215;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#25105;&#20204;&#23545;&#20110;&#20855;&#26377;&#20219;&#24847;&#24230;&#37327;&#30340;&#26377;&#38480;&#23383;&#27597;&#34920;&#36890;&#36947;&#20013;&#30340;&#22833;&#30495;&#24863;&#30693;&#26435;&#34913;&#36827;&#34892;&#30740;&#31350;&#65292;&#23558;&#24863;&#30693;&#25351;&#25968;&#23450;&#20041;&#20026;&#27779;&#29791;&#26031;&#22374;&#36317;&#31163;-$1$&#65292;&#23558;&#22833;&#30495;&#30697;&#38453;&#23450;&#20041;&#20026;&#20219;&#24847;&#12290;&#22312;&#36825;&#20010;&#35774;&#23450;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#22833;&#30495;&#24863;&#30693;&#20989;&#25968;&#21644;&#26368;&#20248;&#37325;&#24314;&#31561;&#20215;&#20110;&#27714;&#35299;&#19968;&#32452;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23545;&#22833;&#30495;&#24863;&#30693;&#26435;&#34913;&#36827;&#34892;&#20102;&#32467;&#26500;&#29305;&#24449;&#21270;&#65292;&#20854;&#20013;&#22833;&#30495;&#24863;&#30693;&#20989;&#25968;&#22312;&#24863;&#30693;&#25351;&#25968;&#19978;&#26159;&#20998;&#27573;&#32447;&#24615;&#30340;&#12290;&#23545;&#20110;&#20108;&#36827;&#21046;&#28304;&#65292;&#25105;&#20204;&#36824;&#23548;&#20986;&#20102;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whenever inspected by humans, reconstructed signals should not be distinguished from real ones. Typically, such a high perceptual quality comes at the price of high reconstruction error, and vice versa. We study this distortion-perception (DP) tradeoff over finite-alphabet channels, for the Wasserstein-$1$ distance induced by a general metric as the perception index, and an arbitrary distortion matrix. Under this setting, we show that computing the DP function and the optimal reconstructions is equivalent to solving a set of linear programming problems. We provide a structural characterization of the DP tradeoff, where the DP function is piecewise linear in the perception index. We further derive a closed-form expression for the case of binary sources.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#32422;&#31616;&#26041;&#27861;&#65292;&#21033;&#29992;&#26684;&#32599;&#33707;&#22827;-&#29926;&#29791;&#26031;&#22374;&#25237;&#24433;&#32479;&#19968;&#20102;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#21516;&#26102;&#35299;&#20915;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#39046;&#22495;&#34920;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02239</link><description>&lt;p&gt;
&#20998;&#24067;&#32422;&#31616;&#65306;&#29992;&#26684;&#32599;&#33707;&#22827;-&#29926;&#29791;&#26031;&#22374;&#25237;&#24433;&#32479;&#19968;&#38477;&#32500;&#21644;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Distributional Reduction: Unifying Dimensionality Reduction and Clustering with Gromov-Wasserstein Projection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#32422;&#31616;&#26041;&#27861;&#65292;&#21033;&#29992;&#26684;&#32599;&#33707;&#22827;-&#29926;&#29791;&#26031;&#22374;&#25237;&#24433;&#32479;&#19968;&#20102;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#21516;&#26102;&#35299;&#20915;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#39046;&#22495;&#34920;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#23398;&#20064;&#26088;&#22312;&#25429;&#25417;&#28508;&#22312;&#30340;&#22823;&#35268;&#27169;&#21644;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#32467;&#26500;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#28041;&#21450;&#20351;&#29992;&#38477;&#32500;&#26041;&#27861;&#23558;&#25968;&#25454;&#25237;&#24433;&#21040;&#21487;&#35299;&#37322;&#30340;&#31354;&#38388;&#19978;&#65292;&#25110;&#23558;&#25968;&#25454;&#28857;&#32452;&#32455;&#25104;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#26159;&#25353;&#39034;&#24207;&#20351;&#29992;&#30340;&#65292;&#32780;&#19981;&#33021;&#20445;&#35777;&#32858;&#31867;&#19982;&#38477;&#32500;&#30456;&#19968;&#33268;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35266;&#28857;&#65306;&#20351;&#29992;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#30340;&#24037;&#20855;&#65292;&#29305;&#21035;&#26159;&#26684;&#32599;&#33707;&#22827;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#65292;&#25105;&#20204;&#23558;&#32858;&#31867;&#21644;&#38477;&#32500;&#32479;&#19968;&#20026;&#19968;&#20010;&#31216;&#20026;&#20998;&#24067;&#32422;&#31616;&#30340;&#21333;&#19968;&#26694;&#26550;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#21333;&#20010;&#20248;&#21270;&#38382;&#39064;&#21516;&#26102;&#35299;&#20915;&#32858;&#31867;&#21644;&#38477;&#32500;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#35299;&#37322;&#24615;&#65292;&#24182;&#34920;&#26126;&#23427;&#22312;&#21508;&#31181;&#22270;&#20687;&#21644;&#22522;&#22240;&#32452;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised learning aims to capture the underlying structure of potentially large and high-dimensional datasets. Traditionally, this involves using dimensionality reduction methods to project data onto interpretable spaces or organizing points into meaningful clusters. In practice, these methods are used sequentially, without guaranteeing that the clustering aligns well with the conducted dimensionality reduction. In this work, we offer a fresh perspective: that of distributions. Leveraging tools from optimal transport, particularly the Gromov-Wasserstein distance, we unify clustering and dimensionality reduction into a single framework called distributional reduction. This allows us to jointly address clustering and dimensionality reduction with a single optimization problem. Through comprehensive experiments, we highlight the versatility and interpretability of our method and show that it outperforms existing approaches across a variety of image and genomics datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36830;&#32493;&#24352;&#37327;&#25918;&#26494;&#26041;&#27861;(CTRA)&#65292;&#29992;&#20110;&#22312;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#20013;&#23547;&#25214;&#22810;&#26679;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;CTRA&#36890;&#36807;&#23545;&#31163;&#25955;&#20915;&#31574;&#21464;&#37327;&#36827;&#34892;&#36830;&#32493;&#25918;&#26494;&#65292;&#35299;&#20915;&#20102;&#23547;&#25214;&#22810;&#26679;&#21270;&#35299;&#20915;&#26041;&#26696;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.02190</link><description>&lt;p&gt;
&#22312;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#20013;&#23547;&#25214;&#22810;&#26679;&#21270;&#35299;&#20915;&#26041;&#26696;&#30340;&#36830;&#32493;&#24352;&#37327;&#25918;&#26494;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Continuous Tensor Relaxation for Finding Diverse Solutions in Combinatorial Optimization Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02190
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36830;&#32493;&#24352;&#37327;&#25918;&#26494;&#26041;&#27861;(CTRA)&#65292;&#29992;&#20110;&#22312;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#20013;&#23547;&#25214;&#22810;&#26679;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;CTRA&#36890;&#36807;&#23545;&#31163;&#25955;&#20915;&#31574;&#21464;&#37327;&#36827;&#34892;&#36830;&#32493;&#25918;&#26494;&#65292;&#35299;&#20915;&#20102;&#23547;&#25214;&#22810;&#26679;&#21270;&#35299;&#20915;&#26041;&#26696;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#23547;&#25214;&#26368;&#20339;&#35299;&#26159;&#26368;&#24120;&#35265;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#21333;&#19968;&#35299;&#20915;&#26041;&#26696;&#21487;&#33021;&#19981;&#36866;&#29992;&#65292;&#22240;&#20026;&#30446;&#26631;&#20989;&#25968;&#21644;&#32422;&#26463;&#26465;&#20214;&#21482;&#26159;&#21407;&#22987;&#29616;&#23454;&#19990;&#30028;&#24773;&#20917;&#30340;&#36817;&#20284;&#20540;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23547;&#25214;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#30340;&#22810;&#26679;&#21270;&#35299;&#20915;&#26041;&#26696;&#21644;&#32422;&#26463;&#20005;&#37325;&#24615;&#30340;&#21464;&#21270;&#25104;&#20026;&#33258;&#28982;&#30340;&#26041;&#21521;&#12290;&#36825;&#31181;&#31574;&#30053;&#25552;&#20379;&#20102;&#22312;&#21518;&#22788;&#29702;&#36807;&#31243;&#20013;&#36873;&#25321;&#21512;&#36866;&#35299;&#20915;&#26041;&#26696;&#30340;&#28789;&#27963;&#24615;&#12290;&#28982;&#32780;&#65292;&#21457;&#29616;&#36825;&#20123;&#22810;&#26679;&#21270;&#35299;&#20915;&#26041;&#26696;&#27604;&#30830;&#23450;&#21333;&#19968;&#35299;&#20915;&#26041;&#26696;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#36830;&#32493;&#24352;&#37327;&#26494;&#24347;&#36864;&#28779; (CTRA) &#26041;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#32452;&#21512;&#20248;&#21270;&#27714;&#35299;&#22120;&#12290;CTRA&#36890;&#36807;&#25193;&#23637;&#36830;&#32493;&#26494;&#24347;&#26041;&#27861;&#65292;&#23558;&#31163;&#25955;&#20915;&#31574;&#21464;&#37327;&#36716;&#25442;&#20026;&#36830;&#32493;&#24352;&#37327;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#22810;&#20010;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#25214;&#21040;&#20102;&#19981;&#21516;&#29305;&#24449;&#30340;&#22810;&#26679;&#21270;&#35299;&#20915;&#26041;&#26696;&#21644;&#32422;&#26463;&#20005;&#37325;&#24615;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Finding the best solution is the most common objective in combinatorial optimization (CO) problems. However, a single solution may not be suitable in practical scenarios, as the objective functions and constraints are only approximations of original real-world situations. To tackle this, finding (i) "heterogeneous solutions", diverse solutions with distinct characteristics, and (ii) "penalty-diversified solutions", variations in constraint severity, are natural directions. This strategy provides the flexibility to select a suitable solution during post-processing. However, discovering these diverse solutions is more challenging than identifying a single solution. To overcome this challenge, this study introduces Continual Tensor Relaxation Annealing (CTRA) for unsupervised-learning-based CO solvers. CTRA addresses various problems simultaneously by extending the continual relaxation approach, which transforms discrete decision variables into continual tensors. This method finds heterog
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;IPS&#65288;LIPS&#65289;&#30340;&#26032;&#30340;Slate Bandit OPE&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#22312;&#20302;&#32500;&#24230;&#30340;Slate&#25277;&#35937;&#31354;&#38388;&#20013;&#23450;&#20041;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#24182;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#20248;&#21270;Slate&#25277;&#35937;&#26469;&#20943;&#23567;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.02171</link><description>&lt;p&gt;
&#36890;&#36807;&#20248;&#21270;&#25277;&#35937;&#30340;&#26041;&#24335;&#36827;&#34892;Slate Bandit&#31574;&#30053;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation of Slate Bandit Policies via Optimizing Abstraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02171
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;IPS&#65288;LIPS&#65289;&#30340;&#26032;&#30340;Slate Bandit OPE&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#22312;&#20302;&#32500;&#24230;&#30340;Slate&#25277;&#35937;&#31354;&#38388;&#20013;&#23450;&#20041;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#24182;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#20248;&#21270;Slate&#25277;&#35937;&#26469;&#20943;&#23567;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;Slate&#19978;&#19979;&#25991;&#24378;&#30423;&#38382;&#39064;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#65292;&#20854;&#20013;&#19968;&#20010;&#31574;&#30053;&#36873;&#25321;&#31216;&#20026;slates&#30340;&#22810;&#32500;&#21160;&#20316;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#25512;&#33616;&#31995;&#32479;&#12289;&#25628;&#32034;&#24341;&#25806;&#12289;&#33829;&#38144;&#20197;&#21450;&#21307;&#30103;&#24212;&#29992;&#20013;&#24191;&#27867;&#23384;&#22312;&#65292;&#28982;&#32780;&#65292;&#30001;&#20110;&#21160;&#20316;&#31354;&#38388;&#22823;&#65292;&#20856;&#22411;&#30340;&#36870;&#20542;&#21521;&#35780;&#20998;&#65288;IPS&#65289;&#20272;&#35745;&#22120;&#23384;&#22312;&#36739;&#22823;&#30340;&#26041;&#24046;&#65292;&#20351;&#24471;&#26377;&#25928;&#30340;OPE&#25104;&#20026;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#20266;&#36870;&#65288;PI&#65289;&#20272;&#35745;&#22120;&#24050;&#34987;&#24341;&#20837;&#20197;&#20943;&#23567;&#26041;&#24046;&#38382;&#39064;&#65292;&#36890;&#36807;&#20551;&#35774;&#22870;&#21169;&#20989;&#25968;&#32447;&#24615;&#65292;&#20294;&#36825;&#21487;&#33021;&#23548;&#33268;&#26174;&#33879;&#30340;&#20559;&#24046;&#65292;&#22240;&#20026;&#36825;&#20010;&#20551;&#35774;&#22312;&#35266;&#27979;&#25968;&#25454;&#20013;&#24456;&#38590;&#39564;&#35777;&#24182;&#19988;&#32463;&#24120;&#20250;&#34987;&#23454;&#36136;&#24615;&#36829;&#21453;&#12290;&#20026;&#20102;&#35299;&#20915;&#20043;&#21069;&#20272;&#35745;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;Slate Bandit OPE&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;&#28508;&#22312;IPS&#65288;LIPS&#65289;&#65292;&#23427;&#22312;&#20302;&#32500;&#24230;&#30340;Slate&#25277;&#35937;&#31354;&#38388;&#20013;&#23450;&#20041;&#20102;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#20248;&#21270;Slate&#25277;&#35937;&#26469;&#26368;&#23567;&#21270;LIPS&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study off-policy evaluation (OPE) in the problem of slate contextual bandits where a policy selects multi-dimensional actions known as slates. This problem is widespread in recommender systems, search engines, marketing, to medical applications, however, the typical Inverse Propensity Scoring (IPS) estimator suffers from substantial variance due to large action spaces, making effective OPE a significant challenge. The PseudoInverse (PI) estimator has been introduced to mitigate the variance issue by assuming linearity in the reward function, but this can result in significant bias as this assumption is hard-to-verify from observed data and is often substantially violated. To address the limitations of previous estimators, we develop a novel estimator for OPE of slate bandits, called Latent IPS (LIPS), which defines importance weights in a low-dimensional slate abstraction space where we optimize slate abstractions to minimize the bias and variance of LIPS in a data-driven way. By do
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#65292;&#35813;&#25351;&#25968;&#26681;&#25454;&#29616;&#26377;&#30340;&#22522;&#30784;&#25351;&#25968;&#23450;&#20041;&#65292;&#24182;&#29992;&#20110;&#26816;&#27979;&#27425;&#20248;&#32858;&#31867;&#25968;&#65292;&#36890;&#36807;&#19982;&#20854;&#20182;&#25351;&#25968;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02162</link><description>&lt;p&gt;
&#19968;&#20010;&#36125;&#21494;&#26031;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;
&lt;/p&gt;
&lt;p&gt;
A Bayesian cluster validity index
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02162
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#65292;&#35813;&#25351;&#25968;&#26681;&#25454;&#29616;&#26377;&#30340;&#22522;&#30784;&#25351;&#25968;&#23450;&#20041;&#65292;&#24182;&#29992;&#20110;&#26816;&#27979;&#27425;&#20248;&#32858;&#31867;&#25968;&#65292;&#36890;&#36807;&#19982;&#20854;&#20182;&#25351;&#25968;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24212;&#29992;&#32858;&#31867;&#31639;&#27861;&#26102;&#65292;&#36873;&#25321;&#32858;&#31867;&#25968;&#26159;&#20851;&#38190;&#27493;&#39588;&#20043;&#19968;&#12290;&#20026;&#20102;&#23436;&#25104;&#36825;&#20010;&#20219;&#21153;&#65292;&#24341;&#20837;&#20102;&#21508;&#31181;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#65288;CVIs&#65289;&#12290;&#22823;&#22810;&#25968;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#37117;&#34987;&#23450;&#20041;&#20026;&#26816;&#27979;&#25968;&#25454;&#38598;&#20013;&#38544;&#34255;&#30340;&#26368;&#20248;&#32858;&#31867;&#25968;&#12290;&#28982;&#32780;&#65292;&#29992;&#25143;&#26377;&#26102;&#24182;&#19981;&#26399;&#26395;&#33719;&#24471;&#26368;&#20248;&#32858;&#31867;&#25968;&#65292;&#32780;&#26159;&#26356;&#36866;&#21512;&#20182;&#20204;&#24212;&#29992;&#30340;&#27425;&#20248;&#32858;&#31867;&#25968;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#29616;&#26377;&#22522;&#30784;&#25351;&#25968;&#30340;&#36125;&#21494;&#26031;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#65288;BCVI&#65289;&#12290;&#35813;&#25351;&#25968;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#25110;&#24191;&#20041;&#29380;&#21033;&#20811;&#38647;&#20808;&#39564;&#23450;&#20041;&#65292;&#24471;&#21040;&#30456;&#21516;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#28982;&#21518;&#25105;&#20204;&#22522;&#20110;Wiroonsri&#25351;&#25968;&#65288;WI&#65289;&#21644;Wiroonsri-Preedasawakul&#25351;&#25968;&#65288;WP&#65289;&#20316;&#20026;&#30828;&#32858;&#31867;&#21644;&#36719;&#32858;&#31867;&#30340;&#22522;&#30784;&#25351;&#25968;&#26469;&#27979;&#35797;&#25105;&#20204;&#30340;BCVI&#12290;&#25105;&#20204;&#23558;&#23427;&#20204;&#30340;&#32467;&#26524;&#19982;&#21407;&#22987;&#30340;&#22522;&#30784;&#25351;&#25968;&#20197;&#21450;&#19968;&#20123;&#20854;&#20182;&#23384;&#22312;&#30340;CVIs&#65288;&#21253;&#25324;Davies and Bouldin (DB)&#65292;Starczewski (STR)&#65289;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selecting the number of clusters is one of the key processes when applying clustering algorithms. To fulfill this task, various cluster validity indices (CVIs) have been introduced. Most of the cluster validity indices are defined to detect the optimal number of clusters hidden in a dataset. However, users sometimes do not expect to get the optimal number of groups but a secondary one which is more reasonable for their applications. This has motivated us to introduce a Bayesian cluster validity index (BCVI) based on existing underlying indices. This index is defined based on either Dirichlet or Generalized Dirichlet priors which result in the same posterior distribution. Our BCVI is then tested based on the Wiroonsri index (WI), and the Wiroonsri-Preedasawakul index (WP) as underlying indices for hard and soft clustering, respectively. We compare their outcomes with the original underlying indices, as well as a few more existing CVIs including Davies and Bouldin (DB), Starczewski (STR)
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36136;&#30097;&#20102;&#25512;&#33616;&#31995;&#32479;&#23454;&#36341;&#20013;&#30446;&#21069;&#24120;&#29992;&#30340;&#8220;&#25720;&#30528;&#30707;&#22836;&#36807;&#27827;&#8221;&#26041;&#27861;&#65292;&#21628;&#21505;&#25682;&#24323;&#21453;&#20044;&#25176;&#37030;&#24605;&#32500;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#22534;&#26632;&#30340;&#38750;&#26631;&#20934;&#29992;&#27861;&#65292;&#20197;&#35299;&#38145;&#22870;&#21169;&#20248;&#21270;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.02152</link><description>&lt;p&gt;
&#35770;&#25991;&#39064;&#30446;&#65306;&#20026;&#20160;&#20040;&#8220;&#25720;&#30528;&#30707;&#22836;&#36807;&#27827;&#8221;&#26041;&#27861;&#20027;&#23548;&#25512;&#33616;&#31995;&#32479;&#23454;&#36341;&#65307;&#21628;&#21505;&#25682;&#24323;&#21453;&#20044;&#25176;&#37030;&#24605;&#32500;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Why the Shooting in the Dark Method Dominates Recommender Systems Practice; A Call to Abandon Anti-Utopian Thinking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36136;&#30097;&#20102;&#25512;&#33616;&#31995;&#32479;&#23454;&#36341;&#20013;&#30446;&#21069;&#24120;&#29992;&#30340;&#8220;&#25720;&#30528;&#30707;&#22836;&#36807;&#27827;&#8221;&#26041;&#27861;&#65292;&#21628;&#21505;&#25682;&#24323;&#21453;&#20044;&#25176;&#37030;&#24605;&#32500;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#22534;&#26632;&#30340;&#38750;&#26631;&#20934;&#29992;&#27861;&#65292;&#20197;&#35299;&#38145;&#22870;&#21169;&#20248;&#21270;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24212;&#29992;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#22788;&#20110;&#19968;&#31181;&#22855;&#29305;&#30340;&#22659;&#22320;&#12290;&#23613;&#31649;&#22312;&#36890;&#36807;A/B&#27979;&#35797;&#26469;&#34913;&#37327;&#24615;&#33021;&#26041;&#38754;&#26377;&#19968;&#20010;&#38750;&#24120;&#20005;&#26684;&#30340;&#21327;&#35758;&#65292;&#20294;&#25214;&#21040;&#35201;&#27979;&#35797;&#30340;&#8220;B&#8221;&#30340;&#26368;&#20339;&#26041;&#27861;&#24182;&#27809;&#26377;&#26126;&#30830;&#22320;&#38024;&#23545;&#24615;&#33021;&#65292;&#32780;&#26159;&#38024;&#23545;&#19968;&#20010;&#20195;&#29702;&#25351;&#26631;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;A/B&#27979;&#35797;&#30340;&#25104;&#21151;&#25110;&#22833;&#36133;&#23436;&#20840;&#21462;&#20915;&#20110;&#25152;&#25552;&#20986;&#30340;&#20195;&#29702;&#25351;&#26631;&#26159;&#21542;&#19982;&#24615;&#33021;&#30456;&#20851;&#24615;&#26356;&#22909;&#12290;&#27809;&#26377;&#21407;&#21017;&#21487;&#20197;&#22312;&#31163;&#32447;&#24773;&#20917;&#19979;&#30830;&#23450;&#19968;&#20010;&#20195;&#29702;&#25351;&#26631;&#26159;&#21542;&#27604;&#21478;&#19968;&#20010;&#26356;&#22909;&#65292;&#36825;&#20351;&#24471;&#20174;&#19994;&#32773;&#20204;&#25720;&#19981;&#30528;&#22836;&#33041;&#12290;&#26412;&#35770;&#25991;&#30340;&#30446;&#30340;&#26159;&#36136;&#30097;&#36825;&#31181;&#21453;&#20044;&#25176;&#37030;&#24605;&#32500;&#65292;&#24182;&#20027;&#24352;&#28145;&#24230;&#23398;&#20064;&#22534;&#26632;&#30340;&#38750;&#26631;&#20934;&#29992;&#27861;&#23454;&#38469;&#19978;&#26377;&#28508;&#21147;&#35299;&#38145;&#20248;&#21270;&#22870;&#21169;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Applied recommender systems research is in a curious position. While there is a very rigorous protocol for measuring performance by A/B testing, best practice for finding a `B' to test does not explicitly target performance but rather targets a proxy measure. The success or failure of a given A/B test then depends entirely on if the proposed proxy is better correlated to performance than the previous proxy. No principle exists to identify if one proxy is better than another offline, leaving the practitioners shooting in the dark. The purpose of this position paper is to question this anti-Utopian thinking and argue that a non-standard use of the deep learning stacks actually has the potential to unlock reward optimizing recommendation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#21152;&#36895;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#21069;&#30651;&#36807;&#31243;&#65292;&#24182;&#35777;&#26126;&#22312;&#28041;&#21450;&#23884;&#22871;&#26399;&#26395;&#21644;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.02111</link><description>&lt;p&gt;
&#21152;&#36895;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#21069;&#30651;&#65306;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#23601;&#22815;&#20102;
&lt;/p&gt;
&lt;p&gt;
Accelerating Look-ahead in Bayesian Optimization: Multilevel Monte Carlo is All you Need
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#21152;&#36895;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#21069;&#30651;&#36807;&#31243;&#65292;&#24182;&#35777;&#26126;&#22312;&#28041;&#21450;&#23884;&#22871;&#26399;&#26395;&#21644;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;(MLMC)&#26469;&#25552;&#39640;&#28041;&#21450;&#23884;&#22871;&#26399;&#26395;&#21644;&#26368;&#22823;&#21270;&#30340;&#22810;&#27493;&#21069;&#30651;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#26222;&#36890;&#33945;&#29305;&#21345;&#27931;&#30340;&#22797;&#26434;&#24230;&#22312;&#23884;&#22871;&#25805;&#20316;&#20013;&#20250;&#38477;&#20302;&#65292;&#32780;MLMC&#33021;&#22815;&#20197;&#35268;&#33539;&#33945;&#29305;&#21345;&#27931;&#25910;&#25947;&#36895;&#24230;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#65292;&#32780;&#19988;&#19981;&#20381;&#36182;&#20110;&#32500;&#24230;&#21644;&#24179;&#28369;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#19968;&#27493;&#21644;&#20004;&#27493;&#21069;&#30651;&#37319;&#38598;&#20989;&#25968;&#30340;&#36817;&#20284;&#25913;&#36827;&#65292;&#20294;&#27491;&#22914;&#25105;&#20204;&#25152;&#35752;&#35770;&#30340;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#22810;&#31181;&#26041;&#38754;&#26159;&#21487;&#25512;&#24191;&#30340;&#65292;&#21253;&#25324;&#36229;&#36234;BO&#30340;&#32972;&#26223;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#31034;&#20363;&#20013;&#23637;&#31034;&#20102;MLMC&#22312;BO&#20013;&#30340;&#20248;&#21183;&#12290;&#20195;&#30721;&#22312;&#36825;&#37324;&#33719;&#21462;&#65306;https://github.com/Shangda-Yang/MLMCBO&#12290;
&lt;/p&gt;
&lt;p&gt;
We leverage multilevel Monte Carlo (MLMC) to improve the performance of multi-step look-ahead Bayesian optimization (BO) methods that involve nested expectations and maximizations. The complexity rate of naive Monte Carlo degrades for nested operations, whereas MLMC is capable of achieving the canonical Monte Carlo convergence rate for this type of problem, independently of dimension and without any smoothness assumptions. Our theoretical study focuses on the approximation improvements for one- and two-step look-ahead acquisition functions, but, as we discuss, the approach is generalizable in various ways, including beyond the context of BO. Findings are verified numerically and the benefits of MLMC for BO are illustrated on several benchmark examples. Code is available here https://github.com/Shangda-Yang/MLMCBO.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#27880;&#24847;&#32593;&#32476;&#20013;&#30340;&#27880;&#24847;&#21147;&#23450;&#20301;&#38382;&#39064;&#65292;&#36890;&#36807;QK&#29305;&#24449;&#20540;&#35889;&#30340;&#38598;&#20013;&#23450;&#20301;&#29616;&#35937;&#26469;&#35299;&#20915;&#19981;&#21516;&#35266;&#28857;&#20043;&#38388;&#30340;&#30683;&#30462;&#12290;</title><link>https://arxiv.org/abs/2402.02098</link><description>&lt;p&gt;
&#33258;&#27880;&#24847;&#32593;&#32476;&#22312;QK&#29305;&#24449;&#20540;&#35889;&#38598;&#20013;&#26102;&#36827;&#34892;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Self-attention Networks Localize When QK-eigenspectrum Concentrates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#27880;&#24847;&#32593;&#32476;&#20013;&#30340;&#27880;&#24847;&#21147;&#23450;&#20301;&#38382;&#39064;&#65292;&#36890;&#36807;QK&#29305;&#24449;&#20540;&#35889;&#30340;&#38598;&#20013;&#23450;&#20301;&#29616;&#35937;&#26469;&#35299;&#20915;&#19981;&#21516;&#35266;&#28857;&#20043;&#38388;&#30340;&#30683;&#30462;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#27880;&#24847;&#26426;&#21046;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#38750;&#24120;&#27969;&#34892;&#12290;&#23427;&#20855;&#26377;&#36866;&#24212;&#24615;&#36873;&#25321;&#36755;&#20837;&#24207;&#21015;&#20013;&#30340;&#26631;&#35760;&#65292;&#24182;&#36890;&#36807;&#35843;&#33410;&#27880;&#24847;&#21147;&#23450;&#20301;&#30340;&#31243;&#24230;&#26469;&#23454;&#29616;&#65292;&#36825;&#34987;&#24456;&#22810;&#30740;&#31350;&#20154;&#21592;&#35748;&#20026;&#26159;&#24378;&#22823;&#27169;&#22411;&#24615;&#33021;&#30340;&#22522;&#30784;&#65292;&#20294;&#20063;&#22797;&#26434;&#21270;&#20102;&#23398;&#20064;&#21160;&#21147;&#23398;&#30340;&#22522;&#26412;&#26426;&#21046;&#12290;&#36817;&#24180;&#26469;&#65292;&#20027;&#35201;&#26377;&#20004;&#31181;&#35266;&#28857;&#23558;&#27880;&#24847;&#21147;&#23450;&#20301;&#19982;&#27169;&#22411;&#24615;&#33021;&#32852;&#31995;&#36215;&#26469;&#12290;&#19968;&#31181;&#35266;&#28857;&#26159;&#31209;&#22349;&#32553;&#65292;&#21363;&#33258;&#27880;&#24847;&#22359;&#23884;&#20837;&#30340;&#26631;&#35760;&#22312;&#19981;&#21516;&#30340;&#26631;&#35760;&#20043;&#38388;&#21464;&#24471;&#38750;&#24120;&#30456;&#20284;&#65292;&#23548;&#33268;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#38477;&#20302;&#12290;&#21478;&#19968;&#31181;&#35266;&#28857;&#26159;&#29109;&#22349;&#32553;&#65292;&#21363;&#27880;&#24847;&#27010;&#29575;&#25509;&#36817;&#38750;&#22343;&#21248;&#19988;&#29109;&#20302;&#65292;&#20351;&#24471;&#23398;&#20064;&#21160;&#21147;&#23398;&#26356;&#23481;&#26131;&#38519;&#20837;&#24179;&#21488;&#26399;&#12290;&#36825;&#20004;&#31181;&#22833;&#25928;&#27169;&#24335;&#20284;&#20046;&#30456;&#20114;&#30683;&#30462;&#65292;&#22240;&#20026;&#31209;&#21644;&#29109;&#22349;&#32553;&#20998;&#21035;&#19982;&#22343;&#21248;&#21644;&#38750;&#22343;&#21248;&#27880;&#24847;&#21147;&#30456;&#20851;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23545;QK&#29305;&#24449;&#20540;&#35889;&#30340;&#38598;&#20013;&#23450;&#20301;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The self-attention mechanism prevails in modern machine learning. It has an interesting functionality of adaptively selecting tokens from an input sequence by modulating the degree of attention localization, which many researchers speculate is the basis of the powerful model performance but complicates the underlying mechanism of the learning dynamics. In recent years, mainly two arguments have connected attention localization to the model performances. One is the rank collapse, where the embedded tokens by a self-attention block become very similar across different tokens, leading to a less expressive network. The other is the entropy collapse, where the attention probability approaches non-uniform and entails low entropy, making the learning dynamics more likely to be trapped in plateaus. These two failure modes may apparently contradict each other because the rank and entropy collapses are relevant to uniform and non-uniform attention, respectively. To this end, we characterize the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#65292;&#36890;&#36807;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#26679;&#26412;&#35201;&#27714;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02041</link><description>&lt;p&gt;
&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
$\alpha$-Divergence Loss Function for Neural Density Ratio Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#65292;&#36890;&#36807;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#26679;&#26412;&#35201;&#27714;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22522;&#30784;&#25216;&#26415;&#23494;&#24230;&#27604;&#20272;&#35745;(DRE)&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22240;DRE&#30340;&#25439;&#22833;&#20989;&#25968;&#32780;&#20986;&#29616;&#20102;&#20248;&#21270;&#38382;&#39064;&#65306;KL&#25955;&#24230;&#38656;&#35201;&#22823;&#26679;&#26412;&#65292;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#28040;&#22833;&#65292;&#25439;&#22833;&#20989;&#25968;&#26799;&#24230;&#26377;&#20559;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#20379;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#23545;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#25216;&#26415;&#39564;&#35777;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;DRE&#30340;&#26679;&#26412;&#35201;&#27714;&#65292;&#20197;$L_1$&#35823;&#24046;&#30340;&#19978;&#30028;&#32852;&#31995;&#36215;&#26469;&#65292;&#35813;&#19978;&#30028;&#23558;&#39640;&#32500;&#24230;DRE&#20219;&#21153;&#20013;&#30340;&#32500;&#24230;&#35781;&#21650;&#20316;&#20026;&#19968;&#20010;&#20849;&#21516;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, neural networks have produced state-of-the-art results for density-ratio estimation (DRE), a fundamental technique in machine learning. However, existing methods bear optimization issues that arise from the loss functions of DRE: a large sample requirement of Kullback--Leibler (KL)-divergence, vanishing of train loss gradients, and biased gradients of the loss functions. Thus, an $\alpha$-divergence loss function ($\alpha$-Div) that offers concise implementation and stable optimization is proposed in this paper. Furthermore, technical justifications for the proposed loss function are presented. The stability of the proposed loss function is empirically demonstrated and the estimation accuracy of DRE tasks is investigated. Additionally, this study presents a sample requirement for DRE using the proposed loss function in terms of the upper bound of $L_1$ error, which connects a curse of dimensionality as a common problem in high-dimensional DRE tasks.
&lt;/p&gt;</description></item><item><title>GenFormer&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#22810;&#20803;&#38543;&#26426;&#36807;&#31243;&#12290;&#23427;&#33021;&#20445;&#30041;&#30446;&#26631;&#32479;&#35745;&#29305;&#24615;&#65292;&#21253;&#25324;&#36793;&#38469;&#20998;&#24067;&#65292;&#24182;&#33021;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24212;&#29992;&#20013;&#36817;&#20284;&#25429;&#25417;&#21040;&#20854;&#20182;&#26399;&#26395;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;&#24212;&#29992;&#20110;&#39118;&#36895;&#25968;&#25454;&#27169;&#25311;&#30340;&#23454;&#39564;&#20013;&#65292;GenFormer&#27169;&#22411;&#29992;&#20110;&#35745;&#31639;&#39118;&#38505;&#31649;&#29702;&#30340;&#36229;&#36234;&#27010;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.02010</link><description>&lt;p&gt;
GenFormer: &#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#29983;&#25104;&#22810;&#20803;&#38543;&#26426;&#36807;&#31243;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
GenFormer: A Deep-Learning-Based Approach for Generating Multivariate Stochastic Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02010
&lt;/p&gt;
&lt;p&gt;
GenFormer&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#22810;&#20803;&#38543;&#26426;&#36807;&#31243;&#12290;&#23427;&#33021;&#20445;&#30041;&#30446;&#26631;&#32479;&#35745;&#29305;&#24615;&#65292;&#21253;&#25324;&#36793;&#38469;&#20998;&#24067;&#65292;&#24182;&#33021;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24212;&#29992;&#20013;&#36817;&#20284;&#25429;&#25417;&#21040;&#20854;&#20182;&#26399;&#26395;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;&#24212;&#29992;&#20110;&#39118;&#36895;&#25968;&#25454;&#27169;&#25311;&#30340;&#23454;&#39564;&#20013;&#65292;GenFormer&#27169;&#22411;&#29992;&#20110;&#35745;&#31639;&#39118;&#38505;&#31649;&#29702;&#30340;&#36229;&#36234;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#29983;&#25104;&#22120;&#23545;&#20110;&#29983;&#25104;&#20445;&#25345;&#30446;&#26631;&#32479;&#35745;&#29305;&#24615;&#30340;&#21512;&#25104;&#23454;&#29616;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GenFormer&#65292;&#19968;&#20010;&#29992;&#20110;&#26102;&#31354;&#22810;&#20803;&#38543;&#26426;&#36807;&#31243;&#30340;&#38543;&#26426;&#29983;&#25104;&#22120;&#12290;&#23427;&#37319;&#29992;&#22522;&#20110;Transformer&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26500;&#24314;&#65292;&#23398;&#20064;&#20102;&#19968;&#20010;&#23558;&#39532;&#23572;&#21487;&#22827;&#29366;&#24577;&#24207;&#21015;&#26144;&#23556;&#21040;&#26102;&#38388;&#24207;&#21015;&#20540;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;GenFormer&#27169;&#22411;&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#20445;&#30041;&#20102;&#30446;&#26631;&#36793;&#38469;&#20998;&#24067;&#65292;&#24182;&#22312;&#28041;&#21450;&#22823;&#37327;&#31354;&#38388;&#20301;&#32622;&#21644;&#38271;&#26102;&#38388;&#27169;&#25311;&#30340;&#25361;&#25112;&#24615;&#24212;&#29992;&#20013;&#36817;&#20284;&#25429;&#25417;&#21040;&#20854;&#20182;&#26399;&#26395;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;&#25105;&#20204;&#23558;GenFormer&#27169;&#22411;&#24212;&#29992;&#20110;&#22312;&#20315;&#32599;&#37324;&#36798;&#24030;&#30340;&#21508;&#20010;&#31449;&#28857;&#27169;&#25311;&#21512;&#25104;&#39118;&#36895;&#25968;&#25454;&#65292;&#20197;&#35745;&#31639;&#39118;&#38505;&#31649;&#29702;&#30340;&#36229;&#36234;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic generators are essential to produce synthetic realizations that preserve target statistical properties. We propose GenFormer, a stochastic generator for spatio-temporal multivariate stochastic processes. It is constructed using a Transformer-based deep learning model that learns a mapping between a Markov state sequence and time series values. The synthetic data generated by the GenFormer model preserves the target marginal distributions and approximately captures other desired statistical properties even in challenging applications involving a large number of spatial locations and a long simulation horizon. The GenFormer model is applied to simulate synthetic wind speed data at various stations in Florida to calculate exceedance probabilities for risk management.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#39640;&#25928;&#25554;&#20214;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#26377;&#25928;&#20272;&#35745;&#24322;&#36136;&#22240;&#26524;&#23545;&#27604;&#65292;&#24182;&#35299;&#20915;&#20102;&#20854;&#20182;&#23398;&#20064;&#31574;&#30053;&#30340;&#19968;&#20123;&#32570;&#28857;&#12290;&#35813;&#26694;&#26550;&#26500;&#24314;&#20102;&#20154;&#21475;&#39118;&#38505;&#20989;&#25968;&#30340;&#39640;&#25928;&#25554;&#20214;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#31283;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.01972</link><description>&lt;p&gt;
&#32452;&#21512;T-learning&#21644;DR-learning&#65306;&#19968;&#20010;&#29992;&#20110;&#39640;&#25928;&#20272;&#35745;&#22240;&#26524;&#23545;&#27604;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Combining T-learning and DR-learning: a framework for oracle-efficient estimation of causal contrasts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01972
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#39640;&#25928;&#25554;&#20214;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#26377;&#25928;&#20272;&#35745;&#24322;&#36136;&#22240;&#26524;&#23545;&#27604;&#65292;&#24182;&#35299;&#20915;&#20102;&#20854;&#20182;&#23398;&#20064;&#31574;&#30053;&#30340;&#19968;&#20123;&#32570;&#28857;&#12290;&#35813;&#26694;&#26550;&#26500;&#24314;&#20102;&#20154;&#21475;&#39118;&#38505;&#20989;&#25968;&#30340;&#39640;&#25928;&#25554;&#20214;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#31283;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#39640;&#25928;&#25554;&#20214;&#65288;EP&#65289;&#23398;&#20064;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#24322;&#36136;&#22240;&#26524;&#23545;&#27604;&#30340;&#26032;&#26694;&#26550;&#65292;&#20363;&#22914;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#21644;&#26465;&#20214;&#30456;&#23545;&#39118;&#38505;&#12290; EP&#23398;&#20064;&#26694;&#26550;&#20139;&#26377;&#19982;Neyman&#27491;&#20132;&#23398;&#20064;&#31574;&#30053;&#65288;&#22914;DR-learning&#21644;R-learning&#65289;&#30456;&#21516;&#30340;oracle&#25928;&#29575;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#23427;&#20204;&#30340;&#19968;&#20123;&#20027;&#35201;&#32570;&#28857;&#65292;&#21253;&#25324;&#65288;i&#65289;&#23454;&#38469;&#36866;&#29992;&#24615;&#21487;&#33021;&#21463;&#21040;&#25439;&#22833;&#20989;&#25968;&#38750;&#20984;&#24615;&#30340;&#38459;&#30861;&#65307; &#65288;ii&#65289;&#23427;&#20204;&#21487;&#33021;&#22240;&#36829;&#21453;&#30028;&#38480;&#30340;&#20498;&#25968;&#27010;&#29575;&#21152;&#26435;&#21644;&#20266;&#32467;&#26524;&#32780;&#23548;&#33268;&#24615;&#33021;&#21644;&#31283;&#23450;&#24615;&#24046;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#20123;&#32570;&#28857;&#65292;EP&#23398;&#20064;&#32773;&#26500;&#24314;&#20102;&#22240;&#26524;&#23545;&#27604;&#30340;&#20154;&#21475;&#39118;&#38505;&#20989;&#25968;&#30340;&#39640;&#25928;&#25554;&#20214;&#20272;&#35745;&#22120;&#65292;&#20174;&#32780;&#32487;&#25215;&#20102;T-learning&#31561;&#25554;&#20214;&#20272;&#35745;&#31574;&#30053;&#30340;&#31283;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#29305;&#24615;&#12290;&#22312;&#21512;&#29702;&#26465;&#20214;&#19979;&#65292;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;EP&#23398;&#20064;&#32773;&#20855;&#26377;oracle&#25928;&#29575;&#65292;&#34920;&#29616;&#20986;&#28176;&#36817;&#31561;&#20215;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce efficient plug-in (EP) learning, a novel framework for the estimation of heterogeneous causal contrasts, such as the conditional average treatment effect and conditional relative risk. The EP-learning framework enjoys the same oracle-efficiency as Neyman-orthogonal learning strategies, such as DR-learning and R-learning, while addressing some of their primary drawbacks, including that (i) their practical applicability can be hindered by loss function non-convexity; and (ii) they may suffer from poor performance and instability due to inverse probability weighting and pseudo-outcomes that violate bounds. To avoid these drawbacks, EP-learner constructs an efficient plug-in estimator of the population risk function for the causal contrast, thereby inheriting the stability and robustness properties of plug-in estimation strategies like T-learning. Under reasonable conditions, EP-learners based on empirical risk minimization are oracle-efficient, exhibiting asymptotic equivalen
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#65292;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.01900</link><description>&lt;p&gt;
&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Distributional Off-policy Evaluation with Bellman Residual Minimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01900
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#65292;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#30340;&#38382;&#39064;&#65292;&#23427;&#26159;&#35768;&#22810;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#31639;&#27861;&#30340;&#22522;&#30784;&#12290;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26041;&#27861;&#65288;&#20381;&#36182;&#20110;&#26368;&#22823;&#20540;-&#25193;&#23637;&#30340;&#32479;&#35745;&#36317;&#31163;&#65292;&#22914;&#26368;&#22823;&#20540;Wasserstein&#36317;&#31163;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30740;&#31350;&#29992;&#20110;&#37327;&#21270;&#20998;&#24067;&#24335;Bellman&#27531;&#24046;&#30340;&#26399;&#26395;-&#25193;&#23637;&#30340;&#32479;&#35745;&#36317;&#31163;&#65292;&#24182;&#19988;&#35777;&#26126;&#23427;&#21487;&#20197;&#19978;&#30028;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#30340;&#26399;&#26395;&#35823;&#24046;&#12290;&#22522;&#20110;&#36825;&#20010;&#26377;&#21560;&#24341;&#21147;&#30340;&#24615;&#36136;&#65292;&#36890;&#36807;&#23558;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#26694;&#26550;&#25512;&#24191;&#21040;DRL&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#27493;&#24341;&#23548;&#36807;&#31243;&#30340;&#26041;&#27861;&#30340;&#21464;&#20307;&#65292;&#20197;&#23454;&#29616;&#22810;&#27493;&#25193;&#23637;&#12290;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#27493;&#38271;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of distributional off-policy evaluation which serves as the foundation of many distributional reinforcement learning (DRL) algorithms. In contrast to most existing works (that rely on supremum-extended statistical distances such as supremum-Wasserstein distance), we study the expectation-extended statistical distance for quantifying the distributional Bellman residuals and show that it can upper bound the expected error of estimating the return distribution. Based on this appealing property, by extending the framework of Bellman residual minimization to DRL, we propose a method called Energy Bellman Residual Minimizer (EBRM) to estimate the return distribution. We establish a finite-sample error bound for the EBRM estimator under the realizability assumption. Furthermore, we introduce a variant of our method based on a multi-step bootstrapping procedure to enable multi-step extension. By selecting an appropriate step level, we obtain a better error bound for thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25913;&#36827;&#20102;&#22522;&#20110;f-&#25955;&#24230;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;f-&#39046;&#22495;&#24046;&#24322;&#24230;&#37327;&#25351;&#26631;&#65292;&#24182;&#36890;&#36807;&#21435;&#38500;&#32477;&#23545;&#20540;&#20989;&#25968;&#21644;&#24341;&#20837;&#32553;&#25918;&#21442;&#25968;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#30446;&#26631;&#35823;&#24046;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#20174;&#32780;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#24674;&#22797;&#20197;&#21069;&#30340;KL&#32467;&#26524;&#65292;&#23558;&#31639;&#27861;&#21644;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#32553;&#23567;&#65292;&#24182;&#36890;&#36807;&#23450;&#20301;&#25216;&#26415;&#24320;&#21457;&#20102;&#24555;&#36895;&#29575;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#22522;&#20110;f-DD&#30340;&#39046;&#22495;&#23398;&#20064;&#31639;&#27861;&#22312;&#27969;&#34892;&#30340;UDA&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.01887</link><description>&lt;p&gt;
&#22522;&#20110;f-&#25955;&#24230;&#21407;&#29702;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#65306;&#19968;&#20010;&#25913;&#36827;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
On f-Divergence Principled Domain Adaptation: An Improved Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25913;&#36827;&#20102;&#22522;&#20110;f-&#25955;&#24230;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;f-&#39046;&#22495;&#24046;&#24322;&#24230;&#37327;&#25351;&#26631;&#65292;&#24182;&#36890;&#36807;&#21435;&#38500;&#32477;&#23545;&#20540;&#20989;&#25968;&#21644;&#24341;&#20837;&#32553;&#25918;&#21442;&#25968;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#30446;&#26631;&#35823;&#24046;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#20174;&#32780;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#24674;&#22797;&#20197;&#21069;&#30340;KL&#32467;&#26524;&#65292;&#23558;&#31639;&#27861;&#21644;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#32553;&#23567;&#65292;&#24182;&#36890;&#36807;&#23450;&#20301;&#25216;&#26415;&#24320;&#21457;&#20102;&#24555;&#36895;&#29575;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#22522;&#20110;f-DD&#30340;&#39046;&#22495;&#23398;&#20064;&#31639;&#27861;&#22312;&#27969;&#34892;&#30340;UDA&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#22312;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25913;&#36827;Acuna&#31561;&#20154;&#65288;2021&#24180;&#65289;&#25552;&#20986;&#30340;UDA&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#23545;&#20854;&#22522;&#20110;f-&#25955;&#24230;&#30340;&#24046;&#24322;&#24230;&#36827;&#34892;&#20102;&#25913;&#36827;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#21363;f-&#39046;&#22495;&#24046;&#24322;&#65288;f-DD&#65289;&#12290;&#36890;&#36807;&#21435;&#38500;&#32477;&#23545;&#20540;&#20989;&#25968;&#24182;&#24341;&#20837;&#19968;&#20010;&#32553;&#25918;&#21442;&#25968;&#65292;f-DD&#20135;&#29983;&#20102;&#26032;&#30340;&#30446;&#26631;&#35823;&#24046;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#24674;&#22797;&#20197;&#21069;&#22522;&#20110;KL&#30340;&#32467;&#26524;&#65292;&#24182;&#24357;&#21512;&#20102;Acuna&#31561;&#20154;&#65288;2021&#24180;&#65289;&#20013;&#25552;&#20986;&#30340;&#31639;&#27861;&#21644;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#21033;&#29992;&#23450;&#20301;&#25216;&#26415;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#24555;&#36895;&#29575;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#27969;&#34892;&#30340;UDA&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#22522;&#20110;f-DD&#30340;&#39046;&#22495;&#23398;&#20064;&#31639;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain adaptation (UDA) plays a crucial role in addressing distribution shifts in machine learning. In this work, we improve the theoretical foundations of UDA proposed by Acuna et al. (2021) by refining their f-divergence-based discrepancy and additionally introducing a new measure, f-domain discrepancy (f-DD). By removing the absolute value function and incorporating a scaling parameter, f-DD yields novel target error and sample complexity bounds, allowing us to recover previous KL-based results and bridging the gap between algorithms and theory presented in Acuna et al. (2021). Leveraging a localization technique, we also develop a fast-rate generalization bound. Empirical results demonstrate the superior performance of f-DD-based domain learning algorithms over previous works in popular UDA benchmarks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#35757;&#32451;PINNs&#30340;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#65292;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;NNCG&#24182;&#20248;&#21270;&#20102;PINN&#24615;&#33021;&#65292;&#20026;&#35757;&#32451;PINNs&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#21644;&#26356;&#24378;&#22823;&#30340;&#20248;&#21270;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.01868</link><description>&lt;p&gt;
&#35757;&#32451;PINNs&#30340;&#25361;&#25112;&#65306;&#20174;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#35282;&#24230;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Challenges in Training PINNs: A Loss Landscape Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#35757;&#32451;PINNs&#30340;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#65292;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;NNCG&#24182;&#20248;&#21270;&#20102;PINN&#24615;&#33021;&#65292;&#20026;&#35757;&#32451;PINNs&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#21644;&#26356;&#24378;&#22823;&#30340;&#20248;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#30340;&#35757;&#32451;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#26368;&#23567;&#21270;PINN&#25439;&#22833;&#20989;&#25968;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#27531;&#24046;&#39033;&#20013;&#30340;&#24494;&#20998;&#31639;&#23376;&#24341;&#36215;&#30340;&#30149;&#24577;&#26465;&#20214;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#22120;Adam&#12289;L-BFGS&#20197;&#21450;&#23427;&#20204;&#30340;&#32452;&#21512;Adam+L-BFGS&#30340;&#24615;&#33021;&#65292;&#34920;&#26126;Adam+L-BFGS&#26356;&#20248;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;NysNewton-CG&#65288;NNCG&#65289;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;PINN&#30340;&#24615;&#33021;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#30149;&#24577;&#24494;&#20998;&#31639;&#23376;&#19982;PINN&#25439;&#22833;&#20013;&#30340;&#30149;&#24577;&#26465;&#20214;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#23637;&#31034;&#20102;&#32467;&#21512;&#19968;&#38454;&#21644;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#35757;&#32451;PINNs&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#21644;&#26356;&#24378;&#22823;&#30340;&#20248;&#21270;&#31574;&#30053;&#65292;&#21487;&#20197;&#25552;&#39640;PINNs&#22312;&#35299;&#20915;&#22256;&#38590;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores challenges in training Physics-Informed Neural Networks (PINNs), emphasizing the role of the loss landscape in the training process. We examine difficulties in minimizing the PINN loss function, particularly due to ill-conditioning caused by differential operators in the residual term. We compare gradient-based optimizers Adam, L-BFGS, and their combination Adam+L-BFGS, showing the superiority of Adam+L-BFGS, and introduce a novel second-order optimizer, NysNewton-CG (NNCG), which significantly improves PINN performance. Theoretically, our work elucidates the connection between ill-conditioned differential operators and ill-conditioning in the PINN loss and shows the benefits of combining first- and second-order optimization methods. Our work presents valuable insights and more powerful optimization strategies for training PINNs, which could improve the utility of PINNs for solving difficult partial differential equations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26356;&#26032;&#20013;&#30340;&#36951;&#24536;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#19978;&#28216;&#23454;&#20363;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;&#26681;&#25454;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#21464;&#21270;&#19982;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#30456;&#20284;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.01865</link><description>&lt;p&gt;
&#25105;&#30340;&#27169;&#22411;&#20250;&#24536;&#35760;&#20160;&#20040;&#65311;&#35821;&#35328;&#27169;&#22411;&#25913;&#36827;&#20013;&#30340;&#34987;&#36951;&#24536;&#23454;&#20363;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26356;&#26032;&#20013;&#30340;&#36951;&#24536;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#19978;&#28216;&#23454;&#20363;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;&#26681;&#25454;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#21464;&#21270;&#19982;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#30456;&#20284;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#35821;&#35328;&#27169;&#22411;&#20250;&#20986;&#29616;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#20165;&#20165;&#36890;&#36807;&#23558;&#27169;&#22411;&#26356;&#26032;&#20026;&#32416;&#27491;&#38169;&#35823;&#23454;&#20363;&#65292;&#20250;&#23548;&#33268;&#28798;&#38590;&#24615;&#30340;&#36951;&#24536;&#65292;&#26356;&#26032;&#21518;&#30340;&#27169;&#22411;&#22312;&#25351;&#23548;&#24494;&#35843;&#25110;&#19978;&#28216;&#35757;&#32451;&#38454;&#27573;&#20013;&#23398;&#21040;&#30340;&#23454;&#20363;&#19978;&#20986;&#29616;&#38169;&#35823;&#12290;&#38543;&#26426;&#37325;&#25773;&#19978;&#28216;&#25968;&#25454;&#30340;&#25928;&#26524;&#19981;&#20196;&#20154;&#28385;&#24847;&#65292;&#24448;&#24448;&#20276;&#38543;&#30528;&#36739;&#39640;&#30340;&#26041;&#24046;&#21644;&#36739;&#24046;&#30340;&#21487;&#25511;&#24615;&#12290;&#20026;&#20102;&#25913;&#21892;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#35797;&#22270;&#39044;&#27979;&#30001;&#20110;&#27169;&#22411;&#26356;&#26032;&#32780;&#36951;&#24536;&#30340;&#19978;&#28216;&#23454;&#20363;&#12290;&#25105;&#20204;&#26681;&#25454;&#19968;&#32452;&#22312;&#32447;&#23398;&#20064;&#30340;&#23454;&#20363;&#21644;&#30456;&#24212;&#34987;&#36951;&#24536;&#30340;&#19978;&#28216;&#39044;&#35757;&#32451;&#23454;&#20363;&#35757;&#32451;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#36825;&#26679;&#30340;&#35266;&#23519;&#32467;&#26524;&#65306;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#30340;&#21464;&#21270;&#31867;&#20284;&#20110;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#21464;&#21270;&#65292;&#36825;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#19981;&#38169;&#30340;&#25928;&#26524;&#65292;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Language models deployed in the wild make errors. However, simply updating the model with the corrected error instances causes catastrophic forgetting -- the updated model makes errors on instances learned during the instruction tuning or upstream training phase. Randomly replaying upstream data yields unsatisfactory performance and often comes with high variance and poor controllability. To this end, we try to forecast upstream examples that will be forgotten due to a model update for improved controllability of the replay process and interpretability. We train forecasting models given a collection of online learned examples and corresponding forgotten upstream pre-training examples. We propose a partially interpretable forecasting model based on the observation that changes in pre-softmax logit scores of pretraining examples resemble that of online learned examples, which performs decently on BART but fails on T5 models. We further show a black-box classifier based on inner products 
&lt;/p&gt;</description></item><item><title>SPDE&#20808;&#39564;&#22312;&#26368;&#20248;&#25554;&#20540;&#20013;&#30340;&#24212;&#29992;&#21450;&#20854;&#19982;&#31070;&#32463;&#32593;&#32476;&#30340;&#32852;&#21512;&#23398;&#20064;&#38382;&#39064;&#65292;&#20026;&#22823;&#35268;&#27169;&#22320;&#29699;&#29289;&#29702;&#25968;&#25454;&#38598;&#30340;&#26102;&#31354;&#25554;&#20540;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.01855</link><description>&lt;p&gt;
SPDE&#20808;&#39564;&#22312;&#31471;&#21040;&#31471;&#31070;&#32463;&#25968;&#25454;&#21516;&#21270;&#26041;&#26696;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
SPDE priors for uncertainty quantification of end-to-end neural data assimilation schemes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01855
&lt;/p&gt;
&lt;p&gt;
SPDE&#20808;&#39564;&#22312;&#26368;&#20248;&#25554;&#20540;&#20013;&#30340;&#24212;&#29992;&#21450;&#20854;&#19982;&#31070;&#32463;&#32593;&#32476;&#30340;&#32852;&#21512;&#23398;&#20064;&#38382;&#39064;&#65292;&#20026;&#22823;&#35268;&#27169;&#22320;&#29699;&#29289;&#29702;&#25968;&#25454;&#38598;&#30340;&#26102;&#31354;&#25554;&#20540;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#22320;&#29699;&#29289;&#29702;&#25968;&#25454;&#38598;&#30340;&#26102;&#31354;&#25554;&#20540;&#36890;&#24120;&#36890;&#36807;&#26368;&#20248;&#25554;&#20540;(Optimal Interpolation&#65292;OI)&#21644;&#26356;&#22797;&#26434;&#30340;&#22522;&#20110;&#27169;&#22411;&#25110;&#25968;&#25454;&#39537;&#21160;&#30340;&#25968;&#25454;&#21516;&#21270;&#25216;&#26415;&#26469;&#22788;&#29702;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;(Spatio-temporal Partial Differential Equations&#65292;SPDE)&#21644;&#39640;&#26031;&#39532;&#23572;&#31185;&#22827;&#38543;&#26426;&#22330;(Gaussian Markov Random Fields&#65292;GMRF)&#20043;&#38388;&#30340;&#32852;&#31995;&#24320;&#36767;&#20102;&#19968;&#26465;&#26032;&#30340;&#36884;&#24452;&#65292;&#29992;&#20110;&#22788;&#29702;&#26368;&#20248;&#25554;&#20540;&#20013;&#30340;&#22823;&#25968;&#25454;&#38598;&#21644;&#29289;&#29702;&#35825;&#23548;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#28145;&#24230;&#23398;&#20064;&#31038;&#21306;&#30340;&#26368;&#26032;&#36827;&#23637;&#20063;&#20351;&#24471;&#21487;&#20197;&#23558;&#36825;&#20010;&#38382;&#39064;&#35270;&#20026;&#23884;&#20837;&#25968;&#25454;&#21516;&#21270;&#21464;&#20998;&#26694;&#26550;&#30340;&#31070;&#32463;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#30340;&#32852;&#21512;&#23398;&#20064;&#38382;&#39064;&#12290;&#37325;&#24314;&#20219;&#21153;&#34987;&#35270;&#20026;&#19968;&#20010;&#21253;&#21547;&#22312;&#21464;&#20998;&#20869;&#37096;&#25104;&#26412;&#20013;&#30340;&#20808;&#39564;&#23398;&#20064;&#38382;&#39064;&#21644;&#21518;&#32773;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26368;&#23567;&#21270;&#65306;&#20808;&#39564;&#27169;&#22411;&#21644;&#27714;&#35299;&#22120;&#37117;&#34987;&#34920;&#31034;&#20026;&#20855;&#26377;&#33258;&#21160;&#24494;&#20998;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;&#26469;&#35757;&#32451;&#65292;&#35813;&#25439;&#22833;&#20989;&#25968;&#36890;&#24120;&#34987;&#34920;&#31034;&#20026;&#19968;&#20123;&#30495;&#23454;&#20540;&#21644;&#37325;&#24314;&#20540;&#20043;&#38388;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The spatio-temporal interpolation of large geophysical datasets has historically been adressed by Optimal Interpolation (OI) and more sophisticated model-based or data-driven DA techniques. In the last ten years, the link established between Stochastic Partial Differential Equations (SPDE) and Gaussian Markov Random Fields (GMRF) opened a new way of handling both large datasets and physically-induced covariance matrix in Optimal Interpolation. Recent advances in the deep learning community also enables to adress this problem as neural architecture embedding data assimilation variational framework. The reconstruction task is seen as a joint learning problem of the prior involved in the variational inner cost and the gradient-based minimization of the latter: both prior models and solvers are stated as neural networks with automatic differentiation which can be trained by minimizing a loss function, typically stated as the mean squared error between some ground truth and the reconstructi
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22312;&#32447;&#24179;&#21488;&#20013;&#19982;&#24178;&#25200;&#36827;&#34892;&#30340;&#23454;&#39564;&#12290;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#32773;&#20998;&#37197;&#19981;&#21516;&#30340;&#33218;&#32473;&#27599;&#20010;&#23454;&#39564;&#21333;&#20803;&#65292;&#26681;&#25454;&#21333;&#20803;&#20043;&#38388;&#30340;&#31354;&#38388;&#36317;&#31163;&#21644;&#23545;&#25163;&#36873;&#25321;&#30340;&#21305;&#37197;&#20989;&#25968;&#26469;&#20915;&#23450;&#27599;&#20010;&#21333;&#20803;&#22312;&#27599;&#36718;&#30340;&#22238;&#25253;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36716;&#25442;&#25919;&#31574;&#33021;&#22815;&#23454;&#29616;&#26368;&#20339;&#30340;&#39044;&#26399;&#36951;&#25022;&#65292;&#20294;&#20219;&#20309;&#36716;&#25442;&#25919;&#31574;&#37117;&#20250;&#36973;&#21463;&#19968;&#23450;&#30340;&#36951;&#25022;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2402.01845</link><description>&lt;p&gt;
&#20855;&#26377;&#24178;&#25200;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Multi-Armed Bandits with Interference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01845
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22312;&#32447;&#24179;&#21488;&#20013;&#19982;&#24178;&#25200;&#36827;&#34892;&#30340;&#23454;&#39564;&#12290;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#32773;&#20998;&#37197;&#19981;&#21516;&#30340;&#33218;&#32473;&#27599;&#20010;&#23454;&#39564;&#21333;&#20803;&#65292;&#26681;&#25454;&#21333;&#20803;&#20043;&#38388;&#30340;&#31354;&#38388;&#36317;&#31163;&#21644;&#23545;&#25163;&#36873;&#25321;&#30340;&#21305;&#37197;&#20989;&#25968;&#26469;&#20915;&#23450;&#27599;&#20010;&#21333;&#20803;&#22312;&#27599;&#36718;&#30340;&#22238;&#25253;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36716;&#25442;&#25919;&#31574;&#33021;&#22815;&#23454;&#29616;&#26368;&#20339;&#30340;&#39044;&#26399;&#36951;&#25022;&#65292;&#20294;&#20219;&#20309;&#36716;&#25442;&#25919;&#31574;&#37117;&#20250;&#36973;&#21463;&#19968;&#23450;&#30340;&#36951;&#25022;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20195;&#22312;&#32447;&#24179;&#21488;&#19978;&#65292;&#19982;&#24178;&#25200;&#36827;&#34892;&#23454;&#39564;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#20197;&#24448;&#26377;&#20851;&#24178;&#25200;&#23454;&#39564;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#25919;&#31574;&#30340;&#26368;&#32456;&#36755;&#20986;&#19978;&#65292;&#32780;&#23545;&#20110;&#32047;&#35745;&#24615;&#33021;&#21017;&#20102;&#35299;&#19981;&#36275;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#20855;&#26377;&#24178;&#25200;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#8221;&#65288;MABI&#65289;&#38382;&#39064;&#65292;&#22312;&#26102;&#38388;&#27573;&#20026;T&#36718;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#32773;&#20026;N&#20010;&#23454;&#39564;&#21333;&#20803;&#20013;&#30340;&#27599;&#20010;&#20998;&#37197;&#19968;&#20010;&#33218;&#12290;&#27599;&#20010;&#21333;&#20803;&#22312;&#27599;&#19968;&#36718;&#30340;&#22238;&#25253;&#21462;&#20915;&#20110;&#8220;&#25152;&#26377;&#8221;&#21333;&#20803;&#30340;&#27835;&#30103;&#26041;&#24335;&#65292;&#32780;&#21333;&#20803;&#20043;&#38388;&#30340;&#31354;&#38388;&#36317;&#31163;&#20250;&#23548;&#33268;&#21333;&#20803;&#30340;&#24433;&#21709;&#21147;&#36880;&#28176;&#34928;&#20943;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#36890;&#29992;&#35774;&#32622;&#65292;&#20854;&#20013;&#22238;&#25253;&#20989;&#25968;&#30001;&#23545;&#25163;&#36873;&#25321;&#65292;&#24182;&#19988;&#22312;&#36718;&#27425;&#21644;&#21333;&#20803;&#20043;&#38388;&#21487;&#20197;&#20219;&#24847;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#36716;&#25442;&#25919;&#31574;&#33021;&#22815;&#23545;&#26368;&#20339;&#22266;&#23450;&#33218;&#25919;&#31574;&#23454;&#29616;&#26368;&#20248;&#30340;&#8220;&#39044;&#26399;&#8221;&#36951;&#25022;&#65292;&#36951;&#25022;&#20540;&#20026;$O(\sqrt T)$&#12290;&#28982;&#32780;&#65292;&#20219;&#20309;&#19968;&#20010;&#36716;&#25442;&#25919;&#31574;&#30340;&#36951;&#25022;&#65288;&#20316;&#20026;&#19968;&#20010;&#38543;&#26426;&#21464;&#37327;&#65289;&#37117;&#20250;&#36973;&#21463;&#19968;&#23450;&#30340;&#36951;&#25022;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Experimentation with interference poses a significant challenge in contemporary online platforms. Prior research on experimentation with interference has concentrated on the final output of a policy. The cumulative performance, while equally crucial, is less well understood. To address this gap, we introduce the problem of {\em Multi-armed Bandits with Interference} (MABI), where the learner assigns an arm to each of $N$ experimental units over a time horizon of $T$ rounds. The reward of each unit in each round depends on the treatments of {\em all} units, where the influence of a unit decays in the spatial distance between units. Furthermore, we employ a general setup wherein the reward functions are chosen by an adversary and may vary arbitrarily across rounds and units. We first show that switchback policies achieve an optimal {\em expected} regret $\tilde O(\sqrt T)$ against the best fixed-arm policy. Nonetheless, the regret (as a random variable) for any switchback policy suffers 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#27169;&#22411;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#21644;&#25511;&#21046;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.01810</link><description>&lt;p&gt;
&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#30340;&#38169;&#35823;&#35268;&#33539;&#21270;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Misspecification uncertainties in near-deterministic regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01810
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#27169;&#22411;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#21644;&#25511;&#21046;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#25439;&#22833;&#26159;&#27169;&#22411;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#21487;&#29992;&#20110;&#23398;&#20064;&#30340;&#40065;&#26834;PAC-Bayes&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#25439;&#22833;&#26368;&#23567;&#21270;&#34987;&#35748;&#20026;&#24573;&#30053;&#20102;&#38169;&#35823;&#35268;&#33539;&#21270;&#65292;&#21363;&#27169;&#22411;&#19981;&#33021;&#23436;&#20840;&#22797;&#21046;&#35266;&#27979;&#32467;&#26524;&#12290;&#36825;&#23548;&#33268;&#22823;&#25968;&#25454;&#25110;&#27424;&#21442;&#25968;&#21270;&#26497;&#38480;&#19979;&#23545;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#26174;&#33879;&#20302;&#20272;&#12290;&#25105;&#20204;&#20998;&#26512;&#36817;&#30830;&#23450;&#24615;&#12289;&#38169;&#35823;&#35268;&#33539;&#21270;&#21644;&#27424;&#21442;&#25968;&#21270;&#26367;&#20195;&#27169;&#22411;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36825;&#26159;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#24191;&#27867;&#30456;&#20851;&#30340;&#19968;&#20010;&#39046;&#22495;&#12290;&#25105;&#20204;&#35777;&#26126;&#21518;&#39564;&#20998;&#24067;&#24517;&#39035;&#35206;&#30422;&#27599;&#20010;&#35757;&#32451;&#28857;&#65292;&#20197;&#36991;&#20813;&#21457;&#25955;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#23548;&#20986;&#19968;&#20010;&#31526;&#21512;&#36825;&#20010;&#32422;&#26463;&#30340;&#32452;&#21512;&#27169;&#22411;&#12290;&#23545;&#20110;&#32447;&#24615;&#27169;&#22411;&#65292;&#36825;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#20135;&#29983;&#30340;&#39069;&#22806;&#24320;&#38144;&#26368;&#23567;&#12290;&#36825;&#31181;&#39640;&#25928;&#26041;&#27861;&#22312;&#27169;&#22411;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#21407;&#23376;&#23610;&#24230;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
The expected loss is an upper bound to the model generalization error which admits robust PAC-Bayes bounds for learning. However, loss minimization is known to ignore misspecification, where models cannot exactly reproduce observations. This leads to significant underestimates of parameter uncertainties in the large data, or underparameterized, limit. We analyze the generalization error of near-deterministic, misspecified and underparametrized surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and derive an ensemble {ansatz} that respects this constraint, which for linear models incurs minimal overhead. The efficient approach is demonstrated on model problems before application to high dimensional datasets in atomistic machine learning. Parameter uncertainties from misspecification survive in the underparametrized limit, giving accurate prediction and boundin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#25991;&#26412;&#21644;&#22270;&#20687;&#22312;&#22240;&#26524;&#25512;&#26029;&#21644;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#26041;&#27861;&#21644;&#26550;&#26500;&#22312;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#19982;&#26631;&#20934;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#26174;&#31034;&#20102;&#30452;&#25509;&#20351;&#29992;&#25991;&#26412;&#21644;&#22270;&#20687;&#36827;&#34892;&#22240;&#26524;&#30740;&#31350;&#30340;&#28508;&#22312;&#22909;&#22788;&#12290;</title><link>https://arxiv.org/abs/2402.01785</link><description>&lt;p&gt;
DoubleMLDeep: &#21033;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#23545;&#22240;&#26524;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
DoubleMLDeep: Estimation of Causal Effects with Multimodal Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#25991;&#26412;&#21644;&#22270;&#20687;&#22312;&#22240;&#26524;&#25512;&#26029;&#21644;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#26041;&#27861;&#21644;&#26550;&#26500;&#22312;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#19982;&#26631;&#20934;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#26174;&#31034;&#20102;&#30452;&#25509;&#20351;&#29992;&#25991;&#26412;&#21644;&#22270;&#20687;&#36827;&#34892;&#22240;&#26524;&#30740;&#31350;&#30340;&#28508;&#22312;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#22240;&#26524;&#25512;&#26029;&#21644;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#20351;&#29992;&#38750;&#32467;&#26500;&#21270;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#65292;&#21363;&#25991;&#26412;&#21644;&#22270;&#20687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#20110;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#37096;&#20998;&#32447;&#24615;&#27169;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;&#25105;&#20204;&#35770;&#25991;&#30340;&#21478;&#19968;&#20010;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#35780;&#20272;&#22312;&#25991;&#26412;&#21644;&#22270;&#20687;&#20316;&#20026;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#24182;&#19982;&#26631;&#20934;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#65292;&#31361;&#20986;&#20102;&#30452;&#25509;&#22312;&#22240;&#26524;&#30740;&#31350;&#20013;&#20351;&#29992;&#25991;&#26412;&#21644;&#22270;&#20687;&#30340;&#28508;&#22312;&#22909;&#22788;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#23545;&#32463;&#27982;&#23398;&#12289;&#24066;&#22330;&#33829;&#38144;&#12289;&#37329;&#34701;&#12289;&#21307;&#23398;&#21644;&#25968;&#25454;&#31185;&#23398;&#31561;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#20182;&#20204;&#24076;&#26395;&#20351;&#29992;&#38750;&#20256;&#32479;&#25968;&#25454;&#20272;&#35745;&#22240;&#26524;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the use of unstructured, multimodal data, namely text and images, in causal inference and treatment effect estimation. We propose a neural network architecture that is adapted to the double machine learning (DML) framework, specifically the partially linear model. An additional contribution of our paper is a new method to generate a semi-synthetic dataset which can be used to evaluate the performance of causal effect estimation in the presence of text and images as confounders. The proposed methods and architectures are evaluated on the semi-synthetic dataset and compared to standard approaches, highlighting the potential benefit of using text and images directly in causal studies. Our findings have implications for researchers and practitioners in economics, marketing, finance, medicine and data science in general who are interested in estimating causal quantities using non-traditional data.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21363;&#25554;&#21363;&#29992;&#22270;&#20687;&#24674;&#22797;&#26694;&#26550;&#65292;&#31216;&#20026;&#38543;&#26426;&#21435;&#22122;&#27491;&#21017;&#21270;&#65288;SNORE&#65289;&#12290;&#35813;&#26694;&#26550;&#22312;&#24688;&#24403;&#22122;&#22768;&#27700;&#24179;&#30340;&#22270;&#20687;&#19978;&#24212;&#29992;&#21435;&#22122;&#22120;&#65292;&#24182;&#22522;&#20110;&#38543;&#26426;&#27491;&#21017;&#21270;&#25552;&#20379;&#20102;&#35299;&#20915;&#30149;&#24577;&#36870;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SNORE&#22312;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.01779</link><description>&lt;p&gt;
&#24102;&#26377;&#38543;&#26426;&#21435;&#22122;&#27491;&#21017;&#21270;&#30340;&#21363;&#25554;&#21363;&#29992;&#22270;&#20687;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play image restoration with Stochastic deNOising REgularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21363;&#25554;&#21363;&#29992;&#22270;&#20687;&#24674;&#22797;&#26694;&#26550;&#65292;&#31216;&#20026;&#38543;&#26426;&#21435;&#22122;&#27491;&#21017;&#21270;&#65288;SNORE&#65289;&#12290;&#35813;&#26694;&#26550;&#22312;&#24688;&#24403;&#22122;&#22768;&#27700;&#24179;&#30340;&#22270;&#20687;&#19978;&#24212;&#29992;&#21435;&#22122;&#22120;&#65292;&#24182;&#22522;&#20110;&#38543;&#26426;&#27491;&#21017;&#21270;&#25552;&#20379;&#20102;&#35299;&#20915;&#30149;&#24577;&#36870;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SNORE&#22312;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21363;&#25554;&#21363;&#29992;&#65288;PnP&#65289;&#31639;&#27861;&#26159;&#19968;&#31867;&#36845;&#20195;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#29289;&#29702;&#27169;&#22411;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27491;&#21017;&#21270;&#26469;&#35299;&#20915;&#22270;&#20687;&#21453;&#28436;&#38382;&#39064;&#12290;&#23613;&#31649;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#20135;&#29983;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#22270;&#20687;&#24674;&#22797;&#32467;&#26524;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#22312;&#36845;&#20195;&#36807;&#31243;&#20013;&#36234;&#26469;&#36234;&#23569;&#22122;&#38899;&#30340;&#22270;&#20687;&#19978;&#30340;&#19968;&#31181;&#38750;&#26631;&#20934;&#30340;&#21435;&#22122;&#22120;&#20351;&#29992;&#26041;&#27861;&#65292;&#36825;&#19982;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#65288;DM&#65289;&#30340;&#26368;&#26032;&#31639;&#27861;&#30456;&#30683;&#30462;&#65292;&#22312;&#36825;&#20123;&#31639;&#27861;&#20013;&#65292;&#21435;&#22122;&#22120;&#20165;&#24212;&#29992;&#20110;&#37325;&#26032;&#21152;&#22122;&#30340;&#22270;&#20687;&#19978;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PnP&#26694;&#26550;&#65292;&#31216;&#20026;&#38543;&#26426;&#21435;&#22122;&#27491;&#21017;&#21270;&#65288;SNORE&#65289;&#65292;&#23427;&#20165;&#22312;&#22122;&#22768;&#27700;&#24179;&#36866;&#24403;&#30340;&#22270;&#20687;&#19978;&#24212;&#29992;&#21435;&#22122;&#22120;&#12290;&#23427;&#22522;&#20110;&#26174;&#24335;&#30340;&#38543;&#26426;&#27491;&#21017;&#21270;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#19968;&#31181;&#35299;&#20915;&#30149;&#24577;&#36870;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#31639;&#27861;&#21450;&#20854;&#36864;&#28779;&#25193;&#23637;&#30340;&#25910;&#25947;&#20998;&#26512;&#12290;&#22312;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;SNORE&#22312;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#20219;&#21153;&#19978;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play (PnP) algorithms are a class of iterative algorithms that address image inverse problems by combining a physical model and a deep neural network for regularization. Even if they produce impressive image restoration results, these algorithms rely on a non-standard use of a denoiser on images that are less and less noisy along the iterations, which contrasts with recent algorithms based on Diffusion Models (DM), where the denoiser is applied only on re-noised images. We propose a new PnP framework, called Stochastic deNOising REgularization (SNORE), which applies the denoiser only on images with noise of the adequate level. It is based on an explicit stochastic regularization, which leads to a stochastic gradient descent algorithm to solve ill-posed inverse problems. A convergence analysis of this algorithm and its annealing extension is provided. Experimentally, we prove that SNORE is competitive with respect to state-of-the-art methods on deblurring and inpainting tasks, 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35777;&#26126;&#20102;&#19968;&#31867;&#20998;&#24067;&#34429;&#28982;&#21487;&#20197;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#20197;&#24635;&#21464;&#24046;&#36317;&#31163;&#36827;&#34892;&#23398;&#20064;&#65292;&#20294;&#21364;&#26080;&#27861;&#22312;&#65288;&#949;&#65292;&#948;&#65289;-&#24046;&#20998;&#38544;&#31169;&#19979;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.00267</link><description>&lt;p&gt;
&#24182;&#38750;&#25152;&#26377;&#21487;&#23398;&#20064;&#30340;&#20998;&#24067;&#31867;&#37117;&#33021;&#22312;&#24046;&#20998;&#38544;&#31169;&#19979;&#36827;&#34892;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Not All Learnable Distribution Classes are Privately Learnable
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00267
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35777;&#26126;&#20102;&#19968;&#31867;&#20998;&#24067;&#34429;&#28982;&#21487;&#20197;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#20197;&#24635;&#21464;&#24046;&#36317;&#31163;&#36827;&#34892;&#23398;&#20064;&#65292;&#20294;&#21364;&#26080;&#27861;&#22312;&#65288;&#949;&#65292;&#948;&#65289;-&#24046;&#20998;&#38544;&#31169;&#19979;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#19968;&#31867;&#20998;&#24067;&#22312;&#26377;&#38480;&#26679;&#26412;&#19979;&#21487;&#20197;&#20197;&#24635;&#21464;&#24046;&#36317;&#31163;&#36827;&#34892;&#23398;&#20064;&#65292;&#20294;&#22312;&#65288;&#949;&#65292;&#948;&#65289;-&#24046;&#20998;&#38544;&#31169;&#19979;&#26080;&#27861;&#23398;&#20064;&#12290;&#36825;&#25512;&#32763;&#20102;Ashtiani&#30340;&#19968;&#20010;&#29468;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give an example of a class of distributions that is learnable in total variation distance with a finite number of samples, but not learnable under $(\varepsilon, \delta)$-differential privacy. This refutes a conjecture of Ashtiani.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#39033;&#24335;&#21442;&#25968;&#21270;sigmoid&#20989;&#25968;(SIGTRON)&#65292;&#24182;&#19988;&#20171;&#32461;&#20102;&#20854;&#20276;&#38543;&#30340;SIC&#27169;&#22411;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#32473;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#25509;&#36817;&#33391;&#22909;&#24179;&#34913;&#30340;&#26465;&#20214;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;SIC&#27169;&#22411;&#23545;&#20110;&#25968;&#25454;&#38598;&#30340;&#21464;&#21270;&#26356;&#21152;&#36866;&#24212;&#65292;&#24182;&#36890;&#36807;&#21019;&#24314;&#20542;&#26012;&#30340;&#36229;&#24179;&#38754;&#26041;&#31243;&#26469;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2312.16043</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#19981;&#24179;&#34913;&#32447;&#24615;&#20998;&#31867;&#30340;&#25193;&#23637;&#38750;&#23545;&#31216;sigmoid&#21644;&#24863;&#30693;&#26426;(SIGTRON)
&lt;/p&gt;
&lt;p&gt;
An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced linear classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#39033;&#24335;&#21442;&#25968;&#21270;sigmoid&#20989;&#25968;(SIGTRON)&#65292;&#24182;&#19988;&#20171;&#32461;&#20102;&#20854;&#20276;&#38543;&#30340;SIC&#27169;&#22411;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#32473;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#25509;&#36817;&#33391;&#22909;&#24179;&#34913;&#30340;&#26465;&#20214;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;SIC&#27169;&#22411;&#23545;&#20110;&#25968;&#25454;&#38598;&#30340;&#21464;&#21270;&#26356;&#21152;&#36866;&#24212;&#65292;&#24182;&#36890;&#36807;&#21019;&#24314;&#20542;&#26012;&#30340;&#36229;&#24179;&#38754;&#26041;&#31243;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#39033;&#24335;&#21442;&#25968;&#21270;sigmoid&#20989;&#25968;&#65292;&#31216;&#20026;SIGTRON&#65292;&#23427;&#26159;&#19968;&#31181;&#25193;&#23637;&#30340;&#38750;&#23545;&#31216;sigmoid&#20989;&#25968;&#21644;&#24863;&#30693;&#26426;&#30340;&#32467;&#21512;&#65292;&#20197;&#21450;&#23427;&#30340;&#20276;&#38543;&#20984;&#27169;&#22411;SIGTRON-&#19981;&#24179;&#34913;&#20998;&#31867;(SIC)&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#20102;&#34394;&#25311;SIGTRON&#20135;&#29983;&#30340;&#20984;&#25439;&#22833;&#20989;&#25968;&#12290;&#19982;&#20256;&#32479;&#30340;$\pi$-&#21152;&#26435;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;SIC&#27169;&#22411;&#22312;&#25439;&#22833;&#20989;&#25968;&#19978;&#27809;&#26377;&#22806;&#37096;&#30340;$\pi$-&#26435;&#37325;&#65292;&#32780;&#26159;&#22312;&#34394;&#25311;&#30340;SIGTRON&#20135;&#29983;&#30340;&#25439;&#22833;&#20989;&#25968;&#20013;&#26377;&#20869;&#37096;&#21442;&#25968;&#12290;&#22240;&#27492;&#65292;&#24403;&#32473;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#25509;&#36817;&#33391;&#22909;&#24179;&#34913;&#30340;&#26465;&#20214;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;SIC&#27169;&#22411;&#23545;&#25968;&#25454;&#38598;&#30340;&#21464;&#21270;&#26356;&#21152;&#36866;&#24212;&#65292;&#27604;&#22914;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20043;&#38388;&#27604;&#20363;&#19981;&#24179;&#34913;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;&#36825;&#31181;&#36866;&#24212;&#26159;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#20542;&#26012;&#30340;&#36229;&#24179;&#38754;&#26041;&#31243;&#26469;&#23454;&#29616;&#30340;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25311;&#29275;&#39039;&#20248;&#21270;(L-BFGS)&#26694;&#26550;&#30340;&#34394;&#25311;&#20984;&#25439;&#22833;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#22522;&#20110;&#21306;&#38388;&#30340;&#20108;&#20998;&#32447;&#24615;&#25628;&#32034;&#31639;&#27861;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article presents a new polynomial parameterized sigmoid called SIGTRON, which is an extended asymmetric sigmoid with Perceptron, and its companion convex model called SIGTRON-imbalanced classification (SIC) model that employs a virtual SIGTRON-induced convex loss function. In contrast to the conventional $\pi$-weighted cost-sensitive learning model, the SIC model does not have an external $\pi$-weight on the loss function but has internal parameters in the virtual SIGTRON-induced loss function. As a consequence, when the given training dataset is close to the well-balanced condition, we show that the proposed SIC model is more adaptive to variations of the dataset, such as the inconsistency of the scale-class-imbalance ratio between the training and test datasets. This adaptation is achieved by creating a skewed hyperplane equation. Additionally, we present a quasi-Newton optimization(L-BFGS) framework for the virtual convex loss by developing an interval-based bisection line sear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#19979;&#30340;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20173;&#28982;&#21463;&#30410;&#12290;</title><link>https://arxiv.org/abs/2311.17539</link><description>&lt;p&gt;
&#22312;&#36807;&#21442;&#25968;&#21270;&#19979;&#20998;&#26512;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Analyzing Sharpness-aware Minimization under Overparameterization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#19979;&#30340;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20173;&#28982;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#23613;&#31649;&#35757;&#32451;&#25439;&#22833;&#30456;&#21516;&#65292;&#20294;&#21487;&#20197;&#24471;&#21040;&#20855;&#26377;&#19981;&#21516;&#27867;&#21270;&#33021;&#21147;&#30340;&#26497;&#23567;&#20540;&#12290;&#26377;&#35777;&#25454;&#34920;&#26126;&#65292;&#26497;&#23567;&#20540;&#30340;&#38160;&#24230;&#19982;&#20854;&#27867;&#21270;&#35823;&#24046;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#22240;&#27492;&#24050;&#32463;&#20570;&#20986;&#20102;&#26356;&#22810;&#21162;&#21147;&#24320;&#21457;&#19968;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#20197;&#26174;&#24335;&#22320;&#25214;&#21040;&#25153;&#24179;&#26497;&#23567;&#20540;&#20316;&#20026;&#26356;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#30340;&#35299;&#12290;&#28982;&#32780;&#65292;&#33267;&#20170;&#20026;&#27490;&#65292;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#31574;&#30053;&#30340;&#24433;&#21709;&#30340;&#30740;&#31350;&#36824;&#19981;&#22810;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#19981;&#21516;&#31243;&#24230;&#30340;&#36807;&#21442;&#25968;&#21270;&#19979;&#30340;SAM&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#34920;&#26126;&#36807;&#21442;&#25968;&#21270;&#23545;SAM&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#28085;&#30422;&#20102;&#21508;&#20010;&#39046;&#22495;&#65292;&#24182;&#34920;&#26126;&#23384;&#22312;&#19968;&#31181;&#19968;&#33268;&#30340;&#36235;&#21183;&#65292;&#21363;SAM&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#21463;&#30410;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#19968;&#20123;&#20196;&#20154;&#20449;&#26381;&#30340;&#26696;&#20363;&#65292;&#35828;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training an overparameterized neural network can yield minimizers of different generalization capabilities despite the same level of training loss. With evidence that suggests a correlation between sharpness of minima and their generalization errors, increasing efforts have been made to develop an optimization method to explicitly find flat minima as more generalizable solutions. However, this sharpness-aware minimization (SAM) strategy has not been studied much yet as to whether and how it is affected by overparameterization.   In this work, we analyze SAM under overparameterization of varying degrees and present both empirical and theoretical results that indicate a critical influence of overparameterization on SAM. Specifically, we conduct extensive numerical experiments across various domains, and show that there exists a consistent trend that SAM continues to benefit from increasing overparameterization. We also discover compelling cases where the effect of overparameterization is
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#21487;&#31283;&#23450;&#35745;&#31639;&#65292;&#33021;&#22815;&#36827;&#34892;&#22810;&#23610;&#24230;&#27604;&#36739;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2311.16054</link><description>&lt;p&gt;
&#29992;&#20110;&#35780;&#20272;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#30340;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;
&lt;/p&gt;
&lt;p&gt;
Metric Space Magnitude for Evaluating the Diversity of Latent Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16054
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#21487;&#31283;&#23450;&#35745;&#31639;&#65292;&#33021;&#22815;&#36827;&#34892;&#22810;&#23610;&#24230;&#27604;&#36739;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24230;&#37327;&#31354;&#38388;&#30340;&#22823;&#23567;&#26159;&#19968;&#31181;&#36817;&#26399;&#24314;&#31435;&#30340;&#19981;&#21464;&#24615;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#25552;&#20379;&#31354;&#38388;&#30340;&#8220;&#26377;&#25928;&#22823;&#23567;&#8221;&#30340;&#34913;&#37327;&#65292;&#24182;&#25429;&#25417;&#21040;&#35768;&#22810;&#20960;&#20309;&#23646;&#24615;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#20869;&#22312;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#24418;&#24335;&#21270;&#20102;&#26377;&#38480;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#20989;&#25968;&#20043;&#38388;&#30340;&#26032;&#39062;&#19981;&#30456;&#20284;&#24615;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;&#25968;&#25454;&#25200;&#21160;&#19979;&#20445;&#35777;&#31283;&#23450;&#65292;&#21487;&#20197;&#39640;&#25928;&#35745;&#31639;&#65292;&#24182;&#19988;&#33021;&#22815;&#23545;&#28508;&#22312;&#34920;&#31034;&#36827;&#34892;&#20005;&#26684;&#30340;&#22810;&#23610;&#24230;&#27604;&#36739;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;&#23454;&#39564;&#22871;&#20214;&#20013;&#30340;&#23454;&#29992;&#24615;&#21644;&#21331;&#36234;&#24615;&#33021;&#65292;&#21253;&#25324;&#19981;&#21516;&#39046;&#22495;&#21644;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#12289;&#27169;&#24335;&#23849;&#28291;&#26816;&#27979;&#20197;&#21450;&#29992;&#20110;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The magnitude of a metric space is a recently-established invariant, providing a measure of the 'effective size' of a space across multiple scales while also capturing numerous geometrical properties. We develop a family of magnitude-based measures of the intrinsic diversity of latent representations, formalising a novel notion of dissimilarity between magnitude functions of finite metric spaces. Our measures are provably stable under perturbations of the data, can be efficiently calculated, and enable a rigorous multi-scale comparison of latent representations. We show the utility and superior performance of our measures in an experimental suite that comprises different domains and tasks, including the evaluation of diversity, the detection of mode collapse, and the evaluation of generative models for text, image, and graph data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36229;&#38271;&#19978;&#19979;&#25991;&#19979;&#20869;&#23384;&#25928;&#29575;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#36229;&#38271;Token&#27880;&#24847;&#21147;&#36817;&#20284;&#30340;&#21333;&#27425;&#27969;&#31639;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#30697;&#38453;$U_1, U_2$&#21152;&#36895;&#27880;&#24847;&#21147;&#35745;&#31639;&#65292;&#35299;&#20915;&#20102;&#37096;&#32626;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#30340;&#35745;&#31639;&#36164;&#28304;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.14652</link><description>&lt;p&gt;
&#19968;&#31181;&#36229;&#38271;Token&#27880;&#24847;&#21147;&#36817;&#20284;&#30340;&#21333;&#27425;&#27969;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
One Pass Streaming Algorithm for Super Long Token Attention Approximation in Sublinear Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.14652
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36229;&#38271;&#19978;&#19979;&#25991;&#19979;&#20869;&#23384;&#25928;&#29575;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#36229;&#38271;Token&#27880;&#24847;&#21147;&#36817;&#20284;&#30340;&#21333;&#27425;&#27969;&#31639;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#30697;&#38453;$U_1, U_2$&#21152;&#36895;&#27880;&#24847;&#21147;&#35745;&#31639;&#65292;&#35299;&#20915;&#20102;&#37096;&#32626;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#30340;&#35745;&#31639;&#36164;&#28304;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#35745;&#31639;&#21516;&#26102;&#20855;&#26377;$O(n^2)$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#21644;$O(n^2)$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#65292;&#36825;&#20351;&#24471;&#22312;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#30340;&#27969;&#24212;&#29992;&#20013;&#37096;&#32626;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(Large Language Models&#65292;LLMs)&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#26368;&#36817;&#30340;OpenAI DevDay&#65288;2023&#24180;11&#26376;6&#26085;&#65289;&#65292;OpenAI&#21457;&#24067;&#20102;&#19968;&#31181;&#33021;&#22815;&#25903;&#25345;128K&#38271;&#25991;&#26723;&#30340;&#26032;&#27169;&#22411;&#65292;&#22312;&#25105;&#20204;&#30340;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#24403;&#19978;&#19979;&#25991;&#38271;&#24230;$n$&#36828;&#22823;&#20110;128K ($n \gg 2^d$)&#26102;&#30340;&#20869;&#23384;&#26377;&#25928;&#38382;&#39064;&#12290;&#32771;&#34385;&#21040;&#20855;&#26377; Query&#12289;Key &#21644; Value &#30697;&#38453;$Q, K, V \in \mathbb{R}^{n \times d}$&#30340;&#21333;&#23618;&#33258;&#27880;&#24847;&#21147;&#65292;&#22810;&#39033;&#24335;&#26041;&#27861;&#36817;&#20284;&#20102;&#27880;&#24847;&#21147;&#36755;&#20986;$T \in \mathbb{R}^{n \times d}$&#12290;&#23427;&#36890;&#36807;&#26500;&#24314;$U_1, U_2 \in \mathbb{R}^{n \times t}$&#22312;$n^{1+o(1)}$&#27425;&#26102;&#38388;&#25191;&#34892;&#20869;&#21152;&#36895;&#27880;&#24847;&#21147;&#35745;&#31639;${\sf Attn}(Q, K, V)$&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#35745;&#31639;&#36817;&#20284;&#30340;&#27880;&#24847;&#21147;&#30697;&#38453;$U_1U_2^\top \in \mathbb{R}^{n \times n}$&#20173;&#38656;&#35201;$O(n^2)$&#30340;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention computation takes both the time complexity of $O(n^2)$ and the space complexity of $O(n^2)$ simultaneously, which makes deploying Large Language Models (LLMs) in streaming applications that involve long contexts requiring substantial computational resources. In recent OpenAI DevDay (Nov 6, 2023), OpenAI released a new model that is able to support a 128K-long document, in our paper, we focus on the memory-efficient issue when context length $n$ is much greater than 128K ($n \gg 2^d$). Considering a single-layer self-attention with Query, Key, and Value matrices $Q, K, V \in \mathbb{R}^{n \times d}$, the polynomial method approximates the attention output $T \in \mathbb{R}^{n \times d}$. It accomplishes this by constructing $U_1, U_2 \in \mathbb{R}^{n \times t}$ to expedite attention ${\sf Attn}(Q, K, V)$ computation within $n^{1+o(1)}$ time executions. Despite this, computing the approximated attention matrix $U_1U_2^\top \in \mathbb{R}^{n \times n}$ still necessitates $O(n^2
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#21487;&#20197;&#26377;&#25928;&#19988;&#26377;&#21147;&#22320;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>https://arxiv.org/abs/2311.14220</link><description>&lt;p&gt;
&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Assumption-lean and Data-adaptive Post-Prediction Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.14220
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#21487;&#20197;&#26377;&#25928;&#19988;&#26377;&#21147;&#22320;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31185;&#23398;&#30740;&#31350;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#40644;&#37329;&#26631;&#20934;&#25968;&#25454;&#30340;&#26377;&#38480;&#21487;&#29992;&#24615;&#65292;&#32780;&#33719;&#21462;&#36825;&#20123;&#25968;&#25454;&#26082;&#32791;&#36153;&#26102;&#38388;&#21448;&#36153;&#21147;&#12290;&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#31185;&#23398;&#23478;&#20204;&#20381;&#36182;&#20110;ML&#31639;&#27861;&#20351;&#29992;&#26131;&#24471;&#30340;&#21327;&#21464;&#37327;&#26469;&#39044;&#27979;&#36825;&#20123;&#40644;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#39044;&#27979;&#32467;&#26524;&#24120;&#24120;&#30452;&#25509;&#29992;&#20110;&#21518;&#32493;&#30340;&#32479;&#35745;&#20998;&#26512;&#20013;&#65292;&#24573;&#30053;&#20102;&#39044;&#27979;&#36807;&#31243;&#24341;&#20837;&#30340;&#19981;&#31934;&#30830;&#24615;&#21644;&#24322;&#36136;&#24615;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#34394;&#20551;&#30340;&#27491;&#38754;&#32467;&#26524;&#21644;&#26080;&#25928;&#30340;&#31185;&#23398;&#32467;&#35770;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#23427;&#20801;&#35768;&#22522;&#20110;ML&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#21644;&#26377;&#21147;&#30340;&#25512;&#26029;&#12290;&#23427;&#30340;&#8220;&#20551;&#35774;&#31616;&#21270;&#8221;&#23646;&#24615;&#20445;&#35777;&#22312;&#24191;&#27867;&#30340;&#32479;&#35745;&#37327;&#19978;&#19981;&#22522;&#20110;ML&#39044;&#27979;&#20570;&#20986;&#21487;&#38752;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#23427;&#30340;&#8220;&#25968;&#25454;&#33258;&#36866;&#24212;&#8221;&#29305;&#24615;&#20445;&#35777;&#20102;&#30456;&#36739;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#25928;&#29575;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
A primary challenge facing modern scientific research is the limited availability of gold-standard data which can be both costly and labor-intensive to obtain. With the rapid development of machine learning (ML), scientists have relied on ML algorithms to predict these gold-standard outcomes with easily obtained covariates. However, these predicted outcomes are often used directly in subsequent statistical analyses, ignoring imprecision and heterogeneity introduced by the prediction procedure. This will likely result in false positive findings and invalid scientific conclusions. In this work, we introduce an assumption-lean and data-adaptive Post-Prediction Inference (POP-Inf) procedure that allows valid and powerful inference based on ML-predicted outcomes. Its "assumption-lean" property guarantees reliable statistical inference without assumptions on the ML-prediction, for a wide range of statistical quantities. Its "data-adaptive'" feature guarantees an efficiency gain over existing
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#19968;&#33324;&#29615;&#22659;&#20013;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#30340;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#22522;&#20110;&#36825;&#31181;&#29615;&#22659;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#21487;&#36776;&#35782;&#24615;&#32467;&#26524;&#65292;&#24182;&#25351;&#20986;&#20102;&#21463;&#21040;&#22260;&#32469;&#33410;&#28857;&#27495;&#20041;&#30340;&#38480;&#21046;&#12290;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#22320;&#38754;&#30495;&#23454;&#27169;&#22411;</title><link>https://arxiv.org/abs/2311.12267</link><description>&lt;p&gt;
&#20174;&#19968;&#33324;&#29615;&#22659;&#20013;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#65306;&#21487;&#36776;&#35782;&#24615;&#21644;&#20869;&#22312;&#27495;&#20041;
&lt;/p&gt;
&lt;p&gt;
Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12267
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#19968;&#33324;&#29615;&#22659;&#20013;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#30340;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#22522;&#20110;&#36825;&#31181;&#29615;&#22659;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#21487;&#36776;&#35782;&#24615;&#32467;&#26524;&#65292;&#24182;&#25351;&#20986;&#20102;&#21463;&#21040;&#22260;&#32469;&#33410;&#28857;&#27495;&#20041;&#30340;&#38480;&#21046;&#12290;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#22320;&#38754;&#30495;&#23454;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#21363;&#20174;&#20302;&#32423;&#35266;&#27979;&#25968;&#25454;&#65288;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#65289;&#20013;&#24674;&#22797;&#39640;&#32423;&#28508;&#22312;&#21464;&#37327;&#21450;&#20854;&#22240;&#26524;&#20851;&#31995;&#30340;&#20219;&#21153;&#65292;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#20174;&#22810;&#20010;&#29615;&#22659;&#29983;&#25104;&#30340;&#35266;&#23519;&#32467;&#26524;&#12290;&#20043;&#21069;&#20851;&#20110;&#22240;&#26524;&#34920;&#31034;&#21487;&#36776;&#35782;&#24615;&#30340;&#32467;&#26524;&#36890;&#24120;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#21333;&#33410;&#28857;&#24178;&#39044;&#65292;&#20294;&#23454;&#38469;&#19978;&#36825;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#65292;&#22240;&#20026;&#28508;&#22312;&#21464;&#37327;&#26412;&#36523;&#23601;&#26410;&#30693;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22522;&#20110;&#26469;&#33258;&#19968;&#33324;&#29615;&#22659;&#30340;&#25968;&#25454;&#30340;&#31532;&#19968;&#20010;&#21487;&#36776;&#35782;&#24615;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#32447;&#24615;&#22240;&#26524;&#27169;&#22411;&#65292;&#34429;&#28982;&#21487;&#20197;&#23436;&#20840;&#24674;&#22797;&#22240;&#26524;&#22270;&#65292;&#20294;&#28508;&#22312;&#21464;&#37327;&#21482;&#33021;&#34987;&#35782;&#21035;&#21040;&#21463;&#21040;&#22260;&#32469;&#33410;&#28857;&#27495;&#20041;&#65288;SNA&#65289;&#30340;&#31243;&#24230;&#19978;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#20445;&#35777;&#30340;&#23545;&#24212;&#23545;&#65292;&#35777;&#26126;&#20102;&#22312;&#25105;&#20204;&#30340;&#35774;&#32622;&#20013;SNA&#22522;&#26412;&#19978;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;LiNGCReL&#65292;&#21487;&#20197;&#34987;&#35777;&#26126;&#21487;&#20197;&#24674;&#22797;&#20986;&#22320;&#38754;&#30495;&#23454;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
We study causal representation learning, the task of recovering high-level latent variables and their causal relationships in the form of a causal graph from low-level observed data (such as text and images), assuming access to observations generated from multiple environments. Prior results on the identifiability of causal representations typically assume access to single-node interventions which is rather unrealistic in practice, since the latent variables are unknown in the first place. In this work, we provide the first identifiability results based on data that stem from general environments. We show that for linear causal models, while the causal graph can be fully recovered, the latent variables are only identified up to the surrounded-node ambiguity (SNA) \citep{varici2023score}. We provide a counterpart of our guarantee, showing that SNA is basically unavoidable in our setting. We also propose an algorithm, \texttt{LiNGCReL} which provably recovers the ground-truth model up to
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24778;&#21916;&#24615;&#39537;&#21160;&#30340;&#31283;&#20581;&#21487;&#35299;&#37322;&#30340;k-NN&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#23545;&#20256;&#32479;&#31639;&#27861;&#36827;&#34892;&#26032;&#30340;&#38416;&#37322;&#65292;&#23454;&#29616;&#20102;&#22312;&#38750;&#21442;&#25968;&#23398;&#20064;&#20013;&#30340;&#20998;&#31867;&#12289;&#22238;&#24402;&#12289;&#23494;&#24230;&#20272;&#35745;&#21644;&#24322;&#24120;&#26816;&#27979;&#31561;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2311.10246</link><description>&lt;p&gt;
&#22522;&#20110;&#24778;&#21916;&#24615;&#39537;&#21160;&#30340;&#31283;&#20581;&#21487;&#35299;&#37322;&#30340;&#38750;&#21442;&#25968;&#23398;&#20064;&#20013;&#30340;k-NN&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Surprisal Driven $k$-NN for Robust and Interpretable Nonparametric Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.10246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24778;&#21916;&#24615;&#39537;&#21160;&#30340;&#31283;&#20581;&#21487;&#35299;&#37322;&#30340;k-NN&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#23545;&#20256;&#32479;&#31639;&#27861;&#36827;&#34892;&#26032;&#30340;&#38416;&#37322;&#65292;&#23454;&#29616;&#20102;&#22312;&#38750;&#21442;&#25968;&#23398;&#20064;&#20013;&#30340;&#20998;&#31867;&#12289;&#22238;&#24402;&#12289;&#23494;&#24230;&#20272;&#35745;&#21644;&#24322;&#24120;&#26816;&#27979;&#31561;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#23398;&#20064;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#27010;&#24565;&#65292;&#26088;&#22312;&#25429;&#25417;&#25968;&#25454;&#20013;&#30340;&#22797;&#26434;&#27169;&#24335;&#21644;&#20851;&#31995;&#65292;&#32780;&#19981;&#23545;&#28508;&#22312;&#30340;&#25968;&#25454;&#20998;&#24067;&#20570;&#20986;&#24378;&#28872;&#30340;&#20551;&#35774;&#12290;&#22312;&#36825;&#19968;&#33539;&#24335;&#19979;&#65292;&#26368;&#20026;&#33879;&#21517;&#30340;&#31639;&#27861;&#20043;&#19968;&#26159;k&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#31639;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#30340;&#24212;&#29992;&#65292;&#20174;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#23545;&#20256;&#32479;&#30340;&#26368;&#36817;&#37051;&#31639;&#27861;&#36827;&#34892;&#20102;&#26032;&#30340;&#38416;&#37322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#20581;&#21487;&#35299;&#37322;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31867;&#12289;&#22238;&#24402;&#12289;&#23494;&#24230;&#20272;&#35745;&#21644;&#24322;&#24120;&#26816;&#27979;&#31561;&#20219;&#21153;&#12290;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#35745;&#31639;&#22686;&#21152;&#29305;&#24449;&#26102;&#30340;&#26465;&#20214;&#29109;&#26469;&#30830;&#23450;&#25968;&#25454;&#28857;&#30340;&#26435;&#37325;&#21644;&#29305;&#24449;&#30340;&#36129;&#29486;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#26174;&#24335;&#30340;&#27169;&#22411;&#35757;&#32451;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#25552;&#20379;&#35814;&#32454;&#30340;&#25968;&#25454;&#28857;&#24433;&#21709;&#26435;&#37325;&#26469;&#35745;&#31639;&#29305;&#24449;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonparametric learning is a fundamental concept in machine learning that aims to capture complex patterns and relationships in data without making strong assumptions about the underlying data distribution. Owing to simplicity and familiarity, one of the most well-known algorithms under this paradigm is the $k$-nearest neighbors ($k$-NN) algorithm. Driven by the usage of machine learning in safety-critical applications, in this work, we shed new light on the traditional nearest neighbors algorithm from the perspective of information theory and propose a robust and interpretable framework for tasks such as classification, regression, density estimation, and anomaly detection using a single model. We can determine data point weights as well as feature contributions by calculating the conditional entropy for adding a feature without the need for explicit model training. This allows us to compute feature contributions by providing detailed data point influence weights with perfect attributi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#20998;&#24067;&#24335;&#37327;&#21270;&#27969;&#30340;GFlowNets&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#27969;&#20989;&#25968;&#36716;&#21270;&#20026;&#20998;&#24067;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#26356;&#22810;&#20449;&#24687;&#30340;&#23398;&#20064;&#20449;&#21495;&#12290;&#36890;&#36807;&#37327;&#21270;&#20989;&#25968;&#21442;&#25968;&#21270;&#27599;&#20010;&#36793;&#27969;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#23398;&#20064;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#65292;&#23454;&#29616;&#23545;&#39118;&#38505;&#19981;&#30830;&#23450;&#24615;&#22330;&#26223;&#30340;&#22788;&#29702;&#65292;&#24182;&#22312;&#29616;&#26377;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2302.05793</link><description>&lt;p&gt;
&#24102;&#26377;&#20998;&#24067;&#24335;&#37327;&#21270;&#27969;&#30340;GFlowNets
&lt;/p&gt;
&lt;p&gt;
Distributional GFlowNets with Quantile Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.05793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#20998;&#24067;&#24335;&#37327;&#21270;&#27969;&#30340;GFlowNets&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#27969;&#20989;&#25968;&#36716;&#21270;&#20026;&#20998;&#24067;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#26356;&#22810;&#20449;&#24687;&#30340;&#23398;&#20064;&#20449;&#21495;&#12290;&#36890;&#36807;&#37327;&#21270;&#20989;&#25968;&#21442;&#25968;&#21270;&#27599;&#20010;&#36793;&#27969;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#23398;&#20064;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#65292;&#23454;&#29616;&#23545;&#39118;&#38505;&#19981;&#30830;&#23450;&#24615;&#22330;&#26223;&#30340;&#22788;&#29702;&#65292;&#24182;&#22312;&#29616;&#26377;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#37319;&#26679;&#22120;&#31995;&#21015;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#19968;&#31995;&#21015;&#20915;&#31574;&#27493;&#39588;&#23398;&#20064;&#29983;&#25104;&#22797;&#26434;&#32452;&#21512;&#32467;&#26500;&#30340;&#38543;&#26426;&#31574;&#30053;&#12290;&#23613;&#31649;&#21463;&#24378;&#21270;&#23398;&#20064;&#21551;&#21457;&#65292;&#24403;&#21069;&#30340;GFlowNet&#26694;&#26550;&#22312;&#36866;&#29992;&#24615;&#19978;&#30456;&#23545;&#26377;&#38480;&#65292;&#26080;&#27861;&#22788;&#29702;&#22870;&#21169;&#20989;&#25968;&#20013;&#30340;&#38543;&#26426;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20998;&#24067;&#24335;&#33539;&#24335;&#26469;&#22788;&#29702;GFlowNets&#65292;&#23558;&#27599;&#20010;&#27969;&#20989;&#25968;&#36716;&#21270;&#20026;&#19968;&#20010;&#20998;&#24067;&#65292;&#20174;&#32780;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#26356;&#22810;&#20449;&#24687;&#30340;&#23398;&#20064;&#20449;&#21495;&#12290;&#36890;&#36807;&#36890;&#36807;&#37327;&#21270;&#20989;&#25968;&#23545;&#27599;&#20010;&#36793;&#27969;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#8220;&#37327;&#21270;&#21305;&#37197;&#8221; GFlowNet&#23398;&#20064;&#31639;&#27861;&#33021;&#22815;&#23398;&#20064;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#65292;&#36825;&#26159;&#22788;&#29702;&#39118;&#38505;&#19981;&#30830;&#23450;&#24615;&#22330;&#26223;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#20998;&#24067;&#24335;&#26041;&#27861;&#30001;&#20110;&#25105;&#20204;&#22686;&#24378;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#29616;&#26377;&#22522;&#20934;&#19978;&#23454;&#29616;&#26174;&#30528;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets) are a new family of probabilistic samplers where an agent learns a stochastic policy for generating complex combinatorial structure through a series of decision-making steps. Despite being inspired from reinforcement learning, the current GFlowNet framework is relatively limited in its applicability and cannot handle stochasticity in the reward function. In this work, we adopt a distributional paradigm for GFlowNets, turning each flow function into a distribution, thus providing more informative learning signals during training. By parameterizing each edge flow through their quantile functions, our proposed \textit{quantile matching} GFlowNet learning algorithm is able to learn a risk-sensitive policy, an essential component for handling scenarios with risk uncertainty. Moreover, we find that the distributional approach can achieve substantial improvement on existing benchmarks compared to prior methods due to our enhanced training algorithm, even i
&lt;/p&gt;</description></item><item><title>&#21487;&#23454;&#29616;&#23398;&#20064;&#19982;&#26080;&#20559;&#23398;&#20064;&#30340;&#31561;&#20215;&#24615;&#26159;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#22522;&#26412;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#29420;&#31435;&#20110;&#27169;&#22411;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#36825;&#20010;&#31561;&#20215;&#24615;&#65292;&#23427;&#21487;&#20197;&#36866;&#29992;&#20110;&#21508;&#31181;&#35774;&#32622;&#65292;&#24182;&#25299;&#23637;&#20102;&#25105;&#20204;&#23545;&#21508;&#31181;&#23398;&#20064;&#24773;&#20917;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2111.04746</link><description>&lt;p&gt;
&#21487;&#23454;&#29616;&#23398;&#20064;&#23601;&#26159;&#20320;&#25152;&#38656;&#35201;&#30340;&#19968;&#20999;
&lt;/p&gt;
&lt;p&gt;
Realizable Learning is All You Need
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2111.04746
&lt;/p&gt;
&lt;p&gt;
&#21487;&#23454;&#29616;&#23398;&#20064;&#19982;&#26080;&#20559;&#23398;&#20064;&#30340;&#31561;&#20215;&#24615;&#26159;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#22522;&#26412;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#29420;&#31435;&#20110;&#27169;&#22411;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#36825;&#20010;&#31561;&#20215;&#24615;&#65292;&#23427;&#21487;&#20197;&#36866;&#29992;&#20110;&#21508;&#31181;&#35774;&#32622;&#65292;&#24182;&#25299;&#23637;&#20102;&#25105;&#20204;&#23545;&#21508;&#31181;&#23398;&#20064;&#24773;&#20917;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#23454;&#29616;&#23398;&#20064;&#19982;&#26080;&#20559;&#23398;&#20064;&#30340;&#31561;&#20215;&#24615;&#26159;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#22522;&#26412;&#29616;&#35937;&#12290;&#20174;&#32463;&#20856;&#30340;PAC&#23398;&#20064;&#21644;&#22238;&#24402;&#21040;&#26368;&#36817;&#30340;&#36235;&#21183;&#22914;&#23545;&#25239;&#40065;&#26834;&#23398;&#20064;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#25105;&#20204;&#20173;&#28982;&#32570;&#20047;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#65307;&#20256;&#32479;&#30340;&#31561;&#20215;&#24615;&#35777;&#26126;&#24448;&#24448;&#26159;&#38646;&#25955;&#30340;&#65292;&#24182;&#19988;&#20381;&#36182;&#20110;&#24378;&#30340;&#27169;&#22411;&#29305;&#23450;&#20551;&#35774;&#65292;&#22914;&#22343;&#21248;&#25910;&#25947;&#21644;&#26679;&#26412;&#21387;&#32553;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#29420;&#31435;&#20110;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#35299;&#37322;&#20102;&#21487;&#23454;&#29616;&#23398;&#20064;&#19982;&#26080;&#20559;&#23398;&#20064;&#30340;&#31561;&#20215;&#24615;&#65306;&#19968;&#20010;&#19977;&#34892;&#20195;&#30721;&#30340;&#40657;&#30418;&#31616;&#21270;&#65292;&#32479;&#19968;&#21644;&#25299;&#23637;&#20102;&#25105;&#20204;&#23545;&#21508;&#31181;&#35774;&#32622;&#30340;&#29702;&#35299;&#12290;&#36825;&#21253;&#25324;&#20102;&#27809;&#26377;&#24050;&#30693;&#21487;&#23398;&#20064;&#24615;&#25551;&#36848;&#30340;&#27169;&#22411;&#65292;&#22914;&#20855;&#26377;&#20219;&#24847;&#20998;&#24067;&#20551;&#35774;&#21644;&#26356;&#19968;&#33324;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#23398;&#20064;&#65292;&#20197;&#21450;&#19968;&#31995;&#21015;&#20854;&#20182;&#27969;&#34892;&#30340;&#35774;&#32622;&#65292;&#22914;&#40065;&#26834;&#23398;&#20064;&#12289;&#37096;&#20998;&#23398;&#20064;&#12289;&#20844;&#24179;&#23398;&#20064;&#21644;&#32479;&#35745;&#26597;&#35810;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The equivalence of realizable and agnostic learnability is a fundamental phenomenon in learning theory. With variants ranging from classical settings like PAC learning and regression to recent trends such as adversarially robust learning, it's surprising that we still lack a unified theory; traditional proofs of the equivalence tend to be disparate, and rely on strong model-specific assumptions like uniform convergence and sample compression.   In this work, we give the first model-independent framework explaining the equivalence of realizable and agnostic learnability: a three-line blackbox reduction that simplifies, unifies, and extends our understanding across a wide variety of settings. This includes models with no known characterization of learnability such as learning with arbitrary distributional assumptions and more general loss functions, as well as a host of other popular settings such as robust learning, partial learning, fair learning, and the statistical query model.   Mor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21518;&#27491;&#21017;&#21270;&#32622;&#20449;&#24102;&#26469;&#25512;&#26029;&#26410;&#30693;&#20989;&#25968;&#21644;&#26377;&#22122;&#22768;&#25968;&#25454;&#35266;&#27979;&#19979;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#30340;&#20010;&#20307;&#35843;&#25511;&#20989;&#25968;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#23616;&#37096;&#26680;&#23398;&#20064;&#21644;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#24314;&#31435;&#32622;&#20449;&#24102;&#30340;&#25361;&#25112;&#24615;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2110.12510</link><description>&lt;p&gt;
&#21518;&#27491;&#21017;&#21270;&#32622;&#20449;&#24102;&#22312;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Post-Regularization Confidence Bands for Ordinary Differential Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2110.12510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21518;&#27491;&#21017;&#21270;&#32622;&#20449;&#24102;&#26469;&#25512;&#26029;&#26410;&#30693;&#20989;&#25968;&#21644;&#26377;&#22122;&#22768;&#25968;&#25454;&#35266;&#27979;&#19979;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#30340;&#20010;&#20307;&#35843;&#25511;&#20989;&#25968;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#23616;&#37096;&#26680;&#23398;&#20064;&#21644;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#24314;&#31435;&#32622;&#20449;&#24102;&#30340;&#25361;&#25112;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#26159;&#30740;&#31350;&#29983;&#29289;&#21644;&#29289;&#29702;&#36807;&#31243;&#31995;&#32479;&#21160;&#24577;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;ODE&#24314;&#27169;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#25512;&#26029;&#19968;&#20010;&#20449;&#21495;&#21464;&#37327;&#23545;&#21478;&#19968;&#20010;&#20449;&#21495;&#21464;&#37327;&#30340;&#20010;&#20307;&#35843;&#25511;&#20316;&#29992;&#30340;&#26174;&#33879;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20855;&#26377;&#26410;&#30693;&#35843;&#25511;&#20851;&#31995;&#30340;ODE&#24314;&#31435;&#32622;&#20449;&#24102;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#24182;&#19988;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#38024;&#23545;&#20855;&#26377;&#26410;&#30693;&#20989;&#25968;&#21644;&#26377;&#22122;&#22768;&#25968;&#25454;&#35266;&#27979;&#30340;ODE&#20013;&#20010;&#20307;&#35843;&#25511;&#20989;&#25968;&#30340;&#21518;&#27491;&#21017;&#21270;&#32622;&#20449;&#24102;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26159;&#31532;&#19968;&#31181;&#36825;&#26679;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#24314;&#31435;&#22312;&#20004;&#20010;&#26032;&#39062;&#30340;&#35201;&#32032;&#19978;&#12290;&#31532;&#19968;&#20010;&#35201;&#32032;&#26159;&#23558;&#20877;&#29983;&#26680;&#23398;&#20064;&#19982;&#23616;&#37096;&#27888;&#21202;&#23637;&#24320;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#23616;&#37096;&#21270;&#26680;&#23398;&#20064;&#26041;&#27861;&#65292;&#31532;&#20108;&#20010;&#35201;&#32032;&#26159;&#35299;&#20915;&#26080;&#31351;&#32500;&#24230;&#20989;&#25968;&#21644;&#38468;&#21152;&#30340;&#27979;&#37327;&#35823;&#24046;&#30340;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#26500;&#24314;&#30340;&#32622;&#20449;&#24102;&#20855;&#26377;&#26399;&#26395;&#30340;&#28176;&#36817;&#35206;&#30422;&#27010;&#29575;&#65292;&#24182;&#19988;&#33021;&#22815;&#24674;&#22797;&#35843;&#25511;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ordinary differential equation (ODE) is an important tool to study the dynamics of a system of biological and physical processes. A central question in ODE modeling is to infer the significance of individual regulatory effect of one signal variable on another. However, building confidence band for ODE with unknown regulatory relations is challenging, and it remains largely an open question. In this article, we construct post-regularization confidence band for individual regulatory function in ODE with unknown functionals and noisy data observations. Our proposal is the first of its kind, and is built on two novel ingredients. The first is a new localized kernel learning approach that combines reproducing kernel learning with local Taylor approximation, and the second is a new de-biasing method that tackles infinite-dimensional functionals and additional measurement errors. We show that the constructed confidence band has the desired asymptotic coverage probability, and the recovered re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36830;&#32493;&#27835;&#30103;&#29615;&#22659;&#30340;&#22810;&#37325;&#31283;&#20581;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20272;&#35745;&#22120;&#65292;&#37319;&#29992;&#20102;&#26680;&#24179;&#28369;&#26041;&#27861;&#65292;&#24182;&#20855;&#26377;&#22810;&#37325;&#31283;&#20581;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>https://arxiv.org/abs/2105.09254</link><description>&lt;p&gt;
&#22312;&#36830;&#32493;&#27835;&#30103;&#19979;&#30340;&#22810;&#37325;&#31283;&#20581;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Multiply Robust Causal Mediation Analysis with Continuous Treatments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2105.09254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36830;&#32493;&#27835;&#30103;&#29615;&#22659;&#30340;&#22810;&#37325;&#31283;&#20581;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20272;&#35745;&#22120;&#65292;&#37319;&#29992;&#20102;&#26680;&#24179;&#28369;&#26041;&#27861;&#65292;&#24182;&#20855;&#26377;&#22810;&#37325;&#31283;&#20581;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#23545;&#27835;&#30103;&#25110;&#26292;&#38706;&#23545;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#30340;&#30452;&#25509;&#21644;&#38388;&#25509;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20013;&#20171;&#20998;&#26512;&#20026;&#37492;&#23450;&#21644;&#20272;&#35745;&#36825;&#20123;&#22240;&#26524;&#25928;&#24212;&#25552;&#20379;&#20102;&#19968;&#20010;&#20005;&#35880;&#30340;&#26694;&#26550;&#12290;&#23545;&#20110;&#20108;&#20803;&#27835;&#30103;&#65292;Tchetgen Tchetgen&#21644;Shpitser (2012)&#25552;&#20986;&#20102;&#30452;&#25509;&#21644;&#38388;&#25509;&#25928;&#24212;&#30340;&#39640;&#25928;&#20272;&#35745;&#22120;&#65292;&#22522;&#20110;&#21442;&#25968;&#30340;&#24433;&#21709;&#20989;&#25968;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#36136;&#65292;&#22914;&#22810;&#37325;&#31283;&#20581;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#21516;&#26102;&#20801;&#35768;&#23545;&#24178;&#25200;&#21442;&#25968;&#36827;&#34892;&#20302;&#20110;&#26681;&#21495;n&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#28982;&#32780;&#65292;&#22312;&#28041;&#21450;&#36830;&#32493;&#27835;&#30103;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#30340;&#20272;&#35745;&#22120;&#27809;&#26377;&#20934;&#22791;&#22909;&#24212;&#29992;&#65292;&#38500;&#38750;&#36827;&#34892;&#24378;&#21442;&#25968;&#20551;&#35774;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#26680;&#24179;&#28369;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36830;&#32493;&#27835;&#30103;&#29615;&#22659;&#30340;&#20272;&#35745;&#22120;&#65292;&#21463;&#21040;Tchetgen Tchetgen&#30340;&#24433;&#21709;&#20989;&#25968;&#20272;&#35745;&#22120;&#30340;&#21551;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many applications, researchers are interested in the direct and indirect causal effects of a treatment or exposure on an outcome of interest. Mediation analysis offers a rigorous framework for identifying and estimating these causal effects. For binary treatments, efficient estimators for the direct and indirect effects are presented in Tchetgen Tchetgen and Shpitser (2012) based on the influence function of the parameter of interest. These estimators possess desirable properties, such as multiple-robustness and asymptotic normality, while allowing for slower than root-n rates of convergence for the nuisance parameters. However, in settings involving continuous treatments, these influence function-based estimators are not readily applicable without making strong parametric assumptions. In this work, utilizing a kernel-smoothing approach, we propose an estimator suitable for settings with continuous treatments inspired by the influence function-based estimator of Tchetgen Tchetgen an
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#26088;&#22312;&#21521;&#35835;&#32773;&#25552;&#20379;&#23545;&#32447;&#24615;&#27169;&#22411;&#21450;&#20854;&#29702;&#35770;&#30340;&#20005;&#26684;&#20171;&#32461;&#65292;&#24182;&#24635;&#32467;&#20102;&#32447;&#24615;&#27169;&#22411;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#37325;&#35201;&#24615;&#21644;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2105.04240</link><description>&lt;p&gt;
&#19968;&#20010;&#23545;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#20005;&#26684;&#20171;&#32461;&#30340;&#20070;&#31821;
&lt;/p&gt;
&lt;p&gt;
A rigorous introduction to linear models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2105.04240
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#26088;&#22312;&#21521;&#35835;&#32773;&#25552;&#20379;&#23545;&#32447;&#24615;&#27169;&#22411;&#21450;&#20854;&#29702;&#35770;&#30340;&#20005;&#26684;&#20171;&#32461;&#65292;&#24182;&#24635;&#32467;&#20102;&#32447;&#24615;&#27169;&#22411;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#37325;&#35201;&#24615;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#26088;&#22312;&#21521;&#35835;&#32773;&#20171;&#32461;&#32447;&#24615;&#27169;&#22411;&#21450;&#20854;&#32972;&#21518;&#30340;&#29702;&#35770;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20026;&#35835;&#32773;&#25552;&#20379;&#19968;&#20010;&#20005;&#35880;&#30340;&#20171;&#32461;&#65292;&#21069;&#25552;&#26159;&#35835;&#32773;&#20855;&#26377;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#27861;&#30340;&#20808;&#21069;&#32463;&#39564;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#36755;&#20986;&#36890;&#24120;&#26159;&#36755;&#20837;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;&#28145;&#24230;&#23398;&#20064;&#29978;&#33267;&#26088;&#22312;&#25214;&#21040;&#20855;&#26377;&#35768;&#22810;&#23618;&#30340;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#65292;&#36825;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#31639;&#27861;&#37117;&#26159;&#22522;&#20110;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#26500;&#24314;&#30340;&#12290;&#25105;&#20204;&#20174;&#19981;&#21516;&#30340;&#35282;&#24230;&#25551;&#36848;&#32447;&#24615;&#27169;&#22411;&#65292;&#25214;&#21040;&#27169;&#22411;&#32972;&#21518;&#30340;&#24615;&#36136;&#21644;&#29702;&#35770;&#12290;&#32447;&#24615;&#27169;&#22411;&#26159;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#20027;&#35201;&#25216;&#26415;&#65292;&#26368;&#20027;&#35201;&#30340;&#24037;&#20855;&#26159;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#65292;&#23427;&#26368;&#23567;&#21270;&#20102;&#24179;&#26041;&#35823;&#24046;&#30340;&#21644;&#12290;&#24403;&#25105;&#20204;&#26377;&#20852;&#36259;&#25214;&#21040;&#26368;&#23567;&#21270;&#30456;&#24212;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#30340;&#22238;&#24402;&#20989;&#25968;&#26102;&#65292;&#36825;&#26159;&#19968;&#20010;&#33258;&#28982;&#30340;&#36873;&#25321;&#12290;&#26412;&#20070;&#20027;&#35201;&#24635;&#32467;&#20102;&#32447;&#24615;&#27169;&#22411;&#32972;&#21518;&#30340;&#30446;&#30340;&#21644;&#37325;&#35201;&#29702;&#35770;&#30340;&#24847;&#20041;&#65292;&#20363;&#22914;&#27010;&#29575;&#20998;&#24067;&#12289;&#25512;&#23548;&#21644;&#20272;&#35745;&#26041;&#27861;&#31561;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
This book is meant to provide an introduction to linear models and the theories behind them. Our goal is to give a rigorous introduction to the readers with prior exposure to ordinary least squares. In machine learning, the output is usually a nonlinear function of the input. Deep learning even aims to find a nonlinear dependence with many layers, which require a large amount of computation. However, most of these algorithms build upon simple linear models. We then describe linear models from different perspectives and find the properties and theories behind the models. The linear model is the main technique in regression problems, and the primary tool for it is the least squares approximation, which minimizes a sum of squared errors. This is a natural choice when we're interested in finding the regression function which minimizes the corresponding expected squared error. This book is primarily a summary of purpose, significance of important theories behind linear models, e.g., distrib
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#20108;&#36827;&#21046;&#29992;&#25143;&#21453;&#39304;&#36827;&#34892;&#32858;&#31867;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#26469;&#26368;&#23567;&#21270;&#32858;&#31867;&#24674;&#22797;&#38169;&#35823;&#29575;&#12290;</title><link>https://arxiv.org/abs/1910.06002</link><description>&lt;p&gt;
&#26469;&#33258;&#22122;&#22768;&#20108;&#36827;&#21046;&#21453;&#39304;&#30340;&#26368;&#20248;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Optimal Clustering from Noisy Binary Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1910.06002
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#20108;&#36827;&#21046;&#29992;&#25143;&#21453;&#39304;&#36827;&#34892;&#32858;&#31867;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#26469;&#26368;&#23567;&#21270;&#32858;&#31867;&#24674;&#22797;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;&#20108;&#36827;&#21046;&#29992;&#25143;&#21453;&#39304;&#26469;&#36827;&#34892;&#32858;&#31867;&#30340;&#38382;&#39064;&#12290;&#36825;&#26679;&#30340;&#38382;&#39064;&#22312;&#22823;&#35268;&#27169;&#26631;&#35760;&#20219;&#21153;&#20013;&#20197;&#26368;&#23567;&#30340;&#29992;&#25143;&#24037;&#20316;&#37327;&#35299;&#20915;&#30340;&#20247;&#21253;&#24179;&#21488;&#19978;&#20986;&#29616;&#12290;&#20363;&#22914;&#65292;&#22312;&#19968;&#20123;&#26368;&#36817;&#30340;reCAPTCHA&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#30340;&#28857;&#20987;&#65288;&#20108;&#36827;&#21046;&#31572;&#26696;&#65289;&#21487;&#20197;&#29992;&#26469;&#26377;&#25928;&#22320;&#26631;&#35760;&#22270;&#20687;&#12290;&#22312;&#25105;&#20204;&#30340;&#25512;&#29702;&#38382;&#39064;&#20013;&#65292;&#39033;&#30446;&#34987;&#20998;&#25104;&#26368;&#21021;&#26410;&#30693;&#30340;&#19981;&#37325;&#21472;&#30340;&#32858;&#31867;&#12290;&#20026;&#20102;&#24674;&#22797;&#36825;&#20123;&#32858;&#31867;&#65292;&#23398;&#20064;&#32773;&#25353;&#39034;&#24207;&#21521;&#29992;&#25143;&#21576;&#29616;&#19968;&#31995;&#21015;&#39033;&#30446;&#65292;&#27599;&#20010;&#39033;&#30446;&#37117;&#38468;&#26377;&#19968;&#20010;&#20174;&#22266;&#23450;&#26377;&#38480;&#38598;&#21512;&#20013;&#36873;&#25321;&#30340;&#20855;&#26377;&#20108;&#36827;&#21046;&#31572;&#26696;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#36825;&#20123;&#39033;&#30446;&#20013;&#30340;&#27599;&#19968;&#20010;&#65292;&#29992;&#25143;&#25552;&#20379;&#30340;&#26159;&#19968;&#20010;&#30001;&#39033;&#30446;&#32858;&#31867;&#12289;&#38382;&#39064;&#21644;&#19968;&#20010;&#25551;&#36848;&#23545;&#39033;&#30446;&#36827;&#34892;&#20998;&#31867;&#30340;&#38590;&#24230;&#30340;&#39033;&#30446;&#29305;&#23450;&#21442;&#25968;&#20915;&#23450;&#26399;&#26395;&#30340;&#22122;&#22768;&#31572;&#26696;&#12290;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#31181;&#31639;&#27861;&#65292;&#20855;&#26377;&#26368;&#23567;&#30340;&#32858;&#31867;&#24674;&#22797;&#38169;&#35823;&#29575;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#20219;&#20309;&#31639;&#27861;&#28385;&#36275;&#30340;&#38382;&#39064;&#29305;&#23450;&#30340;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#65292;&#29992;&#20110;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of clustering a set of items from binary user feedback. Such a problem arises in crowdsourcing platforms solving large-scale labeling tasks with minimal effort put on the users. For example, in some of the recent reCAPTCHA systems, users clicks (binary answers) can be used to efficiently label images. In our inference problem, items are grouped into initially unknown non-overlapping clusters. To recover these clusters, the learner sequentially presents to users a finite list of items together with a question with a binary answer selected from a fixed finite set. For each of these items, the user provides a noisy answer whose expectation is determined by the item cluster and the question and by an item-specific parameter characterizing the {\it hardness} of classifying the item. The objective is to devise an algorithm with a minimal cluster recovery error rate. We derive problem-specific information-theoretical lower bounds on the error rate satisfied by any algorit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#32477;&#23545;&#20540;&#25439;&#22833;&#20989;&#25968;&#20026; $\ell_p$ &#30340;&#19981;&#30830;&#23450;&#22238;&#24402;&#35774;&#32622;&#20013;&#26500;&#24314;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#36924;&#36817;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#23545;&#20110;&#32447;&#24615;&#22238;&#24402;&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;&#32500;&#24230;&#22823;&#23567;&#30340;&#21387;&#32553;&#65292;&#23545;&#20110; $\ell_1$ &#21644; $\ell_\infty$ &#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;&#32500;&#24230;&#22823;&#23567;&#30340;&#26377;&#25928;&#23436;&#20840;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65307;&#21516;&#26102;&#65292;&#35777;&#26126;&#20102;&#20854;&#20182; $\ell_p$ &#25439;&#22833;&#20989;&#25968;&#19981;&#23384;&#22312;&#26377;&#38480;&#23610;&#23544;&#30340;&#23436;&#20840;&#19981;&#21487;&#30693;&#21387;&#32553;&#26041;&#26696;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/1810.01864</link><description>&lt;p&gt;
&#26080;&#30693;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#19981;&#21487;&#30693;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Agnostic Sample Compression Schemes for Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1810.01864
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#32477;&#23545;&#20540;&#25439;&#22833;&#20989;&#25968;&#20026; $\ell_p$ &#30340;&#19981;&#30830;&#23450;&#22238;&#24402;&#35774;&#32622;&#20013;&#26500;&#24314;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#36924;&#36817;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#23545;&#20110;&#32447;&#24615;&#22238;&#24402;&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;&#32500;&#24230;&#22823;&#23567;&#30340;&#21387;&#32553;&#65292;&#23545;&#20110; $\ell_1$ &#21644; $\ell_\infty$ &#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;&#32500;&#24230;&#22823;&#23567;&#30340;&#26377;&#25928;&#23436;&#20840;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65307;&#21516;&#26102;&#65292;&#35777;&#26126;&#20102;&#20854;&#20182; $\ell_p$ &#25439;&#22833;&#20989;&#25968;&#19981;&#23384;&#22312;&#26377;&#38480;&#23610;&#23544;&#30340;&#23436;&#20840;&#19981;&#21487;&#30693;&#21387;&#32553;&#26041;&#26696;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#32477;&#23545;&#20540;&#25439;&#22833;&#20989;&#25968;&#20026; $\ell_p$ &#30340;&#19981;&#30830;&#23450;&#22238;&#24402;&#35774;&#32622;&#20013;&#33719;&#24471;&#20102;&#31532;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#21387;&#32553;&#30340;&#31215;&#26497;&#32467;&#26524;&#65292;&#20854;&#20013; $p \in [1, \infty]$&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#36924;&#36817;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#23637;&#31034;&#20102;&#25351;&#25968;&#32423;&#22823;&#23567;&#30340;fat-shattering&#32500;&#24230;&#20294;&#19982;&#26679;&#26412;&#25968;&#37327;&#26080;&#20851;&#30340;&#23454;&#20540;&#20989;&#25968;&#31867;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#32447;&#24615;&#32500;&#24230;&#22823;&#23567;&#30340;&#36924;&#36817;&#21387;&#32553;&#12290;&#27492;&#22806;&#65292;&#22312;$\ell_1$&#21644;$\ell_\infty$&#25439;&#22833;&#20989;&#25968;&#20013;&#65292;&#25105;&#20204;&#29978;&#33267;&#21487;&#20197;&#23637;&#31034;&#20986;&#19968;&#20010;&#32447;&#24615;&#32500;&#24230;&#22823;&#23567;&#30340;&#26377;&#25928;&#23436;&#20840;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#23545;&#20110;&#20854;&#20182;&#27599;&#19968;&#20010; $\ell_p$ &#25439;&#22833;&#20989;&#25968;&#65292;&#20854;&#20013; $p \in (1,\infty)$&#65292;&#19981;&#23384;&#22312;&#26377;&#38480;&#23610;&#23544;&#30340;&#23436;&#20840;&#19981;&#21487;&#30693;&#21387;&#32553;&#26041;&#26696;&#12290;&#36825;&#36827;&#19968;&#27493;&#25913;&#36827;&#21644;&#25512;&#24191;&#20102;David&#12289;Moran&#21644;Yehudayoff&#23545;&#20110;$\ell_2$&#25439;&#22833;&#30340;&#36127;&#38754;&#32467;&#26524;&#12290;&#25105;&#20204;&#26368;&#21518;&#25552;&#20986;&#20102;&#19968;&#33324;&#24615;&#30340;&#24320;&#25918;&#38382;&#39064;&#65306;&#23545;&#20110; $\ell_1$ &#25439;&#22833;&#30340;&#19981;&#21487;&#30693;&#22238;&#24402;&#38382;&#39064;&#65292;&#26159;&#21542;&#27599;&#20010;&#20989;&#25968;&#31867;&#37117;&#23384;&#22312;&#23610;&#23544;&#20026;...&#30340;&#23436;&#20840;&#21387;&#32553;&#26041;&#26696;&#65311;
&lt;/p&gt;
&lt;p&gt;
We obtain the first positive results for bounded sample compression in the agnostic regression setting with the $\ell_p$ loss, where $p\in [1,\infty]$. We construct a generic approximate sample compression scheme for real-valued function classes exhibiting exponential size in the fat-shattering dimension but independent of the sample size. Notably, for linear regression, an approximate compression of size linear in the dimension is constructed. Moreover, for $\ell_1$ and $\ell_\infty$ losses, we can even exhibit an efficient exact sample compression scheme of size linear in the dimension. We further show that for every other $\ell_p$ loss, $p\in (1,\infty)$, there does not exist an exact agnostic compression scheme of bounded size. This refines and generalizes a negative result of David, Moran, and Yehudayoff for the $\ell_2$ loss. We close by posing general open questions: for agnostic regression with $\ell_1$ loss, does every function class admits an exact compression scheme of size 
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#35757;&#32451;&#20013;&#23398;&#20064;&#27969;&#24418;&#65292;&#24182;&#20351;&#29992;Ricci&#27969;&#20351;&#27969;&#24418;&#28508;&#31354;&#38388;&#36880;&#27493;&#36866;&#24212;&#21160;&#21147;&#23398;&#30340;&#21464;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;PDE&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#30340;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2401.14591</link><description>&lt;p&gt;
&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#26102;&#21464;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Ricci flow-guided autoencoders in learning time-dependent dynamics. (arXiv:2401.14591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14591
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#35757;&#32451;&#20013;&#23398;&#20064;&#27969;&#24418;&#65292;&#24182;&#20351;&#29992;Ricci&#27969;&#20351;&#27969;&#24418;&#28508;&#31354;&#38388;&#36880;&#27493;&#36866;&#24212;&#21160;&#21147;&#23398;&#30340;&#21464;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;PDE&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#26102;&#38388;&#19978;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#65292;&#20854;&#20013;&#27969;&#24418;&#28508;&#31354;&#38388;&#26681;&#25454;Ricci&#27969;&#21457;&#23637;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#22312;&#29289;&#29702;&#20449;&#24687;&#35774;&#32622;&#20013;&#27169;&#25311;Ricci&#27969;&#26469;&#23454;&#29616;&#65292;&#24182;&#19988;&#21487;&#20197;&#21305;&#37197;&#27969;&#24418;&#37327;&#65292;&#20197;&#20415;&#23454;&#29616;Ricci&#27969;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#27969;&#24418;&#26159;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#23398;&#20064;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#35782;&#21035;&#20986;&#29702;&#24819;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#21516;&#26102;&#28436;&#21464;&#20063;&#33021;&#22312;&#38745;&#24577;&#26041;&#27861;&#19978;&#24341;&#36215;&#26356;&#23485;&#23481;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#31561;&#29702;&#24819;&#29305;&#24449;&#30340;PDE&#65292;&#24182;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#36827;&#34892;&#35823;&#24046;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a manifold-based autoencoder method for learning nonlinear dynamics in time, notably partial differential equations (PDEs), in which the manifold latent space evolves according to Ricci flow. This can be accomplished by simulating Ricci flow in a physics-informed setting, and manifold quantities can be matched so that Ricci flow is empirically achieved. With our methodology, the manifold is learned as part of the training procedure, so ideal geometries may be discerned, while the evolution simultaneously induces a more accommodating latent representation over static methods. We present our method on a range of numerical experiments consisting of PDEs that encompass desirable characteristics such as periodicity and randomness, remarking error on in-distribution and extrapolation scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20998;&#35299;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#35299;&#20915;&#20302;&#32990;&#29366;&#31209;&#24352;&#37327;&#24674;&#22797;&#38382;&#39064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#22823;&#24352;&#37327;&#20998;&#35299;&#20026;&#20004;&#20010;&#36739;&#23567;&#30340;&#22240;&#23376;&#24352;&#37327;&#65292;&#22312;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#21644;&#23384;&#20648;&#38656;&#27714;&#30340;&#21516;&#26102;&#65292;&#30830;&#20445;&#20102;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.11940</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#35299;&#26799;&#24230;&#19979;&#38477;&#23454;&#29616;&#20302;&#32990;&#29366;&#31209;&#24352;&#37327;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent. (arXiv:2401.11940v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11940
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20998;&#35299;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#35299;&#20915;&#20302;&#32990;&#29366;&#31209;&#24352;&#37327;&#24674;&#22797;&#38382;&#39064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#22823;&#24352;&#37327;&#20998;&#35299;&#20026;&#20004;&#20010;&#36739;&#23567;&#30340;&#22240;&#23376;&#24352;&#37327;&#65292;&#22312;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#21644;&#23384;&#20648;&#38656;&#27714;&#30340;&#21516;&#26102;&#65292;&#30830;&#20445;&#20102;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#23569;&#37327;&#34987;&#30772;&#22351;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#24674;&#22797;&#20855;&#26377;&#20302;&#32990;&#29366;&#31209;&#32467;&#26500;&#30340;&#24352;&#37327;&#30340;&#38382;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#38656;&#35201;&#35745;&#31639;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;t-SVD&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#35745;&#31639;&#23494;&#38598;&#30340;&#36807;&#31243;&#65292;&#20351;&#23427;&#20204;&#38590;&#20197;&#22788;&#29702;&#22823;&#35268;&#27169;&#24352;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31867;&#20284;&#20110;Burer-Monteiro&#65288;BM&#65289;&#26041;&#27861;&#30340;&#20998;&#35299;&#36807;&#31243;&#30340;&#39640;&#25928;&#20302;&#32990;&#29366;&#31209;&#24352;&#37327;&#24674;&#22797;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#22522;&#26412;&#26041;&#27861;&#28041;&#21450;&#23558;&#19968;&#20010;&#22823;&#24352;&#37327;&#20998;&#35299;&#20026;&#20004;&#20010;&#36739;&#23567;&#30340;&#22240;&#23376;&#24352;&#37327;&#65292;&#28982;&#21518;&#36890;&#36807;&#20998;&#35299;&#26799;&#24230;&#19979;&#38477;&#65288;FGD&#65289;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#35813;&#31574;&#30053;&#28040;&#38500;&#20102;t-SVD&#35745;&#31639;&#30340;&#38656;&#35201;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#35745;&#31639;&#25104;&#26412;&#21644;&#23384;&#20648;&#38656;&#27714;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#20197;&#20445;&#35777;FGD&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the problem of recovering a tensor with an underlying low-tubal-rank structure from a small number of corrupted linear measurements. Traditional approaches tackling such a problem require the computation of tensor Singular Value Decomposition (t-SVD), that is a computationally intensive process, rendering them impractical for dealing with large-scale tensors. Aim to address this challenge, we propose an efficient and effective low-tubal-rank tensor recovery method based on a factorization procedure akin to the Burer-Monteiro (BM) method. Precisely, our fundamental approach involves decomposing a large tensor into two smaller factor tensors, followed by solving the problem through factorized gradient descent (FGD). This strategy eliminates the need for t-SVD computation, thereby reducing computational costs and storage requirements. We provide rigorous theoretical analysis to ensure the convergence of FGD under both noise-free and noisy situations. Additionally, it 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#30340;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#21608;&#22260;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2401.05574</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#22343;&#20540;&#30340;&#40065;&#26834;&#32858;&#31867;&#30340;&#19968;&#33324;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A general theory for robust clustering via trimmed mean. (arXiv:2401.05574v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#30340;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#21608;&#22260;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#24322;&#36136;&#25968;&#25454;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#32858;&#31867;&#26159;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#12290;&#35768;&#22810;&#26368;&#36817;&#30340;&#32467;&#26524;&#20027;&#35201;&#20851;&#27880;&#22312;&#25968;&#25454;&#22260;&#32469;&#24102;&#26377;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#20998;&#24067;&#26102;&#30340;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#38480;&#21046;&#24615;&#30340;&#27425;&#39640;&#26031;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#24120;&#24120;&#26080;&#25928;&#65292;&#22240;&#20026;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#23637;&#31034;&#20102;&#22260;&#32469;&#20013;&#24515;&#28857;&#30340;&#37325;&#23614;&#20998;&#24067;&#25110;&#21463;&#21040;&#21487;&#33021;&#30340;&#25932;&#23545;&#25915;&#20987;&#65292;&#38656;&#35201;&#20855;&#26377;&#40065;&#26834;&#25968;&#25454;&#39537;&#21160;&#21021;&#22987;&#21270;&#30340;&#40065;&#26834;&#32858;&#31867;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#21033;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#21464;&#37327;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#65292;&#22312;&#20013;&#24515;&#28857;&#21608;&#22260;&#30340;&#35823;&#24046;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#19968;&#20010;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#19978;&#30028;&#20381;&#36182;&#20110;&#32858;&#31867;&#30340;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21363;&#20351;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31616;&#21270;&#20026;&#20122;&#39640;&#26031;&#27169;&#22411;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is a fundamental tool in statistical machine learning in the presence of heterogeneous data. Many recent results focus primarily on optimal mislabeling guarantees, when data are distributed around centroids with sub-Gaussian errors. Yet, the restrictive sub-Gaussian model is often invalid in practice, since various real-world applications exhibit heavy tail distributions around the centroids or suffer from possible adversarial attacks that call for robust clustering with a robust data-driven initialization. In this paper, we introduce a hybrid clustering technique with a novel multivariate trimmed mean type centroid estimate to produce mislabeling guarantees under a weak initialization condition for general error distributions around the centroids. A matching lower bound is derived, up to factors depending on the number of clusters. In addition, our approach also produces the optimal mislabeling even in the presence of adversarial outliers. Our results reduce to the sub-Gaus
&lt;/p&gt;</description></item><item><title>SASSL&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#39118;&#26684;&#36801;&#31227;&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#36890;&#36807;&#35299;&#32806;&#35821;&#20041;&#21644;&#39118;&#26684;&#23646;&#24615;&#65292;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#26679;&#26412;&#65292;&#20174;&#32780;&#25552;&#21319;&#20102;&#22270;&#20687;&#20998;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2312.01187</link><description>&lt;p&gt;
SASSL:&#36890;&#36807;&#31070;&#32463;&#39118;&#26684;&#36801;&#31227;&#22686;&#24378;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer. (arXiv:2312.01187v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01187
&lt;/p&gt;
&lt;p&gt;
SASSL&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#39118;&#26684;&#36801;&#31227;&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#36890;&#36807;&#35299;&#32806;&#35821;&#20041;&#21644;&#39118;&#26684;&#23646;&#24615;&#65292;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#26679;&#26412;&#65292;&#20174;&#32780;&#25552;&#21319;&#20102;&#22270;&#20687;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#20381;&#36182;&#20110;&#25968;&#25454;&#22686;&#24378;&#26469;&#20174;&#26080;&#26631;&#31614;&#22270;&#20687;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#34920;&#24449;&#12290;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#22686;&#24378;&#27969;&#27700;&#32447;&#21253;&#25324;&#20102;&#21508;&#31181;&#21407;&#22987;&#30340;&#36716;&#25442;&#65292;&#20294;&#36890;&#24120;&#24573;&#30053;&#20102;&#33258;&#28982;&#22270;&#20687;&#30340;&#32467;&#26500;&#12290;&#22240;&#27492;&#65292;&#22686;&#24378;&#26679;&#26412;&#21487;&#33021;&#26174;&#31034;&#20986;&#36864;&#21270;&#30340;&#35821;&#20041;&#20449;&#24687;&#21644;&#20302;&#39118;&#26684;&#22810;&#26679;&#24615;&#65292;&#20174;&#32780;&#24433;&#21709;&#21040;&#33258;&#30417;&#30563;&#34920;&#24449;&#30340;&#19979;&#28216;&#24615;&#33021;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SASSL&#30340;&#26032;&#22411;&#22686;&#24378;&#25216;&#26415;&#65292;&#23427;&#22522;&#20110;&#31070;&#32463;&#39118;&#26684;&#36801;&#31227;&#12290;&#35813;&#26041;&#27861;&#23558;&#22270;&#20687;&#20013;&#30340;&#35821;&#20041;&#21644;&#39118;&#26684;&#23646;&#24615;&#35299;&#32806;&#65292;&#24182;&#20165;&#23545;&#39118;&#26684;&#24212;&#29992;&#36716;&#25442;&#65292;&#20445;&#25345;&#20869;&#23481;&#65292;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#26679;&#26412;&#65292;&#26356;&#22909;&#22320;&#20445;&#30041;&#23427;&#20204;&#30340;&#35821;&#20041;&#23646;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#19982;&#24191;&#20026;&#25509;&#21463;&#30340;MoCo v2&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;ImageNet&#19978;&#30340;top-1&#20998;&#31867;&#24615;&#33021;&#25552;&#21319;&#36229;&#36807;2%&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning relies heavily on data augmentation to extract meaningful representations from unlabeled images. While existing state-of-the-art augmentation pipelines incorporate a wide range of primitive transformations, these often disregard natural image structure. Thus, augmented samples can exhibit degraded semantic information and low stylistic diversity, affecting downstream performance of self-supervised representations. To overcome this, we propose SASSL: Style Augmentations for Self Supervised Learning, a novel augmentation technique based on Neural Style Transfer. The method decouples semantic and stylistic attributes in images and applies transformations exclusively to the style while preserving content, generating diverse augmented samples that better retain their semantic properties. Experimental results show our technique achieves a top-1 classification performance improvement of more than 2% on ImageNet compared to the well-established MoCo v2. We also measure
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#65292;&#22312;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#22522;&#30784;&#19978;&#65292;&#23545;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#36827;&#34892;&#20102;&#20855;&#20307;&#30340;&#20272;&#35745;&#35823;&#24046;&#20998;&#26512;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#25269;&#25239;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#31561;&#20851;&#38190;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.15330</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#32852;&#37030;&#23398;&#20064;&#65306;&#20855;&#26377;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#30340;&#24322;&#26500;&#28151;&#21512;&#27169;&#22411;&#30340;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Federated Learning: A Federated Gradient EM Algorithm for Heterogeneous Mixture Models with Robustness against Adversarial Attacks. (arXiv:2310.15330v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15330
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#65292;&#22312;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#22522;&#30784;&#19978;&#65292;&#23545;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#36827;&#34892;&#20102;&#20855;&#20307;&#30340;&#20272;&#35745;&#35823;&#24046;&#20998;&#26512;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#25269;&#25239;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#31561;&#20851;&#38190;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#26377;&#30417;&#30563;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#26080;&#30417;&#30563;&#30340;&#32852;&#37030;&#23398;&#20064;&#39046;&#22495;&#30456;&#23545;&#36739;&#23569;&#25506;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#65292;&#28982;&#21518;&#23558;&#36825;&#19968;&#36890;&#29992;&#29702;&#35770;&#24212;&#29992;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#20197;&#25551;&#36848;&#27169;&#22411;&#21442;&#25968;&#21644;&#28151;&#21512;&#27604;&#20363;&#30340;&#26174;&#24335;&#20272;&#35745;&#35823;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#20855;&#26377;&#20197;&#19979;&#20960;&#20010;&#20851;&#38190;&#20248;&#21183;&#65306;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#20855;&#26377;&#24377;&#24615;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
While supervised federated learning approaches have enjoyed significant success, the domain of unsupervised federated learning remains relatively underexplored. In this paper, we introduce a novel federated gradient EM algorithm designed for the unsupervised learning of mixture models with heterogeneous mixture proportions across tasks. We begin with a comprehensive finite-sample theory that holds for general mixture models, then apply this general theory on Gaussian Mixture Models (GMMs) and Mixture of Regressions (MoRs) to characterize the explicit estimation error of model parameters and mixture proportions. Our proposed federated gradient EM algorithm demonstrates several key advantages: adaptability to unknown task similarity, resilience against adversarial attacks on a small fraction of data sources, protection of local data privacy, and computational and communication efficiency.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#36890;&#36807;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#24341;&#20837;&#19981;&#21516;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#32780;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#21017;&#30001;&#36825;&#20123;&#29305;&#24449;&#25152;&#20915;&#23450;&#12290;</title><link>http://arxiv.org/abs/2310.07891</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks. (arXiv:2310.07891v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07891
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#36890;&#36807;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#24341;&#20837;&#19981;&#21516;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#32780;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#21017;&#30001;&#36825;&#20123;&#29305;&#24449;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#23398;&#20064;&#34987;&#35748;&#20026;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25104;&#21151;&#30340;&#22522;&#26412;&#21407;&#22240;&#20043;&#19968;&#12290;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#24050;&#32463;&#20005;&#26684;&#35777;&#26126;&#65292;&#22312;&#20004;&#23618;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#31532;&#19968;&#23618;&#36827;&#34892;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#65292;&#28982;&#21518;&#22312;&#31532;&#20108;&#23618;&#36827;&#34892;&#23725;&#22238;&#24402;&#21487;&#20197;&#23548;&#33268;&#29305;&#24449;&#23398;&#20064;&#65307;&#29305;&#24449;&#30697;&#38453;&#30340;&#35889;&#20013;&#20250;&#20986;&#29616;&#20998;&#31163;&#30340;&#19968;&#32500;&#32452;&#20214;&#65292;&#31216;&#20026;&#8220;spike&#8221;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#22266;&#23450;&#26799;&#24230;&#19979;&#38477;&#27493;&#38271;&#26102;&#65292;&#36825;&#20010;&#8220;spike&#8221;&#20165;&#25552;&#20379;&#20102;&#30446;&#26631;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#20214;&#30340;&#20449;&#24687;&#65292;&#22240;&#27492;&#23398;&#20064;&#38750;&#32447;&#24615;&#32452;&#20214;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23398;&#20064;&#29575;&#38543;&#26679;&#26412;&#22823;&#23567;&#22686;&#38271;&#26102;&#65292;&#36825;&#26679;&#30340;&#35757;&#32451;&#23454;&#38469;&#19978;&#24341;&#20837;&#20102;&#22810;&#20010;&#19968;&#32500;&#32452;&#20214;&#65292;&#27599;&#20010;&#32452;&#20214;&#23545;&#24212;&#19968;&#20010;&#29305;&#23450;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#26497;&#38480;&#22823;&#32500;&#24230;&#21644;&#22823;&#26679;&#26412;&#35757;&#32451;&#21644;&#27979;&#35797;&#35823;&#24046;&#23436;&#20840;&#30001;&#36825;&#20123;&#8220;spike&#8221;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature learning is thought to be one of the fundamental reasons for the success of deep neural networks. It is rigorously known that in two-layer fully-connected neural networks under certain conditions, one step of gradient descent on the first layer followed by ridge regression on the second layer can lead to feature learning; characterized by the appearance of a separated rank-one component -- spike -- in the spectrum of the feature matrix. However, with a constant gradient descent step size, this spike only carries information from the linear component of the target function and therefore learning non-linear components is impossible. We show that with a learning rate that grows with the sample size, such training in fact introduces multiple rank-one components, each corresponding to a specific polynomial feature. We further prove that the limiting large-dimensional and large sample training and test errors of the updated neural networks are fully characterized by these spikes. By 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#29702;&#35770;&#20998;&#26512;&#20102;&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Adv-NTK&#30340;AT&#31639;&#27861;&#26469;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06112</link><description>&lt;p&gt;
&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#30340;&#29702;&#35770;&#20998;&#26512;&#65306;&#19968;&#31181;NTK&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach. (arXiv:2310.06112v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#29702;&#35770;&#20998;&#26512;&#20102;&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Adv-NTK&#30340;AT&#31639;&#27861;&#26469;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;(AT)&#26159;&#22686;&#24378;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#40065;&#26834;&#24615;&#30340;&#32463;&#20856;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#23454;&#39564;&#35777;&#26126;&#23427;&#23384;&#22312;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#21363;&#38271;&#26102;&#38388;&#30340;AT&#21487;&#33021;&#23545;DNNs&#30340;&#40065;&#26834;&#24615;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#26412;&#25991;&#23545;DNNs&#30340;&#40065;&#26834;&#36807;&#25311;&#21512;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#35299;&#37322;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#31070;&#32463;&#20999;&#21521;&#26680;(NTK)&#29702;&#35770;&#38750;&#24179;&#20961;&#22320;&#25193;&#23637;&#21040;AT&#65292;&#24182;&#35777;&#26126;&#20102;&#36890;&#36807;AT&#35757;&#32451;&#30340;&#23485;DNN&#21487;&#20197;&#24456;&#22909;&#22320;&#36817;&#20284;&#20026;&#19968;&#20010;&#32447;&#24615;&#21270;&#30340;DNN&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#24179;&#26041;&#25439;&#22833;&#65292;&#21487;&#20197;&#25512;&#23548;&#20986;&#32447;&#24615;&#21270;DNN&#30340;&#38381;&#24335;AT&#21160;&#21147;&#23398;&#65292;&#25581;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;AT&#36864;&#21270;&#29616;&#35937;&#65306;&#38271;&#26399;&#30340;AT&#23558;&#23548;&#33268;&#23485;DNN&#36864;&#21270;&#20026;&#27809;&#26377;AT&#30340;DNN&#65292;&#20174;&#32780;&#24341;&#36215;&#40065;&#26834;&#36807;&#25311;&#21512;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;Adv-NTK&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#31532;&#19968;&#31181;&#38024;&#23545;&#26080;&#38480;&#23485;&#30340;DNNs&#30340;AT&#31639;&#27861;&#12290;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Adv-NTK&#21487;&#20197;&#24110;&#21161;&#26080;&#38480;&#23485;&#30340;DNNs&#25552;&#21319;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training (AT) is a canonical method for enhancing the robustness of deep neural networks (DNNs). However, recent studies empirically demonstrated that it suffers from robust overfitting, i.e., a long time AT can be detrimental to the robustness of DNNs. This paper presents a theoretical explanation of robust overfitting for DNNs. Specifically, we non-trivially extend the neural tangent kernel (NTK) theory to AT and prove that an adversarially trained wide DNN can be well approximated by a linearized DNN. Moreover, for squared loss, closed-form AT dynamics for the linearized DNN can be derived, which reveals a new AT degeneration phenomenon: a long-term AT will result in a wide DNN degenerates to that obtained without AT and thus cause robust overfitting. Based on our theoretical results, we further design a method namely Adv-NTK, the first AT algorithm for infinite-width DNNs. Experiments on real-world datasets show that Adv-NTK can help infinite-width DNNs enhance comparab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.05401</link><description>&lt;p&gt;
Entropy-MCMC: &#36731;&#26494;&#20174;&#24179;&#22374;&#30406;&#22320;&#36827;&#34892;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Entropy-MCMC: Sampling from Flat Basins with Ease. (arXiv:2310.05401v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20381;&#36182;&#20110;&#23545;&#21518;&#39564;&#20998;&#24067;&#30340;&#36136;&#37327;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;&#22312;&#24615;&#36136;&#19978;&#26159;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#65292;&#23616;&#37096;&#27169;&#24335;&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#26377;&#38480;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#65292;&#20174;&#21407;&#22987;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#24615;&#33021;&#65292;&#22240;&#20026;&#19968;&#20123;&#26679;&#26412;&#21487;&#33021;&#20250;&#38519;&#20837;&#8220;&#22351;&#8221;&#27169;&#24335;&#24182;&#20986;&#29616;&#36807;&#25311;&#21512;&#12290;&#22522;&#20110;&#35266;&#23519;&#21040;&#20302;&#27867;&#21270;&#35823;&#24046;&#30340;&#8220;&#22909;&#8221;&#27169;&#24335;&#36890;&#24120;&#23384;&#22312;&#20110;&#33021;&#37327;&#26223;&#35266;&#30340;&#24179;&#22374;&#30406;&#22320;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20559;&#32622;&#37319;&#26679;&#26397;&#21521;&#36825;&#20123;&#24179;&#22374;&#21306;&#22495;&#30340;&#21518;&#39564;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#24341;&#23548;&#21464;&#37327;&#65292;&#20854;&#31283;&#24577;&#20998;&#24067;&#31867;&#20284;&#20110;&#24179;&#28369;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#27809;&#26377;&#23574;&#38160;&#30340;&#27169;&#24577;&#65292;&#20197;&#24341;&#23548;MCMC&#37319;&#26679;&#22120;&#22312;&#24179;&#22374;&#30340;&#30406;&#22320;&#20013;&#37319;&#26679;&#12290;&#36890;&#36807;&#23558;&#27492;&#24341;&#23548;&#21464;&#37327;&#19982;&#27169;&#22411;&#21442;&#25968;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#21487;&#20197;&#22312;&#26368;&#23567;&#35745;&#31639;&#24320;&#38144;&#19979;&#23454;&#29616;&#39640;&#25928;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20803;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian deep learning counts on the quality of posterior distribution estimation. However, the posterior of deep neural networks is highly multi-modal in nature, with local modes exhibiting varying generalization performance. Given a practical budget, sampling from the original posterior can lead to suboptimal performance, as some samples may become trapped in "bad" modes and suffer from overfitting. Leveraging the observation that "good" modes with low generalization error often reside in flat basins of the energy landscape, we propose to bias sampling on the posterior toward these flat regions. Specifically, we introduce an auxiliary guiding variable, the stationary distribution of which resembles a smoothed posterior free from sharp modes, to lead the MCMC sampler to flat basins. By integrating this guiding variable with the model parameter, we create a simple joint distribution that enables efficient sampling with minimal computational overhead. We prove the convergence of our met
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20998;&#35299;transformer&#30340;&#38544;&#34255;&#29366;&#24577;&#65292;&#25581;&#31034;&#20102;&#20854;&#22312;&#35821;&#20041;&#29702;&#35299;&#20013;&#30340;&#38544;&#21547;&#20960;&#20309;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2310.04861</link><description>&lt;p&gt;
&#36890;&#36807;&#21306;&#20998;&#20301;&#32622;&#21644;&#19978;&#19979;&#25991;&#26469;&#25581;&#31034;Transformers&#20013;&#30340;&#38544;&#34255;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Uncovering hidden geometry in Transformers via disentangling position and context. (arXiv:2310.04861v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20998;&#35299;transformer&#30340;&#38544;&#34255;&#29366;&#24577;&#65292;&#25581;&#31034;&#20102;&#20854;&#22312;&#35821;&#20041;&#29702;&#35299;&#20013;&#30340;&#38544;&#21547;&#20960;&#20309;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformers&#24191;&#27867;&#29992;&#20110;&#20174;&#36755;&#20837;&#20196;&#29260;&#20013;&#25552;&#21462;&#22797;&#26434;&#30340;&#35821;&#20041;&#24847;&#20041;&#65292;&#28982;&#32780;&#23427;&#20204;&#36890;&#24120;&#20316;&#20026;&#40657;&#30418;&#27169;&#22411;&#36816;&#34892;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#20449;&#24687;&#20016;&#23500;&#30340;&#26041;&#27861;&#65292;&#23558;&#35757;&#32451;&#22909;&#30340;transformer&#30340;&#38544;&#34255;&#29366;&#24577;&#65288;&#25110;&#23884;&#20837;&#65289;&#20998;&#35299;&#20026;&#21487;&#35299;&#37322;&#30340;&#32452;&#20214;&#12290;&#23545;&#20110;&#20219;&#20309;&#23618;&#65292;&#36755;&#20837;&#24207;&#21015;&#26679;&#26412;&#30340;&#23884;&#20837;&#21521;&#37327;&#30001;&#19968;&#20010;&#24352;&#37327;&#34920;&#31034; $\boldsymbol{h} \in \mathbb{R}^{C \times T \times d}$&#12290;&#32473;&#23450;&#22312;&#24207;&#21015;&#65288;&#25110;&#19978;&#19979;&#25991;&#65289; $c \le C$ &#30340;&#20301;&#32622; $t \le T$ &#22788;&#30340;&#23884;&#20837;&#21521;&#37327; $\boldsymbol{h}_{c,t} \in \mathbb{R}^d$&#65292;&#25552;&#21462;&#22343;&#20540;&#25928;&#26524;&#24471;&#21040;&#20998;&#35299;&#24418;&#24335; \[ \boldsymbol{h}_{c,t} = \boldsymbol{\mu} + \mathbf{pos}_t + \mathbf{ctx}_c + \mathbf{resid}_{c,t} \] &#20854;&#20013; $\boldsymbol{\mu}$ &#26159;&#20840;&#23616;&#22343;&#20540;&#21521;&#37327;&#65292;$\mathbf{pos}_t$ &#21644; $\mathbf{ctx}_c$ &#20998;&#21035;&#26159;&#36328;&#19978;&#19979;&#25991;&#21644;&#36328;&#20301;&#32622;&#30340;&#22343;&#20540;&#21521;&#37327;&#65292;$\mathbf{resid}_{c,t}$ &#26159;&#27531;&#20313;&#21521;&#37327;&#12290;&#38024;&#23545;&#27969;&#34892;&#30340;transformer&#26550;&#26500;&#21644;&#22810;&#26679;&#30340;&#25991;&#26412;&#25968;&#25454;&#38598;&#65292;&#32463;&#39564;&#32467;&#26524;&#34920;&#26126;...
&lt;/p&gt;
&lt;p&gt;
Transformers are widely used to extract complex semantic meanings from input tokens, yet they usually operate as black-box models. In this paper, we present a simple yet informative decomposition of hidden states (or embeddings) of trained transformers into interpretable components. For any layer, embedding vectors of input sequence samples are represented by a tensor $\boldsymbol{h} \in \mathbb{R}^{C \times T \times d}$. Given embedding vector $\boldsymbol{h}_{c,t} \in \mathbb{R}^d$ at sequence position $t \le T$ in a sequence (or context) $c \le C$, extracting the mean effects yields the decomposition \[ \boldsymbol{h}_{c,t} = \boldsymbol{\mu} + \mathbf{pos}_t + \mathbf{ctx}_c + \mathbf{resid}_{c,t} \] where $\boldsymbol{\mu}$ is the global mean vector, $\mathbf{pos}_t$ and $\mathbf{ctx}_c$ are the mean vectors across contexts and across positions respectively, and $\mathbf{resid}_{c,t}$ is the residual vector. For popular transformer architectures and diverse text datasets, empirica
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LSL-GFN&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#36895;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#65292;&#20174;&#32780;&#25552;&#39640;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.02823</link><description>&lt;p&gt;
&#23398;&#20064;&#28201;&#24230;&#26465;&#20214;&#19979;&#23610;&#24230;&#26631;&#37327;&#21270;&#30340;GFlowNets
&lt;/p&gt;
&lt;p&gt;
Learning to Scale Logits for Temperature-Conditional GFlowNets. (arXiv:2310.02823v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02823
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LSL-GFN&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#36895;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#65292;&#20174;&#32780;&#25552;&#39640;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
GFlowNets&#26159;&#19968;&#31181;&#27010;&#29575;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#38543;&#26426;&#31574;&#30053;&#26469;&#39034;&#24207;&#29983;&#25104;&#32452;&#21512;&#32467;&#26500;&#65292;&#20363;&#22914;&#20998;&#23376;&#22270;&#12290;&#23427;&#20204;&#30340;&#35757;&#32451;&#30446;&#26631;&#26159;&#25353;&#27604;&#20363;&#37319;&#26679;&#20855;&#26377;&#30456;&#24212;&#28201;&#24230;&#35843;&#33410;&#30340;&#23545;&#35937;&#30340;&#22870;&#21169;&#12290;&#22312;GFlowNets&#20013;&#65292;&#28201;&#24230;&#26465;&#20214;&#19979;&#30340;GFlowNets&#20195;&#34920;&#20102;&#19968;&#31995;&#21015;&#30001;&#28201;&#24230;&#32034;&#24341;&#30340;&#31574;&#30053;&#65292;&#27599;&#20010;&#31574;&#30053;&#19982;&#30456;&#24212;&#30340;&#28201;&#24230;&#35843;&#33410;&#22870;&#21169;&#20989;&#25968;&#30456;&#20851;&#32852;&#12290;&#28201;&#24230;&#26465;&#20214;&#19979;&#30340;GFlowNets&#30340;&#20027;&#35201;&#20248;&#21183;&#22312;&#20110;&#36890;&#36807;&#35843;&#25972;&#28201;&#24230;&#26469;&#25511;&#21046;&#23545;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#23398;&#20064;&#28201;&#24230;&#26465;&#20214;&#19979;&#23610;&#24230;&#26631;&#37327;&#21270;&#30340;GFlowNets&#65288;LSL-GFN&#65289;&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#23427;&#26497;&#22823;&#22320;&#21152;&#36895;&#20102;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#12290;&#23427;&#22522;&#20110;&#19968;&#20010;&#24605;&#24819;&#65292;&#21363;&#20043;&#21069;&#25552;&#20986;&#30340;&#28201;&#24230;&#26465;&#20214;&#26041;&#27861;&#22312;&#28145;&#24230;&#32593;&#32476;&#30340;&#35757;&#32451;&#20013;&#24341;&#20837;&#20102;&#25968;&#20540;&#25361;&#25112;&#65292;&#22240;&#20026;&#19981;&#21516;&#30340;&#28201;&#24230;&#21487;&#33021;&#23548;&#33268;&#38750;&#24120;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
GFlowNets are probabilistic models that learn a stochastic policy that sequentially generates compositional structures, such as molecular graphs. They are trained with the objective of sampling such objects with probability proportional to the object's reward. Among GFlowNets, the temperature-conditional GFlowNets represent a family of policies indexed by temperature, and each is associated with the correspondingly tempered reward function. The major benefit of temperature-conditional GFlowNets is the controllability of GFlowNets' exploration and exploitation through adjusting temperature. We propose Learning to Scale Logits for temperature-conditional GFlowNets (LSL-GFN), a novel architectural design that greatly accelerates the training of temperature-conditional GFlowNets. It is based on the idea that previously proposed temperature-conditioning approaches introduced numerical challenges in the training of the deep network because different temperatures may give rise to very differe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30456;&#23545;&#23494;&#38598;&#30340;&#22270;&#19978;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#20013;&#29289;&#29702;&#21551;&#21457;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;PI-GNN&#65289;&#27714;&#35299;&#22120;&#30340;&#34920;&#29616;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;PI-GNN&#27714;&#35299;&#22120;&#22312;&#23398;&#20064;&#26089;&#26399;&#21487;&#33021;&#38519;&#20837;&#25152;&#26377;&#21464;&#37327;&#20026;&#38646;&#30340;&#23616;&#37096;&#35299;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36890;&#36807;&#25511;&#21046;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.16965</link><description>&lt;p&gt;
&#25511;&#21046;&#32452;&#21512;&#20248;&#21270;&#30340;&#36830;&#32493;&#25918;&#26494;
&lt;/p&gt;
&lt;p&gt;
Controlling Continuous Relaxation for Combinatorial Optimization. (arXiv:2309.16965v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16965
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30456;&#23545;&#23494;&#38598;&#30340;&#22270;&#19978;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#20013;&#29289;&#29702;&#21551;&#21457;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;PI-GNN&#65289;&#27714;&#35299;&#22120;&#30340;&#34920;&#29616;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;PI-GNN&#27714;&#35299;&#22120;&#22312;&#23398;&#20064;&#26089;&#26399;&#21487;&#33021;&#38519;&#20837;&#25152;&#26377;&#21464;&#37327;&#20026;&#38646;&#30340;&#23616;&#37096;&#35299;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36890;&#36807;&#25511;&#21046;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#32452;&#21512;&#20248;&#21270;&#65288;CO&#65289;&#38382;&#39064;&#20013;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#26174;&#31034;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;&#36890;&#36807;&#26080;&#30417;&#30563;&#23398;&#20064;&#25214;&#21040;&#36817;&#20284;&#35299;&#30340;&#21463;&#29289;&#29702;&#21551;&#21457;&#30340;GNN&#65288;PI-GNN&#65289;&#27714;&#35299;&#22120;&#22312;&#22823;&#35268;&#27169;CO&#38382;&#39064;&#19978;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#30456;&#23545;&#23494;&#38598;&#22270;&#19978;&#30340;CO&#38382;&#39064;&#65292;&#36138;&#23146;&#31639;&#27861;&#30340;&#24615;&#33021;&#24694;&#21270;&#65292;&#20294;&#23545;&#20110;PI-GNN&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#21364;&#27809;&#26377;&#22826;&#22810;&#35752;&#35770;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;PI-GNN&#27714;&#35299;&#22120;&#37319;&#29992;&#20102;&#25918;&#26494;&#31574;&#30053;&#65292;&#23398;&#20064;&#21518;&#38656;&#35201;&#20174;&#36830;&#32493;&#31354;&#38388;&#20154;&#24037;&#36716;&#25442;&#22238;&#21407;&#22987;&#31163;&#25955;&#31354;&#38388;&#65292;&#21487;&#33021;&#20250;&#30772;&#22351;&#35299;&#30340;&#40065;&#26834;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;PI-GNN&#27714;&#35299;&#22120;&#22312;&#23494;&#38598;&#22270;&#19978;&#30340;CO&#38382;&#39064;&#30340;&#23398;&#20064;&#26089;&#26399;&#21487;&#33021;&#38519;&#20837;&#23616;&#37096;&#35299;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#25152;&#26377;&#21464;&#37327;&#37117;&#20026;&#38646;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25511;&#21046;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in combinatorial optimization (CO) problems emphasize the potential of graph neural networks (GNNs). The physics-inspired GNN (PI-GNN) solver, which finds approximate solutions through unsupervised learning, has attracted significant attention for large-scale CO problems. Nevertheless, there has been limited discussion on the performance of the PI-GNN solver for CO problems on relatively dense graphs where the performance of greedy algorithms worsens. In addition, since the PI-GNN solver employs a relaxation strategy, an artificial transformation from the continuous space back to the original discrete space is necessary after learning, potentially undermining the robustness of the solutions. This paper numerically demonstrates that the PI-GNN solver can be trapped in a local solution, where all variables are zero, in the early stage of learning for CO problems on the dense graphs. Then, we address these problems by controlling the continuity and discreteness of rela
&lt;/p&gt;</description></item><item><title>&#26080;&#30417;&#30563;&#30340;&#23545;&#27604;&#19968;&#33268;&#25490;&#24207;&#19982;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#21463;&#36923;&#36753;&#32422;&#26463;&#24341;&#23548;&#30340;&#25506;&#27979;&#27169;&#22411;&#65292;&#23454;&#29616;&#22312;&#22810;&#20010;&#35821;&#21477;&#20013;&#22987;&#32456;&#26144;&#23556;&#21040;&#23545;&#27604;&#30340;&#30495;-&#20551;&#26497;&#28857;&#30340;&#25490;&#24207;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2309.06991</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#23545;&#27604;&#19968;&#33268;&#25490;&#24207;&#19982;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Contrast-Consistent Ranking with Language Models. (arXiv:2309.06991v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06991
&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#23545;&#27604;&#19968;&#33268;&#25490;&#24207;&#19982;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#21463;&#36923;&#36753;&#32422;&#26463;&#24341;&#23548;&#30340;&#25506;&#27979;&#27169;&#22411;&#65292;&#23454;&#29616;&#22312;&#22810;&#20010;&#35821;&#21477;&#20013;&#22987;&#32456;&#26144;&#23556;&#21040;&#23545;&#27604;&#30340;&#30495;-&#20551;&#26497;&#28857;&#30340;&#25490;&#24207;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#21253;&#21547;&#22522;&#20110;&#25490;&#24207;&#30340;&#30693;&#35782;&#65292;&#24182;&#19988;&#26159;&#22788;&#29702;&#19978;&#19979;&#25991;&#25490;&#21517;&#20219;&#21153;&#30340;&#24378;&#22823;&#35299;&#20915;&#32773;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20851;&#27880;&#20110;&#37197;&#23545;&#12289;&#28857;&#23545;&#21644;&#21015;&#34920;&#25552;&#31034;&#25216;&#26415;&#65292;&#20197;&#25581;&#31034;&#35821;&#35328;&#27169;&#22411;&#30340;&#25490;&#24207;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#21363;&#20351;&#22312;&#20180;&#32454;&#26657;&#20934;&#21644;&#38480;&#21046;&#35299;&#30721;&#30340;&#24773;&#20917;&#19979;&#65292;&#22522;&#20110;&#25552;&#31034;&#30340;&#25216;&#26415;&#22312;&#20135;&#29983;&#30340;&#25490;&#24207;&#20013;&#20063;&#19981;&#24635;&#26159;&#33258;&#27965;&#30340;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#25506;&#32034;&#19968;&#31181;&#21463;&#26080;&#30417;&#30563;&#25506;&#27979;&#26041;&#27861;Contrast-Consistent Search&#65288;CCS&#65289;&#21551;&#21457;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#36825;&#20010;&#24819;&#27861;&#26159;&#35757;&#32451;&#19968;&#20010;&#21463;&#36923;&#36753;&#32422;&#26463;&#24341;&#23548;&#30340;&#25506;&#27979;&#27169;&#22411;&#65306;&#27169;&#22411;&#23545;&#19968;&#20010;&#35821;&#21477;&#21450;&#20854;&#21542;&#23450;&#30340;&#34920;&#31034;&#24517;&#39035;&#22312;&#22810;&#20010;&#35821;&#21477;&#20013;&#22987;&#32456;&#26144;&#23556;&#21040;&#23545;&#27604;&#30340;&#30495;-&#20551;&#26497;&#28857;&#12290;&#25105;&#20204;&#20551;&#35774;&#31867;&#20284;&#30340;&#32422;&#26463;&#36866;&#29992;&#20110;&#25152;&#26377;&#39033;&#36890;&#36807;&#19968;&#33268;&#24615;&#23545;&#30456;&#20851;&#25490;&#24207;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks. For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank reviews by sentiment. Recent work focuses on pairwise, pointwise, and listwise prompting techniques to elicit a language model's ranking knowledge. However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce. This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS). The idea is to train a probing model guided by a logical constraint: a model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements. We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent pair
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#21487;&#20197;&#25581;&#31034;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#20013;&#35774;&#35745;&#20915;&#31574;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2308.16681</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65306;&#19968;&#20999;&#65292;&#26080;&#22788;&#19981;&#22312;&#65292;&#20840;&#26041;&#20301;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness. (arXiv:2308.16681v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16681
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#21487;&#20197;&#25581;&#31034;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#20013;&#35774;&#35745;&#20915;&#31574;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#29699;&#33539;&#22260;&#20869;&#30340;&#35768;&#22810;&#31995;&#32479;&#37117;&#21033;&#29992;&#31639;&#27861;&#20915;&#31574;&#26469;&#65288;&#37096;&#20998;&#65289;&#33258;&#21160;&#21270;&#20197;&#21069;&#30001;&#20154;&#31867;&#36827;&#34892;&#30340;&#20915;&#31574;&#12290;&#24403;&#35774;&#35745;&#33391;&#22909;&#26102;&#65292;&#36825;&#20123;&#31995;&#32479;&#25215;&#35834;&#26356;&#23458;&#35266;&#30340;&#20915;&#31574;&#65292;&#21516;&#26102;&#33410;&#30465;&#22823;&#37327;&#36164;&#28304;&#65292;&#33410;&#32422;&#20154;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#35774;&#35745;&#19981;&#33391;&#26102;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#23545;&#31038;&#20250;&#32676;&#20307;&#36827;&#34892;&#27495;&#35270;&#30340;&#19981;&#20844;&#24179;&#20915;&#31574;&#12290;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#30340;&#19979;&#28216;&#25928;&#24212;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#31995;&#32479;&#35774;&#35745;&#21644;&#23454;&#26045;&#36807;&#31243;&#20013;&#30340;&#20915;&#31574;&#65292;&#22240;&#20026;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#21487;&#33021;&#20250;&#22312;&#24314;&#27169;&#36807;&#31243;&#20013;&#32531;&#35299;&#25110;&#21152;&#24378;&#12290;&#35768;&#22810;&#36825;&#20123;&#35774;&#35745;&#20915;&#31574;&#26159;&#38544;&#21547;&#36827;&#34892;&#30340;&#65292;&#19981;&#30693;&#36947;&#23427;&#20204;&#30830;&#20999;&#22320;&#22914;&#20309;&#24433;&#21709;&#26368;&#32456;&#31995;&#32479;&#12290;&#22240;&#27492;&#65292;&#26126;&#30830;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#35774;&#35745;&#20013;&#30340;&#20915;&#31574;&#24182;&#20102;&#35299;&#36825;&#20123;&#20915;&#31574;&#22914;&#20309;&#24433;&#21709;&#32467;&#26524;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#38750;&#24120;&#37325;&#35201;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#24515;&#29702;&#23398;&#39046;&#22495;&#30340;&#35265;&#35299;&#65292;&#24182;&#24341;&#20837;&#20102;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A vast number of systems across the world use algorithmic decision making (ADM) to (partially) automate decisions that have previously been made by humans. When designed well, these systems promise more objective decisions while saving large amounts of resources and freeing up human time. However, when ADM systems are not designed well, they can lead to unfair decisions which discriminate against societal groups. The downstream effects of ADMs critically depend on the decisions made during the systems' design and implementation, as biases in data can be mitigated or reinforced along the modeling pipeline. Many of these design decisions are made implicitly, without knowing exactly how they will influence the final system. It is therefore important to make explicit the decisions made during the design of ADM systems and understand how these decisions affect the fairness of the resulting system.  To study this issue, we draw on insights from the field of psychology and introduce the metho
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#36335;&#24452;&#30456;&#20851;&#30340;NJ-ODE&#26041;&#27861;&#25193;&#23637;&#21040;&#20855;&#26377;&#22122;&#22768;&#35266;&#27979;&#21644;&#30456;&#20851;&#35266;&#27979;&#26694;&#26550;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#35777;&#31034;&#20363;&#12290;</title><link>http://arxiv.org/abs/2307.13147</link><description>&lt;p&gt;
&#23558;&#36335;&#24452;&#30456;&#20851;&#30340;NJ-ODE&#25193;&#23637;&#21040;&#26377;&#22122;&#22768;&#30340;&#35266;&#27979;&#21644;&#30456;&#20851;&#35266;&#27979;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Extending Path-Dependent NJ-ODEs to Noisy Observations and a Dependent Observation Framework. (arXiv:2307.13147v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13147
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#36335;&#24452;&#30456;&#20851;&#30340;NJ-ODE&#26041;&#27861;&#25193;&#23637;&#21040;&#20855;&#26377;&#22122;&#22768;&#35266;&#27979;&#21644;&#30456;&#20851;&#35266;&#27979;&#26694;&#26550;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#35777;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36335;&#24452;&#30456;&#20851;&#30340;&#31070;&#32463;&#36339;&#36291;ODE (PD-NJ-ODE) &#26159;&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#20855;&#26377;&#19981;&#35268;&#21017;&#21644;&#19981;&#23436;&#25972;&#35266;&#27979;&#30340;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#36807;&#31243;&#30340;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23398;&#20064;&#32473;&#23450;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#19981;&#23436;&#25972;&#36807;&#21435;&#35266;&#27979;&#30340;&#26368;&#20248;&#39044;&#27979;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#20551;&#35774;&#36807;&#31243;&#26412;&#36523;&#21644;&#22352;&#26631;&#20998;&#21035;&#35266;&#27979;&#26102;&#38388;&#26159;&#29420;&#31435;&#30340;&#65292;&#24182;&#19988;&#20551;&#35774;&#35266;&#27979;&#26159;&#26080;&#22122;&#22768;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20004;&#31181;&#25193;&#23637;&#26469;&#35299;&#38500;&#36825;&#20123;&#38480;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#20197;&#21450;&#23427;&#20204;&#30340;&#23454;&#35777;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Path-Dependent Neural Jump ODE (PD-NJ-ODE) is a model for predicting continuous-time stochastic processes with irregular and incomplete observations. In particular, the method learns optimal forecasts given irregularly sampled time series of incomplete past observations. So far the process itself and the coordinate-wise observation times were assumed to be independent and observations were assumed to be noiseless. In this work we discuss two extensions to lift these restrictions and provide theoretical guarantees as well as empirical examples for them.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.12971</link><description>&lt;p&gt;
&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#30340;&#39044;&#27979;&#65306;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#31995;&#32479;&#22320;&#35782;&#21035;&#21644;&#27604;&#36739;&#20998;&#26512;&#26368;&#20808;&#36827;&#30340;&#20379;&#24212;&#38142;&#39044;&#27979;&#31574;&#30053;&#21644;&#25216;&#26415;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#22823;&#25968;&#25454;&#20998;&#26512;&#24212;&#29992;&#20110;&#20379;&#24212;&#38142;&#31649;&#29702;&#20013;&#65292;&#21253;&#25324;&#38382;&#39064;&#35782;&#21035;&#12289;&#25968;&#25454;&#26469;&#28304;&#12289;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12289;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12289;&#36229;&#21442;&#25968;&#35843;&#20248;&#12289;&#24615;&#33021;&#35780;&#20272;&#21644;&#20248;&#21270;&#65292;&#20197;&#21450;&#39044;&#27979;&#23545;&#20154;&#21147;&#12289;&#24211;&#23384;&#21644;&#25972;&#20010;&#20379;&#24212;&#38142;&#30340;&#24433;&#21709;&#12290;&#39318;&#20808;&#35752;&#35770;&#20102;&#26681;&#25454;&#20379;&#24212;&#38142;&#31574;&#30053;&#25910;&#38598;&#25968;&#25454;&#30340;&#38656;&#27714;&#20197;&#21450;&#22914;&#20309;&#25910;&#38598;&#25968;&#25454;&#12290;&#25991;&#31456;&#35752;&#35770;&#20102;&#26681;&#25454;&#21608;&#26399;&#25110;&#20379;&#24212;&#38142;&#30446;&#26631;&#38656;&#35201;&#19981;&#21516;&#31867;&#22411;&#30340;&#39044;&#27979;&#12290;&#25512;&#33616;&#20351;&#29992;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#21644;&#35823;&#24046;&#27979;&#37327;&#31995;&#32479;&#26469;&#20248;&#21270;&#34920;&#29616;&#26368;&#20339;&#30340;&#27169;&#22411;&#12290;&#36824;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#20197;&#21450;&#31649;&#29702;&#20915;&#31574;&#20381;&#36182;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#26469;&#30830;&#23450;&#27169;&#22411;&#24615;&#33021;&#21442;&#25968;&#21644;&#25913;&#36827;&#36816;&#33829;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and 
&lt;/p&gt;</description></item><item><title>R-Learning&#22312;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#26102;&#37319;&#29992;&#20102;&#36870;&#21464;&#25968;&#21152;&#26435;&#30340;&#24418;&#24335;&#26469;&#31283;&#23450;&#22238;&#24402;&#65292;&#24182;&#31616;&#21270;&#20102;&#20559;&#24046;&#39033;&#12290;</title><link>http://arxiv.org/abs/2307.09700</link><description>&lt;p&gt;
R-Learning&#19982;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#30340;&#36870;&#21464;&#25968;&#21152;&#26435;&#30340;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
The Connection Between R-Learning and Inverse-Variance Weighting for Estimation of Heterogeneous Treatment Effects. (arXiv:2307.09700v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09700
&lt;/p&gt;
&lt;p&gt;
R-Learning&#22312;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#26102;&#37319;&#29992;&#20102;&#36870;&#21464;&#25968;&#21152;&#26435;&#30340;&#24418;&#24335;&#26469;&#31283;&#23450;&#22238;&#24402;&#65292;&#24182;&#31616;&#21270;&#20102;&#20559;&#24046;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#21160;&#26426;&#26159;&#20026;&#20102;&#25506;&#35752;&#24191;&#27867;&#27969;&#34892;&#30340;&#8220;R-Learner&#8221;&#30340;&#24615;&#33021;&#12290;&#20687;&#20854;&#20182;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#65288;CATEs&#65289;&#30340;&#26041;&#27861;&#19968;&#26679;&#65292;R-Learning&#21487;&#20197;&#34920;&#31034;&#20026;&#21152;&#26435;&#20266;&#32467;&#26524;&#22238;&#24402;&#65288;POR&#65289;&#12290;&#20808;&#21069;&#23545;POR&#25216;&#26415;&#30340;&#27604;&#36739;&#24050;&#32463;&#20180;&#32454;&#27880;&#24847;&#20102;&#20266;&#32467;&#26524;&#36716;&#25442;&#30340;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35748;&#20026;&#24615;&#33021;&#30340;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#23454;&#38469;&#19978;&#26159;&#26435;&#37325;&#30340;&#36873;&#25321;&#12290;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#35748;&#20026;R-Learning&#38544;&#24335;&#22320;&#25191;&#34892;&#20102;&#21152;&#26435;&#24418;&#24335;&#30340;POR&#65292;&#20854;&#20013;&#26435;&#37325;&#31283;&#23450;&#20102;&#22238;&#24402;&#65292;&#24182;&#20801;&#35768;&#23545;&#20559;&#24046;&#39033;&#36827;&#34892;&#26041;&#20415;&#30340;&#31616;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our motivation is to shed light the performance of the widely popular "R-Learner." Like many other methods for estimating conditional average treatment effects (CATEs), R-Learning can be expressed as a weighted pseudo-outcome regression (POR). Previous comparisons of POR techniques have paid careful attention to the choice of pseudo-outcome transformation. However, we argue that the dominant driver of performance is actually the choice of weights. Specifically, we argue that R-Learning implicitly performs an inverse-variance weighted form of POR. These weights stabilize the regression and allow for convenient simplifications of bias terms.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#24555;&#36895;&#30340;&#32463;&#39564;&#22330;&#26223;&#25552;&#21462;&#31639;&#27861;&#65292;&#19968;&#31181;&#35782;&#21035;&#20043;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#22330;&#26223;&#24182;&#25552;&#20379;&#22330;&#26223;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#34920;&#31034;&#65292;&#21478;&#19968;&#31181;&#20174;&#24050;&#23454;&#29616;&#30340;&#19990;&#30028;&#29366;&#24577;&#20013;&#36873;&#25321;&#37325;&#35201;&#30340;&#25968;&#25454;&#28857;&#65292;&#24182;&#19982;&#39640;&#38454;&#26679;&#26412;&#30697;&#19968;&#33268;&#65292;&#36825;&#20123;&#31639;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#36866;&#29992;&#20110;&#19968;&#33268;&#30340;&#22522;&#20110;&#22330;&#26223;&#30340;&#24314;&#27169;&#21644;&#39640;&#32500;&#25968;&#20540;&#31215;&#20998;&#12290;</title><link>http://arxiv.org/abs/2307.03927</link><description>&lt;p&gt;
&#24555;&#36895;&#32463;&#39564;&#22330;&#26223;
&lt;/p&gt;
&lt;p&gt;
Fast Empirical Scenarios. (arXiv:2307.03927v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03927
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#24555;&#36895;&#30340;&#32463;&#39564;&#22330;&#26223;&#25552;&#21462;&#31639;&#27861;&#65292;&#19968;&#31181;&#35782;&#21035;&#20043;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#22330;&#26223;&#24182;&#25552;&#20379;&#22330;&#26223;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#34920;&#31034;&#65292;&#21478;&#19968;&#31181;&#20174;&#24050;&#23454;&#29616;&#30340;&#19990;&#30028;&#29366;&#24577;&#20013;&#36873;&#25321;&#37325;&#35201;&#30340;&#25968;&#25454;&#28857;&#65292;&#24182;&#19982;&#39640;&#38454;&#26679;&#26412;&#30697;&#19968;&#33268;&#65292;&#36825;&#20123;&#31639;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#36866;&#29992;&#20110;&#19968;&#33268;&#30340;&#22522;&#20110;&#22330;&#26223;&#30340;&#24314;&#27169;&#21644;&#39640;&#32500;&#25968;&#20540;&#31215;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24076;&#26395;&#20174;&#22823;&#22411;&#21644;&#39640;&#32500;&#38754;&#26495;&#25968;&#25454;&#20013;&#25552;&#21462;&#19968;&#23567;&#37096;&#20998;&#19982;&#26679;&#26412;&#30697;&#19968;&#33268;&#30340;&#20195;&#34920;&#24615;&#22330;&#26223;&#12290;&#22312;&#20004;&#31181;&#26032;&#31639;&#27861;&#20013;&#65292;&#31532;&#19968;&#31181;&#31639;&#27861;&#35782;&#21035;&#20043;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#22330;&#26223;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#22330;&#26223;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#34920;&#31034;&#12290;&#31532;&#20108;&#31181;&#31639;&#27861;&#20174;&#24050;&#23454;&#29616;&#30340;&#19990;&#30028;&#29366;&#24577;&#20013;&#36873;&#25321;&#37325;&#35201;&#30340;&#25968;&#25454;&#28857;&#65292;&#24182;&#19982;&#39640;&#38454;&#26679;&#26412;&#30697;&#20449;&#24687;&#19968;&#33268;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#21487;&#29992;&#20110;&#19968;&#33268;&#30340;&#22522;&#20110;&#22330;&#26223;&#30340;&#24314;&#27169;&#21644;&#39640;&#32500;&#25968;&#20540;&#31215;&#20998;&#12290;&#24191;&#27867;&#30340;&#25968;&#20540;&#22522;&#20934;&#27979;&#35797;&#30740;&#31350;&#21644;&#22312;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;&#25903;&#25345;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We seek to extract a small number of representative scenarios from large and high-dimensional panel data that are consistent with sample moments. Among two novel algorithms, the first identifies scenarios that have not been observed before, and comes with a scenario-based representation of covariance matrices. The second proposal picks important data points from states of the world that have already realized, and are consistent with higher-order sample moment information. Both algorithms are efficient to compute, and lend themselves to consistent scenario-based modeling and high-dimensional numerical integration. Extensive numerical benchmarking studies and an application in portfolio optimization favor the proposed algorithms.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#26041;&#27861;&#65288;GGS&#65289;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#65292;&#28040;&#38500;&#20102;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#25628;&#32034;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#22312;&#21457;&#29616;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2307.00494</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimizing protein fitness using Gibbs sampling with Graph-based Smoothing. (arXiv:2307.00494v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00494
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#26041;&#27861;&#65288;GGS&#65289;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#65292;&#28040;&#38500;&#20102;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#25628;&#32034;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#22312;&#21457;&#29616;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#35774;&#35745;&#20986;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#20855;&#26377;&#26356;&#39640;&#36866;&#24212;&#24615;&#30340;&#26032;&#22411;&#34507;&#30333;&#36136;&#23545;&#35768;&#22810;&#21307;&#23398;&#39046;&#22495;&#26469;&#35828;&#37117;&#26159;&#38761;&#21629;&#24615;&#30340;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#31351;&#20030;&#25628;&#32034;&#28023;&#37327;&#24207;&#21015;&#31354;&#38388;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20197;&#21069;&#30340;&#26041;&#27861;&#23558;&#25628;&#32034;&#38480;&#21046;&#22312;&#20174;&#21442;&#32771;&#24207;&#21015;&#30340;&#23567;&#31361;&#21464;&#21322;&#24452;&#33539;&#22260;&#20869;&#65292;&#20294;&#36825;&#26679;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#26497;&#22823;&#22320;&#38480;&#21046;&#20102;&#35774;&#35745;&#31354;&#38388;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26088;&#22312;&#28040;&#38500;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#25928;&#30340;&#25506;&#32034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#65288;GGS&#65289;&#65292;&#23427;&#36890;&#36807;&#36845;&#20195;&#24212;&#29992;&#24102;&#26377;&#26799;&#24230;&#30340;Gibbs&#26469;&#25552;&#20986;&#26377;&#21033;&#30340;&#31361;&#21464;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;&#26041;&#27861;&#21435;&#38500;&#23548;&#33268;&#20551;&#38451;&#24615;&#30340;&#22122;&#22768;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;&#38598;&#20013;&#21457;&#29616;&#20102;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#65292;&#26368;&#22810;&#20855;&#26377;8&#20010;&#31361;&#21464;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;GFP&#21644;AAV&#35774;&#35745;&#38382;&#39064;&#12289;&#28040;&#34701;&#35797;&#39564;&#21644;&#22522;&#20934;&#27169;&#22411;&#26469;&#38416;&#26126;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to design novel proteins with higher fitness on a given task would be revolutionary for many fields of medicine. However, brute-force search through the combinatorially large space of sequences is infeasible. Prior methods constrain search to a small mutational radius from a reference sequence, but such heuristics drastically limit the design space. Our work seeks to remove the restriction on mutational distance while enabling efficient exploration. We propose Gibbs sampling with Graph-based Smoothing (GGS) which iteratively applies Gibbs with gradients to propose advantageous mutations using graph-based smoothing to remove noisy gradients that lead to false positives. Our method is state-of-the-art in discovering high-fitness proteins with up to 8 mutations from the training set. We study the GFP and AAV design problems, ablations, and baselines to elucidate the results. Code: https://github.com/kirjner/GGS
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#38556;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#21463;&#38544;&#31169;&#32422;&#26463;&#19988;&#26377;&#38480;&#26631;&#35760;&#25968;&#25454;&#26465;&#20214;&#19979;&#65292;&#20174;&#20844;&#24320;&#28304;&#39046;&#22495;&#21040;&#30446;&#26631;&#39046;&#22495;&#36827;&#34892;&#30417;&#30563;&#22495;&#33258;&#36866;&#24212;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#35299;&#20915;&#19968;&#33324;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#26377;&#21033;&#30340;&#29702;&#35770;&#23398;&#20064;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.08838</link><description>&lt;p&gt;
&#20855;&#26377;&#29702;&#35770;&#20445;&#38556;&#30340;&#24046;&#20998;&#38544;&#31169;&#22495;&#33258;&#36866;&#24212;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Domain Adaptation with Theoretical Guarantees. (arXiv:2306.08838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08838
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#38556;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#21463;&#38544;&#31169;&#32422;&#26463;&#19988;&#26377;&#38480;&#26631;&#35760;&#25968;&#25454;&#26465;&#20214;&#19979;&#65292;&#20174;&#20844;&#24320;&#28304;&#39046;&#22495;&#21040;&#30446;&#26631;&#39046;&#22495;&#36827;&#34892;&#30417;&#30563;&#22495;&#33258;&#36866;&#24212;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#35299;&#20915;&#19968;&#33324;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#26377;&#21033;&#30340;&#29702;&#35770;&#23398;&#20064;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#23398;&#20064;&#32773;&#21487;&#29992;&#30340;&#26631;&#35760;&#25968;&#25454;&#21463;&#21040;&#38544;&#31169;&#32422;&#26463;&#24182;&#30456;&#23545;&#26377;&#38480;&#12290;&#20026;&#20102;&#20026;&#30446;&#26631;&#39046;&#22495;&#23548;&#20986;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#22120;&#65292;&#36890;&#24120;&#26377;&#21033;&#20110;&#21033;&#29992;&#26469;&#33258;&#19982;&#30446;&#26631;&#39046;&#22495;&#30456;&#36817;&#30340;&#21478;&#19968;&#39046;&#22495;&#30340;&#20844;&#24320;&#26631;&#35760;&#25968;&#25454;&#12290;&#36825;&#26159;&#20174;&#20844;&#20849;&#28304;&#39046;&#22495;&#21040;&#31169;&#26377;&#30446;&#26631;&#39046;&#22495;&#30340;&#29616;&#20195;&#30417;&#30563;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181; $(\epsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#30417;&#30563;&#24615;&#33258;&#36866;&#24212;&#12290;&#23545;&#20110;&#20854;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#33324;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#20248;&#21270;&#38382;&#39064;&#26368;&#36817;&#34987;&#35777;&#26126;&#20855;&#26377;&#26377;&#21033;&#30340;&#29702;&#35770;&#23398;&#20064;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;&#26159;&#20026;&#20855;&#26377;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#22238;&#24402;&#35774;&#35745;&#30340;&#65292;&#24182;&#26174;&#31034;&#20026;&#35299;&#20915;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#31639;&#27861;&#26159;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#21487;&#33021;&#26159;&#38750;&#20984;&#20294;Lipschitz&#21644;&#24179;&#28369;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#20294;&#25105;&#20204;&#20063;&#25253;&#21578;&#20102;&#20960;&#20010;&#23454;&#39564;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many applications, the labeled data at the learner's disposal is subject to privacy constraints and is relatively limited. To derive a more accurate predictor for the target domain, it is often beneficial to leverage publicly available labeled data from an alternative domain, somewhat close to the target domain. This is the modern problem of supervised domain adaptation from a public source to a private target domain. We present two $(\epsilon, \delta)$-differentially private adaptation algorithms for supervised adaptation, for which we make use of a general optimization problem, recently shown to benefit from favorable theoretical learning guarantees. Our first algorithm is designed for regression with linear predictors and shown to solve a convex optimization problem. Our second algorithm is a more general solution for loss functions that may be non-convex but Lipschitz and smooth. While our main objective is a theoretical analysis, we also report the results of several experiment
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#22823;&#35268;&#27169;&#23494;&#38598;&#38543;&#26426;Kronecker&#22270;&#36827;&#34892;&#20102;&#20998;&#26512;&#21644;&#36817;&#20284;&#25512;&#26029;&#65292;&#25552;&#20986;&#20102;&#8220;&#21435;&#22122;&#22768;&#21644;&#27714;&#35299;&#8221;&#20803;&#31639;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#25512;&#26029;&#22270;&#21442;&#25968;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#24615;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.08489</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#23494;&#38598;&#38543;&#26426;Kronecker&#22270;&#30340;&#20998;&#26512;&#21644;&#36817;&#20284;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Analysis and Approximate Inference of Large and Dense Random Kronecker Graphs. (arXiv:2306.08489v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08489
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#22823;&#35268;&#27169;&#23494;&#38598;&#38543;&#26426;Kronecker&#22270;&#36827;&#34892;&#20102;&#20998;&#26512;&#21644;&#36817;&#20284;&#25512;&#26029;&#65292;&#25552;&#20986;&#20102;&#8220;&#21435;&#22122;&#22768;&#21644;&#27714;&#35299;&#8221;&#20803;&#31639;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#25512;&#26029;&#22270;&#21442;&#25968;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22270;&#27169;&#22411;&#22312;&#31185;&#23398;&#21644;&#24037;&#19994;&#20013;&#21457;&#25381;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#24182;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#24471;&#21040;&#24212;&#29992;&#65292;&#21253;&#25324;&#31038;&#20132;&#21644;&#20132;&#36890;&#32593;&#32476;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#20998;&#23376;&#36951;&#20256;&#23398;&#12290;&#26412;&#25991;&#23545;\cite{leskovec2010kronecker}&#20013;&#25552;&#20986;&#30340;&#38543;&#26426;Kronecker&#22270;&#27169;&#22411;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#65292;&#24403;&#22270;&#39030;&#28857;&#25968;&#37327;$N$&#24456;&#22823;&#26102;&#12290;&#22522;&#20110;&#26368;&#36817;&#22312;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#23494;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;Kronecker&#22270;&#37051;&#25509;&#30697;&#38453;&#36817;&#20284;&#36981;&#24490;&#19968;&#20010;&#20449;&#21495;&#21152;&#22122;&#22768;&#27169;&#22411;&#65292;&#20854;&#20013;&#20449;&#21495;&#30697;&#38453;&#30340;&#31209;&#24456;&#23567;&#65288;&#26368;&#22810;&#20026;$\log N$&#38454;&#65289;&#65292;&#22312;&#22270;&#21442;&#25968;&#20013;&#26159;&#32447;&#24615;&#30340;&#65292;&#32780;&#38543;&#26426;&#30340;&#22122;&#22768;&#30697;&#38453;&#20855;&#26377;&#22235;&#20998;&#20043;&#19968;&#22278;&#24418;&#22855;&#24322;&#20540;&#20998;&#24067;&#12290;&#36825;&#20010;&#35266;&#23519;&#20801;&#35768;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#21435;&#22122;&#22768;&#21644;&#27714;&#35299;&#8221;&#20803;&#31639;&#27861;&#26469;&#36817;&#20284;&#25512;&#26029;&#22270;&#21442;&#25968;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#65288;&#28176;&#36817;&#30340;&#65289;&#24615;&#33021;&#20445;&#35777;&#12290;&#36890;&#36807;&#22270;i&#30340;&#25968;&#20540;&#23454;&#39564;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random graph models are playing an increasingly important role in science and industry, and finds their applications in a variety of fields ranging from social and traffic networks, to recommendation systems and molecular genetics. In this paper, we perform an in-depth analysis of the random Kronecker graph model proposed in \cite{leskovec2010kronecker}, when the number of graph vertices $N$ is large. Built upon recent advances in random matrix theory, we show, in the dense regime, that the random Kronecker graph adjacency matrix follows approximately a signal-plus-noise model, with a small-rank (of order at most $\log N$) signal matrix that is linear in the graph parameters and a random noise matrix having a quarter-circle-form singular value distribution. This observation allows us to propose a ``denoise-and-solve'' meta algorithm to approximately infer the graph parameters, with reduced computational complexity and (asymptotic) performance guarantee. Numerical experiments of graph i
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#35266;&#27979;&#20559;&#24046;&#26469;&#25913;&#36827;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#20010;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#19982;&#23545;&#26410;&#35266;&#27979;&#21327;&#21464;&#37327;&#30340;&#30417;&#30563;&#23398;&#20064;&#24615;&#33021;&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.04775</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#20559;&#24046;&#25552;&#39640;&#30697;&#38453;&#34917;&#20840;&#30340;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exploiting Observation Bias to Improve Matrix Completion. (arXiv:2306.04775v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#35266;&#27979;&#20559;&#24046;&#26469;&#25913;&#36827;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#20010;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#19982;&#23545;&#26410;&#35266;&#27979;&#21327;&#21464;&#37327;&#30340;&#30417;&#30563;&#23398;&#20064;&#24615;&#33021;&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#21464;&#24418;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#65292;&#20854;&#20013;&#36755;&#20837;&#25968;&#25454;&#20197;&#20559;&#24046;&#30340;&#26041;&#24335;&#21576;&#29616;&#65292;&#31867;&#20284;&#20110;Ma&#21644;Chen&#25152;&#24341;&#20837;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#21033;&#29992;&#20559;&#24046;&#19982;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#20043;&#38388;&#30340;&#20849;&#20139;&#20449;&#24687;&#26469;&#25913;&#36827;&#39044;&#27979;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65306;&#65288;i&#65289;&#23558;&#35266;&#27979;&#27169;&#24335;&#35299;&#37322;&#20026;&#23436;&#20840;&#35266;&#27979;&#30340;&#22122;&#22768;&#30697;&#38453;&#65292;&#25105;&#20204;&#23545;&#35266;&#27979;&#27169;&#24335;&#24212;&#29992;&#20256;&#32479;&#30340;&#30697;&#38453;&#34917;&#20840;&#26041;&#27861;&#26469;&#20272;&#35745;&#28508;&#22312;&#22240;&#32032;&#20043;&#38388;&#30340;&#36317;&#31163;&#65307; (ii)&#25105;&#20204;&#23545;&#24674;&#22797;&#30340;&#29305;&#24449;&#24212;&#29992;&#30417;&#30563;&#23398;&#20064;&#26469;&#22635;&#34917;&#32570;&#22833;&#35266;&#23519;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#29575;&#65292;&#36825;&#20123;&#35823;&#24046;&#29575;&#19982;&#30456;&#24212;&#30340;&#30417;&#30563;&#23398;&#20064;&#21442;&#25968;&#29575;&#30456;&#31454;&#20105;&#65292;&#36825;&#34920;&#26126;&#25105;&#20204;&#30340;&#23398;&#20064;&#24615;&#33021;&#19982;&#20351;&#29992;&#26410;&#35266;&#27979;&#21327;&#21464;&#37327;&#30456;&#24403;&#12290;&#23454;&#35777;&#35780;&#20272;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#21453;&#26144;&#20102;&#31867;&#20284;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a variant of matrix completion where entries are revealed in a biased manner, adopting a model akin to that introduced by Ma and Chen. Instead of treating this observation bias as a disadvantage, as is typically the case, our goal is to exploit the shared information between the bias and the outcome of interest to improve predictions. Towards this, we propose a simple two-stage algorithm: (i) interpreting the observation pattern as a fully observed noisy matrix, we apply traditional matrix completion methods to the observation pattern to estimate the distances between the latent factors; (ii) we apply supervised learning on the recovered features to impute missing observations. We establish finite-sample error rates that are competitive with the corresponding supervised learning parametric rates, suggesting that our learning performance is comparable to having access to the unobserved covariates. Empirical evaluation using a real-world dataset reflects similar performance g
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;Equity-Transformer&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#65292;&#24182;&#29983;&#25104;&#32771;&#34385;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;&#30740;&#31350;&#26174;&#31034;&#65292;Equity-Transformer&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02689</link><description>&lt;p&gt;
&#23558;NP&#22256;&#38590;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20316;&#20026;&#20855;&#26377;&#20844;&#24179;&#32972;&#26223;&#30340;&#39034;&#24207;&#29983;&#25104;&#26469;&#35299;&#20915;
&lt;/p&gt;
&lt;p&gt;
Solving NP-hard Min-max Routing Problems as Sequential Generation with Equity Context. (arXiv:2306.02689v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;Equity-Transformer&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#65292;&#24182;&#29983;&#25104;&#32771;&#34385;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;&#30740;&#31350;&#26174;&#31034;&#65292;Equity-Transformer&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#26088;&#22312;&#26368;&#23567;&#21270;&#25152;&#26377;&#20195;&#29702;&#21830;&#21327;&#21516;&#35775;&#38382;&#25152;&#26377;&#22478;&#24066;&#30340;&#26368;&#22823;&#26053;&#28216;&#38271;&#24230;&#65292;&#21363;&#23436;&#25104;&#26102;&#38388;&#12290;&#36825;&#20123;&#38382;&#39064;&#21253;&#25324;&#26377;&#24433;&#21709;&#21147;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#34987;&#35748;&#20026;&#26159;NP&#22256;&#38590;&#30340;&#12290;&#29616;&#26377;&#26041;&#27861;&#38754;&#20020;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#38656;&#35201;&#21327;&#35843;&#20247;&#22810;&#20195;&#29702;&#21830;&#35206;&#30422;&#25968;&#21315;&#20010;&#22478;&#24066;&#30340;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#22810;&#20010;&#20195;&#29702;&#21830;&#30340;&#21516;&#26102;&#20915;&#31574;&#24314;&#27169;&#20026;&#39034;&#24207;&#29983;&#25104;&#36807;&#31243;&#65292;&#20801;&#35768;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#12290;&#22312;&#39034;&#24207;&#36817;&#20284;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#19978;&#19979;&#25991;Transformer&#27169;&#22411;Equity-Transformer&#65292;&#23427;&#29983;&#25104;&#32771;&#34385;&#20854;&#20182;&#20195;&#29702;&#21830;&#20043;&#38388;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;Equity-Transformer&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#20854;&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#24471;&#21040;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Min-max routing problems aim to minimize the maximum tour length among agents as they collaboratively visit all cities, i.e., the completion time. These problems include impactful real-world applications but are known as NP-hard. Existing methods are facing challenges, particularly in large-scale problems that require the coordination of numerous agents to cover thousands of cities. This paper proposes a new deep-learning framework to solve large-scale min-max routing problems. We model the simultaneous decision-making of multiple agents as a sequential generation process, allowing the utilization of scalable deep-learning models for sequential decision-making. In the sequentially approximated problem, we propose a scalable contextual Transformer model, Equity-Transformer, which generates sequential actions considering an equitable workload among other agents. The effectiveness of Equity-Transformer is demonstrated through its superior performance in two representative min-max routing 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#29616;&#26377;&#26041;&#27861;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#26080;&#28145;&#24230;&#20381;&#36182;&#24615;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.01992</link><description>&lt;p&gt;
&#20851;&#20110;ReLU&#32593;&#32476;&#30340;&#22823;&#23567;&#26080;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
On Size-Independent Sample Complexity of ReLU Networks. (arXiv:2306.01992v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#29616;&#26377;&#26041;&#27861;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#26080;&#28145;&#24230;&#20381;&#36182;&#24615;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#27867;&#21270;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#23398;&#20064;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#22312;&#26435;&#37325;&#30697;&#38453;&#19978;&#32473;&#23450;&#33539;&#25968;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#31867;&#30340;Rademacher&#22797;&#26434;&#24230;&#12290;&#20043;&#21069;Golowich-Rakhlin-Shamir (2020)&#33719;&#24471;&#20102;&#19968;&#20010;&#19981;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#65288;&#19982;Frobenius&#33539;&#25968;&#30340;&#20056;&#31215;&#25104;&#27604;&#20363;&#65289;&#19978;&#30028;&#65292;&#38500;&#20102;&#19968;&#20010;&#24179;&#26041;&#26681;&#28145;&#24230;&#30340;&#22240;&#23376;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#36890;&#24120;&#26681;&#26412;&#27809;&#26377;&#26126;&#26174;&#30340;&#28145;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the sample complexity of learning ReLU neural networks from the point of view of generalization. Given norm constraints on the weight matrices, a common approach is to estimate the Rademacher complexity of the associated function class. Previously Golowich-Rakhlin-Shamir (2020) obtained a bound independent of the network size (scaling with a product of Frobenius norms) except for a factor of the square-root depth. We give a refinement which often has no explicit depth-dependence at all.
&lt;/p&gt;</description></item><item><title>&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;, &#20854;&#23398;&#20064;&#26426;&#21046;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;</title><link>http://arxiv.org/abs/2306.01271</link><description>&lt;p&gt;
&#20026;&#20160;&#20040;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#20250;&#21516;&#26102;&#20986;&#29616;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#65311;
&lt;/p&gt;
&lt;p&gt;
Why Clean Generalization and Robust Overfitting Both Happen in Adversarial Training. (arXiv:2306.01271v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01271
&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;, &#20854;&#23398;&#20064;&#26426;&#21046;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#19982;&#22312;&#26631;&#20934;&#28145;&#24230;&#23398;&#20064;&#29615;&#22659;&#20013;&#20986;&#29616;&#24778;&#20154;&#30340;&#24178;&#20928;&#27867;&#21270;&#33021;&#21147;&#31867;&#20284;&#65292;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20063;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#21040;&#26410;&#35265;&#36807;&#30340;&#24178;&#20928;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#19982;&#24178;&#20928;&#27867;&#21270;&#19981;&#21516;&#30340;&#26159;&#65292;&#23613;&#31649;&#23545;&#25239;&#35757;&#32451;&#33021;&#22815;&#23454;&#29616;&#20302;&#40065;&#26834;&#35757;&#32451;&#35823;&#24046;&#65292;&#20173;&#23384;&#22312;&#26174;&#33879;&#30340;&#40065;&#26834;&#27867;&#21270;&#36317;&#31163;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#25506;&#32034;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#30340;&#26426;&#21046;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#36825;&#31181;&#29616;&#35937;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#25239;&#35757;&#32451;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#29305;&#24449;&#23398;&#20064;&#36807;&#31243;&#65292;&#35299;&#37322;&#20102;&#23545;&#25239;&#35757;&#32451;&#22914;&#20309;&#23548;&#33268;&#32593;&#32476;&#23398;&#20064;&#32773;&#36827;&#20837;&#21040;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29366;&#24577;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#36890;&#36807;&#36843;&#20351;&#23398;&#20064;&#22120;&#25104;&#20026;&#24378;&#39044;&#27979;&#32593;&#32476;&#65292;&#23545;&#25239;&#35757;&#32451;&#23558;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training is a standard method to train deep neural networks to be robust to adversarial perturbation. Similar to surprising $\textit{clean generalization}$ ability in the standard deep learning setting, neural networks trained by adversarial training also generalize well for $\textit{unseen clean data}$. However, in constrast with clean generalization, while adversarial training method is able to achieve low $\textit{robust training error}$, there still exists a significant $\textit{robust generalization gap}$, which promotes us exploring what mechanism leads to both $\textit{clean generalization and robust overfitting (CGRO)}$ during learning process. In this paper, we provide a theoretical understanding of this CGRO phenomenon in adversarial training. First, we propose a theoretical framework of adversarial training, where we analyze $\textit{feature learning process}$ to explain how adversarial training leads network learner to CGRO regime. Specifically, we prove that, u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2305.16905</link><description>&lt;p&gt;
&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65306;&#36125;&#21494;&#26031;&#25512;&#29702;&#25552;&#39640;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Laplace-Approximated Neural Additive Models: Improving Interpretability with Bayesian Inference. (arXiv:2305.16905v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#24212;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#40657;&#30418;&#24615;&#36136;&#38459;&#30861;&#20102;&#35299;&#37322;&#24615;&#12290;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;NAM&#65289;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#32593;&#32476;&#20998;&#20026;&#21152;&#24615;&#23376;&#32593;&#32476;&#65292;&#20174;&#32780;&#20351;&#36755;&#20837;&#29305;&#24449;&#21644;&#39044;&#27979;&#20043;&#38388;&#30340;&#20132;&#20114;&#21464;&#24471;&#26126;&#26174;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20197;&#19979;&#19977;&#20010;&#26041;&#38754;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#65306;a&#65289;&#23427;&#36890;&#36807;&#20272;&#35745;&#23376;&#32593;&#32476;&#30340;&#20989;&#25968;&#31354;&#38388;&#19981;&#30830;&#23450;&#24615;&#20026;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65307;b&#65289;&#23427;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#36807;&#31243;&#25191;&#34892;&#29305;&#24449;&#30340;&#38544;&#24335;&#36873;&#25321;&#65307;c&#65289;&#23427;&#21487;&#29992;&#20110;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#65292;&#20316;&#20026;&#31934;&#32454;&#35843;&#25972;&#30340;&#20132;&#20114;&#27169;&#22411;&#20505;&#36873;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#35777;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;LA-NAM&#65289;&#25552;&#39640;&#20102;NAM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#23398;&#20064;&#21040;&#30340;&#23376;&#32593;&#32476;&#30340;&#20132;&#20114;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) have found successful applications in many fields, but their black-box nature hinders interpretability. This is addressed by the neural additive model (NAM), in which the network is divided into additive sub-networks, thus making apparent the interaction between input features and predictions. In this paper, we approach the additive structure from a Bayesian perspective and develop a practical Laplace approximation. This enhances interpretability in three primary ways: a) It provides credible intervals for the recovered feature interactions by estimating function-space uncertainty of the sub-networks; b) it yields a tractable estimate of the marginal likelihood, which can be used to perform an implicit selection of features through an empirical Bayes procedure; and c) it can be used to rank feature pairs as candidates for second-order interactions in fine-tuned interaction models. We show empirically that our proposed Laplace-approximated NAM (LA-NAM) improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#20854;&#36890;&#36807;&#26367;&#25442;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#26174;&#30528;&#25552;&#39640;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#22343;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.16368</link><description>&lt;p&gt;
&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#65306;&#23398;&#20064;&#20849;&#36717;&#26799;&#24230;&#27861;&#30340;&#39044;&#22788;&#29702;&#22120;
&lt;/p&gt;
&lt;p&gt;
Neural incomplete factorization: learning preconditioners for the conjugate gradient method. (arXiv:2305.16368v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#20854;&#36890;&#36807;&#26367;&#25442;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#26174;&#30528;&#25552;&#39640;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#22343;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#29992;&#20110;&#21152;&#36895;&#31185;&#23398;&#35745;&#31639;&#21644;&#20248;&#21270;&#20013;&#36935;&#21040;&#30340;&#22823;&#35268;&#27169;&#32447;&#24615;&#26041;&#31243;&#32452;&#27714;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#36890;&#36807;&#26367;&#25442;&#19982;&#20849;&#36717;&#26799;&#24230;&#27861;&#19968;&#36215;&#20351;&#29992;&#30340;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#65288;&#31216;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#65289;&#26174;&#30528;&#21152;&#36895;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#21463;&#31232;&#30095;&#30697;&#38453;&#29702;&#35770;&#21551;&#21457;&#30340;&#26032;&#22411;&#28040;&#24687;&#20256;&#36882;&#22359;&#65292;&#23427;&#19982;&#23547;&#25214;&#30697;&#38453;&#30340;&#31232;&#30095;&#20998;&#35299;&#30340;&#30446;&#26631;&#30456;&#19968;&#33268;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#38382;&#39064;&#21644;&#26469;&#33258;&#31185;&#23398;&#35745;&#31639;&#30340;&#30495;&#23454;&#38382;&#39064;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#22987;&#32456;&#20248;&#20110;&#26368;&#24120;&#35265;&#30340;&#36890;&#29992;&#39044;&#22788;&#29702;&#22120;&#65292;&#21253;&#25324;&#19981;&#23436;&#20840;&#30340;Cholesky&#26041;&#27861;&#65292;&#22312;&#25910;&#25947;&#36895;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a novel data-driven approach to accelerate solving large-scale linear equation systems encountered in scientific computing and optimization. Our method utilizes self-supervised training of a graph neural network to generate an effective preconditioner tailored to the specific problem domain. By replacing conventional hand-crafted preconditioners used with the conjugate gradient method, our approach, named neural incomplete factorization (NeuralIF), significantly speeds-up convergence and computational efficiency. At the core of our method is a novel message-passing block, inspired by sparse matrix theory, that aligns with the objective to find a sparse factorization of the matrix. We evaluate our proposed method on both a synthetic and a real-world problem arising from scientific computing. Our results demonstrate that NeuralIF consistently outperforms the most common general-purpose preconditioners, including the incomplete Cholesky method, achieving competit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22987;&#32456;&#33021;&#22815;&#25104;&#21151;&#32763;&#36716;&#27979;&#35797;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#12289;&#35780;&#20272;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#31561;&#22810;&#37325;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.12809</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#26469;&#32763;&#36716;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Relabel Minimal Training Subset to Flip a Prediction. (arXiv:2305.12809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22987;&#32456;&#33021;&#22815;&#25104;&#21151;&#32763;&#36716;&#27979;&#35797;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#12289;&#35780;&#20272;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#31561;&#22810;&#37325;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Yang&#31561;&#20154;&#21457;&#29616;&#65292;&#20165;&#21024;&#38500;1%&#30340;&#35757;&#32451;&#25968;&#25454;&#23601;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#32467;&#26524;&#32763;&#36716;&#12290;&#37492;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#23384;&#22312;&#22122;&#22768;&#25968;&#25454;&#30340;&#26222;&#36941;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#22312;&#27169;&#22411;&#35757;&#32451;&#20043;&#21069;&#36890;&#36807;&#37325;&#26032;&#26631;&#35760;&#19968;&#20010;&#23567;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#21487;&#21542;&#23548;&#33268;&#27979;&#35797;&#32467;&#26524;&#32763;&#36716;&#65311;&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#36825;&#31181;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22987;&#32456;&#33021;&#22815;&#20135;&#29983;&#25104;&#21151;&#30340;&#32467;&#26524;&#12290;&#36825;&#31181;&#26426;&#21046;&#26377;&#22810;&#37325;&#20316;&#29992;&#65306;&#65288;1&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#34917;&#20805;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#24674;&#22797;&#21487;&#33021;&#38169;&#35823;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#65307;&#65288;2&#65289;&#35780;&#20272;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#22240;&#20026;&#26412;&#25991;&#21457;&#29616;&#23376;&#38598;&#30340;&#22823;&#23567;&#19982;&#35757;&#32451;&#38598;&#20013;&#22122;&#22768;&#25968;&#25454;&#30340;&#27604;&#20363;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#20851;&#31995;&#65307;&#65288;3&#65289;&#25552;&#20379;&#20102;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#30340;&#35265;&#35299;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#39033;&#24037;&#20316;&#20195;&#34920;&#20102;&#23545;&#35782;&#21035;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#38382;&#39064;&#30340;&#31532;&#19968;&#27425;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identi
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#20219;&#24847;&#35775;&#38382;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#30340;Q&#30340;&#27969;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#21487;&#20197;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#12290;</title><link>http://arxiv.org/abs/2305.11857</link><description>&lt;p&gt;
Q-malizing&#27969;&#21644;&#26080;&#31351;&#23567;&#23494;&#24230;&#27604;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Q-malizing flow and infinitesimal density ratio estimation. (arXiv:2305.11857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11857
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#20219;&#24847;&#35775;&#38382;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#30340;Q&#30340;&#27969;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#21487;&#20197;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#30340;&#27491;&#21017;&#21270;&#27969;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20854;&#20013;&#27969;&#32593;&#32476;&#20174;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#27491;&#24577;&#20998;&#24067;&#12290;&#19968;&#31181;&#33021;&#22815;&#20174;P&#20256;&#36755;&#21040;&#20219;&#24847;Q&#30340;&#27969;&#27169;&#22411;&#65292;&#20854;&#20013;P&#21644;Q&#37117;&#21487;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#35775;&#38382;&#65292;&#23558;&#22312;&#21508;&#31181;&#24212;&#29992;&#20852;&#36259;&#20013;&#20351;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#36817;&#24320;&#21457;&#30340;&#26395;&#36828;&#38236;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#65288;DRE&#65289;&#65292;&#23427;&#38656;&#35201;&#26500;&#24314;&#20013;&#38388;&#23494;&#24230;&#20197;&#22312;P&#21644;Q&#20043;&#38388;&#24314;&#31435;&#26725;&#26753;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#26679;&#30340;&#8220;Q-malizing&#27969;&#8221;&#65292;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#32463;&#39564;&#26679;&#26412;&#30340;&#21487;&#36870;&#20256;&#36755;&#20174;P&#21040;Q&#65288;&#21453;&#20043;&#20134;&#28982;&#65289;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#20256;&#36755;&#25104;&#26412;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#35757;&#32451;&#22909;&#30340;&#27969;&#27169;&#22411;&#20351;&#25105;&#20204;&#33021;&#22815;&#27839;&#19982;&#26102;&#38388;&#21442;&#25968;&#21270;&#30340;log&#23494;&#24230;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#65292;&#36890;&#36807;&#35757;&#32451;&#38468;&#21152;&#30340;&#36830;&#32493;&#26102;&#38388;&#27969;&#32593;&#32476;&#20351;&#29992;&#20998;&#31867;&#25439;&#22833;&#26469;&#20272;&#35745;log&#23494;&#24230;&#30340;&#26102;&#38388;&#20559;&#23548;&#25968;&#12290;&#36890;&#36807;&#31215;&#20998;&#26102;&#38388;&#24471;&#20998;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Continuous normalizing flows are widely used in generative tasks, where a flow network transports from a data distribution $P$ to a normal distribution. A flow model that can transport from $P$ to an arbitrary $Q$, where both $P$ and $Q$ are accessible via finite samples, would be of various application interests, particularly in the recently developed telescoping density ratio estimation (DRE) which calls for the construction of intermediate densities to bridge between $P$ and $Q$. In this work, we propose such a ``Q-malizing flow'' by a neural-ODE model which is trained to transport invertibly from $P$ to $Q$ (and vice versa) from empirical samples and is regularized by minimizing the transport cost. The trained flow model allows us to perform infinitesimal DRE along the time-parametrized $\log$-density by training an additional continuous-time flow network using classification loss, which estimates the time-partial derivative of the $\log$-density. Integrating the time-score network
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;Lipschitz&#32422;&#26463;&#30340;&#35299;&#30721;&#22120;&#32593;&#32476;&#65292;&#21487;&#20197;&#31616;&#21333;&#26126;&#20102;&#22320;&#25511;&#21046;&#24191;&#27867;&#30340;VAE&#27169;&#22411;&#30340;&#21518;&#39564;&#22349;&#22604;&#31243;&#24230;&#65292;&#24182;&#24102;&#26377;&#20855;&#20307;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.12770</link><description>&lt;p&gt;
&#22522;&#20110;&#21453;Lipschitz&#32422;&#26463;&#30340;&#35299;&#30721;&#22120;&#32593;&#32476;&#25511;&#21046;&#21518;&#39564;&#22349;&#22604;
&lt;/p&gt;
&lt;p&gt;
Controlling Posterior Collapse by an Inverse Lipschitz Constraint on the Decoder Network. (arXiv:2304.12770v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;Lipschitz&#32422;&#26463;&#30340;&#35299;&#30721;&#22120;&#32593;&#32476;&#65292;&#21487;&#20197;&#31616;&#21333;&#26126;&#20102;&#22320;&#25511;&#21046;&#24191;&#27867;&#30340;VAE&#27169;&#22411;&#30340;&#21518;&#39564;&#22349;&#22604;&#31243;&#24230;&#65292;&#24182;&#24102;&#26377;&#20855;&#20307;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26159;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#20013;&#21462;&#24471;&#24040;&#22823;&#25104;&#21151;&#30340;&#19968;&#31181;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#23427;&#20204;&#23384;&#22312;&#19968;&#20010;&#31216;&#20026;&#21518;&#39564;&#22349;&#22604;&#30340;&#38382;&#39064;&#65292;&#24403;&#32534;&#30721;&#22120;&#19982;&#27809;&#26377;&#32771;&#34385;&#36755;&#20837;&#25968;&#25454;&#30340;&#28508;&#22312;&#32467;&#26500;&#30340;&#20808;&#39564;&#37325;&#21512;&#25110;&#22349;&#22604;&#26102;&#23601;&#20250;&#21457;&#29983;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;Lipschitz&#31070;&#32463;&#32593;&#32476;&#30340;&#35299;&#30721;&#22120;&#65292;&#22522;&#20110;&#36825;&#20010;&#26550;&#26500;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#31616;&#21333;&#26126;&#20102;&#22320;&#25511;&#21046;&#24191;&#27867;&#30340;VAE&#27169;&#22411;&#30340;&#21518;&#39564;&#22349;&#22604;&#31243;&#24230;&#65292;&#24182;&#24102;&#26377;&#20855;&#20307;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) are one of the deep generative models that have experienced enormous success over the past decades. However, in practice, they suffer from a problem called posterior collapse, which occurs when the encoder coincides, or collapses, with the prior taking no information from the latent structure of the input data into consideration. In this work, we introduce an inverse Lipschitz neural network into the decoder and, based on this architecture, provide a new method that can control in a simple and clear manner the degree of posterior collapse for a wide range of VAE models equipped with a concrete theoretical guarantee. We also illustrate the effectiveness of our method through several numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#29983;&#25104;&#30340;&#36807;&#31243;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#36882;&#24402;&#26144;&#23556;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#22810;&#20010;&#24212;&#29992;&#21450;&#30456;&#20851;&#39046;&#22495;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.04657</link><description>&lt;p&gt;
&#35770;&#38543;&#26426;&#36941;&#21382;&#30340;&#24378;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the strong stability of ergodic iterations. (arXiv:2304.04657v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#29983;&#25104;&#30340;&#36807;&#31243;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#36882;&#24402;&#26144;&#23556;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#22810;&#20010;&#24212;&#29992;&#21450;&#30456;&#20851;&#39046;&#22495;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#30001;&#38543;&#26426;&#20989;&#25968;&#36845;&#20195;&#29983;&#25104;&#30340;&#36807;&#31243;&#65292;&#36825;&#20123;&#20989;&#25968;&#30001;&#19968;&#20010;&#24179;&#31283;&#19988;&#31526;&#21512;&#36941;&#21382;&#26465;&#20214;&#30340;&#24207;&#21015;&#39537;&#21160;&#12290;&#22914;&#26524;&#23384;&#22312;&#19968;&#20010;&#38543;&#26426;&#21021;&#22987;&#21270;&#20351;&#24471;&#35813;&#36807;&#31243;&#26159;&#31283;&#23450;&#21644;&#36941;&#21382;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;&#20219;&#20309;&#20854;&#20182;&#21021;&#22987;&#21270;&#65292;&#20004;&#20010;&#36807;&#31243;&#20043;&#38388;&#30340;&#24046;&#24322;&#20960;&#20046;&#32943;&#23450;&#25910;&#25947;&#20110;&#38646;&#65292;&#37027;&#20040;&#36825;&#26679;&#30340;&#36807;&#31243;&#34987;&#31216;&#20026;&#24378;&#31283;&#23450;&#12290;&#22312;&#23545;&#24212;&#36882;&#24402;&#26144;&#23556;&#19978;&#26045;&#21152;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#65292;&#32780;&#19981;&#22312;&#39537;&#21160;&#24207;&#21015;&#19978;&#26045;&#21152;&#20219;&#20309;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36845;&#20195;&#30340;&#24378;&#31283;&#23450;&#24615;&#12290;&#22810;&#20010;&#24212;&#29992;&#34987;&#30740;&#31350;&#65292;&#22914;&#38543;&#26426;&#36924;&#36817;&#21644;&#25490;&#38431;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20855;&#26377;&#20381;&#36182;&#22122;&#22768;&#30340; Langevin &#22411;&#36845;&#20195;&#21644;&#22810;&#22411;&#20998;&#25903;&#36807;&#31243;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit processes generated by iterated random functions driven by a stationary and ergodic sequence. Such a process is called strongly stable if a random initialization exists, for which the process is stationary and ergodic, and for any other initialization, the difference of the two processes converges to zero almost surely. Under some mild conditions on the corresponding recursive map, without any condition on the driving sequence, we show the strong stability of iterations. Several applications are surveyed such as stochastic approximation and queuing. Furthermore, new results are deduced for Langevin-type iterations with dependent noise and for multitype branching processes.
&lt;/p&gt;</description></item></channel></rss>