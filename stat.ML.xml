<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;PPO-AIRL + SAC&#20197;&#35299;&#20915;SAC&#31639;&#27861;&#22312;AIRL&#35757;&#32451;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.14593</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#65306;&#20174;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#30340;&#35282;&#24230;
&lt;/p&gt;
&lt;p&gt;
Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14593
&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;PPO-AIRL + SAC&#20197;&#35299;&#20915;SAC&#31639;&#27861;&#22312;AIRL&#35757;&#32451;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;AIRL&#65289;&#20316;&#20026;&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#22522;&#30707;&#26041;&#27861;&#12290;&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;AIRL&#30340;&#20004;&#20010;&#19981;&#21516;&#35282;&#24230;&#65306;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#12290;&#25105;&#20204;&#20174;&#29992;Soft Actor-Critic&#65288;SAC&#65289;&#26367;&#25442;AIRL&#20013;&#30340;&#20869;&#32622;&#31639;&#27861;&#24320;&#22987;&#65292;&#20197;&#22686;&#24378;&#26679;&#26412;&#25928;&#29575;&#65292;&#36825;&#35201;&#24402;&#21151;&#20110;SAC&#30340;&#31163;&#31574;&#30053;&#24418;&#24335;&#21644;&#30456;&#23545;&#20110;AIRL&#32780;&#35328;&#21487;&#35782;&#21035;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#27169;&#22411;&#12290;&#36825;&#30830;&#23454;&#22312;&#31574;&#30053;&#27169;&#20223;&#26041;&#38754;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20294;&#19981;&#24910;&#32473;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#24102;&#26469;&#20102;&#32570;&#28857;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;SAC&#31639;&#27861;&#26412;&#36523;&#22312;AIRL&#35757;&#32451;&#36807;&#31243;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;&#65292;PPO-AIRL + SAC&#65292;&#20197;&#33719;&#24471;&#20196;&#20154;&#28385;&#24847;&#30340;&#36716;&#31227;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29615;&#22659;&#25552;&#21462;&#35299;&#24320;&#30340;&#22870;&#21169;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14593v1 Announce Type: new  Abstract: Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone approach in imitation learning. This paper rethinks the two different angles of AIRL: policy imitation and transferable reward recovery. We begin with substituting the built-in algorithm in AIRL with soft actor-critic (SAC) during the policy optimization process to enhance sample efficiency, thanks to the off-policy formulation of SAC and identifiable Markov decision process (MDP) models with respect to AIRL. It indeed exhibits a significant improvement in policy imitation but accidentally brings drawbacks to transferable reward recovery. To learn this issue, we illustrate that the SAC algorithm itself is not feasible to disentangle the reward function comprehensively during the AIRL training process, and propose a hybrid framework, PPO-AIRL + SAC, for satisfactory transfer effect. Additionally, we analyze the capability of environments to extract disentangled rewa
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20256;&#36882;&#23398;&#20064;&#22240;&#26524;&#26041;&#27861;&#26469;&#35780;&#20272;&#20808;&#22825;&#24615;&#24515;&#33039;&#25163;&#26415;&#21518;&#32467;&#26524;&#30340;&#31181;&#26063;/&#27665;&#26063;&#21644;&#22320;&#29702;&#21464;&#24322;&#65292;&#26377;&#21161;&#20110;&#22312;&#32771;&#34385;&#19981;&#21516;&#20154;&#32676;&#39118;&#38505;&#22240;&#32032;&#21644;&#32467;&#26524;&#24046;&#24322;&#26469;&#28304;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;</title><link>https://arxiv.org/abs/2403.14573</link><description>&lt;p&gt;
&#19968;&#20010;&#20256;&#36882;&#23398;&#20064;&#22240;&#26524;&#26041;&#27861;&#26469;&#35780;&#20272;&#20808;&#22825;&#24615;&#24515;&#33039;&#25163;&#26415;&#21518;&#32467;&#26524;&#30340;&#31181;&#26063;/&#27665;&#26063;&#21644;&#22320;&#29702;&#21464;&#24322;
&lt;/p&gt;
&lt;p&gt;
A Transfer Learning Causal Approach to Evaluate Racial/Ethnic and Geographic Variation in Outcomes Following Congenital Heart Surgery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14573
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20256;&#36882;&#23398;&#20064;&#22240;&#26524;&#26041;&#27861;&#26469;&#35780;&#20272;&#20808;&#22825;&#24615;&#24515;&#33039;&#25163;&#26415;&#21518;&#32467;&#26524;&#30340;&#31181;&#26063;/&#27665;&#26063;&#21644;&#22320;&#29702;&#21464;&#24322;&#65292;&#26377;&#21161;&#20110;&#22312;&#32771;&#34385;&#19981;&#21516;&#20154;&#32676;&#39118;&#38505;&#22240;&#32032;&#21644;&#32467;&#26524;&#24046;&#24322;&#26469;&#28304;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#22825;&#24615;&#24515;&#33039;&#32570;&#38519;(CHD)&#26159;&#32654;&#22269;&#26368;&#24120;&#35265;&#30340;&#20808;&#22825;&#32570;&#38519;&#65292;&#25163;&#26415;&#32467;&#26524;&#22312;&#20840;&#22269;&#33539;&#22260;&#20869;&#21464;&#21270;&#24456;&#22823;&#12290;&#29305;&#23450;&#24739;&#32773;&#20122;&#32452;&#30340;CHD&#27835;&#30103;&#32467;&#26524;&#26377;&#25152;&#19981;&#21516;&#65292;&#38750;&#35199;&#29677;&#29273;&#35028;&#40657;&#20154;&#21644;&#35199;&#29677;&#29273;&#35028;&#20154;&#21475;&#30340;&#27515;&#20129;&#29575;&#21644;&#21457;&#30149;&#29575;&#36739;&#39640;&#12290;&#30001;&#20110;&#30149;&#20363;&#28151;&#21512;&#26377;&#24456;&#22823;&#24046;&#24322;&#21644;&#20122;&#32452;&#35268;&#27169;&#36739;&#23567;&#65292;&#31181;&#26063;/&#27665;&#26063;&#20122;&#32452;&#20869;&#32467;&#26524;&#30340;&#26377;&#25928;&#27604;&#36739;&#24456;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#29992;&#20110;&#32467;&#26524;&#35780;&#20272;&#65292;&#24182;&#21033;&#29992;&#20256;&#36882;&#23398;&#20064;&#30340;&#36827;&#23637;&#32467;&#21512;&#30446;&#26631;&#21644;&#28304;&#20154;&#32676;&#30340;&#25968;&#25454;&#65292;&#24110;&#21161;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#21516;&#26102;&#32771;&#34385;&#36328;&#20154;&#32676;&#19981;&#21516;&#39118;&#38505;&#22240;&#32032;&#21644;&#32467;&#26524;&#24046;&#24322;&#30340;&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14573v1 Announce Type: cross  Abstract: Congenital heart defects (CHD) are the most prevalent birth defects in the United States and surgical outcomes vary considerably across the country. The outcomes of treatment for CHD differ for specific patient subgroups, with non-Hispanic Black and Hispanic populations experiencing higher rates of mortality and morbidity. A valid comparison of outcomes within racial/ethnic subgroups is difficult given large differences in case-mix and small subgroup sizes. We propose a causal inference framework for outcome assessment and leverage advances in transfer learning to incorporate data from both target and source populations to help estimate causal effects while accounting for different sources of risk factor and outcome differences across populations. Using the Society of Thoracic Surgeons' Congenital Heart Surgery Database (STS-CHSD), we focus on a national cohort of patients undergoing the Norwood operation from 2016-2022 to assess opera
&lt;/p&gt;</description></item><item><title>&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#26041;&#27861;&#25913;&#36827;&#20102;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#23545;&#38750;&#32447;&#24615;&#28151;&#28102;&#20851;&#31995;&#30340;&#35843;&#25972;&#65292;&#25670;&#33073;&#20256;&#32479;&#20989;&#25968;&#24418;&#24335;&#20551;&#35774;&#65292;&#20294;&#20173;&#28982;&#20381;&#36182;&#20110;&#26631;&#20934;&#22240;&#26524;&#20551;&#35774;&#12290;</title><link>https://arxiv.org/abs/2403.14385</link><description>&lt;p&gt;
&#29992;&#21452;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;--&#19968;&#31181;&#26041;&#27861;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Estimating Causal Effects with Double Machine Learning -- A Method Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14385
&lt;/p&gt;
&lt;p&gt;
&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#26041;&#27861;&#25913;&#36827;&#20102;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#23545;&#38750;&#32447;&#24615;&#28151;&#28102;&#20851;&#31995;&#30340;&#35843;&#25972;&#65292;&#25670;&#33073;&#20256;&#32479;&#20989;&#25968;&#24418;&#24335;&#20551;&#35774;&#65292;&#20294;&#20173;&#28982;&#20381;&#36182;&#20110;&#26631;&#20934;&#22240;&#26524;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#35266;&#27979;&#25968;&#25454;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#20173;&#28982;&#26159;&#19968;&#20010;&#38750;&#24120;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#36817;&#24180;&#26469;&#65292;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#25918;&#23485;&#20256;&#32479;&#20551;&#35774;&#20197;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#30340;&#26032;&#26694;&#26550;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#20854;&#20013;&#19968;&#20010;&#26368;&#37325;&#35201;&#30340;&#26041;&#27861;-"&#21452;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;"&#65288;DML&#65289;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#23427;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#30456;&#23545;&#20110;&#26356;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#30340;&#34920;&#29616;&#65292;&#28982;&#21518;&#23558;&#20854;&#24212;&#29992;&#20110;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#34920;&#26126;&#65292;&#22312;DML&#20013;&#24212;&#29992;&#19968;&#20010;&#36866;&#24403;&#28789;&#27963;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#25913;&#36827;&#23545;&#21508;&#31181;&#38750;&#32447;&#24615;&#28151;&#28102;&#20851;&#31995;&#30340;&#35843;&#25972;&#12290;&#36825;&#31181;&#20248;&#21183;&#20351;&#24471;&#21487;&#20197;&#25670;&#33073;&#36890;&#24120;&#22312;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#24517;&#38656;&#30340;&#20256;&#32479;&#20989;&#25968;&#24418;&#24335;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#20851;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#26631;&#20934;&#20551;&#35774;&#26041;&#38754;&#20173;&#28982;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14385v1 Announce Type: cross  Abstract: The estimation of causal effects with observational data continues to be a very active research area. In recent years, researchers have developed new frameworks which use machine learning to relax classical assumptions necessary for the estimation of causal effects. In this paper, we review one of the most prominent methods - "double/debiased machine learning" (DML) - and empirically evaluate it by comparing its performance on simulated data relative to more traditional statistical methods, before applying it to real-world data. Our findings indicate that the application of a suitably flexible machine learning algorithm within DML improves the adjustment for various nonlinear confounding relationships. This advantage enables a departure from traditional functional form assumptions typically necessary in causal effect estimation. However, we demonstrate that the method continues to critically depend on standard assumptions about causal 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20195;&#29702;&#28151;&#28102;&#22240;&#23376;&#20998;&#35299; (PCF) &#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#28151;&#21512;&#20195;&#29702;&#21464;&#37327;&#26469;&#20272;&#35745;&#36830;&#32493;&#22788;&#29702;&#25928;&#24212;&#65292;&#23454;&#39564;&#35777;&#26126;&#22312;&#39640;&#26679;&#26412;&#22823;&#23567;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#22312;&#22240;&#26524;&#25928;&#26524;&#20272;&#35745;&#20013;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#30456;&#20851;&#24615;&#21644;&#36739;&#20302;&#30340;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.14228</link><description>&lt;p&gt;
&#20174;&#39640;&#32500;&#20195;&#29702;&#21464;&#37327;&#20013;&#24674;&#22797;&#28508;&#22312;&#28508;&#22312;&#22240;&#32032;
&lt;/p&gt;
&lt;p&gt;
Recovering Latent Confounders from High-dimensional Proxy Variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14228
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20195;&#29702;&#28151;&#28102;&#22240;&#23376;&#20998;&#35299; (PCF) &#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#28151;&#21512;&#20195;&#29702;&#21464;&#37327;&#26469;&#20272;&#35745;&#36830;&#32493;&#22788;&#29702;&#25928;&#24212;&#65292;&#23454;&#39564;&#35777;&#26126;&#22312;&#39640;&#26679;&#26412;&#22823;&#23567;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#22312;&#22240;&#26524;&#25928;&#26524;&#20272;&#35745;&#20013;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#30456;&#20851;&#24615;&#21644;&#36739;&#20302;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#28508;&#22312;&#28508;&#20239;&#32773;&#65292;&#20174;&#20195;&#29702;&#21464;&#37327;&#26159;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#20197;&#21069;&#30340;&#26041;&#27861;&#23616;&#38480;&#20110;&#20302;&#32500;&#20195;&#29702;&#65292;&#25490;&#24207;&#20195;&#29702;&#21644;&#20108;&#20803;&#27835;&#30103;&#12290;&#25105;&#20204;&#28040;&#38500;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20195;&#29702;&#28151;&#28102;&#22240;&#23376;&#20998;&#35299; (PCF) &#26694;&#26550;&#65292;&#29992;&#20110;&#36830;&#32493;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#65292;&#24403;&#28508;&#22312;&#28151;&#28102;&#22240;&#23376;&#36890;&#36807;&#39640;&#32500;&#65292;&#28151;&#21512;&#20195;&#29702;&#21464;&#37327;&#32780;&#26174;&#29616;&#12290;&#23545;&#20110;&#29305;&#23450;&#26679;&#26412;&#22823;&#23567;&#65292;&#25105;&#20204;&#30340;&#20004;&#27493; PCF &#23454;&#26045;&#65292;&#20351;&#29992;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512; (ICA-PCF) &#21644;&#31471;&#21040;&#31471;&#23454;&#26045;&#65292;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477; (GD-PCF)&#65292;&#22312;&#39640;&#26679;&#26412;&#22823;&#23567;&#33539;&#22260;&#20869;&#65292;&#19982;&#28508;&#22312;&#28151;&#28102;&#22240;&#23376;&#30340;&#30456;&#20851;&#24615;&#36739;&#39640;&#65292;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#32477;&#23545;&#35823;&#24046;&#36739;&#20302;&#12290;&#65292;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#12290;&#21363;&#20351;&#38754;&#23545;&#27668;&#20505;&#25968;&#25454;&#65292;ICA-PCF &#24674;&#22797;&#20102;&#35299;&#37322;&#27431;&#27954;&#38477;&#38632;&#27169;&#24335;&#30340; North Atlantic Oscillation $75.9\%$ &#26041;&#24046;&#30340;&#22235;&#20010;&#20998;&#37327;&#65292;&#19968;&#20010;&#24050;&#30693;&#30340;&#38477;&#27700;&#27169;&#24335;&#30340;&#28151;&#28102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14228v1 Announce Type: cross  Abstract: Detecting latent confounders from proxy variables is an essential problem in causal effect estimation. Previous approaches are limited to low-dimensional proxies, sorted proxies, and binary treatments. We remove these assumptions and present a novel Proxy Confounder Factorization (PCF) framework for continuous treatment effect estimation when latent confounders manifest through high-dimensional, mixed proxy variables. For specific sample sizes, our two-step PCF implementation, using Independent Component Analysis (ICA-PCF), and the end-to-end implementation, using Gradient Descent (GD-PCF), achieve high correlation with the latent confounder and low absolute error in causal effect estimation with synthetic datasets in the high sample size regime. Even when faced with climate data, ICA-PCF recovers four components that explain $75.9\%$ of the variance in the North Atlantic Oscillation, a known confounder of precipitation patterns in Eur
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#34920;&#26126;&#20855;&#26377;&#38750;&#31232;&#30095;&#36890;&#29992;&#20808;&#39564;&#30340;BNNs&#21487;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#23567;&#21270;&#26368;&#20248;&#21518;&#39564;&#27987;&#24230;&#36895;&#29575;&#33267;&#30495;&#23454;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.14225</link><description>&lt;p&gt;
&#20855;&#26377;&#26435;&#37325;&#36890;&#29992;&#20808;&#39564;&#30340;&#20840;&#36830;&#25509;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#27987;&#24230;
&lt;/p&gt;
&lt;p&gt;
Posterior concentrations of fully-connected Bayesian neural networks with general priors on the weights
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#34920;&#26126;&#20855;&#26377;&#38750;&#31232;&#30095;&#36890;&#29992;&#20808;&#39564;&#30340;BNNs&#21487;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#23567;&#21270;&#26368;&#20248;&#21518;&#39564;&#27987;&#24230;&#36895;&#29575;&#33267;&#30495;&#23454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#22791;&#21463;&#20851;&#27880;&#65292;&#24182;&#24050;&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#24471;&#21040;&#26377;&#25928;&#21033;&#29992;&#12290;&#20808;&#21069;&#26377;&#20851;BNNs&#21518;&#39564;&#27987;&#24230;&#24615;&#36136;&#30340;&#30740;&#31350;&#24050;&#26377;&#20960;&#39033;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36825;&#20123;&#30740;&#31350;&#20165;&#22312;&#20855;&#26377;&#31232;&#30095;&#25110;&#37325;&#23614;&#20808;&#39564;&#30340;BNN&#27169;&#22411;&#20013;&#23637;&#31034;&#32467;&#26524;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#30446;&#21069;&#23578;&#26080;&#20851;&#20110;&#20351;&#29992;&#39640;&#26031;&#20808;&#39564;&#30340;BNNs&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#32780;&#39640;&#26031;&#20808;&#39564;&#26159;&#26368;&#24120;&#29992;&#30340;&#20808;&#39564;&#20043;&#19968;&#12290;&#36825;&#31181;&#29702;&#35770;&#32570;&#22833;&#28304;&#20110;&#32570;&#20047;&#36817;&#20284;&#38750;&#31232;&#30095;&#19988;&#20855;&#26377;&#26377;&#30028;&#21442;&#25968;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#21442;&#25968;&#30340;&#38750;&#31232;&#30095;DNNs&#30340;&#26032;&#36817;&#20284;&#29702;&#35770;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#36825;&#19968;&#36817;&#20284;&#29702;&#35770;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20855;&#26377;&#38750;&#31232;&#30095;&#36890;&#29992;&#20808;&#39564;&#30340;BNNs&#21487;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#23567;&#21270;&#26368;&#20248;&#21518;&#39564;&#27987;&#24230;&#36895;&#29575;&#33267;&#30495;&#23454;&#27169;&#22411;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14225v1 Announce Type: cross  Abstract: Bayesian approaches for training deep neural networks (BNNs) have received significant interest and have been effectively utilized in a wide range of applications. There have been several studies on the properties of posterior concentrations of BNNs. However, most of these studies only demonstrate results in BNN models with sparse or heavy-tailed priors. Surprisingly, no theoretical results currently exist for BNNs using Gaussian priors, which are the most commonly used one. The lack of theory arises from the absence of approximation results of Deep Neural Networks (DNNs) that are non-sparse and have bounded parameters. In this paper, we present a new approximation theory for non-sparse DNNs with bounded parameters. Additionally, based on the approximation theory, we show that BNNs with non-sparse general priors can achieve near-minimax optimal posterior concentration rates to the true model.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;OTSeg&#20013;&#30340;Multi-Prompts Sinkhorn Attention&#26426;&#21046;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#21033;&#29992;&#22810;&#20010;&#25991;&#26412;&#25552;&#31034;&#26469;&#21305;&#37197;&#30456;&#20851;&#20687;&#32032;&#23884;&#20837;&#65292;&#20174;&#32780;&#25552;&#21319;&#38646;&#26679;&#26412;&#35821;&#20041;&#20998;&#21106;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.14183</link><description>&lt;p&gt;
OTSeg&#65306;&#22810;&#25552;&#31034;Sinkhorn&#27880;&#24847;&#21147;&#29992;&#20110;&#38646;&#26679;&#26412;&#35821;&#20041;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14183
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;OTSeg&#20013;&#30340;Multi-Prompts Sinkhorn Attention&#26426;&#21046;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#21033;&#29992;&#22810;&#20010;&#25991;&#26412;&#25552;&#31034;&#26469;&#21305;&#37197;&#30456;&#20851;&#20687;&#32032;&#23884;&#20837;&#65292;&#20174;&#32780;&#25552;&#21319;&#38646;&#26679;&#26412;&#35821;&#20041;&#20998;&#21106;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
CLIP&#30340;&#26368;&#26032;&#25104;&#21151;&#35777;&#26126;&#20102;&#36890;&#36807;&#23558;&#22810;&#27169;&#24577;&#30693;&#35782;&#36716;&#31227;&#21040;&#20687;&#32032;&#32423;&#20998;&#31867;&#26469;&#36827;&#34892;&#38646;&#26679;&#26412;&#35821;&#20041;&#20998;&#21106;&#30340;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#21033;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;CLIP&#30693;&#35782;&#26469;&#32039;&#23494;&#23545;&#40784;&#25991;&#26412;&#23884;&#20837;&#21644;&#20687;&#32032;&#23884;&#20837;&#20173;&#28982;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;OTSeg&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#27169;&#24577;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#26088;&#22312;&#22686;&#24378;&#22810;&#20010;&#25991;&#26412;&#25552;&#31034;&#21305;&#37197;&#30456;&#20851;&#20687;&#32032;&#23884;&#20837;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#31639;&#27861;&#30340;&#22810;&#25552;&#31034;Sinkhorn&#65288;MPS&#65289;&#65292;&#36825;&#20351;&#24471;&#22810;&#20010;&#25991;&#26412;&#25552;&#31034;&#21487;&#20197;&#26377;&#36873;&#25321;&#22320;&#20851;&#27880;&#22270;&#20687;&#20687;&#32032;&#20869;&#30340;&#21508;&#31181;&#35821;&#20041;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#21463;&#21040;Sinkformers&#22312;&#21333;&#27169;&#24577;&#35774;&#32622;&#20013;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MPS&#30340;&#25193;&#23637;&#65292;&#31216;&#20026;&#22810;&#25552;&#31034;Sinkhorn&#27880;&#24847;&#21147;&#65288;MPSA&#65289;&#65292;&#23427;&#26377;&#25928;&#22320;&#21462;&#20195;&#20102;Transformer&#26694;&#26550;&#20013;&#22810;&#27169;&#24577;&#35774;&#32622;&#20013;&#30340;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14183v1 Announce Type: cross  Abstract: The recent success of CLIP has demonstrated promising results in zero-shot semantic segmentation by transferring muiltimodal knowledge to pixel-level classification. However, leveraging pre-trained CLIP knowledge to closely align text embeddings with pixel embeddings still has limitations in existing approaches. To address this issue, we propose OTSeg, a novel multimodal attention mechanism aimed at enhancing the potential of multiple text prompts for matching associated pixel embeddings. We first propose Multi-Prompts Sinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads multiple text prompts to selectively focus on various semantic features within image pixels. Moreover, inspired by the success of Sinkformers in unimodal settings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn Attention (MPSA), which effectively replaces cross-attention mechanisms within Transformer framework in multimodal settin
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31867;&#21035;&#30340;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;$h$-PMD&#65292;&#23427;&#36890;&#36807;&#22312;PMD&#26356;&#26032;&#35268;&#21017;&#20013;&#32467;&#21512;&#22810;&#27493;&#36138;&#24515;&#31574;&#30053;&#25913;&#36827;&#21644;&#21069;&#30651;&#28145;&#24230;$h&#65292;&#20197;&#35299;&#20915;&#25240;&#25187;&#26080;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2403.14156</link><description>&lt;p&gt;
&#20855;&#26377;&#21069;&#30651;&#29305;&#24615;&#30340;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Policy Mirror Descent with Lookahead
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14156
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31867;&#21035;&#30340;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;$h$-PMD&#65292;&#23427;&#36890;&#36807;&#22312;PMD&#26356;&#26032;&#35268;&#21017;&#20013;&#32467;&#21512;&#22810;&#27493;&#36138;&#24515;&#31574;&#30053;&#25913;&#36827;&#21644;&#21069;&#30651;&#28145;&#24230;$h&#65292;&#20197;&#35299;&#20915;&#25240;&#25187;&#26080;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#65288;PMD&#65289;&#20316;&#20026;&#19968;&#31181;&#22810;&#21151;&#33021;&#31639;&#27861;&#26694;&#26550;&#65292;&#21253;&#25324;&#20960;&#31181;&#37325;&#35201;&#30340;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#22914;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#31639;&#27861;&#65288;&#22914;TRPO&#21644;PPO&#65289;&#30456;&#32852;&#31995;&#12290;PMD&#21487;&#20197;&#30475;&#20316;&#26159;&#23454;&#29616;&#27491;&#21017;&#21270;1&#27493;&#36138;&#24515;&#31574;&#30053;&#25913;&#36827;&#30340;&#36719;&#31574;&#30053;&#36845;&#20195;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;1&#27493;&#36138;&#24515;&#31574;&#30053;&#21487;&#33021;&#19981;&#26159;&#26368;&#20339;&#36873;&#25321;&#65292;&#26368;&#36817;&#22312;RL&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#22914;AlphaGo&#21644;AlphaZero&#24050;&#32463;&#35777;&#26126;&#65292;&#30456;&#23545;&#20110;&#22810;&#27493;&#39588;&#65292;&#36138;&#24515;&#26041;&#27861;&#21487;&#20197;&#36229;&#36234;&#23427;&#20204;&#30340;1&#27493;&#39588;&#23545;&#24212;&#29289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31867;&#21035;&#30340;PMD&#31639;&#27861;&#65292;&#31216;&#20026;$h$-PMD&#65292;&#23427;&#23558;&#20855;&#26377;&#21069;&#30651;&#28145;&#24230;$h$&#30340;&#22810;&#27493;&#36138;&#24515;&#31574;&#30053;&#25913;&#36827;&#32467;&#21512;&#21040;PMD&#26356;&#26032;&#35268;&#21017;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#25240;&#25187;&#26080;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#20854;&#20013;&#25240;&#25187;&#22240;&#23376;&#20026;$\gamma$&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;$h$-PMD&#21487;&#20197;&#25512;&#24191;&#26631;&#20934;&#30340;PMD&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14156v1 Announce Type: cross  Abstract: Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\gamma$, we show that $h$-PMD which generalizes the standard PMD enj
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#20998;&#27835;&#26041;&#27861;&#23558;&#21464;&#37327;&#20998;&#32452;&#65292;&#25353;&#29031;&#26465;&#20214;&#29420;&#31435;&#20851;&#31995;&#23398;&#20064;&#22240;&#26524;&#22270;&#65292;&#20197;&#25552;&#39640;&#22312;&#26679;&#26412;&#37327;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#30340;&#20272;&#31639;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.14125</link><description>&lt;p&gt;
&#20351;&#29992;&#26681;&#31062;&#20851;&#31995;&#23545;&#21464;&#37327;&#36827;&#34892;&#20998;&#32452;&#23398;&#20064;&#22240;&#26524;&#22270;
&lt;/p&gt;
&lt;p&gt;
Learning causal graphs using variable grouping according to ancestral relationship
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14125
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20998;&#27835;&#26041;&#27861;&#23558;&#21464;&#37327;&#20998;&#32452;&#65292;&#25353;&#29031;&#26465;&#20214;&#29420;&#31435;&#20851;&#31995;&#23398;&#20064;&#22240;&#26524;&#22270;&#65292;&#20197;&#25552;&#39640;&#22312;&#26679;&#26412;&#37327;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#30340;&#20272;&#31639;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#26679;&#26412;&#37327;&#30456;&#23545;&#20110;&#21464;&#37327;&#25968;&#37327;&#36739;&#23567;&#26102;&#65292;&#20351;&#29992;&#29616;&#26377;&#26041;&#27861;&#20272;&#31639;&#22240;&#26524;&#22270;&#30340;&#20934;&#30830;&#24615;&#20250;&#38477;&#20302;&#12290;&#26377;&#20123;&#26041;&#27861;&#22312;&#26679;&#26412;&#37327;&#23567;&#20110;&#21464;&#37327;&#25968;&#37327;&#26102;&#24182;&#19981;&#21487;&#34892;&#12290;&#20026;&#20102;&#35268;&#36991;&#36825;&#20123;&#38382;&#39064;&#65292;&#19968;&#20123;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#37319;&#29992;&#20998;&#27835;&#26041;&#27861;&#30340;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#12290;&#20026;&#20102;&#23398;&#20064;&#25972;&#20010;&#22240;&#26524;&#22270;&#65292;&#36825;&#20123;&#26041;&#27861;&#39318;&#20808;&#26681;&#25454;&#21464;&#37327;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#20851;&#31995;&#23558;&#21464;&#37327;&#20998;&#21106;&#25104;&#20960;&#20010;&#23376;&#38598;&#65292;&#28982;&#21518;&#23558;&#24120;&#35268;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#24212;&#29992;&#20110;&#27599;&#20010;&#23376;&#38598;&#24182;&#21512;&#24182;&#20272;&#35745;&#32467;&#26524;&#12290;&#30001;&#20110;&#20998;&#27835;&#26041;&#27861;&#20943;&#23569;&#20102;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#24212;&#29992;&#30340;&#21464;&#37327;&#25968;&#37327;&#65292;&#22240;&#27492;&#39044;&#35745;&#21487;&#20197;&#25913;&#21892;&#22240;&#26524;&#22270;&#30340;&#20272;&#31639;&#20934;&#30830;&#24615;&#65292;&#23588;&#20854;&#26159;&#22312;&#26679;&#26412;&#37327;&#30456;&#23545;&#36739;&#23567;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14125v1 Announce Type: cross  Abstract: Several causal discovery algorithms have been proposed. However, when the sample size is small relative to the number of variables, the accuracy of estimating causal graphs using existing methods decreases. And some methods are not feasible when the sample size is smaller than the number of variables. To circumvent these problems, some researchers proposed causal structure learning algorithms using divide-and-conquer approaches. For learning the entire causal graph, the approaches first split variables into several subsets according to the conditional independence relationships among the variables, then apply a conventional causal discovery algorithm to each subset and merge the estimated results. Since the divide-and-conquer approach reduces the number of variables to which a causal structure learning algorithm is applied, it is expected to improve the estimation accuracy of causal graphs, especially when the sample size is small rela
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#24322;&#24120;&#20540;&#30699;&#27491;&#26426;&#21046;&#65292;&#36890;&#36807;&#23558;&#30699;&#27491;&#21644;&#20272;&#35745;&#38598;&#25104;&#21040;&#32852;&#21512;&#20248;&#21270;&#26694;&#26550;&#20013;&#65292;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#21644;&#20985;&#25104;&#26412;&#20989;&#25968;&#26469;&#26816;&#27979;&#21644;&#31227;&#38500;&#24322;&#24120;&#20540;&#65292;&#24182;&#36873;&#25321;&#26368;&#20339;&#20998;&#24067;&#26469;&#25191;&#34892;&#20272;&#35745;&#20219;&#21153;</title><link>https://arxiv.org/abs/2403.14067</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#30340;&#33258;&#21160;&#24322;&#24120;&#20540;&#30699;&#27491;
&lt;/p&gt;
&lt;p&gt;
Automatic Outlier Rectification via Optimal Transport
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14067
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#24322;&#24120;&#20540;&#30699;&#27491;&#26426;&#21046;&#65292;&#36890;&#36807;&#23558;&#30699;&#27491;&#21644;&#20272;&#35745;&#38598;&#25104;&#21040;&#32852;&#21512;&#20248;&#21270;&#26694;&#26550;&#20013;&#65292;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#21644;&#20985;&#25104;&#26412;&#20989;&#25968;&#26469;&#26816;&#27979;&#21644;&#31227;&#38500;&#24322;&#24120;&#20540;&#65292;&#24182;&#36873;&#25321;&#26368;&#20339;&#20998;&#24067;&#26469;&#25191;&#34892;&#20272;&#35745;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27010;&#24565;&#26694;&#26550;&#65292;&#20351;&#29992;&#20855;&#26377;&#20985;&#25104;&#26412;&#20989;&#25968;&#30340;&#26368;&#20248;&#36755;&#36816;&#26469;&#26816;&#27979;&#24322;&#24120;&#20540;&#12290;&#20256;&#32479;&#30340;&#24322;&#24120;&#20540;&#26816;&#27979;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#20004;&#38454;&#27573;&#27969;&#31243;&#65306;&#39318;&#20808;&#26816;&#27979;&#24182;&#31227;&#38500;&#24322;&#24120;&#20540;&#65292;&#28982;&#21518;&#22312;&#28165;&#27905;&#25968;&#25454;&#19978;&#25191;&#34892;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#27809;&#26377;&#23558;&#24322;&#24120;&#20540;&#31227;&#38500;&#19982;&#20272;&#35745;&#20219;&#21153;&#32852;&#31995;&#36215;&#26469;&#65292;&#30041;&#19979;&#20102;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#24322;&#24120;&#20540;&#30699;&#27491;&#26426;&#21046;&#65292;&#23558;&#30699;&#27491;&#21644;&#20272;&#35745;&#38598;&#25104;&#21040;&#19968;&#20010;&#32852;&#21512;&#20248;&#21270;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#39318;&#20808;&#21033;&#29992;&#20855;&#26377;&#20985;&#25104;&#26412;&#20989;&#25968;&#30340;&#26368;&#20248;&#36755;&#36816;&#36317;&#31163;&#26469;&#26500;&#24314;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#20013;&#30340;&#30699;&#27491;&#38598;&#21512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36873;&#25321;&#22312;&#30699;&#27491;&#38598;&#21512;&#20013;&#30340;&#26368;&#20339;&#20998;&#24067;&#26469;&#25191;&#34892;&#20272;&#35745;&#20219;&#21153;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#24341;&#20837;&#30340;&#20985;&#25104;&#26412;&#20989;&#25968;&#26159;&#20351;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#20851;&#38190;&#24615;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14067v1 Announce Type: cross  Abstract: In this paper, we propose a novel conceptual framework to detect outliers using optimal transport with a concave cost function. Conventional outlier detection approaches typically use a two-stage procedure: first, outliers are detected and removed, and then estimation is performed on the cleaned data. However, this approach does not inform outlier removal with the estimation task, leaving room for improvement. To address this limitation, we propose an automatic outlier rectification mechanism that integrates rectification and estimation within a joint optimization framework. We take the first step to utilize an optimal transport distance with a concave cost function to construct a rectification set in the space of probability distributions. Then, we select the best distribution within the rectification set to perform the estimation task. Notably, the concave cost function we introduced in this paper is the key to making our estimator e
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20551;&#35774;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#26032;&#26679;&#26412;&#26159;&#21542;&#23646;&#20110;&#20869;&#37096;&#20998;&#24067;&#25110;&#22806;&#37096;&#20998;&#24067;&#65292;&#22312;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#22914;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>https://arxiv.org/abs/2403.14058</link><description>&lt;p&gt;
&#22522;&#20110;&#20551;&#35774;&#30340;&#28145;&#24230;&#23398;&#20064;&#29992;&#20110;&#22806;&#22495;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Hypothesis-Driven Deep Learning for Out of Distribution Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20551;&#35774;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#26032;&#26679;&#26412;&#26159;&#21542;&#23646;&#20110;&#20869;&#37096;&#20998;&#24067;&#25110;&#22806;&#37096;&#20998;&#24067;&#65292;&#22312;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#22914;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#36879;&#26126;&#40657;&#30418;&#31995;&#32479;&#30340;&#39044;&#27979;&#32463;&#24120;&#29992;&#20110;&#35832;&#22914;&#21307;&#30103;&#20445;&#20581;&#31561;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#12290;&#23545;&#20110;&#36825;&#31867;&#24212;&#29992;&#65292;&#35780;&#20272;&#27169;&#22411;&#22788;&#29702;&#36229;&#20986;&#35757;&#32451;&#25968;&#25454;&#22495;&#30340;&#26679;&#26412;&#30340;&#26041;&#24335;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#23384;&#22312;&#20960;&#31181;&#24230;&#37327;&#21644;&#27979;&#35797;&#26469;&#26816;&#27979;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#20013;&#30340;&#36229;&#20986;&#20998;&#24067;&#65288;OoD&#65289;&#25968;&#25454;&#21644;&#20998;&#24067;&#20869;&#65288;InD&#65289;&#25968;&#25454;&#65292;&#20294;&#23427;&#20204;&#30340;&#24615;&#33021;&#22312;&#25968;&#25454;&#38598;&#12289;&#27169;&#22411;&#21644;&#20219;&#21153;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20551;&#35774;&#30340;&#26041;&#27861;&#26469;&#37327;&#21270;&#26032;&#26679;&#26412;&#26159;InD&#36824;&#26159;OoD&#12290;&#32473;&#23450;&#19968;&#20010;&#35757;&#32451;&#36807;&#30340;DNN&#21644;&#19968;&#20123;&#36755;&#20837;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;DNN&#39304;&#36865;&#36755;&#20837;&#24182;&#35745;&#31639;&#19968;&#32452;OoD&#24230;&#37327;&#65292;&#31216;&#20026;&#28508;&#22312;&#21709;&#24212;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;OoD&#26816;&#27979;&#38382;&#39064;&#34920;&#36848;&#20026;&#28508;&#22312;&#21709;&#24212;&#20043;&#38388;&#30340;&#20551;&#35774;&#26816;&#39564;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#25490;&#21015;&#30340;&#37325;&#26032;&#37319;&#26679;&#26469;&#25512;&#26029;&#22312;&#38646;&#20551;&#35774;&#19979;&#35266;&#23519;&#21040;&#30340;&#28508;&#22312;&#21709;&#24212;&#30340;&#26174;&#33879;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14058v1 Announce Type: new  Abstract: Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare. For such applications, it is crucial to assess how models handle samples beyond the domain of training data. While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use. In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD. Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses. We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#38543;&#26426;&#36882;&#24402;&#26041;&#31243;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#37325;&#23614;&#29305;&#24615;&#65292;&#24182;&#36890;&#36807;i-p&#30697;&#38453;&#29702;&#35770;&#25193;&#23637;&#20102;G\"{u}rb\"{u}zbalaban&#31561;&#20154;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.13868</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#36882;&#24402;&#26041;&#31243;&#20998;&#26512;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#37325;&#23614;&#29305;&#24615;
&lt;/p&gt;
&lt;p&gt;
Analysing heavy-tail properties of Stochastic Gradient Descent by means of Stochastic Recurrence Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#38543;&#26426;&#36882;&#24402;&#26041;&#31243;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#37325;&#23614;&#29305;&#24615;&#65292;&#24182;&#36890;&#36807;i-p&#30697;&#38453;&#29702;&#35770;&#25193;&#23637;&#20102;G\"{u}rb\"{u}zbalaban&#31561;&#20154;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#29702;&#35770;&#30340;&#26368;&#36817;&#30740;&#31350;&#20013;&#65292;&#35266;&#23519;&#21040;&#21487;&#20197;&#22312;&#38543;&#26426;&#36882;&#24402;&#30340;&#27010;&#29575;&#26694;&#26550;&#19979;&#30740;&#31350;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#37325;&#23614;&#29305;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;G\"{u}rb\"{u}zbalaban&#31561;&#20154;&#65288;arXiv:2006.04740&#65289;&#32771;&#34385;&#20102;&#19968;&#20010;&#23545;&#24212;&#20110;&#32447;&#24615;&#22238;&#24402;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;SGD&#30340;&#36845;&#20195;&#21487;&#20197;&#36890;&#36807;&#22810;&#21464;&#37327;&#20223;&#23556;&#38543;&#26426;&#36882;&#24402;$X_k=A_k X_{k-1}+B_k$&#26469;&#24314;&#27169;&#65292;&#20854;&#20013;$(A_k, B_k)$&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#23545;&#65292;$A_k$&#26159;&#19968;&#20010;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#65292;$B_k$&#26159;&#19968;&#20010;&#38543;&#26426;&#21521;&#37327;&#12290;&#26412;&#25991;&#23558;&#22238;&#31572;&#24341;&#29992;&#35770;&#25991;&#20013;&#30340;&#20960;&#20010;&#26410;&#35299;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#19981;&#21487;&#32422;-&#36817;&#31471;&#65288;i-p&#65289;&#30697;&#38453;&#29702;&#35770;&#25193;&#23637;&#20182;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13868v1 Announce Type: cross  Abstract: In recent works on the theory of machine learning, it has been observed that heavy tail properties of Stochastic Gradient Descent (SGD) can be studied in the probabilistic framework of stochastic recursions. In particular, G\"{u}rb\"{u}zbalaban et al. (arXiv:2006.04740) considered a setup corresponding to linear regression for which iterations of SGD can be modelled by a multivariate affine stochastic recursion $X_k=A_k X_{k-1}+B_k$, for independent and identically distributed pairs $(A_k, B_k)$, where $A_k$ is a random symmetric matrix and $B_k$ is a random vector. In this work, we will answer several open questions of the quoted paper and extend their results by applying the theory of irreducible-proximal (i-p) matrices.
&lt;/p&gt;</description></item><item><title>TreeDOX&#26159;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#20351;&#29992;&#26102;&#38388;&#24310;&#36831;&#36807;&#24230;&#23884;&#20837;&#21644;&#39069;&#22806;&#26641;&#22238;&#24402;&#22120;&#36827;&#34892;&#29305;&#24449;&#38477;&#32500;&#21644;&#39044;&#27979;&#65292;&#24182;&#22312;&#28145;&#24230;&#39044;&#27979;&#28151;&#27788;&#31995;&#32479;&#20013;&#34920;&#29616;&#20986;state-of-the-art&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13836</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#30340;&#23398;&#20064;&#29992;&#20110;&#28145;&#24230;&#39044;&#27979;&#28151;&#27788;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Tree-based Learning for High-Fidelity Prediction of Chaos
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13836
&lt;/p&gt;
&lt;p&gt;
TreeDOX&#26159;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#20351;&#29992;&#26102;&#38388;&#24310;&#36831;&#36807;&#24230;&#23884;&#20837;&#21644;&#39069;&#22806;&#26641;&#22238;&#24402;&#22120;&#36827;&#34892;&#29305;&#24449;&#38477;&#32500;&#21644;&#39044;&#27979;&#65292;&#24182;&#22312;&#28145;&#24230;&#39044;&#27979;&#28151;&#27788;&#31995;&#32479;&#20013;&#34920;&#29616;&#20986;state-of-the-art&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#39044;&#27979;&#28151;&#27788;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#26159;&#33267;&#20851;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#38656;&#35201;&#36827;&#34892;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#36825;&#20005;&#37325;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65306;TreeDOX&#12290;&#23427;&#20351;&#29992;&#26102;&#38388;&#24310;&#36831;&#36807;&#24230;&#23884;&#20837;&#20316;&#20026;&#26174;&#24335;&#30701;&#26399;&#35760;&#24518;&#65292;&#20197;&#21450;&#39069;&#22806;&#26641;&#22238;&#24402;&#22120;&#26469;&#25191;&#34892;&#29305;&#24449;&#38477;&#32500;&#21644;&#39044;&#27979;&#12290;&#25105;&#20204;&#20351;&#29992;Henon&#26144;&#23556;&#65292;Lorenz&#21644;Kuramoto-Sivashinsky&#31995;&#32479;&#20197;&#21450;&#29616;&#23454;&#19990;&#30028;&#30340;Southern Oscillation Index&#23637;&#31034;&#20102;TreeDOX&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13836v1 Announce Type: new  Abstract: Model-free forecasting of the temporal evolution of chaotic systems is crucial but challenging. Existing solutions require hyperparameter tuning, significantly hindering their wider adoption. In this work, we introduce a tree-based approach not requiring hyperparameter tuning: TreeDOX. It uses time delay overembedding as explicit short-term memory and Extra-Trees Regressors to perform feature reduction and forecasting. We demonstrate the state-of-the-art performance of TreeDOX using the Henon map, Lorenz and Kuramoto-Sivashinsky systems, and the real-world Southern Oscillation Index.
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#20013;&#24341;&#20837;&#32447;&#24615;&#32422;&#26463;&#26435;&#37325;&#65288;LCW&#65289;&#26469;&#20943;&#23569;&#28608;&#27963;&#20559;&#31227;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#28145;&#24230;&#21069;&#21521;&#32593;&#32476;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.13833</link><description>&lt;p&gt;
&#32447;&#24615;&#32422;&#26463;&#26435;&#37325;&#65306;&#20943;&#23569;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#28608;&#27963;&#20559;&#31227;
&lt;/p&gt;
&lt;p&gt;
Linearly Constrained Weights: Reducing Activation Shift for Faster Training of Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13833
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#24341;&#20837;&#32447;&#24615;&#32422;&#26463;&#26435;&#37325;&#65288;LCW&#65289;&#26469;&#20943;&#23569;&#28608;&#27963;&#20559;&#31227;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#28145;&#24230;&#21069;&#21521;&#32593;&#32476;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#30830;&#23450;&#20102;&#28608;&#27963;&#20559;&#31227;&#65292;&#36825;&#26159;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19968;&#20010;&#31616;&#21333;&#20294;&#26174;&#33879;&#30340;&#29616;&#35937;&#65292;&#21363;&#31070;&#32463;&#20803;&#30340;&#39044;&#28608;&#27963;&#20540;&#20855;&#26377;&#38750;&#38646;&#22343;&#20540;&#65292;&#35813;&#22343;&#20540;&#21462;&#20915;&#20110;&#31070;&#32463;&#20803;&#30340;&#26435;&#37325;&#21521;&#37327;&#19982;&#21069;&#19968;&#23618;&#28608;&#27963;&#21521;&#37327;&#22343;&#20540;&#20043;&#38388;&#30340;&#22841;&#35282;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32447;&#24615;&#32422;&#26463;&#26435;&#37325;&#65288;LCW&#65289;&#65292;&#20197;&#20943;&#23569;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#23618;&#20013;&#30340;&#28608;&#27963;&#20559;&#31227;&#12290;&#20174;&#32593;&#32476;&#21464;&#37327;&#30340;&#26041;&#24046;&#22914;&#20309;&#36890;&#36807;&#21069;&#21521;&#21644;&#21453;&#21521;&#38142;&#20013;&#30340;&#23618;&#25805;&#20316;&#26469;&#25913;&#21464;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#20943;&#23569;&#31070;&#32463;&#32593;&#32476;&#20013;&#28608;&#27963;&#20559;&#31227;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#23427;&#19982;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#30340;&#20851;&#31995;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;LCW&#20351;&#20855;&#26377;sigmoid&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#21069;&#21521;&#32593;&#32476;&#33021;&#22815;&#36890;&#36807;&#35299;&#20915;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#32780;&#24471;&#20197;&#26377;&#25928;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#19982;&#25209;&#24402;&#19968;&#21270;&#32467;&#21512;&#20351;&#29992;&#65292;LCW&#25913;&#36827;&#20102;genera
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13833v1 Announce Type: cross  Abstract: In this paper, we first identify activation shift, a simple but remarkable phenomenon in a neural network in which the preactivation value of a neuron has non-zero mean that depends on the angle between the weight vector of the neuron and the mean of the activation vector in the previous layer. We then propose linearly constrained weights (LCW) to reduce the activation shift in both fully connected and convolutional layers. The impact of reducing the activation shift in a neural network is studied from the perspective of how the variance of variables in the network changes through layer operations in both forward and backward chains. We also discuss its relationship to the vanishing gradient problem. Experimental results show that LCW enables a deep feedforward network with sigmoid activation functions to be trained efficiently by resolving the vanishing gradient problem. Moreover, combined with batch normalization, LCW improves genera
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#21453;&#20107;&#23454;&#30284;&#30151;&#27835;&#30103;&#24314;&#35758;&#65292;&#38598;&#25104;&#20102;&#22810;&#31181;&#22810;&#32452;&#23398;&#25216;&#26415;&#30340;&#19987;&#23478;&#65292;&#21487;&#25552;&#20379;&#20248;&#36234;&#24615;&#33021;&#21644;&#20915;&#31574;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2402.12190</link><description>&lt;p&gt;
&#22522;&#20110;AI&#30340;&#31934;&#20934;&#32959;&#30244;&#23398;&#65306;&#22522;&#20110;&#22810;&#32452;&#23398;&#25968;&#25454;&#30340;&#20010;&#24615;&#21270;&#21453;&#20107;&#23454;&#27835;&#30103;&#24314;&#35758;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Towards AI-Based Precision Oncology: A Machine Learning Framework for Personalized Counterfactual Treatment Suggestions based on Multi-Omics Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12190
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#21453;&#20107;&#23454;&#30284;&#30151;&#27835;&#30103;&#24314;&#35758;&#65292;&#38598;&#25104;&#20102;&#22810;&#31181;&#22810;&#32452;&#23398;&#25216;&#26415;&#30340;&#19987;&#23478;&#65292;&#21487;&#25552;&#20379;&#20248;&#36234;&#24615;&#33021;&#21644;&#20915;&#31574;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#39537;&#21160;&#30340;&#31934;&#20934;&#32959;&#30244;&#23398;&#20855;&#26377;&#36890;&#36807;&#21033;&#29992;AI&#27169;&#22411;&#20998;&#26512;&#22797;&#26434;&#24739;&#32773;&#29305;&#24449;&#19982;&#23545;&#24212;&#27835;&#30103;&#32467;&#26524;&#20043;&#38388;&#20114;&#21160;&#30340;&#28508;&#21147;&#65292;&#26377;&#26395;&#37325;&#22609;&#30284;&#30151;&#27835;&#30103;&#12290;&#26032;&#25216;&#26415;&#24179;&#21488;&#20419;&#36827;&#20102;&#21450;&#26102;&#33719;&#21462;&#22810;&#27169;&#24577;&#32959;&#30244;&#29983;&#29289;&#23398;&#25968;&#25454;&#65292;&#22914;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#25968;&#25454;&#65292;&#20351;&#24471;&#36825;&#31181;&#25968;&#25454;&#30340;&#36136;&#37327;&#21644;&#25968;&#37327;&#21487;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#25913;&#36827;&#20020;&#24202;&#20915;&#31574;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22359;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#22522;&#20110;&#35757;&#32451;&#26377;&#20851;&#22810;&#31181;&#22810;&#32452;&#23398;&#25216;&#26415;&#30340;&#26426;&#22120;&#23398;&#20064;&#19987;&#23478;&#32452;&#25104;&#30340;&#38598;&#25104;&#26469;&#36827;&#34892;&#20010;&#24615;&#21270;&#21453;&#20107;&#23454;&#30284;&#30151;&#27835;&#30103;&#24314;&#35758;&#12290;&#36825;&#20123;&#19987;&#38376;&#30340;&#21453;&#20107;&#23454;&#19987;&#23478;&#26681;&#25454;&#25216;&#26415;&#19981;&#26029;&#32858;&#21512;&#20026;&#24615;&#33021;&#26356;&#20248;&#36234;&#30340;&#19987;&#23478;&#65292;&#21487;&#25552;&#20379;&#20915;&#31574;&#30340;&#32622;&#20449;&#24230;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12190v1 Announce Type: cross  Abstract: AI-driven precision oncology has the transformative potential to reshape cancer treatment by leveraging the power of AI models to analyze the interaction between complex patient characteristics and their corresponding treatment outcomes. New technological platforms have facilitated the timely acquisition of multimodal data on tumor biology at an unprecedented resolution, such as single-cell multi-omics data, making this quality and quantity of data available for data-driven improved clinical decision-making. In this work, we propose a modular machine learning framework designed for personalized counterfactual cancer treatment suggestions based on an ensemble of machine learning experts trained on diverse multi-omics technologies. These specialized counterfactual experts per technology are consistently aggregated into a more powerful expert with superior performance and can provide both confidence and an explanation of its decision. The
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;&#19981;&#21516;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;</title><link>https://arxiv.org/abs/2302.13425</link><description>&lt;p&gt;
&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#35843;&#26597;&#65306;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.13425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;&#19981;&#21516;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20197;&#21450;&#31185;&#23398;&#19982;&#24037;&#31243;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#20154;&#20204;&#20063;&#35748;&#35782;&#21040;DNNs&#26377;&#26102;&#20250;&#20570;&#20986;&#24847;&#22806;&#12289;&#38169;&#35823;&#20294;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#22312;&#33258;&#21160;&#39550;&#39542;&#12289;&#21307;&#23398;&#35786;&#26029;&#21644;&#28798;&#38590;&#21709;&#24212;&#31561;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#20986;&#29616;&#20005;&#37325;&#21518;&#26524;&#12290;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#26088;&#22312;&#20272;&#35745;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#65292;&#36229;&#36234;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#36817;&#24180;&#26469;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#38024;&#23545;DNNs&#30340;UQ&#26041;&#27861;&#12290;&#31995;&#32479;&#22320;&#23545;&#36825;&#20123;UQ&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#24182;&#27604;&#36739;&#23427;&#20204;&#30340;&#20248;&#21183;&#21644;&#21155;&#21183;&#20855;&#26377;&#26497;&#22823;&#30340;&#23454;&#38469;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#35843;&#26597;&#22823;&#22810;&#38598;&#20013;&#22312;&#20174;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35282;&#24230;&#25110;&#36125;&#21494;&#26031;&#35282;&#24230;&#23545;UQ&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#65292;&#24573;&#30053;&#20102;&#27599;&#31181;&#26041;&#27861;&#21487;&#33021;&#24341;&#20837;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.13425v3 Announce Type: replace  Abstract: Deep neural networks (DNNs) have achieved tremendous success in making accurate predictions for computer vision, natural language processing, as well as science and engineering domains. However, it is also well-recognized that DNNs sometimes make unexpected, incorrect, but overconfident predictions. This can cause serious consequences in high-stake applications, such as autonomous driving, medical diagnosis, and disaster response. Uncertainty quantification (UQ) aims to estimate the confidence of DNN predictions beyond prediction accuracy. In recent years, many UQ methods have been developed for DNNs. It is of great practical value to systematically categorize these UQ methods and compare their advantages and disadvantages. However, existing surveys mostly focus on categorizing UQ methodologies from a neural network architecture perspective or a Bayesian perspective and ignore the source of uncertainty that each methodology can incor
&lt;/p&gt;</description></item><item><title>&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#32467;&#21512;&#20102;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#20998;&#35299;&#21644;&#38750;&#21442;&#25968;&#33258;&#20030;&#25277;&#26679;&#26041;&#26696;&#65292;&#35299;&#20915;&#20102;&#35889;&#32858;&#31867;&#20013;&#25910;&#25947;&#21040;&#27425;&#20248;&#35299;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20986;&#20102;&#20854;&#22312;&#20272;&#35745;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#26102;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2209.05812</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#35889;&#32858;&#31867;&#30340;&#38750;&#21442;&#25968;&#33258;&#20030;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Non-Parametric Bootstrap for Spectral Clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.05812
&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#32467;&#21512;&#20102;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#20998;&#35299;&#21644;&#38750;&#21442;&#25968;&#33258;&#20030;&#25277;&#26679;&#26041;&#26696;&#65292;&#35299;&#20915;&#20102;&#35889;&#32858;&#31867;&#20013;&#25910;&#25947;&#21040;&#27425;&#20248;&#35299;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20986;&#20102;&#20854;&#22312;&#20272;&#35745;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#26102;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#26159;&#32858;&#31867;&#39046;&#22495;&#20013;&#24120;&#29992;&#30340;&#26041;&#27861;&#65292;&#20854;&#36719;&#32858;&#31867;&#25104;&#21592;&#27010;&#29575;&#24456;&#26377;&#30410;&#22788;&#12290;&#25311;&#21512;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#20351;&#29992;&#35889;&#32858;&#31867;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#21033;&#29992;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;EM&#31639;&#27861;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#65292;&#21253;&#25324;&#25910;&#25947;&#21040;&#27425;&#20248;&#35299;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#20004;&#31181;&#26032;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#32467;&#21512;&#20102;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#20998;&#35299;&#21644;&#38750;&#21442;&#25968;&#33258;&#20030;&#25277;&#26679;&#26041;&#26696;&#12290;&#27169;&#25311;&#26174;&#31034;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19988;&#23637;&#31034;&#20986;&#23427;&#20204;&#19981;&#20165;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#32780;&#19988;&#22312;&#20272;&#35745;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#26102;&#65292;&#19982;&#20854;&#20182;&#32858;&#31867;&#31639;&#27861;&#30456;&#27604;&#65292;&#23427;&#20204;&#36824;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#36991;&#20813;&#31967;&#31957;&#35299;&#30340;&#33021;&#21147;&#12290;&#30456;&#36739;&#20110;&#20854;&#20182;&#25311;&#21512;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#30340;&#33258;&#20030;&#31639;&#27861;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;&#25910;&#25947;&#24615;&#26041;&#38754;&#26356;&#21152;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.05812v2 Announce Type: replace-cross  Abstract: Finite mixture modelling is a popular method in the field of clustering and is beneficial largely due to its soft cluster membership probabilities. A common method for fitting finite mixture models is to employ spectral clustering, which can utilize the expectation-maximization (EM) algorithm. However, the EM algorithm falls victim to a number of issues, including convergence to sub-optimal solutions. We address this issue by developing two novel algorithms that incorporate the spectral decomposition of the data matrix and a non-parametric bootstrap sampling scheme. Simulations display the validity of our algorithms and demonstrate not only their flexibility, but also their computational efficiency and ability to avoid poor solutions when compared to other clustering algorithms for estimating finite mixture models. Our techniques are more consistent in their convergence when compared to other bootstrapped algorithms that fit fi
&lt;/p&gt;</description></item><item><title>&#20004;&#31181;&#26041;&#27861;&#22312;&#24102;&#32570;&#22833;&#20540;&#30340;&#30417;&#30563;&#23398;&#20064;&#20013;&#34920;&#29616;&#20986;&#19968;&#33268;&#24615;&#65292;&#24403;&#32570;&#22833;&#20540;&#19981;&#20855;&#20449;&#24687;&#24615;&#26102;&#65292;&#20351;&#29992;&#24120;&#25968;&#36827;&#34892;&#25554;&#34917;&#26159;&#19968;&#31181;&#31616;&#21333;&#19988;&#37325;&#35201;&#30340;&#23454;&#36341;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/1902.06931</link><description>&lt;p&gt;
&#20851;&#20110;&#24102;&#32570;&#22833;&#20540;&#30340;&#30417;&#30563;&#23398;&#20064;&#30340;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the consistency of supervised learning with missing values
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1902.06931
&lt;/p&gt;
&lt;p&gt;
&#20004;&#31181;&#26041;&#27861;&#22312;&#24102;&#32570;&#22833;&#20540;&#30340;&#30417;&#30563;&#23398;&#20064;&#20013;&#34920;&#29616;&#20986;&#19968;&#33268;&#24615;&#65292;&#24403;&#32570;&#22833;&#20540;&#19981;&#20855;&#20449;&#24687;&#24615;&#26102;&#65292;&#20351;&#29992;&#24120;&#25968;&#36827;&#34892;&#25554;&#34917;&#26159;&#19968;&#31181;&#31616;&#21333;&#19988;&#37325;&#35201;&#30340;&#23454;&#36341;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#35774;&#32622;&#20013;&#65292;&#25968;&#25454;&#23384;&#22312;&#32570;&#22833;&#20540;&#65292;&#36825;&#20351;&#24471;&#20998;&#26512;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20016;&#23500;&#30340;&#25991;&#29486;&#28041;&#21450;&#32570;&#22833;&#20540;&#22312;&#25512;&#26029;&#26694;&#26550;&#20013;&#30340;&#22788;&#29702;&#65306;&#20174;&#19981;&#23436;&#25972;&#30340;&#34920;&#20013;&#20272;&#35745;&#21442;&#25968;&#21450;&#20854;&#26041;&#24046;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#32771;&#34385;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#65306;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20013;&#20986;&#29616;&#32570;&#22833;&#20540;&#26102;&#39044;&#27979;&#30446;&#26631;&#12290;&#25105;&#20204;&#34920;&#26126;&#20102;&#20004;&#31181;&#26041;&#27861;&#22312;&#39044;&#27979;&#20013;&#30340;&#19968;&#33268;&#24615;&#12290;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#32467;&#26524;&#26159;&#65292;&#24403;&#32570;&#22833;&#20540;&#19981;&#20855;&#20449;&#24687;&#24615;&#26102;&#65292;&#20351;&#29992;&#24120;&#25968;&#36827;&#34892;&#25554;&#34917;&#65292;&#20363;&#22914;&#22312;&#23398;&#20064;&#20043;&#21069;&#20351;&#29992;&#22343;&#20540;&#65292;&#26159;&#19968;&#33268;&#30340;&#12290;&#36825;&#19982;&#25512;&#26029;&#35774;&#32622;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65292;&#25512;&#26029;&#35774;&#32622;&#20013;&#24120;&#29992;&#30340;&#22343;&#20540;&#25554;&#34917;&#26041;&#27861;&#34987;&#25351;&#36131;&#25197;&#26354;&#25968;&#25454;&#30340;&#20998;&#24067;&#12290;&#36825;&#26679;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#33021;&#22815;&#20445;&#25345;&#19968;&#33268;&#24615;&#26159;&#24456;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36866;&#29992;&#20110;&#23436;&#25972;&#35266;&#27979;&#30340;&#39044;&#27979;&#22120;&#21487;&#20197;&#36890;&#36807;&#22810;&#37325;&#25554;&#34917;&#22312;&#19981;&#23436;&#25972;&#25968;&#25454;&#19978;&#36827;&#34892;&#26368;&#20339;&#39044;&#27979;&#12290;&#26368;&#21518;&#65292;&#20026;&#20102;&#27604;&#36739;&#25554;&#34917;
&lt;/p&gt;
&lt;p&gt;
arXiv:1902.06931v4 Announce Type: replace-cross  Abstract: In many application settings, the data have missing entries which make analysis challenging. An abundant literature addresses missing values in an inferential framework: estimating parameters and their variance from incomplete tables. Here, we consider supervised-learning settings: predicting a target when missing values appear in both training and testing data. We show the consistency of two approaches in prediction. A striking result is that the widely-used method of imputing with a constant, such as the mean prior to learning is consistent when missing values are not informative. This contrasts with inferential settings where mean imputation is pointed at for distorting the distribution of the data. That such a simple approach can be consistent is important in practice. We also show that a predictor suited for complete observations can predict optimally on incomplete data,through multiple imputation.Finally, to compare imput
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#12289;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31867;&#21644;&#34920;&#24449;&#21160;&#21147;&#23398;&#21464;&#21270;&#30340;&#25299;&#25169;&#19981;&#21464;&#29305;&#24449;&#25552;&#21462;&#65292;&#29305;&#21035;&#20851;&#27880;&#36229;&#20020;&#30028;&#38669;&#26222;&#20998;&#27495;&#12290;&#36825;&#20010;&#26041;&#27861;&#21487;&#20197;&#24110;&#21161;&#39044;&#27979;&#31995;&#32479;&#30340;&#36136;&#21464;&#21644;&#24120;&#21457;&#34892;&#20026;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2312.09234</link><description>&lt;p&gt;
&#20570;&#26102;&#38388;&#25197;&#26354;&#21543;&#65306;&#23398;&#20064;&#21160;&#21147;&#31995;&#32479;&#30340;&#25299;&#25169;&#19981;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
Let's do the time-warp-attend: Learning topological invariants of dynamical systems. (arXiv:2312.09234v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.09234
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#12289;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31867;&#21644;&#34920;&#24449;&#21160;&#21147;&#23398;&#21464;&#21270;&#30340;&#25299;&#25169;&#19981;&#21464;&#29305;&#24449;&#25552;&#21462;&#65292;&#29305;&#21035;&#20851;&#27880;&#36229;&#20020;&#30028;&#38669;&#26222;&#20998;&#27495;&#12290;&#36825;&#20010;&#26041;&#27861;&#21487;&#20197;&#24110;&#21161;&#39044;&#27979;&#31995;&#32479;&#30340;&#36136;&#21464;&#21644;&#24120;&#21457;&#34892;&#20026;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#39046;&#22495;&#20013;&#30340;&#21160;&#21147;&#31995;&#32479;&#65292;&#20174;&#30005;&#36335;&#21040;&#29983;&#24577;&#32593;&#32476;&#65292;&#24403;&#20854;&#22522;&#26412;&#21442;&#25968;&#36328;&#36234;&#38408;&#20540;&#26102;&#65292;&#20250;&#21457;&#29983;&#36136;&#21464;&#21644;&#24120;&#21457;&#24615;&#30340;&#34892;&#20026;&#21464;&#21270;&#65292;&#31216;&#20026;&#20998;&#27495;&#12290;&#29616;&#26377;&#26041;&#27861;&#33021;&#22815;&#39044;&#27979;&#21333;&#20010;&#31995;&#32479;&#20013;&#21363;&#23558;&#21457;&#29983;&#30340;&#28798;&#38590;&#65292;&#20294;&#20027;&#35201;&#22522;&#20110;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#19988;&#22312;&#20998;&#31867;&#19981;&#21516;&#31995;&#32479;&#30340;&#23450;&#24615;&#21160;&#21147;&#23398;&#21464;&#21270;&#21644;&#25512;&#24191;&#21040;&#30495;&#23454;&#25968;&#25454;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#12289;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#21160;&#21147;&#23398;&#21464;&#21270;&#36827;&#34892;&#20998;&#31867;&#24182;&#34920;&#24449;&#20998;&#27495;&#36793;&#30028;&#30340;&#25299;&#25169;&#19981;&#21464;&#29305;&#24449;&#25552;&#21462;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#36229;&#20020;&#30028;&#38669;&#26222;&#20998;&#27495;&#30340;&#20856;&#22411;&#26696;&#20363;&#65292;&#20854;&#29992;&#20110;&#27169;&#25311;&#24191;&#27867;&#24212;&#29992;&#30340;&#21608;&#26399;&#24615;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#30340;&#21367;&#31215;&#20851;&#27880;&#26041;&#27861;&#32463;&#36807;&#20102;&#25968;&#25454;&#22686;&#24378;&#35757;&#32451;&#65292;&#40723;&#21169;&#23398;&#20064;&#21487;&#20197;&#29992;&#20110;&#26816;&#27979;&#20998;&#27495;&#36793;&#30028;&#30340;&#25299;&#25169;&#19981;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamical systems across the sciences, from electrical circuits to ecological networks, undergo qualitative and often catastrophic changes in behavior, called bifurcations, when their underlying parameters cross a threshold. Existing methods predict oncoming catastrophes in individual systems but are primarily time-series-based and struggle both to categorize qualitative dynamical regimes across diverse systems and to generalize to real data. To address this challenge, we propose a data-driven, physically-informed deep-learning framework for classifying dynamical regimes and characterizing bifurcation boundaries based on the extraction of topologically invariant features. We focus on the paradigmatic case of the supercritical Hopf bifurcation, which is used to model periodic dynamics across a wide range of applications. Our convolutional attention method is trained with data augmentations that encourage the learning of topological invariants which can be used to detect bifurcation boun
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;EQNN&#65289;&#21644;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNN&#65289;&#19982;&#32463;&#20856;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#65292;&#32467;&#26524;&#34920;&#26126;&#12298;$\mathbb{Z}_2\times \mathbb{Z}_2$&#12299;EQNN&#21644;QNN&#22312;&#36739;&#23567;&#30340;&#21442;&#25968;&#38598;&#21644;&#36866;&#20013;&#30340;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#19978;&#34920;&#29616;&#20248;&#36234;&#12290;</title><link>http://arxiv.org/abs/2311.18744</link><description>&lt;p&gt;
&#12298;$\mathbb{Z}_2\times \mathbb{Z}_2$&#12299;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65306;&#19982;&#32463;&#20856;&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#20934;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
$\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks. (arXiv:2311.18744v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.18744
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;EQNN&#65289;&#21644;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNN&#65289;&#19982;&#32463;&#20856;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#65292;&#32467;&#26524;&#34920;&#26126;&#12298;$\mathbb{Z}_2\times \mathbb{Z}_2$&#12299;EQNN&#21644;QNN&#22312;&#36739;&#23567;&#30340;&#21442;&#25968;&#38598;&#21644;&#36866;&#20013;&#30340;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#19978;&#34920;&#29616;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;EQNN&#65289;&#21644;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNN&#65289;&#19982;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#24212;&#29289;&#65306;&#31561;&#21464;&#37327;&#31070;&#32463;&#32593;&#32476;&#65288;ENN&#65289;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#30340;&#29609;&#20855;&#31034;&#20363;&#35780;&#20272;&#27599;&#20010;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#20851;&#27880;&#27169;&#22411;&#22797;&#26434;&#24230;&#65288;&#30001;&#21442;&#25968;&#25968;&#37327;&#27979;&#37327;&#65289;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#12298;$\mathbb{Z}_2\times \mathbb{Z}_2$&#12299;EQNN&#21644;QNN&#22312;&#36739;&#23567;&#30340;&#21442;&#25968;&#38598;&#21644;&#36866;&#20013;&#30340;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#19978;&#25552;&#20379;&#20102;&#26356;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a comprehensive comparative analysis of the performance of Equivariant Quantum Neural Networks (EQNN) and Quantum Neural Networks (QNN), juxtaposed against their classical counterparts: Equivariant Neural Networks (ENN) and Deep Neural Networks (DNN). We evaluate the performance of each network with two toy examples for a binary classification task, focusing on model complexity (measured by the number of parameters) and the size of the training data set. Our results show that the $\mathbb{Z}_2\times \mathbb{Z}_2$ EQNN and the QNN provide superior performance for smaller parameter sets and modest training data samples.
&lt;/p&gt;</description></item><item><title>LMC&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#34920;&#26126;&#65292;&#21482;&#38656;&#23545;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#65292;&#21363;&#21487;&#23454;&#29616;&#39640;&#25928;&#35745;&#31639;&#12290;&#36890;&#36807;&#24341;&#20837;&#23436;&#25972;&#21442;&#25968;&#21270;&#30340;&#8220;&#25237;&#24433;LMC&#8221;&#27169;&#22411;&#21644;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#34920;&#36798;&#24335;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#26410;&#32463;&#22788;&#29702;&#30340;&#26041;&#27861;&#30340;&#20248;&#24322;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.12032</link><description>&lt;p&gt;
LMC&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#31934;&#30830;&#21644;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Exact and efficient solutions of the LMC Multitask Gaussian Process model. (arXiv:2310.12032v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12032
&lt;/p&gt;
&lt;p&gt;
LMC&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#34920;&#26126;&#65292;&#21482;&#38656;&#23545;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#65292;&#21363;&#21487;&#23454;&#29616;&#39640;&#25928;&#35745;&#31639;&#12290;&#36890;&#36807;&#24341;&#20837;&#23436;&#25972;&#21442;&#25968;&#21270;&#30340;&#8220;&#25237;&#24433;LMC&#8221;&#27169;&#22411;&#21644;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#34920;&#36798;&#24335;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#26410;&#32463;&#22788;&#29702;&#30340;&#26041;&#27861;&#30340;&#20248;&#24322;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#20849;&#21516;&#20851;&#32852;&#27169;&#22411;&#65288;LMC&#65289;&#26159;&#19968;&#31181;&#38750;&#24120;&#36890;&#29992;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#22238;&#24402;&#25110;&#20998;&#31867;&#12290;&#34429;&#28982;&#20854;&#34920;&#36798;&#33021;&#21147;&#21644;&#27010;&#24565;&#31616;&#21333;&#24615;&#24456;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#26420;&#32032;&#23454;&#29616;&#22312;&#25968;&#25454;&#28857;&#25968;&#37327;&#21644;&#20219;&#21153;&#25968;&#37327;&#26041;&#38754;&#20855;&#26377;&#31435;&#26041;&#22797;&#26434;&#24230;&#65292;&#20351;&#24471;&#23545;&#22823;&#22810;&#25968;&#24212;&#29992;&#26469;&#35828;&#65292;&#24517;&#39035;&#36827;&#34892;&#36817;&#20284;&#22788;&#29702;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#35813;&#27169;&#22411;&#30340;&#28508;&#22312;&#36807;&#31243;&#21487;&#20197;&#35299;&#32806;&#65292;&#23548;&#33268;&#20165;&#19982;&#25152;&#36848;&#36807;&#31243;&#25968;&#37327;&#21576;&#32447;&#24615;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25193;&#23637;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#20174;&#26368;&#19968;&#33324;&#30340;&#20551;&#35774;&#20013;&#23637;&#31034;&#20102;&#22312;LMC&#30340;&#39640;&#25928;&#31934;&#30830;&#35745;&#31639;&#25152;&#38656;&#30340;&#21807;&#19968;&#26465;&#20214;&#26159;&#23545;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32467;&#26524;&#30340;&#23436;&#25972;&#21442;&#25968;&#21270;&#8220;&#25237;&#24433;LMC&#8221;&#27169;&#22411;&#65292;&#24182;&#32473;&#20986;&#20102;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#30340;&#34920;&#36798;&#24335;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#20248;&#21270;&#12290;&#25105;&#20204;&#23545;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#20102;&#21442;&#25968;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30456;&#23545;&#20110;&#26410;&#32463;&#22788;&#29702;&#30340;&#26041;&#27861;&#30340;&#20248;&#24322;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Linear Model of Co-regionalization (LMC) is a very general model of multitask gaussian process for regression or classification. While its expressivity and conceptual simplicity are appealing, naive implementations have cubic complexity in the number of datapoints and number of tasks, making approximations mandatory for most applications. However, recent work has shown that under some conditions the latent processes of the model can be decoupled, leading to a complexity that is only linear in the number of said processes. We here extend these results, showing from the most general assumptions that the only condition necessary to an efficient exact computation of the LMC is a mild hypothesis on the noise model. We introduce a full parametrization of the resulting \emph{projected LMC} model, and an expression of the marginal likelihood enabling efficient optimization. We perform a parametric study on synthetic data to show the excellent performance of our approach, compared to an unr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36890;&#36807;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#36817;&#20284;&#32852;&#21512;&#20998;&#24067;&#65292;&#35777;&#26126;&#20102;&#31890;&#23376;&#27969;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#22312;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#36229;&#20998;&#36776;&#29575;&#31561;&#36870;&#38382;&#39064;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03054</link><description>&lt;p&gt;
&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#26799;&#24230;&#27969;&#30340;&#21518;&#39564;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36890;&#36807;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#36817;&#20284;&#32852;&#21512;&#20998;&#24067;&#65292;&#35777;&#26126;&#20102;&#31890;&#23376;&#27969;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#22312;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#36229;&#20998;&#36776;&#29575;&#31561;&#36870;&#38382;&#39064;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36825;&#20010;MMD&#65292;&#20063;&#34987;&#31216;&#20026;&#33021;&#37327;&#36317;&#31163;&#65292;&#20855;&#26377;&#20687;&#36890;&#36807;&#20999;&#29255;&#21644;&#25490;&#24207;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#30340;&#20960;&#20010;&#26377;&#30410;&#23646;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#26469;&#36817;&#20284;&#30495;&#23454;&#24773;&#20917;&#21644;&#35266;&#23519;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#24182;&#20026;&#21518;&#39564;&#20998;&#24067;&#24314;&#31435;&#20102;&#35823;&#24046;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31890;&#23376;&#27969;&#30830;&#23454;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#33021;&#21147;&#36890;&#36807;&#25968;&#23383;&#31034;&#20363;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#21253;&#25324;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#35832;&#22914;&#36229;&#20998;&#36776;&#29575;&#12289;&#20462;&#22797;&#21644;&#20302;&#21058;&#37327;&#21644;&#26377;&#38480;&#35282;&#24230;&#35774;&#32622;&#19979;&#30340;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#31561;&#36870;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose conditional flows of the maximum mean discrepancy (MMD) with the negative distance kernel for posterior sampling and conditional generative modeling. This MMD, which is also known as energy distance, has several advantageous properties like efficient computation via slicing and sorting. We approximate the joint distribution of the ground truth and the observations using discrete Wasserstein gradient flows and establish an error bound for the posterior distributions. Further, we prove that our particle flow is indeed a Wasserstein gradient flow of an appropriate functional. The power of our method is demonstrated by numerical examples including conditional image generation and inverse problems like superresolution, inpainting and computed tomography in low-dose and limited-angle settings.
&lt;/p&gt;</description></item><item><title>ED-NeRF &#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340; 3D &#22330;&#26223;&#32534;&#36753;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22330;&#26223;&#23884;&#20837;&#21040;&#28508;&#31354;&#38388;&#20013;&#65292;&#24471;&#21040;&#26356;&#24555;&#36895;&#19988;&#26356;&#26131;&#20110;&#32534;&#36753;&#30340; NeRF &#39592;&#24178;&#12290;</title><link>http://arxiv.org/abs/2310.02712</link><description>&lt;p&gt;
ED-NeRF: &#20351;&#29992;&#28508;&#31354;&#38388; NeRF &#23454;&#29616;&#39640;&#25928;&#30340;&#25991;&#26412;&#24341;&#23548;&#30340; 3D &#22330;&#26223;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF. (arXiv:2310.02712v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02712
&lt;/p&gt;
&lt;p&gt;
ED-NeRF &#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340; 3D &#22330;&#26223;&#32534;&#36753;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22330;&#26223;&#23884;&#20837;&#21040;&#28508;&#31354;&#38388;&#20013;&#65292;&#24471;&#21040;&#26356;&#24555;&#36895;&#19988;&#26356;&#26131;&#20110;&#32534;&#36753;&#30340; NeRF &#39592;&#24178;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25991;&#26412;&#21040;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#22312;&#20108;&#32500;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#36827;&#23637;&#24050;&#32463;&#25193;&#23637;&#21040;&#19977;&#32500;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#20174;&#25991;&#26412;&#25551;&#36848;&#20013;&#29983;&#25104;&#26032;&#30340;&#19977;&#32500;&#23545;&#35937;&#12290;&#36825;&#28436;&#21464;&#25104;&#20102; NeRF &#32534;&#36753;&#26041;&#27861;&#65292;&#36890;&#36807;&#25991;&#26412;&#26465;&#20214;&#20801;&#35768;&#23545;&#29616;&#26377;&#30340;&#19977;&#32500;&#23545;&#35937;&#36827;&#34892;&#25805;&#20316;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340; NeRF &#32534;&#36753;&#25216;&#26415;&#22312;&#24615;&#33021;&#19978;&#38754;&#20020;&#30528;&#19968;&#20123;&#38480;&#21046;&#65292;&#22914;&#35757;&#32451;&#36895;&#24230;&#24930;&#21644;&#20351;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#19981;&#20805;&#20998;&#32771;&#34385;&#32534;&#36753;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; 3D NeRF &#32534;&#36753;&#26041;&#27861;&#65292;&#31216;&#20026; ED-NeRF&#65292;&#36890;&#36807;&#23558;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#25104;&#21151;&#23884;&#20837;&#21040;&#28508;&#25193;&#25955;&#27169;&#22411; (LDM) &#30340;&#28508;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#29420;&#29305;&#30340;&#32454;&#21270;&#23618;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#19968;&#20010;&#19981;&#20165;&#26356;&#24555;&#65292;&#32780;&#19988;&#26356;&#36866;&#21512;&#20110;&#32534;&#36753;&#30340; NeRF &#39592;&#24178;&#65292;&#19982;&#20256;&#32479;&#30340;&#22270;&#20687;&#31354;&#38388; NeRF &#32534;&#36753;&#30456;&#27604;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been a significant advancement in text-to-image diffusion models, leading to groundbreaking performance in 2D image generation. These advancements have been extended to 3D models, enabling the generation of novel 3D objects from textual descriptions. This has evolved into NeRF editing methods, which allow the manipulation of existing 3D objects through textual conditioning. However, existing NeRF editing techniques have faced limitations in their performance due to slow training speeds and the use of loss functions that do not adequately consider editing. To address this, here we present a novel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding real-world scenes into the latent space of the latent diffusion model (LDM) through a unique refinement layer. This approach enables us to obtain a NeRF backbone that is not only faster but also more amenable to editing compared to traditional image space NeRF editing. Furthermore, we propose an improved loss 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#20154;&#30340;&#20381;&#20174;&#31243;&#24230;&#21644;&#26426;&#22120;&#25552;&#20379;&#24314;&#35758;&#30340;&#26102;&#26426;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#26469;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2310.00817</link><description>&lt;p&gt;
&#23398;&#20064;&#22914;&#20309;&#25552;&#20379;&#27880;&#37325;&#20381;&#20174;&#24615;&#30340;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Learning to Make Adherence-Aware Advice. (arXiv:2310.00817v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#20154;&#30340;&#20381;&#20174;&#31243;&#24230;&#21644;&#26426;&#22120;&#25552;&#20379;&#24314;&#35758;&#30340;&#26102;&#26426;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#26469;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#20154;&#31867;&#20915;&#31574;&#20013;&#25198;&#28436;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#35282;&#33394;&#65292;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#20132;&#20114;&#23384;&#22312;&#25361;&#25112;&#12290;&#30001;&#20110;&#27809;&#26377;&#20805;&#20998;&#32771;&#34385;&#21040;&#20154;&#31867;&#24573;&#35270;&#20154;&#24037;&#26234;&#33021;&#24314;&#35758;&#21644;&#20154;&#24037;&#26234;&#33021;&#36873;&#25321;&#24615;&#25552;&#20379;&#24314;&#35758;&#30340;&#38656;&#27714;&#65292;&#19968;&#20010;&#25361;&#25112;&#23601;&#26469;&#33258;&#20110;&#24213;&#23618;&#20154;&#24037;&#26234;&#33021;&#31574;&#30053;&#30340;&#19981;&#20339;&#34920;&#29616;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#20154;&#31867;&#30340;&#20381;&#20174;&#31243;&#24230;&#65288;&#21363;&#20154;&#31867;&#36981;&#24490;/&#25298;&#32477;&#26426;&#22120;&#24314;&#35758;&#30340;&#27010;&#29575;&#65289;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#25512;&#36831;&#36873;&#39033;&#65292;&#20351;&#24471;&#26426;&#22120;&#22312;&#26368;&#21512;&#36866;&#30340;&#26102;&#20505;&#21487;&#20197;&#26242;&#26102;&#19981;&#25552;&#20379;&#24314;&#35758;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#65292;&#24182;&#20165;&#22312;&#20851;&#38190;&#26102;&#21051;&#25552;&#20379;&#24314;&#35758;&#12290;&#19982;&#38382;&#39064;&#19981;&#21487;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#19987;&#38376;&#21270;&#23398;&#20064;&#31639;&#27861;&#19981;&#20165;&#20855;&#26377;&#26356;&#22909;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#33021;&#65292;&#32780;&#19988;&#22312;&#23454;&#35777;&#24615;&#33021;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
As artificial intelligence (AI) systems play an increasingly prominent role in human decision-making, challenges surface in the realm of human-AI interactions. One challenge arises from the suboptimal AI policies due to the inadequate consideration of humans disregarding AI recommendations, as well as the need for AI to provide advice selectively when it is most pertinent. This paper presents a sequential decision-making model that (i) takes into account the human's adherence level (the probability that the human follows/rejects machine advice) and (ii) incorporates a defer option so that the machine can temporarily refrain from making advice. We provide learning algorithms that learn the optimal advice policy and make advice only at critical time stamps. Compared to problem-agnostic reinforcement learning algorithms, our specialized learning algorithms not only enjoy better theoretical convergence properties but also show strong empirical performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#30340;&#26089;&#20572;&#27490;&#26041;&#27861;&#65292;&#36890;&#36807;&#35266;&#23519;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#30446;&#26631;&#20540;&#26469;&#20915;&#23450;&#26159;&#21542;&#20572;&#27490;&#35780;&#20272;&#65292;&#32780;&#26080;&#38656;&#38382;&#39064;&#29305;&#23450;&#30340;&#30693;&#35782;&#12290;&#22312;&#27979;&#35797;&#20013;&#65292;&#35813;&#26041;&#27861;&#22312;&#28216;&#25103;&#12289;&#26426;&#22120;&#20154;&#21644;&#32463;&#20856;&#25511;&#21046;&#39046;&#22495;&#20013;&#34920;&#29616;&#20986;&#33410;&#30465;&#35745;&#31639;&#26102;&#38388;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2308.03574</link><description>&lt;p&gt;
&#28436;&#21270;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#20013;&#30340;&#24191;&#20041;&#26089;&#20572;&#27490;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Early Stopping in Evolutionary Direct Policy Search. (arXiv:2308.03574v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#30340;&#26089;&#20572;&#27490;&#26041;&#27861;&#65292;&#36890;&#36807;&#35266;&#23519;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#30446;&#26631;&#20540;&#26469;&#20915;&#23450;&#26159;&#21542;&#20572;&#27490;&#35780;&#20272;&#65292;&#32780;&#26080;&#38656;&#38382;&#39064;&#29305;&#23450;&#30340;&#30693;&#35782;&#12290;&#22312;&#27979;&#35797;&#20013;&#65292;&#35813;&#26041;&#27861;&#22312;&#28216;&#25103;&#12289;&#26426;&#22120;&#20154;&#21644;&#32463;&#20856;&#25511;&#21046;&#39046;&#22495;&#20013;&#34920;&#29616;&#20986;&#33410;&#30465;&#35745;&#31639;&#26102;&#38388;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#23588;&#20854;&#26159;&#28041;&#21450;&#22312;&#29289;&#29702;&#19990;&#30028;&#20013;&#36827;&#34892;&#35780;&#20272;&#30340;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#20219;&#21153;&#20013;&#65292;&#35780;&#20272;&#26102;&#38388;&#36890;&#24120;&#36739;&#38271;&#12290;&#24403;&#22312;&#22266;&#23450;&#26102;&#38388;&#27573;&#20869;&#35780;&#20272;&#35299;&#20915;&#26041;&#26696;&#26102;&#65292;&#24448;&#24448;&#20250;&#26126;&#30830;&#26080;&#27861;&#36890;&#36807;&#22686;&#21152;&#35745;&#31639;&#26102;&#38388;&#26469;&#25552;&#39640;&#30446;&#26631;&#20540;&#65288;&#20363;&#22914;&#65292;&#24403;&#20004;&#36718;&#26426;&#22120;&#20154;&#25345;&#32493;&#22312;&#21407;&#22320;&#26059;&#36716;&#26102;&#65289;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#21450;&#26089;&#20572;&#27490;&#35780;&#20272;&#20197;&#33410;&#30465;&#35745;&#31639;&#26102;&#38388;&#26159;&#26377;&#24847;&#20041;&#30340;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#35780;&#20272;&#20572;&#27490;&#26041;&#27861;&#37117;&#26159;&#38382;&#39064;&#29305;&#23450;&#30340;&#65292;&#24182;&#19988;&#38656;&#35201;&#19987;&#38376;&#20026;&#24403;&#21069;&#20219;&#21153;&#35774;&#35745;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#30340;&#26089;&#20572;&#27490;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21482;&#26597;&#30475;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#30446;&#26631;&#20540;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#38382;&#39064;&#29305;&#23450;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#22312;&#20116;&#20010;&#26469;&#33258;&#28216;&#25103;&#12289;&#26426;&#22120;&#20154;&#21644;&#32463;&#20856;&#25511;&#21046;&#39046;&#22495;&#30340;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#29615;&#22659;&#20013;&#27979;&#35797;&#20102;&#24341;&#20837;&#30340;&#20572;&#27490;&#20934;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#33410;&#30465;&#20102;&#35745;&#31639;&#26102;&#38388;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lengthy evaluation times are common in many optimization problems such as direct policy search tasks, especially when they involve conducting evaluations in the physical world, e.g. in robotics applications. Often, when evaluating a solution over a fixed time period, it becomes clear that the objective value will not increase with additional computation time (for example, when a two-wheeled robot continuously spins on the spot). In such cases, it makes sense to stop the evaluation early to save computation time. However, most approaches to stop the evaluation are problem-specific and need to be specifically designed for the task at hand. Therefore, we propose an early stopping method for direct policy search. The proposed method only looks at the objective value at each time step and requires no problem-specific knowledge.  We test the introduced stopping criterion in five direct policy search environments drawn from games, robotics, and classic control domains, and show that it can sa
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#21508;&#31181;&#20551;&#35774;&#19979;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20250;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#32500;&#24230;&#22312;&#31070;&#32463;&#32593;&#32476;&#36807;&#25311;&#21512;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.15141</link><description>&lt;p&gt;
&#20174;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#32531;&#21644;&#36807;&#25311;&#21512;&#21040;&#33391;&#24615;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
From Tempered to Benign Overfitting in ReLU Neural Networks. (arXiv:2305.15141v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#21508;&#31181;&#20551;&#35774;&#19979;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20250;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#32500;&#24230;&#22312;&#31070;&#32463;&#32593;&#32476;&#36807;&#25311;&#21512;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#34987;&#35266;&#23519;&#21040;&#21363;&#20351;&#35757;&#32451;&#27169;&#22411;&#26469;&#23436;&#32654;&#22320;&#36866;&#24212;&#22024;&#26434;&#30340;&#25968;&#25454;&#20063;&#33021;&#24456;&#22909;&#22320;&#25512;&#24191;&#12290;&#36825;&#19968;&#29616;&#35937;&#24341;&#21457;&#20102;&#22823;&#37327;&#20851;&#20110;&#8220;&#33391;&#24615;&#36807;&#25311;&#21512;&#8221;&#30340;&#24037;&#20316;&#65292;&#20854;&#20013;&#20869;&#25554;&#39044;&#27979;&#22120;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#24615;&#33021;&#12290;&#26368;&#36817;&#65292;&#26377;&#20154;&#29468;&#27979;&#24182;&#32463;&#39564;&#24615;&#22320;&#35266;&#23519;&#21040;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#36890;&#24120;&#26356;&#22909;&#22320;&#25551;&#36848;&#20026;&#8220;&#32531;&#21644;&#36807;&#25311;&#21512;&#8221;&#65292;&#20854;&#20013;&#24615;&#33021;&#26082;&#38750;&#26368;&#20248;&#65292;&#20063;&#38750;&#24494;&#19981;&#36275;&#36947;&#65292;&#24182;&#38543;&#22122;&#22768;&#27700;&#24179;&#30340;&#21464;&#21270;&#32780;&#38477;&#20302;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#36825;&#19968;&#20027;&#24352;&#23578;&#32570;&#20047;&#20851;&#20110;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#30340;&#35777;&#26126;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20960;&#20010;&#32467;&#26524;&#65292;&#26088;&#22312;&#24357;&#21512;&#36825;&#20123;&#20114;&#34917;&#30340;&#35266;&#28857;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#31867;&#35774;&#32622;&#65292;&#20351;&#29992;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#35777;&#26126;&#22312;&#21508;&#31181;&#20551;&#35774;&#19979;&#65292;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35777;&#26126;&#36755;&#20837;&#32500;&#24230;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26377;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparameterized neural networks (NNs) are observed to generalize well even when trained to perfectly fit noisy data. This phenomenon motivated a large body of work on "benign overfitting", where interpolating predictors achieve near-optimal performance. Recently, it was conjectured and empirically observed that the behavior of NNs is often better described as "tempered overfitting", where the performance is non-optimal yet also non-trivial, and degrades as a function of the noise level. However, a theoretical justification of this claim for non-linear NNs has been lacking so far. In this work, we provide several results that aim at bridging these complementing views. We study a simple classification setting with 2-layer ReLU NNs, and prove that under various assumptions, the type of overfitting transitions from tempered in the extreme case of one-dimensional data, to benign in high dimensions. Thus, we show that the input dimension has a crucial role on the type of overfitting in thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#20998;&#21106;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#24322;&#36136;&#24615;&#21151;&#33021;&#25968;&#25454;&#65292;&#36890;&#36807;&#21160;&#24577;&#35268;&#21010;&#30340;EM&#31639;&#27861;&#36817;&#20284;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65292;&#26041;&#27861;&#22312;&#27169;&#25311;&#19982;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.10712</link><description>&lt;p&gt;
&#24322;&#36136;&#24615;&#21151;&#33021;&#25968;&#25454;&#30340;&#28151;&#21512;&#20998;&#21106;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mixture of segmentation for heterogeneous functional data. (arXiv:2303.10712v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#20998;&#21106;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#24322;&#36136;&#24615;&#21151;&#33021;&#25968;&#25454;&#65292;&#36890;&#36807;&#21160;&#24577;&#35268;&#21010;&#30340;EM&#31639;&#27861;&#36817;&#20284;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65292;&#26041;&#27861;&#22312;&#27169;&#25311;&#19982;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26102;&#38388;&#21644;&#20154;&#21475;&#24322;&#36136;&#24615;&#30340;&#21151;&#33021;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#20998;&#21106;&#27169;&#22411;&#65292;&#26088;&#22312;&#20445;&#25345;&#21151;&#33021;&#32467;&#26500;&#30340;&#21516;&#26102;&#34920;&#31034;&#24322;&#36136;&#24615;&#12290; &#35752;&#35770;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#21487;&#36776;&#35782;&#24615;&#21644;&#19968;&#33268;&#24615;&#65292;&#24182;&#37319;&#29992;&#21160;&#24577;&#35268;&#21010;&#30340;EM&#31639;&#27861;&#26469;&#36817;&#20284;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#12290; &#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#35828;&#26126;&#65292;&#24182;&#22312;&#29992;&#30005;&#37327;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider functional data with heterogeneity in time and in population. We propose a mixture model with segmentation of time to represent this heterogeneity while keeping the functional structure. Maximum likelihood estimator is considered, proved to be identifiable and consistent. In practice, an EM algorithm is used, combined with dynamic programming for the maximization step, to approximate the maximum likelihood estimator. The method is illustrated on a simulated dataset, and used on a real dataset of electricity consumption.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2209.10053</link><description>&lt;p&gt;
&#32463;&#39564;&#36807;&#31243;&#30340;&#23454;&#20363;&#30456;&#20851;&#30340;&#19968;&#33268;&#23614;&#37096;&#30028;
&lt;/p&gt;
&lt;p&gt;
Instance-dependent uniform tail bounds for empirical processes. (arXiv:2209.10053v3 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10053
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#31867;&#20026;&#25351;&#26631;&#65292;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;&#36890;&#36807;&#23558;&#26631;&#20934;&#36890;&#29992;&#38142;&#25509;&#35770;&#35777;&#24341;&#20837;&#19968;&#20010;&#26368;&#21021;&#30340;&#8220;&#27844;&#27668;&#8221;&#27493;&#39588;&#26469;&#24314;&#31435;&#23614;&#37096;&#30028;&#12290;&#29983;&#25104;&#30340;&#23614;&#37096;&#30028;&#26377;&#19968;&#20010;&#20027;&#35201;&#30340;&#22797;&#26434;&#24230;&#32452;&#25104;&#37096;&#20998;&#65292;&#21363;&#19968;&#20010;&#20851;&#20110;&#27844;&#27668;&#20989;&#25968;&#31867;&#30340; Talagrand $\gamma$ &#20989;&#25968;&#30340;&#21464;&#20307;&#65292;&#20197;&#21450;&#19968;&#20010;&#23454;&#20363;&#30456;&#20851;&#30340;&#20559;&#24046;&#39033;&#65292;&#36890;&#36807;&#19968;&#20010;&#36866;&#24403;&#32553;&#25918;&#30340;&#36866;&#24403;&#33539;&#25968;&#30340;&#29256;&#26412;&#26469;&#34913;&#37327;&#12290;&#36825;&#20123;&#39033;&#37117;&#20351;&#29992;&#22522;&#20110;&#30456;&#20851;&#30340;&#27597;&#20989;&#25968;&#30340;&#26576;&#20123;&#31995;&#25968;&#26469;&#34920;&#36798;&#12290;&#24403;&#20989;&#25968;&#31867;&#22312;&#32473;&#23450;&#30340;&#65288;&#25351;&#25968;&#22411;&#65289;Orlicz&#31354;&#38388;&#20013;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26356;&#26126;&#30830;&#30340;&#36817;&#20284;&#20540;&#26469;&#25551;&#36848;&#25152;&#25552;&#21040;&#30340;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We formulate a uniform tail bound for empirical processes indexed by a class of functions, in terms of the individual deviations of the functions rather than the worst-case deviation in the considered class. The tail bound is established by introducing an initial "deflation" step to the standard generic chaining argument. The resulting tail bound has a main complexity component, a variant of Talagrand's $\gamma$ functional for the deflated function class, as well as an instance-dependent deviation term, measured by an appropriately scaled version of a suitable norm. Both of these terms are expressed using certain coefficients formulated based on the relevant cumulant generating functions. We also provide more explicit approximations for the mentioned coefficients, when the function class lies in a given (exponential type) Orlicz space.
&lt;/p&gt;</description></item></channel></rss>