<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20855;&#26377;&#19968;&#23450;&#26435;&#37325;&#32422;&#26463;&#30340;CNNs&#30340;&#26032;&#36924;&#36817;&#19978;&#30028;&#65292;&#20197;&#21450;&#23545;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#35206;&#30422;&#25968;&#20570;&#20102;&#26032;&#30340;&#20998;&#26512;&#65292;&#20026;&#22522;&#20110;CNNs&#30340;&#23398;&#20064;&#38382;&#39064;&#25512;&#23548;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#22312;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#21644;&#20108;&#20803;&#20998;&#31867;&#26041;&#38754;&#21462;&#24471;&#20102;&#26497;&#23567;&#26368;&#20248;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.16459</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23398;&#20064;&#25910;&#25947;&#36895;&#29575;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the rates of convergence for learning with convolutional neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16459
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20855;&#26377;&#19968;&#23450;&#26435;&#37325;&#32422;&#26463;&#30340;CNNs&#30340;&#26032;&#36924;&#36817;&#19978;&#30028;&#65292;&#20197;&#21450;&#23545;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#35206;&#30422;&#25968;&#20570;&#20102;&#26032;&#30340;&#20998;&#26512;&#65292;&#20026;&#22522;&#20110;CNNs&#30340;&#23398;&#20064;&#38382;&#39064;&#25512;&#23548;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#22312;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#21644;&#20108;&#20803;&#20998;&#31867;&#26041;&#38754;&#21462;&#24471;&#20102;&#26497;&#23567;&#26368;&#20248;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#30340;&#36924;&#36817;&#21644;&#23398;&#20064;&#33021;&#21147;&#12290;&#31532;&#19968;&#20010;&#32467;&#26524;&#35777;&#26126;&#20102;&#22312;&#26435;&#37325;&#19978;&#26377;&#19968;&#23450;&#32422;&#26463;&#26465;&#20214;&#19979;CNNs&#30340;&#26032;&#36924;&#36817;&#19978;&#30028;&#12290;&#31532;&#20108;&#20010;&#32467;&#26524;&#32473;&#20986;&#20102;&#23545;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#35206;&#30422;&#25968;&#30340;&#26032;&#20998;&#26512;&#65292;&#20854;&#20013;CNNs&#26159;&#20854;&#29305;&#20363;&#12290;&#35813;&#20998;&#26512;&#35814;&#32454;&#32771;&#34385;&#20102;&#26435;&#37325;&#30340;&#22823;&#23567;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#32473;&#20986;&#20102;&#27604;&#29616;&#26377;&#25991;&#29486;&#26356;&#22909;&#30340;&#19978;&#30028;&#12290;&#21033;&#29992;&#36825;&#20004;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#33021;&#22815;&#25512;&#23548;&#22522;&#20110;CNNs&#30340;&#20272;&#35745;&#22120;&#22312;&#35768;&#22810;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#35774;&#32622;&#20013;&#20026;&#22522;&#20110;CNNs&#30340;&#26368;&#23567;&#20108;&#20056;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#24314;&#31435;&#20102;&#26497;&#23567;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#23545;&#20110;&#20108;&#20803;&#20998;&#31867;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#20855;&#26377;&#38128;&#38142;&#25439;&#22833;&#21644;&#36923;&#36753;&#25439;&#22833;&#30340;CNN&#20998;&#31867;&#22120;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#21516;&#26102;&#36824;&#34920;&#26126;&#25152;&#24471;&#21040;&#30340;&#36895;&#29575;&#22312;&#20960;&#31181;&#24773;&#20917;&#19979;&#26159;&#26497;&#23567;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16459v1 Announce Type: new  Abstract: We study the approximation and learning capacities of convolutional neural networks (CNNs). Our first result proves a new approximation bound for CNNs with certain constraint on the weights. Our second result gives a new analysis on the covering number of feed-forward neural networks, which include CNNs as special cases. The analysis carefully takes into account the size of the weights and hence gives better bounds than existing literature in some situations. Using these two results, we are able to derive rates of convergence for estimators based on CNNs in many learning problems. In particular, we establish minimax optimal convergence rates of the least squares based on CNNs for learning smooth functions in the nonparametric regression setting. For binary classification, we derive convergence rates for CNN classifiers with hinge loss and logistic loss. It is also shown that the obtained rates are minimax optimal in several settings.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#20449;&#24687;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.12295</link><description>&lt;p&gt;
&#36890;&#36807;&#25511;&#21046;&#34394;&#35686;&#35206;&#30422;&#29575;&#36873;&#25321;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;
&lt;/p&gt;
&lt;p&gt;
Selecting informative conformal prediction sets with false coverage rate control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12295
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#20449;&#24687;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20998;&#31867;&#65292;&#31526;&#21512;&#26041;&#27861;&#20026;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#22120;&#25552;&#20379;&#39044;&#27979;&#32467;&#26524;/&#26631;&#31614;&#30340;&#39044;&#27979;&#38598;&#21512;&#65292;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#29575;&#12290;&#22312;&#36825;&#37324;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#26679;&#19968;&#31181;&#24773;&#20917;&#65292;&#21363;&#36825;&#31181;&#39044;&#27979;&#38598;&#21512;&#26159;&#32463;&#36807;&#36873;&#25321;&#36807;&#31243;&#24471;&#21040;&#30340;&#12290;&#35813;&#36873;&#25321;&#36807;&#31243;&#35201;&#27714;&#36873;&#25321;&#30340;&#39044;&#27979;&#38598;&#22312;&#26576;&#31181;&#26126;&#30830;&#23450;&#20041;&#30340;&#24847;&#20041;&#19978;&#26159;&#8220;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#8221;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20998;&#31867;&#21644;&#22238;&#24402;&#35774;&#32622;&#65292;&#22312;&#36825;&#20123;&#35774;&#32622;&#20013;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#21482;&#32771;&#34385;&#20855;&#26377;&#39044;&#27979;&#26631;&#31614;&#38598;&#25110;&#39044;&#27979;&#21306;&#38388;&#36275;&#22815;&#23567;&#12289;&#19981;&#21253;&#25324;&#31354;&#20540;&#25110;&#36981;&#23432;&#20854;&#20182;&#36866;&#24403;&#30340;&#8220;&#21333;&#35843;&#8221;&#32422;&#26463;&#30340;&#26679;&#26412;&#20026;&#20855;&#26377;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#12290;&#34429;&#28982;&#36825;&#28085;&#30422;&#20102;&#21508;&#31181;&#24212;&#29992;&#20013;&#21487;&#33021;&#24863;&#20852;&#36259;&#30340;&#35768;&#22810;&#35774;&#32622;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#26469;&#26500;&#24314;&#36825;&#26679;&#30340;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#19978;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#65288;FCR&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12295v1 Announce Type: cross  Abstract: In supervised learning, including regression and classification, conformal methods provide prediction sets for the outcome/label with finite sample coverage for any machine learning predictors. We consider here the case where such prediction sets come after a selection process. The selection process requires that the selected prediction sets be `informative' in a well defined sense. We consider both the classification and regression settings where the analyst may consider as informative only the sample with prediction label sets or prediction intervals small enough, excluding null values, or obeying other appropriate `monotone' constraints. While this covers many settings of possible interest in various applications, we develop a unified framework for building such informative conformal prediction sets while controlling the false coverage rate (FCR) on the selected sample. While conformal prediction sets after selection have been the f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#32771;&#34385;&#38544;&#31169;&#32422;&#26463;&#12290;</title><link>https://arxiv.org/abs/2403.11343</link><description>&lt;p&gt;
&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Transfer Learning with Differential Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#32771;&#34385;&#38544;&#31169;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#36234;&#26469;&#36234;&#21463;&#21040;&#27426;&#36814;&#65292;&#25968;&#25454;&#24322;&#26500;&#24615;&#21644;&#38544;&#31169;&#24615;&#26159;&#20004;&#20010;&#31361;&#20986;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#20869;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#26088;&#22312;&#36890;&#36807;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#36981;&#23432;&#38544;&#31169;&#32422;&#26463;&#12290;&#25105;&#20204;&#20005;&#26684;&#21046;&#23450;&#20102;\textit{&#32852;&#37030;&#24046;&#20998;&#38544;&#31169;}&#30340;&#27010;&#24565;&#65292;&#20026;&#27599;&#20010;&#25968;&#25454;&#38598;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65292;&#32780;&#26080;&#38656;&#20551;&#35774;&#26377;&#19968;&#20010;&#21463;&#20449;&#20219;&#30340;&#20013;&#22830;&#26381;&#21153;&#22120;&#12290;&#22312;&#36825;&#20010;&#38544;&#31169;&#32422;&#26463;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#20010;&#32463;&#20856;&#30340;&#32479;&#35745;&#38382;&#39064;&#65292;&#21363;&#21333;&#21464;&#37327;&#22343;&#20540;&#20272;&#35745;&#12289;&#20302;&#32500;&#32447;&#24615;&#22238;&#24402;&#21644;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#12290;&#36890;&#36807;&#30740;&#31350;&#26497;&#23567;&#20540;&#29575;&#24182;&#30830;&#23450;&#36825;&#20123;&#38382;&#39064;&#30340;&#38544;&#31169;&#25104;&#26412;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32852;&#37030;&#24046;&#20998;&#38544;&#31169;&#26159;&#24050;&#24314;&#31435;&#30340;&#23616;&#37096;&#21644;&#20013;&#22830;&#27169;&#22411;&#20043;&#38388;&#30340;&#19968;&#31181;&#20013;&#38388;&#38544;&#31169;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11343v1 Announce Type: new  Abstract: Federated learning is gaining increasing popularity, with data heterogeneity and privacy being two prominent challenges. In this paper, we address both issues within a federated transfer learning framework, aiming to enhance learning on a target data set by leveraging information from multiple heterogeneous source data sets while adhering to privacy constraints. We rigorously formulate the notion of \textit{federated differential privacy}, which offers privacy guarantees for each data set without assuming a trusted central server. Under this privacy constraint, we study three classical statistical problems, namely univariate mean estimation, low-dimensional linear regression, and high-dimensional linear regression. By investigating the minimax rates and identifying the costs of privacy for these problems, we show that federated differential privacy is an intermediate privacy model between the well-established local and central models of 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#21512;&#21464;&#37327;&#30340;&#26497;&#31471;&#22270;&#27169;&#22411;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#24674;&#22797;&#26465;&#20214;&#22270;&#21644;&#28508;&#21464;&#37327;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.09604</link><description>&lt;p&gt;
&#28151;&#21512;&#21464;&#37327;&#30340;&#26497;&#31471;&#22270;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Extremal graphical modeling with latent variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09604
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#21512;&#21464;&#37327;&#30340;&#26497;&#31471;&#22270;&#27169;&#22411;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#24674;&#22797;&#26465;&#20214;&#22270;&#21644;&#28508;&#21464;&#37327;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26497;&#31471;&#22270;&#27169;&#22411;&#32534;&#30721;&#22810;&#21464;&#37327;&#26497;&#31471;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#65292;&#24182;&#20026;&#37327;&#21270;&#32597;&#35265;&#20107;&#20214;&#39118;&#38505;&#25552;&#20379;&#24378;&#22823;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38754;&#21521;&#28508;&#21464;&#37327;&#30340;&#21487;&#24310;&#20280;&#22270;&#27169;&#22411;&#30340;&#21487;&#34892;&#20984;&#35268;&#21010;&#26041;&#27861;&#65292;&#23558; H\"usler-Reiss &#31934;&#24230;&#30697;&#38453;&#20998;&#35299;&#20026;&#32534;&#30721;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#22270;&#32467;&#26500;&#30340;&#31232;&#30095;&#37096;&#20998;&#21644;&#32534;&#30721;&#23569;&#37327;&#28508;&#21464;&#37327;&#23545;&#35266;&#23519;&#21464;&#37327;&#30340;&#24433;&#21709;&#30340;&#20302;&#31209;&#37096;&#20998;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;\texttt{eglatent}&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#23427;&#33021;&#19968;&#33268;&#22320;&#24674;&#22797;&#26465;&#20214;&#22270;&#20197;&#21450;&#28508;&#21464;&#37327;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09604v1 Announce Type: cross  Abstract: Extremal graphical models encode the conditional independence structure of multivariate extremes and provide a powerful tool for quantifying the risk of rare events. Prior work on learning these graphs from data has focused on the setting where all relevant variables are observed. For the popular class of H\"usler-Reiss models, we propose the \texttt{eglatent} method, a tractable convex program for learning extremal graphical models in the presence of latent variables. Our approach decomposes the H\"usler-Reiss precision matrix into a sparse component encoding the graphical structure among the observed variables after conditioning on the latent variables, and a low-rank component encoding the effect of a few latent variables on the observed variables. We provide finite-sample guarantees of \texttt{eglatent} and show that it consistently recovers the conditional graph as well as the number of latent variables. We highlight the improved 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#36817;&#20284;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#65292;&#25104;&#21151;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#34920;&#29616;&#20986;&#33394;.</title><link>https://arxiv.org/abs/2403.04764</link><description>&lt;p&gt;
&#23558;Thompson&#25277;&#26679;&#36951;&#25022;&#19982;Sigma&#27604;&#29575;&#65288;TS-RSR&#65289;&#26368;&#23567;&#21270;&#65306;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32463;&#36807;&#35777;&#26126;&#30340;&#39640;&#25928;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a provably efficient algorithm for batch Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04764
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#36817;&#20284;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#65292;&#25104;&#21151;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#34920;&#29616;&#20986;&#33394;.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#65292;&#20854;&#20013;&#25277;&#26679;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#26041;&#27861;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#26469;&#36827;&#34892;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#33021;&#22815;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#20013;&#36873;&#25321;&#30340;&#21160;&#20316;&#65292;&#20197;&#26368;&#23567;&#21270;&#28857;&#20043;&#38388;&#30340;&#20887;&#20313;&#65292;&#21516;&#26102;&#20851;&#27880;&#20855;&#26377;&#39640;&#39044;&#27979;&#22343;&#20540;&#25110;&#39640;&#19981;&#30830;&#23450;&#24615;&#30340;&#28857;&#12290;&#25105;&#20204;&#23545;&#31639;&#27861;&#30340;&#36951;&#25022;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#26368;&#21518;&#65292;&#20174;&#25968;&#23383;&#19978;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#31995;&#21015;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#22312;&#24179;&#22343;&#20540;&#19978;&#27604;&#20960;&#20010;&#31454;&#20105;&#23545;&#25163;&#30340;&#22522;&#20934;&#25209;&#37327;BO&#31639;&#27861;&#34920;&#29616;&#25552;&#39640;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04764v1 Announce Type: new  Abstract: This paper presents a new approach for batch Bayesian Optimization (BO), where the sampling takes place by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio. Our objective is able to coordinate the actions chosen in each batch in a way that minimizes redundancy between points whilst focusing on points with high predictive means or high uncertainty. We provide high-probability theoretical guarantees on the regret of our algorithm. Finally, numerically, we demonstrate that our method attains state-of-the-art performance on a range of nonconvex test functions, where it outperforms several competitive benchmark batch BO algorithms by an order of magnitude on average.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#27169;&#22411;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#21644;&#25511;&#21046;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.01810</link><description>&lt;p&gt;
&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#30340;&#38169;&#35823;&#35268;&#33539;&#21270;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Misspecification uncertainties in near-deterministic regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01810
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36817;&#30830;&#23450;&#24615;&#22238;&#24402;&#20013;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#27169;&#22411;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#21644;&#25511;&#21046;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#25439;&#22833;&#26159;&#27169;&#22411;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#21487;&#29992;&#20110;&#23398;&#20064;&#30340;&#40065;&#26834;PAC-Bayes&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#25439;&#22833;&#26368;&#23567;&#21270;&#34987;&#35748;&#20026;&#24573;&#30053;&#20102;&#38169;&#35823;&#35268;&#33539;&#21270;&#65292;&#21363;&#27169;&#22411;&#19981;&#33021;&#23436;&#20840;&#22797;&#21046;&#35266;&#27979;&#32467;&#26524;&#12290;&#36825;&#23548;&#33268;&#22823;&#25968;&#25454;&#25110;&#27424;&#21442;&#25968;&#21270;&#26497;&#38480;&#19979;&#23545;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#26174;&#33879;&#20302;&#20272;&#12290;&#25105;&#20204;&#20998;&#26512;&#36817;&#30830;&#23450;&#24615;&#12289;&#38169;&#35823;&#35268;&#33539;&#21270;&#21644;&#27424;&#21442;&#25968;&#21270;&#26367;&#20195;&#27169;&#22411;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36825;&#26159;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#24191;&#27867;&#30456;&#20851;&#30340;&#19968;&#20010;&#39046;&#22495;&#12290;&#25105;&#20204;&#35777;&#26126;&#21518;&#39564;&#20998;&#24067;&#24517;&#39035;&#35206;&#30422;&#27599;&#20010;&#35757;&#32451;&#28857;&#65292;&#20197;&#36991;&#20813;&#21457;&#25955;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#23548;&#20986;&#19968;&#20010;&#31526;&#21512;&#36825;&#20010;&#32422;&#26463;&#30340;&#32452;&#21512;&#27169;&#22411;&#12290;&#23545;&#20110;&#32447;&#24615;&#27169;&#22411;&#65292;&#36825;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#20135;&#29983;&#30340;&#39069;&#22806;&#24320;&#38144;&#26368;&#23567;&#12290;&#36825;&#31181;&#39640;&#25928;&#26041;&#27861;&#22312;&#27169;&#22411;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#21407;&#23376;&#23610;&#24230;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
The expected loss is an upper bound to the model generalization error which admits robust PAC-Bayes bounds for learning. However, loss minimization is known to ignore misspecification, where models cannot exactly reproduce observations. This leads to significant underestimates of parameter uncertainties in the large data, or underparameterized, limit. We analyze the generalization error of near-deterministic, misspecified and underparametrized surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and derive an ensemble {ansatz} that respects this constraint, which for linear models incurs minimal overhead. The efficient approach is demonstrated on model problems before application to high dimensional datasets in atomistic machine learning. Parameter uncertainties from misspecification survive in the underparametrized limit, giving accurate prediction and boundin
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FRED&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24182;&#19988;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#20854;&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01605</link><description>&lt;p&gt;
&#23545;&#20110;&#25991;&#26412;&#39044;&#27979;&#30340;&#24544;&#23454;&#21644;&#31283;&#20581;&#30340;&#26412;&#22320;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01605
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FRED&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24182;&#19988;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#20854;&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#24615;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#24471;&#21040;&#20449;&#20219;&#21644;&#37096;&#32626;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#27169;&#22411;&#30340;&#26041;&#27861;&#36890;&#24120;&#22797;&#26434;&#65292;&#24182;&#19988;&#32570;&#20047;&#22362;&#23454;&#30340;&#25968;&#23398;&#22522;&#30784;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#20063;&#19981;&#33021;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;FRED&#65288;Faithful and Robust Explainer for textual Documents&#65289;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24403;&#36825;&#20123;&#35789;&#34987;&#31227;&#38500;&#26102;&#23545;&#39044;&#27979;&#32467;&#26524;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#27491;&#24335;&#30340;&#23450;&#20041;&#21644;&#23545;&#21487;&#35299;&#37322;&#20998;&#31867;&#22120;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#30830;&#31435;&#20102;FRED&#30340;&#21487;&#38752;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;FRED&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretability is essential for machine learning models to be trusted and deployed in critical domains. However, existing methods for interpreting text models are often complex, lack solid mathematical foundations, and their performance is not guaranteed. In this paper, we propose FRED (Faithful and Robust Explainer for textual Documents), a novel method for interpreting predictions over text. FRED identifies key words in a document that significantly impact the prediction when removed. We establish the reliability of FRED through formal definitions and theoretical analyses on interpretable classifiers. Additionally, our empirical evaluation against state-of-the-art methods demonstrates the effectiveness of FRED in providing insights into text models.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;EIF+&#21644;ExIFFI&#20004;&#31181;&#25913;&#36827;&#20102;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;&#30340;&#26041;&#27861;&#65292;&#20998;&#21035;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#25512;&#24191;&#33021;&#21147;&#21644;&#35299;&#37322;&#24615;&#33021;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#22312;&#24322;&#24120;&#26816;&#27979;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.05468</link><description>&lt;p&gt;
ExIFFI&#21644;EIF+&#65306;&#35299;&#37322;&#24615;&#21644;&#22686;&#24378;&#30340;&#25512;&#24191;&#33021;&#21147;&#20197;&#25193;&#23637;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
ExIFFI and EIF+: Interpretability and Enhanced Generalizability to Extend the Extended Isolation Forest. (arXiv:2310.05468v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;EIF+&#21644;ExIFFI&#20004;&#31181;&#25913;&#36827;&#20102;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;&#30340;&#26041;&#27861;&#65292;&#20998;&#21035;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#25512;&#24191;&#33021;&#21147;&#21644;&#35299;&#37322;&#24615;&#33021;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#22312;&#24322;&#24120;&#26816;&#27979;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#28041;&#21450;&#22312;&#22797;&#26434;&#25968;&#25454;&#38598;&#21644;&#31995;&#32479;&#20013;&#35782;&#21035;&#24322;&#24120;&#34892;&#20026;&#12290;&#34429;&#28982;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21644;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;DSS&#65289;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#20165;&#20165;&#23450;&#20301;&#24322;&#24120;&#24448;&#24448;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#19981;&#36275;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#29992;&#25143;&#36890;&#24120;&#38656;&#35201;&#20102;&#35299;&#39044;&#27979;&#32972;&#21518;&#30340;&#21407;&#22240;&#65292;&#20197;&#20415;&#36827;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#24182;&#22686;&#24378;&#23545;&#27169;&#22411;&#30340;&#20449;&#20219;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#24322;&#24120;&#26816;&#27979;&#30340;&#26080;&#30417;&#30563;&#24615;&#36136;&#65292;&#21019;&#24314;&#21487;&#35299;&#37322;&#30340;&#24037;&#20855;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;EIF+&#65292;&#36825;&#26159;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;&#65288;EIF&#65289;&#30340;&#22686;&#24378;&#21464;&#20307;&#65292;&#26088;&#22312;&#22686;&#24378;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ExIFFI&#65292;&#19968;&#31181;&#23558;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;&#19982;&#35299;&#37322;&#24615;&#21151;&#33021;&#65288;&#29305;&#24449;&#25490;&#21517;&#65289;&#30456;&#32467;&#21512;&#30340;&#26032;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#25552;&#20379;&#20102;&#20197;&#23396;&#31435;&#22522;&#20110;&#26041;&#27861;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#32508;&#21512;&#27604;&#36739;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anomaly detection, an essential unsupervised machine learning task, involves identifying unusual behaviors within complex datasets and systems. While Machine Learning algorithms and decision support systems (DSSs) offer effective solutions for this task, simply pinpointing anomalies often falls short in real-world applications. Users of these systems often require insight into the underlying reasons behind predictions to facilitate Root Cause Analysis and foster trust in the model. However, due to the unsupervised nature of anomaly detection, creating interpretable tools is challenging. This work introduces EIF+, an enhanced variant of Extended Isolation Forest (EIF), designed to enhance generalization capabilities. Additionally, we present ExIFFI, a novel approach that equips Extended Isolation Forest with interpretability features, specifically feature rankings. Experimental results provide a comprehensive comparative analysis of Isolation-based approaches for Anomaly Detection, incl
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#26680;&#26041;&#27861;&#26159;&#37327;&#23376;&#21644;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#26368;&#33258;&#28982;&#30340;&#32852;&#31995;&#20043;&#19968;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65306;&#36890;&#36807;&#24341;&#20837;&#35745;&#31639;&#26222;&#36866;&#24615;&#65292;&#20219;&#20309;&#26680;&#20989;&#25968;&#37117;&#21487;&#20197;&#34920;&#31034;&#20026;&#37327;&#23376;&#29305;&#24449;&#26144;&#23556;&#21644;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#12290;</title><link>http://arxiv.org/abs/2309.14419</link><description>&lt;p&gt;
&#20851;&#20110;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#30340;&#34920;&#36798;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
On the expressivity of embedding quantum kernels. (arXiv:2309.14419v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14419
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26680;&#26041;&#27861;&#26159;&#37327;&#23376;&#21644;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#26368;&#33258;&#28982;&#30340;&#32852;&#31995;&#20043;&#19968;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65306;&#36890;&#36807;&#24341;&#20837;&#35745;&#31639;&#26222;&#36866;&#24615;&#65292;&#20219;&#20309;&#26680;&#20989;&#25968;&#37117;&#21487;&#20197;&#34920;&#31034;&#20026;&#37327;&#23376;&#29305;&#24449;&#26144;&#23556;&#21644;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26680;&#26041;&#27861;&#30340;&#32972;&#26223;&#19979;&#65292;&#37327;&#23376;&#26680;&#19982;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#24314;&#31435;&#20102;&#26368;&#33258;&#28982;&#30340;&#32852;&#31995;&#12290;&#26680;&#26041;&#27861;&#20381;&#36182;&#20110;&#20869;&#31215;&#29305;&#24449;&#21521;&#37327;&#65292;&#36825;&#20123;&#29305;&#24449;&#21521;&#37327;&#23384;&#22312;&#20110;&#22823;&#22411;&#29305;&#24449;&#31354;&#38388;&#20013;&#12290;&#37327;&#23376;&#26680;&#36890;&#24120;&#36890;&#36807;&#26174;&#24335;&#26500;&#36896;&#37327;&#23376;&#29305;&#24449;&#24577;&#24182;&#35745;&#31639;&#23427;&#20204;&#30340;&#20869;&#31215;&#26469;&#35780;&#20272;&#65292;&#36825;&#37324;&#31216;&#20026;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#12290;&#30001;&#20110;&#32463;&#20856;&#26680;&#36890;&#24120;&#22312;&#19981;&#20351;&#29992;&#29305;&#24449;&#21521;&#37327;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#24819;&#30693;&#36947;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#30340;&#34920;&#36798;&#33021;&#21147;&#22914;&#20309;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;&#26159;&#21542;&#25152;&#26377;&#30340;&#37327;&#23376;&#26680;&#37117;&#21487;&#20197;&#34920;&#36798;&#20026;&#37327;&#23376;&#29305;&#24449;&#24577;&#30340;&#20869;&#31215;&#65311;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#32467;&#26524;&#26159;&#32943;&#23450;&#30340;&#65306;&#36890;&#36807;&#35843;&#29992;&#35745;&#31639;&#26222;&#36866;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#23545;&#20110;&#20219;&#20309;&#26680;&#20989;&#25968;&#65292;&#24635;&#26159;&#23384;&#22312;&#23545;&#24212;&#30340;&#37327;&#23376;&#29305;&#24449;&#26144;&#23556;&#21644;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#12290;&#28982;&#32780;&#65292;&#38382;&#39064;&#26356;&#20851;&#27880;&#30340;&#26159;&#26377;&#25928;&#30340;&#26500;&#36896;&#26041;&#24335;&#12290;&#22312;&#31532;&#20108;&#37096;&#20998;&#20013;
&lt;/p&gt;
&lt;p&gt;
One of the most natural connections between quantum and classical machine learning has been established in the context of kernel methods. Kernel methods rely on kernels, which are inner products of feature vectors living in large feature spaces. Quantum kernels are typically evaluated by explicitly constructing quantum feature states and then taking their inner product, here called embedding quantum kernels. Since classical kernels are usually evaluated without using the feature vectors explicitly, we wonder how expressive embedding quantum kernels are. In this work, we raise the fundamental question: can all quantum kernels be expressed as the inner product of quantum feature states? Our first result is positive: Invoking computational universality, we find that for any kernel function there always exists a corresponding quantum feature map and an embedding quantum kernel. The more operational reading of the question is concerned with efficient constructions, however. In a second part
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.12488</link><description>&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#21644;&#31283;&#23450;&#24615;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;(GD)&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#30340;&#25805;&#20316;&#31526;&#33539;&#25968;&#20250;&#22686;&#38271;&#65292;&#30452;&#21040;&#25509;&#36817;$2/\eta$&#65292;&#20043;&#21518;&#20250;&#22312;&#35813;&#20540;&#21608;&#22260;&#27874;&#21160;&#12290;&#26681;&#25454;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20108;&#27425;&#36924;&#36817;&#65292;$2/\eta$&#34987;&#31216;&#20026;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#12290;&#25105;&#20204;&#20351;&#29992;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#30830;&#23450;&#20102;&#19968;&#20010;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#65292;SAM&#26159;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;GD&#21464;&#31181;&#12290;&#19982;GD&#19981;&#21516;&#65292;SAM&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;&#36890;&#36807;&#19977;&#20010;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#30340;&#23454;&#35777;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;SAM&#22312;&#36825;&#20010;&#20998;&#26512;&#20013;&#30830;&#23450;&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#19978;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value.  The quantity $2/\eta$ has been called the "edge of stability" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an "edge of stability" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21387;&#32553;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;(SCALLION&#21644;SCAFCOM)&#65292;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#32463;&#20856;&#30340;&#38543;&#26426;&#25511;&#21046;&#24179;&#22343;&#27861;&#24182;&#25552;&#20986;&#20102;&#31561;&#20215;&#20294;&#26356;&#39640;&#25928;/&#31616;&#21270;&#30340;&#24418;&#24335;&#65292;&#20943;&#23569;&#20102;&#19978;&#34892;&#36890;&#20449;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2308.08165</link><description>&lt;p&gt;
&#24102;&#26377;&#36890;&#20449;&#21387;&#32553;&#30340;&#38543;&#26426;&#25511;&#21046;&#24179;&#22343;&#27861;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic Controlled Averaging for Federated Learning with Communication Compression. (arXiv:2308.08165v1 [math.OC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21387;&#32553;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;(SCALLION&#21644;SCAFCOM)&#65292;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#32463;&#20856;&#30340;&#38543;&#26426;&#25511;&#21046;&#24179;&#22343;&#27861;&#24182;&#25552;&#20986;&#20102;&#31561;&#20215;&#20294;&#26356;&#39640;&#25928;/&#31616;&#21270;&#30340;&#24418;&#24335;&#65292;&#20943;&#23569;&#20102;&#19978;&#34892;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#20449;&#21387;&#32553;&#26159;&#19968;&#31181;&#26088;&#22312;&#20943;&#23569;&#36890;&#36807;&#26080;&#32447;&#20256;&#36755;&#30340;&#20449;&#24687;&#37327;&#30340;&#25216;&#26415;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#26377;&#28508;&#21147;&#20943;&#36731;&#36890;&#20449;&#24320;&#38144;&#12290;&#28982;&#32780;&#65292;&#36890;&#20449;&#21387;&#32553;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#21253;&#25324;&#21387;&#32553;&#24341;&#36215;&#30340;&#20449;&#24687;&#22833;&#30495;&#20197;&#21450;&#32852;&#37030;&#23398;&#20064;&#30340;&#29305;&#24615;&#65292;&#22914;&#37096;&#20998;&#21442;&#19982;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#26377;&#25152;&#21457;&#23637;&#65292;&#21387;&#32553;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#23578;&#26410;&#20805;&#20998;&#21033;&#29992;&#12290;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#19981;&#33021;&#36866;&#24212;&#20219;&#24847;&#30340;&#25968;&#25454;&#24322;&#26500;&#24615;&#25110;&#37096;&#20998;&#21442;&#19982;&#65292;&#35201;&#20040;&#35201;&#27714;&#23545;&#21387;&#32553;&#26377;&#20005;&#26684;&#30340;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20855;&#26377;&#24320;&#38144;&#20943;&#21322;&#30340;&#19978;&#34892;&#36890;&#20449;&#25104;&#26412;&#30340;&#32463;&#20856;&#38543;&#26426;&#25511;&#21046;&#24179;&#22343;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#21387;&#32553;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;SCALLION&#21644;SCAFCOM&#12290;
&lt;/p&gt;
&lt;p&gt;
Communication compression, a technique aiming to reduce the information volume to be transmitted over the air, has gained great interests in Federated Learning (FL) for the potential of alleviating its communication overhead. However, communication compression brings forth new challenges in FL due to the interplay of compression-incurred information distortion and inherent characteristics of FL such as partial participation and data heterogeneity. Despite the recent development, the performance of compressed FL approaches has not been fully exploited. The existing approaches either cannot accommodate arbitrary data heterogeneity or partial participation, or require stringent conditions on compression.  In this paper, we revisit the seminal stochastic controlled averaging method by proposing an equivalent but more efficient/simplified formulation with halved uplink communication costs. Building upon this implementation, we propose two compressed FL algorithms, SCALLION and SCAFCOM, to s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#39640;&#20998;&#36776;&#29575;&#24494;&#20998;&#26041;&#31243;&#26694;&#26550;&#22238;&#31572;&#20102;Nesterov-1983&#21644;FISTA&#26159;&#21542;&#22312;&#24378;&#20984;&#20989;&#25968;&#19978;&#32447;&#24615;&#25910;&#25947;&#30340;&#38382;&#39064;&#65292;&#24182;&#25351;&#20986;&#32447;&#24615;&#25910;&#25947;&#24615;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#24615;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2306.09694</link><description>&lt;p&gt;
&#20855;&#26377;&#24378;&#20984;&#24615;&#30340; Nesterov-1983 &#30340;&#32447;&#24615;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Linear convergence of Nesterov-1983 with the strong convexity. (arXiv:2306.09694v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#39640;&#20998;&#36776;&#29575;&#24494;&#20998;&#26041;&#31243;&#26694;&#26550;&#22238;&#31572;&#20102;Nesterov-1983&#21644;FISTA&#26159;&#21542;&#22312;&#24378;&#20984;&#20989;&#25968;&#19978;&#32447;&#24615;&#25910;&#25947;&#30340;&#38382;&#39064;&#65292;&#24182;&#25351;&#20986;&#32447;&#24615;&#25910;&#25947;&#24615;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#24615;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#29616;&#20195;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#65292;Nesterov &#30340;&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#27861;&#26159;&#19968;&#20010;&#24320;&#21019;&#24615;&#37324;&#31243;&#30865;&#65292;&#35813;&#26041;&#27861;&#22312;[Nesterov&#65292;1983]&#20013;&#25552;&#20986;&#65292;&#31616;&#31216;&#20026;Nesterov-1983&#12290;&#27492;&#21518;&#65292;&#37325;&#35201;&#30340;&#36827;&#23637;&#20043;&#19968;&#26159;&#23427;&#30340;&#36817;&#31471;&#25512;&#24191;&#65292;&#21517;&#20026;&#24555;&#36895;&#36845;&#20195;&#25910;&#32553;&#38408;&#20540;&#31639;&#27861;&#65288;FISTA&#65289;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#22270;&#20687;&#31185;&#23398;&#21644;&#24037;&#31243;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#20173;&#26410;&#30693;&#36947;Nesterov-1983&#21644;FISTA&#26159;&#21542;&#22312;&#24378;&#20984;&#20989;&#25968;&#19978;&#32447;&#24615;&#25910;&#25947;&#65292;&#32780;&#36825;&#24050;&#34987;&#21015;&#20026;&#32508;&#21512;&#35780;&#23457;[Chambolle&#21644;Pock&#65292;2016&#65292;&#38468;&#24405;B]&#20013;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#39640;&#20998;&#36776;&#29575;&#24494;&#20998;&#26041;&#31243;&#26694;&#26550;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#19982;&#20808;&#21069;&#37319;&#29992;&#30340;&#30456;&#31354;&#38388;&#34920;&#31034;&#19968;&#36215;&#65292;&#26500;&#36896;Lyapunov&#20989;&#25968;&#30340;&#20851;&#38190;&#21306;&#21035;&#22312;&#20110;&#21160;&#33021;&#30340;&#31995;&#25968;&#38543;&#36845;&#20195;&#32780;&#21464;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25351;&#20986;&#65292;&#19978;&#36848;&#20004;&#31181;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#27809;&#26377;&#20381;&#36182;&#20110;&#24378;&#20984;&#20989;&#25968;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
For modern gradient-based optimization, a developmental landmark is Nesterov's accelerated gradient descent method, which is proposed in [Nesterov, 1983], so shorten as Nesterov-1983. Afterward, one of the important progresses is its proximal generalization, named the fast iterative shrinkage-thresholding algorithm (FISTA), which is widely used in image science and engineering. However, it is unknown whether both Nesterov-1983 and FISTA converge linearly on the strongly convex function, which has been listed as the open problem in the comprehensive review [Chambolle and Pock, 2016, Appendix B]. In this paper, we answer this question by the use of the high-resolution differential equation framework. Along with the phase-space representation previously adopted, the key difference here in constructing the Lyapunov function is that the coefficient of the kinetic energy varies with the iteration. Furthermore, we point out that the linear convergence of both the two algorithms above has no d
&lt;/p&gt;</description></item></channel></rss>