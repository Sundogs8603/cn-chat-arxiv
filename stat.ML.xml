<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21644;&#20998;&#26512;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20449;&#24687;&#22686;&#30410;&#30340;&#22522;&#26412;&#24615;&#36136;&#65292;&#21253;&#25324;&#30028;&#38480;&#21644;&#38142;&#35268;&#21017;&#65292;&#38416;&#26126;&#20102;&#22240;&#26524;&#29109;&#19982;&#38543;&#26426;&#24178;&#39044;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#22240;&#26524;&#26465;&#20214;&#29109;&#21644;&#22240;&#26524;&#26465;&#20214;&#20449;&#24687;&#22686;&#30410;&#30340;&#23450;&#20041;&#65292;&#20026;&#25552;&#21319;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01341</link><description>&lt;p&gt;
&#22240;&#26524;&#29109;&#21644;&#20449;&#24687;&#22686;&#30410;&#30340;&#22522;&#26412;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Fundamental Properties of Causal Entropy and Information Gain
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01341
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21644;&#20998;&#26512;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20449;&#24687;&#22686;&#30410;&#30340;&#22522;&#26412;&#24615;&#36136;&#65292;&#21253;&#25324;&#30028;&#38480;&#21644;&#38142;&#35268;&#21017;&#65292;&#38416;&#26126;&#20102;&#22240;&#26524;&#29109;&#19982;&#38543;&#26426;&#24178;&#39044;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#22240;&#26524;&#26465;&#20214;&#29109;&#21644;&#22240;&#26524;&#26465;&#20214;&#20449;&#24687;&#22686;&#30410;&#30340;&#23450;&#20041;&#65292;&#20026;&#25552;&#21319;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#21457;&#23637;&#20351;&#24471;&#33021;&#22815;&#37327;&#21270;&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#19979;&#30340;&#22240;&#26524;&#25511;&#21046;&#12290;&#36825;&#26159;&#36890;&#36807;&#24341;&#20837;&#19968;&#20123;&#37327;&#26469;&#32534;&#30721;&#22312;&#24178;&#39044;&#21478;&#19968;&#20010;&#21464;&#37327;&#26102;&#26576;&#20010;&#21464;&#37327;&#29109;&#30340;&#21464;&#21270;&#26469;&#23454;&#29616;&#30340;&#12290;&#36825;&#20123;&#37327;&#34987;&#21629;&#21517;&#20026;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20449;&#24687;&#22686;&#30410;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#20449;&#24687;&#35770;&#26041;&#27861;&#22312;&#22240;&#26524;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#36215;&#20851;&#38190;&#20316;&#29992;&#26102;&#30340;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21644;&#20998;&#26512;&#36825;&#20123;&#27010;&#24565;&#30340;&#22522;&#26412;&#24615;&#36136;&#65292;&#21253;&#25324;&#30028;&#38480;&#21644;&#38142;&#35268;&#21017;&#65292;&#23545;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20449;&#24687;&#22686;&#30410;&#30340;&#27010;&#24565;&#36827;&#34892;&#20102;&#24418;&#24335;&#19978;&#30340;&#29702;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#22240;&#26524;&#29109;&#19982;&#38543;&#26426;&#24178;&#39044;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#22240;&#26524;&#26465;&#20214;&#29109;&#21644;&#22240;&#26524;&#26465;&#20214;&#20449;&#24687;&#22686;&#30410;&#30340;&#23450;&#20041;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#36825;&#20010;&#25506;&#32034;&#20026;&#25552;&#21319;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent developments enable the quantification of causal control given a structural causal model (SCM). This has been accomplished by introducing quantities which encode changes in the entropy of one variable when intervening on another. These measures, named causal entropy and causal information gain, aim to address limitations in existing information theoretical approaches for machine learning tasks where causality plays a crucial role. They have not yet been properly mathematically studied. Our research contributes to the formal understanding of the notions of causal entropy and causal information gain by establishing and analyzing fundamental properties of these concepts, including bounds and chain rules. Furthermore, we elucidate the relationship between causal entropy and stochastic interventions. We also propose definitions for causal conditional entropy and causal conditional information gain. Overall, this exploration paves the way for enhancing causal machine learning tasks th
&lt;/p&gt;</description></item><item><title>LoRA+&#36890;&#36807;&#35774;&#32622;&#19981;&#21516;&#30340;&#23398;&#20064;&#29575;&#26469;&#25913;&#36827;&#21407;&#22987;LoRA&#30340;&#20302;&#25928;&#29575;&#38382;&#39064;&#65292;&#22312;&#20445;&#25345;&#35745;&#31639;&#25104;&#26412;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#21644;&#24494;&#35843;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.12354</link><description>&lt;p&gt;
LoRA+: &#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#39640;&#25928;&#20302;&#31209;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
LoRA+: Efficient Low Rank Adaptation of Large Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12354
&lt;/p&gt;
&lt;p&gt;
LoRA+&#36890;&#36807;&#35774;&#32622;&#19981;&#21516;&#30340;&#23398;&#20064;&#29575;&#26469;&#25913;&#36827;&#21407;&#22987;LoRA&#30340;&#20302;&#25928;&#29575;&#38382;&#39064;&#65292;&#22312;&#20445;&#25345;&#35745;&#31639;&#25104;&#26412;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#21644;&#24494;&#35843;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26368;&#21021;&#30001;&#32993;&#31561;&#20154;&#65288;2021&#24180;&#65289;&#24341;&#20837;&#65292;&#23548;&#33268;&#23545;&#20855;&#26377;&#22823;&#23485;&#24230;&#65288;&#23884;&#20837;&#32500;&#24230;&#65289;&#30340;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#26102;&#34920;&#29616;&#20122;&#20248;&#12290;&#36825;&#26159;&#22240;&#20026;LoRA&#20013;&#30340;&#36866;&#37197;&#22120;&#30697;&#38453;A&#21644;B&#20351;&#29992;&#30456;&#21516;&#30340;&#23398;&#20064;&#29575;&#36827;&#34892;&#26356;&#26032;&#12290;&#36890;&#36807;&#23545;&#22823;&#23485;&#24230;&#32593;&#32476;&#36827;&#34892;&#32553;&#25918;&#21442;&#25968;&#30340;&#35770;&#35777;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#36866;&#37197;&#22120;&#30697;&#38453;A&#21644;B&#20351;&#29992;&#30456;&#21516;&#30340;&#23398;&#20064;&#29575;&#19981;&#21033;&#20110;&#26377;&#25928;&#30340;&#29305;&#24449;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#34920;&#26126;LoRA&#30340;&#36825;&#31181;&#27425;&#20248;&#24615;&#21487;&#20197;&#31616;&#21333;&#22320;&#36890;&#36807;&#20026;LoRA&#36866;&#37197;&#22120;&#30697;&#38453;A&#21644;B&#35774;&#32622;&#19981;&#21516;&#30340;&#23398;&#20064;&#29575;&#20197;&#21450;&#19968;&#20010;&#31934;&#24515;&#36873;&#25321;&#30340;&#27604;&#29575;&#26469;&#36827;&#34892;&#26657;&#27491;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#25552;&#20986;&#30340;&#31639;&#27861;&#31216;&#20026;LoRA$+$&#12290;&#22312;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20013;&#65292;LoRA$+$&#22312;&#30456;&#21516;&#35745;&#31639;&#25104;&#26412;&#19979;&#25552;&#39640;&#20102;&#24615;&#33021;&#65288;1-2&#65285;&#30340;&#25913;&#36827;&#65289;&#21644;&#24494;&#35843;&#36895;&#24230;&#65288;&#26368;&#22810;&#25552;&#36895;&#32422;2&#20493;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12354v1 Announce Type: cross  Abstract: In this paper, we show that Low Rank Adaptation (LoRA) as originally introduced in Hu et al. (2021) leads to suboptimal finetuning of models with large width (embedding dimension). This is due to the fact that adapter matrices A and B in LoRA are updated with the same learning rate. Using scaling arguments for large width networks, we demonstrate that using the same learning rate for A and B does not allow efficient feature learning. We then show that this suboptimality of LoRA can be corrected simply by setting different learning rates for the LoRA adapter matrices A and B with a well-chosen ratio. We call this proposed algorithm LoRA$+$. In our extensive experiments, LoRA$+$ improves performance (1-2 $\%$ improvements) and finetuning speed (up to $\sim$ 2X SpeedUp), at the same computational cost as LoRA.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26080;&#30417;&#30563;&#23545;&#25239;&#24494;&#35843;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;CLIP&#35270;&#35273;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22686;&#24378;&#21508;&#31181;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#24694;&#24847;&#31532;&#19977;&#26041;&#25552;&#20379;&#25805;&#32437;&#22270;&#20687;&#30340;&#29992;&#25143;&#38544;&#24418;&#25915;&#20987;&#24471;&#20197;&#26460;&#32477;&#12290;</title><link>https://arxiv.org/abs/2402.12336</link><description>&lt;p&gt;
Robust CLIP: &#23545;&#35270;&#35273;&#23884;&#20837;&#36827;&#34892;&#26080;&#30417;&#30563;&#23545;&#25239;&#24494;&#35843;&#20197;&#33719;&#24471;&#24378;&#22823;&#30340;&#22823;&#35268;&#27169;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12336
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#23545;&#25239;&#24494;&#35843;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;CLIP&#35270;&#35273;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22686;&#24378;&#21508;&#31181;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#24694;&#24847;&#31532;&#19977;&#26041;&#25552;&#20379;&#25805;&#32437;&#22270;&#20687;&#30340;&#29992;&#25143;&#38544;&#24418;&#25915;&#20987;&#24471;&#20197;&#26460;&#32477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35832;&#22914;OpenFlamingo&#12289;LLaVA&#21644;GPT-4&#20043;&#31867;&#30340;&#22810;&#27169;&#22411;&#22522;&#30784;&#27169;&#22411;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#29992;&#20110;&#21508;&#31181;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#35270;&#35273;&#27169;&#24577;&#19978;&#26497;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#25915;&#20987;&#21487;&#20197;&#29992;&#26469;&#20256;&#25773;&#34394;&#20551;&#20449;&#24687;&#25110;&#27450;&#39575;&#29992;&#25143;&#65292;&#22240;&#27492;&#26500;&#25104;&#20102;&#19968;&#20010;&#37325;&#22823;&#39118;&#38505;&#65292;&#36825;&#20351;&#24471;&#22823;&#22411;&#22810;&#27169;&#22411;&#22522;&#30784;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#25104;&#20026;&#19968;&#39033;&#32039;&#36843;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#23545;&#25239;&#24494;&#35843;&#26041;&#26696;&#65292;&#20197;&#33719;&#24471;&#24378;&#22823;&#30340;CLIP&#35270;&#35273;&#32534;&#30721;&#22120;&#65292;&#22312;&#25152;&#26377;&#20381;&#36182;&#20110;CLIP&#30340;&#35270;&#35273;&#19979;&#28216;&#20219;&#21153;&#65288;VLMs&#12289;&#38646;&#26679;&#26412;&#20998;&#31867;&#65289;&#19978;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#26086;&#26356;&#25442;&#21407;&#22987;&#30340;CLIP&#27169;&#22411;&#65292;&#29992;&#25143;&#22312;&#20351;&#29992;VLMs&#26102;&#20250;&#21463;&#21040;&#24694;&#24847;&#31532;&#19977;&#26041;&#25552;&#20379;&#30340;&#25805;&#32437;&#22270;&#20687;&#30340;&#28508;&#22312;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12336v1 Announce Type: cross  Abstract: Multi-modal foundation models like OpenFlamingo, LLaVA, and GPT-4 are increasingly used for various real-world tasks. Prior work has shown that these models are highly vulnerable to adversarial attacks on the vision modality. These attacks can be leveraged to spread fake information or defraud users, and thus pose a significant risk, which makes the robustness of large multi-modal foundation models a pressing problem. The CLIP model, or one of its variants, is used as a frozen vision encoder in many vision-language models (VLMs), e.g. LLaVA and OpenFlamingo. We propose an unsupervised adversarial fine-tuning scheme to obtain a robust CLIP vision encoder, which yields robustness on all vision down-stream tasks (VLMs, zero-shot classification) that rely on CLIP. In particular, we show that stealth-attacks on users of VLMs by a malicious third party providing manipulated images are no longer possible once one replaces the original CLIP mo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#29983;&#25104;&#29983;&#23384;&#36712;&#36857;&#21644;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#29305;&#23450;&#32467;&#26500;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#35299;&#20915;&#20102;&#39044;&#27979;&#12289;&#25968;&#25454;&#34917;&#20805;&#21644;&#29983;&#25104;&#21407;&#22411;&#26102;&#38388;&#30456;&#20851;&#36712;&#36857;&#31561;&#20219;&#21153;</title><link>https://arxiv.org/abs/2402.12331</link><description>&lt;p&gt;
&#29983;&#25104;&#29983;&#23384;&#21487;&#35299;&#37322;&#36712;&#36857;&#21644;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Generating Survival Interpretable Trajectories and Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12331
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#29983;&#25104;&#29983;&#23384;&#36712;&#36857;&#21644;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#29305;&#23450;&#32467;&#26500;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#35299;&#20915;&#20102;&#39044;&#27979;&#12289;&#25968;&#25454;&#34917;&#20805;&#21644;&#29983;&#25104;&#21407;&#22411;&#26102;&#38388;&#30456;&#20851;&#36712;&#36857;&#31561;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24212;&#29992;&#29305;&#23450;&#32467;&#26500;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#26469;&#29983;&#25104;&#29983;&#23384;&#36712;&#36857;&#21644;&#25968;&#25454;&#30340;&#26032;&#27169;&#22411;&#12290; &#23427;&#35299;&#20915;&#20102;&#19977;&#20010;&#20219;&#21153;&#12290; &#39318;&#20808;&#65292;&#23427;&#22522;&#20110;Beran&#20272;&#35745;&#22120;&#20026;&#26032;&#29983;&#25104;&#30340;&#29305;&#24449;&#21521;&#37327;&#25552;&#20379;&#20107;&#20214;&#26102;&#38388;&#30340;&#39044;&#27979;&#21644;&#29983;&#23384;&#20989;&#25968;&#30340;&#24418;&#24335;&#12290; &#31532;&#20108;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#32473;&#23450;&#30340;&#35757;&#32451;&#38598;&#29983;&#25104;&#39069;&#22806;&#25968;&#25454;&#65292;&#21487;&#20197;&#34917;&#20805;&#21407;&#22987;&#25968;&#25454;&#38598;&#12290; &#31532;&#19977;&#65292;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#23427;&#20026;&#23545;&#35937;&#29983;&#25104;&#20102;&#19968;&#20010;&#21407;&#22411;&#26102;&#38388;&#30456;&#20851;&#36712;&#36857;&#65292;&#25551;&#36848;&#20102;&#22914;&#20309;&#25913;&#21464;&#23545;&#35937;&#30340;&#29305;&#24449;&#20197;&#23454;&#29616;&#19981;&#21516;&#26102;&#38388;&#20107;&#20214;&#30340;&#26102;&#38388;&#12290; &#36712;&#36857;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#31181;&#21453;&#20107;&#23454;&#35299;&#37322;&#12290; &#30001;&#20110;&#23558;&#29305;&#23450;&#21152;&#26435;&#26041;&#26696;&#32435;&#20837;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#20013;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#35757;&#32451;&#21644;&#25512;&#29702;&#36807;&#31243;&#20013;&#34920;&#29616;&#20986;&#40065;&#26834;&#24615;&#12290; &#35813;&#27169;&#22411;&#36824;&#36890;&#36807;&#35299;&#20915;&#20998;&#31867;&#38382;&#39064;&#30830;&#23450;&#20102;&#26032;&#29983;&#25104;&#25968;&#25454;&#30340;&#34987;&#23457;&#26597;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12331v1 Announce Type: cross  Abstract: A new model for generating survival trajectories and data based on applying an autoencoder of a specific structure is proposed. It solves three tasks. First, it provides predictions in the form of the expected event time and the survival function for a new generated feature vector on the basis of the Beran estimator. Second, the model generates additional data based on a given training set that would supplement the original dataset. Third, the most important, it generates a prototype time-dependent trajectory for an object, which characterizes how features of the object could be changed to achieve a different time to an event. The trajectory can be viewed as a type of the counterfactual explanation. The proposed model is robust during training and inference due to a specific weighting scheme incorporating into the variational autoencoder. The model also determines the censored indicators of new generated data by solving a classificatio
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#35889;&#32858;&#31867;&#20013;&#29305;&#24449;&#21521;&#37327;&#30340;&#28176;&#36817;&#39640;&#26031;&#27874;&#21160;&#29616;&#35937;&#65292;&#20026;&#31934;&#30830;&#39044;&#27979;&#35889;&#32858;&#31867;&#30340;&#20998;&#31867;&#24615;&#33021;&#25552;&#20379;&#20102;&#37325;&#35201;&#20381;&#25454;&#12290;</title><link>https://arxiv.org/abs/2402.12302</link><description>&lt;p&gt;
&#35889;&#32858;&#31867;&#20013;&#29305;&#24449;&#21521;&#37327;&#30340;&#28176;&#36817;&#39640;&#26031;&#27874;&#21160;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Gaussian Fluctuations of Eigenvectors in Spectral Clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12302
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#35889;&#32858;&#31867;&#20013;&#29305;&#24449;&#21521;&#37327;&#30340;&#28176;&#36817;&#39640;&#26031;&#27874;&#21160;&#29616;&#35937;&#65292;&#20026;&#31934;&#30830;&#39044;&#27979;&#35889;&#32858;&#31867;&#30340;&#20998;&#31867;&#24615;&#33021;&#25552;&#20379;&#20102;&#37325;&#35201;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35889;&#32858;&#31867;&#30340;&#24615;&#33021;&#20381;&#36182;&#20110;&#30456;&#20284;&#30697;&#38453;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#26465;&#30446;&#27874;&#21160;&#65292;&#35813;&#27874;&#21160;&#30452;&#21040;&#29616;&#22312;&#20173;&#26410;&#24471;&#21040;&#25551;&#36848;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#19968;&#33324;&#23574;&#23792;&#38543;&#26426;&#30697;&#38453;&#27169;&#22411;&#30340;&#20449;&#21495;+&#22122;&#22768;&#32467;&#26500;&#34987;&#36716;&#31227;&#21040;&#30456;&#24212;&#30340;&#26684;&#25289;&#22982;&#26680;&#30697;&#38453;&#30340;&#29305;&#24449;&#21521;&#37327;&#19978;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#26465;&#30446;&#27874;&#21160;&#22312;&#22823;&#32500;&#24230;&#21306;&#22495;&#21576;&#39640;&#26031;&#20998;&#24067;&#12290;&#36825;&#31181;&#31867;&#20284;&#20110;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#30340;&#32467;&#26524;&#26159;&#20934;&#30830;&#39044;&#27979;&#35889;&#32858;&#31867;&#30340;&#20998;&#31867;&#24615;&#33021;&#30340;&#26368;&#21518;&#19968;&#22359;&#32570;&#22833;&#30340;&#25340;&#22270;&#12290;&#25552;&#20986;&#30340;&#35777;&#26126;&#38750;&#24120;&#36890;&#29992;&#65292;&#20165;&#20381;&#36182;&#20110;&#22122;&#22768;&#30340;&#26059;&#36716;&#19981;&#21464;&#24615;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#20102;&#36825;&#20010;&#29616;&#35937;&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12302v1 Announce Type: cross  Abstract: The performance of spectral clustering relies on the fluctuations of the entries of the eigenvectors of a similarity matrix, which has been left uncharacterized until now. In this letter, it is shown that the signal $+$ noise structure of a general spike random matrix model is transferred to the eigenvectors of the corresponding Gram kernel matrix and the fluctuations of their entries are Gaussian in the large-dimensional regime. This CLT-like result was the last missing piece to precisely predict the classification performance of spectral clustering. The proposed proof is very general and relies solely on the rotational invariance of the noise. Numerical experiments on synthetic and real data illustrate the universality of this phenomenon.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#39537;&#21160;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#34701;&#20837;&#27010;&#29575;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#21435;&#22122;&#30340;&#26041;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#22270;&#20687;&#21453;&#28436;&#20219;&#21153;&#20013;&#65292;&#22312;&#25104;&#20687;&#20013;&#25512;&#21160;&#20102;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;</title><link>https://arxiv.org/abs/2402.12292</link><description>&lt;p&gt;
&#27491;&#21017;&#21270;&#21435;&#22122;&#65306;&#36125;&#21494;&#26031;&#27169;&#22411;&#21644;&#38543;&#21518;&#30340;Langevin-within-split Gibbs&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Regularization by denoising: Bayesian model and Langevin-within-split Gibbs sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12292
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#39537;&#21160;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#34701;&#20837;&#27010;&#29575;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#21435;&#22122;&#30340;&#26041;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#22270;&#20687;&#21453;&#28436;&#20219;&#21153;&#20013;&#65292;&#22312;&#25104;&#20687;&#20013;&#25512;&#21160;&#20102;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#19968;&#20010;&#27010;&#29575;&#21270;&#30340;&#30456;&#23545;&#24212;&#20110;&#27491;&#21017;&#21270;&#21435;&#22122;&#65288;RED&#65289;&#33539;&#24335;&#30340;&#26041;&#27861;&#23454;&#29616;&#23545;&#22270;&#20687;&#21453;&#28436;&#12290;&#27492;&#22806;&#65292;&#23427;&#23454;&#29616;&#20102;&#19968;&#20010;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#20174;&#25152;&#24471;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#22522;&#20110;&#28176;&#36817;&#31934;&#30830;&#25968;&#25454;&#22686;&#24191;&#65288;AXDA&#65289;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#19968;&#20010;&#23884;&#20837;&#20102;&#19968;&#20010;Langevin&#33945;&#29305;&#21345;&#27931;&#27493;&#39588;&#30340;&#25286;&#20998;Gibbs&#37319;&#26679;&#65288;SGS&#65289;&#30340;&#36817;&#20284;&#23454;&#20363;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#24120;&#35265;&#30340;&#25104;&#20687;&#20219;&#21153;&#65292;&#22914;&#21435;&#27169;&#31946;&#12289;&#20462;&#34917;&#21644;&#36229;&#20998;&#36776;&#29575;&#65292;&#36890;&#36807;&#22823;&#37327;&#30340;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#36825;&#20123;&#36129;&#29486;&#36890;&#36807;&#22312;&#27010;&#29575;&#26694;&#26550;&#20869;&#21033;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#65292;&#20419;&#36827;&#20102;&#25104;&#20687;&#20013;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12292v1 Announce Type: cross  Abstract: This paper introduces a Bayesian framework for image inversion by deriving a probabilistic counterpart to the regularization-by-denoising (RED) paradigm. It additionally implements a Monte Carlo algorithm specifically tailored for sampling from the resulting posterior distribution, based on an asymptotically exact data augmentation (AXDA). The proposed algorithm is an approximate instance of split Gibbs sampling (SGS) which embeds one Langevin Monte Carlo step. The proposed method is applied to common imaging tasks such as deblurring, inpainting and super-resolution, demonstrating its efficacy through extensive numerical experiments. These contributions advance Bayesian inference in imaging by leveraging data-driven regularization strategies within a probabilistic framework.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#19981;&#21516;&#25968;&#25454;&#22495;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#65292;&#25512;&#27979;&#20102;&#27169;&#22411;&#23545;&#29305;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2402.12264</link><description>&lt;p&gt;
&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification in fine-tuned LLMs using LoRA ensembles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12264
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#19981;&#21516;&#25968;&#25454;&#22495;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#65292;&#25512;&#27979;&#20102;&#27169;&#22411;&#23545;&#29305;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#29305;&#23450;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#23613;&#31649;&#23545;&#20110;&#31934;&#35843;&#27169;&#22411;&#23398;&#21040;&#20102;&#20160;&#20040;&#12289;&#36951;&#24536;&#20102;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#20449;&#20219;&#20854;&#39044;&#27979;&#20173;&#28982;&#32570;&#20047;&#19968;&#20010;&#19968;&#33324;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#23545;&#31934;&#35843;LLMs&#36827;&#34892;&#22522;&#20110;&#21518;&#39564;&#36924;&#36817;&#30340;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;Mistral-7b&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#20102;&#19977;&#20010;&#24120;&#35265;&#30340;&#22810;&#39033;&#36873;&#25321;&#25968;&#25454;&#38598;&#65292;&#24182;&#23545;&#20854;&#22312;&#31934;&#35843;&#36807;&#31243;&#20013;&#21644;&#20043;&#21518;&#23545;&#19981;&#21516;&#30446;&#26631;&#39046;&#22495;&#30340;&#24863;&#30693;&#22797;&#26434;&#24615;&#21644;&#27169;&#22411;&#25928;&#33021;&#36827;&#34892;&#20102;&#23450;&#37327;&#21644;&#23450;&#24615;&#30340;&#32467;&#35770;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22522;&#20110;&#25968;&#20540;&#23454;&#39564;&#25903;&#25345;&#65292;&#25105;&#20204;&#23545;&#37027;&#20123;&#23545;&#20110;&#32473;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#29109;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#25552;&#20986;&#20102;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12264v1 Announce Type: cross  Abstract: Fine-tuning large language models can improve task specific performance, although a general understanding of what the fine-tuned model has learned, forgotten and how to trust its predictions is still missing. We derive principled uncertainty quantification for fine-tuned LLMs with posterior approximations using computationally efficient low-rank adaptation ensembles. We analyze three common multiple-choice datasets using low-rank adaptation ensembles based on Mistral-7b, and draw quantitative and qualitative conclusions on their perceived complexity and model efficacy on the different target domains during and after fine-tuning. In particular, backed by the numerical experiments, we hypothesise about signals from entropic uncertainty measures for data domains that are inherently difficult for a given architecture to learn.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#22312;&#21160;&#24577;&#31995;&#32479;&#20013;&#21033;&#29992;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#22312;&#19981;&#38656;&#35201;&#28023;&#37327;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12241</link><description>&lt;p&gt;
&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#25910;&#25947;&#24615;&#65306;&#38750;&#28176;&#36817;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence of Gradient Descent for Recurrent Neural Networks: A Nonasymptotic Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12241
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#22312;&#21160;&#24577;&#31995;&#32479;&#20013;&#21033;&#29992;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#22312;&#19981;&#38656;&#35201;&#28023;&#37327;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#22312;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#19979;&#21033;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#22312;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#22312;\emph{&#19981;}&#38656;&#35201;&#28023;&#37327;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#38750;&#28176;&#36817;&#24615;&#20998;&#26512;&#65292;(i)&#21033;&#29992;&#24207;&#21015;&#38271;&#24230;$T$&#12289;&#26679;&#26412;&#22823;&#23567;$n$&#21644;&#29615;&#22659;&#32500;&#24230;$d$&#32473;&#20986;&#20102;&#32593;&#32476;&#22823;&#23567;$m$&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;$\tau$&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;(ii)&#30830;&#23450;&#20102;&#21160;&#24577;&#31995;&#32479;&#20013;&#38271;&#26399;&#20381;&#36182;&#23545;&#25910;&#25947;&#21644;&#32593;&#32476;&#23485;&#24230;&#30028;&#38480;&#30340;&#26174;&#30528;&#24433;&#21709;&#65292;&#36825;&#20123;&#30028;&#38480;&#30001;&#28608;&#27963;&#20989;&#25968;&#30340;Lipschitz&#36830;&#32493;&#24615;&#20915;&#23450;&#30340;&#25130;&#27490;&#28857;&#26469;&#34920;&#24449;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#19968;&#20998;&#26512;&#25581;&#31034;&#20102;&#19968;&#20010;&#22949;&#21892;&#21021;&#22987;&#21270;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#22312;$n$&#20010;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#32593;&#32476;&#22823;&#23567;$m$&#20165;&#23545;&#25968;&#22320;&#38543;$n$&#25193;&#23637;&#23601;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;&#36825;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65292;&#21069;&#32773;&#38656;&#35201;&#39640;&#38454;&#22810;&#39033;&#24335;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12241v1 Announce Type: new  Abstract: We analyze recurrent neural networks trained with gradient descent in the supervised learning setting for dynamical systems, and prove that gradient descent can achieve optimality \emph{without} massive overparameterization. Our in-depth nonasymptotic analysis (i) provides sharp bounds on the network size $m$ and iteration complexity $\tau$ in terms of the sequence length $T$, sample size $n$ and ambient dimension $d$, and (ii) identifies the significant impact of long-term dependencies in the dynamical system on the convergence and network width bounds characterized by a cutoff point that depends on the Lipschitz continuity of the activation function. Remarkably, this analysis reveals that an appropriately-initialized recurrent neural network trained with $n$ samples can achieve optimality with a network size $m$ that scales only logarithmically with $n$. This sharply contrasts with the prior works that require high-order polynomial dep
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#30340;&#26080;&#30417;&#30563;&#20108;&#21449;&#26641;&#29992;&#20110;&#32858;&#31867;&#65292;&#31216;&#20026;Kauri&#65292;&#36890;&#36807;&#36138;&#23146;&#26368;&#22823;&#21270; kernel KMeans &#30446;&#26631;&#26469;&#25191;&#34892;&#65292;&#26080;&#38656;&#23450;&#20041;&#36136;&#24515;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20854;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.12232</link><description>&lt;p&gt;
&#23558; Kernel KMeans &#32858;&#31867;&#25286;&#20998;&#29992;&#20110;&#31471;&#21040;&#31471;&#26080;&#30417;&#30563;&#20915;&#31574;&#26641;
&lt;/p&gt;
&lt;p&gt;
Kernel KMeans clustering splits for end-to-end unsupervised decision trees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12232
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#30340;&#26080;&#30417;&#30563;&#20108;&#21449;&#26641;&#29992;&#20110;&#32858;&#31867;&#65292;&#31216;&#20026;Kauri&#65292;&#36890;&#36807;&#36138;&#23146;&#26368;&#22823;&#21270; kernel KMeans &#30446;&#26631;&#26469;&#25191;&#34892;&#65292;&#26080;&#38656;&#23450;&#20041;&#36136;&#24515;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20854;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26641;&#26159;&#33719;&#21462;&#23545;&#30456;&#23545;&#36739;&#23567;&#25968;&#25454;&#38598;&#36827;&#34892;&#21487;&#35299;&#37322;&#39044;&#27979;&#30340;&#20415;&#21033;&#27169;&#22411;&#12290;&#34429;&#28982;&#26377;&#24456;&#22810;&#20851;&#20110;&#30417;&#30563;&#23398;&#20064;&#20013;&#31471;&#21040;&#31471;&#26500;&#24314;&#36825;&#31181;&#26641;&#30340;&#25552;&#35758;&#65292;&#20294;&#22312;&#27809;&#26377;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#29992;&#20110;&#32858;&#31867;&#30340;&#26641;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#20316;&#21697;&#20027;&#35201;&#38598;&#20013;&#20110;&#20351;&#29992;&#26641;&#26469;&#35299;&#37322;&#21478;&#19968;&#20010;&#32858;&#31867;&#31639;&#27861;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#22312;&#36825;&#37324;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#30340;&#26080;&#30417;&#30563;&#20108;&#21449;&#26641;&#29992;&#20110;&#32858;&#31867;&#65306;Kauri&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#36138;&#23146;&#26368;&#22823;&#21270; kernel KMeans &#30446;&#26631;&#26469;&#25191;&#34892;&#65292;&#32780;&#26080;&#38656;&#23450;&#20041;&#36136;&#24515;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23558;&#27492;&#27169;&#22411;&#19982;&#26368;&#36817;&#30340;&#26080;&#30417;&#30563;&#26641;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#23637;&#31034;&#24403;&#20351;&#29992;&#32447;&#24615;&#26680;&#26102;&#65292;Kauri &#30340;&#24615;&#33021;&#30456;&#21516;&#12290;&#23545;&#20110;&#20854;&#20182;&#20869;&#26680;&#65292;Kauri &#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#34920;&#29616;&#20248;&#20110;&#20869;&#26680; KMeans &#21644; CART &#20915;&#31574;&#26641;&#30340;&#20018;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12232v1 Announce Type: cross  Abstract: Trees are convenient models for obtaining explainable predictions on relatively small datasets. Although there are many proposals for the end-to-end construction of such trees in supervised learning, learning a tree end-to-end for clustering without labels remains an open challenge. As most works focus on interpreting with trees the result of another clustering algorithm, we present here a novel end-to-end trained unsupervised binary tree for clustering: Kauri. This method performs a greedy maximisation of the kernel KMeans objective without requiring the definition of centroids. We compare this model on multiple datasets with recent unsupervised trees and show that Kauri performs identically when using a linear kernel. For other kernels, Kauri often outperforms the concatenation of kernel KMeans and a CART decision tree.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#21453;&#20107;&#23454;&#30284;&#30151;&#27835;&#30103;&#24314;&#35758;&#65292;&#38598;&#25104;&#20102;&#22810;&#31181;&#22810;&#32452;&#23398;&#25216;&#26415;&#30340;&#19987;&#23478;&#65292;&#21487;&#25552;&#20379;&#20248;&#36234;&#24615;&#33021;&#21644;&#20915;&#31574;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2402.12190</link><description>&lt;p&gt;
&#22522;&#20110;AI&#30340;&#31934;&#20934;&#32959;&#30244;&#23398;&#65306;&#22522;&#20110;&#22810;&#32452;&#23398;&#25968;&#25454;&#30340;&#20010;&#24615;&#21270;&#21453;&#20107;&#23454;&#27835;&#30103;&#24314;&#35758;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Towards AI-Based Precision Oncology: A Machine Learning Framework for Personalized Counterfactual Treatment Suggestions based on Multi-Omics Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12190
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#21453;&#20107;&#23454;&#30284;&#30151;&#27835;&#30103;&#24314;&#35758;&#65292;&#38598;&#25104;&#20102;&#22810;&#31181;&#22810;&#32452;&#23398;&#25216;&#26415;&#30340;&#19987;&#23478;&#65292;&#21487;&#25552;&#20379;&#20248;&#36234;&#24615;&#33021;&#21644;&#20915;&#31574;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#39537;&#21160;&#30340;&#31934;&#20934;&#32959;&#30244;&#23398;&#20855;&#26377;&#36890;&#36807;&#21033;&#29992;AI&#27169;&#22411;&#20998;&#26512;&#22797;&#26434;&#24739;&#32773;&#29305;&#24449;&#19982;&#23545;&#24212;&#27835;&#30103;&#32467;&#26524;&#20043;&#38388;&#20114;&#21160;&#30340;&#28508;&#21147;&#65292;&#26377;&#26395;&#37325;&#22609;&#30284;&#30151;&#27835;&#30103;&#12290;&#26032;&#25216;&#26415;&#24179;&#21488;&#20419;&#36827;&#20102;&#21450;&#26102;&#33719;&#21462;&#22810;&#27169;&#24577;&#32959;&#30244;&#29983;&#29289;&#23398;&#25968;&#25454;&#65292;&#22914;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#25968;&#25454;&#65292;&#20351;&#24471;&#36825;&#31181;&#25968;&#25454;&#30340;&#36136;&#37327;&#21644;&#25968;&#37327;&#21487;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#25913;&#36827;&#20020;&#24202;&#20915;&#31574;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22359;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#22522;&#20110;&#35757;&#32451;&#26377;&#20851;&#22810;&#31181;&#22810;&#32452;&#23398;&#25216;&#26415;&#30340;&#26426;&#22120;&#23398;&#20064;&#19987;&#23478;&#32452;&#25104;&#30340;&#38598;&#25104;&#26469;&#36827;&#34892;&#20010;&#24615;&#21270;&#21453;&#20107;&#23454;&#30284;&#30151;&#27835;&#30103;&#24314;&#35758;&#12290;&#36825;&#20123;&#19987;&#38376;&#30340;&#21453;&#20107;&#23454;&#19987;&#23478;&#26681;&#25454;&#25216;&#26415;&#19981;&#26029;&#32858;&#21512;&#20026;&#24615;&#33021;&#26356;&#20248;&#36234;&#30340;&#19987;&#23478;&#65292;&#21487;&#25552;&#20379;&#20915;&#31574;&#30340;&#32622;&#20449;&#24230;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12190v1 Announce Type: cross  Abstract: AI-driven precision oncology has the transformative potential to reshape cancer treatment by leveraging the power of AI models to analyze the interaction between complex patient characteristics and their corresponding treatment outcomes. New technological platforms have facilitated the timely acquisition of multimodal data on tumor biology at an unprecedented resolution, such as single-cell multi-omics data, making this quality and quantity of data available for data-driven improved clinical decision-making. In this work, we propose a modular machine learning framework designed for personalized counterfactual cancer treatment suggestions based on an ensemble of machine learning experts trained on diverse multi-omics technologies. These specialized counterfactual experts per technology are consistently aggregated into a more powerful expert with superior performance and can provide both confidence and an explanation of its decision. The
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#26368;&#23567;&#26497;&#23567;&#36951;&#25022;&#30340;&#22810;&#23545;&#25968;&#32553;&#25918;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#23454;&#29616;&#23545;&#35774;&#35745;&#30697;&#38453;&#29305;&#24449;&#20540;&#20851;&#31995;&#30340;&#25511;&#21046;&#65292;&#23454;&#29616;&#20102;&#32047;&#31215;&#36951;&#25022;&#30340;&#23545;&#25968;&#32553;&#25918;&#12290;</title><link>https://arxiv.org/abs/2402.12042</link><description>&lt;p&gt;
&#20855;&#26377;&#22810;&#23545;&#25968;&#26497;&#23567;&#26497;&#23567;&#36951;&#25022;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Linear bandits with polylogarithmic minimax regret
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12042
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#26368;&#23567;&#26497;&#23567;&#36951;&#25022;&#30340;&#22810;&#23545;&#25968;&#32553;&#25918;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#23454;&#29616;&#23545;&#35774;&#35745;&#30697;&#38453;&#29305;&#24449;&#20540;&#20851;&#31995;&#30340;&#25511;&#21046;&#65292;&#23454;&#29616;&#20102;&#32047;&#31215;&#36951;&#25022;&#30340;&#23545;&#25968;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#26426;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#23545;&#20110;&#35813;&#27169;&#22411;&#65292;&#24403;&#25105;&#20204;&#36873;&#25321;&#36234;&#26469;&#36234;&#25509;&#36817;&#26410;&#30693;&#21521;&#37327;&#30340;&#21333;&#20301;&#29699;&#19978;&#30340;&#21160;&#20316;&#26102;&#65292;&#20122;&#39640;&#26031;&#22122;&#22768;&#21442;&#25968;&#20197;&#32447;&#24615;&#26041;&#24335;&#28040;&#22833;&#12290;&#25105;&#20204;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#24341;&#20837;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20854;&#22312;&#26102;&#38388;&#38271;&#24230;$T$&#30340;&#24773;&#20917;&#19979;&#21576;&#23545;&#25968;$^3&#65288;T&#65289;$&#30340;&#26368;&#23567;&#36951;&#25022;&#32553;&#25918;&#65292;&#19982;&#20856;&#22411;&#36172;&#21338;&#26426;&#31639;&#27861;&#30340;&#24179;&#26041;&#26681;&#36951;&#25022;&#32553;&#25918;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#25105;&#20204;&#30340;&#31574;&#30053;&#22522;&#20110;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#36890;&#36807;&#20960;&#20309;&#35770;&#35777;&#23454;&#29616;&#20102;&#35774;&#35745;&#30697;&#38453;$V_t$&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;$t$&#22788;&#30340;&#29305;&#24449;&#20540;&#20851;&#31995;$\lambda_{\min} ( V_t ) = \Omega (\sqrt{\lambda_{\max}(V_t ) })$&#65292;&#36825;&#20123;&#20960;&#20309;&#35770;&#35777;&#19982;&#22122;&#22768;&#27169;&#22411;&#26080;&#20851;&#65292;&#24182;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20005;&#26684;&#25511;&#21046;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#26399;&#26395;&#36951;&#25022;&#20026;$O(\frac1{t})$&#30340;&#25968;&#37327;&#32423;&#65292;&#20174;&#32780;&#23548;&#33268;&#32047;&#31215;&#36951;&#25022;&#30340;&#23545;&#25968;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12042v1 Announce Type: cross  Abstract: We study a noise model for linear stochastic bandits for which the subgaussian noise parameter vanishes linearly as we select actions on the unit sphere closer and closer to the unknown vector. We introduce an algorithm for this problem that exhibits a minimax regret scaling as $\log^3(T)$ in the time horizon $T$, in stark contrast the square root scaling of this regret for typical bandit algorithms. Our strategy, based on weighted least-squares estimation, achieves the eigenvalue relation $\lambda_{\min} ( V_t ) = \Omega (\sqrt{\lambda_{\max}(V_t ) })$ for the design matrix $V_t$ at each time step $t$ through geometrical arguments that are independent of the noise model and might be of independent interest. This allows us to tightly control the expected regret in each time step to be of the order $O(\frac1{t})$, leading to the logarithmic scaling of the cumulative regret.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#31163;&#31574;&#30053;&#21644;&#22312;&#31574;&#30053;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#39318;&#27425;&#25552;&#20986;&#20102;&#20943;&#23567;&#35813;&#24046;&#36317;&#30340;&#26465;&#20214;&#65292;&#21516;&#26102;&#21457;&#29616;&#22312;&#26465;&#20214;&#19981;&#28385;&#36275;&#26102;&#20250;&#20135;&#29983;&#30701;&#26495;&#12290;</title><link>https://arxiv.org/abs/2402.12034</link><description>&lt;p&gt;
&#31163;&#31574;&#30053;&#21644;&#22312;&#31574;&#30053;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#20309;&#26102;&#33021;&#22815;&#19968;&#33268;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Do Off-Policy and On-Policy Policy Gradient Methods Align?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12034
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#31163;&#31574;&#30053;&#21644;&#22312;&#31574;&#30053;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#39318;&#27425;&#25552;&#20986;&#20102;&#20943;&#23567;&#35813;&#24046;&#36317;&#30340;&#26465;&#20214;&#65292;&#21516;&#26102;&#21457;&#29616;&#22312;&#26465;&#20214;&#19981;&#28385;&#36275;&#26102;&#20250;&#20135;&#29983;&#30701;&#26495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#26159;&#24191;&#27867;&#37319;&#29992;&#30340;&#22312;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#21462;&#24471;&#25104;&#21151;&#65292;&#28982;&#32780;&#30001;&#20110;&#20854;&#33261;&#21517;&#26157;&#33879;&#30340;&#26679;&#26412;&#25928;&#29575;&#20302;&#65292;&#23427;&#20204;&#30340;&#20351;&#29992;&#20173;&#28982;&#23616;&#38480;&#20110;&#21487;&#20197;&#24555;&#36895;&#20934;&#30830;&#27169;&#25311;&#30340;&#38382;&#39064;&#12290;&#25913;&#36827;&#26679;&#26412;&#25928;&#29575;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#20462;&#25913;&#23427;&#20204;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20351;&#20043;&#33021;&#22815;&#20174;&#31163;&#31574;&#30053;&#26679;&#26412;&#20013;&#35745;&#31639;&#32780;&#26080;&#38656;&#37325;&#35201;&#24615;&#37319;&#26679;&#12290;&#19968;&#20010;&#25104;&#29087;&#30340;&#31163;&#31574;&#30053;&#30446;&#26631;&#23601;&#26159;&#28216;&#33633;&#30446;&#26631;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#28216;&#33633;&#30446;&#26631;&#19982;&#20256;&#32479;&#22312;&#31574;&#30053;&#30446;&#26631;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#22312;&#31163;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#29702;&#35770;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#20943;&#23569;&#22312;&#31163;&#24046;&#36317;&#30340;&#26465;&#20214;&#65292;&#21516;&#26102;&#24314;&#31435;&#20102;&#24403;&#36825;&#20123;&#26465;&#20214;&#26410;&#34987;&#28385;&#36275;&#26102;&#20986;&#29616;&#30340;&#32570;&#38519;&#30340;&#32463;&#39564;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12034v1 Announce Type: cross  Abstract: Policy gradient methods are widely adopted reinforcement learning algorithms for tasks with continuous action spaces. These methods succeeded in many application domains, however, because of their notorious sample inefficiency their use remains limited to problems where fast and accurate simulations are available. A common way to improve sample efficiency is to modify their objective function to be computable from off-policy samples without importance sampling. A well-established off-policy objective is the excursion objective. This work studies the difference between the excursion objective and the traditional on-policy objective, which we refer to as the on-off gap. We provide the first theoretical analysis showing conditions to reduce the on-off gap while establishing empirical evidence of shortfalls arising when these conditions are not met.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#28085;&#30422;&#25152;&#26377;&#23454;&#38469;&#24773;&#20917;&#30340;Wasserstein&#20998;&#24067;&#40065;&#26834;&#27169;&#22411;&#30830;&#20999;&#27867;&#21270;&#20445;&#35777;&#65292;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#20256;&#36755;&#25104;&#26412;&#20989;&#25968;&#21644;&#25439;&#22833;&#20989;&#25968;&#65292;&#21253;&#25324;&#28145;&#24230;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.11981</link><description>&lt;p&gt;
Wasserstein&#20998;&#24067;&#40065;&#26834;&#27169;&#22411;&#30340;&#36890;&#29992;&#27867;&#21270;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Universal Generalization Guarantees for Wasserstein Distributionally Robust Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#28085;&#30422;&#25152;&#26377;&#23454;&#38469;&#24773;&#20917;&#30340;Wasserstein&#20998;&#24067;&#40065;&#26834;&#27169;&#22411;&#30830;&#20999;&#27867;&#21270;&#20445;&#35777;&#65292;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#20256;&#36755;&#25104;&#26412;&#20989;&#25968;&#21644;&#25439;&#22833;&#20989;&#25968;&#65292;&#21253;&#25324;&#28145;&#24230;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#31283;&#20581;&#20248;&#21270;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#35757;&#32451;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21560;&#24341;&#20154;&#26041;&#24335;&#65292;&#33021;&#22815;&#25429;&#25417;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#26368;&#36817;&#30340;&#32479;&#35745;&#20998;&#26512;&#35777;&#26126;&#65292;&#22522;&#20110;Wasserstein&#27169;&#31946;&#38598;&#26500;&#24314;&#30340;&#40065;&#26834;&#27169;&#22411;&#20855;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#25171;&#30772;&#20102;&#32500;&#24230;&#28798;&#38590;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26524;&#26159;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#33719;&#24471;&#30340;&#65292;&#20197;&#36817;&#20284;&#20195;&#20215;&#33719;&#24471;&#65292;&#25110;&#32773;&#22312;&#23454;&#36341;&#20013;&#38590;&#20197;&#39564;&#35777;&#30340;&#20551;&#35774;&#19979;&#33719;&#24471;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#24314;&#31435;&#20102;&#28085;&#30422;&#25152;&#26377;&#23454;&#38469;&#24773;&#20917;&#30340;&#30830;&#20999;&#27867;&#21270;&#20445;&#35777;&#65292;&#21253;&#25324;&#20219;&#20309;&#20256;&#36755;&#25104;&#26412;&#20989;&#25968;&#21644;&#20219;&#20309;&#25439;&#22833;&#20989;&#25968;&#65292;&#21487;&#33021;&#26159;&#38750;&#20984;&#21644;&#38750;&#24179;&#28369;&#30340;&#24773;&#20917;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#65292;&#32780;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#23558;&#38750;&#24179;&#28369;&#20998;&#26512;&#29702;&#35770;&#19982;&#32463;&#20856;&#38598;&#20013;&#32467;&#26524;&#30456;&#32467;&#21512;&#30340;&#26032;&#39062;&#35777;&#26126;&#25216;&#26415;&#26469;&#23454;&#29616;&#36825;&#19968;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36275;&#22815;&#36890;&#29992;&#65292;&#21487;&#20197;&#25299;&#23637;&#33267;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11981v1 Announce Type: cross  Abstract: Distributionally robust optimization has emerged as an attractive way to train robust machine learning models, capturing data uncertainty and distribution shifts. Recent statistical analyses have proved that robust models built from Wasserstein ambiguity sets have nice generalization guarantees, breaking the curse of dimensionality. However, these results are obtained in specific cases, at the cost of approximations, or under assumptions difficult to verify in practice. In contrast, we establish, in this article, exact generalization guarantees that cover all practical cases, including any transport cost function and any loss function, potentially non-convex and nonsmooth. For instance, our result applies to deep learning, without requiring restrictive assumptions. We achieve this result through a novel proof technique that combines nonsmooth analysis rationale with classical concentration results. Our approach is general enough to ext
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#34987;&#23457;&#26597;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;($\mathcal{C}$-BALD)&#65292;&#36890;&#36807;&#25512;&#23548;&#34987;&#23457;&#26597;&#20998;&#24067;&#30340;&#29109;&#21644;&#20114;&#20449;&#24687;&#65292;&#20248;&#21270;&#30446;&#26631;&#20989;&#25968;&#65292;&#22312;&#24191;&#27867;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19979;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.11973</link><description>&lt;p&gt;
&#34987;&#23457;&#26597;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian Active Learning for Censored Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11973
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#34987;&#23457;&#26597;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;($\mathcal{C}$-BALD)&#65292;&#36890;&#36807;&#25512;&#23548;&#34987;&#23457;&#26597;&#20998;&#24067;&#30340;&#29109;&#21644;&#20114;&#20449;&#24687;&#65292;&#20248;&#21270;&#30446;&#26631;&#20989;&#25968;&#65292;&#22312;&#24191;&#27867;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19979;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#22522;&#20110;&#20449;&#24687;&#35770;&#26041;&#27861;&#65292;&#19987;&#27880;&#20110;&#26368;&#22823;&#21270;&#26032;&#35266;&#27979;&#25552;&#20379;&#32473;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#24687;&#12290;&#36890;&#24120;&#36890;&#36807;&#26368;&#22823;&#21270;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#36890;&#36807;&#20998;&#27495;&#65288;BALD&#65289;&#33719;&#24471;&#20989;&#25968;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#24378;&#35843;&#65292;&#22312;&#26032;&#25968;&#25454;&#28857;&#36973;&#21463;&#23457;&#26597;&#26102;&#20272;&#35745;BALD&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#20854;&#20013;&#21482;&#35266;&#23519;&#21040;&#30446;&#26631;&#30340;&#21098;&#36753;&#20540;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#34987;&#23457;&#26597;&#20998;&#24067;&#30340;&#29109;&#21644;&#20114;&#20449;&#24687;&#65292;&#24182;&#25512;&#23548;&#20102;&#34987;&#23457;&#26597;&#22238;&#24402;&#20013;&#30340;&#20027;&#21160;&#23398;&#20064;&#30340;BALD&#30446;&#26631;&#65288;$\mathcal{C}$-BALD&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24314;&#27169;&#26041;&#27861;&#26469;&#20272;&#35745;$\mathcal{C}$-BALD&#30446;&#26631;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#34987;&#23457;&#26597;&#35774;&#32622;&#20013;&#30340;&#20027;&#21160;&#23398;&#20064;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#24191;&#27867;&#30340;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#65292;&#25105;&#20204;&#35777;&#26126;$\mathcal{C}$-BALD&#22312;&#34987;&#23457;&#26597;&#22238;&#24402;&#20013;&#20248;&#20110;&#20854;&#20182;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11973v1 Announce Type: new  Abstract: Bayesian active learning is based on information theoretical approaches that focus on maximising the information that new observations provide to the model parameters. This is commonly done by maximising the Bayesian Active Learning by Disagreement (BALD) acquisitions function. However, we highlight that it is challenging to estimate BALD when the new data points are subject to censorship, where only clipped values of the targets are observed. To address this, we derive the entropy and the mutual information for censored distributions and derive the BALD objective for active learning in censored regression ($\mathcal{C}$-BALD). We propose a novel modelling approach to estimate the $\mathcal{C}$-BALD objective and use it for active learning in the censored setting. Across a wide range of datasets and models, we demonstrate that $\mathcal{C}$-BALD outperforms other Bayesian active learning methods in censored regression.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#26159;&#24378;&#20984;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.11858</link><description>&lt;p&gt;
&#22312;&#26446;&#32676;&#19978;&#30340;&#38543;&#26426;Hessian&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Stochastic Hessian Fitting on Lie Group
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#26159;&#24378;&#20984;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#12290;&#20351;&#29992;&#20102;&#19968;&#20010;Hessian&#25311;&#21512;&#20934;&#21017;&#65292;&#21487;&#29992;&#20110;&#25512;&#23548;&#22823;&#37096;&#20998;&#24120;&#29992;&#26041;&#27861;&#65292;&#22914;BFGS&#12289;&#39640;&#26031;&#29275;&#39039;&#12289;AdaGrad&#31561;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#19981;&#21516;&#25910;&#25947;&#36895;&#29575;&#65292;&#20363;&#22914;&#65292;&#22312;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#27425;&#32447;&#24615;&#36895;&#29575;&#21644;&#23545;&#31216;&#27491;&#23450;&#65288;SPL&#65289;&#30697;&#38453;&#21644;&#26576;&#20123;&#26446;&#32676;&#19978;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#32447;&#24615;&#36895;&#29575;&#12290;&#22312;&#29305;&#23450;&#19988;&#36275;&#22815;&#19968;&#33324;&#30340;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#34987;&#35777;&#26126;&#26159;&#24378;&#20984;&#30340;&#12290;&#20026;&#20102;&#30830;&#35748;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#35774;&#32622;&#19979;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#22914;&#26377;&#22122;&#22768;&#30340;Hessian-&#21521;&#37327;&#20056;&#31215;&#12289;&#26102;&#21464;&#30340;Hessians&#21644;&#20302;&#31934;&#24230;&#31639;&#26415;&#12290;&#36825;&#20123;&#21457;&#29616;&#23545;&#20381;&#36182;&#20110;&#38543;&#26426;&#20108;&#38454;&#20248;&#21270;&#30340;&#26041;&#27861;&#26159;&#26377;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11858v1 Announce Type: cross  Abstract: This paper studies the fitting of Hessian or its inverse with stochastic Hessian-vector products. A Hessian fitting criterion, which can be used to derive most of the commonly used methods, e.g., BFGS, Gaussian-Newton, AdaGrad, etc., is used for the analysis. Our studies reveal different convergence rates for different Hessian fitting methods, e.g., sublinear rates for gradient descent in the Euclidean space and a commonly used closed-form solution, linear rates for gradient descent on the manifold of symmetric positive definite (SPL) matrices and certain Lie groups. The Hessian fitting problem is further shown to be strongly convex under mild conditions on a specific yet general enough Lie group. To confirm our analysis, these methods are tested under different settings like noisy Hessian-vector products, time varying Hessians, and low precision arithmetic. These findings are useful for stochastic second order optimizations that rely 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11789</link><description>&lt;p&gt;
&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#20551;&#35774;&#30340;&#32479;&#35745;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Generated Hypotheses by Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#30340;&#22686;&#24378;&#24615;&#33021;&#21152;&#36895;&#20102;&#20854;&#34701;&#20837;&#31185;&#23398;&#30740;&#31350;&#12290;&#29305;&#21035;&#26159;&#65292;&#21033;&#29992;&#29983;&#25104;&#24335;AI&#21019;&#24314;&#31185;&#23398;&#20551;&#35774;&#26159;&#24456;&#26377;&#21069;&#36884;&#30340;&#65292;&#24182;&#19988;&#27491;&#22312;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#24403;&#20351;&#29992;AI&#29983;&#25104;&#30340;&#20551;&#35774;&#36827;&#34892;&#20851;&#38190;&#20915;&#31574;&#65288;&#22914;&#21307;&#23398;&#35786;&#26029;&#65289;&#26102;&#65292;&#39564;&#35777;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#36827;&#34892;&#21307;&#23398;&#35786;&#26029;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26469;&#37327;&#21270;&#20854;&#21487;&#38752;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#20351;&#29992;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#29983;&#25104;&#30340;&#22270;&#20687;&#26159;&#30001;&#32463;&#36807;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#36825;&#19968;&#20107;&#23454;&#26465;&#20214;&#19979;&#30340;&#32479;&#35745;&#26816;&#39564;&#12290;&#21033;&#29992;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#32479;&#35745;&#21487;&#38752;&#24615;&#21487;&#20197;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25511;&#21046;&#38169;&#35823;&#29575;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11789v1 Announce Type: cross  Abstract: The enhanced performance of AI has accelerated its integration into scientific research. In particular, the use of generative AI to create scientific hypotheses is promising and is increasingly being applied across various fields. However, when employing AI-generated hypotheses for critical decisions, such as medical diagnoses, verifying their reliability is crucial. In this study, we consider a medical diagnostic task using generated images by diffusion models, and propose a statistical test to quantify its reliability. The basic idea behind the proposed statistical test is to employ a selective inference framework, where we consider a statistical test conditional on the fact that the generated images are produced by a trained diffusion model. Using the proposed method, the statistical reliability of medical image diagnostic results can be quantified in the form of a p-value, allowing for decision-making with a controlled error rate. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35780;&#20272;&#22522;&#20110;&#25351;&#25968;&#30340;&#36164;&#28304;&#20998;&#37197;&#31574;&#30053;&#26377;&#25928;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32763;&#35793;&#21644;&#25193;&#23637;&#32479;&#35745;&#25991;&#29486;&#20013;&#30340;&#26368;&#26032;&#24605;&#24819;&#65292;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#20272;&#35745;&#22120;&#21644;&#35745;&#31639;&#28176;&#36817;&#27491;&#30830;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.11771</link><description>&lt;p&gt;
&#35780;&#20272;&#22522;&#20110;&#25351;&#25968;&#30340;&#27835;&#30103;&#20998;&#37197;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Effectiveness of Index-Based Treatment Allocation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35780;&#20272;&#22522;&#20110;&#25351;&#25968;&#30340;&#36164;&#28304;&#20998;&#37197;&#31574;&#30053;&#26377;&#25928;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32763;&#35793;&#21644;&#25193;&#23637;&#32479;&#35745;&#25991;&#29486;&#20013;&#30340;&#26368;&#26032;&#24605;&#24819;&#65292;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#20272;&#35745;&#22120;&#21644;&#35745;&#31639;&#28176;&#36817;&#27491;&#30830;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#36164;&#28304;&#31232;&#32570;&#26102;&#65292;&#38656;&#35201;&#19968;&#31181;&#20998;&#37197;&#31574;&#30053;&#26469;&#20915;&#23450;&#35841;&#33021;&#33719;&#24471;&#36164;&#28304;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35780;&#20272;&#22522;&#20110;&#25351;&#25968;&#30340;&#20998;&#37197;&#31574;&#30053;&#30340;&#26041;&#27861;&#65292;&#35813;&#31574;&#30053;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25968;&#25454;&#65292;&#23558;&#26377;&#38480;&#25968;&#37327;&#30340;&#36164;&#28304;&#20998;&#37197;&#32473;&#26368;&#38656;&#35201;&#30340;&#20154;&#12290;&#25105;&#20204;&#20174;&#32479;&#35745;&#25991;&#29486;&#20013;&#32763;&#35793;&#21644;&#25193;&#23637;&#20102;&#26368;&#36817;&#30340;&#24819;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#21644;&#35745;&#31639;&#28176;&#36817;&#27491;&#30830;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#24471;&#20986;&#26377;&#25928;&#30340;&#32479;&#35745;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11771v1 Announce Type: cross  Abstract: When resources are scarce, an allocation policy is needed to decide who receives a resource. This problem occurs, for instance, when allocating scarce medical resources and is often solved using modern ML methods. This paper introduces methods to evaluate index-based allocation policies -- that allocate a fixed number of resources to those who need them the most -- by using data from a randomized control trial. Such policies create dependencies between agents, which render the assumptions behind standard statistical tests invalid and limit the effectiveness of estimators. Addressing these challenges, we translate and extend recent ideas from the statistics literature to present an efficient estimator and methods for computing asymptotically correct confidence intervals. This enables us to effectively draw valid statistical conclusions, a critical gap in previous work. Our extensive experiments validate our methodology in practical sett
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20809;&#35889;&#19981;&#24179;&#34913;&#30340;&#27010;&#24565;&#20316;&#20026;&#23548;&#33268;&#31867;&#21035;&#24046;&#24322;&#30340;&#28508;&#22312;&#26469;&#28304;&#65292;&#24182;&#30740;&#31350;&#20102;&#20809;&#35889;&#19981;&#24179;&#34913;&#19982;&#31867;&#21035;&#20559;&#35265;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20026;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#31867;&#21035;&#24046;&#24322;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#22312;&#22810;&#20010;&#39044;&#35757;&#32451;&#32534;&#30721;&#22120;&#20013;&#39564;&#35777;&#20102;&#36825;&#31181;&#32852;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.11742</link><description>&lt;p&gt;
&#24179;&#34913;&#25968;&#25454;&#65292;&#19981;&#24179;&#34913;&#20809;&#35889;&#65306;&#25581;&#31034;&#20855;&#26377;&#20809;&#35889;&#19981;&#24179;&#34913;&#30340;&#31867;&#21035;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Balanced Data, Imbalanced Spectra: Unveiling Class Disparities with Spectral Imbalance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11742
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20809;&#35889;&#19981;&#24179;&#34913;&#30340;&#27010;&#24565;&#20316;&#20026;&#23548;&#33268;&#31867;&#21035;&#24046;&#24322;&#30340;&#28508;&#22312;&#26469;&#28304;&#65292;&#24182;&#30740;&#31350;&#20102;&#20809;&#35889;&#19981;&#24179;&#34913;&#19982;&#31867;&#21035;&#20559;&#35265;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20026;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#31867;&#21035;&#24046;&#24322;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#22312;&#22810;&#20010;&#39044;&#35757;&#32451;&#32534;&#30721;&#22120;&#20013;&#39564;&#35777;&#20102;&#36825;&#31181;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#27169;&#22411;&#34987;&#26399;&#26395;&#22312;&#19981;&#21516;&#31867;&#21035;&#19978;&#34920;&#29616;&#21516;&#26679;&#33391;&#22909;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#23427;&#20204;&#30340;&#34920;&#29616;&#24448;&#24448;&#23384;&#22312;&#36739;&#22823;&#24046;&#36317;&#12290;&#36825;&#20010;&#31867;&#21035;&#20559;&#35265;&#38382;&#39064;&#22312;&#26679;&#26412;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#22312;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#30456;&#23545;&#34987;&#24573;&#35270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29305;&#24449;&#20013;&#30340;&#20809;&#35889;&#19981;&#24179;&#34913;&#27010;&#24565;&#20316;&#20026;&#31867;&#21035;&#24046;&#24322;&#30340;&#28508;&#22312;&#26469;&#28304;&#65292;&#24182;&#30740;&#31350;&#20809;&#35889;&#19981;&#24179;&#34913;&#19982;&#31867;&#21035;&#20559;&#35265;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#32852;&#31995;&#12290;&#20026;&#20102;&#24314;&#31435;&#20809;&#35889;&#19981;&#24179;&#34913;&#19982;&#31867;&#21035;&#24046;&#36317;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#31867;&#21035;&#24046;&#24322;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25512;&#23548;&#20102;&#39640;&#32500;&#28151;&#21512;&#27169;&#22411;&#35774;&#23450;&#20013;&#27599;&#31867;&#38169;&#35823;&#30340;&#31934;&#30830;&#34920;&#36798;&#24335;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;11&#20010;&#19981;&#21516;&#30340;&#26368;&#20808;&#36827;&#30340;&#39044;&#35757;&#32451;&#32534;&#30721;&#22120;&#20013;&#30740;&#31350;&#20102;&#36825;&#19968;&#29616;&#35937;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#22914;&#20309;&#29992;&#20110;&#27604;&#36739;&#32534;&#30721;&#22120;&#30340;&#36136;&#37327;&#65292;&#20197;&#21450;&#35780;&#20272;&#21644;&#32452;&#21512;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11742v1 Announce Type: new  Abstract: Classification models are expected to perform equally well for different classes, yet in practice, there are often large gaps in their performance. This issue of class bias is widely studied in cases of datasets with sample imbalance, but is relatively overlooked in balanced datasets. In this work, we introduce the concept of spectral imbalance in features as a potential source for class disparities and study the connections between spectral imbalance and class bias in both theory and practice. To build the connection between spectral imbalance and class gap, we develop a theoretical framework for studying class disparities and derive exact expressions for the per-class error in a high-dimensional mixture model setting. We then study this phenomenon in 11 different state-of-the-art pretrained encoders and show how our proposed framework can be used to compare the quality of encoders, as well as evaluate and combine data augmentation stra
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#65292;&#20854;&#25903;&#25345;&#36235;&#20110;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#23427;&#22312;&#26368;&#22351;&#24773;&#20917;&#31215;&#20998;&#35823;&#24046;&#38598;&#20013;&#19981;&#31561;&#24335;&#19978;&#20248;&#20110;i.i.d.&#33945;&#29305;&#21345;&#32599;&#12290;</title><link>https://arxiv.org/abs/2402.11736</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;Gibbs&#27979;&#24230;&#30340;&#33945;&#29305;&#21345;&#32599;&#65306;&#27010;&#29575;&#38543;&#26426;&#25918;&#29287;&#30340;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo with kernel-based Gibbs measures: Guarantees for probabilistic herding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11736
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#65292;&#20854;&#25903;&#25345;&#36235;&#20110;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#35823;&#24046;&#65292;&#35777;&#26126;&#20102;&#23427;&#22312;&#26368;&#22351;&#24773;&#20917;&#31215;&#20998;&#35823;&#24046;&#38598;&#20013;&#19981;&#31561;&#24335;&#19978;&#20248;&#20110;i.i.d.&#33945;&#29305;&#21345;&#32599;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kernel herding&#23646;&#20110;&#19968;&#31867;&#30830;&#23450;&#24615;&#30340;&#22235;&#20301;&#25968;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#19978;&#30340;&#26368;&#22351;&#24773;&#20917;&#31215;&#20998;&#35823;&#24046;&#12290;&#23613;&#31649;&#26377;&#24456;&#24378;&#30340;&#23454;&#39564;&#25903;&#25345;&#65292;&#20294;&#22312;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#21363;RKHS&#26159;&#26080;&#38480;&#32500;&#26102;&#65292;&#35777;&#26126;&#36825;&#31181;&#26368;&#22351;&#24773;&#20917;&#35823;&#24046;&#20197;&#27604;&#26631;&#20934;&#31215;&#20998;&#33410;&#28857;&#25968;&#37327;&#30340;&#24179;&#26041;&#26681;&#26356;&#24555;&#30340;&#36895;&#29575;&#20943;&#23569;&#26159;&#22256;&#38590;&#30340;&#12290;&#22312;&#36825;&#31687;&#29702;&#35770;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#20851;&#20110;&#31215;&#20998;&#33410;&#28857;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#65292;&#20854;&#25903;&#25345;&#36235;&#20110;&#26368;&#23567;&#21270;&#19982;&#26680;&#25918;&#29287;&#30456;&#21516;&#30340;&#26368;&#22351;&#24773;&#20917;&#35823;&#24046;&#12290;&#25105;&#20204;&#35777;&#26126;&#23427;&#20248;&#20110;i.i.d.&#33945;&#29305;&#21345;&#32599;&#65292;&#24847;&#21619;&#30528;&#22312;&#26368;&#22351;&#24773;&#20917;&#31215;&#20998;&#35823;&#24046;&#19978;&#20855;&#26377;&#26356;&#32039;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;&#12290;&#23613;&#31649;&#23578;&#26410;&#25552;&#39640;&#36895;&#29575;&#65292;&#20294;&#36825;&#34920;&#26126;&#20102;&#30740;&#31350;Gibbs&#27979;&#24230;&#30340;&#25968;&#23398;&#24037;&#20855;&#21487;&#20197;&#24110;&#21161;&#29702;&#35299;&#26680;&#25918;&#29287;&#21450;&#20854;&#21464;&#20307;&#22312;&#35745;&#31639;&#19978;&#30340;&#25913;&#36827;&#31243;&#24230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11736v1 Announce Type: new  Abstract: Kernel herding belongs to a family of deterministic quadratures that seek to minimize the worst-case integration error over a reproducing kernel Hilbert space (RKHS). In spite of strong experimental support, it has revealed difficult to prove that this worst-case error decreases at a faster rate than the standard square root of the number of quadrature nodes, at least in the usual case where the RKHS is infinite-dimensional. In this theoretical paper, we study a joint probability distribution over quadrature nodes, whose support tends to minimize the same worst-case error as kernel herding. We prove that it does outperform i.i.d. Monte Carlo, in the sense of coming with a tighter concentration inequality on the worst-case integration error. While not improving the rate yet, this demonstrates that the mathematical tools of the study of Gibbs measures can help understand to what extent kernel herding and its variants improve on computation
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#35760;&#24518;&#26680;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#24182;&#22312;Sobolev&#33539;&#25968;Loss&#20989;&#25968;&#21644;RKHS&#27491;&#21017;&#21270;&#19979;&#23454;&#29616;&#22238;&#24402;&#65292;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#25913;&#36827;&#24615;&#33021;&#65292;&#23545;&#27604;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11705</link><description>&lt;p&gt;
&#22312;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#23398;&#20064;&#35760;&#24518;&#26680;
&lt;/p&gt;
&lt;p&gt;
Learning Memory Kernels in Generalized Langevin Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11705
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#35760;&#24518;&#26680;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#24182;&#22312;Sobolev&#33539;&#25968;Loss&#20989;&#25968;&#21644;RKHS&#27491;&#21017;&#21270;&#19979;&#23454;&#29616;&#22238;&#24402;&#65292;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#25913;&#36827;&#24615;&#33021;&#65292;&#23545;&#27604;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#30340;&#35760;&#24518;&#26680;&#12290;&#35813;&#26041;&#27861;&#26368;&#21021;&#21033;&#29992;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20174;&#36712;&#36857;&#25968;&#25454;&#20013;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#65292;&#28982;&#21518;&#36890;&#36807;&#22522;&#20110;Sobolev&#33539;&#25968;&#30340;&#22238;&#24402;&#21644;RKHS&#27491;&#21017;&#21270;&#26469;&#36827;&#34892;&#22238;&#24402;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20445;&#35777;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#20102;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#26680;&#20272;&#35745;&#35823;&#24046;&#21463;&#25511;&#20110;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#31034;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30456;&#23545;&#20110;&#20381;&#36182;&#20110;$L^2$&#25439;&#22833;&#20989;&#25968;&#30340;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#20197;&#21450;&#20174;&#36870;&#25289;&#26222;&#25289;&#26031;&#21464;&#25442;&#25512;&#23548;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#65292;&#36825;&#20123;&#31034;&#20363;&#31361;&#26174;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#21508;&#31181;&#26435;&#37325;&#21442;&#25968;&#36873;&#25321;&#19978;&#30340;&#25345;&#32493;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21253;&#25324;&#21147;&#21644;&#28418;&#31227;&#39033;&#22312;&#26041;&#31243;&#20013;&#30340;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11705v1 Announce Type: cross  Abstract: We introduce a novel approach for learning memory kernels in Generalized Langevin Equations. This approach initially utilizes a regularized Prony method to estimate correlation functions from trajectory data, followed by regression over a Sobolev norm-based loss function with RKHS regularization. Our approach guarantees improved performance within an exponentially weighted $L^2$ space, with the kernel estimation error controlled by the error in estimated correlation functions. We demonstrate the superiority of our estimator compared to other regression estimators that rely on $L^2$ loss functions and also an estimator derived from the inverse Laplace transform, using numerical examples that highlight its consistent advantage across various weight parameter selections. Additionally, we provide examples that include the application of force and drift terms in the equation.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#30340;&#20272;&#35745;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#21442;&#25968;&#36895;&#29575;&#19979;&#23558;&#20854;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>https://arxiv.org/abs/2402.11652</link><description>&lt;p&gt;
&#22240;&#26524;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#21452;&#37325;&#31283;&#20581;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Inference in Causal Latent Factor Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11652
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#30340;&#20272;&#35745;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#21442;&#25968;&#36895;&#29575;&#19979;&#23558;&#20854;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#26032;&#26694;&#26550;&#65292;&#35813;&#29615;&#22659;&#20855;&#26377;&#22823;&#37327;&#21333;&#20301;&#21644;&#32467;&#26524;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#37327;&#26159;&#21452;&#37325;&#31283;&#20581;&#30340;&#65292;&#32467;&#21512;&#20102;&#32467;&#26524;&#22635;&#34917;&#12289;&#20498;&#25968;&#27010;&#29575;&#21152;&#26435;&#20197;&#21450;&#19968;&#31181;&#29992;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#26032;&#22411;&#20132;&#21449;&#37197;&#23545;&#31243;&#24207;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#26032;&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#25910;&#25947;&#21040;&#21442;&#25968;&#36895;&#29575;&#19979;&#30340;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;&#27169;&#25311;&#32467;&#26524;&#23637;&#31034;&#20102;&#26412;&#25991;&#20998;&#26512;&#30340;&#20272;&#35745;&#37327;&#30340;&#24418;&#24335;&#29305;&#24615;&#30340;&#23454;&#38469;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11652v1 Announce Type: cross  Abstract: This article introduces a new framework for estimating average treatment effects under unobserved confounding in modern data-rich environments featuring large numbers of units and outcomes. The proposed estimator is doubly robust, combining outcome imputation, inverse probability weighting, and a novel cross-fitting procedure for matrix completion. We derive finite-sample and asymptotic guarantees, and show that the error of the new estimator converges to a mean-zero Gaussian distribution at a parametric rate. Simulation results demonstrate the practical relevance of the formal properties of the estimators analyzed in this article.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26679;&#26465;&#25311;&#25554;&#20540;&#36827;&#34892;&#21333;&#21464;&#37327;&#23494;&#24230;&#20272;&#35745;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#32858;&#31867;&#24314;&#27169;&#65292;&#20026;&#26500;&#24314;&#36866;&#29992;&#30340;&#22810;&#20803;&#20998;&#24067;&#25552;&#20379;&#20102;&#26032;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.11552</link><description>&lt;p&gt;
&#22522;&#20110;&#26679;&#26465;&#25311;&#25554;&#20540;&#30340;&#32463;&#39564;&#23494;&#24230;&#20272;&#35745;&#21450;&#20854;&#22312;Copulas&#32858;&#31867;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Empirical Density Estimation based on Spline Quasi-Interpolation with applications to Copulas clustering modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26679;&#26465;&#25311;&#25554;&#20540;&#36827;&#34892;&#21333;&#21464;&#37327;&#23494;&#24230;&#20272;&#35745;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#32858;&#31867;&#24314;&#27169;&#65292;&#20026;&#26500;&#24314;&#36866;&#29992;&#30340;&#22810;&#20803;&#20998;&#24067;&#25552;&#20379;&#20102;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#24230;&#20272;&#35745;&#26159;&#21508;&#20010;&#39046;&#22495;&#20869;&#29992;&#20110;&#24314;&#27169;&#21644;&#29702;&#35299;&#25968;&#25454;&#22522;&#30784;&#20998;&#24067;&#30340;&#22522;&#26412;&#25216;&#26415;&#12290;&#23494;&#24230;&#20272;&#35745;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#12290;&#22312;&#22788;&#29702;&#21333;&#21464;&#37327;&#25110;&#22810;&#21464;&#37327;&#25968;&#25454;&#26102;&#65292;&#36825;&#19968;&#36807;&#31243;&#23588;&#20026;&#37325;&#35201;&#65292;&#23545;&#20110;&#32858;&#31867;&#12289;&#24322;&#24120;&#26816;&#27979;&#21644;&#29983;&#25104;&#24314;&#27169;&#31561;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26679;&#26465;&#25311;&#25554;&#20540;&#26469;&#36817;&#20284;&#21333;&#21464;&#37327;&#23494;&#24230;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#32858;&#31867;&#24314;&#27169;&#30340;&#26041;&#27861;&#12290;&#25152;&#20351;&#29992;&#30340;&#32858;&#31867;&#25216;&#26415;&#22522;&#20110;&#26500;&#24314;&#36866;&#29992;&#30340;&#22810;&#20803;&#20998;&#24067;&#65292;&#36825;&#21462;&#20915;&#20110;&#23545;&#21333;&#21464;&#37327;&#32463;&#39564;&#23494;&#24230;&#65288;&#36793;&#38469;&#23494;&#24230;&#65289;&#30340;&#20272;&#35745;&#12290;&#35813;&#36924;&#36817;&#26159;&#36890;&#36807;&#20351;&#29992;&#25552;&#20986;&#30340;&#26679;&#26465;&#25311;&#25554;&#20540;&#23454;&#29616;&#30340;&#65292;&#21516;&#26102;&#29992;&#20110;&#24314;&#27169;&#25152;&#23547;&#27714;&#30340;&#32858;&#31867;&#21010;&#20998;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11552v1 Announce Type: cross  Abstract: Density estimation is a fundamental technique employed in various fields to model and to understand the underlying distribution of data. The primary objective of density estimation is to estimate the probability density function of a random variable. This process is particularly valuable when dealing with univariate or multivariate data and is essential for tasks such as clustering, anomaly detection, and generative modeling. In this paper we propose the mono-variate approximation of the density using spline quasi interpolation and we applied it in the context of clustering modeling. The clustering technique used is based on the construction of suitable multivariate distributions which rely on the estimation of the monovariate empirical densities (marginals). Such an approximation is achieved by using the proposed spline quasi-interpolation, while the joint distributions to model the sought clustering partition is constructed with the 
&lt;/p&gt;</description></item><item><title>OptEx&#26159;&#31532;&#19968;&#20010;&#36890;&#36807;&#21033;&#29992;&#24182;&#34892;&#35745;&#31639;&#26469;&#20943;&#36731;&#19968;&#38454;&#20248;&#21270;&#30340;&#36845;&#20195;&#29942;&#39048;&#24182;&#22686;&#24378;&#25928;&#29575;&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#26680;&#21270;&#26799;&#24230;&#20272;&#35745;&#23454;&#29616;&#36845;&#20195;&#30340;&#24182;&#34892;&#21270;&#65292;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.11427</link><description>&lt;p&gt;
OptEx: &#21033;&#29992;&#36817;&#20284;&#24182;&#34892;&#21270;&#36845;&#20195;&#21152;&#36895;&#19968;&#38454;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
OptEx: Expediting First-Order Optimization with Approximately Parallelized Iterations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11427
&lt;/p&gt;
&lt;p&gt;
OptEx&#26159;&#31532;&#19968;&#20010;&#36890;&#36807;&#21033;&#29992;&#24182;&#34892;&#35745;&#31639;&#26469;&#20943;&#36731;&#19968;&#38454;&#20248;&#21270;&#30340;&#36845;&#20195;&#29942;&#39048;&#24182;&#22686;&#24378;&#25928;&#29575;&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#26680;&#21270;&#26799;&#24230;&#20272;&#35745;&#23454;&#29616;&#36845;&#20195;&#30340;&#24182;&#34892;&#21270;&#65292;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31532;&#19968;&#38454;&#20248;&#21270;&#65288;FOO&#65289;&#31639;&#27861;&#22312;&#35832;&#22914;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#21435;&#22122;&#31561;&#20247;&#22810;&#35745;&#31639;&#39046;&#22495;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#31561;&#22797;&#26434;&#20219;&#21153;&#24448;&#24448;&#23548;&#33268;&#26174;&#33879;&#30340;&#20302;&#25928;&#65292;&#22240;&#20026;&#38656;&#35201;&#35768;&#22810;&#39034;&#24207;&#36845;&#20195;&#20197;&#23454;&#29616;&#25910;&#25947;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#38454;&#20248;&#21270;&#21152;&#36895;&#36817;&#20284;&#24182;&#34892;&#36845;&#20195;&#65288;OptEx&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36890;&#36807;&#21033;&#29992;&#24182;&#34892;&#35745;&#31639;&#26469;&#20943;&#36731;&#20854;&#36845;&#20195;&#29942;&#39048;&#32780;&#22686;&#24378;FOO&#25928;&#29575;&#30340;&#26694;&#26550;&#12290;OptEx&#37319;&#29992;&#26680;&#21270;&#26799;&#24230;&#20272;&#35745;&#26469;&#21033;&#29992;&#26799;&#24230;&#21382;&#21490;&#36827;&#34892;&#26410;&#26469;&#26799;&#24230;&#39044;&#27979;&#65292;&#23454;&#29616;&#20102;&#36845;&#20195;&#30340;&#24182;&#34892;&#21270; -- &#36825;&#26159;&#19968;&#31181;&#26366;&#32463;&#34987;&#35748;&#20026;&#30001;&#20110;FOO&#20013;&#22266;&#26377;&#30340;&#36845;&#20195;&#20381;&#36182;&#32780;&#19981;&#20999;&#23454;&#38469;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#26680;&#21270;&#26799;&#24230;&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#21644;&#22522;&#20110;SGD&#30340;OptEx&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#35748;&#20102;&#20854;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11427v1 Announce Type: cross  Abstract: First-order optimization (FOO) algorithms are pivotal in numerous computational domains such as machine learning and signal denoising. However, their application to complex tasks like neural network training often entails significant inefficiencies due to the need for many sequential iterations for convergence. In response, we introduce first-order optimization expedited with approximately parallelized iterations (OptEx), the first framework that enhances the efficiency of FOO by leveraging parallel computing to mitigate its iterative bottleneck. OptEx employs kernelized gradient estimation to make use of gradient history for future gradient prediction, enabling parallelization of iterations -- a strategy once considered impractical because of the inherent iterative dependency in FOO. We provide theoretical guarantees for the reliability of our kernelized gradient estimation and the iteration complexity of SGD-based OptEx, confirming t
&lt;/p&gt;</description></item><item><title>&#32473;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#30830;&#23450;&#24615;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#30340;&#26657;&#20934;&#36317;&#31163;&#35823;&#24046;&#26368;&#22810;&#20026;$2\sqrt{T}$</title><link>https://arxiv.org/abs/2402.11410</link><description>&lt;p&gt;
&#33719;&#24471;$2\sqrt{T}$&#21040;&#26657;&#20934;&#30340;&#22522;&#26412;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
An Elementary Predictor Obtaining $2\sqrt{T}$ Distance to Calibration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11410
&lt;/p&gt;
&lt;p&gt;
&#32473;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#30830;&#23450;&#24615;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#30340;&#26657;&#20934;&#36317;&#31163;&#35823;&#24046;&#26368;&#22810;&#20026;$2\sqrt{T}$
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Blasiok&#31561;&#20154;[2023]&#25552;&#20986;&#20102;&#26657;&#20934;&#36317;&#31163;&#20316;&#20026;&#19968;&#31181;&#33258;&#28982;&#30340;&#26657;&#20934;&#35823;&#24046;&#24230;&#37327;&#65292;&#19982;&#39044;&#26399;&#30340;&#26657;&#20934;&#35823;&#24046;(ECE)&#19981;&#21516;&#65292;&#23427;&#26159;&#36830;&#32493;&#30340;&#12290;&#26368;&#36817;&#65292;Qiao&#21644;Zheng [2024]&#32473;&#20986;&#20102;&#19968;&#20010;&#38750;&#26500;&#36896;&#24615;&#30340;&#35770;&#35777;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#22312;&#32447;&#39044;&#27979;&#22120;&#30340;&#23384;&#22312;&#65292;&#35813;&#39044;&#27979;&#22120;&#21487;&#20197;&#22312;&#23545;&#25239;&#35774;&#32622;&#20013;&#33719;&#24471;$O(\sqrt{T})$&#30340;&#26657;&#20934;&#36317;&#31163;&#65292;&#32780;&#23545;&#20110;ECE&#26469;&#35828;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#20182;&#20204;&#23558;&#25214;&#21040;&#19968;&#31181;&#26126;&#30830;&#30340;&#12289;&#39640;&#25928;&#30340;&#31639;&#27861;&#20316;&#20026;&#19968;&#20010;&#38656;&#35201;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#20010;&#38750;&#24120;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#30830;&#23450;&#24615;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#30340;&#26657;&#20934;&#36317;&#31163;&#35823;&#24046;&#26368;&#22810;&#20026;$2\sqrt{T}$&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11410v1 Announce Type: new  Abstract: Blasiok et al. [2023] proposed distance to calibration as a natural measure of calibration error that unlike expected calibration error (ECE) is continuous. Recently, Qiao and Zheng [2024] gave a non-constructive argument establishing the existence of an online predictor that can obtain $O(\sqrt{T})$ distance to calibration in the adversarial setting, which is known to be impossible for ECE. They leave as an open problem finding an explicit, efficient algorithm. We resolve this problem and give an extremely simple, efficient, deterministic algorithm that obtains distance to calibration error at most $2\sqrt{T}$.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38543;&#26426;&#20132;&#27969;&#65288;AC&#65289;&#27010;&#29575;&#32422;&#26463;&#65288;CC&#65289;&#26368;&#20248;&#28526;&#27969;&#65288;OPF&#65289;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;IEEE&#27979;&#35797;&#26696;&#20363;&#23637;&#31034;&#20102;&#20854;&#23454;&#35777;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.11365</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#30340;&#25968;&#25454;&#39537;&#21160;&#38543;&#26426;&#20132;&#27969;&#20248;&#21270;&#28526;&#27969;
&lt;/p&gt;
&lt;p&gt;
Data-Driven Stochastic AC-OPF using Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11365
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38543;&#26426;&#20132;&#27969;&#65288;AC&#65289;&#27010;&#29575;&#32422;&#26463;&#65288;CC&#65289;&#26368;&#20248;&#28526;&#27969;&#65288;OPF&#65289;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;IEEE&#27979;&#35797;&#26696;&#20363;&#23637;&#31034;&#20102;&#20854;&#23454;&#35777;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32858;&#28966;&#20110;&#21457;&#23637;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38543;&#26426;&#20132;&#27969;&#65288;AC&#65289;&#27010;&#29575;&#32422;&#26463;&#65288;CC&#65289;&#26368;&#20248;&#28526;&#27969;&#65288;OPF&#65289;&#38382;&#39064;&#12290;&#34429;&#28982;AC CC-OPF&#38382;&#39064;&#22312;&#23398;&#26415;&#30028;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#30001;&#20110;&#39640;&#24230;&#38750;&#32447;&#24615;&#21644;&#35745;&#31639;&#35201;&#27714;&#24456;&#39640;&#65292;&#38480;&#21046;&#20102;&#20854;&#23454;&#38469;&#24433;&#21709;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#35299;&#20915;&#36825;&#19968;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20110;&#22810;&#20010;IEEE&#27979;&#35797;&#26696;&#20363;&#26469;&#23637;&#31034;&#20854;&#23454;&#35777;&#25928;&#29575;&#12290;&#20026;&#20102;&#35299;&#20915;&#38750;&#20984;&#21644;&#35745;&#31639;&#22797;&#26434;&#30340;CC AC-OPF&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#26426;&#22120;&#23398;&#20064;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#27169;&#22411;&#12290;&#23436;&#25972;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#19968;&#20010;&#31616;&#21333;&#20294;&#38750;&#20984;&#30340;&#25968;&#25454;&#39537;&#21160;&#36817;&#20284;&#33267;AC&#28526;&#27969;&#26041;&#31243;&#65292;&#33021;&#22815;&#32435;&#20837;&#19981;&#30830;&#23450;&#36755;&#20837;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#21508;&#31181;&#36817;&#20284;&#26469;&#20256;&#25773;GP&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11365v1 Announce Type: new  Abstract: The thesis focuses on developing a data-driven algorithm, based on machine learning, to solve the stochastic alternating current (AC) chance-constrained (CC) Optimal Power Flow (OPF) problem. Although the AC CC-OPF problem has been successful in academic circles, it is highly nonlinear and computationally demanding, which limits its practical impact. The proposed approach aims to address this limitation and demonstrate its empirical efficiency through applications to multiple IEEE test cases. To solve the non-convex and computationally challenging CC AC-OPF problem, the proposed approach relies on a machine learning Gaussian process regression (GPR) model. The full Gaussian process (GP) approach is capable of learning a simple yet non-convex data-driven approximation to the AC power flow equations that can incorporate uncertain inputs. The proposed approach uses various approximations for GP-uncertainty propagation. The full GP CC-OPF ap
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#23558;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#35270;&#20026;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#25104;&#21151;&#35843;&#25972; EI &#24182;&#23637;&#31034;&#20854;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11345</link><description>&lt;p&gt;
&#21464;&#20998;&#29109;&#25628;&#32034;&#29992;&#20110;&#35843;&#25972;&#26399;&#26395;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Variational Entropy Search for Adjusting Expected Improvement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#23558;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#35270;&#20026;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#25104;&#21151;&#35843;&#25972; EI &#24182;&#23637;&#31034;&#20854;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bayesian optimization &#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#30340;&#25216;&#26415;&#65292;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#26159;&#35813;&#39046;&#22495;&#20013;&#26368;&#24120;&#29992;&#30340;&#33719;&#21462;&#20989;&#25968;&#12290;&#34429;&#28982; EI &#36890;&#24120;&#34987;&#35270;&#20026;&#19982;&#20854;&#20182;&#20449;&#24687;&#29702;&#35770;&#33719;&#21462;&#20989;&#25968;&#65288;&#22914;&#29109;&#25628;&#32034;&#65288;ES&#65289;&#21644;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#65289;&#19981;&#21516;&#65292;&#20294;&#25105;&#20204;&#30340;&#24037;&#20316;&#25581;&#31034;&#20102;&#65292;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#26041;&#27861;&#65292;EI &#21487;&#20197;&#34987;&#35270;&#20026; MES &#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#22312;&#36825;&#19968;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#20449;&#24687;&#29702;&#35770;&#27010;&#24565;&#30340;&#21407;&#21017;&#25972;&#21512;&#21040; EI &#20013;&#26469;&#35843;&#25972; EI&#12290;VES-Gamma &#30340;&#26377;&#25928;&#24615;&#22312;&#21508;&#31181;&#27979;&#35797;&#20989;&#25968;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;&#31361;&#20986;&#20102;&#23427;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#22330;&#26223;&#20013;&#30340;&#29702;&#35770;&#21644;&#23454;&#38469;&#29992;&#36884;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11345v1 Announce Type: cross  Abstract: Bayesian optimization is a widely used technique for optimizing black-box functions, with Expected Improvement (EI) being the most commonly utilized acquisition function in this domain. While EI is often viewed as distinct from other information-theoretic acquisition functions, such as entropy search (ES) and max-value entropy search (MES), our work reveals that EI can be considered a special case of MES when approached through variational inference (VI). In this context, we have developed the Variational Entropy Search (VES) methodology and the VES-Gamma algorithm, which adapts EI by incorporating principles from information-theoretic concepts. The efficacy of VES-Gamma is demonstrated across a variety of test functions and read datasets, highlighting its theoretical and practical utilities in Bayesian optimization scenarios.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39044;&#22788;&#29702;&#31639;&#27861;&#35782;&#21035;&#23637;&#29616;&#23545;&#31216;&#24615;&#30340;&#27491;&#21017;&#23376;&#36229;&#22270;&#65292;&#20174;&#32780;&#25552;&#39640;&#36229;&#22270;&#22312;&#39640;&#38454;&#38142;&#25509;&#39044;&#27979;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#21306;&#20998;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.11339</link><description>&lt;p&gt;
&#36890;&#36807;&#36229;&#22270;&#23545;&#31216;&#24615;&#25171;&#30772;&#36827;&#34892;&#39640;&#38454;&#38142;&#25509;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Expressive Higher-Order Link Prediction through Hypergraph Symmetry Breaking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11339
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39044;&#22788;&#29702;&#31639;&#27861;&#35782;&#21035;&#23637;&#29616;&#23545;&#31216;&#24615;&#30340;&#27491;&#21017;&#23376;&#36229;&#22270;&#65292;&#20174;&#32780;&#25552;&#39640;&#36229;&#22270;&#22312;&#39640;&#38454;&#38142;&#25509;&#39044;&#27979;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#21306;&#20998;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#36229;&#22270;&#30001;&#19968;&#32452;&#33410;&#28857;&#20197;&#21450;&#31216;&#20026;&#36229;&#36793;&#30340;&#33410;&#28857;&#23376;&#38598;&#21512;&#32452;&#25104;&#12290;&#26356;&#39640;&#38454;&#38142;&#25509;&#39044;&#27979;&#26159;&#39044;&#27979;&#19968;&#20010;&#36229;&#22270;&#20013;&#26159;&#21542;&#23384;&#22312;&#32570;&#22833;&#30340;&#36229;&#36793;&#30340;&#20219;&#21153;&#12290;&#20026;&#39640;&#38454;&#38142;&#25509;&#39044;&#27979;&#23398;&#20064;&#30340;&#36229;&#36793;&#34920;&#31034;&#22312;&#21516;&#26500;&#19979;&#19981;&#22833;&#21435;&#21306;&#20998;&#33021;&#21147;&#26102;&#20855;&#26377;&#23436;&#20840;&#34920;&#36798;&#24615;&#12290;&#35768;&#22810;&#29616;&#26377;&#30340;&#36229;&#22270;&#34920;&#31034;&#23398;&#20064;&#22120;&#21463;&#21040;&#24191;&#20041;Weisfeiler Lehman-1&#65288;GWL-1&#65289;&#31639;&#27861;&#30340;&#34920;&#36798;&#33021;&#21147;&#38480;&#21046;&#65292;&#23427;&#26159;Weisfeiler Lehman-1&#31639;&#27861;&#30340;&#25512;&#24191;&#12290;&#28982;&#32780;&#65292;GWL-1&#30340;&#34920;&#36798;&#33021;&#21147;&#26377;&#38480;&#12290;&#20107;&#23454;&#19978;&#65292;&#20855;&#26377;&#30456;&#21516;GWL-1&#20540;&#33410;&#28857;&#30340;&#35825;&#23548;&#23376;&#36229;&#22270;&#26159;&#26080;&#27861;&#21306;&#20998;&#30340;&#12290;&#27492;&#22806;&#65292;&#22312;&#36229;&#22270;&#19978;&#36827;&#34892;&#28040;&#24687;&#20256;&#36882;&#21487;&#33021;&#24050;&#32463;&#22312;GPU&#20869;&#23384;&#19978;&#21464;&#24471;&#35745;&#31639;&#26114;&#36149;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#21487;&#20197;&#35782;&#21035;&#20986;&#23637;&#29616;&#23545;&#31216;&#24615;&#30340;&#29305;&#23450;&#27491;&#21017;&#23376;&#36229;&#22270;&#30340;&#39044;&#22788;&#29702;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11339v1 Announce Type: new  Abstract: A hypergraph consists of a set of nodes along with a collection of subsets of the nodes called hyperedges. Higher-order link prediction is the task of predicting the existence of a missing hyperedge in a hypergraph. A hyperedge representation learned for higher order link prediction is fully expressive when it does not lose distinguishing power up to an isomorphism. Many existing hypergraph representation learners, are bounded in expressive power by the Generalized Weisfeiler Lehman-1 (GWL-1) algorithm, a generalization of the Weisfeiler Lehman-1 algorithm. However, GWL-1 has limited expressive power. In fact, induced subhypergraphs with identical GWL-1 valued nodes are indistinguishable. Furthermore, message passing on hypergraphs can already be computationally expensive, especially on GPU memory. To address these limitations, we devise a preprocessing algorithm that can identify certain regular subhypergraphs exhibiting symmetry. Our p
&lt;/p&gt;</description></item><item><title>&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25506;&#32034;&#30340;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#32570;&#20047;&#37096;&#20998;&#21453;&#39304;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#31574;&#30053;&#26469;&#30830;&#20445;&#25152;&#26377;&#23376;&#32676;&#20307;&#37117;&#34987;&#25506;&#32034;&#12289;&#38450;&#27490;&#38169;&#35823;&#20998;&#31867;&#12289;&#20197;&#21450;&#25910;&#25947;&#21040;&#26399;&#26395;&#30340;&#20998;&#31867;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.11338</link><description>&lt;p&gt;
&#20855;&#26377;&#37096;&#20998;&#21453;&#39304;&#30340;&#20844;&#24179;&#20998;&#31867;&#65306;&#19968;&#31181;&#22522;&#20110;&#25506;&#32034;&#30340;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fair Classification with Partial Feedback: An Exploration-Based Data-Collection Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11338
&lt;/p&gt;
&lt;p&gt;
&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25506;&#32034;&#30340;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#32570;&#20047;&#37096;&#20998;&#21453;&#39304;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#31574;&#30053;&#26469;&#30830;&#20445;&#25152;&#26377;&#23376;&#32676;&#20307;&#37117;&#34987;&#25506;&#32034;&#12289;&#38450;&#27490;&#38169;&#35823;&#20998;&#31867;&#12289;&#20197;&#21450;&#25910;&#25947;&#21040;&#26399;&#26395;&#30340;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#39044;&#27979;&#22330;&#26223;&#65288;&#20363;&#22914;&#20449;&#36151;&#25918;&#27454;&#65289;&#20013;&#65292;&#21482;&#26377;&#36807;&#21435;&#34987;&#31215;&#26497;&#20998;&#31867;&#30340;&#26679;&#26412;&#25165;&#20250;&#35266;&#23519;&#21040;&#30495;&#23454;&#32467;&#26524;&#12290;&#36825;&#20123;&#36807;&#21435;&#30340;&#35266;&#23519;&#32467;&#26524;&#24418;&#25104;&#20102;&#29992;&#20110;&#35757;&#32451;&#20998;&#31867;&#22120;&#20197;&#36827;&#34892;&#26410;&#26469;&#39044;&#27979;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#32570;&#20047;&#20851;&#20110;&#36807;&#21435;&#65288;&#38169;&#35823;&#22320;&#65289;&#34987;&#36127;&#38754;&#20998;&#31867;&#30340;&#26679;&#26412;&#32467;&#26524;&#30340;&#20449;&#24687;&#65292;&#21487;&#33021;&#23548;&#33268;&#38169;&#35823;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21033;&#29992;&#21487;&#29992;&#25968;&#25454;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20379;&#19968;&#31995;&#21015;&#25506;&#32034;&#31574;&#30053;&#26469;&#25910;&#38598;&#20851;&#20110;&#21542;&#21017;&#20250;&#34987;&#24573;&#30053;&#30340;&#23376;&#32676;&#20307;&#30340;&#32467;&#26524;&#25968;&#25454;&#12290;&#23545;&#20110;&#20219;&#20309;&#25506;&#32034;&#31574;&#30053;&#65292;&#35813;&#26041;&#27861;&#37117;&#20855;&#26377;&#20197;&#19979;&#20445;&#35777;&#65306;&#65288;1&#65289;&#25152;&#26377;&#23376;&#32676;&#20307;&#37117;&#24471;&#21040;&#20102;&#25506;&#32034;&#65292;&#65288;2&#65289;&#20551;&#38451;&#24615;&#30340;&#27604;&#20363;&#21463;&#21040;&#20102;&#38480;&#21046;&#65292;&#65288;3&#65289;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#25910;&#25947;&#21040;&#19968;&#20010;&#8220;&#26399;&#26395;&#8221;&#30340;&#20998;&#31867;&#22120;&#12290;&#27491;&#30830;&#30340;&#25506;&#32034;&#31574;&#30053;&#21462;&#20915;&#20110;&#19978;&#19979;&#25991;&#65307;&#23427;&#21487;&#20197;&#36873;&#25321;&#20197;&#25913;&#21892;&#23398;&#20064;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11338v1 Announce Type: cross  Abstract: In many predictive contexts (e.g., credit lending), true outcomes are only observed for samples that were positively classified in the past. These past observations, in turn, form training datasets for classifiers that make future predictions. However, such training datasets lack information about the outcomes of samples that were (incorrectly) negatively classified in the past and can lead to erroneous classifiers. We present an approach that trains a classifier using available data and comes with a family of exploration strategies to collect outcome data about subpopulations that otherwise would have been ignored. For any exploration strategy, the approach comes with guarantees that (1) all sub-populations are explored, (2) the fraction of false positives is bounded, and (3) the trained classifier converges to a "desired" classifier. The right exploration strategy is context-dependent; it can be chosen to improve learning guarantees 
&lt;/p&gt;</description></item><item><title>&#37325;&#26500;&#23398;&#20064;&#25152;&#20135;&#29983;&#30340;&#29305;&#24449;&#23545;&#24863;&#30693;&#26080;&#29992;&#65292;&#38656;&#35201;&#36890;&#36807;&#20854;&#20182;&#31574;&#30053;&#22914;&#21435;&#22122;&#23398;&#20064;&#26469;&#32531;&#35299;&#36825;&#31181;&#19981;&#19968;&#33268;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11337</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26500;&#23398;&#20064;&#20135;&#29983;&#23545;&#24863;&#30693;&#26080;&#29992;&#30340;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Learning by Reconstruction Produces Uninformative Features For Perception
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11337
&lt;/p&gt;
&lt;p&gt;
&#37325;&#26500;&#23398;&#20064;&#25152;&#20135;&#29983;&#30340;&#29305;&#24449;&#23545;&#24863;&#30693;&#26080;&#29992;&#65292;&#38656;&#35201;&#36890;&#36807;&#20854;&#20182;&#31574;&#30053;&#22914;&#21435;&#22122;&#23398;&#20064;&#26469;&#32531;&#35299;&#36825;&#31181;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36755;&#20837;&#31354;&#38388;&#37325;&#26500;&#26159;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#34920;&#31034;&#23398;&#20064;&#33539;&#24335;&#12290;&#23613;&#31649;&#37325;&#26500;&#21644;&#29983;&#25104;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#36890;&#36807;&#37325;&#26500;&#23398;&#20064;&#19982;&#20026;&#24863;&#30693;&#23398;&#20064;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21069;&#32773;&#23558;&#27169;&#22411;&#30340;&#23481;&#37327;&#20998;&#37197;&#32473;&#35299;&#37322;&#35266;&#23519;&#21040;&#30340;&#26041;&#24046;&#30340;&#25968;&#25454;&#23376;&#31354;&#38388;--&#36825;&#26159;&#23545;&#21518;&#32773;&#26080;&#29992;&#30340;&#29305;&#24449;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11337v1 Announce Type: cross  Abstract: Input space reconstruction is an attractive representation learning paradigm. Despite interpretability of the reconstruction and generation, we identify a misalignment between learning by reconstruction, and learning for perception. We show that the former allocates a model's capacity towards a subspace of the data explaining the observed variance--a subspace with uninformative features for the latter. For example, the supervised TinyImagenet task with images projected onto the top subspace explaining 90\% of the pixel variance can be solved with 45\% test accuracy. Using the bottom subspace instead, accounting for only 20\% of the pixel variance, reaches 55\% test accuracy. The features for perception being learned last explains the need for long training time, e.g., with Masked Autoencoders. Learning by denoising is a popular strategy to alleviate that misalignment. We prove that while some noise strategies such as masking are indeed
&lt;/p&gt;</description></item><item><title>&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20302;&#27491;&#21017;&#24615;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;&#30340;&#20195;&#29702;&#24314;&#27169;&#30340;&#28145;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#26041;&#27861;($\text{DAS}^2$)&#65292;&#36890;&#36807;&#27867;&#21270;&#28145;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#65288;DAS&#65289;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#24230;&#25968;&#25454;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.11283</link><description>&lt;p&gt;
&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#20195;&#29702;&#24314;&#27169;&#30340;&#28145;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deep adaptive sampling for surrogate modeling without labeled data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20302;&#27491;&#21017;&#24615;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;&#30340;&#20195;&#29702;&#24314;&#27169;&#30340;&#28145;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#26041;&#27861;($\text{DAS}^2$)&#65292;&#36890;&#36807;&#27867;&#21270;&#28145;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#65288;DAS&#65289;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#24230;&#25968;&#25454;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#29702;&#24314;&#27169;&#23545;&#20110;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#20855;&#26377;&#37325;&#35201;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;&#19982;&#20256;&#32479;&#30340;&#25968;&#20540;&#26041;&#27861;&#30456;&#27604;&#65292;&#20351;&#29992;&#29289;&#29702;&#20449;&#24687;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26500;&#24314;&#36825;&#20123;&#31995;&#32479;&#30340;&#27169;&#25311;&#22120;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#22788;&#29702;&#39640;&#32500;&#24230;&#65292;&#36825;&#38656;&#35201;&#36890;&#36807;&#35757;&#32451;&#19968;&#32452;&#38543;&#26426;&#26679;&#26412;&#26469;&#26368;&#23567;&#21270;&#25439;&#22833;&#12290;&#28982;&#32780;&#65292;&#38543;&#26426;&#26679;&#26412;&#24341;&#20837;&#20102;&#32479;&#35745;&#35823;&#24046;&#65292;&#36825;&#21487;&#33021;&#25104;&#20026;&#20302;&#27491;&#21017;&#24615;&#21644;&#39640;&#32500;&#38382;&#39064;&#36817;&#20284;&#30340;&#20027;&#35201;&#35823;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20302;&#27491;&#21017;&#24615;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;&#30340;&#20195;&#29702;&#24314;&#27169;&#30340;&#28145;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#26041;&#27861;&#65288;$\text{DAS}^2$&#65289;&#65292;&#20854;&#20013;&#25105;&#20204;&#23558;&#28145;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#65288;DAS&#65289;&#26041;&#27861;&#25512;&#24191;&#21040;&#24314;&#31435;&#20302;&#27491;&#21017;&#24615;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;&#30340;&#20195;&#29702;&#27169;&#22411;&#12290;&#22312;&#21442;&#25968;&#35774;&#32622;&#20013;&#65292;&#27531;&#24046;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#26410;&#24402;&#19968;&#21270;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;PDF&#65289;&#30340;&#20272;&#35745;.
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11283v1 Announce Type: cross  Abstract: Surrogate modeling is of great practical significance for parametric differential equation systems. In contrast to classical numerical methods, using physics-informed deep learning methods to construct simulators for such systems is a promising direction due to its potential to handle high dimensionality, which requires minimizing a loss over a training set of random samples. However, the random samples introduce statistical errors, which may become the dominant errors for the approximation of low-regularity and high-dimensional problems. In this work, we present a deep adaptive sampling method for surrogate modeling ($\text{DAS}^2$), where we generalize the deep adaptive sampling (DAS) method [62] [Tang, Wan and Yang, 2023] to build surrogate models for low-regularity parametric differential equations. In the parametric setting, the residual loss function can be regarded as an unnormalized probability density function (PDF) of the spa
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#33258;&#36866;&#24212;&#20998;&#21106;&#24179;&#34913;&#26862;&#26519;&#65288;ASBF&#65289;&#65292;&#21487;&#22312;&#23398;&#20064;&#26641;&#34920;&#31034;&#30340;&#21516;&#26102;&#65292;&#22312;&#22797;&#26434;&#24773;&#20917;&#19979;&#23454;&#29616;&#26497;&#23567;&#26497;&#20248;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26412;&#22320;&#21270;&#29256;&#26412;&#65292;&#22312;H\"older&#31867;&#19979;&#36798;&#21040;&#26368;&#23567;&#26497;&#20248;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11228</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#20998;&#21106;&#24179;&#34913;&#20248;&#21270;&#38543;&#26426;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Adaptive Split Balancing for Optimal Random Forest
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11228
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#33258;&#36866;&#24212;&#20998;&#21106;&#24179;&#34913;&#26862;&#26519;&#65288;ASBF&#65289;&#65292;&#21487;&#22312;&#23398;&#20064;&#26641;&#34920;&#31034;&#30340;&#21516;&#26102;&#65292;&#22312;&#22797;&#26434;&#24773;&#20917;&#19979;&#23454;&#29616;&#26497;&#23567;&#26497;&#20248;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26412;&#22320;&#21270;&#29256;&#26412;&#65292;&#22312;H\"older&#31867;&#19979;&#36798;&#21040;&#26368;&#23567;&#26497;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#38543;&#26426;&#26862;&#26519;&#36890;&#24120;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#22312;&#22797;&#26434;&#24773;&#20917;&#19979;&#32570;&#20047;&#36866;&#24212;&#24615;&#65292;&#25110;&#22312;&#31616;&#21333;&#12289;&#24179;&#28369;&#24773;&#26223;&#19979;&#22833;&#21435;&#26368;&#20248;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#33258;&#36866;&#24212;&#20998;&#21106;&#24179;&#34913;&#26862;&#26519;&#65288;ASBF&#65289;&#65292;&#33021;&#22815;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#26641;&#34920;&#31034;&#65292;&#21516;&#26102;&#22312;Lipschitz&#31867;&#19979;&#23454;&#29616;&#26497;&#23567;&#26497;&#20248;&#24615;&#12290;&#20026;&#20102;&#21033;&#29992;&#26356;&#39640;&#38454;&#30340;&#24179;&#28369;&#24615;&#27700;&#24179;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#26412;&#22320;&#21270;&#29256;&#26412;&#65292;&#35813;&#29256;&#26412;&#22312;&#20219;&#24847;$q \in \mathbb{N}$&#21644;$\beta \in (0,1]$&#30340;H&#246;lder&#31867;$\mathcal{H}^{q,\beta}$&#19979;&#36798;&#21040;&#26368;&#23567;&#26497;&#20248;&#24615;&#12290;&#19982;&#24191;&#27867;&#20351;&#29992;&#30340;&#38543;&#26426;&#29305;&#24449;&#36873;&#25321;&#19981;&#21516;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#23545;&#29616;&#26377;&#26041;&#27861;&#30340;&#24179;&#34913;&#20462;&#25913;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36807;&#24230;&#20381;&#36182;&#36741;&#21161;&#38543;&#26426;&#24615;&#21487;&#33021;&#20250;&#25439;&#23475;&#26641;&#27169;&#22411;&#30340;&#36924;&#36817;&#33021;&#21147;&#65292;&#23548;&#33268;&#27425;&#20248;&#32467;&#26524;&#12290;&#30456;&#21453;&#65292;&#19968;&#20010;&#26356;&#24179;&#34913;&#12289;&#26356;&#23569;&#38543;&#26426;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11228v1 Announce Type: cross  Abstract: While random forests are commonly used for regression problems, existing methods often lack adaptability in complex situations or lose optimality under simple, smooth scenarios. In this study, we introduce the adaptive split balancing forest (ASBF), capable of learning tree representations from data while simultaneously achieving minimax optimality under the Lipschitz class. To exploit higher-order smoothness levels, we further propose a localized version that attains the minimax rate under the H\"older class $\mathcal{H}^{q,\beta}$ for any $q\in\mathbb{N}$ and $\beta\in(0,1]$. Rather than relying on the widely-used random feature selection, we consider a balanced modification to existing approaches. Our results indicate that an over-reliance on auxiliary randomness may compromise the approximation power of tree models, leading to suboptimal results. Conversely, a less random, more balanced approach demonstrates optimality. Additionall
&lt;/p&gt;</description></item><item><title>AdAdaGrad&#21644;AdAdaGradNorm&#26159;&#19968;&#20010;&#33258;&#36866;&#24212;&#22686;&#21152;&#25209;&#22823;&#23567;&#30340;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#31574;&#30053;&#65292;&#35777;&#26126;AdaGradNorm&#20197;&#39640;&#27010;&#29575;&#22312;$O(1/K)$&#36895;&#24230;&#19979;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2402.11215</link><description>&lt;p&gt;
AdAdaGrad&#65306;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#30340;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
AdAdaGrad: Adaptive Batch Size Schemes for Adaptive Gradient Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11215
&lt;/p&gt;
&lt;p&gt;
AdAdaGrad&#21644;AdAdaGradNorm&#26159;&#19968;&#20010;&#33258;&#36866;&#24212;&#22686;&#21152;&#25209;&#22823;&#23567;&#30340;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#31574;&#30053;&#65292;&#35777;&#26126;AdaGradNorm&#20197;&#39640;&#27010;&#29575;&#22312;$O(1/K)$&#36895;&#24230;&#19979;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#20248;&#21270;&#22120;&#20013;&#25209;&#37327;&#22823;&#23567;&#30340;&#36873;&#25321;&#23545;&#27169;&#22411;&#35757;&#32451;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21464;&#21270;&#25209;&#22823;&#23567;&#30340;&#23454;&#36341;&#30456;&#23545;&#20854;&#20182;&#36229;&#21442;&#25968;&#36739;&#23569;&#25506;&#35752;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#33258;&#36866;&#24212;&#37319;&#26679;&#26041;&#27861;&#20013;&#23548;&#20986;&#30340;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#31574;&#30053;&#65292;&#20256;&#32479;&#19978;&#20165;&#24212;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#12290;&#32771;&#34385;&#21040;&#23398;&#20064;&#36895;&#29575;&#21644;&#25209;&#22823;&#23567;&#20043;&#38388;&#30340;&#26174;&#33879;&#30456;&#20114;&#20316;&#29992;&#65292;&#20197;&#21450;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#26222;&#21450;&#65292;&#25105;&#20204;&#24378;&#35843;&#22312;&#36825;&#20123;&#24773;&#22659;&#20013;&#38656;&#35201;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#31574;&#30053;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;AdAdaGrad&#21450;&#20854;&#26631;&#37327;&#21464;&#20307;AdAdaGradNorm&#65292;&#23427;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#22686;&#21152;&#25209;&#22823;&#23567;&#65292;&#21516;&#26102;&#20351;&#29992;AdaGrad&#21644;AdaGradNorm&#36827;&#34892;&#27169;&#22411;&#26356;&#26032;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;AdaGradNorm&#20197;&#39640;&#27010;&#29575;&#20197;$O(1/K)$&#30340;&#36895;&#24230;&#25910;&#25947;&#65292;&#29992;&#20110;&#25214;&#21040;&#20809;&#28369;&#38750;&#20984;&#20989;&#25968;&#30340;&#19968;&#38454;&#31283;&#23450;&#28857;&#22312;$K$&#27425;&#36845;&#20195;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11215v1 Announce Type: new  Abstract: The choice of batch sizes in stochastic gradient optimizers is critical for model training. However, the practice of varying batch sizes throughout the training process is less explored compared to other hyperparameters. We investigate adaptive batch size strategies derived from adaptive sampling methods, traditionally applied only in stochastic gradient descent. Given the significant interplay between learning rates and batch sizes, and considering the prevalence of adaptive gradient methods in deep learning, we emphasize the need for adaptive batch size strategies in these contexts. We introduce AdAdaGrad and its scalar variant AdAdaGradNorm, which incrementally increase batch sizes during training, while model updates are performed using AdaGrad and AdaGradNorm. We prove that AdaGradNorm converges with high probability at a rate of $\mathscr{O}(1/K)$ for finding a first-order stationary point of smooth nonconvex functions within $K$ i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#26041;&#27861;LowPopArt&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#37327;B(Q)&#25552;&#20379;&#26356;&#32039;&#23494;&#30340;&#24674;&#22797;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#39564;&#35774;&#35745;&#26631;&#20934;&#65292;&#20197;&#21450;&#20004;&#31181;&#36866;&#29992;&#20110;&#19968;&#33324;Arm&#38598;&#30340;&#20302;&#31209;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.11156</link><description>&lt;p&gt;
&#39640;&#25928;&#30340;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#12289;&#23454;&#39564;&#35774;&#35745;&#21644;&#22522;&#20110;Arm&#38598;&#30340;&#20302;&#31209;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Efficient Low-Rank Matrix Estimation, Experimental Design, and Arm-Set-Dependent Low-Rank Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11156
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#26041;&#27861;LowPopArt&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#37327;B(Q)&#25552;&#20379;&#26356;&#32039;&#23494;&#30340;&#24674;&#22797;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#39564;&#35774;&#35745;&#26631;&#20934;&#65292;&#20197;&#21450;&#20004;&#31181;&#36866;&#29992;&#20110;&#19968;&#33324;Arm&#38598;&#30340;&#20302;&#31209;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20302;&#31209;&#30697;&#38453;&#36857;&#22238;&#24402;&#21644;&#30456;&#20851;&#30340;&#20302;&#31209;&#30697;&#38453;&#36172;&#21338;&#38382;&#39064;&#12290;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#21327;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LowPopArt&#30340;&#26032;&#22411;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#20854;&#20381;&#36182;&#20110;&#19968;&#20010;&#26032;&#39062;&#25968;&#37327;B(Q)&#30340;&#24674;&#22797;&#20445;&#35777;&#65292;&#35813;&#25968;&#37327;&#34920;&#24449;&#20102;&#38382;&#39064;&#30340;&#38590;&#24230;&#65292;&#20854;&#20013;Q&#26159;&#27979;&#37327;&#20998;&#24067;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20960;&#20010;&#38382;&#39064;&#20013;&#21487;&#20197;&#25552;&#20379;&#27604;&#32463;&#20856;&#30340;&#26680;&#33539;&#25968;&#24809;&#32602;&#26368;&#23567;&#20108;&#20056;&#27861;&#65288;Koltchinskii&#31561;&#20154;&#65292;2011&#65289;&#26356;&#32039;&#23494;&#30340;&#24674;&#22797;&#20445;&#35777;&#12290;&#20026;&#20102;&#22312;&#20174;&#20219;&#24847;&#32473;&#23450;&#30340;&#27979;&#37327;&#38598;&#21512;A&#20013;&#36827;&#34892;&#26377;&#38480;&#27979;&#37327;&#30340;&#24773;&#20917;&#19979;&#25191;&#34892;&#39640;&#25928;&#20272;&#35745;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#39564;&#35774;&#35745;&#26631;&#20934;&#65292;&#35813;&#26631;&#20934;&#20197;&#35745;&#31639;&#25928;&#29575;&#26368;&#23567;&#21270;B(Q)&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#26032;&#39062;&#20272;&#35745;&#22120;&#21644;&#23454;&#39564;&#35774;&#35745;&#25512;&#23548;&#20102;&#20004;&#31181;&#36866;&#29992;&#20110;&#19968;&#33324;Arm&#38598;&#30340;&#20302;&#31209;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#65292;&#20854;&#20139;&#26377;&#25913;&#36827;&#30340;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11156v1 Announce Type: cross  Abstract: We study low-rank matrix trace regression and the related problem of low-rank matrix bandits. Assuming access to the distribution of the covariates, we propose a novel low-rank matrix estimation method called LowPopArt and provide its recovery guarantee that depends on a novel quantity denoted by B(Q) that characterizes the hardness of the problem, where Q is the covariance matrix of the measurement distribution. We show that our method can provide tighter recovery guarantees than classical nuclear norm penalized least squares (Koltchinskii et al., 2011) in several problems. To perform efficient estimation with a limited number of measurements from an arbitrarily given measurement set A, we also propose a novel experimental design criterion that minimizes B(Q) with computational efficiency. We leverage our novel estimator and design of experiments to derive two low-rank linear bandit algorithms for general arm sets that enjoy improved 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20989;&#25968;&#20559;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65292;&#20854;&#22312;&#19968;&#31867;&#26925;&#29699;&#19978;&#23454;&#29616;&#20102;&#65288;&#36817;&#20046;&#65289;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#36866;&#24212;&#26410;&#30693;&#36870;&#38382;&#39064;&#24230;&#30340;&#25552;&#21069;&#20572;&#27490;&#35268;&#21017;&#12290;</title><link>https://arxiv.org/abs/2402.11134</link><description>&lt;p&gt;
&#20989;&#25968;&#20559;&#26368;&#23567;&#20108;&#20056;&#27861;&#65306;&#26368;&#20248;&#25910;&#25947;&#29575;&#21644;&#33258;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Functional Partial Least-Squares: Optimal Rates and Adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11134
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20989;&#25968;&#20559;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65292;&#20854;&#22312;&#19968;&#31867;&#26925;&#29699;&#19978;&#23454;&#29616;&#20102;&#65288;&#36817;&#20046;&#65289;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#36866;&#24212;&#26410;&#30693;&#36870;&#38382;&#39064;&#24230;&#30340;&#25552;&#21069;&#20572;&#27490;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#26631;&#37327;&#21709;&#24212;&#21644; Hilbert &#31354;&#38388;&#20540;&#39044;&#27979;&#21464;&#37327;&#30340;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#21453;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#20849;&#36717;&#26799;&#24230;&#26041;&#27861;&#30456;&#20851;&#30340;&#20989;&#25968;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#20272;&#35745;&#30340;&#26032;&#20844;&#24335;&#12290;&#25105;&#20204;&#23558;&#23637;&#31034;&#35813;&#20272;&#35745;&#22120;&#22312;&#19968;&#31867;&#26925;&#29699;&#19978;&#23454;&#29616;&#20102;&#65288;&#36817;&#20046;&#65289;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#33021;&#22815;&#36866;&#24212;&#26410;&#30693;&#36870;&#38382;&#39064;&#24230;&#30340;&#25552;&#21069;&#20572;&#27490;&#35268;&#21017;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20272;&#35745;&#22120;&#19982;&#20027;&#25104;&#20998;&#22238;&#24402;&#20272;&#35745;&#22120;&#20043;&#38388;&#30340;&#19968;&#20123;&#29702;&#35770;&#21644;&#20223;&#30495;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11134v1 Announce Type: cross  Abstract: We consider the functional linear regression model with a scalar response and a Hilbert space-valued predictor, a well-known ill-posed inverse problem. We propose a new formulation of the functional partial least-squares (PLS) estimator related to the conjugate gradient method. We shall show that the estimator achieves the (nearly) optimal convergence rate on a class of ellipsoids and we introduce an early stopping rule which adapts to the unknown degree of ill-posedness. Some theoretical and simulation comparison between the estimator and the principal component regression estimator is provided.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24314;&#31435;&#23545;&#25239;&#30446;&#26631;&#25439;&#22833;&#30340;&#27867;&#21270;&#30028;&#38480;&#26469;&#35299;&#20915;&#30446;&#26631;&#22495;&#26631;&#31614;&#32570;&#22833;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.11120</link><description>&lt;p&gt;
DART: &#19968;&#31181;&#38754;&#21521;&#23545;&#25239;&#40065;&#26834;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DART: A Principled Approach to Adversarially Robust Unsupervised Domain Adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24314;&#31435;&#23545;&#25239;&#30446;&#26631;&#25439;&#22833;&#30340;&#27867;&#21270;&#30028;&#38480;&#26469;&#35299;&#20915;&#30446;&#26631;&#22495;&#26631;&#31614;&#32570;&#22833;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#36716;&#31227;&#21644;&#23545;&#25239;&#26679;&#26412;&#26159;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38754;&#20020;&#30340;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#34429;&#28982;&#36825;&#20123;&#25361;&#25112;&#24050;&#34987;&#20998;&#21035;&#30740;&#31350;&#65292;&#20294;&#23427;&#20204;&#30340;&#32467;&#21512;&#20173;&#28982;&#26159;&#19968;&#20010;&#30456;&#23545;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#37325;&#35201;&#20027;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#24120;&#35265;&#30340;&#20998;&#24067;&#36716;&#31227;&#35774;&#32622;&#19979;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#38382;&#39064;&#65292;&#21363;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#12290;&#20855;&#20307;&#22320;&#65292;&#32473;&#23450;&#19968;&#20010;&#24102;&#26631;&#31614;&#30340;&#28304;&#22495; $D_S$ &#21644;&#19968;&#20010;&#24102;&#26377;&#30456;&#20851;&#20294;&#19981;&#21516;&#20998;&#24067;&#30340;&#26410;&#26631;&#35760;&#30446;&#26631;&#22495; $D_T$&#65292;&#30446;&#26631;&#26159;&#20026; $D_T$ &#33719;&#24471;&#19968;&#20010;&#23545;&#25239;&#40065;&#26834;&#30340;&#27169;&#22411;&#12290;&#30446;&#26631;&#22495;&#26631;&#31614;&#30340;&#32570;&#22833;&#25552;&#20986;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#20256;&#32479;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#38450;&#24481;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110; $D_T$&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#23545;&#25239;&#30446;&#26631;&#25439;&#22833;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#20854;&#20013;&#21253;&#25324;&#19982;&#25968;&#25454;&#25439;&#22833;&#30456;&#20851;&#30340;&#39033;&#21644;&#26368;&#22351;&#24773;&#20917;&#22495;&#20998;&#27495;&#30340;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11120v1 Announce Type: new  Abstract: Distribution shifts and adversarial examples are two major challenges for deploying machine learning models. While these challenges have been studied individually, their combination is an important topic that remains relatively under-explored. In this work, we study the problem of adversarial robustness under a common setting of distribution shift - unsupervised domain adaptation (UDA). Specifically, given a labeled source domain $D_S$ and an unlabeled target domain $D_T$ with related but different distributions, the goal is to obtain an adversarially robust model for $D_T$. The absence of target domain labels poses a unique challenge, as conventional adversarial robustness defenses cannot be directly applied to $D_T$. To address this challenge, we first establish a generalization bound for the adversarial target loss, which consists of (i) terms related to the loss on the data, and (ii) a measure of worst-case domain divergence. Motivat
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24471;&#20998;&#35268;&#21017;&#26500;&#24314;&#27010;&#29575;&#39044;&#27979;&#26641;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#26641;&#30340;&#39044;&#27979;&#24615;&#33021;&#24182;&#29983;&#25104;&#26356;&#22909;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;</title><link>https://arxiv.org/abs/2402.11052</link><description>&lt;p&gt;
&#36890;&#36807;&#24471;&#20998;&#35268;&#21017;&#26500;&#24314;&#27010;&#29575;&#39044;&#27979;&#26641;
&lt;/p&gt;
&lt;p&gt;
Building Trees for Probabilistic Prediction via Scoring Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11052
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24471;&#20998;&#35268;&#21017;&#26500;&#24314;&#27010;&#29575;&#39044;&#27979;&#26641;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#26641;&#30340;&#39044;&#27979;&#24615;&#33021;&#24182;&#29983;&#25104;&#26356;&#22909;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#26500;&#24314;&#30340;&#20915;&#31574;&#26641;&#22312;&#38750;&#21442;&#25968;&#39044;&#27979;&#20013;&#20173;&#28982;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#22312;&#19981;&#30830;&#23450;&#24615;&#22312;&#20998;&#26512;&#21644;&#20915;&#31574;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#26102;&#65292;&#39044;&#27979;&#27010;&#29575;&#20998;&#24067;&#20248;&#20110;&#28857;&#39044;&#27979;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20462;&#25913;&#26641;&#20197;&#29983;&#25104;&#38750;&#21442;&#25968;&#39044;&#27979;&#20998;&#24067;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20351;&#29992;&#26631;&#20934;&#26041;&#27861;&#26500;&#24314;&#26641;&#21487;&#33021;&#19981;&#20250;&#20135;&#29983;&#33391;&#22909;&#30340;&#39044;&#27979;&#20998;&#24067;&#65292;&#24182;&#25552;&#20986;&#23558;&#26641;&#30340;&#20998;&#21106;&#26631;&#20934;&#26356;&#25913;&#20026;&#22522;&#20110;&#36866;&#24403;&#24471;&#20998;&#35268;&#21017;&#30340;&#26631;&#20934;&#12290;&#23545;&#27169;&#25311;&#25968;&#25454;&#21644;&#20960;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#20351;&#29992;&#36825;&#20123;&#26032;&#30340;&#20998;&#21106;&#26631;&#20934;&#20250;&#23548;&#33268;&#20855;&#26377;&#25913;&#36827;&#39044;&#27979;&#24615;&#33021;&#30340;&#26641;&#65292;&#32771;&#34385;&#25972;&#20010;&#39044;&#27979;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11052v1 Announce Type: cross  Abstract: Decision trees built with data remain in widespread use for nonparametric prediction. Predicting probability distributions is preferred over point predictions when uncertainty plays a prominent role in analysis and decision-making. We study modifying a tree to produce nonparametric predictive distributions. We find the standard method for building trees may not result in good predictive distributions and propose changing the splitting criteria for trees to one based on proper scoring rules. Analysis of both simulated data and several real datasets demonstrates that using these new splitting criteria results in trees with improved predictive properties considering the entire predictive distribution.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RAD&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39046;&#22495;&#26631;&#27880;&#30340;&#27491;&#21017;&#21270;&#26469;&#35757;&#32451;&#40065;&#26834;&#30340;&#26368;&#21518;&#19968;&#23618;&#20998;&#31867;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30340;&#39046;&#22495;&#26631;&#27880;&#65292;&#22312;&#20855;&#26377;&#39046;&#22495;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20248;&#36234;&#12290;</title><link>https://arxiv.org/abs/2402.11039</link><description>&lt;p&gt;
&#20855;&#26377;&#39046;&#22495;&#26631;&#31614;&#22122;&#22768;&#30340;&#20122;&#32676;&#20307;&#36716;&#31227;&#40065;&#26834;&#24615;&#36890;&#36807;&#39046;&#22495;&#26631;&#27880;&#30340;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robustness to Subpopulation Shift with Domain Label Noise via Regularized Annotation of Domains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11039
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RAD&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39046;&#22495;&#26631;&#27880;&#30340;&#27491;&#21017;&#21270;&#26469;&#35757;&#32451;&#40065;&#26834;&#30340;&#26368;&#21518;&#19968;&#23618;&#20998;&#31867;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30340;&#39046;&#22495;&#26631;&#27880;&#65292;&#22312;&#20855;&#26377;&#39046;&#22495;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#38024;&#23545;&#26368;&#20248;&#32452;&#20934;&#30830;&#24615;(WGA)&#36827;&#34892;&#26368;&#21518;&#19968;&#23618;&#37325;&#26032;&#35757;&#32451;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#36807;&#20110;&#20381;&#36182;&#20110;&#33391;&#22909;&#26631;&#27880;&#30340;&#32452;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#36341;&#20013;&#23637;&#31034;&#20102;&#65292;&#22522;&#20110;&#27880;&#37322;&#30340;&#25968;&#25454;&#22686;&#24378;&#20351;&#29992;&#19979;&#37319;&#26679;&#25110;&#19978;&#21152;&#26435;&#29992;&#20110;WGA&#26159;&#23481;&#26131;&#21463;&#21040;&#39046;&#22495;&#26631;&#27880;&#22122;&#22768;&#24178;&#25200;&#65292;&#22312;&#39640;&#22122;&#22768;&#24773;&#20917;&#19979;&#25509;&#36817;&#20351;&#29992;&#21407;&#22987;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;WGA&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#39046;&#22495;&#26631;&#27880;&#27491;&#21017;&#21270;(RAD)&#26469;&#35757;&#32451;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#21518;&#19968;&#23618;&#20998;&#31867;&#22120;&#65292;&#32780;&#26080;&#38656;&#26126;&#30830;&#30340;&#39046;&#22495;&#26631;&#27880;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;RAD&#19982;&#20854;&#20182;&#26368;&#36817;&#25552;&#20986;&#30340;&#26080;&#39046;&#22495;&#26631;&#27880;&#25216;&#26415;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#20165;&#26377;5%&#30340;&#22122;&#22768;&#65292;RAD&#20063;&#22312;&#20960;&#20010;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#19978;&#32988;&#36807;&#26368;&#20808;&#36827;&#30340;&#20381;&#36182;&#27880;&#37322;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11039v1 Announce Type: new  Abstract: Existing methods for last layer retraining that aim to optimize worst-group accuracy (WGA) rely heavily on well-annotated groups in the training data. We show, both in theory and practice, that annotation-based data augmentations using either downsampling or upweighting for WGA are susceptible to domain annotation noise, and in high-noise regimes approach the WGA of a model trained with vanilla empirical risk minimization. We introduce Regularized Annotation of Domains (RAD) in order to train robust last layer classifiers without the need for explicit domain annotations. Our results show that RAD is competitive with other recently proposed domain annotation-free techniques. Most importantly, RAD outperforms state-of-the-art annotation-reliant methods even with only 5% noise in the training data for several publicly available datasets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#31232;&#30095;&#23376;&#31354;&#38388;&#21464;&#20998;&#25512;&#26029;&#65288;SSVI&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#35757;&#32451;&#21644;&#25512;&#26029;&#38454;&#27573;&#22987;&#32456;&#20445;&#25345;&#39640;&#24230;&#31232;&#30095;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#20840;&#31232;&#30095;BNN&#26694;&#26550;</title><link>https://arxiv.org/abs/2402.11025</link><description>&lt;p&gt;
&#20351;&#29992;&#31232;&#30095;&#23376;&#31354;&#38388;&#21464;&#20998;&#25512;&#26029;&#35757;&#32451;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Training Bayesian Neural Networks with Sparse Subspace Variational Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11025
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#31232;&#30095;&#23376;&#31354;&#38388;&#21464;&#20998;&#25512;&#26029;&#65288;SSVI&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#35757;&#32451;&#21644;&#25512;&#26029;&#38454;&#27573;&#22987;&#32456;&#20445;&#25345;&#39640;&#24230;&#31232;&#30095;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#20840;&#31232;&#30095;BNN&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#25552;&#20379;&#20102;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#20195;&#20215;&#26159;&#22823;&#24133;&#22686;&#21152;&#35757;&#32451;&#21644;&#25512;&#26029;&#25104;&#26412;&#12290;&#31232;&#30095;BNN&#24050;&#34987;&#30740;&#31350;&#29992;&#20110;&#39640;&#25928;&#25512;&#26029;&#65292;&#36890;&#24120;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#24341;&#20837;&#31232;&#30095;&#24615;&#25110;&#36890;&#36807;&#21518;&#32493;&#23545;&#23494;&#38598;BNN&#36827;&#34892;&#21387;&#32553;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#38477;&#20302;&#24040;&#22823;&#30340;&#35757;&#32451;&#25104;&#26412;&#20173;&#28982;&#26159;&#19968;&#20010;&#38590;&#39064;&#65292;&#29305;&#21035;&#26159;&#32771;&#34385;&#21040;&#38656;&#35201;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31232;&#30095;&#23376;&#31354;&#38388;&#21464;&#20998;&#25512;&#26029;&#65288;SSVI&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#35757;&#32451;&#21644;&#25512;&#26029;&#38454;&#27573;&#22987;&#32456;&#20445;&#25345;&#39640;&#24230;&#31232;&#30095;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#20840;&#31232;&#30095;BNN&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20174;&#19968;&#20010;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#20302;&#32500;&#31232;&#30095;&#23376;&#31354;&#38388;&#24320;&#22987;&#65292;&#20132;&#26367;&#20248;&#21270;&#31232;&#30095;&#23376;&#31354;&#38388;&#22522;&#21521;&#37327;&#30340;&#36873;&#25321;&#20197;&#21450;&#30456;&#20851;&#21442;&#25968;&#12290;&#23613;&#31649;&#22522;&#21521;&#37327;&#36873;&#25321;&#34987;&#25551;&#36848;&#20026;&#19968;&#20010;&#19981;&#21487;&#24494;&#20998;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#36817;&#20284;&#27714;&#35299;&#35813;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11025v1 Announce Type: new  Abstract: Bayesian neural networks (BNNs) offer uncertainty quantification but come with the downside of substantially increased training and inference costs. Sparse BNNs have been investigated for efficient inference, typically by either slowly introducing sparsity throughout the training or by post-training compression of dense BNNs. The dilemma of how to cut down massive training costs remains, particularly given the requirement to learn about the uncertainty. To solve this challenge, we introduce Sparse Subspace Variational Inference (SSVI), the first fully sparse BNN framework that maintains a consistently highly sparse Bayesian model throughout the training and inference phases. Starting from a randomly initialized low-dimensional sparse subspace, our approach alternately optimizes the sparse subspace basis selection and its associated parameters. While basis selection is characterized as a non-differentiable problem, we approximate the opti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#23616;&#38480;&#24615;&#65292;&#21457;&#29616;&#20854;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#27867;&#21270;&#33021;&#21147;&#19981;&#36275;&#30340;&#21407;&#22240;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;SAMformer&#65292;&#36890;&#36807;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#36991;&#20813;&#20102;&#38519;&#20837;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#24182;&#22312;&#24120;&#29992;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#12290;</title><link>https://arxiv.org/abs/2402.10198</link><description>&lt;p&gt;
&#20351;&#29992;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#21644;&#36890;&#36947;&#27880;&#24847;&#21147;&#35299;&#38145;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#23616;&#38480;&#24615;&#65292;&#21457;&#29616;&#20854;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#27867;&#21270;&#33021;&#21147;&#19981;&#36275;&#30340;&#21407;&#22240;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;SAMformer&#65292;&#36890;&#36807;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#36991;&#20813;&#20102;&#38519;&#20837;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#24182;&#22312;&#24120;&#29992;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26550;&#26500;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#21462;&#24471;&#20102;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#22810;&#20803;&#38271;&#26399;&#39044;&#27979;&#26041;&#38754;&#65292;&#23427;&#20204;&#20173;&#28982;&#19981;&#22914;&#26356;&#31616;&#21333;&#30340;&#32447;&#24615;&#22522;&#32447;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#19968;&#20010;&#29609;&#20855;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#23613;&#31649;Transformer&#20855;&#26377;&#39640;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#26080;&#27861;&#25910;&#25947;&#21040;&#30495;&#27491;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;Transformer&#30340;&#27880;&#24847;&#21147;&#26159;&#36896;&#25104;&#20854;&#20302;&#27867;&#21270;&#33021;&#21147;&#30340;&#21407;&#22240;&#12290;&#22522;&#20110;&#36825;&#19968;&#35748;&#35782;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;&#65292;&#22312;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#25104;&#21151;&#36991;&#20813;&#20102;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20010;&#32467;&#26524;&#36866;&#29992;&#20110;&#25152;&#26377;&#24120;&#29992;&#30340;&#23454;&#38469;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;&#29305;&#21035;&#26159;&#65292;&#30456;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#65292;SAMformer&#30340;&#24179;&#22343;&#24615;&#33021;&#25552;&#39640;&#20102;14.33%&#65292;&#24182;&#19988;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569;&#20102;&#32422;4&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10198v1 Announce Type: new  Abstract: Transformer-based architectures achieved breakthrough performance in natural language processing and computer vision, yet they remain inferior to simpler linear baselines in multivariate long-term forecasting. To better understand this phenomenon, we start by studying a toy linear forecasting problem for which we show that transformers are incapable of converging to their true solution despite their high expressive power. We further identify the attention of transformers as being responsible for this low generalization capacity. Building upon this insight, we propose a shallow lightweight transformer model that successfully escapes bad local minima when optimized with sharpness-aware optimization. We empirically demonstrate that this result extends to all commonly used real-world multivariate time series datasets. In particular, SAMformer surpasses the current state-of-the-art model TSMixer by 14.33% on average, while having ~4 times few
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07355</link><description>&lt;p&gt;
&#20174;&#22343;&#22330;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling from the Mean-Field Stationary Distribution
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#25110;&#32773;&#31561;&#20215;&#22320;&#65292;&#21363;&#21253;&#21547;&#20132;&#20114;&#39033;&#30340;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#26368;&#23567;&#21270;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#27934;&#23519;&#26159;&#23558;&#36825;&#20010;&#38382;&#39064;&#30340;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;&#35299;&#32806;&#65306;(1) &#36890;&#36807;&#26377;&#38480;&#31890;&#23376;&#31995;&#32479;&#36924;&#36817;&#22343;&#22330;SDE&#65292;&#36890;&#36807;&#26102;&#38388;&#22343;&#21248;&#20256;&#25773;&#28151;&#27788;&#65292;&#21644;(2) &#36890;&#36807;&#26631;&#20934;&#23545;&#25968;&#20985;&#25277;&#26679;&#22120;&#20174;&#26377;&#38480;&#31890;&#23376;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#26356;&#31616;&#21333;&#65292;&#20854;&#28789;&#27963;&#24615;&#20801;&#35768;&#32467;&#21512;&#29992;&#20110;&#31639;&#27861;&#21644;&#29702;&#35770;&#30340;&#26368;&#26032;&#25216;&#26415;&#12290;&#36825;&#23548;&#33268;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the complexity of sampling from the stationary distribution of a mean-field SDE, or equivalently, the complexity of minimizing a functional over the space of probability measures which includes an interaction term.   Our main insight is to decouple the two key aspects of this problem: (1) approximation of the mean-field SDE via a finite-particle system, via uniform-in-time propagation of chaos, and (2) sampling from the finite-particle stationary distribution, via standard log-concave samplers. Our approach is conceptually simpler and its flexibility allows for incorporating the state-of-the-art for both algorithms and theory. This leads to improved guarantees in numerous settings, including better guarantees for optimizing certain two-layer neural networks in the mean-field regime.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PEAK&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#30340;&#26816;&#39564;&#12290;PEAK&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.06122</link><description>&lt;p&gt;
&#20351;&#29992;PEAK&#36827;&#34892;&#31397;&#25506;&#65306;&#22810;&#20010;&#25968;&#25454;&#27969;&#22343;&#20540;&#30340;&#39034;&#24207;&#12289;&#38750;&#21442;&#25968;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PEAK&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#30340;&#26816;&#39564;&#12290;PEAK&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21517;&#20026;PEAK&#65288;&#22522;&#20110;&#26399;&#26395;&#24179;&#22343;&#36164;&#20135;&#30340;&#31397;&#25506;&#65289;&#65292;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#30340;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#27979;&#35797;&#12290;PEAK&#22312;&#35745;&#31639;&#19978;&#21487;&#34892;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#25105;&#20204;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#25105;&#20204;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#21644;&#38408;&#20540;&#35782;&#21035;&#20219;&#21153;&#20013;&#23545;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel nonparametric sequential test for composite hypotheses for means of multiple data streams. Our proposed method, \emph{peeking with expectation-based averaged capital} (PEAK), builds upon the testing-as-betting framework and provides a non-asymptotic $\alpha$-level test across any stopping time. PEAK is computationally tractable and efficiently rejects hypotheses that are incorrect across all potential distributions that satisfy our nonparametric assumption, enabling joint composite hypothesis testing on multiple streams of data. We numerically validate our theoretical findings under the best arm identification and threshold identification in the bandit setting, illustrating the computational efficiency of our method against state-of-the-art testing methods.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;IPS&#65288;LIPS&#65289;&#30340;&#26032;&#30340;Slate Bandit OPE&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#22312;&#20302;&#32500;&#24230;&#30340;Slate&#25277;&#35937;&#31354;&#38388;&#20013;&#23450;&#20041;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#24182;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#20248;&#21270;Slate&#25277;&#35937;&#26469;&#20943;&#23567;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.02171</link><description>&lt;p&gt;
&#36890;&#36807;&#20248;&#21270;&#25277;&#35937;&#30340;&#26041;&#24335;&#36827;&#34892;Slate Bandit&#31574;&#30053;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation of Slate Bandit Policies via Optimizing Abstraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02171
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;IPS&#65288;LIPS&#65289;&#30340;&#26032;&#30340;Slate Bandit OPE&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#22312;&#20302;&#32500;&#24230;&#30340;Slate&#25277;&#35937;&#31354;&#38388;&#20013;&#23450;&#20041;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#24182;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#20248;&#21270;Slate&#25277;&#35937;&#26469;&#20943;&#23567;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;Slate&#19978;&#19979;&#25991;&#24378;&#30423;&#38382;&#39064;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#65292;&#20854;&#20013;&#19968;&#20010;&#31574;&#30053;&#36873;&#25321;&#31216;&#20026;slates&#30340;&#22810;&#32500;&#21160;&#20316;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#25512;&#33616;&#31995;&#32479;&#12289;&#25628;&#32034;&#24341;&#25806;&#12289;&#33829;&#38144;&#20197;&#21450;&#21307;&#30103;&#24212;&#29992;&#20013;&#24191;&#27867;&#23384;&#22312;&#65292;&#28982;&#32780;&#65292;&#30001;&#20110;&#21160;&#20316;&#31354;&#38388;&#22823;&#65292;&#20856;&#22411;&#30340;&#36870;&#20542;&#21521;&#35780;&#20998;&#65288;IPS&#65289;&#20272;&#35745;&#22120;&#23384;&#22312;&#36739;&#22823;&#30340;&#26041;&#24046;&#65292;&#20351;&#24471;&#26377;&#25928;&#30340;OPE&#25104;&#20026;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#20266;&#36870;&#65288;PI&#65289;&#20272;&#35745;&#22120;&#24050;&#34987;&#24341;&#20837;&#20197;&#20943;&#23567;&#26041;&#24046;&#38382;&#39064;&#65292;&#36890;&#36807;&#20551;&#35774;&#22870;&#21169;&#20989;&#25968;&#32447;&#24615;&#65292;&#20294;&#36825;&#21487;&#33021;&#23548;&#33268;&#26174;&#33879;&#30340;&#20559;&#24046;&#65292;&#22240;&#20026;&#36825;&#20010;&#20551;&#35774;&#22312;&#35266;&#27979;&#25968;&#25454;&#20013;&#24456;&#38590;&#39564;&#35777;&#24182;&#19988;&#32463;&#24120;&#20250;&#34987;&#23454;&#36136;&#24615;&#36829;&#21453;&#12290;&#20026;&#20102;&#35299;&#20915;&#20043;&#21069;&#20272;&#35745;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;Slate Bandit OPE&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;&#28508;&#22312;IPS&#65288;LIPS&#65289;&#65292;&#23427;&#22312;&#20302;&#32500;&#24230;&#30340;Slate&#25277;&#35937;&#31354;&#38388;&#20013;&#23450;&#20041;&#20102;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#20248;&#21270;Slate&#25277;&#35937;&#26469;&#26368;&#23567;&#21270;LIPS&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study off-policy evaluation (OPE) in the problem of slate contextual bandits where a policy selects multi-dimensional actions known as slates. This problem is widespread in recommender systems, search engines, marketing, to medical applications, however, the typical Inverse Propensity Scoring (IPS) estimator suffers from substantial variance due to large action spaces, making effective OPE a significant challenge. The PseudoInverse (PI) estimator has been introduced to mitigate the variance issue by assuming linearity in the reward function, but this can result in significant bias as this assumption is hard-to-verify from observed data and is often substantially violated. To address the limitations of previous estimators, we develop a novel estimator for OPE of slate bandits, called Latent IPS (LIPS), which defines importance weights in a low-dimensional slate abstraction space where we optimize slate abstractions to minimize the bias and variance of LIPS in a data-driven way. By do
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#65292;&#36890;&#36807;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#26679;&#26412;&#35201;&#27714;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02041</link><description>&lt;p&gt;
&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
$\alpha$-Divergence Loss Function for Neural Density Ratio Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#65292;&#36890;&#36807;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#26679;&#26412;&#35201;&#27714;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22522;&#30784;&#25216;&#26415;&#23494;&#24230;&#27604;&#20272;&#35745;(DRE)&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22240;DRE&#30340;&#25439;&#22833;&#20989;&#25968;&#32780;&#20986;&#29616;&#20102;&#20248;&#21270;&#38382;&#39064;&#65306;KL&#25955;&#24230;&#38656;&#35201;&#22823;&#26679;&#26412;&#65292;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#28040;&#22833;&#65292;&#25439;&#22833;&#20989;&#25968;&#26799;&#24230;&#26377;&#20559;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#20379;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#23545;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#25216;&#26415;&#39564;&#35777;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;DRE&#30340;&#26679;&#26412;&#35201;&#27714;&#65292;&#20197;$L_1$&#35823;&#24046;&#30340;&#19978;&#30028;&#32852;&#31995;&#36215;&#26469;&#65292;&#35813;&#19978;&#30028;&#23558;&#39640;&#32500;&#24230;DRE&#20219;&#21153;&#20013;&#30340;&#32500;&#24230;&#35781;&#21650;&#20316;&#20026;&#19968;&#20010;&#20849;&#21516;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, neural networks have produced state-of-the-art results for density-ratio estimation (DRE), a fundamental technique in machine learning. However, existing methods bear optimization issues that arise from the loss functions of DRE: a large sample requirement of Kullback--Leibler (KL)-divergence, vanishing of train loss gradients, and biased gradients of the loss functions. Thus, an $\alpha$-divergence loss function ($\alpha$-Div) that offers concise implementation and stable optimization is proposed in this paper. Furthermore, technical justifications for the proposed loss function are presented. The stability of the proposed loss function is empirically demonstrated and the estimation accuracy of DRE tasks is investigated. Additionally, this study presents a sample requirement for DRE using the proposed loss function in terms of the upper bound of $L_1$ error, which connects a curse of dimensionality as a common problem in high-dimensional DRE tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#26041;&#27861;&#26469;&#30740;&#31350;&#36825;&#20123;&#38544;&#34255;&#26497;&#23567;&#20540;&#30340;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2312.16819</link><description>&lt;p&gt;
&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;
&lt;/p&gt;
&lt;p&gt;
Hidden Minima in Two-Layer ReLU Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#26041;&#27861;&#26469;&#30740;&#31350;&#36825;&#20123;&#38544;&#34255;&#26497;&#23567;&#20540;&#30340;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#25311;&#21512;&#20855;&#26377;$d$&#20010;&#36755;&#20837;&#12289;$k$&#20010;&#31070;&#32463;&#20803;&#20197;&#21450;&#30001;&#30446;&#26631;&#32593;&#32476;&#29983;&#25104;&#30340;&#26631;&#31614;&#30340;&#20004;&#23618;ReLU&#32593;&#32476;&#25152;&#28041;&#21450;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#26368;&#36817;&#21457;&#29616;&#20102;&#20004;&#31181;&#26080;&#31351;&#26063;&#30340;&#34394;&#20551;&#26497;&#23567;&#20540;&#65292;&#27599;&#20010;$d$&#23545;&#24212;&#19968;&#20010;&#26497;&#23567;&#20540;&#12290;&#23646;&#20110;&#31532;&#19968;&#31867;&#30340;&#26497;&#23567;&#20540;&#30340;&#25439;&#22833;&#22312;$d$&#22686;&#21152;&#26102;&#25910;&#25947;&#20110;&#38646;&#12290;&#22312;&#31532;&#20108;&#31867;&#20013;&#65292;&#25439;&#22833;&#20445;&#25345;&#36828;&#31163;&#20110;&#38646;&#12290;&#37027;&#20040;&#65292;&#22914;&#20309;&#36991;&#20813;&#23646;&#20110;&#21518;&#19968;&#31867;&#30340;&#26497;&#23567;&#20540;&#21602;&#65311;&#24184;&#36816;&#30340;&#26159;&#65292;&#36825;&#26679;&#30340;&#26497;&#23567;&#20540;&#20174;&#19981;&#20250;&#34987;&#26631;&#20934;&#20248;&#21270;&#26041;&#27861;&#26816;&#27979;&#21040;&#12290;&#21463;&#21040;&#27492;&#29616;&#35937;&#24615;&#36136;&#30340;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#30740;&#31350;&#38544;&#34255;&#26497;&#23567;&#20540;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#30340;&#26041;&#27861;&#12290;&#26681;&#25454;&#29616;&#26377;&#30340;&#20998;&#26512;&#65292;&#20004;&#31181;&#31867;&#22411;&#30340;Hessian&#35889;&#22312;$O(d^{-1/2})$&#39033;&#27169;&#24847;&#20041;&#19979;&#19968;&#33268; -- &#19981;&#22826;&#20048;&#35266;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#25439;&#22833;&#34987;&#26368;&#23567;&#21270;&#25110;&#26368;&#22823;&#21270;&#30340;&#26354;&#32447;&#36827;&#34892;&#65292;&#36890;&#24120;&#31216;&#20026;&#20999;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.16819v2 Announce Type: replace  Abstract: The optimization problem associated to fitting two-layer ReLU networks having $d$~inputs, $k$~neurons, and labels generated by a target network, is considered. Two types of infinite families of spurious minima, giving one minimum per $d$, were recently found. The loss at minima belonging to the first type converges to zero as $d$ increases. In the second type, the loss remains bounded away from zero. That being so, how may one avoid minima belonging to the latter type? Fortunately, such minima are never detected by standard optimization methods. Motivated by questions concerning the nature of this phenomenon, we develop methods to study distinctive analytic properties of hidden minima.   By existing analyses, the Hessian spectrum of both types agree modulo $O(d^{-1/2})$-terms -- not promising. Thus, rather, our investigation proceeds by studying curves along which the loss is minimized or maximized, generally referred to as tangency 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#30340;&#20004;&#20840;&#20854;&#32654;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#23545;&#25239;&#24615;&#21644;&#38543;&#26426;&#24773;&#20917;&#19979;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#38024;&#23545;&#26368;&#23567;&#27425;&#20248;&#24046;&#36317;&#30340;&#22810;&#23545;&#25968;&#32423;&#21035;&#36895;&#29575;&#21644;&#22312;&#23545;&#25239;&#24615;&#24773;&#20917;&#19979;&#30340;&#31532;&#19968;&#38454;&#25110;&#31532;&#20108;&#38454;&#30028;&#20197;&#21450;&#22522;&#20110;Shannon&#29109;&#27491;&#21017;&#39033;&#30340;FTRL&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2312.15433</link><description>&lt;p&gt;
&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#30340;&#20004;&#20840;&#20854;&#32654;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Best-of-Both-Worlds Algorithms for Linear Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15433
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#30340;&#20004;&#20840;&#20854;&#32654;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#23545;&#25239;&#24615;&#21644;&#38543;&#26426;&#24773;&#20917;&#19979;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#38024;&#23545;&#26368;&#23567;&#27425;&#20248;&#24046;&#36317;&#30340;&#22810;&#23545;&#25968;&#32423;&#21035;&#36895;&#29575;&#21644;&#22312;&#23545;&#25239;&#24615;&#24773;&#20917;&#19979;&#30340;&#31532;&#19968;&#38454;&#25110;&#31532;&#20108;&#38454;&#30028;&#20197;&#21450;&#22522;&#20110;Shannon&#29109;&#27491;&#21017;&#39033;&#30340;FTRL&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;$K$&#33218;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#30340;&#20004;&#20840;&#20854;&#32654;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#23545;&#25239;&#24615;&#21644;&#38543;&#26426;&#24773;&#20917;&#19979;&#22343;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#30028;&#65292;&#32780;&#26080;&#38656;&#20851;&#20110;&#29615;&#22659;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#22312;&#38543;&#26426;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22810;&#23545;&#25968;&#32423;&#21035;&#30340;&#36895;&#29575;$\frac{(dK)^2\mathrm{poly}\log(dKT)}{\Delta_{\min}}$&#65292;&#20854;&#20013;$\Delta_{\min}$&#26159;$d$&#32500;&#24773;&#22659;&#31354;&#38388;&#20013;&#30340;&#26368;&#23567;&#27425;&#20248;&#24046;&#36317;&#12290;&#22312;&#23545;&#25239;&#24615;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#31532;&#19968;&#38454;$\widetilde{O}(dK\sqrt{L^*})$&#30028;&#25110;&#32773;&#31532;&#20108;&#38454;$\widetilde{O}(dK\sqrt{\Lambda^*})$&#30028;&#65292;&#20854;&#20013;$L^*$&#26159;&#26368;&#20339;&#25805;&#20316;&#30340;&#32047;&#31215;&#25439;&#22833;&#65292;$\Lambda^*$&#26159;&#31639;&#27861;&#20135;&#29983;&#30340;&#25439;&#22833;&#30340;&#32047;&#31215;&#20108;&#27425;&#30697;&#30340;&#19968;&#31181;&#27010;&#24565;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#24102;&#26377;Shannon&#29109;&#27491;&#21017;&#39033;&#30340;FTRL&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#30693;&#36947;&#21327;&#26041;&#24046;&#30697;&#38453;&#36870;&#30340;&#31639;&#27861;&#65292;&#24182;&#23454;&#29616;&#20102;&#22810;&#23545;&#25968;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.15433v2 Announce Type: replace  Abstract: We study best-of-both-worlds algorithms for $K$-armed linear contextual bandits. Our algorithms deliver near-optimal regret bounds in both the adversarial and stochastic regimes, without prior knowledge about the environment. In the stochastic regime, we achieve the polylogarithmic rate $\frac{(dK)^2\mathrm{poly}\log(dKT)}{\Delta_{\min}}$, where $\Delta_{\min}$ is the minimum suboptimality gap over the $d$-dimensional context space. In the adversarial regime, we obtain either the first-order $\widetilde{O}(dK\sqrt{L^*})$ bound, or the second-order $\widetilde{O}(dK\sqrt{\Lambda^*})$ bound, where $L^*$ is the cumulative loss of the best action and $\Lambda^*$ is a notion of the cumulative second moment for the losses incurred by the algorithm. Moreover, we develop an algorithm based on FTRL with Shannon entropy regularizer that does not require the knowledge of the inverse of the covariance matrix, and achieves a polylogarithmic regre
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#21457;&#29616;&#32479;&#35745;&#27169;&#24335;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#39640;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2312.14922</link><description>&lt;p&gt;
&#20174;&#39640;&#38454;&#32479;&#35745;&#37327;&#20013;&#39640;&#25928;&#23398;&#20064;&#65306;&#20551;&#35774;&#26816;&#39564;&#12289;&#38543;&#26426;&#29305;&#24449;&#21644;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning from higher-order statistics, efficiently: hypothesis tests, random features, and neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14922
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#21457;&#29616;&#32479;&#35745;&#27169;&#24335;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#39640;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#25797;&#38271;&#21457;&#29616;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#30340;&#32479;&#35745;&#27169;&#24335;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#24230;&#37327;&#19977;&#20010;&#25110;&#26356;&#22810;&#21464;&#37327;&#38388;&#30340;&#38750;&#39640;&#26031;&#30456;&#20851;&#24615;&#30340;&#39640;&#38454;&#32047;&#31215;&#37327;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#29305;&#21035;&#37325;&#35201;&#12290;&#20294;&#31070;&#32463;&#32593;&#32476;&#26377;&#22810;&#26377;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65311;&#25105;&#20204;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#25506;&#35752;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#37324;&#32479;&#35745;&#23398;&#23478;&#38656;&#35201;&#20174;$d$&#32500;&#36755;&#20837;&#30340;&#38454;-$p\ge 4$&#32047;&#31215;&#37327;&#20013;&#24674;&#22797;&#20986;&#19968;&#20010;&#29305;&#26435;&#26041;&#21521;&#25110;&#8220;&#23574;&#23792;&#8221;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#20998;&#26512;&#25152;&#38656;&#26679;&#26412;&#25968;$n$&#26469;&#34920;&#24449;&#24674;&#22797;&#23574;&#23792;&#30340;&#22522;&#26412;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#65292;&#20197;&#24378;&#28872;&#21306;&#20998;&#26469;&#33258;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#21644;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#36755;&#20837;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#32479;&#35745;&#19978;&#30340;&#21487;&#21306;&#20998;&#24615;&#38656;&#35201;$n\gtrsim d$&#20010;&#26679;&#26412;&#65292;&#32780;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21306;&#20998;&#36825;&#20004;&#20010;&#20998;&#24067;&#21017;&#38656;&#35201;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14922v2 Announce Type: replace-cross  Abstract: Neural networks excel at discovering statistical patterns in high-dimensional data sets. In practice, higher-order cumulants, which quantify the non-Gaussian correlations between three or more variables, are particularly important for the performance of neural networks. But how efficient are neural networks at extracting features from higher-order cumulants? We study this question in the spiked cumulant model, where the statistician needs to recover a privileged direction or "spike" from the order-$p\ge 4$ cumulants of $d$-dimensional inputs. We first characterise the fundamental statistical and computational limits of recovering the spike by analysing the number of samples $n$ required to strongly distinguish between inputs from the spiked cumulant model and isotropic Gaussian inputs. We find that statistical distinguishability requires $n\gtrsim d$ samples, while distinguishing the two distributions in polynomial time require
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;&#39640;&#32500;&#31232;&#30095;&#35774;&#32622;&#20013;&#21033;&#29992;&#26032;&#30340;&#20248;&#21270;&#31243;&#24207;&#23454;&#29616;&#40065;&#26834;&#31232;&#30095;&#20851;&#32852;&#20272;&#35745;&#65292;&#36890;&#36807;&#22686;&#24191;Lagrange&#31639;&#27861;&#21644;&#33258;&#36866;&#24212;&#26799;&#24230;&#19979;&#38477;&#30340;&#32452;&#21512;&#65292;&#25552;&#20379;&#20102;&#26356;&#31934;&#30830;&#30340;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#30456;&#23545;&#29616;&#26377;&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2311.17563</link><description>&lt;p&gt;
&#39640;&#25928;&#35745;&#31639;&#31232;&#30095;&#21644;&#40065;&#26834;&#26368;&#22823;&#20851;&#32852;&#20272;&#35745;&#37327;
&lt;/p&gt;
&lt;p&gt;
Efficient Computation of Sparse and Robust Maximum Association Estimators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;&#39640;&#32500;&#31232;&#30095;&#35774;&#32622;&#20013;&#21033;&#29992;&#26032;&#30340;&#20248;&#21270;&#31243;&#24207;&#23454;&#29616;&#40065;&#26834;&#31232;&#30095;&#20851;&#32852;&#20272;&#35745;&#65292;&#36890;&#36807;&#22686;&#24191;Lagrange&#31639;&#27861;&#21644;&#33258;&#36866;&#24212;&#26799;&#24230;&#19979;&#38477;&#30340;&#32452;&#21512;&#65292;&#25552;&#20379;&#20102;&#26356;&#31934;&#30830;&#30340;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#30456;&#23545;&#29616;&#26377;&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#40065;&#26834;&#32479;&#35745;&#20272;&#35745;&#37327;&#21463;&#21040;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#36739;&#23567;&#65292;&#20294;&#23427;&#20204;&#30340;&#35745;&#31639;&#36890;&#24120;&#26356;&#20855;&#25361;&#25112;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#32500;&#31232;&#30095;&#35774;&#32622;&#20013;&#12290;&#26032;&#30340;&#20248;&#21270;&#31243;&#24207;&#65292;&#20027;&#35201;&#22312;&#35745;&#31639;&#26426;&#31185;&#23398;&#39046;&#22495;&#24320;&#21457;&#65292;&#20026;&#40065;&#26834;&#32479;&#35745;&#39046;&#22495;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#31243;&#24207;&#26469;&#23454;&#29616;&#40065;&#26834;&#31232;&#30095;&#20851;&#32852;&#20272;&#35745;&#12290;&#35813;&#38382;&#39064;&#34987;&#25286;&#20998;&#20026;&#19968;&#20010;&#40065;&#26834;&#20272;&#35745;&#27493;&#39588;&#65292;&#25509;&#30528;&#26159;&#19968;&#20010;&#20313;&#39033;&#35299;&#32806;&#30340;&#65288;&#21452;&#36793;&#65289;&#20984;&#38382;&#39064;&#30340;&#20248;&#21270;&#12290;&#37319;&#29992;&#22686;&#24191;Lagrange&#31639;&#27861;&#21644;&#33258;&#36866;&#24212;&#26799;&#24230;&#19979;&#38477;&#30340;&#32452;&#21512;&#65292;&#36824;&#21253;&#25324;&#36866;&#24403;&#30340;&#32422;&#26463;&#26465;&#20214;&#20197;&#35825;&#23548;&#31232;&#30095;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#20851;&#31639;&#27861;&#31934;&#24230;&#30340;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#19968;&#32972;&#26223;&#19979;&#30456;&#23545;&#29616;&#26377;&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;&#39640;&#32500;&#23454;&#35777;&#31034;&#20363;&#24378;&#35843;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.17563v2 Announce Type: replace-cross  Abstract: Although robust statistical estimators are less affected by outlying observations, their computation is usually more challenging. This is particularly the case in high-dimensional sparse settings. The availability of new optimization procedures, mainly developed in the computer science domain, offers new possibilities for the field of robust statistics. This paper investigates how such procedures can be used for robust sparse association estimators. The problem can be split into a robust estimation step followed by an optimization for the remaining decoupled, (bi-)convex problem. A combination of the augmented Lagrangian algorithm and adaptive gradient descent is implemented to also include suitable constraints for inducing sparsity. We provide results concerning the precision of the algorithm and show the advantages over existing algorithms in this context. High-dimensional empirical examples underline the usefulness of this p
&lt;/p&gt;</description></item><item><title>ColaBO&#26159;&#31532;&#19968;&#20010;&#36125;&#21494;&#26031;&#21407;&#29702;&#26694;&#26550;&#65292;&#20801;&#35768;&#39046;&#22495;&#19987;&#23478;&#23450;&#21046;&#20248;&#21270;&#31243;&#24207;&#65292;&#25972;&#21512;&#20808;&#39564;&#20449;&#24565;&#20197;&#21152;&#36895;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2311.14645</link><description>&lt;p&gt;
&#19968;&#33324;&#26694;&#26550;&#29992;&#20110;&#29992;&#25143;&#24341;&#23548;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
A General Framework for User-Guided Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.14645
&lt;/p&gt;
&lt;p&gt;
ColaBO&#26159;&#31532;&#19968;&#20010;&#36125;&#21494;&#26031;&#21407;&#29702;&#26694;&#26550;&#65292;&#20801;&#35768;&#39046;&#22495;&#19987;&#23478;&#23450;&#21046;&#20248;&#21270;&#31243;&#24207;&#65292;&#25972;&#21512;&#20808;&#39564;&#20449;&#24565;&#20197;&#21152;&#36895;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#22312;&#21508;&#31181;&#31185;&#23398;&#23398;&#31185;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#33258;&#21160;&#12289;&#36890;&#29992;&#19988;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#26368;&#23567;&#20102;&#35299;&#22522;&#30784;&#20989;&#25968;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#33021;&#22815;&#25972;&#21512;&#20851;&#20110;&#24453;&#20248;&#21270;&#20989;&#25968;&#30340;&#20808;&#39564;&#30693;&#35782;&#25110;&#20449;&#24565;&#20197;&#21152;&#36895;&#20248;&#21270;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#36825;&#38477;&#20302;&#20102;&#23545;&#20855;&#26377;&#39044;&#31639;&#32039;&#36843;&#30693;&#35782;&#28170;&#21338;&#30340;&#23454;&#36341;&#32773;&#30340;&#21560;&#24341;&#21147;&#12290;&#20026;&#20102;&#20801;&#35768;&#39046;&#22495;&#19987;&#23478;&#23450;&#21046;&#20248;&#21270;&#31243;&#24207;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ColaBO&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36125;&#21494;&#26031;&#21407;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#25972;&#21512;&#36229;&#20986;&#20856;&#22411;&#26680;&#32467;&#26500;&#30340;&#20808;&#39564;&#20449;&#24565;&#65292;&#22914;&#20248;&#21270;&#22120;&#30340;&#21487;&#33021;&#20301;&#32622;&#25110;&#26368;&#20339;&#20540;&#12290;ColaBO&#30340;&#36890;&#29992;&#24615;&#20351;&#20854;&#36866;&#29992;&#20110;&#19981;&#21516;&#33945;&#29305;&#21345;&#27931;&#25910;&#33719;&#20989;&#25968;&#21644;&#29992;&#25143;&#20449;&#24565;&#30340;&#31867;&#22411;&#12290;&#25105;&#20204;&#32463;&#39564;&#24615;&#22320;&#23637;&#31034;&#20102;ColaBO&#30340;&#33021;&#21147;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.14645v2 Announce Type: replace  Abstract: The optimization of expensive-to-evaluate black-box functions is prevalent in various scientific disciplines. Bayesian optimization is an automatic, general and sample-efficient method to solve these problems with minimal knowledge of the underlying function dynamics. However, the ability of Bayesian optimization to incorporate prior knowledge or beliefs about the function at hand in order to accelerate the optimization is limited, which reduces its appeal for knowledgeable practitioners with tight budgets. To allow domain experts to customize the optimization routine, we propose ColaBO, the first Bayesian-principled framework for incorporating prior beliefs beyond the typical kernel structure, such as the likely location of the optimizer or the optimal value. The generality of ColaBO makes it applicable across different Monte Carlo acquisition functions and types of user beliefs. We empirically demonstrate ColaBO's ability to substa
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#23436;&#25972;&#25910;&#25947;&#29702;&#35770;&#20445;&#35777;&#65292;&#33719;&#24471;&#20102;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#20248;&#19978;&#38480;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2311.13584</link><description>&lt;p&gt;
&#20851;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#21450;&#20854;&#35823;&#24046;&#30028;&#38480;&#65306;&#23436;&#20840;&#25910;&#25947;&#20272;&#35745;&#19979;&#30340;&#23545;&#25968;&#20985;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13584
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#23436;&#25972;&#25910;&#25947;&#29702;&#35770;&#20445;&#35777;&#65292;&#33719;&#24471;&#20102;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#20248;&#19978;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#20026;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#34892;&#20026;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#32780;&#25105;&#20204;&#29992;&#20110;&#24471;&#20998;&#20272;&#35745;&#30340;&#36924;&#36817;&#20989;&#25968;&#31867;&#30001;Lipschitz&#36830;&#32493;&#20989;&#25968;&#32452;&#25104;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#28608;&#21169;&#24615;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24378;&#22823;&#20043;&#22788;&#65292;&#21363;&#20174;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#30340;&#39640;&#26031;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#30456;&#20851;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#24471;&#20998;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#23558;&#20854;&#19982;&#30456;&#24212;&#30340;&#37319;&#26679;&#20272;&#35745;&#32467;&#21512;&#36215;&#26469;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26368;&#22909;&#30340;&#24050;&#30693;&#19978;&#38480;&#20272;&#35745;&#65292;&#28041;&#21450;&#20851;&#38190;&#24863;&#20852;&#36259;&#30340;&#25968;&#37327;&#65292;&#22914;&#25968;&#25454;&#20998;&#24067;&#65288;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#30340;&#39640;&#26031;&#20998;&#24067;&#65289;&#19982;&#25105;&#20204;&#30340;&#37319;&#26679;&#31639;&#27861;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#32500;&#24230;&#21644;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13584v2 Announce Type: replace  Abstract: We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm.   Beyond the motivating example and in order to allow for the use of a diverse range o
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25193;&#25955;&#37319;&#26679;&#21644;Krylov&#23376;&#31354;&#38388;&#26041;&#27861;&#21327;&#21516;&#32467;&#21512;&#30340;&#26032;&#22411;&#39640;&#25928;&#37319;&#26679;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2303.05754</link><description>&lt;p&gt;
&#20998;&#35299;&#25193;&#25955;&#37319;&#26679;&#22120;&#29992;&#20110;&#21152;&#36895;&#22823;&#35268;&#27169;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Decomposed Diffusion Sampler for Accelerating Large-Scale Inverse Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2303.05754
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25193;&#25955;&#37319;&#26679;&#21644;Krylov&#23376;&#31354;&#38388;&#26041;&#27861;&#21327;&#21516;&#32467;&#21512;&#30340;&#26032;&#22411;&#39640;&#25928;&#37319;&#26679;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Krylov&#23376;&#31354;&#38388;&#26159;&#36890;&#36807;&#23558;&#32473;&#23450;&#21521;&#37327;&#19982;&#32447;&#24615;&#21464;&#25442;&#30697;&#38453;&#21450;&#20854;&#36830;&#32493;&#24130;&#30456;&#20056;&#32780;&#29983;&#25104;&#30340;&#65292;&#24191;&#27867;&#30740;&#31350;&#30340;&#32463;&#20856;&#20248;&#21270;&#25991;&#29486;&#20013;&#21033;&#29992;Krylov&#23376;&#31354;&#38388;&#35774;&#35745;&#31639;&#27861;&#20197;&#24555;&#36895;&#25910;&#25947;&#22823;&#35268;&#27169;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#39640;&#25928;&#30340;&#25193;&#25955;&#37319;&#26679;&#31574;&#30053;&#65292;&#23558;&#25193;&#25955;&#37319;&#26679;&#19982;Krylov&#23376;&#31354;&#38388;&#26041;&#27861;&#21327;&#21516;&#32467;&#21512;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2303.05754v3 Announce Type: replace-cross  Abstract: Krylov subspace, which is generated by multiplying a given vector by the matrix of a linear transformation and its successive powers, has been extensively studied in classical optimization literature to design algorithms that converge quickly for large linear inverse problems. For example, the conjugate gradient method (CG), one of the most popular Krylov subspace methods, is based on the idea of minimizing the residual error in the Krylov subspace. However, with the recent advancement of high-performance diffusion solvers for inverse problems, it is not clear how classical wisdom can be synergistically combined with modern diffusion models. In this study, we propose a novel and efficient diffusion sampling strategy that synergistically combines the diffusion sampling and Krylov subspace methods. Specifically, we prove that if the tangent space at a denoised sample by Tweedie's formula forms a Krylov subspace, then the CG initi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#20998;&#24067;&#24335;&#37327;&#21270;&#27969;&#30340;GFlowNets&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#27969;&#20989;&#25968;&#36716;&#21270;&#20026;&#20998;&#24067;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#26356;&#22810;&#20449;&#24687;&#30340;&#23398;&#20064;&#20449;&#21495;&#12290;&#36890;&#36807;&#37327;&#21270;&#20989;&#25968;&#21442;&#25968;&#21270;&#27599;&#20010;&#36793;&#27969;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#23398;&#20064;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#65292;&#23454;&#29616;&#23545;&#39118;&#38505;&#19981;&#30830;&#23450;&#24615;&#22330;&#26223;&#30340;&#22788;&#29702;&#65292;&#24182;&#22312;&#29616;&#26377;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2302.05793</link><description>&lt;p&gt;
&#24102;&#26377;&#20998;&#24067;&#24335;&#37327;&#21270;&#27969;&#30340;GFlowNets
&lt;/p&gt;
&lt;p&gt;
Distributional GFlowNets with Quantile Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.05793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#20998;&#24067;&#24335;&#37327;&#21270;&#27969;&#30340;GFlowNets&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#27969;&#20989;&#25968;&#36716;&#21270;&#20026;&#20998;&#24067;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#26356;&#22810;&#20449;&#24687;&#30340;&#23398;&#20064;&#20449;&#21495;&#12290;&#36890;&#36807;&#37327;&#21270;&#20989;&#25968;&#21442;&#25968;&#21270;&#27599;&#20010;&#36793;&#27969;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#23398;&#20064;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#65292;&#23454;&#29616;&#23545;&#39118;&#38505;&#19981;&#30830;&#23450;&#24615;&#22330;&#26223;&#30340;&#22788;&#29702;&#65292;&#24182;&#22312;&#29616;&#26377;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#37319;&#26679;&#22120;&#31995;&#21015;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#19968;&#31995;&#21015;&#20915;&#31574;&#27493;&#39588;&#23398;&#20064;&#29983;&#25104;&#22797;&#26434;&#32452;&#21512;&#32467;&#26500;&#30340;&#38543;&#26426;&#31574;&#30053;&#12290;&#23613;&#31649;&#21463;&#24378;&#21270;&#23398;&#20064;&#21551;&#21457;&#65292;&#24403;&#21069;&#30340;GFlowNet&#26694;&#26550;&#22312;&#36866;&#29992;&#24615;&#19978;&#30456;&#23545;&#26377;&#38480;&#65292;&#26080;&#27861;&#22788;&#29702;&#22870;&#21169;&#20989;&#25968;&#20013;&#30340;&#38543;&#26426;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20998;&#24067;&#24335;&#33539;&#24335;&#26469;&#22788;&#29702;GFlowNets&#65292;&#23558;&#27599;&#20010;&#27969;&#20989;&#25968;&#36716;&#21270;&#20026;&#19968;&#20010;&#20998;&#24067;&#65292;&#20174;&#32780;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#26356;&#22810;&#20449;&#24687;&#30340;&#23398;&#20064;&#20449;&#21495;&#12290;&#36890;&#36807;&#36890;&#36807;&#37327;&#21270;&#20989;&#25968;&#23545;&#27599;&#20010;&#36793;&#27969;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#8220;&#37327;&#21270;&#21305;&#37197;&#8221; GFlowNet&#23398;&#20064;&#31639;&#27861;&#33021;&#22815;&#23398;&#20064;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#65292;&#36825;&#26159;&#22788;&#29702;&#39118;&#38505;&#19981;&#30830;&#23450;&#24615;&#22330;&#26223;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#20998;&#24067;&#24335;&#26041;&#27861;&#30001;&#20110;&#25105;&#20204;&#22686;&#24378;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#29616;&#26377;&#22522;&#20934;&#19978;&#23454;&#29616;&#26174;&#30528;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets) are a new family of probabilistic samplers where an agent learns a stochastic policy for generating complex combinatorial structure through a series of decision-making steps. Despite being inspired from reinforcement learning, the current GFlowNet framework is relatively limited in its applicability and cannot handle stochasticity in the reward function. In this work, we adopt a distributional paradigm for GFlowNets, turning each flow function into a distribution, thus providing more informative learning signals during training. By parameterizing each edge flow through their quantile functions, our proposed \textit{quantile matching} GFlowNet learning algorithm is able to learn a risk-sensitive policy, an essential component for handling scenarios with risk uncertainty. Moreover, we find that the distributional approach can achieve substantial improvement on existing benchmarks compared to prior methods due to our enhanced training algorithm, even i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#29992;&#20110;&#21033;&#29992;&#20613;&#37324;&#21494;&#31995;&#25968;&#35299;&#20915;&#29109;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#22312;&#26080;&#38480;&#32500;Banach&#31354;&#38388;&#20013;&#30340;&#20960;&#20046;&#32943;&#23450;&#25910;&#25947;&#24615;&#21644;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2302.00982</link><description>&lt;p&gt;
&#22312;Banach&#31354;&#38388;&#20013;&#30340;&#38543;&#26426;&#26368;&#20248;&#36755;&#36816;&#29992;&#20110;&#22810;&#20803;&#20998;&#20301;&#25968;&#30340;&#27491;&#21017;&#21270;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Stochastic optimal transport in Banach Spaces for regularized estimation of multivariate quantiles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.00982
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#29992;&#20110;&#21033;&#29992;&#20613;&#37324;&#21494;&#31995;&#25968;&#35299;&#20915;&#29109;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#22312;&#26080;&#38480;&#32500;Banach&#31354;&#38388;&#20013;&#30340;&#20960;&#20046;&#32943;&#23450;&#25910;&#25947;&#24615;&#21644;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20004;&#20010;&#32477;&#23545;&#36830;&#32493;&#27010;&#29575;&#27979;&#24230;$\mu$&#21644;$\nu$&#20043;&#38388;&#30340;&#29109;&#26368;&#20248;&#36755;&#36816;&#65288;EOT&#65289;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21463;&#33945;&#26085;-&#22350;&#25176;&#32599;&#32500;&#22855;&#20998;&#20301;&#25968;&#30340;&#29305;&#23450;&#35774;&#32622;&#21551;&#21457;&#65292;&#20854;&#20013;&#28304;&#27979;&#24230;$\mu$&#35201;&#20040;&#26159;&#21333;&#20301;&#36229;&#31435;&#26041;&#20307;&#19978;&#30340;&#22343;&#21248;&#20998;&#24067;&#65292;&#35201;&#20040;&#26159;&#29699;&#38754;&#22343;&#21248;&#20998;&#24067;&#12290;&#21033;&#29992;&#28304;&#27979;&#24230;&#30340;&#30693;&#35782;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#20854;&#20613;&#37324;&#21494;&#31995;&#25968;&#26469;&#21442;&#25968;&#21270;&#22350;&#25176;&#32599;&#32500;&#22855;&#23545;&#20598;&#21183;&#33021;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#30340;&#38543;&#26426;&#31639;&#27861;&#30340;&#27599;&#27425;&#36845;&#20195;&#37117;&#20250;&#20943;&#23569;&#21040;&#20004;&#20010;&#20613;&#37324;&#21494;&#21464;&#25442;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#24555;&#36895;&#20613;&#37324;&#21494;&#21464;&#25442;&#65288;FFT&#65289;&#26469;&#23454;&#29616;&#27714;&#35299;EOT&#30340;&#24555;&#36895;&#25968;&#20540;&#26041;&#27861;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25105;&#20204;&#30340;&#38543;&#26426;&#31639;&#27861;&#22312;&#21462;&#20540;&#20110;&#26080;&#38480;&#32500;Banach&#31354;&#38388;&#20013;&#30340;&#20960;&#20046;&#32943;&#23450;&#25910;&#25947;&#24615;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#20013;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.00982v2 Announce Type: replace-cross  Abstract: We introduce a new stochastic algorithm for solving entropic optimal transport (EOT) between two absolutely continuous probability measures $\mu$ and $\nu$. Our work is motivated by the specific setting of Monge-Kantorovich quantiles where the source measure $\mu$ is either the uniform distribution on the unit hypercube or the spherical uniform distribution. Using the knowledge of the source measure, we propose to parametrize a Kantorovich dual potential by its Fourier coefficients. In this way, each iteration of our stochastic algorithm reduces to two Fourier transforms that enables us to make use of the Fast Fourier Transform (FFT) in order to implement a fast numerical method to solve EOT. We study the almost sure convergence of our stochastic algorithm that takes its values in an infinite-dimensional Banach space. Then, using numerical experiments, we illustrate the performances of our approach on the computation of regular
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#19981;&#19968;&#23450;&#21253;&#21547;&#22312;&#26680;&#31354;&#38388;&#20013;&#30340;&#24773;&#20917;&#19979;&#65292;&#20998;&#27835;&#26680;&#20989;&#25968;&#30340;&#21151;&#33021;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#30340;&#32479;&#35745;&#20248;&#21270;&#24615;&#12290;</title><link>https://arxiv.org/abs/2211.10968</link><description>&lt;p&gt;
&#20998;&#27835;&#26680;&#20989;&#25968;&#30340;&#21151;&#33021;&#32447;&#24615;&#22238;&#24402;&#30340;&#32479;&#35745;&#20248;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical Optimality of Divide and Conquer Kernel-based Functional Linear Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.10968
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#19981;&#19968;&#23450;&#21253;&#21547;&#22312;&#26680;&#31354;&#38388;&#20013;&#30340;&#24773;&#20917;&#19979;&#65292;&#20998;&#27835;&#26680;&#20989;&#25968;&#30340;&#21151;&#33021;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#30340;&#32479;&#35745;&#20248;&#21270;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#23545;&#20110;&#27491;&#21017;&#21270;&#30340;&#26680;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#21151;&#33021;&#32447;&#24615;&#22238;&#24402;&#30340;&#20998;&#26512;&#36890;&#24120;&#35201;&#27714;&#30446;&#26631;&#20989;&#25968;&#21253;&#21547;&#22312;&#36825;&#20010;&#26680;&#31354;&#38388;&#20013;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#19981;&#19968;&#23450;&#39547;&#30041;&#22312;&#22522;&#26412;RKHS&#20013;&#30340;&#24773;&#20917;&#19979;&#65292;&#20998;&#27835;&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;&#20316;&#20026;&#19968;&#31181;&#22522;&#20110;&#20998;&#35299;&#30340;&#21487;&#25193;&#23637;&#26041;&#27861;&#65292;&#21151;&#33021;&#32447;&#24615;&#22238;&#24402;&#30340;&#20998;&#27835;&#20272;&#35745;&#22120;&#21487;&#20197;&#22823;&#24133;&#20943;&#23569;&#26102;&#38388;&#21644;&#20869;&#23384;&#20013;&#30340;&#31639;&#27861;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#37319;&#29992;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24314;&#31435;&#20102;&#38024;&#23545;&#20998;&#27835;&#20272;&#35745;&#22120;&#22312;&#35299;&#37322;&#21464;&#37327;&#21644;&#30446;&#26631;&#20989;&#25968;&#30340;&#21508;&#31181;&#27491;&#21017;&#24615;&#26465;&#20214;&#19979;&#30340;&#39044;&#27979;&#30340;&#23574;&#38160;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#12290;&#36890;&#36807;&#24314;&#31435;&#26368;&#23567;-&#26368;&#22823;&#19979;&#30028;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#23548;&#20986;&#29575;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#26080;&#22122;&#22768;&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#20123;&#29575;&#33021;&#22815;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.10968v3 Announce Type: replace  Abstract: Previous analysis of regularized functional linear regression in a reproducing kernel Hilbert space (RKHS) typically requires the target function to be contained in this kernel space. This paper studies the convergence performance of divide-and-conquer estimators in the scenario that the target function does not necessarily reside in the underlying RKHS. As a decomposition-based scalable approach, the divide-and-conquer estimators of functional linear regression can substantially reduce the algorithmic complexities in time and memory. We develop an integral operator approach to establish sharp finite sample upper bounds for prediction with divide-and-conquer estimators under various regularity conditions of explanatory variables and target function. We also prove the asymptotic optimality of the derived rates by building the mini-max lower bounds. Finally, we consider the convergence of noiseless estimators and show that the rates ca
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#19968;&#33324;&#22270;&#32467;&#26500;&#38382;&#39064;&#20013;&#30340;&#26041;&#24046;&#20272;&#35745;&#65292;&#24320;&#21457;&#20102;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;&#22120;&#24182;&#25552;&#20379;&#20102;&#19978;&#30028;&#65292;&#20801;&#35768;&#25512;&#24191;&#21040;&#26356;&#24191;&#27867;&#30340;&#20998;&#24067;&#31867;&#12290;</title><link>https://arxiv.org/abs/2207.12638</link><description>&lt;p&gt;
&#20855;&#26377;&#34701;&#21512;&#22871;&#32034;&#30340;&#22270;&#20013;&#26041;&#24046;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Variance estimation in graphs with the fused lasso
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2207.12638
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#19968;&#33324;&#22270;&#32467;&#26500;&#38382;&#39064;&#20013;&#30340;&#26041;&#24046;&#20272;&#35745;&#65292;&#24320;&#21457;&#20102;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;&#22120;&#24182;&#25552;&#20379;&#20102;&#19978;&#30028;&#65292;&#20801;&#35768;&#25512;&#24191;&#21040;&#26356;&#24191;&#27867;&#30340;&#20998;&#24067;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19968;&#33324;&#22270;&#32467;&#26500;&#38382;&#39064;&#20013;&#30340;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20026;&#21516;&#26041;&#24046;&#24773;&#20917;&#24320;&#21457;&#20102;&#19968;&#20010;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;&#19968;&#33324;&#22270;&#20013;&#19968;&#33268;&#20272;&#35745;&#26041;&#24046;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#22343;&#20540;&#20449;&#21495;&#20855;&#26377;&#24635;&#21464;&#21270;&#19982;&#26631;&#20934;&#23610;&#24230;&#26102;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#38142;&#24335;&#22270;&#21644;&#20108;&#32500;&#32593;&#26684;&#22270;&#19978;&#36798;&#21040;&#26368;&#23567;&#26368;&#22823;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#19968;&#33324;&#22270;&#20013;&#25552;&#20379;&#20102;&#34701;&#21512;&#22871;&#32034;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#34920;&#29616;&#30340;&#19968;&#33324;&#19978;&#30028;&#65292;&#26681;&#25454;&#30697;&#26465;&#20214;&#21644;&#35823;&#24046;&#23614;&#37096;&#34892;&#20026;&#30340;&#30028;&#38480;&#12290;&#36825;&#20123;&#19978;&#30028;&#20351;&#25105;&#20204;&#33021;&#22815;&#25512;&#24191;&#21040;&#26356;&#24191;&#27867;&#30340;&#20998;&#24067;&#31867;&#65292;&#20363;&#22914;&#20122;&#25351;&#25968;&#20998;&#24067;&#65292;&#35768;&#22810;&#29616;&#26377;&#20851;&#20110;&#34701;&#21512;&#22871;&#32034;&#30340;&#32467;&#26524;&#20165;&#22312;&#20551;&#35774;&#38169;&#35823;&#20026;&#20122;&#39640;&#26031;&#38543;&#26426;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#25104;&#31435;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#19978;&#30028;&#65292;&#25105;&#20204;&#38543;&#21518;&#30740;&#31350;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20272;&#31639;&#26041;&#24046;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2207.12638v3 Announce Type: replace-cross  Abstract: We study the problem of variance estimation in general graph-structured problems. First, we develop a linear time estimator for the homoscedastic case that can consistently estimate the variance in general graphs. We show that our estimator attains minimax rates for the chain and 2D grid graphs when the mean signal has total variation with canonical scaling. Furthermore, we provide general upper bounds on the mean squared error performance of the fused lasso estimator in general graphs under a moment condition and a bound on the tail behavior of the errors. These upper bounds allow us to generalize for broader classes of distributions, such as sub-exponential, many existing results on the fused lasso that are only known to hold with the assumption that errors are sub-Gaussian random variables. Exploiting our upper bounds, we then study a simple total variation regularization estimator for estimating the signal of variances in t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32676;&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26032;&#39046;&#22495;&#36827;&#34892;&#35789;&#23884;&#20837;&#30340;&#20256;&#36882;&#23398;&#20064;&#65292;&#20197;&#35299;&#20915;&#19981;&#21516;&#39046;&#22495;&#21333;&#35789;&#21547;&#20041;&#24046;&#24322;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2104.08928</link><description>&lt;p&gt;
&#22522;&#20110;&#32676;&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#30340;&#35789;&#23884;&#20837;&#20256;&#36882;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2104.08928
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32676;&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26032;&#39046;&#22495;&#36827;&#34892;&#35789;&#23884;&#20837;&#30340;&#20256;&#36882;&#23398;&#20064;&#65292;&#20197;&#35299;&#20915;&#19981;&#21516;&#39046;&#22495;&#21333;&#35789;&#21547;&#20041;&#24046;&#24322;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20026;&#35768;&#22810;&#39046;&#22495;&#30340;&#20915;&#31574;&#32773;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#25968;&#25454;&#28304;&#65292;&#28085;&#30422;&#33539;&#22260;&#20174;&#38646;&#21806;&#20013;&#30340;&#20135;&#21697;&#35780;&#35770;&#21040;&#21307;&#30103;&#20445;&#20581;&#20013;&#30340;&#25252;&#29702;&#35760;&#24405;&#12290;&#20026;&#20102;&#21033;&#29992;&#36825;&#20123;&#20449;&#24687;&#65292;&#36890;&#24120;&#20250;&#36890;&#36807;&#26080;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#65288;&#22914;&#30697;&#38453;&#20998;&#35299;&#65289;&#23558;&#21333;&#35789;&#36716;&#25442;&#20026;&#35789;&#23884;&#20837;&#8212;&#8212;&#32534;&#30721;&#21333;&#35789;&#20043;&#38388;&#35821;&#20041;&#20851;&#31995;&#30340;&#21521;&#37327;&#12290;&#28982;&#32780;&#65292;&#20174;&#20855;&#26377;&#26377;&#38480;&#35757;&#32451;&#25968;&#25454;&#30340;&#26032;&#39046;&#22495;&#23398;&#20064;&#21333;&#35789;&#23884;&#20837;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#22312;&#26032;&#39046;&#22495;&#20013;&#65292;&#21333;&#35789;&#30340;&#21547;&#20041;/&#29992;&#27861;&#21487;&#33021;&#19981;&#21516;&#65292;&#20363;&#22914;&#65292;&#8220;positive&#8221;&#19968;&#35789;&#36890;&#24120;&#20855;&#26377;&#27491;&#38754;&#24773;&#32490;&#65292;&#20294;&#22312;&#21307;&#30103;&#35760;&#24405;&#20013;&#24448;&#24448;&#20855;&#26377;&#36127;&#38754;&#24773;&#32490;&#65292;&#22240;&#20026;&#23427;&#21487;&#33021;&#24847;&#21619;&#30528;&#24739;&#32773;&#26816;&#27979;&#21576;&#38451;&#24615;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#39044;&#35745;&#21482;&#26377;&#23569;&#37327;&#39046;&#22495;&#29305;&#23450;&#21333;&#35789;&#21487;&#33021;&#20855;&#26377;&#26032;&#21547;&#20041;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#30452;&#35266;&#30340;&#20004;&#38454;&#27573;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#32676;&#31232;&#30095;&#24809;&#32602;&#26469;&#26377;&#25928;&#22320;&#20256;&#36882;&#23398;&#20064;&#39046;&#22495;&#29305;&#23450;&#30340;&#26032;&#21547;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2104.08928v3 Announce Type: replace-cross  Abstract: Unstructured text provides decision-makers with a rich data source in many domains, ranging from product reviews in retail to nursing notes in healthcare. To leverage this information, words are typically translated into word embeddings -- vectors that encode the semantic relationships between words -- through unsupervised learning algorithms such as matrix factorization. However, learning word embeddings from new domains with limited training data can be challenging, because the meaning/usage may be different in the new domain, e.g., the word ``positive'' typically has positive sentiment, but often has negative sentiment in medical notes since it may imply that a patient tested positive for a disease. In practice, we expect that only a small number of domain-specific words may have new meanings. We propose an intuitive two-stage estimator that exploits this structure via a group-sparse penalty to efficiently transfer learn dom
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Deep-Lock&#30340;&#36890;&#29992;&#21644;&#36731;&#37327;&#32423;&#22522;&#20110;&#23494;&#38053;&#30340;&#27169;&#22411;&#38145;&#23450;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;S-&#30418;&#23545;&#35757;&#32451;&#23436;&#27605;&#30340;DNN&#27169;&#22411;&#30340;&#27599;&#20010;&#21442;&#25968;&#36827;&#34892;&#21152;&#23494;&#65292;&#24182;&#30830;&#20445;&#21482;&#26377;&#22312;&#24212;&#29992;&#27491;&#30830;&#30340;&#31192;&#23494;&#23494;&#38053;&#26102;&#27169;&#22411;&#25165;&#33021;&#27491;&#30830;&#36816;&#34892;&#65292;&#20174;&#32780;&#38450;&#27490;&#20102;DNN&#27169;&#22411;&#30340;&#26410;&#32463;&#25480;&#26435;&#20351;&#29992;&#12290;</title><link>https://arxiv.org/abs/2008.05966</link><description>&lt;p&gt;
Deep-Lock: &#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23433;&#20840;&#25480;&#26435;
&lt;/p&gt;
&lt;p&gt;
Deep-Lock: Secure Authorization for Deep Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2008.05966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Deep-Lock&#30340;&#36890;&#29992;&#21644;&#36731;&#37327;&#32423;&#22522;&#20110;&#23494;&#38053;&#30340;&#27169;&#22411;&#38145;&#23450;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;S-&#30418;&#23545;&#35757;&#32451;&#23436;&#27605;&#30340;DNN&#27169;&#22411;&#30340;&#27599;&#20010;&#21442;&#25968;&#36827;&#34892;&#21152;&#23494;&#65292;&#24182;&#30830;&#20445;&#21482;&#26377;&#22312;&#24212;&#29992;&#27491;&#30830;&#30340;&#31192;&#23494;&#23494;&#38053;&#26102;&#27169;&#22411;&#25165;&#33021;&#27491;&#30830;&#36816;&#34892;&#65292;&#20174;&#32780;&#38450;&#27490;&#20102;DNN&#27169;&#22411;&#30340;&#26410;&#32463;&#25480;&#26435;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#23436;&#27605;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#27169;&#22411;&#34987;&#35270;&#20026;&#22810;&#31181;&#21830;&#19994;&#27169;&#24335;&#20013;&#30340;&#26377;&#20215;&#20540;&#30340;&#30693;&#35782;&#20135;&#26435;&#65288;IP&#65289;&#12290;&#38450;&#27490;IP&#30423;&#31363;&#21644;&#26410;&#32463;&#25480;&#26435;&#20351;&#29992;&#36825;&#20123;DNN&#27169;&#22411;&#24050;&#34987;&#19994;&#30028;&#25552;&#20986;&#20316;&#20026;&#19968;&#20010;&#37325;&#22823;&#20851;&#27880;&#28857;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#36890;&#29992;&#19988;&#36731;&#37327;&#30340;&#22522;&#20110;&#23494;&#38053;&#30340;&#27169;&#22411;&#38145;&#23450;&#26041;&#26696;&#8212;Deep-Lock&#65292;&#35299;&#20915;&#20102;&#38450;&#27490;DNN&#27169;&#22411;&#26410;&#32463;&#25480;&#26435;&#20351;&#29992;&#30340;&#38382;&#39064;&#65292;&#30830;&#20445;&#34987;&#38145;&#23450;&#30340;&#27169;&#22411;&#21482;&#26377;&#22312;&#24212;&#29992;&#27491;&#30830;&#30340;&#31192;&#23494;&#23494;&#38053;&#26102;&#25165;&#33021;&#27491;&#30830;&#36816;&#34892;&#12290;Deep-Lock&#26041;&#26696;&#21033;&#29992;&#20855;&#26377;&#33391;&#22909;&#23433;&#20840;&#24615;&#36136;&#30340;S-&#30418;&#23545;&#32463;&#36807;&#35757;&#32451;&#30340;DNN&#27169;&#22411;&#30340;&#27599;&#20010;&#21442;&#25968;&#36827;&#34892;&#21152;&#23494;&#65292;&#20351;&#29992;&#20027;&#23494;&#38053;&#36890;&#36807;&#23494;&#38053;&#35843;&#24230;&#31639;&#27861;&#29983;&#25104;&#31192;&#23494;&#23494;&#38053;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#21152;&#23494;&#26435;&#37325;&#30340;&#23494;&#38598;&#32593;&#32476;&#34987;&#21457;&#29616;&#33021;&#22815;&#25269;&#25239;&#27169;&#22411;&#24494;&#35843;&#25915;&#20987;&#12290;&#26368;&#21518;&#65292;Deep-Lock&#19981;&#38656;&#35201;&#23545;DNN&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#35757;&#32451;&#36827;&#34892;&#20219;&#20309;&#24178;&#39044;&#65292;&#20351;&#20854;&#36866;&#29992;&#20110;&#25152;&#26377;&#24050;&#23384;&#22312;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2008.05966v2 Announce Type: replace  Abstract: Trained Deep Neural Network (DNN) models are considered valuable Intellectual Properties (IP) in several business models. Prevention of IP theft and unauthorized usage of such DNN models has been raised as of significant concern by industry. In this paper, we address the problem of preventing unauthorized usage of DNN models by proposing a generic and lightweight key-based model-locking scheme, which ensures that a locked model functions correctly only upon applying the correct secret key. The proposed scheme, known as Deep-Lock, utilizes S-Boxes with good security properties to encrypt each parameter of a trained DNN model with secret keys generated from a master key via a key scheduling algorithm. The resulting dense network of encrypted weights is found robust against model fine-tuning attacks. Finally, Deep-Lock does not require any intervention in the structure and training of the DNN models, making it applicable for all existin
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;-&#23614;&#37096;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23454;&#29616;&#65292;&#33021;&#22815;&#26681;&#25454;&#31232;&#30095;&#31243;&#24230;&#33258;&#36866;&#24212;&#35843;&#25972;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20197;&#36866;&#24212;&#26356;&#22810;&#25110;&#26356;&#23569;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2007.02192</link><description>&lt;p&gt;
&#23614;&#37096;&#33258;&#36866;&#24212;&#36125;&#21494;&#26031;&#25910;&#32553;
&lt;/p&gt;
&lt;p&gt;
Tail-adaptive Bayesian shrinkage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.02192
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;-&#23614;&#37096;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23454;&#29616;&#65292;&#33021;&#22815;&#26681;&#25454;&#31232;&#30095;&#31243;&#24230;&#33258;&#36866;&#24212;&#35843;&#25972;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20197;&#36866;&#24212;&#26356;&#22810;&#25110;&#26356;&#23569;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#22238;&#24402;&#38382;&#39064;&#19979;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#25910;&#32553;&#20808;&#39564;&#20027;&#35201;&#35774;&#35745;&#29992;&#20110;&#22312;&#25152;&#35859;&#30340;&#36229;&#31232;&#30095;&#39046;&#22495;&#20174;&#25104;&#21315;&#19978;&#19975;&#20010;&#39044;&#27979;&#21464;&#37327;&#20013;&#26816;&#27979;&#23569;&#25968;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#24403;&#31232;&#30095;&#31243;&#24230;&#36866;&#20013;&#26102;&#65292;&#23427;&#20204;&#21487;&#33021;&#34920;&#29616;&#19981;&#23613;&#20154;&#24847;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#29305;&#24615;&#20013;&#65292;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20250;&#33258;&#36866;&#24212;&#35843;&#25972;&#65292;&#38543;&#30528;&#31232;&#30095;&#27700;&#24179;&#30340;&#22686;&#21152;&#25110;&#20943;&#23569;&#21464;&#24471;&#26356;&#22823;&#25110;&#26356;&#23567;&#65292;&#20197;&#36866;&#24212;&#20808;&#39564;&#22320;&#26356;&#22810;&#25110;&#26356;&#23569;&#30340;&#20449;&#21495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#23616;&#23616;&#37096;&#23614;&#37096;&#65288;GLT&#65289;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#20197;&#30830;&#20445;&#36825;&#31181;&#23646;&#24615;&#12290;&#25105;&#20204;&#32771;&#23519;&#20102;&#20808;&#39564;&#30340;&#23614;&#37096;&#25351;&#25968;&#19982;&#22522;&#30784;&#31232;&#30095;&#27700;&#24179;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#35777;&#26126;GLT&#21518;&#39564;&#20250;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.02192v4 Announce Type: replace-cross  Abstract: Robust Bayesian methods for high-dimensional regression problems under diverse sparse regimes are studied. Traditional shrinkage priors are primarily designed to detect a handful of signals from tens of thousands of predictors in the so-called ultra-sparsity domain. However, they may not perform desirably when the degree of sparsity is moderate. In this paper, we propose a robust sparse estimation method under diverse sparsity regimes, which has a tail-adaptive shrinkage property. In this property, the tail-heaviness of the prior adjusts adaptively, becoming larger or smaller as the sparsity level increases or decreases, respectively, to accommodate more or fewer signals, a posteriori. We propose a global-local-tail (GLT) Gaussian mixture distribution that ensures this property. We examine the role of the tail-index of the prior in relation to the underlying sparsity level and demonstrate that the GLT posterior contracts at the
&lt;/p&gt;</description></item><item><title>&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;SplitSGD&#65292;&#36890;&#36807;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#31283;&#24577;&#26816;&#27979;&#65292;&#22312;&#26816;&#27979;&#21040;&#31283;&#24577;&#38454;&#27573;&#26102;&#38477;&#20302;&#23398;&#20064;&#36895;&#29575;&#65292;&#20351;&#20854;&#36866;&#29992;&#20110;&#20984;&#38382;&#39064;&#21644;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/1910.08597</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#35010;&#35786;&#26029;&#23454;&#29616;&#38543;&#26426;&#20248;&#21270;&#30340;&#31283;&#20581;&#23398;&#20064;&#29575;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Robust Learning Rate Selection for Stochastic Optimization via Splitting Diagnostic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1910.08597
&lt;/p&gt;
&lt;p&gt;
&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;SplitSGD&#65292;&#36890;&#36807;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#31283;&#24577;&#26816;&#27979;&#65292;&#22312;&#26816;&#27979;&#21040;&#31283;&#24577;&#38454;&#27573;&#26102;&#38477;&#20302;&#23398;&#20064;&#36895;&#29575;&#65292;&#20351;&#20854;&#36866;&#29992;&#20110;&#20984;&#38382;&#39064;&#21644;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;SplitSGD&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#30340;&#26032;&#30340;&#21160;&#24577;&#23398;&#20064;&#29575;&#35843;&#24230;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#26816;&#27979;&#21040;&#31283;&#24577;&#38454;&#27573;&#26102;&#38477;&#20302;&#23398;&#20064;&#36895;&#29575;&#65292;&#20197;&#26356;&#22909;&#22320;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#65292;&#21363;&#24403;&#36845;&#20195;&#22788;&#20110;&#23616;&#37096;&#26368;&#23567;&#20540;&#38468;&#36817;&#26102;&#21487;&#33021;&#20250;&#20986;&#29616;&#21453;&#24377;&#12290;&#36890;&#36807;&#23558;&#21333;&#32447;&#31243;&#20998;&#25104;&#20004;&#20010;&#37096;&#20998;&#65292;&#24182;&#20351;&#29992;&#20004;&#20010;&#32447;&#31243;&#26799;&#24230;&#30340;&#20869;&#31215;&#20316;&#20026;&#31283;&#24577;&#24230;&#37327;&#26469;&#25191;&#34892;&#26816;&#27979;&#12290;&#22522;&#20110;&#36825;&#20010;&#31616;&#21333;&#20294;&#32463;&#36807;&#39564;&#35777;&#26377;&#25928;&#30340;&#31283;&#24577;&#26816;&#27979;&#65292;SplitSGD&#26131;&#20110;&#23454;&#29616;&#65292;&#24182;&#19988;&#22522;&#26412;&#19981;&#20250;&#27604;&#26631;&#20934;SGD&#20135;&#29983;&#39069;&#22806;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#26082;&#36866;&#29992;&#20110;&#20984;&#38382;&#39064;&#65292;&#20063;&#36866;&#29992;&#20110;&#35757;&#32451;&#65288;&#38750;&#20984;&#65289;&#31070;&#32463;&#32593;&#32476;&#65292;&#34920;&#29616;&#27604;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#26356;&#22909;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#35266;&#23519;&#21040;&#35813;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:1910.08597v5 Announce Type: replace-cross  Abstract: This paper proposes SplitSGD, a new dynamic learning rate schedule for stochastic optimization. This method decreases the learning rate for better adaptation to the local geometry of the objective function whenever a stationary phase is detected, that is, the iterates are likely to bounce at around a vicinity of a local minimum. The detection is performed by splitting the single thread into two and using the inner product of the gradients from the two threads as a measure of stationarity. Owing to this simple yet provably valid stationarity detection, SplitSGD is easy-to-implement and essentially does not incur additional computational cost than standard SGD. Through a series of extensive experiments, we show that this method is appropriate for both convex problems and training (non-convex) neural networks, with performance compared favorably to other stochastic optimization methods. Importantly, this method is observed to be v
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65288;MTuM&#65289;&#65292;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14593</link><description>&lt;p&gt;
&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#31283;&#20581;&#20272;&#35745;Pareto&#30340;&#23610;&#24230;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Robust Estimation of Pareto's Scale Parameter from Grouped Data. (arXiv:2401.14593v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65288;MTuM&#65289;&#65292;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21487;&#33719;&#21462;&#30340;&#23436;&#20840;&#35266;&#27979;&#21040;&#30340;&#20174;&#22836;&#33267;&#23614;&#30340;&#25439;&#22833;&#20005;&#37325;&#24615;&#26679;&#26412;&#25968;&#25454;&#38598;&#23384;&#22312;&#26102;&#65292;&#23384;&#22312;&#35768;&#22810;&#31283;&#20581;&#20272;&#35745;&#22120;&#20316;&#20026;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65288;MLE&#65289;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#20998;&#32452;&#25439;&#22833;&#20005;&#37325;&#24615;&#25968;&#25454;&#26102;&#65292;&#31283;&#20581;&#30340;MLE&#26367;&#20195;&#26041;&#26696;&#30340;&#36873;&#25321;&#21464;&#24471;&#38750;&#24120;&#26377;&#38480;&#65292;&#21482;&#26377;&#23569;&#25968;&#26041;&#27861;&#21487;&#29992;&#65292;&#20363;&#22914;&#26368;&#23567;&#20108;&#20056;&#27861;&#12289;&#26368;&#23567;Hellinger&#36317;&#31163;&#21644;&#26368;&#20248;&#26377;&#30028;&#24433;&#21709;&#20989;&#25968;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#25130;&#26029;&#30697;&#27861;&#30340;&#26032;&#22411;&#31283;&#20581;&#20272;&#35745;&#25216;&#26415;&#65292;&#35813;&#26041;&#27861;&#19987;&#38376;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;MTuM&#30340;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerous robust estimators exist as alternatives to the maximum likelihood estimator (MLE) when a completely observed ground-up loss severity sample dataset is available. However, the options for robust alternatives to MLE become significantly limited when dealing with grouped loss severity data, with only a handful of methods like least squares, minimum Hellinger distance, and optimal bounded influence function available. This paper introduces a novel robust estimation technique, the Method of Truncated Moments (MTuM), specifically designed to estimate the tail index of a Pareto distribution from grouped data. Inferential justification of MTuM is established by employing the central limit theorem and validating them through a comprehensive simulation study.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#36890;&#36807;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#35774;&#35745;&#25913;&#21892;&#20102;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.11665</link><description>&lt;p&gt;
&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#36817;&#20284; Thompson &#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo. (arXiv:2401.11665v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#36890;&#36807;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#35774;&#35745;&#25913;&#21892;&#20102;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#26041;&#27861;&#25193;&#23637;&#20102;&#20854;&#36866;&#29992;&#33539;&#22260;&#65292;&#20174;&#39640;&#26031;&#21518;&#39564;&#37319;&#26679;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#24179;&#28369;&#21518;&#39564;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#35201;&#27714;&#39640;&#20934;&#30830;&#24615;&#26102;&#65292;&#20173;&#28982;&#38754;&#20020;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#21033;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo&#65292;&#21518;&#32773;&#26159;&#27169;&#25311;&#39640;&#32500;&#21518;&#39564;&#30340;&#36890;&#29992;&#24037;&#20855;&#12290;&#22522;&#20110;&#26631;&#20934;&#30340;&#24179;&#28369;&#24615;&#21644;&#23545;&#25968;&#20985;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#21152;&#36895;&#21518;&#39564;&#38598;&#20013;&#21644;&#37319;&#26679;&#12290;&#35813;&#35774;&#35745;&#25913;&#36827;&#20102;&#23454;&#29616;&#23545;&#25968;&#36951;&#25022;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;$\mathcal{\tilde O}(d)$&#25913;&#36827;&#21040;$\mathcal{\tilde O}(\sqrt{d})$&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#21512;&#25104;&#23454;&#39564;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#32463;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approximate Thompson sampling with Langevin Monte Carlo broadens its reach from Gaussian posterior sampling to encompass more general smooth posteriors. However, it still encounters scalability issues in high-dimensional problems when demanding high accuracy. To address this, we propose an approximate Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where the latter is the go-to workhorse for simulations of high-dimensional posteriors. Based on the standard smoothness and log-concavity conditions, we study the accelerated posterior concentration and sampling using a specific potential function. This design improves the sample complexity for realizing logarithmic regrets from $\mathcal{\tilde O}(d)$ to $\mathcal{\tilde O}(\sqrt{d})$. The scalability and robustness of our algorithm are also empirically validated through synthetic experiments in high-dimensional bandit problems.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#24182;&#25552;&#20379;&#20102;&#26465;&#20214;&#12290;&#36825;&#26159;&#23545;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#30340;&#36845;&#20195;&#26041;&#27861;&#30340;&#19968;&#31181;&#37325;&#35201;&#34917;&#20805;&#12290;</title><link>http://arxiv.org/abs/2401.05394</link><description>&lt;p&gt;
&#36845;&#20195;&#27491;&#21017;&#21270;&#19982;k&#25903;&#25745;&#33539;&#25968;&#65306;&#31232;&#30095;&#24674;&#22797;&#30340;&#37325;&#35201;&#34917;&#20805;
&lt;/p&gt;
&lt;p&gt;
Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery. (arXiv:2401.05394v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05394
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#24182;&#25552;&#20379;&#20102;&#26465;&#20214;&#12290;&#36825;&#26159;&#23545;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#30340;&#36845;&#20195;&#26041;&#27861;&#30340;&#19968;&#31181;&#37325;&#35201;&#34917;&#20805;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#24674;&#22797;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#22788;&#29702;&#20013;&#26080;&#22788;&#19981;&#22312;&#12290;&#30001;&#20110;&#31232;&#30095;&#24674;&#22797;&#30340;NP&#22256;&#38590;&#24615;&#36136;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#35201;&#20040;&#21463;&#38480;&#20110;&#36866;&#29992;&#26465;&#20214;&#65288;&#29978;&#33267;&#26410;&#30693;&#65289;&#65292;&#35201;&#20040;&#35745;&#31639;&#25104;&#26412;&#39640;&#12290;&#26368;&#36817;&#65292;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#24555;&#36895;&#26041;&#27861;&#20986;&#29616;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#19968;&#27425;&#36890;&#36807;&#26469;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#26041;&#27861;&#20013;&#32321;&#29712;&#30340;&#32593;&#26684;&#25628;&#32034;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36825;&#20123;&#36845;&#20195;&#26041;&#27861;&#37117;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#65292;&#38656;&#35201;&#21463;&#38480;&#30340;&#36866;&#29992;&#26465;&#20214;&#65292;&#24182;&#19988;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#22833;&#36133;&#12290;&#22240;&#27492;&#65292;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#26356;&#24191;&#27867;&#30340;&#26465;&#20214;&#19979;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#20173;&#38656;&#36827;&#19968;&#27493;&#25506;&#32034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#22522;&#20110;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#32780;&#19981;&#26159;$\ell_1$&#33539;&#25968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;IRKSN&#36827;&#34892;&#31232;&#30095;&#24674;&#22797;&#30340;&#26465;&#20214;&#65292;&#24182;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse recovery is ubiquitous in machine learning and signal processing. Due to the NP-hard nature of sparse recovery, existing methods are known to suffer either from restrictive (or even unknown) applicability conditions, or high computational cost. Recently, iterative regularization methods have emerged as a promising fast approach because they can achieve sparse recovery in one pass through early stopping, rather than the tedious grid-search used in the traditional methods. However, most of those iterative methods are based on the $\ell_1$ norm which requires restrictive applicability conditions and could fail in many cases. Therefore, achieving sparse recovery with iterative regularization methods under a wider range of conditions has yet to be further explored. To address this issue, we propose a novel iterative regularization algorithm, IRKSN, based on the $k$-support norm regularizer rather than the $\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and compar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21453;&#36716;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#35813;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20860;&#23481;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#22312;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2401.02739</link><description>&lt;p&gt;
&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65306;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;
&lt;/p&gt;
&lt;p&gt;
Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors. (arXiv:2401.02739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21453;&#36716;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#35813;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20860;&#23481;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#22312;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#65292;&#19968;&#31181;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36817;&#20284;&#25512;&#26029;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#36741;&#21161;&#28508;&#21464;&#37327;&#22686;&#21152;&#20102;&#21464;&#20998;&#21518;&#39564;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#34920;&#36798;&#24615;&#30340;&#27169;&#22411;&#31867;&#65292;&#36890;&#36807;&#21453;&#36716;&#29992;&#25143;&#25351;&#23450;&#30340;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#25105;&#20204;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#21463;&#21040;&#35273;&#37266;-&#30561;&#30496;&#31639;&#27861;&#21551;&#21457;&#30340;&#36793;&#38469;&#20284;&#28982;&#26032;&#19979;&#30028;&#26469;&#25311;&#21512;&#36825;&#20123;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65288;&#23427;&#36866;&#37197;&#20102;&#27491;&#21017;&#21270;&#30340;ELBO&#25193;&#23637;&#65289;&#65292;&#19982;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#20860;&#23481;&#65292;&#24182;&#19988;&#34920;&#29616;&#20248;&#20110;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#25110;&#23545;&#25239;&#32593;&#32476;&#30340;&#26367;&#20195;&#36817;&#20284;&#21518;&#39564;&#31867;&#21035;&#12290;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24471;&#21040;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;DD-VAE&#65289;&#31639;&#27861;&#12290;&#25105;&#20204;&#23558;&#35813;&#31639;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#23398;&#20013;&#30340;&#19968;&#20010;&#28608;&#21169;&#20219;&#21153; -- &#20174;&#20154;&#31867;&#22522;&#22240;&#32452;&#20013;&#25512;&#26029;&#28508;&#22312;&#34880;&#32479; -- &#36229;&#36807;&#20102;&#24378;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose denoising diffusion variational inference (DDVI), an approximate inference algorithm for latent variable models which relies on diffusion models as expressive variational posteriors. Our method augments variational posteriors with auxiliary latents, which yields an expressive class of models that perform diffusion in latent space by reversing a user-specified noising process. We fit these models by optimizing a novel lower bound on the marginal likelihood inspired by the wake-sleep algorithm. Our method is easy to implement (it fits a regularized extension of the ELBO), is compatible with black-box variational inference, and outperforms alternative classes of approximate posteriors based on normalizing flows or adversarial networks. When applied to deep latent variable models, our method yields the denoising diffusion VAE (DD-VAE) algorithm. We use this algorithm on a motivating task in biology -- inferring latent ancestry from human genomes -- outperforming strong baselines
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#37325;&#20849;&#20139;&#21644;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#30340;&#35757;&#32451;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#25200;&#21160;&#21644;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.11122</link><description>&lt;p&gt;
&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Sensitivity-Aware Amortized Bayesian Inference. (arXiv:2310.11122v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#37325;&#20849;&#20139;&#21644;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#30340;&#35757;&#32451;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#25200;&#21160;&#21644;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#26159;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#36827;&#34892;&#27010;&#29575;&#25512;&#29702;&#21644;&#20915;&#31574;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#29616;&#20195;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#20013;&#30340;&#22522;&#26412;&#36873;&#25321;&#28041;&#21450;&#20284;&#28982;&#20989;&#25968;&#21644;&#20808;&#39564;&#20998;&#24067;&#30340;&#35268;&#33539;&#12289;&#21518;&#39564;&#36924;&#36817;&#22120;&#21644;&#25968;&#25454;&#12290;&#27599;&#20010;&#36873;&#25321;&#37117;&#21487;&#20197;&#26174;&#30528;&#24433;&#21709;&#22522;&#20110;&#27169;&#22411;&#30340;&#25512;&#26029;&#21644;&#21518;&#32493;&#20915;&#31574;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#34892;&#25935;&#24863;&#24615;&#20998;&#26512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26041;&#38754;&#30340;&#26041;&#27861;&#65292;&#23558;&#25935;&#24863;&#24615;&#20998;&#26512;&#25972;&#21512;&#21040;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#65288;ABI&#65292;&#21363;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#25311;&#25512;&#26029;&#65289;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;&#26435;&#37325;&#20849;&#20139;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#32534;&#30721;&#26367;&#20195;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#20043;&#38388;&#30340;&#32467;&#26500;&#30456;&#20284;&#24615;&#65292;&#20197;&#26368;&#23567;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#25512;&#26029;&#26469;&#35780;&#20272;&#23545;&#21508;&#31181;&#25968;&#25454;&#25200;&#21160;&#25110;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#12290;&#19982;&#22823;&#22810;&#25968;&#20854;&#20182;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#27604;&#65292;&#36825;&#20004;&#20010;&#27493;&#39588;&#37117;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference is a powerful framework for making probabilistic inferences and decisions under uncertainty. Fundamental choices in modern Bayesian workflows concern the specification of the likelihood function and prior distributions, the posterior approximator, and the data. Each choice can significantly influence model-based inference and subsequent decisions, thereby necessitating sensitivity analysis. In this work, we propose a multifaceted approach to integrate sensitivity analyses into amortized Bayesian inference (ABI, i.e., simulation-based inference with neural networks). First, we utilize weight sharing to encode the structural similarities between alternative likelihood and prior specifications in the training process with minimal computational overhead. Second, we leverage the rapid inference of neural networks to assess sensitivity to various data perturbations or pre-processing procedures. In contrast to most other Bayesian approaches, both steps circumvent the costly
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#26080;&#38480;&#22823;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65292;&#24471;&#20986;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.05518</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;LSTD&#21644;&#38543;&#26426;&#29305;&#24449;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21452;&#19979;&#38477;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
On Double-Descent in Reinforcement Learning with LSTD and Random Features. (arXiv:2310.05518v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05518
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#26080;&#38480;&#22823;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65292;&#24471;&#20986;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20854;&#24615;&#33021;&#21463;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#36807;&#21442;&#25968;&#21270;&#21644;&#20854;&#24102;&#26469;&#30340;&#22909;&#22788;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#29702;&#35299;&#65292;&#20294;&#26159;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#24773;&#20917;&#21017;&#19981;&#22826;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#21644;L2&#27491;&#21017;&#21270;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#23558;&#21442;&#25968;&#20010;&#25968;&#19982;&#35775;&#38382;&#29366;&#24577;&#20010;&#25968;&#20043;&#27604;&#23450;&#20041;&#20026;&#20851;&#38190;&#22240;&#32032;&#65292;&#24403;&#35813;&#27604;&#20540;&#22823;&#20110;1&#26102;&#31216;&#20026;&#36807;&#21442;&#25968;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#65292;&#21363;&#22312;&#21442;&#25968;/&#29366;&#24577;&#27604;&#20026;1&#38468;&#36817;&#20250;&#31361;&#28982;&#24615;&#33021;&#19979;&#38477;&#12290;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#29305;&#24449;&#21644;&#25042;&#24816;&#35757;&#32451;&#31574;&#30053;&#65292;&#25105;&#20204;&#22312;&#26080;&#38480;&#22823;&#30340;&#21442;&#25968;&#21644;&#29366;&#24577;&#25968;&#19979;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#26368;&#20248;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#22312;&#35813;&#31639;&#27861;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal Difference (TD) algorithms are widely used in Deep Reinforcement Learning (RL). Their performance is heavily influenced by the size of the neural network. While in supervised learning, the regime of over-parameterization and its benefits are well understood, the situation in RL is much less clear. In this paper, we present a theoretical analysis of the influence of network size and $l_2$-regularization on performance. We identify the ratio between the number of parameters and the number of visited states as a crucial factor and define over-parameterization as the regime when it is larger than one. Furthermore, we observe a double-descent phenomenon, i.e., a sudden drop in performance around the parameter/state ratio of one. Leveraging random features and the lazy training regime, we study the regularized Least-Square Temporal Difference (LSTD) algorithm in an asymptotic regime, as both the number of parameters and states go to infinity, maintaining a constant ratio. We derive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.05401</link><description>&lt;p&gt;
Entropy-MCMC: &#36731;&#26494;&#20174;&#24179;&#22374;&#30406;&#22320;&#36827;&#34892;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Entropy-MCMC: Sampling from Flat Basins with Ease. (arXiv:2310.05401v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20381;&#36182;&#20110;&#23545;&#21518;&#39564;&#20998;&#24067;&#30340;&#36136;&#37327;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;&#22312;&#24615;&#36136;&#19978;&#26159;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#65292;&#23616;&#37096;&#27169;&#24335;&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#26377;&#38480;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#65292;&#20174;&#21407;&#22987;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#24615;&#33021;&#65292;&#22240;&#20026;&#19968;&#20123;&#26679;&#26412;&#21487;&#33021;&#20250;&#38519;&#20837;&#8220;&#22351;&#8221;&#27169;&#24335;&#24182;&#20986;&#29616;&#36807;&#25311;&#21512;&#12290;&#22522;&#20110;&#35266;&#23519;&#21040;&#20302;&#27867;&#21270;&#35823;&#24046;&#30340;&#8220;&#22909;&#8221;&#27169;&#24335;&#36890;&#24120;&#23384;&#22312;&#20110;&#33021;&#37327;&#26223;&#35266;&#30340;&#24179;&#22374;&#30406;&#22320;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20559;&#32622;&#37319;&#26679;&#26397;&#21521;&#36825;&#20123;&#24179;&#22374;&#21306;&#22495;&#30340;&#21518;&#39564;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#24341;&#23548;&#21464;&#37327;&#65292;&#20854;&#31283;&#24577;&#20998;&#24067;&#31867;&#20284;&#20110;&#24179;&#28369;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#27809;&#26377;&#23574;&#38160;&#30340;&#27169;&#24577;&#65292;&#20197;&#24341;&#23548;MCMC&#37319;&#26679;&#22120;&#22312;&#24179;&#22374;&#30340;&#30406;&#22320;&#20013;&#37319;&#26679;&#12290;&#36890;&#36807;&#23558;&#27492;&#24341;&#23548;&#21464;&#37327;&#19982;&#27169;&#22411;&#21442;&#25968;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#21487;&#20197;&#22312;&#26368;&#23567;&#35745;&#31639;&#24320;&#38144;&#19979;&#23454;&#29616;&#39640;&#25928;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20803;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian deep learning counts on the quality of posterior distribution estimation. However, the posterior of deep neural networks is highly multi-modal in nature, with local modes exhibiting varying generalization performance. Given a practical budget, sampling from the original posterior can lead to suboptimal performance, as some samples may become trapped in "bad" modes and suffer from overfitting. Leveraging the observation that "good" modes with low generalization error often reside in flat basins of the energy landscape, we propose to bias sampling on the posterior toward these flat regions. Specifically, we introduce an auxiliary guiding variable, the stationary distribution of which resembles a smoothed posterior free from sharp modes, to lead the MCMC sampler to flat basins. By integrating this guiding variable with the model parameter, we create a simple joint distribution that enables efficient sampling with minimal computational overhead. We prove the convergence of our met
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21435;&#22122;&#20013;&#30340;&#21518;&#39564;&#20998;&#24067;&#21450;&#20854;&#19982;&#21518;&#39564;&#22343;&#20540;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#24212;&#29992;&#20110;&#39044;&#35757;&#32451;&#21435;&#22122;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#20027;&#25104;&#20998;&#21644;&#36817;&#20284;&#36793;&#38469;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;&#19981;&#38656;&#35201;&#26174;&#24335;&#35745;&#31639;&#39640;&#38454;&#30697;&#24352;&#37327;&#25110;&#36827;&#34892;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;</title><link>http://arxiv.org/abs/2309.13598</link><description>&lt;p&gt;
&#20851;&#20110;&#21435;&#22122;&#20013;&#30340;&#21518;&#39564;&#20998;&#24067;&#65306;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Posterior Distribution in Denoising: Application to Uncertainty Quantification. (arXiv:2309.13598v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13598
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21435;&#22122;&#20013;&#30340;&#21518;&#39564;&#20998;&#24067;&#21450;&#20854;&#19982;&#21518;&#39564;&#22343;&#20540;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#24212;&#29992;&#20110;&#39044;&#35757;&#32451;&#21435;&#22122;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#20027;&#25104;&#20998;&#21644;&#36817;&#20284;&#36793;&#38469;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;&#19981;&#38656;&#35201;&#26174;&#24335;&#35745;&#31639;&#39640;&#38454;&#30697;&#24352;&#37327;&#25110;&#36827;&#34892;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#31639;&#27861;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#65292;&#20174;&#38477;&#22122;&#20302;&#32423;&#21035;&#25104;&#20687;&#20256;&#24863;&#22120;&#21040;&#25552;&#21319;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#21518;&#19968;&#31867;&#26041;&#27861;&#20351;&#29992;Tweedie&#20844;&#24335;&#65292;&#23558;&#39640;&#26031;&#21435;&#22122;&#30340;&#21518;&#39564;&#22343;&#20540;&#65288;&#21363;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#21435;&#22122;&#22120;&#65289;&#19982;&#25968;&#25454;&#20998;&#24067;&#30340;&#35780;&#20998;&#38142;&#25509;&#36215;&#26469;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25512;&#23548;&#20102;&#21518;&#39564;&#20998;&#24067;&#30340;&#39640;&#38454;&#20013;&#24515;&#30697;&#19982;&#21518;&#39564;&#22343;&#20540;&#30340;&#39640;&#38454;&#23548;&#25968;&#20043;&#38388;&#30340;&#22522;&#26412;&#20851;&#31995;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#36827;&#34892;&#39044;&#35757;&#32451;&#21435;&#22122;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#39640;&#25928;&#35745;&#31639;&#22270;&#20687;&#20219;&#20309;&#25152;&#38656;&#21306;&#22495;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#20027;&#25104;&#20998;&#65292;&#20197;&#21450;&#22914;&#20309;&#36817;&#20284;&#27839;&#36825;&#20123;&#65288;&#25110;&#20219;&#20309;&#20854;&#20182;&#65289;&#19968;&#32500;&#26041;&#21521;&#30340;&#23436;&#25972;&#36793;&#38469;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24555;&#36895;&#19988;&#20869;&#23384;&#39640;&#25928;&#65292;&#22240;&#20026;&#23427;&#19981;&#38656;&#35201;&#26174;&#24335;&#35745;&#31639;&#25110;&#23384;&#20648;&#39640;&#38454;&#30697;&#24352;&#37327;&#65292;&#24182;&#19988;&#26080;&#38656;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoisers play a central role in many applications, from noise suppression in low-grade imaging sensors, to empowering score-based generative models. The latter category of methods makes use of Tweedie's formula, which links the posterior mean in Gaussian denoising (i.e., the minimum MSE denoiser) with the score of the data distribution. Here, we derive a fundamental relation between the higher-order central moments of the posterior distribution, and the higher-order derivatives of the posterior mean. We harness this result for uncertainty quantification of pre-trained denoisers. Particularly, we show how to efficiently compute the principal components of the posterior distribution for any desired region of an image, as well as to approximate the full marginal distribution along those (or any other) one-dimensional directions. Our method is fast and memory efficient, as it does not explicitly compute or store the high-order moment tensors and it requires no training or fine tuning of t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#39044;&#27979;&#22303;&#22756;&#19982;&#26893;&#29289;&#34920;&#22411;&#20043;&#38388;&#32852;&#31995;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#35777;&#26126;&#21152;&#20837;&#22303;&#22756;&#29289;&#29702;&#21270;&#23398;&#24615;&#36136;&#21644;&#24494;&#29983;&#29289;&#31181;&#32676;&#23494;&#24230;&#31561;&#29615;&#22659;&#29305;&#24449;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11157</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20154;&#31867;&#38480;&#21046;&#65306;&#21033;&#29992;&#22303;&#22756;&#24494;&#29983;&#29289;&#25968;&#25454;&#39044;&#27979;&#26893;&#29289;&#34920;&#22411;
&lt;/p&gt;
&lt;p&gt;
Human Limits in Machine Learning: Prediction of Plant Phenotypes Using Soil Microbiome Data. (arXiv:2306.11157v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#39044;&#27979;&#22303;&#22756;&#19982;&#26893;&#29289;&#34920;&#22411;&#20043;&#38388;&#32852;&#31995;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#35777;&#26126;&#21152;&#20837;&#22303;&#22756;&#29289;&#29702;&#21270;&#23398;&#24615;&#36136;&#21644;&#24494;&#29983;&#29289;&#31181;&#32676;&#23494;&#24230;&#31561;&#29615;&#22659;&#29305;&#24449;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20445;&#25252;&#22303;&#22756;&#20581;&#24247;&#34987;&#35748;&#20026;&#26159;21&#19990;&#32426;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#65292;&#22240;&#20026;&#23427;&#22312;&#20892;&#19994;&#12289;&#20154;&#31867;&#20581;&#24247;&#21644;&#29983;&#29289;&#22810;&#26679;&#24615;&#26041;&#38754;&#20855;&#26377;&#24191;&#27867;&#65288;&#21487;&#33021;&#20855;&#26377;&#23041;&#32961;&#24615;&#30340;&#65289;&#24433;&#21709;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#20004;&#31181;&#27169;&#22411;&#65288;&#38543;&#26426;&#26862;&#26519;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65289;&#25506;&#32034;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#29702;&#35299;&#22303;&#22756;&#21644;&#29983;&#29289;&#34920;&#22411;&#20043;&#38388;&#32852;&#31995;&#30340;&#39044;&#27979;&#28508;&#21147;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#20013;&#21152;&#20837;&#22303;&#22756;&#29289;&#29702;&#21270;&#23398;&#24615;&#36136;&#21644;&#24494;&#29983;&#29289;&#31181;&#32676;&#23494;&#24230;&#31561;&#29615;&#22659;&#29305;&#24449;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#25506;&#32034;&#22810;&#31181;&#25968;&#25454;&#39044;&#22788;&#29702;&#31574;&#30053;&#65292;&#22914;&#24402;&#19968;&#21270;&#12289;&#38646;&#26367;&#25442;&#21644;&#25968;&#25454;&#22686;&#24378;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The preservation of soil health has been identified as one of the main challenges of the XXI century given its vast (and potentially threatening) ramifications in agriculture, human health and biodiversity. Here, we provide the first deep investigation of the predictive potential of machine-learning models to understand the connections between soil and biological phenotypes. Indeed, we investigate an integrative framework performing accurate machine-learning-based prediction of plant phenotypes from biological, chemical and physical properties of the soil via two models: random forest and Bayesian neural network. We show that prediction is improved, as evidenced by higher weighted F1 scores, when incorporating into the models environmental features like soil physicochemical properties and microbial population density in addition to the microbiome information. Furthermore, by exploring multiple data preprocessing strategies such as normalization, zero replacement, and data augmentation,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#33021;&#37327;&#22522;&#27169;&#22411;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#21644;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.00684</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#27969;&#37319;&#26679;&#24179;&#34913;&#35757;&#32451;&#33021;&#37327;&#22522;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Balanced Training of Energy-Based Models with Adaptive Flow Sampling. (arXiv:2306.00684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00684
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#33021;&#37327;&#22522;&#27169;&#22411;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#21644;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#27169;&#22411; (EBM) &#26159;&#19968;&#31181;&#30452;&#25509;&#21442;&#25968;&#21270;&#26410;&#26631;&#20934;&#21270;&#23545;&#25968;&#23494;&#24230;&#30340;&#22810;&#21151;&#33021;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#12290;EBM &#38750;&#24120;&#28789;&#27963;&#65292;&#20294;&#32570;&#20047;&#27169;&#22411;&#30340;&#35268;&#33539;&#21270;&#24120;&#37327;&#65292;&#20351;&#27169;&#22411;&#30340;&#20284;&#28982;&#20989;&#25968;&#35745;&#31639;&#19981;&#21487;&#34892;&#12290;&#36817;&#24180;&#26469;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#36817;&#20284;&#37319;&#26679;&#22120;&#21644;&#21464;&#20998;&#25512;&#29702;&#25216;&#26415;&#26469;&#20272;&#35745;&#20284;&#28982;&#20989;&#25968;&#26799;&#24230;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20123;&#25216;&#26415;&#22312;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23545;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#31934;&#24230;&#65292;&#20363;&#22914;&#30830;&#23450;&#25968;&#25454;&#38598;&#20013;&#19981;&#21516;&#31867;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#65292;&#21364;&#20184;&#20986;&#20102;&#24456;&#23569;&#30340;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#19968;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24402;&#19968;&#21270;&#27969; (NF)&#65292;&#36825;&#31181;&#27169;&#22411;&#26368;&#36817;&#34987;&#25552;&#20986;&#20197;&#20415;&#20110;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23558; NF &#25311;&#21512;&#21040; EBM &#19978;&#65292;&#20197;&#20415; NF &#36741;&#21161;&#19979;&#30340;&#37319;&#26679;&#26041;&#26696;&#33021;&#22815;&#22987;&#32456;&#20026; EBM &#25552;&#20379;&#20934;&#30830;&#30340;&#26799;&#24230;&#65292;&#26368;&#32456;&#25552;&#39640;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479; EBM &#35757;&#32451;&#25216;&#26415;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#21644;&#26356;&#22909;&#30340;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-based models (EBMs) are versatile density estimation models that directly parameterize an unnormalized log density. Although very flexible, EBMs lack a specified normalization constant of the model, making the likelihood of the model computationally intractable. Several approximate samplers and variational inference techniques have been proposed to estimate the likelihood gradients for training. These techniques have shown promising results in generating samples, but little attention has been paid to the statistical accuracy of the estimated density, such as determining the relative importance of different classes in a dataset. In this work, we propose a new maximum likelihood training algorithm for EBMs that uses a different type of generative model, normalizing flows (NF), which have recently been proposed to facilitate sampling. Our method fits an NF to an EBM during training so that an NF-assisted sampling scheme provides an accurate gradient for the EBMs at all times, ultim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#31163;&#32447;&#35757;&#32451;&#30340; Web &#20195;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;WebGUM&#65292;&#23558;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.11854</link><description>&lt;p&gt;
&#20351;&#29992;&#25351;&#20196;&#24494;&#35843;&#22522;&#30784;&#27169;&#22411;&#30340;&#22810;&#27169;&#24577; Web &#23548;&#33322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal Web Navigation with Instruction-Finetuned Foundation Models. (arXiv:2305.11854v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11854
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#31163;&#32447;&#35757;&#32451;&#30340; Web &#20195;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;WebGUM&#65292;&#23558;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20027; Web &#23548;&#33322;&#30340;&#36827;&#23637;&#21463;&#21040;&#20102;&#20381;&#36182;&#25968;&#21313;&#20159;&#27425;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#25506;&#32034;&#24615;&#20132;&#20114;&#21644;&#20855;&#26377;&#39046;&#22495;&#29305;&#23450;&#27169;&#22411;&#35774;&#35745;&#30340;&#24433;&#21709;&#65292;&#36825;&#20351;&#24471;&#38590;&#20197;&#21033;&#29992;&#26469;&#33258;&#20016;&#23500;&#39046;&#22495;&#22806;&#25968;&#25454;&#30340;&#27867;&#21270;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#33073;&#26426;&#35757;&#32451;&#65292;&#29992;&#20110;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#30340; Web &#20195;&#29702;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;&#65292; WebGUM&#65292;&#23427;&#35266;&#23519;&#20102;&#32593;&#39029;&#25130;&#22270;&#21644; HTML &#39029;&#38754;&#65292;&#24182;&#36755;&#20986; Web &#23548;&#33322;&#25805;&#20316;&#65292;&#22914;&#21333;&#20987;&#21644;&#36755;&#20837;&#12290;WebGUM &#26159;&#36890;&#36807;&#32852;&#21512;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#22312;&#22823;&#37327;&#30340;&#28436;&#31034;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#12290;&#25105;&#20204;&#20973;&#32463;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#26126;&#26174;&#20248;&#20110;&#20043;&#21069;&#30340;&#24037;&#20316;&#12290;&#22312; MiniWoB &#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#36229;&#36807;&#20043;&#21069;&#26368;&#20339;&#33073;&#26426;&#26041;&#27861; 31.9% &#20197;&#19978;&#65292;&#25509;&#36817;&#23454;&#29616;&#22312;&#32447;&#20132;&#20114;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The progress of autonomous web navigation has been hindered by the dependence on billions of exploratory interactions via online reinforcement learning, and domain-specific model designs that make it difficult to leverage generalization from rich out-of-domain data. In this work, we study data-driven offline training for web agents with vision-language foundation models. We propose an instruction-following multimodal agent, WebGUM, that observes both webpage screenshots and HTML pages and outputs web navigation actions, such as click and type. WebGUM is trained by jointly finetuning an instruction-finetuned language model and a vision transformer on a large corpus of demonstrations. We empirically demonstrate this recipe improves the agent's ability of grounded visual perception, HTML comprehension and multi-step reasoning, outperforming prior works by a significant margin. On the MiniWoB benchmark, we improve over the previous best offline methods by more than 31.9%, being close to re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#26102;&#38388;&#23610;&#24230;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#25910;&#25947;&#24615;&#65292;&#35813;&#26694;&#26550;&#21253;&#25324;&#20102;&#21508;&#31181;&#27969;&#34892;&#30340;Adam&#23478;&#26063;&#31639;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#21644;&#24212;&#23545;&#37325;&#23614;&#22122;&#22768;&#30340;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#34920;&#26126;&#20102;&#20854;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.03938</link><description>&lt;p&gt;
Adam&#23478;&#26063;&#31639;&#27861;&#22312;&#26080;&#24179;&#28369;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adam-family Methods for Nonsmooth Optimization with Convergence Guarantees. (arXiv:2305.03938v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#26102;&#38388;&#23610;&#24230;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#25910;&#25947;&#24615;&#65292;&#35813;&#26694;&#26550;&#21253;&#25324;&#20102;&#21508;&#31181;&#27969;&#34892;&#30340;Adam&#23478;&#26063;&#31639;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#21644;&#24212;&#23545;&#37325;&#23614;&#22122;&#22768;&#30340;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#34920;&#26126;&#20102;&#20854;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;Adam&#23478;&#26063;&#31639;&#27861;&#22312;&#26080;&#24179;&#28369;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#65292;&#29305;&#21035;&#26159;&#22312;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#26102;&#38388;&#23610;&#24230;&#26694;&#26550;&#65292;&#37319;&#29992;&#21452;&#26102;&#38388;&#23610;&#24230;&#26356;&#26032;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#20102;&#21508;&#31181;&#27969;&#34892;&#30340;Adam&#23478;&#26063;&#31639;&#27861;&#65292;&#22312;&#35757;&#32451;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#20013;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#65292;&#32467;&#21512;&#26799;&#24230;&#35009;&#21098;&#25216;&#26415;&#65292;&#29992;&#20110;&#35757;&#32451;&#20855;&#26377;&#37325;&#23614;&#22122;&#22768;&#30340;&#26080;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#29978;&#33267;&#22312;&#20165;&#20551;&#23450;&#35780;&#20272;&#22122;&#22768;&#21487;&#31215;&#30340;&#24773;&#20917;&#19979;&#20063;&#20250;&#25910;&#25947;&#12290;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#39640;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a comprehensive study on the convergence properties of Adam-family methods for nonsmooth optimization, especially in the training of nonsmooth neural networks. We introduce a novel two-timescale framework that adopts a two-timescale updating scheme, and prove its convergence properties under mild assumptions. Our proposed framework encompasses various popular Adam-family methods, providing convergence guarantees for these methods in training nonsmooth neural networks. Furthermore, we develop stochastic subgradient methods that incorporate gradient clipping techniques for training nonsmooth neural networks with heavy-tailed noise. Through our framework, we show that our proposed methods converge even when the evaluation noises are only assumed to be integrable. Extensive numerical experiments demonstrate the high efficiency and robustness of our proposed methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27969;&#24418;&#23398;&#20064;&#20013;&#24212;&#29992;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#30340;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#27604;OT&#22270;&#26356;&#20415;&#23452;&#22320;&#35745;&#31639;&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;&#21644;&#20280;&#32553;&#30340;&#31561;&#36317;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.00199</link><description>&lt;p&gt;
&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#22312;&#27969;&#34892;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Applications of No-Collision Transportation Maps in Manifold Learning. (arXiv:2304.00199v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00199
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27969;&#24418;&#23398;&#20064;&#20013;&#24212;&#29992;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#30340;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#27604;OT&#22270;&#26356;&#20415;&#23452;&#22320;&#35745;&#31639;&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;&#21644;&#20280;&#32553;&#30340;&#31561;&#36317;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24341;&#20837;&#20110;[Nurbekyan et al.&#65292;2020]&#30340;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#22312;&#22270;&#20687;&#25968;&#25454;&#30340;&#27969;&#24418;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#34920;&#31034;&#31867;&#20284;&#36816;&#21160;&#25110;&#21464;&#24418;&#29616;&#35937;&#30340;&#25968;&#25454;&#20013;&#65292;&#24212;&#29992;&#22522;&#20110;&#36816;&#36755;&#30340;&#36317;&#31163;&#21644;&#29305;&#24449;&#30340;&#30740;&#31350;&#22823;&#24133;&#22686;&#21152;&#12290;&#20107;&#23454;&#19978;&#65292;&#22266;&#23450;&#20301;&#32622;&#27604;&#36739;&#24378;&#24230;&#36890;&#24120;&#26080;&#27861;&#26174;&#31034;&#25968;&#25454;&#32467;&#26500;&#12290;&#22312;[Nurbekyan et al.&#65292;2020]&#20013;&#24320;&#21457;&#30340;&#26080;&#30896;&#25758;&#22270;&#21644;&#36317;&#31163;&#31867;&#20284;&#20110;&#26368;&#20248;&#20256;&#36755;(OT)&#22270;&#30340;&#20960;&#20309;&#29305;&#24449;&#20294;&#30001;&#20110;&#26080;&#38656;&#20248;&#21270;&#65292;&#35745;&#31639;&#25104;&#26412;&#35201;&#20415;&#23452;&#24471;&#22810;&#12290;&#26412;&#25991;&#35777;&#26126;&#26080;&#30896;&#25758;&#36317;&#31163;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;(&#20998;&#21035;&#26159;&#20280;&#32553;)&#21644;&#35013;&#22791;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#30340;&#24179;&#31227;(&#20998;&#21035;&#26159;&#20280;&#32553;)&#21521;&#37327;&#20043;&#38388;&#30340;&#31561;&#36317;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#20197;&#21450;OT&#21644;&#32447;&#24615;OT&#22270;&#65292;&#19968;&#33324;&#26469;&#35828;&#19981;&#33021;&#20026;&#26059;&#36716;&#25552;&#20379;&#31561;&#36317;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we investigate applications of no-collision transportation maps introduced in [Nurbekyan et. al., 2020] in manifold learning for image data. Recently, there has been a surge in applying transportation-based distances and features for data representing motion-like or deformation-like phenomena. Indeed, comparing intensities at fixed locations often does not reveal the data structure. No-collision maps and distances developed in [Nurbekyan et. al., 2020] are sensitive to geometric features similar to optimal transportation (OT) maps but much cheaper to compute due to the absence of optimization. In this work, we prove that no-collision distances provide an isometry between translations (respectively dilations) of a single probability measure and the translation (respectively dilation) vectors equipped with a Euclidean distance. Furthermore, we prove that no-collision transportation maps, as well as OT and linearized OT maps, do not in general provide an isometry for rotatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#21442;&#25968;&#32467;&#26500;&#20551;&#35774;&#30340;&#40657;&#30418;&#31243;&#24207;&#65292;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#12290;&#35813;&#31243;&#24207;&#21487;&#20197;&#25104;&#21151;&#22320;&#20174;&#20855;&#26377;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.15041</link><description>&lt;p&gt;
&#26397;&#40657;&#30418;&#21442;&#25968;&#20272;&#35745;&#36808;&#36827;
&lt;/p&gt;
&lt;p&gt;
Towards black-box parameter estimation. (arXiv:2303.15041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#21442;&#25968;&#32467;&#26500;&#20551;&#35774;&#30340;&#40657;&#30418;&#31243;&#24207;&#65292;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#12290;&#35813;&#31243;&#24207;&#21487;&#20197;&#25104;&#21151;&#22320;&#20174;&#20855;&#26377;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#26368;&#36817;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#25104;&#21151;&#24037;&#20855;&#65292;&#27169;&#25311;&#23481;&#26131;&#20294;&#20284;&#28982;&#35745;&#31639;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#25104;&#21151;&#21462;&#20915;&#20110;&#27169;&#25311;&#20986;&#21487;&#20197;&#20805;&#20998;&#22797;&#21046;&#35266;&#23519;&#25968;&#25454;&#30340;&#21442;&#25968;&#65292;&#24182;&#19988;&#30446;&#21069;&#32570;&#20047;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#20135;&#29983;&#36825;&#20123;&#27169;&#25311;&#25968;&#25454;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#24369;&#21442;&#25968;&#32467;&#26500;&#20551;&#35774;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#26032;&#30340;&#40657;&#30418;&#31243;&#24207;&#12290;&#23545;&#20110;&#20284;&#28982;&#20989;&#25968;&#26377;&#36739;&#39057;&#32321;&#20986;&#29616;&#30340;&#33391;&#22909;&#32467;&#26500;&#30340;&#24773;&#20917;&#65292;&#22914;&#26102;&#38388;&#24207;&#21015;&#65292;&#36825;&#26159;&#36890;&#36807;&#22312;&#24191;&#27867;&#30340;&#27169;&#25311;&#25968;&#25454;&#24211;&#19978;&#39044;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#30340;&#65292;&#35813;&#25968;&#25454;&#24211;&#28085;&#30422;&#20102;&#21508;&#31181;&#25968;&#25454;&#22823;&#23567;&#30340;&#33539;&#22260;&#12290;&#23545;&#20110;&#20854;&#20182;&#31867;&#22411;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#65292;&#21017;&#38656;&#35201;&#19968;&#20010;&#36845;&#20195;&#30340;&#31639;&#27861;&#26469;&#25351;&#23548;&#22810;&#36718;&#27491;&#30830;&#21442;&#25968;&#21306;&#22495;&#30340;&#27169;&#25311;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#25104;&#21151;&#22320;&#20174;&#20855;&#26377;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning algorithms have recently shown to be a successful tool in estimating parameters of statistical models for which simulation is easy, but likelihood computation is challenging. But the success of these approaches depends on simulating parameters that sufficiently reproduce the observed data, and, at present, there is a lack of efficient methods to produce these simulations. We develop new black-box procedures to estimate parameters of statistical models based only on weak parameter structure assumptions. For well-structured likelihoods with frequent occurrences, such as in time series, this is achieved by pre-training a deep neural network on an extensive simulated database that covers a wide range of data sizes. For other types of complex dependencies, an iterative algorithm guides simulations to the correct parameter region in multiple rounds. These approaches can successfully estimate and quantify the uncertainty of parameters from non-Gaussian models with complex spatia
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20351;&#29992;&#30340;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968; $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2302.08766</link><description>&lt;p&gt;
&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#30340;&#19979;&#30028;&#21644;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08766
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20351;&#29992;&#30340;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968; $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#26368;&#20248;&#21270;&#38382;&#39064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#19978;&#23618;&#21644;&#19979;&#23618;&#30446;&#26631;&#23545;&#24212;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#22240;&#27492;&#20855;&#26377;&#24635;&#21644;&#32467;&#26500;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33879;&#21517;&#30340;SARAH&#31639;&#27861;&#30340;&#21452;&#23618;&#25193;&#23637;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#38656;&#35201;$\mathcal {O}((n+m)^{\frac{1}{2}}\varepsilon ^{-1})$&#27425;&#26799;&#24230;&#35745;&#31639;&#25165;&#33021;&#23454;&#29616;$\varepsilon$&#31283;&#23450;&#24615;&#65292;&#20854;&#20013;$n+m$&#26159;&#26679;&#26412;&#24635;&#25968;&#65292;&#36825;&#27604;&#20808;&#21069;&#25152;&#26377;&#30340;&#21452;&#23618;&#31639;&#27861;&#37117;&#35201;&#22909;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#29992;&#20110;&#24471;&#21040;&#21452;&#23618;&#38382;&#39064;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#25152;&#38656;&#30340;oracle&#35843;&#29992;&#27425;&#25968;&#12290;&#36825;&#20010;&#19979;&#30028;&#27491;&#26159;&#25105;&#20204;&#30340;&#31639;&#27861;&#25152;&#36798;&#21040;&#30340;&#65292;&#22240;&#27492;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\mathcal{O}((n+m)^{\frac12}\varepsilon^{-1})$ gradient computations to achieve $\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20004;&#31181;&#22522;&#20110;&#20256;&#36755;&#26144;&#23556;&#30340;&#25277;&#26679;&#26041;&#27861;&#65292;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#27969;&#30340;&#25552;&#35758;&#21487;&#20197;&#22788;&#29702;&#22810;&#23792;&#30446;&#26631;&#65292;&#22312;&#39640;&#32500;&#24230;&#21644;&#35757;&#32451;&#19981;&#33391;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#20381;&#36182;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#26356;&#21152;&#31283;&#20581;&#12290;</title><link>http://arxiv.org/abs/2302.04763</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#36817;&#20284;&#20256;&#36755;&#26144;&#23556;&#36827;&#34892;&#25277;&#26679;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Sampling with Approximate Transport Maps. (arXiv:2302.04763v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20004;&#31181;&#22522;&#20110;&#20256;&#36755;&#26144;&#23556;&#30340;&#25277;&#26679;&#26041;&#27861;&#65292;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#27969;&#30340;&#25552;&#35758;&#21487;&#20197;&#22788;&#29702;&#22810;&#23792;&#30446;&#26631;&#65292;&#22312;&#39640;&#32500;&#24230;&#21644;&#35757;&#32451;&#19981;&#33391;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#20381;&#36182;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#26356;&#21152;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#20998;&#24067;&#36716;&#21270;&#20026;&#26131;&#20110;&#22788;&#29702;&#30340;&#20998;&#24067;&#65292;&#20256;&#36755;&#26144;&#23556;&#21487;&#20197;&#31616;&#21270;&#20855;&#26377;&#38750;&#24179;&#20961;&#20960;&#20309;&#32467;&#26500;&#30340;&#20998;&#24067;&#30340;&#25277;&#26679;&#12290;&#38543;&#30528;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#20256;&#32479;&#27969;&#65288;NF&#65289;&#30340;&#21457;&#23637;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#28508;&#21147;&#19981;&#26029;&#25552;&#39640;&#12290;NF&#22686;&#24378;&#37319;&#26679;&#22120;&#26368;&#36817;&#25552;&#20986;&#20102;&#23558;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#19982;&#65288;i&#65289;&#26469;&#33258;&#27969;&#30340;&#25552;&#35758;&#32472;&#21046;&#25110;&#65288;ii&#65289;&#22522;&#20110;&#27969;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#30456;&#32467;&#21512;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#21040;&#30340;&#20256;&#36755;&#30340;&#36136;&#37327;&#20250;&#24433;&#21709;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#39318;&#27425;&#38416;&#26126;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#30456;&#23545;&#20248;&#21183;&#21644;&#21155;&#21183;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24471;&#20986;&#32467;&#35770;&#65306;&#30452;&#21040;&#20013;&#31561;&#32500;&#24230;&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#20351;&#29992;&#22522;&#20110;&#27969;&#30340;&#25552;&#35758;&#22788;&#29702;&#22810;&#23792;&#30446;&#26631;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#22312;&#39640;&#32500;&#24230;&#21644;&#35757;&#32451;&#19981;&#33391;&#30340;&#24773;&#20917;&#19979;&#65292;&#20381;&#36182;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#22312;&#22810;&#27169;&#24335;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#20294;&#20854;&#20182;&#26041;&#38754;&#26356;&#20026;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transport maps can ease the sampling of distributions with non-trivial geometries by transforming them into distributions that are easier to handle. The potential of this approach has risen with the development of Normalizing Flows (NF) which are maps parameterized with deep neural networks trained to push a reference distribution towards a target. NF-enhanced samplers recently proposed blend (Markov chain) Monte Carlo methods with either (i) proposal draws from the flow or (ii) a flow-based reparametrization. In both cases, the quality of the learned transport conditions performance. The present work clarifies for the first time the relative strengths and weaknesses of these two approaches. Our study concludes that multimodal targets can be reliably handled with flow-based proposals up to moderately high dimensions. In contrast, methods relying on reparametrization struggle with multimodality but are more robust otherwise in high-dimensional settings and under poor training. To furthe
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#20197;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#35770;&#25991;&#25552;&#20379;&#20102;&#27169;&#22411;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#29992;&#25143;&#25968;&#37327;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.14115</link><description>&lt;p&gt;
&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Inverse Solvability and Security with Applications to Federated Learning. (arXiv:2211.14115v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14115
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#20197;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#35770;&#25991;&#25552;&#20379;&#20102;&#27169;&#22411;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#29992;&#25143;&#25968;&#37327;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#32447;&#24615;&#21069;&#21521;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#24212;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#20013;&#20351;&#29992;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#26679;&#30340;&#27169;&#22411;&#30340;&#31034;&#20363;&#65292;&#20854;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#22312;&#26412;&#25991;&#20013;&#24471;&#21040;&#23450;&#20041;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#21442;&#19982;&#32473;&#23450;&#36845;&#20195;&#30340;&#22823;&#37327;&#29992;&#25143;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#25152;&#25552;&#20986;&#27010;&#24565;&#30340;&#21487;&#33021;&#25193;&#23637;&#65292;&#21253;&#25324;&#38750;&#32447;&#24615;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the concepts of inverse solvability and security for a generic linear forward model and demonstrate how they can be applied to models used in federated learning. We provide examples of such models which differ in the resulting inverse solvability and security as defined in this paper. We also show how the large number of users participating in a given iteration of federated learning can be leveraged to increase both solvability and security. Finally, we discuss possible extensions of the presented concepts including the nonlinear case.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#23558;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#24191;&#27867;&#30340;&#31354;&#38388;&#20013;&#65292;&#24182;&#23548;&#33268;&#20998;&#25968;&#21305;&#37197;&#30340;&#21407;&#22987;&#25193;&#23637;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2211.03595</link><description>&lt;p&gt;
&#20174;&#21435;&#22122;&#25193;&#25955;&#21040;&#21435;&#22122;&#39532;&#23572;&#31185;&#22827;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
From Denoising Diffusions to Denoising Markov Models. (arXiv:2211.03595v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.03595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#23558;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#24191;&#27867;&#30340;&#31354;&#38388;&#20013;&#65292;&#24182;&#23548;&#33268;&#20998;&#25968;&#21305;&#37197;&#30340;&#21407;&#22987;&#25193;&#23637;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#26159;&#23637;&#29616;&#20986;&#21331;&#36234;&#23454;&#39564;&#24615;&#33021;&#30340;&#26368;&#20808;&#36827;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#20182;&#20204;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#25193;&#25955;&#21040;&#39640;&#26031;&#20998;&#24067;&#65292;&#28982;&#21518;&#23398;&#20064;&#36870;&#36716;&#36825;&#20010;&#22122;&#22768;&#36807;&#31243;&#20197;&#33719;&#21462;&#21512;&#25104;&#25968;&#25454;&#28857;&#12290;&#21435;&#22122;&#25193;&#25955;&#20381;&#36182;&#20110;&#20351;&#29992;&#20998;&#25968;&#21305;&#37197;&#23545;&#22122;&#22768;&#25968;&#25454;&#23494;&#24230;&#30340;&#23545;&#25968;&#23548;&#25968;&#30340;&#36924;&#36817;&#12290;&#24403;&#21482;&#33021;&#20174;&#20808;&#39564;&#20998;&#24067;&#21644;&#20284;&#28982;&#20989;&#25968;&#20013;&#36827;&#34892;&#25277;&#26679;&#26102;&#65292;&#36825;&#31181;&#27169;&#22411;&#20063;&#21487;&#29992;&#20110;&#25191;&#34892;&#36817;&#20284;&#21518;&#39564;&#27169;&#25311;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#23558;&#27492;&#26041;&#27861;&#25512;&#24191;&#21040;&#19968;&#31867;&#24191;&#27867;&#30340;&#31354;&#38388;&#65292;&#24182;&#23548;&#33268;&#20998;&#25968;&#21305;&#37197;&#30340;&#21407;&#22987;&#25193;&#23637;&#12290;&#25105;&#20204;&#36890;&#36807;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#35828;&#26126;&#20102;&#25152;&#24471;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusions are state-of-the-art generative models exhibiting remarkable empirical performance. They work by diffusing the data distribution into a Gaussian distribution and then learning to reverse this noising process to obtain synthetic datapoints. The denoising diffusion relies on approximations of the logarithmic derivatives of the noised data densities using score matching. Such models can also be used to perform approximate posterior simulation when one can only sample from the prior and likelihood. We propose a unifying framework generalising this approach to a wide class of spaces and leading to an original extension of score matching. We illustrate the resulting models on various applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#35777;&#26126;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#23545;&#23398;&#20064;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#35828;&#26126;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#26102;&#65292;&#23569;&#25968;&#21644;&#22810;&#25968;&#31867;&#30340;&#23398;&#20064;&#26354;&#32447;&#20250;&#36981;&#24490;&#27425;&#20248;&#36712;&#36857;&#65292;&#21516;&#26102;&#25552;&#20986;&#23545;&#27599;&#31181;&#31867;&#21035;&#26799;&#24230;&#20570;&#20986;&#36129;&#29486;&#30340;&#24402;&#19968;&#21270;&#21464;&#20307;&#65292;&#20197;&#35299;&#20915;&#20248;&#21270;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#30340;&#31454;&#20105;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2207.00391</link><description>&lt;p&gt;
&#31867;&#21035;&#19981;&#24179;&#34913;&#19979;&#30340;&#23398;&#20064;&#21160;&#24577;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of the Learning Dynamics under Class Imbalance. (arXiv:2207.00391v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.00391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#35777;&#26126;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#23545;&#23398;&#20064;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#35828;&#26126;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#26102;&#65292;&#23569;&#25968;&#21644;&#22810;&#25968;&#31867;&#30340;&#23398;&#20064;&#26354;&#32447;&#20250;&#36981;&#24490;&#27425;&#20248;&#36712;&#36857;&#65292;&#21516;&#26102;&#25552;&#20986;&#23545;&#27599;&#31181;&#31867;&#21035;&#26799;&#24230;&#20570;&#20986;&#36129;&#29486;&#30340;&#24402;&#19968;&#21270;&#21464;&#20307;&#65292;&#20197;&#35299;&#20915;&#20248;&#21270;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#30340;&#31454;&#20105;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#19981;&#24179;&#34913;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#24120;&#35265;&#30340;&#38382;&#39064;&#65292;&#20250;&#20005;&#37325;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#12290;&#34429;&#28982;&#26377;&#21508;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#20204;&#23545;&#23398;&#20064;&#21160;&#24577;&#30340;&#25910;&#25947;&#24433;&#21709;&#23578;&#26410;&#34987;&#29702;&#35299;&#12290;&#26412;&#25991;&#38416;&#26126;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#23545;&#23398;&#20064;&#30340;&#26174;&#33879;&#36127;&#38754;&#24433;&#21709;&#65292;&#24403;&#20351;&#29992;&#26799;&#24230;&#20248;&#21270;&#22120;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#23569;&#25968;&#31867;&#21644;&#22810;&#25968;&#31867;&#30340;&#23398;&#20064;&#26354;&#32447;&#20250;&#36981;&#24490;&#27425;&#20248;&#36712;&#36857;&#12290;&#36825;&#31181;&#25918;&#32531;&#19982;&#19981;&#24179;&#34913;&#27604;&#30456;&#20851;&#65292;&#21487;&#20197;&#36861;&#28335;&#21040;&#20248;&#21270;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#30340;&#31454;&#20105;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#20998;&#26512;&#20102;&#20840;&#25209;&#27425;&#65288;GD&#65289;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#21644;&#21508;&#31181;&#23545;&#27599;&#31181;&#31867;&#21035;&#26799;&#24230;&#20570;&#20986;&#36129;&#29486;&#30340;&#24402;&#19968;&#21270;&#21464;&#20307;&#12290;&#25105;&#20204;&#21457;&#29616;GD&#19981;&#33021;&#20445;&#35777;&#38477;&#20302;&#27599;&#20010;&#31867;&#21035;&#30340;&#25439;&#22833;&#65292;&#20294;&#21487;&#20197;&#36890;&#36807;&#25191;&#34892;&#21508;&#33258;&#24402;&#19968;&#21270;&#26799;&#24230;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#20351;&#29992;SGD&#26102;, &#31867;&#21035;&#19981;&#24179;&#34913;&#20250;&#23545;&#31639;&#27861;&#20135;&#29983;&#39069;&#22806;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data imbalance is a common problem in machine learning that can have a critical effect on the performance of a model. Various solutions exist but their impact on the convergence of the learning dynamics is not understood. Here, we elucidate the significant negative impact of data imbalance on learning, showing that the learning curves for minority and majority classes follow sub-optimal trajectories when training with a gradient-based optimizer. This slowdown is related to the imbalance ratio and can be traced back to a competition between the optimization of different classes. Our main contribution is the analysis of the convergence of full-batch (GD) and stochastic gradient descent (SGD), and of variants that renormalize the contribution of each per-class gradient. We find that GD is not guaranteed to decrease the loss for each class but that this problem can be addressed by performing a per-class normalization of the gradient. With SGD, class imbalance has an additional effect on th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#24490;&#29615;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#22797;&#26434;&#30340;&#22810;&#26234;&#33021;&#20307;&#22330;&#26223;&#20013;&#20272;&#35745;&#24178;&#39044;&#25928;&#26524;&#12290;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#26102;&#38388;&#21464;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#20851;&#31995;&#21644;&#21327;&#21464;&#37327;&#21453;&#20107;&#23454;&#39044;&#27979;&#30340;&#22797;&#26434;&#32467;&#26500;&#65292;&#33021;&#22815;&#20934;&#30830;&#35780;&#20272;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#25552;&#20379;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.01900</link><description>&lt;p&gt;
&#22312;&#22797;&#26434;&#30340;&#22810;&#26234;&#33021;&#20307;&#22330;&#26223;&#20013;&#20272;&#35745;&#21453;&#20107;&#23454;&#27835;&#30103;&#32467;&#26524;&#30340;&#26102;&#38388;&#21464;&#21270;
&lt;/p&gt;
&lt;p&gt;
Estimating counterfactual treatment outcomes over time in complex multi-agent scenarios. (arXiv:2206.01900v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.01900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#24490;&#29615;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#22797;&#26434;&#30340;&#22810;&#26234;&#33021;&#20307;&#22330;&#26223;&#20013;&#20272;&#35745;&#24178;&#39044;&#25928;&#26524;&#12290;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#26102;&#38388;&#21464;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#20851;&#31995;&#21644;&#21327;&#21464;&#37327;&#21453;&#20107;&#23454;&#39044;&#27979;&#30340;&#22797;&#26434;&#32467;&#26500;&#65292;&#33021;&#22815;&#20934;&#30830;&#35780;&#20272;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#25552;&#20379;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#24037;&#31243;&#21644;&#31185;&#23398;&#39046;&#22495;&#20013;&#65292;&#35780;&#20272;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#30340;&#24178;&#39044;&#34892;&#20026;&#65288;&#20363;&#22914;&#65292;&#20154;&#31867;&#20309;&#26102;&#24212;&#35813;&#24178;&#39044;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#65292;&#20309;&#26102;&#29699;&#21592;&#24212;&#35813;&#20256;&#32473;&#38431;&#21451;&#36827;&#34892;&#22909;&#23556;&#38376;&#65289;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20351;&#29992;&#21453;&#20107;&#23454;&#30340;&#38271;&#26399;&#39044;&#27979;&#26469;&#20272;&#35745;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE&#65289;&#26159;&#35780;&#20272;&#27492;&#31867;&#24178;&#39044;&#25514;&#26045;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20256;&#32479;&#26694;&#26550;&#27809;&#26377;&#32771;&#34385;&#21040;&#22810;&#26234;&#33021;&#20307;&#20851;&#31995;&#30340;&#26102;&#38388;&#21464;&#21270;&#21644;&#21327;&#21464;&#37327;&#21453;&#20107;&#23454;&#39044;&#27979;&#30340;&#22797;&#26434;&#32467;&#26500;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;ITE&#30340;&#38169;&#35823;&#35780;&#20272;&#21644;&#35299;&#37322;&#22256;&#38590;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#24490;&#29615;&#32593;&#32476;&#65292;&#29992;&#20110;&#20272;&#35745;&#24178;&#39044;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21033;&#29992;&#22270;&#24418;&#21464;&#20998;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#39046;&#22495;&#30693;&#35782;&#30340;&#35745;&#31639;&#26469;&#36827;&#34892;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#30340;&#38271;&#26399;&#39044;&#27979;&#30340;ITE&#20272;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#30830;&#35748;&#24490;&#29615;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluation of intervention in a multi-agent system, e.g., when humans should intervene in autonomous driving systems and when a player should pass to teammates for a good shot, is challenging in various engineering and scientific fields. Estimating the individual treatment effect (ITE) using counterfactual long-term prediction is practical to evaluate such interventions. However, most of the conventional frameworks did not consider the time-varying complex structure of multi-agent relationships and covariate counterfactual prediction. This may lead to erroneous assessments of ITE and difficulty in interpretation. Here we propose an interpretable, counterfactual recurrent network in multi-agent systems to estimate the effect of the intervention. Our model leverages graph variational recurrent neural networks and theory-based computation with domain knowledge for the ITE estimation framework based on long-term prediction of multi-agent covariates and outcomes, which can confirm the circu
&lt;/p&gt;</description></item></channel></rss>