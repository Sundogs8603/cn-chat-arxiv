<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#25581;&#31034;&#26435;&#37325;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#25104;&#21151;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#34892;&#30340;&#22522;&#20110;&#26679;&#26412;&#25512;&#29702;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#26469;&#35299;&#20915;&#37319;&#26679;&#21644;&#25910;&#25947;&#38382;&#39064;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01484</link><description>&lt;p&gt;
&#36830;&#25509;&#28857;&#65306;&#27169;&#24335;&#36830;&#25509;&#26159;&#21542;&#26159;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21487;&#34892;&#30340;&#22522;&#20110;&#26679;&#26412;&#25512;&#29702;&#30340;&#20851;&#38190;&#65311;
&lt;/p&gt;
&lt;p&gt;
Connecting the Dots: Is Mode-Connectedness the Key to Feasible Sample-Based Inference in Bayesian Neural Networks?
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01484
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25581;&#31034;&#26435;&#37325;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#25104;&#21151;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#34892;&#30340;&#22522;&#20110;&#26679;&#26412;&#25512;&#29702;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#26469;&#35299;&#20915;&#37319;&#26679;&#21644;&#25910;&#25947;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#20110;&#26679;&#26412;&#25512;&#29702;&#65288;SBI&#65289;&#20013;&#65292;&#32593;&#32476;&#21442;&#25968;&#31354;&#38388;&#30340;&#22823;&#23567;&#21644;&#32467;&#26500;&#26159;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#25509;&#21463;&#26435;&#37325;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#29305;&#24449;&#20851;&#31995;&#65292;&#25104;&#21151;&#23454;&#29616;SBI&#26159;&#21487;&#33021;&#30340;&#65292;&#25581;&#31034;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#21644;&#37319;&#26679;&#38382;&#39064;&#22256;&#38590;&#20043;&#38388;&#30340;&#31995;&#32479;&#32852;&#31995;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#37319;&#26679;&#21644;&#25910;&#25947;&#35786;&#26029;&#30340;&#23454;&#38469;&#25351;&#21335;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20855;&#26377;&#31454;&#20105;&#24615;&#33021;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
A major challenge in sample-based inference (SBI) for Bayesian neural networks is the size and structure of the networks' parameter space. Our work shows that successful SBI is possible by embracing the characteristic relationship between weight and function space, uncovering a systematic link between overparameterization and the difficulty of the sampling problem. Through extensive experiments, we establish practical guidelines for sampling and convergence diagnosis. As a result, we present a Bayesian deep ensemble approach as an effective solution with competitive performance and uncertainty quantification.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#26680;-&#29305;&#24449;&#23545;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#65288;KEP-SVGP&#65289;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#33258;&#27880;&#24847;&#21147;&#12290;&#36890;&#36807;&#26680;SVD&#65288;KSVD&#65289;&#35299;&#20915;&#20102;&#27880;&#24847;&#21147;&#26680;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#38477;&#20302;&#30340;&#22797;&#26434;&#24230;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01476</link><description>&lt;p&gt;
&#33258;&#26680;-&#29305;&#24449;&#23545;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#20013;&#30340;&#33258;&#27880;&#24847;&#21147;
&lt;/p&gt;
&lt;p&gt;
Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#26680;-&#29305;&#24449;&#23545;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#65288;KEP-SVGP&#65289;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#33258;&#27880;&#24847;&#21147;&#12290;&#36890;&#36807;&#26680;SVD&#65288;KSVD&#65289;&#35299;&#20915;&#20102;&#27880;&#24847;&#21147;&#26680;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#38477;&#20302;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;Transformer&#20855;&#26377;&#26174;&#33879;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#33021;&#21147;&#65292;&#20294;&#23427;&#20063;&#21487;&#33021;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#65292;&#24182;&#38656;&#35201;&#26657;&#20934;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#36825;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26469;&#35299;&#20915;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#23558;&#23545;&#31216;&#26680;&#24212;&#29992;&#20110;&#21464;&#20998;&#25512;&#26029;&#19979;&#30340;&#27880;&#24847;&#21147;&#26680;&#65307;&#28982;&#32780;&#65292;&#24573;&#30053;&#20102;&#27880;&#24847;&#21147;&#26680;&#26412;&#36136;&#19978;&#26159;&#19981;&#23545;&#31216;&#30340;&#20107;&#23454;&#12290;&#27492;&#22806;&#65292;&#25512;&#23548;&#20986;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;GP&#21518;&#39564;&#30340;&#22797;&#26434;&#24230;&#20173;&#28982;&#24456;&#39640;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#33258;&#27880;&#24847;&#21147;&#30340;&#26680;-&#29305;&#24449;&#23545;&#31232;&#30095;&#21464; &#20998;&#39640;&#26031;&#36807;&#31243;&#65288;KEP-SVGP&#65289;&#65292;&#20854;&#20013;&#36890;&#36807;&#26680;SVD&#65288;KSVD&#65289;&#35299;&#20915;&#20102;&#27880;&#24847;&#21147;&#26680;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#33719;&#24471;&#20102;&#38477;&#20302;&#30340;&#22797;&#26434;&#24230;&#12290;&#36890;&#36807;KEP-SVGP&#65292;i&#65289;&#30001;&#20110;&#19982;&#27880;&#24847;&#21147;&#26680;&#30340;KSVD&#30456;&#23545;&#24212;&#30340;&#20004;&#32452;&#22855;&#24322;&#21521;&#37327;&#24341;&#23548;&#30340;SVGP&#23545;&#23436;&#20840;&#34920;&#24449;&#20102;&#19981;&#23545;&#31216;&#24615;&#65307;ii&#65289;&#20165;&#20351;&#29992;&#23569;&#37327;&#19982;KSVD&#30456;&#23545;&#24212;&#30340;&#20276;&#38543;&#29305;&#24449;&#20989;&#25968;&#65292;&#25512;&#23548;SVGP&#21518;&#39564;&#27010;&#29575;&#23494;&#24230;&#21487;&#20197;&#23454;&#29616;&#36739;&#20302;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
While the great capability of Transformers significantly boosts prediction accuracy, it could also yield overconfident predictions and require calibrated uncertainty estimation, which can be commonly tackled by Gaussian processes (GPs). Existing works apply GPs with symmetric kernels under variational inference to the attention kernel; however, omitting the fact that attention kernels are in essence asymmetric. Moreover, the complexity of deriving the GP posteriors remains high for large-scale data. In this work, we propose Kernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for building uncertainty-aware self-attention where the asymmetry of attention kernels is tackled by Kernel SVD (KSVD) and a reduced complexity is acquired. Through KEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors from KSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) using only a small set of adjoint eigenfunctions from KSVD, the derivation of SVGP posteri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#32447;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36882;&#20943;&#27493;&#38271;&#26469;&#25913;&#36827;&#22312;&#20219;&#24847;&#24207;&#21015;&#19978;&#30340;&#35206;&#30422;&#29575;&#20445;&#35777;&#65292;&#24182;&#19988;&#33021;&#22815;&#21516;&#26102;&#20272;&#35745;&#24635;&#20307;&#20998;&#20301;&#25968;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01139</link><description>&lt;p&gt;
&#22312;&#32447;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#20013;&#24102;&#26377;&#36882;&#20943;&#27493;&#38271;
&lt;/p&gt;
&lt;p&gt;
Online conformal prediction with decaying step sizes
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#32447;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36882;&#20943;&#27493;&#38271;&#26469;&#25913;&#36827;&#22312;&#20219;&#24847;&#24207;&#21015;&#19978;&#30340;&#35206;&#30422;&#29575;&#20445;&#35777;&#65292;&#24182;&#19988;&#33021;&#22815;&#21516;&#26102;&#20272;&#35745;&#24635;&#20307;&#20998;&#20301;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#24102;&#26377;&#36882;&#20943;&#27493;&#38271;&#30340;&#22312;&#32447;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#12290;&#21644;&#20043;&#21069;&#30340;&#26041;&#27861;&#19968;&#26679;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#33021;&#22312;&#20219;&#24847;&#24207;&#21015;&#19978;&#22238;&#28335;&#24615;&#22320;&#20445;&#35777;&#35206;&#30422;&#29575;&#12290;&#28982;&#32780;&#65292;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#20272;&#35745;&#20986;&#24635;&#20307;&#20998;&#20301;&#25968;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#26174;&#33879;&#25913;&#36827;&#30340;&#23454;&#38469;&#29305;&#24615;&#65306;&#29305;&#21035;&#26159;&#22312;&#20998;&#24067;&#31283;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#35206;&#30422;&#29575;&#25509;&#36817;&#25152;&#26399;&#26395;&#30340;&#27700;&#24179;&#65292;&#19981;&#20165;&#20165;&#22312;&#35266;&#27979;&#24207;&#21015;&#30340;&#24179;&#22343;&#20540;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a method for online conformal prediction with decaying step sizes. Like previous methods, ours possesses a retrospective guarantee of coverage for arbitrary sequences. However, unlike previous methods, we can simultaneously estimate a population quantile when it exists. Our theory and experiments indicate substantially improved practical properties: in particular, when the distribution is stable, the coverage is close to the desired level for every time point, not just on average over the observed sequence.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#35299;&#37322;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#36890;&#36807;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#65292;&#32780;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#35201;&#27714;&#22686;&#21152;&#35757;&#32451;&#27493;&#25968;&#24555;&#20110;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#65292;&#19982;&#23454;&#35777;&#35266;&#23519;&#30456;&#19968;&#33268;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01092</link><description>&lt;p&gt;
&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#30340;&#21160;&#21147;&#23398;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Dynamical Model of Neural Scaling Laws
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01092
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#35299;&#37322;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#36890;&#36807;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#65292;&#32780;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#35201;&#27714;&#22686;&#21152;&#35757;&#32451;&#27493;&#25968;&#24555;&#20110;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#65292;&#19982;&#23454;&#35777;&#35266;&#23519;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#38543;&#30528;&#35757;&#32451;&#26102;&#38388;&#12289;&#25968;&#25454;&#38598;&#22823;&#23567;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#39044;&#27979;&#24615;&#22320;&#25552;&#39640;&#65292;&#36328;&#22810;&#20010;&#25968;&#37327;&#32423;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#23450;&#24459;&#65292;&#23427;&#25253;&#21578;&#20102;&#22312;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#22823;&#23567;&#26102;&#24615;&#33021;&#19982;&#35745;&#31639;&#25968;&#37327;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#35757;&#32451;&#21644;&#27867;&#21270;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#20316;&#20026;&#32593;&#32476;&#35757;&#32451;&#21644;&#27867;&#21270;&#30340;&#21487;&#35299;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#22797;&#29616;&#20102;&#20851;&#20110;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#30340;&#35768;&#22810;&#35266;&#23519;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23545;&#20110;&#20026;&#20160;&#20040;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#25552;&#20986;&#20102;&#19968;&#20010;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#29702;&#35770;&#39044;&#27979;&#20102;&#19968;&#31181;&#19981;&#23545;&#31216;&#30340;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#65292;&#20854;&#20013;&#35757;&#32451;&#27493;&#25968;&#30340;&#22686;&#21152;&#36895;&#24230;&#24555;&#20110;&#27169;&#22411;&#21442;&#25968;&#30340;&#22686;&#21152;&#36895;&#24230;&#65292;&#19982;&#26368;&#36817;&#30340;&#23454;&#35777;&#35266;&#23519;&#19968;&#33268;&#12290;&#20854;&#27425;&#65292;&#35266;&#23519;&#21040;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#65292;&#32593;&#32476;&#20250;&#25910;&#25947;&#21040;&#26080;&#38480;&#23485;&#24230;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-wi
&lt;/p&gt;</description></item><item><title>&#26126;&#30830;&#34920;&#31034;&#20449;&#24687;&#32467;&#26500;&#26159;&#20998;&#26512;&#21644;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;</title><link>https://arxiv.org/abs/2403.00993</link><description>&lt;p&gt;
&#35770;&#37096;&#20998;&#21487;&#35266;&#23519;&#24207;&#21015;&#22242;&#38431;&#21644;&#28216;&#25103;&#20013;&#20449;&#24687;&#32467;&#26500;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00993
&lt;/p&gt;
&lt;p&gt;
&#26126;&#30830;&#34920;&#31034;&#20449;&#24687;&#32467;&#26500;&#26159;&#20998;&#26512;&#21644;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#20449;&#24687;&#32467;&#26500;&#25551;&#36848;&#20102;&#31995;&#32479;&#20013;&#19981;&#21516;&#26102;&#21051;&#20107;&#20214;&#22914;&#20309;&#30456;&#20114;&#24433;&#21709;&#12290;&#26412;&#25991;&#20027;&#24352;&#26126;&#30830;&#34920;&#31034;&#20449;&#24687;&#32467;&#26500;&#26159;&#20998;&#26512;&#21644;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#25552;&#20986;&#20855;&#26377;&#26126;&#30830;&#20449;&#24687;&#32467;&#26500;&#34920;&#31034;&#30340;&#26032;&#22411;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00993v1 Announce Type: cross  Abstract: In a sequential decision-making problem, the information structure is the description of how events in the system occurring at different points in time affect each other. Classical models of reinforcement learning (e.g., MDPs, POMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular information structure, while more general models like predictive state representations do not explicitly model the information structure. By contrast, real-world sequential decision-making problems typically involve a complex and time-varying interdependence of system variables, requiring a rich and flexible representation of information structure.   In this paper, we argue for the perspective that explicit representation of information structures is an important component of analyzing and solving reinforcement learning problems. We propose novel reinforcement learning models with an explicit representation of information structure, capturing 
&lt;/p&gt;</description></item><item><title>AdAdaGrad&#21644;AdAdaGradNorm&#26159;&#19968;&#20010;&#33258;&#36866;&#24212;&#22686;&#21152;&#25209;&#22823;&#23567;&#30340;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#31574;&#30053;&#65292;&#35777;&#26126;AdaGradNorm&#20197;&#39640;&#27010;&#29575;&#22312;$O(1/K)$&#36895;&#24230;&#19979;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2402.11215</link><description>&lt;p&gt;
AdAdaGrad&#65306;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#30340;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
AdAdaGrad: Adaptive Batch Size Schemes for Adaptive Gradient Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11215
&lt;/p&gt;
&lt;p&gt;
AdAdaGrad&#21644;AdAdaGradNorm&#26159;&#19968;&#20010;&#33258;&#36866;&#24212;&#22686;&#21152;&#25209;&#22823;&#23567;&#30340;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#31574;&#30053;&#65292;&#35777;&#26126;AdaGradNorm&#20197;&#39640;&#27010;&#29575;&#22312;$O(1/K)$&#36895;&#24230;&#19979;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#20248;&#21270;&#22120;&#20013;&#25209;&#37327;&#22823;&#23567;&#30340;&#36873;&#25321;&#23545;&#27169;&#22411;&#35757;&#32451;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21464;&#21270;&#25209;&#22823;&#23567;&#30340;&#23454;&#36341;&#30456;&#23545;&#20854;&#20182;&#36229;&#21442;&#25968;&#36739;&#23569;&#25506;&#35752;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#33258;&#36866;&#24212;&#37319;&#26679;&#26041;&#27861;&#20013;&#23548;&#20986;&#30340;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#31574;&#30053;&#65292;&#20256;&#32479;&#19978;&#20165;&#24212;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#12290;&#32771;&#34385;&#21040;&#23398;&#20064;&#36895;&#29575;&#21644;&#25209;&#22823;&#23567;&#20043;&#38388;&#30340;&#26174;&#33879;&#30456;&#20114;&#20316;&#29992;&#65292;&#20197;&#21450;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#26222;&#21450;&#65292;&#25105;&#20204;&#24378;&#35843;&#22312;&#36825;&#20123;&#24773;&#22659;&#20013;&#38656;&#35201;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#31574;&#30053;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;AdAdaGrad&#21450;&#20854;&#26631;&#37327;&#21464;&#20307;AdAdaGradNorm&#65292;&#23427;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#22686;&#21152;&#25209;&#22823;&#23567;&#65292;&#21516;&#26102;&#20351;&#29992;AdaGrad&#21644;AdaGradNorm&#36827;&#34892;&#27169;&#22411;&#26356;&#26032;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;AdaGradNorm&#20197;&#39640;&#27010;&#29575;&#20197;$O(1/K)$&#30340;&#36895;&#24230;&#25910;&#25947;&#65292;&#29992;&#20110;&#25214;&#21040;&#20809;&#28369;&#38750;&#20984;&#20989;&#25968;&#30340;&#19968;&#38454;&#31283;&#23450;&#28857;&#22312;$K$&#27425;&#36845;&#20195;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11215v1 Announce Type: new  Abstract: The choice of batch sizes in stochastic gradient optimizers is critical for model training. However, the practice of varying batch sizes throughout the training process is less explored compared to other hyperparameters. We investigate adaptive batch size strategies derived from adaptive sampling methods, traditionally applied only in stochastic gradient descent. Given the significant interplay between learning rates and batch sizes, and considering the prevalence of adaptive gradient methods in deep learning, we emphasize the need for adaptive batch size strategies in these contexts. We introduce AdAdaGrad and its scalar variant AdAdaGradNorm, which incrementally increase batch sizes during training, while model updates are performed using AdaGrad and AdaGradNorm. We prove that AdaGradNorm converges with high probability at a rate of $\mathscr{O}(1/K)$ for finding a first-order stationary point of smooth nonconvex functions within $K$ i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SLIPS&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#21518;&#39564;&#25277;&#26679;&#23454;&#29616;&#38543;&#26426;&#23450;&#20301;&#65292;&#22635;&#34917;&#20102;&#20174;&#38750;&#26631;&#20934;&#21270;&#30446;&#26631;&#23494;&#24230;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#30340;&#31354;&#30333;&#12290;</title><link>https://arxiv.org/abs/2402.10758</link><description>&lt;p&gt;
&#36890;&#36807;&#36845;&#20195;&#21518;&#39564;&#25277;&#26679;&#23454;&#29616;&#38543;&#26426;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Stochastic Localization via Iterative Posterior Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SLIPS&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#21518;&#39564;&#25277;&#26679;&#23454;&#29616;&#38543;&#26426;&#23450;&#20301;&#65292;&#22635;&#34917;&#20102;&#20174;&#38750;&#26631;&#20934;&#21270;&#30446;&#26631;&#23494;&#24230;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#31435;&#22312;&#22522;&#20110;&#24471;&#20998;&#23398;&#20064;&#30340;&#22522;&#30784;&#19978;&#65292;&#36817;&#26399;&#23545;&#38543;&#26426;&#23450;&#20301;&#25216;&#26415;&#20135;&#29983;&#20102;&#26032;&#30340;&#20852;&#36259;&#12290;&#22312;&#36825;&#20123;&#27169;&#22411;&#20013;&#65292;&#20154;&#20204;&#36890;&#36807;&#38543;&#26426;&#36807;&#31243;&#65288;&#31216;&#20026;&#35266;&#27979;&#36807;&#31243;&#65289;&#20026;&#25968;&#25454;&#20998;&#24067;&#20013;&#30340;&#26679;&#26412;&#24341;&#20837;&#22122;&#22768;&#65292;&#24182;&#36880;&#28176;&#23398;&#20064;&#19982;&#35813;&#21160;&#21147;&#23398;&#20851;&#32852;&#30340;&#21435;&#22122;&#22120;&#12290;&#38500;&#20102;&#29305;&#23450;&#24212;&#29992;&#20043;&#22806;&#65292;&#23545;&#20110;&#20174;&#38750;&#26631;&#20934;&#21270;&#30446;&#26631;&#23494;&#24230;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#65292;&#23545;&#38543;&#26426;&#23450;&#20301;&#30340;&#20351;&#29992;&#23578;&#26410;&#24471;&#21040;&#24191;&#27867;&#25506;&#35752;&#12290;&#26412;&#39033;&#24037;&#20316;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#38543;&#26426;&#23450;&#20301;&#26694;&#26550;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#26126;&#30830;&#30340;&#35266;&#27979;&#36807;&#31243;&#65292;&#19982;&#28789;&#27963;&#30340;&#21435;&#22122;&#26102;&#38388;&#34920;&#30456;&#20851;&#32852;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#23436;&#25972;&#30340;&#26041;&#27861;&#35770;&#65292;&#21363;&#8220;&#36890;&#36807;&#36845;&#20195;&#21518;&#39564;&#25277;&#26679;&#23454;&#29616;&#38543;&#26426;&#23450;&#20301;&#8221;&#65288;SLIPS&#65289;&#65292;&#20197;&#33719;&#24471;&#35813;&#21160;&#21147;&#23398;&#30340;&#36817;&#20284;&#26679;&#26412;&#65292;&#24182;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#26679;&#26412;&#26469;&#33258;&#30446;&#26631;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#26696;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10758v1 Announce Type: cross  Abstract: Building upon score-based learning, new interest in stochastic localization techniques has recently emerged. In these models, one seeks to noise a sample from the data distribution through a stochastic process, called observation process, and progressively learns a denoiser associated to this dynamics. Apart from specific applications, the use of stochastic localization for the problem of sampling from an unnormalized target density has not been explored extensively. This work contributes to fill this gap. We consider a general stochastic localization framework and introduce an explicit class of observation processes, associated with flexible denoising schedules. We provide a complete methodology, $\textit{Stochastic Localization via Iterative Posterior Sampling}$ (SLIPS), to obtain approximate samples of this dynamics, and as a by-product, samples from the target distribution. Our scheme is based on a Markov chain Monte Carlo estimati
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21512;&#24182;&#20351;&#29992;&#19981;&#21516;&#36807;&#28388;&#22120;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#39034;&#24207;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09698</link><description>&lt;p&gt;
&#21512;&#24182;&#19981;&#21516;&#36807;&#28388;&#22120;&#20013;&#30340;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
Combining Evidence Across Filtrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09698
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21512;&#24182;&#20351;&#29992;&#19981;&#21516;&#36807;&#28388;&#22120;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#39034;&#24207;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20219;&#20309;&#26102;&#21051;&#26377;&#25928;&#30340;&#39034;&#24207;&#25512;&#29702;&#20013;&#65292;&#24050;&#30693;&#20219;&#20309;&#21487;&#25509;&#21463;&#30340;&#25512;&#29702;&#26041;&#27861;&#24517;&#39035;&#22522;&#20110;&#27979;&#35797;&#38789;&#21644;&#23427;&#20204;&#30340;&#32452;&#21512;&#24191;&#20041;&#21270;&#65292;&#31216;&#20026;e&#36827;&#31243;&#65292;&#23427;&#20204;&#26159;&#38750;&#36127;&#36827;&#31243;&#65292;&#20854;&#22312;&#20219;&#20309;&#20219;&#24847;&#20572;&#26102;&#30340;&#26399;&#26395;&#19978;&#30028;&#19981;&#36229;&#36807;&#19968;&#12290;e&#36827;&#31243;&#37327;&#21270;&#20102;&#38024;&#23545;&#22797;&#21512;&#38646;&#20551;&#35774;&#30340;&#19968;&#31995;&#21015;&#32467;&#26524;&#30340;&#32047;&#31215;&#35777;&#25454;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#19981;&#21516;&#20449;&#24687;&#38598;&#65288;&#21363;&#36807;&#28388;&#22120;&#65289;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#21512;&#24182;&#26041;&#27861;&#65292;&#38024;&#23545;&#19968;&#20010;&#38646;&#20551;&#35774;&#12290;&#23613;&#31649;&#22312;&#30456;&#21516;&#36807;&#28388;&#22120;&#19978;&#26500;&#24314;&#30340;e&#36827;&#31243;&#21487;&#20197;&#36731;&#26494;&#22320;&#21512;&#24182;&#65288;&#20363;&#22914;&#65292;&#36890;&#36807;&#24179;&#22343;&#65289;&#65292;&#20294;&#22312;&#19981;&#21516;&#36807;&#28388;&#22120;&#19978;&#26500;&#24314;&#30340;e&#36827;&#31243;&#19981;&#33021;&#37027;&#20040;&#23481;&#26131;&#22320;&#21512;&#24182;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#36739;&#31895;&#30340;&#36807;&#28388;&#22120;&#20013;&#30340;&#26377;&#25928;&#24615;&#19981;&#33021;&#36716;&#25442;&#20026;&#22312;&#26356;&#32454;&#30340;&#36807;&#28388;&#22120;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#25991;&#29486;&#20013;&#19977;&#20010;&#20855;&#20307;&#20363;&#23376;&#65306;&#21487;&#20132;&#25442;&#24615;&#27979;&#35797;&#65292;&#29420;&#31435;&#24615;&#27979;&#35797;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09698v1 Announce Type: cross  Abstract: In anytime-valid sequential inference, it is known that any admissible inference procedure must be based on test martingales and their composite generalization, called e-processes, which are nonnegative processes whose expectation at any arbitrary stopping time is upper-bounded by one. An e-process quantifies the accumulated evidence against a composite null hypothesis over a sequence of outcomes. This paper studies methods for combining e-processes that are computed using different information sets, i.e., filtrations, for a null hypothesis. Even though e-processes constructed on the same filtration can be combined effortlessly (e.g., by averaging), e-processes constructed on different filtrations cannot be combined as easily because their validity in a coarser filtration does not translate to validity in a finer filtration. We discuss three concrete examples of such e-processes in the literature: exchangeability tests, independence te
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;1-WL&#31639;&#27861;&#22312;&#22270;&#21516;&#26500;&#38382;&#39064;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#27867;&#21270;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#22686;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#23545;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#24182;&#19981;&#24635;&#26159;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24341;&#20837;&#23376;&#22270;&#20449;&#24687;&#21644;&#32463;&#20856;&#30340;&#36793;&#32536;&#29702;&#35770;&#65292;&#25506;&#32034;&#20102;&#26356;&#39640;&#34920;&#36798;&#21147;&#19982;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26465;&#20214;&#12290;&#26799;&#24230;&#27969;&#20063;&#34987;&#35777;&#26126;&#21487;&#20197;&#20419;&#36827;&#27169;&#22411;&#23398;&#20064;&#26356;&#20016;&#23500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07568</link><description>&lt;p&gt;
Weisfeiler-Leman&#22312;&#36793;&#32536;&#26465;&#20214;&#19979;&#30340;&#26356;&#39640;&#34920;&#36798;&#21147;&#30340;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
Weisfeiler-Leman at the margin: When more expressivity matters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07568
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;1-WL&#31639;&#27861;&#22312;&#22270;&#21516;&#26500;&#38382;&#39064;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#27867;&#21270;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#22686;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#23545;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#24182;&#19981;&#24635;&#26159;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24341;&#20837;&#23376;&#22270;&#20449;&#24687;&#21644;&#32463;&#20856;&#30340;&#36793;&#32536;&#29702;&#35770;&#65292;&#25506;&#32034;&#20102;&#26356;&#39640;&#34920;&#36798;&#21147;&#19982;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26465;&#20214;&#12290;&#26799;&#24230;&#27969;&#20063;&#34987;&#35777;&#26126;&#21487;&#20197;&#20419;&#36827;&#27169;&#22411;&#23398;&#20064;&#26356;&#20016;&#23500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Weisfeiler-Leman&#31639;&#27861;&#65288;1-WL&#65289;&#26159;&#19968;&#20010;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#29992;&#20110;&#22270;&#21516;&#26500;&#38382;&#39064;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#12290;&#26368;&#36817;&#65292;&#35813;&#31639;&#27861;&#22312;&#29702;&#35299;&#20256;&#36882;&#28040;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#20197;&#21450;&#20316;&#20026;&#22270;&#26680;&#20989;&#25968;&#26041;&#38754;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;1-WL&#22312;&#21306;&#20998;&#38750;&#21516;&#26500;&#22270;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#26356;&#20855;&#34920;&#36798;&#21147;&#30340;MPNN&#21644;&#26680;&#26550;&#26500;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#22686;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#25913;&#36827;&#30340;&#27867;&#21270;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#36890;&#36807;&#22270;&#21516;&#26500;&#26469;&#35266;&#23519;&#26102;&#65292;&#26550;&#26500;&#30340;&#34920;&#36798;&#33021;&#21147;&#22312;&#35299;&#37322;&#20854;&#27867;&#21270;&#24615;&#33021;&#26041;&#38754;&#20855;&#26377;&#26377;&#38480;&#30340;&#27934;&#23519;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30528;&#37325;&#22312;1-WL&#21644;MPNN&#20013;&#24341;&#20837;&#23376;&#22270;&#20449;&#24687;&#65292;&#24182;&#36816;&#29992;&#32463;&#20856;&#30340;&#36793;&#32536;&#29702;&#35770;&#26469;&#30740;&#31350;&#26550;&#26500;&#30340;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#19982;&#25913;&#36827;&#30340;&#27867;&#21270;&#24615;&#33021;&#20043;&#38388;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#26799;&#24230;&#27969;&#22914;&#20309;&#25512;&#21160;&#27169;&#22411;&#23398;&#20064;&#26356;&#20016;&#23500;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Weisfeiler-Leman algorithm ($1$-WL) is a well-studied heuristic for the graph isomorphism problem. Recently, the algorithm has played a prominent role in understanding the expressive power of message-passing graph neural networks (MPNNs) and being effective as a graph kernel. Despite its success, $1$-WL faces challenges in distinguishing non-isomorphic graphs, leading to the development of more expressive MPNN and kernel architectures. However, the relationship between enhanced expressivity and improved generalization performance remains unclear. Here, we show that an architecture's expressivity offers limited insights into its generalization performance when viewed through graph isomorphism. Moreover, we focus on augmenting $1$-WL and MPNNs with subgraph information and employ classical margin theory to investigate the conditions under which an architecture's increased expressivity aligns with improved generalization performance. In addition, we show that gradient flow pushes the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#32467;&#26500;&#20887;&#20313;&#30340;&#20302;&#31209;&#36924;&#36817;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36924;&#36817;&#20887;&#20313;&#32452;&#20214;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#36807;&#37327;&#39118;&#38505;&#26469;&#25903;&#25345;&#29702;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.06884</link><description>&lt;p&gt;
&#32467;&#26500;&#20887;&#20313;&#30340;&#20302;&#31209;&#36924;&#36817;&#29992;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Low-Rank Approximation of Structural Redundancy for Self-Supervised Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#32467;&#26500;&#20887;&#20313;&#30340;&#20302;&#31209;&#36924;&#36817;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36924;&#36817;&#20887;&#20313;&#32452;&#20214;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#36807;&#37327;&#39118;&#38505;&#26469;&#25903;&#25345;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#37325;&#26500;&#22411;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#65292;&#20197;&#25581;&#31034;&#20854;&#26377;&#25928;&#24615;&#12290;&#22312;&#25317;&#26377;&#26080;&#38480;&#37327;&#30340;&#26631;&#35760;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23436;&#32654;&#32447;&#24615;&#36924;&#36817;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12290;&#35813;&#26465;&#20214;&#25581;&#31034;&#20102;&#19968;&#20010;&#20445;&#30041;&#26631;&#31614;&#31867;&#21035;Y&#30340;&#28385;&#31209;&#32452;&#20214;&#65292;&#20197;&#21450;&#19968;&#20010;&#20887;&#20313;&#32452;&#20214;&#12290;&#21463;&#21040;&#35813;&#26465;&#20214;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20302;&#31209;&#20998;&#35299;&#36924;&#36817;&#20887;&#20313;&#32452;&#20214;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#30001;&#20998;&#35299;&#31209;s&#21442;&#25968;&#21270;&#30340;&#26032;&#37327;$\epsilon_s$&#26469;&#34913;&#37327;&#36924;&#36817;&#36136;&#37327;&#12290;&#25105;&#20204;&#23558;$\epsilon_s$&#25972;&#21512;&#21040;&#32447;&#24615;&#22238;&#24402;&#21644;&#23725;&#22238;&#24402;&#35774;&#32622;&#19979;&#30340;&#36807;&#37327;&#39118;&#38505;&#20998;&#26512;&#20013;&#65292;&#21518;&#19968;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#29992;&#20110;&#22788;&#29702;&#23398;&#20064;&#29305;&#24449;&#30340;&#32500;&#24230;&#36828;&#22823;&#20110;&#19979;&#28216;&#20219;&#21153;&#30340;&#26631;&#35760;&#26679;&#26412;&#25968;n&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19977;&#20010;&#31616;&#21270;&#23454;&#39564;&#65292;&#20197;&#27604;&#36739;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#21644;&#30417;&#30563;&#23398;&#20064;&#65292;&#20197;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the data-generating mechanism for reconstructive SSL to shed light on its effectiveness. With an infinite amount of labeled samples, we provide a sufficient and necessary condition for perfect linear approximation. The condition reveals a full-rank component that preserves the label classes of Y, along with a redundant component. Motivated by the condition, we propose to approximate the redundant component by a low-rank factorization and measure the approximation quality by introducing a new quantity $\epsilon_s$, parameterized by the rank of factorization s. We incorporate $\epsilon_s$ into the excess risk analysis under both linear regression and ridge regression settings, where the latter regularization approach is to handle scenarios when the dimension of the learned features is much larger than the number of labeled samples n for downstream tasks. We design three stylized experiments to compare SSL with supervised learning under different settings to support our theoretic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#20542;&#21521;&#20110;&#23545;&#31216;&#25490;&#21015;&#20989;&#25968;&#65292;&#23545;&#31216;&#32676;&#30340;&#34920;&#31034;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#20998;&#26512;&#39044;&#27979;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21270;&#27169;&#22411;&#26469;&#35299;&#20915;&#23398;&#20064;&#26354;&#32447;&#21644;&#32593;&#32476;&#36755;&#20986;&#65292;&#24182;&#22312;&#24120;&#35265;&#35774;&#32622;&#20013;&#24471;&#20986;&#23398;&#20064;&#33021;&#21147;&#30340;&#32039;&#23494;&#36793;&#30028;&#65292;&#26368;&#21518;&#36824;&#35777;&#26126;&#20102;WikiText&#25968;&#25454;&#38598;&#20855;&#26377;&#25490;&#21015;&#23545;&#31216;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05173</link><description>&lt;p&gt;
&#25506;&#32034;Transformer&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;: &#19968;&#20010;&#26469;&#33258;&#26080;&#31351;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Inductive Bias in Transformers: A View From Infinity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#20542;&#21521;&#20110;&#23545;&#31216;&#25490;&#21015;&#20989;&#25968;&#65292;&#23545;&#31216;&#32676;&#30340;&#34920;&#31034;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#20998;&#26512;&#39044;&#27979;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21270;&#27169;&#22411;&#26469;&#35299;&#20915;&#23398;&#20064;&#26354;&#32447;&#21644;&#32593;&#32476;&#36755;&#20986;&#65292;&#24182;&#22312;&#24120;&#35265;&#35774;&#32622;&#20013;&#24471;&#20986;&#23398;&#20064;&#33021;&#21147;&#30340;&#32039;&#23494;&#36793;&#30028;&#65292;&#26368;&#21518;&#36824;&#35777;&#26126;&#20102;WikiText&#25968;&#25454;&#38598;&#20855;&#26377;&#25490;&#21015;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#22312;&#26080;&#31351;&#30340;&#36807;&#21442;&#25968;&#21270;&#39640;&#26031;&#36807;&#31243;&#26497;&#38480;&#20013;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#25351;&#20986;Transformer&#27169;&#22411;&#22312;&#24207;&#21015;&#31354;&#38388;&#20013;&#26356;&#20542;&#21521;&#20110;&#23545;&#31216;&#25490;&#21015;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#31216;&#32676;&#30340;&#34920;&#31034;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#22312;&#25968;&#25454;&#38598;&#23545;token&#20043;&#38388;&#30340;&#25490;&#21015;&#20855;&#26377;&#23545;&#31216;&#24615;&#26102;&#32473;&#20986;&#23450;&#37327;&#30340;&#20998;&#26512;&#39044;&#27979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21270;&#30340;Transformer&#27169;&#22411;&#65292;&#24182;&#22312;&#26497;&#38480;&#26465;&#20214;&#19979;&#27714;&#35299;&#27169;&#22411;&#65292;&#21253;&#25324;&#23545;&#23398;&#20064;&#26354;&#32447;&#21644;&#32593;&#32476;&#36755;&#20986;&#30340;&#20934;&#30830;&#39044;&#27979;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#24120;&#35265;&#30340;&#35774;&#32622;&#20013;&#65292;&#21487;&#20197;&#25512;&#23548;&#20986;&#23398;&#20064;&#33021;&#21147;&#30340;&#32039;&#23494;&#36793;&#30028;&#65292;&#20197;&#19978;&#19979;&#25991;&#38271;&#24230;&#20316;&#20026;&#20989;&#25968;&#30340;&#32553;&#25918;&#23450;&#24459;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;WikiText&#25968;&#25454;&#38598;&#30830;&#23454;&#20855;&#26377;&#19968;&#23450;&#31243;&#24230;&#30340;&#25490;&#21015;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study inductive bias in Transformers in the infinitely over-parameterized Gaussian process limit and argue transformers tend to be biased towards more permutation symmetric functions in sequence space. We show that the representation theory of the symmetric group can be used to give quantitative analytical predictions when the dataset is symmetric to permutations between tokens. We present a simplified transformer block and solve the model at the limit, including accurate predictions for the learning curves and network outputs. We show that in common setups, one can derive tight bounds in the form of a scaling law for the learnability as a function of the context length. Finally, we argue WikiText dataset, does indeed possess a degree of permutation symmetry.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;&#30340;&#26041;&#27861;&#21487;&#20197;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#65292;&#20174;&#32780;&#22312;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#26041;&#38754;&#21462;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02644</link><description>&lt;p&gt;
&#36890;&#36807;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#30340;&#26041;&#27861;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Variational DAG Estimation via State Augmentation With Stochastic Permutations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02644
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;&#30340;&#26041;&#27861;&#21487;&#20197;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#65292;&#20174;&#32780;&#22312;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#26041;&#38754;&#21462;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#65292;&#21363;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#65292;&#26159;&#19968;&#20010;&#22312;&#32479;&#35745;&#21644;&#35745;&#31639;&#19978;&#37117;&#24456;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#22312;&#22240;&#26524;&#21457;&#29616;&#31561;&#39046;&#22495;&#26377;&#30528;&#37325;&#35201;&#24212;&#29992;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#22312;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#26041;&#38754;&#26159;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#22788;&#29702;&#20247;&#25152;&#21608;&#30693;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#12290;&#20174;&#27010;&#29575;&#25512;&#26029;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#20027;&#35201;&#30340;&#25361;&#25112;&#26159;&#65288;i&#65289;&#34920;&#31034;&#28385;&#36275;DAG&#32422;&#26463;&#30340;&#22270;&#30340;&#20998;&#24067;&#21644;&#65288;ii&#65289;&#20272;&#35745;&#24213;&#23618;&#32452;&#21512;&#31354;&#38388;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;DAG&#21644;&#25490;&#21015;&#30340;&#25193;&#23637;&#31354;&#38388;&#19978;&#26500;&#24314;&#32852;&#21512;&#20998;&#24067;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#21518;&#39564;&#20272;&#35745;&#65292;&#22312;&#20854;&#20013;&#21033;&#29992;&#20102;&#31163;&#25955;&#20998;&#24067;&#30340;&#36830;&#32493;&#26494;&#24347;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#33021;&#22815;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the structure of a Bayesian network, in the form of a directed acyclic graph (DAG), from observational data is a statistically and computationally hard problem with essential applications in areas such as causal discovery. Bayesian approaches are a promising direction for solving this task, as they allow for uncertainty quantification and deal with well-known identifiability issues. From a probabilistic inference perspective, the main challenges are (i) representing distributions over graphs that satisfy the DAG constraint and (ii) estimating a posterior over the underlying combinatorial space. We propose an approach that addresses these challenges by formulating a joint distribution on an augmented space of DAGs and permutations. We carry out posterior estimation via variational inference, where we exploit continuous relaxations of discrete distributions. We show that our approach can outperform competitive Bayesian and non-Bayesian benchmarks on a range of synthetic and re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#27979;&#35797;&#26102;&#24207;&#25968;&#25454;&#20043;&#38388;&#29420;&#31435;&#24615;&#30340;&#26102;&#24207;&#20381;&#36182;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#33021;&#22815;&#20272;&#35745;&#26368;&#20339;&#20381;&#36182;&#28382;&#21518;&#12290;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#22312;&#27979;&#35797;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#26102;&#28176;&#36817;&#26377;&#25928;&#21644;&#26222;&#36941;&#19968;&#33268;&#65292;&#24182;&#19988;&#19982;&#22810;&#31181;&#20381;&#36182;&#24230;&#37327;&#26041;&#27861;&#20860;&#23481;&#12290;</title><link>https://arxiv.org/abs/1908.06486</link><description>&lt;p&gt;
&#26102;&#24207;&#25968;&#25454;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Independence Testing for Temporal Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1908.06486
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#27979;&#35797;&#26102;&#24207;&#25968;&#25454;&#20043;&#38388;&#29420;&#31435;&#24615;&#30340;&#26102;&#24207;&#20381;&#36182;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#33021;&#22815;&#20272;&#35745;&#26368;&#20339;&#20381;&#36182;&#28382;&#21518;&#12290;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#22312;&#27979;&#35797;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#26102;&#28176;&#36817;&#26377;&#25928;&#21644;&#26222;&#36941;&#19968;&#33268;&#65292;&#24182;&#19988;&#19982;&#22810;&#31181;&#20381;&#36182;&#24230;&#37327;&#26041;&#27861;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#24207;&#25968;&#25454;&#22312;&#29616;&#20195;&#25968;&#25454;&#31185;&#23398;&#20013;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#21028;&#26029;&#20004;&#20010;&#26102;&#38388;&#24207;&#21015;&#26159;&#21542;&#30456;&#20851;&#12290;&#29616;&#26377;&#26041;&#27861;&#24120;&#24120;&#23384;&#22312;&#38480;&#21046;&#65292;&#22914;&#20381;&#36182;&#21442;&#25968;&#20551;&#35774;&#12289;&#20165;&#26816;&#27979;&#32447;&#24615;&#20851;&#32852;&#12289;&#38656;&#35201;&#22810;&#20010;&#27979;&#35797;&#21644;&#20462;&#27491;&#31561;&#12290;&#34429;&#28982;&#26368;&#36817;&#25552;&#20986;&#20102;&#35768;&#22810;&#38750;&#21442;&#25968;&#21644;&#26222;&#36941;&#19968;&#33268;&#30340;&#20381;&#36182;&#24230;&#37327;&#26041;&#27861;&#65292;&#20294;&#30452;&#25509;&#24212;&#29992;&#20110;&#26102;&#24207;&#25968;&#25454;&#21487;&#33021;&#23548;&#33268;p&#20540;&#33192;&#32960;&#21644;&#26080;&#25928;&#30340;&#26816;&#39564;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#22522;&#20110;&#22359;&#32622;&#25442;&#30340;&#26102;&#24207;&#20381;&#36182;&#32479;&#35745;&#37327;&#26469;&#27979;&#35797;&#26102;&#24207;&#25968;&#25454;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#12290;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#27979;&#35797;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#26102;&#26159;&#28176;&#36817;&#26377;&#25928;&#21644;&#26222;&#36941;&#19968;&#33268;&#30340;&#65292;&#24182;&#19988;&#33021;&#22815;&#20272;&#35745;&#26368;&#22823;&#21270;&#20381;&#36182;&#30340;&#26368;&#20339;&#20381;&#36182;&#28382;&#21518;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#19982;&#20016;&#23500;&#30340;&#36317;&#31163;&#21644;&#26680;&#24515;&#20381;&#36182;&#24230;&#37327;&#26041;&#27861;&#20860;&#23481;&#65292;&#28040;&#38500;&#20102;
&lt;/p&gt;
&lt;p&gt;
Temporal data are increasingly prevalent in modern data science. A fundamental question is whether two time-series are related or not. Existing approaches often have limitations, such as relying on parametric assumptions, detecting only linear associations, and requiring multiple tests and corrections. While many non-parametric and universally consistent dependence measures have recently been proposed, directly applying them to temporal data can inflate the p-value and result in invalid test. To address these challenges, this paper introduces the temporal dependence statistic with block permutation to test independence between temporal data. Under proper assumptions, the proposed procedure is asymptotically valid and universally consistent for testing independence between stationary time-series, and capable of estimating the optimal dependence lag that maximizes the dependence. Notably, it is compatible with a rich family of distance and kernel based dependence measures, eliminates the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;</title><link>http://arxiv.org/abs/2310.16705</link><description>&lt;p&gt;
&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#27969;&#22312;&#21464;&#20998;&#25512;&#26029;&#30340;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gradient Flow over Variational Parameter Space for Variational Inference. (arXiv:2310.16705v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#21464;&#20998;&#21442;&#25968;&#34987;&#35843;&#25972;&#20197;&#20351;&#21464;&#20998;&#20998;&#24067;&#19982;&#30495;&#23454;&#21518;&#39564;&#23613;&#21487;&#33021;&#25509;&#36817;&#12290;&#21487;&#20197;&#36890;&#36807;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#26222;&#36890;&#26799;&#24230;&#19979;&#38477;&#25110;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#26469;&#35299;&#20915;&#20248;&#21270;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#19968;&#20010;&#8220;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#8221;&#20013;&#23450;&#20041;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#20248;&#21270;&#25216;&#26415;&#65292;&#21363;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#21644;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#65292;&#21487;&#20197;&#37325;&#26032;&#35299;&#37322;&#20026;&#25152;&#25552;&#20986;&#30340;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#30340;&#29305;&#23450;&#23454;&#20363;&#12290;&#20026;&#20102;&#25552;&#39640;&#20248;&#21270;&#25928;&#29575;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#23454;&#29992;&#30340;&#26041;&#27861;&#26469;&#25968;&#20540;&#27714;&#35299;&#31163;&#25955;&#26799;&#24230;&#27969;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference (VI) can be cast as an optimization problem in which the variational parameters are tuned to closely align a variational distribution with the true posterior. The optimization task can be approached through vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient VI. In this work, we reframe VI as the optimization of an objective that concerns probability distributions defined over a \textit{variational parameter space}. Subsequently, we propose Wasserstein gradient descent for tackling this optimization problem. Notably, the optimization techniques, namely black-box VI and natural-gradient VI, can be reinterpreted as specific instances of the proposed Wasserstein gradient descent. To enhance the efficiency of optimization, we develop practical methods for numerically solving the discrete gradient flows. We validate the effectiveness of the proposed methods through empirical experiments on a synthetic dataset, supplemented by theore
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#65292;&#36890;&#36807;&#28040;&#38500;&#20808;&#39564;&#30693;&#35782;&#38656;&#27714;&#21644;&#25511;&#21046;&#20998;&#24067;&#28418;&#31227;&#65292;&#35813;&#31639;&#27861;&#22312;&#36951;&#25022;&#30028;&#38480;&#26041;&#38754;&#20855;&#26377;&#31361;&#20986;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2308.10675</link><description>&lt;p&gt;
&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#20013;&#30340;&#26368;&#20339;&#26041;&#26696;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback. (arXiv:2308.10675v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10675
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#65292;&#36890;&#36807;&#28040;&#38500;&#20808;&#39564;&#30693;&#35782;&#38656;&#27714;&#21644;&#25511;&#21046;&#20998;&#24067;&#28418;&#31227;&#65292;&#35813;&#31639;&#27861;&#22312;&#36951;&#25022;&#30028;&#38480;&#26041;&#38754;&#20855;&#26377;&#31361;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#21487;&#21464;&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#22823;&#24310;&#36831;$d_{\mathrm{max}}$&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;&#38656;&#27714;&#65292;&#24182;&#22312;&#20004;&#20010;&#24773;&#26223;&#19979;&#25552;&#20379;&#26356;&#32039;&#23494;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#25913;&#36827;&#20102;Masoudian&#31561;&#20154;[2022]&#30340;&#20808;&#21069;&#24037;&#20316;&#12290;&#31639;&#27861;&#21644;&#23427;&#30340;&#36951;&#25022;&#30028;&#38480;&#26159;&#22522;&#20110;&#26410;&#35299;&#20915;&#30340;&#35266;&#27979;&#27425;&#25968;&#65288;&#22312;&#34892;&#21160;&#26102;&#38388;&#35266;&#23519;&#21040;&#30340;&#25968;&#37327;&#65289;&#32780;&#19981;&#26159;&#24310;&#36831;&#25110;&#26368;&#22823;&#24310;&#36831;&#65288;&#21482;&#26377;&#24403;&#21453;&#39304;&#21040;&#36798;&#26102;&#25165;&#33021;&#35266;&#23519;&#21040;&#30340;&#25968;&#37327;&#65289;&#12290;&#19968;&#20010;&#20027;&#35201;&#30340;&#36129;&#29486;&#26159;&#22522;&#20110;&#26377;&#20559;&#25439;&#22833;&#20272;&#35745;&#22120;&#21644;&#36339;&#36807;&#20855;&#26377;&#36807;&#22823;&#24310;&#36831;&#35266;&#27979;&#30340;&#26032;&#22411;&#20998;&#24067;&#28418;&#31227;&#25511;&#21046;&#12290;&#21478;&#19968;&#20010;&#20027;&#35201;&#30340;&#36129;&#29486;&#26159;&#35777;&#26126;&#20102;&#20855;&#26377;&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#26159;&#30001;&#22312;&#36339;&#36807;&#20855;&#26377;&#36807;&#22823;&#24310;&#36831;&#35266;&#27979;&#21518;&#30340;&#32047;&#31215;&#26410;&#35299;&#20915;&#35266;&#27979;&#27425;&#25968;&#26469;&#25551;&#36848;&#30340;&#65292;&#32780;&#19981;&#26159;&#24310;&#36831;&#25110;&#26368;&#22823;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new best-of-both-worlds algorithm for bandits with variably delayed feedback. The algorithm improves on prior work by Masoudian et al. [2022] by eliminating the need in prior knowledge of the maximal delay $d_{\mathrm{max}}$ and providing tighter regret bounds in both regimes. The algorithm and its regret bounds are based on counts of outstanding observations (a quantity that is observed at action time) rather than delays or the maximal delay (quantities that are only observed when feedback arrives). One major contribution is a novel control of distribution drift, which is based on biased loss estimators and skipping of observations with excessively large delays. Another major contribution is demonstrating that the complexity of best-of-both-worlds bandits with delayed feedback is characterized by the cumulative count of outstanding observations after skipping of observations with excessively large delays, rather than the delays or the maximal delay.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#22270;&#33258;&#21516;&#24577;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#65292;&#25214;&#21040;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;&#23618;&#20989;&#25968;&#20043;&#38388;&#30340;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#12290;</title><link>http://arxiv.org/abs/2307.07810</link><description>&lt;p&gt;
&#22270;&#33258;&#21516;&#24577;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Graph Automorphism Group Equivariant Neural Networks. (arXiv:2307.07810v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07810
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#22270;&#33258;&#21516;&#24577;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#65292;&#25214;&#21040;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;&#23618;&#20989;&#25968;&#20043;&#38388;&#30340;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20219;&#20309;&#20855;&#26377;n&#20010;&#39030;&#28857;&#21644;&#20854;&#33258;&#21516;&#24577;&#32676;Aut(G)&#30340;&#22270;G&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;&#21487;&#33021;&#30340;Aut(G)-&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#65292;&#20854;&#23618;&#26159;n&#32500;&#23454;&#25968;&#24352;&#37327;&#30340;&#26576;&#20123;&#24352;&#37327;&#24130;&#27425;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22312;n&#32500;&#23454;&#25968;&#31354;&#38388;&#30340;&#26631;&#20934;&#22522;&#19979;&#25214;&#21040;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;Aut(G)-&#31561;&#21464;&#23618;&#20989;&#25968;&#20043;&#38388;&#30340;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
For any graph $G$ having $n$ vertices and its automorphism group $\textrm{Aut}(G)$, we provide a full characterisation of all of the possible $\textrm{Aut}(G)$-equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. In particular, we find a spanning set of matrices for the learnable, linear, $\textrm{Aut}(G)$-equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$.
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#20855;&#26377;&#29616;&#23454;&#20551;&#35774;&#30340;&#25968;&#25454;&#38598;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#30830;&#23450;&#22240;&#26524;&#26041;&#21521;&#21464;&#25104;&#20102;&#19968;&#20010;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20351;&#29992;&#23454;&#38469;&#25968;&#25454;&#38598;&#39564;&#35777;&#20102;&#26412;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02931</link><description>&lt;p&gt;
&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery using Bayesian Model Selection. (arXiv:2306.02931v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02931
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20855;&#26377;&#29616;&#23454;&#20551;&#35774;&#30340;&#25968;&#25454;&#38598;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#30830;&#23450;&#22240;&#26524;&#26041;&#21521;&#21464;&#25104;&#20102;&#19968;&#20010;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20351;&#29992;&#23454;&#38469;&#25968;&#25454;&#38598;&#39564;&#35777;&#20102;&#26412;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21482;&#26377;&#20004;&#20010;&#21464;&#37327;&#30340;&#35266;&#27979;&#25968;&#25454;&#19988;&#27809;&#26377;&#20854;&#20182;&#20551;&#35774;&#65292;&#26080;&#27861;&#25512;&#26029;&#21738;&#20010;&#21464;&#37327;&#26159;&#24341;&#36215;&#21478;&#19968;&#20010;&#21464;&#37327;&#30340;&#21407;&#22240;&#12290;&#22823;&#37096;&#20998;&#22240;&#26524;&#25991;&#29486;&#32858;&#28966;&#20110;&#38024;&#23545;&#24378;&#20551;&#35774;&#30340;&#25968;&#25454;&#38598;(&#22914;&#21152;&#24615;&#22122;&#22768;&#25110;&#21442;&#25968;&#35745;&#25968;&#38480;&#21046;)&#20445;&#35777;&#22240;&#26524;&#26041;&#21521;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;&#28982;&#32780;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#34987;&#27979;&#35797;&#20110;&#36829;&#21453;&#20551;&#35774;&#30340;&#29616;&#23454;&#25968;&#25454;&#38598;&#19978;&#12290;&#26412;&#25991;&#22312;&#27492;&#22522;&#30784;&#19978;&#25552;&#20986;&#22914;&#20309;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#20869;&#20351;&#29992;&#22240;&#26524;&#20551;&#35774;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#21046;&#23450;&#20855;&#26377;&#29616;&#23454;&#20551;&#35774;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#32534;&#30721;&#29420;&#31435;&#30340;&#22240;&#26524;&#26426;&#21046;&#65292;&#23548;&#33268;&#22240;&#26524;&#26041;&#21521;&#20043;&#38388;&#30340;&#38750;&#23545;&#31216;&#24615;&#12290;&#22240;&#27492;&#65292;&#30830;&#23450;&#22240;&#26524;&#26041;&#21521;&#25104;&#20026;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20026;&#20309;&#22312;&#24050;&#30693;&#21487;&#35782;&#21035;&#30340;&#24773;&#20917;&#21644;&#28789;&#27963;&#30340;&#27169;&#22411;&#31867;&#19978;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
With only observational data on two variables, and without other assumptions, it is not possible to infer which one causes the other. Much of the causal literature has focused on guaranteeing identifiability of causal direction in statistical models for datasets where strong assumptions hold, such as additive noise or restrictions on parameter count. These methods are then subsequently tested on realistic datasets, most of which violate their assumptions. Building on previous attempts, we show how to use causal assumptions within the Bayesian framework. This allows us to specify models with realistic assumptions, while also encoding independent causal mechanisms, leading to an asymmetry between the causal directions. Identifying causal direction then becomes a Bayesian model selection problem. We analyse why Bayesian model selection works for known identifiable cases and flexible model classes, while also providing correctness guarantees about its behaviour. To demonstrate our approach
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31181;&#21487;&#33021;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;</title><link>http://arxiv.org/abs/2305.18728</link><description>&lt;p&gt;
&#25554;&#20214;&#21270;&#34920;&#29616;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Plug-in Performative Optimization. (arXiv:2305.18728v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18728
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31181;&#21487;&#33021;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#39044;&#27979;&#20855;&#26377;&#34920;&#29616;&#24615;&#26102;&#65292;&#36873;&#25321;&#21738;&#20010;&#39044;&#27979;&#22120;&#37096;&#32626;&#23558;&#24433;&#21709;&#26410;&#26469;&#35266;&#27979;&#30340;&#20998;&#24067;&#12290;&#22312;&#34920;&#29616;&#24615;&#23398;&#20064;&#20013;&#65292;&#24635;&#20307;&#30446;&#26631;&#26159;&#25214;&#21040;&#20855;&#26377;&#20302;&#8220;&#34920;&#29616;&#24615;&#39118;&#38505;&#8221;&#30340;&#39044;&#27979;&#22120;&#65292;&#21363;&#22312;&#20854;&#24341;&#23548;&#30340;&#20998;&#24067;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#26368;&#20248;&#21270;&#34920;&#29616;&#24615;&#39118;&#38505;&#30340;&#19968;&#31995;&#21015;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#36172;&#24466;&#31639;&#27861;&#21644;&#20854;&#20182;&#26080;&#23548;&#25968;&#26041;&#27861;&#65292;&#22312;&#34920;&#29616;&#24615;&#21453;&#39304;&#20013;&#19981;&#30693;&#36947;&#20219;&#20309;&#32467;&#26500;&#65292;&#23548;&#33268;&#25910;&#25947;&#36895;&#24230;&#26497;&#24930;&#12290;&#34917;&#20805;&#30340;&#19968;&#31995;&#21015;&#35299;&#20915;&#26041;&#26696;&#21033;&#29992;&#21453;&#39304;&#20013;&#30340;&#26174;&#24335;&#8220;&#27169;&#22411;&#8221;&#65292;&#20363;&#22914;&#25112;&#30053;&#20998;&#31867;&#20013;&#30340;&#26368;&#20339;&#21709;&#24212;&#27169;&#22411;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#24555;&#30340;&#36895;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36895;&#29575;&#20851;&#38190;&#20381;&#36182;&#20110;&#21453;&#39304;&#27169;&#22411;&#30340;&#35268;&#33539;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21551;&#21160;&#20102;&#23545;&#22312;&#34920;&#29616;&#24615;&#39044;&#27979;&#20013;&#20351;&#29992;&#21487;&#33021;&#30340;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#31216;&#20026;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
When predictions are performative, the choice of which predictor to deploy influences the distribution of future observations. The overarching goal in learning under performativity is to find a predictor that has low \emph{performative risk}, that is, good performance on its induced distribution. One family of solutions for optimizing the performative risk, including bandits and other derivative-free methods, is agnostic to any structure in the performative feedback, leading to exceedingly slow convergence rates. A complementary family of solutions makes use of explicit \emph{models} for the feedback, such as best-response models in strategic classification, enabling significantly faster rates. However, these rates critically rely on the feedback model being well-specified. In this work we initiate a study of the use of possibly \emph{misspecified} models in performative prediction. We study a general protocol for making use of models, called \emph{plug-in performative optimization}, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Density-Softmax&#30340;&#24555;&#36895;&#30830;&#23450;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23494;&#24230;&#20989;&#25968;&#19982;softmax&#32467;&#21512;&#26469;&#25552;&#39640;&#20998;&#24067;&#21464;&#21270;&#19979;&#30340;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#25928;&#29575;&#21644;&#21487;&#34892;&#24615;</title><link>http://arxiv.org/abs/2302.06495</link><description>&lt;p&gt;
Density-Softmax: &#22312;&#20998;&#24067;&#21464;&#21270;&#19979;&#25552;&#39640;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#24555;&#36895;&#30830;&#23450;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts. (arXiv:2302.06495v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06495
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Density-Softmax&#30340;&#24555;&#36895;&#30830;&#23450;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23494;&#24230;&#20989;&#25968;&#19982;softmax&#32467;&#21512;&#26469;&#25552;&#39640;&#20998;&#24067;&#21464;&#21270;&#19979;&#30340;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#25928;&#29575;&#21644;&#21487;&#34892;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#35265;&#30830;&#23450;&#24615;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#20998;&#24067;&#21464;&#21270;&#19979;&#23384;&#22312;&#36739;&#22823;&#30340;&#36807;&#24230;&#33258;&#20449;&#38382;&#39064;&#65292;&#27010;&#29575;&#26041;&#27861;&#34429;&#28982;&#33021;&#32531;&#35299;&#27492;&#38382;&#39064;&#20294;&#35745;&#31639;&#25928;&#29575;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;Density-Softmax&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23494;&#24230;&#20989;&#25968;&#19982;softmax&#32467;&#21512;&#65292;&#20197;&#24555;&#36895;&#19988;&#36731;&#37327;&#32423;&#30340;&#26041;&#24335;&#25552;&#39640;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#28508;&#22312;&#34920;&#31034;&#30340;&#20284;&#28982;&#20540;&#65292;&#22312;&#27979;&#35797;&#26102;&#22312;&#36828;&#31163;&#35757;&#32451;&#26679;&#26412;&#26102;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#29702;&#35770;&#35777;&#26126;&#21644;&#23454;&#39564;&#19978;&#65292;Density-Softmax&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#26631;&#20934;softmax&#30340;&#36807;&#24230;&#33258;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prevalent deterministic deep-learning models suffer from significant over-confidence under distribution shifts. Probabilistic approaches can reduce this problem but struggle with computational efficiency. In this paper, we propose Density-Softmax, a fast and lightweight deterministic method to improve calibrated uncertainty estimation via a combination of density function with the softmax layer. By using the latent representation's likelihood value, our approach produces more uncertain predictions when test samples are distant from the training samples. Theoretically, we show that Density-Softmax can produce high-quality uncertainty estimation with neural networks, as it is the solution of minimax uncertainty risk and is distance-aware, thus reducing the over-confidence of the standard softmax. Empirically, our method enjoys similar computational efficiency as a single forward pass deterministic with standard softmax on the shifted toy, vision, and language datasets across modern deep-
&lt;/p&gt;</description></item></channel></rss>