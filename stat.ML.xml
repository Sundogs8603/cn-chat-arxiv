<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25237;&#31080;&#30340;&#22312;&#32447;&#20381;&#20174;&#27169;&#22411;&#32858;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#36807;&#21435;&#34920;&#29616;&#35843;&#25972;&#27169;&#22411;&#26435;&#37325;&#12290;</title><link>https://arxiv.org/abs/2403.15527</link><description>&lt;p&gt;
&#20381;&#20174;&#22312;&#32447;&#27169;&#22411;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Conformal online model aggregation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15527
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25237;&#31080;&#30340;&#22312;&#32447;&#20381;&#20174;&#27169;&#22411;&#32858;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#36807;&#21435;&#34920;&#29616;&#35843;&#25972;&#27169;&#22411;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20381;&#20174;&#39044;&#27979;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#31181;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#27010;&#24565;&#65292;&#32780;&#19981;&#38656;&#35201;&#20570;&#20986;&#24378;&#28872;&#30340;&#20998;&#24067;&#20551;&#35774;&#12290;&#23427;&#36866;&#29992;&#20110;&#20219;&#20309;&#40657;&#30418;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#23558;&#28857;&#39044;&#27979;&#36716;&#25442;&#25104;&#20855;&#26377;&#39044;&#23450;&#20041;&#36793;&#38469;&#35206;&#30422;&#20445;&#35777;&#30340;&#38598;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#20381;&#20174;&#39044;&#27979;&#21482;&#22312;&#20107;&#20808;&#30830;&#23450;&#24213;&#23618;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#36215;&#20316;&#29992;&#12290;&#20381;&#20174;&#39044;&#27979;&#20013;&#30456;&#23545;&#36739;&#23569;&#28041;&#21450;&#30340;&#38382;&#39064;&#26159;&#27169;&#22411;&#36873;&#25321;&#21644;/&#25110;&#32858;&#21512;&#65306;&#23545;&#20110;&#32473;&#23450;&#30340;&#38382;&#39064;&#65292;&#24212;&#35813;&#22914;&#20309;&#20381;&#20174;&#21270;&#20247;&#22810;&#39044;&#27979;&#26041;&#27861;&#65288;&#38543;&#26426;&#26862;&#26519;&#12289;&#31070;&#32463;&#32593;&#32476;&#12289;&#27491;&#21017;&#21270;&#32447;&#24615;&#27169;&#22411;&#31561;&#65289;&#65311;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20381;&#20174;&#27169;&#22411;&#32858;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#35774;&#32622;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#23558;&#26469;&#33258;&#22810;&#20010;&#31639;&#27861;&#30340;&#39044;&#27979;&#38598;&#36827;&#34892;&#25237;&#31080;&#65292;&#20854;&#20013;&#26681;&#25454;&#36807;&#21435;&#34920;&#29616;&#35843;&#25972;&#27169;&#22411;&#19978;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15527v1 Announce Type: cross  Abstract: Conformal prediction equips machine learning models with a reasonable notion of uncertainty quantification without making strong distributional assumptions. It wraps around any black-box prediction model and converts point predictions into set predictions that have a predefined marginal coverage guarantee. However, conformal prediction only works if we fix the underlying machine learning model in advance. A relatively unaddressed issue in conformal prediction is that of model selection and/or aggregation: for a given problem, which of the plethora of prediction methods (random forests, neural nets, regularized linear models, etc.) should we conformalize? This paper proposes a new approach towards conformal model aggregation in online settings that is based on combining the prediction sets from several algorithms by voting, where weights on the models are adapted over time based on past performance.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#36817;&#20284;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#65292;&#25104;&#21151;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#34920;&#29616;&#20986;&#33394;.</title><link>https://arxiv.org/abs/2403.04764</link><description>&lt;p&gt;
&#23558;Thompson&#25277;&#26679;&#36951;&#25022;&#19982;Sigma&#27604;&#29575;&#65288;TS-RSR&#65289;&#26368;&#23567;&#21270;&#65306;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32463;&#36807;&#35777;&#26126;&#30340;&#39640;&#25928;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a provably efficient algorithm for batch Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04764
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#36817;&#20284;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#65292;&#25104;&#21151;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#34920;&#29616;&#20986;&#33394;.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#65292;&#20854;&#20013;&#25277;&#26679;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#26041;&#27861;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#26469;&#36827;&#34892;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#33021;&#22815;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#20013;&#36873;&#25321;&#30340;&#21160;&#20316;&#65292;&#20197;&#26368;&#23567;&#21270;&#28857;&#20043;&#38388;&#30340;&#20887;&#20313;&#65292;&#21516;&#26102;&#20851;&#27880;&#20855;&#26377;&#39640;&#39044;&#27979;&#22343;&#20540;&#25110;&#39640;&#19981;&#30830;&#23450;&#24615;&#30340;&#28857;&#12290;&#25105;&#20204;&#23545;&#31639;&#27861;&#30340;&#36951;&#25022;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#26368;&#21518;&#65292;&#20174;&#25968;&#23383;&#19978;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#31995;&#21015;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#22312;&#24179;&#22343;&#20540;&#19978;&#27604;&#20960;&#20010;&#31454;&#20105;&#23545;&#25163;&#30340;&#22522;&#20934;&#25209;&#37327;BO&#31639;&#27861;&#34920;&#29616;&#25552;&#39640;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04764v1 Announce Type: new  Abstract: This paper presents a new approach for batch Bayesian Optimization (BO), where the sampling takes place by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio. Our objective is able to coordinate the actions chosen in each batch in a way that minimizes redundancy between points whilst focusing on points with high predictive means or high uncertainty. We provide high-probability theoretical guarantees on the regret of our algorithm. Finally, numerically, we demonstrate that our method attains state-of-the-art performance on a range of nonconvex test functions, where it outperforms several competitive benchmark batch BO algorithms by an order of magnitude on average.
&lt;/p&gt;</description></item><item><title>&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#25193;&#25955;&#27169;&#22411;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#65292;&#26377;&#25928;&#22320;&#20174;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.03008</link><description>&lt;p&gt;
&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Diffusive Gibbs Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03008
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#25193;&#25955;&#27169;&#22411;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#65292;&#26377;&#25928;&#22320;&#20174;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#26041;&#27861;&#22312;&#22810;&#27169;&#24577;&#20998;&#24067;&#30340;&#28151;&#21512;&#19981;&#36275;&#26041;&#38754;&#23384;&#22312;&#30528;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#20998;&#23376;&#21160;&#21147;&#23398;&#31561;&#23454;&#38469;&#24212;&#29992;&#20013;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#8212;&#8212;&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#65288;DiGS&#65289;&#65292;&#29992;&#20110;&#26377;&#25928;&#37319;&#26679;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#12290;DiGS&#38598;&#25104;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#21033;&#29992;&#39640;&#26031;&#21367;&#31215;&#21019;&#24314;&#19968;&#20010;&#36741;&#21161;&#22122;&#22768;&#20998;&#24067;&#65292;&#20197;&#22312;&#21407;&#22987;&#31354;&#38388;&#20013;&#36830;&#25509;&#23396;&#31435;&#30340;&#27169;&#24577;&#65292;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#20174;&#20004;&#20010;&#31354;&#38388;&#20013;&#20132;&#26367;&#25277;&#21462;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#37319;&#26679;&#22810;&#27169;&#24577;&#20998;&#24067;&#26041;&#38754;&#34920;&#29616;&#20986;&#27604;&#24182;&#34892;&#28201;&#24230;&#27861;&#31561;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#12290;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#37319;&#26679;&#22120;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#65292;&#21253;&#25324;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12289;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21644;&#20998;&#23376;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
The inadequate mixing of conventional Markov Chain Monte Carlo (MCMC) methods for multi-modal distributions presents a significant challenge in practical applications such as Bayesian inference and molecular dynamics. Addressing this, we propose Diffusive Gibbs Sampling (DiGS), an innovative family of sampling methods designed for effective sampling from distributions characterized by distant and disconnected modes. DiGS integrates recent developments in diffusion models, leveraging Gaussian convolution to create an auxiliary noisy distribution that bridges isolated modes in the original space and applying Gibbs sampling to alternately draw samples from both spaces. Our approach exhibits a better mixing property for sampling multi-modal distributions than state-of-the-art methods such as parallel tempering. We demonstrate that our sampler attains substantially improved results across various tasks, including mixtures of Gaussians, Bayesian neural networks and molecular dynamics.
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#29420;&#31435;&#23884;&#20837;&#26102;&#38388;&#24207;&#21015;&#29255;&#27573;&#21487;&#20197;&#20135;&#29983;&#26356;&#22909;&#30340;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#22359;&#37325;&#26500;&#20219;&#21153;&#21644;&#29420;&#31435;&#23884;&#20837;&#27599;&#20010;&#22359;&#30340;MLP&#27169;&#22411;&#20197;&#21450;&#20114;&#34917;&#23545;&#27604;&#23398;&#20064;&#26469;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2312.16427</link><description>&lt;p&gt;
&#29420;&#31435;&#23398;&#20064;&#23558;&#26102;&#38388;&#24207;&#21015;&#29255;&#27573;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Learning to Embed Time Series Patches Independently
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16427
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#29420;&#31435;&#23884;&#20837;&#26102;&#38388;&#24207;&#21015;&#29255;&#27573;&#21487;&#20197;&#20135;&#29983;&#26356;&#22909;&#30340;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#22359;&#37325;&#26500;&#20219;&#21153;&#21644;&#29420;&#31435;&#23884;&#20837;&#27599;&#20010;&#22359;&#30340;MLP&#27169;&#22411;&#20197;&#21450;&#20114;&#34917;&#23545;&#27604;&#23398;&#20064;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25513;&#30721;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20316;&#20026;&#19968;&#31181;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#31574;&#30053;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#21463;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#30340;&#25513;&#30721;&#22270;&#20687;&#24314;&#27169;&#21551;&#21457;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#39318;&#20808;&#23558;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20998;&#22359;&#22788;&#29702;&#24182;&#37096;&#20998;&#25513;&#30422;&#65292;&#28982;&#21518;&#35757;&#32451;Transformer&#27169;&#22411;&#36890;&#36807;&#20174;&#26410;&#25513;&#30422;&#30340;&#22359;&#39044;&#27979;&#34987;&#25513;&#30422;&#22359;&#26469;&#25429;&#25417;&#22359;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35748;&#20026;&#25429;&#25417;&#36825;&#31181;&#22359;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#21487;&#33021;&#19981;&#26159;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;&#23398;&#20064;&#30340;&#26368;&#20339;&#31574;&#30053;&#65307;&#30456;&#21453;&#65292;&#29420;&#31435;&#23398;&#20064;&#23884;&#20837;&#29255;&#27573;&#20250;&#20135;&#29983;&#26356;&#22909;&#30340;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;1&#65289;&#31616;&#21333;&#30340;&#22359;&#37325;&#26500;&#20219;&#21153;&#65292;&#33258;&#21160;&#23558;&#27599;&#20010;&#22359;&#36827;&#34892;&#32534;&#30721;&#32780;&#19981;&#26597;&#30475;&#20854;&#20182;&#22359;&#65292;&#20197;&#21450;2&#65289;&#29420;&#33258;&#23884;&#20837;&#27599;&#20010;&#22359;&#30340;&#31616;&#21333;&#22359;&#24335;MLP&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20114;&#34917;&#23545;&#27604;&#23398;&#20064;&#26469;&#26377;&#25928;&#22320;&#20998;&#23618;&#25429;&#33719;&#30456;&#37051;&#26102;&#38388;&#24207;&#21015;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.16427v2 Announce Type: replace-cross  Abstract: Masked time series modeling has recently gained much attention as a self-supervised representation learning strategy for time series. Inspired by masked image modeling in computer vision, recent works first patchify and partially mask out time series, and then train Transformers to capture the dependencies between patches by predicting masked patches from unmasked patches. However, we argue that capturing such patch dependencies might not be an optimal strategy for time series representation learning; rather, learning to embed patches independently results in better time series representations. Specifically, we propose to use 1) the simple patch reconstruction task, which autoencode each patch without looking at other patches, and 2) the simple patch-wise MLP that embeds each patch independently. In addition, we introduce complementary contrastive learning to hierarchically capture adjacent time series information efficiently. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#26816;&#39564;&#26694;&#26550;&#65292;&#21033;&#29992;&#35268;&#33539;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#26469;&#36827;&#34892;&#25512;&#26029;&#65292;&#24182;&#36991;&#20813;&#20102;&#23545;&#23436;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#24314;&#27169;&#38656;&#27714;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#23454;&#36136;&#24615;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.15502</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Bayesian Tests. (arXiv:2401.15502v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#26816;&#39564;&#26694;&#26550;&#65292;&#21033;&#29992;&#35268;&#33539;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#26469;&#36827;&#34892;&#25512;&#26029;&#65292;&#24182;&#36991;&#20813;&#20102;&#23545;&#23436;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#24314;&#27169;&#38656;&#27714;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#23454;&#36136;&#24615;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21033;&#29992;&#26426;&#23494;&#25968;&#25454;&#36827;&#34892;&#31185;&#23398;&#20551;&#35774;&#26816;&#39564;&#30340;&#39046;&#22495;&#20013;&#65292;&#24046;&#20998;&#38544;&#31169;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#22522;&#30707;&#12290;&#22312;&#25253;&#21578;&#31185;&#23398;&#21457;&#29616;&#26102;&#65292;&#24191;&#27867;&#37319;&#29992;&#36125;&#21494;&#26031;&#26816;&#39564;&#65292;&#22240;&#20026;&#23427;&#20204;&#26377;&#25928;&#22320;&#36991;&#20813;&#20102;P&#20540;&#30340;&#20027;&#35201;&#25209;&#35780;&#65292;&#21363;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#21644;&#26080;&#27861;&#37327;&#21270;&#23545;&#31454;&#20105;&#20551;&#35774;&#30340;&#25903;&#25345;&#35777;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#22522;&#20110;&#35268;&#33539;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#22522;&#30784;&#19978;&#33258;&#28982;&#20135;&#29983;&#65292;&#20174;&#32780;&#20445;&#25345;&#20102;&#25512;&#26029;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#19987;&#27880;&#20110;&#22522;&#20110;&#24191;&#27867;&#20351;&#29992;&#30340;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#22240;&#23376;&#65292;&#25105;&#20204;&#36991;&#20813;&#20102;&#23545;&#23436;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#24314;&#27169;&#30340;&#38656;&#27714;&#65292;&#24182;&#30830;&#20445;&#20102;&#23454;&#36136;&#24615;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#32452;&#20805;&#20998;&#26465;&#20214;&#65292;&#20197;&#22312;&#25152;&#25552;&#26694;&#26550;&#19979;&#30830;&#31435;&#36125;&#21494;&#26031;&#22240;&#23376;&#19968;&#33268;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential privacy has emerged as an significant cornerstone in the realm of scientific hypothesis testing utilizing confidential data. In reporting scientific discoveries, Bayesian tests are widely adopted since they effectively circumnavigate the key criticisms of P-values, namely, lack of interpretability and inability to quantify evidence in support of the competing hypotheses. We present a novel differentially private Bayesian hypotheses testing framework that arise naturally under a principled data generative mechanism, inherently maintaining the interpretability of the resulting inferences. Furthermore, by focusing on differentially private Bayes factors based on widely used test statistics, we circumvent the need to model the complete data generative mechanism and ensure substantial computational benefits. We also provide a set of sufficient conditions to establish results on Bayes factor consistency under the proposed framework. The utility of the devised technology is showc
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;</title><link>http://arxiv.org/abs/2401.01404</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#23376;&#20108;&#27425;&#26102;&#38388;&#32593;&#32476;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable network reconstruction in subquadratic time. (arXiv:2401.01404v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01404
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#37325;&#24314;&#26159;&#25351;&#22312;&#21482;&#26377;&#20851;&#20110;&#26465;&#20214;&#20598;&#32852;&#30340;&#35266;&#27979;&#25968;&#25454;&#65292;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#25110;&#22270;&#27169;&#22411;&#30340;&#29420;&#31435;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#30830;&#23450;N&#20010;&#33410;&#28857;&#20043;&#38388;&#26410;&#35266;&#27979;&#21040;&#30340;&#25104;&#23545;&#32806;&#21512;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;&#20284;&#20046;&#26080;&#27861;&#36991;&#20813;&#30340;&#20108;&#27425;&#22797;&#26434;&#24230;O(N^2)&#65292;&#21363;&#35201;&#32771;&#34385;&#27599;&#31181;&#21487;&#33021;&#30340;&#25104;&#23545;&#32806;&#21512;&#33267;&#23569;&#19968;&#27425;&#65292;&#23613;&#31649;&#22823;&#22810;&#25968;&#24863;&#20852;&#36259;&#30340;&#32593;&#32476;&#37117;&#26159;&#31232;&#30095;&#30340;&#65292;&#38750;&#38646;&#32806;&#21512;&#30340;&#25968;&#37327;&#21482;&#26377;O(N)&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#24191;&#27867;&#37325;&#24314;&#38382;&#39064;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#20854;&#22312;&#23376;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#20854;&#25968;&#25454;&#30456;&#20851;&#22797;&#26434;&#24230;&#23485;&#26494;&#19978;&#30028;&#20026;O(N^(3/2)logN)&#65292;&#20294;&#20855;&#26377;&#26356;&#20856;&#22411;&#30340;&#23545;&#25968;&#32447;&#24615;&#22797;&#26434;&#24230;O(Nlog^2 N)&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#65292;&#20135;&#29983;&#20102;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network reconstruction consists in determining the unobserved pairwise couplings between $N$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. A major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $O(N^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $O(N)$. Here we present a general algorithm applicable to a broad range of reconstruction problems that achieves its result in subquadratic time, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\log N)$, but with a more typical log-linear complexity of $O(N\log^2N)$. Our algorithm relies on a stochastic second neighbor search that produces the best edge candidat
&lt;/p&gt;</description></item><item><title>&#31526;&#21512;&#20915;&#31574;&#29702;&#35770;&#26159;&#19968;&#31181;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#19981;&#23436;&#32654;&#30340;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#20135;&#29983;&#23433;&#20840;&#30340;&#33258;&#20027;&#20915;&#31574;&#12290;&#35813;&#29702;&#35770;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#21487;&#20197;&#22312;&#27809;&#26377;&#23545;&#19990;&#30028;&#27169;&#22411;&#20570;&#20986;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20855;&#26377;&#20302;&#39118;&#38505;&#30340;&#32479;&#35745;&#20445;&#35777;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2310.05921</link><description>&lt;p&gt;
&#31526;&#21512;&#20915;&#31574;&#29702;&#35770;: &#36890;&#36807;&#19981;&#23436;&#32654;&#30340;&#39044;&#27979;&#20135;&#29983;&#23433;&#20840;&#30340;&#33258;&#20027;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions. (arXiv:2310.05921v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05921
&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#20915;&#31574;&#29702;&#35770;&#26159;&#19968;&#31181;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#19981;&#23436;&#32654;&#30340;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#20135;&#29983;&#23433;&#20840;&#30340;&#33258;&#20027;&#20915;&#31574;&#12290;&#35813;&#29702;&#35770;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#21487;&#20197;&#22312;&#27809;&#26377;&#23545;&#19990;&#30028;&#27169;&#22411;&#20570;&#20986;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20855;&#26377;&#20302;&#39118;&#38505;&#30340;&#32479;&#35745;&#20445;&#35777;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31526;&#21512;&#20915;&#31574;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#19981;&#23436;&#32654;&#30340;&#24773;&#20917;&#19979;&#20135;&#29983;&#23433;&#20840;&#30340;&#33258;&#20027;&#20915;&#31574;&#12290;&#36825;&#31181;&#20915;&#31574;&#30340;&#20363;&#23376;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#20174;&#20381;&#36182;&#20110;&#34892;&#20154;&#39044;&#27979;&#30340;&#26426;&#22120;&#20154;&#35268;&#21010;&#31639;&#27861;&#65292;&#21040;&#26657;&#20934;&#33258;&#21160;&#21270;&#21046;&#36896;&#20197;&#23454;&#29616;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#38169;&#35823;&#29575;&#65292;&#20877;&#21040;&#22312;&#36816;&#34892;&#26102;&#36873;&#25321;&#20449;&#20219;&#21517;&#20041;&#31574;&#30053;&#36824;&#26159;&#20999;&#25442;&#21040;&#23433;&#20840;&#22791;&#20221;&#31574;&#30053;&#12290;&#25105;&#20204;&#31639;&#27861;&#20135;&#29983;&#30340;&#20915;&#31574;&#22312;&#32479;&#35745;&#20445;&#35777;&#30340;&#24773;&#20917;&#19979;&#26159;&#23433;&#20840;&#30340;&#65292;&#26080;&#38656;&#23545;&#19990;&#30028;&#27169;&#22411;&#20316;&#20986;&#20219;&#20309;&#20551;&#35774;&#65307;&#35266;&#27979;&#25968;&#25454;&#21487;&#20197;&#19981;&#28385;&#36275;&#29420;&#31435;&#21516;&#20998;&#24067;(I.I.D.)&#30340;&#26465;&#20214;&#65292;&#29978;&#33267;&#21487;&#33021;&#26159;&#23545;&#25239;&#24615;&#30340;&#12290;&#35813;&#29702;&#35770;&#23558;&#31526;&#21512;&#39044;&#27979;&#30340;&#32467;&#26524;&#25193;&#23637;&#21040;&#30452;&#25509;&#26657;&#20934;&#20915;&#31574;&#65292;&#32780;&#19981;&#38656;&#35201;&#26500;&#24314;&#39044;&#27979;&#38598;&#21512;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#22260;&#32469;&#20154;&#31867;&#36827;&#34892;&#26426;&#22120;&#20154;&#36816;&#21160;&#35268;&#21010;&#12289;&#33258;&#21160;&#32929;&#31080;&#20132;&#26131;&#21644;&#26426;&#22120;&#20154;&#21046;&#36896;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Conformal Decision Theory, a framework for producing safe autonomous decisions despite imperfect machine learning predictions. Examples of such decisions are ubiquitous, from robot planning algorithms that rely on pedestrian predictions, to calibrating autonomous manufacturing to exhibit high throughput and low error, to the choice of trusting a nominal policy versus switching to a safe backup policy at run-time. The decisions produced by our algorithms are safe in the sense that they come with provable statistical guarantees of having low risk without any assumptions on the world model whatsoever; the observations need not be I.I.D. and can even be adversarial. The theory extends results from conformal prediction to calibrate decisions directly, without requiring the construction of prediction sets. Experiments demonstrate the utility of our approach in robot motion planning around humans, automated stock trading, and robot manufacturin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#19968;&#31995;&#21015;&#32447;&#24615;&#31995;&#32479;&#23454;&#20363;&#20013;&#35774;&#32622;&#27714;&#35299;&#22120;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#36873;&#25321;&#21442;&#25968;&#65292;&#21487;&#20197;&#25509;&#36817;&#26368;&#20339;&#24635;&#36845;&#20195;&#27425;&#25968;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#30697;&#38453;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2310.02246</link><description>&lt;p&gt;
&#23398;&#20064;&#25918;&#26494;&#65306;&#22312;&#19968;&#31995;&#21015;&#32447;&#24615;&#31995;&#32479;&#23454;&#20363;&#20013;&#35774;&#32622;&#27714;&#35299;&#22120;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances. (arXiv:2310.02246v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#19968;&#31995;&#21015;&#32447;&#24615;&#31995;&#32479;&#23454;&#20363;&#20013;&#35774;&#32622;&#27714;&#35299;&#22120;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#36873;&#25321;&#21442;&#25968;&#65292;&#21487;&#20197;&#25509;&#36817;&#26368;&#20339;&#24635;&#36845;&#20195;&#27425;&#25968;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#30697;&#38453;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#32447;&#24615;&#31995;&#32479;$Ax=b$&#26159;&#19968;&#31181;&#22522;&#26412;&#30340;&#31185;&#23398;&#35745;&#31639;&#21407;&#29702;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#27714;&#35299;&#22120;&#21644;&#39044;&#22788;&#29702;&#22120;&#12290;&#23427;&#20204;&#24102;&#26377;&#21442;&#25968;&#65292;&#20854;&#26368;&#20339;&#20540;&#21462;&#20915;&#20110;&#35201;&#35299;&#20915;&#30340;&#31995;&#32479;&#65292;&#24182;&#19988;&#36890;&#24120;&#26080;&#27861;&#25110;&#25104;&#26412;&#36807;&#39640;&#20197;&#30830;&#23450;&#65307;&#22240;&#27492;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#27425;&#20248;&#21551;&#21457;&#24335;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#38656;&#35201;&#35299;&#20915;&#35768;&#22810;&#30456;&#20851;&#32447;&#24615;&#31995;&#32479;&#30340;&#24120;&#35265;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#22312;&#21333;&#20010;&#25968;&#20540;&#27169;&#25311;&#26399;&#38388;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#26159;&#21542;&#21487;&#20197;&#39034;&#24207;&#36873;&#25321;&#21442;&#25968;&#65292;&#20197;&#33719;&#24471;&#25509;&#36817;&#26368;&#20339;&#24635;&#36845;&#20195;&#27425;&#25968;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#30697;&#38453;&#35745;&#31639;&#65311;&#23545;&#20110;&#36807;&#24230;&#36731;&#26494;&#65288;SOR&#65289;&#36825;&#31181;&#26631;&#20934;&#27714;&#35299;&#22120;&#65292;&#25105;&#20204;&#22238;&#31572;&#32943;&#23450;&#30340;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#20351;&#29992;&#20165;&#36845;&#20195;&#27425;&#25968;&#20316;&#20026;&#21453;&#39304;&#30340;&#36172;&#24466;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#36873;&#25321;&#24207;&#21015;&#23454;&#20363;&#30340;&#21442;&#25968;&#65292;&#20351;&#24471;&#24635;&#25104;&#26412;&#25509;&#36817;&#26368;&#20339;&#22266;&#23450;&#30340;&#969;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving a linear system $Ax=b$ is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed. These come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify; thus in practice sub-optimal heuristics are used. We consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation. In this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations? We answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter $\omega$ has a strong impact on its runtime. For this method, we prove that a bandit online learning algorithm -- using only the number of iterations as feedback -- can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed $\omega$ as
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#22312;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30740;&#31350;&#20102;&#22996;&#25176;&#30340;&#25968;&#25454;&#25910;&#38598;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#26368;&#20248;&#22865;&#32422;&#35299;&#20915;&#20102;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.01837</link><description>&lt;p&gt;
&#22996;&#25176;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#25910;&#38598;
&lt;/p&gt;
&lt;p&gt;
Delegating Data Collection in Decentralized Machine Learning. (arXiv:2309.01837v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01837
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#22312;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30740;&#31350;&#20102;&#22996;&#25176;&#30340;&#25968;&#25454;&#25910;&#38598;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#26368;&#20248;&#22865;&#32422;&#35299;&#20915;&#20102;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#30340;&#20986;&#29616;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#25910;&#38598;&#30340;&#22996;&#25176;&#38382;&#39064;&#12290;&#20197;&#22865;&#32422;&#29702;&#35770;&#20026;&#20986;&#21457;&#28857;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#35299;&#20915;&#20004;&#20010;&#22522;&#26412;&#26426;&#22120;&#23398;&#20064;&#25361;&#25112;&#30340;&#26368;&#20248;&#21644;&#36817;&#20284;&#26368;&#20248;&#22865;&#32422;&#65306;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#20219;&#20309;&#27169;&#22411;&#26368;&#20248;&#24615;&#33021;&#30340;&#32570;&#20047;&#30693;&#35782;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#32447;&#24615;&#22865;&#32422;&#21487;&#20197;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#21363;&#20351;&#22996;&#25176;&#20154;&#21482;&#26377;&#19968;&#20010;&#23567;&#30340;&#27979;&#35797;&#38598;&#65292;&#20063;&#33021;&#23454;&#29616;1-1/e&#30340;&#19968;&#31561;&#25928;&#29992;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#22996;&#25176;&#20154;&#27979;&#35797;&#38598;&#22823;&#23567;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#21487;&#20197;&#36798;&#21040;&#23545;&#26368;&#20248;&#25928;&#29992;&#30340;&#36924;&#36817;&#12290;&#20026;&#20102;&#35299;&#20915;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#21487;&#20197;&#33258;&#36866;&#24212;&#21644;&#39640;&#25928;&#22320;&#35745;&#31639;&#26368;&#20248;&#22865;&#32422;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the emergence of decentralized machine learning ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental machine learning challenges: lack of certainty in the assessment of model quality and lack of knowledge regarding the optimal performance of any model. We show that lack of certainty can be dealt with via simple linear contracts that achieve 1-1/e fraction of the first-best utility, even if the principal has a small test set. Furthermore, we give sufficient conditions on the size of the principal's test set that achieves a vanishing additive approximation to the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PICLE&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#27010;&#29575;&#27169;&#22411;&#24555;&#36895;&#35745;&#31639;&#27599;&#20010;&#32452;&#21512;&#30340;&#36866;&#24212;&#24230;&#26469;&#21152;&#36895;&#25628;&#32034;&#65292;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#36716;&#31227;&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.06545</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#26694;&#26550;&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Framework for Modular Continual Learning. (arXiv:2306.06545v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PICLE&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#27010;&#29575;&#27169;&#22411;&#24555;&#36895;&#35745;&#31639;&#27599;&#20010;&#32452;&#21512;&#30340;&#36866;&#24212;&#24230;&#26469;&#21152;&#36895;&#25628;&#32034;&#65292;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#36716;&#31227;&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22359;&#21270;&#26041;&#27861;&#26159;&#22686;&#37327;&#23398;&#20064;&#39046;&#22495;&#30340;&#26377;&#21069;&#36884;&#26041;&#21521;&#65292;&#27599;&#20010;&#38382;&#39064;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22359;&#32452;&#21512;&#19988;&#36991;&#20813;&#36951;&#24536;&#12290;&#28982;&#32780;&#65292;&#25628;&#32034;&#21487;&#33021;&#30340;&#27169;&#22359;&#32452;&#21512;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#22240;&#20026;&#35780;&#20272;&#32452;&#21512;&#24615;&#33021;&#38656;&#35201;&#19968;&#36718;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31181;&#21517;&#20026;PICLE&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#27010;&#29575;&#27169;&#22411;&#26469;&#24555;&#36895;&#35745;&#31639;&#27599;&#20010;&#32452;&#21512;&#30340;&#36866;&#24212;&#24230;&#26469;&#21152;&#36895;&#25628;&#32034;&#12290;&#27169;&#22411;&#32467;&#21512;&#20808;&#21069;&#20851;&#20110;&#33391;&#22909;&#27169;&#22359;&#32452;&#21512;&#30340;&#30693;&#35782;&#19982;&#25968;&#25454;&#38598;&#29305;&#23450;&#20449;&#24687;&#12290;&#23427;&#30340;&#20351;&#29992;&#34987;&#20998;&#20026;&#24863;&#30693;&#21644;&#28508;&#22312;&#23376;&#38598;&#31561;&#23376;&#38598;&#30340;&#25628;&#32034;&#31354;&#38388;&#21152;&#20197;&#34917;&#20805;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;PICLE&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#36716;&#31227;&#30340;&#27169;&#22359;&#21270;&#22686;&#37327;&#23398;&#20064;&#31639;&#27861;&#65292;&#21516;&#26102;&#36824;&#33021;&#25193;&#23637;&#21040;&#22823;&#22411;&#25628;&#32034;&#31354;&#38388;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#22522;&#20934;&#22871;&#20214;&#19978;&#23545;&#20854;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#20123;&#22871;&#20214;&#26088;&#22312;&#25429;&#25417;&#22686;&#37327;&#23398;&#20064;&#25216;&#26415;&#30340;&#19981;&#21516;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modular approaches, which use a different composition of modules for each problem and avoid forgetting by design, have been shown to be a promising direction in continual learning (CL). However, searching through the large, discrete space of possible module compositions is a challenge because evaluating a composition's performance requires a round of neural network training. To address this challenge, we develop a modular CL framework, called PICLE, that accelerates search by using a probabilistic model to cheaply compute the fitness of each composition. The model combines prior knowledge about good module compositions with dataset-specific information. Its use is complemented by splitting up the search space into subsets, such as perceptual and latent subsets. We show that PICLE is the first modular CL algorithm to achieve different types of transfer while scaling to large search spaces. We evaluate it on two benchmark suites designed to capture different desiderata of CL techniques. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#25152;&#38656;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20855;&#26377;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;&#19988;&#19982;&#23481;&#24046;&#27700;&#24179;&#30340;&#20851;&#32852;&#24615;&#26368;&#20339;&#12290;</title><link>http://arxiv.org/abs/2305.19001</link><description>&lt;p&gt;
&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31574;&#30053;&#35780;&#20272;&#30340;&#39640;&#27010;&#29575;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sharp high-probability sample complexities for policy evaluation with linear function approximation. (arXiv:2305.19001v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#25152;&#38656;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20855;&#26377;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;&#19988;&#19982;&#23481;&#24046;&#27700;&#24179;&#30340;&#20851;&#32852;&#24615;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28041;&#21450;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#22312;&#26080;&#38480;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#36827;&#34892;&#31574;&#30053;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#31574;&#30053;&#35780;&#20272;&#31639;&#27861;&#65288;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#31639;&#27861;&#21644;&#24102;&#26377;&#26799;&#24230;&#26657;&#27491;&#30340;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#32447;&#24615;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65289;&#25152;&#38656;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20197;&#20445;&#35777;&#26368;&#20339;&#32447;&#24615;&#31995;&#25968;&#30340;&#39044;&#23450;&#20041;&#20272;&#35745;&#35823;&#24046;&#12290;&#22312;&#31574;&#30053;&#35774;&#32622;&#21644;&#31163;&#32447;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#36798;&#21040;&#20102;&#19982;&#23481;&#24046;&#27700;&#24179;&#30340;&#26368;&#20339;&#20851;&#32852;&#24615;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19982;&#38382;&#39064;&#30456;&#20851;&#37327;&#26126;&#30830;&#30340;&#20851;&#31995;&#65292;&#24182;&#22312;&#31574;&#30053;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#19978;&#38480;&#30028;&#38480;&#19982;&#20851;&#38190;&#38382;&#39064;&#21442;&#25968;&#19978;&#30340;&#26497;&#23567;&#26497;&#22823;&#19979;&#38480;&#30028;&#38480;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with the problem of policy evaluation with linear function approximation in discounted infinite horizon Markov decision processes. We investigate the sample complexities required to guarantee a predefined estimation error of the best linear coefficients for two widely-used policy evaluation algorithms: the temporal difference (TD) learning algorithm and the two-timescale linear TD with gradient correction (TDC) algorithm. In both the on-policy setting, where observations are generated from the target policy, and the off-policy setting, where samples are drawn from a behavior policy potentially different from the target policy, we establish the first sample complexity bound with high-probability convergence guarantee that attains the optimal dependence on the tolerance level. We also exhihit an explicit dependence on problem-related quantities, and show in the on-policy setting that our upper bound matches the minimax lower bound on crucial problem parameters, in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#22312;&#32473;&#23450;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#35299;&#20986;&#21463;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#25552;&#20986;&#26032;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#65292;&#24182;&#24212;&#29992;&#20110;&#31232;&#30095;&#30697;&#38453;&#31561;&#24773;&#22659;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32479;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.15121</link><description>&lt;p&gt;
&#22312;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Learning linear dynamical systems under convex constraints. (arXiv:2303.15121v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#32473;&#23450;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#35299;&#20986;&#21463;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#25552;&#20986;&#26032;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#65292;&#24182;&#24212;&#29992;&#20110;&#31232;&#30095;&#30697;&#38453;&#31561;&#24773;&#22659;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32479;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#21333;&#20010;&#36712;&#36857;&#20013;&#35782;&#21035;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#26410;&#23545;&#31995;&#32479;&#30697;&#38453; $A^* \in \mathbb{R}^{n \times n}$ &#36827;&#34892;&#32467;&#26500;&#20551;&#35774;&#30340;&#24773;&#20917;&#65292;&#24182;&#23545;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056; (OLS) &#20272;&#35745;&#22120;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#12290;&#25105;&#20204;&#20551;&#35774;&#21487;&#29992;&#20808;&#21069;&#30340; $A^*$ &#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#21487;&#20197;&#22312;&#21253;&#21547; $A^*$ &#30340;&#20984;&#38598; $\mathcal{K}$ &#20013;&#25429;&#33719;&#12290;&#23545;&#20110;&#38543;&#21518;&#30340;&#21463;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#35299;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986; Frobenius &#33539;&#25968;&#19979;&#20381;&#36182;&#20110; $\mathcal{K}$ &#22312; $A^*$ &#22788;&#20999;&#38181;&#30340;&#23616;&#37096;&#22823;&#23567;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#19968;&#32467;&#26524;&#30340;&#26377;&#29992;&#24615;&#65292;&#25105;&#20204;&#23558;&#20854;&#23454;&#20363;&#21270;&#20026;&#20197;&#19979;&#35774;&#32622;&#65306;(i) $\mathcal{K}$ &#26159; $\mathbb{R}^{n \times n}$ &#20013;&#30340; $d$ &#32500;&#23376;&#31354;&#38388;&#65292;&#25110;&#32773; (ii) $A^*$ &#26159; $k$ &#31232;&#30095;&#30340;&#65292;$\mathcal{K}$ &#26159;&#36866;&#24403;&#32553;&#25918;&#30340; $\ell_1$ &#29699;&#12290;&#22312; $d, k \ll n^2$ &#30340;&#21306;&#22495;&#20013;&#65292;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#23545;&#20110;&#30456;&#21516;&#30340;&#32479;&#35745;&#21644;&#22122;&#22768;&#20551;&#35774;&#27604; OLS &#20272;&#35745;&#22120;&#33719;&#24471;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of identification of linear dynamical systems from a single trajectory. Recent results have predominantly focused on the setup where no structural assumption is made on the system matrix $A^* \in \mathbb{R}^{n \times n}$, and have consequently analyzed the ordinary least squares (OLS) estimator in detail. We assume prior structural information on $A^*$ is available, which can be captured in the form of a convex set $\mathcal{K}$ containing $A^*$. For the solution of the ensuing constrained least squares estimator, we derive non-asymptotic error bounds in the Frobenius norm which depend on the local size of the tangent cone of $\mathcal{K}$ at $A^*$. To illustrate the usefulness of this result, we instantiate it for the settings where, (i) $\mathcal{K}$ is a $d$ dimensional subspace of $\mathbb{R}^{n \times n}$, or (ii) $A^*$ is $k$-sparse and $\mathcal{K}$ is a suitably scaled $\ell_1$ ball. In the regimes where $d, k \ll n^2$, our bounds improve upon those obta
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#20010;&#22788;&#29702;&#20302;&#32500;&#27969;&#24418;&#25968;&#25454;&#30340;&#22238;&#24402;&#26694;&#26550;&#65292;&#39318;&#20808;&#36890;&#36807;&#26500;&#24314;&#22270;&#24418;&#39592;&#26550;&#26469;&#25429;&#25417;&#28508;&#22312;&#30340;&#27969;&#24418;&#20960;&#20309;&#32467;&#26500;&#65292;&#28982;&#21518;&#22312;&#20854;&#19978;&#36816;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#25216;&#26415;&#26469;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#65292;&#38500;&#20102;&#20855;&#26377;&#38750;&#21442;&#25968;&#20248;&#28857;&#20043;&#22806;&#65292;&#22312;&#22788;&#29702;&#22810;&#20010;&#27969;&#24418;&#25968;&#25454;&#65292;&#22024;&#26434;&#35266;&#23519;&#26102;&#20063;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.11786</link><description>&lt;p&gt;
Skeleton Regression&#65306;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#32467;&#26500;&#20272;&#35745;&#30340;&#22522;&#20110;&#22270;&#24418;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Skeleton Regression: A Graph-Based Approach to Estimation with Manifold Structure. (arXiv:2303.11786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11786
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#20010;&#22788;&#29702;&#20302;&#32500;&#27969;&#24418;&#25968;&#25454;&#30340;&#22238;&#24402;&#26694;&#26550;&#65292;&#39318;&#20808;&#36890;&#36807;&#26500;&#24314;&#22270;&#24418;&#39592;&#26550;&#26469;&#25429;&#25417;&#28508;&#22312;&#30340;&#27969;&#24418;&#20960;&#20309;&#32467;&#26500;&#65292;&#28982;&#21518;&#22312;&#20854;&#19978;&#36816;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#25216;&#26415;&#26469;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#65292;&#38500;&#20102;&#20855;&#26377;&#38750;&#21442;&#25968;&#20248;&#28857;&#20043;&#22806;&#65292;&#22312;&#22788;&#29702;&#22810;&#20010;&#27969;&#24418;&#25968;&#25454;&#65292;&#22024;&#26434;&#35266;&#23519;&#26102;&#20063;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22238;&#24402;&#26694;&#26550;&#65292;&#26088;&#22312;&#22788;&#29702;&#22260;&#32469;&#20302;&#32500;&#27969;&#24418;&#30340;&#22797;&#26434;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#26500;&#24314;&#19968;&#20010;&#22270;&#24418;&#34920;&#31034;&#65292;&#31216;&#20026;&#39592;&#26550;&#65292;&#20197;&#25429;&#33719;&#28508;&#22312;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#39592;&#26550;&#22270;&#19978;&#23450;&#20041;&#25351;&#26631;&#65292;&#24212;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#25216;&#26415;&#65292;&#20197;&#21450;&#22522;&#20110;&#22270;&#24418;&#30340;&#29305;&#24449;&#36716;&#25442;&#26469;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#12290;&#38500;&#20102;&#21253;&#25324;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#19968;&#20123;&#38750;&#21442;&#25968;&#22238;&#24402;&#22120;&#22312;&#39592;&#26550;&#22270;&#31561;&#19968;&#33324;&#24230;&#37327;&#31354;&#38388;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;&#25152;&#25552;&#20986;&#30340;&#22238;&#24402;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#36991;&#24320;&#32500;&#24230;&#28798;&#38590;&#65292;&#20855;&#26377;&#21487;&#20197;&#22788;&#29702;&#22810;&#20010;&#27969;&#24418;&#30340;&#24182;&#38598;&#24182;&#19988;&#40065;&#26834;&#24615;&#33021;&#24212;&#23545;&#21152;&#24615;&#22122;&#22768;&#21644;&#22024;&#26434;&#35266;&#23519;&#30340;&#39069;&#22806;&#20248;&#21183;&#12290;&#25105;&#20204;&#20026;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new regression framework designed to deal with large-scale, complex data that lies around a low-dimensional manifold. Our approach first constructs a graph representation, referred to as the skeleton, to capture the underlying geometric structure. We then define metrics on the skeleton graph and apply nonparametric regression techniques, along with feature transformations based on the graph, to estimate the regression function. In addition to the included nonparametric methods, we also discuss the limitations of some nonparametric regressors with respect to the general metric space such as the skeleton graph. The proposed regression framework allows us to bypass the curse of dimensionality and provides additional advantages that it can handle the union of multiple manifolds and is robust to additive noise and noisy observations. We provide statistical guarantees for the proposed method and demonstrate its effectiveness through simulations and real data examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#27010;&#29575;&#20998;&#24067;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#23884;&#20837;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#26816;&#39564;&#22312;&#20998;&#31163;&#36793;&#30028;&#26041;&#38754;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#27491;&#21017;&#21270;&#30340;&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#24471;&#26816;&#39564;&#20855;&#26377;&#26356;&#23567;&#30340;&#20998;&#31163;&#36793;&#30028;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;&#26816;&#39564;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#31574;&#30053;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#23637;&#31034;&#20102;&#20854;&#36817;&#20046;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2212.09201</link><description>&lt;p&gt;
&#20855;&#26377;&#35889;&#27491;&#21017;&#21270;&#30340;&#26680;&#21452;&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Spectral Regularized Kernel Two-Sample Tests. (arXiv:2212.09201v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#27010;&#29575;&#20998;&#24067;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#23884;&#20837;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#26816;&#39564;&#22312;&#20998;&#31163;&#36793;&#30028;&#26041;&#38754;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#27491;&#21017;&#21270;&#30340;&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#24471;&#26816;&#39564;&#20855;&#26377;&#26356;&#23567;&#30340;&#20998;&#31163;&#36793;&#30028;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;&#26816;&#39564;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#31574;&#30053;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#23637;&#31034;&#20102;&#20854;&#36817;&#20046;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#19968;&#31181;&#22312;&#38750;&#21442;&#25968;&#26816;&#39564;&#38382;&#39064;&#20013;&#24191;&#21463;&#27426;&#36814;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#27010;&#29575;&#20998;&#24067;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#23884;&#20837;&#30340;&#27010;&#24565;&#26469;&#22788;&#29702;&#19968;&#33324;&#65288;&#21363;&#38750;&#27431;&#20960;&#37324;&#24471;&#65289;&#22495;&#19978;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#24037;&#20316;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#29702;&#35299;&#22522;&#20110;&#36825;&#31181;&#26041;&#27861;&#26500;&#24314;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#26368;&#20248;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27969;&#34892;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#21452;&#26679;&#26412;&#26816;&#39564;&#22312;Hellinger&#36317;&#31163;&#19979;&#30340;&#20998;&#31163;&#36793;&#30028;&#26041;&#38754;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#27491;&#21017;&#21270;&#30340;MMD&#26816;&#39564;&#20462;&#25913;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#21327;&#26041;&#24046;&#20449;&#24687;&#65288;MMD&#26816;&#39564;&#26080;&#27861;&#25429;&#33719;&#65289;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26816;&#39564;&#20855;&#26377;&#27604;MMD&#26816;&#39564;&#26356;&#23567;&#30340;&#20998;&#31163;&#36793;&#30028;&#30340;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#24615;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19978;&#36848;&#26816;&#39564;&#30340;&#33258;&#36866;&#24212;&#29256;&#26412;&#65292;&#20854;&#20013;&#28041;&#21450;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#31574;&#30053;&#26469;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#24182;&#23637;&#31034;&#20102;&#33258;&#36866;&#24212;&#26816;&#39564;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the last decade, an approach that has gained a lot of popularity to tackle non-parametric testing problems on general (i.e., non-Euclidean) domains is based on the notion of reproducing kernel Hilbert space (RKHS) embedding of probability distributions. The main goal of our work is to understand the optimality of two-sample tests constructed based on this approach. First, we show that the popular MMD (maximum mean discrepancy) two-sample test is not optimal in terms of the separation boundary measured in Hellinger distance. Second, we propose a modification to the MMD test based on spectral regularization by taking into account the covariance information (which is not captured by the MMD test) and prove the proposed test to be minimax optimal with a smaller separation boundary than that achieved by the MMD test. Third, we propose an adaptive version of the above test which involves a data-driven strategy to choose the regularization parameter and show the adaptive test to be almos
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#20108;&#27425;&#27169;&#22411;&#21487;&#20197;&#23637;&#31034;&#20986;&#31070;&#32463;&#32593;&#32476;&#22312;&#22823;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#30340;&#8220;&#24377;&#24339;&#38454;&#27573;&#8221;&#65292;&#24182;&#19988;&#22312;&#27867;&#21270;&#29305;&#24615;&#19978;&#19982;&#31070;&#32463;&#32593;&#32476;&#26377;&#30456;&#20284;&#20043;&#22788;&#65292;&#26159;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2205.11787</link><description>&lt;p&gt;
&#29992;&#20110;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#21160;&#24577;&#30340;&#20108;&#27425;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Quadratic models for understanding neural network dynamics. (arXiv:2205.11787v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11787
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20108;&#27425;&#27169;&#22411;&#21487;&#20197;&#23637;&#31034;&#20986;&#31070;&#32463;&#32593;&#32476;&#22312;&#22823;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#30340;&#8220;&#24377;&#24339;&#38454;&#27573;&#8221;&#65292;&#24182;&#19988;&#22312;&#27867;&#21270;&#29305;&#24615;&#19978;&#19982;&#31070;&#32463;&#32593;&#32476;&#26377;&#30456;&#20284;&#20043;&#22788;&#65292;&#26159;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#31070;&#32463;&#32593;&#32476;&#30340;&#23485;&#24230;&#22686;&#21152;&#26102;&#65292;&#21487;&#20197;&#29992;&#32447;&#24615;&#27169;&#22411;&#26469;&#36924;&#36817;&#31070;&#32463;&#32593;&#32476;&#65292;&#20294;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#29305;&#24615;&#19981;&#33021;&#34987;&#32447;&#24615;&#27169;&#22411;&#25429;&#25417;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#31070;&#32463;&#20108;&#27425;&#27169;&#22411;&#21487;&#20197;&#23637;&#31034;&#8220;&#24377;&#24339;&#38454;&#27573;&#8221;[Lewkowycz&#31561;&#20154;&#65292;2020]&#65292;&#24403;&#20351;&#29992;&#22823;&#23398;&#20064;&#29575;&#35757;&#32451;&#27492;&#31867;&#27169;&#22411;&#26102;&#20250;&#20986;&#29616;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#65292;&#31070;&#32463;&#20108;&#27425;&#27169;&#22411;&#30340;&#34892;&#20026;&#19982;&#31070;&#32463;&#32593;&#32476;&#22312;&#27867;&#21270;&#29305;&#24615;&#19978;&#26377;&#30456;&#20284;&#20043;&#22788;&#65292;&#23588;&#20854;&#26159;&#22312;&#24377;&#24339;&#38454;&#27573;&#33539;&#22260;&#20869;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#20108;&#27425;&#27169;&#22411;&#21487;&#20197;&#25104;&#20026;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
While neural networks can be approximated by linear models as their width increases, certain properties of wide neural networks cannot be captured by linear models. In this work we show that recently proposed Neural Quadratic Models can exhibit the "catapult phase" [Lewkowycz et al. 2020] that arises when training such models with large learning rates. We then empirically show that the behaviour of neural quadratic models parallels that of neural networks in generalization, especially in the catapult phase regime. Our analysis further demonstrates that quadratic models can be an effective tool for analysis of neural networks.
&lt;/p&gt;</description></item></channel></rss>