<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#31227;&#23398;&#20064;&#25216;&#26415;&#65292;&#21033;&#29992;&#21487;&#29992;&#25968;&#25454;&#38598;&#29983;&#25104;&#19968;&#20010;&#27169;&#22411;&#65292;&#20197;&#26816;&#27979;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#20013;&#30340;&#24120;&#35265;&#28431;&#27934;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#20197;&#24179;&#22343;&#21484;&#22238;&#29575;&#20026;72&#65285;&#26816;&#27979;C&#21644;Java&#20195;&#30721;&#20013;&#30340;&#28431;&#27934;&#12290;</title><link>http://arxiv.org/abs/2303.06177</link><description>&lt;p&gt;
&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#36719;&#20214;&#28431;&#27934;&#39044;&#27979;&#30693;&#35782;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Software Vulnerability Prediction Knowledge Transferring Between Programming Languages. (arXiv:2303.06177v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#31227;&#23398;&#20064;&#25216;&#26415;&#65292;&#21033;&#29992;&#21487;&#29992;&#25968;&#25454;&#38598;&#29983;&#25104;&#19968;&#20010;&#27169;&#22411;&#65292;&#20197;&#26816;&#27979;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#20013;&#30340;&#24120;&#35265;&#28431;&#27934;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#20197;&#24179;&#22343;&#21484;&#22238;&#29575;&#20026;72&#65285;&#26816;&#27979;C&#21644;Java&#20195;&#30721;&#20013;&#30340;&#28431;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study proposes a transfer learning technique to detect common vulnerabilities in different programming languages by leveraging available datasets. The results show that the proposed model detects vulnerabilities in both C and Java codes with an average recall of 72%.
&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#33258;&#21160;&#21270;&#21644;&#26234;&#33021;&#30340;&#36719;&#20214;&#28431;&#27934;&#26816;&#27979;&#27169;&#22411;&#19968;&#30452;&#21463;&#21040;&#30740;&#31350;&#21644;&#24320;&#21457;&#31038;&#21306;&#30340;&#20851;&#27880;&#12290;&#36825;&#20010;&#39046;&#22495;&#26368;&#22823;&#30340;&#25361;&#25112;&#20043;&#19968;&#26159;&#32570;&#20047;&#25152;&#26377;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#30340;&#20195;&#30721;&#26679;&#26412;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#36716;&#31227;&#23398;&#20064;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21033;&#29992;&#21487;&#29992;&#25968;&#25454;&#38598;&#29983;&#25104;&#19968;&#20010;&#27169;&#22411;&#65292;&#20197;&#26816;&#27979;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#20013;&#30340;&#24120;&#35265;&#28431;&#27934;&#12290;&#25105;&#20204;&#20351;&#29992;C&#28304;&#20195;&#30721;&#26679;&#26412;&#35757;&#32451;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#27169;&#22411;&#65292;&#28982;&#21518;&#20351;&#29992;Java&#28304;&#20195;&#30721;&#26679;&#26412;&#26469;&#37319;&#29992;&#21644;&#35780;&#20272;&#23398;&#20064;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#20195;&#30721;&#26679;&#26412;&#65306;NIST&#36719;&#20214;&#20445;&#38556;&#21442;&#32771;&#25968;&#25454;&#38598;&#65288;SARD&#65289;&#21644;Draper VDISC&#25968;&#25454;&#38598;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#20197;&#24179;&#22343;&#21484;&#22238;&#29575;&#20026;72&#65285;&#26816;&#27979;C&#21644;Java&#20195;&#30721;&#20013;&#30340;&#28431;&#27934;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#21487;&#35299;&#37322;&#30340;AI&#26469;&#35843;&#26597;&#27599;&#20010;&#29305;&#24449;&#23545;&#30693;&#35782;&#36716;&#31227;&#26426;&#21046;&#30340;&#36129;&#29486;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Developing automated and smart software vulnerability detection models has been receiving great attention from both research and development communities. One of the biggest challenges in this area is the lack of code samples for all different programming languages. In this study, we address this issue by proposing a transfer learning technique to leverage available datasets and generate a model to detect common vulnerabilities in different programming languages. We use C source code samples to train a Convolutional Neural Network (CNN) model, then, we use Java source code samples to adopt and evaluate the learned model. We use code samples from two benchmark datasets: NIST Software Assurance Reference Dataset (SARD) and Draper VDISC dataset. The results show that proposed model detects vulnerabilities in both C and Java codes with average recall of 72\%. Additionally, we employ explainable AI to investigate how much each feature contributes to the knowledge transfer mechanisms between 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#37327;&#35282;&#33394;&#30340;&#26080;&#30417;&#30563;&#29305;&#24449;&#22686;&#24378;&#26041;&#27861;&#23545;&#20195;&#30721;&#31070;&#32463;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#22312;&#25968;&#25454;&#38598;&#31243;&#24207;&#20013;&#28155;&#21152;&#21333;&#20010;&#21464;&#37327;&#30340;&#35282;&#33394;&#26469;&#20016;&#23500;&#28304;&#20195;&#30721;&#25968;&#25454;&#38598;&#65292;&#24182;&#22240;&#27492;&#23545;&#21464;&#37327;&#35282;&#33394;&#22686;&#24378;&#22312;&#35757;&#32451;Code2Seq&#27169;&#22411;&#20013;&#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2303.04942</link><description>&lt;p&gt;
&#20195;&#30721;&#31070;&#32463;&#27169;&#22411;&#20013;&#22522;&#20110;&#21464;&#37327;&#35282;&#33394;&#30340;&#29305;&#24449;&#22686;&#24378;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Study of Variable-Role-based Feature Enrichment in Neural Models of Code. (arXiv:2303.04942v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#37327;&#35282;&#33394;&#30340;&#26080;&#30417;&#30563;&#29305;&#24449;&#22686;&#24378;&#26041;&#27861;&#23545;&#20195;&#30721;&#31070;&#32463;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#22312;&#25968;&#25454;&#38598;&#31243;&#24207;&#20013;&#28155;&#21152;&#21333;&#20010;&#21464;&#37327;&#30340;&#35282;&#33394;&#26469;&#20016;&#23500;&#28304;&#20195;&#30721;&#25968;&#25454;&#38598;&#65292;&#24182;&#22240;&#27492;&#23545;&#21464;&#37327;&#35282;&#33394;&#22686;&#24378;&#22312;&#35757;&#32451;Code2Seq&#27169;&#22411;&#20013;&#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the impact of an unsupervised feature enrichment approach based on variable roles on the performance of neural models of code, and enriches a source code dataset by adding the role of individual variables in the dataset programs, thereby conducting a study on the impact of variable role enrichment in training the Code2Seq model.
&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#27169;&#22411;&#22823;&#22823;&#20943;&#23569;&#20102;&#29305;&#24449;&#24037;&#31243;&#30340;&#24320;&#38144;&#65292;&#20294;&#36755;&#20837;&#20013;&#21487;&#29992;&#30340;&#29305;&#24449;&#21487;&#33021;&#20250;&#26174;&#33879;&#24433;&#21709;&#27169;&#22411;&#30340;&#35757;&#32451;&#25104;&#26412;&#21644;&#24615;&#33021;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#37327;&#35282;&#33394;&#30340;&#26080;&#30417;&#30563;&#29305;&#24449;&#22686;&#24378;&#26041;&#27861;&#23545;&#20195;&#30721;&#31070;&#32463;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#21464;&#37327;&#35282;&#33394;&#30340;&#27010;&#24565;&#65288;&#22914;Sajaniemi&#31561;&#20154;&#30340;&#20316;&#21697;&#20013;&#25152;&#20171;&#32461;&#30340;&#65289;&#24050;&#34987;&#21457;&#29616;&#26377;&#21161;&#20110;&#23398;&#29983;&#30340;&#32534;&#31243;&#33021;&#21147;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#20010;&#27010;&#24565;&#26159;&#21542;&#20250;&#25552;&#39640;&#20195;&#30721;&#31070;&#32463;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#31687;&#30740;&#31350;Sajaniemi&#31561;&#20154;&#30340;&#21464;&#37327;&#35282;&#33394;&#27010;&#24565;&#22914;&#20309;&#24433;&#21709;&#20195;&#30721;&#31070;&#32463;&#27169;&#22411;&#30340;&#24037;&#20316;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#25968;&#25454;&#38598;&#31243;&#24207;&#20013;&#28155;&#21152;&#21333;&#20010;&#21464;&#37327;&#30340;&#35282;&#33394;&#26469;&#20016;&#23500;&#28304;&#20195;&#30721;&#25968;&#25454;&#38598;&#65292;&#24182;&#22240;&#27492;&#23545;&#21464;&#37327;&#35282;&#33394;&#22686;&#24378;&#22312;&#35757;&#32451;Code2Seq&#27169;&#22411;&#20013;&#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although deep neural models substantially reduce the overhead of feature engineering, the features readily available in the inputs might significantly impact training cost and the performance of the models. In this paper, we explore the impact of an unsuperivsed feature enrichment approach based on variable roles on the performance of neural models of code. The notion of variable roles (as introduced in the works of Sajaniemi et al. [Refs. 1,2]) has been found to help students' abilities in programming. In this paper, we investigate if this notion would improve the performance of neural models of code. To the best of our knowledge, this is the first work to investigate how Sajaniemi et al.'s concept of variable roles can affect neural models of code. In particular, we enrich a source code dataset by adding the role of individual variables in the dataset programs, and thereby conduct a study on the impact of variable role enrichment in training the Code2Seq model. In addition, we shed l
&lt;/p&gt;</description></item></channel></rss>