<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#22686;&#24378;&#24037;&#20316;&#25512;&#33616;&#12290;&#36890;&#36807;&#21033;&#29992;LLMs&#20016;&#23500;&#30340;&#22806;&#37096;&#30693;&#35782;&#21644;&#25991;&#26412;&#22788;&#29702;&#33021;&#21147;&#65292;&#21487;&#20197;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#38656;&#35201;&#35299;&#20915;LLMs&#34394;&#26500;&#29983;&#25104;&#21644;&#23569;&#26679;&#26412;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.10747</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;LLM&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#22686;&#24378;&#24037;&#20316;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Enhancing Job Recommendation through LLM-based Generative Adversarial Networks. (arXiv:2307.10747v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10747
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#22686;&#24378;&#24037;&#20316;&#25512;&#33616;&#12290;&#36890;&#36807;&#21033;&#29992;LLMs&#20016;&#23500;&#30340;&#22806;&#37096;&#30693;&#35782;&#21644;&#25991;&#26412;&#22788;&#29702;&#33021;&#21147;&#65292;&#21487;&#20197;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#38656;&#35201;&#35299;&#20915;LLMs&#34394;&#26500;&#29983;&#25104;&#21644;&#23569;&#26679;&#26412;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#25307;&#32856;&#24179;&#21488;&#19978;&#21521;&#29992;&#25143;&#25512;&#33616;&#21512;&#36866;&#30340;&#24037;&#20316;&#26159;&#19968;&#20010;&#20851;&#38190;&#20219;&#21153;&#65292;&#21487;&#20197;&#25552;&#39640;&#29992;&#25143;&#28385;&#24847;&#24230;&#21644;&#24179;&#21488;&#30340;&#30408;&#21033;&#33021;&#21147;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#25512;&#33616;&#26041;&#27861;&#38754;&#20020;&#30340;&#25361;&#25112;&#21253;&#25324;&#29992;&#25143;&#31616;&#21382;&#30340;&#20302;&#36136;&#37327;&#65292;&#24433;&#21709;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#23454;&#38469;&#25928;&#26524;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#21033;&#29992;&#20854;&#20013;&#21253;&#21547;&#30340;&#20016;&#23500;&#22806;&#37096;&#30693;&#35782;&#20197;&#21450;&#23427;&#20204;&#24378;&#22823;&#30340;&#25991;&#26412;&#22788;&#29702;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#26159;&#23454;&#29616;&#26356;&#20934;&#30830;&#30340;&#25512;&#33616;&#30340;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#21033;&#29992;LLMs&#26469;&#22686;&#24378;&#25512;&#33616;&#32467;&#26524;&#24182;&#38750;&#36866;&#29992;&#20110;&#25152;&#26377;&#24773;&#20917;&#65292;&#22240;&#20026;LLMs&#21487;&#33021;&#23384;&#22312;&#34394;&#26500;&#29983;&#25104;&#21644;&#23569;&#26679;&#26412;&#38382;&#39064;&#65292;&#38477;&#20302;&#20102;&#31616;&#21382;&#23436;&#25104;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;LLM&#30340;&#24037;&#20316;&#25512;&#33616;&#26041;&#27861;&#12290;&#20026;&#20102;&#32531;&#35299;LLMs&#34394;&#26500;&#29983;&#25104;&#30340;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#21462;&#20934;&#30830;&#21644;&#26377;&#20215;&#20540;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommending suitable jobs to users is a critical task in online recruitment platforms, as it can enhance users' satisfaction and the platforms' profitability. While existing job recommendation methods encounter challenges such as the low quality of users' resumes, which hampers their accuracy and practical effectiveness. With the rapid development of large language models (LLMs), utilizing the rich external knowledge encapsulated within them, as well as their powerful capabilities of text processing and reasoning, is a promising way to complete users' resumes for more accurate recommendations. However, directly leveraging LLMs to enhance recommendation results is not a one-size-fits-all solution, as LLMs may suffer from fabricated generation and few-shot problems, which degrade the quality of resume completion. In this paper, we propose a novel LLM-based approach for job recommendation. To alleviate the limitation of fabricated generation for LLMs, we extract accurate and valuable inf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;RDF&#30693;&#35782;&#22270;&#30340;&#32422;&#26463;&#25512;&#33616;&#31995;&#32479;&#65292;&#24212;&#29992;&#20110;&#36710;&#36742;&#36141;&#20080;/&#38144;&#21806;&#39046;&#22495;&#65292;&#36890;&#36807;&#26174;&#24335;&#21033;&#29992;&#32422;&#26463;&#21644;&#30693;&#35782;&#22270;&#30340;&#32467;&#21512;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#26681;&#25454;&#29992;&#25143;&#30340;&#20559;&#22909;&#35782;&#21035;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2307.10702</link><description>&lt;p&gt;
&#22522;&#20110;RDF&#30693;&#35782;&#22270;&#30340;&#32422;&#26463;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Constraint-based Recommender System via RDF Knowledge Graphs. (arXiv:2307.10702v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;RDF&#30693;&#35782;&#22270;&#30340;&#32422;&#26463;&#25512;&#33616;&#31995;&#32479;&#65292;&#24212;&#29992;&#20110;&#36710;&#36742;&#36141;&#20080;/&#38144;&#21806;&#39046;&#22495;&#65292;&#36890;&#36807;&#26174;&#24335;&#21033;&#29992;&#32422;&#26463;&#21644;&#30693;&#35782;&#22270;&#30340;&#32467;&#21512;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#26681;&#25454;&#29992;&#25143;&#30340;&#20559;&#22909;&#35782;&#21035;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#20197;RDF&#24418;&#24335;&#34920;&#31034;&#65292;&#33021;&#22815;&#36890;&#36807;&#26412;&#20307;&#27169;&#22411;&#26469;&#24314;&#27169;&#23454;&#20307;&#21450;&#20854;&#20851;&#31995;&#12290;&#36817;&#24180;&#26469;&#65292;&#30693;&#35782;&#22270;&#22312;&#20449;&#24687;&#24314;&#27169;&#26041;&#38754;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#29289;&#21697;&#21644;&#29992;&#25143;&#21487;&#20197;&#34987;&#26144;&#23556;&#21644;&#38598;&#25104;&#21040;&#30693;&#35782;&#22270;&#20013;&#65292;&#20174;&#32780;&#21487;&#20197;&#34920;&#31034;&#29992;&#25143;&#21644;&#29289;&#21697;&#20043;&#38388;&#26356;&#22810;&#30340;&#38142;&#25509;&#21644;&#20851;&#31995;&#12290;&#22522;&#20110;&#32422;&#26463;&#30340;&#25512;&#33616;&#31995;&#32479;&#22522;&#20110;&#26174;&#24335;&#21033;&#29992;&#32422;&#26463;&#26469;&#28145;&#20837;&#25366;&#25496;&#25512;&#33616;&#30693;&#35782;&#65292;&#24182;&#35782;&#21035;&#30456;&#20851;&#30340;&#25512;&#33616;&#12290;&#24403;&#32467;&#21512;&#30693;&#35782;&#22270;&#26102;&#65292;&#22522;&#20110;&#32422;&#26463;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#32422;&#26463;&#38598;&#26041;&#38754;&#33719;&#24471;&#20102;&#22810;&#20010;&#20248;&#21183;&#12290;&#26412;&#25991;&#30740;&#31350;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;RDF&#30693;&#35782;&#22270;&#24212;&#29992;&#20110;&#36710;&#36742;&#36141;&#20080;/&#38144;&#21806;&#39046;&#22495;&#30340;&#32422;&#26463;&#25512;&#33616;&#31995;&#32479;&#30340;&#26500;&#24314;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#26681;&#25454;&#29992;&#25143;&#30340;&#20559;&#22909;&#35782;&#21035;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graphs, represented in RDF, are able to model entities and their relations by means of ontologies. The use of knowledge graphs for information modeling has attracted interest in recent years. In recommender systems, items and users can be mapped and integrated into the knowledge graph, which can represent more links and relationships between users and items. Constraint-based recommender systems are based on the idea of explicitly exploiting deep recommendation knowledge through constraints to identify relevant recommendations. When combined with knowledge graphs, a constraint-based recommender system gains several benefits in terms of constraint sets. In this paper, we investigate and propose the construction of a constraint-based recommender system via RDF knowledge graphs applied to the vehicle purchase/sale domain. The results of our experiments show that the proposed approach is able to efficiently identify recommendations in accordance with user preferences.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#26500;&#24314;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#65292;&#22312;&#36710;&#36742;&#36141;&#20080;/&#38144;&#21806;&#39046;&#22495;&#20013;&#23637;&#29616;&#20102;&#20854;&#33391;&#22909;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.10680</link><description>&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Personalized Recommender System Based-on Knowledge Graph Embeddings. (arXiv:2307.10680v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#26500;&#24314;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#65292;&#22312;&#36710;&#36742;&#36141;&#20080;/&#38144;&#21806;&#39046;&#22495;&#20013;&#23637;&#29616;&#20102;&#20854;&#33391;&#22909;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#36890;&#36807;&#26412;&#20307;&#35770;&#23545;&#23454;&#20307;&#21450;&#20854;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#65292;&#24050;&#34987;&#35777;&#26126;&#22312;&#20449;&#24687;&#24314;&#27169;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#23545;&#23558;&#30693;&#35782;&#22270;&#35889;&#29992;&#20316;&#20449;&#24687;&#24314;&#27169;&#30340;&#20852;&#36259;&#19981;&#26029;&#22686;&#38271;&#65292;&#22240;&#27492;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#20063;&#36234;&#26469;&#36234;&#24191;&#27867;&#12290;&#36890;&#36807;&#23558;&#29992;&#25143;&#21644;&#29289;&#21697;&#32435;&#20837;&#30693;&#35782;&#22270;&#35889;&#65292;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#23427;&#20204;&#20043;&#38388;&#30340;&#38544;&#21547;&#20851;&#32852;&#24182;&#25552;&#20379;&#26356;&#20934;&#30830;&#30340;&#25512;&#33616;&#12290;&#26412;&#25991;&#36890;&#36807;&#24212;&#29992;&#20110;&#36710;&#36742;&#36141;&#20080;/&#38144;&#21806;&#39046;&#22495;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#30740;&#31350;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#30340;&#26500;&#24314;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#19982;&#20010;&#20307;&#29992;&#25143;&#19968;&#33268;&#30340;&#30456;&#20851;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graphs have proven to be effective for modeling entities and their relationships through the use of ontologies. The recent emergence in interest for using knowledge graphs as a form of information modeling has led to their increased adoption in recommender systems. By incorporating users and items into the knowledge graph, these systems can better capture the implicit connections between them and provide more accurate recommendations. In this paper, we investigate and propose the construction of a personalized recommender system via knowledge graphs embedding applied to the vehicle purchase/sale domain. The results of our experimentation demonstrate the efficacy of the proposed method in providing relevant recommendations that are consistent with individual users.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#35299;&#32806;&#23545;&#27604;&#23398;&#20064;&#21644;&#22810;&#27169;&#24577;&#26041;&#27861;&#26469;&#35299;&#20915;&#27969;&#34892;&#20559;&#35265;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#25991;&#26412;&#20869;&#23481;&#21644;&#29289;&#21697;ID&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#25552;&#21462;&#29305;&#24449;&#65292;&#21516;&#26102;&#23398;&#20064;&#36890;&#29992;&#29289;&#21697;&#34920;&#31034;&#65292;&#20174;&#32780;&#25552;&#39640;&#35821;&#35328;&#34920;&#31034;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.10650</link><description>&lt;p&gt;
&#36890;&#36807;&#35299;&#32806;&#23545;&#27604;&#23398;&#20064;&#26469;&#22686;&#24378;&#35821;&#35328;&#22686;&#24378;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Language-Enhanced Session-Based Recommendation with Decoupled Contrastive Learning. (arXiv:2307.10650v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#35299;&#32806;&#23545;&#27604;&#23398;&#20064;&#21644;&#22810;&#27169;&#24577;&#26041;&#27861;&#26469;&#35299;&#20915;&#27969;&#34892;&#20559;&#35265;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#25991;&#26412;&#20869;&#23481;&#21644;&#29289;&#21697;ID&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#25552;&#21462;&#29305;&#24449;&#65292;&#21516;&#26102;&#23398;&#20064;&#36890;&#29992;&#29289;&#21697;&#34920;&#31034;&#65292;&#20174;&#32780;&#25552;&#39640;&#35821;&#35328;&#34920;&#31034;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#25216;&#26415;&#26088;&#22312;&#36890;&#36807;&#20998;&#26512;&#36807;&#21435;&#30340;&#20132;&#20114;&#26469;&#25429;&#25417;&#21160;&#24577;&#29992;&#25143;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#21382;&#21490;&#29289;&#21697;ID&#24207;&#21015;&#20197;&#25552;&#21462;&#29992;&#25143;&#20559;&#22909;&#65292;&#23548;&#33268;&#20102;&#27969;&#34892;&#20559;&#35265;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#31561;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#22810;&#27169;&#24577;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#30340;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#19981;&#21516;&#30340;&#27169;&#24577;&#65292;&#21253;&#25324;&#25991;&#26412;&#20869;&#23481;&#21644;&#29289;&#21697;ID&#65292;&#21033;&#29992;CatBoost&#21033;&#29992;&#36825;&#20123;&#27169;&#24577;&#30340;&#20114;&#34917;&#24615;&#12290;&#20026;&#20102;&#23398;&#20064;&#36890;&#29992;&#29289;&#21697;&#34920;&#31034;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#34920;&#31034;&#30340;&#29289;&#21697;&#26816;&#32034;&#26550;&#26500;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20174;&#25991;&#26412;&#20869;&#23481;&#20013;&#25552;&#21462;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35299;&#32806;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#26469;&#22686;&#24378;&#35821;&#35328;&#34920;&#31034;&#30340;&#26377;&#25928;&#24615;&#12290;&#36825;&#31181;&#25216;&#26415;&#35299;&#32806;&#20102;&#24207;&#21015;&#34920;&#31034;&#21644;&#29289;&#21697;&#34920;&#31034;&#31354;&#38388;&#65292;&#20419;&#36827;&#21452;&#21521;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Session-based recommendation techniques aim to capture dynamic user behavior by analyzing past interactions. However, existing methods heavily rely on historical item ID sequences to extract user preferences, leading to challenges such as popular bias and cold-start problems. In this paper, we propose a hybrid multimodal approach for session-based recommendation to address these challenges. Our approach combines different modalities, including textual content and item IDs, leveraging the complementary nature of these modalities using CatBoost. To learn universal item representations, we design a language representation-based item retrieval architecture that extracts features from the textual content utilizing pre-trained language models. Furthermore, we introduce a novel Decoupled Contrastive Learning method to enhance the effectiveness of the language representation. This technique decouples the sequence representation and item representation space, facilitating bidirectional alignmen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#20013;&#35821;&#20041;&#30456;&#20284;&#24230;&#35745;&#31639;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#22312;&#22788;&#29702;&#25991;&#26412;&#25968;&#25454;&#26102;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.10639</link><description>&lt;p&gt;
&#22312;&#22522;&#20110;RDF&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#25913;&#36827;&#35821;&#20041;&#30456;&#20284;&#24230;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
Improving Semantic Similarity Measure Within a Recommender System Based-on RDF Graphs. (arXiv:2307.10639v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#20013;&#35821;&#20041;&#30456;&#20284;&#24230;&#35745;&#31639;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#22312;&#22788;&#29702;&#25991;&#26412;&#25968;&#25454;&#26102;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20170;&#20449;&#24687;&#29190;&#28856;&#30340;&#26102;&#20195;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#29992;&#25143;&#20381;&#36182;&#25512;&#33616;&#31995;&#32479;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#24314;&#35758;&#12289;&#25512;&#33616;&#25110;&#28789;&#24863;&#12290;&#35821;&#20041;&#30456;&#20851;&#24615;&#25110;&#30456;&#20284;&#24615;&#30340;&#27979;&#37327;&#22312;&#22788;&#29702;&#25991;&#26412;&#25968;&#25454;&#30340;&#19981;&#21516;&#24212;&#29992;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#65292;&#23601;&#20687;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#19968;&#26679;&#12290;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#35768;&#22810;&#26412;&#20307;&#35770;&#24050;&#34987;&#24320;&#21457;&#24182;&#29992;&#20316;&#20449;&#24687;&#31995;&#32479;&#20013;&#30693;&#35782;&#24211;&#30340;&#32467;&#26500;&#21270;&#34920;&#31034;&#24418;&#24335;&#12290;&#26412;&#25991;&#25552;&#20986;&#24182;&#23454;&#26045;&#20102;&#19968;&#31181;&#22312;&#22522;&#20110;RDF&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#25913;&#36827;&#35821;&#20041;&#30456;&#20284;&#24230;&#35745;&#31639;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's era of information explosion, more users are becoming more reliant upon recommender systems to have better advice, suggestions, or inspire them. The measure of the semantic relatedness or likeness between terms, words, or text data plays an important role in different applications dealing with textual data, as in a recommender system. Over the past few years, many ontologies have been developed and used as a form of structured representation of knowledge bases for information systems. The measure of semantic similarity from ontology has developed by several methods. In this paper, we propose and carry on an approach for the improvement of semantic similarity calculations within a recommender system based-on RDF graphs.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#65292;&#24182;&#36890;&#36807;&#22312;&#39184;&#39302;&#35780;&#35770;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.10617</link><description>&lt;p&gt;
&#20351;&#29992;&#25991;&#26412;&#20998;&#31867;&#26816;&#27979;&#34394;&#20551;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10617
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#65292;&#24182;&#36890;&#36807;&#22312;&#39184;&#39302;&#35780;&#35770;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22312;&#32447;&#35780;&#35770;&#22312;&#25512;&#24191;&#20219;&#20309;&#20135;&#21697;&#25110;&#26381;&#21153;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20225;&#19994;&#21487;&#33021;&#20250;&#23884;&#20837;&#34394;&#20551;&#35780;&#35770;&#20197;&#21560;&#24341;&#23458;&#25143;&#36141;&#20080;&#20182;&#20204;&#30340;&#20135;&#21697;&#12290;&#20182;&#20204;&#29978;&#33267;&#21487;&#33021;&#31361;&#20986;&#24378;&#35843;&#33258;&#24049;&#20135;&#21697;&#30340;&#20248;&#28857;&#25110;&#25209;&#35780;&#31454;&#20105;&#23545;&#25163;&#30340;&#20135;&#21697;&#12290;&#24066;&#22330;&#33829;&#38144;&#20154;&#21592;&#12289;&#24191;&#21578;&#21830;&#21644;&#20854;&#20182;&#22312;&#32447;&#21830;&#19994;&#29992;&#25143;&#26377;&#21160;&#26426;&#20026;&#20182;&#20204;&#24819;&#35201;&#25512;&#24191;&#30340;&#20135;&#21697;&#32534;&#20889;&#34394;&#20551;&#30340;&#27491;&#38754;&#35780;&#35770;&#65292;&#25110;&#32773;&#20026;&#20182;&#20204;&#30495;&#27491;&#19981;&#21916;&#27426;&#30340;&#20135;&#21697;&#25552;&#20379;&#34394;&#20551;&#30340;&#36127;&#38754;&#35780;&#35770;&#12290;&#22240;&#27492;&#65292;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#26159;&#19968;&#20010;&#32039;&#36843;&#19988;&#25345;&#32493;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#30740;&#31350;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#12290;&#35770;&#25991;&#35843;&#26597;&#20102;&#22312;&#19968;&#20010;&#39184;&#39302;&#35780;&#35770;&#30340;&#34394;&#20551;&#24847;&#35265;&#22403;&#22334;&#35821;&#26009;&#24211;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22810;&#27425;&#23454;&#39564;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;n-gram&#27169;&#22411;&#21644;&#26368;&#22823;&#29305;&#24449;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, online reviews play a vital role for promoting any kind of product or services. Businesses may embed fake reviews in order to attract customers to purchase their products. They may even highlight the benefits of their own product or criticize the competition's product. Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like. So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation. Thus, identifying deceptive reviews is an intense and on-going research area. This research paper proposes machine learning model approach to identify deceptive reviews. The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews. We developed a n-gram model and max features to identify 
&lt;/p&gt;</description></item><item><title>SPRINT&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;Python&#24037;&#20855;&#21253;&#65292;&#22522;&#20110;Pyserini&#21644;Lucene&#65292;&#25903;&#25345;&#35780;&#20272;&#21644;&#35299;&#26512;&#38646;&#26679;&#26412;&#31070;&#32463;&#31232;&#30095;&#26816;&#32034;&#12290;&#23427;&#35299;&#20915;&#20102;&#32570;&#20047;&#32479;&#19968;&#29615;&#22659;&#21644;&#23454;&#29616;&#22312;&#26410;&#35265;&#36807;&#39046;&#22495;&#19978;&#30340;&#26816;&#32034;&#33021;&#21147;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.10488</link><description>&lt;p&gt;
SPRINT: &#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#21644;&#35299;&#26512;&#38646;&#26679;&#26412;&#31070;&#32463;&#31232;&#30095;&#26816;&#32034;&#30340;&#32479;&#19968;&#24037;&#20855;&#21253;
&lt;/p&gt;
&lt;p&gt;
SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval. (arXiv:2307.10488v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10488
&lt;/p&gt;
&lt;p&gt;
SPRINT&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;Python&#24037;&#20855;&#21253;&#65292;&#22522;&#20110;Pyserini&#21644;Lucene&#65292;&#25903;&#25345;&#35780;&#20272;&#21644;&#35299;&#26512;&#38646;&#26679;&#26412;&#31070;&#32463;&#31232;&#30095;&#26816;&#32034;&#12290;&#23427;&#35299;&#20915;&#20102;&#32570;&#20047;&#32479;&#19968;&#29615;&#22659;&#21644;&#23454;&#29616;&#22312;&#26410;&#35265;&#36807;&#39046;&#22495;&#19978;&#30340;&#26816;&#32034;&#33021;&#21147;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#31232;&#30095;&#26816;&#32034;&#31995;&#32479;&#20381;&#36182;&#20110;&#35789;&#27719;&#34920;&#31034;&#26469;&#26816;&#32034;&#25991;&#26723;&#65292;&#22914;BM25&#65292;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#21344;&#20027;&#23548;&#22320;&#20301;&#12290;&#38543;&#30528;&#35832;&#22914;BERT&#36825;&#26679;&#30340;&#39044;&#35757;&#32451;transformer&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#31070;&#32463;&#31232;&#30095;&#26816;&#32034;&#24341;&#39046;&#20102;&#26816;&#32034;&#20013;&#30340;&#26032;&#33539;&#24335;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#30446;&#21069;&#32570;&#20047;&#25903;&#25345;&#19981;&#21516;&#31232;&#30095;&#26816;&#32034;&#22120;&#22312;&#32479;&#19968;&#30340;&#29615;&#22659;&#20013;&#36816;&#34892;&#30340;&#36719;&#20214;&#12290;&#36825;&#22952;&#30861;&#20102;&#23454;&#36341;&#32773;&#20844;&#27491;&#22320;&#27604;&#36739;&#19981;&#21516;&#30340;&#31232;&#30095;&#27169;&#22411;&#65292;&#24182;&#33719;&#24471;&#30495;&#23454;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;&#36824;&#26377;&#19968;&#20010;&#32570;&#22833;&#30340;&#37096;&#20998;&#26159;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#24037;&#20316;&#26159;&#23545;&#31232;&#30095;&#26816;&#32034;&#27169;&#22411;&#36827;&#34892;&#22495;&#20869;&#26816;&#32034;&#35780;&#20272;&#65292;&#21363;&#20165;&#22312;&#19968;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35780;&#20272;&#65306;MS MARCO&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#26816;&#32034;&#31995;&#32479;&#20013;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#35201;&#27714;&#26159;&#27169;&#22411;&#33021;&#22815;&#22312;&#26410;&#35265;&#36807;&#30340;&#22495;&#22806;&#65292;&#21363;&#38646;&#26679;&#26412;&#26816;&#32034;&#20219;&#21153;&#20013;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;SPRINT&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;Pyserini&#21644;Lucene&#30340;&#32479;&#19968;Python&#24037;&#20855;&#21253;&#65292;&#25903;&#25345;&#31070;&#32463;&#31232;&#30095;&#26816;&#32034;&#30340;&#36890;&#29992;&#25509;&#21475;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditionally, sparse retrieval systems relied on lexical representations to retrieve documents, such as BM25, dominated information retrieval tasks. With the onset of pre-trained transformer models such as BERT, neural sparse retrieval has led to a new paradigm within retrieval. Despite the success, there has been limited software supporting different sparse retrievers running in a unified, common environment. This hinders practitioners from fairly comparing different sparse models and obtaining realistic evaluation results. Another missing piece is, that a majority of prior work evaluates sparse retrieval models on in-domain retrieval, i.e. on a single dataset: MS MARCO. However, a key requirement in practical retrieval systems requires models that can generalize well to unseen out-of-domain, i.e. zero-shot retrieval tasks. In this work, we provide SPRINT, a unified Python toolkit based on Pyserini and Lucene, supporting a common interface for evaluating neural sparse retrieval. The 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21160;&#24577;&#25506;&#32034;&#22270;&#65288;DEG&#65289;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#36830;&#32493;&#32454;&#21270;&#21644;&#22270;&#26500;&#24314;&#36807;&#31243;&#65292;&#36798;&#21040;&#20102;&#22312;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#25552;&#39640;&#25628;&#32034;&#25928;&#29575;&#12289;&#39044;&#27979;&#32034;&#24341;&#22823;&#23567;&#12289;&#20445;&#25345;&#36830;&#36890;&#24615;&#21644;&#21160;&#24577;&#22270;&#32467;&#26500;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.10479</link><description>&lt;p&gt;
&#20351;&#29992;&#36830;&#32493;&#32454;&#21270;&#30340;&#21160;&#24577;&#25506;&#32034;&#22270;&#36827;&#34892;&#24555;&#36895;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Fast Approximate Nearest Neighbor Search with a Dynamic Exploration Graph using Continuous Refinement. (arXiv:2307.10479v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21160;&#24577;&#25506;&#32034;&#22270;&#65288;DEG&#65289;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#36830;&#32493;&#32454;&#21270;&#21644;&#22270;&#26500;&#24314;&#36807;&#31243;&#65292;&#36798;&#21040;&#20102;&#22312;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#25552;&#39640;&#25628;&#32034;&#25928;&#29575;&#12289;&#39044;&#27979;&#32034;&#24341;&#22823;&#23567;&#12289;&#20445;&#25345;&#36830;&#36890;&#24615;&#21644;&#21160;&#24577;&#22270;&#32467;&#26500;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#65292;&#22522;&#20110;&#22270;&#30340;&#31639;&#27861;&#22312;&#31934;&#24230;&#21644;&#25628;&#32034;&#26102;&#38388;&#20043;&#38388;&#25552;&#20379;&#20102;&#26368;&#20339;&#30340;&#25240;&#34935;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21160;&#24577;&#25506;&#32034;&#22270;&#65288;DEG&#65289;&#65292;&#36890;&#36807;&#32467;&#21512;&#20004;&#20010;&#26032;&#24605;&#24819;&#65292;&#22312;&#25628;&#32034;&#21644;&#25506;&#32034;&#25928;&#29575;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65306;&#39318;&#20808;&#65292;&#36890;&#36807;&#37096;&#20998;&#26367;&#25442;&#29616;&#26377;&#36793;&#26469;&#22686;&#37327;&#26500;&#24314;&#19968;&#20010;&#21333;&#20010;&#30340;&#26080;&#21521;&#20598;&#27491;&#21017;&#22270;&#65292;&#20197;&#21516;&#26102;&#25972;&#21512;&#26032;&#39030;&#28857;&#21644;&#26356;&#26032;&#26087;&#37051;&#22495;&#12290;&#20854;&#27425;&#65292;&#20351;&#29992;&#36793;&#20248;&#21270;&#31639;&#27861;&#36830;&#32493;&#25913;&#21892;&#22270;&#30340;&#36136;&#37327;&#12290;&#23558;&#36825;&#31181;&#25345;&#32493;&#32454;&#21270;&#19982;&#22270;&#26500;&#24314;&#36807;&#31243;&#30456;&#32467;&#21512;&#65292;&#22987;&#32456;&#20445;&#25345;&#33391;&#22909;&#32452;&#32455;&#30340;&#22270;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#65306;&#65288;1&#65289;&#25552;&#39640;&#25628;&#32034;&#25928;&#29575;&#65292;&#65288;2&#65289;&#39044;&#27979;&#32034;&#24341;&#22823;&#23567;&#65292;&#65288;3&#65289;&#20445;&#35777;&#25152;&#26377;&#39030;&#28857;&#30340;&#36830;&#36890;&#24615;&#21644;&#21487;&#36798;&#24615;&#65292;&#20197;&#21450;&#65288;4&#65289;&#21160;&#24577;&#22270;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#29616;&#26377;&#22522;&#20110;&#22270;&#30340;&#25628;&#32034;&#31995;&#32479;&#22312;&#22788;&#29702;&#32034;&#24341;&#26597;&#35810;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
For approximate nearest neighbor search, graph-based algorithms have shown to offer the best trade-off between accuracy and search time. We propose the Dynamic Exploration Graph (DEG) which significantly outperforms existing algorithms in terms of search and exploration efficiency by combining two new ideas: First, a single undirected even regular graph is incrementally built by partially replacing existing edges to integrate new vertices and to update old neighborhoods at the same time. Secondly, an edge optimization algorithm is used to continuously improve the quality of the graph. Combining this ongoing refinement with the graph construction process leads to a well-organized graph structure at all times, resulting in: (1) increased search efficiency, (2) predictable index size, (3) guaranteed connectivity and therefore reachability of all vertices, and (4) a dynamic graph structure. In addition we investigate how well existing graph-based search systems can handle indexed queries w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#19987;&#21033;&#22270;&#20687;&#20013;&#21487;&#35270;&#21270;&#31867;&#22411;&#21644;&#35270;&#35282;&#30340;&#20998;&#31867;&#38382;&#39064;&#65292;&#25193;&#23637;&#20102;CLEF-IP&#25968;&#25454;&#38598;&#24182;&#37319;&#29992;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#31867;&#12290;&#36825;&#39033;&#30740;&#31350;&#23545;&#20110;&#20419;&#36827;&#19987;&#21033;&#25506;&#32034;&#21644;&#26816;&#32034;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2307.10471</link><description>&lt;p&gt;
&#19987;&#21033;&#20013;&#21487;&#35270;&#21270;&#31867;&#22411;&#21644;&#35270;&#35282;&#30340;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Classification of Visualization Types and Perspectives in Patents. (arXiv:2307.10471v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#19987;&#21033;&#22270;&#20687;&#20013;&#21487;&#35270;&#21270;&#31867;&#22411;&#21644;&#35270;&#35282;&#30340;&#20998;&#31867;&#38382;&#39064;&#65292;&#25193;&#23637;&#20102;CLEF-IP&#25968;&#25454;&#38598;&#24182;&#37319;&#29992;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#31867;&#12290;&#36825;&#39033;&#30740;&#31350;&#23545;&#20110;&#20419;&#36827;&#19987;&#21033;&#25506;&#32034;&#21644;&#26816;&#32034;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#27599;&#24180;&#19987;&#21033;&#30003;&#35831;&#25968;&#37327;&#30340;&#36805;&#36895;&#22686;&#38271;&#65292;&#20419;&#36827;&#19987;&#21033;&#25506;&#32034;&#21644;&#26816;&#32034;&#30340;&#20449;&#24687;&#21644;&#22810;&#23186;&#20307;&#26816;&#32034;&#26041;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#21516;&#31867;&#22411;&#30340;&#21487;&#35270;&#21270;&#65288;&#20363;&#22914;&#65292;&#22270;&#24418;&#12289;&#25216;&#26415;&#22270;&#32440;&#65289;&#21644;&#35270;&#35282;&#65288;&#20363;&#22914;&#65292;&#20391;&#35270;&#12289;&#36879;&#35270;&#65289;&#34987;&#29992;&#26469;&#21487;&#35270;&#21270;&#19987;&#21033;&#21019;&#26032;&#30340;&#32454;&#33410;&#12290;&#23545;&#36825;&#20123;&#22270;&#20687;&#30340;&#20998;&#31867;&#21487;&#20197;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#25628;&#32034;&#24182;&#36827;&#34892;&#36827;&#19968;&#27493;&#20998;&#26512;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#29992;&#20110;&#22270;&#20687;&#31867;&#22411;&#20998;&#31867;&#30340;&#25968;&#25454;&#38598;&#32570;&#23569;&#19968;&#20123;&#37325;&#35201;&#30340;&#19987;&#21033;&#21487;&#35270;&#21270;&#31867;&#22411;&#12290;&#27492;&#22806;&#65292;&#30456;&#20851;&#30740;&#31350;&#27809;&#26377;&#20351;&#29992;&#21253;&#25324;transformers&#22312;&#20869;&#30340;&#26368;&#26032;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26469;&#20998;&#31867;&#19987;&#21033;&#22270;&#20687;&#20013;&#30340;&#21487;&#35270;&#21270;&#31867;&#22411;&#21644;&#35270;&#35282;&#12290;&#25105;&#20204;&#23545;&#19987;&#21033;&#20013;&#22270;&#20687;&#31867;&#22411;&#20998;&#31867;&#30340;CLEF-IP&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#22686;&#21152;&#21040;&#20102;&#21313;&#20010;&#31867;&#21035;&#65292;&#24182;&#25552;&#20379;&#20102;&#25163;&#21160;&#26631;&#27880;&#30340;&#30495;&#23454;&#26631;&#31614;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#19968;&#20010;&#25968;&#25454;&#38598;&#20013;&#25512;&#23548;&#20986;&#19968;&#32452;&#23618;&#32423;&#31867;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the swift growth of patent applications each year, information and multimedia retrieval approaches that facilitate patent exploration and retrieval are of utmost importance. Different types of visualizations (e.g., graphs, technical drawings) and perspectives (e.g., side view, perspective) are used to visualize details of innovations in patents. The classification of these images enables a more efficient search and allows for further analysis. So far, datasets for image type classification miss some important visualization types for patents. Furthermore, related work does not make use of recent deep learning approaches including transformers. In this paper, we adopt state-of-the-art deep learning methods for the classification of visualization types and perspectives in patent images. We extend the CLEF-IP dataset for image type classification in patents to ten classes and provide manual ground truth annotations. In addition, we derive a set of hierarchical classes from a dataset
&lt;/p&gt;</description></item><item><title>IncDSI&#26159;&#19968;&#31181;&#36882;&#22686;&#21487;&#26356;&#26032;&#30340;&#25991;&#26723;&#26816;&#32034;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#26368;&#23567;&#25913;&#21464;&#32593;&#32476;&#21442;&#25968;&#30340;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#29616;&#23454;&#26102;&#28155;&#21152;&#25991;&#26723;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#25972;&#20010;&#27169;&#22411;&#65292;&#20855;&#26377;&#19982;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#30456;&#31454;&#20105;&#30340;&#36895;&#24230;&#65292;&#33021;&#22815;&#23454;&#26102;&#26356;&#26032;&#30340;&#25991;&#26723;&#26816;&#32034;&#31995;&#32479;&#30340;&#24320;&#21457;&#12290;</title><link>http://arxiv.org/abs/2307.10323</link><description>&lt;p&gt;
IncDSI&#65306;&#36882;&#22686;&#21487;&#26356;&#26032;&#30340;&#25991;&#26723;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
IncDSI: Incrementally Updatable Document Retrieval. (arXiv:2307.10323v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10323
&lt;/p&gt;
&lt;p&gt;
IncDSI&#26159;&#19968;&#31181;&#36882;&#22686;&#21487;&#26356;&#26032;&#30340;&#25991;&#26723;&#26816;&#32034;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#26368;&#23567;&#25913;&#21464;&#32593;&#32476;&#21442;&#25968;&#30340;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#29616;&#23454;&#26102;&#28155;&#21152;&#25991;&#26723;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#25972;&#20010;&#27169;&#22411;&#65292;&#20855;&#26377;&#19982;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#30456;&#31454;&#20105;&#30340;&#36895;&#24230;&#65292;&#33021;&#22815;&#23454;&#26102;&#26356;&#26032;&#30340;&#25991;&#26723;&#26816;&#32034;&#31995;&#32479;&#30340;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;iable&#25628;&#32034;&#32034;&#24341;&#26159;&#26368;&#36817;&#25552;&#20986;&#30340;&#19968;&#31181;&#25991;&#26723;&#26816;&#32034;&#33539;&#20363;&#65292;&#23427;&#23558;&#25991;&#26723;&#35821;&#26009;&#24211;&#30340;&#20449;&#24687;&#32534;&#30721;&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#20013;&#65292;&#24182;&#30452;&#25509;&#23558;&#26597;&#35810;&#26144;&#23556;&#21040;&#30456;&#24212;&#30340;&#25991;&#26723;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#35768;&#22810;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#27169;&#22411;&#20855;&#26377;&#19968;&#20010;&#37325;&#35201;&#38480;&#21046;&#65306;&#22312;&#35757;&#32451;&#27169;&#22411;&#20043;&#21518;&#28155;&#21152;&#26032;&#25991;&#26723;&#24182;&#19981;&#23481;&#26131;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;IncDSI&#65292;&#19968;&#31181;&#23454;&#26102;&#28155;&#21152;&#25991;&#26723;&#30340;&#26041;&#27861;&#65288;&#27599;&#20010;&#25991;&#26723;&#32422;20-50&#27627;&#31186;&#65289;&#65292;&#32780;&#26080;&#38656;&#23545;&#25972;&#20010;&#25968;&#25454;&#38598;&#65288;&#29978;&#33267;&#37096;&#20998;&#25968;&#25454;&#38598;&#65289;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#23558;&#28155;&#21152;&#25991;&#26723;&#30340;&#36807;&#31243;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#22312;&#32593;&#32476;&#21442;&#25968;&#19978;&#36827;&#34892;&#26368;&#23567;&#25913;&#21464;&#30340;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#12290;&#34429;&#28982;&#36895;&#24230;&#26356;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#65292;&#20294;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#30456;&#31454;&#20105;&#65292;&#24182;&#19988;&#21487;&#20197;&#23454;&#26102;&#26356;&#26032;&#30340;&#25991;&#26723;&#26816;&#32034;&#31995;&#32479;&#30340;&#24320;&#21457;&#12290;&#25105;&#20204;&#30340;IncDSI&#20195;&#30721;
&lt;/p&gt;
&lt;p&gt;
Differentiable Search Index is a recently proposed paradigm for document retrieval, that encodes information about a corpus of documents within the parameters of a neural network and directly maps queries to corresponding documents. These models have achieved state-of-the-art performances for document retrieval across many benchmarks. These kinds of models have a significant limitation: it is not easy to add new documents after a model is trained. We propose IncDSI, a method to add documents in real time (about 20-50ms per document), without retraining the model on the entire dataset (or even parts thereof). Instead we formulate the addition of documents as a constrained optimization problem that makes minimal changes to the network parameters. Although orders of magnitude faster, our approach is competitive with re-training the model on the whole dataset and enables the development of document retrieval systems that can be updated with new information in real-time. Our code for IncDSI
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#23391;&#21152;&#25289;&#27468;&#26354;&#30340;&#27468;&#35789;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#23545;&#36825;&#20123;&#27468;&#26354;&#30340;&#24773;&#32490;&#36827;&#34892;&#22810;&#31867;&#20998;&#31867;&#65292;&#21253;&#25324;&#24555;&#20048;&#12289;&#24754;&#20260;&#12289;&#28010;&#28459;&#21644;&#25918;&#26494;&#65292;&#20026;&#20351;&#38899;&#20048;&#26356;&#36148;&#36817;&#20154;&#20204;&#30340;&#24773;&#24863;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2307.10314</link><description>&lt;p&gt;
&#22522;&#20110;&#27468;&#35789;&#30340;&#23391;&#21152;&#25289;&#27468;&#26354;&#24773;&#32490;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Mood Classification of Bangla Songs Based on Lyrics. (arXiv:2307.10314v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#23391;&#21152;&#25289;&#27468;&#26354;&#30340;&#27468;&#35789;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#23545;&#36825;&#20123;&#27468;&#26354;&#30340;&#24773;&#32490;&#36827;&#34892;&#22810;&#31867;&#20998;&#31867;&#65292;&#21253;&#25324;&#24555;&#20048;&#12289;&#24754;&#20260;&#12289;&#28010;&#28459;&#21644;&#25918;&#26494;&#65292;&#20026;&#20351;&#38899;&#20048;&#26356;&#36148;&#36817;&#20154;&#20204;&#30340;&#24773;&#24863;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#20048;&#33021;&#21796;&#36215;&#21508;&#31181;&#24773;&#32490;&#65292;&#38543;&#30528;&#25216;&#26415;&#30340;&#36827;&#27493;&#65292;&#20154;&#20204;&#23545;&#38899;&#20048;&#30340;&#25509;&#35302;&#20063;&#36234;&#26469;&#36234;&#22810;&#12290;&#28982;&#32780;&#23545;&#20110;&#23637;&#29616;&#19981;&#21516;&#20154;&#31867;&#24773;&#24863;&#30340;&#23391;&#21152;&#25289;&#38899;&#20048;&#65292;&#30456;&#20851;&#30340;&#30740;&#31350;&#23578;&#19981;&#36275;&#22815;&#12290;&#26412;&#25991;&#30340;&#20316;&#32773;&#26088;&#22312;&#36890;&#36807;&#20998;&#26512;&#23391;&#21152;&#25289;&#27468;&#26354;&#30340;&#27468;&#35789;&#26469;&#20998;&#31867;&#20854;&#24773;&#32490;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#30740;&#31350;&#20154;&#21592;&#25910;&#38598;&#20102;4000&#39318;&#23391;&#21152;&#25289;&#27468;&#26354;&#30340;&#27468;&#35789;&#21644;&#27969;&#27966;&#65292;&#24182;&#36816;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;BERT&#31639;&#27861;&#26469;&#20998;&#26512;&#25968;&#25454;&#12290;&#22312;&#36825;4000&#39318;&#27468;&#26354;&#20013;&#65292;1513&#39318;&#20195;&#34920;&#24754;&#20260;&#24773;&#32490;&#65292;1362&#39318;&#20195;&#34920;&#28010;&#28459;&#24773;&#32490;&#65292;886&#39318;&#20195;&#34920;&#24555;&#20048;&#65292;&#20854;&#20313;&#30340;239&#39318;&#34987;&#24402;&#31867;&#20026;&#25918;&#26494;&#12290;&#36890;&#36807;&#23884;&#20837;&#27468;&#35789;&#65292;&#20316;&#32773;&#23558;&#36825;&#20123;&#27468;&#26354;&#20998;&#20026;&#22235;&#31181;&#24773;&#32490;&#65306;&#24555;&#20048;&#12289;&#24754;&#20260;&#12289;&#28010;&#28459;&#21644;&#25918;&#26494;&#12290;&#35813;&#30740;&#31350;&#23545;&#20110;&#23454;&#29616;&#38899;&#20048;&#30340;&#22810;&#31867;&#24773;&#32490;&#20998;&#31867;&#33267;&#20851;&#37325;&#35201;&#65292;&#20351;&#38899;&#20048;&#26356;&#33021;&#19982;&#20154;&#20204;&#30340;&#24773;&#24863;&#20135;&#29983;&#20849;&#40483;&#12290;&#35813;&#25991;&#31456;&#35814;&#32454;&#25551;&#36848;&#20102;&#36890;&#36807;&#27468;&#35789;&#20934;&#30830;&#25512;&#23548;&#20986;&#30340;&#22235;&#31181;&#24773;&#32490;&#30340;&#33258;&#21160;&#21270;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Music can evoke various emotions, and with the advancement of technology, it has become more accessible to people. Bangla music, which portrays different human emotions, lacks sufficient research. The authors of this article aim to analyze Bangla songs and classify their moods based on the lyrics. To achieve this, this research has compiled a dataset of 4000 Bangla song lyrics, genres, and used Natural Language Processing and the Bert Algorithm to analyze the data. Among the 4000 songs, 1513 songs are represented for the sad mood, 1362 for the romantic mood, 886 for happiness, and the rest 239 are classified as relaxation. By embedding the lyrics of the songs, the authors have classified the songs into four moods: Happy, Sad, Romantic, and Relaxed. This research is crucial as it enables a multi-class classification of songs' moods, making the music more relatable to people's emotions. The article presents the automated result of the four moods accurately derived from the song lyrics.
&lt;/p&gt;</description></item><item><title>NaRuto&#26159;&#19968;&#20010;&#31995;&#32479;&#65292;&#21487;&#20197;&#20174;&#21465;&#20107;&#25991;&#26412;&#20013;&#33258;&#21160;&#25552;&#21462;&#32467;&#26500;&#21270;&#20107;&#20214;&#65292;&#24182;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#34892;&#21160;&#27169;&#22411;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#23436;&#20840;&#33258;&#21160;&#21270;&#26041;&#27861;&#21644;&#19982;&#21322;&#33258;&#21160;&#21270;&#26041;&#27861;&#30456;&#23218;&#32654;&#12290;</title><link>http://arxiv.org/abs/2307.10247</link><description>&lt;p&gt;
&#20174;&#21465;&#20107;&#25991;&#26412;&#20013;&#33258;&#21160;&#33719;&#21462;&#34892;&#21160;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Automated Action Model Acquisition from Narrative Texts. (arXiv:2307.10247v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10247
&lt;/p&gt;
&lt;p&gt;
NaRuto&#26159;&#19968;&#20010;&#31995;&#32479;&#65292;&#21487;&#20197;&#20174;&#21465;&#20107;&#25991;&#26412;&#20013;&#33258;&#21160;&#25552;&#21462;&#32467;&#26500;&#21270;&#20107;&#20214;&#65292;&#24182;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#34892;&#21160;&#27169;&#22411;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#23436;&#20840;&#33258;&#21160;&#21270;&#26041;&#27861;&#21644;&#19982;&#21322;&#33258;&#21160;&#21270;&#26041;&#27861;&#30456;&#23218;&#32654;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34892;&#21160;&#27169;&#22411;&#20197;&#21069;&#25552;/&#25928;&#26524;&#20844;&#29702;&#30340;&#24418;&#24335;&#23384;&#22312;&#65292;&#20026;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#25552;&#20379;&#34892;&#21160;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#32852;&#21644;&#21160;&#26426;&#36830;&#25509;&#12290;&#34892;&#21160;&#27169;&#22411;&#33719;&#21462;&#34987;&#35748;&#20026;&#26159;&#35745;&#21010;&#25216;&#26415;&#24212;&#29992;&#20013;&#30340;&#29942;&#39048;&#65292;&#29305;&#21035;&#26159;&#22312;&#21465;&#20107;&#35745;&#21010;&#20013;&#12290;&#20174;&#21465;&#20107;&#25991;&#26412;&#20013;&#20197;&#33258;&#21160;&#21270;&#30340;&#26041;&#24335;&#33719;&#21462;&#34892;&#21160;&#27169;&#22411;&#26159;&#24517;&#35201;&#30340;&#65292;&#20294;&#30001;&#20110;&#36825;&#26679;&#30340;&#25991;&#26412;&#26412;&#36136;&#19978;&#22797;&#26434;&#65292;&#22240;&#27492;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;NaRuto&#65292;&#19968;&#20010;&#31995;&#32479;&#65292;&#23427;&#21487;&#20197;&#20174;&#21465;&#20107;&#25991;&#26412;&#20013;&#25552;&#21462;&#32467;&#26500;&#21270;&#20107;&#20214;&#65292;&#24182;&#22522;&#20110;&#24120;&#35782;&#20107;&#20214;&#20851;&#31995;&#30340;&#39044;&#27979;&#20197;&#21450;&#25991;&#26412;&#19978;&#30340;&#30683;&#30462;&#21644;&#30456;&#20284;&#24615;&#26080;&#30417;&#30563;&#22320;&#29983;&#25104;&#35745;&#21010;&#35821;&#35328;&#39118;&#26684;&#30340;&#34892;&#21160;&#27169;&#22411;&#12290;&#32463;&#20856;&#30340;&#21465;&#20107;&#35745;&#21010;&#39046;&#22495;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;NaRuto&#21487;&#20197;&#29983;&#25104;&#36136;&#37327;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#23436;&#20840;&#33258;&#21160;&#21270;&#26041;&#27861;&#30340;&#34892;&#21160;&#27169;&#22411;&#65292;&#29978;&#33267;&#19982;&#21322;&#33258;&#21160;&#21270;&#26041;&#27861;&#30340;&#34892;&#21160;&#27169;&#22411;&#30456;&#23218;&#32654;&#12290;
&lt;/p&gt;
&lt;p&gt;
Action models, which take the form of precondition/effect axioms, facilitate causal and motivational connections between actions for AI agents. Action model acquisition has been identified as a bottleneck in the application of planning technology, especially within narrative planning. Acquiring action models from narrative texts in an automated way is essential, but challenging because of the inherent complexities of such texts. We present NaRuto, a system that extracts structured events from narrative text and subsequently generates planning-language-style action models based on predictions of commonsense event relations, as well as textual contradictions and similarities, in an unsupervised manner. Experimental results in classical narrative planning domains show that NaRuto can generate action models of significantly better quality than existing fully automated methods, and even on par with those of semi-automated methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#28145;&#24230;&#25512;&#33616;&#31995;&#32479;&#22312;&#38754;&#23545;&#30828;&#20214;&#38169;&#35823;&#26102;&#30340;&#20581;&#22766;&#24615;&#36827;&#34892;&#20102;&#31995;&#32479;&#30740;&#31350;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#38169;&#35823;&#27880;&#20837;&#26694;&#26550;Terrorch&#65292;&#21457;&#29616;&#28608;&#27963;&#21098;&#35009;&#26159;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#38169;&#35823;&#32531;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#39640;&#36798;30%&#30340;&#34987;&#38477;&#20302;&#30340;AUC-ROC&#24471;&#20998;&#12290;</title><link>http://arxiv.org/abs/2307.10244</link><description>&lt;p&gt;
&#23545;&#28145;&#24230;&#25512;&#33616;&#31995;&#32479;&#25239;&#30828;&#20214;&#38169;&#35823;&#33021;&#21147;&#30340;&#35780;&#20272;&#21644;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Evaluating and Enhancing Robustness of Deep Recommendation Systems Against Hardware Errors. (arXiv:2307.10244v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#28145;&#24230;&#25512;&#33616;&#31995;&#32479;&#22312;&#38754;&#23545;&#30828;&#20214;&#38169;&#35823;&#26102;&#30340;&#20581;&#22766;&#24615;&#36827;&#34892;&#20102;&#31995;&#32479;&#30740;&#31350;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#38169;&#35823;&#27880;&#20837;&#26694;&#26550;Terrorch&#65292;&#21457;&#29616;&#28608;&#27963;&#21098;&#35009;&#26159;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#38169;&#35823;&#32531;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#39640;&#36798;30%&#30340;&#34987;&#38477;&#20302;&#30340;AUC-ROC&#24471;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#25512;&#33616;&#31995;&#32479;&#65288;DRS&#65289;&#20005;&#37325;&#20381;&#36182;&#20110;&#19987;&#29992;&#30340;&#39640;&#24615;&#33021;&#35745;&#31639;&#30828;&#20214;&#21644;&#21152;&#36895;&#22120;&#65292;&#20197;&#20248;&#21270;&#33021;&#28304;&#12289;&#25928;&#29575;&#21644;&#25512;&#33616;&#36136;&#37327;&#12290;&#23613;&#31649;&#30446;&#21069;&#22312;&#37096;&#32626;DRS&#30340;&#22823;&#35268;&#27169;&#31995;&#32479;&#20013;&#35266;&#23519;&#21040;&#30828;&#20214;&#38169;&#35823;&#30340;&#22686;&#21152;&#65292;&#20294;DRS&#30340;&#20581;&#22766;&#24615;&#19968;&#30452;&#26410;&#21463;&#21040;&#37325;&#35270;&#12290;&#26412;&#25991;&#39318;&#27425;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;DRS&#22312;&#38754;&#23545;&#30828;&#20214;&#38169;&#35823;&#26102;&#30340;&#20581;&#22766;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;Terrorch&#30340;&#29992;&#25143;&#21451;&#22909;&#12289;&#39640;&#25928;&#28789;&#27963;&#30340;&#38169;&#35823;&#27880;&#20837;&#26694;&#26550;&#65292;&#22522;&#20110;&#24191;&#27867;&#20351;&#29992;&#30340;PyTorch&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#24191;&#27867;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;&#35266;&#23519;&#21040;DRS&#30340;&#20581;&#22766;&#24615;&#21463;&#21040;&#22810;&#31181;&#22240;&#32032;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#27169;&#22411;&#21442;&#25968;&#21644;&#36755;&#20837;&#29305;&#24449;&#12290;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;3&#31181;&#38169;&#35823;&#32531;&#35299;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#31639;&#27861;&#30340;&#23481;&#38169;&#65288;ABFT&#65289;&#12289;&#28608;&#27963;&#21098;&#35009;&#21644;&#36873;&#25321;&#24615;&#20301;&#20445;&#25252;&#65288;SBP&#65289;&#12290;&#25105;&#20204;&#21457;&#29616;&#24212;&#29992;&#28608;&#27963;&#21098;&#35009;&#21487;&#20197;&#24674;&#22797;&#34987;&#38477;&#20302;&#30340;AUC-ROC&#24471;&#20998;&#39640;&#36798;30%&#65292;&#36825;&#20351;&#20854;&#25104;&#20026;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#32531;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep recommendation systems (DRS) heavily depend on specialized HPC hardware and accelerators to optimize energy, efficiency, and recommendation quality. Despite the growing number of hardware errors observed in large-scale fleet systems where DRS are deployed, the robustness of DRS has been largely overlooked. This paper presents the first systematic study of DRS robustness against hardware errors. We develop Terrorch, a user-friendly, efficient and flexible error injection framework on top of the widely-used PyTorch. We evaluate a wide range of models and datasets and observe that the DRS robustness against hardware errors is influenced by various factors from model parameters to input characteristics. We also explore 3 error mitigation methods including algorithm based fault tolerance (ABFT), activation clipping and selective bit protection (SBP). We find that applying activation clipping can recover up to 30% of the degraded AUC-ROC score, making it a promising mitigation method.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#22686;&#24378;&#30340;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#27169;&#22411;G2P2&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#25552;&#31034;&#30340;&#26041;&#24335;&#65292;&#21033;&#29992;&#22270;&#32467;&#26500;&#30340;&#35821;&#20041;&#20851;&#31995;&#26469;&#25552;&#21319;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.10230</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#22686;&#24378;&#30340;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#30340;Prompt&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
Prompt Tuning on Graph-augmented Low-resource Text Classification. (arXiv:2307.10230v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#22686;&#24378;&#30340;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#27169;&#22411;G2P2&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#25552;&#31034;&#30340;&#26041;&#24335;&#65292;&#21033;&#29992;&#22270;&#32467;&#26500;&#30340;&#35821;&#20041;&#20851;&#31995;&#26469;&#25552;&#21319;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#20998;&#31867;&#26159;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#19968;&#20010;&#22522;&#30784;&#38382;&#39064;&#65292;&#26377;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#65292;&#20363;&#22914;&#39044;&#27979;&#22312;&#32447;&#25991;&#31456;&#30340;&#20027;&#39064;&#21644;&#30005;&#23376;&#21830;&#21153;&#20135;&#21697;&#25551;&#36848;&#30340;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#65292;&#21363;&#27809;&#26377;&#25110;&#21482;&#26377;&#24456;&#23569;&#26631;&#27880;&#26679;&#26412;&#30340;&#24773;&#20917;&#65292;&#23545;&#30417;&#30563;&#23398;&#20064;&#26500;&#25104;&#20102;&#20005;&#37325;&#38382;&#39064;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#35768;&#22810;&#25991;&#26412;&#25968;&#25454;&#26412;&#36136;&#19978;&#37117;&#24314;&#31435;&#22312;&#32593;&#32476;&#32467;&#26500;&#19978;&#65292;&#20363;&#22914;&#22312;&#32447;&#25991;&#31456;&#30340;&#36229;&#38142;&#25509;/&#24341;&#29992;&#32593;&#32476;&#21644;&#30005;&#23376;&#21830;&#21153;&#20135;&#21697;&#30340;&#29992;&#25143;-&#29289;&#21697;&#36141;&#20080;&#32593;&#32476;&#12290;&#36825;&#20123;&#22270;&#32467;&#26500;&#25429;&#25417;&#20102;&#20016;&#23500;&#30340;&#35821;&#20041;&#20851;&#31995;&#65292;&#26377;&#21161;&#20110;&#22686;&#24378;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Graph-Grounded Pre-training and Prompting (G2P2)&#30340;&#26032;&#27169;&#22411;&#65292;&#20197;&#20004;&#26041;&#38754;&#26041;&#27861;&#35299;&#20915;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#38382;&#39064;&#12290;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#22522;&#20110;&#22270;&#20132;&#20114;&#30340;&#23545;&#27604;&#31574;&#30053;&#65292;&#20849;&#21516;&#39044;&#35757;&#32451;&#22270;&#25991;&#27169;&#22411;&#65307;&#22312;&#19979;&#28216;&#20998;&#31867;&#38454;&#27573;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#25163;&#24037;&#35774;&#35745;&#30340;&#25552;&#31034;&#20449;&#24687;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Text classification is a fundamental problem in information retrieval with many real-world applications, such as predicting the topics of online articles and the categories of e-commerce product descriptions. However, low-resource text classification, with no or few labeled samples, presents a serious concern for supervised learning. Meanwhile, many text data are inherently grounded on a network structure, such as a hyperlink/citation network for online articles, and a user-item purchase network for e-commerce products. These graph structures capture rich semantic relationships, which can potentially augment low-resource text classification. In this paper, we propose a novel model called Graph-Grounded Pre-training and Prompting (G2P2) to address low-resource text classification in a two-pronged approach. During pre-training, we propose three graph interaction-based contrastive strategies to jointly pre-train a graph-text model; during downstream classification, we explore handcrafted 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;IPW&#30340;&#26080;&#20559;&#25490;&#24207;&#24230;&#37327;&#26041;&#27861;&#65292;&#38024;&#23545;&#21452;&#36793;&#24066;&#22330;&#20013;&#29992;&#25143;&#20043;&#38388;&#30340;&#20559;&#35265;&#30456;&#20114;&#20316;&#29992;&#65292;&#35299;&#20915;&#20102;&#20301;&#32622;&#20559;&#35265;&#21644;&#20004;&#20010;&#29992;&#25143;&#32676;&#20307;&#30340;&#20301;&#32622;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.10204</link><description>&lt;p&gt;
&#22522;&#20110;IPW&#30340;&#21452;&#36793;&#24066;&#22330;&#20013;&#30340;&#26080;&#20559;&#25490;&#24207;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
An IPW-based Unbiased Ranking Metric in Two-sided Markets. (arXiv:2307.10204v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10204
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;IPW&#30340;&#26080;&#20559;&#25490;&#24207;&#24230;&#37327;&#26041;&#27861;&#65292;&#38024;&#23545;&#21452;&#36793;&#24066;&#22330;&#20013;&#29992;&#25143;&#20043;&#38388;&#30340;&#20559;&#35265;&#30456;&#20114;&#20316;&#29992;&#65292;&#35299;&#20915;&#20102;&#20301;&#32622;&#20559;&#35265;&#21644;&#20004;&#20010;&#29992;&#25143;&#32676;&#20307;&#30340;&#20301;&#32622;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;&#65288;LTR&#65289;&#23545;&#20110;&#20248;&#20808;&#32771;&#34385;&#26469;&#33258;&#26377;&#20559;&#30340;&#38544;&#24335;&#29992;&#25143;&#21453;&#39304;&#65288;&#22914;&#28857;&#20987;&#25968;&#25454;&#65289;&#30340;&#39033;&#30446;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#25216;&#26415;&#65292;&#20363;&#22914;&#20498;&#25968;&#20542;&#21521;&#24615;&#21152;&#26435;&#65288;IPW&#65289;&#65292;&#29992;&#20110;&#21333;&#36793;&#24066;&#22330;&#12290;&#28982;&#32780;&#65292;&#22312;&#21452;&#36793;&#24066;&#22330;&#65288;&#22914;&#24037;&#20316;&#24179;&#21488;&#25110;&#32422;&#20250;&#26381;&#21153;&#65289;&#20013;&#65292;&#25104;&#21151;&#36716;&#21270;&#38656;&#35201;&#21305;&#37197;&#20004;&#20010;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#20294;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#20851;&#27880;&#36739;&#23569;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#21452;&#36793;&#24066;&#22330;&#20013;&#29992;&#25143;&#20043;&#38388;&#30340;&#20559;&#35265;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;LTR&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#21452;&#36793;&#21305;&#37197;&#24179;&#21488;&#20013;&#21453;&#39304;&#26426;&#21046;&#30340;&#24418;&#24335;&#21270;&#65292;&#24182;&#25351;&#20986;&#23427;&#20204;&#30340;&#38544;&#24335;&#21453;&#39304;&#21487;&#33021;&#21253;&#21547;&#26469;&#33258;&#20004;&#20010;&#29992;&#25143;&#32676;&#20307;&#30340;&#20301;&#32622;&#20559;&#24046;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;IPW&#20272;&#35745;&#22120;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;&#21452;&#36793;IPW&#65292;&#20197;&#35299;&#20915;&#21452;&#36793;&#24066;&#22330;&#20013;&#30340;&#20301;&#32622;&#20559;&#35265;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#20272;&#35745;&#22120;&#28385;&#36275;&#30495;&#23454;&#25490;&#21517;&#30340;&#26080;&#20559;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In modern recommendation systems, unbiased learning-to-rank (LTR) is crucial for prioritizing items from biased implicit user feedback, such as click data. Several techniques, such as Inverse Propensity Weighting (IPW), have been proposed for single-sided markets. However, less attention has been paid to two-sided markets, such as job platforms or dating services, where successful conversions require matching preferences from both users. This paper addresses the complex interaction of biases between users in two-sided markets and proposes a tailored LTR approach. We first present a formulation of feedback mechanisms in two-sided matching platforms and point out that their implicit feedback may include position bias from both user groups. On the basis of this observation, we extend the IPW estimator and propose a new estimator, named two-sided IPW, to address the position bases in two-sided markets. We prove that the proposed estimator satisfies the unbiasedness for the ground-truth ran
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;CrowdOpinion&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#27719;&#38598;&#26631;&#31614;&#20998;&#24067;&#20013;&#30456;&#20284;&#30340;&#39033;&#30446;&#65292;&#25581;&#31034;&#22312;&#32676;&#20307;&#20013;&#23384;&#22312;&#30340;&#26377;&#24847;&#20041;&#30340;&#35266;&#28857;&#20998;&#27495;&#65292;&#29305;&#21035;&#26159;&#22312;&#26631;&#27880;&#32773;&#20154;&#32676;&#20013;&#21487;&#33021;&#24050;&#32463;&#20195;&#34920;&#24615;&#19981;&#36275;&#30340;&#32676;&#20307;&#20013;&#12290;</title><link>http://arxiv.org/abs/2307.10189</link><description>&lt;p&gt;
&#20027;&#35266;&#25968;&#25454;&#30340;&#20027;&#35266;&#20154;&#32676;&#20998;&#27495;&#65306;&#36890;&#36807;&#32676;&#20307;&#32423;&#23398;&#20064;&#25581;&#31034;&#26377;&#24847;&#20041;&#30340;&#32676;&#20307;&#24847;&#35265;
&lt;/p&gt;
&lt;p&gt;
Subjective Crowd Disagreements for Subjective Data: Uncovering Meaningful CrowdOpinion with Population-level Learning. (arXiv:2307.10189v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;CrowdOpinion&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#27719;&#38598;&#26631;&#31614;&#20998;&#24067;&#20013;&#30456;&#20284;&#30340;&#39033;&#30446;&#65292;&#25581;&#31034;&#22312;&#32676;&#20307;&#20013;&#23384;&#22312;&#30340;&#26377;&#24847;&#20041;&#30340;&#35266;&#28857;&#20998;&#27495;&#65292;&#29305;&#21035;&#26159;&#22312;&#26631;&#27880;&#32773;&#20154;&#32676;&#20013;&#21487;&#33021;&#24050;&#32463;&#20195;&#34920;&#24615;&#19981;&#36275;&#30340;&#32676;&#20307;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#22312;AI&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#21253;&#25324;&#22788;&#29702;&#25913;&#21464;&#20154;&#20204;&#29983;&#27963;&#30340;&#20915;&#31574;&#25110;&#31649;&#29702;&#20154;&#31867;&#21019;&#24314;&#30340;&#32593;&#32476;/&#31038;&#20132;&#23186;&#20307;&#20869;&#23481;&#30340;&#31995;&#32479;&#12290;&#20256;&#32479;&#19978;&#65292;&#22312;&#36827;&#34892;&#20219;&#20309;&#23398;&#20064;&#20043;&#21069;&#65292;&#20250;&#35299;&#20915;&#26631;&#27880;&#32773;&#20043;&#38388;&#30340;&#20998;&#27495;&#12290;&#28982;&#32780;&#65292;&#30740;&#31350;&#20154;&#21592;&#36234;&#26469;&#36234;&#22810;&#22320;&#35748;&#35782;&#21040;&#26631;&#27880;&#32773;&#20043;&#38388;&#30340;&#20998;&#27495;&#26159;&#26222;&#36941;&#23384;&#22312;&#19988;&#26377;&#24847;&#20041;&#30340;&#12290;&#20182;&#20204;&#36824;&#36136;&#30097;&#31995;&#32479;&#22312;&#26631;&#27880;&#32773;&#20998;&#27495;&#26102;&#30340;&#24615;&#33021;&#12290;&#23588;&#20854;&#26159;&#22312;&#24573;&#35270;&#23569;&#25968;&#35266;&#28857;&#26102;&#65292;&#23588;&#20854;&#26159;&#22312;&#26631;&#27880;&#32773;&#20154;&#32676;&#20013;&#21487;&#33021;&#24050;&#32463;&#20195;&#34920;&#24615;&#19981;&#36275;&#30340;&#32676;&#20307;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;\emph{CrowdOpinion}&#65292;&#23427;&#20351;&#29992;&#35821;&#35328;&#29305;&#24449;&#21644;&#26631;&#31614;&#20998;&#24067;&#23558;&#30456;&#20284;&#30340;&#39033;&#30446;&#27719;&#38598;&#25104;&#36739;&#22823;&#30340;&#26631;&#31614;&#20998;&#24067;&#26679;&#26412;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;&#22235;&#31181;&#29983;&#25104;&#26041;&#27861;&#21644;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#20116;&#20010;&#26631;&#31614;&#20998;&#24067;&#21644;&#29305;&#24449;&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;&#25105;&#20204;&#20351;&#29992;&#20116;&#20010;p
&lt;/p&gt;
&lt;p&gt;
Human-annotated data plays a critical role in the fairness of AI systems, including those that deal with life-altering decisions or moderating human-created web/social media content. Conventionally, annotator disagreements are resolved before any learning takes place. However, researchers are increasingly identifying annotator disagreement as pervasive and meaningful. They also question the performance of a system when annotators disagree. Particularly when minority views are disregarded, especially among groups that may already be underrepresented in the annotator population. In this paper, we introduce \emph{CrowdOpinion}\footnote{Accepted for publication at ACL 2023}, an unsupervised learning based approach that uses language features and label distributions to pool similar items into larger samples of label distributions. We experiment with four generative and one density-based clustering method, applied to five linear combinations of label distributions and features. We use five p
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#23454;&#20307;&#30340;&#20851;&#32852;&#27169;&#22411;&#65288;EBRM&#65289;&#30340;&#26032;&#27169;&#22411;&#65292;&#23558;&#26597;&#35810;-&#21830;&#21697;&#20851;&#32852;&#38382;&#39064;&#20998;&#35299;&#20026;&#22810;&#20010;&#26597;&#35810;-&#23454;&#20307;&#20851;&#32852;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#36719;&#36923;&#36753;&#32858;&#21512;&#32467;&#26524;&#65292;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.00370</link><description>&lt;p&gt;
&#25552;&#21319;&#30005;&#23376;&#21830;&#21153;&#25628;&#32034;&#20013;&#30340;&#25991;&#26412;&#21305;&#37197;&#33021;&#21147;&#65306;&#22522;&#20110;&#21487;&#29702;&#35299;&#12289;&#21487;&#24178;&#39044;&#21644;&#24555;&#36895;&#23454;&#20307;&#20851;&#32852;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Improving Text Matching in E-Commerce Search with A Rationalizable, Intervenable and Fast Entity-Based Relevance Model. (arXiv:2307.00370v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#23454;&#20307;&#30340;&#20851;&#32852;&#27169;&#22411;&#65288;EBRM&#65289;&#30340;&#26032;&#27169;&#22411;&#65292;&#23558;&#26597;&#35810;-&#21830;&#21697;&#20851;&#32852;&#38382;&#39064;&#20998;&#35299;&#20026;&#22810;&#20010;&#26597;&#35810;-&#23454;&#20307;&#20851;&#32852;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#36719;&#36923;&#36753;&#32858;&#21512;&#32467;&#26524;&#65292;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#23376;&#21830;&#21153;&#25628;&#32034;&#31995;&#32479;&#20013;&#65292;&#20174;&#22823;&#37327;&#21830;&#21697;&#20013;&#21457;&#29616;&#29992;&#25143;&#26597;&#35810;&#30340;&#30446;&#26631;&#21830;&#21697;&#26159;&#20027;&#35201;&#30446;&#26631;&#20043;&#19968;&#12290;&#20851;&#32852;&#39044;&#27979;&#23545;&#20110;&#25628;&#32034;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#26377;&#21161;&#20110;&#25552;&#39640;&#24615;&#33021;&#12290;&#30446;&#21069;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;&#27169;&#22411;&#22914;Bi-encoder&#21644;Cross-encoder&#20998;&#21035;&#22312;&#20934;&#30830;&#24615;&#25110;&#25512;&#29702;&#36895;&#24230;&#19978;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#65292;&#31216;&#20026;&#22522;&#20110;&#23454;&#20307;&#30340;&#20851;&#32852;&#27169;&#22411;&#65288;EBRM&#65289;&#12290;&#25105;&#20204;&#35782;&#21035;&#21830;&#21697;&#20013;&#21253;&#21547;&#30340;&#23454;&#20307;&#65292;&#24182;&#23558;QI&#65288;&#26597;&#35810;-&#21830;&#21697;&#65289;&#20851;&#32852;&#38382;&#39064;&#20998;&#35299;&#20026;&#22810;&#20010;QE&#65288;&#26597;&#35810;-&#23454;&#20307;&#65289;&#20851;&#32852;&#38382;&#39064;&#65307;&#28982;&#21518;&#20351;&#29992;&#36719;&#36923;&#36753;&#24418;&#24335;&#32858;&#21512;&#20854;&#32467;&#26524;&#20197;&#24418;&#25104;QI&#30340;&#39044;&#27979;&#12290;&#20998;&#35299;&#20801;&#35768;&#25105;&#20204;&#20351;&#29992;Cross-encoder QE&#20851;&#32852;&#27169;&#22359;&#20197;&#33719;&#24471;&#39640;&#20934;&#30830;&#24615;&#65292;&#24182;&#20026;&#24555;&#36895;&#22312;&#32447;&#25512;&#29702;&#32531;&#23384;QE&#39044;&#27979;&#12290;&#21033;&#29992;&#36719;&#36923;&#36753;&#20351;&#39044;&#27979;&#36807;&#31243;&#21487;&#35299;&#37322;&#24615;&#39640;&#24182;&#20855;&#26377;&#24178;&#39044;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering the intended items of user queries from a massive repository of items is one of the main goals of an e-commerce search system. Relevance prediction is essential to the search system since it helps improve performance. When online serving a relevance model, the model is required to perform fast and accurate inference. Currently, the widely used models such as Bi-encoder and Cross-encoder have their limitations in accuracy or inference speed respectively. In this work, we propose a novel model called the Entity-Based Relevance Model (EBRM). We identify the entities contained in an item and decompose the QI (query-item) relevance problem into multiple QE (query-entity) relevance problems; we then aggregate their results to form the QI prediction using a soft logic formulation. The decomposition allows us to use a Cross-encoder QE relevance module for high accuracy as well as cache QE predictions for fast online inference. Utilizing soft logic makes the prediction procedure int
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#25552;&#31034;&#24037;&#31243;&#30340;&#26041;&#27861;&#25351;&#23548;ChatGPT&#23545;&#31185;&#23398;&#25991;&#29486;&#36827;&#34892;&#33258;&#21160;&#21270;&#25991;&#26412;&#25366;&#25496;&#65292;&#20197;&#33719;&#24471;&#37329;&#23646;-&#26377;&#26426;&#26694;&#26550;&#65288;MOF&#65289;&#21512;&#25104;&#26465;&#20214;&#12290;&#36890;&#36807;&#35813;&#31995;&#32479;&#65292;&#21487;&#20197;&#39640;&#31934;&#30830;&#22320;&#25552;&#21462;&#22823;&#37327;&#21512;&#25104;&#21442;&#25968;&#65292;&#20026;MOF&#21512;&#25104;&#25552;&#20379;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2306.11296</link><description>&lt;p&gt;
ChatGPT&#21270;&#23398;&#21161;&#25163;&#29992;&#20110;&#25991;&#26412;&#25366;&#25496;&#21644;MOF&#21512;&#25104;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis. (arXiv:2306.11296v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11296
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#25552;&#31034;&#24037;&#31243;&#30340;&#26041;&#27861;&#25351;&#23548;ChatGPT&#23545;&#31185;&#23398;&#25991;&#29486;&#36827;&#34892;&#33258;&#21160;&#21270;&#25991;&#26412;&#25366;&#25496;&#65292;&#20197;&#33719;&#24471;&#37329;&#23646;-&#26377;&#26426;&#26694;&#26550;&#65288;MOF&#65289;&#21512;&#25104;&#26465;&#20214;&#12290;&#36890;&#36807;&#35813;&#31995;&#32479;&#65292;&#21487;&#20197;&#39640;&#31934;&#30830;&#22320;&#25552;&#21462;&#22823;&#37327;&#21512;&#25104;&#21442;&#25968;&#65292;&#20026;MOF&#21512;&#25104;&#25552;&#20379;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#25552;&#31034;&#24037;&#31243;&#26469;&#25351;&#23548;ChatGPT&#33258;&#21160;&#21270;&#22320;&#20174;&#31185;&#23398;&#25991;&#29486;&#20013;&#25366;&#25496;&#22810;&#26679;&#30340;&#37329;&#23646;-&#26377;&#26426;&#26694;&#26550;&#65288;MOF&#65289;&#21512;&#25104;&#26465;&#20214;&#12290;&#36825;&#26377;&#25928;&#22320;&#20943;&#23569;&#20102;ChatGPT&#22312;&#31185;&#23398;&#39046;&#22495;&#20013;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26102;&#20986;&#29616;&#20449;&#24687;&#20135;&#29983;&#35823;&#24046;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#36890;&#36807;ChatGPT&#26412;&#36523;&#32534;&#31243;&#26469;&#24320;&#21457;&#23454;&#26045;&#25991;&#26412;&#25366;&#25496;&#30340;&#19977;&#20010;&#19981;&#21516;&#36807;&#31243;&#12290;&#25152;&#26377;&#36825;&#20123;&#36807;&#31243;&#37117;&#21487;&#20197;&#35299;&#26512;&#12289;&#25628;&#32034;&#12289;&#36807;&#28388;&#12289;&#20998;&#31867;&#12289;&#25688;&#35201;&#21644;&#25968;&#25454;&#32479;&#19968;&#65292;&#20294;&#22312;&#21171;&#21160;&#21147;&#12289;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#26377;&#19981;&#21516;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#37096;&#32626;&#20102;&#35813;&#31995;&#32479;&#65292;&#20174;&#21516;&#34892;&#35780;&#23457;&#30340;&#30740;&#31350;&#25991;&#31456;&#20013;&#25552;&#21462;&#20102;26257&#20010;&#19981;&#21516;&#30340;&#21512;&#25104;&#21442;&#25968;&#65292;&#28041;&#21450;&#22823;&#32422;800&#20010;MOF&#12290;&#36825;&#20010;&#36807;&#31243;&#21253;&#21547;&#20102;&#25105;&#20204;&#30340;ChemPrompt&#24037;&#31243;&#31574;&#30053;&#65292;&#20197;&#25351;&#23548;ChatGPT&#36827;&#34892;&#25991;&#26412;&#25366;&#25496;&#65292;&#32467;&#26524;&#26174;&#31034;&#20986;&#20102;90-99%&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#31934;&#30830;&#24230;&#12289;&#21484;&#22238;&#29575;&#21644;F1&#24471;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
We use prompt engineering to guide ChatGPT in the automation of text mining of metal-organic frameworks (MOFs) synthesis conditions from diverse formats and styles of the scientific literature. This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging. Our approach involves the development of a workflow implementing three different processes for text mining, programmed by ChatGPT itself. All of them enable parsing, searching, filtering, classification, summarization, and data unification with different tradeoffs between labor, speed, and accuracy. We deploy this system to extract 26,257 distinct synthesis parameters pertaining to approximately 800 MOFs sourced from peer-reviewed research articles. This process incorporates our ChemPrompt Engineering strategy to instruct ChatGPT in text mining, resulting in impressive precision, recall, and F1 scores of 90-99%. Furthe
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23398;&#20064;&#21704;&#24076;&#25216;&#26415;&#25552;&#39640;&#38646;&#26679;&#26412;&#23494;&#38598;&#26816;&#32034;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20811;&#26381;&#20102;&#23384;&#20648;&#23494;&#38598;&#32034;&#24341;&#30340;&#39640;&#20869;&#23384;&#20351;&#29992;&#38382;&#39064;&#65292;&#24182;&#22312;&#36328;&#39046;&#22495;&#29615;&#22659;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2205.11498</link><description>&lt;p&gt;
&#20026;&#26377;&#25928;&#21644;&#39640;&#25928;&#30340;&#38646;&#26679;&#26412;&#23494;&#38598;&#26816;&#32034;&#27880;&#20837;&#39046;&#22495;&#36866;&#24212;&#30340;&#23398;&#20064;&#21704;&#24076;
&lt;/p&gt;
&lt;p&gt;
Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval. (arXiv:2205.11498v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11498
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#21704;&#24076;&#25216;&#26415;&#25552;&#39640;&#38646;&#26679;&#26412;&#23494;&#38598;&#26816;&#32034;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20811;&#26381;&#20102;&#23384;&#20648;&#23494;&#38598;&#32034;&#24341;&#30340;&#39640;&#20869;&#23384;&#20351;&#29992;&#38382;&#39064;&#65292;&#24182;&#22312;&#36328;&#39046;&#22495;&#29615;&#22659;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#26816;&#32034;&#22312;&#26080;&#26597;&#35810;&#35789;&#26816;&#32034;&#20013;&#20811;&#26381;&#20102;&#35789;&#27719;&#38548;&#38402;&#65292;&#24182;&#22312;&#33258;&#21160;&#20449;&#24687;&#26816;&#32034;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#23613;&#31649;&#25104;&#21151;&#65292;&#20294;&#23494;&#38598;&#26816;&#32034;&#22120;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#26381;&#21153;&#25104;&#26412;&#36739;&#39640;&#12290;&#23545;&#20110;&#38656;&#35201;&#20174;&#25968;&#30334;&#19975;&#20221;&#25991;&#26723;&#20013;&#25628;&#32034;&#30340;&#29992;&#20363;&#65292;&#23494;&#38598;&#32034;&#24341;&#21464;&#24471;&#24222;&#22823;&#65292;&#24182;&#19988;&#22312;&#23384;&#20648;&#32034;&#24341;&#26102;&#38656;&#35201;&#39640;&#20869;&#23384;&#20351;&#29992;&#37327;&#12290;&#26368;&#36817;&#30340;&#23398;&#20064;&#21704;&#24076;&#65288;LTH&#65289;&#25216;&#26415;&#65292;&#22914;BPR&#21644;JPQ&#65292;&#29983;&#25104;&#20108;&#36827;&#21046;&#25991;&#26723;&#21521;&#37327;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#23384;&#20648;&#23494;&#38598;&#32034;&#24341;&#30340;&#20869;&#23384;&#38656;&#27714;&#12290;LTH&#25216;&#26415;&#26159;&#26377;&#30417;&#30563;&#30340;&#65292;&#24182;&#20351;&#29992;&#25490;&#21517;&#25439;&#22833;&#23545;&#26816;&#32034;&#22120;&#36827;&#34892;&#24494;&#35843;&#12290;&#23427;&#20204;&#20248;&#20110;&#20256;&#32479;&#30340;&#21521;&#37327;&#21387;&#32553;&#25216;&#26415;&#65292;&#22914;PCA&#25110;PQ&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#32570;&#23569;&#30340;&#19968;&#20010;&#29615;&#33410;&#26159;&#29616;&#26377;&#25216;&#26415;&#20165;&#22312;&#39046;&#22495;&#20869;&#36827;&#34892;&#35780;&#20272;&#65292;&#21363;&#20165;&#22312;&#21333;&#19968;&#25968;&#25454;&#38598;&#65288;&#22914;MS MARCO&#65289;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;LTH&#21644;&#21521;&#37327;&#21387;&#32553;&#25216;&#26415;&#65292;&#20197;&#25552;&#39640;TAS-B d&#30340;&#38646;&#26679;&#26412;&#26816;&#32034;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dense retrieval overcome the lexical gap and has shown great success in ad-hoc information retrieval (IR). Despite their success, dense retrievers are expensive to serve across practical use cases. For use cases requiring to search from millions of documents, the dense index becomes bulky and requires high memory usage for storing the index. More recently, learning-to-hash (LTH) techniques, for e.g., BPR and JPQ, produce binary document vectors, thereby reducing the memory requirement to efficiently store the dense index. LTH techniques are supervised and finetune the retriever using a ranking loss. They outperform their counterparts, i.e., traditional out-of-the-box vector compression techniques such as PCA or PQ. A missing piece from prior work is that existing techniques have been evaluated only in-domain, i.e., on a single dataset such as MS MARCO. In our work, we evaluate LTH and vector compression techniques for improving the downstream zero-shot retrieval accuracy of the TAS-B d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#22870;&#21169;&#31232;&#23569;&#26102;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2109.12509</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#28145;&#24230;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Deep Exploration for Recommendation Systems. (arXiv:2109.12509v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#22870;&#21169;&#31232;&#23569;&#26102;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#24212;&#20174;&#24310;&#36831;&#21453;&#39304;&#20013;&#25506;&#32034;&#21644;&#23398;&#20064;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#24448;&#24448;&#20391;&#37325;&#20110;&#20174;&#29992;&#25143;&#23545;&#21333;&#20010;&#25512;&#33616;&#30340;&#21709;&#24212;&#20013;&#23398;&#20064;&#12290;&#36825;&#20123;&#24037;&#20316;&#21033;&#29992;&#20102;&#30417;&#30563;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20294;&#25918;&#24323;&#20102;&#23398;&#20064;&#29992;&#25143;&#20043;&#21518;&#30340;&#34892;&#20026;&#12290;&#22312;&#36807;&#21435;&#30340;&#24037;&#20316;&#20013;&#65292;&#34429;&#28982;&#33268;&#21147;&#20110;&#20174;&#38543;&#21518;&#30340;&#34892;&#20026;&#20013;&#23398;&#20064;&#65292;&#20294;&#32570;&#20047;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#24341;&#23548;&#24182;&#33719;&#21462;&#26377;&#24847;&#20041;&#30340;&#24310;&#36831;&#21453;&#39304;&#12290;&#24403;&#22870;&#21169;&#36739;&#23569;&#26102;&#65292;&#36890;&#36807;&#24341;&#23548;&#25506;&#32034;&#26377;&#24847;&#20041;&#30340;&#24310;&#36831;&#21453;&#39304;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20026;&#25512;&#33616;&#31995;&#32479;&#24320;&#21457;&#20102;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#25512;&#33616;&#31995;&#32479;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#22312;&#21333;&#27493;&#25506;&#32034;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#26159;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#30340;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommendation systems ought to benefit by probing for and learning from delayed feedback. Research has tended to focus on learning from a user's response to a single recommendation. Such work, which leverages methods of supervised and bandit learning, forgoes learning from the user's subsequent behavior. Where past work has aimed to learn from subsequent behavior, there has been a lack of effective methods for probing to elicit informative delayed feedback. Effective exploration through probing for delayed feedback becomes particularly challenging when rewards are sparse. To address this, we develop deep exploration methods for recommendation systems. In particular, we formulate recommendation as a sequential decision problem and demonstrate benefits of deep exploration over single-step exploration. Our experiments are carried out with high-fidelity industrial-grade simulators and establish large improvements over existing algorithms.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20934;&#21017;&#30340;&#38750;&#37319;&#26679;&#23398;&#20064;&#26694;&#26550;&#65292;&#21629;&#21517;&#20026;CHCF&#65292;&#29992;&#20110;&#22810;&#34892;&#20026;&#38544;&#24335;&#25512;&#33616;&#30340;&#24322;&#26500;&#21327;&#21516;&#36807;&#28388;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#19978;&#38480;&#21644;&#19979;&#38480;&#38408;&#20540;&#26469;&#25351;&#31034;&#36873;&#25321;&#26631;&#20934;&#65292;&#24182;&#25351;&#23548;&#29992;&#25143;&#20559;&#22909;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2105.11876</link><description>&lt;p&gt;
&#22522;&#20110;&#20934;&#21017;&#30340;&#22810;&#34892;&#20026;&#38544;&#24335;&#25512;&#33616;&#30340;&#24322;&#26500;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Criterion-based Heterogeneous Collaborative Filtering for Multi-behavior Implicit Recommendation. (arXiv:2105.11876v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.11876
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20934;&#21017;&#30340;&#38750;&#37319;&#26679;&#23398;&#20064;&#26694;&#26550;&#65292;&#21629;&#21517;&#20026;CHCF&#65292;&#29992;&#20110;&#22810;&#34892;&#20026;&#38544;&#24335;&#25512;&#33616;&#30340;&#24322;&#26500;&#21327;&#21516;&#36807;&#28388;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#19978;&#38480;&#21644;&#19979;&#38480;&#38408;&#20540;&#26469;&#25351;&#31034;&#36873;&#25321;&#26631;&#20934;&#65292;&#24182;&#25351;&#23548;&#29992;&#25143;&#20559;&#22909;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22810;&#23186;&#20307;&#20449;&#24687;&#31995;&#32479;&#20013;&#30340;&#20114;&#21160;&#34892;&#20026;&#21576;&#29190;&#28856;&#24335;&#22686;&#38271;&#65292;&#21033;&#29992;&#26469;&#33258;&#21508;&#31181;&#36741;&#21161;&#34892;&#20026;&#65288;&#22914;&#25552;&#31034;&#21644;&#25910;&#34255;&#65289;&#30340;&#25968;&#25454;&#65292;&#22810;&#34892;&#20026;&#25512;&#33616;&#31995;&#32479;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#21508;&#31181;&#22810;&#34892;&#20026;&#25512;&#33616;&#26041;&#27861;&#20013;&#65292;&#38750;&#37319;&#26679;&#26041;&#27861;&#34920;&#29616;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#20108;&#36827;&#21046;&#22238;&#24402;&#30340;&#38750;&#37319;&#26679;&#26041;&#27861;&#36890;&#24120;&#24573;&#30053;&#20102;&#20004;&#28857;&#35266;&#23519;&#65306;&#65288;1&#65289;&#29992;&#25143;&#23545;&#19981;&#21516;&#39033;&#30446;&#20855;&#26377;&#19981;&#21516;&#30340;&#20559;&#22909;&#24378;&#24230;&#65292;&#22240;&#27492;&#19981;&#33021;&#31616;&#21333;&#36890;&#36807;&#20108;&#36827;&#21046;&#38544;&#24335;&#25968;&#25454;&#26469;&#34913;&#37327;&#65307;&#65288;2&#65289;&#22810;&#20010;&#34892;&#20026;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#23545;&#19981;&#21516;&#30340;&#29992;&#25143;&#21644;&#39033;&#30446;&#26159;&#19981;&#21516;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#37319;&#26679;&#23398;&#20064;&#26694;&#26550;&#65292;&#21629;&#21517;&#20026;&#22522;&#20110;&#20934;&#21017;&#30340;&#24322;&#26500;&#21327;&#21516;&#36807;&#28388;&#65288;CHCF&#65289;&#12290;CHCF&#24341;&#20837;&#20102;&#19978;&#38480;&#21644;&#19979;&#38480;&#38408;&#20540;&#26469;&#25351;&#31034;&#36873;&#25321;&#26631;&#20934;&#65292;&#24182;&#25351;&#23548;&#29992;&#25143;&#20559;&#22909;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have witnessed the explosive growth of interaction behaviors in multimedia information systems, where multi-behavior recommender systems have received increasing attention by leveraging data from various auxiliary behaviors such as tip and collect. Among various multi-behavior recommendation methods, non-sampling methods have shown superiority over negative sampling methods. However, two observations are usually ignored in existing state-of-the-art non-sampling methods based on binary regression: (1) users have different preference strengths for different items, so they cannot be measured simply by binary implicit data; (2) the dependency across multiple behaviors varies for different users and items. To tackle the above issue, we propose a novel non-sampling learning framework named Criterion-guided Heterogeneous Collaborative Filtering (CHCF). CHCF introduces both upper and lower thresholds to indicate selection criteria, which will guide user preference learning. Beside
&lt;/p&gt;</description></item><item><title>ABNIRML&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#27169;&#22411;&#30340;&#34892;&#20026;&#65292;&#21253;&#25324;&#20889;&#20316;&#39118;&#26684;&#12289;&#20107;&#23454;&#24615;&#12289;&#23545;&#25913;&#20889;&#21644;&#35789;&#24207;&#30340;&#25935;&#24863;&#24615;&#31561;&#29305;&#24449;&#12290;&#36890;&#36807;&#36827;&#34892;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#25506;&#31350;&#20102;&#31070;&#32463;&#27169;&#22411;&#22686;&#30410;&#30340;&#22240;&#32032;&#65292;&#24182;&#21457;&#29616;&#20102;&#28508;&#22312;&#30340;&#20559;&#35265;&#12290;</title><link>http://arxiv.org/abs/2011.00696</link><description>&lt;p&gt;
ABNIRML: &#20998;&#26512;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#27169;&#22411;&#30340;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
ABNIRML: Analyzing the Behavior of Neural IR Models. (arXiv:2011.00696v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.00696
&lt;/p&gt;
&lt;p&gt;
ABNIRML&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#27169;&#22411;&#30340;&#34892;&#20026;&#65292;&#21253;&#25324;&#20889;&#20316;&#39118;&#26684;&#12289;&#20107;&#23454;&#24615;&#12289;&#23545;&#25913;&#20889;&#21644;&#35789;&#24207;&#30340;&#25935;&#24863;&#24615;&#31561;&#29305;&#24449;&#12290;&#36890;&#36807;&#36827;&#34892;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#25506;&#31350;&#20102;&#31070;&#32463;&#27169;&#22411;&#22686;&#30410;&#30340;&#22240;&#32032;&#65292;&#24182;&#21457;&#29616;&#20102;&#28508;&#22312;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#19978;&#19979;&#25991;&#21270;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;BERT&#21644;T5&#65289;&#24050;&#32463;&#24314;&#31435;&#20102;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#30340;&#26032;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36824;&#19981;&#23436;&#20840;&#29702;&#35299;&#20026;&#20160;&#20040;&#36825;&#20123;&#26041;&#27861;&#22914;&#27492;&#26377;&#25928;&#65292;&#26159;&#20160;&#20040;&#20351;&#19968;&#20123;&#21464;&#31181;&#27604;&#20854;&#20182;&#21464;&#31181;&#26356;&#26377;&#25928;&#65292;&#20197;&#21450;&#23427;&#20204;&#21487;&#33021;&#23384;&#22312;&#21738;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#26694;&#26550;&#26469;&#20998;&#26512;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#27169;&#22411;&#34892;&#20026;&#65288;ABNIRML&#65289;&#65292;&#21253;&#25324;&#26032;&#30340;&#35786;&#26029;&#25506;&#38024;&#31867;&#22411;&#65292;&#20801;&#35768;&#25105;&#20204;&#27979;&#35797;&#20808;&#21069;&#25216;&#26415;&#26410;&#35299;&#20915;&#30340;&#20960;&#20010;&#29305;&#24449;&#65292;&#20363;&#22914;&#20889;&#20316;&#39118;&#26684;&#65292;&#20107;&#23454;&#24615;&#65292;&#23545;&#25913;&#20889;&#21644;&#35789;&#24207;&#30340;&#25935;&#24863;&#24615;&#31561;&#12290;&#20026;&#20102;&#23637;&#31034;&#36825;&#20010;&#26694;&#26550;&#30340;&#20215;&#20540;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#24471;&#20986;&#20102;&#23545;&#31070;&#32463;&#27169;&#22411;&#22686;&#30410;&#22240;&#32032;&#30340;&#35265;&#35299;&#65292;&#24182;&#30830;&#23450;&#20102;&#27169;&#22411;&#21487;&#33021;&#23384;&#22312;&#30340;&#28508;&#22312;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#19968;&#20123;&#32467;&#26524;&#35777;&#23454;&#20102;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#20363;&#22914;&#26368;&#36817;&#30340;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#23545;&#26597;&#35810;&#30340;&#30830;&#20999;&#26415;&#35821;&#21305;&#37197;&#30340;&#20381;&#36182;&#31243;&#24230;&#36739;&#20302;&#65292;&#32780;&#26159;&#21033;&#29992;&#26356;&#20016;&#23500;&#30340;&#35821;&#35328;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretrained contextualized language models such as BERT and T5 have established a new state-of-the-art for ad-hoc search. However, it is not yet well-understood why these methods are so effective, what makes some variants more effective than others, and what pitfalls they may have. We present a new comprehensive framework for Analyzing the Behavior of Neural IR ModeLs (ABNIRML), which includes new types of diagnostic probes that allow us to test several characteristics -- such as writing styles, factuality, sensitivity to paraphrasing and word order -- that are not addressed by previous techniques. To demonstrate the value of the framework, we conduct an extensive empirical study that yields insights into the factors that contribute to the neural model's gains, and identify potential unintended biases the models exhibit. Some of our results confirm conventional wisdom, like that recent neural ranking models rely less on exact term overlap with the query, and instead leverage richer ling
&lt;/p&gt;</description></item></channel></rss>