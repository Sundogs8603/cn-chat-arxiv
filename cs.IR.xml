<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>T2Ranking&#26159;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20013;&#25991;&#27573;&#33853;&#25490;&#24207;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20351;&#29992;&#20102;4&#32423;&#20998;&#32423;&#30456;&#20851;&#24615;&#35780;&#20998;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#25968;&#25454;&#38598;&#22312;&#25968;&#25454;&#35268;&#27169;&#12289;&#32454;&#31890;&#24230;&#30456;&#20851;&#24615;&#27880;&#37322;&#21644;&#38169;&#35823;&#36127;&#38754;&#38382;&#39064;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2304.03679</link><description>&lt;p&gt;
T2Ranking&#65306;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20013;&#25991;&#27573;&#33853;&#25490;&#24207;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
T2Ranking: A large-scale Chinese Benchmark for Passage Ranking. (arXiv:2304.03679v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03679
&lt;/p&gt;
&lt;p&gt;
T2Ranking&#26159;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20013;&#25991;&#27573;&#33853;&#25490;&#24207;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20351;&#29992;&#20102;4&#32423;&#20998;&#32423;&#30456;&#20851;&#24615;&#35780;&#20998;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#25968;&#25454;&#38598;&#22312;&#25968;&#25454;&#35268;&#27169;&#12289;&#32454;&#31890;&#24230;&#30456;&#20851;&#24615;&#27880;&#37322;&#21644;&#38169;&#35823;&#36127;&#38754;&#38382;&#39064;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27573;&#33853;&#25490;&#21517;&#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#65306;&#27573;&#33853;&#26816;&#32034;&#21644;&#27573;&#33853;&#37325;&#26032;&#25490;&#24207;&#65292;&#36825;&#26159;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#20013;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#37117;&#20851;&#27880;&#30340;&#37325;&#35201;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20027;&#39064;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#27573;&#33853;&#25490;&#21517;&#30340;&#24120;&#29992;&#25968;&#25454;&#38598;&#36890;&#24120;&#20851;&#27880;&#33521;&#35821;&#35821;&#35328;&#12290;&#23545;&#20110;&#38750;&#33521;&#35821;&#35821;&#22659;&#65292;&#22914;&#20013;&#25991;&#65292;&#29616;&#26377;&#30340;&#25968;&#25454;&#38598;&#22312;&#25968;&#25454;&#35268;&#27169;&#12289;&#32454;&#31890;&#24230;&#30456;&#20851;&#24615;&#27880;&#37322;&#21644;&#38169;&#35823;&#36127;&#38754;&#38382;&#39064;&#26041;&#38754;&#21463;&#21040;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;T2Ranking&#65292;&#36825;&#26159;&#19968;&#20010;&#38024;&#23545;&#20013;&#25991;&#27573;&#33853;&#25490;&#24207;&#30340;&#22823;&#35268;&#27169;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;T2Ranking&#21253;&#25324;&#26469;&#33258;&#30495;&#23454;&#25628;&#32034;&#24341;&#25806;&#30340;&#36229;&#36807;300K&#20010;&#26597;&#35810;&#21644;&#36229;&#36807;2M&#20010;&#21807;&#19968;&#30340;&#27573;&#33853;&#12290;&#19987;&#23478;&#35780;&#27880;&#21592;&#34987;&#25307;&#21215;&#65292;&#20026;&#26597;&#35810;-&#27573;&#33853;&#23545;&#25552;&#20379;4&#32423;&#20998;&#32423;&#30456;&#20851;&#24615;&#35780;&#20998;&#65288;&#32454;&#31890;&#24230;&#65289;&#65292;&#32780;&#19981;&#26159;&#20108;&#36827;&#21046;&#30456;&#20851;&#24615;&#21028;&#26029;&#65288;&#31895;&#31890;&#24230;&#65289;&#12290;&#20026;&#20102;&#20943;&#23569;&#38169;&#35823;&#36127;&#38754;&#38382;&#39064;&#65292;&#22312;&#25191;&#34892;&#30456;&#20851;&#24615;&#27880;&#37322;&#26102;&#32771;&#34385;&#26356;&#22810;&#20855;&#26377;&#36739;&#39640;&#22810;&#26679;&#24615;&#30340;&#27573;&#33853;&#65292;&#29305;&#21035;&#26159;&#22312;&#27979;&#35797;&#38598;&#20013;&#65292;&#20197;&#30830;&#20445;&#26368;&#22823;&#21270;&#35780;&#27880;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Passage ranking involves two stages: passage retrieval and passage re-ranking, which are important and challenging topics for both academics and industries in the area of Information Retrieval (IR). However, the commonly-used datasets for passage ranking usually focus on the English language. For non-English scenarios, such as Chinese, the existing datasets are limited in terms of data scale, fine-grained relevance annotation and false negative issues. To address this problem, we introduce T2Ranking, a large-scale Chinese benchmark for passage ranking. T2Ranking comprises more than 300K queries and over 2M unique passages from real-world search engines. Expert annotators are recruited to provide 4-level graded relevance scores (fine-grained) for query-passage pairs instead of binary relevance judgments (coarse-grained). To ease the false negative issues, more passages with higher diversities are considered when performing relevance annotations, especially in the test set, to ensure a m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;GenExpan&#65292;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26694;&#26550;&#65292;&#21033;&#29992;&#21069;&#32512;&#26641;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.03531</link><description>&lt;p&gt;
&#20174;&#26816;&#32034;&#21040;&#29983;&#25104;&#65306;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
From Retrieval to Generation: Efficient and Effective Entity Set Expansion. (arXiv:2304.03531v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;GenExpan&#65292;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26694;&#26550;&#65292;&#21033;&#29992;&#21069;&#32512;&#26641;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#38598;&#25193;&#23637;&#65288;ESE&#65289;&#26159;&#19968;&#39033;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#26088;&#22312;&#25193;&#23637;&#30001;&#23567;&#30340;&#31181;&#23376;&#23454;&#20307;&#38598;&#25551;&#36848;&#30340;&#30446;&#26631;&#35821;&#20041;&#31867;&#30340;&#23454;&#20307;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;ESE&#26041;&#27861;&#26159;&#22522;&#20110;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#38656;&#35201;&#25552;&#21462;&#23454;&#20307;&#30340;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#35745;&#31639;&#31181;&#23376;&#23454;&#20307;&#21644;&#20505;&#36873;&#23454;&#20307;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20004;&#20010;&#30446;&#30340;&#65292;&#23427;&#20204;&#24517;&#39035;&#36845;&#20195;&#22320;&#36941;&#21382;&#35821;&#26009;&#24211;&#21644;&#25968;&#25454;&#38598;&#20013;&#25552;&#20379;&#30340;&#23454;&#20307;&#35789;&#27719;&#65292;&#23548;&#33268;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#36739;&#24046;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#26816;&#32034;&#30340;ESE&#26041;&#27861;&#28040;&#32791;&#30340;&#26102;&#38388;&#19982;&#23454;&#20307;&#35789;&#27719;&#21644;&#35821;&#26009;&#24211;&#30340;&#22823;&#23567;&#25104;&#32447;&#24615;&#22686;&#38271;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#24335;ESE&#26694;&#26550;&#65292;Generative Entity Set Expansion (GenExpan)&#65292;&#23427;&#21033;&#29992;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#23436;&#25104;ESE&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#37319;&#29992;&#21069;&#32512;&#26641;&#26469;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entity Set Expansion (ESE) is a critical task aiming to expand entities of the target semantic class described by a small seed entity set. Most existing ESE methods are retrieval-based frameworks that need to extract the contextual features of entities and calculate the similarity between seed entities and candidate entities. To achieve the two purposes, they should iteratively traverse the corpus and the entity vocabulary provided in the datasets, resulting in poor efficiency and scalability. The experimental results indicate that the time consumed by the retrieval-based ESE methods increases linearly with entity vocabulary and corpus size. In this paper, we firstly propose a generative ESE framework, Generative Entity Set Expansion (GenExpan), which utilizes a generative pre-trained language model to accomplish ESE task. Specifically, a prefix tree is employed to guarantee the validity of entity generation, and automatically generated class names are adopted to guide the model to gen
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#24335;AI&#21487;&#20197;&#20811;&#26381;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38480;&#21046;&#65292;&#20351;&#20854;&#33021;&#22815;&#29983;&#25104;&#28385;&#36275;&#29992;&#25143;&#29305;&#23450;&#20449;&#24687;&#38656;&#27714;&#30340;&#20869;&#23481;&#65292;&#24182;&#19988;&#29992;&#25143;&#21487;&#20197;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#26469;&#25351;&#23548;&#20869;&#23481;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2304.03516</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#25512;&#33616;&#65306;&#36208;&#21521;&#19979;&#19968;&#20195;&#25512;&#33616;&#31995;&#32479;&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Recommendation: Towards Next-generation Recommender Paradigm. (arXiv:2304.03516v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03516
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;AI&#21487;&#20197;&#20811;&#26381;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38480;&#21046;&#65292;&#20351;&#20854;&#33021;&#22815;&#29983;&#25104;&#28385;&#36275;&#29992;&#25143;&#29305;&#23450;&#20449;&#24687;&#38656;&#27714;&#30340;&#20869;&#23481;&#65292;&#24182;&#19988;&#29992;&#25143;&#21487;&#20197;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#26469;&#25351;&#23548;&#20869;&#23481;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#20174;&#39033;&#30446;&#38598;&#21512;&#20013;&#26816;&#32034;&#39033;&#30446;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#22522;&#20110;&#26816;&#32034;&#30340;&#25512;&#33616;&#33539;&#24335;&#38754;&#20020;&#20004;&#20010;&#38480;&#21046;&#65306;1&#65289;&#35821;&#26009;&#24211;&#20013;&#30340;&#20154;&#24037;&#29983;&#25104;&#39033;&#30446;&#21487;&#33021;&#26080;&#27861;&#28385;&#36275;&#29992;&#25143;&#30340;&#22810;&#26679;&#21270;&#20449;&#24687;&#38656;&#27714;&#65292;2&#65289;&#29992;&#25143;&#36890;&#24120;&#36890;&#36807;&#28857;&#20987;&#31561;&#34987;&#21160;&#19988;&#20302;&#25928;&#30340;&#21453;&#39304;&#26041;&#24335;&#35843;&#25972;&#25512;&#33616;&#20869;&#23481;&#12290;&#36817;&#24180;&#26469;&#65292;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#26174;&#33879;&#25104;&#21151;&#65292;&#20855;&#26377;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#28508;&#21147;&#65306;1&#65289;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#21487;&#20197;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#20869;&#23481;&#20197;&#28385;&#36275;&#29992;&#25143;&#29305;&#23450;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;2&#65289;&#26032;&#20852;&#30340;ChatGPT&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#26174;&#33879;&#25552;&#39640;&#20102;&#29992;&#25143;&#20934;&#30830;&#34920;&#36798;&#20449;&#24687;&#38656;&#27714;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#30340;&#22823;&#29190;&#21457;&#25351;&#24341;&#25105;&#20204;&#36208;&#21521;&#19979;&#19968;&#20195;&#25512;&#33616;&#33539;&#24335;&#65292;&#20855;&#26377;&#20004;&#20010;&#26032;&#30340;&#30446;&#26631;&#65306;1&#65289;&#36890;&#36807;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20010;&#24615;&#21270;&#20869;&#23481;&#65292;2&#65289;&#25972;&#21512;&#29992;&#25143;&#25351;&#20196;&#20197;&#25351;&#23548;&#30001;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems typically retrieve items from an item corpus for personalized recommendations. However, such a retrieval-based recommender paradigm faces two limitations: 1) the human-generated items in the corpus might fail to satisfy the users' diverse information needs, and 2) users usually adjust the recommendations via passive and inefficient feedback such as clicks. Nowadays, AI-Generated Content (AIGC) has revealed significant success across various domains, offering the potential to overcome these limitations: 1) generative AI can produce personalized items to meet users' specific information needs, and 2) the newly emerged ChatGPT significantly facilitates users to express information needs more precisely via natural language instructions. In this light, the boom of AIGC points the way towards the next-generation recommender paradigm with two new objectives: 1) generating personalized content through generative AI, and 2) integrating user instructions to guide content gene
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;CONTINUOUS&#65292;&#21487;&#20197;&#23545;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#36827;&#34892;&#36830;&#32493;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;&#65292;&#23427;&#36890;&#36807;&#23558;&#23884;&#20837;&#22823;&#23567;&#36873;&#25321;&#24314;&#27169;&#20026;&#36830;&#32493;&#21464;&#37327;&#35299;&#20915;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#35777;&#23454;&#20102;&#23427;&#30340;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.03501</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#36830;&#32493;&#36755;&#20837;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Continuous Input Embedding Size Search For Recommender Systems. (arXiv:2304.03501v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03501
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;CONTINUOUS&#65292;&#21487;&#20197;&#23545;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#36827;&#34892;&#36830;&#32493;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;&#65292;&#23427;&#36890;&#36807;&#23558;&#23884;&#20837;&#22823;&#23567;&#36873;&#25321;&#24314;&#27169;&#20026;&#36830;&#32493;&#21464;&#37327;&#35299;&#20915;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#35777;&#23454;&#20102;&#23427;&#30340;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#26159;&#29616;&#20170;&#25512;&#33616;&#31995;&#32479;&#26368;&#27969;&#34892;&#30340;&#22522;&#30784;&#65292;&#20854;&#24615;&#33021;&#21331;&#36234;&#12290;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#36890;&#36807;&#23545;&#29992;&#25143;&#21644;&#39033;&#30446;&#36827;&#34892;&#34920;&#31034;&#65292;&#29992;&#20110;&#23545;&#25104;&#23545;&#30456;&#20284;&#24230;&#30340;&#35745;&#31639;&#12290;&#25152;&#26377;&#23884;&#20837;&#21521;&#37327;&#20256;&#32479;&#19978;&#37117;&#34987;&#38480;&#21046;&#22312;&#19968;&#20010;&#30456;&#23545;&#36739;&#22823;&#30340;&#32479;&#19968;&#22823;&#23567;&#65288;&#20363;&#22914;256&#32500;&#65289;&#12290;&#38543;&#30528;&#24403;&#20195;&#30005;&#23376;&#21830;&#21153;&#20013;&#29992;&#25143;&#21644;&#39033;&#30446;&#30446;&#24405;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#36825;&#31181;&#35774;&#35745;&#26174;&#28982;&#21464;&#24471;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#20419;&#36827;&#36731;&#37327;&#32423;&#25512;&#33616;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26368;&#36817;&#24320;&#36767;&#20102;&#19968;&#20123;&#26426;&#20250;&#65292;&#29992;&#20110;&#35782;&#21035;&#19981;&#21516;&#29992;&#25143;/&#39033;&#30446;&#30340;&#19981;&#21516;&#23884;&#20837;&#22823;&#23567;&#12290;&#28982;&#32780;&#65292;&#21463;&#21040;&#25628;&#32034;&#25928;&#29575;&#21644;&#23398;&#20064;&#26368;&#20248;RL&#31574;&#30053;&#30340;&#38480;&#21046;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;RL&#30340;&#26041;&#27861;&#34987;&#38480;&#21046;&#20026;&#39640;&#24230;&#31163;&#25955;&#30340;&#39044;&#23450;&#20041;&#23884;&#20837;&#22823;&#23567;&#36873;&#39033;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#34987;&#24191;&#27867;&#24573;&#35270;&#30340;&#28508;&#21147;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#35745;&#31639;&#39044;&#31639;&#19979;&#24341;&#20837;&#26356;&#32454;&#30340;&#31890;&#24230;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;CONTINUOUS&#65292;&#21487;&#20197;&#23545;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#36827;&#34892;&#36830;&#32493;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;&#12290;CONTINUOUS&#36890;&#36807;&#23558;&#23884;&#20837;&#22823;&#23567;&#36873;&#25321;&#24314;&#27169;&#20026;&#36830;&#32493;&#21464;&#37327;&#21644;&#21046;&#23450;&#21487;&#24494;&#20248;&#21270;&#38382;&#39064;&#30340;&#24418;&#24335;&#26469;&#35299;&#20915;&#20043;&#21069;&#24037;&#20316;&#30340;&#25361;&#25112;&#12290;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;CONTINUOUS&#20248;&#20110;&#22522;&#32447;&#30340;&#20248;&#36234;&#24615;&#65292;&#39564;&#35777;&#20102;&#21160;&#24577;&#20248;&#21270;&#23884;&#20837;&#22823;&#23567;&#30340;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e-commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a giv
&lt;/p&gt;</description></item><item><title>CAPOT&#20351;&#29992;&#21518;&#35757;&#32451;&#23545;&#27604;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#20110;&#22122;&#22768;&#26597;&#35810;&#30340;&#20581;&#22766;&#24615;&#65292;&#34920;&#29616;&#31867;&#20284;&#20110;&#25968;&#25454;&#22686;&#24378;&#20294;&#27809;&#26377;&#20854;&#24320;&#38144;&#12290;</title><link>http://arxiv.org/abs/2304.03401</link><description>&lt;p&gt;
CAPOT: &#20351;&#29992;&#21518;&#35757;&#32451;&#23545;&#27604;&#23545;&#40784;&#21019;&#24314;&#24378;&#20581;&#30340;&#23494;&#38598;&#26597;&#35810;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
CAPOT: Creating Robust Dense Query Encoders using Post Training Contrastive Alignment. (arXiv:2304.03401v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03401
&lt;/p&gt;
&lt;p&gt;
CAPOT&#20351;&#29992;&#21518;&#35757;&#32451;&#23545;&#27604;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#20110;&#22122;&#22768;&#26597;&#35810;&#30340;&#20581;&#22766;&#24615;&#65292;&#34920;&#29616;&#31867;&#20284;&#20110;&#25968;&#25454;&#22686;&#24378;&#20294;&#27809;&#26377;&#20854;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#35789;&#34920;&#31034;&#30340;&#25104;&#21151;&#21644;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#30340;&#36827;&#27493;&#20351;&#24471;&#22522;&#20110;&#23494;&#38598;&#21521;&#37327;&#30340;&#26816;&#32034;&#25104;&#20026;&#27573;&#33853;&#21644;&#25991;&#26723;&#25490;&#21517;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#21452;&#32534;&#30721;&#22120;&#34429;&#28982;&#26377;&#25928;&#21644;&#39640;&#25928;&#65292;&#20294;&#23545;&#26597;&#35810;&#20998;&#24067;&#21644;&#22024;&#26434;&#26597;&#35810;&#21464;&#21270;&#24456;&#33030;&#24369;&#12290;&#25968;&#25454;&#22686;&#24378;&#21487;&#20197;&#20351;&#27169;&#22411;&#26356;&#21152;&#20581;&#22766;&#65292;&#20294;&#20250;&#24341;&#20837;&#35757;&#32451;&#38598;&#29983;&#25104;&#30340;&#24320;&#38144;&#65292;&#24182;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#21644;&#32034;&#24341;&#37325;&#24314;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102; Contrastive Alignment POst Training (CAPOT)&#65292;&#19968;&#31181;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#25991;&#26723;&#32534;&#30721;&#22120;&#65292;&#35753;&#26597;&#35810;&#32534;&#30721;&#22120;&#23398;&#20064;&#23558;&#22024;&#26434;&#26597;&#35810;&#19982;&#20854;&#26410;&#26356;&#25913;&#30340;&#26681;&#23545;&#40784;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#20581;&#22766;&#24615;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102; CAPOT &#22312; MSMARCO&#12289;&#33258;&#28982;&#38382;&#39064;&#21644; Trivia QA &#27573;&#33853;&#26816;&#32034;&#30340;&#22024;&#26434;&#21464;&#20307;&#19978;&#65292;&#21457;&#29616; CAPOT &#20855;&#26377;&#19982;&#25968;&#25454;&#22686;&#24378;&#31867;&#20284;&#30340;&#24433;&#21709;&#65292;&#20294;&#27809;&#26377;&#23427;&#30340;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of contextual word representations and advances in neural information retrieval have made dense vector-based retrieval a standard approach for passage and document ranking. While effective and efficient, dual-encoders are brittle to variations in query distributions and noisy queries. Data augmentation can make models more robust but introduces overhead to training set generation and requires retraining and index regeneration. We present Contrastive Alignment POst Training (CAPOT), a highly efficient finetuning method that improves model robustness without requiring index regeneration, the training set optimization, or alteration. CAPOT enables robust retrieval by freezing the document encoder while the query encoder learns to align noisy queries with their unaltered root. We evaluate CAPOT noisy variants of MSMARCO, Natural Questions, and Trivia QA passage retrieval, finding CAPOT has a similar impact as data augmentation with none of its overhead.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#37051;&#25509;&#30697;&#38453;&#65292;&#23427;&#21253;&#25324;&#20102;&#29992;&#25143;-&#29992;&#25143;&#21644;&#39033;&#30446;-&#39033;&#30446;&#30340;&#30456;&#20851;&#24615;&#65292;&#20197;&#21450;&#19968;&#20010;&#32463;&#36807;&#36866;&#24403;&#35774;&#35745;&#30340;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#65292;&#24182;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;top-K&#37319;&#26679;&#22686;&#24378;&#20102;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#65292;&#20197;&#26356;&#22909;&#22320;&#36866;&#24212;&#25152;&#26377;&#29992;&#25143;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2304.03344</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#22270;&#21327;&#20316;&#20449;&#21495;&#21435;&#22122;&#19982;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Graph Collaborative Signals Denoising and Augmentation for Recommendation. (arXiv:2304.03344v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03344
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#37051;&#25509;&#30697;&#38453;&#65292;&#23427;&#21253;&#25324;&#20102;&#29992;&#25143;-&#29992;&#25143;&#21644;&#39033;&#30446;-&#39033;&#30446;&#30340;&#30456;&#20851;&#24615;&#65292;&#20197;&#21450;&#19968;&#20010;&#32463;&#36807;&#36866;&#24403;&#35774;&#35745;&#30340;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#65292;&#24182;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;top-K&#37319;&#26679;&#22686;&#24378;&#20102;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#65292;&#20197;&#26356;&#22909;&#22320;&#36866;&#24212;&#25152;&#26377;&#29992;&#25143;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21327;&#20316;&#36807;&#28388;&#65288;GCF&#65289;&#26159;&#25429;&#25417;&#25512;&#33616;&#31995;&#32479;&#20013;&#39640;&#38454;&#21327;&#21516;&#20449;&#21495;&#30340;&#27969;&#34892;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;GCF&#30340;&#21452;&#21521;&#37051;&#25509;&#30697;&#38453;&#65292;&#20854;&#23450;&#20041;&#20102;&#22522;&#20110;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#36827;&#34892;&#32858;&#21512;&#30340;&#37051;&#23621;&#65292;&#23545;&#20110;&#26377;&#22823;&#37327;&#20132;&#20114;&#20294;&#19981;&#36275;&#30340;&#29992;&#25143;/&#39033;&#30446;&#26469;&#35828;&#21487;&#33021;&#26159;&#22024;&#26434;&#30340;&#12290;&#27492;&#22806;&#65292;&#37051;&#25509;&#30697;&#38453;&#24573;&#30053;&#20102;&#29992;&#25143;-&#29992;&#25143;&#21644;&#39033;&#30446;-&#39033;&#30446;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#21487;&#33021;&#38480;&#21046;&#20102;&#32858;&#21512;&#30340;&#26377;&#30410;&#37051;&#23621;&#30340;&#33539;&#22260;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#37051;&#25509;&#30697;&#38453;&#65292;&#23427;&#21253;&#25324;&#20102;&#29992;&#25143;-&#29992;&#25143;&#21644;&#39033;&#30446;-&#39033;&#30446;&#30340;&#30456;&#20851;&#24615;&#65292;&#20197;&#21450;&#19968;&#20010;&#32463;&#36807;&#36866;&#24403;&#35774;&#35745;&#30340;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#65292;&#20197;&#24179;&#34913;&#25152;&#26377;&#29992;&#25143;&#20043;&#38388;&#30340;&#20132;&#20114;&#25968;&#37327;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#39044;&#20808;&#35757;&#32451;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#26041;&#27861;&#26469;&#33719;&#24471;&#29992;&#25143;/&#39033;&#30446;&#23884;&#20837;&#65292;&#28982;&#21518;&#36890;&#36807;top-K&#37319;&#26679;&#22686;&#24378;&#20102;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#12290;&#25105;&#20204;&#36824;&#22686;&#24378;&#20102;&#23545;&#31216;&#30340;&#29992;&#25143;-&#29992;&#25143;&#21644;&#39033;&#30446;-&#39033;&#30446;&#30456;&#20851;&#32452;&#20214;&#65292;&#20197;&#26356;&#22909;&#22320;&#36866;&#24212;&#25152;&#26377;&#29992;&#25143;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph collaborative filtering (GCF) is a popular technique for capturing high-order collaborative signals in recommendation systems. However, GCF's bipartite adjacency matrix, which defines the neighbors being aggregated based on user-item interactions, can be noisy for users/items with abundant interactions and insufficient for users/items with scarce interactions. Additionally, the adjacency matrix ignores user-user and item-item correlations, which can limit the scope of beneficial neighbors being aggregated.  In this work, we propose a new graph adjacency matrix that incorporates user-user and item-item correlations, as well as a properly designed user-item interaction matrix that balances the number of interactions across all users. To achieve this, we pre-train a graph-based recommendation method to obtain users/items embeddings, and then enhance the user-item interaction matrix via top-K sampling. We also augment the symmetric user-user and item-item correlation components to th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#20174;&#19981;&#21516;&#23545;&#35805;QA&#35821;&#26009;&#24211;&#20013;&#29983;&#25104;&#30340;ChatGPT&#30340;&#21709;&#24212;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#27491;&#30830;&#31572;&#26696;&#30340;&#30456;&#20284;&#24230;&#12290;&#30740;&#31350;&#21457;&#29616;ChatGPT&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#38169;&#35823;&#30340;&#31572;&#26696;&#65292;&#25552;&#20379;&#20102;&#28508;&#22312;&#29992;&#25143;&#21644;&#24320;&#21457;&#32773;&#30340;&#23453;&#36149;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2304.03325</link><description>&lt;p&gt;
ChatGPT-Crawler&#65306;&#21457;&#29616;ChatGPT&#26159;&#21542;&#30495;&#30340;&#30693;&#36947;&#33258;&#24049;&#22312;&#35828;&#20160;&#20040;&#12290;&#65288;arXiv:2304.03325v1 [cs.CL]&#65289;
&lt;/p&gt;
&lt;p&gt;
ChatGPT-Crawler: Find out if ChatGPT really knows what it's talking about. (arXiv:2304.03325v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03325
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#20174;&#19981;&#21516;&#23545;&#35805;QA&#35821;&#26009;&#24211;&#20013;&#29983;&#25104;&#30340;ChatGPT&#30340;&#21709;&#24212;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#27491;&#30830;&#31572;&#26696;&#30340;&#30456;&#20284;&#24230;&#12290;&#30740;&#31350;&#21457;&#29616;ChatGPT&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#38169;&#35823;&#30340;&#31572;&#26696;&#65292;&#25552;&#20379;&#20102;&#28508;&#22312;&#29992;&#25143;&#21644;&#24320;&#21457;&#32773;&#30340;&#23453;&#36149;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22240;&#20854;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#30340;&#20986;&#33394;&#34920;&#29616;&#32780;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#26497;&#22823;&#20852;&#36259;&#12290;&#20854;&#20013;&#65292;OpenAI&#24320;&#21457;&#30340;ChatGPT&#24050;&#32463;&#25104;&#20026;&#26089;&#26399;&#37319;&#29992;&#32773;&#20013;&#38750;&#24120;&#27969;&#34892;&#30340;&#27169;&#22411;&#65292;&#20182;&#20204;&#29978;&#33267;&#23558;&#20854;&#35270;&#20026;&#23458;&#25143;&#26381;&#21153;&#12289;&#25945;&#32946;&#12289;&#21307;&#30103;&#21644;&#37329;&#34701;&#31561;&#35768;&#22810;&#39046;&#22495;&#30340;&#30772;&#22351;&#24615;&#25216;&#26415;&#12290;&#29702;&#35299;&#36825;&#20123;&#21021;&#26399;&#29992;&#25143;&#30340;&#35266;&#28857;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#20026;&#19981;&#21516;&#39046;&#22495;&#25216;&#26415;&#30340;&#28508;&#22312;&#20248;&#21183;&#12289;&#21155;&#21183;&#12289;&#25104;&#21151;&#25110;&#22833;&#36133;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#12290;&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;ChatGPT&#20174;&#19981;&#21516;&#23545;&#35805;QA&#35821;&#26009;&#24211;&#20013;&#29983;&#25104;&#30340;&#21709;&#24212;&#12290;&#30740;&#31350;&#20351;&#29992;BERT&#30456;&#20284;&#24230;&#20998;&#25968;&#23558;&#36825;&#20123;&#21709;&#24212;&#19982;&#27491;&#30830;&#31572;&#26696;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#33719;&#24471;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#65288;NLI&#65289;&#26631;&#31614;&#12290;&#36824;&#35745;&#31639;&#24182;&#27604;&#36739;&#20102;&#35780;&#20272;&#20998;&#25968;&#65292;&#20197;&#30830;&#23450;GPT-3&#65286;GPT-4&#30340;&#25972;&#20307;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#30830;&#23450;&#20102;ChatGPT&#25552;&#20379;&#38169;&#35823;&#31572;&#26696;&#30340;&#24773;&#20917;&#65292;&#20026;&#30456;&#20851;&#39046;&#22495;&#25552;&#20379;&#20102;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models have gained considerable interest for their impressive performance on various tasks. Among these models, ChatGPT developed by OpenAI has become extremely popular among early adopters who even regard it as a disruptive technology in many fields like customer service, education, healthcare, and finance. It is essential to comprehend the opinions of these initial users as it can provide valuable insights into the potential strengths, weaknesses, and success or failure of the technology in different areas. This research examines the responses generated by ChatGPT from different Conversational QA corpora. The study employed BERT similarity scores to compare these responses with correct answers and obtain Natural Language Inference(NLI) labels. Evaluation scores were also computed and compared to determine the overall performance of GPT-3 \&amp; GPT-4. Additionally, the study identified instances where ChatGPT provided incorrect answers to questions, providing insights into
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#22810;&#27169;&#24577;&#33258;&#30417;&#30563;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26377;&#25928;&#22320;&#23398;&#20064;&#27169;&#24577;&#24863;&#30693;&#29992;&#25143;&#20559;&#22909;&#21644;&#36328;&#27169;&#24577;&#20381;&#36182;&#20851;&#31995;&#30340;&#33258;&#25105;&#30417;&#25511;&#20449;&#21495;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#25928;&#26524;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#21644;&#22810;&#27169;&#24577;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2302.10632</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#33258;&#30417;&#30563;&#23398;&#20064;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Multi-Modal Self-Supervised Learning for Recommendation. (arXiv:2302.10632v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10632
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#22810;&#27169;&#24577;&#33258;&#30417;&#30563;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26377;&#25928;&#22320;&#23398;&#20064;&#27169;&#24577;&#24863;&#30693;&#29992;&#25143;&#20559;&#22909;&#21644;&#36328;&#27169;&#24577;&#20381;&#36182;&#20851;&#31995;&#30340;&#33258;&#25105;&#30417;&#25511;&#20449;&#21495;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#25928;&#26524;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#21644;&#22810;&#27169;&#24577;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#20998;&#20139;&#24179;&#21488;&#65288;&#20363;&#22914; TikTok&#12289;YouTube&#65289;&#30340;&#23835;&#36215;&#20351;&#24471;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#33021;&#22815;&#23558;&#21508;&#31181;&#27169;&#24335;&#65288;&#20363;&#22914;&#35270;&#35273;&#12289;&#25991;&#26412;&#21644;&#22768;&#38899;&#65289;&#32435;&#20837;&#28508;&#22312;&#29992;&#25143;&#34920;&#31034;&#27861;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#22810;&#27169;&#24577;&#25512;&#33616;&#24037;&#20316;&#21033;&#29992;&#22810;&#23186;&#20307;&#20869;&#23481;&#29305;&#24449;&#22686;&#24378;&#29289;&#21697;&#23884;&#20837;&#65292;&#20294;&#23427;&#20204;&#30340;&#27169;&#22411;&#34920;&#31034;&#33021;&#21147;&#21463;&#21040;&#37325;&#26631;&#31614;&#20381;&#36182;&#24615;&#21644;&#31232;&#30095;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#30340;&#24433;&#21709;&#12290;&#21463;&#33258;&#30417;&#25511;&#23398;&#20064;&#22312;&#20943;&#36731;&#26631;&#31614;&#31232;&#32570;&#24615;&#38382;&#39064;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25506;&#32034;&#26377;&#25928;&#22320;&#23398;&#20064;&#27169;&#24577;&#24863;&#30693;&#29992;&#25143;&#20559;&#22909;&#21644;&#36328;&#27169;&#24577;&#20381;&#36182;&#20851;&#31995;&#30340;&#33258;&#25105;&#30417;&#25511;&#20449;&#21495;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#27169;&#24577;&#33258;&#30417;&#25511;&#23398;&#20064;&#65288;MMSSL&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#34920;&#24449;&#29992;&#25143;-&#29289;&#21697;&#21327;&#21516;&#35270;&#22270;&#21644;&#29289;&#21697;&#22810;&#27169;&#24577;&#35821;&#20041;&#35270;&#22270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#27169;&#24577;&#24863;&#30693;&#30340;&#20132;&#20114;&#32467;&#26500;&#23398;&#20064;&#32452;&#20214;&#65307;&#20026;&#20102;&#22312;&#27169;&#24577;&#30456;&#20851;&#30340;&#25512;&#33616;&#20219;&#21153;&#20013;&#36827;&#19968;&#27493;&#21033;&#29992;&#33258;&#25105;&#30417;&#25511;&#20449;&#21495;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#23398;&#20064;&#29992;&#25143;&#20869;&#37096;&#27169;&#24577;&#20998;&#24067;&#30340;&#27169;&#24577;&#30456;&#20851;&#30340;&#39044;&#25991;&#26412;&#20219;&#21153;&#12290;&#23545;&#21508;&#31181;&#30495;&#23454;&#19990;&#30028;&#25512;&#33616;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MMSSL&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#25512;&#33616;&#22522;&#32447;&#21644;&#22810;&#27169;&#24577;&#23545;&#24212;&#29289;&#65292;&#29305;&#21035;&#26159;&#22312;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
The online emergence of multi-modal sharing platforms (eg, TikTok, Youtube) is powering personalized recommender systems to incorporate various modalities (eg, visual, textual and acoustic) into the latent user representations. While existing works on multi-modal recommendation exploit multimedia content features in enhancing item embeddings, their model representation capability is limited by heavy label reliance and weak robustness on sparse user behavior data. Inspired by the recent progress of self-supervised learning in alleviating label scarcity issue, we explore deriving self-supervision signals with effectively learning of modality-aware user preference and cross-modal dependencies. To this end, we propose a new Multi-Modal Self-Supervised Learning (MMSSL) method which tackles two key challenges. Specifically, to characterize the inter-dependency between the user-item collaborative view and item multi-modal semantic view, we design a modality-aware interactive structure learnin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#65292;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2302.09051</link><description>&lt;p&gt;
&#22797;&#26434;&#38382;&#31572;&#21644;&#35821;&#35328;&#27169;&#22411;&#28151;&#21512;&#26550;&#26500;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Complex QA and language models hybrid architectures, Survey. (arXiv:2302.09051v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#65292;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#26631;&#20934;&#38382;&#39064;&#19978;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#65292;&#20294;&#22312;&#35299;&#20915;&#26356;&#20855;&#20307;&#30340;&#22797;&#26434;&#38382;&#39064;&#26102;&#65288;&#22914;&#22312;&#19981;&#21516;&#25991;&#21270;&#20013;&#20010;&#20154;&#33258;&#30001;&#27010;&#24565;&#30340;&#21464;&#21270;&#22914;&#20309;&#65311;&#20160;&#20040;&#26159;&#20026;&#20943;&#23569;&#27668;&#20505;&#21464;&#21270;&#32780;&#23454;&#29616;&#30340;&#26368;&#20339;&#21457;&#30005;&#26041;&#27861;&#32452;&#21512;&#65311;&#65289;&#65292;&#38656;&#35201;&#29305;&#23450;&#30340;&#26550;&#26500;&#12289;&#30693;&#35782;&#12289;&#25216;&#33021;&#12289;&#26041;&#27861;&#12289;&#25935;&#24863;&#25968;&#25454;&#20445;&#25252;&#12289;&#21487;&#35299;&#37322;&#24615;&#12289;&#20154;&#31867;&#23457;&#25209;&#21644;&#22810;&#21151;&#33021;&#21453;&#39304;&#12290;&#26368;&#36817;&#30340;&#39033;&#30446;&#22914;ChatGPT&#21644;GALACTICA&#20801;&#35768;&#38750;&#19987;&#19994;&#20154;&#21592;&#20102;&#35299;LLM&#22312;&#22797;&#26434;QA&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#20197;&#21450;&#21516;&#31561;&#24378;&#22823;&#30340;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23457;&#26597;&#25152;&#38656;&#30340;&#25216;&#33021;&#21644;&#35780;&#20272;&#25216;&#26415;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32508;&#36848;&#20102;&#29616;&#26377;&#30340;&#28151;&#21512;&#26550;&#26500;&#65292;&#23558;LLM&#19982;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#12289;&#20449;&#24687;&#26816;&#32034;&#12289;&#30693;&#35782;&#22270;&#35889;&#21644;&#20854;&#20182;AI/ML&#25216;&#26415;&#30456;&#32467;&#21512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;&#36825;&#20123;CQA&#31995;&#32479;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#26410;&#26469;&#30740;&#31350;&#30340;&#21487;&#33021;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper reviews the state-of-the-art of language models architectures and strategies for "complex" question-answering (QA, CQA, CPS) with a focus on hybridization. Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems (e.g. How does the concept of personal freedom vary between different cultures ? What is the best mix of power generation methods to reduce climate change ?) you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of LLM in complex QA. In this paper, we start by reviewing required skills and evaluation techniques. We integrate findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#26041;&#27861;&#30340;&#22312;&#32447;&#23454;&#39564;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#65292;&#23558;&#19981;&#23436;&#25972;&#25351;&#26631;&#20540;&#30340;&#29992;&#25143;&#20998;&#20026;&#35775;&#23458;&#21644;&#32570;&#22833;&#36141;&#20080;&#32773;&#20004;&#32452;&#65292;&#20351;&#29992;$k$-&#26368;&#36817;&#37051;&#22635;&#34917;&#26041;&#27861;&#65292;&#24182;&#32771;&#34385;&#23454;&#39564;&#29305;&#23450;&#30340;&#29305;&#24449;&#21644;&#29992;&#25143;&#30340;&#36141;&#29289;&#36335;&#24452;&#27963;&#21160;&#65292;&#21516;&#26102;&#20351;&#29992;&#20998;&#23618;&#21644;&#32858;&#31867;&#32467;&#21512;&#30340;&#26041;&#24335;&#25552;&#39640;&#22635;&#34917;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2209.06125</link><description>&lt;p&gt;
&#22522;&#20110;&#32858;&#31867;&#30340;&#32570;&#22833;&#36141;&#20080;&#32773;&#22312;&#32447;&#23454;&#39564;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Clustering-based Imputation for Dropout Buyers in Large-scale Online Experimentation. (arXiv:2209.06125v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.06125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#26041;&#27861;&#30340;&#22312;&#32447;&#23454;&#39564;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#65292;&#23558;&#19981;&#23436;&#25972;&#25351;&#26631;&#20540;&#30340;&#29992;&#25143;&#20998;&#20026;&#35775;&#23458;&#21644;&#32570;&#22833;&#36141;&#20080;&#32773;&#20004;&#32452;&#65292;&#20351;&#29992;$k$-&#26368;&#36817;&#37051;&#22635;&#34917;&#26041;&#27861;&#65292;&#24182;&#32771;&#34385;&#23454;&#39564;&#29305;&#23450;&#30340;&#29305;&#24449;&#21644;&#29992;&#25143;&#30340;&#36141;&#29289;&#36335;&#24452;&#27963;&#21160;&#65292;&#21516;&#26102;&#20351;&#29992;&#20998;&#23618;&#21644;&#32858;&#31867;&#32467;&#21512;&#30340;&#26041;&#24335;&#25552;&#39640;&#22635;&#34917;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#23454;&#39564;&#20013;&#65292;&#21512;&#36866;&#30340;&#24230;&#37327;&#25351;&#26631;&#65288;&#27604;&#22914;&#36141;&#20080;&#65289;&#21487;&#20197;&#25552;&#20379;&#25903;&#25345;&#20551;&#35774;&#21644;&#22686;&#24378;&#20915;&#31574;&#36807;&#31243;&#30340;&#24378;&#26377;&#21147;&#35777;&#25454;&#12290;&#20294;&#26159;&#65292;&#22312;&#32447;&#23454;&#39564;&#20013;&#32463;&#24120;&#20986;&#29616;&#19981;&#23436;&#25972;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#20351;&#24471;&#21487;&#29992;&#25968;&#25454;&#27604;&#35745;&#21010;&#30340;&#22312;&#32447;&#23454;&#39564;&#65288;&#27604;&#22914;A/B&#27979;&#35797;&#65289;&#35201;&#23569;&#24471;&#22810;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32570;&#22833;&#36141;&#20080;&#32773;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#25351;&#26631;&#20540;&#19981;&#23436;&#25972;&#30340;&#29992;&#25143;&#20998;&#20026;&#20004;&#32452;&#65306;&#35775;&#23458;&#21644;&#32570;&#22833;&#36141;&#20080;&#32773;&#12290;&#20026;&#20102;&#20998;&#26512;&#19981;&#23436;&#25972;&#30340;&#25351;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;$k$-&#26368;&#36817;&#37051;&#22635;&#34917;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#22635;&#34917;&#26041;&#27861;&#32771;&#34385;&#20102;&#23454;&#39564;&#29305;&#23450;&#30340;&#29305;&#24449;&#21644;&#29992;&#25143;&#27839;&#36141;&#29289;&#36335;&#24452;&#30340;&#27963;&#21160;&#65292;&#20801;&#35768;&#19981;&#21516;&#30340;&#29992;&#25143;&#26377;&#19981;&#21516;&#30340;&#22635;&#34917;&#20540;&#12290;&#20026;&#20102;&#26041;&#20415;&#22320;&#22635;&#34917;&#22312;&#32447;&#23454;&#39564;&#20013;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#29992;&#20998;&#23618;&#21644;&#32858;&#31867;&#32467;&#21512;&#30340;&#26041;&#24335;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#19982;&#29616;&#26377;&#30340;&#27604;&#36739;&#26041;&#27861;&#30456;&#27604;&#36739;&#20026;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online experimentation, appropriate metrics (e.g., purchase) provide strong evidence to support hypotheses and enhance the decision-making process. However, incomplete metrics are frequently occurred in the online experimentation, making the available data to be much fewer than the planned online experiments (e.g., A/B testing). In this work, we introduce the concept of dropout buyers and categorize users with incomplete metric values into two groups: visitors and dropout buyers. For the analysis of incomplete metrics, we propose a clustering-based imputation method using $k$-nearest neighbors. Our proposed imputation method considers both the experiment-specific features and users' activities along their shopping paths, allowing different imputation values for different users. To facilitate efficient imputation of large-scale data sets in online experimentation, the proposed method uses a combination of stratification and clustering. The performance of the proposed method is compar
&lt;/p&gt;</description></item></channel></rss>