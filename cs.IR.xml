<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#24615;&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#32622;&#20449;&#24230;&#24230;&#37327;&#21644;&#35299;&#37322;&#26469;&#22686;&#24378;&#31995;&#32479;&#29983;&#25104;&#30340;&#25512;&#33616;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.12034</link><description>&lt;p&gt;
&#31526;&#21512;&#24615;&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Conformal Group Recommender System. (arXiv:2307.12034v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#24615;&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#32622;&#20449;&#24230;&#24230;&#37327;&#21644;&#35299;&#37322;&#26469;&#22686;&#24378;&#31995;&#32479;&#29983;&#25104;&#30340;&#25512;&#33616;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#65288;GRS&#65289;&#22312;&#22522;&#20110;&#32676;&#20307;&#20559;&#22909;&#32780;&#19981;&#26159;&#20010;&#20154;&#20559;&#22909;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#26080;&#23613;&#30340;&#24211;&#23384;&#20013;&#21457;&#29616;&#30456;&#20851;&#29289;&#21697;&#33267;&#20851;&#37325;&#35201;&#65292;&#20363;&#22914;&#21521;&#19968;&#32676;&#20154;&#25512;&#33616;&#30005;&#24433;&#12289;&#39184;&#39302;&#25110;&#26053;&#28216;&#30446;&#30340;&#22320;&#12290;&#20256;&#32479;&#30340;&#32676;&#20307;&#25512;&#33616;&#27169;&#22411;&#34987;&#35774;&#35745;&#20026;&#20687;&#19968;&#20010;&#40657;&#30418;&#23376;&#65292;&#20005;&#26684;&#20851;&#27880;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#23558;&#35299;&#37322;&#25512;&#33616;&#30340;&#36131;&#20219;&#25918;&#22312;&#29992;&#25143;&#36523;&#19978;&#12290;&#36817;&#24180;&#26469;&#65292;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#30740;&#31350;&#30340;&#37325;&#28857;&#24050;&#20174;&#20165;&#20165;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#36716;&#21521;&#22686;&#21152;&#33258;&#20449;&#24230;&#21644;&#35299;&#37322;&#31561;&#20215;&#20540;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31526;&#21512;&#24615;&#39044;&#27979;&#26694;&#26550;&#65292;&#23427;&#22312;&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#20013;&#25552;&#20379;&#20102;&#19982;&#39044;&#27979;&#19968;&#36215;&#30340;&#32622;&#20449;&#24230;&#24230;&#37327;&#65292;&#20197;&#22686;&#24378;&#31995;&#32479;&#29983;&#25104;&#30340;&#31616;&#21333;&#25512;&#33616;&#12290;&#22312;&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#31181;&#38750;&#31526;&#21512;&#24230;&#24230;&#37327;&#65292;&#23427;&#22312;&#25552;&#39640;&#25512;&#33616;&#25928;&#26524;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Group recommender systems (GRS) are critical in discovering relevant items from a near-infinite inventory based on group preferences rather than individual preferences, like recommending a movie, restaurant, or tourist destination to a group of individuals. The traditional models of group recommendation are designed to act like a black box with a strict focus on improving recommendation accuracy, and most often, they place the onus on the users to interpret recommendations. In recent years, the focus of Recommender Systems (RS) research has shifted away from merely improving recommendation accuracy towards value additions such as confidence and explanation. In this work, we propose a conformal prediction framework that provides a measure of confidence with prediction in conjunction with a group recommender system to augment the system-generated plain recommendations. In the context of group recommender systems, we propose various nonconformity measures that play a vital role in the eff
&lt;/p&gt;</description></item><item><title>XWalk&#26159;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#28216;&#36208;&#30340;&#22270;&#24418;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#25512;&#33616;&#31995;&#32479;&#25216;&#26415;&#20013;&#20511;&#37492;&#30340;&#20135;&#21697;&#25628;&#32034;&#20505;&#36873;&#38598;&#26816;&#32034;&#65292;&#33021;&#22815;&#26497;&#22823;&#22320;&#25913;&#36827;&#22836;&#37096;&#26597;&#35810;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#27979;&#35797;&#20013;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.12019</link><description>&lt;p&gt;
XWalk: &#22522;&#20110;&#38543;&#26426;&#28216;&#36208;&#30340;&#20135;&#21697;&#25628;&#32034;&#20505;&#36873;&#38598;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
XWalk: Random Walk Based Candidate Retrieval for Product Search. (arXiv:2307.12019v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12019
&lt;/p&gt;
&lt;p&gt;
XWalk&#26159;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#28216;&#36208;&#30340;&#22270;&#24418;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#25512;&#33616;&#31995;&#32479;&#25216;&#26415;&#20013;&#20511;&#37492;&#30340;&#20135;&#21697;&#25628;&#32034;&#20505;&#36873;&#38598;&#26816;&#32034;&#65292;&#33021;&#22815;&#26497;&#22823;&#22320;&#25913;&#36827;&#22836;&#37096;&#26597;&#35810;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#27979;&#35797;&#20013;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#23376;&#21830;&#21153;&#20013;&#65292;&#22836;&#37096;&#26597;&#35810;&#21344;&#25454;&#20102;&#32477;&#22823;&#37096;&#20998;&#30340;&#38144;&#21806;&#39069;&#65292;&#24182;&#19988;&#23545;&#22836;&#37096;&#26597;&#35810;&#30340;&#25913;&#36827;&#23545;&#19994;&#21153;&#38750;&#24120;&#26377;&#24433;&#21709;&#21147;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#30417;&#30563;&#24335;&#30340;&#25628;&#32034;&#26041;&#27861;&#22312;&#22836;&#37096;&#26597;&#35810;&#30456;&#23545;&#20110;&#23614;&#37096;&#26597;&#35810;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#26497;&#22823;&#25913;&#21892;&#22836;&#37096;&#26597;&#35810;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;XWalk&#65292;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#28216;&#36208;&#30340;&#22270;&#24418;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#25512;&#33616;&#31995;&#32479;&#25216;&#26415;&#20013;&#20511;&#37492;&#30340;&#20135;&#21697;&#25628;&#32034;&#20505;&#36873;&#38598;&#26816;&#32034;&#12290;XWalk&#22312;&#22823;&#35268;&#27169;&#39640;&#27969;&#37327;&#30340;&#30005;&#23376;&#21830;&#21153;&#29615;&#22659;&#20013;&#35757;&#32451;&#21644;&#25512;&#26029;&#38750;&#24120;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#22836;&#37096;&#26597;&#35810;&#24615;&#33021;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#30456;&#24403;&#22823;&#30340;&#25913;&#36827;&#65292;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#26816;&#32034;&#22120;&#12290;&#23558;XWalk&#19982;&#31070;&#32463;&#21644;/&#25110;&#35789;&#27719;&#26816;&#32034;&#22120;&#36827;&#34892;&#38598;&#25104;&#65292;&#32467;&#21512;&#20102;&#20004;&#32773;&#30340;&#20248;&#21183;&#65292;&#25152;&#24471;&#21040;&#30340;&#26816;&#32034;&#31995;&#32479;&#22312;&#31163;&#32447;&#30456;&#20851;&#24615;&#35780;&#20272;&#21644;&#22312;&#32447;A/B&#27979;&#35797;&#20013;&#20248;&#20110;&#25152;&#26377;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In e-commerce, head queries account for the vast majority of gross merchandise sales and improvements to head queries are highly impactful to the business. While most supervised approaches to search perform better in head queries vs. tail queries, we propose a method that further improves head query performance dramatically. We propose XWalk, a random-walk based graph approach to candidate retrieval for product search that borrows from recommendation system techniques. XWalk is highly efficient to train and inference in a large-scale high traffic e-commerce setting, and shows substantial improvements in head query performance over state-of-the-art neural retreivers. Ensembling XWalk with a neural and/or lexical retriever combines the best of both worlds and the resulting retrieval system outperforms all other methods in both offline relevance-based evaluation and in online A/B tests.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;HTP&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#20102;&#29992;&#25143;&#21382;&#21490;&#20132;&#20114;&#30340;&#20840;&#38754;&#26102;&#38388;&#27169;&#24335;&#65292;&#21253;&#25324;&#32477;&#23545;&#26102;&#38388;&#20449;&#24687;&#12289;&#30456;&#23545;&#39033;&#30446;&#26102;&#38388;&#38388;&#38548;&#21644;&#30456;&#23545;&#25512;&#33616;&#26102;&#38388;&#38388;&#38548;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#25506;&#32034;&#22522;&#20110;&#39033;&#30446;&#30340;&#32477;&#23545;&#26102;&#38388;&#27169;&#24335;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#20214;&#26469;&#35299;&#20915;&#30456;&#23545;&#39033;&#30446;&#26102;&#38388;&#38388;&#38548;&#21644;&#30456;&#23545;&#25512;&#33616;&#26102;&#38388;&#38388;&#38548;&#20043;&#38388;&#30340;&#24494;&#22937;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.11994</link><description>&lt;p&gt;
HTP: &#21033;&#29992;&#20840;&#38754;&#30340;&#26102;&#38388;&#27169;&#24335;&#36827;&#34892;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
HTP: Exploiting Holistic Temporal Patterns for Sequential Recommendation. (arXiv:2307.11994v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;HTP&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#20102;&#29992;&#25143;&#21382;&#21490;&#20132;&#20114;&#30340;&#20840;&#38754;&#26102;&#38388;&#27169;&#24335;&#65292;&#21253;&#25324;&#32477;&#23545;&#26102;&#38388;&#20449;&#24687;&#12289;&#30456;&#23545;&#39033;&#30446;&#26102;&#38388;&#38388;&#38548;&#21644;&#30456;&#23545;&#25512;&#33616;&#26102;&#38388;&#38388;&#38548;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#25506;&#32034;&#22522;&#20110;&#39033;&#30446;&#30340;&#32477;&#23545;&#26102;&#38388;&#27169;&#24335;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#20214;&#26469;&#35299;&#20915;&#30456;&#23545;&#39033;&#30446;&#26102;&#38388;&#38388;&#38548;&#21644;&#30456;&#23545;&#25512;&#33616;&#26102;&#38388;&#38388;&#38548;&#20043;&#38388;&#30340;&#24494;&#22937;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#36890;&#36807;&#26126;&#30830;&#21033;&#29992;&#29992;&#25143;&#21382;&#21490;&#20132;&#20114;&#30340;&#26102;&#38388;&#39034;&#24207;&#65292;&#20026;&#19979;&#19968;&#20010;&#39033;&#30446;&#30340;&#25512;&#33616;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#29992;&#25143;&#30340;&#20132;&#20114;&#21253;&#21547;&#26356;&#22810;&#26377;&#29992;&#30340;&#26102;&#38388;&#20449;&#24687;&#65292;&#19968;&#20123;&#24320;&#21019;&#24615;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#26412;&#25991;&#31995;&#32479;&#22320;&#35843;&#26597;&#20102;&#39034;&#24207;&#25512;&#33616;&#20013;&#21508;&#31181;&#26102;&#38388;&#20449;&#24687;&#65292;&#24182;&#30830;&#23450;&#20102;&#19977;&#31181;&#26377;&#21033;&#30340;&#26102;&#38388;&#27169;&#24335;&#65292;&#21253;&#25324;&#32477;&#23545;&#26102;&#38388;&#20449;&#24687;&#12289;&#30456;&#23545;&#39033;&#30446;&#26102;&#38388;&#38388;&#38548;&#21644;&#30456;&#23545;&#25512;&#33616;&#26102;&#38388;&#38388;&#38548;&#12290;&#25105;&#20204;&#26159;&#31532;&#19968;&#20010;&#25506;&#32034;&#22522;&#20110;&#39033;&#30446;&#30340;&#32477;&#23545;&#26102;&#38388;&#27169;&#24335;&#30340;&#30740;&#31350;&#12290;&#23613;&#31649;&#29616;&#26377;&#27169;&#22411;&#21482;&#32771;&#34385;&#36825;&#19977;&#31181;&#27169;&#24335;&#20013;&#30340;&#19968;&#31181;&#25110;&#20004;&#31181;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20840;&#38754;&#26102;&#38388;&#27169;&#24335;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;HTP&#65292;&#20197;&#20805;&#20998;&#21033;&#29992;&#36825;&#19977;&#31181;&#27169;&#24335;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#32452;&#20214;&#26469;&#22788;&#29702;&#30456;&#23545;&#39033;&#30446;&#26102;&#38388;&#38388;&#38548;&#21644;&#30456;&#23545;&#25512;&#33616;&#26102;&#38388;&#38388;&#38548;&#20043;&#38388;&#30340;&#24494;&#22937;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommender systems have demonstrated a huge success for next-item recommendation by explicitly exploiting the temporal order of users' historical interactions. In practice, user interactions contain more useful temporal information beyond order, as shown by some pioneering studies. In this paper, we systematically investigate various temporal information for sequential recommendation and identify three types of advantageous temporal patterns beyond order, including absolute time information, relative item time intervals and relative recommendation time intervals. We are the first to explore item-oriented absolute time patterns. While existing models consider only one or two of these three patterns, we propose a novel holistic temporal pattern based neural network, named HTP, to fully leverage all these three patterns. In particular, we introduce novel components to address the subtle correlations between relative item time intervals and relative recommendation time interval
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#20316;&#24335;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#23646;&#24615;&#32593;&#32476;&#23884;&#20837;&#65292;&#36890;&#36807;&#28145;&#20837;&#21442;&#19982;&#33410;&#28857;&#23646;&#24615;&#26469;&#22686;&#24378;&#33410;&#28857;&#36830;&#25509;&#24182;&#25913;&#21892;&#23545;&#38750;&#27963;&#21160;&#33410;&#28857;&#30340;&#24863;&#21463;&#22495;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.11981</link><description>&lt;p&gt;
&#21327;&#20316;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#23646;&#24615;&#32593;&#32476;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Collaborative Graph Neural Networks for Attributed Network Embedding. (arXiv:2307.11981v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#20316;&#24335;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#23646;&#24615;&#32593;&#32476;&#23884;&#20837;&#65292;&#36890;&#36807;&#28145;&#20837;&#21442;&#19982;&#33410;&#28857;&#23646;&#24615;&#26469;&#22686;&#24378;&#33410;&#28857;&#36830;&#25509;&#24182;&#25913;&#21892;&#23545;&#38750;&#27963;&#21160;&#33410;&#28857;&#30340;&#24863;&#21463;&#22495;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#23646;&#24615;&#32593;&#32476;&#23884;&#20837;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#21033;&#29992;&#32593;&#32476;&#32467;&#26500;&#65292;&#32780;&#23545;&#33410;&#28857;&#23646;&#24615;&#30340;&#21033;&#29992;&#30456;&#23545;&#36739;&#23569;&#65292;&#23427;&#20204;&#21482;&#22312;&#21021;&#22987;&#23618;&#20316;&#20026;&#33410;&#28857;&#29305;&#24449;&#12290;&#36825;&#31181;&#31616;&#21333;&#30340;&#31574;&#30053;&#38480;&#21046;&#20102;&#33410;&#28857;&#23646;&#24615;&#22312;&#22686;&#24378;&#33410;&#28857;&#36830;&#25509;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#23548;&#33268;&#20102;&#23545;&#20855;&#26377;&#23569;&#37327;&#29978;&#33267;&#27809;&#26377;&#37051;&#23621;&#30340;&#38750;&#27963;&#21160;&#33410;&#28857;&#30340;&#26377;&#38480;&#24863;&#21463;&#22495;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;GNN&#30340;&#35757;&#32451;&#30446;&#26631;&#65288;&#21363;&#37325;&#26500;&#32593;&#32476;&#32467;&#26500;&#65289;&#20063;&#19981;&#21253;&#25324;&#33410;&#28857;&#23646;&#24615;&#65292;&#23613;&#31649;&#30740;&#31350;&#34920;&#26126;&#37325;&#26500;&#33410;&#28857;&#23646;&#24615;&#26159;&#26377;&#30410;&#30340;&#12290;&#22240;&#27492;&#65292;&#28145;&#20837;&#21442;&#19982;&#22270;&#21367;&#31215;&#25805;&#20316;&#21644;&#35757;&#32451;&#30446;&#26631;&#31561;GNN&#20851;&#38190;&#32452;&#20214;&#20013;&#30340;&#33410;&#28857;&#23646;&#24615;&#26159;&#24456;&#26377;&#21069;&#26223;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#26159;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#38656;&#35201;&#36866;&#24403;&#30340;&#38598;&#25104;&#26041;&#24335;&#26469;&#20445;&#25345;GNN&#30340;&#20248;&#28857;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#24046;&#36317;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21327;&#20316;&#24335;&#22270;&#31070;&#32463;&#32593;&#32476;...
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have shown prominent performance on attributed network embedding. However, existing efforts mainly focus on exploiting network structures, while the exploitation of node attributes is rather limited as they only serve as node features at the initial layer. This simple strategy impedes the potential of node attributes in augmenting node connections, leading to limited receptive field for inactive nodes with few or even no neighbors. Furthermore, the training objectives (i.e., reconstructing network structures) of most GNNs also do not include node attributes, although studies have shown that reconstructing node attributes is beneficial. Thus, it is encouraging to deeply involve node attributes in the key components of GNNs, including graph convolution operations and training objectives. However, this is a nontrivial task since an appropriate way of integration is required to maintain the merits of GNNs. To bridge the gap, in this paper, we propose COllaborat
&lt;/p&gt;</description></item><item><title>MythQA&#26159;&#19968;&#39033;&#26032;&#30340;&#22810;&#31572;&#26696;&#24320;&#25918;&#39046;&#22495;&#38382;&#39064;&#22238;&#31572;&#65288;QA&#65289;&#20219;&#21153;&#65292;&#26088;&#22312;&#36890;&#36807;&#30683;&#30462;&#31435;&#22330;&#25366;&#25496;&#26469;&#26816;&#27979;&#22823;&#35268;&#27169;&#26597;&#35810;&#20540;&#24471;&#26816;&#26597;&#30340;&#26029;&#35328;&#12290;&#35813;&#20219;&#21153;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#21253;&#21547;522&#20010;&#22522;&#20110;&#26377;&#20105;&#35758;&#30340;&#35805;&#39064;&#30340;&#35780;&#20272;&#25968;&#25454;&#38598;&#26469;&#36827;&#34892;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.11848</link><description>&lt;p&gt;
MythQA: &#22810;&#31572;&#26696;&#24320;&#25918;&#39046;&#22495;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#22823;&#35268;&#27169;&#26597;&#35810;&#20540;&#24471;&#26816;&#26597;&#30340;&#26029;&#35328;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering. (arXiv:2307.11848v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11848
&lt;/p&gt;
&lt;p&gt;
MythQA&#26159;&#19968;&#39033;&#26032;&#30340;&#22810;&#31572;&#26696;&#24320;&#25918;&#39046;&#22495;&#38382;&#39064;&#22238;&#31572;&#65288;QA&#65289;&#20219;&#21153;&#65292;&#26088;&#22312;&#36890;&#36807;&#30683;&#30462;&#31435;&#22330;&#25366;&#25496;&#26469;&#26816;&#27979;&#22823;&#35268;&#27169;&#26597;&#35810;&#20540;&#24471;&#26816;&#26597;&#30340;&#26029;&#35328;&#12290;&#35813;&#20219;&#21153;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#21253;&#21547;522&#20010;&#22522;&#20110;&#26377;&#20105;&#35758;&#30340;&#35805;&#39064;&#30340;&#35780;&#20272;&#25968;&#25454;&#38598;&#26469;&#36827;&#34892;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#20540;&#24471;&#26816;&#26597;&#30340;&#26029;&#35328;&#26816;&#27979;&#26088;&#22312;&#21521;&#19979;&#28216;&#30340;&#20107;&#23454;&#26680;&#26597;&#31995;&#32479;&#25110;&#20154;&#24037;&#19987;&#23478;&#25552;&#20379;&#21487;&#33021;&#30340;&#38169;&#35823;&#20449;&#24687;&#36827;&#34892;&#26816;&#26597;&#12290;&#36825;&#26159;&#21152;&#36895;&#20107;&#23454;&#26680;&#26597;&#36807;&#31243;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#35768;&#22810;&#21162;&#21147;&#24050;&#32463;&#25237;&#20837;&#21040;&#22914;&#20309;&#20174;&#39044;&#25910;&#38598;&#30340;&#23569;&#37327;&#26029;&#35328;&#20013;&#35782;&#21035;&#20540;&#24471;&#26816;&#26597;&#30340;&#26029;&#35328;&#30340;&#30740;&#31350;&#20013;&#65292;&#20294;&#22914;&#20309;&#30452;&#25509;&#20174;&#22823;&#35268;&#27169;&#20449;&#24687;&#28304;&#65288;&#22914;Twitter&#65289;&#26377;&#25928;&#26816;&#27979;&#20540;&#24471;&#26816;&#26597;&#30340;&#26029;&#35328;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MythQA&#65292;&#19968;&#39033;&#26032;&#30340;&#22810;&#31572;&#26696;&#24320;&#25918;&#39046;&#22495;&#38382;&#39064;&#22238;&#31572;&#65288;QA&#65289;&#20219;&#21153;&#65292;&#35813;&#20219;&#21153;&#28041;&#21450;&#29992;&#20110;&#26597;&#35810;&#20540;&#24471;&#26816;&#26597;&#30340;&#22823;&#35268;&#27169;&#26029;&#35328;&#26816;&#27979;&#30340;&#30683;&#30462;&#31435;&#22330;&#25366;&#25496;&#12290;&#36825;&#19968;&#24819;&#27861;&#30340;&#32972;&#21518;&#26159;&#65292;&#30683;&#30462;&#30340;&#26029;&#35328;&#26159;&#20540;&#24471;&#30001;&#36866;&#24403;&#30340;&#26426;&#26500;&#36827;&#34892;&#23457;&#26597;&#30340;&#38169;&#35823;&#20449;&#24687;&#30340;&#24378;&#26377;&#21147;&#25351;&#26631;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;TweetMythQA&#65292;&#19968;&#20010;&#21253;&#21547;522&#20010;&#22522;&#20110;&#26377;&#20105;&#35758;&#30340;&#35805;&#39064;&#30340;&#20107;&#23454;&#22411;&#22810;&#31572;&#26696;&#38382;&#39064;&#30340;&#35780;&#20272;&#25968;&#25454;&#38598;&#12290;&#27599;&#20010;&#38382;&#39064;&#37117;&#24102;&#26377;&#22810;&#20010;&#31572;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Check-worthy claim detection aims at providing plausible misinformation to downstream fact-checking systems or human experts to check. This is a crucial step toward accelerating the fact-checking process. Many efforts have been put into how to identify check-worthy claims from a small scale of pre-collected claims, but how to efficiently detect check-worthy claims directly from a large-scale information source, such as Twitter, remains underexplored. To fill this gap, we introduce MythQA, a new multi-answer open-domain question answering(QA) task that involves contradictory stance mining for query-based large-scale check-worthy claim detection. The idea behind this is that contradictory claims are a strong indicator of misinformation that merits scrutiny by the appropriate authorities. To study this task, we construct TweetMythQA, an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics. Each question is annotated with multiple answers. Moreover
&lt;/p&gt;</description></item><item><title>AutoAlign&#26159;&#19968;&#31181;&#20840;&#33258;&#21160;&#30340;&#30693;&#35782;&#22270;&#35889;&#23545;&#40784;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#25163;&#24037;&#21046;&#20316;&#30340;&#31181;&#23376;&#23545;&#40784;&#12290;&#23427;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#25429;&#25417;&#35859;&#35789;&#30456;&#20284;&#24615;&#65292;&#24182;&#20351;&#29992;TransE&#35745;&#31639;&#23454;&#20307;&#23884;&#20837;&#26469;&#23454;&#29616;&#23454;&#20307;&#23545;&#40784;&#12290;</title><link>http://arxiv.org/abs/2307.11772</link><description>&lt;p&gt;
AutoAlign&#65306;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20840;&#33258;&#21160;&#26377;&#25928;&#30693;&#35782;&#22270;&#35889;&#23545;&#40784;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment enabled by Large Language Models. (arXiv:2307.11772v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11772
&lt;/p&gt;
&lt;p&gt;
AutoAlign&#26159;&#19968;&#31181;&#20840;&#33258;&#21160;&#30340;&#30693;&#35782;&#22270;&#35889;&#23545;&#40784;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#25163;&#24037;&#21046;&#20316;&#30340;&#31181;&#23376;&#23545;&#40784;&#12290;&#23427;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#25429;&#25417;&#35859;&#35789;&#30456;&#20284;&#24615;&#65292;&#24182;&#20351;&#29992;TransE&#35745;&#31639;&#23454;&#20307;&#23884;&#20837;&#26469;&#23454;&#29616;&#23454;&#20307;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#38388;&#30340;&#23454;&#20307;&#23545;&#40784;&#20219;&#21153;&#26088;&#22312;&#35782;&#21035;&#20986;&#20004;&#20010;&#19981;&#21516;&#30693;&#35782;&#22270;&#35889;&#20013;&#34920;&#31034;&#30456;&#21516;&#23454;&#20307;&#30340;&#27599;&#23545;&#23454;&#20307;&#12290;&#35768;&#22810;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#24050;&#34987;&#25552;&#20986;&#29992;&#20110;&#36825;&#20010;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#37117;&#38656;&#35201;&#25163;&#24037;&#21046;&#20316;&#30340;&#31181;&#23376;&#23545;&#40784;&#65292;&#36825;&#26159;&#38750;&#24120;&#26114;&#36149;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#21517;&#20026;AutoAlign&#30340;&#23436;&#20840;&#33258;&#21160;&#23545;&#40784;&#26041;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#20219;&#20309;&#25163;&#24037;&#21046;&#20316;&#30340;&#31181;&#23376;&#23545;&#40784;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#35859;&#35789;&#23884;&#20837;&#65292;AutoAlign&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26500;&#24314;&#35859;&#35789;&#36817;&#37051;&#22270;&#65292;&#33258;&#21160;&#25429;&#25417;&#20004;&#20010;&#30693;&#35782;&#22270;&#35889;&#20013;&#35859;&#35789;&#30340;&#30456;&#20284;&#24615;&#12290;&#23545;&#20110;&#23454;&#20307;&#23884;&#20837;&#65292;AutoAlign&#39318;&#20808;&#20351;&#29992;TransE&#29420;&#31435;&#35745;&#31639;&#27599;&#20010;&#30693;&#35782;&#22270;&#35889;&#30340;&#23454;&#20307;&#23884;&#20837;&#65292;&#28982;&#21518;&#36890;&#36807;&#35745;&#31639;&#22522;&#20110;&#23454;&#20307;&#23646;&#24615;&#30340;&#23454;&#20307;&#30456;&#20284;&#24615;&#65292;&#23558;&#20004;&#20010;&#30693;&#35782;&#22270;&#35889;&#30340;&#23454;&#20307;&#23884;&#20837;&#31227;&#21160;&#21040;&#30456;&#21516;&#30340;&#21521;&#37327;&#31354;&#38388;&#20013;&#12290;&#22240;&#27492;&#65292;AutoAlign&#23454;&#29616;&#20102;&#35859;&#35789;&#23545;&#40784;&#21644;&#23454;&#20307;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require manually crafted seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help of large language models to automatically capture the similarity between predicates across two KGs. For entity embeddings, AutoAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs' entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity al
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21021;&#27493;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#26816;&#32034;&#22686;&#24378;&#23545;&#24320;&#25918;&#22495;&#38382;&#31572;&#20219;&#21153;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#26174;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#34920;&#29616;&#20986;&#33258;&#20449;&#65292;&#24182;&#19988;&#22238;&#31572;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2307.11019</link><description>&lt;p&gt;
&#29992;&#26816;&#32034;&#22686;&#24378;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation. (arXiv:2307.11019v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21021;&#27493;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#26816;&#32034;&#22686;&#24378;&#23545;&#24320;&#25918;&#22495;&#38382;&#31572;&#20219;&#21153;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#26174;&#31034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#34920;&#29616;&#20986;&#33258;&#20449;&#65292;&#24182;&#19988;&#22238;&#31572;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#65288;&#20363;&#22914;&#65292;&#24320;&#25918;&#22495;&#38382;&#31572;&#65288;QA&#65289;&#65289;&#38656;&#35201;&#22823;&#37327;&#30340;&#20107;&#23454;&#30693;&#35782;&#65292;&#24182;&#32463;&#24120;&#20381;&#36182;&#22806;&#37096;&#20449;&#24687;&#36827;&#34892;&#21327;&#21161;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65288;&#20363;&#22914;&#65292;ChatGPT&#65289;&#22312;&#35299;&#20915;&#21253;&#25324;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#22312;&#20869;&#30340;&#21508;&#31181;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#24778;&#20154;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;LLMs&#22312;&#24863;&#30693;&#20854;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;&#26041;&#38754;&#34920;&#29616;&#22914;&#20309;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#26816;&#32034;&#22686;&#24378;&#26102;&#30340;&#34892;&#20026;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;LLMs&#30340;&#20107;&#23454;&#30693;&#35782;&#36793;&#30028;&#36827;&#34892;&#20102;&#21021;&#27493;&#20998;&#26512;&#65292;&#24182;&#30740;&#31350;&#20102;&#26816;&#32034;&#22686;&#24378;&#23545;LLMs&#22312;&#24320;&#25918;&#22495;QA&#19978;&#30340;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#20102;&#19977;&#20010;&#20027;&#35201;&#30740;&#31350;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26816;&#26597;LLMs&#30340;QA&#24615;&#33021;&#12289;&#20808;&#39564;&#21028;&#26029;&#21644;&#21518;&#39564;&#21028;&#26029;&#26469;&#36827;&#34892;&#20998;&#26512;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;LLMs&#23545;&#20110;&#33258;&#24049;&#22238;&#31572;&#38382;&#39064;&#30340;&#33021;&#21147;&#21644;&#22238;&#31572;&#30340;&#20934;&#30830;&#24615;&#20805;&#28385;&#20102;&#33258;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require a substantial amount of factual knowledge and often rely on external information for assistance. Recently, large language models (LLMs) (e.g., ChatGPT), have demonstrated impressive prowess in solving a wide range of tasks with world knowledge, including knowledge-intensive tasks. However, it remains unclear how well LLMs are able to perceive their factual knowledge boundaries, particularly how they behave when incorporating retrieval augmentation. In this study, we present an initial analysis of the factual knowledge boundaries of LLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially, we focus on three primary research questions and analyze them by examining QA performance, priori judgement and posteriori judgement of LLMs. We show evidence that LLMs possess unwavering confidence in their capabilities to respond to questions and the accuracy of their responses. Furthermore, retrieval 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#65292;&#24182;&#36890;&#36807;&#22312;&#39184;&#39302;&#35780;&#35770;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.10617</link><description>&lt;p&gt;
&#20351;&#29992;&#25991;&#26412;&#20998;&#31867;&#26816;&#27979;&#34394;&#20551;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10617
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#65292;&#24182;&#36890;&#36807;&#22312;&#39184;&#39302;&#35780;&#35770;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22312;&#32447;&#35780;&#35770;&#22312;&#25512;&#24191;&#20219;&#20309;&#20135;&#21697;&#25110;&#26381;&#21153;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20225;&#19994;&#21487;&#33021;&#20250;&#23884;&#20837;&#34394;&#20551;&#35780;&#35770;&#20197;&#21560;&#24341;&#23458;&#25143;&#36141;&#20080;&#20182;&#20204;&#30340;&#20135;&#21697;&#12290;&#20182;&#20204;&#29978;&#33267;&#21487;&#33021;&#31361;&#20986;&#24378;&#35843;&#33258;&#24049;&#20135;&#21697;&#30340;&#20248;&#28857;&#25110;&#25209;&#35780;&#31454;&#20105;&#23545;&#25163;&#30340;&#20135;&#21697;&#12290;&#24066;&#22330;&#33829;&#38144;&#20154;&#21592;&#12289;&#24191;&#21578;&#21830;&#21644;&#20854;&#20182;&#22312;&#32447;&#21830;&#19994;&#29992;&#25143;&#26377;&#21160;&#26426;&#20026;&#20182;&#20204;&#24819;&#35201;&#25512;&#24191;&#30340;&#20135;&#21697;&#32534;&#20889;&#34394;&#20551;&#30340;&#27491;&#38754;&#35780;&#35770;&#65292;&#25110;&#32773;&#20026;&#20182;&#20204;&#30495;&#27491;&#19981;&#21916;&#27426;&#30340;&#20135;&#21697;&#25552;&#20379;&#34394;&#20551;&#30340;&#36127;&#38754;&#35780;&#35770;&#12290;&#22240;&#27492;&#65292;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#26159;&#19968;&#20010;&#32039;&#36843;&#19988;&#25345;&#32493;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#30740;&#31350;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26041;&#27861;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#12290;&#35770;&#25991;&#35843;&#26597;&#20102;&#22312;&#19968;&#20010;&#39184;&#39302;&#35780;&#35770;&#30340;&#34394;&#20551;&#24847;&#35265;&#22403;&#22334;&#35821;&#26009;&#24211;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22810;&#27425;&#23454;&#39564;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;n-gram&#27169;&#22411;&#21644;&#26368;&#22823;&#29305;&#24449;&#26469;&#35782;&#21035;&#34394;&#20551;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, online reviews play a vital role for promoting any kind of product or services. Businesses may embed fake reviews in order to attract customers to purchase their products. They may even highlight the benefits of their own product or criticize the competition's product. Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like. So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation. Thus, identifying deceptive reviews is an intense and on-going research area. This research paper proposes machine learning model approach to identify deceptive reviews. The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews. We developed a n-gram model and max features to identify 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21160;&#24577;&#25506;&#32034;&#22270;&#65288;DEG&#65289;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#36830;&#32493;&#32454;&#21270;&#21644;&#22270;&#26500;&#24314;&#36807;&#31243;&#65292;&#36798;&#21040;&#20102;&#22312;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#25552;&#39640;&#25628;&#32034;&#25928;&#29575;&#12289;&#39044;&#27979;&#32034;&#24341;&#22823;&#23567;&#12289;&#20445;&#25345;&#36830;&#36890;&#24615;&#21644;&#21160;&#24577;&#22270;&#32467;&#26500;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.10479</link><description>&lt;p&gt;
&#20351;&#29992;&#36830;&#32493;&#32454;&#21270;&#30340;&#21160;&#24577;&#25506;&#32034;&#22270;&#36827;&#34892;&#24555;&#36895;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Fast Approximate Nearest Neighbor Search with a Dynamic Exploration Graph using Continuous Refinement. (arXiv:2307.10479v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21160;&#24577;&#25506;&#32034;&#22270;&#65288;DEG&#65289;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#36830;&#32493;&#32454;&#21270;&#21644;&#22270;&#26500;&#24314;&#36807;&#31243;&#65292;&#36798;&#21040;&#20102;&#22312;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#25552;&#39640;&#25628;&#32034;&#25928;&#29575;&#12289;&#39044;&#27979;&#32034;&#24341;&#22823;&#23567;&#12289;&#20445;&#25345;&#36830;&#36890;&#24615;&#21644;&#21160;&#24577;&#22270;&#32467;&#26500;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#65292;&#22522;&#20110;&#22270;&#30340;&#31639;&#27861;&#22312;&#31934;&#24230;&#21644;&#25628;&#32034;&#26102;&#38388;&#20043;&#38388;&#25552;&#20379;&#20102;&#26368;&#20339;&#30340;&#25240;&#34935;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21160;&#24577;&#25506;&#32034;&#22270;&#65288;DEG&#65289;&#65292;&#36890;&#36807;&#32467;&#21512;&#20004;&#20010;&#26032;&#24605;&#24819;&#65292;&#22312;&#25628;&#32034;&#21644;&#25506;&#32034;&#25928;&#29575;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65306;&#39318;&#20808;&#65292;&#36890;&#36807;&#37096;&#20998;&#26367;&#25442;&#29616;&#26377;&#36793;&#26469;&#22686;&#37327;&#26500;&#24314;&#19968;&#20010;&#21333;&#20010;&#30340;&#26080;&#21521;&#20598;&#27491;&#21017;&#22270;&#65292;&#20197;&#21516;&#26102;&#25972;&#21512;&#26032;&#39030;&#28857;&#21644;&#26356;&#26032;&#26087;&#37051;&#22495;&#12290;&#20854;&#27425;&#65292;&#20351;&#29992;&#36793;&#20248;&#21270;&#31639;&#27861;&#36830;&#32493;&#25913;&#21892;&#22270;&#30340;&#36136;&#37327;&#12290;&#23558;&#36825;&#31181;&#25345;&#32493;&#32454;&#21270;&#19982;&#22270;&#26500;&#24314;&#36807;&#31243;&#30456;&#32467;&#21512;&#65292;&#22987;&#32456;&#20445;&#25345;&#33391;&#22909;&#32452;&#32455;&#30340;&#22270;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#65306;&#65288;1&#65289;&#25552;&#39640;&#25628;&#32034;&#25928;&#29575;&#65292;&#65288;2&#65289;&#39044;&#27979;&#32034;&#24341;&#22823;&#23567;&#65292;&#65288;3&#65289;&#20445;&#35777;&#25152;&#26377;&#39030;&#28857;&#30340;&#36830;&#36890;&#24615;&#21644;&#21487;&#36798;&#24615;&#65292;&#20197;&#21450;&#65288;4&#65289;&#21160;&#24577;&#22270;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#29616;&#26377;&#22522;&#20110;&#22270;&#30340;&#25628;&#32034;&#31995;&#32479;&#22312;&#22788;&#29702;&#32034;&#24341;&#26597;&#35810;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
For approximate nearest neighbor search, graph-based algorithms have shown to offer the best trade-off between accuracy and search time. We propose the Dynamic Exploration Graph (DEG) which significantly outperforms existing algorithms in terms of search and exploration efficiency by combining two new ideas: First, a single undirected even regular graph is incrementally built by partially replacing existing edges to integrate new vertices and to update old neighborhoods at the same time. Secondly, an edge optimization algorithm is used to continuously improve the quality of the graph. Combining this ongoing refinement with the graph construction process leads to a well-organized graph structure at all times, resulting in: (1) increased search efficiency, (2) predictable index size, (3) guaranteed connectivity and therefore reachability of all vertices, and (4) a dynamic graph structure. In addition we investigate how well existing graph-based search systems can handle indexed queries w
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24635;&#32467;&#20102;&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#26816;&#32034;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#21644;&#26368;&#20339;&#23454;&#36341;&#65292;&#20171;&#32461;&#20102;&#38024;&#23545;&#19981;&#21516;&#29983;&#29289;&#21307;&#23398;&#20449;&#24687;&#38656;&#27714;&#30340;&#25991;&#29486;&#26816;&#32034;&#24037;&#20855;&#65292;&#24182;&#26088;&#22312;&#24110;&#21161;&#35835;&#32773;&#39640;&#25928;&#28385;&#36275;&#20854;&#20449;&#24687;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2307.09683</link><description>&lt;p&gt;
PubMed&#21450;&#20854;&#20182;&#65306;&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#26816;&#32034;&#30340;&#26368;&#26032;&#36827;&#23637;&#21644;&#26368;&#20339;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
PubMed and Beyond: Recent Advances and Best Practices in Biomedical Literature Search. (arXiv:2307.09683v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24635;&#32467;&#20102;&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#26816;&#32034;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#21644;&#26368;&#20339;&#23454;&#36341;&#65292;&#20171;&#32461;&#20102;&#38024;&#23545;&#19981;&#21516;&#29983;&#29289;&#21307;&#23398;&#20449;&#24687;&#38656;&#27714;&#30340;&#25991;&#29486;&#26816;&#32034;&#24037;&#20855;&#65292;&#24182;&#26088;&#22312;&#24110;&#21161;&#35835;&#32773;&#39640;&#25928;&#28385;&#36275;&#20854;&#20449;&#24687;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#20135;&#29983;&#20102;&#20016;&#23500;&#30340;&#20449;&#24687;&#65292;&#20854;&#20013;&#24456;&#22810;&#21482;&#33021;&#36890;&#36807;&#25991;&#29486;&#33719;&#21462;&#12290;&#22240;&#27492;&#65292;&#25991;&#29486;&#26816;&#32034;&#26159;&#20020;&#24202;&#21644;&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#20013;&#24314;&#31435;&#22312;&#20808;&#21069;&#30693;&#35782;&#22522;&#30784;&#19978;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#23613;&#31649;&#20154;&#24037;&#26234;&#33021;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#23558;&#21151;&#33021;&#25193;&#23637;&#21040;&#20102;&#36229;&#36234;&#22522;&#20110;&#20851;&#38190;&#23383;&#30340;&#25628;&#32034;&#65292;&#20294;&#36825;&#20123;&#36827;&#23637;&#21487;&#33021;&#23545;&#20020;&#24202;&#21307;&#29983;&#21644;&#30740;&#31350;&#20154;&#21592;&#26469;&#35828;&#36824;&#27604;&#36739;&#38476;&#29983;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20123;&#29305;&#23450;&#20110;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#20449;&#24687;&#38656;&#27714;&#30340;&#25991;&#29486;&#26816;&#32034;&#24037;&#20855;&#65292;&#26088;&#22312;&#24110;&#21161;&#35835;&#32773;&#39640;&#25928;&#22320;&#28385;&#36275;&#20182;&#20204;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;&#25105;&#20204;&#39318;&#20808;&#23545;&#24191;&#27867;&#20351;&#29992;&#30340;PubMed&#25628;&#32034;&#24341;&#25806;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#21253;&#25324;&#26368;&#26032;&#30340;&#25913;&#36827;&#21644;&#20173;&#28982;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#20116;&#31181;&#29305;&#23450;&#20449;&#24687;&#38656;&#27714;&#30340;&#25991;&#29486;&#26816;&#32034;&#24037;&#20855;&#65306;1.&#20026;&#24490;&#35777;&#21307;&#23398;&#23547;&#25214;&#39640;&#36136;&#37327;&#20020;&#24202;&#30740;&#31350;&#12290;2.&#20026;&#31934;&#20934;&#21307;&#23398;&#21644;&#22522;&#22240;&#32452;&#23398;&#26816;&#32034;&#22522;&#22240;&#30456;&#20851;&#20449;&#24687;&#12290;3.&#26681;&#25454;&#24847;&#20041;&#25628;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Biomedical research yields a wealth of information, much of which is only accessible through the literature. Consequently, literature search is an essential tool for building on prior knowledge in clinical and biomedical research. Although recent improvements in artificial intelligence have expanded functionality beyond keyword-based search, these advances may be unfamiliar to clinicians and researchers. In response, we present a survey of literature search tools tailored to both general and specific information needs in biomedicine, with the objective of helping readers efficiently fulfill their information needs. We first examine the widely used PubMed search engine, discussing recent improvements and continued challenges. We then describe literature search tools catering to five specific information needs: 1. Identifying high-quality clinical research for evidence-based medicine. 2. Retrieving gene-related information for precision medicine and genomics. 3. Searching by meaning, inc
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#26469;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#26041;&#27861;&#65288;SPTAR&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#24182;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#29983;&#25104;&#24369;&#26597;&#35810;&#65292;&#21487;&#20197;&#25552;&#39640;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.08303</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#36719;&#25552;&#31034;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#26469;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#26041;&#27861;&#65288;SPTAR&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#24182;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#29983;&#25104;&#24369;&#26597;&#35810;&#65292;&#21487;&#20197;&#25552;&#39640;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#26816;&#32034;&#65288;DR&#65289;&#23558;&#26597;&#35810;&#21644;&#25991;&#26723;&#36716;&#21270;&#20026;&#23494;&#38598;&#21521;&#37327;&#34920;&#31034;&#65292;&#24182;&#22312;&#21521;&#37327;&#31354;&#38388;&#20013;&#27979;&#37327;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;DR&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#32570;&#20047;&#39046;&#22495;&#29305;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#34429;&#28982;DR&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#20174;&#22823;&#35268;&#27169;&#20844;&#20849;&#25968;&#25454;&#38598;&#65288;&#22914;MS MARCO&#65289;&#20013;&#23398;&#20064;&#65292;&#20294;&#35777;&#25454;&#34920;&#26126;&#65292;&#24182;&#38750;&#25152;&#26377;DR&#27169;&#22411;&#21644;&#39046;&#22495;&#37117;&#33021;&#21516;&#31561;&#21463;&#30410;&#20110;&#36801;&#31227;&#23398;&#20064;&#12290;&#26368;&#36817;&#65292;&#19968;&#20123;&#30740;&#31350;&#20154;&#21592;&#36716;&#21521;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#25913;&#36827;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;DR&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20013;&#37319;&#29992;&#30340;&#30828;&#25552;&#31034;&#25110;&#20154;&#24037;&#32534;&#20889;&#30340;&#25552;&#31034;&#26080;&#27861;&#20445;&#35777;&#29983;&#25104;&#30340;&#24369;&#26597;&#35810;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#22686;&#24378;DR&#30340;&#36719;&#25552;&#31034;&#35843;&#20248;&#65288;SPTAR&#65289;&#65306;&#23545;&#20110;&#27599;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#21033;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#22312;&#26377;&#38480;&#30340;&#30495;&#23454;&#25968;&#25454;&#19978;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#65292;&#28982;&#21518;&#29992;&#36825;&#20123;&#25552;&#31034;&#24341;&#23548;LLMs&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#26631;&#35760;&#24369;&#26597;&#35810;&#65292;&#20174;&#32780;&#24471;&#21040;&#36275;&#22815;&#30340;&#24369;&#25991;&#26723;-&#26597;&#35810;&#23545;&#26469;&#35757;&#32451;&#20219;&#21153;&#29305;&#23450;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#21033;&#29992;&#29992;&#25143;&#35780;&#35770;&#21644;&#30456;&#20851;&#39033;&#30446;&#29305;&#24449;&#29983;&#25104;&#23545;&#27604;&#35780;&#20215;&#21477;&#23376;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#25214;&#21040;&#26368;&#36866;&#21512;&#30340;&#20135;&#21697;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#39033;&#30446;&#32534;&#30721;&#27169;&#22359;&#12289;&#27604;&#36739;&#29983;&#25104;&#27169;&#22359;&#21644;&#20010;&#24615;&#21270;&#35299;&#30721;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#39564;&#35777;&#20102;&#29983;&#25104;&#21477;&#23376;&#30340;&#30456;&#20851;&#24615;&#21644;&#30495;&#23454;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.03691</link><description>&lt;p&gt;
&#23558;&#33529;&#26524;&#19982;&#33529;&#26524;&#36827;&#34892;&#27604;&#36739;&#65306;&#20174;&#29992;&#25143;&#35780;&#35770;&#29983;&#25104;&#32437;&#21521;&#24863;&#30693;&#30340;&#27604;&#36739;&#21477;&#23376;
&lt;/p&gt;
&lt;p&gt;
Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review. (arXiv:2307.03691v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03691
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#21033;&#29992;&#29992;&#25143;&#35780;&#35770;&#21644;&#30456;&#20851;&#39033;&#30446;&#29305;&#24449;&#29983;&#25104;&#23545;&#27604;&#35780;&#20215;&#21477;&#23376;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#25214;&#21040;&#26368;&#36866;&#21512;&#30340;&#20135;&#21697;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#39033;&#30446;&#32534;&#30721;&#27169;&#22359;&#12289;&#27604;&#36739;&#29983;&#25104;&#27169;&#22359;&#21644;&#20010;&#24615;&#21270;&#35299;&#30721;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#39564;&#35777;&#20102;&#29983;&#25104;&#21477;&#23376;&#30340;&#30456;&#20851;&#24615;&#21644;&#30495;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20247;&#22810;&#30456;&#20284;&#30340;&#36873;&#25321;&#20013;&#25214;&#21040;&#26368;&#20339;&#20135;&#21697;&#26159;&#38750;&#24120;&#32791;&#26102;&#30340;&#12290;&#27604;&#36739;&#21477;&#23376;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#20197;&#31361;&#20986;&#30340;&#26041;&#24335;&#23545;&#27604;&#19968;&#20010;&#39033;&#30446;&#19982;&#20854;&#20182;&#39033;&#30446;&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#24378;&#35843;&#20986;&#37325;&#35201;&#29305;&#24449;&#12290;&#22522;&#20110;&#29992;&#25143;&#23545;&#19968;&#20010;&#25110;&#22810;&#20010;&#39033;&#30446;&#30340;&#35780;&#35770;&#21450;&#30456;&#20851;&#39033;&#30446;&#29305;&#24449;&#65292;&#25105;&#20204;&#29983;&#25104;&#27604;&#36739;&#35780;&#35770;&#21477;&#23376;&#26469;&#24110;&#21161;&#29992;&#25143;&#25214;&#21040;&#26368;&#36866;&#21512;&#30340;&#20135;&#21697;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21253;&#25324;&#19977;&#20010;&#36830;&#32493;&#32452;&#20214;&#65306;&#65288;i&#65289;&#19968;&#20010;&#39033;&#30446;&#32534;&#30721;&#27169;&#22359;&#29992;&#20110;&#23545;&#39033;&#30446;&#36827;&#34892;&#32534;&#30721;&#27604;&#36739;&#65292;&#65288;ii&#65289;&#19968;&#20010;&#27604;&#36739;&#29983;&#25104;&#27169;&#22359;&#20197;&#33258;&#22238;&#24402;&#30340;&#26041;&#24335;&#29983;&#25104;&#27604;&#36739;&#21477;&#23376;&#65292;&#65288;iii&#65289;&#19968;&#31181;&#29992;&#20110;&#29992;&#25143;&#20010;&#24615;&#21270;&#30340;&#26032;&#22411;&#35299;&#30721;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27969;&#31243;&#33021;&#22815;&#29983;&#25104;&#27969;&#30021;&#19988;&#22810;&#26679;&#30340;&#27604;&#36739;&#21477;&#23376;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20154;&#31867;&#35780;&#20272;&#30740;&#31350;&#26469;&#39564;&#35777;&#25105;&#20204;&#29983;&#25104;&#30340;&#21477;&#23376;&#30340;&#30456;&#20851;&#24615;&#21644;&#30495;&#23454;&#24615;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#29983;&#25104;&#30456;&#20851;&#19988;&#30495;&#23454;&#30340;&#27604;&#36739;&#35780;&#35770;&#21477;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is time-consuming to find the best product among many similar alternatives. Comparative sentences can help to contrast one item from others in a way that highlights important features of an item that stand out. Given reviews of one or multiple items and relevant item features, we generate comparative review sentences to aid users to find the best fit. Specifically, our model consists of three successive components in a transformer: (i) an item encoding module to encode an item for comparison, (ii) a comparison generation module that generates comparative sentences in an autoregressive manner, (iii) a novel decoding method for user personalization. We show that our pipeline generates fluent and diverse comparative sentences. We run experiments on the relevance and fidelity of our generated sentences in a human evaluation study and find that our algorithm creates comparative review sentences that are relevant and truthful.
&lt;/p&gt;</description></item><item><title>EvalRS 2023&#26088;&#22312;&#25506;&#35752;&#25512;&#33616;&#31995;&#32479;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#20851;&#27880;&#20854;&#22312;&#29616;&#23454;&#22330;&#26223;&#19979;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;&#36807;&#21435;&#21482;&#26377;&#20934;&#30830;&#24230;&#30340;&#27979;&#37327;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#20840;&#38754;&#35780;&#20272;&#20854;&#24615;&#33021;&#65292;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#26377;&#29992;&#24615;&#21644;&#20449;&#24687;&#37327;&#31561;&#26041;&#38754;&#20063;&#24212;&#35813;&#34987;&#20851;&#27880;&#12290;&#26412;&#27425;&#30740;&#35752;&#20250;&#26159;&#21435;&#24180;CIKM&#30740;&#35752;&#20250;&#30340;&#32487;&#25215;&#21644;&#21457;&#23637;&#65292;&#24102;&#26377;&#23454;&#38469;&#25805;&#20316;&#24615;&#21644;&#20114;&#21160;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07145</link><description>&lt;p&gt;
EvalRS 2023. &#38754;&#21521;&#23454;&#38469;&#24212;&#29992;&#30340;&#20840;&#38754;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
EvalRS 2023. Well-Rounded Recommender Systems For Real-World Deployments. (arXiv:2304.07145v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07145
&lt;/p&gt;
&lt;p&gt;
EvalRS 2023&#26088;&#22312;&#25506;&#35752;&#25512;&#33616;&#31995;&#32479;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#20851;&#27880;&#20854;&#22312;&#29616;&#23454;&#22330;&#26223;&#19979;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;&#36807;&#21435;&#21482;&#26377;&#20934;&#30830;&#24230;&#30340;&#27979;&#37327;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#20840;&#38754;&#35780;&#20272;&#20854;&#24615;&#33021;&#65292;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#26377;&#29992;&#24615;&#21644;&#20449;&#24687;&#37327;&#31561;&#26041;&#38754;&#20063;&#24212;&#35813;&#34987;&#20851;&#27880;&#12290;&#26412;&#27425;&#30740;&#35752;&#20250;&#26159;&#21435;&#24180;CIKM&#30740;&#35752;&#20250;&#30340;&#32487;&#25215;&#21644;&#21457;&#23637;&#65292;&#24102;&#26377;&#23454;&#38469;&#25805;&#20316;&#24615;&#21644;&#20114;&#21160;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
EvalRS&#26088;&#22312;&#27719;&#32858;&#20135;&#19994;&#21644;&#23398;&#26415;&#30028;&#30340;&#20174;&#19994;&#32773;&#65292;&#20419;&#36827;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;&#20840;&#38754;&#35780;&#20272;&#30340;&#35752;&#35770;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#22312;&#21508;&#31181;&#37096;&#32626;&#22330;&#26223;&#19979;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#21482;&#36890;&#36807;&#20934;&#30830;&#24615;&#25351;&#26631;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#20123;&#25351;&#26631;&#26080;&#27861;&#23436;&#20840;&#25551;&#36848;&#20854;&#27867;&#21270;&#33021;&#21147;&#24182;&#24573;&#35270;&#20102;&#37325;&#35201;&#30340;&#26041;&#38754;&#65292;&#22914;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#26377;&#29992;&#24615;&#12289;&#20449;&#24687;&#37327;&#31561;&#12290;&#26412;&#27425;&#30740;&#35752;&#20250;&#22312;CIKM&#21435;&#24180;&#30740;&#35752;&#20250;&#30340;&#25104;&#21151;&#22522;&#30784;&#19978;&#36827;&#19968;&#27493;&#25193;&#22823;&#33539;&#22260;&#65292;&#24182;&#37319;&#21462;&#20114;&#21160;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
EvalRS aims to bring together practitioners from industry and academia to foster a debate on rounded evaluation of recommender systems, with a focus on real-world impact across a multitude of deployment scenarios. Recommender systems are often evaluated only through accuracy metrics, which fall short of fully characterizing their generalization capabilities and miss important aspects, such as fairness, bias, usefulness, informativeness. This workshop builds on the success of last year's workshop at CIKM, but with a broader scope and an interactive format.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20174;&#27491;&#24335;&#30340;&#35282;&#24230;&#21453;&#24605;&#20102;&#25490;&#21517;&#20013;&#21484;&#22238;&#29575;&#30340;&#27979;&#37327;&#38382;&#39064;&#65292;&#25552;&#20986;&#21484;&#22238;&#26041;&#21521;&#30340;&#27010;&#24565;&#21644;&#35789;&#20856;&#24335;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.11370</link><description>&lt;p&gt;
&#21484;&#22238;&#29575;&#12289;&#40065;&#26834;&#24615;&#21644;&#35789;&#20856;&#24335;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Recall, Robustness, and Lexicographic Evaluation. (arXiv:2302.11370v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11370
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20174;&#27491;&#24335;&#30340;&#35282;&#24230;&#21453;&#24605;&#20102;&#25490;&#21517;&#20013;&#21484;&#22238;&#29575;&#30340;&#27979;&#37327;&#38382;&#39064;&#65292;&#25552;&#20986;&#21484;&#22238;&#26041;&#21521;&#30340;&#27010;&#24565;&#21644;&#35789;&#20856;&#24335;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#20351;&#29992;&#21484;&#22238;&#29575;&#26469;&#35780;&#20272;&#21508;&#31181;&#26816;&#32034;&#12289;&#25512;&#33616;&#21644;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#25490;&#21517;&#12290;&#23613;&#31649;&#22312;&#38598;&#21512;&#35780;&#20272;&#20013;&#26377;&#20851;&#21484;&#22238;&#29575;&#30340;&#20439;&#35821;&#35299;&#37322;&#65292;&#20294;&#30740;&#31350;&#31038;&#21306;&#36828;&#26410;&#29702;&#35299;&#25490;&#21517;&#21484;&#22238;&#29575;&#30340;&#21407;&#29702;&#12290;&#23545;&#21484;&#22238;&#29575;&#32570;&#20047;&#21407;&#29702;&#29702;&#35299;&#25110;&#21160;&#26426;&#23548;&#33268;&#20449;&#24687;&#26816;&#32034;&#31038;&#21306;&#25209;&#35780;&#21484;&#22238;&#29575;&#26159;&#21542;&#26377;&#29992;&#20316;&#20026;&#19968;&#20010;&#25351;&#26631;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#20174;&#27491;&#24335;&#30340;&#35282;&#24230;&#21453;&#24605;&#25490;&#21517;&#20013;&#21484;&#22238;&#29575;&#30340;&#27979;&#37327;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#30001;&#19977;&#20010;&#21407;&#21017;&#32452;&#25104;&#65306;&#21484;&#22238;&#29575;&#12289;&#40065;&#26834;&#24615;&#21644;&#35789;&#20856;&#24335;&#35780;&#20272;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#27491;&#24335;&#23450;&#20041;&#8220;&#21484;&#22238;&#26041;&#21521;&#8221;&#20026;&#25935;&#24863;&#20110;&#24213;&#37096;&#25490;&#21517;&#30456;&#20851;&#26465;&#30446;&#31227;&#21160;&#30340;&#24230;&#37327;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20174;&#21487;&#33021;&#30340;&#25628;&#32034;&#32773;&#21644;&#20869;&#23481;&#25552;&#20379;&#32773;&#30340;&#40065;&#26834;&#24615;&#35282;&#24230;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#21484;&#22238;&#26041;&#21521;&#27010;&#24565;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#23454;&#29992;&#30340;&#35789;&#20856;&#24335;&#26041;&#27861;&#26469;&#25193;&#23637;&#23545;&#21484;&#22238;&#30340;&#27010;&#24565;&#21644;&#29702;&#35770;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Researchers use recall to evaluate rankings across a variety of retrieval, recommendation, and machine learning tasks. While there is a colloquial interpretation of recall in set-based evaluation, the research community is far from a principled understanding of recall metrics for rankings. The lack of principled understanding of or motivation for recall has resulted in criticism amongst the retrieval community that recall is useful as a measure at all. In this light, we reflect on the measurement of recall in rankings from a formal perspective. Our analysis is composed of three tenets: recall, robustness, and lexicographic evaluation. First, we formally define `recall-orientation' as sensitivity to movement of the bottom-ranked relevant item. Second, we analyze our concept of recall orientation from the perspective of robustness with respect to possible searchers and content providers. Finally, we extend this conceptual and theoretical treatment of recall by developing a practical pref
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#36827;&#34892;&#20102;&#32508;&#36848;&#65292;&#28085;&#30422;&#20102;&#38745;&#24577;&#12289;&#21160;&#24577;&#21644;&#22810;&#27169;&#24577;&#19977;&#31181;&#22270;&#31867;&#22411;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2212.05767</link><description>&lt;p&gt;
&#20851;&#20110;&#22270;&#31867;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#32508;&#36848;&#65306;&#38745;&#24577;&#12289;&#21160;&#24577;&#21644;&#22810;&#27169;&#24577;
&lt;/p&gt;
&lt;p&gt;
A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multimodal. (arXiv:2212.05767v7 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#36827;&#34892;&#20102;&#32508;&#36848;&#65292;&#28085;&#30422;&#20102;&#38745;&#24577;&#12289;&#21160;&#24577;&#21644;&#22810;&#27169;&#24577;&#19977;&#31181;&#22270;&#31867;&#22411;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#65288;KGR&#65289;&#26088;&#22312;&#26681;&#25454;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#20013;&#30340;&#36923;&#36753;&#35268;&#21017;&#25512;&#26029;&#20986;&#26032;&#30340;&#20107;&#23454;&#65292;&#24050;&#25104;&#20026;&#24555;&#36895;&#22686;&#38271;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#23427;&#24050;&#34987;&#35777;&#26126;&#22312;&#35768;&#22810;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#20013;&#26497;&#22823;&#22320;&#26377;&#30410;&#65292;&#22914;&#38382;&#39064;&#22238;&#31572;&#12289;&#25512;&#33616;&#31995;&#32479;&#31561;&#12290;&#26681;&#25454;&#22270;&#31867;&#22411;&#65292;&#29616;&#26377;&#30340;KGR&#27169;&#22411;&#21487;&#20197;&#22823;&#33268;&#20998;&#20026;&#19977;&#31867;&#65292;&#21363;&#38745;&#24577;&#27169;&#22411;&#12289;&#26102;&#24577;&#27169;&#22411;&#21644;&#22810;&#27169;&#24577;&#27169;&#22411;&#12290;&#35813;&#39046;&#22495;&#30340;&#26089;&#26399;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#38745;&#24577;KGR&#19978;&#65292;&#32780;&#26368;&#36817;&#30340;&#24037;&#20316;&#23581;&#35797;&#21033;&#29992;&#26356;&#23454;&#38469;&#21644;&#26356;&#25509;&#36817;&#29616;&#23454;&#19990;&#30028;&#30340;&#26102;&#24577;&#21644;&#22810;&#27169;&#24577;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#26080;&#32508;&#21512;&#24635;&#32467;&#21644;&#35752;&#35770;&#36825;&#19968;&#37325;&#35201;&#26041;&#21521;&#20013;&#30340;&#27169;&#22411;&#30340;&#35843;&#26597;&#35770;&#25991;&#21644;&#24320;&#28304;&#23384;&#20648;&#24211;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#38024;&#23545;&#20174;&#38745;&#24577;&#21040;&#26102;&#24577;&#20877;&#21040;&#22810;&#27169;&#24577;KG&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#30340;&#39318;&#27425;&#32508;&#36848;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26412;&#25991;&#22522;&#20110;&#21452;&#23618;&#20998;&#31867;&#23545;&#27169;&#22411;&#36827;&#34892;&#20102;&#22238;&#39038;&#65292;
&lt;/p&gt;
&lt;p&gt;
Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to significantly benefit the usage of KGs in many AI applications, such as question answering, recommendation systems, and etc. According to the graph types, existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. Early works in this domain mainly focus on static KGR, and recent works try to leverage the temporal and multi-modal information, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the models are reviewed based on bi-level taxonomy,
&lt;/p&gt;</description></item><item><title>ICPE&#26159;&#19968;&#31181;&#38754;&#21521;&#25512;&#33616;&#21435;&#20559;&#20506;&#30340;&#39033;&#30446;&#32858;&#31867;&#22810;&#30446;&#26631;&#20248;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#24179;&#34913;&#19981;&#21516;&#27969;&#34892;&#24230;&#30340;&#39033;&#30446;&#32858;&#31867;&#30340;&#23398;&#20064;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#27169;&#22411;&#20174;&#20559;&#20506;&#25968;&#25454;&#29983;&#25104;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#23545;&#28508;&#22312;&#26377;&#36259;&#39033;&#30446;&#30340;&#25506;&#32034;&#12290;</title><link>http://arxiv.org/abs/2109.12887</link><description>&lt;p&gt;
ICPE:&#19968;&#31181;&#38754;&#21521;&#25512;&#33616;&#21435;&#20559;&#20506;&#30340;&#39033;&#30446;&#32858;&#31867;&#22810;&#30446;&#26631;&#20248;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
ICPE: An Item Cluster-Wise Pareto-Efficient Framework for Recommendation Debiasing. (arXiv:2109.12887v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12887
&lt;/p&gt;
&lt;p&gt;
ICPE&#26159;&#19968;&#31181;&#38754;&#21521;&#25512;&#33616;&#21435;&#20559;&#20506;&#30340;&#39033;&#30446;&#32858;&#31867;&#22810;&#30446;&#26631;&#20248;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#24179;&#34913;&#19981;&#21516;&#27969;&#34892;&#24230;&#30340;&#39033;&#30446;&#32858;&#31867;&#30340;&#23398;&#20064;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#27169;&#22411;&#20174;&#20559;&#20506;&#25968;&#25454;&#29983;&#25104;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#23545;&#28508;&#22312;&#26377;&#36259;&#39033;&#30446;&#30340;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#21382;&#21490;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30340;&#25512;&#33616;&#31995;&#32479;&#23545;&#20110;&#22522;&#20110;web&#30340;&#26381;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#35757;&#32451;&#25512;&#33616;&#27169;&#22411;&#30340;&#35266;&#23519;&#25968;&#25454;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#20506;&#38382;&#39064;&#12290;&#23454;&#38469;&#19978;&#65292;&#25968;&#25454;&#38598;&#30340;&#39033;&#30446;&#39057;&#29575;&#20998;&#24067;&#21576;&#39640;&#24230;&#20559;&#26012;&#30340;&#24130;&#24459;&#20998;&#24067;&#12290;&#19968;&#23567;&#37096;&#20998;&#28909;&#38376;&#39033;&#30446;&#30340;&#20132;&#20114;&#20960;&#20046;&#21344;&#25454;&#20102;&#25972;&#20010;&#35757;&#32451;&#25968;&#25454;&#12290;&#20174;&#36825;&#31181;&#20559;&#20506;&#25968;&#25454;&#35757;&#32451;&#30340;&#27491;&#24120;&#27169;&#22411;&#20542;&#21521;&#20110;&#37325;&#22797;&#29983;&#25104;&#26469;&#33258;&#28909;&#38376;&#39033;&#30446;&#30340;&#25512;&#33616;&#65292;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#20559;&#20506;&#24182;&#24433;&#21709;&#20102;&#23545;&#28508;&#22312;&#26377;&#36259;&#39033;&#30446;&#30340;&#25506;&#32034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#39033;&#30446;&#32858;&#31867;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#35270;&#35282;&#21019;&#26032;&#24615;&#22320;&#25506;&#32034;&#25512;&#33616;&#21435;&#20559;&#20506;&#30340;&#26680;&#24515;&#20027;&#39064;&#12290;&#20026;&#20102;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#24179;&#34913;&#23545;&#19981;&#21516;&#27969;&#34892;&#24230;&#30340;&#39033;&#30446;&#32858;&#31867;&#30340;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#21363;Item Cluster-Wise Pareto-Efficient Recommendation&#65288;ICPE&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender system based on historical user-item interactions is of vital importance for web-based services. However, the observed data used to train the recommender model suffers from severe bias issues. Practically, the item frequency distribution of the dataset is a highly skewed power-law distribution. Interactions of a small fraction of head items account for almost the whole training data. The normal training paradigm from such biased data tends to repetitively generate recommendations from the head items, which further exacerbates the biases and affects the exploration of potentially interesting items from the niche set. In this work, we innovatively explore the central theme of recommendation debiasing from an item cluster-wise multi-objective optimization perspective. Aiming to balance the learning on various item clusters that differ in popularity during the training process, we propose a model-agnostic framework namely Item Cluster-Wise Pareto-Efficient Recommendation (ICPE)
&lt;/p&gt;</description></item></channel></rss>