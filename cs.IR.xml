<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65288;COVE&#65289;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19979;&#30340;&#23454;&#20307;&#20998;&#31867;&#20449;&#24687;&#65292;&#24182;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16761</link><description>&lt;p&gt;
&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Co-evolving Vector Quantization for ID-based Recommendation. (arXiv:2308.16761v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16761
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65288;COVE&#65289;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19979;&#30340;&#23454;&#20307;&#20998;&#31867;&#20449;&#24687;&#65292;&#24182;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31867;&#21035;&#20449;&#24687;&#23545;&#20110;&#25552;&#39640;&#25512;&#33616;&#30340;&#36136;&#37327;&#21644;&#20010;&#24615;&#21270;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#20013;&#65292;&#39033;&#30446;&#31867;&#21035;&#20449;&#24687;&#30340;&#21487;&#29992;&#24615;&#24182;&#19981;&#19968;&#33268;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#20197;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#23454;&#20307;&#65288;&#21363;&#29992;&#25143;&#21644;&#39033;&#30446;&#65289;&#22312;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19978;&#30340;&#20998;&#31867;&#20449;&#24687;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65292;&#21363;COVE&#65292;&#23427;&#33021;&#22815;&#21516;&#26102;&#23398;&#20064;&#21644;&#25913;&#36827;&#20195;&#30721;&#34920;&#31034;&#21644;&#23454;&#20307;&#23884;&#20837;&#65292;&#24182;&#20197;&#20174;&#38543;&#26426;&#21021;&#22987;&#21270;&#29366;&#24577;&#24320;&#22987;&#30340;&#31471;&#21040;&#31471;&#26041;&#24335;&#36827;&#34892;&#12290;&#36890;&#36807;&#20854;&#39640;&#24230;&#36866;&#24212;&#24615;&#65292;COVE&#21487;&#20197;&#36731;&#26494;&#38598;&#25104;&#21040;&#29616;&#26377;&#30340;&#25512;&#33616;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;COVE&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#21015;&#34920;&#23436;&#25104;&#12289;&#21327;&#21516;&#36807;&#28388;&#21644;&#28857;&#20987;&#29575;&#39044;&#27979;&#65292;&#28085;&#30422;&#19981;&#21516;&#30340;&#25512;&#33616;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Category information plays a crucial role in enhancing the quality and personalization of recommendations. Nevertheless, the availability of item category information is not consistently present, particularly in the context of ID-based recommendations. In this work, we propose an alternative approach to automatically learn and generate entity (i.e., user and item) categorical information at different levels of granularity, specifically for ID-based recommendation. Specifically, we devise a co-evolving vector quantization framework, namely COVE, which enables the simultaneous learning and refinement of code representation and entity embedding in an end-to-end manner, starting from the randomly initialized states. With its high adaptability, COVE can be easily integrated into existing recommendation models. We validate the effectiveness of COVE on various recommendation tasks including list completion, collaborative filtering, and click-through rate prediction, across different recommend
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;LLM&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#26597;&#35810;&#37325;&#20889;&#26041;&#27861;&#26469;&#25552;&#39640;&#25991;&#26412;&#25490;&#21517;&#20219;&#21153;&#12290;&#36890;&#36807;&#36890;&#36807;&#19978;&#19979;&#25991;&#24863;&#30693;&#25552;&#31034;&#26469;&#37325;&#20889;&#27169;&#31946;&#30340;&#35757;&#32451;&#26597;&#35810;&#65292;&#20811;&#26381;&#20102;&#27010;&#24565;&#28418;&#31227;&#21644;&#25512;&#29702;&#24320;&#38144;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16753</link><description>&lt;p&gt;
&#22522;&#20110;LLM&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#26597;&#35810;&#37325;&#20889;&#26041;&#27861;&#29992;&#20110;&#25991;&#26412;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Context Aware Query Rewriting for Text Rankers using LLM. (arXiv:2308.16753v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16753
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;LLM&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#26597;&#35810;&#37325;&#20889;&#26041;&#27861;&#26469;&#25552;&#39640;&#25991;&#26412;&#25490;&#21517;&#20219;&#21153;&#12290;&#36890;&#36807;&#36890;&#36807;&#19978;&#19979;&#25991;&#24863;&#30693;&#25552;&#31034;&#26469;&#37325;&#20889;&#27169;&#31946;&#30340;&#35757;&#32451;&#26597;&#35810;&#65292;&#20811;&#26381;&#20102;&#27010;&#24565;&#28418;&#31227;&#21644;&#25512;&#29702;&#24320;&#38144;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#37325;&#20889;&#26159;&#19968;&#31867;&#24212;&#29992;&#20110;&#19981;&#23436;&#20840;&#25351;&#23450;&#21644;&#27169;&#31946;&#26597;&#35810;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#20811;&#26381;&#25991;&#26723;&#25490;&#21517;&#20013;&#30340;&#35789;&#27719;&#19981;&#21305;&#37197;&#38382;&#39064;&#12290;&#26597;&#35810;&#36890;&#24120;&#22312;&#26597;&#35810;&#22788;&#29702;&#36807;&#31243;&#20013;&#36827;&#34892;&#37325;&#20889;&#65292;&#20197;&#20415;&#20026;&#19979;&#28216;&#25490;&#21517;&#22120;&#25552;&#20379;&#26356;&#22909;&#30340;&#26597;&#35810;&#24314;&#27169;&#12290;&#38543;&#30528;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#65292;&#24050;&#32463;&#24320;&#22987;&#30740;&#31350;&#20351;&#29992;&#29983;&#25104;&#26041;&#27861;&#29983;&#25104;&#20266;&#25991;&#26723;&#26469;&#35299;&#20915;&#36825;&#31181;&#22266;&#26377;&#30340;&#35789;&#27719;&#24046;&#36317;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;LLMs&#22312;&#25552;&#39640;&#25991;&#26412;&#25490;&#21517;&#20219;&#21153;&#20013;&#26597;&#35810;&#37325;&#20889;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#21457;&#29616;&#20351;&#29992;LLMs&#20316;&#20026;&#26597;&#35810;&#37325;&#20889;&#22120;&#23384;&#22312;&#20004;&#20010;&#22266;&#26377;&#23616;&#38480;&#24615;--&#22312;&#20165;&#20351;&#29992;&#26597;&#35810;&#20316;&#20026;&#25552;&#31034;&#26102;&#23384;&#22312;&#27010;&#24565;&#28418;&#31227;&#65292;&#24182;&#19988;&#22312;&#26597;&#35810;&#22788;&#29702;&#36807;&#31243;&#20013;&#23384;&#22312;&#22823;&#37327;&#30340;&#25512;&#29702;&#24320;&#38144;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#25928;&#26524;&#24778;&#20154;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;&#24863;&#30693;&#26597;&#35810;&#37325;&#20889;&#65288;CAR&#65289;&#65292;&#20197;&#21033;&#29992;LLMs&#30340;&#20248;&#21183;&#36827;&#34892;&#26597;&#35810;&#29702;&#35299;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#19978;&#19979;&#25991;&#24863;&#30693;&#25552;&#31034;&#26469;&#37325;&#20889;&#27169;&#31946;&#30340;&#35757;&#32451;&#26597;&#35810;&#65292;&#20197;&#22312;&#26597;&#35810;&#29702;&#35299;&#26041;&#38754;&#33719;&#24471;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Query rewriting refers to an established family of approaches that are applied to underspecified and ambiguous queries to overcome the vocabulary mismatch problem in document ranking. Queries are typically rewritten during query processing time for better query modelling for the downstream ranker. With the advent of large-language models (LLMs), there have been initial investigations into using generative approaches to generate pseudo documents to tackle this inherent vocabulary gap. In this work, we analyze the utility of LLMs for improved query rewriting for text ranking tasks. We find that there are two inherent limitations of using LLMs as query re-writers -- concept drift when using only queries as prompts and large inference costs during query processing. We adopt a simple, yet surprisingly effective, approach called context aware query rewriting (CAR) to leverage the benefits of LLMs for query understanding. Firstly, we rewrite ambiguous training queries by context-aware prompti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#27010;&#24565;&#65292;&#21363;&#22522;&#20110;&#21518;&#26524;&#30340;&#35299;&#37322;&#65292;&#20197;&#24378;&#35843;&#25512;&#33616;&#39033;&#23545;&#29992;&#25143;&#20010;&#20154;&#28040;&#36153;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#25143;&#20307;&#39564;&#21644;&#28385;&#24847;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.16708</link><description>&lt;p&gt;
&#19987;&#27880;&#20110;&#24433;&#21709;&#65306;&#22522;&#20110;&#21518;&#26524;&#30340;&#25512;&#33616;&#31995;&#32479;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Concentrating on the Impact: Consequence-based Explanations in Recommender Systems. (arXiv:2308.16708v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16708
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#27010;&#24565;&#65292;&#21363;&#22522;&#20110;&#21518;&#26524;&#30340;&#35299;&#37322;&#65292;&#20197;&#24378;&#35843;&#25512;&#33616;&#39033;&#23545;&#29992;&#25143;&#20010;&#20154;&#28040;&#36153;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#25143;&#20307;&#39564;&#21644;&#28385;&#24847;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#29992;&#25143;&#20915;&#31574;&#20013;&#36215;&#21040;&#36741;&#21161;&#20316;&#29992;&#65292;&#25512;&#33616;&#39033;&#30340;&#21576;&#29616;&#26041;&#24335;&#21644;&#35299;&#37322;&#26159;&#25552;&#21319;&#29992;&#25143;&#20307;&#39564;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#29983;&#25104;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#20294;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#22312;&#29305;&#23450;&#39046;&#22495;&#32570;&#20047;&#19987;&#19994;&#30693;&#35782;&#30340;&#29992;&#25143;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#27010;&#24565;&#65292;&#21363;&#22522;&#20110;&#21518;&#26524;&#30340;&#35299;&#37322;&#65292;&#36825;&#31181;&#35299;&#37322;&#24378;&#35843;&#25512;&#33616;&#39033;&#23545;&#29992;&#25143;&#20010;&#20154;&#28040;&#36153;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#20351;&#24471;&#36981;&#24490;&#25512;&#33616;&#30340;&#25928;&#26524;&#26356;&#21152;&#28165;&#26224;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#22312;&#32447;&#29992;&#25143;&#30740;&#31350;&#65292;&#20197;&#39564;&#35777;&#20851;&#20110;&#21518;&#26524;&#35299;&#37322;&#30340;&#27427;&#36175;&#24230;&#20197;&#21450;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#19981;&#21516;&#35299;&#37322;&#30446;&#26631;&#19978;&#30340;&#24433;&#21709;&#30340;&#20551;&#35774;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#21518;&#26524;&#35299;&#37322;&#30340;&#37325;&#35201;&#24615;&#24471;&#21040;&#20102;&#29992;&#25143;&#30340;&#35748;&#21487;&#65292;&#24182;&#19988;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems assist users in decision-making, where the presentation of recommended items and their explanations are critical factors for enhancing the overall user experience. Although various methods for generating explanations have been proposed, there is still room for improvement, particularly for users who lack expertise in a specific item domain. In this study, we introduce the novel concept of \textit{consequence-based explanations}, a type of explanation that emphasizes the individual impact of consuming a recommended item on the user, which makes the effect of following recommendations clearer. We conducted an online user study to examine our assumption about the appreciation of consequence-based explanations and their impacts on different explanation aims in recommender systems. Our findings highlight the importance of consequence-based explanations, which were well-received by users and effectively improved user satisfaction in recommender systems. These results prov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21512;&#20316;&#19987;&#23478;&#23454;&#29616;&#20102;&#38271;&#23614;&#22270;&#20998;&#31867;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#22270;&#25968;&#25454;&#19978;&#30340;&#19981;&#36275;&#12290;</title><link>http://arxiv.org/abs/2308.16609</link><description>&lt;p&gt;
&#36890;&#36807;&#21512;&#20316;&#19987;&#23478;&#23454;&#29616;&#38271;&#23614;&#22270;&#20998;&#31867;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Long-Tailed Recognition for Graph Classification via Collaborative Experts. (arXiv:2308.16609v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21512;&#20316;&#19987;&#23478;&#23454;&#29616;&#20102;&#38271;&#23614;&#22270;&#20998;&#31867;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#22270;&#25968;&#25454;&#19978;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#20998;&#31867;&#26088;&#22312;&#23398;&#20064;&#29992;&#20110;&#26377;&#25928;&#31867;&#21035;&#20998;&#37197;&#30340;&#22270;&#32423;&#34920;&#31034;&#65292;&#22312;&#24179;&#34913;&#30340;&#31867;&#21035;&#20998;&#24067;&#30340;&#39640;&#36136;&#37327;&#25968;&#25454;&#38598;&#30340;&#25903;&#25345;&#19979;&#21462;&#24471;&#20102;&#26480;&#20986;&#25104;&#26524;&#12290;&#20107;&#23454;&#19978;&#65292;&#22823;&#22810;&#25968;&#29616;&#23454;&#19990;&#30028;&#30340;&#22270;&#25968;&#25454;&#33258;&#28982;&#21576;&#29616;&#38271;&#23614;&#24418;&#24335;&#65292;&#20854;&#20013;&#22836;&#37096;&#31867;&#21035;&#30340;&#26679;&#26412;&#25968;&#37327;&#36828;&#36229;&#36807;&#23614;&#37096;&#31867;&#21035;&#65292;&#22240;&#27492;&#22312;&#38271;&#23614;&#25968;&#25454;&#19978;&#30740;&#31350;&#22270;&#32423;&#20998;&#31867;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20294;&#20173;&#28982;&#36739;&#23569;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#35270;&#35273;&#20013;&#30340;&#38271;&#23614;&#23398;&#20064;&#26041;&#27861;&#22823;&#22810;&#26080;&#27861;&#21516;&#26102;&#20248;&#21270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20998;&#31867;&#22120;&#35757;&#32451;&#65292;&#24182;&#19988;&#24573;&#30053;&#20102;&#38590;&#20197;&#20998;&#31867;&#30340;&#31867;&#21035;&#30340;&#25366;&#25496;&#12290;&#30452;&#25509;&#23558;&#29616;&#26377;&#26041;&#27861;&#24212;&#29992;&#20110;&#22270;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#24615;&#33021;&#65292;&#22240;&#20026;&#22312;&#22270;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30001;&#20110;&#22797;&#26434;&#30340;&#25299;&#25169;&#29305;&#24449;&#20250;&#26356;&#21152;&#25935;&#24863;&#20110;&#38271;&#23614;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#38271;&#23614;&#22270;&#32423;&#20998;&#31867;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Graph classification, aiming at learning the graph-level representations for effective class assignments, has received outstanding achievements, which heavily relies on high-quality datasets that have balanced class distribution. In fact, most real-world graph data naturally presents a long-tailed form, where the head classes occupy much more samples than the tail classes, it thus is essential to study the graph-level classification over long-tailed data while still remaining largely unexplored. However, most existing long-tailed learning methods in visions fail to jointly optimize the representation learning and classifier training, as well as neglect the mining of the hard-to-classify classes. Directly applying existing methods to graphs may lead to sub-optimal performance, since the model trained on graphs would be more sensitive to the long-tailed distribution due to the complex topological characteristics. Hence, in this paper, we propose a novel long-tailed graph-level classifica
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30340;&#21019;&#26032;&#28857;&#26159;&#23558;&#25512;&#33616;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34701;&#21512;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#20132;&#20114;&#24335;&#25512;&#33616;&#31995;&#32479;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#27169;&#22411;&#22312;&#25552;&#20379;&#35299;&#37322;&#21644;&#21442;&#19982;&#23545;&#35805;&#20219;&#21153;&#26041;&#38754;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2308.16505</link><description>&lt;p&gt;
&#25512;&#33616;AI&#20195;&#29702;&#65306;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#21040;&#20132;&#20114;&#24335;&#25512;&#33616;&#20013;
&lt;/p&gt;
&lt;p&gt;
Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations. (arXiv:2308.16505v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16505
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30340;&#21019;&#26032;&#28857;&#26159;&#23558;&#25512;&#33616;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34701;&#21512;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#20132;&#20114;&#24335;&#25512;&#33616;&#31995;&#32479;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#27169;&#22411;&#22312;&#25552;&#20379;&#35299;&#37322;&#21644;&#21442;&#19982;&#23545;&#35805;&#20219;&#21153;&#26041;&#38754;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#27169;&#22411;&#36890;&#36807;&#21033;&#29992;&#24191;&#27867;&#30340;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#26469;&#25552;&#20379;&#39046;&#22495;&#29305;&#23450;&#30340;&#29289;&#21697;&#25512;&#33616;&#65292;&#23637;&#29616;&#20986;&#36731;&#37327;&#32423;&#39046;&#22495;&#19987;&#23478;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#25552;&#20379;&#35299;&#37322;&#21644;&#21442;&#19982;&#23545;&#35805;&#31561;&#22810;&#26679;&#21270;&#20219;&#21153;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20195;&#34920;&#20102;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#30340;&#37325;&#35201;&#36827;&#23637;&#65292;&#22312;&#25351;&#20196;&#29702;&#35299;&#12289;&#24120;&#35782;&#25512;&#29702;&#21644;&#20154;&#31867;&#20132;&#20114;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;LLMs&#32570;&#20047;&#39046;&#22495;&#29305;&#23450;&#29289;&#21697;&#30446;&#24405;&#21644;&#34892;&#20026;&#27169;&#24335;&#30340;&#30693;&#35782;&#65292;&#29305;&#21035;&#26159;&#22312;&#19982;&#19968;&#33324;&#19990;&#30028;&#30693;&#35782;&#19981;&#21516;&#30340;&#39046;&#22495;&#65292;&#22914;&#22312;&#32447;&#30005;&#23376;&#21830;&#21153;&#12290;&#20026;&#27599;&#20010;&#39046;&#22495;&#24494;&#35843;LLMs&#26082;&#19981;&#32463;&#27982;&#21448;&#19981;&#39640;&#25928;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#25512;&#33616;&#27169;&#22411;&#21644;LLMs&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#32467;&#21512;&#21508;&#33258;&#30340;&#20248;&#21183;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#20132;&#20114;&#24335;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#26694;&#26550;&#31216;&#20026;RecAgent&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;LLMs
&lt;/p&gt;
&lt;p&gt;
Recommender models excel at providing domain-specific item recommendations by leveraging extensive user behavior data. Despite their ability to act as lightweight domain experts, they struggle to perform versatile tasks such as providing explanations and engaging in conversations. On the other hand, large language models (LLMs) represent a significant step towards artificial general intelligence, showcasing remarkable capabilities in instruction comprehension, commonsense reasoning, and human interaction. However, LLMs lack the knowledge of domain-specific item catalogs and behavioral patterns, particularly in areas that diverge from general world knowledge, such as online e-commerce. Finetuning LLMs for each domain is neither economic nor efficient.  In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create a versatile and interactive recommender system. We introduce an efficient framework called RecAgent, which employs LLMs a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;AntM$^{2}$C&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#22810;&#22330;&#26223;&#22810;&#27169;&#24577;&#28857;&#20987;&#29575;&#39044;&#27979;&#12290;&#35813;&#25968;&#25454;&#38598;&#24357;&#34917;&#20102;&#29616;&#26377;&#25968;&#25454;&#38598;&#30340;&#38480;&#21046;&#65292;&#21253;&#25324;&#22810;&#20010;&#22330;&#26223;&#20013;&#19981;&#21516;&#31867;&#22411;&#39033;&#30446;&#30340;&#24314;&#27169;&#20197;&#21450;&#22810;&#27169;&#24577;&#29305;&#24449;&#30340;&#32570;&#20047;&#12290;&#23427;&#23558;&#20026;&#27169;&#22411;&#30340;&#21487;&#38752;&#35780;&#20272;&#25552;&#20379;&#26356;&#20840;&#38754;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2308.16437</link><description>&lt;p&gt;
AntM$^{2}$C&#65306;&#19968;&#20010;&#29992;&#20110;&#22810;&#22330;&#26223;&#22810;&#27169;&#24577;&#28857;&#20987;&#29575;&#39044;&#27979;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
AntM$^{2}$C: A Large Scale Dataset For Multi-Scenario Multi-Modal CTR Prediction. (arXiv:2308.16437v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16437
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;AntM$^{2}$C&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#22810;&#22330;&#26223;&#22810;&#27169;&#24577;&#28857;&#20987;&#29575;&#39044;&#27979;&#12290;&#35813;&#25968;&#25454;&#38598;&#24357;&#34917;&#20102;&#29616;&#26377;&#25968;&#25454;&#38598;&#30340;&#38480;&#21046;&#65292;&#21253;&#25324;&#22810;&#20010;&#22330;&#26223;&#20013;&#19981;&#21516;&#31867;&#22411;&#39033;&#30446;&#30340;&#24314;&#27169;&#20197;&#21450;&#22810;&#27169;&#24577;&#29305;&#24449;&#30340;&#32570;&#20047;&#12290;&#23427;&#23558;&#20026;&#27169;&#22411;&#30340;&#21487;&#38752;&#35780;&#20272;&#25552;&#20379;&#26356;&#20840;&#38754;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#20986;&#29616;&#20102;&#21508;&#31181;&#20844;&#24320;&#30340;CTR&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#25968;&#25454;&#38598;&#20027;&#35201;&#23384;&#22312;&#20197;&#19979;&#38480;&#21046;&#12290;&#39318;&#20808;&#65292;&#29992;&#25143;&#36890;&#24120;&#20250;&#20174;&#22810;&#20010;&#22330;&#26223;&#20013;&#28857;&#20987;&#19981;&#21516;&#31867;&#22411;&#30340;&#39033;&#30446;&#65292;&#20174;&#22810;&#20010;&#22330;&#26223;&#24314;&#27169;&#21487;&#20197;&#26356;&#20840;&#38754;&#22320;&#20102;&#35299;&#29992;&#25143;&#12290;&#29616;&#26377;&#25968;&#25454;&#38598;&#21482;&#21253;&#25324;&#26469;&#33258;&#21333;&#20010;&#22330;&#26223;&#30340;&#30456;&#21516;&#31867;&#22411;&#39033;&#30446;&#30340;&#25968;&#25454;&#12290;&#20854;&#27425;&#65292;&#22810;&#27169;&#24577;&#29305;&#24449;&#22312;&#22810;&#22330;&#26223;&#39044;&#27979;&#20013;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#35299;&#20915;&#20102;&#19981;&#21516;&#22330;&#26223;&#20043;&#38388;&#19981;&#19968;&#33268;&#30340;ID&#32534;&#30721;&#38382;&#39064;&#12290;&#29616;&#26377;&#25968;&#25454;&#38598;&#22522;&#20110;ID&#29305;&#24449;&#65292;&#32570;&#20047;&#22810;&#27169;&#24577;&#29305;&#24449;&#12290;&#31532;&#19977;&#65292;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21487;&#20197;&#25552;&#20379;&#26356;&#21487;&#38752;&#30340;&#27169;&#22411;&#35780;&#20272;&#65292;&#20805;&#20998;&#21453;&#26144;&#27169;&#22411;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;&#29616;&#26377;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#32422;&#20026;1&#20159;&#65292;&#19982;&#29616;&#23454;&#19990;&#30028;&#30340;CTR&#39044;&#27979;&#30456;&#27604;&#30456;&#23545;&#36739;&#23567;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction is a crucial issue in recommendation systems. There has been an emergence of various public CTR datasets. However, existing datasets primarily suffer from the following limitations. Firstly, users generally click different types of items from multiple scenarios, and modeling from multiple scenarios can provide a more comprehensive understanding of users. Existing datasets only include data for the same type of items from a single scenario. Secondly, multi-modal features are essential in multi-scenario prediction as they address the issue of inconsistent ID encoding between different scenarios. The existing datasets are based on ID features and lack multi-modal features. Third, a large-scale dataset can provide a more reliable evaluation of models, fully reflecting the performance differences between models. The scale of existing datasets is around 100 million, which is relatively small compared to the real-world CTR prediction. To address these limit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#24494;&#35270;&#39057;&#25512;&#33616;&#20013;&#35270;&#39057;&#38271;&#24230;&#25928;&#24212;&#30340;&#26041;&#27861;-&#35270;&#39057;&#38271;&#24230;&#28040;&#38500;&#25512;&#33616;&#65288;VLDRec&#65289;&#65292;&#36890;&#36807;&#35774;&#35745;&#25968;&#25454;&#26631;&#27880;&#26041;&#27861;&#21644;&#26679;&#26412;&#29983;&#25104;&#27169;&#22359;&#65292;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#29992;&#25143;&#35266;&#30475;&#26102;&#38388;&#20559;&#22909;&#65292;&#24182;&#19988;&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#25216;&#26415;&#26469;&#32852;&#21512;&#20248;&#21270;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.14276</link><description>&lt;p&gt;
&#32531;&#35299;&#24494;&#35270;&#39057;&#25512;&#33616;&#20013;&#30340;&#35270;&#39057;&#38271;&#24230;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Alleviating Video-Length Effect for Micro-video Recommendation. (arXiv:2308.14276v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#24494;&#35270;&#39057;&#25512;&#33616;&#20013;&#35270;&#39057;&#38271;&#24230;&#25928;&#24212;&#30340;&#26041;&#27861;-&#35270;&#39057;&#38271;&#24230;&#28040;&#38500;&#25512;&#33616;&#65288;VLDRec&#65289;&#65292;&#36890;&#36807;&#35774;&#35745;&#25968;&#25454;&#26631;&#27880;&#26041;&#27861;&#21644;&#26679;&#26412;&#29983;&#25104;&#27169;&#22359;&#65292;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#29992;&#25143;&#35266;&#30475;&#26102;&#38388;&#20559;&#22909;&#65292;&#24182;&#19988;&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#25216;&#26415;&#26469;&#32852;&#21512;&#20248;&#21270;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#35270;&#39057;&#24179;&#21488;&#22914;&#25238;&#38899;&#31561;&#29616;&#22312;&#38750;&#24120;&#27969;&#34892;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#29305;&#28857;&#26159;&#29992;&#25143;&#19981;&#20877;&#20174;&#19968;&#32452;&#35270;&#39057;&#20013;&#36873;&#25321;&#24863;&#20852;&#36259;&#30340;&#35270;&#39057;&#65292;&#32780;&#26159;&#35201;&#20040;&#35266;&#30475;&#25512;&#33616;&#30340;&#35270;&#39057;&#65292;&#35201;&#20040;&#36339;&#36716;&#21040;&#19979;&#19968;&#20010;&#35270;&#39057;&#12290;&#22240;&#27492;&#65292;&#29992;&#25143;&#35266;&#30475;&#34892;&#20026;&#30340;&#26102;&#38388;&#38271;&#24230;&#25104;&#20026;&#35782;&#21035;&#20559;&#22909;&#30340;&#26368;&#37325;&#35201;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#32463;&#39564;&#25968;&#25454;&#20998;&#26512;&#26174;&#31034;&#20102;&#35270;&#39057;&#38271;&#24230;&#25928;&#24212;&#65292;&#21363;&#38271;&#35270;&#39057;&#26356;&#23481;&#26131;&#33719;&#24471;&#26356;&#39640;&#30340;&#24179;&#22343;&#35266;&#30475;&#26102;&#38388;&#65292;&#22240;&#27492;&#37319;&#29992;&#36825;&#31181;&#35266;&#30475;&#26102;&#38388;&#26631;&#31614;&#26469;&#34913;&#37327;&#29992;&#25143;&#20559;&#22909;&#21487;&#33021;&#20250;&#23548;&#33268;&#20559;&#24046;&#27169;&#22411;&#26356;&#20559;&#21521;&#20110;&#38271;&#35270;&#39057;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#24494;&#35270;&#39057;&#25512;&#33616;&#20013;&#35270;&#39057;&#38271;&#24230;&#25928;&#24212;&#30340;&#26041;&#27861;-&#35270;&#39057;&#38271;&#24230;&#28040;&#38500;&#25512;&#33616;&#65288;VLDRec&#65289;&#12290;VLDRec&#35774;&#35745;&#20102;&#25968;&#25454;&#26631;&#27880;&#26041;&#27861;&#21644;&#26679;&#26412;&#29983;&#25104;&#27169;&#22359;&#65292;&#20197;&#26356;&#22909;&#22320;&#20197;&#35266;&#30475;&#26102;&#38388;&#20026;&#23548;&#21521;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#12290;&#23427;&#36827;&#19968;&#27493;&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#25216;&#26415;&#26469;&#32852;&#21512;&#20248;&#21270;&#19978;&#36848;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Micro-videos platforms such as TikTok are extremely popular nowadays. One important feature is that users no longer select interested videos from a set, instead they either watch the recommended video or skip to the next one. As a result, the time length of users' watching behavior becomes the most important signal for identifying preferences. However, our empirical data analysis has shown a video-length effect that long videos are easier to receive a higher value of average view time, thus adopting such view-time labels for measuring user preferences can easily induce a biased model that favors the longer videos. In this paper, we propose a Video Length Debiasing Recommendation (VLDRec) method to alleviate such an effect for micro-video recommendation. VLDRec designs the data labeling approach and the sample generation module that better capture user preferences in a view-time oriented manner. It further leverages the multi-task learning technique to jointly optimize the above samples
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#24182;&#25552;&#20379;&#35780;&#20272;&#26426;&#21046;&#65292;&#21516;&#26102;&#20063;&#32771;&#34385;&#21040;&#20102;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#26088;&#22312;&#24110;&#21161;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#22522;&#20110;&#21487;&#20449;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2307.15464</link><description>&lt;p&gt;
&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#36136;&#37327;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Framework to Automatically Determine the Quality of Open Data Catalogs. (arXiv:2307.15464v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#24182;&#25552;&#20379;&#35780;&#20272;&#26426;&#21046;&#65292;&#21516;&#26102;&#20063;&#32771;&#34385;&#21040;&#20102;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#26088;&#22312;&#24110;&#21161;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#22522;&#20110;&#21487;&#20449;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#30446;&#24405;&#22312;&#29616;&#20195;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#20419;&#36827;&#21508;&#31181;&#25968;&#25454;&#36164;&#20135;&#30340;&#21457;&#29616;&#12289;&#29702;&#35299;&#21644;&#21033;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#24320;&#25918;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#29615;&#22659;&#20013;&#30830;&#20445;&#20854;&#36136;&#37327;&#21644;&#21487;&#38752;&#24615;&#26159;&#22797;&#26434;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35299;&#20915;&#20102;&#39640;&#25928;&#21644;&#21487;&#38752;&#30340;&#36136;&#37327;&#35780;&#20272;&#26426;&#21046;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#21508;&#31181;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#22914;&#20934;&#30830;&#24615;&#12289;&#23436;&#25972;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#21450;&#26102;&#24615;&#65292;&#25552;&#20379;&#22810;&#31181;&#35780;&#20272;&#20860;&#23481;&#24615;&#21644;&#30456;&#20284;&#24615;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20197;&#21450;&#23454;&#26045;&#19968;&#32452;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#22914;&#28335;&#28304;&#24615;&#12289;&#21487;&#35835;&#24615;&#21644;&#35768;&#21487;&#35777;&#12290;&#20854;&#30446;&#26631;&#26159;&#20351;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#33021;&#22815;&#22522;&#20110;&#21487;&#20449;&#21644;&#31934;&#24515;&#31649;&#29702;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data catalogs play a crucial role in modern data-driven organizations by facilitating the discovery, understanding, and utilization of diverse data assets. However, ensuring their quality and reliability is complex, especially in open and large-scale data environments. This paper proposes a framework to automatically determine the quality of open data catalogs, addressing the need for efficient and reliable quality assessment mechanisms. Our framework can analyze various core quality dimensions, such as accuracy, completeness, consistency, scalability, and timeliness, offer several alternatives for the assessment of compatibility and similarity across such catalogs as well as the implementation of a set of non-core quality dimensions such as provenance, readability, and licensing. The goal is to empower data-driven organizations to make informed decisions based on trustworthy and well-curated data assets. The source code that illustrates our approach can be downloaded from https://www.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;GENRE&#65292;&#23427;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#65292;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#25552;&#20379;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#12290;</title><link>http://arxiv.org/abs/2305.06566</link><description>&lt;p&gt;
LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#21021;&#25506;
&lt;/p&gt;
&lt;p&gt;
A First Look at LLM-Powered Generative News Recommendation. (arXiv:2305.06566v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;GENRE&#65292;&#23427;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#65292;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#25552;&#20379;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#29992;&#25143;&#27983;&#35272;&#28023;&#37327;&#22312;&#32447;&#26032;&#38395;&#20869;&#23481;&#25152;&#24517;&#38656;&#30340;&#24037;&#20855;&#65292;&#28982;&#32780;&#29616;&#26377;&#30340;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30528;&#20919;&#21551;&#21160;&#38382;&#39064;&#12289;&#29992;&#25143;&#30011;&#20687;&#24314;&#27169;&#21644;&#26032;&#38395;&#20869;&#23481;&#29702;&#35299;&#31561;&#37325;&#22823;&#25361;&#25112;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#36890;&#24120;&#36890;&#36807;&#27169;&#22411;&#35774;&#35745;&#36981;&#24490;&#19968;&#31181;&#19981;&#28789;&#27963;&#30340;&#20363;&#34892;&#31243;&#24207;&#26469;&#35299;&#20915;&#29305;&#23450;&#30340;&#25361;&#25112;&#65292;&#20294;&#22312;&#29702;&#35299;&#26032;&#38395;&#20869;&#23481;&#21644;&#25429;&#25417;&#29992;&#25143;&#20852;&#36259;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;GENRE&#65292;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;&#65292;&#23427;&#21033;&#29992;&#26469;&#33258;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#26469;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#26469;&#25552;&#20379;&#19968;&#31181;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#26032;&#38395;&#25512;&#33616;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;GENRE&#22312;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#20013;&#30340;&#24212;&#29992;&#12290;&#20351;&#29992;&#21508;&#31181;&#27969;&#34892;&#30340;&#25512;&#33616;&#27169;&#22411;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;GENRE&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding. Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests. In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data. Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design. We showcase the use of GENRE for personalized news generation, user profiling, and news summarization. Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#21704;&#24076;&#26041;&#27861;&#65292;&#20351;&#29992;&#30456;&#20284;&#24615;&#20998;&#24067;&#26657;&#20934;&#26469;&#35299;&#20915;&#22312;&#31163;&#25955;&#21704;&#24076;&#30721;&#31354;&#38388;&#20013;&#30340;&#30456;&#20284;&#24615;&#22349;&#32553;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.07669</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#21704;&#24076;&#19982;&#30456;&#20284;&#24615;&#20998;&#24067;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Hashing with Similarity Distribution Calibration. (arXiv:2302.07669v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#21704;&#24076;&#26041;&#27861;&#65292;&#20351;&#29992;&#30456;&#20284;&#24615;&#20998;&#24067;&#26657;&#20934;&#26469;&#35299;&#20915;&#22312;&#31163;&#25955;&#21704;&#24076;&#30721;&#31354;&#38388;&#20013;&#30340;&#30456;&#20284;&#24615;&#22349;&#32553;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#21704;&#24076;&#26041;&#27861;&#36890;&#24120;&#26088;&#22312;&#36890;&#36807;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#20108;&#36827;&#21046;&#21704;&#24076;&#30721;&#26469;&#20445;&#30041;&#29305;&#24449;&#31354;&#38388;&#20013;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#32463;&#24120;&#24573;&#35270;&#19968;&#20010;&#20107;&#23454;&#65292;&#21363;&#22312;&#31163;&#25955;&#30340;&#21704;&#24076;&#30721;&#31354;&#38388;&#20013;&#65292;&#36830;&#32493;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#21487;&#33021;&#26080;&#27861;&#34987;&#20445;&#30041;&#65292;&#36825;&#26159;&#22240;&#20026;&#21704;&#24076;&#30721;&#30340;&#30456;&#20284;&#24615;&#33539;&#22260;&#21463;&#21040;&#20102;&#38480;&#21046;&#12290;&#30456;&#20284;&#24615;&#33539;&#22260;&#21463;&#21040;&#21704;&#24076;&#30721;&#38271;&#24230;&#30340;&#38480;&#21046;&#65292;&#21487;&#33021;&#23548;&#33268;&#19968;&#20010;&#31216;&#20026;&#30456;&#20284;&#24615;&#22349;&#32553;&#30340;&#38382;&#39064;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#27491;&#36127;&#25968;&#25454;&#28857;&#23545;&#22312;&#21704;&#24076;&#31354;&#38388;&#20013;&#21464;&#24471;&#19981;&#22826;&#21487;&#21306;&#20998;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#30456;&#20284;&#24615;&#20998;&#24067;&#26657;&#20934;&#65288;SDC&#65289;&#26041;&#27861;&#12290;SDC&#23558;&#21704;&#24076;&#30721;&#30456;&#20284;&#24615;&#20998;&#24067;&#23545;&#40784;&#21040;&#19968;&#20010;&#26657;&#20934;&#20998;&#24067;&#65288;&#20363;&#22914;beta&#20998;&#24067;&#65289;&#65292;&#20351;&#24471;&#25972;&#20010;&#30456;&#20284;&#24615;&#33539;&#22260;&#37117;&#26377;&#36275;&#22815;&#30340;&#20998;&#25955;&#65292;&#20174;&#32780;&#32531;&#35299;&#20102;&#30456;&#20284;&#24615;&#22349;&#32553;&#38382;&#39064;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;SDC&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised hashing methods typically aim to preserve the similarity between data points in a feature space by mapping them to binary hash codes. However, these methods often overlook the fact that the similarity between data points in the continuous feature space may not be preserved in the discrete hash code space, due to the limited similarity range of hash codes. The similarity range is bounded by the code length and can lead to a problem known as similarity collapse. That is, the positive and negative pairs of data points become less distinguishable from each other in the hash space. To alleviate this problem, in this paper a novel Similarity Distribution Calibration (SDC) method is introduced. SDC aligns the hash code similarity distribution towards a calibration distribution (e.g., beta distribution) with sufficient spread across the entire similarity range, thus alleviating the similarity collapse problem. Extensive experiments show that our SDC outperforms significantly the s
&lt;/p&gt;</description></item></channel></rss>