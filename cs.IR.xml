<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#20381;&#36182;&#30340;&#21704;&#24076;&#26041;&#27861;USR-LSH&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23637;&#24320;&#23454;&#20363;&#32423;&#25968;&#25454;&#37325;&#24314;&#30340;&#20248;&#21270;&#26356;&#26032;&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#30340;&#20449;&#24687;&#20445;&#30041;&#33021;&#21147;&#65292;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#30340;&#36951;&#24536;&#26426;&#21046;&#65292;&#20351;&#24471;&#25968;&#25454;&#21487;&#20197;&#24555;&#36895;&#21024;&#38500;&#21644;&#25554;&#20837;&#65292;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#65292;&#36825;&#26159;&#19968;&#31181;&#20855;&#26377;&#25968;&#25454;&#38544;&#31169;&#21644;&#23433;&#20840;&#35201;&#27714;&#30340;&#22312;&#32447;ANN&#25628;&#32034;&#30340;&#23454;&#38469;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2304.02350</link><description>&lt;p&gt;
&#26410;&#25240;&#21472;&#33258;&#37325;&#24314;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#65306;&#36208;&#21521;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#30340;&#26426;&#22120;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Unfolded Self-Reconstruction LSH: Towards Machine Unlearning in Approximate Nearest Neighbour Search. (arXiv:2304.02350v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02350
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#20381;&#36182;&#30340;&#21704;&#24076;&#26041;&#27861;USR-LSH&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23637;&#24320;&#23454;&#20363;&#32423;&#25968;&#25454;&#37325;&#24314;&#30340;&#20248;&#21270;&#26356;&#26032;&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#30340;&#20449;&#24687;&#20445;&#30041;&#33021;&#21147;&#65292;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#30340;&#36951;&#24536;&#26426;&#21046;&#65292;&#20351;&#24471;&#25968;&#25454;&#21487;&#20197;&#24555;&#36895;&#21024;&#38500;&#21644;&#25554;&#20837;&#65292;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#65292;&#36825;&#26159;&#19968;&#31181;&#20855;&#26377;&#25968;&#25454;&#38544;&#31169;&#21644;&#23433;&#20840;&#35201;&#27714;&#30340;&#22312;&#32447;ANN&#25628;&#32034;&#30340;&#23454;&#38469;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26159;&#25628;&#32034;&#24341;&#25806;&#12289;&#25512;&#33616;&#31995;&#32479;&#31561;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#35768;&#22810;&#26368;&#36817;&#30340;&#24037;&#20316;&#37117;&#26159;&#22522;&#20110;&#23398;&#20064;&#30340;&#25968;&#25454;&#20998;&#24067;&#20381;&#36182;&#21704;&#24076;&#65292;&#23454;&#29616;&#20102;&#33391;&#22909;&#30340;&#26816;&#32034;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#23545;&#29992;&#25143;&#38544;&#31169;&#21644;&#23433;&#20840;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#21152;&#65292;&#25105;&#20204;&#32463;&#24120;&#38656;&#35201;&#20174;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#21024;&#38500;&#29992;&#25143;&#25968;&#25454;&#20449;&#24687;&#20197;&#28385;&#36275;&#29305;&#23450;&#30340;&#38544;&#31169;&#21644;&#23433;&#20840;&#35201;&#27714;&#12290;&#36825;&#31181;&#38656;&#27714;&#38656;&#35201;ANN&#25628;&#32034;&#31639;&#27861;&#25903;&#25345;&#24555;&#36895;&#30340;&#22312;&#32447;&#25968;&#25454;&#21024;&#38500;&#21644;&#25554;&#20837;&#12290;&#24403;&#21069;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#21704;&#24076;&#26041;&#27861;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#21704;&#24076;&#20989;&#25968;&#65292;&#36825;&#26159;&#30001;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#26102;&#38388;&#25104;&#26412;&#22826;&#39640;&#32780;&#38590;&#20197;&#25215;&#21463;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#25968;&#25454;&#20381;&#36182;&#21704;&#24076;&#26041;&#27861;&#65292;&#21517;&#20026;unfolded self-reconstruction locality-sensitive hashing (USR-LSH)&#12290;&#25105;&#20204;&#30340;USR-LSH&#23637;&#24320;&#20102;&#23454;&#20363;&#32423;&#25968;&#25454;&#37325;&#24314;&#30340;&#20248;&#21270;&#26356;&#26032;&#65292;&#36825;&#27604;&#25968;&#25454;&#26080;&#20851;&#30340;LSH&#26356;&#33021;&#20445;&#30041;&#25968;&#25454;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;USR-LSH&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#30340;&#36951;&#24536;&#26426;&#21046;&#65292;&#29992;&#20110;&#24555;&#36895;&#30340;&#25968;&#25454;&#21024;&#38500;&#21644;&#25554;&#20837;&#65292;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;USR-LSH&#22312;&#26816;&#32034;&#20934;&#30830;&#24615;&#21644;&#26102;&#38388;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#21704;&#24076;&#26041;&#27861;&#12290;USR-LSH&#26159;&#20855;&#26377;&#25968;&#25454;&#38544;&#31169;&#21644;&#23433;&#20840;&#35201;&#27714;&#30340;&#22312;&#32447;ANN&#25628;&#32034;&#30340;&#23454;&#38469;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approximate nearest neighbour (ANN) search is an essential component of search engines, recommendation systems, etc. Many recent works focus on learning-based data-distribution-dependent hashing and achieve good retrieval performance. However, due to increasing demand for users' privacy and security, we often need to remove users' data information from Machine Learning (ML) models to satisfy specific privacy and security requirements. This need requires the ANN search algorithm to support fast online data deletion and insertion. Current learning-based hashing methods need retraining the hash function, which is prohibitable due to the vast time-cost of large-scale data. To address this problem, we propose a novel data-dependent hashing method named unfolded self-reconstruction locality-sensitive hashing (USR-LSH). Our USR-LSH unfolded the optimization update for instance-wise data reconstruction, which is better for preserving data information than data-independent LSH. Moreover, our US
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102; MoocRadar&#65292;&#19968;&#31181;&#22810;&#26041;&#38754;&#30340;&#12289;&#32454;&#31890;&#24230;&#30340;&#30693;&#35782;&#24211;&#65292;&#29992;&#20110;&#25552;&#39640; MOOC &#20013;&#35748;&#30693;&#23398;&#29983;&#24314;&#27169;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.02205</link><description>&lt;p&gt;
MoocRadar: &#19968;&#31181;&#22810;&#26041;&#38754;&#30340;&#12289;&#32454;&#31890;&#24230;&#30340;&#30693;&#35782;&#24211;&#65292;&#29992;&#20110;&#25552;&#39640; MOOC &#20013;&#35748;&#30693;&#23398;&#29983;&#24314;&#27169;&#30340;&#31934;&#24230;
&lt;/p&gt;
&lt;p&gt;
MoocRadar: A Fine-grained and Multi-aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs. (arXiv:2304.02205v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02205
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102; MoocRadar&#65292;&#19968;&#31181;&#22810;&#26041;&#38754;&#30340;&#12289;&#32454;&#31890;&#24230;&#30340;&#30693;&#35782;&#24211;&#65292;&#29992;&#20110;&#25552;&#39640; MOOC &#20013;&#35748;&#30693;&#23398;&#29983;&#24314;&#27169;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#29983;&#24314;&#27169;&#26159;&#26234;&#33021;&#25945;&#32946;&#20013;&#25512;&#26029;&#23398;&#29983;&#23398;&#20064;&#29305;&#24449;&#30340;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#23613;&#31649;&#20174;&#30693;&#35782;&#36319;&#36394;&#21644;&#35748;&#30693;&#35786;&#26029;&#30340;&#26368;&#36817;&#23581;&#35797;&#25552;&#20986;&#20102;&#20960;&#20010;&#26377;&#24076;&#26395;&#25913;&#36827;&#24403;&#21069;&#27169;&#22411;&#21487;&#29992;&#24615;&#21644;&#26377;&#25928;&#24615;&#30340;&#26041;&#21521;&#65292;&#20294;&#29616;&#26377;&#20844;&#20849;&#25968;&#25454;&#38598;&#20173;&#28982;&#19981;&#36275;&#20197;&#28385;&#36275;&#36825;&#20123;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#30340;&#38656;&#27714;&#65292;&#22240;&#20026;&#23427;&#20204;&#24573;&#30053;&#20102;&#23436;&#25972;&#30340;&#32451;&#20064;&#24773;&#22659;&#12289;&#32454;&#31890;&#24230;&#30340;&#27010;&#24565;&#21644;&#35748;&#30693;&#26631;&#31614;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102; MoocRadar&#65292;&#23427;&#26159;&#19968;&#20010;&#30001; 2,513 &#20010;&#32451;&#20064;&#38382;&#39064;&#12289;5,600 &#20010;&#30693;&#35782;&#27010;&#24565;&#21644;&#36229;&#36807; 1200 &#19975;&#34892;&#20026;&#35760;&#24405;&#32452;&#25104;&#30340;&#32454;&#31890;&#24230;&#12289;&#22810;&#26041;&#38754;&#30340;&#30693;&#35782;&#24211;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20197;&#20445;&#35777;&#32454;&#31890;&#24230;&#27010;&#24565;&#21644;&#35748;&#30693;&#26631;&#31614;&#30340;&#39640;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#27880;&#37322;&#12290;&#32479;&#35745;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#20026;&#26410;&#26469;&#25913;&#36827;&#26234;&#33021;&#25945;&#32946;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Student modeling, the task of inferring a student's learning characteristics through their interactions with coursework, is a fundamental issue in intelligent education. Although the recent attempts from knowledge tracing and cognitive diagnosis propose several promising directions for improving the usability and effectiveness of current models, the existing public datasets are still insufficient to meet the need for these potential solutions due to their ignorance of complete exercising contexts, fine-grained concepts, and cognitive labels. In this paper, we present MoocRadar, a fine-grained, multi-aspect knowledge repository consisting of 2,513 exercise questions, 5,600 knowledge concepts, and over 12 million behavioral records. Specifically, we propose a framework to guarantee a high-quality and comprehensive annotation of fine-grained concepts and cognitive labels. The statistical and experimental results indicate that our dataset provides the basis for the future improvements of e
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26377;&#25928;&#30340;&#36328;&#35821;&#35328;&#25220;&#34989;&#26816;&#27979;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#26426;&#22120;&#32763;&#35793;&#21644;&#35789;&#20041;&#28040;&#27495;&#65292;&#20351;&#29992;&#24320;&#25918;&#30340;&#22810;&#35821;&#35328;&#21516;&#20041;&#35789;&#24211;&#36827;&#34892;&#20505;&#36873;&#26816;&#32034;&#20219;&#21153;&#21644;&#39044;&#35757;&#32451;&#30340;&#22522;&#20110;&#22810;&#35821;&#35328;BERT&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.01352</link><description>&lt;p&gt;
&#19968;&#31181;&#31616;&#21333;&#26377;&#25928;&#30340;&#36328;&#35821;&#35328;&#25220;&#34989;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Simple and Effective Method of Cross-Lingual Plagiarism Detection. (arXiv:2304.01352v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01352
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26377;&#25928;&#30340;&#36328;&#35821;&#35328;&#25220;&#34989;&#26816;&#27979;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#26426;&#22120;&#32763;&#35793;&#21644;&#35789;&#20041;&#28040;&#27495;&#65292;&#20351;&#29992;&#24320;&#25918;&#30340;&#22810;&#35821;&#35328;&#21516;&#20041;&#35789;&#24211;&#36827;&#34892;&#20505;&#36873;&#26816;&#32034;&#20219;&#21153;&#21644;&#39044;&#35757;&#32451;&#30340;&#22522;&#20110;&#22810;&#35821;&#35328;BERT&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36328;&#35821;&#35328;&#25220;&#34989;&#26816;&#27979;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22823;&#37327;&#30340;&#35821;&#35328;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#24320;&#25918;&#30340;&#22810;&#35821;&#35328;&#21516;&#20041;&#35789;&#24211;&#36827;&#34892;&#20505;&#36873;&#26816;&#32034;&#20219;&#21153;&#65292;&#24182;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22522;&#20110;&#22810;&#35821;&#35328;BERT&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#12290;&#35813;&#26041;&#27861;&#22312;&#20351;&#29992;&#26102;&#19981;&#20381;&#36182;&#26426;&#22120;&#32763;&#35793;&#21644;&#35789;&#20041;&#28040;&#27495;&#65292;&#22240;&#27492;&#36866;&#29992;&#20110;&#35768;&#22810;&#35821;&#35328;&#65292;&#21253;&#25324;&#36164;&#28304;&#21294;&#20047;&#30340;&#35821;&#35328;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#29616;&#26377;&#21644;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#22312;&#27861;&#35821;&#12289;&#20420;&#35821;&#21644;&#20122;&#32654;&#23612;&#20122;&#35821;&#31561;&#35821;&#35328;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a simple cross-lingual plagiarism detection method applicable to a large number of languages. The presented approach leverages open multilingual thesauri for candidate retrieval task and pre-trained multilingual BERT-based language models for detailed analysis. The method does not rely on machine translation and word sense disambiguation when in use, and therefore is suitable for a large number of languages, including under-resourced languages. The effectiveness of the proposed approach is demonstrated for several existing and new benchmarks, achieving state-of-the-art results for French, Russian, and Armenian languages.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#25968;&#25454;&#30340;&#29992;&#25143;&#21442;&#19982;&#24230;&#19982;&#29289;&#21697;&#30456;&#20851;&#24615;&#24314;&#27169;&#26041;&#27861;&#65292;&#29305;&#21035;&#32771;&#34385;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#21453;&#39304;&#21644;&#32456;&#27490;&#34892;&#20026;&#30340;&#38543;&#26426;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.06101</link><description>&lt;p&gt;
&#35770;&#24314;&#31435;&#22522;&#20110;&#38543;&#26426;&#21453;&#39304;&#30340;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
On Modeling Long-Term User Engagement from Stochastic Feedback. (arXiv:2302.06101v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06101
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#25968;&#25454;&#30340;&#29992;&#25143;&#21442;&#19982;&#24230;&#19982;&#29289;&#21697;&#30456;&#20851;&#24615;&#24314;&#27169;&#26041;&#27861;&#65292;&#29305;&#21035;&#32771;&#34385;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#21453;&#39304;&#21644;&#32456;&#27490;&#34892;&#20026;&#30340;&#38543;&#26426;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#32456;&#26497;&#30446;&#26631;&#26159;&#25552;&#39640;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;&#24378;&#21270;&#23398;&#20064;&#26159;&#23454;&#29616;&#27492;&#30446;&#26631;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#33539;&#20363;&#65292;&#22240;&#20026;&#23427;&#30452;&#25509;&#20248;&#21270;&#20102;&#24207;&#36143;&#25512;&#33616;&#30340;&#25972;&#20307;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#38656;&#35201;&#20445;&#23384;&#25512;&#33616;&#30340;&#29289;&#21697;&#20197;&#21450;&#20854;&#20182;&#20505;&#36873;&#29289;&#21697;&#65292;&#36825;&#20250;&#23548;&#33268;&#24040;&#22823;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#20505;&#36873;&#39033;&#65292;&#32780;&#26159;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#24314;&#31435;&#29992;&#25143;&#21442;&#19982;&#24230;&#19982;&#29289;&#21697;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#32771;&#34385;&#20102;&#29992;&#25143;&#21453;&#39304;&#21644;&#32456;&#27490;&#34892;&#20026;&#30340;&#38543;&#26426;&#24615;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20855;&#26377;&#26222;&#36866;&#24615;&#20294;&#22312;&#20197;&#21069;&#30340;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#24037;&#20316;&#20013;&#24456;&#23569;&#34987;&#35752;&#35770;&#12290;&#22312;&#30495;&#23454;&#25512;&#33616;&#31995;&#32479;&#30340;&#22312;&#32447; A/B &#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24314;&#31435;&#20004;&#31181;&#31867;&#22411;&#38543;&#26426;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
An ultimate goal of recommender systems (RS) is to improve user engagement. Reinforcement learning (RL) is a promising paradigm for this goal, as it directly optimizes overall performance of sequential recommendation. However, many existing RL-based approaches induce huge computational overhead, because they require not only the recommended items but also all other candidate items to be stored. This paper proposes an efficient alternative that does not require the candidate items. The idea is to model the correlation between user engagement and items directly from data. Moreover, the proposed approach consider randomness in user feedback and termination behavior, which are ubiquitous for RS but rarely discussed in RL-based prior work. With online A/B experiments on real-world RS, we confirm the efficacy of the proposed approach and the importance of modeling the two types of randomness.
&lt;/p&gt;</description></item></channel></rss>