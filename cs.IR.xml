<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65292;&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#25198;&#28436;&#20851;&#38190;&#35282;&#33394;&#12290;&#35813;&#27169;&#22411;&#26088;&#22312;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#65292;&#24182;&#35299;&#20915;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.06871</link><description>&lt;p&gt;
&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Non-autoregressive Generative Models for Reranking Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65292;&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#25198;&#28436;&#20851;&#38190;&#35282;&#33394;&#12290;&#35813;&#27169;&#22411;&#26088;&#22312;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#65292;&#24182;&#35299;&#20915;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#37325;&#26032;&#25490;&#24207;&#36890;&#36807;&#24314;&#27169;&#39033;&#30446;&#20043;&#38388;&#30340;&#20869;&#37096;&#30456;&#20851;&#24615;&#36215;&#21040;&#20102;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#37325;&#26032;&#25490;&#24207;&#30340;&#20851;&#38190;&#25361;&#25112;&#22312;&#20110;&#22312;&#25490;&#21015;&#30340;&#32452;&#21512;&#31354;&#38388;&#20013;&#25506;&#32034;&#26368;&#20339;&#24207;&#21015;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#29983;&#25104;&#22120;-&#35780;&#20272;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#29983;&#25104;&#22120;&#29983;&#25104;&#22810;&#20010;&#21487;&#34892;&#24207;&#21015;&#65292;&#35780;&#20272;&#22120;&#22522;&#20110;&#20272;&#35745;&#30340;&#21015;&#34920;&#24471;&#20998;&#36873;&#25321;&#26368;&#20339;&#24207;&#21015;&#12290;&#29983;&#25104;&#22120;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#29983;&#25104;&#27169;&#22411;&#38750;&#24120;&#36866;&#21512;&#29983;&#25104;&#22120;&#20989;&#25968;&#12290;&#24403;&#21069;&#30340;&#29983;&#25104;&#27169;&#22411;&#37319;&#29992;&#33258;&#22238;&#24402;&#31574;&#30053;&#36827;&#34892;&#24207;&#21015;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#26102;&#24037;&#19994;&#31995;&#32479;&#20013;&#37096;&#32626;&#33258;&#22238;&#24402;&#27169;&#22411;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65288;NAR4Rec&#65289;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#19982;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;m
&lt;/p&gt;
&lt;p&gt;
In a multi-stage recommendation system, reranking plays a crucial role by modeling the intra-list correlations among items.The key challenge of reranking lies in the exploration of optimal sequences within the combinatorial space of permutations. Recent research proposes a generator-evaluator learning paradigm, where the generator generates multiple feasible sequences and the evaluator picks out the best sequence based on the estimated listwise score. Generator is of vital importance, and generative models are well-suited for the generator function. Current generative models employ an autoregressive strategy for sequence generation. However, deploying autoregressive models in real-time industrial systems is challenging. Hence, we propose a Non-AutoRegressive generative model for reranking Recommendation (NAR4Rec) designed to enhance efficiency and effectiveness. To address challenges related to sparse training samples and dynamic candidates impacting model convergence, we introduce a m
&lt;/p&gt;</description></item><item><title>&#22312;&#35831;&#27714;&#32423;&#21035;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#26041;&#27861;&#21644;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.16108</link><description>&lt;p&gt;
&#35831;&#27714;&#32423;&#21035;&#25512;&#33616;&#20013;&#30340;&#26410;&#26469;&#24433;&#21709;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Future Impact Decomposition in Request-level Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.16108
&lt;/p&gt;
&lt;p&gt;
&#22312;&#35831;&#27714;&#32423;&#21035;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#26041;&#27861;&#21644;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#24378;&#21270;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#22312;&#20248;&#21270;&#29992;&#25143;&#21644;&#31995;&#32479;&#20043;&#38388;&#30340;&#20132;&#20114;&#24207;&#21015;&#20197;&#25552;&#39640;&#38271;&#26399;&#24615;&#33021;&#26041;&#38754;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#20986;&#20110;&#23454;&#38469;&#21407;&#22240;&#65292;&#31574;&#30053;&#30340;&#21160;&#20316;&#36890;&#24120;&#34987;&#35774;&#35745;&#20026;&#25512;&#33616;&#19968;&#32452;&#29289;&#21697;&#20197;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#29992;&#25143;&#30340;&#39057;&#32321;&#21644;&#36830;&#32493;&#30340;&#27983;&#35272;&#35831;&#27714;&#12290;&#22312;&#36825;&#31181;&#21015;&#34920;&#24335;&#25512;&#33616;&#22330;&#26223;&#20013;&#65292;&#29992;&#25143;&#29366;&#24577;&#22312;&#30456;&#24212;&#30340;MDP&#65288;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65289;&#34920;&#36848;&#20013;&#30340;&#27599;&#20010;&#35831;&#27714;&#19978;&#37117;&#20250;&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35831;&#27714;&#32423;&#21035;&#30340;&#34920;&#36848;&#19982;&#29992;&#25143;&#30340;&#29289;&#21697;&#32423;&#21035;&#34892;&#20026;&#23454;&#36136;&#19978;&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#35831;&#27714;&#32423;&#21035;MDP&#19979;&#65292;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#35831;&#27714;&#32423;&#21035;&#26041;&#27861;&#21644;&#25552;&#20986;&#30340;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#26469;&#25903;&#25345;&#36825;&#19968;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommender systems, reinforcement learning solutions have shown promising results in optimizing the interaction sequence between users and the system over the long-term performance. For practical reasons, the policy's actions are typically designed as recommending a list of items to handle users' frequent and continuous browsing requests more efficiently. In this list-wise recommendation scenario, the user state is updated upon every request in the corresponding MDP formulation. However, this request-level formulation is essentially inconsistent with the user's item-level behavior. In this study, we demonstrate that an item-level optimization approach can better utilize item characteristics and optimize the policy's performance even under the request-level MDP. We support this claim by comparing the performance of standard request-level methods with the proposed item-level actor-critic framework in both simulation and online experiments. Furthermore, we show that a reward-based fut
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Self-BioRAG&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#26816;&#32034;&#21644;&#33258;&#25105;&#21453;&#24605;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#21307;&#30103;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#19987;&#27880;&#20110;&#29983;&#25104;&#35299;&#37322;&#12289;&#26816;&#32034;&#39046;&#22495;&#29305;&#23450;&#25991;&#26723;&#20197;&#21450;&#23545;&#29983;&#25104;&#30340;&#21709;&#24212;&#36827;&#34892;&#33258;&#25105;&#21453;&#24605;&#12290;</title><link>http://arxiv.org/abs/2401.15269</link><description>&lt;p&gt;
&#36890;&#36807;&#26816;&#32034;&#21644;&#33258;&#25105;&#21453;&#24605;&#25913;&#21892;&#21307;&#30103;&#25512;&#29702;&#33021;&#21147;&#30340;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models. (arXiv:2401.15269v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15269
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Self-BioRAG&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#26816;&#32034;&#21644;&#33258;&#25105;&#21453;&#24605;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#21307;&#30103;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#19987;&#27880;&#20110;&#29983;&#25104;&#35299;&#37322;&#12289;&#26816;&#32034;&#39046;&#22495;&#29305;&#23450;&#25991;&#26723;&#20197;&#21450;&#23545;&#29983;&#25104;&#30340;&#21709;&#24212;&#36827;&#34892;&#33258;&#25105;&#21453;&#24605;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#19987;&#26377;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#20363;&#22914;GPT-4&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#20013;&#35299;&#20915;&#20102;&#20174;&#22810;&#39033;&#36873;&#25321;&#39064;&#21040;&#38271;&#31687;&#29983;&#25104;&#31561;&#22810;&#26679;&#21270;&#25361;&#25112;&#30340;&#37324;&#31243;&#30865;&#12290;&#20026;&#20102;&#35299;&#20915;LLMs&#32534;&#30721;&#30693;&#35782;&#26080;&#27861;&#22788;&#29702;&#30340;&#25361;&#25112;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#21508;&#31181;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#30693;&#35782;&#35821;&#26009;&#24211;&#20013;&#25628;&#32034;&#25991;&#26723;&#24182;&#26080;&#26465;&#20214;&#25110;&#26377;&#36873;&#25321;&#22320;&#23558;&#20854;&#38468;&#21152;&#21040;LLMs&#30340;&#36755;&#20837;&#26469;&#36827;&#34892;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#23558;&#29616;&#26377;&#26041;&#27861;&#24212;&#29992;&#20110;&#19981;&#21516;&#39046;&#22495;&#29305;&#23450;&#38382;&#39064;&#26102;&#65292;&#20986;&#29616;&#20102;&#27867;&#21270;&#33021;&#21147;&#24046;&#30340;&#38382;&#39064;&#65292;&#23548;&#33268;&#33719;&#21462;&#19981;&#27491;&#30830;&#30340;&#25991;&#26723;&#25110;&#20570;&#20986;&#19981;&#20934;&#30830;&#30340;&#21028;&#26029;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#21307;&#23398;&#25991;&#26412;&#26694;&#26550;Self-BioRAG&#65292;&#19987;&#38376;&#29992;&#20110;&#29983;&#25104;&#35299;&#37322;&#12289;&#26816;&#32034;&#39046;&#22495;&#29305;&#23450;&#25991;&#26723;&#21644;&#33258;&#25105;&#21453;&#24605;&#29983;&#25104;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;84k&#20010;&#32463;&#36807;&#36807;&#28388;&#30340;&#29983;&#29289;&#21307;&#23398;&#25351;&#20196;&#38598;&#26469;&#35757;&#32451;Self-BioRAG&#65292;&#23427;&#20855;&#22791;&#35780;&#20272;&#33258;&#24049;&#30340;&#22522;&#22240;
&lt;/p&gt;
&lt;p&gt;
Recent proprietary large language models (LLMs), such as GPT-4, have achieved a milestone in tackling diverse challenges in the biomedical domain, ranging from multiple-choice questions to long-form generations. To address challenges that still cannot be handled with the encoded knowledge of LLMs, various retrieval-augmented generation (RAG) methods have been developed by searching documents from the knowledge corpus and appending them unconditionally or selectively to the input of LLMs for generation. However, when applying existing methods to different domain-specific problems, poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments. In this paper, we introduce Self-BioRAG, a framework reliable for biomedical text that specializes in generating explanations, retrieving domain-specific documents, and self-reflecting generated responses. We utilize 84k filtered biomedical instruction sets to train Self-BioRAG that can assess its gene
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20986;&#20102;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#20004;&#31181;&#27169;&#22411;&#33539;&#24335;&#65292;&#24635;&#32467;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24378;&#35843;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2305.19860</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Large Language Models for Recommendation. (arXiv:2305.19860v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20986;&#20102;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#20004;&#31181;&#27169;&#22411;&#33539;&#24335;&#65292;&#24635;&#32467;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24378;&#35843;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#24182;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#24341;&#36215;&#20102;&#37325;&#35270;&#12290;&#36825;&#20123;&#27169;&#22411;&#20351;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#28023;&#37327;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#24050;&#22312;&#23398;&#20064;&#36890;&#29992;&#34920;&#31034;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#30528;&#25104;&#21151;&#65292;&#24182;&#26377;&#21487;&#33021;&#36890;&#36807;&#19968;&#20123;&#26377;&#25928;&#30340;&#36716;&#31227;&#25216;&#26415;&#65288;&#22914;&#24494;&#35843;&#21644;&#25552;&#31034;&#35843;&#25972;&#65289;&#31561;&#25163;&#27573;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#21508;&#20010;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#25512;&#33616;&#36136;&#37327;&#30340;&#20851;&#38190;&#26159;&#21033;&#29992;&#23427;&#20204;&#39640;&#36136;&#37327;&#30340;&#25991;&#26412;&#29305;&#24449;&#34920;&#31034;&#21644;&#22823;&#37327;&#30340;&#22806;&#37096;&#30693;&#35782;&#35206;&#30422;&#65292;&#24314;&#31435;&#39033;&#30446;&#21644;&#29992;&#25143;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#20102;&#20840;&#38754;&#20102;&#35299;&#29616;&#26377;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#26412;&#32508;&#36848;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#20998;&#20026;&#20004;&#31181;&#20027;&#35201;&#33539;&#24335;&#65292;&#20998;&#21035;&#26159;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#36825;&#20123;&#33539;&#24335;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#24378;&#35843;&#20102;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#24320;&#25918;&#24615;&#30740;&#31350;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have emerged as powerful tools in the field of Natural Language Processing (NLP) and have recently gained significant attention in the domain of Recommendation Systems (RS). These models, trained on massive amounts of data using self-supervised learning, have demonstrated remarkable success in learning universal representations and have the potential to enhance various aspects of recommendation systems by some effective transfer techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect of harnessing the power of language models in enhancing recommendation quality is the utilization of their high-quality representations of textual features and their extensive coverage of external knowledge to establish correlations between items and users. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey presents a taxonomy that categorizes these models into two major paradigms, respectively Discrimi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#24341;&#23548;&#30340;Federated Recommendation&#20010;&#24615;&#21270;&#26694;&#26550;&#65288;GPFedRec&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#22270;&#32467;&#26500;&#26469;&#22686;&#24378;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#21327;&#20316;&#65292;&#21487;&#20197;&#21516;&#26102;&#20351;&#29992;&#20849;&#20139;&#21644;&#20010;&#24615;&#21270;&#30340;&#20449;&#24687;&#65292;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2305.07866</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#24341;&#23548;&#30340;Federated Recommendation&#20010;&#24615;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Graph-guided Personalization for Federated Recommendation. (arXiv:2305.07866v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#24341;&#23548;&#30340;Federated Recommendation&#20010;&#24615;&#21270;&#26694;&#26550;&#65288;GPFedRec&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#22270;&#32467;&#26500;&#26469;&#22686;&#24378;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#21327;&#20316;&#65292;&#21487;&#20197;&#21516;&#26102;&#20351;&#29992;&#20849;&#20139;&#21644;&#20010;&#24615;&#21270;&#30340;&#20449;&#24687;&#65292;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Federated Recommendation&#26159;&#19968;&#31181;&#26032;&#30340;&#26381;&#21153;&#26550;&#26500;&#65292;&#21487;&#20197;&#22312;&#19981;&#19982;&#26381;&#21153;&#22120;&#20849;&#20139;&#29992;&#25143;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#25512;&#33616;&#12290;&#29616;&#26377;&#26041;&#27861;&#22312;&#27599;&#20010;&#23458;&#25143;&#31471;&#19978;&#37096;&#32626;&#25512;&#33616;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#21516;&#27493;&#21644;&#32858;&#21512;&#39033;&#30446;&#23884;&#20837;&#26469;&#21327;&#35843;&#23427;&#20204;&#30340;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29992;&#25143;&#36890;&#24120;&#23545;&#26576;&#20123;&#39033;&#30446;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#20559;&#22909;&#65292;&#36825;&#20123;&#26041;&#27861;&#20250;&#26080;&#24046;&#21035;&#22320;&#32858;&#21512;&#26469;&#33258;&#25152;&#26377;&#23458;&#25143;&#31471;&#30340;&#39033;&#30446;&#23884;&#20837;&#65292;&#20174;&#32780;&#20013;&#21644;&#20102;&#24213;&#23618;&#29992;&#25143;&#29305;&#23450;&#30340;&#20559;&#22909;&#12290;&#36825;&#31181;&#24573;&#35270;&#23558;&#20351;&#24471;&#32858;&#21512;&#23884;&#20837;&#21464;&#24471;&#19981;&#22826;&#20855;&#26377;&#21306;&#20998;&#24615;&#65292;&#24182;&#38459;&#30861;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22270;&#24341;&#23548;&#30340;Federated Recommendation&#20010;&#24615;&#21270;&#26694;&#26550;&#65288;GPFedRec&#65289;&#12290;GPFedRec&#36890;&#36807;&#21033;&#29992;&#33258;&#36866;&#24212;&#22270;&#32467;&#26500;&#26469;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#30340;&#30456;&#20851;&#24615;&#65292;&#22686;&#24378;&#20102;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#21327;&#20316;&#12290;&#27492;&#22806;&#65292;&#23427;&#23558;&#23458;&#25143;&#31471;&#30340;&#35757;&#32451;&#36807;&#31243;&#21046;&#23450;&#20026;&#32479;&#19968;&#30340;&#32852;&#37030;&#20248;&#21270;&#26694;&#26550;&#65292;&#20854;&#20013;&#27169;&#22411;&#21487;&#20197;&#21516;&#26102;&#20351;&#29992;&#20849;&#20139;&#21644;&#20010;&#24615;&#21270;&#30340;&#20449;&#24687;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;GPFedRec&#22312;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#21516;&#26102;&#65292;&#22312;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Recommendation is a new service architecture providing recommendations without sharing user data with the server. Existing methods deploy a recommendation model on each client and coordinate their training by synchronizing and aggregating item embeddings. However, while users usually hold diverse preferences toward certain items, these methods indiscriminately aggregate item embeddings from all clients, neutralizing underlying user-specific preferences. Such neglect will leave the aggregated embedding less discriminative and hinder personalized recommendations. This paper proposes a novel Graph-guided Personalization framework (GPFedRec) for the federated recommendation. The GPFedRec enhances cross-client collaboration by leveraging an adaptive graph structure to capture the correlation of user preferences. Besides, it guides training processes on clients by formulating them into a unified federated optimization framework, where models can simultaneously use shared and person
&lt;/p&gt;</description></item></channel></rss>