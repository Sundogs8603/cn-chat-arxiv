<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>CoProver&#26159;&#19968;&#31181;&#35777;&#26126;&#26500;&#36896;&#25512;&#33616;&#31995;&#32479;&#65292;&#33021;&#22815;&#20174;&#35777;&#26126;&#26500;&#36896;&#36807;&#31243;&#20013;&#30340;&#36807;&#21435;&#25805;&#20316;&#20013;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#25506;&#32034;&#23384;&#20648;&#22312;ITP&#20013;&#30340;&#20851;&#20110;&#20197;&#21069;&#35777;&#26126;&#30340;&#30693;&#35782;&#26469;&#25552;&#20379;&#26377;&#29992;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2304.10486</link><description>&lt;p&gt;
CoProver: &#19968;&#31181;&#35777;&#26126;&#26500;&#36896;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
CoProver: A Recommender System for Proof Construction. (arXiv:2304.10486v1 [cs.LO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10486
&lt;/p&gt;
&lt;p&gt;
CoProver&#26159;&#19968;&#31181;&#35777;&#26126;&#26500;&#36896;&#25512;&#33616;&#31995;&#32479;&#65292;&#33021;&#22815;&#20174;&#35777;&#26126;&#26500;&#36896;&#36807;&#31243;&#20013;&#30340;&#36807;&#21435;&#25805;&#20316;&#20013;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#25506;&#32034;&#23384;&#20648;&#22312;ITP&#20013;&#30340;&#20851;&#20110;&#20197;&#21069;&#35777;&#26126;&#30340;&#30693;&#35782;&#26469;&#25552;&#20379;&#26377;&#29992;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#20114;&#24335;&#23450;&#29702;&#35777;&#26126;&#24037;&#20855;(ITPs)&#26159;&#24418;&#24335;&#21270;&#26041;&#27861;&#19987;&#23478;&#24037;&#20855;&#24211;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#19968;&#37096;&#20998;, &#29992;&#20110;&#26500;&#24314;&#21644;(&#24418;&#24335;)&#39564;&#35777;&#35777;&#26126;. &#35777;&#26126;&#30340;&#22797;&#26434;&#24615;&#21644;&#36890;&#24120;&#38656;&#35201;&#30340;&#19987;&#19994;&#27700;&#24179;&#24448;&#24448;&#20250;&#38459;&#30861;ITPs&#30340;&#37319;&#29992;. &#26368;&#36817;&#30340;&#19968;&#31995;&#21015;&#24037;&#20316;&#30740;&#31350;&#20102;&#23558;&#22522;&#20110;ITP&#29992;&#25143;&#27963;&#21160;&#36319;&#36394;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20316;&#20026;&#23454;&#29616;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#21487;&#34892;&#36884;&#24452;&#30340;&#26041;&#27861;. &#34429;&#28982;&#36825;&#26159;&#19968;&#26465;&#26377;&#20215;&#20540;&#30340;&#30740;&#31350;&#32447;, &#20294;&#20173;&#28982;&#26377;&#35768;&#22810;&#38382;&#39064;&#38656;&#35201;&#20154;&#31867;&#30340;&#30417;&#30563;&#25165;&#33021;&#23436;&#20840;&#23436;&#25104;&#65292;&#22240;&#27492;&#23558;&#23398;&#20064;&#26041;&#27861;&#24212;&#29992;&#20110;&#21327;&#21161;&#29992;&#25143;&#25552;&#20379;&#26377;&#29992;&#24314;&#35758;&#21487;&#33021;&#26356;&#20026;&#26377;&#30410;&#12290;&#36319;&#38543;&#29992;&#25143;&#21327;&#21161;&#30340;&#24605;&#36335;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;CoProver&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;transformers&#30340;&#35777;&#26126;&#25512;&#33616;&#31995;&#32479;&#65292;&#33021;&#22815;&#20174;&#35777;&#26126;&#26500;&#36896;&#36807;&#31243;&#20013;&#30340;&#36807;&#21435;&#25805;&#20316;&#20013;&#23398;&#20064;&#65292;&#21516;&#26102;&#25506;&#32034;&#23384;&#20648;&#22312;ITP&#20013;&#30340;&#20851;&#20110;&#20197;&#21069;&#35777;&#26126;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interactive Theorem Provers (ITPs) are an indispensable tool in the arsenal of formal method experts as a platform for construction and (formal) verification of proofs. The complexity of the proofs in conjunction with the level of expertise typically required for the process to succeed can often hinder the adoption of ITPs. A recent strain of work has investigated methods to incorporate machine learning models trained on ITP user activity traces as a viable path towards full automation. While a valuable line of investigation, many problems still require human supervision to be completed fully, thus applying learning methods to assist the user with useful recommendations can prove more fruitful.  Following the vein of user assistance, we introduce CoProver, a proof recommender system based on transformers, capable of learning from past actions during proof construction, all while exploring knowledge stored in the ITP concerning previous proofs. CoProver employs a neurally learnt sequenc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;SARF&#65292;&#36890;&#36807;&#21033;&#29992;&#21516;&#20041;&#20851;&#31995;&#36741;&#21161;&#25552;&#39640;&#20102;&#23569;&#26679;&#26412;&#20851;&#31995;&#25512;&#29702;&#30340;&#27867;&#21270;&#24615;&#33021;&#21644;&#20934;&#30830;&#24615;&#65292;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#36229;&#36234;&#20102;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.10297</link><description>&lt;p&gt;
SARF: &#21033;&#29992;&#21516;&#20041;&#20851;&#31995;&#36741;&#21161;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#20197;&#36827;&#34892;&#23569;&#26679;&#26412;&#20851;&#31995;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
SARF: Aliasing Relation Assisted Self-Supervised Learning for Few-shot Relation Reasoning. (arXiv:2304.10297v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10297
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;SARF&#65292;&#36890;&#36807;&#21033;&#29992;&#21516;&#20041;&#20851;&#31995;&#36741;&#21161;&#25552;&#39640;&#20102;&#23569;&#26679;&#26412;&#20851;&#31995;&#25512;&#29702;&#30340;&#27867;&#21270;&#24615;&#33021;&#21644;&#20934;&#30830;&#24615;&#65292;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#36229;&#36234;&#20102;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#20013;&#38024;&#23545;&#23569;&#37327;&#25968;&#25454;&#12289;&#38271;&#23614;&#30340;&#20851;&#31995;&#25512;&#29702;&#65288;FS-KGR&#65289;&#36817;&#24180;&#26469;&#22240;&#20854;&#23454;&#29992;&#24615;&#32780;&#22791;&#21463;&#20851;&#27880;&#12290;&#20043;&#21069;&#30340;&#26041;&#27861;&#38656;&#35201;&#25163;&#21160;&#26500;&#24314;&#20803;&#20851;&#31995;&#38598;&#26469;&#39044;&#35757;&#32451;&#65292;&#23548;&#33268;&#20102;&#22823;&#37327;&#30340;&#21171;&#21160;&#25104;&#26412;&#12290;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#34987;&#35270;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#26696;&#65292;&#20294;&#22312;FS-KGR&#20219;&#21153;&#20013;&#20173;&#22788;&#20110;&#26089;&#26399;&#38454;&#27573;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#24573;&#30053;&#20102;&#21033;&#29992;&#19982;&#30446;&#26631;&#25968;&#25454;&#31232;&#23569;&#20851;&#31995;&#20855;&#26377;&#31867;&#20284;&#19978;&#19979;&#25991;&#35821;&#20041;&#30340;&#21516;&#20041;&#20851;&#31995;&#65288;AR&#65289;&#30340;&#26377;&#30410;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21516;&#20041;&#20851;&#31995;&#36741;&#21161;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#21629;&#21517;&#20026;SARF&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#35774;&#35745;&#20102;&#22235;&#20010;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#21363;SSL&#25512;&#29702;&#27169;&#22359;&#12289;AR&#36741;&#21161;&#26426;&#21046;&#12289;&#34701;&#21512;&#27169;&#22359;&#21644;&#35780;&#20998;&#20989;&#25968;&#12290;&#25105;&#20204;&#39318;&#20808;&#20197;&#29983;&#25104;&#24335;&#30340;&#26041;&#24335;&#29983;&#25104;&#20849;&#29616;&#27169;&#24335;&#30340;&#34920;&#31034;&#65292;&#21516;&#26102;&#35774;&#35745;AR&#36741;&#21161;&#26426;&#21046;&#26469;&#25429;&#25417;&#25968;&#25454;&#31232;&#23569;&#20851;&#31995;&#30340;&#30456;&#20284;&#19978;&#19979;&#25991;&#35821;&#20041;&#12290;&#28982;&#21518;&#65292;&#36825;&#20004;&#20010;&#34920;&#31034;&#34987;&#34701;&#21512;&#36215;&#26469;&#29983;&#25104;&#32508;&#21512;&#29305;&#24449;&#34920;&#31034;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#37319;&#29992;&#35780;&#20998;&#20989;&#25968;&#26469;&#39044;&#27979;&#22522;&#20110;&#27492;&#29305;&#24449;&#34920;&#31034;&#30340;&#30446;&#26631;&#20851;&#31995;&#12290;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#22522;&#20934;&#27979;&#35797;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;SARF&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Few-shot relation reasoning on knowledge graphs (FS-KGR) aims to infer long-tail data-poor relations, which has drawn increasing attention these years due to its practicalities. The pre-training of previous methods needs to manually construct the meta-relation set, leading to numerous labor costs. Self-supervised learning (SSL) is treated as a solution to tackle the issue, but still at an early stage for FS-KGR task. Moreover, most of the existing methods ignore leveraging the beneficial information from aliasing relations (AR), i.e., data-rich relations with similar contextual semantics to the target data-poor relation. Therefore, we proposed a novel Self-Supervised Learning model by leveraging Aliasing Relations to assist FS-KGR, termed SARF. Concretely, four main components are designed in our model, i.e., SSL reasoning module, AR-assisted mechanism, fusion module, and scoring function. We first generate the representation of the co-occurrence patterns in a generative manner. Meanwh
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Z&#24418;&#26354;&#32447;&#30340;&#20107;&#20214;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#39640;&#25928;&#25506;&#32034;&#27773;&#36710;&#25968;&#25454;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#22788;&#29702;&#22823;&#22411;&#36710;&#38431;&#30340;&#38750;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#20351;&#33258;&#21160;&#39550;&#39542;&#36719;&#20214;&#26356;&#22909;&#22320;&#25484;&#25569;&#29616;&#23454;&#22330;&#26223;&#19979;&#30340;&#39550;&#39542;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.10232</link><description>&lt;p&gt;
&#22522;&#20110;Z&#24418;&#26354;&#32447;&#30340;&#20107;&#20214;&#26816;&#32034;&#26041;&#27861;&#22312;&#39640;&#25928;&#25506;&#32034;&#27773;&#36710;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
ZEBRA: Z-order Curve-based Event Retrieval Approach to Efficiently Explore Automotive Data. (arXiv:2304.10232v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Z&#24418;&#26354;&#32447;&#30340;&#20107;&#20214;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#39640;&#25928;&#25506;&#32034;&#27773;&#36710;&#25968;&#25454;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#22788;&#29702;&#22823;&#22411;&#36710;&#38431;&#30340;&#38750;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#20351;&#33258;&#21160;&#39550;&#39542;&#36719;&#20214;&#26356;&#22909;&#22320;&#25484;&#25569;&#29616;&#23454;&#22330;&#26223;&#19979;&#30340;&#39550;&#39542;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#33258;&#21160;&#39550;&#39542;&#36719;&#20214;&#30340;&#24615;&#33021;&#20027;&#35201;&#30001;&#29616;&#23454;&#19990;&#30028;&#25910;&#38598;&#30340;&#25968;&#25454;&#39537;&#21160;&#12290;&#34429;&#28982;&#19987;&#19994;&#27979;&#35797;&#39550;&#39542;&#21592;&#24471;&#21040;&#25216;&#26415;&#25903;&#25345;&#26469;&#21322;&#33258;&#21160;&#22320;&#27880;&#37322;&#39550;&#39542;&#25805;&#20316;&#65292;&#26356;&#22909;&#22320;&#35782;&#21035;&#20107;&#20214;&#65292;&#20294;&#26159;&#22823;&#22411;&#36710;&#38431;&#20013;&#30340;&#31616;&#21333;&#25968;&#25454;&#35760;&#24405;&#22120;&#36890;&#24120;&#32570;&#20047;&#33258;&#21160;&#21644;&#35814;&#32454;&#30340;&#20107;&#20214;&#20998;&#31867;&#65292;&#22240;&#27492;&#38656;&#35201;&#39069;&#22806;&#30340;&#21518;&#22788;&#29702;&#24037;&#20316;&#12290;&#28982;&#32780;&#65292;&#19987;&#19994;&#27979;&#35797;&#39550;&#39542;&#21592;&#30340;&#25968;&#25454;&#36136;&#37327;&#26174;&#28982;&#27604;&#32570;&#23569;&#26631;&#31614;&#30340;&#22823;&#22411;&#36710;&#38431;&#26356;&#39640;&#65292;&#20294;&#22823;&#22411;&#36710;&#38431;&#30340;&#38750;&#27880;&#37322;&#25968;&#25454;&#38598;&#26356;&#20855;&#26377;&#20195;&#34920;&#24615;&#65292;&#21487;&#29992;&#20110;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#22788;&#29702;&#30340;&#20856;&#22411;&#12289;&#29616;&#23454;&#30340;&#39550;&#39542;&#24773;&#26223;&#12290;&#20294;&#26159;&#65292;&#22312;&#21518;&#22788;&#29702;&#26399;&#38388;&#28155;&#21152;&#26377;&#20215;&#20540;&#30340;&#27880;&#37322;&#36234;&#26469;&#36234;&#26114;&#36149;&#65292;&#34429;&#28982;&#25193;&#22823;&#22823;&#22411;&#36710;&#38431;&#30340;&#25968;&#25454;&#30456;&#23545;&#36739;&#31616;&#21333;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;Z&#24418;&#31354;&#38388;&#22635;&#20805;&#26354;&#32447;&#31995;&#32479;&#22320;&#20943;&#23569;&#25968;&#25454;&#32500;&#25968;&#65292;
&lt;/p&gt;
&lt;p&gt;
Evaluating the performance of software for automated vehicles is predominantly driven by data collected from the real world. While professional test drivers are supported with technical means to semi-automatically annotate driving maneuvers to allow better event identification, simple data loggers in large vehicle fleets typically lack automatic and detailed event classification and hence, extra effort is needed when post-processing such data. Yet, the data quality from professional test drivers is apparently higher than the one from large fleets where labels are missing, but the non-annotated data set from large vehicle fleets is much more representative for typical, realistic driving scenarios to be handled by automated vehicles. However, while growing the data from large fleets is relatively simple, adding valuable annotations during post-processing has become increasingly expensive. In this paper, we leverage Z-order space-filling curves to systematically reduce data dimensionality
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27573;&#33853;&#26816;&#32034;&#20013;&#37319;&#29992;&#22522;&#20110;&#25991;&#26412;&#19987;&#23478;&#28151;&#21512;&#30340;&#19978;&#19979;&#25991;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#39044;&#35757;&#32451;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#25913;&#36827;&#23884;&#20837;&#31354;&#38388;&#30340;&#21028;&#21035;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.10195</link><description>&lt;p&gt;
CoT-MoTE&#65306;&#25506;&#32034;&#22522;&#20110;&#25991;&#26412;&#19987;&#23478;&#28151;&#21512;&#30340;&#19978;&#19979;&#25991;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#39044;&#35757;&#32451;&#22312;&#27573;&#33853;&#26816;&#32034;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
CoT-MoTE: Exploring ConTextual Masked Auto-Encoder Pre-training with Mixture-of-Textual-Experts for Passage Retrieval. (arXiv:2304.10195v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10195
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27573;&#33853;&#26816;&#32034;&#20013;&#37319;&#29992;&#22522;&#20110;&#25991;&#26412;&#19987;&#23478;&#28151;&#21512;&#30340;&#19978;&#19979;&#25991;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#39044;&#35757;&#32451;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#25913;&#36827;&#23884;&#20837;&#31354;&#38388;&#30340;&#21028;&#21035;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27573;&#33853;&#26816;&#32034;&#26088;&#22312;&#20174;&#22823;&#35268;&#27169;&#24320;&#25918;&#24335;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#30456;&#20851;&#27573;&#33853;&#12290;&#19978;&#19979;&#25991;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#22312;&#21333;&#20307;&#21452;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#29942;&#39048;&#39044;&#35757;&#32451;&#20013;&#35777;&#26126;&#26377;&#25928;&#65292;&#24182;&#24120;&#24120;&#34987;&#37319;&#29992;&#20026;&#22522;&#26412;&#30340;&#26816;&#32034;&#26550;&#26500;&#65292;&#22312;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#38454;&#27573;&#20013;&#23558;&#26597;&#35810;&#21644;&#27573;&#33853;&#32534;&#30721;&#20026;&#23427;&#20204;&#30340;&#28508;&#22312;&#23884;&#20837;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#31616;&#21333;&#22320;&#20849;&#20139;&#25110;&#20998;&#31163;&#21452;&#32534;&#30721;&#22120;&#30340;&#21442;&#25968;&#20250;&#23548;&#33268;&#23884;&#20837;&#31354;&#38388;&#30340;&#19981;&#24179;&#34913;&#21028;&#21035;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#20808;&#35757;&#32451;&#20855;&#26377;&#25991;&#26412;&#19987;&#23478;&#28151;&#21512;&#30340;&#19978;&#19979;&#25991;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#65288;CoT-MoTE&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20026;&#26597;&#35810;&#21644;&#27573;&#33853;&#30340;&#19981;&#21516;&#23646;&#24615;&#20998;&#21035;&#32534;&#30721;&#25991;&#26412;&#29305;&#23450;&#30340;&#19987;&#23478;&#12290;&#21516;&#26102;&#65292;&#20173;&#20445;&#30041;&#19968;&#20010;&#20849;&#20139;&#30340;&#33258;&#25105;&#27880;&#24847;&#23618;&#65292;&#29992;&#20110;&#32479;&#19968;&#30340;&#27880;&#24847;&#24314;&#27169;&#12290;&#23545;&#22823;&#35268;&#27169;&#27573;&#33853;&#26816;&#32034;&#22522;&#20934;&#27979;&#35797;&#30340;&#32467;&#26524;&#26174;&#31034;&#31283;&#23450;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Passage retrieval aims to retrieve relevant passages from large collections of the open-domain corpus. Contextual Masked Auto-Encoding has been proven effective in representation bottleneck pre-training of a monolithic dual-encoder for passage retrieval. Siamese or fully separated dual-encoders are often adopted as basic retrieval architecture in the pre-training and fine-tuning stages for encoding queries and passages into their latent embedding spaces. However, simply sharing or separating the parameters of the dual-encoder results in an imbalanced discrimination of the embedding spaces. In this work, we propose to pre-train Contextual Masked Auto-Encoder with Mixture-of-Textual-Experts (CoT-MoTE). Specifically, we incorporate textual-specific experts for individually encoding the distinct properties of queries and passages. Meanwhile, a shared self-attention layer is still kept for unified attention modeling. Results on large-scale passage retrieval benchmarks show steady improvemen
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#39046;&#22495;&#24191;&#27867;&#20351;&#29992;&#30340;ChatGPT&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#21363;&#20351;&#27809;&#26377;&#24494;&#35843;&#65292;ChatGPT&#22312;&#20116;&#20010;&#25512;&#33616;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#25512;&#33616;&#31934;&#24230;&#21644;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.10149</link><description>&lt;p&gt;
ChatGPT&#26159;&#19968;&#20010;&#22909;&#30340;&#25512;&#33616;&#31639;&#27861;&#21527;&#65311;&#21021;&#27493;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Is ChatGPT a Good Recommender? A Preliminary Study. (arXiv:2304.10149v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10149
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#39046;&#22495;&#24191;&#27867;&#20351;&#29992;&#30340;ChatGPT&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#21363;&#20351;&#27809;&#26377;&#24494;&#35843;&#65292;ChatGPT&#22312;&#20116;&#20010;&#25512;&#33616;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#25512;&#33616;&#31934;&#24230;&#21644;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#24182;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20256;&#32479;&#25512;&#33616;&#26041;&#27861;&#37117;&#26159;&#29305;&#23450;&#20219;&#21153;&#30340;&#65292;&#22240;&#27492;&#32570;&#20047;&#26377;&#25928;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#26368;&#36817;&#65292;ChatGPT&#30340;&#20986;&#29616;&#36890;&#36807;&#22686;&#24378;&#23545;&#35805;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#26174;&#33879;&#25512;&#36827;&#20102;NLP&#20219;&#21153;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;ChatGPT&#22312;&#25512;&#33616;&#39046;&#22495;&#30340;&#24212;&#29992;&#36824;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#30340;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;ChatGPT&#20316;&#20026;&#36890;&#29992;&#25512;&#33616;&#27169;&#22411;&#65292;&#25506;&#35752;&#23427;&#23558;&#20174;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#33719;&#24471;&#30340;&#24191;&#27867;&#35821;&#35328;&#21644;&#19990;&#30028;&#30693;&#35782;&#36716;&#31227;&#21040;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#28508;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#32452;&#25552;&#31034;&#65292;&#24182;&#35780;&#20272;ChatGPT&#22312;&#20116;&#20010;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#34920;&#29616;&#12290;&#19982;&#20256;&#32479;&#30340;&#25512;&#33616;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#22312;&#25972;&#20010;&#35780;&#20272;&#36807;&#31243;&#20013;&#25105;&#20204;&#19981;&#24494;&#35843;ChatGPT&#65292;&#20165;&#20381;&#38752;&#25552;&#31034;&#33258;&#36523;&#23558;&#25512;&#33616;&#20219;&#21153;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems have witnessed significant advancements and have been widely used over the past decades. However, most traditional recommendation methods are task-specific and therefore lack efficient generalization ability. Recently, the emergence of ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of conversational models. Nonetheless, the application of ChatGPT in the recommendation domain has not been thoroughly investigated. In this paper, we employ ChatGPT as a general-purpose recommendation model to explore its potential for transferring extensive linguistic and world knowledge acquired from large-scale corpora to recommendation scenarios. Specifically, we design a set of prompts and evaluate ChatGPT's performance on five recommendation scenarios. Unlike traditional recommendation methods, we do not fine-tune ChatGPT during the entire evaluation process, relying only on the prompts themselves to convert recommendation tasks into natural language 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20197;Booking.com&#20026;&#22522;&#30784;&#65292;&#20197;&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#20026;&#30740;&#31350;&#65292;&#23637;&#31034;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#28040;&#36153;&#32773;&#20010;&#20154;&#25968;&#25454;&#65292;&#24182;&#35752;&#35770;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#26412;&#26696;&#20363;&#30740;&#31350;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2304.09603</link><description>&lt;p&gt;
&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#65306;&#20197;Booking.com&#20026;&#20363;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Visualising Personal Data Flows: Insights from a Case Study of Booking.com. (arXiv:2304.09603v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;Booking.com&#20026;&#22522;&#30784;&#65292;&#20197;&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#20026;&#30740;&#31350;&#65292;&#23637;&#31034;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#28040;&#36153;&#32773;&#20010;&#20154;&#25968;&#25454;&#65292;&#24182;&#35752;&#35770;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#26412;&#26696;&#20363;&#30740;&#31350;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21830;&#19994;&#26426;&#26500;&#25345;&#26377;&#21644;&#22788;&#29702;&#30340;&#20010;&#20154;&#25968;&#25454;&#37327;&#36234;&#26469;&#36234;&#22810;&#12290;&#25919;&#31574;&#21644;&#27861;&#24459;&#19981;&#26029;&#21464;&#21270;&#65292;&#35201;&#27714;&#36825;&#20123;&#20844;&#21496;&#22312;&#25910;&#38598;&#12289;&#23384;&#20648;&#12289;&#22788;&#29702;&#21644;&#20849;&#20139;&#36825;&#20123;&#25968;&#25454;&#26041;&#38754;&#26356;&#21152;&#36879;&#26126;&#12290;&#26412;&#25991;&#25253;&#21578;&#20102;&#25105;&#20204;&#20197;Booking.com&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#20174;&#20182;&#20204;&#30340;&#38544;&#31169;&#25919;&#31574;&#20013;&#25552;&#21462;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#21487;&#35270;&#21270;&#24037;&#20316;&#12290;&#36890;&#36807;&#23637;&#31034;&#35813;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#20854;&#28040;&#36153;&#32773;&#30340;&#20010;&#20154;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38382;&#39064;&#65292;&#24182;&#25193;&#23637;&#20102;&#26377;&#20851;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#33539;&#22260;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#30340;&#35752;&#35770;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#26412;&#26696;&#20363;&#30740;&#31350;&#21487;&#20197;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#22312;&#22797;&#26434;&#21830;&#19994;&#29983;&#24577;&#31995;&#32479;&#20013;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
Commercial organisations are holding and processing an ever-increasing amount of personal data. Policies and laws are continually changing to require these companies to be more transparent regarding collection, storage, processing and sharing of this data. This paper reports our work of taking Booking.com as a case study to visualise personal data flows extracted from their privacy policy. By showcasing how the company shares its consumers' personal data, we raise questions and extend discussions on the challenges and limitations of using privacy policy to inform customers the true scale and landscape of personal data flows. More importantly, this case study can inform us about future research on more data flow-oriented privacy policy analysis and on the construction of a more comprehensive ontology on personal data flows in complicated business ecosystems.
&lt;/p&gt;</description></item></channel></rss>