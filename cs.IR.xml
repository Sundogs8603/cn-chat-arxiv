<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#21487;&#29992;&#20110;SDG&#30740;&#31350;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#26469;&#28304;&#65292;&#24182;&#20197;&#23545;SDG 7&#30456;&#20851;&#25991;&#29486;&#30340;&#20998;&#26512;&#20026;&#31034;&#20363;&#12290;&#36825;&#31181;&#26041;&#27861;&#23558;&#25163;&#21160;&#23450;&#24615;&#32534;&#30721;&#19982;&#35268;&#21017;&#24212;&#29992;&#30456;&#32467;&#21512;&#65292;&#35745;&#31639;&#21270;&#22320;&#23454;&#29616;&#20102;&#25968;&#25454;&#23454;&#20307;&#25552;&#21462;&#12290;&#26410;&#26469;&#30340;&#24037;&#20316;&#21487;&#20197;&#36890;&#36807;&#26356;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#25193;&#23637;&#35813;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.07983</link><description>&lt;p&gt;
&#25968;&#25454;&#21457;&#29616;&#19982;&#21487;&#25345;&#32493;&#21457;&#23637;&#30446;&#26631;&#65306;&#19968;&#31181;&#31995;&#32479;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Data Discovery for the SDGs: A Systematic Rule-based Approach. (arXiv:2307.07983v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#21487;&#29992;&#20110;SDG&#30740;&#31350;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#26469;&#28304;&#65292;&#24182;&#20197;&#23545;SDG 7&#30456;&#20851;&#25991;&#29486;&#30340;&#20998;&#26512;&#20026;&#31034;&#20363;&#12290;&#36825;&#31181;&#26041;&#27861;&#23558;&#25163;&#21160;&#23450;&#24615;&#32534;&#30721;&#19982;&#35268;&#21017;&#24212;&#29992;&#30456;&#32467;&#21512;&#65292;&#35745;&#31639;&#21270;&#22320;&#23454;&#29616;&#20102;&#25968;&#25454;&#23454;&#20307;&#25552;&#21462;&#12290;&#26410;&#26469;&#30340;&#24037;&#20316;&#21487;&#20197;&#36890;&#36807;&#26356;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#25193;&#23637;&#35813;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
2015&#24180;&#65292;&#32852;&#21512;&#22269;&#25552;&#20986;&#20102;17&#20010;&#21487;&#25345;&#32493;&#21457;&#23637;&#30446;&#26631;&#65288;SDGs&#65289;&#65292;&#35201;&#22312;2030&#24180;&#20043;&#21069;&#23454;&#29616;&#65292;&#22312;&#36825;&#20123;&#30446;&#26631;&#20013;&#65292;&#25968;&#25454;&#34987;&#25512;&#23815;&#20026;&#21019;&#26032;&#21487;&#25345;&#32493;&#21457;&#23637;&#21644;&#34913;&#37327;&#23454;&#29616;SDGs&#36827;&#23637;&#30340;&#25163;&#27573;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#21487;&#29992;&#20110;SDG&#30740;&#31350;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#26469;&#28304;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23558;&#31995;&#32479;&#30340;&#26144;&#23556;&#26041;&#27861;&#19982;&#25163;&#21160;&#23450;&#24615;&#32534;&#30721;&#30456;&#32467;&#21512;&#65292;&#24212;&#29992;&#35268;&#21017;&#36827;&#34892;&#35745;&#31639;&#21270;&#30340;&#25968;&#25454;&#23454;&#20307;&#25552;&#21462;&#12290;&#26412;&#25991;&#20197;&#23545;SDG 7&#30456;&#20851;&#25991;&#29486;&#30340;&#20998;&#26512;&#20026;&#31034;&#20363;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#36824;&#23545;&#35813;&#26041;&#27861;&#36827;&#34892;&#35752;&#35770;&#65292;&#24182;&#24314;&#35758;&#26410;&#26469;&#36890;&#36807;&#26356;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#25193;&#23637;&#35813;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 2015, the United Nations put forward 17 Sustainable Development Goals (SDGs) to be achieved by 2030, where data has been promoted as a focus to innovating sustainable development and as a means to measuring progress towards achieving the SDGs. In this study, we propose a systematic approach towards discovering data types and sources that can be used for SDG research. The proposed method integrates a systematic mapping approach using manual qualitative coding over a corpus of SDG-related research literature followed by an automated process that applies rules to perform data entity extraction computationally. This approach is exemplified by an analysis of literature relating to SDG 7, the results of which are also presented in this paper. The paper concludes with a discussion of the approach and suggests future work to extend the method with more advance NLP and machine learning techniques.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#24773;&#24863;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21452;&#36890;&#36947;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#24847;&#35265;&#25366;&#25496;&#65292;&#24182;&#29992;&#20110;&#25512;&#33616;&#20135;&#21697;&#12290;&#36890;&#36807;&#24212;&#29992;SMOTE&#31639;&#27861;&#22686;&#21152;&#35780;&#35770;&#25968;&#37327;&#24182;&#23545;&#25968;&#25454;&#36827;&#34892;&#24179;&#34913;&#65292;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#31639;&#27861;&#20026;&#32858;&#31867;&#20998;&#37197;&#26435;&#37325;&#65292;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.07798</link><description>&lt;p&gt;
&#20351;&#29992;&#21452;&#36890;&#36947;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25512;&#33616;&#31995;&#32479;&#30340;&#24847;&#35265;&#25366;&#25496;
&lt;/p&gt;
&lt;p&gt;
Opinion mining using Double Channel CNN for Recommender System. (arXiv:2307.07798v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07798
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#24773;&#24863;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21452;&#36890;&#36947;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#24847;&#35265;&#25366;&#25496;&#65292;&#24182;&#29992;&#20110;&#25512;&#33616;&#20135;&#21697;&#12290;&#36890;&#36807;&#24212;&#29992;SMOTE&#31639;&#27861;&#22686;&#21152;&#35780;&#35770;&#25968;&#37327;&#24182;&#23545;&#25968;&#25454;&#36827;&#34892;&#24179;&#34913;&#65292;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#31639;&#27861;&#20026;&#32858;&#31867;&#20998;&#37197;&#26435;&#37325;&#65292;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20114;&#32852;&#32593;&#21644;&#31038;&#20132;&#23186;&#20307;&#30340;&#21457;&#23637;&#65292;&#20135;&#29983;&#20102;&#22823;&#37327;&#30340;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#12290;&#36825;&#20123;&#25968;&#25454;&#20013;&#21253;&#25324;&#29992;&#25143;&#23545;&#22312;&#32447;&#21830;&#24215;&#21644;&#31038;&#20132;&#23186;&#20307;&#19978;&#20135;&#21697;&#30340;&#24847;&#35265;&#12290;&#36890;&#36807;&#23545;&#36825;&#20123;&#24847;&#35265;&#36827;&#34892;&#25506;&#32034;&#21644;&#20998;&#31867;&#65292;&#21487;&#20197;&#33719;&#21462;&#26377;&#29992;&#30340;&#20449;&#24687;&#65292;&#21253;&#25324;&#29992;&#25143;&#28385;&#24847;&#24230;&#12289;&#29992;&#25143;&#23545;&#29305;&#23450;&#20107;&#20214;&#30340;&#21453;&#39304;&#12289;&#39044;&#27979;&#29305;&#23450;&#20135;&#21697;&#30340;&#38144;&#21806;&#24773;&#20917;&#31561;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#24773;&#24863;&#20998;&#26512;&#24182;&#29992;&#20110;&#25512;&#33616;&#20135;&#21697;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#20855;&#26377;&#20116;&#23618;&#30340;&#21452;&#36890;&#36947;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#24847;&#35265;&#25366;&#25496;&#65292;&#35813;&#27169;&#22411;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#20102;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#36890;&#36807;&#24212;&#29992;SMOTE&#31639;&#27861;&#26469;&#22686;&#21152;&#21021;&#22987;&#25968;&#25454;&#38598;&#30340;&#35780;&#35770;&#25968;&#37327;&#65292;&#24182;&#23545;&#25968;&#25454;&#36827;&#34892;&#24179;&#34913;&#12290;&#28982;&#21518;&#25105;&#20204;&#23545;&#36825;&#20123;&#35780;&#35770;&#36827;&#34892;&#20102;&#32858;&#31867;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#31639;&#27861;&#20026;&#27599;&#20010;&#32858;&#31867;&#20998;&#37197;&#20102;&#19968;&#20010;&#26435;&#37325;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#24050;&#32463;&#22312;&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Much unstructured data has been produced with the growth of the Internet and social media. A significant volume of textual data includes users' opinions about products in online stores and social media. By exploring and categorizing them, helpful information can be acquired, including customer satisfaction, user feedback about a particular event, predicting the sale of a specific product, and other similar cases. In this paper, we present an approach for sentiment analysis with a deep learning model and use it to recommend products. A two-channel convolutional neural network model has been used for opinion mining, which has five layers and extracts essential features from the data. We increased the number of comments by applying the SMOTE algorithm to the initial dataset and balanced the data. Then we proceed to cluster the aspects. We also assign a weight to each cluster using tensor decomposition algorithms that improve the recommender system's performance. Our proposed method has re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#25913;&#36827;&#36861;&#36394;&#38142;&#25509;&#25512;&#33616;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#31561;&#21521;&#36317;&#31163;&#21644;&#32452;&#21512;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#38750;&#32447;&#24615;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#20174;&#20960;&#20309;&#35270;&#35282;&#25506;&#32034;&#35821;&#20041;&#30456;&#20284;&#24615;&#23545;&#20110;&#36861;&#36394;&#24615;&#30740;&#31350;&#26159;&#26377;&#24110;&#21161;&#30340;&#12290;&#20316;&#32773;&#22312;&#22810;&#20010;&#39033;&#30446;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#25351;&#20986;&#36825;&#20123;&#21457;&#29616;&#21487;&#20197;&#23545;&#20854;&#20182;&#20449;&#24687;&#26816;&#32034;&#38382;&#39064;&#36215;&#21040;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.07781</link><description>&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#38750;&#31561;&#21521;&#36317;&#31163;&#21644;&#32452;&#21512;&#25913;&#36827;&#36861;&#36394;&#38142;&#25509;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Improving Trace Link Recommendation by Using Non-Isotropic Distances and Combinations. (arXiv:2307.07781v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#25913;&#36827;&#36861;&#36394;&#38142;&#25509;&#25512;&#33616;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#31561;&#21521;&#36317;&#31163;&#21644;&#32452;&#21512;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#38750;&#32447;&#24615;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#20174;&#20960;&#20309;&#35270;&#35282;&#25506;&#32034;&#35821;&#20041;&#30456;&#20284;&#24615;&#23545;&#20110;&#36861;&#36394;&#24615;&#30740;&#31350;&#26159;&#26377;&#24110;&#21161;&#30340;&#12290;&#20316;&#32773;&#22312;&#22810;&#20010;&#39033;&#30446;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#25351;&#20986;&#36825;&#20123;&#21457;&#29616;&#21487;&#20197;&#23545;&#20854;&#20182;&#20449;&#24687;&#26816;&#32034;&#38382;&#39064;&#36215;&#21040;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#24320;&#21457;&#29983;&#21629;&#21608;&#26399;&#20013;&#30340;&#26500;&#20214;&#20043;&#38388;&#23384;&#22312;&#36861;&#36394;&#38142;&#25509;&#21487;&#20197;&#25552;&#39640;&#36719;&#20214;&#24320;&#21457;&#12289;&#32500;&#25252;&#21644;&#36816;&#33829;&#36807;&#31243;&#20013;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#36861;&#36394;&#38142;&#25509;&#30340;&#21019;&#24314;&#21644;&#32500;&#25252;&#32791;&#26102;&#19988;&#23481;&#26131;&#20986;&#38169;&#12290;&#36817;&#24180;&#26469;&#65292;&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#24378;&#22823;&#24037;&#20855;&#30340;&#20986;&#29616;&#65292;&#23545;&#33258;&#21160;&#35745;&#31639;&#36861;&#36394;&#38142;&#25509;&#36827;&#34892;&#30740;&#31350;&#30340;&#21162;&#21147;&#36880;&#28176;&#22686;&#21152;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#22312;&#30740;&#31350;&#29992;&#20110;&#35745;&#31639;&#36861;&#36394;&#38142;&#25509;&#30340;&#38750;&#32447;&#24615;&#30456;&#20284;&#24230;&#24230;&#37327;&#26102;&#25152;&#20570;&#30340;&#19968;&#20123;&#35266;&#23519;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#20174;&#20960;&#20309;&#35270;&#35282;&#26469;&#30475;&#24453;&#35821;&#20041;&#30456;&#20284;&#24615;&#21487;&#20197;&#26377;&#21161;&#20110;&#26410;&#26469;&#30340;&#36861;&#36394;&#24615;&#30740;&#31350;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#24320;&#28304;&#39033;&#30446;&#21644;&#20004;&#20010;&#24037;&#19994;&#39033;&#30446;&#30340;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#35266;&#23519;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25351;&#20986;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#26356;&#20855;&#26222;&#36941;&#24615;&#65292;&#20063;&#21487;&#20197;&#20026;&#20854;&#20182;&#20449;&#24687;&#26816;&#32034;&#38382;&#39064;&#22880;&#23450;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The existence of trace links between artifacts of the software development life cycle can improve the efficiency of many activities during software development, maintenance and operations. Unfortunately, the creation and maintenance of trace links is time-consuming and error-prone. Research efforts have been spent to automatically compute trace links and lately gained momentum, e.g., due to the availability of powerful tools in the area of natural language processing. In this paper, we report on some observations that we made during studying non-linear similarity measures for computing trace links. We argue, that taking a geometric viewpoint on semantic similarity can be helpful for future traceability research. We evaluated our observations on a dataset of four open source projects and two industrial projects. We furthermore point out that our findings are more general and can build the basis for other information retrieval problems as well.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20351;&#29992;CNN-LSTM&#27169;&#22411;&#23545;&#27874;&#26031;&#25512;&#29305;&#30340;&#25919;&#27835;&#24773;&#24863;&#36827;&#34892;&#20998;&#26512;&#65292;&#20351;&#29992;ParsBERT&#36827;&#34892;&#35789;&#27719;&#34920;&#31034;&#65292;&#24182;&#27604;&#36739;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#26524;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#65292;&#20854;&#20013;CNN-LSTM&#27169;&#22411;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#20998;&#21035;&#36798;&#21040;&#20102;89%&#21644;71%&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.07740</link><description>&lt;p&gt;
&#20351;&#29992;CNN-LSTM&#27169;&#22411;&#23545;&#27874;&#26031;&#25512;&#29305;&#30340;&#25919;&#27835;&#24773;&#24863;&#36827;&#34892;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model. (arXiv:2307.07740v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07740
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20351;&#29992;CNN-LSTM&#27169;&#22411;&#23545;&#27874;&#26031;&#25512;&#29305;&#30340;&#25919;&#27835;&#24773;&#24863;&#36827;&#34892;&#20998;&#26512;&#65292;&#20351;&#29992;ParsBERT&#36827;&#34892;&#35789;&#27719;&#34920;&#31034;&#65292;&#24182;&#27604;&#36739;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#26524;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#65292;&#20854;&#20013;CNN-LSTM&#27169;&#22411;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#20998;&#21035;&#36798;&#21040;&#20102;89%&#21644;71%&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#24863;&#20998;&#26512;&#26159;&#35782;&#21035;&#21644;&#20998;&#31867;&#20154;&#20204;&#23545;&#21508;&#31181;&#35805;&#39064;&#30340;&#24773;&#24863;&#25110;&#35266;&#28857;&#30340;&#36807;&#31243;&#12290;&#36817;&#24180;&#26469;&#65292;&#23545;Twitter&#24773;&#24863;&#30340;&#20998;&#26512;&#25104;&#20026;&#19968;&#20010;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#30340;&#35805;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#27874;&#26031;&#25919;&#27835;&#25512;&#29305;&#30340;&#24773;&#24863;&#12290;&#25105;&#20204;&#20351;&#29992;&#35789;&#34955;&#27169;&#22411;&#21644;ParsBERT&#36827;&#34892;&#35789;&#27719;&#34920;&#31034;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#24212;&#29992;&#20102;&#39640;&#26031;&#26420;&#32032;&#36125;&#21494;&#26031;&#12289;&#26799;&#24230;&#25552;&#21319;&#12289;&#36923;&#36753;&#22238;&#24402;&#12289;&#20915;&#31574;&#26641;&#12289;&#38543;&#26426;&#26862;&#26519;&#20197;&#21450;CNN&#21644;LSTM&#30340;&#32452;&#21512;&#26469;&#20998;&#31867;&#25512;&#29305;&#30340;&#26497;&#24615;&#12290;&#26412;&#30740;&#31350;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;ParsBERT&#23884;&#20837;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#27604;&#26426;&#22120;&#23398;&#20064;&#34920;&#29616;&#26356;&#22909;&#12290;CNN-LSTM&#27169;&#22411;&#22312;&#31532;&#19968;&#20010;&#26377;&#19977;&#31181;&#31867;&#21035;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#20026;89&#65285;&#65292;&#22312;&#31532;&#20108;&#20010;&#26377;&#19971;&#31181;&#31867;&#21035;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#20026;71&#65285;&#12290;&#30001;&#20110;&#27874;&#26031;&#35821;&#30340;&#22797;&#26434;&#24615;&#65292;&#36798;&#21040;&#36825;&#19968;&#25928;&#29575;&#27700;&#24179;&#26159;&#19968;&#39033;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sentiment analysis is the process of identifying and categorizing people's emotions or opinions regarding various topics. The analysis of Twitter sentiment has become an increasingly popular topic in recent years. In this paper, we present several machine learning and a deep learning model to analysis sentiment of Persian political tweets. Our analysis was conducted using Bag of Words and ParsBERT for word representation. We applied Gaussian Naive Bayes, Gradient Boosting, Logistic Regression, Decision Trees, Random Forests, as well as a combination of CNN and LSTM to classify the polarities of tweets. The results of this study indicate that deep learning with ParsBERT embedding performs better than machine learning. The CNN-LSTM model had the highest classification accuracy with 89 percent on the first dataset with three classes and 71 percent on the second dataset with seven classes. Due to the complexity of Persian, it was a difficult task to achieve this level of efficiency.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#22810;Agent&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#21046;&#20013;&#65292;&#26368;&#31361;&#20986;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;$\epsilon$-greedy&#21487;&#20197;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#35299;&#20915;&#21516;&#26102;&#23384;&#22312;&#30340;&#28608;&#21169;&#22240;&#32032;&#12289;&#19978;&#19979;&#25991;&#21644;&#25439;&#22351;&#38382;&#39064;</title><link>http://arxiv.org/abs/2307.07675</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#33410;&#28857;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#21046;&#20013;Epoch-Greedy&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms. (arXiv:2307.07675v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07675
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#22810;Agent&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#21046;&#20013;&#65292;&#26368;&#31361;&#20986;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;$\epsilon$-greedy&#21487;&#20197;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#35299;&#20915;&#21516;&#26102;&#23384;&#22312;&#30340;&#28608;&#21169;&#22240;&#32032;&#12289;&#19978;&#19979;&#25991;&#21644;&#25439;&#22351;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20687;&#28857;&#20987;&#20184;&#36153;(Pay-Per-Click)&#25293;&#21334;&#36825;&#26679;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#21046;&#20013;&#36827;&#34892;&#39640;&#25928;&#23398;&#20064;&#36890;&#24120;&#28041;&#21450;&#19977;&#20010;&#25361;&#25112;&#65306;1)&#24341;&#23548;&#30495;&#23454;&#20986;&#20215;&#34892;&#20026;(&#28608;&#21169;&#22240;&#32032;)&#65292;2)&#22312;&#29992;&#25143;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#20013;&#20351;&#29992;&#20010;&#24615;&#21270;(&#19978;&#19979;&#25991;)&#65292;3)&#35268;&#36991;&#28857;&#20987;&#27169;&#24335;&#20013;&#30340;&#25805;&#32437;(&#25439;&#22351;&#34892;&#20026;)&#12290;&#36807;&#21435;&#25991;&#29486;&#20013;&#27599;&#20010;&#25361;&#25112;&#37117;&#34987;&#29420;&#31435;&#30740;&#31350;&#36807;&#65307;&#28608;&#21169;&#22240;&#32032;&#24050;&#22312;&#19968;&#31995;&#21015;&#30740;&#31350;&#20013;&#24471;&#21040;&#35299;&#20915;&#65292;&#19978;&#19979;&#25991;&#38382;&#39064;&#24050;&#36890;&#36807;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#24471;&#21040;&#24191;&#27867;&#35299;&#20915;&#65292;&#32780;&#25439;&#22351;&#38382;&#39064;&#21017;&#36890;&#36807;&#26368;&#36817;&#30340;&#20851;&#20110;&#20855;&#26377;&#23545;&#25239;&#24615;&#25439;&#22351;&#30340;&#36172;&#21338;&#26426;&#21046;&#24037;&#20316;&#36827;&#34892;&#35752;&#35770;&#12290;&#30001;&#20110;&#36825;&#20123;&#25361;&#25112;&#21516;&#26102;&#23384;&#22312;&#65292;&#37325;&#35201;&#30340;&#26159;&#20102;&#35299;&#27599;&#31181;&#26041;&#27861;&#22312;&#35299;&#20915;&#20854;&#20182;&#25361;&#25112;&#26102;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20379;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#25152;&#26377;&#25361;&#25112;&#30340;&#31639;&#27861;&#65292;&#24182;&#31361;&#20986;&#36825;&#31181;&#32452;&#21512;&#20013;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#31361;&#20986;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;$\epsilon$-greedy&#21487;&#20197;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#35299;&#20915;&#21516;&#26102;&#23384;&#22312;&#30340;&#28608;&#21169;&#22240;&#32032;&#12289;&#19978;&#19979;&#25991;&#21644;&#25439;&#22351;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). Each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. Since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. In this work, we show that the most prominent contextual bandit algorithm, $\epsilon$-greedy can be extended to
&lt;/p&gt;</description></item><item><title>Parmesan&#26159;&#19968;&#20010;&#21407;&#22411;&#31995;&#32479;&#65292;&#29992;&#20110;&#22312;&#19978;&#19979;&#25991;&#20013;&#25628;&#32034;&#21644;&#23450;&#20041;&#25968;&#23398;&#27010;&#24565;&#65292;&#29305;&#21035;&#20851;&#27880;&#33539;&#30068;&#35770;&#39046;&#22495;&#12290;&#35813;&#31995;&#32479;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#32452;&#20214;&#36827;&#34892;&#27010;&#24565;&#25552;&#21462;&#12289;&#20851;&#31995;&#25552;&#21462;&#12289;&#23450;&#20041;&#25552;&#21462;&#21644;&#23454;&#20307;&#38142;&#25509;&#12290;&#36890;&#36807;&#35813;&#31995;&#32479;&#30340;&#24320;&#21457;&#65292;&#21487;&#20197;&#35299;&#20915;&#29616;&#26377;&#25216;&#26415;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#33539;&#30068;&#35770;&#39046;&#22495;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20004;&#20010;&#25968;&#23398;&#35821;&#26009;&#24211;&#20197;&#25903;&#25345;&#31995;&#32479;&#30340;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.06699</link><description>&lt;p&gt;
Parmesan&#65306;&#25945;&#32946;&#20013;&#30340;&#25968;&#23398;&#27010;&#24565;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Parmesan: mathematical concept extraction for education. (arXiv:2307.06699v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06699
&lt;/p&gt;
&lt;p&gt;
Parmesan&#26159;&#19968;&#20010;&#21407;&#22411;&#31995;&#32479;&#65292;&#29992;&#20110;&#22312;&#19978;&#19979;&#25991;&#20013;&#25628;&#32034;&#21644;&#23450;&#20041;&#25968;&#23398;&#27010;&#24565;&#65292;&#29305;&#21035;&#20851;&#27880;&#33539;&#30068;&#35770;&#39046;&#22495;&#12290;&#35813;&#31995;&#32479;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#32452;&#20214;&#36827;&#34892;&#27010;&#24565;&#25552;&#21462;&#12289;&#20851;&#31995;&#25552;&#21462;&#12289;&#23450;&#20041;&#25552;&#21462;&#21644;&#23454;&#20307;&#38142;&#25509;&#12290;&#36890;&#36807;&#35813;&#31995;&#32479;&#30340;&#24320;&#21457;&#65292;&#21487;&#20197;&#35299;&#20915;&#29616;&#26377;&#25216;&#26415;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#33539;&#30068;&#35770;&#39046;&#22495;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20004;&#20010;&#25968;&#23398;&#35821;&#26009;&#24211;&#20197;&#25903;&#25345;&#31995;&#32479;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23398;&#26159;&#19968;&#20010;&#39640;&#24230;&#19987;&#19994;&#21270;&#30340;&#39046;&#22495;&#65292;&#20855;&#26377;&#33258;&#24049;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#20294;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#30740;&#31350;&#21364;&#26377;&#38480;&#12290;&#28982;&#32780;&#65292;&#25968;&#23398;&#22312;&#35768;&#22810;&#19981;&#21516;&#39046;&#22495;&#30340;&#36328;&#23398;&#31185;&#30740;&#31350;&#20013;&#32463;&#24120;&#20381;&#36182;&#20110;&#23545;&#25968;&#23398;&#27010;&#24565;&#30340;&#29702;&#35299;&#12290;&#20026;&#20102;&#24110;&#21161;&#26469;&#33258;&#20854;&#20182;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21407;&#22411;&#31995;&#32479;&#65292;&#29992;&#20110;&#22312;&#19978;&#19979;&#25991;&#20013;&#25628;&#32034;&#21644;&#23450;&#20041;&#25968;&#23398;&#27010;&#24565;&#65292;&#37325;&#28857;&#20851;&#27880;&#33539;&#30068;&#35770;&#39046;&#22495;&#12290;&#36825;&#20010;&#31995;&#32479;&#21517;&#20026;Parmesan&#65292;&#20381;&#36182;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#32452;&#20214;&#65292;&#21253;&#25324;&#27010;&#24565;&#25552;&#21462;&#12289;&#20851;&#31995;&#25552;&#21462;&#12289;&#23450;&#20041;&#25552;&#21462;&#21644;&#23454;&#20307;&#38142;&#25509;&#12290;&#22312;&#24320;&#21457;&#36825;&#20010;&#31995;&#32479;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#25216;&#26415;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#33539;&#30068;&#35770;&#39046;&#22495;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#25216;&#26415;&#65292;&#36825;&#31181;&#25216;&#26415;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#25105;&#20204;&#39044;&#35745;&#31995;&#32479;&#23558;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#19981;&#26029;&#28436;&#21464;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20004;&#20010;&#28165;&#29702;&#36807;&#30340;&#25968;&#23398;&#35821;&#26009;&#24211;&#65292;&#29992;&#20110;&#25903;&#25345;&#21407;&#22411;&#31995;&#32479;&#65292;&#36825;&#20123;&#35821;&#26009;&#24211;&#22522;&#20110;&#26399;&#21002;&#25991;&#31456;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mathematics is a highly specialized domain with its own unique set of challenges that has seen limited study in natural language processing. However, mathematics is used in a wide variety of fields and multidisciplinary research in many different domains often relies on an understanding of mathematical concepts. To aid researchers coming from other fields, we develop a prototype system for searching for and defining mathematical concepts in context, focusing on the field of category theory. This system, Parmesan, depends on natural language processing components including concept extraction, relation extraction, definition extraction, and entity linking. In developing this system, we show that existing techniques cannot be applied directly to the category theory domain, and suggest hybrid techniques that do perform well, though we expect the system to evolve over time. We also provide two cleaned mathematical corpora that power the prototype system, which are based on journal articles 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GLORY&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20840;&#23616;&#22270;&#19982;&#26412;&#22320;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26500;&#24314;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#65292;&#24182;&#32771;&#34385;&#20102;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2307.06576</link><description>&lt;p&gt;
&#36229;&#36234;&#26412;&#22320;&#33539;&#22260;&#65306;&#20840;&#29699;&#22270;&#22686;&#24378;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06576
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GLORY&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20840;&#23616;&#22270;&#19982;&#26412;&#22320;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26500;&#24314;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#65292;&#24182;&#32771;&#34385;&#20102;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#22320;&#21521;&#29992;&#25143;&#25512;&#33616;&#20505;&#36873;&#26032;&#38395;&#25991;&#31456;&#19968;&#30452;&#26159;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#30340;&#26680;&#24515;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#36817;&#26399;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20351;&#29992;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#20174;&#20016;&#23500;&#30340;&#25991;&#26412;&#25968;&#25454;&#20013;&#25552;&#21462;&#35821;&#20041;&#20449;&#24687;&#65292;&#20351;&#29992;&#20174;&#26412;&#22320;&#21382;&#21490;&#26032;&#38395;&#27966;&#29983;&#30340;&#22522;&#20110;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#32570;&#20047;&#20840;&#23616;&#35270;&#35282;&#65292;&#26410;&#33021;&#32771;&#34385;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#65292;&#36229;&#36234;&#35821;&#20041;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411; GLORY&#65288;Global-LOcal news Recommendation sYstem&#65289;&#65292;&#23427;&#32467;&#21512;&#20102;&#20174;&#20854;&#20182;&#29992;&#25143;&#23398;&#21040;&#30340;&#20840;&#23616;&#34920;&#31034;&#21644;&#26412;&#22320;&#34920;&#31034;&#65292;&#26469;&#22686;&#24378;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#20840;&#23616;&#26032;&#38395;&#22270;&#65292;&#24182;&#20351;&#29992;&#38376;&#25511;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20016;&#23500;&#26032;&#38395;&#34920;&#31034;&#65292;&#20174;&#32780;&#36890;&#36807;&#21382;&#21490;&#26032;&#38395;&#32858;&#21512;&#22120;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems. Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news. However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information. To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems. We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DWT-CompCNN&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#30452;&#25509;&#23545;&#20351;&#29992;HTJ2K&#31639;&#27861;&#21387;&#32553;&#30340;&#25991;&#26723;&#36827;&#34892;&#20998;&#31867;&#65292;&#20174;&#32780;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.01359</link><description>&lt;p&gt;
DWT-CompCNN&#65306;&#29992;&#20110;&#39640;&#21534;&#21520;&#37327;JPEG 2000&#21387;&#32553;&#25991;&#26723;&#30340;&#28145;&#24230;&#22270;&#20687;&#20998;&#31867;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
DWT-CompCNN: Deep Image Classification Network for High Throughput JPEG 2000 Compressed Documents. (arXiv:2306.01359v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01359
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DWT-CompCNN&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#30452;&#25509;&#23545;&#20351;&#29992;HTJ2K&#31639;&#27861;&#21387;&#32553;&#30340;&#25991;&#26723;&#36827;&#34892;&#20998;&#31867;&#65292;&#20174;&#32780;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20219;&#20309;&#21253;&#21547;&#25991;&#26723;&#22270;&#20687;&#30340;&#25968;&#23383;&#24212;&#29992;&#31243;&#24207;&#65292;&#22914;&#26816;&#32034;&#65292;&#25991;&#26723;&#22270;&#20687;&#30340;&#20998;&#31867;&#25104;&#20026;&#24517;&#35201;&#30340;&#38454;&#27573;&#12290;&#20256;&#32479;&#19978;&#65292;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#30340;&#65292;&#25991;&#26723;&#30340;&#23436;&#25972;&#29256;&#26412;&#65292;&#21363;&#26410;&#21387;&#32553;&#30340;&#25991;&#26723;&#22270;&#20687;&#26500;&#25104;&#36755;&#20837;&#25968;&#25454;&#38598;&#65292;&#36825;&#20250;&#22240;&#25968;&#25454;&#37327;&#22823;&#32780;&#24102;&#26469;&#23041;&#32961;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#21487;&#20197;&#20351;&#29992;&#25991;&#26723;&#30340;&#21387;&#32553;&#34920;&#31034;&#65288;&#22312;&#37096;&#20998;&#35299;&#21387;&#32553;&#30340;&#24773;&#20917;&#19979;&#65289;&#65292;&#30452;&#25509;&#23436;&#25104;&#30456;&#21516;&#30340;&#20998;&#31867;&#20219;&#21153;&#20197;&#20351;&#25972;&#20010;&#36807;&#31243;&#35745;&#31639;&#25928;&#29575;&#26356;&#39640;&#65292;&#37027;&#23558;&#20250;&#26159;&#19968;&#39033;&#21019;&#26032;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;DWT-CompCNN&#65292;&#29992;&#20110;&#20351;&#29992;&#39640;&#21534;&#21520;&#37327;JPEG 2000&#65288;HTJ2K&#65289;&#31639;&#27861;&#21387;&#32553;&#30340;&#25991;&#26723;&#30340;&#20998;&#31867;&#12290;&#25152;&#25552;&#20986;&#30340;DWT-CompCNN&#21253;&#25324;&#20116;&#20010;&#21367;&#31215;&#23618;&#65292;&#21367;&#31215;&#26680;&#22823;&#23567;&#20998;&#21035;&#20026;16&#12289;32&#12289;64&#12289;128&#21644;256&#29992;&#20110;&#20174;&#25552;&#21462;&#30340;&#23567;&#27874;&#31995;&#25968;&#20013;&#25552;&#39640;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
For any digital application with document images such as retrieval, the classification of document images becomes an essential stage. Conventionally for the purpose, the full versions of the documents, that is the uncompressed document images make the input dataset, which poses a threat due to the big volume required to accommodate the full versions of the documents. Therefore, it would be novel, if the same classification task could be accomplished directly (with some partial decompression) with the compressed representation of documents in order to make the whole process computationally more efficient. In this research work, a novel deep learning model, DWT CompCNN is proposed for classification of documents that are compressed using High Throughput JPEG 2000 (HTJ2K) algorithm. The proposed DWT-CompCNN comprises of five convolutional layers with filter sizes of 16, 32, 64, 128, and 256 consecutively for each increasing layer to improve learning from the wavelet coefficients extracted
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20197;Booking.com&#20026;&#22522;&#30784;&#65292;&#20197;&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#20026;&#30740;&#31350;&#65292;&#23637;&#31034;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#28040;&#36153;&#32773;&#20010;&#20154;&#25968;&#25454;&#65292;&#24182;&#35752;&#35770;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#26412;&#26696;&#20363;&#30740;&#31350;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2304.09603</link><description>&lt;p&gt;
&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#65306;&#20197;Booking.com&#20026;&#20363;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Visualising Personal Data Flows: Insights from a Case Study of Booking.com. (arXiv:2304.09603v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;Booking.com&#20026;&#22522;&#30784;&#65292;&#20197;&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#20026;&#30740;&#31350;&#65292;&#23637;&#31034;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#28040;&#36153;&#32773;&#20010;&#20154;&#25968;&#25454;&#65292;&#24182;&#35752;&#35770;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#26412;&#26696;&#20363;&#30740;&#31350;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21830;&#19994;&#26426;&#26500;&#25345;&#26377;&#21644;&#22788;&#29702;&#30340;&#20010;&#20154;&#25968;&#25454;&#37327;&#36234;&#26469;&#36234;&#22810;&#12290;&#25919;&#31574;&#21644;&#27861;&#24459;&#19981;&#26029;&#21464;&#21270;&#65292;&#35201;&#27714;&#36825;&#20123;&#20844;&#21496;&#22312;&#25910;&#38598;&#12289;&#23384;&#20648;&#12289;&#22788;&#29702;&#21644;&#20849;&#20139;&#36825;&#20123;&#25968;&#25454;&#26041;&#38754;&#26356;&#21152;&#36879;&#26126;&#12290;&#26412;&#25991;&#25253;&#21578;&#20102;&#25105;&#20204;&#20197;Booking.com&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#20174;&#20182;&#20204;&#30340;&#38544;&#31169;&#25919;&#31574;&#20013;&#25552;&#21462;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#21487;&#35270;&#21270;&#24037;&#20316;&#12290;&#36890;&#36807;&#23637;&#31034;&#35813;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#20854;&#28040;&#36153;&#32773;&#30340;&#20010;&#20154;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38382;&#39064;&#65292;&#24182;&#25193;&#23637;&#20102;&#26377;&#20851;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#33539;&#22260;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#30340;&#35752;&#35770;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#26412;&#26696;&#20363;&#30740;&#31350;&#21487;&#20197;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#22312;&#22797;&#26434;&#21830;&#19994;&#29983;&#24577;&#31995;&#32479;&#20013;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
Commercial organisations are holding and processing an ever-increasing amount of personal data. Policies and laws are continually changing to require these companies to be more transparent regarding collection, storage, processing and sharing of this data. This paper reports our work of taking Booking.com as a case study to visualise personal data flows extracted from their privacy policy. By showcasing how the company shares its consumers' personal data, we raise questions and extend discussions on the challenges and limitations of using privacy policy to inform customers the true scale and landscape of personal data flows. More importantly, this case study can inform us about future research on more data flow-oriented privacy policy analysis and on the construction of a more comprehensive ontology on personal data flows in complicated business ecosystems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#36793;&#30028;&#24863;&#30693;&#36741;&#21161;&#21644;&#28176;&#36827;&#35821;&#20041;&#20248;&#21270;&#30340;&#21452;&#21453;&#39304;&#27880;&#24847;&#21147;&#26694;&#26550; (DFA-BASO)&#12290;&#36890;&#36807;&#24341;&#20837;&#36793;&#30028;&#20445;&#25252;&#26657;&#20934;&#21644;&#21452;&#29305;&#24449;&#21453;&#39304;&#34917;&#20805;&#27169;&#22359;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20943;&#23569;&#20449;&#24687;&#25439;&#22833;&#12289;&#25233;&#21046;&#22122;&#22768;&#12289;&#22686;&#24378;&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.02867</link><description>&lt;p&gt;
&#22522;&#20110;&#36793;&#30028;&#24863;&#30693;&#36741;&#21161;&#21644;&#28176;&#36827;&#35821;&#20041;&#20248;&#21270;&#30340;&#21452;&#21453;&#39304;&#27880;&#24847;&#21147;&#26694;&#26550;&#29992;&#20110;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Dual Feedback Attention Framework via Boundary-Aware Auxiliary and Progressive Semantic Optimization for Salient Object Detection in Optical Remote Sensing Imagery. (arXiv:2303.02867v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#36793;&#30028;&#24863;&#30693;&#36741;&#21161;&#21644;&#28176;&#36827;&#35821;&#20041;&#20248;&#21270;&#30340;&#21452;&#21453;&#39304;&#27880;&#24847;&#21147;&#26694;&#26550; (DFA-BASO)&#12290;&#36890;&#36807;&#24341;&#20837;&#36793;&#30028;&#20445;&#25252;&#26657;&#20934;&#21644;&#21452;&#29305;&#24449;&#21453;&#39304;&#34917;&#20805;&#27169;&#22359;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20943;&#23569;&#20449;&#24687;&#25439;&#22833;&#12289;&#25233;&#21046;&#22122;&#22768;&#12289;&#22686;&#24378;&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#36880;&#28176;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#36825;&#35201;&#24402;&#21151;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#33258;&#28982;&#22330;&#26223;&#22270;&#20687;&#20013;&#30340;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#33258;&#28982;&#22330;&#26223;&#22270;&#20687;&#21644;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#22312;&#35768;&#22810;&#26041;&#38754;&#26159;&#19981;&#21516;&#30340;&#65292;&#20363;&#22914;&#35206;&#30422;&#33539;&#22260;&#22823;&#12289;&#32972;&#26223;&#22797;&#26434;&#20197;&#21450;&#30446;&#26631;&#31867;&#22411;&#21644;&#23610;&#24230;&#30340;&#24040;&#22823;&#24046;&#24322;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#19968;&#31181;&#19987;&#38376;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#27809;&#26377;&#20805;&#20998;&#20851;&#27880;&#21040;&#30446;&#26631;&#30340;&#36793;&#30028;&#65292;&#26368;&#32456;&#26174;&#33879;&#24615;&#22270;&#30340;&#23436;&#25972;&#24615;&#20173;&#38656;&#35201;&#25913;&#36827;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#36793;&#30028;&#24863;&#30693;&#36741;&#21161;&#21644;&#28176;&#36827;&#35821;&#20041;&#20248;&#21270;&#30340;&#21452;&#21453;&#39304;&#27880;&#24847;&#21147;&#26694;&#26550;&#65288;DFA-BASO&#65289;&#12290;&#39318;&#20808;&#65292;&#24341;&#20837;&#20102;&#36793;&#30028;&#20445;&#25252;&#26657;&#20934;(BPC)&#27169;&#22359;&#65292;&#29992;&#20110;&#20943;&#23569;&#27491;&#21521;&#20256;&#25773;&#36807;&#31243;&#20013;&#36793;&#30028;&#20301;&#32622;&#20449;&#24687;&#30340;&#20002;&#22833;&#65292;&#24182;&#25233;&#21046;&#20302;&#32423;&#29305;&#24449;&#20013;&#30340;&#22122;&#22768;&#12290;&#20854;&#27425;&#65292;&#24341;&#20837;&#20102;&#21452;&#29305;&#24449;&#21453;&#39304;&#34917;&#20805;(DFFC)&#27169;&#22359;&#65292;&#29992;&#20110;&#22686;&#24378;&#27491;&#21453;&#39304;&#21644;&#36127;&#21453;&#39304;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#25552;&#39640;&#26174;&#33879;&#24615;&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Salient object detection in optical remote sensing image (ORSI-SOD) has gradually attracted attention thanks to the development of deep learning (DL) and salient object detection in natural scene image (NSI-SOD). However, NSI and ORSI are different in many aspects, such as large coverage, complex background, and large differences in target types and scales. Therefore, a new dedicated method is needed for ORSI-SOD. In addition, existing methods do not pay sufficient attention to the boundary of the object, and the completeness of the final saliency map still needs improvement. To address these issues, we propose a novel method called Dual Feedback Attention Framework via Boundary-Aware Auxiliary and Progressive Semantic Optimization (DFA-BASO). First, Boundary Protection Calibration (BPC) module is proposed to reduce the loss of edge position information during forward propagation and suppress noise in low-level features. Second, a Dual Feature Feedback Complementary (DFFC) module is pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20219;&#21153;&#65292;&#36890;&#36807;&#21078;&#26512;&#32463;&#20856;&#30340;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#33616;&#27169;&#22411;&#65292;&#21457;&#29616;&#19968;&#20123;&#22797;&#26434;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#20256;&#25773;&#37096;&#20998;&#26159;&#22810;&#20313;&#30340;&#12290;&#22522;&#20110;&#27492;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Multi-Level Attention Mixture Network (Atten-Mixer)&#65292;&#23427;&#36890;&#36807;&#31227;&#38500;&#22810;&#20313;&#30340;&#20256;&#25773;&#37096;&#20998;&#65292;&#23454;&#29616;&#20102;&#23545;&#35835;&#20986;&#27169;&#22359;&#30340;&#26356;&#39640;&#25928;&#21033;&#29992;&#12290;</title><link>http://arxiv.org/abs/2206.12781</link><description>&lt;p&gt;
&#36890;&#36807;Atten-Mixer&#32593;&#32476;&#39640;&#25928;&#21033;&#29992;&#22810;&#32423;&#29992;&#25143;&#24847;&#22270;&#36827;&#34892;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Efficiently Leveraging Multi-level User Intent for Session-based Recommendation via Atten-Mixer Network. (arXiv:2206.12781v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.12781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20219;&#21153;&#65292;&#36890;&#36807;&#21078;&#26512;&#32463;&#20856;&#30340;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#33616;&#27169;&#22411;&#65292;&#21457;&#29616;&#19968;&#20123;&#22797;&#26434;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#20256;&#25773;&#37096;&#20998;&#26159;&#22810;&#20313;&#30340;&#12290;&#22522;&#20110;&#27492;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Multi-Level Attention Mixture Network (Atten-Mixer)&#65292;&#23427;&#36890;&#36807;&#31227;&#38500;&#22810;&#20313;&#30340;&#20256;&#25773;&#37096;&#20998;&#65292;&#23454;&#29616;&#20102;&#23545;&#35835;&#20986;&#27169;&#22359;&#30340;&#26356;&#39640;&#25928;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#26088;&#22312;&#26681;&#25454;&#30701;&#26242;&#19988;&#21160;&#24577;&#30340;&#20250;&#35805;&#39044;&#27979;&#29992;&#25143;&#30340;&#19979;&#19968;&#20010;&#21160;&#20316;&#12290;&#26368;&#36817;&#65292;&#22312;&#21033;&#29992;&#21508;&#31181;&#31934;&#24515;&#35774;&#35745;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(GNN)&#25429;&#25417;&#29289;&#21697;&#20043;&#38388;&#30340;&#25104;&#23545;&#20851;&#31995;&#26041;&#38754;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20852;&#36259;&#65292;&#20284;&#20046;&#34920;&#26126;&#35774;&#35745;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#26159;&#25552;&#39640;&#23454;&#35777;&#24615;&#33021;&#30340;&#19975;&#28789;&#33647;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#27169;&#22411;&#22797;&#26434;&#24230;&#21576;&#25351;&#25968;&#22686;&#38271;&#30340;&#21516;&#26102;&#65292;&#20165;&#21462;&#24471;&#20102;&#30456;&#23545;&#36739;&#23567;&#30340;&#25913;&#36827;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21078;&#26512;&#20102;&#32463;&#20856;&#30340;&#22522;&#20110;GNN&#30340;SBR&#27169;&#22411;&#65292;&#24182;&#22312;&#32463;&#39564;&#19978;&#21457;&#29616;&#65292;&#19968;&#20123;&#22797;&#26434;&#30340;GNN&#20256;&#25773;&#22312;&#32473;&#23450;&#35835;&#20986;&#27169;&#22359;&#22312;GNN&#27169;&#22411;&#20013;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#30340;&#24773;&#20917;&#19979;&#26159;&#22810;&#20313;&#30340;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#30452;&#35266;&#22320;&#25552;&#20986;&#20102;&#31227;&#38500;GNN&#20256;&#25773;&#37096;&#20998;&#30340;&#24819;&#27861;&#65292;&#32780;&#35835;&#20986;&#27169;&#22359;&#23558;&#22312;&#27169;&#22411;&#25512;&#29702;&#36807;&#31243;&#20013;&#25215;&#25285;&#26356;&#22810;&#36131;&#20219;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Multi-Level Attention Mixture Network (Atten-Mixer)&#65292;&#23427;&#21516;&#26102;&#21033;&#29992;&#27010;&#24565;-
&lt;/p&gt;
&lt;p&gt;
Session-based recommendation (SBR) aims to predict the user's next action based on short and dynamic sessions. Recently, there has been an increasing interest in utilizing various elaborately designed graph neural networks (GNNs) to capture the pair-wise relationships among items, seemingly suggesting the design of more complicated models is the panacea for improving the empirical performance. However, these models achieve relatively marginal improvements with exponential growth in model complexity. In this paper, we dissect the classical GNN-based SBR models and empirically find that some sophisticated GNN propagations are redundant, given the readout module plays a significant role in GNN-based models. Based on this observation, we intuitively propose to remove the GNN propagation part, while the readout module will take on more responsibility in the model reasoning process. To this end, we propose the Multi-Level Attention Mixture Network (Atten-Mixer), which leverages both concept-
&lt;/p&gt;</description></item></channel></rss>