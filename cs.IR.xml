<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340; Calibrate Proxy &#32467;&#26500;&#65292;&#36890;&#36807;&#21033;&#29992;&#23454;&#38469;&#26679;&#26412;&#20449;&#24687;&#25913;&#21892;&#20102;&#22522;&#20110;&#20195;&#29702;&#30340;&#25439;&#22833;&#30456;&#20284;&#24615;&#35745;&#31639;&#65292;&#24341;&#20837;&#19968;&#20010;&#26657;&#20934;&#25439;&#22833;&#26469;&#32422;&#26463;&#20195;&#29702;&#20248;&#21270;&#26041;&#21521;&#31867;&#21035;&#29305;&#24449;&#20013;&#24515;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#36739;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.09162</link><description>&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#30340;&#40065;&#26834;&#24615;&#26657;&#20934;&#20195;&#29702;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Robust Calibrate Proxy Loss for Deep Metric Learning. (arXiv:2304.09162v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340; Calibrate Proxy &#32467;&#26500;&#65292;&#36890;&#36807;&#21033;&#29992;&#23454;&#38469;&#26679;&#26412;&#20449;&#24687;&#25913;&#21892;&#20102;&#22522;&#20110;&#20195;&#29702;&#30340;&#25439;&#22833;&#30456;&#20284;&#24615;&#35745;&#31639;&#65292;&#24341;&#20837;&#19968;&#20010;&#26657;&#20934;&#25439;&#22833;&#26469;&#32422;&#26463;&#20195;&#29702;&#20248;&#21270;&#26041;&#21521;&#31867;&#21035;&#29305;&#24449;&#20013;&#24515;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#36739;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#20013;&#65292;&#20027;&#27969;&#30740;&#31350;&#21487;&#20998;&#20026;&#20004;&#31181;&#65306;&#22522;&#20110;&#20195;&#29702;&#30340;&#26041;&#27861;&#21644;&#22522;&#20110;&#25104;&#23545;&#30340;&#26041;&#27861;&#12290;&#22522;&#20110;&#20195;&#29702;&#30340;&#26041;&#27861;&#30001;&#20110;&#35757;&#32451;&#22797;&#26434;&#24230;&#20302;&#12289;&#32593;&#32476;&#25910;&#25947;&#24555;&#36895;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#23616;&#38480;&#22312;&#20110;&#20195;&#29702;&#20248;&#21270;&#30001;&#32593;&#32476;&#23436;&#25104;&#65292;&#20351;&#24471;&#38590;&#20197;&#20934;&#30830;&#22320;&#34920;&#31034;&#25968;&#25454;&#23454;&#38469;&#31867;&#21035;&#30340;&#29305;&#24449;&#20998;&#24067;&#24773;&#20917;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181; Calibrate Proxy&#65288;CP&#65289;&#32467;&#26500;&#65292;&#21033;&#29992;&#23454;&#38469;&#26679;&#26412;&#20449;&#24687;&#25913;&#21892;&#20102;&#22522;&#20110;&#20195;&#29702;&#30340;&#25439;&#22833;&#30340;&#30456;&#20284;&#24230;&#35745;&#31639;&#65292;&#24182;&#24341;&#20837;&#20102;&#26657;&#20934;&#25439;&#22833;&#26469;&#32422;&#26463;&#20195;&#29702;&#20248;&#21270;&#26397;&#21521;&#31867;&#21035;&#29305;&#24449;&#20013;&#24515;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#31867;&#21035;&#35774;&#32622;&#20102;&#23569;&#37327;&#20195;&#29702;&#20197;&#20943;&#36731;&#31867;&#20869;&#24046;&#24322;&#23545;&#26816;&#32034;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#22312;&#19977;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#21644;&#22810;&#20010;&#21512;&#25104;&#26631;&#31614;&#22122;&#22768;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#35780;&#20272;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The mainstream researche in deep metric learning can be divided into two genres: proxy-based and pair-based methods. Proxy-based methods have attracted extensive attention due to the lower training complexity and fast network convergence. However, these methods have limitations as the poxy optimization is done by network, which makes it challenging for the proxy to accurately represent the feature distrubtion of the real class of data. In this paper, we propose a Calibrate Proxy (CP) structure, which uses the real sample information to improve the similarity calculation in proxy-based loss and introduces a calibration loss to constraint the proxy optimization towards the center of the class features. At the same time, we set a small number of proxies for each class to alleviate the impact of intra-class differences on retrieval performance. The effectiveness of our method is evaluated by extensive experiments on three public datasets and multiple synthetic label-noise datasets. The res
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;LLMs&#21327;&#21161;&#20154;&#31867;&#19987;&#23478;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#21487;&#33021;&#26041;&#27861;&#21644;&#38382;&#39064;&#65292;&#21046;&#23450;&#20102;&#20154;&#26426;&#21327;&#20316;&#35889;&#31995;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#19982;&#32463;&#36807;&#35757;&#32451;&#30340;&#20154;&#31867;&#35780;&#20272;&#32773;&#21028;&#26029;&#30456;&#20851;&#24615;&#30340;&#21021;&#27493;&#23454;&#39564;&#65292;&#20197;&#21450;&#25903;&#25345;&#21644;&#21453;&#23545;&#20351;&#29992;LLMs&#36827;&#34892;&#33258;&#21160;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20004;&#20010;&#23545;&#31435;&#35266;&#28857;&#20197;&#21450;&#22949;&#21327;&#30340;&#35266;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.09161</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#30456;&#20851;&#24615;&#35780;&#20215;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Perspectives on Large Language Models for Relevance Judgment. (arXiv:2304.09161v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09161
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;LLMs&#21327;&#21161;&#20154;&#31867;&#19987;&#23478;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#21487;&#33021;&#26041;&#27861;&#21644;&#38382;&#39064;&#65292;&#21046;&#23450;&#20102;&#20154;&#26426;&#21327;&#20316;&#35889;&#31995;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#19982;&#32463;&#36807;&#35757;&#32451;&#30340;&#20154;&#31867;&#35780;&#20272;&#32773;&#21028;&#26029;&#30456;&#20851;&#24615;&#30340;&#21021;&#27493;&#23454;&#39564;&#65292;&#20197;&#21450;&#25903;&#25345;&#21644;&#21453;&#23545;&#20351;&#29992;LLMs&#36827;&#34892;&#33258;&#21160;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20004;&#20010;&#23545;&#31435;&#35266;&#28857;&#20197;&#21450;&#22949;&#21327;&#30340;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#34987;&#38382;&#21450;&#26102;&#65292;&#20687;ChatGPT&#36825;&#26679;&#30340;&#24403;&#21069;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22768;&#31216;&#23427;&#20204;&#21487;&#20197;&#21327;&#21161;&#25105;&#20204;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#12290;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#35748;&#20026;&#36825;&#19981;&#20250;&#23548;&#33268;&#21487;&#20449;&#30340;&#20449;&#24687;&#26816;&#32034;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;LLMs&#21327;&#21161;&#20154;&#31867;&#19987;&#23478;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#21487;&#33021;&#26041;&#27861;&#20197;&#21450;&#21487;&#33021;&#20986;&#29616;&#30340;&#38382;&#39064;&#21644;&#20851;&#27880;&#28857;&#12290;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#35889;&#31995;&#65292;&#21487;&#20197;&#23558;&#19981;&#21516;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#31574;&#30053;&#36827;&#34892;&#20998;&#31867;&#65292;&#22522;&#20110;&#20154;&#31867;&#23545;&#26426;&#22120;&#30340;&#20381;&#36182;&#31243;&#24230;&#12290;&#38024;&#23545;&#8220;&#23436;&#20840;&#33258;&#21160;&#21270;&#35780;&#20272;&#8221;&#30340;&#26497;&#31471;&#28857;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#36827;&#34892;&#20102;&#22522;&#20110;LLM&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#19982;&#32463;&#36807;&#35757;&#32451;&#30340;&#20154;&#31867;&#35780;&#20272;&#32773;&#21028;&#26029;&#30340;&#30456;&#20851;&#24615;&#30340;&#21021;&#27493;&#23454;&#39564;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#25991;&#29486;&#12289;&#25105;&#20204;&#30340;&#21021;&#27493;&#23454;&#39564;&#35777;&#25454;&#20197;&#21450;&#25105;&#20204;&#20316;&#20026;&#20449;&#24687;&#26816;&#32034;&#30740;&#31350;&#20154;&#21592;&#30340;&#32463;&#39564;&#65292;&#25552;&#20986;&#20102;&#25903;&#25345;&#21644;&#21453;&#23545;&#20351;&#29992;LLMs&#36827;&#34892;&#33258;&#21160;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20004;&#20010;&#23545;&#31435;&#35266;&#28857;&#20197;&#21450;&#22949;&#21327;&#30340;&#35266;&#28857;&#12290;&#25105;&#20204;&#24076;&#26395;&#24320;&#22987;&#36827;&#34892;&#24314;&#35774;&#24615;&#30340;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
When asked, current large language models (LLMs) like ChatGPT claim that they can assist us with relevance judgments. Many researchers think this would not lead to credible IR research. In this perspective paper, we discuss possible ways for LLMs to assist human experts along with concerns and issues that arise. We devise a human-machine collaboration spectrum that allows categorizing different relevance judgment strategies, based on how much the human relies on the machine. For the extreme point of "fully automated assessment", we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing two opposing perspectives - for and against the use of LLMs for automatic relevance judgments - and a compromise perspective, informed by our analyses of the literature, our preliminary experimental evidence, and our experience as IR researchers.  We hope to start a constructive discussion withi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#35299;&#20915;&#30005;&#21830;&#24191;&#21578;&#31995;&#32479;&#20013;&#36190;&#21161;&#20135;&#21697;&#20248;&#21270;&#30340;&#22810;&#20010;&#38382;&#39064;&#65292;&#32780;&#19981;&#38656;&#35201;&#25913;&#21464;&#29616;&#26377;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#32467;&#26500;&#12290;&#20351;&#29992;&#35813;&#26694;&#26550;&#21487;&#20197;&#22788;&#29702;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#38382;&#39064;&#65292;&#24182;&#20026;&#22810;&#20010;&#35780;&#20272;&#25351;&#26631;&#24102;&#26469;&#22686;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.09107</link><description>&lt;p&gt;
&#30005;&#21830;&#20013;&#20248;&#21270;&#36190;&#21161;&#20135;&#21697;&#30340;&#23454;&#36341;&#32463;&#39564;
&lt;/p&gt;
&lt;p&gt;
Practical Lessons on Optimizing Sponsored Products in eCommerce. (arXiv:2304.09107v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#35299;&#20915;&#30005;&#21830;&#24191;&#21578;&#31995;&#32479;&#20013;&#36190;&#21161;&#20135;&#21697;&#20248;&#21270;&#30340;&#22810;&#20010;&#38382;&#39064;&#65292;&#32780;&#19981;&#38656;&#35201;&#25913;&#21464;&#29616;&#26377;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#32467;&#26500;&#12290;&#20351;&#29992;&#35813;&#26694;&#26550;&#21487;&#20197;&#22788;&#29702;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#38382;&#39064;&#65292;&#24182;&#20026;&#22810;&#20010;&#35780;&#20272;&#25351;&#26631;&#24102;&#26469;&#22686;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36190;&#21161;&#20135;&#21697;&#20248;&#21270;&#20013;&#30340;&#22810;&#20010;&#38382;&#39064;&#65292;&#21253;&#25324;&#22522;&#20110;&#20301;&#32622;&#30340;&#21435;&#20559;&#24046;&#12289;&#28857;&#20987;-&#36716;&#21270;&#22810;&#20219;&#21153;&#23398;&#20064;&#20197;&#21450;&#39044;&#27979;&#28857;&#20987;&#29575;&#30340;&#26657;&#20934;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#32780;&#19981;&#38656;&#35201;&#25913;&#21464;&#29616;&#26377;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#32467;&#26500;&#65292;&#22240;&#27492;&#21487;&#20197;&#19982;&#22823;&#22810;&#25968;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#32467;&#21512;&#20351;&#29992;&#65288;&#21253;&#25324;&#27973;&#23618;&#27169;&#22411;&#65292;&#22914;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#25968;&#25454;&#21644;&#29305;&#24449;&#24037;&#31243;&#25216;&#26415;&#65292;&#20197;&#22788;&#29702;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#19978;&#36848;&#38382;&#39064;; &#28982;&#21518;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#23454;&#29992;&#26694;&#26550;&#22312;&#26469;&#33258;&#22312;&#32447;&#36141;&#29289;&#32593;&#31449;&#27969;&#37327;&#26085;&#24535;&#30340;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#30340;&#25928;&#30410;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#25552;&#35758;&#30340;&#23454;&#29992;&#26694;&#26550;&#19982;&#25968;&#25454;&#21644;&#29305;&#24449;&#24037;&#31243;&#20063;&#21487;&#20197;&#22788;&#29702;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#38382;&#39064;&#65292;&#24182;&#20026;&#22810;&#20010;&#35780;&#20272;&#25351;&#26631;&#24102;&#26469;&#22686;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study multiple problems from sponsored product optimization in ad system, including position-based de-biasing, click-conversion multi-task learning, and calibration on predicted click-through-rate (pCTR). We propose a practical machine learning framework that provides the solutions to such problems without structural change to existing machine learning models, thus can be combined with most machine learning models including shallow models (e.g. gradient boosting decision trees, support vector machines). In this paper, we first propose data and feature engineering techniques to handle the aforementioned problems in ad system; after that, we evaluate the benefit of our practical framework on real-world data sets from our traffic logs from online shopping site. We show that our proposed practical framework with data and feature engineering can also handle the perennial problems in ad systems and bring increments to multiple evaluation metrics.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#23558;&#23458;&#25143;360&#24230;&#35270;&#35282;&#30340;&#19981;&#21516;&#34892;&#20026;&#25110;&#29305;&#24449;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#26500;&#24314;&#20986;&#31867;&#20284;&#27169;&#22411;&#20197;&#25913;&#21892;&#23458;&#25143;&#23450;&#20301;&#30340;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#30005;&#21830;&#21644;&#26053;&#28216;&#39046;&#22495;&#20013;&#33021;&#22815;&#26377;&#25928;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.09105</link><description>&lt;p&gt;
&#25506;&#31350;&#23458;&#25143;360&#24230;&#35270;&#35282;&#23454;&#29616;&#31867;&#20284;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Exploring 360-Degree View of Customers for Lookalike Modeling. (arXiv:2304.09105v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09105
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#23558;&#23458;&#25143;360&#24230;&#35270;&#35282;&#30340;&#19981;&#21516;&#34892;&#20026;&#25110;&#29305;&#24449;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#26500;&#24314;&#20986;&#31867;&#20284;&#27169;&#22411;&#20197;&#25913;&#21892;&#23458;&#25143;&#23450;&#20301;&#30340;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#30005;&#21830;&#21644;&#26053;&#28216;&#39046;&#22495;&#20013;&#33021;&#22815;&#26377;&#25928;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31867;&#20284;&#24314;&#27169;&#26159;&#22522;&#20110;&#29992;&#25143;&#30456;&#20284;&#24615;&#23545;&#20135;&#21697;&#38144;&#21806;&#21644;&#25193;&#23637;&#24191;&#21578;&#27963;&#21160;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#30340;&#20551;&#35774;&#12290;&#36825;&#39033;&#24037;&#20316;&#30340;&#25361;&#25112;&#22312;&#20110;&#29992;&#25143;&#32676;&#20307;&#30340;&#24322;&#36136;&#24615;&#21644;&#20854;&#31232;&#30095;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#23458;&#25143;&#30340;&#19981;&#21516;&#34892;&#20026;&#25110;&#29305;&#24449;&#65288;&#22914;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#12289;&#22312;&#19981;&#21516;&#24179;&#21488;&#19978;&#30340;&#36141;&#20080;&#34892;&#20026;&#12289;&#23458;&#25143;&#24544;&#35802;&#34892;&#20026;&#65289;&#32479;&#19968;&#36215;&#26469;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#31867;&#20284;&#27169;&#22411;&#65292;&#20197;&#25913;&#21892;&#20048;&#22825;&#38598;&#22242;&#30340;&#23458;&#25143;&#23450;&#20301;&#12290;&#30495;&#23454;&#30340;&#30005;&#23376;&#21830;&#21153;&#21644;&#26053;&#28216;&#25968;&#25454;&#38598;&#19978;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31867;&#20284;&#27169;&#22411;&#23545;&#20110;&#29992;&#25143;&#23450;&#20301;&#20219;&#21153;&#38750;&#24120;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lookalike models are based on the assumption that user similarity plays an important role towards product selling and enhancing the existing advertising campaigns from a very large user base. Challenges associated to these models reside on the heterogeneity of the user base and its sparsity. In this work, we propose a novel framework that unifies the customers different behaviors or features such as demographics, buying behaviors on different platforms, customer loyalty behaviors and build a lookalike model to improve customer targeting for Rakuten Group, Inc. Extensive experiments on real e-commerce and travel datasets demonstrate the effectiveness of our proposed lookalike model for user targeting task.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#21644;&#23454;&#26045;&#20102;&#19968;&#20010;&#21517;&#20026;MATURE-HEALTH&#30340;&#20581;&#24247;&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#39044;&#27979;&#30005;&#35299;&#36136;&#19981;&#24179;&#34913;&#24182;&#25512;&#33616;&#33829;&#20859;&#24179;&#34913;&#30340;&#39135;&#29289;&#65292;&#20174;&#32780;&#22686;&#21152;&#26089;&#26399;&#26816;&#27979;&#30142;&#30149;&#30340;&#26426;&#20250;&#24182;&#38450;&#27490;&#20581;&#24247;&#36827;&#19968;&#27493;&#24694;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.09099</link><description>&lt;p&gt;
MATURE-HEALTH: MAndatory FeaTURE&#36873;&#25321;&#30340;&#20581;&#24247;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices. (arXiv:2304.09099v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09099
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#21644;&#23454;&#26045;&#20102;&#19968;&#20010;&#21517;&#20026;MATURE-HEALTH&#30340;&#20581;&#24247;&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#39044;&#27979;&#30005;&#35299;&#36136;&#19981;&#24179;&#34913;&#24182;&#25512;&#33616;&#33829;&#20859;&#24179;&#34913;&#30340;&#39135;&#29289;&#65292;&#20174;&#32780;&#22686;&#21152;&#26089;&#26399;&#26816;&#27979;&#30142;&#30149;&#30340;&#26426;&#20250;&#24182;&#38450;&#27490;&#20581;&#24247;&#36827;&#19968;&#27493;&#24694;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#34913;&#30005;&#35299;&#36136;&#23545;&#20110;&#20154;&#20307;&#22120;&#23448;&#30340;&#36866;&#24403;&#21151;&#33021;&#33267;&#20851;&#37325;&#35201;&#21644;&#24517;&#19981;&#21487;&#23569;&#65292;&#22240;&#20026;&#30005;&#35299;&#36136;&#22833;&#34913;&#21487;&#33021;&#26159;&#28508;&#22312;&#30149;&#29702;&#29983;&#29702;&#23398;&#21457;&#23637;&#30340;&#25351;&#31034;&#12290;&#39640;&#25928;&#30417;&#27979;&#30005;&#35299;&#36136;&#22833;&#34913;&#19981;&#20165;&#21487;&#20197;&#22686;&#21152;&#30142;&#30149;&#26089;&#26399;&#26816;&#27979;&#30340;&#26426;&#20250;&#65292;&#32780;&#19988;&#21487;&#20197;&#36890;&#36807;&#20005;&#26684;&#36981;&#24490;&#33829;&#20859;&#25511;&#21046;&#39278;&#39135;&#20197;&#24179;&#34913;&#30005;&#35299;&#36136;&#20174;&#32780;&#38450;&#27490;&#20581;&#24247;&#36827;&#19968;&#27493;&#24694;&#21270;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#24182;&#23454;&#26045;&#20102;&#19968;&#20010;&#25512;&#33616;&#31995;&#32479;MATURE Health&#65292;&#35813;&#31995;&#32479;&#39044;&#27979;&#34880;&#28082;&#20013;&#24517;&#38656;&#30005;&#35299;&#36136;&#21644;&#20854;&#20182;&#29289;&#36136;&#30340;&#19981;&#24179;&#34913;&#65292;&#28982;&#21518;&#25512;&#33616;&#21547;&#26377;&#24179;&#34913;&#33829;&#20859;&#30340;&#39135;&#29289;&#65292;&#20197;&#36991;&#20813;&#30005;&#35299;&#36136;&#19981;&#24179;&#34913;&#30340;&#21457;&#29983;&#12290;&#35813;&#27169;&#22411;&#32771;&#34385;&#21040;&#29992;&#25143;&#26368;&#36817;&#30340;&#23454;&#39564;&#23460;&#32467;&#26524;&#21644;&#27599;&#26085;&#39135;&#29289;&#25668;&#20837;&#37327;&#26469;&#39044;&#27979;&#30005;&#35299;&#36136;&#19981;&#24179;&#34913;&#12290;MATURE Health&#20381;&#36182;&#20110;MATURE Food&#31639;&#27861;&#25512;&#33616;&#39135;&#29289;&#65292;&#21518;&#32773;&#20165;&#25512;&#33616;&#37027;&#20123;
&lt;/p&gt;
&lt;p&gt;
Balancing electrolytes is utmost important and essential for appropriate functioning of organs in human body as electrolytes imbalance can be an indication of the development of underlying pathophysiology. Efficient monitoring of electrolytes imbalance not only can increase the chances of early detection of disease, but also prevents the further deterioration of the health by strictly following nutrient controlled diet for balancing the electrolytes post disease detection. In this research, a recommender system MATURE Health is proposed and implemented, which predicts the imbalance of mandatory electrolytes and other substances presented in blood and recommends the food items with the balanced nutrients to avoid occurrence of the electrolytes imbalance. The proposed model takes user most recent laboratory results and daily food intake into account to predict the electrolytes imbalance. MATURE Health relies on MATURE Food algorithm to recommend food items as latter recommends only those
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;Sheaf&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#26041;&#27861;&#65292;&#20351;&#24471;&#20854;&#22312;&#22522;&#20934;&#25512;&#33616;&#20219;&#21153;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.09097</link><description>&lt;p&gt;
&#22522;&#20110;Sheaf&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Sheaf Neural Networks for Graph-based Recommender Systems. (arXiv:2304.09097v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09097
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Sheaf&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#26041;&#27861;&#65292;&#20351;&#24471;&#20854;&#22312;&#22522;&#20934;&#25512;&#33616;&#20219;&#21153;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;Graph&#31070;&#32463;&#32593;&#32476;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#65292;&#21253;&#25324;&#25512;&#33616;&#31995;&#32479;&#12290;Graph&#31070;&#32463;&#32593;&#32476;&#23545;&#20854;&#20182;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#22312;&#20110;&#65292;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#35768;&#22810;&#38382;&#39064;&#21487;&#20197;&#33258;&#28982;&#22320;&#24314;&#27169;&#20026;&#22270;&#65292;&#20854;&#20013;&#33410;&#28857;&#21487;&#20197;&#26159;&#29992;&#25143;&#25110;&#39033;&#30446;&#65292;&#36793;&#20195;&#34920;&#20559;&#22909;&#20851;&#31995;&#12290; &#22312;&#24403;&#21069;&#30340;Graph&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#20013;&#65292;&#33410;&#28857;&#29992;&#22312;&#35757;&#32451;&#26102;&#23398;&#20064;&#21040;&#30340;&#38745;&#24577;&#21521;&#37327;&#34920;&#31034;&#12290;&#36825;&#31181;&#38745;&#24577;&#21521;&#37327;&#21487;&#33021;&#21482;&#36866;&#29992;&#20110;&#25429;&#25417;&#23450;&#20041;&#23427;&#20204;&#30340;&#19968;&#20123;&#29992;&#25143;&#25110;&#39033;&#30446;&#30340;&#24494;&#22937;&#24046;&#21035;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#21551;&#21457;&#33539;&#30068;&#35770;&#30340;&#27169;&#22411;&#65306;Sheaf&#31070;&#32463;&#32593;&#32476;&#12290;Sheaf&#31070;&#32463;&#32593;&#32476;&#21450;&#20854;&#36830;&#25509;&#30340;&#25289;&#26222;&#25289;&#26031;&#21487;&#20197;&#36890;&#36807;&#23558;&#27599;&#20010;&#33410;&#28857;&#65288;&#20197;&#21450;&#36793;&#65289;&#19982;&#21521;&#37327;&#31354;&#38388;&#32780;&#19981;&#26159;&#21333;&#20010;&#21521;&#37327;&#30456;&#20851;&#32852;&#26469;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#12290;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#26356;&#20016;&#23500;&#65292;&#24182;&#20801;&#35768;&#22312;&#25512;&#29702;&#26102;&#36873;&#25321;&#27491;&#30830;&#30340;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#30340;&#27169;&#22411;&#26356;&#20855;&#34920;&#29616;&#21147;&#21644;&#28789;&#27963;&#24615;&#65292;&#22312;&#20960;&#20010;&#22522;&#20934;&#25512;&#33616;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent progress in Graph Neural Networks has resulted in wide adoption by many applications, including recommendation systems. The reason for Graph Neural Networks' superiority over other approaches is that many problems in recommendation systems can be naturally modeled as graphs, where nodes can be either users or items and edges represent preference relationships. In current Graph Neural Network approaches, nodes are represented with a static vector learned at training time. This static vector might only be suitable to capture some of the nuances of users or items they define. To overcome this limitation, we propose using a recently proposed model inspired by category theory: Sheaf Neural Networks. Sheaf Neural Networks, and its connected Laplacian, can address the previous problem by associating every node (and edge) with a vector space instead than a single vector. The vector space representation is richer and allows picking the proper representation at inference time. This approa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#21644;&#30697;&#38453;&#20998;&#35299;&#30340;&#20445;&#25252;&#38544;&#31169;&#25512;&#33616;&#31995;&#32479;&#65292;&#37319;&#29992;&#36755;&#20986;&#25200;&#21160;&#30340;&#39640;&#26031;&#26426;&#21046;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#65292;&#36890;&#36807;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#23545;&#25972;&#20307;&#38544;&#31169;&#25439;&#22833;&#36827;&#34892;&#29305;&#24449;&#21270;&#65292;&#22312;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#25512;&#33616;&#31995;&#32479;&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.09096</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#26426;&#21046;&#30340;&#20445;&#25252;&#38544;&#31169;&#30697;&#38453;&#20998;&#35299;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism. (arXiv:2304.09096v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#21644;&#30697;&#38453;&#20998;&#35299;&#30340;&#20445;&#25252;&#38544;&#31169;&#25512;&#33616;&#31995;&#32479;&#65292;&#37319;&#29992;&#36755;&#20986;&#25200;&#21160;&#30340;&#39640;&#26031;&#26426;&#21046;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#65292;&#36890;&#36807;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#23545;&#25972;&#20307;&#38544;&#31169;&#25439;&#22833;&#36827;&#34892;&#29305;&#24449;&#21270;&#65292;&#22312;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#25512;&#33616;&#31995;&#32479;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#31435;&#25512;&#33616;&#31995;&#32479;&#38656;&#35201;&#20998;&#26512;&#29992;&#25143;&#25968;&#25454;&#65292;&#36825;&#21487;&#33021;&#20250;&#27844;&#38706;&#29992;&#25143;&#30340;&#20010;&#20154;&#20449;&#24687;&#12290;&#21311;&#21517;&#21270;&#29992;&#25143;&#25968;&#25454;&#36890;&#24120;&#19981;&#36275;&#20197;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;&#37492;&#20110;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#21644;&#30697;&#38453;&#20998;&#35299;&#30340;&#20445;&#25252;&#38544;&#31169;&#25512;&#33616;&#31995;&#32479;&#65292;&#30697;&#38453;&#20998;&#35299;&#26159;&#26368;&#27969;&#34892;&#30340;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#20043;&#19968;&#12290;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#65292;&#21363;&#20351;&#23545;&#25163;&#25317;&#26377;&#29992;&#25143;&#30340;&#20844;&#24320;&#20449;&#24687;&#65292;&#20063;&#21487;&#20197;&#38450;&#27490;&#23545;&#25163;&#25552;&#21462;&#25935;&#24863;&#29992;&#25143;&#20449;&#24687;&#12290;&#25105;&#20204;&#37319;&#29992;&#36755;&#20986;&#25200;&#21160;&#30340;&#39640;&#26031;&#26426;&#21046;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#24182;&#21457;&#24067;&#28385;&#36275;&#38544;&#31169;&#23450;&#20041;&#30340;&#29992;&#25143;&#26723;&#26696;&#12290;&#25105;&#20204;&#20351;&#29992;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#23545;&#25972;&#20307;&#38544;&#31169;&#25439;&#22833;&#36827;&#34892;&#20102;&#32039;&#23494;&#30340;&#29305;&#24449;&#21270;&#12290;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Building a recommendation system involves analyzing user data, which can potentially leak sensitive information about users. Anonymizing user data is often not sufficient for preserving user privacy. Motivated by this, we propose a privacy-preserving recommendation system based on the differential privacy framework and matrix factorization, which is one of the most popular algorithms for recommendation systems. As differential privacy is a powerful and robust mathematical framework for designing privacy-preserving machine learning algorithms, it is possible to prevent adversaries from extracting sensitive user information even if the adversary possesses their publicly available (auxiliary) information. We implement differential privacy via the Gaussian mechanism in the form of output perturbation and release user profiles that satisfy privacy definitions. We employ R\'enyi Differential Privacy for a tight characterization of the overall privacy loss. We perform extensive experiments on
&lt;/p&gt;</description></item><item><title>KLEVER&#26159;&#19968;&#20010;&#26032;&#30340;CRS&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#29289;&#21697;&#21644;&#23427;&#20204;&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#21333;&#35789;&#32852;&#21512;&#24314;&#27169;&#22312;&#21516;&#19968;&#35821;&#20041;&#31354;&#38388;&#20013;&#65292;&#35299;&#20915;&#20102;&#20197;&#21069;&#24037;&#20316;&#20013;&#30340;&#29289;&#21697;&#21644;&#21333;&#35789;&#35821;&#20041;&#31354;&#38388;&#19981;&#23545;&#40784;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.09093</link><description>&lt;p&gt;
&#22522;&#20110;&#25551;&#36848;&#24615;&#22270;&#30340;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29289;&#21697;&#21644;&#19978;&#19979;&#25991;&#29702;&#35299;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improving Items and Contexts Understanding with Descriptive Graph for Conversational Recommendation. (arXiv:2304.09093v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09093
&lt;/p&gt;
&lt;p&gt;
KLEVER&#26159;&#19968;&#20010;&#26032;&#30340;CRS&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#29289;&#21697;&#21644;&#23427;&#20204;&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#21333;&#35789;&#32852;&#21512;&#24314;&#27169;&#22312;&#21516;&#19968;&#35821;&#20041;&#31354;&#38388;&#20013;&#65292;&#35299;&#20915;&#20102;&#20197;&#21069;&#24037;&#20316;&#20013;&#30340;&#29289;&#21697;&#21644;&#21333;&#35789;&#35821;&#20041;&#31354;&#38388;&#19981;&#23545;&#40784;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#65288;CRS&#65289;&#22312;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#25552;&#39640;&#29289;&#21697;&#21644;&#19978;&#19979;&#25991;&#21333;&#35789;&#34920;&#31034;&#26041;&#38754;&#22788;&#20110;&#26368;&#21069;&#27839;&#27700;&#24179;&#65292;&#20197;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#25512;&#33616;&#21644;&#21709;&#24212;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#29289;&#21697;&#21644;&#21333;&#35789;&#30340;&#34920;&#31034;&#36890;&#24120;&#22312;&#20004;&#20010;&#29420;&#31435;&#30340;&#35821;&#20041;&#31354;&#38388;&#20013;&#24314;&#27169;&#65292;&#36825;&#20250;&#23548;&#33268;&#23427;&#20204;&#20043;&#38388;&#30340;&#19981;&#23545;&#40784;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#24403;&#29992;&#25143;&#36755;&#20837;&#20449;&#24687;&#19981;&#36275;&#26102;&#65292;&#36825;&#23558;&#23548;&#33268;CRS&#20165;&#23454;&#29616;&#27425;&#20248;&#25490;&#21517;&#34920;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#20197;&#21069;&#24037;&#20316;&#30340;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;CRS&#26694;&#26550;KLEVER&#65292;&#23427;&#21487;&#20197;&#32852;&#21512;&#24314;&#27169;&#22312;&#30456;&#21516;&#35821;&#20041;&#31354;&#38388;&#20013;&#30340;&#29289;&#21697;&#21644;&#23427;&#20204;&#30456;&#20851;&#30340;&#19978;&#19979;&#25991;&#21333;&#35789;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20174;&#20016;&#23500;&#30340;&#29289;&#21697;&#25991;&#26412;&#29305;&#24449;&#65288;&#22914;&#29289;&#21697;&#25551;&#36848;&#21644;&#31867;&#21035;&#65289;&#20013;&#26500;&#24314;&#19968;&#20010;&#29289;&#21697;&#25551;&#36848;&#24615;&#22270;&#12290;&#22522;&#20110;&#26500;&#24314;&#30340;&#25551;&#36848;&#24615;&#22270;&#65292;KLEVER&#20849;&#21516;&#23398;&#20064;&#21333;&#35789;&#21644;&#29289;&#21697;&#30340;&#23884;&#20837;&#65292;&#20197;&#22686;&#24378;&#25512;&#33616;&#21644;&#23545;&#35805;&#29983;&#25104;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art methods on conversational recommender systems (CRS) leverage external knowledge to enhance both items' and contextual words' representations to achieve high quality recommendations and responses generation. However, the representations of the items and words are usually modeled in two separated semantic spaces, which leads to misalignment issue between them. Consequently, this will cause the CRS to only achieve a sub-optimal ranking performance, especially when there is a lack of sufficient information from the user's input. To address limitations of previous works, we propose a new CRS framework KLEVER, which jointly models items and their associated contextual words in the same semantic space. Particularly, we construct an item descriptive graph from the rich items' textual features, such as item description and categories. Based on the constructed descriptive graph, KLEVER jointly learns the embeddings of the words and items, towards enhancing both recommender and d
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37319;&#29992;&#28459;&#30011;&#25512;&#33616;MAB&#35774;&#32622;&#65292;&#19982;&#20247;&#21253;&#24037;&#20316;&#32773;&#23545;&#20851;&#38190;MAB&#20551;&#35774;&#30340;&#26377;&#25928;&#24615;&#36827;&#34892;&#30740;&#31350;&#65292;&#32467;&#26524;&#25361;&#25112;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#24378;&#35843;&#20102;&#38656;&#35201;&#36827;&#34892;&#26356;&#22810;&#20851;&#20110;MAB&#25512;&#33616;&#20013;&#36825;&#20123;&#20551;&#35774;&#30340;&#23454;&#35777;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2304.09088</link><description>&lt;p&gt;
&#25512;&#33616;&#20013;&#30340;Bandit&#31639;&#27861;&#30340;&#29616;&#22330;&#27979;&#35797;&#65306;&#20102;&#35299;MAB&#20013;&#20851;&#20110;&#20154;&#31867;&#20559;&#22909;&#20551;&#35774;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
A Field Test of Bandit Algorithms for Recommendations: Understanding the Validity of Assumptions on Human Preferences in Multi-armed Bandits. (arXiv:2304.09088v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37319;&#29992;&#28459;&#30011;&#25512;&#33616;MAB&#35774;&#32622;&#65292;&#19982;&#20247;&#21253;&#24037;&#20316;&#32773;&#23545;&#20851;&#38190;MAB&#20551;&#35774;&#30340;&#26377;&#25928;&#24615;&#36827;&#34892;&#30740;&#31350;&#65292;&#32467;&#26524;&#25361;&#25112;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#24378;&#35843;&#20102;&#38656;&#35201;&#36827;&#34892;&#26356;&#22810;&#20851;&#20110;MAB&#25512;&#33616;&#20013;&#36825;&#20123;&#20551;&#35774;&#30340;&#23454;&#35777;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#28183;&#36879;&#21040;&#29616;&#20195;&#29983;&#27963;&#20013;&#65292;&#22609;&#36896;&#20102;&#25105;&#20204;&#35835;&#20160;&#20040;&#23186;&#20307;&#21644;&#28040;&#36153;&#20160;&#20040;&#20135;&#21697;&#12290;&#39537;&#21160;&#27492;&#31867;&#31995;&#32479;&#30340;&#31639;&#27861;&#24448;&#24448;&#21253;&#25324;&#22522;&#20110;&#30417;&#30563;&#23398;&#20064;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#20363;&#22914;&#20855;&#26377;&#22810;&#31181;&#21551;&#21457;&#24335;&#36873;&#25321;&#30340;&#28508;&#22312;&#22240;&#32032;&#27169;&#22411;&#12290;&#21516;&#26102;&#65292;&#26377;&#20851;&#25512;&#33616;&#30340;&#29702;&#35770;&#22788;&#29702;&#36890;&#24120;&#28041;&#21450;&#38382;&#39064;&#30340;&#20915;&#31574;&#29702;&#35770;&#24615;&#36136;&#65292;&#21253;&#25324;&#36890;&#36807;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#26694;&#26550;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#30340;&#38656;&#35201;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;MAB&#30340;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;&#20551;&#35774;&#12290;&#36825;&#20123;&#20559;&#22909;&#20551;&#35774;&#24456;&#23569;&#20351;&#29992;&#20154;&#21592;&#30740;&#31350;&#36827;&#34892;&#27979;&#35797;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#32570;&#20047;&#20844;&#24320;&#21487;&#29992;&#30340;&#24037;&#20855;&#21253;&#26469;&#36827;&#34892;&#36825;&#20123;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#28459;&#30011;&#25512;&#33616;MAB&#35774;&#32622;&#20013;&#19982;&#20247;&#21253;&#24037;&#20316;&#32773;&#36827;&#34892;&#30740;&#31350;&#12290;&#27599;&#20010;&#26426;&#22120;&#33218;&#34920;&#31034;&#19968;&#20010;&#28459;&#30011;&#31867;&#21035;&#65292;&#29992;&#25143;&#22312;&#27599;&#27425;&#25512;&#33616;&#21518;&#25552;&#20379;&#21453;&#39304;&#12290;&#25105;&#20204;&#26816;&#26597;&#20102;&#20851;&#38190;MAB&#20551;&#35774;&#30340;&#26377;&#25928;&#24615;&#65292;&#21363;&#20154;&#31867;&#20559;&#22909;&#26159;&#26102;&#31354;&#20855;&#26377;&#38745;&#24577;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#24314;&#27169;&#20026;&#28508;&#22312;&#25910;&#30410;&#20998;&#24067;&#30340;&#22024;&#26434;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#25361;&#25112;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#24378;&#35843;&#20102;&#38656;&#35201;&#36827;&#34892;&#26356;&#22810;&#20851;&#20110;MAB&#25512;&#33616;&#20013;&#36825;&#20123;&#20551;&#35774;&#30340;&#23454;&#35777;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized recommender systems suffuse modern life, shaping what media we read and what products we consume. Algorithms powering such systems tend to consist of supervised learning-based heuristics, such as latent factor models with a variety of heuristically chosen prediction targets. Meanwhile, theoretical treatments of recommendation frequently address the decision-theoretic nature of the problem, including the need to balance exploration and exploitation, via the multi-armed bandits (MABs) framework. However, MAB-based approaches rely heavily on assumptions about human preferences. These preference assumptions are seldom tested using human subject studies, partly due to the lack of publicly available toolkits to conduct such studies. In this work, we conduct a study with crowdworkers in a comics recommendation MABs setting. Each arm represents a comic category, and users provide feedback after each recommendation. We check the validity of core MABs assumptions-that human preferen
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MDDL&#30340;&#22810;&#36890;&#36947;&#28145;&#24230;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#25972;&#21512;&#22810;&#31181;&#31574;&#30053;&#65292;&#20197;&#22686;&#24378;&#20301;&#32622;&#20998;&#37197;&#30340;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12290;&#35813;&#26694;&#26550;&#22312;&#22312;&#32447;&#21644;&#31163;&#32447;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#19968;&#20123;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.09087</link><description>&lt;p&gt;
MDDL: &#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#22810;&#36890;&#36947;Feed&#20301;&#32622;&#20998;&#37197;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MDDL: A Framework for Reinforcement Learning-based Position Allocation in Multi-Channel Feed. (arXiv:2304.09087v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MDDL&#30340;&#22810;&#36890;&#36947;&#28145;&#24230;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#25972;&#21512;&#22810;&#31181;&#31574;&#30053;&#65292;&#20197;&#22686;&#24378;&#20301;&#32622;&#20998;&#37197;&#30340;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12290;&#35813;&#26694;&#26550;&#22312;&#22312;&#32447;&#21644;&#31163;&#32447;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#19968;&#20123;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#20301;&#32622;&#20998;&#37197;&#31995;&#32479;&#30340;&#20027;&#27969;&#26041;&#27861;&#26159;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#20026;&#21508;&#36890;&#36947;&#30340;&#29289;&#21697;&#20998;&#37197;&#21512;&#36866;&#30340;&#20301;&#32622;&#65292;&#28982;&#21518;&#28151;&#21512;&#21040;Feed&#20013;&#12290;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#20351;&#29992;&#20004;&#31181;&#25968;&#25454;&#65306;&#31574;&#30053;&#25968;&#25454;&#21644;&#38543;&#26426;&#25968;&#25454;&#12290;&#31574;&#30053;&#25968;&#25454;&#26469;&#33258;&#24403;&#21069;&#22312;&#32447;&#27169;&#22411;&#65292;&#23427;&#21463;&#21040;&#29366;&#24577;-&#21160;&#20316;&#23545;&#20998;&#24067;&#19981;&#22343;&#34913;&#30340;&#22256;&#25200;&#65292;&#23548;&#33268;&#35757;&#32451;&#36807;&#31243;&#20013;&#23384;&#22312;&#20005;&#37325;&#30340;&#39640;&#20272;&#38382;&#39064;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#38543;&#26426;&#25968;&#25454;&#25552;&#20379;&#20102;&#26356;&#22343;&#21248;&#30340;&#29366;&#24577;-&#21160;&#20316;&#23545;&#20998;&#24067;&#65292;&#20294;&#22312;&#24037;&#19994;&#22330;&#26223;&#20013;&#24456;&#38590;&#33719;&#21462;&#65292;&#22240;&#20026;&#38543;&#26426;&#25506;&#32034;&#21487;&#33021;&#20250;&#23545;&#24179;&#21488;&#25910;&#20837;&#21644;&#29992;&#25143;&#20307;&#39564;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#30001;&#20110;&#36825;&#20004;&#31181;&#25968;&#25454;&#20855;&#26377;&#19981;&#21516;&#30340;&#20998;&#24067;&#65292;&#22240;&#27492;&#35774;&#35745;&#19968;&#31181;&#26377;&#25928;&#30340;&#31574;&#30053;&#26469;&#21033;&#29992;&#20004;&#31181;&#25968;&#25454;&#20197;&#22686;&#24378;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#26524;&#24050;&#25104;&#20026;&#19968;&#20010;&#26497;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MDDL&#65288;&#22810;&#36890;&#36947;&#28145;&#24230;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#23398;&#20064;&#65289;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#26088;&#22312;&#25972;&#21512;&#22810;&#31181;&#31574;&#30053;&#65292;&#20197;&#22686;&#24378;&#20301;&#32622;&#20998;&#37197;&#30340;RL&#27169;&#22411;&#35757;&#32451;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#32447;&#21644;&#31163;&#32447;&#24615;&#33021;&#26041;&#38754;&#65292;MDDL&#34920;&#29616;&#20248;&#20110;&#19968;&#20123;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays, the mainstream approach in position allocation system is to utilize a reinforcement learning model to allocate appropriate locations for items in various channels and then mix them into the feed. There are two types of data employed to train reinforcement learning (RL) model for position allocation, named strategy data and random data. Strategy data is collected from the current online model, it suffers from an imbalanced distribution of state-action pairs, resulting in severe overestimation problems during training. On the other hand, random data offers a more uniform distribution of state-action pairs, but is challenging to obtain in industrial scenarios as it could negatively impact platform revenue and user experience due to random exploration. As the two types of data have different distributions, designing an effective strategy to leverage both types of data to enhance the efficacy of the RL model training has become a highly challenging problem. In this study, we propo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#26080;&#20559;&#35780;&#20998;&#24179;&#34913;&#24050;&#26377;&#30340;&#21435;&#20559;&#26041;&#27861;&#26469;&#23545;&#25239;&#26410;&#35266;&#27979;&#28151;&#28102;&#21644;&#27169;&#22411;&#35268;&#33539;&#35823;&#24046;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.09085</link><description>&lt;p&gt;
&#21033;&#29992;&#23569;&#37327;&#26080;&#20559;&#35780;&#20998;&#24179;&#34913;&#26410;&#35266;&#27979;&#28151;&#28102;&#30340;&#21435;&#20559;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Balancing Unobserved Confounding with a Few Unbiased Ratings in Debiased Recommendations. (arXiv:2304.09085v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09085
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#26080;&#20559;&#35780;&#20998;&#24179;&#34913;&#24050;&#26377;&#30340;&#21435;&#20559;&#26041;&#27861;&#26469;&#23545;&#25239;&#26410;&#35266;&#27979;&#28151;&#28102;&#21644;&#27169;&#22411;&#35268;&#33539;&#35823;&#24046;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#34987;&#35270;&#20026;&#35299;&#20915;&#20449;&#24687;&#36807;&#36733;&#30340;&#26377;&#25928;&#24037;&#20855;&#65292;&#20294;&#20247;&#25152;&#21608;&#30693;&#65292;&#23384;&#22312;&#21508;&#31181;&#20559;&#24046;&#20351;&#24471;&#22312;&#22823;&#35268;&#27169;&#35266;&#27979;&#25968;&#25454;&#19978;&#36827;&#34892;&#30452;&#25509;&#35757;&#32451;&#20250;&#23548;&#33268;&#27425;&#20248;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;&#20174;&#38543;&#26426;&#25511;&#21046;&#35797;&#39564;&#25110;A/B&#27979;&#35797;&#20013;&#33719;&#24471;&#30340;&#26080;&#20559;&#35780;&#20998;&#34987;&#35748;&#20026;&#26159;&#40644;&#37329;&#26631;&#20934;&#65292;&#20294;&#22312;&#29616;&#23454;&#20013;&#25104;&#26412;&#39640;&#19988;&#35268;&#27169;&#36739;&#23567;&#12290;&#20026;&#20102;&#21033;&#29992;&#36825;&#20004;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#21033;&#29992;&#26080;&#20559;&#35780;&#20998;&#26469;&#20462;&#27491;&#22312;&#26377;&#20559;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#20542;&#21521;&#24615;&#25110;&#25554;&#34917;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#23384;&#22312;&#26410;&#35266;&#27979;&#28151;&#28102;&#25110;&#27169;&#22411;&#35268;&#33539;&#35823;&#24046;&#26102;&#26080;&#27861;&#33719;&#24471;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#19978;&#20445;&#35777;&#30340;&#27169;&#22411;&#19981;&#21487;&#30693;&#24179;&#34913;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;&#29616;&#26377;&#30340;&#21435;&#20559;&#26041;&#27861;&#65292;&#26088;&#22312;&#23545;&#25239;&#26410;&#35266;&#27979;&#28151;&#28102;&#21644;&#27169;&#22411;&#35268;&#33539;&#35823;&#24046;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20805;&#20998;&#21033;&#29992;&#20102;&#26080;&#20559;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are seen as an effective tool to address information overload, but it is widely known that the presence of various biases makes direct training on large-scale observational data result in sub-optimal prediction performance. In contrast, unbiased ratings obtained from randomized controlled trials or A/B tests are considered to be the golden standard, but are costly and small in scale in reality. To exploit both types of data, recent works proposed to use unbiased ratings to correct the parameters of the propensity or imputation models trained on the biased dataset. However, the existing methods fail to obtain accurate predictions in the presence of unobserved confounding or model misspecification. In this paper, we propose a theoretically guaranteed model-agnostic balancing approach that can be applied to any existing debiasing method with the aim of combating unobserved confounding and model misspecification. The proposed approach makes full use of unbiased data by 
&lt;/p&gt;</description></item><item><title>DRIFT&#26159;&#19968;&#20010;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#26550;&#26500;&#65292;&#20351;&#29992;&#38544;&#24335;&#21453;&#39304;&#65292;&#20197;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#65292;&#24182;&#20351;&#29992;SAROS&#31639;&#27861;&#23454;&#29616;&#31934;&#20934;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2304.09084</link><description>&lt;p&gt;
DRIFT: &#19968;&#31181;&#22522;&#20110;&#38544;&#24335;&#21453;&#39304;&#30340;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
DRIFT: A Federated Recommender System with Implicit Feedback on the Items. (arXiv:2304.09084v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09084
&lt;/p&gt;
&lt;p&gt;
DRIFT&#26159;&#19968;&#20010;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#26550;&#26500;&#65292;&#20351;&#29992;&#38544;&#24335;&#21453;&#39304;&#65292;&#20197;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#65292;&#24182;&#20351;&#29992;SAROS&#31639;&#27861;&#23454;&#29616;&#31934;&#20934;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#22312;&#32593;&#32476;&#19978;&#21487;&#29992;&#30340;&#29289;&#21697;&#36234;&#26469;&#36234;&#22810;&#65292;&#36825;&#20351;&#24471;&#29992;&#25143;&#24456;&#38590;&#25214;&#21040;&#20182;&#20204;&#21916;&#27426;&#30340;&#29289;&#21697;&#12290;&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#20351;&#29992;&#29992;&#25143;&#30340;&#21382;&#21490;&#20132;&#20114;&#26469;&#25214;&#21040;&#26368;&#36866;&#21512;&#29992;&#25143;&#30340;&#29289;&#21697;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20132;&#20114;&#21487;&#33021;&#26356;&#25110;&#26356;&#23569;&#25935;&#24863;&#65292;&#24182;&#25910;&#38598;&#23427;&#20204;&#28041;&#21450;&#21040;&#29992;&#25143;&#38544;&#31169;&#30340;&#38382;&#39064;&#12290;&#32852;&#37030;&#31995;&#32479;&#24050;&#32463;&#26174;&#31034;&#20986;&#21363;&#20351;&#22312;&#19981;&#23384;&#20648;&#29992;&#25143;&#20010;&#20154;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#36827;&#34892;&#20934;&#30830;&#21644;&#26377;&#25928;&#30340;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#20351;&#29992;&#29992;&#25143;&#30340;&#21363;&#26102;&#21453;&#39304;&#12290;&#22312;&#26412;&#25253;&#21578;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DRIFT&#65292;&#19968;&#31181;&#20351;&#29992;&#38544;&#24335;&#21453;&#39304;&#30340;&#32852;&#21512;&#25512;&#33616;&#31995;&#32479;&#26550;&#26500;&#12290;&#25105;&#20204;&#30340;&#23398;&#20064;&#27169;&#22411;&#22522;&#20110;&#26368;&#36817;&#29992;&#20110;&#38544;&#24335;&#21453;&#39304;&#25512;&#33616;&#30340;&#31639;&#27861;SAROS&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20351;&#25512;&#33616;&#19982;SAROS&#19968;&#26679;&#31934;&#30830;&#65292;&#21516;&#26102;&#19981;&#25439;&#23475;&#29992;&#25143;&#30340;&#38544;&#31169;&#12290;&#36890;&#36807;&#23454;&#39564;&#21644;&#25910;&#25947;&#24615;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;DRIFT&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays there are more and more items available online, this makes it hard for users to find items that they like. Recommender systems aim to find the item who best suits the user, using his historical interactions. Depending on the context, these interactions may be more or less sensitive and collecting them brings an important problem concerning the users' privacy. Federated systems have shown that it is possible to make accurate and efficient recommendations without storing users' personal information. However, these systems use instantaneous feedback from the user. In this report, we propose DRIFT, a federated architecture for recommender systems, using implicit feedback. Our learning model is based on a recent algorithm for recommendation with implicit feedbacks SAROS. We aim to make recommendations as precise as SAROS, without compromising the users' privacy. In this report we show that thanks to our experiments, but also thanks to a theoretical analysis on the convergence. We h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#20998;&#31867;&#26041;&#27861;&#65292;&#21363;&#23558;&#19968;&#32452;&#25991;&#20214;&#20998;&#25104;&#19981;&#21516;&#30340;&#26041;&#35328;&#65292;&#20854;&#20013;&#26041;&#35328;&#30001;&#20854;&#34892;&#20026;&#27169;&#24335;&#32452;&#25104;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#36138;&#24515;&#31639;&#27861;&#20174;&#25991;&#20214;-&#28040;&#24687;&#25968;&#25454;&#30697;&#38453;&#30340;&#25968;&#25454;&#38598;&#20013;&#25512;&#26029;&#20986;&#20505;&#36873;&#26041;&#35328;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#26159;&#26368;&#20248;&#26102;&#30340;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2304.09082</link><description>&lt;p&gt;
&#25353;&#29031;&#28151;&#21512;&#30340;&#21333;&#35843;&#20998;&#35299;&#26080;&#30417;&#30563;&#32858;&#31867;&#25991;&#20214;&#26041;&#35328;
&lt;/p&gt;
&lt;p&gt;
Unsupervised clustering of file dialects according to monotonic decompositions of mixtures. (arXiv:2304.09082v1 [cs.PL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#20998;&#31867;&#26041;&#27861;&#65292;&#21363;&#23558;&#19968;&#32452;&#25991;&#20214;&#20998;&#25104;&#19981;&#21516;&#30340;&#26041;&#35328;&#65292;&#20854;&#20013;&#26041;&#35328;&#30001;&#20854;&#34892;&#20026;&#27169;&#24335;&#32452;&#25104;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#36138;&#24515;&#31639;&#27861;&#20174;&#25991;&#20214;-&#28040;&#24687;&#25968;&#25454;&#30697;&#38453;&#30340;&#25968;&#25454;&#38598;&#20013;&#25512;&#26029;&#20986;&#20505;&#36873;&#26041;&#35328;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#26159;&#26368;&#20248;&#26102;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#20998;&#31867;&#26041;&#27861;&#65292;&#26681;&#25454;&#19968;&#32452;&#31243;&#24207;&#28040;&#32791;&#30340;&#28040;&#24687;&#65292;&#23558;&#19968;&#32452;&#25991;&#20214;&#20998;&#21106;&#20026;&#19981;&#37325;&#21472;&#30340;&#26041;&#35328;&#12290;&#28040;&#24687;&#30340;&#27169;&#24335;&#21487;&#20197;&#34987;&#29992;&#20316;&#29305;&#23450;&#34892;&#20026;&#30340;&#26631;&#24535;&#65292;&#26377;&#20123;&#28040;&#24687;&#21487;&#33021;&#20250;&#21516;&#26102;&#20986;&#29616;&#65292;&#32780;&#20854;&#20182;&#28040;&#24687;&#19981;&#20250;&#12290;&#28040;&#24687;&#27169;&#24335;&#21487;&#20197;&#29992;&#26469;&#23558;&#25991;&#20214;&#20998;&#31867;&#20026;&#19981;&#21516;&#26041;&#35328;&#12290;&#19968;&#20010;&#26041;&#35328;&#30001;&#23376;&#38598;&#28040;&#24687;&#20316;&#20026;&#24517;&#38656;&#28040;&#24687;&#26469;&#23450;&#20041;&#12290;&#19968;&#26086;&#23558;&#25991;&#20214;&#32622;&#20110;&#26041;&#35328;&#21450;&#20854;&#24517;&#38656;&#30340;&#28040;&#24687;&#20043;&#19979;&#65292;&#21097;&#19979;&#30340;&#28040;&#24687;&#21017;&#26159;&#32479;&#35745;&#29420;&#31435;&#30340;&#12290;&#26377;&#20102;&#36825;&#20010;&#26041;&#35328;&#23450;&#20041;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36138;&#24515;&#31639;&#27861;&#65292;&#20174;&#25991;&#20214;-&#28040;&#24687;&#25968;&#25454;&#30697;&#38453;&#30340;&#25968;&#25454;&#38598;&#20013;&#25512;&#26029;&#20986;&#20505;&#36873;&#26041;&#35328;&#12290;&#25991;&#31456;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#22312;&#22810;&#31181;&#25991;&#20214;&#26684;&#24335;&#19978;&#30340;&#25928;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#26159;&#26368;&#20248;&#26102;&#30340;&#26465;&#20214;&#12290;&#25991;&#31456;&#34920;&#26126;&#65292;&#20998;&#26512;&#21592;&#38656;&#35201;&#32771;&#34385;&#30340;&#26041;&#35328;&#27604;&#19981;&#21516;&#25991;&#20214;&#25152;&#38656;&#30340;&#32452;&#25968;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an unsupervised classification method that partitions a set of files into non-overlapping dialects based upon their behaviors, determined by messages produced by a collection of programs that consume them. The pattern of messages can be used as the signature of a particular kind of behavior, with the understanding that some messages are likely to co-occur, while others are not. Patterns of messages can be used to classify files into dialects. A dialect is defined by a subset of messages, called the required messages. Once files are conditioned upon dialect and its required messages, the remaining messages are statistically independent.  With this definition of dialect in hand, we present a greedy algorithm that deduces candidate dialects from a dataset consisting of a matrix of file-message data, demonstrate its performance on several file formats, and prove conditions under which it is optimal. We show that an analyst needs to consider fewer dialects than distinct 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;CTR&#39044;&#27979;&#30340;&#28418;&#31227;&#24863;&#30693;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#38598;&#25104;&#23398;&#20064;&#65292;&#36890;&#36807;&#26174;&#24335;&#30340;&#22522;&#20110;&#35823;&#24046;&#30340;&#28418;&#31227;&#26816;&#27979;&#26469;&#35299;&#20915;CTR&#39044;&#27979;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.09062</link><description>&lt;p&gt;
&#24635;&#26159;&#22686;&#24378;&#20320;&#30340;&#20248;&#21183;: &#19968;&#31181;&#38754;&#21521;CTR&#39044;&#27979;&#30340;&#28418;&#31227;&#24863;&#30693;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Always Strengthen Your Strengths: A Drift-Aware Incremental Learning Framework for CTR Prediction. (arXiv:2304.09062v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09062
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;CTR&#39044;&#27979;&#30340;&#28418;&#31227;&#24863;&#30693;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#38598;&#25104;&#23398;&#20064;&#65292;&#36890;&#36807;&#26174;&#24335;&#30340;&#22522;&#20110;&#35823;&#24046;&#30340;&#28418;&#31227;&#26816;&#27979;&#26469;&#35299;&#20915;CTR&#39044;&#27979;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575; (CTR) &#39044;&#27979;&#22312;&#25512;&#33616;&#31995;&#32479;&#21644;&#22312;&#32447;&#24191;&#21578;&#24179;&#21488;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#24037;&#19994;&#22330;&#26223;&#20013;&#20351;&#29992;&#26102;&#65292;CTR &#27169;&#22411;&#35266;&#23519;&#21040;&#30340;&#29992;&#25143;&#29983;&#25104;&#25968;&#25454;&#36890;&#24120;&#20197;&#27969;&#30340;&#24418;&#24335;&#21040;&#36798;&#12290;&#27969;&#24335;&#25968;&#25454;&#20855;&#26377;&#38543;&#30528;&#26102;&#38388;&#32780;&#28418;&#31227;&#24182;&#21487;&#33021;&#37325;&#29616;&#30340;&#29305;&#24615;&#12290;&#22914;&#26524;&#27169;&#22411;&#20165;&#36866;&#24212;&#20110;&#26032;&#25968;&#25454;&#20998;&#24067;&#65292;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#27492;&#22806;&#65292;&#37325;&#22797;&#23398;&#20064;&#24050;&#32463;&#20986;&#29616;&#30340;&#20998;&#24067;&#26159;&#20302;&#25928;&#30340;&#12290;&#30001;&#20110;&#20869;&#23384;&#38480;&#21046;&#21644;&#22823;&#35268;&#27169;&#24037;&#19994;&#24212;&#29992;&#20013;&#25968;&#25454;&#20998;&#24067;&#30340;&#22810;&#26679;&#24615;&#65292;&#20256;&#32479;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#31574;&#30053;&#65288;&#22914;&#37325;&#25918;&#12289;&#21442;&#25968;&#38548;&#31163;&#21644;&#30693;&#35782;&#33976;&#39311;&#65289;&#38590;&#20197;&#37096;&#32626;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#22522;&#20110;&#38598;&#25104;&#23398;&#20064;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#28418;&#31227;&#24863;&#30693;&#22686;&#37327;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;CTR&#39044;&#27979;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#36890;&#36807;&#23545;&#27969;&#25968;&#25454;&#36827;&#34892;&#26174;&#24335;&#22522;&#20110;&#35823;&#24046;&#30340;&#28418;&#31227;&#26816;&#27979;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#21457;&#29616;&#20998;&#24067;&#28418;&#31227;&#24182;&#26377;&#38024;&#23545;&#24615;&#22320;&#23398;&#20064;&#25968;&#25454;&#20998;&#24067;&#28418;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction is of great importance in recommendation systems and online advertising platforms. When served in industrial scenarios, the user-generated data observed by the CTR model typically arrives as a stream. Streaming data has the characteristic that the underlying distribution drifts over time and may recur. This can lead to catastrophic forgetting if the model simply adapts to new data distribution all the time. Also, it's inefficient to relearn distribution that has been occurred. Due to memory constraints and diversity of data distributions in large-scale industrial applications, conventional strategies for catastrophic forgetting such as replay, parameter isolation, and knowledge distillation are difficult to be deployed. In this work, we design a novel drift-aware incremental learning framework based on ensemble learning to address catastrophic forgetting in CTR prediction. With explicit error-based drift detection on streaming data, the framework fur
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#22522;&#20110;&#34920;&#31034;-&#32858;&#21512;&#31574;&#30053;&#26500;&#24314;&#21487;&#25193;&#23637;&#20294;&#26377;&#25928;&#30340;APC&#27169;&#22411;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#65292;&#21487;&#20197;&#21253;&#25324;&#21508;&#31181;&#34920;&#31034;&#23398;&#20064;&#21644;&#24207;&#21015;&#24314;&#27169;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2304.09061</link><description>&lt;p&gt;
&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#20013;&#33258;&#21160;&#29983;&#25104;&#25773;&#25918;&#21015;&#34920;&#30340;&#21487;&#25193;&#23637;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Scalable Framework for Automatic Playlist Continuation on Music Streaming Services. (arXiv:2304.09061v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#22522;&#20110;&#34920;&#31034;-&#32858;&#21512;&#31574;&#30053;&#26500;&#24314;&#21487;&#25193;&#23637;&#20294;&#26377;&#25928;&#30340;APC&#27169;&#22411;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#65292;&#21487;&#20197;&#21253;&#25324;&#21508;&#31181;&#34920;&#31034;&#23398;&#20064;&#21644;&#24207;&#21015;&#24314;&#27169;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#36890;&#24120;&#26088;&#22312;&#25512;&#33616;&#27468;&#26354;&#20197;&#25193;&#23637;&#29992;&#25143;&#22312;&#35813;&#26381;&#21153;&#19978;&#21019;&#24314;&#30340;&#25773;&#25918;&#21015;&#34920;&#12290;&#28982;&#32780;&#65292;&#22312;&#20445;&#30041;&#20854;&#38899;&#20048;&#29305;&#24449;&#21644;&#31526;&#21512;&#29992;&#25143;&#20542;&#21521;&#30340;&#24773;&#20917;&#19979;&#25193;&#23637;&#25773;&#25918;&#21015;&#34920;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#36890;&#24120;&#34987;&#31216;&#20026;&#33258;&#21160;&#25773;&#25918;&#21015;&#34920;&#24310;&#32493;&#65288;APC&#65289;&#12290;&#27492;&#22806;&#65292;&#23613;&#31649;&#36825;&#20123;&#26381;&#21153;&#32463;&#24120;&#38656;&#35201;&#22312;&#22823;&#22411;&#30446;&#24405;&#20013;&#23454;&#26102;&#36873;&#25321;&#26368;&#20339;&#27468;&#26354;&#36827;&#34892;&#25512;&#33616;&#65292;&#20294;&#26368;&#36817;&#20851;&#20110;APC&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20855;&#26377;&#23569;&#37327;&#21487;&#25193;&#23637;&#24615;&#20445;&#35777;&#24182;&#22312;&#30456;&#23545;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35780;&#20272;&#30340;&#27169;&#22411;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#30340;&#21487;&#25193;&#23637;&#20294;&#26377;&#25928;&#30340;APC&#27169;&#22411;&#12290;&#22522;&#20110;&#34920;&#31034;-&#32858;&#21512;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#35774;&#35745;&#30830;&#20445;&#21487;&#25193;&#23637;&#24615;&#65292;&#21516;&#26102;&#36275;&#22815;&#28789;&#27963;&#65292;&#21487;&#20197;&#21253;&#21547;&#21508;&#31181;&#34920;&#31034;&#23398;&#20064;&#21644;&#24207;&#21015;&#24314;&#27169;&#25216;&#26415;&#65292;&#20363;&#22914;&#22522;&#20110;Transformer&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#21644;&#24773;&#20917;&#19979;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26694;&#26550;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Music streaming services often aim to recommend songs for users to extend the playlists they have created on these services. However, extending playlists while preserving their musical characteristics and matching user preferences remains a challenging task, commonly referred to as Automatic Playlist Continuation (APC). Besides, while these services often need to select the best songs to recommend in real-time and among large catalogs with millions of candidates, recent research on APC mainly focused on models with few scalability guarantees and evaluated on relatively small datasets. In this paper, we introduce a general framework to build scalable yet effective APC models for large-scale applications. Based on a represent-then-aggregate strategy, it ensures scalability by design while remaining flexible enough to incorporate a wide range of representation learning and sequence modeling techniques, e.g., based on Transformers. We demonstrate the relevance of this framework through in-
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#32467;&#21512;k-NN&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#33021;&#22815;&#25552;&#39640;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.09058</link><description>&lt;p&gt;
&#37325;&#35775;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;k-NN
&lt;/p&gt;
&lt;p&gt;
Revisiting k-NN for Pre-trained Language Models. (arXiv:2304.09058v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#32467;&#21512;k-NN&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#33021;&#22815;&#25552;&#39640;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#20316;&#20026;&#21442;&#25968;&#21270;&#30340;&#24613;&#20999;&#23398;&#20064;&#22120;&#65292;&#24050;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24403;&#21069;&#33539;&#24335;&#30340;&#23454;&#38469;&#36873;&#25321;&#12290;&#19982;&#27492;&#24418;&#25104;&#23545;&#27604;&#30340;&#26159;&#65292;k-&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#20998;&#31867;&#22120;&#20316;&#20026;&#24310;&#36831;&#23398;&#20064;&#27169;&#22411;&#65292;&#20542;&#21521;&#20110;&#20943;&#36731;&#36807;&#25311;&#21512;&#21644;&#23396;&#31435;&#22122;&#22768;&#12290;&#26412;&#25991;&#20013;&#25105;&#20204;&#37325;&#35775;&#20102;k-NN&#20998;&#31867;&#22120;&#65292;&#20197;&#22686;&#24378;&#22522;&#20110;PLMs&#30340;&#20998;&#31867;&#22120;&#12290;&#20174;&#26041;&#27861;&#23618;&#38754;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#37319;&#29992;&#25991;&#26412;&#34920;&#31034;&#30340;PLMs&#22312;&#20004;&#20010;&#27493;&#39588;&#20013;&#37319;&#29992;k-NN&#65306;&#65288;1&#65289;&#21033;&#29992;k-NN&#20316;&#20026;&#20808;&#39564;&#30693;&#35782;&#26469;&#26657;&#20934;&#35757;&#32451;&#36807;&#31243;&#65288;2&#65289;&#32447;&#24615;&#25554;&#20540;k-NN&#39044;&#27979;&#30340;&#27010;&#29575;&#20998;&#24067;&#21644;PLMs&#20998;&#31867;&#22120;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26680;&#24515;&#26159;&#23454;&#29616;&#20102;k-NN&#26657;&#20934;&#35757;&#32451;&#65292;&#23558;&#39044;&#27979;&#32467;&#26524;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#20013;&#26131;&#20110;&#21644;&#38590;&#20197;&#23398;&#20064;&#30340;&#31034;&#20363;&#30340;&#25351;&#26631;&#12290;&#20174;&#24212;&#29992;&#22330;&#26223;&#22810;&#26679;&#24615;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#24494;&#35843;&#12289;&#25552;&#31034;&#24494;&#35843;&#33539;&#24335;&#21644;&#38646;&#26679;&#26412;&#20219;&#21153;&#35774;&#32622;&#30340;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#32467;&#21512;k-NN&#21487;&#20197;&#22312;&#25152;&#26377;&#21463;&#21040;&#26816;&#26597;&#30340;&#35774;&#32622;&#20013;&#25345;&#32493;&#25552;&#39640;PLMs&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#25152;&#26377;&#21463;&#21040;&#32771;&#34385;&#30340;&#35774;&#32622;&#20013;&#36305;&#36194;&#20102;&#22522;&#20110;&#26222;&#36890;PLMs&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained Language Models (PLMs), as parametric-based eager learners, have become the de-facto choice for current paradigms of Natural Language Processing (NLP). In contrast, k-Nearest-Neighbor (k-NN) classifiers, as the lazy learning paradigm, tend to mitigate over-fitting and isolated noise. In this paper, we revisit k-NN classifiers for augmenting the PLMs-based classifiers. From the methodological level, we propose to adopt k-NN with textual representations of PLMs in two steps: (1) Utilize k-NN as prior knowledge to calibrate the training process. (2) Linearly interpolate the probability distribution predicted by k-NN with that of the PLMs' classifier. At the heart of our approach is the implementation of k-NN-calibrated training, which treats predicted results as indicators for easy versus hard examples during the training process. From the perspective of the diversity of application scenarios, we conduct extensive experiments on fine-tuning, prompt-tuning paradigms and zero-sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22788;&#29702;&#29983;&#25104;&#24335;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#20869;&#30340;&#35821;&#20041;&#32467;&#26500;&#65292;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.09048</link><description>&lt;p&gt;
CodeKGC&#65306;&#29992;&#20110;&#29983;&#25104;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#30340;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
CodeKGC: Code Language Model for Generative Knowledge Graph Construction. (arXiv:2304.09048v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22788;&#29702;&#29983;&#25104;&#24335;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#20869;&#30340;&#35821;&#20041;&#32467;&#26500;&#65292;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#30340;&#29983;&#25104;&#24335;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#26041;&#27861;&#36890;&#24120;&#26080;&#27861;&#25429;&#25417;&#32467;&#26500;&#24615;&#30693;&#35782;&#65292;&#32780;&#21482;&#26159;&#23558;&#33258;&#28982;&#35821;&#35328;&#36716;&#21270;&#20026;&#24207;&#21015;&#21270;&#25991;&#26412;&#25110;&#35268;&#33539;&#35821;&#35328;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20687;&#20195;&#30721;&#36825;&#26679;&#30340;&#32467;&#26500;&#21270;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#22823;&#22411;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20102;&#22312;&#29702;&#35299;&#33258;&#28982;&#35821;&#35328;&#20197;&#36827;&#34892;&#32467;&#26500;&#24615;&#39044;&#27979;&#21644;&#25512;&#29702;&#20219;&#21153;&#26041;&#38754;&#30340;&#21331;&#36234;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22788;&#29702;&#29983;&#25104;&#24335;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#32473;&#23450;&#20195;&#30721;&#26684;&#24335;&#30340;&#33258;&#28982;&#35821;&#35328;&#36755;&#20837;&#30340;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#26159;&#29983;&#25104;&#21487;&#20197;&#34920;&#31034;&#20026;&#20195;&#30721;&#34917;&#20840;&#20219;&#21153;&#30340;&#19977;&#20803;&#32452;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#20855;&#26377;&#27169;&#24335;&#24863;&#30693;&#22411;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#20869;&#30340;&#35821;&#20041;&#32467;&#26500;&#12290;&#30001;&#20110;&#20195;&#30721;&#26412;&#36136;&#19978;&#20855;&#26377;&#32467;&#26500;&#65292;&#22914;&#31867;&#21644;&#20989;&#25968;&#23450;&#20041;&#65292;&#22240;&#27492;&#23427;&#20316;&#20026;&#20808;&#39564;&#30340;&#35821;&#20041;&#32467;&#26500;&#30693;&#35782;&#27169;&#22411;&#38750;&#24120;&#26377;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#22522;&#20110;&#21407;&#29702;&#30340;&#29983;&#25104;&#26041;&#27861;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#21407;&#29702;&#25552;&#20379;&#20102;&#27169;&#22411;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current generative knowledge graph construction approaches usually fail to capture structural knowledge by simply flattening natural language into serialized texts or a specification language. However, large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks. Intuitively, we address the task of generative knowledge graph construction with code language model: given a code-format natural language input, the target is to generate triples which can be represented as code completion tasks. Specifically, we develop schema-aware prompts that effectively utilize the semantic structure within the knowledge graph. As code inherently possesses structure, such as class and function definitions, it serves as a useful model for prior semantic structural knowledge. Furthermore, we employ a rationale-enhanced generation method to boost the performance. Rationales provi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#24369;&#30417;&#30563;&#23398;&#20064;(GWS)&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#33021;&#22815;&#36845;&#20195;&#22320;&#20351;&#29992;&#29616;&#26377;&#30340;&#25490;&#24207;&#27169;&#22411;(&#24369;&#26631;&#27880;&#22120;)&#20135;&#29983;&#22823;&#37327;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#26080;&#38656;&#25163;&#21160;&#26631;&#27880;&#23601;&#33021;&#26174;&#33879;&#25552;&#39640;&#25490;&#24207;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.08912</link><description>&lt;p&gt;
&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#30340;&#24191;&#20041;&#24369;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Weak Supervision for Neural Information Retrieval. (arXiv:2304.08912v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#24369;&#30417;&#30563;&#23398;&#20064;(GWS)&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#33021;&#22815;&#36845;&#20195;&#22320;&#20351;&#29992;&#29616;&#26377;&#30340;&#25490;&#24207;&#27169;&#22411;(&#24369;&#26631;&#27880;&#22120;)&#20135;&#29983;&#22823;&#37327;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#26080;&#38656;&#25163;&#21160;&#26631;&#27880;&#23601;&#33021;&#26174;&#33879;&#25552;&#39640;&#25490;&#24207;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;(NRM)&#22312;&#22810;&#20010;&#20449;&#24687;&#26816;&#32034;(IR)&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#26377;&#25928;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#35757;&#32451;NRM&#36890;&#24120;&#38656;&#35201;&#22823;&#35268;&#27169;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#36825;&#24456;&#38590;&#19988;&#26114;&#36149;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21487;&#20197;&#36890;&#36807;&#24369;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#24335;&#26469;&#35757;&#32451;NRM&#65292;&#20854;&#20013;&#20351;&#29992;&#29616;&#26377;&#30340;&#25490;&#24207;&#27169;&#22411;(&#31216;&#20026;&#24369;&#26631;&#27880;&#22120;)&#33258;&#21160;&#20135;&#29983;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;NRM&#12290;&#24369;&#30417;&#30563;&#30340;NRM&#21487;&#20197;&#20174;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#20013;&#25512;&#24191;&#65292;&#24182;&#26174;&#33879;&#20248;&#20110;&#24369;&#26631;&#27880;&#22120;&#12290;&#26412;&#25991;&#36890;&#36807;&#36845;&#20195;&#30340;&#37325;&#26032;&#26631;&#27880;&#36807;&#31243;&#23545;&#36825;&#20010;&#24819;&#27861;&#36827;&#34892;&#20102;&#25512;&#24191;&#65292;&#35777;&#26126;&#20102;&#24369;&#30417;&#30563;&#27169;&#22411;&#21487;&#20197;&#36845;&#20195;&#22320;&#25198;&#28436;&#24369;&#26631;&#27880;&#22120;&#30340;&#35282;&#33394;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#20351;&#29992;&#24050;&#25163;&#21160;&#26631;&#27880;&#30340;&#25968;&#25454;&#23601;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#25490;&#24207;&#24615;&#33021;&#12290;&#25152;&#25552;&#20986;&#30340;&#24191;&#20041;&#24369;&#30417;&#30563;&#23398;&#20064;(GWS)&#35299;&#20915;&#26041;&#26696;&#26159;&#36890;&#29992;&#30340;&#65292;&#24182;&#19988;&#19982;&#25490;&#24207;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#30456;&#20114;&#29420;&#31435;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#22235;&#20010;GWS&#30340;&#23454;&#29616;&#65306;&#33258;&#25105;&#26631;&#27880;&#12289;&#36328;&#26631;&#27880;&#12289;&#32852;&#21512;&#36328;&#26631;&#27880;&#21644;&#33258;&#25105;&#26631;&#27880;&#12289;&#33258;&#20030;&#27861;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;GWS&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#24182;&#19982;&#20840;&#30417;&#30563;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural ranking models (NRMs) have demonstrated effective performance in several information retrieval (IR) tasks. However, training NRMs often requires large-scale training data, which is difficult and expensive to obtain. To address this issue, one can train NRMs via weak supervision, where a large dataset is automatically generated using an existing ranking model (called the weak labeler) for training NRMs. Weakly supervised NRMs can generalize from the observed data and significantly outperform the weak labeler. This paper generalizes this idea through an iterative re-labeling process, demonstrating that weakly supervised models can iteratively play the role of weak labeler and significantly improve ranking performance without using manually labeled data. The proposed Generalized Weak Supervision (GWS) solution is generic and orthogonal to the ranking model architecture. This paper offers four implementations of GWS: self-labeling, cross-labeling, joint cross- and self-labeling, and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#21452;&#31890;&#24230;&#23545;&#27604;&#23398;&#20064;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#22810;&#31890;&#24230;CL&#26694;&#26550;&#21644;&#26032;&#30340;CL&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#20250;&#35805;&#20043;&#38388;&#24494;&#23567;&#30340;&#24046;&#24322;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.08873</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#31890;&#24230;&#23545;&#27604;&#23398;&#20064;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Dual-Ganularity Contrastive Learning for Session-based Recommendation. (arXiv:2304.08873v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08873
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#21452;&#31890;&#24230;&#23545;&#27604;&#23398;&#20064;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#22810;&#31890;&#24230;CL&#26694;&#26550;&#21644;&#26032;&#30340;CL&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#20250;&#35805;&#20043;&#38388;&#24494;&#23567;&#30340;&#24046;&#24322;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#65288;SBRS&#65289;&#22312;&#24403;&#21069;&#30005;&#23376;&#21830;&#21153;&#21644;&#27969;&#23186;&#20307;&#25512;&#33616;&#22330;&#26223;&#20013;&#26356;&#36866;&#29992;&#65292;&#22240;&#27492;&#25104;&#20026;&#20102;&#28909;&#38376;&#35805;&#39064;&#12290;SBRS&#36935;&#21040;&#30340;&#25968;&#25454;&#36890;&#24120;&#38750;&#24120;&#31232;&#30095;&#65292;&#20063;&#26159;&#38480;&#21046;&#25512;&#33616;&#20934;&#30830;&#24230;&#30340;&#29942;&#39048;&#20043;&#19968;&#12290;&#22240;&#27492;&#65292;&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#22312;SBRS&#20013;&#24212;&#29992;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#22312;&#31232;&#30095;&#25968;&#25454;&#26465;&#20214;&#19979;&#25913;&#21892;&#23884;&#20837;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;CL&#31574;&#30053;&#22312;&#24378;&#21046;&#25191;&#34892;&#26356;&#32454;&#31890;&#24230;&#65288;&#20363;&#22914;&#65292;&#22240;&#32032;&#32423;&#65289;&#27604;&#36739;&#26041;&#38754;&#33021;&#21147;&#26377;&#38480;&#65292;&#22240;&#27492;&#26080;&#27861;&#25429;&#25417;&#23454;&#20363;&#20043;&#38388;&#30340;&#24494;&#23567;&#24046;&#24322;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#36825;&#20123;&#31574;&#30053;&#36890;&#24120;&#20351;&#29992;&#39033;&#30446;&#25110;&#29255;&#27573;&#38543;&#26426;&#21024;&#38500;&#20316;&#20026;&#25968;&#25454;&#22686;&#24378;&#30340;&#25163;&#27573;&#65292;&#21487;&#33021;&#23548;&#33268;&#25968;&#25454;&#26356;&#31232;&#30095;&#65292;&#20174;&#32780;&#26080;&#25928;&#22320;&#33258;&#25105;&#30417;&#30563;&#20449;&#21495;&#12290;&#36890;&#36807;&#35299;&#20915;&#19978;&#36848;&#20004;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#24230;CL&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#20855;&#26377;&#21452;&#37325;&#31890;&#24230;&#30340;&#20004;&#20010;&#39069;&#22806;&#30340;&#23884;&#20837;&#21367;&#31215;&#36890;&#36947;&#21512;&#24182;&#21040;&#32593;&#32476;&#20013;&#65292;&#20351;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#20250;&#35805;&#30340;&#26412;&#22320;&#39033;&#30446;&#21644;&#20840;&#23616;&#22240;&#32032;&#20449;&#24687;&#30340;&#20849;&#20139;&#21644;&#21028;&#21035;&#34920;&#31034;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CL&#31574;&#30053;&#65292;&#20351;&#29992;&#33258;&#25105;&#30417;&#30563;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#26469;&#24378;&#21046;&#25191;&#34892;&#32454;&#31890;&#24230;&#27604;&#36739;&#12290;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#20250;&#35805;&#20043;&#38388;&#30340;&#24494;&#23567;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Session-based recommendation systems(SBRS) are more suitable for the current e-commerce and streaming media recommendation scenarios and thus have become a hot topic. The data encountered by SBRS is typically highly sparse, which also serves as one of the bottlenecks limiting the accuracy of recommendations. So Contrastive Learning(CL) is applied in SBRS owing to its capability of improving embedding learning under the condition of sparse data. However, existing CL strategies are limited in their ability to enforce finer-grained (e.g., factor-level) comparisons and, as a result, are unable to capture subtle differences between instances. More than that, these strategies usually use item or segment dropout as a means of data augmentation which may result in sparser data and thus ineffective self-supervised signals. By addressing the two aforementioned limitations, we introduce a novel multi-granularity CL framework. Specifically, two extra augmented embedding convolution channels with d
&lt;/p&gt;</description></item><item><title>eTOP&#26694;&#26550;&#21487;&#20197;&#22312;&#20219;&#20309;AutoML&#31995;&#32479;&#20043;&#19978;&#24037;&#20316;&#65292;&#24182;&#20915;&#23450;&#26159;&#21542;&#23558;&#25191;&#34892;&#31649;&#36947;&#21040;&#26368;&#21518;&#25110;&#22312;&#20013;&#38388;&#27493;&#39588;&#32456;&#27490;&#20197;&#26356;&#24555;&#22320;&#35757;&#32451;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2304.08597</link><description>&lt;p&gt;
eTOP&#65306;&#29992;&#20110;&#26356;&#24555;&#22320;&#35757;&#32451;AutoML&#31995;&#32479;&#30340;&#31649;&#36947;&#25552;&#21069;&#32456;&#27490;
&lt;/p&gt;
&lt;p&gt;
eTOP: Early Termination of Pipelines for Faster Training of AutoML Systems. (arXiv:2304.08597v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08597
&lt;/p&gt;
&lt;p&gt;
eTOP&#26694;&#26550;&#21487;&#20197;&#22312;&#20219;&#20309;AutoML&#31995;&#32479;&#20043;&#19978;&#24037;&#20316;&#65292;&#24182;&#20915;&#23450;&#26159;&#21542;&#23558;&#25191;&#34892;&#31649;&#36947;&#21040;&#26368;&#21518;&#25110;&#22312;&#20013;&#38388;&#27493;&#39588;&#32456;&#27490;&#20197;&#26356;&#24555;&#22320;&#35757;&#32451;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#21644;&#30828;&#20214;&#25216;&#26415;&#30340;&#26368;&#26032;&#36827;&#23637;&#20351;&#24471;AI/ML&#27169;&#22411;&#21487;&#20197;&#24212;&#29992;&#21040;&#26085;&#24120;&#24212;&#29992;&#20013;&#65292;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#25152;&#25552;&#20379;&#26381;&#21153;&#30340;&#36136;&#37327;&#12290;&#20294;&#26159;&#23545;&#20110;&#32473;&#23450;&#30340;&#24212;&#29992;&#31243;&#24207;&#65292;&#25214;&#21040;&#21512;&#36866;&#30340;AI/ML&#27169;&#22411;&#26159;&#19968;&#20010;&#22797;&#26434;&#32780;&#26114;&#36149;&#30340;&#36807;&#31243;&#65292;&#28041;&#21450;&#22810;&#20010;&#30456;&#20114;&#20851;&#32852;&#30340;&#27493;&#39588;&#65288;&#31216;&#20026;&#31649;&#36947;&#65289;&#65292;&#22914;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#29305;&#24449;&#24037;&#31243;&#12289;&#36873;&#25321;&#21644;&#27169;&#22411;&#35843;&#25972;&#30340;&#29983;&#25104;&#12289;&#35757;&#32451;&#21644;&#35780;&#20272;&#31561;&#12290;&#36825;&#20123;&#31649;&#36947;&#22312;&#32467;&#26500;&#19978;&#26159;&#22797;&#26434;&#30340;&#65292;&#22312;&#35745;&#31639;&#36164;&#28304;&#21644;&#26102;&#38388;&#19978;&#37117;&#24456;&#26114;&#36149;&#65292;&#24182;&#19982;&#27599;&#20010;&#27493;&#39588;&#30456;&#20851;&#32852;&#12290;AutoML&#31995;&#32479;&#33258;&#21160;&#25628;&#32034;&#36825;&#20123;&#36229;&#21442;&#25968;&#65292;&#20294;&#36895;&#24230;&#24456;&#24930;&#65292;&#22240;&#20026;&#23427;&#20204;&#20381;&#36182;&#20110;&#31649;&#36947;&#30340;&#26368;&#32456;&#36755;&#20986;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;eTOP&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#22312;&#20219;&#20309;AutoML&#31995;&#32479;&#20043;&#19978;&#24037;&#20316;&#65292;&#24182;&#20915;&#23450;&#26159;&#21542;&#23558;&#31649;&#36947;&#25191;&#34892;&#21040;&#26368;&#21518;&#25110;&#22312;&#20013;&#38388;&#27493;&#39588;&#32456;&#27490;&#12290;&#22312;26&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35780;&#20272;&#20197;&#21450;eTOP&#19982;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in software and hardware technologies have enabled the use of AI/ML models in everyday applications has significantly improved the quality of service rendered. However, for a given application, finding the right AI/ML model is a complex and costly process, that involves the generation, training, and evaluation of multiple interlinked steps (called pipelines), such as data pre-processing, feature engineering, selection, and model tuning. These pipelines are complex (in structure) and costly (both in compute resource and time) to execute end-to-end, with a hyper-parameter associated with each step. AutoML systems automate the search of these hyper-parameters but are slow, as they rely on optimizing the pipeline's end output. We propose the eTOP Framework which works on top of any AutoML system and decides whether or not to execute the pipeline to the end or terminate at an intermediate step. Experimental evaluation on 26 benchmark datasets and integration of eTOPwith 
&lt;/p&gt;</description></item><item><title>CAM2&#26159;&#19968;&#20010;&#38754;&#21521;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#33268;&#24615;&#24863;&#30693;&#22810;&#20219;&#21153;&#25490;&#21517;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#22240;&#26524;&#24314;&#27169;&#31995;&#32479;&#22320;&#35299;&#24320;&#29992;&#25143;&#23545;&#27969;&#34892;&#29289;&#21697;&#30340;&#19968;&#33268;&#24615;&#19982;&#20182;&#20204;&#30495;&#27491;&#20852;&#36259;&#30340;&#32852;&#31995;&#65292;&#26469;&#28040;&#38500;&#21382;&#21490;&#29992;&#25143;&#20132;&#20114;&#25968;&#25454;&#24102;&#26469;&#30340;&#19968;&#33268;&#24615;&#20559;&#35265;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#24471;&#21040;&#26377;&#25928;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.08562</link><description>&lt;p&gt;
CAM2: &#38754;&#21521;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#33268;&#24615;&#24863;&#30693;&#22810;&#20219;&#21153;&#25490;&#21517;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
CAM2: Conformity-Aware Multi-Task Ranking Model for Large-Scale Recommender Systems. (arXiv:2304.08562v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08562
&lt;/p&gt;
&lt;p&gt;
CAM2&#26159;&#19968;&#20010;&#38754;&#21521;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#33268;&#24615;&#24863;&#30693;&#22810;&#20219;&#21153;&#25490;&#21517;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#22240;&#26524;&#24314;&#27169;&#31995;&#32479;&#22320;&#35299;&#24320;&#29992;&#25143;&#23545;&#27969;&#34892;&#29289;&#21697;&#30340;&#19968;&#33268;&#24615;&#19982;&#20182;&#20204;&#30495;&#27491;&#20852;&#36259;&#30340;&#32852;&#31995;&#65292;&#26469;&#28040;&#38500;&#21382;&#21490;&#29992;&#25143;&#20132;&#20114;&#25968;&#25454;&#24102;&#26469;&#30340;&#19968;&#33268;&#24615;&#20559;&#35265;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#24471;&#21040;&#26377;&#25928;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#21382;&#21490;&#29992;&#25143;&#20132;&#20114;&#25968;&#25454;&#25311;&#21512;&#21040;&#22823;&#35268;&#27169;&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#20013;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#19968;&#33268;&#24615;&#20559;&#35265;&#65292;&#22240;&#20026;&#29992;&#25143;&#20852;&#36259;&#21487;&#33021;&#24456;&#38590;&#30830;&#23450;&#65292;&#32780;&#35768;&#22810;&#39033;&#30446;&#36890;&#24120;&#22522;&#20110;&#29983;&#24577;&#31995;&#32479;&#22240;&#32032;&#32780;&#19981;&#26159;&#19982;&#20010;&#20307;&#29992;&#25143;&#30456;&#20851;&#24615;&#20132;&#20114;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CAM2&#65292;&#36825;&#26159;&#19968;&#20010;&#19968;&#33268;&#24615;&#24863;&#30693;&#30340;&#22810;&#20219;&#21153;&#25490;&#21517;&#27169;&#22411;&#65292;&#26088;&#22312;&#20026;&#20854;&#20013;&#19968;&#20010;&#26368;&#22823;&#30340;&#24037;&#19994;&#25512;&#33616;&#24179;&#21488;&#21521;&#29992;&#25143;&#25552;&#20379;&#30456;&#20851;&#29289;&#21697;&#12290;CAM2&#36890;&#36807;&#21033;&#29992;&#22240;&#26524;&#24314;&#27169;&#31995;&#32479;&#22320;&#35299;&#24320;&#29992;&#25143;&#23545;&#27969;&#34892;&#29289;&#21697;&#30340;&#19968;&#33268;&#24615;&#19982;&#20182;&#20204;&#30495;&#27491;&#20852;&#36259;&#30340;&#32852;&#31995;&#12290;&#36825;&#20010;&#26694;&#26550;&#26159;&#21487;&#25512;&#24191;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#25193;&#23637;&#20197;&#25903;&#25345;&#22312;&#20219;&#20309;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22810;&#20010;&#19968;&#33268;&#24615;&#21644;&#29992;&#25143;&#30456;&#20851;&#24615;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20379;&#26356;&#28145;&#20837;&#30340;&#23454;&#36341;&#35265;&#35299;&#65292;&#24182;&#36890;&#36807;&#31163;&#32447;&#35780;&#20272;&#30340;&#25913;&#36827;&#26469;&#28436;&#31034;&#25152;&#25552;&#20986;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning large-scale industrial recommender system models by fitting them to historical user interaction data makes them vulnerable to conformity bias. This may be due to a number of factors, including the fact that user interests may be difficult to determine and that many items are often interacted with based on ecosystem factors other than their relevance to the individual user. In this work, we introduce CAM2, a conformity-aware multi-task ranking model to serve relevant items to users on one of the largest industrial recommendation platforms. CAM2 addresses these challenges systematically by leveraging causal modeling to disentangle users' conformity to popular items from their true interests. This framework is generalizable and can be scaled to support multiple representations of conformity and user relevance in any large-scale recommender system. We provide deeper practical insights and demonstrate the effectiveness of the proposed model through improvements in offline evaluatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32467;&#26500;&#21387;&#32553;&#21644;&#27169;&#22411;&#23610;&#23544;&#19981;&#23545;&#31216;&#30340;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411; KALE&#65292;&#26377;&#25928;&#25552;&#39640;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#30340;&#25512;&#29702;&#25928;&#29575;&#65292;&#21516;&#26102;&#20801;&#35768;&#26597;&#35810;&#32534;&#30721;&#22120;&#30340;&#26377;&#25928;&#21387;&#32553;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20840;&#37096;&#30340;&#20877;&#35757;&#32451;&#25110;&#32034;&#24341;&#29983;&#25104;&#65292;&#27492;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#36229;&#36807;DistilBERT&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2304.01016</link><description>&lt;p&gt;
&#24555;&#36895;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#22120;&#21033;&#29992;KALE&#36827;&#34892;&#21518;&#32622;KL&#23545;&#40784;&#30340;&#24322;&#24418;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411;&#35757;&#32451; (arXiv:2304.01016v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler Alignment of Embeddings for Asymmetrical dual encoders. (arXiv:2304.01016v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01016
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32467;&#26500;&#21387;&#32553;&#21644;&#27169;&#22411;&#23610;&#23544;&#19981;&#23545;&#31216;&#30340;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411; KALE&#65292;&#26377;&#25928;&#25552;&#39640;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#30340;&#25512;&#29702;&#25928;&#29575;&#65292;&#21516;&#26102;&#20801;&#35768;&#26597;&#35810;&#32534;&#30721;&#22120;&#30340;&#26377;&#25928;&#21387;&#32553;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20840;&#37096;&#30340;&#20877;&#35757;&#32451;&#25110;&#32034;&#24341;&#29983;&#25104;&#65292;&#27492;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#36229;&#36807;DistilBERT&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#32467;&#26500;&#21387;&#32553;&#21644;&#27169;&#22411;&#23610;&#23544;&#19981;&#23545;&#31216;&#30340;&#21452;&#32534;&#30721;&#22120;&#27169;&#22411;&#65292;&#26088;&#22312;&#25552;&#39640;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#30340;&#25512;&#29702;&#36895;&#24230;&#12290;&#36890;&#36807;&#23545;MSMARCO&#12289;&#33258;&#28982;&#38382;&#31572;&#12289;&#38382;&#31572;&#28216;&#25103;&#31561;&#22810;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#21069;&#21518;&#35757;&#32451;&#21387;&#32553;&#23454;&#39564;&#65292;&#30740;&#31350;&#20102;&#21387;&#32553;&#23545;&#31995;&#32479;&#25512;&#29702;&#25928;&#29575;&#30340;&#24433;&#21709;&#65292;&#32467;&#26524;&#34920;&#26126;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#22120;&#30340;&#21452;&#32534;&#30721;&#22120;&#32467;&#26500;&#24322;&#24418;&#21270;&#26377;&#21161;&#20110;&#25552;&#39640;&#20854;&#25512;&#29702;&#25928;&#29575;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;Kullback Leibler Alignment of Embeddings (KALE)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35009;&#21098;&#21644;&#23545;&#40784;&#26597;&#35810;&#32534;&#30721;&#22120;&#65292;&#25552;&#39640;&#20102;&#23494;&#38598;&#20449;&#24687;&#26816;&#32034;&#30340;&#25512;&#29702;&#25928;&#29575;&#12290;KALE&#25193;&#23637;&#20102;&#20256;&#32479;&#30340;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65292;&#20351;&#24471;&#22312;&#21452;&#32534;&#30721;&#22120;&#35757;&#32451;&#21518;&#21487;&#20197;&#26377;&#25928;&#22320;&#23545;&#26597;&#35810;&#32534;&#30721;&#22120;&#36827;&#34892;&#21387;&#32553;&#32780;&#26080;&#38656;&#36827;&#34892;&#23436;&#25972;&#30340;&#20877;&#35757;&#32451;&#25110;&#32034;&#24341;&#29983;&#25104;&#12290;&#20351;&#29992;KALE&#21644;&#19981;&#23545;&#31216;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;DistilBERT&#24615;&#33021;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#27169;&#22411;&#23610;&#23544;&#26356;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of improving the inference latency of language model-based dense retrieval systems by introducing structural compression and model size asymmetry between the context and query encoders. First, we investigate the impact of pre and post-training compression on the MSMARCO, Natural Questions, TriviaQA, SQUAD, and SCIFACT, finding that asymmetry in the dual encoders in dense retrieval can lead to improved inference efficiency. Knowing this, we introduce Kullback Leibler Alignment of Embeddings (KALE), an efficient and accurate method for increasing the inference efficiency of dense retrieval methods by pruning and aligning the query encoder after training. Specifically, KALE extends traditional Knowledge Distillation after bi-encoder training, allowing for effective query encoder compression without full retraining or index generation. Using KALE and asymmetric training, we can generate models which exceed the performance of DistilBERT despite having 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#25311;&#40657;&#30418;&#31070;&#32463;&#25490;&#21517;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#21487;&#34987;&#40657;&#24125;SEO&#29992;&#26469;&#25171;&#36133;&#26356;&#22909;&#38450;&#25252;&#30340;&#25628;&#32034;&#24341;&#25806;&#12290;</title><link>http://arxiv.org/abs/2209.06506</link><description>&lt;p&gt;
&#38454;-&#26080;&#24207;&#65306;&#40657;&#30418;&#31070;&#32463;&#25490;&#21517;&#27169;&#22411;&#30340;&#27169;&#25311;&#23545;&#25239;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models. (arXiv:2209.06506v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.06506
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#25311;&#40657;&#30418;&#31070;&#32463;&#25490;&#21517;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#21487;&#34987;&#40657;&#24125;SEO&#29992;&#26469;&#25171;&#36133;&#26356;&#22909;&#38450;&#25252;&#30340;&#25628;&#32034;&#24341;&#25806;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#25991;&#26412;&#25490;&#21517;&#27169;&#22411;&#21462;&#24471;&#20102;&#26174;&#30528;&#36827;&#23637;&#65292;&#24182;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#24212;&#29992;&#20110;&#23454;&#36341;&#20013;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#20063;&#32487;&#25215;&#20102;&#19968;&#33324;&#31070;&#32463;&#27169;&#22411;&#30340;&#23545;&#25239;&#24615;&#24369;&#28857;&#65292;&#34429;&#28982;&#24050;&#34987;&#21457;&#29616;&#65292;&#20294;&#20173;&#26410;&#34987;&#20808;&#21069;&#30340;&#30740;&#31350;&#20805;&#20998;&#25506;&#35752;&#12290;&#27492;&#22806;&#65292;&#36825;&#31181;&#23545;&#25239;&#24615;&#24369;&#28857;&#21487;&#33021;&#34987;&#40657;&#24125;SEO&#29992;&#26469;&#25171;&#36133;&#26356;&#22909;&#38450;&#25252;&#30340;&#25628;&#32034;&#24341;&#25806;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#25311;&#40657;&#30418;&#31070;&#32463;&#27573;&#33853;&#25490;&#21517;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#30446;&#26631;&#25490;&#21517;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#26522;&#20030;&#20851;&#38190;&#26597;&#35810;/&#20505;&#36873;&#39033;&#36879;&#26126;&#21270;&#24182;&#27169;&#20223;&#65292;&#28982;&#21518;&#35757;&#32451;&#19968;&#20010;&#25490;&#21517;&#27169;&#20223;&#27169;&#22411;&#12290;&#21033;&#29992;&#25490;&#21517;&#27169;&#20223;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#31934;&#24515;&#25805;&#32437;&#25490;&#21517;&#32467;&#26524;&#24182;&#23558;&#25805;&#32437;&#25915;&#20987;&#36716;&#31227;&#21040;&#30446;&#26631;&#25490;&#21517;&#27169;&#22411;&#19978;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#20351;&#29992;&#37197;&#23545;&#30446;&#26631;&#20989;&#25968;&#24378;&#21270;&#65292;&#20197;&#29983;&#25104;&#23545;&#25239;&#35302;&#21457;&#22120;&#65292;&#20174;&#32780;&#23548;&#33268;PremE.
&lt;/p&gt;
&lt;p&gt;
Neural text ranking models have witnessed significant advancement and are increasingly being deployed in practice. Unfortunately, they also inherit adversarial vulnerabilities of general neural models, which have been detected but remain underexplored by prior studies. Moreover, the inherit adversarial vulnerabilities might be leveraged by blackhat SEO to defeat better-protected search engines. In this study, we propose an imitation adversarial attack on black-box neural passage ranking models. We first show that the target passage ranking model can be transparentized and imitated by enumerating critical queries/candidates and then train a ranking imitation model. Leveraging the ranking imitation model, we can elaborately manipulate the ranking results and transfer the manipulation attack to the target ranking model. For this purpose, we propose an innovative gradient-based attack method, empowered by the pairwise objective function, to generate adversarial triggers, which causes preme
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;PMC-Patients&#8221;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#23450;&#20041;&#21644;&#27979;&#35797;&#30149;&#24739;&#21040;&#25991;&#31456;&#30340;&#26816;&#32034;&#65288;ReCDS-PAR&#65289;&#21644;&#30149;&#24739;&#21040;&#30149;&#24739;&#30340;&#26816;&#32034;&#65288;ReCDS-PPR&#65289;&#65292;&#20197;&#35780;&#20272;&#22522;&#20110;&#21484;&#22238;&#30340;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;ReCDS&#65289;&#30340;&#24615;&#33021;&#12290;PMC-Patients&#25968;&#25454;&#38598;&#28085;&#30422;&#36926;10,000&#21517;&#30149;&#24739;&#20449;&#24687;&#21644;27,000&#31687;PubMed Central&#25991;&#31456;&#65292;&#24182;&#23637;&#31034;&#20102;&#22810;&#31181;ReCDS&#31995;&#32479;&#30340;&#25928;&#26524;&#20998;&#26512;&#21644;20&#20010;&#26696;&#20363;&#30340;&#23454;&#29992;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2202.13876</link><description>&lt;p&gt;
PMC-Patients: &#29992;&#20110;&#35780;&#20272;&#22522;&#20110;&#21484;&#22238;&#30340;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#30340;&#22823;&#35268;&#27169;&#30149;&#24739;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
PMC-Patients: A Large-scale Dataset of Patient Summaries and Relations for Benchmarking Retrieval-based Clinical Decision Support Systems. (arXiv:2202.13876v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.13876
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;PMC-Patients&#8221;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#23450;&#20041;&#21644;&#27979;&#35797;&#30149;&#24739;&#21040;&#25991;&#31456;&#30340;&#26816;&#32034;&#65288;ReCDS-PAR&#65289;&#21644;&#30149;&#24739;&#21040;&#30149;&#24739;&#30340;&#26816;&#32034;&#65288;ReCDS-PPR&#65289;&#65292;&#20197;&#35780;&#20272;&#22522;&#20110;&#21484;&#22238;&#30340;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;ReCDS&#65289;&#30340;&#24615;&#33021;&#12290;PMC-Patients&#25968;&#25454;&#38598;&#28085;&#30422;&#36926;10,000&#21517;&#30149;&#24739;&#20449;&#24687;&#21644;27,000&#31687;PubMed Central&#25991;&#31456;&#65292;&#24182;&#23637;&#31034;&#20102;&#22810;&#31181;ReCDS&#31995;&#32479;&#30340;&#25928;&#26524;&#20998;&#26512;&#21644;20&#20010;&#26696;&#20363;&#30340;&#23454;&#29992;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#65306;&#22522;&#20110;&#21484;&#22238;&#30340;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;ReCDS&#65289;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#30456;&#20851;&#25991;&#29486;&#21644;&#31867;&#20284;&#30149;&#24739;&#30340;&#20449;&#24687;&#26469;&#24110;&#21161;&#20020;&#24202;&#24037;&#20316;&#27969;&#31243;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#22810;&#26679;&#30340;&#30149;&#24739;&#25910;&#38598;&#21644;&#20844;&#24320;&#30340;&#22823;&#35268;&#27169;&#30149;&#24739;&#23618;&#38754;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;ReCDS&#31995;&#32479;&#30340;&#21457;&#23637;&#21463;&#21040;&#20102;&#20005;&#37325;&#38459;&#30861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20351;&#29992;&#21517;&#20026;PMC-Patients&#30340;&#26032;&#25968;&#25454;&#38598;&#23450;&#20041;&#21644;&#27979;&#35797;&#20004;&#20010;ReCDS&#20219;&#21153;&#65306;&#30149;&#24739;&#21040;&#25991;&#31456;&#30340;&#26816;&#32034;&#65288;ReCDS-PAR&#65289;&#21644;&#30149;&#24739;&#21040;&#30149;&#24739;&#30340;&#26816;&#32034;&#65288;ReCDS-PPR&#65289;&#12290;&#26041;&#27861;&#65306;&#25105;&#20204;&#20351;&#29992;&#31616;&#21333;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#20174;PubMed Central&#25991;&#31456;&#20013;&#25552;&#21462;&#30149;&#24739;&#24635;&#32467;&#65292;&#24182;&#21033;&#29992;PubMed&#24341;&#25991;&#20851;&#31995;&#22270;&#26469;&#23450;&#20041;&#30149;&#24739;-&#25991;&#31456;&#30456;&#20851;&#24615;&#21644;&#30149;&#24739;-&#30149;&#24739;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#36824;&#22312;PMC-Patients&#22522;&#20934;&#27979;&#35797;&#19978;&#23454;&#26045;&#21644;&#35780;&#20272;&#20102;&#20960;&#31181;ReCDS&#31995;&#32479;&#65292;&#21253;&#25324;&#31232;&#30095;&#26816;&#32034;&#22120;&#12289;&#23494;&#38598;&#26816;&#32034;&#22120;&#21644;&#26368;&#36817;&#37051;&#26816;&#32034;&#22120;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20960;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#20197;&#23637;&#31034;PMC-Patients&#30340;&#20020;&#24202;&#25928;&#29992;&#12290;&#32467;&#26524;&#65306;PMC-Patients&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;10,186&#21517;&#30149;&#24739;&#30340;&#20449;&#24687;&#65292;&#28085;&#30422;&#20102;&#36926;27,000&#31687;PubMed Central&#25991;&#31456;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;ReCDS&#20219;&#21153;&#30340;&#22522;&#20934;&#35780;&#20272;&#32467;&#26524;&#21644;&#22810;&#31181;&#31995;&#32479;&#30340;&#25928;&#26524;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#20004;&#20010;&#20219;&#21153;&#30340;20&#20010;&#26696;&#20363;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;PMC-Patients&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Objective: Retrieval-based Clinical Decision Support (ReCDS) can aid clinical workflow by providing relevant literature and similar patients for a given patient. However, the development of ReCDS systems has been severely obstructed by the lack of diverse patient collections and publicly available large-scale patient-level annotation datasets. In this paper, we aim to define and benchmark two ReCDS tasks: Patient-to-Article Retrieval (ReCDS-PAR) and Patient-to-Patient Retrieval (ReCDS-PPR) using a novel dataset called PMC-Patients.  Methods: We extract patient summaries from PubMed Central articles using simple heuristics and utilize the PubMed citation graph to define patient-article relevance and patient-patient similarity. We also implement and evaluate several ReCDS systems on the PMC-Patients benchmarks, including sparse retrievers, dense retrievers, and nearest neighbor retrievers. We conduct several case studies to show the clinical utility of PMC-Patients.  Results: PMC-Patient
&lt;/p&gt;</description></item><item><title>&#20302;&#36164;&#28304;&#24773;&#22659;&#19979;&#65292;&#22914;&#20309;&#35753;&#30693;&#35782;&#25277;&#21462;&#26356;&#22909;&#22320;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#25552;&#21462;&#20449;&#24687;&#65311;&#26412;&#25991;&#35843;&#30740;&#20102;&#19977;&#31181;&#35299;&#20915;&#33539;&#24335;&#65306;&#39640;&#36164;&#28304;&#25968;&#25454;&#12289;&#26356;&#24378;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#19982;&#27169;&#22411;&#30340;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2202.08063</link><description>&lt;p&gt;
&#20302;&#36164;&#28304;&#24773;&#22659;&#19979;&#30340;&#30693;&#35782;&#25277;&#21462;&#65306;&#35843;&#30740;&#19982;&#23637;&#26395;
&lt;/p&gt;
&lt;p&gt;
Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective. (arXiv:2202.08063v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.08063
&lt;/p&gt;
&lt;p&gt;
&#20302;&#36164;&#28304;&#24773;&#22659;&#19979;&#65292;&#22914;&#20309;&#35753;&#30693;&#35782;&#25277;&#21462;&#26356;&#22909;&#22320;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#25552;&#21462;&#20449;&#24687;&#65311;&#26412;&#25991;&#35843;&#30740;&#20102;&#19977;&#31181;&#35299;&#20915;&#33539;&#24335;&#65306;&#39640;&#36164;&#28304;&#25968;&#25454;&#12289;&#26356;&#24378;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#19982;&#27169;&#22411;&#30340;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#25277;&#21462;&#65288;KE&#65289;&#26088;&#22312;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#25552;&#21462;&#32467;&#26500;&#20449;&#24687;&#65292;&#36890;&#24120;&#36973;&#21463;&#25968;&#25454;&#21294;&#20047;&#21644;&#20986;&#29616;&#26410;&#35265;&#31867;&#22411;&#65288;&#20302;&#36164;&#28304;&#24773;&#22659;&#65289;&#30340;&#22256;&#25200;&#12290;&#35768;&#22810;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#24050;&#24191;&#27867;&#30740;&#31350;&#24182;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#34920;&#29616;&#12290;&#26412;&#25991;&#23545;&#20302;&#36164;&#28304;&#24773;&#22659;&#19979;KE&#36827;&#34892;&#25991;&#29486;&#32508;&#36848;&#65292;&#24182;&#23558;&#29616;&#26377;&#30340;&#24037;&#20316;&#31995;&#32479;&#24615;&#22320;&#20998;&#20026;&#19977;&#31181;&#33539;&#24335;&#65306;&#65288;1&#65289;&#21033;&#29992;&#39640;&#36164;&#28304;&#25968;&#25454;&#65292;&#65288;2&#65289;&#21033;&#29992;&#26356;&#24378;&#30340;&#27169;&#22411;&#65292;&#65288;3&#65289;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#21644;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#26377;&#21069;&#36884;&#30340;&#24212;&#29992;&#65292;&#24182;&#27010;&#36848;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#19968;&#20123;&#28508;&#22312;&#26041;&#21521;&#12290;&#25105;&#20204;&#24076;&#26395;&#25105;&#20204;&#30340;&#35843;&#30740;&#21487;&#20197;&#24110;&#21161;&#23398;&#26415;&#21644;&#24037;&#19994;&#30028;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#39046;&#22495;&#65292;&#28608;&#21457;&#26356;&#22810;&#30340;&#21019;&#24847;&#65292;&#25552;&#21319;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge Extraction (KE), aiming to extract structural information from unstructured texts, often suffers from data scarcity and emerging unseen types, i.e., low-resource scenarios. Many neural approaches to low-resource KE have been widely investigated and achieved impressive performance. In this paper, we present a literature review towards KE in low-resource scenarios, and systematically categorize existing works into three paradigms: (1) exploiting higher-resource data, (2) exploiting stronger models, and (3) exploiting data and models together. In addition, we highlight promising applications and outline some potential directions for future research. We hope that our survey can help both the academic and industrial communities to better understand this field, inspire more ideas, and boost broader applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23436;&#25104;&#26368;&#23569;&#27604;&#36187;&#30340;&#21069;&#25552;&#19979;&#23547;&#25214;&#38182;&#26631;&#36187;&#22270;&#20013;&#20896;&#20891;&#65288;Copeland&#33719;&#32988;&#32773;&#65289;&#30340;&#26368;&#20248;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#21152;&#36895;&#20449;&#24687;&#26816;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#65292;&#36825;&#23545;&#20110;&#36827;&#34892;&#24490;&#29615;&#36187;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20855;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#65292;&#33021;&#20943;&#23569;&#27169;&#22411;&#25512;&#29702;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2111.13621</link><description>&lt;p&gt;
&#23547;&#25214;&#38182;&#26631;&#36187;&#22270;&#20013;&#20896;&#20891;&#30340;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Optimal Algorithm for Finding Champions in Tournament Graphs. (arXiv:2111.13621v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.13621
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23436;&#25104;&#26368;&#23569;&#27604;&#36187;&#30340;&#21069;&#25552;&#19979;&#23547;&#25214;&#38182;&#26631;&#36187;&#22270;&#20013;&#20896;&#20891;&#65288;Copeland&#33719;&#32988;&#32773;&#65289;&#30340;&#26368;&#20248;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#21152;&#36895;&#20449;&#24687;&#26816;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#65292;&#36825;&#23545;&#20110;&#36827;&#34892;&#24490;&#29615;&#36187;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20855;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#65292;&#33021;&#20943;&#23569;&#27169;&#22411;&#25512;&#29702;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38182;&#26631;&#36187;&#22270;&#26159;&#19968;&#20010;&#23436;&#20840;&#26377;&#21521;&#22270;&#65292;&#21487;&#29992;&#20110;&#27169;&#25311;$n$&#21517;&#36873;&#25163;&#20043;&#38388;&#30340;&#24490;&#29615;&#36187;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#23547;&#25214;&#38182;&#26631;&#36187;&#30340;&#20896;&#20891;&#65288;&#20134;&#31216;Copeland&#33719;&#32988;&#32773;&#65289;&#30340;&#38382;&#39064;&#65292;&#21363;&#36194;&#24471;&#26368;&#22810;&#27604;&#36187;&#30340;&#36873;&#25163;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25506;&#31350;&#36890;&#36807;&#36827;&#34892;&#36739;&#23569;&#27604;&#36187;&#26469;&#23547;&#25214;&#20896;&#20891;&#30340;&#31639;&#27861;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#21487;&#20197;&#21152;&#36895;&#22810;&#31181;&#20449;&#24687;&#26816;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#65292;&#21253;&#25324;&#38382;&#31572;&#12289;&#23545;&#35805;&#25628;&#32034;&#31561;&#12290;&#36825;&#20123;&#24212;&#29992;&#32463;&#24120;&#36890;&#36807;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20272;&#35745;&#35841;&#20250;&#36194;&#24471;&#27599;&#20010;&#25104;&#23545;&#27604;&#36187;&#65292;&#20174;&#32780;&#35825;&#23548;&#36873;&#25163;&#20043;&#38388;&#30340;&#24490;&#29615;&#36187;&#26469;&#23547;&#25214;&#20896;&#20891;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#36129;&#29486;&#20801;&#35768;&#36890;&#36807;&#25191;&#34892;&#36739;&#23569;&#30340;&#27169;&#22411;&#25512;&#29702;&#26469;&#23547;&#25214;&#20896;&#20891;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#20855;&#26377;&#24120;&#25968;&#25104;&#21151;&#27010;&#29575;&#30340;&#30830;&#23450;&#24615;&#25110;&#38543;&#26426;&#31639;&#27861;&#25214;&#21040;&#20896;&#20891;&#37117;&#38656;&#35201;$\Omega(\ell n)$&#27425;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
A tournament graph is a complete directed graph, which can be used to model a round-robin tournament between $n$ players. In this paper, we address the problem of finding a champion of the tournament, also known as Copeland winner, which is a player that wins the highest number of matches. In detail, we aim to investigate algorithms that find the champion by playing a low number of matches. Solving this problem allows us to speed up several Information Retrieval and Recommender System applications, including question answering, conversational search, etc. Indeed, these applications often search for the champion inducing a round-robin tournament among the players by employing a machine learning model to estimate who wins each pairwise comparison. Our contribution, thus, allows finding the champion by performing a low number of model inferences. We prove that any deterministic or randomized algorithm finding a champion with constant success probability requires $\Omega(\ell n)$ compariso
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#21270;&#20808;&#39564;&#65292;&#23558;&#20854;&#19982;&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#26694;&#26550;&#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#20132;&#26367;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35299;&#20915;&#31163;&#25955;&#20449;&#21495;&#37325;&#24314;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/1906.00309</link><description>&lt;p&gt;
&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#22312;&#31163;&#25955;&#20449;&#21495;&#37325;&#24314;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sparse Bayesian Learning Approach for Discrete Signal Reconstruction. (arXiv:1906.00309v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1906.00309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#21270;&#20808;&#39564;&#65292;&#23558;&#20854;&#19982;&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#26694;&#26550;&#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#20132;&#26367;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35299;&#20915;&#31163;&#25955;&#20449;&#21495;&#37325;&#24314;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#65288;SBL&#65289;&#30340;&#35282;&#24230;&#35299;&#20915;&#20102;&#31163;&#25955;&#20449;&#21495;&#37325;&#24314;&#30340;&#38382;&#39064;&#12290;&#36890;&#24120;&#65292;&#22312;SBL&#26694;&#26550;&#19979;&#20351;&#29992;&#29702;&#24819;&#30340;&#31163;&#25955;&#21270;&#20808;&#39564;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#29702;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#21270;&#20808;&#39564;&#65292;&#20197;&#21033;&#29992;&#24863;&#20852;&#36259;&#20449;&#21495;&#30340;&#31163;&#25955;&#29305;&#24615;&#30340;&#30693;&#35782;&#12290;&#36890;&#36807;&#23558;&#31163;&#25955;&#21270;&#20808;&#39564;&#38598;&#25104;&#21040;SBL&#26694;&#26550;&#20013;&#65292;&#24182;&#24212;&#29992;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#65288;VBI&#65289;&#26041;&#27861;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#20132;&#26367;&#20248;&#21270;&#31639;&#27861;&#26469;&#20849;&#21516;&#34920;&#24449;&#26377;&#38480;&#23383;&#27597;&#29305;&#24449;&#24182;&#37325;&#24314;&#26410;&#30693;&#20449;&#21495;&#12290;&#24403;&#27979;&#37327;&#30697;&#38453;&#26159;&#27599;&#20010;&#20998;&#37327;&#30340;i.i.d.&#39640;&#26031;&#20998;&#24067;&#26102;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#24191;&#20041;&#36817;&#20284;&#20449;&#24687;&#20256;&#36882;&#65288;GAMP&#65289;&#23884;&#20837;&#21040;&#22522;&#20110;VBI&#30340;&#26041;&#27861;&#20013;&#65292;&#20197;&#30452;&#25509;&#37319;&#29992;&#29702;&#24819;&#20808;&#39564;&#24182;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#36127;&#25285;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study addresses the problem of discrete signal reconstruction from the perspective of sparse Bayesian learning (SBL). Generally, it is intractable to perform the Bayesian inference with the ideal discretization prior under the SBL framework. To overcome this challenge, we introduce a novel discretization enforcing prior to exploit the knowledge of the discrete nature of the signal-of-interest. By integrating the discretization enforcing prior into the SBL framework and applying the variational Bayesian inference (VBI) methodology, we devise an alternating optimization algorithm to jointly characterize the finite-alphabet feature and reconstruct the unknown signal. When the measurement matrix is i.i.d. Gaussian per component, we further embed the generalized approximate message passing (GAMP) into the VBI-based method, so as to directly adopt the ideal prior and significantly reduce the computational burden. Simulation results demonstrate substantial performance improvement of the 
&lt;/p&gt;</description></item></channel></rss>