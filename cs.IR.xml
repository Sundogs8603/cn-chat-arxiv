<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22914;&#20309;&#20351;&#29992;LLMs&#26469;&#25913;&#36827;&#24207;&#21015;&#25512;&#33616;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19977;&#31181;&#27491;&#20132;&#26041;&#27861;&#21644;&#23427;&#20204;&#30340;&#28151;&#21512;&#24418;&#24335;&#26469;&#21033;&#29992;LLMs&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#22823;&#37327;&#23454;&#39564;&#21644;&#19981;&#21516;&#37197;&#32622;&#19978;&#30340;&#25506;&#32034;&#65292;&#25105;&#20204;&#21457;&#29616;&#36890;&#36807;&#21021;&#22987;&#21270;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#21487;&#20197;&#23454;&#29616;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01339</link><description>&lt;p&gt;
&#20351;&#29992;LLMs&#25913;&#36827;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Improving Sequential Recommendations with LLMs
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22914;&#20309;&#20351;&#29992;LLMs&#26469;&#25913;&#36827;&#24207;&#21015;&#25512;&#33616;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19977;&#31181;&#27491;&#20132;&#26041;&#27861;&#21644;&#23427;&#20204;&#30340;&#28151;&#21512;&#24418;&#24335;&#26469;&#21033;&#29992;LLMs&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#22823;&#37327;&#23454;&#39564;&#21644;&#19981;&#21516;&#37197;&#32622;&#19978;&#30340;&#25506;&#32034;&#65292;&#25105;&#20204;&#21457;&#29616;&#36890;&#36807;&#21021;&#22987;&#21270;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#21487;&#20197;&#23454;&#29616;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#65292;&#24207;&#21015;&#25512;&#33616;&#38382;&#39064;&#24341;&#36215;&#20102;&#30456;&#24403;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#65292;&#23548;&#33268;&#20102;&#35768;&#22810;&#25512;&#33616;&#27169;&#22411;&#30340;&#20986;&#29616;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#29616;&#20170;&#22312;&#35768;&#22810;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#24212;&#29992;&#20013;&#24341;&#20837;&#20102;&#39072;&#35206;&#24615;&#24433;&#21709;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#26500;&#24314;&#25110;&#25913;&#36827;&#24207;&#21015;&#25512;&#33616;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19977;&#31181;&#27491;&#20132;&#26041;&#27861;&#21644;&#23427;&#20204;&#30340;&#28151;&#21512;&#24418;&#24335;&#65292;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#21033;&#29992;LLMs&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#20851;&#27880;&#32452;&#25104;&#25216;&#26415;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#24182;&#23545;&#27599;&#20010;&#26041;&#27861;&#30830;&#23450;&#19968;&#31995;&#21015;&#21487;&#34892;&#30340;&#26367;&#20195;&#36873;&#25321;&#65292;&#26469;&#30740;&#31350;&#27599;&#20010;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#24182;&#25506;&#32034;&#20102;&#21508;&#31181;&#37197;&#32622;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#35821;&#35328;&#27169;&#22411;&#21644;&#22522;&#20934;&#25512;&#33616;&#27169;&#22411;&#65292;&#20197;&#33719;&#24471;&#27599;&#20010;&#26041;&#27861;&#30340;&#24615;&#33021;&#30340;&#32508;&#21512;&#22270;&#29255;&#12290;&#22312;&#20854;&#20182;&#35266;&#23519;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#36890;&#36807;&#21021;&#22987;&#21270;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#21487;&#20197;&#23454;&#29616;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
The sequential recommendation problem has attracted considerable research attention in the past few years, leading to the rise of numerous recommendation models. In this work, we explore how Large Language Models (LLMs), which are nowadays introducing disruptive effects in many AI-based applications, can be used to build or improve sequential recommendation approaches. Specifically, we design three orthogonal approaches and hybrids of those to leverage the power of LLMs in different ways. In addition, we investigate the potential of each approach by focusing on its comprising technical aspects and determining an array of alternative choices for each one. We conduct extensive experiments on three datasets and explore a large variety of configurations, including different language models and baseline recommendation models, to obtain a comprehensive picture of the performance of each approach. Among other observations, we highlight that initializing state-of-the-art sequential recommendat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21306;&#22495;&#24433;&#21709;&#21147;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#24191;&#21578;&#29260;&#24191;&#21578;&#30340;&#36951;&#25022;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#26159;&#36890;&#36807;&#22686;&#37327;&#36138;&#23146;&#30340;&#26041;&#24335;&#36873;&#25321;&#24191;&#21578;&#20301;&#65292;&#21517;&#20026;&#8220;&#39044;&#31639;&#26377;&#25928;&#30340;&#36138;&#23146;&#8221;&#26041;&#27861;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01294</link><description>&lt;p&gt;
&#22312;&#21306;&#22495;&#24433;&#21709;&#21147;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#24191;&#21578;&#29260;&#24191;&#21578;&#30340;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Minimizing Regret in Billboard Advertisement under Zonal Influence Constraint
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21306;&#22495;&#24433;&#21709;&#21147;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#24191;&#21578;&#29260;&#24191;&#21578;&#30340;&#36951;&#25022;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#26159;&#36890;&#36807;&#22686;&#37327;&#36138;&#23146;&#30340;&#26041;&#24335;&#36873;&#25321;&#24191;&#21578;&#20301;&#65292;&#21517;&#20026;&#8220;&#39044;&#31639;&#26377;&#25928;&#30340;&#36138;&#23146;&#8221;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20856;&#22411;&#30340;&#24191;&#21578;&#29260;&#24191;&#21578;&#25216;&#26415;&#20013;&#65292;&#19968;&#20010;&#24433;&#21709;&#25552;&#20379;&#32773;&#25317;&#26377;&#35768;&#22810;&#25968;&#23383;&#24191;&#21578;&#29260;&#65292;&#35768;&#22810;&#24191;&#21578;&#21830;&#22522;&#20110;&#20184;&#36153;&#30340;&#26041;&#24335;&#21521;&#24433;&#21709;&#25552;&#20379;&#32773;&#35831;&#27714;&#20182;&#20204;&#24191;&#21578;&#20869;&#23481;&#30340;&#29305;&#23450;&#27425;&#25968;&#23637;&#31034;&#12290;&#22914;&#26524;&#24433;&#21709;&#25552;&#20379;&#32773;&#25552;&#20379;&#20102;&#25152;&#38656;&#25110;&#26356;&#22810;&#30340;&#24433;&#21709;&#21147;&#65292;&#37027;&#20040;&#20182;&#23558;&#33719;&#24471;&#20840;&#37096;&#20184;&#27454;&#65292;&#21542;&#21017;&#21482;&#33021;&#33719;&#24471;&#37096;&#20998;&#20184;&#27454;&#12290;&#23545;&#20110;&#19968;&#20010;&#24433;&#21709;&#25552;&#20379;&#32773;&#26469;&#35828;&#65292;&#22914;&#26524;&#20182;&#25552;&#20379;&#30340;&#24433;&#21709;&#21147;&#22810;&#20110;&#25110;&#23569;&#20110;&#24191;&#21578;&#21830;&#25152;&#38656;&#30340;&#24433;&#21709;&#21147;&#65292;&#36825;&#23545;&#20182;&#26469;&#35828;&#26159;&#19968;&#31181;&#25439;&#22833;&#12290;&#36825;&#34987;&#24418;&#24335;&#21270;&#20026;&#8220;&#36951;&#25022;&#8221;&#65292;&#33258;&#28982;&#32780;&#28982;&#22320;&#65292;&#22312;&#24433;&#21709;&#25552;&#20379;&#32773;&#30340;&#32972;&#26223;&#19979;&#65292;&#30446;&#26631;&#23558;&#26159;&#22312;&#24191;&#21578;&#21830;&#20043;&#38388;&#20998;&#37197;&#24191;&#21578;&#29260;&#20301;&#32622;&#65292;&#20197;&#20351;&#24635;&#36951;&#25022;&#26368;&#23567;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#30740;&#31350;&#20026;&#19968;&#20010;&#31163;&#25955;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22235;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#20197;&#22686;&#37327;&#36138;&#23146;&#30340;&#26041;&#24335;&#20174;&#21487;&#29992;&#30340;&#24191;&#21578;&#20301;&#20013;&#36873;&#25321;&#24191;&#21578;&#29260;&#20301;&#32622;&#65292;&#25105;&#20204;&#31216;&#36825;&#31181;&#26041;&#27861;&#20026;&#8220;&#39044;&#31639;&#26377;&#25928;&#30340;&#36138;&#23146;&#8221;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a typical billboard advertisement technique, a number of digital billboards are owned by an influence provider, and many advertisers approach the influence provider for a specific number of views of their advertisement content on a payment basis. If the influence provider provides the demanded or more influence, then he will receive the full payment or else a partial payment. In the context of an influence provider, if he provides more or less than an advertiser's demanded influence, it is a loss for him. This is formalized as 'Regret', and naturally, in the context of the influence provider, the goal will be to allocate the billboard slots among the advertisers such that the total regret is minimized. In this paper, we study this problem as a discrete optimization problem and propose four solution approaches. The first one selects the billboard slots from the available ones in an incremental greedy manner, and we call this method the Budget Effective Greedy approach. In the second 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#29992;&#20110;&#26174;&#24335;&#22320;&#24314;&#27169;&#23618;&#27425;&#21270;&#22810;&#20852;&#36259;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#23618;&#27425;&#32858;&#31867;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#26469;&#25366;&#25496;&#23618;&#27425;&#21270;&#30340;&#22810;&#20852;&#36259;&#20449;&#24687;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01253</link><description>&lt;p&gt;
HimiRec: &#24314;&#27169;&#23618;&#27425;&#21270;&#22810;&#20852;&#36259;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
HimiRec: Modeling Hierarchical Multi-interest for Recommendation
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01253
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#29992;&#20110;&#26174;&#24335;&#22320;&#24314;&#27169;&#23618;&#27425;&#21270;&#22810;&#20852;&#36259;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#23618;&#27425;&#32858;&#31867;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#26469;&#25366;&#25496;&#23618;&#27425;&#21270;&#30340;&#22810;&#20852;&#36259;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#19994;&#32423;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#21253;&#21547;&#26816;&#32034;&#38454;&#27573;&#21644;&#25490;&#21517;&#38454;&#27573;&#65292;&#20197;&#22788;&#29702;&#20159;&#32423;&#29992;&#25143;&#21644;&#29289;&#21697;&#12290;&#26816;&#32034;&#38454;&#27573;&#29992;&#20110;&#26816;&#32034;&#19982;&#29992;&#25143;&#20852;&#36259;&#30456;&#20851;&#30340;&#20505;&#36873;&#29289;&#21697;&#36827;&#34892;&#25512;&#33616;&#65292;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#32463;&#24120;&#24773;&#20917;&#19979;&#65292;&#29992;&#25143;&#23637;&#31034;&#20986;&#23618;&#27425;&#21270;&#30340;&#22810;&#20010;&#20852;&#36259;&#65292;&#27604;&#22914;&#19968;&#20010;&#22312;&#20307;&#32946;&#20013;&#28909;&#34935;&#25903;&#25345;&#37329;&#24030;&#21191;&#22763;&#38431;&#30340;&#29992;&#25143;&#65292;&#20063;&#20250;&#23545;&#20960;&#20046;&#25152;&#26377;&#21160;&#30011;&#26377;&#20852;&#36259;&#65292;&#20307;&#32946;&#21644;&#21160;&#30011;&#22788;&#20110;&#21516;&#26679;&#30340;&#23618;&#27425;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#38544;&#24335;&#22320;&#23398;&#20064;&#36825;&#31181;&#23618;&#27425;&#21270;&#24046;&#24322;&#65292;&#23548;&#33268;&#26356;&#32454;&#31890;&#24230;&#30340;&#20852;&#36259;&#20449;&#24687;&#34987;&#24179;&#22343;&#21270;&#65292;&#38480;&#21046;&#20102;&#23545;&#29992;&#25143;&#22312;&#28909;&#38376;&#20852;&#36259;&#21644;&#20854;&#20182;&#36731;&#20852;&#36259;&#26041;&#38754;&#30340;&#35814;&#32454;&#29702;&#35299;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#29992;&#20110;&#26174;&#24335;&#22320;&#24314;&#27169;&#23618;&#27425;&#21270;&#22810;&#20852;&#36259;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#25105;&#20204;&#20351;&#29992;&#23618;&#27425;&#32858;&#31867;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#26469;&#25366;&#25496;&#23618;&#27425;&#21270;&#30340;&#22810;&#20852;&#36259;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Industrial recommender systems usually consist of the retrieval stage and the ranking stage, to handle the billion-scale of users and items. The retrieval stage retrieves candidate items relevant to user interests for recommendations and has attracted much attention. Frequently, users show hierarchical multi-interests reflected in a heavy user of a certain NBA team Golden State Warriors in Sports, who is also a light user of almost the whole Animation. Both Sports and Animation are at the same level. However, most existing methods implicitly learn this hierarchical difference, making more fine-grained interest information to be averaged and limiting detailed understanding of the user's different needs in heavy interests and other light interests. Therefore, we propose a novel two-stage approach to explicitly modeling hierarchical multi-interest for recommendation in this work. In the first hierarchical multi-interest mining stage, the hierarchical clustering and transformer-based model
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26080;&#32541;&#38598;&#25104;&#29983;&#25104;&#24335;&#26816;&#32034;&#12289;&#38381;&#24335;&#29983;&#25104;&#21644;RAG&#65292;&#21033;&#29992;&#22806;&#37096;&#35821;&#26009;&#22788;&#29702;&#21508;&#31181;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01176</link><description>&lt;p&gt;
&#20026;&#21033;&#29992;&#22806;&#37096;&#35821;&#26009;&#36827;&#34892;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#32780;&#26500;&#24314;&#30340;&#32479;&#19968;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Towards a Unified Language Model for Knowledge-Intensive Tasks Utilizing External Corpus
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26080;&#32541;&#38598;&#25104;&#29983;&#25104;&#24335;&#26816;&#32034;&#12289;&#38381;&#24335;&#29983;&#25104;&#21644;RAG&#65292;&#21033;&#29992;&#22806;&#37096;&#35821;&#26009;&#22788;&#29702;&#21508;&#31181;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#26377;&#25928;&#24615;&#65292;&#28982;&#32780;&#22312;&#38656;&#35201;&#22806;&#37096;&#30693;&#35782;&#26469;&#28304;&#30340;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#20013;&#65292;&#23427;&#20204;&#24448;&#24448;&#20250;&#20135;&#29983;&#34394;&#26500;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#30340;&#20107;&#23454;&#20934;&#30830;&#24615;&#65292;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25104;&#20026;&#20102;&#19968;&#31181;&#27969;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#26816;&#32034;&#27169;&#22359;&#36890;&#24120;&#20381;&#36182;&#20110;&#22823;&#35268;&#27169;&#30340;&#25991;&#26723;&#32034;&#24341;&#65292;&#36825;&#21487;&#33021;&#19982;&#29983;&#25104;&#20219;&#21153;&#30456;&#33073;&#31163;&#12290;&#36890;&#36807;&#29983;&#25104;&#24335;&#26816;&#32034;&#65288;GR&#65289;&#26041;&#27861;&#65292;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#30456;&#20851;&#25991;&#26723;&#26631;&#35782;&#31526;&#65288;DocIDs&#65289;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#26816;&#32034;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;GR&#19982;&#19979;&#28216;&#20219;&#21153;&#20043;&#38388;&#30340;&#20851;&#31995;&#20197;&#21450;LLMs&#22312;GR&#20013;&#30340;&#28508;&#21147;&#23578;&#26410;&#24471;&#21040;&#25506;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26080;&#32541;&#38598;&#25104;&#29983;&#25104;&#24335;&#26816;&#32034;&#12289;&#38381;&#24335;&#29983;&#25104;&#21644;RAG&#65292;&#21033;&#29992;&#22806;&#37096;&#35821;&#26009;&#22788;&#29702;&#21508;&#31181;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of large language models (LLMs) has showcased their efficacy across various domains, yet they often hallucinate, especially in knowledge-intensive tasks that require external knowledge sources. To improve factual accuracy of language models, retrieval-augmented generation (RAG) has emerged as a popular solution. However, traditional retrieval modules often rely on large-scale document indexes, which can be disconnected from generative tasks. Through generative retrieval (GR) approach, language models can achieve superior retrieval performance by directly generating relevant document identifiers (DocIDs). However, the relationship between GR and downstream tasks, as well as the potential of LLMs in GR, remains unexplored. In this paper, we present a unified language model that utilizes external corpus to handle various knowledge-intensive tasks by seamlessly integrating generative retrieval, closed-book generation, and RAG. In order to achieve effective retrieval and generati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#26234;&#33021;&#20307;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65288;MACRS&#65289;&#65292;&#23427;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#22810;&#26234;&#33021;&#20307;&#34892;&#21160;&#35268;&#21010;&#26694;&#26550;&#26469;&#25511;&#21046;&#23545;&#35805;&#27969;&#31243;&#65292;&#24182;&#22522;&#20110;LLM&#29983;&#25104;&#22810;&#20010;&#20505;&#36873;&#21709;&#24212;&#12290;&#36825;&#20010;&#31995;&#32479;&#33021;&#22815;&#25552;&#39640;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#24182;&#21033;&#29992;&#29992;&#25143;&#21453;&#39304;&#26469;&#26356;&#22909;&#22320;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01135</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Multi-Agent Conversational Recommender System
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01135
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#26234;&#33021;&#20307;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65288;MACRS&#65289;&#65292;&#23427;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#22810;&#26234;&#33021;&#20307;&#34892;&#21160;&#35268;&#21010;&#26694;&#26550;&#26469;&#25511;&#21046;&#23545;&#35805;&#27969;&#31243;&#65292;&#24182;&#22522;&#20110;LLM&#29983;&#25104;&#22810;&#20010;&#20505;&#36873;&#21709;&#24212;&#12290;&#36825;&#20010;&#31995;&#32479;&#33021;&#22815;&#25552;&#39640;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#24182;&#21033;&#29992;&#29992;&#25143;&#21453;&#39304;&#26469;&#26356;&#22909;&#22320;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#19982;&#29992;&#25143;&#36827;&#34892;&#27969;&#30021;&#30340;&#22810;&#36718;&#23545;&#35805;&#26041;&#38754;&#20855;&#26377;&#24378;&#22823;&#30340;&#33021;&#21147;&#65292;&#23427;&#20204;&#26377;&#28508;&#21147;&#36827;&#19968;&#27493;&#25552;&#39640;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65288;CRS&#65289;&#30340;&#24615;&#33021;&#12290;&#19982;LLM&#25797;&#38271;&#30340;&#26080;&#30446;&#30340;&#38386;&#32842;&#19981;&#21516;&#65292;CRS&#26377;&#19968;&#20010;&#26126;&#30830;&#30340;&#30446;&#26631;&#12290;&#22240;&#27492;&#65292;&#24517;&#39035;&#25511;&#21046;LLM&#20013;&#30340;&#23545;&#35805;&#27969;&#31243;&#65292;&#20197;&#25104;&#21151;&#21521;&#29992;&#25143;&#25512;&#33616;&#36866;&#24403;&#30340;&#29289;&#21697;&#12290;&#27492;&#22806;&#65292;CRS&#20013;&#30340;&#29992;&#25143;&#21453;&#39304;&#21487;&#20197;&#24110;&#21161;&#31995;&#32479;&#26356;&#22909;&#22320;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#65292;&#20294;&#29616;&#26377;&#30740;&#31350;&#24573;&#35270;&#20102;&#36825;&#19968;&#28857;&#12290;&#28982;&#32780;&#65292;&#31616;&#21333;&#22320;&#25552;&#31034;LLM&#36827;&#34892;&#23545;&#35805;&#25512;&#33616;&#26080;&#27861;&#35299;&#20915;&#19978;&#36848;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21253;&#21547;&#20004;&#20010;&#20851;&#38190;&#27169;&#22359;&#30340;&#22810;&#26234;&#33021;&#20307;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65288;MACRS&#65289;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#26234;&#33021;&#20307;&#34892;&#21160;&#35268;&#21010;&#26694;&#26550;&#65292;&#21487;&#20197;&#22522;&#20110;&#22235;&#20010;&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#20307;&#25511;&#21046;&#23545;&#35805;&#27969;&#31243;&#12290;&#36825;&#20010;&#21512;&#20316;&#30340;&#22810;&#26234;&#33021;&#20307;&#26694;&#26550;&#23558;&#22522;&#20110;&#19981;&#21516;&#30340;&#26041;&#26696;&#29983;&#25104;&#21508;&#31181;&#20505;&#36873;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to strong capabilities in conducting fluent, multi-turn conversations with users, Large Language Models (LLMs) have the potential to further improve the performance of Conversational Recommender System (CRS). Unlike the aimless chit-chat that LLM excels at, CRS has a clear target. So it is imperative to control the dialogue flow in the LLM to successfully recommend appropriate items to the users. Furthermore, user feedback in CRS can assist the system in better modeling user preferences, which has been ignored by existing studies. However, simply prompting LLM to conduct conversational recommendation cannot address the above two key challenges.   In this paper, we propose Multi-Agent Conversational Recommender System (MACRS) which contains two essential modules. First, we design a multi-agent act planning framework, which can control the dialogue flow based on four LLM-based agents. This cooperative multi-agent framework will generate various candidate responses based on different 
&lt;/p&gt;</description></item><item><title>TransFR&#26159;&#19968;&#31181;&#20855;&#22791;&#36890;&#29992;&#25991;&#26412;&#34920;&#31034;&#30340;&#21487;&#36801;&#31227;&#32852;&#37030;&#25512;&#33616;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#31934;&#35843;&#26412;&#22320;&#31169;&#26377;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#35299;&#20915;&#20102;&#32852;&#37030;&#29615;&#22659;&#19979;&#30340;&#19981;&#21487;&#36801;&#31227;&#24615;&#12289;&#20919;&#21551;&#21160;&#29615;&#22659;&#19979;&#30340;&#19981;&#21487;&#29992;&#24615;&#21644;&#38544;&#31169;&#27844;&#38706;&#31561;&#38382;&#39064;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01124</link><description>&lt;p&gt;
TransFR&#65306;&#20855;&#22791;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#36801;&#31227;&#32852;&#37030;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
TransFR: Transferable Federated Recommendation with Pre-trained Language Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01124
&lt;/p&gt;
&lt;p&gt;
TransFR&#26159;&#19968;&#31181;&#20855;&#22791;&#36890;&#29992;&#25991;&#26412;&#34920;&#31034;&#30340;&#21487;&#36801;&#31227;&#32852;&#37030;&#25512;&#33616;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#31934;&#35843;&#26412;&#22320;&#31169;&#26377;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#35299;&#20915;&#20102;&#32852;&#37030;&#29615;&#22659;&#19979;&#30340;&#19981;&#21487;&#36801;&#31227;&#24615;&#12289;&#20919;&#21551;&#21160;&#29615;&#22659;&#19979;&#30340;&#19981;&#21487;&#29992;&#24615;&#21644;&#38544;&#31169;&#27844;&#38706;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#25512;&#33616; (FRs) &#26159;&#19968;&#31181;&#20419;&#36827;&#22810;&#20010;&#26412;&#22320;&#23458;&#25143;&#31471;&#22312;&#19981;&#26292;&#38706;&#29992;&#25143;&#31169;&#26377;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20849;&#21516;&#23398;&#20064;&#20840;&#23616;&#27169;&#22411;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#26550;&#26500;&#12290;&#22312;&#20256;&#32479;&#30340;FRs&#20013;&#65292;&#19968;&#31181;&#20027;&#23548;&#33539;&#24335;&#26159;&#21033;&#29992;&#31163;&#25955;&#30340;&#36523;&#20221;&#26469;&#34920;&#31034;&#29992;&#25143;/&#23458;&#25143;&#31471;&#21644;&#29289;&#21697;&#65292;&#28982;&#21518;&#23558;&#20854;&#26144;&#23556;&#21040;&#39046;&#22495;&#29305;&#23450;&#30340;&#23884;&#20837;&#20013;&#21442;&#19982;&#27169;&#22411;&#35757;&#32451;&#12290;&#23613;&#31649;&#24615;&#33021;&#21487;&#35266;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#19981;&#33021;&#24573;&#35270;&#30340;&#19977;&#20010;&#22266;&#26377;&#38480;&#21046;&#65292;&#21363;&#39046;&#22495;&#38388;&#30340;&#19981;&#21487;&#36801;&#31227;&#24615;&#65292;&#22312;&#20919;&#21551;&#21160;&#29615;&#22659;&#20013;&#30340;&#19981;&#21487;&#29992;&#24615;&#20197;&#21450;&#22312;&#32852;&#37030;&#35757;&#32451;&#36807;&#31243;&#20013;&#28508;&#22312;&#30340;&#38544;&#31169;&#27844;&#38706;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#22791;&#36890;&#29992;&#25991;&#26412;&#34920;&#31034;&#30340;&#21487;&#36801;&#31227;&#32852;&#37030;&#25512;&#33616;&#27169;&#22411;TransFR&#65292;&#23427;&#24039;&#22937;&#22320;&#32467;&#21512;&#20102;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36171;&#20104;&#30340;&#36890;&#29992;&#33021;&#21147;&#21644;&#36890;&#36807;&#31934;&#35843;&#26412;&#22320;&#31169;&#26377;&#25968;&#25454;&#36171;&#20104;&#30340;&#20010;&#24615;&#21270;&#33021;&#21147;&#12290;&#20855;&#20307;&#22320;&#65292;&#23427;&#39318;&#20808;&#23398;&#20064;&#65307;...
&lt;/p&gt;
&lt;p&gt;
Federated recommendations (FRs), facilitating multiple local clients to collectively learn a global model without disclosing user private data, have emerged as a prevalent architecture for privacy-preserving recommendations. In conventional FRs, a dominant paradigm is to utilize discrete identities to represent users/clients and items, which are subsequently mapped to domain-specific embeddings to participate in model training. Despite considerable performance, we reveal three inherent limitations that can not be ignored in federated settings, i.e., non-transferability across domains, unavailability in cold-start settings, and potential privacy violations during federated training. To this end, we propose a transferable federated recommendation model with universal textual representations, TransFR, which delicately incorporates the general capabilities empowered by pre-trained language models and the personalized abilities by fine-tuning local private data. Specifically, it first learn
&lt;/p&gt;</description></item><item><title>CF4J&#26159;&#19968;&#20010;&#19987;&#20026;&#30740;&#31350;&#35797;&#38169;&#36807;&#31243;&#32780;&#35774;&#35745;&#30340;Java&#24211;&#65292;&#29992;&#20110;&#36827;&#34892;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#23454;&#39564;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01008</link><description>&lt;p&gt;
CF4J: &#36866;&#29992;&#20110;Java&#30340;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
CF4J: Collaborative Filtering for Java
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01008
&lt;/p&gt;
&lt;p&gt;
CF4J&#26159;&#19968;&#20010;&#19987;&#20026;&#30740;&#31350;&#35797;&#38169;&#36807;&#31243;&#32780;&#35774;&#35745;&#30340;Java&#24211;&#65292;&#29992;&#20110;&#36827;&#34892;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#20026;&#35299;&#20915;&#20449;&#24687;&#36807;&#36733;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#21457;&#34920;&#20102;&#25968;&#30334;&#31687;&#35770;&#25991;&#65292;&#20197;&#25913;&#36827;&#19981;&#21516;&#30340;RS&#21151;&#33021;&#12290;&#24314;&#35758;&#20351;&#29992;RS&#26694;&#26550;&#31616;&#21270;RS&#30740;&#31350;&#20154;&#21592;&#30340;&#24037;&#20316;&#65306;a) &#35774;&#35745;&#21644;&#23454;&#29616;&#25512;&#33616;&#26041;&#27861;&#65292;b) &#21152;&#24555;&#23454;&#39564;&#30340;&#25191;&#34892;&#26102;&#38388;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;CF4J&#65292;&#19968;&#20010;&#29992;&#20110;&#36827;&#34892;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;RS&#30740;&#31350;&#23454;&#39564;&#30340;Java&#24211;&#12290;CF4J&#26159;&#20174;&#30740;&#31350;&#20154;&#21592;&#21040;&#30740;&#31350;&#20154;&#21592;&#30340;&#35774;&#35745;&#12290;&#23427;&#20801;&#35768;&#65306;a) &#35835;&#21462;RS&#25968;&#25454;&#38598;&#65292;b) &#20840;&#38754;&#19988;&#26131;&#20110;&#35775;&#38382;&#25968;&#25454;&#21644;&#20013;&#38388;&#25110;&#26368;&#32456;&#32467;&#26524;&#65292;c) &#25193;&#23637;&#20027;&#35201;&#21151;&#33021;&#65292;d) &#24182;&#21457;&#25191;&#34892;&#23454;&#29616;&#30340;&#26041;&#27861;&#65292;e) &#36890;&#36807;&#36136;&#37327;&#24230;&#37327;&#25552;&#20379;&#20840;&#38754;&#35780;&#20272;&#12290;&#24635;&#32780;&#35328;&#20043;&#65292;CF4J&#20316;&#20026;&#19968;&#20010;&#19987;&#38376;&#20026;&#30740;&#31350;&#35797;&#38169;&#36807;&#31243;&#32780;&#35774;&#35745;&#30340;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender Systems (RS) provide a relevant tool to mitigate the information overload problem. A large number of researchers have published hundreds of papers to improve different RS features. It is advisable to use RS frameworks that simplify RS researchers: a) to design and implement recommendations methods and, b) to speed up the execution time of the experiments. In this paper, we present CF4J, a Java library designed to carry out Collaborative Filtering based RS research experiments. CF4J has been designed from researchers to researchers. It allows: a) RS datasets reading, b) full and easy access to data and intermediate or final results, c) to extend their main functionalities, d) to concurrently execute the implemented methods, and e) to provide a thorough evaluation for the implementations by quality measures. In summary, CF4J serves as a library specifically designed for the research trial and error process.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38754;&#21521;&#38750;&#31243;&#24207;&#21592;&#29992;&#25143;&#30340;KG&#38382;&#31572;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#20307;&#38142;&#25509;&#21644;GPT&#27169;&#22411;&#29983;&#25104;SPARQL&#26597;&#35810;&#65292;&#20351;&#29992;CWA&#39044;&#35757;&#32451;&#25152;&#26377;&#23454;&#20307;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;SPARQL&#21305;&#37197;&#29575;&#20026;62.703%&#12290;</title><link>https://rss.arxiv.org/abs/2402.00969</link><description>&lt;p&gt;
&#20351;&#29992;Entity&#39044;&#35757;&#32451;GPT&#20026;KG&#38382;&#31572;&#29983;&#25104;SPARQL
&lt;/p&gt;
&lt;p&gt;
SPARQL Generation with Entity Pre-trained GPT for KG Question Answering
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38754;&#21521;&#38750;&#31243;&#24207;&#21592;&#29992;&#25143;&#30340;KG&#38382;&#31572;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#20307;&#38142;&#25509;&#21644;GPT&#27169;&#22411;&#29983;&#25104;SPARQL&#26597;&#35810;&#65292;&#20351;&#29992;CWA&#39044;&#35757;&#32451;&#25152;&#26377;&#23454;&#20307;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;SPARQL&#21305;&#37197;&#29575;&#20026;62.703%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#30340;&#27969;&#34892;&#24230;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#36805;&#36895;&#22686;&#38271;&#12290;&#20154;&#20204;&#21487;&#20197;&#36890;&#36807;&#20114;&#32852;&#32593;&#19978;&#30340;&#35768;&#22810;&#22312;&#32447;&#25968;&#25454;&#24211;&#26597;&#35810;&#36825;&#20123;&#30693;&#35782;&#12290;&#20294;&#26159;&#65292;&#22914;&#26524;&#38750;&#31243;&#24207;&#21592;&#29992;&#25143;&#33021;&#22815;&#35775;&#38382;&#20182;&#20204;&#24819;&#35201;&#30693;&#36947;&#30340;&#20219;&#20309;&#20449;&#24687;&#65292;&#37027;&#23558;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25104;&#23601;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24050;&#32463;&#20184;&#20986;&#20102;&#24456;&#22810;&#21162;&#21147;&#65292;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24037;&#20855;&#21644;&#36890;&#36807;&#35768;&#22810;&#25361;&#25112;&#28608;&#21169;&#21019;&#36896;&#21147;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37325;&#28857;&#26159;&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#19978;&#36827;&#34892;&#27491;&#30830;&#30340;&#23454;&#20307;&#38142;&#25509;&#65292;&#24182;&#35757;&#32451;&#19968;&#20010;GPT&#27169;&#22411;&#26469;&#20174;&#20013;&#21019;&#24314;SPARQL&#26597;&#35810;&#12290;&#25105;&#20204;&#25104;&#21151;&#22320;&#30830;&#23450;&#20102;&#36825;&#20010;&#20219;&#21153;&#20013;&#21487;&#33021;&#26368;&#38590;&#20197;&#22312;&#23569;&#25968;&#25110;&#38646;&#27425;&#23581;&#35797;&#20013;&#35299;&#20915;&#30340;&#23646;&#24615;&#65292;&#24182;&#25552;&#20986;&#23545;&#25152;&#26377;&#23454;&#20307;&#36827;&#34892;&#39044;&#35757;&#32451;&#65288;&#22312;CWA&#19979;&#65289;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;3&#27425;&#23581;&#35797;&#20013;&#65292;&#25105;&#20204;&#22312;&#27979;&#35797;&#20013;&#33719;&#24471;&#20102;62.703%&#30340;&#20934;&#30830;&#30340;SPARQL&#21305;&#37197;&#29575;&#65292;&#22312;&#23454;&#20307;&#38142;&#25509;&#25361;&#25112;&#20013;&#33719;&#24471;&#20102;0.809&#30340;F1&#20540;&#65292;&#22312;&#38382;&#39064;&#22238;&#31572;&#25361;&#25112;&#20013;&#33719;&#24471;&#20102;0.009&#30340;F1&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge Graphs popularity has been rapidly growing in last years. All that knowledge is available for people to query it through the many online databases on the internet. Though, it would be a great achievement if non-programmer users could access whatever information they want to know. There has been a lot of effort oriented to solve this task using natural language processing tools and creativity encouragement by way of many challenges. Our approach focuses on assuming a correct entity linking on the natural language questions and training a GPT model to create SPARQL queries from them. We managed to isolate which property of the task can be the most difficult to solve at few or zero-shot and we proposed pre-training on all entities (under CWA) to improve the performance. We obtained a 62.703% accuracy of exact SPARQL matches on testing at 3-shots, a F1 of 0.809 on the entity linking challenge and a F1 of 0.009 on the question answering challenge.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31383;&#21475;&#36807;&#28388;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#35821;&#20041;&#25628;&#32034;&#38382;&#39064;&#20013;&#23454;&#29616;&#39640;&#36895;&#25628;&#32034;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36895;&#24230;&#25552;&#21319;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00943</link><description>&lt;p&gt;
&#20351;&#29992;&#31383;&#21475;&#36807;&#28388;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Approximate Nearest Neighbor Search with Window Filters
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00943
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31383;&#21475;&#36807;&#28388;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#35821;&#20041;&#25628;&#32034;&#38382;&#39064;&#20013;&#23454;&#29616;&#39640;&#36895;&#25628;&#32034;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36895;&#24230;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23450;&#20041;&#24182;&#30740;&#31350;&#20102;$\textit{c-&#36817;&#20284;&#31383;&#21475;&#25628;&#32034;}$&#38382;&#39064;&#65306;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#20854;&#20013;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#28857;&#37117;&#26377;&#19968;&#20010;&#25968;&#20540;&#26631;&#31614;&#65292;&#30446;&#26631;&#26159;&#22312;&#20219;&#24847;&#26631;&#31614;&#33539;&#22260;&#20869;&#25214;&#21040;&#26597;&#35810;&#28857;&#30340;&#26368;&#36817;&#37051;&#12290;&#35768;&#22810;&#35821;&#20041;&#25628;&#32034;&#38382;&#39064;&#65292;&#20363;&#22914;&#24102;&#26377;&#26102;&#38388;&#25139;&#36807;&#28388;&#22120;&#30340;&#22270;&#20687;&#21644;&#25991;&#26723;&#25628;&#32034;&#65292;&#25110;&#24102;&#26377;&#25104;&#26412;&#36807;&#28388;&#22120;&#30340;&#20135;&#21697;&#25628;&#32034;&#65292;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#33258;&#28982;&#20363;&#23376;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#22312;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22359;&#21270;&#26641;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#35299;&#20915;&#20256;&#32479;c-&#36817;&#20284;&#26368;&#36817;&#37051;&#38382;&#39064;&#30340;&#32034;&#24341;&#36716;&#21270;&#20026;&#35299;&#20915;&#31383;&#21475;&#25628;&#32034;&#30340;&#25968;&#25454;&#32467;&#26500;&#12290;&#22312;&#26631;&#20934;&#30340;&#26368;&#36817;&#37051;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#65292;&#37197;&#22791;&#20102;&#38543;&#26426;&#26631;&#31614;&#20540;&#12289;&#23545;&#25239;&#24615;&#26500;&#24314;&#30340;&#23884;&#20837;&#20197;&#21450;&#24102;&#26377;&#30495;&#23454;&#26102;&#38388;&#25139;&#30340;&#22270;&#20687;&#25628;&#32034;&#23884;&#20837;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19982;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30456;&#27604;&#39640;&#36798;75&#20493;&#30340;&#36895;&#24230;&#25552;&#21319;&#65292;&#21516;&#26102;&#20445;&#25345;&#30456;&#21516;&#30340;&#21484;&#22238;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We define and investigate the problem of $\textit{c-approximate window search}$: approximate nearest neighbor search where each point in the dataset has a numeric label, and the goal is to find nearest neighbors to queries within arbitrary label ranges. Many semantic search problems, such as image and document search with timestamp filters, or product search with cost filters, are natural examples of this problem. We propose and theoretically analyze a modular tree-based framework for transforming an index that solves the traditional c-approximate nearest neighbor problem into a data structure that solves window search. On standard nearest neighbor benchmark datasets equipped with random label values, adversarially constructed embeddings, and image search embeddings with real timestamps, we obtain up to a $75\times$ speedup over existing solutions at the same level of recall.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26469;&#35299;&#20915;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22686;&#24378;&#29305;&#24449;&#25552;&#21462;&#22120;&#30340;&#29983;&#25104;&#33021;&#21147;&#26469;&#20943;&#36731;&#26102;&#38388;&#29305;&#24449;&#28418;&#31227;&#30340;&#24433;&#21709;&#12290;</title><link>https://rss.arxiv.org/abs/2312.09901</link><description>&lt;p&gt;
&#20919;&#21551;&#21160;&#25512;&#33616;&#30340;&#26102;&#38388;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Temporally and Distributionally Robust Optimization for Cold-Start Recommendation
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2312.09901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26469;&#35299;&#20915;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22686;&#24378;&#29305;&#24449;&#25552;&#21462;&#22120;&#30340;&#29983;&#25104;&#33021;&#21147;&#26469;&#20943;&#36731;&#26102;&#38388;&#29305;&#24449;&#28418;&#31227;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#65288;Collaborative Filtering&#65292;CF&#65289;&#25512;&#33616;&#27169;&#22411;&#39640;&#24230;&#20381;&#36182;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#26469;&#23398;&#20064;CF&#34920;&#31034;&#65292;&#22240;&#27492;&#22312;&#25512;&#33616;&#20919;&#21551;&#21160;&#39033;&#30446;&#26041;&#38754;&#23384;&#22312;&#30701;&#26495;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#24341;&#20837;&#39033;&#30446;&#29305;&#24449;&#65288;&#22914;&#32553;&#30053;&#22270;&#65289;&#36827;&#34892;&#20919;&#21551;&#21160;&#39033;&#30446;&#25512;&#33616;&#12290;&#20182;&#20204;&#22312;&#28909;&#21551;&#21160;&#39033;&#30446;&#19978;&#23398;&#20064;&#19968;&#20010;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#20197;&#20351;&#29305;&#24449;&#34920;&#31034;&#19982;&#20132;&#20114;&#23545;&#40784;&#65292;&#28982;&#21518;&#21033;&#29992;&#29305;&#24449;&#25552;&#21462;&#22120;&#25552;&#21462;&#20919;&#21551;&#21160;&#39033;&#30446;&#30340;&#29305;&#24449;&#34920;&#31034;&#36827;&#34892;&#20132;&#20114;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#20919;&#21551;&#21160;&#39033;&#30446;&#30340;&#29305;&#24449;&#65292;&#23588;&#20854;&#26159;&#21463;&#27426;&#36814;&#30340;&#39033;&#30446;&#65292;&#30001;&#20110;&#26102;&#38388;&#29305;&#24449;&#28418;&#31227;&#65292;&#24448;&#24448;&#19982;&#28909;&#21551;&#21160;&#39033;&#30446;&#30340;&#29305;&#24449;&#20559;&#31163;&#65292;&#20351;&#24471;&#29305;&#24449;&#25552;&#21462;&#22120;&#26080;&#27861;&#20934;&#30830;&#23398;&#20064;&#20919;&#21551;&#21160;&#39033;&#30446;&#30340;&#29305;&#24449;&#34920;&#31034;&#12290;&#20026;&#20102;&#20943;&#36731;&#26102;&#38388;&#29305;&#24449;&#28418;&#31227;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;Distributionally Robust Optimization&#65292;DRO&#65289;&#26469;&#22686;&#24378;&#29305;&#24449;&#25552;&#21462;&#22120;&#30340;&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;DRO&#26041;&#27861;&#38754;&#20020;&#19968;&#20010;i
&lt;/p&gt;
&lt;p&gt;
Collaborative Filtering (CF) recommender models highly depend on user-item interactions to learn CF representations, thus falling short of recommending cold-start items. To address this issue, prior studies mainly introduce item features (e.g., thumbnails) for cold-start item recommendation. They learn a feature extractor on warm-start items to align feature representations with interactions, and then leverage the feature extractor to extract the feature representations of cold-start items for interaction prediction. Unfortunately, the features of cold-start items, especially the popular ones, tend to diverge from those of warm-start ones due to temporal feature shifts, preventing the feature extractor from accurately learning feature representations of cold-start items.   To alleviate the impact of temporal feature shifts, we consider using Distributionally Robust Optimization (DRO) to enhance the generation ability of the feature extractor. Nonetheless, existing DRO methods face an i
&lt;/p&gt;</description></item><item><title>&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#21040;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#36716;&#21464;&#12290;&#36825;&#31687;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25512;&#33616;&#25968;&#25454;&#30340;&#20027;&#35201;&#38382;&#39064;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2401.17878</link><description>&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Data-Centric Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17878
&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#21040;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#36716;&#21464;&#12290;&#36825;&#31687;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25512;&#33616;&#25968;&#25454;&#30340;&#20027;&#35201;&#38382;&#39064;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#24212;&#23545;&#20449;&#24687;&#36807;&#36733;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#23454;&#38469;&#22330;&#26223;&#12290;&#26368;&#36817;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#36235;&#21183;&#20986;&#29616;&#20102;&#33539;&#24335;&#36716;&#21464;&#65292;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#30340;&#21019;&#26032;&#36716;&#21521;&#25968;&#25454;&#36136;&#37327;&#21644;&#25968;&#37327;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#19968;&#21464;&#21270;&#24341;&#20986;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#65288;Data-Centric RS&#65289;&#30340;&#27010;&#24565;&#65292;&#26631;&#24535;&#30528;&#35813;&#39046;&#22495;&#30340;&#37325;&#35201;&#21457;&#23637;&#12290;&#26412;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#22320;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#65292;&#21253;&#25324;1&#65289;&#25512;&#33616;&#25968;&#25454;&#21644;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#65307;2&#65289;&#25512;&#33616;&#25968;&#25454;&#38754;&#20020;&#30340;&#19977;&#20010;&#20027;&#35201;&#38382;&#39064;&#65307;3&#65289;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#32780;&#24320;&#23637;&#30340;&#26368;&#36817;&#30740;&#31350;&#65307;&#20197;&#21450;4&#65289;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#30340;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) have become essential tools for mitigating information overload in a range of real-world scenarios. Recent trends in RS have seen a paradigm shift, moving the spotlight from model-centric innovations to the importance of data quality and quantity. This evolution has given rise to the concept of data-centric recommender systems (Data-Centric RS), marking a significant development in the field. This survey provides the first systematic overview of Data-Centric RS, covering 1) the foundational concepts of recommendation data and Data-Centric RS; 2) three primary issues in recommendation data; 3) recent research developed to address these issues; and 4) several potential future directions in Data-Centric RS.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;DQN&#30340;&#22312;&#32447;&#21361;&#26426;&#20107;&#20214;&#25688;&#35201;&#29983;&#25104;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#24635;&#32467;&#22810;&#20010;&#28798;&#23475;&#30456;&#20851;&#30340;&#25968;&#25454;&#27969;&#65292;&#26080;&#38656;&#20154;&#24037;&#26631;&#27880;&#25110;&#20869;&#23481;&#37325;&#26032;&#25490;&#24207;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2401.06683</link><description>&lt;p&gt;
DQNC2S&#65306;&#22522;&#20110;DQN&#30340;&#36328;&#27969;&#21361;&#26426;&#20107;&#20214;&#25688;&#35201;&#29983;&#25104;&#22120;
&lt;/p&gt;
&lt;p&gt;
DQNC2S: DQN-based Cross-stream Crisis event Summarizer. (arXiv:2401.06683v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;DQN&#30340;&#22312;&#32447;&#21361;&#26426;&#20107;&#20214;&#25688;&#35201;&#29983;&#25104;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#24635;&#32467;&#22810;&#20010;&#28798;&#23475;&#30456;&#20851;&#30340;&#25968;&#25454;&#27969;&#65292;&#26080;&#38656;&#20154;&#24037;&#26631;&#27880;&#25110;&#20869;&#23481;&#37325;&#26032;&#25490;&#24207;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21516;&#26102;&#24635;&#32467;&#22810;&#20010;&#19982;&#28798;&#23475;&#30456;&#20851;&#30340;&#25968;&#25454;&#27969;&#23588;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#29616;&#26377;&#30340;&#26816;&#32034;&#19982;&#37325;&#26032;&#25490;&#24207;&#31574;&#30053;&#22312;&#22810;&#27969;&#25968;&#25454;&#30340;&#22266;&#26377;&#20887;&#20313;&#21644;&#22810;&#26597;&#35810;&#29615;&#22659;&#19979;&#30340;&#38480;&#21046;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#26631;&#27880;&#21644;&#28145;&#24230;Q&#32593;&#32476;&#30340;&#22312;&#32447;&#21361;&#26426;&#26102;&#38388;&#36724;&#29983;&#25104;&#26041;&#27861;&#12290;&#23427;&#33021;&#22815;&#23454;&#26102;&#36873;&#25321;&#30456;&#20851;&#30340;&#25991;&#26412;&#29255;&#27573;&#65292;&#26080;&#38656;&#20154;&#24037;&#26631;&#27880;&#25110;&#20869;&#23481;&#37325;&#26032;&#25490;&#24207;&#65292;&#20174;&#32780;&#20351;&#25512;&#29702;&#26102;&#38388;&#19982;&#36755;&#20837;&#26597;&#35810;&#30340;&#25968;&#37327;&#26080;&#20851;&#12290;&#35813;&#26041;&#27861;&#36824;&#23558;&#20887;&#20313;&#36807;&#28388;&#22120;&#34701;&#20837;&#22870;&#21169;&#20989;&#25968;&#20013;&#65292;&#20197;&#26377;&#25928;&#22788;&#29702;&#36328;&#27969;&#20869;&#23481;&#37325;&#21472;&#12290;&#22312;CrisisFACTS 2022&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25152;&#36798;&#21040;&#30340;ROUGE&#21644;BERTScore&#32467;&#26524;&#20248;&#20110;&#26368;&#20339;&#24615;&#33021;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Summarizing multiple disaster-relevant data streams simultaneously is particularly challenging as existing Retrieve&amp;Re-ranking strategies suffer from the inherent redundancy of multi-stream data and limited scalability in a multi-query setting. This work proposes an online approach to crisis timeline generation based on weak annotation with Deep Q-Networks. It selects on-the-fly the relevant pieces of text without requiring neither human annotations nor content re-ranking. This makes the inference time independent of the number of input queries. The proposed approach also incorporates a redundancy filter into the reward function to effectively handle cross-stream content overlaps. The achieved ROUGE and BERTScore results are superior to those of best-performing models on the CrisisFACTS 2022 benchmark.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#20013;&#24847;&#22270;&#23398;&#20064;&#30340;&#31471;&#21040;&#31471;&#21487;&#23398;&#20064;&#32858;&#31867;&#26041;&#27861;ELCRec&#65292;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#30340;&#22797;&#26434;&#20248;&#21270;&#38382;&#39064;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#32858;&#31867;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.05975</link><description>&lt;p&gt;
&#29992;&#20110;&#25512;&#33616;&#20013;&#24847;&#22270;&#23398;&#20064;&#30340;&#31471;&#21040;&#31471;&#21487;&#23398;&#20064;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
End-to-end Learnable Clustering for Intent Learning in Recommendation. (arXiv:2401.05975v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#20013;&#24847;&#22270;&#23398;&#20064;&#30340;&#31471;&#21040;&#31471;&#21487;&#23398;&#20064;&#32858;&#31867;&#26041;&#27861;ELCRec&#65292;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#30340;&#22797;&#26434;&#20248;&#21270;&#38382;&#39064;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#32858;&#31867;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25366;&#25496;&#29992;&#25143;&#30340;&#24847;&#22270;&#22312;&#24207;&#21015;&#25512;&#33616;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;ICLRec&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21644;&#32858;&#31867;&#26469;&#25552;&#21462;&#29992;&#25143;&#30340;&#28508;&#22312;&#24847;&#22270;&#12290;&#23613;&#31649;&#23427;&#24050;&#32463;&#26174;&#31034;&#20986;&#26377;&#25928;&#24615;&#65292;&#20294;&#29616;&#26377;&#30340;&#26041;&#27861;&#23384;&#22312;&#22797;&#26434;&#21644;&#32321;&#29712;&#30340;&#20132;&#26367;&#20248;&#21270;&#38382;&#39064;&#65292;&#23548;&#33268;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#22312;&#24191;&#20041;&#26399;&#26395;&#26368;&#22823;&#21270;(EM)&#26694;&#26550;&#20013;&#20998;&#31163;&#34920;&#31034;&#23398;&#20064;&#21644;&#32858;&#31867;&#20248;&#21270;&#32463;&#24120;&#23548;&#33268;&#27425;&#20248;&#24615;&#33021;&#12290;&#20854;&#27425;&#65292;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#32858;&#31867;&#20250;&#24433;&#21709;&#22823;&#35268;&#27169;&#34892;&#19994;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24847;&#22270;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;ELCRec&#65292;&#23427;&#23558;&#34920;&#31034;&#23398;&#20064;&#38598;&#25104;&#21040;&#19968;&#20010;&#31471;&#21040;&#31471;&#21487;&#23398;&#20064;&#32858;&#31867;&#26694;&#26550;&#20013;&#36827;&#34892;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mining users' intents plays a crucial role in sequential recommendation. The recent approach, ICLRec, was introduced to extract underlying users' intents using contrastive learning and clustering. While it has shown effectiveness, the existing method suffers from complex and cumbersome alternating optimization, leading to two main issues. Firstly, the separation of representation learning and clustering optimization within a generalized expectation maximization (EM) framework often results in sub-optimal performance. Secondly, performing clustering on the entire dataset hampers scalability for large-scale industry data. To address these challenges, we propose a novel intent learning method called \underline{ELCRec}, which integrates representation learning into an \underline{E}nd-to-end \underline{L}earnable \underline{C}lustering framework for \underline{Rec}ommendation. Specifically, we encode users' behavior sequences and initialize the cluster centers as learnable network parameter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.05817</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22914;&#20309;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#21463;&#30410;&#65306;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Can Recommender Systems Benefit from Large Language Models: A Survey. (arXiv:2306.05817v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21305;&#37197;&#20114;&#32852;&#32593;&#24212;&#29992;&#31243;&#24207;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20986;&#20102;&#24778;&#20154;&#30340;&#26032;&#20852;&#33021;&#21147;&#65288;&#20363;&#22914;&#25351;&#20196;&#36319;&#36394;&#12289;&#25512;&#29702;&#65289;&#65292;&#20174;&#32780;&#20026;&#23558;LLM&#35843;&#25972;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#20197;&#25552;&#39640;&#24615;&#33021;&#21644;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#30340;&#30740;&#31350;&#26041;&#21521;&#24102;&#26469;&#20102;&#24076;&#26395;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#24212;&#29992;&#23548;&#21521;&#30340;&#35282;&#24230;&#23545;&#27492;&#30740;&#31350;&#26041;&#21521;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#20004;&#20010;&#27491;&#20132;&#30340;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#23545;&#20110;&#8220;&#22312;&#21738;&#37324;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;LLM&#22312;&#25512;&#33616;&#27969;&#31243;&#30340;&#19981;&#21516;&#38454;&#27573;&#20013;&#21487;&#33021;&#21457;&#25381;&#30340;&#20316;&#29992;&#65292;&#21363;&#29305;&#24449;&#24037;&#31243;&#12289;&#29305;&#24449;&#32534;&#30721;&#22120;&#12289;&#35780;&#20998;/&#25490;&#21517;&#20989;&#25968;&#21644;&#27969;&#31243;&#25511;&#21046;&#22120;&#12290;&#23545;&#20110;&#8220;&#22914;&#20309;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#31574;&#30053;&#65292;&#20174;&#32780;&#24471;&#20986;&#20004;&#20010;&#32454;&#31890;&#24230;&#30340;&#20998;&#31867;&#26631;&#20934;&#65292;&#21363;&#26159;&#21542;&#35843;&#25972;LLM&#21644;&#26159;&#21542;&#23558;LLM&#20316;&#20026;&#29420;&#31435;&#27169;&#22411;&#25110;&#28151;&#21512;&#27169;&#22411;&#32452;&#20214;&#20351;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#23558;LLM&#35843;&#25972;&#21040;RS&#20013;&#30340;&#19968;&#20123;&#25361;&#25112;&#21644;&#28508;&#22312;&#26041;&#21521;&#65292;&#21253;&#25324;&#19982;&#29616;&#26377;&#31995;&#32479;&#30340;&#38598;&#25104;&#12289;&#29992;&#25143;&#21453;&#39304;&#12289;&#35780;&#20272;&#24230;&#37327;&#21644;&#30693;&#35782;&#33976;&#39311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) play important roles to match users' information needs for Internet applications. In natural language processing (NLP) domains, large language model (LLM) has shown astonishing emergent abilities (e.g., instruction following, reasoning), thus giving rise to the promising research direction of adapting LLM to RS for performance enhancements and user experience improvements. In this paper, we conduct a comprehensive survey on this research direction from an application-oriented view. We first summarize existing research works from two orthogonal perspectives: where and how to adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, and pipeline controller. For the "HOW" question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLMs or not, a
&lt;/p&gt;</description></item></channel></rss>