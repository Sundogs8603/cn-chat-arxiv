<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20316;&#36127;&#36733;&#21644;&#23398;&#20064;&#30340;Z-&#32034;&#24341;&#21464;&#20307;&#65292;&#36890;&#36807;&#20248;&#21270;&#23384;&#20648;&#24067;&#23616;&#21644;&#25628;&#32034;&#32467;&#26500;&#65292;&#25913;&#21892;&#20102;&#33539;&#22260;&#26597;&#35810;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#39029;&#38754;&#36339;&#36291;&#26426;&#21046;&#36827;&#19968;&#27493;&#25552;&#21319;&#26597;&#35810;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#32034;&#24341;&#22312;&#33539;&#22260;&#26597;&#35810;&#26102;&#38388;&#12289;&#28857;&#26597;&#35810;&#24615;&#33021;&#21644;&#26500;&#24314;&#26102;&#38388;&#19982;&#32034;&#24341;&#22823;&#23567;&#20043;&#38388;&#20445;&#25345;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2310.04268</link><description>&lt;p&gt;
&#22522;&#20110;&#24037;&#20316;&#36127;&#36733;&#21644;&#23398;&#20064;&#30340;Z-&#32034;&#24341;
&lt;/p&gt;
&lt;p&gt;
Workload-aware and Learned Z-Indexes. (arXiv:2310.04268v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04268
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20316;&#36127;&#36733;&#21644;&#23398;&#20064;&#30340;Z-&#32034;&#24341;&#21464;&#20307;&#65292;&#36890;&#36807;&#20248;&#21270;&#23384;&#20648;&#24067;&#23616;&#21644;&#25628;&#32034;&#32467;&#26500;&#65292;&#25913;&#21892;&#20102;&#33539;&#22260;&#26597;&#35810;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#39029;&#38754;&#36339;&#36291;&#26426;&#21046;&#36827;&#19968;&#27493;&#25552;&#21319;&#26597;&#35810;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#32034;&#24341;&#22312;&#33539;&#22260;&#26597;&#35810;&#26102;&#38388;&#12289;&#28857;&#26597;&#35810;&#24615;&#33021;&#21644;&#26500;&#24314;&#26102;&#38388;&#19982;&#32034;&#24341;&#22823;&#23567;&#20043;&#38388;&#20445;&#25345;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20316;&#36127;&#36733;&#21644;&#23398;&#20064;&#30340;Z-&#32034;&#24341;&#30340;&#21464;&#20307;&#65292;&#35813;&#32034;&#24341;&#21516;&#26102;&#20248;&#21270;&#23384;&#20648;&#24067;&#23616;&#21644;&#25628;&#32034;&#32467;&#26500;&#65292;&#20316;&#20026;&#35299;&#20915;&#31354;&#38388;&#32034;&#24341;&#30340;&#25361;&#25112;&#30340;&#21487;&#34892;&#35299;&#20915;&#26041;&#26696;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#21046;&#23450;&#20102;&#19968;&#20010;&#25104;&#26412;&#20989;&#25968;&#65292;&#29992;&#20110;&#34913;&#37327;Z-&#32034;&#24341;&#22312;&#25968;&#25454;&#38598;&#19978;&#30340;&#33539;&#22260;&#26597;&#35810;&#24037;&#20316;&#36127;&#36733;&#19979;&#30340;&#24615;&#33021;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#20998;&#21306;&#21644;&#25490;&#24207;&#20248;&#21270;Z-&#32034;&#24341;&#32467;&#26500;&#65292;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39029;&#38754;&#36339;&#36291;&#26426;&#21046;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#26080;&#20851;&#25968;&#25454;&#39029;&#38754;&#30340;&#35775;&#38382;&#26469;&#25913;&#21892;&#26597;&#35810;&#24615;&#33021;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#22522;&#32447;&#65292;&#25105;&#20204;&#30340;&#32034;&#24341;&#24179;&#22343;&#25913;&#21892;&#20102;40%&#30340;&#33539;&#22260;&#26597;&#35810;&#26102;&#38388;&#65292;&#21516;&#26102;&#22987;&#32456;&#34920;&#29616;&#24471;&#26356;&#22909;&#25110;&#19982;&#26368;&#20808;&#36827;&#30340;&#31354;&#38388;&#32034;&#24341;&#30456;&#24403;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32034;&#24341;&#22312;&#25552;&#20379;&#26377;&#21033;&#30340;&#26500;&#24314;&#26102;&#38388;&#21644;&#32034;&#24341;&#22823;&#23567;&#26435;&#34913;&#30340;&#21516;&#26102;&#65292;&#20445;&#25345;&#33391;&#22909;&#30340;&#28857;&#26597;&#35810;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, a learned and workload-aware variant of a Z-index, which jointly optimizes storage layout and search structures, as a viable solution for the above challenges of spatial indexing. Specifically, we first formulate a cost function to measure the performance of a Z-index on a dataset for a range-query workload. Then, we optimize the Z-index structure by minimizing the cost function through adaptive partitioning and ordering for index construction. Moreover, we design a novel page-skipping mechanism to improve its query performance by reducing access to irrelevant data pages. Our extensive experiments show that our index improves range query time by 40% on average over the baselines, while always performing better or comparably to state-of-the-art spatial indexes. Additionally, our index maintains good point query performance while providing favourable construction time and index size tradeoffs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CoHeat&#31639;&#27861;&#65292;&#19968;&#31181;&#20934;&#30830;&#30340;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#26041;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#32467;&#21512;&#21382;&#21490;&#21644;&#20851;&#32852;&#20449;&#24687;&#65292;&#24212;&#23545;&#25414;&#32465;&#20114;&#21160;&#20998;&#24067;&#30340;&#20542;&#26012;&#65292;&#24182;&#26377;&#25928;&#22320;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.03813</link><description>&lt;p&gt;
&#20934;&#30830;&#30340;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#65306;&#22522;&#20110;&#27969;&#34892;&#24230;&#30340;&#32858;&#21512;&#21644;&#35838;&#31243;&#21152;&#28909;
&lt;/p&gt;
&lt;p&gt;
Accurate Cold-start Bundle Recommendation via Popularity-based Coalescence and Curriculum Heating. (arXiv:2310.03813v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CoHeat&#31639;&#27861;&#65292;&#19968;&#31181;&#20934;&#30830;&#30340;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#26041;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#32467;&#21512;&#21382;&#21490;&#21644;&#20851;&#32852;&#20449;&#24687;&#65292;&#24212;&#23545;&#25414;&#32465;&#20114;&#21160;&#20998;&#24067;&#30340;&#20542;&#26012;&#65292;&#24182;&#26377;&#25928;&#22320;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#20934;&#30830;&#22320;&#21521;&#29992;&#25143;&#25512;&#33616;&#20919;&#21551;&#21160;&#25414;&#32465;&#65311;&#25414;&#32465;&#25512;&#33616;&#20013;&#30340;&#20919;&#21551;&#21160;&#38382;&#39064;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#26032;&#24314;&#25414;&#32465;&#19981;&#26029;&#20986;&#29616;&#20197;&#28385;&#36275;&#21508;&#31181;&#33829;&#38144;&#30446;&#30340;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#20043;&#21069;&#27809;&#26377;&#30740;&#31350;&#28041;&#21450;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#20919;&#21551;&#21160;&#29289;&#21697;&#25512;&#33616;&#26041;&#27861;&#36807;&#20110;&#20381;&#36182;&#21382;&#21490;&#20449;&#24687;&#65292;&#21363;&#20351;&#23545;&#20110;&#19981;&#21463;&#27426;&#36814;&#30340;&#25414;&#32465;&#20063;&#26159;&#22914;&#27492;&#65292;&#26080;&#27861;&#24212;&#23545;&#25414;&#32465;&#20114;&#21160;&#20998;&#24067;&#39640;&#24230;&#20542;&#26012;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CoHeat&#65288;&#22522;&#20110;&#27969;&#34892;&#24230;&#30340;&#32858;&#21512;&#21644;&#35838;&#31243;&#21152;&#28909;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20934;&#30830;&#30340;&#20919;&#21551;&#21160;&#25414;&#32465;&#25512;&#33616;&#26041;&#27861;&#12290;CoHeat&#36890;&#36807;&#32467;&#21512;&#21382;&#21490;&#20449;&#24687;&#21644;&#20851;&#32852;&#20449;&#24687;&#26469;&#20272;&#35745;&#29992;&#25143;&#19982;&#25414;&#32465;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#24212;&#23545;&#25414;&#32465;&#20114;&#21160;&#20998;&#24067;&#30340;&#39640;&#24230;&#20542;&#26012;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;CoHeat&#36824;&#36890;&#36807;&#21033;&#29992;&#35838;&#31243;&#23398;&#20064;&#21644;&#32858;&#21512;&#29305;&#24449;&#23398;&#20064;&#25928;&#26524;&#22320;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can we accurately recommend cold-start bundles to users? The cold-start problem in bundle recommendation is critical in practical scenarios since new bundles are continuously created for various marketing purposes. Despite its importance, no previous studies have addressed cold-start bundle recommendation. Moreover, existing methods for cold-start item recommendation overly rely on historical information, even for unpopular bundles, failing to tackle the primary challenge of the highly skewed distribution of bundle interactions. In this work, we propose CoHeat (Popularity-based Coalescence and Curriculum Heating), an accurate approach for the cold-start bundle recommendation. CoHeat tackles the highly skewed distribution of bundle interactions by incorporating both historical and affiliation information based on the bundle's popularity when estimating the user-bundle relationship. Furthermore, CoHeat effectively learns latent representations by exploiting curriculum learning and co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20010;&#24615;&#21270;Transformer&#30340;&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;&#65292;&#36890;&#36807;&#20248;&#21270;&#25490;&#21517;&#38454;&#27573;&#30340;&#29305;&#24449;&#29983;&#25104;&#65292;&#25552;&#39640;&#20102;&#25512;&#33616;&#36136;&#37327;&#12290;&#21516;&#26102;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#29992;&#20110;&#35299;&#20915;&#20559;&#32622;&#19978;&#19979;&#25991;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.03481</link><description>&lt;p&gt;
&#22522;&#20110;&#20010;&#24615;&#21270;Transformer&#30340;Yandex&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Personalized Transformer-based Ranking for e-Commerce at Yandex. (arXiv:2310.03481v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20010;&#24615;&#21270;Transformer&#30340;&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;&#65292;&#36890;&#36807;&#20248;&#21270;&#25490;&#21517;&#38454;&#27573;&#30340;&#29305;&#24449;&#29983;&#25104;&#65292;&#25552;&#39640;&#20102;&#25512;&#33616;&#36136;&#37327;&#12290;&#21516;&#26102;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#29992;&#20110;&#35299;&#20915;&#20559;&#32622;&#19978;&#19979;&#25991;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#29992;&#25143;&#27963;&#21160;&#20026;&#22522;&#30784;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#25512;&#33616;&#23545;&#20110;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#29992;&#25143;&#24847;&#22270;&#19981;&#26126;&#30830;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20027;&#39029;&#19978;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#23884;&#20837;&#24335;&#30340;&#20010;&#24615;&#21270;&#31995;&#32479;&#22312;&#30005;&#23376;&#21830;&#21153;&#39046;&#22495;&#30340;&#25512;&#33616;&#21644;&#25628;&#32034;&#32467;&#26524;&#36136;&#37327;&#26041;&#38754;&#26377;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24037;&#20316;&#22823;&#22810;&#38598;&#20013;&#22312;&#22686;&#24378;&#26816;&#32034;&#38454;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38024;&#23545;&#30005;&#23376;&#21830;&#21153;&#25512;&#33616;&#20013;&#30340;&#25490;&#21517;&#38454;&#27573;&#65292;&#26816;&#32034;&#32858;&#28966;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20135;&#29983;&#30340;&#29305;&#24449;&#26159;&#27425;&#20248;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#35757;&#32451;&#36807;&#31243;&#65292;&#36890;&#36807;&#24494;&#35843;&#20004;&#22612;&#27169;&#22411;&#26469;&#23454;&#29616;&#26368;&#20339;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;&#25105;&#20204;&#35814;&#32454;&#25551;&#36848;&#20102;&#25105;&#20204;&#19987;&#38376;&#20026;&#30005;&#23376;&#21830;&#21153;&#20010;&#24615;&#21270;&#35774;&#35745;&#30340;&#22522;&#20110;Transformer&#30340;&#20004;&#22612;&#27169;&#22411;&#26550;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#32447;&#27169;&#22411;&#20013;&#21435;&#20559;&#32622;&#19978;&#19979;&#25991;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalizing the user experience with high-quality recommendations based on user activities is vital for e-commerce platforms. This is particularly important in scenarios where the user's intent is not explicit, such as on the homepage. Recently, personalized embedding-based systems have significantly improved the quality of recommendations and search results in the e-commerce domain. However, most of these works focus on enhancing the retrieval stage.  In this paper, we demonstrate that features produced by retrieval-focused deep learning models are sub-optimal for ranking stage in e-commerce recommendations. To address this issue, we propose a two-stage training process that fine-tunes two-tower models to achieve optimal ranking performance. We provide a detailed description of our transformer-based two-tower model architecture, which is specifically designed for personalization in e-commerce.  Additionally, we introduce a novel technique for debiasing context in offline models and 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#35775;&#35848;&#12289;&#35843;&#26597;&#21644;&#22312;&#32447;&#23454;&#39564;&#65292;&#22312;&#29702;&#35299;&#29992;&#25143;&#23545;&#20110;&#30005;&#24433;&#25512;&#33616;&#31995;&#32479;&#24191;&#24230;&#30340;&#24773;&#24863;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#20123;&#21457;&#29616;&#65292;&#29421;&#31364;&#30340;&#25512;&#33616;&#34987;&#35748;&#20026;&#26159;&#26377;&#29992;&#30340;&#65292;&#20294;&#20063;&#26377;&#19968;&#37096;&#20998;&#29992;&#25143;&#24076;&#26395;&#33719;&#24471;&#26356;&#24191;&#27867;&#30340;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2309.13296</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#30005;&#24433;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20114;&#21160;&#20869;&#23481;&#22810;&#26679;&#24615;&#21644;&#29992;&#25143;&#25506;&#32034;&#65306;&#29616;&#22330;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Interactive Content Diversity and User Exploration in Online Movie Recommenders: A Field Experiment. (arXiv:2309.13296v1 [cs.HC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13296
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#35775;&#35848;&#12289;&#35843;&#26597;&#21644;&#22312;&#32447;&#23454;&#39564;&#65292;&#22312;&#29702;&#35299;&#29992;&#25143;&#23545;&#20110;&#30005;&#24433;&#25512;&#33616;&#31995;&#32479;&#24191;&#24230;&#30340;&#24773;&#24863;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#20123;&#21457;&#29616;&#65292;&#29421;&#31364;&#30340;&#25512;&#33616;&#34987;&#35748;&#20026;&#26159;&#26377;&#29992;&#30340;&#65292;&#20294;&#20063;&#26377;&#19968;&#37096;&#20998;&#29992;&#25143;&#24076;&#26395;&#33719;&#24471;&#26356;&#24191;&#27867;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24120;&#24120;&#38590;&#20197;&#22312;&#28385;&#36275;&#29992;&#25143;&#21475;&#21619;&#21644;&#25552;&#20379;&#24847;&#22806;&#25512;&#33616;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;&#24403;&#25512;&#33616;&#36807;&#20110;&#29421;&#31364;&#65292;&#26080;&#27861;&#28085;&#30422;&#29992;&#25143;&#20559;&#22909;&#30340;&#23436;&#25972;&#33539;&#22260;&#26102;&#65292;&#31995;&#32479;&#34987;&#35748;&#20026;&#26080;&#29992;&#12290;&#30456;&#21453;&#65292;&#24403;&#31995;&#32479;&#24314;&#35758;&#22826;&#22810;&#29992;&#25143;&#19981;&#21916;&#27426;&#30340;&#29289;&#21697;&#26102;&#65292;&#34987;&#35748;&#20026;&#26159;&#20919;&#28448;&#25110;&#26080;&#25928;&#30340;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#20102;&#35299;&#29992;&#25143;&#23545;&#30005;&#24433;&#25512;&#33616;&#31995;&#32479;&#24191;&#24230;&#30340;&#24773;&#24863;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#35775;&#35848;&#21644;&#35843;&#26597;&#65292;&#24182;&#21457;&#29616;&#35768;&#22810;&#29992;&#25143;&#35748;&#20026;&#29421;&#31364;&#30340;&#25512;&#33616;&#26159;&#26377;&#29992;&#30340;&#65292;&#32780;&#23569;&#25968;&#29992;&#25143;&#26126;&#30830;&#24076;&#26395;&#33719;&#24471;&#26356;&#24191;&#27867;&#30340;&#25512;&#33616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#24182;&#36827;&#34892;&#20102;&#19968;&#39033;&#22312;&#32447;&#29616;&#22330;&#23454;&#39564;&#65292;&#35780;&#20272;&#20102;&#20004;&#31181;&#26032;&#25509;&#21475;&#65292;&#26088;&#22312;&#21521;&#29992;&#25143;&#25552;&#20379;&#26356;&#24191;&#27867;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#35266;&#23519;&#20102;&#20004;&#32452;&#29992;&#25143;&#30340;&#20559;&#22909;&#21644;&#34892;&#20026;&#65306;&#20855;&#26377;&#36739;&#39640;&#21021;&#22987;&#30005;&#24433;&#22810;&#26679;&#24615;&#21644;&#20855;&#26377;&#36739;&#20302;&#22810;&#26679;&#24615;&#30340;&#29992;&#25143;&#12290;&#22312;&#25105;&#20204;&#30340;&#21457;&#29616;&#20013;&#65292;
&lt;/p&gt;
&lt;p&gt;
Recommender systems often struggle to strike a balance between matching users' tastes and providing unexpected recommendations. When recommendations are too narrow and fail to cover the full range of users' preferences, the system is perceived as useless. Conversely, when the system suggests too many items that users don't like, it is considered impersonal or ineffective. To better understand user sentiment about the breadth of recommendations given by a movie recommender, we conducted interviews and surveys and found out that many users considered narrow recommendations to be useful, while a smaller number explicitly wanted greater breadth. Additionally, we designed and ran an online field experiment with a larger user group, evaluating two new interfaces designed to provide users with greater access to broader recommendations. We looked at user preferences and behavior for two groups of users: those with higher initial movie diversity and those with lower diversity. Among our finding
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20026;&#20102;&#26356;&#26377;&#25928;&#22320;&#31579;&#36873;&#31995;&#32479;&#24615;&#23457;&#26597;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#25506;&#32034;&#20351;&#29992;&#19981;&#21516;&#30340;&#26597;&#35810;&#26469;&#28304;&#65292;&#22914;&#29992;&#20110;&#26816;&#32034;&#25991;&#26723;&#21644;&#22522;&#20110;&#25351;&#20196;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#26597;&#35810;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#31579;&#36873;&#36807;&#31243;&#20013;&#26356;&#20934;&#30830;&#22320;&#25490;&#21517;&#37325;&#35201;&#25991;&#26723;&#65292;&#24182;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.05238</link><description>&lt;p&gt;
&#20026;&#26356;&#26377;&#25928;&#30340;&#31995;&#32479;&#24615;&#23457;&#26597;&#31579;&#36873;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;
&lt;/p&gt;
&lt;p&gt;
Generating Natural Language Queries for More Effective Systematic Review Screening Prioritisation. (arXiv:2309.05238v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05238
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20026;&#20102;&#26356;&#26377;&#25928;&#22320;&#31579;&#36873;&#31995;&#32479;&#24615;&#23457;&#26597;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#25506;&#32034;&#20351;&#29992;&#19981;&#21516;&#30340;&#26597;&#35810;&#26469;&#28304;&#65292;&#22914;&#29992;&#20110;&#26816;&#32034;&#25991;&#26723;&#21644;&#22522;&#20110;&#25351;&#20196;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#26597;&#35810;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#31579;&#36873;&#36807;&#31243;&#20013;&#26356;&#20934;&#30830;&#22320;&#25490;&#21517;&#37325;&#35201;&#25991;&#26723;&#65292;&#24182;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#23398;&#31995;&#32479;&#24615;&#23457;&#26597;&#20013;&#30340;&#31579;&#36873;&#20248;&#20808;&#32423;&#30446;&#26631;&#26159;&#36890;&#36807;&#22797;&#26434;&#30340;&#24067;&#23572;&#26597;&#35810;&#23545;&#26816;&#32034;&#21040;&#30340;&#25991;&#26723;&#38598;&#36827;&#34892;&#25490;&#21517;&#12290;&#20248;&#20808;&#22788;&#29702;&#26368;&#37325;&#35201;&#30340;&#25991;&#26723;&#21487;&#20197;&#30830;&#20445;&#21518;&#32493;&#23457;&#26597;&#27493;&#39588;&#33021;&#22815;&#26356;&#39640;&#25928;&#12289;&#26356;&#26377;&#25928;&#22320;&#36827;&#34892;&#12290;&#30446;&#21069;&#30340;&#26368;&#26032;&#25216;&#26415;&#20351;&#29992;&#23457;&#26597;&#30340;&#26368;&#32456;&#26631;&#39064;&#20316;&#20026;&#26597;&#35810;&#65292;&#21033;&#29992;&#22522;&#20110;BERT&#30340;&#31070;&#32463;&#25490;&#24207;&#22120;&#23545;&#25991;&#26723;&#36827;&#34892;&#25490;&#21517;&#12290;&#28982;&#32780;&#65292;&#26368;&#32456;&#26631;&#39064;&#21482;&#22312;&#23457;&#26597;&#36807;&#31243;&#32467;&#26463;&#26102;&#24418;&#25104;&#65292;&#36825;&#20351;&#24471;&#35813;&#26041;&#27861;&#19981;&#20999;&#23454;&#38469;&#65292;&#22240;&#20026;&#23427;&#20381;&#36182;&#20110;ex post facto&#30340;&#20449;&#24687;&#12290;&#22312;&#31579;&#36873;&#30340;&#26102;&#20505;&#65292;&#21482;&#26377;&#19968;&#20010;&#31895;&#30053;&#30340;&#24037;&#20316;&#26631;&#39064;&#21487;&#29992;&#65292;&#20351;&#29992;BERT-based&#25490;&#24207;&#22120;&#26102;&#25928;&#26524;&#26126;&#26174;&#19981;&#22914;&#26368;&#32456;&#26631;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#29992;&#20110;&#31579;&#36873;&#20248;&#20808;&#32423;&#30340;&#26597;&#35810;&#30340;&#26367;&#20195;&#26469;&#28304;&#65292;&#20363;&#22914;&#29992;&#20110;&#26816;&#32034;&#24453;&#31579;&#36873;&#25991;&#26723;&#30340;&#24067;&#23572;&#26597;&#35810;&#65292;&#20197;&#21450;&#30001;&#22522;&#20110;&#25351;&#20196;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;ChatGPT&#21644;Alpaca&#65289;&#29983;&#25104;&#30340;&#26597;&#35810;&#12290;&#25105;&#20204;&#30340;&#26368;&#20339;&#26041;&#27861;&#19981;&#20165;&#20165;&#26159;
&lt;/p&gt;
&lt;p&gt;
Screening prioritisation in medical systematic reviews aims to rank the set of documents retrieved by complex Boolean queries. Prioritising the most important documents ensures that subsequent review steps can be carried out more efficiently and effectively. The current state of the art uses the final title of the review as a query to rank the documents using BERT-based neural rankers. However, the final title is only formulated at the end of the review process, which makes this approach impractical as it relies on ex post facto information. At the time of screening, only a rough working title is available, with which the BERT-based ranker performs significantly worse than with the final title. In this paper, we explore alternative sources of queries for prioritising screening, such as the Boolean query used to retrieve the documents to be screened and queries generated by instruction-based generative large-scale language models such as ChatGPT and Alpaca. Our best approach is not only
&lt;/p&gt;</description></item><item><title>ConvFormer&#26159;&#19968;&#31181;&#23545;Transformer&#26550;&#26500;&#36827;&#34892;&#25913;&#36827;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#39034;&#24207;&#29992;&#25143;&#24314;&#27169;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;Transformer&#30340;&#26680;&#24515;&#26500;&#24314;&#27169;&#22359;&#21644;&#20998;&#26512;&#39033;&#30446;&#23545;&#39033;&#30446;&#26426;&#21046;&#65292;&#22312;&#36827;&#34892;&#23454;&#39564;&#20998;&#26512;&#21518;&#30830;&#23450;&#20102;&#19977;&#20010;&#22522;&#26412;&#26631;&#20934;&#65292;&#24182;&#24341;&#20837;&#20102;ConvFormer&#26469;&#28385;&#36275;&#36825;&#20123;&#26631;&#20934;&#12290;</title><link>http://arxiv.org/abs/2308.02925</link><description>&lt;p&gt;
ConvFormer&#65306;&#37325;&#26032;&#23457;&#35270;Transformer&#29992;&#20110;&#39034;&#24207;&#29992;&#25143;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
ConvFormer: Revisiting Transformer for Sequential User Modeling. (arXiv:2308.02925v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02925
&lt;/p&gt;
&lt;p&gt;
ConvFormer&#26159;&#19968;&#31181;&#23545;Transformer&#26550;&#26500;&#36827;&#34892;&#25913;&#36827;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#39034;&#24207;&#29992;&#25143;&#24314;&#27169;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;Transformer&#30340;&#26680;&#24515;&#26500;&#24314;&#27169;&#22359;&#21644;&#20998;&#26512;&#39033;&#30446;&#23545;&#39033;&#30446;&#26426;&#21046;&#65292;&#22312;&#36827;&#34892;&#23454;&#39564;&#20998;&#26512;&#21518;&#30830;&#23450;&#20102;&#19977;&#20010;&#22522;&#26412;&#26631;&#20934;&#65292;&#24182;&#24341;&#20837;&#20102;ConvFormer&#26469;&#28385;&#36275;&#36825;&#20123;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#29992;&#25143;&#24314;&#27169;&#26159;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#65292;&#20854;&#30528;&#37325;&#20110;&#39044;&#27979;&#29992;&#25143;&#26368;&#21916;&#27426;&#30340;&#19979;&#19968;&#20010;&#39033;&#30446;&#65292;&#38656;&#35201;&#28145;&#20837;&#29702;&#35299;&#29992;&#25143;&#30340;&#34892;&#20026;&#24207;&#21015;&#12290;&#23613;&#31649;Transformer&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#30528;&#25104;&#21151;&#65292;&#20294;&#22312;&#29702;&#35299;&#29992;&#25143;&#34892;&#20026;&#26041;&#38754;&#23578;&#26410;&#20805;&#20998;&#21457;&#25381;&#20854;&#28508;&#21147;&#12290;&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Transformer&#31867;&#20284;&#30340;&#26550;&#26500;&#65292;&#26088;&#22312;&#25512;&#36827;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#39318;&#20808;&#37325;&#26032;&#23457;&#35270;Transformer&#26041;&#27861;&#30340;&#26680;&#24515;&#26500;&#24314;&#27169;&#22359;&#65292;&#22312;&#39034;&#24207;&#29992;&#25143;&#24314;&#27169;&#30340;&#32972;&#26223;&#19979;&#20998;&#26512;&#39033;&#30446;&#23545;&#39033;&#30446;&#26426;&#21046;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#36827;&#34892;&#24443;&#24213;&#30340;&#23454;&#39564;&#20998;&#26512;&#21518;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19977;&#20010;&#35774;&#35745;&#39640;&#25928;&#39034;&#24207;&#29992;&#25143;&#27169;&#22411;&#30340;&#22522;&#26412;&#26631;&#20934;&#65292;&#24076;&#26395;&#36825;&#20123;&#26631;&#20934;&#33021;&#20316;&#20026;&#23454;&#29992;&#25351;&#21335;&#65292;&#28608;&#21457;&#21644;&#22609;&#36896;&#26410;&#26469;&#30340;&#35774;&#35745;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ConvFormer&#65292;&#19968;&#31181;&#23545;Transformer&#26550;&#26500;&#36827;&#34892;&#31616;&#21333;&#20294;&#24378;&#22823;&#20462;&#25913;&#30340;&#26041;&#27861;&#65292;&#28385;&#36275;&#20102;&#36825;&#20123;&#26631;&#20934;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential user modeling, a critical task in personalized recommender systems, focuses on predicting the next item a user would prefer, requiring a deep understanding of user behavior sequences. Despite the remarkable success of Transformer-based models across various domains, their full potential in comprehending user behavior remains untapped. In this paper, we re-examine Transformer-like architectures aiming to advance state-of-the-art performance. We start by revisiting the core building blocks of Transformer-based methods, analyzing the effectiveness of the item-to-item mechanism within the context of sequential user modeling. After conducting a thorough experimental analysis, we identify three essential criteria for devising efficient sequential user models, which we hope will serve as practical guidelines to inspire and shape future designs. Following this, we introduce ConvFormer, a simple but powerful modification to the Transformer architecture that meets these criteria, yiel
&lt;/p&gt;</description></item><item><title>PDS-Net is a novel framework for QoS prediction that effectively reduces errors resulting from noise data by utilizing a probabilistic space and a condition-based multitasking loss function.</title><link>http://arxiv.org/abs/2308.02580</link><description>&lt;p&gt;
Probabilistic Deep Supervision Network: &#19968;&#31181;&#25239;&#22122;&#22768;&#30340;QoS&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Deep Supervision Network: A Noise-Resilient Approach for QoS Prediction. (arXiv:2308.02580v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02580
&lt;/p&gt;
&lt;p&gt;
PDS-Net is a novel framework for QoS prediction that effectively reduces errors resulting from noise data by utilizing a probabilistic space and a condition-based multitasking loss function.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;QoS&#65288;&#26381;&#21153;&#36136;&#37327;&#65289;&#30340;&#39044;&#27979;&#26159;&#19968;&#39033;&#37325;&#35201;&#20219;&#21153;&#65292;&#20934;&#30830;&#39044;&#27979;&#26410;&#30693;&#30340;QoS&#20540;&#21487;&#20197;&#25552;&#39640;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;QoS&#39044;&#27979;&#25216;&#26415;&#22312;&#23384;&#22312;&#22122;&#22768;&#25968;&#25454;&#65288;&#22914;&#34394;&#20551;&#20301;&#32622;&#20449;&#24687;&#25110;&#34394;&#25311;&#32593;&#20851;&#65289;&#26102;&#21487;&#33021;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;QoS&#39044;&#27979;&#26694;&#26550;&#8212;&#8212;&#27010;&#29575;&#28145;&#24230;&#30417;&#30563;&#32593;&#32476;&#65288;PDS-Net&#65289;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;PDS-Net&#21033;&#29992;&#22522;&#20110;&#39640;&#26031;&#30340;&#27010;&#29575;&#31354;&#38388;&#30417;&#30563;&#20013;&#38388;&#23618;&#65292;&#24182;&#23398;&#20064;&#24050;&#30693;&#29305;&#24449;&#21644;&#30495;&#23454;&#26631;&#31614;&#30340;&#27010;&#29575;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;PDS-Net&#37319;&#29992;&#22522;&#20110;&#26465;&#20214;&#30340;&#22810;&#20219;&#21153;&#25439;&#22833;&#20989;&#25968;&#26469;&#35782;&#21035;&#20855;&#26377;&#22122;&#22768;&#25968;&#25454;&#30340;&#23545;&#35937;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#36825;&#20123;&#23545;&#35937;&#30340;&#27010;&#29575;&#31354;&#38388;&#19982;&#30495;&#23454;&#26631;&#31614;&#27010;&#29575;&#31354;&#38388;&#20043;&#38388;&#30340;Kullback-Leibler&#36317;&#31163;&#65292;&#30452;&#25509;&#23545;&#20174;&#27010;&#29575;&#31354;&#38388;&#20013;&#37319;&#26679;&#30340;&#28145;&#24230;&#29305;&#24449;&#36827;&#34892;&#30417;&#30563;&#12290;&#22240;&#27492;&#65292;PDS-Net&#26377;&#25928;&#20943;&#23569;&#20102;&#22240;&#20256;&#25773;&#24341;&#36215;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quality of Service (QoS) prediction is an essential task in recommendation systems, where accurately predicting unknown QoS values can improve user satisfaction. However, existing QoS prediction techniques may perform poorly in the presence of noise data, such as fake location information or virtual gateways. In this paper, we propose the Probabilistic Deep Supervision Network (PDS-Net), a novel framework for QoS prediction that addresses this issue. PDS-Net utilizes a Gaussian-based probabilistic space to supervise intermediate layers and learns probability spaces for both known features and true labels. Moreover, PDS-Net employs a condition-based multitasking loss function to identify objects with noise data and applies supervision directly to deep features sampled from the probability space by optimizing the Kullback-Leibler distance between the probability space of these objects and the real-label probability space. Thus, PDS-Net effectively reduces errors resulting from the propag
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#19968;&#33268;&#24615;&#30340;&#22312;&#32447;&#24191;&#21578;&#39044;&#25490;&#21517;&#26694;&#26550;&#65292;&#21033;&#29992;&#20102;&#19968;&#20010;&#22522;&#20110;&#22359;&#30340;&#37319;&#26679;&#27169;&#22359;&#21644;&#19968;&#20010;&#21363;&#25554;&#21363;&#29992;&#30340;&#25490;&#21517;&#23545;&#40784;&#27169;&#22359;&#65292;&#26469;&#26174;&#24335;&#20248;&#21270;ECPM&#25490;&#21517;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#12290;&#20182;&#20204;&#37319;&#29992;&#20102;&#22522;&#20110;Delta NDCG&#30340;&#21152;&#26435;&#26426;&#21046;&#65292;&#20197;&#26356;&#22909;&#22320;&#21306;&#20998;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.03516</link><description>&lt;p&gt;
COPR&#65306;&#38754;&#21521;&#19968;&#33268;&#24615;&#30340;&#22312;&#32447;&#24191;&#21578;&#39044;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
COPR: Consistency-Oriented Pre-Ranking for Online Advertising. (arXiv:2306.03516v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03516
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#19968;&#33268;&#24615;&#30340;&#22312;&#32447;&#24191;&#21578;&#39044;&#25490;&#21517;&#26694;&#26550;&#65292;&#21033;&#29992;&#20102;&#19968;&#20010;&#22522;&#20110;&#22359;&#30340;&#37319;&#26679;&#27169;&#22359;&#21644;&#19968;&#20010;&#21363;&#25554;&#21363;&#29992;&#30340;&#25490;&#21517;&#23545;&#40784;&#27169;&#22359;&#65292;&#26469;&#26174;&#24335;&#20248;&#21270;ECPM&#25490;&#21517;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#12290;&#20182;&#20204;&#37319;&#29992;&#20102;&#22522;&#20110;Delta NDCG&#30340;&#21152;&#26435;&#26426;&#21046;&#65292;&#20197;&#26356;&#22909;&#22320;&#21306;&#20998;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32423;&#32852;&#26550;&#26500;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#24191;&#21578;&#31995;&#32479;&#20013;&#20197;&#24179;&#34913;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#22312;&#36825;&#31181;&#26550;&#26500;&#20013;&#65292;&#39044;&#25490;&#21517;&#27169;&#22411;&#34987;&#26399;&#26395;&#25104;&#20026;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#25490;&#21517;&#27169;&#22411;&#36817;&#20284;&#65292;&#20197;&#22788;&#29702;&#26356;&#22810;&#20855;&#26377;&#20005;&#26684;&#24310;&#36831;&#35201;&#27714;&#30340;&#20505;&#36873;&#32773;&#12290;&#30001;&#20110;&#27169;&#22411;&#23481;&#37327;&#30340;&#24046;&#36317;&#65292;&#39044;&#25490;&#21517;&#21644;&#25490;&#21517;&#27169;&#22411;&#36890;&#24120;&#20250;&#29983;&#25104;&#19981;&#19968;&#33268;&#30340;&#25490;&#21517;&#32467;&#26524;&#65292;&#20174;&#32780;&#25439;&#23475;&#25972;&#20010;&#31995;&#32479;&#30340;&#25928;&#26524;&#12290;&#25552;&#20986;&#20102;&#24471;&#20998;&#23545;&#40784;&#30340;&#33539;&#24335;&#20197;&#35268;&#33539;&#23427;&#20204;&#30340;&#21407;&#22987;&#20998;&#25968;&#65292;&#20351;&#23427;&#20204;&#20445;&#25345;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#22312;&#22312;&#32447;&#24191;&#21578;&#20013;&#24212;&#29992;&#26102;&#65292;&#30001;&#20110;&#24517;&#28982;&#30340;&#23545;&#40784;&#35823;&#24046;&#21644;&#31454;&#26631;&#30340;&#35823;&#24046;&#25918;&#22823;&#65292;&#23427;&#20250;&#36973;&#21463;&#22256;&#25200;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38754;&#21521;&#19968;&#33268;&#24615;&#30340;&#22312;&#32447;&#24191;&#21578;&#39044;&#25490;&#21517;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#37319;&#29992;&#20102;&#19968;&#20010;&#22522;&#20110;&#22359;&#30340;&#37319;&#26679;&#27169;&#22359;&#21644;&#19968;&#20010;&#21363;&#25554;&#21363;&#29992;&#30340;&#25490;&#21517;&#23545;&#40784;&#27169;&#22359;&#65292;&#26469;&#26174;&#24335;&#20248;&#21270;ECPM&#25490;&#21517;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#12290;&#37319;&#29992;&#20102;&#22522;&#20110;$\Delta NDCG$&#30340;&#21152;&#26435;&#26426;&#21046;&#65292;&#20197;&#26356;&#22909;&#22320;&#21306;&#20998;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cascading architecture has been widely adopted in large-scale advertising systems to balance efficiency and effectiveness. In this architecture, the pre-ranking model is expected to be a lightweight approximation of the ranking model, which handles more candidates with strict latency requirements. Due to the gap in model capacity, the pre-ranking and ranking models usually generate inconsistent ranked results, thus hurting the overall system effectiveness. The paradigm of score alignment is proposed to regularize their raw scores to be consistent. However, it suffers from inevitable alignment errors and error amplification by bids when applied in online advertising. To this end, we introduce a consistency-oriented pre-ranking framework for online advertising, which employs a chunk-based sampling module and a plug-and-play rank alignment module to explicitly optimize consistency of ECPM-ranked results. A $\Delta NDCG$-based weighting mechanism is adopted to better distinguish the import
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39034;&#24207;&#28436;&#21270;&#26465;&#20214;&#20114;&#21160;&#30693;&#35782;&#22270;&#35889; (SCEIKG) &#26694;&#26550;&#65292;&#29992;&#20110;&#20013;&#21307;&#33647;&#25512;&#33616;&#12290;&#36825;&#20010;&#26694;&#26550;&#36890;&#36807;&#32771;&#34385;&#24739;&#32773;&#22312;&#22810;&#27425;&#23601;&#35786;&#20013;&#30340;&#30149;&#24773;&#21160;&#24577;&#21644;&#33609;&#33647;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#25552;&#20379;&#20934;&#30830;&#30340;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2305.17866</link><description>&lt;p&gt;
&#12298;&#39034;&#24207;&#28436;&#21270;&#26465;&#20214;&#20114;&#21160;&#30693;&#35782;&#22270;&#35889;&#22312;&#20013;&#21307;&#33647;&#25512;&#33616;&#20013;&#30340;&#24212;&#29992;&#12299;
&lt;/p&gt;
&lt;p&gt;
Sequential Condition Evolved Interaction Knowledge Graph for Traditional Chinese Medicine Recommendation. (arXiv:2305.17866v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39034;&#24207;&#28436;&#21270;&#26465;&#20214;&#20114;&#21160;&#30693;&#35782;&#22270;&#35889; (SCEIKG) &#26694;&#26550;&#65292;&#29992;&#20110;&#20013;&#21307;&#33647;&#25512;&#33616;&#12290;&#36825;&#20010;&#26694;&#26550;&#36890;&#36807;&#32771;&#34385;&#24739;&#32773;&#22312;&#22810;&#27425;&#23601;&#35786;&#20013;&#30340;&#30149;&#24773;&#21160;&#24577;&#21644;&#33609;&#33647;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#25552;&#20379;&#20934;&#30830;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#20013;&#21307;&#33647; (TCM) &#22312;&#27835;&#30103;&#21508;&#31181;&#30142;&#30149;&#26102;&#26377;&#30528;&#20016;&#23500;&#30340;&#21382;&#21490;&#65292;&#21033;&#29992;&#22825;&#28982;&#33609;&#33647;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;TCM&#30340;&#35786;&#26029;&#21644;&#27835;&#30103;&#39640;&#24230;&#20010;&#24615;&#21270;&#65292;&#26377;&#26426;&#32508;&#21512;&#65292;&#38656;&#35201;&#20840;&#38754;&#32771;&#34385;&#24739;&#32773;&#30340;&#29366;&#20917;&#21644;&#30151;&#29366;&#21464;&#21270;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;TCM&#25512;&#33616;&#26041;&#27861;&#24573;&#30053;&#20102;&#24739;&#32773;&#29366;&#24577;&#30340;&#21464;&#21270;&#65292;&#21482;&#25506;&#32034;&#30151;&#29366;&#21644;&#22788;&#26041;&#20043;&#38388;&#30340;&#28508;&#22312;&#27169;&#24335;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39034;&#24207;&#28436;&#21270;&#26465;&#20214;&#20114;&#21160;&#30693;&#35782;&#22270;&#35889; (SCEIKG) &#26694;&#26550;&#65292;&#23558;&#27169;&#22411;&#35270;&#20026;&#19968;&#20010;&#39034;&#24207;&#22788;&#26041;&#21046;&#23450;&#38382;&#39064;&#65292;&#32771;&#34385;&#20102;&#24739;&#32773;&#22312;&#22810;&#27425;&#23601;&#35786;&#20013;&#30340;&#30149;&#24773;&#21160;&#24577;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#20114;&#21160;&#30693;&#35782;&#22270;&#35889;&#32435;&#20837;&#21040;&#25512;&#33616;&#20013;&#65292;&#36890;&#36807;&#32771;&#34385;&#19981;&#21516;&#33609;&#33647;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#21644;&#24739;&#32773;&#30340;&#29366;&#20917;&#26469;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;TCM&#25512;&#33616;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional Chinese Medicine (TCM) has a rich history of utilizing natural herbs to treat a diversity of illnesses. In practice, TCM diagnosis and treatment are highly personalized and organically holistic, requiring comprehensive consideration of the patient's state and symptoms over time. However, existing TCM recommendation approaches overlook the changes in patient status and only explore potential patterns between symptoms and prescriptions. In this paper, we propose a novel Sequential Condition Evolved Interaction Knowledge Graph (SCEIKG), a framework that treats the model as a sequential prescription-making problem by considering the dynamics of the patient's condition across multiple visits. In addition, we incorporate an interaction knowledge graph to enhance the accuracy of recommendations by considering the interactions between different herbs and the patient's condition. Experimental results on a real-world dataset demonstrate that our approach outperforms existing TCM reco
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#30693;&#35782;&#21453;&#24605;&#30340;&#26032;&#33539;&#24335;&#65292;&#26088;&#22312;&#24110;&#21161;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21033;&#29992;&#24050;&#32463;&#32534;&#30721;&#22312;&#20854;&#39044;&#35757;&#32451;&#21442;&#25968;&#20013;&#30340;&#30456;&#20851;&#28508;&#22312;&#30693;&#35782;&#65292;&#32780;&#19981;&#38656;&#35201;&#20174;&#22806;&#37096;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#22312;&#27169;&#22411;&#20013;&#28155;&#21152;&#25552;&#31034;&#65292;&#24182;&#23558;&#30456;&#20851;&#30693;&#35782;&#27880;&#20837;&#27169;&#22411;&#36827;&#34892;&#25972;&#21512;&#65292;&#21462;&#24471;&#20102;&#22312;&#24120;&#35782;&#25512;&#29702;&#20219;&#21153;&#21644;GLUE&#22522;&#20934;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.08732</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#21453;&#24605;
&lt;/p&gt;
&lt;p&gt;
Knowledge Rumination for Pre-trained Language Models. (arXiv:2305.08732v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08732
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#30693;&#35782;&#21453;&#24605;&#30340;&#26032;&#33539;&#24335;&#65292;&#26088;&#22312;&#24110;&#21161;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21033;&#29992;&#24050;&#32463;&#32534;&#30721;&#22312;&#20854;&#39044;&#35757;&#32451;&#21442;&#25968;&#20013;&#30340;&#30456;&#20851;&#28508;&#22312;&#30693;&#35782;&#65292;&#32780;&#19981;&#38656;&#35201;&#20174;&#22806;&#37096;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#22312;&#27169;&#22411;&#20013;&#28155;&#21152;&#25552;&#31034;&#65292;&#24182;&#23558;&#30456;&#20851;&#30693;&#35782;&#27880;&#20837;&#27169;&#22411;&#36827;&#34892;&#25972;&#21512;&#65292;&#21462;&#24471;&#20102;&#22312;&#24120;&#35782;&#25512;&#29702;&#20219;&#21153;&#21644;GLUE&#22522;&#20934;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#26222;&#36890;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#21333;&#29420;&#22788;&#29702;&#30693;&#35782;&#23494;&#38598;&#22411;NLP&#20219;&#21153;&#30340;&#33021;&#21147;&#19981;&#36275;&#65292;&#22240;&#27492;&#65292;&#19968;&#20123;&#24037;&#20316;&#23581;&#35797;&#23558;&#22806;&#37096;&#30693;&#35782;&#38598;&#25104;&#21040;PLMs&#20013;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26377;&#30528;&#26377;&#21069;&#36884;&#30340;&#32467;&#26524;&#65292;&#20294;&#25105;&#20204;&#32463;&#39564;&#24615;&#22320;&#35266;&#23519;&#21040;&#65292;PLM&#21487;&#33021;&#24050;&#32463;&#22312;&#20854;&#39044;&#35757;&#32451;&#21442;&#25968;&#20013;&#32534;&#30721;&#20102;&#20016;&#23500;&#30340;&#30693;&#35782;&#65292;&#20294;&#22312;&#24212;&#29992;&#21040;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#26102;&#26410;&#33021;&#20805;&#20998;&#21033;&#29992;&#23427;&#20204;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#30693;&#35782;&#21453;&#24605;&#30340;&#26032;&#33539;&#24335;&#65292;&#20197;&#24110;&#21161;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21033;&#29992;&#30456;&#20851;&#30340;&#28508;&#22312;&#30693;&#35782;&#65292;&#32780;&#19981;&#38656;&#35201;&#20174;&#22806;&#37096;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#23427;&#20204;&#12290;&#36890;&#36807;&#31616;&#21333;&#22320;&#22312;PLMs&#20013;&#28155;&#21152;&#19968;&#20010;&#22914;&#8220;&#25454;&#25105;&#25152;&#30693;&#8221;&#30340;&#25552;&#31034;&#65292;&#25105;&#20204;&#35797;&#22270;&#22238;&#39038;&#30456;&#20851;&#30340;&#28508;&#22312;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#27880;&#20837;&#27169;&#22411;&#20197;&#36827;&#34892;&#30693;&#35782;&#25972;&#21512;&#12290;&#25105;&#20204;&#23558;&#25552;&#20986;&#30340;&#30693;&#35782;&#21453;&#24605;&#24212;&#29992;&#20110;&#21508;&#31181;&#35821;&#35328;&#27169;&#22411;&#65292;&#21253;&#25324;RoBERTa&#12289;DeBERTa&#21644;GPT-3&#12290;&#22312;&#20845;&#20010;&#24120;&#35782;&#25512;&#29702;&#20219;&#21153;&#21644;GLUE&#22522;&#20934;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;.....
&lt;/p&gt;
&lt;p&gt;
Previous studies have revealed that vanilla pre-trained language models (PLMs) lack the capacity to handle knowledge-intensive NLP tasks alone; thus, several works have attempted to integrate external knowledge into PLMs. However, despite the promising outcome, we empirically observe that PLMs may have already encoded rich knowledge in their pre-trained parameters but fail to fully utilize them when applying them to knowledge-intensive tasks. In this paper, we propose a new paradigm dubbed Knowledge Rumination to help the pre-trained language model utilize that related latent knowledge without retrieving it from the external corpus. By simply adding a prompt like "As far as I know" to the PLMs, we try to review related latent knowledge and inject them back into the model for knowledge consolidation. We apply the proposed knowledge rumination to various language models, including RoBERTa, DeBERTa, and GPT-3. Experimental results on six commonsense reasoning tasks and GLUE benchmarks dem
&lt;/p&gt;</description></item><item><title>PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.06674</link><description>&lt;p&gt;
PK-ICR: &#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#36827;&#34892;&#22522;&#20110;&#22330;&#26223;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue. (arXiv:2302.06674v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06674
&lt;/p&gt;
&lt;p&gt;
PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#21035;&#19982;&#23545;&#35805;&#31995;&#32479;&#30456;&#20851;&#30340;&#35282;&#33394;&#21644;&#30693;&#35782;&#23545;&#20110;&#22522;&#20110;&#22330;&#26223;&#30340;&#23545;&#35805;&#24212;&#31572;&#29983;&#25104;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#27599;&#20010;&#23545;&#35805;&#22522;&#26412;&#19978;&#37117;&#26159;&#23396;&#31435;&#30740;&#31350;&#30340;&#65292;&#32780;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#24341;&#20837;&#20102;&#26356;&#23454;&#38469;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20219;&#21153;&#12290;&#25105;&#20204;&#23558;&#35282;&#33394;&#21644;&#30693;&#35782;&#21452;&#19978;&#19979;&#25991;&#35782;&#21035;&#23450;&#20041;&#20026;&#20026;&#32473;&#23450;&#30340;&#23545;&#35805;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20219;&#21153;&#65292;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#35774;&#32622;&#20013;&#21487;&#33021;&#20855;&#26377;&#25552;&#21319;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26816;&#32034;&#30340;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#21033;&#29992;&#23545;&#35805;&#30340;&#25152;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#34913;&#37327;&#19982;&#25968;&#25454;&#22686;&#24378;&#30456;&#20851;&#30340;&#35821;&#20041;&#24046;&#24322;&#26679;&#26412;&#65288;&#21363;&#22256;&#38590;&#36127;&#26679;&#26412;&#65289;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying relevant persona or knowledge for conversational systems is critical to grounded dialogue response generation. However, each grounding has been mostly researched in isolation with more practical multi-context dialogue tasks introduced in recent works. We define Persona and Knowledge Dual Context Identification as the task to identify persona and knowledge jointly for a given dialogue, which could be of elevated importance in complex multi-context dialogue settings. We develop a novel grounding retrieval method that utilizes all contexts of dialogue simultaneously. Our method requires less computational power via utilizing neural QA retrieval models. We further introduce our novel null-positive rank test which measures ranking performance on semantically dissimilar samples (i.e. hard negatives) in relation to data augmentation.
&lt;/p&gt;</description></item><item><title>GraphFormers&#26159;&#19968;&#31181;&#23558;GNN&#23884;&#22871;&#21040;Transformer&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#24335;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#20934;&#30830;&#29702;&#35299;&#25991;&#26412;&#22270;&#20013;&#27599;&#20010;&#33410;&#28857;&#30340;&#35821;&#20041;&#65292;&#21516;&#26102;&#24341;&#20837;&#28176;&#36827;&#24335;&#23398;&#20064;&#21152;&#36895;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2105.02605</link><description>&lt;p&gt;
GraphFormers: GNN&#23884;&#22871;Transformer&#29992;&#20110;&#25991;&#26412;&#22270;&#30340;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph. (arXiv:2105.02605v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.02605
&lt;/p&gt;
&lt;p&gt;
GraphFormers&#26159;&#19968;&#31181;&#23558;GNN&#23884;&#22871;&#21040;Transformer&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#24335;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#20934;&#30830;&#29702;&#35299;&#25991;&#26412;&#22270;&#20013;&#27599;&#20010;&#33410;&#28857;&#30340;&#35821;&#20041;&#65292;&#21516;&#26102;&#24341;&#20837;&#28176;&#36827;&#24335;&#23398;&#20064;&#21152;&#36895;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#22270;&#30340;&#34920;&#31034;&#23398;&#20064;&#26159;&#22522;&#20110;&#20010;&#20307;&#25991;&#26412;&#29305;&#24449;&#21644;&#37051;&#22495;&#20449;&#24687;&#29983;&#25104;&#33410;&#28857;&#20302;&#32500;&#23884;&#20837;&#30340;&#36807;&#31243;&#12290;&#26368;&#36817;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#31361;&#30772;&#25512;&#21160;&#20102;&#30456;&#24212;&#25216;&#26415;&#30340;&#21457;&#23637;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#20027;&#35201;&#20381;&#36182;&#32423;&#32852;&#27169;&#22411;&#26550;&#26500;&#65306;&#39318;&#20808;&#65292;&#33410;&#28857;&#30340;&#25991;&#26412;&#29305;&#24449;&#30001;&#35821;&#35328;&#27169;&#22411;&#29420;&#31435;&#32534;&#30721;&#65307;&#28982;&#21518;&#65292;&#25991;&#26412;&#23884;&#20837;&#30001;&#22270;&#31070;&#32463;&#32593;&#32476;&#32858;&#21512;&#12290;&#28982;&#32780;&#65292;&#19978;&#36848;&#26550;&#26500;&#30001;&#20110;&#23545;&#25991;&#26412;&#29305;&#24449;&#30340;&#29420;&#31435;&#24314;&#27169;&#32780;&#21463;&#21040;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;GraphFormers&#65292;&#20854;&#20013;GNN&#30340;&#20998;&#23618;&#32452;&#20214;&#23884;&#22871;&#22312;&#35821;&#35328;&#27169;&#22411;&#30340;Transformer&#22359;&#26049;&#36793;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;&#26550;&#26500;&#65292;&#25991;&#26412;&#32534;&#30721;&#21644;&#22270;&#32858;&#21512;&#34701;&#21512;&#20026;&#19968;&#20010;&#36845;&#20195;&#24335;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#20174;&#20840;&#23616;&#35270;&#35282;&#20934;&#30830;&#29702;&#35299;&#27599;&#20010;&#33410;&#28857;&#30340;&#35821;&#20041;&#12290;&#27492;&#22806;&#65292;&#19968;&#31181;&#28176;&#36827;&#24335;&#23398;&#20064;&#26041;&#27861;&#34987;&#24341;&#20837;&#20197;&#21152;&#36895;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
The representation learning on textual graph is to generate low-dimensional embeddings for the nodes based on the individual textual features and the neighbourhood information. Recent breakthroughs on pretrained language models and graph neural networks push forward the development of corresponding techniques. The existing works mainly rely on the cascaded model architecture: the textual features of nodes are independently encoded by language models at first; the textual embeddings are aggregated by graph neural networks afterwards. However, the above architecture is limited due to the independent modeling of textual features. In this work, we propose GraphFormers, where layerwise GNN components are nested alongside the transformer blocks of language models. With the proposed architecture, the text encoding and the graph aggregation are fused into an iterative workflow, {making} each node's semantic accurately comprehended from the global perspective. In addition, a {progressive} learn
&lt;/p&gt;</description></item></channel></rss>