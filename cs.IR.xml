<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>NeMig&#26159;&#19968;&#20221;&#20851;&#20110;&#31227;&#27665;&#30340;&#21452;&#35821;&#26032;&#38395;&#25910;&#38598;&#21644;&#30693;&#35782;&#22270;&#35889;&#65292;&#23545;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#25991;&#31456;&#30340;&#24773;&#32490;&#20542;&#21521;&#12289;&#23186;&#20307;&#26426;&#26500;&#30340;&#25919;&#27835;&#20542;&#21521;&#65292;&#20197;&#21450;&#28040;&#27495;&#20041;&#30340;&#23376;&#20027;&#39064;&#21644;&#21629;&#21517;&#23454;&#20307;&#12290;</title><link>http://arxiv.org/abs/2309.00550</link><description>&lt;p&gt;
NeMig -- &#19968;&#20221;&#20851;&#20110;&#31227;&#27665;&#30340;&#21452;&#35821;&#26032;&#38395;&#25910;&#38598;&#21644;&#30693;&#35782;&#22270;&#35889;
&lt;/p&gt;
&lt;p&gt;
NeMig -- A Bilingual News Collection and Knowledge Graph about Migration. (arXiv:2309.00550v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00550
&lt;/p&gt;
&lt;p&gt;
NeMig&#26159;&#19968;&#20221;&#20851;&#20110;&#31227;&#27665;&#30340;&#21452;&#35821;&#26032;&#38395;&#25910;&#38598;&#21644;&#30693;&#35782;&#22270;&#35889;&#65292;&#23545;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#25991;&#31456;&#30340;&#24773;&#32490;&#20542;&#21521;&#12289;&#23186;&#20307;&#26426;&#26500;&#30340;&#25919;&#27835;&#20542;&#21521;&#65292;&#20197;&#21450;&#28040;&#27495;&#20041;&#30340;&#23376;&#20027;&#39064;&#21644;&#21629;&#21517;&#23454;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#38395;&#25512;&#33616;&#36890;&#36807;&#36807;&#28388;&#21644;&#20256;&#25773;&#20851;&#20110;&#19981;&#21516;&#20027;&#39064;&#30340;&#20449;&#24687;&#65292;&#23545;&#22609;&#36896;&#20844;&#20247;&#19990;&#30028;&#35266;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#22312;&#20170;&#22825;&#30340;&#25968;&#23383;&#31038;&#20250;&#20013;&#65292;&#29702;&#35299;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#24433;&#21709;&#24050;&#32463;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#25935;&#24863;&#35805;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;NeMig&#65292;&#19968;&#20221;&#20851;&#20110;&#31227;&#27665;&#20027;&#39064;&#30340;&#21452;&#35821;&#26032;&#38395;&#25910;&#38598;&#20197;&#21450;&#30456;&#24212;&#30340;&#20016;&#23500;&#29992;&#25143;&#25968;&#25454;&#12290;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#26032;&#38395;&#25512;&#33616;&#25968;&#25454;&#38598;&#65292;NeMig&#28085;&#30422;&#20102;&#24503;&#22269;&#21644;&#32654;&#22269;&#21457;&#24067;&#30340;&#26377;&#20851;&#21333;&#19968;&#26377;&#20105;&#35758;&#35805;&#39064;&#30340;&#25991;&#31456;&#12290;&#25105;&#20204;&#27880;&#37322;&#20102;&#25991;&#31456;&#30340;&#24773;&#32490;&#20542;&#21521;&#20197;&#21450;&#23186;&#20307;&#26426;&#26500;&#30340;&#25919;&#27835;&#20542;&#21521;&#65292;&#24182;&#25552;&#21462;&#20102;&#36890;&#36807;Wikidata&#28040;&#27495;&#20041;&#30340;&#23376;&#20027;&#39064;&#21644;&#21629;&#21517;&#23454;&#20307;&#12290;&#36825;&#20123;&#29305;&#24449;&#21487;&#20197;&#29992;&#26469;&#20998;&#26512;&#31639;&#27861;&#26032;&#38395;&#25512;&#33616;&#30340;&#24433;&#21709;&#65292;&#36229;&#36807;&#22522;&#20110;&#20934;&#30830;&#24230;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
News recommendation plays a critical role in shaping the public's worldviews through the way in which it filters and disseminates information about different topics. Given the crucial impact that media plays in opinion formation, especially for sensitive topics, understanding the effects of personalized recommendation beyond accuracy has become essential in today's digital society. In this work, we present NeMig, a bilingual news collection on the topic of migration, and corresponding rich user data. In comparison to existing news recommendation datasets, which comprise a large variety of monolingual news, NeMig covers articles on a single controversial topic, published in both Germany and the US. We annotate the sentiment polarization of the articles and the political leanings of the media outlets, in addition to extracting subtopics and named entities disambiguated through Wikidata. These features can be used to analyze the effects of algorithmic news curation beyond accuracy-based p
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#19988;&#23454;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35843;&#20248;&#29616;&#25104;&#30340;&#22270;&#24418;&#32034;&#24341;&#65292;&#36890;&#36807;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#32508;&#21512;&#35843;&#20248;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#22312;SISAP 2023&#32034;&#24341;&#25361;&#25112;&#20013;&#21462;&#24471;&#20102;&#20248;&#24322;&#30340;&#25104;&#32489;&#65292;&#24182;&#21487;&#25193;&#23637;&#21040;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2309.00472</link><description>&lt;p&gt;
&#36890;&#29992;&#19988;&#23454;&#29992;&#30340;&#22270;&#24418;&#32034;&#24341;&#35843;&#20248;&#26041;&#27861;&#65306;UTokyo&#22242;&#38431;&#30340;SISAP&#32034;&#24341;&#25361;&#25112;&#25253;&#21578;
&lt;/p&gt;
&lt;p&gt;
General and Practical Tuning Method for Off-the-Shelf Graph-Based Index: SISAP Indexing Challenge Report by Team UTokyo. (arXiv:2309.00472v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#19988;&#23454;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35843;&#20248;&#29616;&#25104;&#30340;&#22270;&#24418;&#32034;&#24341;&#65292;&#36890;&#36807;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#32508;&#21512;&#35843;&#20248;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#22312;SISAP 2023&#32034;&#24341;&#25361;&#25112;&#20013;&#21462;&#24471;&#20102;&#20248;&#24322;&#30340;&#25104;&#32489;&#65292;&#24182;&#21487;&#25193;&#23637;&#21040;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22270;&#24418;&#31639;&#27861;&#22312;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#34920;&#29616;&#20986;&#24456;&#22909;&#30340;&#25928;&#26524;&#65292;&#20294;&#22914;&#20309;&#23545;&#36825;&#20123;&#31995;&#32479;&#36827;&#34892;&#26368;&#20248;&#35843;&#20248;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#35843;&#20248;&#29616;&#25104;&#30340;&#22270;&#24418;&#32034;&#24341;&#65292;&#37325;&#28857;&#32771;&#34385;&#21521;&#37327;&#30340;&#32500;&#24230;&#12289;&#25968;&#25454;&#24211;&#22823;&#23567;&#21644;&#22270;&#36941;&#21382;&#30340;&#20837;&#21475;&#28857;&#12290;&#25105;&#20204;&#21033;&#29992;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#32508;&#21512;&#35843;&#20248;&#65292;&#20197;&#28385;&#36275;&#25152;&#38656;&#30340;&#21484;&#22238;&#29575;&#21644;&#27599;&#31186;&#26597;&#35810;&#25968;&#65288;QPS&#65289;&#27700;&#24179;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;SISAP 2023&#32034;&#24341;&#25361;&#25112;&#30340;A&#20219;&#21153;&#65292;&#24182;&#22312;10M&#21644;30M&#36712;&#36947;&#19978;&#33719;&#24471;&#31532;&#20108;&#21517;&#12290;&#19982;&#34542;&#21147;&#26041;&#27861;&#30456;&#27604;&#65292;&#23427;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36866;&#29992;&#20110;&#22270;&#24418;&#32034;&#24341;&#30340;&#35843;&#20248;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#27604;&#36187;&#20043;&#22806;&#30340;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the efficacy of graph-based algorithms for Approximate Nearest Neighbor (ANN) searches, the optimal tuning of such systems remains unclear. This study introduces a method to tune the performance of off-the-shelf graph-based indexes, focusing on the dimension of vectors, database size, and entry points of graph traversal. We utilize a black-box optimization algorithm to perform integrated tuning to meet the required levels of recall and Queries Per Second (QPS). We applied our approach to Task A of the SISAP 2023 Indexing Challenge and got second place in the 10M and 30M tracks. It improves performance substantially compared to brute force methods. This research offers a universally applicable tuning method for graph-based indexes, extending beyond the specific conditions of the competition to broader uses.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20851;&#27880;&#20110;&#20919;&#21551;&#21160;&#38382;&#39064;&#20013;&#30340;&#20559;&#22909;&#33719;&#21462;&#65292;&#22312;&#35813;&#38382;&#39064;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#32570;&#20047;&#29992;&#25143;&#23384;&#22312;&#25110;&#35775;&#38382;&#20854;&#20182;&#29992;&#25143;&#25968;&#25454;&#21463;&#38480;&#12290;&#25105;&#20204;&#37319;&#29992;&#21487;&#35299;&#37322;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#29992;&#25143;&#24037;&#20316;&#37327;&#26368;&#22823;&#21270;&#20449;&#24687;&#33719;&#21462;&#65292;&#24182;&#22312;&#20559;&#22909;&#33719;&#21462;&#36807;&#31243;&#20013;&#37319;&#29992;&#26080;&#30417;&#30563;&#12289;&#21322;&#30417;&#30563;&#21644;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.00356</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#20027;&#21160;&#23398;&#20064;&#29992;&#20110;&#20559;&#22909;&#33719;&#21462;
&lt;/p&gt;
&lt;p&gt;
Explainable Active Learning for Preference Elicitation. (arXiv:2309.00356v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20851;&#27880;&#20110;&#20919;&#21551;&#21160;&#38382;&#39064;&#20013;&#30340;&#20559;&#22909;&#33719;&#21462;&#65292;&#22312;&#35813;&#38382;&#39064;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#32570;&#20047;&#29992;&#25143;&#23384;&#22312;&#25110;&#35775;&#38382;&#20854;&#20182;&#29992;&#25143;&#25968;&#25454;&#21463;&#38480;&#12290;&#25105;&#20204;&#37319;&#29992;&#21487;&#35299;&#37322;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#29992;&#25143;&#24037;&#20316;&#37327;&#26368;&#22823;&#21270;&#20449;&#24687;&#33719;&#21462;&#65292;&#24182;&#22312;&#20559;&#22909;&#33719;&#21462;&#36807;&#31243;&#20013;&#37319;&#29992;&#26080;&#30417;&#30563;&#12289;&#21322;&#30417;&#30563;&#21644;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#20837;&#20102;&#35299;&#26032;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#24182;&#38543;&#21518;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#38656;&#35201;&#26234;&#33021;&#22320;&#22788;&#29702;&#29992;&#25143;&#20132;&#20114;&#65292;&#21363;&#25552;&#20986;&#30456;&#20851;&#38382;&#39064;&#20197;&#26377;&#25928;&#33719;&#21462;&#26377;&#20215;&#20540;&#30340;&#20449;&#24687;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#29305;&#23450;&#24773;&#26223;&#65292;&#22312;&#35813;&#24773;&#26223;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#32570;&#20047;&#36275;&#22815;&#30340;&#29992;&#25143;&#23384;&#22312;&#25110;&#35775;&#38382;&#20854;&#20182;&#29992;&#25143;&#25968;&#25454;&#21463;&#38480;&#65292;&#38459;&#30861;&#20102;&#21033;&#29992;&#31995;&#32479;&#20013;&#29616;&#26377;&#25968;&#25454;&#30340;&#29992;&#25143;&#24314;&#27169;&#26041;&#27861;&#12290;&#25105;&#20204;&#37319;&#29992;&#20027;&#21160;&#23398;&#20064;(AL)&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#22312;&#26368;&#23567;&#29992;&#25143;&#24037;&#20316;&#37327;&#30340;&#24773;&#20917;&#19979;&#26368;&#22823;&#21270;&#20449;&#24687;&#33719;&#21462;&#12290;AL&#20174;&#19968;&#20010;&#22823;&#22411;&#26080;&#26631;&#31614;&#38598;&#21512;&#20013;&#36873;&#25321;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#21521;&#35810;&#38382;&#39044;&#27979;&#26631;&#31614;&#65292;&#24182;&#26368;&#32456;&#26356;&#26032;&#26426;&#22120;&#23398;&#20064;(ML)&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#35299;&#37322;&#24615;&#20559;&#22909;&#33719;&#21462;&#36807;&#31243;&#20013;&#37319;&#29992;&#20102;&#26080;&#30417;&#30563;&#12289;&#21322;&#30417;&#30563;&#21644;&#30417;&#30563;ML&#30340;&#38598;&#25104;&#36807;&#31243;&#12290;&#23427;&#21033;&#29992;&#29992;&#25143;&#23545;&#31995;&#32479;&#36820;&#22238;&#25512;&#33616;&#30340;&#21453;&#39304;&#65288;&#32473;&#20104;&#31995;&#32479;&#30340;&#27880;&#24847;&#25110;&#21916;&#22909;&#65289;&#21644;&#29992;&#25143;&#23545;&#38382;&#39064;&#30340;&#21453;&#39304;&#21521;&#20182;&#20204;&#35299;&#37322;&#21644;&#36741;&#21161;&#20445;&#25345;&#29992;&#25143;&#28385;&#24847;&#24230;&#21644;&#21442;&#19982;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaining insights into the preferences of new users and subsequently personalizing recommendations necessitate managing user interactions intelligently, namely, posing pertinent questions to elicit valuable information effectively. In this study, our focus is on a specific scenario of the cold-start problem, where the recommendation system lacks adequate user presence or access to other users' data is restricted, obstructing employing user profiling methods utilizing existing data in the system. We employ Active Learning (AL) to solve the addressed problem with the objective of maximizing information acquisition with minimal user effort. AL operates for selecting informative data from a large unlabeled set to inquire an oracle to label them and eventually updating a machine learning (ML) model. We operate AL in an integrated process of unsupervised, semi-supervised, and supervised ML within an explanatory preference elicitation process. It harvests user feedback (given for the system's 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#22312;&#38899;&#20048;&#35270;&#39057;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#21019;&#24314;&#38899;&#39057;&#21644;&#35270;&#39057;&#27169;&#24577;&#30340;&#21452;&#21521;&#32534;&#30721;&#22120;&#24182;&#37319;&#29992;&#23545;&#27604;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38899;&#20048;&#26631;&#31614;&#21644;&#27969;&#27966;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#19982;&#26080;&#23545;&#27604;&#24494;&#35843;&#30340;&#39044;&#35757;&#32451;&#32593;&#32476;&#30456;&#27604;&#65292;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#24182;&#19981;&#26174;&#31034;&#20986;&#20248;&#21183;&#12290;&#36890;&#36807;&#23545;&#23398;&#20064;&#34920;&#31034;&#36827;&#34892;&#23450;&#24615;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#23545;&#27604;&#23398;&#20064;&#22312;&#38899;&#20048;&#35270;&#39057;&#20013;&#21487;&#33021;&#19981;&#36866;&#29992;&#30340;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2309.00347</link><description>&lt;p&gt;
&#38754;&#21521;&#38899;&#20048;&#35270;&#39057;&#39046;&#22495;&#30340;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Contrastive Learning in Music Video Domain. (arXiv:2309.00347v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#22312;&#38899;&#20048;&#35270;&#39057;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#21019;&#24314;&#38899;&#39057;&#21644;&#35270;&#39057;&#27169;&#24577;&#30340;&#21452;&#21521;&#32534;&#30721;&#22120;&#24182;&#37319;&#29992;&#23545;&#27604;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38899;&#20048;&#26631;&#31614;&#21644;&#27969;&#27966;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#19982;&#26080;&#23545;&#27604;&#24494;&#35843;&#30340;&#39044;&#35757;&#32451;&#32593;&#32476;&#30456;&#27604;&#65292;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#24182;&#19981;&#26174;&#31034;&#20986;&#20248;&#21183;&#12290;&#36890;&#36807;&#23545;&#23398;&#20064;&#34920;&#31034;&#36827;&#34892;&#23450;&#24615;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#23545;&#27604;&#23398;&#20064;&#22312;&#38899;&#20048;&#35270;&#39057;&#20013;&#21487;&#33021;&#19981;&#36866;&#29992;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#26159;&#19968;&#31181;&#23398;&#20064;&#22810;&#27169;&#24577;&#34920;&#31034;&#30340;&#24378;&#22823;&#26041;&#27861;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#22270;&#20687;-&#25991;&#26412;&#26816;&#32034;&#12289;&#38899;&#39057;-&#35270;&#35273;&#34920;&#31034;&#23398;&#20064;&#31561;&#21508;&#31181;&#39046;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20123;&#21457;&#29616;&#22312;&#38899;&#20048;&#35270;&#39057;&#39046;&#22495;&#26159;&#21542;&#36866;&#29992;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20026;&#38899;&#39057;&#21644;&#35270;&#39057;&#27169;&#24577;&#21019;&#24314;&#20102;&#19968;&#20010;&#21452;&#21521;&#32534;&#30721;&#22120;&#65292;&#24182;&#20351;&#29992;&#21452;&#21521;&#23545;&#27604;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#21253;&#21547;55&#19975;&#20010;&#38899;&#20048;&#35270;&#39057;&#30340;&#24037;&#19994;&#25968;&#25454;&#38598;&#20197;&#21450;&#20844;&#20849;&#30340;&#30334;&#19975;&#27468;&#26354;&#25968;&#25454;&#38598;&#65292;&#24182;&#22312;&#38899;&#20048;&#26631;&#31614;&#21644;&#27969;&#27966;&#20998;&#31867;&#30340;&#19979;&#28216;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#23398;&#20064;&#34920;&#31034;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#22312;&#20004;&#20010;&#20219;&#21153;&#19978;&#35780;&#20272;&#26102;&#65292;&#26080;&#23545;&#27604;&#24494;&#35843;&#30340;&#39044;&#35757;&#32451;&#32593;&#32476;&#20248;&#20110;&#25105;&#20204;&#30340;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#23545;&#27604;&#23398;&#20064;&#22312;&#38899;&#20048;&#35270;&#39057;&#20013;&#22833;&#36133;&#30340;&#21407;&#22240;&#65292;&#25105;&#20204;&#23545;&#23398;&#20064;&#34920;&#31034;&#36827;&#34892;&#20102;&#23450;&#24615;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#20026;&#20160;&#20040;&#23545;&#27604;&#23398;&#20064;&#21487;&#33021;&#19981;&#36866;&#21512;&#38899;&#20048;&#35270;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning is a powerful way of learning multimodal representations across various domains such as image-caption retrieval and audio-visual representation learning. In this work, we investigate if these findings generalize to the domain of music videos. Specifically, we create a dual en-coder for the audio and video modalities and train it using a bidirectional contrastive loss. For the experiments, we use an industry dataset containing 550 000 music videos as well as the public Million Song Dataset, and evaluate the quality of learned representations on the downstream tasks of music tagging and genre classification. Our results indicate that pre-trained networks without contrastive fine-tuning outperform our contrastive learning approach when evaluated on both tasks. To gain a better understanding of the reasons contrastive learning was not successful for music videos, we perform a qualitative analysis of the learned representations, revealing why contrastive learning might 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30340;&#21019;&#26032;&#28857;&#26159;&#23558;&#25512;&#33616;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34701;&#21512;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#20132;&#20114;&#24335;&#25512;&#33616;&#31995;&#32479;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#27169;&#22411;&#22312;&#25552;&#20379;&#35299;&#37322;&#21644;&#21442;&#19982;&#23545;&#35805;&#20219;&#21153;&#26041;&#38754;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2308.16505</link><description>&lt;p&gt;
&#25512;&#33616;AI&#20195;&#29702;&#65306;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#21040;&#20132;&#20114;&#24335;&#25512;&#33616;&#20013;
&lt;/p&gt;
&lt;p&gt;
Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations. (arXiv:2308.16505v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16505
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30340;&#21019;&#26032;&#28857;&#26159;&#23558;&#25512;&#33616;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34701;&#21512;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#20132;&#20114;&#24335;&#25512;&#33616;&#31995;&#32479;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#27169;&#22411;&#22312;&#25552;&#20379;&#35299;&#37322;&#21644;&#21442;&#19982;&#23545;&#35805;&#20219;&#21153;&#26041;&#38754;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#27169;&#22411;&#36890;&#36807;&#21033;&#29992;&#24191;&#27867;&#30340;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#26469;&#25552;&#20379;&#39046;&#22495;&#29305;&#23450;&#30340;&#29289;&#21697;&#25512;&#33616;&#65292;&#23637;&#29616;&#20986;&#36731;&#37327;&#32423;&#39046;&#22495;&#19987;&#23478;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#25552;&#20379;&#35299;&#37322;&#21644;&#21442;&#19982;&#23545;&#35805;&#31561;&#22810;&#26679;&#21270;&#20219;&#21153;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20195;&#34920;&#20102;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#30340;&#37325;&#35201;&#36827;&#23637;&#65292;&#22312;&#25351;&#20196;&#29702;&#35299;&#12289;&#24120;&#35782;&#25512;&#29702;&#21644;&#20154;&#31867;&#20132;&#20114;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;LLMs&#32570;&#20047;&#39046;&#22495;&#29305;&#23450;&#29289;&#21697;&#30446;&#24405;&#21644;&#34892;&#20026;&#27169;&#24335;&#30340;&#30693;&#35782;&#65292;&#29305;&#21035;&#26159;&#22312;&#19982;&#19968;&#33324;&#19990;&#30028;&#30693;&#35782;&#19981;&#21516;&#30340;&#39046;&#22495;&#65292;&#22914;&#22312;&#32447;&#30005;&#23376;&#21830;&#21153;&#12290;&#20026;&#27599;&#20010;&#39046;&#22495;&#24494;&#35843;LLMs&#26082;&#19981;&#32463;&#27982;&#21448;&#19981;&#39640;&#25928;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#25512;&#33616;&#27169;&#22411;&#21644;LLMs&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#32467;&#21512;&#21508;&#33258;&#30340;&#20248;&#21183;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#20132;&#20114;&#24335;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#26694;&#26550;&#31216;&#20026;RecAgent&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;LLMs
&lt;/p&gt;
&lt;p&gt;
Recommender models excel at providing domain-specific item recommendations by leveraging extensive user behavior data. Despite their ability to act as lightweight domain experts, they struggle to perform versatile tasks such as providing explanations and engaging in conversations. On the other hand, large language models (LLMs) represent a significant step towards artificial general intelligence, showcasing remarkable capabilities in instruction comprehension, commonsense reasoning, and human interaction. However, LLMs lack the knowledge of domain-specific item catalogs and behavioral patterns, particularly in areas that diverge from general world knowledge, such as online e-commerce. Finetuning LLMs for each domain is neither economic nor efficient.  In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create a versatile and interactive recommender system. We introduce an efficient framework called RecAgent, which employs LLMs a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#27979;&#35797;&#26102;&#38388;&#23884;&#20837;&#24402;&#19968;&#21270;&#8221;&#30340;&#31574;&#30053;&#26469;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#28909;&#38376;&#20559;&#35265;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#24402;&#19968;&#21270;&#30340;&#29289;&#21697;&#23884;&#20837;&#26469;&#25511;&#21046;&#23884;&#20837;&#22823;&#23567;&#65292;&#24182;&#36890;&#36807;&#19982;&#29992;&#25143;&#21644;&#29289;&#21697;&#23884;&#20837;&#30340;&#35282;&#24230;&#30456;&#20284;&#24230;&#21306;&#20998;&#21463;&#27426;&#36814;&#21644;&#19981;&#21463;&#27426;&#36814;&#30340;&#29289;&#21697;&#65292;&#20174;&#32780;&#26377;&#25928;&#20943;&#23569;&#20102;&#28909;&#38376;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2308.11288</link><description>&lt;p&gt;
&#27979;&#35797;&#26102;&#38388;&#23884;&#20837;&#24402;&#19968;&#21270;&#23545;&#28909;&#38376;&#20559;&#35265;&#30340;&#32531;&#35299;
&lt;/p&gt;
&lt;p&gt;
Test Time Embedding Normalization for Popularity Bias Mitigation. (arXiv:2308.11288v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#27979;&#35797;&#26102;&#38388;&#23884;&#20837;&#24402;&#19968;&#21270;&#8221;&#30340;&#31574;&#30053;&#26469;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#28909;&#38376;&#20559;&#35265;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#24402;&#19968;&#21270;&#30340;&#29289;&#21697;&#23884;&#20837;&#26469;&#25511;&#21046;&#23884;&#20837;&#22823;&#23567;&#65292;&#24182;&#36890;&#36807;&#19982;&#29992;&#25143;&#21644;&#29289;&#21697;&#23884;&#20837;&#30340;&#35282;&#24230;&#30456;&#20284;&#24230;&#21306;&#20998;&#21463;&#27426;&#36814;&#21644;&#19981;&#21463;&#27426;&#36814;&#30340;&#29289;&#21697;&#65292;&#20174;&#32780;&#26377;&#25928;&#20943;&#23569;&#20102;&#28909;&#38376;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28909;&#38376;&#20559;&#35265;&#26159;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#26222;&#36941;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#28909;&#38376;&#29289;&#21697;&#20542;&#21521;&#20110;&#20027;&#23548;&#25512;&#33616;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#27979;&#35797;&#26102;&#38388;&#23884;&#20837;&#24402;&#19968;&#21270;&#8221;&#20316;&#20026;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#31574;&#30053;&#26469;&#32531;&#35299;&#28909;&#38376;&#20559;&#35265;&#65292;&#20854;&#24615;&#33021;&#36229;&#36807;&#20102;&#20197;&#24448;&#30340;&#32531;&#35299;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25512;&#29702;&#38454;&#27573;&#21033;&#29992;&#24402;&#19968;&#21270;&#30340;&#29289;&#21697;&#23884;&#20837;&#26469;&#25511;&#21046;&#23884;&#20837;&#30340;&#22823;&#23567;&#65292;&#32780;&#23884;&#20837;&#30340;&#22823;&#23567;&#19982;&#29289;&#21697;&#30340;&#27969;&#34892;&#24230;&#39640;&#24230;&#30456;&#20851;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#37319;&#26679;softmax&#25439;&#22833;&#30456;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#26356;&#26377;&#25928;&#22320;&#20943;&#23569;&#20102;&#28909;&#38376;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#29992;&#25143;&#21644;&#29289;&#21697;&#23884;&#20837;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#23884;&#20837;&#20043;&#38388;&#30340;&#35282;&#24230;&#30456;&#20284;&#24230;&#21487;&#20197;&#21306;&#20998;&#21463;&#27426;&#36814;&#21644;&#19981;&#21463;&#27426;&#36814;&#30340;&#29289;&#21697;&#65292;&#32780;&#19981;&#32771;&#34385;&#23427;&#20204;&#30340;&#27969;&#34892;&#31243;&#24230;&#12290;&#36825;&#19968;&#20998;&#26512;&#35299;&#37322;&#20102;&#25105;&#20204;&#26041;&#27861;&#25104;&#21151;&#30340;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Popularity bias is a widespread problem in the field of recommender systems, where popular items tend to dominate recommendation results. In this work, we propose 'Test Time Embedding Normalization' as a simple yet effective strategy for mitigating popularity bias, which surpasses the performance of the previous mitigation approaches by a significant margin. Our approach utilizes the normalized item embedding during the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity. Through extensive experiments, we show that our method combined with the sampled softmax loss effectively reduces popularity bias compare to previous approaches for bias mitigation. We further investigate the relationship between user and item embeddings and find that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity. The analysis explains the mechanism behind the success of our approac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#32422;&#26463;&#38750;&#36127;&#24352;&#37327;&#22240;&#24335;&#20998;&#35299;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#26816;&#27979;&#21644;&#23450;&#20301;&#20027;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#31232;&#30095;&#32422;&#26463;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#21464;&#20307;&#65292;&#33021;&#22815;&#26377;&#25928;&#25511;&#21046;&#23398;&#20064;&#21040;&#30340;&#20027;&#39064;&#30340;&#38271;&#24230;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#21457;&#29616;&#30701;&#26399;&#21644;&#38271;&#26399;&#26102;&#24577;&#20027;&#39064;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2010.01600</link><description>&lt;p&gt;
&#22522;&#20110;&#31232;&#30095;&#32422;&#26463;&#38750;&#36127;&#24352;&#37327;&#22240;&#24335;&#20998;&#35299;&#26816;&#27979;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#20027;&#39064;
&lt;/p&gt;
&lt;p&gt;
Sparseness-constrained Nonnegative Tensor Factorization for Detecting Topics at Different Time Scales. (arXiv:2010.01600v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.01600
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#32422;&#26463;&#38750;&#36127;&#24352;&#37327;&#22240;&#24335;&#20998;&#35299;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#26816;&#27979;&#21644;&#23450;&#20301;&#20027;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#31232;&#30095;&#32422;&#26463;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#21464;&#20307;&#65292;&#33021;&#22815;&#26377;&#25928;&#25511;&#21046;&#23398;&#20064;&#21040;&#30340;&#20027;&#39064;&#30340;&#38271;&#24230;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#21457;&#29616;&#30701;&#26399;&#21644;&#38271;&#26399;&#26102;&#24577;&#20027;&#39064;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#25968;&#25454;&#65288;&#22914;&#26032;&#38395;&#25991;&#31456;&#25110;Twitter&#21160;&#24577;&#65289;&#36890;&#24120;&#21253;&#21547;&#25345;&#20037;&#36235;&#21183;&#21644;&#30701;&#26242;&#28909;&#38376;&#20027;&#39064;&#30340;&#28151;&#21512;&#12290;&#19968;&#20010;&#25104;&#21151;&#30340;&#20027;&#39064;&#24314;&#27169;&#31574;&#30053;&#24212;&#33021;&#22815;&#26816;&#27979;&#36825;&#20004;&#31181;&#31867;&#22411;&#30340;&#20027;&#39064;&#65292;&#24182;&#28165;&#26224;&#22320;&#23450;&#20301;&#23427;&#20204;&#22312;&#26102;&#38388;&#19978;&#30340;&#20301;&#32622;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#38750;&#36127;CANDECOMP/PARAFAC&#20998;&#35299;&#65288;NCPD&#65289;&#33021;&#22815;&#33258;&#21160;&#21457;&#29616;&#25345;&#32493;&#26102;&#38388;&#21464;&#21270;&#30340;&#20027;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31232;&#30095;&#32422;&#26463;&#30340;NCPD&#65288;S-NCPD&#65289;&#21450;&#20854;&#22312;&#32447;&#21464;&#20307;&#65292;&#20197;&#26377;&#25928;&#19988;&#39640;&#25928;&#22320;&#25511;&#21046;&#23398;&#20064;&#21040;&#30340;&#20027;&#39064;&#38271;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37327;&#21270;&#34913;&#37327;&#20027;&#39064;&#38271;&#24230;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#21322;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#65288;&#21253;&#25324;&#26032;&#38395;&#26631;&#39064;&#65289;&#20013;&#23637;&#31034;&#20102;S-NCPD&#65288;&#20197;&#21450;&#20854;&#22312;&#32447;&#21464;&#20307;&#65289;&#21457;&#29616;&#30701;&#26399;&#21644;&#38271;&#26399;&#26102;&#24577;&#20027;&#39064;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;S-NCPD&#30340;&#22312;&#32447;&#21464;&#20307;&#27604;S-NCPD&#26356;&#24555;&#22320;&#20943;&#23569;&#37325;&#26500;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal data (such as news articles or Twitter feeds) often consists of a mixture of long-lasting trends and popular but short-lasting topics of interest. A truly successful topic modeling strategy should be able to detect both types of topics and clearly locate them in time. In this paper, we first show that nonnegative CANDECOMP/PARAFAC decomposition (NCPD) is able to discover topics of variable persistence automatically. Then, we propose sparseness-constrained NCPD (S-NCPD) and its online variant in order to actively control the length of the learned topics effectively and efficiently. Further, we propose quantitative ways to measure the topic length and demonstrate the ability of S-NCPD (as well as its online variant) to discover short and long-lasting temporal topics in a controlled manner in semi-synthetic and real-world data including news headlines. We also demonstrate that the online variant of S-NCPD reduces the reconstruction error more rapidly than S-NCPD.
&lt;/p&gt;</description></item></channel></rss>