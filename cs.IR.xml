<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#26694;&#26550;&#65292;&#36890;&#36807;&#20248;&#21270;&#31639;&#27861;&#23454;&#29616;&#20102;&#28040;&#36153;&#32773;&#21644;&#29983;&#20135;&#32773;&#20004;&#26041;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#21487;&#27867;&#21270;&#24615;&#21644;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#26681;&#25454;&#19981;&#21516;&#30340;&#32676;&#20307;&#20998;&#21106;&#12289;&#25512;&#33616;&#27169;&#22411;&#36873;&#25321;&#21644;&#39046;&#22495;&#35774;&#32622;&#23454;&#29616;&#20844;&#24179;&#24615;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.00485</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#28040;&#36153;&#32773;&#21644;&#29983;&#20135;&#32773;&#32676;&#20307;&#20844;&#24179;&#20248;&#21270;&#30340;&#25512;&#33616;&#31995;&#32479;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Personalized Framework for Consumer and Producer Group Fairness Optimization in Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00485
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#26694;&#26550;&#65292;&#36890;&#36807;&#20248;&#21270;&#31639;&#27861;&#23454;&#29616;&#20102;&#28040;&#36153;&#32773;&#21644;&#29983;&#20135;&#32773;&#20004;&#26041;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#21487;&#27867;&#21270;&#24615;&#21644;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#26681;&#25454;&#19981;&#21516;&#30340;&#32676;&#20307;&#20998;&#21106;&#12289;&#25512;&#33616;&#27169;&#22411;&#36873;&#25321;&#21644;&#39046;&#22495;&#35774;&#32622;&#23454;&#29616;&#20844;&#24179;&#24615;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#24847;&#35782;&#21040;&#65292;&#24403;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#29992;&#20110;&#33258;&#21160;&#21270;&#20915;&#31574;&#26102;&#65292;&#21487;&#33021;&#20250;&#23545;&#20010;&#20154;&#25110;&#32676;&#20307;&#36827;&#34892;&#19981;&#20844;&#24179;&#24453;&#36935;&#65292;&#20174;&#32780;&#20135;&#29983;&#27861;&#24459;&#12289;&#20262;&#29702;&#25110;&#32463;&#27982;&#26041;&#38754;&#30340;&#24433;&#21709;&#12290;&#25512;&#33616;&#31995;&#32479;&#26159;&#36825;&#20123;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#37325;&#35201;&#20363;&#23376;&#65292;&#23427;&#20204;&#24110;&#21161;&#29992;&#25143;&#20570;&#20986;&#20915;&#31574;&#12290;&#36807;&#21435;&#22823;&#37096;&#20998;&#20851;&#20110;&#25512;&#33616;&#31995;&#32479;&#20844;&#24179;&#24615;&#30340;&#25991;&#29486;&#30740;&#31350;&#37117;&#26159;&#23558;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#29420;&#31435;&#23545;&#24453;&#65292;&#24573;&#35270;&#20102;&#25512;&#33616;&#31995;&#32479;&#22312;&#21452;&#36793;&#24066;&#22330;&#20013;&#30340;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CP-FairRank&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#37325;&#26032;&#25490;&#21517;&#31639;&#27861;&#65292;&#22312;&#32852;&#21512;&#30446;&#26631;&#26694;&#26550;&#20013;&#26080;&#32541;&#38598;&#25104;&#20102;&#28040;&#36153;&#32773;&#21644;&#29983;&#20135;&#32773;&#20004;&#26041;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#21487;&#27867;&#21270;&#24615;&#65292;&#24182;&#21487;&#20197;&#26681;&#25454;&#32676;&#20307;&#20998;&#21106;&#12289;&#25512;&#33616;&#27169;&#22411;&#36873;&#25321;&#21644;&#39046;&#22495;&#32771;&#34385;&#22810;&#26679;&#30340;&#20844;&#24179;&#24615;&#35774;&#32622;&#65292;&#36825;&#26159;&#20854;&#19968;&#20010;&#37325;&#35201;&#29305;&#28857;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#31995;&#32479;&#21487;&#20197;&#21516;&#26102;&#25552;&#39640;&#28040;&#36153;&#32773;&#21644;&#29983;&#20135;&#32773;&#30340;&#28385;&#24847;&#24230;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been an increasing recognition that when machine learning (ML) algorithms are used to automate decisions, they may mistreat individuals or groups, with legal, ethical, or economic implications. Recommender systems are prominent examples of these machine learning (ML) systems that aid users in making decisions. The majority of past literature research on RS fairness treats user and item fairness concerns independently, ignoring the fact that recommender systems function in a two-sided marketplace. In this paper, we propose CP-FairRank, an optimization-based re-ranking algorithm that seamlessly integrates fairness constraints from both the consumer and producer side in a joint objective framework. The framework is generalizable and may take into account varied fairness settings based on group segmentation, recommendation model selection, and domain, which is one of its key characteristics. For instance, we demonstrate that the system may jointly increase consum
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19987;&#21033;&#21709;&#24212;&#26234;&#33021;&#31995;&#32479;PARIS&#21644;LE-PARIS&#65292;&#36890;&#36807;&#26500;&#24314;OA&#20027;&#39064;&#25968;&#25454;&#24211;&#12289;&#24320;&#21457;&#21709;&#24212;&#27169;&#26495;&#20197;&#21450;&#23454;&#26045;&#25512;&#33616;&#31995;&#32479;&#21644;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#65292;&#26088;&#22312;&#21152;&#24555;&#19987;&#21033;&#24459;&#24072;&#22788;&#29702;&#23457;&#26597;&#24847;&#35265;&#22238;&#24212;&#30340;&#25928;&#29575;&#12290; &#36890;&#36807;&#22810;&#33539;&#24335;&#20998;&#26512;&#21644;&#38271;&#26399;&#25968;&#25454;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;OA&#20027;&#39064;&#30340;&#24314;&#35774;&#24615;&#21644;LLM&#23545;&#20110;&#22238;&#24212;&#33258;&#21160;&#29983;&#25104;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.00421</link><description>&lt;p&gt;
&#20174;PARIS&#21040;LE-PARIS&#65306;&#36890;&#36807;&#25512;&#33616;&#31995;&#32479;&#21644;&#21327;&#20316;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#19987;&#21033;&#21709;&#24212;&#33258;&#21160;&#21270;
&lt;/p&gt;
&lt;p&gt;
From PARIS to LE-PARIS: Toward Patent Response Automation with Recommender Systems and Collaborative Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19987;&#21033;&#21709;&#24212;&#26234;&#33021;&#31995;&#32479;PARIS&#21644;LE-PARIS&#65292;&#36890;&#36807;&#26500;&#24314;OA&#20027;&#39064;&#25968;&#25454;&#24211;&#12289;&#24320;&#21457;&#21709;&#24212;&#27169;&#26495;&#20197;&#21450;&#23454;&#26045;&#25512;&#33616;&#31995;&#32479;&#21644;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#65292;&#26088;&#22312;&#21152;&#24555;&#19987;&#21033;&#24459;&#24072;&#22788;&#29702;&#23457;&#26597;&#24847;&#35265;&#22238;&#24212;&#30340;&#25928;&#29575;&#12290; &#36890;&#36807;&#22810;&#33539;&#24335;&#20998;&#26512;&#21644;&#38271;&#26399;&#25968;&#25454;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;OA&#20027;&#39064;&#30340;&#24314;&#35774;&#24615;&#21644;LLM&#23545;&#20110;&#22238;&#24212;&#33258;&#21160;&#29983;&#25104;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19987;&#21033;&#23457;&#26597;&#20013;&#65292;&#23545;&#20110;&#21450;&#26102;&#21644;&#26377;&#25928;&#22320;&#22238;&#24212;&#23457;&#26597;&#24847;&#35265;&#65288;OAs&#65289;&#23545;&#20110;&#33719;&#24471;&#19987;&#21033;&#33267;&#20851;&#37325;&#35201;&#65292;&#28982;&#32780;&#36807;&#21435;&#30340;&#33258;&#21160;&#21270;&#21644;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#24456;&#23569;&#28041;&#21450;&#21040;&#36825;&#19968;&#26041;&#38754;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20171;&#32461;&#20102;&#19987;&#21033;&#23457;&#26597;&#24847;&#35265;&#21709;&#24212;&#26234;&#33021;&#31995;&#32479;&#65288;PARIS&#65289;&#21450;&#20854;&#20808;&#36827;&#29256;&#26412;LE-PARIS&#12290;&#36825;&#20123;&#31995;&#32479;&#26088;&#22312;&#21152;&#24555;&#19987;&#21033;&#24459;&#24072;&#22312;&#21327;&#20316;&#22788;&#29702;OA&#22238;&#24212;&#26041;&#38754;&#30340;&#25928;&#29575;&#12290;&#31995;&#32479;&#30340;&#20851;&#38190;&#29305;&#24449;&#21253;&#25324;&#26500;&#24314;OA&#20027;&#39064;&#25968;&#25454;&#24211;&#65292;&#24320;&#21457;&#21709;&#24212;&#27169;&#26495;&#65292;&#20197;&#21450;&#23454;&#26045;&#25512;&#33616;&#31995;&#32479;&#21644;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#12290;&#25105;&#20204;&#30340;&#39564;&#35777;&#28041;&#21450;&#20351;&#29992;USPTO Office Action&#25968;&#25454;&#24211;&#21644;&#24459;&#24072;&#19982;&#25105;&#20204;&#31995;&#32479;&#30340;&#38271;&#26399;&#20132;&#20114;&#25968;&#25454;&#36827;&#34892;&#30340;&#22810;&#33539;&#24335;&#20998;&#26512;&#65292;&#20026;&#26399;&#20845;&#24180;&#12290;&#36890;&#36807;&#20116;&#20010;&#30740;&#31350;&#65292;&#25105;&#20204;&#21033;&#29992;&#20027;&#39064;&#24314;&#27169;&#21644;&#25552;&#20986;&#30340;Delphi&#36807;&#31243;&#26469;&#26816;&#39564;OA&#20027;&#39064;&#30340;&#24314;&#35774;&#24615;&#65288;&#30740;&#31350;1&#21644;2&#65289;&#65292;&#36824;&#26377;&#20351;&#29992;&#25512;&#33616;&#31995;&#32479;&#21644;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#26469;&#25552;&#39640;&#22238;&#24212;&#36136;&#37327;&#65288;&#30740;&#31350;3&#21644;4&#65289;&#65292;&#20197;&#21450;&#32463;&#36807;&#35757;&#32451;&#30340;LLM&#23545;&#20110;&#22238;&#24212;&#33258;&#21160;&#29983;&#25104;&#30340;&#21487;&#34892;&#24615;&#65288;&#30740;&#31350;5&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In patent prosecution, timely and effective responses to Office Actions (OAs) are crucial for acquiring patents, yet past automation and AI research have scarcely addressed this aspect. To address this gap, our study introduces the Patent Office Action Response Intelligence System (PARIS) and its advanced version, the Large Language Model Enhanced PARIS (LE-PARIS). These systems are designed to expedite the efficiency of patent attorneys in collaboratively handling OA responses. The systems' key features include the construction of an OA Topics Database, development of Response Templates, and implementation of Recommender Systems and LLM-based Response Generation. Our validation involves a multi-paradigmatic analysis using the USPTO Office Action database and longitudinal data of attorney interactions with our systems over six years. Through five studies, we examine the constructiveness of OA topics (studies 1 and 2) using topic modeling and the proposed Delphi process, the efficacy of
&lt;/p&gt;</description></item><item><title>EASRec&#26159;&#19968;&#20010;&#38024;&#23545;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#24377;&#24615;&#26550;&#26500;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#21098;&#26525;&#25216;&#26415;&#21644;&#20808;&#36827;&#27169;&#22411;&#26550;&#26500;&#32467;&#21512;&#65292;&#20197;&#21450;&#36164;&#28304;&#21463;&#38480;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#21644;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#20445;&#25345;&#25110;&#22686;&#24378;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.00390</link><description>&lt;p&gt;
EASRec&#65306;&#29992;&#20110;&#39640;&#25928;&#38271;&#26399;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#24377;&#24615;&#26550;&#26500;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
EASRec: Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00390
&lt;/p&gt;
&lt;p&gt;
EASRec&#26159;&#19968;&#20010;&#38024;&#23545;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#24377;&#24615;&#26550;&#26500;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#21098;&#26525;&#25216;&#26415;&#21644;&#20808;&#36827;&#27169;&#22411;&#26550;&#26500;&#32467;&#21512;&#65292;&#20197;&#21450;&#36164;&#28304;&#21463;&#38480;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#21644;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#20445;&#25345;&#25110;&#22686;&#24378;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#20016;&#23500;&#30340;&#26102;&#20195;&#65292;&#20174;&#28023;&#37327;&#20449;&#24687;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#35265;&#35299;&#30340;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#35299;&#20915;&#20102;&#24403;&#21069;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65288;SRSs&#65289;&#22312;&#35745;&#31639;&#21644;&#36164;&#28304;&#25928;&#29575;&#26041;&#38754;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#37319;&#29992;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#27169;&#22411;&#65288;&#22914;SASRec&#65289;&#30340;&#31995;&#32479;&#12290;&#36825;&#20123;&#31995;&#32479;&#26088;&#22312;&#20026;&#21508;&#31181;&#24212;&#29992;&#25552;&#20379;&#19979;&#19968;&#20010;&#39033;&#30446;&#30340;&#25512;&#33616;&#65292;&#20174;&#30005;&#23376;&#21830;&#21153;&#21040;&#31038;&#20132;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#22312;&#25512;&#29702;&#38454;&#27573;&#20250;&#20135;&#29983;&#30456;&#24403;&#22823;&#30340;&#35745;&#31639;&#25104;&#26412;&#21644;&#36164;&#28304;&#28040;&#32791;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#33258;&#21160;&#21098;&#26525;&#25216;&#26415;&#21644;&#20808;&#36827;&#27169;&#22411;&#26550;&#26500;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#20013;&#27969;&#34892;&#30340;&#36164;&#28304;&#21463;&#38480;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#25216;&#26415;&#30340;&#28508;&#21147;&#65292;&#20197;&#35843;&#25972;&#27169;&#22411;&#20197;&#20943;&#23569;FLOPs&#12289;&#24310;&#36831;&#21644;&#33021;&#37327;&#20351;&#29992;&#65292;&#21516;&#26102;&#20445;&#25345;&#25110;&#22686;&#24378;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24320;&#21457;&#20102;&#19968;&#31181;
&lt;/p&gt;
&lt;p&gt;
In this age where data is abundant, the ability to distill meaningful insights from the sea of information is essential. Our research addresses the computational and resource inefficiencies that current Sequential Recommender Systems (SRSs) suffer from. especially those employing attention-based models like SASRec, These systems are designed for next-item recommendations in various applications, from e-commerce to social networks. However, such systems suffer from substantial computational costs and resource consumption during the inference stage. To tackle these issues, our research proposes a novel method that combines automatic pruning techniques with advanced model architectures. We also explore the potential of resource-constrained Neural Architecture Search (NAS), a technique prevalent in the realm of recommendation systems, to fine-tune models for reduced FLOPs, latency, and energy usage while retaining or even enhancing accuracy. The main contribution of our work is developing 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36229;&#36234;&#20256;&#32479;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#22522;&#20110;&#32771;&#35797;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#30456;&#20851;&#24615;&#21028;&#26029;&#65292;&#32780;&#26159;&#26681;&#25454;&#25991;&#26412;&#26159;&#21542;&#21253;&#21547;&#33021;&#22238;&#31572;&#20851;&#38190;&#38382;&#39064;&#30340;&#20449;&#24687;&#26469;&#21028;&#26029;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#35774;&#35745;EXAM&#21487;&#22238;&#31572;&#24230;&#25351;&#26631;&#21644;&#20004;&#31181;&#35780;&#20272;&#25514;&#26045;&#65292;&#21487;&#20197;&#35780;&#20272;&#20449;&#24687;&#26816;&#32034;/&#29983;&#25104;&#31995;&#32479;&#30340;&#20027;&#39064;&#30456;&#20851;&#20449;&#24687;&#25552;&#20379;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.00309</link><description>&lt;p&gt;
&#36229;&#36234;&#20256;&#32479;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#22522;&#20110;&#32771;&#35797;&#30340;&#35780;&#20272;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Exam-based Evaluation Approach Beyond Traditional Relevance Judgments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00309
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36229;&#36234;&#20256;&#32479;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#22522;&#20110;&#32771;&#35797;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#30456;&#20851;&#24615;&#21028;&#26029;&#65292;&#32780;&#26159;&#26681;&#25454;&#25991;&#26412;&#26159;&#21542;&#21253;&#21547;&#33021;&#22238;&#31572;&#20851;&#38190;&#38382;&#39064;&#30340;&#20449;&#24687;&#26469;&#21028;&#26029;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#35774;&#35745;EXAM&#21487;&#22238;&#31572;&#24230;&#25351;&#26631;&#21644;&#20004;&#31181;&#35780;&#20272;&#25514;&#26045;&#65292;&#21487;&#20197;&#35780;&#20272;&#20449;&#24687;&#26816;&#32034;/&#29983;&#25104;&#31995;&#32479;&#30340;&#20027;&#39064;&#30456;&#20851;&#20449;&#24687;&#25552;&#20379;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#20449;&#24687;&#26816;&#32034;&#35780;&#20272;&#22522;&#20110;&#30456;&#20851;&#24615;&#21028;&#26029;&#65292;&#36825;&#20123;&#21028;&#26029;&#21487;&#20197;&#25163;&#21160;&#25110;&#33258;&#21160;&#21019;&#24314;&#65292;&#24182;&#19988;&#20915;&#31574;&#36890;&#24120;&#34987;&#22806;&#21253;&#32473;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#33539;&#24335;&#65292;&#20174;&#19981;&#20381;&#36182;&#20219;&#20309;&#24418;&#24335;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#12290;&#30456;&#21453;&#65292;&#22914;&#26524;&#19968;&#27573;&#25991;&#26412;&#21253;&#21547;&#21487;&#20197;&#22238;&#31572;&#20851;&#38190;&#38382;&#39064;&#30340;&#20449;&#24687;&#65292;&#25105;&#20204;&#23558;&#20854;&#23450;&#20041;&#20026;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#24605;&#24819;&#35774;&#35745;&#20102;EXAM&#21487;&#22238;&#31572;&#24230;&#25351;&#26631;&#65292;&#20197;&#35780;&#20272;&#20449;&#24687;&#26816;&#32034;/&#29983;&#25104;&#31995;&#32479;&#25552;&#20379;&#20027;&#39064;&#30456;&#20851;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#35774;&#24819;&#19968;&#20010;&#20154;&#31867;&#35780;&#22996;&#30340;&#35282;&#33394;&#26159;&#32534;&#36753;&#21644;&#23450;&#20041;&#19968;&#20010;&#32771;&#35797;&#39064;&#24211;&#65292;&#29992;&#20110;&#27979;&#35797;&#25991;&#26412;&#20013;&#30456;&#20851;&#20449;&#24687;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#36890;&#36807;&#29983;&#25104;&#19968;&#20010;&#21021;&#22987;&#30340;&#32771;&#35797;&#39064;&#30446;&#38598;&#26469;&#25903;&#25345;&#36825;&#19968;&#27493;&#39588;&#12290;&#22312;&#19979;&#19968;&#20010;&#38454;&#27573;&#65292;&#22522;&#20110;LLM&#30340;&#38382;&#31572;&#31995;&#32479;&#23558;&#36890;&#36807;&#36319;&#36394;&#21487;&#20197;&#22238;&#31572;&#21738;&#20010;&#32771;&#35797;&#39064;&#30446;&#26469;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#35780;&#20272;&#25351;&#26631;&#65306;&#22238;&#24518;&#23548;&#21521;&#30340;EXAM&#35206;&#30422;&#24230;&#25351;&#26631;&#21644;
&lt;/p&gt;
&lt;p&gt;
Current IR evaluation is based on relevance judgments, created either manually or automatically, with decisions outsourced to Large Language Models (LLMs). We offer an alternative paradigm, that never relies on relevance judgments in any form. Instead, a text is defined as relevant if it contains information that enables the answering of key questions. We use this idea to design the EXAM Answerability Metric to evaluate information retrieval/generation systems for their ability to provide topically relevant information.   We envision the role of a human judge to edit and define an exam question bank that will test for the presence of relevant information in text. We support this step by generating an initial set of exam questions. In the next phase, an LLM-based question answering system will automatically grade system responses by tracking which exam questions are answerable with which system responses. We propose two evaluation measures, the recall-oriented EXAM Cover metric, and the
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PAP-REC&#26694;&#26550;&#65292;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#33258;&#21160;&#25552;&#31034;&#30340;&#25512;&#33616;&#35821;&#35328;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#20010;&#24615;&#21270;&#25552;&#31034;&#26631;&#35760;&#26469;&#20943;&#36731;&#25163;&#21160;&#35774;&#35745;&#25552;&#31034;&#25152;&#24102;&#26469;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.00284</link><description>&lt;p&gt;
PAP-REC: &#20010;&#24615;&#21270;&#33258;&#21160;&#25552;&#31034;&#30340;&#25512;&#33616;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
PAP-REC: Personalized Automatic Prompt for Recommendation Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PAP-REC&#26694;&#26550;&#65292;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#33258;&#21160;&#25552;&#31034;&#30340;&#25512;&#33616;&#35821;&#35328;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#20010;&#24615;&#21270;&#25552;&#31034;&#26631;&#35760;&#26469;&#20943;&#36731;&#25163;&#21160;&#35774;&#35745;&#25552;&#31034;&#25152;&#24102;&#26469;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20986;&#29616;&#30340;&#22522;&#20110;&#25552;&#31034;&#30340;&#25512;&#33616;&#35821;&#35328;&#27169;&#22411;&#65288;RLM&#65289;&#21487;&#20197;&#32479;&#19968;&#35299;&#20915;&#22810;&#20010;&#25512;&#33616;&#20219;&#21153;&#12290;&#36825;&#20123;RLM&#20805;&#20998;&#21033;&#29992;&#20102;&#20174;&#20016;&#23500;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#21040;&#30340;&#36951;&#20256;&#30693;&#35782;&#65292;&#36890;&#36807;&#25552;&#31034;&#26469;&#35299;&#20915;&#19979;&#28216;&#25512;&#33616;&#20219;&#21153;&#65292;&#32780;&#19981;&#38656;&#35201;&#24341;&#20837;&#39069;&#22806;&#30340;&#21442;&#25968;&#25110;&#32593;&#32476;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#25163;&#24037;&#35774;&#35745;&#30340;&#25552;&#31034;&#38656;&#35201;&#26174;&#33879;&#30340;&#19987;&#19994;&#30693;&#35782;&#21644;&#20154;&#21147;&#25237;&#20837;&#65292;&#31245;&#24494;&#25913;&#20889;&#25552;&#31034;&#23601;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#30340;&#24040;&#22823;&#21464;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PAP-REC&#65292;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#33258;&#21160;&#25552;&#31034;&#30340;&#25512;&#33616;&#35821;&#35328;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#20197;&#32531;&#35299;&#25163;&#21160;&#35774;&#35745;&#25552;&#31034;&#23548;&#33268;&#30340;&#20302;&#25928;&#29575;&#21644;&#20302;&#25928;&#26524;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20010;&#24615;&#21270;&#33258;&#21160;&#25552;&#31034;&#20801;&#35768;&#19981;&#21516;&#30340;&#29992;&#25143;&#22312;&#30456;&#21516;&#20219;&#21153;&#20013;&#20855;&#26377;&#19981;&#21516;&#30340;&#25552;&#31034;&#26631;&#35760;&#65292;&#36825;&#20123;&#26631;&#35760;&#26159;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#33258;&#21160;&#29983;&#25104;&#30340;&#12290;&#20010;&#24615;&#21270;&#33258;&#21160;&#25552;&#31034;&#29983;&#25104;&#25512;&#33616;&#35821;&#35328;&#27169;&#22411;&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#24222;&#22823;&#30340;&#25628;&#32034;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently emerged prompt-based Recommendation Language Models (RLM) can solve multiple recommendation tasks uniformly. The RLMs make full use of the inherited knowledge learned from the abundant pre-training data to solve the downstream recommendation tasks by prompts, without introducing additional parameters or network training. However, handcrafted prompts require significant expertise and human effort since slightly rewriting prompts may cause massive performance changes. In this paper, we propose PAP-REC, a framework to generate the Personalized Automatic Prompt for RECommendation language models to mitigate the inefficiency and ineffectiveness problems derived from manually designed prompts. Specifically, personalized automatic prompts allow different users to have different prompt tokens for the same task, automatically generated using a gradient-based method. One challenge for personalized automatic prompt generation for recommendation language models is the extremely large sear
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;Pareto&#30340;&#24102;&#26377;&#36951;&#24536;&#26354;&#32447;&#30340;&#22810;&#30446;&#26631;&#25512;&#33616;&#31995;&#32479;&#65288;PMORS&#65289;&#36890;&#36807;&#24341;&#20837;&#36951;&#24536;&#27169;&#22411;&#21644;Pareto&#20248;&#21270;&#27714;&#35299;&#22120;&#65292;&#33021;&#22815;&#22788;&#29702;&#26126;&#30830;&#30340;&#36127;&#38754;&#21453;&#39304;&#24182;&#22312;&#22810;&#30446;&#26631;&#25512;&#33616;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2312.16868</link><description>&lt;p&gt;
&#22522;&#20110;Pareto&#30340;&#24102;&#26377;&#36951;&#24536;&#26354;&#32447;&#30340;&#22810;&#30446;&#26631;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Pareto-based Multi-Objective Recommender System with Forgetting Curve
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16868
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Pareto&#30340;&#24102;&#26377;&#36951;&#24536;&#26354;&#32447;&#30340;&#22810;&#30446;&#26631;&#25512;&#33616;&#31995;&#32479;&#65288;PMORS&#65289;&#36890;&#36807;&#24341;&#20837;&#36951;&#24536;&#27169;&#22411;&#21644;Pareto&#20248;&#21270;&#27714;&#35299;&#22120;&#65292;&#33021;&#22815;&#22788;&#29702;&#26126;&#30830;&#30340;&#36127;&#38754;&#21453;&#39304;&#24182;&#22312;&#22810;&#30446;&#26631;&#25512;&#33616;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#32423;&#32852;&#26550;&#26500;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#22312;&#32447;&#25512;&#33616;&#24179;&#21488;&#20013;&#21457;&#25381;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#22312;&#22788;&#29702;&#36127;&#38754;&#21453;&#39304;&#30340;&#26041;&#27861;&#19978;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#20363;&#22914;&#65292;&#22312;&#30701;&#35270;&#39057;&#24179;&#21488;&#19978;&#65292;&#29992;&#25143;&#24448;&#24448;&#20250;&#24555;&#36895;&#22320;&#28369;&#21160;&#21024;&#38500;&#20182;&#20204;&#19981;&#21916;&#27426;&#30340;&#35270;&#39057;&#65292;&#25512;&#33616;&#31995;&#32479;&#38656;&#35201;&#25509;&#25910;&#36825;&#20123;&#26126;&#30830;&#30340;&#36127;&#38754;&#21453;&#39304;&#24182;&#36827;&#34892;&#35843;&#25972;&#20197;&#36991;&#20813;&#36825;&#20123;&#25512;&#33616;&#12290;&#32771;&#34385;&#21040;&#35760;&#24518;&#20013;&#30340;&#36817;&#26399;&#25928;&#24212;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33406;&#23486;&#28009;&#26031;&#36951;&#24536;&#26354;&#32447;&#30340;&#36951;&#24536;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#36127;&#38754;&#21453;&#39304;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;Pareto&#20248;&#21270;&#27714;&#35299;&#22120;&#65292;&#20197;&#22312;&#36817;&#26399;&#24615;&#21644;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#21462;&#24471;&#26356;&#22909;&#30340;&#24179;&#34913;&#12290;&#24635;&#32467;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;Pareto&#30340;&#24102;&#26377;&#36951;&#24536;&#26354;&#32447;&#30340;&#22810;&#30446;&#26631;&#25512;&#33616;&#31995;&#32479;&#65288;PMORS&#65289;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#22810;&#30446;&#26631;&#25512;&#33616;&#65292;&#24182;&#22312;&#38754;&#23545;&#26126;&#30830;&#30340;&#36127;&#38754;&#21453;&#39304;&#26102;&#34920;&#29616;&#20986;&#36275;&#22815;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#23545;PMORS&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#21462;&#24471;&#20102;&#26377;&#21033;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems with cascading architecture play an increasingly significant role in online recommendation platforms, where the approach to dealing with negative feedback is a vital issue. For instance, in short video platforms, users tend to quickly slip away from candidates that they feel aversive, and recommender systems are expected to receive these explicit negative feedbacks and make adjustments to avoid these recommendations. Considering recency effect in memories, we propose a forgetting model based on Ebbinghaus Forgetting Curve to cope with negative feedback. In addition, we introduce a Pareto optimization solver to guarantee a better trade-off between recency and model performance. In conclusion, we propose Pareto-based Multi-Objective Recommender System with forgetting curve (PMORS), which can be applied to any multi-objective recommendation and show sufficiently superiority when facing explicit negative feedback. We have conducted evaluations of PMORS and achieved favo
&lt;/p&gt;</description></item><item><title>InstructRetro&#26159;&#30446;&#21069;&#35268;&#27169;&#26368;&#22823;&#30340;&#20351;&#29992;&#26816;&#32034;&#39044;&#35757;&#32451;&#30340;LLM&#65292;&#25193;&#23637;&#20102;&#22522;&#30784;&#27169;&#22411;Retro 48B&#65292;&#36890;&#36807;&#25351;&#20196;&#35843;&#20248;&#22312;&#21508;&#31181;&#38646;&#26679;&#20363;&#20219;&#21153;&#19978;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2310.07713</link><description>&lt;p&gt;
InstructRetro: &#26816;&#32034;&#22686;&#24378;&#30340;&#39044;&#35757;&#32451;&#20013;&#25351;&#20196;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.07713
&lt;/p&gt;
&lt;p&gt;
InstructRetro&#26159;&#30446;&#21069;&#35268;&#27169;&#26368;&#22823;&#30340;&#20351;&#29992;&#26816;&#32034;&#39044;&#35757;&#32451;&#30340;LLM&#65292;&#25193;&#23637;&#20102;&#22522;&#30784;&#27169;&#22411;Retro 48B&#65292;&#36890;&#36807;&#25351;&#20196;&#35843;&#20248;&#22312;&#21508;&#31181;&#38646;&#26679;&#20363;&#20219;&#21153;&#19978;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26816;&#32034;&#22686;&#24378;&#25216;&#26415;&#23545;&#33258;&#22238;&#24402;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#39044;&#35757;&#32451;&#21487;&#20197;&#25552;&#39640;&#22256;&#24785;&#24230;&#21644;&#20107;&#23454;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#26816;&#32034;&#22686;&#24378;LLM&#30340;&#35268;&#27169;&#20173;&#28982;&#26377;&#38480;&#65288;&#22914;Retro&#20855;&#26377;75&#20159;&#20010;&#21442;&#25968;&#65289;&#65292;&#36825;&#38480;&#21046;&#20102;&#25351;&#20196;&#35843;&#20248;&#21644;&#38646;&#26679;&#20363;&#27867;&#21270;&#30340;&#25928;&#26524;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Retro 48B&#65292;&#36825;&#26159;&#30446;&#21069;&#35268;&#27169;&#26368;&#22823;&#30340;&#20351;&#29992;&#26816;&#32034;&#39044;&#35757;&#32451;&#30340;LLM&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20351;&#29992;&#26816;&#32034;&#25216;&#26415;&#20174;1.2&#19975;&#20159;&#20010;&#26631;&#35760;&#20013;&#32487;&#32493;&#39044;&#35757;&#32451;&#19968;&#20010;43B&#30340;GPT&#27169;&#22411;&#65292;&#24182;&#20511;&#21161;Retro&#26041;&#27861;&#23558;&#20854;&#25193;&#23637;&#21040;4800&#20159;&#20010;&#21442;&#25968;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#24471;&#21040;&#30340;&#22522;&#30784;&#27169;&#22411;Retro 48B&#22312;&#22256;&#24785;&#24230;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#20165;&#20351;&#29992;1.2&#19975;&#20159;&#20010;&#26631;&#35760;&#36827;&#34892;&#35757;&#32451;&#30340;43B GPT&#27169;&#22411;&#65292;&#19988;&#21482;&#22686;&#21152;&#20102;2.58%&#30340;GPU&#20351;&#29992;&#26102;&#38388;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26174;&#33879;&#25193;&#23637;&#28508;&#21147;&#12290;&#22312;&#23545;Retro&#36827;&#34892;&#25351;&#20196;&#35843;&#20248;&#21518;&#65292;InstructRetro&#22312;&#21508;&#31181;&#38646;&#26679;&#20363;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretraining auto-regressive large language models (LLMs) with retrieval demonstrates better perplexity and factual accuracy by leveraging external databases. However, the size of existing pretrained retrieval-augmented LLM is still limited (e.g., Retro has 7.5B parameters), which limits the effectiveness of instruction tuning and zero-shot generalization. In this work, we introduce Retro 48B, the largest LLM pretrained with retrieval. Specifically, we continue to pretrain a 43B GPT model on additional 100 billion tokens using the Retro augmentation method by retrieving from 1.2 trillion tokens. Notably, the obtained foundation model, Retro 48B, largely outperforms the counterpart GPT 43B trained on 1.2T tokens in terms of perplexity with only 2.58% additional GPU hours, demonstrating the significant scaling potential of the method. After instruction tuning on Retro, InstructRetro demonstrates significant improvement over the instruction tuned GPT on a wide range of zero-shot tasks. Spe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#38646;&#26679;&#26412;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31995;&#32479;&#24615;&#32508;&#36848;&#33258;&#21160;&#31579;&#36873;&#30340;&#26377;&#25928;&#24615;&#65292;&#32467;&#26524;&#26174;&#31034;&#25351;&#23548;&#24494;&#35843;&#21644;&#26657;&#20934;&#25216;&#26415;&#22312;&#31579;&#36873;&#20013;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#19988;&#19982;&#38646;&#26679;&#26412;&#27169;&#22411;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#33410;&#30465;&#31579;&#36873;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2401.06320</link><description>&lt;p&gt;
&#38646;&#26679;&#26412;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#31995;&#32479;&#24615;&#32508;&#36848;&#31579;&#36873;&#33258;&#21160;&#21270;
&lt;/p&gt;
&lt;p&gt;
Zero-shot Generative Large Language Models for Systematic Review Screening Automation. (arXiv:2401.06320v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#38646;&#26679;&#26412;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31995;&#32479;&#24615;&#32508;&#36848;&#33258;&#21160;&#31579;&#36873;&#30340;&#26377;&#25928;&#24615;&#65292;&#32467;&#26524;&#26174;&#31034;&#25351;&#23548;&#24494;&#35843;&#21644;&#26657;&#20934;&#25216;&#26415;&#22312;&#31579;&#36873;&#20013;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#19988;&#19982;&#38646;&#26679;&#26412;&#27169;&#22411;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#33410;&#30465;&#31579;&#36873;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#24615;&#32508;&#36848;&#23545;&#20110;&#22522;&#20110;&#35777;&#25454;&#30340;&#21307;&#23398;&#38750;&#24120;&#37325;&#35201;&#65292;&#23427;&#20204;&#32508;&#21512;&#20998;&#26512;&#20102;&#29305;&#23450;&#38382;&#39064;&#30340;&#24050;&#21457;&#34920;&#30740;&#31350;&#32467;&#26524;&#12290;&#36827;&#34892;&#27492;&#31867;&#32508;&#36848;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#36164;&#28304;&#21644;&#26102;&#38388;&#65292;&#29305;&#21035;&#26159;&#22312;&#31579;&#36873;&#38454;&#27573;&#65292;&#38656;&#35201;&#35780;&#20272;&#20986;&#29256;&#29289;&#25688;&#35201;&#26159;&#21542;&#24212;&#21253;&#25324;&#22312;&#32508;&#36848;&#20013;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#38646;&#26679;&#26412;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#33258;&#21160;&#31579;&#36873;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20843;&#31181;&#19981;&#21516;&#30340;LLM&#30340;&#25928;&#26524;&#65292;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#39044;&#23450;&#20041;&#30340;&#21484;&#22238;&#38408;&#20540;&#30340;&#26657;&#20934;&#25216;&#26415;&#65292;&#29992;&#20110;&#30830;&#23450;&#26159;&#21542;&#24212;&#23558;&#20986;&#29256;&#29289;&#21253;&#25324;&#22312;&#31995;&#32479;&#24615;&#32508;&#36848;&#20013;&#12290;&#25105;&#20204;&#30340;&#20840;&#38754;&#35780;&#20272;&#20351;&#29992;&#20102;&#20116;&#20010;&#26631;&#20934;&#27979;&#35797;&#38598;&#65292;&#32467;&#26524;&#26174;&#31034;&#25351;&#23548;&#24494;&#35843;&#22312;&#31579;&#36873;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#65292;&#26657;&#20934;&#20351;LLMs&#22312;&#23454;&#29616;&#30446;&#26631;&#21484;&#22238;&#26041;&#38754;&#26356;&#23454;&#29992;&#65292;&#24182;&#19988;&#23558;&#36825;&#20004;&#32773;&#19982;&#38646;&#26679;&#26412;&#27169;&#22411;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#19982;&#29616;&#26377;&#25216;&#26415;&#30456;&#27604;&#33410;&#30465;&#20102;&#22823;&#37327;&#31579;&#36873;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Systematic reviews are crucial for evidence-based medicine as they comprehensively analyse published research findings on specific questions. Conducting such reviews is often resource- and time-intensive, especially in the screening phase, where abstracts of publications are assessed for inclusion in a review. This study investigates the effectiveness of using zero-shot large language models~(LLMs) for automatic screening. We evaluate the effectiveness of eight different LLMs and investigate a calibration technique that uses a predefined recall threshold to determine whether a publication should be included in a systematic review. Our comprehensive evaluation using five standard test collections shows that instruction fine-tuning plays an important role in screening, that calibration renders LLMs practical for achieving a targeted recall, and that combining both with an ensemble of zero-shot models saves significant screening time compared to state-of-the-art approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;Stack Overflow&#22238;&#31572;&#20013;&#30340;&#20449;&#24687;&#39640;&#20142;&#12290;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#24320;&#21457;&#20102;&#33258;&#21160;&#25512;&#33616;&#31361;&#20986;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.01472</link><description>&lt;p&gt;
Stack Overflow&#22238;&#31572;&#20013;&#20449;&#24687;&#39640;&#20142;&#30340;&#21021;&#25506;
&lt;/p&gt;
&lt;p&gt;
A First Look at Information Highlighting in Stack Overflow Answers. (arXiv:2401.01472v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;Stack Overflow&#22238;&#31572;&#20013;&#30340;&#20449;&#24687;&#39640;&#20142;&#12290;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#24320;&#21457;&#20102;&#33258;&#21160;&#25512;&#33616;&#31361;&#20986;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#27983;&#35272;Stack Overflow&#65288;SO&#65289;&#30340;&#30693;&#35782;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#20351;&#24086;&#23376;&#23545;&#29992;&#25143;&#26356;&#29983;&#21160;&#65292;SO&#20801;&#35768;&#29992;&#25143;&#20351;&#29992;Markdown&#25110;HTML&#32534;&#20889;&#21644;&#32534;&#36753;&#24086;&#23376;&#65292;&#20197;&#20415;&#29992;&#25143;&#21487;&#20197;&#21033;&#29992;&#21508;&#31181;&#26684;&#24335;&#21270;&#26679;&#24335;&#65288;&#20363;&#22914;&#31895;&#20307;&#12289;&#26012;&#20307;&#21644;&#20195;&#30721;&#65289;&#26469;&#31361;&#20986;&#37325;&#35201;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#31361;&#20986;&#20449;&#24687;&#30340;&#30740;&#31350;&#20173;&#28982;&#26377;&#38480;&#12290;&#30446;&#26631;&#65306;&#25105;&#20204;&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;SO&#22238;&#31572;&#20013;&#30340;&#20449;&#24687;&#39640;&#20142;&#12290;&#20026;&#20102;&#25193;&#23637;&#25105;&#20204;&#20043;&#21069;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#21033;&#29992;&#26368;&#21021;&#35774;&#35745;&#29992;&#20110;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#24320;&#21457;&#20102;&#33258;&#21160;&#25512;&#33616;&#24102;&#26377;&#26684;&#24335;&#21270;&#26679;&#24335;&#30340;&#31361;&#20986;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;&#26041;&#27861;&#65306;&#26412;&#25991;&#30740;&#31350;&#20102;Stack Overflow&#30340;31,169,429&#20010;&#22238;&#31572;&#12290;&#20026;&#20102;&#35757;&#32451;&#25512;&#33616;&#27169;&#22411;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;CNN&#21644;BERT&#27169;&#22411;&#65292;&#38024;&#23545;&#27599;&#31181;&#26684;&#24335;&#21270;&#31867;&#22411;&#65288;&#21363;&#31895;&#20307;&#12289;&#26012;&#20307;&#12289;&#20195;&#30721;&#21644;&#26631;&#39064;&#65289;&#20351;&#29992;&#25105;&#20204;&#20174;SO&#22238;&#31572;&#25910;&#38598;&#30340;&#31361;&#20986;&#20449;&#24687;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Context: Navigating the knowledge of Stack Overflow (SO) remains challenging. To make the posts vivid to users, SO allows users to write and edit posts with Markdown or HTML so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. Nonetheless, there have been limited studies on the highlighted information. Objective: We carried out the first large-scale exploratory study on the information highlighted in SO answers in our recent study. To extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using neural network architectures initially designed for the Named Entity Recognition task. Method: In this paper, we studied 31,169,429 answers of Stack Overflow. For training recommendation models, we choose CNN and BERT models for each type of formatting (i.e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#65292;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#31574;&#30053;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#26032;&#21453;&#24212;&#25351;&#32441;&#65292;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#27492;&#31995;&#32479;&#21487;&#20197;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.10776</link><description>&lt;p&gt;
&#22312;&#21270;&#23398;&#21512;&#25104;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#20013;&#65292;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Generative Agent for Reaction Condition Recommendation in Chemical Synthesis. (arXiv:2311.10776v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.10776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#65292;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#31574;&#30053;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#26032;&#21453;&#24212;&#25351;&#32441;&#65292;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#27492;&#31995;&#32479;&#21487;&#20197;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20026;&#21270;&#23398;&#31038;&#20250;&#20013;&#30340;&#33258;&#21160;&#21270;&#21270;&#23398;&#21453;&#24212;&#38138;&#24179;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#26410;&#26469;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#12290;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#25628;&#32034;&#21644;&#20998;&#26512;&#31574;&#30053;&#65292;&#35813;&#20195;&#29702;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#26597;&#35810;&#20998;&#23376;&#25968;&#25454;&#24211;&#65292;&#24182;&#20174;&#22312;&#32447;&#25991;&#29486;&#20013;&#25552;&#21462;&#20851;&#38190;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#36824;&#37197;&#22791;&#20102;&#25105;&#20204;&#20026;RCR&#20219;&#21153;&#24320;&#21457;&#30340;&#26032;&#21453;&#24212;&#25351;&#32441;&#12290;&#30001;&#20110;RAG&#25216;&#26415;&#30340;&#20351;&#29992;&#65292;&#25105;&#20204;&#30340;&#20195;&#29702;&#20351;&#29992;&#26356;&#26032;&#30340;&#22312;&#32447;&#25968;&#25454;&#24211;&#20316;&#20026;&#30693;&#35782;&#28304;&#65292;&#26174;&#33879;&#20248;&#20110;&#20165;&#21463;&#20854;&#35757;&#32451;&#25968;&#25454;&#22266;&#23450;&#30693;&#35782;&#38480;&#21046;&#30340;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#31995;&#32479;&#21487;&#20197;&#26174;&#33879;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;&#36825;&#19968;&#37325;&#22823;&#36827;&#23637;&#23558;&#35745;&#31639;&#25216;&#26415;&#19982;&#21270;&#23398;&#31038;&#20250;&#26356;&#32039;&#23494;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent artificial intelligence (AI) research plots a promising future of automatic chemical reactions within the chemistry society. This study presents a transformative AI agent that automates the reaction condition recommendation (RCR) task in chemistry using retrieval-augmented generation (RAG) technology. By emulating expert chemists search and analysis strategies, the agent employs large language models (LLMs) to interrogate molecular databases and distill critical data from online literature. Further, the AI agent is equipped with our novel reaction fingerprint developed for the RCR task. Thanks to the RAG technology, our agent uses updated online databases as knowledge sources, significantly outperforming conventional AIs confined to the fixed knowledge within its training data. The resulting system can significantly reduce chemists workload, allowing them to focus on more fundamental and creative scientific problems. This significant advancement brings closer computational techn
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#20998;&#26512;&#21644;&#39564;&#35777;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#26041;&#27861;&#22312;&#22823;&#22411;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.13063</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#12289;&#39564;&#35777;&#21644;&#24212;&#29992;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies. (arXiv:2309.13063v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13063
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#20998;&#26512;&#21644;&#39564;&#35777;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#26041;&#27861;&#22312;&#22823;&#22411;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26085;&#24535;&#25968;&#25454;&#21487;&#20197;&#25581;&#31034;&#29992;&#25143;&#19982;&#32593;&#32476;&#25628;&#32034;&#26381;&#21153;&#30340;&#20132;&#20114;&#26041;&#24335;&#12289;&#29992;&#25143;&#30340;&#38656;&#27714;&#20197;&#21450;&#28385;&#24847;&#31243;&#24230;&#31561;&#23453;&#36149;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20998;&#26512;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#24182;&#19981;&#23481;&#26131;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#26032;&#30340;&#32593;&#32476;&#25628;&#32034;&#24418;&#24335;&#65292;&#22914;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#32842;&#22825;&#12290;&#20026;&#20102;&#29702;&#35299;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#25105;&#20204;&#38656;&#35201;&#19968;&#31181;&#33021;&#22815;&#29992;&#26377;&#24847;&#20041;&#30340;&#20998;&#31867;&#26041;&#24335;&#26631;&#35760;&#23427;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#25429;&#25417;&#20854;&#22810;&#26679;&#24615;&#21644;&#21160;&#24577;&#24615;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#19988;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#32780;&#35328;&#65292;&#35201;&#20040;&#20195;&#20215;&#39640;&#26114;&#35201;&#20040;&#19981;&#22815;&#28789;&#27963;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#26032;&#26041;&#27861;&#65292;&#36825;&#31181;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#20016;&#23500;&#19988;&#30456;&#20851;&#30340;&#27010;&#24565;&#12289;&#25551;&#36848;&#21644;&#31034;&#20363;&#26469;&#34920;&#31034;&#29992;&#25143;&#24847;&#22270;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;LLM&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#26085;&#24535;&#20998;&#26512;&#21487;&#33021;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;&#36825;&#26679;&#30340;&#20998;&#31867;&#24471;&#19981;&#21040;&#22806;&#37096;&#39564;&#35777;&#65292;&#24182;&#19988;&#21487;&#33021;&#23384;&#22312;&#19981;&#33391;&#30340;&#21453;&#39304;&#22238;&#36335;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20154;&#24037;&#19987;&#23478;&#21644;&#35780;&#20272;&#32773;&#26469;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Log data can reveal valuable information about how users interact with web search services, what they want, and how satisfied they are. However, analyzing user intents in log data is not easy, especially for new forms of web search such as AI-driven chat. To understand user intents from log data, we need a way to label them with meaningful categories that capture their diversity and dynamics. Existing methods rely on manual or ML-based labeling, which are either expensive or inflexible for large and changing datasets. We propose a novel solution using large language models (LLMs), which can generate rich and relevant concepts, descriptions, and examples for user intents. However, using LLMs to generate a user intent taxonomy and apply it to do log analysis can be problematic for two main reasons: such a taxonomy is not externally validated, and there may be an undesirable feedback loop. To overcome these issues, we propose a new methodology with human experts and assessors to verify th
&lt;/p&gt;</description></item></channel></rss>