<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>GUR&#26159;&#19968;&#31181;&#39044;&#35757;&#32451;&#26694;&#26550;&#65292;&#23558;&#35821;&#35328;&#24314;&#27169;&#21644;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#32467;&#21512;&#22312;&#21333;&#20010;&#35757;&#32451;&#27493;&#39588;&#20013;&#65292;&#36890;&#36807;&#20174;&#21407;&#22987;&#26080;&#26631;&#31614;&#25991;&#26723;&#20013;&#36873;&#25321;&#30456;&#20284;&#30340;&#25991;&#26412;&#23545;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#26080;&#38656;&#20219;&#20309;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#21363;&#21487;&#20316;&#20026;&#26816;&#32034;&#22120;&#36229;&#36807;&#20854;&#20182;&#39044;&#35757;&#32451;&#22522;&#32447;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.10056</link><description>&lt;p&gt;
&#20026;&#20102;&#34920;&#31034;&#32780;&#29983;&#25104;&#8212;&#8212;&#19968;&#31181;&#32467;&#21512;&#23545;&#27604;&#23398;&#20064;&#30340;&#35821;&#35328;&#39044;&#35757;&#32451;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Generate to Understand for Representation. (arXiv:2306.10056v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10056
&lt;/p&gt;
&lt;p&gt;
GUR&#26159;&#19968;&#31181;&#39044;&#35757;&#32451;&#26694;&#26550;&#65292;&#23558;&#35821;&#35328;&#24314;&#27169;&#21644;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#32467;&#21512;&#22312;&#21333;&#20010;&#35757;&#32451;&#27493;&#39588;&#20013;&#65292;&#36890;&#36807;&#20174;&#21407;&#22987;&#26080;&#26631;&#31614;&#25991;&#26723;&#20013;&#36873;&#25321;&#30456;&#20284;&#30340;&#25991;&#26412;&#23545;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#26080;&#38656;&#20219;&#20309;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#21363;&#21487;&#20316;&#20026;&#26816;&#32034;&#22120;&#36229;&#36807;&#20854;&#20182;&#39044;&#35757;&#32451;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#28044;&#29616;&#20102;&#22823;&#37327;&#39640;&#36136;&#37327;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#26497;&#22823;&#22320;&#24433;&#21709;&#20102;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#12289;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#21644;&#25991;&#26412;&#34920;&#31034;&#31561;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#19978;&#36825;&#20123;&#27169;&#22411;&#26159;&#22312;&#29305;&#23450;&#39046;&#22495;&#30340;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#24182;&#36827;&#34892;&#29305;&#23450;&#20219;&#21153;&#30340;&#24494;&#35843;&#65292;&#36825;&#23548;&#33268;&#20102;&#39640;&#26114;&#30340;GPU&#20351;&#29992;&#21644;&#21171;&#21160;&#21147;&#25104;&#26412;&#12290;&#25991;&#31456;&#25552;&#20986;&#20102;GUR&#65306;&#19968;&#31181;&#23558;&#35821;&#35328;&#24314;&#27169;&#21644;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#32467;&#21512;&#22312;&#21333;&#20010;&#35757;&#32451;&#27493;&#39588;&#20013;&#30340;&#39044;&#35757;&#32451;&#26694;&#26550;&#12290;&#25105;&#20204;&#20174;&#21407;&#22987;&#30340;&#26080;&#26631;&#31614;&#25991;&#26723;&#20013;&#22522;&#20110;&#26368;&#38271;&#20844;&#20849;&#23376;&#23383;&#31526;&#20018;&#65288;LCS&#65289;&#36873;&#25321;&#30456;&#20284;&#30340;&#25991;&#26412;&#23545;&#65292;&#24182;&#20351;&#29992;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#21644;&#26080;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;GUR&#27169;&#22411;&#22312;&#27809;&#26377;&#20219;&#20309;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#20316;&#20026;&#26816;&#32034;&#22120;&#36229;&#36807;&#20102;&#25152;&#26377;&#20854;&#20182;&#39044;&#35757;&#32451;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, a significant number of high-quality pretrained models have emerged, greatly impacting Natural Language Understanding (NLU), Natural Language Generation (NLG), and Text Representation tasks. Traditionally, these models are pretrained on custom domain corpora and finetuned for specific tasks, resulting in high costs related to GPU usage and labor. Unfortunately, recent trends in language modeling have shifted towards enhancing performance through scaling, further exacerbating the associated costs.  Introducing GUR: a pretraining framework that combines language modeling and contrastive learning objectives in a single training step. We select similar text pairs based on their Longest Common Substring (LCS) from raw unlabeled documents and train the model using masked language modeling and unsupervised contrastive learning. The resulting model, GUR, achieves impressive results without any labeled training data, outperforming all other pretrained baselines as a retriever a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#39318;&#20010;&#20855;&#26377;&#19977;&#22823;&#20851;&#38190;&#29305;&#24449;&#8212;&#8212;&#22270;&#24418;&#27880;&#24847;&#21147;&#12289;&#22810;&#27169;&#24577;&#27880;&#24847;&#21147;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#38754;&#21521;NFT&#30340;&#22810;&#27880;&#24847;&#21147;&#25512;&#33616;&#31995;&#32479;(NFT-MARS)&#65292;&#20197;&#35299;&#20915;NFT&#24066;&#22330;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.10053</link><description>&lt;p&gt;
NFT&#21040;MARS&#65306;&#38754;&#21521;NFT&#30340;&#22810;&#27880;&#24847;&#21147;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
NFTs to MARS: Multi-Attention Recommender System for NFTs. (arXiv:2306.10053v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#39318;&#20010;&#20855;&#26377;&#19977;&#22823;&#20851;&#38190;&#29305;&#24449;&#8212;&#8212;&#22270;&#24418;&#27880;&#24847;&#21147;&#12289;&#22810;&#27169;&#24577;&#27880;&#24847;&#21147;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#38754;&#21521;NFT&#30340;&#22810;&#27880;&#24847;&#21147;&#25512;&#33616;&#31995;&#32479;(NFT-MARS)&#65292;&#20197;&#35299;&#20915;NFT&#24066;&#22330;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#22686;&#24378;&#21508;&#20010;&#39046;&#22495;&#29992;&#25143;&#20307;&#39564;&#30340;&#24517;&#22791;&#24037;&#20855;&#12290;&#23613;&#31649;&#38024;&#23545;&#30005;&#24433;&#12289;&#38899;&#20048;&#21644;&#30005;&#23376;&#21830;&#21153;&#30340;&#25512;&#33616;&#31995;&#32479;&#24050;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#26085;&#30410;&#22686;&#38271;&#21644;&#32463;&#27982;&#24847;&#20041;&#37325;&#22823;&#30340;&#38750;&#21516;&#36136;&#21270;&#20195;&#24065;&#65288;NFT&#65289;&#24066;&#22330;&#20173;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;NFT&#24066;&#22330;&#30340;&#29420;&#29305;&#29305;&#24615;&#21644;&#26085;&#30410;&#31361;&#20986;&#30340;&#22320;&#20301;&#20984;&#26174;&#20102;&#24320;&#21457;&#19987;&#38376;&#38024;&#23545;&#20854;&#38656;&#27714;&#30340;&#23450;&#21046;&#25512;&#33616;&#31995;&#32479;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25581;&#31034;&#20854;&#20805;&#20998;&#28508;&#21147;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;NFT&#30340;&#29420;&#29305;&#29305;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#39318;&#20010;&#19987;&#38376;&#35774;&#35745;&#20197;&#24212;&#23545;NFT&#24066;&#22330;&#25361;&#25112;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#38754;&#21521;NFT&#30340;&#22810;&#27880;&#24847;&#21147;&#25512;&#33616;&#31995;&#32479;(NFT-MARS)&#65292;&#20855;&#26377;&#19977;&#20010;&#20851;&#38190;&#29305;&#24449;&#65306;(1)&#22270;&#24418;&#27880;&#24847;&#21147;&#20197;&#22788;&#29702;&#31232;&#30095;&#30340;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;;(2)&#22810;&#27169;&#24577;&#27880;&#24847;&#21147;&#20197;&#34701;&#20837;&#29992;&#25143;&#30340;&#29305;&#24449;&#20559;&#22909;;(3)&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#32771;&#34385;NFT&#20316;&#20026;&#33402;&#26415;&#20316;&#21697;&#21644;&#25968;&#23383;&#36164;&#20135;&#30340;&#21452;&#37325;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have become essential tools for enhancing user experiences across various domains. While extensive research has been conducted on recommender systems for movies, music, and e-commerce, the rapidly growing and economically significant Non-Fungible Token (NFT) market remains underexplored. The unique characteristics and increasing prominence of the NFT market highlight the importance of developing tailored recommender systems to cater to its specific needs and unlock its full potential. In this paper, we examine the distinctive characteristics of NFTs and propose the first recommender system specifically designed to address NFT market challenges. In specific, we develop a Multi-Attention Recommender System for NFTs (NFT-MARS) with three key characteristics: (1) graph attention to handle sparse user-item interactions, (2) multi-modal attention to incorporate feature preference of users, and (3) multi-task learning to consider the dual nature of NFTs as both artwork and
&lt;/p&gt;</description></item><item><title>TOBY&#26159;&#19968;&#31181;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#33021;&#24110;&#21161;&#29992;&#25143;&#25506;&#32034;&#23398;&#26415;&#35843;&#26597;&#35770;&#25991;&#30340;&#20869;&#23481;&#65292;&#21253;&#25324;&#20998;&#31867;&#23618;&#27425;&#32467;&#26500;&#35270;&#22270;&#12289;&#25991;&#26723;&#30456;&#20284;&#24615;&#35270;&#22270;&#12289;&#24341;&#29992;&#32593;&#32476;&#35270;&#22270;&#21644;&#35770;&#25991;&#25512;&#33616;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2306.10051</link><description>&lt;p&gt;
TOBY:&#19968;&#31181;&#29992;&#20110;&#25506;&#32034;&#23398;&#26415;&#35843;&#26597;&#35770;&#25991;&#25968;&#25454;&#30340;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
TOBY: A Tool for Exploring Data in Academic Survey Papers. (arXiv:2306.10051v1 [cs.DL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10051
&lt;/p&gt;
&lt;p&gt;
TOBY&#26159;&#19968;&#31181;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#33021;&#24110;&#21161;&#29992;&#25143;&#25506;&#32034;&#23398;&#26415;&#35843;&#26597;&#35770;&#25991;&#30340;&#20869;&#23481;&#65292;&#21253;&#25324;&#20998;&#31867;&#23618;&#27425;&#32467;&#26500;&#35270;&#22270;&#12289;&#25991;&#26723;&#30456;&#20284;&#24615;&#35270;&#22270;&#12289;&#24341;&#29992;&#32593;&#32476;&#35270;&#22270;&#21644;&#35770;&#25991;&#25512;&#33616;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;TOBY&#65292;&#19968;&#31181;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#24110;&#21161;&#29992;&#25143;&#25506;&#32034;&#23398;&#26415;&#35843;&#26597;&#35770;&#25991;&#30340;&#20869;&#23481;&#12290;&#21487;&#35270;&#21270;&#21253;&#25324;&#22235;&#20010;&#37096;&#20998;&#65306;&#35843;&#26597;&#25968;&#25454;&#30340;&#20998;&#31867;&#23618;&#27425;&#32467;&#26500;&#35270;&#22270;&#65292;&#20998;&#31867;&#31867;&#21035;&#31354;&#38388;&#20013;&#30340;&#25991;&#26723;&#30456;&#20284;&#24615;&#35270;&#22270;&#65292;&#24341;&#29992;&#32593;&#32476;&#35270;&#22270;&#20197;&#21450;&#19968;&#31181;&#26032;&#30340;&#35770;&#25991;&#25512;&#33616;&#24037;&#20855;&#12290;&#26412;&#25991;&#23558;&#35752;&#35770;&#36825;&#20123;&#21151;&#33021;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#24037;&#20855;&#37096;&#32626;&#24773;&#26223;&#19979;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper describes TOBY, a visualization tool that helps a user explore the contents of an academic survey paper. The visualization consists of four components: a hierarchical view of taxonomic data in the survey, a document similarity view in the space of taxonomic classes, a network view of citations, and a new paper recommendation tool. In this paper, we will discuss these features in the context of three separate deployments of the tool.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#34913;&#39033;&#30446;&#21644;&#29992;&#25143;&#20844;&#24179;&#24615;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#20302;&#21518;&#24724;&#30340;&#22312;&#32447;&#20248;&#21270;&#31639;&#27861;&#23454;&#29616;&#20102;&#32500;&#25345;&#25910;&#30410;&#21516;&#26102;&#23454;&#29616;&#20844;&#24179;&#25512;&#33616;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2306.10050</link><description>&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#25554;&#20540;&#39033;&#30446;&#21644;&#29992;&#25143;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Interpolating Item and User Fairness in Recommendation Systems. (arXiv:2306.10050v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#34913;&#39033;&#30446;&#21644;&#29992;&#25143;&#20844;&#24179;&#24615;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#20302;&#21518;&#24724;&#30340;&#22312;&#32447;&#20248;&#21270;&#31639;&#27861;&#23454;&#29616;&#20102;&#32500;&#25345;&#25910;&#30410;&#21516;&#26102;&#23454;&#29616;&#20844;&#24179;&#25512;&#33616;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#36793;&#24179;&#21488;&#20013;&#65292;&#24179;&#21488;&#19982;&#21334;&#23478;&#65288;&#39033;&#30446;&#65289;&#21644;&#23458;&#25143;&#65288;&#29992;&#25143;&#65289;&#31561;&#21508;&#31181;&#21508;&#26679;&#30340;&#21033;&#30410;&#30456;&#20851;&#32773;&#20114;&#21160;&#65292;&#27599;&#20010;&#30456;&#20851;&#32773;&#37117;&#26377;&#33258;&#24049;&#30340;&#26399;&#26395;&#32467;&#26524;&#65292;&#23547;&#25214;&#21512;&#36866;&#30340;&#24179;&#34913;&#28857;&#21464;&#24471;&#38750;&#24120;&#22797;&#26434;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#8220;&#20844;&#24179;&#25104;&#26412;&#8221;&#65292;&#23427;&#25429;&#25417;&#20102;&#24179;&#21488;&#22312;&#24179;&#34913;&#19981;&#21516;&#21033;&#30410;&#30456;&#20851;&#32773;&#21033;&#30410;&#26102;&#21487;&#33021;&#20570;&#20986;&#30340;&#22949;&#21327;&#12290;&#20986;&#20110;&#36825;&#20010;&#30446;&#30340;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20844;&#24179;&#25512;&#33616;&#26694;&#26550;&#65292;&#20854;&#20013;&#24179;&#21488;&#22312;&#25554;&#20540;&#39033;&#30446;&#21644;&#29992;&#25143;&#20844;&#24179;&#24615;&#32422;&#26463;&#26102;&#26368;&#22823;&#21270;&#20854;&#25910;&#30410;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#26356;&#29616;&#23454;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22312;&#32447;&#35774;&#32622;&#20013;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#20844;&#24179;&#25512;&#33616;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24179;&#21488;&#32570;&#20047;&#20102;&#35299;&#29992;&#25143;&#20559;&#22909;&#30340;&#30693;&#35782;&#65292;&#21482;&#33021;&#35266;&#23519;&#20108;&#36827;&#21046;&#36141;&#20080;&#20915;&#31574;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#20302;&#21518;&#24724;&#30340;&#22312;&#32447;&#20248;&#21270;&#31639;&#27861;&#65292;&#23427;&#22312;&#32500;&#25252;&#24179;&#21488;&#25910;&#30410;&#30340;&#21516;&#26102;&#31649;&#29702;&#39033;&#30446;&#21644;&#29992;&#25143;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#23454;&#29616;&#20844;&#24179;&#25512;&#33616;&#21516;&#26102;&#20445;&#25345;&#39640;&#25910;&#30410;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online platforms employ recommendation systems to enhance customer engagement and drive revenue. However, in a multi-sided platform where the platform interacts with diverse stakeholders such as sellers (items) and customers (users), each with their own desired outcomes, finding an appropriate middle ground becomes a complex operational challenge. In this work, we investigate the ``price of fairness'', which captures the platform's potential compromises when balancing the interests of different stakeholders. Motivated by this, we propose a fair recommendation framework where the platform maximizes its revenue while interpolating between item and user fairness constraints. We further examine the fair recommendation problem in a more realistic yet challenging online setting, where the platform lacks knowledge of user preferences and can only observe binary purchase decisions. To address this, we design a low-regret online optimization algorithm that preserves the platform's revenue while
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37051;&#22495;&#37325;&#21472;&#30340;&#22522;&#20110;&#22270;&#24418;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#65288;GNNO&#65289;&#65292;&#21033;&#29992;&#38544;&#34255;&#22312;&#29992;&#25143;&#34892;&#20026;&#20013;&#30340;&#32467;&#26500;&#20449;&#24687;&#36827;&#34892;&#36127;&#37319;&#26679;&#65292;&#29992;&#20110;&#22686;&#36827;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#30340;&#35757;&#32451;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.10047</link><description>&lt;p&gt;
&#22522;&#20110;&#37051;&#22495;&#30340;&#38590;&#20363;&#25366;&#25496;&#29992;&#20110;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Neighborhood-based Hard Negative Mining for Sequential Recommendation. (arXiv:2306.10047v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10047
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37051;&#22495;&#37325;&#21472;&#30340;&#22522;&#20110;&#22270;&#24418;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#65288;GNNO&#65289;&#65292;&#21033;&#29992;&#38544;&#34255;&#22312;&#29992;&#25143;&#34892;&#20026;&#20013;&#30340;&#32467;&#26500;&#20449;&#24687;&#36827;&#34892;&#36127;&#37319;&#26679;&#65292;&#29992;&#20110;&#22686;&#36827;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#30340;&#35757;&#32451;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#26102;&#65292;&#36127;&#37319;&#26679;&#22312;&#20854;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#30446;&#21069;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#31574;&#30053;&#26469;&#25366;&#25496;&#20449;&#24687;&#20016;&#23500;&#30340;&#36127;&#26679;&#26412;&#65292;&#20197;&#24378;&#21270;&#35757;&#32451;&#21644;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#24456;&#23569;&#26377;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#32467;&#26500;&#20449;&#24687;&#12290;&#26412;&#25991;&#35266;&#23519;&#21040;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#19981;&#21516;&#31243;&#24230;&#37051;&#22495;&#37325;&#21472;&#30340;&#19981;&#21516;&#32452;&#33410;&#28857;&#23545;&#30456;&#20284;&#24230;&#30340;&#20998;&#24067;&#21457;&#29983;&#26174;&#30528;&#21464;&#21270;&#65292;&#36825;&#34920;&#26126;&#19981;&#21516;&#32452;&#20013;&#30340;&#39033;&#30446;&#23545;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#30340;&#36127;&#20851;&#31995;&#12290;&#21463;&#27492;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37051;&#22495;&#37325;&#21472;&#30340;&#22522;&#20110;&#22270;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#65288;GNNO&#65289;&#26469;&#21033;&#29992;&#38544;&#34255;&#22312;&#29992;&#25143;&#34892;&#20026;&#20013;&#30340;&#32467;&#26500;&#20449;&#24687;&#36827;&#34892;&#36127;&#37319;&#26679;&#12290;GNNO&#39318;&#20808;&#20351;&#29992;&#35757;&#32451;&#24207;&#21015;&#26500;&#24314;&#20840;&#23616;&#21152;&#26435;&#39033;&#30446;&#36716;&#25442;&#22270;&#12290;&#38543;&#21518;&#65292;&#23427;&#26681;&#25454;&#19982;&#30446;&#26631;&#39033;&#30340;&#37325;&#21472;&#31243;&#24230;&#26469;&#25366;&#25496;&#38590;&#20363;&#36127;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Negative sampling plays a crucial role in training successful sequential recommendation models. Instead of merely employing random negative sample selection, numerous strategies have been proposed to mine informative negative samples to enhance training and performance. However, few of these approaches utilize structural information. In this work, we observe that as training progresses, the distributions of node-pair similarities in different groups with varying degrees of neighborhood overlap change significantly, suggesting that item pairs in distinct groups may possess different negative relationships. Motivated by this observation, we propose a Graph-based Negative sampling approach based on Neighborhood Overlap (GNNO) to exploit structural information hidden in user behaviors for negative mining. GNNO first constructs a global weighted item transition graph using training sequences. Subsequently, it mines hard negative samples based on the degree of overlap with the target item on
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;4&#20010;&#22522;&#26412;&#24067;&#23616;&#22359;&#21644;4&#20010;&#25991;&#26412;&#31867;&#21035;&#30340;&#24067;&#23616;&#26631;&#31614;&#30340;&#25968;&#23383;&#25991;&#26723;&#30340;&#21322;&#33258;&#21160;&#27880;&#37322;&#36807;&#31243;&#65292;&#29983;&#25104;&#20102;&#19968;&#20010;&#29992;&#20110;&#20844;&#20849;&#20107;&#21153;&#39046;&#22495;&#30340;DLA&#26032;&#25968;&#25454;&#24211;&#65292;&#20197;&#24110;&#21161;&#33258;&#21160;&#22788;&#29702;&#25968;&#23383;&#25991;&#26723;&#12290;</title><link>http://arxiv.org/abs/2306.10046</link><description>&lt;p&gt;
&#20844;&#20849;&#20107;&#21153;&#39046;&#22495;&#20013;&#25991;&#26723;&#24067;&#23616;&#27880;&#37322;&#65306;&#25968;&#25454;&#24211;&#19982;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Document Layout Annotation: Database and Benchmark in the Domain of Public Affairs. (arXiv:2306.10046v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10046
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;4&#20010;&#22522;&#26412;&#24067;&#23616;&#22359;&#21644;4&#20010;&#25991;&#26412;&#31867;&#21035;&#30340;&#24067;&#23616;&#26631;&#31614;&#30340;&#25968;&#23383;&#25991;&#26723;&#30340;&#21322;&#33258;&#21160;&#27880;&#37322;&#36807;&#31243;&#65292;&#29983;&#25104;&#20102;&#19968;&#20010;&#29992;&#20110;&#20844;&#20849;&#20107;&#21153;&#39046;&#22495;&#30340;DLA&#26032;&#25968;&#25454;&#24211;&#65292;&#20197;&#24110;&#21161;&#33258;&#21160;&#22788;&#29702;&#25968;&#23383;&#25991;&#26723;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27599;&#22825;&#37117;&#20250;&#29983;&#25104;&#25104;&#21315;&#19978;&#19975;&#20010;&#25968;&#23383;&#25991;&#26723;&#65292;&#20854;&#20013;&#21253;&#21547;&#23545;&#20844;&#21496;&#12289;&#20844;&#20849;&#32452;&#32455;&#21644;&#20844;&#27665;&#26377;&#29992;&#30340;&#20449;&#24687;&#12290;&#37492;&#20110;&#25163;&#21160;&#22788;&#29702;&#36825;&#20123;&#25991;&#26723;&#30340;&#19981;&#21487;&#33021;&#24615;&#65292;&#22312;&#26576;&#20123;&#34892;&#19994;&#20013;&#33258;&#21160;&#22788;&#29702;&#36825;&#20123;&#25991;&#26723;&#21464;&#24471;&#36234;&#26469;&#36234;&#24517;&#35201;&#12290;&#28982;&#32780;&#65292;&#36825;&#39033;&#20219;&#21153;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#20165;&#22522;&#20110;&#25991;&#26412;&#30340;&#35299;&#26512;&#26159;&#19981;&#36275;&#20197;&#23436;&#20840;&#29702;&#35299;&#36890;&#36807;&#19981;&#21516;&#37325;&#35201;&#24615;&#30340;&#19981;&#21516;&#32452;&#20214;&#21576;&#29616;&#30340;&#20449;&#24687;&#30340;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#25991;&#26723;&#24067;&#23616;&#20998;&#26512;&#65288;DLA&#65289;&#22810;&#24180;&#26469;&#19968;&#30452;&#26159;&#19968;&#20010;&#26377;&#36259;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#26088;&#22312;&#26816;&#27979;&#21644;&#20998;&#31867;&#25991;&#26723;&#30340;&#22522;&#26412;&#32452;&#20214;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#31243;&#24207;&#23545;&#25968;&#23383;&#25991;&#26723;&#36827;&#34892;&#21322;&#33258;&#21160;&#27880;&#37322;&#65292;&#21253;&#25324;4&#20010;&#22522;&#26412;&#24067;&#23616;&#22359;&#21644;4&#20010;&#25991;&#26412;&#31867;&#21035;&#30340;&#19981;&#21516;&#24067;&#23616;&#26631;&#31614;&#12290;&#25105;&#20204;&#24212;&#29992;&#27492;&#31243;&#24207;&#22312;20&#22235;&#20010;&#26469;&#33258;&#35199;&#29677;&#29273;&#25919;&#24220;&#30340;&#25968;&#25454;&#28304;&#19978;&#25910;&#38598;&#20102;&#19968;&#20010;&#20844;&#20849;&#20107;&#21153;&#39046;&#22495;&#30340;DLA&#26032;&#25968;&#25454;&#24211;&#12290;&#35813;&#25968;&#25454;&#24211;&#21253;&#21547;......
&lt;/p&gt;
&lt;p&gt;
Every day, thousands of digital documents are generated with useful information for companies, public organizations, and citizens. Given the impossibility of processing them manually, the automatic processing of these documents is becoming increasingly necessary in certain sectors. However, this task remains challenging, since in most cases a text-only based parsing is not enough to fully understand the information presented through different components of varying significance. In this regard, Document Layout Analysis (DLA) has been an interesting research field for many years, which aims to detect and classify the basic components of a document. In this work, we used a procedure to semi-automatically annotate digital documents with different layout labels, including 4 basic layout blocks and 4 text categories. We apply this procedure to collect a novel database for DLA in the public affairs domain, using a set of 24 data sources from the Spanish Administration. The database comprises 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#23558;&#23454;&#20307;&#38142;&#25509;&#21040;&#30693;&#35782;&#24211;&#20013;&#30340;&#36890;&#29992;&#31995;&#32479;&#65292;&#24182;&#23558;&#20854;&#36866;&#24212;&#20110;&#38142;&#25509;&#29305;&#23450;&#39046;&#22495;&#30340;&#23454;&#20307;&#65292;&#29305;&#21035;&#26159; COVID-19 &#30456;&#20851;&#31185;&#23398;&#25991;&#29486;&#20013;&#30340;&#23884;&#20837;&#24335;&#23454;&#20307;&#12290;&#36890;&#36807;&#21033;&#29992;&#34920;&#26684;&#30340;&#32467;&#26500;&#21644;&#35821;&#20041;&#29305;&#24449;&#65292;&#20197;&#25552;&#39640;&#25972;&#20307;&#23454;&#20307;&#38142;&#25509;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.10044</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#31185;&#23398;&#25991;&#29486;&#20013;&#34920;&#26684;&#23454;&#20307;&#38142;&#25509;&#30340;&#23454;&#29992;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Practical Entity Linking System for Tables in Scientific Literature. (arXiv:2306.10044v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#23558;&#23454;&#20307;&#38142;&#25509;&#21040;&#30693;&#35782;&#24211;&#20013;&#30340;&#36890;&#29992;&#31995;&#32479;&#65292;&#24182;&#23558;&#20854;&#36866;&#24212;&#20110;&#38142;&#25509;&#29305;&#23450;&#39046;&#22495;&#30340;&#23454;&#20307;&#65292;&#29305;&#21035;&#26159; COVID-19 &#30456;&#20851;&#31185;&#23398;&#25991;&#29486;&#20013;&#30340;&#23884;&#20837;&#24335;&#23454;&#20307;&#12290;&#36890;&#36807;&#21033;&#29992;&#34920;&#26684;&#30340;&#32467;&#26500;&#21644;&#35821;&#20041;&#29305;&#24449;&#65292;&#20197;&#25552;&#39640;&#25972;&#20307;&#23454;&#20307;&#38142;&#25509;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#38142;&#25509;&#26159;&#26500;&#24314;&#30693;&#35782;&#22270;&#35889;&#30340;&#37325;&#35201;&#27493;&#39588;&#65292;&#21487;&#20197;&#26041;&#20415;&#22320;&#22238;&#31572;&#21253;&#25324;&#20174;&#36825;&#20123;&#25991;&#26723;&#20013;&#26816;&#32034;&#30456;&#20851;&#20449;&#24687;&#22312;&#20869;&#30340;&#39640;&#32423;&#38382;&#39064;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#31995;&#32479;&#65292;&#29992;&#20110;&#23558;&#23454;&#20307;&#38142;&#25509;&#21040;&#32500;&#22522;&#25968;&#25454;&#30693;&#35782;&#24211;&#20013;&#30340;&#39033;&#12290;&#23427;&#25551;&#36848;&#20102;&#22914;&#20309;&#36866;&#24212;&#35813;&#31995;&#32479;&#20197;&#38142;&#25509;&#39046;&#22495;&#29305;&#23450;&#30340;&#23454;&#20307;&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#26469;&#33258;COVID-19&#30456;&#20851;&#31185;&#23398;&#25991;&#29486;&#20013;&#30340;&#23884;&#20837;&#24335;&#23454;&#20307;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#31995;&#32479;&#30340;&#31163;&#32447;&#23454;&#20363;&#30340;&#35774;&#32622;&#65292;&#20351;&#25105;&#20204;&#30340;&#23454;&#20307;&#38142;&#25509;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#26356;&#21152;&#21487;&#34892;&#12290;&#20316;&#20026;&#25512;&#26029;&#31185;&#23398;&#34920;&#26684;&#30340;&#35821;&#20041;&#21547;&#20041;&#30340;&#26356;&#24191;&#27867;&#26041;&#27861;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#21033;&#29992;&#34920;&#26684;&#30340;&#32467;&#26500;&#21644;&#35821;&#20041;&#29305;&#24449;&#26469;&#25552;&#39640;&#25972;&#20307;&#23454;&#20307;&#38142;&#25509;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entity linking is an important step towards constructing knowledge graphs that facilitate advanced question answering over scientific documents, including the retrieval of relevant information included in tables within these documents. This paper introduces a general-purpose system for linking entities to items in the Wikidata knowledge base. It describes how we adapt this system for linking domain-specific entities, especially for those entities embedded within tables drawn from COVID-19-related scientific literature. We describe the setup of an efficient offline instance of the system that enables our entity-linking approach to be more feasible in practice. As part of a broader approach to infer the semantic meaning of scientific tables, we leverage the structural and semantic characteristics of the tables to improve overall entity linking performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37197;&#23545;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23558;&#26041;&#38754;-&#24847;&#35265;&#37197;&#23545;&#30693;&#35782;&#27880;&#20837;&#21040;Aspect Sentiment Triplet Extraction&#65288;ASTE&#65289;&#27169;&#22411;&#20013;&#65292;&#25552;&#39640;&#20102;&#19977;&#20803;&#32452;&#25552;&#21462;&#30340;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.10042</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;Aspect Sentiment Triplet Extraction&#30340;&#37197;&#23545;&#22686;&#24378;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Pairing Enhancement Approach for Aspect Sentiment Triplet Extraction. (arXiv:2306.10042v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10042
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37197;&#23545;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23558;&#26041;&#38754;-&#24847;&#35265;&#37197;&#23545;&#30693;&#35782;&#27880;&#20837;&#21040;Aspect Sentiment Triplet Extraction&#65288;ASTE&#65289;&#27169;&#22411;&#20013;&#65292;&#25552;&#39640;&#20102;&#19977;&#20803;&#32452;&#25552;&#21462;&#30340;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Aspect Sentiment Triplet Extraction&#65288;ASTE&#65289;&#26088;&#22312;&#20174;&#35780;&#35770;&#25991;&#26412;&#20013;&#25552;&#21462;&#19968;&#20010;&#26041;&#38754;&#26415;&#35821;&#12289;&#19968;&#20010;&#24847;&#35265;&#26415;&#35821;&#21644;&#23427;&#20204;&#30456;&#24212;&#30340;&#24773;&#24863;&#26497;&#24615;&#30340;&#19977;&#20803;&#32452;&#12290;&#30001;&#20110;&#35821;&#35328;&#30340;&#22797;&#26434;&#24615;&#21644;&#21333;&#20010;&#21477;&#23376;&#20013;&#23384;&#22312;&#22810;&#20010;&#26041;&#38754;&#26415;&#35821;&#21644;&#24847;&#35265;&#26415;&#35821;&#65292;&#24403;&#21069;&#30340;&#27169;&#22411;&#32463;&#24120;&#20250;&#28151;&#28102;&#25551;&#36848;&#23427;&#30340;&#26041;&#38754;&#26415;&#35821;&#21644;&#24847;&#35265;&#26415;&#35821;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37197;&#23545;&#22686;&#24378;&#26041;&#27861;&#65292;&#23427;&#22312;&#35757;&#32451;&#38454;&#27573;&#37319;&#29992;&#23545;&#27604;&#23398;&#20064;&#65292;&#23558;&#26041;&#38754;-&#24847;&#35265;&#37197;&#23545;&#30693;&#35782;&#27880;&#20837;&#21040;&#19977;&#20803;&#32452;&#25552;&#21462;&#27169;&#22411;&#20013;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20960;&#31181;&#30456;&#20851;&#32463;&#20856;&#21644;&#26368;&#20808;&#36827;&#30340;&#19977;&#20803;&#32452;&#25552;&#21462;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22235;&#20010;ASTE&#25968;&#25454;&#38598;&#65288;&#21363;14lap&#65292;14res&#65292;15res&#21644;16res&#65289;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#27492;&#22806;&#65292;&#28040;&#34701;&#30740;&#31350;&#36827;&#34892;&#20998;&#26512;&#24182;&#39564;&#35777;&#20102;&#23545;&#27604;&#23398;&#20064;&#30456;&#27604;&#20854;&#20182;&#37197;&#23545;&#22686;&#24378;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Aspect Sentiment Triplet Extraction (ASTE) aims to extract the triplet of an aspect term, an opinion term, and their corresponding sentiment polarity from the review texts. Due to the complexity of language and the existence of multiple aspect terms and opinion terms in a single sentence, current models often confuse the connections between an aspect term and the opinion term describing it. To address this issue, we propose a pairing enhancement approach for ASTE, which incorporates contrastive learning during the training stage to inject aspect-opinion pairing knowledge into the triplet extraction model. Experimental results demonstrate that our approach performs well on four ASTE datasets (i.e., 14lap, 14res, 15res and 16res) compared to several related classical and state-of-the-art triplet extraction methods. Moreover, ablation studies conduct an analysis and verify the advantage of contrastive learning over other pairing enhancement approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#26032;&#38395;&#25991;&#31456;&#25968;&#25454;&#65292;&#37319;&#29992;Transformer&#27169;&#22411;&#27169;&#25311;&#21830;&#19994;&#36712;&#36857;&#65292;&#25581;&#31034;&#21830;&#19994;&#36235;&#21183;&#21644;&#34892;&#19994;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.10034</link><description>&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#26102;&#31354;&#25968;&#25454;&#20998;&#26512;&#22312;&#25581;&#31034;&#21830;&#19994;&#36712;&#36857;&#26041;&#38754;&#30340;&#24212;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Unlocking Insights into Business Trajectories with Transformer-based Spatio-temporal Data Analysis. (arXiv:2306.10034v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#26032;&#38395;&#25991;&#31456;&#25968;&#25454;&#65292;&#37319;&#29992;Transformer&#27169;&#22411;&#27169;&#25311;&#21830;&#19994;&#36712;&#36857;&#65292;&#25581;&#31034;&#21830;&#19994;&#36235;&#21183;&#21644;&#34892;&#19994;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21830;&#19994;&#19990;&#30028;&#25345;&#32493;&#21457;&#23637;&#65292;&#20445;&#25345;&#39046;&#20808;&#38656;&#35201;&#28145;&#20837;&#29702;&#35299;&#24066;&#22330;&#36235;&#21183;&#21644;&#19994;&#32489;&#12290;&#26412;&#25991;&#36890;&#36807;&#27169;&#25311;&#21830;&#19994;&#36712;&#36857;&#65292;&#21033;&#29992;&#26032;&#38395;&#25991;&#31456;&#25968;&#25454;&#26469;&#28385;&#36275;&#36825;&#19968;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
The world of business is constantly evolving and staying ahead of the curve requires a deep understanding of market trends and performance. This article addresses this requirement by modeling business trajectories using news articles data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;CoHHGN+&#65292;&#29992;&#20110;&#35299;&#20915;&#32570;&#20047;&#29992;&#25143;ID&#30340;&#30005;&#21830;&#32593;&#31449;&#25968;&#25454;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#23450;&#20041;&#30340;&#20266;&#20250;&#35805;&#20197;&#21450;&#21253;&#25324;&#20215;&#26684;&#12289;&#31867;&#21035;&#12289;&#24615;&#21035;&#21644;&#22320;&#21306;&#31561;&#29992;&#25143;&#20449;&#24687;&#65292;&#24471;&#21040;&#20102;&#36739;&#22909;&#30340;&#25512;&#33616;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10029</link><description>&lt;p&gt;
&#37319;&#29992;&#20998;&#23618;&#23884;&#20837;&#21644;&#20250;&#35805;&#23646;&#24615;&#30340;&#20266;&#20250;&#35805;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Pseudo session-based recommendation with hierarchical embedding and session attributes. (arXiv:2306.10029v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10029
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;CoHHGN+&#65292;&#29992;&#20110;&#35299;&#20915;&#32570;&#20047;&#29992;&#25143;ID&#30340;&#30005;&#21830;&#32593;&#31449;&#25968;&#25454;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#23450;&#20041;&#30340;&#20266;&#20250;&#35805;&#20197;&#21450;&#21253;&#25324;&#20215;&#26684;&#12289;&#31867;&#21035;&#12289;&#24615;&#21035;&#21644;&#22320;&#21306;&#31561;&#29992;&#25143;&#20449;&#24687;&#65292;&#24471;&#21040;&#20102;&#36739;&#22909;&#30340;&#25512;&#33616;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#38544;&#31169;&#38382;&#39064;&#65292;&#30005;&#23376;&#21830;&#21153;&#32593;&#31449;&#26080;&#27861;&#20026;&#27599;&#20010;&#20132;&#26131;&#25968;&#25454;&#26465;&#30446;&#25552;&#20379;&#26631;&#35782;&#21495;&#65288;&#29992;&#25143;ID&#65289;&#12290;&#22240;&#20026;&#22823;&#22810;&#25968;&#25512;&#33616;&#26041;&#27861;&#20551;&#23450;&#25152;&#26377;&#25968;&#25454;&#37117;&#34987;&#20998;&#37197;&#20102;&#29992;&#25143;ID&#65292;&#25152;&#20197;&#23427;&#20204;&#19981;&#33021;&#24212;&#29992;&#20110;&#27809;&#26377;&#29992;&#25143;ID&#30340;&#25968;&#25454;&#12290;&#26368;&#36817;&#30740;&#31350;&#20102;&#22522;&#20110;&#20250;&#35805;&#20449;&#24687;&#30340;&#20250;&#35805;&#25512;&#33616;&#65288;SBR&#65289;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#29992;&#25143;&#30340;&#30701;&#26399;&#34892;&#20026;&#20449;&#24687;&#12290;&#24120;&#35268;&#30340;SBR&#21482;&#20351;&#29992;&#19982;&#24863;&#20852;&#36259;&#30340;&#39033;&#30446;&#30456;&#20851;&#30340;&#20449;&#24687;&#26469;&#36827;&#34892;&#25512;&#33616;&#65288;&#20363;&#22914;&#65292;&#22312;EC&#31449;&#28857;&#19978;&#20351;&#29992;&#39033;&#30446;ID&#65289;&#12290;&#29305;&#21035;&#26159;&#22312;EC&#32593;&#31449;&#30340;&#24773;&#20917;&#19979;&#65292;&#35760;&#24405;&#30340;&#25968;&#25454;&#21253;&#25324;&#34987;&#36141;&#20080;&#30340;&#29289;&#21697;&#21517;&#31216;&#12289;&#29289;&#21697;&#20215;&#26684;&#12289;&#31867;&#21035;&#23618;&#27425;&#32467;&#26500;&#20197;&#21450;&#29992;&#25143;&#30340;&#24615;&#21035;&#21644;&#22320;&#21306;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20026;&#27809;&#26377;&#29992;&#25143;ID&#21644;&#20250;&#35805;ID&#30340;EC&#32593;&#31449;&#30340;&#36141;&#20080;&#21382;&#21490;&#25968;&#25454;&#23450;&#20041;&#20102;&#20266;&#20250;&#35805;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;CoHHGN+&#20250;&#35805;&#25512;&#33616;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#21327;&#21516;&#23548;&#21521;&#30340;&#24322;&#26500;&#36229;&#22270;&#21644;&#20840;&#23616;&#22270;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, electronic commerce (EC) websites have been unable to provide an identification number (user ID) for each transaction data entry because of privacy issues. Because most recommendation methods assume that all data are assigned a user ID, they cannot be applied to the data without user IDs. Recently, session-based recommendation (SBR) based on session information, which is short-term behavioral information of users, has been studied. A general SBR uses only information about the item of interest to make a recommendation (e.g., item ID for an EC site). Particularly in the case of EC sites, the data recorded include the name of the item being purchased, the price of the item, the category hierarchy, and the gender and region of the user. In this study, we define a pseudo--session for the purchase history data of an EC site without user IDs and session IDs. Finally, we propose an SBR with a co-guided heterogeneous hypergraph and globalgraph network plus, called CoHHGN+. The result
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GLSM&#30340;&#22522;&#20110;&#22270;&#30340;&#38271;&#26399;&#21644;&#30701;&#26399;&#20852;&#36259;&#27169;&#22411;&#65292;&#21487;&#20197;&#24456;&#22909;&#22320;&#22788;&#29702;&#38271;&#26399;&#21644;&#30701;&#26399;&#29992;&#25143;&#20852;&#36259;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.10028</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#38271;&#30701;&#26399;&#20852;&#36259;&#27169;&#22411;&#29992;&#20110;&#28857;&#20987;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Graph Based Long-Term And Short-Term Interest Model for Click-Through Rate Prediction. (arXiv:2306.10028v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GLSM&#30340;&#22522;&#20110;&#22270;&#30340;&#38271;&#26399;&#21644;&#30701;&#26399;&#20852;&#36259;&#27169;&#22411;&#65292;&#21487;&#20197;&#24456;&#22909;&#22320;&#22788;&#29702;&#38271;&#26399;&#21644;&#30701;&#26399;&#29992;&#25143;&#20852;&#36259;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#39044;&#27979;&#26088;&#22312;&#39044;&#27979;&#29992;&#25143;&#28857;&#20987;&#39033;&#30340;&#27010;&#29575;&#65292;&#26159;&#22312;&#32447;&#25512;&#33616;&#21644;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#20043;&#19968;&#12290;&#22312;&#36825;&#26679;&#30340;&#31995;&#32479;&#20013;&#65292;&#20016;&#23500;&#30340;&#29992;&#25143;&#34892;&#20026;&#65288;&#21363;&#38271;&#26399;&#21644;&#30701;&#26399;&#65289;&#24050;&#34987;&#35777;&#26126;&#23545;&#25429;&#25417;&#29992;&#25143;&#20852;&#36259;&#38750;&#24120;&#26377;&#20215;&#20540;&#12290;&#24037;&#19994;&#30028;&#21644;&#23398;&#26415;&#30028;&#37117;&#23545;&#36825;&#20010;&#20027;&#39064;&#38750;&#24120;&#20851;&#27880;&#65292;&#24182;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#24314;&#27169;&#38271;&#26399;&#21644;&#30701;&#26399;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#12290;&#20294;&#20173;&#23384;&#22312;&#19968;&#20123;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#65288;1&#65289;&#22522;&#20110;&#35268;&#21017;&#21644;&#25130;&#26029;&#30340;&#26041;&#27861;&#20174;&#38271;&#26399;&#34892;&#20026;&#20013;&#25552;&#21462;&#20449;&#24687;&#26131;&#23548;&#33268;&#20449;&#24687;&#20002;&#22833;&#65292;&#65288;2&#65289;&#20174;&#30701;&#26399;&#34892;&#20026;&#20013;&#25552;&#21462;&#20449;&#24687;&#26102;&#21333;&#19968;&#21453;&#39304;&#34892;&#20026;&#26080;&#35770;&#22330;&#26223;&#37117;&#20250;&#23548;&#33268;&#20449;&#24687;&#28151;&#28102;&#21644;&#22122;&#22768;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#30340;&#38271;&#26399;&#21644;&#30701;&#26399;&#20852;&#36259;&#27169;&#22411;&#65292;&#31216;&#20026;GLSM&#12290;&#23427;&#30001;&#19968;&#20010;&#22810;&#20852;&#36259;&#22270;&#32467;&#26500;&#32452;&#25104;&#65292;&#29992;&#20110;&#25429;&#25417;&#38271;&#26399;&#29992;&#25143;&#34892;&#20026;&#65292;&#19968;&#20010;&#22810;&#22330;&#26223;&#20852;&#36259;&#23376;&#22270;&#29992;&#20110;&#25429;&#25417;&#30701;&#26399;&#29992;&#25143;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction aims to predict the probability that the user will click an item, which has been one of the key tasks in online recommender and advertising systems. In such systems, rich user behavior (viz. long- and short-term) has been proved to be of great value in capturing user interests. Both industry and academy have paid much attention to this topic and propose different approaches to modeling with long-term and short-term user behavior data. But there are still some unresolved issues. More specially, (1) rule and truncation based methods to extract information from long-term behavior are easy to cause information loss, and (2) single feedback behavior regardless of scenario to extract information from short-term behavior lead to information confusion and noise. To fill this gap, we propose a Graph based Long-term and Short-term interest Model, termed GLSM. It consists of a multi-interest graph structure for capturing long-term user behavior, a multi-scenari
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#35299;&#21644;&#20132;&#38169;&#22810;&#20010;&#25490;&#21517;&#30340;&#21518;&#28857;&#20987;&#24230;&#37327;&#20197;&#20943;&#23569;&#26679;&#26412;&#26041;&#24046;&#12290;&#35813;&#26041;&#27861;&#19987;&#27880;&#20110;&#27979;&#37327;&#22810;&#20010;&#25490;&#21517;&#20013;&#27599;&#20010;&#39033;&#30446;&#30340;&#21518;&#28857;&#20987;&#24230;&#37327;&#65292;&#24182;&#20248;&#21270;&#25490;&#21517;&#20197;&#26292;&#38706;&#20855;&#26377;&#39640;&#32676;&#20307;&#26041;&#24046;&#30340;&#39033;&#30446;&#12290;</title><link>http://arxiv.org/abs/2306.10024</link><description>&lt;p&gt;
&#20998;&#35299;&#21644;&#20132;&#38169;&#29992;&#20110;&#20943;&#23569;&#21518;&#28857;&#20987;&#24230;&#37327;&#30340;&#26041;&#24046;
&lt;/p&gt;
&lt;p&gt;
Decomposition and Interleaving for Variance Reduction of Post-click Metrics. (arXiv:2306.10024v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10024
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#35299;&#21644;&#20132;&#38169;&#22810;&#20010;&#25490;&#21517;&#30340;&#21518;&#28857;&#20987;&#24230;&#37327;&#20197;&#20943;&#23569;&#26679;&#26412;&#26041;&#24046;&#12290;&#35813;&#26041;&#27861;&#19987;&#27880;&#20110;&#27979;&#37327;&#22810;&#20010;&#25490;&#21517;&#20013;&#27599;&#20010;&#39033;&#30446;&#30340;&#21518;&#28857;&#20987;&#24230;&#37327;&#65292;&#24182;&#20248;&#21270;&#25490;&#21517;&#20197;&#26292;&#38706;&#20855;&#26377;&#39640;&#32676;&#20307;&#26041;&#24046;&#30340;&#39033;&#30446;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#36739;&#22810;&#20010;&#25490;&#21517;&#21518;&#28857;&#20987;&#24230;&#37327;&#65288;&#20363;&#22914;&#20572;&#30041;&#26102;&#38388;&#21644;&#36716;&#21270;&#29575;&#65289;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#28041;&#21450;&#65288;1&#65289;&#23558;&#25490;&#21517;&#30340;&#21518;&#28857;&#20987;&#24230;&#37327;&#27979;&#37327;&#20998;&#35299;&#20026;&#28857;&#20987;&#27169;&#22411;&#20272;&#35745;&#21644;&#25490;&#21517;&#20013;&#27599;&#20010;&#39033;&#30340;&#21518;&#28857;&#20987;&#24230;&#37327;&#27979;&#37327;&#65292;&#20197;&#21450;&#65288;2&#65289;&#20132;&#38169;&#22810;&#20010;&#25490;&#21517;&#20197;&#29983;&#25104;&#19968;&#20010;&#20559;&#22909;&#26292;&#38706;&#20855;&#26377;&#39640;&#32676;&#20307;&#26041;&#24046;&#30340;&#39033;&#30446;&#30340;&#21333;&#20010;&#25490;&#21517;&#12290;&#21518;&#28857;&#20987;&#24230;&#37327;&#27979;&#37327;&#30340;&#20998;&#35299;&#20351;&#24471;&#21487;&#20197;&#22312;&#25490;&#21517;&#20013;&#33258;&#30001;&#24067;&#23616;&#39033;&#30446;&#65292;&#24182;&#19987;&#27880;&#20110;&#22810;&#20010;&#25490;&#21517;&#20013;&#27599;&#20010;&#39033;&#30446;&#30340;&#21518;&#28857;&#20987;&#24230;&#37327;&#30340;&#27979;&#37327;&#12290;&#22810;&#20010;&#25490;&#21517;&#30340;&#20132;&#38169;&#36890;&#36807;&#20248;&#21270;&#23637;&#31034;&#32473;&#29992;&#25143;&#30340;&#25490;&#21517;&#65292;&#20197;&#20415;&#37027;&#20123;&#39033;&#30446;&#25509;&#25910;&#26356;&#22810;&#30340;&#21518;&#28857;&#20987;&#24230;&#37327;&#26679;&#26412;&#65292;&#20174;&#32780;&#20943;&#23569;&#20855;&#26377;&#39640;&#32676;&#20307;&#26041;&#24046;&#30340;&#39033;&#30446;&#30340;&#26679;&#26412;&#26041;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#35777;&#26126;&#65292;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#22320;&#38477;&#20302;&#21518;&#28857;&#20987;&#24230;&#37327;&#30340;&#26679;&#26412;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we propose an efficient method for comparing the post-click metric (e.g., dwell time and conversion rate) of multiple rankings in online experiments. The proposed method involves (1) the decomposition of the post-click metric measurement of a ranking into a click model estimation and a post-click metric measurement of each item in the ranking, and (2) interleaving of multiple rankings to produce a single ranking that preferentially exposes items possessing a high population variance. The decomposition of the post-click metric measurement enables the free layout of items in a ranking and focuses on the measurement of the post-click metric of each item in the multiple rankings. The interleaving of multiple rankings reduces the sample variance of the items possessing a high population variance by optimizing a ranking to be presented to the users so that those items received more samples of the post-click metric. In addition, we provide a proof that the proposed method leads
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#20132;&#38169;&#27604;&#36739;&#26041;&#27861;&#30340;&#25928;&#29575;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#21457;&#29616;&#24403;&#29992;&#25143;&#26681;&#25454;&#30456;&#20851;&#24615;&#31163;&#24320;&#25490;&#21517;&#26102;&#65292;&#20132;&#38169;&#27604;&#36739;&#27604;A/B&#27979;&#35797;&#26356;&#20026;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2306.10023</link><description>&lt;p&gt;
&#23545;&#20132;&#38169;&#27604;&#36739;&#25928;&#29575;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Theoretical Analysis on the Efficiency of Interleaved Comparisons. (arXiv:2306.10023v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#20132;&#38169;&#27604;&#36739;&#26041;&#27861;&#30340;&#25928;&#29575;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#21457;&#29616;&#24403;&#29992;&#25143;&#26681;&#25454;&#30456;&#20851;&#24615;&#31163;&#24320;&#25490;&#21517;&#26102;&#65292;&#20132;&#38169;&#27604;&#36739;&#27604;A/B&#27979;&#35797;&#26356;&#20026;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#19968;&#31181;&#29992;&#20110;&#25490;&#21517;&#30340;&#39640;&#25928;&#22312;&#32447;&#35780;&#20272;&#26041;&#27861;&#8212;&#8212;&#20132;&#38169;&#27604;&#36739;&#65292;&#36827;&#34892;&#20102;&#25928;&#29575;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#34429;&#28982;&#20132;&#38169;&#27604;&#36739;&#24050;&#32463;&#24212;&#29992;&#20110;&#23454;&#38469;&#31995;&#32479;&#20013;&#65292;&#20294;&#20854;&#39640;&#25928;&#29575;&#30340;&#28304;&#22836;&#22312;&#25991;&#29486;&#20013;&#23578;&#26410;&#24471;&#21040;&#26126;&#30830;&#30340;&#38416;&#36848;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#31867;&#20284;&#20110;&#26222;&#36890;&#20132;&#38169;&#27604;&#36739;&#26041;&#27861;&#30340;&#31616;&#21333;&#20132;&#38169;&#27604;&#36739;&#26041;&#27861;&#65292;&#24182;&#25506;&#32034;&#20102;&#19968;&#31181;&#26465;&#20214;&#65292;&#35813;&#26465;&#20214;&#19979;&#20132;&#38169;&#27604;&#36739;&#26041;&#27861;&#27604;A/B&#27979;&#35797;&#26356;&#26377;&#25928;&#12290;&#20854;&#20013;&#30340;&#26465;&#20214;&#26159;&#65292;&#24403;&#29992;&#25143;&#26681;&#25454;&#29289;&#21697;&#30340;&#30456;&#20851;&#24615;&#26469;&#31163;&#24320;&#25490;&#21517;&#26102;&#65288;&#36825;&#26159;&#28857;&#20987;&#27169;&#22411;&#20013;&#30340;&#19968;&#20010;&#20856;&#22411;&#20551;&#35774;&#65289;&#65292;&#36825;&#31181;&#24773;&#20917;&#23601;&#20250;&#20986;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#22522;&#20110;&#25968;&#20540;&#20998;&#26512;&#21644;&#29992;&#25143;&#27169;&#25311;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#29702;&#35770;&#32467;&#26524;&#19982;&#23454;&#35777;&#32467;&#26524;&#26159;&#19968;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study presents a theoretical analysis on the efficiency of interleaving, an efficient online evaluation method for rankings. Although interleaving has already been applied to production systems, the source of its high efficiency has not been clarified in the literature. Therefore, this study presents a theoretical analysis on the efficiency of interleaving methods. We begin by designing a simple interleaving method similar to ordinary interleaving methods. Then, we explore a condition under which the interleaving method is more efficient than A/B testing and find that this is the case when users leave the ranking depending on the item's relevance, a typical assumption made in click models. Finally, we perform experiments based on numerical analysis and user simulation, demonstrating that the theoretical results are consistent with the empirical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31890;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#38395;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#20998;&#26512;&#26032;&#38395;&#30340;&#29305;&#24615;&#26469;&#25512;&#33616;&#36866;&#24403;&#30340;&#28192;&#36947;&#12290;</title><link>http://arxiv.org/abs/2306.10022</link><description>&lt;p&gt;
&#22522;&#20110;&#31890;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#38395;&#25512;&#33616;&#28192;&#36947;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The News Delivery Channel Recommendation Based on Granular Neural Network. (arXiv:2306.10022v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10022
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31890;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#38395;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#20998;&#26512;&#26032;&#38395;&#30340;&#29305;&#24615;&#26469;&#25512;&#33616;&#36866;&#24403;&#30340;&#28192;&#36947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31070;&#32463;&#32593;&#32476;&#25216;&#26415;&#30340;&#19981;&#26029;&#25104;&#29087;&#21644;&#25193;&#23637;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#21253;&#25324;&#35821;&#38899;&#35782;&#21035;&#12289;&#26426;&#22120;&#32763;&#35793;&#12289;&#22270;&#20687;&#22788;&#29702;&#20197;&#21450;&#25512;&#33616;&#31995;&#32479;&#30340;&#21019;&#24314;&#12290;&#22240;&#27492;&#65292;&#35768;&#22810;&#22797;&#26434;&#30340;&#23454;&#38469;&#38382;&#39064;&#37117;&#21487;&#20197;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#24471;&#21040;&#35299;&#20915;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31890;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#25512;&#33616;&#26032;&#38395;&#21040;&#36866;&#24403;&#30340;&#28192;&#36947;&#30340;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#20998;&#26512;&#26032;&#38395;&#30340;&#29305;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#19968;&#31181;&#29305;&#23450;&#30340;&#31070;&#32463;&#32593;&#32476;&#34987;&#35748;&#20026;&#26159;&#31890;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the continuous maturation and expansion of neural network technology, deep neural networks have been widely utilized as the fundamental building blocks of deep learning in a variety of applications, including speech recognition, machine translation, image processing, and the creation of recommendation systems. Therefore, many real-world complex problems can be solved by the deep learning techniques. As is known, traditional news recommendation systems mostly employ techniques based on collaborative filtering and deep learning, but the performance of these algorithms is constrained by the sparsity of the data and the scalability of the approaches. In this paper, we propose a recommendation model using granular neural network model to recommend news to appropriate channels by analyzing the properties of news. Specifically, a specified neural network serves as the foundation for the granular neural network that the model is considered to be build. Different information granularities 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102; RecFusion&#65292;&#19968;&#31181;&#29305;&#23450;&#38024;&#23545;1D&#21644;/&#25110;&#20108;&#36827;&#21046;&#35774;&#32622;&#30340;&#25512;&#33616;&#27169;&#22411;&#26041;&#27861;&#65292;&#20854;&#21033;&#29992;&#20102;&#20108;&#39033;&#24335;&#25193;&#25955;&#36807;&#31243;&#23545;&#20108;&#20803;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#36827;&#34892;&#26174;&#24335;&#24314;&#27169;&#65292;&#24182;&#22312;&#26680;&#24515;&#25512;&#33616;&#35774;&#32622;&#21644;&#26368;&#24120;&#35265;&#30340;&#25968;&#25454;&#38598;&#19978;&#25509;&#36817;&#22797;&#26434;&#30340;VAE&#22522;&#32447;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.08947</link><description>&lt;p&gt;
RecFusion&#65306;&#22522;&#20110;&#20108;&#39033;&#24335;&#25193;&#25955;&#36807;&#31243;&#30340;1D&#25968;&#25454;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
RecFusion: A Binomial Diffusion Process for 1D Data for Recommendation. (arXiv:2306.08947v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102; RecFusion&#65292;&#19968;&#31181;&#29305;&#23450;&#38024;&#23545;1D&#21644;/&#25110;&#20108;&#36827;&#21046;&#35774;&#32622;&#30340;&#25512;&#33616;&#27169;&#22411;&#26041;&#27861;&#65292;&#20854;&#21033;&#29992;&#20102;&#20108;&#39033;&#24335;&#25193;&#25955;&#36807;&#31243;&#23545;&#20108;&#20803;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#36827;&#34892;&#26174;&#24335;&#24314;&#27169;&#65292;&#24182;&#22312;&#26680;&#24515;&#25512;&#33616;&#35774;&#32622;&#21644;&#26368;&#24120;&#35265;&#30340;&#25968;&#25454;&#38598;&#19978;&#25509;&#36817;&#22797;&#26434;&#30340;VAE&#22522;&#32447;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;RecFusion&#65292;&#36825;&#26159;&#19968;&#32452;&#29992;&#20110;&#25512;&#33616;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;&#19981;&#21516;&#20110;&#21253;&#21547;&#31354;&#38388;&#30456;&#20851;&#24615;&#30340;&#22270;&#20687;&#25968;&#25454;&#65292;&#24120;&#29992;&#20110;&#25512;&#33616;&#30340;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#32570;&#20047;&#29992;&#25143;&#21644;&#39033;&#30446;&#20043;&#38388;&#30340;&#31354;&#38388;&#20851;&#31995;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#19968;&#32500;&#21521;&#37327;&#19978;&#21046;&#23450;&#20102;&#25193;&#25955;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#20108;&#39033;&#24335;&#25193;&#25955;&#65292;&#36825;&#20010;&#26041;&#27861;&#21033;&#29992;&#20102;&#20271;&#21162;&#21033;&#36807;&#31243;&#26174;&#24335;&#22320;&#23545;&#20108;&#20803;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;RecFusion&#22312;&#26680;&#24515;&#25512;&#33616;&#35774;&#32622;&#65288;&#38024;&#23545;&#20108;&#36827;&#21046;&#38750;&#39034;&#24207;&#21453;&#39304;&#30340;&#21069;n&#39033;&#25512;&#33616;&#65289;&#21644;&#26368;&#24120;&#35265;&#30340;&#25968;&#25454;&#38598;&#65288;MovieLens&#21644;Netflix&#65289;&#19978;&#25509;&#36817;&#20110;&#22797;&#26434;&#30340;VAE&#22522;&#32447;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#19987;&#38376;&#38024;&#23545;1D&#21644;/&#25110;&#20108;&#36827;&#21046;&#35774;&#32622;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#24847;&#20041;&#36229;&#20986;&#20102;&#25512;&#33616;&#31995;&#32479;&#65292;&#20363;&#22914;&#22312;&#21307;&#23398;&#39046;&#22495;&#20013;&#20351;&#29992;MRI&#21644;CT&#25195;&#25551;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we propose RecFusion, which comprise a set of diffusion models for recommendation. Unlike image data which contain spatial correlations, a user-item interaction matrix, commonly utilized in recommendation, lacks spatial relationships between users and items. We formulate diffusion on a 1D vector and propose binomial diffusion, which explicitly models binary user-item interactions with a Bernoulli process. We show that RecFusion approaches the performance of complex VAE baselines on the core recommendation setting (top-n recommendation for binary non-sequential feedback) and the most common datasets (MovieLens and Netflix). Our proposed diffusion models that are specialized for 1D and/or binary setups have implications beyond recommendation systems, such as in the medical domain with MRI and CT scans.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#25490;&#24207;&#21644;&#25104;&#32489;&#39044;&#27979;&#30340;&#22810;&#30446;&#26631;&#20989;&#25968;&#65292;&#21487;&#20197;&#22312;&#30495;&#23454;&#24212;&#29992;&#20013;&#26356;&#22909;&#22320;&#24179;&#34913;&#25490;&#24207;&#21644;&#25104;&#32489;&#65292;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08650</link><description>&lt;p&gt;
&#24403;&#35780;&#20998;&#24456;&#37325;&#35201;&#26102;&#30340;&#23398;&#20064;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Learning to Rank when Grades Matter. (arXiv:2306.08650v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#25490;&#24207;&#21644;&#25104;&#32489;&#39044;&#27979;&#30340;&#22810;&#30446;&#26631;&#20989;&#25968;&#65292;&#21487;&#20197;&#22312;&#30495;&#23454;&#24212;&#29992;&#20013;&#26356;&#22909;&#22320;&#24179;&#34913;&#25490;&#24207;&#21644;&#25104;&#32489;&#65292;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#30340;&#23398;&#20064;&#25490;&#24207;&#24212;&#29992;&#20013;&#65292;&#20998;&#32423;&#26631;&#31614;&#24191;&#27867;&#23384;&#22312;&#65292;&#29305;&#21035;&#26159;&#22312;&#20154;&#24037;&#26631;&#27880;&#30340;&#30456;&#20851;&#24615;&#25968;&#25454;&#20013;&#12290;&#20256;&#32479;&#30340;&#23398;&#20064;&#25490;&#24207;&#25216;&#26415;&#26088;&#22312;&#20248;&#21270;&#25991;&#20214;&#30340;&#25490;&#24207;&#39034;&#24207;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#36890;&#24120;&#24573;&#30053;&#20102;&#23454;&#38469;&#20998;&#25968;&#30340;&#39044;&#27979;&#12290;&#36825;&#20351;&#23427;&#20204;&#26080;&#27861;&#22312;&#38656;&#35201;&#32771;&#34385;&#20998;&#25968;&#30340;&#24212;&#29992;&#31243;&#24207;&#20013;&#34987;&#37319;&#29992;&#65292;&#20363;&#22914;&#31579;&#36873;&#8220;&#21155;&#36136;&#8221;&#25991;&#20214;&#12290;&#22312;&#33391;&#22909;&#30340;&#25490;&#24207;&#24615;&#33021;&#21644;&#33391;&#22909;&#30340;&#31561;&#32423;&#39044;&#27979;&#24615;&#33021;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#32463;&#25506;&#32034;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#35201;&#20040;&#21482;&#20851;&#27880;&#25490;&#24207;&#24615;&#33021;&#32780;&#19981;&#26657;&#20934;&#27169;&#22411;&#36755;&#20986;&#65292;&#35201;&#20040;&#23558;&#25104;&#32489;&#35270;&#20026;&#25968;&#20540;&#65292;&#20551;&#35774;&#26631;&#31614;&#22312;&#32447;&#24615;&#33539;&#22260;&#20869;&#65292;&#24182;&#26410;&#21033;&#29992;&#24207;&#25968;&#32423;&#21035;&#20449;&#24687;&#12290;&#26412;&#25991;&#23545;&#23398;&#20064;&#25490;&#24207;&#19982;&#25104;&#32489;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#21516;&#26102;&#37325;&#35270;&#25490;&#24207;&#24615;&#33021;&#21644;&#31561;&#32423;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#20351;&#29992;&#38750;&#26631;&#37327;&#20998;&#32423;&#36827;&#34892;&#25490;&#21517;&#30340;&#24418;&#24335;&#21270;&#35752;&#35770;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#30446;&#26631;&#20989;&#25968;&#65292;&#29992;&#20110;&#32852;&#21512;&#20248;&#21270;&#25490;&#24207;&#21644;&#25104;&#32489;&#39044;&#27979;&#24615;&#33021;&#12290;&#22522;&#20110;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25490;&#24207;&#21644;&#31561;&#32423;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#22343;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graded labels are ubiquitous in real-world learning-to-rank applications, especially in human rated relevance data. Traditional learning-to-rank techniques aim to optimize the ranked order of documents. They typically, however, ignore predicting actual grades. This prevents them from being adopted in applications where grades matter, such as filtering out ``poor'' documents. Achieving both good ranking performance and good grade prediction performance is still an under-explored problem. Existing research either focuses only on ranking performance by not calibrating model outputs, or treats grades as numerical values, assuming labels are on a linear scale and failing to leverage the ordinal grade information. In this paper, we conduct a rigorous study of learning to rank with grades, where both ranking performance and grade prediction performance are important. We provide a formal discussion on how to perform ranking with non-scalar predictions for grades, and propose a multiobjective f
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20221;&#22823;&#35268;&#27169;&#12289;&#30495;&#23454;&#30340;&#25968;&#25454;&#38598;KuaiSAR&#65292;&#35813;&#25968;&#25454;&#38598;&#35760;&#24405;&#20102;&#24555;&#25163;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#20013;&#30495;&#23454;&#30340;&#38598;&#25104;&#25628;&#32034;&#21644;&#25512;&#33616;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.07705</link><description>&lt;p&gt;
KuaiSAR: &#19968;&#20221;&#32479;&#19968;&#30340;&#25628;&#32034;&#19982;&#25512;&#33616;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
KuaiSAR: A Unified Search And Recommendation Dataset. (arXiv:2306.07705v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07705
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20221;&#22823;&#35268;&#27169;&#12289;&#30495;&#23454;&#30340;&#25968;&#25454;&#38598;KuaiSAR&#65292;&#35813;&#25968;&#25454;&#38598;&#35760;&#24405;&#20102;&#24555;&#25163;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#20013;&#30495;&#23454;&#30340;&#38598;&#25104;&#25628;&#32034;&#21644;&#25512;&#33616;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#21644;&#25512;&#33616;&#26381;&#21153;&#30340;&#34701;&#21512;&#26159;&#20687;&#24555;&#25163;&#21644;&#25238;&#38899;&#36825;&#26679;&#30340;&#22312;&#32447;&#20869;&#23481;&#24179;&#21488;&#30340;&#37325;&#35201;&#26041;&#38754;&#12290;S&amp;R&#24314;&#27169;&#30340;&#25972;&#21512;&#26159;&#19994;&#30028;&#23454;&#36341;&#32773;&#37319;&#29992;&#30340;&#39640;&#24230;&#30452;&#35266;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#65292;&#23398;&#26415;&#30028;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#36827;&#34892;&#30340;&#30740;&#31350;&#26126;&#26174;&#19981;&#36275;&#12290;&#22240;&#27492;&#65292;&#22312;&#23398;&#26415;&#30028;&#21644;&#20135;&#19994;&#30028;&#20043;&#38388;&#22312;&#36825;&#20010;&#39046;&#22495;&#36827;&#34892;&#30740;&#31350;&#30340;&#23454;&#36341;&#20043;&#38388;&#20986;&#29616;&#20102;&#23454;&#36136;&#24615;&#30340;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24555;&#25163;&#30340;&#19968;&#20010;&#39046;&#20808;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#25910;&#38598;&#30340;&#38598;&#25104;&#25628;&#32034;&#19982;&#25512;&#33616;&#34892;&#20026;&#30340;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;KuaiSAR&#12290;&#19982;&#20197;&#21069;&#30340;&#25968;&#25454;&#38598;&#19981;&#21516;&#65292;KuaiSAR&#35760;&#24405;&#20102;&#30495;&#23454;&#29992;&#25143;&#30340;&#34892;&#20026;&#65292;&#27599;&#20010;&#34892;&#20026;&#30340;&#21457;&#29983;&#26102;&#38388;&#37117;&#34987;&#31934;&#30830;&#35760;&#24405;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
The confluence of Search and Recommendation services is a vital aspect of online content platforms like Kuaishou and TikTok. The integration of S&amp;R modeling is a highly intuitive approach adopted by industry practitioners. However, there is a noticeable lack of research conducted in this area within the academia, primarily due to the absence of publicly available datasets. Consequently, a substantial gap has emerged between academia and industry regarding research endeavors in this field. To bridge this gap, we introduce the first large-scale, real-world dataset KuaiSAR of integrated Search And Recommendation behaviors collected from Kuaishou, a leading short-video app in China with over 300 million daily active users. Previous research in this field has predominantly employed publicly available datasets that are semi-synthetic and simulated, with artificially fabricated search behaviors. Distinct from previous datasets, KuaiSAR records genuine user behaviors, the occurrence of each in
&lt;/p&gt;</description></item><item><title>&#19968;&#31181;&#21327;&#21516;&#36807;&#28388;&#26032;&#26041;&#27861;&#29992;&#20110;&#31283;&#20581;&#23545;&#35805;&#29702;&#35299;&#65292;&#22312;&#21382;&#21490;&#29992;&#25143;-&#23454;&#20307;&#20132;&#20114;&#30340;&#22522;&#30784;&#19978;&#65292;&#21033;&#29992;&#22810;&#36339;&#23458;&#25143;&#20146;&#21644;&#21147;&#20016;&#23500;&#27599;&#20010;&#29992;&#25143;&#30340;&#32034;&#24341;&#65292;&#24182;&#20351;&#29992;&#26377;&#38480;&#20869;&#23384;BFGS&#31639;&#27861;&#35843;&#25972;&#27599;&#20010;&#32034;&#24341;&#30340;&#26435;&#37325;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#26126;&#26174;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#20010;&#24615;&#21270;&#26597;&#35810;&#37325;&#20889;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.14449</link><description>&lt;p&gt;
&#22270;&#35889;&#36935;&#35265;LLM&#65306;&#19968;&#31181;&#29992;&#20110;&#31283;&#20581;&#23545;&#35805;&#29702;&#35299;&#30340;&#21327;&#21516;&#36807;&#28388;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding. (arXiv:2305.14449v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14449
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#21327;&#21516;&#36807;&#28388;&#26032;&#26041;&#27861;&#29992;&#20110;&#31283;&#20581;&#23545;&#35805;&#29702;&#35299;&#65292;&#22312;&#21382;&#21490;&#29992;&#25143;-&#23454;&#20307;&#20132;&#20114;&#30340;&#22522;&#30784;&#19978;&#65292;&#21033;&#29992;&#22810;&#36339;&#23458;&#25143;&#20146;&#21644;&#21147;&#20016;&#23500;&#27599;&#20010;&#29992;&#25143;&#30340;&#32034;&#24341;&#65292;&#24182;&#20351;&#29992;&#26377;&#38480;&#20869;&#23384;BFGS&#31639;&#27861;&#35843;&#25972;&#27599;&#20010;&#32034;&#24341;&#30340;&#26435;&#37325;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#26126;&#26174;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#20010;&#24615;&#21270;&#26597;&#35810;&#37325;&#20889;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65288;&#20363;&#22914;Alexa&#65292;Siri&#65292;Google Assistant&#31561;&#65289;&#38656;&#35201;&#29702;&#35299;&#23384;&#22312;&#32570;&#38519;&#30340;&#26597;&#35810;&#20197;&#30830;&#20445;&#31283;&#20581;&#30340;&#20250;&#35805;&#29702;&#35299;&#24182;&#20943;&#23569;&#29992;&#25143;&#25705;&#25830;&#12290;&#36825;&#20123;&#26377;&#32570;&#38519;&#30340;&#26597;&#35810;&#36890;&#24120;&#26159;&#30001;&#29992;&#25143;&#30340;&#27495;&#20041;&#21644;&#38169;&#35823;&#65292;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#65288;NLU&#65289;&#20013;&#30340;&#38169;&#35823;&#24341;&#36215;&#30340;&#12290;&#20010;&#24615;&#21270;&#26597;&#35810;&#37325;&#20889;&#65288;&#20010;&#24615;&#21270;QR&#65289;&#26088;&#22312;&#20943;&#23569;&#36523;&#20307;&#21644;&#23614;&#37096;&#29992;&#25143;&#26597;&#35810;&#27969;&#37327;&#20013;&#30340;&#32570;&#38519;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#19982;&#23545;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#36807;&#21435;&#25104;&#21151;&#30340;&#29992;&#25143;&#20132;&#20114;&#30340;&#32034;&#24341;&#12290;&#26412;&#25991;&#25552;&#20986;&#25105;&#20204;&#30340;&#8220;&#21327;&#21516;&#26597;&#35810;&#37325;&#20889;&#8221;&#26041;&#27861;&#65292;&#19987;&#27880;&#20110;&#37325;&#20889;&#29992;&#25143;&#21382;&#21490;&#20013;&#27809;&#26377;&#20986;&#29616;&#36807;&#30340;&#26032;&#22411;&#29992;&#25143;&#20132;&#20114;&#12290;&#35813;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#8220;&#29992;&#25143;&#21453;&#39304;&#20132;&#20114;&#22270;&#8221;&#65288;FIG&#65289;&#65292;&#30001;&#21382;&#21490;&#29992;&#25143;-&#23454;&#20307;&#20132;&#20114;&#32452;&#25104;&#65292;&#24182;&#21033;&#29992;&#22810;&#36339;&#23458;&#25143;&#20146;&#21644;&#21147;&#26469;&#20016;&#23500;&#27599;&#20010;&#29992;&#25143;&#30340;&#32034;&#24341;&#65288;&#21363;&#21327;&#21516;&#29992;&#25143;&#32034;&#24341;&#65289;&#65292;&#20174;&#32780;&#24110;&#21161;&#35206;&#30422;&#26410;&#26469;&#26410;&#26366;&#35265;&#36807;&#30340;&#23384;&#22312;&#32570;&#38519;&#30340;&#26597;&#35810;&#12290;&#20026;&#20102;&#38450;&#27490;&#36825;&#20123;&#26032;&#30340;&#20016;&#23500;&#32034;&#24341;&#34987;&#22122;&#22768;&#21453;&#39304;&#20132;&#20114;&#25152;&#25903;&#37197;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#26377;&#38480;&#20869;&#23384;BFGS&#65288;LLM&#65289;&#31639;&#27861;&#21644;&#22238;&#36864;&#26041;&#26696;&#26469;&#35843;&#25972;&#27599;&#20010;&#32034;&#24341;&#30340;&#26435;&#37325;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#20010;&#24615;&#21270;QR&#26041;&#27861;&#65292;&#24182;&#22312;&#26410;&#30475;&#21040;&#30340;&#29992;&#25143;&#20132;&#20114;&#19978;&#21462;&#24471;&#20102;&#36817;&#20046;&#23436;&#32654;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational AI systems (e.g. Alexa, Siri, Google Assistant, etc.) need to understand queries with defects to ensure robust conversational understanding and reduce user frictions. The defective queries are often induced by user ambiguities and mistakes, or errors in the automatic speech recognition (ASR) and natural language understanding (NLU).  Personalized query rewriting (personalized QR) targets reducing defects in the torso and tail user query traffic, and it typically relies on an index of past successful user interactions with the conversational AI. This paper presents our "Collaborative Query Rewriting" approach that focuses on rewriting novel user interactions unseen in the user history. This approach builds a "user Feedback Interaction Graph" (FIG) consisting of historical user-entity interactions, and leverages multi-hop customer affinity to enrich each user's index (i.e. the Collaborative User Index) that would help cover future unseen defective queries. To counteract th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#30005;&#23376;&#21830;&#21153;&#21644;&#21307;&#30103;&#20445;&#20581;&#31561;&#19987;&#19994;&#39046;&#22495;&#20013;&#65292;&#21033;&#29992;&#24378;&#22823;&#30340;&#27169;&#22411;&#29983;&#25104;&#39640;&#36136;&#37327;&#29305;&#23450;&#20219;&#21153;&#21644;&#39046;&#22495;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#25506;&#32034;&#29992;&#20110;&#39044;&#27979;&#23545;&#25991;&#26723;&#30340;&#26597;&#35810;&#20998;&#32423;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20351;&#29992;&#26080;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#36827;&#19968;&#27493;&#25913;&#36827;&#23545;&#25968;&#25454;&#20013;&#30456;&#20851;&#24615;&#27169;&#24335;&#30340;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.11944</link><description>&lt;p&gt;
&#25506;&#32034;&#29992;&#20110;&#30456;&#20851;&#24615;&#39044;&#27979;&#30340;&#21512;&#25104;&#26597;&#35810;&#29983;&#25104;&#30340;&#21487;&#34892;&#24615;
&lt;/p&gt;
&lt;p&gt;
Exploring the Viability of Synthetic Query Generation for Relevance Prediction. (arXiv:2305.11944v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#30005;&#23376;&#21830;&#21153;&#21644;&#21307;&#30103;&#20445;&#20581;&#31561;&#19987;&#19994;&#39046;&#22495;&#20013;&#65292;&#21033;&#29992;&#24378;&#22823;&#30340;&#27169;&#22411;&#29983;&#25104;&#39640;&#36136;&#37327;&#29305;&#23450;&#20219;&#21153;&#21644;&#39046;&#22495;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#25506;&#32034;&#29992;&#20110;&#39044;&#27979;&#23545;&#25991;&#26723;&#30340;&#26597;&#35810;&#20998;&#32423;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20351;&#29992;&#26080;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#36827;&#19968;&#27493;&#25913;&#36827;&#23545;&#25968;&#25454;&#20013;&#30456;&#20851;&#24615;&#27169;&#24335;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;-&#25991;&#26723;&#30456;&#20851;&#24615;&#39044;&#27979;&#26159;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#36234;&#26469;&#36234;&#22810;&#22320;&#20351;&#29992;&#65288;&#39044;&#20808;&#35757;&#32451;&#30340;&#65289;&#22522;&#20110;&#36716;&#25442;&#22120;&#30340;&#27169;&#22411;&#26469;&#35299;&#20915;&#65292;&#36825;&#20123;&#27169;&#22411;&#20351;&#29992;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292;&#22312;&#30005;&#23376;&#21830;&#21153;&#21644;&#21307;&#30103;&#20445;&#20581;&#31561;&#19987;&#19994;&#39046;&#22495;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21463;&#21040;&#39046;&#22495;&#20869;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#21294;&#20047;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26368;&#36817;&#30340;&#26041;&#27861;&#21033;&#29992;&#36825;&#20123;&#24378;&#22823;&#30340;&#27169;&#22411;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#29305;&#23450;&#20219;&#21153;&#21644;&#39046;&#22495;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20027;&#35201;&#25506;&#32034;&#20102;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#25110;&#29992;&#20110;&#38382;&#31572;&#21644;&#20108;&#20803;&#65288;&#26159;/&#21542;&#65289;&#30456;&#20851;&#24615;&#39044;&#27979;&#30340;&#26597;&#35810;&#29983;&#25104;&#65288;QGen&#65289;, &#20854;&#20013;&#20363;&#22914;&#65292;QGen&#27169;&#22411;&#32473;&#20986;&#19968;&#20010;&#25991;&#26723;&#65292;&#24182;&#35757;&#32451;&#29983;&#25104;&#19968;&#20010;&#19982;&#35813;&#25991;&#26723;&#30456;&#20851;&#30340;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#23545;&#30456;&#20851;&#24615;&#26377;&#19968;&#20010;&#26356;&#32454;&#31890;&#24230;&#30340;&#27010;&#24565;&#65292;&#32780;&#19981;&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#26159;/&#21542;&#26631;&#31614;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#35814;&#32454;&#30340;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;QGen&#26041;&#27861;&#23454;&#29616;&#32454;&#24494;&#30340;&#30456;&#20851;&#24615;&#39044;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#21512;&#25104;&#26597;&#35810;&#26469;&#39044;&#27979;&#23545;&#25991;&#26723;&#30340;&#26597;&#35810;&#20998;&#32423;&#30456;&#20851;&#24615;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25506;&#32034;&#20351;&#29992;&#26080;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#36827;&#19968;&#27493;&#25913;&#36827;&#23545;&#25968;&#25454;&#20013;&#30456;&#20851;&#24615;&#27169;&#24335;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Query-document relevance prediction is a critical problem in Information Retrieval systems. This problem has increasingly been tackled using (pretrained) transformer-based models which are finetuned using large collections of labeled data. However, in specialized domains such as e-commerce and healthcare, the viability of this approach is limited by the dearth of large in-domain data. To address this paucity, recent methods leverage these powerful models to generate high-quality task and domain-specific synthetic data. Prior work has largely explored synthetic data generation or query generation (QGen) for Question-Answering (QA) and binary (yes/no) relevance prediction, where for instance, the QGen models are given a document, and trained to generate a query relevant to that document. However in many problems, we have a more fine-grained notion of relevance than a simple yes/no label. Thus, in this work, we conduct a detailed study into how QGen approaches can be leveraged for nuanced
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#32467;&#21512;k-NN&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#33021;&#22815;&#25552;&#39640;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.09058</link><description>&lt;p&gt;
&#37325;&#35775;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;k-NN
&lt;/p&gt;
&lt;p&gt;
Revisiting k-NN for Pre-trained Language Models. (arXiv:2304.09058v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#32467;&#21512;k-NN&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#33021;&#22815;&#25552;&#39640;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#20316;&#20026;&#21442;&#25968;&#21270;&#30340;&#24613;&#20999;&#23398;&#20064;&#22120;&#65292;&#24050;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24403;&#21069;&#33539;&#24335;&#30340;&#23454;&#38469;&#36873;&#25321;&#12290;&#19982;&#27492;&#24418;&#25104;&#23545;&#27604;&#30340;&#26159;&#65292;k-&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#20998;&#31867;&#22120;&#20316;&#20026;&#24310;&#36831;&#23398;&#20064;&#27169;&#22411;&#65292;&#20542;&#21521;&#20110;&#20943;&#36731;&#36807;&#25311;&#21512;&#21644;&#23396;&#31435;&#22122;&#22768;&#12290;&#26412;&#25991;&#20013;&#25105;&#20204;&#37325;&#35775;&#20102;k-NN&#20998;&#31867;&#22120;&#65292;&#20197;&#22686;&#24378;&#22522;&#20110;PLMs&#30340;&#20998;&#31867;&#22120;&#12290;&#20174;&#26041;&#27861;&#23618;&#38754;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#37319;&#29992;&#25991;&#26412;&#34920;&#31034;&#30340;PLMs&#22312;&#20004;&#20010;&#27493;&#39588;&#20013;&#37319;&#29992;k-NN&#65306;&#65288;1&#65289;&#21033;&#29992;k-NN&#20316;&#20026;&#20808;&#39564;&#30693;&#35782;&#26469;&#26657;&#20934;&#35757;&#32451;&#36807;&#31243;&#65288;2&#65289;&#32447;&#24615;&#25554;&#20540;k-NN&#39044;&#27979;&#30340;&#27010;&#29575;&#20998;&#24067;&#21644;PLMs&#20998;&#31867;&#22120;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26680;&#24515;&#26159;&#23454;&#29616;&#20102;k-NN&#26657;&#20934;&#35757;&#32451;&#65292;&#23558;&#39044;&#27979;&#32467;&#26524;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#20013;&#26131;&#20110;&#21644;&#38590;&#20197;&#23398;&#20064;&#30340;&#31034;&#20363;&#30340;&#25351;&#26631;&#12290;&#20174;&#24212;&#29992;&#22330;&#26223;&#22810;&#26679;&#24615;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#24494;&#35843;&#12289;&#25552;&#31034;&#24494;&#35843;&#33539;&#24335;&#21644;&#38646;&#26679;&#26412;&#20219;&#21153;&#35774;&#32622;&#30340;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#32467;&#21512;k-NN&#21487;&#20197;&#22312;&#25152;&#26377;&#21463;&#21040;&#26816;&#26597;&#30340;&#35774;&#32622;&#20013;&#25345;&#32493;&#25552;&#39640;PLMs&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#25152;&#26377;&#21463;&#21040;&#32771;&#34385;&#30340;&#35774;&#32622;&#20013;&#36305;&#36194;&#20102;&#22522;&#20110;&#26222;&#36890;PLMs&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained Language Models (PLMs), as parametric-based eager learners, have become the de-facto choice for current paradigms of Natural Language Processing (NLP). In contrast, k-Nearest-Neighbor (k-NN) classifiers, as the lazy learning paradigm, tend to mitigate over-fitting and isolated noise. In this paper, we revisit k-NN classifiers for augmenting the PLMs-based classifiers. From the methodological level, we propose to adopt k-NN with textual representations of PLMs in two steps: (1) Utilize k-NN as prior knowledge to calibrate the training process. (2) Linearly interpolate the probability distribution predicted by k-NN with that of the PLMs' classifier. At the heart of our approach is the implementation of k-NN-calibrated training, which treats predicted results as indicators for easy versus hard examples during the training process. From the perspective of the diversity of application scenarios, we conduct extensive experiments on fine-tuning, prompt-tuning paradigms and zero-sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#23884;&#20837;&#24335;&#20559;&#22909;&#27169;&#22411;&#8212;&#8212;Probe&#65292;&#26088;&#22312;&#35299;&#20915;&#29992;&#25143;&#22312;&#26102;&#38388;&#36328;&#24230;&#30340;&#36141;&#29289;&#36873;&#25321;&#20013;&#30340;&#25237;&#24433;&#20559;&#24046;&#21644;&#21442;&#29031;&#28857;&#25928;&#24212;&#65292;&#25552;&#39640;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#21644;&#20010;&#24615;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.06016</link><description>&lt;p&gt;
Probe&#65306;&#23398;&#20064;&#29992;&#25143;&#22312;&#26102;&#38388;&#36328;&#24230;&#30340;&#25414;&#32465;&#36873;&#25321;&#20013;&#30340;&#20010;&#24615;&#21270;&#25237;&#24433;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Probe: Learning Users' Personalized Projection Bias in Intertemporal Bundle Choices. (arXiv:2303.06016v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06016
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#23884;&#20837;&#24335;&#20559;&#22909;&#27169;&#22411;&#8212;&#8212;Probe&#65292;&#26088;&#22312;&#35299;&#20915;&#29992;&#25143;&#22312;&#26102;&#38388;&#36328;&#24230;&#30340;&#36141;&#29289;&#36873;&#25321;&#20013;&#30340;&#25237;&#24433;&#20559;&#24046;&#21644;&#21442;&#29031;&#28857;&#25928;&#24212;&#65292;&#25552;&#39640;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#21644;&#20010;&#24615;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#36328;&#24230;&#30340;&#36873;&#25321;&#38656;&#35201;&#26435;&#34913;&#29616;&#22312;&#30340;&#25104;&#26412;&#21644;&#26410;&#26469;&#30340;&#25910;&#30410;&#12290;&#20854;&#20013;&#19968;&#31181;&#20855;&#20307;&#30340;&#36873;&#25321;&#26159;&#20915;&#23450;&#36141;&#20080;&#21333;&#20010;&#29289;&#21697;&#36824;&#26159;&#36873;&#25321;&#21253;&#21547;&#35813;&#29289;&#21697;&#30340;&#25414;&#32465;&#38144;&#21806;&#26041;&#24335;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#20551;&#35774;&#20010;&#20154;&#23545;&#36825;&#20123;&#36873;&#25321;&#20013;&#28041;&#21450;&#30340;&#22240;&#32032;&#26377;&#20934;&#30830;&#30340;&#26399;&#26395;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#20013;&#65292;&#29992;&#25143;&#23545;&#36825;&#20123;&#22240;&#32032;&#30340;&#24863;&#30693;&#24448;&#24448;&#23384;&#22312;&#20559;&#24046;&#65292;&#23548;&#33268;&#20102;&#38750;&#29702;&#24615;&#21644;&#27425;&#20248;&#30340;&#20915;&#31574;&#12290;&#26412;&#25991;&#37325;&#28857;&#20851;&#27880;&#20004;&#31181;&#24120;&#35265;&#30340;&#20559;&#24046;&#65306;&#25237;&#24433;&#20559;&#24046;&#21644;&#21442;&#29031;&#28857;&#25928;&#24212;&#65292;&#24182;&#20026;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20559;&#24046;&#23884;&#20837;&#24335;&#20559;&#22909;&#27169;&#22411;&#8212;&#8212;Probe&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21152;&#26435;&#20989;&#25968;&#26469;&#25429;&#25417;&#29992;&#25143;&#30340;&#25237;&#24433;&#20559;&#24046;&#65292;&#21033;&#29992;&#20215;&#20540;&#20989;&#25968;&#26469;&#32771;&#34385;&#21442;&#29031;&#28857;&#25928;&#24212;&#65292;&#24182;&#24341;&#20837;&#34892;&#20026;&#32463;&#27982;&#23398;&#20013;&#30340;&#21069;&#26223;&#29702;&#35770;&#26469;&#32452;&#21512;&#21152;&#26435;&#21644;&#20215;&#20540;&#20989;&#25968;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#30830;&#23450;&#29992;&#25143;&#36141;&#20080;&#25414;&#32465;&#38144;&#21806;&#30340;&#27010;&#29575;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#21644;&#20010;&#24615;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intertemporal choices involve making decisions that require weighing the costs in the present against the benefits in the future. One specific type of intertemporal choice is the decision between purchasing an individual item or opting for a bundle that includes that item. Previous research assumes that individuals have accurate expectations of the factors involved in these choices. However, in reality, users' perceptions of these factors are often biased, leading to irrational and suboptimal decision-making. In this work, we specifically focus on two commonly observed biases: projection bias and the reference-point effect. To address these biases, we propose a novel bias-embedded preference model called Probe. The Probe incorporates a weight function to capture users' projection bias and a value function to account for the reference-point effect, and introduce prospect theory from behavioral economics to combine the weight and value functions. This allows us to determine the probabili
&lt;/p&gt;</description></item><item><title>Pacos&#26159;&#19968;&#20010;&#19978;&#19979;&#25991;&#20381;&#36182;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#20559;&#22909;&#36870;&#36716;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#29992;&#25143;&#30340;&#33258;&#36866;&#24212;&#26435;&#37325;&#12289;&#27604;&#36739;&#21644;&#26174;&#31034;&#20301;&#32622;&#31561;&#21487;&#35299;&#37322;&#22240;&#32032;&#65292;&#26377;&#21161;&#20110;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#12290;</title><link>http://arxiv.org/abs/2303.05648</link><description>&lt;p&gt;
Pacos: &#24314;&#27169;&#29992;&#25143;&#30340;&#21487;&#35299;&#37322;&#21644;&#19978;&#19979;&#25991;&#20381;&#36182;&#36873;&#25321;&#20197;&#22788;&#29702;&#20559;&#22909;&#36870;&#36716;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Pacos: Modeling Users' Interpretable and Context-Dependent Choices in Preference Reversals. (arXiv:2303.05648v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05648
&lt;/p&gt;
&lt;p&gt;
Pacos&#26159;&#19968;&#20010;&#19978;&#19979;&#25991;&#20381;&#36182;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#20559;&#22909;&#36870;&#36716;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#29992;&#25143;&#30340;&#33258;&#36866;&#24212;&#26435;&#37325;&#12289;&#27604;&#36739;&#21644;&#26174;&#31034;&#20301;&#32622;&#31561;&#21487;&#35299;&#37322;&#22240;&#32032;&#65292;&#26377;&#21161;&#20110;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36873;&#25321;&#38382;&#39064;&#26159;&#25351;&#20174;&#22810;&#20010;&#39033;&#30446;&#20013;&#36873;&#25321;&#26368;&#20339;&#36873;&#25321;&#65292;&#23398;&#20064;&#29992;&#25143;&#22312;&#36873;&#25321;&#38382;&#39064;&#20013;&#30340;&#20559;&#22909;&#23545;&#20110;&#29702;&#35299;&#20915;&#31574;&#26426;&#21046;&#21644;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#36890;&#24120;&#20551;&#35774;&#20154;&#20204;&#29420;&#31435;&#22320;&#35780;&#20272;&#39033;&#30446;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#20294;&#26159;&#29992;&#25143;&#30340;&#20559;&#22909;&#21462;&#20915;&#20110;&#39033;&#30446;&#25152;&#22788;&#30340;&#24066;&#22330;&#65292;&#36825;&#34987;&#31216;&#20026;&#19978;&#19979;&#25991;&#25928;&#24212;&#65307;&#32780;&#29992;&#25143;&#23545;&#20004;&#20010;&#39033;&#30446;&#30340;&#20559;&#22909;&#39034;&#24207;&#29978;&#33267;&#21487;&#33021;&#34987;&#39072;&#20498;&#65292;&#36825;&#34987;&#31216;&#20026;&#20559;&#22909;&#36870;&#36716;&#12290;&#26412;&#25991;&#35782;&#21035;&#20102;&#23548;&#33268;&#19978;&#19979;&#25991;&#25928;&#24212;&#30340;&#19977;&#20010;&#22240;&#32032;&#65306;&#29992;&#25143;&#30340;&#33258;&#36866;&#24212;&#26435;&#37325;&#12289;&#39033;&#30446;&#20043;&#38388;&#30340;&#27604;&#36739;&#21644;&#26174;&#31034;&#20301;&#32622;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Pacos&#30340;&#19978;&#19979;&#25991;&#20381;&#36182;&#20559;&#22909;&#27169;&#22411;&#20316;&#20026;&#32479;&#19968;&#26694;&#26550;&#26469;&#21516;&#26102;&#35299;&#20915;&#36825;&#19977;&#20010;&#22240;&#32032;&#65292;&#24182;&#32771;&#34385;&#20102;&#20004;&#31181;&#35774;&#35745;&#26041;&#27861;&#65292;&#21253;&#25324;&#20855;&#26377;&#39640;&#21487;&#35299;&#37322;&#24615;&#30340;&#21152;&#24615;&#26041;&#27861;&#21644;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#30340;&#22522;&#20110;ANN&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#21508;&#31181;&#24066;&#22330;&#24773;&#26223;&#21644;&#27169;&#22411;&#21442;&#25968;&#30340;&#20559;&#22909;&#36870;&#36716;&#26465;&#20214;&#65292;&#24182;&#23637;&#31034;&#20102;Pacos&#21487;&#20197;&#26377;&#25928;&#22320;&#25429;&#25417;&#20559;&#22909;&#36870;&#36716;&#12290;&#27492;&#22806;&#65292;Pacos&#21487;&#20197;&#25552;&#20379;&#19978;&#19979;&#25991;&#25928;&#24212;&#21644;&#29992;&#25143;&#33258;&#36866;&#24212;&#34892;&#20026;&#30340;&#21487;&#35299;&#37322;&#25351;&#31034;&#65292;&#26377;&#21161;&#20110;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Choice problems refer to selecting the best choices from several items, and learning users' preferences in choice problems is of great significance in understanding the decision making mechanisms and providing personalized services. Existing works typically assume that people evaluate items independently. In practice, however, users' preferences depend on the market in which items are placed, which is known as context effects; and the order of users' preferences for two items may even be reversed, which is referred to preference reversals. In this work, we identify three factors contributing to context effects: users' adaptive weights, the inter-item comparison, and display positions. We propose a context-dependent preference model named Pacos as a unified framework for addressing three factors simultaneously, and consider two design methods including an additive method with high interpretability and an ANN-based method with high accuracy. We study the conditions for preference reversa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20114;Wasserstein&#36317;&#31163;&#26368;&#23567;&#21270;&#30340;&#26032;&#22411;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;Wasserstein&#36317;&#31163;&#27979;&#37327;&#26469;&#22686;&#24378;&#20114;&#20449;&#24687;&#26368;&#22823;&#21270;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#39034;&#24207;&#25512;&#33616;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.12197</link><description>&lt;p&gt;
&#24207;&#21015;&#25512;&#33616;&#30340;&#20114;Wasserstein&#36317;&#31163;&#26368;&#23567;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mutual Wasserstein Discrepancy Minimization for Sequential Recommendation. (arXiv:2301.12197v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12197
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20114;Wasserstein&#36317;&#31163;&#26368;&#23567;&#21270;&#30340;&#26032;&#22411;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;Wasserstein&#36317;&#31163;&#27979;&#37327;&#26469;&#22686;&#24378;&#20114;&#20449;&#24687;&#26368;&#22823;&#21270;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#39034;&#24207;&#25512;&#33616;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#30340;&#39034;&#24207;&#25512;&#33616;&#36890;&#36807;&#26368;&#22823;&#21270;&#20114;&#20449;&#24687;&#21644;&#35774;&#35745;&#33391;&#22909;&#30340;&#25968;&#25454;&#22686;&#24191;&#26174;&#33879;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;, &#30446;&#21069;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#22522;&#20110;&#35745;&#31639;Kullback Leibler&#24046;&#24322;&#65292;&#24182;&#19988;&#23384;&#22312;&#35768;&#22810;&#23616;&#38480;&#24615;&#65292;&#21253;&#25324;&#38750;&#23545;&#31216;&#20272;&#35745;&#12289;&#25351;&#25968;&#26679;&#26412;&#22823;&#23567;&#38656;&#27714;&#21644;&#35757;&#32451;&#19981;&#31283;&#23450;&#12290;&#32780;&#20351;&#29992;&#30340;&#29616;&#26377;&#25968;&#25454;&#22686;&#24191;&#22823;&#22810;&#26159;&#38543;&#26426;&#30340;&#65292;&#21487;&#33021;&#20250;&#22240;&#20026;&#38543;&#26426;&#20462;&#25913;&#32780;&#30772;&#22351;&#39034;&#24207;&#30456;&#20851;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20114;Wasserstein&#36317;&#31163;&#26368;&#23567;&#21270;&#30340;&#26032;&#22411;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;Wasserstein&#36317;&#31163;&#27979;&#37327;&#26469;&#35780;&#20272;&#22686;&#24191;&#24207;&#21015;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#65292;&#36890;&#36807;&#20943;&#23569;&#21407;&#22987;&#21644;&#22686;&#24191;&#24207;&#21015;&#30340;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#22686;&#24378;&#20114;&#20449;&#24687;&#26368;&#22823;&#21270;&#12290;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#39034;&#24207;&#25512;&#33616;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised sequential recommendation significantly improves recommendation performance by maximizing mutual information with well-designed data augmentations. However, the mutual information estimation is based on the calculation of Kullback Leibler divergence with several limitations, including asymmetrical estimation, the exponential need of the sample size, and training instability. Also, existing data augmentations are mostly stochastic and can potentially break sequential correlations with random modifications. These two issues motivate us to investigate an alternative robust mutual information measurement capable of modeling uncertainty and alleviating KL divergence limitations. To this end, we propose a novel self-supervised learning framework based on Mutual WasserStein discrepancy minimization MStein for the sequential recommendation. We propose the Wasserstein Discrepancy Measurement to measure the mutual information between augmented sequences. Wasserstein Discrepancy M
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MASTER&#30340;&#22810;&#20219;&#21153;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#21033;&#29992;&#29942;&#39048;&#25513;&#34109;&#33258;&#32534;&#30721;&#22120;&#32479;&#19968;&#21508;&#31181;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#24182;&#23558;&#20854;&#38598;&#25104;&#21040;&#19968;&#20010;&#27169;&#22411;&#20013;&#12290;&#35813;&#27169;&#22411;&#22312;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#30456;&#27604;&#21516;&#31561;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#36164;&#28304;&#30340;&#26368;&#20808;&#36827;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#65292;MASTER&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2212.07841</link><description>&lt;p&gt;
MASTER:&#22810;&#20219;&#21153;&#39044;&#35757;&#32451;&#30340;&#29942;&#39048;&#25513;&#34109;&#33258;&#32534;&#30721;&#22120;&#27604;&#23494;&#38598;&#22411;&#26816;&#32034;&#22120;&#26356;&#22909;
&lt;/p&gt;
&lt;p&gt;
MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers. (arXiv:2212.07841v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MASTER&#30340;&#22810;&#20219;&#21153;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#21033;&#29992;&#29942;&#39048;&#25513;&#34109;&#33258;&#32534;&#30721;&#22120;&#32479;&#19968;&#21508;&#31181;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#24182;&#23558;&#20854;&#38598;&#25104;&#21040;&#19968;&#20010;&#27169;&#22411;&#20013;&#12290;&#35813;&#27169;&#22411;&#22312;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#30456;&#27604;&#21516;&#31561;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#36164;&#28304;&#30340;&#26368;&#20808;&#36827;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#65292;MASTER&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#23494;&#38598;&#26816;&#32034;&#26041;&#27861;&#20013;&#65292;&#39044;&#35757;&#32451;&#30340;Transformer&#65288;&#22914;BERT&#65289;&#36890;&#24120;&#29992;&#20110;&#21442;&#25968;&#21021;&#22987;&#21270;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#27491;&#22312;&#25506;&#32034;&#26356;&#26377;&#25928;&#30340;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#23494;&#38598;&#21521;&#37327;&#30340;&#36136;&#37327;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#26032;&#39062;&#32780;&#26377;&#25928;&#30340;&#20219;&#21153;&#65292;&#20294;&#23427;&#20204;&#19981;&#21516;&#30340;&#36755;&#20837;&#26684;&#24335;&#21644;&#23398;&#20064;&#30446;&#26631;&#20351;&#23427;&#20204;&#38590;&#20197;&#34987;&#25972;&#21512;&#36215;&#26469;&#20849;&#21516;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#25991;&#26088;&#22312;&#23558;&#21508;&#31181;&#39044;&#35757;&#32451;&#20219;&#21153;&#32479;&#19968;&#25104;&#29942;&#39048;&#25513;&#34109;&#33258;&#32534;&#30721;&#22120;&#65292;&#23558;&#23427;&#20204;&#25972;&#21512;&#21040;&#19968;&#20010;&#22810;&#20219;&#21153;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#65292;&#21517;&#20026;MASTER&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;MASTER&#21033;&#29992;&#20849;&#20139;&#32534;&#30721;&#22120;&#22810;&#35299;&#30721;&#22120;&#26550;&#26500;&#65292;&#21487;&#20197;&#26500;&#36896;&#34920;&#31034;&#29942;&#39048;&#65292;&#23558;&#36328;&#21508;&#31181;&#20219;&#21153;&#30340;&#20016;&#23500;&#35821;&#20041;&#20449;&#24687;&#21387;&#32553;&#25104;&#23494;&#38598;&#21521;&#37327;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25972;&#21512;&#20102;&#19977;&#31181;&#20195;&#34920;&#24615;&#30340;&#39044;&#35757;&#32451;&#20219;&#21153;&#65306;&#30772;&#25439;&#27573;&#33853;&#24674;&#22797;&#12289;&#30456;&#20851;&#27573;&#33853;&#24674;&#22797;&#21644;PLMs&#36755;&#20986;&#24674;&#22797;&#65292;&#20197;&#21516;&#26102;&#36827;&#34892;&#36716;&#24405;&#12289;&#32034;&#24341;&#21644;QA&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;MASTER&#22312;&#30456;&#21516;&#30340;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#36164;&#28304;&#19979;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#65292;&#34920;&#26126;&#20102;&#23558;&#21508;&#31181;&#39044;&#35757;&#32451;&#20219;&#21153;&#20197;&#32479;&#19968;&#30340;&#26684;&#24335;&#38598;&#25104;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained Transformers (\eg BERT) have been commonly used in existing dense retrieval methods for parameter initialization, and recent studies are exploring more effective pre-training tasks for further improving the quality of dense vectors. Although various novel and effective tasks have been proposed, their different input formats and learning objectives make them hard to be integrated for jointly improving the model performance. In this work, we aim to unify a variety of pre-training tasks into the bottlenecked masked autoencoder manner, and integrate them into a multi-task pre-trained model, namely MASTER. Concretely, MASTER utilizes a shared-encoder multi-decoder architecture that can construct a representation bottleneck to compress the abundant semantic information across tasks into dense vectors. Based on it, we integrate three types of representative pre-training tasks: corrupted passages recovering, related passages recovering and PLMs outputs recovering, to characterize t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26497;&#31616;&#30340;&#25512;&#33616;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;(XSimGCL)&#65292;&#21457;&#29616;&#26377;&#25928;&#20943;&#36731;&#27969;&#34892;&#24230;&#20559;&#35265;&#19982;&#20419;&#36827;&#38271;&#23614;&#29289;&#21697;&#21457;&#29616;&#24182;&#19981;&#38656;&#35201;&#36807;&#22810;&#30340;&#22270;&#24418;&#22686;&#24378;&#12290;</title><link>http://arxiv.org/abs/2209.02544</link><description>&lt;p&gt;
XSimGCL&#65306;&#38754;&#21521;&#26497;&#31616;&#25512;&#33616;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
XSimGCL: Towards Extremely Simple Graph Contrastive Learning for Recommendation. (arXiv:2209.02544v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26497;&#31616;&#30340;&#25512;&#33616;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;(XSimGCL)&#65292;&#21457;&#29616;&#26377;&#25928;&#20943;&#36731;&#27969;&#34892;&#24230;&#20559;&#35265;&#19982;&#20419;&#36827;&#38271;&#23614;&#29289;&#21697;&#21457;&#29616;&#24182;&#19981;&#38656;&#35201;&#36807;&#22810;&#30340;&#22270;&#24418;&#22686;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#27604;&#23398;&#20064;(Contrastive learning, CL)&#22312;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#24615;&#33021;&#26041;&#38754;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#12290;&#22522;&#20110;CL&#30340;&#25512;&#33616;&#27169;&#22411;&#30340;&#21407;&#29702;&#26159;: &#30830;&#20445;&#20174;&#29992;&#25143;-&#29289;&#21697;&#20108;&#20998;&#22270;&#30340;&#19981;&#21516;&#22270;&#24418;&#22686;&#24378;&#20013;&#27966;&#29983;&#30340;&#34920;&#31034;&#19968;&#33268;&#24615;&#12290;&#36825;&#31181;&#33258;&#30417;&#30563;&#26041;&#27861;&#21487;&#20197;&#20174;&#21407;&#22987;&#25968;&#25454;&#20013;&#25552;&#21462;&#36890;&#29992;&#29305;&#24449;&#65292;&#20943;&#36731;&#25968;&#25454;&#31232;&#30095;&#24615;&#30340;&#38382;&#39064;&#12290;&#23613;&#31649;&#36825;&#31181;&#26041;&#27861;&#24456;&#26377;&#25928;&#65292;&#20294;&#26159;&#20854;&#24615;&#33021;&#25552;&#21319;&#30340;&#22240;&#32032;&#23578;&#26410;&#34987;&#23436;&#20840;&#29702;&#35299;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;CL&#23545;&#25512;&#33616;&#30340;&#24433;&#21709;&#30340;&#26032;&#35265;&#35299;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;CL&#20351;&#27169;&#22411;&#23398;&#20064;&#21040;&#26356;&#22343;&#21248;&#20998;&#24067;&#30340;&#29992;&#25143;&#21644;&#29289;&#21697;&#34920;&#31034;&#65292;&#20174;&#32780;&#20943;&#36731;&#20102;&#30427;&#34892;&#30340;&#27969;&#34892;&#24230;&#20559;&#35265;&#65292;&#20419;&#36827;&#20102;&#38271;&#23614;&#29289;&#21697;&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#34920;&#26126;&#65292;&#20043;&#21069;&#35748;&#20026;&#24517;&#19981;&#21487;&#23569;&#30340;&#22270;&#24418;&#22686;&#24378;&#22312;&#22522;&#20110;CL&#30340;&#25512;&#33616;&#20013;&#30456;&#23545;&#19981;&#21487;&#38752;&#19988;&#24433;&#21709;&#26377;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning (CL) has recently been demonstrated critical in improving recommendation performance. The underlying principle of CL-based recommendation models is to ensure the consistency between representations derived from different graph augmentations of the user-item bipartite graph. This self-supervised approach allows for the extraction of general features from raw data, thereby mitigating the issue of data sparsity. Despite the effectiveness of this paradigm, the factors contributing to its performance gains have yet to be fully understood. This paper provides novel insights into the impact of CL on recommendation. Our findings indicate that CL enables the model to learn more evenly distributed user and item representations, which alleviates the prevalent popularity bias and promoting long-tail items. Our analysis also suggests that the graph augmentations, previously considered essential, are relatively unreliable and of limited significance in CL-based recommendation. B
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#20998;&#35010;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;VFed-SSD&#65292;&#29992;&#20110;&#25913;&#21892;&#24191;&#21578;&#27169;&#22411;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#30456;&#20114;&#37325;&#21472;&#30340;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#20998;&#35299;&#32852;&#37030;&#27169;&#22411;&#26469;&#22312;&#27169;&#22411;&#24615;&#33021;&#21644;&#25512;&#29702;&#25928;&#29575;&#20043;&#38388;&#20445;&#25345;&#24179;&#34913;&#12290;&#23454;&#39564;&#32467;&#26524;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#26126;&#65292;VFed-SSD&#30456;&#23545;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#25512;&#29702;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2205.15987</link><description>&lt;p&gt;
VFed-SSD&#65306;&#38754;&#21521;&#23454;&#29992;&#30340;&#22402;&#30452;&#32852;&#37030;&#24191;&#21578;
&lt;/p&gt;
&lt;p&gt;
VFed-SSD: Towards Practical Vertical Federated Advertising. (arXiv:2205.15987v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.15987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#20998;&#35010;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;VFed-SSD&#65292;&#29992;&#20110;&#25913;&#21892;&#24191;&#21578;&#27169;&#22411;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#30456;&#20114;&#37325;&#21472;&#30340;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#20998;&#35299;&#32852;&#37030;&#27169;&#22411;&#26469;&#22312;&#27169;&#22411;&#24615;&#33021;&#21644;&#25512;&#29702;&#25928;&#29575;&#20043;&#38388;&#20445;&#25345;&#24179;&#34913;&#12290;&#23454;&#39564;&#32467;&#26524;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#26126;&#65292;VFed-SSD&#30456;&#23545;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#25512;&#29702;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#23433;&#20840;&#23398;&#20064;&#33539;&#24335;&#65292;&#21033;&#29992;&#36328;&#26426;&#26500;&#31169;&#26377;&#25968;&#25454;&#65292;&#26088;&#22312;&#36890;&#36807;&#21551;&#29992;&#24191;&#21578;&#20027;&#21644;&#21457;&#24067;&#32773;&#31169;&#26377;&#25317;&#26377;&#30340;&#20114;&#34917;&#29992;&#25143;&#23646;&#24615;&#30340;&#32852;&#21512;&#23398;&#20064;&#26469;&#25913;&#36827;&#24191;&#21578;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#23558;&#23427;&#24212;&#29992;&#21040;&#24191;&#21578;&#31995;&#32479;&#26102;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#65306;a&#65289;&#26631;&#35760;&#37325;&#21472;&#26679;&#26412;&#30340;&#26377;&#38480;&#35268;&#27169;&#65292;&#20197;&#21450;b&#65289;&#23454;&#26102;&#36328;&#26426;&#26500;&#26381;&#21153;&#30340;&#39640;&#25104;&#26412;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20004;&#20010;&#38480;&#21046;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#20998;&#35010;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;VFed-SSD&#12290;&#25105;&#20204;&#35748;&#20026;&#65306;i&#65289;&#22312;&#24191;&#21578;&#31995;&#32479;&#20013;&#26377;&#22823;&#37327;&#26410;&#26631;&#35760;&#30340;&#37325;&#21472;&#25968;&#25454;&#21487;&#29992;&#65292;ii&#65289;&#36890;&#36807;&#20998;&#35299;&#32852;&#37030;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#27169;&#22411;&#24615;&#33021;&#21644;&#25512;&#29702;&#25104;&#26412;&#20043;&#38388;&#20445;&#25345;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
As an emerging secure learning paradigm in lever-aging cross-agency private data, vertical federatedlearning (VFL) is expected to improve advertising models by enabling the joint learning of complementary user attributes privately owned by the advertiser and the publisher. However, there are two key challenges in applying it to advertising systems: a) the limited scale of labeled overlapping samples, and b) the high cost of real-time cross-agency serving. In this paper, we propose a semi-supervised split distillation framework VFed-SSD to alleviate the two limitations. We identify that: i)there are massive unlabeled overlapped data available in advertising systems, and ii) we can keep a balance between model performance and inference cost by decomposing the federated model. Specifically, we develop a self-supervised task MatchedPair Detection (MPD) to exploit the vertically partitioned unlabeled data and propose the Split Knowledge Distillation (SplitKD) schema to avoid cross-agency se
&lt;/p&gt;</description></item></channel></rss>