<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#30340;&#31471;&#21040;&#31471;&#19979;&#19968;&#20301;&#32622;&#25512;&#33616;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21253;&#25324;&#21382;&#21490;&#32534;&#30721;&#22120;&#12289;&#26597;&#35810;&#29983;&#25104;&#22120;&#21644;&#20559;&#22909;&#35299;&#30721;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#21040;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#20559;&#22909;&#24182;&#23454;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2303.12507</link><description>&lt;p&gt;
&#22522;&#20110;&#23545;&#27604;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#30340;&#31471;&#21040;&#31471;&#20010;&#24615;&#21270;&#19979;&#19968;&#20301;&#32622;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
End-to-End Personalized Next Location Recommendation via Contrastive User Preference Modeling. (arXiv:2303.12507v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12507
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#30340;&#31471;&#21040;&#31471;&#19979;&#19968;&#20301;&#32622;&#25512;&#33616;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21253;&#25324;&#21382;&#21490;&#32534;&#30721;&#22120;&#12289;&#26597;&#35810;&#29983;&#25104;&#22120;&#21644;&#20559;&#22909;&#35299;&#30721;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#21040;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#20559;&#22909;&#24182;&#23454;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#22522;&#20110;&#22320;&#29702;&#20301;&#32622;&#30340;&#26381;&#21153;&#22914;&#30446;&#30340;&#22320;&#39044;&#27979;&#21644;&#36335;&#32447;&#35268;&#21010;&#20013;&#65292;&#39044;&#27979;&#19979;&#19968;&#20010;&#20301;&#32622;&#26159;&#19968;&#39033;&#38750;&#24120;&#26377;&#20215;&#20540;&#21644;&#24120;&#35265;&#30340;&#38656;&#27714;&#12290;&#19979;&#19968;&#20010;&#20301;&#32622;&#25512;&#33616;&#30340;&#30446;&#26631;&#26159;&#26681;&#25454;&#29992;&#25143;&#30340;&#21382;&#21490;&#36712;&#36857;&#39044;&#27979;&#29992;&#25143;&#23558;&#35201;&#21435;&#30340;&#19979;&#19968;&#20010;&#20852;&#36259;&#28857;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#27169;&#22411;&#20165;&#20174;&#29992;&#25143;&#30340;&#21382;&#21490;&#31614;&#21040;&#24207;&#21015;&#20013;&#23398;&#20064;&#31227;&#21160;&#27169;&#24335;&#65292;&#32780;&#24573;&#35270;&#20102;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#30340;&#37325;&#35201;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; POIFormer &#27169;&#22411;&#26469;&#36827;&#34892;&#31471;&#21040;&#31471;&#19979;&#19968;&#20301;&#32622;&#25512;&#33616;&#65292;&#20854;&#20013;&#21253;&#25324;&#23545;&#27604;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#12290;&#35813;&#27169;&#22411;&#30001;&#19977;&#20010;&#20027;&#35201;&#27169;&#22359;&#32452;&#25104;&#65306;&#21382;&#21490;&#32534;&#30721;&#22120;&#12289;&#26597;&#35810;&#29983;&#25104;&#22120;&#21644;&#20559;&#22909;&#35299;&#30721;&#22120;&#12290;&#21382;&#21490;&#32534;&#30721;&#22120;&#26088;&#22312;&#20174;&#21382;&#21490;&#31614;&#21040;&#24207;&#21015;&#20013;&#24314;&#27169;&#31227;&#21160;&#27169;&#24335;&#65292;&#32780;&#26597;&#35810;&#29983;&#25104;&#22120;&#26126;&#30830;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#20197;&#29983;&#25104;&#29992;&#25143;&#29305;&#23450;&#30340;&#24847;&#22270;&#26597;&#35810;&#12290;&#26368;&#21518;&#65292;&#20559;&#22909;&#35299;&#30721;&#22120;&#23558;&#24847;&#22270;&#26597;&#35810;&#21644;&#21382;&#21490;&#20449;&#24687;&#32452;&#21512;&#36215;&#26469;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#24182;&#26377;&#25928;&#22320;&#25429;&#25417;&#21040;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting the next location is a highly valuable and common need in many location-based services such as destination prediction and route planning. The goal of next location recommendation is to predict the next point-of-interest a user might go to based on the user's historical trajectory. Most existing models learn mobility patterns merely from users' historical check-in sequences while overlooking the significance of user preference modeling. In this work, a novel Point-of-Interest Transformer (POIFormer) with contrastive user preference modeling is developed for end-to-end next location recommendation. This model consists of three major modules: history encoder, query generator, and preference decoder. History encoder is designed to model mobility patterns from historical check-in sequences, while query generator explicitly learns user preferences to generate user-specific intention queries. Finally, preference decoder combines the intention queries and historical information to p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#32534;&#30721;&#22120;&#30340;&#26597;&#35810;-FAQ&#21305;&#37197;&#27169;&#22411;&#65292;&#31216;&#20026;MFBE&#65292;&#21033;&#29992;FAQ&#30340;&#22810;&#20010;&#39046;&#22495;&#32452;&#21512;&#65292;&#22312;&#27169;&#22411;&#35757;&#32451;&#21644;&#25512;&#29702;&#36807;&#31243;&#20013;&#33719;&#30410;&#65292;&#35299;&#20915;&#20102;&#35832;&#22914;&#22266;&#26377;&#35789;&#27719;&#24046;&#36317;&#12289;FAQ&#26631;&#39064;&#20013;&#32570;&#20047;&#36275;&#22815;&#30340;&#19978;&#19979;&#25991;&#31561;&#38382;&#39064;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.11953</link><description>&lt;p&gt;
MFBE&#65306;&#21033;&#29992;FAQ&#30340;&#22810;&#39046;&#22495;&#20449;&#24687;&#36827;&#34892;&#39640;&#25928;&#23494;&#38598;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
MFBE: Leveraging Multi-Field Information of FAQs for Efficient Dense Retrieval. (arXiv:2302.11953v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11953
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#32534;&#30721;&#22120;&#30340;&#26597;&#35810;-FAQ&#21305;&#37197;&#27169;&#22411;&#65292;&#31216;&#20026;MFBE&#65292;&#21033;&#29992;FAQ&#30340;&#22810;&#20010;&#39046;&#22495;&#32452;&#21512;&#65292;&#22312;&#27169;&#22411;&#35757;&#32451;&#21644;&#25512;&#29702;&#36807;&#31243;&#20013;&#33719;&#30410;&#65292;&#35299;&#20915;&#20102;&#35832;&#22914;&#22266;&#26377;&#35789;&#27719;&#24046;&#36317;&#12289;FAQ&#26631;&#39064;&#20013;&#32570;&#20047;&#36275;&#22815;&#30340;&#19978;&#19979;&#25991;&#31561;&#38382;&#39064;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#38382;&#31572;&#39046;&#22495;&#20013;&#65292;&#39057;&#32321;&#35810;&#38382;&#38382;&#39064;&#65288;FAQ&#65289;&#30340;&#26816;&#32034;&#26159;&#19968;&#20010;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#37325;&#35201;&#23376;&#39046;&#22495;&#12290;&#36825;&#37324;&#65292;&#22312;&#22238;&#24212;&#29992;&#25143;&#26597;&#35810;&#26102;&#65292;&#26816;&#32034;&#31995;&#32479;&#36890;&#24120;&#20250;&#20174;&#30693;&#35782;&#24211;&#36820;&#22238;&#30456;&#20851;&#30340;FAQ&#12290;&#36825;&#31181;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#20854;&#22312;&#23454;&#26102;&#24314;&#31435;&#26597;&#35810;&#21644;FAQ&#20043;&#38388;&#30340;&#35821;&#20041;&#21305;&#37197;&#30340;&#33021;&#21147;&#12290;&#30001;&#20110;&#26597;&#35810;&#21644;FAQ&#20043;&#38388;&#30340;&#22266;&#26377;&#35789;&#27719;&#24046;&#36317;&#65292;FAQ&#26631;&#39064;&#20013;&#32570;&#20047;&#36275;&#22815;&#30340;&#19978;&#19979;&#25991;&#65292;&#26631;&#35760;&#25968;&#25454;&#31232;&#32570;&#21644;&#39640;&#26816;&#32034;&#24310;&#36831;&#65292;&#36825;&#39033;&#20219;&#21153;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#32534;&#30721;&#22120;&#30340;&#26597;&#35810;-FAQ&#21305;&#37197;&#27169;&#22411;&#65292;&#23427;&#22312;&#27169;&#22411;&#35757;&#32451;&#21644;&#25512;&#29702;&#36807;&#31243;&#20013;&#21033;&#29992;FAQ&#30340;&#22810;&#20010;&#39046;&#22495;&#32452;&#21512;&#65288;&#22914;&#38382;&#39064;&#12289;&#31572;&#26696;&#21644;&#31867;&#21035;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#22810;&#39046;&#22495;&#21452;&#32534;&#30721;&#22120;&#65288;MFBE&#65289;&#27169;&#22411;&#20174;&#22810;&#20010;FAQ&#39046;&#22495;&#30340;&#39069;&#22806;&#19978;&#19979;&#25991;&#20013;&#33719;&#30410;&#65292;&#24182;&#19988;&#21363;&#20351;&#21482;&#26377;&#24456;&#23569;&#30340;&#26631;&#35760;&#25968;&#25454;&#20063;&#34920;&#29616;&#20986;&#33394;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the domain of question-answering in NLP, the retrieval of Frequently Asked Questions (FAQ) is an important sub-area which is well researched and has been worked upon for many languages. Here, in response to a user query, a retrieval system typically returns the relevant FAQs from a knowledge-base. The efficacy of such a system depends on its ability to establish semantic match between the query and the FAQs in real-time. The task becomes challenging due to the inherent lexical gap between queries and FAQs, lack of sufficient context in FAQ titles, scarcity of labeled data and high retrieval latency. In this work, we propose a bi-encoder-based query-FAQ matching model that leverages multiple combinations of FAQ fields (like, question, answer, and category) both during model training and inference. Our proposed Multi-Field Bi-Encoder (MFBE) model benefits from the additional context resulting from multiple FAQ fields and performs well even with minimal labeled data. We empirically sup
&lt;/p&gt;</description></item></channel></rss>