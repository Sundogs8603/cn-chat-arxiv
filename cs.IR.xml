<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30334;&#19975;&#32423;&#21035;&#21160;&#20316;&#31354;&#38388;&#38382;&#39064;&#19978;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.01566</link><description>&lt;p&gt;
&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#65306;&#36229;&#36234;Plackett-Luce
&lt;/p&gt;
&lt;p&gt;
Fast Slate Policy Optimization: Going Beyond Plackett-Luce. (arXiv:2308.01566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;Slate&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30334;&#19975;&#32423;&#21035;&#21160;&#20316;&#31354;&#38388;&#38382;&#39064;&#19978;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#19968;&#20010;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#26500;&#24314;&#27169;&#22359;&#26159;&#36820;&#22238;Slate&#65292;&#21363;&#32473;&#23450;&#19968;&#20010;&#26597;&#35810;&#36820;&#22238;&#26377;&#24207;&#30340;&#39033;&#30446;&#21015;&#34920;&#12290;&#35813;&#25216;&#26415;&#30340;&#24212;&#29992;&#21253;&#25324;&#25628;&#32034;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#12290;&#24403;&#34892;&#21160;&#31354;&#38388;&#24456;&#22823;&#26102;&#65292;&#20915;&#31574;&#31995;&#32479;&#20250;&#38480;&#21046;&#22312;&#29305;&#23450;&#32467;&#26500;&#20013;&#20197;&#24555;&#36895;&#23436;&#25104;&#22312;&#32447;&#26597;&#35810;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#36825;&#20123;&#22823;&#35268;&#27169;&#20915;&#31574;&#31995;&#32479;&#22312;&#32473;&#23450;&#20219;&#24847;&#22870;&#21169;&#20989;&#25968;&#19979;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#23398;&#20064;&#38382;&#39064;&#36716;&#21270;&#20026;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#31867;&#65292;&#23427;&#28304;&#20110;&#20915;&#31574;&#20989;&#25968;&#30340;&#19968;&#31181;&#26032;&#39062;&#25918;&#26494;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#30340;&#21160;&#20316;&#31354;&#38388;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#24120;&#29992;&#30340;Plackett-Luce&#31574;&#30053;&#31867;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21160;&#20316;&#31354;&#38388;&#22823;&#23567;&#36798;&#21040;&#30334;&#19975;&#32423;&#21035;&#30340;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
An increasingly important building block of large scale machine learning systems is based on returning slates; an ordered lists of items given a query. Applications of this technology include: search, information retrieval and recommender systems. When the action space is large, decision systems are restricted to a particular structure to complete online queries quickly. This paper addresses the optimization of these large scale decision systems given an arbitrary reward function. We cast this learning problem in a policy optimization framework and propose a new class of policies, born from a novel relaxation of decision functions. This results in a simple, yet efficient learning algorithm that scales to massive action spaces. We compare our method to the commonly adopted Plackett-Luce policy class and demonstrate the effectiveness of our approach on problems with action space sizes in the order of millions.
&lt;/p&gt;</description></item></channel></rss>