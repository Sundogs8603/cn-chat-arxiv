<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#37325;&#23545;&#27604;&#32593;&#32476;&#65288;DCN&#65289;&#65292;&#36890;&#36807;&#20004;&#20010;&#32452;&#20214;&#20805;&#20998;&#21033;&#29992;&#20102;&#29992;&#25143;&#21644;&#29289;&#21697;&#20004;&#20010;&#35270;&#35282;&#65292;&#20197;&#29983;&#25104;&#22320;&#38754;&#30495;&#23454;&#30340;&#33258;&#30417;&#30563;&#20449;&#21495;&#65292;&#35299;&#20915;&#20102;&#38543;&#26426;&#23631;&#34109;&#21382;&#21490;&#29289;&#21697;&#24102;&#26469;&#30340;&#24207;&#21015;&#31232;&#30095;&#24615;&#21644;&#19981;&#21487;&#38752;&#20449;&#21495;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#32437;&#21521;&#25512;&#33616;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2209.08446</link><description>&lt;p&gt;
&#32437;&#21521;&#25512;&#33616;&#20013;&#29992;&#25143;&#21644;&#29289;&#21697;&#35270;&#35282;&#30340;&#21452;&#37325;&#23545;&#27604;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Dual Contrastive Network for Sequential Recommendation with User and Item-Centric Perspectives. (arXiv:2209.08446v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.08446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#37325;&#23545;&#27604;&#32593;&#32476;&#65288;DCN&#65289;&#65292;&#36890;&#36807;&#20004;&#20010;&#32452;&#20214;&#20805;&#20998;&#21033;&#29992;&#20102;&#29992;&#25143;&#21644;&#29289;&#21697;&#20004;&#20010;&#35270;&#35282;&#65292;&#20197;&#29983;&#25104;&#22320;&#38754;&#30495;&#23454;&#30340;&#33258;&#30417;&#30563;&#20449;&#21495;&#65292;&#35299;&#20915;&#20102;&#38543;&#26426;&#23631;&#34109;&#21382;&#21490;&#29289;&#21697;&#24102;&#26469;&#30340;&#24207;&#21015;&#31232;&#30095;&#24615;&#21644;&#19981;&#21487;&#38752;&#20449;&#21495;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#32437;&#21521;&#25512;&#33616;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#27969;&#23186;&#20307;&#25968;&#25454;&#30340;&#29190;&#21457;&#65292;&#32437;&#21521;&#25512;&#33616;&#25104;&#20026;&#23454;&#29616;&#26102;&#38388;&#24863;&#30693;&#20010;&#24615;&#21270;&#24314;&#27169;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#37325;&#23545;&#27604;&#32593;&#32476;&#65288;DCN&#65289;&#65292;&#36890;&#36807;&#20004;&#20010;&#32452;&#20214;&#8212;&#8212;&#22522;&#20110;&#29992;&#25143;&#30340;&#23545;&#27604;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#21697;&#30340;&#23545;&#27604;&#23398;&#20064;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#29992;&#25143;&#21644;&#29289;&#21697;&#20004;&#20010;&#35270;&#35282;&#65292;&#20197;&#29983;&#25104;&#22320;&#38754;&#30495;&#23454;&#30340;&#33258;&#30417;&#30563;&#20449;&#21495;&#65292;&#35299;&#20915;&#20102;&#38543;&#26426;&#23631;&#34109;&#21382;&#21490;&#29289;&#21697;&#24102;&#26469;&#30340;&#24207;&#21015;&#31232;&#30095;&#24615;&#21644;&#19981;&#21487;&#38752;&#20449;&#21495;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#32437;&#21521;&#25512;&#33616;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the outbreak of today's streaming data, the sequential recommendation is a promising solution to achieve time-aware personalized modeling. It aims to infer the next interacted item of a given user based on the history item sequence. Some recent works tend to improve the sequential recommendation via random masking on the history item so as to generate self-supervised signals. But such approaches will indeed result in sparser item sequence and unreliable signals. Besides, the existing sequential recommendation models are only user-centric, i.e., based on the historical items by chronological order to predict the probability of candidate items, which ignores whether the items from a provider can be successfully recommended. Such user-centric recommendation will make it impossible for the provider to expose their new items and result in popular bias.  In this paper, we propose a novel Dual Contrastive Network (DCN) to generate ground-truth self-supervised signals for sequential recom
&lt;/p&gt;</description></item><item><title>SpaDE &#26159;&#19968;&#31181;&#21033;&#29992;&#21452;&#37325;&#32534;&#30721;&#22120;&#23398;&#20064;&#25991;&#26723;&#34920;&#31034;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#25913;&#21892;&#35789;&#27719;&#21305;&#37197;&#21644;&#25193;&#23637;&#39069;&#22806;&#26415;&#35821;&#26469;&#25903;&#25345;&#35821;&#20041;&#21305;&#37197;&#65292;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2209.05917</link><description>&lt;p&gt;
SpaDE: &#19968;&#31181;&#21033;&#29992;&#21452;&#37325;&#25991;&#26723;&#32534;&#30721;&#22120;&#25913;&#21892;&#31232;&#30095;&#34920;&#31034;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval. (arXiv:2209.05917v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.05917
&lt;/p&gt;
&lt;p&gt;
SpaDE &#26159;&#19968;&#31181;&#21033;&#29992;&#21452;&#37325;&#32534;&#30721;&#22120;&#23398;&#20064;&#25991;&#26723;&#34920;&#31034;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#25913;&#21892;&#35789;&#27719;&#21305;&#37197;&#21644;&#25193;&#23637;&#39069;&#22806;&#26415;&#35821;&#26469;&#25903;&#25345;&#35821;&#20041;&#21305;&#37197;&#65292;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#30340;&#25991;&#26723;&#34920;&#31034;&#32463;&#24120;&#34987;&#29992;&#26469;&#36890;&#36807;&#31934;&#30830;&#30340;&#35789;&#27719;&#21305;&#37197;&#26469;&#26816;&#32034;&#30456;&#20851;&#25991;&#26723;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39044;&#20808;&#35745;&#31639;&#30340;&#20498;&#25490;&#32034;&#24341;&#65292;&#20250;&#24341;&#21457;&#35789;&#27719;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;&#26368;&#36817;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#38656;&#35201;&#26114;&#36149;&#30340;&#26597;&#35810;&#25512;&#29702;&#25104;&#26412;&#65292;&#36825;&#24847;&#21619;&#30528;&#25928;&#29575;&#21644;&#25928;&#26524;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21333;&#32534;&#30721;&#22120;&#25490;&#21517;&#27169;&#22411;&#65292;&#21033;&#29992;&#21452;&#37325;&#32534;&#30721;&#22120;&#23398;&#20064;&#25991;&#26723;&#34920;&#31034;&#65292;&#31216;&#20026; Sparse retriever using a Dual document Encoder (SpaDE)&#12290;&#27599;&#20010;&#32534;&#30721;&#22120;&#22312;&#25913;&#21892;&#35789;&#27719;&#21305;&#37197;&#21644;&#25193;&#23637;&#39069;&#22806;&#26415;&#35821;&#26469;&#25903;&#25345;&#35821;&#20041;&#21305;&#37197;&#26041;&#38754;&#21457;&#25381;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#21327;&#21516;&#35757;&#32451;&#31574;&#30053;&#21487;&#20197;&#26377;&#25928;&#22320;&#35757;&#32451;&#21452;&#37325;&#32534;&#30721;&#22120;&#65292;&#24182;&#36991;&#20813;&#19981;&#24517;&#35201;&#30340;&#24178;&#39044;&#24444;&#27492;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SpaDE &#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#26816;&#32034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse document representations have been widely used to retrieve relevant documents via exact lexical matching. Owing to the pre-computed inverted index, it supports fast ad-hoc search but incurs the vocabulary mismatch problem. Although recent neural ranking models using pre-trained language models can address this problem, they usually require expensive query inference costs, implying the trade-off between effectiveness and efficiency. Tackling the trade-off, we propose a novel uni-encoder ranking model, Sparse retriever using a Dual document Encoder (SpaDE), learning document representation via the dual encoder. Each encoder plays a central role in (i) adjusting the importance of terms to improve lexical matching and (ii) expanding additional terms to support semantic matching. Furthermore, our co-training strategy trains the dual encoder effectively and avoids unnecessary intervention in training each other. Experimental results on several benchmarks show that SpaDE outperforms ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#26041;&#27861;&#26469;&#35299;&#20915;&#30697;&#38453;&#21644;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#20445;&#30041;&#21333;&#20301;&#27604;&#20363;&#21644;&#19968;&#33268;&#24615;&#20004;&#20010;&#32422;&#26463;&#26465;&#20214;&#21487;&#20197;&#23454;&#29616;&#35299;&#30340;&#23384;&#22312;&#24615;&#19982;&#21807;&#19968;&#24615;&#12290;</title><link>http://arxiv.org/abs/2204.01815</link><description>&lt;p&gt;
&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#19968;&#33268;&#24615;&#21644;&#20844;&#24179;&#20445;&#35777;&#30340;&#25512;&#33616;&#31995;&#32479;&#24352;&#37327;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Tensor Completion with Provable Consistency and Fairness Guarantees for Recommender Systems. (arXiv:2204.01815v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.01815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#26041;&#27861;&#26469;&#35299;&#20915;&#30697;&#38453;&#21644;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#20445;&#30041;&#21333;&#20301;&#27604;&#20363;&#21644;&#19968;&#33268;&#24615;&#20004;&#20010;&#32422;&#26463;&#26465;&#20214;&#21487;&#20197;&#23454;&#29616;&#35299;&#30340;&#23384;&#22312;&#24615;&#19982;&#21807;&#19968;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#19968;&#33268;&#24615;&#30340;&#26041;&#27861;&#26469;&#23450;&#20041;&#21644;&#35299;&#20915;&#38750;&#36127;/&#27491;&#30697;&#38453;&#21644;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#30340;&#26032;&#39062;&#20043;&#22788;&#22312;&#20110;&#65292;&#25105;&#20204;&#19981;&#26159;&#20154;&#20026;&#22320;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#20219;&#24847;&#20248;&#21270;&#38382;&#39064;&#65292;&#20363;&#22914;&#65292;&#26368;&#23567;&#21270;&#19968;&#20010;&#32467;&#26500;&#37327;&#65292;&#22914;&#31209;&#25110;&#33539;&#25968;&#65292;&#32780;&#26159;&#23637;&#31034;&#20102;&#19968;&#20010;&#21333;&#19968;&#30340;&#23646;&#24615;/&#32422;&#26463;&#65306;&#20445;&#30041;&#21333;&#20301;&#27604;&#20363;&#19968;&#33268;&#24615;&#65292;&#20445;&#35777;&#20102;&#35299;&#30340;&#23384;&#22312;&#65292;&#24182;&#22312;&#30456;&#23545;&#36739;&#24369;&#30340;&#25903;&#25345;&#20551;&#35774;&#19979;&#20445;&#35777;&#20102;&#35299;&#30340;&#21807;&#19968;&#24615;&#12290;&#35813;&#26694;&#26550;&#21644;&#35299;&#31639;&#27861;&#20063;&#30452;&#25509;&#25512;&#24191;&#21040;&#20219;&#24847;&#32500;&#24230;&#30340;&#24352;&#37327;&#20013;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#22266;&#23450;&#32500;&#24230; d &#30340;&#38382;&#39064;&#35268;&#27169;&#30340;&#32447;&#24615;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#22312;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20004;&#20010;&#21512;&#29702;&#30340;&#24615;&#36136;&#65292;&#36825;&#20123;&#24615;&#36136;&#24212;&#35813;&#36866;&#29992;&#20110;&#20219;&#20309; RS &#38382;&#39064;&#30340;&#35299;&#65292;&#36275;&#20197;&#20801;&#35768;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20869;&#24314;&#31435;&#21807;&#19968;&#24615;&#20445;&#35777;&#12290;&#20851;&#38190;&#29702;&#35770;&#36129;&#29486;&#26159;&#23637;&#31034;&#20102;&#36825;&#20123;&#32422;&#26463;&#19979;&#35299;&#30340;&#23384;&#22312;&#24615;&#19982;&#21807;&#19968;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new consistency-based approach for defining and solving nonnegative/positive matrix and tensor completion problems. The novelty of the framework is that instead of artificially making the problem well-posed in the form of an application-arbitrary optimization problem, e.g., minimizing a bulk structural measure such as rank or norm, we show that a single property/constraint: preserving unit-scale consistency, guarantees the existence of both a solution and, under relatively weak support assumptions, uniqueness. The framework and solution algorithms also generalize directly to tensors of arbitrary dimensions while maintaining computational complexity that is linear in problem size for fixed dimension d. In the context of recommender system (RS) applications, we prove that two reasonable properties that should be expected to hold for any solution to the RS problem are sufficient to permit uniqueness guarantees to be established within our framework. Key theoretical contribu
&lt;/p&gt;</description></item></channel></rss>