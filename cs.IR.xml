<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#21033;&#29992;&#29992;&#25143;&#35780;&#35770;&#21644;&#30456;&#20851;&#39033;&#30446;&#29305;&#24449;&#29983;&#25104;&#23545;&#27604;&#35780;&#20215;&#21477;&#23376;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#25214;&#21040;&#26368;&#36866;&#21512;&#30340;&#20135;&#21697;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#39033;&#30446;&#32534;&#30721;&#27169;&#22359;&#12289;&#27604;&#36739;&#29983;&#25104;&#27169;&#22359;&#21644;&#20010;&#24615;&#21270;&#35299;&#30721;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#39564;&#35777;&#20102;&#29983;&#25104;&#21477;&#23376;&#30340;&#30456;&#20851;&#24615;&#21644;&#30495;&#23454;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.03691</link><description>&lt;p&gt;
&#23558;&#33529;&#26524;&#19982;&#33529;&#26524;&#36827;&#34892;&#27604;&#36739;&#65306;&#20174;&#29992;&#25143;&#35780;&#35770;&#29983;&#25104;&#32437;&#21521;&#24863;&#30693;&#30340;&#27604;&#36739;&#21477;&#23376;
&lt;/p&gt;
&lt;p&gt;
Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review. (arXiv:2307.03691v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03691
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#21033;&#29992;&#29992;&#25143;&#35780;&#35770;&#21644;&#30456;&#20851;&#39033;&#30446;&#29305;&#24449;&#29983;&#25104;&#23545;&#27604;&#35780;&#20215;&#21477;&#23376;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#25214;&#21040;&#26368;&#36866;&#21512;&#30340;&#20135;&#21697;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#39033;&#30446;&#32534;&#30721;&#27169;&#22359;&#12289;&#27604;&#36739;&#29983;&#25104;&#27169;&#22359;&#21644;&#20010;&#24615;&#21270;&#35299;&#30721;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#39564;&#35777;&#20102;&#29983;&#25104;&#21477;&#23376;&#30340;&#30456;&#20851;&#24615;&#21644;&#30495;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20247;&#22810;&#30456;&#20284;&#30340;&#36873;&#25321;&#20013;&#25214;&#21040;&#26368;&#20339;&#20135;&#21697;&#26159;&#38750;&#24120;&#32791;&#26102;&#30340;&#12290;&#27604;&#36739;&#21477;&#23376;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#20197;&#31361;&#20986;&#30340;&#26041;&#24335;&#23545;&#27604;&#19968;&#20010;&#39033;&#30446;&#19982;&#20854;&#20182;&#39033;&#30446;&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#24378;&#35843;&#20986;&#37325;&#35201;&#29305;&#24449;&#12290;&#22522;&#20110;&#29992;&#25143;&#23545;&#19968;&#20010;&#25110;&#22810;&#20010;&#39033;&#30446;&#30340;&#35780;&#35770;&#21450;&#30456;&#20851;&#39033;&#30446;&#29305;&#24449;&#65292;&#25105;&#20204;&#29983;&#25104;&#27604;&#36739;&#35780;&#35770;&#21477;&#23376;&#26469;&#24110;&#21161;&#29992;&#25143;&#25214;&#21040;&#26368;&#36866;&#21512;&#30340;&#20135;&#21697;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21253;&#25324;&#19977;&#20010;&#36830;&#32493;&#32452;&#20214;&#65306;&#65288;i&#65289;&#19968;&#20010;&#39033;&#30446;&#32534;&#30721;&#27169;&#22359;&#29992;&#20110;&#23545;&#39033;&#30446;&#36827;&#34892;&#32534;&#30721;&#27604;&#36739;&#65292;&#65288;ii&#65289;&#19968;&#20010;&#27604;&#36739;&#29983;&#25104;&#27169;&#22359;&#20197;&#33258;&#22238;&#24402;&#30340;&#26041;&#24335;&#29983;&#25104;&#27604;&#36739;&#21477;&#23376;&#65292;&#65288;iii&#65289;&#19968;&#31181;&#29992;&#20110;&#29992;&#25143;&#20010;&#24615;&#21270;&#30340;&#26032;&#22411;&#35299;&#30721;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27969;&#31243;&#33021;&#22815;&#29983;&#25104;&#27969;&#30021;&#19988;&#22810;&#26679;&#30340;&#27604;&#36739;&#21477;&#23376;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20154;&#31867;&#35780;&#20272;&#30740;&#31350;&#26469;&#39564;&#35777;&#25105;&#20204;&#29983;&#25104;&#30340;&#21477;&#23376;&#30340;&#30456;&#20851;&#24615;&#21644;&#30495;&#23454;&#24615;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#29983;&#25104;&#30456;&#20851;&#19988;&#30495;&#23454;&#30340;&#27604;&#36739;&#35780;&#35770;&#21477;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is time-consuming to find the best product among many similar alternatives. Comparative sentences can help to contrast one item from others in a way that highlights important features of an item that stand out. Given reviews of one or multiple items and relevant item features, we generate comparative review sentences to aid users to find the best fit. Specifically, our model consists of three successive components in a transformer: (i) an item encoding module to encode an item for comparison, (ii) a comparison generation module that generates comparative sentences in an autoregressive manner, (iii) a novel decoding method for user personalization. We show that our pipeline generates fluent and diverse comparative sentences. We run experiments on the relevance and fidelity of our generated sentences in a human evaluation study and find that our algorithm creates comparative review sentences that are relevant and truthful.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#19981;&#21487;&#38477;&#35299;&#23567;&#27874;&#21464;&#25442;&#19982;&#23884;&#20837;&#35821;&#20041;&#36793;&#32536;&#33258;&#21160;&#32534;&#30721;&#22120;&#30456;&#32467;&#21512;&#30340;&#26032;&#31574;&#30053;&#65292;&#29992;&#20110;&#25913;&#21892;&#22810;&#35821;&#35328;&#23433;&#20840;&#25514;&#26045;&#21644;&#38477;&#22122;&#12290;&#35813;&#31995;&#32479;&#36890;&#36807;&#25552;&#21462;&#29305;&#24449;&#24182;&#20445;&#30041;&#25968;&#25454;&#20013;&#30340;&#26102;&#38388;&#21644;&#22320;&#29702;&#38142;&#25509;&#65292;&#25104;&#21151;&#25429;&#33719;&#37325;&#35201;&#20449;&#24687;&#65292;&#24182;&#25552;&#39640;&#20102;&#31995;&#32479;&#26816;&#27979;&#24322;&#24120;&#21644;&#21306;&#20998;&#21512;&#27861;&#20869;&#23481;&#19982;&#21361;&#38505;&#23041;&#32961;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.03679</link><description>&lt;p&gt;
&#23884;&#20837;&#35821;&#20041;&#36793;&#32536;&#33258;&#21160;&#32534;&#30721;&#22120;&#20013;&#30340;&#19981;&#21487;&#38477;&#35299;&#23567;&#27874;&#21464;&#25442;&#23545;&#22810;&#35821;&#35328;&#23433;&#20840;&#25913;&#36827;&#21644;&#38477;&#22122;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Undecimated Wavelet Transform for Word Embedded Semantic Marginal Autoencoder in Security improvement and Denoising different Languages. (arXiv:2307.03679v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#19981;&#21487;&#38477;&#35299;&#23567;&#27874;&#21464;&#25442;&#19982;&#23884;&#20837;&#35821;&#20041;&#36793;&#32536;&#33258;&#21160;&#32534;&#30721;&#22120;&#30456;&#32467;&#21512;&#30340;&#26032;&#31574;&#30053;&#65292;&#29992;&#20110;&#25913;&#21892;&#22810;&#35821;&#35328;&#23433;&#20840;&#25514;&#26045;&#21644;&#38477;&#22122;&#12290;&#35813;&#31995;&#32479;&#36890;&#36807;&#25552;&#21462;&#29305;&#24449;&#24182;&#20445;&#30041;&#25968;&#25454;&#20013;&#30340;&#26102;&#38388;&#21644;&#22320;&#29702;&#38142;&#25509;&#65292;&#25104;&#21151;&#25429;&#33719;&#37325;&#35201;&#20449;&#24687;&#65292;&#24182;&#25552;&#39640;&#20102;&#31995;&#32479;&#26816;&#27979;&#24322;&#24120;&#21644;&#21306;&#20998;&#21512;&#27861;&#20869;&#23481;&#19982;&#21361;&#38505;&#23041;&#32961;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#19981;&#21487;&#38477;&#35299;&#23567;&#27874;&#21464;&#25442;&#19982;&#23884;&#20837;&#35821;&#20041;&#36793;&#32536;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;WESMA&#65289;&#30456;&#32467;&#21512;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#21892;&#23433;&#20840;&#25514;&#26045;&#21644;&#38477;&#22122;&#22810;&#31181;&#35821;&#35328;&#30340;&#26032;&#31574;&#30053;&#12290;&#36825;&#20123;&#31574;&#30053;&#30340;&#25972;&#21512;&#26088;&#22312;&#35299;&#20915;&#25968;&#25454;&#22788;&#29702;&#24212;&#29992;&#20013;&#30340;&#40065;&#26834;&#24615;&#12289;&#38544;&#31169;&#24615;&#21644;&#22810;&#35821;&#35328;&#24615;&#38382;&#39064;&#12290;&#19981;&#21487;&#38477;&#35299;&#23567;&#27874;&#21464;&#25442;&#34987;&#29992;&#20316;&#29305;&#24449;&#25552;&#21462;&#24037;&#20855;&#65292;&#20197;&#35782;&#21035;&#36755;&#20837;&#25968;&#25454;&#20013;&#31361;&#20986;&#30340;&#35821;&#35328;&#27169;&#24335;&#21644;&#32467;&#26500;&#29305;&#24615;&#12290;&#36890;&#36807;&#37319;&#29992;&#36825;&#31181;&#21464;&#25442;&#65292;&#25552;&#35758;&#30340;&#31995;&#32479;&#21487;&#20197;&#22312;&#20445;&#30041;&#25968;&#25454;&#20013;&#30340;&#26102;&#38388;&#21644;&#22320;&#29702;&#38142;&#25509;&#30340;&#21516;&#26102;&#65292;&#25104;&#21151;&#25429;&#33719;&#37325;&#35201;&#20449;&#24687;&#12290;&#36825;&#36890;&#36807;&#22686;&#21152;&#31995;&#32479;&#26816;&#27979;&#24322;&#24120;&#12289;&#21457;&#29616;&#38544;&#34255;&#27169;&#24335;&#20197;&#21450;&#21306;&#20998;&#21512;&#27861;&#20869;&#23481;&#21644;&#21361;&#38505;&#23041;&#32961;&#30340;&#33021;&#21147;&#26469;&#25913;&#21892;&#23433;&#20840;&#25514;&#26045;&#12290;&#23884;&#20837;&#35821;&#20041;&#36793;&#32536;&#33258;&#21160;&#32534;&#30721;&#22120;&#36824;&#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#26234;&#33021;&#26694;&#26550;&#26469;&#38477;&#32500;&#21644;&#38477;&#22122;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
By combining the undecimated wavelet transform within a Word Embedded Semantic Marginal Autoencoder (WESMA), this research study provides a novel strategy for improving security measures and denoising multiple languages. The incorporation of these strategies is intended to address the issues of robustness, privacy, and multilingualism in data processing applications. The undecimated wavelet transform is used as a feature extraction tool to identify prominent language patterns and structural qualities in the input data. The proposed system may successfully capture significant information while preserving the temporal and geographical links within the data by employing this transform. This improves security measures by increasing the system's ability to detect abnormalities, discover hidden patterns, and distinguish between legitimate content and dangerous threats. The Word Embedded Semantic Marginal Autoencoder also functions as an intelligent framework for dimensionality and noise redu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#32467;&#26500;&#24341;&#23548;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;Transformer&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#12290;&#24403;&#21069;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#26410;&#33021;&#20805;&#20998;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#38480;&#21046;&#20102;&#20854;&#25512;&#29702;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.03591</link><description>&lt;p&gt;
&#32467;&#26500;&#24341;&#23548;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;Transformer&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning. (arXiv:2307.03591v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#32467;&#26500;&#24341;&#23548;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;Transformer&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#12290;&#24403;&#21069;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#26410;&#33021;&#20805;&#20998;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#38480;&#21046;&#20102;&#20854;&#25512;&#29702;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#30693;&#35782;&#22270;&#35889;(MKGs)&#30452;&#35266;&#22320;&#32452;&#32455;&#20102;&#21508;&#31181;&#27169;&#24335;&#30340;&#20449;&#24687;&#65292;&#21487;&#20197;&#24800;&#21450;&#22810;&#20010;&#23454;&#38469;&#30340;&#19979;&#28216;&#20219;&#21153;&#65292;&#22914;&#25512;&#33616;&#31995;&#32479;&#21644;&#35270;&#35273;&#38382;&#31572;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;MKGs&#20173;&#28982;&#36828;&#31163;&#23436;&#25972;&#65292;&#36825;&#20419;&#20351;&#20102;MKG&#25512;&#29702;&#27169;&#22411;&#30340;&#20852;&#36215;&#12290;&#26368;&#36817;&#65292;&#38543;&#30528;&#36890;&#29992;&#20154;&#24037;&#26550;&#26500;&#30340;&#21457;&#23637;&#65292;&#39044;&#35757;&#32451;transformer&#27169;&#22411;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#22810;&#27169;&#24577;&#22330;&#26223;&#12290;&#28982;&#32780;&#65292;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;transformer (MPT)&#29992;&#20110;&#30693;&#35782;&#22270;&#25512;&#29702; (KGR) &#30340;&#30740;&#31350;&#20173;&#22788;&#20110;&#26089;&#26399;&#38454;&#27573;&#12290;&#20316;&#20026;MKG&#21644;&#20854;&#20182;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#26368;&#22823;&#21306;&#21035;&#65292;MKG&#20013;&#20016;&#23500;&#30340;&#32467;&#26500;&#20449;&#24687;&#20173;&#28982;&#26080;&#27861;&#22312;&#29616;&#26377;&#30340;MPT&#27169;&#22411;&#20013;&#20805;&#20998;&#21033;&#29992;&#12290;&#22823;&#22810;&#25968;&#27169;&#22411;&#21482;&#23558;&#22270;&#32467;&#26500;&#29992;&#20316;&#21305;&#37197;&#19982;&#21516;&#19968;&#23454;&#20307;&#30456;&#36830;&#30340;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#26816;&#32034;&#26144;&#23556;&#12290;&#36825;&#31181;&#26041;&#24335;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#25512;&#29702;&#24615;&#33021;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22270;&#32467;&#26500;&#24341;&#23548;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;Transformer&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal knowledge graphs (MKGs), which intuitively organize information in various modalities, can benefit multiple practical downstream tasks, such as recommendation systems, and visual question answering. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial architectures, the pretrained transformer models have drawn increasing attention, especially for multimodal scenarios. However, the research of multimodal pretrained transformer (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multimodal data, the rich structural information underlying the MKG still cannot be fully leveraged in existing MPT models. Most of them only utilize the graph structure as a retrieval map for matching images and texts connected with the same entity. This manner hinders their reasoning performances. To this end, we propose the graph S
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PIM+RA&#30340;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#25512;&#33616;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#25913;&#36827;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#20108;&#20998;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#21644;&#26356;&#22909;&#30340;&#25512;&#33616;&#36164;&#28304;&#20998;&#37197;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12289;&#35206;&#30422;&#33539;&#22260;&#12289;&#22810;&#26679;&#24615;&#21644;&#26032;&#39062;&#24615;&#65292;&#21516;&#26102;&#20063;&#23454;&#29616;&#20102;&#23545;&#38271;&#23614;&#29289;&#21697;&#30340;&#26377;&#25928;&#26333;&#20809;&#12290;</title><link>http://arxiv.org/abs/2307.03399</link><description>&lt;p&gt;
&#19968;&#20010;&#25913;&#36827;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#25512;&#33616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Network Resource Allocation Recommendation Method with An Improved Similarity Measure. (arXiv:2307.03399v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03399
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PIM+RA&#30340;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#25512;&#33616;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#25913;&#36827;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#20108;&#20998;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#21644;&#26356;&#22909;&#30340;&#25512;&#33616;&#36164;&#28304;&#20998;&#37197;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12289;&#35206;&#30422;&#33539;&#22260;&#12289;&#22810;&#26679;&#24615;&#21644;&#26032;&#39062;&#24615;&#65292;&#21516;&#26102;&#20063;&#23454;&#29616;&#20102;&#23545;&#38271;&#23614;&#29289;&#21697;&#30340;&#26377;&#25928;&#26333;&#20809;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#34987;&#35748;&#20026;&#26159;&#31649;&#29702;&#20449;&#24687;&#36807;&#36733;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#31639;&#27861;&#22312;&#36825;&#31867;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#20027;&#35201;&#24378;&#35843;&#31934;&#30830;&#30340;&#25512;&#33616;&#65292;&#22240;&#27492;&#24573;&#35270;&#20102;&#35206;&#30422;&#29575;&#12289;&#22810;&#26679;&#24615;&#21644;&#29289;&#21697;&#30340;&#26032;&#39062;&#24615;&#31561;&#20854;&#20182;&#37325;&#35201;&#26041;&#38754;&#12290;&#36825;&#31181;&#26041;&#27861;&#23548;&#33268;&#38271;&#23614;&#29289;&#21697;&#30340;&#26333;&#20809;&#29575;&#36739;&#20302;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PIM+RA&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#20010;&#24615;&#21270;&#25512;&#33616;&#24182;&#26356;&#26377;&#30446;&#30340;&#22320;&#20998;&#37197;&#25512;&#33616;&#36164;&#28304;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#21253;&#21547;&#33258;&#36830;&#25509;&#36793;&#21644;&#26435;&#37325;&#30340;&#20108;&#20998;&#32593;&#32476;&#65292;&#24182;&#37319;&#29992;&#25913;&#36827;&#30340;Pearson&#30456;&#20851;&#31995;&#25968;&#36827;&#34892;&#26356;&#22909;&#30340;&#37325;&#26032;&#20998;&#37197;&#12290;PIM+RA&#30340;&#35780;&#20272;&#19981;&#20165;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#26174;&#31034;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#32780;&#19988;&#22312;&#25512;&#33616;&#30340;&#35206;&#30422;&#33539;&#22260;&#12289;&#22810;&#26679;&#24615;&#21644;&#26032;&#39062;&#24615;&#26041;&#38754;&#20063;&#26377;&#26174;&#33879;&#30340;&#22686;&#24378;&#12290;&#23427;&#36890;&#36807;&#20026;&#38271;&#23614;&#29289;&#21697;&#25552;&#20379;&#26377;&#25928;&#26333;&#20809;&#30340;&#21516;&#26102;&#65292;&#20801;&#35768;&#33258;&#23450;&#20041;&#21442;&#25968;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#25512;&#33616;&#39057;&#29575;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have been acknowledged as efficacious tools for managing information overload. Nevertheless, conventional algorithms adopted in such systems primarily emphasize precise recommendations and, consequently, overlook other vital aspects like the coverage, diversity, and novelty of items. This approach results in less exposure for long-tail items. In this paper, to personalize the recommendations and allocate recommendation resources more purposively, a method named PIM+RA is proposed. This method utilizes a bipartite network that incorporates self-connecting edges and weights. Furthermore, an improved Pearson correlation coefficient is employed for better redistribution. The evaluation of PIM+RA demonstrates a significant enhancement not only in accuracy but also in coverage, diversity, and novelty of the recommendation. It leads to a better balance in recommendation frequency by providing effective exposure to long-tail items, while allowing customized parameters to ad
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;InfoSync&#30340;&#26032;&#25968;&#25454;&#38598;&#21644;&#19968;&#31181;&#20004;&#27493;&#26041;&#27861;&#65292;&#29992;&#20110;&#36328;&#35821;&#35328;&#21322;&#32467;&#26500;&#21270;&#34920;&#26684;&#30340;&#20449;&#24687;&#21516;&#27493;&#12290;&#36890;&#36807;&#20449;&#24687;&#23545;&#40784;&#21644;&#20449;&#24687;&#26356;&#26032;&#65292;&#35813;&#26041;&#27861;&#22312;InfoSync&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#20102;&#39640;&#25928;&#30340;&#24615;&#33021;&#65292;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.03313</link><description>&lt;p&gt;
InfoSync&#65306;&#36328;&#22810;&#35821;&#35328;&#21322;&#32467;&#26500;&#21270;&#34920;&#26684;&#30340;&#20449;&#24687;&#21516;&#27493;
&lt;/p&gt;
&lt;p&gt;
InfoSync: Information Synchronization across Multilingual Semi-structured Tables. (arXiv:2307.03313v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03313
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;InfoSync&#30340;&#26032;&#25968;&#25454;&#38598;&#21644;&#19968;&#31181;&#20004;&#27493;&#26041;&#27861;&#65292;&#29992;&#20110;&#36328;&#35821;&#35328;&#21322;&#32467;&#26500;&#21270;&#34920;&#26684;&#30340;&#20449;&#24687;&#21516;&#27493;&#12290;&#36890;&#36807;&#20449;&#24687;&#23545;&#40784;&#21644;&#20449;&#24687;&#26356;&#26032;&#65292;&#35813;&#26041;&#27861;&#22312;InfoSync&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#20102;&#39640;&#25928;&#30340;&#24615;&#33021;&#65292;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#35821;&#35328;&#21322;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#20449;&#24687;&#21516;&#27493;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20363;&#22914;&#65292;&#24212;&#35813;&#36328;&#35821;&#35328;&#21516;&#27493;&#32500;&#22522;&#30334;&#31185;&#34920;&#26684;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;InfoSyncC&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#26041;&#27861;&#23454;&#29616;&#34920;&#26684;&#21516;&#27493;&#12290;InfoSync&#21253;&#21547;&#20102;14&#31181;&#35821;&#35328;&#30340;10&#19975;&#20010;&#20197;&#23454;&#20307;&#20026;&#20013;&#24515;&#30340;&#34920;&#26684;&#65288;&#32500;&#22522;&#30334;&#31185;Infoboxes&#65289;&#65292;&#20854;&#20013;&#19968;&#37096;&#20998;&#65288;3.5K&#23545;&#65289;&#26159;&#25163;&#21160;&#27880;&#37322;&#30340;&#12290;&#25552;&#20986;&#30340;&#26041;&#27861;&#21253;&#25324;1&#65289;&#20449;&#24687;&#23545;&#40784;&#26469;&#26144;&#23556;&#34892;&#21644;2&#65289;&#20449;&#24687;&#26356;&#26032;&#26469;&#26356;&#26032;&#36328;&#22810;&#35821;&#35328;&#34920;&#26684;&#20013;&#23545;&#40784;&#34920;&#26684;&#20013;&#30340;&#32570;&#22833;/&#36807;&#26102;&#20449;&#24687;&#12290;&#22312;InfoSync&#19978;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;&#20449;&#24687;&#23545;&#40784;&#23454;&#29616;&#20102;87.91&#30340;F1&#24471;&#20998;&#65288;&#33521;&#25991;&lt;-&gt;&#38750;&#33521;&#25991;&#65289;&#12290;&#20026;&#20102;&#35780;&#20272;&#20449;&#24687;&#26356;&#26032;&#65292;&#25105;&#20204;&#23545;603&#20010;&#34920;&#26684;&#23545;&#30340;Infoboxes&#36827;&#34892;&#20102;&#20154;&#24037;&#36741;&#21161;&#30340;&#32500;&#22522;&#30334;&#31185;&#32534;&#36753;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#32500;&#22522;&#30334;&#31185;&#19978;&#21462;&#24471;&#20102;77.28%&#30340;&#25509;&#21463;&#29575;&#65292;&#26174;&#31034;&#20986;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information Synchronization of semi-structured data across languages is challenging. For instance, Wikipedia tables in one language should be synchronized across languages. To address this problem, we introduce a new dataset InfoSyncC and a two-step method for tabular synchronization. InfoSync contains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages, of which a subset (3.5K pairs) are manually annotated. The proposed method includes 1) Information Alignment to map rows and 2) Information Update for updating missing/outdated information for aligned tables across multilingual tables. When evaluated on InfoSync, information alignment achieves an F1 score of 87.91 (en &lt;-&gt; non-en). To evaluate information updation, we perform human-assisted Wikipedia edits on Infoboxes for 603 table pairs. Our approach obtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of the proposed method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;DENCLUE&#31639;&#27861;&#26368;&#20248;&#21442;&#25968;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#37096;&#20998;&#35752;&#35770;&#20102;&#20854;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.03206</link><description>&lt;p&gt;
DENCLUE&#30340;&#26368;&#20248;&#24102;&#23485;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Optimal Bandwidth Selection for DENCLUE. (arXiv:2307.03206v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03206
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;DENCLUE&#31639;&#27861;&#26368;&#20248;&#21442;&#25968;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#37096;&#20998;&#35752;&#35770;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#24037;&#19994;&#20013;&#65292;&#32858;&#31867;&#31639;&#27861;&#26159;&#31639;&#27861;&#24037;&#31243;&#24072;&#30340;&#26085;&#24120;&#24037;&#20316;&#12290;&#23613;&#31649;&#22312;2010&#24180;&#20043;&#21069;&#65292;&#32858;&#31867;&#31639;&#27861;&#32463;&#21382;&#20102;&#24555;&#36895;&#22686;&#38271;&#65292;&#20294;&#22312;&#28145;&#24230;&#23398;&#20064;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#23454;&#38469;&#24037;&#19994;&#26631;&#20934;&#20043;&#21518;&#65292;&#19982;&#35813;&#30740;&#31350;&#20027;&#39064;&#30456;&#20851;&#30340;&#21019;&#26032;&#20572;&#28382;&#19981;&#21069;&#12290;2007&#24180;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DENCLUE&#30340;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#25968;&#25454;&#32467;&#26500;&#30340;&#32858;&#31867;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30452;&#21040;2011&#24180;&#65292;&#35813;&#31639;&#27861;&#30340;&#21442;&#25968;&#36873;&#25321;&#38382;&#39064;&#20173;&#28982;&#34987;&#22823;&#37096;&#20998;&#24573;&#35270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;DENCLUE&#31639;&#27861;&#26368;&#20248;&#21442;&#25968;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#37096;&#20998;&#35752;&#35770;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In modern day industry, clustering algorithms are daily routines of algorithm engineers. Although clustering algorithms experienced rapid growth before 2010. Innovation related to the research topic has stagnated after deep learning became the de facto industrial standard for machine learning applications. In 2007, a density-based clustering algorithm named DENCLUE was invented to solve clustering problem for nonlinear data structures. However, its parameter selection problem was largely neglected until 2011. In this paper, we propose a new approach to compute the optimal parameters for the DENCLUE algorithm, and discuss its performance in the experiment section.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;JEPOO&#30340;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#65292;&#25903;&#25345;&#21333;&#38899;&#39640;&#21644;&#22810;&#38899;&#39640;&#25968;&#25454;&#65292;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#31934;&#24230;&#25552;&#21319;&#39640;&#36798;10.6%&#65292;8.3%&#21644;10.3%&#12290;</title><link>http://arxiv.org/abs/2306.01304</link><description>&lt;p&gt;
JEPOO&#65306;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#20013;&#20934;&#30830;&#20272;&#35745;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#30340;&#32852;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
JEPOO: Highly Accurate Joint Estimation of Pitch, Onset and Offset for Music Information Retrieval. (arXiv:2306.01304v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;JEPOO&#30340;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#65292;&#25903;&#25345;&#21333;&#38899;&#39640;&#21644;&#22810;&#38899;&#39640;&#25968;&#25454;&#65292;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#31934;&#24230;&#25552;&#21319;&#39640;&#36798;10.6%&#65292;8.3%&#21644;10.3%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26059;&#24459;&#25552;&#21462;&#26159;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#65292;&#32780;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#30340;&#20272;&#35745;&#26159;&#26059;&#24459;&#25552;&#21462;&#30340;&#20851;&#38190;&#23376;&#20219;&#21153;&#12290;&#29616;&#26377;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#26377;&#38480;&#65292;&#24182;&#19988;&#21482;&#36866;&#29992;&#20110;&#21333;&#38899;&#39640;&#25110;&#22810;&#38899;&#39640;&#25968;&#25454;&#20013;&#30340;&#19968;&#31181;&#31867;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;JEPOO&#30340;&#39640;&#24230;&#20934;&#30830;&#30340;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#32852;&#21512;&#20272;&#35745;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#26032;&#39062;&#30340;&#27169;&#22411;&#35774;&#35745;&#21644;&#19968;&#31181;&#21517;&#20026;&#24085;&#32047;&#25176;&#27169;&#35843;&#25439;&#22833;&#30340;&#20248;&#21270;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#32852;&#21512;&#23398;&#20064;&#20248;&#21270;&#21644;&#22788;&#29702;&#21333;&#38899;&#39640;&#21644;&#22810;&#38899;&#39640;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;&#36825;&#26159;&#31532;&#19968;&#31181;&#33021;&#22815;&#20934;&#30830;&#22788;&#29702;&#21333;&#38899;&#39640;&#21644;&#22810;&#38899;&#39640;&#38899;&#20048;&#25968;&#25454;&#65292;&#29978;&#33267;&#28151;&#21512;&#31867;&#22411;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#22312;&#24191;&#27867;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#20840;&#38754;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;JEPOO&#22312;&#39044;&#27979;&#38899;&#39640;&#12289;&#36215;&#22987;&#21644;&#32456;&#27490;&#26041;&#38754;&#27604;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20998;&#21035;&#39640;&#20986;10.6&#65285;&#12289;8.3&#65285;&#21644;10.3&#65285;&#65292;&#21516;&#26102;&#23545;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#21644;&#20048;&#22120;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Melody extraction is a core task in music information retrieval, and the estimation of pitch, onset and offset are key sub-tasks in melody extraction. Existing methods have limited accuracy, and work for only one type of data, either single-pitch or multipitch. In this paper, we propose a highly accurate method for joint estimation of pitch, onset and offset, named JEPOO. We address the challenges of joint learning optimization and handling both single-pitch and multi-pitch data through novel model design and a new optimization technique named Pareto modulated loss with loss weight regularization. This is the first method that can accurately handle both single-pitch and multi-pitch music data, and even a mix of them. A comprehensive experimental study on a wide range of real datasets shows that JEPOO outperforms state-ofthe-art methods by up to 10.6%, 8.3% and 10.3% for the prediction of Pitch, Onset and Offset, respectively, and JEPOO is robust for various types of data and instrument
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#26088;&#22312;&#36890;&#36807;&#23545;&#35821;&#20041;&#23884;&#20837;API&#22312;&#23454;&#38469;&#26816;&#32034;&#22330;&#26223;&#20013;&#30340;&#20998;&#26512;,&#20026;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#25214;&#21040;&#36866;&#24403;&#30340;&#26381;&#21153;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#33521;&#35821;&#19978;&#20351;&#29992;API&#37325;&#26032;&#25490;&#21517;BM25&#30340;&#32467;&#26524;&#26159;&#19968;&#31181;&#39044;&#31639;&#21451;&#22909;&#30340;&#26368;&#20248;&#20570;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.06300</link><description>&lt;p&gt;
&#35780;&#20272;&#20449;&#24687;&#26816;&#32034;&#30340;&#23884;&#20837;&#24335;API
&lt;/p&gt;
&lt;p&gt;
Evaluating Embedding APIs for Information Retrieval. (arXiv:2305.06300v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06300
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#26088;&#22312;&#36890;&#36807;&#23545;&#35821;&#20041;&#23884;&#20837;API&#22312;&#23454;&#38469;&#26816;&#32034;&#22330;&#26223;&#20013;&#30340;&#20998;&#26512;,&#20026;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#25214;&#21040;&#36866;&#24403;&#30340;&#26381;&#21153;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#33521;&#35821;&#19978;&#20351;&#29992;API&#37325;&#26032;&#25490;&#21517;BM25&#30340;&#32467;&#26524;&#26159;&#19968;&#31181;&#39044;&#31639;&#21451;&#22909;&#30340;&#26368;&#20248;&#20570;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#19981;&#26029;&#22686;&#22823;&#20351;&#24471;&#20854;&#26222;&#21450;&#21270;&#25104;&#20026;&#20102;&#19968;&#39033;&#25361;&#25112;&#65292;&#22240;&#27492;&#35768;&#22810;&#20844;&#21496;&#21644;&#21021;&#21019;&#20225;&#19994;&#36890;&#36807;API&#21521;&#31038;&#21306;&#25552;&#20379;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35775;&#38382;&#26435;&#38480;&#12290;&#20854;&#20013;&#19968;&#20010;&#36866;&#29992;&#20110;&#23494;&#38598;&#26816;&#32034;&#30340;&#29305;&#23450;API&#26159;&#35821;&#20041;&#23884;&#20837;&#24335;API&#65292;&#20854;&#21487;&#26500;&#24314;&#32473;&#23450;&#25991;&#26412;&#30340;&#21521;&#37327;&#34920;&#31034;&#12290;&#22312;&#25317;&#26377;&#36234;&#26469;&#36234;&#22810;API&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#25991;&#26088;&#22312;&#20998;&#26512;&#22312;&#23454;&#38469;&#26816;&#32034;&#22330;&#26223;&#20013;&#35821;&#20041;&#23884;&#20837;&#24335;API&#20197;&#24110;&#21161;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#26681;&#25454;&#20182;&#20204;&#30340;&#38656;&#27714;&#25214;&#21040;&#36866;&#24403;&#30340;&#26381;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24076;&#26395;&#35843;&#26597;&#29616;&#26377;API&#22312;&#39046;&#22495;&#27867;&#21270;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#20004;&#20010;&#26631;&#20934;&#22522;&#20934;BEIR&#21644;MIRACL&#19978;&#35780;&#20272;&#20102;&#23884;&#20837;&#24335;API&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20351;&#29992;API&#37325;&#26032;&#25490;&#21517;BM25&#32467;&#26524;&#26159;&#19968;&#31181;&#39044;&#31639;&#21451;&#22909;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#33521;&#35821;&#19978;&#26368;&#26377;&#25928;&#65292;&#19982;&#26631;&#20934;&#20570;&#27861;&#21363;&#20316;&#20026;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#22120;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ever-increasing size of language models curtails their widespread access to the community, thereby galvanizing many companies and startups into offering access to large language models through APIs. One particular API, suitable for dense retrieval, is the semantic embedding API that builds vector representations of a given text. With a growing number of APIs at our disposal, in this paper, our goal is to analyze semantic embedding APIs in realistic retrieval scenarios in order to assist practitioners and researchers in finding suitable services according to their needs. Specifically, we wish to investigate the capabilities of existing APIs on domain generalization and multilingual retrieval. For this purpose, we evaluate the embedding APIs on two standard benchmarks, BEIR, and MIRACL. We find that re-ranking BM25 results using the APIs is a budget-friendly approach and is most effective on English, in contrast to the standard practice, i.e., employing them as first-stage retrievers
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35782;&#21035;&#21644;&#35299;&#20915;&#20102;&#24403;&#21069;&#21487;&#24494;&#25628;&#32034;&#32034;&#24341;&#27169;&#22411;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#22312;&#32034;&#24341;&#21644;&#26816;&#32034;&#36807;&#31243;&#20013;&#23384;&#22312;&#30340;&#25968;&#25454;&#20998;&#24067;&#19981;&#21305;&#37197;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#32034;&#24341;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2206.10128</link><description>&lt;p&gt;
&#23558;&#32034;&#24341;&#21644;&#26816;&#32034;&#26725;&#25509;&#36215;&#26469;&#65292;&#20026;&#20855;&#26377;&#26597;&#35810;&#29983;&#25104;&#30340;&#21487;&#24494;&#25628;&#32034;&#32034;&#24341;&#22635;&#34917;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Bridging the Gap Between Indexing and Retrieval for Differentiable Search Index with Query Generation. (arXiv:2206.10128v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10128
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35782;&#21035;&#21644;&#35299;&#20915;&#20102;&#24403;&#21069;&#21487;&#24494;&#25628;&#32034;&#32034;&#24341;&#27169;&#22411;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#22312;&#32034;&#24341;&#21644;&#26816;&#32034;&#36807;&#31243;&#20013;&#23384;&#22312;&#30340;&#25968;&#25454;&#20998;&#24067;&#19981;&#21305;&#37197;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#32034;&#24341;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#24494;&#25628;&#32034;&#32034;&#24341;(DSI)&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#20449;&#24687;&#26816;&#32034;&#33539;&#24335;&#12290;&#19982;&#20256;&#32479;&#30340;&#26816;&#32034;&#26550;&#26500;&#19981;&#21516;&#65292;&#20854;&#20013;&#32034;&#24341;&#21644;&#26816;&#32034;&#26159;&#20004;&#20010;&#19981;&#21516;&#30340;&#32452;&#20214;&#65292;DSI&#20351;&#29992;&#21333;&#20010;transformer&#27169;&#22411;&#26469;&#25191;&#34892;&#32034;&#24341;&#21644;&#26816;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#24182;&#35299;&#20915;&#20102;&#24403;&#21069;DSI&#27169;&#22411;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;DSI&#32034;&#24341;&#21644;&#26816;&#32034;&#36807;&#31243;&#20043;&#38388;&#20986;&#29616;&#30340;&#25968;&#25454;&#20998;&#24067;&#19981;&#21305;&#37197;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35748;&#20026;&#65292;&#22312;&#32034;&#24341;&#36807;&#31243;&#20013;&#65292;&#24403;&#21069;DSI&#26041;&#27861;&#23398;&#20064;&#26500;&#24314;&#38271;&#25991;&#26723;&#30340;&#25991;&#26412;&#19982;&#25991;&#26723;&#26631;&#35782;&#31526;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#20294;&#26816;&#32034;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;&#26597;&#35810;&#36890;&#24120;&#27604;&#32034;&#24341;&#30340;&#25991;&#26723;&#35201;&#30701;&#24471;&#22810;&#12290;&#24403;&#23558;DSI&#29992;&#20110;&#36328;&#35821;&#35328;&#26816;&#32034;&#26102;&#65292;&#36825;&#20010;&#38382;&#39064;&#36827;&#19968;&#27493;&#21152;&#21095;&#65292;&#22240;&#20026;&#25991;&#26723;&#25991;&#26412;&#21644;&#26597;&#35810;&#25991;&#26412;&#22788;&#20110;&#19981;&#21516;&#30340;&#35821;&#35328;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#24403;&#21069;DSI&#27169;&#22411;&#30340;&#36825;&#20010;&#26681;&#26412;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;DSI&#32034;&#24341;&#26694;&#26550;&#65292;c
&lt;/p&gt;
&lt;p&gt;
The Differentiable Search Index (DSI) is an emerging paradigm for information retrieval. Unlike traditional retrieval architectures where index and retrieval are two different and separate components, DSI uses a single transformer model to perform both indexing and retrieval.  In this paper, we identify and tackle an important issue of current DSI models: the data distribution mismatch that occurs between the DSI indexing and retrieval processes. Specifically, we argue that, at indexing, current DSI methods learn to build connections between the text of long documents and the identifier of the documents, but then retrieval of document identifiers is based on queries that are commonly much shorter than the indexed documents. This problem is further exacerbated when using DSI for cross-lingual retrieval, where document text and query text are in different languages.  To address this fundamental problem of current DSI models, we propose a simple yet effective indexing framework for DSI, c
&lt;/p&gt;</description></item></channel></rss>