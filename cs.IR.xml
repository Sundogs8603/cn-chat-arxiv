<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;K-means&#32858;&#31867;&#31639;&#27861;&#65292;&#36890;&#36807;&#31454;&#20105;&#24615;&#38543;&#26426;&#26679;&#26412;&#22823;&#23567;&#20248;&#21270;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;Big-means&#20013;&#30340;&#24182;&#34892;&#22823;&#25968;&#25454;&#32858;&#31867;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.18766</link><description>&lt;p&gt;
&#36890;&#36807;&#31454;&#20105;&#24615;&#38543;&#26426;&#26679;&#26412;&#22823;&#23567;&#20248;&#21270;&#22312;Big-means&#20013;&#23454;&#29616;&#20248;&#36234;&#30340;&#24182;&#34892;&#22823;&#25968;&#25454;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Superior Parallel Big Data Clustering through Competitive Stochastic Sample Size Optimization in Big-means
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18766
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;K-means&#32858;&#31867;&#31639;&#27861;&#65292;&#36890;&#36807;&#31454;&#20105;&#24615;&#38543;&#26426;&#26679;&#26412;&#22823;&#23567;&#20248;&#21270;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;Big-means&#20013;&#30340;&#24182;&#34892;&#22823;&#25968;&#25454;&#32858;&#31867;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;K-means&#32858;&#31867;&#31639;&#27861;&#65292;&#26159;&#23545;&#20256;&#32479;Big-means&#26041;&#27861;&#30340;&#36827;&#27493;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#25972;&#21512;&#20102;&#24182;&#34892;&#22788;&#29702;&#12289;&#38543;&#26426;&#25277;&#26679;&#21644;&#31454;&#20105;&#24615;&#20248;&#21270;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#19987;&#20026;&#22823;&#25968;&#25454;&#24212;&#29992;&#35774;&#35745;&#30340;&#21487;&#25193;&#23637;&#21464;&#20307;&#12290;&#23427;&#35299;&#20915;&#20102;&#20256;&#32479;&#25216;&#26415;&#36890;&#24120;&#38754;&#20020;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#35745;&#31639;&#26102;&#38388;&#25361;&#25112;&#12290;&#35813;&#31639;&#27861;&#22312;&#25191;&#34892;&#36807;&#31243;&#20013;&#21160;&#24577;&#35843;&#25972;&#27599;&#20010;&#24037;&#20316;&#20154;&#21592;&#30340;&#26679;&#26412;&#22823;&#23567;&#65292;&#20248;&#21270;&#24615;&#33021;&#12290;&#36825;&#20123;&#26679;&#26412;&#22823;&#23567;&#30340;&#25968;&#25454;&#19981;&#26029;&#34987;&#20998;&#26512;&#65292;&#20419;&#36827;&#20102;&#25214;&#21040;&#26368;&#26377;&#25928;&#37197;&#32622;&#30340;&#35782;&#21035;&#12290;&#36890;&#36807;&#22312;&#20351;&#29992;&#19981;&#21516;&#26679;&#26412;&#22823;&#23567;&#30340;&#24037;&#20316;&#20154;&#21592;&#20043;&#38388;&#24341;&#20837;&#31454;&#20105;&#22240;&#32032;&#65292;&#36827;&#19968;&#27493;&#21050;&#28608;&#20102;Big-means&#31639;&#27861;&#20869;&#30340;&#25928;&#29575;&#12290;&#26412;&#36136;&#19978;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#22312;&#24182;&#34892;&#35745;&#31639;&#29615;&#22659;&#20013;&#37319;&#29992;&#38543;&#26426;&#12289;&#31454;&#20105;&#24615;&#25277;&#26679;&#31574;&#30053;&#65292;&#24179;&#34913;&#20102;&#35745;&#31639;&#26102;&#38388;&#21644;&#32858;&#31867;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18766v1 Announce Type: cross  Abstract: This paper introduces a novel K-means clustering algorithm, an advancement on the conventional Big-means methodology. The proposed method efficiently integrates parallel processing, stochastic sampling, and competitive optimization to create a scalable variant designed for big data applications. It addresses scalability and computation time challenges typically faced with traditional techniques. The algorithm adjusts sample sizes dynamically for each worker during execution, optimizing performance. Data from these sample sizes are continually analyzed, facilitating the identification of the most efficient configuration. By incorporating a competitive element among workers using different sample sizes, efficiency within the Big-means algorithm is further stimulated. In essence, the algorithm balances computational time and clustering quality by employing a stochastic, competitive sampling strategy in a parallel computing setting.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#26159;&#21542;&#36981;&#24490;&#20854;&#20182;&#31070;&#32463;&#27169;&#22411;&#30340;&#32553;&#25918;&#35268;&#24459;&#65292;&#24182;&#25552;&#20986;&#20351;&#29992;&#23545;&#27604;&#23545;&#25968;&#20284;&#28982;&#20316;&#20026;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#12290;</title><link>https://arxiv.org/abs/2403.18684</link><description>&lt;p&gt;
&#23494;&#38598;&#26816;&#32034;&#30340;&#25193;&#23637;&#35268;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws For Dense Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18684
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#26159;&#21542;&#36981;&#24490;&#20854;&#20182;&#31070;&#32463;&#27169;&#22411;&#30340;&#32553;&#25918;&#35268;&#24459;&#65292;&#24182;&#25552;&#20986;&#20351;&#29992;&#23545;&#27604;&#23545;&#25968;&#20284;&#28982;&#20316;&#20026;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#31070;&#32463;&#27169;&#22411;&#25193;&#23637;&#21040;&#26356;&#22823;&#35268;&#27169;&#24050;&#32463;&#22312;&#22810;&#39033;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#29305;&#21035;&#26159;&#22312;&#35821;&#35328;&#29983;&#25104;&#26041;&#38754;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#31070;&#32463;&#27169;&#22411;&#30340;&#24615;&#33021;&#24120;&#36981;&#24490;&#21487;&#39044;&#27979;&#30340;&#25193;&#23637;&#35268;&#24459;&#65292;&#19982;&#35757;&#32451;&#38598;&#22823;&#23567;&#21644;&#27169;&#22411;&#22823;&#23567;&#31561;&#22240;&#32032;&#30456;&#20851;&#12290;&#36825;&#19968;&#27934;&#23519;&#21147;&#38750;&#24120;&#23453;&#36149;&#65292;&#23588;&#20854;&#26159;&#38543;&#30528;&#22823;&#35268;&#27169;&#23454;&#39564;&#21464;&#24471;&#36234;&#26469;&#36234;&#32791;&#36153;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26816;&#32034;&#25351;&#26631;&#30340;&#31163;&#25955;&#24615;&#20197;&#21450;&#26816;&#32034;&#20219;&#21153;&#20013;&#35757;&#32451;&#25968;&#25454;&#21644;&#27169;&#22411;&#22823;&#23567;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#23494;&#38598;&#26816;&#32034;&#20013;&#30340;&#36825;&#31181;&#25193;&#23637;&#35268;&#24459;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#26159;&#21542;&#36981;&#24490;&#20854;&#20182;&#31070;&#32463;&#27169;&#22411;&#30340;&#32553;&#25918;&#35268;&#24459;&#12290;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#23545;&#27604;&#23545;&#25968;&#20284;&#28982;&#20316;&#20026;&#35780;&#20272;&#25351;&#26631;&#65292;&#24182;&#23545;&#23454;&#29616;&#20102;&#19981;&#21516;&#21442;&#25968;&#25968;&#37327;&#24182;&#20351;&#29992;&#19981;&#21516;&#25968;&#37327;&#30340;&#25968;&#25454;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18684v1 Announce Type: cross  Abstract: Scaling up neural models has yielded significant advancements in a wide array of tasks, particularly in language generation. Previous studies have found that the performance of neural models frequently adheres to predictable scaling laws, correlated with factors such as training set size and model size. This insight is invaluable, especially as large-scale experiments grow increasingly resource-intensive. Yet, such scaling law has not been fully explored in dense retrieval due to the discrete nature of retrieval metrics and complex relationships between training data and model sizes in retrieval tasks. In this study, we investigate whether the performance of dense retrieval models follows the scaling law as other neural models. We propose to use contrastive log-likelihood as the evaluation metric and conduct extensive experiments with dense retrieval models implemented with different numbers of parameters and trained with different amo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#30340;&#35821;&#20041;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#22810;&#20219;&#21153;&#23398;&#20064;&#22312;&#29992;&#25143;-&#39033;&#30446;&#21644;&#39033;&#30446;-&#39033;&#30446;&#20132;&#20114;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#25552;&#20379;&#20010;&#24615;&#21270;&#21644;&#22810;&#26679;&#21270;&#30340;&#25512;&#33616;&#12290;</title><link>https://arxiv.org/abs/2403.18667</link><description>&lt;p&gt;
&#25913;&#36827;&#20869;&#23481;&#25512;&#33616;&#65306;&#22522;&#20110;&#30693;&#35782;&#22270;&#30340;&#35821;&#20041;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#22810;&#26679;&#24615;&#21644;&#20919;&#21551;&#21160;&#29992;&#25143;
&lt;/p&gt;
&lt;p&gt;
Improving Content Recommendation: Knowledge Graph-Based Semantic Contrastive Learning for Diversity and Cold-Start Users
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18667
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#30340;&#35821;&#20041;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#22810;&#20219;&#21153;&#23398;&#20064;&#22312;&#29992;&#25143;-&#39033;&#30446;&#21644;&#39033;&#30446;-&#39033;&#30446;&#20132;&#20114;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#25552;&#20379;&#20010;&#24615;&#21270;&#21644;&#22810;&#26679;&#21270;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22788;&#29702;&#19982;&#25968;&#25454;&#31232;&#30095;&#24615;&#12289;&#20919;&#21551;&#21160;&#38382;&#39064;&#21644;&#25512;&#33616;&#31995;&#32479;&#22810;&#26679;&#24615;&#30456;&#20851;&#30340;&#25361;&#25112;&#26082;&#33267;&#20851;&#37325;&#35201;&#21448;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#35768;&#22810;&#24403;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#21033;&#29992;&#30693;&#35782;&#22270;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#32467;&#21512;&#22522;&#20110;&#39033;&#30446;&#21644;&#29992;&#25143;-&#39033;&#30446;&#21327;&#20316;&#20449;&#21495;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#19968;&#20010;&#26222;&#36941;&#36235;&#21183;&#26159;&#19987;&#27880;&#20110;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#65292;&#20294;&#20250;&#22686;&#21152;&#27169;&#22411;&#22797;&#26434;&#24615;&#12289;&#38477;&#20302;&#22810;&#26679;&#24615;&#24182;&#20351;&#20219;&#21153;&#21464;&#24471;&#26356;&#22797;&#26434;&#12290;&#25552;&#20379;&#26082;&#20010;&#24615;&#21270;&#21448;&#22810;&#26679;&#21270;&#30340;&#25512;&#33616;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#32780;&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#23454;&#29616;&#39640;&#25490;&#21517;&#24615;&#33021;&#65292;&#27604;&#22914;&#28857;&#20987;&#29575;&#12289;&#21484;&#22238;&#29575;&#31561;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#29992;&#25143;-&#39033;&#30446;&#21644;&#39033;&#30446;-&#39033;&#30446;&#20132;&#20114;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#22312;&#25551;&#36848;&#24615;&#25991;&#26412;&#19978;&#24212;&#29992;&#22522;&#20110;&#39033;&#30446;&#30340;&#23545;&#27604;&#23398;&#20064;&#65292;&#26681;&#25454;&#39033;&#30446;&#20803;&#25968;&#25454;&#23545;&#27491;&#36127;&#26679;&#26412;&#36827;&#34892;&#25277;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#27169;&#22411;&#33021;&#26356;&#22909;&#22320;&#29702;&#35299;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18667v1 Announce Type: cross  Abstract: Addressing the challenges related to data sparsity, cold-start problems, and diversity in recommendation systems is both crucial and demanding. Many current solutions leverage knowledge graphs to tackle these issues by combining both item-based and user-item collaborative signals. A common trend in these approaches focuses on improving ranking performance at the cost of escalating model complexity, reducing diversity, and complicating the task. It is essential to provide recommendations that are both personalized and diverse, rather than solely relying on achieving high rank-based performance, such as Click-through Rate, Recall, etc. In this paper, we propose a hybrid multi-task learning approach, training on user-item and item-item interactions. We apply item-based contrastive learning on descriptive text, sampling positive and negative pairs based on item metadata. Our approach allows the model to better understand the relationships 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#24182;&#23450;&#20041;&#20102;&#21487;&#25512;&#33616;&#24615;&#35782;&#21035;&#38382;&#39064;&#65292;&#19987;&#27880;&#20110;&#22312;&#24403;&#21069;&#23545;&#35805;&#29615;&#22659;&#20013;&#25506;&#35752;&#26159;&#21542;&#38656;&#35201;&#25512;&#33616;&#65292;&#20197;&#20943;&#23569;&#29992;&#25143;&#24178;&#25200;&#12290;</title><link>https://arxiv.org/abs/2403.18628</link><description>&lt;p&gt;
&#26159;&#21542;&#25512;&#33616;&#65306;&#22312;&#19982;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#35805;&#20013;&#35782;&#21035;&#21487;&#25512;&#33616;&#24615;
&lt;/p&gt;
&lt;p&gt;
To Recommend or Not: Recommendability Identification in Conversations with Pre-trained Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18628
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#24182;&#23450;&#20041;&#20102;&#21487;&#25512;&#33616;&#24615;&#35782;&#21035;&#38382;&#39064;&#65292;&#19987;&#27880;&#20110;&#22312;&#24403;&#21069;&#23545;&#35805;&#29615;&#22659;&#20013;&#25506;&#35752;&#26159;&#21542;&#38656;&#35201;&#25512;&#33616;&#65292;&#20197;&#20943;&#23569;&#29992;&#25143;&#24178;&#25200;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#25512;&#33616;&#31995;&#32479;&#20027;&#35201;&#20851;&#27880;&#20110;&#25512;&#33616;&#20160;&#20040;&#65292;&#20551;&#35774;&#29992;&#25143;&#24635;&#26159;&#38656;&#35201;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;ChatGPT&#21644;&#20854;&#20182;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#24191;&#27867;&#20256;&#25773;&#65292;&#22312;&#23545;&#35805;&#31995;&#32479;&#30340;&#32972;&#26223;&#19979;&#26356;&#20851;&#38190;&#30340;&#38382;&#39064;&#26159;&#22312;&#20026;&#29992;&#25143;&#25552;&#20379;&#25512;&#33616;&#26381;&#21153;&#26102;&#22914;&#20309;&#26368;&#23567;&#21270;&#29992;&#25143;&#30340;&#24178;&#25200;&#12290;&#25105;&#20204;&#27491;&#24335;&#23450;&#20041;&#20102;&#21487;&#25512;&#33616;&#24615;&#35782;&#21035;&#38382;&#39064;&#65292;&#26088;&#22312;&#30830;&#23450;&#22312;&#29305;&#23450;&#22330;&#26223;&#20013;&#26159;&#21542;&#38656;&#35201;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18628v1 Announce Type: new  Abstract: Most current recommender systems primarily focus on what to recommend, assuming users always require personalized recommendations. However, with the widely spread of ChatGPT and other chatbots, a more crucial problem in the context of conversational systems is how to minimize user disruption when we provide recommendation services for users. While previous research has extensively explored different user intents in dialogue systems, fewer efforts are made to investigate whether recommendations should be provided. In this paper, we formally define the recommendability identification problem, which aims to determine whether recommendations are necessary in a specific scenario. First, we propose and define the recommendability identification task, which investigates the need for recommendations in the current conversational context. A new dataset is constructed. Subsequently, we discuss and evaluate the feasibility of leveraging pre-trained
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20122;&#39532;&#36874;&#26159;&#21542;&#23384;&#22312;&#33258;&#25105;&#20559;&#22909;&#30340;&#20570;&#27861;&#65292;&#35752;&#35770;&#20102;&#22914;&#20309;&#21033;&#29992;&#35745;&#31639;&#26426;&#31185;&#23398;&#24037;&#20855;&#36827;&#34892;&#22522;&#20110;&#31639;&#27861;&#23457;&#35745;&#30340;&#30417;&#31649;&#65292;&#20197;&#35268;&#33539;&#25968;&#23383;&#24066;&#22330;&#12290;</title><link>https://arxiv.org/abs/2403.18623</link><description>&lt;p&gt;
&#21453;&#22404;&#26029;&#12289;&#20122;&#39532;&#36874;&#21644;&#31639;&#27861;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Antitrust, Amazon, and Algorithmic Auditing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18623
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20122;&#39532;&#36874;&#26159;&#21542;&#23384;&#22312;&#33258;&#25105;&#20559;&#22909;&#30340;&#20570;&#27861;&#65292;&#35752;&#35770;&#20102;&#22914;&#20309;&#21033;&#29992;&#35745;&#31639;&#26426;&#31185;&#23398;&#24037;&#20855;&#36827;&#34892;&#22522;&#20110;&#31639;&#27861;&#23457;&#35745;&#30340;&#30417;&#31649;&#65292;&#20197;&#35268;&#33539;&#25968;&#23383;&#24066;&#22330;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#24066;&#22330;&#20013;&#65292;&#21453;&#22404;&#26029;&#27861;&#21644;&#29305;&#27530;&#27861;&#35268;&#26088;&#22312;&#30830;&#20445;&#24066;&#22330;&#20445;&#25345;&#31454;&#20105;&#65292;&#23613;&#31649;&#25968;&#23383;&#24179;&#21488;&#22312;&#27599;&#20010;&#20154;&#29983;&#27963;&#20013;&#25198;&#28436;&#30528;&#20027;&#23548;&#35282;&#33394;&#12290;&#19982;&#20256;&#32479;&#24066;&#22330;&#19981;&#21516;&#65292;&#36825;&#20123;&#24066;&#22330;&#20013;&#30340;&#24066;&#22330;&#21442;&#19982;&#32773;&#34892;&#20026;&#24456;&#23481;&#26131;&#34987;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31995;&#21015;&#23454;&#35777;&#35843;&#26597;&#65292;&#25506;&#35752;&#20122;&#39532;&#36874;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#21442;&#19982;&#20102;&#36890;&#24120;&#34987;&#25551;&#36848;&#20026;&#33258;&#25105;&#20559;&#22909;&#30340;&#20570;&#27861;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#26412;&#25991;&#20013;&#20351;&#29992;&#30340;&#35745;&#31639;&#26426;&#31185;&#23398;&#24037;&#20855;&#22914;&#20309;&#22312;&#22522;&#20110;&#31639;&#27861;&#23457;&#35745;&#30340;&#30417;&#31649;&#29615;&#22659;&#20013;&#20351;&#29992;&#65292;&#24182;&#35201;&#27714;&#22312;&#35268;&#27169;&#19978;&#30417;&#31649;&#25968;&#23383;&#24066;&#22330;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18623v1 Announce Type: cross  Abstract: In digital markets, antitrust law and special regulations aim to ensure that markets remain competitive despite the dominating role that digital platforms play today in everyone's life. Unlike traditional markets, market participant behavior is easily observable in these markets. We present a series of empirical investigations into the extent to which Amazon engages in practices that are typically described as self-preferencing. We discuss how the computer science tools used in this paper can be used in a regulatory environment that is based on algorithmic auditing and requires regulating digital markets at scale.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20026;&#29992;&#25143;&#20986;&#21457;&#22320;&#21487;&#21040;&#36798;&#30340;&#22478;&#24066;&#26053;&#34892;&#20998;&#37197;&#21487;&#25345;&#32493;&#24615;&#25351;&#26631;&#65288;SF&#25351;&#25968;&#65289;&#12290;</title><link>https://arxiv.org/abs/2403.18604</link><description>&lt;p&gt;
&#24314;&#27169;&#21487;&#25345;&#32493;&#22478;&#24066;&#26053;&#34892;&#65306;&#23558;CO2&#25490;&#25918;&#12289;&#28909;&#24230;&#21644;&#23395;&#33410;&#24615;&#25972;&#21512;&#21040;&#26053;&#28216;&#25512;&#33616;&#31995;&#32479;&#20013;
&lt;/p&gt;
&lt;p&gt;
Modeling Sustainable City Trips: Integrating CO2 Emissions, Popularity, and Seasonality into Tourism Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18604
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20026;&#29992;&#25143;&#20986;&#21457;&#22320;&#21487;&#21040;&#36798;&#30340;&#22478;&#24066;&#26053;&#34892;&#20998;&#37197;&#21487;&#25345;&#32493;&#24615;&#25351;&#26631;&#65288;SF&#25351;&#25968;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#36807;&#36733;&#21644;&#22797;&#26434;&#20915;&#31574;&#36807;&#31243;&#30340;&#26102;&#20195;&#65292;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#24050;&#25104;&#20026;&#21508;&#20010;&#39046;&#22495;&#19981;&#21487;&#25110;&#32570;&#30340;&#24037;&#20855;&#65292;&#23588;&#20854;&#26159;&#26053;&#34892;&#21644;&#26053;&#28216;&#39046;&#22495;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20026;&#29992;&#25143;&#20986;&#21457;&#22320;&#21487;&#21040;&#36798;&#30340;&#22478;&#24066;&#26053;&#34892;&#20998;&#37197;&#21487;&#25345;&#32493;&#24615;&#25351;&#26631;&#65288;SF&#25351;&#25968;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18604v1 Announce Type: new  Abstract: In an era of information overload and complex decision-making processes, Recommender Systems (RS) have emerged as indispensable tools across diverse domains, particularly travel and tourism. These systems simplify trip planning by offering personalized recommendations that consider individual preferences and address broader challenges like seasonality, travel regulations, and capacity constraints. The intricacies of the tourism domain, characterized by multiple stakeholders, including consumers, item providers, platforms, and society, underscore the complexity of achieving balance among diverse interests. Although previous research has focused on fairness in Tourism Recommender Systems (TRS) from a multistakeholder perspective, limited work has focused on generating sustainable recommendations.   Our paper introduces a novel approach for assigning a sustainability indicator (SF index) for city trips accessible from the users' starting po
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39038;&#23458;&#34892;&#20026;&#30340;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#39038;&#23458;&#22312;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#33258;&#28982;&#34892;&#20026;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;&#25512;&#33616;&#32467;&#26524;</title><link>https://arxiv.org/abs/2403.18536</link><description>&lt;p&gt;
&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#34892;&#20026;&#30340;&#30005;&#23376;&#21830;&#21153;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Novel Behavior-Based Recommendation System for E-commerce
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18536
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39038;&#23458;&#34892;&#20026;&#30340;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#39038;&#23458;&#22312;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#33258;&#28982;&#34892;&#20026;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;&#25512;&#33616;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#25512;&#33616;&#31995;&#32479;&#20381;&#36182;&#20110;&#29992;&#25143;&#35780;&#20998;&#65292;&#36825;&#21463;&#21040;&#29992;&#25143;&#21327;&#20316;&#27424;&#32570;&#21644;&#31232;&#30095;&#38382;&#39064;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34892;&#20026;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#39038;&#23458;&#22312;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#33258;&#28982;&#34892;&#20026;&#65292;&#22914;&#27983;&#35272;&#21644;&#28857;&#20987;&#12290;&#25552;&#20986;&#30340;&#25512;&#33616;&#31995;&#32479;&#28041;&#21450;&#23545;&#27963;&#36291;&#39038;&#23458;&#36827;&#34892;&#32858;&#31867;&#12289;&#30830;&#23450;&#37051;&#22495;&#12289;&#25910;&#38598;&#30456;&#20284;&#29992;&#25143;&#12289;&#22522;&#20110;&#30456;&#20284;&#29992;&#25143;&#35745;&#31639;&#20135;&#21697;&#22768;&#35465;&#20197;&#21450;&#25512;&#33616;&#39640;&#22768;&#35465;&#20135;&#21697;&#12290;&#20026;&#20102;&#20811;&#26381;&#39038;&#23458;&#34892;&#20026;&#21644;&#20256;&#32479;&#32858;&#31867;&#26041;&#27861;&#30340;&#22797;&#26434;&#24615;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20135;&#21697;&#31867;&#21035;&#30340;&#26080;&#30417;&#30563;&#32858;&#31867;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#25512;&#33616;&#26041;&#27861;&#12290;&#35813;&#30740;&#31350;&#22312;&#20960;&#20010;&#26041;&#38754;&#20570;&#20986;&#20102;&#26174;&#33879;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18536v1 Announce Type: cross  Abstract: The majority of existing recommender systems rely on user ratings, which are limited by the lack of user collaboration and the sparsity problem. To address these issues, this study proposes a behavior-based recommender system that leverages customers' natural behaviors, such as browsing and clicking, on e-commerce platforms. The proposed recommendation system involves clustering active customers, determining neighborhoods, collecting similar users, calculating product reputation based on similar users, and recommending high-reputation products. To overcome the complexity of customer behaviors and traditional clustering methods, an unsupervised clustering approach based on product categories is developed to enhance the recommendation methodology. This study makes notable contributions in several aspects. Firstly, a groundbreaking behavior-based recommendation methodology is developed, incorporating customer behavior to generate accurate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#21327;&#20316;&#29983;&#25104;&#24335;&#25512;&#33616;&#31995;&#32479;ColaRec&#65292;&#26088;&#22312;&#35299;&#20915;&#29983;&#25104;&#24335;&#25512;&#33616;&#20013;&#30340;&#21327;&#20316;&#20449;&#21495;&#38598;&#25104;&#21644;&#20449;&#24687;&#23545;&#40784;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.18480</link><description>&lt;p&gt;
&#36890;&#36807;&#20869;&#23481;&#21644;&#21327;&#20316;&#38598;&#25104;&#22686;&#24378;&#29983;&#25104;&#24335;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Enhanced Generative Recommendation via Content and Collaboration Integration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18480
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#21327;&#20316;&#29983;&#25104;&#24335;&#25512;&#33616;&#31995;&#32479;ColaRec&#65292;&#26088;&#22312;&#35299;&#20915;&#29983;&#25104;&#24335;&#25512;&#33616;&#20013;&#30340;&#21327;&#20316;&#20449;&#21495;&#38598;&#25104;&#21644;&#20449;&#24687;&#23545;&#40784;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#25512;&#33616;&#24050;&#32463;&#20986;&#29616;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#33539;&#24335;&#65292;&#26088;&#22312;&#36890;&#36807;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#26368;&#26032;&#36827;&#23637;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#12290;&#26412;&#20219;&#21153;&#34987;&#21046;&#23450;&#20026;&#19968;&#20010;&#24207;&#21015;&#21040;&#24207;&#21015;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#20854;&#20013;&#36755;&#20837;&#24207;&#21015;&#21253;&#21547;&#19982;&#29992;&#25143;&#20808;&#21069;&#20132;&#20114;&#30340;&#39033;&#30446;&#30456;&#20851;&#30340;&#25968;&#25454;&#65292;&#36755;&#20986;&#24207;&#21015;&#34920;&#31034;&#24314;&#35758;&#39033;&#30446;&#30340;&#29983;&#25104;&#26631;&#35782;&#31526;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29983;&#25104;&#24335;&#25512;&#33616;&#26041;&#27861;&#20173;&#28982;&#38754;&#20020;&#30528;&#20197;&#19979;&#25361;&#25112;&#65306;&#26377;&#25928;&#22320;&#22312;&#32479;&#19968;&#29983;&#25104;&#26694;&#26550;&#20869;&#38598;&#25104;&#29992;&#25143;-&#39033;&#30446;&#21327;&#20316;&#20449;&#21495;&#21644;&#39033;&#30446;&#20869;&#23481;&#20449;&#24687;&#65292;&#20197;&#21450;&#22312;&#20869;&#23481;&#20449;&#24687;&#21644;&#21327;&#20316;&#20449;&#21495;&#20043;&#38388;&#25191;&#34892;&#39640;&#25928;&#30340;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18480v1 Announce Type: new  Abstract: Generative recommendation has emerged as a promising paradigm aimed at augmenting recommender systems with recent advancements in generative artificial intelligence. This task has been formulated as a sequence-to-sequence generation process, wherein the input sequence encompasses data pertaining to the user's previously interacted items, and the output sequence denotes the generative identifier for the suggested item. However, existing generative recommendation approaches still encounter challenges in (i) effectively integrating user-item collaborative signals and item content information within a unified generative framework, and (ii) executing an efficient alignment between content information and collaborative signals.   In this paper, we introduce content-based collaborative generation for recommender systems, denoted as ColaRec. To capture collaborative signals, the generative item identifiers are derived from a pretrained collabora
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#23884;&#20837;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#23398;&#20064;&#29992;&#25143;/&#39033;&#30446;&#30340;&#32034;&#24341;&#21040;&#20803;&#23884;&#20837;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.18479</link><description>&lt;p&gt;
&#36731;&#37327;&#32423;&#23884;&#20837;&#29992;&#20110;&#22270;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Lightweight Embeddings for Graph Collaborative Filtering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18479
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#23884;&#20837;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#23398;&#20064;&#29992;&#25143;/&#39033;&#30446;&#30340;&#32034;&#24341;&#21040;&#20803;&#23884;&#20837;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30446;&#21069;&#26159;&#26368;&#26377;&#25928;&#30340;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20351;&#29992;&#23884;&#20837;&#34920;&#26469;&#34920;&#31034;&#27599;&#20010;&#29992;&#25143;/&#39033;&#30446;&#20026;&#19981;&#21516;&#30340;&#21521;&#37327;&#65292;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#32487;&#25215;&#20102;&#21442;&#25968;&#25928;&#29575;&#20302;&#19979;&#30340;&#38271;&#26399;&#32570;&#38519;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#23884;&#20837;&#26041;&#27861;&#65292;&#21363;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#33258;&#21160;&#23398;&#20064;&#29992;&#25143;/&#39033;&#30446;&#30340;&#32034;&#24341;&#21040;&#23545;&#24212;&#30340;&#20803;&#23884;&#20837;&#20043;&#38388;&#30340;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18479v1 Announce Type: new  Abstract: Graph neural networks (GNNs) are currently one of the most performant collaborative filtering methods. Meanwhile, owing to the use of an embedding table to represent each user/item as a distinct vector, GNN-based recommenders have inherited the long-standing defect of parameter inefficiency. As a common practice for scalable embeddings, parameter sharing enables the use of fewer embedding vectors (i.e., meta-embeddings). When assigning meta-embeddings, most existing methods are a heuristically designed, predefined mapping from each user's/item's ID to the corresponding meta-embedding indexes, thus simplifying the optimization problem into learning only the meta-embeddings. However, in the context of GNN-based collaborative filtering, such a fixed mapping omits the semantic correlations between entities that are evident in the user-item interaction graph, leading to suboptimal recommendation performance. To this end, we propose Lightweigh
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#35825;&#39285;&#25928;&#24212;&#23545;&#29992;&#25143;&#25628;&#32034;&#20132;&#20114;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#34913;&#37327;IR&#31995;&#32479;&#33030;&#24369;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;DEJA-VU&#25351;&#26631;&#26469;&#35780;&#20272;&#31995;&#32479;&#23545;&#35825;&#39285;&#25928;&#24212;&#30340;&#26131;&#24863;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.18462</link><description>&lt;p&gt;
&#25628;&#32034;&#20132;&#20114;&#20013;&#30340;&#35825;&#39285;&#25928;&#24212;&#65306;&#29702;&#35299;&#29992;&#25143;&#34892;&#20026;&#21644;&#27979;&#37327;&#31995;&#32479;&#33030;&#24369;&#24615;
&lt;/p&gt;
&lt;p&gt;
Decoy Effect In Search Interaction: Understanding User Behavior and Measuring System Vulnerability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18462
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#35825;&#39285;&#25928;&#24212;&#23545;&#29992;&#25143;&#25628;&#32034;&#20132;&#20114;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#34913;&#37327;IR&#31995;&#32479;&#33030;&#24369;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;DEJA-VU&#25351;&#26631;&#26469;&#35780;&#20272;&#31995;&#32479;&#23545;&#35825;&#39285;&#25928;&#24212;&#30340;&#26131;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#35825;&#39285;&#25928;&#24212;&#23545;&#29992;&#25143;&#25628;&#32034;&#20132;&#20114;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#34913;&#37327;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#31995;&#32479;&#23545;&#36825;&#31181;&#24433;&#21709;&#30340;&#33030;&#24369;&#24615;&#30340;&#26041;&#27861;&#12290;&#23427;&#25506;&#35752;&#20102;&#35825;&#39285;&#32467;&#26524;&#22914;&#20309;&#25913;&#21464;&#29992;&#25143;&#22312;&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;&#19978;&#30340;&#20132;&#20114;&#65292;&#20851;&#27880;&#28857;&#20987;&#27010;&#29575;&#12289;&#27983;&#35272;&#26102;&#38388;&#21644;&#24863;&#30693;&#25991;&#26723;&#26377;&#29992;&#24615;&#31561;&#25351;&#26631;&#12290;&#36890;&#36807;&#20998;&#26512;&#26469;&#33258;&#22810;&#20010;&#25968;&#25454;&#38598;&#30340;&#29992;&#25143;&#20132;&#20114;&#26085;&#24535;&#65292;&#30740;&#31350;&#34920;&#26126;&#35825;&#39285;&#32467;&#26524;&#26174;&#33879;&#24433;&#21709;&#29992;&#25143;&#34892;&#20026;&#21644;&#24863;&#30693;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#35843;&#26597;&#20102;&#19981;&#21516;&#20219;&#21153;&#38590;&#24230;&#21644;&#29992;&#25143;&#30693;&#35782;&#27700;&#24179;&#22914;&#20309;&#20462;&#25913;&#35825;&#39285;&#25928;&#24212;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#26356;&#23481;&#26131;&#30340;&#20219;&#21153;&#21644;&#36739;&#20302;&#30340;&#30693;&#35782;&#27700;&#24179;&#20250;&#23548;&#33268;&#26356;&#39640;&#30340;&#30446;&#26631;&#25991;&#26723;&#21442;&#19982;&#24230;&#12290;&#22312;IR&#31995;&#32479;&#35780;&#20272;&#26041;&#38754;&#65292;&#30740;&#31350;&#24341;&#20837;&#20102;DEJA-VU&#25351;&#26631;&#26469;&#35780;&#20272;&#31995;&#32479;&#23545;&#35825;&#39285;&#25928;&#24212;&#30340;&#26131;&#24863;&#24615;&#65292;&#24182;&#22312;&#29305;&#23450;&#26816;&#32034;&#20219;&#21153;&#19978;&#36827;&#34892;&#27979;&#35797;&#12290;&#32467;&#26524;&#26174;&#31034;&#22312;&#31995;&#32479;&#19978;&#23384;&#22312;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18462v1 Announce Type: new  Abstract: This study examines the decoy effect's underexplored influence on user search interactions and methods for measuring information retrieval (IR) systems' vulnerability to this effect. It explores how decoy results alter users' interactions on search engine result pages, focusing on metrics like click-through likelihood, browsing time, and perceived document usefulness. By analyzing user interaction logs from multiple datasets, the study demonstrates that decoy results significantly affect users' behavior and perceptions. Furthermore, it investigates how different levels of task difficulty and user knowledge modify the decoy effect's impact, finding that easier tasks and lower knowledge levels lead to higher engagement with target documents. In terms of IR system evaluation, the study introduces the DEJA-VU metric to assess systems' susceptibility to the decoy effect, testing it on specific retrieval tasks. The results show differences in 
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;DELTA&#65292;&#21033;&#29992;&#32467;&#26500;&#21270;&#35789;&#23545;&#40784;&#39044;&#35757;&#32451;&#21028;&#21035;&#24335;&#32534;&#30721;&#22120;&#36827;&#34892;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#65292;&#36890;&#36807;&#24378;&#35843;&#20851;&#38190;&#20107;&#23454;&#26469;&#25552;&#39640;&#34920;&#31034;&#30340;&#21028;&#21035;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.18435</link><description>&lt;p&gt;
&#21033;&#29992;&#32467;&#26500;&#21270;&#35789;&#23545;&#40784;&#39044;&#35757;&#32451;&#21028;&#21035;&#24335;&#32534;&#30721;&#22120;&#36827;&#34892;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
DELTA: Pre-train a Discriminative Encoder for Legal Case Retrieval via Structural Word Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18435
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;DELTA&#65292;&#21033;&#29992;&#32467;&#26500;&#21270;&#35789;&#23545;&#40784;&#39044;&#35757;&#32451;&#21028;&#21035;&#24335;&#32534;&#30721;&#22120;&#36827;&#34892;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#65292;&#36890;&#36807;&#24378;&#35843;&#20851;&#38190;&#20107;&#23454;&#26469;&#25552;&#39640;&#34920;&#31034;&#30340;&#21028;&#21035;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#26159;&#26377;&#25928;&#30340;&#12290;&#29616;&#26377;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#20391;&#37325;&#20110;&#25552;&#39640;[CLS]&#26631;&#35760;&#30340;&#19978;&#19979;&#25991;&#23884;&#20837;&#30340;&#34920;&#24449;&#33021;&#21147;&#65292;&#24182;&#20351;&#29992;&#25991;&#26412;&#35821;&#20041;&#30456;&#20284;&#24615;&#35745;&#31639;&#30456;&#20851;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#27861;&#24459;&#39046;&#22495;&#65292;&#25991;&#26412;&#35821;&#20041;&#30456;&#20284;&#24615;&#24182;&#19981;&#24635;&#26159;&#24847;&#21619;&#30528;&#26696;&#20363;&#20043;&#38388;&#36275;&#22815;&#30456;&#20851;&#12290;&#30456;&#21453;&#65292;&#22312;&#27861;&#24459;&#26696;&#20363;&#20013;&#65292;&#30456;&#20851;&#24615;&#20027;&#35201;&#21462;&#20915;&#20110;&#24433;&#21709;&#26368;&#32456;&#21028;&#20915;&#30340;&#20851;&#38190;&#20107;&#23454;&#30340;&#30456;&#20284;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DELTA&#65292;&#36825;&#26159;&#19968;&#20010;&#20026;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#35774;&#35745;&#30340;&#21028;&#21035;&#24335;&#27169;&#22411;&#12290;&#22522;&#26412;&#24605;&#24819;&#26159;&#22312;&#27861;&#24459;&#26696;&#20363;&#20013;&#25214;&#21040;&#20851;&#38190;&#20107;&#23454;&#65292;&#24182;&#23558;[CLS]&#26631;&#35760;&#30340;&#19978;&#19979;&#25991;&#23884;&#20837;&#36924;&#36817;&#36825;&#20123;&#20851;&#38190;&#20107;&#23454;&#65292;&#21516;&#26102;&#36828;&#31163;&#38750;&#20851;&#38190;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18435v1 Announce Type: cross  Abstract: Recent research demonstrates the effectiveness of using pre-trained language models for legal case retrieval. Most of the existing works focus on improving the representation ability for the contextualized embedding of the [CLS] token and calculate relevance using textual semantic similarity. However, in the legal domain, textual semantic similarity does not always imply that the cases are relevant enough. Instead, relevance in legal cases primarily depends on the similarity of key facts that impact the final judgment. Without proper treatments, the discriminative ability of learned representations could be limited since legal cases are lengthy and contain numerous non-key facts. To this end, we introduce DELTA, a discriminative model designed for legal case retrieval. The basic idea involves pinpointing key facts in legal cases and pulling the contextualized embedding of the [CLS] token closer to the key facts while pushing away from 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20851;&#31995;&#24863;&#30693;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#28508;&#22312;&#20851;&#31995;&#21457;&#29616;&#65288;LRD&#65289;&#25552;&#21319;&#20102;&#25512;&#33616;&#31995;&#32479;&#22312;&#21508;&#31181;&#22330;&#26223;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.18348</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20851;&#31995;&#24863;&#30693;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Sequential Recommendation with Latent Relations based on Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18348
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20851;&#31995;&#24863;&#30693;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#28508;&#22312;&#20851;&#31995;&#21457;&#29616;&#65288;LRD&#65289;&#25552;&#21319;&#20102;&#25512;&#33616;&#31995;&#32479;&#22312;&#21508;&#31181;&#22330;&#26223;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18348v1 &#22768;&#26126;&#31867;&#22411;: &#26032;&#30340;&#25688;&#35201;: &#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#36890;&#36807;&#24314;&#27169;&#29992;&#25143;&#22522;&#20110;&#21382;&#21490;&#20114;&#21160;&#30340;&#20559;&#22909;&#26469;&#39044;&#27979;&#21487;&#33021;&#21560;&#24341;&#29992;&#25143;&#30340;&#39033;&#30446;&#12290;&#20256;&#32479;&#30340;&#39034;&#24207;&#25512;&#33616;&#26041;&#27861;&#20381;&#36182;&#20110;&#25429;&#33719;&#39033;&#30446;&#20043;&#38388;&#30340;&#38544;&#24615;&#21327;&#20316;&#36807;&#28388;&#20449;&#21495;&#12290;&#26368;&#36817;&#30340;&#22522;&#20110;&#20851;&#31995;&#24863;&#30693;&#30340;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#36890;&#36807;&#23558;&#39033;&#30446;&#20851;&#31995;&#26126;&#30830;&#32435;&#20837;&#29992;&#25143;&#21382;&#21490;&#24207;&#21015;&#30340;&#24314;&#27169;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#26399;&#24453;&#30340;&#24615;&#33021;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#20851;&#31995;&#26469;&#33258;&#30693;&#35782;&#22270;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#25163;&#21160;&#39044;&#23450;&#20041;&#30340;&#20851;&#31995;&#65292;&#24182;&#21463;&#21040;&#31232;&#30095;&#38382;&#39064;&#30340;&#22256;&#25200;&#65292;&#38480;&#21046;&#20102;&#22312;&#20855;&#26377;&#19981;&#21516;&#39033;&#30446;&#20851;&#31995;&#30340;&#21508;&#31181;&#22330;&#26223;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#20851;&#31995;&#21457;&#29616;&#65288;LRD&#65289;&#30340;&#26032;&#39062;&#20851;&#31995;&#24863;&#30693;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#12290;&#19982;&#20197;&#24448;&#20381;&#36182;&#39044;&#23450;&#20041;&#35268;&#21017;&#30340;&#20851;&#31995;&#24863;&#30693;&#27169;&#22411;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#35758;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25552;&#20379;&#26032;&#31867;&#22411;&#30340;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18348v1 Announce Type: new  Abstract: Sequential recommender systems predict items that may interest users by modeling their preferences based on historical interactions. Traditional sequential recommendation methods rely on capturing implicit collaborative filtering signals among items. Recent relation-aware sequential recommendation models have achieved promising performance by explicitly incorporating item relations into the modeling of user historical sequences, where most relations are extracted from knowledge graphs. However, existing methods rely on manually predefined relations and suffer the sparsity issue, limiting the generalization ability in diverse scenarios with varied item relations. In this paper, we propose a novel relation-aware sequential recommendation framework with Latent Relation Discovery (LRD). Different from previous relation-aware models that rely on predefined rules, we propose to leverage the Large Language Model (LLM) to provide new types of re
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#19990;&#30028;&#30693;&#35782;&#26469;&#22686;&#24378;&#22522;&#20110;&#24120;&#35782;&#30340;&#30693;&#35782;&#25512;&#33616;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#20808;&#21069;&#24037;&#20316;&#20013;&#30693;&#35782;&#22270;&#30340;&#23616;&#38480;&#24615;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.18325</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#22522;&#20110;&#24120;&#35782;&#30340;&#30693;&#35782;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Common Sense Enhanced Knowledge-based Recommendation with Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18325
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#19990;&#30028;&#30693;&#35782;&#26469;&#22686;&#24378;&#22522;&#20110;&#24120;&#35782;&#30340;&#30693;&#35782;&#25512;&#33616;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#20808;&#21069;&#24037;&#20316;&#20013;&#30693;&#35782;&#22270;&#30340;&#23616;&#38480;&#24615;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#25512;&#33616;&#27169;&#22411;&#26377;&#25928;&#22320;&#32531;&#35299;&#20102;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#65292;&#21033;&#29992;&#30693;&#35782;&#22270;&#20013;&#30340;&#20391;&#38754;&#20449;&#24687;&#65292;&#24182;&#21462;&#24471;&#20102;&#30456;&#24403;&#21487;&#35266;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#20351;&#29992;&#30340;&#30693;&#35782;&#22270;&#65292;&#21363;&#22522;&#20110;&#20803;&#25968;&#25454;&#30340;&#30693;&#35782;&#22270;&#65292;&#36890;&#24120;&#26159;&#22522;&#20110;&#29289;&#21697;&#30340;&#23646;&#24615;&#21644;&#20849;&#29616;&#20851;&#31995;&#65288;&#20363;&#22914;&#65292;&#20063;&#36141;&#20080;&#65289;&#26500;&#24314;&#30340;&#65292;&#21069;&#32773;&#25552;&#20379;&#26377;&#38480;&#20449;&#24687;&#65292;&#21518;&#32773;&#20381;&#36182;&#20805;&#20998;&#30340;&#20132;&#20114;&#25968;&#25454;&#65292;&#20173;&#28982;&#21463;&#20919;&#21551;&#21160;&#38382;&#39064;&#22256;&#25200;&#12290;&#20316;&#20026;&#19968;&#31181;&#20855;&#26377;&#27010;&#25324;&#24615;&#21644;&#26222;&#36866;&#24615;&#30340;&#30693;&#35782;&#24418;&#24335;&#65292;&#24120;&#35782;&#21487;&#20197;&#20316;&#20026;&#20803;&#25968;&#25454;&#30693;&#35782;&#22270;&#30340;&#34917;&#20805;&#65292;&#24182;&#20026;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#25552;&#20379;&#26032;&#35270;&#35282;&#12290;&#26368;&#36817;&#65292;&#21463;&#30410;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#20852;&#19990;&#30028;&#30693;&#35782;&#65292;&#39640;&#25928;&#33719;&#21462;&#24120;&#35782;&#21464;&#24471;&#21487;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#33616;&#26694;&#26550; incor
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18325v1 Announce Type: new  Abstract: Knowledge-based recommendation models effectively alleviate the data sparsity issue leveraging the side information in the knowledge graph, and have achieved considerable performance. Nevertheless, the knowledge graphs used in previous work, namely metadata-based knowledge graphs, are usually constructed based on the attributes of items and co-occurring relations (e.g., also buy), in which the former provides limited information and the latter relies on sufficient interaction data and still suffers from cold start issue. Common sense, as a form of knowledge with generality and universality, can be used as a supplement to the metadata-based knowledge graph and provides a new perspective for modeling users' preferences. Recently, benefiting from the emergent world knowledge of the large language model, efficient acquisition of common sense has become possible. In this paper, we propose a novel knowledge-based recommendation framework incor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#24773;&#22659;&#20316;&#20026;&#29992;&#25143;&#20132;&#20114;&#30340;&#21069;&#25552;&#26465;&#20214;&#30340;&#26032;&#35270;&#35282;&#65292;&#24182;&#22522;&#20110;&#27492;&#35774;&#35745;&#20102;&#19968;&#31181;&#38754;&#21521;&#24773;&#22659;&#30340;&#25512;&#33616;&#31995;&#32479;&#22686;&#24378;&#22120;&#12290;</title><link>https://arxiv.org/abs/2403.18317</link><description>&lt;p&gt;
&#19968;&#31181;&#38754;&#21521;&#24773;&#22659;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#22686;&#24378;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Situation-aware Enhancer for Personalized Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18317
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#24773;&#22659;&#20316;&#20026;&#29992;&#25143;&#20132;&#20114;&#30340;&#21069;&#25552;&#26465;&#20214;&#30340;&#26032;&#35270;&#35282;&#65292;&#24182;&#22522;&#20110;&#27492;&#35774;&#35745;&#20102;&#19968;&#31181;&#38754;&#21521;&#24773;&#22659;&#30340;&#25512;&#33616;&#31995;&#32479;&#22686;&#24378;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#29992;&#25143;&#19982;&#25512;&#33616;&#31995;&#32479;&#65288;RecSys&#65289;&#20132;&#20114;&#26102;&#65292;&#24403;&#21069;&#30340;&#24773;&#22659;&#65292;&#27604;&#22914;&#26102;&#38388;&#12289;&#22320;&#28857;&#21644;&#29615;&#22659;&#65292;&#26174;&#33879;&#24433;&#21709;&#20182;&#20204;&#30340;&#20559;&#22909;&#12290;&#24773;&#22659;&#20316;&#20026;&#20132;&#20114;&#30340;&#32972;&#26223;&#65292;&#29992;&#25143;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#20851;&#31995;&#38543;&#30528;&#24773;&#22659;&#21464;&#21270;&#32780;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;RecSys&#23558;&#24773;&#22659;&#12289;&#29992;&#25143;&#21644;&#29289;&#21697;&#35270;&#20026;&#21516;&#19968;&#32423;&#21035;&#12290;&#23427;&#20204;&#21482;&#33021;&#20998;&#21035;&#24314;&#27169;&#24773;&#22659;&#19982;&#29992;&#25143;/&#29289;&#21697;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#32780;&#26080;&#27861;&#24314;&#27169;&#24773;&#22659;&#21160;&#24577;&#23545;&#29992;&#25143;-&#29289;&#21697;&#20851;&#32852;&#65288;&#21363;&#29992;&#25143;&#20559;&#22909;&#65289;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#24773;&#22659;&#35270;&#20026;&#29992;&#25143;&#20132;&#20114;&#30340;&#21069;&#25552;&#26465;&#20214;&#30340;&#26032;&#35270;&#35282;&#12290;&#36825;&#20010;&#35270;&#35282;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#24773;&#22659;&#19982;&#29992;&#25143;/&#29289;&#21697;&#34920;&#31034;&#20998;&#24320;&#65292;&#24182;&#25429;&#25417;&#24773;&#22659;&#23545;&#29992;&#25143;-&#29289;&#21697;&#20851;&#31995;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#26356;&#20840;&#38754;&#22320;&#29702;&#35299;&#24773;&#22659;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#38754;&#21521;&#24773;&#22659;&#30340;&#25512;&#33616;&#22686;&#24378;&#22120;&#65288;SARE&#65289;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18317v1 Announce Type: new  Abstract: When users interact with Recommender Systems (RecSys), current situations, such as time, location, and environment, significantly influence their preferences. Situations serve as the background for interactions, where relationships between users and items evolve with situation changes. However, existing RecSys treat situations, users, and items on the same level. They can only model the relations between situations and users/items respectively, rather than the dynamic impact of situations on user-item associations (i.e., user preferences). In this paper, we provide a new perspective that takes situations as the preconditions for users' interactions. This perspective allows us to separate situations from user/item representations, and capture situations' influences over the user-item relationship, offering a more comprehensive understanding of situations. Based on it, we propose a novel Situation-Aware Recommender Enhancer (SARE), a plugg
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;NFT&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#32508;&#21512;&#21033;&#29992;NFT&#20132;&#26131;&#35760;&#24405;&#21644;&#22806;&#37096;&#39033;&#30446;&#29305;&#24449;&#31561;&#22810;&#31181;&#25968;&#25454;&#28304;&#65292;&#36890;&#36807;&#25968;&#25454;&#39640;&#25928;&#30340;&#22522;&#20110;&#22270;&#30340;&#26041;&#27861;&#29983;&#25104;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#24182;&#21033;&#29992;&#36229;&#20986;&#29992;&#25143;-&#39033;&#30446;&#20114;&#21160;&#30340;&#36755;&#20837;&#39564;&#35777;&#20102;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.18305</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#39033;&#30446;&#29305;&#24449;&#30340;NFT&#21487;&#25910;&#34255;&#21697;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Recommender System for NFT Collectibles with Item Feature
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18305
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;NFT&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#32508;&#21512;&#21033;&#29992;NFT&#20132;&#26131;&#35760;&#24405;&#21644;&#22806;&#37096;&#39033;&#30446;&#29305;&#24449;&#31561;&#22810;&#31181;&#25968;&#25454;&#28304;&#65292;&#36890;&#36807;&#25968;&#25454;&#39640;&#25928;&#30340;&#22522;&#20110;&#22270;&#30340;&#26041;&#27861;&#29983;&#25104;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#24182;&#21033;&#29992;&#36229;&#20986;&#29992;&#25143;-&#39033;&#30446;&#20114;&#21160;&#30340;&#36755;&#20837;&#39564;&#35777;&#20102;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#34987;&#31215;&#26497;&#30740;&#31350;&#24182;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#20197;&#35299;&#20915;&#20449;&#24687;&#36807;&#36733;&#38382;&#39064;&#12290;&#23613;&#31649;&#26377;&#35768;&#22810;&#20851;&#20110;&#30005;&#24433;&#12289;&#38899;&#20048;&#21644;&#30005;&#23376;&#21830;&#21153;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#30740;&#31350;&#65292;&#20294;&#30456;&#27604;&#20043;&#19979;&#65292;&#23613;&#31649;NFT&#24066;&#22330;&#25345;&#32493;&#22686;&#38271;&#65292;&#23545;&#20110;NFT&#30340;&#25512;&#33616;&#31995;&#32479;&#21364;&#21463;&#21040;&#20102;&#30456;&#23545;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;NFT&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#21508;&#31181;&#25968;&#25454;&#28304;&#65292;&#20174;NFT&#20132;&#26131;&#35760;&#24405;&#21040;&#22806;&#37096;&#39033;&#30446;&#29305;&#24449;&#65292;&#29983;&#25104;&#31526;&#21512;&#20010;&#20154;&#20559;&#22909;&#30340;&#31934;&#30830;&#25512;&#33616;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#26377;&#25928;&#25429;&#25417;&#27599;&#20010;&#39033;&#30446;&#19982;&#29992;&#25143;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#29983;&#25104;&#21253;&#21547;&#33410;&#28857;&#29305;&#24449;&#20449;&#24687;&#21644;&#22270;&#32467;&#26500;&#30340;&#33410;&#28857;&#65288;&#39033;&#30446;&#65289;&#23884;&#20837;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#36229;&#20986;&#29992;&#25143;-&#39033;&#30446;&#20114;&#21160;&#30340;&#36755;&#20837;&#65292;&#22914;&#22270;&#20687;&#29305;&#24449;&#12289;&#25991;&#26412;&#29305;&#24449;&#21644;&#20215;&#26684;&#29305;&#24449;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18305v1 Announce Type: cross  Abstract: Recommender systems have been actively studied and applied in various domains to deal with information overload. Although there are numerous studies on recommender systems for movies, music, and e-commerce, comparatively less attention has been paid to the recommender system for NFTs despite the continuous growth of the NFT market. This paper presents a recommender system for NFTs that utilizes a variety of data sources, from NFT transaction records to external item features, to generate precise recommendations that cater to individual preferences. We develop a data-efficient graph-based recommender system to efficiently capture the complex relationship between each item and users and generate node(item) embeddings which incorporate both node feature information and graph structure. Furthermore, we exploit inputs beyond user-item interactions, such as image feature, text feature, and price feature. Numerical experiments verify the perf
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#20013;&#38750;&#35789;&#27719;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#36807;&#30340;&#26032;&#29992;&#25143;&#21644;&#29289;&#21697;&#65292;&#36890;&#36807;&#26356;&#22909;&#22320;&#21033;&#29992;&#21487;&#29992;&#30340;&#29992;&#25143;/&#29289;&#21697;&#29305;&#24449;&#26469;&#25913;&#21892;&#23884;&#20837;&#34920;&#20013;&#30340;&#38750;&#35789;&#27719;&#22788;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.18280</link><description>&lt;p&gt;
&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38750;&#35789;&#27719;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Improving Out-of-Vocabulary Handling in Recommendation Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#20013;&#38750;&#35789;&#27719;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#36807;&#30340;&#26032;&#29992;&#25143;&#21644;&#29289;&#21697;&#65292;&#36890;&#36807;&#26356;&#22909;&#22320;&#21033;&#29992;&#21487;&#29992;&#30340;&#29992;&#25143;/&#29289;&#21697;&#29305;&#24449;&#26469;&#25913;&#21892;&#23884;&#20837;&#34920;&#20013;&#30340;&#38750;&#35789;&#27719;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#37117;&#26159;&#19968;&#20010;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#39046;&#22495;&#65292;&#22240;&#20026;&#23427;&#20204;&#23545;&#25968;&#21313;&#20159;&#29992;&#25143;&#30340;&#26085;&#24120;&#22312;&#32447;&#20307;&#39564;&#26377;&#30528;&#24191;&#27867;&#24433;&#21709;&#12290;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#26159;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#21644;&#29289;&#21697;&#21487;&#33021;&#27809;&#26377;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#25512;&#33616;&#12290;&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#21478;&#19968;&#20010;&#38382;&#39064;&#65306;&#22312;&#35757;&#32451;&#26102;&#25512;&#33616;&#26410;&#35265;&#36807;&#30340;&#26032;&#29992;&#25143;&#21644;&#29289;&#21697;&#65288;&#38750;&#35789;&#27719;&#65292;&#25110;OOV&#65289;&#12290;&#36825;&#31181;&#24773;&#20917;&#34987;&#31216;&#20026;&#24402;&#32435;&#35774;&#32622;&#65292;&#23545;&#20110;&#22522;&#20110;&#22240;&#23376;&#20998;&#35299;&#30340;&#27169;&#22411;&#29305;&#21035;&#26377;&#38382;&#39064;&#65292;&#22240;&#20026;&#36825;&#20123;&#27169;&#22411;&#20165;&#20381;&#36182;&#20110;&#22312;&#35757;&#32451;&#26102;&#30475;&#21040;&#30340;&#29992;&#25143;/&#29289;&#21697;&#26469;&#32534;&#30721;&#22266;&#23450;&#30340;&#21442;&#25968;&#21521;&#37327;&#12290;&#35768;&#22810;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;&#23454;&#36341;&#20013;&#24448;&#24448;&#24456;&#22825;&#30495;&#65292;&#27604;&#22914;&#23558;OOV&#29992;&#25143;/&#29289;&#21697;&#20998;&#37197;&#21040;&#38543;&#26426;&#26742;&#20013;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#21033;&#29992;&#21487;&#29992;&#29992;&#25143;/&#29289;&#21697;&#29305;&#24449;&#26469;&#25913;&#36827;&#23884;&#20837;&#34920;&#20013;OOV&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18280v1 Announce Type: new  Abstract: Recommendation systems (RS) are an increasingly relevant area for both academic and industry researchers, given their widespread impact on the daily online experiences of billions of users. One common issue in real RS is the cold-start problem, where users and items may not contain enough information to produce high-quality recommendations. This work focuses on a complementary problem: recommending new users and items unseen (out-of-vocabulary, or OOV) at training time. This setting is known as the inductive setting and is especially problematic for factorization-based models, which rely on encoding only those users/items seen at training time with fixed parameter vectors. Many existing solutions applied in practice are often naive, such as assigning OOV users/items to random buckets. In this work, we tackle this problem and propose approaches that better leverage available user/item features to improve OOV handling at the embedding tabl
&lt;/p&gt;</description></item><item><title>Mamba&#27169;&#22411;&#22522;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#22312;&#22810;&#20010;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#19982;Transformer&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#32463;&#20856;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;--&#25991;&#26723;&#25490;&#21517;&#20013;&#23637;&#29616;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.18276</link><description>&lt;p&gt;
RankMamba&#65292;&#22312;Transformer&#26102;&#20195;&#23545;Mamba&#25991;&#26723;&#25490;&#21517;&#24615;&#33021;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
RankMamba, Benchmarking Mamba's Document Ranking Performance in the Era of Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18276
&lt;/p&gt;
&lt;p&gt;
Mamba&#27169;&#22411;&#22522;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#22312;&#22810;&#20010;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#19982;Transformer&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#32463;&#20856;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;--&#25991;&#26723;&#25490;&#21517;&#20013;&#23637;&#29616;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#32467;&#26500;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#65288;CV&#65289;&#21644;&#20449;&#24687;&#26816;&#32034;(IR)&#31561;&#22810;&#20010;&#24212;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;Transformer&#26550;&#26500;&#30340;&#26680;&#24515;&#26426;&#21046;--&#27880;&#24847;&#21147;&#65292;&#22312;&#35757;&#32451;&#20013;&#38656;&#35201;$O(n^2)$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#22312;&#25512;&#26029;&#20013;&#38656;&#35201;$O(n)$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#35768;&#22810;&#24037;&#20316;&#24050;&#32463;&#25552;&#20986;&#25913;&#36827;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#27604;&#22914;Flash Attention&#21644;Multi-query Attention&#12290;&#21478;&#19968;&#26041;&#38754;&#30340;&#24037;&#20316;&#26088;&#22312;&#35774;&#35745;&#26032;&#30340;&#26426;&#21046;&#26469;&#21462;&#20195;&#27880;&#24847;&#21147;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#19968;&#20010;&#26174;&#33879;&#27169;&#22411;&#32467;&#26500;--Mamba&#65292;&#22312;&#22810;&#20010;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#19982;Transformer&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18276v1 Announce Type: cross  Abstract: Transformer structure has achieved great success in multiple applied machine learning communities, such as natural language processing (NLP), computer vision (CV) and information retrieval (IR). Transformer architecture's core mechanism -- attention requires $O(n^2)$ time complexity in training and $O(n)$ time complexity in inference. Many works have been proposed to improve the attention mechanism's scalability, such as Flash Attention and Multi-query Attention. A different line of work aims to design new mechanisms to replace attention. Recently, a notable model structure -- Mamba, which is based on state space models, has achieved transformer-equivalent performance in multiple sequence modeling tasks.   In this work, we examine \mamba's efficacy through the lens of a classical IR task -- document ranking. A reranker model takes a query and a document as input, and predicts a scalar relevance score. This task demands the language mod
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20004;&#22612;&#25512;&#33616;&#27169;&#22411;&#20013;&#20351;&#29992;&#21333;&#27425;&#21453;&#21521;&#20256;&#25773;&#26356;&#26032;&#31574;&#30053;&#30340;&#26041;&#27861;&#65292;&#25361;&#25112;&#20102;&#29616;&#26377;&#31639;&#27861;&#20013;&#24179;&#31561;&#23545;&#24453;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#20551;&#35774;&#12290;</title><link>https://arxiv.org/abs/2403.18227</link><description>&lt;p&gt;
&#20004;&#22612;&#25512;&#33616;&#27169;&#22411;&#20013;&#30340;&#21333;&#27425;&#21453;&#21521;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
One Backpropagation in Two Tower Recommendation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18227
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20004;&#22612;&#25512;&#33616;&#27169;&#22411;&#20013;&#20351;&#29992;&#21333;&#27425;&#21453;&#21521;&#20256;&#25773;&#26356;&#26032;&#31574;&#30053;&#30340;&#26041;&#27861;&#65292;&#25361;&#25112;&#20102;&#29616;&#26377;&#31639;&#27861;&#20013;&#24179;&#31561;&#23545;&#24453;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#24050;&#32463;&#30475;&#21040;&#20026;&#20102;&#20943;&#36731;&#20449;&#24687;&#36807;&#36733;&#32780;&#24320;&#21457;&#20004;&#22612;&#25512;&#33616;&#27169;&#22411;&#30340;&#24191;&#27867;&#30740;&#31350;&#12290;&#36825;&#31181;&#27169;&#22411;&#20013;&#21487;&#20197;&#35782;&#21035;&#20986;&#22235;&#20010;&#26500;&#24314;&#27169;&#22359;&#65292;&#20998;&#21035;&#26159;&#29992;&#25143;-&#29289;&#21697;&#32534;&#30721;&#12289;&#36127;&#37319;&#26679;&#12289;&#25439;&#22833;&#35745;&#31639;&#21644;&#21453;&#21521;&#20256;&#25773;&#26356;&#26032;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#29616;&#26377;&#31639;&#27861;&#20165;&#30740;&#31350;&#20102;&#21069;&#19977;&#20010;&#27169;&#22359;&#65292;&#21364;&#24573;&#30053;&#20102;&#21453;&#21521;&#20256;&#25773;&#27169;&#22359;&#12290;&#20182;&#20204;&#37117;&#37319;&#29992;&#26576;&#31181;&#24418;&#24335;&#30340;&#21452;&#21453;&#21521;&#20256;&#25773;&#31574;&#30053;&#65292;&#22522;&#20110;&#19968;&#20010;&#38544;&#21547;&#30340;&#20551;&#35774;&#65292;&#21363;&#22312;&#35757;&#32451;&#38454;&#27573;&#24179;&#31561;&#23545;&#24453;&#29992;&#25143;&#21644;&#29289;&#21697;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#36825;&#31181;&#24179;&#31561;&#35757;&#32451;&#20551;&#35774;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21333;&#27425;&#21453;&#21521;&#20256;&#25773;&#26356;&#26032;&#31574;&#30053;&#65292;&#36825;&#31181;&#31574;&#30053;&#20445;&#30041;&#20102;&#29289;&#21697;&#32534;&#30721;&#22612;&#30340;&#27491;&#24120;&#26799;&#24230;&#21453;&#21521;&#20256;&#25773;&#65292;&#20294;&#21066;&#20943;&#20102;&#29992;&#25143;&#32534;&#30721;&#22612;&#30340;&#21453;&#21521;&#20256;&#25773;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31227;&#21160;&#32858;&#21512;&#26356;&#26032;&#31574;&#30053;&#26469;&#26356;&#26032;&#27599;&#20010;&#35757;&#32451;&#21608;&#26399;&#20013;&#30340;&#29992;&#25143;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18227v1 Announce Type: new  Abstract: Recent years have witnessed extensive researches on developing two tower recommendation models for relieving information overload. Four building modules can be identified in such models, namely, user-item encoding, negative sampling, loss computing and back-propagation updating. To the best of our knowledge, existing algorithms have researched only on the first three modules, yet neglecting the backpropagation module. They all adopt a kind of two backpropagation strategy, which are based on an implicit assumption of equally treating users and items in the training phase. In this paper, we challenge such an equal training assumption and propose a novel one backpropagation updating strategy, which keeps the normal gradient backpropagation for the item encoding tower, but cuts off the backpropagation for the user encoding tower. Instead, we propose a moving-aggregation updating strategy to update a user encoding in each training epoch. Exce
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;AI&#27169;&#22411;&#22312;&#25991;&#26723;&#29702;&#35299;&#20219;&#21153;&#20013;&#23545;&#20110;&#24067;&#23616;&#21644;&#22270;&#20687;&#25968;&#25454;&#26377;&#30410;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;AI&#26159;&#21542;&#33021;&#26377;&#25928;&#25429;&#25417;&#25991;&#20214;&#32654;&#23398;&#30340;&#24494;&#22937;&#20043;&#22788;&#12290;</title><link>https://arxiv.org/abs/2403.18183</link><description>&lt;p&gt;
AI&#27169;&#22411;&#33021;&#21542;&#27427;&#36175;&#25991;&#26723;&#32654;&#23398;&#65311;&#25506;&#31350;&#21487;&#35835;&#24615;&#19982;&#29256;&#38754;&#36136;&#37327;&#19982;&#39044;&#27979;&#32622;&#20449;&#24230;&#30340;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Can AI Models Appreciate Document Aesthetics? An Exploration of Legibility and Layout Quality in Relation to Prediction Confidence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18183
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;AI&#27169;&#22411;&#22312;&#25991;&#26723;&#29702;&#35299;&#20219;&#21153;&#20013;&#23545;&#20110;&#24067;&#23616;&#21644;&#22270;&#20687;&#25968;&#25454;&#26377;&#30410;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;AI&#26159;&#21542;&#33021;&#26377;&#25928;&#25429;&#25417;&#25991;&#20214;&#32654;&#23398;&#30340;&#24494;&#22937;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20221;&#31934;&#24515;&#35774;&#35745;&#30340;&#25991;&#20214;&#19981;&#20165;&#36890;&#36807;&#25991;&#23383;&#20256;&#36798;&#20449;&#24687;&#65292;&#36824;&#36890;&#36807;&#35270;&#35273;&#20248;&#38597;&#20256;&#36798;&#20449;&#24687;&#12290;&#20316;&#32773;&#21033;&#29992;&#39068;&#33394;&#12289;&#23383;&#20307;&#12289;&#22270;&#24418;&#21644;&#24067;&#23616;&#31561;&#32654;&#23398;&#20803;&#32032;&#26469;&#22609;&#36896;&#20449;&#24687;&#30340;&#24863;&#30693;&#12290;&#32463;&#36807;&#24515;&#29702;&#27934;&#23519;&#21147;&#21551;&#21457;&#30340;&#21608;&#21040;&#25991;&#20214;&#35774;&#35745;&#26082;&#22686;&#24378;&#20102;&#35270;&#35273;&#21560;&#24341;&#21147;&#65292;&#20063;&#22686;&#36827;&#20102;&#20869;&#23481;&#30340;&#29702;&#35299;&#12290;&#23613;&#31649;&#26368;&#20808;&#36827;&#30340;&#25991;&#20214;AI&#27169;&#22411;&#23637;&#31034;&#20102;&#23558;&#24067;&#23616;&#21644;&#22270;&#20687;&#25968;&#25454;&#34701;&#20837;&#30340;&#22909;&#22788;&#65292;&#20294;&#25991;&#20214;&#32654;&#23398;&#30340;&#24494;&#22937;&#20043;&#22788;&#26159;&#21542;&#34987;&#26377;&#25928;&#25429;&#25417;&#20173;&#19981;&#28165;&#26970;&#12290;&#20026;&#20102;&#24357;&#21512;&#20154;&#31867;&#35748;&#30693;&#19982;AI&#23545;&#32654;&#23398;&#20803;&#32032;&#35299;&#37322;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20551;&#35774;&#65292;&#28041;&#21450;AI&#22312;&#25991;&#20214;&#29702;&#35299;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#65292;&#29305;&#21035;&#26159;&#26893;&#26681;&#20110;&#25991;&#20214;&#35774;&#35745;&#21407;&#21017;&#12290;&#22312;&#20851;&#27880;&#21487;&#35835;&#24615;&#21644;&#29256;&#38754;&#36136;&#37327;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#27979;&#35797;&#20102;&#32654;&#23398;&#25928;&#26524;&#30340;&#22235;&#20010;&#26041;&#38754;&#65306;&#22122;&#38899;&#12289;&#23383;&#20307;&#22823;&#23567;&#23545;&#27604;&#12289;&#23545;&#40784;&#21644;&#22797;&#26434;&#24615;&#65292;&#20197;&#27169;&#22411;&#32622;&#20449;&#24230;&#20026;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18183v1 Announce Type: new  Abstract: A well-designed document communicates not only through its words but also through its visual eloquence. Authors utilize aesthetic elements such as colors, fonts, graphics, and layouts to shape the perception of information. Thoughtful document design, informed by psychological insights, enhances both the visual appeal and the comprehension of the content. While state-of-the-art document AI models demonstrate the benefits of incorporating layout and image data, it remains unclear whether the nuances of document aesthetics are effectively captured. To bridge the gap between human cognition and AI interpretation of aesthetic elements, we formulated hypotheses concerning AI behavior in document understanding tasks, specifically anchored in document design principles. With a focus on legibility and layout quality, we tested four aspects of aesthetic effects: noise, font-size contrast, alignment, and complexity, on model confidence using corre
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#22312;HCI&#25991;&#29486;&#20013;&#20351;&#29992;LLMs&#21644;&#32467;&#26500;&#21270;&#25991;&#26412;&#20998;&#26512;&#25216;&#26415;&#25552;&#21462;&#23454;&#39564;&#25968;&#25454;&#30340;&#26032;&#31995;&#32479;&#65292;&#35780;&#20272;&#20102;GPT-3.5&#21644;Llama-2&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#24182;&#20998;&#26512;&#20102;&#20351;&#29992;LLMs&#22312;&#30740;&#31350;&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#39118;&#38505;&#12290;</title><link>https://arxiv.org/abs/2403.18173</link><description>&lt;p&gt;
HCI&#25968;&#25454;&#24037;&#20316;&#20013;&#30340;LLMs&#65306;&#24357;&#21512;&#20449;&#24687;&#26816;&#32034;&#19982;&#36127;&#36131;&#20219;&#30740;&#31350;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18173
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#22312;HCI&#25991;&#29486;&#20013;&#20351;&#29992;LLMs&#21644;&#32467;&#26500;&#21270;&#25991;&#26412;&#20998;&#26512;&#25216;&#26415;&#25552;&#21462;&#23454;&#39564;&#25968;&#25454;&#30340;&#26032;&#31995;&#32479;&#65292;&#35780;&#20272;&#20102;GPT-3.5&#21644;Llama-2&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#24182;&#20998;&#26512;&#20102;&#20351;&#29992;LLMs&#22312;&#30740;&#31350;&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#31185;&#23398;&#35770;&#25991;&#20013;&#39640;&#25928;&#20934;&#30830;&#22320;&#25552;&#21462;&#20449;&#24687;&#22312;&#36805;&#36895;&#21457;&#23637;&#30340;&#20154;&#26426;&#20132;&#20114;&#30740;&#31350;&#20013;&#30340;&#25991;&#29486;&#32508;&#36848;&#36807;&#31243;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#20171;&#32461;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#65292;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#32467;&#21512;&#32467;&#26500;&#21270;&#25991;&#26412;&#20998;&#26512;&#25216;&#26415;&#20174;HCI&#25991;&#29486;&#20013;&#25552;&#21462;&#23454;&#39564;&#25968;&#25454;&#65292;&#24378;&#35843;&#20851;&#38190;&#35201;&#32032;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#30740;&#31350;&#39046;&#22495;&#20013;&#20351;&#29992;LLMs&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#39118;&#38505;&#12290;&#25105;&#20204;&#23545;&#21253;&#21547;300&#31687;CHI 2020-2022&#35770;&#25991;&#25351;&#23450;&#20449;&#24687;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#20197;&#35780;&#20272;&#20004;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-3.5&#65288;text-davinci-003&#65289;&#21644;Llama-2-70b&#19982;&#32467;&#26500;&#21270;&#25991;&#26412;&#20998;&#26512;&#25216;&#26415;&#21512;&#20316;&#30340;&#24615;&#33021;&#12290;GPT-3.5&#27169;&#22411;&#33719;&#24471;&#20102;58%&#30340;&#31934;&#30830;&#24230;&#21644;7.00&#30340;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;Llama-2&#27169;&#22411;&#26174;&#31034;&#20986;56%&#30340;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18173v1 Announce Type: cross  Abstract: Efficient and accurate information extraction from scientific papers is significant in the rapidly developing human-computer interaction research in the literature review process. Our paper introduces and analyses a new information retrieval system using state-of-the-art Large Language Models (LLMs) in combination with structured text analysis techniques to extract experimental data from HCI literature, emphasizing key elements. Then We analyze the challenges and risks of using LLMs in the world of research. We performed a comprehensive analysis on our conducted dataset, which contained the specified information of 300 CHI 2020-2022 papers, to evaluate the performance of the two large language models, GPT-3.5 (text-davinci-003) and Llama-2-70b, paired with structured text analysis techniques. The GPT-3.5 model gains an accuracy of 58\% and a mean absolute error of 7.00. In contrast, the Llama2 model indicates an accuracy of 56\% with a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Mask Specific Language Modeling&#65288;MSLM&#65289;&#26041;&#27861;&#26469;&#25913;&#21892;LM&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#23545;&#30446;&#26631;&#39046;&#22495;&#30693;&#35782;&#30340;&#25935;&#24863;&#24615;&#65292;&#36890;&#36807;&#21152;&#26435;&#39046;&#22495;&#29305;&#23450;&#26415;&#35821;&#30340;&#37325;&#35201;&#24615;&#36827;&#34892;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.18025</link><description>&lt;p&gt;
&#36890;&#36807;&#29305;&#23450;&#25513;&#30721;&#25439;&#22833;&#25913;&#21892;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#65306;&#20197;&#29983;&#29289;&#21307;&#23398;&#23454;&#20307;&#35782;&#21035;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18025
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Mask Specific Language Modeling&#65288;MSLM&#65289;&#26041;&#27861;&#26469;&#25913;&#21892;LM&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#23545;&#30446;&#26631;&#39046;&#22495;&#30693;&#35782;&#30340;&#25935;&#24863;&#24615;&#65292;&#36890;&#36807;&#21152;&#26435;&#39046;&#22495;&#29305;&#23450;&#26415;&#35821;&#30340;&#37325;&#35201;&#24615;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#35843;&#25972;&#21040;&#26032;&#39046;&#22495;&#36890;&#24120;&#36890;&#36807;&#22312;&#29305;&#23450;&#39046;&#22495;&#25968;&#25454;&#19978;&#24494;&#35843;&#39044;&#35757;&#32451;LM&#65288;PLM&#65289;&#26469;&#23454;&#29616;&#12290;&#24494;&#35843;&#23558;&#26032;&#30693;&#35782;&#24341;&#20837;LM&#65292;&#20351;&#23427;&#33021;&#22815;&#29702;&#35299;&#21644;&#26377;&#25928;&#25191;&#34892;&#30446;&#26631;&#22495;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#24494;&#35843;&#21487;&#33021;&#20250;&#26080;&#24847;&#20013;&#21464;&#24471;&#19981;&#22815;&#25935;&#24863;&#65292;&#22914;&#26524;&#23427;&#24573;&#35270;&#20102;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20043;&#38388;&#30340;&#24191;&#27867;&#24046;&#24322;&#65288;&#20363;&#22914;&#22312;&#35789;&#20041;&#19978;&#65289;&#12290;&#20026;&#20102;&#35299;&#20915;&#24494;&#35843;&#19981;&#25935;&#24863;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Mask Specific Language Modeling&#65288;MSLM&#65289;&#65292;&#19968;&#31181;&#36890;&#36807;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#36866;&#24403;&#21152;&#26435;&#39046;&#22495;&#29305;&#23450;&#26415;&#35821;&#65288;DS-terms&#65289;&#30340;&#37325;&#35201;&#24615;&#26469;&#26377;&#25928;&#33719;&#21462;&#30446;&#26631;&#39046;&#22495;&#30693;&#35782;&#30340;&#26041;&#27861;&#12290;MSLM&#21516;&#26102;&#23631;&#34109;DS&#26415;&#35821;&#21644;&#36890;&#29992;&#35789;&#65292;&#28982;&#21518;&#36890;&#36807;&#30830;&#20445;LM&#21463;&#21040;&#26356;&#22823;&#24809;&#32602;&#26469;&#23398;&#20064;&#29305;&#23450;&#20110;&#25513;&#30721;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18025v1 Announce Type: cross  Abstract: Adapting language models (LMs) to novel domains is often achieved through fine-tuning a pre-trained LM (PLM) on domain-specific data. Fine-tuning introduces new knowledge into an LM, enabling it to comprehend and efficiently perform a target domain task. Fine-tuning can however be inadvertently insensitive if it ignores the wide array of disparities (e.g in word meaning) between source and target domains. For instance, words such as chronic and pressure may be treated lightly in social conversations, however, clinically, these words are usually an expression of concern. To address insensitive fine-tuning, we propose Mask Specific Language Modeling (MSLM), an approach that efficiently acquires target domain knowledge by appropriately weighting the importance of domain-specific terms (DS-terms) during fine-tuning. MSLM jointly masks DS-terms and generic words, then learns mask-specific losses by ensuring LMs incur larger penalties for in
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;MA4DIV&#26041;&#27861;&#65292;&#23558;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#24314;&#27169;&#20026;&#22810;&#20010;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21512;&#20316;&#20219;&#21153;&#65292;&#30452;&#25509;&#20248;&#21270;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#22914;$\alpha$-NDCG&#65292;&#20197;&#23454;&#29616;&#39640;&#35757;&#32451;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.17421</link><description>&lt;p&gt;
MA4DIV&#65306;&#29992;&#20110;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MA4DIV: Multi-Agent Reinforcement Learning for Search Result Diversification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17421
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;MA4DIV&#26041;&#27861;&#65292;&#23558;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#24314;&#27169;&#20026;&#22810;&#20010;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21512;&#20316;&#20219;&#21153;&#65292;&#30452;&#25509;&#20248;&#21270;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#22914;$\alpha$-NDCG&#65292;&#20197;&#23454;&#29616;&#39640;&#35757;&#32451;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#65288;SRD&#65289;&#30340;&#30446;&#26631;&#26159;&#30830;&#20445;&#25152;&#36873;&#25991;&#26723;&#28085;&#30422;&#23613;&#21487;&#33021;&#22810;&#30340;&#19981;&#21516;&#23376;&#20027;&#39064;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#21033;&#29992;&#8220;&#36138;&#23146;&#36873;&#25321;&#8221;&#33539;&#24335;&#65292;&#21363;&#19968;&#27425;&#36873;&#25321;&#19968;&#20010;&#20855;&#26377;&#26368;&#39640;&#22810;&#26679;&#24615;&#20998;&#25968;&#30340;&#25991;&#26723;&#12290;&#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#25928;&#29575;&#20302;&#19979;&#65292;&#23481;&#26131;&#38519;&#20837;&#27425;&#20248;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;&#19968;&#20123;&#20854;&#20182;&#26041;&#27861;&#26088;&#22312;&#36817;&#20284;&#20248;&#21270;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#22914;$\alpha$-NDCG&#65292;&#20294;&#32467;&#26524;&#20173;&#28982;&#19981;&#23613;&#22914;&#20154;&#24847;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#29992;&#20110;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#24615;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#26041;&#27861;&#65292;&#31216;&#20026;MA4DIV&#12290;&#22312;&#36825;&#31181;&#26041;&#27861;&#20013;&#65292;&#27599;&#20010;&#25991;&#26723;&#37117;&#26159;&#19968;&#20010;&#26234;&#33021;&#20307;&#65292;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#34987;&#24314;&#27169;&#20026;&#22810;&#20010;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21512;&#20316;&#20219;&#21153;&#12290;&#35813;&#26041;&#27861;&#20801;&#35768;&#30452;&#25509;&#20248;&#21270;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#22914;$\alpha$-NDCG&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#35757;&#32451;&#25928;&#29575;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#21021;&#27493;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17421v1 Announce Type: cross  Abstract: The objective of search result diversification (SRD) is to ensure that selected documents cover as many different subtopics as possible. Existing methods primarily utilize a paradigm of "greedy selection", i.e., selecting one document with the highest diversity score at a time. These approaches tend to be inefficient and are easily trapped in a suboptimal state. In addition, some other methods aim to approximately optimize the diversity metric, such as $\alpha$-NDCG, but the results still remain suboptimal. To address these challenges, we introduce Multi-Agent reinforcement learning (MARL) for search result DIVersity, which called MA4DIV. In this approach, each document is an agent and the search result diversification is modeled as a cooperative task among multiple agents. This approach allows for directly optimizing the diversity metrics, such as $\alpha$-NDCG, while achieving high training efficiency. We conducted preliminary experi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#31895;&#35843;&#20248;&#20316;&#20026;&#19968;&#20010;&#20013;&#38388;&#23398;&#20064;&#38454;&#27573;&#65292;&#36830;&#25509;&#20102;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#65292;&#22312;&#19987;&#39064;&#25991;&#26723;&#26816;&#32034;&#20013;&#26174;&#33879;&#25913;&#21892;&#20102;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.16915</link><description>&lt;p&gt;
&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31895;&#35843;&#20248;&#30340;&#19987;&#39064;&#25991;&#26723;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#31895;&#35843;&#20248;&#20316;&#20026;&#19968;&#20010;&#20013;&#38388;&#23398;&#20064;&#38454;&#27573;&#65292;&#36830;&#25509;&#20102;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#65292;&#22312;&#19987;&#39064;&#25991;&#26723;&#26816;&#32034;&#20013;&#26174;&#33879;&#25913;&#21892;&#20102;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20013;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM-based IR&#65289;&#36827;&#34892;&#24494;&#35843;&#38656;&#35201;&#23398;&#20064;&#26597;&#35810;&#34920;&#31034;&#21644;&#26597;&#35810;-&#25991;&#26723;&#20851;&#31995;&#65292;&#38500;&#20102;&#19979;&#28216;&#20219;&#21153;&#29305;&#23450;&#30340;&#23398;&#20064;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#31895;&#35843;&#20248;&#20316;&#20026;&#19968;&#20010;&#20013;&#38388;&#23398;&#20064;&#38454;&#27573;&#65292;&#36830;&#25509;&#20102;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#12290;&#36890;&#36807;&#22312;&#31895;&#35843;&#20248;&#23398;&#20064;&#26597;&#35810;&#34920;&#31034;&#21644;&#26597;&#35810;-&#25991;&#26723;&#20851;&#31995;&#65292;&#25105;&#20204;&#26088;&#22312;&#20943;&#23569;&#24494;&#35843;&#30340;&#36127;&#25285;&#65292;&#25552;&#39640;&#19979;&#28216;IR&#20219;&#21153;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#31895;&#35843;&#20248;&#30340;&#26597;&#35810;-&#25991;&#26723;&#23545;&#39044;&#27979;&#65288;QDPP&#65289;&#65292;&#20854;&#39044;&#27979;&#26597;&#35810;-&#25991;&#26723;&#23545;&#30340;&#36866;&#24403;&#24615;&#12290;&#35780;&#20272;&#23454;&#39564;&#26174;&#31034;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26174;&#33879;&#25913;&#21892;&#20102;&#22235;&#20010;&#19987;&#39064;&#25991;&#26723;&#26816;&#32034;&#25968;&#25454;&#38598;&#20013;&#30340;MRR&#21644;/&#25110;nDCG@5&#12290;&#27492;&#22806;&#65292;&#26597;&#35810;&#39044;&#27979;&#20219;&#21153;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#31895;&#35843;&#20248;&#20419;&#36827;&#20102;&#26597;&#35810;&#34920;&#31034;&#21644;&#26597;&#35810;-&#25991;&#26723;&#20851;&#31995;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16915v1 Announce Type: cross  Abstract: Fine-tuning in information retrieval systems using pre-trained language models (PLM-based IR) requires learning query representations and query-document relations, in addition to downstream task-specific learning. This study introduces coarse-tuning as an intermediate learning stage that bridges pre-training and fine-tuning. By learning query representations and query-document relations in coarse-tuning, we aim to reduce the load of fine-tuning and improve the learning effect of downstream IR tasks. We propose Query-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the appropriateness of query-document pairs. Evaluation experiments show that the proposed method significantly improves MRR and/or nDCG@5 in four ad-hoc document retrieval datasets. Furthermore, the results of the query prediction task suggested that coarse-tuning facilitated learning of query representation and query-document relations.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Meta-Split&#32593;&#32476;&#65288;MSN&#65289;&#26469;&#35299;&#20915;&#28040;&#36153;&#32773;&#20043;&#38388;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#20013;&#38480;&#37327;&#24211;&#23384;&#20135;&#21697;&#25512;&#33616;&#20013;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#36890;&#36807;&#20998;&#21106;&#29992;&#25143;&#21382;&#21490;&#24207;&#21015;&#26469;&#26377;&#25928;&#21033;&#29992;&#29992;&#25143;&#21382;&#21490;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2403.06747</link><description>&lt;p&gt;
MetaSplit: &#29992;&#20110;&#38480;&#37327;&#20135;&#21697;&#25512;&#33616;&#30340;Meta-Split&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06747
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Meta-Split&#32593;&#32476;&#65288;MSN&#65289;&#26469;&#35299;&#20915;&#28040;&#36153;&#32773;&#20043;&#38388;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#20013;&#38480;&#37327;&#24211;&#23384;&#20135;&#21697;&#25512;&#33616;&#20013;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#36890;&#36807;&#20998;&#21106;&#29992;&#25143;&#21382;&#21490;&#24207;&#21015;&#26469;&#26377;&#25928;&#21033;&#29992;&#29992;&#25143;&#21382;&#21490;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#23545;&#20110;&#38754;&#21521;&#28040;&#36153;&#32773;&#30340;&#30005;&#23376;&#21830;&#21153;&#31995;&#32479;&#65292;&#28040;&#36153;&#32773;&#20043;&#38388;&#30340;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#36890;&#24120;&#20250;&#36935;&#21040;&#38480;&#37327;&#24211;&#23384;&#38382;&#39064;&#65292;&#21363;&#20135;&#21697;&#22312;C2C&#31995;&#32479;&#20013;&#21482;&#33021;&#38144;&#21806;&#19968;&#27425;&#12290;&#36825;&#20026;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#24102;&#26469;&#20102;&#20960;&#20010;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#37492;&#20110;&#27599;&#20010;&#20135;&#21697;&#65288;&#21363;&#21830;&#21697;&#65289;&#30340;&#26377;&#38480;&#29992;&#25143;&#20132;&#20114;&#65292;CTR&#27169;&#22411;&#20013;&#23545;&#24212;&#30340;&#21830;&#21697;&#23884;&#20837;&#21487;&#33021;&#19981;&#23481;&#26131;&#25910;&#25947;&#12290;&#36825;&#20351;&#24471;&#20256;&#32479;&#22522;&#20110;&#24207;&#21015;&#24314;&#27169;&#30340;&#26041;&#27861;&#26080;&#27861;&#26377;&#25928;&#21033;&#29992;&#29992;&#25143;&#21382;&#21490;&#20449;&#24687;&#65292;&#22240;&#20026;&#21382;&#21490;&#29992;&#25143;&#34892;&#20026;&#21253;&#21547;&#20102;&#19981;&#21516;&#24211;&#23384;&#37327;&#30340;&#21830;&#21697;&#28151;&#21512;&#12290;&#29305;&#21035;&#26159;&#65292;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#20542;&#21521;&#20110;&#23558;&#26356;&#22810;&#32047;&#31215;&#29992;&#25143;&#20132;&#20114;&#30340;&#20135;&#21697;&#20998;&#37197;&#26356;&#39640;&#30340;&#20998;&#25968;&#65292;&#23548;&#33268;&#38480;&#37327;&#20135;&#21697;&#34987;&#24573;&#35270;&#19988;&#23545;&#26368;&#32456;&#36755;&#20986;&#30340;&#36129;&#29486;&#36739;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Meta-Split&#32593;&#32476;&#65288;MSN&#65289;&#26469;&#20998;&#21106;&#29992;&#25143;&#21382;&#21490;&#24207;&#21015;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06747v1 Announce Type: new  Abstract: Compared to business-to-consumer (B2C) e-commerce systems, consumer-to-consumer (C2C) e-commerce platforms usually encounter the limited-stock problem, that is, a product can only be sold one time in a C2C system. This poses several unique challenges for click-through rate (CTR) prediction. Due to limited user interactions for each product (i.e. item), the corresponding item embedding in the CTR model may not easily converge. This makes the conventional sequence modeling based approaches cannot effectively utilize user history information since historical user behaviors contain a mixture of items with different volume of stocks. Particularly, the attention mechanism in a sequence model tends to assign higher score to products with more accumulated user interactions, making limited-stock products being ignored and contribute less to the final output. To this end, we propose the Meta-Split Network (MSN) to split user history sequence regar
&lt;/p&gt;</description></item><item><title>DynaWarp&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25104;&#21592;&#33609;&#22270;&#32467;&#26500;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#22238;&#31572;&#22810;&#38598;&#22810;&#25104;&#21592;&#26597;&#35810;&#65292;&#30456;&#27604;&#20110;&#20498;&#25490;&#32034;&#24341;&#21644;&#25104;&#21592;&#33609;&#22270;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#23384;&#20648;&#25928;&#29575;&#21644;&#26597;&#35810;&#21534;&#21520;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.18355</link><description>&lt;p&gt;
DynaWarp -- &#39640;&#25928;&#30340;&#22823;&#35268;&#27169;&#26085;&#24535;&#23384;&#20648;&#21644;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
DynaWarp -- Efficient, large-scale log storage and retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18355
&lt;/p&gt;
&lt;p&gt;
DynaWarp&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25104;&#21592;&#33609;&#22270;&#32467;&#26500;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#22238;&#31572;&#22810;&#38598;&#22810;&#25104;&#21592;&#26597;&#35810;&#65292;&#30456;&#27604;&#20110;&#20498;&#25490;&#32034;&#24341;&#21644;&#25104;&#21592;&#33609;&#22270;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#23384;&#20648;&#25928;&#29575;&#21644;&#26597;&#35810;&#21534;&#21520;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#22823;&#35268;&#27169;&#30417;&#25511;&#31995;&#32479;&#24517;&#39035;&#23454;&#26102;&#22788;&#29702;&#21644;&#23384;&#20648;&#22823;&#37327;&#26085;&#24535;&#25968;&#25454;&#12290;&#22312;&#26597;&#35810;&#26102;&#65292;&#31995;&#32479;&#24517;&#39035;&#22522;&#20110;&#26085;&#24535;&#28040;&#24687;&#30340;&#20869;&#23481;&#25214;&#21040;&#30456;&#20851;&#26085;&#24535;&#65292;&#20351;&#29992;&#33021;&#22815;&#25193;&#23637;&#21040;&#36825;&#20123;&#25968;&#25454;&#37327;&#24182;&#19988;&#20173;&#28982;&#39640;&#25928;&#30340;&#25903;&#25345;&#32467;&#26500;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;DynaWarp&#25104;&#21592;&#33609;&#22270;&#65292;&#33021;&#22815;&#22238;&#31572;&#22810;&#38598;&#22810;&#25104;&#21592;&#26597;&#35810;&#65292;&#21487;&#20316;&#20026;&#27969;&#24335;&#26085;&#24535;&#25968;&#25454;&#30340;&#29616;&#26377;&#32034;&#24341;&#32467;&#26500;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;DynaWarp&#25152;&#38656;&#30340;&#23384;&#20648;&#31354;&#38388;&#27604;&#27979;&#35797;&#30340;&#26368;&#20808;&#36827;&#30340;&#20498;&#25490;&#32034;&#24341;&#23569;&#20102;&#39640;&#36798;93&#65285;&#65292;&#35823;&#25253;&#29575;&#27604;&#27979;&#35797;&#30340;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#33609;&#22270;&#23569;&#20102;&#39640;&#36798;&#22235;&#20010;&#25968;&#37327;&#32423;&#12290;&#27492;&#22806;&#65292;DynaWarp&#30340;&#26597;&#35810;&#21534;&#21520;&#37327;&#27604;&#27979;&#35797;&#30340;&#20498;&#25490;&#32034;&#24341;&#39640;&#20986;&#39640;&#36798;250&#20493;&#65292;&#24182;&#19988;&#27604;&#27979;&#35797;&#30340;&#25104;&#21592;&#33609;&#22270;&#39640;&#20986;&#39640;&#36798;240&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18355v1 Announce Type: new  Abstract: Modern, large scale monitoring systems have to process and store vast amounts of log data in near real-time. At query time the systems have to find relevant logs based on the content of the log message using support structures that can scale to these amounts of data while still being efficient to use. We present our novel DynaWarp membership sketch, capable of answering Multi-Set Multi-Membership-Queries, that can be used as an alternative to existing indexing structures for streamed log data. In our experiments, DynaWarp required up to 93% less storage space than the tested state-of-the-art inverted index and had up to four orders of magnitude less false-positives than the tested state-of-the-art membership sketch. Additionally, DynaWarp achieved up to 250 times higher query throughput than the tested inverted index and up to 240 times higher query throughput than the tested membership sketch.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#29616;&#23454;&#32422;&#26463;&#30340;&#36731;&#37327;&#32423;&#24323;&#26435;&#26426;&#21046;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20877;&#25490;&#24207;&#38454;&#27573;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#36798;&#21040;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#24320;&#28304;&#20195;&#30721;&#20197;&#20419;&#36827;&#20854;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.12997</link><description>&lt;p&gt;
&#26397;&#30528;&#21487;&#20449;&#30340;&#20877;&#25490;&#24207;&#65306;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#24323;&#26435;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Towards Trustworthy Reranking: A Simple yet Effective Abstention Mechanism
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12997
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#29616;&#23454;&#32422;&#26463;&#30340;&#36731;&#37327;&#32423;&#24323;&#26435;&#26426;&#21046;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20877;&#25490;&#24207;&#38454;&#27573;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#36798;&#21040;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#24320;&#28304;&#20195;&#30721;&#20197;&#20419;&#36827;&#20854;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#65288;NIR&#65289;&#24050;&#32463;&#26174;&#33879;&#25913;&#36827;&#20102;&#22522;&#20110;&#21551;&#21457;&#24335;&#30340;IR&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#22833;&#36133;&#20173;&#28982;&#39057;&#32321;&#21457;&#29983;&#65292;&#36890;&#24120;&#25152;&#20351;&#29992;&#30340;&#27169;&#22411;&#26080;&#27861;&#26816;&#32034;&#19982;&#29992;&#25143;&#26597;&#35810;&#30456;&#20851;&#30340;&#25991;&#26723;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#36866;&#29992;&#20110;&#29616;&#23454;&#32422;&#26463;&#30340;&#36731;&#37327;&#32423;&#24323;&#26435;&#26426;&#21046;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#29305;&#21035;&#24378;&#35843;&#20877;&#25490;&#24207;&#38454;&#27573;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21327;&#35758;&#65292;&#29992;&#20110;&#22312;&#40657;&#21283;&#23376;&#22330;&#26223;&#20013;&#35780;&#20272;&#24323;&#26435;&#31574;&#30053;&#30340;&#25928;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#25968;&#25454;&#39537;&#21160;&#26426;&#21046;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#39564;&#22797;&#21046;&#21644;&#24323;&#26435;&#23454;&#26045;&#30340;&#24320;&#28304;&#20195;&#30721;&#65292;&#20419;&#36827;&#20854;&#22312;&#19981;&#21516;&#29615;&#22659;&#20013;&#26356;&#24191;&#27867;&#30340;&#37319;&#29992;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12997v1 Announce Type: cross  Abstract: Neural Information Retrieval (NIR) has significantly improved upon heuristic-based IR systems. Yet, failures remain frequent, the models used often being unable to retrieve documents relevant to the user's query. We address this challenge by proposing a lightweight abstention mechanism tailored for real-world constraints, with particular emphasis placed on the reranking phase. We introduce a protocol for evaluating abstention strategies in a black-box scenario, demonstrating their efficacy, and propose a simple yet effective data-driven mechanism. We provide open-source code for experiment replication and abstention implementation, fostering wider adoption and application in diverse contexts.
&lt;/p&gt;</description></item><item><title>&#21487;&#39564;&#35777;&#29983;&#25104;&#20013;&#26816;&#32034;&#30340;&#25991;&#20214;&#19981;&#20165;&#24110;&#21161;LLM&#29983;&#25104;&#27491;&#30830;&#31572;&#26696;&#65292;&#36824;&#20316;&#20026;&#29992;&#25143;&#39564;&#35777;LLM&#36755;&#20986;&#30340;&#35777;&#25454;&#65292;&#20294;&#30446;&#21069;&#24191;&#27867;&#20351;&#29992;&#30340;&#26816;&#32034;&#22120;&#24050;&#25104;&#20026;&#24615;&#33021;&#29942;&#39048;&#65292;&#38656;&#35201;&#35299;&#20915;&#12290;</title><link>https://arxiv.org/abs/2311.07838</link><description>&lt;p&gt;
LLatrieval&#65306;LLM-&#39564;&#35777;&#26816;&#32034;&#29992;&#20110;&#21487;&#39564;&#35777;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
LLatrieval: LLM-Verified Retrieval for Verifiable Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07838
&lt;/p&gt;
&lt;p&gt;
&#21487;&#39564;&#35777;&#29983;&#25104;&#20013;&#26816;&#32034;&#30340;&#25991;&#20214;&#19981;&#20165;&#24110;&#21161;LLM&#29983;&#25104;&#27491;&#30830;&#31572;&#26696;&#65292;&#36824;&#20316;&#20026;&#29992;&#25143;&#39564;&#35777;LLM&#36755;&#20986;&#30340;&#35777;&#25454;&#65292;&#20294;&#30446;&#21069;&#24191;&#27867;&#20351;&#29992;&#30340;&#26816;&#32034;&#22120;&#24050;&#25104;&#20026;&#24615;&#33021;&#29942;&#39048;&#65292;&#38656;&#35201;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#39564;&#35777;&#29983;&#25104;&#26088;&#22312;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#29983;&#25104;&#20855;&#26377;&#25903;&#25745;&#25991;&#20214;&#30340;&#25991;&#26412;&#65292;&#36825;&#20351;&#29992;&#25143;&#33021;&#22815;&#28789;&#27963;&#39564;&#35777;&#31572;&#26696;&#65292;&#24182;&#20351;LLM&#30340;&#36755;&#20986;&#26356;&#21487;&#38752;&#12290;&#26816;&#32034;&#22312;&#21487;&#39564;&#35777;&#29983;&#25104;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26816;&#32034;&#21040;&#30340;&#25991;&#20214;&#19981;&#20165;&#34917;&#20805;&#30693;&#35782;&#20197;&#24110;&#21161;LLM&#29983;&#25104;&#27491;&#30830;&#31572;&#26696;&#65292;&#36824;&#20316;&#20026;&#25903;&#25345;&#29992;&#25143;&#39564;&#35777;LLM&#36755;&#20986;&#30340;&#35777;&#25454;&#12290;&#28982;&#32780;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;&#26816;&#32034;&#22120;&#25104;&#20026;&#25972;&#20010;&#27969;&#31243;&#30340;&#29942;&#39048;&#65292;&#24182;&#38480;&#21046;&#20102;&#25972;&#20307;&#24615;&#33021;&#12290;&#30001;&#20110;&#36890;&#24120;&#20855;&#26377;&#30340;&#21442;&#25968;&#27604;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23569;&#24471;&#22810;&#65292;&#24182;&#19988;&#23578;&#26410;&#35777;&#26126;&#33021;&#22815;&#33391;&#22909;&#22320;&#25193;&#23637;&#21040;LLM&#30340;&#35268;&#27169;&#65292;&#22240;&#27492;&#23427;&#20204;&#30340;&#33021;&#21147;&#36890;&#24120;&#27604;LLMs&#24046;&#12290;&#22914;&#26524;&#26816;&#32034;&#22120;&#26410;&#33021;&#27491;&#30830;&#25214;&#21040;&#25903;&#25345;&#25991;&#20214;&#65292;&#21017;LLM&#23558;&#26080;&#27861;&#29983;&#25104;&#27491;&#30830;&#21644;&#21487;&#39564;&#35777;&#30340;&#31572;&#26696;&#65292;&#36825;&#20250;&#25513;&#30422;LLM&#30340;&#26174;&#33879;&#33021;&#21147;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07838v2 Announce Type: replace  Abstract: Verifiable generation aims to let the large language model (LLM) generate text with supporting documents, which enables the user to flexibly verify the answer and makes the LLM's output more reliable. Retrieval plays a crucial role in verifiable generation. Specifically, the retrieved documents not only supplement knowledge to help the LLM generate correct answers, but also serve as supporting evidence for the user to verify the LLM's output. However, the widely used retrievers become the bottleneck of the entire pipeline and limit the overall performance. Their capabilities are usually inferior to LLMs since they often have much fewer parameters than the large language model and have not been demonstrated to scale well to the size of LLMs. If the retriever does not correctly find the supporting documents, the LLM can not generate the correct and verifiable answer, which overshadows the LLM's remarkable abilities. To address these li
&lt;/p&gt;</description></item></channel></rss>