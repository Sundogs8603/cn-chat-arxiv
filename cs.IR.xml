<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#24341;&#20837;&#20102;&#22238;&#28335;&#20219;&#21153;&#65292;&#36890;&#36807;&#26816;&#32034;&#25991;&#26412;&#27573;&#26469;&#30830;&#23450;&#24341;&#21457;&#29992;&#25143;&#26597;&#35810;&#30340;&#21407;&#22240;&#65292;&#28041;&#21450;&#21040;&#19981;&#21516;&#39046;&#22495;&#65292;&#21253;&#25324;&#35762;&#24231;&#12289;&#26032;&#38395;&#21644;&#23545;&#35805;&#65292;&#35780;&#20272;&#20102;&#38646;&#27425;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.03956</link><description>&lt;p&gt;
&#22238;&#28335;&#65306;&#26816;&#32034;&#26597;&#35810;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
Backtracing: Retrieving the Cause of the Query
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03956
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#22238;&#28335;&#20219;&#21153;&#65292;&#36890;&#36807;&#26816;&#32034;&#25991;&#26412;&#27573;&#26469;&#30830;&#23450;&#24341;&#21457;&#29992;&#25143;&#26597;&#35810;&#30340;&#21407;&#22240;&#65292;&#28041;&#21450;&#21040;&#19981;&#21516;&#39046;&#22495;&#65292;&#21253;&#25324;&#35762;&#24231;&#12289;&#26032;&#38395;&#21644;&#23545;&#35805;&#65292;&#35780;&#20272;&#20102;&#38646;&#27425;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#22312;&#32447;&#20869;&#23481;&#38376;&#25143;&#20801;&#35768;&#29992;&#25143;&#25552;&#20986;&#38382;&#39064;&#20197;&#34917;&#20805;&#20182;&#20204;&#30340;&#29702;&#35299;&#65288;&#20363;&#22914;&#65292;&#23545;&#35762;&#24231;&#30340;&#29702;&#35299;&#65289;&#12290;&#34429;&#28982;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#31995;&#32479;&#21487;&#20197;&#20026;&#36825;&#31867;&#29992;&#25143;&#26597;&#35810;&#25552;&#20379;&#31572;&#26696;&#65292;&#20294;&#23427;&#20204;&#24182;&#19981;&#30452;&#25509;&#24110;&#21161;&#20869;&#23481;&#21019;&#24314;&#32773;&#65288;&#22914;&#24076;&#26395;&#25913;&#36827;&#20869;&#23481;&#30340;&#35762;&#24072;&#65289;&#35782;&#21035;&#24341;&#21457;&#29992;&#25143;&#25552;&#20986;&#36825;&#20123;&#38382;&#39064;&#30340;&#27573;&#33853;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22238;&#28335;&#20219;&#21153;&#65292;&#31995;&#32479;&#26816;&#32034;&#20986;&#26368;&#26377;&#21487;&#33021;&#24341;&#21457;&#29992;&#25143;&#26597;&#35810;&#30340;&#25991;&#26412;&#27573;&#12290;&#25105;&#20204;&#23545;&#25552;&#39640;&#20869;&#23481;&#20256;&#36882;&#21644;&#27807;&#36890;&#20013;&#37325;&#35201;&#30340;&#22238;&#28335;&#20219;&#21153;&#36827;&#34892;&#20102;&#19977;&#20010;&#29616;&#23454;&#19990;&#30028;&#39046;&#22495;&#30340;&#24418;&#24335;&#21270;&#65306;&#65288;a&#65289;&#35762;&#24231;&#39046;&#22495;&#20013;&#23398;&#29983;&#22256;&#24785;&#30340;&#21407;&#22240;&#65292;&#65288;b&#65289;&#26032;&#38395;&#25991;&#31456;&#39046;&#22495;&#20013;&#35835;&#32773;&#22909;&#22855;&#24515;&#30340;&#21407;&#22240;&#65292;&#20197;&#21450;&#65288;c&#65289;&#23545;&#35805;&#39046;&#22495;&#20013;&#29992;&#25143;&#24773;&#32490;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#27969;&#34892;&#30340;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#21644;&#35821;&#35328;&#24314;&#27169;&#26041;&#27861;&#30340;&#38646;&#27425;&#24615;&#33021;&#65292;&#21253;&#25324;&#21452;&#32534;&#30721;&#22120;&#12289;&#37325;&#26032;&#25490;&#24207;&#21644;&#22522;&#20110;&#21487;&#33021;&#24615;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03956v1 Announce Type: cross  Abstract: Many online content portals allow users to ask questions to supplement their understanding (e.g., of lectures). While information retrieval (IR) systems may provide answers for such user queries, they do not directly assist content creators -- such as lecturers who want to improve their content -- identify segments that _caused_ a user to ask those questions. We introduce the task of backtracing, in which systems retrieve the text segment that most likely caused a user query. We formalize three real-world domains for which backtracing is important in improving content delivery and communication: understanding the cause of (a) student confusion in the Lecture domain, (b) reader curiosity in the News Article domain, and (c) user emotion in the Conversation domain. We evaluate the zero-shot performance of popular information retrieval methods and language modeling methods, including bi-encoder, re-ranking and likelihood-based methods and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;BLaIR&#65292;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;&#25512;&#33616;&#22330;&#26223;&#30340;&#39044;&#35757;&#32451;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21830;&#21697;&#20803;&#25968;&#25454;&#19982;&#33258;&#28982;&#35821;&#35328;&#35821;&#22659;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#25552;&#39640;&#20102;&#26816;&#32034;&#21644;&#25512;&#33616;&#21830;&#21697;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.03952</link><description>&lt;p&gt;
&#23558;&#35821;&#35328;&#21644;&#29289;&#21697;&#32852;&#31995;&#36215;&#26469;&#36827;&#34892;&#26816;&#32034;&#21644;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Bridging Language and Items for Retrieval and Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;BLaIR&#65292;&#19968;&#20010;&#19987;&#38376;&#38024;&#23545;&#25512;&#33616;&#22330;&#26223;&#30340;&#39044;&#35757;&#32451;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21830;&#21697;&#20803;&#25968;&#25454;&#19982;&#33258;&#28982;&#35821;&#35328;&#35821;&#22659;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#25552;&#39640;&#20102;&#26816;&#32034;&#21644;&#25512;&#33616;&#21830;&#21697;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;BLaIR&#65292;&#36825;&#26159;&#19968;&#31995;&#21015;&#19987;&#38376;&#38024;&#23545;&#25512;&#33616;&#22330;&#26223;&#30340;&#39044;&#35757;&#32451;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#12290;BLaIR&#34987;&#35757;&#32451;&#29992;&#20110;&#23398;&#20064;&#21830;&#21697;&#20803;&#25968;&#25454;&#19982;&#28508;&#22312;&#33258;&#28982;&#35821;&#35328;&#35821;&#22659;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#23545;&#20110;&#26816;&#32034;&#21644;&#25512;&#33616;&#21830;&#21697;&#24456;&#26377;&#29992;&#12290;&#20026;&#20102;&#39044;&#35757;&#32451;BLaIR&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;Amazon Reviews 2023&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#20102;&#26469;&#33258;33&#20010;&#31867;&#8203;&#8203;&#21035;&#30340;&#36229;&#36807;5.7&#20159;&#26465;&#35780;&#35770;&#21644;4800&#19975;&#20010;&#29289;&#21697;&#65292;&#26126;&#26174;&#25193;&#22823;&#20102;&#20043;&#21069;&#29256;&#26412;&#30340;&#33539;&#22260;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;BLaIR&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21253;&#25324;&#19968;&#20010;&#21517;&#20026;&#22797;&#26434;&#20135;&#21697;&#25628;&#32034;&#30340;&#26032;&#20219;&#21153;&#65292;&#25351;&#30340;&#26159;&#22312;&#32473;&#23450;&#38271;&#19988;&#22797;&#26434;&#30340;&#33258;&#28982;&#35821;&#35328;&#35821;&#22659;&#30340;&#24773;&#20917;&#19979;&#26816;&#32034;&#30456;&#20851;&#29289;&#21697;&#12290;&#21033;&#29992;&#20687;ChatGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#30456;&#24212;&#22320;&#26500;&#24314;&#20102;&#19968;&#20010;&#21322;&#21512;&#25104;&#35780;&#20272;&#38598;Amazon-C4&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26032;&#20219;&#21153;&#20197;&#21450;&#20256;&#32479;&#30340;&#26816;&#32034;&#21644;&#25512;&#33616;&#20219;&#21153;&#20013;&#65292;BLaIR&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03952v1 Announce Type: new  Abstract: This paper introduces BLaIR, a series of pretrained sentence embedding models specialized for recommendation scenarios. BLaIR is trained to learn correlations between item metadata and potential natural language context, which is useful for retrieving and recommending items. To pretrain BLaIR, we collect Amazon Reviews 2023, a new dataset comprising over 570 million reviews and 48 million items from 33 categories, significantly expanding beyond the scope of previous versions. We evaluate the generalization ability of BLaIR across multiple domains and tasks, including a new task named complex product search, referring to retrieving relevant items given long, complex natural language contexts. Leveraging large language models like ChatGPT, we correspondingly construct a semi-synthetic evaluation set, Amazon-C4. Empirical results on the new task, as well as conventional retrieval and recommendation tasks, demonstrate that BLaIR exhibit stro
&lt;/p&gt;</description></item><item><title>Mamba4Rec&#26159;&#39318;&#20010;&#25506;&#32034;&#36873;&#25321;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#29992;&#20110;&#39640;&#25928;&#24207;&#21015;&#25512;&#33616;&#30340;&#24037;&#20316;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#25512;&#26029;&#25928;&#29575;&#30340;&#21516;&#26102;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.03900</link><description>&lt;p&gt;
Mamba4Rec&#65306;&#38024;&#23545;&#20855;&#26377;&#36873;&#25321;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#39640;&#25928;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Mamba4Rec: Towards Efficient Sequential Recommendation with Selective State Space Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03900
&lt;/p&gt;
&lt;p&gt;
Mamba4Rec&#26159;&#39318;&#20010;&#25506;&#32034;&#36873;&#25321;&#24615;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#29992;&#20110;&#39640;&#25928;&#24207;&#21015;&#25512;&#33616;&#30340;&#24037;&#20316;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#25512;&#26029;&#25928;&#29575;&#30340;&#21516;&#26102;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#25512;&#33616;&#26088;&#22312;&#20272;&#35745;&#21160;&#24577;&#29992;&#25143;&#20559;&#22909;&#21644;&#21382;&#21490;&#29992;&#25143;&#34892;&#20026;&#20043;&#38388;&#30340;&#39034;&#24207;&#20381;&#36182;&#20851;&#31995;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;Mamba4Rec&#65292;&#36825;&#26159;&#39318;&#20010;&#25506;&#32034;&#36873;&#25321;&#24615;SSM&#28508;&#21147;&#20197;&#23454;&#29616;&#39640;&#25928;&#24207;&#21015;&#25512;&#33616;&#30340;&#24037;&#20316;&#12290;&#36890;&#36807;&#22522;&#26412;&#30340;Mamba&#22359;&#26500;&#24314;&#65292;&#32467;&#21512;&#19968;&#31995;&#21015;&#39034;&#24207;&#24314;&#27169;&#25216;&#26415;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#27169;&#22411;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#25512;&#26029;&#25928;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;Mamba4Rec&#33021;&#22815;&#24456;&#22909;&#22320;&#22788;&#29702;&#24207;&#21015;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03900v1 Announce Type: new  Abstract: Sequential recommendation aims to estimate the dynamic user preferences and sequential dependencies among historical user behaviors. Although Transformer-based models have proven to be effective for sequential recommendation, they suffer from the inference inefficiency problem stemming from the quadratic computational complexity of attention operators, especially for long-range behavior sequences. Inspired by the recent success of state space models (SSMs), we propose Mamba4Rec, which is the first work to explore the potential of selective SSMs for efficient sequential recommendation. Built upon the basic Mamba block which is a selective SSM with an efficient hardware-aware parallel algorithm, we incorporate a series of sequential modeling techniques to further promote the model performance and meanwhile maintain the inference efficiency. Experiments on two public datasets demonstrate that Mamba4Rec is able to well address the effectiven
&lt;/p&gt;</description></item><item><title>Cobweb&#26159;&#19968;&#31181;&#31867;&#20284;&#20154;&#31867;&#31867;&#21035;&#23398;&#20064;&#31995;&#32479;&#65292;&#37319;&#29992;&#31867;&#21035;&#25928;&#29992;&#24230;&#37327;&#26500;&#24314;&#20998;&#23618;&#32452;&#32455;&#30340;&#31867;&#20284;&#26641;&#29366;&#32467;&#26500;&#65292;&#33021;&#22815;&#25429;&#25417;&#24515;&#29702;&#25928;&#24212;&#24182;&#22312;&#21333;&#19968;&#27169;&#22411;&#20013;&#23637;&#29616;&#20986;&#23454;&#20363;&#21644;&#21407;&#22411;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#65292;&#20026;&#23558;&#26469;&#30740;&#31350;&#20154;&#31867;&#31867;&#21035;&#23398;&#20064;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;</title><link>https://arxiv.org/abs/2403.03835</link><description>&lt;p&gt;
Cobweb&#65306;&#19968;&#31181;&#22686;&#37327;&#21644;&#20998;&#23618;&#24335;&#30340;&#20154;&#31867;&#31867;&#21035;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03835
&lt;/p&gt;
&lt;p&gt;
Cobweb&#26159;&#19968;&#31181;&#31867;&#20284;&#20154;&#31867;&#31867;&#21035;&#23398;&#20064;&#31995;&#32479;&#65292;&#37319;&#29992;&#31867;&#21035;&#25928;&#29992;&#24230;&#37327;&#26500;&#24314;&#20998;&#23618;&#32452;&#32455;&#30340;&#31867;&#20284;&#26641;&#29366;&#32467;&#26500;&#65292;&#33021;&#22815;&#25429;&#25417;&#24515;&#29702;&#25928;&#24212;&#24182;&#22312;&#21333;&#19968;&#27169;&#22411;&#20013;&#23637;&#29616;&#20986;&#23454;&#20363;&#21644;&#21407;&#22411;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#65292;&#20026;&#23558;&#26469;&#30740;&#31350;&#20154;&#31867;&#31867;&#21035;&#23398;&#20064;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Cobweb&#26159;&#19968;&#31181;&#31867;&#20284;&#20154;&#31867;&#30340;&#31867;&#21035;&#23398;&#20064;&#31995;&#32479;&#65292;&#19982;&#20854;&#20182;&#22686;&#37327;&#20998;&#31867;&#27169;&#22411;&#19981;&#21516;&#30340;&#26159;&#65292;&#23427;&#21033;&#29992;&#31867;&#21035;&#25928;&#29992;&#24230;&#37327;&#26500;&#24314;&#20998;&#23618;&#32452;&#32455;&#30340;&#31867;&#20284;&#26641;&#29366;&#32467;&#26500;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;Cobweb&#33021;&#22815;&#25429;&#25417;&#24515;&#29702;&#25928;&#24212;&#65292;&#22914;&#22522;&#26412;&#27700;&#24179;&#12289;&#20856;&#22411;&#24615;&#21644;&#25159;&#24418;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#23545;Cobweb&#20316;&#20026;&#20154;&#31867;&#20998;&#31867;&#27169;&#22411;&#30340;&#26356;&#24191;&#27867;&#35780;&#20272;&#20173;&#28982;&#32570;&#20047;&#12290;&#26412;&#30740;&#31350;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#12290;&#23427;&#30830;&#23450;&#20102;Cobweb&#19982;&#32463;&#20856;&#30340;&#20154;&#31867;&#31867;&#21035;&#23398;&#20064;&#25928;&#24212;&#30340;&#19968;&#33268;&#24615;&#12290;&#36824;&#25506;&#35752;&#20102;Cobweb&#23637;&#29616;&#20986;&#22312;&#21333;&#19968;&#27169;&#22411;&#20013;&#26082;&#26377;&#23454;&#20363;&#21448;&#26377;&#21407;&#22411;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#23558;&#26469;&#30740;&#31350;Cobweb&#20316;&#20026;&#20154;&#31867;&#31867;&#21035;&#23398;&#20064;&#30340;&#32508;&#21512;&#27169;&#22411;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03835v1 Announce Type: cross  Abstract: Cobweb, a human like category learning system, differs from other incremental categorization models in constructing hierarchically organized cognitive tree-like structures using the category utility measure. Prior studies have shown that Cobweb can capture psychological effects such as the basic level, typicality, and fan effects. However, a broader evaluation of Cobweb as a model of human categorization remains lacking. The current study addresses this gap. It establishes Cobweb's alignment with classical human category learning effects. It also explores Cobweb's flexibility to exhibit both exemplar and prototype like learning within a single model. These findings set the stage for future research on Cobweb as a comprehensive model of human category learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35299;&#32544;&#32467;&#22270;&#23545;&#27604;&#23398;&#20064;&#23454;&#29616;&#24847;&#22270;&#24863;&#30693;&#25512;&#33616;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#24847;&#22270;&#20197;&#21450;&#36825;&#20123;&#24847;&#22270;&#19978;&#30340;&#34892;&#20026;&#20998;&#24067;</title><link>https://arxiv.org/abs/2403.03714</link><description>&lt;p&gt;
&#36890;&#36807;&#35299;&#32544;&#32467;&#22270;&#23545;&#27604;&#23398;&#20064;&#23454;&#29616;&#24847;&#22270;&#24863;&#30693;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Intent-aware Recommendation via Disentangled Graph Contrastive Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03714
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35299;&#32544;&#32467;&#22270;&#23545;&#27604;&#23398;&#20064;&#23454;&#29616;&#24847;&#22270;&#24863;&#30693;&#25512;&#33616;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#24847;&#22270;&#20197;&#21450;&#36825;&#20123;&#24847;&#22270;&#19978;&#30340;&#34892;&#20026;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#25512;&#33616;&#31995;&#32479;&#24050;&#32463;&#25104;&#20026;&#20027;&#27969;&#36235;&#21183;&#20043;&#19968;&#65292;&#36825;&#26159;&#22240;&#20026;&#23427;&#33021;&#22815;&#20174;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#20013;&#24378;&#22823;&#22320;&#23398;&#20064;&#12290;&#20174;&#34892;&#20026;&#25968;&#25454;&#20013;&#29702;&#35299;&#29992;&#25143;&#24847;&#22270;&#26159;&#25512;&#33616;&#31995;&#32479;&#30340;&#20851;&#38190;&#65292;&#36825;&#20026;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#26412;&#35201;&#27714;&#12290;&#19968;&#20010;&#26159;&#22312;&#29616;&#23454;&#20013;&#29992;&#25143;&#34892;&#20026;&#36890;&#24120;&#26159;&#19981;&#36275;&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#23398;&#20064;&#22797;&#26434;&#32780;&#22810;&#26679;&#30340;&#24847;&#22270;&#12290;&#21478;&#19968;&#20010;&#26159;&#19981;&#21516;&#30340;&#34892;&#20026;&#20855;&#26377;&#19981;&#21516;&#30340;&#24847;&#22270;&#20998;&#24067;&#65292;&#22240;&#27492;&#22914;&#20309;&#24314;&#31435;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#23454;&#29616;&#26356;&#26377;&#35299;&#37322;&#21147;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35299;&#32544;&#32467;&#22270;&#23545;&#27604;&#23398;&#20064;&#23454;&#29616;&#24847;&#22270;&#24863;&#30693;&#25512;&#33616;&#65288;Intent-aware Recommendation via Disentangled Graph Contrastive Learning&#65292;IDCL&#65289;&#65292;&#21516;&#26102;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#24847;&#22270;&#20197;&#21450;&#36825;&#20123;&#24847;&#22270;&#19978;&#30340;&#34892;&#20026;&#20998;&#24067;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#24314;&#27169;&#20026;&#29992;&#25143;-&#29289;&#21697;-&#27010;&#24565;&#22270;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;GNN&#30340;&#34892;&#20026;&#35299;&#32544;&#32467;&#27169;&#22359;&#26469;&#23398;&#20064;&#19981;&#21516;&#30340;&#24847;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03714v1 Announce Type: new  Abstract: Graph neural network (GNN) based recommender systems have become one of the mainstream trends due to the powerful learning ability from user behavior data. Understanding the user intents from behavior data is the key to recommender systems, which poses two basic requirements for GNN-based recommender systems. One is how to learn complex and diverse intents especially when the user behavior is usually inadequate in reality. The other is different behaviors have different intent distributions, so how to establish their relations for a more explainable recommender system. In this paper, we present the Intent-aware Recommendation via Disentangled Graph Contrastive Learning (IDCL), which simultaneously learns interpretable intents and behavior distributions over those intents. Specifically, we first model the user behavior data as a user-item-concept graph, and design a GNN based behavior disentangling module to learn the different intents. T
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;E2URec&#65292;&#36825;&#26159;&#20026;&#20102;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36951;&#24536;&#29305;&#23450;&#29992;&#25143;&#25968;&#25454;&#25152;&#38754;&#20020;&#30340;&#25928;&#29575;&#21644;&#26377;&#25928;&#24615;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.03536</link><description>&lt;p&gt;
&#20026;&#25512;&#33616;&#32780;&#35774;&#35745;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39640;&#25928;&#21644;&#26377;&#25928;&#30340;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Towards Efficient and Effective Unlearning of Large Language Models for Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03536
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;E2URec&#65292;&#36825;&#26159;&#20026;&#20102;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36951;&#24536;&#29305;&#23450;&#29992;&#25143;&#25968;&#25454;&#25152;&#38754;&#20020;&#30340;&#25928;&#29575;&#21644;&#26377;&#25928;&#24615;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26174;&#33879;&#36827;&#23637;&#20135;&#29983;&#20102;&#19968;&#39033;&#26377;&#21069;&#36884;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#21363;&#21033;&#29992;LLMs&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#65288;LLMRec&#65289;&#12290; LLMRec&#30340;&#26377;&#25928;&#24615;&#28304;&#33258;LLMs&#22266;&#26377;&#30340;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#12290; LLMRec&#36890;&#36807;&#22522;&#20110;&#29992;&#25143;&#20114;&#21160;&#25968;&#25454;&#30340;&#25351;&#23548;&#35843;&#25972;&#33719;&#24471;&#25512;&#33616;&#21151;&#33021;&#12290; &#28982;&#32780;&#65292;&#20026;&#20102;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#24182;&#20248;&#21270;&#25928;&#29992;&#65292;LLMRec&#36824;&#24517;&#39035;&#26377;&#24847;&#24536;&#35760;&#29305;&#23450;&#29992;&#25143;&#25968;&#25454;&#65292;&#36825;&#36890;&#24120;&#31216;&#20026;&#25512;&#33616;&#36951;&#24536;&#12290; &#22312;LLMs&#26102;&#20195;&#65292;&#25512;&#33616;&#36951;&#24536;&#22312;\textit{&#25928;&#29575;}&#21644;\textit{&#26377;&#25928;&#24615;}&#26041;&#38754;&#20026;LLMRec&#24102;&#26469;&#20102;&#26032;&#25361;&#25112;&#12290; &#29616;&#26377;&#30340;&#36951;&#24536;&#26041;&#27861;&#38656;&#35201;&#26356;&#26032;LLMRec&#20013;&#25968;&#21313;&#20159;&#21442;&#25968;&#65292;&#36825;&#26159;&#26114;&#36149;&#19988;&#32791;&#26102;&#30340;&#12290; &#27492;&#22806;&#65292;&#23427;&#20204;&#22312;&#36951;&#24536;&#36807;&#31243;&#20013;&#24635;&#26159;&#24433;&#21709;&#27169;&#22411;&#25928;&#29992;&#12290; &#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;\textbf{E2URec}&#65292;&#31532;&#19968;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03536v1 Announce Type: cross  Abstract: The significant advancements in large language models (LLMs) give rise to a promising research direction, i.e., leveraging LLMs as recommenders (LLMRec). The efficacy of LLMRec arises from the open-world knowledge and reasoning capabilities inherent in LLMs. LLMRec acquires the recommendation capabilities through instruction tuning based on user interaction data. However, in order to protect user privacy and optimize utility, it is also crucial for LLMRec to intentionally forget specific user data, which is generally referred to as recommendation unlearning. In the era of LLMs, recommendation unlearning poses new challenges for LLMRec in terms of \textit{inefficiency} and \textit{ineffectiveness}. Existing unlearning methods require updating billions of parameters in LLMRec, which is costly and time-consuming. Besides, they always impact the model utility during the unlearning process. To this end, we propose \textbf{E2URec}, the first
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#29983;&#25104;&#20266;&#26631;&#31614;&#23454;&#29616;&#30340;&#26080;&#30417;&#30563;&#22810;&#35821;&#35328;&#31264;&#23494;&#26816;&#32034;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#35821;&#35328;&#20449;&#24687;&#26816;&#32034;&#20013;&#21462;&#24471;&#20248;&#24322;&#24615;&#33021;&#65292;&#25552;&#39640;&#20102;&#22810;&#35821;&#35328;&#26816;&#32034;&#22120;&#30340;&#23454;&#29992;&#24615;</title><link>https://arxiv.org/abs/2403.03516</link><description>&lt;p&gt;
&#36890;&#36807;&#29983;&#25104;&#20266;&#26631;&#31614;&#23454;&#29616;&#30340;&#26080;&#30417;&#30563;&#22810;&#35821;&#35328;&#31264;&#23494;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03516
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29983;&#25104;&#20266;&#26631;&#31614;&#23454;&#29616;&#30340;&#26080;&#30417;&#30563;&#22810;&#35821;&#35328;&#31264;&#23494;&#26816;&#32034;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#35821;&#35328;&#20449;&#24687;&#26816;&#32034;&#20013;&#21462;&#24471;&#20248;&#24322;&#24615;&#33021;&#65292;&#25552;&#39640;&#20102;&#22810;&#35821;&#35328;&#26816;&#32034;&#22120;&#30340;&#23454;&#29992;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31264;&#23494;&#26816;&#32034;&#26041;&#27861;&#22312;&#22810;&#35821;&#35328;&#20449;&#24687;&#26816;&#32034;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#37197;&#23545;&#25968;&#25454;&#65292;&#36825;&#22312;&#22810;&#35821;&#35328;&#22330;&#26223;&#19979;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;UMR&#65292;&#19968;&#31181;&#26080;&#38656;&#20219;&#20309;&#37197;&#23545;&#25968;&#25454;&#35757;&#32451;&#30340;&#26080;&#30417;&#30563;&#22810;&#35821;&#35328;&#31264;&#23494;&#26816;&#32034;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#24207;&#21015;&#20284;&#28982;&#20272;&#35745;&#33021;&#21147;&#26469;&#33719;&#21462;&#29992;&#20110;&#35757;&#32451;&#31264;&#23494;&#26816;&#32034;&#22120;&#30340;&#20266;&#26631;&#31614;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#26694;&#26550;&#65292;&#36890;&#36807;&#36845;&#20195;&#25913;&#21892;&#22810;&#35821;&#35328;&#31264;&#23494;&#26816;&#32034;&#22120;&#30340;&#24615;&#33021;&#12290;&#23545;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;UMR&#30340;&#24615;&#33021;&#20248;&#20110;&#30417;&#30563;&#22522;&#32447;&#65292;&#23637;&#31034;&#20102;&#26080;&#38656;&#37197;&#23545;&#25968;&#25454;&#35757;&#32451;&#22810;&#35821;&#35328;&#26816;&#32034;&#22120;&#30340;&#28508;&#21147;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;&#25105;&#20204;&#30340;&#28304;&#20195;&#30721;&#12289;&#25968;&#25454;&#21644;&#27169;&#22411;&#24050;&#20844;&#24320;&#21487;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03516v1 Announce Type: new  Abstract: Dense retrieval methods have demonstrated promising performance in multilingual information retrieval, where queries and documents can be in different languages. However, dense retrievers typically require a substantial amount of paired data, which poses even greater challenges in multilingual scenarios. This paper introduces UMR, an Unsupervised Multilingual dense Retriever trained without any paired data. Our approach leverages the sequence likelihood estimation capabilities of multilingual language models to acquire pseudo labels for training dense retrievers. We propose a two-stage framework which iteratively improves the performance of multilingual dense retrievers. Experimental results on two benchmark datasets show that UMR outperforms supervised baselines, showcasing the potential of training multilingual retrievers without paired data, thereby enhancing their practicality. Our source code, data, and models are publicly available
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#33539;&#24335;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#39640;&#32423;&#21305;&#37197;&#21644;&#29983;&#25104;&#36830;&#36143;&#32467;&#26500;&#30340;&#21465;&#36848;&#65292;&#24110;&#21161;&#29992;&#25143;&#26356;&#20840;&#38754;&#29702;&#35299;&#20107;&#20214;&#12290;</title><link>https://arxiv.org/abs/2403.03424</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Generative News Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03424
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#33539;&#24335;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#39640;&#32423;&#21305;&#37197;&#21644;&#29983;&#25104;&#36830;&#36143;&#32467;&#26500;&#30340;&#21465;&#36848;&#65292;&#24110;&#21161;&#29992;&#25143;&#26356;&#20840;&#38754;&#29702;&#35299;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26032;&#38395;&#25512;&#33616;&#26041;&#27861;&#36890;&#36807;&#22312;&#20505;&#36873;&#26032;&#38395;&#21644;&#30001;&#21382;&#21490;&#28857;&#20987;&#26032;&#38395;&#20135;&#29983;&#30340;&#29992;&#25143;&#34920;&#31034;&#20043;&#38388;&#36827;&#34892;&#35821;&#20041;&#21305;&#37197;&#26469;&#22788;&#29702;&#27492;&#20219;&#21153;&#12290;&#20294;&#23427;&#20204;&#24573;&#35270;&#20102;&#19981;&#21516;&#26032;&#38395;&#25991;&#31456;&#20043;&#38388;&#30340;&#39640;&#32423;&#36830;&#25509;&#65292;&#20063;&#24573;&#30053;&#20102;&#36825;&#20123;&#26032;&#38395;&#25991;&#31456;&#19982;&#29992;&#25143;&#20043;&#38388;&#30340;&#28145;&#21051;&#20851;&#31995;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#23450;&#20041;&#35268;&#23450;&#23427;&#20204;&#21482;&#33021;&#21407;&#26679;&#21457;&#24067;&#26032;&#38395;&#25991;&#31456;&#12290;&#30456;&#21453;&#65292;&#23558;&#20960;&#31687;&#30456;&#20851;&#26032;&#38395;&#25991;&#31456;&#25972;&#21512;&#25104;&#36830;&#36143;&#30340;&#21465;&#36848;&#23558;&#24110;&#21161;&#29992;&#25143;&#26356;&#24555;&#36895;&#12289;&#20840;&#38754;&#22320;&#29702;&#35299;&#20107;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#33539;&#24335;&#65292;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;(1)&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20869;&#37096;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#26469;&#36827;&#34892;&#20505;&#36873;&#26032;&#38395;&#21644;&#29992;&#25143;&#34920;&#31034;&#20043;&#38388;&#30340;&#39640;&#32423;&#21305;&#37197;&#65307;(2)&#22522;&#20110;&#25552;&#20379;&#26356;&#24555;&#36895;&#12289;&#20840;&#38754;&#29702;&#35299;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03424v1 Announce Type: new  Abstract: Most existing news recommendation methods tackle this task by conducting semantic matching between candidate news and user representation produced by historical clicked news. However, they overlook the high-level connections among different news articles and also ignore the profound relationship between these news articles and users. And the definition of these methods dictates that they can only deliver news articles as-is. On the contrary, integrating several relevant news articles into a coherent narrative would assist users in gaining a quicker and more comprehensive understanding of events. In this paper, we propose a novel generative news recommendation paradigm that includes two steps: (1) Leveraging the internal knowledge and reasoning capabilities of the Large Language Model (LLM) to perform high-level matching between candidate news and user representation; (2) Generating a coherent and logically structured narrative based on t
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;FedHCDR&#26694;&#26550;&#65292;&#36890;&#36807;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#30340;&#26041;&#24335;&#35299;&#20915;&#20102;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#19981;&#21516;&#39046;&#22495;&#25968;&#25454;&#24322;&#36136;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.02630</link><description>&lt;p&gt;
FedHCDR: &#20855;&#26377;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#30340;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
FedHCDR: Federated Cross-Domain Recommendation with Hypergraph Signal Decoupling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02630
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;FedHCDR&#26694;&#26550;&#65292;&#36890;&#36807;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#30340;&#26041;&#24335;&#35299;&#20915;&#20102;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#19981;&#21516;&#39046;&#22495;&#25968;&#25454;&#24322;&#36136;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36328;&#39046;&#22495;&#25512;&#33616;&#65288;CDR&#65289;&#22791;&#21463;&#20851;&#27880;&#65292;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#39046;&#22495;&#30340;&#29992;&#25143;&#25968;&#25454;&#26469;&#22686;&#24378;&#25512;&#33616;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;CDR&#26041;&#27861;&#38656;&#35201;&#36328;&#39046;&#22495;&#20849;&#20139;&#29992;&#25143;&#25968;&#25454;&#65292;&#36829;&#21453;&#20102;&#12298;&#36890;&#29992;&#25968;&#25454;&#20445;&#25252;&#26465;&#20363;&#12299;&#65288;GDPR&#65289;&#12290;&#22240;&#27492;&#65292;&#24050;&#25552;&#20986;&#20102;&#35768;&#22810;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;&#65288;FedCDR&#65289;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#19981;&#21516;&#39046;&#22495;&#38388;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#19981;&#21487;&#36991;&#20813;&#22320;&#24433;&#21709;&#20102;&#32852;&#37030;&#23398;&#20064;&#30340;&#25972;&#20307;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FedHCDR&#65292;&#19968;&#31181;&#20855;&#26377;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#30340;&#26032;&#22411;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;&#26694;&#26550;&#12290;&#20855;&#20307;&#22320;&#65292;&#20026;&#20102;&#35299;&#20915;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#31216;&#20026;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#65288;HSD&#65289;&#30340;&#26041;&#27861;&#65292;&#23558;&#29992;&#25143;&#29305;&#24449;&#35299;&#32806;&#20026;&#39046;&#22495;&#29420;&#26377;&#21644;&#39046;&#22495;&#20849;&#20139;&#29305;&#24449;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#39640;&#36890;&#21644;&#20302;&#36890;&#36229;&#22270;&#28388;&#27874;&#22120;&#26469;&#36827;&#34892;&#35299;&#32806;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02630v1 Announce Type: new  Abstract: In recent years, Cross-Domain Recommendation (CDR) has drawn significant attention, which utilizes user data from multiple domains to enhance the recommendation performance. However, current CDR methods require sharing user data across domains, thereby violating the General Data Protection Regulation (GDPR). Consequently, numerous approaches have been proposed for Federated Cross-Domain Recommendation (FedCDR). Nevertheless, the data heterogeneity across different domains inevitably influences the overall performance of federated learning. In this study, we propose FedHCDR, a novel Federated Cross-Domain Recommendation framework with Hypergraph signal decoupling. Specifically, to address the data heterogeneity across domains, we introduce an approach called hypergraph signal decoupling (HSD) to decouple the user features into domain-exclusive and domain-shared features. The approach employs high-pass and low-pass hypergraph filters to de
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#39044;&#35745;&#31639;&#30340;&#23884;&#20837;&#30456;&#20284;&#24615;&#29983;&#25104;&#20010;&#24615;&#21270;&#20449;&#24687;&#27969;&#65292;&#25552;&#39640;&#20102;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#23458;&#25143;&#21442;&#19982;&#24230;&#21644;&#20307;&#39564;&#65292;&#36716;&#21270;&#29575;&#25552;&#21319;4.9&#65285;&#12290;</title><link>https://arxiv.org/abs/2402.16073</link><description>&lt;p&gt;
&#20351;&#29992;&#39044;&#35745;&#31639;&#30340;&#23884;&#20837;&#30456;&#20284;&#24615;&#29983;&#25104;&#20960;&#20046;&#23454;&#26102;&#20010;&#24615;&#21270;&#20449;&#24687;&#27969;
&lt;/p&gt;
&lt;p&gt;
Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16073
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#39044;&#35745;&#31639;&#30340;&#23884;&#20837;&#30456;&#20284;&#24615;&#29983;&#25104;&#20010;&#24615;&#21270;&#20449;&#24687;&#27969;&#65292;&#25552;&#39640;&#20102;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#23458;&#25143;&#21442;&#19982;&#24230;&#21644;&#20307;&#39564;&#65292;&#36716;&#21270;&#29575;&#25552;&#21319;4.9&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#23884;&#20837;&#26469;&#32534;&#30721;&#29992;&#25143;&#21160;&#20316;&#21644;&#39033;&#30446;&#65292;&#28982;&#21518;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#36827;&#34892;&#26816;&#32034;&#65292;&#20351;&#29992;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#20004;&#20010;&#25361;&#25112;&#65306;1&#65289;&#29992;&#25143;&#23884;&#20837;&#21487;&#33021;&#38480;&#21046;&#25152;&#25429;&#33719;&#30340;&#20852;&#36259;&#22810;&#26679;&#24615;&#65292;2&#65289;&#20445;&#25345;&#23427;&#20204;&#26368;&#26032;&#38656;&#35201;&#26114;&#36149;&#30340;&#23454;&#26102;&#22522;&#30784;&#35774;&#26045;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23454;&#38469;&#24037;&#19994;&#29615;&#22659;&#20013;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21160;&#24577;&#26356;&#26032;&#23458;&#25143;&#37197;&#32622;&#25991;&#20214;&#65292;&#24182;&#27599;&#20004;&#20998;&#38047;&#32452;&#25104;&#19968;&#20010;&#20449;&#24687;&#27969;&#65292;&#21033;&#29992;&#39044;&#35745;&#31639;&#30340;&#23884;&#20837;&#21450;&#20854;&#21508;&#33258;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#22312;&#33655;&#20848;&#21644;&#27604;&#21033;&#26102;&#26368;&#22823;&#30340;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#20043;&#19968;Bol&#19978;&#27979;&#35797;&#24182;&#37096;&#32626;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#23458;&#25143;&#21442;&#19982;&#24230;&#21644;&#20307;&#39564;&#65292;&#23548;&#33268;&#36716;&#21270;&#29575;&#26174;&#33879;&#25552;&#39640;&#20102;4.9&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16073v1 Announce Type: cross  Abstract: In personalized recommender systems, embeddings are often used to encode customer actions and items, and retrieval is then performed in the embedding space using approximate nearest neighbor search. However, this approach can lead to two challenges: 1) user embeddings can restrict the diversity of interests captured and 2) the need to keep them up-to-date requires an expensive, real-time infrastructure. In this paper, we propose a method that overcomes these challenges in a practical, industrial setting. The method dynamically updates customer profiles and composes a feed every two minutes, employing precomputed embeddings and their respective similarities. We tested and deployed this method to personalise promotional items at Bol, one of the largest e-commerce platforms of the Netherlands and Belgium. The method enhanced customer engagement and experience, leading to a significant 4.9% uplift in conversions.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#30041;&#23384;&#24341;&#21457;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#30340;&#34892;&#20026;&#22312;&#36807;&#28193;&#26399;&#38388;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#65292;&#20174;&#32780;&#30772;&#22351;&#20102;A/B&#23454;&#39564;&#20316;&#20026;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13959</link><description>&lt;p&gt;
&#20855;&#26377;&#24322;&#26500;&#29992;&#25143;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#30041;&#23384;&#24341;&#21457;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Retention Induced Biases in a Recommendation System with Heterogeneous Users
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13959
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#30041;&#23384;&#24341;&#21457;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#30340;&#34892;&#20026;&#22312;&#36807;&#28193;&#26399;&#38388;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#65292;&#20174;&#32780;&#30772;&#22351;&#20102;A/B&#23454;&#39564;&#20316;&#20026;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#30740;&#31350;&#20102;&#19968;&#20010;&#20855;&#26377;&#29992;&#25143;&#27969;&#20837;&#21644;&#27969;&#22833;&#21160;&#24577;&#30340;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#30340;&#27010;&#24565;&#27169;&#22411;&#12290;&#24403;&#27969;&#20837;&#21644;&#27969;&#22833;&#36798;&#21040;&#24179;&#34913;&#26102;&#65292;&#29992;&#25143;&#20998;&#24067;&#36798;&#21040;&#31283;&#23450;&#29366;&#24577;&#12290;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#25913;&#21464;&#31283;&#23450;&#29366;&#24577;&#24182;&#20135;&#29983;&#36807;&#28193;&#26399;&#12290;&#22312;&#36825;&#20010;&#26399;&#38388;&#65292;RS&#30340;&#34892;&#20026;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#36807;&#28193;&#26399;&#20869;&#33719;&#24471;&#30340;A/B&#23454;&#39564;&#25351;&#26631;&#26159;RS&#38271;&#26399;&#24615;&#33021;&#30340;&#20559;&#35265;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#23398;&#32773;&#21644;&#23454;&#36341;&#32773;&#32463;&#24120;&#22312;&#24341;&#20837;&#26032;&#31639;&#27861;&#21518;&#19981;&#20037;&#36827;&#34892;A/B&#27979;&#35797;&#20197;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#40644;&#37329;&#26631;&#20934;&#30340;A/B&#23454;&#39564;&#33539;&#24335;&#21487;&#33021;&#20135;&#29983;&#38169;&#35823;&#32467;&#35770;&#12290;&#25105;&#36824;&#31616;&#35201;&#35752;&#35770;&#20102;&#29992;&#25143;&#20445;&#30041;&#21160;&#24577;&#36896;&#25104;&#30340;&#25968;&#25454;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13959v1 Announce Type: new  Abstract: I examine a conceptual model of a recommendation system (RS) with user inflow and churn dynamics. When inflow and churn balance out, the user distribution reaches a steady state. Changing the recommendation algorithm alters the steady state and creates a transition period. During this period, the RS behaves differently from its new steady state. In particular, A/B experiment metrics obtained in transition periods are biased indicators of the RS's long term performance. Scholars and practitioners, however, often conduct A/B tests shortly after introducing new algorithms to validate their effectiveness. This A/B experiment paradigm, widely regarded as the gold standard for assessing RS improvements, may consequently yield false conclusions. I also briefly discuss the data bias caused by the user retention dynamics.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65288;COVE&#65289;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19979;&#30340;&#23454;&#20307;&#20998;&#31867;&#20449;&#24687;&#65292;&#24182;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16761</link><description>&lt;p&gt;
&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Co-evolving Vector Quantization for ID-based Recommendation. (arXiv:2308.16761v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16761
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65288;COVE&#65289;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19979;&#30340;&#23454;&#20307;&#20998;&#31867;&#20449;&#24687;&#65292;&#24182;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31867;&#21035;&#20449;&#24687;&#23545;&#20110;&#25552;&#39640;&#25512;&#33616;&#30340;&#36136;&#37327;&#21644;&#20010;&#24615;&#21270;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#20013;&#65292;&#39033;&#30446;&#31867;&#21035;&#20449;&#24687;&#30340;&#21487;&#29992;&#24615;&#24182;&#19981;&#19968;&#33268;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#20197;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#23454;&#20307;&#65288;&#21363;&#29992;&#25143;&#21644;&#39033;&#30446;&#65289;&#22312;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19978;&#30340;&#20998;&#31867;&#20449;&#24687;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65292;&#21363;COVE&#65292;&#23427;&#33021;&#22815;&#21516;&#26102;&#23398;&#20064;&#21644;&#25913;&#36827;&#20195;&#30721;&#34920;&#31034;&#21644;&#23454;&#20307;&#23884;&#20837;&#65292;&#24182;&#20197;&#20174;&#38543;&#26426;&#21021;&#22987;&#21270;&#29366;&#24577;&#24320;&#22987;&#30340;&#31471;&#21040;&#31471;&#26041;&#24335;&#36827;&#34892;&#12290;&#36890;&#36807;&#20854;&#39640;&#24230;&#36866;&#24212;&#24615;&#65292;COVE&#21487;&#20197;&#36731;&#26494;&#38598;&#25104;&#21040;&#29616;&#26377;&#30340;&#25512;&#33616;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;COVE&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#21015;&#34920;&#23436;&#25104;&#12289;&#21327;&#21516;&#36807;&#28388;&#21644;&#28857;&#20987;&#29575;&#39044;&#27979;&#65292;&#28085;&#30422;&#19981;&#21516;&#30340;&#25512;&#33616;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Category information plays a crucial role in enhancing the quality and personalization of recommendations. Nevertheless, the availability of item category information is not consistently present, particularly in the context of ID-based recommendations. In this work, we propose an alternative approach to automatically learn and generate entity (i.e., user and item) categorical information at different levels of granularity, specifically for ID-based recommendation. Specifically, we devise a co-evolving vector quantization framework, namely COVE, which enables the simultaneous learning and refinement of code representation and entity embedding in an end-to-end manner, starting from the randomly initialized states. With its high adaptability, COVE can be easily integrated into existing recommendation models. We validate the effectiveness of COVE on various recommendation tasks including list completion, collaborative filtering, and click-through rate prediction, across different recommend
&lt;/p&gt;</description></item></channel></rss>