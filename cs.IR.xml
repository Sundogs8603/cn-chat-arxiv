<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#26292;&#38706;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#30340;&#20542;&#21521;&#21644;&#26292;&#38706;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#12290;</title><link>http://arxiv.org/abs/2310.20388</link><description>&lt;p&gt;
&#19981;&#20351;&#29992;&#26292;&#38706;&#25968;&#25454;&#30340;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#20542;&#21521;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimating Propensity for Causality-based Recommendation without Exposure Data. (arXiv:2310.20388v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#26292;&#38706;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#30340;&#20542;&#21521;&#21644;&#26292;&#38706;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#31995;&#32479;&#20851;&#27880;&#29992;&#25143;&#19982;&#29289;&#21697;&#20132;&#20114;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#21363;&#29289;&#21697;&#30340;&#25512;&#33616;&#25110;&#26292;&#38706;&#32473;&#29992;&#25143;&#30340;&#24773;&#20917;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#30340;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#25512;&#33616;&#12290;&#30001;&#20110;&#23545;&#29992;&#25143;&#12289;&#21334;&#23478;&#21644;&#24179;&#21488;&#37117;&#26377;&#22810;&#26041;&#38754;&#30340;&#22909;&#22788;&#65292;&#36825;&#31867;&#25512;&#33616;&#31995;&#32479;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#26041;&#27861;&#38656;&#35201;&#39069;&#22806;&#30340;&#36755;&#20837;&#65292;&#21363;&#26292;&#38706;&#25968;&#25454;&#21644;/&#25110;&#20542;&#21521;&#24471;&#20998;&#65288;&#21363;&#26292;&#38706;&#30340;&#27010;&#29575;&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;&#30001;&#20110;&#25216;&#26415;&#25110;&#38544;&#31169;&#38480;&#21046;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#24448;&#24448;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#23545;&#20110;&#24314;&#27169;&#25512;&#33616;&#22240;&#26524;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#30340;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#20542;&#21521;&#20272;&#35745;&#65288;PropCare&#65289;&#12290;&#23427;&#21487;&#20197;&#20174;&#19968;&#31181;&#26356;&#23454;&#38469;&#30340;&#35774;&#32622;&#20013;&#20272;&#35745;&#20542;&#21521;&#21644;&#26292;&#38706;&#65292;&#21363;&#21482;&#26377;&#20132;&#20114;&#25968;&#25454;&#21487;&#29992;&#65292;&#27809;&#26377;&#20851;&#20110;&#26292;&#38706;&#25110;&#20542;&#21521;&#30340;&#20219;&#20309;&#30495;&#23454;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causality-based recommendation systems focus on the causal effects of user-item interactions resulting from item exposure (i.e., which items are recommended or exposed to the user), as opposed to conventional correlation-based recommendation. They are gaining popularity due to their multi-sided benefits to users, sellers and platforms alike. However, existing causality-based recommendation methods require additional input in the form of exposure data and/or propensity scores (i.e., the probability of exposure) for training. Such data, crucial for modeling causality in recommendation, are often not available in real-world situations due to technical or privacy constraints. In this paper, we bridge the gap by proposing a new framework, called Propensity Estimation for Causality-based Recommendation (PropCare). It can estimate the propensity and exposure from a more practical setup, where only interaction data are available without any ground truth on exposure or propensity in training an
&lt;/p&gt;</description></item><item><title>LiLAS 2020&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#23398;&#26415;&#25628;&#32034;&#23454;&#39564;&#23460;&#65292;&#25552;&#20379;&#20102;&#20004;&#20010;&#24179;&#21488;LIVIVO&#21644;GESIS Search&#65292;&#22312;&#30495;&#23454;&#29615;&#22659;&#20013;&#35780;&#20272;&#23398;&#26415;&#25628;&#32034;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.20387</link><description>&lt;p&gt;
LiLAS 2020&#32508;&#36848; -- &#29992;&#20110;&#23398;&#26415;&#25628;&#32034;&#30340;&#29983;&#27963;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
Overview of LiLAS 2020 -- Living Labs for Academic Search. (arXiv:2310.20387v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20387
&lt;/p&gt;
&lt;p&gt;
LiLAS 2020&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#23398;&#26415;&#25628;&#32034;&#23454;&#39564;&#23460;&#65292;&#25552;&#20379;&#20102;&#20004;&#20010;&#24179;&#21488;LIVIVO&#21644;GESIS Search&#65292;&#22312;&#30495;&#23454;&#29615;&#22659;&#20013;&#35780;&#20272;&#23398;&#26415;&#25628;&#32034;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#26415;&#25628;&#32034;&#26159;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#22810;&#24180;&#26469;&#19968;&#30452;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#21363;&#20351;&#22312;&#20170;&#22825;&#65292;&#23547;&#25214;&#23398;&#26415;&#36164;&#26009;&#20173;&#28982;&#26159;&#19968;&#20010;&#24191;&#27867;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#26368;&#36817;&#24320;&#22987;&#33268;&#21147;&#20110;&#35299;&#20915;&#20687;COVID-19&#22823;&#27969;&#34892;&#36825;&#26679;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#27979;&#35797;&#38598;&#21644;&#19987;&#38376;&#30340;&#25968;&#25454;&#38598;&#22914;CORD-19&#21482;&#33021;&#36827;&#34892;&#31995;&#32479;&#23548;&#21521;&#30340;&#23454;&#39564;&#65292;&#32780;&#22312;&#30495;&#23454;&#29615;&#22659;&#20013;&#35780;&#20272;&#31639;&#27861;&#30340;&#26426;&#20250;&#21482;&#23545;&#26469;&#33258;&#24037;&#19994;&#30028;&#30340;&#30740;&#31350;&#20154;&#21592;&#24320;&#25918;&#12290;&#22312;LiLAS&#20013;&#65292;&#25105;&#20204;&#24320;&#25918;&#20102;&#20004;&#20010;&#23398;&#26415;&#25628;&#32034;&#24179;&#21488;&#65292;&#20197;&#20415;&#21442;&#19982;&#30740;&#31350;&#32773;&#33021;&#22815;&#22312;&#22522;&#20110;Docker&#30340;&#30740;&#31350;&#29615;&#22659;&#20013;&#35780;&#20272;&#20182;&#20204;&#30340;&#31995;&#32479;&#12290;&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#25551;&#36848;&#20102;&#21160;&#26426;&#12289;&#22522;&#30784;&#35774;&#26045;&#21644;&#20004;&#20010;&#31995;&#32479;LIVIVO&#21644;GESIS Search&#65292;&#23427;&#20204;&#26159;CLEF&#23454;&#39564;&#23460;&#30340;&#19968;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Academic Search is a timeless challenge that the field of Information Retrieval has been dealing with for many years. Even today, the search for academic material is a broad field of research that recently started working on problems like the COVID-19 pandemic. However, test collections and specialized data sets like CORD-19 only allow for system-oriented experiments, while the evaluation of algorithms in real-world environments is only available to researchers from industry. In LiLAS, we open up two academic search platforms to allow participating research to evaluate their systems in a Docker-based research environment. This overview paper describes the motivation, infrastructure, and two systems LIVIVO and GESIS Search that are part of this CLEF lab.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20351;&#29992;&#22823;&#35268;&#27169;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;&#29616;&#26377;&#30340;&#22810;&#27169;&#24577;&#25512;&#33616;&#31995;&#32479;&#20027;&#35201;&#20381;&#36182;&#20110;&#21333;&#29420;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#24182;&#19988;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#21482;&#26377;&#27973;&#23618;&#27425;&#30340;&#23545;&#40784;&#65292;&#32780;&#22823;&#35268;&#27169;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#27169;&#24577;&#20043;&#38388;&#30340;&#28508;&#22312;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.20343</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#29992;&#20110;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Large Multi-modal Encoders for Recommendation. (arXiv:2310.20343v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20351;&#29992;&#22823;&#35268;&#27169;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;&#29616;&#26377;&#30340;&#22810;&#27169;&#24577;&#25512;&#33616;&#31995;&#32479;&#20027;&#35201;&#20381;&#36182;&#20110;&#21333;&#29420;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#24182;&#19988;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#21482;&#26377;&#27973;&#23618;&#27425;&#30340;&#23545;&#40784;&#65292;&#32780;&#22823;&#35268;&#27169;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#27169;&#24577;&#20043;&#38388;&#30340;&#28508;&#22312;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#24555;&#36895;&#22686;&#38271;&#30340;&#22312;&#32447;&#22810;&#23186;&#20307;&#26381;&#21153;&#65288;&#22914;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#65289;&#20351;&#24471;&#38656;&#35201;&#24320;&#21457;&#20010;&#24615;&#21270;&#25512;&#33616;&#26041;&#27861;&#26469;&#23545;&#27599;&#20010;&#39033;&#30446;&#30340;&#22810;&#26679;&#20869;&#23481;&#36827;&#34892;&#32534;&#30721;&#12290;&#29616;&#20195;&#30340;&#22810;&#27169;&#24577;&#25512;&#33616;&#31995;&#32479;&#21033;&#29992;&#20174;&#21407;&#22987;&#22270;&#20687;&#21644;&#29289;&#21697;&#25551;&#36848;&#20013;&#33719;&#21462;&#30340;&#22810;&#31181;&#29305;&#24449;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22810;&#27169;&#24577;&#25512;&#33616;&#31995;&#32479;&#20027;&#35201;&#20381;&#36182;&#20110;&#36890;&#36807;&#39044;&#35757;&#32451;&#30340;&#23186;&#20307;&#29305;&#23450;&#32534;&#30721;&#22120;&#21333;&#29420;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#24182;&#19988;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#21482;&#26377;&#27973;&#23618;&#27425;&#30340;&#23545;&#40784;&#65292;&#38480;&#21046;&#20102;&#36825;&#20123;&#31995;&#32479;&#25429;&#25417;&#27169;&#24577;&#20043;&#38388;&#28508;&#22312;&#20851;&#31995;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#22312;&#25512;&#33616;&#31995;&#32479;&#29305;&#23450;&#32972;&#26223;&#19979;&#20351;&#29992;&#22823;&#35268;&#27169;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#30340;&#29992;&#27861;&#65292;&#22240;&#20026;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#35780;&#20272;&#29289;&#21697;&#25490;&#21517;&#26102;&#65292;&#36825;&#20123;&#32534;&#30721;&#22120;&#20197;&#21069;&#24050;&#32463;&#23637;&#31034;&#20986;&#26368;&#20808;&#36827;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, the rapid growth of online multimedia services, such as e-commerce platforms, has necessitated the development of personalised recommendation approaches that can encode diverse content about each item. Indeed, modern multi-modal recommender systems exploit diverse features obtained from raw images and item descriptions to enhance the recommendation performance. However, the existing multi-modal recommenders primarily depend on the features extracted individually from different media through pre-trained modality-specific encoders, and exhibit only shallow alignments between different modalities - limiting these systems' ability to capture the underlying relationships between the modalities. In this paper, we investigate the usage of large multi-modal encoders within the specific context of recommender systems, as these have previously demonstrated state-of-the-art effectiveness when ranking items across various domains. Specifically, we tailor two state-of-the-art multi
&lt;/p&gt;</description></item><item><title>FA&#22242;&#38431;&#21442;&#21152;&#20102;NTCIR-17 UFO&#20219;&#21153;&#65292;&#36890;&#36807;&#21033;&#29992;ELECTRA&#35821;&#35328;&#27169;&#22411;&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#23545;&#34920;&#26684;&#20013;&#26377;&#20215;&#20540;&#25968;&#25454;&#30340;&#25552;&#21462;&#65292;&#36798;&#21040;&#20102;93.43%&#30340;&#20934;&#30830;&#29575;&#65292;&#24182;&#22312;&#25490;&#34892;&#27036;&#19978;&#33719;&#24471;&#31532;&#20108;&#21517;&#12290;&#22312;TTRE&#20219;&#21153;&#20013;&#65292;&#20182;&#20204;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#26469;&#25552;&#21462;&#25991;&#26412;&#21644;&#34920;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.20322</link><description>&lt;p&gt;
NTCIR-17 UFO&#20219;&#21153;&#20013;&#30340;FA&#22242;&#38431;&#65288;arXiv:2310.20322v1 [cs.CL]&#65289;
&lt;/p&gt;
&lt;p&gt;
FA Team at the NTCIR-17 UFO Task. (arXiv:2310.20322v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20322
&lt;/p&gt;
&lt;p&gt;
FA&#22242;&#38431;&#21442;&#21152;&#20102;NTCIR-17 UFO&#20219;&#21153;&#65292;&#36890;&#36807;&#21033;&#29992;ELECTRA&#35821;&#35328;&#27169;&#22411;&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#25104;&#21151;&#23454;&#29616;&#20102;&#23545;&#34920;&#26684;&#20013;&#26377;&#20215;&#20540;&#25968;&#25454;&#30340;&#25552;&#21462;&#65292;&#36798;&#21040;&#20102;93.43%&#30340;&#20934;&#30830;&#29575;&#65292;&#24182;&#22312;&#25490;&#34892;&#27036;&#19978;&#33719;&#24471;&#31532;&#20108;&#21517;&#12290;&#22312;TTRE&#20219;&#21153;&#20013;&#65292;&#20182;&#20204;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#26469;&#25552;&#21462;&#25991;&#26412;&#21644;&#34920;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
FA&#22242;&#38431;&#21442;&#21152;&#20102;NTCIR-17 UFO&#30340;&#34920;&#26684;&#25968;&#25454;&#25552;&#21462;&#65288;TDE&#65289;&#21644;&#25991;&#26412;&#21040;&#34920;&#26684;&#20851;&#31995;&#25552;&#21462;&#65288;TTRE&#65289;&#20219;&#21153;&#12290;&#26412;&#25991;&#25253;&#21578;&#20102;&#25105;&#20204;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#23448;&#26041;&#32467;&#26524;&#12290;&#25105;&#20204;&#25104;&#21151;&#22320;&#21033;&#29992;&#22522;&#20110;ELECTRA&#35821;&#35328;&#27169;&#22411;&#30340;&#21508;&#31181;&#22686;&#24378;&#25216;&#26415;&#20174;&#34920;&#26684;&#20013;&#25552;&#21462;&#26377;&#20215;&#20540;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#21162;&#21147;&#23548;&#33268;&#20102;93.43%&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;TDE&#20934;&#30830;&#29575;&#65292;&#24182;&#20351;&#25105;&#20204;&#22312;&#25490;&#34892;&#27036;&#19978;&#25490;&#21517;&#31532;&#20108;&#12290;&#36825;&#19968;&#21331;&#36234;&#25104;&#23601;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;TTRE&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#26469;&#25552;&#21462;&#25991;&#26412;&#21644;&#34920;&#26684;&#20043;&#38388;&#30340;&#26377;&#24847;&#20041;&#30340;&#20851;&#31995;&#65292;&#24182;&#39564;&#35777;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The FA team participated in the Table Data Extraction (TDE) and Text-to-Table Relationship Extraction (TTRE) tasks of the NTCIR-17 Understanding of Non-Financial Objects in Financial Reports (UFO). This paper reports our approach to solving the problems and discusses the official results. We successfully utilized various enhancement techniques based on the ELECTRA language model to extract valuable data from tables. Our efforts resulted in an impressive TDE accuracy rate of 93.43 %, positioning us in second place on the Leaderboard rankings. This outstanding achievement is a testament to our proposed approach's effectiveness. In the TTRE task, we proposed the rule-based method to extract meaningful relationships between the text and tables task and confirmed the performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#27604;&#36739;&#24615;&#20135;&#21697;&#35780;&#35770;&#20013;&#25552;&#21462;&#20135;&#21697;&#27604;&#36739;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#35821;&#20041;&#35282;&#33394;&#26631;&#27880;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2310.20274</link><description>&lt;p&gt;
&#20174;&#27604;&#36739;&#24615;&#20135;&#21697;&#35780;&#35770;&#20013;&#25552;&#21462;&#24863;&#20852;&#36259;&#30340;&#23454;&#20307;
&lt;/p&gt;
&lt;p&gt;
Extracting Entities of Interest from Comparative Product Reviews. (arXiv:2310.20274v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20274
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#27604;&#36739;&#24615;&#20135;&#21697;&#35780;&#35770;&#20013;&#25552;&#21462;&#20135;&#21697;&#27604;&#36739;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#35821;&#20041;&#35282;&#33394;&#26631;&#27880;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#21508;&#31181;&#30005;&#23376;&#21830;&#21153;&#32593;&#31449;&#30340;&#29992;&#25143;&#35780;&#35770;&#20013;&#25552;&#21462;&#20135;&#21697;&#27604;&#36739;&#20449;&#24687;&#12290;&#20219;&#20309;&#19968;&#20010;&#27604;&#36739;&#24615;&#20135;&#21697;&#35780;&#35770;&#37117;&#26377;&#19977;&#20010;&#37325;&#35201;&#30340;&#20449;&#24687;&#23454;&#20307;&#65306;&#34987;&#27604;&#36739;&#20135;&#21697;&#30340;&#21517;&#31216;&#65292;&#29992;&#25143;&#35266;&#28857;&#65288;&#35859;&#35789;&#65289;&#20197;&#21450;&#34987;&#27604;&#36739;&#30340;&#29305;&#24449;&#25110;&#26041;&#38754;&#12290;&#25152;&#26377;&#36825;&#20123;&#20449;&#24687;&#23454;&#20307;&#24444;&#27492;&#20381;&#36182;&#24182;&#21463;&#21040;&#35780;&#35770;&#35821;&#35328;&#35268;&#21017;&#30340;&#32422;&#26463;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#36825;&#20123;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#21487;&#20197;&#24456;&#22909;&#22320;&#36890;&#36807;LSTM&#36827;&#34892;&#25429;&#25417;&#12290;&#25105;&#20204;&#22312;&#29616;&#26377;&#30340;&#25163;&#21160;&#26631;&#35760;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#31995;&#32479;&#65292;&#24182;&#35266;&#23519;&#21040;&#20854;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#30340;&#35821;&#20041;&#35282;&#33394;&#26631;&#27880;&#65288;SRL&#65289;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a deep learning based approach to extract product comparison information out of user reviews on various e-commerce websites. Any comparative product review has three major entities of information: the names of the products being compared, the user opinion (predicate) and the feature or aspect under comparison. All these informing entities are dependent on each other and bound by the rules of the language, in the review. We observe that their inter-dependencies can be captured well using LSTMs. We evaluate our system on existing manually labeled datasets and observe out-performance over the existing Semantic Role Labeling (SRL) framework popular for this task.
&lt;/p&gt;</description></item><item><title>FedRec+&#26159;&#19968;&#20010;&#38598;&#25104;&#26694;&#26550;&#65292;&#26088;&#22312;&#22686;&#24378;&#38544;&#31169;&#24615;&#21644;&#35299;&#20915;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;&#23427;&#21033;&#29992;&#29305;&#24449;&#30456;&#20284;&#24615;&#26469;&#29983;&#25104;&#20266;&#39033;&#30446;&#30340;&#34394;&#25311;&#35780;&#20998;&#65292;&#20943;&#23569;&#22122;&#22768;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;Wasserstein&#36317;&#31163;&#26469;&#20272;&#35745;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.20193</link><description>&lt;p&gt;
FedRec+:&#22686;&#24378;&#38544;&#31169;&#24615;&#21644;&#35299;&#20915;&#24322;&#36136;&#24615;&#38382;&#39064;&#30340;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
FedRec+: Enhancing Privacy and Addressing Heterogeneity in Federated Recommendation Systems. (arXiv:2310.20193v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20193
&lt;/p&gt;
&lt;p&gt;
FedRec+&#26159;&#19968;&#20010;&#38598;&#25104;&#26694;&#26550;&#65292;&#26088;&#22312;&#22686;&#24378;&#38544;&#31169;&#24615;&#21644;&#35299;&#20915;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;&#23427;&#21033;&#29992;&#29305;&#24449;&#30456;&#20284;&#24615;&#26469;&#29983;&#25104;&#20266;&#39033;&#30446;&#30340;&#34394;&#25311;&#35780;&#20998;&#65292;&#20943;&#23569;&#22122;&#22768;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;Wasserstein&#36317;&#31163;&#26469;&#20272;&#35745;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#20445;&#25252;&#38544;&#31169;&#21644;&#38477;&#20302;&#36793;&#32536;&#29992;&#25143;&#30340;&#36890;&#20449;&#25104;&#26412;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;&#32852;&#37030;&#23398;&#20064;&#22312;&#36991;&#20813;&#23458;&#25143;&#31471;&#21644;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#25968;&#25454;&#20132;&#25442;&#26041;&#38754;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#30740;&#31350;&#34920;&#26126;&#65292;&#26381;&#21153;&#22120;&#21487;&#20197;&#26681;&#25454;&#20004;&#36718;&#29992;&#25143;&#19978;&#20256;&#30340;&#26799;&#24230;&#30340;&#38750;&#38646;&#26799;&#24230;&#21464;&#21270;&#26469;&#25512;&#26029;&#29992;&#25143;&#30340;&#35780;&#20998;&#12290;&#27492;&#22806;&#65292;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#23548;&#33268;&#25512;&#33616;&#24615;&#33021;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedRec+&#30340;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#30340;&#38598;&#25104;&#26694;&#26550;&#65292;&#26088;&#22312;&#22686;&#24378;&#38544;&#31169;&#24615;&#24182;&#35299;&#20915;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;FedRec+&#21033;&#29992;&#22522;&#20110;&#29305;&#24449;&#30456;&#20284;&#24615;&#30340;&#26368;&#20248;&#23376;&#38598;&#36873;&#25321;&#26469;&#29983;&#25104;&#20266;&#39033;&#30446;&#30340;&#36817;&#20284;&#26368;&#20339;&#34394;&#25311;&#35780;&#20998;&#65292;&#20165;&#21033;&#29992;&#29992;&#25143;&#30340;&#26412;&#22320;&#20449;&#24687;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20943;&#23569;&#22122;&#22768;&#32780;&#19981;&#22686;&#21152;&#39069;&#22806;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;Wasserstein&#36317;&#31163;&#26469;&#20272;&#35745;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Preserving privacy and reducing communication costs for edge users pose significant challenges in recommendation systems. Although federated learning has proven effective in protecting privacy by avoiding data exchange between clients and servers, it has been shown that the server can infer user ratings based on updated non-zero gradients obtained from two consecutive rounds of user-uploaded gradients. Moreover, federated recommendation systems (FRS) face the challenge of heterogeneity, leading to decreased recommendation performance. In this paper, we propose FedRec+, an ensemble framework for FRS that enhances privacy while addressing the heterogeneity challenge. FedRec+ employs optimal subset selection based on feature similarity to generate near-optimal virtual ratings for pseudo items, utilizing only the user's local information. This approach reduces noise without incurring additional communication costs. Furthermore, we utilize the Wasserstein distance to estimate the heterogene
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LFG&#30340;&#29983;&#25104;&#32593;&#32476;&#65292;&#29992;&#20110;&#23454;&#29616;&#23454;&#26102;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#32593;&#32476;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21160;&#24577;&#29983;&#25104;&#29992;&#25143;&#30340;&#28508;&#22312;&#22240;&#23376;&#65292;&#26080;&#38656;&#37325;&#26032;&#20998;&#35299;&#25110;&#37325;&#26032;&#35757;&#32451;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#32593;&#32476;&#22312;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#23454;&#26102;&#25512;&#33616;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.20189</link><description>&lt;p&gt;
LFG&#65306;&#19968;&#31181;&#29992;&#20110;&#23454;&#26102;&#25512;&#33616;&#30340;&#29983;&#25104;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
LFG: A Generative Network for Real-Time Recommendation. (arXiv:2310.20189v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LFG&#30340;&#29983;&#25104;&#32593;&#32476;&#65292;&#29992;&#20110;&#23454;&#29616;&#23454;&#26102;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#32593;&#32476;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21160;&#24577;&#29983;&#25104;&#29992;&#25143;&#30340;&#28508;&#22312;&#22240;&#23376;&#65292;&#26080;&#38656;&#37325;&#26032;&#20998;&#35299;&#25110;&#37325;&#26032;&#35757;&#32451;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#32593;&#32476;&#22312;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#23454;&#26102;&#25512;&#33616;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26159;&#24403;&#20170;&#37325;&#35201;&#30340;&#20449;&#24687;&#25216;&#26415;&#65292;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#30340;&#25512;&#33616;&#31639;&#27861;&#24050;&#25104;&#20026;&#35813;&#39046;&#22495;&#30340;&#30740;&#31350;&#28909;&#28857;&#12290;&#36890;&#36807;&#30697;&#38453;&#20998;&#35299;&#21644;&#26799;&#24230;&#19979;&#38477;&#25429;&#25417;&#28508;&#22312;&#29305;&#24449;&#20197;&#36866;&#24212;&#29992;&#25143;&#20559;&#22909;&#30340;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#65288;LFM&#65289;&#25512;&#21160;&#20102;&#21508;&#31181;&#25913;&#36827;&#25512;&#33616;&#20934;&#30830;&#24615;&#30340;&#25512;&#33616;&#31639;&#27861;&#30340;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;LFM&#30340;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#27169;&#22411;&#32570;&#20047;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#26102;&#25512;&#33616;&#26041;&#38754;&#23384;&#22312;&#19968;&#20123;&#32570;&#28857;&#65292;&#22240;&#20026;&#24403;&#26377;&#26032;&#29992;&#25143;&#21040;&#36798;&#26102;&#38656;&#35201;&#37325;&#26032;&#36827;&#34892;&#30697;&#38453;&#20998;&#35299;&#21644;&#37325;&#26032;&#35757;&#32451;&#12290;&#38024;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#26412;&#25991;&#21019;&#26032;&#24615;&#22320;&#25552;&#20986;&#20102;&#19968;&#31181;Latent Factor Generator (LFG)&#32593;&#32476;&#65292;&#24182;&#23558;&#30005;&#24433;&#25512;&#33616;&#20316;&#20026;&#30740;&#31350;&#20027;&#39064;&#12290;LFG&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21160;&#24577;&#29983;&#25104;&#29992;&#25143;&#30340;&#28508;&#22312;&#22240;&#23376;&#65292;&#26080;&#38656;&#37325;&#26032;&#20998;&#35299;&#25110;&#37325;&#26032;&#35757;&#32451;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#23454;&#26102;&#25512;&#33616;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are essential information technologies today, and recommendation algorithms combined with deep learning have become a research hotspot in this field. The recommendation model known as LFM (Latent Factor Model), which captures latent features through matrix factorization and gradient descent to fit user preferences, has given rise to various recommendation algorithms that bring new improvements in recommendation accuracy. However, collaborative filtering recommendation models based on LFM lack flexibility and has shortcomings for real-time recommendations, as they need to redo the matrix factorization and retrain using gradient descent when new users arrive. In response to this, this paper innovatively proposes a Latent Factor Generator (LFG) network, and set the movie recommendation as research theme. The LFG dynamically generates user latent factors through deep neural networks without the need for re-factorization or retrain. Experimental results indicate that the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#20869;&#22312;&#22870;&#21169;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#20013;&#25163;&#24037;&#21046;&#20316;&#22870;&#21169;&#20989;&#25968;&#26080;&#27861;&#28385;&#36275;&#29992;&#25143;&#24847;&#22270;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23398;&#20064;&#19982;&#29992;&#25143;&#30340;&#20132;&#20114;&#26469;&#33719;&#24471;&#20869;&#22312;&#22870;&#21169;&#65292;&#36827;&#32780;&#20248;&#21270;CRS&#31574;&#30053;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#25104;&#21151;&#29575;&#24182;&#26368;&#23567;&#21270;&#23545;&#35805;&#36718;&#27425;&#65292;&#20197;&#36798;&#21040;&#26356;&#22909;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.20109</link><description>&lt;p&gt;
&#22810;&#30446;&#26631;&#20869;&#22312;&#22870;&#21169;&#23398;&#20064;&#29992;&#20110;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Multi-Objective Intrinsic Reward Learning for Conversational Recommender Systems. (arXiv:2310.20109v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#20869;&#22312;&#22870;&#21169;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#20013;&#25163;&#24037;&#21046;&#20316;&#22870;&#21169;&#20989;&#25968;&#26080;&#27861;&#28385;&#36275;&#29992;&#25143;&#24847;&#22270;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23398;&#20064;&#19982;&#29992;&#25143;&#30340;&#20132;&#20114;&#26469;&#33719;&#24471;&#20869;&#22312;&#22870;&#21169;&#65292;&#36827;&#32780;&#20248;&#21270;CRS&#31574;&#30053;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#25104;&#21151;&#29575;&#24182;&#26368;&#23567;&#21270;&#23545;&#35805;&#36718;&#27425;&#65292;&#20197;&#36798;&#21040;&#26356;&#22909;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65288;CRS&#65289;&#31215;&#26497;&#33719;&#21462;&#29992;&#25143;&#20559;&#22909;&#20197;&#29983;&#25104;&#36866;&#24212;&#24615;&#25512;&#33616;&#12290;&#20027;&#27969;&#30340;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;CRS&#35299;&#20915;&#26041;&#26696;&#20005;&#37325;&#20381;&#36182;&#25163;&#24037;&#21046;&#20316;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#36825;&#21487;&#33021;&#19982;CRS&#20219;&#21153;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#19981;&#19968;&#33268;&#12290;&#22240;&#27492;&#65292;&#35774;&#35745;&#20219;&#21153;&#29305;&#23450;&#30340;&#22870;&#21169;&#23545;&#20110;&#20419;&#36827;CRS&#31574;&#30053;&#23398;&#20064;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#22312;&#25991;&#29486;&#20013;&#23578;&#26410;&#24471;&#21040;&#24191;&#27867;&#25506;&#35752;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#21363;&#36890;&#36807;&#19982;&#29992;&#25143;&#30340;&#20114;&#21160;&#23398;&#20064;&#20869;&#22312;&#22870;&#21169;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#20869;&#22312;&#22870;&#21169;&#23398;&#20064;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#22810;&#30446;&#26631;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#12290;&#20869;&#23618;&#20248;&#21270;CRS&#31574;&#30053;&#65292;&#36890;&#36807;&#23398;&#20064;&#21040;&#30340;&#20869;&#22312;&#22870;&#21169;&#36827;&#34892;&#22686;&#24378;&#65292;&#32780;&#22806;&#23618;&#39537;&#21160;&#20869;&#22312;&#22870;&#21169;&#20248;&#21270;&#20004;&#20010;CRS&#29305;&#23450;&#30446;&#26631;&#65306;&#26368;&#22823;&#21270;&#25104;&#21151;&#29575;&#21644;&#26368;&#23567;&#21270;&#23545;&#35805;&#20013;&#36798;&#21040;&#25104;&#21151;&#25512;&#33616;&#25152;&#38656;&#30340;&#36718;&#27425;&#25968;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational Recommender Systems (CRS) actively elicit user preferences to generate adaptive recommendations. Mainstream reinforcement learning-based CRS solutions heavily rely on handcrafted reward functions, which may not be aligned with user intent in CRS tasks. Therefore, the design of task-specific rewards is critical to facilitate CRS policy learning, which remains largely under-explored in the literature. In this work, we propose a novel approach to address this challenge by learning intrinsic rewards from interactions with users. Specifically, we formulate intrinsic reward learning as a multi-objective bi-level optimization problem. The inner level optimizes the CRS policy augmented by the learned intrinsic rewards, while the outer level drives the intrinsic rewards to optimize two CRS-specific objectives: maximizing the success rate and minimizing the number of turns to reach a successful recommendation in conversations. To evaluate the effectiveness of our approach, we cond
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;</title><link>http://arxiv.org/abs/2310.20091</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#23494;&#24230;&#29992;&#25143;&#34920;&#31034;&#26041;&#27861;&#29992;&#20110;&#22810;&#20852;&#36259;&#20010;&#24615;&#21270;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval. (arXiv:2310.20091v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35774;&#35745;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#20934;&#30830;&#24314;&#27169;&#29992;&#25143;&#30340;&#21508;&#31181;&#22810;&#26679;&#21270;&#21644;&#21160;&#24577;&#30340;&#20852;&#36259;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#29992;&#25143;&#24314;&#27169;&#26041;&#27861;&#65292;&#22914;&#21333;&#28857;&#21644;&#22810;&#28857;&#34920;&#31034;&#65292;&#23384;&#22312;&#20934;&#30830;&#24615;&#12289;&#22810;&#26679;&#24615;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#36866;&#24212;&#24615;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#19981;&#36275;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#8212;&#8212;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;GPR4DUR&#21033;&#29992;DURs&#26469;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#65292;&#21516;&#26102;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;GPR4DUR&#30340;&#36866;&#24212;&#24615;&#21644;&#25928;&#29575;&#65292;&#32780;&#20351;&#29992;&#27169;&#25311;&#29992;&#25143;&#30340;&#22312;&#32447;&#23454;&#39564;&#21017;&#35777;&#26126;&#20102;&#23427;&#36890;&#36807;&#26377;&#25928;&#21033;&#29992;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#33021;&#22815;&#35299;&#20915;&#25506;&#32034;-&#24320;&#21457;&#30340;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, computational cost, and adaptability. To overcome these deficiencies, we introduce density-based user representations (DURs), a novel model that leverages Gaussian process regression for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty.
&lt;/p&gt;</description></item><item><title>&#20010;&#24615;&#21270;&#26159;NLP&#31995;&#32479;&#20013;&#29992;&#25143;&#20307;&#39564;&#30340;&#20851;&#38190;&#65292;&#26412;&#25991;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#24635;&#32467;&#21644;&#26816;&#32034;&#25972;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20219;&#21153;&#24863;&#30693;&#30340;&#24635;&#32467;&#22686;&#24378;&#20010;&#24615;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.20081</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#24635;&#32467;&#21644;&#26816;&#32034;&#25972;&#21512;&#65292;&#22686;&#24378;&#20010;&#24615;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models. (arXiv:2310.20081v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20081
&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#26159;NLP&#31995;&#32479;&#20013;&#29992;&#25143;&#20307;&#39564;&#30340;&#20851;&#38190;&#65292;&#26412;&#25991;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#24635;&#32467;&#21644;&#26816;&#32034;&#25972;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20219;&#21153;&#24863;&#30693;&#30340;&#24635;&#32467;&#22686;&#24378;&#20010;&#24615;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;(NLP)&#31995;&#32479;&#20013;&#29992;&#25143;&#20307;&#39564;&#30340;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#26469;&#26356;&#22909;&#22320;&#20010;&#24615;&#21270;&#29992;&#25143;&#20307;&#39564;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#20010;&#24615;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#19968;&#20010;&#30452;&#25509;&#30340;&#26041;&#27861;&#26159;&#23558;&#36807;&#21435;&#30340;&#29992;&#25143;&#25968;&#25454;&#24182;&#20837;&#35821;&#35328;&#27169;&#22411;&#30340;&#25552;&#31034;&#20013;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#20250;&#23548;&#33268;&#36755;&#20837;&#36807;&#38271;&#65292;&#36229;&#20986;&#36755;&#20837;&#38271;&#24230;&#38480;&#21046;&#65292;&#24182;&#19988;&#24341;&#36215;&#24310;&#36831;&#21644;&#25104;&#26412;&#38382;&#39064;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#36873;&#25321;&#24615;&#22320;&#25552;&#21462;&#30456;&#20851;&#30340;&#29992;&#25143;&#25968;&#25454;&#65288;&#21363;&#36873;&#25321;&#24615;&#26816;&#32034;&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#20197;&#26500;&#24314;&#19979;&#28216;&#20219;&#21153;&#30340;&#25552;&#31034;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#26816;&#32034;&#30340;&#26041;&#27861;&#21463;&#38480;&#20110;&#28508;&#22312;&#30340;&#20449;&#24687;&#20002;&#22833;&#12289;&#32570;&#20047;&#26356;&#28145;&#20837;&#30340;&#29992;&#25143;&#29702;&#35299;&#21644;&#20919;&#21551;&#21160;&#25361;&#25112;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24635;&#32467;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#26816;&#32034;&#22686;&#24378;&#20010;&#24615;&#21270;&#19982;&#20219;&#21153;&#24863;&#30693;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalization, the ability to tailor a system to individual users, is an essential factor in user experience with natural language processing (NLP) systems. With the emergence of Large Language Models (LLMs), a key question is how to leverage these models to better personalize user experiences. To personalize a language model's output, a straightforward approach is to incorporate past user data into the language model prompt, but this approach can result in lengthy inputs exceeding limitations on input length and incurring latency and cost issues. Existing approaches tackle such challenges by selectively extracting relevant user data (i.e. selective retrieval) to construct a prompt for downstream tasks. However, retrieval-based methods are limited by potential information loss, lack of more profound user understanding, and cold-start challenges. To overcome these limitations, we propose a novel summary-augmented approach by extending retrieval-augmented personalization with task-awar
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#29702;&#35299;&#28508;&#22312;&#22240;&#32032;&#25512;&#33616;&#31639;&#27861;&#20013;&#30340;&#25935;&#24863;&#23646;&#24615;&#20851;&#32852;&#20559;&#35265;&#12290;&#36825;&#20010;&#26694;&#26550;&#20801;&#35768;&#20174;&#19994;&#20154;&#21592;&#25506;&#32034;&#25512;&#33616;&#31995;&#32479;&#22914;&#20309;&#24341;&#20837;&#25110;&#25918;&#22823;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#34920;&#36798;&#20260;&#23475;&#65292;&#24182;&#20026;&#20182;&#20204;&#25552;&#20379;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.20061</link><description>&lt;p&gt;
&#29702;&#35299;&#28508;&#22312;&#22240;&#32032;&#25512;&#33616;&#31639;&#27861;&#20013;&#25935;&#24863;&#23646;&#24615;&#20851;&#32852;&#20559;&#35265;&#30340;&#35780;&#20272;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Evaluation Framework for Understanding Sensitive Attribute Association Bias in Latent Factor Recommendation Algorithms. (arXiv:2310.20061v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20061
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#29702;&#35299;&#28508;&#22312;&#22240;&#32032;&#25512;&#33616;&#31639;&#27861;&#20013;&#30340;&#25935;&#24863;&#23646;&#24615;&#20851;&#32852;&#20559;&#35265;&#12290;&#36825;&#20010;&#26694;&#26550;&#20801;&#35768;&#20174;&#19994;&#20154;&#21592;&#25506;&#32034;&#25512;&#33616;&#31995;&#32479;&#22914;&#20309;&#24341;&#20837;&#25110;&#25918;&#22823;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#34920;&#36798;&#20260;&#23475;&#65292;&#24182;&#20026;&#20182;&#20204;&#25552;&#20379;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#28508;&#22312;&#22240;&#32032;&#25512;&#33616;&#31639;&#27861;&#20013;&#30340;&#34920;&#31034;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#24341;&#20837;&#20102;&#23646;&#24615;&#20851;&#32852;&#20559;&#35265;&#30340;&#27010;&#24565;&#65292;&#35753;&#20174;&#19994;&#20154;&#21592;&#21487;&#20197;&#25506;&#32034;&#25512;&#33616;&#31995;&#32479;&#22914;&#20309;&#24341;&#20837;&#25110;&#25918;&#22823;&#21033;&#30410;&#30456;&#20851;&#32773;&#34920;&#36798;&#19978;&#30340;&#20260;&#23475;&#12290;&#24403;&#25935;&#24863;&#23646;&#24615;&#22312;&#35757;&#32451;&#30340;&#25512;&#33616;&#28508;&#22312;&#31354;&#38388;&#20013;&#34987;&#35821;&#20041;&#25429;&#25417;&#25110;&#32416;&#32544;&#26102;&#65292;&#23601;&#20250;&#20986;&#29616;&#23646;&#24615;&#20851;&#32852;&#20559;&#35265;&#65288;AAB&#65289;&#12290;&#36825;&#31181;&#20559;&#35265;&#21487;&#33021;&#23548;&#33268;&#25512;&#33616;&#32773;&#24378;&#21270;&#26377;&#23475;&#30340;&#21051;&#26495;&#21360;&#35937;&#65292;&#20174;&#32780;&#21487;&#33021;&#23545;&#31995;&#32479;&#30340;&#20351;&#29992;&#32773;&#21644;&#20379;&#24212;&#32773;&#21033;&#30410;&#30456;&#20851;&#32773;&#36896;&#25104;&#36827;&#19968;&#27493;&#30340;&#34920;&#36798;&#20260;&#23475;&#12290;&#28508;&#22312;&#22240;&#32032;&#25512;&#33616;&#27169;&#22411;&#30001;&#20110;&#33021;&#22815;&#23558;&#26174;&#24335;&#21644;&#38544;&#24335;&#23646;&#24615;&#32416;&#32544;&#22312;&#35757;&#32451;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#65292;&#22240;&#27492;&#23481;&#26131;&#36973;&#21463;AAB&#30340;&#24433;&#21709;&#12290;&#30001;&#20110;&#22312;&#28151;&#21512;&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#23454;&#20307;&#21521;&#37327;&#20316;&#20026;&#23646;&#24615;&#22312;&#19979;&#28216;&#32452;&#20214;&#20013;&#30340;&#20351;&#29992;&#36234;&#26469;&#36234;&#24120;&#35265;&#65292;&#22240;&#27492;&#29702;&#35299;&#36825;&#31181;&#29616;&#35937;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#20026;&#20174;&#19994;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21487;&#20197;&#24110;&#21161;&#20182;&#20204;&#35780;&#20272;&#21644;&#35299;&#20915;AAB&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel evaluation framework for representation bias in latent factor recommendation (LFR) algorithms. Our framework introduces the concept of attribute association bias in recommendations allowing practitioners to explore how recommendation systems can introduce or amplify stakeholder representation harm. Attribute association bias (AAB) occurs when sensitive attributes become semantically captured or entangled in the trained recommendation latent space. This bias can result in the recommender reinforcing harmful stereotypes, which may result in downstream representation harms to system consumer and provider stakeholders. LFR models are at risk of experiencing AAB due to their ability to entangle explicit and implicit attributes into the trained latent space. Understanding this phenomenon is essential due to the increasingly common use of entity vectors as attributes in downstream components in hybrid industry recommendation systems. We provide practitioners with a framewor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Split-NER&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#23558;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#38382;&#39064;&#20998;&#25104;&#25552;&#21462;&#23454;&#20307;&#25552;&#21450;&#36328;&#24230;&#21644;&#36328;&#24230;&#20998;&#31867;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#28982;&#21518;&#21033;&#29992;&#38382;&#31572;&#27169;&#22411;&#35299;&#20915;&#36825;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#21644;&#20934;&#30830;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2310.19942</link><description>&lt;p&gt;
Split-NER: &#36890;&#36807;&#20004;&#20010;&#22522;&#20110;&#38382;&#31572;&#30340;&#20998;&#31867;&#35299;&#20915;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Split-NER: Named Entity Recognition via Two Question-Answering-based Classifications. (arXiv:2310.19942v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Split-NER&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#23558;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#38382;&#39064;&#20998;&#25104;&#25552;&#21462;&#23454;&#20307;&#25552;&#21450;&#36328;&#24230;&#21644;&#36328;&#24230;&#20998;&#31867;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#28982;&#21518;&#21033;&#29992;&#38382;&#31572;&#27169;&#22411;&#35299;&#20915;&#36825;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#21644;&#20934;&#30830;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#38382;&#39064;&#20998;&#25104;&#20004;&#20010;&#36923;&#36753;&#23376;&#20219;&#21153;&#65306;&#65288;1&#65289;&#25552;&#21462;&#23454;&#20307;&#25552;&#21450;&#36328;&#24230;&#65292;&#26080;&#35770;&#23454;&#20307;&#31867;&#22411;&#22914;&#20309;&#65307;&#65288;2&#65289;&#23558;&#36328;&#24230;&#20998;&#31867;&#20026;&#23454;&#20307;&#31867;&#22411;&#12290;&#36827;&#19968;&#27493;&#65292;&#25105;&#20204;&#23558;&#36825;&#20004;&#20010;&#23376;&#20219;&#21153;&#37117;&#24418;&#24335;&#21270;&#20026;&#38382;&#31572;&#38382;&#39064;&#65292;&#24182;&#20135;&#29983;&#20004;&#20010;&#21487;&#20197;&#20998;&#21035;&#20026;&#27599;&#20010;&#23376;&#20219;&#21153;&#36827;&#34892;&#20248;&#21270;&#30340;&#26356;&#36731;&#30340;&#27169;&#22411;&#12290;&#22312;&#22235;&#20010;&#36328;&#39046;&#22495;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#20010;&#20004;&#27493;&#27861;&#26082;&#26377;&#25928;&#21448;&#33410;&#30465;&#26102;&#38388;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;SplitNER&#22312;OntoNotes5.0&#12289;WNUT17&#21644;&#19968;&#20010;&#32593;&#32476;&#23433;&#20840;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#36229;&#36807;&#20102;&#22522;&#32447;&#65292;&#24182;&#22312;BioNLP13CG&#19978;&#34920;&#29616;&#30456;&#24403;&#12290;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#65292;&#19982;QA&#22522;&#32447;&#23545;&#29031;&#30456;&#27604;&#65292;&#23427;&#22312;&#35757;&#32451;&#26102;&#20943;&#23569;&#20102;&#26174;&#33879;&#30340;&#26102;&#38388;&#12290;&#25105;&#20204;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#28304;&#20110;&#20998;&#21035;&#23545;&#36328;&#24230;&#26816;&#27979;&#21644;&#20998;&#31867;&#36827;&#34892;BERT&#27169;&#22411;&#30340;&#24494;&#35843;&#12290;&#28304;&#20195;&#30721;&#21487;&#22312;https://github.com/c3sr/split-ner&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we address the NER problem by splitting it into two logical sub-tasks: (1) Span Detection which simply extracts entity mention spans irrespective of entity type; (2) Span Classification which classifies the spans into their entity types. Further, we formulate both sub-tasks as question-answering (QA) problems and produce two leaner models which can be optimized separately for each sub-task. Experiments with four cross-domain datasets demonstrate that this two-step approach is both effective and time efficient. Our system, SplitNER outperforms baselines on OntoNotes5.0, WNUT17 and a cybersecurity dataset and gives on-par performance on BioNLP13CG. In all cases, it achieves a significant reduction in training time compared to its QA baseline counterpart. The effectiveness of our system stems from fine-tuning the BERT model twice, separately for span detection and classification. The source code can be found at https://github.com/c3sr/split-ner.
&lt;/p&gt;</description></item><item><title>BTRec&#26159;&#19968;&#31181;&#22522;&#20110;BERT&#30340;&#36712;&#36857;&#25512;&#33616;&#31639;&#27861;&#65292;&#23427;&#21033;&#29992;&#29992;&#25143;&#30340;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#21644;&#36807;&#21435;&#30340;POI&#35775;&#38382;&#20449;&#24687;&#65292;&#36890;&#36807;&#20462;&#25913;&#21518;&#30340;BERT&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;POI&#34892;&#31243;&#39044;&#27979;&#65292;&#20174;&#32780;&#20026;&#26053;&#28216;&#32773;&#25552;&#20379;&#26377;&#38024;&#23545;&#24615;&#30340;&#25512;&#33616;&#34892;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.19886</link><description>&lt;p&gt;
BTRec: &#22522;&#20110;BERT&#30340;&#20010;&#24615;&#21270;&#26053;&#28216;&#36712;&#36857;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
BTRec: BERT-Based Trajectory Recommendation for Personalized Tours. (arXiv:2310.19886v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19886
&lt;/p&gt;
&lt;p&gt;
BTRec&#26159;&#19968;&#31181;&#22522;&#20110;BERT&#30340;&#36712;&#36857;&#25512;&#33616;&#31639;&#27861;&#65292;&#23427;&#21033;&#29992;&#29992;&#25143;&#30340;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#21644;&#36807;&#21435;&#30340;POI&#35775;&#38382;&#20449;&#24687;&#65292;&#36890;&#36807;&#20462;&#25913;&#21518;&#30340;BERT&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;POI&#34892;&#31243;&#39044;&#27979;&#65292;&#20174;&#32780;&#20026;&#26053;&#28216;&#32773;&#25552;&#20379;&#26377;&#38024;&#23545;&#24615;&#30340;&#25512;&#33616;&#34892;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#26053;&#28216;&#32773;&#26469;&#35828;&#65292;&#25317;&#26377;&#19968;&#20010;&#31934;&#24515;&#35268;&#21010;&#30340;&#34892;&#31243;&#21644;&#30456;&#20851;&#25512;&#33616;&#26159;&#24230;&#36807;&#24841;&#24555;&#20551;&#26399;&#30340;&#20851;&#38190;&#65292;&#23588;&#20854;&#26159;&#24403;&#20182;&#20204;&#35775;&#38382;&#38476;&#29983;&#22478;&#24066;&#26102;&#12290;&#35768;&#22810;&#26053;&#28216;&#25512;&#33616;&#24037;&#20855;&#21482;&#32771;&#34385;&#20102;&#26377;&#38480;&#30340;&#22240;&#32032;&#65292;&#22914;&#28909;&#38376;&#26223;&#28857;&#21644;&#36335;&#24452;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#25552;&#20379;&#30340;&#35299;&#20915;&#26041;&#26696;&#21487;&#33021;&#19981;&#24635;&#26159;&#19982;&#31995;&#32479;&#30340;&#20010;&#20307;&#29992;&#25143;&#20445;&#25345;&#19968;&#33268;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BTREC&#65288;&#22522;&#20110;BERT&#30340;&#36712;&#36857;&#25512;&#33616;&#65289;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#23427;&#20174;POIBERT&#23884;&#20837;&#31639;&#27861;&#25193;&#23637;&#21040;&#20351;&#29992;BERT&#26694;&#26550;&#25512;&#33616;&#20010;&#24615;&#21270;POI&#34892;&#31243;&#12290;&#25105;&#20204;&#30340;BTREC&#31639;&#27861;&#23558;&#29992;&#25143;&#30340;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#21644;&#36807;&#21435;&#30340;POI&#35775;&#38382;&#20449;&#24687;&#21512;&#24182;&#21040;&#20462;&#25913;&#21518;&#30340;BERT&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20197;&#32473;&#20986;&#19968;&#23545;&#20986;&#21457;&#22320;&#21644;&#30446;&#30340;&#22320;POI&#30340;&#20010;&#24615;&#21270;POI&#34892;&#31243;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#25512;&#33616;&#31995;&#32479;&#21487;&#20197;&#21019;&#24314;&#19968;&#20010;&#26368;&#22823;&#21270;&#35775;&#38382;POI&#30340;&#26053;&#34892;&#34892;&#31243;&#65292;&#21516;&#26102;&#32771;&#34385;&#29992;&#25143;&#30340;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
An essential task for tourists having a pleasant holiday is to have a well-planned itinerary with relevant recommendations, especially when visiting unfamiliar cities. Many tour recommendation tools only take into account a limited number of factors, such as popular Points of Interest (POIs) and routing constraints. Consequently, the solutions they provide may not always align with the individual users of the system. We propose an iterative algorithm in this paper, namely: BTREC (BERT-based Trajectory Recommendation), that extends from the POIBERT embedding algorithm to recommend personalized itineraries on POIs using the BERT framework. Our BTREC algorithm incorporates users' demographic information alongside past POI visits into a modified BERT language model to recommend a personalized POI itinerary prediction given a pair of source and destination POIs. Our recommendation system can create a travel itinerary that maximizes POIs visited, while also taking into account user preferenc
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;COVID-19&#30123;&#33495;&#25968;&#25454;&#38598;&#30340;&#33258;&#21160;&#21270;&#34394;&#20551;&#20449;&#24687;&#39539;&#26021;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#20449;&#24687;&#21644;&#32463;&#36807;&#31574;&#21010;&#30340;&#20107;&#23454;&#26680;&#26597;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#22823;&#35268;&#27169;&#33258;&#21160;&#39539;&#26021;&#34394;&#20551;&#20449;&#24687;&#12290;&#36825;&#20026;&#23545;&#25239;&#34394;&#20551;&#20449;&#24687;&#25552;&#20379;&#20102;&#19968;&#31181;&#25104;&#26412;&#25928;&#30410;&#39640;&#12289;&#21487;&#25193;&#23637;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.19834</link><description>&lt;p&gt;
AMIR&#65306;&#22522;&#20110;COVID-19&#30123;&#33495;&#25968;&#25454;&#38598;&#30340;&#33258;&#21160;&#21270;&#34394;&#20551;&#20449;&#24687;&#39539;&#26021;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
AMIR: Automated MisInformation Rebuttal -- A COVID-19 Vaccination Datasets based Recommendation System. (arXiv:2310.19834v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19834
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;COVID-19&#30123;&#33495;&#25968;&#25454;&#38598;&#30340;&#33258;&#21160;&#21270;&#34394;&#20551;&#20449;&#24687;&#39539;&#26021;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#20449;&#24687;&#21644;&#32463;&#36807;&#31574;&#21010;&#30340;&#20107;&#23454;&#26680;&#26597;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#22823;&#35268;&#27169;&#33258;&#21160;&#39539;&#26021;&#34394;&#20551;&#20449;&#24687;&#12290;&#36825;&#20026;&#23545;&#25239;&#34394;&#20551;&#20449;&#24687;&#25552;&#20379;&#20102;&#19968;&#31181;&#25104;&#26412;&#25928;&#30410;&#39640;&#12289;&#21487;&#25193;&#23637;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34394;&#20551;&#20449;&#24687;&#36817;&#24180;&#26469;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#31038;&#20250;&#23041;&#32961;&#65292;&#29305;&#21035;&#26159;&#22312;COVID-19&#22823;&#27969;&#34892;&#30340;&#32972;&#26223;&#19979;&#65292;&#23427;&#21152;&#21095;&#20102;&#30123;&#33495;&#29369;&#35947;&#19981;&#20915;&#12290;&#23545;&#25239;&#34394;&#20551;&#20449;&#24687;&#30340;&#25104;&#26412;&#25928;&#30410;&#39640;&#12289;&#21487;&#25193;&#23637;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#24403;&#21153;&#20043;&#24613;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#22914;&#20309;&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#33719;&#21462;&#30340;&#29616;&#26377;&#20449;&#24687;&#65292;&#24182;&#19982;&#26356;&#22810;&#32463;&#36807;&#31574;&#21010;&#30340;&#20107;&#23454;&#26680;&#26597;&#25968;&#25454;&#24211;&#30456;&#32467;&#21512;&#65292;&#20197;&#20419;&#36827;&#22823;&#35268;&#27169;&#33258;&#21160;&#39539;&#26021;&#34394;&#20551;&#20449;&#24687;&#12290;&#34429;&#28982;&#36825;&#37324;&#30340;&#24819;&#27861;&#21487;&#20197;&#25512;&#24191;&#24182;&#37325;&#26032;&#24212;&#29992;&#20110;&#20351;&#29992;&#22810;&#31181;&#20449;&#24687;&#26469;&#28304;&#21644;&#28385;&#36275;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#20809;&#35889;&#30340;&#36739;&#22823;&#33539;&#22260;&#30340;&#34394;&#20551;&#20449;&#24687;&#32531;&#35299;&#65292;&#20294;&#26412;&#24037;&#20316;&#20316;&#20026;&#19968;&#20010;&#27010;&#24565;&#39564;&#35777;&#21463;&#38480;&#20110;&#20854;&#33539;&#22260;&#65292;&#20165;&#38480;&#20110;&#23545;&#25512;&#25991;&#30340;&#21453;&#39539;&#65292;&#19988;&#20165;&#38480;&#20110;COVID-19&#30456;&#20851;&#30340;&#34394;&#20551;&#20449;&#24687;&#12290;&#23427;&#21033;&#29992;&#20102;&#20004;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#65292;&#21363;FaCov&#65288;&#32463;&#20107;&#23454;&#26680;&#26597;&#30340;&#25991;&#31456;&#65289;&#21644;misleading&#65288;&#31038;&#20132;&#23186;&#20307;&#25512;&#25991;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Misinformation has emerged as a major societal threat in recent years in general; specifically in the context of the COVID-19 pandemic, it has wrecked havoc, for instance, by fuelling vaccine hesitancy. Cost-effective, scalable solutions for combating misinformation are the need of the hour. This work explored how existing information obtained from social media and augmented with more curated fact checked data repositories can be harnessed to facilitate automated rebuttal of misinformation at scale. While the ideas herein can be generalized and reapplied in the broader context of misinformation mitigation using a multitude of information sources and catering to the spectrum of social media platforms, this work serves as a proof of concept, and as such, it is confined in its scope to only rebuttal of tweets, and in the specific context of misinformation regarding COVID-19. It leverages two publicly available datasets, viz. FaCov (fact-checked articles) and misleading (social media Twitt
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ICSRec&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24314;&#27169;&#29992;&#25143;&#30340;&#28508;&#22312;&#24847;&#22270;&#65292;&#20197;&#25552;&#39640;&#39034;&#24207;&#25512;&#33616;&#30340;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21644;&#20132;&#21449;&#23376;&#24207;&#21015;&#26469;&#20934;&#30830;&#25429;&#25417;&#29992;&#25143;&#30340;&#24847;&#22270;&#12290;</title><link>http://arxiv.org/abs/2310.14318</link><description>&lt;p&gt;
&#29992;&#20132;&#21449;&#23376;&#24207;&#21015;&#36827;&#34892;&#24847;&#22270;&#23545;&#27604;&#23398;&#20064;&#30340;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Intent Contrastive Learning with Cross Subsequences for Sequential Recommendation. (arXiv:2310.14318v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14318
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ICSRec&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24314;&#27169;&#29992;&#25143;&#30340;&#28508;&#22312;&#24847;&#22270;&#65292;&#20197;&#25552;&#39640;&#39034;&#24207;&#25512;&#33616;&#30340;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21644;&#20132;&#21449;&#23376;&#24207;&#21015;&#26469;&#20934;&#30830;&#25429;&#25417;&#29992;&#25143;&#30340;&#24847;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#30340;&#36141;&#20080;&#34892;&#20026;&#20027;&#35201;&#21463;&#21040;&#20182;&#20204;&#30340;&#24847;&#22270;&#24433;&#21709;&#65288;&#20363;&#22914;&#65292;&#36141;&#20080;&#35013;&#39280;&#29992;&#30340;&#34915;&#26381;&#65292;&#36141;&#20080;&#30011;&#30011;&#29992;&#30340;&#30011;&#31508;&#31561;&#65289;&#12290;&#24314;&#27169;&#29992;&#25143;&#30340;&#28508;&#22312;&#24847;&#22270;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#25512;&#33616;&#30340;&#24615;&#33021;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#32771;&#34385;&#36741;&#21161;&#20449;&#24687;&#20013;&#30340;&#39044;&#23450;&#20041;&#26631;&#31614;&#25110;&#24341;&#20837;&#38543;&#26426;&#25968;&#25454;&#22686;&#24378;&#26469;&#24314;&#27169;&#29992;&#25143;&#30340;&#24847;&#22270;&#12290;&#28982;&#32780;&#65292;&#36741;&#21161;&#20449;&#24687;&#26159;&#31232;&#30095;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;&#25512;&#33616;&#31995;&#32479;&#24182;&#19981;&#24635;&#26159;&#21487;&#29992;&#30340;&#65292;&#24341;&#20837;&#38543;&#26426;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#24341;&#20837;&#22122;&#22768;&#65292;&#20174;&#32780;&#25913;&#21464;&#24207;&#21015;&#20013;&#38544;&#34255;&#30340;&#24847;&#22270;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;&#29992;&#25143;&#30340;&#24847;&#22270;&#36827;&#34892;&#39034;&#24207;&#25512;&#33616;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#32463;&#24120;&#21464;&#21270;&#19988;&#19981;&#21487;&#35266;&#23519;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#24847;&#22270;&#23545;&#27604;&#23398;&#20064;&#19982;&#20132;&#21449;&#23376;&#24207;&#21015;&#65288;ICSRec&#65289;&#65292;&#29992;&#20110;&#24314;&#27169;&#29992;&#25143;&#30340;&#28508;&#22312;&#24847;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The user purchase behaviors are mainly influenced by their intentions (e.g., buying clothes for decoration, buying brushes for painting, etc.). Modeling a user's latent intention can significantly improve the performance of recommendations. Previous works model users' intentions by considering the predefined label in auxiliary information or introducing stochastic data augmentation to learn purposes in the latent space. However, the auxiliary information is sparse and not always available for recommender systems, and introducing stochastic data augmentation may introduce noise and thus change the intentions hidden in the sequence. Therefore, leveraging user intentions for sequential recommendation (SR) can be challenging because they are frequently varied and unobserved. In this paper, Intent contrastive learning with Cross Subsequences for sequential Recommendation (ICSRec) is proposed to model users' latent intentions. Specifically, ICSRec first segments a user's sequential behaviors
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#20845;&#20010;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#30340;&#30740;&#31350;&#65292;&#21457;&#29616;&#20102;&#26597;&#35810;&#30340;&#20803;&#25968;&#25454;&#12289;&#38382;&#39064;&#26500;&#25104;&#26041;&#24335;&#21644;&#29992;&#25143;&#20114;&#21160;&#27700;&#24179;&#19982;&#31532;&#19968;&#20010;&#22238;&#31572;&#26102;&#38388;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#24182;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26597;&#35810;&#26159;&#21542;&#33021;&#22815;&#36805;&#36895;&#33719;&#24471;&#22238;&#31572;&#12290;</title><link>http://arxiv.org/abs/2309.05961</link><description>&lt;p&gt;
&#35780;&#20272;&#28526;&#36215;&#28526;&#33853;&#65306;&#23545;&#19981;&#21516;&#24179;&#21488;&#38388;&#38382;&#31572;&#36235;&#21183;&#30340;&#28145;&#20837;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms. (arXiv:2309.05961v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#20845;&#20010;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#30340;&#30740;&#31350;&#65292;&#21457;&#29616;&#20102;&#26597;&#35810;&#30340;&#20803;&#25968;&#25454;&#12289;&#38382;&#39064;&#26500;&#25104;&#26041;&#24335;&#21644;&#29992;&#25143;&#20114;&#21160;&#27700;&#24179;&#19982;&#31532;&#19968;&#20010;&#22238;&#31572;&#26102;&#38388;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#24182;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26597;&#35810;&#26159;&#21542;&#33021;&#22815;&#36805;&#36895;&#33719;&#24471;&#22238;&#31572;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#22240;&#20854;&#24555;&#36895;&#22238;&#31572;&#29992;&#25143;&#26597;&#35810;&#30340;&#33021;&#21147;&#32780;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#36825;&#20123;&#22238;&#31572;&#36895;&#24230;&#30340;&#24555;&#24930;&#21462;&#20915;&#20110;&#26597;&#35810;&#29305;&#23450;&#21644;&#29992;&#25143;&#30456;&#20851;&#30340;&#22240;&#32032;&#30340;&#32508;&#21512;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#20845;&#20010;&#39640;&#24230;&#27969;&#34892;&#30340;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#65292;&#20998;&#26512;&#20102;&#36825;&#20123;&#22240;&#32032;&#22312;&#20854;&#20013;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#25581;&#31034;&#20102;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#22238;&#31572;&#25152;&#33457;&#36153;&#30340;&#26102;&#38388;&#19982;&#20803;&#25968;&#25454;&#12289;&#38382;&#39064;&#30340;&#26500;&#25104;&#26041;&#24335;&#21644;&#29992;&#25143;&#20043;&#38388;&#30340;&#20114;&#21160;&#27700;&#24179;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20351;&#29992;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20998;&#26512;&#36825;&#20123;&#20803;&#25968;&#25454;&#21644;&#29992;&#25143;&#20114;&#21160;&#27169;&#24335;&#65292;&#25105;&#20204;&#35797;&#22270;&#39044;&#27979;&#21738;&#20123;&#26597;&#35810;&#23558;&#36805;&#36895;&#33719;&#24471;&#21021;&#22987;&#22238;&#31572;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community Question Answering (CQA) platforms steadily gain popularity as they provide users with fast responses to their queries. The swiftness of these responses is contingent on a mixture of query-specific and user-related elements. This paper scrutinizes these contributing factors within the context of six highly popular CQA platforms, identified through their standout answering speed. Our investigation reveals a correlation between the time taken to yield the first response to a question and several variables: the metadata, the formulation of the questions, and the level of interaction among users. Additionally, by employing conventional machine learning models to analyze these metadata and patterns of user interaction, we endeavor to predict which queries will receive their initial responses promptly.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#25552;&#20379;&#36866;&#29992;&#20110;&#21019;&#19994;&#20225;&#19994;&#21644;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2306.17256</link><description>&lt;p&gt;
&#20197;&#25552;&#31034;&#20026;&#22522;&#30784;&#30340;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#25552;&#20379;&#36866;&#29992;&#20110;&#21019;&#19994;&#20225;&#19994;&#21644;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#26681;&#25454;&#29992;&#25143;&#36807;&#21435;&#30340;&#34892;&#20026;&#24110;&#21161;&#29992;&#25143;&#21457;&#29616;&#19982;&#20854;&#20852;&#36259;&#30456;&#31526;&#30340;&#20449;&#24687;&#26041;&#38754;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#24403;&#29992;&#25143;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#21382;&#21490;&#20132;&#20114;&#35760;&#24405;&#19981;&#21487;&#29992;&#26102;&#65292;&#24320;&#21457;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#36825;&#23601;&#26159;&#25152;&#35859;&#30340;&#31995;&#32479;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#12290;&#27492;&#38382;&#39064;&#22312;&#21019;&#19994;&#20225;&#19994;&#25110;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#20013;&#23588;&#20026;&#31361;&#20986;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#29992;&#25143;&#25110;&#29289;&#21697;&#30340;&#20919;&#21551;&#21160;&#22330;&#26223;&#65292;&#20854;&#20013;&#31995;&#32479;&#20173;&#28982;&#36890;&#36807;&#22312;&#21516;&#19968;&#39046;&#22495;&#20013;&#30340;&#21382;&#21490;&#29992;&#25143;&#21644;&#29289;&#21697;&#20132;&#20114;&#36827;&#34892;&#35757;&#32451;&#26469;&#20026;&#26032;&#29992;&#25143;&#25110;&#29289;&#21697;&#25552;&#20379;&#25512;&#33616;&#65292;&#32780;&#26080;&#27861;&#35299;&#20915;&#25105;&#20204;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#40511;&#27807;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#19988;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#20854;&#20013;&#21253;&#21547;&#29992;&#25143;&#36164;&#26009;&#21644;&#29289;&#21697;&#23646;&#24615;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems play a crucial role in helping users discover information that aligns with their interests based on their past behaviors. However, developing personalized recommendation systems becomes challenging when historical records of user-item interactions are unavailable, leading to what is known as the system cold-start recommendation problem. This issue is particularly prominent in start-up businesses or platforms with insufficient user engagement history. Previous studies focus on user or item cold-start scenarios, where systems could make recommendations for new users or items but are still trained with historical user-item interactions in the same domain, which cannot solve our problem. To bridge the gap, our research introduces an innovative and effective approach, capitalizing on the capabilities of pre-trained language models. We transform the recommendation process into sentiment analysis of natural languages containing information of user profiles and item attribu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;ALCE&#65292;&#26159;&#39318;&#20010;&#33258;&#21160;LLMs&#24341;&#25991;&#35780;&#20272;&#22522;&#20934;&#65292;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24102;&#24341;&#25991;&#30340;&#25991;&#26412;&#65292;&#25552;&#39640;&#20854;&#20107;&#23454;&#27491;&#30830;&#24615;&#21644;&#21487;&#39564;&#35777;&#24615;&#65307;&#25552;&#31034;LLMs&#29305;&#23450;&#30340;&#20851;&#38190;&#35789;&#25110;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24341;&#25991;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14627</link><description>&lt;p&gt;
&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24102;&#24341;&#25991;&#30340;&#25991;&#26412;
&lt;/p&gt;
&lt;p&gt;
Enabling Large Language Models to Generate Text with Citations. (arXiv:2305.14627v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;ALCE&#65292;&#26159;&#39318;&#20010;&#33258;&#21160;LLMs&#24341;&#25991;&#35780;&#20272;&#22522;&#20934;&#65292;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24102;&#24341;&#25991;&#30340;&#25991;&#26412;&#65292;&#25552;&#39640;&#20854;&#20107;&#23454;&#27491;&#30830;&#24615;&#21644;&#21487;&#39564;&#35777;&#24615;&#65307;&#25552;&#31034;LLMs&#29305;&#23450;&#30340;&#20851;&#38190;&#35789;&#25110;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24341;&#25991;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#25104;&#20026;&#24191;&#27867;&#20351;&#29992;&#30340;&#20449;&#24687;&#23547;&#25214;&#24037;&#20855;&#65292;&#20294;&#29983;&#25104;&#30340;&#36755;&#20986;&#23481;&#26131;&#20986;&#29616;&#24187;&#35273;&#12290;&#26412;&#25991;&#26088;&#22312;&#23454;&#29616;LLMs&#29983;&#25104;&#24102;&#24341;&#25991;&#30340;&#25991;&#26412;&#65292;&#25552;&#39640;&#20854;&#20107;&#23454;&#27491;&#30830;&#24615;&#21644;&#21487;&#39564;&#35777;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ALCE&#65292;&#36825;&#26159;&#39318;&#20010;&#33258;&#21160;LLMs&#24341;&#25991;&#35780;&#20272;&#22522;&#20934;&#12290;ALCE&#25910;&#38598;&#20102;&#21508;&#31181;&#38382;&#39064;&#21644;&#26816;&#32034;&#35821;&#26009;&#24211;&#65292;&#24182;&#35201;&#27714;&#24314;&#31435;&#31471;&#21040;&#31471;&#31995;&#32479;&#20197;&#26816;&#32034;&#25903;&#25345;&#35777;&#25454;&#24182;&#29983;&#25104;&#24102;&#26377;&#24341;&#25991;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#27839;&#30528;&#27969;&#30021;&#24615;&#12289;&#27491;&#30830;&#24615;&#21644;&#24341;&#25991;&#36136;&#37327;&#19977;&#20010;&#32500;&#24230;&#26500;&#24314;&#33258;&#21160;&#25351;&#26631;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#19982;&#20154;&#31867;&#21028;&#26029;&#30340;&#24378;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;LLMs&#21644;&#26032;&#30340;&#25552;&#31034;&#31574;&#30053;&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#24403;&#21069;&#31995;&#32479;&#20173;&#26377;&#30456;&#24403;&#22823;&#30340;&#25552;&#21319;&#31354;&#38388;--&#20363;&#22914;&#65292;&#25552;&#31034;LLMs&#29305;&#23450;&#30340;&#20851;&#38190;&#35789;&#25110;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24341;&#25991;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#26410;&#26469;&#30740;&#31350;&#21457;&#23637;&#33021;&#22815;&#29983;&#25104;&#21487;&#39564;&#35777;&#21644;&#21487;&#20449;&#36182;&#36755;&#20986;&#30340;LLMs&#25552;&#20379;&#20102;&#22362;&#23454;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have emerged as a widely-used tool for information seeking, but their generated outputs are prone to hallucination. In this work, we aim to enable LLMs to generate text with citations, improving their factual correctness and verifiability. Existing work mainly relies on commercial search engines and human evaluation, making it challenging to reproduce and compare with different modeling approaches. We propose ALCE, the first benchmark for Automatic LLMs' Citation Evaluation. ALCE collects a diverse set of questions and retrieval corpora and requires building end-to-end systems to retrieve supporting evidence and generate answers with citations. We build automatic metrics along three dimensions -- fluency, correctness, and citation quality -- and demonstrate their strong correlation with human judgements. Our experiments with state-of-the-art LLMs and novel prompting strategies show that current systems have considerable room for improvements -for example,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;GenExpan&#65292;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26694;&#26550;&#65292;&#21033;&#29992;&#21069;&#32512;&#26641;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.03531</link><description>&lt;p&gt;
&#20174;&#26816;&#32034;&#21040;&#29983;&#25104;&#65306;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
From Retrieval to Generation: Efficient and Effective Entity Set Expansion. (arXiv:2304.03531v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;GenExpan&#65292;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#26694;&#26550;&#65292;&#21033;&#29992;&#21069;&#32512;&#26641;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#38598;&#25193;&#23637;&#65288;ESE&#65289;&#26159;&#19968;&#39033;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#26088;&#22312;&#25193;&#23637;&#30001;&#23567;&#30340;&#31181;&#23376;&#23454;&#20307;&#38598;&#25551;&#36848;&#30340;&#30446;&#26631;&#35821;&#20041;&#31867;&#30340;&#23454;&#20307;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;ESE&#26041;&#27861;&#26159;&#22522;&#20110;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#38656;&#35201;&#25552;&#21462;&#23454;&#20307;&#30340;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#35745;&#31639;&#31181;&#23376;&#23454;&#20307;&#21644;&#20505;&#36873;&#23454;&#20307;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20004;&#20010;&#30446;&#30340;&#65292;&#23427;&#20204;&#24517;&#39035;&#36845;&#20195;&#22320;&#36941;&#21382;&#35821;&#26009;&#24211;&#21644;&#25968;&#25454;&#38598;&#20013;&#25552;&#20379;&#30340;&#23454;&#20307;&#35789;&#27719;&#65292;&#23548;&#33268;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#36739;&#24046;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#26816;&#32034;&#30340;ESE&#26041;&#27861;&#28040;&#32791;&#30340;&#26102;&#38388;&#19982;&#23454;&#20307;&#35789;&#27719;&#21644;&#35821;&#26009;&#24211;&#30340;&#22823;&#23567;&#25104;&#32447;&#24615;&#22686;&#38271;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#24335;ESE&#26694;&#26550;&#65292;Generative Entity Set Expansion (GenExpan)&#65292;&#23427;&#21033;&#29992;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#23436;&#25104;ESE&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#37319;&#29992;&#21069;&#32512;&#26641;&#26469;&#20445;&#35777;&#23454;&#20307;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#37319;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#31867;&#21517;&#26469;&#24341;&#23548;&#27169;&#22411;&#29983;&#25104;&#21516;&#19968;&#31867;&#23454;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entity Set Expansion (ESE) is a critical task aiming to expand entities of the target semantic class described by a small seed entity set. Most existing ESE methods are retrieval-based frameworks that need to extract the contextual features of entities and calculate the similarity between seed entities and candidate entities. To achieve the two purposes, they should iteratively traverse the corpus and the entity vocabulary provided in the datasets, resulting in poor efficiency and scalability. The experimental results indicate that the time consumed by the retrieval-based ESE methods increases linearly with entity vocabulary and corpus size. In this paper, we firstly propose a generative ESE framework, Generative Entity Set Expansion (GenExpan), which utilizes a generative pre-trained language model to accomplish ESE task. Specifically, a prefix tree is employed to guarantee the validity of entity generation, and automatically generated class names are adopted to guide the model to gen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25490;&#21517;&#38382;&#39064;&#30340;&#21015;&#34920;&#32423;&#21035;&#23545;&#40784;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21015;&#34920;&#30340;&#32467;&#26500;&#29305;&#24615;&#65292;&#22312;&#39046;&#22495;&#36866;&#24212;&#20013;&#23454;&#29616;&#20174;&#28304;&#39046;&#22495;&#21040;&#30446;&#26631;&#39046;&#22495;&#30340;&#30693;&#35782;&#36716;&#31227;&#12290;</title><link>http://arxiv.org/abs/2212.10764</link><description>&lt;p&gt;
&#23398;&#20064;&#29992;&#20110;&#25490;&#21517;&#30340;&#21015;&#34920;&#32423;&#21035;&#39046;&#22495;&#19981;&#21464;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning List-Level Domain-Invariant Representations for Ranking. (arXiv:2212.10764v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25490;&#21517;&#38382;&#39064;&#30340;&#21015;&#34920;&#32423;&#21035;&#23545;&#40784;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21015;&#34920;&#30340;&#32467;&#26500;&#29305;&#24615;&#65292;&#22312;&#39046;&#22495;&#36866;&#24212;&#20013;&#23454;&#29616;&#20174;&#28304;&#39046;&#22495;&#21040;&#30446;&#26631;&#39046;&#22495;&#30340;&#30693;&#35782;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#36866;&#24212;&#26088;&#22312;&#23558;&#22312;&#65288;&#25968;&#25454;&#20016;&#23500;&#65289;&#28304;&#39046;&#22495;&#23398;&#21040;&#30340;&#30693;&#35782;&#36716;&#31227;&#21040;&#65288;&#36164;&#28304;&#26377;&#38480;&#65289;&#30446;&#26631;&#39046;&#22495;&#65292;&#19968;&#31181;&#24120;&#29992;&#30340;&#26041;&#27861;&#26159;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#65292;&#23427;&#21305;&#37197;&#24182;&#23545;&#40784;&#29305;&#24449;&#31354;&#38388;&#19978;&#30340;&#25968;&#25454;&#20998;&#24067;&#12290;&#23613;&#31649;&#36825;&#31181;&#26041;&#27861;&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#21644;&#24212;&#29992;&#65292;&#20294;&#22312;&#25490;&#21517;&#38382;&#39064;&#19978;&#30340;&#24212;&#29992;&#21364;&#26159;&#38646;&#25955;&#30340;&#65292;&#24182;&#19988;&#29616;&#26377;&#30340;&#20960;&#31181;&#23454;&#29616;&#32570;&#20047;&#29702;&#35770;&#19978;&#30340;&#35777;&#26126;&#12290;&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#29992;&#20110;&#25490;&#21517;&#30340;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#12290;&#22312;&#23457;&#26597;&#20043;&#21069;&#30340;&#24037;&#20316;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#20182;&#20204;&#23454;&#26045;&#20102;&#25105;&#20204;&#31216;&#20043;&#20026;&#39033;&#30446;&#32423;&#21035;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#32858;&#21512;&#30340;&#25152;&#26377;&#21015;&#34920;&#20013;&#23545;&#36827;&#34892;&#25490;&#21517;&#30340;&#39033;&#30446;&#20998;&#24067;&#36827;&#34892;&#23545;&#40784;&#65292;&#20294;&#24573;&#30053;&#20102;&#21015;&#34920;&#30340;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#21015;&#34920;&#30340;&#32467;&#26500;&#24212;&#35813;&#34987;&#21033;&#29992;&#65292;&#22240;&#20026;&#23427;&#26159;&#25490;&#21517;&#38382;&#39064;&#30340;&#22266;&#26377;&#29305;&#24615;&#65292;&#20854;&#20013;&#25968;&#25454;&#21644;&#24230;&#37327;&#26159;&#22312;&#21015;&#34920;&#19978;&#23450;&#20041;&#21644;&#35745;&#31639;&#30340;&#65292;&#32780;&#19981;&#26159;&#22312;&#39033;&#30446;&#26412;&#36523;&#19978;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#19981;&#19968;&#33268;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21015;&#34920;&#32423;&#21035;&#23545;&#40784;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Domain adaptation aims to transfer the knowledge learned on (data-rich) source domains to (low-resource) target domains, and a popular method is invariant representation learning, which matches and aligns the data distributions on the feature space. Although this method is studied extensively and applied on classification and regression problems, its adoption on ranking problems is sporadic, and the few existing implementations lack theoretical justifications. This paper revisits invariant representation learning for ranking. Upon reviewing prior work, we found that they implement what we call item-level alignment, which aligns the distributions of the items being ranked from all lists in aggregate but ignores their list structure. However, the list structure should be leveraged, because it is intrinsic to ranking problems where the data and the metrics are defined and computed on lists, not the items by themselves. To close this discrepancy, we propose list-level alignment -learning
&lt;/p&gt;</description></item></channel></rss>