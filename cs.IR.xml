<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>LLMRec&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#32570;&#24615;&#21644;&#38468;&#21152;&#20449;&#24687;&#24341;&#20837;&#21103;&#20316;&#29992;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#24378;&#20132;&#20114;&#36793;&#12289;&#22686;&#24378;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#29702;&#35299;&#21644;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.00423</link><description>&lt;p&gt;
LLMRec: &#20351;&#29992;&#22270;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
LLMRec: Large Language Models with Graph Augmentation for Recommendation. (arXiv:2311.00423v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00423
&lt;/p&gt;
&lt;p&gt;
LLMRec&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#32570;&#24615;&#21644;&#38468;&#21152;&#20449;&#24687;&#24341;&#20837;&#21103;&#20316;&#29992;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#24378;&#20132;&#20114;&#36793;&#12289;&#22686;&#24378;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#29702;&#35299;&#21644;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31232;&#30095;&#24615;&#19968;&#30452;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#65292;&#20043;&#21069;&#30340;&#30740;&#31350;&#23581;&#35797;&#36890;&#36807;&#24341;&#20837;&#38468;&#21152;&#20449;&#24687;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24448;&#24448;&#20250;&#24102;&#26469;&#22122;&#22768;&#12289;&#21487;&#29992;&#24615;&#38382;&#39064;&#21644;&#25968;&#25454;&#36136;&#37327;&#20302;&#19979;&#31561;&#21103;&#20316;&#29992;&#65292;&#20174;&#32780;&#24433;&#21709;&#23545;&#29992;&#25143;&#20559;&#22909;&#30340;&#20934;&#30830;&#24314;&#27169;&#65292;&#36827;&#32780;&#23545;&#25512;&#33616;&#24615;&#33021;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#37492;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#30693;&#35782;&#24211;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LLMRec&#30340;&#26032;&#26694;&#26550;&#65292;&#23427;&#36890;&#36807;&#37319;&#29992;&#19977;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22522;&#20110;LLM&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22312;&#32447;&#24179;&#21488;&#65288;&#22914;Netflix&#65292;MovieLens&#65289;&#20013;&#20016;&#23500;&#30340;&#20869;&#23481;&#65292;&#22312;&#19977;&#20010;&#26041;&#38754;&#22686;&#24378;&#20132;&#20114;&#22270;&#65306;&#65288;i&#65289;&#21152;&#24378;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#36793;&#65292;&#65288;ii&#65289;&#22686;&#24378;&#23545;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#30340;&#29702;&#35299;&#65292;&#65288;iii&#65289;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#65292;&#30452;&#35266;&#22320;&#34920;&#31034;&#29992;&#25143;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies. Our approach leverages the rich content available within online platforms (e.g., Netflix, MovieLens) to augment the interaction graph in three ways: (i) reinforcing user-item interaction egde, (ii) enhancing the understanding of item node attributes, and (iii) conducting user node profiling, intuiti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#22686;&#24378;&#30340;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#27169;&#22411;G2P2&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#25552;&#31034;&#30340;&#26041;&#24335;&#65292;&#21033;&#29992;&#22270;&#32467;&#26500;&#30340;&#35821;&#20041;&#20851;&#31995;&#26469;&#25552;&#21319;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.10230</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#22686;&#24378;&#30340;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#30340;Prompt&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
Prompt Tuning on Graph-augmented Low-resource Text Classification. (arXiv:2307.10230v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#22686;&#24378;&#30340;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#27169;&#22411;G2P2&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#25552;&#31034;&#30340;&#26041;&#24335;&#65292;&#21033;&#29992;&#22270;&#32467;&#26500;&#30340;&#35821;&#20041;&#20851;&#31995;&#26469;&#25552;&#21319;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#20998;&#31867;&#26159;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#19968;&#20010;&#22522;&#30784;&#38382;&#39064;&#65292;&#26377;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#65292;&#20363;&#22914;&#39044;&#27979;&#22312;&#32447;&#25991;&#31456;&#30340;&#20027;&#39064;&#21644;&#30005;&#23376;&#21830;&#21153;&#20135;&#21697;&#25551;&#36848;&#30340;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#65292;&#21363;&#27809;&#26377;&#25110;&#21482;&#26377;&#24456;&#23569;&#26631;&#27880;&#26679;&#26412;&#30340;&#24773;&#20917;&#65292;&#23545;&#30417;&#30563;&#23398;&#20064;&#26500;&#25104;&#20102;&#20005;&#37325;&#38382;&#39064;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#35768;&#22810;&#25991;&#26412;&#25968;&#25454;&#26412;&#36136;&#19978;&#37117;&#24314;&#31435;&#22312;&#32593;&#32476;&#32467;&#26500;&#19978;&#65292;&#20363;&#22914;&#22312;&#32447;&#25991;&#31456;&#30340;&#36229;&#38142;&#25509;/&#24341;&#29992;&#32593;&#32476;&#21644;&#30005;&#23376;&#21830;&#21153;&#20135;&#21697;&#30340;&#29992;&#25143;-&#29289;&#21697;&#36141;&#20080;&#32593;&#32476;&#12290;&#36825;&#20123;&#22270;&#32467;&#26500;&#25429;&#25417;&#20102;&#20016;&#23500;&#30340;&#35821;&#20041;&#20851;&#31995;&#65292;&#26377;&#21161;&#20110;&#22686;&#24378;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Graph-Grounded Pre-training and Prompting (G2P2)&#30340;&#26032;&#27169;&#22411;&#65292;&#20197;&#20004;&#26041;&#38754;&#26041;&#27861;&#35299;&#20915;&#20302;&#36164;&#28304;&#25991;&#26412;&#20998;&#31867;&#38382;&#39064;&#12290;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#22522;&#20110;&#22270;&#20132;&#20114;&#30340;&#23545;&#27604;&#31574;&#30053;&#65292;&#20849;&#21516;&#39044;&#35757;&#32451;&#22270;&#25991;&#27169;&#22411;&#65307;&#22312;&#19979;&#28216;&#20998;&#31867;&#38454;&#27573;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#25163;&#24037;&#35774;&#35745;&#30340;&#25552;&#31034;&#20449;&#24687;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Text classification is a fundamental problem in information retrieval with many real-world applications, such as predicting the topics of online articles and the categories of e-commerce product descriptions. However, low-resource text classification, with no or few labeled samples, presents a serious concern for supervised learning. Meanwhile, many text data are inherently grounded on a network structure, such as a hyperlink/citation network for online articles, and a user-item purchase network for e-commerce products. These graph structures capture rich semantic relationships, which can potentially augment low-resource text classification. In this paper, we propose a novel model called Graph-Grounded Pre-training and Prompting (G2P2) to address low-resource text classification in a two-pronged approach. During pre-training, we propose three graph interaction-based contrastive strategies to jointly pre-train a graph-text model; during downstream classification, we explore handcrafted 
&lt;/p&gt;</description></item><item><title>&#21487;&#20449;&#24230;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#24050;&#32463;&#20174;&#20197;&#20934;&#30830;&#24615;&#20026;&#23548;&#21521;&#36716;&#21464;&#20026;&#20197;&#36879;&#26126;&#12289;&#20844;&#27491;&#12289;&#31283;&#20581;&#24615;&#20026;&#29305;&#28857;&#30340;&#21487;&#20449;&#24230;&#25512;&#33616;&#31995;&#32479;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#21487;&#20449;&#24230;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#25991;&#29486;&#32508;&#36848;&#21644;&#35752;&#35770;&#12290;</title><link>http://arxiv.org/abs/2208.06265</link><description>&lt;p&gt;
&#21487;&#20449;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Trustworthy Recommender Systems. (arXiv:2208.06265v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06265
&lt;/p&gt;
&lt;p&gt;
&#21487;&#20449;&#24230;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#24050;&#32463;&#20174;&#20197;&#20934;&#30830;&#24615;&#20026;&#23548;&#21521;&#36716;&#21464;&#20026;&#20197;&#36879;&#26126;&#12289;&#20844;&#27491;&#12289;&#31283;&#20581;&#24615;&#20026;&#29305;&#28857;&#30340;&#21487;&#20449;&#24230;&#25512;&#33616;&#31995;&#32479;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#21487;&#20449;&#24230;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#25991;&#29486;&#32508;&#36848;&#21644;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#24110;&#21161;&#29992;&#25143;&#20174;&#24222;&#22823;&#30340;&#30446;&#24405;&#20013;&#26377;&#25928;&#22320;&#26816;&#32034;&#24863;&#20852;&#36259;&#30340;&#29289;&#21697;&#12290;&#38271;&#26399;&#20197;&#26469;&#65292;&#30740;&#31350;&#20154;&#21592;&#19968;&#30452;&#33268;&#21147;&#20110;&#24320;&#21457;&#20934;&#30830;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#36817;&#24180;&#26469;&#65292;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#36234;&#26469;&#36234;&#22810;&#30340;&#23041;&#32961;&#65292;&#21253;&#25324;&#26469;&#33258;&#25915;&#20987;&#12289;&#31995;&#32479;&#21644;&#29992;&#25143;&#20135;&#29983;&#30340;&#24178;&#25200;&#20197;&#21450;&#31995;&#32479;&#30340;&#20559;&#35265;&#12290;&#22240;&#27492;&#65292;&#20165;&#20165;&#20851;&#27880;&#20934;&#30830;&#24615;&#24050;&#32463;&#19981;&#22815;&#65292;&#30740;&#31350;&#24517;&#39035;&#32771;&#34385;&#20854;&#20182;&#37325;&#35201;&#22240;&#32032;&#65292;&#22914;&#21487;&#20449;&#24230;&#12290;&#23545;&#20110;&#32456;&#31471;&#29992;&#25143;&#26469;&#35828;&#65292;&#19968;&#20010;&#20540;&#24471;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#19981;&#20165;&#35201;&#20934;&#30830;&#65292;&#32780;&#19988;&#36824;&#35201;&#36879;&#26126;&#12289;&#26080;&#20559;&#35265;&#12289;&#20844;&#27491;&#65292;&#24182;&#19988;&#23545;&#24178;&#25200;&#25110;&#25915;&#20987;&#20855;&#26377;&#31283;&#20581;&#24615;&#12290;&#36825;&#20123;&#35266;&#23519;&#23454;&#38469;&#19978;&#23548;&#33268;&#20102;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#30340;&#33539;&#24335;&#36716;&#21464;: &#20174;&#20197;&#20934;&#30830;&#24615;&#20026;&#23548;&#21521;&#30340;&#25512;&#33616;&#31995;&#32479;&#36716;&#21521;&#20102;&#20197;&#21487;&#20449;&#24230;&#20026;&#23548;&#21521;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#30740;&#31350;&#20154;&#21592;&#32570;&#20047;&#23545;&#21487;&#20449;&#24230;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#25991;&#29486;&#30340;&#31995;&#32479;&#27010;&#36848;&#21644;&#35752;&#35770;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20379;&#20102;&#21487;&#20449;&#24230;&#25512;&#33616;&#31995;&#32479;&#30340;&#27010;&#36848;&#65292;&#21253;&#25324;&#23545;&#35813;&#26032;&#20852;&#19988;&#24555;&#36895;&#21457;&#23637;&#39046;&#22495;&#30340;&#25991;&#29486;&#30340;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RSs) aim to help users to effectively retrieve items of their interests from a large catalogue. For a quite long period of time, researchers and practitioners have been focusing on developing accurate RSs. Recent years have witnessed an increasing number of threats to RSs, coming from attacks, system and user generated noise, system bias. As a result, it has become clear that a strict focus on RS accuracy is limited and the research must consider other important factors, e.g., trustworthiness. For end users, a trustworthy RS (TRS) should not only be accurate, but also transparent, unbiased and fair as well as robust to noise or attacks. These observations actually led to a paradigm shift of the research on RSs: from accuracy-oriented RSs to TRSs. However, researchers lack a systematic overview and discussion of the literature in this novel and fast developing field of TRSs. To this end, in this paper, we provide an overview of TRSs, including a discussion of the mo
&lt;/p&gt;</description></item></channel></rss>