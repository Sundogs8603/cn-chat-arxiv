<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29983;&#25104;&#20851;&#32852;&#24314;&#27169;&#65288;GRM&#65289;&#26041;&#27861;&#65292;&#20351;&#29992;&#20851;&#32852;&#24863;&#30693;&#26679;&#26412;&#20272;&#35745;&#65288;RASE&#65289;&#36827;&#34892;&#25991;&#26412;&#21152;&#26435;&#65292;&#20197;&#26356;&#20934;&#30830;&#26435;&#34913;&#25193;&#23637;&#35789;&#39033;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;GRM&#26041;&#27861;&#22312;&#19977;&#20010;&#26631;&#20934;&#25991;&#26723;&#25490;&#21517;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.09938</link><description>&lt;p&gt;
&#20351;&#29992;&#20851;&#32852;&#24863;&#30693;&#26679;&#26412;&#20272;&#35745;&#30340;&#29983;&#25104;&#20851;&#32852;&#24314;&#27169;&#26469;&#36827;&#34892;&#25991;&#26723;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
GRM: Generative Relevance Modeling Using Relevance-Aware Sample Estimation for Document Retrieval. (arXiv:2306.09938v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29983;&#25104;&#20851;&#32852;&#24314;&#27169;&#65288;GRM&#65289;&#26041;&#27861;&#65292;&#20351;&#29992;&#20851;&#32852;&#24863;&#30693;&#26679;&#26412;&#20272;&#35745;&#65288;RASE&#65289;&#36827;&#34892;&#25991;&#26412;&#21152;&#26435;&#65292;&#20197;&#26356;&#20934;&#30830;&#26435;&#34913;&#25193;&#23637;&#35789;&#39033;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;GRM&#26041;&#27861;&#22312;&#19977;&#20010;&#26631;&#20934;&#25991;&#26723;&#25490;&#21517;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26412;&#36827;&#34892;&#29983;&#25104;&#20851;&#32852;&#21453;&#39304;&#65288;GRF&#65289;&#21487;&#20197;&#22686;&#24378;&#26597;&#35810;&#25193;&#23637;&#30340;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#35821;&#35328;&#27169;&#22411;&#21487;&#33021;&#20250;&#29983;&#25104;&#19981;&#30456;&#20851;&#30340;&#20449;&#24687;&#65292;&#23545;&#26816;&#32034;&#25928;&#26524;&#26377;&#23475;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#20851;&#32852;&#24863;&#30693;&#26679;&#26412;&#20272;&#35745;&#65288;RASE&#65289;&#30340;&#29983;&#25104;&#20851;&#32852;&#24314;&#27169;&#65288;GRM&#65289;&#65292;&#26469;&#26356;&#20934;&#30830;&#22320;&#21152;&#26435;&#25193;&#23637;&#35789;&#39033;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#29983;&#25104;&#30340;&#25991;&#26723;&#35782;&#21035;&#31867;&#20284;&#30340;&#30495;&#23454;&#25991;&#26723;&#65292;&#24182;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#37325;&#26032;&#25490;&#24207;&#22120;&#20272;&#35745;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;&#22312;&#19977;&#20010;&#26631;&#20934;&#25991;&#26723;&#25490;&#21517;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;GRM&#23558;&#22343;&#20540;&#24179;&#22343;&#31934;&#24230;&#65288;MAP&#65289;&#25552;&#39640;&#20102;6-9%&#21644;R@1k&#25552;&#39640;&#20102;2-4%&#65292;&#36229;&#36807;&#20102;&#20808;&#21069;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies show that Generative Relevance Feedback (GRF), using text generated by Large Language Models (LLMs), can enhance the effectiveness of query expansion. However, LLMs can generate irrelevant information that harms retrieval effectiveness. To address this, we propose Generative Relevance Modeling (GRM) that uses Relevance-Aware Sample Estimation (RASE) for more accurate weighting of expansion terms. Specifically, we identify similar real documents for each generated document and use a neural re-ranker to estimate their relevance. Experiments on three standard document ranking benchmarks show that GRM improves MAP by 6-9% and R@1k by 2-4%, surpassing previous methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#22522;&#20110;&#24773;&#24863;&#20998;&#26512;&#30340;&#25628;&#32034;&#21151;&#33021;&#35299;&#20915;&#25628;&#32034;&#32467;&#26524;&#20013;&#30340;&#22810;&#20041;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#21484;&#22238;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;&#25152;&#20351;&#29992;&#30340;Sentistrength&#31243;&#24207;&#22312;&#20998;&#31867;&#25628;&#32034;&#32467;&#26524;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#32858;&#31867;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20998;&#26512;&#20114;&#32852;&#32593;&#19978;&#23454;&#20307;&#30340;&#24773;&#24863;&#21644;&#22768;&#35465;&#12290;</title><link>http://arxiv.org/abs/2306.09777</link><description>&lt;p&gt;
&#22522;&#20110;&#24773;&#24863;&#20998;&#26512;&#30340;&#26234;&#33021;&#25628;&#32034;&#24341;&#25806;&#20998;&#31867;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Smart Sentiment Analysis-based Search Engine Classification Intelligence. (arXiv:2306.09777v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22522;&#20110;&#24773;&#24863;&#20998;&#26512;&#30340;&#25628;&#32034;&#21151;&#33021;&#35299;&#20915;&#25628;&#32034;&#32467;&#26524;&#20013;&#30340;&#22810;&#20041;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#21484;&#22238;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;&#25152;&#20351;&#29992;&#30340;Sentistrength&#31243;&#24207;&#22312;&#20998;&#31867;&#25628;&#32034;&#32467;&#26524;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#32858;&#31867;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20998;&#26512;&#20114;&#32852;&#32593;&#19978;&#23454;&#20307;&#30340;&#24773;&#24863;&#21644;&#22768;&#35465;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#24341;&#25806;&#26159;&#20154;&#20204;&#22312;&#20114;&#32852;&#32593;&#19978;&#23547;&#25214;&#20449;&#24687;&#30340;&#24120;&#29992;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#25628;&#32034;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#25552;&#20379;&#27969;&#34892;&#20294;&#19981;&#19968;&#23450;&#30456;&#20851;&#30340;&#32467;&#26524;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#29616;&#19968;&#20010;&#30830;&#23450;&#26816;&#32034;&#20449;&#24687;&#24773;&#24863;&#33394;&#24425;&#30340;&#25628;&#32034;&#21151;&#33021;&#26469;&#35299;&#20915;&#25628;&#32034;&#32467;&#26524;&#20013;&#30340;&#22810;&#20041;&#38382;&#39064;&#12290;&#35813;&#30740;&#31350;&#21033;&#29992;&#32593;&#32476;&#29228;&#34411;&#20174;&#33521;&#22269;&#24191;&#25773;&#20844;&#21496;&#65288;BBC&#65289;&#26032;&#38395;&#32593;&#31449;&#25910;&#38598;&#25968;&#25454;&#65292;&#20351;&#29992;Sentistrength&#31243;&#24207;&#30830;&#23450;&#26032;&#38395;&#25991;&#31456;&#30340;&#24773;&#24863;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#25628;&#32034;&#21151;&#33021;&#22312;&#25552;&#39640;&#21484;&#22238;&#29575;&#30340;&#21516;&#26102;&#65292;&#20934;&#30830;&#22320;&#26816;&#32034;&#21040;&#20102;&#38750;&#22810;&#20041;&#26032;&#38395;&#12290;&#27492;&#22806;&#65292;Sentistrength&#22312;&#20998;&#31867;&#25628;&#32034;&#32467;&#26524;&#26041;&#38754;&#30340;&#34920;&#29616;&#20248;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#32858;&#31867;&#26041;&#27861;&#12290;&#26412;&#25991;&#20171;&#32461;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#20998;&#26512;&#20114;&#32852;&#32593;&#19978;&#23454;&#20307;&#30340;&#24773;&#24863;&#21644;&#22768;&#35465;&#12290;
&lt;/p&gt;
&lt;p&gt;
Search engines are widely used for finding information on the internet. However, there are limitations in the current search approach, such as providing popular but not necessarily relevant results. This research addresses the issue of polysemy in search results by implementing a search function that determines the sentimentality of the retrieved information. The study utilizes a web crawler to collect data from the British Broadcasting Corporation (BBC) news site, and the sentimentality of the news articles is determined using the Sentistrength program. The results demonstrate that the proposed search function improves recall value while accurately retrieving nonpolysemous news. Furthermore, Sentistrength outperforms deep learning and clustering methods in classifying search results. The methodology presented in this article can be applied to analyze the sentimentality and reputation of entities on the internet.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20266;&#30456;&#20851;&#21453;&#39304;&#30340;&#22312;&#32447;&#33976;&#39311;&#25216;&#26415;&#65292;&#36890;&#36807;&#22312;&#32447;&#36880;&#27493;&#24314;&#31435;&#27169;&#22411;&#65292;&#39044;&#27979;&#26597;&#35810;&#19982;&#25991;&#26723;&#30340;&#30456;&#20851;&#24471;&#20998;&#65292;&#24182;&#22312;&#32034;&#24341;&#20013;&#39640;&#25928;&#25191;&#34892;&#65292;&#20197;&#20248;&#21270;&#25972;&#20307;&#26816;&#32034;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.09657</link><description>&lt;p&gt;
Online Distillation for Pseudo-Relevance Feedback&#65288;&#20266;&#30456;&#20851;&#21453;&#39304;&#30340;&#22312;&#32447;&#33976;&#39311;&#25216;&#26415;&#65289;
&lt;/p&gt;
&lt;p&gt;
Online Distillation for Pseudo-Relevance Feedback. (arXiv:2306.09657v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20266;&#30456;&#20851;&#21453;&#39304;&#30340;&#22312;&#32447;&#33976;&#39311;&#25216;&#26415;&#65292;&#36890;&#36807;&#22312;&#32447;&#36880;&#27493;&#24314;&#31435;&#27169;&#22411;&#65292;&#39044;&#27979;&#26597;&#35810;&#19982;&#25991;&#26723;&#30340;&#30456;&#20851;&#24471;&#20998;&#65292;&#24182;&#22312;&#32034;&#24341;&#20013;&#39640;&#25928;&#25191;&#34892;&#65292;&#20197;&#20248;&#21270;&#25972;&#20307;&#26816;&#32034;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#33976;&#39311;&#26159;&#19968;&#31181;&#25552;&#39640;&#31070;&#32463;&#25628;&#32034;&#27169;&#22411;&#25928;&#26524;&#30340;&#37325;&#35201;&#26041;&#27861;&#12290;&#24403;&#21069;&#65292;&#20256;&#32479;&#30340;&#33976;&#39311;&#26041;&#27861;&#37319;&#29992;&#31163;&#32447;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#21363;&#35757;&#32451;&#19968;&#20010;&#26032;&#30340;&#31070;&#32463;&#27169;&#22411;&#39044;&#27979;&#20219;&#24847;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24471;&#20998;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#33976;&#39311;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#33976;&#39311;&#36880;&#27493;&#24314;&#31435;&#27169;&#22411;&#65292;&#20197;&#27492;&#26469;&#39044;&#27979;&#26576;&#19968;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24471;&#20998;&#65292;&#24182;&#22312;&#32034;&#24341;&#20013;&#25191;&#34892;&#20986;&#33394;&#12290;&#35813;&#25216;&#26415;&#19981;&#20165;&#21487;&#20197;&#25193;&#22823;&#37325;&#26032;&#25490;&#24207;&#30340;&#25991;&#26723;&#25968;&#37327;&#65292;&#36824;&#33021;&#35782;&#21035;&#22312;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#20013;&#34987;&#24573;&#30053;&#30340;&#25991;&#26723;&#65292;&#20197;&#20248;&#21270;&#25972;&#20307;&#26816;&#32034;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model distillation has emerged as a prominent technique to improve neural search models. To date, distillation taken an offline approach, wherein a new neural model is trained to predict relevance scores between arbitrary queries and documents. In this paper, we explore a departure from this offline distillation strategy by investigating whether a model for a specific query can be effectively distilled from neural re-ranking results (i.e., distilling in an online setting). Indeed, we find that a lexical model distilled online can reasonably replicate the re-ranking of a neural model. More importantly, these models can be used as queries that execute efficiently on indexes. This second retrieval stage can enrich the pool of documents for re-ranking by identifying documents that were missed in the first retrieval stage. Empirically, we show that this approach performs favourably when compared with established pseudo relevance feedback techniques, dense retrieval methods, and sparse-dense
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; P-Summ &#30340;&#26080;&#30417;&#30563;&#31639;&#27861;&#65292;&#33021;&#22815;&#29983;&#25104;&#31526;&#21512;&#29992;&#25143;&#20010;&#24615;&#21270;&#38656;&#27714;&#30340;&#23398;&#26415;&#25991;&#26412;&#25277;&#21462;&#24335;&#25688;&#35201;&#12290;&#35813;&#31639;&#27861;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#20854;&#33021;&#22815;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#21253;&#21547;&#25152;&#38656;&#30340;&#30693;&#35782;&#24182;&#28040;&#38500;&#19981;&#38656;&#35201;&#30340;&#30693;&#35782;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#31890;&#24230;&#35780;&#20272;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2306.09604</link><description>&lt;p&gt;
&#25105;&#38656;&#35201;&#36825;&#20010;&#65292;&#32780;&#19981;&#26159;&#37027;&#20010;&#65306;&#20010;&#24615;&#21270;&#25688;&#35201;&#31185;&#23398;&#23398;&#26415;&#25991;&#26412;
&lt;/p&gt;
&lt;p&gt;
I Want This, Not That: Personalized Summarization of Scientific Scholarly Texts. (arXiv:2306.09604v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09604
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; P-Summ &#30340;&#26080;&#30417;&#30563;&#31639;&#27861;&#65292;&#33021;&#22815;&#29983;&#25104;&#31526;&#21512;&#29992;&#25143;&#20010;&#24615;&#21270;&#38656;&#27714;&#30340;&#23398;&#26415;&#25991;&#26412;&#25277;&#21462;&#24335;&#25688;&#35201;&#12290;&#35813;&#31639;&#27861;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#20854;&#33021;&#22815;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#21253;&#21547;&#25152;&#38656;&#30340;&#30693;&#35782;&#24182;&#28040;&#38500;&#19981;&#38656;&#35201;&#30340;&#30693;&#35782;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#31890;&#24230;&#35780;&#20272;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#30417;&#30563;&#31639;&#27861; P-Summ&#65292;&#23427;&#21033;&#29992;&#21152;&#26435;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#25581;&#31034;&#25991;&#26723;&#30340;&#28508;&#22312;&#35821;&#20041;&#31354;&#38388;&#65292;&#22312;&#31526;&#21512;&#29992;&#25143;&#30693;&#35782;&#38656;&#27714;&#30340;&#22522;&#30784;&#19978;&#65292;&#23545;&#21477;&#23376;&#36827;&#34892;&#35780;&#20998;&#65292;&#29983;&#25104;&#31185;&#23398;&#23398;&#26415;&#25991;&#26412;&#30340;&#25277;&#21462;&#24335;&#25688;&#35201;&#20197;&#28385;&#36275;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#38656;&#27714;&#12290;&#35813;&#26041;&#27861;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#20854;&#33021;&#22815;&#21253;&#21547;&#25152;&#38656;&#30340;&#30693;&#35782;&#24182;&#28040;&#38500;&#19981;&#38656;&#35201;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#31890;&#24230;&#35780;&#20272;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#27604;&#36739;&#29983;&#25104;&#30340;&#20010;&#24615;&#21270;&#25688;&#35201;&#19982;&#31995;&#32479;&#29983;&#25104;&#30340;&#36890;&#29992;&#25688;&#35201;&#65292;&#21253;&#25324;&#21477;&#23376;&#12289;&#35789;&#35821;&#21644;&#35821;&#20041;&#19977;&#20010;&#23618;&#27425;&#23545;&#35813;&#25688;&#35201;&#30340;&#36136;&#37327;&#36827;&#34892;&#35780;&#20272;&#12290;&#35780;&#20272;&#31639;&#27861;&#22312;&#35821;&#20041;&#23618;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#26159;&#36890;&#36807;&#19982;&#21442;&#32771;&#25688;&#35201;&#21644;&#29992;&#25143;&#38656;&#27714;&#36827;&#34892;&#27604;&#36739;&#23436;&#25104;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a proposal for an unsupervised algorithm, P-Summ, that generates an extractive summary of scientific scholarly text to meet the personal knowledge needs of the user. The method delves into the latent semantic space of the document exposed by Weighted Non-negative Matrix Factorization, and scores sentences in consonance with the knowledge needs of the user. The novelty of the algorithm lies in its ability to include desired knowledge and eliminate unwanted knowledge in the personal summary.  We also propose a multi-granular evaluation framework, which assesses the quality of generated personal summaries at three levels of granularity sentence, terms and semantic. The framework uses system generated generic summary instead of human generated summary as gold standard for evaluating the quality of personal summary generated by the algorithm. The effectiveness of the algorithm at the semantic level is evaluated by taking into account the reference summary and the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;h2oGPT&#65292;&#36825;&#26159;&#19968;&#22871;&#24320;&#28304;&#20195;&#30721;&#24211;&#65292;&#29992;&#20110;&#21019;&#24314;&#21644;&#20351;&#29992;&#22522;&#20110;GPTs&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#21253;&#25324;100&#65285;&#31169;&#26377;&#25991;&#26723;&#25628;&#32034;&#12290;&#30446;&#26631;&#26159;&#21019;&#24314;&#30495;&#27491;&#24320;&#28304;&#30340;&#26367;&#20195;&#23553;&#38381;&#28304;GPTs&#65292;&#25552;&#39640;&#20154;&#24037;&#26234;&#33021;&#30340;&#24320;&#21457;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.08161</link><description>&lt;p&gt;
h2oGPT&#65306;&#27665;&#20027;&#21270;&#22823;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
h2oGPT: Democratizing Large Language Models. (arXiv:2306.08161v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08161
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;h2oGPT&#65292;&#36825;&#26159;&#19968;&#22871;&#24320;&#28304;&#20195;&#30721;&#24211;&#65292;&#29992;&#20110;&#21019;&#24314;&#21644;&#20351;&#29992;&#22522;&#20110;GPTs&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#21253;&#25324;100&#65285;&#31169;&#26377;&#25991;&#26723;&#25628;&#32034;&#12290;&#30446;&#26631;&#26159;&#21019;&#24314;&#30495;&#27491;&#24320;&#28304;&#30340;&#26367;&#20195;&#23553;&#38381;&#28304;GPTs&#65292;&#25552;&#39640;&#20154;&#24037;&#26234;&#33021;&#30340;&#24320;&#21457;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#39044;&#35757;&#32451;&#21464;&#21387;&#22120;&#65288;GPTs&#65289;&#65292;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;GPT-4&#22240;&#20854;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#30340;&#29616;&#23454;&#24212;&#29992;&#32780;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#38761;&#21629;&#30340;&#19968;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#20063;&#24102;&#26469;&#20102;&#35768;&#22810;&#37325;&#22823;&#30340;&#39118;&#38505;&#65292;&#22914;&#23384;&#22312;&#26377;&#20559;&#35265;&#12289;&#31169;&#20154;&#25110;&#26377;&#23475;&#25991;&#26412;&#21644;&#26410;&#32463;&#25480;&#26435;&#30340;&#29256;&#26435;&#26448;&#26009;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;h2oGPT&#65292;&#36825;&#26159;&#19968;&#22871;&#24320;&#28304;&#20195;&#30721;&#24211;&#65292;&#29992;&#20110;&#21019;&#24314;&#21644;&#20351;&#29992;&#22522;&#20110;GPTs&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#35813;&#39033;&#30446;&#30340;&#30446;&#26631;&#26159;&#21019;&#24314;&#19990;&#30028;&#19978;&#26368;&#22909;&#30340;&#30495;&#27491;&#24320;&#28304;&#30340;&#26367;&#20195;&#23553;&#38381;&#28304;GPTs&#12290;&#19982;&#24320;&#28304;&#31038;&#21306;&#21512;&#20316;&#65292;&#20316;&#20026;&#20854;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#24320;&#28304;&#20102;&#20960;&#20010;LLM&#65292;&#20854;&#21442;&#25968;&#20174;7&#20159;&#21040;400&#20159;&#65292;&#21487;&#22312;&#23436;&#20840;&#33258;&#30001;&#30340;Apache 2.0&#35768;&#21487;&#19979;&#21830;&#29992;&#12290;&#25105;&#20204;&#30340;&#21457;&#24067;&#21253;&#25324;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#30340;100&#65285;&#31169;&#26377;&#25991;&#26723;&#25628;&#32034;&#12290;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#26377;&#21161;&#20110;&#20419;&#36827;&#20154;&#24037;&#26234;&#33021;&#30340;&#21457;&#23637;&#24182;&#20351;&#20854;&#26356;&#21152;&#21487;&#38752;&#12290;
&lt;/p&gt;
&lt;p&gt;
Foundation Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their real-world applications though natural language processing. However, they also pose many significant risks such as the presence of biased, private, or harmful text, and the unauthorized inclusion of copyrighted material.  We introduce h2oGPT, a suite of open-source code repositories for the creation and use of Large Language Models (LLMs) based on Generative Pretrained Transformers (GPTs). The goal of this project is to create the world's best truly open-source alternative to closed-source GPTs. In collaboration with and as part of the incredible and unstoppable open-source community, we open-source several fine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for commercial use under fully permissive Apache 2.0 licenses. Included in our release is 100% private document search using natural language.  Open-source language models help boost AI development and make it more accessible
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;DPVP&#26041;&#27861;&#65292;&#29992;&#20110;&#22806;&#21334;&#25512;&#33616;&#65292;&#32771;&#34385;&#21040;&#29992;&#25143;&#23545;&#21830;&#24215;&#21644;&#39135;&#21697;&#30340;&#21452;&#37325;&#20559;&#22909;&#20197;&#21450;&#22312;&#19968;&#22825;&#20013;&#30340;&#19981;&#21516;&#26102;&#27573;&#20559;&#22909;&#30340;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2306.04370</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#21608;&#26399;&#21464;&#21270;&#20559;&#22909;&#30340;&#22806;&#21334;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Modeling Dual Period-Varying Preferences for Takeaway Recommendation. (arXiv:2306.04370v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04370
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;DPVP&#26041;&#27861;&#65292;&#29992;&#20110;&#22806;&#21334;&#25512;&#33616;&#65292;&#32771;&#34385;&#21040;&#29992;&#25143;&#23545;&#21830;&#24215;&#21644;&#39135;&#21697;&#30340;&#21452;&#37325;&#20559;&#22909;&#20197;&#21450;&#22312;&#19968;&#22825;&#20013;&#30340;&#19981;&#21516;&#26102;&#27573;&#20559;&#22909;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22806;&#21334;&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#31934;&#20934;&#25552;&#20379;&#31526;&#21512;&#29992;&#25143;&#20852;&#36259;&#30340;&#21830;&#24215;&#21644;&#39135;&#29289;&#65292;&#24050;&#32463;&#20026;&#25968;&#21313;&#20159;&#29992;&#25143;&#30340;&#26085;&#24120;&#29983;&#27963;&#25552;&#20379;&#26381;&#21153;&#12290;&#19982;&#20256;&#32479;&#25512;&#33616;&#19981;&#21516;&#65292;&#22806;&#21334;&#25512;&#33616;&#38754;&#20020;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#65288;1&#65289;&#21452;&#37325;&#20132;&#20114;&#24863;&#30693;&#20559;&#22909;&#24314;&#27169;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#36890;&#24120;&#20851;&#27880;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#21333;&#19968;&#20559;&#22909;&#65292;&#32780;&#22806;&#21334;&#25512;&#33616;&#38656;&#35201;&#20840;&#38754;&#32771;&#34385;&#29992;&#25143;&#23545;&#21830;&#24215;&#21644;&#39135;&#21697;&#30340;&#21452;&#37325;&#20559;&#22909;&#12290;(2) &#21608;&#26399;&#24615;&#21464;&#21270;&#20559;&#22909;&#24314;&#27169;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#36890;&#24120;&#20174;&#20250;&#35805;&#32423;&#21035;&#25110;&#26085;&#32423;&#21035;&#30340;&#35282;&#24230;&#26469;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#30340;&#36830;&#32493;&#21464;&#21270;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#30340;&#22806;&#21334;&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#30340;&#20559;&#22909;&#22312;&#26089;&#26216;&#12289;&#20013;&#21320;&#12289;&#26202;&#19978;&#21644;&#28145;&#22812;&#31561;&#26102;&#27573;&#37117;&#20250;&#26377;&#26174;&#33879;&#30340;&#21464;&#21270;&#12290;&#38024;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#21608;&#26399;&#21464;&#21270;&#20559;&#22909;&#30340;&#22806;&#21334;&#25512;&#33616;&#24314;&#27169;&#65288;DPVP&#65289;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21452;&#37325;&#20132;&#20114;&#24863;&#30693;&#27169;&#22359;&#65292;&#26088;&#22312;
&lt;/p&gt;
&lt;p&gt;
Takeaway recommender systems, which aim to accurately provide stores that offer foods meeting users' interests, have served billions of users in our daily life. Different from traditional recommendation, takeaway recommendation faces two main challenges: (1) Dual Interaction-Aware Preference Modeling. Traditional recommendation commonly focuses on users' single preferences for items while takeaway recommendation needs to comprehensively consider users' dual preferences for stores and foods. (2) Period-Varying Preference Modeling. Conventional recommendation generally models continuous changes in users' preferences from a session-level or day-level perspective. However, in practical takeaway systems, users' preferences vary significantly during the morning, noon, night, and late night periods of the day. To address these challenges, we propose a Dual Period-Varying Preference modeling (DPVP) for takeaway recommendation. Specifically, we design a dual interaction-aware module, aiming to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#26080;&#27169;&#22411;&#25968;&#25454;&#23376;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#29992;&#25143;-&#29289;&#21697;&#22270;&#30340;&#25299;&#25169;&#32467;&#26500;&#26469;&#20272;&#35745;&#27599;&#20010;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#20256;&#25773;&#26469;&#24179;&#28369;&#20272;&#35745;&#20540;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#26080;&#27169;&#22411;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#23376;&#37319;&#26679;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.16391</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#26080;&#27169;&#22411;&#25968;&#25454;&#23376;&#37319;&#26679;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Graph-Based Model-Agnostic Data Subsampling for Recommendation Systems. (arXiv:2305.16391v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#26080;&#27169;&#22411;&#25968;&#25454;&#23376;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#29992;&#25143;-&#29289;&#21697;&#22270;&#30340;&#25299;&#25169;&#32467;&#26500;&#26469;&#20272;&#35745;&#27599;&#20010;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#20256;&#25773;&#26469;&#24179;&#28369;&#20272;&#35745;&#20540;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#26080;&#27169;&#22411;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#23376;&#37319;&#26679;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#23376;&#37319;&#26679;&#24191;&#27867;&#29992;&#20110;&#21152;&#36895;&#35757;&#32451;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#12290;&#22823;&#22810;&#25968;&#23376;&#37319;&#26679;&#26041;&#27861;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#65292;&#24120;&#24120;&#38656;&#35201;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;&#35797;&#39564;&#27169;&#22411;&#26469;&#36890;&#36807;&#26679;&#26412;&#38590;&#24230;&#31561;&#26041;&#24335;&#27979;&#37327;&#25968;&#25454;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#35797;&#39564;&#27169;&#22411;&#34987;&#38169;&#35823;&#25351;&#23450;&#26102;&#65292;&#22522;&#20110;&#27169;&#22411;&#30340;&#23376;&#37319;&#26679;&#26041;&#27861;&#23558;&#20250;&#24694;&#21270;&#12290;&#37492;&#20110;&#35797;&#39564;&#27169;&#22411;&#30340;&#38169;&#35823;&#25351;&#23450;&#22312;&#30495;&#23454;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#32467;&#26500;&#65292;&#21363;&#22270;&#24418;&#26469;&#25506;&#32034;&#30340;&#26080;&#27169;&#22411;&#25968;&#25454;&#23376;&#37319;&#26679;&#26041;&#27861;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30740;&#31350;&#29992;&#25143;-&#29289;&#21697;&#22270;&#30340;&#25299;&#25169;&#32467;&#26500;&#65292;&#36890;&#36807;&#22270;&#23548;&#30005;&#24615;&#26469;&#20272;&#35745;&#27599;&#20010;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#65288;&#21363;&#29992;&#25143;-&#29289;&#21697;&#22270;&#20013;&#30340;&#19968;&#26465;&#36793;&#65289;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#20256;&#25773;&#27493;&#39588;&#65292;&#24179;&#28369;&#20272;&#35745;&#30340;&#37325;&#35201;&#24615;&#20540;&#12290;&#30001;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#26080;&#27169;&#22411;&#30340;&#65292;&#22240;&#27492;&#25105;&#20204;&#21487;&#20197;&#23558;&#26080;&#27169;&#22411;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#23376;&#37319;&#26679;&#26041;&#27861;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#32452;&#21512;&#20351;&#29992;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#22343;&#27604;&#20219;&#20309;&#21333;&#19968;&#26041;&#27861;&#37117;&#35201;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data subsampling is widely used to speed up the training of large-scale recommendation systems. Most subsampling methods are model-based and often require a pre-trained pilot model to measure data importance via e.g. sample hardness. However, when the pilot model is misspecified, model-based subsampling methods deteriorate. Since model misspecification is persistent in real recommendation systems, we instead propose model-agnostic data subsampling methods by only exploring input data structure represented by graphs. Specifically, we study the topology of the user-item graph to estimate the importance of each user-item interaction (an edge in the user-item graph) via graph conductance, followed by a propagation step on the network to smooth out the estimated importance value.  Since our proposed method is model-agnostic, we can marry the merits of both model-agnostic and model-based subsampling methods. Empirically, we show that combing the two consistently improves over any single meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;Web&#25628;&#32034;&#31995;&#32479;&#20013;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#21033;&#29992;&#24515;&#29702;&#27979;&#37327;&#21644;&#20247;&#21253;&#25216;&#26415;&#65292;&#20998;&#26512;&#20102;&#21487;&#35299;&#37322;&#24615;&#30340;&#22810;&#20010;&#22240;&#32032;&#65292;&#20197;&#26399;&#25214;&#21040;&#35299;&#37322;&#24615;&#19982;&#20154;&#31867;&#22240;&#32032;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2210.09430</link><description>&lt;p&gt;
&#36890;&#36807;&#24515;&#29702;&#27979;&#37327;&#21644;&#20247;&#21253;&#35780;&#20272;&#25628;&#32034;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating Search Explainability with Psychometrics and Crowdsourcing. (arXiv:2210.09430v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09430
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;Web&#25628;&#32034;&#31995;&#32479;&#20013;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#21033;&#29992;&#24515;&#29702;&#27979;&#37327;&#21644;&#20247;&#21253;&#25216;&#26415;&#65292;&#20998;&#26512;&#20102;&#21487;&#35299;&#37322;&#24615;&#30340;&#22810;&#20010;&#22240;&#32032;&#65292;&#20197;&#26399;&#25214;&#21040;&#35299;&#37322;&#24615;&#19982;&#20154;&#31867;&#22240;&#32032;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#31995;&#32479;&#24050;&#25104;&#20026;&#25105;&#20204;&#26085;&#24120;&#29983;&#27963;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#19968;&#37096;&#20998;&#12290;&#30001;&#20110;&#25628;&#32034;&#24341;&#25806;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#23545;&#35805;&#20195;&#29702;&#22312;&#20174;&#23089;&#20048;&#25628;&#32034;&#21040;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31561;&#21508;&#20010;&#39046;&#22495;&#24471;&#21040;&#24212;&#29992;&#65292;&#22240;&#27492;&#38656;&#35201;&#36879;&#26126;&#21644;&#21487;&#35299;&#37322;&#30340;&#31995;&#32479;&#26469;&#30830;&#20445;&#21487;&#36861;&#28335;&#12289;&#20844;&#27491;&#21644;&#26080;&#20559;&#35265;&#30340;&#32467;&#26524;&#12290;&#23613;&#31649;&#22312;&#21487;&#35299;&#37322;&#30340;AI&#21644;IR&#25216;&#26415;&#26041;&#38754;&#21462;&#24471;&#20102;&#35768;&#22810;&#36817;&#26399;&#36827;&#23637;&#65292;&#20294;&#20173;&#26080;&#27861;&#23601;&#31995;&#32479;&#21487;&#35299;&#37322;&#24615;&#30340;&#21547;&#20041;&#36798;&#25104;&#20849;&#35782;&#12290;&#34429;&#28982;&#36234;&#26469;&#36234;&#22810;&#30340;&#25991;&#29486;&#34920;&#26126;&#65292;&#35299;&#37322;&#24615;&#21253;&#21547;&#22810;&#20010;&#23376;&#22240;&#32032;&#65292;&#20294;&#23454;&#38469;&#19978;&#25152;&#26377;&#29616;&#26377;&#26041;&#27861;&#20960;&#20046;&#37117;&#23558;&#20854;&#35270;&#20026;&#21333;&#19968;&#27010;&#24565;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#24515;&#29702;&#27979;&#37327;&#21644;&#20247;&#21253;&#30740;&#31350;&#20102;Web&#25628;&#32034;&#31995;&#32479;&#20013;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#30830;&#23450;&#20154;&#31867;&#20013;&#24515;&#22240;&#32032;&#19982;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information retrieval (IR) systems have become an integral part of our everyday lives. As search engines, recommender systems, and conversational agents are employed across various domains from recreational search to clinical decision support, there is an increasing need for transparent and explainable systems to guarantee accountable, fair, and unbiased results. Despite many recent advances towards explainable AI and IR techniques, there is no consensus on what it means for a system to be explainable. Although a growing body of literature suggests that explainability is comprised of multiple subfactors, virtually all existing approaches treat it as a singular notion. In this paper, we examine explainability in Web search systems, leveraging psychometrics and crowdsourcing to identify human-centered factors of explainability.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20027;&#35201;&#38024;&#23545;&#25991;&#26723;&#23618;&#38754;&#19978;&#30340;&#20851;&#31995;&#25277;&#21462;&#20013;&#23384;&#22312;&#20551;&#38452;&#24615;&#30340;&#38382;&#39064;&#65292;&#22312;&#37325;&#26032;&#27880;&#37322; DocRED &#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#34987;&#24573;&#30053;&#30340;&#20851;&#31995;&#19977;&#20803;&#32452;&#21518;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#24615;&#33021;&#25552;&#21319;&#32422; 13 F1 &#20998;&#25968;&#30340;&#26032;&#25968;&#25454;&#38598; Re-DocRED&#65292;&#24182;&#21457;&#29616;&#20102;&#26377;&#25928;&#25913;&#36827;&#30340;&#28508;&#22312;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2205.12696</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270; DocRED - &#35299;&#20915;&#20851;&#31995;&#25277;&#21462;&#20013;&#30340;&#20551;&#38452;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Revisiting DocRED -- Addressing the False Negative Problem in Relation Extraction. (arXiv:2205.12696v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12696
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20027;&#35201;&#38024;&#23545;&#25991;&#26723;&#23618;&#38754;&#19978;&#30340;&#20851;&#31995;&#25277;&#21462;&#20013;&#23384;&#22312;&#20551;&#38452;&#24615;&#30340;&#38382;&#39064;&#65292;&#22312;&#37325;&#26032;&#27880;&#37322; DocRED &#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#34987;&#24573;&#30053;&#30340;&#20851;&#31995;&#19977;&#20803;&#32452;&#21518;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#24615;&#33021;&#25552;&#21319;&#32422; 13 F1 &#20998;&#25968;&#30340;&#26032;&#25968;&#25454;&#38598; Re-DocRED&#65292;&#24182;&#21457;&#29616;&#20102;&#26377;&#25928;&#25913;&#36827;&#30340;&#28508;&#22312;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
DocRED &#25968;&#25454;&#38598;&#26159;&#26368;&#27969;&#34892;&#21644;&#24191;&#27867;&#20351;&#29992;&#30340;&#25991;&#26723;&#32423;&#20851;&#31995;&#25277;&#21462;&#22522;&#20934;&#25968;&#25454;&#38598;&#20043;&#19968;&#12290;&#23427;&#37319;&#29992;&#20102;&#19968;&#20010;&#25512;&#33616;-&#20462;&#35746;&#30340;&#26631;&#27880;&#26041;&#26696;&#65292;&#20197;&#33719;&#24471;&#22823;&#35268;&#27169;&#30340;&#27880;&#37322;&#25968;&#25454;&#38598;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616; DocRED &#30340;&#26631;&#27880;&#26159;&#19981;&#23436;&#25972;&#30340;&#65292;&#21363;&#20551;&#38452;&#24615;&#26679;&#26412;&#24456;&#26222;&#36941;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#32570;&#28857;&#65292;&#25105;&#20204;&#36890;&#36807;&#21521;&#21407;&#22987; DocRED &#20013;&#28155;&#21152;&#34987;&#24573;&#30053;&#30340;&#20851;&#31995;&#19977;&#20803;&#32452;&#26469;&#37325;&#26032;&#27880;&#37322;&#20102; 4,053 &#20010;&#25991;&#26723;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#20462;&#27491;&#21518;&#30340; DocRED &#25968;&#25454;&#38598;&#21629;&#21517;&#20026; Re-DocRED&#12290;&#25105;&#20204;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#27169;&#22411;&#22312;&#36825;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#24320;&#23637;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#25105;&#20204;&#30340; Re-DocRED &#35757;&#32451;&#21644;&#35780;&#20272;&#30340;&#27169;&#22411;&#24615;&#33021;&#25552;&#39640;&#20102;&#22823;&#32422; 13 &#20010; F1 &#20998;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#20998;&#26512;&#65292;&#35782;&#21035;&#20986;&#20102;&#36827;&#19968;&#27493;&#25913;&#36827;&#30340;&#28508;&#22312;&#39046;&#22495;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#20844;&#24320;&#22312; https://github&#12290;
&lt;/p&gt;
&lt;p&gt;
The DocRED dataset is one of the most popular and widely used benchmarks for document-level relation extraction (RE). It adopts a recommend-revise annotation scheme so as to have a large-scale annotated dataset. However, we find that the annotation of DocRED is incomplete, i.e., false negative samples are prevalent. We analyze the causes and effects of the overwhelming false negative problem in the DocRED dataset. To address the shortcoming, we re-annotate 4,053 documents in the DocRED dataset by adding the missed relation triples back to the original DocRED. We name our revised DocRED dataset Re-DocRED. We conduct extensive experiments with state-of-the-art neural models on both datasets, and the experimental results show that the models trained and evaluated on our Re-DocRED achieve performance improvements of around 13 F1 points. Moreover, we conduct a comprehensive analysis to identify the potential areas for further improvement. Our dataset is publicly available at https://github.
&lt;/p&gt;</description></item></channel></rss>