<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;THUIR2&#22242;&#38431;&#22312;NTCIR-16 Session&#25628;&#32034;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#20182;&#20204;&#22312;FOSS&#21644;POSS&#23376;&#20219;&#21153;&#20013;&#20351;&#29992;&#20102;&#23398;&#20064;&#25490;&#24207;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#21462;&#24471;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.00250</link><description>&lt;p&gt;
THUIR2&#22312;NTCIR-16 Session&#25628;&#32034;&#65288;SS&#65289;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
THUIR2 at NTCIR-16 Session Search (SS) Task. (arXiv:2307.00250v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;THUIR2&#22242;&#38431;&#22312;NTCIR-16 Session&#25628;&#32034;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#20182;&#20204;&#22312;FOSS&#21644;POSS&#23376;&#20219;&#21153;&#20013;&#20351;&#29992;&#20102;&#23398;&#20064;&#25490;&#24207;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#21462;&#24471;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#22242;&#38431;&#65288;THUIR2&#65289;&#21442;&#21152;&#20102;NTCIR-16 Session&#25628;&#32034;&#65288;SS&#65289;&#20219;&#21153;&#30340;FOSS&#21644;POSS&#23376;&#20219;&#21153;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21644;&#32467;&#26524;&#12290;&#22312;FOSS&#23376;&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#23398;&#20064;&#25490;&#24207;&#21644;&#31934;&#32454;&#35843;&#25972;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#25552;&#20132;&#20102;&#20116;&#20010;&#36816;&#34892;&#12290;&#25105;&#20204;&#20351;&#29992;&#33258;&#36866;&#24212;&#25968;&#25454;&#21644;&#20250;&#35805;&#20449;&#24687;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#31934;&#32454;&#35843;&#25972;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#32452;&#35013;&#36215;&#26469;&#12290;&#32452;&#35013;&#30340;&#27169;&#22411;&#22312;&#21021;&#27493;&#35780;&#20272;&#20013;&#22312;&#25152;&#26377;&#21442;&#19982;&#32773;&#20013;&#21462;&#24471;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;&#22312;POSS&#23376;&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#32452;&#35013;&#30340;&#27169;&#22411;&#65292;&#22312;&#21021;&#27493;&#35780;&#20272;&#20013;&#20063;&#21462;&#24471;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our team(THUIR2) participated in both FOSS and POSS subtasks of the NTCIR-161 Session Search (SS) Task. This paper describes our approaches and results. In the FOSS subtask, we submit five runs using learning-to-rank and fine-tuned pre-trained language models. We fine-tuned the pre-trained language model with ad-hoc data and session information and assembled them by a learning-to-rank method. The assembled model achieves the best performance among all participants in the preliminary evaluation. In the POSS subtask, we used an assembled model which also achieves the best performance in the preliminary evaluation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21453;&#20107;&#23454;&#21327;&#21516;&#25512;&#29702;&#65288;CCR&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#21453;&#20107;&#23454;&#25512;&#29702;&#21644;&#36923;&#36753;&#25512;&#29702;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#21453;&#20107;&#23454;&#25512;&#29702;&#29983;&#25104;&#22256;&#38590;&#30340;&#21453;&#20107;&#23454;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;CCR&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#23637;&#31034;&#20102;&#22914;&#20309;&#32531;&#35299;&#25968;&#25454;&#31232;&#32570;&#12289;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#22686;&#24378;&#36879;&#26126;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.00165</link><description>&lt;p&gt;
&#21453;&#20107;&#23454;&#21327;&#21516;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Collaborative Reasoning. (arXiv:2307.00165v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21453;&#20107;&#23454;&#21327;&#21516;&#25512;&#29702;&#65288;CCR&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#21453;&#20107;&#23454;&#25512;&#29702;&#21644;&#36923;&#36753;&#25512;&#29702;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#21453;&#20107;&#23454;&#25512;&#29702;&#29983;&#25104;&#22256;&#38590;&#30340;&#21453;&#20107;&#23454;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;CCR&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#23637;&#31034;&#20102;&#22914;&#20309;&#32531;&#35299;&#25968;&#25454;&#31232;&#32570;&#12289;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#22686;&#24378;&#36879;&#26126;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#29702;&#21644;&#36923;&#36753;&#25512;&#29702;&#26159;&#20154;&#31867;&#26234;&#33021;&#30340;&#20004;&#31181;&#37325;&#35201;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#26426;&#22120;&#26234;&#33021;&#32972;&#26223;&#19979;&#65292;&#23427;&#20204;&#30340;&#20851;&#31995;&#36824;&#26410;&#24471;&#21040;&#24191;&#27867;&#25506;&#32034;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#20849;&#21516;&#24314;&#27169;&#36825;&#20004;&#31181;&#25512;&#29702;&#33021;&#21147;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#25972;&#21512;&#21453;&#20107;&#23454;&#25512;&#29702;&#21644;&#65288;&#31070;&#32463;&#65289;&#36923;&#36753;&#25512;&#29702;&#20004;&#31181;&#37325;&#35201;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21453;&#20107;&#23454;&#21327;&#21516;&#25512;&#29702;&#65288;CCR&#65289;&#65292;&#23427;&#36890;&#36807;&#36827;&#34892;&#21453;&#20107;&#23454;&#36923;&#36753;&#25512;&#29702;&#26469;&#25913;&#36827;&#24615;&#33021;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20197;&#25512;&#33616;&#31995;&#32479;&#20026;&#20363;&#65292;&#23637;&#31034;&#20102;CCR&#22914;&#20309;&#32531;&#35299;&#25968;&#25454;&#31232;&#32570;&#12289;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#22686;&#24378;&#36879;&#26126;&#24230;&#12290;&#20174;&#25216;&#26415;&#19978;&#35762;&#65292;&#25105;&#20204;&#21033;&#29992;&#21453;&#20107;&#23454;&#25512;&#29702;&#26469;&#29983;&#25104;&#8220;&#22256;&#38590;&#8221;&#30340;&#21453;&#20107;&#23454;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;&#36825;&#19982;&#21407;&#22987;&#30340;&#35757;&#32451;&#26679;&#26412;&#19968;&#36215;&#21487;&#20197;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal reasoning and logical reasoning are two important types of reasoning abilities for human intelligence. However, their relationship has not been extensively explored under machine intelligence context. In this paper, we explore how the two reasoning abilities can be jointly modeled to enhance both accuracy and explainability of machine learning models. More specifically, by integrating two important types of reasoning ability -- counterfactual reasoning and (neural) logical reasoning -- we propose Counterfactual Collaborative Reasoning (CCR), which conducts counterfactual logic reasoning to improve the performance. In particular, we use recommender system as an example to show how CCR alleviate data scarcity, improve accuracy and enhance transparency. Technically, we leverage counterfactual reasoning to generate "difficult" counterfactual training examples for data augmentation, which -together with the original training examples -- can enhance the model performance. Since the 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#27169;&#24577;&#39046;&#22495;&#33258;&#36866;&#24212;&#25216;&#26415;&#23454;&#29616;&#36328;&#39046;&#22495;&#25512;&#33616;&#31995;&#32479;&#65292;&#35299;&#20915;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#65292;&#25552;&#21319;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.13887</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#27169;&#24577;&#39046;&#22495;&#33258;&#36866;&#24212;&#23454;&#29616;&#36328;&#39046;&#22495;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Cross-domain Recommender Systems via Multimodal Domain Adaptation. (arXiv:2306.13887v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13887
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#27169;&#24577;&#39046;&#22495;&#33258;&#36866;&#24212;&#25216;&#26415;&#23454;&#29616;&#36328;&#39046;&#22495;&#25512;&#33616;&#31995;&#32479;&#65292;&#35299;&#20915;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#65292;&#25552;&#21319;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#24050;&#25104;&#20026;&#25512;&#33616;&#31995;&#32479;&#26368;&#37325;&#35201;&#30340;&#23454;&#29616;&#31574;&#30053;&#20043;&#19968;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#21033;&#29992;&#20010;&#20154;&#20351;&#29992;&#27169;&#24335;&#29983;&#25104;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#23588;&#20854;&#26159;&#23545;&#20110;&#26032;&#25512;&#20986;&#30340;&#24179;&#21488;&#65292;CF&#25216;&#26415;&#24120;&#24120;&#38754;&#20020;&#25968;&#25454;&#31232;&#30095;&#24615;&#30340;&#38382;&#39064;&#65292;&#36825;&#26497;&#22823;&#22320;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;&#22312;&#35299;&#20915;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#26041;&#38754;&#65292;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#20960;&#31181;&#26041;&#27861;&#65292;&#20854;&#20013;&#36328;&#39046;&#22495;&#21327;&#21516;&#36807;&#28388;&#65288;CDCF&#65289;&#22312;&#26368;&#36817;&#21463;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#34917;&#20607;&#30446;&#26631;&#39046;&#22495;&#20013;&#21487;&#29992;&#21453;&#39304;&#30340;&#19981;&#36275;&#65292;CDCF&#26041;&#27861;&#21033;&#29992;&#20854;&#20182;&#36741;&#21161;&#39046;&#22495;&#20013;&#30340;&#20449;&#24687;&#12290;&#22823;&#22810;&#25968;&#20256;&#32479;&#30340;CDCF&#26041;&#27861;&#30340;&#30446;&#26631;&#26159;&#22312;&#39046;&#22495;&#20043;&#38388;&#25214;&#21040;&#19968;&#32452;&#20849;&#21516;&#30340;&#23454;&#20307;&#65288;&#29992;&#25143;&#25110;&#39033;&#30446;&#65289;&#65292;&#28982;&#21518;&#23558;&#23427;&#20204;&#29992;&#20316;&#30693;&#35782;&#36716;&#31227;&#30340;&#26725;&#26753;&#12290;&#20294;&#26159;&#65292;&#22823;&#22810;&#25968;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#26159;&#20174;&#19981;&#21516;&#30340;&#39046;&#22495;&#25910;&#38598;&#30340;&#65292;&#36825;&#20351;&#24471;&#36328;&#39046;&#22495;&#21327;&#21516;&#36807;&#28388;&#26356;&#21152;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative Filtering (CF) has emerged as one of the most prominent implementation strategies for building recommender systems. The key idea is to exploit the usage patterns of individuals to generate personalized recommendations. CF techniques, especially for newly launched platforms, often face a critical issue known as the data sparsity problem, which greatly limits their performance. Several approaches have been proposed in the literature to tackle the problem of data sparsity, among which cross-domain collaborative filtering (CDCF) has gained significant attention in the recent past. In order to compensate for the scarcity of available feedback in a target domain, the CDCF approach makes use of information available in other auxiliary domains. Most of the traditional CDCF approach aim is to find a common set of entities (users or items) across the domains and then use them as a bridge for knowledge transfer. However, most real-world datasets are collected from different domains,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#21160;&#35821;&#20041;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#26681;&#25454;&#26053;&#23458;&#30340;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#65292;&#23454;&#39564;&#20013;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10946</link><description>&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network. (arXiv:2306.10946v1 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#21160;&#35821;&#20041;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#26681;&#25454;&#26053;&#23458;&#30340;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#65292;&#23454;&#39564;&#20013;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#25512;&#33616;&#31639;&#27861;&#22312;&#30456;&#23545;&#25104;&#29087;&#38454;&#27573;&#65292;&#20294;&#22312;&#29305;&#23450;&#39046;&#22495;&#30340;&#25512;&#33616;&#20173;&#23384;&#22312;&#38382;&#39064;&#12290;&#20363;&#22914;&#22312;&#26053;&#28216;&#39046;&#22495;&#65292;&#36873;&#25321;&#36866;&#21512;&#30340;&#26053;&#28216;&#26223;&#28857;&#23646;&#24615;&#27969;&#31243;&#20316;&#20026;&#25512;&#33616;&#22522;&#30784;&#36739;&#20026;&#22797;&#26434;&#12290;&#26412;&#25991;&#25552;&#20986;&#25913;&#36827;&#30340;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#27169;&#22411;(Att-KGCN)&#65292;&#33258;&#21160;&#35821;&#20041;&#22320;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#23618;&#23558;&#30456;&#23545;&#30456;&#20284;&#30340;&#20301;&#32622;&#36827;&#34892;&#32858;&#21512;&#65292;&#24182;&#36890;&#36807;&#25512;&#29702;&#26053;&#23458;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#12290;&#23454;&#39564;&#20013;&#65292;&#37319;&#29992;&#32034;&#31185;&#29305;&#25289;&#23707;-&#20063;&#38376;&#30340;&#26053;&#28216;&#25968;&#25454;&#65292;&#35777;&#26126;&#20102;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#26053;&#28216;&#39046;&#22495;&#30340;&#26223;&#28857;&#25512;&#33616;&#25928;&#26524;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recommendation algorithm based on knowledge graphs is at a relatively mature stage. However, there are still some problems in the recommendation of specific areas. For example, in the tourism field, selecting suitable tourist attraction attributes process is complicated as the recommendation basis for tourist attractions. In this paper, we propose the improved Attention Knowledge Graph Convolution Network model, named (Att-KGCN), which automatically discovers the neighboring entities of the target scenic spot semantically. The attention layer aggregates relatively similar locations and represents them with an adjacent vector. Then, according to the tourist's preferred choices, the model predicts the probability of similar spots as a recommendation system. A knowledge graph dataset of tourist attractions used based on tourism data on Socotra Island-Yemen. Through experiments, it is verified that the Attention Knowledge Graph Convolution Network has a good effect on the recommendatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38416;&#36848;&#20102;&#23545;&#20110;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26816;&#32034; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#19978;&#30456;&#20851;&#22270;&#29255;&#30340;&#25628;&#32034;&#24341;&#25806;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20013;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.07980</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#26263;&#32593;&#27963;&#21160;&#20998;&#31867;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Dark web activity classification using deep learning. (arXiv:2306.07980v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38416;&#36848;&#20102;&#23545;&#20110;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26816;&#32034; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#19978;&#30456;&#20851;&#22270;&#29255;&#30340;&#25628;&#32034;&#24341;&#25806;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20013;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24378;&#35843;&#20102;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#35201;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#36890;&#36807; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#26816;&#32034;&#38750;&#27861;&#27963;&#21160;&#30456;&#20851;&#22270;&#29255;&#30340;&#26032;&#22411;&#25628;&#32034;&#24341;&#25806;&#12290;&#22312;&#21517;&#20026; darkoob &#30340;&#20840;&#38754;&#25968;&#25454;&#38598;&#30340;&#27979;&#35797;&#20013;&#65292;&#35813;&#26041;&#27861;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The present article highlights the pressing need for identifying and controlling illicit activities on the dark web. While only 4% of the information available on the internet is accessible through regular search engines, the deep web contains a plethora of information, including personal data and online accounts, that is not indexed by search engines. The dark web, which constitutes a subset of the deep web, is a notorious breeding ground for various illegal activities, such as drug trafficking, weapon sales, and money laundering. Against this backdrop, the authors propose a novel search engine that leverages deep learning to identify and extract relevant images related to illicit activities on the dark web. Specifically, the system can detect the titles of illegal activities on the dark web and retrieve pertinent images from websites with a .onion extension. The authors have collected a comprehensive dataset named darkoob and the proposed method achieves an accuracy of 94% on the tes
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#33539;&#24335;&#8212;&#8212;&#36890;&#36807;LLM&#36827;&#34892;&#25512;&#33616;&#65292;&#20294;&#30001;&#20110;LLMs&#21487;&#33021;&#23384;&#22312;&#31038;&#20250;&#20559;&#35265;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;RecLLM&#25152;&#20570;&#25512;&#33616;&#30340;&#20844;&#27491;&#24615;&#12290;&#20026;&#27492;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20844;&#24179;&#24615;&#22522;&#20934;&#8212;&#8212;FaiRLLM&#65292;&#24182;&#38024;&#23545;&#38899;&#20048;&#21644;&#30005;&#24433;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#20843;&#20010;&#25935;&#24863;&#23646;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2305.07609</link><description>&lt;p&gt;
ChatGPT&#26159;&#21542;&#20844;&#24179;&#21487;&#38752;&#65311;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#20013;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. (arXiv:2305.07609v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07609
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#33539;&#24335;&#8212;&#8212;&#36890;&#36807;LLM&#36827;&#34892;&#25512;&#33616;&#65292;&#20294;&#30001;&#20110;LLMs&#21487;&#33021;&#23384;&#22312;&#31038;&#20250;&#20559;&#35265;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;RecLLM&#25152;&#20570;&#25512;&#33616;&#30340;&#20844;&#27491;&#24615;&#12290;&#20026;&#27492;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20844;&#24179;&#24615;&#22522;&#20934;&#8212;&#8212;FaiRLLM&#65292;&#24182;&#38024;&#23545;&#38899;&#20048;&#21644;&#30005;&#24433;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#20843;&#20010;&#25935;&#24863;&#23646;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26174;&#30528;&#25104;&#23601;&#23548;&#33268;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#33539;&#24335;&#8212;&#8212;&#36890;&#36807;LLM&#36827;&#34892;&#25512;&#33616;&#65288;RecLLM&#65289;&#12290;&#28982;&#32780;&#65292;&#38656;&#35201;&#27880;&#24847;LLMs&#21487;&#33021;&#21253;&#21547;&#31038;&#20250;&#20559;&#35265;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;RecLLM&#25152;&#20570;&#25512;&#33616;&#30340;&#20844;&#27491;&#24615;&#12290;&#20026;&#20102;&#36991;&#20813;RecLLM&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#26377;&#24517;&#35201;&#20174;&#29992;&#25143;&#30340;&#21508;&#31181;&#25935;&#24863;&#23646;&#24615;&#35282;&#24230;&#35780;&#20272;RecLLM&#30340;&#20844;&#24179;&#24615;&#12290;&#30001;&#20110;RecLLM&#33539;&#24335;&#19982;&#20256;&#32479;&#25512;&#33616;&#33539;&#24335;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#65292;&#22240;&#27492;&#30452;&#25509;&#20351;&#29992;&#20256;&#32479;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#22522;&#20934;&#26159;&#26377;&#38382;&#39064;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#22256;&#22659;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#65292;&#31216;&#20026;&#8220;&#36890;&#36807;LLM&#30340;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#8221;&#65288;FaiRLLM&#65289;&#12290;&#35813;&#22522;&#20934;&#21253;&#25324;&#31934;&#24515;&#35774;&#35745;&#30340;&#25351;&#26631;&#21644;&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20004;&#20010;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#20843;&#20010;&#25935;&#24863;&#23646;&#24615;&#65306;&#38899;&#20048;&#21644;&#30005;&#24433;&#12290;&#36890;&#36807;&#21033;&#29992;&#25105;&#20204;&#30340;FaiRLLM&#22522;&#20934;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable achievements of Large Language Models (LLMs) have led to the emergence of a novel recommendation paradigm -- Recommendation via LLM (RecLLM). Nevertheless, it is important to note that LLMs may contain social prejudices, and therefore, the fairness of recommendations made by RecLLM requires further investigation. To avoid the potential risks of RecLLM, it is imperative to evaluate the fairness of RecLLM with respect to various sensitive attributes on the user side. Due to the differences between the RecLLM paradigm and the traditional recommendation paradigm, it is problematic to directly use the fairness benchmark of traditional recommendation. To address the dilemma, we propose a novel benchmark called Fairness of Recommendation via LLM (FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset that accounts for eight sensitive attributes1 in two recommendation scenarios: music and movies. By utilizing our FaiRLLM benchmark, we conducted an evaluation 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.06569</link><description>&lt;p&gt;
&#22914;&#20309;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#32034;&#24341;&#39033;&#30446;ID
&lt;/p&gt;
&lt;p&gt;
How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#23558;&#25512;&#33616;&#20219;&#21153;&#36716;&#25442;&#20026;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#25512;&#33616;&#12290;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#24314;&#35758;&#30340;&#39033;&#30446;&#32780;&#19981;&#26159;&#35745;&#31639;&#20256;&#32479;&#25512;&#33616;&#27169;&#22411;&#20013;&#27599;&#20010;&#20505;&#36873;&#39033;&#30446;&#30340;&#25490;&#21517;&#24471;&#20998;&#65292;&#31616;&#21270;&#20102;&#25512;&#33616;&#31649;&#36947;&#65292;&#36991;&#20813;&#20102;&#22810;&#27573;&#36807;&#28388;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#20915;&#23450;&#35201;&#25512;&#33616;&#21738;&#20123;&#39033;&#30446;&#26102;&#29983;&#25104;&#36807;&#38271;&#30340;&#25991;&#26412;&#65292;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#21019;&#24314;LLM&#20860;&#23481;&#30340;&#39033;&#30446;ID&#26159;&#24517;&#35201;&#30340;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#65292;&#20197;P5&#20026;&#20195;&#34920;&#30340;&#20027;&#24178;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32034;&#24341;&#26041;&#27861;&#22797;&#21046;&#20854;&#32467;&#26524;&#12290;&#25105;&#20204;&#39318;&#20808;&#35752;&#35770;&#20102;&#20960;&#31181;&#24494;&#19981;&#36275;&#36947;&#30340;&#39033;&#30446;&#32034;&#24341;&#26041;&#27861;&#65288;&#22914;&#29420;&#31435;&#32034;&#24341;&#12289;&#26631;&#39064;&#32034;&#24341;&#21644;&#38543;&#26426;&#32034;&#24341;&#65289;&#30340;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#19981;&#36866;&#29992;&#20110;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32034;&#24341;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#31181;&#32034;&#24341;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#32034;&#24341;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
&lt;/p&gt;</description></item><item><title>TALLRec&#26159;&#23545;LLMs&#36827;&#34892;&#35843;&#25972;&#30340;&#19968;&#31181;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;LLMs&#19982;&#25512;&#33616;&#31995;&#32479;&#23545;&#40784;&#65292;&#20174;&#32780;&#22686;&#24378;LLMs&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.00447</link><description>&lt;p&gt;
TALLRec: &#19968;&#31181;&#19982;&#25512;&#33616;&#31995;&#32479;&#23545;&#40784;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26377;&#25928;&#19988;&#39640;&#25928;&#30340;&#35843;&#25972;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation. (arXiv:2305.00447v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00447
&lt;/p&gt;
&lt;p&gt;
TALLRec&#26159;&#23545;LLMs&#36827;&#34892;&#35843;&#25972;&#30340;&#19968;&#31181;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;LLMs&#19982;&#25512;&#33616;&#31995;&#32479;&#23545;&#40784;&#65292;&#20174;&#32780;&#22686;&#24378;LLMs&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#23637;&#29616;&#20102;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#26174;&#33879;&#24615;&#33021;&#65292;&#22240;&#27492;&#30740;&#31350;&#20154;&#21592;&#24320;&#22987;&#25506;&#32034;&#23427;&#20204;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#28508;&#21147;&#12290;&#34429;&#28982;&#21021;&#22987;&#30340;&#23581;&#35797;&#24050;&#32463;&#21033;&#29992;&#20102;LLMs&#30340;&#20248;&#24322;&#33021;&#21147;&#65292;&#27604;&#22914;&#36890;&#36807;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#25552;&#31034;&#35789;&#26469;&#20016;&#23500;&#30693;&#35782;&#24182;&#36827;&#34892;&#24378;&#21270;&#27867;&#21270;&#65292;&#20294;&#26159;&#30001;&#20110;LLMs&#30340;&#35757;&#32451;&#20219;&#21153;&#19982;&#25512;&#33616;&#20219;&#21153;&#20043;&#38388;&#30340;&#24040;&#22823;&#24046;&#24322;&#20197;&#21450;&#39044;&#35757;&#32451;&#26399;&#38388;&#30340;&#19981;&#36275;&#30340;&#25512;&#33616;&#25968;&#25454;&#65292;LLMs&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#20173;&#28982;&#19981;&#29702;&#24819;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#25512;&#33616;&#25968;&#25454;&#23545;LLMs&#36827;&#34892;&#35843;&#25972;&#26469;&#26500;&#24314;&#22823;&#22411;&#25512;&#33616;&#35821;&#35328;&#27169;&#22411;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TALLRec&#30340;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#35843;&#25972;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;LLMs&#19982;&#25512;&#33616;&#31995;&#32479;&#23545;&#40784;&#12290;&#25105;&#20204;&#24050;&#32463;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;TALLRec&#26694;&#26550;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;LLMs&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains, thereby prompting researchers to explore their potential for use in recommendation systems. Initial attempts have leveraged the exceptional capabilities of LLMs, such as rich knowledge and strong generalization through In-context Learning, which involves phrasing the recommendation task as prompts. Nevertheless, the performance of LLMs in recommendation tasks remains suboptimal due to a substantial disparity between the training tasks for LLMs and recommendation tasks, as well as inadequate recommendation data during pre-training. To bridge the gap, we consider building a Large Recommendation Language Model by tunning LLMs with recommendation data. To this end, we propose an efficient and effective Tuning framework for Aligning LLMs with Recommendation, namely TALLRec. We have demonstrated that the proposed TALLRec framework can significantly enhance the recommendation capabilities of LLMs in 
&lt;/p&gt;</description></item><item><title>MOJITO&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;Transformer&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#28151;&#21512;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#21644;&#26102;&#38388;&#32972;&#26223;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#65292;&#20174;&#32780;&#20934;&#30830;&#39044;&#27979;&#19979;&#19968;&#20010;&#25512;&#33616;&#29289;&#21697;&#12290;&#22312;&#22810;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#65292;MOJITO&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#30340;Transformer&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2304.08158</link><description>&lt;p&gt;
&#26102;&#38388;&#24863;&#30693;&#39034;&#24207;&#25512;&#33616;&#20013;&#30340;&#27880;&#24847;&#21147;&#28151;&#21512;
&lt;/p&gt;
&lt;p&gt;
Attention Mixtures for Time-Aware Sequential Recommendation. (arXiv:2304.08158v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08158
&lt;/p&gt;
&lt;p&gt;
MOJITO&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;Transformer&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#28151;&#21512;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#21644;&#26102;&#38388;&#32972;&#26223;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#65292;&#20174;&#32780;&#20934;&#30830;&#39044;&#27979;&#19979;&#19968;&#20010;&#25512;&#33616;&#29289;&#21697;&#12290;&#22312;&#22810;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#65292;MOJITO&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#30340;Transformer&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#27169;&#22411;&#22312;&#39034;&#24207;&#25512;&#33616;&#20013;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26550;&#26500;&#32463;&#24120;&#24573;&#35270;&#29992;&#25143;&#20559;&#22909;&#21644;&#26102;&#38388;&#32972;&#26223;&#20043;&#38388;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#12290;&#22312;&#26412;&#31687;&#30701;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;MOJITO&#65292;&#19968;&#31181;&#25913;&#36827;&#30340;Transformer&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65292;&#23427;&#35299;&#20915;&#20102;&#36825;&#20010;&#23616;&#38480;&#24615;&#12290;MOJITO&#21033;&#29992;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#26102;&#38388;&#32972;&#26223;&#21644;&#29289;&#21697;&#23884;&#20837;&#34920;&#31034;&#30340;&#39640;&#26031;&#28151;&#21512;&#36827;&#34892;&#39034;&#24207;&#24314;&#27169;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#39044;&#27979;&#19979;&#19968;&#20010;&#24212;&#35813;&#21521;&#29992;&#25143;&#25512;&#33616;&#21738;&#20123;&#29289;&#21697;&#65292;&#36825;&#21462;&#20915;&#20110;&#36807;&#21435;&#30340;&#34892;&#20026;&#21644;&#26102;&#38388;&#32972;&#26223;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#35777;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#30456;&#20851;&#24615;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;Transformer&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers emerged as powerful methods for sequential recommendation. However, existing architectures often overlook the complex dependencies between user preferences and the temporal context. In this short paper, we introduce MOJITO, an improved Transformer sequential recommender system that addresses this limitation. MOJITO leverages Gaussian mixtures of attention-based temporal context and item embedding representations for sequential modeling. Such an approach permits to accurately predict which items should be recommended next to users depending on past actions and the temporal context. We demonstrate the relevance of our approach, by empirically outperforming existing Transformers for sequential recommendation on several real-world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20197;&#23458;&#25143;&#20026;&#20013;&#24515;&#30340;&#33829;&#38144;&#27963;&#21160;&#20013;&#23547;&#25214;&#30456;&#20284;&#23458;&#25143;&#30340;&#21487;&#25193;&#23637;&#21644;&#39640;&#25928;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#33021;&#22788;&#29702;&#20159;&#32423;&#23458;&#25143;&#65292;&#24182;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#23884;&#20837;&#27169;&#22411;&#21644;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26041;&#27861;&#26469;&#23547;&#25214;&#24863;&#20852;&#36259;&#30340;&#30456;&#20284;&#23458;&#25143;&#12290;&#36890;&#36807;&#26500;&#24314;&#21487;&#35299;&#37322;&#19988;&#26377;&#24847;&#20041;&#30340;&#23458;&#25143;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#21508;&#31181;&#19994;&#21153;&#20852;&#36259;&#12290;</title><link>http://arxiv.org/abs/2301.03147</link><description>&lt;p&gt;
&#23547;&#25214;&#30005;&#23376;&#21830;&#21153;&#33829;&#38144;&#30340;&#30456;&#20284;&#23458;&#25143;
&lt;/p&gt;
&lt;p&gt;
Finding Lookalike Customers for E-Commerce Marketing. (arXiv:2301.03147v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.03147
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20197;&#23458;&#25143;&#20026;&#20013;&#24515;&#30340;&#33829;&#38144;&#27963;&#21160;&#20013;&#23547;&#25214;&#30456;&#20284;&#23458;&#25143;&#30340;&#21487;&#25193;&#23637;&#21644;&#39640;&#25928;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#33021;&#22788;&#29702;&#20159;&#32423;&#23458;&#25143;&#65292;&#24182;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#23884;&#20837;&#27169;&#22411;&#21644;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26041;&#27861;&#26469;&#23547;&#25214;&#24863;&#20852;&#36259;&#30340;&#30456;&#20284;&#23458;&#25143;&#12290;&#36890;&#36807;&#26500;&#24314;&#21487;&#35299;&#37322;&#19988;&#26377;&#24847;&#20041;&#30340;&#23458;&#25143;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#21508;&#31181;&#19994;&#21153;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#23458;&#25143;&#20026;&#20013;&#24515;&#30340;&#33829;&#38144;&#27963;&#21160;&#20026;&#27779;&#23572;&#29595;&#30340;&#30005;&#23376;&#21830;&#21153;&#32593;&#31449;&#27969;&#37327;&#36129;&#29486;&#20102;&#24456;&#22823;&#30340;&#19968;&#37096;&#20998;&#12290;&#38543;&#30528;&#23458;&#25143;&#25968;&#25454;&#35268;&#27169;&#30340;&#22686;&#22823;&#65292;&#25193;&#22823;&#33829;&#38144;&#21463;&#20247;&#20197;&#35302;&#36798;&#26356;&#22810;&#23458;&#25143;&#23545;&#30005;&#23376;&#21830;&#21153;&#20844;&#21496;&#30340;&#19994;&#21153;&#22686;&#38271;&#21644;&#20026;&#23458;&#25143;&#24102;&#26469;&#26356;&#22810;&#20215;&#20540;&#21464;&#24471;&#26356;&#20026;&#20851;&#38190;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#19988;&#39640;&#25928;&#30340;&#31995;&#32479;&#26469;&#25193;&#22823;&#33829;&#38144;&#27963;&#21160;&#30340;&#30446;&#26631;&#21463;&#20247;&#65292;&#35813;&#31995;&#32479;&#21487;&#20197;&#22788;&#29702;&#20159;&#32423;&#23458;&#25143;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#23884;&#20837;&#27169;&#22411;&#26469;&#34920;&#31034;&#23458;&#25143;&#65292;&#20351;&#29992;&#19968;&#31181;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26041;&#27861;&#24555;&#36895;&#25214;&#21040;&#24863;&#20852;&#36259;&#30340;&#30456;&#20284;&#23458;&#25143;&#12290;&#35813;&#27169;&#22411;&#33021;&#22815;&#36890;&#36807;&#26500;&#24314;&#21487;&#35299;&#37322;&#19988;&#26377;&#24847;&#20041;&#30340;&#23458;&#25143;&#30456;&#20284;&#24230;&#24230;&#37327;&#26469;&#22788;&#29702;&#21508;&#31181;&#19994;&#21153;&#20852;&#36259;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#26469;&#23637;&#31034;&#25105;&#20204;&#30340;&#31995;&#32479;&#21644;&#23458;&#25143;&#23884;&#20837;&#27169;&#22411;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Customer-centric marketing campaigns generate a large portion of e-commerce website traffic for Walmart. As the scale of customer data grows larger, expanding the marketing audience to reach more customers is becoming more critical for e-commerce companies to drive business growth and bring more value to customers. In this paper, we present a scalable and efficient system to expand targeted audience of marketing campaigns, which can handle hundreds of millions of customers. We use a deep learning based embedding model to represent customers and an approximate nearest neighbor search method to quickly find lookalike customers of interest. The model can deal with various business interests by constructing interpretable and meaningful customer similarity metrics. We conduct extensive experiments to demonstrate the great performance of our system and customer embedding model.
&lt;/p&gt;</description></item><item><title>&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#20026;&#22312;&#32447;&#24191;&#21578;&#39046;&#22495;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#20197;&#24212;&#23545;&#20256;&#32479;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2209.15635</link><description>&lt;p&gt;
&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#29992;&#20110;&#39640;&#25928;&#22312;&#32447;&#24191;&#21578;
&lt;/p&gt;
&lt;p&gt;
Vertical Semi-Federated Learning for Efficient Online Advertising. (arXiv:2209.15635v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15635
&lt;/p&gt;
&lt;p&gt;
&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#20026;&#22312;&#32447;&#24191;&#21578;&#39046;&#22495;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#20197;&#24212;&#23545;&#20256;&#32479;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26550;&#26500;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;1&#65289;&#36866;&#29992;&#33539;&#22260;&#21463;&#38480;&#20110;&#37325;&#21472;&#26679;&#26412;&#65307;2&#65289;&#23454;&#26102;&#32852;&#21512;&#26381;&#21153;&#30340;&#31995;&#32479;&#25361;&#25112;&#36739;&#39640;&#65292;&#36825;&#38480;&#21046;&#20102;&#20854;&#22312;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#35774;&#32622;&#8212;&#8212;&#21322;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;(Semi-VFL)&#65292;&#20197;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#12290;&#21322;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26088;&#22312;&#23454;&#29616;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#23454;&#38469;&#24037;&#19994;&#24212;&#29992;&#26041;&#24335;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#34920;&#29616;&#20248;&#20110;&#21333;&#26041;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#23616;&#37096;&#26381;&#21153;&#30340;&#20415;&#21033;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31934;&#24515;&#35774;&#35745;&#30340;&#32852;&#21512;&#29305;&#26435;&#23398;&#20064;&#26694;&#26550;(JPL)&#65292;&#26469;&#35299;&#20915;&#34987;&#21160;&#26041;&#29305;&#24449;&#32570;&#22833;&#21644;&#36866;&#24212;&#25972;&#20010;&#26679;&#26412;&#31354;&#38388;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#25512;&#29702;&#39640;&#25928;&#30340;&#36866;&#29992;&#20110;&#25972;&#20010;&#26679;&#26412;&#31354;&#38388;&#30340;&#21333;&#26041;&#23398;&#29983;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#32852;&#21512;&#29305;&#24449;&#25193;&#23637;&#30340;&#20248;&#21183;&#12290;&#26032;&#30340;&#34920;&#31034;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
The traditional vertical federated learning schema suffers from two main issues: 1) restricted applicable scope to overlapped samples and 2) high system challenge of real-time federated serving, which limits its application to advertising systems. To this end, we advocate a new learning setting Semi-VFL (Vertical Semi-Federated Learning) to tackle these challenge. Semi-VFL is proposed to achieve a practical industry application fashion for VFL, by learning a federation-aware local model which performs better than single-party models and meanwhile maintain the convenience of local-serving. For this purpose, we propose the carefully designed Joint Privileged Learning framework (JPL) to i) alleviate the absence of the passive party's feature and ii) adapt to the whole sample space. Specifically, we build an inference-efficient single-party student model applicable to the whole sample space and meanwhile maintain the advantage of the federated feature extension. New representation distilla
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#28385;&#36275;&#25237;&#25918;&#25104;&#26412;&#22238;&#25253;&#29575;&#38480;&#21046;&#30340;&#24191;&#21578;&#21830;&#30340;&#22312;&#32447;&#31454;&#20215;&#31639;&#27861;&#65292;&#36890;&#36807;&#31616;&#20415;&#30340;&#22312;&#32447;&#31639;&#27861;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#20540;&#65292;&#24182;&#19988;&#24635;&#32467;&#20102;&#19982;&#20808;&#21069;&#24037;&#20316;&#30340;&#38598;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2208.13713</link><description>&lt;p&gt;
&#38754;&#21521;&#25910;&#30410;&#38480;&#21046;&#24191;&#21578;&#21830;&#30340;&#22312;&#32447;&#31454;&#20215;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Bidding Algorithms for Return-on-Spend Constrained Advertisers. (arXiv:2208.13713v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.13713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#28385;&#36275;&#25237;&#25918;&#25104;&#26412;&#22238;&#25253;&#29575;&#38480;&#21046;&#30340;&#24191;&#21578;&#21830;&#30340;&#22312;&#32447;&#31454;&#20215;&#31639;&#27861;&#65292;&#36890;&#36807;&#31616;&#20415;&#30340;&#22312;&#32447;&#31639;&#27861;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#20540;&#65292;&#24182;&#19988;&#24635;&#32467;&#20102;&#19982;&#20808;&#21069;&#24037;&#20316;&#30340;&#38598;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24191;&#21578;&#19994;&#36817;&#24180;&#26469;&#25104;&#38271;&#20026;&#19968;&#20010;&#31454;&#20105;&#28608;&#28872;&#19988;&#22797;&#26434;&#30340;&#25968;&#21313;&#20159;&#32654;&#20803;&#34892;&#19994;&#65292;&#24191;&#21578;&#21830;&#22312;&#22823;&#35268;&#27169;&#21644;&#39640;&#39057;&#29575;&#19979;&#36827;&#34892;&#24191;&#21578;&#20301;&#31454;&#20215;&#12290;&#36825;&#23548;&#33268;&#38656;&#27714;&#22686;&#21152;&#20102;&#23545;&#20110;&#39640;&#25928;&#30340;"&#33258;&#21160;&#31454;&#20215;"&#31639;&#27861;&#65292;&#20197;&#30830;&#23450;&#26368;&#22823;&#21270;&#24191;&#21578;&#21830;&#30446;&#26631;&#30340;&#25237;&#26631;&#20215;&#26684;&#65292;&#21516;&#26102;&#28385;&#36275;&#29305;&#23450;&#30340;&#38480;&#21046;&#26465;&#20214;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21333;&#20010;&#26368;&#22823;&#21270;&#20215;&#20540;&#24191;&#21578;&#21830;&#38754;&#20020;&#30340;&#36234;&#26469;&#36234;&#27969;&#34892;&#30340;&#38480;&#21046;&#26465;&#20214;&#20043;&#19968;&#65306;&#25237;&#25918;&#25104;&#26412;&#22238;&#25253;&#29575;&#65288;RoS&#65289;&#12290;&#25105;&#20204;&#20197;&#30456;&#23545;&#20110;&#30693;&#36947;&#25152;&#26377;&#26597;&#35810;&#30340;&#26368;&#20248;&#31639;&#27861;&#30340;&#36951;&#25022;&#20540;&#20026;&#34913;&#37327;&#26631;&#20934;&#26469;&#37327;&#21270;&#25928;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24403;&#26597;&#35810;&#24207;&#21015;&#26159;&#26469;&#33258;&#26576;&#20010;&#20998;&#24067;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#26102;&#65292;&#35813;&#31639;&#27861;&#22312;&#26399;&#26395;&#20540;&#19978;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#20540;&#65292;&#21516;&#26102;&#22987;&#32456;&#36981;&#23432;&#25351;&#23450;&#30340;RoS&#32422;&#26463;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#19982;Balseiro&#12289;Lu&#21644;Mirrokni [BLM20]&#30340;&#20808;&#21069;&#24037;&#20316;&#30456;&#32467;&#21512;&#65292;&#20197;&#22312;&#23562;&#37325;&#32422;&#26463;&#30340;&#21516;&#26102;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online advertising has recently grown into a highly competitive and complex multi-billion-dollar industry, with advertisers bidding for ad slots at large scales and high frequencies. This has resulted in a growing need for efficient "auto-bidding" algorithms that determine the bids for incoming queries to maximize advertisers' targets subject to their specified constraints. This work explores efficient online algorithms for a single value-maximizing advertiser under an increasingly popular constraint: Return-on-Spend (RoS). We quantify efficiency in terms of regret relative to the optimal algorithm, which knows all queries a priori.  We contribute a simple online algorithm that achieves near-optimal regret in expectation while always respecting the specified RoS constraint when the input sequence of queries are i.i.d. samples from some distribution. We also integrate our results with the previous work of Balseiro, Lu, and Mirrokni [BLM20] to achieve near-optimal regret while respecting
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#20998;&#24067;&#36716;&#31227;&#35270;&#35282;&#20986;&#21457;&#65292;&#30740;&#31350;&#20102;&#20174;&#20559;&#21521;&#21453;&#39304;&#20013;&#23398;&#20064;&#26080;&#20559;&#31639;&#27861;&#36827;&#34892;&#25512;&#33616;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#24314;&#31435;&#26080;&#20559;&#25512;&#33616;&#19982;&#20998;&#24067;&#36716;&#31227;&#30340;&#20851;&#31995;&#65292;&#23545;&#29616;&#26377;&#26080;&#20559;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#35299;&#37322;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#27867;&#21270;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2206.03851</link><description>&lt;p&gt;
&#22312;&#26080;&#20559;&#25512;&#33616;&#20013;&#37325;&#26032;&#32771;&#34385;&#23398;&#20064;&#30446;&#26631;&#65306;&#20998;&#24067;&#36716;&#31227;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective. (arXiv:2206.03851v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#20998;&#24067;&#36716;&#31227;&#35270;&#35282;&#20986;&#21457;&#65292;&#30740;&#31350;&#20102;&#20174;&#20559;&#21521;&#21453;&#39304;&#20013;&#23398;&#20064;&#26080;&#20559;&#31639;&#27861;&#36827;&#34892;&#25512;&#33616;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#24314;&#31435;&#26080;&#20559;&#25512;&#33616;&#19982;&#20998;&#24067;&#36716;&#31227;&#30340;&#20851;&#31995;&#65292;&#23545;&#29616;&#26377;&#26080;&#20559;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#35299;&#37322;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#27867;&#21270;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#20559;&#21521;&#21453;&#39304;&#20013;&#23398;&#20064;&#26080;&#20559;&#31639;&#27861;&#36827;&#34892;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#19968;&#20010;&#26032;&#39062;&#30340;&#20998;&#24067;&#36716;&#31227;&#35270;&#35282;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#26368;&#36817;&#22312;&#26080;&#20559;&#25512;&#33616;&#39046;&#22495;&#30340;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#21508;&#31181;&#25216;&#26415;&#22914;&#37325;&#26032;&#21152;&#26435;&#12289;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#20803;&#23398;&#20064;&#65292;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#25104;&#26524;&#12290;&#23613;&#31649;&#23427;&#20204;&#22312;&#23454;&#35777;&#19978;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22823;&#37096;&#20998;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#65292;&#23548;&#33268;&#20102;&#29702;&#35770;&#21644;&#26368;&#26032;&#31639;&#27861;&#20043;&#38388;&#30340;&#26174;&#33879;&#24046;&#36317;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#29616;&#26377;&#26080;&#20559;&#23398;&#20064;&#30446;&#26631;&#20026;&#20309;&#36866;&#29992;&#20110;&#26080;&#20559;&#25512;&#33616;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#26080;&#20559;&#25512;&#33616;&#19982;&#20998;&#24067;&#36716;&#31227;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#65292;&#26174;&#31034;&#20102;&#29616;&#26377;&#30340;&#26080;&#20559;&#23398;&#20064;&#30446;&#26631;&#38544;&#21547;&#22320;&#23558;&#26377;&#20559;&#30340;&#35757;&#32451;&#20998;&#24067;&#19982;&#26080;&#20559;&#30340;&#27979;&#35797;&#20998;&#24067;&#23545;&#40784;&#12290;&#22522;&#20110;&#36825;&#20010;&#20851;&#31995;&#65292;&#25105;&#20204;&#38024;&#23545;&#29616;&#26377;&#30340;&#26080;&#20559;&#23398;&#20064;&#26041;&#27861;&#21457;&#23637;&#20102;&#20004;&#20010;&#27867;&#21270;&#30028;&#38480;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#23398;&#20064;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies the problem of learning unbiased algorithms from biased feedback for recommendation. We address this problem from a novel distribution shift perspective. Recent works in unbiased recommendation have advanced the state-of-the-art with various techniques such as re-weighting, multi-task learning, and meta-learning. Despite their empirical successes, most of them lack theoretical guarantees, forming non-negligible gaps between theories and recent algorithms. In this paper, we propose a theoretical understanding of why existing unbiased learning objectives work for unbiased recommendation. We establish a close connection between unbiased recommendation and distribution shift, which shows that existing unbiased learning objectives implicitly align biased training and unbiased test distributions. Built upon this connection, we develop two generalization bounds for existing unbiased learning methods and analyze their learning behavior. Besides, as a result of the distributio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PromptRank&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#30340;&#22810;&#36339;&#36335;&#24452;&#20877;&#25490;&#21517;&#65292;&#23454;&#29616;&#20102;&#23569;&#26679;&#26412;&#30340;&#22810;&#36339;&#38382;&#39064;&#26816;&#32034;&#12290;&#22312;HotpotQA&#25968;&#25454;&#38598;&#19978;&#65292;PromptRank&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20351;&#29992;&#30340;&#22823;&#37327;&#35757;&#32451;&#26679;&#26412;&#65292;&#20165;&#20351;&#29992;128&#20010;&#35757;&#32451;&#31034;&#20363;&#23601;&#33021;&#36798;&#21040;&#36739;&#39640;&#30340;&#21484;&#22238;&#29575;&#12290;</title><link>http://arxiv.org/abs/2205.12650</link><description>&lt;p&gt;
&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#30340;&#23569;&#26679;&#26412;&#22810;&#36339;&#38382;&#39064;&#20877;&#25490;&#21517;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Few-shot Reranking for Multi-hop QA via Language Model Prompting. (arXiv:2205.12650v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PromptRank&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#30340;&#22810;&#36339;&#36335;&#24452;&#20877;&#25490;&#21517;&#65292;&#23454;&#29616;&#20102;&#23569;&#26679;&#26412;&#30340;&#22810;&#36339;&#38382;&#39064;&#26816;&#32034;&#12290;&#22312;HotpotQA&#25968;&#25454;&#38598;&#19978;&#65292;PromptRank&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20351;&#29992;&#30340;&#22823;&#37327;&#35757;&#32451;&#26679;&#26412;&#65292;&#20165;&#20351;&#29992;128&#20010;&#35757;&#32451;&#31034;&#20363;&#23601;&#33021;&#36798;&#21040;&#36739;&#39640;&#30340;&#21484;&#22238;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24320;&#25918;&#39046;&#22495;&#38382;&#39064;&#30340;&#23569;&#26679;&#26412;&#22810;&#36339;&#38382;&#39064;&#20877;&#25490;&#21517;&#12290;&#20026;&#20102;&#20943;&#23569;&#23545;&#22823;&#37327;&#26631;&#35760;&#30340;&#38382;&#39064;-&#25991;&#26723;&#23545;&#36827;&#34892;&#26816;&#32034;&#22120;&#35757;&#32451;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PromptRank&#65292;&#23427;&#20381;&#36182;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#22810;&#36339;&#36335;&#24452;&#36827;&#34892;&#20877;&#25490;&#21517;&#12290;PromptRank&#39318;&#20808;&#26500;&#24314;&#19968;&#20010;&#22522;&#20110;&#25351;&#20196;&#30340;&#25552;&#31034;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#20010;&#20505;&#36873;&#25991;&#26723;&#36335;&#24452;&#65292;&#28982;&#21518;&#26681;&#25454;&#35821;&#35328;&#27169;&#22411;&#20013;&#32473;&#23450;&#36335;&#24452;&#25552;&#31034;&#30340;&#26465;&#20214;&#27010;&#29575;&#65292;&#35745;&#31639;&#32473;&#23450;&#38382;&#39064;&#21644;&#36335;&#24452;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#24471;&#20998;&#12290;&#19982;&#22522;&#20110;&#22823;&#37327;&#31034;&#20363;&#35757;&#32451;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;PromptRank&#22312;&#21482;&#26377;128&#20010;&#35757;&#32451;&#31034;&#20363;&#30340;&#24773;&#20917;&#19979;&#22312;HotpotQA&#19978;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#26816;&#32034;&#24615;&#33021;&#8212;&#8212;PromptRank&#30340;&#21484;&#22238;&#29575;@10&#20026;73.6&#65292;&#32780;PathRetriever&#20026;77.8&#65292;&#22810;&#36339;&#31264;&#23494;&#26816;&#32034;&#20026;77.5&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/mukhal/PromptRank&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study few-shot reranking for multi-hop QA with open-domain questions. To alleviate the need for a large number of labeled question-document pairs for retriever training, we propose PromptRank, which relies on large language models prompting for multi-hop path reranking. PromptRank first constructs an instruction-based prompt that includes a candidate document path and then computes the relevance score between a given question and the path based on the conditional likelihood of the question given the path prompt according to a language model. PromptRank yields strong retrieval performance on HotpotQA with only 128 training examples compared to state-of-the-art methods trained on thousands of examples -- 73.6 recall@10 by PromptRank vs. 77.8 by PathRetriever and 77.5 by multi-hop dense retrieval. Code available at https://github.com/mukhal/PromptRank
&lt;/p&gt;</description></item></channel></rss>