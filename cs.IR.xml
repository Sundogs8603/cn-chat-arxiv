<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32842;&#22825;&#30340;&#29983;&#25104;&#31995;&#32479;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#31616;&#21270;&#21644;&#22686;&#24378;&#20986;&#29256;&#29289;&#31649;&#29702;&#36807;&#31243;&#65292;&#21253;&#25324;&#25506;&#32034;&#24615;&#25628;&#32034;&#21644;&#26816;&#32034;&#20197;&#21450;&#32534;&#30446;&#21644;&#31649;&#29702;&#12290;&#36825;&#19968;&#31995;&#32479;&#33021;&#22815;&#19982;Semantic Scholar&#12289;BibSonomy&#21644;Zotero&#31561;&#24179;&#21488;&#20132;&#20114;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#22312;&#21457;&#29616;&#12289;&#31649;&#29702;&#21644;&#27880;&#35299;&#30456;&#20851;&#20986;&#29256;&#29289;&#26041;&#38754;&#25552;&#20379;&#20415;&#21033;&#12290;</title><link>http://arxiv.org/abs/2401.09092</link><description>&lt;p&gt;
BibSonomy&#28385;&#36275;ChatLLMs&#36827;&#34892;&#20986;&#29256;&#29289;&#31649;&#29702;&#65306;&#20174;&#32842;&#22825;&#21040;&#20986;&#29256;&#29289;&#31649;&#29702;&#65306;&#20351;&#29992;BibSonomy&#21644;LLMs&#25972;&#29702;&#30456;&#20851;&#24037;&#20316;(arXiv:2401.09092v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
BibSonomy Meets ChatLLMs for Publication Management: From Chat to Publication Management: Organizing your related work using BibSonomy &amp; LLMs. (arXiv:2401.09092v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32842;&#22825;&#30340;&#29983;&#25104;&#31995;&#32479;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#31616;&#21270;&#21644;&#22686;&#24378;&#20986;&#29256;&#29289;&#31649;&#29702;&#36807;&#31243;&#65292;&#21253;&#25324;&#25506;&#32034;&#24615;&#25628;&#32034;&#21644;&#26816;&#32034;&#20197;&#21450;&#32534;&#30446;&#21644;&#31649;&#29702;&#12290;&#36825;&#19968;&#31995;&#32479;&#33021;&#22815;&#19982;Semantic Scholar&#12289;BibSonomy&#21644;Zotero&#31561;&#24179;&#21488;&#20132;&#20114;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#22312;&#21457;&#29616;&#12289;&#31649;&#29702;&#21644;&#27880;&#35299;&#30456;&#20851;&#20986;&#29256;&#29289;&#26041;&#38754;&#25552;&#20379;&#20415;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31185;&#23398;&#25991;&#29486;&#24211;&#30340;&#19981;&#26029;&#22686;&#38271;&#65292;&#30740;&#31350;&#20154;&#21592;&#22312;&#21457;&#29616;&#12289;&#31649;&#29702;&#21644;&#27880;&#35299;&#30456;&#20851;&#20986;&#29256;&#29289;&#26041;&#38754;&#38754;&#20020;&#30528;&#37325;&#22823;&#25361;&#25112;&#12290;&#20256;&#32479;&#24179;&#21488;&#22914;Semantic Scholar&#12289;BibSonomy&#21644;Zotero&#25552;&#20379;&#20102;&#25991;&#29486;&#31649;&#29702;&#24037;&#20855;&#65292;&#20294;&#24448;&#24448;&#38656;&#35201;&#25163;&#21160;&#36755;&#20837;&#26631;&#31614;&#21644;&#20803;&#25968;&#25454;&#65292;&#24037;&#20316;&#32321;&#29712;&#19988;&#23481;&#26131;&#20986;&#38169;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#65292;&#21033;&#29992;&#22522;&#20110;&#32842;&#22825;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#31616;&#21270;&#21644;&#25913;&#36827;&#20986;&#29256;&#29289;&#31649;&#29702;&#30340;&#36807;&#31243;&#12290;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#22522;&#20110;&#32842;&#22825;&#30340;&#30028;&#38754;&#65292;&#21487;&#20197;&#19982;&#21508;&#31181;&#21518;&#31471;&#36827;&#34892;&#30452;&#35266;&#30340;&#20132;&#20114;&#65292;&#21253;&#25324;Semantic Scholar&#12289;BibSonomy&#21644;Zotero Webscraper&#12290;&#23427;&#25903;&#25345;&#20004;&#31181;&#20027;&#35201;&#29992;&#36884;&#65306;&#65288;1&#65289;&#25506;&#32034;&#24615;&#25628;&#32034;&#21644;&#26816;&#32034;-&#21033;&#29992;LLMs&#25628;&#32034;&#21644;&#26816;&#32034;&#29305;&#23450;&#21644;&#36890;&#29992;&#30340;&#31185;&#23398;&#20986;&#29256;&#29289;&#65292;&#21516;&#26102;&#35299;&#20915;&#20869;&#23481;&#21457;&#29983;&#21644;&#25968;&#25454;&#36807;&#26102;&#30340;&#25361;&#25112;&#65307;&#65288;2&#65289;&#32534;&#30446;&#21644;&#31649;&#29702;-&#24110;&#21161;&#29992;&#25143;&#32452;&#32455;&#21644;&#31649;&#29702;&#30456;&#20851;&#24037;&#20316;&#30340;&#20986;&#29256;&#29289;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ever-growing corpus of scientific literature presents significant challenges for researchers with respect to discovery, management, and annotation of relevant publications. Traditional platforms like Semantic Scholar, BibSonomy, and Zotero offer tools for literature management, but largely require manual laborious and error-prone input of tags and metadata. Here, we introduce a novel retrieval augmented generation system that leverages chat-based large language models (LLMs) to streamline and enhance the process of publication management. It provides a unified chat-based interface, enabling intuitive interactions with various backends, including Semantic Scholar, BibSonomy, and the Zotero Webscraper. It supports two main use-cases: (1) Explorative Search &amp; Retrieval - leveraging LLMs to search for and retrieve both specific and general scientific publications, while addressing the challenges of content hallucination and data obsolescence; and (2) Cataloguing &amp; Management - aiding i
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#30693;&#35782;&#22686;&#24378;&#31574;&#30053;&#65292;&#20174;&#20302;&#23618;&#30693;&#35782;&#20013;&#25552;&#21462;&#39640;&#23618;&#37329;&#23383;&#22612;&#29366;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22810;&#23618;&#20998;&#23618;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#25512;&#29702;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#25512;&#29702;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.09070</link><description>&lt;p&gt;
&#30693;&#35782;&#37329;&#23383;&#22612;&#65306;&#19968;&#31181;&#29992;&#20110;&#25512;&#24191;&#30693;&#35782;&#22686;&#24378;&#21644;&#25512;&#29702;&#30340;&#26032;&#22411;&#20998;&#23618;&#25512;&#29702;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Knowledge Pyramid: A Novel Hierarchical Reasoning Structure for Generalized Knowledge Augmentation and Inference. (arXiv:2401.09070v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09070
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#30693;&#35782;&#22686;&#24378;&#31574;&#30053;&#65292;&#20174;&#20302;&#23618;&#30693;&#35782;&#20013;&#25552;&#21462;&#39640;&#23618;&#37329;&#23383;&#22612;&#29366;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22810;&#23618;&#20998;&#23618;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#25512;&#29702;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#25512;&#29702;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#30340;&#25512;&#29702;&#34987;&#35748;&#20026;&#26159;&#20998;&#26512;&#35821;&#20041;&#32593;&#32476;&#30340;&#26377;&#25928;&#25163;&#27573;&#65292;&#24182;&#22312;&#20449;&#24687;&#26816;&#32034;&#12289;&#25512;&#33616;&#12289;&#20915;&#31574;&#21644;&#20154;&#26426;&#20132;&#20114;&#31561;&#39046;&#22495;&#20855;&#26377;&#24040;&#22823;&#30340;&#29992;&#36884;&#12290;&#23427;&#24191;&#27867;&#24212;&#29992;&#20110;&#25512;&#33616;&#12289;&#20915;&#31574;&#12289;&#38382;&#31572;&#12289;&#25628;&#32034;&#31561;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#30740;&#31350;&#20027;&#35201;&#20351;&#29992;KG&#20013;&#30340;&#20302;&#23618;&#30693;&#35782;&#36827;&#34892;&#25512;&#29702;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#25512;&#29702;&#30340;&#27867;&#21270;&#19981;&#36275;&#21644;&#40065;&#26834;&#24615;&#24046;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#29702;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#30693;&#35782;&#22686;&#24378;&#31574;&#30053;&#65292;&#20197;&#25552;&#39640;KG&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#20174;&#20302;&#23618;&#30693;&#35782;&#20013;&#25552;&#21462;&#39640;&#23618;&#37329;&#23383;&#22612;&#29366;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22312;&#22810;&#23618;&#23618;&#27425;&#21270;KG&#20013;&#30340;&#25512;&#29702;&#65292;&#26412;&#25991;&#31216;&#20043;&#20026;&#30693;&#35782;&#37329;&#23383;&#22612;&#12290;&#25105;&#20204;&#20351;&#29992;&#25552;&#20986;&#30340;&#26041;&#27861;&#23545;&#19968;&#20123;&#21307;&#30103;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25552;&#20986;&#30340;&#30693;&#35782;&#37329;&#23383;&#22612;&#25913;&#36827;&#20102;&#30693;&#35782;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graph (KG) based reasoning has been regarded as an effective means for the analysis of semantic networks and is of great usefulness in areas of information retrieval, recommendation, decision-making, and man-machine interaction. It is widely used in recommendation, decision-making, question-answering, search, and other fields. However, previous studies mainly used low-level knowledge in the KG for reasoning, which may result in insufficient generalization and poor robustness of reasoning. To this end, this paper proposes a new inference approach using a novel knowledge augmentation strategy to improve the generalization capability of KG. This framework extracts high-level pyramidal knowledge from low-level knowledge and applies it to reasoning in a multi-level hierarchical KG, called knowledge pyramid in this paper. We tested some medical data sets using the proposed approach, and the experimental results show that the proposed knowledge pyramid has improved the knowledge inf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#20307;&#20808;&#21069;&#30340;&#24577;&#24230;&#22914;&#20309;&#24433;&#21709;&#29616;&#20195;&#20449;&#24687;&#33719;&#21462;&#36807;&#31243;&#65292;&#29305;&#21035;&#26159;&#35895;&#27468;&#25628;&#32034;&#21576;&#29616;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#28041;&#21450;&#22549;&#32974;&#20027;&#39064;&#30340;&#32508;&#21512;&#30740;&#31350;&#65292;&#26412;&#25991;&#25581;&#31034;&#20102;&#25628;&#32034;&#24341;&#25806;&#31639;&#27861;&#25918;&#22823;&#20010;&#20307;&#20559;&#35265;&#30340;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.09044</link><description>&lt;p&gt;
Google&#25628;&#32034;&#31639;&#27861;&#23545;&#20559;&#35265;&#30340;&#25918;&#22823;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Algorithmic amplification of biases on Google Search. (arXiv:2401.09044v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#20307;&#20808;&#21069;&#30340;&#24577;&#24230;&#22914;&#20309;&#24433;&#21709;&#29616;&#20195;&#20449;&#24687;&#33719;&#21462;&#36807;&#31243;&#65292;&#29305;&#21035;&#26159;&#35895;&#27468;&#25628;&#32034;&#21576;&#29616;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#28041;&#21450;&#22549;&#32974;&#20027;&#39064;&#30340;&#32508;&#21512;&#30740;&#31350;&#65292;&#26412;&#25991;&#25581;&#31034;&#20102;&#25628;&#32034;&#24341;&#25806;&#31639;&#27861;&#25918;&#22823;&#20010;&#20307;&#20559;&#35265;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#33719;&#21462;&#36807;&#31243;&#30340;&#28436;&#21464;&#65292;&#30001;&#35895;&#27468;&#31561;&#25628;&#32034;&#24341;&#25806;&#39537;&#21160;&#65292;&#24050;&#32463;&#25913;&#21464;&#20102;&#20154;&#20204;&#23545;&#20449;&#24687;&#30340;&#33719;&#21462;&#26041;&#24335;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#20307;&#20808;&#21069;&#30340;&#24577;&#24230;&#22914;&#20309;&#24433;&#21709;&#29616;&#20195;&#20449;&#24687;&#33719;&#21462;&#36807;&#31243;&#65292;&#29305;&#21035;&#26159;&#35895;&#27468;&#25628;&#32034;&#21576;&#29616;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#28041;&#21450;&#22549;&#32974;&#20027;&#39064;&#30340;&#32508;&#21512;&#30740;&#31350;&#65292;&#21253;&#25324;&#35843;&#26597;&#21644;&#20449;&#24687;&#33719;&#21462;&#20219;&#21153;&#65292;&#26412;&#25991;&#25552;&#20379;&#20102;&#22235;&#20010;&#20851;&#38190;&#30340;&#35266;&#28857;&#65306;1&#65289;&#22312;&#22549;&#32974;&#38382;&#39064;&#19978;&#25345;&#30456;&#21453;&#24577;&#24230;&#30340;&#20010;&#20307;&#20250;&#25910;&#21040;&#19981;&#21516;&#30340;&#25628;&#32034;&#32467;&#26524;&#12290;2&#65289;&#20010;&#20307;&#36890;&#36807;&#36873;&#25321;&#26597;&#35810;&#26102;&#20351;&#29992;&#30340;&#35789;&#27719;&#34920;&#36798;&#33258;&#24049;&#30340;&#20449;&#24565;&#65292;&#20174;&#32780;&#22609;&#36896;&#20102;&#25628;&#32034;&#32467;&#26524;&#30340;&#32467;&#26524;&#12290;3&#65289;&#27492;&#22806;&#65292;&#29992;&#25143;&#30340;&#25628;&#32034;&#21382;&#21490;&#22312;&#25345;&#30456;&#21453;&#24577;&#24230;&#30340;&#20154;&#32676;&#20013;&#23548;&#33268;&#20102;&#19981;&#21516;&#30340;&#32467;&#26524;&#12290;4&#65289;&#35895;&#27468;&#25628;&#32034;&#24341;&#25806;&#22312;&#25628;&#32034;&#32467;&#26524;&#20013;&#24378;&#21270;&#20102;&#20808;&#21069;&#23384;&#22312;&#30340;&#20449;&#24565;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#20154;&#31867;&#20559;&#35265;&#21644;&#31639;&#27861;&#36807;&#31243;&#20043;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#35265;&#35299;&#65292;&#31361;&#20986;&#20102;&#23545;&#20559;&#35265;&#36827;&#34892;&#24178;&#39044;&#21644;&#35843;&#25972;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The evolution of information-seeking processes, driven by search engines like Google, has transformed the access to information people have. This paper investigates how individuals' preexisting attitudes influence the modern information-seeking process, specifically the results presented by Google Search. Through a comprehensive study involving surveys and information-seeking tasks focusing on the topic of abortion, the paper provides four crucial insights: 1) Individuals with opposing attitudes on abortion receive different search results. 2) Individuals express their beliefs in their choice of vocabulary used in formulating the search queries, shaping the outcome of the search. 3) Additionally, the user's search history contributes to divergent results among those with opposing attitudes. 4) Google Search engine reinforces preexisting beliefs in search results. Overall, this study provides insights into the interplay between human biases and algorithmic processes, highlighting the po
&lt;/p&gt;</description></item><item><title>UOEP&#26159;&#19968;&#31181;&#29992;&#25143;&#23548;&#21521;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#19981;&#21516;&#27963;&#36291;&#27700;&#24179;&#30340;&#29992;&#25143;&#32676;&#20307;&#23454;&#29616;&#32454;&#31890;&#24230;&#25506;&#32034;&#65292;&#20197;&#22686;&#24378;&#29992;&#25143;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2401.09034</link><description>&lt;p&gt;
UOEP: &#29992;&#25143;&#23548;&#21521;&#30340;&#25506;&#32034;&#31574;&#30053;&#20197;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#29992;&#25143;&#20307;&#39564;
&lt;/p&gt;
&lt;p&gt;
UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems. (arXiv:2401.09034v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09034
&lt;/p&gt;
&lt;p&gt;
UOEP&#26159;&#19968;&#31181;&#29992;&#25143;&#23548;&#21521;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#19981;&#21516;&#27963;&#36291;&#27700;&#24179;&#30340;&#29992;&#25143;&#32676;&#20307;&#23454;&#29616;&#32454;&#31890;&#24230;&#25506;&#32034;&#65292;&#20197;&#22686;&#24378;&#29992;&#25143;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#24050;&#32463;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#65292;&#26377;&#25928;&#22320;&#25506;&#32034;&#29992;&#25143;&#30340;&#20852;&#36259;&#65292;&#20197;&#25552;&#21319;&#29992;&#25143;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;&#28982;&#32780;&#65292;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30528;&#25968;&#21315;&#19975;&#20010;&#39033;&#30446;&#20043;&#38388;&#30340;&#19981;&#21516;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#65292;&#36825;&#22686;&#21152;&#20102;&#25506;&#32034;&#30340;&#38590;&#24230;&#12290;&#20363;&#22914;&#65292;&#19981;&#21516;&#27963;&#36291;&#27700;&#24179;&#30340;&#29992;&#25143;&#34892;&#20026;&#38656;&#35201;&#19981;&#21516;&#24378;&#24230;&#30340;&#25506;&#32034;&#65292;&#32780;&#20043;&#21069;&#30340;&#30740;&#31350;&#24448;&#24448;&#24573;&#35270;&#20102;&#36825;&#19968;&#26041;&#38754;&#65292;&#23545;&#25152;&#26377;&#29992;&#25143;&#24212;&#29992;&#32479;&#19968;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#26368;&#32456;&#25439;&#23475;&#20102;&#29992;&#25143;&#30340;&#38271;&#26399;&#20307;&#39564;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#25143;&#23548;&#21521;&#30340;&#25506;&#32034;&#31574;&#30053;&#65288;UOEP&#65289;&#65292;&#19968;&#31181;&#22312;&#29992;&#25143;&#32676;&#20307;&#20013;&#23454;&#29616;&#32454;&#31890;&#24230;&#25506;&#32034;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#26500;&#24314;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#35780;&#35770;&#23478;&#65292;&#23427;&#20801;&#35768;&#22312;&#19981;&#21516;&#30340;&#32047;&#31215;&#22870;&#21169;&#21453;&#39304;&#30340;&#20998;&#20301;&#25968;&#27700;&#24179;&#19979;&#36827;&#34892;&#31574;&#30053;&#20248;&#21270;&#65292;&#34920;&#31034;&#20855;&#26377;&#19981;&#21516;&#27963;&#21160;&#27700;&#24179;&#30340;&#29992;&#25143;&#32676;&#20307;&#12290;&#22312;&#36825;&#20010;&#35780;&#35770;&#23478;&#30340;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#32452;&#19981;&#21516;&#30340;&#28436;&#21592;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) has gained traction for enhancing user long-term experiences in recommender systems by effectively exploring users' interests. However, modern recommender systems exhibit distinct user behavioral patterns among tens of millions of items, which increases the difficulty of exploration. For example, user behaviors with different activity levels require varying intensity of exploration, while previous studies often overlook this aspect and apply a uniform exploration strategy to all users, which ultimately hurts user experiences in the long run. To address these challenges, we propose User-Oriented Exploration Policy (UOEP), a novel approach facilitating fine-grained exploration among user groups. We first construct a distributional critic which allows policy optimization under varying quantile levels of cumulative reward feedbacks from users, representing user groups with varying activity levels. Guided by this critic, we devise a population of distinct actors 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20272;&#35745;&#32500;&#22522;&#30334;&#31185;&#19981;&#21516;&#23454;&#20307;&#31867;&#22411;&#30340;&#24615;&#21035;&#23436;&#25972;&#24615;&#30340;&#24037;&#20855;&#65292;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#20102;&#32500;&#22522;&#30334;&#31185;&#20013;&#19981;&#21516;&#23376;&#31867;&#21035;&#20154;&#29289;&#30340;&#24615;&#21035;&#27604;&#20363;&#21644;&#35206;&#30422;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.08993</link><description>&lt;p&gt;
&#35780;&#20272;&#32500;&#22522;&#30334;&#31185;&#30340;&#24615;&#21035;&#23436;&#25972;&#24615;
&lt;/p&gt;
&lt;p&gt;
Estimating Gender Completeness in Wikipedia. (arXiv:2401.08993v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20272;&#35745;&#32500;&#22522;&#30334;&#31185;&#19981;&#21516;&#23454;&#20307;&#31867;&#22411;&#30340;&#24615;&#21035;&#23436;&#25972;&#24615;&#30340;&#24037;&#20855;&#65292;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#20102;&#32500;&#22522;&#30334;&#31185;&#20013;&#19981;&#21516;&#23376;&#31867;&#21035;&#20154;&#29289;&#30340;&#24615;&#21035;&#27604;&#20363;&#21644;&#35206;&#30422;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#22522;&#30334;&#31185;&#20869;&#23481;&#20013;&#30340;&#24615;&#21035;&#22833;&#34913;&#26159;&#19968;&#20010;&#24050;&#30693;&#30340;&#25361;&#25112;&#65292;&#32534;&#36753;&#32676;&#20307;&#27491;&#22312;&#31215;&#26497;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#26412;&#25991;&#30340;&#30446;&#30340;&#26159;&#20026;&#32500;&#22522;&#30334;&#31185;&#31038;&#21306;&#25552;&#20379;&#24037;&#20855;&#65292;&#20197;&#20272;&#35745;&#32500;&#22522;&#30334;&#31185;&#19981;&#21516;&#23454;&#20307;&#31867;&#22411;&#65288;&#20063;&#31216;&#20026;&#31867;&#65289;&#20013;&#38382;&#39064;&#30340;&#20005;&#37325;&#31243;&#24230;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24212;&#29992;&#22522;&#20110;&#24615;&#21035;&#23646;&#24615;&#30340;&#31867;&#23436;&#25972;&#24615;&#20272;&#35745;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#19981;&#20165;&#26174;&#31034;&#20102;&#32500;&#22522;&#30334;&#31185;&#20013;&#19981;&#21516;&#23376;&#31867;&#21035;&#20154;&#29289;&#30340;&#24615;&#21035;&#27604;&#20363;&#65292;&#36824;&#32473;&#20986;&#20102;&#19981;&#21516;&#24615;&#21035;&#21644;&#23376;&#31867;&#21035;&#20154;&#29289;&#30340;&#35206;&#30422;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gender imbalance in Wikipedia content is a known challenge which the editor community is actively addressing. The aim of this paper is to provide the Wikipedia community with instruments to estimate the magnitude of the problem for different entity types (also known as classes) in Wikipedia. To this end, we apply class completeness estimation methods based on the gender attribute. Our results show not only which gender for different sub-classes of Person is more prevalent in Wikipedia, but also an idea of how complete the coverage is for difference genders and sub-classes of Person.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22312;&#38899;&#39057;&#23884;&#20837;&#20013;&#25805;&#20316;&#33410;&#22863;&#65292;&#26412;&#30740;&#31350;&#23454;&#29616;&#20102;&#22312;&#32500;&#25345;&#20854;&#20182;&#23646;&#24615;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#65292;&#26816;&#32034;&#20986;&#22312;&#33410;&#22863;&#19978;&#30456;&#20284;&#20294;&#22312;&#20854;&#20182;&#26041;&#38754;&#19981;&#21516;&#30340;&#38899;&#20048;&#26354;&#30446;&#12290;</title><link>http://arxiv.org/abs/2401.08902</link><description>&lt;p&gt;
&#31867;&#20284;&#20294;&#26356;&#24555;&#65306;&#38899;&#20048;&#38899;&#39057;&#23884;&#20837;&#20013;&#30340;&#33410;&#22863;&#25805;&#20316;&#29992;&#20110;&#33410;&#22863;&#39044;&#27979;&#21644;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Similar but Faster: Manipulation of Tempo in Music Audio Embeddings for Tempo Prediction and Search. (arXiv:2401.08902v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08902
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#38899;&#39057;&#23884;&#20837;&#20013;&#25805;&#20316;&#33410;&#22863;&#65292;&#26412;&#30740;&#31350;&#23454;&#29616;&#20102;&#22312;&#32500;&#25345;&#20854;&#20182;&#23646;&#24615;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#65292;&#26816;&#32034;&#20986;&#22312;&#33410;&#22863;&#19978;&#30456;&#20284;&#20294;&#22312;&#20854;&#20182;&#26041;&#38754;&#19981;&#21516;&#30340;&#38899;&#20048;&#26354;&#30446;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#39057;&#23884;&#20837;&#20351;&#24471;&#38899;&#39057;&#25991;&#20214;&#30340;&#30456;&#20284;&#24615;&#33021;&#22815;&#36827;&#34892;&#22823;&#35268;&#27169;&#27604;&#36739;&#65292;&#29992;&#20110;&#25628;&#32034;&#21644;&#25512;&#33616;&#31561;&#24212;&#29992;&#12290;&#30001;&#20110;&#38899;&#39057;&#30456;&#20284;&#24615;&#30340;&#20027;&#35266;&#24615;&#65292;&#35774;&#35745;&#33021;&#22815;&#22238;&#31572;&#38899;&#39057;&#26159;&#21542;&#30456;&#20284;&#20197;&#21450;&#30456;&#20284;&#30340;&#26041;&#24335;&#65288;&#20363;&#22914;&#65292;&#19982;&#33410;&#22863;&#12289;&#24773;&#32490;&#25110;&#27969;&#27966;&#30456;&#20851;&#65289;&#30340;&#31995;&#32479;&#21487;&#33021;&#26356;&#21152;&#29702;&#24819;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#25552;&#20986;&#20102;&#33021;&#22815;&#23545;&#29305;&#23450;&#23646;&#24615;&#36827;&#34892;&#21152;&#26435;&#20197;&#22312;&#21518;&#32493;&#20219;&#21153;&#20013;&#24378;&#35843;&#36825;&#20123;&#23646;&#24615;&#30340;&#20998;&#31163;&#23884;&#20837;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#36825;&#20123;&#23376;&#31354;&#38388;&#30340;&#29420;&#31435;&#24615;&#20197;&#21450;&#23545;&#20854;&#36827;&#34892;&#25805;&#20316;&#20197;&#26816;&#32034;&#22312;&#29305;&#23450;&#26041;&#24335;&#19979;&#30456;&#20284;&#20294;&#19981;&#21516;&#30340;&#26354;&#30446;&#30340;&#30740;&#31350;&#23578;&#26410;&#36827;&#34892;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#25805;&#20316;&#33410;&#22863;&#20316;&#20026;&#36825;&#20010;&#30446;&#26631;&#30340;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#33410;&#22863;&#36716;&#25442;&#20989;&#25968;&#65292;&#21487;&#20197;&#22312;&#29616;&#26377;&#23884;&#20837;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#25805;&#20316;&#33410;&#22863;&#65292;&#21516;&#26102;&#20445;&#25345;&#27969;&#27966;&#31561;&#20854;&#20182;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Audio embeddings enable large scale comparisons of the similarity of audio files for applications such as search and recommendation. Due to the subjectivity of audio similarity, it can be desirable to design systems that answer not only whether audio is similar, but similar in what way (e.g., wrt. tempo, mood or genre). Previous works have proposed disentangled embedding spaces where subspaces representing specific, yet possibly correlated, attributes can be weighted to emphasize those attributes in downstream tasks. However, no research has been conducted into the independence of these subspaces, nor their manipulation, in order to retrieve tracks that are similar but different in a specific way. Here, we explore the manipulation of tempo in embedding spaces as a case-study towards this goal. We propose tempo translation functions that allow for efficient manipulation of tempo within a pre-existing embedding space whilst maintaining other properties such as genre. As this translation 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#38899;&#20048;&#25968;&#25454;&#38598;&#19978;&#30340;&#38899;&#39057;&#34920;&#31034;&#65292;&#21457;&#29616;&#36890;&#36807;&#36866;&#24403;&#30340;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#65292;&#21487;&#20197;&#20943;&#23569;&#19968;&#39318;&#26354;&#30446;&#20013;&#22343;&#21248;&#30340;&#38899;&#20048;&#29305;&#24615;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#26412;&#22320;&#21270;&#65292;&#24182;&#25552;&#39640;&#20854;&#20182;&#23646;&#24615;&#30340;&#26412;&#22320;&#21270;&#12290;&#36825;&#23545;&#20110;&#38899;&#20048;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#26368;&#36817;&#37051;&#31639;&#27861;&#24212;&#29992;&#26159;&#37325;&#35201;&#30340;&#12290;</title><link>http://arxiv.org/abs/2401.08889</link><description>&lt;p&gt;
&#23545;&#25968;&#25454;&#22686;&#24378;&#22312;&#23545;&#27604;&#23398;&#20064;&#38899;&#20048;&#38899;&#39057;&#34920;&#31034;&#20013;&#30340;&#23616;&#37096;&#23884;&#20837;&#29305;&#24615;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the Effect of Data-Augmentation on Local Embedding Properties in the Contrastive Learning of Music Audio Representations. (arXiv:2401.08889v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08889
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#38899;&#20048;&#25968;&#25454;&#38598;&#19978;&#30340;&#38899;&#39057;&#34920;&#31034;&#65292;&#21457;&#29616;&#36890;&#36807;&#36866;&#24403;&#30340;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#65292;&#21487;&#20197;&#20943;&#23569;&#19968;&#39318;&#26354;&#30446;&#20013;&#22343;&#21248;&#30340;&#38899;&#20048;&#29305;&#24615;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#26412;&#22320;&#21270;&#65292;&#24182;&#25552;&#39640;&#20854;&#20182;&#23646;&#24615;&#30340;&#26412;&#22320;&#21270;&#12290;&#36825;&#23545;&#20110;&#38899;&#20048;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#26368;&#36817;&#37051;&#31639;&#27861;&#24212;&#29992;&#26159;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#39057;&#23884;&#20837;&#26159;&#29702;&#35299;&#22823;&#37327;&#38899;&#20048;&#30446;&#24405;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#36890;&#24120;&#65292;&#23884;&#20837;&#26159;&#26681;&#25454;&#23427;&#20204;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#26469;&#35780;&#20272;&#30340;&#65292;&#28982;&#32780;&#23569;&#26377;&#30740;&#31350;&#35843;&#26597;&#23884;&#20837;&#31354;&#38388;&#26412;&#36523;&#30340;&#23616;&#37096;&#29305;&#24615;&#65292;&#32780;&#36825;&#20123;&#23616;&#37096;&#29305;&#24615;&#23545;&#20110;&#26368;&#36817;&#37051;&#31639;&#27861;&#22312;&#38899;&#20048;&#25628;&#32034;&#21644;&#25512;&#33616;&#20013;&#30340;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#20064;&#38899;&#20048;&#25968;&#25454;&#38598;&#19978;&#30340;&#38899;&#39057;&#34920;&#31034;&#26102;&#65292;&#36890;&#24120;&#22312;&#19968;&#39318;&#26354;&#30446;&#20013;&#26159;&#22343;&#21248;&#30340;&#38899;&#20048;&#29305;&#24615;&#65288;&#22914;&#38899;&#35843;&#21644;&#36895;&#24230;&#65289;&#22312;&#25152;&#24471;&#21040;&#30340;&#23884;&#20837;&#31354;&#38388;&#30340;&#37051;&#22495;&#30340;&#23616;&#37096;&#24615;&#20013;&#24471;&#21040;&#20102;&#20307;&#29616;&#12290;&#36890;&#36807;&#24212;&#29992;&#36866;&#24403;&#30340;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#65292;&#36825;&#20123;&#29305;&#24615;&#30340;&#26412;&#22320;&#21270;&#19981;&#20165;&#21487;&#20197;&#20943;&#23569;&#65292;&#32780;&#19988;&#20854;&#20182;&#23646;&#24615;&#30340;&#26412;&#22320;&#21270;&#20063;&#20250;&#22686;&#21152;&#12290;&#20363;&#22914;&#65292;&#19982;&#38750;&#19987;&#19994;&#21548;&#20247;&#20851;&#31995;&#36739;&#23567;&#30340;&#38899;&#39640;&#21644;&#36895;&#24230;&#31561;&#29305;&#24449;&#30340;&#23616;&#37096;&#24615;&#21487;&#33021;&#20250;&#24471;&#21040;&#32531;&#35299;&#65292;&#21516;&#26102;&#25913;&#21892;&#26356;&#26174;&#33879;&#29305;&#24449;&#30340;&#23616;&#37096;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Audio embeddings are crucial tools in understanding large catalogs of music. Typically embeddings are evaluated on the basis of the performance they provide in a wide range of downstream tasks, however few studies have investigated the local properties of the embedding spaces themselves which are important in nearest neighbor algorithms, commonly used in music search and recommendation. In this work we show that when learning audio representations on music datasets via contrastive learning, musical properties that are typically homogeneous within a track (e.g., key and tempo) are reflected in the locality of neighborhoods in the resulting embedding space. By applying appropriate data augmentation strategies, localisation of such properties can not only be reduced but the localisation of other attributes is increased. For example, locality of features such as pitch and tempo that are less relevant to non-expert listeners, may be mitigated while improving the locality of more salient fea
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#20869;&#23481;&#30340;&#26041;&#27861;&#21644;&#26469;&#33258;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#30340;&#20803;&#25968;&#25454;&#65292;&#25104;&#21151;&#35782;&#21035;&#21644;&#39044;&#27979;&#19982;COVID-19&#22823;&#27969;&#34892;&#30456;&#20851;&#30340;&#34394;&#20551;&#26032;&#38395;&#24086;&#23376;&#65292;&#20934;&#30830;&#29575;&#39640;&#36798;93%&#12290;</title><link>http://arxiv.org/abs/2401.08841</link><description>&lt;p&gt;
&#25506;&#32034;&#22522;&#20110;&#20869;&#23481;&#21644;&#20803;&#25968;&#25454;&#20998;&#26512;&#30340;&#26816;&#27979;&#20551;&#26032;&#38395;&#20449;&#24687;&#20256;&#25773;&#65306;&#20197;COVID-19&#20026;&#20363;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exploring Content-Based and Meta-Data Analysis for Detecting Fake News Infodemic: A case study on COVID-19. (arXiv:2401.08841v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08841
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#20869;&#23481;&#30340;&#26041;&#27861;&#21644;&#26469;&#33258;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#30340;&#20803;&#25968;&#25454;&#65292;&#25104;&#21151;&#35782;&#21035;&#21644;&#39044;&#27979;&#19982;COVID-19&#22823;&#27969;&#34892;&#30456;&#20851;&#30340;&#34394;&#20551;&#26032;&#38395;&#24086;&#23376;&#65292;&#20934;&#30830;&#29575;&#39640;&#36798;93%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#20896;&#30123;&#24773;&#65288;COVID-19&#65289;&#21487;&#33021;&#26159;&#36817;&#20195;&#21382;&#21490;&#19978;&#26368;&#20855;&#30772;&#22351;&#24615;&#30340;&#20840;&#29699;&#21355;&#29983;&#28798;&#38590;&#12290;&#23427;&#23545;&#25972;&#20010;&#19990;&#30028;&#36896;&#25104;&#20102;&#36127;&#38754;&#24433;&#21709;&#65292;&#20960;&#20046;&#23558;&#20840;&#29699;&#32463;&#27982;&#38519;&#20837;&#20572;&#28382;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#30149;&#27602;&#30340;&#20256;&#25773;&#65292;&#24863;&#26579;&#20154;&#25968;&#30340;&#22686;&#21152;&#20197;&#21450;&#23545;&#20107;&#20214;&#30340;&#34394;&#20551;&#28040;&#24687;&#12289;&#38169;&#35823;&#20449;&#24687;&#21644;&#20551;&#20449;&#24687;&#30340;&#20256;&#25773;&#20063;&#38543;&#20043;&#22686;&#21152;&#12290;&#36825;&#20123;&#21253;&#25324;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#20256;&#25773;&#26410;&#32463;&#35777;&#23454;&#30340;&#20581;&#24247;&#24314;&#35758;&#21644;&#30103;&#27861;&#12290;&#26412;&#25991;&#20351;&#29992;&#22522;&#20110;&#20869;&#23481;&#30340;&#26041;&#27861;&#20197;&#21450;&#20174;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#21457;&#24067;&#30340;&#28040;&#24687;&#20013;&#25552;&#28860;&#30340;&#20803;&#25968;&#25454;&#26469;&#35782;&#21035;&#26377;&#20851;&#22823;&#27969;&#34892;&#30149;&#30340;&#34394;&#20551;&#20449;&#24687;&#12290;&#20351;&#29992;&#22522;&#20110;&#20869;&#23481;&#30340;&#26041;&#27861;&#32467;&#21512;&#20803;&#25968;&#25454;&#20197;&#21450;&#21021;&#22987;&#29305;&#24449;&#20998;&#26512;&#65292;&#24182;&#27979;&#35797;&#20102;&#20960;&#31181;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#26469;&#35782;&#21035;&#21644;&#39044;&#27979;&#35823;&#23548;&#24615;&#30340;&#24086;&#23376;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26816;&#27979;&#19982;COVID-19&#22823;&#27969;&#34892;&#30456;&#20851;&#30340;&#34394;&#20551;&#26032;&#38395;&#30340;&#24086;&#23376;&#26041;&#38754;&#26174;&#31034;&#20986;93%&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The coronavirus pandemic (COVID-19) is probably the most disruptive global health disaster in recent history. It negatively impacted the whole world and virtually brought the global economy to a standstill. However, as the virus was spreading, infecting people and claiming thousands of lives so was the spread and propagation of fake news, misinformation and disinformation about the event. These included the spread of unconfirmed health advice and remedies on social media. In this paper, false information about the pandemic is identified using a content-based approach and metadata curated from messages posted to online social networks. A content-based approach combined with metadata as well as an initial feature analysis is used and then several supervised learning models are tested for identifying and predicting misleading posts. Our approach shows up to 93% accuracy in the detection of fake news related posts about the COVID-19 pandemic
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#31038;&#20132;&#38899;&#20048;&#25512;&#33616;&#20013;&#24433;&#21709;&#38899;&#20048;&#20114;&#21160;&#30340;&#31038;&#20132;&#21644;&#29615;&#22659;&#22240;&#32032;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25509;&#25910;&#32773;&#19982;&#21457;&#36865;&#32773;&#38899;&#20048;&#21697;&#21619;&#30456;&#20284;&#12289;&#20998;&#20139;&#30340;&#38899;&#36712;&#36866;&#21512;&#25509;&#25910;&#32773;&#30340;&#21697;&#21619;&#12289;&#25509;&#25910;&#32773;&#19982;&#21457;&#36865;&#32773;&#20855;&#26377;&#26356;&#24378;&#21644;&#26356;&#20146;&#23494;&#30340;&#32852;&#31995;&#20197;&#21450;&#20998;&#20139;&#30340;&#33402;&#26415;&#23478;&#22312;&#25509;&#25910;&#32773;&#30340;&#20851;&#31995;&#20013;&#21463;&#27426;&#36814;&#65292;&#36825;&#20123;&#22240;&#32032;&#37117;&#20250;&#22686;&#21152;&#25509;&#25910;&#32773;&#19982;&#26032;&#33402;&#26415;&#23478;&#30340;&#20114;&#21160;&#12290;</title><link>http://arxiv.org/abs/2401.08818</link><description>&lt;p&gt;
Link Me Baby One More Time: &#22312; Spotify &#19978;&#30340;&#31038;&#20132;&#38899;&#20048;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Link Me Baby One More Time: Social Music Discovery on Spotify. (arXiv:2401.08818v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#31038;&#20132;&#38899;&#20048;&#25512;&#33616;&#20013;&#24433;&#21709;&#38899;&#20048;&#20114;&#21160;&#30340;&#31038;&#20132;&#21644;&#29615;&#22659;&#22240;&#32032;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25509;&#25910;&#32773;&#19982;&#21457;&#36865;&#32773;&#38899;&#20048;&#21697;&#21619;&#30456;&#20284;&#12289;&#20998;&#20139;&#30340;&#38899;&#36712;&#36866;&#21512;&#25509;&#25910;&#32773;&#30340;&#21697;&#21619;&#12289;&#25509;&#25910;&#32773;&#19982;&#21457;&#36865;&#32773;&#20855;&#26377;&#26356;&#24378;&#21644;&#26356;&#20146;&#23494;&#30340;&#32852;&#31995;&#20197;&#21450;&#20998;&#20139;&#30340;&#33402;&#26415;&#23478;&#22312;&#25509;&#25910;&#32773;&#30340;&#20851;&#31995;&#20013;&#21463;&#27426;&#36814;&#65292;&#36825;&#20123;&#22240;&#32032;&#37117;&#20250;&#22686;&#21152;&#25509;&#25910;&#32773;&#19982;&#26032;&#33402;&#26415;&#23478;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#24433;&#21709;&#20010;&#20154;&#20043;&#38388;&#38899;&#20048;&#25512;&#33616;&#21644;&#21457;&#29616;&#32467;&#26524;&#30340;&#31038;&#20132;&#21644;&#29615;&#22659;&#22240;&#32032;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20351;&#29992; Spotify &#30340;&#25968;&#25454;&#26469;&#30740;&#31350;&#29992;&#25143;&#20043;&#38388;&#21457;&#36865;&#38142;&#25509;&#23548;&#33268;&#25509;&#25910;&#32773;&#19982;&#20998;&#20139;&#30340;&#33402;&#26415;&#23478;&#30340;&#38899;&#20048;&#20114;&#21160;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20960;&#20010;&#21487;&#33021;&#24433;&#21709;&#36825;&#19968;&#36807;&#31243;&#30340;&#22240;&#32032;&#65292;&#22914;&#21457;&#36865;&#32773;&#19982;&#25509;&#25910;&#32773;&#30340;&#20851;&#31995;&#24378;&#24230;&#65292;&#29992;&#25143;&#22312; Spotify &#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#35282;&#33394;&#65292;&#20182;&#20204;&#30340;&#38899;&#20048;&#31038;&#20132;&#20957;&#32858;&#21147;&#65292;&#20197;&#21450;&#26032;&#33402;&#26415;&#23478;&#19982;&#25509;&#25910;&#32773;&#30340;&#21697;&#21619;&#30456;&#20284;&#31243;&#24230;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24403;&#25509;&#25910;&#32773;&#19982;&#21457;&#36865;&#32773;&#30340;&#38899;&#20048;&#21697;&#21619;&#30456;&#20284;&#19988;&#20998;&#20139;&#30340;&#38899;&#36712;&#36866;&#21512;&#20182;&#20204;&#30340;&#21697;&#21619;&#26102;&#65292;&#20182;&#20204;&#26356;&#26377;&#21487;&#33021;&#19982;&#26032;&#33402;&#26415;&#23478;&#20114;&#21160;&#65307;&#24403;&#20182;&#20204;&#19982;&#21457;&#36865;&#32773;&#26377;&#26356;&#24378;&#21644;&#26356;&#20146;&#23494;&#30340;&#32852;&#31995;&#26102;&#65292;&#20063;&#26356;&#26377;&#21487;&#33021;&#20114;&#21160;&#65307;&#20197;&#21450;&#24403;&#20998;&#20139;&#30340;&#33402;&#26415;&#23478;&#22312;&#25509;&#25910;&#32773;&#30340;&#20851;&#31995;&#20013;&#21463;&#27426;&#36814;&#26102;&#65292;&#20063;&#26356;&#26377;&#21487;&#33021;&#20114;&#21160;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#21457;&#29616;&#26500;&#24314;&#20102;&#19968;&#20010;&#38543;&#26426;&#26862;&#26519;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#39044;&#27979;&#20998;&#20139;&#30340;&#38899;&#20048;&#36712;&#36947;&#26159;&#21542;&#20250;&#23548;&#33268;&#25509;&#25910;&#32773;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore the social and contextual factors that influence the outcome of person-to-person music recommendations and discovery. Specifically, we use data from Spotify to investigate how a link sent from one user to another results in the receiver engaging with the music of the shared artist. We consider several factors that may influence this process, such as the strength of the sender-receiver relationship, the user's role in the Spotify social network, their music social cohesion, and how similar the new artist is to the receiver's taste. We find that the receiver of a link is more likely to engage with a new artist when (1) they have similar music taste to the sender and the shared track is a good fit for their taste, (2) they have a stronger and more intimate tie with the sender, and (3) the shared artist is popular with the receiver's connections. Finally, we use these findings to build a Random Forest classifier to predict whether a shared music track will result in the receiver
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#32452;&#32455;&#30149;&#29702;&#23398;&#22270;&#20687;&#25628;&#32034;&#25216;&#26415;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#20026;&#35745;&#31639;&#30149;&#29702;&#23398;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#31616;&#26126;&#30340;&#27010;&#36848;&#65292;&#26088;&#22312;&#23547;&#27714;&#26377;&#25928;&#12289;&#24555;&#36895;&#21644;&#39640;&#25928;&#30340;&#22270;&#20687;&#25628;&#32034;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.08699</link><description>&lt;p&gt;
&#20851;&#20110;&#32452;&#32455;&#30149;&#29702;&#23398;&#22270;&#20687;&#25628;&#32034;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Image Search in Histopathology. (arXiv:2401.08699v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08699
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#32452;&#32455;&#30149;&#29702;&#23398;&#22270;&#20687;&#25628;&#32034;&#25216;&#26415;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#20026;&#35745;&#31639;&#30149;&#29702;&#23398;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#31616;&#26126;&#30340;&#27010;&#36848;&#65292;&#26088;&#22312;&#23547;&#27714;&#26377;&#25928;&#12289;&#24555;&#36895;&#21644;&#39640;&#25928;&#30340;&#22270;&#20687;&#25628;&#32034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32452;&#32455;&#30149;&#29702;&#23398;&#30340;&#30149;&#29702;&#22270;&#20687;&#21487;&#20197;&#36890;&#36807;&#35013;&#26377;&#25668;&#20687;&#22836;&#30340;&#26174;&#24494;&#38236;&#25110;&#20840;&#25195;&#25551;&#20202;&#33719;&#21462;&#12290;&#21033;&#29992;&#30456;&#20284;&#24615;&#35745;&#31639;&#22522;&#20110;&#36825;&#20123;&#22270;&#20687;&#21305;&#37197;&#24739;&#32773;&#65292;&#22312;&#30740;&#31350;&#21644;&#20020;&#24202;&#29615;&#22659;&#20013;&#20855;&#26377;&#37325;&#35201;&#28508;&#21147;&#12290;&#26368;&#36817;&#25628;&#32034;&#25216;&#26415;&#30340;&#36827;&#23637;&#20351;&#24471;&#21487;&#20197;&#23545;&#21508;&#31181;&#32452;&#32455;&#31867;&#22411;&#30340;&#32454;&#32990;&#32467;&#26500;&#36827;&#34892;&#24494;&#22937;&#30340;&#37327;&#21270;&#65292;&#20419;&#36827;&#27604;&#36739;&#65292;&#24182;&#22312;&#19982;&#35786;&#26029;&#21644;&#27835;&#30103;&#36807;&#30340;&#30149;&#20363;&#25968;&#25454;&#24211;&#36827;&#34892;&#27604;&#36739;&#26102;&#23454;&#29616;&#20851;&#20110;&#35786;&#26029;&#12289;&#39044;&#21518;&#21644;&#26032;&#24739;&#32773;&#39044;&#27979;&#30340;&#25512;&#26029;&#12290;&#26412;&#25991;&#20840;&#38754;&#22238;&#39038;&#20102;&#32452;&#32455;&#30149;&#29702;&#23398;&#22270;&#20687;&#25628;&#32034;&#25216;&#26415;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#20026;&#35745;&#31639;&#30149;&#29702;&#23398;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#31616;&#26126;&#30340;&#27010;&#36848;&#65292;&#20197;&#23547;&#27714;&#26377;&#25928;&#12289;&#24555;&#36895;&#21644;&#39640;&#25928;&#30340;&#22270;&#20687;&#25628;&#32034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pathology images of histopathology can be acquired from camera-mounted microscopes or whole slide scanners. Utilizing similarity calculations to match patients based on these images holds significant potential in research and clinical contexts. Recent advancements in search technologies allow for nuanced quantification of cellular structures across diverse tissue types, facilitating comparisons and enabling inferences about diagnosis, prognosis, and predictions for new patients when compared against a curated database of diagnosed and treated cases. In this paper, we comprehensively review the latest developments in image search technologies for histopathology, offering a concise overview tailored for computational pathology researchers seeking effective, fast and efficient image search methods in their work.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#25991;&#26412;&#30456;&#20284;&#24615;&#36827;&#34892;&#33258;&#21160;&#31572;&#26696;&#39564;&#35777;&#30340;&#26041;&#27861;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#31185;&#23398;&#38382;&#39064;&#22238;&#31572;&#20013;&#65292;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#22312;&#22810;&#39033;&#36873;&#25321;&#38382;&#39064;&#20013;&#20248;&#20110;&#31070;&#32463;&#26041;&#27861;&#12290;&#36890;&#36807;&#27604;&#36739;&#25105;&#20204;&#30340;&#30417;&#30563;&#27169;&#22411;&#19982;&#20854;&#20182;&#25991;&#26412;&#30456;&#20284;&#24615;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.08688</link><description>&lt;p&gt;
&#20351;&#29992;&#25991;&#26412;&#30456;&#20284;&#24615;&#36827;&#34892;&#33258;&#21160;&#31572;&#26696;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Automated Answer Validation using Text Similarity. (arXiv:2401.08688v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08688
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#25991;&#26412;&#30456;&#20284;&#24615;&#36827;&#34892;&#33258;&#21160;&#31572;&#26696;&#39564;&#35777;&#30340;&#26041;&#27861;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#31185;&#23398;&#38382;&#39064;&#22238;&#31572;&#20013;&#65292;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#22312;&#22810;&#39033;&#36873;&#25321;&#38382;&#39064;&#20013;&#20248;&#20110;&#31070;&#32463;&#26041;&#27861;&#12290;&#36890;&#36807;&#27604;&#36739;&#25105;&#20204;&#30340;&#30417;&#30563;&#27169;&#22411;&#19982;&#20854;&#20182;&#25991;&#26412;&#30456;&#20284;&#24615;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#31572;&#26696;&#39564;&#35777;&#21487;&#20197;&#36890;&#36807;&#20026;&#23398;&#20064;&#32773;&#25552;&#20379;&#36866;&#24403;&#30340;&#21453;&#39304;&#65292;&#20351;&#38382;&#39064;&#22238;&#31572;&#31995;&#32479;&#21644;&#22312;&#32447;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26356;&#24191;&#27867;&#21487;&#29992;&#26469;&#25552;&#39640;&#23398;&#20064;&#25928;&#26524;&#12290;&#22312;&#31185;&#23398;&#38382;&#39064;&#22238;&#31572;&#26041;&#38754;&#24050;&#32463;&#26377;&#19968;&#20123;&#30740;&#31350;&#34920;&#26126;&#65292;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#22312;&#36825;&#20010;&#38382;&#39064;&#30340;&#22810;&#39033;&#36873;&#25321;&#29256;&#26412;&#20013;&#20248;&#20110;&#31070;&#32463;&#26041;&#27861;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#23402;&#29983;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#30417;&#30563;&#27169;&#22411;&#19982;&#20854;&#20182;&#22522;&#20110;&#25991;&#26412;&#30456;&#20284;&#24615;&#30340;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated answer validation can help improve learning outcomes by providing appropriate feedback to learners, and by making question answering systems and online learning solutions more widely available. There have been some works in science question answering which show that information retrieval methods outperform neural methods, especially in the multiple choice version of this problem. We implement Siamese neural network models and produce a generalised solution to this problem. We compare our supervised model with other text similarity based solutions.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#36827;&#21270;&#30340;&#21363;&#26102;&#20852;&#36259;&#32593;&#32476;&#65288;DEI2N&#65289;&#26469;&#35299;&#20915;&#35302;&#21457;&#24341;&#23548;&#25512;&#33616;&#65288;TIR&#65289;&#20013;&#30340;&#28857;&#20987;&#29575;&#39044;&#27979;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#29992;&#25143;&#34892;&#20026;&#30340;&#26102;&#38388;&#20449;&#24687;&#12289;&#21363;&#26102;&#20852;&#36259;&#30340;&#21160;&#24577;&#21464;&#21270;&#20197;&#21450;&#35302;&#21457;&#39033;&#21644;&#30446;&#26631;&#39033;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;</title><link>http://arxiv.org/abs/2401.07769</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#36827;&#21270;&#30340;&#21363;&#26102;&#20852;&#36259;&#32593;&#32476;&#29992;&#20110;&#35302;&#21457;&#24341;&#23548;&#25512;&#33616;&#20013;&#30340;CTR&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Deep Evolutional Instant Interest Network for CTR Prediction in Trigger-Induced Recommendation. (arXiv:2401.07769v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07769
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#36827;&#21270;&#30340;&#21363;&#26102;&#20852;&#36259;&#32593;&#32476;&#65288;DEI2N&#65289;&#26469;&#35299;&#20915;&#35302;&#21457;&#24341;&#23548;&#25512;&#33616;&#65288;TIR&#65289;&#20013;&#30340;&#28857;&#20987;&#29575;&#39044;&#27979;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#29992;&#25143;&#34892;&#20026;&#30340;&#26102;&#38388;&#20449;&#24687;&#12289;&#21363;&#26102;&#20852;&#36259;&#30340;&#21160;&#24577;&#21464;&#21270;&#20197;&#21450;&#35302;&#21457;&#39033;&#21644;&#30446;&#26631;&#39033;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#22312;&#35768;&#22810;&#34892;&#19994;&#20013;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#20363;&#22914;&#30005;&#23376;&#21830;&#21153;&#12289;&#27969;&#23186;&#20307;&#12289;&#31038;&#20132;&#23186;&#20307;&#31561;&#12290;&#26368;&#36817;&#65292;&#20986;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#22330;&#26223;&#65292;&#31216;&#20026;&#35302;&#21457;&#24341;&#23548;&#25512;&#33616;&#65288;TIR&#65289;&#65292;&#29992;&#25143;&#21487;&#20197;&#36890;&#36807;&#35302;&#21457;&#39033;&#26126;&#30830;&#34920;&#36798;&#20182;&#20204;&#30340;&#21363;&#26102;&#20852;&#36259;&#65292;&#22312;&#35768;&#22810;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#65288;&#22914;&#38463;&#37324;&#24052;&#24052;&#21644;&#20122;&#39532;&#36874;&#65289;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#26041;&#27861;&#36890;&#24120;&#26080;&#27861;&#26126;&#30830;&#24314;&#27169;&#29992;&#25143;&#30340;&#21363;&#26102;&#20852;&#36259;&#65292;&#22240;&#27492;&#22312;TIR&#20013;&#33719;&#24471;&#27425;&#20248;&#32467;&#26524;&#12290;&#23613;&#31649;&#26377;&#19968;&#20123;&#21516;&#26102;&#32771;&#34385;&#35302;&#21457;&#39033;&#21644;&#30446;&#26631;&#39033;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#20173;&#26410;&#32771;&#34385;&#29992;&#25143;&#34892;&#20026;&#30340;&#26102;&#38388;&#20449;&#24687;&#12289;&#29992;&#25143;&#21521;&#19979;&#28378;&#21160;&#26102;&#21363;&#26102;&#20852;&#36259;&#30340;&#21160;&#24577;&#21464;&#21270;&#20197;&#21450;&#35302;&#21457;&#39033;&#21644;&#30446;&#26631;&#39033;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;--&#28145;&#24230;&#36827;&#21270;&#30340;&#21363;&#26102;&#20852;&#36259;&#32593;&#32476;&#65288;DEI2N&#65289;&#65292;&#29992;&#20110;TIR&#22330;&#26223;&#20013;&#30340;&#28857;&#20987;&#29575;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recommendation has been playing a key role in many industries, e.g., e-commerce, streaming media, social media, etc. Recently, a new recommendation scenario, called Trigger-Induced Recommendation (TIR), where users are able to explicitly express their instant interests via trigger items, is emerging as an essential role in many e-commerce platforms, e.g., Alibaba.com and Amazon. Without explicitly modeling the user's instant interest, traditional recommendation methods usually obtain sub-optimal results in TIR. Even though there are a few methods considering the trigger and target items simultaneously to solve this problem, they still haven't taken into account temporal information of user behaviors, the dynamic change of user instant interest when the user scrolls down and the interactions between the trigger and target items. To tackle these problems, we propose a novel method -- Deep Evolutional Instant Interest Network (DEI2N), for click-through rate prediction in TIR scenarios
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#22122;&#25193;&#25955;&#25512;&#33616;&#27169;&#22411;&#65288;DDRM&#65289;&#65292;&#36890;&#36807;&#22312;&#25512;&#33616;&#27169;&#22411;&#20013;&#27880;&#20837;&#22122;&#22768;&#24182;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#22810;&#27493;&#21435;&#22122;&#36807;&#31243;&#65292;&#22686;&#24378;&#29992;&#25143;&#21644;&#39033;&#30446;&#23884;&#20837;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06982</link><description>&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Denoising Diffusion Recommender Model. (arXiv:2401.06982v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06982
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#22122;&#25193;&#25955;&#25512;&#33616;&#27169;&#22411;&#65288;DDRM&#65289;&#65292;&#36890;&#36807;&#22312;&#25512;&#33616;&#27169;&#22411;&#20013;&#27880;&#20837;&#22122;&#22768;&#24182;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#22810;&#27493;&#21435;&#22122;&#36807;&#31243;&#65292;&#22686;&#24378;&#29992;&#25143;&#21644;&#39033;&#30446;&#23884;&#20837;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#38754;&#20020;&#30528;&#20855;&#26377;&#22122;&#22768;&#30340;&#38544;&#24335;&#21453;&#39304;&#38382;&#39064;&#12290;&#22823;&#22810;&#25968;&#30740;&#31350;&#20174;&#25968;&#25454;&#28165;&#27927;&#30340;&#35282;&#24230;&#32531;&#35299;&#22122;&#22768;&#38382;&#39064;&#65292;&#22914;&#25968;&#25454;&#37325;&#26032;&#37319;&#26679;&#21644;&#37325;&#26032;&#21152;&#26435;&#65292;&#20294;&#23427;&#20204;&#21463;&#21040;&#21551;&#21457;&#24335;&#20551;&#35774;&#30340;&#38480;&#21046;&#12290;&#21478;&#19968;&#31181;&#21435;&#22122;&#26041;&#27861;&#26159;&#20174;&#27169;&#22411;&#30340;&#35282;&#24230;&#65292;&#31215;&#26497;&#22320;&#21521;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#20013;&#27880;&#20837;&#22122;&#22768;&#65292;&#24182;&#22686;&#24378;&#27169;&#22411;&#30340;&#20869;&#22312;&#21435;&#22122;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#21435;&#22122;&#36807;&#31243;&#23545;&#25512;&#33616;&#27169;&#22411;&#30340;&#34920;&#31034;&#33021;&#21147;&#26469;&#25429;&#25417;&#22122;&#22768;&#27169;&#24335;&#25552;&#20986;&#20102;&#26174;&#33879;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#25512;&#33616;&#27169;&#22411;&#65288;DDRM&#65289;&#65292;&#23427;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#20351;&#29992;&#22810;&#27493;&#21435;&#22122;&#36807;&#31243;&#26469;&#22686;&#24378;&#26469;&#33258;&#20219;&#20309;&#25512;&#33616;&#27169;&#22411;&#30340;&#29992;&#25143;&#21644;&#39033;&#30446;&#23884;&#20837;&#30340;&#40065;&#26834;&#24615;&#12290;DDRM&#22312;&#21069;&#21521;&#36807;&#31243;&#20013;&#27880;&#20837;&#21463;&#25511;&#39640;&#26031;&#22122;&#22768;&#65292;&#24182;&#22312;&#21453;&#21521;&#21435;&#22122;&#36807;&#31243;&#20013;&#36845;&#20195;&#22320;&#21435;&#38500;&#22122;&#22768;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#22122;&#22768;&#21453;&#39304;&#30340;&#23884;&#20837;&#40065;&#26834;&#24615;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20851;&#38190;&#22312;&#20110;&#25552;&#20379;&#19968;&#31181;&#33021;&#22815;&#25429;&#25417;&#22122;&#22768;&#27169;&#24335;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#22810;&#27493;&#21435;&#22122;&#36807;&#31243;&#26469;&#25913;&#21892;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems often grapple with noisy implicit feedback. Most studies alleviate the noise issues from data cleaning perspective such as data resampling and reweighting, but they are constrained by heuristic assumptions. Another denoising avenue is from model perspective, which proactively injects noises into user-item interactions and enhance the intrinsic denoising ability of models. However, this kind of denoising process poses significant challenges to the recommender model's representation capacity to capture noise patterns. To address this issue, we propose Denoising Diffusion Recommender Model (DDRM), which leverages multi-step denoising process based on diffusion models to robustify user and item embeddings from any recommender models. DDRM injects controlled Gaussian noises in the forward process and iteratively removes noises in the reverse denoising process, thereby improving embedding robustness against noisy feedback. To achieve this target, the key lies in offering 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedDCSR&#30340;&#32852;&#37030;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#26469;&#22788;&#29702;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24207;&#21015;&#29305;&#24449;&#24322;&#36136;&#24615;&#65292;&#24182;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2309.08420</link><description>&lt;p&gt;
FedDCSR: &#36890;&#36807;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#23454;&#29616;&#32852;&#37030;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning. (arXiv:2309.08420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08420
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedDCSR&#30340;&#32852;&#37030;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#26469;&#22788;&#29702;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24207;&#21015;&#29305;&#24449;&#24322;&#36136;&#24615;&#65292;&#24182;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#39046;&#22495;&#30340;&#29992;&#25143;&#24207;&#21015;&#25968;&#25454;&#30340;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;(CSR)&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;CSR&#26041;&#27861;&#38656;&#35201;&#22312;&#39046;&#22495;&#20043;&#38388;&#20849;&#20139;&#21407;&#22987;&#29992;&#25143;&#25968;&#25454;&#65292;&#36825;&#36829;&#21453;&#20102;&#12298;&#36890;&#29992;&#25968;&#25454;&#20445;&#25252;&#26465;&#20363;&#12299;(GDPR)&#12290;&#22240;&#27492;&#65292;&#26377;&#24517;&#35201;&#23558;&#32852;&#37030;&#23398;&#20064;(FL)&#21644;CSR&#30456;&#32467;&#21512;&#65292;&#20805;&#20998;&#21033;&#29992;&#19981;&#21516;&#39046;&#22495;&#30340;&#30693;&#35782;&#65292;&#21516;&#26102;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24207;&#21015;&#29305;&#24449;&#24322;&#36136;&#24615;&#23545;FL&#30340;&#25972;&#20307;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FedDCSR&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#35299;&#20915;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24207;&#21015;&#29305;&#24449;&#24322;&#36136;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#39046;&#22495;&#20869;-&#39046;&#22495;&#38388;&#24207;&#21015;&#34920;&#31034;&#35299;&#32544;(SRD)&#30340;&#26041;&#27861;&#65292;&#23558;&#29992;&#25143;&#24207;&#21015;&#29305;&#24449;&#35299;&#32544;&#25104;&#39046;&#22495;&#20849;&#20139;&#21644;&#39046;&#22495;&#19987;&#23646;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-domain Sequential Recommendation (CSR) which leverages user sequence data from multiple domains has received extensive attention in recent years. However, the existing CSR methods require sharing origin user data across domains, which violates the General Data Protection Regulation (GDPR). Thus, it is necessary to combine federated learning (FL) and CSR to fully utilize knowledge from different domains while preserving data privacy. Nonetheless, the sequence feature heterogeneity across different domains significantly impacts the overall performance of FL. In this paper, we propose FedDCSR, a novel federated cross-domain sequential recommendation framework via disentangled representation learning. Specifically, to address the sequence feature heterogeneity across domains, we introduce an approach called inter-intra domain sequence representation disentanglement (SRD) to disentangle the user sequence features into domain-shared and domain-exclusive features. In addition, we design
&lt;/p&gt;</description></item></channel></rss>