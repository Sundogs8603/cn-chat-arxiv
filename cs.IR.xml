<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65288;COVE&#65289;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19979;&#30340;&#23454;&#20307;&#20998;&#31867;&#20449;&#24687;&#65292;&#24182;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16761</link><description>&lt;p&gt;
&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Co-evolving Vector Quantization for ID-based Recommendation. (arXiv:2308.16761v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16761
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65288;COVE&#65289;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19979;&#30340;&#23454;&#20307;&#20998;&#31867;&#20449;&#24687;&#65292;&#24182;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31867;&#21035;&#20449;&#24687;&#23545;&#20110;&#25552;&#39640;&#25512;&#33616;&#30340;&#36136;&#37327;&#21644;&#20010;&#24615;&#21270;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#20013;&#65292;&#39033;&#30446;&#31867;&#21035;&#20449;&#24687;&#30340;&#21487;&#29992;&#24615;&#24182;&#19981;&#19968;&#33268;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#20197;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#23454;&#20307;&#65288;&#21363;&#29992;&#25143;&#21644;&#39033;&#30446;&#65289;&#22312;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19978;&#30340;&#20998;&#31867;&#20449;&#24687;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65292;&#21363;COVE&#65292;&#23427;&#33021;&#22815;&#21516;&#26102;&#23398;&#20064;&#21644;&#25913;&#36827;&#20195;&#30721;&#34920;&#31034;&#21644;&#23454;&#20307;&#23884;&#20837;&#65292;&#24182;&#20197;&#20174;&#38543;&#26426;&#21021;&#22987;&#21270;&#29366;&#24577;&#24320;&#22987;&#30340;&#31471;&#21040;&#31471;&#26041;&#24335;&#36827;&#34892;&#12290;&#36890;&#36807;&#20854;&#39640;&#24230;&#36866;&#24212;&#24615;&#65292;COVE&#21487;&#20197;&#36731;&#26494;&#38598;&#25104;&#21040;&#29616;&#26377;&#30340;&#25512;&#33616;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;COVE&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#21015;&#34920;&#23436;&#25104;&#12289;&#21327;&#21516;&#36807;&#28388;&#21644;&#28857;&#20987;&#29575;&#39044;&#27979;&#65292;&#28085;&#30422;&#19981;&#21516;&#30340;&#25512;&#33616;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Category information plays a crucial role in enhancing the quality and personalization of recommendations. Nevertheless, the availability of item category information is not consistently present, particularly in the context of ID-based recommendations. In this work, we propose an alternative approach to automatically learn and generate entity (i.e., user and item) categorical information at different levels of granularity, specifically for ID-based recommendation. Specifically, we devise a co-evolving vector quantization framework, namely COVE, which enables the simultaneous learning and refinement of code representation and entity embedding in an end-to-end manner, starting from the randomly initialized states. With its high adaptability, COVE can be easily integrated into existing recommendation models. We validate the effectiveness of COVE on various recommendation tasks including list completion, collaborative filtering, and click-through rate prediction, across different recommend
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#65292;&#36890;&#36807;&#20174;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#30456;&#20284;&#26696;&#20363;&#24182;&#36873;&#25321;&#26368;&#31867;&#20284;&#30340;&#19978;&#19979;&#25991;&#26469;&#39044;&#27979;&#31572;&#26696;&#65292;&#20197;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#21644;&#26032;&#38395;&#38382;&#31572;&#20013;&#65292;CBR-MRC&#30340;&#20934;&#30830;&#24615;&#36229;&#36807;&#22522;&#20934;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#19982;&#20854;&#20182;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.14815</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Machine Reading Comprehension using Case-based Reasoning. (arXiv:2305.14815v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#65292;&#36890;&#36807;&#20174;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#30456;&#20284;&#26696;&#20363;&#24182;&#36873;&#25321;&#26368;&#31867;&#20284;&#30340;&#19978;&#19979;&#25991;&#26469;&#39044;&#27979;&#31572;&#26696;&#65292;&#20197;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#21644;&#26032;&#38395;&#38382;&#31572;&#20013;&#65292;CBR-MRC&#30340;&#20934;&#30830;&#24615;&#36229;&#36807;&#22522;&#20934;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#19982;&#20854;&#20182;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#30830;&#19988;&#21487;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20013;&#30340;&#31572;&#26696;&#25552;&#21462;&#65292;&#35813;&#26041;&#27861;&#31867;&#20284;&#20110;&#32463;&#20856;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#65288;CBR&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#22522;&#20110;&#19968;&#20010;&#20551;&#35774;&#65292;&#21363;&#30456;&#20284;&#38382;&#39064;&#30340;&#19978;&#19979;&#25991;&#21270;&#31572;&#26696;&#24444;&#27492;&#20043;&#38388;&#20855;&#26377;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#32473;&#23450;&#19968;&#20010;&#27979;&#35797;&#38382;&#39064;&#65292;CBR-MRC&#39318;&#20808;&#20174;&#38750;&#21442;&#25968;&#21270;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#19968;&#32452;&#30456;&#20284;&#30340;&#26696;&#20363;&#65292;&#28982;&#21518;&#36890;&#36807;&#36873;&#25321;&#27979;&#35797;&#19978;&#19979;&#25991;&#20013;&#26368;&#31867;&#20284;&#20110;&#26816;&#32034;&#21040;&#30340;&#26696;&#20363;&#20013;&#19978;&#19979;&#25991;&#21270;&#31572;&#26696;&#34920;&#31034;&#30340;&#33539;&#22260;&#26469;&#39044;&#27979;&#31572;&#26696;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21322;&#21442;&#25968;&#21270;&#30340;&#29305;&#24615;&#20351;&#20854;&#33021;&#22815;&#23558;&#39044;&#27979;&#24402;&#22240;&#20110;&#29305;&#23450;&#30340;&#35777;&#25454;&#26696;&#20363;&#38598;&#65292;&#22240;&#27492;&#22312;&#26500;&#24314;&#21487;&#38752;&#19988;&#21487;&#35843;&#35797;&#30340;&#38382;&#31572;&#31995;&#32479;&#26102;&#26159;&#19968;&#20010;&#29702;&#24819;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;CBR-MRC&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#65288;NaturalQuestions&#65289;&#21644;&#26032;&#38395;&#38382;&#31572;&#65288;NewsQA&#65289;&#19978;&#27604;&#22823;&#22411;&#35835;&#32773;&#27169;&#22411;&#25552;&#20379;&#20102;&#39640;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#20248;&#20110;&#22522;&#20934;&#20998;&#21035;&#25552;&#21319;&#20102;11.5&#21644;8.4 EM&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;CBR-MRC&#22312;&#35782;&#21035;&#19982;&#20182;&#20154;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an accurate and interpretable method for answer extraction in machine reading comprehension that is reminiscent of case-based reasoning (CBR) from classical AI. Our method (CBR-MRC) builds upon the hypothesis that contextualized answers to similar questions share semantic similarities with each other. Given a test question, CBR-MRC first retrieves a set of similar cases from a non-parametric memory and then predicts an answer by selecting the span in the test context that is most similar to the contextualized representations of answers in the retrieved cases. The semi-parametric nature of our approach allows it to attribute a prediction to the specific set of evidence cases, making it a desirable choice for building reliable and debuggable QA systems. We show that CBR-MRC provides high accuracy comparable with large reader models and outperforms baselines by 11.5 and 8.4 EM on NaturalQuestions and NewsQA, respectively. Further, we demonstrate the ability of CBR-MRC in identi
&lt;/p&gt;</description></item></channel></rss>