<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22269;&#38469;&#21327;&#35758;&#20013;&#33258;&#21160;&#21270;&#25552;&#21462;&#27491;&#24335;&#21046;&#24230;&#35774;&#35745;&#30340;&#30693;&#35782;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#20110;&#12298;&#26080;&#24418;&#25991;&#21270;&#36951;&#20135;&#20445;&#25252;&#20844;&#32422;&#12299;&#30340;&#27979;&#35797;&#20998;&#26512;&#20102;&#27491;&#24335;&#21046;&#24230;&#35774;&#35745;&#20013;&#21442;&#19982;&#32773;&#30340;&#21487;&#35265;&#24615;&#21644;&#37325;&#35201;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.16750</link><description>&lt;p&gt;
&#33258;&#21160;&#21270;&#22269;&#38469;&#21327;&#35758;&#20013;&#21046;&#24230;&#35774;&#35745;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Automating the Analysis of Institutional Design in International Agreements. (arXiv:2305.16750v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16750
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22269;&#38469;&#21327;&#35758;&#20013;&#33258;&#21160;&#21270;&#25552;&#21462;&#27491;&#24335;&#21046;&#24230;&#35774;&#35745;&#30340;&#30693;&#35782;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#20110;&#12298;&#26080;&#24418;&#25991;&#21270;&#36951;&#20135;&#20445;&#25252;&#20844;&#32422;&#12299;&#30340;&#27979;&#35797;&#20998;&#26512;&#20102;&#27491;&#24335;&#21046;&#24230;&#35774;&#35745;&#20013;&#21442;&#19982;&#32773;&#30340;&#21487;&#35265;&#24615;&#21644;&#37325;&#35201;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#22914;&#20309;&#33258;&#21160;&#22320;&#20174;&#22269;&#38469;&#21327;&#35758;&#20013;&#25552;&#21462;&#27491;&#24335;&#21046;&#24230;&#35774;&#35745;&#12289;&#35268;&#33539;&#12289;&#35268;&#21017;&#21644;&#21442;&#19982;&#32773;&#31561;&#30693;&#35782;&#12290;&#37325;&#28857;&#26159;&#20998;&#26512;&#35268;&#33539;&#25991;&#21270;&#36951;&#20135;&#20851;&#31995;&#20851;&#38190;&#26041;&#38754;&#30340;&#27491;&#24335;&#21046;&#24230;&#35774;&#35745;&#20013;&#21442;&#19982;&#32773;&#30340;&#21487;&#35265;&#24615;&#21644;&#37325;&#35201;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25152;&#24320;&#21457;&#30340;&#24037;&#20855;&#37319;&#29992;&#20102;&#22810;&#31181;&#25216;&#26415;&#65292;&#22914;&#25910;&#38598;&#27861;&#24459;&#25991;&#20214;&#12289;&#29992;&#21046;&#24230;&#35821;&#27861;&#27880;&#37322;&#36825;&#20123;&#25991;&#20214;&#24182;&#20351;&#29992;&#22270;&#20998;&#26512;&#26041;&#27861;&#26469;&#25506;&#32034;&#27491;&#24335;&#21046;&#24230;&#35774;&#35745;&#12290;&#35813;&#31995;&#32479;&#23545;2003&#24180;&#12298;&#26080;&#24418;&#25991;&#21270;&#36951;&#20135;&#20445;&#25252;&#20844;&#32422;&#12299;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the automatic knowledge extraction of formal institutional design - norms, rules, and actors - from international agreements. The focus was to analyze the relationship between the visibility and centrality of actors in the formal institutional design in regulating critical aspects of cultural heritage relations. The developed tool utilizes techniques such as collecting legal documents, annotating them with Institutional Grammar, and using graph analysis to explore the formal institutional design. The system was tested against the 2003 UNESCO Convention for the Safeguarding of the Intangible Cultural Heritage.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#20449;&#24687;&#26816;&#32034;&#21338;&#24328;&#35770;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#20197;&#36798;&#25104;&#26356;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#35777;&#26126;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.16695</link><description>&lt;p&gt;
&#23547;&#27714;&#31283;&#23450;&#24615;&#65306;&#20855;&#26377;&#21021;&#22987;&#25991;&#20214;&#30340;&#25112;&#30053;&#20986;&#29256;&#21830;&#30340;&#23398;&#20064;&#21160;&#24577;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Search for Stability: Learning Dynamics of Strategic Publishers with Initial Documents. (arXiv:2305.16695v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#20449;&#24687;&#26816;&#32034;&#21338;&#24328;&#35770;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#20197;&#36798;&#25104;&#26356;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#35777;&#26126;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20449;&#24687;&#26816;&#32034;&#30340;&#21338;&#24328;&#35770;&#27169;&#22411;&#65292;&#20854;&#20013;&#25112;&#30053;&#20986;&#29256;&#21830;&#26088;&#22312;&#22312;&#20445;&#25345;&#21407;&#22987;&#25991;&#26723;&#23436;&#25972;&#24615;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#33258;&#24049;&#25490;&#21517;&#31532;&#19968;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24120;&#29992;&#30340;PRP&#25490;&#21517;&#26041;&#26696;&#23548;&#33268;&#29615;&#22659;&#19981;&#31283;&#23450;&#65292;&#28216;&#25103;&#32463;&#24120;&#26080;&#27861;&#36798;&#21040;&#32431;&#32435;&#20160;&#22343;&#34913;&#12290;&#25105;&#20204;&#23558;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#24182;&#20171;&#32461;&#20004;&#20010;&#25490;&#21517;&#20989;&#25968;&#65292;&#23427;&#20204;&#26159;RRP&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#65292;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#23548;&#33268;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#30340;&#31215;&#26497;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23450;&#20041;&#20986;&#29256;&#21830;&#21644;&#29992;&#25143;&#30340;&#31119;&#21033;&#65292;&#24182;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#65292;&#31361;&#26174;&#20102;&#30830;&#23450;&#25628;&#32034;&#24341;&#25806;&#35774;&#35745;&#24072;&#24212;&#36873;&#25321;&#21738;&#31181;&#25490;&#21517;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a game-theoretic model of information retrieval, in which strategic publishers aim to maximize their chances of being ranked first by the search engine, while maintaining the integrity of their original documents. We show that the commonly used PRP ranking scheme results in an unstable environment where games often fail to reach pure Nash equilibrium. We propose the Relative Ranking Principle (RRP) as an alternative ranking principle, and introduce two ranking functions that are instances of the RRP. We provide both theoretical and empirical evidence that these methods lead to a stable search ecosystem, by providing positive results on the learning dynamics convergence. We also define the publishers' and users' welfare, and demonstrate a possible publisher-user trade-off, which highlights the complexity of determining which ranking function should be selected by the search engine designer.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;&#21512;&#25104;&#26631;&#35782;&#31526;&#30340;&#22810;&#35270;&#35282;&#26631;&#35782;&#31526;&#26469;&#22686;&#24378;&#29983;&#25104;&#24335;&#26816;&#32034;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#26816;&#32034;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.16675</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#26631;&#35782;&#22686;&#24378;&#29983;&#25104;&#24335;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Multiview Identifiers Enhanced Generative Retrieval. (arXiv:2305.16675v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16675
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;&#21512;&#25104;&#26631;&#35782;&#31526;&#30340;&#22810;&#35270;&#35282;&#26631;&#35782;&#31526;&#26469;&#22686;&#24378;&#29983;&#25104;&#24335;&#26816;&#32034;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#26816;&#32034;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20854;&#31616;&#21333;&#22320;&#23558;&#26597;&#35810;&#19982;&#29616;&#26377;&#27573;&#33853;&#21305;&#37197;&#65292;&#29983;&#25104;&#24335;&#26816;&#32034;&#29983;&#25104;&#27573;&#33853;&#30340;&#26631;&#35782;&#31526;&#23383;&#31526;&#20018;&#20316;&#20026;&#26816;&#32034;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26631;&#35782;&#31526;&#24517;&#39035;&#36275;&#22815;&#29420;&#29305;&#20197;&#20195;&#34920;&#19968;&#20010;&#27573;&#33853;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#20351;&#29992;&#25968;&#23383;ID&#25110;&#25991;&#26412;&#29255;&#27573;&#65288;&#22914;&#26631;&#39064;&#25110;&#23376;&#23383;&#31526;&#20018;&#65289;&#20316;&#20026;&#26631;&#35782;&#31526;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26631;&#35782;&#31526;&#19981;&#33021;&#24456;&#22909;&#22320;&#35206;&#30422;&#19968;&#20010;&#27573;&#33853;&#30340;&#20869;&#23481;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31867;&#22411;&#30340;&#26631;&#35782;&#31526;&#65292;&#21363;&#22522;&#20110;&#27573;&#33853;&#20869;&#23481;&#29983;&#25104;&#30340;&#21512;&#25104;&#26631;&#35782;&#31526;&#65292;&#21487;&#20197;&#25972;&#21512;&#25991;&#26412;&#29255;&#27573;&#32570;&#20047;&#30340;&#24773;&#22659;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21516;&#26102;&#32771;&#34385;&#22810;&#35270;&#35282;&#26631;&#35782;&#31526;&#65292;&#21253;&#25324;&#21512;&#25104;&#26631;&#35782;&#31526;&#12289;&#26631;&#39064;&#21644;&#23376;&#23383;&#31526;&#20018;&#12290;&#36825;&#20123;&#26631;&#35782;&#31526;&#30340;&#35270;&#35282;&#30456;&#20114;&#34917;&#20805;&#65292;&#26377;&#21161;&#20110;&#20174;&#22810;&#20010;&#35282;&#24230;&#32508;&#21512;&#25490;&#21517;&#27573;&#33853;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#29983;&#25104;&#24335;&#26816;&#32034;&#20013;&#34920;&#29616;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;
Instead of simply matching a query to pre-existing passages, generative retrieval generates identifier strings of passages as the retrieval target. At a cost, the identifier must be distinctive enough to represent a passage. Current approaches use either a numeric ID or a text piece (such as a title or substrings) as the identifier. However, these identifiers cannot cover a passage's content well. As such, we are motivated to propose a new type of identifier, synthetic identifiers, that are generated based on the content of a passage and could integrate contextualized information that text pieces lack. Furthermore, we simultaneously consider multiview identifiers, including synthetic identifiers, titles, and substrings. These views of identifiers complement each other and facilitate the holistic ranking of passages from multiple perspectives. We conduct a series of experiments on three public datasets, and the results indicate that our proposed approach performs the best in generative 
&lt;/p&gt;</description></item><item><title>FARA&#26159;&#19968;&#31181;&#26410;&#26469;&#24863;&#30693;&#30340;&#20844;&#24179;&#20248;&#21270;&#25490;&#21517;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#22810;&#20010;&#25490;&#21517;&#21015;&#34920;&#24182;&#23558;&#20854;&#20445;&#23384;&#21040;&#26410;&#26469;&#30340;&#20250;&#35805;&#20013;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#20844;&#24179;&#24615;&#21644;&#30456;&#20851;&#24615;&#24046;&#24322;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;FARA&#22312;&#25490;&#21517;&#30456;&#20851;&#24615;&#21644;&#20844;&#24179;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.16637</link><description>&lt;p&gt;
FARA: &#26410;&#26469;&#24863;&#30693;&#30340;&#20844;&#24179;&#20248;&#21270;&#25490;&#21517;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
FARA: Future-aware Ranking Algorithm for Fairness Optimization. (arXiv:2305.16637v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16637
&lt;/p&gt;
&lt;p&gt;
FARA&#26159;&#19968;&#31181;&#26410;&#26469;&#24863;&#30693;&#30340;&#20844;&#24179;&#20248;&#21270;&#25490;&#21517;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#22810;&#20010;&#25490;&#21517;&#21015;&#34920;&#24182;&#23558;&#20854;&#20445;&#23384;&#21040;&#26410;&#26469;&#30340;&#20250;&#35805;&#20013;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#20844;&#24179;&#24615;&#21644;&#30456;&#20851;&#24615;&#24046;&#24322;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;FARA&#22312;&#25490;&#21517;&#30456;&#20851;&#24615;&#21644;&#20844;&#24179;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#21517;&#31995;&#32479;&#26159;&#29616;&#20195;&#20449;&#24687;&#26816;&#32034;&#24212;&#29992;&#65288;&#20363;&#22914;&#25628;&#32034;&#24341;&#25806;&#21644;&#25512;&#33616;&#31995;&#32479;&#65289;&#30340;&#20851;&#38190;&#32452;&#20214;&#12290;&#38500;&#20102;&#19982;&#29992;&#25143;&#30456;&#20851;&#30340;&#25490;&#21517;&#30456;&#20851;&#24615;&#22806;&#65292;&#21521;&#39033;&#30446;&#25552;&#20379;&#32773;&#20844;&#24179;&#30340;&#26333;&#20809;&#24230;&#20063;&#34987;&#35748;&#20026;&#26159;&#25490;&#21517;&#20248;&#21270;&#30340;&#37325;&#35201;&#22240;&#32032;&#12290;&#35768;&#22810;&#20844;&#24179;&#25490;&#21517;&#31639;&#27861;&#24050;&#34987;&#25552;&#20986;&#20197;&#32852;&#21512;&#20248;&#21270;&#25490;&#21517;&#30456;&#20851;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#20844;&#24179;&#25490;&#21517;&#26041;&#27861;&#37319;&#29992;&#36138;&#24515;&#31639;&#27861;&#65292;&#20165;&#38024;&#23545;&#19979;&#19968;&#20010;&#21363;&#26102;&#20250;&#35805;&#25110;&#35831;&#27714;&#20248;&#21270;&#25490;&#21517;&#12290;&#27491;&#22914;&#26412;&#25991;&#25152;&#31034;&#65292;&#36825;&#31181;&#30701;&#35270;&#30340;&#33539;&#24335;&#21487;&#33021;&#38480;&#21046;&#25490;&#21517;&#20248;&#21270;&#30340;&#19978;&#38480;&#65292;&#24182;&#23548;&#33268;&#38271;&#26399;&#30340;&#27425;&#20248;&#24615;&#33021;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FARA&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#26410;&#26469;&#24863;&#30693;&#25490;&#21517;&#31639;&#27861;&#65292;&#29992;&#20110;&#25490;&#21517;&#30456;&#20851;&#24615;&#21644;&#20844;&#24179;&#20248;&#21270;&#12290;FARA&#19981;&#26159;&#36138;&#23146;&#22320;&#20248;&#21270;&#19979;&#19968;&#20010;&#20250;&#35805;&#30340;&#25490;&#21517;&#65292;&#32780;&#26159;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#22810;&#20010;&#25490;&#21517;&#21015;&#34920;&#24182;&#23558;&#23427;&#20204;&#20445;&#23384;&#21040;&#26410;&#26469;&#20250;&#35805;&#20013;&#65292;&#26469;&#25552;&#21069;&#35268;&#21010;&#12290;&#29305;&#21035;&#22320;&#65292;FARA&#26088;&#22312;&#26368;&#23567;&#21270;&#25490;&#21517;&#21015;&#34920;&#30340;&#20844;&#24179;&#24615;&#21644;&#30456;&#20851;&#24615;&#24046;&#24322;&#65292;&#24182;&#32771;&#34385;&#26410;&#26469;&#20250;&#35805;&#23545;&#24403;&#21069;&#25490;&#21517;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;FARA&#22312;&#25490;&#21517;&#30456;&#20851;&#24615;&#21644;&#20844;&#24179;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#20844;&#24179;&#25490;&#21517;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ranking systems are the key components of modern Information Retrieval (IR) applications, such as search engines and recommender systems. Besides the ranking relevance to users, the exposure fairness to item providers has also been considered an important factor in ranking optimization. Many fair ranking algorithms have been proposed to jointly optimize both ranking relevance and fairness. However, we find that most existing fair ranking methods adopt greedy algorithms that only optimize rankings for the next immediate session or request. As shown in this paper, such a myopic paradigm could limit the upper bound of ranking optimization and lead to suboptimal performance in the long term. To this end, we propose FARA, a novel Future-Aware Ranking Algorithm for ranking relevance and fairness optimization. Instead of greedily optimizing rankings for the next immediate session, FARA plans ahead by jointly optimizing multiple ranklists together and saving them for future sessions. Particula
&lt;/p&gt;</description></item><item><title>DataFinder&#33021;&#22815;&#26681;&#25454;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#25512;&#33616;&#30456;&#20851;&#25968;&#25454;&#38598;&#65292;&#35299;&#20915;&#31185;&#23398;&#23478;&#22312;&#29616;&#26377;&#25968;&#25454;&#38598;&#20013;&#23547;&#25214;&#21512;&#36866;&#25968;&#25454;&#38598;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2305.16636</link><description>&lt;p&gt;
DataFinder: &#20174;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#20013;&#25512;&#33616;&#31185;&#23398;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions. (arXiv:2305.16636v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16636
&lt;/p&gt;
&lt;p&gt;
DataFinder&#33021;&#22815;&#26681;&#25454;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#25512;&#33616;&#30456;&#20851;&#25968;&#25454;&#38598;&#65292;&#35299;&#20915;&#31185;&#23398;&#23478;&#22312;&#29616;&#26377;&#25968;&#25454;&#38598;&#20013;&#23547;&#25214;&#21512;&#36866;&#25968;&#25454;&#38598;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20381;&#36182;&#20110;&#25968;&#25454;&#38598;&#26469;&#24320;&#21457;&#21644;&#39564;&#35777;&#30740;&#31350;&#24819;&#27861;&#12290;&#37492;&#20110;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#30340;&#22686;&#38271;&#65292;&#25214;&#21040;&#21512;&#36866;&#30340;&#25968;&#25454;&#38598;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#12290;&#20219;&#20309;&#30740;&#31350;&#38382;&#39064;&#23545;&#33021;&#22815;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#30340;&#25968;&#25454;&#38598;&#30340;&#35201;&#27714;&#37117;&#26377;&#26126;&#30830;&#21644;&#38544;&#21547;&#30340;&#38480;&#21046;&#65292;&#20363;&#22914;&#25968;&#25454;&#38598;&#22823;&#23567;&#12289;&#27169;&#24577;&#21644;&#39046;&#22495;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#39033;&#26032;&#20219;&#21153;&#65292;&#21363;&#22312;&#32473;&#23450;&#19968;&#20010;&#30740;&#31350;&#24819;&#27861;&#30340;&#31616;&#30701;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#24773;&#20917;&#19979;&#25512;&#33616;&#30456;&#20851;&#25968;&#25454;&#38598;&#65292;&#20197;&#24110;&#21161;&#20154;&#20204;&#25214;&#21040;&#31526;&#21512;&#20182;&#20204;&#38656;&#27714;&#30340;&#30456;&#20851;&#25968;&#25454;&#38598;&#12290;&#25968;&#25454;&#38598;&#25512;&#33616;&#23384;&#22312;&#29420;&#29305;&#30340;&#20449;&#24687;&#26816;&#32034;&#38382;&#39064;&#65292;&#25968;&#25454;&#38598;&#24456;&#38590;&#30452;&#25509;&#32034;&#24341;&#36827;&#34892;&#25628;&#32034;&#65292;&#20063;&#27809;&#26377;&#29616;&#25104;&#30340;&#35821;&#26009;&#24211;&#29992;&#20110;&#36825;&#20010;&#20219;&#21153;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;DataFinder&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#33258;&#21160;&#26500;&#24314;&#30340;&#36739;&#22823;&#35757;&#32451;&#38598;&#65288;17500&#20010;&#26597;&#35810;&#65289;&#21644;&#19968;&#20010;&#36739;&#23567;&#30340;&#19987;&#23478;&#27880;&#37322;&#30340;&#35780;&#20272;&#38598;&#65288;392&#20010;&#26597;&#35810;&#65289;&#12290;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#21508;&#31181;&#20449;&#24687;&#26816;&#32034;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning relies on datasets to develop and validate research ideas. Given the growth of publicly available data, finding the right dataset to use is increasingly difficult. Any research question imposes explicit and implicit constraints on how well a given dataset will enable researchers to answer this question, such as dataset size, modality, and domain. We introduce a new task of recommending relevant datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs. Dataset recommendation poses unique challenges as an information retrieval problem; datasets are hard to directly index for search and there are no corpora readily available for this task. To operationalize this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries). Using this data, we compare various information retrieval 
&lt;/p&gt;</description></item><item><title>CARAMEL&#26159;&#19968;&#31181;&#22522;&#20110;&#38745;&#24577;&#20989;&#25968;&#26500;&#24314;&#25216;&#26415;&#30340;&#31354;&#38388;&#39640;&#25928;&#30340;&#21482;&#35835;&#26597;&#25214;&#34920;&#65292;&#19987;&#38376;&#29992;&#20110;&#22788;&#29702;&#20540;&#26159;&#22810;&#38598;&#21512;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2305.16545</link><description>&lt;p&gt;
CARAMEL&#65306;&#36890;&#36807;&#21387;&#32553;&#38745;&#24577;&#20989;&#25968;&#23454;&#29616;&#30340;&#31616;&#27905;&#21482;&#35835;&#26597;&#25214;&#34920;
&lt;/p&gt;
&lt;p&gt;
CARAMEL: A Succinct Read-Only Lookup Table via Compressed Static Functions. (arXiv:2305.16545v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16545
&lt;/p&gt;
&lt;p&gt;
CARAMEL&#26159;&#19968;&#31181;&#22522;&#20110;&#38745;&#24577;&#20989;&#25968;&#26500;&#24314;&#25216;&#26415;&#30340;&#31354;&#38388;&#39640;&#25928;&#30340;&#21482;&#35835;&#26597;&#25214;&#34920;&#65292;&#19987;&#38376;&#29992;&#20110;&#22788;&#29702;&#20540;&#26159;&#22810;&#38598;&#21512;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#25214;&#34920;&#26159;&#35768;&#22810;&#25968;&#25454;&#22788;&#29702;&#21644;&#31995;&#32479;&#24212;&#29992;&#31243;&#24207;&#20013;&#30340;&#22522;&#26412;&#32467;&#26500;&#12290;&#38543;&#30528;&#32593;&#32476;&#35268;&#27169;&#36234;&#26469;&#36234;&#22823;&#65292;&#36825;&#20123;&#24212;&#29992;&#31243;&#24207;&#32463;&#24120;&#38656;&#35201;&#21387;&#32553;&#25216;&#26415;&#26469;&#25903;&#25345;&#24555;&#36895;&#38543;&#26426;O&#65288;1&#65289;&#26597;&#25214;&#21387;&#32553;&#25968;&#25454;&#20013;&#30340;&#21333;&#20010;&#21442;&#25968;&#65288;&#21363;&#22312;RAM&#20013;&#36827;&#34892;&#22359;&#35299;&#21387;&#32553;&#65289;&#12290;&#21463;&#26368;&#36817;&#38745;&#24577;&#20989;&#25968;&#26500;&#24314;&#25216;&#26415;&#30340;&#36827;&#23637;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CARAMEL&#30340;&#31354;&#38388;&#39640;&#25928;&#30340;&#19981;&#21487;&#21464;&#38190;&#20540;&#25968;&#25454;&#34920;&#31034;&#65292;&#19987;&#38376;&#38024;&#23545;&#20540;&#26159;&#22810;&#38598;&#21512;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lookup tables are a fundamental structure in many data processing and systems applications. Examples include tokenized text in NLP, quantized embedding collections in recommendation systems, integer sketches for streaming data, and hash-based string representations in genomics. With the increasing size of web-scale data, such applications often require compression techniques that support fast random $O(1)$ lookup of individual parameters directly on the compressed data (i.e. without blockwise decompression in RAM). While the community has proposd a number of succinct data structures that support queries over compressed representations, these approaches do not fully leverage the low-entropy structure prevalent in real-world workloads to reduce space. Inspired by recent advances in static function construction techniques, we propose a space-efficient representation of immutable key-value data, called CARAMEL, specifically designed for the case where the values are multi-sets. By carefull
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#26080;&#27169;&#22411;&#25968;&#25454;&#23376;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#29992;&#25143;-&#29289;&#21697;&#22270;&#30340;&#25299;&#25169;&#32467;&#26500;&#26469;&#20272;&#35745;&#27599;&#20010;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#20256;&#25773;&#26469;&#24179;&#28369;&#20272;&#35745;&#20540;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#26080;&#27169;&#22411;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#23376;&#37319;&#26679;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.16391</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#26080;&#27169;&#22411;&#25968;&#25454;&#23376;&#37319;&#26679;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Graph-Based Model-Agnostic Data Subsampling for Recommendation Systems. (arXiv:2305.16391v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#26080;&#27169;&#22411;&#25968;&#25454;&#23376;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#29992;&#25143;-&#29289;&#21697;&#22270;&#30340;&#25299;&#25169;&#32467;&#26500;&#26469;&#20272;&#35745;&#27599;&#20010;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#20256;&#25773;&#26469;&#24179;&#28369;&#20272;&#35745;&#20540;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#26080;&#27169;&#22411;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#23376;&#37319;&#26679;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#23376;&#37319;&#26679;&#24191;&#27867;&#29992;&#20110;&#21152;&#36895;&#35757;&#32451;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#12290;&#22823;&#22810;&#25968;&#23376;&#37319;&#26679;&#26041;&#27861;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#65292;&#24120;&#24120;&#38656;&#35201;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;&#35797;&#39564;&#27169;&#22411;&#26469;&#36890;&#36807;&#26679;&#26412;&#38590;&#24230;&#31561;&#26041;&#24335;&#27979;&#37327;&#25968;&#25454;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#35797;&#39564;&#27169;&#22411;&#34987;&#38169;&#35823;&#25351;&#23450;&#26102;&#65292;&#22522;&#20110;&#27169;&#22411;&#30340;&#23376;&#37319;&#26679;&#26041;&#27861;&#23558;&#20250;&#24694;&#21270;&#12290;&#37492;&#20110;&#35797;&#39564;&#27169;&#22411;&#30340;&#38169;&#35823;&#25351;&#23450;&#22312;&#30495;&#23454;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#32467;&#26500;&#65292;&#21363;&#22270;&#24418;&#26469;&#25506;&#32034;&#30340;&#26080;&#27169;&#22411;&#25968;&#25454;&#23376;&#37319;&#26679;&#26041;&#27861;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30740;&#31350;&#29992;&#25143;-&#29289;&#21697;&#22270;&#30340;&#25299;&#25169;&#32467;&#26500;&#65292;&#36890;&#36807;&#22270;&#23548;&#30005;&#24615;&#26469;&#20272;&#35745;&#27599;&#20010;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#65288;&#21363;&#29992;&#25143;-&#29289;&#21697;&#22270;&#20013;&#30340;&#19968;&#26465;&#36793;&#65289;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#20256;&#25773;&#27493;&#39588;&#65292;&#24179;&#28369;&#20272;&#35745;&#30340;&#37325;&#35201;&#24615;&#20540;&#12290;&#30001;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#26080;&#27169;&#22411;&#30340;&#65292;&#22240;&#27492;&#25105;&#20204;&#21487;&#20197;&#23558;&#26080;&#27169;&#22411;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#23376;&#37319;&#26679;&#26041;&#27861;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#32452;&#21512;&#20351;&#29992;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#22343;&#27604;&#20219;&#20309;&#21333;&#19968;&#26041;&#27861;&#37117;&#35201;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data subsampling is widely used to speed up the training of large-scale recommendation systems. Most subsampling methods are model-based and often require a pre-trained pilot model to measure data importance via e.g. sample hardness. However, when the pilot model is misspecified, model-based subsampling methods deteriorate. Since model misspecification is persistent in real recommendation systems, we instead propose model-agnostic data subsampling methods by only exploring input data structure represented by graphs. Specifically, we study the topology of the user-item graph to estimate the importance of each user-item interaction (an edge in the user-item graph) via graph conductance, followed by a propagation step on the network to smooth out the estimated importance value.  Since our proposed method is model-agnostic, we can marry the merits of both model-agnostic and model-based subsampling methods. Empirically, we show that combing the two consistently improves over any single meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GPT-3&#21644;GPT-4&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#34920;&#29616;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#21487;&#33021;&#20135;&#29983;&#30340;&#38169;&#35823;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2305.16326</link><description>&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#22522;&#20934;&#12289;&#22522;&#32447;&#21644;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GPT-3&#21644;GPT-4&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#34920;&#29616;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#21487;&#33021;&#20135;&#29983;&#30340;&#38169;&#35823;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#25163;&#21160;&#31579;&#36873;&#21644;&#25552;&#21462;&#30693;&#35782;&#21464;&#24471;&#22256;&#38590;&#12290;&#33258;&#21160;&#20174;&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;BioNLP&#65289;&#25216;&#26415;&#26377;&#21161;&#20110;&#20943;&#36731;&#36825;&#31181;&#36127;&#25285;&#12290;&#36817;&#24180;&#26469;&#65292;&#22914;GPT-3&#21644;GPT-4&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22240;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#32780;&#21463;&#21040;&#37325;&#35270;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#22312;BioNLP&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#23545;&#26041;&#27861;&#24320;&#21457;&#21644;&#19979;&#28216;&#29992;&#25143;&#30340;&#24433;&#21709;&#20173;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#65288;1&#65289;&#22312;&#22235;&#20010;&#24212;&#29992;&#31243;&#24207;&#20013;&#22312;&#20843;&#20010;BioNLP&#25968;&#25454;&#38598;&#20013;&#24314;&#31435;&#20102;GPT-3&#21644;GPT-4&#22312;&#38646;-shot&#21644;&#19968;-shot&#35774;&#32622;&#19979;&#30340;&#22522;&#20934;&#34920;&#29616;&#65292;&#21253;&#25324;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65292;&#20851;&#31995;&#25552;&#21462;&#65292;&#22810;&#26631;&#31614;&#25991;&#26723;&#20998;&#31867;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#21644;&#25512;&#29702;&#65307;&#65288;2&#65289;&#23457;&#26597;&#20102;LLMs&#20135;&#29983;&#30340;&#38169;&#35823;&#65292;&#24182;&#23558;&#38169;&#35823;&#20998;&#20026;&#19977;&#31181;&#31867;&#22411;&#65306;&#32570;&#22833;&#65292;&#19981;&#19968;&#33268;&#21644;&#19981;&#38656;&#35201;&#30340;&#20154;&#24037;&#20869;&#23481;&#65307;&#65288;3&#65289;&#25552;&#20986;&#20102;&#20351;&#29992;LLMs&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#20250;&#35805;&#25628;&#32034;&#30340;ConvGQR&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#37325;&#26032;&#26500;&#36896;&#26597;&#35810;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2305.15645</link><description>&lt;p&gt;
ConvGQR&#65306;&#38754;&#21521;&#20250;&#35805;&#25628;&#32034;&#30340;&#29983;&#25104;&#24335;&#26597;&#35810;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
ConvGQR: Generative Query Reformulation for Conversational Search. (arXiv:2305.15645v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15645
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#20250;&#35805;&#25628;&#32034;&#30340;ConvGQR&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#37325;&#26032;&#26500;&#36896;&#26597;&#35810;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20250;&#35805;&#25628;&#32034;&#20013;&#65292;&#29992;&#25143;&#24403;&#21069;&#25628;&#32034;&#24847;&#22270;&#20381;&#36182;&#20110;&#20808;&#21069;&#30340;&#23545;&#35805;&#21382;&#21490;&#12290;&#20174;&#25972;&#20010;&#23545;&#35805;&#19978;&#19979;&#25991;&#20013;&#30830;&#23450;&#19968;&#20010;&#33391;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#36991;&#20813;&#26597;&#35810;&#32534;&#30721;&#22120;&#30340;&#26114;&#36149;&#37325;&#26032;&#35757;&#32451;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#26041;&#27861;&#23581;&#35797;&#23398;&#20064;&#19968;&#20010;&#37325;&#20889;&#27169;&#22411;&#65292;&#36890;&#36807;&#27169;&#20223;&#25163;&#21160;&#26597;&#35810;&#37325;&#20889;&#26469;&#21435;&#38500;&#24403;&#21069;&#26597;&#35810;&#30340;&#19978;&#19979;&#25991;&#12290;&#28982;&#32780;&#65292;&#25163;&#21160;&#37325;&#20889;&#30340;&#26597;&#35810;&#24182;&#19981;&#24635;&#26159;&#26368;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;&#35757;&#32451;&#37325;&#20889;&#27169;&#22411;&#20250;&#38480;&#21046;&#27169;&#22411;&#20135;&#29983;&#33391;&#22909;&#25628;&#32034;&#26597;&#35810;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;ConvGQR&#65292;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#65292;&#19968;&#20010;&#29992;&#20110;&#26597;&#35810;&#37325;&#20889;&#65292;&#21478;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#28508;&#22312;&#31572;&#26696;&#65292;&#20197;&#37325;&#26032;&#26500;&#36896;&#20250;&#35805;&#26597;&#35810;&#12290;&#36890;&#36807;&#32467;&#21512;&#20004;&#32773;&#65292;ConvGQR&#21487;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#23558;&#26597;&#35810;&#37325;&#26500;&#19982;&#26816;&#32034;&#24615;&#33021;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#24449;&#36873;&#25321;&#30340;&#30456;&#20284;&#24230;&#20998;&#25968;&#27169;&#22411;&#65292;&#29992;&#20110;&#39564;&#35777;ConvGQR&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In conversational search, the user's real search intent for the current turn is dependent on the previous conversation history. It is challenging to determine a good search query from the whole conversation context. To avoid the expensive re-training of the query encoder, most existing methods try to learn a rewriting model to de-contextualize the current query by mimicking the manual query rewriting. However, manually rewritten queries are not always the best search queries. Training a rewriting model on them would limit the model's ability to produce good search queries. Another useful hint is the potential answer to the question. In this paper, we propose ConvGQR, a new framework to reformulate conversational queries based on generative pre-trained language models (PLMs), one for query rewriting and another for generating potential answers. By combining both, ConvGQR can produce better search queries. In addition, to relate query reformulation to retrieval performance, we propose a 
&lt;/p&gt;</description></item><item><title>&#20026;&#20102;&#25913;&#21892;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20195;&#34920;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#22810;&#26679;&#21270;&#26041;&#27861;&#65292;&#24182;&#22312;Pinterest&#24179;&#21488;&#19978;&#23454;&#39564;&#21644;&#37096;&#32626;&#20102;&#21487;&#25193;&#23637;&#30340;&#22810;&#26679;&#21270;&#26426;&#21046;&#65292;&#20197;&#25913;&#21892;&#32654;&#23481;&#21644;&#26102;&#23578;&#31867;&#21035;&#20013;&#19981;&#21516;&#32932;&#33394;&#30340;&#20195;&#34920;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15534</link><description>&lt;p&gt;
&#22312;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#22312;&#32447;&#34920;&#31034;&#24456;&#37325;&#35201;&#65306;&#23454;&#29992;&#30340;&#31471;&#21040;&#31471;&#22810;&#26679;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation Online Matters: Practical End-to-End Diversification in Search and Recommender Systems. (arXiv:2305.15534v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15534
&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25913;&#21892;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20195;&#34920;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#22810;&#26679;&#21270;&#26041;&#27861;&#65292;&#24182;&#22312;Pinterest&#24179;&#21488;&#19978;&#23454;&#39564;&#21644;&#37096;&#32626;&#20102;&#21487;&#25193;&#23637;&#30340;&#22810;&#26679;&#21270;&#26426;&#21046;&#65292;&#20197;&#25913;&#21892;&#32654;&#23481;&#21644;&#26102;&#23578;&#31867;&#21035;&#20013;&#19981;&#21516;&#32932;&#33394;&#30340;&#20195;&#34920;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;&#32447;&#24179;&#21488;&#22312;&#21508;&#20010;&#20154;&#21475;&#32479;&#35745;&#23398;&#20013;&#30340;&#20351;&#29992;&#19981;&#26029;&#22686;&#38271;&#65292;&#29992;&#25143;&#32463;&#24120;&#34920;&#36798;&#24076;&#26395;&#22312;&#20869;&#23481;&#20013;&#24863;&#21463;&#21040;&#33258;&#24049;&#30340;&#20195;&#34920;&#24615;&#12290;&#20026;&#20102;&#25913;&#21892;&#25628;&#32034;&#32467;&#26524;&#21644;&#25512;&#33616;&#20013;&#30340;&#20195;&#34920;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31471;&#21040;&#31471;&#30340;&#22810;&#26679;&#21270;&#26041;&#27861;&#65292;&#30830;&#20445;&#22810;&#26679;&#21270;&#20869;&#23481;&#22312;&#36825;&#20123;&#31995;&#32479;&#30340;&#21508;&#20010;&#38454;&#27573;&#20013;&#27969;&#21160;&#65292;&#20174;&#26816;&#32034;&#21040;&#25490;&#24207;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;Pinterest&#24179;&#21488;&#30340;&#29983;&#20135;&#30028;&#38754;&#20013;&#24320;&#21457;&#12289;&#23454;&#39564;&#21644;&#37096;&#32626;&#21487;&#25193;&#23637;&#30340;&#22810;&#26679;&#21270;&#26426;&#21046;&#65292;&#21253;&#25324;&#25628;&#32034;&#12289;&#30456;&#20851;&#20135;&#21697;&#21644;&#26032;&#29992;&#25143;&#20027;&#39029;&#65292;&#20197;&#25913;&#21892;&#32654;&#23481;&#21644;&#26102;&#23578;&#20869;&#23481;&#20013;&#19981;&#21516;&#32932;&#33394;&#30340;&#20195;&#34920;&#24615;&#12290;&#29983;&#20135;&#31995;&#32479;&#20013;&#30340;&#22810;&#26679;&#21270;&#21253;&#25324;&#19977;&#20010;&#32452;&#25104;&#37096;&#20998;&#65306;&#30830;&#23450;&#20250;&#35302;&#21457;&#22810;&#26679;&#21270;&#30340;&#35831;&#27714;&#65292;&#22312;&#26816;&#32034;&#38454;&#27573;&#30830;&#20445;&#20174;&#22823;&#22411;&#20869;&#23481;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#21040;&#22810;&#26679;&#21270;&#30340;&#20869;&#23481;&#65292;&#26368;&#21518;&#65292;&#22312;&#25490;&#21517;&#38454;&#27573;&#20197;&#33258;&#25105;&#35843;&#25972;&#30340;&#26041;&#24335;&#24179;&#34913;&#22810;&#26679;&#24615;&#21644;&#25928;&#29992;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20174;&#20351;&#29992;Strong-O&#24320;&#22987;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the use of online platforms continues to grow across all demographics, users often express a desire to feel represented in the content. To improve representation in search results and recommendations, we introduce end-to-end diversification, ensuring that diverse content flows throughout the various stages of these systems, from retrieval to ranking. We develop, experiment, and deploy scalable diversification mechanisms in multiple production surfaces on the Pinterest platform, including Search, Related Products, and New User Homefeed, to improve the representation of different skin tones in beauty and fashion content. Diversification in production systems includes three components: identifying requests that will trigger diversification, ensuring diverse content is retrieved from the large content corpus during the retrieval stage, and finally, balancing the diversity-utility trade-off in a self-adjusting manner in the ranking stage. Our approaches, which evolved from using Strong-O
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;PALR&#30340;&#26694;&#26550;&#65292;&#23558;&#29992;&#25143;&#30340;&#21382;&#21490;&#34892;&#20026;&#19982;LLMs&#30456;&#32467;&#21512;&#65292;&#29983;&#25104;&#29992;&#25143;&#21916;&#27426;&#30340;&#29289;&#21697;&#30340;&#25512;&#33616;&#12290;&#19982;&#29616;&#26377;&#30340;&#25512;&#33616;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;PALR&#26694;&#26550;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.07622</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#24863;&#30693;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;LMMs&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
PALR: Personalization Aware LLMs for Recommendation. (arXiv:2305.07622v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;PALR&#30340;&#26694;&#26550;&#65292;&#23558;&#29992;&#25143;&#30340;&#21382;&#21490;&#34892;&#20026;&#19982;LLMs&#30456;&#32467;&#21512;&#65292;&#29983;&#25104;&#29992;&#25143;&#21916;&#27426;&#30340;&#29289;&#21697;&#30340;&#25512;&#33616;&#12290;&#19982;&#29616;&#26377;&#30340;&#25512;&#33616;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;PALR&#26694;&#26550;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30001;&#20110;&#20854;&#20986;&#33394;&#30340;&#24615;&#33021;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;PALR&#65292;&#23558;&#29992;&#25143;&#30340;&#21382;&#21490;&#34892;&#20026;&#19982;LLMs&#30456;&#32467;&#21512;&#65292;&#20197;&#29983;&#25104;&#29992;&#25143;&#21916;&#27426;&#30340;&#29289;&#21697;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#29992;&#25143;/&#29289;&#21697;&#20114;&#21160;&#20316;&#20026;&#20505;&#36873;&#26816;&#32034;&#30340;&#25351;&#23548;&#65292;&#28982;&#21518;&#37319;&#29992;&#22522;&#20110;LLMs&#30340;&#25490;&#24207;&#27169;&#22411;&#29983;&#25104;&#25512;&#33616;&#29289;&#21697;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#30340;&#25512;&#33616;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;PALR&#26694;&#26550;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have recently received significant attention for their exceptional capabilities. Despite extensive efforts in developing general-purpose LLMs that can be utilized in various natural language processing (NLP) tasks, there has been less research exploring their potential in recommender systems. In this paper, we propose a novel framework, named PALR, which aiming to combine user history behaviors (such as clicks, purchases, ratings, etc.) with LLMs to generate user preferred items. Specifically, we first use user/item interactions as guidance for candidate retrieval. Then we adopt a LLM-based ranking model to generate recommended items. Unlike existing approaches that typically adopt general-purpose LLMs for zero/few-shot recommendation testing or training on small-sized language models (with less than 1 billion parameters), which cannot fully elicit LLMs' reasoning abilities and leverage rich item side parametric knowledge, we fine-tune a 7 billion parameter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21160;&#25968;&#25454;&#21435;&#22122;&#30340;&#25512;&#33616;&#26694;&#26550;&#8212;&#8212;AutoDenoise&#65292;&#21033;&#29992;&#26174;&#24335;&#25968;&#25454;&#20316;&#20026;&#39564;&#35777;&#38598;&#21160;&#24577; guiding &#25512;&#33616;&#31639;&#27861;&#30340;&#35757;&#32451;&#65292;&#23545;&#38544;&#24335;&#25968;&#25454;&#36827;&#34892;&#21435;&#22122;&#22788;&#29702;&#65292;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.07070</link><description>&lt;p&gt;
&#33258;&#21160;&#25968;&#25454;&#21435;&#22122;&#25216;&#26415;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Automated Data Denoising for Recommendation. (arXiv:2305.07070v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21160;&#25968;&#25454;&#21435;&#22122;&#30340;&#25512;&#33616;&#26694;&#26550;&#8212;&#8212;AutoDenoise&#65292;&#21033;&#29992;&#26174;&#24335;&#25968;&#25454;&#20316;&#20026;&#39564;&#35777;&#38598;&#21160;&#24577; guiding &#25512;&#33616;&#31639;&#27861;&#30340;&#35757;&#32451;&#65292;&#23545;&#38544;&#24335;&#25968;&#25454;&#36827;&#34892;&#21435;&#22122;&#22788;&#29702;&#65292;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#22823;&#22810;&#25968;&#24179;&#21488;&#25910;&#38598;&#30340;&#21453;&#39304;&#25968;&#25454;&#26082;&#26377;&#22823;&#35268;&#27169;&#12289;&#33258;&#28982;&#22024;&#26434;&#30340;&#38544;&#24335;&#21453;&#39304;&#65292;&#20063;&#26377;&#23567;&#35268;&#27169;&#20294;&#39640;&#24230;&#30456;&#20851;&#30340;&#26174;&#24335;&#21453;&#39304;&#12290;&#30001;&#20110;&#25968;&#25454;&#31232;&#32570;&#30340;&#38382;&#39064;&#65292;&#38544;&#24335;&#21453;&#39304;&#36890;&#24120;&#26159;&#35757;&#32451;&#25512;&#33616;&#31995;&#32479;&#30340;&#40664;&#35748;&#36873;&#25321;&#65292;&#20294;&#36825;&#31181;&#25968;&#25454;&#21487;&#33021;&#38750;&#24120;&#22024;&#26434;&#65292;&#22240;&#20026;&#29992;&#25143;&#34892;&#20026;&#30340;&#38543;&#26426;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#36890;&#36807;&#21033;&#29992;&#20004;&#31181;&#21453;&#39304;&#30340;&#20248;&#21183;&#26469;&#24357;&#34917;&#21478;&#19968;&#31181;&#30340;&#24369;&#28857;&#65292;&#25105;&#20204;&#21487;&#20197;&#20960;&#20046;&#19981;&#33457;&#36153;&#20160;&#20040;&#20195;&#20215;&#26469;&#32531;&#35299;&#20197;&#19978;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21160;&#25968;&#25454;&#21435;&#22122;&#30340;&#26694;&#26550;&#8212;&#8212;AutoDenoise&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#65292;&#23427;&#20351;&#29992;&#23569;&#37327;&#26174;&#24335;&#25968;&#25454;&#20316;&#20026;&#39564;&#35777;&#38598;&#26469;&#25351;&#23548;&#25512;&#33616;&#31639;&#27861;&#30340;&#35757;&#32451;&#12290;AutoDenoise&#21463;&#21040;&#35838;&#31243;&#23398;&#20064;&#65288;CL&#65289;&#30340;&#24191;&#20041;&#23450;&#20041;&#30340;&#21551;&#21457;&#65292;&#23398;&#20250;&#33258;&#21160;&#21160;&#24577;&#22320;&#36827;&#34892;&#35838;&#31243;&#23398;&#20064;&#65292;&#36827;&#32780;&#23545;&#25968;&#25454;&#36827;&#34892;&#21435;&#22122;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world scenarios, most platforms collect both large-scale, naturally noisy implicit feedback and small-scale yet highly relevant explicit feedback. Due to the issue of data sparsity, implicit feedback is often the default choice for training recommender systems (RS), however, such data could be very noisy due to the randomness and diversity of user behaviors. For instance, a large portion of clicks may not reflect true user preferences and many purchases may result in negative reviews or returns. Fortunately, by utilizing the strengths of both types of feedback to compensate for the weaknesses of the other, we can mitigate the above issue at almost no cost. In this work, we propose an Automated Data Denoising framework, \textbf{\textit{AutoDenoise}}, for recommendation, which uses a small number of explicit data as validation set to guide the recommender training. Inspired by the generalized definition of curriculum learning (CL), AutoDenoise learns to automatically and dynamica
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#32773;&#25552;&#20986;&#35757;&#32451;&#25490;&#21517;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#25928;&#29575;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#20102;&#20154;&#24037;&#20195;&#30721;&#20999;&#25442;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#23454;&#39564;&#34920;&#26126;&#22312;&#36328;&#35821;&#35328;&#26816;&#32034;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#20013;&#20250;&#24102;&#26469;&#26174;&#33879;&#25913;&#36827;&#65292;&#22312;&#19981;&#24433;&#21709;&#21333;&#35821;&#26816;&#32034;&#30340;&#22522;&#30784;&#19978;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#36828;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26816;&#32034;&#12290;</title><link>http://arxiv.org/abs/2305.05295</link><description>&lt;p&gt;
&#36890;&#36807;&#35757;&#32451;&#20154;&#24037;&#20195;&#30721;&#20999;&#25442;&#25968;&#25454;&#26469;&#25552;&#21319;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data. (arXiv:2305.05295v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05295
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32773;&#25552;&#20986;&#35757;&#32451;&#25490;&#21517;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#25928;&#29575;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#20102;&#20154;&#24037;&#20195;&#30721;&#20999;&#25442;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#23454;&#39564;&#34920;&#26126;&#22312;&#36328;&#35821;&#35328;&#26816;&#32034;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#20013;&#20250;&#24102;&#26469;&#26174;&#33879;&#25913;&#36827;&#65292;&#22312;&#19981;&#24433;&#21709;&#21333;&#35821;&#26816;&#32034;&#30340;&#22522;&#30784;&#19978;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#36828;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26816;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#20197;&#33521;&#35821;&#20026;&#20195;&#34920;&#30340;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#27169;&#22411;&#20197;&#38646;&#26679;&#26412;&#26041;&#24335;&#36801;&#31227;&#21040;&#20854;&#20182;&#35821;&#35328;&#24050;&#25104;&#20026;&#34987;&#24191;&#27867;&#37319;&#29992;&#30340;&#26041;&#27861;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#26597;&#35810;&#21644;&#25991;&#26723;&#20197;&#19981;&#21516;&#35821;&#35328;&#23384;&#22312;&#26102;&#65292;&#38646;&#26679;&#26412;&#25490;&#21517;&#22120;&#30340;&#26377;&#25928;&#24615;&#20250;&#38477;&#20302;&#12290;&#20986;&#20110;&#36825;&#20010;&#21407;&#22240;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#20154;&#24037;&#20195;&#30721;&#20999;&#25442;&#25968;&#25454;&#26469;&#35757;&#32451;&#25490;&#21517;&#27169;&#22411;&#65292;&#32780;&#25105;&#20204;&#29983;&#25104;&#36825;&#20123;&#25968;&#25454;&#26159;&#36890;&#36807;&#21033;&#29992;&#21452;&#35821;&#35789;&#34920;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23581;&#35797;&#20102;&#20174;&#65288;1&#65289;&#36328;&#35821;&#35328;&#35789;&#23884;&#20837;&#21644;&#65288;2&#65289;&#24179;&#34892;&#32500;&#22522;&#30334;&#31185;&#39029;&#38754;&#26631;&#39064;&#24471;&#20986;&#30340;&#35789;&#34920;&#12290;&#25105;&#20204;&#20351;&#29992;mMARCO&#25968;&#25454;&#38598;&#23545;&#28085;&#30422;&#21333;&#35821;IR&#65288;MoIR&#65289;&#12289;&#36328;&#35821;&#35328;IR&#65288;CLIR&#65289;&#21644;&#22810;&#35821;&#35328;IR&#65288;MLIR&#65289;&#30340;36&#31181;&#35821;&#35328;&#23545;&#30340;&#37325;&#25490;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20195;&#30721;&#20999;&#25442;&#21487;&#20197;&#22312;&#20445;&#25345;MoIR&#24615;&#33021;&#31283;&#23450;&#30340;&#21516;&#26102;&#65292;&#22312;CLIR&#20013;&#20135;&#29983;5.1 MRR@10&#30340;&#19968;&#33268;&#21644;&#26174;&#33879;&#22686;&#30410;&#65292;&#20197;&#21450;&#22312;MLIR&#20013;&#20135;&#29983;3.9 MRR@10&#30340;&#22686;&#30410;&#12290;&#20196;&#20154;&#40723;&#33310;&#30340;&#26159;&#65292;&#36828;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#22686;&#30410;&#29305;&#21035;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transferring information retrieval (IR) models from a high-resource language (typically English) to other languages in a zero-shot fashion has become a widely adopted approach. In this work, we show that the effectiveness of zero-shot rankers diminishes when queries and documents are present in different languages. Motivated by this, we propose to train ranking models on artificially code-switched data instead, which we generate by utilizing bilingual lexicons. To this end, we experiment with lexicons induced from (1) cross-lingual word embeddings and (2) parallel Wikipedia page titles. We use the mMARCO dataset to extensively evaluate reranking models on 36 language pairs spanning Monolingual IR (MoIR), Cross-lingual IR (CLIR), and Multilingual IR (MLIR). Our results show that code-switching can yield consistent and substantial gains of 5.1 MRR@10 in CLIR and 3.9 MRR@10 in MLIR, while maintaining stable performance in MoIR. Encouragingly, the gains are especially pronounced for distan
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#24179;&#34892;&#21644;&#38750;&#24179;&#34892;&#35821;&#26009;&#24211;&#26469;&#25552;&#39640;&#22810;&#35821;&#31181;&#20449;&#24687;&#26816;&#32034;&#30340;&#25928;&#26524;&#65292;&#20165;&#20351;&#29992;&#33521;&#35821;IR&#35757;&#32451;&#25968;&#25454;&#21644;&#19968;&#20123;&#24179;&#34892;&#35821;&#26009;&#24211;&#21363;&#21487;&#22312;&#38750;&#33521;&#35821;&#25968;&#25454;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#26816;&#32034;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2210.06633</link><description>&lt;p&gt;
&#26080;&#20851;&#35821;&#35328;&#30340;&#22810;&#35821;&#31181;&#20449;&#24687;&#26816;&#32034;&#19982;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Language Agnostic Multilingual Information Retrieval with Contrastive Learning. (arXiv:2210.06633v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06633
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#24179;&#34892;&#21644;&#38750;&#24179;&#34892;&#35821;&#26009;&#24211;&#26469;&#25552;&#39640;&#22810;&#35821;&#31181;&#20449;&#24687;&#26816;&#32034;&#30340;&#25928;&#26524;&#65292;&#20165;&#20351;&#29992;&#33521;&#35821;IR&#35757;&#32451;&#25968;&#25454;&#21644;&#19968;&#20123;&#24179;&#34892;&#35821;&#26009;&#24211;&#21363;&#21487;&#22312;&#38750;&#33521;&#35821;&#25968;&#25454;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#26816;&#32034;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35821;&#31181;&#20449;&#24687;&#26816;&#32034;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#22312;&#35768;&#22810;&#35821;&#35328;&#20013;&#33719;&#21462;&#32463;&#36807;&#27880;&#37322;&#30340;&#35757;&#32451;&#25968;&#25454;&#25104;&#26412;&#24456;&#39640;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#22312;&#21482;&#26377;&#33521;&#35821;IR&#35757;&#32451;&#25968;&#25454;&#21644;&#33521;&#35821;&#19982;&#20854;&#20182;&#35821;&#35328;&#20043;&#38388;&#30340;&#19968;&#20123;&#24179;&#34892;&#35821;&#26009;&#24211;&#21487;&#29992;&#26102;&#35757;&#32451;&#22810;&#35821;&#31181;IR&#31995;&#32479;&#12290;&#25105;&#20204;&#21033;&#29992;&#24179;&#34892;&#21644;&#38750;&#24179;&#34892;&#35821;&#26009;&#24211;&#26469;&#25552;&#39640;&#39044;&#35757;&#32451;&#22810;&#35821;&#31181;&#35821;&#35328;&#27169;&#22411;&#30340;&#36328;&#35821;&#35328;&#20256;&#36882;&#33021;&#21147;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#35821;&#20041;&#23545;&#27604;&#25439;&#22833;&#65292;&#20197;&#23545;&#40784;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#30340;&#24179;&#34892;&#21477;&#23376;&#30340;&#34920;&#31034;&#65292;&#20197;&#21450;&#19968;&#31181;&#26032;&#30340;&#35821;&#35328;&#23545;&#27604;&#25439;&#22833;&#65292;&#21033;&#29992;&#24179;&#34892;&#21477;&#23376;&#23545;&#20174;&#38750;&#24179;&#34892;&#35821;&#26009;&#24211;&#20013;&#30340;&#21477;&#23376;&#34920;&#31034;&#20013;&#21024;&#38500;&#35821;&#35328;&#29305;&#23450;&#20449;&#24687;&#12290;&#22312;&#20351;&#29992;&#36825;&#20123;&#25439;&#22833;&#23545;&#33521;&#35821;IR&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#24182;&#22312;&#38750;&#33521;&#35821;&#25968;&#25454;&#19978;&#36827;&#34892;&#38646;-shot&#35780;&#20272;&#26102;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#26126;&#26174;&#30340;&#25913;&#36827;&#65292;&#21516;&#26102;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multilingual information retrieval (IR) is challenging since annotated training data is costly to obtain in many languages. We present an effective method to train multilingual IR systems when only English IR training data and some parallel corpora between English and other languages are available. We leverage parallel and non-parallel corpora to improve the pretrained multilingual language models' cross-lingual transfer ability. We design a semantic contrastive loss to align representations of parallel sentences that share the same semantics in different languages, and a new language contrastive loss to leverage parallel sentence pairs to remove language-specific information in sentence representations from non-parallel corpora. When trained on English IR data with these losses and evaluated zero-shot on non-English data, our model demonstrates significant improvement to prior work on retrieval performance, while it requires much less computational effort. We also demonstrate the valu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#26435;&#22810;&#20852;&#36259;&#26816;&#32034;&#27169;&#22411;&#65288;Multi-Interest Preference&#65292;MIP&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20026;&#29992;&#25143;&#24314;&#31435;&#22810;&#20010;&#20852;&#36259;&#23884;&#20837;&#65292;&#24182;&#23558;&#29992;&#25143;&#22312;&#22810;&#20010;&#20852;&#36259;&#19978;&#30340;&#20559;&#22909;&#36827;&#34892;&#24314;&#27169;&#65292;&#20174;&#32780;&#25552;&#39640;&#20505;&#36873;&#26816;&#32034;&#32467;&#26524;&#30340;&#26597;&#20840;&#29575;&#12290;</title><link>http://arxiv.org/abs/2207.06652</link><description>&lt;p&gt;
&#27599;&#20010;&#20154;&#30340;&#20559;&#22909;&#21464;&#21270;&#19981;&#21516;&#65306;&#21152;&#26435;&#22810;&#20852;&#36259;&#26816;&#32034;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Everyone's Preference Changes Differently: Weighted Multi-Interest Retrieval Model. (arXiv:2207.06652v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.06652
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#26435;&#22810;&#20852;&#36259;&#26816;&#32034;&#27169;&#22411;&#65288;Multi-Interest Preference&#65292;MIP&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20026;&#29992;&#25143;&#24314;&#31435;&#22810;&#20010;&#20852;&#36259;&#23884;&#20837;&#65292;&#24182;&#23558;&#29992;&#25143;&#22312;&#22810;&#20010;&#20852;&#36259;&#19978;&#30340;&#20559;&#22909;&#36827;&#34892;&#24314;&#27169;&#65292;&#20174;&#32780;&#25552;&#39640;&#20505;&#36873;&#26816;&#32034;&#32467;&#26524;&#30340;&#26597;&#20840;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#23884;&#20837;&#65288;&#29992;&#25143;&#30340;&#21521;&#37327;&#21270;&#34920;&#31034;&#65289;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#20316;&#29992;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#26469;&#26500;&#24314;&#29992;&#25143;&#30340;&#22810;&#32500;&#24230;&#34920;&#31034;&#65292;&#20197;&#20415;&#20110;&#26816;&#32034;&#20219;&#21153;&#20013;&#25214;&#21040;&#30456;&#20284;&#30340;&#29289;&#21697;&#65292;&#24182;&#19988;&#24050;&#32463;&#22312;&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;&#20013;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#12290;&#26368;&#36817;&#20154;&#20204;&#21457;&#29616;&#20351;&#29992;&#22810;&#31181;&#23884;&#20837;&#65288;&#21363;&#22810;&#20010;&#32500;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;&#65289;&#26469;&#34920;&#31034;&#29992;&#25143;&#30340;&#20852;&#36259;&#26159;&#26377;&#29992;&#30340;&#65292;&#27599;&#20010;&#23884;&#20837;&#34920;&#31034;&#29992;&#25143;&#30340;&#26576;&#20010;&#20027;&#39064;&#20852;&#36259;&#12290;&#23545;&#20110;&#22810;&#20852;&#36259;&#34920;&#31034;&#65292;&#37325;&#35201;&#30340;&#26159;&#23545;&#29992;&#25143;&#22312;&#19981;&#21516;&#20027;&#39064;&#19978;&#30340;&#20559;&#22909;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#19988;&#20102;&#35299;&#20559;&#22909;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#24773;&#20917;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#26080;&#27861;&#20272;&#31639;&#29992;&#25143;&#23545;&#27599;&#20010;&#20852;&#36259;&#30340;&#22909;&#24863;&#24230;&#65292;&#35201;&#20040;&#19981;&#21512;&#29702;&#22320;&#20551;&#35774;&#27599;&#20010;&#29992;&#25143;&#23545;&#27599;&#20010;&#20852;&#36259;&#30340;&#20852;&#36259;&#24378;&#24230;&#20250;&#20197;&#30456;&#31561;&#30340;&#36895;&#29575;&#19979;&#38477;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#20505;&#36873;&#26816;&#32034;&#32467;&#26524;&#30340;&#26597;&#20840;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21152;&#26435;&#22810;&#20852;&#36259;&#26816;&#32034;&#27169;&#22411;&#65288;Multi-Interest Preference, MIP&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20026;&#29992;&#25143;&#20135;&#29983;&#22810;&#20010;&#20852;&#36259;&#23884;&#20837;&#65292;&#24182;&#19988;&#21487;&#20197;&#23545;&#29992;&#25143;&#22312;&#22810;&#31181;&#20852;&#36259;&#19979;&#30340;&#20559;&#22909;&#36827;&#34892;&#20272;&#35745;&#65292;&#20174;&#32780;&#25552;&#39640;&#20505;&#36873;&#26816;&#32034;&#32467;&#26524;&#30340;&#26597;&#20840;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
User embeddings (vectorized representations of a user) are essential in recommendation systems. Numerous approaches have been proposed to construct a representation for the user in order to find similar items for retrieval tasks, and they have been proven effective in industrial recommendation systems as well. Recently people have discovered the power of using multiple embeddings to represent a user, with the hope that each embedding represents the user's interest in a certain topic. With multi-interest representation, it's important to model the user's preference over the different topics and how the preference change with time. However, existing approaches either fail to estimate the user's affinity to each interest or unreasonably assume every interest of every user fades with an equal rate with time, thus hurting the recall of candidate retrieval. In this paper, we propose the Multi-Interest Preference (MIP) model, an approach that not only produces multi-interest for users by usin
&lt;/p&gt;</description></item></channel></rss>