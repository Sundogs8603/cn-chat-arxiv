<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20174;&#25512;&#29305;&#25130;&#22270;&#20013;&#25552;&#21462;&#25512;&#25991;&#25991;&#26412;&#12289;&#26102;&#38388;&#25139;&#21644;&#25512;&#29305;&#21477;&#26564;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#24320;&#21457;&#19968;&#20010;&#24037;&#20855;&#65292;&#21033;&#29992;&#23454;&#26102;&#32593;&#32476;&#21644;&#32593;&#32476;&#23384;&#26723;&#20013;&#30340;&#36164;&#28304;&#65292;&#35780;&#20272;&#19968;&#24352;&#25512;&#29305;&#25130;&#22270;&#20013;&#25512;&#25991;&#30495;&#23454;&#24615;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.08236</link><description>&lt;p&gt;
&#20174;&#25512;&#29305;&#25130;&#22270;&#20013;&#25552;&#21462;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Extracting Information from Twitter Screenshots. (arXiv:2306.08236v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20174;&#25512;&#29305;&#25130;&#22270;&#20013;&#25552;&#21462;&#25512;&#25991;&#25991;&#26412;&#12289;&#26102;&#38388;&#25139;&#21644;&#25512;&#29305;&#21477;&#26564;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#24320;&#21457;&#19968;&#20010;&#24037;&#20855;&#65292;&#21033;&#29992;&#23454;&#26102;&#32593;&#32476;&#21644;&#32593;&#32476;&#23384;&#26723;&#20013;&#30340;&#36164;&#28304;&#65292;&#35780;&#20272;&#19968;&#24352;&#25512;&#29305;&#25130;&#22270;&#20013;&#25512;&#25991;&#30495;&#23454;&#24615;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#65292;&#25130;&#22270;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#20449;&#24687;&#20998;&#20139;&#26041;&#27861;&#12290;&#29992;&#25143;&#22312;&#20998;&#20139;&#25130;&#22270;&#20043;&#21069;&#24456;&#23569;&#39564;&#35777;&#20854;&#20013;&#30340;&#24086;&#23376;&#26159;&#30495;&#23454;&#30340;&#36824;&#26159;&#34394;&#20551;&#30340;&#12290;&#36890;&#36807;&#34394;&#20551;&#25130;&#22270;&#36827;&#34892;&#30340;&#20449;&#24687;&#20998;&#20139;&#20250;&#20005;&#37325;&#23548;&#33268;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#38169;&#35823;&#20449;&#24687;&#21644;&#35823;&#23548;&#20449;&#24687;&#20256;&#25773;&#12290;&#25105;&#20204;&#30340;&#32456;&#26497;&#30446;&#26631;&#26159;&#24320;&#21457;&#19968;&#20010;&#24037;&#20855;&#65292;&#21487;&#20197;&#36890;&#36807;&#22312;&#23454;&#26102;&#32593;&#32476;&#21644;&#32593;&#32476;&#23384;&#26723;&#20013;&#21457;&#29616;&#30340;&#36164;&#28304;&#65292;&#23545;&#25512;&#29305;&#30340;&#25130;&#22270;&#25552;&#20379;&#25512;&#25991;&#30495;&#23454;&#24615;&#30340;&#27010;&#29575;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#20174;&#25512;&#29305;&#25130;&#22270;&#20013;&#25552;&#21462;&#25512;&#25991;&#25991;&#26412;&#12289;&#26102;&#38388;&#25139;&#21644;&#25512;&#29305;&#21477;&#26564;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Screenshots are prevalent on social media as a common approach for information sharing. Users rarely verify before sharing a screenshot whether the post it contains is fake or real. Information sharing through fake screenshots can be highly responsible for misinformation and disinformation spread on social media. Our ultimate goal is to develop a tool that could take a screenshot of a tweet and provide a probability that the tweet is real, using resources found on the live web and in web archives. This paper provides methods for extracting the tweet text, timestamp, and Twitter handle from a screenshot of a tweet.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861; CGNN&#65292;&#23427;&#21033;&#29992;&#19968;&#33268;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#21516;&#36136;&#24615;&#20551;&#35774;&#30340;&#26679;&#26412;&#36873;&#25321;&#25216;&#26415;&#65292;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#23545;&#33410;&#28857;&#20998;&#31867;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#36807;&#28388;&#20986;&#22122;&#22768;&#33410;&#28857;&#21644;&#22686;&#24378;&#33410;&#28857;&#34920;&#31034;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.08194</link><description>&lt;p&gt;
&#22312;&#26631;&#31614;&#22122;&#22768;&#19979;&#30340;&#22270;&#19978;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning on Graphs under Label Noise. (arXiv:2306.08194v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08194
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861; CGNN&#65292;&#23427;&#21033;&#29992;&#19968;&#33268;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#21516;&#36136;&#24615;&#20551;&#35774;&#30340;&#26679;&#26412;&#36873;&#25321;&#25216;&#26415;&#65292;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#23545;&#33410;&#28857;&#20998;&#31867;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#36807;&#28388;&#20986;&#22122;&#22768;&#33410;&#28857;&#21644;&#22686;&#24378;&#33410;&#28857;&#34920;&#31034;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#31038;&#20132;&#20998;&#26512;&#21644;&#24322;&#24120;&#26816;&#27979;&#12290;&#34429;&#28982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22312;&#36825;&#39033;&#20219;&#21153;&#19978;&#24050;&#32463;&#21462;&#24471;&#20102;&#19968;&#20123;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#30446;&#21069;&#30340;&#25216;&#26415;&#36890;&#24120;&#20551;&#35774;&#33410;&#28857;&#30340;&#26631;&#31614;&#20449;&#24687;&#26159;&#20934;&#30830;&#30340;&#65292;&#36825;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#21487;&#33021;&#24182;&#19981;&#25104;&#31435;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#26631;&#31614;&#22122;&#22768;&#19979;&#30340;&#22270;&#19978;&#23398;&#20064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;&#19968;&#33268;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;CGNN&#65289;&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#23427;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#22270;&#23545;&#27604;&#23398;&#20064;&#20316;&#20026;&#27491;&#21017;&#21270;&#39033;&#65292;&#20419;&#36827;&#22686;&#24378;&#33410;&#28857;&#30340;&#20004;&#20010;&#35270;&#35282;&#20855;&#26377;&#19968;&#33268;&#30340;&#34920;&#31034;&#12290;&#30001;&#20110;&#36825;&#20010;&#27491;&#21017;&#21270;&#39033;&#19981;&#33021;&#21033;&#29992;&#26631;&#31614;&#20449;&#24687;&#65292;&#23427;&#21487;&#20197;&#22686;&#24378;&#33410;&#28857;&#34920;&#31034;&#23545;&#26631;&#31614;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22312;&#22270;&#19978;&#26816;&#27979;&#22122;&#22768;&#26631;&#31614;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21516;&#36136;&#24615;&#20551;&#35774;&#30340;&#26679;&#26412;&#36873;&#25321;&#25216;&#26415;&#65292;&#36890;&#36807;&#27979;&#37327;&#23884;&#20837;&#21644;&#23427;&#20204;&#30340;&#37051;&#23621;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#26469;&#35782;&#21035;&#22122;&#22768;&#33410;&#28857;&#12290;&#21508;&#31181;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;CGNN&#21487;&#20197;&#26377;&#25928;&#22320;&#32531;&#35299;&#26631;&#31614;&#22122;&#22768;&#23545;&#33410;&#28857;&#20998;&#31867;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#24182;&#22312;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#26631;&#31614;&#22122;&#22768;&#27169;&#22411;&#19979;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Node classification on graphs is a significant task with a wide range of applications, including social analysis and anomaly detection. Even though graph neural networks (GNNs) have produced promising results on this task, current techniques often presume that label information of nodes is accurate, which may not be the case in real-world applications. To tackle this issue, we investigate the problem of learning on graphs with label noise and develop a novel approach dubbed Consistent Graph Neural Network (CGNN) to solve it. Specifically, we employ graph contrastive learning as a regularization term, which promotes two views of augmented nodes to have consistent representations. Since this regularization term cannot utilize label information, it can enhance the robustness of node representations to label noise. Moreover, to detect noisy labels on the graph, we present a sample selection technique based on the homophily assumption, which identifies noisy nodes by measuring the consisten
&lt;/p&gt;</description></item><item><title>Adobe&#30340;20,000&#22810;&#31181;&#23383;&#20307;&#24211;&#26159;&#20010;&#36873;&#25321;&#24656;&#24807;&#30151;&#24739;&#32773;&#30340;&#22121;&#26790;&#65292;&#26412;&#25991;&#36890;&#36807;&#21019;&#36896;&#19968;&#20010;&#22522;&#20110;&#29992;&#25143;&#24847;&#22270;&#30340;&#31995;&#32479;&#26469;&#33258;&#21160;&#32473;&#29992;&#25143;&#25552;&#20379;&#21512;&#36866;&#30340;&#23383;&#20307;&#25512;&#33616;&#65292;&#30446;&#21069;&#24050;&#34987;&#25968;&#30334;&#19975; Adobe Express &#29992;&#25143;&#20351;&#29992;&#65292;&#28857;&#20987;&#29575;&#39640;&#36798; 25% &#20197;&#19978;&#12290;</title><link>http://arxiv.org/abs/2306.08188</link><description>&lt;p&gt;
&#22522;&#20110;&#29992;&#25143;&#24847;&#22270;&#30340;&#19978;&#19979;&#25991;&#23383;&#20307;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Contextual Font Recommendations based on User Intent. (arXiv:2306.08188v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08188
&lt;/p&gt;
&lt;p&gt;
Adobe&#30340;20,000&#22810;&#31181;&#23383;&#20307;&#24211;&#26159;&#20010;&#36873;&#25321;&#24656;&#24807;&#30151;&#24739;&#32773;&#30340;&#22121;&#26790;&#65292;&#26412;&#25991;&#36890;&#36807;&#21019;&#36896;&#19968;&#20010;&#22522;&#20110;&#29992;&#25143;&#24847;&#22270;&#30340;&#31995;&#32479;&#26469;&#33258;&#21160;&#32473;&#29992;&#25143;&#25552;&#20379;&#21512;&#36866;&#30340;&#23383;&#20307;&#25512;&#33616;&#65292;&#30446;&#21069;&#24050;&#34987;&#25968;&#30334;&#19975; Adobe Express &#29992;&#25143;&#20351;&#29992;&#65292;&#28857;&#20987;&#29575;&#39640;&#36798; 25% &#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Adobe Fonts &#25317;&#26377;&#36229;&#36807; 20,000 &#31181;&#29420;&#29305;&#30340;&#23383;&#20307;&#24211;&#65292;&#29992;&#20110;&#21019;&#36896;&#22270;&#24418;&#12289;&#28023;&#25253;&#12289;&#22797;&#21512;&#29289;&#31561;&#12290;&#30001;&#20110;&#23383;&#20307;&#24211;&#30340;&#29305;&#27530;&#24615;&#65292;&#36873;&#25321;&#21512;&#36866;&#30340;&#23383;&#20307;&#26159;&#19968;&#39033;&#38656;&#35201;&#22823;&#37327;&#32463;&#39564;&#30340;&#33392;&#24040;&#20219;&#21153;&#12290;&#23545;&#20110;&#22823;&#22810;&#25968; Adobe &#20135;&#21697;&#29992;&#25143;&#65292;&#29305;&#21035;&#26159; Adobe Express &#30340;&#26222;&#36890;&#29992;&#25143;&#65292;&#36825;&#36890;&#24120;&#24847;&#21619;&#30528;&#36873;&#25321;&#40664;&#35748;&#23383;&#20307;&#32780;&#19981;&#26159;&#20351;&#29992;&#20016;&#23500;&#22810;&#26679;&#30340;&#21487;&#29992;&#23383;&#20307;&#12290;&#26412;&#30740;&#31350;&#21019;&#36896;&#20102;&#19968;&#20010;&#22522;&#20110;&#29992;&#25143;&#24847;&#22270;&#30340;&#31995;&#32479;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#19978;&#19979;&#25991;&#23383;&#20307;&#25512;&#33616;&#65292;&#20197;&#21327;&#21161;&#20182;&#20204;&#30340;&#21019;&#20316;&#20043;&#26053;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#25509;&#21463;&#22810;&#35821;&#35328;&#25991;&#26412;&#36755;&#20837;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#30340;&#24847;&#22270;&#25512;&#33616;&#36866;&#24403;&#30340;&#23383;&#20307;&#12290;&#26681;&#25454;&#29992;&#25143;&#30340;&#36164;&#26684;&#65292;&#20813;&#36153;&#21644;&#20184;&#36153;&#23383;&#20307;&#30340;&#28151;&#21512;&#27604;&#20363;&#23558;&#20250;&#20570;&#20986;&#30456;&#24212;&#30340;&#35843;&#25972;&#12290;&#35813;&#21151;&#33021;&#30446;&#21069;&#24050;&#34987;&#25968;&#30334;&#19975; Adobe Express &#29992;&#25143;&#20351;&#29992;&#65292;&#28857;&#20987;&#29575;&#39640;&#36798; 25% &#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adobe Fonts has a rich library of over 20,000 unique fonts that Adobe users utilize for creating graphics, posters, composites etc. Due to the nature of the large library, knowing what font to select can be a daunting task that requires a lot of experience. For most users in Adobe products, especially casual users of Adobe Express, this often means choosing the default font instead of utilizing the rich and diverse fonts available. In this work, we create an intent-driven system to provide contextual font recommendations to users to aid in their creative journey. Our system takes in multilingual text input and recommends suitable fonts based on the user's intent. Based on user entitlements, the mix of free and paid fonts is adjusted. The feature is currently used by millions of Adobe Express users with a CTR of &gt;25%.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;h2oGPT&#65292;&#36825;&#26159;&#19968;&#22871;&#24320;&#28304;&#20195;&#30721;&#24211;&#65292;&#29992;&#20110;&#21019;&#24314;&#21644;&#20351;&#29992;&#22522;&#20110;GPTs&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#21253;&#25324;100&#65285;&#31169;&#26377;&#25991;&#26723;&#25628;&#32034;&#12290;&#30446;&#26631;&#26159;&#21019;&#24314;&#30495;&#27491;&#24320;&#28304;&#30340;&#26367;&#20195;&#23553;&#38381;&#28304;GPTs&#65292;&#25552;&#39640;&#20154;&#24037;&#26234;&#33021;&#30340;&#24320;&#21457;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.08161</link><description>&lt;p&gt;
h2oGPT&#65306;&#27665;&#20027;&#21270;&#22823;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
h2oGPT: Democratizing Large Language Models. (arXiv:2306.08161v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08161
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;h2oGPT&#65292;&#36825;&#26159;&#19968;&#22871;&#24320;&#28304;&#20195;&#30721;&#24211;&#65292;&#29992;&#20110;&#21019;&#24314;&#21644;&#20351;&#29992;&#22522;&#20110;GPTs&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#21253;&#25324;100&#65285;&#31169;&#26377;&#25991;&#26723;&#25628;&#32034;&#12290;&#30446;&#26631;&#26159;&#21019;&#24314;&#30495;&#27491;&#24320;&#28304;&#30340;&#26367;&#20195;&#23553;&#38381;&#28304;GPTs&#65292;&#25552;&#39640;&#20154;&#24037;&#26234;&#33021;&#30340;&#24320;&#21457;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#39044;&#35757;&#32451;&#21464;&#21387;&#22120;&#65288;GPTs&#65289;&#65292;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;GPT-4&#22240;&#20854;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#30340;&#29616;&#23454;&#24212;&#29992;&#32780;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#38761;&#21629;&#30340;&#19968;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#20063;&#24102;&#26469;&#20102;&#35768;&#22810;&#37325;&#22823;&#30340;&#39118;&#38505;&#65292;&#22914;&#23384;&#22312;&#26377;&#20559;&#35265;&#12289;&#31169;&#20154;&#25110;&#26377;&#23475;&#25991;&#26412;&#21644;&#26410;&#32463;&#25480;&#26435;&#30340;&#29256;&#26435;&#26448;&#26009;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;h2oGPT&#65292;&#36825;&#26159;&#19968;&#22871;&#24320;&#28304;&#20195;&#30721;&#24211;&#65292;&#29992;&#20110;&#21019;&#24314;&#21644;&#20351;&#29992;&#22522;&#20110;GPTs&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#35813;&#39033;&#30446;&#30340;&#30446;&#26631;&#26159;&#21019;&#24314;&#19990;&#30028;&#19978;&#26368;&#22909;&#30340;&#30495;&#27491;&#24320;&#28304;&#30340;&#26367;&#20195;&#23553;&#38381;&#28304;GPTs&#12290;&#19982;&#24320;&#28304;&#31038;&#21306;&#21512;&#20316;&#65292;&#20316;&#20026;&#20854;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#24320;&#28304;&#20102;&#20960;&#20010;LLM&#65292;&#20854;&#21442;&#25968;&#20174;7&#20159;&#21040;400&#20159;&#65292;&#21487;&#22312;&#23436;&#20840;&#33258;&#30001;&#30340;Apache 2.0&#35768;&#21487;&#19979;&#21830;&#29992;&#12290;&#25105;&#20204;&#30340;&#21457;&#24067;&#21253;&#25324;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#30340;100&#65285;&#31169;&#26377;&#25991;&#26723;&#25628;&#32034;&#12290;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#26377;&#21161;&#20110;&#20419;&#36827;&#20154;&#24037;&#26234;&#33021;&#30340;&#21457;&#23637;&#24182;&#20351;&#20854;&#26356;&#21152;&#21487;&#38752;&#12290;
&lt;/p&gt;
&lt;p&gt;
Foundation Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their real-world applications though natural language processing. However, they also pose many significant risks such as the presence of biased, private, or harmful text, and the unauthorized inclusion of copyrighted material.  We introduce h2oGPT, a suite of open-source code repositories for the creation and use of Large Language Models (LLMs) based on Generative Pretrained Transformers (GPTs). The goal of this project is to create the world's best truly open-source alternative to closed-source GPTs. In collaboration with and as part of the incredible and unstoppable open-source community, we open-source several fine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for commercial use under fully permissive Apache 2.0 licenses. Included in our release is 100% private document search using natural language.  Open-source language models help boost AI development and make it more accessible
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#35821;&#20041;ID&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29289;&#21697;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#36825;&#20123;ID&#26159;&#20174;&#20869;&#23481;&#23884;&#20837;&#20013;&#23398;&#20064;&#30340;&#65292;&#21487;&#20197;&#25429;&#25417;&#27010;&#24565;&#30340;&#23618;&#27425;&#20851;&#31995;&#65292;&#30456;&#36739;&#20110;&#23436;&#20840;&#28040;&#38500;ID&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#35821;&#20041;ID&#33021;&#26356;&#22909;&#22320;&#25552;&#39640;&#25512;&#33616;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.08121</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#20041;ID&#36827;&#34892;&#26356;&#22909;&#30340;&#27867;&#21270;&#65306;&#25512;&#33616;&#25490;&#21517;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Better Generalization with Semantic IDs: A case study in Ranking for Recommendations. (arXiv:2306.08121v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#35821;&#20041;ID&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29289;&#21697;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#36825;&#20123;ID&#26159;&#20174;&#20869;&#23481;&#23884;&#20837;&#20013;&#23398;&#20064;&#30340;&#65292;&#21487;&#20197;&#25429;&#25417;&#27010;&#24565;&#30340;&#23618;&#27425;&#20851;&#31995;&#65292;&#30456;&#36739;&#20110;&#23436;&#20840;&#28040;&#38500;ID&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#35821;&#20041;ID&#33021;&#26356;&#22909;&#22320;&#25552;&#39640;&#25512;&#33616;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#27169;&#22411;&#20013;&#65292;&#35757;&#32451;&#22909;&#30340;&#29289;&#21697;&#34920;&#31034;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#36890;&#24120;&#65292;&#19968;&#39033;&#21830;&#21697;&#20250;&#34987;&#20998;&#37197;&#19968;&#20010;&#21807;&#19968;&#30340;&#38543;&#26426;&#29983;&#25104;&#30340;ID&#65292;&#24182;&#19988;&#36890;&#24120;&#20250;&#36890;&#36807;&#23398;&#20064;&#19982;&#38543;&#26426;ID&#20540;&#30456;&#23545;&#24212;&#30340;&#23884;&#20837;&#26469;&#34920;&#31034;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#22312;&#29289;&#21697;&#25968;&#37327;&#22823;&#19988;&#29289;&#21697;&#26381;&#20174;&#24130;&#24459;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#8212;&#8212;&#36825;&#26159;&#30495;&#23454;&#19990;&#30028;&#25512;&#33616;&#31995;&#32479;&#30340;&#20856;&#22411;&#29305;&#24449;&#8212;&#8212;&#20250;&#26377;&#19968;&#23450;&#23616;&#38480;&#24615;&#12290;&#36825;&#20250;&#23548;&#33268;&#29289;&#21697;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#27169;&#22411;&#26080;&#27861;&#23545;&#23614;&#37096;&#21644;&#20197;&#21069;&#26410;&#35265;&#36807;&#30340;&#29289;&#21697;&#36827;&#34892;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;&#23436;&#20840;&#28040;&#38500;&#36825;&#20123;ID&#29305;&#24449;&#21450;&#20854;&#23398;&#20064;&#30340;&#23884;&#20837;&#20197;&#35299;&#20915;&#20919;&#21551;&#21160;&#38382;&#39064;&#20250;&#20005;&#37325;&#38477;&#20302;&#25512;&#33616;&#36136;&#37327;&#12290;&#22522;&#20110;&#20869;&#23481;&#30340;&#29289;&#21697;&#23884;&#20837;&#26356;&#20026;&#21487;&#38752;&#65292;&#20294;&#23545;&#20110;&#29992;&#25143;&#36807;&#21435;&#30340;&#29289;&#21697;&#20132;&#20114;&#24207;&#21015;&#26469;&#35828;&#65292;&#23427;&#20204;&#25104;&#26412;&#39640;&#19988;&#20351;&#29992;&#22256;&#38590;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#35821;&#20041;ID&#26469;&#34920;&#31034;&#31163;&#25955;&#30340;&#29289;&#21697;&#65292;&#36825;&#20123;ID&#26159;&#36890;&#36807;&#20351;&#29992;RQ-VAE&#20174;&#20869;&#23481;&#23884;&#20837;&#20013;&#23398;&#20064;&#30340;&#65292;&#21487;&#20197;&#25429;&#25417;&#27010;&#24565;&#30340;&#23618;&#27425;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training good representations for items is critical in recommender models. Typically, an item is assigned a unique randomly generated ID, and is commonly represented by learning an embedding corresponding to the value of the random ID. Although widely used, this approach have limitations when the number of items are large and items are power-law distributed -- typical characteristics of real-world recommendation systems. This leads to the item cold-start problem, where the model is unable to make reliable inferences for tail and previously unseen items. Removing these ID features and their learned embeddings altogether to combat cold-start issue severely degrades the recommendation quality. Content-based item embeddings are more reliable, but they are expensive to store and use, particularly for users' past item interaction sequence. In this paper, we use Semantic IDs, a compact discrete item representations learned from content embeddings using RQ-VAE that captures hierarchy of concep
&lt;/p&gt;</description></item><item><title>Mol-Instructions&#26159;&#19968;&#20010;&#19987;&#38376;&#20026;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#35774;&#35745;&#30340;&#32508;&#21512;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#29289;&#39046;&#22495;&#20013;&#30340;&#36866;&#24212;&#33021;&#21147;&#21644;&#35748;&#30693;&#25935;&#38160;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.08018</link><description>&lt;p&gt;
Mol-Instructions: &#19968;&#20010;&#22823;&#35268;&#27169;&#29983;&#29289;&#20998;&#23376;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#20026;&#22823;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;
Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08018
&lt;/p&gt;
&lt;p&gt;
Mol-Instructions&#26159;&#19968;&#20010;&#19987;&#38376;&#20026;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#35774;&#35745;&#30340;&#32508;&#21512;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#29289;&#39046;&#22495;&#20013;&#30340;&#36866;&#24212;&#33021;&#21147;&#21644;&#35748;&#30693;&#25935;&#38160;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#20854;&#21331;&#36234;&#30340;&#20219;&#21153;&#22788;&#29702;&#33021;&#21147;&#21644;&#21019;&#26032;&#30340;&#36755;&#20986;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#25512;&#21160;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#29983;&#29289;&#20998;&#23376;&#30740;&#31350;&#31561;&#19987;&#19994;&#39046;&#22495;&#30340;&#29087;&#32451;&#24212;&#29992;&#36824;&#21463;&#21040;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Mol-Instructions&#65292;&#36825;&#26159;&#19968;&#20010;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#12289;&#19987;&#38376;&#38024;&#23545;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#35774;&#35745;&#30340;&#32508;&#21512;&#25351;&#20196;&#25968;&#25454;&#38598;&#12290;Mol-Instructions&#30001;&#19977;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#32452;&#25104;&#65306;&#20998;&#23376;&#23548;&#21521;&#25351;&#20196;&#12289;&#34507;&#30333;&#36136;&#23548;&#21521;&#25351;&#20196;&#21644;&#29983;&#29289;&#20998;&#23376;&#25991;&#26412;&#25351;&#20196;&#65292;&#27599;&#20010;&#37096;&#20998;&#37117;&#34987;&#31574;&#21010;&#29992;&#20110;&#22686;&#24378;LLM&#23545;&#29983;&#29289;&#20998;&#23376;&#29305;&#24615;&#21644;&#34892;&#20026;&#30340;&#29702;&#35299;&#21644;&#39044;&#27979;&#33021;&#21147;&#12290;&#36890;&#36807;&#23545;&#20195;&#34920;&#24615;LLM&#30340;&#24191;&#27867;&#25351;&#20196;&#35843;&#25972;&#23454;&#39564;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;Mol-Instructions&#22312;&#22686;&#24378;&#22823;&#27169;&#22411;&#22312;&#29983;&#29289;&#20998;&#23376;&#30740;&#31350;&#22797;&#26434;&#39046;&#22495;&#20869;&#30340;&#36866;&#24212;&#33021;&#21147;&#21644;&#35748;&#30693;&#25935;&#38160;&#24230;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#20174;&#32780;&#20419;&#36827;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a meticulously curated, comprehensive instruction dataset expressly designed for the biomolecular realm. Mol-Instructions is composed of three pivotal components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions, each curated to enhance the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on the representative LLM, we underscore the potency of Mol-Instructions to enhance the adaptability and cognitive acuity of large models within the complex sphere of biomolecular studies, thereby promoting advancements in the biomol
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38416;&#36848;&#20102;&#23545;&#20110;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26816;&#32034; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#19978;&#30456;&#20851;&#22270;&#29255;&#30340;&#25628;&#32034;&#24341;&#25806;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20013;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.07980</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#26263;&#32593;&#27963;&#21160;&#20998;&#31867;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Dark web activity classification using deep learning. (arXiv:2306.07980v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38416;&#36848;&#20102;&#23545;&#20110;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26816;&#32034; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#19978;&#30456;&#20851;&#22270;&#29255;&#30340;&#25628;&#32034;&#24341;&#25806;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20013;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24378;&#35843;&#20102;&#35782;&#21035;&#21644;&#25511;&#21046;&#26263;&#32593;&#38750;&#27861;&#27963;&#21160;&#30340;&#36843;&#20999;&#38656;&#35201;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#36890;&#36807; .onion &#25193;&#23637;&#21517;&#30340;&#32593;&#31449;&#26816;&#32034;&#38750;&#27861;&#27963;&#21160;&#30456;&#20851;&#22270;&#29255;&#30340;&#26032;&#22411;&#25628;&#32034;&#24341;&#25806;&#12290;&#22312;&#21517;&#20026; darkoob &#30340;&#20840;&#38754;&#25968;&#25454;&#38598;&#30340;&#27979;&#35797;&#20013;&#65292;&#35813;&#26041;&#27861;&#36798;&#21040;&#20102;94% &#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The present article highlights the pressing need for identifying and controlling illicit activities on the dark web. While only 4% of the information available on the internet is accessible through regular search engines, the deep web contains a plethora of information, including personal data and online accounts, that is not indexed by search engines. The dark web, which constitutes a subset of the deep web, is a notorious breeding ground for various illegal activities, such as drug trafficking, weapon sales, and money laundering. Against this backdrop, the authors propose a novel search engine that leverages deep learning to identify and extract relevant images related to illicit activities on the dark web. Specifically, the system can detect the titles of illegal activities on the dark web and retrieve pertinent images from websites with a .onion extension. The authors have collected a comprehensive dataset named darkoob and the proposed method achieves an accuracy of 94% on the tes
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#36870;&#25991;&#26723;&#39057;&#29575;&#65288;IDF&#65289;&#21644;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#65288;LDA&#65289;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#20197;&#26356;&#22909;&#22320;&#24212;&#23545;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#19981;&#21516;&#23646;&#24615;&#65292;&#36890;&#36807;&#22522;&#20110;&#28857;&#36190;&#25968;&#12289;&#35780;&#35770;&#25968;&#21644;&#36716;&#21457;&#25968;&#31561;&#23646;&#24615;&#23545;&#27599;&#20010;&#25991;&#26723;&#30340;&#37325;&#35201;&#24615;&#36827;&#34892;&#21152;&#26435;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#36807;&#28388;&#22122;&#22768;&#24182;&#35782;&#21035;&#26368;&#30456;&#20851;&#30340;&#20851;&#38190;&#35789;&#12290;</title><link>http://arxiv.org/abs/2306.07978</link><description>&lt;p&gt;
&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#23646;&#24615;&#22686;&#24378;&#20851;&#38190;&#35789;&#26816;&#27979;&#65306;&#22522;&#20110;IDF-LDA&#27169;&#22411;&#24212;&#29992;&#20110;&#26032;&#28010;&#24494;&#21338;
&lt;/p&gt;
&lt;p&gt;
Utilizing Social Media Attributes for Enhanced Keyword Detection: An IDF-LDA Model Applied to Sina Weibo. (arXiv:2306.07978v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#36870;&#25991;&#26723;&#39057;&#29575;&#65288;IDF&#65289;&#21644;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#65288;LDA&#65289;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#20197;&#26356;&#22909;&#22320;&#24212;&#23545;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#19981;&#21516;&#23646;&#24615;&#65292;&#36890;&#36807;&#22522;&#20110;&#28857;&#36190;&#25968;&#12289;&#35780;&#35770;&#25968;&#21644;&#36716;&#21457;&#25968;&#31561;&#23646;&#24615;&#23545;&#27599;&#20010;&#25991;&#26723;&#30340;&#37325;&#35201;&#24615;&#36827;&#34892;&#21152;&#26435;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#36807;&#28388;&#22122;&#22768;&#24182;&#35782;&#21035;&#26368;&#30456;&#20851;&#30340;&#20851;&#38190;&#35789;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;Twitter&#21644;&#24494;&#21338;&#31561;&#31038;&#20132;&#23186;&#20307;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#20174;&#22823;&#37327;&#23454;&#26102;&#25991;&#26412;&#25968;&#25454;&#27969;&#20013;&#26816;&#27979;&#20851;&#38190;&#35789;&#24050;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#30340;&#38382;&#39064;&#12290;&#20851;&#38190;&#35789;&#26816;&#27979;&#38382;&#39064;&#26088;&#22312;&#20174;&#28023;&#37327;&#25991;&#26412;&#25968;&#25454;&#20013;&#25628;&#32034;&#37325;&#35201;&#20449;&#24687;&#20197;&#21453;&#26144;&#26368;&#37325;&#35201;&#30340;&#20107;&#20214;&#25110;&#35805;&#39064;&#12290;&#28982;&#32780;&#65292;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#36890;&#24120;&#20855;&#26377;&#29420;&#29305;&#30340;&#29305;&#28857;&#65306;&#25991;&#26723;&#36890;&#24120;&#24456;&#30701;&#65292;&#35821;&#35328;&#21475;&#35821;&#21270;&#65292;&#24182;&#19988;&#25968;&#25454;&#24456;&#21487;&#33021;&#20855;&#26377;&#37325;&#35201;&#30340;&#26102;&#38388;&#27169;&#24335;&#12290;&#22240;&#27492;&#65292;&#20174;&#36825;&#20123;&#25991;&#26412;&#27969;&#20013;&#21457;&#29616;&#20851;&#38190;&#20449;&#24687;&#21487;&#33021;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#31038;&#20132;&#23186;&#20307;&#20013;&#30340;&#20851;&#38190;&#35789;&#26816;&#27979;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#23558;&#36870;&#25991;&#26723;&#39057;&#29575;&#65288;IDF&#65289;&#21644;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#65288;LDA&#65289;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#26356;&#22909;&#22320;&#24212;&#23545;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#19981;&#21516;&#23646;&#24615;&#65292;&#22914;&#28857;&#36190;&#25968;&#12289;&#35780;&#35770;&#25968;&#21644;&#36716;&#21457;&#25968;&#12290;&#36890;&#36807;&#22522;&#20110;&#36825;&#20123;&#23646;&#24615;&#23545;&#27599;&#20010;&#25991;&#26723;&#30340;&#37325;&#35201;&#24615;&#36827;&#34892;&#21152;&#26435;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#36807;&#28388;&#22122;&#22768;&#24182;&#35782;&#21035;&#26368;&#30456;&#20851;&#30340;&#20851;&#38190;&#35789;&#12290;&#25105;&#20204;&#22312;&#20013;&#22269;&#27969;&#34892;&#30340;&#24494;&#21338;&#24179;&#21488;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#31934;&#30830;&#24230;&#12289;&#21484;&#22238;&#29575;&#21644;F1&#24471;&#20998;&#26041;&#38754;&#20248;&#20110;&#22522;&#20934;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rapid development of social media such as Twitter and Weibo, detecting keywords from a huge volume of text data streams in real-time has become a critical problem. The keyword detection problem aims at searching important information from massive text data to reflect the most important events or topics. However, social media data usually has unique features: the documents are usually short, the language is colloquial, and the data is likely to have significant temporal patterns. Therefore, it could be challenging to discover critical information from these text streams. In this paper, we propose a novel method to address the keyword detection problem in social media. Our model combines the Inverse Document Frequency (IDF) and Latent Dirichlet Allocation (LDA) models to better cope with the distinct attributes of social media data, such as the number of likes, comments, and retweets. By weighting the importance of each document based on these attributes, our method can effectiv
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20221;&#22823;&#35268;&#27169;&#12289;&#30495;&#23454;&#30340;&#25968;&#25454;&#38598;KuaiSAR&#65292;&#35813;&#25968;&#25454;&#38598;&#35760;&#24405;&#20102;&#24555;&#25163;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#20013;&#30495;&#23454;&#30340;&#38598;&#25104;&#25628;&#32034;&#21644;&#25512;&#33616;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.07705</link><description>&lt;p&gt;
KuaiSAR: &#19968;&#20221;&#32479;&#19968;&#30340;&#25628;&#32034;&#19982;&#25512;&#33616;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
KuaiSAR: A Unified Search And Recommendation Dataset. (arXiv:2306.07705v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07705
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20221;&#22823;&#35268;&#27169;&#12289;&#30495;&#23454;&#30340;&#25968;&#25454;&#38598;KuaiSAR&#65292;&#35813;&#25968;&#25454;&#38598;&#35760;&#24405;&#20102;&#24555;&#25163;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#20013;&#30495;&#23454;&#30340;&#38598;&#25104;&#25628;&#32034;&#21644;&#25512;&#33616;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#21644;&#25512;&#33616;&#26381;&#21153;&#30340;&#34701;&#21512;&#26159;&#20687;&#24555;&#25163;&#21644;&#25238;&#38899;&#36825;&#26679;&#30340;&#22312;&#32447;&#20869;&#23481;&#24179;&#21488;&#30340;&#37325;&#35201;&#26041;&#38754;&#12290;S&amp;R&#24314;&#27169;&#30340;&#25972;&#21512;&#26159;&#19994;&#30028;&#23454;&#36341;&#32773;&#37319;&#29992;&#30340;&#39640;&#24230;&#30452;&#35266;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#65292;&#23398;&#26415;&#30028;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#36827;&#34892;&#30340;&#30740;&#31350;&#26126;&#26174;&#19981;&#36275;&#12290;&#22240;&#27492;&#65292;&#22312;&#23398;&#26415;&#30028;&#21644;&#20135;&#19994;&#30028;&#20043;&#38388;&#22312;&#36825;&#20010;&#39046;&#22495;&#36827;&#34892;&#30740;&#31350;&#30340;&#23454;&#36341;&#20043;&#38388;&#20986;&#29616;&#20102;&#23454;&#36136;&#24615;&#30340;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24555;&#25163;&#30340;&#19968;&#20010;&#39046;&#20808;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#25910;&#38598;&#30340;&#38598;&#25104;&#25628;&#32034;&#19982;&#25512;&#33616;&#34892;&#20026;&#30340;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;KuaiSAR&#12290;&#19982;&#20197;&#21069;&#30340;&#25968;&#25454;&#38598;&#19981;&#21516;&#65292;KuaiSAR&#35760;&#24405;&#20102;&#30495;&#23454;&#29992;&#25143;&#30340;&#34892;&#20026;&#65292;&#27599;&#20010;&#34892;&#20026;&#30340;&#21457;&#29983;&#26102;&#38388;&#37117;&#34987;&#31934;&#30830;&#35760;&#24405;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
The confluence of Search and Recommendation services is a vital aspect of online content platforms like Kuaishou and TikTok. The integration of S&amp;R modeling is a highly intuitive approach adopted by industry practitioners. However, there is a noticeable lack of research conducted in this area within the academia, primarily due to the absence of publicly available datasets. Consequently, a substantial gap has emerged between academia and industry regarding research endeavors in this field. To bridge this gap, we introduce the first large-scale, real-world dataset KuaiSAR of integrated Search And Recommendation behaviors collected from Kuaishou, a leading short-video app in China with over 300 million daily active users. Previous research in this field has predominantly employed publicly available datasets that are semi-synthetic and simulated, with artificially fabricated search behaviors. Distinct from previous datasets, KuaiSAR records genuine user behaviors, the occurrence of each in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#65292;&#20294;&#26412;&#25991;&#25552;&#20986;&#30340;&#19968;&#31181;&#31639;&#27861;&#36890;&#36807;&#24809;&#32602;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#21019;&#24314;&#32773;&#65292;&#25104;&#21151;&#22320;&#28608;&#21169;&#20102;&#29983;&#20135;&#32773;&#21019;&#36896;&#39640;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.07479</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;
&lt;/p&gt;
&lt;p&gt;
Incentivizing High-Quality Content in Online Recommender Systems. (arXiv:2306.07479v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#65292;&#20294;&#26412;&#25991;&#25552;&#20986;&#30340;&#19968;&#31181;&#31639;&#27861;&#36890;&#36807;&#24809;&#32602;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#21019;&#24314;&#32773;&#65292;&#25104;&#21151;&#22320;&#28608;&#21169;&#20102;&#29983;&#20135;&#32773;&#21019;&#36896;&#39640;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20687;TikTok&#21644;YouTube&#36825;&#26679;&#30340;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#65292;&#24179;&#21488;&#30340;&#20915;&#31574;&#31639;&#27861;&#22609;&#36896;&#20102;&#20869;&#23481;&#29983;&#20135;&#32773;&#30340;&#28608;&#21169;&#65292;&#21253;&#25324;&#29983;&#20135;&#32773;&#22312;&#20869;&#23481;&#36136;&#37327;&#19978;&#25237;&#20837;&#22810;&#23569;&#21162;&#21147;&#12290;&#35768;&#22810;&#24179;&#21488;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#65292;&#36825;&#20250;&#20135;&#29983;&#36328;&#26102;&#38388;&#30340;&#28608;&#21169;&#65292;&#22240;&#20026;&#20170;&#22825;&#29983;&#20135;&#30340;&#20869;&#23481;&#20250;&#24433;&#21709;&#26410;&#26469;&#20869;&#23481;&#30340;&#25512;&#33616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#20135;&#29983;&#30340;&#28608;&#21169;&#65292;&#20998;&#26512;&#20102;&#22312;&#32435;&#20160;&#22343;&#34913;&#19979;&#29983;&#20135;&#30340;&#20869;&#23481;&#36136;&#37327;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20687;Hedge&#21644;EXP3&#36825;&#26679;&#30340;&#32463;&#20856;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;&#29305;&#21035;&#22320;&#65292;&#20869;&#23481;&#36136;&#37327;&#22312;&#23398;&#20064;&#29575;&#26041;&#38754;&#26377;&#19978;&#38480;&#65292;&#24182;&#19988;&#38543;&#30528;&#20856;&#22411;&#23398;&#20064;&#29575;&#36827;&#23637;&#32780;&#36235;&#36817;&#20110;&#38646;&#12290;&#22312;&#36825;&#19968;&#36127;&#38754;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;&#22522;&#20110;&#24809;&#32602;&#21019;&#24314;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#29983;&#20135;&#32773;&#8212;&#8212;&#27491;&#30830;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#39640;&#36136;&#37327;&#20869;&#23481;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#26032;&#39062;&#30340;&#31574;&#30053;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#20811;&#26381;&#20102;&#22312;&#32452;&#21512;&#35774;&#32622;&#20013;&#24212;&#29992;&#23545;&#25239;&#24615;&#25216;&#26415;&#30340;&#25361;&#25112;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#25104;&#21151;&#22320;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#39640;&#36136;&#37327;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
For content recommender systems such as TikTok and YouTube, the platform's decision algorithm shapes the incentives of content producers, including how much effort the content producers invest in the quality of their content. Many platforms employ online learning, which creates intertemporal incentives, since content produced today affects recommendations of future content. In this paper, we study the incentives arising from online learning, analyzing the quality of content produced at a Nash equilibrium. We show that classical online learning algorithms, such as Hedge and EXP3, unfortunately incentivize producers to create low-quality content. In particular, the quality of content is upper bounded in terms of the learning rate and approaches zero for typical learning rate schedules. Motivated by this negative result, we design a different learning algorithm -- based on punishing producers who create low-quality content -- that correctly incentivizes producers to create high-quality co
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#26159;&#21542;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#25277;&#35937;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#33258;&#21160;&#29983;&#25104;&#27861;&#24459;&#26696;&#20363;&#21028;&#20915;&#30340;&#25688;&#35201;&#65292;&#24182;&#22312;&#21360;&#24230;&#30340;&#27861;&#24237;&#26696;&#20363;&#21028;&#20915;&#20013;&#36827;&#34892;&#20102;&#30456;&#20851;&#23454;&#39564;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.01248</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#25277;&#35937;&#27169;&#22411;&#21644;LLMs&#22312;&#27861;&#24459;&#26696;&#20363;&#21028;&#20915;&#25688;&#35201;&#20013;&#30340;&#24212;&#29992;&#20934;&#22791;&#24773;&#20917;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?. (arXiv:2306.01248v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01248
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#26159;&#21542;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#25277;&#35937;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#33258;&#21160;&#29983;&#25104;&#27861;&#24459;&#26696;&#20363;&#21028;&#20915;&#30340;&#25688;&#35201;&#65292;&#24182;&#22312;&#21360;&#24230;&#30340;&#27861;&#24237;&#26696;&#20363;&#21028;&#20915;&#20013;&#36827;&#34892;&#20102;&#30456;&#20851;&#23454;&#39564;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#25688;&#35201;&#27861;&#24459;&#26696;&#20363;&#21028;&#20915;&#19968;&#30452;&#26159;&#37319;&#29992;&#25277;&#21462;&#24335;&#25688;&#35201;&#26041;&#27861;&#23581;&#35797;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36817;&#24180;&#26469;&#65292;&#20855;&#26377;&#29983;&#25104;&#26356;&#33258;&#28982;&#21644;&#36830;&#36143;&#25688;&#35201;&#33021;&#21147;&#30340;&#25277;&#35937;&#25688;&#35201;&#27169;&#22411;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#29616;&#22312;&#24050;&#32463;&#26377;&#20102;&#19987;&#38376;&#29992;&#20110;&#27861;&#24459;&#39046;&#22495;&#30340;&#39044;&#35757;&#32451;&#25277;&#35937;&#25688;&#35201;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#22914;ChatGPT&#36825;&#26679;&#30340;&#36890;&#29992;&#39046;&#22495;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25991;&#26412;&#65292;&#24182;&#20855;&#26377;&#25991;&#26412;&#25688;&#35201;&#30340;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#20540;&#24471;&#38382;&#30340;&#26159;&#65292;&#36825;&#20123;&#27169;&#22411;&#26159;&#21542;&#24050;&#20934;&#22791;&#22909;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#26696;&#20363;&#21028;&#20915;&#30340;&#25277;&#35937;&#25688;&#35201;&#12290;&#20026;&#20102;&#25506;&#35752;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#39046;&#22495;&#29305;&#23450;&#30340;&#25277;&#35937;&#24615;&#25688;&#35201;&#27169;&#22411;&#21644;&#36890;&#29992;&#39046;&#22495;&#30340;LLMs&#24212;&#29992;&#20110;&#21360;&#24230;&#27861;&#24237;&#26696;&#20363;&#21028;&#20915;&#20013;&#65292;&#24182;&#26816;&#26597;&#25152;&#29983;&#25104;&#25688;&#35201;&#30340;&#36136;&#37327;&#12290;&#38500;&#20102;&#25688;&#35201;&#36136;&#37327;&#30340;&#26631;&#20934;&#24230;&#37327;&#65292;&#25105;&#20204;&#36824;&#26816;&#26597;&#20102;&#29983;&#25104;&#30340;&#25688;&#35201;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#19981;&#19968;&#33268;&#24615;&#21644;&#34394;&#26500;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatic summarization of legal case judgements has traditionally been attempted by using extractive summarization methods. However, in recent years, abstractive summarization models are gaining popularity since they can generate more natural and coherent summaries. Legal domain-specific pre-trained abstractive summarization models are now available. Moreover, general-domain pre-trained Large Language Models (LLMs), such as ChatGPT, are known to generate high-quality text and have the capacity for text summarization. Hence it is natural to ask if these models are ready for off-the-shelf application to automatically generate abstractive summaries for case judgements. To explore this question, we apply several state-of-the-art domain-specific abstractive summarization models and general-domain LLMs on Indian court case judgements, and check the quality of the generated summaries. In addition to standard metrics for summary quality, we check for inconsistencies and hallucinations in the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22810;&#35821;&#31181;&#29992;&#25143;&#26597;&#35810;&#25340;&#20889;&#26816;&#26597;&#22120;&#65292;&#23427;&#38750;&#24120;&#24555;&#36895;&#12289;&#21487;&#25193;&#23637;&#65292;&#24182;&#26681;&#25454;&#29305;&#23450;&#20135;&#21697;&#30340;&#38656;&#27714;&#35843;&#25972;&#20854;&#35789;&#27719;&#34920;&#21644;&#25340;&#20889;&#36755;&#20986;&#65292;&#20197;&#28385;&#36275;&#29992;&#25143;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2305.01082</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22810;&#35821;&#31181;&#29992;&#25143;&#26597;&#35810;&#25340;&#20889;&#26816;&#26597;&#22120;
&lt;/p&gt;
&lt;p&gt;
Contextual Multilingual Spellchecker for User Queries. (arXiv:2305.01082v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22810;&#35821;&#31181;&#29992;&#25143;&#26597;&#35810;&#25340;&#20889;&#26816;&#26597;&#22120;&#65292;&#23427;&#38750;&#24120;&#24555;&#36895;&#12289;&#21487;&#25193;&#23637;&#65292;&#24182;&#26681;&#25454;&#29305;&#23450;&#20135;&#21697;&#30340;&#38656;&#27714;&#35843;&#25972;&#20854;&#35789;&#27719;&#34920;&#21644;&#25340;&#20889;&#36755;&#20986;&#65292;&#20197;&#28385;&#36275;&#29992;&#25143;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25340;&#20889;&#26816;&#26597;&#26159;&#26368;&#22522;&#26412;&#21644;&#24191;&#27867;&#20351;&#29992;&#30340;&#25628;&#32034;&#21151;&#33021;&#20043;&#19968;&#12290;&#32416;&#27491;&#25340;&#20889;&#38169;&#35823;&#30340;&#29992;&#25143;&#26597;&#35810;&#19981;&#20165;&#22686;&#24378;&#20102;&#29992;&#25143;&#20307;&#39564;&#65292;&#32780;&#19988;&#29992;&#25143;&#20063;&#26399;&#26395;&#33021;&#22815;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24191;&#27867;&#21487;&#29992;&#30340;&#25340;&#20889;&#26816;&#26597;&#35299;&#20915;&#26041;&#26696;&#35201;&#20040;&#27604;&#26368;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#31934;&#24230;&#20302;&#65292;&#35201;&#20040;&#36895;&#24230;&#22826;&#24930;&#65292;&#26080;&#27861;&#29992;&#20110;&#24310;&#36831;&#26159;&#20851;&#38190;&#35201;&#27714;&#30340;&#25628;&#32034;&#29992;&#20363;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#26368;&#26032;&#30340;&#21019;&#26032;&#26550;&#26500;&#38598;&#20013;&#22312;&#33521;&#35821;&#19978;&#65292;&#24182;&#19988;&#27809;&#26377;&#20197;&#22810;&#35821;&#35328;&#26041;&#24335;&#36827;&#34892;&#22521;&#35757;&#65292;&#24182;&#19988;&#26159;&#38024;&#23545;&#36739;&#38271;&#25991;&#26412;&#30340;&#25340;&#20889;&#32416;&#27491;&#36827;&#34892;&#22521;&#35757;&#65292;&#36825;&#26159;&#19982;&#23545;&#29992;&#25143;&#26597;&#35810;&#30340;&#25340;&#20889;&#32416;&#27491;&#19981;&#21516;&#30340;&#33539;&#24335;&#65292;&#20854;&#20013;&#19978;&#19979;&#25991;&#24456;&#23569;(&#22823;&#22810;&#25968;&#26597;&#35810;&#21482;&#26377;1-2&#20010;&#21333;&#35789;)&#12290;&#26368;&#21518;&#65292;&#30001;&#20110;&#22823;&#22810;&#25968;&#20225;&#19994;&#26377;&#29420;&#29305;&#30340;&#35789;&#27719;&#65292;&#20363;&#22914;&#20135;&#21697;&#21517;&#31216;&#65292;&#29616;&#25104;&#30340;&#25340;&#20889;&#35299;&#20915;&#26041;&#26696;&#26080;&#27861;&#28385;&#36275;&#29992;&#25143;&#30340;&#38656;&#27714;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#35821;&#35328;&#25340;&#20889;&#26816;&#26597;&#22120;&#65292;&#23427;&#38750;&#24120;&#24555;&#36895;&#21644;&#21487;&#25193;&#23637;&#65292;&#24182;&#26681;&#25454;&#29305;&#23450;&#20135;&#21697;&#30340;&#38656;&#27714;&#35843;&#25972;&#20854;&#35789;&#27719;&#34920;&#21644;&#25340;&#20889;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spellchecking is one of the most fundamental and widely used search features. Correcting incorrectly spelled user queries not only enhances the user experience but is expected by the user. However, most widely available spellchecking solutions are either lower accuracy than state-of-the-art solutions or too slow to be used for search use cases where latency is a key requirement. Furthermore, most innovative recent architectures focus on English and are not trained in a multilingual fashion and are trained for spell correction in longer text, which is a different paradigm from spell correction for user queries, where context is sparse (most queries are 1-2 words long). Finally, since most enterprises have unique vocabularies such as product names, off-the-shelf spelling solutions fall short of users' needs. In this work, we build a multilingual spellchecker that is extremely fast and scalable and that adapts its vocabulary and hence speller output based on a specific product's needs. Fu
&lt;/p&gt;</description></item><item><title>LightGCL&#26159;&#19968;&#31181;&#26032;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#36275;&#12290;&#35813;&#27169;&#22411;&#37319;&#29992;&#22855;&#24322;&#20540;&#20998;&#35299;&#36827;&#34892;&#23545;&#27604;&#22686;&#24378;&#65292;&#26356;&#22909;&#22320;&#20445;&#30041;&#20102;&#20869;&#22312;&#30340;&#35821;&#20041;&#32467;&#26500;&#65292;&#24182;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#36890;&#29992;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.08191</link><description>&lt;p&gt;
LightGCL: &#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#29992;&#20110;&#25512;&#33616;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation. (arXiv:2302.08191v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08191
&lt;/p&gt;
&lt;p&gt;
LightGCL&#26159;&#19968;&#31181;&#26032;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#36275;&#12290;&#35813;&#27169;&#22411;&#37319;&#29992;&#22855;&#24322;&#20540;&#20998;&#35299;&#36827;&#34892;&#23545;&#27604;&#22686;&#24378;&#65292;&#26356;&#22909;&#22320;&#20445;&#30041;&#20102;&#20869;&#22312;&#30340;&#35821;&#20041;&#32467;&#26500;&#65292;&#24182;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#36890;&#29992;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#26041;&#27861;&#12290;&#26368;&#36817;&#65292;&#23558;&#23545;&#27604;&#23398;&#20064;&#19982;GNN&#32467;&#21512;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20351;&#29992;&#65292;&#22312;&#22788;&#29702;&#39640;&#24230;&#31232;&#30095;&#30340;&#25968;&#25454;&#26041;&#38754;&#37319;&#21462;&#25968;&#25454;&#22686;&#24378;&#26041;&#26696;&#65292;&#24050;&#32463;&#26174;&#31034;&#20986;&#36229;&#36234;&#20854;&#20182;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#22312;&#20854;&#25104;&#21151;&#30340;&#22522;&#30784;&#19978;&#65292;&#29616;&#26377;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#22823;&#22810;&#35201;&#20040;&#22312;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#22270;&#19978;&#25191;&#34892;&#38543;&#26426;&#25200;&#21160;(&#20363;&#22914;&#33410;&#28857;/&#36793;&#25200;&#21160;)&#65292;&#35201;&#20040;&#20381;&#36182;&#20110;&#21551;&#21457;&#24335;&#30340;&#22686;&#24378;&#25216;&#26415;(&#20363;&#22914;&#29992;&#25143;&#32858;&#31867;)&#26469;&#29983;&#25104;&#23545;&#27604;&#35270;&#22270;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#36825;&#20123;&#26041;&#27861;&#19981;&#33021;&#24456;&#22909;&#22320;&#20445;&#25345;&#20869;&#22312;&#30340;&#35821;&#20041;&#32467;&#26500;&#65292;&#24182;&#19988;&#24456;&#23481;&#26131;&#21463;&#21040;&#22122;&#38899;&#25200;&#21160;&#30340;&#24433;&#21709;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;LightGCL&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;&#33539;&#24335;&#65292;&#35299;&#20915;&#20102;&#23545;&#27604;&#23398;&#20064;&#27169;&#22411;&#22240;&#22122;&#38899;&#32780;&#22833;&#21435;&#36890;&#29992;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20165;&#20351;&#29992;&#22855;&#24322;&#20540;&#20998;&#35299;&#36827;&#34892;&#23545;&#27604;&#22686;&#24378;&#65292;&#20351;&#20854;&#26356;&#22909;&#22320;&#20445;&#30041;&#20102;&#20869;&#22312;&#30340;&#35821;&#20041;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural network (GNN) is a powerful learning approach for graph-based recommender systems. Recently, GNNs integrated with contrastive learning have shown superior performance in recommendation with their data augmentation schemes, aiming at dealing with highly sparse data. Despite their success, most existing graph contrastive learning methods either perform stochastic augmentation (e.g., node/edge perturbation) on the user-item interaction graph, or rely on the heuristic-based augmentation techniques (e.g., user clustering) for generating contrastive views. We argue that these methods cannot well preserve the intrinsic semantic structures and are easily biased by the noise perturbation. In this paper, we propose a simple yet effective graph contrastive learning paradigm LightGCL that mitigates these issues impairing the generality and robustness of CL-based recommenders. Our model exclusively utilizes singular value decomposition for contrastive augmentation, which enables the un
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861; iDCF&#65292;&#36890;&#36807;&#23398;&#20064;&#21487;&#35782;&#21035;&#30340;&#28151;&#28102;&#22240;&#32032;&#26469;&#28040;&#38500;&#25512;&#33616;&#20559;&#24046;&#65292;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#26377;&#25928;&#24615;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2302.05052</link><description>&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#28040;&#38500;&#25512;&#33616;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Debiasing Recommendation by Learning Identifiable Latent Confounders. (arXiv:2302.05052v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861; iDCF&#65292;&#36890;&#36807;&#23398;&#20064;&#21487;&#35782;&#21035;&#30340;&#28151;&#28102;&#22240;&#32032;&#26469;&#28040;&#38500;&#25512;&#33616;&#20559;&#24046;&#65292;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#26377;&#25928;&#24615;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#39044;&#27979;&#29992;&#25143;&#23545;&#26410;&#34987;&#26333;&#20809;&#30340;&#29289;&#21697;&#30340;&#21453;&#39304;&#12290;&#28151;&#28102;&#20559;&#24046;&#26159;&#30001;&#20110;&#23384;&#22312;&#26410;&#27979;&#37327;&#30340;&#21464;&#37327;&#65288;&#20363;&#22914;&#65292;&#29992;&#25143;&#30340;&#31038;&#20250;&#32463;&#27982;&#29366;&#20917;&#65289;&#21487;&#33021;&#20250;&#24433;&#21709;&#29992;&#25143;&#30340;&#26333;&#20809;&#21644;&#21453;&#39304;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#35201;&#20040;&#23545;&#36825;&#20123;&#26410;&#27979;&#37327;&#21464;&#37327;&#20570;&#20986;&#19981;&#21487;&#34892;&#30340;&#20551;&#35774;&#65292;&#35201;&#20040;&#30452;&#25509;&#25512;&#26029;&#29992;&#25143;&#30340;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#26080;&#27861;&#20445;&#35777;&#35782;&#21035;&#20986;&#21453;&#20107;&#23454;&#30340;&#21453;&#39304;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#24102;&#26377;&#20559;&#35265;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#21487;&#35782;&#21035;&#30340;&#21435;&#28151;&#28102;&#65288;iDCF&#65289;&#65292;&#23427;&#21033;&#29992;&#19968;&#32452;&#20195;&#29702;&#21464;&#37327;&#65288;&#20363;&#22914;&#65292;&#35266;&#23519;&#21040;&#30340;&#29992;&#25143;&#29305;&#24449;&#65289;&#26469;&#35299;&#20915;&#19978;&#36848;&#30340;&#38750;&#35782;&#21035;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;iDCF&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#21435;&#28151;&#28102;&#30340;&#25512;&#33616;&#26694;&#26550;&#65292;&#23427;&#24212;&#29992;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#26469;&#25512;&#26029;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#24182;&#35782;&#21035;&#21453;&#20107;&#23454;&#30340;&#21453;&#39304;&#65292;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#21508;&#31181;&#30495;&#23454;&#19990;&#30028;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#24191;&#27867;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20943;&#23569;&#28151;&#28102;&#20559;&#24046;&#21644;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems aim to predict users' feedback on items not exposed to them.  Confounding bias arises due to the presence of unmeasured variables (e.g., the socio-economic status of a user) that can affect both a user's exposure and feedback. Existing methods either (1) make untenable assumptions about these unmeasured variables or (2) directly infer latent confounders from users' exposure. However, they cannot guarantee the identification of counterfactual feedback, which can lead to biased predictions. In this work, we propose a novel method, i.e., identifiable deconfounder (iDCF), which leverages a set of proxy variables (e.g., observed user features) to resolve the aforementioned non-identification issue. The proposed iDCF is a general deconfounded recommendation framework that applies proximal causal inference to infer the unmeasured confounders and identify the counterfactual feedback with theoretical guarantees. Extensive experiments on various real-world and synthetic da
&lt;/p&gt;</description></item><item><title>RLTP&#31639;&#27861;&#26159;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24191;&#21578;&#39044;&#21152;&#36733;&#36807;&#31243;&#20013;&#30340;&#24310;&#36831;&#21360;&#35937;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2302.02592</link><description>&lt;p&gt;
RLTP&#31639;&#27861;&#65306;&#29992;&#20110;&#39044;&#21152;&#36733;&#24191;&#21578;&#20013;&#30340;&#24310;&#36831;&#21360;&#35937;&#24314;&#27169;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
RLTP: Reinforcement Learning to Pace for Delayed Impression Modeling in Preloaded Ads. (arXiv:2302.02592v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02592
&lt;/p&gt;
&lt;p&gt;
RLTP&#31639;&#27861;&#26159;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24191;&#21578;&#39044;&#21152;&#36733;&#36807;&#31243;&#20013;&#30340;&#24310;&#36831;&#21360;&#35937;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22686;&#21152;&#21697;&#29260;&#30693;&#21517;&#24230;&#65292;&#35768;&#22810;&#24191;&#21578;&#21830;&#19982;&#24191;&#21578;&#24179;&#21488;&#31614;&#35746;&#21512;&#21516;&#36141;&#20080;&#24191;&#21578;&#27969;&#37327;&#65292;&#28982;&#21518;&#23558;&#24191;&#21578;&#25237;&#25918;&#21040;&#30446;&#26631;&#21463;&#20247;&#20013;&#12290;&#22312;&#25972;&#20010;&#24191;&#21578;&#25237;&#25918;&#26399;&#38388;&#65292;&#24191;&#21578;&#21830;&#36890;&#24120;&#24076;&#26395;&#24191;&#21578;&#33719;&#24471;&#29305;&#23450;&#30340;&#21360;&#35937;&#25968;&#65292;&#24182;&#26399;&#26395;&#24191;&#21578;&#23637;&#31034;&#30340;&#25928;&#26524;&#36234;&#22909;&#36234;&#22909;&#65288;&#22914;&#39640;&#28857;&#20987;&#29575;&#65289;&#12290;&#24191;&#21578;&#24179;&#21488;&#36890;&#36807;&#23454;&#26102;&#35843;&#25972;&#27969;&#37327;&#35831;&#27714;&#30340;&#36873;&#25321;&#27010;&#29575;&#26469;&#28385;&#36275;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#21457;&#24067;&#32773;&#30340;&#31574;&#30053;&#20063;&#20250;&#24433;&#21709;&#24191;&#21578;&#25237;&#25918;&#36807;&#31243;&#65292;&#36825;&#26159;&#24191;&#21578;&#24179;&#21488;&#26080;&#27861;&#25511;&#21046;&#30340;&#12290;&#39044;&#21152;&#36733;&#26159;&#35768;&#22810;&#31867;&#22411;&#24191;&#21578;&#65288;&#22914;&#35270;&#39057;&#24191;&#21578;&#65289;&#30340;&#24120;&#29992;&#31574;&#30053;&#65292;&#20197;&#30830;&#20445;&#22312;&#27969;&#37327;&#35831;&#27714;&#21518;&#26174;&#31034;&#30340;&#21709;&#24212;&#26102;&#38388;&#26159;&#21512;&#29702;&#30340;&#65292;&#36825;&#23558;&#23548;&#33268;&#24310;&#36831;&#21360;&#35937;&#29616;&#35937;&#12290;&#20256;&#32479;&#30340;&#37197;&#36895;&#31639;&#27861;&#26080;&#27861;&#24456;&#22909;&#22320;&#22788;&#29702;&#39044;&#21152;&#36733;&#30340;&#29305;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#20381;&#36182;&#20110;&#21363;&#26102;&#21453;&#39304;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
To increase brand awareness, many advertisers conclude contracts with advertising platforms to purchase traffic and then deliver advertisements to target audiences. In a whole delivery period, advertisers usually desire a certain impression count for the ads, and they also expect that the delivery performance is as good as possible (e.g., obtaining high click-through rate). Advertising platforms employ pacing algorithms to satisfy the demands via adjusting the selection probabilities to traffic requests in real-time. However, the delivery procedure is also affected by the strategies from publishers, which cannot be controlled by advertising platforms. Preloading is a widely used strategy for many types of ads (e.g., video ads) to make sure that the response time for displaying after a traffic request is legitimate, which results in delayed impression phenomenon. Traditional pacing algorithms cannot handle the preloading nature well because they rely on immediate feedback signals, and m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#24178;&#39044;&#26041;&#27861;&#26469;&#25552;&#39640;&#25991;&#26412;&#21305;&#37197;&#25512;&#33616;&#31995;&#32479;&#30340;&#36328;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24120;&#29992;&#30340;&#22522;&#20110;&#31934;&#35843;&#27169;&#22411;&#30340;&#26041;&#27861;&#22312;&#20855;&#26377;&#26032;&#39046;&#22495;&#25968;&#25454;&#26102;&#26377;&#21453;&#25928;&#26524;&#65292;&#20026;&#27492;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#24178;&#39044;&#30340;&#37325;&#35201;&#24615;&#24230;&#37327;&#26469;&#35299;&#37322;&#27867;&#21270;&#22833;&#36133;&#30340;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2210.10636</link><description>&lt;p&gt;
&#20351;&#29992;&#24178;&#39044;&#26041;&#27861;&#25552;&#39640;&#25991;&#26412;&#21305;&#37197;&#25512;&#33616;&#31995;&#32479;&#30340;&#36328;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Using Interventions to Improve Out-of-Distribution Generalization of Text-Matching Recommendation Systems. (arXiv:2210.10636v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10636
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#24178;&#39044;&#26041;&#27861;&#26469;&#25552;&#39640;&#25991;&#26412;&#21305;&#37197;&#25512;&#33616;&#31995;&#32479;&#30340;&#36328;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24120;&#29992;&#30340;&#22522;&#20110;&#31934;&#35843;&#27169;&#22411;&#30340;&#26041;&#27861;&#22312;&#20855;&#26377;&#26032;&#39046;&#22495;&#25968;&#25454;&#26102;&#26377;&#21453;&#25928;&#26524;&#65292;&#20026;&#27492;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#24178;&#39044;&#30340;&#37325;&#35201;&#24615;&#24230;&#37327;&#26469;&#35299;&#37322;&#27867;&#21270;&#22833;&#36133;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#29992;&#25143;&#30340;&#36755;&#20837;&#25991;&#26412;&#65292;&#25991;&#26412;&#21305;&#37197;&#25512;&#33616;&#31995;&#32479;&#36890;&#36807;&#23558;&#36755;&#20837;&#25991;&#26412;&#19982;&#21487;&#29992;&#21830;&#21697;&#30340;&#25551;&#36848;&#36827;&#34892;&#27604;&#36739;&#26469;&#36755;&#20986;&#30456;&#20851;&#21830;&#21697;&#65292;&#20363;&#22914;&#22312;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#21830;&#21697;&#25512;&#33616;&#12290;&#30001;&#20110;&#29992;&#25143;&#30340;&#20852;&#36259;&#21644;&#29289;&#21697;&#24211;&#23384;&#39044;&#35745;&#20250;&#21457;&#29983;&#21464;&#21270;&#65292;&#22240;&#27492;&#25991;&#26412;&#21305;&#37197;&#31995;&#32479;&#20855;&#26377;&#27867;&#21270;&#33267;&#25968;&#25454;&#21464;&#21270;&#30340;&#33021;&#21147;&#65292;&#36825;&#26159;&#19968;&#39033;&#31216;&#20026;&#36328;&#39046;&#22495;&#65288;OOD&#65289;&#27867;&#21270;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#31934;&#35843;&#22823;&#22411;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#30456;&#23545;&#20110;&#24050;&#37197;&#23545;&#30340;&#21830;&#21697;&#30456;&#20851;&#25968;&#25454;&#65288;&#20363;&#22914;&#29992;&#25143;&#28857;&#20987;&#65289;&#30340;&#27969;&#34892;&#26041;&#27861;&#21487;&#33021;&#23545;OOD&#27867;&#21270;&#20855;&#26377;&#21453;&#25928;&#26524;&#12290;&#23545;&#20110;&#21830;&#21697;&#25512;&#33616;&#20219;&#21153;&#65292;&#22312;&#25512;&#33616;&#26032;&#31867;&#21035;&#25110;&#26410;&#26469;&#26102;&#38388;&#27573;&#30340;&#21830;&#21697;&#26102;&#65292;&#24494;&#35843;&#33719;&#24471;&#30340;&#20934;&#30830;&#24615;&#27604;&#22522;&#30784;&#27169;&#22411;&#26356;&#24046;&#12290;&#20026;&#20102;&#35299;&#37322;&#36825;&#31181;&#27867;&#21270;&#22833;&#36133;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#24178;&#39044;&#30340;&#37325;&#35201;&#24615;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#26174;&#31034;&#24494;&#35843;&#27169;&#22411;&#25429;&#25417;&#20102;&#34394;&#20551;&#30456;&#20851;&#24615;&#65292;&#24182;&#26410;&#23398;&#20064;&#30830;&#23450;&#20219;&#20309;&#20004;&#20010;&#25991;&#26412;&#20043;&#38388;&#30456;&#20851;&#24615;&#30340;&#22240;&#26524;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a user's input text, text-matching recommender systems output relevant items by comparing the input text to available items' description, such as product-to-product recommendation on e-commerce platforms. As users' interests and item inventory are expected to change, it is important for a text-matching system to generalize to data shifts, a task known as out-of-distribution (OOD) generalization. However, we find that the popular approach of fine-tuning a large, base language model on paired item relevance data (e.g., user clicks) can be counter-productive for OOD generalization. For a product recommendation task, fine-tuning obtains worse accuracy than the base model when recommending items in a new category or for a future time period. To explain this generalization failure, we consider an intervention-based importance metric, which shows that a fine-tuned model captures spurious correlations and fails to learn the causal features that determine the relevance between any two tex
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;PLAtE&#30340;&#22823;&#35268;&#27169;&#21015;&#34920;&#39029;&#32593;&#32476;&#25277;&#21462;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#20174;&#20135;&#21697;&#35780;&#35770;&#39029;&#38754;&#20013;&#25552;&#21462;&#21830;&#21697;&#21015;&#34920;&#21644;&#20135;&#21697;&#23646;&#24615;&#12290;&#25968;&#25454;&#38598;&#30001;52,898&#20010;&#39033;&#30446;&#21644;156,014&#20010;&#23646;&#24615;&#32452;&#25104;&#65292;&#26159;&#31532;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#21015;&#34920;&#39029;&#32593;&#32476;&#25277;&#21462;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2205.12386</link><description>&lt;p&gt;
PLAtE: &#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#21015;&#34920;&#39029;&#32593;&#32476;&#25277;&#21462;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
PLAtE: A Large-scale Dataset for List Page Web Extraction. (arXiv:2205.12386v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12386
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;PLAtE&#30340;&#22823;&#35268;&#27169;&#21015;&#34920;&#39029;&#32593;&#32476;&#25277;&#21462;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#20174;&#20135;&#21697;&#35780;&#35770;&#39029;&#38754;&#20013;&#25552;&#21462;&#21830;&#21697;&#21015;&#34920;&#21644;&#20135;&#21697;&#23646;&#24615;&#12290;&#25968;&#25454;&#38598;&#30001;52,898&#20010;&#39033;&#30446;&#21644;156,014&#20010;&#23646;&#24615;&#32452;&#25104;&#65292;&#26159;&#31532;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#21015;&#34920;&#39029;&#32593;&#32476;&#25277;&#21462;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31070;&#32463;&#27169;&#22411;&#34987;&#21033;&#29992;&#26469;&#26174;&#33879;&#25552;&#39640;&#20174;&#21322;&#32467;&#26500;&#21270;&#32593;&#31449;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#32487;&#32493;&#36827;&#27493;&#30340;&#38556;&#30861;&#26159;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#25968;&#37327;&#22826;&#23569;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102; PLAtE &#65288;Pages of Lists Attribute Extraction&#65289;&#22522;&#20934;&#25968;&#25454;&#38598;&#20316;&#20026;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26032;&#32593;&#32476;&#25277;&#21462;&#20219;&#21153;&#12290;PLAtE &#20027;&#35201;&#20851;&#27880;&#36141;&#29289;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#20174;&#21253;&#21547;&#22810;&#20010;&#39033;&#30446;&#30340;&#20135;&#21697;&#35780;&#35770;&#39029;&#38754;&#20013;&#25552;&#21462;&#65292;&#21253;&#21547;&#20004;&#20010;&#20219;&#21153;&#65306;&#65288;1&#65289;&#26597;&#25214;&#20135;&#21697;&#21015;&#34920;&#20998;&#21106;&#36793;&#30028;&#21644;&#65288;2&#65289;&#25552;&#21462;&#27599;&#20010;&#20135;&#21697;&#30340;&#23646;&#24615;&#12290;PLAtE&#30001;&#26469;&#33258;6,694&#20010;&#39029;&#38754;&#30340;52,898&#20010;&#39033;&#30446;&#21644;156,014&#20010;&#23646;&#24615;&#32452;&#25104;&#65292;&#26159;&#31532;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#21015;&#34920;&#39029;&#32593;&#32476;&#25277;&#21462;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#20351;&#29992;&#22810;&#38454;&#27573;&#26041;&#27861;&#26469;&#25910;&#38598;&#21644;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#24182;&#23558;&#19977;&#20010;&#26368;&#20808;&#36827;&#30340;&#32593;&#32476;&#25277;&#21462;&#27169;&#22411;&#36866;&#24212;&#20110;&#20004;&#20010;&#20219;&#21153;&#65292;&#23450;&#37327;&#21644;&#23450;&#24615;&#27604;&#36739;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, neural models have been leveraged to significantly improve the performance of information extraction from semi-structured websites. However, a barrier for continued progress is the small number of datasets large enough to train these models. In this work, we introduce the PLAtE (Pages of Lists Attribute Extraction) benchmark dataset as a challenging new web extraction task. PLAtE focuses on shopping data, specifically extractions from product review pages with multiple items encompassing the tasks of: (1) finding product-list segmentation boundaries and (2) extracting attributes for each product. PLAtE is composed of 52, 898 items collected from 6, 694 pages and 156, 014 attributes, making it the first largescale list page web extraction dataset. We use a multi-stage approach to collect and annotate the dataset and adapt three state-of-the-art web extraction models to the two tasks comparing their strengths and weaknesses both quantitatively and qualitatively.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20960;&#20010;AL&#21477;&#23376;&#26597;&#35810;&#35780;&#20272;&#20989;&#25968;&#65292;&#20851;&#27880;&#28508;&#22312;&#27491;&#38754;&#26631;&#35760;&#65292;&#24182;&#20351;&#29992;&#26356;&#22909;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#27491;&#24120;&#21270;&#26041;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;NER&#27880;&#37322;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2111.03837</link><description>&lt;p&gt;
&#38598;&#20013;&#20851;&#27880;&#28508;&#22312;&#21629;&#21517;&#23454;&#20307;&#30340;&#20027;&#21160;&#26631;&#27880;&#33719;&#21462;
&lt;/p&gt;
&lt;p&gt;
Focusing on Potential Named Entities During Active Label Acquisition. (arXiv:2111.03837v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.03837
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20960;&#20010;AL&#21477;&#23376;&#26597;&#35810;&#35780;&#20272;&#20989;&#25968;&#65292;&#20851;&#27880;&#28508;&#22312;&#27491;&#38754;&#26631;&#35760;&#65292;&#24182;&#20351;&#29992;&#26356;&#22909;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#27491;&#24120;&#21270;&#26041;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;NER&#27880;&#37322;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;(NER)&#26088;&#22312;&#35782;&#21035;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#21629;&#21517;&#23454;&#20307;&#30340;&#25552;&#21450;&#24182;&#23558;&#20854;&#20998;&#31867;&#21040;&#39044;&#23450;&#20041;&#30340;&#21629;&#21517;&#23454;&#20307;&#31867;&#21035;&#20013;&#12290;&#34429;&#28982;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26377;&#21161;&#20110;&#22312;NER&#20013;&#23454;&#29616;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#35768;&#22810;&#29305;&#23450;&#39046;&#22495;&#30340;NER&#24212;&#29992;&#20173;&#38656;&#35201;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#12290;&#20027;&#21160;&#23398;&#20064;(AL)&#26159;&#35299;&#20915;&#26631;&#31614;&#33719;&#21462;&#38382;&#39064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24050;&#29992;&#20110;NER&#20219;&#21153;&#65292;&#20197;&#26368;&#23567;&#21270;&#27880;&#37322;&#25104;&#26412;&#32780;&#19981;&#29306;&#29298;&#27169;&#22411;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#26631;&#35760;&#30340;&#20005;&#37325;&#19981;&#22343;&#21248;&#31867;&#20998;&#24067;&#24341;&#20837;&#20102;&#35774;&#35745;&#26377;&#25928;&#30340;NER&#20027;&#21160;&#23398;&#20064;&#26597;&#35810;&#26041;&#27861;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;AL&#21477;&#23376;&#26597;&#35810;&#35780;&#20272;&#20989;&#25968;&#65292;&#26356;&#22810;&#20851;&#27880;&#28508;&#22312;&#30340;&#27491;&#38754;&#26631;&#35760;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#21477;&#23376;&#21644;&#26631;&#35760;&#25104;&#26412;&#35780;&#20272;&#31574;&#30053;&#26469;&#35780;&#20272;&#36825;&#20123;&#25552;&#35758;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#26356;&#22909;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#27491;&#24120;&#21270;&#26041;&#27861;&#65292;&#20197;&#24809;&#32602;&#36807;&#38271;&#25110;&#36807;&#30701;&#30340;&#21477;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
Named entity recognition (NER) aims to identify mentions of named entities in an unstructured text and classify them into predefined named entity classes. While deep learning-based pre-trained language models help to achieve good predictive performances in NER, many domain-specific NER applications still call for a substantial amount of labeled data. Active learning (AL), a general framework for the label acquisition problem, has been used for NER tasks to minimize the annotation cost without sacrificing model performance. However, the heavily imbalanced class distribution of tokens introduces challenges in designing effective AL querying methods for NER. We propose several AL sentence query evaluation functions that pay more attention to potential positive tokens, and evaluate these proposed functions with both sentence-based and token-based cost evaluation strategies. We also propose a better data-driven normalization approach to penalize sentences that are too long or too short. Our
&lt;/p&gt;</description></item></channel></rss>