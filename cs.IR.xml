<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#36807;&#31243;&#25366;&#25496;&#26041;&#27861;&#65292;&#22312;&#24320;&#28304;&#20195;&#30721;&#20013;&#26500;&#24314;&#26085;&#24535;&#26469;&#36861;&#36394;&#21644;&#20102;&#35299;&#24320;&#28304;&#31038;&#21306;&#30340;&#27963;&#36291;&#25104;&#21592;&#21644;&#27963;&#21160;&#31867;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.00686</link><description>&lt;p&gt;
&#22312;&#24320;&#28304;&#20195;&#30721;&#20013;&#25366;&#25496;&#24320;&#21457;&#32773;&#30340;&#35780;&#35770;&#65306;&#19968;&#31181;&#36807;&#31243;&#25366;&#25496;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mining Reviews in Open Source Code for Developers Trail: A Process Mining Approach. (arXiv:2308.00686v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00686
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#36807;&#31243;&#25366;&#25496;&#26041;&#27861;&#65292;&#22312;&#24320;&#28304;&#20195;&#30721;&#20013;&#26500;&#24314;&#26085;&#24535;&#26469;&#36861;&#36394;&#21644;&#20102;&#35299;&#24320;&#28304;&#31038;&#21306;&#30340;&#27963;&#36291;&#25104;&#21592;&#21644;&#27963;&#21160;&#31867;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23457;&#35745;&#36712;&#36857;&#26159;&#20219;&#20309;&#26085;&#24535;&#20013;&#35760;&#24405;&#27963;&#21160;&#25191;&#34892;&#32773;&#30340;&#35777;&#25454;&#24615;&#25351;&#26631;&#12290;&#29616;&#20195;&#21453;&#24212;&#24335;&#31995;&#32479;&#65288;&#22914;&#20107;&#21153;&#22788;&#29702;&#31995;&#32479;&#12289;&#31649;&#29702;&#20449;&#24687;&#31995;&#32479;&#12289;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#29978;&#33267;&#39640;&#32423;&#31649;&#29702;&#31995;&#32479;&#65289;&#22312;&#25191;&#34892;&#26085;&#24120;&#20219;&#21153;&#26102;&#35760;&#24405;&#29992;&#25143;&#30340;&#27963;&#21160;&#65292;&#20854;&#20013;&#19968;&#20010;&#26368;&#37325;&#35201;&#30340;&#21407;&#22240;&#21487;&#33021;&#26159;&#23433;&#20840;&#24615;&#12290;&#20026;&#20102;&#26377;&#25928;&#30417;&#25511;&#21644;&#31649;&#29702;&#38544;&#31169;&#21644;&#20449;&#24687;&#35775;&#38382;&#65292;&#36825;&#20123;&#26085;&#24535;&#20013;&#25429;&#33719;&#21644;&#35760;&#24405;&#30340;&#36712;&#36857;&#22312;&#36825;&#26041;&#38754;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#24320;&#28304;&#39046;&#22495;&#65292;&#24773;&#20917;&#24182;&#38750;&#22914;&#27492;&#12290;&#23613;&#31649;&#33258;&#30001;&#36719;&#20214;&#30340;&#30446;&#26631;&#26159;&#20801;&#35768;&#35775;&#38382;&#12289;&#20813;&#36153;&#20998;&#21457;&#21644;&#20462;&#25913;&#20195;&#30721;&#30340;&#26435;&#21033;&#65292;&#20294;&#25317;&#26377;&#27492;&#31867;&#23457;&#35745;&#36712;&#36857;&#21487;&#20197;&#24110;&#21161;&#36861;&#36394;&#21644;&#20102;&#35299;&#36825;&#20123;&#31038;&#21306;&#30340;&#27963;&#36291;&#25104;&#21592;&#20197;&#21450;&#20182;&#20204;&#25191;&#34892;&#30340;&#27963;&#21160;&#31867;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#36807;&#31243;&#25366;&#25496;&#26469;&#26500;&#24314;&#26085;&#24535;&#65292;&#23613;&#21487;&#33021;&#21033;&#29992;&#22312;&#24320;&#28304;&#23384;&#20648;&#24211;&#20013;&#25214;&#21040;&#30340;&#25968;&#25454;&#65292;&#20197;&#20135;&#29983;&#19968;&#20010;&#36807;&#31243;&#25366;&#25496;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Audit trails are evidential indications of activities performers in any logs. Modern reactive systems such as transaction processing systems, management information systems, decision support systems and even executive management systems log activities of users as they perform their daily tasks for a number of reasons and perhaps one of the most important is security. In order to efficiently monitor and manage privacy and access to information, the trails as captured and recorded in these logs play a pivotal role in this regard. In Open Source realm, however, this is not the case. Although the objective with free software is to allow for access, free distribution and the rights to modify coding, having such audit trails can help to trace and understand how active members of these communities are and the type of activities they perform. In this paper, we propose using process mining to construct logs using as much data as can be found in open source repositories in order to produce a pro
&lt;/p&gt;</description></item><item><title>TimePool &#26159;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#19968;&#20803;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#38656;&#27714;&#30340;&#21487;&#35270;&#21270;&#21407;&#22411;&#65292;&#20801;&#35768;&#29992;&#25143;&#26500;&#24314;&#20132;&#20114;&#24335;&#26597;&#35810;&#24182;&#36890;&#36807;&#21487;&#35270;&#21270;&#30340;&#26041;&#24335;&#25506;&#32034;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.00682</link><description>&lt;p&gt;
TimePool&#65306;&#21487;&#35270;&#21270;&#22238;&#31572;&#8220;&#21738;&#20010;&#26102;&#21051;&#20197;&#21450;&#20309;&#26102;&#8221;&#38382;&#39064;&#30340;&#19968;&#20803;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
TimePool: Visually Answer "Which and When" Questions On Univariate Time Series. (arXiv:2308.00682v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00682
&lt;/p&gt;
&lt;p&gt;
TimePool &#26159;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#19968;&#20803;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#38656;&#27714;&#30340;&#21487;&#35270;&#21270;&#21407;&#22411;&#65292;&#20801;&#35768;&#29992;&#25143;&#26500;&#24314;&#20132;&#20114;&#24335;&#26597;&#35810;&#24182;&#36890;&#36807;&#21487;&#35270;&#21270;&#30340;&#26041;&#24335;&#25506;&#32034;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#25506;&#32034;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#26102;&#65292;&#20998;&#26512;&#24072;&#32463;&#24120;&#25552;&#20986;&#8220;&#21738;&#20010;&#26102;&#21051;&#20197;&#21450;&#20309;&#26102;&#8221;&#38382;&#39064;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;&#36229;&#36807;&#19968;&#30334;&#24180;&#30340;&#19990;&#30028;&#20154;&#22343;&#23551;&#21629;&#25968;&#25454;&#65292;&#20182;&#20204;&#21487;&#33021;&#35810;&#38382;&#21069;&#21313;&#20010;&#22312;&#20154;&#22343;&#23551;&#21629;&#19978;&#30340;&#22269;&#23478;&#21644;&#20182;&#20204;&#36798;&#21040;&#36825;&#19968;&#22320;&#20301;&#30340;&#26102;&#38388;&#27573;&#65292;&#25110;&#32773;&#37027;&#20123;&#27604;&#29233;&#23572;&#20848;&#30340;&#20154;&#22343;&#23551;&#21629;&#26356;&#38271;&#30340;&#22269;&#23478;&#20197;&#21450;&#20309;&#26102;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;TimePool&#65292;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#19968;&#20803;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#38656;&#27714;&#30340;&#26032;&#30340;&#21487;&#35270;&#21270;&#21407;&#22411;&#12290;&#23427;&#20801;&#35768;&#29992;&#25143;&#26500;&#24314;&#20132;&#20114;&#24335;&#30340;&#8220;&#21738;&#20010;&#26102;&#21051;&#20197;&#21450;&#20309;&#26102;&#8221;&#26597;&#35810;&#65292;&#24182;&#36890;&#36807;&#21487;&#35270;&#21270;&#30340;&#26041;&#24335;&#25506;&#32034;&#32467;&#26524;&#20197;&#33719;&#21462;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
When exploring time series datasets, analysts often pose "which and when" questions. For example, with world life expectancy data over one hundred years, they may inquire about the top 10 countries in life expectancy and the time period when they achieved this status, or which countries have had longer life expectancy than Ireland and when. This paper proposes TimePool, a new visualization prototype, to address this need for univariate time series analysis. It allows users to construct interactive "which and when" queries and visually explore the results for insights.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#25991;&#26412;&#25991;&#26723;&#30340;&#22270;&#35889;&#32858;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#23637;&#31034;&#32452;&#21512;&#25289;&#26222;&#25289;&#26031;&#23884;&#20837;&#12289;K&#23884;&#20837;&#21644;&#35789;&#21521;&#37327;&#31354;&#38388;&#23884;&#20837;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#26500;&#24314;&#20102;&#25991;&#26412;&#20869;&#23481;&#21644;&#32858;&#31867;&#32467;&#26524;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;</title><link>http://arxiv.org/abs/2308.00504</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#25991;&#26412;&#25991;&#26723;&#30340;&#22270;&#35889;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Explainable Graph Spectral Clustering of Text Documents. (arXiv:2308.00504v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00504
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#25991;&#26412;&#25991;&#26723;&#30340;&#22270;&#35889;&#32858;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#23637;&#31034;&#32452;&#21512;&#25289;&#26222;&#25289;&#26031;&#23884;&#20837;&#12289;K&#23884;&#20837;&#21644;&#35789;&#21521;&#37327;&#31354;&#38388;&#23884;&#20837;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#26500;&#24314;&#20102;&#25991;&#26412;&#20869;&#23481;&#21644;&#32858;&#31867;&#32467;&#26524;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20809;&#35889;&#32858;&#31867;&#26041;&#27861;&#20197;&#20854;&#33021;&#22815;&#34920;&#31034;&#19981;&#21516;&#24418;&#29366;&#12289;&#23494;&#24230;&#31561;&#30340;&#32858;&#31867;&#32780;&#38395;&#21517;&#12290;&#28982;&#32780;&#65292;&#23558;&#36825;&#20123;&#31639;&#27861;&#24212;&#29992;&#20110;&#25991;&#26412;&#25991;&#26723;&#26102;&#65292;&#20854;&#32467;&#26524;&#24456;&#38590;&#21521;&#29992;&#25143;&#35299;&#37322;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#22312;&#20809;&#35889;&#31354;&#38388;&#20013;&#30340;&#23884;&#20837;&#19982;&#25991;&#26723;&#20869;&#23481;&#27809;&#26377;&#26126;&#26174;&#30340;&#20851;&#31995;&#12290;&#22240;&#27492;&#65292;&#36843;&#20999;&#38656;&#35201;&#30740;&#31350;&#35299;&#37322;&#32858;&#31867;&#32467;&#26524;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#27492;&#30446;&#26631;&#30340;&#36129;&#29486;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35299;&#37322;&#22522;&#20110;&#32452;&#21512;&#25289;&#26222;&#25289;&#26031;&#30340;&#22270;&#35889;&#32858;&#31867;&#32467;&#26524;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#23637;&#31034;&#32452;&#21512;&#25289;&#26222;&#25289;&#26031;&#23884;&#20837;&#12289;K&#23884;&#20837;&#65288;&#26412;&#25991;&#25552;&#20986;&#65289;&#21644;&#35789;&#21521;&#37327;&#31354;&#38388;&#23884;&#20837;&#30340;&#65288;&#36817;&#20284;&#65289;&#31561;&#20215;&#24615;&#12290;&#20174;&#32780;&#26500;&#24314;&#20102;&#25991;&#26412;&#20869;&#23481;&#21644;&#32858;&#31867;&#32467;&#26524;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;&#25105;&#20204;&#20026;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#32972;&#26223;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#30740;&#31350;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26377;&#21033;&#26465;&#20214;&#19979;&#65292;K&#23884;&#20837;&#24456;&#22909;&#22320;&#36817;&#20284;&#20102;&#25289;&#26222;&#25289;&#26031;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spectral clustering methods are known for their ability to represent clusters of diverse shapes, densities etc. However, results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents. Therefore there is an urgent need to elaborate methods for explaining the outcome of the clustering. This paper presents a contribution towards this goal. We present a proposal of explanation of results of combinatorial Laplacian based graph spectral clustering. It is based on showing (approximate) equivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in this paper) and term vector space embedding. Hence a bridge is constructed between the textual contents and the clustering results. We provide theoretical background for this approach. We performed experimental study showing that $K$-embedding approximates well Laplacian embedding under favourable blo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21306;&#22495;&#25340;&#20889;&#20064;&#24815;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#31070;&#32463;&#25490;&#21517;&#27169;&#22411;&#22312;&#21516;&#20041;&#35789;&#24773;&#20917;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#23613;&#31649;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#32654;&#24335;&#25340;&#20889;&#20559;&#24046;&#12290;&#35268;&#33539;&#21270;&#25991;&#26723;&#30340;&#25340;&#20889;&#20250;&#24433;&#21709;&#25152;&#26377;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.00480</link><description>&lt;p&gt;
&#20851;&#20110;&#21306;&#22495;&#25340;&#20889;&#20064;&#24815;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#24433;&#21709;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Effects of Regional Spelling Conventions in Retrieval Models. (arXiv:2308.00480v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00480
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21306;&#22495;&#25340;&#20889;&#20064;&#24815;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#31070;&#32463;&#25490;&#21517;&#27169;&#22411;&#22312;&#21516;&#20041;&#35789;&#24773;&#20917;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#23613;&#31649;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#32654;&#24335;&#25340;&#20889;&#20559;&#24046;&#12290;&#35268;&#33539;&#21270;&#25991;&#26723;&#30340;&#25340;&#20889;&#20250;&#24433;&#21709;&#25152;&#26377;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#25490;&#21517;&#27169;&#22411;&#30340;&#19968;&#20010;&#20248;&#21183;&#26159;&#23427;&#20204;&#22312;&#21516;&#20041;&#35789;&#24773;&#20917;&#19979;&#20855;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21363;&#24403;&#20004;&#20010;&#21333;&#35789;&#20855;&#26377;&#30456;&#20284;&#25110;&#30456;&#21516;&#30340;&#21547;&#20041;&#26102;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#24182;&#37327;&#21270;&#20102;&#21508;&#31181;&#25490;&#21517;&#27169;&#22411;&#22312;&#19968;&#20010;&#26126;&#30830;&#30340;&#21516;&#20041;&#35789;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#65306;&#24403;&#21333;&#35789;&#20165;&#22240;&#21306;&#22495;&#25340;&#20889;&#20064;&#24815;&#30340;&#24046;&#24322;&#32780;&#20197;&#19981;&#21516;&#30340;&#24418;&#24335;&#34920;&#36798;&#26102;&#65288;&#20363;&#22914;color vs colour&#65289;&#12290;&#25105;&#20204;&#39318;&#20808;&#25506;&#32034;&#20102;&#29992;&#20110;&#31070;&#32463;&#26816;&#32034;&#26041;&#27861;&#30340;&#39044;&#35757;&#32451;&#12289;&#35757;&#32451;&#21644;&#35780;&#20272;&#30340;&#25968;&#25454;&#38598;&#20013;&#32654;&#24335;&#33521;&#35821;&#21644;&#33521;&#24335;&#33521;&#35821;&#25340;&#20889;&#24815;&#20363;&#30340;&#26222;&#36941;&#24615;&#65292;&#24182;&#21457;&#29616;&#32654;&#24335;&#25340;&#20889;&#24815;&#20363;&#35201;&#36828;&#36828;&#22810;&#20110;&#33521;&#24335;&#25340;&#20889;&#20064;&#24815;&#12290;&#23613;&#31649;&#35757;&#32451;&#25968;&#25454;&#23384;&#22312;&#36825;&#20123;&#20559;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#26816;&#32034;&#27169;&#22411;&#22312;&#36825;&#31181;&#21516;&#20041;&#35789;&#24773;&#20917;&#19979;&#36890;&#24120;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26816;&#32034;&#20013;&#23545;&#25991;&#26723;&#25340;&#20889;&#36827;&#34892;&#35268;&#33539;&#21270;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#25152;&#26377;&#27169;&#22411;&#37117;&#21463;&#21040;&#25991;&#26723;&#25340;&#20889;&#35268;&#33539;&#21270;&#30340;&#24433;&#21709;&#12290;&#23613;&#31649;&#22312;&#35268;&#33539;&#21270;&#30340;&#24773;&#20917;&#19979;&#23427;&#20204;&#37117;&#32463;&#21382;&#20102;&#24615;&#33021;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
One advantage of neural ranking models is that they are meant to generalise well in situations of synonymity i.e. where two words have similar or identical meanings. In this paper, we investigate and quantify how well various ranking models perform in a clear-cut case of synonymity: when words are simply expressed in different surface forms due to regional differences in spelling conventions (e.g., color vs colour). We first explore the prevalence of American and British English spelling conventions in datasets used for the pre-training, training and evaluation of neural retrieval methods, and find that American spelling conventions are far more prevalent. Despite these biases in the training data, we find that retrieval models often generalise well in this case of synonymity. We explore the effect of document spelling normalisation in retrieval and observe that all models are affected by normalising the document's spelling. While they all experience a drop in performance when normalis
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26597;&#35810;&#37325;&#26500;&#30340;&#33021;&#21147;&#19982;&#20256;&#32479;&#30340;&#20351;&#29992;&#20266;&#30456;&#20851;&#21453;&#39304;&#30340;&#26041;&#27861;&#30456;&#27604;&#36739;&#65292;&#20351;&#29992;&#20004;&#20010;&#20195;&#34920;&#24615;&#30340;&#26597;&#35810;&#37325;&#26500;&#26694;&#26550;GenQR&#21644;GenPRF&#36827;&#34892;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2308.00415</link><description>&lt;p&gt;
&#20026;&#26377;&#25928;&#30340;Adhoc&#25628;&#32034;&#29983;&#25104;&#26597;&#35810;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Generative Query Reformulation for Effective Adhoc Search. (arXiv:2308.00415v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26597;&#35810;&#37325;&#26500;&#30340;&#33021;&#21147;&#19982;&#20256;&#32479;&#30340;&#20351;&#29992;&#20266;&#30456;&#20851;&#21453;&#39304;&#30340;&#26041;&#27861;&#30456;&#27604;&#36739;&#65292;&#20351;&#29992;&#20004;&#20010;&#20195;&#34920;&#24615;&#30340;&#26597;&#35810;&#37325;&#26500;&#26694;&#26550;GenQR&#21644;GenPRF&#36827;&#34892;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#20013;&#65292;&#33258;&#21160;&#37325;&#26500;&#29992;&#25143;&#26597;&#35810;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#25928;&#26524;&#65292;&#22914;&#20266;&#30456;&#20851;&#21453;&#39304;&#26041;&#27861;&#12290;&#26368;&#36817;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#30340;&#36827;&#23637;&#23637;&#31034;&#20102;&#23427;&#20204;&#29983;&#25104;&#19982;&#32473;&#23450;&#25552;&#31034;&#30456;&#20851;&#30340;&#21709;&#24212;&#30340;&#33021;&#21147;&#12290;&#37492;&#20110;&#36825;&#19968;&#25104;&#21151;&#65292;&#25105;&#20204;&#33268;&#21147;&#20110;&#30740;&#31350;&#36825;&#20123;&#27169;&#22411;&#25191;&#34892;&#26597;&#35810;&#37325;&#26500;&#30340;&#33021;&#21147;&#65292;&#20197;&#21450;&#23427;&#20204;&#19982;&#20351;&#29992;&#20266;&#30456;&#20851;&#21453;&#39304;&#30340;&#38271;&#26399;&#26597;&#35810;&#37325;&#26500;&#26041;&#27861;&#30456;&#27604;&#36739;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#20195;&#34920;&#24615;&#30340;&#26597;&#35810;&#37325;&#26500;&#26694;&#26550;&#65292;GenQR&#21644;GenPRF&#12290;GenQR&#30452;&#25509;&#37325;&#26500;&#29992;&#25143;&#36755;&#20837;&#30340;&#26597;&#35810;&#65292;&#32780;GenPRF&#36890;&#36807;&#20351;&#29992;&#20266;&#30456;&#20851;&#21453;&#39304;&#20449;&#24687;&#20026;&#26597;&#35810;&#25552;&#20379;&#38468;&#21152;&#19978;&#19979;&#25991;&#12290;&#23545;&#20110;&#27599;&#31181;&#37325;&#26500;&#26041;&#27861;&#65292;&#25105;&#20204;&#37319;&#29992;&#19981;&#21516;&#30340;&#25216;&#26415;&#65292;&#21253;&#25324;&#24494;&#35843;&#21644;&#30452;&#25509;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performing automatic reformulations of a user's query is a popular paradigm used in information retrieval (IR) for improving effectiveness -- as exemplified by the pseudo-relevance feedback approaches, which expand the query in order to alleviate the vocabulary mismatch problem. Recent advancements in generative language models have demonstrated their ability in generating responses that are relevant to a given prompt. In light of this success, we seek to study the capacity of such models to perform query reformulation and how they compare with long-standing query reformulation methods that use pseudo-relevance feedback. In particular, we investigate two representative query reformulation frameworks, GenQR and GenPRF. GenQR directly reformulates the user's input query, while GenPRF provides additional context for the query by making use of pseudo-relevance feedback information. For each reformulation method, we leverage different techniques, including fine-tuning and direct prompting, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#25361;&#25112;&#22270;&#21327;&#21516;&#36807;&#28388;&#30340;&#31070;&#35805;&#65292;&#36890;&#36807;&#20851;&#27880;&#32467;&#26524;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#25104;&#21151;&#22797;&#21046;&#20102;&#20845;&#20010;&#27969;&#34892;&#30340;&#22270;&#25512;&#33616;&#27169;&#22411;&#22312;&#20960;&#20010;&#24120;&#35265;&#21644;&#26032;&#25968;&#25454;&#38598;&#19978;&#30340;&#32467;&#26524;&#65292;&#24182;&#19982;&#20256;&#32479;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2308.00404</link><description>&lt;p&gt;
&#25361;&#25112;&#22270;&#21327;&#21516;&#36807;&#28388;&#30340;&#31070;&#35805;&#65306;&#19968;&#39033;&#22522;&#20110;&#25512;&#29702;&#21644;&#21487;&#22797;&#21046;&#24615;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis. (arXiv:2308.00404v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00404
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#25361;&#25112;&#22270;&#21327;&#21516;&#36807;&#28388;&#30340;&#31070;&#35805;&#65292;&#36890;&#36807;&#20851;&#27880;&#32467;&#26524;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#25104;&#21151;&#22797;&#21046;&#20102;&#20845;&#20010;&#27969;&#34892;&#30340;&#22270;&#25512;&#33616;&#27169;&#22411;&#22312;&#20960;&#20010;&#24120;&#35265;&#21644;&#26032;&#25968;&#25454;&#38598;&#19978;&#30340;&#32467;&#26524;&#65292;&#24182;&#19982;&#20256;&#32479;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65288;GNNs&#65289;&#30340;&#25104;&#21151;&#26174;&#33879;&#25512;&#21160;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#65292;&#36890;&#36807;&#23558;&#29992;&#25143;&#21644;&#29289;&#21697;&#26377;&#25928;&#22320;&#24314;&#27169;&#20026;&#19968;&#20010;&#20108;&#20998;&#22270;&#21644;&#26080;&#21521;&#22270;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#21407;&#22987;&#30340;&#22522;&#20110;&#22270;&#30340;&#20316;&#21697;&#36890;&#24120;&#22312;&#26410;&#39564;&#35777;&#20854;&#22312;&#20855;&#20307;&#37197;&#32622;&#19979;&#30340;&#26377;&#25928;&#24615;&#30340;&#24773;&#20917;&#19979;&#37319;&#29992;&#22522;&#32447;&#35770;&#25991;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#30528;&#37325;&#20851;&#27880;&#32467;&#26524;&#30340;&#21487;&#22797;&#21046;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25104;&#21151;&#22797;&#21046;&#20102;&#20845;&#20010;&#27969;&#34892;&#19988;&#26368;&#26032;&#30340;&#22270;&#25512;&#33616;&#27169;&#22411;&#65288;NGCF&#12289;DGCF&#12289;LightGCN&#12289;SGL&#12289;UltraGCN&#21644;GFCF&#65289;&#22312;&#19977;&#20010;&#24120;&#35265;&#22522;&#20934;&#25968;&#25454;&#38598;&#65288;Gowalla&#12289;Yelp 2018&#21644;&#20122;&#39532;&#36874;&#22270;&#20070;&#65289;&#19978;&#30340;&#32467;&#26524;&#30340;&#20195;&#30721;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#22270;&#27169;&#22411;&#19982;&#22312;&#31163;&#32447;&#35780;&#20272;&#20013;&#34920;&#29616;&#33391;&#22909;&#30340;&#20256;&#32479;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25193;&#23637;&#20102;&#23545;&#20004;&#20010;&#32570;&#20047;&#29616;&#26377;&#25991;&#29486;&#20013;&#24050;&#24314;&#31435;&#35774;&#32622;&#30340;&#26032;&#25968;&#25454;&#38598;&#65288;Allrecipes&#21644;BookCrossing&#65289;&#30340;&#30740;&#31350;&#12290;&#30001;&#20110;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#19982;&#20197;&#21069;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19981;&#21516;&#65292;&#20351;&#24471;&#25105;&#20204;&#23545;&#22270;&#25512;&#33616;&#27169;&#22411;&#24615;&#33021;&#30340;&#35780;&#20272;&#32467;&#26524;&#26356;&#21152;&#28145;&#20837;&#21644;&#20840;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of graph neural network-based models (GNNs) has significantly advanced recommender systems by effectively modeling users and items as a bipartite, undirected graph. However, many original graph-based works often adopt results from baseline papers without verifying their validity for the specific configuration under analysis. Our work addresses this issue by focusing on the replicability of results. We present a code that successfully replicates results from six popular and recent graph recommendation models (NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark datasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these graph models with traditional collaborative filtering models that historically performed well in offline evaluations. Furthermore, we extend our study to two new datasets (Allrecipes and BookCrossing) that lack established setups in existing literature. As the performance on these datasets differs from the previous bench
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35268;&#21017;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#26816;&#27979;&#21644;&#20998;&#31867;&#29289;&#32852;&#32593;&#32593;&#32476;&#20013;&#30340;&#26032;&#22411;&#25915;&#20987;&#21644;&#24322;&#24120;&#12290;&#35813;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#25913;&#21892;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35813;&#39046;&#22495;&#20013;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.00005</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#35268;&#21017;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26816;&#27979;&#21644;&#20998;&#31867;&#29289;&#32852;&#32593;&#32593;&#32476;&#20013;&#30340;&#26032;&#22411;&#25915;&#20987;&#21644;&#24322;&#24120;
&lt;/p&gt;
&lt;p&gt;
Detection and Classification of Novel Attacks and Anomaly in IoT Network using Rule based Deep Learning Model. (arXiv:2308.00005v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00005
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35268;&#21017;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#26816;&#27979;&#21644;&#20998;&#31867;&#29289;&#32852;&#32593;&#32593;&#32476;&#20013;&#30340;&#26032;&#22411;&#25915;&#20987;&#21644;&#24322;&#24120;&#12290;&#35813;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#25913;&#21892;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35813;&#39046;&#22495;&#20013;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25915;&#20987;&#32773;&#29616;&#22312;&#20351;&#29992;&#22797;&#26434;&#25216;&#26415;&#65292;&#22914;&#22810;&#24577;&#24615;&#65292;&#20197;&#25913;&#21464;&#27599;&#27425;&#26032;&#25915;&#20987;&#30340;&#25915;&#20987;&#27169;&#24335;&#12290;&#22240;&#27492;&#65292;&#26816;&#27979;&#26032;&#22411;&#25915;&#20987;&#23545;&#20110;&#32593;&#32476;&#23433;&#20840;&#19987;&#23478;&#21644;&#30740;&#31350;&#20154;&#21592;&#26469;&#35828;&#24050;&#32463;&#25104;&#20026;&#26368;&#22823;&#30340;&#25361;&#25112;&#12290;&#26368;&#36817;&#65292;&#24322;&#24120;&#21644;&#28151;&#21512;&#26041;&#27861;&#34987;&#29992;&#20110;&#26816;&#27979;&#32593;&#32476;&#25915;&#20987;&#12290;&#32780;&#26816;&#27979;&#26032;&#22411;&#25915;&#20987;&#26159;&#24191;&#27867;&#24212;&#29992;&#29289;&#32852;&#32593;&#25216;&#26415;&#30340;&#20851;&#38190;&#12290;&#26032;&#22411;&#25915;&#20987;&#21487;&#20197;&#36731;&#26131;&#35268;&#36991;&#29616;&#26377;&#22522;&#20110;&#31614;&#21517;&#30340;&#26816;&#27979;&#26041;&#27861;&#65292;&#29978;&#33267;&#38590;&#20197;&#34987;&#21457;&#29616;&#22810;&#24180;&#12290;&#29616;&#26377;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20063;&#26410;&#33021;&#26816;&#27979;&#20986;&#36825;&#20123;&#25915;&#20987;&#65292;&#24182;&#19988;&#35823;&#25253;&#29575;&#24456;&#39640;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35268;&#21017;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25216;&#26415;&#20316;&#20026;&#35299;&#20915;&#26816;&#27979;&#26032;&#22411;&#25915;&#20987;&#38382;&#39064;&#30340;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#36739;&#22909;&#22320;&#25913;&#36827;&#20102;&#30456;&#24212;&#30340;&#22522;&#20934;&#32467;&#26524;&#65292;&#21253;&#25324;CICIDS 2017&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attackers are now using sophisticated techniques, like polymorphism, to change the attack pattern for each new attack. Thus, the detection of novel attacks has become the biggest challenge for cyber experts and researchers. Recently, anomaly and hybrid approaches are used for the detection of network attacks. Detecting novel attacks, on the other hand, is a key enabler for a wide range of IoT applications. Novel attacks can easily evade existing signature-based detection methods and are extremely difficult to detect, even going undetected for years. Existing machine learning models have also failed to detect the attack and have a high rate of false positives. In this paper, a rule-based deep neural network technique has been proposed as a framework for addressing the problem of detecting novel attacks. The designed framework significantly improves respective benchmark results, including the CICIDS 2017 dataset. The experimental results show that the proposed model keeps a good balance 
&lt;/p&gt;</description></item><item><title>Jina Embeddings&#26159;&#19968;&#32452;&#39640;&#24615;&#33021;&#30340;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25991;&#26412;&#30340;&#35821;&#20041;&#26412;&#36136;&#12290;&#35813;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;Jina Embeddings&#30340;&#24320;&#21457;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#24615;&#33021;&#35780;&#20272;&#39564;&#35777;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.11224</link><description>&lt;p&gt;
Jina Embeddings:&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#24615;&#33021;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models. (arXiv:2307.11224v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11224
&lt;/p&gt;
&lt;p&gt;
Jina Embeddings&#26159;&#19968;&#32452;&#39640;&#24615;&#33021;&#30340;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25991;&#26412;&#30340;&#35821;&#20041;&#26412;&#36136;&#12290;&#35813;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;Jina Embeddings&#30340;&#24320;&#21457;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#24615;&#33021;&#35780;&#20272;&#39564;&#35777;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Jina Embeddings&#30001;&#19968;&#32452;&#39640;&#24615;&#33021;&#30340;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#32452;&#25104;&#65292;&#33021;&#22815;&#23558;&#21508;&#31181;&#25991;&#26412;&#36755;&#20837;&#36716;&#21270;&#20026;&#25968;&#20540;&#34920;&#31034;&#65292;&#20174;&#32780;&#25429;&#25417;&#25991;&#26412;&#30340;&#35821;&#20041;&#26412;&#36136;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#24182;&#38750;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#25991;&#26412;&#29983;&#25104;&#65292;&#20294;&#22312;&#23494;&#38598;&#26816;&#32034;&#21644;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#31561;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#26412;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;Jina Embeddings&#30340;&#24320;&#21457;&#36807;&#31243;&#65292;&#20174;&#21019;&#24314;&#39640;&#36136;&#37327;&#30340;&#25104;&#23545;&#21644;&#19977;&#20803;&#25968;&#25454;&#38598;&#24320;&#22987;&#12290;&#23427;&#24378;&#35843;&#20102;&#25968;&#25454;&#28165;&#29702;&#22312;&#25968;&#25454;&#38598;&#20934;&#22791;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#65292;&#24182;&#23545;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#36827;&#34892;&#20102;&#28145;&#20837;&#25506;&#35752;&#65292;&#26368;&#21518;&#21033;&#29992;Massive Textual Embedding Benchmark&#65288;MTEB&#65289;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Jina Embeddings constitutes a set of high-performance sentence embedding models adept at translating various textual inputs into numerical representations, thereby capturing the semantic essence of the text. While these models are not exclusively designed for text generation, they excel in applications such as dense retrieval and semantic textual similarity. This paper details the development of Jina Embeddings, starting with the creation of a high-quality pairwise and triplet dataset. It underlines the crucial role of data cleaning in dataset preparation, gives in-depth insights into the model training process, and concludes with a comprehensive performance evaluation using the Massive Textual Embedding Benchmark (MTEB).
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;In-Context RALM&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30456;&#20851;&#25991;&#20214;&#20316;&#20026;&#36755;&#20837;&#30340;&#19968;&#37096;&#20998;&#65292;&#26080;&#38656;&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#36827;&#19968;&#27493;&#30340;&#35757;&#32451;&#21363;&#21487;&#26174;&#33879;&#25552;&#39640;&#35821;&#35328;&#24314;&#27169;&#24615;&#33021;&#21644;&#28304;&#24402;&#22240;&#33021;&#21147;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;RALM&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#26356;&#31616;&#21333;&#30340;&#37096;&#32626;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2302.00083</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
In-Context Retrieval-Augmented Language Models. (arXiv:2302.00083v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;In-Context RALM&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30456;&#20851;&#25991;&#20214;&#20316;&#20026;&#36755;&#20837;&#30340;&#19968;&#37096;&#20998;&#65292;&#26080;&#38656;&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#36827;&#19968;&#27493;&#30340;&#35757;&#32451;&#21363;&#21487;&#26174;&#33879;&#25552;&#39640;&#35821;&#35328;&#24314;&#27169;&#24615;&#33021;&#21644;&#28304;&#24402;&#22240;&#33021;&#21147;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;RALM&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#26356;&#31616;&#21333;&#30340;&#37096;&#32626;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;(RALM)&#26041;&#27861;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#23558;&#30456;&#20851;&#25991;&#20214;&#20174;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#20986;&#26469;&#19982;&#35821;&#35328;&#27169;&#22411;(LM)&#36827;&#34892;&#21327;&#21516;&#65292;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#35821;&#35328;&#24314;&#27169;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#36824;&#21487;&#20197;&#32531;&#35299;&#20107;&#23454;&#19981;&#20934;&#30830;&#30340;&#25991;&#26412;&#29983;&#25104;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#33258;&#28982;&#30340;&#28304;&#24402;&#22240;&#26426;&#21046;&#12290;&#29616;&#26377;&#30340;RALM&#26041;&#27861;&#30528;&#37325;&#20110;&#20462;&#25913;LM&#26550;&#26500;&#20197;&#20415;&#20110;&#25972;&#21512;&#22806;&#37096;&#20449;&#24687;&#65292;&#20174;&#32780;&#22823;&#22823;&#22686;&#21152;&#20102;&#37096;&#32626;&#30340;&#22797;&#26434;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;RALM&#65306;&#20445;&#25345;LM&#26550;&#26500;&#19981;&#21464;&#65292;&#24182;&#22312;&#36755;&#20837;&#20013;&#28155;&#21152;&#26816;&#32034;&#21040;&#30340;&#25991;&#20214;&#65292;&#26080;&#38656;&#23545;LM&#36827;&#34892;&#20219;&#20309;&#36827;&#19968;&#27493;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22522;&#20110;&#29616;&#25104;&#30340;&#36890;&#29992;&#26816;&#32034;&#22120;&#30340;&#19978;&#19979;&#25991;RALM&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#19981;&#21516;&#35821;&#26009;&#24211;&#20013;&#33021;&#22815;&#25552;&#20379;&#20986;&#20154;&#24847;&#26009;&#30340;&#22823;&#24133;&#24230;&#30340;LM&#22686;&#30410;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#25991;&#20214;&#26816;&#32034;&#21644;&#25490;&#21517;&#26426;&#21046;&#21487;&#20197;&#38024;&#23545;RALM&#35774;&#32622;&#36827;&#34892;&#19987;&#38376;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Language Modeling (RALM) methods, which condition a language model (LM) on relevant documents from a grounding corpus during generation, were shown to significantly improve language modeling performance. In addition, they can mitigate the problem of factually inaccurate text generation and provide natural source attribution mechanism. Existing RALM approaches focus on modifying the LM architecture in order to facilitate the incorporation of external information, significantly complicating deployment. This paper considers a simple alternative, which we dub In-Context RALM: leaving the LM architecture unchanged and prepending grounding documents to the input, without any further training of the LM. We show that In-Context RALM that builds on off-the-shelf general purpose retrievers provides surprisingly large LM gains across model sizes and diverse corpora. We also demonstrate that the document retrieval and ranking mechanism can be specialized to the RALM setting to 
&lt;/p&gt;</description></item></channel></rss>