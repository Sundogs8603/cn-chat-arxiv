<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>RankVicuna&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;&#38646;&#26679;&#26412;&#35774;&#32622;&#20013;&#25191;&#34892;&#39640;&#36136;&#37327;&#21015;&#34920;&#25490;&#24207;&#30340;&#23436;&#20840;&#24320;&#28304;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#27604;GPT-3.5&#23567;&#24471;&#22810;&#30340;&#21442;&#25968;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#19982;&#38646;&#26679;&#26412;&#37325;&#26032;&#25490;&#24207;&#30456;&#24403;&#30340;&#25928;&#26524;&#65292;&#24182;&#20026;&#23558;&#26469;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2309.15088</link><description>&lt;p&gt;
RankVicuna: &#20351;&#29992;&#24320;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38646;&#26679;&#26412;&#21015;&#34920;&#25490;&#24207;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models. (arXiv:2309.15088v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15088
&lt;/p&gt;
&lt;p&gt;
RankVicuna&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;&#38646;&#26679;&#26412;&#35774;&#32622;&#20013;&#25191;&#34892;&#39640;&#36136;&#37327;&#21015;&#34920;&#25490;&#24207;&#30340;&#23436;&#20840;&#24320;&#28304;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#27604;GPT-3.5&#23567;&#24471;&#22810;&#30340;&#21442;&#25968;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#19982;&#38646;&#26679;&#26412;&#37325;&#26032;&#25490;&#24207;&#30456;&#24403;&#30340;&#25928;&#26524;&#65292;&#24182;&#20026;&#23558;&#26469;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#25104;&#21151;&#22320;&#23558;ChatGPT&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20110;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#37325;&#26032;&#25490;&#24207;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#65292;&#36825;&#26679;&#30340;&#24037;&#20316;&#22823;&#22810;&#24314;&#31435;&#22312;&#19981;&#36879;&#26126;&#30340;API&#21518;&#38754;&#30340;&#19987;&#26377;&#27169;&#22411;&#19978;&#12290;&#36825;&#31181;&#26041;&#27861;&#20135;&#29983;&#30340;&#23454;&#39564;&#32467;&#26524;&#19981;&#21487;&#22797;&#29616;&#19988;&#38750;&#30830;&#23450;&#24615;&#65292;&#23041;&#32961;&#21040;&#24314;&#31435;&#22312;&#36825;&#31181;&#19981;&#31283;&#23450;&#22522;&#30784;&#19978;&#30340;&#32467;&#26524;&#30340;&#30495;&#23454;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#37325;&#22823;&#32570;&#38519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RankVicuna&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;&#38646;&#26679;&#26412;&#35774;&#32622;&#20013;&#25191;&#34892;&#39640;&#36136;&#37327;&#21015;&#34920;&#25490;&#24207;&#30340;&#23436;&#20840;&#24320;&#28304;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#22312;TREC 2019&#21644;2020&#28145;&#24230;&#23398;&#20064;&#36319;&#36394;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#27604;GPT-3.5&#23567;&#24471;&#22810;&#30340;7B&#21442;&#25968;&#27169;&#22411;&#23454;&#29616;&#19982;&#38646;&#26679;&#26412;&#37325;&#26032;&#25490;&#24207;&#30456;&#24403;&#30340;&#25928;&#26524;&#65292;&#23613;&#31649;&#25105;&#20204;&#30340;&#25928;&#26524;&#20173;&#30053;&#36874;&#20110;GPT-4&#37325;&#26032;&#25490;&#24207;&#12290;&#25105;&#20204;&#24076;&#26395;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#23558;&#26469;&#20351;&#29992;&#29616;&#20195;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#37325;&#26032;&#25490;&#24207;&#30340;&#30740;&#31350;&#25552;&#20379;&#22522;&#30784;&#12290;&#22797;&#29616;&#25105;&#20204;&#32467;&#26524;&#25152;&#38656;&#30340;&#25152;&#26377;&#20195;&#30721;&#37117;&#21487;&#20197;&#22312;h&#38142;&#25509;&#22788;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Researchers have successfully applied large language models (LLMs) such as ChatGPT to reranking in an information retrieval context, but to date, such work has mostly been built on proprietary models hidden behind opaque API endpoints. This approach yields experimental results that are not reproducible and non-deterministic, threatening the veracity of outcomes that build on such shaky foundations. To address this significant shortcoming, we present RankVicuna, the first fully open-source LLM capable of performing high-quality listwise reranking in a zero-shot setting. Experimental results on the TREC 2019 and 2020 Deep Learning Tracks show that we can achieve effectiveness comparable to zero-shot reranking with GPT-3.5 with a much smaller 7B parameter model, although our effectiveness remains slightly behind reranking with GPT-4. We hope our work provides the foundation for future research on reranking with modern LLMs. All the code necessary to reproduce our results is available at h
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#25991;&#29486;&#23884;&#20837;&#22312;&#30740;&#31350;&#35770;&#25991;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#32593;&#32476;&#20998;&#26512;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26469;&#35780;&#20272;&#25512;&#33616;&#30340;&#26032;&#39062;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;&#30740;&#31350;&#34920;&#26126;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36873;&#25321;&#19981;&#21516;&#30340;&#20195;&#34920;&#24615;&#26041;&#27861;&#20250;&#23545;&#25512;&#33616;&#32467;&#26524;&#30340;&#24615;&#36136;&#20135;&#29983;&#24433;&#21709;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35770;&#25991;&#23884;&#20837;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#21019;&#26032;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.14984</link><description>&lt;p&gt;
&#25991;&#29486;&#23884;&#20837;&#22312;&#30740;&#31350;&#35770;&#25991;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20316;&#29992;: &#26159;&#30772;&#22351;&#23398;&#31185;&#36793;&#30028;&#36824;&#26159;&#21152;&#24378;&#23427;&#65311;
&lt;/p&gt;
&lt;p&gt;
The Role of Document Embedding in Research Paper Recommender Systems: To Breakdown or to Bolster Disciplinary Borders?. (arXiv:2309.14984v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#25991;&#29486;&#23884;&#20837;&#22312;&#30740;&#31350;&#35770;&#25991;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#32593;&#32476;&#20998;&#26512;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26469;&#35780;&#20272;&#25512;&#33616;&#30340;&#26032;&#39062;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;&#30740;&#31350;&#34920;&#26126;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36873;&#25321;&#19981;&#21516;&#30340;&#20195;&#34920;&#24615;&#26041;&#27861;&#20250;&#23545;&#25512;&#33616;&#32467;&#26524;&#30340;&#24615;&#36136;&#20135;&#29983;&#24433;&#21709;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35770;&#25991;&#23884;&#20837;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#21019;&#26032;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#30340;&#25512;&#33616;&#31995;&#32479;&#25991;&#29486;&#20013;&#65292;&#26032;&#39062;&#24615;&#21644;&#22810;&#26679;&#24615;&#34987;&#35748;&#20026;&#26159;&#26377;&#29992;&#25512;&#33616;&#30340;&#20851;&#38190;&#23646;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#30740;&#31350;&#35770;&#25991;&#25512;&#33616;&#31995;&#32479;&#30340;&#20855;&#20307;&#23376;&#39046;&#22495;&#20013;&#65292;&#36825;&#20123;&#23646;&#24615;&#24471;&#21040;&#20102;&#26377;&#38480;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20026;&#31185;&#23398;&#23478;&#25552;&#20379;&#26032;&#39062;&#21644;&#22810;&#26679;&#30340;&#30740;&#31350;&#35770;&#25991;&#25512;&#33616;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20943;&#23569;&#38548;&#31163;&#38405;&#35835;&#65292;&#25171;&#30772;&#36807;&#28388;&#27873;&#21644;&#20419;&#36827;&#36328;&#23398;&#31185;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#30740;&#31350;&#35770;&#25991;&#25512;&#33616;&#30340;&#26032;&#39062;&#24615;&#21644;&#22810;&#26679;&#24615;&#30340;&#26032;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21033;&#29992;&#20102;&#32593;&#32476;&#20998;&#26512;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;&#20351;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26356;&#22823;&#30340;&#30740;&#31350;&#35770;&#25991;&#25512;&#33616;&#31995;&#32479;&#20013;&#36873;&#25321;&#20195;&#34920;&#24615;&#26041;&#27861;&#21487;&#20197;&#23545;&#19979;&#28216;&#25512;&#33616;&#30340;&#24615;&#36136;&#65292;&#29305;&#21035;&#26159;&#23427;&#20204;&#30340;&#26032;&#39062;&#24615;&#21644;&#22810;&#26679;&#24615;&#20135;&#29983;&#21487;&#34913;&#37327;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#35770;&#25991;&#23884;&#20837;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#23427;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#21019;&#26032;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the extensive recommender systems literature, novelty and diversity have been identified as key properties of useful recommendations. However, these properties have received limited attention in the specific sub-field of research paper recommender systems. In this work, we argue for the importance of offering novel and diverse research paper recommendations to scientists. This approach aims to reduce siloed reading, break down filter bubbles, and promote interdisciplinary research. We propose a novel framework for evaluating the novelty and diversity of research paper recommendations that leverages methods from network analysis and natural language processing. Using this framework, we show that the choice of representational method within a larger research paper recommendation system can have a measurable impact on the nature of downstream recommendations, specifically on their novelty and diversity. We introduce a novel paper embedding method, which we demonstrate offers more innov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;MAINT&#27169;&#22411;&#65292;&#36890;&#36807;&#22810;&#37325;&#25237;&#24433;&#21644;&#22810;&#26041;&#38754;&#27880;&#24847;&#21147;&#26426;&#21046;&#25429;&#25417;&#22810;&#26041;&#38754;&#30340;&#20559;&#22909;&#21644;&#24847;&#22270;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#22810;&#34892;&#20026;&#24207;&#21015;&#25512;&#33616;&#20013;&#26080;&#27861;&#25429;&#25417;&#22810;&#26041;&#38754;&#29305;&#24615;&#21644;&#22788;&#29702;&#22122;&#22768;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.14938</link><description>&lt;p&gt;
&#23545;&#20110;&#22810;&#34892;&#20026;&#24207;&#21015;&#25512;&#33616;&#65292;&#24314;&#27169;&#22810;&#26041;&#38754;&#30340;&#20559;&#22909;&#21644;&#24847;&#22270;
&lt;/p&gt;
&lt;p&gt;
Modeling Multi-aspect Preferences and Intents for Multi-behavioral Sequential Recommendation. (arXiv:2309.14938v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;MAINT&#27169;&#22411;&#65292;&#36890;&#36807;&#22810;&#37325;&#25237;&#24433;&#21644;&#22810;&#26041;&#38754;&#27880;&#24847;&#21147;&#26426;&#21046;&#25429;&#25417;&#22810;&#26041;&#38754;&#30340;&#20559;&#22909;&#21644;&#24847;&#22270;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#22810;&#34892;&#20026;&#24207;&#21015;&#25512;&#33616;&#20013;&#26080;&#27861;&#25429;&#25417;&#22810;&#26041;&#38754;&#29305;&#24615;&#21644;&#22788;&#29702;&#22122;&#22768;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#34892;&#20026;&#24207;&#21015;&#25512;&#33616;&#36817;&#24180;&#26469;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38480;&#21046;&#12290;&#39318;&#20808;&#65292;&#29992;&#25143;&#30340;&#20559;&#22909;&#21644;&#24847;&#22270;&#21487;&#20197;&#20174;&#22810;&#20010;&#35282;&#24230;&#36827;&#34892;&#31934;&#32454;&#25551;&#36848;&#65307;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#26080;&#27861;&#25429;&#25417;&#20854;&#22810;&#26041;&#38754;&#30340;&#29305;&#24615;&#12290;&#20854;&#27425;&#65292;&#29992;&#25143;&#34892;&#20026;&#21487;&#33021;&#21253;&#21547;&#22122;&#22768;&#65292;&#32780;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#19981;&#33021;&#26377;&#25928;&#22788;&#29702;&#22122;&#22768;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#22810;&#20010;&#25237;&#24433;&#30340;&#27880;&#24847;&#21147;&#24490;&#29615;&#27169;&#22411;&#65292;&#29992;&#20110;&#25429;&#25417;&#22810;&#26041;&#38754;&#30340;&#20559;&#22909;&#21644;&#24847;&#22270;&#65288;&#31616;&#31216;MAINT&#65289;&#12290;&#20026;&#20102;&#20174;&#30446;&#26631;&#34892;&#20026;&#20013;&#25552;&#21462;&#22810;&#26041;&#38754;&#30340;&#20559;&#22909;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#26041;&#38754;&#25237;&#24433;&#26426;&#21046;&#65292;&#29992;&#20110;&#20174;&#22810;&#20010;&#26041;&#38754;&#29983;&#25104;&#22810;&#20010;&#20559;&#22909;&#34920;&#31034;&#12290;&#20026;&#20102;&#20174;&#22810;&#31867;&#22411;&#34892;&#20026;&#20013;&#25552;&#21462;&#22810;&#26041;&#38754;&#24847;&#22270;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#22411;LSTM&#21644;&#22810;&#26041;&#38754;&#31934;&#21270;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;&#27880;&#24847;&#21147;&#26426;&#21046;&#21487;&#20197;&#28388;&#38500;&#22122;&#22768;&#24182;&#20174;&#22810;&#20010;&#26041;&#38754;&#29983;&#25104;&#22810;&#20010;&#24847;&#22270;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-behavioral sequential recommendation has recently attracted increasing attention. However, existing methods suffer from two major limitations. Firstly, user preferences and intents can be described in fine-grained detail from multiple perspectives; yet, these methods fail to capture their multi-aspect nature. Secondly, user behaviors may contain noises, and most existing methods could not effectively deal with noises. In this paper, we present an attentive recurrent model with multiple projections to capture Multi-Aspect preferences and INTents (MAINT in short). To extract multi-aspect preferences from target behaviors, we propose a multi-aspect projection mechanism for generating multiple preference representations from multiple aspects. To extract multi-aspect intents from multi-typed behaviors, we propose a behavior-enhanced LSTM and a multi-aspect refinement attention mechanism. The attention mechanism can filter out noises and generate multiple intent representations from di
&lt;/p&gt;</description></item><item><title>REFORM&#26159;&#19968;&#20010;CTR&#39044;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#20010;&#27969;&#24335;&#21472;&#21152;&#30340;&#24490;&#29615;&#32467;&#26500;&#21033;&#29992;&#20102;&#22810;&#32423;&#39640;&#38454;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#28040;&#38500;&#20102;&#35823;&#20851;&#32852;&#12290;</title><link>http://arxiv.org/abs/2309.14891</link><description>&lt;p&gt;
REFORM: &#31227;&#38500;CTR&#39044;&#27979;&#20013;&#30340;&#35823;&#20851;&#32852;&#30340;&#22810;&#32423;&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;
REFORM: Removing False Correlation in Multi-level Interaction for CTR Prediction. (arXiv:2309.14891v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14891
&lt;/p&gt;
&lt;p&gt;
REFORM&#26159;&#19968;&#20010;CTR&#39044;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#20010;&#27969;&#24335;&#21472;&#21152;&#30340;&#24490;&#29615;&#32467;&#26500;&#21033;&#29992;&#20102;&#22810;&#32423;&#39640;&#38454;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#28040;&#38500;&#20102;&#35823;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#26159;&#22312;&#32447;&#24191;&#21578;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#65292;&#20934;&#30830;&#30340;&#39044;&#27979;&#23545;&#20110;&#29992;&#25143;&#23450;&#20301;&#21644;&#20010;&#24615;&#21270;&#25512;&#33616;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#21069;&#27839;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#22797;&#26434;&#30340;&#38544;&#24335;&#21644;&#26174;&#24335;&#29305;&#24449;&#20132;&#20114;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24573;&#35270;&#20102;&#30001;&#28151;&#28102;&#22240;&#23376;&#25110;&#36873;&#25321;&#20559;&#24046;&#24341;&#36215;&#30340;&#35823;&#20851;&#32852;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#36825;&#20123;&#20132;&#20114;&#30340;&#22797;&#26434;&#24615;&#21644;&#20887;&#20313;&#24615;&#19979;&#21464;&#24471;&#26356;&#21152;&#20005;&#37325;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;CTR&#39044;&#27979;&#26694;&#26550;&#65292;&#31216;&#20026;REFORM&#65292;&#22312;&#22810;&#32423;&#29305;&#24449;&#20132;&#20114;&#20013;&#31227;&#38500;&#20102;&#35823;&#20851;&#32852;&#12290;&#25152;&#25552;&#20986;&#30340;REFORM&#26694;&#26550;&#36890;&#36807;&#20004;&#20010;&#27969;&#24335;&#21472;&#21152;&#30340;&#24490;&#29615;&#32467;&#26500;&#21033;&#29992;&#20102;&#22823;&#37327;&#30340;&#22810;&#32423;&#39640;&#38454;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#28040;&#38500;&#20102;&#35823;&#20851;&#32852;&#12290;&#35813;&#26694;&#26550;&#26377;&#20004;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65306;I. &#22810;&#32423;&#21472;&#21152;&#24490;&#29615;&#65288;MSR&#65289;&#32467;&#26500;&#20351;&#27169;&#22411;&#33021;&#22815;&#39640;&#25928;&#22320;&#25429;&#25417;&#21040;&#26469;&#33258;&#29305;&#24449;&#31354;&#38388;&#30340;&#22810;&#26679;&#38750;&#32447;&#24615;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction is a critical task in online advertising and recommendation systems, as accurate predictions are essential for user targeting and personalized recommendations. Most recent cutting-edge methods primarily focus on investigating complex implicit and explicit feature interactions. However, these methods neglect the issue of false correlations caused by confounding factors or selection bias. This problem is further magnified by the complexity and redundancy of these interactions. We propose a CTR prediction framework that removes false correlation in multi-level feature interaction, termed REFORM. The proposed REFORM framework exploits a wide range of multi-level high-order feature representations via a two-stream stacked recurrent structure while eliminating false correlations. The framework has two key components: I. The multi-level stacked recurrent (MSR) structure enables the model to efficiently capture diverse nonlinear interactions from feature spa
&lt;/p&gt;</description></item><item><title>ALEX&#26159;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#22270;&#20256;&#36755;&#23398;&#20064;&#38382;&#39064;&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#22270;&#23545;&#27604;&#23398;&#20064;&#21644;&#24179;&#34913;&#26631;&#31614;&#20998;&#24067;&#30340;&#23376;&#22270;&#26500;&#24314;&#26041;&#27861;&#26469;&#25552;&#20379;&#31283;&#20581;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2309.14673</link><description>&lt;p&gt;
ALEX: &#26397;&#21521;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#26377;&#25928;&#22270;&#20256;&#36755;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
ALEX: Towards Effective Graph Transfer Learning with Noisy Labels. (arXiv:2309.14673v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14673
&lt;/p&gt;
&lt;p&gt;
ALEX&#26159;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#22270;&#20256;&#36755;&#23398;&#20064;&#38382;&#39064;&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#20351;&#29992;&#22270;&#23545;&#27604;&#23398;&#20064;&#21644;&#24179;&#34913;&#26631;&#31614;&#20998;&#24067;&#30340;&#23376;&#22270;&#26500;&#24314;&#26041;&#27861;&#26469;&#25552;&#20379;&#31283;&#20581;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#22240;&#22312;&#21508;&#31181;&#22270;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#20986;&#33394;&#34920;&#29616;&#32780;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#22522;&#20110;GNN&#30340;&#26041;&#27861;&#37117;&#26159;&#20351;&#29992;&#23436;&#20840;&#27880;&#37322;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#30740;&#31350;&#65292;&#23548;&#33268;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#22270;&#23398;&#20064;&#22330;&#26223;&#20013;&#34920;&#29616;&#19981;&#20339;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#30340;&#22270;&#20256;&#36755;&#23398;&#20064;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#23558;&#30693;&#35782;&#20174;&#24102;&#26377;&#22122;&#22768;&#30340;&#28304;&#22270;&#20256;&#36755;&#21040;&#26410;&#26631;&#35760;&#30340;&#30446;&#26631;&#22270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;Balance Alignment and Information-aware Examination (ALEX)&#30340;&#26032;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;ALEX&#39318;&#20808;&#20351;&#29992;&#22855;&#24322;&#20540;&#20998;&#35299;&#29983;&#25104;&#20855;&#26377;&#20851;&#38190;&#32467;&#26500;&#35821;&#20041;&#30340;&#19981;&#21516;&#35270;&#22270;&#65292;&#21033;&#29992;&#22270;&#23545;&#27604;&#23398;&#20064;&#26469;&#25552;&#20379;&#31283;&#20581;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;&#20026;&#20102;&#20943;&#36731;&#26631;&#31614;&#20559;&#31227;&#21644;&#39046;&#22495;&#20559;&#31227;&#65292;&#25105;&#20204;&#20272;&#35745;&#19968;&#20010;&#20808;&#39564;&#20998;&#24067;&#26469;&#26500;&#24314;&#20855;&#26377;&#24179;&#34913;&#26631;&#31614;&#20998;&#24067;&#30340;&#23376;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have garnered considerable interest due to their exceptional performance in a wide range of graph machine learning tasks. Nevertheless, the majority of GNN-based approaches have been examined using well-annotated benchmark datasets, leading to suboptimal performance in real-world graph learning scenarios. To bridge this gap, the present paper investigates the problem of graph transfer learning in the presence of label noise, which transfers knowledge from a noisy source graph to an unlabeled target graph. We introduce a novel technique termed Balance Alignment and Information-aware Examination (ALEX) to address this challenge. ALEX first employs singular value decomposition to generate different views with crucial structural semantics, which help provide robust node representations using graph contrastive learning. To mitigate both label shift and domain shift, we estimate a prior distribution to build subgraphs with balanced label distributions. Building o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;RuBERT&#27169;&#22411;&#21644;Transformer&#25216;&#26415;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21307;&#23398;&#21672;&#35810;&#30340;&#29992;&#25143;&#26597;&#35810;&#20998;&#31867;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#19987;&#23478;&#29305;&#38271;&#65292;&#34920;&#29616;&#20986;&#36229;&#36807;92%&#30340;&#24615;&#33021;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#21644;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.14662</link><description>&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#21307;&#23398;&#21672;&#35810;&#29992;&#25143;&#26597;&#35810;&#20998;&#31867;&#19982;&#19987;&#23478;&#29305;&#38271;&#30456;&#20851;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Tranformer-based classification of user queries for medical consultancy with respect to expert specialisation. (arXiv:2309.14662v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14662
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;RuBERT&#27169;&#22411;&#21644;Transformer&#25216;&#26415;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21307;&#23398;&#21672;&#35810;&#30340;&#29992;&#25143;&#26597;&#35810;&#20998;&#31867;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#19987;&#23478;&#29305;&#38271;&#65292;&#34920;&#29616;&#20986;&#36229;&#36807;92%&#30340;&#24615;&#33021;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#21644;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#21307;&#30103;&#26102;&#20195;&#65292;&#23545;&#20110;&#29087;&#32451;&#30340;&#21307;&#30103;&#25903;&#25345;&#30340;&#38656;&#27714;&#27491;&#22312;&#22686;&#38271;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#31574;&#30053;&#65292;&#21033;&#29992;RuBERT&#27169;&#22411;&#65292;&#23558;&#21307;&#23398;&#21672;&#35810;&#39046;&#22495;&#30340;&#29992;&#25143;&#26597;&#35810;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#30528;&#37325;&#20851;&#27880;&#19987;&#23478;&#30340;&#29305;&#38271;&#12290;&#36890;&#36807;&#21033;&#29992;Transformer&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#22312;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#38598;&#19978;&#23545;&#39044;&#35757;&#32451;&#30340;RuBERT&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#23454;&#29616;&#20102;&#26597;&#35810;&#19982;&#29305;&#23450;&#21307;&#23398;&#19987;&#38271;&#20043;&#38388;&#30340;&#31934;&#30830;&#23545;&#24212;&#12290;&#36890;&#36807;&#20351;&#29992;&#20840;&#38754;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20132;&#21449;&#39564;&#35777;&#21644;&#20256;&#32479;&#30340;&#27979;&#35797;&#21644;&#35757;&#32451;&#38598;&#21010;&#20998;&#19979;&#22343;&#20855;&#26377;&#20248;&#31168;&#30340;&#24615;&#33021;&#65292;F1&#24471;&#20998;&#36229;&#36807;92%&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#24515;&#33039;&#30149;&#23398;&#12289;&#31070;&#32463;&#30149;&#23398;&#21644;&#30382;&#32932;&#31185;&#31561;&#21307;&#23398;&#39046;&#22495;&#30340;&#27867;&#21270;&#24615;&#33021;&#20063;&#38750;&#24120;&#20986;&#33394;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#23454;&#38469;&#30410;&#22788;&#65292;&#21487;&#20197;&#23558;&#29992;&#25143;&#24341;&#23548;&#33267;&#36866;&#24403;&#30340;&#19987;&#23478;&#20197;&#33719;&#24471;&#21450;&#26102;&#32780;&#26377;&#38024;&#23545;&#24615;&#30340;&#21307;&#30103;&#24314;&#35758;&#12290;&#23427;&#36824;&#25552;&#39640;&#20102;&#21307;&#30103;&#31995;&#32479;&#30340;&#25928;&#29575;&#65292;&#20943;&#23569;&#20102;&#20174;&#19994;&#32773;&#30340;&#36127;&#25285;&#12290;
&lt;/p&gt;
&lt;p&gt;
The need for skilled medical support is growing in the era of digital healthcare. This research presents an innovative strategy, utilising the RuBERT model, for categorising user inquiries in the field of medical consultation with a focus on expert specialisation. By harnessing the capabilities of transformers, we fine-tuned the pre-trained RuBERT model on a varied dataset, which facilitates precise correspondence between queries and particular medical specialisms. Using a comprehensive dataset, we have demonstrated our approach's superior performance with an F1-score of over 92%, calculated through both cross-validation and the traditional split of test and train datasets. Our approach has shown excellent generalisation across medical domains such as cardiology, neurology and dermatology. This methodology provides practical benefits by directing users to appropriate specialists for prompt and targeted medical advice. It also enhances healthcare system efficiency, reduces practitioner 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#22635;&#34917;&#20102;&#20851;&#20110;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#25512;&#33616;&#31639;&#27861;&#22312;&#31639;&#27861;&#21246;&#32467;&#30740;&#31350;&#20013;&#34987;&#24573;&#35270;&#30340;&#31354;&#30333;&#65292;&#24182;&#21457;&#29616;&#25512;&#33616;&#31639;&#27861;&#21487;&#20197;&#20915;&#23450;&#22522;&#20110;AI&#30340;&#23450;&#20215;&#31639;&#27861;&#30340;&#31454;&#20105;&#25110;&#21246;&#32467;&#21160;&#24577;&#12290;</title><link>http://arxiv.org/abs/2309.14548</link><description>&lt;p&gt;
&#31639;&#27861;&#21246;&#32467;&#36824;&#26159;&#31454;&#20105;&#65306;&#24179;&#21488;&#25512;&#33616;&#31995;&#32479;&#30340;&#35282;&#33394;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Collusion or Competition: the Role of Platforms' Recommender Systems. (arXiv:2309.14548v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14548
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#22635;&#34917;&#20102;&#20851;&#20110;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#25512;&#33616;&#31639;&#27861;&#22312;&#31639;&#27861;&#21246;&#32467;&#30740;&#31350;&#20013;&#34987;&#24573;&#35270;&#30340;&#31354;&#30333;&#65292;&#24182;&#21457;&#29616;&#25512;&#33616;&#31639;&#27861;&#21487;&#20197;&#20915;&#23450;&#22522;&#20110;AI&#30340;&#23450;&#20215;&#31639;&#27861;&#30340;&#31454;&#20105;&#25110;&#21246;&#32467;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#23398;&#26415;&#30740;&#31350;&#24191;&#27867;&#25506;&#35752;&#20102;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;(AI)&#30340;&#21160;&#24577;&#23450;&#20215;&#31639;&#27861;&#23548;&#33268;&#30340;&#31639;&#27861;&#21246;&#32467;&#12290;&#28982;&#32780;&#65292;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#20351;&#29992;&#25512;&#33616;&#31639;&#27861;&#26469;&#20998;&#37197;&#19981;&#21516;&#20135;&#21697;&#30340;&#26333;&#20809;&#65292;&#32780;&#36825;&#19968;&#37325;&#35201;&#26041;&#38754;&#22312;&#20808;&#21069;&#30340;&#31639;&#27861;&#21246;&#32467;&#30740;&#31350;&#20013;&#34987;&#22823;&#37096;&#20998;&#24573;&#35270;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#22635;&#34917;&#20102;&#25991;&#29486;&#20013;&#36825;&#19968;&#37325;&#35201;&#30340;&#31354;&#30333;&#65292;&#24182;&#26816;&#39564;&#20102;&#25512;&#33616;&#31639;&#27861;&#22914;&#20309;&#20915;&#23450;&#22522;&#20110;AI&#30340;&#23450;&#20215;&#31639;&#27861;&#30340;&#31454;&#20105;&#25110;&#21246;&#32467;&#21160;&#24577;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#24120;&#29992;&#30340;&#25512;&#33616;&#31639;&#27861;&#65306;(i)&#20197;&#26368;&#22823;&#21270;&#21334;&#23478;&#24635;&#21033;&#28070;&#20026;&#30446;&#26631;&#30340;&#25512;&#33616;&#31995;&#32479;&#21644;(ii)&#20197;&#26368;&#22823;&#21270;&#24179;&#21488;&#19978;&#20135;&#21697;&#38656;&#27714;&#20026;&#30446;&#26631;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#37325;&#22797;&#21338;&#24328;&#26694;&#26550;&#65292;&#23558;&#21334;&#23478;&#30340;&#23450;&#20215;&#31639;&#27861;&#21644;&#24179;&#21488;&#30340;&#25512;&#33616;&#31639;&#27861;&#36827;&#34892;&#20102;&#25972;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent academic research has extensively examined algorithmic collusion resulting from the utilization of artificial intelligence (AI)-based dynamic pricing algorithms. Nevertheless, e-commerce platforms employ recommendation algorithms to allocate exposure to various products, and this important aspect has been largely overlooked in previous studies on algorithmic collusion. Our study bridges this important gap in the literature and examines how recommendation algorithms can determine the competitive or collusive dynamics of AI-based pricing algorithms. Specifically, two commonly deployed recommendation algorithms are examined: (i) a recommender system that aims to maximize the sellers' total profit (profit-based recommender system) and (ii) a recommender system that aims to maximize the demand for products sold on the platform (demand-based recommender system). We construct a repeated game framework that incorporates both pricing algorithms adopted by sellers and the platform's recom
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GLORY&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20840;&#23616;&#22270;&#19982;&#26412;&#22320;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26500;&#24314;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#65292;&#24182;&#32771;&#34385;&#20102;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2307.06576</link><description>&lt;p&gt;
&#36229;&#36234;&#26412;&#22320;&#33539;&#22260;&#65306;&#20840;&#29699;&#22270;&#22686;&#24378;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06576
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GLORY&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20840;&#23616;&#22270;&#19982;&#26412;&#22320;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26500;&#24314;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#65292;&#24182;&#32771;&#34385;&#20102;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#22320;&#21521;&#29992;&#25143;&#25512;&#33616;&#20505;&#36873;&#26032;&#38395;&#25991;&#31456;&#19968;&#30452;&#26159;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#30340;&#26680;&#24515;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#36817;&#26399;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20351;&#29992;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#20174;&#20016;&#23500;&#30340;&#25991;&#26412;&#25968;&#25454;&#20013;&#25552;&#21462;&#35821;&#20041;&#20449;&#24687;&#65292;&#20351;&#29992;&#20174;&#26412;&#22320;&#21382;&#21490;&#26032;&#38395;&#27966;&#29983;&#30340;&#22522;&#20110;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#32570;&#20047;&#20840;&#23616;&#35270;&#35282;&#65292;&#26410;&#33021;&#32771;&#34385;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#65292;&#36229;&#36234;&#35821;&#20041;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411; GLORY&#65288;Global-LOcal news Recommendation sYstem&#65289;&#65292;&#23427;&#32467;&#21512;&#20102;&#20174;&#20854;&#20182;&#29992;&#25143;&#23398;&#21040;&#30340;&#20840;&#23616;&#34920;&#31034;&#21644;&#26412;&#22320;&#34920;&#31034;&#65292;&#26469;&#22686;&#24378;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#20840;&#23616;&#26032;&#38395;&#22270;&#65292;&#24182;&#20351;&#29992;&#38376;&#25511;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20016;&#23500;&#26032;&#38395;&#34920;&#31034;&#65292;&#20174;&#32780;&#36890;&#36807;&#21382;&#21490;&#26032;&#38395;&#32858;&#21512;&#22120;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems. Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news. However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information. To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems. We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.06569</link><description>&lt;p&gt;
&#22914;&#20309;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#32034;&#24341;&#39033;&#30446;ID
&lt;/p&gt;
&lt;p&gt;
How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#23558;&#25512;&#33616;&#20219;&#21153;&#36716;&#25442;&#20026;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#25512;&#33616;&#12290;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#24314;&#35758;&#30340;&#39033;&#30446;&#32780;&#19981;&#26159;&#35745;&#31639;&#20256;&#32479;&#25512;&#33616;&#27169;&#22411;&#20013;&#27599;&#20010;&#20505;&#36873;&#39033;&#30446;&#30340;&#25490;&#21517;&#24471;&#20998;&#65292;&#31616;&#21270;&#20102;&#25512;&#33616;&#31649;&#36947;&#65292;&#36991;&#20813;&#20102;&#22810;&#27573;&#36807;&#28388;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#20915;&#23450;&#35201;&#25512;&#33616;&#21738;&#20123;&#39033;&#30446;&#26102;&#29983;&#25104;&#36807;&#38271;&#30340;&#25991;&#26412;&#65292;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#21019;&#24314;LLM&#20860;&#23481;&#30340;&#39033;&#30446;ID&#26159;&#24517;&#35201;&#30340;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#65292;&#20197;P5&#20026;&#20195;&#34920;&#30340;&#20027;&#24178;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32034;&#24341;&#26041;&#27861;&#22797;&#21046;&#20854;&#32467;&#26524;&#12290;&#25105;&#20204;&#39318;&#20808;&#35752;&#35770;&#20102;&#20960;&#31181;&#24494;&#19981;&#36275;&#36947;&#30340;&#39033;&#30446;&#32034;&#24341;&#26041;&#27861;&#65288;&#22914;&#29420;&#31435;&#32034;&#24341;&#12289;&#26631;&#39064;&#32034;&#24341;&#21644;&#38543;&#26426;&#32034;&#24341;&#65289;&#30340;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#19981;&#36866;&#29992;&#20110;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32034;&#24341;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#31181;&#32034;&#24341;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#32034;&#24341;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#20171;&#32461;&#20102;&#25968;&#25454;&#31934;&#28860;&#30340;&#27010;&#24565;&#21644;&#26041;&#27861;&#65292;&#20197;&#21450;&#38024;&#23545;&#19981;&#21516;&#25968;&#25454;&#31867;&#22411;&#30340;&#24212;&#29992;&#12290;&#25968;&#25454;&#31934;&#28860;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#27169;&#22411;&#35757;&#32451;&#12289;&#25512;&#29702;&#21644;&#26550;&#26500;&#25628;&#32034;&#31561;&#22330;&#26223;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#22823;&#22411;&#25968;&#25454;&#38598;&#35757;&#32451;&#27169;&#22411;&#25152;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.04272</link><description>&lt;p&gt;
&#25968;&#25454;&#31934;&#28860;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Data Distillation: A Survey. (arXiv:2301.04272v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04272
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#20171;&#32461;&#20102;&#25968;&#25454;&#31934;&#28860;&#30340;&#27010;&#24565;&#21644;&#26041;&#27861;&#65292;&#20197;&#21450;&#38024;&#23545;&#19981;&#21516;&#25968;&#25454;&#31867;&#22411;&#30340;&#24212;&#29992;&#12290;&#25968;&#25454;&#31934;&#28860;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#27169;&#22411;&#35757;&#32451;&#12289;&#25512;&#29702;&#21644;&#26550;&#26500;&#25628;&#32034;&#31561;&#22330;&#26223;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#22823;&#22411;&#25968;&#25454;&#38598;&#35757;&#32451;&#27169;&#22411;&#25152;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#27969;&#34892;&#23548;&#33268;&#20102;&#22823;&#37327;&#21508;&#31181;&#21508;&#26679;&#30340;&#25968;&#25454;&#38598;&#30340;&#25972;&#29702;&#12290;&#23613;&#31649;&#22312;&#20010;&#21035;&#20219;&#21153;&#19978;&#34920;&#29616;&#25509;&#36817;&#20154;&#31867;&#27700;&#24179;&#65292;&#20294;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#21442;&#25968;&#24222;&#22823;&#30340;&#27169;&#22411;&#38754;&#20020;&#22810;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;&#22914;&#65288;a&#65289;&#39640;&#27169;&#22411;&#35757;&#32451;&#26102;&#38388;&#65307;&#65288;b&#65289;&#24930;&#30340;&#30740;&#31350;&#36845;&#20195;&#65307;&#21644;&#65288;c&#65289;&#24046;&#30340;&#29983;&#24577;&#21487;&#25345;&#32493;&#24615;&#12290;&#20316;&#20026;&#26367;&#20195;&#26041;&#26696;&#65292;&#25968;&#25454;&#31934;&#28860;&#26041;&#27861;&#26088;&#22312;&#21512;&#25104;&#31616;&#27905;&#30340;&#25968;&#25454;&#25688;&#35201;&#65292;&#36825;&#20123;&#25688;&#35201;&#21487;&#20197;&#20316;&#20026;&#21407;&#22987;&#25968;&#25454;&#38598;&#30340;&#26377;&#25928;&#26367;&#20195;&#21697;&#65292;&#29992;&#20110;&#27169;&#22411;&#35757;&#32451;&#12289;&#25512;&#29702;&#12289;&#26550;&#26500;&#25628;&#32034;&#31561;&#22330;&#26223;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#25454;&#31934;&#28860;&#30340;&#19968;&#20010;&#24418;&#24335;&#26694;&#26550;&#65292;&#24182;&#25552;&#20379;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#35814;&#32454;&#20998;&#31867;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#28085;&#30422;&#20102;&#38024;&#23545;&#19981;&#21516;&#25968;&#25454;&#31867;&#22411;&#30340;&#25968;&#25454;&#31934;&#28860;&#26041;&#27861;&#65292;&#21253;&#25324;&#22270;&#20687;&#12289;&#22270;&#24418;&#21644;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#65288;&#25512;&#33616;&#31995;&#32479;&#65289;&#65292;&#21516;&#26102;&#30830;&#23450;&#20102;&#24403;&#21069;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
The popularity of deep learning has led to the curation of a vast number of massive and multifarious datasets. Despite having close-to-human performance on individual tasks, training parameter-hungry models on large datasets poses multi-faceted problems such as (a) high model-training time; (b) slow research iteration; and (c) poor eco-sustainability. As an alternative, data distillation approaches aim to synthesize terse data summaries, which can serve as effective drop-in replacements of the original dataset for scenarios like model training, inference, architecture search, etc. In this survey, we present a formal framework for data distillation, along with providing a detailed taxonomy of existing approaches. Additionally, we cover data distillation approaches for different data modalities, namely images, graphs, and user-item interactions (recommender systems), while also identifying current challenges and future research directions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21367;&#31215;&#22359;&#21305;&#37197;&#31639;&#27861;&#65292;&#29992;&#20110;&#38899;&#20048;&#32467;&#26500;&#20998;&#26512;&#65292;&#36890;&#36807;&#35745;&#31639;&#33258;&#30456;&#20284;&#30697;&#38453;&#26469;&#36798;&#21040;&#19982;&#26377;&#30417;&#30563;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.15356</link><description>&lt;p&gt;
&#20351;&#29992;&#21367;&#31215;&#22359;&#21305;&#37197;&#20998;&#21106;&#31639;&#27861;&#36827;&#34892;&#38899;&#20048;&#32467;&#26500;&#20998;&#26512;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Convolutive Block-Matching Segmentation Algorithm with Application to Music Structure Analysis. (arXiv:2210.15356v2 [cs.SD] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21367;&#31215;&#22359;&#21305;&#37197;&#31639;&#27861;&#65292;&#29992;&#20110;&#38899;&#20048;&#32467;&#26500;&#20998;&#26512;&#65292;&#36890;&#36807;&#35745;&#31639;&#33258;&#30456;&#20284;&#30697;&#38453;&#26469;&#36798;&#21040;&#19982;&#26377;&#30417;&#30563;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#20048;&#32467;&#26500;&#20998;&#26512;&#65288;MSA&#65289;&#21253;&#25324;&#23558;&#19968;&#39318;&#27468;&#26354;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#37096;&#20998;&#65288;&#22914;&#8220;&#21103;&#27468;&#8221;&#65292;&#8220;&#35799;&#27468;&#8221;&#65292;&#8220;&#29420;&#22863;&#8221;&#31561;&#65289;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#23547;&#25214;&#27468;&#26354;&#30340;&#31616;&#21270;&#32452;&#32455;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#21367;&#31215;&#22359;&#21305;&#37197;&#65288;CBM&#65289;&#31639;&#27861;&#65292;&#19987;&#38376;&#29992;&#20110;MSA&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;CBM&#31639;&#27861;&#26159;&#19968;&#31181;&#21160;&#24577;&#35268;&#21010;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;&#33258;&#30456;&#20284;&#30697;&#38453;&#65292;&#36825;&#26159;MSA&#20013;&#30340;&#19968;&#31181;&#26631;&#20934;&#24037;&#20855;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#33258;&#30456;&#20284;&#30697;&#38453;&#26159;&#20174;&#38899;&#39057;&#20449;&#21495;&#30340;&#29305;&#24449;&#34920;&#31034;&#20013;&#35745;&#31639;&#20986;&#26469;&#30340;&#65292;&#26102;&#38388;&#26681;&#25454;&#23567;&#33410;&#21051;&#24230;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#30456;&#20284;&#24230;&#20989;&#25968;&#26469;&#35745;&#31639;&#33258;&#30456;&#20284;&#30697;&#38453;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;4&#20010;&#25351;&#26631;&#20013;&#26377;3&#20010;&#25351;&#26631;&#19978;&#30340;&#24615;&#33021;&#19982;&#26377;&#30417;&#30563;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#24403;&#65292;&#21516;&#26102;&#23427;&#26159;&#26080;&#30417;&#30563;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Music Structure Analysis (MSA) consists of representing a song in sections (such as ``chorus'', ``verse'', ``solo'' etc), and can be seen as the retrieval of a simplified organization of the song. This work presents a new algorithm, called Convolutive Block-Matching (CBM) algorithm, devoted to MSA. In particular, the CBM algorithm is a dynamic programming algorithm, applying on autosimilarity matrices, a standard tool in MSA. In this work, autosimilarity matrices are computed from the feature representation of an audio signal, and time is sampled on the barscale. We study three different similarity functions for the computation of autosimilarity matrices. We report that the proposed algorithm achieves a level of performance competitive to that of supervised State-of-the-Art methods on 3 among 4 metrics, while being unsupervised.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;EPIC-KITCHENS-100&#22810;&#23454;&#20363;&#26816;&#32034;&#25361;&#25112;2022&#20013;&#21033;&#29992;&#35821;&#20041;&#35282;&#33394;&#19978;&#19979;&#25991;&#21270;&#30340;&#35270;&#39057;&#29305;&#24449;&#36827;&#34892;&#25991;&#26412;-&#35270;&#39057;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19977;&#20803;&#25439;&#22833;&#20989;&#25968;&#22312;&#22810;&#20010;&#23884;&#20837;&#31354;&#38388;&#20013;&#34701;&#21512;&#35270;&#39057;&#21644;&#25991;&#26412;&#29305;&#24449;&#65292;&#36229;&#36807;&#20102;&#24378;&#22522;&#32447;&#65292;&#22312;nDCG&#21644;mAP&#26041;&#38754;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2206.14381</link><description>&lt;p&gt;
&#21033;&#29992;&#35821;&#20041;&#35282;&#33394;&#19978;&#19979;&#25991;&#21270;&#30340;&#35270;&#39057;&#29305;&#24449;&#22312;EPIC-KITCHENS-100&#22810;&#23454;&#20363;&#25991;&#26412;-&#35270;&#39057;&#26816;&#32034;&#25361;&#25112;2022&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Exploiting Semantic Role Contextualized Video Features for Multi-Instance Text-Video Retrieval EPIC-KITCHENS-100 Multi-Instance Retrieval Challenge 2022. (arXiv:2206.14381v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14381
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;EPIC-KITCHENS-100&#22810;&#23454;&#20363;&#26816;&#32034;&#25361;&#25112;2022&#20013;&#21033;&#29992;&#35821;&#20041;&#35282;&#33394;&#19978;&#19979;&#25991;&#21270;&#30340;&#35270;&#39057;&#29305;&#24449;&#36827;&#34892;&#25991;&#26412;-&#35270;&#39057;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19977;&#20803;&#25439;&#22833;&#20989;&#25968;&#22312;&#22810;&#20010;&#23884;&#20837;&#31354;&#38388;&#20013;&#34701;&#21512;&#35270;&#39057;&#21644;&#25991;&#26412;&#29305;&#24449;&#65292;&#36229;&#36807;&#20102;&#24378;&#22522;&#32447;&#65292;&#22312;nDCG&#21644;mAP&#26041;&#38754;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#25253;&#21578;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#22312;EPIC-KITCHENS-100&#22810;&#23454;&#20363;&#26816;&#32034;&#25361;&#25112;2022&#20013;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#21477;&#23376;&#35299;&#26512;&#20026;&#19982;&#21160;&#35789;&#21644;&#21517;&#35789;&#30456;&#23545;&#24212;&#30340;&#35821;&#20041;&#35282;&#33394;&#65307;&#28982;&#21518;&#21033;&#29992;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#22810;&#20010;&#23884;&#20837;&#31354;&#38388;&#20013;&#36890;&#36807;&#19977;&#20803;&#25439;&#22833;&#20989;&#25968;&#21033;&#29992;&#35821;&#20041;&#35282;&#33394;&#19978;&#19979;&#25991;&#21270;&#30340;&#35270;&#39057;&#29305;&#24449;&#21644;&#25991;&#26412;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26631;&#20934;&#21270;&#25240;&#25187;&#32047;&#35745;&#22686;&#30410;&#65288;nDCG&#65289;&#26041;&#38754;&#36229;&#36807;&#20102;&#24378;&#22522;&#32447;&#65292;&#36825;&#23545;&#20110;&#35821;&#20041;&#30456;&#20284;&#24230;&#26356;&#26377;&#20215;&#20540;&#12290;&#25105;&#20204;&#30340;&#25552;&#20132;&#22312;nDCG&#25490;&#21517;&#31532;&#19977;&#65292;&#22312;mAP&#25490;&#21517;&#31532;&#22235;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this report, we present our approach for EPIC-KITCHENS-100 Multi-Instance Retrieval Challenge 2022. We first parse sentences into semantic roles corresponding to verbs and nouns; then utilize self-attentions to exploit semantic role contextualized video features along with textual features via triplet losses in multiple embedding spaces. Our method overpasses the strong baseline in normalized Discounted Cumulative Gain (nDCG), which is more valuable for semantic similarity. Our submission is ranked 3rd for nDCG and ranked 4th for mAP.
&lt;/p&gt;</description></item></channel></rss>