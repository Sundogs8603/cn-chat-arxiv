<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#30693;&#35782;&#30340;&#22810;&#27169;&#24577;&#38899;&#20048;&#30456;&#20284;&#24615;&#65292;&#26088;&#22312;&#24320;&#21457;&#19968;&#20010;&#23436;&#20840;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#31995;&#32479;&#65292;&#20026;&#26368;&#32456;&#29992;&#25143;&#25552;&#20379;&#26356;&#22810;&#23545;&#38899;&#20048;&#30456;&#20284;&#24615;&#21644;&#20998;&#31867;&#31995;&#32479;&#30340;&#25511;&#21046;&#21644;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.12249</link><description>&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#30340;&#22810;&#27169;&#24577;&#38899;&#20048;&#30456;&#20284;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Knowledge-based Multimodal Music Similarity. (arXiv:2306.12249v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#30693;&#35782;&#30340;&#22810;&#27169;&#24577;&#38899;&#20048;&#30456;&#20284;&#24615;&#65292;&#26088;&#22312;&#24320;&#21457;&#19968;&#20010;&#23436;&#20840;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#31995;&#32479;&#65292;&#20026;&#26368;&#32456;&#29992;&#25143;&#25552;&#20379;&#26356;&#22810;&#23545;&#38899;&#20048;&#30456;&#20284;&#24615;&#21644;&#20998;&#31867;&#31995;&#32479;&#30340;&#25511;&#21046;&#21644;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#20048;&#30456;&#20284;&#24615;&#26159;&#38899;&#20048;&#26816;&#32034;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#38899;&#20048;&#20998;&#26512;&#30340;&#37325;&#35201;&#26041;&#38754;&#12290;&#32780;&#19988;&#65292;&#23545;&#20110;&#38899;&#20048;&#19987;&#23478;&#26469;&#35828;&#65292;&#30456;&#20284;&#24615;&#21487;&#20197;&#30740;&#31350;&#20316;&#26354;&#23478;&#21644;&#21382;&#21490;&#26102;&#26399;&#20043;&#38388;&#30340;&#31867;&#27604;&#21644;&#24433;&#21709;&#12290;&#30446;&#21069;&#65292;&#38024;&#23545;&#38899;&#20048;&#30456;&#20284;&#24615;&#30340;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#31526;&#21495;&#20869;&#23481;&#65292;&#36825;&#21487;&#33021;&#25104;&#26412;&#39640;&#26114;&#19988;&#19981;&#24635;&#26159;&#26131;&#20110;&#33719;&#24471;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20351;&#29992;&#38899;&#39057;&#20449;&#21495;&#30340;&#26041;&#27861;&#36890;&#24120;&#26080;&#27861;&#25552;&#20379;&#26377;&#20851;&#35266;&#23519;&#21040;&#30340;&#30456;&#20284;&#24615;&#32972;&#21518;&#21407;&#22240;&#30340;&#20219;&#20309;&#35265;&#35299;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#31526;&#21495;&#21644;&#38899;&#39057;&#20869;&#23481;&#26469;&#30740;&#31350;&#38899;&#20048;&#30456;&#20284;&#24615;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#30340;&#26159;&#24320;&#21457;&#19968;&#20010;&#23436;&#20840;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#31995;&#32479;&#65292;&#21487;&#20197;&#20026;&#26368;&#32456;&#29992;&#25143;&#25552;&#20379;&#26356;&#22810;&#23545;&#38899;&#20048;&#30456;&#20284;&#24615;&#21644;&#20998;&#31867;&#31995;&#32479;&#30340;&#25511;&#21046;&#21644;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Music similarity is an essential aspect of music retrieval, recommendation systems, and music analysis. Moreover, similarity is of vital interest for music experts, as it allows studying analogies and influences among composers and historical periods. Current approaches to musical similarity rely mainly on symbolic content, which can be expensive to produce and is not always readily available. Conversely, approaches using audio signals typically fail to provide any insight about the reasons behind the observed similarity. This research addresses the limitations of current approaches by focusing on the study of musical similarity using both symbolic and audio content. The aim of this research is to develop a fully explainable and interpretable system that can provide end-users with more control and understanding of music similarity and classification systems.
&lt;/p&gt;</description></item><item><title>CompMix&#26159;&#19968;&#20010;&#24322;&#26500;&#38382;&#31572;&#31995;&#32479;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#26377;&#22810;&#20010;&#20449;&#24687;&#28304;&#21644;&#22797;&#26434;&#24847;&#22270;&#65292;&#26088;&#22312;&#25552;&#20379;&#20844;&#24179;&#30340;&#35780;&#20272;QA&#31995;&#32479;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.12235</link><description>&lt;p&gt;
CompMix: &#19968;&#31181;&#24322;&#26500;&#38382;&#31572;&#31995;&#32479;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
CompMix: A Benchmark for Heterogeneous Question Answering. (arXiv:2306.12235v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12235
&lt;/p&gt;
&lt;p&gt;
CompMix&#26159;&#19968;&#20010;&#24322;&#26500;&#38382;&#31572;&#31995;&#32479;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#26377;&#22810;&#20010;&#20449;&#24687;&#28304;&#21644;&#22797;&#26434;&#24847;&#22270;&#65292;&#26088;&#22312;&#25552;&#20379;&#20844;&#24179;&#30340;&#35780;&#20272;QA&#31995;&#32479;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20107;&#23454;&#20026;&#20013;&#24515;&#30340;&#38382;&#31572;&#31995;&#32479;&#32463;&#24120;&#38656;&#35201;&#35775;&#38382;&#22810;&#31181;&#24322;&#26500;&#20449;&#24687;&#28304;&#12290;&#36890;&#36807;&#20849;&#21516;&#32771;&#34385;&#22810;&#20010;&#20449;&#24687;&#28304;&#65292;&#22914;&#30693;&#35782;&#24211;&#12289;&#25991;&#26412;&#25910;&#38598;&#21644;&#26469;&#33258;&#32593;&#32476;&#30340;&#34920;&#26684;&#65292;&#38382;&#31572;&#31995;&#32479;&#21487;&#20197;&#22686;&#24378;&#20854;&#31572;&#26696;&#35206;&#30422;&#33539;&#22260;&#21644;&#21487;&#20449;&#24230;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340; QA &#22522;&#20934;&#27979;&#35797;&#22823;&#22810;&#26159;&#20026;&#20102;&#26500;&#24314;&#21333;&#19968;&#30340;&#30693;&#35782;&#36164;&#28304;&#32780;&#35774;&#35745;&#30340;&#12290;&#36825;&#38480;&#21046;&#20102;&#36825;&#20123;&#22522;&#20934;&#27979;&#35797;&#30340;&#33021;&#21147;&#65292;&#26080;&#27861;&#20844;&#24179;&#22320;&#35780;&#20272;&#21487;&#20197;&#21033;&#29992;&#22810;&#20010;&#20449;&#24687;&#24211;&#30340; QA &#31995;&#32479;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102; CompMix&#65292;&#36825;&#26159;&#19968;&#31181;&#30001;&#20247;&#21253;&#38382;&#31572;&#26500;&#24314;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#33258;&#28982;&#22320;&#35201;&#27714;&#38598;&#25104;&#22810;&#31181;&#36755;&#20837;&#28304;&#12290;CompMix &#20849;&#26377; 9,410 &#20010;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#22810;&#20010;&#22797;&#26434;&#24847;&#22270;&#65292;&#22914;&#36830;&#25509;&#21644;&#26102;&#38388;&#26465;&#20214;&#12290;&#22312; CompMix &#19978;&#35780;&#20272;&#19968;&#31995;&#21015; QA &#31995;&#32479;&#24378;&#35843;&#20102;&#36827;&#19968;&#27493;&#30740;&#31350;&#21033;&#29992;&#24322;&#26500;&#20449;&#24687;&#28304;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fact-centric question answering (QA) often requires access to multiple, heterogeneous, information sources. By jointly considering several sources like a knowledge base (KB), a text collection, and tables from the web, QA systems can enhance their answer coverage and confidence. However, existing QA benchmarks are mostly constructed with a single source of knowledge in mind. This limits capabilities of these benchmarks to fairly evaluate QA systems that can tap into more than one information repository. To bridge this gap, we release CompMix, a crowdsourced QA benchmark which naturally demands the integration of a mixture of input sources. CompMix has a total of 9,410 questions, and features several complex intents like joins and temporal conditions. Evaluation of a range of QA systems on CompMix highlights the need for further research on leveraging information from heterogeneous sources.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#23398;&#20064;&#29992;&#25143;&#29983;&#21629;&#21608;&#26399;&#34920;&#31034;&#30340;&#22810;&#20219;&#21153;&#25512;&#33616;&#38454;&#27573;&#33258;&#36866;&#24212;&#32593;&#32476;&#65288;STAN&#65289;&#26694;&#26550;&#65292;&#21033;&#29992;&#29992;&#25143;&#29983;&#21629;&#21608;&#26399;&#38454;&#27573;&#26469;&#22686;&#24378;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#22312;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;STAN&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#21644;&#29992;&#25143;&#20445;&#30041;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.12232</link><description>&lt;p&gt;
&#22522;&#20110;&#23398;&#20064;&#29992;&#25143;&#29983;&#21629;&#21608;&#26399;&#34920;&#31034;&#30340;&#22810;&#20219;&#21153;&#25512;&#33616;&#38454;&#27573;&#33258;&#36866;&#24212;&#32593;&#32476;&#65288;STAN&#65289;
&lt;/p&gt;
&lt;p&gt;
STAN: Stage-Adaptive Network for Multi-Task Recommendation by Learning User Lifecycle-Based Representation. (arXiv:2306.12232v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#23398;&#20064;&#29992;&#25143;&#29983;&#21629;&#21608;&#26399;&#34920;&#31034;&#30340;&#22810;&#20219;&#21153;&#25512;&#33616;&#38454;&#27573;&#33258;&#36866;&#24212;&#32593;&#32476;&#65288;STAN&#65289;&#26694;&#26550;&#65292;&#21033;&#29992;&#29992;&#25143;&#29983;&#21629;&#21608;&#26399;&#38454;&#27573;&#26469;&#22686;&#24378;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#22312;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;STAN&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#21644;&#29992;&#25143;&#20445;&#30041;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#35768;&#22810;&#22312;&#32447;&#24179;&#21488;&#19978;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#20854;&#20027;&#35201;&#30446;&#26631;&#26159;&#28385;&#36275;&#21644;&#30041;&#20303;&#29992;&#25143;&#12290;&#30001;&#20110;&#30452;&#25509;&#20248;&#21270;&#29992;&#25143;&#20445;&#30041;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#27492;&#36890;&#24120;&#20250;&#37319;&#29992;&#22810;&#31181;&#35780;&#20272;&#25351;&#26631;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#23558;&#36825;&#20123;&#35780;&#20272;&#25351;&#26631;&#30340;&#20248;&#21270;&#24418;&#24335;&#21270;&#20026;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#65292;&#20294;&#24120;&#24120;&#24573;&#30053;&#20102;&#29992;&#25143;&#23545;&#19981;&#21516;&#20219;&#21153;&#30340;&#20559;&#22909;&#26159;&#20010;&#24615;&#21270;&#30340;&#24182;&#19988;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#20107;&#23454;&#12290;&#30830;&#23450;&#21644;&#36319;&#36394;&#29992;&#25143;&#20559;&#22909;&#30340;&#28436;&#21464;&#21487;&#20197;&#25913;&#21892;&#29992;&#25143;&#20445;&#30041;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#29992;&#25143;&#29983;&#21629;&#21608;&#26399;&#8221;&#30340;&#27010;&#24565;&#65292;&#30001;&#22810;&#20010;&#38454;&#27573;&#32452;&#25104;&#65292;&#20854;&#29305;&#24449;&#26159;&#29992;&#25143;&#23545;&#19981;&#21516;&#20219;&#21153;&#20559;&#22909;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38454;&#27573;&#33258;&#36866;&#24212;&#32593;&#32476;&#65288;STAN&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#27169;&#29992;&#25143;&#29983;&#21629;&#21608;&#26399;&#38454;&#27573;&#12290;STAN&#39318;&#20808;&#22522;&#20110;&#23398;&#20064;&#21040;&#30340;&#29992;&#25143;&#20559;&#22909;&#26469;&#35782;&#21035;&#28508;&#22312;&#30340;&#29992;&#25143;&#29983;&#21629;&#21608;&#26399;&#38454;&#27573;&#65292;&#28982;&#21518;&#21033;&#29992;&#38454;&#27573;&#34920;&#31034;&#22686;&#24378;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;STAN&#22312;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#21644;&#29992;&#25143;&#20445;&#30041;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems play a vital role in many online platforms, with their primary objective being to satisfy and retain users. As directly optimizing user retention is challenging, multiple evaluation metrics are often employed. Existing methods generally formulate the optimization of these evaluation metrics as a multitask learning problem, but often overlook the fact that user preferences for different tasks are personalized and change over time. Identifying and tracking the evolution of user preferences can lead to better user retention. To address this issue, we introduce the concept of "user lifecycle", consisting of multiple stages characterized by users' varying preferences for different tasks. We propose a novel Stage-Adaptive Network (STAN) framework for modeling user lifecycle stages. STAN first identifies latent user lifecycle stages based on learned user preferences, and then employs the stage representation to enhance multi-task learning performance. Our experimental r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#20174;&#20044;&#25176;&#37030;&#30340;&#20154;&#21475;&#36317;&#31163;&#8221;&#65288;PDU&#65289;&#30340;&#21518;&#36873;&#25321;&#31574;&#30053;&#65292;&#29992;&#20110;&#30830;&#23450;&#21644;&#36873;&#25321; Pareto-&#26368;&#20248;&#35299;&#20013;&#30340;&#26368;&#20339;&#35299;&#12290;&#35813;&#26041;&#27861;&#20998;&#26512;&#28857;&#30340;&#20998;&#24067;&#65292;&#36890;&#36807;&#20272;&#35745; PDU &#20998;&#25968;&#30340;&#28857;&#30340;&#24179;&#22343;&#20301;&#32622;&#26469;&#30830;&#23450;&#26368;&#20339;&#35299;&#30340;&#21487;&#33021;&#20301;&#32622;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126; PDU &#22312;&#20934;&#30830;&#24615;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.12165</link><description>&lt;p&gt;
&#25628;&#32034;&#21644;&#25512;&#33616;&#20013; Pareto-&#26368;&#20248;&#35299;&#21518;&#36873;&#25321;&#31574;&#30053;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Post-hoc Selection of Pareto-Optimal Solutions in Search and Recommendation. (arXiv:2306.12165v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#20174;&#20044;&#25176;&#37030;&#30340;&#20154;&#21475;&#36317;&#31163;&#8221;&#65288;PDU&#65289;&#30340;&#21518;&#36873;&#25321;&#31574;&#30053;&#65292;&#29992;&#20110;&#30830;&#23450;&#21644;&#36873;&#25321; Pareto-&#26368;&#20248;&#35299;&#20013;&#30340;&#26368;&#20339;&#35299;&#12290;&#35813;&#26041;&#27861;&#20998;&#26512;&#28857;&#30340;&#20998;&#24067;&#65292;&#36890;&#36807;&#20272;&#35745; PDU &#20998;&#25968;&#30340;&#28857;&#30340;&#24179;&#22343;&#20301;&#32622;&#26469;&#30830;&#23450;&#26368;&#20339;&#35299;&#30340;&#21487;&#33021;&#20301;&#32622;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126; PDU &#22312;&#20934;&#30830;&#24615;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#21644;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#20219;&#21153;&#20174;&#22522;&#20110;&#21333;&#19968;&#24230;&#37327;&#35745;&#31639;&#26368;&#32456;&#32467;&#26524;&#30340;&#25490;&#21517;&#36807;&#28193;&#20026;&#22810;&#30446;&#26631;&#38382;&#39064;&#12290;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#20250;&#24471;&#21040;&#19968;&#32452; Pareto-&#26368;&#20248;&#35299;&#65292;&#31216;&#20026; Pareto frontier&#65292;&#20854;&#20013;&#27809;&#26377;&#30446;&#26631;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#21892;&#32780;&#19981;&#25439;&#23475;&#20854;&#20182;&#30446;&#26631;&#12290;&#21407;&#21017;&#19978;&#65292;Pareto frontier &#19978;&#30340;&#25152;&#26377;&#28857;&#37117;&#26377;&#21487;&#33021;&#20195;&#34920;&#30528;&#22522;&#20110;&#20004;&#20010;&#25110;&#22810;&#20010;&#24230;&#37327;&#30456;&#32467;&#21512;&#36873;&#25321;&#30340;&#26368;&#20339;&#27169;&#22411;&#20505;&#36873;&#32773;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#20174;&#20044;&#25176;&#37030;&#30340;&#20154;&#21475;&#36317;&#31163;&#8221;&#65288;PDU&#65289;&#30340;&#26032;&#39062;&#21518;&#36873;&#25321;&#31574;&#30053;&#65292;&#37319;&#29992;&#29702;&#35770;&#19978;&#30340;&#27491;&#24403;&#21270;&#25216;&#26415;&#26469;&#30830;&#23450;&#21644;&#36873;&#25321; Pareto-&#26368;&#20248;&#35299;&#20013;&#30340;&#26368;&#20339;&#35299;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;PDU &#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#28857;&#19982;&#20854;&#20044;&#25176;&#37030;&#28857;&#65288;&#30446;&#26631;&#30340;&#29702;&#24819;&#24615;&#33021;&#65289;&#20043;&#38388;&#30340;&#36317;&#31163;&#26469;&#20998;&#26512;&#28857;&#30340;&#20998;&#24067;&#12290;&#22312;&#19968;&#23450;&#38408;&#20540;&#33539;&#22260;&#20869;&#65292;&#36890;&#36807;&#20272;&#35745; PDU &#20998;&#25968;&#30340;&#28857;&#30340;&#24179;&#22343;&#20301;&#32622;&#26469;&#30830;&#23450;&#26368;&#20339;&#35299;&#30340;&#21487;&#33021;&#20301;&#32622;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272; PDU &#24182;&#19982;&#20854;&#20182;&#30693;&#21517;&#30340;&#36873;&#25321;&#31574;&#30053;&#36827;&#34892;&#27604;&#36739;&#65292;&#32467;&#26524;&#34920;&#26126; PDU &#22312;&#20934;&#30830;&#24615;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information Retrieval (IR) and Recommender Systems (RS) tasks are moving from computing a ranking of final results based on a single metric to multi-objective problems. Solving these problems leads to a set of Pareto-optimal solutions, known as Pareto frontier, in which no objective can be further improved without hurting the others. In principle, all the points on the Pareto frontier are potential candidates to represent the best model selected with respect to the combination of two, or more, metrics. To our knowledge, there are no well-recognized strategies to decide which point should be selected on the frontier. In this paper, we propose a novel, post-hoc, theoretically-justified technique, named "Population Distance from Utopia" (PDU), to identify and select the one-best Pareto-optimal solution from the frontier. In detail, PDU analyzes the distribution of the points by investigating how far each point is from its utopia point (the ideal performance for the objectives). The possib
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31038;&#20132;&#23186;&#20307;&#19978;COVID-19&#35805;&#39064;&#23545;&#20844;&#20247;&#25509;&#31181;&#30123;&#33495;&#24577;&#24230;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#21487;&#20197;&#20998;&#26512;&#35805;&#39064;&#20849;&#40483;&#21644;&#21160;&#21147;&#36716;&#31227;&#65292;&#22686;&#21152;&#30740;&#31350;&#19982;&#20844;&#20247;&#30340;&#36879;&#26126;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.12118</link><description>&lt;p&gt;
&#21487;&#35270;&#21270;&#25506;&#31350;&#19982;COVID-19&#30123;&#33495;&#25509;&#31181;&#24577;&#24230;&#30456;&#20851;&#30340;&#35752;&#35770;&#35805;&#39064;
&lt;/p&gt;
&lt;p&gt;
Visualizing Relation Between (De)Motivating Topics and Public Stance toward COVID-19 Vaccine. (arXiv:2306.12118v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12118
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31038;&#20132;&#23186;&#20307;&#19978;COVID-19&#35805;&#39064;&#23545;&#20844;&#20247;&#25509;&#31181;&#30123;&#33495;&#24577;&#24230;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#21487;&#20197;&#20998;&#26512;&#35805;&#39064;&#20849;&#40483;&#21644;&#21160;&#21147;&#36716;&#31227;&#65292;&#22686;&#21152;&#30740;&#31350;&#19982;&#20844;&#20247;&#30340;&#36879;&#26126;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#22312;&#24403;&#20170;&#36890;&#35759;&#20013;&#36215;&#21040;&#20102;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#20294;&#35823;&#23548;&#21644;&#24694;&#24847;&#35780;&#35770;&#24456;&#23481;&#26131;&#21344;&#25454;&#35805;&#39064;&#65292;&#24341;&#23548;&#20844;&#20247;&#33286;&#35770;&#12290;&#22312;COVID-19&#30123;&#24773;&#26399;&#38388;&#65292;&#25105;&#20204;&#30475;&#21040;&#20102;&#19981;&#23454;&#20449;&#24687;&#30340;&#24433;&#21709;&#65292;&#20844;&#20849;&#21355;&#29983;&#23448;&#21592;&#22312;&#35797;&#22270;&#28608;&#21169;&#20844;&#20247;&#25509;&#31181;&#30123;&#33495;&#26102;&#36973;&#21040;&#20102;&#37325;&#22823;&#25269;&#21046;&#12290;&#20026;&#20102;&#24212;&#23545;&#24403;&#21069;&#21644;&#20219;&#20309;&#26410;&#26469;&#30340;&#32039;&#24613;&#23041;&#32961;&#65292;&#24182;&#28608;&#21169;&#20844;&#20247;&#26397;&#30528;&#19968;&#20010;&#20849;&#21516;&#30340;&#30446;&#26631;&#21069;&#36827;&#65292;&#25105;&#20204;&#38656;&#35201;&#20102;&#35299;&#20844;&#20247;&#21160;&#21147;&#30340;&#36716;&#31227;&#20197;&#21450;&#21738;&#20123;&#35805;&#39064;&#22312;&#26222;&#36890;&#27665;&#20247;&#20013;&#26377;&#20849;&#40483;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#20197;&#26816;&#26597;&#21644;&#20998;&#26512;COVID-19&#30123;&#24773;&#26399;&#38388;Twitter-sphere&#20013;&#30340;&#35805;&#39064;&#65292;&#24182;&#20102;&#35299;&#20851;&#38190;&#22240;&#32032;&#26159;&#20160;&#20040;&#23548;&#33268;&#20844;&#20247;&#23545;&#25509;&#31181;&#30123;&#33495;&#30340;&#24577;&#24230;&#36716;&#21464;&#12290;&#35813;&#24037;&#20855;&#21487;&#20197;&#36731;&#26494;&#25512;&#24191;&#20026;&#20219;&#20309;&#24773;&#26223;&#30340;&#35270;&#35273;&#20998;&#26512;&#24037;&#20855;&#65292;&#24182;&#22686;&#21152;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#23545;&#30740;&#31350;&#20154;&#21592;&#21644;&#26222;&#36890;&#27665;&#20247;&#30340;&#36879;&#26126;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
While social media plays a vital role in communication nowadays, misinformation and trolls can easily take over the conversation and steer public opinion on these platforms. We saw the effect of misinformation during the {COVID-19} pandemic when public health officials faced significant push-back while trying to motivate the public to vaccinate. To tackle the current and any future threats in emergencies and motivate the public towards a common goal, it is essential to understand how public motivation shifts and which topics resonate among the general population. In this study, we proposed an interactive visualization tool to inspect and analyze the topics that resonated among Twitter-sphere during the {COVID-19} pandemic and understand the key factors that shifted public stance for vaccination. This tool can easily be generalized for any scenario for visual analysis and to increase the transparency of social media data for researchers and the general population alike.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#32593;&#32476;&#29228;&#34411;&#21644;&#32593;&#39029;&#25490;&#21517;&#31639;&#27861;&#22312;&#22788;&#29702;Web&#25968;&#25454;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65307;&#22312;&#35780;&#20272;&#20116;&#31181;&#19981;&#21516;&#30340;&#29228;&#21462;&#31639;&#27861;&#21518;&#65292;&#26088;&#22312;&#30830;&#23450;&#26368;&#26377;&#25928;&#30340;&#29228;&#21462;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.12027</link><description>&lt;p&gt;
&#22810;&#31181;&#32593;&#32476;&#29228;&#34411;&#31639;&#27861;&#30340;&#27604;&#36739;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Comparative analysis of various web crawler algorithms. (arXiv:2306.12027v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#32593;&#32476;&#29228;&#34411;&#21644;&#32593;&#39029;&#25490;&#21517;&#31639;&#27861;&#22312;&#22788;&#29702;Web&#25968;&#25454;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65307;&#22312;&#35780;&#20272;&#20116;&#31181;&#19981;&#21516;&#30340;&#29228;&#21462;&#31639;&#27861;&#21518;&#65292;&#26088;&#22312;&#30830;&#23450;&#26368;&#26377;&#25928;&#30340;&#29228;&#21462;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35770;&#36848;&#20102;&#32593;&#32476;&#29228;&#34411;&#21644;&#32593;&#39029;&#25490;&#21517;&#31639;&#27861;&#22312;&#22788;&#29702;&#19990;&#30028;&#21508;&#22320;&#32593;&#32476;&#25968;&#25454;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#12290;&#38543;&#30528;Web&#30340;&#24613;&#21095;&#22686;&#38271;&#65292;&#39640;&#25928;&#30340;&#25628;&#32034;&#21644;&#26816;&#32034;&#26041;&#27861;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#32593;&#32476;&#29228;&#34411;&#26159;&#23558;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#36716;&#25442;&#20026;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#36807;&#31243;&#65292;&#20174;&#32780;&#23454;&#29616;&#26377;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#12290;&#27492;&#22806;&#65292;&#32593;&#39029;&#25490;&#21517;&#31639;&#27861;&#22312;&#35780;&#20272;&#32593;&#39029;&#30340;&#36136;&#37327;&#21644;&#21463;&#27426;&#36814;&#31243;&#24230;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#32972;&#26223;&#65292;&#24182;&#35780;&#20272;&#20102;&#20116;&#31181;&#19981;&#21516;&#30340;&#29228;&#21462;&#31639;&#27861;&#65306;&#40104;&#40060;&#25628;&#32034;&#65292;&#22522;&#20110;&#20248;&#20808;&#32423;&#30340;&#38431;&#21015;&#65292;&#26420;&#32032;&#36125;&#21494;&#26031;&#65292;&#24191;&#24230;&#20248;&#20808;&#21644;&#28145;&#24230;&#20248;&#20808;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#26368;&#26377;&#25928;&#30340;&#32593;&#32476;&#29228;&#34411;&#31639;&#27861;&#12290;&#36890;&#36807;&#20102;&#35299;&#36825;&#20123;&#31639;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#25552;&#39640;&#33258;&#24049;&#22312;Web&#19978;&#23548;&#33322;&#21644;&#25552;&#21462;&#26377;&#20215;&#20540;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This presentation focuses on the importance of web crawling and page ranking algorithms in dealing with the massive amount of data present on the World Wide Web. As the web continues to grow exponentially, efficient search and retrieval methods become crucial. Web crawling is a process that converts unstructured data into structured data, enabling effective information retrieval. Additionally, page ranking algorithms play a significant role in assessing the quality and popularity of web pages. The presentation explores the background of these algorithms and evaluates five different crawling algorithms: Shark Search, Priority-Based Queue, Naive Bayes, Breadth-First, and Depth-First. The goal is to identify the most effective algorithm for crawling web pages. By understanding these algorithms, we can enhance our ability to navigate the web and extract valuable information efficiently.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22855;&#24322;&#35889;&#24179;&#28369;&#31639;&#27861;&#32531;&#35299;&#39034;&#24207;&#25512;&#33616;&#20013;&#24207;&#21015;&#19982;&#39033;&#30446;&#25490;&#21517;&#36864;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;SSA&#25351;&#26631;&#26469;&#35780;&#20272;&#35813;&#38382;&#39064;&#30340;&#20005;&#37325;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11986</link><description>&lt;p&gt;
&#36890;&#36807;&#22855;&#24322;&#35889;&#24179;&#28369;&#35299;&#20915;&#39034;&#24207;&#25512;&#33616;&#20013;&#30340;&#25490;&#21517;&#36864;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Addressing the Rank Degeneration in Sequential Recommendation via Singular Spectrum Smoothing. (arXiv:2306.11986v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22855;&#24322;&#35889;&#24179;&#28369;&#31639;&#27861;&#32531;&#35299;&#39034;&#24207;&#25512;&#33616;&#20013;&#24207;&#21015;&#19982;&#39033;&#30446;&#25490;&#21517;&#36864;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;SSA&#25351;&#26631;&#26469;&#35780;&#20272;&#35813;&#38382;&#39064;&#30340;&#20005;&#37325;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#30740;&#31350;&#21160;&#24577;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#24182;&#29983;&#25104;&#19979;&#19968;&#20010;&#39033;&#30446;&#39044;&#27979;&#12290;&#19979;&#19968;&#20010;&#39033;&#30446;&#30340;&#20559;&#22909;&#36890;&#24120;&#26159;&#36890;&#36807;&#24207;&#21015;&#21644;&#39033;&#30446;&#34920;&#31034;&#20043;&#38388;&#30340;&#20146;&#21644;&#24230;&#29983;&#25104;&#30340;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#65292;&#24207;&#21015;&#21644;&#39033;&#30446;&#34920;&#31034;&#37117;&#20250;&#36973;&#21463;&#25490;&#21517;&#38477;&#32423;&#38382;&#39064;&#12290;&#25490;&#21517;&#36864;&#21270;&#38382;&#39064;&#20005;&#37325;&#25439;&#23475;&#20102;&#39034;&#24207;&#25512;&#33616;&#30340;&#34920;&#31034;&#12290;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#29702;&#35770;&#36830;&#25509;&#24207;&#21015;&#34920;&#31034;&#38477;&#32423;&#38382;&#39064;&#19982;&#39033;&#30446;&#25490;&#21517;&#36864;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#24555;&#36895;&#22855;&#24322;&#20540;&#34928;&#20943;&#29616;&#35937;&#19982;&#36716;&#25442;&#22120;&#24207;&#21015;&#36755;&#20986;&#21644;&#39033;&#30446;&#23884;&#20837;&#20013;&#30340;&#25490;&#21517;&#25240;&#21472;&#38382;&#39064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22855;&#24322;&#20540;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;SSA&#65289;&#35780;&#20272;&#25351;&#26631;&#65292;&#21516;&#26102;&#32531;&#35299;&#39034;&#24207;&#25512;&#33616;&#20013;&#30340;&#24207;&#21015;&#21644;&#39033;&#30446;&#34920;&#31034;&#25490;&#21517;&#36864;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation (SR) investigates the dynamic user preferences modeling and generates the next-item prediction. The next item preference is typically generated by the affinity between the sequence and item representations. However, both sequence and item representations suffer from the rank degeneration issue due to the data sparsity problem. The rank degeneration issue significantly impairs the representations for SR. This motivates us to measure how severe is the rank degeneration issue and alleviate the sequence and item representation rank degeneration issues simultaneously for SR.  In this work, we theoretically connect the sequence representation degeneration issue with the item rank degeneration, particularly for short sequences and cold items. We also identify the connection between the fast singular value decay phenomenon and the rank collapse issue in transformer sequence output and item embeddings. We propose the area under the singular value curve metric to evalua
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#20174;&#20010;&#20307;&#20844;&#24179;&#20998;&#24067;&#20013;&#37319;&#26679;&#25490;&#21517;&#65292;&#21516;&#26102;&#30830;&#20445;&#27599;&#20010;&#36755;&#20986;&#30340;&#25490;&#21517;&#37117;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#36755;&#20986;&#25490;&#21517;&#30340;&#26399;&#26395;&#25928;&#29992;&#33267;&#23569;&#26159;&#26368;&#20248;&#20844;&#24179;&#35299;&#30340;&#25928;&#29992;&#30340;$\alpha$&#20493;&#65292;&#20854;&#20013;$\alpha$&#26159;&#19968;&#20010;&#37327;&#21270;&#20844;&#24179;&#32422;&#26463;&#32039;&#24230;&#30340;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.11964</link><description>&lt;p&gt;
&#37319;&#26679;&#20010;&#20307;&#20844;&#24179;&#19988;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#30340;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Sampling Individually-Fair Rankings that are Always Group Fair. (arXiv:2306.11964v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11964
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#20174;&#20010;&#20307;&#20844;&#24179;&#20998;&#24067;&#20013;&#37319;&#26679;&#25490;&#21517;&#65292;&#21516;&#26102;&#30830;&#20445;&#27599;&#20010;&#36755;&#20986;&#30340;&#25490;&#21517;&#37117;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#36755;&#20986;&#25490;&#21517;&#30340;&#26399;&#26395;&#25928;&#29992;&#33267;&#23569;&#26159;&#26368;&#20248;&#20844;&#24179;&#35299;&#30340;&#25928;&#29992;&#30340;$\alpha$&#20493;&#65292;&#20854;&#20013;$\alpha$&#26159;&#19968;&#20010;&#37327;&#21270;&#20844;&#24179;&#32422;&#26463;&#32039;&#24230;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24179;&#21488;&#19978;&#30340;&#25490;&#21517;&#21487;&#20197;&#24110;&#21161;&#29992;&#25143;&#24555;&#36895;&#25214;&#21040;&#30456;&#20851;&#20449;&#24687;&#65292;&#22914;&#20154;&#29289;&#12289;&#26032;&#38395;&#12289;&#23186;&#20307;&#21644;&#20135;&#21697;&#12290;&#20844;&#24179;&#25490;&#21517;&#26159;&#19968;&#31181;&#20026;&#20102;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#32780;&#20248;&#21270;&#19968;&#32452;&#39033;&#30446;&#25490;&#21517;&#30340;&#20219;&#21153;&#65292;&#24050;&#32463;&#22312;&#31639;&#27861;&#20844;&#24179;&#24615;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36817;&#26399;&#30340;&#30740;&#31350;&#34920;&#26126;&#39033;&#30446;&#25928;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#19981;&#20844;&#24179;&#30340;&#20027;&#35201;&#21407;&#22240;&#65292;&#24182;&#24314;&#35758;&#22312;&#36755;&#20986;&#20013;&#24341;&#20837;&#38543;&#26426;&#24615;&#12290;&#36825;&#31181;&#38543;&#26426;&#24615;&#32463;&#36807;&#20180;&#32454;&#36873;&#25321;&#65292;&#20197;&#30830;&#20445;&#23545;&#27599;&#20010;&#39033;&#30446;&#36827;&#34892;&#20805;&#20998;&#19988;&#21512;&#29702;&#30340;&#20195;&#34920;&#65288;&#21516;&#26102;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#65289;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#31181;&#38543;&#26426;&#24615;&#65292;&#36755;&#20986;&#30340;&#25490;&#21517;&#21487;&#33021;&#20250;&#36829;&#21453;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#20174;&#19968;&#20010;&#20010;&#20307;&#20844;&#24179;&#20998;&#24067;&#20013;&#25277;&#26679;&#25490;&#21517;&#65292;&#21516;&#26102;&#30830;&#20445;&#27599;&#20010;&#36755;&#20986;&#30340;&#25490;&#21517;&#37117;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#36755;&#20986;&#25490;&#21517;&#30340;&#26399;&#26395;&#25928;&#29992;&#33267;&#23569;&#26159;&#26368;&#20248;&#20844;&#24179;&#35299;&#30340;&#25928;&#29992;&#30340; $\alpha$ &#20493;&#65292;&#20854;&#20013; $\alpha$ &#26159;&#19968;&#20010;&#37327;&#21270;&#20844;&#24179;&#32422;&#26463;&#32039;&#24230;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#39640;&#25928;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rankings on online platforms help their end-users find the relevant information -- people, news, media, and products -- quickly. Fair ranking tasks, which ask to rank a set of items to maximize utility subject to satisfying group-fairness constraints, have gained significant interest in the Algorithmic Fairness, Information Retrieval, and Machine Learning literature. Recent works, however, identify uncertainty in the utilities of items as a primary cause of unfairness and propose introducing randomness in the output. This randomness is carefully chosen to guarantee an adequate representation of each item (while accounting for the uncertainty). However, due to this randomness, the output rankings may violate group fairness constraints. We give an efficient algorithm that samples rankings from an individually-fair distribution while ensuring that every output ranking is group fair. The expected utility of the output ranking is at least $\alpha$ times the utility of the optimal fair solut
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22810;&#27169;&#24577;&#21307;&#23398;&#25968;&#25454;&#34701;&#21512;&#22312;&#26234;&#24935;&#21307;&#30103;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#31526;&#21512;DIKW&#26426;&#21046;&#30340;&#36890;&#29992;&#34701;&#21512;&#26694;&#26550;&#65292;&#25506;&#35752;&#20102;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2306.11963</link><description>&lt;p&gt;
&#26234;&#24935;&#21307;&#30103;&#20013;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;:&#20174;&#25968;&#25454;&#12289;&#20449;&#24687;&#12289;&#30693;&#35782;&#21040;&#26234;&#24935;&#20043;&#26053;
&lt;/p&gt;
&lt;p&gt;
Multimodality Fusion for Smart Healthcare: a Journey from Data, Information, Knowledge to Wisdom. (arXiv:2306.11963v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22810;&#27169;&#24577;&#21307;&#23398;&#25968;&#25454;&#34701;&#21512;&#22312;&#26234;&#24935;&#21307;&#30103;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#31526;&#21512;DIKW&#26426;&#21046;&#30340;&#36890;&#29992;&#34701;&#21512;&#26694;&#26550;&#65292;&#25506;&#35752;&#20102;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#21307;&#23398;&#25968;&#25454;&#34701;&#21512;&#24050;&#25104;&#20026;&#26234;&#24935;&#21307;&#30103;&#20013;&#30340;&#19968;&#31181;&#38761;&#26032;&#24615;&#26041;&#27861;&#65292;&#33021;&#22815;&#20840;&#38754;&#20102;&#35299;&#24739;&#32773;&#20581;&#24247;&#29366;&#20917;&#21644;&#20010;&#24615;&#21270;&#27835;&#30103;&#26041;&#26696;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22810;&#27169;&#24577;&#34701;&#21512;&#20026;&#26234;&#24935;&#21307;&#30103;&#24102;&#26469;&#30340;&#20174;&#25968;&#25454;&#12289;&#20449;&#24687;&#21644;&#30693;&#35782;&#21040;&#26234;&#24935;&#65288;DIKW&#65289;&#20043;&#26053;&#12290;&#20840;&#38754;&#22238;&#39038;&#20102;&#22810;&#27169;&#24577;&#21307;&#23398;&#25968;&#25454;&#34701;&#21512;&#30340;&#30740;&#31350;&#29616;&#29366;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#19981;&#21516;&#25968;&#25454;&#27169;&#24577;&#30340;&#38598;&#25104;&#26041;&#24335;&#12290;&#25991;&#31456;&#25506;&#35752;&#20102;&#29305;&#24449;&#36873;&#25321;&#12289;&#22522;&#20110;&#35268;&#21017;&#30340;&#31995;&#32479;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#28145;&#24230;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#19981;&#21516;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#34701;&#21512;&#21644;&#20998;&#26512;&#12290;&#21516;&#26102;&#65292;&#25991;&#31456;&#20063;&#30528;&#37325;&#35752;&#35770;&#20102;&#22810;&#27169;&#24577;&#34701;&#21512;&#22312;&#21307;&#30103;&#20445;&#20581;&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#32508;&#21512;&#35780;&#36848;&#30340;&#26694;&#26550;&#21644;&#35265;&#35299;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31526;&#21512;DIKW&#26426;&#21046;&#30340;&#36890;&#29992;&#22810;&#27169;&#24577;&#21307;&#30103;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#12290;&#27492;&#22806;&#65292;&#25991;&#31456;&#36824;&#25506;&#35752;&#20102;&#26410;&#26469;&#19982;&#39044;&#27979;&#12289;&#39044;&#38450;&#12289;&#20010;&#24615;&#21270;&#21644;&#27835;&#30103;&#26377;&#20851;&#30340;&#21307;&#30103;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal medical data fusion has emerged as a transformative approach in smart healthcare, enabling a comprehensive understanding of patient health and personalized treatment plans. In this paper, a journey from data, information, and knowledge to wisdom (DIKW) is explored through multimodal fusion for smart healthcare. A comprehensive review of multimodal medical data fusion focuses on the integration of various data modalities are presented. It explores different approaches such as Feature selection, Rule-based systems, Machine learning, Deep learning, and Natural Language Processing for fusing and analyzing multimodal data. The paper also highlights the challenges associated with multimodal fusion in healthcare. By synthesizing the reviewed frameworks and insights, a generic framework for multimodal medical data fusion is proposed while aligning with the DIKW mechanism. Moreover, it discusses future directions aligned with the four pillars of healthcare: Predictive, Preventive, Pe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#25968;&#25454;&#22788;&#29702;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#20013;&#20351;&#29992;&#22522;&#20110;&#26816;&#32034;&#30340;Transformer&#27169;&#22411;&#26469;&#35299;&#20915;&#34920;&#26684;&#22686;&#24378;&#20219;&#21153;&#65292;&#24182;&#37319;&#29992;&#33258;&#23398;&#20064;&#31574;&#30053;&#26469;&#35757;&#32451;&#27169;&#22411;&#20197;&#37325;&#26500;&#21407;&#22987;&#20540;&#25110;&#26631;&#39064;&#65292;&#20197;&#20415;&#20943;&#36731;&#25968;&#25454;&#20998;&#26512;&#24072;&#22312;&#25968;&#25454;&#22788;&#29702;&#20013;&#30340;&#24037;&#20316;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.11843</link><description>&lt;p&gt;
&#22522;&#20110;&#26816;&#32034;&#30340;Transformer&#27169;&#22411;&#29992;&#20110;&#34920;&#26684;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Based Transformer for Table Augmentation. (arXiv:2306.11843v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#25968;&#25454;&#22788;&#29702;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#20013;&#20351;&#29992;&#22522;&#20110;&#26816;&#32034;&#30340;Transformer&#27169;&#22411;&#26469;&#35299;&#20915;&#34920;&#26684;&#22686;&#24378;&#20219;&#21153;&#65292;&#24182;&#37319;&#29992;&#33258;&#23398;&#20064;&#31574;&#30053;&#26469;&#35757;&#32451;&#27169;&#22411;&#20197;&#37325;&#26500;&#21407;&#22987;&#20540;&#25110;&#26631;&#39064;&#65292;&#20197;&#20415;&#20943;&#36731;&#25968;&#25454;&#20998;&#26512;&#24072;&#22312;&#25968;&#25454;&#22788;&#29702;&#20013;&#30340;&#24037;&#20316;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20934;&#22791;&#65288;&#20063;&#31216;&#25968;&#25454;&#25972;&#29702;&#65289;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#36827;&#34892;&#20998;&#26512;&#25110;&#26500;&#24314;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26102;&#26368;&#32791;&#36153;&#26102;&#38388;&#21644;&#31934;&#21147;&#30340;&#27493;&#39588;&#20043;&#19968;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#21160;&#25968;&#25454;&#22788;&#29702;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#35797;&#22270;&#20943;&#36731;&#26368;&#32456;&#29992;&#25143;&#65288;&#20363;&#22914;&#25968;&#25454;&#20998;&#26512;&#24072;&#65289;&#22312;&#20174;&#25968;&#25454;&#28246;&#20013;&#26500;&#24314;&#21160;&#24577;&#34920;&#26684;&#25968;&#25454;&#30340;&#36807;&#31243;&#20013;&#30340;&#24037;&#20316;&#37327;&#12290;&#25105;&#20204;&#26088;&#22312;&#35299;&#20915;&#34920;&#26684;&#22686;&#24378;&#20219;&#21153;&#65292;&#21253;&#25324;&#34892;/&#21015;&#22635;&#20805;&#21644;&#25968;&#25454;&#25554;&#34917;&#12290;&#32473;&#23450;&#19968;&#32452;&#34920;&#26684;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#30340;&#33258;&#23398;&#20064;Transformer&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#33258;&#23398;&#20064;&#31574;&#30053;&#26159;&#20174;&#35821;&#26009;&#24211;&#20013;&#38543;&#26426;&#21435;&#38500;&#34920;&#26684;&#65292;&#24182;&#35757;&#32451;&#26816;&#32034;&#27169;&#22411;&#20197;&#22312;&#32473;&#23450;&#37096;&#20998;&#34920;&#26684;&#20316;&#20026;&#36755;&#20837;&#30340;&#24773;&#20917;&#19979;&#37325;&#26500;&#21407;&#22987;&#20540;&#25110;&#26631;&#39064;&#12290;&#25105;&#20204;&#37319;&#29992;&#36825;&#31181;&#31574;&#30053;&#26469;&#39318;&#20808;&#35757;&#32451;&#23494;&#38598;&#30340;&#31070;&#32463;&#26816;&#32034;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Data preparation, also called data wrangling, is considered one of the most expensive and time-consuming steps when performing analytics or building machine learning models. Preparing data typically involves collecting and merging data from complex heterogeneous, and often large-scale data sources, such as data lakes. In this paper, we introduce a novel approach toward automatic data wrangling in an attempt to alleviate the effort of end-users, e.g. data analysts, in structuring dynamic views from data lakes in the form of tabular data. We aim to address table augmentation tasks, including row/column population and data imputation. Given a corpus of tables, we propose a retrieval augmented self-trained transformer model. Our self-learning strategy consists in randomly ablating tables from the corpus and training the retrieval-based model to reconstruct the original values or headers given the partial tables as input. We adopt this strategy to first train the dense neural retrieval mode
&lt;/p&gt;</description></item></channel></rss>