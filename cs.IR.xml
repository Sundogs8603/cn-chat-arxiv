<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CLLM4Rec&#65292;&#39318;&#20010;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#25512;&#33616;&#31995;&#32479;&#30340; ID &#27169;&#24335;&#32039;&#23494;&#38598;&#25104;&#30340;&#21327;&#21516;&#25512;&#33616;&#31639;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#35821;&#20041;&#24046;&#36317;&#12289;&#34394;&#20551;&#30456;&#20851;&#21644;&#20302;&#25928;&#25512;&#33616;&#31561;&#38382;&#39064;&#12290;&#36890;&#36807;&#25193;&#23637;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#35789;&#27719;&#34920;&#65292;&#24182;&#24341;&#20837;&#36719;&#30828;&#25552;&#31034;&#31574;&#30053;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#27169;&#25311;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#21327;&#21516;&#19982;&#20869;&#23481;&#35821;&#20041;&#12290;</title><link>http://arxiv.org/abs/2311.01343</link><description>&lt;p&gt;
&#21327;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Collaborative Large Language Model for Recommender Systems. (arXiv:2311.01343v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CLLM4Rec&#65292;&#39318;&#20010;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#25512;&#33616;&#31995;&#32479;&#30340; ID &#27169;&#24335;&#32039;&#23494;&#38598;&#25104;&#30340;&#21327;&#21516;&#25512;&#33616;&#31639;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#35821;&#20041;&#24046;&#36317;&#12289;&#34394;&#20551;&#30456;&#20851;&#21644;&#20302;&#25928;&#25512;&#33616;&#31561;&#38382;&#39064;&#12290;&#36890;&#36807;&#25193;&#23637;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#35789;&#27719;&#34920;&#65292;&#24182;&#24341;&#20837;&#36719;&#30828;&#25552;&#31034;&#31574;&#30053;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#27169;&#25311;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#21327;&#21516;&#19982;&#20869;&#23481;&#35821;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#23545;&#22522;&#20110;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24320;&#21457;&#19979;&#19968;&#20195;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#20135;&#29983;&#20102;&#20852;&#36259;&#65292;&#20805;&#20998;&#21033;&#29992;&#20854;&#32534;&#30721;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#33258;&#28982;&#35821;&#35328;&#19982;&#25512;&#33616;&#20219;&#21153;&#20043;&#38388;&#30340;&#35821;&#20041;&#24046;&#36317;&#20173;&#26410;&#24471;&#21040;&#24456;&#22909;&#30340;&#35299;&#20915;&#65292;&#23548;&#33268;&#19968;&#20123;&#38382;&#39064;&#65292;&#22914;&#34394;&#20551;&#30456;&#20851;&#30340;&#29992;&#25143;/&#39033;&#30446;&#25551;&#36848;&#31526;&#12289;&#23545;&#29992;&#25143;/&#39033;&#30446;&#20869;&#23481;&#30340;&#20302;&#25928;&#35821;&#35328;&#24314;&#27169;&#20197;&#21450;&#36890;&#36807;&#33258;&#21160;&#22238;&#24402;&#36827;&#34892;&#20302;&#25928;&#30340;&#25512;&#33616;&#31561;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CLLM4Rec&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#32039;&#23494;&#38598;&#25104;LLM&#33539;&#24335;&#21644;RS&#30340;ID&#33539;&#24335;&#30340;&#29983;&#25104;RS&#65292;&#26088;&#22312;&#21516;&#26102;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#29992;&#25143;/&#39033;&#30446;ID&#26631;&#35760;&#25193;&#23637;&#20102;&#39044;&#35757;&#32451;LLM&#30340;&#35789;&#27719;&#34920;&#65292;&#20197;&#24544;&#23454;&#22320;&#27169;&#25311;&#29992;&#25143;/&#39033;&#30446;&#30340;&#21327;&#21516;&#21644;&#20869;&#23481;&#35821;&#20041;&#12290;&#22240;&#27492;&#65292;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36719;&#30828;&#25552;&#31034;&#31574;&#30053;&#65292;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#26377;&#25928;&#22320;&#23398;&#20064;&#29992;&#25143;/&#39033;&#30446;&#30340;&#21327;&#21516;/&#20869;&#23481;&#26631;&#35760;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there is a growing interest in developing next-generation recommender systems (RSs) based on pretrained large language models (LLMs), fully utilizing their encoded knowledge and reasoning ability. However, the semantic gap between natural language and recommendation tasks is still not well addressed, leading to multiple issues such as spuriously-correlated user/item descriptors, ineffective language modeling on user/item contents, and inefficient recommendations via auto-regression, etc. In this paper, we propose CLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and ID paradigm of RS, aiming to address the above challenges simultaneously. We first extend the vocabulary of pretrained LLMs with user/item ID tokens to faithfully model the user/item collaborative and content semantics. Accordingly, in the pretraining stage, a novel soft+hard prompting strategy is proposed to effectively learn user/item collaborative/content token embeddings via language m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20013;&#30340;&#38382;&#39064;&#22238;&#31572;&#36827;&#34892;&#20102;&#33539;&#22260;&#22238;&#39038;&#12290;&#19982;&#20854;&#20182;&#21307;&#23398;QA&#20219;&#21153;&#19981;&#21516;&#65292;EHR QA&#36890;&#36807;&#20174;&#24739;&#32773;&#30340;&#21307;&#30103;&#35760;&#24405;&#20013;&#33719;&#21462;&#31572;&#26696;&#12290;&#36825;&#39033;&#30740;&#31350;&#20026;&#29616;&#26377;&#30340;EHR QA&#20316;&#21697;&#25552;&#20379;&#20102;&#26041;&#27861;&#35770;&#22238;&#39038;&#12290;</title><link>http://arxiv.org/abs/2310.08759</link><description>&lt;p&gt;
&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#38382;&#39064;&#22238;&#31572;&#65306;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#30340;&#33539;&#22260;&#22238;&#39038;
&lt;/p&gt;
&lt;p&gt;
Question Answering for Electronic Health Records: A Scoping Review of datasets and models. (arXiv:2310.08759v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08759
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20013;&#30340;&#38382;&#39064;&#22238;&#31572;&#36827;&#34892;&#20102;&#33539;&#22260;&#22238;&#39038;&#12290;&#19982;&#20854;&#20182;&#21307;&#23398;QA&#20219;&#21153;&#19981;&#21516;&#65292;EHR QA&#36890;&#36807;&#20174;&#24739;&#32773;&#30340;&#21307;&#30103;&#35760;&#24405;&#20013;&#33719;&#21462;&#31572;&#26696;&#12290;&#36825;&#39033;&#30740;&#31350;&#20026;&#29616;&#26377;&#30340;EHR QA&#20316;&#21697;&#25552;&#20379;&#20102;&#26041;&#27861;&#35770;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#24739;&#32773;&#30456;&#20851;&#30340;&#38382;&#39064;&#22238;&#31572;&#65288;QA&#65289;&#31995;&#32479;&#21487;&#20197;&#24110;&#21161;&#20020;&#24202;&#21307;&#29983;&#21644;&#24739;&#32773;&#12290;&#23427;&#20204;&#21487;&#20197;&#24110;&#21161;&#20020;&#24202;&#21307;&#29983;&#20570;&#20915;&#31574;&#65292;&#24182;&#20351;&#24739;&#32773;&#26356;&#22909;&#22320;&#20102;&#35299;&#20182;&#20204;&#30340;&#30149;&#21382;&#12290;&#22823;&#37327;&#30340;&#24739;&#32773;&#25968;&#25454;&#23384;&#20648;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20013;&#65292;&#20351;&#24471;EHR QA&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#22312;EHR QA&#20013;&#65292;&#31572;&#26696;&#26159;&#20174;&#24739;&#32773;&#30340;&#21307;&#30103;&#35760;&#24405;&#20013;&#33719;&#24471;&#30340;&#12290;&#30001;&#20110;&#25968;&#25454;&#26684;&#24335;&#21644;&#27169;&#24335;&#30340;&#24046;&#24322;&#65292;&#36825;&#19982;&#20854;&#20182;&#20351;&#29992;&#21307;&#23398;&#32593;&#31449;&#25110;&#31185;&#23398;&#35770;&#25991;&#26816;&#32034;&#31572;&#26696;&#30340;&#21307;&#23398;QA&#20219;&#21153;&#26377;&#24456;&#22823;&#30340;&#19981;&#21516;&#65292;&#36825;&#20351;&#24471;&#30740;&#31350;EHR&#38382;&#39064;&#22238;&#31572;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#23545;&#29616;&#26377;&#20851;&#20110;EHR QA&#30340;&#20316;&#21697;&#36827;&#34892;&#26041;&#27861;&#35770;&#22238;&#39038;&#12290;&#25105;&#20204;&#22312;&#21253;&#25324;Google Scholar&#12289;ACL Anthology&#12289;ACM Digital Library&#21644;PubMed&#22312;&#20869;&#30340;&#22235;&#20010;&#25968;&#23383;&#36164;&#28304;&#20013;&#25628;&#32034;&#20102;&#20174;2005&#24180;1&#26376;1&#26085;&#21040;2023&#24180;9&#26376;30&#26085;&#30340;&#25991;&#31456;&#65292;&#20197;&#25910;&#38598;&#26377;&#20851;EHR QA&#30340;&#30456;&#20851;&#20986;&#29256;&#29289;&#12290;&#20849;&#21457;&#29616;&#20102;4111&#31687;&#35770;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;
Question Answering (QA) systems on patient-related data can assist both clinicians and patients. They can, for example, assist clinicians in decision-making and enable patients to have a better understanding of their medical history. Significant amounts of patient data are stored in Electronic Health Records (EHRs), making EHR QA an important research area. In EHR QA, the answer is obtained from the medical record of the patient. Because of the differences in data format and modality, this differs greatly from other medical QA tasks that employ medical websites or scientific papers to retrieve answers, making it critical to research EHR question answering. This study aimed to provide a methodological review of existing works on QA over EHRs. We searched for articles from January 1st, 2005 to September 30th, 2023 in four digital sources including Google Scholar, ACL Anthology, ACM Digital Library, and PubMed to collect relevant publications on EHR QA. 4111 papers were identified for our
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#32447;&#24615;&#24490;&#29615;&#21333;&#20803;&#65288;LRURec&#65289;&#12290;&#19982;&#24403;&#21069;&#30340;&#33258;&#27880;&#24847;&#27169;&#22411;&#30456;&#27604;&#65292;LRURec&#20855;&#26377;&#24555;&#36895;&#30340;&#25512;&#26029;&#36895;&#24230;&#12289;&#33021;&#22815;&#36827;&#34892;&#22686;&#37327;&#25512;&#26029;&#12289;&#26356;&#23567;&#30340;&#27169;&#22411;&#22823;&#23567;&#21644;&#21487;&#24182;&#34892;&#35757;&#32451;&#12290;&#36890;&#36807;&#20248;&#21270;&#26550;&#26500;&#24182;&#24341;&#20837;&#38750;&#32447;&#24615;&#65292;LRURec&#22312;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.02367</link><description>&lt;p&gt;
&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#32447;&#24615;&#24490;&#29615;&#21333;&#20803;
&lt;/p&gt;
&lt;p&gt;
Linear Recurrent Units for Sequential Recommendation. (arXiv:2310.02367v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02367
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#32447;&#24615;&#24490;&#29615;&#21333;&#20803;&#65288;LRURec&#65289;&#12290;&#19982;&#24403;&#21069;&#30340;&#33258;&#27880;&#24847;&#27169;&#22411;&#30456;&#27604;&#65292;LRURec&#20855;&#26377;&#24555;&#36895;&#30340;&#25512;&#26029;&#36895;&#24230;&#12289;&#33021;&#22815;&#36827;&#34892;&#22686;&#37327;&#25512;&#26029;&#12289;&#26356;&#23567;&#30340;&#27169;&#22411;&#22823;&#23567;&#21644;&#21487;&#24182;&#34892;&#35757;&#32451;&#12290;&#36890;&#36807;&#20248;&#21270;&#26550;&#26500;&#24182;&#24341;&#20837;&#38750;&#32447;&#24615;&#65292;LRURec&#22312;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#39034;&#24207;&#25512;&#33616;&#20381;&#36182;&#20110;&#22522;&#20110;&#33258;&#27880;&#24847;&#30340;&#25512;&#33616;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#35745;&#31639;&#20195;&#20215;&#39640;&#65292;&#24448;&#24448;&#23545;&#23454;&#26102;&#25512;&#33616;&#26469;&#35828;&#36807;&#20110;&#32531;&#24930;&#12290;&#27492;&#22806;&#65292;&#33258;&#27880;&#24847;&#25805;&#20316;&#26159;&#22312;&#24207;&#21015;&#23618;&#32423;&#19978;&#36827;&#34892;&#30340;&#65292;&#22240;&#27492;&#23545;&#20110;&#20302;&#25104;&#26412;&#30340;&#22686;&#37327;&#25512;&#26029;&#26469;&#35828;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#21463;&#21040;&#39640;&#25928;&#35821;&#35328;&#24314;&#27169;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#32447;&#24615;&#24490;&#29615;&#21333;&#20803;&#65288;LRURec&#65289;&#12290;&#31867;&#20284;&#20110;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65292;LRURec&#20855;&#26377;&#24555;&#36895;&#30340;&#25512;&#26029;&#36895;&#24230;&#65292;&#24182;&#19988;&#33021;&#22815;&#23545;&#39034;&#24207;&#36755;&#20837;&#36827;&#34892;&#22686;&#37327;&#25512;&#26029;&#12290;&#36890;&#36807;&#20998;&#35299;&#32447;&#24615;&#24490;&#29615;&#25805;&#20316;&#24182;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#35774;&#35745;&#36882;&#24402;&#24182;&#34892;&#21270;&#65292;LRURec&#25552;&#20379;&#20102;&#20943;&#23567;&#27169;&#22411;&#22823;&#23567;&#21644;&#21487;&#24182;&#34892;&#35757;&#32451;&#30340;&#39069;&#22806;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#26045;&#19968;&#31995;&#21015;&#20462;&#25913;&#26469;&#20248;&#21270;LRURec&#30340;&#26550;&#26500;&#65292;&#20197;&#35299;&#20915;&#32570;&#20047;&#38750;&#32447;&#24615;&#21644;&#25913;&#21892;&#35757;&#32451;&#21160;&#24577;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#25552;&#20986;&#30340;LRURec&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art sequential recommendation relies heavily on self-attention-based recommender models. Yet such models are computationally expensive and often too slow for real-time recommendation. Furthermore, the self-attention operation is performed at a sequence-level, thereby making low-cost incremental inference challenging. Inspired by recent advances in efficient language modeling, we propose linear recurrent units for sequential recommendation (LRURec). Similar to recurrent neural networks, LRURec offers rapid inference and can achieve incremental inference on sequential inputs. By decomposing the linear recurrence operation and designing recursive parallelization in our framework, LRURec provides the additional benefits of reduced model size and parallelizable training. Moreover, we optimize the architecture of LRURec by implementing a series of modifications to address the lack of non-linearity and improve training dynamics. To validate the effectiveness of our proposed LRURe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65288;KC&#65289;&#65292;&#36890;&#36807;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#26597;&#35810;&#20998;&#31867;&#24615;&#33021;&#65292;&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2308.01098</link><description>&lt;p&gt;
&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21033;&#29992;&#22810;&#19987;&#23478;&#30693;&#35782;&#33976;&#39311;&#23454;&#29616;&#26356;&#22909;&#30340;&#26597;&#35810;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search. (arXiv:2308.01098v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65288;KC&#65289;&#65292;&#36890;&#36807;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#26597;&#35810;&#20998;&#31867;&#24615;&#33021;&#65292;&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#20998;&#31867;&#20316;&#20026;&#29702;&#35299;&#29992;&#25143;&#24847;&#22270;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22312;&#32447;&#24191;&#21578;&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#20026;&#20102;&#30830;&#20445;&#26356;&#20302;&#30340;&#24310;&#36831;&#65292;&#24120;&#20351;&#29992;&#27973;&#23618;&#27169;&#22411;&#65288;&#22914;FastText&#65289;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;FastText&#27169;&#22411;&#30340;&#34920;&#24449;&#33021;&#21147;&#19981;&#36275;&#65292;&#23548;&#33268;&#20998;&#31867;&#24615;&#33021;&#36739;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#19968;&#20123;&#20302;&#39057;&#26597;&#35810;&#21644;&#23614;&#37096;&#31867;&#21035;&#19978;&#12290;&#20351;&#29992;&#26356;&#28145;&#20837;&#19988;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#65288;&#22914;BERT&#65289;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#23558;&#23548;&#33268;&#26356;&#39640;&#30340;&#22312;&#32447;&#25512;&#26029;&#24310;&#36831;&#21644;&#26356;&#26114;&#36149;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22240;&#27492;&#65292;&#22914;&#20309;&#22312;&#25512;&#26029;&#25928;&#29575;&#21644;&#20998;&#31867;&#24615;&#33021;&#20043;&#38388;&#25240;&#34935;&#26174;&#28982;&#20855;&#26377;&#37325;&#22823;&#23454;&#38469;&#24847;&#20041;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#30693;&#35782;&#33976;&#39311;&#65288;KC&#65289;&#65292;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65292;&#20197;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35757;&#32451;&#19968;&#20010;&#31163;&#32447;&#27169;&#22411;&#65292;&#36890;&#36807;&#33976;&#39311;&#30693;&#35782;&#26469;&#25913;&#21892;&#22312;&#32447;&#27169;&#22411;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Search query classification, as an effective way to understand user intents, is of great importance in real-world online ads systems. To ensure a lower latency, a shallow model (e.g. FastText) is widely used for efficient online inference. However, the representation ability of the FastText model is insufficient, resulting in poor classification performance, especially on some low-frequency queries and tailed categories. Using a deeper and more complex model (e.g. BERT) is an effective solution, but it will cause a higher online inference latency and more expensive computing costs. Thus, how to juggle both inference efficiency and classification performance is obviously of great practical importance. To overcome this challenge, in this paper, we propose knowledge condensation (KC), a simple yet effective knowledge distillation framework to boost the classification performance of the online FastText model under strict low latency constraints. Specifically, we propose to train an offline
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#65292;&#36890;&#36807;&#20174;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#30456;&#20284;&#26696;&#20363;&#24182;&#36873;&#25321;&#26368;&#31867;&#20284;&#30340;&#19978;&#19979;&#25991;&#26469;&#39044;&#27979;&#31572;&#26696;&#65292;&#20197;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#21644;&#26032;&#38395;&#38382;&#31572;&#20013;&#65292;CBR-MRC&#30340;&#20934;&#30830;&#24615;&#36229;&#36807;&#22522;&#20934;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#19982;&#20854;&#20182;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.14815</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Machine Reading Comprehension using Case-based Reasoning. (arXiv:2305.14815v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#65292;&#36890;&#36807;&#20174;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#30456;&#20284;&#26696;&#20363;&#24182;&#36873;&#25321;&#26368;&#31867;&#20284;&#30340;&#19978;&#19979;&#25991;&#26469;&#39044;&#27979;&#31572;&#26696;&#65292;&#20197;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#21644;&#26032;&#38395;&#38382;&#31572;&#20013;&#65292;CBR-MRC&#30340;&#20934;&#30830;&#24615;&#36229;&#36807;&#22522;&#20934;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#19982;&#20854;&#20182;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#30830;&#19988;&#21487;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20013;&#30340;&#31572;&#26696;&#25552;&#21462;&#65292;&#35813;&#26041;&#27861;&#31867;&#20284;&#20110;&#32463;&#20856;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#65288;CBR&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#22522;&#20110;&#19968;&#20010;&#20551;&#35774;&#65292;&#21363;&#30456;&#20284;&#38382;&#39064;&#30340;&#19978;&#19979;&#25991;&#21270;&#31572;&#26696;&#24444;&#27492;&#20043;&#38388;&#20855;&#26377;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#32473;&#23450;&#19968;&#20010;&#27979;&#35797;&#38382;&#39064;&#65292;CBR-MRC&#39318;&#20808;&#20174;&#38750;&#21442;&#25968;&#21270;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#19968;&#32452;&#30456;&#20284;&#30340;&#26696;&#20363;&#65292;&#28982;&#21518;&#36890;&#36807;&#36873;&#25321;&#27979;&#35797;&#19978;&#19979;&#25991;&#20013;&#26368;&#31867;&#20284;&#20110;&#26816;&#32034;&#21040;&#30340;&#26696;&#20363;&#20013;&#19978;&#19979;&#25991;&#21270;&#31572;&#26696;&#34920;&#31034;&#30340;&#33539;&#22260;&#26469;&#39044;&#27979;&#31572;&#26696;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21322;&#21442;&#25968;&#21270;&#30340;&#29305;&#24615;&#20351;&#20854;&#33021;&#22815;&#23558;&#39044;&#27979;&#24402;&#22240;&#20110;&#29305;&#23450;&#30340;&#35777;&#25454;&#26696;&#20363;&#38598;&#65292;&#22240;&#27492;&#22312;&#26500;&#24314;&#21487;&#38752;&#19988;&#21487;&#35843;&#35797;&#30340;&#38382;&#31572;&#31995;&#32479;&#26102;&#26159;&#19968;&#20010;&#29702;&#24819;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;CBR-MRC&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#65288;NaturalQuestions&#65289;&#21644;&#26032;&#38395;&#38382;&#31572;&#65288;NewsQA&#65289;&#19978;&#27604;&#22823;&#22411;&#35835;&#32773;&#27169;&#22411;&#25552;&#20379;&#20102;&#39640;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#20248;&#20110;&#22522;&#20934;&#20998;&#21035;&#25552;&#21319;&#20102;11.5&#21644;8.4 EM&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;CBR-MRC&#22312;&#35782;&#21035;&#19982;&#20182;&#20154;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an accurate and interpretable method for answer extraction in machine reading comprehension that is reminiscent of case-based reasoning (CBR) from classical AI. Our method (CBR-MRC) builds upon the hypothesis that contextualized answers to similar questions share semantic similarities with each other. Given a test question, CBR-MRC first retrieves a set of similar cases from a non-parametric memory and then predicts an answer by selecting the span in the test context that is most similar to the contextualized representations of answers in the retrieved cases. The semi-parametric nature of our approach allows it to attribute a prediction to the specific set of evidence cases, making it a desirable choice for building reliable and debuggable QA systems. We show that CBR-MRC provides high accuracy comparable with large reader models and outperforms baselines by 11.5 and 8.4 EM on NaturalQuestions and NewsQA, respectively. Further, we demonstrate the ability of CBR-MRC in identi
&lt;/p&gt;</description></item></channel></rss>