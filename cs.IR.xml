<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;DRAGIN&#65292;&#26088;&#22312;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#21160;&#24577;&#26816;&#32034;&#21644;&#29983;&#25104;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.10081</link><description>&lt;p&gt;
DRAGIN&#65306;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#26102;&#20449;&#24687;&#38656;&#27714;&#30340;&#21160;&#24577;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10081
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;DRAGIN&#65292;&#26088;&#22312;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#21160;&#24577;&#26816;&#32034;&#21644;&#29983;&#25104;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#33539;&#24335;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#20027;&#21160;&#20915;&#23450;&#20309;&#26102;&#20197;&#21450;&#20309;&#26102;&#26816;&#32034;&#12290;&#35813;&#33539;&#24335;&#30340;&#20004;&#20010;&#20851;&#38190;&#20803;&#32032;&#26159;&#30830;&#23450;&#28608;&#27963;&#26816;&#32034;&#27169;&#22359;&#30340;&#26368;&#20339;&#26102;&#26426;&#65288;&#20915;&#23450;&#20309;&#26102;&#26816;&#32034;&#65289;&#20197;&#21450;&#19968;&#26086;&#35302;&#21457;&#26816;&#32034;&#65292;&#21046;&#23450;&#36866;&#24403;&#30340;&#26597;&#35810;&#65288;&#30830;&#23450;&#35201;&#26816;&#32034;&#20160;&#20040;&#65289;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#21160;&#24577;RAG&#26041;&#27861;&#22312;&#20004;&#20010;&#26041;&#38754;&#37117;&#23384;&#22312;&#19981;&#36275;&#12290;&#39318;&#20808;&#65292;&#20915;&#23450;&#20309;&#26102;&#36827;&#34892;&#26816;&#32034;&#30340;&#31574;&#30053;&#36890;&#24120;&#20381;&#36182;&#20110;&#38745;&#24577;&#35268;&#21017;&#12290;&#27492;&#22806;&#65292;&#20915;&#23450;&#35201;&#26816;&#32034;&#20160;&#20040;&#30340;&#31574;&#30053;&#36890;&#24120;&#23616;&#38480;&#20110;LLM&#30340;&#26368;&#36817;&#19968;&#21477;&#25110;&#26368;&#21518;&#20960;&#20010;&#26631;&#35760;&#65292;&#32780;LLM&#30340;&#23454;&#26102;&#20449;&#24687;&#38656;&#27714;&#21487;&#33021;&#36328;&#36234;&#25972;&#20010;&#19978;&#19979;&#25991;&#12290;&#20026;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;DRAGIN&#65292; &#21363;&#22522;&#20110;LLMs&#23454;&#26102;&#20449;&#24687;&#38656;&#27714;&#30340;&#21160;&#24577;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10081v1 Announce Type: new  Abstract: Dynamic retrieval augmented generation (RAG) paradigm actively decides when and what to retrieve during the text generation process of Large Language Models (LLMs). There are two key elements of this paradigm: identifying the optimal moment to activate the retrieval module (deciding when to retrieve) and crafting the appropriate query once retrieval is triggered (determining what to retrieve). However, current dynamic RAG methods fall short in both aspects. Firstly, the strategies for deciding when to retrieve often rely on static rules. Moreover, the strategies for deciding what to retrieve typically limit themselves to the LLM's most recent sentence or the last few tokens, while the LLM's real-time information needs may span across the entire context. To overcome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic Retrieval Augmented Generation based on the real-time Information Needs of LLMs. Our framework is specif
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#65292;&#38024;&#23545;&#39135;&#35889;&#25991;&#26412;&#24320;&#21457;&#20102;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#31995;&#32479;&#30340;&#25968;&#25454;&#22788;&#29702;&#21644;&#20998;&#26512;&#65292;&#26500;&#24314;&#20102;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#26032;&#39135;&#35889;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2402.17447</link><description>&lt;p&gt;
&#39135;&#35889;&#30340;&#28145;&#24230;&#23398;&#20064;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Deep Learning Based Named Entity Recognition Models for Recipes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17447
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#65292;&#38024;&#23545;&#39135;&#35889;&#25991;&#26412;&#24320;&#21457;&#20102;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#31995;&#32479;&#30340;&#25968;&#25454;&#22788;&#29702;&#21644;&#20998;&#26512;&#65292;&#26500;&#24314;&#20102;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#26032;&#39135;&#35889;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39135;&#29289;&#36890;&#36807;&#21508;&#31181;&#21162;&#21147;&#26041;&#24335;&#24433;&#21709;&#30528;&#25105;&#20204;&#30340;&#29983;&#27963;&#65292;&#21253;&#25324;&#21475;&#21619;&#12289;&#33829;&#20859;&#12289;&#20581;&#24247;&#21644;&#21487;&#25345;&#32493;&#24615;&#12290;&#39135;&#35889;&#26159;&#36890;&#36807;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20195;&#20195;&#30456;&#20256;&#30340;&#25991;&#21270;&#33014;&#22218;&#12290;&#33258;&#21160;&#35782;&#21035;&#21629;&#21517;&#23454;&#20307;&#30340;&#21327;&#35758;&#65292;&#21363;&#39135;&#35889;&#25991;&#26412;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#65292;&#23545;&#20110;&#21508;&#31181;&#24212;&#29992;&#26469;&#35828;&#37117;&#20855;&#26377;&#24040;&#22823;&#20215;&#20540;&#65292;&#20174;&#20449;&#24687;&#25552;&#21462;&#21040;&#26032;&#39062;&#39135;&#35889;&#29983;&#25104;&#12290;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#26159;&#19968;&#31181;&#20174;&#24050;&#30693;&#26631;&#31614;&#30340;&#38750;&#32467;&#26500;&#21270;&#25110;&#21322;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#20174;&#25163;&#21160;&#27880;&#37322;&#30340;6,611&#20010;&#25104;&#20998;&#30701;&#35821;&#30340;&#25968;&#25454;&#24320;&#22987;&#65292;&#32047;&#31215;&#21019;&#24314;&#20102;26,445&#20010;&#30701;&#35821;&#30340;&#22686;&#24378;&#25968;&#25454;&#38598;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#28165;&#29702;&#21644;&#20998;&#26512;&#20102;&#26469;&#33258;RecipeDB&#30340;&#25104;&#20998;&#30701;&#35821;&#65292;&#36825;&#26159;&#40644;&#37329;&#26631;&#20934;&#30340;&#39135;&#35889;&#25968;&#25454;&#23384;&#20648;&#24211;&#65292;&#24182;&#20351;&#29992;Stanford NER&#36827;&#34892;&#20102;&#26631;&#27880;&#12290;&#22522;&#20110;&#20998;&#26512;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;&#23545;88,526&#20010;&#30701;&#35821;&#30340;&#23376;&#38598;&#36827;&#34892;&#20102;&#21462;&#26679;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17447v1 Announce Type: cross  Abstract: Food touches our lives through various endeavors, including flavor, nourishment, health, and sustainability. Recipes are cultural capsules transmitted across generations via unstructured text. Automated protocols for recognizing named entities, the building blocks of recipe text, are of immense value for various applications ranging from information extraction to novel recipe generation. Named entity recognition is a technique for extracting information from unstructured or semi-structured data with known labels. Starting with manually-annotated data of 6,611 ingredient phrases, we created an augmented dataset of 26,445 phrases cumulatively. Simultaneously, we systematically cleaned and analyzed ingredient phrases from RecipeDB, the gold-standard recipe data repository, and annotated them using the Stanford NER. Based on the analysis, we sampled a subset of 88,526 phrases using a clustering-based approach while preserving the diversity
&lt;/p&gt;</description></item><item><title>ListT5&#36890;&#36807;Fusion-in-Decoder&#25216;&#26415;&#23454;&#29616;&#21015;&#34920;&#37325;&#25490;&#65292;&#22312;&#38646;-shot&#26816;&#32034;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#25928;&#29575;&#39640;&#20110;&#20043;&#21069;&#30340;&#27169;&#22411;&#65292;&#24182;&#35299;&#20915;&#20102;&#20197;&#24448;&#21015;&#34920;&#37325;&#25490;&#22120;&#30340;&#20013;&#38388;&#27573;&#20002;&#22833;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.15838</link><description>&lt;p&gt;
ListT5: &#22522;&#20110;&#35299;&#30721;&#22120;&#20869;&#34701;&#21512;&#30340;&#21015;&#34920;&#37325;&#25490;&#26041;&#27861;&#25913;&#21892;&#38646;-shot&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15838
&lt;/p&gt;
&lt;p&gt;
ListT5&#36890;&#36807;Fusion-in-Decoder&#25216;&#26415;&#23454;&#29616;&#21015;&#34920;&#37325;&#25490;&#65292;&#22312;&#38646;-shot&#26816;&#32034;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#25928;&#29575;&#39640;&#20110;&#20043;&#21069;&#30340;&#27169;&#22411;&#65292;&#24182;&#35299;&#20915;&#20102;&#20197;&#24448;&#21015;&#34920;&#37325;&#25490;&#22120;&#30340;&#20013;&#38388;&#27573;&#20002;&#22833;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ListT5&#65292;&#19968;&#31181;&#22522;&#20110;&#22312;&#35757;&#32451;&#21644;&#25512;&#26029;&#26102;&#22788;&#29702;&#22810;&#20010;&#20505;&#36873;&#27573;&#33853;&#30340;Fusion-in-Decoder&#65288;FiD&#65289;&#30340;&#26032;&#22411;&#37325;&#25490;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;m&#20803;&#38182;&#26631;&#36187;&#25490;&#24207;&#21644;&#36755;&#20986;&#32531;&#23384;&#30340;&#21015;&#34920;&#25490;&#24207;&#30340;&#39640;&#25928;&#25512;&#26029;&#26694;&#26550;&#12290;&#25105;&#20204;&#22312;BEIR&#22522;&#20934;&#19978;&#35780;&#20272;&#21644;&#27604;&#36739;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#35777;&#26126;&#20102;ListT5&#65288;1&#65289;&#22312;&#24179;&#22343;NDCG@10&#24471;&#20998;&#19978;&#27604;&#26368;&#20808;&#36827;&#30340;RankT5&#22522;&#32447;&#34920;&#29616;&#20986;&#26126;&#26174;&#30340;+1.3&#22686;&#30410;&#65292;&#65288;2&#65289;&#20855;&#26377;&#19982;&#36880;&#28857;&#25490;&#21517;&#27169;&#22411;&#21487;&#27604;&#25311;&#30340;&#25928;&#29575;&#65292;&#24182;&#36229;&#36234;&#20197;&#21069;&#30340;&#21015;&#34920;&#25490;&#24207;&#27169;&#22411;&#30340;&#25928;&#29575;&#65292;&#65288;3&#65289;&#20811;&#26381;&#20102;&#20197;&#21069;&#21015;&#34920;&#37325;&#25490;&#22120;&#30340;&#20013;&#38388;&#27573;&#20002;&#22833;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#12289;&#27169;&#22411;&#26816;&#26597;&#28857;&#21644;&#35780;&#20272;&#26694;&#26550;&#23436;&#20840;&#24320;&#28304;&#22312; \url{https://github.com/soyoung97/ListT5}&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15838v1 Announce Type: new  Abstract: We propose ListT5, a novel reranking approach based on Fusion-in-Decoder (FiD) that handles multiple candidate passages at both train and inference time. We also introduce an efficient inference framework for listwise ranking based on m-ary tournament sort with output caching. We evaluate and compare our model on the BEIR benchmark for zero-shot retrieval task, demonstrating that ListT5 (1) outperforms the state-of-the-art RankT5 baseline with a notable +1.3 gain in the average NDCG@10 score, (2) has an efficiency comparable to pointwise ranking models and surpasses the efficiency of previous listwise ranking models, and (3) overcomes the lost-in-the-middle problem of previous listwise rerankers. Our code, model checkpoints, and the evaluation framework are fully open-sourced at \url{https://github.com/soyoung97/ListT5}.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#21487;&#32553;&#25918;&#25512;&#33616;&#27169;&#22411;&#20013;&#23884;&#20837;&#23618;&#30340;&#23849;&#28291;&#29616;&#35937;&#65292;&#21457;&#29616;&#29305;&#24449;&#20132;&#20114;&#27169;&#22359;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#38480;&#21046;&#20102;&#23884;&#20837;&#23398;&#20064;&#65292;&#20294;&#20063;&#26159;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2310.04400</link><description>&lt;p&gt;
&#35770;&#21487;&#25193;&#23637;&#25512;&#33616;&#27169;&#22411;&#20013;&#23884;&#20837;&#22349;&#32553;&#29616;&#35937;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Embedding Collapse when Scaling up Recommendation Models. (arXiv:2310.04400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04400
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#21487;&#32553;&#25918;&#25512;&#33616;&#27169;&#22411;&#20013;&#23884;&#20837;&#23618;&#30340;&#23849;&#28291;&#29616;&#35937;&#65292;&#21457;&#29616;&#29305;&#24449;&#20132;&#20114;&#27169;&#22359;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#38480;&#21046;&#20102;&#23884;&#20837;&#23398;&#20064;&#65292;&#20294;&#20063;&#26159;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#22522;&#30784;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#24341;&#21457;&#20102;&#24320;&#21457;&#22823;&#22411;&#25512;&#33616;&#27169;&#22411;&#20197;&#21033;&#29992;&#22823;&#37327;&#21487;&#29992;&#25968;&#25454;&#30340;&#26377;&#21069;&#26223;&#36235;&#21183;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35797;&#39564;&#25918;&#22823;&#29616;&#26377;&#30340;&#25512;&#33616;&#27169;&#22411;&#26102;&#21457;&#29616;&#65292;&#25193;&#22823;&#30340;&#27169;&#22411;&#24182;&#27809;&#26377;&#20196;&#20154;&#28385;&#24847;&#30340;&#25913;&#36827;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25193;&#22823;&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#31181;&#23884;&#20837;&#22349;&#32553;&#29616;&#35937;&#65292;&#36825;&#26368;&#32456;&#38459;&#30861;&#20102;&#21487;&#25193;&#23637;&#24615;&#65292;&#22312;&#36825;&#31181;&#29616;&#35937;&#20013;&#65292;&#23884;&#20837;&#30697;&#38453;&#20542;&#21521;&#20110;&#23384;&#22312;&#20110;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25512;&#33616;&#27169;&#22411;&#29305;&#23450;&#30340;&#29305;&#24449;&#20132;&#20114;&#27169;&#22359;&#20855;&#26377;&#21452;&#37325;&#20316;&#29992;&#12290;&#19968;&#26041;&#38754;&#65292;&#24403;&#19982;&#22349;&#32553;&#30340;&#23884;&#20837;&#20132;&#20114;&#26102;&#65292;&#35813;&#20132;&#20114;&#38480;&#21046;&#20102;&#23884;&#20837;&#23398;&#20064;&#65292;&#21152;&#21095;&#20102;&#23849;&#28291;&#38382;&#39064;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#29305;&#24449;&#20132;&#20114;&#23545;&#20110;&#32531;&#35299;&#20551;&#29305;&#24449;&#30340;&#25311;&#21512;&#33267;&#20851;&#37325;&#35201;&#65292;&#20174;&#32780;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;&#22522;&#20110;&#36825;&#19968;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Recent advances in deep foundation models have led to a promising trend of developing large recommendation models to leverage vast amounts of available data. However, we experiment to scale up existing recommendation models and observe that the enlarged models do not improve satisfactorily. In this context, we investigate the embedding layers of enlarged models and identify a phenomenon of embedding collapse, which ultimately hinders scalability, wherein the embedding matrix tends to reside in a low-dimensional subspace. Through empirical and theoretical analysis, we demonstrate that the feature interaction module specific to recommendation models has a two-sided effect. On the one hand, the interaction restricts embedding learning when interacting with collapsed embeddings, exacerbating the collapse issue. On the other hand, feature interaction is crucial in mitigating the fitting of spurious features, thereby improving scalability. Based on this analysis, we propose a simple yet effe
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#24050;&#24314;&#31435;&#30340;&#27880;&#37322;&#32534;&#30721;&#26412;&#30340;&#30693;&#35782;&#65292;&#25506;&#32034;&#38646;&#26679;&#26412;&#26041;&#27861;&#29992;&#20110;&#25919;&#27835;&#20107;&#20214;&#26412;&#20307;&#20851;&#31995;&#20998;&#31867;&#65292;&#24182;&#20171;&#32461;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#21517;&#20026;ZSP&#12290;ZSP&#37319;&#29992;&#20102;&#19968;&#31181;&#26641;&#26597;&#35810;&#26694;&#26550;&#65292;&#25552;&#39640;&#20102;&#35299;&#37322;&#24615;&#12289;&#25928;&#29575;&#21644;&#23545;&#27169;&#24335;&#26356;&#25913;&#30340;&#36866;&#24212;&#24615;&#12290;&#22312;&#32454;&#31890;&#24230;&#26681;&#20195;&#30721;&#20998;&#31867;&#19978;&#65292;ZSP&#30340;&#24615;&#33021;&#26126;&#26174;&#20248;&#20110;ChatGPT&#65292;F1&#24471;&#20998;&#25552;&#39640;&#20102;40%&#12290;</title><link>http://arxiv.org/abs/2308.07876</link><description>&lt;p&gt;
&#36890;&#36807;&#32534;&#30721;&#26412;&#30693;&#35782;&#12289;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#21644;ChatGPT&#26469;&#21512;&#25104;&#25919;&#27835;&#38646;&#26679;&#26412;&#20851;&#31995;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT. (arXiv:2308.07876v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07876
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#24050;&#24314;&#31435;&#30340;&#27880;&#37322;&#32534;&#30721;&#26412;&#30340;&#30693;&#35782;&#65292;&#25506;&#32034;&#38646;&#26679;&#26412;&#26041;&#27861;&#29992;&#20110;&#25919;&#27835;&#20107;&#20214;&#26412;&#20307;&#20851;&#31995;&#20998;&#31867;&#65292;&#24182;&#20171;&#32461;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#21517;&#20026;ZSP&#12290;ZSP&#37319;&#29992;&#20102;&#19968;&#31181;&#26641;&#26597;&#35810;&#26694;&#26550;&#65292;&#25552;&#39640;&#20102;&#35299;&#37322;&#24615;&#12289;&#25928;&#29575;&#21644;&#23545;&#27169;&#24335;&#26356;&#25913;&#30340;&#36866;&#24212;&#24615;&#12290;&#22312;&#32454;&#31890;&#24230;&#26681;&#20195;&#30721;&#20998;&#31867;&#19978;&#65292;ZSP&#30340;&#24615;&#33021;&#26126;&#26174;&#20248;&#20110;ChatGPT&#65292;F1&#24471;&#20998;&#25552;&#39640;&#20102;40%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#20107;&#20214;&#32534;&#30721;&#30340;&#30417;&#30563;&#27169;&#22411;&#22312;&#24615;&#33021;&#26041;&#38754;&#36828;&#36828;&#36229;&#36807;&#27169;&#24335;&#21305;&#37197;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#20165;&#20165;&#20381;&#36182;&#20110;&#26032;&#30340;&#27880;&#37322;&#65292;&#24573;&#35270;&#20102;&#19987;&#23478;&#25968;&#25454;&#24211;&#20013;&#30340;&#22823;&#37327;&#30693;&#35782;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#32454;&#31890;&#24230;&#20998;&#31867;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#24050;&#24314;&#31435;&#30340;&#27880;&#37322;&#32534;&#30721;&#26412;&#30340;&#30693;&#35782;&#65292;&#25506;&#32034;&#38646;&#26679;&#26412;&#26041;&#27861;&#29992;&#20110;&#25919;&#27835;&#20107;&#20214;&#26412;&#20307;&#20851;&#31995;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#28085;&#30422;&#20102;ChatGPT&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#21517;&#20026;ZSP&#12290;ZSP&#37319;&#29992;&#20102;&#19968;&#31181;&#26641;&#26597;&#35810;&#26694;&#26550;&#65292;&#23558;&#20219;&#21153;&#20998;&#35299;&#20026;&#19978;&#19979;&#25991;&#12289;&#35821;&#24577;&#21644;&#31867;&#21035;&#28040;&#27495;&#30340;&#19981;&#21516;&#23618;&#27425;&#12290;&#35813;&#26694;&#26550;&#25552;&#39640;&#20102;&#35299;&#37322;&#24615;&#12289;&#25928;&#29575;&#21644;&#23545;&#27169;&#24335;&#26356;&#25913;&#30340;&#36866;&#24212;&#24615;&#12290;&#36890;&#36807;&#22312;&#25105;&#20204;&#26032;&#31574;&#21010;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#25351;&#20986;&#20102;ChatGPT&#20013;&#30340;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#31361;&#20986;&#20102;ZSP&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;ZSP&#22312;&#32454;&#31890;&#24230;&#26681;&#20195;&#30721;&#20998;&#31867;&#30340;F1&#24471;&#20998;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25552;&#39640;40%&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent supervised models for event coding vastly outperform pattern-matching methods. However, their reliance solely on new annotations disregards the vast knowledge within expert databases, hindering their applicability to fine-grained classification. To address these limitations, we explore zero-shot approaches for political event ontology relation classification, by leveraging knowledge from established annotation codebooks. Our study encompasses both ChatGPT and a novel natural language inference (NLI) based approach named ZSP. ZSP adopts a tree-query framework that deconstructs the task into context, modality, and class disambiguation levels. This framework improves interpretability, efficiency, and adaptability to schema changes. By conducting extensive experiments on our newly curated datasets, we pinpoint the instability issues within ChatGPT and highlight the superior performance of ZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained Rootcode classific
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26412;&#22320;&#26032;&#38395;&#26816;&#27979;&#21644;&#22522;&#20110;&#20869;&#23481;&#30340;&#26412;&#22320;&#26032;&#38395;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#24369;&#30417;&#30563;&#26694;&#26550;&#21644;&#33258;&#21160;&#21270;&#25968;&#25454;&#22788;&#29702;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#35206;&#30422;&#29575;&#12290;</title><link>http://arxiv.org/abs/2301.08146</link><description>&lt;p&gt;
&#20320;&#25152;&#22312;&#31038;&#21306;&#21457;&#29983;&#20102;&#20160;&#20040;&#65311;&#19968;&#31181;&#24369;&#30417;&#30563;&#26041;&#27861;&#29992;&#20110;&#21457;&#29616;&#26412;&#22320;&#26032;&#38395;&#12290;
&lt;/p&gt;
&lt;p&gt;
What's happening in your neighborhood? A Weakly Supervised Approach to Detect Local News. (arXiv:2301.08146v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08146
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26412;&#22320;&#26032;&#38395;&#26816;&#27979;&#21644;&#22522;&#20110;&#20869;&#23481;&#30340;&#26412;&#22320;&#26032;&#38395;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#24369;&#30417;&#30563;&#26694;&#26550;&#21644;&#33258;&#21160;&#21270;&#25968;&#25454;&#22788;&#29702;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#22320;&#26032;&#38395;&#26159;&#24433;&#21709;&#29305;&#23450;&#22320;&#29702;&#21306;&#22495;&#65288;&#22914;&#22478;&#24066;&#12289;&#21439;&#21644;&#24030;&#65289;&#29992;&#25143;&#30340;&#26032;&#38395;&#23376;&#38598;&#12290;&#26816;&#27979;&#26412;&#22320;&#26032;&#38395;&#26159;&#20934;&#30830;&#22320;&#25512;&#33616;&#26412;&#22320;&#26032;&#38395;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#22522;&#20110;&#26368;&#26032;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#38598;&#25104;&#21270;&#30340;&#27969;&#31243;&#65292;&#23454;&#29616;&#20102;&#33258;&#21160;&#21270;&#26412;&#22320;&#26032;&#38395;&#26816;&#27979;&#21644;&#22522;&#20110;&#20869;&#23481;&#30340;&#26412;&#22320;&#26032;&#38395;&#25512;&#33616;&#12290;&#26412;&#25991;&#30528;&#37325;&#20171;&#32461;&#20102;&#31649;&#36947;&#30340;&#31532;&#19968;&#27493;&#39588;&#65306;&#65288;1&#65289;&#32467;&#21512;&#39046;&#22495;&#30693;&#35782;&#21644;&#33258;&#21160;&#25968;&#25454;&#22788;&#29702;&#30340;&#24369;&#30417;&#30563;&#26694;&#26550;&#65292;&#65288;2&#65289;&#21487;&#25193;&#23637;&#21040;&#22810;&#35821;&#35328;&#35774;&#32622;&#12290;&#19982;&#26031;&#22374;&#31119;CoreNLP NER&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#27969;&#31243;&#22312;&#32463;&#36807;&#30495;&#23454;&#19990;&#30028;&#21644;&#20154;&#24037;&#26631;&#35760;&#25968;&#25454;&#30340;&#35780;&#20272;&#26102;&#20855;&#26377;&#26356;&#39640;&#30340;&#31934;&#24230;&#21644;&#21484;&#22238;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Local news articles are a subset of news that impact users in a geographical area, such as a city, county, or state. Detecting local news (Step 1) and subsequently deciding its geographical location as well as radius of impact (Step 2) are two important steps towards accurate local news recommendation. Naive rule-based methods, such as detecting city names from the news title, tend to give erroneous results due to lack of understanding of the news content. Empowered by the latest development in natural language processing, we develop an integrated pipeline that enables automatic local news detection and content-based local news recommendations. In this paper, we focus on Step 1 of the pipeline, which highlights: (1) a weakly supervised framework incorporated with domain knowledge and auto data processing, and (2) scalability to multi-lingual settings. Compared with Stanford CoreNLP NER model, our pipeline has higher precision and recall evaluated on a real-world and human-labeled datas
&lt;/p&gt;</description></item></channel></rss>