<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#34701;&#21512;&#22810;&#27169;&#24577;&#20449;&#24687;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#20013;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#22270;&#34920;&#31034;&#29992;&#25143;&#30340;&#21382;&#21490;&#35760;&#24405;&#65292;&#36890;&#36807;&#33410;&#28857;&#38388;&#30340;&#36830;&#25509;&#26469;&#34920;&#24449;&#21508;&#20010;&#29289;&#21697;&#30340;&#27169;&#24577;&#29305;&#24449;&#12290;&#36890;&#36807;&#24341;&#20837;&#21452;&#37325;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#23545;&#21516;&#36136;&#21644;&#24322;&#36136;&#37051;&#23621;&#30340;&#21306;&#20998;&#65292;&#24182;&#36890;&#36807;&#22270;&#20256;&#25773;&#36807;&#31243;&#26469;&#33258;&#36866;&#24212;&#22320;&#35843;&#25972;&#33410;&#28857;&#30340;&#34701;&#21512;&#39034;&#24207;&#12290;</title><link>http://arxiv.org/abs/2308.15980</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#22810;&#27169;&#24577;&#34701;&#21512;&#22312;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#20013;
&lt;/p&gt;
&lt;p&gt;
Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems. (arXiv:2308.15980v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15980
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#34701;&#21512;&#22810;&#27169;&#24577;&#20449;&#24687;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#20013;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#22270;&#34920;&#31034;&#29992;&#25143;&#30340;&#21382;&#21490;&#35760;&#24405;&#65292;&#36890;&#36807;&#33410;&#28857;&#38388;&#30340;&#36830;&#25509;&#26469;&#34920;&#24449;&#21508;&#20010;&#29289;&#21697;&#30340;&#27169;&#24577;&#29305;&#24449;&#12290;&#36890;&#36807;&#24341;&#20837;&#21452;&#37325;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#23545;&#21516;&#36136;&#21644;&#24322;&#36136;&#37051;&#23621;&#30340;&#21306;&#20998;&#65292;&#24182;&#36890;&#36807;&#22270;&#20256;&#25773;&#36807;&#31243;&#26469;&#33258;&#36866;&#24212;&#22320;&#35843;&#25972;&#33410;&#28857;&#30340;&#34701;&#21512;&#39034;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39034;&#24207;&#25512;&#33616;&#20013;&#65292;&#22810;&#27169;&#24577;&#20449;&#24687;&#65288;&#22914;&#25991;&#26412;&#25110;&#22270;&#20687;&#65289;&#21487;&#20197;&#25552;&#20379;&#23545;&#29289;&#21697;&#29305;&#24449;&#26356;&#20840;&#38754;&#30340;&#35266;&#28857;&#12290;&#23558;&#27169;&#24577;&#29305;&#24449;&#34701;&#20837;&#29289;&#21697;&#34920;&#31034;&#30340;&#26368;&#20339;&#38454;&#27573;&#65288;&#26089;&#26399;&#25110;&#26202;&#26399;&#65289;&#20173;&#23384;&#22312;&#20105;&#35758;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#30340;&#26041;&#27861;&#65288;&#21517;&#20026;MMSR&#65289;&#65292;&#20197;&#33258;&#36866;&#24212;&#39034;&#24207;&#34701;&#21512;&#27169;&#24577;&#29305;&#24449;&#65292;&#20351;&#27599;&#20010;&#27169;&#24577;&#21487;&#20197;&#20248;&#20808;&#32771;&#34385;&#20854;&#22266;&#26377;&#30340;&#39034;&#24207;&#29305;&#24615;&#25110;&#20854;&#19982;&#20854;&#20182;&#27169;&#24577;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;MMSR&#23558;&#27599;&#20010;&#29992;&#25143;&#30340;&#21382;&#21490;&#35760;&#24405;&#34920;&#31034;&#20026;&#19968;&#20010;&#22270;&#65292;&#20854;&#20013;&#29992;&#25143;&#21382;&#21490;&#24207;&#21015;&#20013;&#27599;&#20010;&#29289;&#21697;&#30340;&#27169;&#24577;&#29305;&#24449;&#30001;&#20114;&#30456;&#20851;&#32852;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;&#21516;&#36136;&#33410;&#28857;&#20043;&#38388;&#30340;&#36793;&#34920;&#31034;&#20869;&#37096;&#27169;&#24577;&#30340;&#39034;&#24207;&#20851;&#31995;&#65292;&#24322;&#36136;&#33410;&#28857;&#20043;&#38388;&#30340;&#36793;&#34920;&#31034;&#27169;&#24577;&#20043;&#38388;&#30340;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#12290;&#22312;&#22270;&#20256;&#25773;&#36807;&#31243;&#20013;&#65292;MMSR&#20351;&#29992;&#21452;&#37325;&#27880;&#24847;&#21147;&#21306;&#21035;&#23545;&#24453;&#21516;&#36136;&#21644;&#24322;&#36136;&#37051;&#23621;&#12290;&#20026;&#20102;&#33258;&#36866;&#24212;&#22320;&#20998;&#37197;&#20855;&#26377;&#19981;&#21516;&#34701;&#21512;&#39034;&#24207;&#30340;&#33410;&#28857;&#65292;MMSR&#20801;&#35768;&#27599;&#20010;&#33410;&#28857;&#30340;&#34920;&#31034;&#36866;&#24212;&#24615;&#22320;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
In sequential recommendation, multi-modal information (e.g., text or image) can provide a more comprehensive view of an item's profile. The optimal stage (early or late) to fuse modality features into item representations is still debated. We propose a graph-based approach (named MMSR) to fuse modality features in an adaptive order, enabling each modality to prioritize either its inherent sequential nature or its interplay with other modalities. MMSR represents each user's history as a graph, where the modality features of each item in a user's history sequence are denoted by cross-linked nodes. The edges between homogeneous nodes represent intra-modality sequential relationships, and the ones between heterogeneous nodes represent inter-modality interdependence relationships. During graph propagation, MMSR incorporates dual attention, differentiating homogeneous and heterogeneous neighbors. To adaptively assign nodes with distinct fusion orders, MMSR allows each node's representation t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#22122;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#25628;&#32034;&#20013;&#30340;&#26597;&#35810;&#24863;&#30693;&#29992;&#25143;&#24314;&#27169;&#65292;&#36890;&#36807;&#35299;&#20915;&#26631;&#20934;&#27880;&#24847;&#21147;&#20844;&#24335;&#30340;&#32570;&#28857;&#26469;&#25552;&#39640;&#20010;&#24615;&#21270;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.15968</link><description>&lt;p&gt;
&#22312;&#20010;&#24615;&#21270;&#25628;&#32034;&#20013;&#21435;&#22122;&#27880;&#24847;&#21147;&#20197;&#23454;&#29616;&#26597;&#35810;&#24863;&#30693;&#29992;&#25143;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Denoising Attention for Query-aware User Modeling in Personalized Search. (arXiv:2308.15968v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#22122;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#25628;&#32034;&#20013;&#30340;&#26597;&#35810;&#24863;&#30693;&#29992;&#25143;&#24314;&#27169;&#65292;&#36890;&#36807;&#35299;&#20915;&#26631;&#20934;&#27880;&#24847;&#21147;&#20844;&#24335;&#30340;&#32570;&#28857;&#26469;&#25552;&#39640;&#20010;&#24615;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#24212;&#29992;&#20197;&#21450;&#22312;&#35768;&#22810;&#25628;&#32034;&#22330;&#26223;&#20013;&#30340;&#20010;&#24615;&#21270;&#37325;&#35201;&#24615;&#65292;&#20010;&#24615;&#21270;&#25628;&#32034;&#32467;&#26524;&#30340;&#20010;&#24615;&#21270;&#21463;&#21040;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#36890;&#36807;&#21033;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#26597;&#35810;&#26102;&#38388;&#26500;&#24314;&#29992;&#25143;&#27169;&#22411;&#65292;&#36825;&#26679;&#21487;&#20197;&#26681;&#25454;&#24403;&#21069;&#26597;&#35810;&#30340;&#30456;&#20851;&#24615;&#26435;&#34913;&#29992;&#25143;&#30456;&#20851;&#20449;&#24687;&#30340;&#36129;&#29486;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#32473;&#20104;&#19982;&#29992;&#25143;&#24403;&#21069;&#25628;&#32034;&#30456;&#20851;&#30340;&#20852;&#36259;&#26356;&#22810;&#30340;&#37325;&#35201;&#24615;&#26469;&#32771;&#34385;&#29992;&#25143;&#20852;&#36259;&#30340;&#22810;&#26679;&#24615;&#12290;&#26412;&#25991;&#39318;&#20808;&#35752;&#35770;&#20102;&#26631;&#20934;&#27880;&#24847;&#21147;&#20844;&#24335;&#22312;&#20010;&#24615;&#21270;&#26041;&#38754;&#30340;&#19968;&#20123;&#32570;&#28857;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20851;&#27880;&#20854;&#24402;&#19968;&#21270;&#26426;&#21046;&#21644;&#20854;&#19981;&#33021;&#23436;&#20840;&#36807;&#28388;&#25481;&#22024;&#26434;&#30340;&#29992;&#25143;&#30456;&#20851;&#20449;&#24687;&#30340;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#21435;&#22122;&#27880;&#24847;&#21147;&#26426;&#21046;&#65306;&#19968;&#31181;&#27880;&#24847;&#21147;&#30340;&#21464;&#20307;&#65292;&#30452;&#25509;&#35299;&#20915;&#20102;&#20197;&#19978;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The personalization of search results has gained increasing attention in the past few years, thanks to the development of Neural Networks-based approaches for Information Retrieval and the importance of personalization in many search scenarios. Recent works have proposed to build user models at query time by leveraging the Attention mechanism, which allows weighing the contribution of the user-related information w.r.t. the current query. This approach allows taking into account the diversity of the user's interests by giving more importance to those related to the current search performed by the user.  In this paper, we first discuss some shortcomings of the standard Attention formulation when employed for personalization. In particular, we focus on issues related to its normalization mechanism and its inability to entirely filter out noisy user-related information. Then, we introduce the Denoising Attention mechanism: an Attention variant that directly tackles the above shortcomings 
&lt;/p&gt;</description></item><item><title>DRGame&#26159;&#19968;&#20010;&#20197;&#24179;&#34913;&#38544;&#21547;&#20559;&#22909;&#20026;&#22522;&#30784;&#30340;&#22810;&#31867;&#21035;&#35270;&#39057;&#28216;&#25103;&#22810;&#26679;&#21270;&#25512;&#33616;&#26694;&#26550;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#27169;&#22411;&#22312;&#22788;&#29702;&#39640;&#24230;&#19981;&#24179;&#34913;&#30340;&#38544;&#21547;&#21453;&#39304;&#21644;&#32771;&#34385;&#22810;&#20010;&#31867;&#21035;&#29305;&#24449;&#26102;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.15823</link><description>&lt;p&gt;
DRGame: &#20197;&#24179;&#34913;&#38544;&#21547;&#20559;&#22909;&#20026;&#22522;&#30784;&#30340;&#22810;&#31867;&#21035;&#35270;&#39057;&#28216;&#25103;&#22810;&#26679;&#21270;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
DRGame: Diversified Recommendation for Multi-category Video Games with Balanced Implicit Preferences. (arXiv:2308.15823v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15823
&lt;/p&gt;
&lt;p&gt;
DRGame&#26159;&#19968;&#20010;&#20197;&#24179;&#34913;&#38544;&#21547;&#20559;&#22909;&#20026;&#22522;&#30784;&#30340;&#22810;&#31867;&#21035;&#35270;&#39057;&#28216;&#25103;&#22810;&#26679;&#21270;&#25512;&#33616;&#26694;&#26550;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#27169;&#22411;&#22312;&#22788;&#29702;&#39640;&#24230;&#19981;&#24179;&#34913;&#30340;&#38544;&#21547;&#21453;&#39304;&#21644;&#32771;&#34385;&#22810;&#20010;&#31867;&#21035;&#29305;&#24449;&#26102;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35746;&#38405;&#26381;&#21153;&#22312;&#35270;&#39057;&#28216;&#25103;&#28040;&#36153;&#20013;&#30340;&#26085;&#30410;&#26222;&#21450;&#24378;&#35843;&#20102;&#25552;&#20379;&#22810;&#26679;&#21270;&#25512;&#33616;&#30340;&#37325;&#35201;&#24615;&#12290;&#20026;&#29992;&#25143;&#25552;&#20379;&#22810;&#26679;&#21270;&#30340;&#28216;&#25103;&#33539;&#22260;&#23545;&#20110;&#20445;&#25345;&#25345;&#32493;&#21442;&#19982;&#21644;&#22521;&#20859;&#38271;&#26399;&#35746;&#38405;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25512;&#33616;&#27169;&#22411;&#22312;&#26377;&#25928;&#22788;&#29702;&#39640;&#24230;&#19981;&#24179;&#34913;&#30340;&#28216;&#25103;&#20132;&#20114;&#20013;&#30340;&#38544;&#21547;&#21453;&#39304;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#21478;&#22806;&#65292;&#23427;&#20204;&#36824;&#38590;&#20197;&#32771;&#34385;&#21040;&#22810;&#20010;&#31867;&#21035;&#30340;&#29420;&#29305;&#29305;&#24449;&#21644;&#19982;&#36825;&#20123;&#31867;&#21035;&#30456;&#20851;&#32852;&#30340;&#28508;&#22312;&#29992;&#25143;&#20852;&#36259;&#12290;&#38024;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DRGame&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#33719;&#24471;&#22810;&#26679;&#21270;&#30340;&#25512;&#33616;&#12290;&#23427;&#20197;&#22810;&#31867;&#21035;&#35270;&#39057;&#28216;&#25103;&#20026;&#20013;&#24515;&#65292;&#21253;&#25324;&#20004;&#20010;&#32452;&#20214;&#65306;&#20197;&#24179;&#34913;&#39537;&#21160;&#30340;&#38544;&#21547;&#20559;&#22909;&#23398;&#20064;&#20026;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#22522;&#20110;&#32858;&#31867;&#30340;&#22810;&#26679;&#21270;&#25512;&#33616;&#27169;&#22359;&#23454;&#29616;&#26368;&#32456;&#39044;&#27979;&#12290;&#31532;&#19968;&#20010;&#27169;&#22359;&#26088;&#22312;&#23454;&#29616;&#38544;&#21547;&#36153;&#29992;&#30340;&#24179;&#34913;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
The growing popularity of subscription services in video game consumption has emphasized the importance of offering diversified recommendations. Providing users with a diverse range of games is essential for ensuring continued engagement and fostering long-term subscriptions. However, existing recommendation models face challenges in effectively handling highly imbalanced implicit feedback in gaming interactions. Additionally, they struggle to take into account the distinctive characteristics of multiple categories and the latent user interests associated with these categories. In response to these challenges, we propose a novel framework, named DRGame, to obtain diversified recommendation. It is centered on multi-category video games, consisting of two {components}: Balance-driven Implicit Preferences Learning for data pre-processing and Clustering-based Diversified Recommendation {Module} for final prediction. The first module aims to achieve a balanced representation of implicit fee
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#33258;&#28982;&#35821;&#35328;&#21487;&#35299;&#37322;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;-&#29289;&#21697;&#29305;&#24449;&#20135;&#29983;&#22522;&#20110;&#20107;&#23454;&#30340;&#20010;&#24615;&#21270;&#35299;&#37322;&#65292;&#21516;&#26102;&#36827;&#34892;&#32852;&#21512;&#23398;&#20064;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#35299;&#37322;&#33021;&#21147;&#21644;&#29992;&#25143;&#30340;&#20449;&#24515;&#21644;&#20449;&#20219;&#12290;</title><link>http://arxiv.org/abs/2308.15813</link><description>&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#30340;&#33258;&#28982;&#35821;&#35328;&#25512;&#33616;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Knowledge-grounded Natural Language Recommendation Explanation. (arXiv:2308.15813v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#33258;&#28982;&#35821;&#35328;&#21487;&#35299;&#37322;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;-&#29289;&#21697;&#29305;&#24449;&#20135;&#29983;&#22522;&#20110;&#20107;&#23454;&#30340;&#20010;&#24615;&#21270;&#35299;&#37322;&#65292;&#21516;&#26102;&#36827;&#34892;&#32852;&#21512;&#23398;&#20064;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#35299;&#37322;&#33021;&#21147;&#21644;&#29992;&#25143;&#30340;&#20449;&#24515;&#21644;&#20449;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#20915;&#31574;&#36741;&#21161;&#29992;&#25143;&#29702;&#35299;&#30340;&#35299;&#37322;&#21487;&#20197;&#25552;&#39640;&#29992;&#25143;&#23545;&#31995;&#32479;&#30340;&#20449;&#24515;&#21644;&#20449;&#20219;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20197;&#20154;&#31867;&#21487;&#35835;&#30340;&#24418;&#24335;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#25552;&#20986;&#30340;&#26041;&#27861;&#24448;&#24448;&#21033;&#29992;&#29992;&#25143;&#32534;&#20889;&#30340;&#29289;&#21697;&#35780;&#35770;&#65292;&#36825;&#20123;&#35780;&#35770;&#36890;&#24120;&#20027;&#35266;&#65292;&#35821;&#35328;&#36139;&#20047;&#65292;&#24182;&#19988;&#26080;&#27861;&#28085;&#30422;&#26410;&#34987;&#36141;&#20080;&#25110;&#35780;&#35770;&#30340;&#26032;&#29289;&#21697;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#26681;&#25454;&#29992;&#25143;&#30340;&#36141;&#20080;&#21382;&#21490;&#65292;&#29983;&#25104;&#20197;&#29289;&#21697;&#29305;&#24449;&#23458;&#35266;&#25551;&#36848;&#30340;&#22522;&#20110;&#20107;&#23454;&#30340;&#25512;&#33616;&#35299;&#37322;&#65292;&#24182;&#38544;&#21547;&#32771;&#34385;&#29992;&#25143;&#30340;&#20559;&#22909;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#33258;&#28982;&#35821;&#35328;&#21487;&#35299;&#37322;&#25512;&#33616;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#30693;&#35782;&#22270;&#35889;&#34920;&#31034;&#65292;&#21033;&#29992;&#29992;&#25143;-&#29289;&#21697;&#29305;&#24449;&#20135;&#29983;&#22522;&#20110;&#20107;&#23454;&#30340;&#20010;&#24615;&#21270;&#35299;&#37322;&#65292;&#21516;&#26102;&#36827;&#34892;&#32852;&#21512;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explanations accompanied by a recommendation can assist users in understanding the decision made by recommendation systems, which in turn increases a user's confidence and trust in the system. Recently, research has focused on generating natural language explanations in a human-readable format. Thus far, the proposed approaches leverage item reviews written by users, which are often subjective, sparse in language, and unable to account for new items that have not been purchased or reviewed before. Instead, we aim to generate fact-grounded recommendation explanations that are objectively described with item features while implicitly considering a user's preferences, based on the user's purchase history. To achieve this, we propose a knowledge graph (KG) approach to natural language explainable recommendation. Our approach draws on user-item features through a novel collaborative filtering-based KG representation to produce fact-grounded, personalized explanations, while jointly learning
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Fragment and Integrate Network (FIN)&#30340;&#26032;&#22411;&#31354;&#38388;-&#26102;&#38388;&#24314;&#27169;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#39135;&#21697;&#35746;&#36141;&#28857;&#20987;&#29575;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20174;&#39034;&#24207;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#22810;&#20010;&#23376;&#24207;&#21015;&#65292;&#20998;&#21035;&#23545;&#27599;&#20010;&#23376;&#24207;&#21015;&#36827;&#34892;&#24314;&#27169;&#65292;&#20174;&#32780;&#25429;&#25417;&#29992;&#25143;&#30340;&#31354;&#38388;-&#26102;&#38388;&#20559;&#22909;&#12290;</title><link>http://arxiv.org/abs/2308.15703</link><description>&lt;p&gt;
&#22522;&#20110;&#38271;&#26399;&#39034;&#24207;&#34892;&#20026;&#30340;&#22312;&#32447;&#39135;&#21697;&#35746;&#36141;&#28857;&#20987;&#29575;&#39044;&#27979;&#30340;&#26032;&#22411;&#26102;&#31354;&#24314;&#27169;&#26041;&#27861;-Fragment and Integrate Network (FIN)
&lt;/p&gt;
&lt;p&gt;
Fragment and Integrate Network (FIN): A Novel Spatial-Temporal Modeling Based on Long Sequential Behavior for Online Food Ordering Click-Through Rate Prediction. (arXiv:2308.15703v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Fragment and Integrate Network (FIN)&#30340;&#26032;&#22411;&#31354;&#38388;-&#26102;&#38388;&#24314;&#27169;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#39135;&#21697;&#35746;&#36141;&#28857;&#20987;&#29575;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20174;&#39034;&#24207;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#22810;&#20010;&#23376;&#24207;&#21015;&#65292;&#20998;&#21035;&#23545;&#27599;&#20010;&#23376;&#24207;&#21015;&#36827;&#34892;&#24314;&#27169;&#65292;&#20174;&#32780;&#25429;&#25417;&#29992;&#25143;&#30340;&#31354;&#38388;-&#26102;&#38388;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31354;&#38388;-&#26102;&#38388;&#20449;&#24687;&#24050;&#34987;&#35777;&#26126;&#22312;&#22312;&#32447;&#22522;&#20110;&#20301;&#32622;&#30340;&#26381;&#21153;&#65288;LBS&#65289;&#20013;&#30340;&#28857;&#20987;&#29575;&#39044;&#27979;&#20219;&#21153;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#29305;&#21035;&#26159;&#22312;&#20027;&#27969;&#30340;&#39135;&#21697;&#35746;&#36141;&#24179;&#21488;&#19978;&#65292;&#22914;DoorDash&#12289;Uber Eats&#12289;&#32654;&#22242;&#21644;&#39295;&#20102;&#20040;&#12290;&#36890;&#36807;&#39034;&#24207;&#34892;&#20026;&#25968;&#25454;&#24314;&#27169;&#29992;&#25143;&#30340;&#31354;&#38388;-&#26102;&#38388;&#20559;&#22909;&#24050;&#25104;&#20026;&#25512;&#33616;&#31995;&#32479;&#21644;&#22312;&#32447;&#24191;&#21578;&#30340;&#28909;&#38376;&#35805;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22823;&#22810;&#32570;&#20047;&#23545;&#20016;&#23500;&#30340;&#31354;&#38388;-&#26102;&#38388;&#20449;&#24687;&#30340;&#34920;&#31034;&#65292;&#25110;&#32773;&#20165;&#22788;&#29702;&#38271;&#24230;&#26377;&#38480;&#30340;&#29992;&#25143;&#34892;&#20026;&#65292;&#20363;&#22914;100&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#21517;&#20026;Fragment and Integrate Network (FIN)&#30340;&#26032;&#22411;&#31354;&#38388;-&#26102;&#38388;&#24314;&#27169;&#33539;&#24335;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;FIN&#21253;&#25324;&#20004;&#20010;&#32593;&#32476;&#65306;&#29255;&#27573;&#32593;&#32476;&#65288;FN&#65289;&#20174;&#32456;&#36523;&#39034;&#24207;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#22810;&#20010;&#23376;&#24207;&#21015;&#65288;MSS&#65289;&#65292;&#36890;&#36807;&#20998;&#21035;&#23545;&#27599;&#20010;MSS&#36827;&#34892;&#24314;&#27169;&#26469;&#25429;&#25417;&#29305;&#23450;&#30340;&#31354;&#38388;-&#26102;&#38388;&#34920;&#31034;&#12290;&#36825;&#37324;&#37319;&#29992;&#20102;&#31616;&#21270;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#22797;&#26434;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spatial-temporal information has been proven to be of great significance for click-through rate prediction tasks in online Location-Based Services (LBS), especially in mainstream food ordering platforms such as DoorDash, Uber Eats, Meituan, and Ele.me. Modeling user spatial-temporal preferences with sequential behavior data has become a hot topic in recommendation systems and online advertising. However, most of existing methods either lack the representation of rich spatial-temporal information or only handle user behaviors with limited length, e.g. 100. In this paper, we tackle these problems by designing a new spatial-temporal modeling paradigm named Fragment and Integrate Network (FIN). FIN consists of two networks: (i) Fragment Network (FN) extracts Multiple Sub-Sequences (MSS) from lifelong sequential behavior data, and captures the specific spatial-temporal representation by modeling each MSS respectively. Here both a simplified attention and a complicated attention are adopted 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22810;&#34892;&#20026;&#39034;&#24207;&#25512;&#33616;&#65288;MBSR&#65289;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;MBSR&#30340;&#23450;&#20041;&#12289;&#24212;&#29992;&#22330;&#26223;&#21644;&#25361;&#25112;&#65292;&#24182;&#35814;&#32454;&#20998;&#31867;&#20102;MBSR&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#37051;&#22495;&#30340;&#26041;&#27861;&#12289;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#26041;&#27861;&#21644;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.15701</link><description>&lt;p&gt;
&#23545;&#22810;&#34892;&#20026;&#39034;&#24207;&#25512;&#33616;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Multi-Behavior Sequential Recommendation. (arXiv:2308.15701v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22810;&#34892;&#20026;&#39034;&#24207;&#25512;&#33616;&#65288;MBSR&#65289;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;MBSR&#30340;&#23450;&#20041;&#12289;&#24212;&#29992;&#22330;&#26223;&#21644;&#25361;&#25112;&#65292;&#24182;&#35814;&#32454;&#20998;&#31867;&#20102;MBSR&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#37051;&#22495;&#30340;&#26041;&#27861;&#12289;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#26041;&#27861;&#21644;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#35299;&#20915;&#20256;&#32479;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20013;&#20449;&#24687;&#36807;&#36733;&#30340;&#38382;&#39064;&#65292;&#20027;&#35201;&#20851;&#27880;&#20174;&#22823;&#37327;&#20449;&#24687;&#20013;&#20026;&#29992;&#25143;&#25512;&#33616;&#26368;&#24863;&#20852;&#36259;&#30340;&#20449;&#24687;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#20154;&#19982;&#31995;&#32479;&#20132;&#20114;&#30340;&#34892;&#20026;&#20855;&#26377;&#39034;&#24207;&#24615;&#21644;&#24322;&#36136;&#24615;&#65292;&#24341;&#21457;&#20102;&#22810;&#34892;&#20026;&#39034;&#24207;&#25512;&#33616;&#65288;MBSR&#65289;&#30340;&#25552;&#20986;&#12290;MBSR&#26159;&#19968;&#20010;&#30456;&#23545;&#26032;&#30340;&#12289;&#20540;&#24471;&#28145;&#20837;&#30740;&#31350;&#30340;&#26041;&#21521;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#24314;&#27169;&#21487;&#20197;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#25512;&#33616;&#65292;&#19968;&#20123;&#30456;&#20851;&#24037;&#20316;&#24050;&#32463;&#25552;&#20986;&#12290;&#26412;&#35843;&#26597;&#26088;&#22312;&#38416;&#26126;MBSR&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;MBSR&#65292;&#21253;&#25324;&#20854;&#38382;&#39064;&#23450;&#20041;&#12289;&#24212;&#29992;&#22330;&#26223;&#21644;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;MBSR&#30340;&#20998;&#31867;&#65292;&#21253;&#25324;&#22522;&#20110;&#37051;&#22495;&#30340;&#26041;&#27861;&#12289;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#26041;&#27861;&#21644;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36827;&#19968;&#27493;&#23558;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#23376;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems is set up to address the issue of information overload in traditional information retrieval systems, which is focused on recommending information that is of most interest to users from massive information. Generally, there is a sequential nature and heterogeneity to the behavior of a person interacting with a system, leading to the proposal of multi-behavior sequential recommendation (MBSR). MBSR is a relatively new and worthy direction for in-depth research, which can achieve state-of-the-art recommendation through suitable modeling, and some related works have been proposed. This survey aims to shed light on the MBSR problem. Firstly, we introduce MBSR in detail, including its problem definition, application scenarios and challenges faced. Secondly, we detail the classification of MBSR, including neighborhood-based methods, matrix factorization-based methods and deep learning-based methods, where we further classify the deep learning-based methods into different l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FADE&#30340;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#36890;&#36807;&#24494;&#35843;&#31574;&#30053;&#21160;&#24577;&#20943;&#36731;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#32676;&#20307;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2308.15651</link><description>&lt;p&gt;
&#22312;&#21160;&#24577;&#25512;&#33616;&#31995;&#32479;&#20013;&#30830;&#20445;&#29992;&#25143;&#20391;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Ensuring User-side Fairness in Dynamic Recommender Systems. (arXiv:2308.15651v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15651
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FADE&#30340;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#36890;&#36807;&#24494;&#35843;&#31574;&#30053;&#21160;&#24577;&#20943;&#36731;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#32676;&#20307;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#20391;&#32676;&#20307;&#20844;&#24179;&#24615;&#23545;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#65292;&#23427;&#26088;&#22312;&#20943;&#36731;&#30001;&#25935;&#24863;&#23646;&#24615;&#65288;&#22914;&#24615;&#21035;&#12289;&#31181;&#26063;&#25110;&#24180;&#40836;&#65289;&#23450;&#20041;&#30340;&#29992;&#25143;&#32676;&#20307;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#24046;&#24322;&#24448;&#24448;&#20250;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#25345;&#32493;&#23384;&#22312;&#29978;&#33267;&#22686;&#21152;&#12290;&#36825;&#38656;&#35201;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#26377;&#25928;&#35299;&#20915;&#29992;&#25143;&#20391;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#65292;&#28982;&#32780;&#36825;&#22312;&#25991;&#29486;&#20013;&#24456;&#23569;&#34987;&#25506;&#35752;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#30830;&#20445;&#29992;&#25143;&#20391;&#20844;&#24179;&#24615;&#65288;&#21363;&#20943;&#23569;&#24615;&#33021;&#24046;&#24322;&#65289;&#30340;&#20856;&#22411;&#26041;&#27861;&#8212;&#8212;&#20844;&#24179;&#32422;&#26463;&#37325;&#26032;&#25490;&#21517;&#65292;&#22312;&#21160;&#24577;&#35774;&#23450;&#20013;&#38754;&#20020;&#20004;&#20010;&#22522;&#26412;&#25361;&#25112;&#65306;&#65288;1&#65289;&#22522;&#20110;&#25490;&#21517;&#30340;&#20844;&#24179;&#32422;&#26463;&#30340;&#38750;&#21487;&#24494;&#24615;&#65292;&#38459;&#30861;&#20102;&#31471;&#21040;&#31471;&#35757;&#32451;&#33539;&#24335;&#65307;&#65288;2&#65289;&#26102;&#38388;&#25928;&#29575;&#20302;&#19979;&#65292;&#38459;&#30861;&#20102;&#23545;&#29992;&#25143;&#20559;&#22909;&#21464;&#21270;&#30340;&#24555;&#36895;&#36866;&#24212;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FADE&#30340;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#36890;&#36807;&#24494;&#35843;&#31574;&#30053;&#21160;&#24577;&#20943;&#36731;&#24615;&#33021;&#24046;&#24322;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#65292;FADE&#25552;&#20986;&#20102;&#19968;&#31181; fine-tuning &#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
User-side group fairness is crucial for modern recommender systems, as it aims to alleviate performance disparity between groups of users defined by sensitive attributes such as gender, race, or age. We find that the disparity tends to persist or even increase over time. This calls for effective ways to address user-side fairness in a dynamic environment, which has been infrequently explored in the literature. However, fairness-constrained re-ranking, a typical method to ensure user-side fairness (i.e., reducing performance disparity), faces two fundamental challenges in the dynamic setting: (1) non-differentiability of the ranking-based fairness constraint, which hinders the end-to-end training paradigm, and (2) time-inefficiency, which impedes quick adaptation to changes in user preferences. In this paper, we propose FAir Dynamic rEcommender (FADE), an end-to-end framework with fine-tuning strategy to dynamically alleviate performance disparity. To tackle the above challenges, FADE u
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#20266;&#24067;&#23572;&#22810;&#39033;&#24335;&#30340;&#24809;&#32602;&#24615;&#34920;&#36798;&#24335;&#20316;&#20026;&#31751;&#20998;&#26512;&#20013;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#33021;&#22815;&#20197;&#31454;&#20105;&#24615;&#30340;&#20934;&#30830;&#24230;&#12289;&#21487;&#37325;&#22797;&#24615;&#21644;&#28165;&#26224;&#35299;&#37322;&#24615;&#25552;&#21462;&#31751;&#12290;</title><link>http://arxiv.org/abs/2308.15553</link><description>&lt;p&gt;
&#20351;&#29992;&#20266;&#24067;&#23572;&#22810;&#39033;&#24335;&#36827;&#34892;&#31751;&#20998;&#26512;&#30340;&#38477;&#32500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Dimensionality Reduction Using pseudo-Boolean polynomials For Cluster Analysis. (arXiv:2308.15553v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15553
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#20266;&#24067;&#23572;&#22810;&#39033;&#24335;&#30340;&#24809;&#32602;&#24615;&#34920;&#36798;&#24335;&#20316;&#20026;&#31751;&#20998;&#26512;&#20013;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#33021;&#22815;&#20197;&#31454;&#20105;&#24615;&#30340;&#20934;&#30830;&#24230;&#12289;&#21487;&#37325;&#22797;&#24615;&#21644;&#28165;&#26224;&#35299;&#37322;&#24615;&#25552;&#21462;&#31751;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;&#20266;&#24067;&#23572;&#22810;&#39033;&#24335;&#30340;&#24809;&#32602;&#24615;&#34920;&#36798;&#24335;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#20316;&#20026;&#31751;&#20998;&#26512;&#36807;&#31243;&#20013;&#19981;&#21464;&#38477;&#32500;&#30340;&#26426;&#21046;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#32500;&#25968;&#25454;&#65292;&#22914;4&#32500;&#40482;&#23614;&#33457;&#25968;&#25454;&#38598;&#21487;&#20197;&#38477;&#33267;2&#32500;&#31354;&#38388;&#65292;&#32780;30&#32500;&#23041;&#26031;&#24247;&#26143;&#24030;&#20083;&#33146;&#30284;&#65288;WDBC&#65289;&#25968;&#25454;&#38598;&#21487;&#20197;&#38477;&#33267;3&#32500;&#31354;&#38388;&#65292;&#36890;&#36807;&#25628;&#32034;&#20301;&#20110;&#38477;&#32500;&#26679;&#26412;&#20043;&#38388;&#30340;&#30452;&#32447;&#25110;&#24179;&#38754;&#65292;&#25105;&#20204;&#21487;&#20197;&#20197;&#32447;&#24615;&#21644;&#26080;&#20559;&#30340;&#26041;&#24335;&#25552;&#21462;&#31751;&#65292;&#24182;&#19988;&#20855;&#26377;&#31454;&#20105;&#24615;&#30340;&#20934;&#30830;&#24230;&#65292;&#21487;&#37325;&#22797;&#24615;&#21644;&#28165;&#26224;&#30340;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce usage of a reduction property of penalty-based formulation of pseudo-Boolean polynomials as a mechanism for invariant dimensionality reduction in cluster analysis processes. In our experiments, we show that multidimensional data, like 4-dimensional Iris Flower dataset can be reduced to 2-dimensional space while the 30-dimensional Wisconsin Diagnostic Breast Cancer (WDBC) dataset can be reduced to 3-dimensional space, and by searching lines or planes that lie between reduced samples we can extract clusters in a linear and unbiased manner with competitive accuracies, reproducibility and clear interpretation.
&lt;/p&gt;</description></item><item><title>&#20013;&#25991;&#24635;&#32467;: &#26412;&#30740;&#31350;&#23545;&#27604;&#20102;&#22522;&#20110;&#22359;&#38142;&#34920;&#21644;&#21487;&#25193;&#23637;&#25968;&#32452;&#30340;&#25991;&#26412;&#21453;&#36716;&#25216;&#26415;&#65292;&#37325;&#28857;&#27604;&#36739;&#20102;&#21160;&#24577;&#26000;&#27874;&#37027;&#22865;&#22359;&#38142;&#34920;&#21644;&#21487;&#25193;&#23637;SQ&#25968;&#32452;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.15498</link><description>&lt;p&gt;
&#25991;&#20013;&#30340;&#32763;&#35793;&#26631;&#39064;: &#22522;&#20110;&#22359;&#38142;&#34920;&#19982;&#21487;&#25193;&#23637;&#25968;&#32452;&#30340;&#25991;&#26412;&#21453;&#36716;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Chunked Lists versus Extensible Arrays for Text Inversion. (arXiv:2308.15498v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15498
&lt;/p&gt;
&lt;p&gt;
&#20013;&#25991;&#24635;&#32467;: &#26412;&#30740;&#31350;&#23545;&#27604;&#20102;&#22522;&#20110;&#22359;&#38142;&#34920;&#21644;&#21487;&#25193;&#23637;&#25968;&#32452;&#30340;&#25991;&#26412;&#21453;&#36716;&#25216;&#26415;&#65292;&#37325;&#28857;&#27604;&#36739;&#20102;&#21160;&#24577;&#26000;&#27874;&#37027;&#22865;&#22359;&#38142;&#34920;&#21644;&#21487;&#25193;&#23637;SQ&#25968;&#32452;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;2017&#24180;&#20851;&#20110;&#20869;&#23384;&#20013;&#22522;&#20110;&#21015;&#34920;&#30340;&#25991;&#26412;&#21453;&#36716;&#30340;&#30740;&#31350;&#20013;[Hawking&#21644;Billerbeck. Efficient In-Memory, List-Based Text Inversion. ADCS 2017]&#65292;&#23545;&#22823;&#37327;&#30340;&#22359;&#38142;&#25509;&#21015;&#34920;&#21464;&#20307;&#36827;&#34892;&#20102;&#20869;&#23384;&#20351;&#29992;&#21644;&#32034;&#24341;&#36895;&#24230;&#30340;&#27604;&#36739;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#21464;&#20307;&#20013;&#34920;&#29616;&#26368;&#20339;&#30340;&#19968;&#31181;&#65288;FBB - &#21160;&#24577;&#26000;&#27874;&#37027;&#22865;&#22359;&#38142;&#34920;&#65289;&#19982;[Moffat&#21644;Mackenzie. Immediate-Access Indexing Using Space-Efficient Extensible Arrays. ADCS 2023]&#20013;&#25552;&#20986;&#30340;&#21487;&#25193;&#23637;SQ&#25968;&#32452;&#25216;&#26415;(SQA)&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
In our 2017 work on in-memory list-based text inversion [Hawking and Billerbeck. Efficient In-Memory, List-Based Text Inversion. ADCS 2017] we compared memory use and indexing speed of a considerable number of variants of chunked linked lists. In the present work we compare the best performing of those variants (FBB - dynamic Fibonacci chunking) with the extensible SQ array technique (SQA) presented in [Moffat and Mackenzie. Immediate-Access Indexing Using Space-Efficient Extensible Arrays. ADCS 2023].
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#22343;&#23884;&#20837;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#23884;&#20837;&#22312;&#25512;&#33616;&#20013;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#36827;&#19968;&#27493;&#25913;&#36827;&#29616;&#23454;&#19990;&#30028;&#23884;&#20837;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2308.12767</link><description>&lt;p&gt;
&#20851;&#20110;&#24179;&#22343;&#23884;&#20837;&#29992;&#20110;&#29289;&#21697;&#25512;&#33616;&#30340;&#19968;&#33268;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Consistency of Average Embeddings for Item Recommendation. (arXiv:2308.12767v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#22343;&#23884;&#20837;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#23884;&#20837;&#22312;&#25512;&#33616;&#20013;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#36827;&#19968;&#27493;&#25913;&#36827;&#29616;&#23454;&#19990;&#30028;&#23884;&#20837;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#20570;&#27861;&#26159;&#23558;&#29289;&#21697;&#23884;&#20837;&#36827;&#34892;&#24179;&#22343;&#20197;&#22312;&#21516;&#19968;&#23884;&#20837;&#31354;&#38388;&#20013;&#20195;&#34920;&#29992;&#25143;&#25110;&#26356;&#39640;&#32423;&#30340;&#27010;&#24565;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#31181;&#20570;&#27861;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26399;&#26395;&#31934;&#24230;&#20998;&#25968;&#65292;&#29992;&#20110;&#34913;&#37327;&#24179;&#22343;&#23884;&#20837;&#19982;&#20854;&#26500;&#24314;&#25152;&#20351;&#29992;&#30340;&#29289;&#21697;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#38543;&#21518;&#22312;&#20855;&#26377;&#29305;&#23450;&#20551;&#35774;&#30340;&#29702;&#35770;&#29615;&#22659;&#21644;&#26469;&#33258;&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#30340;&#30495;&#23454;&#25968;&#25454;&#19978;&#20998;&#26512;&#20102;&#35813;&#20998;&#25968;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#21450;&#20854;&#32463;&#39564;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24378;&#35843;&#20102;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#20540;&#22312;&#25512;&#33616;&#20013;&#30340;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#26356;&#22909;&#22320;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#23884;&#20837;&#19982;&#25105;&#20204;&#29702;&#35770;&#29615;&#22659;&#30340;&#20551;&#35774;&#30456;&#19968;&#33268;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
A prevalent practice in recommender systems consists of averaging item embeddings to represent users or higher-level concepts in the same embedding space. This paper investigates the relevance of such a practice. For this purpose, we propose an expected precision score, designed to measure the consistency of an average embedding relative to the items used for its construction. We subsequently analyze the mathematical expression of this score in a theoretical setting with specific assumptions, as well as its empirical behavior on real-world data from music streaming services. Our results emphasize that real-world averages are less consistent for recommendation, which paves the way for future research to better align real-world embeddings with assumptions from our theoretical setting.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25552;&#31034;&#24335;&#24494;&#35843;&#26694;&#26550;VPGNN&#65292;&#29992;&#20110;&#20419;&#38144;&#21048;&#28389;&#29992;&#26816;&#27979;&#12290;&#36890;&#36807;&#35774;&#35745;&#26032;&#39062;&#30340;&#22270;&#25552;&#31034;&#20989;&#25968;&#65292;&#23558;&#19979;&#28216;&#20219;&#21153;&#37325;&#26500;&#20026;&#19982;&#39044;&#35757;&#32451;&#20013;&#30340;&#39044;&#25991;&#26412;&#20219;&#21153;&#31867;&#20284;&#30340;&#27169;&#26495;&#65292;&#20174;&#32780;&#32553;&#23567;&#20102;&#30446;&#26631;&#24046;&#36317;&#12290;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;VPGNN&#22312;&#23569;&#26679;&#26412;&#21644;&#21322;&#30417;&#30563;&#24773;&#20917;&#19979;&#30340;&#24378;&#22823;&#24615;&#33021;&#65292;&#24182;&#22312;&#29983;&#20135;&#29615;&#22659;&#20013;&#23454;&#29616;&#20102;23.4%&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2308.10028</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20419;&#38144;&#21048;&#28389;&#29992;&#26816;&#27979;&#20013;&#30340;&#25552;&#31034;&#24335;&#24494;&#35843;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks. (arXiv:2308.10028v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10028
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25552;&#31034;&#24335;&#24494;&#35843;&#26694;&#26550;VPGNN&#65292;&#29992;&#20110;&#20419;&#38144;&#21048;&#28389;&#29992;&#26816;&#27979;&#12290;&#36890;&#36807;&#35774;&#35745;&#26032;&#39062;&#30340;&#22270;&#25552;&#31034;&#20989;&#25968;&#65292;&#23558;&#19979;&#28216;&#20219;&#21153;&#37325;&#26500;&#20026;&#19982;&#39044;&#35757;&#32451;&#20013;&#30340;&#39044;&#25991;&#26412;&#20219;&#21153;&#31867;&#20284;&#30340;&#27169;&#26495;&#65292;&#20174;&#32780;&#32553;&#23567;&#20102;&#30446;&#26631;&#24046;&#36317;&#12290;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;VPGNN&#22312;&#23569;&#26679;&#26412;&#21644;&#21322;&#30417;&#30563;&#24773;&#20917;&#19979;&#30340;&#24378;&#22823;&#24615;&#33021;&#65292;&#24182;&#22312;&#29983;&#20135;&#29615;&#22659;&#20013;&#23454;&#29616;&#20102;23.4%&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20419;&#38144;&#21048;&#28389;&#29992;&#26816;&#27979;&#26159;&#30005;&#23376;&#21830;&#21153;&#20013;&#37325;&#35201;&#30340;&#24322;&#24120;&#26816;&#27979;&#38382;&#39064;&#12290;&#34429;&#28982;&#20986;&#29616;&#20102;&#35768;&#22810;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#30417;&#30563;&#24335;&#33539;&#24335;&#21462;&#20915;&#20110;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#12290;&#19968;&#20010;&#24120;&#35265;&#30340;&#26367;&#20195;&#26041;&#26696;&#26159;&#37319;&#29992;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#20351;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#24182;&#22312;&#26377;&#38480;&#26631;&#31614;&#30340;&#19979;&#28216;&#20219;&#21153;&#19978;&#36827;&#19968;&#27493;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292;&#8220;&#39044;&#35757;&#32451;&#65292;&#24494;&#35843;&#8221;&#33539;&#24335;&#24120;&#24120;&#21463;&#21040;&#39044;&#35757;&#32451;&#21644;&#19979;&#28216;&#20219;&#21153;&#20043;&#38388;&#30446;&#26631;&#24046;&#36317;&#30340;&#22256;&#25200;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;VPGNN&#65292;&#19968;&#31181;&#22522;&#20110;GNN&#30340;&#25552;&#31034;&#24335;&#24494;&#35843;&#26694;&#26550;&#29992;&#20110;&#20419;&#38144;&#21048;&#28389;&#29992;&#26816;&#27979;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22270;&#25552;&#31034;&#20989;&#25968;&#65292;&#23558;&#19979;&#28216;&#20219;&#21153;&#37325;&#26500;&#25104;&#19982;&#39044;&#35757;&#32451;&#20013;&#30340;&#39044;&#25991;&#26412;&#20219;&#21153;&#31867;&#20284;&#30340;&#27169;&#26495;&#65292;&#20174;&#32780;&#32553;&#23567;&#20102;&#30446;&#26631;&#24046;&#36317;&#12290;&#22312;&#19987;&#26377;&#21644;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;VPGNN&#22312;&#23569;&#26679;&#26412;&#21644;&#21322;&#30417;&#30563;&#24773;&#20917;&#19979;&#30340;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#22312;&#29983;&#20135;&#29615;&#22659;&#20013;&#22312;&#32447;&#37096;&#32626;VPGNN&#26174;&#31034;&#20986;23.4%&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Voucher abuse detection is an important anomaly detection problem in E-commerce. While many GNN-based solutions have emerged, the supervised paradigm depends on a large quantity of labeled data. A popular alternative is to adopt self-supervised pre-training using label-free data, and further fine-tune on a downstream task with limited labels. Nevertheless, the "pre-train, fine-tune" paradigm is often plagued by the objective gap between pre-training and downstream tasks. Hence, we propose VPGNN, a prompt-based fine-tuning framework on GNNs for voucher abuse detection. We design a novel graph prompting function to reformulate the downstream task into a similar template as the pretext task in pre-training, thereby narrowing the objective gap. Extensive experiments on both proprietary and public datasets demonstrate the strength of VPGNN in both few-shot and semi-supervised scenarios. Moreover, an online deployment of VPGNN in a production environment shows a 23.4% improvement over two ex
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#26469;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#26041;&#27861;&#65288;SPTAR&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#24182;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#29983;&#25104;&#24369;&#26597;&#35810;&#65292;&#21487;&#20197;&#25552;&#39640;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.08303</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#36719;&#25552;&#31034;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#26469;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#26041;&#27861;&#65288;SPTAR&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#24182;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#29983;&#25104;&#24369;&#26597;&#35810;&#65292;&#21487;&#20197;&#25552;&#39640;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#26816;&#32034;&#65288;DR&#65289;&#23558;&#26597;&#35810;&#21644;&#25991;&#26723;&#36716;&#21270;&#20026;&#23494;&#38598;&#21521;&#37327;&#34920;&#31034;&#65292;&#24182;&#22312;&#21521;&#37327;&#31354;&#38388;&#20013;&#27979;&#37327;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;DR&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#32570;&#20047;&#39046;&#22495;&#29305;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#34429;&#28982;DR&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#20174;&#22823;&#35268;&#27169;&#20844;&#20849;&#25968;&#25454;&#38598;&#65288;&#22914;MS MARCO&#65289;&#20013;&#23398;&#20064;&#65292;&#20294;&#35777;&#25454;&#34920;&#26126;&#65292;&#24182;&#38750;&#25152;&#26377;DR&#27169;&#22411;&#21644;&#39046;&#22495;&#37117;&#33021;&#21516;&#31561;&#21463;&#30410;&#20110;&#36801;&#31227;&#23398;&#20064;&#12290;&#26368;&#36817;&#65292;&#19968;&#20123;&#30740;&#31350;&#20154;&#21592;&#36716;&#21521;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#25913;&#36827;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;DR&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20013;&#37319;&#29992;&#30340;&#30828;&#25552;&#31034;&#25110;&#20154;&#24037;&#32534;&#20889;&#30340;&#25552;&#31034;&#26080;&#27861;&#20445;&#35777;&#29983;&#25104;&#30340;&#24369;&#26597;&#35810;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#22686;&#24378;DR&#30340;&#36719;&#25552;&#31034;&#35843;&#20248;&#65288;SPTAR&#65289;&#65306;&#23545;&#20110;&#27599;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#21033;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#22312;&#26377;&#38480;&#30340;&#30495;&#23454;&#25968;&#25454;&#19978;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#65292;&#28982;&#21518;&#29992;&#36825;&#20123;&#25552;&#31034;&#24341;&#23548;LLMs&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#26631;&#35760;&#24369;&#26597;&#35810;&#65292;&#20174;&#32780;&#24471;&#21040;&#36275;&#22815;&#30340;&#24369;&#25991;&#26723;-&#26597;&#35810;&#23545;&#26469;&#35757;&#32451;&#20219;&#21153;&#29305;&#23450;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25581;&#31034;&#20102;&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#35780;&#20272;&#22120;&#26102;&#23384;&#22312;&#30340;&#31995;&#32479;&#20559;&#24046;&#65292;&#21487;&#20197;&#36890;&#36807;&#25913;&#21464;&#20505;&#36873;&#21709;&#24212;&#30340;&#39034;&#24207;&#26469;&#25805;&#32437;&#35780;&#20272;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26657;&#20934;&#26694;&#26550;&#65292;&#21253;&#25324;&#22810;&#35777;&#25454;&#26657;&#20934;&#12289;&#22343;&#34913;&#20301;&#32622;&#26657;&#20934;&#21644;&#20154;&#26426;&#21327;&#21516;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2305.17926</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#19981;&#26159;&#20844;&#24179;&#30340;&#35780;&#20272;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are not Fair Evaluators. (arXiv:2305.17926v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#35780;&#20272;&#22120;&#26102;&#23384;&#22312;&#30340;&#31995;&#32479;&#20559;&#24046;&#65292;&#21487;&#20197;&#36890;&#36807;&#25913;&#21464;&#20505;&#36873;&#21709;&#24212;&#30340;&#39034;&#24207;&#26469;&#25805;&#32437;&#35780;&#20272;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26657;&#20934;&#26694;&#26550;&#65292;&#21253;&#25324;&#22810;&#35777;&#25454;&#26657;&#20934;&#12289;&#22343;&#34913;&#20301;&#32622;&#26657;&#20934;&#21644;&#20154;&#26426;&#21327;&#21516;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#37319;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65288;&#20363;&#22914;GPT-4&#65289;&#20316;&#20026;&#35009;&#21028;&#26469;&#35780;&#20998;&#21644;&#27604;&#36739;&#20505;&#36873;&#27169;&#22411;&#29983;&#25104;&#30340;&#21709;&#24212;&#36136;&#37327;&#30340;&#35780;&#20272;&#33539;&#24335;&#20013;&#23384;&#22312;&#30340;&#31995;&#32479;&#20559;&#24046;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#31616;&#21333;&#22320;&#25913;&#21464;&#20505;&#36873;&#21709;&#24212;&#22312;&#19978;&#19979;&#25991;&#20013;&#20986;&#29616;&#30340;&#39034;&#24207;&#65292;&#21487;&#20197;&#36731;&#26494;&#22320;&#25805;&#32437;&#20505;&#36873;&#21709;&#24212;&#30340;&#36136;&#37327;&#25490;&#21517;&#12290;&#36825;&#31181;&#25805;&#32437;&#20351;&#24471;&#19968;&#20010;&#27169;&#22411;&#30475;&#36215;&#26469;&#27604;&#21478;&#19968;&#20010;&#27169;&#22411;&#35201;&#20248;&#36234;&#24471;&#22810;&#65292;&#20363;&#22914;&#65292;&#20351;&#29992;ChatGPT&#20316;&#20026;&#35780;&#20272;&#22120;&#65292;&#22312;80&#20010;&#27979;&#35797;&#26597;&#35810;&#20013;&#65292;Vicuna-13B&#21487;&#20197;&#20987;&#36133;ChatGPT&#30340;66&#20010;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26657;&#20934;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#21547;&#19977;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#31574;&#30053;&#65306;1&#65289;&#22810;&#35777;&#25454;&#26657;&#20934;&#65292;&#35201;&#27714;&#35780;&#20272;&#27169;&#22411;&#22312;&#20998;&#37197;&#35780;&#20998;&#20043;&#21069;&#29983;&#25104;&#22810;&#20010;&#35780;&#20272;&#35777;&#25454;&#65307;2&#65289;&#22343;&#34913;&#20301;&#32622;&#26657;&#20934;&#65292;&#22312;&#21508;&#31181;&#39034;&#24207;&#20013;&#32858;&#21512;&#32467;&#26524;&#20197;&#30830;&#23450;&#26368;&#32456;&#20998;&#25968;&#65307;3&#65289;&#20154;&#26426;&#21327;&#21516;&#26657;&#20934;&#65292;&#24341;&#20837;&#24179;&#34913;&#30340;&#20301;&#32622;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we uncover a systematic bias in the evaluation paradigm of adopting large language models~(LLMs), e.g., GPT-4, as a referee to score and compare the quality of responses generated by candidate models. We find that the quality ranking of candidate responses can be easily hacked by simply altering their order of appearance in the context. This manipulation allows us to skew the evaluation result, making one model appear considerably superior to the other, e.g., Vicuna-13B could beat ChatGPT on 66 over 80 tested queries with ChatGPT as an evaluator. To address this issue, we propose a calibration framework with three simple yet effective strategies: 1) Multiple Evidence Calibration, which requires the evaluator model to generate multiple evaluation evidence before assigning ratings; 2) Balanced Position Calibration, which aggregates results across various orders to determine the final score; 3) Human-in-the-Loop Calibration, which introduces a balanced position diversity en
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;GENRE&#65292;&#23427;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#65292;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#25552;&#20379;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#12290;</title><link>http://arxiv.org/abs/2305.06566</link><description>&lt;p&gt;
LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#21021;&#25506;
&lt;/p&gt;
&lt;p&gt;
A First Look at LLM-Powered Generative News Recommendation. (arXiv:2305.06566v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;GENRE&#65292;&#23427;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#65292;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#25552;&#20379;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#29992;&#25143;&#27983;&#35272;&#28023;&#37327;&#22312;&#32447;&#26032;&#38395;&#20869;&#23481;&#25152;&#24517;&#38656;&#30340;&#24037;&#20855;&#65292;&#28982;&#32780;&#29616;&#26377;&#30340;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30528;&#20919;&#21551;&#21160;&#38382;&#39064;&#12289;&#29992;&#25143;&#30011;&#20687;&#24314;&#27169;&#21644;&#26032;&#38395;&#20869;&#23481;&#29702;&#35299;&#31561;&#37325;&#22823;&#25361;&#25112;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#36890;&#24120;&#36890;&#36807;&#27169;&#22411;&#35774;&#35745;&#36981;&#24490;&#19968;&#31181;&#19981;&#28789;&#27963;&#30340;&#20363;&#34892;&#31243;&#24207;&#26469;&#35299;&#20915;&#29305;&#23450;&#30340;&#25361;&#25112;&#65292;&#20294;&#22312;&#29702;&#35299;&#26032;&#38395;&#20869;&#23481;&#21644;&#25429;&#25417;&#29992;&#25143;&#20852;&#36259;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;GENRE&#65292;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;&#65292;&#23427;&#21033;&#29992;&#26469;&#33258;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#26469;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#26469;&#25552;&#20379;&#19968;&#31181;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#26032;&#38395;&#25512;&#33616;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;GENRE&#22312;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#20013;&#30340;&#24212;&#29992;&#12290;&#20351;&#29992;&#21508;&#31181;&#27969;&#34892;&#30340;&#25512;&#33616;&#27169;&#22411;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;GENRE&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding. Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests. In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data. Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design. We showcase the use of GENRE for personalized news generation, user profiling, and news summarization. Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#21452;&#31890;&#24230;&#23545;&#27604;&#23398;&#20064;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#22810;&#31890;&#24230;CL&#26694;&#26550;&#21644;&#26032;&#30340;CL&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#20250;&#35805;&#20043;&#38388;&#24494;&#23567;&#30340;&#24046;&#24322;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.08873</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#31890;&#24230;&#23545;&#27604;&#23398;&#20064;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Dual-Ganularity Contrastive Learning for Session-based Recommendation. (arXiv:2304.08873v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08873
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#21452;&#31890;&#24230;&#23545;&#27604;&#23398;&#20064;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#22810;&#31890;&#24230;CL&#26694;&#26550;&#21644;&#26032;&#30340;CL&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#20250;&#35805;&#20043;&#38388;&#24494;&#23567;&#30340;&#24046;&#24322;&#65292;&#24182;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#65288;SBRS&#65289;&#22312;&#24403;&#21069;&#30005;&#23376;&#21830;&#21153;&#21644;&#27969;&#23186;&#20307;&#25512;&#33616;&#22330;&#26223;&#20013;&#26356;&#36866;&#29992;&#65292;&#22240;&#27492;&#25104;&#20026;&#20102;&#28909;&#38376;&#35805;&#39064;&#12290;SBRS&#36935;&#21040;&#30340;&#25968;&#25454;&#36890;&#24120;&#38750;&#24120;&#31232;&#30095;&#65292;&#20063;&#26159;&#38480;&#21046;&#25512;&#33616;&#20934;&#30830;&#24230;&#30340;&#29942;&#39048;&#20043;&#19968;&#12290;&#22240;&#27492;&#65292;&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#22312;SBRS&#20013;&#24212;&#29992;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#22312;&#31232;&#30095;&#25968;&#25454;&#26465;&#20214;&#19979;&#25913;&#21892;&#23884;&#20837;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;CL&#31574;&#30053;&#22312;&#24378;&#21046;&#25191;&#34892;&#26356;&#32454;&#31890;&#24230;&#65288;&#20363;&#22914;&#65292;&#22240;&#32032;&#32423;&#65289;&#27604;&#36739;&#26041;&#38754;&#33021;&#21147;&#26377;&#38480;&#65292;&#22240;&#27492;&#26080;&#27861;&#25429;&#25417;&#23454;&#20363;&#20043;&#38388;&#30340;&#24494;&#23567;&#24046;&#24322;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#36825;&#20123;&#31574;&#30053;&#36890;&#24120;&#20351;&#29992;&#39033;&#30446;&#25110;&#29255;&#27573;&#38543;&#26426;&#21024;&#38500;&#20316;&#20026;&#25968;&#25454;&#22686;&#24378;&#30340;&#25163;&#27573;&#65292;&#21487;&#33021;&#23548;&#33268;&#25968;&#25454;&#26356;&#31232;&#30095;&#65292;&#20174;&#32780;&#26080;&#25928;&#22320;&#33258;&#25105;&#30417;&#30563;&#20449;&#21495;&#12290;&#36890;&#36807;&#35299;&#20915;&#19978;&#36848;&#20004;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#24230;CL&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#20855;&#26377;&#21452;&#37325;&#31890;&#24230;&#30340;&#20004;&#20010;&#39069;&#22806;&#30340;&#23884;&#20837;&#21367;&#31215;&#36890;&#36947;&#21512;&#24182;&#21040;&#32593;&#32476;&#20013;&#65292;&#20351;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#20250;&#35805;&#30340;&#26412;&#22320;&#39033;&#30446;&#21644;&#20840;&#23616;&#22240;&#32032;&#20449;&#24687;&#30340;&#20849;&#20139;&#21644;&#21028;&#21035;&#34920;&#31034;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CL&#31574;&#30053;&#65292;&#20351;&#29992;&#33258;&#25105;&#30417;&#30563;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#26469;&#24378;&#21046;&#25191;&#34892;&#32454;&#31890;&#24230;&#27604;&#36739;&#12290;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#22320;&#25429;&#25417;&#20250;&#35805;&#20043;&#38388;&#30340;&#24494;&#23567;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Session-based recommendation systems(SBRS) are more suitable for the current e-commerce and streaming media recommendation scenarios and thus have become a hot topic. The data encountered by SBRS is typically highly sparse, which also serves as one of the bottlenecks limiting the accuracy of recommendations. So Contrastive Learning(CL) is applied in SBRS owing to its capability of improving embedding learning under the condition of sparse data. However, existing CL strategies are limited in their ability to enforce finer-grained (e.g., factor-level) comparisons and, as a result, are unable to capture subtle differences between instances. More than that, these strategies usually use item or segment dropout as a means of data augmentation which may result in sparser data and thus ineffective self-supervised signals. By addressing the two aforementioned limitations, we introduce a novel multi-granularity CL framework. Specifically, two extra augmented embedding convolution channels with d
&lt;/p&gt;</description></item><item><title>RecXplainer&#25552;&#20379;&#20102;&#19968;&#31181;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;&#20998;&#25674;&#23646;&#24615;&#20010;&#24615;&#21270;&#35299;&#37322;&#65292;&#20197;&#35299;&#20915;&#29992;&#25143;&#21644;&#24320;&#21457;&#32773;&#20043;&#38388;&#30340;&#20449;&#20219;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.14935</link><description>&lt;p&gt;
RecXplainer: &#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;&#20998;&#25674;&#23646;&#24615;&#20010;&#24615;&#21270;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
RecXplainer: Amortized Attribute-based Personalized Explanations for Recommender Systems. (arXiv:2211.14935v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14935
&lt;/p&gt;
&lt;p&gt;
RecXplainer&#25552;&#20379;&#20102;&#19968;&#31181;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;&#20998;&#25674;&#23646;&#24615;&#20010;&#24615;&#21270;&#35299;&#37322;&#65292;&#20197;&#35299;&#20915;&#29992;&#25143;&#21644;&#24320;&#21457;&#32773;&#20043;&#38388;&#30340;&#20449;&#20219;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#25968;&#23383;&#19990;&#30028;&#20013;&#24433;&#21709;&#30528;&#25105;&#20204;&#30340;&#35768;&#22810;&#20132;&#20114;&#65292;&#24433;&#21709;&#30528;&#25105;&#20204;&#36141;&#29289;&#12289;&#27983;&#35272;YouTube&#25110;TikTok&#26102;&#25152;&#30475;&#21040;&#30340;&#20869;&#23481;&#65292;&#20197;&#21450;&#22312;&#20351;&#29992;&#37202;&#24215;&#24179;&#21488;&#26102;&#23637;&#31034;&#32473;&#25105;&#20204;&#30340;&#39184;&#39302;&#21644;&#37202;&#24215;&#12290;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#26159;&#22522;&#20110;&#19987;&#26377;&#21644;&#24320;&#28304;&#25968;&#25454;&#38598;&#35757;&#32451;&#30340;&#24222;&#22823;&#19988;&#19981;&#36879;&#26126;&#30340;&#27169;&#22411;&#12290;&#33258;&#28982;&#32780;&#28982;&#22320;&#65292;&#22312;&#24320;&#21457;&#32773;&#21644;&#29992;&#25143;&#26041;&#38754;&#24341;&#21457;&#20102;&#20449;&#20219;&#38382;&#39064;&#65306;&#31995;&#32479;&#26159;&#21542;&#27491;&#24120;&#24037;&#20316;&#65292;&#20026;&#20160;&#20040;&#29992;&#25143;&#25910;&#21040;&#65288;&#25110;&#26410;&#25910;&#21040;&#65289;&#29305;&#23450;&#30340;&#25512;&#33616;&#65311;&#22312;&#25512;&#33616;&#26049;&#36793;&#25552;&#20379;&#35299;&#37322;&#21487;&#20197;&#20943;&#36731;&#19968;&#20123;&#36825;&#20123;&#20851;&#27880;&#12290;&#30446;&#21069;&#36741;&#21161;&#25512;&#33616;&#31995;&#32479;&#21453;&#39304;&#30340;&#29616;&#29366;&#35201;&#20040;&#26159;&#29992;&#25143;&#29305;&#23450;&#30340;&#35299;&#37322;&#65288;&#20363;&#22914;&#65292;&#8220;&#36141;&#20080;&#21830;&#21697;B&#30340;&#29992;&#25143;&#20063;&#36141;&#20080;&#20102;&#21830;&#21697;A&#8221;&#65289;&#65292;&#35201;&#20040;&#26159;&#29289;&#21697;&#29305;&#23450;&#30340;&#35299;&#37322;&#65288;&#20363;&#22914;&#65292;&#8220;&#25105;&#20204;&#25512;&#33616;&#21830;&#21697;A&#26159;&#22240;&#20026;&#24744;&#35266;&#30475;/&#36141;&#20080;&#20102;&#21830;&#21697;B&#8221;&#65289;&#12290;&#28982;&#32780;&#65292;&#29992;&#25143;&#23558;&#20010;&#24615;&#21270;&#30340;&#32972;&#26223;&#20449;&#24687;&#24102;&#20837;&#20182;&#20204;&#30340;&#25628;&#32034;&#20307;&#39564;&#20013;&#65292;&#23558;&#19968;&#20010;&#29289;&#21697;&#30340;&#20215;&#20540;&#35270;&#20026;&#35813;&#29289;&#21697;&#30340;&#20989;&#25968;.
&lt;/p&gt;
&lt;p&gt;
Recommender systems influence many of our interactions in the digital world -- impacting how we shop for clothes, sorting what we see when browsing YouTube or TikTok, and determining which restaurants and hotels we are shown when using hospitality platforms. Modern recommender systems are large, opaque models trained on a mixture of proprietary and open-source datasets. Naturally, issues of trust arise on both the developer and user side: is the system working correctly, and why did a user receive (or not receive) a particular recommendation? Providing an explanation alongside a recommendation alleviates some of these concerns. The status quo for auxiliary recommender system feedback is either user-specific explanations (e.g., "users who bought item B also bought item A") or item-specific explanations (e.g., "we are recommending item A because you watched/bought item B"). However, users bring personalized context into their search experience, valuing an item as a function of that item'
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#32500;&#30456;&#20284;&#24230;&#30340;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#28246;&#20013;&#39640;&#25928;&#22320;&#21457;&#29616;&#21487;&#36830;&#25509;&#34920;&#12290;&#36890;&#36807;&#23558;&#25991;&#26412;&#20540;&#23884;&#20837;&#39640;&#32500;&#21521;&#37327;&#24182;&#20351;&#29992;&#30456;&#20284;&#24615;&#35859;&#35789;&#36830;&#25509;&#21015;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#35299;&#20915;&#31561;&#20540;&#36830;&#25509;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#35782;&#21035;&#20986;&#26356;&#26377;&#24847;&#20041;&#30340;&#32467;&#26524;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#35782;&#21035;&#20986;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#22810;&#30340;&#21487;&#36830;&#25509;&#34920;&#12290;</title><link>http://arxiv.org/abs/2010.13273</link><description>&lt;p&gt;
&#25968;&#25454;&#28246;&#20013;&#39640;&#32500;&#30456;&#20284;&#24230;&#20026;&#22522;&#30784;&#30340;&#39640;&#25928;&#21487;&#36830;&#25509;&#34920;&#21457;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Joinable Table Discovery in Data Lakes: A High-Dimensional Similarity-Based Approach. (arXiv:2010.13273v4 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.13273
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#32500;&#30456;&#20284;&#24230;&#30340;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#28246;&#20013;&#39640;&#25928;&#22320;&#21457;&#29616;&#21487;&#36830;&#25509;&#34920;&#12290;&#36890;&#36807;&#23558;&#25991;&#26412;&#20540;&#23884;&#20837;&#39640;&#32500;&#21521;&#37327;&#24182;&#20351;&#29992;&#30456;&#20284;&#24615;&#35859;&#35789;&#36830;&#25509;&#21015;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#35299;&#20915;&#31561;&#20540;&#36830;&#25509;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#35782;&#21035;&#20986;&#26356;&#26377;&#24847;&#20041;&#30340;&#32467;&#26524;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#35782;&#21035;&#20986;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#22810;&#30340;&#21487;&#36830;&#25509;&#34920;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#28246;&#20013;&#23547;&#25214;&#21487;&#36830;&#25509;&#34920;&#26159;&#35768;&#22810;&#24212;&#29992;&#30340;&#20851;&#38190;&#36807;&#31243;&#65292;&#20363;&#22914;&#25968;&#25454;&#38598;&#25104;&#12289;&#25968;&#25454;&#22686;&#24378;&#12289;&#25968;&#25454;&#20998;&#26512;&#21644;&#25968;&#25454;&#24066;&#22330;&#12290;&#20256;&#32479;&#30340;&#26041;&#27861;&#21482;&#33021;&#25214;&#21040;&#31561;&#20540;&#36830;&#25509;&#30340;&#34920;&#65292;&#26080;&#27861;&#22788;&#29702;&#25340;&#20889;&#38169;&#35823;&#21644;&#19981;&#21516;&#30340;&#26684;&#24335;&#65292;&#20063;&#26080;&#27861;&#25429;&#25417;&#21040;&#20219;&#20309;&#35821;&#20041;&#36830;&#25509;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PEXESO&#65292;&#19968;&#31181;&#29992;&#20110;&#22312;&#25968;&#25454;&#28246;&#20013;&#21457;&#29616;&#21487;&#36830;&#25509;&#34920;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#23558;&#25991;&#26412;&#20540;&#23884;&#20837;&#21040;&#39640;&#32500;&#21521;&#37327;&#20013;&#65292;&#24182;&#22312;&#39640;&#32500;&#21521;&#37327;&#19978;&#20351;&#29992;&#30456;&#20284;&#24615;&#35859;&#35789;&#26469;&#36830;&#25509;&#21015;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#31561;&#20540;&#36830;&#25509;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#20986;&#26356;&#26377;&#24847;&#20041;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#39640;&#25928;&#22320;&#25214;&#21040;&#20855;&#26377;&#30456;&#20284;&#24615;&#30340;&#21487;&#36830;&#25509;&#34920;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22359;&#21644;&#39564;&#35777;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22522;&#20110;&#20013;&#24515;&#28857;&#30340;&#36807;&#28388;&#25216;&#26415;&#12290;&#38024;&#23545;&#25968;&#25454;&#28246;&#24456;&#22823;&#19988;&#32034;&#24341;&#26080;&#27861;&#36866;&#24212;&#20027;&#20869;&#23384;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20998;&#21306;&#25216;&#26415;&#12290;&#23454;&#39564;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#31561;&#20540;&#36830;&#25509;&#21644;&#20844;&#20849;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#33021;&#22815;&#35782;&#21035;&#20986;&#26356;&#22810;&#30340;&#34920;&#12290;
&lt;/p&gt;
&lt;p&gt;
Finding joinable tables in data lakes is key procedure in many applications such as data integration, data augmentation, data analysis, and data market. Traditional approaches that find equi-joinable tables are unable to deal with misspellings and different formats, nor do they capture any semantic joins. In this paper, we propose PEXESO, a framework for joinable table discovery in data lakes. We embed textual values as high-dimensional vectors and join columns under similarity predicates on high-dimensional vectors, hence to address the limitations of equi-join approaches and identify more meaningful results. To efficiently find joinable tables with similarity, we propose a block-and-verify method that utilizes pivot-based filtering. A partitioning technique is developed to cope with the case when the data lake is large and the index cannot fit in main memory. An experimental evaluation on real datasets shows that our solution identifies substantially more tables than equi-joins and o
&lt;/p&gt;</description></item></channel></rss>