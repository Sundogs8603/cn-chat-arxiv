<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#32467;&#21512;&#31038;&#20250;&#23398;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#26426;&#22120;&#23398;&#20064;&#20844;&#24179;&#24615;&#30340;&#35282;&#24230;&#21644;&#24037;&#20855;&#65292;&#30528;&#30524;&#20110;&#30456;&#20851;&#24615;&#22312;&#20844;&#24179;&#25490;&#24207;&#20013;&#30340;&#24212;&#29992;&#21644;&#20316;&#29992;&#65292;&#24182;&#25512;&#23548;&#20986;&#30456;&#20851;&#24615;&#35780;&#20998;&#24212;&#28385;&#36275;&#30340;&#19968;&#32452;&#26399;&#26395;&#26631;&#20934;&#20197;&#23454;&#29616;&#26377;&#24847;&#20041;&#22320;&#25351;&#23548;&#20844;&#24179;&#24178;&#39044;&#25514;&#26045;&#12290;</title><link>http://arxiv.org/abs/2305.05608</link><description>&lt;p&gt;
&#30456;&#20851;&#24615;&#22312;&#20844;&#24179;&#25490;&#24207;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Role of Relevance in Fair Ranking. (arXiv:2305.05608v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32467;&#21512;&#31038;&#20250;&#23398;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#26426;&#22120;&#23398;&#20064;&#20844;&#24179;&#24615;&#30340;&#35282;&#24230;&#21644;&#24037;&#20855;&#65292;&#30528;&#30524;&#20110;&#30456;&#20851;&#24615;&#22312;&#20844;&#24179;&#25490;&#24207;&#20013;&#30340;&#24212;&#29992;&#21644;&#20316;&#29992;&#65292;&#24182;&#25512;&#23548;&#20986;&#30456;&#20851;&#24615;&#35780;&#20998;&#24212;&#28385;&#36275;&#30340;&#19968;&#32452;&#26399;&#26395;&#26631;&#20934;&#20197;&#23454;&#29616;&#26377;&#24847;&#20041;&#22320;&#25351;&#23548;&#20844;&#24179;&#24178;&#39044;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24179;&#21488;&#22312;&#26426;&#20250;&#33719;&#21462;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65306;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#25490;&#21517;&#36890;&#36807;&#22312;&#25307;&#32856;&#24179;&#21488;&#30340;&#24037;&#20316;&#32844;&#20301;&#12289;&#27714;&#32844;&#32773;&#25110;&#22312;&#32447;&#24066;&#22330;&#30340;&#21334;&#23478;&#20013;&#20998;&#37197;&#26333;&#20809;&#26426;&#20250;&#26469;&#21019;&#24314;&#21644;&#38480;&#21046;&#36873;&#39033;&#12290;&#20026;&#20102;&#36127;&#36131;&#20219;&#22320;&#36825;&#26679;&#20570;&#65292;&#36825;&#20123;&#31038;&#20250;&#30456;&#20851;&#31995;&#32479;&#37319;&#29992;&#21508;&#31181;&#20844;&#24179;&#25514;&#26045;&#21644;&#24178;&#39044;&#25514;&#26045;&#65292;&#20854;&#20013;&#35768;&#22810;&#25514;&#26045;&#35797;&#22270;&#26681;&#25454;&#20215;&#20540;&#20998;&#37197;&#26333;&#20809;&#26426;&#20250;&#12290;&#20294;&#26159;&#65292;&#22240;&#20026;&#36825;&#20123;&#26500;&#36896;&#36890;&#24120;&#19981;&#26159;&#30452;&#25509;&#21487;&#35266;&#23519;&#30340;&#65292;&#25152;&#20197;&#24179;&#21488;&#24517;&#39035;&#20351;&#29992;&#20195;&#29702;&#35780;&#20998;&#65292;&#22914;&#30456;&#20851;&#24615;&#65292;&#24182;&#20174;&#25628;&#32034;&#32773;&#30340;&#34892;&#20026;&#20449;&#21495;&#20013;&#25512;&#26029;&#20986;&#23427;&#20204;&#12290;&#28982;&#32780;&#65292;&#20851;&#38190;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65292;&#21363;&#30456;&#20851;&#24615;&#22312;&#39640;&#39118;&#38505;&#30340;&#20844;&#24179;&#25490;&#24207;&#20013;&#26159;&#21542;&#23653;&#34892;&#20854;&#20316;&#20026;&#20215;&#20540;&#35780;&#20998;&#36825;&#26679;&#30340;&#20316;&#29992;&#12290;&#26412;&#25991;&#32467;&#21512;&#31038;&#20250;&#23398;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#26426;&#22120;&#23398;&#20064;&#20844;&#24179;&#24615;&#30340;&#35282;&#24230;&#21644;&#24037;&#20855;&#65292;&#25512;&#23548;&#20986;&#30456;&#20851;&#24615;&#35780;&#20998;&#24212;&#28385;&#36275;&#30340;&#19968;&#32452;&#26399;&#26395;&#26631;&#20934;&#65292;&#20197;&#20415;&#26377;&#24847;&#20041;&#22320;&#25351;&#23548;&#20844;&#24179;&#24178;&#39044;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online platforms mediate access to opportunity: relevance-based rankings create and constrain options by allocating exposure to job openings and job candidates in hiring platforms, or sellers in a marketplace. In order to do so responsibly, these socially consequential systems employ various fairness measures and interventions, many of which seek to allocate exposure based on worthiness. Because these constructs are typically not directly observable, platforms must instead resort to using proxy scores such as relevance and infer them from behavioral signals such as searcher clicks. Yet, it remains an open question whether relevance fulfills its role as such a worthiness score in high-stakes fair rankings.  In this paper, we combine perspectives and tools from the social sciences, information retrieval, and fairness in machine learning to derive a set of desired criteria that relevance scores should satisfy in order to meaningfully guide fairness interventions. We then empirically show 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#31181;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#23398;&#20064;&#30340;&#25512;&#33616;&#26694;&#26550;&#65292;&#21517;&#20026;MBA&#65292;&#35299;&#20915;&#20102;&#23398;&#20064;&#36890;&#29992;&#19988;&#20934;&#30830;&#29992;&#25143;&#20559;&#22909;&#21644;&#20811;&#26381;&#35266;&#23519;&#21040;&#30340;&#38544;&#24335;&#29992;&#25143;&#21453;&#39304;&#20013;&#30340;&#22122;&#22768;&#21644;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.05585</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#34892;&#20026;&#21305;&#37197;&#26041;&#24335;&#25552;&#39640;&#22522;&#20110;&#38544;&#24335;&#21453;&#39304;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Improving Implicit Feedback-Based Recommendation through Multi-Behavior Alignment. (arXiv:2305.05585v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05585
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#31181;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#23398;&#20064;&#30340;&#25512;&#33616;&#26694;&#26550;&#65292;&#21517;&#20026;MBA&#65292;&#35299;&#20915;&#20102;&#23398;&#20064;&#36890;&#29992;&#19988;&#20934;&#30830;&#29992;&#25143;&#20559;&#22909;&#21644;&#20811;&#26381;&#35266;&#23519;&#21040;&#30340;&#38544;&#24335;&#29992;&#25143;&#21453;&#39304;&#20013;&#30340;&#22122;&#22768;&#21644;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#38544;&#24615;&#21453;&#39304;&#30340;&#25512;&#33616;&#31995;&#32479;&#24448;&#24448;&#20351;&#29992;&#22823;&#37327;&#21333;&#19968;&#31867;&#22411;&#30340;&#38544;&#24335;&#29992;&#25143;&#21453;&#39304;&#65292;&#20363;&#22914;&#28857;&#20987;&#65292;&#20197;&#22686;&#24378;&#23545;&#31232;&#26377;&#30446;&#26631;&#34892;&#20026;&#65292;&#22914;&#36141;&#20080;&#30340;&#39044;&#27979;&#12290;&#38024;&#23545;&#27492;&#31867;&#30446;&#26631;&#34892;&#20026;&#39044;&#27979;&#65292;&#20351;&#29992;&#22810;&#31181;&#31867;&#22411;&#30340;&#38544;&#24335;&#29992;&#25143;&#21453;&#39304;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#23398;&#20064;&#22810;&#31181;&#29992;&#25143;&#34892;&#20026;&#30340;&#30740;&#31350;&#24448;&#24448;&#26410;&#33021;&#35299;&#20915;&#20197;&#19979;&#38382;&#39064;&#65306;&#65288;i&#65289;&#20174;&#19981;&#21516;&#30340;&#34892;&#20026;&#25968;&#25454;&#20998;&#24067;&#20013;&#23398;&#20064;&#36890;&#29992;&#21644;&#20934;&#30830;&#30340;&#29992;&#25143;&#20559;&#22909;&#65307;&#65288;ii&#65289;&#20811;&#26381;&#35266;&#23519;&#21040;&#30340;&#38544;&#24335;&#29992;&#25143;&#21453;&#39304;&#20013;&#30340;&#22122;&#22768;&#21644;&#20559;&#24046;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#34892;&#20026;&#21305;&#37197;&#65288;MBA&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#22810;&#31181;&#34892;&#20026;&#25968;&#25454;&#23398;&#20064;&#30340;&#25512;&#33616;&#26694;&#26550;&#12290;&#25105;&#20204;&#20551;&#35774;&#26469;&#33258;&#21516;&#19968;&#29992;&#25143;&#30340;&#22810;&#31181;&#34892;&#20026;&#65288;&#20363;&#22914;&#28857;&#20987;&#21644;&#36141;&#20080;&#65289;&#24212;&#21453;&#26144;&#35813;&#29992;&#25143;&#31867;&#20284;&#30340;&#20559;&#22909;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;&#28508;&#22312;&#30340;&#36890;&#29992;&#29992;&#25143;&#20559;&#22909;&#35270;&#20026;&#28508;&#22312;&#30340;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems that learn from implicit feedback often use large volumes of a single type of implicit user feedback, such as clicks, to enhance the prediction of sparse target behavior such as purchases. Using multiple types of implicit user feedback for such target behavior prediction purposes is still an open question. Existing studies that attempted to learn from multiple types of user behavior often fail to: (i) learn universal and accurate user preferences from different behavioral data distributions, and (ii) overcome the noise and bias in observed implicit user feedback. To address the above problems, we propose multi-behavior alignment (MBA), a novel recommendation framework that learns from implicit feedback by using multiple types of behavioral data. We conjecture that multiple types of behavior from the same user (e.g., clicks and purchases) should reflect similar preferences of that user. To this end, we regard the underlying universal user preferences as a latent vari
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#30005;&#23376;&#21830;&#21153;&#20013;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#23454;&#29616;&#19968;&#33268;&#30340;&#25991;&#26412;&#20998;&#31867;&#30340;&#26032;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26088;&#22312;&#25913;&#36827;&#20135;&#21697;&#20998;&#31867;&#27169;&#22411;&#30340;&#19968;&#33268;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#29983;&#20135;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.05402</link><description>&lt;p&gt;
&#22312;&#30005;&#23376;&#21830;&#21153;&#20013;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#23454;&#29616;&#19968;&#33268;&#30340;&#25991;&#26412;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Consistent Text Categorization using Data Augmentation in e-Commerce. (arXiv:2305.05402v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#30005;&#23376;&#21830;&#21153;&#20013;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#23454;&#29616;&#19968;&#33268;&#30340;&#25991;&#26412;&#20998;&#31867;&#30340;&#26032;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26088;&#22312;&#25913;&#36827;&#20135;&#21697;&#20998;&#31867;&#27169;&#22411;&#30340;&#19968;&#33268;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#29983;&#20135;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#20998;&#31867;&#26159;&#19968;&#39033;&#20851;&#38190;&#30340;&#12289;&#24191;&#27867;&#24212;&#29992;&#20110;&#24037;&#19994;&#39046;&#22495;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#26088;&#22312;&#25913;&#36827;&#19968;&#23478;&#20027;&#35201;&#32593;&#32476;&#20844;&#21496;&#24050;&#32463;&#22312;&#20351;&#29992;&#30340;&#20135;&#21697;&#20998;&#31867;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#12290;&#22312;&#35813;&#27169;&#22411;&#26680;&#24515;&#20013;&#65292;&#20135;&#21697;&#20998;&#31867;&#27169;&#22411;&#26159;&#19968;&#20010;&#25991;&#26412;&#20998;&#31867;&#27169;&#22411;&#65292;&#25509;&#21463;&#20135;&#21697;&#26631;&#39064;&#20316;&#20026;&#36755;&#20837;&#65292;&#24182;&#20174;&#25968;&#21315;&#20010;&#21487;&#29992;&#20505;&#36873;&#39033;&#20013;&#36755;&#20986;&#26368;&#21512;&#36866;&#30340;&#31867;&#21035;&#12290;&#32463;&#36807;&#36827;&#19968;&#27493;&#35266;&#23519;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#31867;&#20284;&#29289;&#21697;&#26631;&#31614;&#19978;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;&#20363;&#22914;&#65292;&#26631;&#39064;&#20013;&#20851;&#20110;&#39068;&#33394;&#25110;&#23610;&#23544;&#30340;&#23567;&#21464;&#21270;&#65292;&#20250;&#23545;&#27169;&#22411;&#20135;&#29983;&#36739;&#22823;&#24433;&#21709;&#12290;&#36825;&#31181;&#29616;&#35937;&#21487;&#33021;&#20250;&#23545;&#19979;&#28216;&#30340;&#25512;&#33616;&#25110;&#25628;&#32034;&#24212;&#29992;&#36896;&#25104;&#36127;&#38754;&#24433;&#21709;&#65292;&#23548;&#33268;&#29992;&#25143;&#20307;&#39564;&#19979;&#38477;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#23454;&#29616;&#19968;&#33268;&#30340;&#25991;&#26412;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25552;&#39640;&#27169;&#22411;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#20445;&#25345;&#20854;&#29983;&#20135;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The categorization of massive e-Commerce data is a crucial, well-studied task, which is prevalent in industrial settings. In this work, we aim to improve an existing product categorization model that is already in use by a major web company, serving multiple applications. At its core, the product categorization model is a text classification model that takes a product title as an input and outputs the most suitable category out of thousands of available candidates. Upon a closer inspection, we found inconsistencies in the labeling of similar items. For example, minor modifications of the product title pertaining to colors or measurements majorly impacted the model's output. This phenomenon can negatively affect downstream recommendation or search applications, leading to a sub-optimal user experience.  To address this issue, we propose a new framework for consistent text categorization. Our goal is to improve the model's consistency while maintaining its production-level performance. W
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#27861;&#24459;&#30693;&#35782;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;CaseEncoder&#65292;&#38024;&#23545;&#27861;&#24459;&#26696;&#20363;&#30340;&#29305;&#27530;&#39046;&#22495;&#38656;&#27714;&#65292;CaseEncoder&#22312;&#25968;&#25454;&#37319;&#26679;&#21644;&#39044;&#35757;&#32451;&#38454;&#27573;&#20013;&#37117;&#20351;&#29992;&#20102;&#27861;&#24459;&#30693;&#35782;&#65292;&#20854;&#20013;&#21253;&#25324;&#21033;&#29992;&#32454;&#31890;&#24230;&#30340;&#27861;&#24459;&#26465;&#27454;&#20449;&#24687;&#24341;&#23548;&#27491;&#36127;&#26679;&#26412;&#30340;&#36873;&#25321;&#65292;&#20197;&#21450;&#35774;&#35745;&#20102;&#19982;&#30456;&#20851;&#27861;&#24459;&#26696;&#20363;&#30340;&#35780;&#21028;&#26631;&#20934;&#30456;&#19968;&#33268;&#30340;&#27861;&#24459;&#29305;&#23450;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#35813;&#27169;&#22411;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#21644;&#27861;&#24459;&#38382;&#31572;&#20219;&#21153;&#19978;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PLMs&#12290;</title><link>http://arxiv.org/abs/2305.05393</link><description>&lt;p&gt;
CaseEncoder&#65306;&#19968;&#31181;&#34701;&#21512;&#27861;&#24459;&#30693;&#35782;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding. (arXiv:2305.05393v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05393
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#27861;&#24459;&#30693;&#35782;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;CaseEncoder&#65292;&#38024;&#23545;&#27861;&#24459;&#26696;&#20363;&#30340;&#29305;&#27530;&#39046;&#22495;&#38656;&#27714;&#65292;CaseEncoder&#22312;&#25968;&#25454;&#37319;&#26679;&#21644;&#39044;&#35757;&#32451;&#38454;&#27573;&#20013;&#37117;&#20351;&#29992;&#20102;&#27861;&#24459;&#30693;&#35782;&#65292;&#20854;&#20013;&#21253;&#25324;&#21033;&#29992;&#32454;&#31890;&#24230;&#30340;&#27861;&#24459;&#26465;&#27454;&#20449;&#24687;&#24341;&#23548;&#27491;&#36127;&#26679;&#26412;&#30340;&#36873;&#25321;&#65292;&#20197;&#21450;&#35774;&#35745;&#20102;&#19982;&#30456;&#20851;&#27861;&#24459;&#26696;&#20363;&#30340;&#35780;&#21028;&#26631;&#20934;&#30456;&#19968;&#33268;&#30340;&#27861;&#24459;&#29305;&#23450;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#35813;&#27169;&#22411;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#21644;&#27861;&#24459;&#38382;&#31572;&#20219;&#21153;&#19978;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PLMs&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#27861;&#24459;&#20449;&#24687;&#31995;&#32479;&#20013;&#65292;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#26159;&#20851;&#38190;&#30340;&#27969;&#31243;&#12290;&#23613;&#31649;&#36817;&#26399;&#30340;&#30740;&#31350;&#21033;&#29992;&#20102;&#22522;&#20110;&#36890;&#29992;&#39046;&#22495;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#33539;&#24335;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;(PLMs)&#26500;&#24314;&#20102;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#30340;&#27169;&#22411;&#65292;&#20294;&#26159;&#20351;&#29992;&#36890;&#29992;&#39046;&#22495;&#30340;PLMs&#20316;&#20026;&#39592;&#24178;&#27169;&#22411;&#26377;&#20854;&#23616;&#38480;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#26080;&#27861;&#23436;&#20840;&#25429;&#25417;&#27861;&#24459;&#26696;&#20363;&#25991;&#26723;&#20013;&#30340;&#28508;&#22312;&#27861;&#24459;&#29305;&#24449;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CaseEncoder&#65292;&#19968;&#31181;&#27861;&#24459;&#25991;&#26723;&#32534;&#30721;&#22120;&#65292;&#23427;&#22312;&#25968;&#25454;&#37319;&#26679;&#21644;&#39044;&#35757;&#32451;&#38454;&#27573;&#21033;&#29992;&#32454;&#31890;&#24230;&#30340;&#27861;&#24459;&#30693;&#35782;&#12290;&#22312;&#25968;&#25454;&#37319;&#26679;&#38454;&#27573;&#65292;&#25105;&#20204;&#21033;&#29992;&#32454;&#31890;&#24230;&#30340;&#27861;&#24459;&#26465;&#27454;&#20449;&#24687;&#24341;&#23548;&#27491;&#36127;&#26679;&#26412;&#30340;&#36873;&#25321;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35757;&#32451;&#25968;&#25454;&#30340;&#36136;&#37327;&#12290;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19982;&#30456;&#20851;&#27861;&#24459;&#26696;&#20363;&#30340;&#35780;&#21028;&#26631;&#20934;&#30456;&#19968;&#33268;&#30340;&#27861;&#24459;&#29305;&#23450;&#39044;&#35757;&#32451;&#20219;&#21153;&#12290;&#26681;&#25454;&#36825;&#20123;&#20219;&#21153;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#8212;&#8212;&#20559;&#32622;&#22278;&#24418;&#25439;&#22833;(Biased Circle Loss)&#26469;&#22788;&#29702;&#27861;&#24459;&#26696;&#20363;&#25968;&#25454;&#38598;&#20013;&#27491;&#36127;&#26679;&#26412;&#20043;&#38388;&#30340;&#19981;&#24179;&#34913;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;CaseEncoder&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#21644;&#27861;&#24459;&#38382;&#31572;&#20219;&#21153;&#19978;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PLMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Legal case retrieval is a critical process for modern legal information systems. While recent studies have utilized pre-trained language models (PLMs) based on the general domain self-supervised pre-training paradigm to build models for legal case retrieval, there are limitations in using general domain PLMs as backbones. Specifically, these models may not fully capture the underlying legal features in legal case documents. To address this issue, we propose CaseEncoder, a legal document encoder that leverages fine-grained legal knowledge in both the data sampling and pre-training phases. In the data sampling phase, we enhance the quality of the training data by utilizing fine-grained law article information to guide the selection of positive and negative examples. In the pre-training phase, we design legal-specific pre-training tasks that align with the judging criteria of relevant legal cases. Based on these tasks, we introduce an innovative loss function called Biased Circle Loss to 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#65292;&#23558;&#20174;&#29992;&#25143;-&#21830;&#21697;&#20132;&#20114;&#20013;&#23398;&#24471;&#30340;&#20960;&#20309;&#20808;&#39564;&#30693;&#35782;&#19982;&#21464;&#20998;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20026;&#29992;&#25143;&#25552;&#20379;&#26082;&#20855;&#22791;&#25512;&#33616;&#24615;&#33021;&#21448;&#20855;&#26377;&#35299;&#37322;&#24615;&#33021;&#30340;&#35299;&#37322;&#25512;&#33616;&#26381;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.05331</link><description>&lt;p&gt;
&#20855;&#26377;&#20960;&#20309;&#20449;&#24687;&#29942;&#39048;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Explainable Recommender with Geometric Information Bottleneck. (arXiv:2305.05331v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05331
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#65292;&#23558;&#20174;&#29992;&#25143;-&#21830;&#21697;&#20132;&#20114;&#20013;&#23398;&#24471;&#30340;&#20960;&#20309;&#20808;&#39564;&#30693;&#35782;&#19982;&#21464;&#20998;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20026;&#29992;&#25143;&#25552;&#20379;&#26082;&#20855;&#22791;&#25512;&#33616;&#24615;&#33021;&#21448;&#20855;&#26377;&#35299;&#37322;&#24615;&#33021;&#30340;&#35299;&#37322;&#25512;&#33616;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#33021;&#22815;&#35299;&#37322;&#20854;&#25512;&#33616;&#20915;&#31574;&#65292;&#22686;&#24378;&#29992;&#25143;&#23545;&#31995;&#32479;&#30340;&#20449;&#20219;&#12290;&#22823;&#22810;&#25968;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#35201;&#20040;&#20381;&#36182;&#20110;&#20154;&#24037;&#26631;&#27880;&#30340;&#21407;&#29702;&#26469;&#35757;&#32451;&#27169;&#22411;&#20197;&#29983;&#25104;&#35299;&#37322;&#65292;&#35201;&#20040;&#21033;&#29992;&#27880;&#24847;&#26426;&#21046;&#20174;&#35780;&#35770;&#20013;&#25552;&#21462;&#37325;&#35201;&#30340;&#25991;&#26412;&#27573;&#33853;&#20316;&#20026;&#35299;&#37322;&#12290;&#25552;&#21462;&#30340;&#21407;&#29702;&#24448;&#24448;&#23616;&#38480;&#20110;&#21333;&#20010;&#35780;&#35770;&#65292;&#21487;&#33021;&#26080;&#27861;&#35782;&#21035;&#35780;&#35770;&#25991;&#26412;&#20043;&#22806;&#30340;&#38544;&#21547;&#29305;&#24449;&#12290;&#20026;&#20102;&#36991;&#20813;&#26114;&#36149;&#30340;&#20154;&#24037;&#27880;&#37322;&#36807;&#31243;&#24182;&#29983;&#25104;&#36229;&#20986;&#21333;&#20010;&#35780;&#35770;&#30340;&#35299;&#37322;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#20174;&#29992;&#25143;-&#21830;&#21697;&#20132;&#20114;&#20013;&#23398;&#24471;&#30340;&#20960;&#20309;&#20808;&#39564;&#30693;&#35782;&#19982;&#21464;&#20998;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#35813;&#32593;&#32476;&#20174;&#29992;&#25143;-&#21830;&#21697;&#35780;&#35770;&#20013;&#25512;&#26029;&#28508;&#22312;&#22240;&#23376;&#12290;&#21333;&#20010;&#29992;&#25143;-&#21830;&#21697;&#23545;&#30340;&#28508;&#22312;&#22240;&#23376;&#21487;&#29992;&#20110;&#25512;&#33616;&#21644;&#35299;&#37322;&#29983;&#25104;&#65292;&#33258;&#28982;&#22320;&#32487;&#25215;&#20102;&#32534;&#30721;&#22312;&#20808;&#39564;&#30693;&#35782;&#20013;&#30340;&#20840;&#23616;&#29305;&#24449;&#12290;&#19977;&#20010;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#25512;&#33616;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#37117;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable recommender systems can explain their recommendation decisions, enhancing user trust in the systems. Most explainable recommender systems either rely on human-annotated rationales to train models for explanation generation or leverage the attention mechanism to extract important text spans from reviews as explanations. The extracted rationales are often confined to an individual review and may fail to identify the implicit features beyond the review text. To avoid the expensive human annotation process and to generate explanations beyond individual reviews, we propose to incorporate a geometric prior learnt from user-item interactions into a variational network which infers latent factors from user-item reviews. The latent factors from an individual user-item pair can be used for both recommendation and explanation generation, which naturally inherit the global characteristics encoded in the prior knowledge. Experimental results on three e-commerce datasets show that our mo
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#32773;&#25552;&#20986;&#35757;&#32451;&#25490;&#21517;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#25928;&#29575;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#20102;&#20154;&#24037;&#20195;&#30721;&#20999;&#25442;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#23454;&#39564;&#34920;&#26126;&#22312;&#36328;&#35821;&#35328;&#26816;&#32034;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#20013;&#20250;&#24102;&#26469;&#26174;&#33879;&#25913;&#36827;&#65292;&#22312;&#19981;&#24433;&#21709;&#21333;&#35821;&#26816;&#32034;&#30340;&#22522;&#30784;&#19978;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#36828;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26816;&#32034;&#12290;</title><link>http://arxiv.org/abs/2305.05295</link><description>&lt;p&gt;
&#36890;&#36807;&#35757;&#32451;&#20154;&#24037;&#20195;&#30721;&#20999;&#25442;&#25968;&#25454;&#26469;&#25552;&#21319;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data. (arXiv:2305.05295v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05295
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32773;&#25552;&#20986;&#35757;&#32451;&#25490;&#21517;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#25928;&#29575;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#20102;&#20154;&#24037;&#20195;&#30721;&#20999;&#25442;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#23454;&#39564;&#34920;&#26126;&#22312;&#36328;&#35821;&#35328;&#26816;&#32034;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#20013;&#20250;&#24102;&#26469;&#26174;&#33879;&#25913;&#36827;&#65292;&#22312;&#19981;&#24433;&#21709;&#21333;&#35821;&#26816;&#32034;&#30340;&#22522;&#30784;&#19978;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#36828;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26816;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#20197;&#33521;&#35821;&#20026;&#20195;&#34920;&#30340;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#27169;&#22411;&#20197;&#38646;&#26679;&#26412;&#26041;&#24335;&#36801;&#31227;&#21040;&#20854;&#20182;&#35821;&#35328;&#24050;&#25104;&#20026;&#34987;&#24191;&#27867;&#37319;&#29992;&#30340;&#26041;&#27861;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#26597;&#35810;&#21644;&#25991;&#26723;&#20197;&#19981;&#21516;&#35821;&#35328;&#23384;&#22312;&#26102;&#65292;&#38646;&#26679;&#26412;&#25490;&#21517;&#22120;&#30340;&#26377;&#25928;&#24615;&#20250;&#38477;&#20302;&#12290;&#20986;&#20110;&#36825;&#20010;&#21407;&#22240;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#20154;&#24037;&#20195;&#30721;&#20999;&#25442;&#25968;&#25454;&#26469;&#35757;&#32451;&#25490;&#21517;&#27169;&#22411;&#65292;&#32780;&#25105;&#20204;&#29983;&#25104;&#36825;&#20123;&#25968;&#25454;&#26159;&#36890;&#36807;&#21033;&#29992;&#21452;&#35821;&#35789;&#34920;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23581;&#35797;&#20102;&#20174;&#65288;1&#65289;&#36328;&#35821;&#35328;&#35789;&#23884;&#20837;&#21644;&#65288;2&#65289;&#24179;&#34892;&#32500;&#22522;&#30334;&#31185;&#39029;&#38754;&#26631;&#39064;&#24471;&#20986;&#30340;&#35789;&#34920;&#12290;&#25105;&#20204;&#20351;&#29992;mMARCO&#25968;&#25454;&#38598;&#23545;&#28085;&#30422;&#21333;&#35821;IR&#65288;MoIR&#65289;&#12289;&#36328;&#35821;&#35328;IR&#65288;CLIR&#65289;&#21644;&#22810;&#35821;&#35328;IR&#65288;MLIR&#65289;&#30340;36&#31181;&#35821;&#35328;&#23545;&#30340;&#37325;&#25490;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20195;&#30721;&#20999;&#25442;&#21487;&#20197;&#22312;&#20445;&#25345;MoIR&#24615;&#33021;&#31283;&#23450;&#30340;&#21516;&#26102;&#65292;&#22312;CLIR&#20013;&#20135;&#29983;5.1 MRR@10&#30340;&#19968;&#33268;&#21644;&#26174;&#33879;&#22686;&#30410;&#65292;&#20197;&#21450;&#22312;MLIR&#20013;&#20135;&#29983;3.9 MRR@10&#30340;&#22686;&#30410;&#12290;&#20196;&#20154;&#40723;&#33310;&#30340;&#26159;&#65292;&#36828;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#22686;&#30410;&#29305;&#21035;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transferring information retrieval (IR) models from a high-resource language (typically English) to other languages in a zero-shot fashion has become a widely adopted approach. In this work, we show that the effectiveness of zero-shot rankers diminishes when queries and documents are present in different languages. Motivated by this, we propose to train ranking models on artificially code-switched data instead, which we generate by utilizing bilingual lexicons. To this end, we experiment with lexicons induced from (1) cross-lingual word embeddings and (2) parallel Wikipedia page titles. We use the mMARCO dataset to extensively evaluate reranking models on 36 language pairs spanning Monolingual IR (MoIR), Cross-lingual IR (CLIR), and Multilingual IR (MLIR). Our results show that code-switching can yield consistent and substantial gains of 5.1 MRR@10 in CLIR and 3.9 MRR@10 in MLIR, while maintaining stable performance in MoIR. Encouragingly, the gains are especially pronounced for distan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20122;&#39532;&#36874;&#30340;&#26032;&#31995;&#32479;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23558;&#39038;&#23458;&#30340;&#22312;&#32447;&#34892;&#20026;&#26144;&#23556;&#25104;&#20026;&#39640;&#32423;&#21035;&#36141;&#29289;&#24847;&#22270;&#65292;&#20197;&#20415;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#25552;&#20379;&#26356;&#30456;&#20851;&#12289;&#21487;&#35299;&#37322;&#21644;&#22810;&#26679;&#21270;&#30340;&#36141;&#29289;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2305.05279</link><description>&lt;p&gt;
&#23398;&#20064;&#20010;&#24615;&#21270;&#25512;&#33616;&#20197;&#22522;&#20110;&#23458;&#25143;&#36141;&#29289;&#24847;&#22270;
&lt;/p&gt;
&lt;p&gt;
Learning to Personalize Recommendation based on Customers' Shopping Intents. (arXiv:2305.05279v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05279
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20122;&#39532;&#36874;&#30340;&#26032;&#31995;&#32479;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23558;&#39038;&#23458;&#30340;&#22312;&#32447;&#34892;&#20026;&#26144;&#23556;&#25104;&#20026;&#39640;&#32423;&#21035;&#36141;&#29289;&#24847;&#22270;&#65292;&#20197;&#20415;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#25552;&#20379;&#26356;&#30456;&#20851;&#12289;&#21487;&#35299;&#37322;&#21644;&#22810;&#26679;&#21270;&#30340;&#36141;&#29289;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#39038;&#23458;&#30340;&#39640;&#32423;&#21035;&#36141;&#29289;&#24847;&#22270;&#65292;&#22914;&#20182;&#20204;&#21435;&#38706;&#33829;&#25110;&#20030;&#21150;&#29983;&#26085;&#27966;&#23545;&#30340;&#24895;&#26395;&#65292;&#23545;&#20110;&#30005;&#21830;&#24179;&#21488;&#38750;&#24120;&#37325;&#35201;&#65307;&#23427;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#26356;&#30456;&#20851;&#12289;&#21487;&#35299;&#37322;&#21644;&#22810;&#26679;&#21270;&#30340;&#25512;&#33616;&#26469;&#25552;&#39640;&#36141;&#29289;&#20307;&#39564;&#30340;&#36136;&#37327;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23454;&#38469;&#25361;&#25112;&#65292;&#36825;&#31181;&#39640;&#32423;&#21035;&#30340;&#36141;&#29289;&#24847;&#22270;&#22312;&#34892;&#19994;&#20013;&#34987;&#24573;&#35270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20122;&#39532;&#36874;&#30340;&#26032;&#31995;&#32479;&#65292;&#26126;&#30830;&#22320;&#35782;&#21035;&#21644;&#21033;&#29992;&#27599;&#20010;&#23458;&#25143;&#30340;&#39640;&#32423;&#21035;&#36141;&#29289;&#24847;&#22270;&#26469;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#33258;&#21160;&#35782;&#21035;&#20122;&#39532;&#36874;&#23458;&#25143;&#27491;&#22312;&#36861;&#27714;&#30340;&#21508;&#31181;&#39640;&#32423;&#21035;&#30446;&#26631;&#65292;&#22914;&#8220;&#21435;&#38706;&#33829;&#8221;&#21644;&#8220;&#20934;&#22791;&#28023;&#28393;&#27966;&#23545;&#8221;&#12290;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#20102;&#25193;&#23637;&#65288;&#36328;&#36234;21&#20010;&#22269;&#23478;&#30340;14&#31181;&#35821;&#35328;&#65289;&#12290;&#28982;&#21518;&#65292;&#19968;&#20010;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23558;&#27599;&#20010;&#23458;&#25143;&#30340;&#22312;&#32447;&#34892;&#20026;&#65292;&#22914;&#20135;&#21697;&#25628;&#32034;&#21644;&#20010;&#20307;&#39033;&#30446;&#21442;&#19982;&#65292;&#26144;&#23556;&#25104;&#19968;&#32452;&#39640;&#32423;&#21035;&#30340;&#36141;&#29289;&#24847;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the customers' high level shopping intent, such as their desire to go camping or hold a birthday party, is critically important for an E-commerce platform; it can help boost the quality of shopping experience by enabling provision of more relevant, explainable, and diversified recommendations. However, such high level shopping intent has been overlooked in the industry due to practical challenges. In this work, we introduce Amazon's new system that explicitly identifies and utilizes each customer's high level shopping intents for personalizing recommendations. We develop a novel technique that automatically identifies various high level goals being pursued by the Amazon customers, such as "go camping", and "preparing for a beach party". Our solution is in a scalable fashion (in 14 languages across 21 countries). Then a deep learning model maps each customer's online behavior, e.g. product search and individual item engagements, into a subset of high level shopping intents
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33945;&#29305;&#21345;&#32599;&#31574;&#30053;&#65292;&#35813;&#31639;&#27861;&#20027;&#35201;&#21033;&#29992;&#32858;&#21512;&#30340;&#39038;&#23458;&#34892;&#20026;&#29305;&#24449;&#65292;&#24573;&#30053;&#21333;&#20010;&#36141;&#29289;&#32773;&#32423;&#21035;&#30340;&#36807;&#21435;&#27963;&#21160;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#25972;&#21512;&#21382;&#21490;&#36141;&#29289;&#34892;&#20026;&#12289;&#39038;&#23458;&#28508;&#22312;&#36141;&#29289;&#30446;&#26631;&#20197;&#21450;&#39038;&#23458;&#21644;&#20869;&#23481;&#20998;&#31867;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#20135;&#29983;&#26356;&#20010;&#24615;&#21270;&#30340;&#20869;&#23481;&#25490;&#21517;&#65292;&#27979;&#37327;&#20540;&#20026;12.08%&#30340;nDCG&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2305.05267</link><description>&lt;p&gt;
&#20351;&#29992;&#39038;&#23458;&#34920;&#31034;&#23398;&#20064;&#20010;&#24615;&#21270;&#39029;&#38754;&#20869;&#23481;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Learning Personalized Page Content Ranking Using Customer Representation. (arXiv:2305.05267v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05267
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33945;&#29305;&#21345;&#32599;&#31574;&#30053;&#65292;&#35813;&#31639;&#27861;&#20027;&#35201;&#21033;&#29992;&#32858;&#21512;&#30340;&#39038;&#23458;&#34892;&#20026;&#29305;&#24449;&#65292;&#24573;&#30053;&#21333;&#20010;&#36141;&#29289;&#32773;&#32423;&#21035;&#30340;&#36807;&#21435;&#27963;&#21160;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#25972;&#21512;&#21382;&#21490;&#36141;&#29289;&#34892;&#20026;&#12289;&#39038;&#23458;&#28508;&#22312;&#36141;&#29289;&#30446;&#26631;&#20197;&#21450;&#39038;&#23458;&#21644;&#20869;&#23481;&#20998;&#31867;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#20135;&#29983;&#26356;&#20010;&#24615;&#21270;&#30340;&#20869;&#23481;&#25490;&#21517;&#65292;&#27979;&#37327;&#20540;&#20026;12.08%&#30340;nDCG&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#23376;&#21830;&#21153;&#32593;&#31449;&#19978;&#65288;&#20363;&#22914;&#20122;&#39532;&#36874;&#12289;eBay&#31561;&#65289;&#65292;&#26377;&#20016;&#23500;&#30340;&#25512;&#33616;&#20869;&#23481;&#65292;&#21487;&#20197;&#24110;&#21161;&#36141;&#29289;&#32773;&#26356;&#26377;&#25928;&#22320;&#36141;&#29289;&#12290;&#28982;&#32780;&#65292;&#37492;&#20110;&#20135;&#21697;&#20247;&#22810;&#65292;&#36873;&#25321;&#26368;&#30456;&#20851;&#30340;&#20869;&#23481;&#20197;&#20943;&#23569;&#20449;&#24687;&#36807;&#36733;&#30340;&#36127;&#25285;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#30001;&#32447;&#24615;&#22240;&#26524;&#36172;&#21338;&#31639;&#27861;&#39537;&#21160;&#30340;&#20869;&#23481;&#25490;&#21517;&#26381;&#21153;&#65292;&#20197;&#22312;&#27599;&#20010;&#19978;&#19979;&#25991;&#19979;&#20026;&#27599;&#20010;&#36141;&#29289;&#32773;&#25490;&#21517;&#21644;&#36873;&#25321;&#20869;&#23481;&#12290;&#35813;&#31639;&#27861;&#20027;&#35201;&#21033;&#29992;&#32858;&#21512;&#30340;&#39038;&#23458;&#34892;&#20026;&#29305;&#24449;&#65292;&#24573;&#30053;&#21333;&#20010;&#36141;&#29289;&#32773;&#32423;&#21035;&#30340;&#36807;&#21435;&#27963;&#21160;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#21382;&#21490;&#27963;&#21160;&#20013;&#25512;&#26029;&#36141;&#29289;&#32773;&#20852;&#36259;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#25972;&#21512;&#20102;&#21382;&#21490;&#36141;&#29289;&#34892;&#20026;&#12289;&#39038;&#23458;&#28508;&#22312;&#36141;&#29289;&#30446;&#26631;&#20197;&#21450;&#39038;&#23458;&#21644;&#20869;&#23481;&#20998;&#31867;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#35813;&#27169;&#22411;&#20135;&#29983;&#20102;&#26356;&#20010;&#24615;&#21270;&#30340;&#20869;&#23481;&#25490;&#21517;&#65292;&#27979;&#37327;&#20540;&#20026;12.08%&#30340;nDCG&#25552;&#21319;&#12290;&#22312;&#22312;&#32447;A/B&#27979;&#35797;&#29615;&#22659;&#20013;&#65292;&#35813;&#27169;&#22411;&#25552;&#39640;&#20102;0.02%&#30340;&#21830;&#19994;&#24230;&#37327;&#24180;&#21270;&#24433;&#21709;&#65292;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
On E-commerce stores (Amazon, eBay etc.) there are rich recommendation content to help shoppers shopping more efficiently. However given numerous products, it's crucial to select most relevant content to reduce the burden of information overload. We introduced a content ranking service powered by a linear causal bandit algorithm to rank and select content for each shopper under each context. The algorithm mainly leverages aggregated customer behavior features, and ignores single shopper level past activities. We study the problem of inferring shoppers interest from historical activities. We propose a deep learning based bandit algorithm that incorporates historical shopping behavior, customer latent shopping goals, and the correlation between customers and content categories. This model produces more personalized content ranking measured by 12.08% nDCG lift. In the online A/B test setting, the model improved 0.02% annualized commercial impact measured by our business metric, validating
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27969;&#34892;&#24230;&#37492;&#21035;&#20934;&#21017;&#65292;&#21363;&#22312;&#20844;&#24179;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#21463;&#27426;&#36814;&#21644;&#19981;&#21463;&#27426;&#36814;&#30340;&#29289;&#21697;&#24212;&#35813;&#24471;&#21040;&#19982;&#21916;&#27426;&#23427;&#30340;&#29992;&#25143;&#25968;&#37327;&#25104;&#27604;&#20363;&#30340;&#20132;&#20114;&#65292;&#38024;&#23545;&#36825;&#20010;&#20934;&#21017;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#27969;&#34892;&#24230;&#20559;&#24046;&#26694;&#26550;&#65292;&#24182;&#22312;&#22810;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#22312;&#21435;&#20559;&#24046;&#21644;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#26174;&#30528;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2305.05204</link><description>&lt;p&gt;
&#20174;&#20132;&#20114;&#34892;&#20026;&#20013;&#28040;&#38500;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#30340;&#27969;&#34892;&#24230;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Popularity Debiasing from Exposure to Interaction in Collaborative Filtering. (arXiv:2305.05204v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27969;&#34892;&#24230;&#37492;&#21035;&#20934;&#21017;&#65292;&#21363;&#22312;&#20844;&#24179;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#21463;&#27426;&#36814;&#21644;&#19981;&#21463;&#27426;&#36814;&#30340;&#29289;&#21697;&#24212;&#35813;&#24471;&#21040;&#19982;&#21916;&#27426;&#23427;&#30340;&#29992;&#25143;&#25968;&#37327;&#25104;&#27604;&#20363;&#30340;&#20132;&#20114;&#65292;&#38024;&#23545;&#36825;&#20010;&#20934;&#21017;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#27969;&#34892;&#24230;&#20559;&#24046;&#26694;&#26550;&#65292;&#24182;&#22312;&#22810;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#22312;&#21435;&#20559;&#24046;&#21644;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#26174;&#30528;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24448;&#24448;&#21463;&#21040;&#27969;&#34892;&#24230;&#20559;&#35265;&#30340;&#24433;&#21709;&#65292;&#36807;&#24230;&#25512;&#33616;&#28909;&#38376;&#29289;&#21697;&#65292;&#32780;&#29306;&#29298;&#19981;&#21463;&#27426;&#36814;&#30340;&#29289;&#21697;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#36890;&#24120;&#20851;&#27880;&#22914;&#20309;&#30830;&#20445;&#27599;&#20010;&#29289;&#21697;&#30340;&#25512;&#33616;&#27425;&#25968;&#26292;&#38706;&#22312;&#30456;&#31561;&#25110;&#25104;&#27604;&#20363;&#30340;&#24773;&#20917;&#19979;,&#20351;&#29992;&#21453;&#21521;&#20559;&#24046;&#21152;&#26435;&#12289;&#22240;&#26524;&#24178;&#39044;&#25110;&#23545;&#25239;&#35757;&#32451;&#31561;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22686;&#21152;&#19981;&#21463;&#27426;&#36814;&#29289;&#21697;&#30340;&#26333;&#20809;&#29575;&#21487;&#33021;&#19981;&#20250;&#24102;&#26469;&#26356;&#22810;&#30340;&#28857;&#20987;&#25110;&#20132;&#20114;&#65292;&#23548;&#33268;&#21033;&#30410;&#20998;&#37197;&#19981;&#24179;&#34913;&#65292;&#26080;&#27861;&#30495;&#27491;&#23454;&#29616;&#21512;&#29702;&#30340;&#27969;&#34892;&#24230;&#37492;&#21035;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27969;&#34892;&#24230;&#37492;&#21035;&#20934;&#21017;&#65292;&#21363;&#22312;&#19968;&#20010;&#20844;&#24179;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#21463;&#27426;&#36814;&#21644;&#19981;&#21463;&#27426;&#36814;&#30340;&#29289;&#21697;&#24212;&#35813;&#24471;&#21040;&#19982;&#21916;&#27426;&#23427;&#30340;&#29992;&#25143;&#25968;&#37327;&#25104;&#27604;&#20363;&#30340;&#20132;&#20114;&#12290;&#22312;&#35813;&#20934;&#21017;&#30340;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;IPL&#27491;&#21017;&#21270;&#39033;&#30340;&#21435;&#20559;&#24046;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#29702;&#35770;&#19978;&#21487;&#20197;&#23454;&#29616;&#27969;&#34892;&#24230;&#21435;&#20559;&#24046;&#21644;&#25512;&#33616;&#24615;&#33021;&#30340;&#21452;&#36194;&#23616;&#38754;&#12290;&#22312;&#20960;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#20960;&#20010;&#26368;&#20808;&#36827;&#30340;&#22522;&#32447;&#27169;&#22411;&#65292;&#24182;&#22312;&#21435;&#20559;&#24046;&#24615;&#33021;&#21644;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems often suffer from popularity bias, where popular items are overly recommended while sacrificing unpopular items. Existing researches generally focus on ensuring the number of recommendations exposure of each item is equal or proportional, using inverse propensity weighting, causal intervention, or adversarial training. However, increasing the exposure of unpopular items may not bring more clicks or interactions, resulting in skewed benefits and failing in achieving real reasonable popularity debiasing. In this paper, we propose a new criterion for popularity debiasing, i.e., in an unbiased recommender system, both popular and unpopular items should receive Interactions Proportional to the number of users who Like it, namely IPL criterion. Under the guidance of the criterion, we then propose a debiasing framework with IPL regularization term which is theoretically shown to achieve a win-win situation of both popularity debiasing and recommendation performance. Experi
&lt;/p&gt;</description></item><item><title>Autumn&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#12289;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;LSM-tree&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#65292;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#30456;&#37051;&#20004;&#23618;&#20043;&#38388;&#30340;&#23481;&#37327;&#27604;&#26469;&#19981;&#26029;&#25552;&#39640;&#35835;&#24615;&#33021;&#65292;&#20351;&#24471;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#25104;&#26412;&#20174;&#20043;&#21069;&#26368;&#20248;&#30340;$O(logN)$&#22797;&#26434;&#24230;&#20248;&#21270;&#21040;&#20102;$O(\sqrt{logN})$&#12290;</title><link>http://arxiv.org/abs/2305.05074</link><description>&lt;p&gt;
Autumn&#65306;&#22522;&#20110;LSM-tree&#30340;&#21487;&#25193;&#23637;&#30340;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;
&lt;/p&gt;
&lt;p&gt;
Autumn: A Scalable Read Optimized LSM-tree based Key-Value Stores with Fast Point and Range Read Speed. (arXiv:2305.05074v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05074
&lt;/p&gt;
&lt;p&gt;
Autumn&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#12289;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;LSM-tree&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#65292;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#30456;&#37051;&#20004;&#23618;&#20043;&#38388;&#30340;&#23481;&#37327;&#27604;&#26469;&#19981;&#26029;&#25552;&#39640;&#35835;&#24615;&#33021;&#65292;&#20351;&#24471;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#25104;&#26412;&#20174;&#20043;&#21069;&#26368;&#20248;&#30340;$O(logN)$&#22797;&#26434;&#24230;&#20248;&#21270;&#21040;&#20102;$O(\sqrt{logN})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Log Structured Merge Trees (LSM-tree)&#30340;&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35768;&#22810;&#23384;&#20648;&#31995;&#32479;&#20013;&#65292;&#20197;&#25903;&#25345;&#26356;&#26032;&#12289;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#31561;&#21508;&#31181;&#25805;&#20316;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Autumn&#30340;&#21487;&#25193;&#23637;&#30340;&#12289;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;&#22522;&#20110;LSM-tree&#30340;&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#65292;&#23427;&#20855;&#26377;&#26368;&#23569;&#30340;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#25104;&#26412;&#12290;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#30456;&#37051;&#20004;&#23618;&#20043;&#38388;&#30340;&#23481;&#37327;&#27604;&#26469;&#19981;&#26029;&#25552;&#39640;&#35835;&#24615;&#33021;&#65292;&#28857;&#35835;&#21644;&#21306;&#38388;&#35835;&#25104;&#26412;&#20174;&#20043;&#21069;&#26368;&#20248;&#30340;$O(logN)$&#22797;&#26434;&#24230;&#20248;&#21270;&#21040;&#20102;$O(\sqrt{logN})$&#65292;&#24182;&#24212;&#29992;&#20102;&#26032;&#30340;Garnering&#21512;&#24182;&#31574;&#30053;&#12290;Autumn&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#12289;&#38754;&#21521;&#35835;&#25805;&#20316;&#20248;&#21270;&#30340;LSM-tree&#38190;&#20540;&#23384;&#20648;&#24341;&#25806;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Log Structured Merge Trees (LSM-tree) based key-value stores are widely used in many storage systems to support a variety of operations such as updates, point reads, and range reads. Traditionally, LSM-tree's merge policy organizes data into multiple levels of exponentially increasing capacity to support high-speed writes. However, we contend that the traditional merge policies are not optimized for reads. In this work, we present Autumn, a scalable and read optimized LSM-tree based key-value stores with minimal point and range read cost. The key idea in improving the read performance is to dynamically adjust the capacity ratio between two adjacent levels as more data are stored. As a result, smaller levels gradually increase their capacities and merge more often. In particular, the point and range read cost improves from the previous best known $O(logN)$ complexity to $O(\sqrt{logN})$ in Autumn by applying the new novel Garnering merge policy. While Garnering merge policy optimize
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#65292;&#23558;&#26816;&#32034;&#21644;&#29983;&#25104;&#32452;&#21512;&#22312;&#19968;&#36215;&#20197;&#20135;&#29983;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2305.05065</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#26816;&#32034;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Recommender Systems with Generative Retrieval. (arXiv:2305.05065v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#65292;&#23558;&#26816;&#32034;&#21644;&#29983;&#25104;&#32452;&#21512;&#22312;&#19968;&#36215;&#20197;&#20135;&#29983;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20351;&#29992;&#22823;&#35268;&#27169;&#26816;&#32034;&#27169;&#22411;&#36827;&#34892;&#25512;&#33616;&#65292;&#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#65306;&#35757;&#32451;&#21452;&#32534;&#30721;&#27169;&#22411;&#23558;&#26597;&#35810;&#21644;&#20505;&#36873;&#39033;&#23884;&#20837;&#21040;&#30456;&#21516;&#30340;&#31354;&#38388;&#20013;&#65292;&#28982;&#21518;&#20351;&#29992;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26469;&#36873;&#25321;&#32473;&#23450;&#26597;&#35810;&#23884;&#20837;&#30340;&#39030;&#37096;&#20505;&#36873;&#39033;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21333;&#38454;&#27573;&#33539;&#20363;&#65306;&#29983;&#25104;&#24335;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#33258;&#22238;&#24402;&#26041;&#24335;&#22312;&#19968;&#20010;&#38454;&#27573;&#20013;&#35299;&#30721;&#30446;&#26631;&#20505;&#36873;&#39033;&#30340;&#26631;&#35782;&#31526;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#19981;&#26159;&#20026;&#27599;&#20010;&#39033;&#30446;&#20998;&#37197;&#38543;&#26426;&#29983;&#25104;&#30340;&#21407;&#23376;ID&#65292;&#32780;&#26159;&#29983;&#25104;&#35821;&#20041;ID&#65306;&#27599;&#20010;&#39033;&#30446;&#30340;&#35821;&#20041;&#26377;&#24847;&#20041;&#30340;&#20803;&#32452;&#32534;&#30721;&#35789;&#65292;&#23427;&#20316;&#20026;&#20854;&#21807;&#19968;&#26631;&#35782;&#31526;&#12290;&#25105;&#20204;&#20351;&#29992;&#31216;&#20026;RQ-VAE&#30340;&#20998;&#23618;&#26041;&#27861;&#29983;&#25104;&#36825;&#20123;&#32534;&#30721;&#35789;&#12290;&#19968;&#26086;&#25105;&#20204;&#23545;&#25152;&#26377;&#39033;&#30446;&#37117;&#26377;&#20102;&#35821;&#20041;ID&#65292;&#23601;&#20250;&#35757;&#32451;&#22522;&#20110;Transformer&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#26469;&#39044;&#27979;&#19979;&#19968;&#20010;&#39033;&#30446;&#30340;&#35821;&#20041;ID&#12290;&#30001;&#20110;&#36825;&#20010;&#27169;&#22411;&#20197;&#33258;&#22238;&#24402;&#30340;&#26041;&#24335;&#30452;&#25509;&#39044;&#27979;&#26631;&#35782;&#19979;&#19968;&#20010;&#39033;&#30340;&#32534;&#30721;&#35789;&#20803;&#32452;&#65292;&#22240;&#27492;&#23427;&#21487;&#20197;&#23558;&#26816;&#32034;&#21644;&#29983;&#25104;&#32452;&#21512;&#22312;&#19968;&#36215;&#20197;&#20135;&#29983;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommender systems leverage large-scale retrieval models consisting of two stages: training a dual-encoder model to embed queries and candidates in the same space, followed by an Approximate Nearest Neighbor (ANN) search to select top candidates given a query's embedding. In this paper, we propose a new single-stage paradigm: a generative retrieval model which autoregressively decodes the identifiers for the target candidates in one phase. To do this, instead of assigning randomly generated atomic IDs to each item, we generate Semantic IDs: a semantically meaningful tuple of codewords for each item that serves as its unique identifier. We use a hierarchical method called RQ-VAE to generate these codewords. Once we have the Semantic IDs for all the items, a Transformer based sequence-to-sequence model is trained to predict the Semantic ID of the next item. Since this model predicts the tuple of codewords identifying the next item directly in an autoregressive manner, it can be c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#30340; URL &#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#65292;&#20854;&#23398;&#29983;&#27169;&#22411;&#22312;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569; 175 &#20493;&#30340;&#24773;&#20917;&#19979;&#65292;&#31934;&#24230;&#25552;&#21319;&#20102; 9%&#65292;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.05027</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#30340;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Web Content Filtering through knowledge distillation of Large Language Models. (arXiv:2305.05027v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#30340; URL &#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#65292;&#20854;&#23398;&#29983;&#27169;&#22411;&#22312;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569; 175 &#20493;&#30340;&#24773;&#20917;&#19979;&#65292;&#31934;&#24230;&#25552;&#21319;&#20102; 9%&#65292;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340; URL &#20998;&#31867;&#26041;&#27861;&#65292;&#26088;&#22312;&#23454;&#29616;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#30340;&#20027;&#35201;&#30446;&#26631;&#65306;&#20445;&#38556;&#32452;&#32455;&#20813;&#21463;&#27861;&#24459;&#21644;&#20262;&#29702;&#39118;&#38505;&#65292;&#38480;&#21046;&#35775;&#38382;&#39640;&#39118;&#38505;&#25110;&#21487;&#30097;&#32593;&#31449;&#65292;&#20197;&#21450;&#20419;&#36827;&#23433;&#20840;&#30340;&#19987;&#19994;&#24037;&#20316;&#29615;&#22659;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20934;&#30830;&#30340;&#20998;&#31867;&#65292;&#24182;&#21033;&#29992;&#24050;&#26377;&#30340;&#30693;&#35782;&#33976;&#39311;&#25216;&#26415;&#21019;&#24314;&#26356;&#23567;&#12289;&#26356;&#19987;&#19994;&#30340;&#23398;&#29983;&#27169;&#22411;&#65292;&#20197;&#29992;&#20110;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#12290;&#22312;&#23558;&#36890;&#36807;&#22823;&#22411;&#23433;&#20840;&#20379;&#24212;&#21830;&#25910;&#38598;&#30340;&#23458;&#25143;&#36965;&#27979;&#25968;&#25454;&#30340; 30 &#20010;&#19981;&#21516;&#20869;&#23481;&#31867;&#21035;&#30340;&#32593;&#31449;&#36827;&#34892;&#20998;&#31867;&#30340;&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#30340;&#23398;&#29983;&#27169;&#22411;&#36890;&#36807;&#33976;&#39311;&#32467;&#26524;&#23454;&#29616;&#20102; 9% &#30340;&#20998;&#31867;&#31934;&#24230;&#25552;&#21319;&#65292;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23398;&#29983;&#27169;&#22411;&#22312;&#21442;&#25968;&#25968;&#37327;&#19978;&#19982;&#21407;&#22987;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#30456;&#27604;&#20943;&#23569;&#20102; 175 &#20493;&#65292;&#20174;&#32780;&#36798;&#21040;&#20102;&#19982;&#32769;&#24072;&#27169;&#22411;&#30456;&#21305;&#37197;&#30340;&#24615;&#33021;&#65292;&#21487;&#20197;&#29992;&#20110;&#22823;&#35268;&#27169;&#30340;&#22312;&#32447;&#25195;&#25551;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a state-of-the-art approach for URL categorization that leverages the power of Large Language Models (LLMs) to address the primary objectives of web content filtering: safeguarding organizations from legal and ethical risks, limiting access to high-risk or suspicious websites, and fostering a secure and professional work environment. Our method utilizes LLMs to generate accurate classifications and then employs established knowledge distillation techniques to create smaller, more specialized student models tailored for web content filtering. Distillation results in a student model with a 9\% accuracy rate improvement in classifying websites, sourced from customer telemetry data collected by a large security vendor, into 30 distinct content categories based on their URLs, surpassing the current state-of-the-art approach. Our student model matches the performance of the teacher LLM with 175 times less parameters, allowing the model to be used for in-line scanning of large vo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#33258;&#32534;&#30721;&#22120;&#30340; ICU &#20020;&#24202;&#20195;&#30721;&#39044;&#27979;&#65292;&#38024;&#23545;&#19981;&#23436;&#25972;&#30340;&#20020;&#24202;&#20195;&#30721;&#28165;&#21333;&#65292;&#20351;&#29992;&#20102;&#21508;&#31181;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#20197;&#21450;&#20004;&#20010;&#24378;&#22522;&#20934;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#20849;&#29616;&#30340;&#26041;&#27861;&#34920;&#29616;&#30053;&#24494;&#26356;&#22909;&#65292;&#23545;&#25239;&#33258;&#32534;&#30721;&#22120;&#23454;&#29616;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.04992</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#32534;&#30721;&#22120;&#30340; ICU &#20020;&#24202;&#20195;&#30721;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Autoencoder-based prediction of ICU clinical codes. (arXiv:2305.04992v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#33258;&#32534;&#30721;&#22120;&#30340; ICU &#20020;&#24202;&#20195;&#30721;&#39044;&#27979;&#65292;&#38024;&#23545;&#19981;&#23436;&#25972;&#30340;&#20020;&#24202;&#20195;&#30721;&#28165;&#21333;&#65292;&#20351;&#29992;&#20102;&#21508;&#31181;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#20197;&#21450;&#20004;&#20010;&#24378;&#22522;&#20934;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#20849;&#29616;&#30340;&#26041;&#27861;&#34920;&#29616;&#30053;&#24494;&#26356;&#22909;&#65292;&#23545;&#25239;&#33258;&#32534;&#30721;&#22120;&#23454;&#29616;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#30149;&#21382;&#20013;&#35786;&#26029;&#20195;&#30721;&#30340;&#21487;&#29992;&#24615;&#23545;&#20110;&#24739;&#32773;&#25252;&#29702;&#20197;&#21450;&#25253;&#38144;&#30446;&#30340;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23558;&#20854;&#36755;&#20837;&#21040;&#30005;&#23376;&#30149;&#21382;&#20013;&#38750;&#24120;&#32321;&#29712;&#65292;&#32780;&#19988;&#19968;&#20123;&#20020;&#24202;&#20195;&#30721;&#21487;&#33021;&#20250;&#34987;&#24573;&#30053;&#12290;&#38024;&#23545;&#19981;&#23436;&#25972;&#30340;&#20020;&#24202;&#20195;&#30721;&#28165;&#21333;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#23436;&#25972;&#20020;&#24202;&#20195;&#30721;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#36825;&#39033;&#20219;&#21153;&#20013;&#21253;&#21547;&#20854;&#20182;&#20020;&#24202;&#24739;&#32773;&#25968;&#25454;&#30340;&#22686;&#21152;&#39044;&#27979;&#20215;&#20540;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102; MIMIC-III &#25968;&#25454;&#38598;&#65292;&#24182;&#23558;&#23436;&#25972;&#20020;&#24202;&#20195;&#30721;&#30340;&#20219;&#21153;&#26694;&#26550;&#23450;&#20026;&#25512;&#33616;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#21508;&#31181;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#20197;&#21450;&#20004;&#20010;&#24378;&#22522;&#20934;&#65307;&#39033;&#20849;&#29616;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#12290;&#36755;&#20837;&#21253;&#25324; 1&#65289;&#35760;&#24405;&#30340;&#24050;&#30693;&#20020;&#24202;&#20195;&#30721;&#65292;2&#65289;&#20195;&#30721;&#21152;&#21464;&#37327;&#12290;&#22522;&#20110;&#20849;&#29616;&#30340;&#26041;&#27861;&#30053;&#24494;&#34920;&#29616;&#26356;&#22909;&#65288;F1 &#20998;&#25968;=0.26&#65292;&#22343;&#20540;&#24179;&#22343;&#20934;&#30830;&#24230;[MAP]=0.19&#65289;&#65292;&#32780; SVD&#65288;F1=0.24&#65292;MAP=0.18&#65289;&#34920;&#29616;&#36739;&#24046;&#12290;&#28982;&#32780;&#65292;&#24403;&#20195;&#30721;&#21152;&#21464;&#37327;&#26102;&#65292;&#23545;&#25239;&#33258;&#32534;&#30721;&#22120;&#23454;&#29616;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Availability of diagnostic codes in Electronic Health Records (EHRs) is crucial for patient care as well as reimbursement purposes. However, entering them in the EHR is tedious, and some clinical codes may be overlooked. Given an in-complete list of clinical codes, we investigate the performance of ML methods on predicting the complete ones, and assess the added predictive value of including other clinical patient data in this task. We used the MIMIC-III dataset and frame the task of completing the clinical codes as a recommendation problem. We con-sider various autoencoder approaches plus two strong baselines; item co-occurrence and Singular Value Decomposition (SVD). Inputs are 1) a record's known clinical codes, 2) the codes plus variables. The co-occurrence-based ap-proach performed slightly better (F1 score=0.26, Mean Average Precision [MAP]=0.19) than the SVD (F1=0.24, MAP=0.18). However, the adversarial autoencoder achieved the best performance when using the codes plus variable
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22522;&#20110;&#22270;&#36974;&#30422;&#33258;&#32534;&#30721;&#22120;&#30340;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#65292;&#23427;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#26292;&#38706;&#20986;&#24102;&#26377;&#36974;&#30422;&#30340;&#39033;&#30446;&#24207;&#21015;&#65292;&#33258;&#36866;&#24212;&#21160;&#24577;&#25552;&#21462;&#20840;&#23616;&#39033;&#30446;&#36716;&#25442;&#20449;&#24687;&#36827;&#34892;&#33258;&#30417;&#30563;&#22686;&#24378;&#65292;&#22312;&#20855;&#26377;&#36739;&#23569;&#26631;&#35760;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#22987;&#32456;&#27604;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#26041;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#32780;&#19988;&#23545;&#25968;&#25454;&#25439;&#22351;&#21644;&#32570;&#22833;&#24773;&#20917;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.04619</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#24418;&#36974;&#30422;&#33258;&#32534;&#30721;&#22120;&#30340;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Graph Masked Autoencoder for Sequential Recommendation. (arXiv:2305.04619v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04619
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22522;&#20110;&#22270;&#36974;&#30422;&#33258;&#32534;&#30721;&#22120;&#30340;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#65292;&#23427;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#26292;&#38706;&#20986;&#24102;&#26377;&#36974;&#30422;&#30340;&#39033;&#30446;&#24207;&#21015;&#65292;&#33258;&#36866;&#24212;&#21160;&#24577;&#25552;&#21462;&#20840;&#23616;&#39033;&#30446;&#36716;&#25442;&#20449;&#24687;&#36827;&#34892;&#33258;&#30417;&#30563;&#22686;&#24378;&#65292;&#22312;&#20855;&#26377;&#36739;&#23569;&#26631;&#35760;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#22987;&#32456;&#27604;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#26041;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#32780;&#19988;&#23545;&#25968;&#25454;&#25439;&#22351;&#21644;&#32570;&#22833;&#24773;&#20917;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#19968;&#20123;&#24378;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65288;&#20363;&#22914;Transformer&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#65289;&#36890;&#36807;&#39640;&#38454;&#39033;&#20381;&#36182;&#24314;&#27169;&#22312;&#24207;&#21015;&#25512;&#33616;&#20013;&#23454;&#29616;&#20102;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#22312;&#26631;&#31614;&#31232;&#32570;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#36739;&#24046;&#30340;&#34920;&#24449;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#26631;&#31614;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#24050;&#32463;&#24341;&#36215;&#20102;&#36817;&#26399;&#30340;&#20851;&#27880;&#65292;&#36890;&#36807;&#23884;&#20837;&#23545;&#27604;&#26469;&#36827;&#34892;&#33258;&#25105;&#30417;&#30563;&#30340;&#25968;&#25454;&#22686;&#24378;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#23545;&#27604;&#35270;&#22270;&#29983;&#25104;&#31574;&#30053;&#30340;&#25163;&#24037;&#21046;&#23450;&#29305;&#24615;&#65292;&#29616;&#26377;&#30340;CL&#22686;&#24378;&#27169;&#22411;&#19981;&#20165;&#38590;&#20197;&#22312;&#19981;&#21516;&#30340;&#24207;&#21015;&#25512;&#33616;&#20219;&#21153;&#20013;&#20135;&#29983;&#19968;&#33268;&#30340;&#24615;&#33021;&#65292;&#36824;&#21487;&#33021;&#23545;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#22122;&#22768;&#19981;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#37492;&#20110;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#33258;&#36866;&#24212;&#20840;&#23616;&#20449;&#24687;&#25552;&#21462;&#30340;&#22270;&#36974;&#30422;&#33258;&#32534;&#30721;&#22120;&#22686;&#24378;&#30340;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#65288;MAERec&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23427;&#33258;&#28982;&#22320;&#36991;&#20813;&#20102;&#19978;&#36848;&#38382;&#39064;&#65292;&#24471;&#30410;&#20110;&#20854;&#29420;&#29305;&#30340;&#25968;&#25454;&#37325;&#26500;&#26426;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#26292;&#38706;&#20986;&#24102;&#26377;&#36974;&#30422;&#30340;&#39033;&#30446;&#24207;&#21015;&#65292;&#20351;&#34920;&#31034;&#19981;&#20165;&#21033;&#29992;&#26412;&#22320;&#39034;&#24207;&#20449;&#24687;&#65292;&#36824;&#21033;&#29992;&#39033;&#30446;&#20043;&#38388;&#30340;&#20840;&#23616;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#20855;&#26377;&#36739;&#23569;&#26631;&#35760;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#22987;&#32456;&#27604;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#26041;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#32780;&#19988;&#23545;&#25968;&#25454;&#25439;&#22351;&#21644;&#32570;&#22833;&#24773;&#20917;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While some powerful neural network architectures (e.g., Transformer, Graph Neural Networks) have achieved improved performance in sequential recommendation with high-order item dependency modeling, they may suffer from poor representation capability in label scarcity scenarios. To address the issue of insufficient labels, Contrastive Learning (CL) has attracted much attention in recent methods to perform data augmentation through embedding contrasting for self-supervision. However, due to the hand-crafted property of their contrastive view generation strategies, existing CL-enhanced models i) can hardly yield consistent performance on diverse sequential recommendation tasks; ii) may not be immune to user behavior data noise. In light of this, we propose a simple yet effective Graph Masked AutoEncoder-enhanced sequential Recommender system (MAERec) that adaptively and dynamically distills global item transitional information for self-supervised augmentation. It naturally avoids the abov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#20010;&#36328;&#39046;&#22495;&#22686;&#24378;&#32593;&#32476;&#65288;CDAnet&#65289;&#65292;&#33021;&#22815;&#36827;&#34892;&#24322;&#26500;&#36755;&#20837;&#19979;&#30340;&#30693;&#35782;&#36716;&#31227;&#21644;&#29983;&#25104;&#22686;&#24378;&#26679;&#26412;&#20943;&#36731;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.03953</link><description>&lt;p&gt;
&#36328;&#39046;&#22495;&#22686;&#24378;&#32593;&#32476;&#29992;&#20110;&#28857;&#20987;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Cross-domain Augmentation Networks for Click-Through Rate Prediction. (arXiv:2305.03953v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03953
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#20010;&#36328;&#39046;&#22495;&#22686;&#24378;&#32593;&#32476;&#65288;CDAnet&#65289;&#65292;&#33021;&#22815;&#36827;&#34892;&#24322;&#26500;&#36755;&#20837;&#19979;&#30340;&#30693;&#35782;&#36716;&#31227;&#21644;&#29983;&#25104;&#22686;&#24378;&#26679;&#26412;&#20943;&#36731;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31232;&#30095;&#24615;&#26159;&#28857;&#20987;&#29575;&#39044;&#27979;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#24403;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#22826;&#31232;&#30095;&#20197;&#33267;&#20110;&#26080;&#27861;&#23398;&#20064;&#21487;&#38752;&#30340;&#27169;&#22411;&#26102;&#12290;&#26368;&#36817;&#65292;&#20026;&#20102;&#21033;&#29992;&#30456;&#20851;&#39046;&#22495;&#30340;&#26377;&#24847;&#20041;&#25968;&#25454;&#65292;&#35768;&#22810;&#36328;&#39046;&#22495;&#28857;&#20987;&#29575;&#65288;CDCTR&#65289;&#39044;&#27979;&#24037;&#20316;&#24050;&#32463;&#34987;&#24320;&#21457;&#20986;&#26469;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;CDCTR&#24037;&#20316;&#20855;&#26377;&#19981;&#20999;&#23454;&#38469;&#30340;&#38480;&#21046;&#65292;&#38656;&#35201;&#36328;&#39046;&#22495;&#20043;&#38388;&#20855;&#26377;&#23436;&#20840;&#30456;&#21516;&#30340;&#29305;&#24449;&#36755;&#20837;&#65292;&#32780;&#36328;&#39046;&#22495;&#19982;&#19981;&#21516;&#30340;&#29305;&#24449;&#36755;&#20837;&#30340;CDCTR&#23578;&#26410;&#34987;&#24191;&#27867;&#25506;&#32034;&#65292;&#20294;&#36825;&#26159;&#19968;&#20010;&#32039;&#24613;&#21644;&#37325;&#35201;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36328;&#39046;&#22495;&#22686;&#24378;&#32593;&#32476;&#65288;CDAnet&#65289;&#65292;&#33021;&#22815;&#22312;&#20855;&#26377;&#24322;&#26500;&#36755;&#20837;&#30340;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#25191;&#34892;&#30693;&#35782;&#36716;&#31227;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;CDAnet&#21253;&#21547;&#19968;&#20010;&#35774;&#35745;&#33391;&#22909;&#30340;&#32763;&#35793;&#32593;&#32476;&#21644;&#19968;&#20010;&#22686;&#24378;&#32593;&#32476;&#65292;&#36825;&#20004;&#20010;&#32593;&#32476;&#35757;&#32451;&#36807;&#31243;&#26159;&#20381;&#27425;&#36827;&#34892;&#30340;&#12290;&#32763;&#35793;&#32593;&#32476;&#33021;&#22815;&#35745;&#31639;&#20986;&#20855;&#26377;&#24322;&#26500;&#36755;&#20837;&#30340;&#20004;&#20010;&#39046;&#22495;&#30340;&#29305;&#24449;&#65292;&#22686;&#24378;&#32593;&#32476;&#33021;&#22815;&#29983;&#25104;&#22686;&#24378;&#26679;&#26412;&#20197;&#32531;&#35299;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#12290;&#22312;&#20004;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data sparsity is an important issue for click-through rate (CTR) prediction, particularly when user-item interactions is too sparse to learn a reliable model. Recently, many works on cross-domain CTR (CDCTR) prediction have been developed in an effort to leverage meaningful data from a related domain. However, most existing CDCTR works have an impractical limitation that requires homogeneous inputs (\textit{i.e.} shared feature fields) across domains, and CDCTR with heterogeneous inputs (\textit{i.e.} varying feature fields) across domains has not been widely explored but is an urgent and important research problem. In this work, we propose a cross-domain augmentation network (CDAnet) being able to perform knowledge transfer between two domains with \textit{heterogeneous inputs}. Specifically, CDAnet contains a designed translation network and an augmentation network which are trained sequentially. The translation network is able to compute features from two domains with heterogeneous 
&lt;/p&gt;</description></item><item><title>SLIM&#26159;&#19968;&#31181;&#24102;&#20498;&#25490;&#32034;&#24341;&#30340;&#22810;&#21521;&#37327;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#19978;&#19979;&#25991;&#21270;&#20196;&#29260;&#23884;&#20837;&#36827;&#34892;&#31232;&#30095;&#21270;&#22788;&#29702;&#21644;&#26202;&#26399;&#20132;&#20114;&#23454;&#29616;&#26377;&#25928;&#26816;&#32034;&#65292;&#19988;&#21487;&#19982;&#29616;&#25104;&#35789;&#24211;&#25628;&#32034;&#24211;&#23436;&#20840;&#20860;&#23481;&#12290;</title><link>http://arxiv.org/abs/2302.06587</link><description>&lt;p&gt;
SLIM: &#24102;&#20498;&#25490;&#32034;&#24341;&#30340;&#22810;&#21521;&#37327;&#26816;&#32034;&#20013;&#30340;&#31232;&#30095;&#21270;&#26202;&#20114;&#21160;
&lt;/p&gt;
&lt;p&gt;
SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes. (arXiv:2302.06587v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06587
&lt;/p&gt;
&lt;p&gt;
SLIM&#26159;&#19968;&#31181;&#24102;&#20498;&#25490;&#32034;&#24341;&#30340;&#22810;&#21521;&#37327;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#19978;&#19979;&#25991;&#21270;&#20196;&#29260;&#23884;&#20837;&#36827;&#34892;&#31232;&#30095;&#21270;&#22788;&#29702;&#21644;&#26202;&#26399;&#20132;&#20114;&#23454;&#29616;&#26377;&#25928;&#26816;&#32034;&#65292;&#19988;&#21487;&#19982;&#29616;&#25104;&#35789;&#24211;&#25628;&#32034;&#24211;&#23436;&#20840;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#20498;&#25490;&#32034;&#24341;&#30340;&#22810;&#21521;&#37327;( SLIM ) &#26816;&#32034;&#26041;&#27861;&#12290;&#22312;&#22810;&#21521;&#37327;&#26816;&#32034;&#26041;&#27861;&#20013;&#65292;ColBERT&#26159;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#21270;&#20196;&#29260;&#23884;&#20837;&#30340;&#21518;&#26399;&#20132;&#20114;&#26368;&#25104;&#29087;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#26377;&#25928;&#23454;&#29616;ColBERT&#38656;&#35201;&#22797;&#26434;&#30340;&#24037;&#31243;&#65292;&#19981;&#21033;&#20110;&#23454;&#38469;&#24212;&#29992;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;SLIM&#39318;&#20808;&#23558;&#27599;&#20010;&#19978;&#19979;&#25991;&#21270;&#30340;&#20196;&#29260;&#21521;&#37327;&#26144;&#23556;&#21040;&#19968;&#20010;&#31232;&#30095;&#30340;&#39640;&#32500;&#35789;&#27719;&#31354;&#38388;&#65292;&#28982;&#21518;&#22312;&#36825;&#20123;&#31232;&#30095;&#30340;&#20196;&#29260;&#23884;&#20837;&#20043;&#38388;&#25191;&#34892;&#26202;&#26399;&#20132;&#20114;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20004;&#38454;&#27573;&#26816;&#32034;&#20307;&#31995;&#32467;&#26500;&#65292;&#21253;&#25324;&#20498;&#25490;&#32034;&#24341;&#26816;&#32034;&#21644;&#20998;&#25968;&#32454;&#21270;&#27169;&#22359;&#65292;&#20197;&#36817;&#20284;&#31232;&#30095;&#21270;&#30340;&#26202;&#26399;&#20132;&#20114;&#65292;&#24182;&#19982;&#35832;&#22914;Lucene&#36825;&#26679;&#30340;&#29616;&#25104;&#35789;&#24211;&#25628;&#32034;&#24211;&#23436;&#20840;&#20860;&#23481;&#12290;SLIM&#22312;&#21508;&#31181;&#26816;&#32034;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#19982;ColBERT&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#20294;&#20855;&#26377;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces Sparsified Late Interaction for Multi-vector (SLIM) retrieval with inverted indexes. Multi-vector retrieval methods have demonstrated their effectiveness on various retrieval datasets, and among them, ColBERT is the most established method based on the late interaction of contextualized token embeddings of pre-trained language models. However, efficient ColBERT implementations require complex engineering and cannot take advantage of off-the-shelf search libraries, impeding their practical use. To address this issue, SLIM first maps each contextualized token vector to a sparse, high-dimensional lexical space before performing late interaction between these sparse token embeddings. We then introduce an efficient two-stage retrieval architecture that includes inverted index retrieval followed by a score refinement module to approximate the sparsified late interaction, which is fully compatible with off-the-shelf lexical search libraries such as Lucene. SLIM achieves 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#24179;&#34892;&#21644;&#38750;&#24179;&#34892;&#35821;&#26009;&#24211;&#26469;&#25552;&#39640;&#22810;&#35821;&#31181;&#20449;&#24687;&#26816;&#32034;&#30340;&#25928;&#26524;&#65292;&#20165;&#20351;&#29992;&#33521;&#35821;IR&#35757;&#32451;&#25968;&#25454;&#21644;&#19968;&#20123;&#24179;&#34892;&#35821;&#26009;&#24211;&#21363;&#21487;&#22312;&#38750;&#33521;&#35821;&#25968;&#25454;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#26816;&#32034;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2210.06633</link><description>&lt;p&gt;
&#26080;&#20851;&#35821;&#35328;&#30340;&#22810;&#35821;&#31181;&#20449;&#24687;&#26816;&#32034;&#19982;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Language Agnostic Multilingual Information Retrieval with Contrastive Learning. (arXiv:2210.06633v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06633
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#24179;&#34892;&#21644;&#38750;&#24179;&#34892;&#35821;&#26009;&#24211;&#26469;&#25552;&#39640;&#22810;&#35821;&#31181;&#20449;&#24687;&#26816;&#32034;&#30340;&#25928;&#26524;&#65292;&#20165;&#20351;&#29992;&#33521;&#35821;IR&#35757;&#32451;&#25968;&#25454;&#21644;&#19968;&#20123;&#24179;&#34892;&#35821;&#26009;&#24211;&#21363;&#21487;&#22312;&#38750;&#33521;&#35821;&#25968;&#25454;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#26816;&#32034;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35821;&#31181;&#20449;&#24687;&#26816;&#32034;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#22312;&#35768;&#22810;&#35821;&#35328;&#20013;&#33719;&#21462;&#32463;&#36807;&#27880;&#37322;&#30340;&#35757;&#32451;&#25968;&#25454;&#25104;&#26412;&#24456;&#39640;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#22312;&#21482;&#26377;&#33521;&#35821;IR&#35757;&#32451;&#25968;&#25454;&#21644;&#33521;&#35821;&#19982;&#20854;&#20182;&#35821;&#35328;&#20043;&#38388;&#30340;&#19968;&#20123;&#24179;&#34892;&#35821;&#26009;&#24211;&#21487;&#29992;&#26102;&#35757;&#32451;&#22810;&#35821;&#31181;IR&#31995;&#32479;&#12290;&#25105;&#20204;&#21033;&#29992;&#24179;&#34892;&#21644;&#38750;&#24179;&#34892;&#35821;&#26009;&#24211;&#26469;&#25552;&#39640;&#39044;&#35757;&#32451;&#22810;&#35821;&#31181;&#35821;&#35328;&#27169;&#22411;&#30340;&#36328;&#35821;&#35328;&#20256;&#36882;&#33021;&#21147;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#35821;&#20041;&#23545;&#27604;&#25439;&#22833;&#65292;&#20197;&#23545;&#40784;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#30340;&#24179;&#34892;&#21477;&#23376;&#30340;&#34920;&#31034;&#65292;&#20197;&#21450;&#19968;&#31181;&#26032;&#30340;&#35821;&#35328;&#23545;&#27604;&#25439;&#22833;&#65292;&#21033;&#29992;&#24179;&#34892;&#21477;&#23376;&#23545;&#20174;&#38750;&#24179;&#34892;&#35821;&#26009;&#24211;&#20013;&#30340;&#21477;&#23376;&#34920;&#31034;&#20013;&#21024;&#38500;&#35821;&#35328;&#29305;&#23450;&#20449;&#24687;&#12290;&#22312;&#20351;&#29992;&#36825;&#20123;&#25439;&#22833;&#23545;&#33521;&#35821;IR&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#24182;&#22312;&#38750;&#33521;&#35821;&#25968;&#25454;&#19978;&#36827;&#34892;&#38646;-shot&#35780;&#20272;&#26102;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#26126;&#26174;&#30340;&#25913;&#36827;&#65292;&#21516;&#26102;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multilingual information retrieval (IR) is challenging since annotated training data is costly to obtain in many languages. We present an effective method to train multilingual IR systems when only English IR training data and some parallel corpora between English and other languages are available. We leverage parallel and non-parallel corpora to improve the pretrained multilingual language models' cross-lingual transfer ability. We design a semantic contrastive loss to align representations of parallel sentences that share the same semantics in different languages, and a new language contrastive loss to leverage parallel sentence pairs to remove language-specific information in sentence representations from non-parallel corpora. When trained on English IR data with these losses and evaluated zero-shot on non-English data, our model demonstrates significant improvement to prior work on retrieval performance, while it requires much less computational effort. We also demonstrate the valu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;160&#22810;&#31687;&#23398;&#26415;&#20986;&#29256;&#29289;&#30340;&#32508;&#36848;&#24635;&#32467;&#20102;&#35813;&#39046;&#22495;&#30446;&#21069;&#30340;&#30740;&#31350;&#29616;&#29366;&#65292;&#24378;&#35843;&#20102;&#19968;&#20123;&#26377;&#21069;&#36884;&#30340;&#26410;&#26469;&#26041;&#21521;&#65292;&#20363;&#22914;&#38656;&#35201;&#36229;&#36234;&#32479;&#35745;&#24179;&#34913;&#30340;&#26032;&#20844;&#24179;&#24615;&#34913;&#37327;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2205.11127</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20844;&#24179;&#24615;&#65306;&#30740;&#31350;&#29616;&#29366;&#19982;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Fairness in Recommender Systems: Research Landscape and Future Directions. (arXiv:2205.11127v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;160&#22810;&#31687;&#23398;&#26415;&#20986;&#29256;&#29289;&#30340;&#32508;&#36848;&#24635;&#32467;&#20102;&#35813;&#39046;&#22495;&#30446;&#21069;&#30340;&#30740;&#31350;&#29616;&#29366;&#65292;&#24378;&#35843;&#20102;&#19968;&#20123;&#26377;&#21069;&#36884;&#30340;&#26410;&#26469;&#26041;&#21521;&#65292;&#20363;&#22914;&#38656;&#35201;&#36229;&#36234;&#32479;&#35745;&#24179;&#34913;&#30340;&#26032;&#20844;&#24179;&#24615;&#34913;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#21487;&#20197;&#26497;&#22823;&#22320;&#24433;&#21709;&#25105;&#20204;&#22312;&#32447;&#19978;&#30475;&#21040;&#30340;&#20449;&#24687;&#65292;&#20363;&#22914;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#65292;&#20174;&#32780;&#24433;&#21709;&#25105;&#20204;&#30340;&#20449;&#20208;&#12289;&#20915;&#31574;&#21644;&#34892;&#21160;&#12290;&#21516;&#26102;&#65292;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#21033;&#30410;&#30456;&#20851;&#32773;&#21019;&#36896;&#24040;&#22823;&#30340;&#21830;&#19994;&#20215;&#20540;&#12290;&#37492;&#20110;&#36825;&#31181;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#31995;&#32479;&#23545;&#20010;&#20154;&#12289;&#32452;&#32455;&#21644;&#31038;&#20250;&#30340;&#28508;&#22312;&#24433;&#21709;&#36234;&#26469;&#36234;&#22823;&#65292;&#20844;&#24179;&#24615;&#38382;&#39064;&#22312;&#36817;&#24180;&#26469;&#24471;&#21040;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#25512;&#33616;&#31995;&#32479;&#20844;&#24179;&#24615;&#30340;&#30740;&#31350;&#20173;&#28982;&#26159;&#19968;&#20010;&#27491;&#22312;&#21457;&#23637;&#30340;&#39046;&#22495;&#12290;&#22312;&#26412;&#27425;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#22238;&#39038;&#20102;&#36817;&#24180;&#26469;&#22312;&#35813;&#39046;&#22495;&#25552;&#20986;&#30340;&#20844;&#24179;&#24615;&#22522;&#26412;&#27010;&#24565;&#21644;&#35266;&#24565;&#12290;&#38543;&#21518;&#65292;&#36890;&#36807;&#23545;160&#22810;&#31687;&#23398;&#26415;&#20986;&#29256;&#29289;&#30340;&#32508;&#36848;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#36825;&#19968;&#39046;&#22495;&#30446;&#21069;&#30340;&#30740;&#31350;&#29616;&#29366;&#65292;&#20363;&#22914;&#19968;&#33324;&#30740;&#31350;&#26041;&#27861;&#12289;&#20844;&#24179;&#24615;&#25514;&#26045;&#21644;&#31639;&#27861;&#26041;&#27861;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#23545;&#26368;&#36817;&#30740;&#31350;&#30340;&#20998;&#26512;&#25351;&#20986;&#20102;&#26576;&#20123;&#30740;&#31350;&#31354;&#30333;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#35768;&#22810;&#30740;&#31350;&#20013;&#65292;&#23545;&#25552;&#20986;&#30340;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#25552;&#21319;&#23646;&#24615;&#32570;&#20047;&#23454;&#36136;&#24615;&#30340;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#35813;&#35843;&#26597;&#36824;&#24378;&#35843;&#20102;&#19968;&#20123;&#26377;&#21069;&#36884;&#30340;&#26410;&#26469;&#26041;&#21521;&#65292;&#20363;&#22914;&#38656;&#35201;&#36229;&#36234;&#32479;&#35745;&#24179;&#34913;&#30340;&#26032;&#20844;&#24179;&#24615;&#34913;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems can strongly influence which information we see online, e.g., on social media, and thus impact our beliefs, decisions, and actions. At the same time, these systems can create substantial business value for different stakeholders. Given the growing potential impact of such AI-based systems on individuals, organizations, and society, questions of fairness have gained increased attention in recent years. However, research on fairness in recommender systems is still a developing area. In this survey, we first review the fundamental concepts and notions of fairness that were put forward in the area in the recent past. Afterward, through a review of more than 160 scholarly publications, we present an overview of how research in this field is currently operationalized, e.g., in terms of general research methodology, fairness measures, and algorithmic approaches. Overall, our analysis of recent works points to certain research gaps. In particular, we find that in many resea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#19979;&#22522;&#20110;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#30340;&#27010;&#24565;&#25512;&#33616;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#21521;&#19981;&#21516;&#19987;&#19994;&#27700;&#24179;&#30340;&#29992;&#25143;&#31934;&#32454;&#25512;&#33616;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2203.11011</link><description>&lt;p&gt;
&#24378;&#21270;&#22411;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#19979;MOOC&#27010;&#24565;&#25512;&#33616;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Reinforced MOOCs Concept Recommendation in Heterogeneous Information Networks. (arXiv:2203.11011v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11011
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#19979;&#22522;&#20110;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#30340;&#27010;&#24565;&#25512;&#33616;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#21521;&#19981;&#21516;&#19987;&#19994;&#27700;&#24179;&#30340;&#29992;&#25143;&#31934;&#32454;&#25512;&#33616;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#22312;&#32447;&#24320;&#25918;&#35838;&#31243;&#65288;MOOCs&#65289;&#36890;&#36807;&#20114;&#32852;&#32593;&#25552;&#20379;&#24320;&#25918;&#35775;&#38382;&#21644;&#24191;&#27867;&#30340;&#20114;&#21160;&#21442;&#19982;&#65292;&#27491;&#22312;&#36805;&#36895;&#25104;&#20026;&#22312;&#32447;&#21644;&#36828;&#31243;&#23398;&#20064;&#30340;&#39318;&#36873;&#26041;&#24335;&#12290;&#35768;&#22810;MOOC&#24179;&#21488;&#20026;&#29992;&#25143;&#25552;&#20379;&#35838;&#31243;&#25512;&#33616;&#26381;&#21153;&#65292;&#20197;&#25552;&#39640;&#29992;&#25143;&#30340;&#23398;&#20064;&#20307;&#39564;&#12290;&#23613;&#31649;&#36825;&#39033;&#26381;&#21153;&#24456;&#26377;&#29992;&#65292;&#20294;&#22914;&#26524;&#30452;&#25509;&#21521;&#29992;&#25143;&#25512;&#33616;&#35838;&#31243;&#21487;&#33021;&#20250;&#24573;&#35270;&#20182;&#20204;&#19981;&#21516;&#30340;&#19987;&#19994;&#27700;&#24179;&#65292;&#22240;&#27492;&#26412;&#25991;&#32771;&#34385;&#20102;&#27010;&#24565;&#25512;&#33616;&#36825;&#20010;&#38382;&#39064;&#65292;&#21487;&#20197;&#31934;&#32454;&#22320;&#21521;&#29992;&#25143;&#25512;&#33616;&#30693;&#35782;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#8212;&#8212;HinCRec-RL&#26469;&#35299;&#20915;MOOC&#20013;&#30340;&#27010;&#24565;&#25512;&#33616;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#21644;&#24378;&#21270;&#23398;&#20064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#27010;&#24565;&#25512;&#33616;&#38382;&#39064;&#22609;&#36896;&#22312;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#20869;&#65292;&#20197;&#34920;&#24449;&#29992;&#25143;&#21644;&#30693;&#35782;&#27010;&#24565;&#20043;&#38388;&#30340;&#21160;&#24577;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;
Massive open online courses (MOOCs), which offer open access and widespread interactive participation through the internet, are quickly becoming the preferred method for online and remote learning. Several MOOC platforms offer the service of course recommendation to users, to improve the learning experience of users. Despite the usefulness of this service, we consider that recommending courses to users directly may neglect their varying degrees of expertise. To mitigate this gap, we examine an interesting problem of concept recommendation in this paper, which can be viewed as recommending knowledge to users in a fine-grained way. We put forward a novel approach, termed HinCRec-RL, for Concept Recommendation in MOOCs, which is based on Heterogeneous Information Networks and Reinforcement Learning. In particular, we propose to shape the problem of concept recommendation within a reinforcement learning framework to characterize the dynamic interaction between users and knowledge concepts 
&lt;/p&gt;</description></item></channel></rss>