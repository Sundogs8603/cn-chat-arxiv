<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22810;&#39046;&#22495;&#20132;&#20114;&#20449;&#24687;&#21644;&#22806;&#37096;&#30693;&#35782;&#22270;&#26469;&#36827;&#34892;&#26032;&#39046;&#22495;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#19968;&#20010;AI&#21161;&#25163;&#24212;&#29992;&#20013;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.06302</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#30693;&#35782;&#22686;&#24378;&#22312;AI&#21161;&#25163;&#24212;&#29992;&#20013;&#30340;&#38646;&#26679;&#26412;&#21644;&#22810;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multi-Task Knowledge Enhancement for Zero-Shot and Multi-Domain Recommendation in an AI Assistant Application. (arXiv:2306.06302v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22810;&#39046;&#22495;&#20132;&#20114;&#20449;&#24687;&#21644;&#22806;&#37096;&#30693;&#35782;&#22270;&#26469;&#36827;&#34892;&#26032;&#39046;&#22495;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#19968;&#20010;AI&#21161;&#25163;&#24212;&#29992;&#20013;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21830;&#19994;&#19978;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#20173;&#28982;&#38590;&#20197;&#23558;&#26032;&#29992;&#25143;&#25972;&#21512;&#36827;&#21435;&#12290;&#30001;&#20110;&#29992;&#25143;&#32463;&#24120;&#22312;&#19981;&#21516;&#39046;&#22495;&#19982;&#20869;&#23481;&#36827;&#34892;&#20132;&#20114;&#65292;&#22240;&#27492;&#21487;&#20197;&#21033;&#29992;&#29992;&#25143;&#22312;&#20043;&#21069;&#30340;&#39046;&#22495;&#20013;&#30340;&#20132;&#20114;&#26469;&#25913;&#21892;&#20854;&#22312;&#26032;&#39046;&#22495;&#20013;&#30340;&#25512;&#33616;&#65288;&#22810;&#39046;&#22495;&#25512;&#33616;&#65289;&#12290;&#30693;&#35782;&#22270;&#22686;&#24378;&#30340;&#21333;&#19968;&#39046;&#22495;&#25512;&#33616;&#65288;&#30693;&#35782;&#22270;&#22686;&#24378;&#65289;&#30340;&#30740;&#31350;&#32447;&#31243;&#29420;&#31435;&#20110;&#27492;&#20351;&#29992;&#22806;&#37096;&#30693;&#35782;&#22270;&#26469;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#25552;&#20986;&#23558;&#36825;&#20123;&#26041;&#27861;&#32479;&#19968;&#36215;&#26469;&#65306;&#21033;&#29992;&#20854;&#20182;&#39046;&#22495;&#20013;&#30340;&#20132;&#20114;&#20449;&#24687;&#20197;&#21450;&#22806;&#37096;&#30693;&#35782;&#22270;&#26469;&#36827;&#34892;&#26032;&#39046;&#22495;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#24819;&#27861;&#24212;&#29992;&#20110;&#19968;&#20010;&#20174;&#25968;&#30334;&#19975;&#29992;&#25143;&#35831;&#27714;&#30340;&#35270;&#39057;&#12289;&#38899;&#20048;&#21644;&#20070;&#31821;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;&#35813;&#25968;&#25454;&#38598;&#29992;&#20110;&#19968;&#20010;AI&#21161;&#25163;&#24212;&#29992;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have found significant commercial success but still struggle with integrating new users. Since users often interact with content in different domains, it is possible to leverage a user's interactions in previous domains to improve that user's recommendations in a new one (multi-domain recommendation). A separate research thread on knowledge graph enhancement uses external knowledge graphs to improve single domain recommendations (knowledge graph enhancement). Both research threads incorporate related information to improve predictions in a new domain. We propose in this work to unify these approaches: Using information from interactions in other domains as well as external knowledge graphs to make predictions in a new domain that would be impossible with either information source alone. We apply these ideas to a dataset derived from millions of users' requests for content across three domains (videos, music, and books) in a live virtual assistant application. We dem
&lt;/p&gt;</description></item><item><title>GitHub&#26159;&#20840;&#29699;&#26368;&#22823;&#30340;&#21327;&#20316;&#36719;&#20214;&#24320;&#21457;&#24179;&#21488;&#20043;&#19968;&#65292;&#25176;&#31649;&#20102;&#36229;&#36807;8&#20159;&#20010;&#24320;&#25918;&#25968;&#25454;&#25991;&#20214;&#65292;&#20849;&#35745;142TB&#30340;&#25968;&#25454;&#65307;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#36807;&#21435;&#22235;&#24180;&#20013;&#20854;&#24320;&#25918;&#25968;&#25454;&#36164;&#20135;&#32463;&#21382;&#20102;&#21152;&#36895;&#22686;&#38271;&#65292;&#26377;&#21161;&#20110;&#21152;&#36895;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#65292;&#35299;&#20915;&#22797;&#26434;&#31038;&#20250;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.06191</link><description>&lt;p&gt;
GitHub&#19978;&#30340;&#24320;&#25918;&#25968;&#25454;&#65306;&#37322;&#25918;&#20154;&#24037;&#26234;&#33021;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Open Data on GitHub: Unlocking the Potential of AI. (arXiv:2306.06191v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06191
&lt;/p&gt;
&lt;p&gt;
GitHub&#26159;&#20840;&#29699;&#26368;&#22823;&#30340;&#21327;&#20316;&#36719;&#20214;&#24320;&#21457;&#24179;&#21488;&#20043;&#19968;&#65292;&#25176;&#31649;&#20102;&#36229;&#36807;8&#20159;&#20010;&#24320;&#25918;&#25968;&#25454;&#25991;&#20214;&#65292;&#20849;&#35745;142TB&#30340;&#25968;&#25454;&#65307;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#36807;&#21435;&#22235;&#24180;&#20013;&#20854;&#24320;&#25918;&#25968;&#25454;&#36164;&#20135;&#32463;&#21382;&#20102;&#21152;&#36895;&#22686;&#38271;&#65292;&#26377;&#21161;&#20110;&#21152;&#36895;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#65292;&#35299;&#20915;&#22797;&#26434;&#31038;&#20250;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
GitHub&#26159;&#20840;&#29699;&#26368;&#22823;&#30340;&#21327;&#20316;&#36719;&#20214;&#24320;&#21457;&#24179;&#21488;&#20043;&#19968;&#65292;&#25317;&#26377;&#36229;&#36807;1&#20159;&#29992;&#25143;&#65292;&#21516;&#26102;&#20063;&#34987;&#24191;&#27867;&#29992;&#20110;&#24320;&#25918;&#25968;&#25454;&#21327;&#20316;&#65292;&#25176;&#31649;&#20102;&#36229;&#36807;8&#20159;&#20010;&#24320;&#25918;&#25968;&#25454;&#25991;&#20214;&#65292;&#20849;&#35745;142TB&#30340;&#25968;&#25454;&#12290;&#26412;&#30740;&#31350;&#24378;&#35843;&#20102;GitHub&#19978;&#24320;&#25918;&#25968;&#25454;&#30340;&#28508;&#21147;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21152;&#36895;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;GitHub&#19978;&#29616;&#26377;&#30340;&#24320;&#25918;&#25968;&#25454;&#21644;&#29992;&#25143;&#20998;&#20139;&#25968;&#25454;&#38598;&#30340;&#27169;&#24335;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;GitHub&#26159;&#19990;&#30028;&#19978;&#26368;&#22823;&#30340;&#24320;&#25918;&#25968;&#25454;&#25176;&#31649;&#24179;&#21488;&#20043;&#19968;&#65292;&#24182;&#22312;&#36807;&#21435;&#22235;&#24180;&#20013;&#32463;&#21382;&#20102;&#24320;&#25918;&#25968;&#25454;&#36164;&#20135;&#30340;&#21152;&#36895;&#22686;&#38271;&#12290;&#36890;&#36807;&#23545;GitHub&#19978;&#24320;&#25918;&#25968;&#25454;&#30340;&#27010;&#36848;&#65292;&#25105;&#20204;&#26088;&#22312;&#36171;&#20104;&#29992;&#25143;&#21644;&#32452;&#32455;&#20351;&#29992;&#29616;&#26377;&#30340;&#24320;&#25918;&#24335;&#25968;&#25454;&#38598;&#24182;&#25552;&#39640;&#23427;&#20204;&#30340;&#21487;&#21457;&#29616;&#24615;&#65292;&#20174;&#32780;&#26368;&#32456;&#26377;&#21161;&#20110;&#35299;&#20915;&#22797;&#26434;&#30340;&#31038;&#20250;&#38382;&#39064;&#12290;&#25105;&#20204;&#20250;&#23558;&#25910;&#38598;&#21040;&#30340;&#19977;&#20010;&#25968;&#25454;&#38598;&#20316;&#20026;&#24320;&#25918;&#25968;&#25454;&#21457;&#24067;&#22312;&#20197;&#19979;&#38142;&#25509;&#65306;https://gith
&lt;/p&gt;
&lt;p&gt;
GitHub is the world's largest platform for collaborative software development, with over 100 million users. GitHub is also used extensively for open data collaboration, hosting more than 800 million open data files, totaling 142 terabytes of data. This study highlights the potential of open data on GitHub and demonstrates how it can accelerate AI research. We analyze the existing landscape of open data on GitHub and the patterns of how users share datasets. Our findings show that GitHub is one of the largest hosts of open data in the world and has experienced an accelerated growth of open data assets over the past four years. By examining the open data landscape on GitHub, we aim to empower users and organizations to leverage existing open datasets and improve their discoverability -- ultimately contributing to the ongoing AI revolution to help address complex societal issues. We release the three datasets that we have collected to support this analysis as open datasets at https://gith
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.05817</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22914;&#20309;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#21463;&#30410;&#65306;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Can Recommender Systems Benefit from Large Language Models: A Survey. (arXiv:2306.05817v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21305;&#37197;&#20114;&#32852;&#32593;&#24212;&#29992;&#31243;&#24207;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20986;&#20102;&#24778;&#20154;&#30340;&#26032;&#20852;&#33021;&#21147;&#65288;&#20363;&#22914;&#25351;&#20196;&#36319;&#36394;&#12289;&#25512;&#29702;&#65289;&#65292;&#20174;&#32780;&#20026;&#23558;LLM&#35843;&#25972;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#20197;&#25552;&#39640;&#24615;&#33021;&#21644;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#30340;&#30740;&#31350;&#26041;&#21521;&#24102;&#26469;&#20102;&#24076;&#26395;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#24212;&#29992;&#23548;&#21521;&#30340;&#35282;&#24230;&#23545;&#27492;&#30740;&#31350;&#26041;&#21521;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#20004;&#20010;&#27491;&#20132;&#30340;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#23545;&#20110;&#8220;&#22312;&#21738;&#37324;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;LLM&#22312;&#25512;&#33616;&#27969;&#31243;&#30340;&#19981;&#21516;&#38454;&#27573;&#20013;&#21487;&#33021;&#21457;&#25381;&#30340;&#20316;&#29992;&#65292;&#21363;&#29305;&#24449;&#24037;&#31243;&#12289;&#29305;&#24449;&#32534;&#30721;&#22120;&#12289;&#35780;&#20998;/&#25490;&#21517;&#20989;&#25968;&#21644;&#27969;&#31243;&#25511;&#21046;&#22120;&#12290;&#23545;&#20110;&#8220;&#22914;&#20309;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#31574;&#30053;&#65292;&#20174;&#32780;&#24471;&#20986;&#20004;&#20010;&#32454;&#31890;&#24230;&#30340;&#20998;&#31867;&#26631;&#20934;&#65292;&#21363;&#26159;&#21542;&#35843;&#25972;LLM&#21644;&#26159;&#21542;&#23558;LLM&#20316;&#20026;&#29420;&#31435;&#27169;&#22411;&#25110;&#28151;&#21512;&#27169;&#22411;&#32452;&#20214;&#20351;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#23558;LLM&#35843;&#25972;&#21040;RS&#20013;&#30340;&#19968;&#20123;&#25361;&#25112;&#21644;&#28508;&#22312;&#26041;&#21521;&#65292;&#21253;&#25324;&#19982;&#29616;&#26377;&#31995;&#32479;&#30340;&#38598;&#25104;&#12289;&#29992;&#25143;&#21453;&#39304;&#12289;&#35780;&#20272;&#24230;&#37327;&#21644;&#30693;&#35782;&#33976;&#39311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) play important roles to match users' information needs for Internet applications. In natural language processing (NLP) domains, large language model (LLM) has shown astonishing emergent abilities (e.g., instruction following, reasoning), thus giving rise to the promising research direction of adapting LLM to RS for performance enhancements and user experience improvements. In this paper, we conduct a comprehensive survey on this research direction from an application-oriented view. We first summarize existing research works from two orthogonal perspectives: where and how to adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, and pipeline controller. For the "HOW" question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLMs or not, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;RD-Suite&#30340;&#31995;&#32479;&#21270;&#21644;&#32479;&#19968;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35299;&#20915;&#25490;&#21517;&#27169;&#22411;&#33976;&#39311;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.04455</link><description>&lt;p&gt;
RD-Suite: &#19968;&#20010;&#29992;&#20110;&#25490;&#21517;&#33976;&#39311;&#22522;&#20934;&#27979;&#35797;&#30340;&#22871;&#20214;
&lt;/p&gt;
&lt;p&gt;
RD-Suite: A Benchmark for Ranking Distillation. (arXiv:2306.04455v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04455
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;RD-Suite&#30340;&#31995;&#32479;&#21270;&#21644;&#32479;&#19968;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35299;&#20915;&#25490;&#21517;&#27169;&#22411;&#33976;&#39311;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#21517;&#27169;&#22411;&#30340;&#33976;&#39311;&#24050;&#25104;&#20026;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#30340;&#37325;&#35201;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;RD-Suite&#30340;&#31995;&#32479;&#21270;&#21644;&#32479;&#19968;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#23427;&#26159;&#30001;4&#20010;&#22823;&#22411;&#23454;&#38469;&#25968;&#25454;&#38598;&#32452;&#25104;&#30340;&#20219;&#21153;&#22871;&#20214;&#65292;&#20197;&#35299;&#20915;&#27492;&#31867;&#27169;&#22411;&#30340;&#35780;&#20272;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The distillation of ranking models has become an important topic in both academia and industry. In recent years, several advanced methods have been proposed to tackle this problem, often leveraging ranking information from teacher rankers that is absent in traditional classification settings. To date, there is no well-established consensus on how to evaluate this class of models. Moreover, inconsistent benchmarking on a wide range of tasks and datasets make it difficult to assess or invigorate advances in this field. This paper first examines representative prior arts on ranking distillation, and raises three questions to be answered around methodology and reproducibility. To that end, we propose a systematic and unified benchmark, Ranking Distillation Suite (RD-Suite), which is a suite of tasks with 4 large real-world datasets, encompassing two major modalities (textual and numeric) and two applications (standard distillation and distillation transfer). RD-Suite consists of benchmark 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36873;&#25321;&#24615;&#25968;&#23383;&#21270;&#30340;&#37051;&#36817;&#24230;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;&#25628;&#32034;&#38750;&#25968;&#23383;&#21270;&#23454;&#20307;&#20869;&#23481;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.18683</link><description>&lt;p&gt;
&#20854;&#25152;&#22312;&#30340;&#20844;&#21496;&#65306;&#22522;&#20110;&#37051;&#36817;&#24230;&#30340;&#26723;&#26696;&#24211;&#23454;&#20307;&#20869;&#23481;&#32034;&#24341;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Known by the Company it Keeps: Proximity-Based Indexing for Physical Content in Archival Repositories. (arXiv:2305.18683v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36873;&#25321;&#24615;&#25968;&#23383;&#21270;&#30340;&#37051;&#36817;&#24230;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;&#25628;&#32034;&#38750;&#25968;&#23383;&#21270;&#23454;&#20307;&#20869;&#23481;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#23384;&#22312;&#22823;&#37327;&#30340;&#25968;&#23383;&#21270;&#20869;&#23481;&#65292;&#20294;&#37325;&#35201;&#30340;&#23454;&#20307;&#20869;&#23481;&#23384;&#20648;&#22312;&#32440;&#36136;&#25110;&#24494;&#32553;&#33180;&#31561;&#29289;&#29702;&#20171;&#36136;&#20013;&#12290;&#20256;&#32479;&#30340;&#38750;&#25968;&#23383;&#21270;&#20869;&#23481;&#32034;&#24341;&#26041;&#27861;&#26159;&#20351;&#29992;&#25163;&#21160;&#21019;&#24314;&#30340;&#20803;&#25968;&#25454;&#26469;&#25551;&#36848;&#20869;&#23481;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36873;&#25321;&#24615;&#25968;&#23383;&#21270;&#30340;&#23567;&#37096;&#20998;&#20869;&#23481;&#20316;&#20026;&#37051;&#36817;&#24230;&#32034;&#24341;&#22522;&#30784;&#30340;&#26041;&#27861;&#65292;&#20197;&#23558;&#29992;&#25143;&#26356;&#25509;&#36817;&#20182;&#20204;&#27491;&#22312;&#23547;&#25214;&#30340;&#20855;&#20307;&#20869;&#23481;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#20351;&#29992;&#27492;&#26041;&#27861;&#26500;&#24314;&#30340;&#30418;&#32423;&#32034;&#24341;&#21487;&#20197;&#25104;&#20026;&#26377;&#25928;&#30340;&#25628;&#32034;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the plethora of born-digital content, vast troves of important content remain accessible only on physical media such as paper or microfilm. The traditional approach to indexing undigitized content is using manually created metadata that describes content at some level of aggregation (e.g., folder, box, or collection). Searchers led in this way to some subset of the content often must then manually examine substantial quantities of physical media to find what they are looking for. This paper proposes a complementary approach, in which selective digitization of a small portion of the content is used as a basis for proximity-based indexing as a way of bringing the user closer to the specific content for which they are looking. Experiments with 35 boxes of partially digitized US State Department records indicate that box-level indexes built in this way can provide a useful basis for search.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#39033;&#30446;&#30456;&#20851;&#24615;&#30340;&#26032;&#22411;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#65292;&#29992;&#20110;&#25552;&#39640;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#23545;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.10824</link><description>&lt;p&gt;
&#34701;&#21512;&#39033;&#30446;&#30456;&#20851;&#24615;&#30340;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Integrating Item Relevance in Training Loss for Sequential Recommender Systems. (arXiv:2305.10824v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#39033;&#30446;&#30456;&#20851;&#24615;&#30340;&#26032;&#22411;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#65292;&#29992;&#20110;&#25552;&#39640;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#23545;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#26159;&#19968;&#31181;&#21463;&#27426;&#36814;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#23427;&#36890;&#36807;&#23398;&#20064;&#29992;&#25143;&#30340;&#21382;&#21490;&#25968;&#25454;&#26469;&#39044;&#27979;&#29992;&#25143;&#19979;&#19968;&#20010;&#21487;&#33021;&#19982;&#20043;&#20132;&#20114;&#30340;&#39033;&#30446;&#12290;&#28982;&#32780;&#65292;&#29992;&#25143;&#30340;&#20132;&#20114;&#21487;&#33021;&#20250;&#21463;&#21040;&#26469;&#33258;&#24080;&#25143;&#20849;&#20139;&#12289;&#19981;&#19968;&#33268;&#30340;&#20559;&#22909;&#25110;&#24847;&#22806;&#28857;&#20987;&#31561;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#65288;i&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#32771;&#34385;&#22810;&#20010;&#26410;&#26469;&#39033;&#30446;&#30340;&#26032;&#30340;&#35780;&#20272;&#21327;&#35758;&#65292;&#65288;ii&#65289;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20851;&#27880;&#30456;&#20851;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#29992;&#20110;&#35757;&#32451;&#20855;&#26377;&#22810;&#20010;&#26410;&#26469;&#39033;&#30446;&#30340;&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#20351;&#20854;&#23545;&#22122;&#22768;&#26356;&#21152;&#40065;&#26834;&#12290;&#25105;&#20204;&#30340;&#20851;&#27880;&#30456;&#20851;&#24615;&#27169;&#22411;&#22312;&#20256;&#32479;&#35780;&#20272;&#21327;&#35758;&#20013;&#25552;&#39640;&#20102;NDCG@10&#32422;1.2%&#21644;HR&#32422;0.88%&#65292;&#32780;&#22312;&#26032;&#35780;&#20272;&#21327;&#35758;&#20013;&#65292;&#25913;&#36827;&#30340;NDCG@10&#32422;1.63%&#21644;HR&#32422;1.5%&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential Recommender Systems (SRSs) are a popular type of recommender system that learns from a user's history to predict the next item they are likely to interact with. However, user interactions can be affected by noise stemming from account sharing, inconsistent preferences, or accidental clicks. To address this issue, we (i) propose a new evaluation protocol that takes multiple future items into account and (ii) introduce a novel relevance-aware loss function to train a SRS with multiple future items to make it more robust to noise. Our relevance-aware models obtain an improvement of ~1.2% of NDCG@10 and 0.88% in the traditional evaluation protocol, while in the new evaluation protocol, the improvement is ~1.63% of NDCG@10 and ~1.5% of HR w.r.t the best performing models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#24352;&#23558;&#20135;&#21697;&#25628;&#32034;&#30475;&#20316;&#31243;&#24207;&#21512;&#25104;&#65292;&#30456;&#27604;&#21521;&#37327;&#31354;&#38388;&#27169;&#22411;&#26377;&#30528;&#37325;&#22823;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2304.11473</link><description>&lt;p&gt;
(&#21521;&#37327;)&#31354;&#38388;&#19981;&#26159;&#26368;&#21518;&#30340;&#30086;&#22495;&#65306;&#23558;&#20135;&#21697;&#25628;&#32034;&#30475;&#20316;&#31243;&#24207;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
(Vector) Space is Not the Final Frontier: Product Search as Program Synthesis. (arXiv:2304.11473v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11473
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#24352;&#23558;&#20135;&#21697;&#25628;&#32034;&#30475;&#20316;&#31243;&#24207;&#21512;&#25104;&#65292;&#30456;&#27604;&#21521;&#37327;&#31354;&#38388;&#27169;&#22411;&#26377;&#30528;&#37325;&#22823;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#30005;&#23376;&#21830;&#21153;&#30340;&#19981;&#26029;&#22686;&#38271;&#65292;&#24040;&#39069;&#25237;&#36164;&#29992;&#20110;&#20449;&#24687;&#26816;&#32034;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20063;&#38543;&#20043;&#32780;&#26469;&#12290;&#34429;&#28982;&#21521;&#37327;&#31354;&#38388;&#27169;&#22411;&#20027;&#23472;&#20102;&#20135;&#21697;&#25628;&#32034;&#20013;&#30340;&#26816;&#32034;&#27169;&#22411;&#65292;&#20294;&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#30340;&#20986;&#29616;&#65292;&#21521;&#37327;&#21270;&#26412;&#36523;&#20063;&#21457;&#29983;&#20102;&#24040;&#22823;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#31435;&#22330;&#35770;&#25991;&#20197;&#30456;&#21453;&#30340;&#26041;&#24335;&#20027;&#24352;&#65292;&#21363;&#31243;&#24207;&#21512;&#25104;&#23545;&#35768;&#22810;&#26597;&#35810;&#21644;&#24066;&#22330;&#20013;&#30340;&#22823;&#37327;&#21442;&#19982;&#32773;&#25552;&#20379;&#20102;&#37325;&#22823;&#20248;&#21183;&#12290;&#25105;&#20204;&#35814;&#32454;&#35828;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#34892;&#19994;&#37325;&#35201;&#24615;&#65292;&#27010;&#36848;&#20102;&#20855;&#20307;&#23454;&#29616;&#32454;&#33410;&#65292;&#24182;&#22522;&#20110;&#25105;&#20204;&#22312;Tooso&#26500;&#24314;&#31867;&#20284;&#31995;&#32479;&#30340;&#32463;&#39564;&#65292;&#22238;&#31572;&#20102;&#19968;&#20123;&#24120;&#35265;&#30340;&#21453;&#23545;&#24847;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
As ecommerce continues growing, huge investments in ML and NLP for Information Retrieval are following. While the vector space model dominated retrieval modelling in product search - even as vectorization itself greatly changed with the advent of deep learning -, our position paper argues in a contrarian fashion that program synthesis provides significant advantages for many queries and a significant number of players in the market. We detail the industry significance of the proposed approach, sketch implementation details, and address common objections drawing from our experience building a similar system at Tooso.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24635;&#32467;&#20102;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#24212;&#29992;&#21644;&#20248;&#20110;&#30417;&#30563;&#23398;&#20064;&#30340;&#34920;&#29616;&#12290;&#20998;&#26512;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24212;&#29992;RL&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#30456;&#20851;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#25506;&#32034;&#21033;&#29992;&#22256;&#22659;&#12289;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#21644;&#21487;&#35299;&#37322;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2109.10665</link><description>&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Reinforcement Learning for Recommender Systems. (arXiv:2109.10665v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.10665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24635;&#32467;&#20102;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#24212;&#29992;&#21644;&#20248;&#20110;&#30417;&#30563;&#23398;&#20064;&#30340;&#34920;&#29616;&#12290;&#20998;&#26512;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24212;&#29992;RL&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#30456;&#20851;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#25506;&#32034;&#21033;&#29992;&#22256;&#22659;&#12289;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#21644;&#21487;&#35299;&#37322;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#19981;&#21516;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#19979;&#24191;&#27867;&#24212;&#29992;&#65292;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#25214;&#21040;&#26377;&#29992;&#30340;&#20449;&#24687;&#12290;&#29305;&#21035;&#26159;&#65292;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#30001;&#20110;&#20132;&#20114;&#24335;&#21644;&#33258;&#20027;&#23398;&#20064;&#30340;&#33021;&#21147;&#24050;&#25104;&#20026;&#36817;&#24180;&#26469;&#30340;&#26032;&#20852;&#30740;&#31350;&#35838;&#39064;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#26041;&#27861;&#24448;&#24448;&#20248;&#20110;&#22823;&#22810;&#25968;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#23558;RL&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#21508;&#31181;&#25361;&#25112;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#20123;&#25361;&#25112;&#21450;&#30456;&#20851;&#35299;&#20915;&#26041;&#26696;&#65292;&#30740;&#31350;RL&#25512;&#33616;&#31995;&#32479;&#30340;&#30740;&#31350;&#32773;&#21644;&#20174;&#19994;&#32773;&#38656;&#35201;&#19968;&#20010;&#21442;&#32771;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#27010;&#36848;&#12289;&#27604;&#36739;&#21644;&#24635;&#32467;&#22235;&#31181;&#20856;&#22411;&#25512;&#33616;&#22330;&#26223;&#19979;&#24212;&#29992;&#30340;RL&#26041;&#27861;&#65292;&#21253;&#25324;&#20132;&#20114;&#24335;&#25512;&#33616;&#12289;&#23545;&#35805;&#24335;&#25512;&#33616;&#12289;&#24207;&#21015;&#25512;&#33616;&#21644;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#31995;&#32479;&#22320;&#20998;&#26512;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24212;&#29992;RL&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#30456;&#20851;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#25506;&#32034;&#21033;&#29992;&#22256;&#22659;&#12289;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#21644;&#21487;&#35299;&#37322;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have been widely applied in different real-life scenarios to help us find useful information. In particular, Reinforcement Learning (RL) based recommender systems have become an emerging research topic in recent years, owing to the interactive nature and autonomous learning ability. Empirical results show that RL-based recommendation methods often surpass most of supervised learning methods. Nevertheless, there are various challenges of applying RL in recommender systems. To understand the challenges and relevant solutions, there should be a reference for researchers and practitioners working on RL-based recommender systems. To this end, we firstly provide a thorough overview, comparisons, and summarization of RL approaches applied in four typical recommendation scenarios, including interactive recommendation, conversational recommendatin, sequential recommendation, and explainable recommendation. Furthermore, we systematically analyze the challenges and relevant so
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#30446;&#26631;&#25512;&#33616;&#31995;&#32479;&#21450;&#20854;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#65292;&#20026;&#26412;&#39046;&#22495;&#30340;&#30740;&#31350;&#32773;&#25552;&#20379;&#20102;&#19968;&#20221;&#37325;&#35201;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2108.06367</link><description>&lt;p&gt;
&#22810;&#30446;&#26631;&#25512;&#33616;&#31995;&#32479;&#65306;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
Multi-Objective Recommendations: A Tutorial. (arXiv:2108.06367v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.06367
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#30446;&#26631;&#25512;&#33616;&#31995;&#32479;&#21450;&#20854;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#65292;&#20026;&#26412;&#39046;&#22495;&#30340;&#30740;&#31350;&#32773;&#25552;&#20379;&#20102;&#19968;&#20221;&#37325;&#35201;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#19968;&#30452;&#22312;&#20026;&#29992;&#25143;&#20915;&#31574;&#25552;&#20379;&#24110;&#21161;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#36890;&#36807;&#27169;&#22411;&#20248;&#21270;&#21333;&#19968;&#30446;&#26631;&#65288;&#20363;&#22914;&#35780;&#20998;&#39044;&#27979;&#35823;&#24046;&#25110;&#25490;&#21517;&#36136;&#37327;&#65289;&#12290;&#36817;&#24180;&#26469;&#65292;&#38543;&#30528;&#22810;&#21333;&#20803;&#21033;&#30410;&#30456;&#20851;&#32773;&#21644;&#22810;&#20219;&#21153;&#25512;&#33616;&#31995;&#32479;&#30340;&#20986;&#29616;&#65292;&#22810;&#30446;&#26631;&#20248;&#21270;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#22810;&#30446;&#26631;&#25512;&#33616;&#30340;&#27010;&#24565;&#65292;&#24182;&#32467;&#21512;&#26696;&#20363;&#36827;&#34892;&#35752;&#35770;&#12290;&#26412;&#25991;&#34987;&#35270;&#20026;&#20316;&#32773;&#22312;ACM SIGKDD 2021 &#22810;&#30446;&#26631;&#25512;&#33616;&#25945;&#31243;&#30340;&#34917;&#20805;&#26448;&#26009;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RecSys) have been well developed to assist user decision making. Traditional RecSys usually optimize a single objective (e.g., rating prediction errors or ranking quality) in the model. There is an emerging demand in multi-objective optimization recently in RecSys, especially in the area of multi-stakeholder and multi-task recommender systems. This article provides an overview of multi-objective recommendations, followed by the discussions with case studies. The document is considered as a supplementary material for our tutorial on multi-objective recommendations at ACM SIGKDD 2021.
&lt;/p&gt;</description></item></channel></rss>