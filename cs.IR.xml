<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#24314;&#27169;&#25512;&#33616;&#31995;&#32479;&#29983;&#24577;&#31995;&#32479;&#38656;&#35201;&#32771;&#34385;&#21442;&#19982;&#32773;&#28608;&#21169;&#12289;&#34892;&#20026;&#20197;&#21450;&#31574;&#30053;&#24341;&#21457;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;&#38271;&#26399;&#20248;&#21270;&#65292;&#20351;&#29992;&#31038;&#20250;&#36873;&#25321;&#26041;&#27861;&#36827;&#34892;&#26435;&#34913;&#65292;&#24182;&#20943;&#23569;&#20449;&#24687;&#19981;&#23545;&#31216;&#12290;</title><link>http://arxiv.org/abs/2309.06375</link><description>&lt;p&gt;
&#24314;&#27169;&#25512;&#33616;&#31995;&#32479;&#29983;&#24577;&#31995;&#32479;&#65306;&#26426;&#21046;&#35774;&#35745;&#12289;&#24378;&#21270;&#23398;&#20064;&#21644;&#29983;&#25104;&#27169;&#22411;&#30340;&#20132;&#21449;&#30740;&#31350;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Modeling Recommender Ecosystems: Research Challenges at the Intersection of Mechanism Design, Reinforcement Learning and Generative Models. (arXiv:2309.06375v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06375
&lt;/p&gt;
&lt;p&gt;
&#24314;&#27169;&#25512;&#33616;&#31995;&#32479;&#29983;&#24577;&#31995;&#32479;&#38656;&#35201;&#32771;&#34385;&#21442;&#19982;&#32773;&#28608;&#21169;&#12289;&#34892;&#20026;&#20197;&#21450;&#31574;&#30053;&#24341;&#21457;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;&#38271;&#26399;&#20248;&#21270;&#65292;&#20351;&#29992;&#31038;&#20250;&#36873;&#25321;&#26041;&#27861;&#36827;&#34892;&#26435;&#34913;&#65292;&#24182;&#20943;&#23569;&#20449;&#24687;&#19981;&#23545;&#31216;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20301;&#20110;&#28085;&#30422;&#29992;&#25143;&#12289;&#20869;&#23481;&#25552;&#20379;&#21830;&#12289;&#24191;&#21578;&#21830;&#21644;&#20854;&#20182;&#21442;&#19982;&#32773;&#34892;&#20026;&#30340;&#22797;&#26434;&#29983;&#24577;&#31995;&#32479;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#22823;&#22810;&#25968;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#30340;&#37325;&#28857;&#65292;&#20197;&#21450;&#22823;&#22810;&#25968;&#37325;&#35201;&#23454;&#29992;&#25512;&#33616;&#31995;&#32479;&#65292;&#20165;&#38480;&#20110;&#20010;&#21035;&#29992;&#25143;&#25512;&#33616;&#30340;&#23616;&#37096;&#12289;&#30701;&#35270;&#20248;&#21270;&#12290;&#36825;&#32473;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#20026;&#29992;&#25143;&#24102;&#26469;&#30340;&#38271;&#26399;&#25928;&#29992;&#24102;&#26469;&#20102;&#37325;&#22823;&#25104;&#26412;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#22914;&#26524;&#35201;&#26368;&#22823;&#21270;&#31995;&#32479;&#23545;&#36825;&#20123;&#21442;&#19982;&#32773;&#30340;&#20215;&#20540;&#24182;&#25552;&#39640;&#25972;&#20307;&#29983;&#24577;&#31995;&#32479;&#30340;&#8220;&#20581;&#24247;&#8221;&#29366;&#20917;&#65292;&#26377;&#24517;&#35201;&#26126;&#30830;&#22320;&#23545;&#31995;&#32479;&#20013;&#25152;&#26377;&#21442;&#19982;&#32773;&#30340;&#28608;&#21169;&#21644;&#34892;&#20026;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#23545;&#20854;&#31574;&#30053;&#24341;&#21457;&#30340;&#30456;&#20114;&#20316;&#29992;&#36827;&#34892;&#24314;&#27169;&#12290;&#20026;&#27492;&#38656;&#35201;&#65306;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31561;&#25216;&#26415;&#36827;&#34892;&#38271;&#26399;&#20248;&#21270;&#65307;&#20351;&#29992;&#31038;&#20250;&#36873;&#25321;&#26041;&#27861;&#20026;&#19981;&#21516;&#21442;&#19982;&#32773;&#30340;&#25928;&#29992;&#36827;&#34892;&#19981;&#21487;&#36991;&#20813;&#30340;&#26435;&#34913;&#65307;&#20943;&#23569;&#20449;&#24687;&#19981;&#23545;&#31216;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommender systems lie at the heart of complex ecosystems that couple the behavior of users, content providers, advertisers, and other actors. Despite this, the focus of the majority of recommender research -- and most practical recommenders of any import -- is on the local, myopic optimization of the recommendations made to individual users. This comes at a significant cost to the long-term utility that recommenders could generate for its users. We argue that explicitly modeling the incentives and behaviors of all actors in the system -- and the interactions among them induced by the recommender's policy -- is strictly necessary if one is to maximize the value the system brings to these actors and improve overall ecosystem "health". Doing so requires: optimization over long horizons using techniques such as reinforcement learning; making inevitable tradeoffs in the utility that can be generated for different actors using the methods of social choice; reducing information asymm
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21160;&#20316;&#20849;&#29616;&#30340;&#20219;&#21153;&#65292;&#24182;&#21019;&#24314;&#20102;ACE&#25968;&#25454;&#38598;&#20197;&#21450;&#30456;&#24212;&#30340;&#20195;&#30721;&#12290;&#36890;&#36807;&#21033;&#29992;&#35270;&#35273;&#21644;&#25991;&#26412;&#20449;&#24687;&#30340;&#22270;&#38142;&#25509;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#25429;&#25417;&#19981;&#21516;&#25968;&#25454;&#22495;&#20013;&#30340;&#20154;&#31867;&#21160;&#20316;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2309.06219</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#38142;&#25509;&#39044;&#27979;&#22312;&#29983;&#27963;&#26041;&#24335;vlog&#20013;&#30340;&#20154;&#31867;&#21160;&#20316;&#20849;&#29616;
&lt;/p&gt;
&lt;p&gt;
Human Action Co-occurrence in Lifestyle Vlogs using Graph Link Prediction. (arXiv:2309.06219v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06219
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21160;&#20316;&#20849;&#29616;&#30340;&#20219;&#21153;&#65292;&#24182;&#21019;&#24314;&#20102;ACE&#25968;&#25454;&#38598;&#20197;&#21450;&#30456;&#24212;&#30340;&#20195;&#30721;&#12290;&#36890;&#36807;&#21033;&#29992;&#35270;&#35273;&#21644;&#25991;&#26412;&#20449;&#24687;&#30340;&#22270;&#38142;&#25509;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#25429;&#25417;&#19981;&#21516;&#25968;&#25454;&#22495;&#20013;&#30340;&#20154;&#31867;&#21160;&#20316;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21160;&#20316;&#20849;&#29616;&#30340;&#20219;&#21153;&#65292;&#21363;&#30830;&#23450;&#20004;&#20010;&#20154;&#31867;&#21160;&#20316;&#26159;&#21542;&#21487;&#20197;&#22312;&#21516;&#19968;&#26102;&#38388;&#38388;&#38548;&#20869;&#20849;&#29616;&#12290;&#25105;&#20204;&#21019;&#24314;&#24182;&#20844;&#24320;&#20102;ACE&#65288;Action Co-occurrencE&#65289;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#30001;&#32422;12k&#20010;&#20849;&#29616;&#30340;&#35270;&#35273;&#21160;&#20316;&#23545;&#21644;&#23427;&#20204;&#23545;&#24212;&#30340;&#35270;&#39057;&#29255;&#27573;&#32452;&#25104;&#30340;&#22823;&#22411;&#22270;&#24418;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#21033;&#29992;&#35270;&#35273;&#21644;&#25991;&#26412;&#20449;&#24687;&#26469;&#33258;&#21160;&#25512;&#26029;&#20004;&#20010;&#21160;&#20316;&#26159;&#21542;&#20849;&#29616;&#30340;&#22270;&#38142;&#25509;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#24418;&#29305;&#21035;&#36866;&#21512;&#25429;&#25417;&#20154;&#31867;&#21160;&#20316;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#19988;&#25152;&#23398;&#20064;&#30340;&#22270;&#24418;&#34920;&#31034;&#23545;&#20110;&#25105;&#20204;&#30340;&#20219;&#21153;&#26159;&#26377;&#25928;&#30340;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#22495;&#20013;&#25429;&#25417;&#21040;&#26032;&#39062;&#32780;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;&#26412;&#25991;&#20171;&#32461;&#30340;ACE&#25968;&#25454;&#38598;&#21644;&#20195;&#30721;&#21487;&#22312;https://github.com/MichiganNLP/vlog_action_co-occurrence&#20844;&#24320;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the task of automatic human action co-occurrence identification, i.e., determine whether two human actions can co-occur in the same interval of time. We create and make publicly available the ACE (Action Co-occurrencE) dataset, consisting of a large graph of ~12k co-occurring pairs of visual actions and their corresponding video clips. We describe graph link prediction models that leverage visual and textual information to automatically infer if two actions are co-occurring. We show that graphs are particularly well suited to capture relations between human actions, and the learned graph representations are effective for our task and capture novel and relevant information across different data domains. The ACE dataset and the code introduced in this paper are publicly available at https://github.com/MichiganNLP/vlog_action_co-occurrence.
&lt;/p&gt;</description></item><item><title>HAMUR&#26159;&#19968;&#31181;&#36229;&#32423;&#36866;&#37197;&#22120;&#29992;&#20110;&#22788;&#29702;&#22810;&#39046;&#22495;&#25512;&#33616;&#30340;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#24341;&#20837;&#39046;&#22495;&#29305;&#23450;&#36866;&#37197;&#22120;&#21644;&#39046;&#22495;&#20849;&#20139;&#36229;&#32593;&#32476;&#26469;&#35299;&#20915;&#24403;&#21069;&#27169;&#22411;&#20013;&#30340;&#30456;&#20114;&#24178;&#25200;&#21644;&#38745;&#24577;&#21442;&#25968;&#38480;&#21046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.06217</link><description>&lt;p&gt;
HAMUR: &#36229;&#32423;&#36866;&#37197;&#22120;&#29992;&#20110;&#22810;&#39046;&#22495;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
HAMUR: Hyper Adapter for Multi-Domain Recommendation. (arXiv:2309.06217v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06217
&lt;/p&gt;
&lt;p&gt;
HAMUR&#26159;&#19968;&#31181;&#36229;&#32423;&#36866;&#37197;&#22120;&#29992;&#20110;&#22788;&#29702;&#22810;&#39046;&#22495;&#25512;&#33616;&#30340;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#24341;&#20837;&#39046;&#22495;&#29305;&#23450;&#36866;&#37197;&#22120;&#21644;&#39046;&#22495;&#20849;&#20139;&#36229;&#32593;&#32476;&#26469;&#35299;&#20915;&#24403;&#21069;&#27169;&#22411;&#20013;&#30340;&#30456;&#20114;&#24178;&#25200;&#21644;&#38745;&#24577;&#21442;&#25968;&#38480;&#21046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#39046;&#22495;&#25512;&#33616; (MDR) &#22312;&#36817;&#24180;&#26469;&#21463;&#21040;&#20102;&#26174;&#30528;&#20851;&#27880;&#65292;&#23427;&#21033;&#29992;&#22810;&#20010;&#39046;&#22495;&#30340;&#25968;&#25454;&#21516;&#26102;&#22686;&#24378;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340; MDR &#27169;&#22411;&#38754;&#20020;&#20004;&#20010;&#38480;&#21046;&#12290;&#39318;&#20808;&#65292;&#22823;&#22810;&#25968;&#27169;&#22411;&#37319;&#29992;&#26126;&#30830;&#20849;&#20139;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#23548;&#33268;&#23427;&#20204;&#20043;&#38388;&#30456;&#20114;&#24178;&#25200;&#12290;&#20854;&#27425;&#65292;&#30001;&#20110;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#20998;&#24067;&#24046;&#24322;&#65292;&#29616;&#26377;&#26041;&#27861;&#20013;&#38745;&#24577;&#21442;&#25968;&#30340;&#20351;&#29992;&#38480;&#21046;&#20102;&#20854;&#36866;&#24212;&#22810;&#26679;&#39046;&#22495;&#30340;&#28789;&#27963;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411; Hyper Adapter for Multi-Domain Recommendation (HAMUR)&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;HAMUR &#21253;&#25324;&#20004;&#20010;&#32452;&#25104;&#37096;&#20998;&#65306;(1). &#39046;&#22495;&#29305;&#23450;&#36866;&#37197;&#22120;&#65292;&#20316;&#20026;&#19968;&#20010;&#21487;&#26080;&#32541;&#38598;&#25104;&#21040;&#21508;&#31181;&#29616;&#26377;&#30340;&#22810;&#39046;&#22495;&#39592;&#24178;&#27169;&#22411;&#30340;&#25554;&#20214;&#27169;&#22359;&#35774;&#35745;&#65292;&#21644; (2). &#39046;&#22495;&#20849;&#20139;&#36229;&#32593;&#32476;&#65292;&#38544;&#21547;&#22320;&#25429;&#25417;&#39046;&#22495;&#38388;&#30340;&#20849;&#20139;&#20449;&#24687;&#24182;&#21160;&#24577;&#29983;&#25104;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-Domain Recommendation (MDR) has gained significant attention in recent years, which leverages data from multiple domains to enhance their performance concurrently.However, current MDR models are confronted with two limitations. Firstly, the majority of these models adopt an approach that explicitly shares parameters between domains, leading to mutual interference among them. Secondly, due to the distribution differences among domains, the utilization of static parameters in existing methods limits their flexibility to adapt to diverse domains. To address these challenges, we propose a novel model Hyper Adapter for Multi-Domain Recommendation (HAMUR). Specifically, HAMUR consists of two components: (1). Domain-specific adapter, designed as a pluggable module that can be seamlessly integrated into various existing multi-domain backbone models, and (2). Domain-shared hyper-network, which implicitly captures shared information among domains and dynamically generates the parameters fo
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#26032;&#38395;&#25925;&#20107;&#38142;&#30340;&#32858;&#31867;&#65292;&#25913;&#36827;&#21644;&#35780;&#20272;&#20102;&#26032;&#38395;&#25512;&#33616;&#20013;&#20449;&#24687;&#30862;&#29255;&#21270;&#30340;&#26816;&#27979;&#12290;&#30740;&#31350;&#32467;&#26524;&#23545;&#20110;&#34913;&#37327;&#20449;&#24687;&#27969;&#30340;&#23436;&#25972;&#24615;&#21644;&#24433;&#21709;&#27665;&#20027;&#21644;&#20844;&#20849;&#35752;&#35770;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2309.06192</link><description>&lt;p&gt;
&#25552;&#39640;&#21644;&#35780;&#20272;&#26032;&#38395;&#25512;&#33616;&#20013;&#30340;&#20449;&#24687;&#30862;&#29255;&#26816;&#27979;&#19982;&#26032;&#38395;&#25925;&#20107;&#38142;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Improving and Evaluating the Detection of Fragmentation in News Recommendations with the Clustering of News Story Chains. (arXiv:2309.06192v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06192
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#26032;&#38395;&#25925;&#20107;&#38142;&#30340;&#32858;&#31867;&#65292;&#25913;&#36827;&#21644;&#35780;&#20272;&#20102;&#26032;&#38395;&#25512;&#33616;&#20013;&#20449;&#24687;&#30862;&#29255;&#21270;&#30340;&#26816;&#27979;&#12290;&#30740;&#31350;&#32467;&#26524;&#23545;&#20110;&#34913;&#37327;&#20449;&#24687;&#27969;&#30340;&#23436;&#25972;&#24615;&#21644;&#24433;&#21709;&#27665;&#20027;&#21644;&#20844;&#20849;&#35752;&#35770;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#22312;&#22609;&#36896;&#27665;&#20027;&#31038;&#20250;&#20013;&#30340;&#20449;&#24687;&#33719;&#21462;&#26041;&#38754;&#25198;&#28436;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#35282;&#33394;&#12290;&#28982;&#32780;&#65292;&#23558;&#25512;&#33616;&#38024;&#23545;&#29992;&#25143;&#30340;&#20855;&#20307;&#20852;&#36259;&#21487;&#33021;&#23548;&#33268;&#20449;&#24687;&#27969;&#30340;&#20998;&#27495;&#12290;&#20449;&#24687;&#25509;&#35302;&#30340;&#30862;&#29255;&#21270;&#23545;&#20844;&#20849;&#39046;&#22495;&#30340;&#23436;&#25972;&#24615;&#26500;&#25104;&#25361;&#25112;&#65292;&#36827;&#32780;&#24433;&#21709;&#27665;&#20027;&#21644;&#20844;&#20849;&#35752;&#35770;&#12290;&#30862;&#29255;&#21270;&#25351;&#26631;&#37327;&#21270;&#20102;&#26032;&#38395;&#25512;&#33616;&#20013;&#20449;&#24687;&#27969;&#30340;&#30862;&#29255;&#21270;&#31243;&#24230;&#12290;&#20934;&#30830;&#34913;&#37327;&#35813;&#25351;&#26631;&#38656;&#35201;&#23558;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24212;&#29992;&#20110;&#35782;&#21035;&#19981;&#21516;&#30340;&#26032;&#38395;&#20107;&#20214;&#12289;&#25925;&#20107;&#25110;&#26102;&#38388;&#32447;&#12290;&#26412;&#25991;&#23545;&#22312;&#26032;&#38395;&#25512;&#33616;&#20013;&#37327;&#21270;&#20449;&#24687;&#30862;&#29255;&#21270;&#30340;&#21508;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#35843;&#26597;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#26032;&#38395;&#25925;&#20107;&#32858;&#31867;&#30340;&#24615;&#33021;&#24230;&#37327;&#21644;&#19981;&#21516;&#27169;&#25311;&#30340;&#26032;&#38395;&#25512;&#33616;&#22330;&#26223;&#19979;&#30340;&#30862;&#29255;&#21270;&#35780;&#20998;&#35780;&#20272;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
News recommender systems play an increasingly influential role in shaping information access within democratic societies. However, tailoring recommendations to users' specific interests can result in the divergence of information streams. Fragmented access to information poses challenges to the integrity of the public sphere, thereby influencing democracy and public discourse. The Fragmentation metric quantifies the degree of fragmentation of information streams in news recommendations. Accurate measurement of this metric requires the application of Natural Language Processing (NLP) to identify distinct news events, stories, or timelines. This paper presents an extensive investigation of various approaches for quantifying Fragmentation in news recommendations. These approaches are evaluated both intrinsically, by measuring performance on news story clustering, and extrinsically, by assessing the Fragmentation scores of different simulated news recommender scenarios. Our findings demons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38598;&#25104;&#27169;&#22411;&#23558;&#30693;&#35782;&#24211;&#19982;&#26597;&#35810;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23454;&#20307;&#35782;&#21035;&#21644;&#38142;&#25509;&#25361;&#25112;&#12290;&#36890;&#36807;&#25193;&#23637;&#30693;&#35782;&#24211;&#21644;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#65292;&#25552;&#39640;&#20102;&#21484;&#22238;&#29575;&#65292;&#24182;&#20351;&#29992;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#21644;&#22810;&#20803;&#21152;&#24615;&#22238;&#24402;&#26641;&#36807;&#28388;&#32467;&#26524;&#24471;&#21040;&#39640;&#31934;&#24230;&#30340;&#23454;&#20307;&#35782;&#21035;&#21644;&#38142;&#25509;&#12290;&#26368;&#32456;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;0.535&#30340;F1&#20998;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.06175</link><description>&lt;p&gt;
AKEM: &#21033;&#29992;&#38598;&#25104;&#27169;&#22411;&#23558;&#30693;&#35782;&#24211;&#19982;&#26597;&#35810;&#23545;&#40784;&#20197;&#36827;&#34892;&#23454;&#20307;&#35782;&#21035;&#21644;&#38142;&#25509;
&lt;/p&gt;
&lt;p&gt;
AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity Recognition and Linking. (arXiv:2309.06175v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06175
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38598;&#25104;&#27169;&#22411;&#23558;&#30693;&#35782;&#24211;&#19982;&#26597;&#35810;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23454;&#20307;&#35782;&#21035;&#21644;&#38142;&#25509;&#25361;&#25112;&#12290;&#36890;&#36807;&#25193;&#23637;&#30693;&#35782;&#24211;&#21644;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#65292;&#25552;&#39640;&#20102;&#21484;&#22238;&#29575;&#65292;&#24182;&#20351;&#29992;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#21644;&#22810;&#20803;&#21152;&#24615;&#22238;&#24402;&#26641;&#36807;&#28388;&#32467;&#26524;&#24471;&#21040;&#39640;&#31934;&#24230;&#30340;&#23454;&#20307;&#35782;&#21035;&#21644;&#38142;&#25509;&#12290;&#26368;&#32456;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;0.535&#30340;F1&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;NLPCC 2015&#20013;&#23454;&#20307;&#35782;&#21035;&#21644;&#38142;&#25509;&#25361;&#25112;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#20219;&#21153;&#21253;&#25324;&#20174;&#30701;&#25628;&#32034;&#26597;&#35810;&#20013;&#25552;&#21462;&#21629;&#21517;&#23454;&#20307;&#30340;&#25552;&#21450;&#65292;&#24182;&#23558;&#20854;&#38142;&#25509;&#21040;&#21442;&#32771;&#20013;&#25991;&#30693;&#35782;&#24211;&#20013;&#30340;&#23454;&#20307;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#25193;&#23637;&#29616;&#26377;&#30693;&#35782;&#24211;&#65292;&#24182;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#35782;&#21035;&#20505;&#36873;&#23454;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#21484;&#22238;&#29575;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20174;&#20505;&#36873;&#23454;&#20307;&#20013;&#25552;&#21462;&#29305;&#24449;&#65292;&#24182;&#21033;&#29992;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#21644;&#22810;&#20803;&#21152;&#24615;&#22238;&#24402;&#26641;&#20316;&#20026;&#35780;&#20998;&#20989;&#25968;&#26469;&#36807;&#28388;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24212;&#29992;&#35268;&#21017;&#26469;&#36827;&#19968;&#27493;&#32454;&#21270;&#32467;&#26524;&#21644;&#25552;&#39640;&#31934;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#36798;&#21040;&#20102;0.535&#30340;F1&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel approach to address the Entity Recognition and Linking Challenge at NLPCC 2015. The task involves extracting named entity mentions from short search queries and linking them to entities within a reference Chinese knowledge base. To tackle this problem, we first expand the existing knowledge base and utilize external knowledge to identify candidate entities, thereby improving the recall rate. Next, we extract features from the candidate entities and utilize Support Vector Regression and Multiple Additive Regression Tree as scoring functions to filter the results. Additionally, we apply rules to further refine the results and enhance precision. Our method is computationally efficient and achieves an F1 score of 0.535.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#39044;&#31639;&#19979;&#65292;&#23545;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25490;&#24207;&#22120;&#36827;&#34892;&#24494;&#35843;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#35266;&#23519;&#21457;&#29616;&#65292;&#22312;&#19981;&#21516;&#38543;&#26426;&#36873;&#25321;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#26102;&#65292;&#26377;&#25928;&#24615;&#23384;&#22312;&#24456;&#22823;&#21464;&#24322;&#24615;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#20027;&#21160;&#36873;&#25321;&#23545;&#25490;&#24207;&#22120;&#25928;&#26524;&#31215;&#26497;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#65292;&#21487;&#20197;&#23454;&#29616;&#26377;&#25928;&#24615;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2309.06131</link><description>&lt;p&gt;
&#23545;&#31070;&#32463;&#25490;&#24207;&#22120;&#36827;&#34892;&#24494;&#35843;&#30340;&#25968;&#25454;&#26631;&#27880;&#65311;&#24403;&#21069;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#24182;&#19981;&#27604;&#38543;&#26426;&#36873;&#25321;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Annotating Data for Fine-Tuning a Neural Ranker? Current Active Learning Strategies are not Better than Random Selection. (arXiv:2309.06131v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06131
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#39044;&#31639;&#19979;&#65292;&#23545;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25490;&#24207;&#22120;&#36827;&#34892;&#24494;&#35843;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#35266;&#23519;&#21457;&#29616;&#65292;&#22312;&#19981;&#21516;&#38543;&#26426;&#36873;&#25321;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#26102;&#65292;&#26377;&#25928;&#24615;&#23384;&#22312;&#24456;&#22823;&#21464;&#24322;&#24615;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#20027;&#21160;&#36873;&#25321;&#23545;&#25490;&#24207;&#22120;&#25928;&#26524;&#31215;&#26497;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#65292;&#21487;&#20197;&#23454;&#29616;&#26377;&#25928;&#24615;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#30340;&#25628;&#32034;&#26041;&#27861;&#30456;&#27604;&#32479;&#35745;&#21644;&#26089;&#26399;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#26174;&#31034;&#20986;&#20102;&#24040;&#22823;&#30340;&#26377;&#25928;&#24615;&#25552;&#21319;&#12290;&#28982;&#32780;&#65292;&#24494;&#35843;&#22522;&#20110;PLM&#30340;&#25490;&#24207;&#22120;&#38656;&#35201;&#22823;&#37327;&#30340;&#26631;&#27880;&#35757;&#32451;&#25968;&#25454;&#12290;&#26631;&#27880;&#25968;&#25454;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#24037;&#21162;&#21147;&#65292;&#22240;&#27492;&#22312;&#20855;&#20307;&#39046;&#22495;&#20219;&#21153;&#20013;&#38750;&#24120;&#26114;&#36149;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#39044;&#31639;&#19979;&#24494;&#35843;&#22522;&#20110;PLM&#30340;&#25490;&#24207;&#22120;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#24773;&#20917;&#65306;&#20174;&#22836;&#24320;&#22987;&#24494;&#35843;&#25490;&#24207;&#22120;&#65292;&#20197;&#21450;&#20174;&#24050;&#32463;&#22312;&#36890;&#29992;&#25968;&#25454;&#19978;&#24494;&#35843;&#30340;&#25490;&#24207;&#22120;&#24320;&#22987;&#36827;&#34892;&#39046;&#22495;&#36866;&#24212;&#65292;&#24182;&#22312;&#30446;&#26631;&#25968;&#25454;&#38598;&#19978;&#32487;&#32493;&#24494;&#35843;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#19981;&#21516;&#38543;&#26426;&#36873;&#25321;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#26102;&#65292;&#26377;&#25928;&#24615;&#23384;&#22312;&#24456;&#22823;&#30340;&#21464;&#24322;&#24615;&#12290;&#36825;&#34920;&#26126;&#36890;&#36807;&#20027;&#21160;&#36873;&#25321;&#23545;&#25490;&#24207;&#22120;&#25928;&#26524;&#26368;&#31215;&#26497;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#65292;&#21487;&#20197;&#23454;&#29616;&#26377;&#25928;&#24615;&#25552;&#21319;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#23558;&#21487;&#20197;&#24494;&#35843;&#20986;&#26377;&#25928;&#30340;PLM&#25490;&#24207;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Search methods based on Pretrained Language Models (PLM) have demonstrated great effectiveness gains compared to statistical and early neural ranking models. However, fine-tuning PLM-based rankers requires a great amount of annotated training data. Annotating data involves a large manual effort and thus is expensive, especially in domain specific tasks. In this paper we investigate fine-tuning PLM-based rankers under limited training data and budget. We investigate two scenarios: fine-tuning a ranker from scratch, and domain adaptation starting with a ranker already fine-tuned on general data, and continuing fine-tuning on a target dataset. We observe a great variability in effectiveness when fine-tuning on different randomly selected subsets of training data. This suggests that it is possible to achieve effectiveness gains by actively selecting a subset of the training data that has the most positive effect on the rankers. This way, it would be possible to fine-tune effective PLM rank
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;GPT-2&#20174;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#38750;&#25688;&#35201;&#25110;&#29983;&#25104;&#24615;&#29305;&#24449;&#21270;&#20154;&#29289;&#23454;&#20307;&#30340;&#38646;-shot&#26041;&#27861;&#65292;&#29992;&#20110;&#25581;&#31034;&#23186;&#20307;&#23545;&#20844;&#20247;&#20154;&#29289;&#30340;&#28508;&#22312;&#24577;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.06112</link><description>&lt;p&gt;
&#25581;&#31034;&#23186;&#20307;&#23545;&#20844;&#20247;&#20154;&#29289;&#30340;&#28508;&#22312;&#24577;&#24230;
&lt;/p&gt;
&lt;p&gt;
Characterizing Latent Perspectives of Media Houses Towards Public Figures. (arXiv:2309.06112v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;GPT-2&#20174;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#38750;&#25688;&#35201;&#25110;&#29983;&#25104;&#24615;&#29305;&#24449;&#21270;&#20154;&#29289;&#23454;&#20307;&#30340;&#38646;-shot&#26041;&#27861;&#65292;&#29992;&#20110;&#25581;&#31034;&#23186;&#20307;&#23545;&#20844;&#20247;&#20154;&#29289;&#30340;&#28508;&#22312;&#24577;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23186;&#20307;&#25253;&#36947;&#20844;&#20247;&#20154;&#29289;&#24448;&#24448;&#21463;&#21040;&#21508;&#33258;&#19990;&#30028;&#35266;&#30340;&#20559;&#35265;&#24433;&#21709;&#12290;&#23545;&#36825;&#20123;&#28508;&#22312;&#27169;&#24335;&#30340;&#25551;&#36848;&#26377;&#21161;&#20110;&#25105;&#20204;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#35299;&#37322;&#26032;&#38395;&#25925;&#20107;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#38656;&#35201;&#22810;&#26679;&#21270;&#25110;&#20027;&#35266;&#30340;&#24635;&#32467;&#65292;&#36825;&#21487;&#33021;&#19981;&#36866;&#21512;&#20998;&#31867;&#20026;&#39044;&#23450;&#20041;&#30340;&#31867;&#21035;&#26631;&#31614;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;GPT-2&#20174;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#38750;&#25688;&#35201;&#25110;&#29983;&#25104;&#24615;&#29305;&#24449;&#21270;&#20154;&#29289;&#23454;&#20307;&#30340;&#38646;-shot&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#26469;&#33258;&#20960;&#23478;&#30693;&#21517;&#26032;&#38395;&#23186;&#20307;&#30340;&#26126;&#30830;&#25991;&#31456;&#20316;&#20026;&#35821;&#26009;&#24211;&#65292;&#20026;&#36825;&#31181;&#26041;&#27861;&#24314;&#31435;&#20102;&#19968;&#20010;&#26377;&#21147;&#30340;&#35770;&#35777;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#29992;&#29305;&#23450;&#30340;&#20154;&#29289;&#23454;&#20307;&#36827;&#34892;&#20102;GPT-2&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#65292;&#28982;&#21518;&#20877;&#29992;&#20174;&#31243;&#24207;&#26500;&#36896;&#30340;&#29305;&#24449;&#21270;&#35821;&#26009;&#24211;&#21019;&#24314;&#30340;&#20154;&#29289;&#23454;&#20307;&#29305;&#24449;&#21270;&#28436;&#31034;&#36827;&#19968;&#27493;&#24494;&#35843;&#23427;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#29992;&#25163;&#21160;&#25552;&#31034;&#30340;&#23454;&#20307;&#21517;&#31216;&#39044;&#28909;&#20102;&#36825;&#20010;&#32463;&#36807;&#20004;&#27425;&#24494;&#35843;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Media houses reporting on public figures, often come with their own biases stemming from their respective worldviews. A characterization of these underlying patterns helps us in better understanding and interpreting news stories. For this, we need diverse or subjective summarizations, which may not be amenable for classifying into predefined class labels. This work proposes a zero-shot approach for non-extractive or generative characterizations of person entities from a corpus using GPT-2. We use well-articulated articles from several well-known news media houses as a corpus to build a sound argument for this approach. First, we fine-tune a GPT-2 pre-trained language model with a corpus where specific person entities are characterized. Second, we further fine-tune this with demonstrations of person entity characterizations, created from a corpus of programmatically constructed characterizations. This twice fine-tuned model is primed with manual prompts consisting of entity names that w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#20845;&#20010;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#30340;&#30740;&#31350;&#65292;&#21457;&#29616;&#20102;&#26597;&#35810;&#30340;&#20803;&#25968;&#25454;&#12289;&#38382;&#39064;&#26500;&#25104;&#26041;&#24335;&#21644;&#29992;&#25143;&#20114;&#21160;&#27700;&#24179;&#19982;&#31532;&#19968;&#20010;&#22238;&#31572;&#26102;&#38388;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#24182;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26597;&#35810;&#26159;&#21542;&#33021;&#22815;&#36805;&#36895;&#33719;&#24471;&#22238;&#31572;&#12290;</title><link>http://arxiv.org/abs/2309.05961</link><description>&lt;p&gt;
&#35780;&#20272;&#28526;&#36215;&#28526;&#33853;&#65306;&#23545;&#19981;&#21516;&#24179;&#21488;&#38388;&#38382;&#31572;&#36235;&#21183;&#30340;&#28145;&#20837;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms. (arXiv:2309.05961v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#20845;&#20010;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#30340;&#30740;&#31350;&#65292;&#21457;&#29616;&#20102;&#26597;&#35810;&#30340;&#20803;&#25968;&#25454;&#12289;&#38382;&#39064;&#26500;&#25104;&#26041;&#24335;&#21644;&#29992;&#25143;&#20114;&#21160;&#27700;&#24179;&#19982;&#31532;&#19968;&#20010;&#22238;&#31572;&#26102;&#38388;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#24182;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26597;&#35810;&#26159;&#21542;&#33021;&#22815;&#36805;&#36895;&#33719;&#24471;&#22238;&#31572;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#22240;&#20854;&#24555;&#36895;&#22238;&#31572;&#29992;&#25143;&#26597;&#35810;&#30340;&#33021;&#21147;&#32780;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#36825;&#20123;&#22238;&#31572;&#36895;&#24230;&#30340;&#24555;&#24930;&#21462;&#20915;&#20110;&#26597;&#35810;&#29305;&#23450;&#21644;&#29992;&#25143;&#30456;&#20851;&#30340;&#22240;&#32032;&#30340;&#32508;&#21512;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#20845;&#20010;&#39640;&#24230;&#27969;&#34892;&#30340;&#31038;&#21306;&#38382;&#31572;&#24179;&#21488;&#65292;&#20998;&#26512;&#20102;&#36825;&#20123;&#22240;&#32032;&#22312;&#20854;&#20013;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#25581;&#31034;&#20102;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#22238;&#31572;&#25152;&#33457;&#36153;&#30340;&#26102;&#38388;&#19982;&#20803;&#25968;&#25454;&#12289;&#38382;&#39064;&#30340;&#26500;&#25104;&#26041;&#24335;&#21644;&#29992;&#25143;&#20043;&#38388;&#30340;&#20114;&#21160;&#27700;&#24179;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20351;&#29992;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20998;&#26512;&#36825;&#20123;&#20803;&#25968;&#25454;&#21644;&#29992;&#25143;&#20114;&#21160;&#27169;&#24335;&#65292;&#25105;&#20204;&#35797;&#22270;&#39044;&#27979;&#21738;&#20123;&#26597;&#35810;&#23558;&#36805;&#36895;&#33719;&#24471;&#21021;&#22987;&#22238;&#31572;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community Question Answering (CQA) platforms steadily gain popularity as they provide users with fast responses to their queries. The swiftness of these responses is contingent on a mixture of query-specific and user-related elements. This paper scrutinizes these contributing factors within the context of six highly popular CQA platforms, identified through their standout answering speed. Our investigation reveals a correlation between the time taken to yield the first response to a question and several variables: the metadata, the formulation of the questions, and the level of interaction among users. Additionally, by employing conventional machine learning models to analyze these metadata and patterns of user interaction, we endeavor to predict which queries will receive their initial responses promptly.
&lt;/p&gt;</description></item><item><title>GLAD&#26159;&#19968;&#20010;&#20869;&#23481;&#24863;&#30693;&#30340;&#21160;&#24577;&#22270;&#29992;&#20110;&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;&#30340;&#26694;&#26550;&#65292;&#23427;&#32508;&#21512;&#20102;&#26085;&#24535;&#35821;&#20041;&#12289;&#20851;&#31995;&#27169;&#24335;&#21644;&#39034;&#24207;&#27169;&#24335;&#65292;&#36890;&#36807;&#35782;&#21035;&#20851;&#38190;&#23383;&#27573;&#21644;&#26500;&#24314;&#21160;&#24577;&#26085;&#24535;&#22270;&#26469;&#26816;&#27979;&#31995;&#32479;&#26085;&#24535;&#20013;&#30340;&#20851;&#32852;&#24322;&#24120;&#12290;</title><link>http://arxiv.org/abs/2309.05953</link><description>&lt;p&gt;
GLAD: &#20869;&#23481;&#24863;&#30693;&#30340;&#21160;&#24577;&#22270;&#29992;&#20110;&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
GLAD: Content-aware Dynamic Graphs For Log Anomaly Detection. (arXiv:2309.05953v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05953
&lt;/p&gt;
&lt;p&gt;
GLAD&#26159;&#19968;&#20010;&#20869;&#23481;&#24863;&#30693;&#30340;&#21160;&#24577;&#22270;&#29992;&#20110;&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;&#30340;&#26694;&#26550;&#65292;&#23427;&#32508;&#21512;&#20102;&#26085;&#24535;&#35821;&#20041;&#12289;&#20851;&#31995;&#27169;&#24335;&#21644;&#39034;&#24207;&#27169;&#24335;&#65292;&#36890;&#36807;&#35782;&#21035;&#20851;&#38190;&#23383;&#27573;&#21644;&#26500;&#24314;&#21160;&#24577;&#26085;&#24535;&#22270;&#26469;&#26816;&#27979;&#31995;&#32479;&#26085;&#24535;&#20013;&#30340;&#20851;&#32852;&#24322;&#24120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35760;&#24405;&#20102;&#26377;&#20851;&#31995;&#32479;&#20449;&#24687;&#30340;&#26085;&#24535;&#22312;&#31995;&#32479;&#30417;&#25511;&#21644;&#35843;&#35797;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#21253;&#25324;&#20107;&#20214;&#21644;&#29366;&#24577;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#26816;&#27979;&#26085;&#24535;&#24207;&#21015;&#20013;&#30340;&#24322;&#24120;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#24573;&#35270;&#20102;&#32771;&#34385;&#31995;&#32479;&#32452;&#20214;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#37325;&#35201;&#24615;&#65292;&#20363;&#22914;&#26381;&#21153;&#21644;&#29992;&#25143;&#65292;&#36825;&#20123;&#21487;&#20197;&#20174;&#26085;&#24535;&#20869;&#23481;&#20013;&#35782;&#21035;&#20986;&#26469;&#12290;&#29702;&#35299;&#36825;&#20123;&#20851;&#31995;&#23545;&#20110;&#26816;&#27979;&#24322;&#24120;&#21450;&#20854;&#28508;&#22312;&#21407;&#22240;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;GLAD&#65292;&#19968;&#20010;&#22522;&#20110;&#22270;&#30340;&#26085;&#24535;&#24322;&#24120;&#26816;&#27979;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#31995;&#32479;&#26085;&#24535;&#20013;&#30340;&#20851;&#32852;&#24322;&#24120;&#12290;GLAD&#23558;&#26085;&#24535;&#35821;&#20041;&#12289;&#20851;&#31995;&#27169;&#24335;&#21644;&#39034;&#24207;&#27169;&#24335;&#32435;&#20837;&#32479;&#19968;&#26694;&#26550;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;GLAD&#39318;&#20808;&#24341;&#20837;&#19968;&#20010;&#23383;&#27573;&#25552;&#21462;&#27169;&#22359;&#65292;&#21033;&#29992;&#22522;&#20110;&#25552;&#31034;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#20174;&#26085;&#24535;&#20869;&#23481;&#20013;&#35782;&#21035;&#20986;&#20851;&#38190;&#23383;&#27573;&#12290;&#28982;&#21518;&#65292;GLAD&#36890;&#36807;&#20114;&#36830;&#25552;&#21462;&#30340;&#23383;&#27573;&#21644;&#26085;&#24535;&#20107;&#20214;&#26500;&#24314;&#28369;&#21160;&#31383;&#21475;&#30340;&#21160;&#24577;&#26085;&#24535;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Logs play a crucial role in system monitoring and debugging by recording valuable system information, including events and states. Although various methods have been proposed to detect anomalies in log sequences, they often overlook the significance of considering relations among system components, such as services and users, which can be identified from log contents. Understanding these relations is vital for detecting anomalies and their underlying causes. To address this issue, we introduce GLAD, a Graph-based Log Anomaly Detection framework designed to detect relational anomalies in system logs. GLAD incorporates log semantics, relational patterns, and sequential patterns into a unified framework for anomaly detection. Specifically, GLAD first introduces a field extraction module that utilizes prompt-based few-shot learning to identify essential fields from log contents. Then GLAD constructs dynamic log graphs for sliding windows by interconnecting extracted fields and log events p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#38382;&#39064;&#65292;&#21253;&#25324;&#24187;&#35273;&#29616;&#35937;&#30340;&#20998;&#31867;&#12289;&#35780;&#20272;&#26631;&#20934;&#21644;&#20943;&#36731;&#24187;&#35273;&#30340;&#31574;&#30053;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2309.05922</link><description>&lt;p&gt;
&#23545;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#20013;&#24187;&#35273;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey of Hallucination in Large Foundation Models. (arXiv:2309.05922v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05922
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#38382;&#39064;&#65292;&#21253;&#25324;&#24187;&#35273;&#29616;&#35937;&#30340;&#20998;&#31867;&#12289;&#35780;&#20272;&#26631;&#20934;&#21644;&#20943;&#36731;&#24187;&#35273;&#30340;&#31574;&#30053;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#30784;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#25351;&#30340;&#26159;&#29983;&#25104;&#20559;&#31163;&#20107;&#23454;&#30340;&#20869;&#23481;&#25110;&#21253;&#21547;&#34394;&#26500;&#20449;&#24687;&#12290;&#26412;&#30740;&#31350;&#27010;&#36848;&#20102;&#36817;&#26399;&#21162;&#21147;&#30340;&#24191;&#27867;&#27010;&#36848;&#65292;&#36825;&#20123;&#21162;&#21147;&#26088;&#22312;&#35782;&#21035;&#12289;&#38416;&#26126;&#21644;&#35299;&#20915;&#24187;&#35273;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#8220;&#22823;&#8221;&#22522;&#30784;&#27169;&#22411;&#65288;LFMs&#65289;&#12290;&#26412;&#25991;&#23545;&#29305;&#23450;&#20110;LFMs&#30340;&#21508;&#31181;&#31867;&#22411;&#30340;&#24187;&#35273;&#29616;&#35937;&#36827;&#34892;&#20102;&#20998;&#31867;&#65292;&#24182;&#24314;&#31435;&#20102;&#35780;&#20272;&#24187;&#35273;&#31243;&#24230;&#30340;&#35780;&#20272;&#26631;&#20934;&#12290;&#23427;&#36824;&#26816;&#26597;&#20102;&#20943;&#36731;LFM&#20013;&#24187;&#35273;&#30340;&#29616;&#26377;&#31574;&#30053;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#28508;&#22312;&#26041;&#21521;&#12290;&#26412;&#25991;&#20840;&#38754;&#25506;&#35752;&#20102;&#19982;LFMs&#20013;&#24187;&#35273;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hallucination in a foundation model (FM) refers to the generation of content that strays from factual reality or includes fabricated information. This survey paper provides an extensive overview of recent efforts that aim to identify, elucidate, and tackle the problem of hallucination, with a particular focus on ``Large'' Foundation Models (LFMs). The paper classifies various types of hallucination phenomena that are specific to LFMs and establishes evaluation criteria for assessing the extent of hallucination. It also examines existing strategies for mitigating hallucination in LFMs and discusses potential directions for future research in this area. Essentially, the paper offers a comprehensive examination of the challenges and solutions related to hallucination in LFMs.
&lt;/p&gt;</description></item><item><title>SAGE&#26159;&#19968;&#20010;&#29992;&#20110;&#22312;&#21313;&#20159;&#32423;&#20135;&#21697;&#30446;&#24405;&#20013;&#29983;&#25104;&#23646;&#24615;&#20540;&#30340;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#36328;&#35821;&#35328;&#12289;&#20135;&#21697;&#31867;&#22411;&#21644;&#30446;&#26631;&#23646;&#24615;&#30340;&#38382;&#39064;&#12290;&#23427;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24314;&#27169;&#26041;&#27861;&#65292;&#21487;&#20197;&#25512;&#26029;&#38544;&#24335;&#20351;&#29992;&#36802;&#22238;&#35821;&#35328;&#25552;&#21040;&#30340;&#23646;&#24615;&#20540;&#65292;&#24182;&#19988;&#33021;&#22815;&#39044;&#27979;&#23646;&#24615;&#30340;&#19981;&#36866;&#29992;&#24615;&#21644;&#26080;&#27861;&#20174;&#21487;&#29992;&#20449;&#24687;&#20013;&#33719;&#21462;&#23646;&#24615;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.05920</link><description>&lt;p&gt;
SAGE: &#38024;&#23545;&#21313;&#20159;&#32423;&#20135;&#21697;&#30446;&#24405;&#30340;&#32467;&#26500;&#21270;&#23646;&#24615;&#20540;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
SAGE: Structured Attribute Value Generation for Billion-Scale Product Catalogs. (arXiv:2309.05920v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05920
&lt;/p&gt;
&lt;p&gt;
SAGE&#26159;&#19968;&#20010;&#29992;&#20110;&#22312;&#21313;&#20159;&#32423;&#20135;&#21697;&#30446;&#24405;&#20013;&#29983;&#25104;&#23646;&#24615;&#20540;&#30340;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#36328;&#35821;&#35328;&#12289;&#20135;&#21697;&#31867;&#22411;&#21644;&#30446;&#26631;&#23646;&#24615;&#30340;&#38382;&#39064;&#12290;&#23427;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24314;&#27169;&#26041;&#27861;&#65292;&#21487;&#20197;&#25512;&#26029;&#38544;&#24335;&#20351;&#29992;&#36802;&#22238;&#35821;&#35328;&#25552;&#21040;&#30340;&#23646;&#24615;&#20540;&#65292;&#24182;&#19988;&#33021;&#22815;&#39044;&#27979;&#23646;&#24615;&#30340;&#19981;&#36866;&#29992;&#24615;&#21644;&#26080;&#27861;&#20174;&#21487;&#29992;&#20449;&#24687;&#20013;&#33719;&#21462;&#23646;&#24615;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;SAGE&#65292;&#19968;&#20010;&#29992;&#20110;&#22312;&#20840;&#29699;&#30005;&#23376;&#21830;&#21153;&#30446;&#24405;&#20013;&#25512;&#26029;&#20135;&#21697;&#23646;&#24615;&#20540;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#25105;&#20204;&#23558;&#23646;&#24615;&#20540;&#39044;&#27979;&#38382;&#39064;&#20197;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24335;&#36716;&#21270;&#20026;&#36328;&#35821;&#35328;&#12289;&#20135;&#21697;&#31867;&#22411;&#21644;&#30446;&#26631;&#23646;&#24615;&#30340;Seq2Seq&#25688;&#35201;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26032;&#27169;&#22411;&#26041;&#27861;&#19981;&#20877;&#23616;&#38480;&#20110;&#22312;&#39044;&#20808;&#25351;&#23450;&#30340;&#36873;&#39033;&#38598;&#20869;&#39044;&#27979;&#23646;&#24615;&#20540;&#65292;&#24182;&#19988;&#20063;&#19981;&#35201;&#27714;&#25152;&#23547;&#25214;&#30340;&#23646;&#24615;&#20540;&#22312;&#25991;&#26412;&#20013;&#26126;&#30830;&#25552;&#21450;&#12290;SAGE&#21487;&#20197;&#25512;&#26029;&#38544;&#24335;&#20351;&#29992;&#36802;&#22238;&#35821;&#35328;&#25552;&#21040;&#30340;&#23646;&#24615;&#20540;&#65292;&#25110;&#32773;&#26681;&#26412;&#19981;&#25552;&#21450;&#30340;&#24120;&#35782;&#40664;&#35748;&#24773;&#20917;&#19979;&#30340;&#23646;&#24615;&#20540;&#12290;&#27492;&#22806;&#65292;SAGE&#33021;&#22815;&#39044;&#27979;&#19968;&#20010;&#23646;&#24615;&#23545;&#20110;&#24403;&#21069;&#20135;&#21697;&#26159;&#21542;&#19981;&#36866;&#29992;&#65292;&#25110;&#32773;&#26159;&#21542;&#26080;&#27861;&#20174;&#21487;&#29992;&#20449;&#24687;&#20013;&#33719;&#21462;&#12290;SAGE&#26159;&#31532;&#19968;&#31181;&#33021;&#22815;&#22312;&#23454;&#38469;&#30005;&#23376;&#21830;&#21153;&#30446;&#24405;&#35774;&#32622;&#20013;&#22788;&#29702;&#23646;&#24615;&#20540;&#39044;&#27979;&#20219;&#21153;&#25152;&#26377;&#26041;&#38754;&#30340;&#26041;&#27861;&#12290;&#19968;&#22871;&#32508;&#21512;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We introduce SAGE; a Generative LLM for inferring attribute values for products across world-wide e-Commerce catalogs. We introduce a novel formulation of the attribute-value prediction problem as a Seq2Seq summarization task, across languages, product types and target attributes. Our novel modeling approach lifts the restriction of predicting attribute values within a pre-specified set of choices, as well as, the requirement that the sought attribute values need to be explicitly mentioned in the text. SAGE can infer attribute values even when such values are mentioned implicitly using periphrastic language, or not-at-all-as is the case for common-sense defaults. Additionally, SAGE is capable of predicting whether an attribute is inapplicable for the product at hand, or non-obtainable from the available information. SAGE is the first method able to tackle all aspects of the attribute-value-prediction task as they arise in practical settings in e-Commerce catalogs. A comprehensive set o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#24067;&#20449;&#24687;&#30340;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#65292;&#24378;&#35843;&#20102;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#38656;&#35201;&#26356;&#21152;&#20851;&#27880;&#25512;&#33616;&#31995;&#32479;&#20013;&#20135;&#29983;&#30340;&#21508;&#31181;&#20998;&#24067;&#20197;&#21450;&#23548;&#33268;&#36825;&#20123;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#36825;&#23545;&#20110;&#35774;&#35745;&#12289;&#35780;&#20272;&#21644;&#21576;&#29616;&#25512;&#33616;&#31995;&#32479;&#30340;&#35780;&#20272;&#21644;&#30740;&#31350;&#32467;&#26524;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.05892</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#20449;&#24687;&#30340;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Distributionally-Informed Recommender System Evaluation. (arXiv:2309.05892v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#24067;&#20449;&#24687;&#30340;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#65292;&#24378;&#35843;&#20102;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#38656;&#35201;&#26356;&#21152;&#20851;&#27880;&#25512;&#33616;&#31995;&#32479;&#20013;&#20135;&#29983;&#30340;&#21508;&#31181;&#20998;&#24067;&#20197;&#21450;&#23548;&#33268;&#36825;&#20123;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#36825;&#23545;&#20110;&#35774;&#35745;&#12289;&#35780;&#20272;&#21644;&#21576;&#29616;&#25512;&#33616;&#31995;&#32479;&#30340;&#35780;&#20272;&#21644;&#30740;&#31350;&#32467;&#26524;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#24120;&#24120;&#38598;&#20013;&#22312;&#29992;&#25143;&#25928;&#26524;&#25351;&#26631;&#25110;&#21830;&#19994;&#25351;&#26631;&#30340;&#28857;&#20272;&#35745;&#19978;&#65292;&#26377;&#26102;&#32467;&#21512;&#22810;&#26679;&#24615;&#21644;&#26032;&#39062;&#24615;&#31561;&#20854;&#20182;&#25351;&#26631;&#12290;&#26412;&#25991;&#20027;&#24352;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#26356;&#21152;&#20851;&#27880;&#25512;&#33616;&#31995;&#32479;&#65288;&#25110;&#20854;&#20182;&#20449;&#24687;&#35775;&#38382;&#31995;&#32479;&#65289;&#20013;&#20135;&#29983;&#30340;&#21508;&#31181;&#20998;&#24067;&#21450;&#23548;&#33268;&#36825;&#20123;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#25105;&#20204;&#30340;&#35266;&#28857;&#20043;&#19968;&#26159;&#65292;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#24517;&#39035;&#26356;&#20840;&#38754;&#22320;&#25253;&#21578;&#21644;&#30740;&#31350;&#19981;&#21516;&#21033;&#30410;&#30456;&#20851;&#32773;&#32676;&#20307;&#20043;&#38388;&#20197;&#21450;&#32676;&#20307;&#20869;&#30340;&#25928;&#29992;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#23454;&#39564;&#36807;&#31243;&#20013;&#65292;&#21508;&#31181;&#24418;&#24335;&#30340;&#20998;&#24067;&#37117;&#20250;&#20986;&#29616;&#65292;&#20998;&#24067;&#24335;&#24605;&#32500;&#23545;&#25105;&#20204;&#35774;&#35745;&#12289;&#35780;&#20272;&#21644;&#21576;&#29616;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#21644;&#30740;&#31350;&#32467;&#26524;&#26377;&#30528;&#37325;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current practice for evaluating recommender systems typically focuses on point estimates of user-oriented effectiveness metrics or business metrics, sometimes combined with additional metrics for considerations such as diversity and novelty. In this paper, we argue for the need for researchers and practitioners to attend more closely to various distributions that arise from a recommender system (or other information access system) and the sources of uncertainty that lead to these distributions. One immediate implication of our argument is that both researchers and practitioners must report and examine more thoroughly the distribution of utility between and within different stakeholder groups. However, distributions of various forms arise in many more aspects of the recommender systems experimental process, and distributional thinking has substantial ramifications for how we design, evaluate, and present recommender systems evaluation and research results. Leveraging and emphasizing dis
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#38543;&#26426;&#22270;&#30528;&#33394;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#24425;&#34425;&#24046;&#20998;&#38544;&#31169;&#30340;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#65292;&#20854;&#20013;&#19981;&#21516;&#30340;&#24425;&#34425;&#23558;&#36830;&#25509;&#30340;&#25968;&#25454;&#38598;&#22270;&#20998;&#21106;&#25104;&#19981;&#21516;&#30340;&#21306;&#22495;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#20010;&#21807;&#19968;&#30340;&#26368;&#20248;$(\epsilon,\delta)$-DP&#26426;&#21046;&#26469;&#20445;&#25252;&#36793;&#30028;&#19978;&#20855;&#26377;&#30456;&#21516;&#24425;&#34425;&#30340;&#25968;&#25454;&#38598;&#30340;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2309.05871</link><description>&lt;p&gt;
&#24191;&#20041;&#24425;&#34425;&#24046;&#20998;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Generalized Rainbow Differential Privacy. (arXiv:2309.05871v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05871
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#22270;&#30528;&#33394;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#24425;&#34425;&#24046;&#20998;&#38544;&#31169;&#30340;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#65292;&#20854;&#20013;&#19981;&#21516;&#30340;&#24425;&#34425;&#23558;&#36830;&#25509;&#30340;&#25968;&#25454;&#38598;&#22270;&#20998;&#21106;&#25104;&#19981;&#21516;&#30340;&#21306;&#22495;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#20010;&#21807;&#19968;&#30340;&#26368;&#20248;$(\epsilon,\delta)$-DP&#26426;&#21046;&#26469;&#20445;&#25252;&#36793;&#30028;&#19978;&#20855;&#26377;&#30456;&#21516;&#24425;&#34425;&#30340;&#25968;&#25454;&#38598;&#30340;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#22270;&#30528;&#33394;&#26469;&#35774;&#35745;&#24046;&#20998;&#38544;&#31169;(DP)&#26426;&#21046;&#30340;&#26032;&#26694;&#26550;&#65292;&#31216;&#20026;&#24425;&#34425;&#24046;&#20998;&#38544;&#31169;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#25968;&#25454;&#38598;&#26159;&#22270;&#20013;&#30340;&#33410;&#28857;&#65292;&#20004;&#20010;&#30456;&#37051;&#30340;&#25968;&#25454;&#38598;&#36890;&#36807;&#36793;&#30456;&#36830;&#12290;&#22270;&#20013;&#30340;&#27599;&#20010;&#25968;&#25454;&#38598;&#37117;&#26377;&#19968;&#31181;&#23545;&#26426;&#21046;&#21487;&#33021;&#30340;&#36755;&#20986;&#30340;&#20559;&#22909;&#25490;&#24207;&#65292;&#36825;&#20123;&#25490;&#24207;&#34987;&#31216;&#20026;&#24425;&#34425;&#12290;&#19981;&#21516;&#30340;&#24425;&#34425;&#23558;&#30456;&#36830;&#30340;&#25968;&#25454;&#38598;&#22270;&#20998;&#21106;&#25104;&#19981;&#21516;&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#22312;&#36825;&#20123;&#21306;&#22495;&#36793;&#30028;&#22788;&#30340;DP&#26426;&#21046;&#34987;&#22266;&#23450;&#65292;&#24182;&#19988;&#23427;&#22312;&#25152;&#26377;&#20855;&#26377;&#30456;&#21516;&#24425;&#34425;&#36793;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#34892;&#20026;&#30456;&#21516;&#65292;&#37027;&#20040;&#23384;&#22312;&#19968;&#20010;&#21807;&#19968;&#30340;&#26368;&#20248;$(\epsilon,\delta)$-DP&#26426;&#21046;(&#21482;&#35201;&#36793;&#30028;&#26465;&#20214;&#26377;&#25928;)&#24182;&#19988;&#21487;&#20197;&#29992;&#38381;&#24418;&#24335;&#34920;&#31034;&#20986;&#26469;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#24039;&#22522;&#20110;&#20248;&#21183;&#25490;&#24207;&#21644;DP&#20043;&#38388;&#30340;&#26377;&#36259;&#20851;&#31995;&#65292;&#36866;&#29992;&#20110;&#20219;&#24847;&#26377;&#38480;&#25968;&#37327;&#30340;&#39068;&#33394;&#21644;$(\epsilon,\delta)$-DP&#65292;&#25913;&#36827;&#20102;&#20808;&#21069;&#21482;&#36866;&#29992;&#20110;&#33267;&#22810;&#19977;&#31181;&#39068;&#33394;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a new framework for designing differentially private (DP) mechanisms via randomized graph colorings, called rainbow differential privacy. In this framework, datasets are nodes in a graph, and two neighboring datasets are connected by an edge. Each dataset in the graph has a preferential ordering for the possible outputs of the mechanism, and these orderings are called rainbows. Different rainbows partition the graph of connected datasets into different regions. We show that if a DP mechanism at the boundary of such regions is fixed and it behaves identically for all same-rainbow boundary datasets, then a unique optimal $(\epsilon,\delta)$-DP mechanism exists (as long as the boundary condition is valid) and can be expressed in closed-form. Our proof technique is based on an interesting relationship between dominance ordering and DP, which applies to any finite number of colors and for $(\epsilon,\delta)$-DP, improving upon previous results that only apply to at most three color
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Stringesthesia&#30340;&#20114;&#21160;&#21644;&#21363;&#20852;&#34920;&#28436;&#33539;&#24335;&#65292;&#36890;&#36807;&#23454;&#26102;&#31070;&#32463;&#25104;&#20687;&#25216;&#26415;&#23558;&#28436;&#21592;&#21644;&#35266;&#20247;&#36830;&#25509;&#36215;&#26469;&#65292;&#23454;&#29616;&#23545;&#28436;&#21592;&#20869;&#24515;&#29366;&#24577;&#30340;&#30452;&#25509;&#35775;&#38382;&#65292;&#24182;&#26681;&#25454;&#28436;&#21592;&#30340;&#20449;&#20219;&#27700;&#24179;&#21160;&#24577;&#38480;&#21046;&#25110;&#20419;&#36827;&#35266;&#20247;&#30340;&#21442;&#19982;&#12290;</title><link>http://arxiv.org/abs/2309.05786</link><description>&lt;p&gt;
Stringesthesia&#65306;&#22522;&#20110;&#20114;&#21160;&#19982;&#21363;&#20852;&#34920;&#28436;&#30340;&#35266;&#20247;&#19982;&#28436;&#21592;&#20043;&#38388;&#30340;&#38899;&#20048;&#21019;&#20316;&#26041;&#24335;&#30340;&#21160;&#24577;&#36716;&#31227;&#65292;&#22522;&#20110;&#20449;&#20219;&#30340;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
Stringesthesia: Dynamically Shifting Musical Agency Between Audience and Performer Based on Trust in an Interactive and Improvised Performance. (arXiv:2309.05786v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Stringesthesia&#30340;&#20114;&#21160;&#21644;&#21363;&#20852;&#34920;&#28436;&#33539;&#24335;&#65292;&#36890;&#36807;&#23454;&#26102;&#31070;&#32463;&#25104;&#20687;&#25216;&#26415;&#23558;&#28436;&#21592;&#21644;&#35266;&#20247;&#36830;&#25509;&#36215;&#26469;&#65292;&#23454;&#29616;&#23545;&#28436;&#21592;&#20869;&#24515;&#29366;&#24577;&#30340;&#30452;&#25509;&#35775;&#38382;&#65292;&#24182;&#26681;&#25454;&#28436;&#21592;&#30340;&#20449;&#20219;&#27700;&#24179;&#21160;&#24577;&#38480;&#21046;&#25110;&#20419;&#36827;&#35266;&#20247;&#30340;&#21442;&#19982;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Stringesthesia&#65292;&#19968;&#31181;&#20114;&#21160;&#21644;&#21363;&#20852;&#34920;&#28436;&#33539;&#24335;&#12290;Stringesthesia&#21033;&#29992;&#23454;&#26102;&#31070;&#32463;&#25104;&#20687;&#25216;&#26415;&#23558;&#28436;&#21592;&#21644;&#35266;&#20247;&#36830;&#25509;&#36215;&#26469;&#65292;&#23454;&#29616;&#23545;&#28436;&#21592;&#20869;&#24515;&#29366;&#24577;&#30340;&#30452;&#25509;&#35775;&#38382;&#65292;&#24182;&#30830;&#23450;&#35266;&#20247;&#22312;&#34920;&#28436;&#20013;&#30340;&#21442;&#19982;&#26041;&#24335;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#31216;&#20026;&#20449;&#20219;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#35780;&#20272;&#19982;&#22823;&#33041;&#20195;&#35874;&#27963;&#21160;&#30456;&#20851;&#30340;&#33041;&#21306;&#65292;&#37319;&#29992;&#26080;&#21019;&#30340;&#21151;&#33021;&#24615;&#36817;&#32418;&#22806;&#20809;&#35889;&#25216;&#26415;&#65288;fNIRS&#65289;&#12290;&#23558;&#28436;&#21592;&#30340;&#20449;&#20219;&#27700;&#24179;&#30340;&#23454;&#26102;&#27979;&#37327;&#21576;&#29616;&#22312;&#28436;&#21592;&#36523;&#21518;&#30340;&#21487;&#35270;&#21270;&#30028;&#38754;&#20013;&#65292;&#29992;&#20110;&#21160;&#24577;&#38480;&#21046;&#25110;&#20419;&#36827;&#35266;&#20247;&#30340;&#21442;&#19982;&#12290;&#26412;&#25991;&#36824;&#35752;&#35770;&#20102;&#23545;&#25105;&#20204;&#35774;&#35745;&#30340;&#21069;&#26399;&#24037;&#20316;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;fNIRS&#25216;&#26415;&#26102;&#30340;&#27010;&#24565;&#21644;&#26041;&#27861;&#19978;&#30340;&#38382;&#39064;&#65292;&#31995;&#32479;&#26550;&#26500;&#20197;&#21450;&#35266;&#20247;&#21644;&#28436;&#21592;&#30340;&#21453;&#39304;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces Stringesthesia, an interactive and improvised performance paradigm. Stringesthesia uses real-time neuroimaging to connect performers and audiences, enabling direct access to the performers mental state and determining audience participation during the performance. Functional near-infrared spectroscopy, or fNIRS, a noninvasive neuroimaging tool, was used to assess metabolic activity of brain areas collectively associated with a metric we call trust. A visualization representing the real-time measurement of the performers level of trust was projected behind the performer and used to dynamically restrict or promote audience participation. Throughout the paper we discuss prior work that heavily influenced our design, conceptual and methodological issues with using fNIRS technology, system architecture, and feedback from the audience and performer.
&lt;/p&gt;</description></item><item><title>tSPM+&#31639;&#27861;&#26159;&#19968;&#31181;&#39640;&#24615;&#33021;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#26102;&#38388;&#27169;&#24335;&#20013;&#21152;&#20837;&#25345;&#32493;&#26102;&#38388;&#32500;&#24230;&#65292;&#25552;&#20379;&#20102;&#39640;&#36895;&#36816;&#34892;&#21644;&#20869;&#23384;&#28040;&#32791;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2309.05671</link><description>&lt;p&gt;
tSPM+&#65306;&#19968;&#31181;&#29992;&#20110;&#20174;&#20020;&#24202;&#25968;&#25454;&#20013;&#25366;&#25496;&#20256;&#36882;&#39034;&#24207;&#27169;&#24335;&#30340;&#39640;&#24615;&#33021;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
tSPM+; a high-performance algorithm for mining transitive sequential patterns from clinical data. (arXiv:2309.05671v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05671
&lt;/p&gt;
&lt;p&gt;
tSPM+&#31639;&#27861;&#26159;&#19968;&#31181;&#39640;&#24615;&#33021;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#26102;&#38388;&#27169;&#24335;&#20013;&#21152;&#20837;&#25345;&#32493;&#26102;&#38388;&#32500;&#24230;&#65292;&#25552;&#20379;&#20102;&#39640;&#36895;&#36816;&#34892;&#21644;&#20869;&#23384;&#28040;&#32791;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22810;&#20174;&#24739;&#32773;&#37027;&#37324;&#25910;&#38598;&#21040;&#30340;&#22823;&#22411;&#20020;&#24202;&#25968;&#25454;&#38598;&#30340;&#21487;&#29992;&#24615;&#65292;&#20351;&#24471;&#20351;&#29992;&#19981;&#21516;&#30340;&#20998;&#26512;&#31639;&#27861;&#23545;&#22797;&#26434;&#30142;&#30149;&#36827;&#34892;&#35745;&#31639;&#21270;&#29305;&#24449;&#21270;&#25104;&#20026;&#21487;&#33021;&#12290;&#19968;&#31181;&#20174;&#22823;&#22411;&#20020;&#24202;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#30693;&#35782;&#30340;&#26377;&#21069;&#36884;&#30340;&#26032;&#26041;&#27861;&#26159;&#23558;&#26102;&#38388;&#27169;&#24335;&#25366;&#25496;&#19982;&#26426;&#22120;&#23398;&#20064;&#24037;&#20316;&#27969;&#31243;&#30456;&#32467;&#21512;&#12290;&#28982;&#32780;&#65292;&#25366;&#25496;&#36825;&#20123;&#26102;&#38388;&#27169;&#24335;&#26159;&#19968;&#39033;&#35745;&#31639;&#23494;&#38598;&#22411;&#20219;&#21153;&#65292;&#24182;&#19988;&#20250;&#23545;&#23384;&#20648;&#22120;&#20135;&#29983;&#24433;&#21709;&#12290;&#30446;&#21069;&#30340;&#31639;&#27861;&#65292;&#22914;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#25366;&#25496;&#65288;tSPM&#65289;&#31639;&#27861;&#65292;&#24050;&#32463;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#20173;&#26377;&#20248;&#21270;&#30340;&#31354;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;tSPM+&#31639;&#27861;&#65292;&#36825;&#26159;tSPM&#31639;&#27861;&#30340;&#19968;&#31181;&#39640;&#24615;&#33021;&#23454;&#29616;&#65292;&#36890;&#36807;&#22312;&#26102;&#38388;&#27169;&#24335;&#20013;&#28155;&#21152;&#25345;&#32493;&#26102;&#38388;&#32500;&#24230;&#65292;&#22686;&#21152;&#20102;&#19968;&#31181;&#26032;&#30340;&#32500;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;tSPM+&#31639;&#27861;&#25552;&#20379;&#20102;&#39640;&#36798;980&#20493;&#30340;&#21152;&#36895;&#21644;&#39640;&#36798;48&#20493;&#30340;&#20869;&#23384;&#20351;&#29992;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#21253;&#21547;R&#21253;&#30340;docker&#23481;&#22120;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#23454;&#39564;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing availability of large clinical datasets collected from patients can enable new avenues for computational characterization of complex diseases using different analytic algorithms. One of the promising new methods for extracting knowledge from large clinical datasets involves temporal pattern mining integrated with machine learning workflows. However, mining these temporal patterns is a computational intensive task and has memory repercussions. Current algorithms, such as the temporal sequence pattern mining (tSPM) algorithm, are already providing promising outcomes, but still leave room for optimization. In this paper, we present the tSPM+ algorithm, a high-performance implementation of the tSPM algorithm, which adds a new dimension by adding the duration to the temporal patterns. We show that the tSPM+ algorithm provides a speed up to factor 980 and a up to 48 fold improvement in memory consumption. Moreover, we present a docker container with an R-package, We also provi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#29305;&#24449;&#20132;&#20114;&#23398;&#20064;&#27169;&#22411;EulerNet&#65292;&#23427;&#37319;&#29992;&#27431;&#25289;&#20844;&#24335;&#23558;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#26144;&#23556;&#21040;&#22797;&#26434;&#21521;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#25928;&#29575;&#30340;&#21516;&#26102;&#25552;&#39640;&#27169;&#22411;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.10711</link><description>&lt;p&gt;
EulerNet: &#22522;&#20110;&#27431;&#25289;&#20844;&#24335;&#30340;&#22797;&#26434;&#21521;&#37327;&#31354;&#38388;&#29305;&#24449;&#20132;&#20114;&#23398;&#20064;&#20197;&#23454;&#29616;&#28857;&#20987;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
EulerNet: Adaptive Feature Interaction Learning via Euler's Formula for CTR Prediction. (arXiv:2304.10711v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#29305;&#24449;&#20132;&#20114;&#23398;&#20064;&#27169;&#22411;EulerNet&#65292;&#23427;&#37319;&#29992;&#27431;&#25289;&#20844;&#24335;&#23558;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#26144;&#23556;&#21040;&#22797;&#26434;&#21521;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#25928;&#29575;&#30340;&#21516;&#26102;&#25552;&#39640;&#27169;&#22411;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28857;&#20987;&#29575;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#23398;&#20064;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#26159;&#38750;&#24120;&#20851;&#38190;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#22312;&#32447;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#20013;&#65292;&#30001;&#20110;&#28023;&#37327;&#29305;&#24449;&#30340;&#23384;&#22312;&#65292;&#35745;&#31639;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#38750;&#24120;&#32791;&#26102;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#25163;&#21160;&#35774;&#35745;&#26368;&#22823;&#38454;&#25968;&#65292;&#24182;&#20174;&#20013;&#36807;&#28388;&#20986;&#26080;&#29992;&#30340;&#20132;&#20114;&#12290;&#23613;&#31649;&#23427;&#20204;&#20943;&#23569;&#20102;&#39640;&#38454;&#29305;&#24449;&#32452;&#21512;&#30340;&#25351;&#25968;&#32423;&#22686;&#38271;&#25152;&#24341;&#36215;&#30340;&#39640;&#35745;&#31639;&#25104;&#26412;&#65292;&#20294;&#30001;&#20110;&#21463;&#21040;&#21463;&#38480;&#30340;&#29305;&#24449;&#38454;&#25968;&#30340;&#27425;&#20248;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#23427;&#20204;&#20173;&#28982;&#20250;&#21463;&#21040;&#27169;&#22411;&#33021;&#21147;&#19979;&#38477;&#30340;&#24433;&#21709;&#12290;&#20445;&#25345;&#27169;&#22411;&#33021;&#21147;&#24182;&#21516;&#26102;&#20445;&#25345;&#20854;&#25928;&#29575;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#19968;&#20010;&#25216;&#26415;&#25361;&#25112;&#65292;&#35813;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#35299;&#20915;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#29305;&#24449;&#20132;&#20114;&#23398;&#20064;&#27169;&#22411;&#65292;&#21517;&#20026;EulerNet&#65292;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#26681;&#25454;&#27431;&#25289;&#20844;&#24335;&#36827;&#34892;&#31354;&#38388;&#26144;&#23556;&#22312;&#22797;&#26434;&#21521;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#29305;&#24449;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning effective high-order feature interactions is very crucial in the CTR prediction task. However, it is very time-consuming to calculate high-order feature interactions with massive features in online e-commerce platforms. Most existing methods manually design a maximal order and further filter out the useless interactions from them. Although they reduce the high computational costs caused by the exponential growth of high-order feature combinations, they still suffer from the degradation of model capability due to the suboptimal learning of the restricted feature orders. The solution to maintain the model capability and meanwhile keep it efficient is a technical challenge, which has not been adequately addressed. To address this issue, we propose an adaptive feature interaction learning model, named as EulerNet, in which the feature interactions are learned in a complex vector space by conducting space mapping according to Euler's formula. EulerNet converts the exponential power
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#31639;&#27861;&#37319;&#26679;&#29992;&#25143;&#31354;&#38388;&#20559;&#22909;&#30340;POI&#25512;&#33616;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#21482;&#22522;&#20110;&#29992;&#25143;&#20808;&#21069;&#35775;&#38382;&#20301;&#32622;&#32858;&#21512;&#30340;&#32570;&#28857;&#65292;&#36866;&#29992;&#20110;&#25512;&#33616;&#26032;&#39062;&#21306;&#22495;&#30340;POI&#12290;</title><link>http://arxiv.org/abs/2304.07041</link><description>&lt;p&gt;
&#19968;&#31181;POI&#25512;&#33616;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Diffusion model for POI recommendation. (arXiv:2304.07041v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#31639;&#27861;&#37319;&#26679;&#29992;&#25143;&#31354;&#38388;&#20559;&#22909;&#30340;POI&#25512;&#33616;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#21482;&#22522;&#20110;&#29992;&#25143;&#20808;&#21069;&#35775;&#38382;&#20301;&#32622;&#32858;&#21512;&#30340;&#32570;&#28857;&#65292;&#36866;&#29992;&#20110;&#25512;&#33616;&#26032;&#39062;&#21306;&#22495;&#30340;POI&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19979;&#19968;&#20010;&#20852;&#36259;&#28857;&#65288;POI&#65289;&#30340;&#25512;&#33616;&#26159;&#23450;&#20301;&#26381;&#21153;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#65292;&#26088;&#22312;&#20026;&#29992;&#25143;&#30340;&#19979;&#19968;&#20010;&#30446;&#30340;&#22320;&#25552;&#20379;&#20010;&#24615;&#21270;&#24314;&#35758;&#12290;&#20808;&#21069;&#20851;&#20110;POI&#25512;&#33616;&#30340;&#24037;&#20316;&#20391;&#37325;&#20110;&#23545;&#29992;&#25143;&#31354;&#38388;&#20559;&#22909;&#30340;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#21033;&#29992;&#31354;&#38388;&#20449;&#24687;&#30340;&#26041;&#27861;&#20165;&#22522;&#20110;&#29992;&#25143;&#20808;&#21069;&#35775;&#38382;&#20301;&#32622;&#30340;&#32858;&#21512;&#65292;&#36825;&#20250;&#20351;&#27169;&#22411;&#19981;&#20250;&#25512;&#33616;&#26032;&#39062;&#21306;&#22495;&#30340;POI&#65292;&#20174;&#32780;&#25439;&#23475;&#20854;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#23558;&#26102;&#38388;&#39034;&#24207;&#20449;&#24687;&#34701;&#20837;&#29992;&#25143;&#30340;&#31354;&#38388;&#20559;&#22909;&#20173;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Diff-POI&#65306;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#37319;&#26679;&#29992;&#25143;&#30340;&#31354;&#38388;&#20559;&#22909;&#65292;&#20197;&#36827;&#34892;&#19979;&#19968;&#27493;POI&#25512;&#33616;&#12290;&#22312;&#25193;&#25955;&#31639;&#27861;&#22312;&#20174;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#26041;&#38754;&#30340;&#24191;&#27867;&#24212;&#29992;&#30340;&#21551;&#21457;&#19979;&#65292;Diff-POI&#20351;&#29992;&#20004;&#20010;&#37327;&#36523;&#23450;&#21046;&#30340;&#22270;&#32534;&#30721;&#27169;&#22359;&#23545;&#29992;&#25143;&#30340;&#35775;&#38382;&#24207;&#21015;&#21644;&#31354;&#38388;&#29305;&#24615;&#36827;&#34892;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Next Point-of-Interest (POI) recommendation is a critical task in location-based services that aim to provide personalized suggestions for the user's next destination. Previous works on POI recommendation have laid focused on modeling the user's spatial preference. However, existing works that leverage spatial information are only based on the aggregation of users' previous visited positions, which discourages the model from recommending POIs in novel areas. This trait of position-based methods will harm the model's performance in many situations. Additionally, incorporating sequential information into the user's spatial preference remains a challenge. In this paper, we propose Diff-POI: a Diffusion-based model that samples the user's spatial preference for the next POI recommendation. Inspired by the wide application of diffusion algorithm in sampling from distributions, Diff-POI encodes the user's visiting sequence and spatial character with two tailor-designed graph encoding modules
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#32508;&#21512;&#35780;&#20272;&#20102;&#26102;&#23578;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#26368;&#26032;&#30740;&#31350;&#36827;&#23637;&#65292;&#24182;&#20998;&#31867;&#24635;&#32467;&#20986;&#29289;&#21697;&#21644;&#26381;&#35013;&#25512;&#33616;&#12289;&#23610;&#23544;&#25512;&#33616;&#21644;&#21487;&#35299;&#37322;&#24615;&#31561;&#26041;&#38754;&#30340;&#30740;&#31350;&#29616;&#29366;&#12290;</title><link>http://arxiv.org/abs/2202.02757</link><description>&lt;p&gt;
&#29616;&#20195;&#26102;&#23578;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Review of Modern Fashion Recommender Systems. (arXiv:2202.02757v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.02757
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#32508;&#21512;&#35780;&#20272;&#20102;&#26102;&#23578;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#26368;&#26032;&#30740;&#31350;&#36827;&#23637;&#65292;&#24182;&#20998;&#31867;&#24635;&#32467;&#20986;&#29289;&#21697;&#21644;&#26381;&#35013;&#25512;&#33616;&#12289;&#23610;&#23544;&#25512;&#33616;&#21644;&#21487;&#35299;&#37322;&#24615;&#31561;&#26041;&#38754;&#30340;&#30740;&#31350;&#29616;&#29366;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#32442;&#32455;&#21644;&#26381;&#35013;&#34892;&#19994;&#34028;&#21187;&#21457;&#23637;&#12290;&#39038;&#23458;&#19981;&#20877;&#38656;&#35201;&#20146;&#33258;&#21435;&#23454;&#20307;&#24215;&#38754;&#65292;&#25490;&#38431;&#35797;&#31359;&#34915;&#29289;&#65292;&#22240;&#20026;&#25104;&#21315;&#19978;&#19975;&#30340;&#20135;&#21697;&#29616;&#22312;&#37117;&#21487;&#20197;&#22312;&#22312;&#32447;&#30446;&#24405;&#20013;&#25214;&#21040;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36873;&#39033;&#22826;&#22810;&#65292;&#19968;&#20010;&#26377;&#25928;&#30340;&#25512;&#33616;&#31995;&#32479;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#20197;&#20415;&#26377;&#25928;&#22320;&#25490;&#24207;&#12289;&#25972;&#29702;&#24182;&#21521;&#29992;&#25143;&#20256;&#36798;&#30456;&#20851;&#30340;&#20135;&#21697;&#36164;&#26009;&#25110;&#20449;&#24687;&#12290;&#26377;&#25928;&#30340;&#26102;&#23578;&#25512;&#33616;&#31995;&#32479;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#25968;&#21313;&#20159;&#39038;&#23458;&#30340;&#36141;&#29289;&#20307;&#39564;&#65292;&#24182;&#22686;&#21152;&#25552;&#20379;&#21830;&#30340;&#38144;&#21806;&#21644;&#25910;&#20837;&#12290;&#26412;&#32508;&#36848;&#30340;&#30446;&#30340;&#26159;&#23545;&#22312;&#26381;&#35013;&#21644;&#26102;&#23578;&#20135;&#21697;&#29305;&#23450;&#22402;&#30452;&#39046;&#22495;&#36816;&#34892;&#30340;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#32508;&#36848;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#26102;&#23578;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#20013;&#26368;&#32039;&#36843;&#30340;&#25361;&#25112;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;&#23427;&#20204;&#35797;&#22270;&#23454;&#29616;&#30340;&#30446;&#26631;&#65288;&#20363;&#22914;&#65292;&#29289;&#21697;&#25110;&#26381;&#35013;&#25512;&#33616;&#12289;&#23610;&#23544;&#25512;&#33616;&#12289;&#21487;&#35299;&#37322;&#24615;&#65289;&#23545;&#25991;&#29486;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
The textile and apparel industries have grown tremendously over the last few years. Customers no longer have to visit many stores, stand in long queues, or try on garments in dressing rooms as millions of products are now available in online catalogs. However, given the plethora of options available, an effective recommendation system is necessary to properly sort, order, and communicate relevant product material or information to users. Effective fashion RS can have a noticeable impact on billions of customers' shopping experiences and increase sales and revenues on the provider side.  The goal of this survey is to provide a review of recommender systems that operate in the specific vertical domain of garment and fashion products. We have identified the most pressing challenges in fashion RS research and created a taxonomy that categorizes the literature according to the objective they are trying to accomplish (e.g., item or outfit recommendation, size recommendation, explainability, 
&lt;/p&gt;</description></item></channel></rss>