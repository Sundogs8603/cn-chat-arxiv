<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31383;&#21475;&#36807;&#28388;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#35821;&#20041;&#25628;&#32034;&#38382;&#39064;&#20013;&#23454;&#29616;&#39640;&#36895;&#25628;&#32034;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36895;&#24230;&#25552;&#21319;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00943</link><description>&lt;p&gt;
&#20351;&#29992;&#31383;&#21475;&#36807;&#28388;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Approximate Nearest Neighbor Search with Window Filters
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00943
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31383;&#21475;&#36807;&#28388;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#35821;&#20041;&#25628;&#32034;&#38382;&#39064;&#20013;&#23454;&#29616;&#39640;&#36895;&#25628;&#32034;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36895;&#24230;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23450;&#20041;&#24182;&#30740;&#31350;&#20102;$\textit{c-&#36817;&#20284;&#31383;&#21475;&#25628;&#32034;}$&#38382;&#39064;&#65306;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#20854;&#20013;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#28857;&#37117;&#26377;&#19968;&#20010;&#25968;&#20540;&#26631;&#31614;&#65292;&#30446;&#26631;&#26159;&#22312;&#20219;&#24847;&#26631;&#31614;&#33539;&#22260;&#20869;&#25214;&#21040;&#26597;&#35810;&#28857;&#30340;&#26368;&#36817;&#37051;&#12290;&#35768;&#22810;&#35821;&#20041;&#25628;&#32034;&#38382;&#39064;&#65292;&#20363;&#22914;&#24102;&#26377;&#26102;&#38388;&#25139;&#36807;&#28388;&#22120;&#30340;&#22270;&#20687;&#21644;&#25991;&#26723;&#25628;&#32034;&#65292;&#25110;&#24102;&#26377;&#25104;&#26412;&#36807;&#28388;&#22120;&#30340;&#20135;&#21697;&#25628;&#32034;&#65292;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#33258;&#28982;&#20363;&#23376;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#22312;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22359;&#21270;&#26641;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#35299;&#20915;&#20256;&#32479;c-&#36817;&#20284;&#26368;&#36817;&#37051;&#38382;&#39064;&#30340;&#32034;&#24341;&#36716;&#21270;&#20026;&#35299;&#20915;&#31383;&#21475;&#25628;&#32034;&#30340;&#25968;&#25454;&#32467;&#26500;&#12290;&#22312;&#26631;&#20934;&#30340;&#26368;&#36817;&#37051;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#65292;&#37197;&#22791;&#20102;&#38543;&#26426;&#26631;&#31614;&#20540;&#12289;&#23545;&#25239;&#24615;&#26500;&#24314;&#30340;&#23884;&#20837;&#20197;&#21450;&#24102;&#26377;&#30495;&#23454;&#26102;&#38388;&#25139;&#30340;&#22270;&#20687;&#25628;&#32034;&#23884;&#20837;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19982;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30456;&#27604;&#39640;&#36798;75&#20493;&#30340;&#36895;&#24230;&#25552;&#21319;&#65292;&#21516;&#26102;&#20445;&#25345;&#30456;&#21516;&#30340;&#21484;&#22238;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We define and investigate the problem of $\textit{c-approximate window search}$: approximate nearest neighbor search where each point in the dataset has a numeric label, and the goal is to find nearest neighbors to queries within arbitrary label ranges. Many semantic search problems, such as image and document search with timestamp filters, or product search with cost filters, are natural examples of this problem. We propose and theoretically analyze a modular tree-based framework for transforming an index that solves the traditional c-approximate nearest neighbor problem into a data structure that solves window search. On standard nearest neighbor benchmark datasets equipped with random label values, adversarially constructed embeddings, and image search embeddings with real timestamps, we obtain up to a $75\times$ speedup over existing solutions at the same level of recall.
&lt;/p&gt;</description></item><item><title>RAM-EHR&#36890;&#36807;&#22686;&#24378;&#26816;&#32034;&#24182;&#21033;&#29992;&#24635;&#32467;&#30693;&#35782;&#65292;&#25552;&#39640;&#20102;&#38024;&#23545;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#20020;&#24202;&#39044;&#27979;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.00815</link><description>&lt;p&gt;
RAM-EHR: &#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#19978;&#30340;&#26816;&#32034;&#22686;&#24378;&#19982;&#20020;&#24202;&#39044;&#27979;&#30456;&#36935;
&lt;/p&gt;
&lt;p&gt;
RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00815
&lt;/p&gt;
&lt;p&gt;
RAM-EHR&#36890;&#36807;&#22686;&#24378;&#26816;&#32034;&#24182;&#21033;&#29992;&#24635;&#32467;&#30693;&#35782;&#65292;&#25552;&#39640;&#20102;&#38024;&#23545;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#20020;&#24202;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;RAM-EHR&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#25913;&#21892;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#19978;&#20020;&#24202;&#39044;&#27979;&#30340;&#26816;&#32034;&#22686;&#24378;&#65288;Retrieval Augmentation&#65289;&#27969;&#31243;&#12290;RAM-EHR&#39318;&#20808;&#25910;&#38598;&#22810;&#20010;&#30693;&#35782;&#26469;&#28304;&#65292;&#23558;&#23427;&#20204;&#36716;&#25442;&#20026;&#25991;&#26412;&#26684;&#24335;&#65292;&#24182;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#26469;&#33719;&#21462;&#19982;&#21307;&#23398;&#27010;&#24565;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;&#36825;&#19968;&#31574;&#30053;&#35299;&#20915;&#20102;&#19982;&#22797;&#26434;&#27010;&#24565;&#21517;&#31216;&#30456;&#20851;&#30340;&#22256;&#38590;&#12290;RAM-EHR&#28982;&#21518;&#22686;&#24191;&#20102;&#19982;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#20195;&#30721;&#32852;&#21512;&#35757;&#32451;&#30340;&#26412;&#22320;EHR&#39044;&#27979;&#27169;&#22411;&#65292;&#20197;&#25429;&#33719;&#26469;&#33258;&#24739;&#32773;&#23601;&#35786;&#21644;&#24635;&#32467;&#30693;&#35782;&#30340;&#20114;&#34917;&#20449;&#24687;&#12290;&#22312;&#20004;&#20010;EHR&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;RAM-EHR&#30456;&#23545;&#20110;&#20043;&#21069;&#30340;&#30693;&#35782;&#22686;&#24378;&#22522;&#32447;&#25928;&#26524;&#26174;&#33879;&#65288;AUROC&#22686;&#30410;3.4&#65285;&#65292;AUPR&#22686;&#30410;7.2&#65285;&#65289;&#65292;&#24378;&#35843;&#20102;RAM-EHR&#30340;&#24635;&#32467;&#30693;&#35782;&#23545;&#20020;&#24202;&#39044;&#27979;&#20219;&#21153;&#30340;&#26377;&#25928;&#24615;&#12290;&#20195;&#30721;&#23558;&#21457;&#24067;&#22312;\url{https://github.com/ritaranx/RAM-EHR}&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00815v1 Announce Type: cross  Abstract: We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \url{https://github.com/ritaranx/RAM-EHR}.
&lt;/p&gt;</description></item><item><title>ARL2&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#21033;&#29992;LLMs&#20316;&#20026;&#26631;&#27880;&#32773;&#65292;&#24182;&#37319;&#29992;&#33258;&#36866;&#24212;&#33258;&#35757;&#32451;&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#23569;&#27880;&#37322;&#25104;&#26412;&#65292;&#24182;&#22312;NQ&#21644;MMLU&#19978;&#21462;&#24471;&#20102;5.4%&#21644;4.6%&#30340;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.13542</link><description>&lt;p&gt;
ARL2: &#36890;&#36807;&#33258;&#23548;&#33258;&#36866;&#24212;&#30456;&#20851;&#24615;&#26631;&#35760;&#23558;&#26816;&#32034;&#22120;&#19982;&#40657;&#30418;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13542
&lt;/p&gt;
&lt;p&gt;
ARL2&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#21033;&#29992;LLMs&#20316;&#20026;&#26631;&#27880;&#32773;&#65292;&#24182;&#37319;&#29992;&#33258;&#36866;&#24212;&#33258;&#35757;&#32451;&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#23569;&#27880;&#37322;&#25104;&#26412;&#65292;&#24182;&#22312;NQ&#21644;MMLU&#19978;&#21462;&#24471;&#20102;5.4%&#21644;4.6%&#30340;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13542v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449; &#25688;&#35201;: &#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#36890;&#36807;&#25972;&#21512;&#22806;&#37096;&#30693;&#35782;&#28304;&#30340;&#30456;&#20851;&#20449;&#24687;&#25913;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#20351;LLMs&#33021;&#22815;&#36866;&#24212;&#29305;&#23450;&#39046;&#22495;&#65292;&#24182;&#20943;&#36731;&#30693;&#35782;&#23494;&#38598;&#20219;&#21153;&#20013;&#30340;&#24187;&#35273;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#20998;&#24320;&#30340;&#35757;&#32451;&#36807;&#31243;&#21644;LLMs&#30340;&#40657;&#30418;&#29305;&#24615;&#65292;&#29616;&#26377;&#30340;&#26816;&#32034;&#22120;&#36890;&#24120;&#19982;LLMs&#19981;&#21305;&#37197;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ARL2&#65292;&#19968;&#31181;&#21033;&#29992;LLMs&#20316;&#20026;&#26631;&#27880;&#32773;&#30340;&#26816;&#32034;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;ARL2&#21033;&#29992;LLMs&#27880;&#37322;&#21644;&#35780;&#20998;&#30456;&#20851;&#35777;&#25454;&#65292;&#20174;&#32780;&#33021;&#22815;&#20174;&#24378;&#22823;&#30340;LLM&#30417;&#30563;&#20013;&#23398;&#20064;&#26816;&#32034;&#22120;&#12290;&#27492;&#22806;&#65292;ARL2&#20351;&#29992;&#33258;&#36866;&#24212;&#33258;&#35757;&#32451;&#31574;&#30053;&#26469;&#31574;&#21010;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#30456;&#20851;&#24615;&#25968;&#25454;&#65292;&#21487;&#20197;&#26377;&#25928;&#38477;&#20302;&#26631;&#27880;&#25104;&#26412;&#12290;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;ARL2&#30340;&#26377;&#25928;&#24615;&#65292;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;NQ&#19978;&#25552;&#39640;&#20102;5.4%&#30340;&#20934;&#30830;&#29575;&#65292;&#22312;MMLU&#19978;&#25552;&#39640;&#20102;4.6%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13542v1 Announce Type: cross  Abstract: Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with LLMs due to their separate training processes and the black-box nature of LLMs. To address this challenge, we propose ARL2, a retriever learning technique that harnesses LLMs as labelers. ARL2 leverages LLMs to annotate and score relevant evidence, enabling learning the retriever from robust LLM supervision. Furthermore, ARL2 uses an adaptive self-training strategy for curating high-quality and diverse relevance data, which can effectively reduce the annotation cost. Extensive experiments demonstrate the effectiveness of ARL2, achieving accuracy improvements of 5.4% on NQ and 4.6% on MMLU compared to the state-of-the-art methods. Additionall
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;LLM-&#35748;&#30693;&#25968;&#25454;&#22686;&#24378;&#30340;&#26041;&#27861;&#26469;&#24191;&#20041;&#23545;&#35805;&#23494;&#38598;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#29983;&#25104;&#22810;&#32423;&#22686;&#24378;&#23545;&#35805;&#65292;&#25429;&#25417;&#22810;&#26679;&#30340;&#23545;&#35805;&#29615;&#22659;&#12290;&#20854;&#27425;&#65292;&#36890;&#36807;&#35748;&#30693;&#24863;&#30693;&#36807;&#31243;&#20943;&#23569;&#38169;&#35823;&#29983;&#25104;&#24773;&#20917;&#65292;&#24182;&#36890;&#36807;&#38590;&#24230;&#33258;&#36866;&#24212;&#26679;&#26412;&#31579;&#36873;&#22120;&#36873;&#25321;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26679;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.07092</link><description>&lt;p&gt;
&#36890;&#36807;LLM-&#35748;&#30693;&#25968;&#25454;&#22686;&#24378;&#24191;&#20041;&#23545;&#35805;&#23494;&#38598;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Generalizing Conversational Dense Retrieval via LLM-Cognition Data Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;LLM-&#35748;&#30693;&#25968;&#25454;&#22686;&#24378;&#30340;&#26041;&#27861;&#26469;&#24191;&#20041;&#23545;&#35805;&#23494;&#38598;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#29983;&#25104;&#22810;&#32423;&#22686;&#24378;&#23545;&#35805;&#65292;&#25429;&#25417;&#22810;&#26679;&#30340;&#23545;&#35805;&#29615;&#22659;&#12290;&#20854;&#27425;&#65292;&#36890;&#36807;&#35748;&#30693;&#24863;&#30693;&#36807;&#31243;&#20943;&#23569;&#38169;&#35823;&#29983;&#25104;&#24773;&#20917;&#65292;&#24182;&#36890;&#36807;&#38590;&#24230;&#33258;&#36866;&#24212;&#26679;&#26412;&#31579;&#36873;&#22120;&#36873;&#25321;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#25628;&#32034;&#21033;&#29992;&#22810;&#36718;&#33258;&#28982;&#35821;&#35328;&#29615;&#22659;&#26469;&#26816;&#32034;&#30456;&#20851;&#27573;&#33853;&#12290;&#29616;&#26377;&#30340;&#23545;&#35805;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#22823;&#22810;&#23558;&#23545;&#35805;&#35270;&#20026;&#19968;&#31995;&#21015;&#22266;&#23450;&#30340;&#38382;&#39064;&#21644;&#22238;&#31572;&#65292;&#24573;&#35270;&#20102;&#20005;&#37325;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064; - &#20063;&#23601;&#26159;&#35828;&#65292;&#29992;&#25143;&#21487;&#20197;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#36827;&#34892;&#23545;&#35805;&#65292;&#32780;&#36825;&#20123;&#22791;&#36873;&#23545;&#35805;&#26159;&#26410;&#35760;&#24405;&#30340;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#32463;&#24120;&#38590;&#20197;&#25512;&#24191;&#21040;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#22810;&#26679;&#23545;&#35805;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;LLM-&#35748;&#30693;&#25968;&#25454;&#22686;&#24378;&#24191;&#20041;&#23545;&#35805;&#23494;&#38598;&#26816;&#32034;&#30340;&#26694;&#26550;(ConvAug)&#12290;ConvAug&#39318;&#20808;&#29983;&#25104;&#22810;&#32423;&#22686;&#24378;&#23545;&#35805;&#65292;&#20197;&#25429;&#25417;&#23545;&#35805;&#29615;&#22659;&#30340;&#22810;&#26679;&#24615;&#12290;&#21463;&#20154;&#31867;&#35748;&#30693;&#26041;&#24335;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#35748;&#30693;&#24863;&#30693;&#36807;&#31243;&#65292;&#20197;&#20943;&#23569;&#38169;&#35823;&#30340;&#27491;&#20363;&#12289;&#36127;&#20363;&#21644;&#24187;&#35273;&#30340;&#29983;&#25104;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#38590;&#24230;&#33258;&#36866;&#24212;&#26679;&#26412;&#31579;&#36873;&#22120;&#65292;&#29992;&#20110;&#36873;&#25321;&#22797;&#26434;&#23545;&#35805;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational search utilizes muli-turn natural language contexts to retrieve relevant passages. Existing conversational dense retrieval models mostly view a conversation as a fixed sequence of questions and responses, overlooking the severe data sparsity problem -- that is, users can perform a conversation in various ways, and these alternate conversations are unrecorded. Consequently, they often struggle to generalize to diverse conversations in real-world scenarios. In this work, we propose a framework for generalizing Conversational dense retrieval via LLM-cognition data Augmentation (ConvAug). ConvAug first generates multi-level augmented conversations to capture the diverse nature of conversational contexts. Inspired by human cognition, we devise a cognition-aware process to mitigate the generation of false positives, false negatives, and hallucinations. Moreover, we develop a difficulty-adaptive sample filter that selects challenging samples for complex conversations, thereby g
&lt;/p&gt;</description></item><item><title>C-RAG&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#35748;&#35777;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#39118;&#38505;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#31526;&#21512;&#39118;&#38505;&#20998;&#26512;&#21644;&#29983;&#25104;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#30830;&#20445;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#20449;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03181</link><description>&lt;p&gt;
C-RAG: &#38024;&#23545;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#35748;&#35777;&#29983;&#25104;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03181
&lt;/p&gt;
&lt;p&gt;
C-RAG&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#35748;&#35777;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#39118;&#38505;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#31526;&#21512;&#39118;&#38505;&#20998;&#26512;&#21644;&#29983;&#25104;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#30830;&#20445;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#20449;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20855;&#22791;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#23384;&#22312;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#22914;&#24187;&#35273;&#21644;&#38169;&#20301;&#12290;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#65288;RAG&#65289;&#34987;&#25552;&#20986;&#26469;&#22686;&#24378;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#20449;&#24615;&#65292;&#36890;&#36807;&#24341;&#20837;&#22806;&#37096;&#30693;&#35782;&#12290;&#20294;&#26159;&#65292;&#23545;&#20110;RAG&#27169;&#22411;&#30340;&#29983;&#25104;&#39118;&#38505;&#30340;&#29702;&#35770;&#29702;&#35299;&#23578;&#26410;&#34987;&#30740;&#31350;&#12290;&#26412;&#25991;&#22238;&#31572;&#20102;&#20197;&#19979;&#38382;&#39064;&#65306;1&#65289;RAG&#26159;&#21542;&#30830;&#23454;&#33021;&#22815;&#38477;&#20302;&#29983;&#25104;&#39118;&#38505;&#65292;2&#65289;&#22914;&#20309;&#23545;RAG&#21644;&#20256;&#32479;LLM&#30340;&#29983;&#25104;&#39118;&#38505;&#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#65292;&#20197;&#21450;3&#65289;&#21738;&#20123;&#20805;&#20998;&#26465;&#20214;&#20351;&#24471;RAG&#27169;&#22411;&#33021;&#22815;&#38477;&#20302;&#29983;&#25104;&#39118;&#38505;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;C-RAG&#65292;&#31532;&#19968;&#20010;&#29992;&#20110;&#35748;&#35777;RAG&#27169;&#22411;&#29983;&#25104;&#39118;&#38505;&#30340;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20026;RAG&#27169;&#22411;&#25552;&#20379;&#20102;&#31526;&#21512;&#39118;&#38505;&#20998;&#26512;&#65292;&#24182;&#30830;&#20445;&#20102;&#29983;&#25104;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#31526;&#21512;&#29983;&#25104;&#39118;&#38505;&#12290;&#25105;&#20204;&#36824;&#23545;&#19968;&#33324;&#26377;&#30028;&#39118;&#38505;&#19979;&#30340;&#31526;&#21512;&#29983;&#25104;&#39118;&#38505;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, the first framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk f
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20013;&#20171;&#32461;&#20102;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#20013;&#30340;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21098;&#26525;&#25968;&#25454;&#26469;&#20943;&#23569;LLM&#30340;&#24494;&#35843;&#25104;&#26412;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#30446;&#26631;&#26469;&#23454;&#29616;&#39640;&#20934;&#30830;&#24615;&#30340;&#25968;&#25454;&#21098;&#26525;&#12290;</title><link>https://arxiv.org/abs/2401.17197</link><description>&lt;p&gt;
&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#30340;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Data-efficient Fine-tuning for LLM-based Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17197
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20013;&#20171;&#32461;&#20102;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#20013;&#30340;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21098;&#26525;&#25968;&#25454;&#26469;&#20943;&#23569;LLM&#30340;&#24494;&#35843;&#25104;&#26412;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#30446;&#26631;&#26469;&#23454;&#29616;&#39640;&#20934;&#30830;&#24615;&#30340;&#25968;&#25454;&#21098;&#26525;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#25512;&#33616;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20854;&#20013;&#24494;&#35843;&#22312;LLM&#30340;&#36866;&#24212;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#24555;&#36895;&#25193;&#23637;&#30340;&#25512;&#33616;&#25968;&#25454;&#19978;&#24494;&#35843;LLM&#30340;&#25104;&#26412;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#23569;&#26679;&#26412;&#24494;&#35843;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#36866;&#24212;LLM&#21040;&#26032;&#30340;&#25512;&#33616;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20026;&#39640;&#25928;&#30340;LLM&#25512;&#33616;&#20219;&#21153;&#21098;&#26525;&#25968;&#25454;&#30340;&#20219;&#21153;&#65292;&#26088;&#22312;&#25214;&#21040;&#36866;&#21512;LLM&#30340;&#23569;&#26679;&#26412;&#24494;&#35843;&#30340;&#20195;&#34920;&#26679;&#26412;&#12290;&#34429;&#28982;&#26680;&#24515;&#38598;&#36873;&#25321;&#19982;&#25152;&#25552;&#20986;&#30340;&#20219;&#21153;&#23494;&#20999;&#30456;&#20851;&#65292;&#20294;&#29616;&#26377;&#30340;&#26680;&#24515;&#38598;&#36873;&#25321;&#26041;&#27861;&#24448;&#24448;&#20381;&#36182;&#20110;&#27425;&#20248;&#21551;&#21457;&#24335;&#25351;&#26631;&#25110;&#38656;&#35201;&#22312;&#22823;&#35268;&#27169;&#25512;&#33616;&#25968;&#25454;&#19978;&#36827;&#34892;&#26114;&#36149;&#30340;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models (LLMs) for recommendation has recently garnered considerable attention, where fine-tuning plays a key role in LLMs' adaptation. However, the cost of fine-tuning LLMs on rapidly expanding recommendation data limits their practical application. To address this challenge, few-shot fine-tuning offers a promising approach to quickly adapt LLMs to new recommendation data. We propose the task of data pruning for efficient LLM-based recommendation, aimed at identifying representative samples tailored for LLMs' few-shot fine-tuning. While coreset selection is closely related to the proposed task, existing coreset selection methods often rely on suboptimal heuristic metrics or entail costly optimization on large-scale recommendation data.   To tackle these issues, we introduce two objectives for the data pruning task in the context of LLM-based recommendation: 1) high accuracy aims to identify the influential samples that can lead to high overall performance; and
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#25506;&#32034;&#20854;&#21033;&#29992;&#29992;&#25143;&#20559;&#22909;&#36827;&#34892;&#25512;&#33616;&#12289;&#37325;&#26032;&#25490;&#24207;&#25512;&#33616;&#21015;&#34920;&#12289;&#21033;&#29992;&#30456;&#20284;&#29992;&#25143;&#20449;&#24687;&#20197;&#21450;&#22788;&#29702;&#20919;&#21551;&#21160;&#24773;&#20917;&#30340;&#33021;&#21147;&#65292;&#24182;&#20351;&#29992;&#19977;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#20840;&#38754;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2309.03613</link><description>&lt;p&gt;
&#35780;&#20272;ChatGPT&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#30340;&#20005;&#35880;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Evaluating ChatGPT as a Recommender System: A Rigorous Approach. (arXiv:2309.03613v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03613
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#25506;&#32034;&#20854;&#21033;&#29992;&#29992;&#25143;&#20559;&#22909;&#36827;&#34892;&#25512;&#33616;&#12289;&#37325;&#26032;&#25490;&#24207;&#25512;&#33616;&#21015;&#34920;&#12289;&#21033;&#29992;&#30456;&#20284;&#29992;&#25143;&#20449;&#24687;&#20197;&#21450;&#22788;&#29702;&#20919;&#21551;&#21160;&#24773;&#20917;&#30340;&#33021;&#21147;&#65292;&#24182;&#20351;&#29992;&#19977;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#20840;&#38754;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#21331;&#36234;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#33021;&#21147;&#65292;&#22823;&#22411;AI&#35821;&#35328;&#27169;&#22411;&#36817;&#24180;&#26469;&#22791;&#21463;&#20851;&#27880;&#12290;&#23427;&#20204;&#22312;&#35821;&#35328;&#30456;&#20851;&#20219;&#21153;&#20013;&#20855;&#26377;&#37325;&#35201;&#36129;&#29486;&#65292;&#21253;&#25324;&#22522;&#20110;&#25552;&#31034;&#30340;&#23398;&#20064;&#65292;&#22240;&#27492;&#23545;&#20110;&#21508;&#31181;&#29305;&#23450;&#20219;&#21153;&#38750;&#24120;&#26377;&#20215;&#20540;&#12290;&#36825;&#31181;&#26041;&#27861;&#37322;&#25918;&#20102;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#65292;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#24615;&#12290;&#30740;&#31350;&#30028;&#27491;&#22312;&#31215;&#26497;&#25506;&#32034;&#23427;&#20204;&#30340;&#24212;&#29992;&#65292;ChatGPT&#20063;&#22240;&#27492;&#33719;&#24471;&#20102;&#35748;&#21487;&#12290;&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#26377;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#65292;&#20294;&#20854;&#22312;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#28508;&#21147;&#20173;&#24453;&#25506;&#32034;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#36890;&#36807;&#25506;&#31350;ChatGPT&#20316;&#20026;&#38646;-shot&#25512;&#33616;&#31995;&#32479;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#21253;&#25324;&#35780;&#20272;&#20854;&#21033;&#29992;&#29992;&#25143;&#20559;&#22909;&#36827;&#34892;&#25512;&#33616;&#12289;&#37325;&#26032;&#25490;&#24207;&#29616;&#26377;&#25512;&#33616;&#21015;&#34920;&#12289;&#21033;&#29992;&#30456;&#20284;&#29992;&#25143;&#30340;&#20449;&#24687;&#20197;&#21450;&#22788;&#29702;&#20919;&#21551;&#21160;&#24773;&#20917;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19977;&#20010;&#25968;&#25454;&#38598;&#65288;MovieLens Small&#12289;Last.FM&#21644;Facebook Bo&#65289;&#36827;&#34892;&#20840;&#38754;&#23454;&#39564;&#26469;&#35780;&#20272;ChatGPT&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent popularity surrounds large AI language models due to their impressive natural language capabilities. They contribute significantly to language-related tasks, including prompt-based learning, making them valuable for various specific tasks. This approach unlocks their full potential, enhancing precision and generalization. Research communities are actively exploring their applications, with ChatGPT receiving recognition. Despite extensive research on large language models, their potential in recommendation scenarios still needs to be explored. This study aims to fill this gap by investigating ChatGPT's capabilities as a zero-shot recommender system. Our goals include evaluating its ability to use user preferences for recommendations, reordering existing recommendation lists, leveraging information from similar users, and handling cold-start situations. We assess ChatGPT's performance through comprehensive experiments using three datasets (MovieLens Small, Last.FM, and Facebook Bo
&lt;/p&gt;</description></item></channel></rss>