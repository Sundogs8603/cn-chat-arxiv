<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#21363;&#20026;&#30740;&#31350;&#35770;&#25991;&#29983;&#25104;&#24314;&#35758;&#24615;&#23616;&#38480;&#65292;&#36890;&#36807;&#35843;&#26597;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#31181;&#26041;&#27861;&#26469;&#25581;&#31034;&#30456;&#20851;&#25361;&#25112;&#12289;&#23454;&#36341;&#35265;&#35299;&#21644;&#28508;&#22312;&#26426;&#20250;&#12290;</title><link>https://arxiv.org/abs/2403.15529</link><description>&lt;p&gt;
LimGen: &#25506;&#31350;&#29992;&#20110;&#29983;&#25104;&#30740;&#31350;&#35770;&#25991;&#24314;&#35758;&#24615;&#23616;&#38480;&#30340;LLMs
&lt;/p&gt;
&lt;p&gt;
LimGen: Probing the LLMs for Generating Suggestive Limitations of Research Papers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15529
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#21363;&#20026;&#30740;&#31350;&#35770;&#25991;&#29983;&#25104;&#24314;&#35758;&#24615;&#23616;&#38480;&#65292;&#36890;&#36807;&#35843;&#26597;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#31181;&#26041;&#27861;&#26469;&#25581;&#31034;&#30456;&#20851;&#25361;&#25112;&#12289;&#23454;&#36341;&#35265;&#35299;&#21644;&#28508;&#22312;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#26597;&#23616;&#38480;&#26159;&#23398;&#26415;&#30740;&#31350;&#35780;&#23457;&#36807;&#31243;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#25581;&#31034;&#20102;&#30740;&#31350;&#21487;&#33021;&#32570;&#20047;&#20915;&#23450;&#24615;&#25110;&#38656;&#35201;&#21152;&#24378;&#30340;&#26041;&#38754;&#12290;&#36825;&#26377;&#21161;&#20110;&#35835;&#32773;&#32771;&#34385;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#26356;&#24191;&#27867;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#30740;&#31350;&#35770;&#25991;&#24314;&#35758;&#24615;&#23616;&#38480;&#29983;&#25104;&#65288;SLG&#65289;&#30340;&#19968;&#39033;&#26032;&#39062;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#32534;&#21046;&#20102;&#19968;&#20010;&#21517;&#20026;LimGen&#30340;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#26469;&#33258;ACL&#25991;&#38598;&#30340;4068&#31687;&#30740;&#31350;&#35770;&#25991;&#21450;&#20854;&#30456;&#20851;&#23616;&#38480;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;&#22810;&#31181;&#26041;&#27861;&#26469;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#24314;&#35758;&#24615;&#23616;&#38480;&#65292;&#36890;&#36807;&#24443;&#24213;&#30740;&#31350;&#30456;&#20851;&#25361;&#25112;&#12289;&#23454;&#36341;&#35265;&#35299;&#21644;&#28508;&#22312;&#26426;&#20250;&#12290;&#25105;&#20204;&#30340;LimGen&#25968;&#25454;&#38598;&#21644;&#20195;&#30721;&#21487;&#20197;&#22312;https://github.com/armbf/LimGen &#19978;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15529v1 Announce Type: cross  Abstract: Examining limitations is a crucial step in the scholarly research reviewing process, revealing aspects where a study might lack decisiveness or require enhancement. This aids readers in considering broader implications for further research. In this article, we present a novel and challenging task of Suggestive Limitation Generation (SLG) for research papers. We compile a dataset called LimGen, encompassing 4068 research papers and their associated limitations from the ACL anthology. We investigate several approaches to harness large language models (LLMs) for producing suggestive limitations, by thoroughly examining the related challenges, practical insights, and potential opportunities. Our LimGen dataset and code can be accessed at https://github.com/armbf/LimGen.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;TopMost&#30340;&#20027;&#39064;&#24314;&#27169;&#31995;&#32479;&#24037;&#20855;&#21253;&#65292;&#36890;&#36807;&#28085;&#30422;&#26356;&#24191;&#27867;&#30340;&#20027;&#39064;&#24314;&#27169;&#22330;&#26223;&#21644;&#20855;&#26377;&#39640;&#24230;&#20957;&#32858;&#21147;&#21644;&#35299;&#32806;&#27169;&#22359;&#21270;&#35774;&#35745;&#30340;&#29305;&#28857;&#65292;&#21487;&#20197;&#20419;&#36827;&#20027;&#39064;&#27169;&#22411;&#30340;&#30740;&#31350;&#21644;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.06908</link><description>&lt;p&gt;
&#36208;&#21521;TopMost&#65306;&#19968;&#20010;&#20027;&#39064;&#24314;&#27169;&#31995;&#32479;&#24037;&#20855;&#21253;
&lt;/p&gt;
&lt;p&gt;
Towards the TopMost: A Topic Modeling System Toolkit. (arXiv:2309.06908v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06908
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;TopMost&#30340;&#20027;&#39064;&#24314;&#27169;&#31995;&#32479;&#24037;&#20855;&#21253;&#65292;&#36890;&#36807;&#28085;&#30422;&#26356;&#24191;&#27867;&#30340;&#20027;&#39064;&#24314;&#27169;&#22330;&#26223;&#21644;&#20855;&#26377;&#39640;&#24230;&#20957;&#32858;&#21147;&#21644;&#35299;&#32806;&#27169;&#22359;&#21270;&#35774;&#35745;&#30340;&#29305;&#28857;&#65292;&#21487;&#20197;&#20419;&#36827;&#20027;&#39064;&#27169;&#22411;&#30340;&#30740;&#31350;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#39064;&#27169;&#22411;&#24050;&#32463;&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#34987;&#25552;&#20986;&#65292;&#24182;&#19988;&#20855;&#26377;&#21508;&#31181;&#24212;&#29992;&#65292;&#22312;&#31070;&#32463;&#21464;&#20998;&#25512;&#26029;&#30340;&#25512;&#21160;&#19979;&#36817;&#26399;&#24471;&#21040;&#20102;&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20027;&#39064;&#27169;&#22411;&#37319;&#29992;&#23436;&#20840;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#12289;&#23454;&#29616;&#21644;&#35780;&#20272;&#35774;&#32622;&#65292;&#36825;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24555;&#36895;&#21033;&#29992;&#21644;&#20844;&#24179;&#27604;&#36739;&#12290;&#36825;&#20005;&#37325;&#38459;&#30861;&#20102;&#20027;&#39064;&#27169;&#22411;&#30340;&#30740;&#31350;&#36827;&#23637;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20027;&#39064;&#24314;&#27169;&#31995;&#32479;&#24037;&#20855;&#21253;&#65288;TopMost&#65289;&#12290;&#19982;&#29616;&#26377;&#30340;&#24037;&#20855;&#21253;&#30456;&#27604;&#65292;TopMost&#36890;&#36807;&#28085;&#30422;&#26356;&#24191;&#27867;&#30340;&#20027;&#39064;&#24314;&#27169;&#22330;&#26223;&#65292;&#21253;&#25324;&#25968;&#25454;&#38598;&#39044;&#22788;&#29702;&#12289;&#27169;&#22411;&#35757;&#32451;&#12289;&#27979;&#35797;&#21644;&#35780;&#20272;&#30340;&#23436;&#25972;&#29983;&#21629;&#21608;&#26399;&#65292;&#33073;&#39062;&#32780;&#20986;&#12290;TopMost&#30340;&#39640;&#24230;&#20957;&#32858;&#21147;&#21644;&#35299;&#32806;&#27169;&#22359;&#21270;&#35774;&#35745;&#21487;&#20197;&#24555;&#36895;&#21033;&#29992;&#65292;&#20844;&#24179;&#27604;&#36739;&#65292;&#24182;&#28789;&#27963;&#25193;&#23637;&#19981;&#21516;&#30340;&#20027;&#39064;&#27169;&#22411;&#65292;&#36825;&#21487;&#20197;&#20419;&#36827;&#20027;&#39064;&#27169;&#22411;&#30340;&#30740;&#31350;&#21644;&#24212;&#29992;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#12289;&#25945;&#31243;&#21644;&#25991;&#26723;&#21487;&#22312;https://github.com/bobxwu/topmost &#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topic models have been proposed for decades with various applications and recently refreshed by the neural variational inference. However, these topic models adopt totally distinct dataset, implementation, and evaluation settings, which hinders their quick utilization and fair comparisons. This greatly hinders the research progress of topic models. To address these issues, in this paper we propose a Topic Modeling System Toolkit (TopMost). Compared to existing toolkits, TopMost stands out by covering a wider range of topic modeling scenarios including complete lifecycles with dataset pre-processing, model training, testing, and evaluations. The highly cohesive and decoupled modular design of TopMost enables quick utilization, fair comparisons, and flexible extensions of different topic models. This can facilitate the research and applications of topic models. Our code, tutorials, and documentation are available at https://github.com/bobxwu/topmost.
&lt;/p&gt;</description></item></channel></rss>