<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#36328;&#24322;&#26500;&#26469;&#28304;&#36827;&#34892;&#25805;&#20316;&#30340;&#26102;&#24577;&#38382;&#31572;&#31995;&#32479;&#65292;&#36890;&#36807;&#24378;&#21046;&#25191;&#34892;&#26102;&#38388;&#32422;&#26463;&#20197;&#30830;&#20445;&#24544;&#23454;&#22238;&#31572;&#65292;&#27491;&#30830;&#22788;&#29702;&#38544;&#21547;&#38382;&#39064;&#65292;&#24182;&#20197;&#32479;&#19968;&#26041;&#24335;&#35206;&#30422;&#30693;&#35782;&#24211;&#12289;&#25991;&#26412;&#21644;&#32593;&#32476;&#34920;&#26684;&#12290;</title><link>https://arxiv.org/abs/2402.15400</link><description>&lt;p&gt;
&#36328;&#24322;&#26500;&#26469;&#28304;&#30340;&#24544;&#23454;&#26102;&#24577;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
Faithful Temporal Question Answering over Heterogeneous Sources
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15400
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#36328;&#24322;&#26500;&#26469;&#28304;&#36827;&#34892;&#25805;&#20316;&#30340;&#26102;&#24577;&#38382;&#31572;&#31995;&#32479;&#65292;&#36890;&#36807;&#24378;&#21046;&#25191;&#34892;&#26102;&#38388;&#32422;&#26463;&#20197;&#30830;&#20445;&#24544;&#23454;&#22238;&#31572;&#65292;&#27491;&#30830;&#22788;&#29702;&#38544;&#21547;&#38382;&#39064;&#65292;&#24182;&#20197;&#32479;&#19968;&#26041;&#24335;&#35206;&#30422;&#30693;&#35782;&#24211;&#12289;&#25991;&#26412;&#21644;&#32593;&#32476;&#34920;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#24577;&#38382;&#31572;&#28041;&#21450;&#26102;&#38388;&#32422;&#26463;&#65292;&#20363;&#22914;&#8220;...&#22312;2019&#24180;&#8221;&#25110;&#8220;...&#22312;COVID&#20043;&#21069;&#8221;&#12290;&#22312;&#21069;&#32773;&#20013;&#65292;&#26102;&#38388;&#26159;&#19968;&#20010;&#26126;&#30830;&#30340;&#26465;&#20214;&#65292;&#22312;&#21518;&#32773;&#20013;&#65292;&#23427;&#26159;&#38544;&#21547;&#30340;&#12290;&#29616;&#26377;&#25216;&#26415;&#26041;&#27861;&#22312;&#19977;&#20010;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;&#31070;&#32463;&#25512;&#29702;&#26102;&#65292;&#26102;&#38388;&#32422;&#26463;&#20165;&#34987;&#36719;&#21305;&#37197;&#65292;&#23481;&#26131;&#23548;&#33268;&#26080;&#25928;&#25110;&#26080;&#27861;&#35299;&#37322;&#30340;&#31572;&#26696;&#12290;&#20854;&#27425;&#65292;&#23545;&#20110;&#28041;&#21450;&#38544;&#21547;&#26102;&#38388;&#30340;&#38382;&#39064;&#25903;&#25345;&#19981;&#36275;&#12290;&#31532;&#19977;&#65292;&#31572;&#26696;&#21482;&#26469;&#33258;&#21333;&#19968;&#26469;&#28304;&#65306;&#30693;&#35782;&#24211;&#65288;KB&#65289;&#25110;&#25991;&#26412;&#35821;&#26009;&#24211;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26102;&#24577;&#38382;&#31572;&#31995;&#32479;&#26469;&#35299;&#20915;&#36825;&#20123;&#32570;&#38519;&#12290;&#39318;&#20808;&#65292;&#23427;&#36890;&#36807;&#20855;&#20307;&#35777;&#25454;&#24378;&#21046;&#25191;&#34892;&#26102;&#38388;&#32422;&#26463;&#20197;&#30830;&#20445;&#24544;&#23454;&#22238;&#31572;&#12290;&#20854;&#27425;&#65292;&#23427;&#27491;&#30830;&#22788;&#29702;&#38544;&#21547;&#38382;&#39064;&#12290;&#31532;&#19977;&#65292;&#23427;&#20197;&#32479;&#19968;&#26041;&#24335;&#35206;&#30422;&#30693;&#35782;&#24211;&#12289;&#25991;&#26412;&#21644;&#32593;&#32476;&#34920;&#26684;&#65292;&#36328;&#24322;&#26500;&#26469;&#28304;&#36827;&#34892;&#25805;&#20316;&#12290;&#35813;&#26041;&#27861;&#20998;&#20026;&#19977;&#20010;&#38454;&#27573;&#65306;&#65288;i&#65289;&#29702;&#35299;&#38382;&#39064;&#21450;&#20854;&#26102;&#38388;&#26465;&#20214;&#65292;&#65288;ii&#65289;&#20174;&#20013;&#26816;&#32034;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15400v1 Announce Type: cross  Abstract: Temporal question answering (QA) involves time constraints, with phrases such as "... in 2019" or "... before COVID". In the former, time is an explicit condition, in the latter it is implicit. State-of-the-art methods have limitations along three dimensions. First, with neural inference, time constraints are merely soft-matched, giving room to invalid or inexplicable answers. Second, questions with implicit time are poorly supported. Third, answers come from a single source: either a knowledge base (KB) or a text corpus. We propose a temporal QA system that addresses these shortcomings. First, it enforces temporal constraints for faithful answering with tangible evidence. Second, it properly handles implicit questions. Third, it operates over heterogeneous sources, covering KB, text and web tables in a unified manner. The method has three stages: (i) understanding the question and its temporal conditions, (ii) retrieving evidence from
&lt;/p&gt;</description></item><item><title>Text2Pic Swift&#26694;&#26550;&#38024;&#23545;&#22823;&#35268;&#27169;&#24211;&#20013;&#25991;&#26412;&#25551;&#36848;&#21040;&#22270;&#20687;&#30340;&#26816;&#32034;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#24378;&#22823;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#31574;&#30053;&#35299;&#20915;&#20102;&#38271;&#25991;&#26412;&#26597;&#35810;&#20013;&#30340;&#27495;&#20041;&#38382;&#39064;</title><link>https://arxiv.org/abs/2402.15276</link><description>&lt;p&gt;
Text2Pic Swift&#65306;&#22686;&#24378;&#22823;&#35268;&#27169;&#24211;&#20013;&#38271;&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15276
&lt;/p&gt;
&lt;p&gt;
Text2Pic Swift&#26694;&#26550;&#38024;&#23545;&#22823;&#35268;&#27169;&#24211;&#20013;&#25991;&#26412;&#25551;&#36848;&#21040;&#22270;&#20687;&#30340;&#26816;&#32034;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#24378;&#22823;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#31574;&#30053;&#35299;&#20915;&#20102;&#38271;&#25991;&#26412;&#26597;&#35810;&#20013;&#30340;&#27495;&#20041;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15276v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#25991;&#26412;&#21040;&#22270;&#20687;&#26816;&#32034;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#21253;&#25324;&#25968;&#23383;&#22270;&#20070;&#39302;&#12289;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#21644;&#22810;&#23186;&#20307;&#25968;&#25454;&#24211;&#65292;&#36890;&#36807;&#20351;&#29992;&#25991;&#26412;&#26597;&#35810;&#26469;&#25628;&#32034;&#22270;&#20687;&#12290;&#23613;&#31649;&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;MLLMs&#65289;&#21462;&#24471;&#20102;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#22312;&#22823;&#35268;&#27169;&#12289;&#22810;&#26679;&#21270;&#21644;&#27169;&#31946;&#30340;&#26816;&#32034;&#22330;&#26223;&#20013;&#30340;&#36866;&#29992;&#24615;&#21463;&#21040;&#26174;&#30528;&#30340;&#35745;&#31639;&#38656;&#27714;&#21644;&#29983;&#25104;&#21487;&#27880;&#20837;&#30340;&#23884;&#20837;&#25152;&#38480;&#21046;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Text2Pic Swift&#26694;&#26550;&#65292;&#19987;&#20026;&#22312;&#24222;&#22823;&#30340;&#25968;&#25454;&#38598;&#20013;&#26377;&#25928;&#21644;&#31283;&#20581;&#22320;&#26816;&#32034;&#19982;&#24191;&#27867;&#25991;&#26412;&#25551;&#36848;&#23545;&#24212;&#30340;&#22270;&#20687;&#32780;&#35774;&#35745;&#12290;&#35813;&#26694;&#26550;&#37319;&#29992;&#20102;&#20004;&#38454;&#27573;&#26041;&#27861;&#65306;&#21021;&#22987;&#22522;&#20110;&#23454;&#20307;&#30340;&#25490;&#24207;&#65288;ER&#65289;&#38454;&#27573;&#36890;&#36807;&#22810;&#26597;&#35810;&#23545;&#22810;&#30446;&#26631;&#30340;&#31574;&#30053;&#26469;&#35299;&#20915;&#38271;&#25991;&#26412;&#26597;&#35810;&#20013;&#22266;&#26377;&#30340;&#27495;&#20041;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#32553;&#23567;&#20102;&#21487;&#33021;&#30340;&#20505;&#36873;&#39033;&#65292;&#20197;&#20415;&#36827;&#34892;&#21518;&#32493;&#20998;&#26512;&#12290;&#25509;&#19979;&#26469;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15276v1 Announce Type: cross  Abstract: Text-to-image retrieval plays a crucial role across various applications, including digital libraries, e-commerce platforms, and multimedia databases, by enabling the search for images using text queries. Despite the advancements in Multimodal Large Language Models (MLLMs), which offer leading-edge performance, their applicability in large-scale, varied, and ambiguous retrieval scenarios is constrained by significant computational demands and the generation of injective embeddings. This paper introduces the Text2Pic Swift framework, tailored for efficient and robust retrieval of images corresponding to extensive textual descriptions in sizable datasets. The framework employs a two-tier approach: the initial Entity-based Ranking (ER) stage addresses the ambiguity inherent in lengthy text queries through a multiple-queries-to-multiple-targets strategy, effectively narrowing down potential candidates for subsequent analysis. Following thi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992; Rk &#25351;&#26631;&#30740;&#31350;&#20102;25&#20010;&#22269;&#23478;&#21644;&#27431;&#30431;&#22312;10&#20010;&#20851;&#38190;&#30740;&#31350;&#20027;&#39064;&#19978;&#30340;&#36129;&#29486;&#65292;&#21457;&#29616;&#22312;&#25216;&#26415;&#39046;&#22495;&#65292;&#32654;&#22269;&#12289;&#20013;&#22269;&#21644;&#27431;&#30431;&#22788;&#20110;&#39046;&#20808;&#22320;&#20301;&#65292;&#32780;&#27431;&#30431;&#26126;&#26174;&#33853;&#21518;&#20110;&#20013;&#22269;&#12290;</title><link>https://arxiv.org/abs/2402.15263</link><description>&lt;p&gt;
&#21508;&#22269;&#22312;&#30693;&#35782;&#36793;&#30028;&#19978;&#30340;&#21162;&#21147;&#65306;&#32654;&#22269;&#20027;&#23548;&#22320;&#20301;&#12289;&#20013;&#22269;&#23835;&#36215;&#21644;&#27431;&#30431;&#20572;&#28382;
&lt;/p&gt;
&lt;p&gt;
Countries pushing the boundaries of knowledge: the US dominance, China rise, and the EU stagnation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15263
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992; Rk &#25351;&#26631;&#30740;&#31350;&#20102;25&#20010;&#22269;&#23478;&#21644;&#27431;&#30431;&#22312;10&#20010;&#20851;&#38190;&#30740;&#31350;&#20027;&#39064;&#19978;&#30340;&#36129;&#29486;&#65292;&#21457;&#29616;&#22312;&#25216;&#26415;&#39046;&#22495;&#65292;&#32654;&#22269;&#12289;&#20013;&#22269;&#21644;&#27431;&#30431;&#22788;&#20110;&#39046;&#20808;&#22320;&#20301;&#65292;&#32780;&#27431;&#30431;&#26126;&#26174;&#33853;&#21518;&#20110;&#20013;&#22269;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#36947;&#21738;&#20123;&#22269;&#23478;&#23545;&#25512;&#21160;&#31185;&#23398;&#25216;&#26415;&#30693;&#35782;&#36793;&#30028;&#30340;&#25299;&#23637;&#36129;&#29486;&#26368;&#22823;&#20855;&#26377;&#31038;&#20250;&#21644;&#25919;&#27835;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#24120;&#35265;&#30340;&#24341;&#29992;&#24230;&#37327;&#19981;&#36275;&#20197;&#34913;&#37327;&#36825;&#31181;&#36129;&#29486;&#12290;&#36825;&#31181;&#24230;&#37327;&#38656;&#35201;&#26356;&#20005;&#26684;&#30340;&#25351;&#26631;&#65292;&#36866;&#29992;&#20110;&#25512;&#21160;&#30693;&#35782;&#36793;&#30028;&#30340;&#26497;&#20855;&#24433;&#21709;&#21147;&#30340;&#31361;&#30772;&#24615;&#35770;&#25991;&#65292;&#36825;&#20123;&#35770;&#25991;&#24341;&#29992;&#37327;&#24456;&#39640;&#20294;&#38750;&#24120;&#32597;&#35265;&#12290;&#26412;&#25991;&#20351;&#29992;&#26368;&#36817;&#25551;&#36848;&#30340; Rk &#25351;&#26631;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#20316;&#32773;&#23558;&#36825;&#19968;&#25351;&#26631;&#24212;&#29992;&#20110; 25 &#20010;&#22269;&#23478;&#21644;&#27431;&#30431;&#22312; 10 &#20010;&#20851;&#38190;&#30740;&#31350;&#20027;&#39064;&#19978;&#65292;&#20854;&#20013;&#20116;&#20010;&#26159;&#25216;&#26415;&#20027;&#39064;&#65292;&#20116;&#20010;&#26159;&#29983;&#29289;&#21307;&#23398;&#20027;&#39064;&#65292;&#29420;&#31435;&#22320;&#30740;&#31350;&#20102;&#22269;&#20869;&#21644;&#22269;&#38469;&#21512;&#20316;&#35770;&#25991;&#12290;&#22312;&#25216;&#26415;&#20027;&#39064;&#19978;&#65292;&#22269;&#20869;&#35770;&#25991;&#30340; Rk &#25351;&#25968;&#26174;&#31034;&#65292;&#24635;&#20307;&#32780;&#35328;&#65292;&#32654;&#22269;&#12289;&#20013;&#22269;&#21644;&#27431;&#30431;&#22788;&#20110;&#39046;&#20808;&#22320;&#20301;&#65307;&#20854;&#20182;&#22269;&#23478;&#26126;&#26174;&#33853;&#21518;&#12290;&#32654;&#22269;&#26126;&#26174;&#39046;&#20808;&#20110;&#20013;&#22269;&#65292;&#32780;&#27431;&#30431;&#36828;&#36828;&#33853;&#21518;&#20110;&#20013;&#22269;&#12290;&#29983;&#29289;&#21307;&#23398;&#20027;&#39064;&#37319;&#29992;&#30456;&#21516;&#30340;&#26041;&#27861;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15263v1 Announce Type: cross  Abstract: Knowing which countries contribute the most to pushing the boundaries of knowledge in science and technology has social and political importance. However, common citation metrics do not adequately measure this contribution. This measure requires more stringent metrics appropriate for the highly influential breakthrough papers that push the boundaries of knowledge, which are very highly cited but very rare. Here I used the recently described Rk index, specifically designed to address this issue. I applied this index to 25 countries and the EU across 10 key research topics, five technological and five biomedical, studying domestic and international collaborative papers independently. In technological topics, the Rk indices of domestic papers show that overall, the USA, China, and the EU are leaders; other countries are clearly behind. The USA is notably ahead of China, and the EU is far behind China. The same approach to biomedical topic
&lt;/p&gt;</description></item><item><title>MACRec&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#22810;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#24182;&#25552;&#20379;&#20102;&#24212;&#29992;&#31034;&#20363;&#12290;</title><link>https://arxiv.org/abs/2402.15235</link><description>&lt;p&gt;
&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Collaboration Framework for Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15235
&lt;/p&gt;
&lt;p&gt;
MACRec&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#22810;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#24182;&#25552;&#20379;&#20102;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#20307;&#22240;&#20854;&#20915;&#31574;&#25216;&#33021;&#21644;&#22788;&#29702;&#22797;&#26434;&#20219;&#21153;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#37492;&#20110;&#24403;&#21069;&#22312;&#21033;&#29992;&#26234;&#33021;&#20307;&#21327;&#20316;&#33021;&#21147;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#26041;&#38754;&#23384;&#22312;&#30340;&#31354;&#30333;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;MACRec&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#39062;&#26694;&#26550;&#12290;&#19982;&#29616;&#26377;&#20851;&#20110;&#20351;&#29992;&#26234;&#33021;&#20307;&#36827;&#34892;&#29992;&#25143;/&#21830;&#21697;&#27169;&#25311;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#26088;&#22312;&#37096;&#32626;&#22810;&#26234;&#33021;&#20307;&#30452;&#25509;&#22788;&#29702;&#25512;&#33616;&#20219;&#21153;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#36890;&#36807;&#21508;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#26469;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#21253;&#25324;&#32463;&#29702;&#12289;&#29992;&#25143;/&#21830;&#21697;&#20998;&#26512;&#24072;&#12289;&#21453;&#23556;&#22120;&#12289;&#25628;&#32034;&#22120;&#21644;&#20219;&#21153;&#35299;&#37322;&#22120;&#65292;&#23427;&#20204;&#20855;&#26377;&#19981;&#21516;&#30340;&#24037;&#20316;&#27969;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#24212;&#29992;&#31034;&#20363;&#65292;&#35828;&#26126;&#24320;&#21457;&#20154;&#21592;&#22914;&#20309;&#36731;&#26494;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#19978;&#20351;&#29992;MACRec&#65292;&#21253;&#25324;&#35780;&#20998;&#39044;&#27979;&#12289;&#24207;&#21015;&#25512;&#33616;&#12289;&#23545;&#35805;&#25512;&#33616;&#21644;&#35299;&#37322;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15235v1 Announce Type: new  Abstract: LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks. Recognizing the current gap in leveraging agent capabilities for multi-agent collaboration in recommendation systems, we introduce MACRec, a novel framework designed to enhance recommendation systems through multi-agent collaboration. Unlike existing work on using agents for user/item simulation, we aim to deploy multi-agents to tackle recommendation tasks directly. In our framework, recommendation tasks are addressed through the collaborative efforts of various specialized agents, including Manager, User/Item Analyst, Reflector, Searcher, and Task Interpreter, with different working flows. Furthermore, we provide application examples of how developers can easily use MACRec on various recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation, and explanation generation
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20174;&#29289;&#21697;&#20391;&#20844;&#24179;&#24615;&#30340;&#35282;&#24230;&#25506;&#35752;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25581;&#31034;&#20102;&#21382;&#21490;&#29992;&#25143;&#20132;&#20114;&#21644;&#27169;&#22411;&#22266;&#26377;&#35821;&#20041;&#20559;&#35265;&#23545;&#20854;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#22240;&#32032;&#65292;&#25552;&#20986;&#20102;&#25193;&#23637;&#20256;&#32479;&#20844;&#24179;&#24615;&#26041;&#27861;&#20197;&#36866;&#29992;&#20110;&#35813;&#25512;&#33616;&#31995;&#32479;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.15215</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#29289;&#21697;&#20391;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Item-side Fairness of Large Language Model-based Recommendation System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15215
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20174;&#29289;&#21697;&#20391;&#20844;&#24179;&#24615;&#30340;&#35282;&#24230;&#25506;&#35752;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25581;&#31034;&#20102;&#21382;&#21490;&#29992;&#25143;&#20132;&#20114;&#21644;&#27169;&#22411;&#22266;&#26377;&#35821;&#20041;&#20559;&#35265;&#23545;&#20854;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#22240;&#32032;&#65292;&#25552;&#20986;&#20102;&#25193;&#23637;&#20256;&#32479;&#20844;&#24179;&#24615;&#26041;&#27861;&#20197;&#36866;&#29992;&#20110;&#35813;&#25512;&#33616;&#31995;&#32479;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15215v1 &#20844;&#21578;&#31867;&#22411;: &#26032; &#25512;&#33616;&#31995;&#32479;&#23545;Web&#20869;&#23481;&#20998;&#21457;&#23494;&#20999;&#20851;&#32852;&#30528;&#24369;&#21183;&#32676;&#20307;&#30340;&#20449;&#24687;&#33719;&#21462;&#21644;&#26292;&#38706;&#26426;&#20250;&#12290;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LRS)&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#20986;&#29616;&#21487;&#33021;&#30001;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#20869;&#22312;&#20559;&#35265;&#32780;&#21521;&#25512;&#33616;&#31995;&#32479;&#24341;&#20837;&#39069;&#22806;&#30340;&#31038;&#20250;&#25361;&#25112;&#12290;&#20174;&#29289;&#21697;&#20391;&#20844;&#24179;&#24615;&#30340;&#35270;&#35282;&#30475;&#65292;&#37492;&#20110;LRS&#19982;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#30456;&#27604;&#30340;&#29420;&#29305;&#29305;&#24615;&#65292;&#20851;&#20110;LRS&#30340;&#29289;&#21697;&#20391;&#20844;&#24179;&#24615;&#20173;&#32570;&#20047;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#20026;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#30740;&#31350;&#23457;&#35270;&#20102;LRS&#30340;&#23646;&#24615;&#19982;&#29289;&#21697;&#20391;&#20844;&#24179;&#24615;&#65292;&#24182;&#25581;&#31034;&#20102;&#21382;&#21490;&#29992;&#25143;&#20132;&#20114;&#21644;LLMs&#22266;&#26377;&#35821;&#20041;&#20559;&#35265;&#30340;&#24433;&#21709;&#22240;&#32032;&#65292;&#25581;&#31034;&#20102;&#38656;&#35201;&#25193;&#23637;&#20256;&#32479;&#29289;&#21697;&#20391;&#20844;&#24179;&#24615;&#26041;&#27861;&#20197;&#36866;&#29992;&#20110;LRS&#30340;&#38656;&#27714;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31616;&#27905;&#26377;&#25928;&#30340;&#26694;&#26550;&#31216;&#20026;IFairLRS&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15215v1 Announce Type: new  Abstract: Recommendation systems for Web content distribution intricately connect to the information access and exposure opportunities for vulnerable populations. The emergence of Large Language Models-based Recommendation System (LRS) may introduce additional societal challenges to recommendation systems due to the inherent biases in Large Language Models (LLMs). From the perspective of item-side fairness, there remains a lack of comprehensive investigation into the item-side fairness of LRS given the unique characteristics of LRS compared to conventional recommendation systems. To bridge this gap, this study examines the property of LRS with respect to item-side fairness and reveals the influencing factors of both historical users' interactions and inherent semantic biases of LLMs, shedding light on the need to extend conventional item-side fairness methods for LRS. Towards this goal, we develop a concise and effective framework called IFairLRS 
&lt;/p&gt;</description></item><item><title>EasyRL4Rec&#26159;&#19968;&#20010;&#38754;&#21521;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#25143;&#21451;&#22909;&#21644;&#39640;&#25928;&#24211;&#65292;&#25552;&#20379;&#20102;&#22810;&#26679;&#21270;&#30340;RL&#29615;&#22659;&#12289;&#20840;&#38754;&#30340;&#26680;&#24515;&#27169;&#22359;&#12289;&#19968;&#33268;&#30340;&#35780;&#20272;&#26631;&#20934;&#21644;&#23450;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#26088;&#22312;&#24110;&#21161;&#31616;&#21270;&#27169;&#22411;&#24320;&#21457;&#24182;&#25913;&#21892;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.15164</link><description>&lt;p&gt;
EasyRL4Rec&#65306;&#38754;&#21521;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#25143;&#21451;&#22909;&#20195;&#30721;&#24211;
&lt;/p&gt;
&lt;p&gt;
EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15164
&lt;/p&gt;
&lt;p&gt;
EasyRL4Rec&#26159;&#19968;&#20010;&#38754;&#21521;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#25143;&#21451;&#22909;&#21644;&#39640;&#25928;&#24211;&#65292;&#25552;&#20379;&#20102;&#22810;&#26679;&#21270;&#30340;RL&#29615;&#22659;&#12289;&#20840;&#38754;&#30340;&#26680;&#24515;&#27169;&#22359;&#12289;&#19968;&#33268;&#30340;&#35780;&#20272;&#26631;&#20934;&#21644;&#23450;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#26088;&#22312;&#24110;&#21161;&#31616;&#21270;&#27169;&#22411;&#24320;&#21457;&#24182;&#25913;&#21892;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;-&#22522;&#30784;&#30340;&#25512;&#33616;&#31995;&#32479;&#65288;RSs&#65289;&#36234;&#26469;&#36234;&#34987;&#35748;&#21487;&#20854;&#25552;&#39640;&#38271;&#26399;&#29992;&#25143;&#21442;&#19982;&#24230;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#39046;&#22495;&#38754;&#20020;&#25361;&#25112;&#65292;&#22914;&#32570;&#20047;&#26131;&#29992;&#30340;&#26694;&#26550;&#12289;&#35780;&#20272;&#26631;&#20934;&#19981;&#19968;&#33268;&#20197;&#21450;&#22797;&#21046;&#20197;&#21069;&#30340;&#24037;&#20316;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38556;&#30861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EasyRL4Rec&#65292;&#19968;&#20010;&#19987;&#20026;&#22522;&#20110;RL&#30340;RSs&#37327;&#36523;&#23450;&#21046;&#30340;&#29992;&#25143;&#21451;&#22909;&#21644;&#39640;&#25928;&#30340;&#24211;&#12290;EasyRL4Rec&#20855;&#26377;&#22522;&#20110;&#20116;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#26500;&#24314;&#30340;&#36731;&#37327;&#32423;&#12289;&#22810;&#26679;&#21270;&#30340;RL&#29615;&#22659;&#65292;&#24182;&#37197;&#22791;&#20102;&#20840;&#38754;&#30340;&#26680;&#24515;&#27169;&#22359;&#65292;&#25552;&#20379;&#20016;&#23500;&#30340;&#36873;&#39033;&#26469;&#31616;&#21270;&#27169;&#22411;&#30340;&#24320;&#21457;&#12290;&#23427;&#24314;&#31435;&#20102;&#19968;&#33268;&#30340;&#35780;&#20272;&#26631;&#20934;&#65292;&#37325;&#28857;&#20851;&#27880;&#38271;&#26399;&#24433;&#21709;&#65292;&#24182;&#24341;&#20837;&#20102;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#23450;&#21046;&#30340;&#29366;&#24577;&#24314;&#27169;&#21644;&#34892;&#20026;&#34920;&#31034;&#30340;&#23450;&#21046;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#20139;&#20102;&#36890;&#36807;&#19982;&#24403;&#21069;&#26041;&#27861;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#33719;&#24471;&#30340;&#23453;&#36149;&#35265;&#35299;&#12290;EasyRL4Rec&#26088;&#22312;&#20419;&#36827;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15164v1 Announce Type: cross  Abstract: Reinforcement Learning (RL)-Based Recommender Systems (RSs) are increasingly recognized for their ability to improve long-term user engagement. Yet, the field grapples with challenges such as the absence of accessible frameworks, inconsistent evaluation standards, and the complexity of replicating prior work. Addressing these obstacles, we present EasyRL4Rec, a user-friendly and efficient library tailored for RL-based RSs. EasyRL4Rec features lightweight, diverse RL environments built on five widely-used public datasets, and is equipped with comprehensive core modules that offer rich options to ease the development of models. It establishes consistent evaluation criteria with a focus on long-term impacts and introduces customized solutions for state modeling and action representation tailored to recommender systems. Additionally, we share valuable insights gained from extensive experiments with current methods. EasyRL4Rec aims to facil
&lt;/p&gt;</description></item><item><title>&#33258;&#21160;&#24191;&#21578;&#31454;&#26631;&#20013;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#20256;&#32479;RL&#31639;&#27861;&#22312;&#22312;&#32447;&#29615;&#22659;&#19979;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.15102</link><description>&lt;p&gt;
&#36712;&#36857;&#24335;&#36845;&#20195;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#33258;&#21160;&#31454;&#26631;
&lt;/p&gt;
&lt;p&gt;
Trajectory-wise Iterative Reinforcement Learning Framework for Auto-bidding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15102
&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#24191;&#21578;&#31454;&#26631;&#20013;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#20256;&#32479;RL&#31639;&#27861;&#22312;&#22312;&#32447;&#29615;&#22659;&#19979;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#24191;&#21578;&#20013;&#65292;&#24191;&#21578;&#20027;&#21442;&#19982;&#24191;&#21578;&#31454;&#25293;&#20197;&#33719;&#21462;&#24191;&#21578;&#26426;&#20250;&#65292;&#36890;&#24120;&#26159;&#36890;&#36807;&#38656;&#27714;&#26041;&#24179;&#21488;(DSPs)&#25552;&#20379;&#30340;&#33258;&#21160;&#31454;&#26631;&#24037;&#20855;&#12290;&#30446;&#21069;&#30340;&#33258;&#21160;&#31454;&#26631;&#31639;&#27861;&#36890;&#24120;&#37319;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23433;&#20840;&#24615;&#38382;&#39064;&#65292;&#22823;&#22810;&#25968;&#22522;&#20110;RL&#30340;&#33258;&#21160;&#31454;&#26631;&#31574;&#30053;&#26159;&#22312;&#27169;&#25311;&#29615;&#22659;&#20013;&#36827;&#34892;&#35757;&#32451;&#30340;&#65292;&#22312;&#22312;&#32447;&#29615;&#22659;&#20013;&#37096;&#32626;&#20250;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;&#20026;&#20102;&#32553;&#23567;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#21487;&#20197;&#24182;&#34892;&#37096;&#32626;&#22810;&#20010;&#33258;&#21160;&#31454;&#26631;&#20195;&#29702;&#20197;&#25910;&#38598;&#22823;&#37327;&#20132;&#20114;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#21487;&#20197;&#21033;&#29992;&#31163;&#32447;RL&#31639;&#27861;&#35757;&#32451;&#26032;&#31574;&#30053;&#12290;&#35757;&#32451;&#21518;&#30340;&#31574;&#30053;&#38543;&#21518;&#21487;&#20197;&#37096;&#32626;&#20197;&#36827;&#34892;&#36827;&#19968;&#27493;&#30340;&#25968;&#25454;&#25910;&#38598;&#65292;&#20174;&#32780;&#24418;&#25104;&#19968;&#20010;&#36845;&#20195;&#35757;&#32451;&#26694;&#26550;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#36845;&#20195;&#31163;&#32447;RL&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#36825;&#31181;&#36845;&#20195;&#31163;&#32447;RL&#26694;&#26550;&#30340;&#24615;&#33021;&#29942;&#39048;&#65292;&#20854;&#26681;&#28304;&#22312;&#20110;&#30001;&#20110;&#20869;&#22312;&#21407;&#22240;&#32780;&#23548;&#33268;&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#20302;&#25928;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15102v1 Announce Type: cross  Abstract: In online advertising, advertisers participate in ad auctions to acquire ad opportunities, often by utilizing auto-bidding tools provided by demand-side platforms (DSPs). The current auto-bidding algorithms typically employ reinforcement learning (RL). However, due to safety concerns, most RL-based auto-bidding policies are trained in simulation, leading to a performance degradation when deployed in online environments. To narrow this gap, we can deploy multiple auto-bidding agents in parallel to collect a large interaction dataset. Offline RL algorithms can then be utilized to train a new policy. The trained policy can subsequently be deployed for further data collection, resulting in an iterative training framework, which we refer to as iterative offline RL. In this work, we identify the performance bottleneck of this iterative offline RL framework, which originates from the ineffective exploration and exploitation caused by the inhe
&lt;/p&gt;</description></item><item><title>ColBERT-XM&#27169;&#22411;&#36890;&#36807;&#20174;&#21333;&#19968;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#38646;-shot&#36716;&#31227;&#21040;&#24191;&#27867;&#30340;&#35821;&#35328;&#65292;&#20174;&#32780;&#28040;&#38500;&#20102;&#23545;&#29305;&#23450;&#35821;&#35328;&#26631;&#35760;&#25968;&#25454;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.15059</link><description>&lt;p&gt;
ColBERT-XM&#65306;&#19968;&#31181;&#29992;&#20110;&#38646;-shot &#22810;&#35821;&#20449;&#24687;&#26816;&#32034;&#30340;&#27169;&#22359;&#21270;&#22810;&#21521;&#37327;&#34920;&#31034;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ColBERT-XM: A Modular Multi-Vector Representation Model for Zero-Shot Multilingual Information Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15059
&lt;/p&gt;
&lt;p&gt;
ColBERT-XM&#27169;&#22411;&#36890;&#36807;&#20174;&#21333;&#19968;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#38646;-shot&#36716;&#31227;&#21040;&#24191;&#27867;&#30340;&#35821;&#35328;&#65292;&#20174;&#32780;&#28040;&#38500;&#20102;&#23545;&#29305;&#23450;&#35821;&#35328;&#26631;&#35760;&#25968;&#25454;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#26816;&#32034;&#22120;&#20027;&#35201;&#38598;&#20013;&#22312;&#33521;&#35821;&#31561;&#39640;&#36164;&#28304;&#35821;&#35328;&#19978;&#65292;&#36825;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#28041;&#21450;&#20854;&#20182;&#35821;&#35328;&#30340;&#26816;&#32034;&#22330;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;&#24403;&#21069;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#33021;&#22815;&#36827;&#34892;&#36328;&#35821;&#35328;&#36716;&#31227;&#30340;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#35268;&#36991;&#38750;&#33521;&#35821;&#35821;&#35328;&#20013;&#32570;&#20047;&#39640;&#36136;&#37327;&#26631;&#35760;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#38656;&#35201;&#22312;&#22810;&#31181;&#35821;&#35328;&#19978;&#36827;&#34892;&#22823;&#37327;&#29305;&#23450;&#20219;&#21153;&#30340;&#24494;&#35843;&#65292;&#22312;&#39044;&#35757;&#32451;&#35821;&#26009;&#24211;&#20013;&#34920;&#31034;&#26497;&#23569;&#30340;&#35821;&#35328;&#20013;&#36890;&#24120;&#34920;&#29616;&#19981;&#20339;&#65292;&#24182;&#19988;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#20043;&#21518;&#38590;&#20197;&#34701;&#21512;&#26032;&#35821;&#35328;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22359;&#21270;&#31264;&#23494;&#26816;&#32034;&#27169;&#22411;&#65292;&#23427;&#20174;&#21333;&#19968;&#39640;&#36164;&#28304;&#35821;&#35328;&#30340;&#20016;&#23500;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#24182;&#26377;&#25928;&#22320;&#38646;-shot &#36716;&#31227;&#21040;&#24191;&#27867;&#30340;&#35821;&#35328;&#65292;&#20174;&#32780;&#28040;&#38500;&#20102;&#23545;&#29305;&#23450;&#35821;&#35328;&#26631;&#35760;&#25968;&#25454;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411; ColBERT-XM &#22312;&#29616;&#26377;&#27169;&#22411;&#19978;&#23637;&#29616;&#20986;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15059v1 Announce Type: new  Abstract: State-of-the-art neural retrievers predominantly focus on high-resource languages like English, which impedes their adoption in retrieval scenarios involving other languages. Current approaches circumvent the lack of high-quality labeled data in non-English languages by leveraging multilingual pretrained language models capable of cross-lingual transfer. However, these models require substantial task-specific fine-tuning across multiple languages, often perform poorly in languages with minimal representation in the pretraining corpus, and struggle to incorporate new languages after the pretraining phase. In this work, we present a novel modular dense retrieval model that learns from the rich data of a single high-resource language and effectively zero-shot transfers to a wide array of languages, thereby eliminating the need for language-specific labeled data. Our model, ColBERT-XM, demonstrates competitive performance against existing st
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#26512;&#20102;&#25512;&#33616;&#31639;&#27861;&#23545;&#29992;&#25143;&#34892;&#20026;&#30340;&#38271;&#26399;&#24433;&#21709;&#65292;&#25506;&#35752;&#20102;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#33021;&#22815;&#32531;&#35299;&#28388;&#27873;&#25928;&#24212;&#12290;</title><link>https://arxiv.org/abs/2402.15013</link><description>&lt;p&gt;
&#25512;&#33616;&#31639;&#27861;&#23545;&#29992;&#25143;&#28040;&#36153;&#27169;&#24335;&#38271;&#26399;&#24433;&#21709;&#30340;&#35299;&#26512;: &#28388;&#27873;&#36824;&#26159;&#21516;&#36136;&#21270;&#65311;
&lt;/p&gt;
&lt;p&gt;
Filter Bubble or Homogenization? Disentangling the Long-Term Effects of Recommendations on User Consumption Patterns
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#26512;&#20102;&#25512;&#33616;&#31639;&#27861;&#23545;&#29992;&#25143;&#34892;&#20026;&#30340;&#38271;&#26399;&#24433;&#21709;&#65292;&#25506;&#35752;&#20102;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#33021;&#22815;&#32531;&#35299;&#28388;&#27873;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31639;&#27861;&#22312;&#22609;&#36896;&#25105;&#20204;&#30340;&#23186;&#20307;&#36873;&#25321;&#26041;&#38754;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#22240;&#27492;&#20102;&#35299;&#23427;&#20204;&#23545;&#29992;&#25143;&#34892;&#20026;&#30340;&#38271;&#26399;&#24433;&#21709;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#19982;&#20004;&#20010;&#20851;&#38190;&#32467;&#26524;&#30456;&#20851;&#32852;&#65306;&#21516;&#36136;&#21270;&#65292;&#21363;&#20351;&#29992;&#25143;&#20855;&#26377;&#19981;&#21516;&#30340;&#22522;&#26412;&#20559;&#22909;&#65292;&#20063;&#20250;&#28040;&#36153;&#30456;&#20284;&#30340;&#20869;&#23481;&#65292;&#20197;&#21450;&#28388;&#27873;&#25928;&#24212;&#65292;&#21363;&#20855;&#26377;&#19981;&#21516;&#20559;&#22909;&#30340;&#20010;&#20154;&#20165;&#28040;&#36153;&#19982;&#20854;&#20559;&#22909;&#19968;&#33268;&#30340;&#20869;&#23481;&#65288;&#19982;&#20854;&#20182;&#29992;&#25143;&#20960;&#20046;&#27809;&#26377;&#37325;&#21472;&#65289;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20551;&#35774;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#65292;&#24182;&#23637;&#31034;&#20010;&#24615;&#21270;&#25512;&#33616;&#36890;&#36807;&#20419;&#36827;&#21516;&#36136;&#21270;&#26469;&#32531;&#35299;&#28388;&#27873;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#19968;&#23545;&#36825;&#20004;&#31181;&#25928;&#24212;&#20043;&#38388;&#30340;&#26435;&#34913;&#30340;&#20551;&#35774;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#26080;&#27861;&#21457;&#23637;&#20986;&#19968;&#31181;&#26356;&#20026;&#32454;&#33268;&#30340;&#30475;&#27861;&#65292;&#21363;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#22914;&#20309;&#29420;&#31435;&#24433;&#21709;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#12290;&#25105;&#20204;&#23545;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#36827;&#34892;&#20102;&#26356;&#31934;&#32454;&#30340;&#23450;&#20041;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15013v1 Announce Type: cross  Abstract: Recommendation algorithms play a pivotal role in shaping our media choices, which makes it crucial to comprehend their long-term impact on user behavior. These algorithms are often linked to two critical outcomes: homogenization, wherein users consume similar content despite disparate underlying preferences, and the filter bubble effect, wherein individuals with differing preferences only consume content aligned with their preferences (without much overlap with other users). Prior research assumes a trade-off between homogenization and filter bubble effects and then shows that personalized recommendations mitigate filter bubbles by fostering homogenization. However, because of this assumption of a tradeoff between these two effects, prior work cannot develop a more nuanced view of how recommendation systems may independently impact homogenization and filter bubble effects. We develop a more refined definition of homogenization and the 
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#38544;&#31192;&#25915;&#20987;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#24494;&#35843;&#25991;&#26412;&#20869;&#23481;&#22312;&#19981;&#24178;&#39044;&#27169;&#22411;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#29289;&#21697;&#30340;&#26333;&#20809;&#24230;&#65292;&#32780;&#36825;&#31181;&#25915;&#20987;&#23545;&#25972;&#20307;&#25512;&#33616;&#24615;&#33021;&#26080;&#24433;&#21709;&#19988;&#38590;&#20197;&#34987;&#26816;&#27979;&#21040;&#12290;</title><link>https://arxiv.org/abs/2402.14836</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#20013;&#30340;&#38544;&#31192;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Stealthy Attack on Large Language Model based Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14836
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#38544;&#31192;&#25915;&#20987;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#24494;&#35843;&#25991;&#26412;&#20869;&#23481;&#22312;&#19981;&#24178;&#39044;&#27169;&#22411;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#29289;&#21697;&#30340;&#26333;&#20809;&#24230;&#65292;&#32780;&#36825;&#31181;&#25915;&#20987;&#23545;&#25972;&#20307;&#25512;&#33616;&#24615;&#33021;&#26080;&#24433;&#21709;&#19988;&#38590;&#20197;&#34987;&#26816;&#27979;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#24378;&#22823;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25512;&#21160;&#25512;&#33616;&#31995;&#32479;(RS)&#30340;&#36827;&#23637;&#26041;&#38754;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#36825;&#20123;&#31995;&#32479;&#34028;&#21187;&#21457;&#23637;&#65292;&#20294;&#23427;&#20204;&#23545;&#23433;&#20840;&#23041;&#32961;&#30340;&#25935;&#24863;&#24615;&#21364;&#34987;&#22823;&#22810;&#24573;&#35270;&#20102;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;LLMs&#24341;&#20837;&#25512;&#33616;&#27169;&#22411;&#20013;&#20135;&#29983;&#26032;&#23433;&#20840;&#28431;&#27934;&#30340;&#24773;&#20917;&#65292;&#36825;&#26159;&#30001;&#20110;&#23427;&#20204;&#27880;&#37325;&#29289;&#21697;&#30340;&#25991;&#26412;&#20869;&#23481;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25915;&#20987;&#32773;&#21487;&#20197;&#22312;&#27979;&#35797;&#38454;&#27573;&#20165;&#36890;&#36807;&#25913;&#21464;&#29289;&#21697;&#30340;&#25991;&#26412;&#20869;&#23481;&#26174;&#33879;&#22686;&#21152;&#20854;&#26333;&#20809;&#24230;&#65292;&#32780;&#26080;&#38656;&#30452;&#25509;&#24178;&#39044;&#27169;&#22411;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#35813;&#25915;&#20987;&#20855;&#26377;&#26174;&#33879;&#30340;&#38544;&#31192;&#24615;&#65292;&#22240;&#20026;&#23427;&#19981;&#20250;&#24433;&#21709;&#25972;&#20307;&#25512;&#33616;&#24615;&#33021;&#65292;&#23545;&#25991;&#26412;&#30340;&#20462;&#25913;&#24494;&#22937;&#65292;&#20351;&#29992;&#25143;&#21644;&#24179;&#21488;&#38590;&#20197;&#26816;&#27979;&#21040;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#20027;&#27969;&#30340;LLM-based&#25512;&#33616;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14836v1 Announce Type: cross  Abstract: Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of recommender systems (RS). However, while these systems have flourished, their susceptibility to security threats has been largely overlooked. In this work, we reveal that the introduction of LLMs into recommendation models presents new security vulnerabilities due to their emphasis on the textual content of items. We demonstrate that attackers can significantly boost an item's exposure by merely altering its textual content during the testing phase, without requiring direct interference with the model's training process. Additionally, the attack is notably stealthy, as it does not affect the overall recommendation performance and the modifications to the text are subtle, making it difficult for users and platforms to detect. Our comprehensive experiments across four mainstream LLM-based recommendation models demonstrate the superior
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22810;&#36339;&#35821;&#27861;&#24863;&#30693;&#20551;&#26032;&#38395;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#34917;&#20805;&#30340;&#35821;&#27861;&#20449;&#24687;&#26469;&#22788;&#29702;&#20551;&#26032;&#38395;&#20013;&#30340;&#24494;&#22937;&#36716;&#25240;</title><link>https://arxiv.org/abs/2402.14834</link><description>&lt;p&gt;
MSynFD: &#22810;&#36339;&#35821;&#27861;&#24863;&#30693;&#20551;&#26032;&#38395;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
MSynFD: Multi-hop Syntax aware Fake News Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14834
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22810;&#36339;&#35821;&#27861;&#24863;&#30693;&#20551;&#26032;&#38395;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#34917;&#20805;&#30340;&#35821;&#27861;&#20449;&#24687;&#26469;&#22788;&#29702;&#20551;&#26032;&#38395;&#20013;&#30340;&#24494;&#22937;&#36716;&#25240;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#30340;&#24191;&#27867;&#20256;&#25773;&#21161;&#38271;&#20102;&#20551;&#26032;&#38395;&#30340;&#24555;&#36895;&#20256;&#25773;&#65292;&#23545;&#25105;&#20204;&#30340;&#29616;&#23454;&#31038;&#20250;&#26500;&#25104;&#23041;&#32961;&#12290;&#29616;&#26377;&#26041;&#27861;&#20351;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#25110;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#20551;&#26032;&#38395;&#30340;&#26816;&#27979;&#65292;&#36890;&#36807;&#20998;&#26512;&#26032;&#38395;&#20869;&#23481;&#21644;/&#25110;&#20854;&#31038;&#20250;&#32972;&#26223;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24120;&#24120;&#24573;&#35270;&#20102;&#22522;&#26412;&#30340;&#25991;&#26412;&#26032;&#38395;&#20869;&#23481;&#65288;&#25991;&#31456;&#65289;&#65292;&#24182;&#19988;&#36807;&#20998;&#20381;&#36182;&#24207;&#21015;&#24314;&#27169;&#21644;&#20840;&#23616;&#27880;&#24847;&#21147;&#26469;&#25552;&#21462;&#35821;&#20041;&#20449;&#24687;&#12290;&#36825;&#20123;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#22788;&#29702;&#26032;&#38395;&#25991;&#31456;&#20013;&#30340;&#22797;&#26434;&#12289;&#24494;&#22937;&#30340;&#36716;&#25240;&#65292;&#27604;&#22914;&#21477;&#27861;-&#35821;&#20041;&#19981;&#21305;&#37197;&#21644;&#20808;&#39564;&#20559;&#24046;&#65292;&#23548;&#33268;&#24615;&#33021;&#36739;&#20302;&#65292;&#24182;&#22312;&#32570;&#22833;&#27169;&#24577;&#25110;&#31038;&#20250;&#32972;&#26223;&#26102;&#21487;&#33021;&#22833;&#36133;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20123;&#37325;&#35201;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#36339;&#35821;&#27861;&#24863;&#30693;&#20551;&#26032;&#38395;&#26816;&#27979;&#65288;MSynFD&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#34701;&#21512;&#20102;&#34917;&#20805;&#30340;&#35821;&#27861;&#20449;&#24687;&#65292;&#20197;&#22788;&#29702;&#20551;&#26032;&#38395;&#20013;&#30340;&#24494;&#22937;&#36716;&#25240;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14834v1 Announce Type: cross  Abstract: The proliferation of social media platforms has fueled the rapid dissemination of fake news, posing threats to our real-life society. Existing methods use multimodal data or contextual information to enhance the detection of fake news by analyzing news content and/or its social context. However, these methods often overlook essential textual news content (articles) and heavily rely on sequential modeling and global attention to extract semantic information. These existing methods fail to handle the complex, subtle twists in news articles, such as syntax-semantics mismatches and prior biases, leading to lower performance and potential failure when modalities or social context are missing. To bridge these significant gaps, we propose a novel multi-hop syntax aware fake news detection (MSynFD) method, which incorporates complementary syntax information to deal with subtle twists in fake news. Specifically, we introduce a syntactical depen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#22312;&#32593;&#32476;&#20013;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#65292;&#21457;&#29616;PageRank&#33021;&#22815;&#24179;&#34913;&#25490;&#21517;&#20013;&#23569;&#25968;&#32676;&#20307;&#30340;&#20195;&#34920;&#24615;&#65292;&#32780;HITS&#21017;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2402.13787</link><description>&lt;p&gt;
&#20174;&#25490;&#21517;&#20013;&#23835;&#36215;&#30340;&#20844;&#24179;&#24615;&#65306;HITS&#21644;PageRank&#22312;&#21516;&#36136;&#32593;&#32476;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#22312;&#32593;&#32476;&#20013;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#65292;&#21457;&#29616;PageRank&#33021;&#22815;&#24179;&#34913;&#25490;&#21517;&#20013;&#23569;&#25968;&#32676;&#20307;&#30340;&#20195;&#34920;&#24615;&#65292;&#32780;HITS&#21017;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20351;&#29992;&#20013;&#24515;&#24615;&#24230;&#37327;&#26631;&#20934;&#30340;&#26368;&#24120;&#35265;&#38142;&#25509;&#31639;&#27861;&#65292;&#22914;PageRank&#21644;HITS&#65292;&#22312;&#32593;&#32476;&#20013;&#21487;&#33021;&#20877;&#29616;&#29978;&#33267;&#25918;&#22823;&#23545;&#23569;&#25968;&#32676;&#20307;&#30340;&#20559;&#35265;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#34892;&#20026;&#26377;&#25152;&#19981;&#21516;&#65306;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#20973;&#32463;&#39564;&#35777;&#26126;&#65292;PageRank&#22312;&#22823;&#37096;&#20998;&#25490;&#21517;&#20301;&#32622;&#19978;&#21453;&#26144;&#20102;&#24230;&#20998;&#24067;&#65292;&#24182;&#19988;&#21487;&#20197;&#24179;&#34913;&#23569;&#25968;&#32676;&#20307;&#22312;&#25490;&#21517;&#38752;&#21069;&#30340;&#33410;&#28857;&#20013;&#30340;&#20195;&#34920;&#24615;&#65307;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#21457;&#29616;HITS&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#65292;&#25903;&#25745;&#35777;&#25454;&#20026;&#23454;&#35777;&#32467;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;HITS&#20013;&#20559;&#35265;&#25918;&#22823;&#30340;&#26681;&#26412;&#21407;&#22240;&#26159;&#32593;&#32476;&#20013;&#23384;&#22312;&#30340;&#21516;&#36136;&#24615;&#27700;&#24179;&#65292;&#36890;&#36807;&#19968;&#20010;&#20855;&#26377;&#20004;&#20010;&#31038;&#21306;&#30340;&#19981;&#26029;&#21457;&#23637;&#30340;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#20197;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#38416;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13787v1 Announce Type: cross  Abstract: In this paper, we investigate the conditions under which link analysis algorithms prevent minority groups from reaching high ranking slots. We find that the most common link-based algorithms using centrality metrics, such as PageRank and HITS, can reproduce and even amplify bias against minority groups in networks. Yet, their behavior differs: one one hand, we empirically show that PageRank mirrors the degree distribution for most of the ranking positions and it can equalize representation of minorities among the top ranked nodes; on the other hand, we find that HITS amplifies pre-existing bias in homophilic networks through a novel theoretical analysis, supported by empirical results. We find the root cause of bias amplification in HITS to be the level of homophily present in the network, modeled through an evolving network model with two communities. We illustrate our theoretical analysis on both synthetic and real datasets and we pr
&lt;/p&gt;</description></item><item><title>ReadAgent&#26159;&#19968;&#20010;&#20855;&#26377;&#38271;&#26399;&#19978;&#19979;&#25991;&#27010;&#35201;&#35760;&#24518;&#30340;&#38405;&#35835;&#20195;&#29702;&#31995;&#32479;&#65292;&#36890;&#36807;&#23454;&#29616;&#19968;&#20010;&#31616;&#21333;&#30340;&#25552;&#31034;&#31995;&#32479;&#65292;&#23427;&#33021;&#22815;&#22788;&#29702;&#38271;&#36755;&#20837;&#24182;&#25552;&#39640;&#26377;&#25928;&#19978;&#19979;&#25991;&#38271;&#24230;&#12290;&#22312;&#35780;&#20272;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.09727</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#38271;&#26399;&#19978;&#19979;&#25991;&#27010;&#35201;&#35760;&#24518;&#30340;&#20154;&#24037;&#26234;&#33021;&#38405;&#35835;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09727
&lt;/p&gt;
&lt;p&gt;
ReadAgent&#26159;&#19968;&#20010;&#20855;&#26377;&#38271;&#26399;&#19978;&#19979;&#25991;&#27010;&#35201;&#35760;&#24518;&#30340;&#38405;&#35835;&#20195;&#29702;&#31995;&#32479;&#65292;&#36890;&#36807;&#23454;&#29616;&#19968;&#20010;&#31616;&#21333;&#30340;&#25552;&#31034;&#31995;&#32479;&#65292;&#23427;&#33021;&#22815;&#22788;&#29702;&#38271;&#36755;&#20837;&#24182;&#25552;&#39640;&#26377;&#25928;&#19978;&#19979;&#25991;&#38271;&#24230;&#12290;&#22312;&#35780;&#20272;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19981;&#20165;&#38480;&#21046;&#22312;&#26576;&#20010;&#26368;&#22823;&#19978;&#19979;&#25991;&#38271;&#24230;&#20869;&#65292;&#32780;&#19988;&#26080;&#27861;&#31283;&#23450;&#22320;&#22788;&#29702;&#38271;&#36755;&#20837;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ReadAgent&#65292;&#19968;&#20010;&#22686;&#21152;&#20102;&#26377;&#25928;&#19978;&#19979;&#25991;&#38271;&#24230;&#30340;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#31995;&#32479;&#65292;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#21487;&#20197;&#36798;&#21040;20&#20493;&#12290;&#21463;&#21040;&#20154;&#31867;&#20132;&#20114;&#24335;&#38405;&#35835;&#38271;&#25991;&#26723;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;ReadAgent&#23454;&#29616;&#20026;&#19968;&#20010;&#31616;&#21333;&#30340;&#25552;&#31034;&#31995;&#32479;&#65292;&#21033;&#29992;LLM&#30340;&#39640;&#32423;&#35821;&#35328;&#33021;&#21147;&#26469;&#65306;&#65288;1&#65289;&#20915;&#23450;&#23558;&#21738;&#20123;&#20869;&#23481;&#23384;&#20648;&#22312;&#19968;&#20010;&#35760;&#24518;&#29255;&#27573;&#20013;&#65292;&#65288;2&#65289;&#23558;&#36825;&#20123;&#35760;&#24518;&#29255;&#27573;&#21387;&#32553;&#25104;&#20026;&#31216;&#20026;&#27010;&#35201;&#35760;&#24518;&#30340;&#30701;&#26102;&#35760;&#24518;&#65292;&#65288;3&#65289;&#22312;&#38656;&#35201;&#26102;&#36890;&#36807;&#21407;&#22987;&#25991;&#26412;&#26597;&#25214;&#27573;&#33853;&#26469;&#25552;&#37266;&#33258;&#24049;&#30456;&#20851;&#32454;&#33410;&#20197;&#23436;&#25104;&#20219;&#21153;&#12290;&#25105;&#20204;&#20351;&#29992;&#26816;&#32034;&#26041;&#27861;&#12289;&#20351;&#29992;&#21407;&#22987;&#38271;&#19978;&#19979;&#25991;&#20197;&#21450;&#20351;&#29992;&#27010;&#35201;&#35760;&#24518;&#26469;&#35780;&#20272;ReadAgent&#19982;&#22522;&#32447;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#35780;&#20272;&#26159;&#22312;&#19977;&#20010;&#38271;&#25991;&#26723;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#19978;&#36827;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09727v1 Announce Type: cross  Abstract: Current Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs. To address these limitations, we propose ReadAgent, an LLM agent system that increases effective context length up to 20x in our experiments. Inspired by how humans interactively read long documents, we implement ReadAgent as a simple prompting system that uses the advanced language capabilities of LLMs to (1) decide what content to store together in a memory episode, (2) compress those memory episodes into short episodic memories called gist memories, and (3) take actions to look up passages in the original text if ReadAgent needs to remind itself of relevant details to complete a task. We evaluate ReadAgent against baselines using retrieval methods, using the original long contexts, and using the gist memories. These evaluations are performed on three long-document reading comprehension task
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#20102;&#32479;&#19968;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#39046;&#22495;&#36827;&#34892;&#28857;&#20987;&#29575;&#39044;&#27979;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#27169;&#22411;&#20013;&#24573;&#30053;&#35821;&#20041;&#20449;&#24687;&#23548;&#33268;&#30340;&#27867;&#21270;&#22256;&#38590;&#65292;&#24182;&#35299;&#20915;&#20102;&#37096;&#20998;&#39046;&#22495;&#20027;&#23548;&#24615;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2312.10743</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#22810;&#39046;&#22495;&#28857;&#20987;&#29575;&#39044;&#27979;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unified Framework for Multi-Domain CTR Prediction via Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.10743
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#20102;&#32479;&#19968;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#39046;&#22495;&#36827;&#34892;&#28857;&#20987;&#29575;&#39044;&#27979;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#27169;&#22411;&#20013;&#24573;&#30053;&#35821;&#20041;&#20449;&#24687;&#23548;&#33268;&#30340;&#27867;&#21270;&#22256;&#38590;&#65292;&#24182;&#35299;&#20915;&#20102;&#37096;&#20998;&#39046;&#22495;&#20027;&#23548;&#24615;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#26159;&#22312;&#32447;&#25512;&#33616;&#24179;&#21488;&#20013;&#30340;&#37325;&#35201;&#20219;&#21153;&#65292;&#28041;&#21450;&#20272;&#35745;&#29992;&#25143;&#36890;&#36807;&#28857;&#20987;&#24191;&#21578;&#25110;&#29289;&#21697;&#32780;&#21442;&#19982;&#30340;&#27010;&#29575;&#12290;&#32473;&#23450;&#21508;&#31867;&#26381;&#21153;&#22914;&#22312;&#32447;&#36141;&#29289;&#12289;&#25171;&#36710;&#12289;&#22806;&#21334;&#21644;&#19987;&#19994;&#26381;&#21153;&#22312;&#21830;&#19994;&#24179;&#21488;&#19978;&#30340;&#21487;&#29992;&#24615;&#65292;&#36825;&#20123;&#24179;&#21488;&#30340;&#25512;&#33616;&#31995;&#32479;&#38656;&#35201;&#36328;&#22810;&#20010;&#39046;&#22495;&#36827;&#34892;CTR&#39044;&#27979;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#21333;&#19968;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39046;&#22495;&#20043;&#38388;&#30340;&#22797;&#26434;&#30456;&#20114;&#24433;&#21709;&#65292;&#22810;&#39046;&#22495;&#28857;&#20987;&#29575;&#65288;MDCTR&#65289;&#39044;&#27979;&#20173;&#28982;&#26159;&#22312;&#32447;&#25512;&#33616;&#20013;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20256;&#32479;&#30340;MDCTR&#27169;&#22411;&#36890;&#24120;&#23558;&#39046;&#22495;&#32534;&#30721;&#20026;&#31163;&#25955;&#26631;&#35782;&#31526;&#65292;&#24573;&#30053;&#20102;&#28508;&#22312;&#30340;&#20016;&#23500;&#35821;&#20041;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#24456;&#38590;&#25512;&#24191;&#21040;&#26032;&#30340;&#39046;&#22495;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#27169;&#22411;&#24456;&#23481;&#26131;&#34987;&#26576;&#20123;&#29305;&#23450;&#39046;&#22495;&#25152;&#20027;&#23548;&#65292;&#23548;&#33268;&#24615;&#33021;&#26174;&#33879;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.10743v3 Announce Type: replace  Abstract: Click-Through Rate (CTR) prediction is a crucial task in online recommendation platforms as it involves estimating the probability of user engagement with advertisements or items by clicking on them. Given the availability of various services like online shopping, ride-sharing, food delivery, and professional services on commercial platforms, recommendation systems in these platforms are required to make CTR predictions across multiple domains rather than just a single domain. However, multi-domain click-through rate (MDCTR) prediction remains a challenging task in online recommendation due to the complex mutual influence between domains. Traditional MDCTR models typically encode domains as discrete identifiers, ignoring rich semantic information underlying. Consequently, they can hardly generalize to new domains. Besides, existing models can be easily dominated by some specific domains, which results in significant performance drops
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#30340;&#33258;&#36866;&#24212;&#22810;&#20852;&#36259;&#21435;&#20559;&#35265;&#26694;&#26550;&#65288;AMID&#65289;&#65292;&#22312;&#24320;&#25918;&#19990;&#30028;&#20551;&#35774;&#19979;&#35774;&#35745;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#22312;&#22312;&#32447;&#30495;&#23454;&#24179;&#21488;&#19978;&#30001;&#20110;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.04590</link><description>&lt;p&gt;
&#22312;&#24320;&#25918;&#19990;&#30028;&#20551;&#35774;&#19979;&#37325;&#26032;&#24605;&#32771;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04590
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#30340;&#33258;&#36866;&#24212;&#22810;&#20852;&#36259;&#21435;&#20559;&#35265;&#26694;&#26550;&#65288;AMID&#65289;&#65292;&#22312;&#24320;&#25918;&#19990;&#30028;&#20551;&#35774;&#19979;&#35774;&#35745;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#22312;&#22312;&#32447;&#30495;&#23454;&#24179;&#21488;&#19978;&#30001;&#20110;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#65288;CDSR&#65289;&#26041;&#27861;&#26088;&#22312;&#35299;&#20915;&#21333;&#19968;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#65288;SDSR&#65289;&#20013;&#23384;&#22312;&#30340;&#25968;&#25454;&#31232;&#30095;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;CDSR&#20316;&#21697;&#35774;&#35745;&#20854;&#31934;&#24515;&#30340;&#32467;&#26500;&#65292;&#20381;&#36182;&#20110;&#37325;&#21472;&#29992;&#25143;&#26469;&#20256;&#25773;&#36328;&#39046;&#22495;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;CDSR&#26041;&#27861;&#37319;&#29992;&#23553;&#38381;&#19990;&#30028;&#20551;&#35774;&#65292;&#20551;&#35774;&#22312;&#22810;&#20010;&#39046;&#22495;&#20043;&#38388;&#23436;&#20840;&#37325;&#21472;&#30340;&#29992;&#25143;&#65292;&#24182;&#19988;&#25968;&#25454;&#20998;&#24067;&#20174;&#35757;&#32451;&#29615;&#22659;&#21040;&#27979;&#35797;&#29615;&#22659;&#20445;&#25345;&#19981;&#21464;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#22240;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#32780;&#22312;&#22312;&#32447;&#30495;&#23454;&#24179;&#21488;&#19978;&#34920;&#29616;&#36739;&#24046;&#12290;&#20026;&#20102;&#22312;&#24320;&#25918;&#19990;&#30028;&#20551;&#35774;&#19979;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#22810;&#20852;&#36259;&#21435;&#20559;&#35265;&#26694;&#26550;&#65292;&#29992;&#20110;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#65288;AMID&#65289;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#22810;&#20852;&#36259;&#20449;&#24687;&#27169;&#22359;&#65288;MIM&#65289;&#21644;&#19968;&#20010;&#21452;&#37325;&#40065;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.04590v3 Announce Type: replace  Abstract: Cross-Domain Sequential Recommendation (CDSR) methods aim to tackle the data sparsity and cold-start problems present in Single-Domain Sequential Recommendation (SDSR). Existing CDSR works design their elaborate structures relying on overlapping users to propagate the cross-domain information. However, current CDSR methods make closed-world assumptions, assuming fully overlapping users across multiple domains and that the data distribution remains unchanged from the training environment to the test environment. As a result, these methods typically result in lower performance on online real-world platforms due to the data distribution shifts. To address these challenges under open-world assumptions, we design an \textbf{A}daptive \textbf{M}ulti-\textbf{I}nterest \textbf{D}ebiasing framework for cross-domain sequential recommendation (\textbf{AMID}), which consists of a multi-interest information module (\textbf{MIM}) and a doubly robu
&lt;/p&gt;</description></item><item><title>Re3val&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#21644;&#37325;&#26032;&#25490;&#21517;&#25216;&#26415;&#36827;&#34892;&#35757;&#32451;&#30340;&#29983;&#25104;&#26816;&#32034;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#37325;&#26032;&#25490;&#21517;&#26816;&#32034;&#24471;&#21040;&#30340;&#39029;&#38754;&#26631;&#39064;&#65292;&#20197;&#26368;&#22823;&#21270;&#36890;&#36807;&#21463;&#38480;&#35299;&#30721;&#29983;&#25104;&#30340;&#22870;&#21169;&#12290;&#21516;&#26102;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#29983;&#25104;&#38382;&#39064;&#26469;&#20943;&#23567;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24357;&#21512;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#39046;&#22495;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2401.16979</link><description>&lt;p&gt;
Re3val: &#24378;&#21270;&#21644;&#37325;&#26032;&#25490;&#21517;&#30340;&#29983;&#25104;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Re3val: Reinforced and Reranked Generative Retrieval. (arXiv:2401.16979v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16979
&lt;/p&gt;
&lt;p&gt;
Re3val&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#21644;&#37325;&#26032;&#25490;&#21517;&#25216;&#26415;&#36827;&#34892;&#35757;&#32451;&#30340;&#29983;&#25104;&#26816;&#32034;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#37325;&#26032;&#25490;&#21517;&#26816;&#32034;&#24471;&#21040;&#30340;&#39029;&#38754;&#26631;&#39064;&#65292;&#20197;&#26368;&#22823;&#21270;&#36890;&#36807;&#21463;&#38480;&#35299;&#30721;&#29983;&#25104;&#30340;&#22870;&#21169;&#12290;&#21516;&#26102;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#29983;&#25104;&#38382;&#39064;&#26469;&#20943;&#23567;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24357;&#21512;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#39046;&#22495;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#26816;&#32034;&#27169;&#22411;&#23558;&#25991;&#26723;&#20013;&#30340;&#20449;&#24687;&#25351;&#38024;&#32534;&#30721;&#20026;&#27169;&#22411;&#21442;&#25968;&#20013;&#30340;&#32034;&#24341;&#12290;&#36825;&#20123;&#27169;&#22411;&#20316;&#20026;&#26356;&#22823;&#30340;&#27969;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#36890;&#36807;&#26816;&#32034;&#30340;&#20449;&#24687;&#26469;&#20026;&#30693;&#35782;&#23494;&#38598;&#22411;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#29983;&#25104;&#26465;&#20214;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#26377;&#20004;&#20010;&#38480;&#21046;&#65306;&#29983;&#25104;&#26816;&#32034;&#27809;&#26377;&#32771;&#34385;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#20854;&#27425;&#65292;&#26816;&#32034;&#26080;&#27861;&#20026;&#19979;&#28216;&#35835;&#32773;&#36827;&#34892;&#35843;&#25972;&#65292;&#22240;&#20026;&#35299;&#30721;&#39029;&#38754;&#26631;&#39064;&#26159;&#19968;&#20010;&#38750;&#21487;&#24494;&#20998;&#30340;&#25805;&#20316;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#32463;&#36807;&#26377;&#38480;&#25968;&#25454;&#35757;&#32451;&#30340;&#29983;&#25104;&#37325;&#26032;&#25490;&#21517;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340; Re3val&#12290;Re3val&#21033;&#29992;&#36890;&#36807;&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#33719;&#24471;&#30340;&#19978;&#19979;&#25991;&#23545;&#24050;&#26816;&#32034;&#39029;&#38754;&#26631;&#39064;&#36827;&#34892;&#37325;&#26032;&#25490;&#21517;&#65292;&#24182;&#21033;&#29992;REINFORCE&#31639;&#27861;&#26368;&#22823;&#21270;&#21463;&#38480;&#35299;&#30721;&#29983;&#25104;&#30340;&#22870;&#21169;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#29983;&#25104;&#38382;&#39064;&#65292;&#20197;&#20943;&#23567;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24357;&#21512;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#39046;&#22495;&#24046;&#36317;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20174;&#20013;&#25552;&#21462;&#21644;&#37325;&#26032;&#25490;&#21517;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative retrieval models encode pointers to information in a corpus as an index within the model's parameters. These models serve as part of a larger pipeline, where retrieved information conditions generation for knowledge-intensive NLP tasks. However, we identify two limitations: the generative retrieval does not account for contextual information. Secondly, the retrieval can't be tuned for the downstream readers as decoding the page title is a non-differentiable operation. This paper introduces Re3val, trained with generative reranking and reinforcement learning using limited data. Re3val leverages context acquired via Dense Passage Retrieval to rerank the retrieved page titles and utilizes REINFORCE to maximize rewards generated by constrained decoding. Additionally, we generate questions from our pre-training dataset to mitigate epistemic uncertainty and bridge the domain gap between the pre-training and fine-tuning datasets. Subsequently, we extract and rerank contexts from th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#25143;&#23545;&#25628;&#32034;&#32467;&#26524;&#35299;&#37322;&#30340;&#38656;&#27714;&#65292;&#21457;&#29616;&#29992;&#25143;&#19981;&#24635;&#26159;&#23547;&#27714;&#35299;&#37322;&#65292;&#20294;&#23545;&#20110;&#22797;&#26434;&#21644;&#20851;&#38190;&#30340;&#20219;&#21153;&#65292;&#35299;&#37322;&#26159;&#26377;&#30410;&#22788;&#30340;&#12290;&#35813;&#30740;&#31350;&#36824;&#24635;&#32467;&#20102;&#26377;&#30410;&#30340;&#35299;&#37322;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#25628;&#32034;&#24341;&#25806;&#21644;&#35299;&#37322;&#30340;&#35774;&#35745;&#24314;&#35758;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#26356;&#22909;&#22320;&#35780;&#20272;&#25628;&#32034;&#32467;&#26524;&#24182;&#25552;&#21319;&#20182;&#20204;&#30340;&#25628;&#32034;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2401.16509</link><description>&lt;p&gt;
&#25581;&#31034;&#29992;&#25143;&#23545;&#25628;&#32034;&#32467;&#26524;&#35299;&#37322;&#30340;&#38656;&#27714;
&lt;/p&gt;
&lt;p&gt;
Dissecting users' needs for search result explanations. (arXiv:2401.16509v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16509
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#25143;&#23545;&#25628;&#32034;&#32467;&#26524;&#35299;&#37322;&#30340;&#38656;&#27714;&#65292;&#21457;&#29616;&#29992;&#25143;&#19981;&#24635;&#26159;&#23547;&#27714;&#35299;&#37322;&#65292;&#20294;&#23545;&#20110;&#22797;&#26434;&#21644;&#20851;&#38190;&#30340;&#20219;&#21153;&#65292;&#35299;&#37322;&#26159;&#26377;&#30410;&#22788;&#30340;&#12290;&#35813;&#30740;&#31350;&#36824;&#24635;&#32467;&#20102;&#26377;&#30410;&#30340;&#35299;&#37322;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#25628;&#32034;&#24341;&#25806;&#21644;&#35299;&#37322;&#30340;&#35774;&#35745;&#24314;&#35758;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#26356;&#22909;&#22320;&#35780;&#20272;&#25628;&#32034;&#32467;&#26524;&#24182;&#25552;&#21319;&#20182;&#20204;&#30340;&#25628;&#32034;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#25628;&#32034;&#24341;&#25806;&#22914;&#20309;&#35299;&#37322;&#25628;&#32034;&#32467;&#26524;&#30340;&#38382;&#39064;&#65292;&#24050;&#26377;&#30740;&#31350;&#20551;&#35774;&#35299;&#37322;&#20250;&#26377;&#30410;&#22788;&#65292;&#24182;&#24341;&#20837;&#20102;&#25628;&#32034;&#32467;&#26524;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20174;&#26681;&#26412;&#19978;&#32771;&#34385;&#20102;&#25628;&#32034;&#35299;&#37322;&#26159;&#21542;&#38656;&#35201;&#20197;&#21450;&#20309;&#26102;&#20250;&#26377;&#30410;&#22788;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#26377;&#30410;&#30340;&#35299;&#37322;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#24182;&#20998;&#20139;&#20102;&#29992;&#25143;&#23545;Google&#21644;Bing&#25552;&#20379;&#30340;&#35299;&#37322;&#21151;&#33021;&#30340;&#30475;&#27861;&#12290;&#23545;&#38750;&#25216;&#26415;&#20154;&#21592;&#30340;&#35775;&#35848;&#26174;&#31034;&#65292;&#29992;&#25143;&#24182;&#19981;&#24635;&#26159;&#23547;&#27714;&#25110;&#29702;&#35299;&#25628;&#32034;&#35299;&#37322;&#65292;&#20294;&#23545;&#20110;&#22797;&#26434;&#21644;&#20851;&#38190;&#30340;&#20219;&#21153;&#65292;&#20182;&#20204;&#35273;&#24471;&#35299;&#37322;&#26377;&#24110;&#21161;&#12290;&#20182;&#20204;&#35748;&#20026;Google&#30340;&#25628;&#32034;&#35299;&#37322;&#22826;&#26126;&#26174;&#65292;&#20294;&#36190;&#36175;&#33021;&#22815;&#36136;&#30097;&#25628;&#32034;&#32467;&#26524;&#30340;&#33021;&#21147;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35774;&#35745;&#24314;&#35758;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#26356;&#22909;&#22320;&#35780;&#20272;&#25628;&#32034;&#32467;&#26524;&#24182;&#25552;&#21319;&#20182;&#20204;&#30340;&#25628;&#32034;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing demand for transparency in search engines to understand how search results are curated and to enhance users' trust. Prior research has introduced search result explanations with a focus on how to explain, assuming explanations are beneficial. Our study takes a step back to examine if search explanations are needed and when they are likely to provide benefits. Additionally, we summarize key characteristics of helpful explanations and share users' perspectives on explanation features provided by Google and Bing. Interviews with non-technical individuals reveal that users do not always seek or understand search explanations and mostly desire them for complex and critical tasks. They find Google's search explanations too obvious but appreciate the ability to contest search results. Based on our findings, we offer design recommendations for search engines and explanations to help users better evaluate search results and enhance their search experience.
&lt;/p&gt;</description></item></channel></rss>