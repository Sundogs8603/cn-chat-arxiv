<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#38477;&#20302;&#20102;&#25163;&#21160;&#21019;&#24314;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;</title><link>https://arxiv.org/abs/2403.17209</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;&#36164;&#20135;&#31649;&#29702;&#22806;&#22771;&#65306;&#25968;&#23383;&#23402;&#29983;&#21644;&#35821;&#20041;&#33410;&#28857;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;
&lt;/p&gt;
&lt;p&gt;
Generation of Asset Administration Shell with Large Language Model Agents: Interoperability in Digital Twins with Semantic Node
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17209
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#38477;&#20302;&#20102;&#25163;&#21160;&#21019;&#24314;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21327;&#21161;&#22312;&#24037;&#19994;4.0&#32972;&#26223;&#19979;&#20026;&#25968;&#23383;&#23402;&#29983;&#24314;&#27169;&#21019;&#24314;&#36164;&#20135;&#31649;&#29702;&#22806;&#22771;&#65288;AAS&#65289;&#23454;&#20363;&#65292;&#26088;&#22312;&#22686;&#24378;&#26234;&#33021;&#21046;&#36896;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#20943;&#23569;&#25163;&#21160;&#24037;&#20316;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#8220;&#35821;&#20041;&#33410;&#28857;&#8221;&#25968;&#25454;&#32467;&#26500;&#26469;&#25429;&#25417;&#25991;&#26412;&#25968;&#25454;&#30340;&#35821;&#20041;&#35201;&#20041;&#12290;&#28982;&#21518;&#65292;&#35774;&#35745;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#31995;&#32479;&#65292;&#29992;&#20110;&#22788;&#29702;&#8220;&#35821;&#20041;&#33410;&#28857;&#8221;&#24182;&#20174;&#25991;&#26412;&#25216;&#26415;&#25968;&#25454;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#26377;&#25928;&#29983;&#25104;&#29575;&#20026;62-79%&#65292;&#34920;&#26126;&#30456;&#24403;&#27604;&#20363;&#30340;&#25163;&#21160;&#21019;&#24314;&#24037;&#20316;&#21487;&#20197;&#36716;&#25442;&#20026;&#26356;&#23481;&#26131;&#30340;&#39564;&#35777;&#24037;&#20316;&#65292;&#20174;&#32780;&#20943;&#23569;&#21019;&#24314;AAS&#23454;&#20363;&#27169;&#22411;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#12290;&#22312;&#25105;&#20204;&#30340;&#35780;&#20272;&#20013;&#65292;&#23545;&#19981;&#21516;LLM&#30340;&#27604;&#36739;&#20998;&#26512;&#20197;&#21450;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#26426;&#21046;&#30340;&#28145;&#20837;&#28040;&#34701;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#20851;LLM&#26377;&#25928;&#24615;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17209v1 Announce Type: new  Abstract: This research introduces a novel approach for assisting the creation of Asset Administration Shell (AAS) instances for digital twin modeling within the context of Industry 4.0, aiming to enhance interoperability in smart manufacturing and reduce manual effort. We construct a "semantic node" data structure to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process "semantic node" and generate AAS instance models from textual technical data. Our evaluation demonstrates a 62-79% effective generation rate, indicating a substantial proportion of manual creation effort can be converted into easier validation effort, thereby reducing the time and cost in creating AAS instance models. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#30740;&#31350;&#38754;&#20020;&#30528;&#20844;&#24179;&#27604;&#36739;&#12289;&#36873;&#25321;&#23646;&#24615;&#20998;&#26512;&#32570;&#20047;&#20197;&#21450;&#36807;&#24230;&#20851;&#27880;&#23792;&#20540;&#24615;&#33021;&#31561;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.12660</link><description>&lt;p&gt;
ERASE&#65306;&#28145;&#24230;&#25512;&#33616;&#31995;&#32479;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
ERASE: Benchmarking Feature Selection Methods for Deep Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12660
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#30740;&#31350;&#38754;&#20020;&#30528;&#20844;&#24179;&#27604;&#36739;&#12289;&#36873;&#25321;&#23646;&#24615;&#20998;&#26512;&#32570;&#20047;&#20197;&#21450;&#36807;&#24230;&#20851;&#27880;&#23792;&#20540;&#24615;&#33021;&#31561;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#25512;&#33616;&#31995;&#32479;(DRS)&#36234;&#26469;&#36234;&#20381;&#36182;&#20110;&#22823;&#37327;&#29305;&#24449;&#23383;&#27573;&#26469;&#25552;&#20379;&#26356;&#31934;&#20934;&#30340;&#25512;&#33616;&#12290;&#26377;&#25928;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22240;&#27492;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#20934;&#30830;&#24615;&#24182;&#20248;&#21270;&#23384;&#20648;&#25928;&#29575;&#65292;&#20197;&#28385;&#36275;&#37096;&#32626;&#38656;&#27714;&#12290;&#30740;&#31350;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;DRS&#30340;&#32972;&#26223;&#19979;&#65292;&#23578;&#22788;&#20110;&#21021;&#26399;&#38454;&#27573;&#65292;&#38754;&#20020;&#19977;&#20010;&#26680;&#24515;&#25361;&#25112;&#65306;&#39318;&#20808;&#65292;&#30740;&#31350;&#35770;&#25991;&#20043;&#38388;&#23454;&#39564;&#35774;&#32622;&#30340;&#24046;&#24322;&#24448;&#24448;&#23548;&#33268;&#19981;&#20844;&#24179;&#27604;&#36739;&#65292;&#36974;&#34109;&#20102;&#23454;&#36341;&#35265;&#35299;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#25991;&#29486;&#32570;&#20047;&#22522;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#36873;&#25321;&#23646;&#24615;&#30340;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#19988;&#32570;&#20047;&#23545;&#36873;&#25321;&#25216;&#26415;&#21644;DRS&#39592;&#24178;&#20043;&#38388;&#36827;&#34892;&#20840;&#38754;&#27604;&#36739;&#30340;&#38480;&#21046;&#24615;&#25991;&#31456;&#30340;&#36890;&#29992;&#24615;&#30740;&#31350;&#21644;&#37096;&#32626;&#12290;&#26368;&#21518;&#65292;&#30740;&#31350;&#24448;&#24448;&#19987;&#27880;&#20110;&#27604;&#36739;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#21487;&#36798;&#21040;&#30340;&#23792;&#20540;&#24615;&#33021;&#65292;&#36825;&#31181;&#26041;&#27861;&#36890;&#24120;&#22312;&#35745;&#31639;&#26041;&#38754;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12660v1 Announce Type: cross  Abstract: Deep Recommender Systems (DRS) are increasingly dependent on a large number of feature fields for more precise recommendations. Effective feature selection methods are consequently becoming critical for further enhancing the accuracy and optimizing storage efficiencies to align with the deployment demands. This research area, particularly in the context of DRS, is nascent and faces three core challenges. Firstly, variant experimental setups across research papers often yield unfair comparisons, obscuring practical insights. Secondly, the existing literature's lack of detailed analysis on selection attributes, based on large-scale datasets and a thorough comparison among selection techniques and DRS backbones, restricts the generalizability of findings and impedes deployment on DRS. Lastly, research often focuses on comparing the peak performance achievable by feature selection methods, an approach that is typically computationally infe
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LLM-ensemble&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#38598;&#25104;&#19981;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#25552;&#39640;&#30005;&#23376;&#21830;&#21153;&#20135;&#21697;&#23646;&#24615;&#20540;&#25552;&#21462;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.00863</link><description>&lt;p&gt;
LLM-Ensemble: &#29992;&#20110;&#30005;&#23376;&#21830;&#21153;&#20135;&#21697;&#23646;&#24615;&#20540;&#25552;&#21462;&#30340;&#26368;&#20339;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00863
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LLM-ensemble&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#38598;&#25104;&#19981;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#25552;&#39640;&#30005;&#23376;&#21830;&#21153;&#20135;&#21697;&#23646;&#24615;&#20540;&#25552;&#21462;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00863v1 &#20844;&#21578;&#31867;&#22411;:&#36328;&#39046;&#22495;&#25688;&#35201;: &#20135;&#21697;&#23646;&#24615;&#20540;&#25552;&#21462;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#21644;&#24403;&#20195;&#30005;&#23376;&#21830;&#21153;&#34892;&#19994;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;&#25552;&#20379;&#31934;&#30830;&#30340;&#20135;&#21697;&#23646;&#24615;&#20540;&#22312;&#30830;&#20445;&#39640;&#36136;&#37327;&#25512;&#33616;&#21644;&#25552;&#21319;&#23458;&#25143;&#28385;&#24847;&#24230;&#26041;&#38754;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#20986;&#29616;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35768;&#22810;&#23646;&#24615;&#25552;&#21462;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39046;&#22495;&#29305;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#12289;&#26550;&#26500;&#21644;&#36229;&#21442;&#25968;&#30340;&#22810;&#26679;&#24615;&#65292;&#19981;&#21516;LLMs&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#20248;&#21183;&#21644;&#21155;&#21183;&#12290;&#36825;&#31181;&#21464;&#21270;&#20351;&#23427;&#20204;&#24444;&#27492;&#20114;&#34917;&#65292;&#27809;&#26377;&#21738;&#20010;LLM&#33021;&#23436;&#20840;&#21387;&#20498;&#20854;&#20182;LLM&#12290;&#32771;&#34385;&#21040;LLMs&#30340;&#22810;&#26679;&#20248;&#21183;&#21644;&#21155;&#21183;&#65292;&#24320;&#21457;&#19968;&#31181;&#21033;&#29992;&#23427;&#20204;&#20114;&#34917;&#28508;&#21147;&#30340;&#38598;&#25104;&#26041;&#27861;&#21464;&#24471;&#24517;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LLM-ensemble&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#38598;&#25104;&#19981;&#21516;LLMs&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00863v1 Announce Type: cross  Abstract: Product attribute value extraction is a pivotal component in Natural Language Processing (NLP) and the contemporary e-commerce industry. The provision of precise product attribute values is fundamental in ensuring high-quality recommendations and enhancing customer satisfaction. The recently emerging Large Language Models (LLMs) have demonstrated state-of-the-art performance in numerous attribute extraction tasks, without the need for domain-specific training data. Nevertheless, varying strengths and weaknesses are exhibited by different LLMs due to the diversity in data, architectures, and hyperparameters. This variation makes them complementary to each other, with no single LLM dominating all others. Considering the diverse strengths and weaknesses of LLMs, it becomes necessary to develop an ensemble method that leverages their complementary potentials. In this paper, we propose a novel algorithm called LLM-ensemble to ensemble diffe
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22810;&#36339;&#35821;&#27861;&#24863;&#30693;&#20551;&#26032;&#38395;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#34917;&#20805;&#30340;&#35821;&#27861;&#20449;&#24687;&#26469;&#22788;&#29702;&#20551;&#26032;&#38395;&#20013;&#30340;&#24494;&#22937;&#36716;&#25240;</title><link>https://arxiv.org/abs/2402.14834</link><description>&lt;p&gt;
MSynFD: &#22810;&#36339;&#35821;&#27861;&#24863;&#30693;&#20551;&#26032;&#38395;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
MSynFD: Multi-hop Syntax aware Fake News Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14834
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22810;&#36339;&#35821;&#27861;&#24863;&#30693;&#20551;&#26032;&#38395;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#34917;&#20805;&#30340;&#35821;&#27861;&#20449;&#24687;&#26469;&#22788;&#29702;&#20551;&#26032;&#38395;&#20013;&#30340;&#24494;&#22937;&#36716;&#25240;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#30340;&#24191;&#27867;&#20256;&#25773;&#21161;&#38271;&#20102;&#20551;&#26032;&#38395;&#30340;&#24555;&#36895;&#20256;&#25773;&#65292;&#23545;&#25105;&#20204;&#30340;&#29616;&#23454;&#31038;&#20250;&#26500;&#25104;&#23041;&#32961;&#12290;&#29616;&#26377;&#26041;&#27861;&#20351;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#25110;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#20551;&#26032;&#38395;&#30340;&#26816;&#27979;&#65292;&#36890;&#36807;&#20998;&#26512;&#26032;&#38395;&#20869;&#23481;&#21644;/&#25110;&#20854;&#31038;&#20250;&#32972;&#26223;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24120;&#24120;&#24573;&#35270;&#20102;&#22522;&#26412;&#30340;&#25991;&#26412;&#26032;&#38395;&#20869;&#23481;&#65288;&#25991;&#31456;&#65289;&#65292;&#24182;&#19988;&#36807;&#20998;&#20381;&#36182;&#24207;&#21015;&#24314;&#27169;&#21644;&#20840;&#23616;&#27880;&#24847;&#21147;&#26469;&#25552;&#21462;&#35821;&#20041;&#20449;&#24687;&#12290;&#36825;&#20123;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#22788;&#29702;&#26032;&#38395;&#25991;&#31456;&#20013;&#30340;&#22797;&#26434;&#12289;&#24494;&#22937;&#30340;&#36716;&#25240;&#65292;&#27604;&#22914;&#21477;&#27861;-&#35821;&#20041;&#19981;&#21305;&#37197;&#21644;&#20808;&#39564;&#20559;&#24046;&#65292;&#23548;&#33268;&#24615;&#33021;&#36739;&#20302;&#65292;&#24182;&#22312;&#32570;&#22833;&#27169;&#24577;&#25110;&#31038;&#20250;&#32972;&#26223;&#26102;&#21487;&#33021;&#22833;&#36133;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20123;&#37325;&#35201;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#36339;&#35821;&#27861;&#24863;&#30693;&#20551;&#26032;&#38395;&#26816;&#27979;&#65288;MSynFD&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#34701;&#21512;&#20102;&#34917;&#20805;&#30340;&#35821;&#27861;&#20449;&#24687;&#65292;&#20197;&#22788;&#29702;&#20551;&#26032;&#38395;&#20013;&#30340;&#24494;&#22937;&#36716;&#25240;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14834v1 Announce Type: cross  Abstract: The proliferation of social media platforms has fueled the rapid dissemination of fake news, posing threats to our real-life society. Existing methods use multimodal data or contextual information to enhance the detection of fake news by analyzing news content and/or its social context. However, these methods often overlook essential textual news content (articles) and heavily rely on sequential modeling and global attention to extract semantic information. These existing methods fail to handle the complex, subtle twists in news articles, such as syntax-semantics mismatches and prior biases, leading to lower performance and potential failure when modalities or social context are missing. To bridge these significant gaps, we propose a novel multi-hop syntax aware fake news detection (MSynFD) method, which incorporates complementary syntax information to deal with subtle twists in fake news. Specifically, we introduce a syntactical depen
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#37096;&#20998;&#39034;&#24207;&#22270;&#21367;&#31215;&#32593;&#32476;&#26469;&#35299;&#20915;&#21333;&#19968;&#22270;&#24418;&#20013;&#22810;&#20010;&#34892;&#20026;&#30340;&#21327;&#21516;&#36807;&#28388;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23450;&#20041;&#22810;&#20010;&#34892;&#20026;&#20043;&#38388;&#30340;&#37096;&#20998;&#39034;&#24207;&#20851;&#31995;&#65292;&#24182;&#21033;&#29992;&#21152;&#26435;&#36793;&#21512;&#24182;&#34892;&#20026;&#22270;&#65292;&#23454;&#29616;&#20102;&#22312;&#20027;&#35201;&#20219;&#21153;&#21644;&#36741;&#21161;&#20219;&#21153;&#19978;&#37117;&#34920;&#29616;&#33391;&#22909;&#30340;&#32852;&#21512;&#23884;&#20837;&#12290;</title><link>https://arxiv.org/abs/2402.07659</link><description>&lt;p&gt;
&#20855;&#26377;&#37096;&#20998;&#39034;&#24207;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#22810;&#34892;&#20026;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07659
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#37096;&#20998;&#39034;&#24207;&#22270;&#21367;&#31215;&#32593;&#32476;&#26469;&#35299;&#20915;&#21333;&#19968;&#22270;&#24418;&#20013;&#22810;&#20010;&#34892;&#20026;&#30340;&#21327;&#21516;&#36807;&#28388;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23450;&#20041;&#22810;&#20010;&#34892;&#20026;&#20043;&#38388;&#30340;&#37096;&#20998;&#39034;&#24207;&#20851;&#31995;&#65292;&#24182;&#21033;&#29992;&#21152;&#26435;&#36793;&#21512;&#24182;&#34892;&#20026;&#22270;&#65292;&#23454;&#29616;&#20102;&#22312;&#20027;&#35201;&#20219;&#21153;&#21644;&#36741;&#21161;&#20219;&#21153;&#19978;&#37117;&#34920;&#29616;&#33391;&#22909;&#30340;&#32852;&#21512;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21333;&#19968;&#22270;&#24418;&#21327;&#20316;&#36807;&#28388;&#65288;CF&#65289;&#21521;&#37327;&#20013;&#34920;&#31034;&#22810;&#20010;&#34892;&#20026;&#30340;&#20449;&#24687;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#36825;&#26159;&#22240;&#20026;&#19981;&#21516;&#30340;&#34892;&#20026;&#33258;&#28982;&#24418;&#25104;&#21333;&#29420;&#30340;&#34892;&#20026;&#22270;&#65292;&#24182;&#23398;&#20064;&#21333;&#29420;&#30340;CF&#23884;&#20837;&#12290;&#29616;&#26377;&#27169;&#22411;&#36890;&#36807;&#25351;&#23450;&#26576;&#20123;&#34892;&#20026;&#30340;CF&#23884;&#20837;&#20316;&#20026;&#20027;&#35201;&#23884;&#20837;&#65292;&#24182;&#21033;&#29992;&#20854;&#20182;&#36741;&#21161;&#24037;&#20855;&#26469;&#22686;&#24378;&#20027;&#35201;&#23884;&#20837;&#26469;&#21512;&#24182;&#36825;&#20123;&#21333;&#29420;&#30340;&#23884;&#20837;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#36890;&#24120;&#22312;&#20027;&#35201;&#20219;&#21153;&#19978;&#32852;&#21512;&#23884;&#20837;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#36741;&#21161;&#20219;&#21153;&#19978;&#34920;&#29616;&#19981;&#20339;&#12290;&#20026;&#20102;&#35299;&#20915;&#30001;&#21333;&#29420;&#30340;&#34892;&#20026;&#22270;&#24341;&#36215;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37096;&#20998;&#39034;&#24207;&#22270;&#65288;POG&#65289;&#30340;&#27010;&#24565;&#12290;POG&#23450;&#20041;&#20102;&#22810;&#20010;&#34892;&#20026;&#30340;&#37096;&#20998;&#39034;&#24207;&#20851;&#31995;&#65292;&#24182;&#23558;&#34892;&#20026;&#32452;&#21512;&#24314;&#27169;&#20026;&#24102;&#26377;&#26435;&#37325;&#30340;&#36793;&#65292;&#20197;&#23558;&#21333;&#29420;&#30340;&#34892;&#20026;&#22270;&#21512;&#24182;&#25104;&#19968;&#20010;&#32852;&#21512;&#30340;POG&#12290;&#29702;&#35770;&#35777;&#26126;&#20102;POG&#21487;&#20197;&#25512;&#24191;&#21040;&#20219;&#20309;&#32473;&#23450;&#30340;&#22810;&#20010;&#34892;&#20026;&#38598;&#12290;&#22522;&#20110;POG&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23450;&#21046;&#30340;&#37096;&#20998;&#39034;&#24207;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representing the information of multiple behaviors in the single graph collaborative filtering (CF) vector has been a long-standing challenge. This is because different behaviors naturally form separate behavior graphs and learn separate CF embeddings. Existing models merge the separate embeddings by appointing the CF embeddings for some behaviors as the primary embedding and utilizing other auxiliaries to enhance the primary embedding. However, this approach often results in the joint embedding performing well on the main tasks but poorly on the auxiliary ones. To address the problem arising from the separate behavior graphs, we propose the concept of Partial Order Graphs (POG). POG defines the partial order relation of multiple behaviors and models behavior combinations as weighted edges to merge separate behavior graphs into a joint POG. Theoretical proof verifies that POG can be generalized to any given set of multiple behaviors. Based on POG, we propose the tailored Partial Order 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#25552;&#31034;&#25200;&#21160;&#30340;&#24433;&#21709;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#25216;&#26415;GGPP&#12290;&#36890;&#36807;GGPP&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;LLMs&#30340;&#36755;&#20986;&#24341;&#23548;&#21040;&#29305;&#23450;&#30340;&#38169;&#35823;&#31572;&#26696;&#65292;&#24182;&#24212;&#23545;&#25552;&#31034;&#20013;&#30340;&#26080;&#20851;&#19978;&#19979;&#25991;&#12290;</title><link>https://arxiv.org/abs/2402.07179</link><description>&lt;p&gt;
&#22312;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#36827;&#34892;&#25552;&#31034;&#25200;&#21160;
&lt;/p&gt;
&lt;p&gt;
Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07179
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#25552;&#31034;&#25200;&#21160;&#30340;&#24433;&#21709;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#25216;&#26415;GGPP&#12290;&#36890;&#36807;GGPP&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;LLMs&#30340;&#36755;&#20986;&#24341;&#23548;&#21040;&#29305;&#23450;&#30340;&#38169;&#35823;&#31572;&#26696;&#65292;&#24182;&#24212;&#23545;&#25552;&#31034;&#20013;&#30340;&#26080;&#20851;&#19978;&#19979;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#40065;&#26834;&#24615;&#22312;&#20854;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#20351;&#29992;&#36805;&#36895;&#22686;&#38271;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#34987;&#35270;&#20026;&#25552;&#39640;&#20174;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#21487;&#20449;&#24230;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;RAG-based LLMs&#30340;&#36755;&#20986;&#22914;&#20309;&#21463;&#21040;&#31245;&#26377;&#19981;&#21516;&#30340;&#36755;&#20837;&#24433;&#21709;&#30340;&#30740;&#31350;&#36824;&#19981;&#22815;&#20805;&#20998;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#21363;&#20351;&#22312;&#25552;&#31034;&#20013;&#25554;&#20837;&#19968;&#20010;&#24456;&#30701;&#30340;&#21069;&#32512;&#20063;&#20250;&#23548;&#33268;&#29983;&#25104;&#30340;&#36755;&#20986;&#19982;&#20107;&#23454;&#27491;&#30830;&#31572;&#26696;&#30456;&#21435;&#29978;&#36828;&#12290;&#25105;&#20204;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#36825;&#31867;&#21069;&#32512;&#23545;RAG&#30340;&#24433;&#21709;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Gradient Guided Prompt Perturbation&#65288;GGPP&#65289;&#30340;&#26032;&#22411;&#20248;&#21270;&#25216;&#26415;&#12290;GGPP&#22312;&#23558;RAG-based LLMs&#30340;&#36755;&#20986;&#24341;&#23548;&#21040;&#29305;&#23450;&#38169;&#35823;&#31572;&#26696;&#26041;&#38754;&#21462;&#24471;&#20102;&#24456;&#39640;&#30340;&#25104;&#21151;&#29575;&#12290;&#23427;&#36824;&#21487;&#20197;&#24212;&#23545;&#25552;&#31034;&#20013;&#35831;&#27714;&#24573;&#30053;&#26080;&#20851;&#19978;&#19979;&#25991;&#30340;&#25351;&#20196;&#12290;&#25105;&#20204;&#36824;&#21033;&#29992;LLMs&#22312;&#24102;&#26377;&#21644;&#19981;&#24102;&#26377;GGPP&#25200;&#21160;&#30340;&#25552;&#31034;&#20043;&#38388;&#30340;&#31070;&#32463;&#20803;&#28608;&#27963;&#24046;&#24322;&#26469;&#25552;&#20379;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The robustness of large language models (LLMs) becomes increasingly important as their use rapidly grows in a wide range of domains. Retrieval-Augmented Generation (RAG) is considered as a means to improve the trustworthiness of text generation from LLMs. However, how the outputs from RAG-based LLMs are affected by slightly different inputs is not well studied. In this work, we find that the insertion of even a short prefix to the prompt leads to the generation of outputs far away from factually correct answers. We systematically evaluate the effect of such prefixes on RAG by introducing a novel optimization technique called Gradient Guided Prompt Perturbation (GGPP). GGPP achieves a high success rate in steering outputs of RAG-based LLMs to targeted wrong answers. It can also cope with instructions in the prompts requesting to ignore irrelevant context. We also exploit LLMs' neuron activation difference between prompts with and without GGPP perturbations to give a method that improves
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21160;&#20316;&#20849;&#29616;&#30340;&#20219;&#21153;&#65292;&#24182;&#21019;&#24314;&#20102;ACE&#25968;&#25454;&#38598;&#20197;&#21450;&#30456;&#24212;&#30340;&#20195;&#30721;&#12290;&#36890;&#36807;&#21033;&#29992;&#35270;&#35273;&#21644;&#25991;&#26412;&#20449;&#24687;&#30340;&#22270;&#38142;&#25509;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#25429;&#25417;&#19981;&#21516;&#25968;&#25454;&#22495;&#20013;&#30340;&#20154;&#31867;&#21160;&#20316;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2309.06219</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#38142;&#25509;&#39044;&#27979;&#22312;&#29983;&#27963;&#26041;&#24335;vlog&#20013;&#30340;&#20154;&#31867;&#21160;&#20316;&#20849;&#29616;
&lt;/p&gt;
&lt;p&gt;
Human Action Co-occurrence in Lifestyle Vlogs using Graph Link Prediction. (arXiv:2309.06219v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06219
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21160;&#20316;&#20849;&#29616;&#30340;&#20219;&#21153;&#65292;&#24182;&#21019;&#24314;&#20102;ACE&#25968;&#25454;&#38598;&#20197;&#21450;&#30456;&#24212;&#30340;&#20195;&#30721;&#12290;&#36890;&#36807;&#21033;&#29992;&#35270;&#35273;&#21644;&#25991;&#26412;&#20449;&#24687;&#30340;&#22270;&#38142;&#25509;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#25429;&#25417;&#19981;&#21516;&#25968;&#25454;&#22495;&#20013;&#30340;&#20154;&#31867;&#21160;&#20316;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21160;&#20316;&#20849;&#29616;&#30340;&#20219;&#21153;&#65292;&#21363;&#30830;&#23450;&#20004;&#20010;&#20154;&#31867;&#21160;&#20316;&#26159;&#21542;&#21487;&#20197;&#22312;&#21516;&#19968;&#26102;&#38388;&#38388;&#38548;&#20869;&#20849;&#29616;&#12290;&#25105;&#20204;&#21019;&#24314;&#24182;&#20844;&#24320;&#20102;ACE&#65288;Action Co-occurrencE&#65289;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#30001;&#32422;12k&#20010;&#20849;&#29616;&#30340;&#35270;&#35273;&#21160;&#20316;&#23545;&#21644;&#23427;&#20204;&#23545;&#24212;&#30340;&#35270;&#39057;&#29255;&#27573;&#32452;&#25104;&#30340;&#22823;&#22411;&#22270;&#24418;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#21033;&#29992;&#35270;&#35273;&#21644;&#25991;&#26412;&#20449;&#24687;&#26469;&#33258;&#21160;&#25512;&#26029;&#20004;&#20010;&#21160;&#20316;&#26159;&#21542;&#20849;&#29616;&#30340;&#22270;&#38142;&#25509;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#24418;&#29305;&#21035;&#36866;&#21512;&#25429;&#25417;&#20154;&#31867;&#21160;&#20316;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#19988;&#25152;&#23398;&#20064;&#30340;&#22270;&#24418;&#34920;&#31034;&#23545;&#20110;&#25105;&#20204;&#30340;&#20219;&#21153;&#26159;&#26377;&#25928;&#30340;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#22495;&#20013;&#25429;&#25417;&#21040;&#26032;&#39062;&#32780;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;&#26412;&#25991;&#20171;&#32461;&#30340;ACE&#25968;&#25454;&#38598;&#21644;&#20195;&#30721;&#21487;&#22312;https://github.com/MichiganNLP/vlog_action_co-occurrence&#20844;&#24320;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the task of automatic human action co-occurrence identification, i.e., determine whether two human actions can co-occur in the same interval of time. We create and make publicly available the ACE (Action Co-occurrencE) dataset, consisting of a large graph of ~12k co-occurring pairs of visual actions and their corresponding video clips. We describe graph link prediction models that leverage visual and textual information to automatically infer if two actions are co-occurring. We show that graphs are particularly well suited to capture relations between human actions, and the learned graph representations are effective for our task and capture novel and relevant information across different data domains. The ACE dataset and the code introduced in this paper are publicly available at https://github.com/MichiganNLP/vlog_action_co-occurrence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#27169;&#25311;&#36830;&#32493;&#20449;&#24687;&#26816;&#32034;&#30340;&#22810;&#20027;&#39064;&#25968;&#25454;&#38598;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#26694;&#26550;&#65292;&#33021;&#22815;&#38450;&#27490;&#28798;&#38590;&#24615;&#36951;&#24536;&#24182;&#25552;&#39640;&#20808;&#21069;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08378</link><description>&lt;p&gt;
&#25512;&#36827;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#25345;&#32493;&#32456;&#36523;&#23398;&#20064;&#65306;&#23450;&#20041;&#12289;&#25968;&#25454;&#38598;&#12289;&#26694;&#26550;&#21644;&#23454;&#35777;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Advancing continual lifelong learning in neural information retrieval: definition, dataset, framework, and empirical evaluation. (arXiv:2308.08378v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#27169;&#25311;&#36830;&#32493;&#20449;&#24687;&#26816;&#32034;&#30340;&#22810;&#20027;&#39064;&#25968;&#25454;&#38598;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#26694;&#26550;&#65292;&#33021;&#22815;&#38450;&#27490;&#28798;&#38590;&#24615;&#36951;&#24536;&#24182;&#25552;&#39640;&#20808;&#21069;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#23398;&#20064;&#26159;&#25351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#23398;&#20064;&#21644;&#36866;&#24212;&#26032;&#20449;&#24687;&#30340;&#21516;&#26102;&#65292;&#19981;&#24433;&#21709;&#20854;&#22312;&#20808;&#21069;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#24050;&#26377;&#22810;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#20294;&#20173;&#32570;&#20047;&#26126;&#30830;&#30340;&#20219;&#21153;&#23450;&#20041;&#65292;&#24182;&#19988;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#22312;&#36825;&#31181;&#32972;&#26223;&#19979;&#20856;&#22411;&#30340;&#23398;&#20064;&#31574;&#30053;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#27169;&#25311;&#36830;&#32493;&#20449;&#24687;&#26816;&#32034;&#30340;&#22810;&#20027;&#39064;&#25968;&#25454;&#38598;&#12290;&#38543;&#21518;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#26694;&#26550;&#65292;&#21253;&#25324;&#20856;&#22411;&#26816;&#32034;&#27169;&#22411;&#21644;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#33021;&#22815;&#25104;&#21151;&#22320;&#38450;&#27490;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#24182;&#25552;&#39640;&#20808;&#21069;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#23884;&#20837;&#30340;&#26816;&#32034;&#26041;&#24335;&#36739;&#20256;&#32479;&#30340;&#22522;&#20110;&#32034;&#24341;&#30340;&#26816;&#32034;&#26041;&#24335;&#20855;&#26377;&#20248;&#21183;&#65292;&#24182;&#19988;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#33021;&#22815;&#26377;&#25928;&#22320;&#25552;&#21319;&#26816;&#32034;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Continual learning refers to the capability of a machine learning model to learn and adapt to new information, without compromising its performance on previously learned tasks. Although several studies have investigated continual learning methods for information retrieval tasks, a well-defined task formulation is still lacking, and it is unclear how typical learning strategies perform in this context. To address this challenge, a systematic task formulation of continual neural information retrieval is presented, along with a multiple-topic dataset that simulates continuous information retrieval. A comprehensive continual neural information retrieval framework consisting of typical retrieval models and continual learning strategies is then proposed. Empirical evaluations illustrate that the proposed framework can successfully prevent catastrophic forgetting in neural information retrieval and enhance performance on previously learned tasks. The results indicate that embedding-based retr
&lt;/p&gt;</description></item></channel></rss>