<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#20174;&#30334;&#24230;&#25628;&#32034;&#24341;&#25806;&#21457;&#24067;&#30340;&#22823;&#35268;&#27169;&#25628;&#32034;&#25968;&#25454;&#38598;&#20986;&#21457;&#65292;&#25506;&#35752;&#20102;&#26080;&#20559;&#21521;&#23398;&#20064;&#25490;&#24207;&#25216;&#26415;&#22312;&#23454;&#38469;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#19982;&#25490;&#21517;&#25439;&#22833;&#21644;&#26597;&#35810;-&#25991;&#26723;&#29305;&#24449;&#36873;&#25321;&#30456;&#27604;&#65292;ULTR&#25216;&#26415;&#24182;&#26410;&#24102;&#26469;&#26126;&#26174;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2404.02543</link><description>&lt;p&gt;
&#26080;&#20559;&#21521;&#23398;&#20064;&#25490;&#24207;&#36935;&#21040;&#29616;&#23454;&#65306;&#30334;&#24230;&#22823;&#35268;&#27169;&#25628;&#32034;&#25968;&#25454;&#38598;&#30340;&#32463;&#39564;&#25945;&#35757;
&lt;/p&gt;
&lt;p&gt;
Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#30334;&#24230;&#25628;&#32034;&#24341;&#25806;&#21457;&#24067;&#30340;&#22823;&#35268;&#27169;&#25628;&#32034;&#25968;&#25454;&#38598;&#20986;&#21457;&#65292;&#25506;&#35752;&#20102;&#26080;&#20559;&#21521;&#23398;&#20064;&#25490;&#24207;&#25216;&#26415;&#22312;&#23454;&#38469;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#19982;&#25490;&#21517;&#25439;&#22833;&#21644;&#26597;&#35810;-&#25991;&#26723;&#29305;&#24449;&#36873;&#25321;&#30456;&#27604;&#65292;ULTR&#25216;&#26415;&#24182;&#26410;&#24102;&#26469;&#26126;&#26174;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#20559;&#21521;&#23398;&#20064;&#25490;&#24207;&#65288;ULTR&#65289;&#26159;&#19968;&#20010;&#29992;&#20110;&#23398;&#20064;&#29992;&#25143;&#28857;&#20987;&#25968;&#25454;&#30340;&#25104;&#29087;&#26694;&#26550;&#65292;&#32780;&#36825;&#20123;&#25968;&#25454;&#24448;&#24448;&#21463;&#25910;&#38598;&#25968;&#25454;&#30340;&#25490;&#21517;&#32773;&#30340;&#20559;&#35265;&#24433;&#21709;&#12290;&#34429;&#28982;&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#35777;&#26126;&#24182;&#22312;&#27169;&#25311;&#20013;&#36827;&#34892;&#20102;&#24191;&#27867;&#27979;&#35797;&#65292;&#20294;ULTR&#25216;&#26415;&#32570;&#20047;&#32463;&#39564;&#39564;&#35777;&#65292;&#23588;&#20854;&#26159;&#22312;&#29616;&#20195;&#25628;&#32034;&#24341;&#25806;&#20013;&#12290;&#30334;&#24230;&#25628;&#32034;&#24341;&#25806;&#21457;&#24067;&#30340;WSDM Cup 2023&#25968;&#25454;&#38598;&#20026;&#35780;&#20272;&#20027;&#35201;ULTR&#25216;&#26415;&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#30340;&#34920;&#29616;&#25552;&#20379;&#20102;&#38590;&#24471;&#30340;&#26426;&#20250;&#12290;&#23613;&#31649;&#22312;WSDM Cup 2023&#26399;&#38388;&#26377;&#22810;&#27425;&#25552;&#20132;&#65292;&#20197;&#21450;&#38543;&#21518;&#30340;NTCIR ULTRE-2&#20219;&#21153;&#65292;&#20294;&#30446;&#21069;&#36824;&#19981;&#28165;&#26970;&#35266;&#23519;&#21040;&#30340;&#25913;&#36827;&#26159;&#21542;&#28304;&#33258;&#24212;&#29992;ULTR&#25110;&#20854;&#20182;&#23398;&#20064;&#25216;&#26415;&#12290;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#23454;&#39564;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#26080;&#20559;&#21521;&#23398;&#20064;&#25490;&#24207;&#25216;&#26415;&#24182;&#19981;&#33021;&#26126;&#26174;&#25552;&#21319;&#24615;&#33021;&#65292;&#23588;&#20854;&#26159;&#19982;&#25490;&#21517;&#25439;&#22833;&#21644;&#26597;&#35810;-&#25991;&#26723;&#29305;&#24449;&#36873;&#25321;&#24102;&#26469;&#30340;&#26126;&#26174;&#24046;&#24322;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02543v1 Announce Type: cross  Abstract: Unbiased learning-to-rank (ULTR) is a well-established framework for learning from user clicks, which are often biased by the ranker collecting the data. While theoretically justified and extensively tested in simulation, ULTR techniques lack empirical validation, especially on modern search engines. The dataset released for the WSDM Cup 2023, collected from Baidu's search engine, offers a rare opportunity to assess the real-world performance of prominent ULTR techniques. Despite multiple submissions during the WSDM Cup 2023 and the subsequent NTCIR ULTRE-2 task, it remains unclear whether the observed improvements stem from applying ULTR or other learning techniques. We revisit and extend the available experiments. We find that unbiased learning-to-rank techniques do not bring clear performance improvements, especially compared to the stark differences brought by the choice of ranking loss and query-document features. Our experiments 
&lt;/p&gt;</description></item><item><title>ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2401.10225</link><description>&lt;p&gt;
ChatQA: &#26500;&#24314;GPT-4&#32423;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10225
&lt;/p&gt;
&lt;p&gt;
ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChatQA&#65292;&#19968;&#31995;&#21015;&#20855;&#26377;GPT-4&#32423;&#21035;&#20934;&#30830;&#24615;&#30340;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#22788;&#29702;&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#26816;&#32034;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#22810;&#36718;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#24494;&#35843;&#65292;&#36825;&#26679;&#21487;&#20197;&#25552;&#20379;&#19982;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22823;&#22823;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;ChatQA-70B&#21487;&#20197;&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24179;&#22343;&#20998;&#19978;&#36229;&#36807;GPT-4&#65288;54.14 vs. 53.90&#65289;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;OpenAI GPT&#27169;&#22411;&#30340;&#20219;&#20309;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#20462;&#27491;&#31574;&#30053;&#65288;DCD&#65289;&#65292;&#29992;&#20110;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#26356;&#26377;&#25928;&#22320;&#23558;&#25945;&#24072;&#27169;&#22411;&#30340;&#25490;&#21517;&#20449;&#24687;&#36716;&#31227;&#21040;&#23398;&#29983;&#27169;&#22411;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#20805;&#20998;&#21033;&#29992;&#20102;&#23398;&#29983;&#27169;&#22411;&#30340;&#39044;&#27979;&#35823;&#24046;&#65292;&#36824;&#25552;&#20379;&#20102;&#26356;&#20840;&#38754;&#30340;&#35270;&#35282;&#65292;&#35299;&#20915;&#20102;&#26494;&#24347;&#25490;&#21517;&#33976;&#39311;&#26041;&#27861;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2109.03459</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#20110;&#25490;&#21517;&#33976;&#39311;&#30340;&#21452;&#37325;&#20462;&#27491;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Dual Correction Strategy for Ranking Distillation in Top-N Recommender System. (arXiv:2109.03459v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.03459
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#20462;&#27491;&#31574;&#30053;&#65288;DCD&#65289;&#65292;&#29992;&#20110;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#26356;&#26377;&#25928;&#22320;&#23558;&#25945;&#24072;&#27169;&#22411;&#30340;&#25490;&#21517;&#20449;&#24687;&#36716;&#31227;&#21040;&#23398;&#29983;&#27169;&#22411;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#20805;&#20998;&#21033;&#29992;&#20102;&#23398;&#29983;&#27169;&#22411;&#30340;&#39044;&#27979;&#35823;&#24046;&#65292;&#36824;&#25552;&#20379;&#20102;&#26356;&#20840;&#38754;&#30340;&#35270;&#35282;&#65292;&#35299;&#20915;&#20102;&#26494;&#24347;&#25490;&#21517;&#33976;&#39311;&#26041;&#27861;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#33976;&#39311;&#26159;&#23558;&#35757;&#32451;&#20805;&#20998;&#30340;&#22823;&#27169;&#22411;&#65288;&#25945;&#24072;&#65289;&#30340;&#30693;&#35782;&#36716;&#31227;&#21040;&#23567;&#27169;&#22411;&#65288;&#23398;&#29983;&#65289;&#30340;&#37325;&#35201;&#30740;&#31350;&#39046;&#22495;&#65292;&#23545;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#23454;&#38469;&#37096;&#32626;&#32780;&#35328;&#65292;&#23427;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26368;&#36817;&#65292;&#26494;&#24347;&#25490;&#21517;&#33976;&#39311;&#65288;RRD&#65289;&#34920;&#26126;&#65292;&#22312;&#25512;&#33616;&#21015;&#34920;&#20013;&#33976;&#39311;&#25490;&#21517;&#20449;&#24687;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#20173;&#28982;&#23384;&#22312;&#20197;&#19979;&#38480;&#21046;&#65306;1&#65289;&#23427;&#26410;&#20805;&#20998;&#21033;&#29992;&#23398;&#29983;&#27169;&#22411;&#30340;&#39044;&#27979;&#35823;&#24046;&#65292;&#20351;&#24471;&#35757;&#32451;&#25928;&#29575;&#19981;&#39640;&#65307;2&#65289;&#23427;&#21482;&#33976;&#39311;&#29992;&#25143;&#20391;&#30340;&#25490;&#21517;&#20449;&#24687;&#65292;&#22312;&#31232;&#30095;&#30340;&#38544;&#24335;&#21453;&#39304;&#19979;&#25552;&#20379;&#30340;&#35270;&#35282;&#19981;&#36275;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#33976;&#39311;&#26041;&#27861;&#65292;&#21363;&#21452;&#37325;&#20462;&#27491;&#31574;&#30053;&#65288;DCD&#65289;&#65292;&#36890;&#36807;&#25945;&#24072;&#27169;&#22411;&#21644;&#23398;&#29983;&#27169;&#22411;&#39044;&#27979;&#20043;&#38388;&#30340;&#24046;&#24322;&#26469;&#20915;&#23450;&#35201;&#33976;&#39311;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge Distillation (KD), which transfers the knowledge of a well-trained large model (teacher) to a small model (student), has become an important area of research for practical deployment of recommender systems. Recently, Relaxed Ranking Distillation (RRD) has shown that distilling the ranking information in the recommendation list significantly improves the performance. However, the method still has limitations in that 1) it does not fully utilize the prediction errors of the student model, which makes the training not fully efficient, and 2) it only distills the user-side ranking information, which provides an insufficient view under the sparse implicit feedback. This paper presents Dual Correction strategy for Distillation (DCD), which transfers the ranking information from the teacher model to the student model in a more efficient manner. Most importantly, DCD uses the discrepancy between the teacher model and the student model predictions to decide which knowledge to be disti
&lt;/p&gt;</description></item></channel></rss>