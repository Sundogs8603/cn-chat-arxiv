<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>LLMRec&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#32570;&#24615;&#21644;&#38468;&#21152;&#20449;&#24687;&#24341;&#20837;&#21103;&#20316;&#29992;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#24378;&#20132;&#20114;&#36793;&#12289;&#22686;&#24378;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#29702;&#35299;&#21644;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.00423</link><description>&lt;p&gt;
LLMRec: &#20351;&#29992;&#22270;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
LLMRec: Large Language Models with Graph Augmentation for Recommendation. (arXiv:2311.00423v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00423
&lt;/p&gt;
&lt;p&gt;
LLMRec&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#32570;&#24615;&#21644;&#38468;&#21152;&#20449;&#24687;&#24341;&#20837;&#21103;&#20316;&#29992;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#24378;&#20132;&#20114;&#36793;&#12289;&#22686;&#24378;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#29702;&#35299;&#21644;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31232;&#30095;&#24615;&#19968;&#30452;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#65292;&#20043;&#21069;&#30340;&#30740;&#31350;&#23581;&#35797;&#36890;&#36807;&#24341;&#20837;&#38468;&#21152;&#20449;&#24687;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24448;&#24448;&#20250;&#24102;&#26469;&#22122;&#22768;&#12289;&#21487;&#29992;&#24615;&#38382;&#39064;&#21644;&#25968;&#25454;&#36136;&#37327;&#20302;&#19979;&#31561;&#21103;&#20316;&#29992;&#65292;&#20174;&#32780;&#24433;&#21709;&#23545;&#29992;&#25143;&#20559;&#22909;&#30340;&#20934;&#30830;&#24314;&#27169;&#65292;&#36827;&#32780;&#23545;&#25512;&#33616;&#24615;&#33021;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#37492;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#30693;&#35782;&#24211;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LLMRec&#30340;&#26032;&#26694;&#26550;&#65292;&#23427;&#36890;&#36807;&#37319;&#29992;&#19977;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22522;&#20110;LLM&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22312;&#32447;&#24179;&#21488;&#65288;&#22914;Netflix&#65292;MovieLens&#65289;&#20013;&#20016;&#23500;&#30340;&#20869;&#23481;&#65292;&#22312;&#19977;&#20010;&#26041;&#38754;&#22686;&#24378;&#20132;&#20114;&#22270;&#65306;&#65288;i&#65289;&#21152;&#24378;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#36793;&#65292;&#65288;ii&#65289;&#22686;&#24378;&#23545;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#30340;&#29702;&#35299;&#65292;&#65288;iii&#65289;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#65292;&#30452;&#35266;&#22320;&#34920;&#31034;&#29992;&#25143;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies. Our approach leverages the rich content available within online platforms (e.g., Netflix, MovieLens) to augment the interaction graph in three ways: (i) reinforcing user-item interaction egde, (ii) enhancing the understanding of item node attributes, and (iii) conducting user node profiling, intuiti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;</title><link>http://arxiv.org/abs/2310.20091</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#23494;&#24230;&#29992;&#25143;&#34920;&#31034;&#26041;&#27861;&#29992;&#20110;&#22810;&#20852;&#36259;&#20010;&#24615;&#21270;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval. (arXiv:2310.20091v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35774;&#35745;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#20934;&#30830;&#24314;&#27169;&#29992;&#25143;&#30340;&#21508;&#31181;&#22810;&#26679;&#21270;&#21644;&#21160;&#24577;&#30340;&#20852;&#36259;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#29992;&#25143;&#24314;&#27169;&#26041;&#27861;&#65292;&#22914;&#21333;&#28857;&#21644;&#22810;&#28857;&#34920;&#31034;&#65292;&#23384;&#22312;&#20934;&#30830;&#24615;&#12289;&#22810;&#26679;&#24615;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#36866;&#24212;&#24615;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#19981;&#36275;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#8212;&#8212;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;GPR4DUR&#21033;&#29992;DURs&#26469;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#65292;&#21516;&#26102;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;GPR4DUR&#30340;&#36866;&#24212;&#24615;&#21644;&#25928;&#29575;&#65292;&#32780;&#20351;&#29992;&#27169;&#25311;&#29992;&#25143;&#30340;&#22312;&#32447;&#23454;&#39564;&#21017;&#35777;&#26126;&#20102;&#23427;&#36890;&#36807;&#26377;&#25928;&#21033;&#29992;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#33021;&#22815;&#35299;&#20915;&#25506;&#32034;-&#24320;&#21457;&#30340;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, computational cost, and adaptability. To overcome these deficiencies, we introduce density-based user representations (DURs), a novel model that leverages Gaussian process regression for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25209;&#21028;&#24615;&#23457;&#35270;&#20102;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.15053</link><description>&lt;p&gt;
&#20851;&#20110;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#30340;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#35770;&#25991;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
On (Normalised) Discounted Cumulative Gain as an Offline Evaluation Metric for Top-$n$ Recommendation. (arXiv:2307.15053v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25209;&#21028;&#24615;&#23457;&#35270;&#20102;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#26041;&#27861;&#36890;&#24120;&#36890;&#36807;&#20004;&#31181;&#26041;&#24335;&#36827;&#34892;&#35780;&#20272;&#65306;(1) &#36890;&#36807;(&#27169;&#25311;)&#22312;&#32447;&#23454;&#39564;&#65292;&#36890;&#24120;&#34987;&#35270;&#20026;&#37329;&#26631;&#20934;&#65292;&#25110;&#32773;(2) &#36890;&#36807;&#19968;&#20123;&#31163;&#32447;&#35780;&#20272;&#31243;&#24207;&#65292;&#30446;&#26631;&#26159;&#36817;&#20284;&#22312;&#32447;&#23454;&#39564;&#30340;&#32467;&#26524;&#12290;&#25991;&#29486;&#20013;&#37319;&#29992;&#20102;&#20960;&#31181;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#65292;&#21463;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#20013;&#24120;&#35265;&#30340;&#25490;&#21517;&#25351;&#26631;&#30340;&#21551;&#21457;&#12290;(Normalised) Discounted Cumulative Gain (nDCG)&#26159;&#20854;&#20013;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#22312;&#24456;&#22810;&#24180;&#37324;&#65292;&#26356;&#39640;&#30340;(n)DCG&#20540;&#34987;&#29992;&#26469;&#23637;&#31034;&#26032;&#26041;&#27861;&#22312;Top-n&#25512;&#33616;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#30340;&#23457;&#35270;&#65292;&#24182;&#30740;&#31350;&#20102;&#25105;&#20204;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;&#25105;&#20204;&#20174;&#31532;&#19968;&#21407;&#29702;&#19978;&#27491;&#24335;&#25552;&#20986;&#20102;DCG&#34987;&#35748;&#20026;&#26159;&#22312;&#32447;&#22870;&#21169;&#30340;&#26080;&#20559;&#20272;&#35745;&#30340;&#20551;&#35774;&#65292;&#24182;&#32473;&#20986;&#20102;&#36825;&#20010;&#25351;&#26631;&#30340;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approaches to recommendation are typically evaluated in one of two ways: (1) via a (simulated) online experiment, often seen as the gold standard, or (2) via some offline evaluation procedure, where the goal is to approximate the outcome of an online experiment. Several offline evaluation metrics have been adopted in the literature, inspired by ranking metrics prevalent in the field of Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one such metric that has seen widespread adoption in empirical studies, and higher (n)DCG values have been used to present new methods as the state-of-the-art in top-$n$ recommendation for many years.  Our work takes a critical look at this approach, and investigates when we can expect such metrics to approximate the gold standard outcome of an online experiment. We formally present the assumptions that are necessary to consider DCG an unbiased estimator of online reward and provide a derivation for this metric from first principles
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#32467;&#26500;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#19981;&#21516;&#30340;&#36755;&#20837;&#36873;&#25321;&#20250;&#23545;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#22312;&#22522;&#20934;&#27979;&#35797;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#8220;&#33258;&#25105;&#22686;&#24378;&#8221;&#25216;&#26415;&#20197;&#25913;&#21892;&#29702;&#35299;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.13062</link><description>&lt;p&gt;
GPT4Table&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#29702;&#35299;&#32467;&#26500;&#21270;&#34920;&#26684;&#25968;&#25454;&#21527;&#65311;&#19968;&#39033;&#22522;&#20934;&#27979;&#35797;&#21644;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study. (arXiv:2305.13062v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13062
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#32467;&#26500;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#19981;&#21516;&#30340;&#36755;&#20837;&#36873;&#25321;&#20250;&#23545;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#22312;&#22522;&#20934;&#27979;&#35797;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#8220;&#33258;&#25105;&#22686;&#24378;&#8221;&#25216;&#26415;&#20197;&#25913;&#21892;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23569;&#26679;&#26412;&#25512;&#29702;&#22120;&#26469;&#35299;&#20915;&#19982;&#33258;&#28982;&#35821;&#35328;&#30456;&#20851;&#30340;&#20219;&#21153;&#36234;&#26469;&#36234;&#20855;&#21560;&#24341;&#21147;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;LLMs&#23545;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#20363;&#22914;&#34920;&#26684;&#65289;&#30340;&#29702;&#35299;&#31243;&#24230;&#36824;&#26377;&#24456;&#22810;&#38656;&#35201;&#23398;&#20064;&#30340;&#22320;&#26041;&#12290;&#23613;&#31649;&#21487;&#20197;&#20351;&#29992;&#34920;&#26684;&#24207;&#21015;&#21270;&#20316;&#20026;LLMs&#30340;&#36755;&#20837;&#65292;&#20294;&#30446;&#21069;&#36824;&#32570;&#20047;&#23545;LLMs&#26159;&#21542;&#30495;&#27491;&#33021;&#22815;&#29702;&#35299;&#36825;&#31867;&#25968;&#25454;&#30340;&#20840;&#38754;&#30740;&#31350;&#12290;&#26412;&#25991;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;LLMs&#30340;&#32467;&#26500;&#29702;&#35299;&#33021;&#21147;&#65288;SUC&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#21019;&#24314;&#30340;&#22522;&#20934;&#27979;&#35797;&#21253;&#25324;&#19971;&#20010;&#20219;&#21153;&#65292;&#27599;&#20010;&#20219;&#21153;&#37117;&#26377;&#20854;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#20363;&#22914;&#21333;&#20803;&#26684;&#26597;&#25214;&#12289;&#34892;&#26816;&#32034;&#21644;&#22823;&#23567;&#26816;&#27979;&#12290;&#25105;&#20204;&#23545;GPT-3.5&#21644;GPT-4&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#35780;&#20272;&#12290;&#25105;&#20204;&#21457;&#29616;&#24615;&#33021;&#22240;&#22810;&#31181;&#36755;&#20837;&#36873;&#25321;&#32780;&#24322;&#65292;&#21253;&#25324;&#34920;&#26684;&#36755;&#20837;&#26684;&#24335;&#12289;&#20869;&#23481;&#39034;&#24207;&#12289;&#35282;&#33394;&#25552;&#31034;&#21644;&#20998;&#21306;&#26631;&#35760;&#31561;&#12290;&#26681;&#25454;&#22522;&#20934;&#27979;&#35797;&#35780;&#20272;&#25152;&#24471;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#33258;&#25105;&#22686;&#24378;&#8221;&#25216;&#26415;&#20197;&#25913;&#21892;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are becoming attractive as few-shot reasoners to solve Natural Language (NL)-related tasks. However, there is still much to learn about how well LLMs understand structured data, such as tables. While it is true that tables can be used as inputs to LLMs with serialization, there lack of comprehensive studies examining whether LLMs can truly comprehend such data. In this paper, we try to understand this by designing a benchmark to evaluate the structural understanding capabilities (SUC) of LLMs. The benchmark we create includes seven tasks, each with its own unique challenges, \eg, cell lookup, row retrieval, and size detection. We run a series of evaluations on GPT-3.5 and GPT-4. We discover that the performance varied depending on a number of input choices, including table input format, content order, role prompting, and partition marks. Drawing from the insights gained through the benchmark evaluations, we then propose \textit{self-augmentation} for effect
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#29305;&#24449;&#22797;&#29992;&#8221;&#30340;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#21333;&#19968;&#30340;&#34920;&#31034;&#31354;&#38388; &#33021;&#22815;&#39640;&#25928;&#26377;&#25928;&#22320;&#23398;&#20064;&#39640;&#36136;&#37327;&#30340;&#29305;&#24449;&#23884;&#20837;&#65292;&#21516;&#26102;&#21306;&#20998;&#19981;&#21516;&#30340;&#20998;&#31867;&#29305;&#24449;&#12290;&#36890;&#36807;&#22312;&#22810;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#21644;&#26032;&#25968;&#25454;&#38598;&#8220;Web-Available Image Search (WAIS)&#8221;&#19978;&#30340;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.12102</link><description>&lt;p&gt;
&#32479;&#19968;&#23884;&#20837;&#65306;&#38754;&#21521; Web &#35268;&#27169; ML &#31995;&#32479;&#30340;&#32463;&#36807;&#39564;&#35777;&#30340;&#29305;&#24449;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Unified Embedding: Battle-Tested Feature Representations for Web-Scale ML Systems. (arXiv:2305.12102v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#29305;&#24449;&#22797;&#29992;&#8221;&#30340;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#21333;&#19968;&#30340;&#34920;&#31034;&#31354;&#38388; &#33021;&#22815;&#39640;&#25928;&#26377;&#25928;&#22320;&#23398;&#20064;&#39640;&#36136;&#37327;&#30340;&#29305;&#24449;&#23884;&#20837;&#65292;&#21516;&#26102;&#21306;&#20998;&#19981;&#21516;&#30340;&#20998;&#31867;&#29305;&#24449;&#12290;&#36890;&#36807;&#22312;&#22810;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#21644;&#26032;&#25968;&#25454;&#38598;&#8220;Web-Available Image Search (WAIS)&#8221;&#19978;&#30340;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#12289;&#26377;&#25928;&#22320;&#23398;&#20064;&#39640;&#36136;&#37327;&#30340;&#29305;&#24449;&#23884;&#20837;&#23545;&#20110; Web &#35268;&#27169;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#26631;&#20934;&#26041;&#27861;&#26159;&#23558;&#27599;&#20010;&#29305;&#24449;&#20540;&#34920;&#31034;&#20026;&#19968;&#20010; d &#32500;&#23884;&#20837;&#65292;&#24341;&#20837;&#25968;&#30334;&#20159;&#20010;&#21442;&#25968;&#65292;&#32780;&#36825;&#20123;&#29305;&#24449;&#30340;&#22522;&#25968;&#38750;&#24120;&#39640;&#12290;&#36825;&#20010;&#29942;&#39048;&#23548;&#33268;&#20102;&#22791;&#36873;&#23884;&#20837;&#31639;&#27861;&#30340;&#37325;&#22823;&#36827;&#23637;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#38750;&#24120;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#21363;&#8220;&#29305;&#24449;&#22797;&#29992;&#8221;&#65292;&#22312;&#35768;&#22810;&#19981;&#21516;&#30340;&#20998;&#31867;&#29305;&#24449;&#20043;&#38388;&#20351;&#29992;&#19968;&#20010;&#21333;&#19968;&#30340;&#34920;&#31034;&#31354;&#38388;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#22797;&#29992;&#30340;&#23884;&#20837;&#21487;&#20197;&#20998;&#35299;&#20026;&#27599;&#20010;&#32452;&#25104;&#29305;&#24449;&#30340;&#32452;&#20214;&#65292;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#21306;&#20998;&#29305;&#24449;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22797;&#29992;&#30340;&#23884;&#20837;&#22312;&#20960;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;Web-Available Image Search (WAIS)&#8221;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#20197;&#20005;&#26684;&#35780;&#20272; Web &#35268;&#27169;&#19979;&#30340;&#26032;&#23884;&#20837;&#31639;&#27861;&#12290;&#25105;&#20204;&#36992;&#35831;&#31038;&#21306;&#36890;&#36807;&#25552;&#20986;&#21487;&#20197;&#20934;&#30830;&#12289;&#39640;&#25928;&#22320;&#23558;&#25968;&#30334;&#19975;&#24352;&#22270;&#20687;&#23884;&#20837;&#21644;&#20998;&#31867;&#21040;&#25104;&#21315;&#19978;&#19975;&#20010;&#31867;&#21035;&#30340;&#26032;&#27169;&#22411;&#26469;&#36129;&#29486; WAIS &#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning high-quality feature embeddings efficiently and effectively is critical for the performance of web-scale machine learning systems. A typical model ingests hundreds of features with vocabularies on the order of millions to billions of tokens. The standard approach is to represent each feature value as a d-dimensional embedding, introducing hundreds of billions of parameters for extremely high-cardinality features. This bottleneck has led to substantial progress in alternative embedding algorithms. Many of these methods, however, make the assumption that each feature uses an independent embedding table. This work introduces a simple yet highly effective framework, Feature Multiplexing, where one single representation space is used across many different categorical features. Our theoretical and empirical analysis reveals that multiplexed embeddings can be decomposed into components from each constituent feature, allowing models to distinguish between features. We show that multip
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#8212;&#8212;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#12290;&#38024;&#23545;&#36825;&#19968;&#20219;&#21153;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#26041;&#26696;&#8212;&#8212;KGEditor&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.10405</link><description>&lt;p&gt;
&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.10405
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#8212;&#8212;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#12290;&#38024;&#23545;&#36825;&#19968;&#20219;&#21153;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#26041;&#26696;&#8212;&#8212;KGEditor&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#23884;&#20837;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;KG&#23884;&#20837;&#36890;&#24120;&#20316;&#20026;&#38745;&#24577;&#24037;&#20214;&#37096;&#32626;&#65292;&#20462;&#25913;&#36215;&#26469;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;KG&#23884;&#20837;&#12290;&#35813;&#20219;&#21153;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#65292;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#22235;&#20010;&#26032;&#25968;&#25454;&#38598;&#65306;E-FB15k237&#12289;A-FB15k237&#12289;E-WN18RR &#21644; A-WN18RR&#65292;&#24182;&#35780;&#20272;&#20102;&#20960;&#31181;&#30693;&#35782;&#32534;&#36753;&#22522;&#32447;&#65292;&#35777;&#26126;&#20102;&#20043;&#21069;&#30340;&#27169;&#22411;&#22788;&#29702;&#35813;&#20219;&#21153;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#24378;&#22823;&#30340;&#22522;&#32447;&#8212;&#8212;KGEditor&#65292;&#23427;&#21033;&#29992;&#36229;&#32593;&#32476;&#30340;&#38468;&#21152;&#21442;&#25968;&#23618;&#26469;&#32534;&#36753;/&#28155;&#21152;&#20107;&#23454;&#12290;&#20840;&#38754;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#26102;&#65292;KGEditor &#30340;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
&lt;/p&gt;</description></item></channel></rss>