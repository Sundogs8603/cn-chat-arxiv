<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#20313;&#24358;&#30456;&#20284;&#24230;&#21487;&#20197;&#20135;&#29983;&#20219;&#24847;&#21644;&#26080;&#24847;&#20041;&#30340;&#8220;&#30456;&#20284;&#24615;&#8221;&#65292;&#21463;&#27491;&#21017;&#21270;&#25511;&#21046;&#65292;&#24182;&#35752;&#35770;&#20102;&#28145;&#23618;&#27169;&#22411;&#23398;&#20064;&#20013;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.05440</link><description>&lt;p&gt;
&#23884;&#20837;&#30340;&#20313;&#24358;&#30456;&#20284;&#24615;&#30495;&#30340;&#21482;&#26159;&#20851;&#20110;&#30456;&#20284;&#24615;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Cosine-Similarity of Embeddings Really About Similarity?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05440
&lt;/p&gt;
&lt;p&gt;
&#20313;&#24358;&#30456;&#20284;&#24230;&#21487;&#20197;&#20135;&#29983;&#20219;&#24847;&#21644;&#26080;&#24847;&#20041;&#30340;&#8220;&#30456;&#20284;&#24615;&#8221;&#65292;&#21463;&#27491;&#21017;&#21270;&#25511;&#21046;&#65292;&#24182;&#35752;&#35770;&#20102;&#28145;&#23618;&#27169;&#22411;&#23398;&#20064;&#20013;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20313;&#24358;&#30456;&#20284;&#24230;&#26159;&#20004;&#20010;&#21521;&#37327;&#20043;&#38388;&#22841;&#35282;&#30340;&#20313;&#24358;&#65292;&#25110;&#32773;&#31561;&#20215;&#22320;&#35828;&#26159;&#23427;&#20204;&#24402;&#19968;&#21270;&#21518;&#30340;&#28857;&#31215;&#12290;&#19968;&#20010;&#24120;&#35265;&#30340;&#24212;&#29992;&#26159;&#36890;&#36807;&#23558;&#20313;&#24358;&#30456;&#20284;&#24230;&#24212;&#29992;&#20110;&#23398;&#20064;&#30340;&#20302;&#32500;&#29305;&#24449;&#23884;&#20837;&#26469;&#37327;&#21270;&#39640;&#32500;&#23545;&#35937;&#20043;&#38388;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#31181;&#26041;&#27861;&#26377;&#26102;&#27604;&#23884;&#20837;&#21521;&#37327;&#20043;&#38388;&#30340;&#26410;&#24402;&#19968;&#21270;&#28857;&#31215;&#25928;&#26524;&#26356;&#22909;&#65292;&#20294;&#26377;&#26102;&#20063;&#26356;&#24046;&#12290;&#20026;&#20102;&#28145;&#20837;&#20102;&#35299;&#36825;&#19968;&#32463;&#39564;&#35266;&#23519;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#30001;&#27491;&#21017;&#21270;&#32447;&#24615;&#27169;&#22411;&#23548;&#20986;&#30340;&#23884;&#20837;&#65292;&#20854;&#20013;&#23553;&#38381;&#24418;&#24335;&#30340;&#35299;&#20915;&#26041;&#26696;&#26377;&#21161;&#20110;&#20998;&#26512;&#27934;&#23519;&#21147;&#12290;&#25105;&#20204;&#22312;&#20998;&#26512;&#19978;&#25512;&#23548;&#20986;&#20313;&#24358;&#30456;&#20284;&#24615;&#22914;&#20309;&#20135;&#29983;&#20219;&#24847;&#19988;&#22240;&#27492;&#26080;&#24847;&#20041;&#30340;&#8220;&#30456;&#20284;&#24615;&#8221;&#12290;&#23545;&#20110;&#19968;&#20123;&#32447;&#24615;&#27169;&#22411;&#65292;&#30456;&#20284;&#24615;&#29978;&#33267;&#19981;&#26159;&#21807;&#19968;&#30340;&#65292;&#32780;&#23545;&#20110;&#20854;&#20182;&#19968;&#20123;&#27169;&#22411;&#65292;&#23427;&#20204;&#21463;&#21040;&#27491;&#21017;&#21270;&#30340;&#38544;&#24335;&#25511;&#21046;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#32447;&#24615;&#27169;&#22411;&#20043;&#22806;&#30340;&#24433;&#21709;&#65306;&#22312;&#23398;&#20064;&#28145;&#23618;&#27169;&#22411;&#26102;&#65292;&#20250;&#37319;&#29992;&#19981;&#21516;&#27491;&#21017;&#21270;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05440v1 Announce Type: cross  Abstract: Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless `similarities.' For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;LLMQA&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#20013;&#25198;&#28436;&#29983;&#25104;&#22120;&#12289;&#37325;&#26032;&#25490;&#24207;&#22120;&#21644;&#35780;&#20272;&#22120;&#31561;&#22810;&#37325;&#35282;&#33394;&#65292;&#32467;&#21512;&#20102;&#26816;&#32034;&#21644;&#29983;&#25104;&#35777;&#25454;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.05217</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35282;&#33394;&#33021;&#21147;&#36827;&#34892;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05217
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;LLMQA&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#20013;&#25198;&#28436;&#29983;&#25104;&#22120;&#12289;&#37325;&#26032;&#25490;&#24207;&#22120;&#21644;&#35780;&#20272;&#22120;&#31561;&#22810;&#37325;&#35282;&#33394;&#65292;&#32467;&#21512;&#20102;&#26816;&#32034;&#21644;&#29983;&#25104;&#35777;&#25454;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#65288;ODQA&#65289;&#24050;&#32463;&#25104;&#20026;&#20449;&#24687;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#30740;&#31350;&#28966;&#28857;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#36981;&#24490;&#20004;&#31181;&#33539;&#24335;&#26469;&#25910;&#38598;&#35777;&#25454;&#65306;&#65288;1&#65289;\textit{&#26816;&#32034;-&#28982;&#21518;&#38405;&#35835;}&#33539;&#24335;&#20174;&#22806;&#37096;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#30456;&#20851;&#25991;&#26723;&#65307;&#21644;&#65288;2&#65289;\textit{&#29983;&#25104;-&#28982;&#21518;&#38405;&#35835;}&#33539;&#24335;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#30456;&#20851;&#25991;&#26723;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#19981;&#33021;&#23436;&#20840;&#28385;&#36275;&#35777;&#25454;&#30340;&#22810;&#26041;&#38754;&#35201;&#27714;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LLMQA&#65292;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#23558;ODQA&#36807;&#31243;&#20998;&#20026;&#19977;&#20010;&#22522;&#26412;&#27493;&#39588;&#65306;&#26597;&#35810;&#25193;&#23637;&#65292;&#25991;&#26723;&#36873;&#25321;&#21644;&#31572;&#26696;&#29983;&#25104;&#65292;&#32467;&#21512;&#20102;&#26816;&#32034;&#21644;&#29983;&#25104;&#35777;&#25454;&#30340;&#20248;&#21183;&#12290;&#30001;&#20110;LLMs&#23637;&#31034;&#20102;&#20854;&#20986;&#33394;&#30340;&#33021;&#21147;&#26469;&#23436;&#25104;&#21508;&#31181;&#20219;&#21153;&#65292;&#25105;&#20204;&#25351;&#23548;LLMs&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20869;&#25198;&#28436;&#29983;&#25104;&#22120;&#12289;&#37325;&#26032;&#25490;&#24207;&#22120;&#21644;&#35780;&#20272;&#22120;&#31561;&#22810;&#31181;&#35282;&#33394;&#65292;&#20351;&#23427;&#20204;&#34701;&#21512;&#22312;ODQA&#36807;&#31243;&#20013;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05217v1 Announce Type: cross  Abstract: Open-domain question answering (ODQA) has emerged as a pivotal research spotlight in information systems. Existing methods follow two main paradigms to collect evidence: (1) The \textit{retrieve-then-read} paradigm retrieves pertinent documents from an external corpus; and (2) the \textit{generate-then-read} paradigm employs large language models (LLMs) to generate relevant documents. However, neither can fully address multifaceted requirements for evidence. To this end, we propose LLMQA, a generalized framework that formulates the ODQA process into three basic steps: query expansion, document selection, and answer generation, combining the superiority of both retrieval-based and generation-based evidence. Since LLMs exhibit their excellent capabilities to accomplish various tasks, we instruct LLMs to play multiple roles as generators, rerankers, and evaluators within our framework, integrating them to collaborate in the ODQA process. 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#21452;&#22612;&#27169;&#22411;&#21644;&#24322;&#36136;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#24212;&#23545;Spotify&#22312;&#24341;&#20837;&#26377;&#22768;&#35835;&#29289;&#21518;&#38754;&#20020;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.05185</link><description>&lt;p&gt;
&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;Spotify&#19978;&#36827;&#34892;&#20010;&#24615;&#21270;&#26377;&#22768;&#35835;&#29289;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Personalized Audiobook Recommendations at Spotify Through Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05185
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#21452;&#22612;&#27169;&#22411;&#21644;&#24322;&#36136;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#24212;&#23545;Spotify&#22312;&#24341;&#20837;&#26377;&#22768;&#35835;&#29289;&#21518;&#38754;&#20020;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#26029;&#21457;&#23637;&#30340;&#25968;&#23383;&#38899;&#39057;&#39046;&#22495;&#20013;&#65292;&#20197;&#20854;&#38899;&#20048;&#21644;&#35848;&#35805;&#20869;&#23481;&#32780;&#38395;&#21517;&#30340;Spotify&#26368;&#36817;&#21521;&#20854;&#24222;&#22823;&#29992;&#25143;&#32676;&#24341;&#20837;&#20102;&#26377;&#22768;&#35835;&#29289;&#12290;&#23613;&#31649;&#21069;&#26223;&#30475;&#22909;&#65292;&#20294;&#36825;&#19968;&#20030;&#25514;&#20026;&#20010;&#24615;&#21270;&#25512;&#33616;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#19982;&#38899;&#20048;&#21644;&#25773;&#23458;&#19981;&#21516;&#65292;&#26368;&#21021;&#38656;&#35201;&#20184;&#36153;&#30340;&#26377;&#22768;&#35835;&#29289;&#22312;&#36141;&#20080;&#21069;&#26080;&#27861;&#36731;&#26494;&#30053;&#35835;&#65292;&#36825;&#22686;&#21152;&#20102;&#25512;&#33616;&#30340;&#30456;&#20851;&#24615;&#30340;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#23558;&#26032;&#20869;&#23481;&#31867;&#22411;&#24341;&#20837;&#29616;&#26377;&#24179;&#21488;&#23548;&#33268;&#25968;&#25454;&#26497;&#24230;&#31232;&#30095;&#65292;&#22240;&#20026;&#22823;&#22810;&#25968;&#29992;&#25143;&#23545;&#36825;&#31181;&#26032;&#20869;&#23481;&#31867;&#22411;&#19981;&#29087;&#24713;&#12290;&#26368;&#21518;&#65292;&#21521;&#25968;&#30334;&#19975;&#29992;&#25143;&#25512;&#33616;&#20869;&#23481;&#35201;&#27714;&#27169;&#22411;&#21453;&#24212;&#36805;&#36895;&#19988;&#21487;&#25193;&#23637;&#24615;&#24378;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#21033;&#29992;&#25773;&#23458;&#21644;&#38899;&#20048;&#29992;&#25143;&#21916;&#22909;&#65292;&#24341;&#20837;&#20102;2T-HGNN&#65292;&#36825;&#26159;&#19968;&#20010;&#30001;&#24322;&#36136;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;HGNNs&#65289;&#21644;&#21452;&#22612;&#65288;2T&#65289;&#27169;&#22411;&#32452;&#25104;&#30340;&#21487;&#25193;&#23637;&#25512;&#33616;&#31995;&#32479;&#12290;&#36825;&#19968;&#26032;&#39062;&#26041;&#27861;&#25581;&#31034;&#20102;&#39033;&#30446;&#20043;&#38388;&#24494;&#22937;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05185v1 Announce Type: cross  Abstract: In the ever-evolving digital audio landscape, Spotify, well-known for its music and talk content, has recently introduced audiobooks to its vast user base. While promising, this move presents significant challenges for personalized recommendations. Unlike music and podcasts, audiobooks, initially available for a fee, cannot be easily skimmed before purchase, posing higher stakes for the relevance of recommendations. Furthermore, introducing a new content type into an existing platform confronts extreme data sparsity, as most users are unfamiliar with this new content type. Lastly, recommending content to millions of users requires the model to react fast and be scalable. To address these challenges, we leverage podcast and music user preferences and introduce 2T-HGNN, a scalable recommendation system comprising Heterogeneous Graph Neural Networks (HGNNs) and a Two Tower (2T) model. This novel approach uncovers nuanced item relationship
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#29992;&#25143;&#34920;&#31034;&#25490;&#26021;&#30340;&#26032;&#22411;&#22810;&#22612;&#22810;&#20852;&#36259;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22810;&#20852;&#36259;&#23398;&#20064;&#26041;&#27861;&#38754;&#20020;&#30340;&#35757;&#32451;&#21644;&#37096;&#32626;&#30446;&#26631;&#24046;&#24322;&#12289;&#26080;&#27861;&#35775;&#38382;&#21830;&#21697;&#20449;&#24687;&#20197;&#21450;&#38590;&#20197;&#24037;&#19994;&#37319;&#29992;&#31561;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.05122</link><description>&lt;p&gt;
&#20855;&#26377;&#29992;&#25143;&#34920;&#31034;&#25490;&#26021;&#30340;&#22810;&#22612;&#22810;&#20852;&#36259;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Multi-Tower Multi-Interest Recommendation with User Representation Repel
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05122
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#29992;&#25143;&#34920;&#31034;&#25490;&#26021;&#30340;&#26032;&#22411;&#22810;&#22612;&#22810;&#20852;&#36259;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22810;&#20852;&#36259;&#23398;&#20064;&#26041;&#27861;&#38754;&#20020;&#30340;&#35757;&#32451;&#21644;&#37096;&#32626;&#30446;&#26631;&#24046;&#24322;&#12289;&#26080;&#27861;&#35775;&#38382;&#21830;&#21697;&#20449;&#24687;&#20197;&#21450;&#38590;&#20197;&#24037;&#19994;&#37319;&#29992;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#36807;&#36733;&#30340;&#26102;&#20195;&#65292;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#37117;&#28145;&#21051;&#35748;&#35782;&#21040;&#25512;&#33616;&#31995;&#32479;&#30340;&#20215;&#20540;&#12290;&#29305;&#21035;&#26159;&#22810;&#20852;&#36259;&#24207;&#21015;&#25512;&#33616;&#26159;&#36817;&#24180;&#26469;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#20851;&#27880;&#30340;&#19968;&#20010;&#23376;&#39046;&#22495;&#12290;&#36890;&#36807;&#29983;&#25104;&#22810;&#29992;&#25143;&#34920;&#31034;&#65292;&#22810;&#20852;&#36259;&#23398;&#20064;&#27169;&#22411;&#22312;&#29702;&#35770;&#19978;&#21644;&#32463;&#39564;&#19978;&#37117;&#27604;&#21333;&#29992;&#25143;&#34920;&#31034;&#27169;&#22411;&#20855;&#26377;&#26356;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23613;&#31649;&#35813;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20294;&#20173;&#23384;&#22312;&#19977;&#20010;&#20027;&#35201;&#38382;&#39064;&#22256;&#25200;&#30528;&#22810;&#20852;&#36259;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#21644;&#21487;&#37319;&#29992;&#24615;&#65292;&#21363;&#35757;&#32451;&#21644;&#37096;&#32626;&#30446;&#26631;&#20043;&#38388;&#30340;&#24046;&#24322;&#12289;&#26080;&#27861;&#35775;&#38382;&#21830;&#21697;&#20449;&#24687;&#20197;&#21450;&#30001;&#20110;&#20854;&#21333;&#22612;&#26550;&#26500;&#32780;&#38590;&#20197;&#24037;&#19994;&#37319;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#20855;&#26377;&#29992;&#25143;&#34920;&#31034;&#25490;&#26021;&#30340;&#26032;&#22411;&#22810;&#22612;&#22810;&#20852;&#36259;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#36890;&#36807;&#36328;&#22810;&#20010;&#22823;&#35268;&#27169;&#23454;&#39564;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05122v1 Announce Type: cross  Abstract: In the era of information overload, the value of recommender systems has been profoundly recognized in academia and industry alike. Multi-interest sequential recommendation, in particular, is a subfield that has been receiving increasing attention in recent years. By generating multiple-user representations, multi-interest learning models demonstrate superior expressiveness than single-user representation models, both theoretically and empirically. Despite major advancements in the field, three major issues continue to plague the performance and adoptability of multi-interest learning methods, the difference between training and deployment objectives, the inability to access item information, and the difficulty of industrial adoption due to its single-tower architecture. We address these challenges by proposing a novel multi-tower multi-interest framework with user representation repel. Experimental results across multiple large-scale 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#21644;&#24378;&#21270;&#23398;&#20064;&#23545;&#40784;&#31243;&#24207;&#65292;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#25512;&#33616;&#25351;&#20196;&#21644;&#20943;&#23569;&#26684;&#24335;&#38169;&#35823;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.05063</link><description>&lt;p&gt;
&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#23454;&#29616;&#21487;&#25511;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Aligning Large Language Models for Controllable Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05063
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#21644;&#24378;&#21270;&#23398;&#20064;&#23545;&#40784;&#31243;&#24207;&#65292;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#25512;&#33616;&#25351;&#20196;&#21644;&#20943;&#23569;&#26684;&#24335;&#38169;&#35823;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24322;&#24120;&#30340;&#26234;&#33021;&#21551;&#21457;&#65292;&#30740;&#31350;&#20154;&#21592;&#24050;&#24320;&#22987;&#25506;&#32034;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#24320;&#21019;&#19979;&#19968;&#20195;&#25512;&#33616;&#31995;&#32479; - &#36825;&#20123;&#31995;&#32479;&#20855;&#26377;&#23545;&#35805;&#12289;&#21487;&#35299;&#37322;&#21644;&#21487;&#25511;&#30340;&#29305;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#25991;&#29486;&#20027;&#35201;&#38598;&#20013;&#22312;&#23558;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#25972;&#21512;&#21040;LLMs&#20013;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#36890;&#24120;&#24573;&#30053;&#20102;&#36981;&#24490;&#25351;&#20196;&#30340;&#33021;&#21147;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#19968;&#32452;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#65292;&#26631;&#35760;&#26469;&#28304;&#20110;&#20256;&#32479;&#25512;&#33616;&#27169;&#22411;&#30340;&#26631;&#31614;&#65292;&#26088;&#22312;&#26126;&#30830;&#25913;&#21892;LLMs&#36981;&#24490;&#29305;&#23450;&#25512;&#33616;&#25351;&#20196;&#30340;&#29087;&#32451;&#31243;&#24230;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#23545;&#40784;&#31243;&#24207;&#65292;&#36827;&#19968;&#27493;&#21152;&#24378;&#20102;LLMs&#22312;&#21709;&#24212;&#29992;&#25143;&#24847;&#22270;&#21644;&#20943;&#23569;&#26684;&#24335;&#38169;&#35823;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26631;&#35760;&#30528;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05063v1 Announce Type: cross  Abstract: Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems - systems that are conversational, explainable, and controllable. However, existing literature primarily concentrates on integrating domain-specific knowledge into LLMs to enhance accuracy, often neglecting the ability to follow instructions. To address this gap, we initially introduce a collection of supervised learning tasks, augmented with labels derived from a conventional recommender model, aimed at explicitly improving LLMs' proficiency in adhering to recommendation-specific instructions. Subsequently, we develop a reinforcement learning-based alignment procedure to further strengthen LLMs' aptitude in responding to users' intentions and mitigating formatting errors. Through extensive experiments on two real-world datasets, our method markedl
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;R&amp;R&#26041;&#27861;&#65292;&#32467;&#21512;reprompting&#21644;in-context retrieval&#20004;&#31181;&#26032;&#22411;&#25552;&#31034;&#26041;&#24335;&#65292;&#25552;&#39640;&#20102;&#22312;&#38271;&#25991;&#26723;&#19978;&#30340;&#38382;&#31572;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.05004</link><description>&lt;p&gt;
&#26080;&#27861;&#35760;&#20303;&#38271;&#25991;&#26723;&#20013;&#30340;&#32454;&#33410;&#65311;&#24744;&#38656;&#35201;&#19968;&#20123;R&amp;R
&lt;/p&gt;
&lt;p&gt;
Can't Remember Details in Long Documents? You Need Some R&amp;R
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05004
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;R&amp;R&#26041;&#27861;&#65292;&#32467;&#21512;reprompting&#21644;in-context retrieval&#20004;&#31181;&#26032;&#22411;&#25552;&#31034;&#26041;&#24335;&#65292;&#25552;&#39640;&#20102;&#22312;&#38271;&#25991;&#26723;&#19978;&#30340;&#38382;&#31572;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#19978;&#19979;&#25991;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35832;&#22914;&#38271;&#31687;&#25991;&#26723;&#19978;&#30340;&#38382;&#31572;&#65288;QA&#65289;&#31561;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#20250;&#38169;&#36807;&#19978;&#19979;&#25991;&#25991;&#26723;&#20013;&#38388;&#30340;&#37325;&#35201;&#20449;&#24687;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;$\textit{R&amp;R}$&#30340;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#20004;&#31181;&#26032;&#22411;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;$\textit{reprompting}$&#21644;$\textit{in-context retrieval}$&#65288;ICR&#65289;&#65292;&#20197;&#20943;&#36731;&#25991;&#26723;&#22411;QA&#20013;&#30340;&#36825;&#31181;&#24433;&#21709;&#12290;&#22312;$\textit{reprompting}$&#20013;&#65292;&#25105;&#20204;&#21608;&#26399;&#24615;&#22320;&#22312;&#25972;&#20010;&#19978;&#19979;&#25991;&#25991;&#26723;&#20013;&#37325;&#22797;&#25552;&#31034;&#35828;&#26126;&#65292;&#20197;&#25552;&#37266;LLM&#20854;&#21407;&#22987;&#20219;&#21153;&#12290;&#22312;ICR&#20013;&#65292;&#25105;&#20204;&#24182;&#19981;&#25351;&#31034;LLM&#30452;&#25509;&#22238;&#31572;&#38382;&#39064;&#65292;&#32780;&#26159;&#25351;&#31034;&#23427;&#26816;&#32034;&#19982;&#32473;&#23450;&#38382;&#39064;&#26368;&#30456;&#20851;&#30340;&#21069;$k$&#20010;&#27573;&#33853;&#32534;&#21495;&#65292;&#28982;&#21518;&#23558;&#20854;&#29992;&#20316;&#31532;&#20108;&#20010;QA&#25552;&#31034;&#20013;&#30340;&#32553;&#30053;&#19978;&#19979;&#25991;&#12290;&#25105;&#20204;&#20351;&#29992;GPT-4 Turbo&#21644;Claude-2.1&#22312;&#38271;&#24230;&#36798;&#21040;80k&#26631;&#35760;&#30340;&#25991;&#26723;&#19978;&#27979;&#35797;&#20102;R&amp;R&#65292;&#24182;&#24179;&#22343;&#35266;&#23519;&#21040;QA&#20934;&#30830;&#29575;&#25552;&#21319;&#20102;16&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05004v1 Announce Type: cross  Abstract: Long-context large language models (LLMs) hold promise for tasks such as question-answering (QA) over long documents, but they tend to miss important information in the middle of context documents (arXiv:2307.03172v3). Here, we introduce $\textit{R&amp;R}$ -- a combination of two novel prompt-based methods called $\textit{reprompting}$ and $\textit{in-context retrieval}$ (ICR) -- to alleviate this effect in document-based QA. In reprompting, we repeat the prompt instructions periodically throughout the context document to remind the LLM of its original task. In ICR, rather than instructing the LLM to answer the question directly, we instruct it to retrieve the top $k$ passage numbers most relevant to the given question, which are then used as an abbreviated context in a second QA prompt. We test R&amp;R with GPT-4 Turbo and Claude-2.1 on documents up to 80k tokens in length and observe a 16-point boost in QA accuracy on average. Our further an
&lt;/p&gt;</description></item><item><title>GPTRec&#27169;&#22411;&#20351;&#29992;Next-K&#31574;&#30053;&#26469;&#29983;&#25104;&#25512;&#33616;&#65292;&#19982;&#20256;&#32479;&#30340;Top-K&#27169;&#22411;&#19981;&#21516;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#32771;&#34385;&#36229;&#20986;&#20934;&#30830;&#24615;&#25351;&#26631;&#30340;&#22797;&#26434;&#39033;&#30446;&#38388;&#30456;&#20114;&#20381;&#36182;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04875</link><description>&lt;p&gt;
&#29992;&#24378;&#21270;&#23398;&#20064;&#23558;GPTRec&#19982;&#36229;&#20986;&#20934;&#30830;&#24615;&#30446;&#26631;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Aligning GPTRec with Beyond-Accuracy Goals with Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04875
&lt;/p&gt;
&lt;p&gt;
GPTRec&#27169;&#22411;&#20351;&#29992;Next-K&#31574;&#30053;&#26469;&#29983;&#25104;&#25512;&#33616;&#65292;&#19982;&#20256;&#32479;&#30340;Top-K&#27169;&#22411;&#19981;&#21516;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#32771;&#34385;&#36229;&#20986;&#20934;&#30830;&#24615;&#25351;&#26631;&#30340;&#22797;&#26434;&#39033;&#30446;&#38388;&#30456;&#20114;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#27169;&#22411;&#30340;&#25913;&#32534;&#65292;&#22914;BERT4Rec&#21644;SASRec&#65292;&#22312;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102; accuracy-based &#25351;&#26631;&#65292;&#22914;NDCG&#26041;&#38754;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;&#36825;&#20123;&#27169;&#22411;&#23558;&#39033;&#30446;&#35270;&#20026;&#26631;&#35760;&#65292;&#28982;&#21518;&#21033;&#29992;&#35780;&#20998;-&#25490;&#21517;&#26041;&#27861;&#65288;Top-K&#31574;&#30053;&#65289;&#65292;&#20854;&#20013;&#27169;&#22411;&#39318;&#20808;&#35745;&#31639;&#39033;&#30446;&#24471;&#20998;&#65292;&#28982;&#21518;&#26681;&#25454;&#27492;&#20998;&#25968;&#23545;&#20854;&#36827;&#34892;&#25490;&#21517;&#12290;&#34429;&#28982;&#35813;&#26041;&#27861;&#23545;&#20110;&#20934;&#30830;&#24615;&#25351;&#26631;&#25928;&#26524;&#24456;&#22909;&#65292;&#20294;&#24456;&#38590;&#23558;&#20854;&#29992;&#20110;&#20248;&#21270;&#26356;&#22797;&#26434;&#30340;&#36229;&#20986;&#20934;&#30830;&#24615;&#25351;&#26631;&#65292;&#22914;&#22810;&#26679;&#24615;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#19981;&#21516; Next-K &#31574;&#30053;&#30340;GPTRec&#27169;&#22411;&#65292;&#20316;&#20026;Top-K&#27169;&#22411;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#19982;&#20256;&#32479;&#30340;Top-K&#25512;&#33616;&#30456;&#27604;&#65292;Next-K&#20250;&#36880;&#20010;&#39033;&#30446;&#29983;&#25104;&#25512;&#33616;&#65292;&#22240;&#27492;&#65292;&#21487;&#20197;&#32771;&#34385;&#36229;&#20986;&#20934;&#30830;&#24615;&#25351;&#26631;&#20013;&#37325;&#35201;&#30340;&#22797;&#26434;&#39033;&#30446;&#38388;&#30456;&#20114;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04875v1 Announce Type: cross  Abstract: Adaptations of Transformer models, such as BERT4Rec and SASRec, achieve state-of-the-art performance in the sequential recommendation task according to accuracy-based metrics, such as NDCG. These models treat items as tokens and then utilise a score-and-rank approach (Top-K strategy), where the model first computes item scores and then ranks them according to this score. While this approach works well for accuracy-based metrics, it is hard to use it for optimising more complex beyond-accuracy metrics such as diversity. Recently, the GPTRec model, which uses a different Next-K strategy, has been proposed as an alternative to the Top-K models. In contrast with traditional Top-K recommendations, Next-K generates recommendations item-by-item and, therefore, can account for complex item-to-item interdependencies important for the beyond-accuracy measures. However, the original GPTRec paper focused only on accuracy in experiments and needed 
&lt;/p&gt;</description></item><item><title>ACORN&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#24615;&#33021;&#21644;&#19982;&#35859;&#35789;&#26080;&#20851;&#30340;&#28151;&#21512;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#35859;&#35789;&#23376;&#22270;&#36941;&#21382;&#26469;&#27169;&#25311;&#29702;&#35770;&#19978;&#29702;&#24819;&#20294;&#23454;&#38469;&#19978;&#19981;&#20999;&#23454;&#38469;&#30340;&#28151;&#21512;&#25628;&#32034;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.04871</link><description>&lt;p&gt;
ACORN&#65306;&#39640;&#24615;&#33021;&#21644;&#35859;&#35789;&#26080;&#20851;&#30340;&#30690;&#37327;&#23884;&#20837;&#21644;&#32467;&#26500;&#21270;&#25968;&#25454;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
ACORN: Performant and Predicate-Agnostic Search Over Vector Embeddings and Structured Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04871
&lt;/p&gt;
&lt;p&gt;
ACORN&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#24615;&#33021;&#21644;&#19982;&#35859;&#35789;&#26080;&#20851;&#30340;&#28151;&#21512;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#35859;&#35789;&#23376;&#22270;&#36941;&#21382;&#26469;&#27169;&#25311;&#29702;&#35770;&#19978;&#29702;&#24819;&#20294;&#23454;&#38469;&#19978;&#19981;&#20999;&#23454;&#38469;&#30340;&#28151;&#21512;&#25628;&#32034;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24212;&#29992;&#31243;&#24207;&#36234;&#26469;&#36234;&#22810;&#22320;&#21033;&#29992;&#28151;&#21512;&#27169;&#24577;&#25968;&#25454;&#65292;&#24182;&#19988;&#24517;&#39035;&#32852;&#21512;&#25628;&#32034;&#30690;&#37327;&#25968;&#25454;&#65292;&#22914;&#23884;&#20837;&#22270;&#20687;&#12289;&#25991;&#26412;&#21644;&#35270;&#39057;&#65292;&#20197;&#21450;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#22914;&#23646;&#24615;&#21644;&#20851;&#38190;&#35789;&#12290;&#38024;&#23545;&#36825;&#31181;&#28151;&#21512;&#25628;&#32034;&#29615;&#22659;&#30340;&#25552;&#20986;&#30340;&#26041;&#27861;&#35201;&#20040;&#24615;&#33021;&#19981;&#20339;&#65292;&#35201;&#20040;&#25903;&#25345;&#19968;&#32452;&#38750;&#24120;&#21463;&#38480;&#21046;&#30340;&#25628;&#32034;&#35859;&#35789;&#65288;&#20363;&#22914;&#65292;&#20165;&#25903;&#25345;&#23567;&#30340;&#30456;&#31561;&#35859;&#35789;&#38598;&#65289;&#65292;&#20351;&#20854;&#23545;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#26469;&#35828;&#19981;&#20999;&#23454;&#38469;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ACORN&#65292;&#19968;&#31181;&#39640;&#24615;&#33021;&#19988;&#19982;&#35859;&#35789;&#26080;&#20851;&#30340;&#28151;&#21512;&#25628;&#32034;&#26041;&#27861;&#12290;ACORN&#22522;&#20110;Hierarchical Navigable Small Worlds&#65288;HNSW&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#22270;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#32034;&#24341;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#25193;&#23637;&#29616;&#26377;&#30340;HNSW&#24211;&#26377;&#25928;&#23454;&#29616;&#12290;ACORN&#24341;&#20837;&#20102;&#35859;&#35789;&#23376;&#22270;&#36941;&#21382;&#30340;&#27010;&#24565;&#65292;&#20197;&#27169;&#25311;&#19968;&#31181;&#22312;&#29702;&#35770;&#19978;&#29702;&#24819;&#20294;&#22312;&#23454;&#36341;&#20013;&#19981;&#20999;&#23454;&#38469;&#30340;&#28151;&#21512;&#25628;&#32034;&#31574;&#30053;&#12290;ACORN&#30340;&#35859;&#35789;&#26080;&#20851;&#26500;&#36896;&#31639;&#27861;&#26088;&#22312;&#23454;&#29616;&#36825;&#31181;&#26377;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04871v1 Announce Type: new  Abstract: Applications increasingly leverage mixed-modality data, and must jointly search over vector data, such as embedded images, text and video, as well as structured data, such as attributes and keywords. Proposed methods for this hybrid search setting either suffer from poor performance or support a severely restricted set of search predicates (e.g., only small sets of equality predicates), making them impractical for many applications. To address this, we present ACORN, an approach for performant and predicate-agnostic hybrid search. ACORN builds on Hierarchical Navigable Small Worlds (HNSW), a state-of-the-art graph-based approximate nearest neighbor index, and can be implemented efficiently by extending existing HNSW libraries. ACORN introduces the idea of predicate subgraph traversal to emulate a theoretically ideal, but impractical, hybrid search strategy. ACORN's predicate-agnostic construction algorithm is designed to enable this effe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#21160;&#31995;&#32479;&#65292;&#32467;&#21512;&#20102;BERT&#23884;&#20837;&#21644;HDBSCAN&#32858;&#31867;&#65292;&#21487;&#20197;&#20174;&#21322;&#32467;&#26500;&#21270;&#38754;&#35848;&#25991;&#26412;&#20013;&#24555;&#36895;&#25552;&#21462;&#20449;&#24687;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20010;&#20415;&#25463;&#30340;&#24037;&#20855;&#26469;&#20998;&#26512;&#21644;&#21487;&#35270;&#21270;&#20027;&#39064;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2403.04819</link><description>&lt;p&gt;
&#20174;&#21322;&#32467;&#26500;&#21270;&#38754;&#35848;&#25991;&#26412;&#20013;&#33258;&#21160;&#25552;&#21462;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Automating the Information Extraction from Semi-Structured Interview Transcripts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#21160;&#31995;&#32479;&#65292;&#32467;&#21512;&#20102;BERT&#23884;&#20837;&#21644;HDBSCAN&#32858;&#31867;&#65292;&#21487;&#20197;&#20174;&#21322;&#32467;&#26500;&#21270;&#38754;&#35848;&#25991;&#26412;&#20013;&#24555;&#36895;&#25552;&#21462;&#20449;&#24687;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20010;&#20415;&#25463;&#30340;&#24037;&#20855;&#26469;&#20998;&#26512;&#21644;&#21487;&#35270;&#21270;&#20027;&#39064;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#24320;&#21457;&#21644;&#24212;&#29992;&#19968;&#31181;&#33258;&#21160;&#31995;&#32479;&#65292;&#26088;&#22312;&#20174;&#21322;&#32467;&#26500;&#21270;&#38754;&#35848;&#25991;&#26412;&#20013;&#25552;&#21462;&#20449;&#24687;&#12290;&#30001;&#20110;&#20256;&#32479;&#30340;&#23450;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#22914;&#32534;&#30721;&#65292;&#21171;&#21160;&#23494;&#38598;&#22411;&#30340;&#26412;&#36136;&#65292;&#23545;&#21487;&#20197;&#20419;&#36827;&#20998;&#26512;&#36807;&#31243;&#30340;&#24037;&#20855;&#23384;&#22312;&#30528;&#37325;&#22823;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#21508;&#31181;&#20027;&#39064;&#24314;&#27169;&#25216;&#26415;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65292;&#36866;&#29992;&#20110;&#20998;&#26512;&#38754;&#35848;&#25991;&#26412;&#30340;&#26368;&#20339;&#27169;&#22411;&#26159;BERT&#23884;&#20837;&#21644;HDBSCAN&#32858;&#31867;&#30340;&#32467;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#36719;&#20214;&#21407;&#22411;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#65292;&#21253;&#25324;&#37027;&#20123;&#27809;&#26377;&#32534;&#31243;&#25216;&#33021;&#30340;&#20154;&#65292;&#33021;&#22815;&#39640;&#25928;&#22788;&#29702;&#21644;&#21487;&#35270;&#21270;&#38754;&#35848;&#25968;&#25454;&#30340;&#20027;&#39064;&#32467;&#26500;&#12290;&#35813;&#24037;&#20855;&#19981;&#20165;&#20419;&#36827;&#20102;&#23450;&#24615;&#20998;&#26512;&#30340;&#21021;&#26399;&#38454;&#27573;&#65292;&#36824;&#20026;&#25581;&#31034;&#30340;&#20027;&#39064;&#20043;&#38388;&#30340;&#30456;&#20114;&#32852;&#31995;&#25552;&#20379;&#20102;&#35265;&#35299;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#23450;&#24615;&#20998;&#26512;&#30340;&#28145;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04819v1 Announce Type: new  Abstract: This paper explores the development and application of an automated system designed to extract information from semi-structured interview transcripts. Given the labor-intensive nature of traditional qualitative analysis methods, such as coding, there exists a significant demand for tools that can facilitate the analysis process. Our research investigates various topic modeling techniques and concludes that the best model for analyzing interview texts is a combination of BERT embeddings and HDBSCAN clustering. We present a user-friendly software prototype that enables researchers, including those without programming skills, to efficiently process and visualize the thematic structure of interview data. This tool not only facilitates the initial stages of qualitative analysis but also offers insights into the interconnectedness of topics revealed, thereby enhancing the depth of qualitative analysis.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23545;&#27604;&#20256;&#32479;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#20174;&#22823;&#22411;&#33521;&#22269;&#27861;&#38498;&#21028;&#20915;&#25968;&#25454;&#38598;&#20013;&#35782;&#21035;&#25688;&#35201;&#35009;&#23450;&#26696;&#20363;&#65292;&#21462;&#24471;&#20102;&#26356;&#39640;&#30340;F1&#24471;&#20998;&#12290;</title><link>https://arxiv.org/abs/2403.04791</link><description>&lt;p&gt;
LLM&#23545;&#25239;&#24459;&#24072;&#65306;&#22312;&#22823;&#22411;&#33521;&#22269;&#26696;&#20363;&#27861;&#24459;&#25968;&#25454;&#38598;&#20013;&#35782;&#21035;&#25688;&#35201;&#35009;&#23450;&#30340;&#23376;&#38598;
&lt;/p&gt;
&lt;p&gt;
LLM vs. Lawyers: Identifying a Subset of Summary Judgments in a Large UK Case Law Dataset
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04791
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23545;&#27604;&#20256;&#32479;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#20174;&#22823;&#22411;&#33521;&#22269;&#27861;&#38498;&#21028;&#20915;&#25968;&#25454;&#38598;&#20013;&#35782;&#21035;&#25688;&#35201;&#35009;&#23450;&#26696;&#20363;&#65292;&#21462;&#24471;&#20102;&#26356;&#39640;&#30340;F1&#24471;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36827;&#34892;&#27861;&#24459;&#39046;&#22495;&#30340;&#35745;&#31639;&#30740;&#31350;&#65292;&#39640;&#25928;&#22320;&#35782;&#21035;&#19982;&#29305;&#23450;&#27861;&#24459;&#38382;&#39064;&#30456;&#20851;&#30340;&#27861;&#38498;&#35009;&#20915;&#25968;&#25454;&#38598;&#26159;&#19968;&#39033;&#33267;&#20851;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#21162;&#21147;&#12290;&#26412;&#30740;&#31350;&#22635;&#34917;&#20102;&#25991;&#29486;&#20013;&#20851;&#20110;&#22914;&#20309;&#20174;&#22823;&#37327;&#33521;&#22269;&#27861;&#38498;&#20915;&#23450;&#30340;&#25991;&#38598;&#20013;&#38548;&#31163;&#26696;&#20363;&#65288;&#22312;&#25105;&#20204;&#30340;&#26696;&#20363;&#20013;&#26159;&#25688;&#35201;&#35009;&#23450;&#65289;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#31181;&#35745;&#31639;&#26041;&#27861;&#30340;&#27604;&#36739;&#20998;&#26512;&#65306;&#65288;1&#65289;&#20256;&#32479;&#30340;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#19987;&#23478;&#29983;&#25104;&#30340;&#20851;&#38190;&#23383;&#21644;&#36923;&#36753;&#36816;&#31639;&#31526;&#65292;&#20197;&#21450;&#65288;2&#65289;&#21019;&#26032;&#24615;&#22320;&#23558;Claude 2&#22823;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20110;&#22522;&#20110;&#29305;&#23450;&#20869;&#23481;&#25552;&#31034;&#20998;&#31867;&#26696;&#20363;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#21253;&#21547;356,011&#20221;&#33521;&#22269;&#27861;&#38498;&#21028;&#20915;&#30340;&#21073;&#26725;&#27861;&#23398;&#25991;&#38598;&#65292;&#24182;&#30830;&#23450;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21152;&#26435;F1&#24471;&#20998;&#20026;0.94&#65292;&#32780;&#20851;&#38190;&#23383;&#30340;&#24471;&#20998;&#20026;0.78&#12290;&#23613;&#31649;&#32463;&#36807;&#36845;&#20195;&#25913;&#36827;&#65292;&#22522;&#20110;&#20851;&#38190;&#23383;&#30340;&#25628;&#32034;&#36923;&#36753;&#26410;&#33021;&#25429;&#25417;&#27861;&#24459;&#35821;&#35328;&#20013;&#30340;&#32454;&#24494;&#24046;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04791v1 Announce Type: new  Abstract: To undertake computational research of the law, efficiently identifying datasets of court decisions that relate to a specific legal issue is a crucial yet challenging endeavour. This study addresses the gap in the literature working with large legal corpora about how to isolate cases, in our case summary judgments, from a large corpus of UK court decisions. We introduce a comparative analysis of two computational methods: (1) a traditional natural language processing-based approach leveraging expert-generated keywords and logical operators and (2) an innovative application of the Claude 2 large language model to classify cases based on content-specific prompts. We use the Cambridge Law Corpus of 356,011 UK court decisions and determine that the large language model achieves a weighted F1 score of 0.94 versus 0.78 for keywords. Despite iterative refinement, the search logic based on keywords fails to capture nuances in legal language. We 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#26512;&#20102;&#25512;&#33616;&#31639;&#27861;&#23545;&#29992;&#25143;&#34892;&#20026;&#30340;&#38271;&#26399;&#24433;&#21709;&#65292;&#25506;&#35752;&#20102;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#33021;&#22815;&#32531;&#35299;&#28388;&#27873;&#25928;&#24212;&#12290;</title><link>https://arxiv.org/abs/2402.15013</link><description>&lt;p&gt;
&#25512;&#33616;&#31639;&#27861;&#23545;&#29992;&#25143;&#28040;&#36153;&#27169;&#24335;&#38271;&#26399;&#24433;&#21709;&#30340;&#35299;&#26512;: &#28388;&#27873;&#36824;&#26159;&#21516;&#36136;&#21270;&#65311;
&lt;/p&gt;
&lt;p&gt;
Filter Bubble or Homogenization? Disentangling the Long-Term Effects of Recommendations on User Consumption Patterns
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#26512;&#20102;&#25512;&#33616;&#31639;&#27861;&#23545;&#29992;&#25143;&#34892;&#20026;&#30340;&#38271;&#26399;&#24433;&#21709;&#65292;&#25506;&#35752;&#20102;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#33021;&#22815;&#32531;&#35299;&#28388;&#27873;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31639;&#27861;&#22312;&#22609;&#36896;&#25105;&#20204;&#30340;&#23186;&#20307;&#36873;&#25321;&#26041;&#38754;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#22240;&#27492;&#20102;&#35299;&#23427;&#20204;&#23545;&#29992;&#25143;&#34892;&#20026;&#30340;&#38271;&#26399;&#24433;&#21709;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#19982;&#20004;&#20010;&#20851;&#38190;&#32467;&#26524;&#30456;&#20851;&#32852;&#65306;&#21516;&#36136;&#21270;&#65292;&#21363;&#20351;&#29992;&#25143;&#20855;&#26377;&#19981;&#21516;&#30340;&#22522;&#26412;&#20559;&#22909;&#65292;&#20063;&#20250;&#28040;&#36153;&#30456;&#20284;&#30340;&#20869;&#23481;&#65292;&#20197;&#21450;&#28388;&#27873;&#25928;&#24212;&#65292;&#21363;&#20855;&#26377;&#19981;&#21516;&#20559;&#22909;&#30340;&#20010;&#20154;&#20165;&#28040;&#36153;&#19982;&#20854;&#20559;&#22909;&#19968;&#33268;&#30340;&#20869;&#23481;&#65288;&#19982;&#20854;&#20182;&#29992;&#25143;&#20960;&#20046;&#27809;&#26377;&#37325;&#21472;&#65289;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20551;&#35774;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#65292;&#24182;&#23637;&#31034;&#20010;&#24615;&#21270;&#25512;&#33616;&#36890;&#36807;&#20419;&#36827;&#21516;&#36136;&#21270;&#26469;&#32531;&#35299;&#28388;&#27873;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#19968;&#23545;&#36825;&#20004;&#31181;&#25928;&#24212;&#20043;&#38388;&#30340;&#26435;&#34913;&#30340;&#20551;&#35774;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#26080;&#27861;&#21457;&#23637;&#20986;&#19968;&#31181;&#26356;&#20026;&#32454;&#33268;&#30340;&#30475;&#27861;&#65292;&#21363;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#22914;&#20309;&#29420;&#31435;&#24433;&#21709;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#12290;&#25105;&#20204;&#23545;&#21516;&#36136;&#21270;&#21644;&#28388;&#27873;&#25928;&#24212;&#36827;&#34892;&#20102;&#26356;&#31934;&#32454;&#30340;&#23450;&#20041;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15013v1 Announce Type: cross  Abstract: Recommendation algorithms play a pivotal role in shaping our media choices, which makes it crucial to comprehend their long-term impact on user behavior. These algorithms are often linked to two critical outcomes: homogenization, wherein users consume similar content despite disparate underlying preferences, and the filter bubble effect, wherein individuals with differing preferences only consume content aligned with their preferences (without much overlap with other users). Prior research assumes a trade-off between homogenization and filter bubble effects and then shows that personalized recommendations mitigate filter bubbles by fostering homogenization. However, because of this assumption of a tradeoff between these two effects, prior work cannot develop a more nuanced view of how recommendation systems may independently impact homogenization and filter bubble effects. We develop a more refined definition of homogenization and the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#22312;&#32593;&#32476;&#20013;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#65292;&#21457;&#29616;PageRank&#33021;&#22815;&#24179;&#34913;&#25490;&#21517;&#20013;&#23569;&#25968;&#32676;&#20307;&#30340;&#20195;&#34920;&#24615;&#65292;&#32780;HITS&#21017;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2402.13787</link><description>&lt;p&gt;
&#20174;&#25490;&#21517;&#20013;&#23835;&#36215;&#30340;&#20844;&#24179;&#24615;&#65306;HITS&#21644;PageRank&#22312;&#21516;&#36136;&#32593;&#32476;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#22312;&#32593;&#32476;&#20013;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#65292;&#21457;&#29616;PageRank&#33021;&#22815;&#24179;&#34913;&#25490;&#21517;&#20013;&#23569;&#25968;&#32676;&#20307;&#30340;&#20195;&#34920;&#24615;&#65292;&#32780;HITS&#21017;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20351;&#29992;&#20013;&#24515;&#24615;&#24230;&#37327;&#26631;&#20934;&#30340;&#26368;&#24120;&#35265;&#38142;&#25509;&#31639;&#27861;&#65292;&#22914;PageRank&#21644;HITS&#65292;&#22312;&#32593;&#32476;&#20013;&#21487;&#33021;&#20877;&#29616;&#29978;&#33267;&#25918;&#22823;&#23545;&#23569;&#25968;&#32676;&#20307;&#30340;&#20559;&#35265;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#34892;&#20026;&#26377;&#25152;&#19981;&#21516;&#65306;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#20973;&#32463;&#39564;&#35777;&#26126;&#65292;PageRank&#22312;&#22823;&#37096;&#20998;&#25490;&#21517;&#20301;&#32622;&#19978;&#21453;&#26144;&#20102;&#24230;&#20998;&#24067;&#65292;&#24182;&#19988;&#21487;&#20197;&#24179;&#34913;&#23569;&#25968;&#32676;&#20307;&#22312;&#25490;&#21517;&#38752;&#21069;&#30340;&#33410;&#28857;&#20013;&#30340;&#20195;&#34920;&#24615;&#65307;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#21457;&#29616;HITS&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#65292;&#25903;&#25745;&#35777;&#25454;&#20026;&#23454;&#35777;&#32467;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;HITS&#20013;&#20559;&#35265;&#25918;&#22823;&#30340;&#26681;&#26412;&#21407;&#22240;&#26159;&#32593;&#32476;&#20013;&#23384;&#22312;&#30340;&#21516;&#36136;&#24615;&#27700;&#24179;&#65292;&#36890;&#36807;&#19968;&#20010;&#20855;&#26377;&#20004;&#20010;&#31038;&#21306;&#30340;&#19981;&#26029;&#21457;&#23637;&#30340;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#20197;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#38416;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13787v1 Announce Type: cross  Abstract: In this paper, we investigate the conditions under which link analysis algorithms prevent minority groups from reaching high ranking slots. We find that the most common link-based algorithms using centrality metrics, such as PageRank and HITS, can reproduce and even amplify bias against minority groups in networks. Yet, their behavior differs: one one hand, we empirically show that PageRank mirrors the degree distribution for most of the ranking positions and it can equalize representation of minorities among the top ranked nodes; on the other hand, we find that HITS amplifies pre-existing bias in homophilic networks through a novel theoretical analysis, supported by empirical results. We find the root cause of bias amplification in HITS to be the level of homophily present in the network, modeled through an evolving network model with two communities. We illustrate our theoretical analysis on both synthetic and real datasets and we pr
&lt;/p&gt;</description></item><item><title>SupplyGraph&#26159;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20379;&#24212;&#38142;&#35268;&#21010;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#26469;&#33258;&#23391;&#21152;&#25289;&#22269;&#19968;&#23478;&#39046;&#20808;&#24555;&#36895;&#28040;&#36153;&#21697;&#20844;&#21496;&#30340;&#23454;&#38469;&#25968;&#25454;&#65292;&#29992;&#20110;&#20248;&#21270;&#12289;&#39044;&#27979;&#21644;&#35299;&#20915;&#20379;&#24212;&#38142;&#38382;&#39064;&#12290;&#25968;&#25454;&#38598;&#20013;&#30340;&#26102;&#38388;&#25968;&#25454;&#20316;&#20026;&#33410;&#28857;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#38144;&#21806;&#39044;&#27979;&#12289;&#29983;&#20135;&#35745;&#21010;&#21644;&#25925;&#38556;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2401.15299</link><description>&lt;p&gt;
SupplyGraph: &#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20379;&#24212;&#38142;&#35268;&#21010;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
SupplyGraph: A Benchmark Dataset for Supply Chain Planning using Graph Neural Networks. (arXiv:2401.15299v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15299
&lt;/p&gt;
&lt;p&gt;
SupplyGraph&#26159;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20379;&#24212;&#38142;&#35268;&#21010;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#26469;&#33258;&#23391;&#21152;&#25289;&#22269;&#19968;&#23478;&#39046;&#20808;&#24555;&#36895;&#28040;&#36153;&#21697;&#20844;&#21496;&#30340;&#23454;&#38469;&#25968;&#25454;&#65292;&#29992;&#20110;&#20248;&#21270;&#12289;&#39044;&#27979;&#21644;&#35299;&#20915;&#20379;&#24212;&#38142;&#38382;&#39064;&#12290;&#25968;&#25454;&#38598;&#20013;&#30340;&#26102;&#38388;&#25968;&#25454;&#20316;&#20026;&#33410;&#28857;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#38144;&#21806;&#39044;&#27979;&#12289;&#29983;&#20135;&#35745;&#21010;&#21644;&#25925;&#38556;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#19981;&#21516;&#39046;&#22495;&#22914;&#36816;&#36755;&#12289;&#29983;&#29289;&#20449;&#24687;&#23398;&#12289;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#22312;&#23558;GNNs&#24212;&#29992;&#20110;&#20379;&#24212;&#38142;&#32593;&#32476;&#26041;&#38754;&#65292;&#30446;&#21069;&#23578;&#32570;&#20047;&#30740;&#31350;&#12290;&#20379;&#24212;&#38142;&#32593;&#32476;&#22312;&#32467;&#26500;&#19978;&#31867;&#20284;&#20110;&#22270;&#24418;&#65292;&#20351;&#20854;&#25104;&#20026;&#24212;&#29992;GNN&#26041;&#27861;&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;&#36825;&#20026;&#20248;&#21270;&#12289;&#39044;&#27979;&#21644;&#35299;&#20915;&#20379;&#24212;&#38142;&#38382;&#39064;&#24320;&#36767;&#20102;&#26080;&#38480;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#27492;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#38556;&#30861;&#22312;&#20110;&#32570;&#20047;&#30495;&#23454;&#19990;&#30028;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#20197;&#20419;&#36827;&#20351;&#29992;GNN&#26469;&#30740;&#31350;&#21644;&#35299;&#20915;&#20379;&#24212;&#38142;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26469;&#33258;&#23391;&#21152;&#25289;&#22269;&#19968;&#23478;&#39046;&#20808;&#30340;&#24555;&#36895;&#28040;&#36153;&#21697;&#20844;&#21496;&#30340;&#23454;&#38469;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#20391;&#37325;&#20110;&#29992;&#20110;&#29983;&#20135;&#30446;&#30340;&#30340;&#20379;&#24212;&#38142;&#35268;&#21010;&#30340;&#26102;&#38388;&#20219;&#21153;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#25324;&#26102;&#38388;&#25968;&#25454;&#20316;&#20026;&#33410;&#28857;&#29305;&#24449;&#65292;&#20197;&#23454;&#29616;&#38144;&#21806;&#39044;&#27979;&#12289;&#29983;&#20135;&#35745;&#21010;&#21644;&#25925;&#38556;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have gained traction across different domains such as transportation, bio-informatics, language processing, and computer vision. However, there is a noticeable absence of research on applying GNNs to supply chain networks. Supply chain networks are inherently graph-like in structure, making them prime candidates for applying GNN methodologies. This opens up a world of possibilities for optimizing, predicting, and solving even the most complex supply chain problems. A major setback in this approach lies in the absence of real-world benchmark datasets to facilitate the research and resolution of supply chain problems using GNNs. To address the issue, we present a real-world benchmark dataset for temporal tasks, obtained from one of the leading FMCG companies in Bangladesh, focusing on supply chain planning for production purposes. The dataset includes temporal data as node features to enable sales predictions, production planning, and the identification of fa
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;</title><link>http://arxiv.org/abs/2310.20091</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#23494;&#24230;&#29992;&#25143;&#34920;&#31034;&#26041;&#27861;&#29992;&#20110;&#22810;&#20852;&#36259;&#20010;&#24615;&#21270;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval. (arXiv:2310.20091v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35774;&#35745;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#20934;&#30830;&#24314;&#27169;&#29992;&#25143;&#30340;&#21508;&#31181;&#22810;&#26679;&#21270;&#21644;&#21160;&#24577;&#30340;&#20852;&#36259;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#29992;&#25143;&#24314;&#27169;&#26041;&#27861;&#65292;&#22914;&#21333;&#28857;&#21644;&#22810;&#28857;&#34920;&#31034;&#65292;&#23384;&#22312;&#20934;&#30830;&#24615;&#12289;&#22810;&#26679;&#24615;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#36866;&#24212;&#24615;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#19981;&#36275;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#8212;&#8212;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;GPR4DUR&#21033;&#29992;DURs&#26469;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#65292;&#21516;&#26102;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;GPR4DUR&#30340;&#36866;&#24212;&#24615;&#21644;&#25928;&#29575;&#65292;&#32780;&#20351;&#29992;&#27169;&#25311;&#29992;&#25143;&#30340;&#22312;&#32447;&#23454;&#39564;&#21017;&#35777;&#26126;&#20102;&#23427;&#36890;&#36807;&#26377;&#25928;&#21033;&#29992;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#33021;&#22815;&#35299;&#20915;&#25506;&#32034;-&#24320;&#21457;&#30340;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, computational cost, and adaptability. To overcome these deficiencies, we introduce density-based user representations (DURs), a novel model that leverages Gaussian process regression for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20174;&#27491;&#24335;&#30340;&#35282;&#24230;&#21453;&#24605;&#20102;&#25490;&#21517;&#20013;&#21484;&#22238;&#29575;&#30340;&#27979;&#37327;&#38382;&#39064;&#65292;&#25552;&#20986;&#21484;&#22238;&#26041;&#21521;&#30340;&#27010;&#24565;&#21644;&#35789;&#20856;&#24335;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.11370</link><description>&lt;p&gt;
&#21484;&#22238;&#29575;&#12289;&#40065;&#26834;&#24615;&#21644;&#35789;&#20856;&#24335;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Recall, Robustness, and Lexicographic Evaluation. (arXiv:2302.11370v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11370
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20174;&#27491;&#24335;&#30340;&#35282;&#24230;&#21453;&#24605;&#20102;&#25490;&#21517;&#20013;&#21484;&#22238;&#29575;&#30340;&#27979;&#37327;&#38382;&#39064;&#65292;&#25552;&#20986;&#21484;&#22238;&#26041;&#21521;&#30340;&#27010;&#24565;&#21644;&#35789;&#20856;&#24335;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#20351;&#29992;&#21484;&#22238;&#29575;&#26469;&#35780;&#20272;&#21508;&#31181;&#26816;&#32034;&#12289;&#25512;&#33616;&#21644;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#25490;&#21517;&#12290;&#23613;&#31649;&#22312;&#38598;&#21512;&#35780;&#20272;&#20013;&#26377;&#20851;&#21484;&#22238;&#29575;&#30340;&#20439;&#35821;&#35299;&#37322;&#65292;&#20294;&#30740;&#31350;&#31038;&#21306;&#36828;&#26410;&#29702;&#35299;&#25490;&#21517;&#21484;&#22238;&#29575;&#30340;&#21407;&#29702;&#12290;&#23545;&#21484;&#22238;&#29575;&#32570;&#20047;&#21407;&#29702;&#29702;&#35299;&#25110;&#21160;&#26426;&#23548;&#33268;&#20449;&#24687;&#26816;&#32034;&#31038;&#21306;&#25209;&#35780;&#21484;&#22238;&#29575;&#26159;&#21542;&#26377;&#29992;&#20316;&#20026;&#19968;&#20010;&#25351;&#26631;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#20174;&#27491;&#24335;&#30340;&#35282;&#24230;&#21453;&#24605;&#25490;&#21517;&#20013;&#21484;&#22238;&#29575;&#30340;&#27979;&#37327;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#30001;&#19977;&#20010;&#21407;&#21017;&#32452;&#25104;&#65306;&#21484;&#22238;&#29575;&#12289;&#40065;&#26834;&#24615;&#21644;&#35789;&#20856;&#24335;&#35780;&#20272;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#27491;&#24335;&#23450;&#20041;&#8220;&#21484;&#22238;&#26041;&#21521;&#8221;&#20026;&#25935;&#24863;&#20110;&#24213;&#37096;&#25490;&#21517;&#30456;&#20851;&#26465;&#30446;&#31227;&#21160;&#30340;&#24230;&#37327;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20174;&#21487;&#33021;&#30340;&#25628;&#32034;&#32773;&#21644;&#20869;&#23481;&#25552;&#20379;&#32773;&#30340;&#40065;&#26834;&#24615;&#35282;&#24230;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#21484;&#22238;&#26041;&#21521;&#27010;&#24565;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#23454;&#29992;&#30340;&#35789;&#20856;&#24335;&#26041;&#27861;&#26469;&#25193;&#23637;&#23545;&#21484;&#22238;&#30340;&#27010;&#24565;&#21644;&#29702;&#35770;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Researchers use recall to evaluate rankings across a variety of retrieval, recommendation, and machine learning tasks. While there is a colloquial interpretation of recall in set-based evaluation, the research community is far from a principled understanding of recall metrics for rankings. The lack of principled understanding of or motivation for recall has resulted in criticism amongst the retrieval community that recall is useful as a measure at all. In this light, we reflect on the measurement of recall in rankings from a formal perspective. Our analysis is composed of three tenets: recall, robustness, and lexicographic evaluation. First, we formally define `recall-orientation' as sensitivity to movement of the bottom-ranked relevant item. Second, we analyze our concept of recall orientation from the perspective of robustness with respect to possible searchers and content providers. Finally, we extend this conceptual and theoretical treatment of recall by developing a practical pref
&lt;/p&gt;</description></item><item><title>&#36825;&#20221;&#32508;&#36848;&#20840;&#38754;&#35843;&#30740;&#20102;&#22522;&#20110;&#22823;&#25968;&#25454;&#30340;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#21644;&#25361;&#25112;&#65292;&#24635;&#32467;&#20102;&#22235;&#31181;&#20027;&#35201;&#31867;&#22411;&#30340;&#25512;&#33616;&#25216;&#26415;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#28508;&#22312;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2206.02631</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#25968;&#25454;&#30340;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Modern Recommendation System based on Big Data. (arXiv:2206.02631v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02631
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#32508;&#36848;&#20840;&#38754;&#35843;&#30740;&#20102;&#22522;&#20110;&#22823;&#25968;&#25454;&#30340;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#21644;&#25361;&#25112;&#65292;&#24635;&#32467;&#20102;&#22235;&#31181;&#20027;&#35201;&#31867;&#22411;&#30340;&#25512;&#33616;&#25216;&#26415;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#28508;&#22312;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#20840;&#38754;&#25506;&#32034;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#21644;&#24403;&#21069;&#29366;&#24577;&#65292;&#36825;&#20123;&#31995;&#32479;&#24050;&#24191;&#27867;&#25972;&#21512;&#21040;&#21508;&#31181;&#32593;&#32476;&#24212;&#29992;&#20013;&#12290;&#23427;&#37325;&#28857;&#20851;&#27880;&#20010;&#24615;&#21270;&#25512;&#33616;&#31574;&#30053;&#22312;&#22312;&#32447;&#20135;&#21697;&#25110;&#26381;&#21153;&#20013;&#30340;&#36827;&#23637;&#12290;&#25105;&#20204;&#23558;&#25512;&#33616;&#25216;&#26415;&#20998;&#20026;&#22235;&#31181;&#20027;&#35201;&#31867;&#22411;&#65306;&#22522;&#20110;&#20869;&#23481;&#30340;&#12289;&#21327;&#21516;&#36807;&#28388;&#30340;&#12289;&#22522;&#20110;&#30693;&#35782;&#30340;&#21644;&#28151;&#21512;&#30340;&#65292;&#27599;&#31181;&#31867;&#22411;&#37117;&#35299;&#20915;&#20102;&#29420;&#29305;&#30340;&#24773;&#26223;&#12290;&#26412;&#32508;&#36848;&#35814;&#32454;&#23457;&#35270;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#21382;&#21490;&#32972;&#26223;&#21644;&#26368;&#26032;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#20351;&#29992;&#22823;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#26412;&#32508;&#36848;&#36824;&#30830;&#23450;&#24182;&#35752;&#35770;&#20102;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#65292;&#22914;&#25968;&#25454;&#31232;&#30095;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#20197;&#21450;&#23545;&#25512;&#33616;&#30340;&#22810;&#26679;&#24615;&#38656;&#27714;&#12290;&#32508;&#36848;&#26368;&#21518;&#24378;&#35843;&#20102;&#36825;&#20123;&#25361;&#25112;&#20316;&#20026;&#26410;&#26469;&#30740;&#31350;&#30340;&#28508;&#22312;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
This survey provides an exhaustive exploration of the evolution and current state of recommendation systems, which have seen widespread integration in various web applications. It focuses on the advancement of personalized recommendation strategies for online products or services. We categorize recommendation techniques into four primary types: content-based, collaborative filtering-based, knowledge-based, and hybrid-based, each addressing unique scenarios. The survey offers a detailed examination of the historical context and the latest innovative approaches in recommendation systems, particularly those employing big data. Additionally, it identifies and discusses key challenges faced by modern recommendation systems, such as data sparsity, scalability issues, and the need for diversity in recommendations. The survey concludes by highlighting these challenges as potential areas for fruitful future research in the field.
&lt;/p&gt;</description></item></channel></rss>