<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22823;&#35268;&#27169;&#36716;&#21270;&#28431;&#26007;&#20248;&#21270;&#38382;&#39064;&#30340;&#26080;&#27169;&#22411;&#36817;&#20284;&#36125;&#21494;&#26031;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#36716;&#21270;&#28431;&#26007;&#27169;&#22411;&#26469;&#25429;&#25417;&#28040;&#36153;&#32773;&#34892;&#20026;&#65292;&#24182;&#23454;&#29616;&#20102;&#38750;&#24120;&#39640;&#30340;&#20934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.06710</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#36716;&#21270;&#28431;&#26007;&#20248;&#21270;&#30340;&#26080;&#27169;&#22411;&#36817;&#20284;&#36125;&#21494;&#26031;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Model-Free Approximate Bayesian Learning for Large-Scale Conversion Funnel Optimization. (arXiv:2401.06710v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06710
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22823;&#35268;&#27169;&#36716;&#21270;&#28431;&#26007;&#20248;&#21270;&#38382;&#39064;&#30340;&#26080;&#27169;&#22411;&#36817;&#20284;&#36125;&#21494;&#26031;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#36716;&#21270;&#28431;&#26007;&#27169;&#22411;&#26469;&#25429;&#25417;&#28040;&#36153;&#32773;&#34892;&#20026;&#65292;&#24182;&#23454;&#29616;&#20102;&#38750;&#24120;&#39640;&#30340;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#33829;&#38144;&#27963;&#21160;&#20013;&#65292;&#26681;&#25454;&#28040;&#36153;&#32773;&#29366;&#24577;&#36873;&#25321;&#24191;&#21578;&#34892;&#21160;&#30340;&#28789;&#27963;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#35782;&#21035;&#26368;&#20248;&#39034;&#24207;&#20010;&#24615;&#21270;&#24178;&#39044;&#20197;&#26368;&#22823;&#21270;&#38024;&#23545;&#26032;&#20135;&#21697;&#30340;&#37319;&#32435;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#36716;&#21270;&#28431;&#26007;&#27169;&#22411;&#26469;&#24314;&#27169;&#28040;&#36153;&#32773;&#34892;&#20026;&#65292;&#35813;&#27169;&#22411;&#25429;&#25417;&#21040;&#27599;&#20010;&#28040;&#36153;&#32773;&#30340;&#29366;&#24577;&#65288;&#20363;&#22914;&#19982;&#20844;&#21496;&#30340;&#20114;&#21160;&#21382;&#21490;&#65289;&#24182;&#20801;&#35768;&#28040;&#36153;&#32773;&#34892;&#20026;&#38543;&#30528;&#20854;&#29366;&#24577;&#21644;&#20844;&#21496;&#30340;&#39034;&#24207;&#24178;&#39044;&#32780;&#21464;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#30005;&#23376;&#37038;&#20214;&#33829;&#38144;&#25968;&#25454;&#38598;&#20013;&#20197;&#38750;&#24120;&#39640;&#30340;&#20934;&#30830;&#24230;&#65288;&#36229;&#36807;0.95&#30340;&#26679;&#26412;&#22806;AUC&#65289;&#25429;&#25417;&#21040;&#28040;&#36153;&#32773;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#38750;&#24120;&#22823;&#35268;&#27169;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#20844;&#21496;&#24517;&#39035;&#20174;&#28040;&#36153;&#32773;&#20132;&#20114;&#20013;&#23398;&#20064;&#21508;&#31181;&#24178;&#39044;&#30340;&#29366;&#24577;&#29305;&#23450;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;&#24402;&#22240;&#30340;&#20915;&#31574;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#26080;&#27169;&#22411;&#36817;&#20284;&#36125;&#21494;&#26031;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The flexibility of choosing the ad action as a function of the consumer state is critical for modern-day marketing campaigns. We study the problem of identifying the optimal sequential personalized interventions that maximize the adoption probability for a new product. We model consumer behavior by a conversion funnel that captures the state of each consumer (e.g., interaction history with the firm) and allows the consumer behavior to vary as a function of both her state and firm's sequential interventions. We show our model captures consumer behavior with very high accuracy (out-of-sample AUC of over 0.95) in a real-world email marketing dataset. However, it results in a very large-scale learning problem, where the firm must learn the state-specific effects of various interventions from consumer interactions. We propose a novel attribution-based decision-making algorithm for this problem that we call model-free approximate Bayesian learning. Our algorithm inherits the interpretability
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#29305;&#23450;&#20110;&#35821;&#26009;&#24211;&#30340;&#35789;&#27719;&#24211;&#25913;&#36827;&#20102;&#23398;&#20064;&#31232;&#30095;&#26816;&#32034;&#31995;&#32479;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#36890;&#36807;&#23558;&#24213;&#23618;BERT&#27169;&#22411;&#38024;&#23545;&#19981;&#21516;&#35789;&#27719;&#24211;&#22823;&#23567;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#26816;&#32034;&#36136;&#37327;&#24182;&#20943;&#23569;&#24310;&#36831;&#12290;&#35813;&#30740;&#31350;&#36824;&#25506;&#35752;&#20102;&#33258;&#23450;&#20041;&#35789;&#27719;&#24211;&#12289;&#25991;&#26723;&#25193;&#23637;&#25216;&#26415;&#21644;&#31232;&#30095;&#27169;&#22411;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#26816;&#32034;&#26041;&#27861;&#20013;&#37117;&#33021;&#21462;&#24471;&#25928;&#26524;&#21644;&#25928;&#29575;&#19978;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.06703</link><description>&lt;p&gt;
&#20511;&#21161;&#29305;&#23450;&#20110;&#35821;&#26009;&#24211;&#30340;&#35789;&#27719;&#24211;&#25913;&#36827;&#20102;&#23398;&#20064;&#31232;&#30095;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Improved Learned Sparse Retrieval with Corpus-Specific Vocabularies. (arXiv:2401.06703v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#29305;&#23450;&#20110;&#35821;&#26009;&#24211;&#30340;&#35789;&#27719;&#24211;&#25913;&#36827;&#20102;&#23398;&#20064;&#31232;&#30095;&#26816;&#32034;&#31995;&#32479;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#36890;&#36807;&#23558;&#24213;&#23618;BERT&#27169;&#22411;&#38024;&#23545;&#19981;&#21516;&#35789;&#27719;&#24211;&#22823;&#23567;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#26816;&#32034;&#36136;&#37327;&#24182;&#20943;&#23569;&#24310;&#36831;&#12290;&#35813;&#30740;&#31350;&#36824;&#25506;&#35752;&#20102;&#33258;&#23450;&#20041;&#35789;&#27719;&#24211;&#12289;&#25991;&#26723;&#25193;&#23637;&#25216;&#26415;&#21644;&#31232;&#30095;&#27169;&#22411;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#26816;&#32034;&#26041;&#27861;&#20013;&#37117;&#33021;&#21462;&#24471;&#25928;&#26524;&#21644;&#25928;&#29575;&#19978;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#32034;&#20102;&#20511;&#21161;&#29305;&#23450;&#20110;&#35821;&#26009;&#24211;&#30340;&#35789;&#27719;&#24211;&#26469;&#25913;&#21892;&#23398;&#20064;&#31232;&#30095;&#26816;&#32034;&#31995;&#32479;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23558;&#24213;&#23618;BERT&#27169;&#22411;&#39044;&#35757;&#32451;&#20110;&#30446;&#26631;&#35821;&#26009;&#24211;&#65292;&#24182;&#38024;&#23545;&#25991;&#26723;&#25193;&#23637;&#36807;&#31243;&#20013;&#19981;&#21516;&#30340;&#35789;&#27719;&#24211;&#22823;&#23567;&#36827;&#34892;&#29305;&#23450;&#35843;&#25972;&#65292;&#21487;&#20197;&#23558;&#26816;&#32034;&#36136;&#37327;&#25552;&#39640;&#26368;&#22810;12&#65285;&#65292;&#21516;&#26102;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#23558;&#24310;&#36831;&#38477;&#20302;&#26368;&#22810;50&#65285;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#37319;&#29992;&#29305;&#23450;&#20110;&#35821;&#26009;&#24211;&#30340;&#35789;&#27719;&#24211;&#24182;&#22686;&#21152;&#35789;&#27719;&#24211;&#22823;&#23567;&#21487;&#20197;&#20943;&#23569;&#24179;&#22343;&#20498;&#25490;&#21015;&#34920;&#38271;&#24230;&#65292;&#20174;&#32780;&#38477;&#20302;&#24310;&#36831;&#12290;&#28040;&#34701;&#30740;&#31350;&#26174;&#31034;&#20102;&#33258;&#23450;&#20041;&#35789;&#27719;&#24211;&#12289;&#25991;&#26723;&#25193;&#23637;&#25216;&#26415;&#21644;&#31232;&#30095;&#27169;&#22411;&#30340;&#31232;&#30095;&#21270;&#30446;&#26631;&#20043;&#38388;&#30340;&#26377;&#36259;&#20114;&#21160;&#12290;&#25928;&#26524;&#21644;&#25928;&#29575;&#30340;&#25913;&#36827;&#21487;&#20197;&#36801;&#31227;&#21040;&#19981;&#21516;&#30340;&#26816;&#32034;&#26041;&#27861;&#65292;&#22914;uniCOIL&#21644;SPLADE&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#25552;&#20379;&#23398;&#20064;&#31232;&#30095;&#26816;&#32034;&#31995;&#32479;&#30340;&#26032;&#30340;&#25928;&#29575;-&#25928;&#26524;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore leveraging corpus-specific vocabularies that improve both efficiency and effectiveness of learned sparse retrieval systems. We find that pre-training the underlying BERT model on the target corpus, specifically targeting different vocabulary sizes incorporated into the document expansion process, improves retrieval quality by up to 12% while in some scenarios decreasing latency by up to 50%. Our experiments show that adopting corpus-specific vocabulary and increasing vocabulary size decreases average postings list length which in turn reduces latency. Ablation studies show interesting interactions between custom vocabularies, document expansion techniques, and sparsification objectives of sparse models. Both effectiveness and efficiency improvements transfer to different retrieval approaches such as uniCOIL and SPLADE and offer a simple yet effective approach to providing new efficiency-effectiveness trade-offs for learned sparse retrieval systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;DQN&#30340;&#22312;&#32447;&#21361;&#26426;&#20107;&#20214;&#25688;&#35201;&#29983;&#25104;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#24635;&#32467;&#22810;&#20010;&#28798;&#23475;&#30456;&#20851;&#30340;&#25968;&#25454;&#27969;&#65292;&#26080;&#38656;&#20154;&#24037;&#26631;&#27880;&#25110;&#20869;&#23481;&#37325;&#26032;&#25490;&#24207;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2401.06683</link><description>&lt;p&gt;
DQNC2S&#65306;&#22522;&#20110;DQN&#30340;&#36328;&#27969;&#21361;&#26426;&#20107;&#20214;&#25688;&#35201;&#29983;&#25104;&#22120;
&lt;/p&gt;
&lt;p&gt;
DQNC2S: DQN-based Cross-stream Crisis event Summarizer. (arXiv:2401.06683v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;DQN&#30340;&#22312;&#32447;&#21361;&#26426;&#20107;&#20214;&#25688;&#35201;&#29983;&#25104;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#24635;&#32467;&#22810;&#20010;&#28798;&#23475;&#30456;&#20851;&#30340;&#25968;&#25454;&#27969;&#65292;&#26080;&#38656;&#20154;&#24037;&#26631;&#27880;&#25110;&#20869;&#23481;&#37325;&#26032;&#25490;&#24207;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21516;&#26102;&#24635;&#32467;&#22810;&#20010;&#19982;&#28798;&#23475;&#30456;&#20851;&#30340;&#25968;&#25454;&#27969;&#23588;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#29616;&#26377;&#30340;&#26816;&#32034;&#19982;&#37325;&#26032;&#25490;&#24207;&#31574;&#30053;&#22312;&#22810;&#27969;&#25968;&#25454;&#30340;&#22266;&#26377;&#20887;&#20313;&#21644;&#22810;&#26597;&#35810;&#29615;&#22659;&#19979;&#30340;&#38480;&#21046;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#26631;&#27880;&#21644;&#28145;&#24230;Q&#32593;&#32476;&#30340;&#22312;&#32447;&#21361;&#26426;&#26102;&#38388;&#36724;&#29983;&#25104;&#26041;&#27861;&#12290;&#23427;&#33021;&#22815;&#23454;&#26102;&#36873;&#25321;&#30456;&#20851;&#30340;&#25991;&#26412;&#29255;&#27573;&#65292;&#26080;&#38656;&#20154;&#24037;&#26631;&#27880;&#25110;&#20869;&#23481;&#37325;&#26032;&#25490;&#24207;&#65292;&#20174;&#32780;&#20351;&#25512;&#29702;&#26102;&#38388;&#19982;&#36755;&#20837;&#26597;&#35810;&#30340;&#25968;&#37327;&#26080;&#20851;&#12290;&#35813;&#26041;&#27861;&#36824;&#23558;&#20887;&#20313;&#36807;&#28388;&#22120;&#34701;&#20837;&#22870;&#21169;&#20989;&#25968;&#20013;&#65292;&#20197;&#26377;&#25928;&#22788;&#29702;&#36328;&#27969;&#20869;&#23481;&#37325;&#21472;&#12290;&#22312;CrisisFACTS 2022&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25152;&#36798;&#21040;&#30340;ROUGE&#21644;BERTScore&#32467;&#26524;&#20248;&#20110;&#26368;&#20339;&#24615;&#33021;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Summarizing multiple disaster-relevant data streams simultaneously is particularly challenging as existing Retrieve&amp;Re-ranking strategies suffer from the inherent redundancy of multi-stream data and limited scalability in a multi-query setting. This work proposes an online approach to crisis timeline generation based on weak annotation with Deep Q-Networks. It selects on-the-fly the relevant pieces of text without requiring neither human annotations nor content re-ranking. This makes the inference time independent of the number of input queries. The proposed approach also incorporates a redundancy filter into the reward function to effectively handle cross-stream content overlaps. The achieved ROUGE and BERTScore results are superior to those of best-performing models on the CrisisFACTS 2022 benchmark.
&lt;/p&gt;</description></item><item><title>LLMRS&#26159;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#38646;-shot&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23558;&#29992;&#25143;&#35780;&#35770;&#32534;&#30721;&#20026;&#35780;&#35770;&#20998;&#25968;&#24182;&#29983;&#25104;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LLMRS&#22312;&#36719;&#20214;&#36141;&#20080;&#26041;&#38754;&#30340;&#25512;&#33616;&#24615;&#33021;&#36229;&#36807;&#22522;&#20934;&#27169;&#22411;&#65292;&#24182;&#25104;&#21151;&#20174;&#20135;&#21697;&#35780;&#35770;&#20013;&#25429;&#25417;&#21040;&#26377;&#24847;&#20041;&#30340;&#20449;&#24687;&#65292;&#25552;&#20379;&#26356;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2401.06676</link><description>&lt;p&gt;
LLMRS: &#35299;&#38145;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#23545;&#36719;&#20214;&#36141;&#20080;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
LLMRS: Unlocking Potentials of LLM-Based Recommender Systems for Software Purchase. (arXiv:2401.06676v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06676
&lt;/p&gt;
&lt;p&gt;
LLMRS&#26159;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#38646;-shot&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23558;&#29992;&#25143;&#35780;&#35770;&#32534;&#30721;&#20026;&#35780;&#35770;&#20998;&#25968;&#24182;&#29983;&#25104;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LLMRS&#22312;&#36719;&#20214;&#36141;&#20080;&#26041;&#38754;&#30340;&#25512;&#33616;&#24615;&#33021;&#36229;&#36807;&#22522;&#20934;&#27169;&#22411;&#65292;&#24182;&#25104;&#21151;&#20174;&#20135;&#21697;&#35780;&#35770;&#20013;&#25429;&#25417;&#21040;&#26377;&#24847;&#20041;&#30340;&#20449;&#24687;&#65292;&#25552;&#20379;&#26356;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26080;&#22788;&#19981;&#22312;&#65292;&#20174;Spotify&#30340;&#27468;&#21333;&#25512;&#33616;&#21040;&#20122;&#39532;&#36874;&#30340;&#20135;&#21697;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#26681;&#25454;&#26041;&#27861;&#25110;&#25968;&#25454;&#38598;&#30340;&#19981;&#21516;&#65292;&#36825;&#20123;&#31995;&#32479;&#36890;&#24120;&#26080;&#27861;&#25429;&#25417;&#29992;&#25143;&#30340;&#20559;&#22909;&#24182;&#29983;&#25104;&#26222;&#36866;&#30340;&#25512;&#33616;&#12290;&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36827;&#23637;&#20026;&#20998;&#26512;&#29992;&#25143;&#26597;&#35810;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#26469;&#25429;&#25417;&#29992;&#25143;&#30340;&#20559;&#22909;&#21644;&#25552;&#39640;&#25928;&#29575;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LLMRS&#65292;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#38646;-shot&#25512;&#33616;&#31995;&#32479;&#65292;&#25105;&#20204;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLM&#23558;&#29992;&#25143;&#35780;&#35770;&#32534;&#30721;&#20026;&#35780;&#35770;&#20998;&#25968;&#65292;&#24182;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#22312;&#20122;&#39532;&#36874;&#20135;&#21697;&#35780;&#35770;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23545;LLMRS&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#29992;&#20110;&#36719;&#20214;&#36141;&#20080;&#30340;&#20351;&#29992;&#26696;&#20363;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;LLMRS&#20248;&#20110;&#22522;&#20110;&#25490;&#21517;&#30340;&#22522;&#20934;&#27169;&#22411;&#65292;&#21516;&#26102;&#25104;&#21151;&#20174;&#20135;&#21697;&#35780;&#35770;&#20013;&#25429;&#25417;&#21040;&#26377;&#24847;&#20041;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems are ubiquitous, from Spotify playlist suggestions to Amazon product suggestions. Nevertheless, depending on the methodology or the dataset, these systems typically fail to capture user preferences and generate general recommendations. Recent advancements in Large Language Models (LLM) offer promising results for analyzing user queries. However, employing these models to capture user preferences and efficiency remains an open question. In this paper, we propose LLMRS, an LLM-based zero-shot recommender system where we employ pre-trained LLM to encode user reviews into a review score and generate user-tailored recommendations. We experimented with LLMRS on a real-world dataset, the Amazon product reviews, for software purchase use cases. The results show that LLMRS outperforms the ranking-based baseline model while successfully capturing meaningful information from product reviews, thereby providing more reliable recommendations.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SemIoE&#30340;&#26032;&#30340;&#35821;&#20041;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;IoE&#22522;&#30784;&#19978;&#30340;&#24037;&#19994;&#20013;&#25968;&#25454;&#25972;&#21512;&#21644;&#22788;&#29702;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.06667</link><description>&lt;p&gt;
SemIoE&#26412;&#20307;&#35770;: &#19968;&#31181;&#38754;&#21521;&#22522;&#20110;IoE&#30340;&#24037;&#19994;&#30340;&#35821;&#20041;&#27169;&#22411;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
The SemIoE Ontology: A Semantic Model Solution for an IoE-based Industry. (arXiv:2401.06667v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06667
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SemIoE&#30340;&#26032;&#30340;&#35821;&#20041;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;IoE&#22522;&#30784;&#19978;&#30340;&#24037;&#19994;&#20013;&#25968;&#25454;&#25972;&#21512;&#21644;&#22788;&#29702;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#24037;&#19994;5.0&#20316;&#20026;&#19968;&#31181;&#26032;&#20852;&#30340;&#33539;&#24335;&#65292;&#23450;&#20041;&#20102;&#36808;&#21521;&#26356;&#26234;&#33021;&#12289;&#29615;&#20445;&#24847;&#35782;&#26356;&#24378;&#12289;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#25968;&#23383;&#31995;&#32479;&#30340;&#20855;&#20307;&#27493;&#39588;&#12290;&#22312;&#26234;&#33021;&#35774;&#22791;&#22312;&#24037;&#19994;&#39046;&#22495;&#20013;&#36234;&#26469;&#36234;&#22797;&#26434;&#21644;&#33258;&#20027;&#30340;&#26102;&#20195;&#65292;&#29289;&#32852;&#32593;&#21450;&#20854;&#28436;&#21464;&#65292;&#21363;&#29289;&#32852;&#32593;&#65288;IoE&#65289;&#65292;&#28041;&#21450;&#20154;&#21592;&#12289;&#26426;&#22120;&#20154;&#12289;&#36807;&#31243;&#21644;&#25968;&#25454;&#22312;&#32593;&#32476;&#20013;&#65292;&#20195;&#34920;&#20102;&#20801;&#35768;&#34892;&#19994;&#23558;&#20154;&#31867;&#30340;&#32463;&#39564;&#21644;&#38656;&#27714;&#32622;&#20110;&#20854;&#29983;&#24577;&#31995;&#32479;&#20013;&#24515;&#30340;&#20027;&#35201;&#25512;&#21160;&#22240;&#32032;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25152;&#28041;&#21450;&#23454;&#20307;&#30340;&#26497;&#31471;&#24322;&#26500;&#24615;&#12289;&#23427;&#20204;&#30340;&#20869;&#22312;&#38656;&#27714;&#21644;&#21512;&#20316;&#33021;&#21147;&#20197;&#21450;&#36866;&#24212;&#21160;&#24577;&#29992;&#25143;&#20013;&#24515;&#29615;&#22659;&#30340;&#30446;&#26631;&#65292;&#23545;&#20110;&#22788;&#29702;&#21644;&#25972;&#21512;IoE&#25152;&#20135;&#29983;&#30340;&#25968;&#25454;&#38656;&#35201;&#29305;&#21035;&#20851;&#27880;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#23601;&#26159;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#35821;&#20041;&#27169;&#22411;&#65292;&#24418;&#24335;&#21270;&#20102;&#22522;&#26412;&#30340;&#34892;&#21160;&#32773;&#65292;
&lt;/p&gt;
&lt;p&gt;
Recently, the Industry 5.0 is gaining attention as a novel paradigm, defining the next concrete steps toward more and more intelligent, green-aware and user-centric digital systems. In an era in which smart devices typically adopted in the industry domain are more and more sophisticated and autonomous, the Internet of Things and its evolution, known as the Internet of Everything (IoE, for short), involving also people, robots, processes and data in the network, represent the main driver to allow industries to put the experiences and needs of human beings at the center of their ecosystems. However, due to the extreme heterogeneity of the involved entities, their intrinsic need and capability to cooperate, and the aim to adapt to a dynamic user-centric context, special attention is required for the integration and processing of the data produced by such an IoE. This is the objective of the present paper, in which we propose a novel semantic model that formalizes the fundamental actors, e
&lt;/p&gt;</description></item><item><title>Ada-Retrieval&#26159;&#19968;&#31181;&#36866;&#24212;&#24615;&#22810;&#36718;&#26816;&#32034;&#33539;&#20363;&#65292;&#29992;&#20110;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#29289;&#21697;&#20505;&#36873;&#32773;&#36873;&#25321;&#36807;&#31243;&#12290;&#23427;&#36890;&#36807;&#36845;&#20195;&#22320;&#25913;&#36827;&#29992;&#25143;&#34920;&#31034;&#26469;&#26356;&#22909;&#22320;&#25429;&#25417;&#23436;&#25972;&#30340;&#29289;&#21697;&#31354;&#38388;&#20013;&#30340;&#28508;&#22312;&#20505;&#36873;&#32773;&#65292;&#24182;&#20855;&#26377;&#27169;&#22411;&#26080;&#20851;&#30340;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2401.06633</link><description>&lt;p&gt;
Ada-Retrieval&#65306;&#36866;&#24212;&#24615;&#22810;&#36718;&#26816;&#32034;&#33539;&#20363;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential Recommendations. (arXiv:2401.06633v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06633
&lt;/p&gt;
&lt;p&gt;
Ada-Retrieval&#26159;&#19968;&#31181;&#36866;&#24212;&#24615;&#22810;&#36718;&#26816;&#32034;&#33539;&#20363;&#65292;&#29992;&#20110;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#29289;&#21697;&#20505;&#36873;&#32773;&#36873;&#25321;&#36807;&#31243;&#12290;&#23427;&#36890;&#36807;&#36845;&#20195;&#22320;&#25913;&#36827;&#29992;&#25143;&#34920;&#31034;&#26469;&#26356;&#22909;&#22320;&#25429;&#25417;&#23436;&#25972;&#30340;&#29289;&#21697;&#31354;&#38388;&#20013;&#30340;&#28508;&#22312;&#20505;&#36873;&#32773;&#65292;&#24182;&#20855;&#26377;&#27169;&#22411;&#26080;&#20851;&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#27169;&#22411;&#26088;&#22312;&#36873;&#25321;&#19982;&#32473;&#23450;&#29992;&#25143;&#20559;&#22909;&#21305;&#37197;&#30340;&#19968;&#23567;&#32452;&#29289;&#21697;&#20505;&#36873;&#32773;&#12290;&#23427;&#20204;&#22312;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#22240;&#20026;&#21518;&#32493;&#30340;&#27169;&#22411;&#65288;&#22914;&#25490;&#21517;&#22120;&#65289;&#39640;&#24230;&#20381;&#36182;&#20110;&#29289;&#21697;&#20505;&#36873;&#32773;&#30340;&#36136;&#37327;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26816;&#32034;&#27169;&#22411;&#37319;&#29992;&#21333;&#36718;&#25512;&#29702;&#33539;&#20363;&#65292;&#21487;&#33021;&#26080;&#27861;&#20805;&#20998;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#30340;&#21160;&#24577;&#24615;&#24182;&#22266;&#23450;&#22312;&#29289;&#21697;&#31354;&#38388;&#30340;&#26576;&#20010;&#21306;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Ada-Retrieval&#65292;&#19968;&#31181;&#36866;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#33258;&#36866;&#24212;&#22810;&#36718;&#26816;&#32034;&#33539;&#20363;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#25913;&#36827;&#29992;&#25143;&#34920;&#31034;&#26469;&#26356;&#22909;&#22320;&#25429;&#25417;&#23436;&#25972;&#30340;&#29289;&#21697;&#31354;&#38388;&#20013;&#30340;&#28508;&#22312;&#20505;&#36873;&#32773;&#12290;Ada-Retrieval&#21253;&#21547;&#20004;&#20010;&#20851;&#38190;&#27169;&#22359;&#65306;&#29289;&#21697;&#34920;&#31034;&#36866;&#37197;&#22120;&#21644;&#29992;&#25143;&#34920;&#31034;&#36866;&#37197;&#22120;&#65292;&#26088;&#22312;&#23558;&#19978;&#19979;&#25991;&#20449;&#24687;&#27880;&#20837;&#29289;&#21697;&#21644;&#29992;&#25143;&#30340;&#34920;&#31034;&#20013;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#27169;&#22411;&#26080;&#20851;&#30340;&#35774;&#35745;&#65292;&#21487;&#20197;&#19982;&#21508;&#31181;&#22522;&#30784;&#27169;&#22411;&#65288;&#22914;RNN&#25110;Transformer&#65289;&#26080;&#32541;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval models aim at selecting a small set of item candidates which match the preference of a given user. They play a vital role in large-scale recommender systems since subsequent models such as rankers highly depend on the quality of item candidates. However, most existing retrieval models employ a single-round inference paradigm, which may not adequately capture the dynamic nature of user preferences and stuck in one area in the item space. In this paper, we propose Ada-Retrieval, an adaptive multi-round retrieval paradigm for recommender systems that iteratively refines user representations to better capture potential candidates in the full item space. Ada-Retrieval comprises two key modules: the item representation adapter and the user representation adapter, designed to inject context information into items' and users' representations. The framework maintains a model-agnostic design, allowing seamless integration with various backbone models such as RNNs or Transformers. We pe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#21464;&#24418;&#22120;&#27169;&#22411;&#21644;&#26144;&#23556;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#36328;&#35821;&#35328;&#25991;&#26723;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#26144;&#23556;&#21040;&#36328;&#35821;&#35328;&#39046;&#22495;&#30340;&#21464;&#24418;&#22120;&#25216;&#26415;&#25991;&#26723;&#34920;&#31034;&#65288;TLDRs&#65289;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23454;&#29616;&#36328;&#35821;&#35328;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2401.06583</link><description>&lt;p&gt;
&#23558;&#21464;&#24418;&#22120;&#25216;&#26415;&#24212;&#29992;&#20110;&#36328;&#35821;&#35328;&#25991;&#26723;&#34920;&#31034;&#30340;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Mapping Transformer Leveraged Embeddings for Cross-Lingual Document Representation. (arXiv:2401.06583v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06583
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#21464;&#24418;&#22120;&#27169;&#22411;&#21644;&#26144;&#23556;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#36328;&#35821;&#35328;&#25991;&#26723;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#26144;&#23556;&#21040;&#36328;&#35821;&#35328;&#39046;&#22495;&#30340;&#21464;&#24418;&#22120;&#25216;&#26415;&#25991;&#26723;&#34920;&#31034;&#65288;TLDRs&#65289;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23454;&#29616;&#36328;&#35821;&#35328;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#23545;&#20110;&#25991;&#26723;&#24050;&#32463;&#25104;&#20026;&#22312;&#32593;&#32476;&#19978;&#25214;&#21040;&#30456;&#20851;&#20869;&#23481;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#24403;&#25512;&#33616;&#38750;&#26597;&#35810;&#35821;&#35328;&#30340;&#25991;&#26723;&#26102;&#65292;&#36825;&#20123;&#31995;&#32479;&#23384;&#22312;&#19968;&#23450;&#38480;&#21046;&#65292;&#21487;&#33021;&#20250;&#24573;&#35270;&#38750;&#27597;&#35821;&#30340;&#36164;&#28304;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#26144;&#23556;&#21040;&#36328;&#35821;&#35328;&#39046;&#22495;&#30340;&#21464;&#24418;&#22120;&#25216;&#26415;&#25991;&#26723;&#34920;&#31034;&#65288;TLDRs&#65289;&#26469;&#34920;&#31034;&#36328;&#35821;&#35328;&#25991;&#26723;&#12290;&#35780;&#20272;&#20102;&#22235;&#20010;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#21464;&#24418;&#22120;&#27169;&#22411;&#65288;mBERT&#65292;mT5 XLM RoBERTa&#65292;ErnieM&#65289;&#22312;20&#31181;&#35821;&#35328;&#23545;&#19978;&#20351;&#29992;&#19977;&#31181;&#26144;&#23556;&#26041;&#27861;&#30340;&#25928;&#26524;&#65292;&#36825;&#20123;&#35821;&#35328;&#23545;&#20195;&#34920;&#20102;&#27431;&#30431;&#36873;&#25321;&#30340;&#20116;&#31181;&#35821;&#35328;&#30340;&#32452;&#21512;&#12290;&#20351;&#29992;Mate&#26816;&#32034;&#29575;&#21644;&#20114;&#24800;&#25490;&#24207;&#31561;&#25351;&#26631;&#26469;&#34913;&#37327;&#26144;&#23556;TLDRs&#19982;&#26410;&#26144;&#23556;TLDRs&#30340;&#25928;&#26524;&#12290;&#32467;&#26524;&#24378;&#35843;&#20102;&#36890;&#36807;&#39044;&#35757;&#32451;&#21464;&#24418;&#22120;&#21644;&#26144;&#23556;&#26041;&#27861;&#23454;&#29616;&#30340;&#36328;&#35821;&#35328;&#34920;&#31034;&#30340;&#33021;&#21147;&#65292;&#20026;&#25193;&#23637;&#36328;&#35821;&#35328;&#25991;&#26723;&#34920;&#31034;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems, for documents, have become tools to find relevant content on the Web. However, these systems have limitations when it comes to recommending documents in languages different from the query language, which means they might overlook resources in non-native languages. This research focuses on representing documents across languages by using Transformer Leveraged Document Representations (TLDRs) that are mapped to a cross-lingual domain. Four multilingual pre-trained transformer models (mBERT, mT5 XLM RoBERTa, ErnieM) were evaluated using three mapping methods across 20 language pairs representing combinations of five selected languages of the European Union. Metrics like Mate Retrieval Rate and Reciprocal Rank were used to measure the effectiveness of mapped TLDRs compared to non-mapped ones. The results highlight the power of cross-lingual representations achieved through pre-trained transformers and mapping approaches suggesting a promising direction for expanding
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#25351;&#20196;&#35843;&#20248;&#30340;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;INTERS&#65292;&#28085;&#30422;&#20102;21&#20010;IR&#20219;&#21153;&#65292;&#35813;&#26041;&#27861;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.06532</link><description>&lt;p&gt;
INTERS: &#20351;&#29992;&#25351;&#20196;&#35843;&#20248;&#35299;&#38145;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25628;&#32034;&#20013;&#30340;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning. (arXiv:2401.06532v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#25351;&#20196;&#35843;&#20248;&#30340;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;INTERS&#65292;&#28085;&#30422;&#20102;21&#20010;IR&#20219;&#21153;&#65292;&#35813;&#26041;&#27861;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35768;&#22810;&#19982;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#20855;&#20307;&#27010;&#24565;&#30340;&#19981;&#32463;&#24120;&#20986;&#29616;&#22312;&#33258;&#28982;&#35821;&#35328;&#20013;&#65292;&#23427;&#20204;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#21487;&#20197;&#21521;LLMs&#25552;&#20379;&#20219;&#21153;&#25551;&#36848;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#22312;&#20419;&#36827;&#20840;&#38754;&#29702;&#35299;&#21644;&#25191;&#34892;IR&#20219;&#21153;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;LLMs&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#25351;&#20196;&#35843;&#20248;&#30340;&#28508;&#21147;&#65292;&#20197;&#25552;&#39640;LLMs&#22312;IR&#20219;&#21153;&#20013;&#30340;&#29087;&#32451;&#31243;&#24230;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;INTERS&#65292;&#28085;&#30422;&#20102;3&#20010;&#22522;&#26412;IR&#31867;&#21035;&#20013;&#30340;21&#20010;&#20219;&#21153;&#65306;&#26597;&#35810;&#29702;&#35299;&#12289;&#25991;&#26723;&#29702;&#35299;&#21644;&#26597;&#35810;&#25991;&#26723;&#20851;&#31995;&#29702;&#35299;&#12290;&#25968;&#25454;&#26469;&#33258;43&#20010;&#19981;&#21516;&#30340;&#30001;&#25163;&#21160;&#32534;&#20889;&#30340;&#27169;&#26495;&#26500;&#25104;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;INTERS&#26174;&#33879;&#25552;&#21319;&#20102;&#21508;&#31181;&#20844;&#24320;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks. Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language. While prompt-based methods can provide task descriptions to LLMs, they often fall short in facilitating comprehensive understanding and execution of IR tasks, thereby limiting LLMs' applicability. To address this gap, in this work, we explore the potential of instruction tuning to enhance LLMs' proficiency in IR tasks. We introduce a novel instruction tuning dataset, INTERS, encompassing 21 tasks across three fundamental IR categories: query understanding, document understanding, and query-document relationship understanding. The data are derived from 43 distinct datasets with manually written templates. Our empirical results reveal that INTERS significantly boosts the performance of various publicly a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;UNEX-RL&#30340;&#22522;&#20110;&#21333;&#21521;&#25191;&#34892;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#20248;&#21270;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#22870;&#21169;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#35299;&#20915;&#35266;&#23519;&#20381;&#36182;&#24615;&#21644;&#32423;&#32852;&#25928;&#24212;&#30340;&#25361;&#25112;&#65292;&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.06470</link><description>&lt;p&gt;
UNEX-RL: &#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#36890;&#36807;&#21333;&#21521;&#25191;&#34892;&#21152;&#24378;&#38271;&#26399;&#22870;&#21169;
&lt;/p&gt;
&lt;p&gt;
UNEX-RL: Reinforcing Long-Term Rewards in Multi-Stage Recommender Systems with UNidirectional EXecution. (arXiv:2401.06470v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;UNEX-RL&#30340;&#22522;&#20110;&#21333;&#21521;&#25191;&#34892;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#20248;&#21270;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#22870;&#21169;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#35299;&#20915;&#35266;&#23519;&#20381;&#36182;&#24615;&#21644;&#32423;&#32852;&#25928;&#24212;&#30340;&#25361;&#25112;&#65292;&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#24320;&#22987;&#20851;&#27880;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26469;&#20248;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#22870;&#21169;&#12290;&#30001;&#20110;&#24037;&#19994;&#32423;&#30340;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#26159;&#35774;&#35745;&#20026;&#22810;&#38454;&#27573;&#31995;&#32479;&#65292;&#20351;&#29992;&#21333;&#20010;&#26234;&#33021;&#20307;&#30340;RL&#26041;&#27861;&#22312;&#21516;&#26102;&#20248;&#21270;&#22810;&#20010;&#38454;&#27573;&#26102;&#38754;&#20020;&#25361;&#25112;&#12290;&#21407;&#22240;&#26159;&#19981;&#21516;&#30340;&#38454;&#27573;&#20855;&#26377;&#19981;&#21516;&#30340;&#35266;&#23519;&#31354;&#38388;&#65292;&#22240;&#27492;&#19981;&#33021;&#30001;&#21333;&#20010;&#26234;&#33021;&#20307;&#24314;&#27169;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;UNidirectional-EXecution&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65288;UNEX-RL&#65289;&#65292;&#29992;&#20110;&#21152;&#24378;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#38271;&#26399;&#22870;&#21169;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21333;&#21521;&#25191;&#34892;&#26159;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#65292;&#23545;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#30340;&#24212;&#29992;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#21363;&#35266;&#23519;&#20381;&#36182;&#24615;&#21644;&#32423;&#32852;&#25928;&#24212;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#32423;&#32852;&#20449;&#24687;&#38142;&#65288;CIC&#65289;&#26041;&#27861;&#26469;&#20998;&#31163;&#29420;&#31435;&#30340;&#35266;&#23519;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been a growing interest in utilizing reinforcement learning (RL) to optimize long-term rewards in recommender systems. Since industrial recommender systems are typically designed as multi-stage systems, RL methods with a single agent face challenges when optimizing multiple stages simultaneously. The reason is that different stages have different observation spaces, and thus cannot be modeled by a single agent. To address this issue, we propose a novel UNidirectional-EXecution-based multi-agent Reinforcement Learning (UNEX-RL) framework to reinforce the long-term rewards in multi-stage recommender systems. We show that the unidirectional execution is a key feature of multi-stage recommender systems, bringing new challenges to the applications of multi-agent reinforcement learning (MARL), namely the observation dependency and the cascading effect. To tackle these challenges, we provide a cascading information chain (CIC) method to separate the independent obse
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#39044;&#27979;&#35780;&#20998;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;GCN&#27169;&#22411;&#20013;&#24341;&#20837;Transformer&#23618;&#65292;&#22312;&#33410;&#28857;&#23884;&#20837;&#26041;&#38754;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.06436</link><description>&lt;p&gt;
&#22312;&#22522;&#20110;&#31038;&#20132;&#32593;&#32476;&#30340;&#29289;&#21697;&#25512;&#33616;&#20013;&#65292;&#29992;Transformer&#23618;&#25913;&#36827;&#22270;&#21367;&#31215;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Improving Graph Convolutional Networks with Transformer Layer in social-based items recommendation. (arXiv:2401.06436v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#39044;&#27979;&#35780;&#20998;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;GCN&#27169;&#22411;&#20013;&#24341;&#20837;Transformer&#23618;&#65292;&#22312;&#33410;&#28857;&#23884;&#20837;&#26041;&#38754;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;GCN&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#39044;&#27979;&#35780;&#20998;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#26631;&#20934;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25193;&#23637;&#20102;&#20960;&#23618;Transformer&#26550;&#26500;&#12290;&#35770;&#25991;&#30340;&#20027;&#35201;&#28966;&#28857;&#26159;&#32593;&#32476;&#20013;&#33410;&#28857;&#23884;&#20837;&#30340;&#32534;&#30721;&#22120;&#26550;&#26500;&#12290;&#20351;&#29992;&#26469;&#33258;&#22522;&#20110;&#22270;&#30340;&#21367;&#31215;&#23618;&#30340;&#23884;&#20837;&#23618;&#65292;&#27880;&#24847;&#26426;&#21046;&#21487;&#20197;&#37325;&#26032;&#25490;&#21015;&#29305;&#24449;&#31354;&#38388;&#65292;&#20026;&#19979;&#28216;&#20219;&#21153;&#33719;&#21462;&#26356;&#39640;&#25928;&#30340;&#23884;&#20837;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26550;&#26500;&#22312;&#20256;&#32479;&#30340;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#20110;GCN&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we have proposed an approach for improving the GCN for predicting ratings in social networks. Our model is expanded from the standard model with several layers of transformer architecture. The main focus of the paper is on the encoder architecture for node embedding in the network. Using the embedding layer from the graph-based convolution layer, the attention mechanism could rearrange the feature space to get a more efficient embedding for the downstream task. The experiments showed that our proposed architecture achieves better performance than GCN on the traditional link prediction task.
&lt;/p&gt;</description></item><item><title>TRACE&#26159;&#19968;&#20010;&#26102;&#38388;&#20851;&#31995;&#36817;&#20284;&#31435;&#26041;&#24341;&#25806;&#65292;&#21487;&#20197;&#20197;&#36739;&#20302;&#25104;&#26412;&#36827;&#34892;&#20132;&#20114;&#24335;&#20998;&#26512;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#29992;&#25143;&#23450;&#20041;&#30340;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2401.06336</link><description>&lt;p&gt;
TRACE:&#19968;&#31181;&#29992;&#20110;&#24555;&#36895;&#25968;&#25454;&#27934;&#23519;&#30340;&#26102;&#38388;&#20851;&#31995;&#36817;&#20284;&#31435;&#26041;&#24341;&#25806;
&lt;/p&gt;
&lt;p&gt;
TRACE: A Time-Relational Approximate Cubing Engine for Fast Data Insights. (arXiv:2401.06336v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06336
&lt;/p&gt;
&lt;p&gt;
TRACE&#26159;&#19968;&#20010;&#26102;&#38388;&#20851;&#31995;&#36817;&#20284;&#31435;&#26041;&#24341;&#25806;&#65292;&#21487;&#20197;&#20197;&#36739;&#20302;&#25104;&#26412;&#36827;&#34892;&#20132;&#20114;&#24335;&#20998;&#26512;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#29992;&#25143;&#23450;&#20041;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#38382;&#39064;&#30340;&#22823;&#31867;&#21487;&#20197;&#34987;&#24314;&#27169;&#20026;&#36890;&#36807;&#29992;&#25143;&#23450;&#20041;&#30340;&#25351;&#26631;&#26469;&#30830;&#23450;&#37325;&#35201;&#30340;&#25968;&#25454;&#29255;&#27573;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;TRACE&#65292;&#19968;&#31181;&#26102;&#38388;&#20851;&#31995;&#36817;&#20284;&#31435;&#26041;&#24341;&#25806;&#65292;&#23427;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#21069;&#26399;&#25104;&#26412;&#65288;&#21253;&#25324;&#31354;&#38388;&#21644;&#35745;&#31639;&#65289;&#22312;&#36825;&#20123;&#29255;&#27573;&#19978;&#36827;&#34892;&#20132;&#20114;&#24335;&#20998;&#26512;&#12290;&#36890;&#36807;&#36880;&#27493;&#23454;&#29616;&#31435;&#26041;&#20307;&#30340;&#26368;&#37325;&#35201;&#37096;&#20998;&#65292;TRACE&#25903;&#25345;&#23545;&#19968;&#22823;&#31867;&#20998;&#26512;&#26597;&#35810;&#30340;&#20132;&#20114;&#24335;&#26597;&#35810;&#65292;&#20363;&#22914;&#25105;&#30340;&#19994;&#21153;&#20013;&#21738;&#20010;&#37096;&#20998;&#30340;&#25910;&#20837;&#22686;&#38271;&#26368;&#24555;&#65288;[SubCategory=Sports Equipment, Gender=Female]&#65289;&#65292;&#21738;&#20123;&#29255;&#27573;&#30340;&#27599;&#29992;&#25143;&#25910;&#20837;&#28382;&#21518;&#65288;[State=CA, Age=20-30]&#65289;&#12290;TRACE&#25903;&#25345;&#35768;&#22810;&#29992;&#25143;&#23450;&#20041;&#30340;&#25351;&#26631;&#65292;&#21253;&#25324;&#24120;&#35265;&#30340;&#32858;&#21512;&#65288;&#22914;SUM&#12289;COUNT&#12289;DISTINCT COUNT&#65289;&#21644;&#26356;&#22797;&#26434;&#30340;&#25351;&#26631;&#65288;&#22914;AVERAGE&#65289;&#12290;&#25105;&#20204;&#38024;&#23545;&#21508;&#31181;&#21830;&#19994;&#29992;&#20363;&#23454;&#26045;&#21644;&#37096;&#32626;&#20102;TRACE&#12290;
&lt;/p&gt;
&lt;p&gt;
A large class of data questions can be modeled as identifying important slices of data driven by user defined metrics. This paper presents TRACE, a Time-Relational Approximate Cubing Engine that enables interactive analysis on such slices with a low upfront cost - both in space and computation. It does this by materializing the most important parts of the cube over time enabling interactive querying for a large class of analytical queries e.g. what part of my business has the highest revenue growth ([SubCategory=Sports Equipment, Gender=Female]), what slices are lagging in revenue per user ([State=CA, Age=20-30]). Many user defined metrics are supported including common aggregations such as SUM, COUNT, DISTINCT COUNT and more complex ones such as AVERAGE. We implemented and deployed TRACE for a variety of business use cases.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#38646;&#26679;&#26412;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31995;&#32479;&#24615;&#32508;&#36848;&#33258;&#21160;&#31579;&#36873;&#30340;&#26377;&#25928;&#24615;&#65292;&#32467;&#26524;&#26174;&#31034;&#25351;&#23548;&#24494;&#35843;&#21644;&#26657;&#20934;&#25216;&#26415;&#22312;&#31579;&#36873;&#20013;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#19988;&#19982;&#38646;&#26679;&#26412;&#27169;&#22411;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#33410;&#30465;&#31579;&#36873;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2401.06320</link><description>&lt;p&gt;
&#38646;&#26679;&#26412;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#31995;&#32479;&#24615;&#32508;&#36848;&#31579;&#36873;&#33258;&#21160;&#21270;
&lt;/p&gt;
&lt;p&gt;
Zero-shot Generative Large Language Models for Systematic Review Screening Automation. (arXiv:2401.06320v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#38646;&#26679;&#26412;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31995;&#32479;&#24615;&#32508;&#36848;&#33258;&#21160;&#31579;&#36873;&#30340;&#26377;&#25928;&#24615;&#65292;&#32467;&#26524;&#26174;&#31034;&#25351;&#23548;&#24494;&#35843;&#21644;&#26657;&#20934;&#25216;&#26415;&#22312;&#31579;&#36873;&#20013;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#19988;&#19982;&#38646;&#26679;&#26412;&#27169;&#22411;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#33410;&#30465;&#31579;&#36873;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#24615;&#32508;&#36848;&#23545;&#20110;&#22522;&#20110;&#35777;&#25454;&#30340;&#21307;&#23398;&#38750;&#24120;&#37325;&#35201;&#65292;&#23427;&#20204;&#32508;&#21512;&#20998;&#26512;&#20102;&#29305;&#23450;&#38382;&#39064;&#30340;&#24050;&#21457;&#34920;&#30740;&#31350;&#32467;&#26524;&#12290;&#36827;&#34892;&#27492;&#31867;&#32508;&#36848;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#36164;&#28304;&#21644;&#26102;&#38388;&#65292;&#29305;&#21035;&#26159;&#22312;&#31579;&#36873;&#38454;&#27573;&#65292;&#38656;&#35201;&#35780;&#20272;&#20986;&#29256;&#29289;&#25688;&#35201;&#26159;&#21542;&#24212;&#21253;&#25324;&#22312;&#32508;&#36848;&#20013;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20351;&#29992;&#38646;&#26679;&#26412;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#33258;&#21160;&#31579;&#36873;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20843;&#31181;&#19981;&#21516;&#30340;LLM&#30340;&#25928;&#26524;&#65292;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#39044;&#23450;&#20041;&#30340;&#21484;&#22238;&#38408;&#20540;&#30340;&#26657;&#20934;&#25216;&#26415;&#65292;&#29992;&#20110;&#30830;&#23450;&#26159;&#21542;&#24212;&#23558;&#20986;&#29256;&#29289;&#21253;&#25324;&#22312;&#31995;&#32479;&#24615;&#32508;&#36848;&#20013;&#12290;&#25105;&#20204;&#30340;&#20840;&#38754;&#35780;&#20272;&#20351;&#29992;&#20102;&#20116;&#20010;&#26631;&#20934;&#27979;&#35797;&#38598;&#65292;&#32467;&#26524;&#26174;&#31034;&#25351;&#23548;&#24494;&#35843;&#22312;&#31579;&#36873;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#65292;&#26657;&#20934;&#20351;LLMs&#22312;&#23454;&#29616;&#30446;&#26631;&#21484;&#22238;&#26041;&#38754;&#26356;&#23454;&#29992;&#65292;&#24182;&#19988;&#23558;&#36825;&#20004;&#32773;&#19982;&#38646;&#26679;&#26412;&#27169;&#22411;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#19982;&#29616;&#26377;&#25216;&#26415;&#30456;&#27604;&#33410;&#30465;&#20102;&#22823;&#37327;&#31579;&#36873;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Systematic reviews are crucial for evidence-based medicine as they comprehensively analyse published research findings on specific questions. Conducting such reviews is often resource- and time-intensive, especially in the screening phase, where abstracts of publications are assessed for inclusion in a review. This study investigates the effectiveness of using zero-shot large language models~(LLMs) for automatic screening. We evaluate the effectiveness of eight different LLMs and investigate a calibration technique that uses a predefined recall threshold to determine whether a publication should be included in a systematic review. Our comprehensive evaluation using five standard test collections shows that instruction fine-tuning plays an important role in screening, that calibration renders LLMs practical for achieving a targeted recall, and that combining both with an ensemble of zero-shot models saves significant screening time compared to state-of-the-art approaches.
&lt;/p&gt;</description></item><item><title>MuGI&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22810;&#25991;&#26412;&#29983;&#25104;&#38598;&#25104;&#26694;&#26550;&#65292;&#23427;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21512;&#20316;&#29983;&#25104;&#22810;&#20010;&#20266;&#21442;&#32771;&#25991;&#29486;&#65292;&#24182;&#23558;&#20854;&#19982;&#26597;&#35810;&#38598;&#25104;&#20197;&#25552;&#21319;&#20449;&#24687;&#26816;&#32034;&#24615;&#33021;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;MuGI&#27169;&#22411;&#22312;TREC DL&#25968;&#25454;&#38598;&#19978;&#30340;BM25&#24615;&#33021;&#19978;&#21462;&#24471;&#20102;18%&#20197;&#19978;&#30340;&#22686;&#24378;&#65292;&#24182;&#22312;BEIR&#19978;&#25552;&#39640;&#20102;7.5%&#12290;</title><link>http://arxiv.org/abs/2401.06311</link><description>&lt;p&gt;
MuGI:&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#25991;&#26412;&#29983;&#25104;&#38598;&#25104;&#22686;&#24378;&#20449;&#24687;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
MuGI: Enhancing Information Retrieval through Multi-Text Generation Intergration with Large Language Models. (arXiv:2401.06311v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06311
&lt;/p&gt;
&lt;p&gt;
MuGI&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22810;&#25991;&#26412;&#29983;&#25104;&#38598;&#25104;&#26694;&#26550;&#65292;&#23427;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21512;&#20316;&#29983;&#25104;&#22810;&#20010;&#20266;&#21442;&#32771;&#25991;&#29486;&#65292;&#24182;&#23558;&#20854;&#19982;&#26597;&#35810;&#38598;&#25104;&#20197;&#25552;&#21319;&#20449;&#24687;&#26816;&#32034;&#24615;&#33021;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;MuGI&#27169;&#22411;&#22312;TREC DL&#25968;&#25454;&#38598;&#19978;&#30340;BM25&#24615;&#33021;&#19978;&#21462;&#24471;&#20102;18%&#20197;&#19978;&#30340;&#22686;&#24378;&#65292;&#24182;&#22312;BEIR&#19978;&#25552;&#39640;&#20102;7.5%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#32463;&#25104;&#20026;&#35821;&#35328;&#25216;&#26415;&#39046;&#22495;&#30340;&#19968;&#20010;&#37325;&#35201;&#21147;&#37327;&#12290;&#23427;&#20204;&#24378;&#22823;&#30340;&#25512;&#29702;&#33021;&#21147;&#21644;&#24191;&#27867;&#30340;&#30693;&#35782;&#24211;&#20351;&#20854;&#22312;&#21508;&#20010;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#65292;&#21253;&#25324;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#26041;&#38754;&#20855;&#22791;&#20102;&#20986;&#33394;&#30340;&#38646;-shot&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#22312;IR&#20013;&#30340;&#23454;&#29992;&#24615;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#21363;&#22810;&#25991;&#26412;&#29983;&#25104;&#38598;&#25104;&#65288;MuGI&#65289;&#65292;&#26469;&#22686;&#24378;&#29616;&#26377;&#30340;IR&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#23548;LLM&#29983;&#25104;&#22810;&#20010;&#20266;&#21442;&#32771;&#25991;&#29486;&#65292;&#24182;&#23558;&#20854;&#19982;&#26597;&#35810;&#36827;&#34892;&#38598;&#25104;&#20197;&#36827;&#34892;&#26816;&#32034;&#12290;&#26080;&#38656;&#35757;&#32451;&#30340;MuGI&#27169;&#22411;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#26597;&#35810;&#25193;&#23637;&#31574;&#30053;&#65292;&#22312;TREC DL&#25968;&#25454;&#38598;&#19978;&#30340;BM25&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26631;&#20934;&#65292;&#24182;&#22312;BEIR&#19978;&#25552;&#39640;&#20102;7.5%&#12290;&#36890;&#36807;MuGI&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#24555;&#36895;&#19988;&#39640;&#20445;&#30495;&#24230;&#30340;&#37325;&#25490;&#24207;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have emerged as a pivotal force in language technology. Their robust reasoning capabilities and expansive knowledge repositories have enabled exceptional zero-shot generalization abilities across various facets of the natural language processing field, including information retrieval (IR). In this paper, we conduct an in-depth investigation into the utility of documents generated by LLMs for IR. We introduce a simple yet effective framework, Multi-Text Generation Integration (MuGI), to augment existing IR methodologies. Specifically, we prompt LLMs to generate multiple pseudo references and integrate with query for retrieval. The training-free MuGI model eclipses existing query expansion strategies, setting a new standard in sparse retrieval. It outstrips supervised counterparts like ANCE and DPR, achieving a notable over 18% enhancement in BM25 on the TREC DL dataset and a 7.5% increase on BEIR. Through MuGI, we have forged a rapid and high-fidelity re-ran
&lt;/p&gt;</description></item><item><title>&#22810;&#25554;&#27133;&#37325;&#26032;&#25490;&#24207;&#22120;&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#37325;&#26032;&#25490;&#24207;&#26694;&#26550;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#21516;&#26102;&#20248;&#21270;&#30456;&#20851;&#24615;&#12289;&#22810;&#26679;&#24615;&#21644;&#26032;&#40092;&#24230;&#12290;&#23427;&#36890;&#36807;&#24314;&#27169;&#29289;&#21697;&#20043;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#21644;&#21033;&#29992;&#22810;&#20010;&#30446;&#26631;&#30340;&#31532;&#20108;&#27425;&#25490;&#24207;&#24471;&#20998;&#26469;&#25552;&#39640;&#31163;&#32447;AUC&#65292;&#24182;&#36890;&#36807;&#31163;&#32447;&#22238;&#25918;&#29702;&#35770;&#22312;&#22810;&#20010;&#30446;&#26631;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65292;&#36827;&#19968;&#27493;&#25913;&#21892;&#31163;&#32447;&#22238;&#25918;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.06293</link><description>&lt;p&gt;
&#22810;&#25554;&#27133;&#37325;&#26032;&#25490;&#24207;&#22120;: &#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#36890;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#37325;&#26032;&#25490;&#24207;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MultiSlot ReRanker: A Generic Model-based Re-Ranking Framework in Recommendation Systems. (arXiv:2401.06293v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06293
&lt;/p&gt;
&lt;p&gt;
&#22810;&#25554;&#27133;&#37325;&#26032;&#25490;&#24207;&#22120;&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#37325;&#26032;&#25490;&#24207;&#26694;&#26550;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#21516;&#26102;&#20248;&#21270;&#30456;&#20851;&#24615;&#12289;&#22810;&#26679;&#24615;&#21644;&#26032;&#40092;&#24230;&#12290;&#23427;&#36890;&#36807;&#24314;&#27169;&#29289;&#21697;&#20043;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#21644;&#21033;&#29992;&#22810;&#20010;&#30446;&#26631;&#30340;&#31532;&#20108;&#27425;&#25490;&#24207;&#24471;&#20998;&#26469;&#25552;&#39640;&#31163;&#32447;AUC&#65292;&#24182;&#36890;&#36807;&#31163;&#32447;&#22238;&#25918;&#29702;&#35770;&#22312;&#22810;&#20010;&#30446;&#26631;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65292;&#36827;&#19968;&#27493;&#25913;&#21892;&#31163;&#32447;&#22238;&#25918;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#37325;&#26032;&#25490;&#24207;&#26694;&#26550;&#8212;&#8212;&#22810;&#25554;&#27133;&#37325;&#26032;&#25490;&#24207;&#22120;&#65292;&#23427;&#21516;&#26102;&#20248;&#21270;&#30456;&#20851;&#24615;&#12289;&#22810;&#26679;&#24615;&#21644;&#26032;&#40092;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#39034;&#24207;&#36138;&#24515;&#31639;&#27861;&#65288;SGA&#65289;&#36275;&#22815;&#39640;&#25928;&#65288;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24230;&#65289;&#29992;&#20110;&#22823;&#35268;&#27169;&#29983;&#20135;&#25512;&#33616;&#24341;&#25806;&#12290;&#23427;&#22312;&#31163;&#32447;AUC&#65288;&#25509;&#25910;&#22120;&#25805;&#20316;&#29305;&#24449;&#26354;&#32447;&#19979;&#38754;&#31215;&#65289;&#19978;&#21462;&#24471;&#20102;6%&#33267;10%&#30340;&#25552;&#21319;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#22312;&#21015;&#34920;&#20013;&#26126;&#30830;&#24314;&#27169;&#20102;&#29289;&#21697;&#20043;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#65292;&#24182;&#21033;&#29992;&#20102;&#22810;&#20010;&#30446;&#26631;&#30340;&#31532;&#20108;&#27425;&#25490;&#24207;&#24471;&#20998;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#31163;&#32447;&#22238;&#25918;&#29702;&#35770;&#25512;&#24191;&#21040;&#22810;&#25554;&#27133;&#37325;&#26032;&#25490;&#24207;&#22330;&#26223;&#65292;&#36890;&#36807;&#22312;&#22810;&#20010;&#30446;&#26631;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#26469;&#25913;&#21892;&#31163;&#32447;&#22238;&#25918;&#32467;&#26524;&#12290;&#31163;&#32447;&#22238;&#25918;&#32467;&#26524;&#36824;&#21487;&#20197;&#36890;&#36807;Pareto&#26368;&#20248;&#24615;&#36827;&#19968;&#27493;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#22522;&#20110;OpenAI Gym&#21644;Ray&#26694;&#26550;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#25554;&#27133;&#37325;&#26032;&#25490;&#24207;&#27169;&#25311;&#22120;&#12290;&#23427;&#21487;&#20197;&#26681;&#25454;&#19981;&#21516;&#30340;&#20551;&#35774;&#36827;&#34892;&#31616;&#21333;&#37197;&#32622;&#65292;&#24555;&#36895;&#35780;&#20272;&#24378;&#21270;&#23398;&#20064;&#21644;...
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a generic model-based re-ranking framework, MultiSlot ReRanker, which simultaneously optimizes relevance, diversity, and freshness. Specifically, our Sequential Greedy Algorithm (SGA) is efficient enough (linear time complexity) for large-scale production recommendation engines. It achieved a lift of $+6\%$ to $ +10\%$ offline Area Under the receiver operating characteristic Curve (AUC) which is mainly due to explicitly modeling mutual influences among items of a list, and leveraging the second pass ranking scores of multiple objectives. In addition, we have generalized the offline replay theory to multi-slot re-ranking scenarios, with trade-offs among multiple objectives. The offline replay results can be further improved by Pareto Optimality. Moreover, we've built a multi-slot re-ranking simulator based on OpenAI Gym integrated with the Ray framework. It can be easily configured for different assumptions to quickly benchmark both reinforcement learning and s
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#26080;&#30417;&#30563;&#30340;&#35821;&#20041;&#25991;&#26723;&#34920;&#31034;&#20197;&#36827;&#34892;&#32454;&#31890;&#24230;&#30340;&#22522;&#20110;&#26041;&#38754;&#30340;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#20811;&#26381;&#29616;&#26377;&#26041;&#27861;&#30340;&#22256;&#38590;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#27169;&#22411;&#22312;&#21508;&#20010;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.06210</link><description>&lt;p&gt;
&#23398;&#20064;&#26080;&#30417;&#30563;&#30340;&#35821;&#20041;&#25991;&#26723;&#34920;&#31034;&#20197;&#36827;&#34892;&#32454;&#31890;&#24230;&#30340;&#22522;&#20110;&#26041;&#38754;&#30340;&#24773;&#24863;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Learning Unsupervised Semantic Document Representation for Fine-grained Aspect-based Sentiment Analysis. (arXiv:2401.06210v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06210
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#26080;&#30417;&#30563;&#30340;&#35821;&#20041;&#25991;&#26723;&#34920;&#31034;&#20197;&#36827;&#34892;&#32454;&#31890;&#24230;&#30340;&#22522;&#20110;&#26041;&#38754;&#30340;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#20811;&#26381;&#29616;&#26377;&#26041;&#27861;&#30340;&#22256;&#38590;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#27169;&#22411;&#22312;&#21508;&#20010;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26723;&#34920;&#31034;&#26159;&#26426;&#22120;&#29702;&#35299;&#20013;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#26680;&#24515;&#12290;&#20197;&#26080;&#30417;&#30563;&#26041;&#24335;&#23398;&#20064;&#30340;&#19968;&#33324;&#34920;&#31034;&#20445;&#30041;&#20102;&#36890;&#29992;&#24615;&#65292;&#21487;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#24773;&#24863;&#20998;&#26512;&#65288;SA&#65289;&#26159;&#19968;&#20010;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#34987;&#35748;&#20026;&#19982;&#35821;&#20041;&#23494;&#20999;&#30456;&#20851;&#65292;&#24182;&#32463;&#24120;&#29992;&#20110;&#35780;&#20272;&#19968;&#33324;&#34920;&#31034;&#12290;&#29616;&#26377;&#30340;&#26080;&#30417;&#30563;&#25991;&#26723;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#20998;&#20026;&#20004;&#31867;&#65306;&#24207;&#21015;&#26041;&#27861;&#65288;&#26174;&#24335;&#32771;&#34385;&#21333;&#35789;&#30340;&#39034;&#24207;&#65289;&#21644;&#38750;&#24207;&#21015;&#26041;&#27861;&#65288;&#19981;&#26174;&#24335;&#32771;&#34385;&#39034;&#24207;&#65289;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#37117;&#26377;&#21508;&#33258;&#30340;&#32570;&#28857;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#20811;&#26381;&#20102;&#36825;&#20004;&#31867;&#26041;&#27861;&#36935;&#21040;&#30340;&#22256;&#38590;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#27969;&#34892;&#30340;SA&#25968;&#25454;&#38598;&#21644;&#32454;&#31890;&#24230;&#30340;&#22522;&#20110;&#26041;&#38754;&#30340;SA&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Document representation is the core of many NLP tasks on machine understanding. A general representation learned in an unsupervised manner reserves generality and can be used for various applications. In practice, sentiment analysis (SA) has been a challenging task that is regarded to be deeply semantic-related and is often used to assess general representations. Existing methods on unsupervised document representation learning can be separated into two families: sequential ones, which explicitly take the ordering of words into consideration, and non-sequential ones, which do not explicitly do so. However, both of them suffer from their own weaknesses. In this paper, we propose a model that overcomes difficulties encountered by both families of methods. Experiments show that our model outperforms state-of-the-art methods on popular SA datasets and a fine-grained aspect-based SA by a large margin.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#22871;&#32508;&#21512;&#30340;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#25351;&#26631;&#65292;&#21253;&#25324;&#30456;&#20284;&#24615;&#25351;&#26631;&#12289;&#20505;&#36873;&#29983;&#25104;&#25351;&#26631;&#12289;&#39044;&#27979;&#25351;&#26631;&#12289;&#25490;&#24207;&#25351;&#26631;&#21644;&#19994;&#21153;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2312.16015</link><description>&lt;p&gt;
&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#30340;&#32508;&#21512;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Survey of Evaluation Techniques for Recommendation Systems. (arXiv:2312.16015v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.16015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#22871;&#32508;&#21512;&#30340;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#25351;&#26631;&#65292;&#21253;&#25324;&#30456;&#20284;&#24615;&#25351;&#26631;&#12289;&#20505;&#36873;&#29983;&#25104;&#25351;&#26631;&#12289;&#39044;&#27979;&#25351;&#26631;&#12289;&#25490;&#24207;&#25351;&#26631;&#21644;&#19994;&#21153;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#23545;&#20110;&#29992;&#25143;&#22312;&#22312;&#32447;&#24179;&#21488;&#19978;&#30340;&#21442;&#19982;&#21644;&#28385;&#24847;&#24230;&#33267;&#20851;&#37325;&#35201;&#12290;&#38543;&#30528;&#36825;&#20123;&#25512;&#33616;&#31995;&#32479;&#36234;&#26469;&#36234;&#24433;&#21709;&#29992;&#25143;&#30340;&#36873;&#25321;&#65292;&#23427;&#20204;&#30340;&#35780;&#20272;&#19981;&#20165;&#20165;&#23616;&#38480;&#20110;&#25216;&#26415;&#24615;&#33021;&#65292;&#32780;&#21464;&#24471;&#23545;&#20110;&#19994;&#21153;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#22871;&#20840;&#38754;&#30340;&#25351;&#26631;&#26469;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#30340;&#22810;&#26041;&#38754;&#29305;&#24615;&#65292;&#27599;&#20010;&#25351;&#26631;&#19987;&#38376;&#25429;&#25417;&#31995;&#32479;&#24615;&#33021;&#30340;&#19981;&#21516;&#26041;&#38754;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20197;&#19979;&#20960;&#20010;&#26041;&#38754;&#30340;&#25351;&#26631;&#65306;&#30456;&#20284;&#24615;&#25351;&#26631;&#65306;&#29992;&#20110;&#37327;&#21270;&#22522;&#20110;&#20869;&#23481;&#30340;&#36807;&#28388;&#26426;&#21046;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#35780;&#20272;&#21327;&#21516;&#36807;&#28388;&#25216;&#26415;&#30340;&#20934;&#30830;&#24615;&#65307;&#20505;&#36873;&#29983;&#25104;&#25351;&#26631;&#65306;&#29992;&#20110;&#35780;&#20272;&#31995;&#32479;&#26377;&#25928;&#22320;&#35782;&#21035;&#24191;&#27867;&#20294;&#30456;&#20851;&#30340;&#39033;&#30446;&#30340;&#33021;&#21147;&#65307;&#39044;&#27979;&#25351;&#26631;&#65306;&#29992;&#20110;&#35780;&#20272;&#39044;&#27979;&#30340;&#29992;&#25143;&#20559;&#22909;&#30340;&#20934;&#30830;&#24615;&#65307;&#25490;&#24207;&#25351;&#26631;&#65306;&#29992;&#20110;&#35780;&#20272;&#25512;&#33616;&#39034;&#24207;&#30340;&#26377;&#25928;&#24615;&#65307;&#19994;&#21153;&#25351;&#26631;&#65306;&#29992;&#20110;&#23545;&#40784;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The effectiveness of recommendation systems is pivotal to user engagement and satisfaction in online platforms. As these recommendation systems increasingly influence user choices, their evaluation transcends mere technical performance and becomes central to business success. This paper addresses the multifaceted nature of recommendations system evaluation by introducing a comprehensive suite of metrics, each tailored to capture a distinct aspect of system performance. We discuss  * Similarity Metrics: to quantify the precision of content-based filtering mechanisms and assess the accuracy of collaborative filtering techniques.  * Candidate Generation Metrics: to evaluate how effectively the system identifies a broad yet relevant range of items.  * Predictive Metrics: to assess the accuracy of forecasted user preferences.  * Ranking Metrics: to evaluate the effectiveness of the order in which recommendations are presented.  * Business Metrics: to align the performance of the recommendat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#26469;&#21512;&#25104;&#19968;&#20010;&#23567;&#32780;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.09874</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset Condensation for Content-Based Recommendation. (arXiv:2310.09874v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09874
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#26469;&#21512;&#25104;&#19968;&#20010;&#23567;&#32780;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20869;&#23481;&#25512;&#33616;&#65288;CBR&#65289;&#25216;&#26415;&#21033;&#29992;&#29289;&#21697;&#30340;&#20869;&#23481;&#20449;&#24687;&#20026;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#65292;&#20294;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#30340;&#36164;&#28304;&#23494;&#38598;&#22411;&#35757;&#32451;&#23384;&#22312;&#38382;&#39064;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#23545;&#25991;&#26412;CBR&#36827;&#34892;&#25968;&#25454;&#38598;&#21387;&#32553;&#30340;&#26041;&#27861;&#12290;&#25968;&#25454;&#38598;&#21387;&#32553;&#30340;&#30446;&#26631;&#26159;&#21512;&#25104;&#19968;&#20010;&#23567;&#19988;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#27169;&#22411;&#24615;&#33021;&#21487;&#20197;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#23218;&#32654;&#12290;&#29616;&#26377;&#30340;&#21387;&#32553;&#26041;&#27861;&#38024;&#23545;&#36830;&#32493;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#25110;&#23884;&#20837;&#21521;&#37327;&#65289;&#30340;&#20998;&#31867;&#20219;&#21153;&#32780;&#35774;&#35745;&#65292;&#30452;&#25509;&#24212;&#29992;&#20110;CBR&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#39640;&#25928;&#30340;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#12290;&#21463;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25991;&#26412;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#20986;&#33394;&#30340;&#33021;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#21033;&#29992;LLMs&#22312;&#25968;&#25454;&#38598;&#21387;&#32553;&#26399;&#38388;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#12290;&#20026;&#20102;&#22788;&#29702;&#28041;&#21450;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#20132;&#20114;&#25968;&#25454;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21452;...
&lt;/p&gt;
&lt;p&gt;
Modern techniques in Content-based Recommendation (CBR) leverage item content information to provide personalized services to users, but suffer from resource-intensive training on large datasets. To address this issue, we explore the dataset condensation for textual CBR in this paper. The goal of dataset condensation is to synthesize a small yet informative dataset, upon which models can achieve performance comparable to those trained on large datasets. While existing condensation approaches are tailored to classification tasks for continuous data like images or embeddings, direct application of them to CBR has limitations. To bridge this gap, we investigate efficient dataset condensation for content-based recommendation. Inspired by the remarkable abilities of large language models (LLMs) in text comprehension and generation, we leverage LLMs to empower the generation of textual content during condensation. To handle the interaction data involving both users and items, we devise a dua
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#35266;&#27979;&#21040;&#30340;&#32676;&#20307;&#36873;&#25321;&#25968;&#25454;&#38598;&#65292;&#39564;&#35777;&#20102;&#30456;&#36739;&#20110;&#26631;&#20934;&#20559;&#22909;&#32858;&#21512;&#31574;&#30053;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32676;&#20307;&#30340;&#26368;&#32456;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2308.03083</link><description>&lt;p&gt;
&#20174;&#32676;&#20307;&#29305;&#24449;&#39044;&#27979;&#32676;&#20307;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Predicting Group Choices from Group Profiles. (arXiv:2308.03083v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#35266;&#27979;&#21040;&#30340;&#32676;&#20307;&#36873;&#25321;&#25968;&#25454;&#38598;&#65292;&#39564;&#35777;&#20102;&#30456;&#36739;&#20110;&#26631;&#20934;&#20559;&#22909;&#32858;&#21512;&#31574;&#30053;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32676;&#20307;&#30340;&#26368;&#32456;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#36890;&#36807;&#23558;&#32676;&#20307;&#25104;&#21592;&#30340;&#20010;&#20154;&#20559;&#22909;&#36827;&#34892;&#32858;&#21512;&#65292;&#24182;&#36873;&#25321;&#32676;&#20307;&#37197;&#32622;&#25991;&#20214;&#20013;&#24471;&#20998;&#26368;&#39640;&#30340;&#39033;&#30446;&#26469;&#20026;&#32676;&#20307;&#25512;&#33616;&#39033;&#30446;&#12290;&#35813;&#31995;&#32479;&#36890;&#36807;&#20551;&#35774;&#32676;&#20307;&#37319;&#29992;&#19982;&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#30456;&#21516;&#30340;&#20559;&#22909;&#32858;&#21512;&#31574;&#30053;&#26469;&#39044;&#27979;&#36825;&#20123;&#25512;&#33616;&#39033;&#23558;&#34987;&#32676;&#20307;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#32676;&#20307;&#30340;&#36873;&#25321;&#26356;&#21152;&#22797;&#26434;&#65292;&#22240;&#20026;&#32676;&#20307;&#25512;&#33616;&#31995;&#32479;&#26080;&#27861;&#30830;&#20999;&#30693;&#36947;&#32676;&#20307;&#23558;&#20351;&#29992;&#30340;&#20559;&#22909;&#32858;&#21512;&#31574;&#30053;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#35266;&#27979;&#21040;&#30340;&#32676;&#20307;&#36873;&#25321;&#25968;&#25454;&#38598;&#65292;&#39564;&#35777;&#20197;&#19979;&#30740;&#31350;&#20551;&#35774;&#65306;&#30456;&#36739;&#20110;&#26631;&#20934;&#20559;&#22909;&#32858;&#21512;&#31574;&#30053;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32676;&#20307;&#30340;&#26368;&#32456;&#36873;&#25321;&#12290;&#21463;&#20915;&#31574;&#26041;&#26696;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#35813;&#29702;&#35770;&#26368;&#26089;&#35797;&#22270;&#35299;&#20915;&#32676;&#20307;&#36873;&#25321;&#39044;&#27979;&#38382;&#39064;&#65292;&#25105;&#20204;&#23547;&#25214;&#32676;&#20307;&#37197;&#32622;&#25991;&#20214;&#30340;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Group recommender systems (GRSs) identify items to recommend to a group of people by aggregating group members' individual preferences into a group profile, and selecting the items that have the largest score in the group profile. The GRS predicts that these recommendations would be chosen by the group, by assuming that the group is applying the same preference aggregation strategy as the one adopted by the GRS. However, predicting the choice of a group is more complex since the GRS is not aware of the exact preference aggregation strategy that is going to be used by the group.  To this end, the aim of this paper is to validate the research hypothesis that, by using a machine learning approach and a data set of observed group choices, it is possible to predict a group's final choice, better than by using a standard preference aggregation strategy. Inspired by the Decision Scheme theory, which first tried to address the group choice prediction problem, we search for a group profile defi
&lt;/p&gt;</description></item></channel></rss>