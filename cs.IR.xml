<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#20013;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#20851;&#27880;&#20102;&#22312;&#31579;&#36873;&#21644;&#25552;&#21462;&#38454;&#27573;&#30340;&#21322;&#33258;&#21160;&#21270;&#36807;&#31243;&#12290;&#35813;&#30740;&#31350;&#20351;&#29992;&#19968;&#20010;&#21253;&#25324;&#20256;&#32479;&#29305;&#24449;&#21644;&#20154;&#24037;&#26234;&#33021;&#29305;&#24449;&#30340;&#26694;&#26550;&#26469;&#32771;&#23519;21&#20010;&#39046;&#20808;&#30340;&#25991;&#29486;&#32508;&#36848;&#24037;&#20855;&#65292;&#24182;&#20998;&#26512;&#20102;11&#20010;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#29486;&#25628;&#32034;&#21644;&#23398;&#26415;&#20889;&#20316;&#36741;&#21161;&#30340;&#26368;&#26032;&#24037;&#20855;&#12290;&#26368;&#21518;&#65292;&#35770;&#25991;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#24403;&#21069;&#36235;&#21183;&#12289;&#20027;&#35201;&#30740;&#31350;&#25361;&#25112;&#21644;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2402.08565</link><description>&lt;p&gt;
&#25991;&#29486;&#32508;&#36848;&#20013;&#30340;&#20154;&#24037;&#26234;&#33021;&#65306;&#26426;&#36935;&#19982;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence for Literature Reviews: Opportunities and Challenges
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08565
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#20013;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#20851;&#27880;&#20102;&#22312;&#31579;&#36873;&#21644;&#25552;&#21462;&#38454;&#27573;&#30340;&#21322;&#33258;&#21160;&#21270;&#36807;&#31243;&#12290;&#35813;&#30740;&#31350;&#20351;&#29992;&#19968;&#20010;&#21253;&#25324;&#20256;&#32479;&#29305;&#24449;&#21644;&#20154;&#24037;&#26234;&#33021;&#29305;&#24449;&#30340;&#26694;&#26550;&#26469;&#32771;&#23519;21&#20010;&#39046;&#20808;&#30340;&#25991;&#29486;&#32508;&#36848;&#24037;&#20855;&#65292;&#24182;&#20998;&#26512;&#20102;11&#20010;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#29486;&#25628;&#32034;&#21644;&#23398;&#26415;&#20889;&#20316;&#36741;&#21161;&#30340;&#26368;&#26032;&#24037;&#20855;&#12290;&#26368;&#21518;&#65292;&#35770;&#25991;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#24403;&#21069;&#36235;&#21183;&#12289;&#20027;&#35201;&#30740;&#31350;&#25361;&#25112;&#21644;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20154;&#24037;&#26234;&#33021;&#22312;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65288;SLR&#65289;&#20013;&#30340;&#24212;&#29992;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#32508;&#36848;&#12290;SLR&#26159;&#19968;&#31181;&#20005;&#35880;&#26377;&#24207;&#30340;&#26041;&#27861;&#35770;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#25972;&#21512;&#20851;&#20110;&#29305;&#23450;&#20027;&#39064;&#30340;&#20808;&#21069;&#30740;&#31350;&#12290;&#35768;&#22810;&#24037;&#20855;&#24050;&#34987;&#24320;&#21457;&#29992;&#20110;&#36741;&#21161;&#21644;&#37096;&#20998;&#33258;&#21160;&#21270;SLR&#36807;&#31243;&#12290;&#20154;&#24037;&#26234;&#33021;&#22312;&#36825;&#20010;&#39046;&#22495;&#30340;&#26085;&#30410;&#37325;&#35201;&#35282;&#33394;&#26174;&#31034;&#20102;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#26356;&#26377;&#25928;&#25903;&#25345;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#26397;&#30528;&#25991;&#29486;&#32508;&#36848;&#30340;&#21322;&#33258;&#21160;&#21270;&#21019;&#24314;&#26041;&#21521;&#21457;&#23637;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#37325;&#28857;&#20851;&#27880;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#22312;SLR&#30340;&#21322;&#33258;&#21160;&#21270;&#20013;&#30340;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#31579;&#36873;&#21644;&#25552;&#21462;&#38454;&#27573;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#23558;23&#20010;&#20256;&#32479;&#29305;&#24449;&#19982;11&#20010;&#20154;&#24037;&#26234;&#33021;&#29305;&#24449;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#65292;&#23545;21&#20010;&#39046;&#20808;&#30340;SLR&#24037;&#20855;&#36827;&#34892;&#20102;&#32771;&#23519;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#29486;&#25628;&#32034;&#21644;&#36741;&#21161;&#23398;&#26415;&#20889;&#20316;&#30340;11&#20010;&#26368;&#26032;&#24037;&#20855;&#12290;&#26368;&#21518;&#65292;&#26412;&#25991;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#24403;&#21069;&#36235;&#21183;&#65292;&#27010;&#36848;&#20102;&#20027;&#35201;&#30340;&#30740;&#31350;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This manuscript presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates previous research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#22270;&#20687;&#21040;&#25991;&#26412;&#27169;&#22411;&#26469;&#22686;&#24378;&#22522;&#20110;&#25991;&#26412;&#30340;&#29289;&#21697;&#26816;&#32034;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#33021;&#22815;&#25552;&#39640;&#29616;&#26377;&#25991;&#26412;&#30340;&#26816;&#32034;&#25928;&#26524;&#24182;&#29983;&#25104;&#39640;&#24230;&#21487;&#25628;&#32034;&#30340;&#29420;&#31435;&#25551;&#36848;&#12290;</title><link>https://arxiv.org/abs/2402.08532</link><description>&lt;p&gt;
&#26631;&#39064;&#65306;&#23383;&#24149;&#32988;&#36807;&#21315;&#35328;&#19975;&#35821;&#65306;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22270;&#20687;&#21040;&#25991;&#26412;&#27169;&#22411;&#22686;&#24378;&#20135;&#21697;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Captions Are Worth a Thousand Words: Enhancing Product Retrieval with Pretrained Image-to-Text Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#22270;&#20687;&#21040;&#25991;&#26412;&#27169;&#22411;&#26469;&#22686;&#24378;&#22522;&#20110;&#25991;&#26412;&#30340;&#29289;&#21697;&#26816;&#32034;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#33021;&#22815;&#25552;&#39640;&#29616;&#26377;&#25991;&#26412;&#30340;&#26816;&#32034;&#25928;&#26524;&#24182;&#29983;&#25104;&#39640;&#24230;&#21487;&#25628;&#32034;&#30340;&#29420;&#31435;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#22810;&#27169;&#24577;&#22270;&#20687;&#21040;&#25991;&#26412;&#27169;&#22411;&#26469;&#22686;&#24378;&#22522;&#20110;&#25991;&#26412;&#30340;&#29289;&#21697;&#26816;&#32034;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22270;&#20687;&#23383;&#24149;&#21644;&#26631;&#35760;&#27169;&#22411;&#65292;&#22914;instructBLIP&#21644;CLIP&#65292;&#29983;&#25104;&#22522;&#20110;&#25991;&#26412;&#30340;&#20135;&#21697;&#25551;&#36848;&#65292;&#24182;&#23558;&#20854;&#19982;&#29616;&#26377;&#30340;&#25991;&#26412;&#25551;&#36848;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#20110;&#26080;&#27861;&#32500;&#25252;&#39640;&#36136;&#37327;&#25991;&#26412;&#25551;&#36848;&#20197;&#26377;&#25928;&#22320;&#25191;&#34892;&#25628;&#32034;&#21644;&#25512;&#33616;&#29992;&#20363;&#30340;&#23567;&#22411;&#30005;&#23376;&#21830;&#21153;&#20225;&#19994;&#23588;&#20026;&#37325;&#35201;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;Amazon&#20844;&#24320;&#21487;&#29992;&#30340;ESCI&#25968;&#25454;&#38598;&#30340;&#20960;&#20010;&#23376;&#38598;&#19978;&#30340;&#30495;&#23454;&#25991;&#26412;&#12289;&#22270;&#20687;&#29983;&#25104;&#25991;&#26412;&#20197;&#21450;&#20004;&#32773;&#30340;&#32452;&#21512;&#30340;&#21487;&#25628;&#32034;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#20855;&#26377;&#22686;&#24378;&#29616;&#26377;&#25991;&#26412;&#26816;&#32034;&#21644;&#29983;&#25104;&#39640;&#24230;&#21487;&#25628;&#32034;&#29420;&#31435;&#25551;&#36848;&#30340;&#21452;&#37325;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the usage of multimodal image-to-text models to enhance text-based item retrieval. We propose utilizing pre-trained image captioning and tagging models, such as instructBLIP and CLIP, to generate text-based product descriptions which are combined with existing text descriptions. Our work is particularly impactful for smaller eCommerce businesses who are unable to maintain the high-quality text descriptions necessary to effectively perform item retrieval for search and recommendation use cases. We evaluate the searchability of ground-truth text, image-generated text, and combinations of both texts on several subsets of Amazon's publicly available ESCI dataset. The results demonstrate the dual capability of our proposed models to enhance the retrieval of existing text and generate highly-searchable standalone descriptions.
&lt;/p&gt;</description></item><item><title>&#38754;&#21521;&#21327;&#21516;&#36807;&#28388;&#30340;&#39057;&#29575;&#24863;&#30693;&#22270;&#20449;&#21495;&#22788;&#29702;&#26041;&#27861;&#65288;FaGSP&#65289;&#37319;&#29992;&#32423;&#32852;&#28388;&#27874;&#27169;&#22359;&#21644;&#24182;&#34892;&#28388;&#27874;&#27169;&#22359;&#65292;&#26088;&#22312;&#26356;&#20934;&#30830;&#22320;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#24182;&#21033;&#29992;&#39640;&#38454;&#37051;&#22495;&#20449;&#24687;&#65292;&#20197;&#25552;&#39640;&#21327;&#21516;&#36807;&#28388;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08426</link><description>&lt;p&gt;
&#38754;&#21521;&#21327;&#21516;&#36807;&#28388;&#30340;&#39057;&#29575;&#24863;&#30693;&#22270;&#20449;&#21495;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Frequency-aware Graph Signal Processing for Collaborative Filtering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08426
&lt;/p&gt;
&lt;p&gt;
&#38754;&#21521;&#21327;&#21516;&#36807;&#28388;&#30340;&#39057;&#29575;&#24863;&#30693;&#22270;&#20449;&#21495;&#22788;&#29702;&#26041;&#27861;&#65288;FaGSP&#65289;&#37319;&#29992;&#32423;&#32852;&#28388;&#27874;&#27169;&#22359;&#21644;&#24182;&#34892;&#28388;&#27874;&#27169;&#22359;&#65292;&#26088;&#22312;&#26356;&#20934;&#30830;&#22320;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#24182;&#21033;&#29992;&#39640;&#38454;&#37051;&#22495;&#20449;&#24687;&#65292;&#20197;&#25552;&#39640;&#21327;&#21516;&#36807;&#28388;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#22522;&#20110;&#22270;&#20449;&#21495;&#22788;&#29702;&#65288;GSP&#65289;&#30340;&#25512;&#33616;&#31639;&#27861;&#22240;&#20854;&#39640;&#25928;&#24615;&#32780;&#22791;&#21463;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#26410;&#32771;&#34385;&#21040;&#21453;&#26144;&#29992;&#25143;/&#29289;&#21697;&#29305;&#24449;&#30340;&#21508;&#31181;&#20132;&#20114;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#26410;&#21033;&#29992;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#39640;&#38454;&#37051;&#22495;&#20449;&#24687;&#26469;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#65292;&#20174;&#32780;&#23548;&#33268;&#23376;&#20248;&#24615;&#33021;&#12290;&#20026;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#21327;&#21516;&#36807;&#28388;&#30340;&#39057;&#29575;&#24863;&#30693;&#22270;&#20449;&#21495;&#22788;&#29702;&#26041;&#27861;&#65288;FaGSP&#65289;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#32423;&#32852;&#28388;&#27874;&#27169;&#22359;&#65292;&#30001;&#29702;&#24819;&#30340;&#39640;&#36890;&#28388;&#27874;&#22120;&#21644;&#29702;&#24819;&#30340;&#20302;&#36890;&#28388;&#27874;&#22120;&#32452;&#25104;&#65292;&#20197;&#36830;&#32493;&#30340;&#26041;&#24335;&#25429;&#33719;&#29420;&#29305;&#21644;&#20849;&#21516;&#30340;&#29992;&#25143;/&#29289;&#21697;&#29305;&#24449;&#65292;&#26356;&#20934;&#30830;&#22320;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#24182;&#34892;&#28388;&#27874;&#27169;&#22359;&#65292;&#30001;&#20004;&#20010;&#20302;&#36890;&#28388;&#27874;&#22120;&#32452;&#25104;&#65292;&#21487;&#20197;&#36731;&#26494;&#25429;&#33719;&#37051;&#22495;&#30340;&#23618;&#27425;&#32467;&#26500;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#21033;&#29992;&#29992;&#25143;/&#29289;&#21697;&#30340;&#39640;&#38454;&#37051;&#22495;&#20449;&#24687;&#36827;&#34892;&#29992;&#25143;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Signal Processing (GSP) based recommendation algorithms have recently attracted lots of attention due to its high efficiency. However, these methods failed to consider the importance of various interactions that reflect unique user/item characteristics and failed to utilize user and item high-order neighborhood information to model user preference, thus leading to sub-optimal performance. To address the above issues, we propose a frequency-aware graph signal processing method (FaGSP) for collaborative filtering. Firstly, we design a Cascaded Filter Module, consisting of an ideal high-pass filter and an ideal low-pass filter that work in a successive manner, to capture both unique and common user/item characteristics to more accurately model user preference. Then, we devise a Parallel Filter Module, consisting of two low-pass filters that can easily capture the hierarchy of neighborhood, to fully utilize high-order neighborhood information of users/items for more accurate user pre
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#30005;&#23376;&#21830;&#21153;&#20449;&#24687;&#31995;&#32479;&#20013;&#23454;&#29616;&#25512;&#33616;&#20250;&#35805;&#31639;&#27861; (ARS) &#24182;&#20998;&#26512;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#21442;&#25968;&#12290;ARS&#31639;&#27861;&#36890;&#36807;&#22270;&#21644;&#32593;&#32476;&#29702;&#35770;&#26500;&#24314;&#25512;&#33616;&#20250;&#35805;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#20010;&#25805;&#20316;&#24615;&#30005;&#23376;&#21830;&#21153;&#20449;&#24687;&#31995;&#32479;&#20013;&#23454;&#38469;&#23454;&#29616;&#65292;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08275</link><description>&lt;p&gt;
&#22522;&#20110;&#25512;&#33616;&#20250;&#35805;&#30340;&#30005;&#23376;&#21830;&#21153;&#20449;&#24687;&#31995;&#32479;&#20013;&#25512;&#33616;&#31639;&#27861;&#30340;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
Implementation of Recommendation Algorithm based on Recommendation Sessions in E-commerce IT System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08275
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#30005;&#23376;&#21830;&#21153;&#20449;&#24687;&#31995;&#32479;&#20013;&#23454;&#29616;&#25512;&#33616;&#20250;&#35805;&#31639;&#27861; (ARS) &#24182;&#20998;&#26512;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#21442;&#25968;&#12290;ARS&#31639;&#27861;&#36890;&#36807;&#22270;&#21644;&#32593;&#32476;&#29702;&#35770;&#26500;&#24314;&#25512;&#33616;&#20250;&#35805;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#20010;&#25805;&#20316;&#24615;&#30005;&#23376;&#21830;&#21153;&#20449;&#24687;&#31995;&#32479;&#20013;&#23454;&#38469;&#23454;&#29616;&#65292;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#25805;&#20316;&#24615;&#30005;&#23376;&#21830;&#21153;&#20449;&#24687;&#31995;&#32479;&#20013;&#23454;&#29616;&#20316;&#32773;&#30340;&#25512;&#33616;&#20250;&#35805;&#31639;&#27861; (ARS) &#30340;&#30740;&#31350;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#21442;&#25968;&#12290;&#25991;&#31456;&#39318;&#20808;&#32508;&#21512;&#27010;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#65292;&#28982;&#21518;&#20171;&#32461;&#20102;&#22522;&#20110;&#25512;&#33616;&#20250;&#35805;&#30340;&#19987;&#26377;ARS&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#22270;&#21644;&#32593;&#32476;&#29702;&#35770;&#26500;&#24314;&#20102;&#25512;&#33616;&#20250;&#35805;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#20316;&#20026;ARS&#31639;&#27861;&#30340;&#36755;&#20837;&#12290;&#26412;&#25991;&#36824;&#25506;&#35752;&#20102;&#22270;&#32467;&#26500;&#34920;&#31034;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;SQL&#26631;&#20934;&#22312;&#20851;&#31995;&#25968;&#25454;&#24211;&#20013;&#23454;&#29616;&#20102;&#20195;&#34920;&#19968;&#32452;&#25512;&#33616;&#20250;&#35805;&#30340;G&#22270;&#12290;ARS&#31639;&#27861;&#22312;&#19968;&#20010;&#25805;&#20316;&#24615;&#30005;&#23376;&#21830;&#21153;&#20449;&#24687;&#31995;&#32479;&#20013;&#24471;&#21040;&#20102;&#23454;&#38469;&#23454;&#29616;&#65292;&#20174;&#32780;&#24320;&#21457;&#20986;&#20102;&#19968;&#20010;&#23436;&#20840;&#36866;&#24212;&#21508;&#31181;&#30005;&#23376;&#21830;&#21153;&#20449;&#24687;&#31995;&#32479;&#30340;&#21487;&#35843;&#25972;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#36890;&#36807;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a study on the implementation of the author's Algorithm of Recommendation Sessions (ARS) in an operational e-commerce information system and analyses the basic parameters of the resulting recommendation system. It begins with a synthetic overview of recommendation systems, followed by a presentation of the proprietary ARS algorithm, which is based on recommendation sessions. A mathematical model of the recommendation session, constructed using graph and network theory, serves as the input for the ARS algorithm. This paper also explores graph structure representation methods and the implementation of a G graph (representing a set of recommendation sessions) in a relational database using the SQL standard. The ARS algorithm was implemented in a working e-commerce information system, leading to the development of a fully functional recommendation system adaptable to various e-commerce IT systems. The effectiveness of the algorithm is demonstrated by research on the rec
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;MOOCs&#20013;&#24179;&#34913;&#26174;&#24335;&#21644;&#38544;&#24335;&#20851;&#31995;&#36827;&#34892;&#30693;&#35782;&#27010;&#24565;&#25512;&#33616;&#12290;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;MOOCs&#30340;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;(HIN)&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#21644;&#23398;&#20064;&#38544;&#24335;&#20851;&#31995;&#65292;&#20174;&#32780;&#25552;&#39640;&#30693;&#35782;&#27010;&#24565;&#25512;&#33616;&#30340;&#24615;&#33021;&#24182;&#28385;&#36275;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.08256</link><description>&lt;p&gt;
&#22312;MOOC&#20013;&#20197;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#24335;&#24314;&#27169;&#24179;&#34913;&#26174;&#24335;&#21644;&#38544;&#24335;&#20851;&#31995;&#65292;&#29992;&#20110;&#30693;&#35782;&#27010;&#24565;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Modeling Balanced Explicit and Implicit Relations with Contrastive Learning for Knowledge Concept Recommendation in MOOCs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;MOOCs&#20013;&#24179;&#34913;&#26174;&#24335;&#21644;&#38544;&#24335;&#20851;&#31995;&#36827;&#34892;&#30693;&#35782;&#27010;&#24565;&#25512;&#33616;&#12290;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;MOOCs&#30340;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;(HIN)&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#21644;&#23398;&#20064;&#38544;&#24335;&#20851;&#31995;&#65292;&#20174;&#32780;&#25552;&#39640;&#30693;&#35782;&#27010;&#24565;&#25512;&#33616;&#30340;&#24615;&#33021;&#24182;&#28385;&#36275;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#24320;&#25918;&#22312;&#32447;&#35838;&#31243;(MOOCs)&#20013;&#65292;&#30693;&#35782;&#27010;&#24565;&#25512;&#33616;&#26159;&#19968;&#20010;&#22791;&#21463;&#20851;&#27880;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;MOOC&#24179;&#21488;&#19978;&#29992;&#25143;&#21644;&#30693;&#35782;&#27010;&#24565;&#20043;&#38388;&#30340;&#26174;&#24335;&#20851;&#31995;&#36827;&#34892;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#22312;&#29992;&#25143;&#30340;&#23398;&#20064;&#27963;&#21160;&#20013;&#20250;&#20135;&#29983;&#22823;&#37327;&#38544;&#24335;&#20851;&#31995;&#65288;&#20363;&#22914;&#65292;&#20849;&#21516;&#20852;&#36259;&#25110;&#30456;&#21516;&#30340;&#30693;&#35782;&#27700;&#24179;&#65289;&#65292;&#29616;&#26377;&#26041;&#27861;&#26410;&#33021;&#32771;&#34385;&#36825;&#20123;&#38544;&#24335;&#20851;&#31995;&#65292;&#24182;&#19988;&#36825;&#20123;&#20851;&#31995;&#26412;&#36523;&#24456;&#38590;&#23398;&#20064;&#21644;&#34920;&#31034;&#65292;&#23548;&#33268;&#30693;&#35782;&#27010;&#24565;&#25512;&#33616;&#34920;&#29616;&#19981;&#20339;&#65292;&#26080;&#27861;&#28385;&#36275;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#38656;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;MOOCs&#20013;&#34920;&#31034;&#21644;&#24179;&#34913;&#26174;&#24335;&#21644;&#38544;&#24335;&#20851;&#31995;&#36827;&#34892;&#30693;&#35782;&#27010;&#24565;&#25512;&#33616;&#65288;CL-KCRec&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#23545;MOOCs&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;(HIN)&#36827;&#34892;&#24314;&#27169;&#26469;&#26500;&#24314;&#19968;&#20010;HIN&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The knowledge concept recommendation in Massive Open Online Courses (MOOCs) is a significant issue that has garnered widespread attention. Existing methods primarily rely on the explicit relations between users and knowledge concepts on the MOOC platforms for recommendation. However, there are numerous implicit relations (e.g., shared interests or same knowledge levels between users) generated within the users' learning activities on the MOOC platforms. Existing methods fail to consider these implicit relations, and these relations themselves are difficult to learn and represent, causing poor performance in knowledge concept recommendation and an inability to meet users' personalized needs. To address this issue, we propose a novel framework based on contrastive learning, which can represent and balance the explicit and implicit relations for knowledge concept recommendation in MOOCs (CL-KCRec). Specifically, we first construct a MOOCs heterogeneous information network (HIN) by modelin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#36848;&#20102;&#20174;&#22240;&#26524;&#23398;&#20064;&#30340;&#35282;&#24230;&#23545;&#21487;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#35843;&#26597;&#12290;&#22240;&#26524;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;TRS&#20013;&#28508;&#22312;&#20559;&#35265;&#21644;&#22122;&#22768;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#39046;&#22495;&#20013;&#65292;&#32570;&#20047;&#19968;&#20010;&#21450;&#26102;&#30340;&#35843;&#26597;&#12290;</title><link>https://arxiv.org/abs/2402.08241</link><description>&lt;p&gt;
&#21487;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#22240;&#26524;&#25512;&#29702;&#25216;&#26415;&#65306;&#19968;&#39033;&#35843;&#26597;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Causal Learning for Trustworthy Recommender Systems: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;&#20174;&#22240;&#26524;&#23398;&#20064;&#30340;&#35282;&#24230;&#23545;&#21487;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#35843;&#26597;&#12290;&#22240;&#26524;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;TRS&#20013;&#28508;&#22312;&#20559;&#35265;&#21644;&#22122;&#22768;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#39046;&#22495;&#20013;&#65292;&#32570;&#20047;&#19968;&#20010;&#21450;&#26102;&#30340;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#22312;&#22312;&#32447;&#20869;&#23481;&#21457;&#29616;&#21644;&#20010;&#24615;&#21270;&#20915;&#31574;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;RS&#20013;&#20986;&#29616;&#30340;&#28431;&#27934;&#20419;&#20351;&#20102;&#21521;&#21487;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#65288;TRS&#65289;&#30340;&#33539;&#24335;&#36716;&#21464;&#12290;&#23613;&#31649;TRS&#21462;&#24471;&#20102;&#35768;&#22810;&#36827;&#23637;&#65292;&#20294;&#22823;&#37096;&#20998;&#37117;&#38598;&#20013;&#22312;&#25968;&#25454;&#30456;&#20851;&#24615;&#19978;&#65292;&#32780;&#24573;&#35270;&#20102;&#25512;&#33616;&#20013;&#30340;&#22522;&#26412;&#22240;&#26524;&#20851;&#31995;&#12290;&#36825;&#20010;&#32570;&#28857;&#38459;&#30861;&#20102;TRS&#22312;&#35299;&#20915;&#21487;&#20449;&#36182;&#24615;&#38382;&#39064;&#26102;&#35782;&#21035;&#21407;&#22240;&#65292;&#23548;&#33268;&#20844;&#24179;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#21463;&#21040;&#38480;&#21046;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#22240;&#26524;&#23398;&#20064;&#20316;&#20026;&#19968;&#31867;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#20986;&#29616;&#65292;&#20197;&#22686;&#24378;TRS&#12290;&#36825;&#20123;&#26041;&#27861;&#20197;&#21487;&#38752;&#30340;&#22240;&#26524;&#20851;&#31995;&#20026;&#22522;&#30784;&#65292;&#22312;&#20943;&#36731;&#21508;&#31181;&#20559;&#35265;&#21644;&#22122;&#22768;&#30340;&#21516;&#26102;&#65292;&#20026;TRS&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#39046;&#22495;&#20013;&#65292;&#32570;&#20047;&#19968;&#20010;&#21450;&#26102;&#30340;&#35843;&#26597;&#12290;&#26412;&#25991;&#20174;&#22240;&#26524;&#23398;&#20064;&#30340;&#35282;&#24230;&#23545;TRS&#36827;&#34892;&#20102;&#27010;&#36848;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#22240;&#26524;&#23548;&#21521;TRS&#65288;CTRS&#65289;&#30340;&#20248;&#21183;&#21644;&#24120;&#35265;&#31243;&#24207;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#28508;&#22312;&#30340;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;&#22312;TRS&#20013;&#30340;&#24212;&#29992;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender Systems (RS) have significantly advanced online content discovery and personalized decision-making. However, emerging vulnerabilities in RS have catalyzed a paradigm shift towards Trustworthy RS (TRS). Despite numerous progress on TRS, most of them focus on data correlations while overlooking the fundamental causal nature in recommendation. This drawback hinders TRS from identifying the cause in addressing trustworthiness issues, leading to limited fairness, robustness, and explainability. To bridge this gap, causal learning emerges as a class of promising methods to augment TRS. These methods, grounded in reliable causality, excel in mitigating various biases and noises while offering insightful explanations for TRS. However, there lacks a timely survey in this vibrant area. This paper creates an overview of TRS from the perspective of causal learning. We begin by presenting the advantages and common procedures of Causality-oriented TRS (CTRS). Then, we identify potential 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#21830;&#19994;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20316;&#29992;&#65292;&#30528;&#37325;&#30740;&#31350;&#20102;&#25968;&#25454;&#28304;&#12289;&#29305;&#24449;&#24037;&#31243;&#21644;&#35780;&#20272;&#25351;&#26631;&#31561;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#31361;&#26174;&#20102;&#25512;&#33616;&#24341;&#25806;&#23545;&#29992;&#25143;&#20307;&#39564;&#21644;&#20915;&#31574;&#36807;&#31243;&#30340;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.08109</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#21040;&#20915;&#31574;&#65306;&#26426;&#22120;&#23398;&#20064;&#22312;&#21830;&#19994;&#25512;&#33616;&#20013;&#30340;&#36716;&#21464;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
From Data to Decisions: The Transformational Power of Machine Learning in Business Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#21830;&#19994;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20316;&#29992;&#65292;&#30528;&#37325;&#30740;&#31350;&#20102;&#25968;&#25454;&#28304;&#12289;&#29305;&#24449;&#24037;&#31243;&#21644;&#35780;&#20272;&#25351;&#26631;&#31561;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#31361;&#26174;&#20102;&#25512;&#33616;&#24341;&#25806;&#23545;&#29992;&#25143;&#20307;&#39564;&#21644;&#20915;&#31574;&#36807;&#31243;&#30340;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#35752;&#26426;&#22120;&#23398;&#20064;&#23545;&#25512;&#33616;&#31995;&#32479;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#28436;&#21464;&#21644;&#26377;&#25928;&#24615;&#30340;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#22312;&#23427;&#20204;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#26085;&#30410;&#37325;&#35201;&#30340;&#32972;&#26223;&#19979;&#12290;&#22312;&#26041;&#27861;&#35770;&#19978;&#65292;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#22609;&#36896;&#21644;&#25913;&#36827;&#30340;&#20316;&#29992;&#65292;&#30528;&#37325;&#30740;&#31350;&#25968;&#25454;&#26469;&#28304;&#12289;&#29305;&#24449;&#24037;&#31243;&#21644;&#35780;&#20272;&#25351;&#26631;&#30340;&#37325;&#35201;&#24615;&#65292;&#20174;&#32780;&#31361;&#26174;&#20102;&#22686;&#24378;&#25512;&#33616;&#31639;&#27861;&#30340;&#36845;&#20195;&#24615;&#36136;&#12290;&#30740;&#31350;&#36824;&#25506;&#35752;&#20102;&#25512;&#33616;&#24341;&#25806;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#39640;&#32423;&#31639;&#27861;&#21644;&#25968;&#25454;&#20998;&#26512;&#39537;&#21160;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#23545;&#29992;&#25143;&#20307;&#39564;&#21644;&#20915;&#31574;&#36807;&#31243;&#30340;&#37325;&#35201;&#24433;&#21709;&#12290;&#36825;&#20123;&#24341;&#25806;&#19981;&#20165;&#31616;&#21270;&#20102;&#20449;&#24687;&#21457;&#29616;&#21644;&#22686;&#24378;&#20102;&#21327;&#20316;&#65292;&#36824;&#21152;&#24555;&#20102;&#30693;&#35782;&#33719;&#21462;&#65292;&#23545;&#20225;&#19994;&#22312;&#25968;&#23383;&#21270;&#39046;&#22495;&#20013;&#30340;&#23548;&#33322;&#33267;&#20851;&#37325;&#35201;&#12290;&#23427;&#20204;&#23545;&#38144;&#21806;&#12289;&#25910;&#20837;&#21644;&#20225;&#19994;&#31454;&#20105;&#20248;&#21183;&#30340;&#36129;&#29486;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research aims to explore the impact of Machine Learning (ML) on the evolution and efficacy of Recommendation Systems (RS), particularly in the context of their growing significance in commercial business environments. Methodologically, the study delves into the role of ML in crafting and refining these systems, focusing on aspects such as data sourcing, feature engineering, and the importance of evaluation metrics, thereby highlighting the iterative nature of enhancing recommendation algorithms. The deployment of Recommendation Engines (RE), driven by advanced algorithms and data analytics, is explored across various domains, showcasing their significant impact on user experience and decision-making processes. These engines not only streamline information discovery and enhance collaboration but also accelerate knowledge acquisition, proving vital in navigating the digital landscape for businesses. They contribute significantly to sales, revenue, and the competitive edge of enterpr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#20302;&#32500;&#21270;&#23398;&#23884;&#20837;&#32467;&#21512;k-d&#26641;&#25968;&#25454;&#32467;&#26500;&#26159;&#21542;&#33021;&#22815;&#22312;&#20445;&#25345;&#23545;&#26631;&#20934;&#21270;&#23398;&#30456;&#20284;&#24615;&#25628;&#32034;&#22522;&#20934;&#24615;&#33021;&#30340;&#21516;&#26102;&#23454;&#29616;&#24555;&#36895;&#26368;&#36817;&#37051;&#26597;&#35810;</title><link>https://arxiv.org/abs/2402.07970</link><description>&lt;p&gt;
&#21033;&#29992;&#20302;&#32500;&#20998;&#23376;&#23884;&#20837;&#36827;&#34892;&#24555;&#36895;&#21270;&#23398;&#30456;&#20284;&#24615;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Utilizing Low-Dimensional Molecular Embeddings for Rapid Chemical Similarity Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#20302;&#32500;&#21270;&#23398;&#23884;&#20837;&#32467;&#21512;k-d&#26641;&#25968;&#25454;&#32467;&#26500;&#26159;&#21542;&#33021;&#22815;&#22312;&#20445;&#25345;&#23545;&#26631;&#20934;&#21270;&#23398;&#30456;&#20284;&#24615;&#25628;&#32034;&#22522;&#20934;&#24615;&#33021;&#30340;&#21516;&#26102;&#23454;&#29616;&#24555;&#36895;&#26368;&#36817;&#37051;&#26597;&#35810;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#37051;&#30456;&#20284;&#24615;&#25628;&#32034;&#26159;&#21270;&#23398;&#39046;&#22495;&#20013;&#24120;&#35265;&#30340;&#20219;&#21153;&#65292;&#22312;&#33647;&#29289;&#21457;&#29616;&#31561;&#39046;&#22495;&#26377;&#30528;&#26174;&#33879;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#19968;&#20123;&#24120;&#29992;&#30340;&#26041;&#27861;&#20173;&#28982;&#37319;&#29992;&#34542;&#21147;&#25628;&#32034;&#30340;&#26041;&#24335;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#20250;&#36896;&#25104;&#35745;&#31639;&#25104;&#26412;&#39640;&#21644;&#26102;&#38388;&#28040;&#32791;&#22823;&#30340;&#38382;&#39064;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#29616;&#20195;&#21270;&#23398;&#25968;&#25454;&#24211;&#30340;&#35268;&#27169;&#20043;&#22823;&#12290;&#20197;&#24448;&#23545;&#36825;&#19968;&#20219;&#21153;&#30340;&#35745;&#31639;&#25216;&#26415;&#36827;&#23637;&#20027;&#35201;&#20381;&#36182;&#20110;&#30828;&#20214;&#25913;&#36827;&#25110;&#29305;&#23450;&#25968;&#25454;&#38598;&#30340;&#25216;&#24039;&#65292;&#32570;&#20047;&#26222;&#36866;&#24615;&#12290;&#32780;&#21033;&#29992;&#20302;&#22797;&#26434;&#24230;&#30340;&#25628;&#32034;&#31639;&#27861;&#30340;&#26041;&#27861;&#30456;&#23545;&#36739;&#23569;&#34987;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#36825;&#31867;&#31639;&#27861;&#37117;&#26159;&#36817;&#20284;&#35299;&#20915;&#26041;&#26696;&#65292;&#25110;&#32773;&#22312;&#20856;&#22411;&#30340;&#39640;&#32500;&#21270;&#23398;&#23884;&#20837;&#20013;&#23384;&#22312;&#22256;&#38590;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#20302;&#32500;&#21270;&#23398;&#23884;&#20837;&#32467;&#21512;k-d&#26641;&#25968;&#25454;&#32467;&#26500;&#26159;&#21542;&#33021;&#22815;&#22312;&#20445;&#25345;&#23545;&#26631;&#20934;&#21270;&#23398;&#30456;&#20284;&#24615;&#25628;&#32034;&#22522;&#20934;&#24615;&#33021;&#30340;&#21516;&#26102;&#23454;&#29616;&#24555;&#36895;&#26368;&#36817;&#37051;&#26597;&#35810;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#30340;&#38477;&#32500;&#26041;&#27861;&#36827;
&lt;/p&gt;
&lt;p&gt;
Nearest neighbor-based similarity searching is a common task in chemistry, with notable use cases in drug discovery. Yet, some of the most commonly used approaches for this task still leverage a brute-force approach. In practice this can be computationally costly and overly time-consuming, due in part to the sheer size of modern chemical databases. Previous computational advancements for this task have generally relied on improvements to hardware or dataset-specific tricks that lack generalizability. Approaches that leverage lower-complexity searching algorithms remain relatively underexplored. However, many of these algorithms are approximate solutions and/or struggle with typical high-dimensional chemical embeddings. Here we evaluate whether a combination of low-dimensional chemical embeddings and a k-d tree data structure can achieve fast nearest neighbor queries while maintaining performance on standard chemical similarity search benchmarks. We examine different dimensionality redu
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#25968;&#25454;&#21019;&#24314;&#32773;&#21644;&#25968;&#25454;&#37325;&#29992;&#32773;&#20043;&#38388;&#36317;&#31163;&#30340;&#29702;&#35770;&#26500;&#24314;&#65292;&#24182;&#30830;&#23450;&#20102;&#24433;&#21709;&#26377;&#25928;&#20256;&#36882;&#30693;&#35782;&#33021;&#21147;&#30340;&#20845;&#20010;&#36317;&#31163;&#32500;&#24230;&#65292;&#20026;&#25968;&#25454;&#31649;&#29702;&#25237;&#36164;&#21644;&#25913;&#36827;&#25968;&#25454;&#20132;&#25442;&#36807;&#31243;&#25552;&#20379;&#25351;&#23548;&#12290;</title><link>https://arxiv.org/abs/2402.07926</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#21019;&#24314;&#32773;&#21040;&#25968;&#25454;&#37325;&#29992;&#32773;&#65306;&#36317;&#31163;&#30340;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
From Data Creator to Data Reuser: Distance Matters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07926
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#25968;&#25454;&#21019;&#24314;&#32773;&#21644;&#25968;&#25454;&#37325;&#29992;&#32773;&#20043;&#38388;&#36317;&#31163;&#30340;&#29702;&#35770;&#26500;&#24314;&#65292;&#24182;&#30830;&#23450;&#20102;&#24433;&#21709;&#26377;&#25928;&#20256;&#36882;&#30693;&#35782;&#33021;&#21147;&#30340;&#20845;&#20010;&#36317;&#31163;&#32500;&#24230;&#65292;&#20026;&#25968;&#25454;&#31649;&#29702;&#25237;&#36164;&#21644;&#25913;&#36827;&#25968;&#25454;&#20132;&#25442;&#36807;&#31243;&#25552;&#20379;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20849;&#20139;&#30740;&#31350;&#25968;&#25454;&#26159;&#22797;&#26434;&#12289;&#21171;&#21160;&#23494;&#38598;&#12289;&#26114;&#36149;&#30340;&#65292;&#38656;&#35201;&#22810;&#20010;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#22522;&#30784;&#35774;&#26045;&#25237;&#36164;&#12290;&#24320;&#25918;&#31185;&#23398;&#25919;&#31574;&#20391;&#37325;&#20110;&#25968;&#25454;&#21457;&#24067;&#32780;&#19981;&#26159;&#25968;&#25454;&#37325;&#29992;&#65292;&#28982;&#32780;&#37325;&#29992;&#20063;&#26159;&#22256;&#38590;&#12289;&#26114;&#36149;&#30340;&#65292;&#21487;&#33021;&#27704;&#36828;&#19981;&#20250;&#21457;&#29983;&#12290;&#36890;&#36807;&#32771;&#34385;&#35841;&#21487;&#33021;&#37325;&#29992;&#25968;&#25454;&#65292;&#22914;&#20309;&#37325;&#29992;&#25968;&#25454;&#65292;&#20026;&#20309;&#37325;&#29992;&#25968;&#25454;&#65292;&#20197;&#21450;&#20309;&#26102;&#37325;&#29992;&#25968;&#25454;&#31561;&#22240;&#32032;&#65292;&#21487;&#20197;&#26356;&#26126;&#26234;&#22320;&#36827;&#34892;&#25968;&#25454;&#31649;&#29702;&#25237;&#36164;&#12290;&#25968;&#25454;&#21019;&#36896;&#32773;&#26080;&#27861;&#39044;&#35265;&#25152;&#26377;&#21487;&#33021;&#30340;&#37325;&#29992;&#25110;&#37325;&#29992;&#32773;&#65307;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#21487;&#33021;&#26377;&#21161;&#20110;&#21033;&#30410;&#30456;&#20851;&#32773;&#20915;&#23450;&#22914;&#20309;&#25237;&#36164;&#30740;&#31350;&#25968;&#25454;&#65292;&#22914;&#20309;&#30830;&#23450;&#28508;&#22312;&#30340;&#37325;&#29992;&#21644;&#37325;&#29992;&#32773;&#65292;&#20197;&#21450;&#22914;&#20309;&#25913;&#36827;&#25968;&#25454;&#20132;&#25442;&#36807;&#31243;&#30340;&#22240;&#32032;&#12290;&#22522;&#20110;&#25968;&#25454;&#20849;&#20139;&#21644;&#37325;&#29992;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#25968;&#25454;&#21019;&#24314;&#32773;&#21644;&#25968;&#25454;&#37325;&#29992;&#32773;&#20043;&#38388;&#36317;&#31163;&#30340;&#29702;&#35770;&#26500;&#24314;&#65292;&#24182;&#30830;&#23450;&#20102;&#24433;&#21709;&#26377;&#25928;&#20256;&#36882;&#30693;&#35782;&#33021;&#21147;&#30340;&#20845;&#20010;&#36317;&#31163;&#32500;&#24230;&#65306;&#39046;&#22495;&#12289;&#26041;&#27861;&#12289;&#21512;&#20316;&#12289;&#31574;&#21010;&#12289;&#30446;&#30340;&#21644;&#26102;&#38388;&#24615;&#12290;&#36825;&#20123;&#32500;&#24230;&#20027;&#35201;&#26159;
&lt;/p&gt;
&lt;p&gt;
Sharing research data is complex, labor-intensive, expensive, and requires infrastructure investments by multiple stakeholders. Open science policies focus on data release rather than on data reuse, yet reuse is also difficult, expensive, and may never occur. Investments in data management could be made more wisely by considering who might reuse data, how, why, for what purposes, and when. Data creators cannot anticipate all possible reuses or reusers; our goal is to identify factors that may aid stakeholders in deciding how to invest in research data, how to identify potential reuses and reusers, and how to improve data exchange processes. Drawing upon empirical studies of data sharing and reuse, we develop the theoretical construct of distance between data creator and data reuser, identifying six distance dimensions that influence the ability to transfer knowledge effectively: domain, methods, collaboration, curation, purposes, and time and temporality. These dimensions are primarily
&lt;/p&gt;</description></item><item><title>C-RAG&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#35748;&#35777;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#39118;&#38505;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#31526;&#21512;&#39118;&#38505;&#20998;&#26512;&#21644;&#29983;&#25104;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#30830;&#20445;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#20449;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03181</link><description>&lt;p&gt;
C-RAG: &#38024;&#23545;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#35748;&#35777;&#29983;&#25104;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03181
&lt;/p&gt;
&lt;p&gt;
C-RAG&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#35748;&#35777;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#39118;&#38505;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#31526;&#21512;&#39118;&#38505;&#20998;&#26512;&#21644;&#29983;&#25104;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#30830;&#20445;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#20449;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20855;&#22791;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#23384;&#22312;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#22914;&#24187;&#35273;&#21644;&#38169;&#20301;&#12290;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#65288;RAG&#65289;&#34987;&#25552;&#20986;&#26469;&#22686;&#24378;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#20449;&#24615;&#65292;&#36890;&#36807;&#24341;&#20837;&#22806;&#37096;&#30693;&#35782;&#12290;&#20294;&#26159;&#65292;&#23545;&#20110;RAG&#27169;&#22411;&#30340;&#29983;&#25104;&#39118;&#38505;&#30340;&#29702;&#35770;&#29702;&#35299;&#23578;&#26410;&#34987;&#30740;&#31350;&#12290;&#26412;&#25991;&#22238;&#31572;&#20102;&#20197;&#19979;&#38382;&#39064;&#65306;1&#65289;RAG&#26159;&#21542;&#30830;&#23454;&#33021;&#22815;&#38477;&#20302;&#29983;&#25104;&#39118;&#38505;&#65292;2&#65289;&#22914;&#20309;&#23545;RAG&#21644;&#20256;&#32479;LLM&#30340;&#29983;&#25104;&#39118;&#38505;&#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#65292;&#20197;&#21450;3&#65289;&#21738;&#20123;&#20805;&#20998;&#26465;&#20214;&#20351;&#24471;RAG&#27169;&#22411;&#33021;&#22815;&#38477;&#20302;&#29983;&#25104;&#39118;&#38505;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;C-RAG&#65292;&#31532;&#19968;&#20010;&#29992;&#20110;&#35748;&#35777;RAG&#27169;&#22411;&#29983;&#25104;&#39118;&#38505;&#30340;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20026;RAG&#27169;&#22411;&#25552;&#20379;&#20102;&#31526;&#21512;&#39118;&#38505;&#20998;&#26512;&#65292;&#24182;&#30830;&#20445;&#20102;&#29983;&#25104;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#31526;&#21512;&#29983;&#25104;&#39118;&#38505;&#12290;&#25105;&#20204;&#36824;&#23545;&#19968;&#33324;&#26377;&#30028;&#39118;&#38505;&#19979;&#30340;&#31526;&#21512;&#29983;&#25104;&#39118;&#38505;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, the first framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#23884;&#20837;&#21521;&#37327;&#21387;&#32553;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#21644;&#23454;&#39564;&#35780;&#20272;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;&#29305;&#24449;&#21644;&#26041;&#27861;&#23398;&#23545;&#36825;&#20123;&#25216;&#26415;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#36827;&#19968;&#27493;&#21457;&#23637;&#20102;&#19968;&#20010;&#27169;&#22359;&#21270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#21387;&#32553;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2311.15578</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21487;&#23398;&#20064;&#21521;&#37327;&#23384;&#20648;&#21387;&#32553;&#30340;&#23454;&#39564;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Experimental Analysis of Large-scale Learnable Vector Storage Compression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15578
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#23884;&#20837;&#21521;&#37327;&#21387;&#32553;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#21644;&#23454;&#39564;&#35780;&#20272;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;&#29305;&#24449;&#21644;&#26041;&#27861;&#23398;&#23545;&#36825;&#20123;&#25216;&#26415;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#36827;&#19968;&#27493;&#21457;&#23637;&#20102;&#19968;&#20010;&#27169;&#22359;&#21270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#21387;&#32553;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#23398;&#20064;&#30340;&#23884;&#20837;&#21521;&#37327;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#24212;&#29992;&#20043;&#19968;&#65292;&#22312;&#21508;&#31181;&#19982;&#25968;&#25454;&#24211;&#30456;&#20851;&#30340;&#39046;&#22495;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#31232;&#30095;&#25968;&#25454;&#30340;&#39640;&#32500;&#24230;&#21644;&#26816;&#32034;&#20219;&#21153;&#20013;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#30340;&#24040;&#22823;&#23481;&#37327;&#23548;&#33268;&#23884;&#20837;&#34920;&#30340;&#20869;&#23384;&#28040;&#32791;&#24456;&#22823;&#65292;&#32473;&#27169;&#22411;&#30340;&#35757;&#32451;&#21644;&#37096;&#32626;&#24102;&#26469;&#20102;&#24040;&#22823;&#25361;&#25112;&#12290;&#36817;&#26399;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#21387;&#32553;&#23884;&#20837;&#21521;&#37327;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#22312;&#27169;&#22411;&#36136;&#37327;&#31245;&#24494;&#19979;&#38477;&#25110;&#24341;&#20837;&#20854;&#20182;&#24320;&#38144;&#30340;&#21516;&#26102;&#65292;&#20854;&#30456;&#23545;&#24615;&#33021;&#20173;&#19981;&#28165;&#26970;&#12290;&#29616;&#26377;&#30340;&#23454;&#39564;&#27604;&#36739;&#21482;&#28085;&#30422;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#23376;&#38598;&#65292;&#24182;&#19988;&#20851;&#27880;&#26377;&#38480;&#30340;&#25351;&#26631;&#12290;&#26412;&#25991;&#23545;&#23884;&#20837;&#21521;&#37327;&#21387;&#32553;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#21644;&#23454;&#39564;&#35780;&#20272;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;&#29305;&#24449;&#21644;&#26041;&#27861;&#23398;&#23545;&#36825;&#20123;&#25216;&#26415;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#36827;&#19968;&#27493;&#21457;&#23637;&#20102;&#19968;&#20010;&#27169;&#22359;&#21270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#21387;&#32553;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learnable embedding vector is one of the most important applications in machine learning, and is widely used in various database-related domains. However, the high dimensionality of sparse data in recommendation tasks and the huge volume of corpus in retrieval-related tasks lead to a large memory consumption of the embedding table, which poses a great challenge to the training and deployment of models. Recent research has proposed various methods to compress the embeddings at the cost of a slight decrease in model quality or the introduction of other overheads. Nevertheless, the relative performance of these methods remains unclear. Existing experimental comparisons only cover a subset of these methods and focus on limited metrics. In this paper, we perform a comprehensive comparative analysis and experimental evaluation of embedding compression. We introduce a new taxonomy that categorizes these techniques based on their characteristics and methodologies, and further develop a modular
&lt;/p&gt;</description></item><item><title>nSimplex Zen&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#25299;&#25169;&#38477;&#32500;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#25104;&#23545;&#36317;&#31163;&#26469;&#38477;&#20302;&#39640;&#32500;&#31354;&#38388;&#30340;&#32500;&#24230;&#12290;&#23427;&#22312;&#29289;&#29702;&#20869;&#23384;&#20351;&#29992;&#21644;&#36317;&#31163;&#35745;&#31639;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2302.11508</link><description>&lt;p&gt;
nSimplex Zen:&#19968;&#31181;&#26032;&#39062;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19982;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#38477;&#32500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
nSimplex Zen: A Novel Dimensionality Reduction for Euclidean and Hilbert Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.11508
&lt;/p&gt;
&lt;p&gt;
nSimplex Zen&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#25299;&#25169;&#38477;&#32500;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#25104;&#23545;&#36317;&#31163;&#26469;&#38477;&#20302;&#39640;&#32500;&#31354;&#38388;&#30340;&#32500;&#24230;&#12290;&#23427;&#22312;&#29289;&#29702;&#20869;&#23384;&#20351;&#29992;&#21644;&#36317;&#31163;&#35745;&#31639;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#25968;&#32422;&#31616;&#25216;&#26415;&#23558;&#39640;&#32500;&#31354;&#38388;&#30340;&#20540;&#26144;&#23556;&#21040;&#20302;&#32500;&#31354;&#38388;&#20013;&#12290;&#32467;&#26524;&#26159;&#38656;&#35201;&#36739;&#23569;&#29289;&#29702;&#20869;&#23384;&#19988;&#20855;&#26377;&#26356;&#24555;&#36317;&#31163;&#35745;&#31639;&#30340;&#31354;&#38388;&#12290;&#36825;&#20123;&#25216;&#26415;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#38656;&#35201;&#28385;&#36275;&#38477;&#32500;&#31354;&#38388;&#25152;&#20855;&#26377;&#30340;&#21487;&#25509;&#21463;&#31934;&#24230;&#19982;&#21407;&#22987;&#31354;&#38388;&#30456;&#27604;&#30340;&#22330;&#26223;&#12290;&#35768;&#22810;&#36825;&#26679;&#30340;&#36716;&#25442;&#26041;&#27861;&#24050;&#32463;&#34987;&#25551;&#36848;&#20986;&#26469;&#12290;&#23427;&#20204;&#34987;&#20998;&#20026;&#20004;&#22823;&#31867;&#65306;&#32447;&#24615;&#21644;&#25299;&#25169;&#12290;&#32447;&#24615;&#26041;&#27861;&#22914;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#21644;&#38543;&#26426;&#25237;&#24433;(RP)&#23558;&#36716;&#25442;&#25104;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#36739;&#20302;&#32500;&#24230;&#30340;&#22522;&#20110;&#30697;&#38453;&#30340;&#36716;&#25442;&#12290;&#25299;&#25169;&#26041;&#27861;&#22914;&#22810;&#32500;&#32553;&#25918;(MDS)&#23581;&#35797;&#20445;&#25345;&#26356;&#39640;&#23618;&#27425;&#30340;&#29305;&#24615;&#65292;&#22914;&#26368;&#36817;&#37051;&#20851;&#31995;&#65292;&#26377;&#20123;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25299;&#25169;&#38477;&#32500;&#26041;&#27861;nSimplex Zen&#12290;&#19982;MDS&#31867;&#20284;&#65292;&#23427;&#21482;&#20381;&#36182;&#20110;&#21407;&#22987;&#31354;&#38388;&#20013;&#30340;&#25104;&#23545;&#36317;&#31163;&#12290;&#20351;&#29992;d
&lt;/p&gt;
&lt;p&gt;
Dimensionality reduction techniques map values from a high dimensional space to one with a lower dimension. The result is a space which requires less physical memory and has a faster distance calculation. These techniques are widely used where required properties of the reduced-dimension space give an acceptable accuracy with respect to the original space. Many such transforms have been described. They have been classified in two main groups: linear and topological. Linear methods such as Principal Component Analysis (PCA) and Random Projection (RP) define matrix-based transforms into a lower dimension of Euclidean space. Topological methods such as Multidimensional Scaling (MDS) attempt to preserve higher-level aspects such as the nearest-neighbour relation, and some may be applied to non-Euclidean spaces. Here, we introduce nSimplex Zen, a novel topological method of reducing dimensionality. Like MDS, it relies only upon pairwise distances measured in the original space. The use of d
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#21644;&#35780;&#20272;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#31995;&#32479;&#20013;&#30340;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#32452;&#20214;&#65292;&#22635;&#34917;&#20102;&#30446;&#21069;&#30740;&#31350;&#20013;&#24573;&#35270;&#30340;&#39046;&#22495;&#65292;&#22312;&#26377;&#25928;&#30340;RAG&#30340;&#25552;&#31034;&#34920;&#36848;&#20013;&#65292;&#19981;&#30456;&#20851;&#25991;&#26723;&#30340;&#21253;&#21547;&#21487;&#33021;&#20250;&#23545;&#31995;&#32479;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.14887</link><description>&lt;p&gt;
&#22122;&#22768;&#30340;&#21147;&#37327;&#65306;&#37325;&#26032;&#23450;&#20041;RAG&#31995;&#32479;&#30340;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
The Power of Noise: Redefining Retrieval for RAG Systems. (arXiv:2401.14887v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#21644;&#35780;&#20272;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#31995;&#32479;&#20013;&#30340;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#32452;&#20214;&#65292;&#22635;&#34917;&#20102;&#30446;&#21069;&#30740;&#31350;&#20013;&#24573;&#35270;&#30340;&#39046;&#22495;&#65292;&#22312;&#26377;&#25928;&#30340;RAG&#30340;&#25552;&#31034;&#34920;&#36848;&#20013;&#65292;&#19981;&#30456;&#20851;&#25991;&#26723;&#30340;&#21253;&#21547;&#21487;&#33021;&#20250;&#23545;&#31995;&#32479;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#31995;&#32479;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20195;&#34920;&#20102;&#19968;&#20010;&#37325;&#22823;&#36827;&#27493;&#12290;RAG&#31995;&#32479;&#36890;&#36807;&#25972;&#21512;&#36890;&#36807;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#38454;&#27573;&#26816;&#32034;&#30340;&#22806;&#37096;&#25968;&#25454;&#26469;&#22686;&#24378;&#20854;&#29983;&#25104;&#33021;&#21147;&#65292;&#20811;&#26381;&#20102;&#26631;&#20934;LLMs&#30340;&#38480;&#21046;&#65292;&#21518;&#32773;&#20165;&#38480;&#20110;&#20854;&#39044;&#20808;&#35757;&#32451;&#30340;&#30693;&#35782;&#21644;&#26377;&#38480;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#12290;&#36825;&#20010;&#39046;&#22495;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;RAG&#31995;&#32479;&#20869;LLMs&#30340;&#29983;&#25104;&#26041;&#38754;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#36890;&#36807;&#20840;&#38754;&#32780;&#25209;&#21028;&#24615;&#22320;&#20998;&#26512;IR&#32452;&#20214;&#23545;RAG&#31995;&#32479;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#20010;&#26816;&#32034;&#22120;&#22312;&#26377;&#25928;&#30340;RAG&#30340;&#25552;&#31034;&#34920;&#36848;&#20013;&#24212;&#35813;&#20855;&#22791;&#30340;&#29305;&#24449;&#65292;&#37325;&#28857;&#20851;&#27880;&#24212;&#35813;&#26816;&#32034;&#21738;&#31181;&#31867;&#22411;&#30340;&#25991;&#26723;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#21508;&#31181;&#22240;&#32032;&#65292;&#22914;&#25991;&#26723;&#19982;&#25552;&#31034;&#30340;&#30456;&#20851;&#24615;&#65292;&#23427;&#20204;&#30340;&#20301;&#32622;&#20197;&#21450;&#19978;&#19979;&#25991;&#20013;&#21253;&#21547;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20986;&#65292;&#21253;&#21547;&#19981;&#30456;&#20851;&#30340;&#25991;&#26723;&#21487;&#33021;&#20250;&#8230;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Generation (RAG) systems represent a significant advancement over traditional Large Language Models (LLMs). RAG systems enhance their generation ability by incorporating external data retrieved through an Information Retrieval (IR) phase, overcoming the limitations of standard LLMs, which are restricted to their pre-trained knowledge and limited context window. Most research in this area has predominantly concentrated on the generative aspect of LLMs within RAG systems. Our study fills this gap by thoroughly and critically analyzing the influence of IR components on RAG systems. This paper analyzes which characteristics a retriever should possess for an effective RAG's prompt formulation, focusing on the type of documents that should be retrieved. We evaluate various elements, such as the relevance of the documents to the prompt, their position, and the number included in the context. Our findings reveal, among other insights, that including irrelevant documents can
&lt;/p&gt;</description></item><item><title>CIDER&#26159;&#19968;&#31181;&#22522;&#20110;&#31867;&#21035;&#24341;&#23548;&#30340;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#24847;&#22270;&#20998;&#31163;&#21644;&#19968;&#33268;&#24615;&#30340;&#26032;&#38395;&#34920;&#31034;&#26469;&#20934;&#30830;&#29702;&#35299;&#26032;&#38395;&#25991;&#31456;&#30340;&#22810;&#20010;&#24847;&#22270;&#65292;&#24182;&#21306;&#20998;&#29992;&#25143;&#19981;&#21516;&#30340;&#21518;&#38405;&#35835;&#20559;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.09401</link><description>&lt;p&gt;
CIDER: &#22522;&#20110;&#31867;&#21035;&#24341;&#23548;&#30340;&#24847;&#22270;&#20998;&#31163;&#26041;&#27861;&#29992;&#20110;&#20934;&#30830;&#30340;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
CIDER: Category-Guided Intent Disentanglement for Accurate Personalized News Recommendation. (arXiv:2310.09401v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09401
&lt;/p&gt;
&lt;p&gt;
CIDER&#26159;&#19968;&#31181;&#22522;&#20110;&#31867;&#21035;&#24341;&#23548;&#30340;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#24847;&#22270;&#20998;&#31163;&#21644;&#19968;&#33268;&#24615;&#30340;&#26032;&#38395;&#34920;&#31034;&#26469;&#20934;&#30830;&#29702;&#35299;&#26032;&#38395;&#25991;&#31456;&#30340;&#22810;&#20010;&#24847;&#22270;&#65292;&#24182;&#21306;&#20998;&#29992;&#25143;&#19981;&#21516;&#30340;&#21518;&#38405;&#35835;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#26088;&#22312;&#24110;&#21161;&#29992;&#25143;&#25214;&#21040;&#19982;&#20854;&#20852;&#36259;&#30456;&#31526;&#30340;&#26032;&#38395;&#25991;&#31456;&#65292;&#36825;&#22312;&#32531;&#35299;&#29992;&#25143;&#20449;&#24687;&#36807;&#36733;&#38382;&#39064;&#26041;&#38754;&#36215;&#21040;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23613;&#31649;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#33268;&#21147;&#20110;&#25913;&#36827;&#29992;&#25143;&#21644;&#26032;&#38395;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;&#20294;&#20197;&#19979;&#25361;&#25112;&#24456;&#23569;&#34987;&#30740;&#31350;&#65306;&#65288;C1&#65289;&#22914;&#20309;&#20934;&#30830;&#29702;&#35299;&#19968;&#31687;&#26032;&#38395;&#25991;&#31456;&#20013;&#21253;&#21547;&#30340;&#22810;&#20010;&#24847;&#22270;&#65311;&#20197;&#21450;&#65288;C2&#65289;&#22914;&#20309;&#21306;&#20998;&#29992;&#25143;&#28857;&#20987;&#21382;&#21490;&#20013;&#23545;&#26032;&#38395;&#25991;&#31456;&#26377;&#19981;&#21516;&#21518;&#38405;&#35835;&#20559;&#22909;&#30340;&#24773;&#20917;&#65311;&#20026;&#20102;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#25361;&#25112;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;&#65288;CIDER&#65289;&#65292;&#23427;&#21033;&#29992;&#65288;1&#65289;&#22522;&#20110;&#31867;&#21035;&#24341;&#23548;&#30340;&#24847;&#22270;&#20998;&#31163;&#26469;&#35299;&#20915;&#65288;C1&#65289;&#21644;&#65288;2&#65289;&#22522;&#20110;&#19968;&#33268;&#24615;&#30340;&#26032;&#38395;&#34920;&#31034;&#26469;&#35299;&#20915;&#65288;C2&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#31867;&#21035;&#39044;&#27979;&#32435;&#20837;CIDER&#30340;&#35757;&#32451;&#36807;&#31243;&#20316;&#20026;&#36741;&#21161;&#20219;&#21153;&#65292;&#36825;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#30417;&#30563;&#20449;&#21495;&#65292;&#20197;&#22686;&#24378;&#24847;&#22270;&#20998;&#31163;&#12290;&#22312;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized news recommendation aims to assist users in finding news articles that align with their interests, which plays a pivotal role in mitigating users' information overload problem. Although many recent works have been studied for better user and news representations, the following challenges have been rarely studied: (C1) How to precisely comprehend a range of intents coupled within a news article? and (C2) How to differentiate news articles with varying post-read preferences in users' click history? To tackle both challenges together, in this paper, we propose a novel personalized news recommendation framework (CIDER) that employs (1) category-guided intent disentanglement for (C1) and (2) consistency-based news representation for (C2). Furthermore, we incorporate a category prediction into the training process of CIDER as an auxiliary task, which provides supplementary supervisory signals to enhance intent disentanglement. Extensive experiments on two real-world datasets rev
&lt;/p&gt;</description></item></channel></rss>