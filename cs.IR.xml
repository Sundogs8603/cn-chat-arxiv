<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;CollabContext&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#24039;&#22937;&#22320;&#23558;&#21327;&#21516;&#36807;&#28388;&#20449;&#21495;&#19982;&#24773;&#22659;&#21270;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#20851;&#38190;&#30340;&#24773;&#22659;&#35821;&#20041;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#20013;&#21327;&#21516;&#20449;&#21495;&#21644;&#24773;&#22659;&#21270;&#34920;&#31034;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2310.09400</link><description>&lt;p&gt;
&#21327;&#20316;&#24773;&#22659;&#21270;&#65306;&#22635;&#34917;&#21327;&#21516;&#36807;&#28388;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Collaborative Contextualization: Bridging the Gap between Collaborative Filtering and Pre-trained Language Model. (arXiv:2310.09400v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;CollabContext&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#24039;&#22937;&#22320;&#23558;&#21327;&#21516;&#36807;&#28388;&#20449;&#21495;&#19982;&#24773;&#22659;&#21270;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#20851;&#38190;&#30340;&#24773;&#22659;&#35821;&#20041;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#20013;&#21327;&#21516;&#20449;&#21495;&#21644;&#24773;&#22659;&#21270;&#34920;&#31034;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#24314;&#27169;&#29992;&#25143;&#21644;&#29289;&#21697;&#26102; heavily relied on identity representations (IDs)&#65292;&#32780;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411; (PLM) &#30340;&#20852;&#36215;&#20016;&#23500;&#20102;&#23545;&#24773;&#22659;&#21270;&#29289;&#21697;&#25551;&#36848;&#30340;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649; PLM &#22312;&#35299;&#20915; few-shot&#12289;zero-shot &#25110;&#32479;&#19968;&#24314;&#27169;&#22330;&#26223;&#26041;&#38754;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#24120;&#24120;&#24573;&#35270;&#20102;&#20851;&#38190;&#30340;&#21327;&#21516;&#36807;&#28388;&#20449;&#21495;&#12290;&#36825;&#31181;&#24573;&#35270;&#24102;&#26469;&#20102;&#20004;&#20010;&#32039;&#36843;&#30340;&#25361;&#25112;&#65306;(1) &#21327;&#20316;&#24773;&#22659;&#21270;&#65292;&#21363;&#21327;&#21516;&#20449;&#21495;&#19982;&#24773;&#22659;&#21270;&#34920;&#31034;&#30340;&#26080;&#32541;&#38598;&#25104;&#12290;(2) &#22312;&#20445;&#30041;&#23427;&#20204;&#30340;&#24773;&#22659;&#35821;&#20041;&#30340;&#21516;&#26102;&#65292;&#24357;&#21512;&#22522;&#20110;ID&#30340;&#34920;&#31034;&#21644;&#24773;&#22659;&#21270;&#34920;&#31034;&#20043;&#38388;&#30340;&#34920;&#31034;&#24046;&#36317;&#30340;&#24517;&#35201;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CollabContext&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#24039;&#22937;&#22320;&#23558;&#21327;&#21516;&#36807;&#28388;&#20449;&#21495;&#19982;&#24773;&#22659;&#21270;&#34920;&#31034;&#32467;&#21512;&#36215;&#26469;&#65292;&#24182;&#23558;&#36825;&#20123;&#34920;&#31034;&#23545;&#40784;&#22312;&#24773;&#22659;&#31354;&#38388;&#20869;&#65292;&#20445;&#30041;&#20102;&#37325;&#35201;&#30340;&#24773;&#22659;&#35821;&#20041;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;...
&lt;/p&gt;
&lt;p&gt;
Traditional recommender systems have heavily relied on identity representations (IDs) to model users and items, while the ascendancy of pre-trained language model (PLM) encoders has enriched the modeling of contextual item descriptions. However, PLMs, although effective in addressing few-shot, zero-shot, or unified modeling scenarios, often neglect the crucial collaborative filtering signal. This neglect gives rise to two pressing challenges: (1) Collaborative Contextualization, the seamless integration of collaborative signals with contextual representations. (2) the imperative to bridge the representation gap between ID-based representations and contextual representations while preserving their contextual semantics. In this paper, we propose CollabContext, a novel model that adeptly combines collaborative filtering signals with contextual representations and aligns these representations within the contextual space, preserving essential contextual semantics. Experimental results acros
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#36793;&#30028;&#24863;&#30693;&#36741;&#21161;&#21644;&#28176;&#36827;&#35821;&#20041;&#20248;&#21270;&#30340;&#21452;&#21453;&#39304;&#27880;&#24847;&#21147;&#26694;&#26550; (DFA-BASO)&#12290;&#36890;&#36807;&#24341;&#20837;&#36793;&#30028;&#20445;&#25252;&#26657;&#20934;&#21644;&#21452;&#29305;&#24449;&#21453;&#39304;&#34917;&#20805;&#27169;&#22359;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20943;&#23569;&#20449;&#24687;&#25439;&#22833;&#12289;&#25233;&#21046;&#22122;&#22768;&#12289;&#22686;&#24378;&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.02867</link><description>&lt;p&gt;
&#22522;&#20110;&#36793;&#30028;&#24863;&#30693;&#36741;&#21161;&#21644;&#28176;&#36827;&#35821;&#20041;&#20248;&#21270;&#30340;&#21452;&#21453;&#39304;&#27880;&#24847;&#21147;&#26694;&#26550;&#29992;&#20110;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Dual Feedback Attention Framework via Boundary-Aware Auxiliary and Progressive Semantic Optimization for Salient Object Detection in Optical Remote Sensing Imagery. (arXiv:2303.02867v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#36793;&#30028;&#24863;&#30693;&#36741;&#21161;&#21644;&#28176;&#36827;&#35821;&#20041;&#20248;&#21270;&#30340;&#21452;&#21453;&#39304;&#27880;&#24847;&#21147;&#26694;&#26550; (DFA-BASO)&#12290;&#36890;&#36807;&#24341;&#20837;&#36793;&#30028;&#20445;&#25252;&#26657;&#20934;&#21644;&#21452;&#29305;&#24449;&#21453;&#39304;&#34917;&#20805;&#27169;&#22359;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20943;&#23569;&#20449;&#24687;&#25439;&#22833;&#12289;&#25233;&#21046;&#22122;&#22768;&#12289;&#22686;&#24378;&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#36880;&#28176;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#36825;&#35201;&#24402;&#21151;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#33258;&#28982;&#22330;&#26223;&#22270;&#20687;&#20013;&#30340;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#33258;&#28982;&#22330;&#26223;&#22270;&#20687;&#21644;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#22312;&#35768;&#22810;&#26041;&#38754;&#26159;&#19981;&#21516;&#30340;&#65292;&#20363;&#22914;&#35206;&#30422;&#33539;&#22260;&#22823;&#12289;&#32972;&#26223;&#22797;&#26434;&#20197;&#21450;&#30446;&#26631;&#31867;&#22411;&#21644;&#23610;&#24230;&#30340;&#24040;&#22823;&#24046;&#24322;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#19968;&#31181;&#19987;&#38376;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#20809;&#23398;&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#26174;&#33879;&#30446;&#26631;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#27809;&#26377;&#20805;&#20998;&#20851;&#27880;&#21040;&#30446;&#26631;&#30340;&#36793;&#30028;&#65292;&#26368;&#32456;&#26174;&#33879;&#24615;&#22270;&#30340;&#23436;&#25972;&#24615;&#20173;&#38656;&#35201;&#25913;&#36827;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#36793;&#30028;&#24863;&#30693;&#36741;&#21161;&#21644;&#28176;&#36827;&#35821;&#20041;&#20248;&#21270;&#30340;&#21452;&#21453;&#39304;&#27880;&#24847;&#21147;&#26694;&#26550;&#65288;DFA-BASO&#65289;&#12290;&#39318;&#20808;&#65292;&#24341;&#20837;&#20102;&#36793;&#30028;&#20445;&#25252;&#26657;&#20934;(BPC)&#27169;&#22359;&#65292;&#29992;&#20110;&#20943;&#23569;&#27491;&#21521;&#20256;&#25773;&#36807;&#31243;&#20013;&#36793;&#30028;&#20301;&#32622;&#20449;&#24687;&#30340;&#20002;&#22833;&#65292;&#24182;&#25233;&#21046;&#20302;&#32423;&#29305;&#24449;&#20013;&#30340;&#22122;&#22768;&#12290;&#20854;&#27425;&#65292;&#24341;&#20837;&#20102;&#21452;&#29305;&#24449;&#21453;&#39304;&#34917;&#20805;(DFFC)&#27169;&#22359;&#65292;&#29992;&#20110;&#22686;&#24378;&#27491;&#21453;&#39304;&#21644;&#36127;&#21453;&#39304;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#25552;&#39640;&#26174;&#33879;&#24615;&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Salient object detection in optical remote sensing image (ORSI-SOD) has gradually attracted attention thanks to the development of deep learning (DL) and salient object detection in natural scene image (NSI-SOD). However, NSI and ORSI are different in many aspects, such as large coverage, complex background, and large differences in target types and scales. Therefore, a new dedicated method is needed for ORSI-SOD. In addition, existing methods do not pay sufficient attention to the boundary of the object, and the completeness of the final saliency map still needs improvement. To address these issues, we propose a novel method called Dual Feedback Attention Framework via Boundary-Aware Auxiliary and Progressive Semantic Optimization (DFA-BASO). First, Boundary Protection Calibration (BPC) module is proposed to reduce the loss of edge position information during forward propagation and suppress noise in low-level features. Second, a Dual Feature Feedback Complementary (DFFC) module is pr
&lt;/p&gt;</description></item></channel></rss>