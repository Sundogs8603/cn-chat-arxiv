<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;SE-PQA&#65288;&#20010;&#24615;&#21270;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#65289;&#30340;&#26032;&#36164;&#28304;&#65292;&#35813;&#36164;&#28304;&#21253;&#25324;&#36229;&#36807;1&#30334;&#19975;&#20010;&#26597;&#35810;&#21644;2&#30334;&#19975;&#20010;&#22238;&#31572;&#65292;&#24182;&#20351;&#29992;&#19968;&#31995;&#21015;&#20016;&#23500;&#30340;&#29305;&#24449;&#27169;&#25311;&#20102;&#27969;&#34892;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#24179;&#21488;&#30340;&#29992;&#25143;&#20043;&#38388;&#30340;&#31038;&#20132;&#20114;&#21160;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#29992;&#20110;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#30340;&#21487;&#22797;&#29616;&#22522;&#32447;&#26041;&#27861;&#65292;&#21253;&#25324;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#20010;&#24615;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.16261</link><description>&lt;p&gt;
SE-PQA: &#20010;&#24615;&#21270;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;
&lt;/p&gt;
&lt;p&gt;
SE-PQA: Personalized Community Question Answering. (arXiv:2306.16261v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16261
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;SE-PQA&#65288;&#20010;&#24615;&#21270;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#65289;&#30340;&#26032;&#36164;&#28304;&#65292;&#35813;&#36164;&#28304;&#21253;&#25324;&#36229;&#36807;1&#30334;&#19975;&#20010;&#26597;&#35810;&#21644;2&#30334;&#19975;&#20010;&#22238;&#31572;&#65292;&#24182;&#20351;&#29992;&#19968;&#31995;&#21015;&#20016;&#23500;&#30340;&#29305;&#24449;&#27169;&#25311;&#20102;&#27969;&#34892;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#24179;&#21488;&#30340;&#29992;&#25143;&#20043;&#38388;&#30340;&#31038;&#20132;&#20114;&#21160;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#29992;&#20110;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#30340;&#21487;&#22797;&#29616;&#22522;&#32447;&#26041;&#27861;&#65292;&#21253;&#25324;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#20010;&#24615;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#20154;&#21270;&#30340;&#20449;&#24687;&#26816;&#32034;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#30740;&#31350;&#30340;&#35838;&#39064;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#20173;&#28982;&#32570;&#20047;&#39640;&#36136;&#37327;&#12289;&#30495;&#23454;&#30340;&#25968;&#25454;&#38598;&#26469;&#24320;&#23637;&#22823;&#35268;&#27169;&#23454;&#39564;&#65292;&#24182;&#35780;&#20272;&#20010;&#24615;&#21270;&#25628;&#32034;&#27169;&#22411;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;SE-PQA (StackExchange - &#20010;&#24615;&#21270;&#38382;&#39064;&#22238;&#31572;)&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#30340;&#31934;&#36873;&#36164;&#28304;&#65292;&#29992;&#20110;&#35774;&#35745;&#21644;&#35780;&#20272;&#19982;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#30456;&#20851;&#30340;&#20010;&#24615;&#21270;&#27169;&#22411;&#12290;&#36129;&#29486;&#30340;&#25968;&#25454;&#38598;&#21253;&#25324;&#36229;&#36807;1&#30334;&#19975;&#20010;&#26597;&#35810;&#21644;2&#30334;&#19975;&#20010;&#22238;&#31572;&#65292;&#20351;&#29992;&#20102;&#19968;&#31995;&#21015;&#20016;&#23500;&#30340;&#29305;&#24449;&#26469;&#27169;&#25311;&#19968;&#20010;&#27969;&#34892;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#24179;&#21488;&#30340;&#29992;&#25143;&#20043;&#38388;&#30340;&#31038;&#20132;&#20114;&#21160;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;SE-PQA&#30340;&#29305;&#28857;&#65292;&#24182;&#35814;&#32454;&#35828;&#26126;&#20102;&#19982;&#38382;&#39064;&#21644;&#22238;&#31572;&#30456;&#20851;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22522;&#20110;&#35813;&#36164;&#28304;&#30340;&#31038;&#21306;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#30340;&#21487;&#22797;&#29616;&#22522;&#32447;&#26041;&#27861;&#65292;&#21253;&#25324;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#20010;&#24615;&#21270;&#26041;&#27861;&#12290;&#21021;&#27493;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#20854;&#21512;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalization in Information Retrieval is a topic studied for a long time. Nevertheless, there is still a lack of high-quality, real-world datasets to conduct large-scale experiments and evaluate models for personalized search. This paper contributes to filling this gap by introducing SE-PQA (StackExchange - Personalized Question Answering), a new curated resource to design and evaluate personalized models related to the task of community Question Answering (cQA). The contributed dataset includes more than 1 million queries and 2 million answers, annotated with a rich set of features modeling the social interactions among the users of a popular cQA platform. We describe the characteristics of SE-PQA and detail the features associated with questions and answers. We also provide reproducible baseline methods for the cQA task based on the resource, including deep learning models and personalization approaches. The results of the preliminary experiments conducted show the appropriateness
&lt;/p&gt;</description></item><item><title>&#22312;&#22823;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26597;&#35810;&#37325;&#20889;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#23436;&#20840;&#25351;&#23450;&#26426;&#22120;&#24847;&#22270;&#30340;&#33258;&#28982;&#35821;&#35328;&#26469;&#25913;&#36827;&#24847;&#22270;&#29702;&#35299;&#21644;&#26500;&#24314;&#39640;&#24615;&#33021;&#26816;&#32034;&#31995;&#32479;&#12290;&#36825;&#31181;&#26694;&#26550;&#30340;&#33021;&#22815;&#20197;&#33258;&#28982;&#35821;&#35328;&#21576;&#29616;&#12289;&#20132;&#20114;&#21644;&#25512;&#29702;&#26426;&#22120;&#24847;&#22270;&#20855;&#26377;&#28145;&#36828;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.16004</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#26597;&#35810;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Query Understanding in the Age of Large Language Models. (arXiv:2306.16004v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16004
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26597;&#35810;&#37325;&#20889;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#23436;&#20840;&#25351;&#23450;&#26426;&#22120;&#24847;&#22270;&#30340;&#33258;&#28982;&#35821;&#35328;&#26469;&#25913;&#36827;&#24847;&#22270;&#29702;&#35299;&#21644;&#26500;&#24314;&#39640;&#24615;&#33021;&#26816;&#32034;&#31995;&#32479;&#12290;&#36825;&#31181;&#26694;&#26550;&#30340;&#33021;&#22815;&#20197;&#33258;&#28982;&#35821;&#35328;&#21576;&#29616;&#12289;&#20132;&#20114;&#21644;&#25512;&#29702;&#26426;&#22120;&#24847;&#22270;&#20855;&#26377;&#28145;&#36828;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20852;&#36215;&#21644;&#24212;&#29992;&#65292;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#36827;&#34892;&#26597;&#35810;&#12289;&#23545;&#35805;&#21644;&#25511;&#21046;&#25628;&#32034;&#21644;&#20449;&#24687;&#26816;&#32034;&#30028;&#38754;&#27491;&#22312;&#36805;&#36895;&#26222;&#21450;&#12290;&#22312;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#20351;&#29992;LLM&#36827;&#34892;&#20132;&#20114;&#24335;&#26597;&#35810;&#37325;&#20889;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26088;&#22312;&#20026;&#25913;&#36827;&#21644;&#36879;&#26126;&#21270;&#24847;&#22270;&#29702;&#35299;&#20197;&#21450;&#20351;&#29992;LLM&#26500;&#24314;&#39640;&#24615;&#33021;&#26816;&#32034;&#31995;&#32479;&#24320;&#36767;&#26032;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#26041;&#38754;&#26159;&#37325;&#20889;&#22120;&#33021;&#22815;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23436;&#20840;&#25351;&#23450;&#26426;&#22120;&#24847;&#22270;&#65292;&#36825;&#20010;&#26426;&#22120;&#24847;&#22270;&#21487;&#20197;&#22312;&#26368;&#32456;&#26816;&#32034;&#38454;&#27573;&#20043;&#21069;&#36827;&#19968;&#27493;&#32454;&#21270;&#12289;&#25511;&#21046;&#21644;&#32534;&#36753;&#12290;&#20197;&#33258;&#28982;&#35821;&#35328;&#21576;&#29616;&#12289;&#20132;&#20114;&#21644;&#25512;&#29702;&#24213;&#23618;&#30340;&#26426;&#22120;&#24847;&#22270;&#23545;&#36879;&#26126;&#24230;&#12289;&#25490;&#21517;&#24615;&#33021;&#20197;&#21450;&#31163;&#24320;&#20256;&#32479;&#24847;&#22270;&#29702;&#35299;&#20013;&#25910;&#38598;&#30417;&#30563;&#20449;&#21495;&#30340;&#26041;&#24335;&#26377;&#28145;&#36828;&#24433;&#21709;&#12290;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#36825;&#19968;&#27010;&#24565;&#65292;&#24182;&#25903;&#25345;&#21021;&#27493;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Querying, conversing, and controlling search and information-seeking interfaces using natural language are fast becoming ubiquitous with the rise and adoption of large-language models (LLM). In this position paper, we describe a generic framework for interactive query-rewriting using LLMs. Our proposal aims to unfold new opportunities for improved and transparent intent understanding while building high-performance retrieval systems using LLMs. A key aspect of our framework is the ability of the rewriter to fully specify the machine intent by the search engine in natural language that can be further refined, controlled, and edited before the final retrieval phase. The ability to present, interact, and reason over the underlying machine intent in natural language has profound implications on transparency, ranking performance, and a departure from the traditional way in which supervised signals were collected for understanding intents. We detail the concept, backed by initial experiments
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#31616;&#21270;&#31038;&#20132;&#23186;&#20307;&#20449;&#24687;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35782;&#21035;&#21307;&#23398;&#23454;&#20307;&#12289;&#26631;&#20934;&#21270;&#23454;&#20307;&#21644;&#20998;&#37197;UMLS&#27010;&#24565;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;COVID-19&#30456;&#20851;&#25512;&#25991;&#30340;&#30151;&#29366;&#35789;&#20856;&#12290;</title><link>http://arxiv.org/abs/2306.16001</link><description>&lt;p&gt;
&#29992;&#28145;&#24230;&#23398;&#20064;&#31616;&#21270;&#31038;&#20132;&#23186;&#20307;&#20449;&#24687;&#26816;&#32034;&#20197;&#25903;&#25345;&#20844;&#20849;&#21355;&#29983;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning. (arXiv:2306.16001v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#31616;&#21270;&#31038;&#20132;&#23186;&#20307;&#20449;&#24687;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35782;&#21035;&#21307;&#23398;&#23454;&#20307;&#12289;&#26631;&#20934;&#21270;&#23454;&#20307;&#21644;&#20998;&#37197;UMLS&#27010;&#24565;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;COVID-19&#30456;&#20851;&#25512;&#25991;&#30340;&#30151;&#29366;&#35789;&#20856;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#22312;&#27969;&#34892;&#30149;&#30417;&#27979;&#20013;&#30340;&#21033;&#29992;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#35777;&#23454;&#12290;&#28982;&#32780;&#65292;&#24403;&#20351;&#29992;&#39044;&#23450;&#20041;&#30340;&#35789;&#27719;&#34920;&#26469;&#26816;&#32034;&#30456;&#20851;&#35821;&#26009;&#24211;&#26102;&#65292;&#24120;&#24120;&#20250;&#24341;&#20837;&#20559;&#35265;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#26088;&#22312;&#26500;&#24314;&#21307;&#23398;&#20439;&#35821;&#21644;&#32479;&#19968;&#21307;&#23398;&#35821;&#35328;&#31995;&#32479;&#65288;UMLS&#65289;&#27010;&#24565;&#30340;&#24191;&#27867;&#23383;&#20856;&#12290;&#35813;&#26694;&#26550;&#30001;&#19977;&#20010;&#27169;&#22359;&#32452;&#25104;&#65306;&#22522;&#20110;BERT&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#20174;&#31038;&#20132;&#23186;&#20307;&#20869;&#23481;&#20013;&#35782;&#21035;&#20986;&#21307;&#23398;&#23454;&#20307;&#65307;&#28145;&#24230;&#23398;&#20064;&#39537;&#21160;&#30340;&#26631;&#20934;&#21270;&#27169;&#22359;&#65292;&#29992;&#20110;&#23545;&#25552;&#21462;&#20986;&#30340;&#23454;&#20307;&#36827;&#34892;&#35268;&#33539;&#21270;&#22788;&#29702;&#65307;&#21322;&#30417;&#30563;&#32858;&#31867;&#27169;&#22359;&#65292;&#23558;&#26368;&#21487;&#33021;&#30340;UMLS&#27010;&#24565;&#20998;&#37197;&#32473;&#27599;&#20010;&#35268;&#33539;&#21270;&#23454;&#20307;&#12290;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#20174;2020&#24180;2&#26376;1&#26085;&#21040;2022&#24180;4&#26376;30&#26085;&#26399;&#38388;&#19982;COVID-19&#30456;&#20851;&#30340;&#25512;&#25991;&#65292;&#29983;&#25104;&#20102;&#19968;&#20010;&#30151;&#29366;&#35789;&#20856;&#65288;&#21487;&#22312;https://github.com/ningkko/UMLS_colloquialism/&#19978;&#33719;&#21462;&#65289;&#65292;&#20854;&#20013;&#21253;&#21547;9,249&#20010;&#26631;&#20934;&#21270;&#23454;&#20307;&#65292;&#26144;&#23556;&#21040;876&#20010;UMLS&#27010;&#24565;&#21644;38,175&#20010;&#20442;&#35821;&#34920;&#36798;&#12290;&#35813;&#26694;&#26550;&#30340;&#28436;&#31034;
&lt;/p&gt;
&lt;p&gt;
The utilization of social media in epidemic surveillance has been well established. Nonetheless, bias is often introduced when pre-defined lexicons are used to retrieve relevant corpus. This study introduces a framework aimed at curating extensive dictionaries of medical colloquialisms and Unified Medical Language System (UMLS) concepts. The framework comprises three modules: a BERT-based Named Entity Recognition (NER) model that identifies medical entities from social media content, a deep-learning powered normalization module that standardizes the extracted entities, and a semi-supervised clustering module that assigns the most probable UMLS concept to each standardized entity. We applied this framework to COVID-19-related tweets from February 1, 2020, to April 30, 2022, generating a symptom dictionary (available at https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249 standardized entities mapped to 876 UMLS concepts and 38,175 colloquial expressions. This framework demo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32544;&#30340;&#28040;&#38500;&#20559;&#35265;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26694;&#26550;&#65288;DB-VAE&#65289;&#65292;&#20197;&#21450;&#19968;&#31181;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30340;&#21333;&#19968;&#21151;&#33021;&#24615;&#20559;&#35265;&#20197;&#21450;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.15961</link><description>&lt;p&gt;
&#36890;&#36807;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#30340;&#35299;&#32544;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26469;&#28040;&#38500;&#25512;&#33616;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Disentangled Variational Auto-encoder Enhanced by Counterfactual Data for Debiasing Recommendation. (arXiv:2306.15961v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32544;&#30340;&#28040;&#38500;&#20559;&#35265;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26694;&#26550;&#65288;DB-VAE&#65289;&#65292;&#20197;&#21450;&#19968;&#31181;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30340;&#21333;&#19968;&#21151;&#33021;&#24615;&#20559;&#35265;&#20197;&#21450;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#32463;&#24120;&#36973;&#21463;&#21508;&#31181;&#25512;&#33616;&#20559;&#35265;&#30340;&#22256;&#25200;&#65292;&#20005;&#37325;&#38459;&#30861;&#20102;&#20854;&#21457;&#23637;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#28040;&#38500;&#25512;&#33616;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#23588;&#20854;&#36866;&#29992;&#20110;&#20004;&#31181;&#26368;&#24120;&#35265;&#30340;&#20559;&#35265;&#65292;&#21363;&#27969;&#34892;&#24230;&#20559;&#35265;&#21644;&#25918;&#22823;&#30340;&#20027;&#35266;&#20559;&#35265;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#28040;&#38500;&#20559;&#35265;&#26041;&#27861;&#36890;&#24120;&#21482;&#20851;&#27880;&#32416;&#27491;&#21333;&#19968;&#20559;&#35265;&#12290;&#36825;&#31181;&#21333;&#19968;&#21151;&#33021;&#24615;&#30340;&#28040;&#38500;&#20559;&#35265;&#24573;&#35270;&#20102;&#25512;&#33616;&#29289;&#21697;&#22810;&#20010;&#20559;&#35265;&#20043;&#38388;&#30340;&#32806;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#20043;&#21069;&#30340;&#24037;&#20316;&#26080;&#27861;&#35299;&#20915;&#31232;&#30095;&#25968;&#25454;&#24102;&#26469;&#30340;&#32570;&#20047;&#30417;&#30563;&#20449;&#21495;&#38382;&#39064;&#65292;&#32780;&#36825;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24050;&#32463;&#21464;&#24471;&#24456;&#26222;&#36941;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#35299;&#32544;&#30340;&#28040;&#38500;&#20559;&#35265;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26694;&#26550;&#65288;DB-VAE&#65289;&#65292;&#26469;&#35299;&#20915;&#21333;&#19968;&#21151;&#33021;&#24615;&#38382;&#39064;&#65292;&#20197;&#21450;&#19968;&#31181;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#20197;&#20943;&#36731;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#24615;&#24102;&#26469;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;DB-VAE&#39318;&#20808;&#25552;&#21462;&#21482;&#21463;&#21333;&#20010;&#20559;&#35265;&#24433;&#21709;&#30340;&#20004;&#31181;&#26497;&#31471;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender system always suffers from various recommendation biases, seriously hindering its development. In this light, a series of debias methods have been proposed in the recommender system, especially for two most common biases, i.e., popularity bias and amplified subjective bias. However, exsisting debias methods usually concentrate on correcting a single bias. Such single-functionality debiases neglect the bias-coupling issue in which the recommended items are collectively attributed to multiple biases. Besides, previous work cannot tackle the lacking supervised signals brought by sparse data, yet which has become a commonplace in the recommender system. In this work, we introduce a disentangled debias variational auto-encoder framework(DB-VAE) to address the single-functionality issue as well as a counterfactual data enhancement method to mitigate the adverse effect due to the data sparsity. In specific, DB-VAE first extracts two types of extreme items only affected by a single
&lt;/p&gt;</description></item><item><title>Pb-Hash&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#21306;b&#20301;&#21704;&#24076;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;B&#20301;&#21704;&#24076;&#20998;&#25104;m&#20010;&#22359;&#26469;&#37325;&#22797;&#20351;&#29992;&#24050;&#26377;&#30340;&#21704;&#24076;&#65292;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#27169;&#22411;&#30340;&#22823;&#23567;&#12290;</title><link>http://arxiv.org/abs/2306.15944</link><description>&lt;p&gt;
Pb-Hash: &#20998;&#21306;b&#20301;&#21704;&#24076;
&lt;/p&gt;
&lt;p&gt;
Pb-Hash: Partitioned b-bit Hashing. (arXiv:2306.15944v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15944
&lt;/p&gt;
&lt;p&gt;
Pb-Hash&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#21306;b&#20301;&#21704;&#24076;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;B&#20301;&#21704;&#24076;&#20998;&#25104;m&#20010;&#22359;&#26469;&#37325;&#22797;&#20351;&#29992;&#24050;&#26377;&#30340;&#21704;&#24076;&#65292;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#27169;&#22411;&#30340;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#21704;&#24076;&#31639;&#27861;&#65292;&#21253;&#25324;minwise&#21704;&#24076;&#65288;MinHash&#65289;&#65292;&#19968;&#27425;&#32622;&#25442;&#21704;&#24076;&#65288;OPH&#65289;&#21644;&#19968;&#33268;&#21152;&#26435;&#37319;&#26679;&#65288;CWS&#65289;&#65292;&#29983;&#25104;B&#20301;&#25972;&#25968;&#12290;&#23545;&#20110;&#27599;&#20010;&#25968;&#25454;&#21521;&#37327;&#30340;k&#20010;&#21704;&#24076;&#65292;&#23384;&#20648;&#31354;&#38388;&#23558;&#26159;B&#215;k&#20301;&#65307;&#24403;&#29992;&#20110;&#22823;&#35268;&#27169;&#23398;&#20064;&#26102;&#65292;&#27169;&#22411;&#22823;&#23567;&#23558;&#26159;2^B&#215;k&#65292;&#36825;&#21487;&#33021;&#24456;&#26114;&#36149;&#12290;&#19968;&#31181;&#26631;&#20934;&#31574;&#30053;&#26159;&#20165;&#20351;&#29992;B&#20301;&#20013;&#30340;&#26368;&#20302;b&#20301;&#65292;&#24182;&#30053;&#24494;&#22686;&#21152;&#21704;&#24076;&#30340;&#25968;&#37327;k&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#23558;B&#20301;&#20998;&#25104;m&#20010;&#22359;&#65292;&#20363;&#22914;b&#215;m=B&#65292;&#26469;&#37325;&#22797;&#20351;&#29992;&#21704;&#24076;&#12290;&#23545;&#24212;&#22320;&#65292;&#27169;&#22411;&#22823;&#23567;&#21464;&#20026;m&#215;2^b&#215;k&#65292;&#36825;&#21487;&#33021;&#27604;&#21407;&#26469;&#30340;2^B&#215;k&#35201;&#23567;&#24471;&#22810;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#26174;&#31034;&#65292;&#36890;&#36807;&#23558;&#21704;&#24076;&#20540;&#20998;&#25104;m&#20010;&#22359;&#65292;&#20934;&#30830;&#24615;&#20250;&#19979;&#38477;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#20351;&#29992;B/m&#20301;&#30340;m&#20010;&#22359;&#23558;&#19981;&#22914;&#30452;&#25509;&#20351;&#29992;B&#20301;&#31934;&#30830;&#12290;&#36825;&#26159;&#30001;&#20110;&#36890;&#36807;&#37325;&#26032;&#20351;&#29992;&#30456;&#21516;&#30340;&#21704;&#24076;&#20540;&#24341;&#36215;&#30340;&#30456;&#20851;&#24615;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;
&lt;/p&gt;
&lt;p&gt;
Many hashing algorithms including minwise hashing (MinHash), one permutation hashing (OPH), and consistent weighted sampling (CWS) generate integers of $B$ bits. With $k$ hashes for each data vector, the storage would be $B\times k$ bits; and when used for large-scale learning, the model size would be $2^B\times k$, which can be expensive. A standard strategy is to use only the lowest $b$ bits out of the $B$ bits and somewhat increase $k$, the number of hashes. In this study, we propose to re-use the hashes by partitioning the $B$ bits into $m$ chunks, e.g., $b\times m =B$. Correspondingly, the model size becomes $m\times 2^b \times k$, which can be substantially smaller than the original $2^B\times k$.  Our theoretical analysis reveals that by partitioning the hash values into $m$ chunks, the accuracy would drop. In other words, using $m$ chunks of $B/m$ bits would not be as accurate as directly using $B$ bits. This is due to the correlation from re-using the same hash. On the other h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20248;&#21270;&#22522;&#20110;Transformer&#30340;&#23494;&#38598;&#35821;&#27573;&#26816;&#32034;&#65288;DPR&#65289;&#31639;&#27861;&#65292;&#20351;&#29992;&#32622;&#20449;&#24230;&#26657;&#20934;&#30340;&#38598;&#21512;&#39044;&#27979;&#26041;&#27861;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#21457;&#29616;&#19981;&#21516;&#39046;&#22495;&#30340;&#26368;&#20248;&#31890;&#24230;&#20063;&#26377;&#25152;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.15917</link><description>&lt;p&gt;
&#32622;&#20449;&#24230;&#26657;&#20934;&#30340;&#38598;&#21512;&#24335;&#23494;&#38598;&#30701;&#35821;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Confidence-Calibrated Ensemble Dense Phrase Retrieval. (arXiv:2306.15917v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20248;&#21270;&#22522;&#20110;Transformer&#30340;&#23494;&#38598;&#35821;&#27573;&#26816;&#32034;&#65288;DPR&#65289;&#31639;&#27861;&#65292;&#20351;&#29992;&#32622;&#20449;&#24230;&#26657;&#20934;&#30340;&#38598;&#21512;&#39044;&#27979;&#26041;&#27861;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#21457;&#29616;&#19981;&#21516;&#39046;&#22495;&#30340;&#26368;&#20248;&#31890;&#24230;&#20063;&#26377;&#25152;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19981;&#38656;&#35201;&#36827;&#19968;&#27493;&#39044;&#35757;&#32451;&#30340;&#22522;&#20110;Transformer&#30340;&#23494;&#38598;&#35821;&#27573;&#26816;&#32034;&#65288;DPR&#65289;&#31639;&#27861;&#65288;&#30001;Karpukhin&#31561;&#20154;&#20110;2020&#24180;&#24320;&#21457;&#65289;&#30340;&#20248;&#21270;&#31243;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#20851;&#38190;&#27934;&#23519;&#65306;&#25105;&#20204;&#22312;&#19981;&#21516;&#30701;&#35821;&#38271;&#24230;&#65288;&#20363;&#22914;&#19968;&#21477;&#21644;&#20116;&#21477;&#65289;&#19978;&#24212;&#29992;DPR&#19978;&#19979;&#25991;&#32534;&#30721;&#22120;&#65292;&#24182;&#23545;&#25152;&#26377;&#36825;&#20123;&#19981;&#21516;&#20998;&#21106;&#30340;&#32467;&#26524;&#36827;&#34892;&#32622;&#20449;&#24230;&#26657;&#20934;&#30340;&#38598;&#21512;&#39044;&#27979;&#12290;&#36825;&#31181;&#30456;&#23545;&#35814;&#23613;&#30340;&#26041;&#27861;&#22312;Google NQ&#21644;SQuAD&#31561;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#29305;&#23450;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#65292;&#32467;&#26524;&#34920;&#26126;&#19981;&#21516;&#30340;&#39063;&#31890;&#24230;&#23545;&#20110;&#19981;&#21516;&#30340;&#39046;&#22495;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the extent to which the transformer-based Dense Passage Retrieval (DPR) algorithm, developed by (Karpukhin et. al. 2020), can be optimized without further pre-training. Our method involves two particular insights: we apply the DPR context encoder at various phrase lengths (e.g. one-sentence versus five-sentence segments), and we take a confidence-calibrated ensemble prediction over all of these different segmentations. This somewhat exhaustive approach achieves start-of-the-art results on benchmark datasets such as Google NQ and SQuAD. We also apply our method to domain-specific datasets, and the results suggest how different granularities are optimal for different domains
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#21516;&#36807;&#28388;&#35757;&#32451;&#20013;&#32500;&#24230;&#26080;&#20851;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#28151;&#21512;&#26041;&#27861;&#65288;DINS&#65289;&#65292;&#36890;&#36807;&#23545;&#37319;&#26679;&#21306;&#22495;&#30340;&#26032;&#35270;&#35282;&#36827;&#34892;&#37325;&#26032;&#23457;&#35270;&#26469;&#25913;&#36827;&#29616;&#26377;&#30340;&#37319;&#26679;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;DINS&#20248;&#20110;&#20854;&#20182;&#36127;&#37319;&#26679;&#26041;&#27861;&#65292;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.15905</link><description>&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#20013;&#32500;&#24230;&#26080;&#20851;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#28151;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Dimension Independent Mixup for Hard Negative Sample in Collaborative Filtering. (arXiv:2306.15905v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#21516;&#36807;&#28388;&#35757;&#32451;&#20013;&#32500;&#24230;&#26080;&#20851;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#28151;&#21512;&#26041;&#27861;&#65288;DINS&#65289;&#65292;&#36890;&#36807;&#23545;&#37319;&#26679;&#21306;&#22495;&#30340;&#26032;&#35270;&#35282;&#36827;&#34892;&#37325;&#26032;&#23457;&#35270;&#26469;&#25913;&#36827;&#29616;&#26377;&#30340;&#37319;&#26679;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;DINS&#20248;&#20110;&#20854;&#20182;&#36127;&#37319;&#26679;&#26041;&#27861;&#65292;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#22522;&#20110;&#36807;&#21435;&#30340;&#20114;&#21160;&#39044;&#27979;&#29992;&#25143;&#30340;&#20559;&#22909;&#12290;&#36127;&#37319;&#26679;&#22312;&#20351;&#29992;&#38544;&#24335;&#21453;&#39304;&#35757;&#32451;&#22522;&#20110;CF&#30340;&#27169;&#22411;&#26102;&#36215;&#21040;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37319;&#26679;&#21306;&#22495;&#30340;&#26032;&#35270;&#35282;&#26469;&#37325;&#26032;&#23457;&#35270;&#29616;&#26377;&#30340;&#37319;&#26679;&#26041;&#27861;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;&#30446;&#21069;&#30340;&#37319;&#26679;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#28857;&#37319;&#26679;&#25110;&#32447;&#37319;&#26679;&#19978;&#65292;&#32570;&#20047;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#26377;&#30456;&#24403;&#22823;&#19968;&#37096;&#20998;&#22256;&#38590;&#37319;&#26679;&#21306;&#22495;&#26410;&#34987;&#25506;&#32034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32500;&#24230;&#26080;&#20851;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#28151;&#21512;&#26041;&#27861;&#65288;DINS&#65289;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#38024;&#23545;&#35757;&#32451;&#22522;&#20110;CF&#30340;&#27169;&#22411;&#30340;&#21306;&#22495;&#37319;&#26679;&#26041;&#27861;&#12290;DINS&#21253;&#25324;&#19977;&#20010;&#27169;&#22359;&#65306;&#22256;&#38590;&#36793;&#30028;&#23450;&#20041;&#12289;&#32500;&#24230;&#26080;&#20851;&#28151;&#21512;&#21644;&#22810;&#36339;&#27744;&#21270;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;DINS&#20248;&#20110;&#20854;&#20182;&#36127;&#37319;&#26679;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#23427;&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative filtering (CF) is a widely employed technique that predicts user preferences based on past interactions. Negative sampling plays a vital role in training CF-based models with implicit feedback. In this paper, we propose a novel perspective based on the sampling area to revisit existing sampling methods. We point out that current sampling methods mainly focus on Point-wise or Line-wise sampling, lacking flexibility and leaving a significant portion of the hard sampling area un-explored. To address this limitation, we propose Dimension Independent Mixup for Hard Negative Sampling (DINS), which is the first Area-wise sampling method for training CF-based models. DINS comprises three modules: Hard Boundary Definition, Dimension Independent Mixup, and Multi-hop Pooling. Experiments with real-world datasets on both matrix factorization and graph-based models demonstrate that DINS outperforms other negative sampling methods, establishing its effectiveness and superiority. Our wo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22359;&#29366;&#29305;&#24449;&#20132;&#20114; (BFI) &#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#29305;&#24449;&#20132;&#20114;&#36807;&#31243;&#20998;&#25104;&#36739;&#23567;&#30340;&#22359;&#65292;&#20197;&#26174;&#33879;&#20943;&#23569;&#20869;&#23384;&#21344;&#29992;&#21644;&#35745;&#31639;&#36127;&#25285;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BFI&#31639;&#27861;&#22312;&#20934;&#30830;&#24615;&#19978;&#25509;&#36817;&#26631;&#20934;DCNv2&#65292;&#21516;&#26102;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#24320;&#38144;&#21644;&#21442;&#25968;&#25968;&#37327;&#65292;&#20026;&#39640;&#25928;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2306.15881</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22359;&#29366;&#29305;&#24449;&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;
Blockwise Feature Interaction in Recommendation Systems. (arXiv:2306.15881v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15881
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22359;&#29366;&#29305;&#24449;&#20132;&#20114; (BFI) &#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#29305;&#24449;&#20132;&#20114;&#36807;&#31243;&#20998;&#25104;&#36739;&#23567;&#30340;&#22359;&#65292;&#20197;&#26174;&#33879;&#20943;&#23569;&#20869;&#23384;&#21344;&#29992;&#21644;&#35745;&#31639;&#36127;&#25285;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BFI&#31639;&#27861;&#22312;&#20934;&#30830;&#24615;&#19978;&#25509;&#36817;&#26631;&#20934;DCNv2&#65292;&#21516;&#26102;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#24320;&#38144;&#21644;&#21442;&#25968;&#25968;&#37327;&#65292;&#20026;&#39640;&#25928;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#20132;&#20114;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#22240;&#20026;&#23427;&#20204;&#25429;&#25417;&#20102;&#29992;&#25143;&#20559;&#22909;&#21644;&#29289;&#21697;&#29305;&#24449;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#12290;&#29616;&#26377;&#26041;&#27861;&#65288;&#22914;&#28145;&#24230;&#21644;&#20132;&#21449;&#32593;&#32476; DCNv2&#65289;&#21487;&#33021;&#30001;&#20110;&#20854;&#36328;&#23618;&#25805;&#20316;&#32780;&#38754;&#20020;&#39640;&#35745;&#31639;&#38656;&#27714;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#22359;&#29366;&#29305;&#24449;&#20132;&#20114; (BFI)&#65292;&#20197;&#24110;&#21161;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#29305;&#24449;&#20132;&#20114;&#36807;&#31243;&#20998;&#25104;&#36739;&#23567;&#30340;&#22359;&#65292;&#25105;&#20204;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#20869;&#23384;&#21344;&#29992;&#21644;&#35745;&#31639;&#36127;&#25285;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#22235;&#20010;&#21464;&#20307;&#65288;&#20998;&#21035;&#20026; P&#12289;Q&#12289;T&#12289;S&#65289;&#30340; BFI&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#35777;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#19982;&#26631;&#20934; DCNv2 &#30456;&#27604;&#26102;&#33021;&#22815;&#23454;&#29616;&#25509;&#36817;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#24320;&#38144;&#21644;&#21442;&#25968;&#25968;&#37327;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#19968;&#31181;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#23454;&#38469;&#35299;&#20915;&#26041;&#26696;&#65292;&#20026;&#39640;&#25928;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature interactions can play a crucial role in recommendation systems as they capture complex relationships between user preferences and item characteristics. Existing methods such as Deep &amp; Cross Network (DCNv2) may suffer from high computational requirements due to their cross-layer operations. In this paper, we propose a novel approach called blockwise feature interaction (BFI) to help alleviate this issue. By partitioning the feature interaction process into smaller blocks, we can significantly reduce both the memory footprint and the computational burden. Four variants (denoted by P, Q, T, S, respectively) of BFI have been developed and empirically compared. Our experimental results demonstrate that the proposed algorithms achieves close accuracy compared to the standard DCNv2, while greatly reducing the computational overhead and the number of parameters. This paper contributes to the development of efficient recommendation systems by providing a practical solution for improving
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#21160;&#35821;&#20041;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#26681;&#25454;&#26053;&#23458;&#30340;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#65292;&#23454;&#39564;&#20013;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10946</link><description>&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network. (arXiv:2306.10946v1 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26053;&#28216;&#26223;&#28857;&#25512;&#33616;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#21160;&#35821;&#20041;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#26681;&#25454;&#26053;&#23458;&#30340;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#65292;&#23454;&#39564;&#20013;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#25512;&#33616;&#31639;&#27861;&#22312;&#30456;&#23545;&#25104;&#29087;&#38454;&#27573;&#65292;&#20294;&#22312;&#29305;&#23450;&#39046;&#22495;&#30340;&#25512;&#33616;&#20173;&#23384;&#22312;&#38382;&#39064;&#12290;&#20363;&#22914;&#22312;&#26053;&#28216;&#39046;&#22495;&#65292;&#36873;&#25321;&#36866;&#21512;&#30340;&#26053;&#28216;&#26223;&#28857;&#23646;&#24615;&#27969;&#31243;&#20316;&#20026;&#25512;&#33616;&#22522;&#30784;&#36739;&#20026;&#22797;&#26434;&#12290;&#26412;&#25991;&#25552;&#20986;&#25913;&#36827;&#30340;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#27169;&#22411;(Att-KGCN)&#65292;&#33258;&#21160;&#35821;&#20041;&#22320;&#21457;&#25496;&#30446;&#26631;&#26223;&#28857;&#30340;&#30456;&#37051;&#23454;&#20307;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#23618;&#23558;&#30456;&#23545;&#30456;&#20284;&#30340;&#20301;&#32622;&#36827;&#34892;&#32858;&#21512;&#65292;&#24182;&#36890;&#36807;&#25512;&#29702;&#26053;&#23458;&#21916;&#22909;&#36873;&#25321;&#65292;&#39044;&#27979;&#31867;&#20284;&#26223;&#28857;&#30340;&#27010;&#29575;&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#12290;&#23454;&#39564;&#20013;&#65292;&#37319;&#29992;&#32034;&#31185;&#29305;&#25289;&#23707;-&#20063;&#38376;&#30340;&#26053;&#28216;&#25968;&#25454;&#65292;&#35777;&#26126;&#20102;&#27880;&#24847;&#21147;&#30693;&#35782;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#26053;&#28216;&#39046;&#22495;&#30340;&#26223;&#28857;&#25512;&#33616;&#25928;&#26524;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recommendation algorithm based on knowledge graphs is at a relatively mature stage. However, there are still some problems in the recommendation of specific areas. For example, in the tourism field, selecting suitable tourist attraction attributes process is complicated as the recommendation basis for tourist attractions. In this paper, we propose the improved Attention Knowledge Graph Convolution Network model, named (Att-KGCN), which automatically discovers the neighboring entities of the target scenic spot semantically. The attention layer aggregates relatively similar locations and represents them with an adjacent vector. Then, according to the tourist's preferred choices, the model predicts the probability of similar spots as a recommendation system. A knowledge graph dataset of tourist attractions used based on tourism data on Socotra Island-Yemen. Through experiments, it is verified that the Attention Knowledge Graph Convolution Network has a good effect on the recommendatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.05817</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22914;&#20309;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#21463;&#30410;&#65306;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Can Recommender Systems Benefit from Large Language Models: A Survey. (arXiv:2306.05817v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21305;&#37197;&#20114;&#32852;&#32593;&#24212;&#29992;&#31243;&#24207;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20986;&#20102;&#24778;&#20154;&#30340;&#26032;&#20852;&#33021;&#21147;&#65288;&#20363;&#22914;&#25351;&#20196;&#36319;&#36394;&#12289;&#25512;&#29702;&#65289;&#65292;&#20174;&#32780;&#20026;&#23558;LLM&#35843;&#25972;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#20197;&#25552;&#39640;&#24615;&#33021;&#21644;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#30340;&#30740;&#31350;&#26041;&#21521;&#24102;&#26469;&#20102;&#24076;&#26395;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#24212;&#29992;&#23548;&#21521;&#30340;&#35282;&#24230;&#23545;&#27492;&#30740;&#31350;&#26041;&#21521;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#20004;&#20010;&#27491;&#20132;&#30340;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#23545;&#20110;&#8220;&#22312;&#21738;&#37324;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;LLM&#22312;&#25512;&#33616;&#27969;&#31243;&#30340;&#19981;&#21516;&#38454;&#27573;&#20013;&#21487;&#33021;&#21457;&#25381;&#30340;&#20316;&#29992;&#65292;&#21363;&#29305;&#24449;&#24037;&#31243;&#12289;&#29305;&#24449;&#32534;&#30721;&#22120;&#12289;&#35780;&#20998;/&#25490;&#21517;&#20989;&#25968;&#21644;&#27969;&#31243;&#25511;&#21046;&#22120;&#12290;&#23545;&#20110;&#8220;&#22914;&#20309;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#31574;&#30053;&#65292;&#20174;&#32780;&#24471;&#20986;&#20004;&#20010;&#32454;&#31890;&#24230;&#30340;&#20998;&#31867;&#26631;&#20934;&#65292;&#21363;&#26159;&#21542;&#35843;&#25972;LLM&#21644;&#26159;&#21542;&#23558;LLM&#20316;&#20026;&#29420;&#31435;&#27169;&#22411;&#25110;&#28151;&#21512;&#27169;&#22411;&#32452;&#20214;&#20351;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#23558;LLM&#35843;&#25972;&#21040;RS&#20013;&#30340;&#19968;&#20123;&#25361;&#25112;&#21644;&#28508;&#22312;&#26041;&#21521;&#65292;&#21253;&#25324;&#19982;&#29616;&#26377;&#31995;&#32479;&#30340;&#38598;&#25104;&#12289;&#29992;&#25143;&#21453;&#39304;&#12289;&#35780;&#20272;&#24230;&#37327;&#21644;&#30693;&#35782;&#33976;&#39311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) play important roles to match users' information needs for Internet applications. In natural language processing (NLP) domains, large language model (LLM) has shown astonishing emergent abilities (e.g., instruction following, reasoning), thus giving rise to the promising research direction of adapting LLM to RS for performance enhancements and user experience improvements. In this paper, we conduct a comprehensive survey on this research direction from an application-oriented view. We first summarize existing research works from two orthogonal perspectives: where and how to adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, and pipeline controller. For the "HOW" question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLMs or not, a
&lt;/p&gt;</description></item></channel></rss>