<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20013;&#38388;&#23618;&#32423;&#30340;&#24341;&#29992;&#24314;&#35758;&#20219;&#21153;&#8212;&#8212;&#27573;&#33853;&#32423;&#24341;&#29992;&#24314;&#35758;&#65292;&#21363;&#20197;&#27573;&#33853;&#30340;&#20027;&#39064;&#21477;&#20026;&#36755;&#20837;&#65292;&#36755;&#20986;&#22312;&#27573;&#33853;&#20013;&#24341;&#29992;&#30340;&#24314;&#35758;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#35299;&#20915;&#27492;&#20219;&#21153;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.12190</link><description>&lt;p&gt;
&#22522;&#20110;&#20027;&#39064;&#21477;&#20316;&#20026;&#26597;&#35810;&#30340;&#27573;&#33853;&#32423;&#24341;&#29992;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Paragraph-level Citation Recommendation based on Topic Sentences as Queries. (arXiv:2305.12190v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12190
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20013;&#38388;&#23618;&#32423;&#30340;&#24341;&#29992;&#24314;&#35758;&#20219;&#21153;&#8212;&#8212;&#27573;&#33853;&#32423;&#24341;&#29992;&#24314;&#35758;&#65292;&#21363;&#20197;&#27573;&#33853;&#30340;&#20027;&#39064;&#21477;&#20026;&#36755;&#20837;&#65292;&#36755;&#20986;&#22312;&#27573;&#33853;&#20013;&#24341;&#29992;&#30340;&#24314;&#35758;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#35299;&#20915;&#27492;&#20219;&#21153;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#29992;&#24314;&#35758;(CR)&#27169;&#22411;&#21487;&#24110;&#21161;&#20316;&#32773;&#22312;&#35770;&#25991;&#20889;&#20316;&#36807;&#31243;&#20013;&#30340;&#21508;&#20010;&#38454;&#27573;&#25214;&#21040;&#30456;&#20851;&#25991;&#31456;&#12290;&#22823;&#22810;&#25968;&#30740;&#31350;&#22788;&#29702;&#20840;&#23616;CR&#65292;&#35813;&#20840;&#23616;CR&#36866;&#29992;&#20110;&#21021;&#22987;&#20889;&#20316;&#38454;&#27573;&#30340;&#19968;&#33324;&#24314;&#35758;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#27573;&#33853;&#32423;CR&#20219;&#21153;&#65292;&#20316;&#20026;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#19968;&#31181;&#20013;&#38388;&#22320;&#24102;&#65292;&#20854;&#20013;&#27573;&#33853;&#30340;&#20027;&#39064;&#21477;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#27573;&#33853;&#20869;&#24341;&#29992;&#30340;&#24314;&#35758;&#20316;&#20026;&#36755;&#20986;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#24182;&#20351;&#29992;ACL&#35770;&#25991;&#25968;&#25454;&#38598;&#19978;&#30340;&#22235;&#20803;&#32452;&#25439;&#22833;&#36827;&#34892;&#20102;&#24494;&#35843;&#65292;&#32467;&#26524;&#26174;&#31034;&#30456;&#23545;&#20110;&#22522;&#32447;&#26377;&#25152;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Citation recommendation (CR) models may help authors find relevant articles at various stages of the paper writing process. Most research has dealt with either global CR, which produces general recommendations suitable for the initial writing stage, or local CR, which produces specific recommendations more fitting for the final writing stages. We propose the task of paragraph-level CR as a middle ground between the two approaches, where the paragraph's topic sentence is taken as input and recommendations for citing within the paragraph are produced at the output. We propose a model for this task, fine-tune it using the quadruplet loss on the dataset of ACL papers, and show improvements over the baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#29305;&#24449;&#22797;&#29992;&#8221;&#30340;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#21333;&#19968;&#30340;&#34920;&#31034;&#31354;&#38388; &#33021;&#22815;&#39640;&#25928;&#26377;&#25928;&#22320;&#23398;&#20064;&#39640;&#36136;&#37327;&#30340;&#29305;&#24449;&#23884;&#20837;&#65292;&#21516;&#26102;&#21306;&#20998;&#19981;&#21516;&#30340;&#20998;&#31867;&#29305;&#24449;&#12290;&#36890;&#36807;&#22312;&#22810;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#21644;&#26032;&#25968;&#25454;&#38598;&#8220;Web-Available Image Search (WAIS)&#8221;&#19978;&#30340;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.12102</link><description>&lt;p&gt;
&#32479;&#19968;&#23884;&#20837;&#65306;&#38754;&#21521; Web &#35268;&#27169; ML &#31995;&#32479;&#30340;&#32463;&#36807;&#39564;&#35777;&#30340;&#29305;&#24449;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Unified Embedding: Battle-Tested Feature Representations for Web-Scale ML Systems. (arXiv:2305.12102v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#29305;&#24449;&#22797;&#29992;&#8221;&#30340;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#21333;&#19968;&#30340;&#34920;&#31034;&#31354;&#38388; &#33021;&#22815;&#39640;&#25928;&#26377;&#25928;&#22320;&#23398;&#20064;&#39640;&#36136;&#37327;&#30340;&#29305;&#24449;&#23884;&#20837;&#65292;&#21516;&#26102;&#21306;&#20998;&#19981;&#21516;&#30340;&#20998;&#31867;&#29305;&#24449;&#12290;&#36890;&#36807;&#22312;&#22810;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#21644;&#26032;&#25968;&#25454;&#38598;&#8220;Web-Available Image Search (WAIS)&#8221;&#19978;&#30340;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#12289;&#26377;&#25928;&#22320;&#23398;&#20064;&#39640;&#36136;&#37327;&#30340;&#29305;&#24449;&#23884;&#20837;&#23545;&#20110; Web &#35268;&#27169;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#26631;&#20934;&#26041;&#27861;&#26159;&#23558;&#27599;&#20010;&#29305;&#24449;&#20540;&#34920;&#31034;&#20026;&#19968;&#20010; d &#32500;&#23884;&#20837;&#65292;&#24341;&#20837;&#25968;&#30334;&#20159;&#20010;&#21442;&#25968;&#65292;&#32780;&#36825;&#20123;&#29305;&#24449;&#30340;&#22522;&#25968;&#38750;&#24120;&#39640;&#12290;&#36825;&#20010;&#29942;&#39048;&#23548;&#33268;&#20102;&#22791;&#36873;&#23884;&#20837;&#31639;&#27861;&#30340;&#37325;&#22823;&#36827;&#23637;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#38750;&#24120;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#21363;&#8220;&#29305;&#24449;&#22797;&#29992;&#8221;&#65292;&#22312;&#35768;&#22810;&#19981;&#21516;&#30340;&#20998;&#31867;&#29305;&#24449;&#20043;&#38388;&#20351;&#29992;&#19968;&#20010;&#21333;&#19968;&#30340;&#34920;&#31034;&#31354;&#38388;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#22797;&#29992;&#30340;&#23884;&#20837;&#21487;&#20197;&#20998;&#35299;&#20026;&#27599;&#20010;&#32452;&#25104;&#29305;&#24449;&#30340;&#32452;&#20214;&#65292;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#21306;&#20998;&#29305;&#24449;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22797;&#29992;&#30340;&#23884;&#20837;&#22312;&#20960;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;Web-Available Image Search (WAIS)&#8221;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#20197;&#20005;&#26684;&#35780;&#20272; Web &#35268;&#27169;&#19979;&#30340;&#26032;&#23884;&#20837;&#31639;&#27861;&#12290;&#25105;&#20204;&#36992;&#35831;&#31038;&#21306;&#36890;&#36807;&#25552;&#20986;&#21487;&#20197;&#20934;&#30830;&#12289;&#39640;&#25928;&#22320;&#23558;&#25968;&#30334;&#19975;&#24352;&#22270;&#20687;&#23884;&#20837;&#21644;&#20998;&#31867;&#21040;&#25104;&#21315;&#19978;&#19975;&#20010;&#31867;&#21035;&#30340;&#26032;&#27169;&#22411;&#26469;&#36129;&#29486; WAIS &#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning high-quality feature embeddings efficiently and effectively is critical for the performance of web-scale machine learning systems. A typical model ingests hundreds of features with vocabularies on the order of millions to billions of tokens. The standard approach is to represent each feature value as a d-dimensional embedding, introducing hundreds of billions of parameters for extremely high-cardinality features. This bottleneck has led to substantial progress in alternative embedding algorithms. Many of these methods, however, make the assumption that each feature uses an independent embedding table. This work introduces a simple yet highly effective framework, Feature Multiplexing, where one single representation space is used across many different categorical features. Our theoretical and empirical analysis reveals that multiplexed embeddings can be decomposed into components from each constituent feature, allowing models to distinguish between features. We show that multip
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#30784;&#27169;&#22411;UP5&#65292;&#23427;&#37319;&#29992;&#21453;&#20107;&#23454;&#20844;&#24179;&#20419;&#36827;&#25216;&#26415;&#26469;&#28040;&#38500;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#65292;&#20174;&#32780;&#23454;&#29616;&#38754;&#21521;&#20844;&#24179;&#24615;&#30340;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2305.12090</link><description>&lt;p&gt;
UP5: &#38754;&#21521;&#20844;&#24179;&#24615;&#25512;&#33616;&#30340;&#26080;&#20559;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
UP5: Unbiased Foundation Model for Fairness-aware Recommendation. (arXiv:2305.12090v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#30784;&#27169;&#22411;UP5&#65292;&#23427;&#37319;&#29992;&#21453;&#20107;&#23454;&#20844;&#24179;&#20419;&#36827;&#25216;&#26415;&#26469;&#28040;&#38500;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#65292;&#20174;&#32780;&#23454;&#29616;&#38754;&#21521;&#20844;&#24179;&#24615;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#31561;&#22522;&#30784;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24050;&#23558;&#23427;&#20204;&#25512;&#21040;&#20102;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#30340;&#21069;&#27839;&#12290;&#27492;&#22806;&#65292;RS&#20013;&#30340;&#20844;&#24179;&#24615;&#24456;&#20851;&#38190;&#65292;&#22240;&#20026;&#35768;&#22810;&#29992;&#25143;&#23558;&#20854;&#29992;&#20110;&#20915;&#31574;&#21644;&#38656;&#27714;&#23653;&#34892;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#32570;&#20047;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#23637;&#31034;&#20844;&#24179;&#24615;&#27700;&#24179;&#21644;&#20844;&#24179;&#22788;&#29702;&#19981;&#21516;&#29992;&#25143;&#32676;&#32452;&#30340;&#36866;&#24403;&#26041;&#27861;&#30340;&#29702;&#35299;&#12290;&#26412;&#25991;&#20391;&#37325;&#20110;&#29992;&#25143;&#26041;&#38754;&#30340;&#19981;&#20844;&#24179;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24443;&#24213;&#26816;&#26597;&#34920;&#26126;&#65292;LLMs&#20013;&#23384;&#22312;&#19981;&#20844;&#24179;&#24615;&#65292;&#23548;&#33268;&#19981;&#20844;&#24179;&#30340;&#25512;&#33616;&#32467;&#26524;&#12290;&#20026;&#20102;&#28040;&#38500;LLM&#20013;&#30340;&#20559;&#24046;&#20197;&#23454;&#29616;&#38754;&#21521;&#20844;&#24179;&#24615;&#30340;&#25512;&#33616;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#20844;&#24179;&#20419;&#36827;&#25216;&#26415;&#30340;&#26032;&#22411;&#26080;&#20559;P5&#65288;UP5&#65289;&#22522;&#30784;&#27169;&#22411;&#12290;CFP&#21253;&#25324;&#20004;&#20010;&#23376;&#27169;&#22359;&#65306;&#20010;&#24615;&#21270;&#21069;&#32512;&#25552;&#31034;&#21644;Prompt&#28151;&#21512;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#20010;&#20307;&#25935;&#24863;&#23646;&#24615;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in foundation models such as large language models (LLM) have propelled them to the forefront of recommender systems (RS). Moreover, fairness in RS is critical since many users apply it for decision-making and demand fulfillment. However, at present, there is a lack of understanding regarding the level of fairness exhibited by recommendation foundation models and the appropriate methods for equitably treating different groups of users in foundation models. In this paper, we focus on user-side unfairness problem and show through a thorough examination that there is unfairness involved in LLMs that lead to unfair recommendation results. To eliminate bias from LLM for fairness-aware recommendation, we introduce a novel Unbiased P5 (UP5) foundation model based on Counterfactually-Fair-Prompting (CFP) techniques. CFP includes two sub-modules: a personalized prefix prompt that enhances fairness with respect to individual sensitive attributes, and a Prompt Mixture that int
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#24615;&#30340;&#28145;&#24230;&#36328;&#39046;&#22495;&#28857;&#20987;&#29575;&#39044;&#27979;&#27169;&#22411;&#8212;&#8212;&#39046;&#22495;&#23545;&#25239;&#28145;&#24230;&#20852;&#36259;&#32593;&#32476;&#65288;DADIN&#65289;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;&#39046;&#22495;&#19981;&#21487;&#30693;&#23618;&#21644;&#29305;&#21035;&#35774;&#35745;&#30340;&#25439;&#22833;&#65292;&#21019;&#26032;&#22320;&#23454;&#29616;&#20102;&#20004;&#20010;&#39046;&#22495;&#30340;&#32852;&#21512;&#20998;&#24067;&#23545;&#40784;&#65292;&#24182;&#37319;&#29992;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#24335;&#19982;&#28857;&#20987;&#29575;&#39044;&#27979;&#25439;&#22833;&#19968;&#36215;&#36827;&#34892;&#20248;&#21270;&#65292;&#30456;&#27604;&#31454;&#20105;&#22522;&#32447;&#31639;&#27861;&#25552;&#21319;&#26126;&#26174;&#12290;</title><link>http://arxiv.org/abs/2305.12058</link><description>&lt;p&gt;
DADIN: &#38754;&#21521;&#36328;&#22495;&#25512;&#33616;&#31995;&#32479;&#30340;&#39046;&#22495;&#23545;&#25239;&#28145;&#24230;&#20852;&#36259;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
DADIN: Domain Adversarial Deep Interest Network for Cross Domain Recommender Systems. (arXiv:2305.12058v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12058
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#24615;&#30340;&#28145;&#24230;&#36328;&#39046;&#22495;&#28857;&#20987;&#29575;&#39044;&#27979;&#27169;&#22411;&#8212;&#8212;&#39046;&#22495;&#23545;&#25239;&#28145;&#24230;&#20852;&#36259;&#32593;&#32476;&#65288;DADIN&#65289;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#24341;&#20837;&#39046;&#22495;&#19981;&#21487;&#30693;&#23618;&#21644;&#29305;&#21035;&#35774;&#35745;&#30340;&#25439;&#22833;&#65292;&#21019;&#26032;&#22320;&#23454;&#29616;&#20102;&#20004;&#20010;&#39046;&#22495;&#30340;&#32852;&#21512;&#20998;&#24067;&#23545;&#40784;&#65292;&#24182;&#37319;&#29992;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#24335;&#19982;&#28857;&#20987;&#29575;&#39044;&#27979;&#25439;&#22833;&#19968;&#36215;&#36827;&#34892;&#20248;&#21270;&#65292;&#30456;&#27604;&#31454;&#20105;&#22522;&#32447;&#31639;&#27861;&#25552;&#21319;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#39044;&#27979;&#26159;&#25512;&#33616;&#31995;&#32479;&#30340;&#20027;&#35201;&#20219;&#21153;&#20043;&#19968;&#65292;&#29992;&#25143;&#38024;&#23545;&#19981;&#21516;&#39033;&#30446;&#36827;&#34892;&#28857;&#20987;&#20197;&#33719;&#21462;&#25512;&#33616;&#32467;&#26524;&#12290;&#38024;&#23545;&#25968;&#25454;&#31232;&#30095;&#24615;&#12289;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30340;&#38271;&#23614;&#20998;&#24067;&#21644;&#39033;&#30446;&#25110;&#29992;&#25143;&#30340;&#20919;&#21551;&#21160;&#31561;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#36328;&#39046;&#22495;&#28857;&#20987;&#29575;&#39044;&#27979;&#27169;&#22411;&#12290;&#20026;&#20102;&#20351;&#28304;&#22495;&#21040;&#30446;&#26631;&#22495;&#30340;&#30693;&#35782;&#36716;&#31227;&#26356;&#21152;&#39034;&#30021;&#65292;&#25552;&#20986;&#20102;&#21019;&#26032;&#24615;&#30340;&#28145;&#24230;&#36328;&#39046;&#22495;&#28857;&#20987;&#29575;&#39044;&#27979;&#27169;&#22411;&#8212;&#8212;&#39046;&#22495;&#23545;&#25239;&#28145;&#24230;&#20852;&#36259;&#32593;&#32476; (DADIN)&#65292;&#23558;&#36328;&#22495;&#25512;&#33616;&#20219;&#21153;&#36716;&#21270;&#20026;&#39046;&#22495;&#36866;&#24212;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#39046;&#22495;&#19981;&#21487;&#30693;&#23618;&#21644;&#29305;&#21035;&#35774;&#35745;&#30340;&#25439;&#22833;&#65292;&#21019;&#26032;&#22320;&#23454;&#29616;&#20102;&#20004;&#20010;&#39046;&#22495;&#30340;&#32852;&#21512;&#20998;&#24067;&#23545;&#40784;&#65292;&#24182;&#37319;&#29992;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#24335;&#19982;&#28857;&#20987;&#29575;&#39044;&#27979;&#25439;&#22833;&#19968;&#36215;&#36827;&#34892;&#20248;&#21270;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21326;&#20026;&#25968;&#25454;&#38598;&#19978;&#65292;DADIN &#30340;&#26354;&#32447;&#19979;&#38754;&#31215; (AUC) &#27604;&#26368;&#20855;&#31454;&#20105;&#21147;&#30340;&#22522;&#32447;&#39640;&#20986;0.08&#65285;&#65292;&#39640;&#20986;0.7&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
Click-Through Rate (CTR) prediction is one of the main tasks of the recommendation system, which is conducted by a user for different items to give the recommendation results. Cross-domain CTR prediction models have been proposed to overcome problems of data sparsity, long tail distribution of user-item interactions, and cold start of items or users. In order to make knowledge transfer from source domain to target domain more smoothly, an innovative deep learning cross-domain CTR prediction model, Domain Adversarial Deep Interest Network (DADIN) is proposed to convert the cross-domain recommendation task into a domain adaptation problem. The joint distribution alignment of two domains is innovatively realized by introducing domain agnostic layers and specially designed loss, and optimized together with CTR prediction loss in a way of adversarial training. It is found that the Area Under Curve (AUC) of DADIN is 0.08% higher than the most competitive baseline on Huawei dataset and is 0.7
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#30005;&#23376;&#21830;&#21153;&#21644;&#21307;&#30103;&#20445;&#20581;&#31561;&#19987;&#19994;&#39046;&#22495;&#20013;&#65292;&#21033;&#29992;&#24378;&#22823;&#30340;&#27169;&#22411;&#29983;&#25104;&#39640;&#36136;&#37327;&#29305;&#23450;&#20219;&#21153;&#21644;&#39046;&#22495;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#25506;&#32034;&#29992;&#20110;&#39044;&#27979;&#23545;&#25991;&#26723;&#30340;&#26597;&#35810;&#20998;&#32423;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20351;&#29992;&#26080;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#36827;&#19968;&#27493;&#25913;&#36827;&#23545;&#25968;&#25454;&#20013;&#30456;&#20851;&#24615;&#27169;&#24335;&#30340;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.11944</link><description>&lt;p&gt;
&#25506;&#32034;&#29992;&#20110;&#30456;&#20851;&#24615;&#39044;&#27979;&#30340;&#21512;&#25104;&#26597;&#35810;&#29983;&#25104;&#30340;&#21487;&#34892;&#24615;
&lt;/p&gt;
&lt;p&gt;
Exploring the Viability of Synthetic Query Generation for Relevance Prediction. (arXiv:2305.11944v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#30005;&#23376;&#21830;&#21153;&#21644;&#21307;&#30103;&#20445;&#20581;&#31561;&#19987;&#19994;&#39046;&#22495;&#20013;&#65292;&#21033;&#29992;&#24378;&#22823;&#30340;&#27169;&#22411;&#29983;&#25104;&#39640;&#36136;&#37327;&#29305;&#23450;&#20219;&#21153;&#21644;&#39046;&#22495;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#25506;&#32034;&#29992;&#20110;&#39044;&#27979;&#23545;&#25991;&#26723;&#30340;&#26597;&#35810;&#20998;&#32423;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20351;&#29992;&#26080;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#36827;&#19968;&#27493;&#25913;&#36827;&#23545;&#25968;&#25454;&#20013;&#30456;&#20851;&#24615;&#27169;&#24335;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;-&#25991;&#26723;&#30456;&#20851;&#24615;&#39044;&#27979;&#26159;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#36234;&#26469;&#36234;&#22810;&#22320;&#20351;&#29992;&#65288;&#39044;&#20808;&#35757;&#32451;&#30340;&#65289;&#22522;&#20110;&#36716;&#25442;&#22120;&#30340;&#27169;&#22411;&#26469;&#35299;&#20915;&#65292;&#36825;&#20123;&#27169;&#22411;&#20351;&#29992;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292;&#22312;&#30005;&#23376;&#21830;&#21153;&#21644;&#21307;&#30103;&#20445;&#20581;&#31561;&#19987;&#19994;&#39046;&#22495;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21463;&#21040;&#39046;&#22495;&#20869;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#21294;&#20047;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26368;&#36817;&#30340;&#26041;&#27861;&#21033;&#29992;&#36825;&#20123;&#24378;&#22823;&#30340;&#27169;&#22411;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#29305;&#23450;&#20219;&#21153;&#21644;&#39046;&#22495;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20027;&#35201;&#25506;&#32034;&#20102;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#25110;&#29992;&#20110;&#38382;&#31572;&#21644;&#20108;&#20803;&#65288;&#26159;/&#21542;&#65289;&#30456;&#20851;&#24615;&#39044;&#27979;&#30340;&#26597;&#35810;&#29983;&#25104;&#65288;QGen&#65289;, &#20854;&#20013;&#20363;&#22914;&#65292;QGen&#27169;&#22411;&#32473;&#20986;&#19968;&#20010;&#25991;&#26723;&#65292;&#24182;&#35757;&#32451;&#29983;&#25104;&#19968;&#20010;&#19982;&#35813;&#25991;&#26723;&#30456;&#20851;&#30340;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#23545;&#30456;&#20851;&#24615;&#26377;&#19968;&#20010;&#26356;&#32454;&#31890;&#24230;&#30340;&#27010;&#24565;&#65292;&#32780;&#19981;&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#26159;/&#21542;&#26631;&#31614;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#35814;&#32454;&#30340;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;QGen&#26041;&#27861;&#23454;&#29616;&#32454;&#24494;&#30340;&#30456;&#20851;&#24615;&#39044;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#21512;&#25104;&#26597;&#35810;&#26469;&#39044;&#27979;&#23545;&#25991;&#26723;&#30340;&#26597;&#35810;&#20998;&#32423;&#30456;&#20851;&#24615;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25506;&#32034;&#20351;&#29992;&#26080;&#30417;&#30563;&#32858;&#31867;&#25216;&#26415;&#36827;&#19968;&#27493;&#25913;&#36827;&#23545;&#25968;&#25454;&#20013;&#30456;&#20851;&#24615;&#27169;&#24335;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Query-document relevance prediction is a critical problem in Information Retrieval systems. This problem has increasingly been tackled using (pretrained) transformer-based models which are finetuned using large collections of labeled data. However, in specialized domains such as e-commerce and healthcare, the viability of this approach is limited by the dearth of large in-domain data. To address this paucity, recent methods leverage these powerful models to generate high-quality task and domain-specific synthetic data. Prior work has largely explored synthetic data generation or query generation (QGen) for Question-Answering (QA) and binary (yes/no) relevance prediction, where for instance, the QGen models are given a document, and trained to generate a query relevant to that document. However in many problems, we have a more fine-grained notion of relevance than a simple yes/no label. Thus, in this work, we conduct a detailed study into how QGen approaches can be leveraged for nuanced
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;InteR&#65292;&#36890;&#36807;&#25628;&#32034;&#24341;&#25806;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#20132;&#20114;&#20419;&#36827;&#30693;&#35782;&#31934;&#28860;&#65292;&#20174;&#32780;&#25552;&#39640;&#26816;&#32034;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.07402</link><description>&lt;p&gt;
&#25628;&#32034;&#24341;&#25806;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38388;&#30340;&#20132;&#20114;&#20248;&#21270;&#30693;&#35782;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
Knowledge Refinement via Interaction Between Search Engines and Large Language Models. (arXiv:2305.07402v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;InteR&#65292;&#36890;&#36807;&#25628;&#32034;&#24341;&#25806;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#20132;&#20114;&#20419;&#36827;&#30693;&#35782;&#31934;&#28860;&#65292;&#20174;&#32780;&#25552;&#39640;&#26816;&#32034;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#22312;&#20174;&#22823;&#37327;&#25968;&#25454;&#20013;&#23450;&#20301;&#30456;&#20851;&#36164;&#28304;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#20316;&#29992;&#65292;&#20854;&#24212;&#29992;&#24050;&#20174;&#20256;&#32479;&#30693;&#35782;&#24211;&#21457;&#23637;&#33267;&#29616;&#20195;&#25628;&#32034;&#24341;&#25806;&#65288;SEs&#65289;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#36827;&#19968;&#27493;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#19982;&#25628;&#32034;&#31995;&#32479;&#20132;&#20114;&#38761;&#21629;&#24615;&#22320;&#25913;&#21464;&#20102;&#35813;&#39046;&#22495;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;LLMs&#21644;SEs&#30340;&#20248;&#32570;&#28857;&#65292;&#24378;&#35843;&#23427;&#20204;&#22312;&#29702;&#35299;&#29992;&#25143;&#26597;&#35810;&#21644;&#26816;&#32034;&#26368;&#26032;&#20449;&#24687;&#26041;&#38754;&#30340;&#21508;&#33258;&#20248;&#21183;&#12290;&#20026;&#20102;&#21033;&#29992;&#20004;&#31181;&#33539;&#20363;&#30340;&#20248;&#21183;&#24182;&#36991;&#20813;&#20854;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;InteR&#65292;&#36825;&#26159;&#19968;&#20010;&#36890;&#36807;SEs&#21644;LLMs&#20043;&#38388;&#30340;&#20132;&#20114;&#20419;&#36827;&#30693;&#35782;&#31934;&#28860;&#30340;&#26032;&#26694;&#26550;&#12290; InteR&#20351;SEs&#33021;&#22815;&#20351;&#29992;LLM&#29983;&#25104;&#30340;&#25688;&#35201;&#26469;&#35843;&#25972;&#26597;&#35810;&#65292;&#21516;&#26102;&#20351;LLMs&#33021;&#22815;&#20351;&#29992;SE&#26816;&#32034;&#21040;&#30340;&#25991;&#26723;&#26469;&#22686;&#24378;&#25552;&#31034;&#12290;&#36825;&#31181;&#36845;&#20195;&#30340;&#31934;&#28860;&#36807;&#31243;&#22686;&#24378;&#20102;SEs&#21644;LLMs&#30340;&#36755;&#20837;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#20934;&#30830;&#30340;&#26816;&#32034;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern search engines (SEs). The emergence of large language models (LLMs) has further revolutionized the field by enabling users to interact with search systems in natural language. In this paper, we explore the advantages and disadvantages of LLMs and SEs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information. To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates knowledge refinement through interaction between SEs and LLMs. InteR allows SEs to refine knowledge in query using LLM-generated summaries and enables LLMs to enhance prompts using SE-retrieved documents. This iterative refinement process augments the inputs of SEs and LLMs, leading to more accurate retrieval. Ex
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#29983;&#25104;&#22823;&#37327;&#21512;&#25104;&#26597;&#35810;&#21644;reranker&#27169;&#22411;&#65292;&#33976;&#39311;&#20026;&#39640;&#25928;&#30340;&#26816;&#32034;&#22120;&#65292;&#36866;&#29992;&#20110;&#38271;&#23614;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2303.00807</link><description>&lt;p&gt;
UDAPDR: &#22522;&#20110;LLM&#25552;&#31034;&#19982;reranker&#33976;&#39311;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers. (arXiv:2303.00807v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00807
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#29983;&#25104;&#22823;&#37327;&#21512;&#25104;&#26597;&#35810;&#21644;reranker&#27169;&#22411;&#65292;&#33976;&#39311;&#20026;&#39640;&#25928;&#30340;&#26816;&#32034;&#22120;&#65292;&#36866;&#29992;&#20110;&#38271;&#23614;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24456;&#22810;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#38656;&#35201;&#22823;&#22411;&#26631;&#27880;&#25968;&#25454;&#38598;&#36827;&#34892;&#24494;&#35843;&#65292;&#20294;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#36890;&#24120;&#19981;&#21487;&#29992;&#65292;&#19988;&#22312;&#24212;&#29992;&#20110;&#30495;&#23454;&#22330;&#26223;&#20013;&#26102;&#21487;&#33021;&#20250;&#22240;&#20026;&#39046;&#22495;&#28418;&#31227;&#32780;&#36805;&#36895;&#22833;&#21435;&#25928;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24265;&#20215;&#29983;&#25104;&#22823;&#37327;&#21512;&#25104;&#26597;&#35810;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#21033;&#29992;&#26114;&#36149;&#30340;LLM&#29983;&#25104;&#23569;&#37327;&#21512;&#25104;&#26597;&#35810;&#65292;&#28982;&#21518;&#20877;&#21033;&#29992;&#25104;&#26412;&#36739;&#20302;&#30340;LLM&#29983;&#25104;&#22823;&#37327;&#30340;&#21512;&#25104;&#26597;&#35810;&#20197;&#24494;&#35843;&#19968;&#32452;reranker&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#36825;&#20123;reranker&#20250;&#34987;&#33976; distill &#25104;&#19968;&#20010;&#39640;&#25928;&#30340;&#26816;&#32034;&#22120;&#65292;&#29992;&#20110;&#30446;&#26631;&#39046;&#22495;&#20013;&#30340;&#26816;&#32034;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#38271;&#23614;&#39046;&#22495;&#20013;&#30340;&#38646;&#26679;&#26412;&#20934;&#30830;&#24615;&#65292;&#21363;&#20351;&#21482;&#20351;&#29992;2K&#20010;&#21512;&#25104;&#26597;&#35810;&#36827;&#34892;&#24494;&#35843;&#65292;&#24182;&#19988;&#27604;&#26631;&#20934;&#30340;reranking&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#24310;&#36831;&#12290;&#25105;&#20204;&#25552;&#20379;&#23436;&#25972;&#30340;&#31471;&#21040;&#31471;&#26041;&#26696;&#65292;&#21253;&#25324;&#21512;&#25104;&#25968;&#25454;&#38598;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many information retrieval tasks require large labeled datasets for fine-tuning. However, such datasets are often unavailable, and their utility for real-world applications can diminish quickly due to domain shifts. To address this challenge, we develop and motivate a method for using large language models (LLMs) to generate large numbers of synthetic queries cheaply. The method begins by generating a small number of synthetic queries using an expensive LLM. After that, a much less expensive one is used to create large numbers of synthetic queries, which are used to fine-tune a family of reranker models. These rerankers are then distilled into a single efficient retriever for use in the target domain. We show that this technique boosts zero-shot accuracy in long-tail domains, even where only 2K synthetic queries are used for fine-tuning, and that it achieves substantially lower latency than standard reranking methods. We make our end-to-end approach, including our synthetic datasets an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#24120;&#29992;&#25439;&#22833;&#20989;&#25968;&#30340;&#20248;&#21155;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#26174;&#33879;&#25552;&#21319;&#22810;&#31181;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.00979</link><description>&lt;p&gt;
&#19968;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#25552;&#21319;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Improving Sequential Recommendation Models with an Enhanced Loss Function. (arXiv:2301.00979v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.00979
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#24120;&#29992;&#25439;&#22833;&#20989;&#25968;&#30340;&#20248;&#21155;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#26174;&#33879;&#25552;&#21319;&#22810;&#31181;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20154;&#20204;&#23545;&#20110;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#22797;&#29616;/&#25913;&#36827;&#29616;&#26377;&#27169;&#22411;&#30340;&#24037;&#20316;&#12290;&#26412;&#25991;&#36890;&#36807;&#20998;&#26512;&#24120;&#29992;&#30340;&#39034;&#24207;&#25512;&#33616;&#25439;&#22833;&#20989;&#25968;&#30340;&#20248;&#21155;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#20805;&#20998;&#21033;&#29992;&#23427;&#20204;&#30340;&#20248;&#28857;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#25913;&#36827;&#30340;&#25439;&#22833;&#20989;&#25968;&#26174;&#33879;&#25552;&#21319;&#20102; GRU4Rec&#65292;SASRec&#65292;SR-GNN&#21644; S3Rec&#31561;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been a growing interest in benchmarking sequential recommendation models and reproducing/improving existing models. For example, Rendle et al. improved matrix factorization models by tuning their parameters and hyperparameters. Petrov and Macdonald developed a more efficient and effective implementation of BERT4Rec, which resolved inconsistencies in performance comparison between BERT4Rec and SASRec in previous works. In particular, BERT4Rec and SASRec share a similar network structure, with the main difference lying in their training objective/loss function. Therefore, we analyzed the advantages and disadvantages of commonly used loss functions in sequential recommendation and proposed an improved loss function that leverages their strengths. We conduct extensive experiments on two influential open-source libraries, and the results demonstrate that our improved loss function significantly enhances the performance of GRU4Rec, SASRec, SR-GNN, and S3Rec models, improving their 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;MetaC&#24694;&#24847;&#25915;&#20987;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27450;&#35784;&#32773;&#26816;&#27979;&#27169;&#22359;PDR&#65292;&#26126;&#30830;&#32771;&#34385;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.11534</link><description>&lt;p&gt;
&#20174;&#33258;&#36866;&#24212;&#27450;&#35784;&#32773;&#26816;&#27979;&#25506;&#31350;&#23545;&#25239;&#40065;&#26834;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Towards Adversarially Robust Recommendation from Adaptive Fraudster Detection. (arXiv:2211.11534v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;MetaC&#24694;&#24847;&#25915;&#20987;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27450;&#35784;&#32773;&#26816;&#27979;&#27169;&#22359;PDR&#65292;&#26126;&#30830;&#32771;&#34385;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#33410;&#28857;&#27880;&#20837;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#22791;&#21463;&#20851;&#27880;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;GraphRfi&#65292;&#23427;&#26377;&#25928;&#20943;&#36731;&#20102;&#27880;&#20837;&#30340;&#34394;&#20551;&#29992;&#25143;&#30340;&#24433;&#21709;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;GraphRfi&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#65292;&#22240;&#20026;&#20854;&#27450;&#35784;&#32773;&#26816;&#27979;&#32452;&#20214;&#30340;&#30417;&#30563;&#24615;&#36136;&#65292;&#22312;&#23454;&#36341;&#20013;&#24456;&#38590;&#33719;&#24471;&#24178;&#20928;&#30340;&#26631;&#31614;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;MetaC&#24694;&#24847;&#25915;&#20987;&#65292;&#38024;&#23545;GNN-based&#21644;MF-based&#25512;&#33616;&#31995;&#32479;&#12290;&#26681;&#25454;&#25105;&#20204;&#20174;&#26131;&#21463;&#25915;&#20987;&#24615;&#20998;&#26512;&#20013;&#24471;&#21040;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27450;&#35784;&#32773;&#26816;&#27979;&#27169;&#22359;&#65292;&#26126;&#30830;&#32771;&#34385;&#20102;&#26631;&#31614;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22359;&#21487;&#20197;&#20316;&#20026;&#19981;&#21516;&#25512;&#33616;&#31995;&#32479;&#30340;&#25554;&#20214;&#65292;&#24418;&#25104;&#19968;&#20010;&#31283;&#20581;&#30340;&#26694;&#26550;&#65288;PDR&#65289;&#12290;&#20840;&#38754;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#26041;&#27861;&#22312;&#25915;&#20987;&#19979;&#20248;&#20110;&#20854;&#20182;&#22522;&#20934;&#26041;&#27861;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#22312;&#26500;&#24314;&#27450;&#35784;&#32773;&#26816;&#27979;&#27169;&#22359;&#26102;&#32771;&#34385;&#26631;&#31614;&#19981;&#30830;&#23450;&#24615;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#23545;&#33410;&#28857;&#27880;&#20837;&#25915;&#20987;&#40065;&#26834;&#24615;&#30340;&#23454;&#29992;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
The robustness of recommender systems under node injection attacks has garnered significant attention. Recently, GraphRfi, a GNN-based recommender system, was proposed and shown to effectively mitigate the impact of injected fake users. However, we demonstrate that GraphRfi remains vulnerable to attacks due to the supervised nature of its fraudster detection component, where obtaining clean labels is challenging in practice. In particular, we propose a powerful poisoning attack, MetaC, against both GNN-based and MF-based recommender systems. Furthermore, we analyze why GraphRfi fails under such an attack. Then, based on our insights obtained from vulnerability analysis, we design an adaptive fraudster detection module that explicitly considers label uncertainty. This module can serve as a plug-in for different recommender systems, resulting in a robust framework named PDR. Comprehensive experiments show that our defense approach outperforms other benchmark methods under attacks. Overal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#21487;&#20197;&#22312;&#38750;&#24120;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#28145;&#24230;&#35821;&#38899;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#21462;&#24471;&#20102;&#19982;&#26368;&#20808;&#36827;&#32467;&#26524;&#30456;&#24403;&#30340;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/1912.05946</link><description>&lt;p&gt;
&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#25552;&#21319;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Leveraging End-to-End Speech Recognition with Neural Architecture Search. (arXiv:1912.05946v2 [eess.AS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1912.05946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#21487;&#20197;&#22312;&#38750;&#24120;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#28145;&#24230;&#35821;&#38899;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#21462;&#24471;&#20102;&#19982;&#26368;&#20808;&#36827;&#32467;&#26524;&#30456;&#24403;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#34987;&#35777;&#23454;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#26041;&#38754;&#20248;&#20110;&#35768;&#22810;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#26377;&#25928;&#23454;&#26045;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#21487;&#20197;&#22312;&#38750;&#24120;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#28145;&#24230;&#35821;&#38899;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#20351;&#29992;&#27969;&#34892;&#30340;LibriSpeech&#21644;TIMIT&#22522;&#20934;&#27979;&#35797;&#20013;&#36827;&#34892;&#30340;&#38899;&#32032;&#35782;&#21035;&#27979;&#35797;&#35777;&#26126;&#20102;&#36825;&#19968;&#20107;&#23454;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#20960;&#20010;&#23567;&#26102;&#20043;&#20869;&#65288;&#19981;&#21040;&#19968;&#22825;&#65289;&#65292;&#27604;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;seq2seq&#27169;&#22411;&#24555;&#22810;&#27425;&#65292;&#25506;&#27979;&#21644;&#35757;&#32451;&#26032;&#30340;&#20505;&#36873;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;LibriSpeech&#35821;&#26009;&#24211;&#19978;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#65288;WER&#65289;&#20026;7&#65285;&#65292;&#22312;TIMIT&#35821;&#26009;&#24211;&#19978;&#30340;&#38899;&#32032;&#35823;&#24046;&#29575;&#65288;PER&#65289;&#20026;13&#65285;&#65292;&#36798;&#21040;&#20102;&#19982;&#26368;&#20808;&#36827;&#32467;&#26524;&#30456;&#24403;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) have been demonstrated to outperform many traditional machine learning algorithms in Automatic Speech Recognition (ASR). In this paper, we show that a large improvement in the accuracy of deep speech models can be achieved with effective Neural Architecture Optimization at a very low computational cost. Phone recognition tests with the popular LibriSpeech and TIMIT benchmarks proved this fact by displaying the ability to discover and train novel candidate models within a few hours (less than a day) many times faster than the attention-based seq2seq models. Our method achieves test error of 7% Word Error Rate (WER) on the LibriSpeech corpus and 13% Phone Error Rate (PER) on the TIMIT corpus, on par with state-of-the-art results.
&lt;/p&gt;</description></item><item><title>NLPExplorer&#26159;&#19968;&#20010;&#33258;&#21160;&#21270;&#38376;&#25143;&#32593;&#31449;&#65292;&#29992;&#20110;&#32034;&#24341;&#12289;&#25628;&#32034;&#21644;&#21487;&#35270;&#21270;NLP&#30740;&#31350;&#25991;&#29486;&#65292;&#25163;&#21160;&#31574;&#21010;&#20116;&#31867;&#20027;&#39064;&#31867;&#21035;&#12290;&#25552;&#20379;&#20102;&#24180;&#36731;&#28909;&#38376;&#20316;&#32773;&#12289;&#28909;&#38376;URL&#21644;&#25968;&#25454;&#38598;&#21015;&#34920;&#12289;&#19981;&#21516;&#20027;&#39064;&#30340;&#35770;&#25991;&#21015;&#34920;&#65292;&#20197;&#21450;&#26368;&#36817;&#28909;&#38376;&#30340;&#35770;&#25991;&#31561;&#12290;</title><link>http://arxiv.org/abs/1910.07351</link><description>&lt;p&gt;
NLPExplorer&#65306;&#25506;&#32034;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#35770;&#25991;&#30340;&#23431;&#23449;
&lt;/p&gt;
&lt;p&gt;
NLPExplorer: Exploring the Universe of NLP Papers. (arXiv:1910.07351v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.07351
&lt;/p&gt;
&lt;p&gt;
NLPExplorer&#26159;&#19968;&#20010;&#33258;&#21160;&#21270;&#38376;&#25143;&#32593;&#31449;&#65292;&#29992;&#20110;&#32034;&#24341;&#12289;&#25628;&#32034;&#21644;&#21487;&#35270;&#21270;NLP&#30740;&#31350;&#25991;&#29486;&#65292;&#25163;&#21160;&#31574;&#21010;&#20116;&#31867;&#20027;&#39064;&#31867;&#21035;&#12290;&#25552;&#20379;&#20102;&#24180;&#36731;&#28909;&#38376;&#20316;&#32773;&#12289;&#28909;&#38376;URL&#21644;&#25968;&#25454;&#38598;&#21015;&#34920;&#12289;&#19981;&#21516;&#20027;&#39064;&#30340;&#35770;&#25991;&#21015;&#34920;&#65292;&#20197;&#21450;&#26368;&#36817;&#28909;&#38376;&#30340;&#35770;&#25991;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31185;&#23398;&#25991;&#31456;&#25968;&#37327;&#30340;&#19981;&#26029;&#22686;&#21152;&#65292;&#20102;&#35299;&#24403;&#21069;&#30740;&#31350;&#36235;&#21183;&#12289;&#38382;&#39064;&#21450;&#20854;&#21019;&#26032;&#35299;&#20915;&#26041;&#26696;&#20173;&#28982;&#26159;&#19968;&#20010;&#29942;&#39048;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;NLPExplorer&#65292;&#36825;&#26159;&#19968;&#20010;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#38376;&#25143;&#32593;&#31449;&#65292;&#29992;&#20110;&#32034;&#24341;&#12289;&#25628;&#32034;&#21644;&#21487;&#35270;&#21270;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30740;&#31350;&#20307;&#37327;&#12290;&#19982;&#20043;&#21069;&#22522;&#20110;&#20027;&#39064;&#24314;&#27169;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;NLPExplorer&#25163;&#21160;&#31574;&#21010;&#20102;&#20116;&#20010;&#31895;&#30053;&#30340;&#12289;&#38750;&#25490;&#20182;&#30340;&#20027;&#39064;&#31867;&#21035;&#65292;&#21363;&#35821;&#35328;&#30446;&#26631;&#65288;&#35821;&#27861;&#12289;&#35821;&#31687;&#31561;&#65289;&#12289;&#20219;&#21153;&#65288;&#26631;&#27880;&#12289;&#25688;&#35201;&#31561;&#65289;&#12289;&#26041;&#27861;&#65288;&#26080;&#30417;&#30563;&#12289;&#30417;&#30563;&#31561;&#65289;&#12289;&#35821;&#35328;&#65288;&#33521;&#35821;&#12289;&#20013;&#25991;&#31561;&#65289;&#21644;&#25968;&#25454;&#38598;&#31867;&#22411;&#65288;&#26032;&#38395;&#12289;&#20020;&#24202;&#31508;&#35760;&#31561;&#65289;&#12290;&#20854;&#20013;&#19968;&#20123;&#26032;&#39062;&#30340;&#21151;&#33021;&#21253;&#25324;&#24180;&#36731;&#28909;&#38376;&#20316;&#32773;&#12289;&#28909;&#38376;URL&#21644;&#25968;&#25454;&#38598;&#21015;&#34920;&#12289;&#19981;&#21516;&#20027;&#39064;&#30340;&#35770;&#25991;&#21015;&#34920;&#20197;&#21450;&#26368;&#36817;&#28909;&#38376;&#30340;&#35770;&#25991;&#12290;&#27492;&#22806;&#65292;&#23427;&#36824;&#25552;&#20379;&#20102;&#35832;&#22914;&#25353;&#24180;&#24230;&#28909;&#24230;&#30340;&#20027;&#39064;&#12289;&#25968;&#25454;&#38598;&#30340;&#32479;&#35745;&#20449;&#24687;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the current research trends, problems, and their innovative solutions remains a bottleneck due to the ever-increasing volume of scientific articles. In this paper, we propose NLPExplorer, a completely automatic portal for indexing, searching, and visualizing Natural Language Processing (NLP) research volume. NLPExplorer presents interesting insights from papers, authors, venues, and topics. In contrast to previous topic modelling based approaches, we manually curate five course-grained non-exclusive topical categories namely Linguistic Target (Syntax, Discourse, etc.), Tasks (Tagging, Summarization, etc.), Approaches (unsupervised, supervised, etc.), Languages (English, Chinese,etc.) and Dataset types (news, clinical notes, etc.). Some of the novel features include a list of young popular authors, popular URLs, and datasets, a list of topically diverse papers and recent popular papers. Also, it provides temporal statistics such as yearwise popularity of topics, datasets, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25512;&#24191;&#21452;&#20998;&#22270;PageRank&#30340;&#24819;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#32593;&#32476;&#30340;&#36229;&#22270;&#31867;&#22411;&#65292;&#35777;&#26126;&#20102;&#22810;&#27169;&#32593;&#32476;&#20013;&#20010;&#24615;&#21270;PageRank&#30340;&#32593;&#32476;&#23481;&#37327;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/1706.00178</link><description>&lt;p&gt;
&#22810;&#27169;&#32593;&#32476;&#20013;&#20010;&#24615;&#21270;PageRank&#30340;&#32593;&#32476;&#23481;&#37327;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Network Capacity Bound for Personalized PageRank in Multimodal Networks. (arXiv:1706.00178v3 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1706.00178
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25512;&#24191;&#21452;&#20998;&#22270;PageRank&#30340;&#24819;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#32593;&#32476;&#30340;&#36229;&#22270;&#31867;&#22411;&#65292;&#35777;&#26126;&#20102;&#22810;&#27169;&#32593;&#32476;&#20013;&#20010;&#24615;&#21270;PageRank&#30340;&#32593;&#32476;&#23481;&#37327;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#31687;&#20808;&#21069;&#30340;&#35770;&#25991;&#20013;&#65292;&#20171;&#32461;&#20102;&#21452;&#20998;&#22270;PageRank&#30340;&#27010;&#24565;&#65292;&#24182;&#25512;&#24191;&#20102;&#20010;&#24615;&#21270;PageRank&#20013;&#33410;&#28857;&#20043;&#38388;&#25480;&#26435;&#27969;&#38480;&#21046;&#30340;&#23450;&#29702;&#12290;&#26412;&#25991;&#23558;&#36825;&#20123;&#32467;&#26524;&#25512;&#24191;&#21040;&#22810;&#27169;&#32593;&#32476;&#20013;&#12290;&#25105;&#20204;&#29305;&#21035;&#22788;&#29702;&#20102;&#19968;&#31181;&#29992;&#20110;&#25551;&#36848;&#22810;&#27169;&#32593;&#32476;&#30340;&#36229;&#22270;&#31867;&#22411;&#65292;&#20854;&#20013;&#36229;&#38142;&#25509;&#23558;&#27599;&#20010;&#27169;&#24577;&#30340;&#33410;&#28857;&#36830;&#25509;&#36215;&#26469;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#36825;&#31181;&#22270;&#30340;PageRank&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#23450;&#20041;&#20102;&#30456;&#24212;&#30340;&#38543;&#26426;&#28216;&#36208;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#35745;&#31639;&#12290;&#25105;&#20204;&#23545;&#20855;&#26377;&#30456;&#21516;&#21644;&#19981;&#21516;&#38459;&#23612;&#22240;&#23376;&#30340;&#24773;&#20917;&#19979;&#25480;&#26435;&#27969;&#20986;&#37327;&#30340;&#26497;&#38480;&#24773;&#20917;&#36827;&#34892;&#20102;&#38472;&#36848;&#21644;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a former paper the concept of Bipartite PageRank was introduced and a theorem on the limit of authority flowing between nodes for personalized PageRank has been generalized. In this paper we want to extend those results to multimodal networks. In particular we deal with a hypergraph type that may be used for describing multimodal network where a hyperlink connects nodes from each of the modalities. We introduce a generalisation of PageRank for such graphs and define the respective random walk model that can be used for computations. We state and prove theorems on the limit of outflow of authority for cases where individual modalities have identical and distinct damping factors.
&lt;/p&gt;</description></item></channel></rss>