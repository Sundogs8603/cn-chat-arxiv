<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;RaLMSpec&#65292;&#36825;&#26159;&#19968;&#20010;&#20351;&#29992;&#25512;&#27979;&#21152;&#36895;&#26816;&#32034;&#22686;&#24378;&#22411;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25512;&#27979;&#24335;&#26816;&#32034;&#21644;&#25209;&#37327;&#39564;&#35777;&#25552;&#20379;&#20102;&#36890;&#29992;&#30340;&#21152;&#36895;&#25928;&#26524;&#65292;&#24182;&#36890;&#36807;&#36827;&#19968;&#27493;&#20248;&#21270;&#21644;&#24182;&#21457;&#22788;&#29702;&#65292;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.14021</link><description>&lt;p&gt;
&#20351;&#29992;&#25512;&#27979;&#21152;&#36895;&#26816;&#32034;&#22686;&#24378;&#22411;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;
&lt;/p&gt;
&lt;p&gt;
Accelerating Retrieval-Augmented Language Model Serving with Speculation. (arXiv:2401.14021v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14021
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;RaLMSpec&#65292;&#36825;&#26159;&#19968;&#20010;&#20351;&#29992;&#25512;&#27979;&#21152;&#36895;&#26816;&#32034;&#22686;&#24378;&#22411;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25512;&#27979;&#24335;&#26816;&#32034;&#21644;&#25209;&#37327;&#39564;&#35777;&#25552;&#20379;&#20102;&#36890;&#29992;&#30340;&#21152;&#36895;&#25928;&#26524;&#65292;&#24182;&#36890;&#36807;&#36827;&#19968;&#27493;&#20248;&#21270;&#21644;&#24182;&#21457;&#22788;&#29702;&#65292;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;RaLM&#65289;&#36890;&#36807;&#23558;&#38750;&#21442;&#25968;&#30340;&#30693;&#35782;&#24211;&#19982;&#21442;&#25968;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#24050;&#32463;&#23637;&#31034;&#20986;&#35299;&#20915;&#30693;&#35782;&#23494;&#38598;&#22411;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#30340;&#28508;&#21147;&#12290;&#19982;&#23545;&#23436;&#20840;&#21442;&#25968;&#21270;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#19981;&#21516;&#65292;RaLM&#22312;&#36866;&#24212;&#26368;&#26032;&#25968;&#25454;&#21644;&#26356;&#22909;&#30340;&#26469;&#28304;&#24402;&#23646;&#26426;&#21046;&#26041;&#38754;&#20855;&#26377;&#20302;&#25104;&#26412;&#30340;&#20248;&#21183;&#12290;&#22312;&#20247;&#22810;&#30340;RaLM&#26041;&#27861;&#20013;&#65292;&#36845;&#20195;&#24335;RaLM&#30001;&#20110;&#26816;&#32034;&#22120;&#19982;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#26356;&#39057;&#32321;&#30340;&#20114;&#21160;&#32780;&#20855;&#26377;&#26356;&#22909;&#30340;&#29983;&#25104;&#36136;&#37327;&#12290;&#23613;&#31649;&#26377;&#36825;&#20123;&#22909;&#22788;&#65292;&#36845;&#20195;&#24335;RaLM&#36890;&#24120;&#20250;&#22240;&#20026;&#39057;&#32321;&#30340;&#26816;&#32034;&#27493;&#39588;&#32780;&#36935;&#21040;&#39640;&#24320;&#38144;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RaLMSpec&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#25512;&#27979;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25512;&#27979;&#24335;&#26816;&#32034;&#21644;&#25209;&#37327;&#39564;&#35777;&#65292;&#33021;&#22815;&#22312;&#20445;&#25345;&#30456;&#21516;&#27169;&#22411;&#36755;&#20986;&#30340;&#21516;&#26102;&#65292;&#25552;&#20379;&#36890;&#29992;&#21152;&#36895;&#30340;&#25928;&#26524;&#12290;&#36890;&#36807;&#36827;&#19968;&#27493;&#32467;&#21512;&#39044;&#21462;&#12289;&#26368;&#20339;&#25512;&#27979;&#27493;&#24133;&#35843;&#24230;&#22120;&#21644;&#24322;&#27493;&#39564;&#35777;&#65292;RaLMSpec&#33021;&#22815;&#33258;&#21160;&#21033;&#29992;&#24182;&#21457;&#24615;&#21644;&#24182;&#34892;&#24615;&#26469;&#26368;&#22823;&#31243;&#24230;&#22320;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval-augmented language models (RaLM) have demonstrated the potential to solve knowledge-intensive natural language processing (NLP) tasks by combining a non-parametric knowledge base with a parametric language model. Instead of fine-tuning a fully parametric model, RaLM excels at its low-cost adaptation to the latest data and better source attribution mechanisms. Among various RaLM approaches, iterative RaLM delivers a better generation quality due to a more frequent interaction between the retriever and the language model. Despite the benefits, iterative RaLM usually encounters high overheads due to the frequent retrieval step. To this end, we propose RaLMSpec, a speculation-inspired framework that provides generic speed-up over iterative RaLM while preserving the same model outputs through speculative retrieval and batched verification. By further incorporating prefetching, optimal speculation stride scheduler, and asynchronous verification, RaLMSpec can automatically exploit t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;3D-MoLM&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#32473;&#35821;&#35328;&#27169;&#22411;&#37197;&#22791;&#19968;&#20010;3D&#20998;&#23376;&#32534;&#30721;&#22120;&#65292;&#23454;&#29616;&#20102;&#23545;3D&#20998;&#23376;-&#25991;&#26412;&#30340;&#35299;&#37322;&#21644;&#20998;&#26512;&#65292;&#27492;&#27169;&#22411;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#22522;&#32447;&#12290;</title><link>http://arxiv.org/abs/2401.13923</link><description>&lt;p&gt;
&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#23545;3D&#20998;&#23376;-&#25991;&#26412;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Towards 3D Molecule-Text Interpretation in Language Models. (arXiv:2401.13923v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13923
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;3D-MoLM&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#32473;&#35821;&#35328;&#27169;&#22411;&#37197;&#22791;&#19968;&#20010;3D&#20998;&#23376;&#32534;&#30721;&#22120;&#65292;&#23454;&#29616;&#20102;&#23545;3D&#20998;&#23376;-&#25991;&#26412;&#30340;&#35299;&#37322;&#21644;&#20998;&#26512;&#65292;&#27492;&#27169;&#22411;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#26377;&#30528;&#24456;&#22823;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#23545;&#20110;&#29702;&#35299;3D&#20998;&#23376;&#32467;&#26500;&#30340;&#22266;&#26377;&#38480;&#21046;&#26497;&#22823;&#22320;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#20851;&#27880;&#20110;3D&#20998;&#23376;-&#25991;&#26412;&#35299;&#37322;&#65292;&#24182;&#25552;&#20986;3D-MoLM&#65306;3D&#20998;&#23376;&#35821;&#35328;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;3D-MoLM&#36890;&#36807;&#20026;LM&#37197;&#22791;&#19968;&#20010;3D&#20998;&#23376;&#32534;&#30721;&#22120;&#65292;&#20351;&#24471;LM&#33021;&#22815;&#35299;&#37322;&#21644;&#20998;&#26512;3D&#20998;&#23376;&#12290;&#36825;&#31181;&#38598;&#25104;&#26159;&#36890;&#36807;&#19968;&#20010;3D&#20998;&#23376;-&#25991;&#26412;&#25237;&#24433;&#22120;&#23454;&#29616;&#30340;&#65292;&#23427;&#36830;&#25509;&#20102;3D&#20998;&#23376;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#31354;&#38388;&#21644;LM&#30340;&#36755;&#20837;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22686;&#24378;3D-MoLM&#22312;&#36328;&#27169;&#24577;&#20998;&#23376;&#29702;&#35299;&#21644;&#25351;&#20196;&#36319;&#38543;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#31934;&#24515;&#31574;&#21010;&#20102;&#19968;&#20010;&#20197;3D&#20998;&#23376;&#20026;&#20013;&#24515;&#30340;&#25351;&#24341;&#35843;&#25972;&#25968;&#25454;&#38598;--3D-MoIT&#12290;&#36890;&#36807;3D&#20998;&#23376;-&#25991;&#26412;&#23545;&#40784;&#21644;3D&#20998;&#23376;&#20013;&#24515;&#30340;&#25351;&#24341;&#35843;&#25972;&#65292;3D-MoLM&#24314;&#31435;&#20102;3D&#20998;&#23376;&#32534;&#30721;&#22120;&#21644;LM&#30340;&#38598;&#25104;&#12290;&#23427;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#26174;&#33879;&#36229;&#36807;&#20102;&#29616;&#26377;&#30340;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language Models (LMs) have greatly influenced diverse domains. However, their inherent limitation in comprehending 3D molecular structures has considerably constrained their potential in the biomolecular domain. To bridge this gap, we focus on 3D molecule-text interpretation, and propose 3D-MoLM: 3D-Molecular Language Modeling. Specifically, 3D-MoLM enables an LM to interpret and analyze 3D molecules by equipping the LM with a 3D molecular encoder. This integration is achieved by a 3D molecule-text projector, bridging the 3D molecular encoder's representation space and the LM's input space. Moreover, to enhance 3D-MoLM's ability of cross-modal molecular understanding and instruction following, we meticulously curated a 3D molecule-centric instruction tuning dataset -- 3D-MoIT. Through 3D molecule-text alignment and 3D molecule-centric instruction tuning, 3D-MoLM establishes an integration of 3D molecular encoder and LM. It significantly surpasses existing baselines on downstream tasks,
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34701;&#20837;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20114;&#34917;&#22686;&#24378;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;&#65292;&#20805;&#20998;&#21457;&#25381;&#23427;&#20204;&#21508;&#33258;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#21319;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.13870</link><description>&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34701;&#20837;&#25512;&#33616;&#31995;&#32479;&#30340;&#20114;&#34917;&#22686;&#24378;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Integrating Large Language Models into Recommendation via Mutual Augmentation and Adaptive Aggregation. (arXiv:2401.13870v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34701;&#20837;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20114;&#34917;&#22686;&#24378;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;&#65292;&#20805;&#20998;&#21457;&#25381;&#23427;&#20204;&#21508;&#33258;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#21319;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25512;&#33616;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#34892;&#20026;&#20013;&#30340;&#21327;&#21516;&#25110;&#36830;&#32493;&#20449;&#24687;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#26368;&#36817;&#65292;&#30001;&#20110;&#20854;&#22312;&#29702;&#35299;&#21644;&#25512;&#29702;&#25991;&#26412;&#35821;&#20041;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#24471;&#21040;&#20102;&#37325;&#35270;&#65292;&#24182;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#21457;&#29616;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#26041;&#27861;&#21644;LLMs&#21508;&#33258;&#20855;&#26377;&#21508;&#33258;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#12290;&#20256;&#32479;&#26041;&#27861;&#25797;&#38271;&#25366;&#25496;&#21327;&#21516;&#20449;&#24687;&#21644;&#24314;&#27169;&#36830;&#32493;&#34892;&#20026;&#65292;&#20294;&#22312;&#25968;&#25454;&#31232;&#30095;&#21644;&#38271;&#23614;&#38382;&#39064;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#32780;LLMs&#21017;&#25797;&#38271;&#21033;&#29992;&#20016;&#23500;&#30340;&#25991;&#26412;&#19978;&#19979;&#25991;&#65292;&#20294;&#22312;&#25366;&#25496;&#21327;&#21516;&#25110;&#36830;&#32493;&#20449;&#24687;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#23613;&#31649;&#23427;&#20204;&#21508;&#33258;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22312;&#21033;&#29992;&#23427;&#20204;&#30340;&#32852;&#21512;&#28508;&#21147;&#26469;&#25552;&#21319;&#25512;&#33616;&#24615;&#33021;&#26041;&#38754;&#23384;&#22312;&#30528;&#26174;&#33879;&#24046;&#36317;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20114;&#34917;&#22686;&#24378;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conventional recommendation methods have achieved notable advancements by harnessing collaborative or sequential information from user behavior. Recently, large language models (LLMs) have gained prominence for their capabilities in understanding and reasoning over textual semantics, and have found utility in various domains, including recommendation. Conventional recommendation methods and LLMs each have their strengths and weaknesses. While conventional methods excel at mining collaborative information and modeling sequential behavior, they struggle with data sparsity and the long-tail problem. LLMs, on the other hand, are proficient at utilizing rich textual contexts but face challenges in mining collaborative or sequential information. Despite their individual successes, there is a significant gap in leveraging their combined potential to enhance recommendation performance.  In this paper, we introduce a general and model-agnostic framework known as \textbf{L}arge \textbf{la}nguage
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20197;&#20044;&#20811;&#20848;&#32654;&#22269;&#29983;&#29289;&#23454;&#39564;&#23460;&#30340;&#34394;&#20551;&#20449;&#24687;&#23459;&#20256;&#36816;&#21160;&#20026;&#20363;&#65292;&#35843;&#26597;&#20102;&#32593;&#32476;&#25628;&#32034;&#24341;&#25806;&#22914;&#20309;&#22788;&#29702;&#19982;&#35875;&#35328;&#30456;&#20851;&#30340;&#20869;&#23481;&#65292;&#25581;&#31034;&#20102;&#31639;&#27861;&#31574;&#21010;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#25805;&#32437;&#30340;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2401.13832</link><description>&lt;p&gt;
&#31639;&#27861;&#31574;&#21010;&#30340;&#35854;&#35328;&#65306;&#25628;&#32034;&#24341;&#25806;&#22914;&#20309;&#22788;&#29702;&#26377;&#20851;&#20044;&#20811;&#20848;&#32654;&#22269;&#29983;&#29289;&#23454;&#39564;&#23460;&#30340;&#34394;&#20551;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Algorithmically Curated Lies: How Search Engines Handle Misinformation about US Biolabs in Ukraine. (arXiv:2401.13832v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13832
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20197;&#20044;&#20811;&#20848;&#32654;&#22269;&#29983;&#29289;&#23454;&#39564;&#23460;&#30340;&#34394;&#20551;&#20449;&#24687;&#23459;&#20256;&#36816;&#21160;&#20026;&#20363;&#65292;&#35843;&#26597;&#20102;&#32593;&#32476;&#25628;&#32034;&#24341;&#25806;&#22914;&#20309;&#22788;&#29702;&#19982;&#35875;&#35328;&#30456;&#20851;&#30340;&#20869;&#23481;&#65292;&#25581;&#31034;&#20102;&#31639;&#27861;&#31574;&#21010;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#25805;&#32437;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#20869;&#23481;&#30340;&#22686;&#38271;&#20419;&#20351;&#37319;&#29992;&#31639;&#27861;&#31995;&#32479;&#36827;&#34892;&#20449;&#24687;&#31574;&#21010;&#12290;&#36825;&#20123;&#31995;&#32479;&#21253;&#25324;&#32593;&#32476;&#25628;&#32034;&#24341;&#25806;&#21644;&#25512;&#33616;&#31995;&#32479;&#65292;&#23545;&#24110;&#21161;&#29992;&#25143;&#20102;&#35299;&#37325;&#35201;&#31038;&#20250;&#21457;&#23637;&#20855;&#26377;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#19982;&#26032;&#38395;&#32534;&#36753;&#19981;&#21516;&#65292;&#31639;&#27861;&#20449;&#24687;&#31574;&#21010;&#31995;&#32479;&#65288;AICSs&#65289;&#23481;&#26131;&#21463;&#21040;&#21508;&#31181;&#24418;&#24335;&#30340;&#22833;&#25928;&#30340;&#24433;&#21709;&#65292;&#36825;&#20351;&#23427;&#20204;&#23481;&#26131;&#21463;&#21040;&#25805;&#32437;&#12290;&#25805;&#32437;&#30340;&#39118;&#38505;&#22312;&#20110;&#65292;AICSs&#24517;&#39035;&#22788;&#29702;&#26377;&#20851;&#34394;&#20551;&#20027;&#24352;&#30340;&#20449;&#24687;&#65292;&#36825;&#20123;&#20027;&#24352;&#26159;&#19987;&#21046;&#25919;&#26435;&#30340;&#23459;&#20256;&#27963;&#21160;&#30340;&#22522;&#30784;&#12290;&#36890;&#36807;&#20197;&#20420;&#32599;&#26031;&#26377;&#20851;&#20044;&#20811;&#20848;&#32654;&#22269;&#29983;&#29289;&#23454;&#39564;&#23460;&#30340;&#34394;&#20551;&#20449;&#24687;&#23459;&#20256;&#36816;&#21160;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#26368;&#24120;&#29992;&#30340;AICSs&#24418;&#24335;&#20043;&#19968;&#8212;&#8212;&#21363;&#32593;&#32476;&#25628;&#32034;&#24341;&#25806;&#22914;&#20309;&#36827;&#34892;&#35875;&#35328;&#30456;&#20851;&#20869;&#23481;&#30340;&#31574;&#21010;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;2020&#24180;6&#26376;&#20351;&#29992;&#34394;&#25311;&#22522;&#20110;&#20195;&#29702;&#30340;&#31639;&#27861;&#36827;&#34892;&#20102;&#23545;Google&#12289;Bing&#21644;Yandex&#25628;&#32034;&#32467;&#26524;&#30340;&#23457;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;
The growing volume of online content prompts the need for adopting algorithmic systems of information curation. These systems range from web search engines to recommender systems and are integral for helping users stay informed about important societal developments. However, unlike journalistic editing the algorithmic information curation systems (AICSs) are known to be subject to different forms of malperformance which make them vulnerable to possible manipulation. The risk of manipulation is particularly prominent in the case when AICSs have to deal with information about false claims that underpin propaganda campaigns of authoritarian regimes. Using as a case study of the Russian disinformation campaign concerning the US biolabs in Ukraine, we investigate how one of the most commonly used forms of AICSs - i.e. web search engines - curate misinformation-related content. For this aim, we conduct virtual agent-based algorithm audits of Google, Bing, and Yandex search outputs in June 20
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#38754;&#23545;&#36793;&#32423;&#25200;&#21160;&#25915;&#20987;&#26102;&#30340;&#20844;&#24179;&#24615;&#40065;&#26834;&#24615;&#65292;&#21457;&#29616;&#29616;&#26377;&#35780;&#20272;&#21327;&#35758;&#23384;&#22312;&#20851;&#38190;&#32570;&#28857;&#12290;</title><link>http://arxiv.org/abs/2401.13823</link><description>&lt;p&gt;
GNN-based&#25512;&#33616;&#20013;&#23545;&#36793;&#32423;&#25200;&#21160;&#30340;&#20844;&#24179;&#24615;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Robustness in Fairness against Edge-level Perturbations in GNN-based Recommendation. (arXiv:2401.13823v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13823
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#38754;&#23545;&#36793;&#32423;&#25200;&#21160;&#25915;&#20987;&#26102;&#30340;&#20844;&#24179;&#24615;&#40065;&#26834;&#24615;&#65292;&#21457;&#29616;&#29616;&#26377;&#35780;&#20272;&#21327;&#35758;&#23384;&#22312;&#20851;&#38190;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#39046;&#22495;&#30340;&#21162;&#21147;&#20174;&#21333;&#32431;&#24378;&#35843;&#25928;&#29992;&#36716;&#21521;&#32771;&#34385;&#36229;&#20986;&#25928;&#29992;&#22240;&#32032;&#65292;&#22914;&#20844;&#24179;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#25512;&#33616;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#36890;&#24120;&#19982;&#20854;&#22312;&#36973;&#21463;&#25915;&#20987;&#26102;&#32500;&#25345;&#21407;&#22987;&#25928;&#29992;&#30340;&#33021;&#21147;&#30456;&#20851;&#12290;&#26377;&#38480;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#25915;&#20987;&#22330;&#26223;&#19979;&#25512;&#33616;&#27169;&#22411;&#22312;&#20844;&#24179;&#24615;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#20363;&#22914;&#36328;&#32452;&#32489;&#25928;&#30340;&#24179;&#31561;&#12290;&#26412;&#25991;&#26088;&#22312;&#35780;&#20272;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#38754;&#23545;&#22522;&#20110;&#36793;&#32423;&#25200;&#21160;&#25915;&#20987;&#26102;&#65292;&#19982;&#20844;&#24179;&#24615;&#30456;&#20851;&#30340;&#40065;&#26834;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22235;&#31181;&#19981;&#21516;&#30340;&#20844;&#24179;&#24615;&#36816;&#20316;&#27169;&#24335;&#65292;&#21253;&#25324;&#28040;&#36153;&#32773;&#21644;&#25552;&#20379;&#32773;&#30340;&#35266;&#28857;&#12290;&#23545;&#19977;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#25200;&#21160;&#23545;&#30446;&#26631;&#20844;&#24179;&#24615;&#27010;&#24565;&#30340;&#24433;&#21709;&#65292;&#25581;&#31034;&#20102;&#29616;&#26377;&#40065;&#26834;&#24615;&#35780;&#20272;&#21327;&#35758;&#20013;&#30340;&#20851;&#38190;&#32570;&#28857;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25200;&#21160;&#20250;&#26356;&#22823;&#22320;&#24433;&#21709;&#28040;&#36153;&#32773;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efforts in the recommendation community are shifting from the sole emphasis on utility to considering beyond-utility factors, such as fairness and robustness. Robustness of recommendation models is typically linked to their ability to maintain the original utility when subjected to attacks. Limited research has explored the robustness of a recommendation model in terms of fairness, e.g., the parity in performance across groups, under attack scenarios. In this paper, we aim to assess the robustness of graph-based recommender systems concerning fairness, when exposed to attacks based on edge-level perturbations. To this end, we considered four different fairness operationalizations, including both consumer and provider perspectives. Experiments on three datasets shed light on the impact of perturbations on the targeted fairness notion, uncovering key shortcomings in existing evaluation protocols for robustness. As an example, we observed perturbations affect consumer fairness on a higher
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#32437;&#21521;&#20027;&#39064;&#24314;&#27169;&#20998;&#26512;&#20102;&#21152;&#25343;&#22823;&#22235;&#25152;&#20027;&#35201;&#22823;&#23398;&#23398;&#29983;&#22312;Reddit&#19978;&#21457;&#24067;&#30340;&#24086;&#23376;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#38543;&#30528;&#26102;&#38388;&#25512;&#31227;&#65292;&#19982;&#24515;&#29702;&#20581;&#24247;&#30456;&#20851;&#30340;&#35752;&#35770;&#36880;&#28176;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2401.13805</link><description>&lt;p&gt;
Reddit&#24086;&#23376;&#30340;&#32437;&#21521;&#24773;&#32490;&#20027;&#39064;&#24314;&#27169;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Longitudinal Sentiment Topic Modelling of Reddit Posts. (arXiv:2401.13805v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13805
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#32437;&#21521;&#20027;&#39064;&#24314;&#27169;&#20998;&#26512;&#20102;&#21152;&#25343;&#22823;&#22235;&#25152;&#20027;&#35201;&#22823;&#23398;&#23398;&#29983;&#22312;Reddit&#19978;&#21457;&#24067;&#30340;&#24086;&#23376;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#38543;&#30528;&#26102;&#38388;&#25512;&#31227;&#65292;&#19982;&#24515;&#29702;&#20581;&#24247;&#30456;&#20851;&#30340;&#35752;&#35770;&#36880;&#28176;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22235;&#25152;&#21152;&#25343;&#22823;&#20027;&#35201;&#22823;&#23398;&#23398;&#29983;&#25776;&#20889;&#30340;Reddit&#24086;&#23376;&#12290;&#36890;&#36807;&#23545;&#24086;&#23376;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#32437;&#21521;&#20027;&#39064;&#24314;&#27169;&#65292;&#25105;&#20204;&#35780;&#20272;&#24773;&#32490;&#35843;&#24615;&#24182;&#25581;&#31034;&#20027;&#35201;&#20027;&#39064;&#21644;&#35752;&#35770;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#37325;&#28857;&#20851;&#27880;2020&#24180;&#33267;2023&#24180;&#30340;&#22235;&#24180;&#26102;&#38388;&#27573;&#65292;&#28085;&#30422;&#20102;COVID-19&#22823;&#27969;&#34892;&#21450;&#20854;&#21518;&#32493;&#24180;&#20221;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31361;&#20986;&#20102;&#19982;&#24515;&#29702;&#20581;&#24247;&#30456;&#20851;&#30340;&#35752;&#35770;&#36880;&#28176;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we analyze texts of Reddit posts written by students of four major Canadian universities. We gauge the emotional tone and uncover prevailing themes and discussions through longitudinal topic modeling of posts textual data. Our study focuses on four years, 2020-2023, covering COVID-19 pandemic and after pandemic years. Our results highlight a gradual uptick in discussions related to mental health.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#26234;&#33021;&#25968;&#25454;&#31649;&#29702;&#21644;&#27934;&#23519;&#21147;&#21487;&#20197;&#35299;&#20915;&#29616;&#20195;&#20892;&#19994;&#38754;&#20020;&#30340;&#22686;&#38271;&#38656;&#27714;&#21644;&#27668;&#20505;&#21464;&#21270;&#31561;&#25361;&#25112;&#65292;&#36890;&#36807;&#25968;&#25454;&#21019;&#26032;&#21487;&#20197;&#25552;&#39640;&#20892;&#19994;&#29983;&#20135;&#21147;&#12289;&#21487;&#25345;&#32493;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.13672</link><description>&lt;p&gt;
&#29992;&#26234;&#33021;&#25968;&#25454;&#31649;&#29702;&#21644;&#27934;&#23519;&#21147;&#25913;&#21464;&#20892;&#19994;
&lt;/p&gt;
&lt;p&gt;
Transforming Agriculture with Intelligent Data Management and Insights. (arXiv:2401.13672v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13672
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26234;&#33021;&#25968;&#25454;&#31649;&#29702;&#21644;&#27934;&#23519;&#21147;&#21487;&#20197;&#35299;&#20915;&#29616;&#20195;&#20892;&#19994;&#38754;&#20020;&#30340;&#22686;&#38271;&#38656;&#27714;&#21644;&#27668;&#20505;&#21464;&#21270;&#31561;&#25361;&#25112;&#65292;&#36890;&#36807;&#25968;&#25454;&#21019;&#26032;&#21487;&#20197;&#25552;&#39640;&#20892;&#19994;&#29983;&#20135;&#21147;&#12289;&#21487;&#25345;&#32493;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20892;&#19994;&#38754;&#20020;&#30528;&#22312;&#27668;&#20505;&#21464;&#21270;&#21644;&#33258;&#28982;&#36164;&#28304;&#20943;&#23569;&#30340;&#32422;&#26463;&#19979;&#65292;&#22312;&#20154;&#21475;&#22686;&#38271;&#30340;&#24773;&#20917;&#19979;&#28385;&#36275;&#31918;&#39135;&#12289;&#29123;&#26009;&#12289;&#39282;&#26009;&#21644;&#32420;&#32500;&#30340;&#22686;&#21152;&#38656;&#27714;&#30340;&#24040;&#22823;&#25361;&#25112;&#12290;&#24613;&#38656;&#25968;&#25454;&#21019;&#26032;&#26469;&#30830;&#20445;&#21644;&#25552;&#39640;&#20892;&#19994;&#29983;&#24577;&#31995;&#32479;&#30340;&#29983;&#20135;&#21147;&#12289;&#21487;&#25345;&#32493;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;&#38543;&#30528;&#21508;&#31181;&#20256;&#24863;&#22120;&#21644;&#29289;&#32852;&#32593;&#35774;&#22791;&#21464;&#24471;&#36234;&#26469;&#36234;&#21487;&#29992;&#12289;&#21487;&#36127;&#25285;&#24471;&#36215;&#12289;&#21487;&#38752;&#12289;&#31283;&#23450;&#65292;&#21487;&#20197;&#36827;&#34892;&#22810;&#26102;&#31354;&#23610;&#24230;&#12289;&#23454;&#26102;&#21644;&#39640;&#20998;&#36776;&#29575;&#30340;&#25968;&#25454;&#25910;&#38598;&#12289;&#25972;&#21512;&#21644;&#20998;&#26512;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#24222;&#22823;&#30340;&#25968;&#25454;&#37327;&#23545;&#25968;&#25454;&#23384;&#20648;&#21644;&#20998;&#26512;&#26500;&#25104;&#20102;&#24040;&#22823;&#25361;&#25112;&#65292;&#31185;&#23398;&#23478;&#20204;&#24120;&#35268;&#30340;&#25968;&#25454;&#31649;&#29702;&#21644;&#20998;&#26512;&#23454;&#36341;&#36234;&#26469;&#36234;&#20302;&#25928;&#12290;&#27492;&#22806;&#65292;&#26469;&#33258;&#19981;&#21516;&#23398;&#31185;&#30340;&#25968;&#25454;&#65292;&#22914;&#22522;&#22240;&#32452;&#23398;&#12289;&#34920;&#22411;&#23398;&#12289;&#29615;&#22659;&#23398;&#12289;&#20892;&#23398;&#21644;&#31038;&#20250;&#32463;&#27982;&#23398;&#65292;&#21487;&#33021;&#39640;&#24230;&#24322;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern agriculture faces grand challenges to meet increased demands for food, fuel, feed, and fiber with population growth under the constraints of climate change and dwindling natural resources. Data innovation is urgently required to secure and improve the productivity, sustainability, and resilience of our agroecosystems. As various sensors and Internet of Things (IoT) instrumentation become more available, affordable, reliable, and stable, it has become possible to conduct data collection, integration, and analysis at multiple temporal and spatial scales, in real-time, and with high resolutions. At the same time, the sheer amount of data poses a great challenge to data storage and analysis, and the \textit{de facto} data management and analysis practices adopted by scientists have become increasingly inefficient. Additionally, the data generated from different disciplines, such as genomics, phenomics, environment, agronomy, and socioeconomic, can be highly heterogeneous. That is, d
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#36866;&#24212;&#24341;&#29992;&#25968;&#25454;&#30340;&#21435;&#20013;&#24515;&#21270;&#21327;&#20316;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35774;&#22791;&#19978;&#30340;&#20852;&#36259;&#28857;&#25512;&#33616;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#21516;&#19968;&#24341;&#29992;&#25968;&#25454;&#23545;&#19981;&#21516;&#29992;&#25143;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.13448</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#24341;&#29992;&#25968;&#25454;&#30340;&#21435;&#20013;&#24515;&#21270;&#21327;&#20316;&#23398;&#20064;&#36827;&#34892;&#35774;&#22791;&#19978;&#30340;&#20852;&#36259;&#28857;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Decentralized Collaborative Learning with Adaptive Reference Data for On-Device POI Recommendation. (arXiv:2401.13448v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13448
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#36866;&#24212;&#24341;&#29992;&#25968;&#25454;&#30340;&#21435;&#20013;&#24515;&#21270;&#21327;&#20316;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35774;&#22791;&#19978;&#30340;&#20852;&#36259;&#28857;&#25512;&#33616;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#21516;&#19968;&#24341;&#29992;&#25968;&#25454;&#23545;&#19981;&#21516;&#29992;&#25143;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#20301;&#32622;&#30340;&#31038;&#20132;&#32593;&#32476;&#20013;&#65292;&#20852;&#36259;&#28857;&#65288;POI&#65289;&#25512;&#33616;&#24110;&#21161;&#29992;&#25143;&#21457;&#29616;&#26377;&#36259;&#30340;&#22320;&#26041;&#12290;&#20026;&#20102;&#20445;&#25252;&#38544;&#31169;&#21644;&#20943;&#23569;&#26381;&#21153;&#22120;&#20381;&#36182;&#65292;&#20174;&#22522;&#20110;&#20113;&#30340;&#27169;&#22411;&#36716;&#21521;&#35774;&#22791;&#19978;&#30340;&#25512;&#33616;&#26159;&#19968;&#20010;&#36235;&#21183;&#12290;&#30001;&#20110;&#20010;&#21035;&#35774;&#22791;&#19978;&#30340;&#26412;&#22320;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#25968;&#25454;&#31232;&#32570;&#65292;&#20165;&#20381;&#36182;&#26412;&#22320;&#25968;&#25454;&#26159;&#19981;&#36275;&#22815;&#30340;&#12290;&#21327;&#20316;&#23398;&#20064;&#65288;CL&#65289;&#20852;&#36215;&#65292;&#20419;&#36827;&#29992;&#25143;&#20043;&#38388;&#30340;&#27169;&#22411;&#20849;&#20139;&#65292;&#20854;&#20013;&#24341;&#29992;&#25968;&#25454;&#20316;&#20026;&#20013;&#20171;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#22312;&#19981;&#30452;&#25509;&#20849;&#20139;&#31169;&#26377;&#25968;&#25454;&#25110;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#20132;&#25442;&#20182;&#20204;&#30340;&#36719;&#20915;&#31574;&#65292;&#30830;&#20445;&#38544;&#31169;&#24182;&#20174;&#21327;&#20316;&#20013;&#21463;&#30410;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#21327;&#20316;&#23398;&#20064;&#30340;&#25512;&#33616;&#36890;&#24120;&#20026;&#25152;&#26377;&#29992;&#25143;&#20351;&#29992;&#21516;&#19968;&#20010;&#24341;&#29992;&#25968;&#25454;&#12290;&#23545;&#19968;&#20010;&#29992;&#25143;&#26377;&#20215;&#20540;&#30340;&#24341;&#29992;&#25968;&#25454;&#21487;&#33021;&#23545;&#21478;&#19968;&#20010;&#29992;&#25143;&#26377;&#23475;&#65292;&#37492;&#20110;&#29992;&#25143;&#20559;&#22909;&#30340;&#22810;&#26679;&#24615;&#12290;&#29992;&#25143;&#21487;&#33021;&#19981;&#20250;&#23545;&#20182;&#20204;&#20852;&#36259;&#33539;&#22260;&#20043;&#22806;&#30340;&#39033;&#30446;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#36719;&#20915;&#31574;&#12290;&#22240;&#27492;&#65292;&#20026;&#25152;&#26377;&#21327;&#20316;&#20351;&#29992;&#30456;&#21516;&#30340;&#24341;&#29992;&#25968;&#25454;&#21487;&#33021;&#20250;&#38459;&#30861;&#21327;&#20316;&#25512;&#33616;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Location-based Social Networks, Point-of-Interest (POI) recommendation helps users discover interesting places. There is a trend to move from the cloud-based model to on-device recommendations for privacy protection and reduced server reliance. Due to the scarcity of local user-item interactions on individual devices, solely relying on local instances is not adequate. Collaborative Learning (CL) emerges to promote model sharing among users, where reference data is an intermediary that allows users to exchange their soft decisions without directly sharing their private data or parameters, ensuring privacy and benefiting from collaboration. However, existing CL-based recommendations typically use a single reference for all users. Reference data valuable for one user might be harmful to another, given diverse user preferences. Users may not offer meaningful soft decisions on items outside their interest scope. Consequently, using the same reference data for all collaborations can imped
&lt;/p&gt;</description></item><item><title>&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24341;&#20837;&#26102;&#38388;&#24615;&#26159;&#20449;&#24687;&#26816;&#32034;&#30340;&#20851;&#38190;&#25361;&#25112;&#65292;&#30446;&#21069;&#30340;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#26080;&#27861;&#24456;&#22909;&#22320;&#22788;&#29702;&#26102;&#38388;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2401.13222</link><description>&lt;p&gt;
&#20851;&#20110;&#26102;&#38388;&#30340;&#37325;&#35201;&#24615;&#65306;&#22312;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#20013;&#24341;&#20837;&#26102;&#38388;&#24615;
&lt;/p&gt;
&lt;p&gt;
It's About Time: Incorporating Temporality in Retrieval Augmented Language Models. (arXiv:2401.13222v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13222
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24341;&#20837;&#26102;&#38388;&#24615;&#26159;&#20449;&#24687;&#26816;&#32034;&#30340;&#20851;&#38190;&#25361;&#25112;&#65292;&#30446;&#21069;&#30340;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#26080;&#27861;&#24456;&#22909;&#22320;&#22788;&#29702;&#26102;&#38388;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#20316;&#20026;&#20840;&#29699;&#30340;&#30693;&#35782;&#23384;&#20648;&#24211;&#65292;&#34987;&#25968;&#21313;&#20159;&#20154;&#29992;&#20110;&#25628;&#32034;&#20449;&#24687;&#12290;&#30830;&#20445;&#29992;&#25143;&#33021;&#22815;&#33719;&#24471;&#26368;&#30456;&#20851;&#21644;&#26368;&#26032;&#30340;&#20449;&#24687;&#26159;&#20449;&#24687;&#26816;&#32034;&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#26469;&#33258;&#19981;&#21516;&#26102;&#38388;&#28857;&#30340;&#22810;&#20010;&#29256;&#26412;&#30340;&#32593;&#32476;&#20869;&#23481;&#30340;&#24773;&#20917;&#19979;&#12290;&#26368;&#36817;&#65292;&#36825;&#20010;&#25361;&#25112;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#65292;&#21407;&#22240;&#26159;&#23545;&#32500;&#22522;&#30334;&#31185;&#25110;&#32593;&#32476;&#20869;&#23481;&#36827;&#34892;&#35757;&#32451;&#30340;&#38382;&#31572;&#24037;&#20855;&#30340;&#22686;&#21152;&#20351;&#29992;&#65292;&#36825;&#20123;&#24037;&#20855;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#39537;&#21160;&#65292;&#32780;&#36825;&#20123;&#27169;&#22411;&#34987;&#21457;&#29616;&#20250;&#34394;&#26500;&#20449;&#24687;&#65292;&#19988;&#22312;&#22788;&#29702;&#26102;&#38388;&#20449;&#24687;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#21363;&#20351;&#26159;&#24341;&#20837;&#25991;&#26723;&#25968;&#25454;&#24211;&#20197;&#20943;&#23569;LLM&#34394;&#26500;&#30340;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#65288;RALM&#65289;&#20063;&#26080;&#27861;&#27491;&#30830;&#22788;&#29702;&#26102;&#38388;&#26597;&#35810;&#12290;&#36825;&#23548;&#33268;RALM&#22312;&#22238;&#31572;&#31867;&#20284;&#8220;&#35841;&#36194;&#24471;&#20102;&#28201;&#32593;&#20896;&#20891;&#65311;&#8221;&#30340;&#26597;&#35810;&#26102;&#65292;&#21482;&#20250;&#26816;&#32034;&#19982;&#28201;&#32593;&#30456;&#20851;&#30340;&#25991;&#26723;&#20869;&#23481;&#65292;&#32780;&#19981;&#23436;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
The web serves as a global repository of knowledge, used by billions of people to search for information. Ensuring that users receive the most relevant and up-to-date information, especially in the presence of multiple versions of web content from different time points remains a critical challenge for information retrieval. This challenge has recently been compounded by the increased use of question answering tools trained on Wikipedia or web content and powered by large language models (LLMs) \citep{chatgpt} which have been found to make up information (or hallucinate), and in addition have been shown to struggle with the temporal dimensions of information. Even Retriever Augmented Language Models (RALMs) which incorporate a document database to reduce LLM hallucination are unable to handle temporal queries correctly. This leads to instances where RALMs respond to queries such as "Who won the Wimbledon Championship?", by retrieving document passages related to Wimbledon but without th
&lt;/p&gt;</description></item><item><title>SynthTab&#26159;&#19968;&#20010;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#30340;&#22823;&#35268;&#27169;&#21513;&#20182;&#35889;&#36716;&#24405;&#25968;&#25454;&#38598;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#25968;&#25454;&#38598;&#35268;&#27169;&#26377;&#38480;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#38899;&#39057;&#20445;&#25345;&#20102;&#21407;&#22987;&#25351;&#27861;&#12289;&#39118;&#26684;&#21644;&#25216;&#24039;&#30340;&#30456;&#31526;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.09085</link><description>&lt;p&gt;
SynthTab: &#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#21513;&#20182;&#35889;&#36716;&#24405;
&lt;/p&gt;
&lt;p&gt;
SynthTab: Leveraging Synthesized Data for Guitar Tablature Transcription. (arXiv:2309.09085v2 [cs.SD] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09085
&lt;/p&gt;
&lt;p&gt;
SynthTab&#26159;&#19968;&#20010;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#30340;&#22823;&#35268;&#27169;&#21513;&#20182;&#35889;&#36716;&#24405;&#25968;&#25454;&#38598;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#25968;&#25454;&#38598;&#35268;&#27169;&#26377;&#38480;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#38899;&#39057;&#20445;&#25345;&#20102;&#21407;&#22987;&#25351;&#27861;&#12289;&#39118;&#26684;&#21644;&#25216;&#24039;&#30340;&#30456;&#31526;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21513;&#20182;&#35889;&#26159;&#21513;&#20182;&#25163;&#24191;&#27867;&#20351;&#29992;&#30340;&#19968;&#31181;&#38899;&#20048;&#31526;&#21495;&#12290;&#23427;&#19981;&#20165;&#25429;&#25417;&#20102;&#19968;&#39318;&#20048;&#26354;&#30340;&#38899;&#20048;&#20869;&#23481;&#65292;&#36824;&#21253;&#25324;&#20102;&#22312;&#20048;&#22120;&#19978;&#30340;&#23454;&#26045;&#21644;&#35013;&#39280;&#12290;&#21513;&#20182;&#35889;&#36716;&#24405;&#65288;GTT&#65289;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#22312;&#38899;&#20048;&#25945;&#32946;&#21644;&#23089;&#20048;&#39046;&#22495;&#26377;&#24191;&#27867;&#24212;&#29992;&#12290;&#29616;&#26377;&#30340;&#25968;&#25454;&#38598;&#22312;&#35268;&#27169;&#21644;&#33539;&#22260;&#19978;&#37117;&#26377;&#38480;&#65292;&#23548;&#33268;&#22522;&#20110;&#36825;&#20123;&#25968;&#25454;&#38598;&#35757;&#32451;&#30340;&#26368;&#20808;&#36827;&#30340;GTT&#27169;&#22411;&#23481;&#26131;&#36807;&#25311;&#21512;&#65292;&#24182;&#19988;&#22312;&#36328;&#25968;&#25454;&#38598;&#30340;&#27867;&#21270;&#20013;&#22833;&#36133;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#21512;&#25104;SynthTab&#65292;&#36825;&#26159;&#19968;&#20010;&#21033;&#29992;&#22810;&#20010;&#21830;&#29992;&#21513;&#20182;&#25554;&#20214;&#21512;&#25104;&#30340;&#22823;&#35268;&#27169;&#21513;&#20182;&#35889;&#36716;&#24405;&#25968;&#25454;&#38598;&#12290;&#35813;&#25968;&#25454;&#38598;&#22522;&#20110;DadaGP&#30340;&#21513;&#20182;&#35889;&#26500;&#24314;&#65292;DadaGP&#25552;&#20379;&#20102;&#25105;&#20204;&#24076;&#26395;&#36716;&#24405;&#30340;&#21513;&#20182;&#35889;&#30340;&#24222;&#22823;&#25910;&#34255;&#21644;&#29305;&#23450;&#31243;&#24230;&#12290;&#25152;&#25552;&#20986;&#30340;&#21512;&#25104;&#27969;&#31243;&#21487;&#20135;&#29983;&#19982;&#21407;&#22987;&#25351;&#27861;&#12289;&#39118;&#26684;&#21644;&#25216;&#24039;&#22312;&#38899;&#33394;&#19978;&#30456;&#31526;&#30340;&#38899;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;
Guitar tablature is a form of music notation widely used among guitarists. It captures not only the musical content of a piece, but also its implementation and ornamentation on the instrument. Guitar Tablature Transcription (GTT) is an important task with broad applications in music education and entertainment. Existing datasets are limited in size and scope, causing state-of-the-art GTT models trained on such datasets to suffer from overfitting and to fail in generalization across datasets. To address this issue, we developed a methodology for synthesizing SynthTab, a large-scale guitar tablature transcription dataset using multiple commercial acoustic and electric guitar plugins. This dataset is built on tablatures from DadaGP, which offers a vast collection and the degree of specificity we wish to transcribe. The proposed synthesis pipeline produces audio which faithfully adheres to the original fingerings, styles, and techniques specified in the tablature with diverse timbre. Exper
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26500;&#24314;&#20010;&#24615;&#21270;&#25512;&#29702;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22240;&#26524;&#21644;&#36923;&#36753;&#25512;&#29702;&#38142;&#25509;&#29992;&#25143;&#30340;&#20010;&#20154;&#36164;&#26009;&#21644;&#34892;&#20026;&#24207;&#21015;&#65292;&#22312;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#24615;&#33021;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#26356;&#22810;&#30340;&#36923;&#36753;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.10835</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#22270;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Enhancing Recommender Systems with Large Language Model Reasoning Graphs. (arXiv:2308.10835v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26500;&#24314;&#20010;&#24615;&#21270;&#25512;&#29702;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22240;&#26524;&#21644;&#36923;&#36753;&#25512;&#29702;&#38142;&#25509;&#29992;&#25143;&#30340;&#20010;&#20154;&#36164;&#26009;&#21644;&#34892;&#20026;&#24207;&#21015;&#65292;&#22312;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#24615;&#33021;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#26356;&#22810;&#30340;&#36923;&#36753;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#20026;&#29992;&#25143;&#25552;&#20379;&#30456;&#20851;&#24314;&#35758;&#65292;&#20294;&#36890;&#24120;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#26080;&#27861;&#25429;&#25417;&#29992;&#25143;&#34892;&#20026;&#21644;&#20010;&#20154;&#36164;&#26009;&#20043;&#38388;&#30340;&#26356;&#39640;&#32423;&#35821;&#20041;&#20851;&#31995;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26500;&#24314;&#20010;&#24615;&#21270;&#25512;&#29702;&#22270;&#12290;&#36825;&#20123;&#22270;&#36890;&#36807;&#22240;&#26524;&#21644;&#36923;&#36753;&#25512;&#29702;&#23558;&#29992;&#25143;&#30340;&#20010;&#20154;&#36164;&#26009;&#21644;&#34892;&#20026;&#24207;&#21015;&#38142;&#25509;&#36215;&#26469;&#65292;&#20197;&#21487;&#35299;&#37322;&#30340;&#26041;&#24335;&#34920;&#31034;&#29992;&#25143;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;LLM&#25512;&#29702;&#22270;&#65288;LLMRG&#65289;&#65292;&#21253;&#25324;&#22235;&#20010;&#32452;&#20214;&#65306;&#38142;&#25509;&#22270;&#25512;&#29702;&#12289;&#21457;&#25955;&#25193;&#23637;&#12289;&#33258;&#25105;&#39564;&#35777;&#19982;&#35780;&#20998;&#65292;&#20197;&#21450;&#30693;&#35782;&#24211;&#33258;&#25105;&#25913;&#36827;&#12290;&#26368;&#32456;&#24471;&#21040;&#30340;&#25512;&#29702;&#22270;&#34987;&#32534;&#30721;&#20026;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20316;&#20026;&#39069;&#22806;&#30340;&#36755;&#20837;&#26469;&#25913;&#36827;&#20256;&#32479;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#29992;&#25143;&#25110;&#39033;&#30446;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;LLMs&#22914;&#20309;&#36890;&#36807;&#20010;&#24615;&#21270;&#25512;&#29702;&#22270;&#23454;&#29616;&#26356;&#20855;&#36923;&#36753;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems aim to provide users with relevant suggestions, but often lack interpretability and fail to capture higher-level semantic relationships between user behaviors and profiles. In this paper, we propose a novel approach that leverages large language models (LLMs) to construct personalized reasoning graphs. These graphs link a user's profile and behavioral sequences through causal and logical inferences, representing the user's interests in an interpretable way. Our approach, LLM reasoning graphs (LLMRG), has four components: chained graph reasoning, divergent extension, self-verification and scoring, and knowledge base self-improvement. The resulting reasoning graph is encoded using graph neural networks, which serves as additional input to improve conventional recommender systems, without requiring extra user or item information. Our approach demonstrates how LLMs can enable more logical and interpretable recommender systems through personalized reasoning graphs. LL
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#20449;&#24687;&#26816;&#32034;&#21338;&#24328;&#35770;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#20197;&#36798;&#25104;&#26356;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#35777;&#26126;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.16695</link><description>&lt;p&gt;
&#23547;&#27714;&#31283;&#23450;&#24615;&#65306;&#20855;&#26377;&#21021;&#22987;&#25991;&#20214;&#30340;&#25112;&#30053;&#20986;&#29256;&#21830;&#30340;&#23398;&#20064;&#21160;&#24577;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Search for Stability: Learning Dynamics of Strategic Publishers with Initial Documents. (arXiv:2305.16695v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#20449;&#24687;&#26816;&#32034;&#21338;&#24328;&#35770;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#20197;&#36798;&#25104;&#26356;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#35777;&#26126;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20449;&#24687;&#26816;&#32034;&#30340;&#21338;&#24328;&#35770;&#27169;&#22411;&#65292;&#20854;&#20013;&#25112;&#30053;&#20986;&#29256;&#21830;&#26088;&#22312;&#22312;&#20445;&#25345;&#21407;&#22987;&#25991;&#26723;&#23436;&#25972;&#24615;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#33258;&#24049;&#25490;&#21517;&#31532;&#19968;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24120;&#29992;&#30340;PRP&#25490;&#21517;&#26041;&#26696;&#23548;&#33268;&#29615;&#22659;&#19981;&#31283;&#23450;&#65292;&#28216;&#25103;&#32463;&#24120;&#26080;&#27861;&#36798;&#21040;&#32431;&#32435;&#20160;&#22343;&#34913;&#12290;&#25105;&#20204;&#23558;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#24182;&#20171;&#32461;&#20004;&#20010;&#25490;&#21517;&#20989;&#25968;&#65292;&#23427;&#20204;&#26159;RRP&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#65292;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#23548;&#33268;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#30340;&#31215;&#26497;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23450;&#20041;&#20986;&#29256;&#21830;&#21644;&#29992;&#25143;&#30340;&#31119;&#21033;&#65292;&#24182;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#65292;&#31361;&#26174;&#20102;&#30830;&#23450;&#25628;&#32034;&#24341;&#25806;&#35774;&#35745;&#24072;&#24212;&#36873;&#25321;&#21738;&#31181;&#25490;&#21517;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a game-theoretic model of information retrieval, in which strategic publishers aim to maximize their chances of being ranked first by the search engine, while maintaining the integrity of their original documents. We show that the commonly used PRP ranking scheme results in an unstable environment where games often fail to reach pure Nash equilibrium. We propose the Relative Ranking Principle (RRP) as an alternative ranking principle, and introduce two ranking functions that are instances of the RRP. We provide both theoretical and empirical evidence that these methods lead to a stable search ecosystem, by providing positive results on the learning dynamics convergence. We also define the publishers' and users' welfare, and demonstrate a possible publisher-user trade-off, which highlights the complexity of determining which ranking function should be selected by the search engine designer.
&lt;/p&gt;</description></item></channel></rss>