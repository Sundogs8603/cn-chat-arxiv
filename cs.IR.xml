<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;LLM&#26159;&#21542;&#21487;&#20197;&#29992;&#20316;&#23545;&#25239;&#29983;&#25104;&#24335;&#21407;&#29983;&#24191;&#21578;&#30340;&#23545;&#31574;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#24191;&#21578;&#20542;&#21521;&#26597;&#35810;&#25968;&#25454;&#38598;&#21644;&#24102;&#33258;&#21160;&#25972;&#21512;&#24191;&#21578;&#30340;&#29983;&#25104;&#31572;&#26696;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#12290;</title><link>https://arxiv.org/abs/2402.04889</link><description>&lt;p&gt;
&#21457;&#29616;&#23545;&#35805;&#24335;&#25628;&#32034;&#20013;&#30340;&#29983;&#25104;&#24335;&#21407;&#29983;&#24191;&#21578;
&lt;/p&gt;
&lt;p&gt;
Detecting Generated Native Ads in Conversational Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04889
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;LLM&#26159;&#21542;&#21487;&#20197;&#29992;&#20316;&#23545;&#25239;&#29983;&#25104;&#24335;&#21407;&#29983;&#24191;&#21578;&#30340;&#23545;&#31574;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#24191;&#21578;&#20542;&#21521;&#26597;&#35810;&#25968;&#25454;&#38598;&#21644;&#24102;&#33258;&#21160;&#25972;&#21512;&#24191;&#21578;&#30340;&#29983;&#25104;&#31572;&#26696;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#25628;&#32034;&#24341;&#25806;&#22914;YouChat&#21644;Microsoft Copilot&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20026;&#26597;&#35810;&#29983;&#25104;&#31572;&#26696;&#12290;&#23558;&#27492;&#25216;&#26415;&#29992;&#20110;&#29983;&#25104;&#24182;&#25972;&#21512;&#24191;&#21578;&#65292;&#32780;&#19981;&#26159;&#23558;&#24191;&#21578;&#19982;&#26377;&#26426;&#25628;&#32034;&#32467;&#26524;&#20998;&#24320;&#25918;&#32622;&#65292;&#21482;&#26159;&#19968;&#23567;&#27493;&#12290;&#36825;&#31181;&#31867;&#22411;&#30340;&#24191;&#21578;&#31867;&#20284;&#20110;&#21407;&#29983;&#24191;&#21578;&#21644;&#20135;&#21697;&#25918;&#32622;&#65292;&#20004;&#32773;&#37117;&#26159;&#38750;&#24120;&#26377;&#25928;&#30340;&#24494;&#22937;&#21644;&#25805;&#32437;&#24615;&#24191;&#21578;&#24418;&#24335;&#12290;&#22312;&#32771;&#34385;&#21040;&#19982;LLM&#30456;&#20851;&#30340;&#39640;&#35745;&#31639;&#25104;&#26412;&#26102;&#65292;&#20449;&#24687;&#25628;&#32034;&#32773;&#23558;&#24456;&#21487;&#33021;&#22312;&#19981;&#20037;&#30340;&#23558;&#26469;&#38754;&#20020;&#36825;&#31181;LLM&#25216;&#26415;&#30340;&#20351;&#29992;&#65292;&#22240;&#27492;&#20379;&#24212;&#21830;&#38656;&#35201;&#24320;&#21457;&#21487;&#25345;&#32493;&#30340;&#21830;&#19994;&#27169;&#24335;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;LLM&#26159;&#21542;&#20063;&#21487;&#20197;&#29992;&#20316;&#23545;&#25239;&#29983;&#25104;&#24335;&#21407;&#29983;&#24191;&#21578;&#30340;&#23545;&#31574;&#65292;&#21363;&#38459;&#27490;&#23427;&#20204;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32534;&#21046;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#24191;&#21578;&#20542;&#21521;&#26597;&#35810;&#25968;&#25454;&#38598;&#21644;&#24102;&#33258;&#21160;&#25972;&#21512;&#24191;&#21578;&#30340;&#29983;&#25104;&#31572;&#26696;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational search engines such as YouChat and Microsoft Copilot use large language models (LLMs) to generate answers to queries. It is only a small step to also use this technology to generate and integrate advertising within these answers - instead of placing ads separately from the organic search results. This type of advertising is reminiscent of native advertising and product placement, both of which are very effective forms of subtle and manipulative advertising. It is likely that information seekers will be confronted with such use of LLM technology in the near future, especially when considering the high computational costs associated with LLMs, for which providers need to develop sustainable business models. This paper investigates whether LLMs can also be used as a countermeasure against generated native ads, i.e., to block them. For this purpose we compile a large dataset of ad-prone queries and of generated answers with automatically integrated ads to experiment with fin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;PEARLM&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#24320;&#23637;&#22522;&#20110;&#36335;&#24452;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#33616;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23545;&#39044;&#35757;&#32451;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#30340;&#20381;&#36182;&#20197;&#21450;&#26410;&#20805;&#20998;&#21033;&#29992;&#23454;&#20307;&#21644;&#20851;&#31995;&#20043;&#38388;&#30456;&#20114;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#65292;&#36824;&#36991;&#20813;&#20102;&#29983;&#25104;&#19981;&#20934;&#30830;&#30340;&#35299;&#37322;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>http://arxiv.org/abs/2310.16452</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;&#36335;&#24452;&#30340;&#30693;&#35782;&#22270;&#25512;&#33616;&#20013;&#30340;&#24544;&#23454;&#36335;&#24452;&#35821;&#35328;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Faithful Path Language Modelling for Explainable Recommendation over Knowledge Graph. (arXiv:2310.16452v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;PEARLM&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#24320;&#23637;&#22522;&#20110;&#36335;&#24452;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#33616;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23545;&#39044;&#35757;&#32451;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#30340;&#20381;&#36182;&#20197;&#21450;&#26410;&#20805;&#20998;&#21033;&#29992;&#23454;&#20307;&#21644;&#20851;&#31995;&#20043;&#38388;&#30456;&#20114;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#65292;&#36824;&#36991;&#20813;&#20102;&#29983;&#25104;&#19981;&#20934;&#30830;&#30340;&#35299;&#37322;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#36335;&#24452;&#25512;&#29702;&#26041;&#27861;&#22312;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#36879;&#26126;&#24230;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PEARLM&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#26377;&#25928;&#25429;&#33719;&#29992;&#25143;&#34892;&#20026;&#21644;&#20135;&#21697;&#31471;&#30693;&#35782;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30452;&#25509;&#20174;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#36335;&#24452;&#20013;&#23398;&#20064;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#24182;&#23558;&#23454;&#20307;&#21644;&#20851;&#31995;&#32479;&#19968;&#22312;&#21516;&#19968;&#20248;&#21270;&#31354;&#38388;&#20013;&#12290;&#24207;&#21015;&#35299;&#30721;&#30340;&#32422;&#26463;&#20445;&#35777;&#20102;&#36335;&#24452;&#23545;&#30693;&#35782;&#22270;&#35889;&#30340;&#24544;&#23454;&#24615;&#12290;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Path reasoning methods over knowledge graphs have gained popularity for their potential to improve transparency in recommender systems. However, the resulting models still rely on pre-trained knowledge graph embeddings, fail to fully exploit the interdependence between entities and relations in the KG for recommendation, and may generate inaccurate explanations. In this paper, we introduce PEARLM, a novel approach that efficiently captures user behaviour and product-side knowledge through language modelling. With our approach, knowledge graph embeddings are directly learned from paths over the KG by the language model, which also unifies entities and relations in the same optimisation space. Constraints on the sequence decoding additionally guarantee path faithfulness with respect to the KG. Experiments on two datasets show the effectiveness of our approach compared to state-of-the-art baselines. Source code and datasets: AVAILABLE AFTER GETTING ACCEPTED.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20998;&#26512;&#20102;&#32676;&#32452;&#20559;&#35265;&#23545;&#25490;&#21517;&#36136;&#37327;&#30340;&#24433;&#21709;&#65292;&#25351;&#20986;&#22312;&#19981;&#32416;&#27491;&#32676;&#32452;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#25152;&#35859;&#30340;&#20844;&#24179;&#25490;&#21517;&#19981;&#30495;&#27491;&#20844;&#24179;&#12290;</title><link>http://arxiv.org/abs/2308.02887</link><description>&lt;p&gt;
&#32676;&#32452;&#25104;&#21592;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Group Membership Bias. (arXiv:2308.02887v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02887
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20998;&#26512;&#20102;&#32676;&#32452;&#20559;&#35265;&#23545;&#25490;&#21517;&#36136;&#37327;&#30340;&#24433;&#21709;&#65292;&#25351;&#20986;&#22312;&#19981;&#32416;&#27491;&#32676;&#32452;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#25152;&#35859;&#30340;&#20844;&#24179;&#25490;&#21517;&#19981;&#30495;&#27491;&#20844;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20174;&#29992;&#25143;&#20132;&#20114;&#20013;&#23398;&#20064;&#25490;&#21517;&#26102;&#65292;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#24517;&#39035;&#35299;&#20915;&#29992;&#25143;&#34892;&#20026;&#20013;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#20197;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#25490;&#21517;&#12290;&#22312;&#25490;&#21517;&#25991;&#29486;&#20013;&#26368;&#36817;&#30740;&#31350;&#30340;&#19968;&#31181;&#20559;&#35265;&#31867;&#22411;&#26159;&#25935;&#24863;&#23646;&#24615;&#65288;&#22914;&#24615;&#21035;&#65289;&#23545;&#29992;&#25143;&#23545;&#39033;&#30446;&#25928;&#29992;&#30340;&#21028;&#26029;&#20135;&#29983;&#30340;&#24433;&#21709;&#12290;&#20363;&#22914;&#65292;&#22312;&#23547;&#25214;&#26576;&#20010;&#19987;&#19994;&#39046;&#22495;&#26102;&#65292;&#19968;&#20123;&#29992;&#25143;&#21487;&#33021;&#23545;&#30007;&#24615;&#20505;&#36873;&#20154;&#27604;&#22899;&#24615;&#20505;&#36873;&#20154;&#26356;&#26377;&#20559;&#35265;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#20559;&#35265;&#31216;&#20026;&#32676;&#32452;&#25104;&#21592;&#20559;&#35265;&#25110;&#32676;&#32452;&#20559;&#35265;&#12290;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#24076;&#26395;&#33719;&#24471;&#19981;&#20165;&#20855;&#26377;&#39640;&#25928;&#29992;&#24615;&#32780;&#19988;&#23545;&#20010;&#20154;&#21644;&#25935;&#24863;&#32676;&#20307;&#20063;&#20844;&#24179;&#30340;&#25490;&#21517;&#12290;&#22522;&#20110;&#20215;&#20540;&#30340;&#20844;&#24179;&#24230;&#37327;&#20381;&#36182;&#20110;&#39033;&#30446;&#30340;&#20272;&#35745;&#20215;&#20540;&#25110;&#25928;&#29992;&#12290;&#22312;&#32676;&#32452;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#25935;&#24863;&#32676;&#20307;&#30340;&#25928;&#29992;&#34987;&#20302;&#20272;&#65292;&#22240;&#27492;&#65292;&#22312;&#19981;&#32416;&#27491;&#36825;&#31181;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#25152;&#35859;&#30340;&#20844;&#24179;&#25490;&#21517;&#24182;&#19981;&#30495;&#27491;&#20844;&#24179;&#12290;&#39318;&#20808;&#65292;&#26412;&#25991;&#20998;&#26512;&#20102;&#32676;&#32452;&#20559;&#35265;&#23545;&#25490;&#21517;&#36136;&#37327;&#20197;&#21450;&#20004;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#24773;&#20917;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
When learning to rank from user interactions, search and recommendation systems must address biases in user behavior to provide a high-quality ranking. One type of bias that has recently been studied in the ranking literature is when sensitive attributes, such as gender, have an impact on a user's judgment about an item's utility. For example, in a search for an expertise area, some users may be biased towards clicking on male candidates over female candidates. We call this type of bias group membership bias or group bias for short. Increasingly, we seek rankings that not only have high utility but are also fair to individuals and sensitive groups. Merit-based fairness measures rely on the estimated merit or utility of the items. With group bias, the utility of the sensitive groups is under-estimated, hence, without correcting for this bias, a supposedly fair ranking is not truly fair. In this paper, first, we analyze the impact of group bias on ranking quality as well as two well-know
&lt;/p&gt;</description></item></channel></rss>