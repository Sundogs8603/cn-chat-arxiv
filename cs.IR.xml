<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26412;&#22320;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23454;&#20307;&#38459;&#22622;&#38382;&#39064;&#12290;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#21704;&#24076;&#20989;&#25968;&#65292;&#33021;&#22815;&#24212;&#29992;&#20110;&#22797;&#26434;&#24230;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#26412;&#22320;&#25935;&#24863;&#21704;&#24076;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2401.18064</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#20307;&#38459;&#22622;&#30340;&#26412;&#22320;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Neural Locality Sensitive Hashing for Entity Blocking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.18064
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26412;&#22320;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23454;&#20307;&#38459;&#22622;&#38382;&#39064;&#12290;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#21704;&#24076;&#20989;&#25968;&#65292;&#33021;&#22815;&#24212;&#29992;&#20110;&#22797;&#26434;&#24230;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#26412;&#22320;&#25935;&#24863;&#21704;&#24076;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#22320;&#25935;&#24863;&#21704;&#24076;&#65288;LSH&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#22788;&#29702;&#24212;&#29992;&#20013;&#30340;&#22522;&#26412;&#31639;&#27861;&#25216;&#26415;&#65292;&#20363;&#22914;&#26368;&#36817;&#37051;&#25628;&#32034;&#12289;&#23454;&#20307;&#35299;&#26512;&#21644;&#32858;&#31867;&#12290;&#28982;&#32780;&#65292;&#22312;&#19968;&#20123;&#30495;&#23454;&#22330;&#26223;&#20013;&#65292;&#30001;&#20110;&#38656;&#35201;&#31934;&#24515;&#35774;&#35745;&#19982;&#29305;&#23450;&#24230;&#37327;&#30456;&#21305;&#37197;&#30340;&#21704;&#24076;&#20989;&#25968;&#65292;LSH&#30340;&#36866;&#29992;&#24615;&#21463;&#21040;&#38480;&#21046;&#12290;&#29616;&#26377;&#22522;&#20110;LSH&#30340;&#23454;&#20307;&#38459;&#22622;&#35299;&#20915;&#26041;&#26696;&#20027;&#35201;&#20381;&#36182;&#20110;&#36890;&#29992;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#20363;&#22914;Jaccard&#30456;&#20284;&#24230;&#65292;&#32780;&#23454;&#38469;&#24212;&#29992;&#26696;&#20363;&#36890;&#24120;&#38656;&#35201;&#22797;&#26434;&#21644;&#23450;&#21046;&#30340;&#30456;&#20284;&#24230;&#35268;&#21017;&#65292;&#36229;&#36807;&#20102;&#36890;&#29992;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#20026;&#36825;&#20123;&#23450;&#21046;&#30340;&#30456;&#20284;&#24230;&#35268;&#21017;&#35774;&#35745;LSH&#20989;&#25968;&#24102;&#26469;&#20102;&#30456;&#24403;&#22823;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#22797;&#26434;&#24230;&#37327;&#30340;&#21704;&#24076;&#20989;&#25968;&#65292;&#20197;&#22686;&#24378;&#26412;&#22320;&#25935;&#24863;&#21704;&#24076;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#22312;&#23454;&#20307;&#35299;&#26512;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#35780;&#20272;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Locality-sensitive hashing (LSH) is a fundamental algorithmic technique widely employed in large-scale data processing applications, such as nearest-neighbor search, entity resolution, and clustering. However, its applicability in some real-world scenarios is limited due to the need for careful design of hashing functions that align with specific metrics. Existing LSH-based Entity Blocking solutions primarily rely on generic similarity metrics such as Jaccard similarity, whereas practical use cases often demand complex and customized similarity rules surpassing the capabilities of generic similarity metrics. Consequently, designing LSH functions for these customized similarity rules presents considerable challenges. In this research, we propose a neuralization approach to enhance locality-sensitive hashing by training deep neural networks to serve as hashing functions for complex metrics. We assess the effectiveness of this approach within the context of the entity resolution problem, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23481;&#38169;&#22411;&#30005;&#23376;&#21457;&#29616;&#21327;&#35758;&#65292;&#33021;&#22815;&#20960;&#20046;&#23436;&#20840;&#25214;&#21040;&#19982;&#35831;&#27714;&#30456;&#24212;&#30340;&#25991;&#20214;&#65292;&#24182;&#26368;&#23567;&#21270;&#38750;&#21709;&#24212;&#25991;&#20214;&#30340;&#25259;&#38706;&#12290;</title><link>https://arxiv.org/abs/2401.17952</link><description>&lt;p&gt;
&#23481;&#38169;&#22411;&#30005;&#23376;&#21457;&#29616;&#21327;&#35758;
&lt;/p&gt;
&lt;p&gt;
Error-Tolerant E-Discovery Protocols
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23481;&#38169;&#22411;&#30005;&#23376;&#21457;&#29616;&#21327;&#35758;&#65292;&#33021;&#22815;&#20960;&#20046;&#23436;&#20840;&#25214;&#21040;&#19982;&#35831;&#27714;&#30456;&#24212;&#30340;&#25991;&#20214;&#65292;&#24182;&#26368;&#23567;&#21270;&#38750;&#21709;&#24212;&#25991;&#20214;&#30340;&#25259;&#38706;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;Dong&#12289;Hartline&#21644;Vijayaraghavan&#65288;2022&#65289;&#22312;&#30005;&#23376;&#21457;&#29616;&#65288;e-discovery&#65289;&#32972;&#26223;&#19979;&#24341;&#20837;&#30340;&#22810;&#26041;&#20998;&#31867;&#38382;&#39064;&#12290;&#26681;&#25454;&#26469;&#33258;&#35831;&#27714;&#26041;&#30340;&#29983;&#20135;&#35201;&#27714;&#65292;&#21709;&#24212;&#26041;&#38656;&#35201;&#25552;&#20379;&#19982;&#35813;&#35201;&#27714;&#30456;&#24212;&#30340;&#25991;&#20214;&#65292;&#20294;&#19981;&#21253;&#25324;&#27861;&#24459;&#29305;&#26435;&#25991;&#20214;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010;&#39564;&#35777;&#21709;&#24212;&#26041;&#21457;&#36865;&#20960;&#20046;&#25152;&#26377;&#21709;&#24212;&#25991;&#20214;&#24182;&#26368;&#23567;&#21270;&#38750;&#21709;&#24212;&#25991;&#20214;&#25259;&#38706;&#30340;&#21327;&#35758;&#12290;&#25105;&#20204;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38750;&#29616;&#23454;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#21327;&#35758;&#65292;&#22312;&#35813;&#35774;&#32622;&#20013;&#65292;&#23454;&#20363;&#21487;&#33021;&#26080;&#27861;&#36890;&#36807;&#32447;&#24615;&#20998;&#31867;&#22120;&#23436;&#20840;&#20998;&#31163;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#21327;&#35758;&#25104;&#21151;&#22320;&#25214;&#21040;&#20102;&#20960;&#20046;&#25152;&#26377;&#30456;&#20851;&#25991;&#20214;&#65292;&#21516;&#26102;&#21482;&#25259;&#38706;&#20102;&#23569;&#37327;&#38750;&#21709;&#24212;&#25991;&#20214;&#12290;&#25105;&#20204;&#36824;&#23545;&#21333;&#32500;&#24230;&#35774;&#32622;&#19979;&#30340;&#21327;&#35758;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#36827;&#34892;&#20102;&#20854;&#20182;&#27169;&#25311;&#25968;&#25454;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#21327;&#35758;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the multi-party classification problem introduced by Dong, Hartline, and Vijayaraghavan (2022) in the context of electronic discovery (e-discovery). Based on a request for production from the requesting party, the responding party is required to provide documents that are responsive to the request except for those that are legally privileged. Our goal is to find a protocol that verifies that the responding party sends almost all responsive documents while minimizing the disclosure of non-responsive documents. We provide protocols in the challenging non-realizable setting, where the instance may not be perfectly separated by a linear classifier. We demonstrate empirically that our protocol successfully manages to find almost all relevant documents, while incurring only a small disclosure of non-responsive documents. We complement this with a theoretical analysis of our protocol in the single-dimensional setting, and other experiments on simulated data which suggest that the 
&lt;/p&gt;</description></item><item><title>&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#21040;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#36716;&#21464;&#12290;&#36825;&#31687;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25512;&#33616;&#25968;&#25454;&#30340;&#20027;&#35201;&#38382;&#39064;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2401.17878</link><description>&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Data-Centric Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17878
&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#21040;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#36716;&#21464;&#12290;&#36825;&#31687;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25512;&#33616;&#25968;&#25454;&#30340;&#20027;&#35201;&#38382;&#39064;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#24212;&#23545;&#20449;&#24687;&#36807;&#36733;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#23454;&#38469;&#22330;&#26223;&#12290;&#26368;&#36817;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#36235;&#21183;&#20986;&#29616;&#20102;&#33539;&#24335;&#36716;&#21464;&#65292;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#30340;&#21019;&#26032;&#36716;&#21521;&#25968;&#25454;&#36136;&#37327;&#21644;&#25968;&#37327;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#19968;&#21464;&#21270;&#24341;&#20986;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#65288;Data-Centric RS&#65289;&#30340;&#27010;&#24565;&#65292;&#26631;&#24535;&#30528;&#35813;&#39046;&#22495;&#30340;&#37325;&#35201;&#21457;&#23637;&#12290;&#26412;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#22320;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#65292;&#21253;&#25324;1&#65289;&#25512;&#33616;&#25968;&#25454;&#21644;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#65307;2&#65289;&#25512;&#33616;&#25968;&#25454;&#38754;&#20020;&#30340;&#19977;&#20010;&#20027;&#35201;&#38382;&#39064;&#65307;3&#65289;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#32780;&#24320;&#23637;&#30340;&#26368;&#36817;&#30740;&#31350;&#65307;&#20197;&#21450;4&#65289;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#30340;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) have become essential tools for mitigating information overload in a range of real-world scenarios. Recent trends in RS have seen a paradigm shift, moving the spotlight from model-centric innovations to the importance of data quality and quantity. This evolution has given rise to the concept of data-centric recommender systems (Data-Centric RS), marking a significant development in the field. This survey provides the first systematic overview of Data-Centric RS, covering 1) the foundational concepts of recommendation data and Data-Centric RS; 2) three primary issues in recommendation data; 3) recent research developed to address these issues; and 4) several potential future directions in Data-Centric RS.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#33021;&#37327;&#30340;&#26032;&#26041;&#27861;DESAlign&#65292;&#20197;&#35299;&#20915;&#22810;&#27169;&#24577;&#23454;&#20307;&#23545;&#40784;&#20013;&#30340;&#35821;&#20041;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#35821;&#20041;&#19981;&#19968;&#33268;&#24615;&#23548;&#33268;&#27169;&#22411;&#36807;&#24230;&#25311;&#21512;&#27169;&#24577;&#22122;&#22768;&#65292;&#32780;DESAlign&#36890;&#36807;&#25554;&#20540;&#32570;&#22833;&#30340;&#35821;&#20041;&#24182;&#24212;&#23545;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#35821;&#20041;&#19968;&#33268;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17859</link><description>&lt;p&gt;
&#23454;&#29616;&#35821;&#20041;&#19968;&#33268;&#24615;&#65306;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#33021;&#37327;&#30340;&#40065;&#26834;&#22810;&#27169;&#24577;&#23454;&#20307;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Towards Semantic Consistency: Dirichlet Energy Driven Robust Multi-Modal Entity Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#33021;&#37327;&#30340;&#26032;&#26041;&#27861;DESAlign&#65292;&#20197;&#35299;&#20915;&#22810;&#27169;&#24577;&#23454;&#20307;&#23545;&#40784;&#20013;&#30340;&#35821;&#20041;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#35821;&#20041;&#19981;&#19968;&#33268;&#24615;&#23548;&#33268;&#27169;&#22411;&#36807;&#24230;&#25311;&#21512;&#27169;&#24577;&#22122;&#22768;&#65292;&#32780;DESAlign&#36890;&#36807;&#25554;&#20540;&#32570;&#22833;&#30340;&#35821;&#20041;&#24182;&#24212;&#23545;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#35821;&#20041;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#27169;&#24577;&#30693;&#35782;&#22270;&#35889;&#65288;MMKG&#65289;&#20013;&#65292;&#22810;&#27169;&#24577;&#23454;&#20307;&#23545;&#40784;&#65288;MMEA&#65289;&#23545;&#20110;&#35782;&#21035;&#19981;&#21516;&#27169;&#24577;&#23646;&#24615;&#38388;&#30340;&#30456;&#21516;&#23454;&#20307;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#22833;&#27169;&#24577;&#23646;&#24615;&#32780;&#23548;&#33268;&#30340;&#35821;&#20041;&#19981;&#19968;&#33268;&#24615;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#20256;&#32479;&#26041;&#27861;&#20381;&#36182;&#20110;&#23646;&#24615;&#25554;&#20540;&#65292;&#20294;&#36825;&#24448;&#24448;&#20250;&#24341;&#20837;&#27169;&#24577;&#22122;&#22768;&#65292;&#25197;&#26354;&#21407;&#22987;&#35821;&#20041;&#12290;&#27492;&#22806;&#65292;&#32570;&#20047;&#19968;&#20010;&#26222;&#36866;&#30340;&#29702;&#35770;&#26694;&#26550;&#38480;&#21046;&#20102;&#23545;&#35821;&#20041;&#19968;&#33268;&#24615;&#30340;&#36827;&#23637;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;DESAlign&#65292;&#36890;&#36807;&#24212;&#29992;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#33021;&#37327;&#30340;&#29702;&#35770;&#26694;&#26550;&#26469;&#30830;&#20445;&#35821;&#20041;&#19968;&#33268;&#24615;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#35821;&#20041;&#19981;&#19968;&#33268;&#24615;&#23548;&#33268;&#27169;&#22411;&#36807;&#24230;&#25311;&#21512;&#27169;&#24577;&#22122;&#22768;&#65292;&#29305;&#21035;&#26159;&#22312;&#27169;&#24577;&#32570;&#22833;&#26102;&#36896;&#25104;&#24615;&#33021;&#27874;&#21160;&#12290;DESAlign&#21019;&#26032;&#22320;&#24212;&#23545;&#20102;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#29616;&#26377;&#27169;&#24577;&#25554;&#20540;&#32570;&#22833;&#30340;&#35821;&#20041;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#19968;&#20010;&#22810;&#27169;&#24577;&#30693;&#35782;&#22270;&#35889;&#23398;&#20064;&#30340;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Multi-Modal Knowledge Graphs (MMKGs), Multi-Modal Entity Alignment (MMEA) is crucial for identifying identical entities across diverse modal attributes. However, semantic inconsistency, mainly due to missing modal attributes, poses a significant challenge. Traditional approaches rely on attribute interpolation, but this often introduces modality noise, distorting the original semantics. Moreover, the lack of a universal theoretical framework limits advancements in achieving semantic consistency. This study introduces a novel approach, DESAlign, which addresses these issues by applying a theoretical framework based on Dirichlet energy to ensure semantic consistency. We discover that semantic inconsistency leads to model overfitting to modality noise, causing performance fluctuations, particularly when modalities are missing. DESAlign innovatively combats over-smoothing and interpolates absent semantics using existing modalities. Our approach includes a multi-modal knowledge graph lea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#30340;&#20027;&#39064;&#32467;&#26500;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#20027;&#39064;&#27169;&#22411;&#33719;&#24471;&#30340;&#20027;&#39064;-&#35789;&#20998;&#24067;&#25968;&#25454;&#65292;&#36890;&#36807;&#28508;&#22312;&#31354;&#38388;&#39033;&#30446;&#21709;&#24212;&#27169;&#22411;&#24314;&#27169;&#20027;&#39064;&#30340;&#32467;&#26500;&#65292;&#20197;&#21450;&#20351;&#29992;&#35780;&#20998;&#26041;&#26696;&#36873;&#25321;&#20195;&#34920;&#24615;&#35789;&#27719;&#26469;&#35299;&#37322;&#20027;&#39064;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#22312;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#21487;&#35270;&#21270;&#20027;&#39064;&#30340;&#28508;&#22312;&#20301;&#32622;&#65292;&#21487;&#20197;&#30452;&#35266;&#22320;&#20102;&#35299;&#20027;&#39064;&#20043;&#38388;&#30340;&#25509;&#36817;&#31243;&#24230;&#21644;&#20851;&#32852;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2401.17855</link><description>&lt;p&gt;
&#22522;&#20110;&#32593;&#32476;&#30340;&#20027;&#39064;&#32467;&#26500;&#21487;&#35270;&#21270;
&lt;/p&gt;
&lt;p&gt;
Network-based Topic Structure Visualization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17855
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#30340;&#20027;&#39064;&#32467;&#26500;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#20027;&#39064;&#27169;&#22411;&#33719;&#24471;&#30340;&#20027;&#39064;-&#35789;&#20998;&#24067;&#25968;&#25454;&#65292;&#36890;&#36807;&#28508;&#22312;&#31354;&#38388;&#39033;&#30446;&#21709;&#24212;&#27169;&#22411;&#24314;&#27169;&#20027;&#39064;&#30340;&#32467;&#26500;&#65292;&#20197;&#21450;&#20351;&#29992;&#35780;&#20998;&#26041;&#26696;&#36873;&#25321;&#20195;&#34920;&#24615;&#35789;&#27719;&#26469;&#35299;&#37322;&#20027;&#39064;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#22312;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#21487;&#35270;&#21270;&#20027;&#39064;&#30340;&#28508;&#22312;&#20301;&#32622;&#65292;&#21487;&#20197;&#30452;&#35266;&#22320;&#20102;&#35299;&#20027;&#39064;&#20043;&#38388;&#30340;&#25509;&#36817;&#31243;&#24230;&#21644;&#20851;&#32852;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#35768;&#22810;&#20027;&#39064;&#20043;&#38388;&#23384;&#22312;&#30456;&#20114;&#20851;&#32852;&#65292;&#36825;&#32473;&#30740;&#31350;&#23427;&#20204;&#30340;&#32467;&#26500;&#21644;&#20851;&#31995;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#20102;&#35299;&#20027;&#39064;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#21450;&#20854;&#30456;&#20851;&#24615;&#21487;&#20197;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#65292;&#25351;&#23548;&#20182;&#20204;&#30340;&#30740;&#31350;&#24182;&#30830;&#23450;&#30740;&#31350;&#30340;&#26041;&#21521;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20174;&#20027;&#39064;&#27169;&#22411;&#20013;&#33719;&#24471;&#30340;&#20027;&#39064;-&#35789;&#20998;&#24067;&#20316;&#20026;&#39033;&#30446;&#21709;&#24212;&#25968;&#25454;&#65292;&#20351;&#29992;&#28508;&#22312;&#31354;&#38388;&#39033;&#30446;&#21709;&#24212;&#27169;&#22411;&#23545;&#20027;&#39064;&#30340;&#32467;&#26500;&#36827;&#34892;&#24314;&#27169;&#12290;&#36890;&#36807;&#26681;&#25454;&#21040;&#21333;&#35789;&#30340;&#36317;&#31163;&#20272;&#35745;&#20027;&#39064;&#30340;&#28508;&#22312;&#20301;&#32622;&#65292;&#25105;&#20204;&#21487;&#20197;&#25429;&#25417;&#21040;&#20027;&#39064;&#30340;&#28508;&#22312;&#32467;&#26500;&#24182;&#25581;&#31034;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#22312;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#21487;&#35270;&#21270;&#20027;&#39064;&#30340;&#28508;&#22312;&#20301;&#32622;&#65292;&#21487;&#20197;&#30452;&#35266;&#22320;&#29702;&#35299;&#23427;&#20204;&#20043;&#38388;&#30340;&#25509;&#36817;&#31243;&#24230;&#21644;&#20851;&#32852;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#25552;&#20986;&#30340;&#35780;&#20998;&#26041;&#26696;&#36873;&#25321;&#20195;&#34920;&#24615;&#35789;&#27719;&#26469;&#34920;&#24449;&#20027;&#39064;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#36861;&#36394;&#20027;&#39064;&#30340;&#28508;&#22312;&#20301;&#32622;&#26469;&#35780;&#20272;&#23427;&#20204;&#30340;&#25104;&#29087;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the real world, many topics are inter-correlated, making it challenging to investigate their structure and relationships. Understanding the interplay between topics and their relevance can provide valuable insights for researchers, guiding their studies and informing the direction of research. In this paper, we utilize the topic-words distribution, obtained from topic models, as item-response data to model the structure of topics using a latent space item response model. By estimating the latent positions of topics based on their distances toward words, we can capture the underlying topic structure and reveal their relationships. Visualizing the latent positions of topics in Euclidean space allows for an intuitive understanding of their proximity and associations. We interpret relationships among topics by characterizing each topic based on representative words selected using a newly proposed scoring scheme. Additionally, we assess the maturity of topics by tracking their latent pos
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;GPT&#27169;&#22411;&#30340;&#20107;&#23454;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#20559;&#35265;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#24179;&#34913;&#25968;&#25454;&#38598;"&#20840;&#29699;&#35828;&#35854;&#32773;"&#65292;&#32467;&#26524;&#26174;&#31034;&#36739;&#26032;&#30340;GPT&#27169;&#22411;&#24182;&#19981;&#24635;&#26159;&#24847;&#21619;&#30528;&#24615;&#33021;&#30340;&#25552;&#21319;&#65292;&#24182;&#19988;&#35266;&#23519;&#21040;&#19968;&#20010;&#20840;&#29699;&#21335;&#26041;&#38472;&#36848;&#34987;&#20559;&#34962;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2401.17839</link><description>&lt;p&gt;
&#20840;&#29699;&#35828;&#35854;&#32773;&#65306;LLMs&#22312;&#26102;&#38388;&#21644;&#22320;&#29702;&#21306;&#22495;&#19978;&#30340;&#20107;&#23454;&#24615;
&lt;/p&gt;
&lt;p&gt;
Global-Liar: Factuality of LLMs over Time and Geographic Regions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;GPT&#27169;&#22411;&#30340;&#20107;&#23454;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#20559;&#35265;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#24179;&#34913;&#25968;&#25454;&#38598;"&#20840;&#29699;&#35828;&#35854;&#32773;"&#65292;&#32467;&#26524;&#26174;&#31034;&#36739;&#26032;&#30340;GPT&#27169;&#22411;&#24182;&#19981;&#24635;&#26159;&#24847;&#21619;&#30528;&#24615;&#33021;&#30340;&#25552;&#21319;&#65292;&#24182;&#19988;&#35266;&#23519;&#21040;&#19968;&#20010;&#20840;&#29699;&#21335;&#26041;&#38472;&#36848;&#34987;&#20559;&#34962;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22810;&#22320;&#20381;&#36182;&#20110;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29305;&#21035;&#26159;&#20687;GPT&#31995;&#21015;&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#20351;&#29992;&#65292;&#31361;&#26174;&#20102;&#23545;&#23427;&#20204;&#30340;&#20107;&#23454;&#20934;&#30830;&#24615;&#21644;&#20844;&#27491;&#24615;&#30340;&#37325;&#35201;&#24615;&#65292;&#23588;&#20854;&#26159;&#22312;&#32593;&#32476;&#19978;&#34394;&#20551;&#20449;&#24687;&#21644;&#35823;&#23548;&#20449;&#24687;&#29462;&#29527;&#20256;&#25773;&#30340;&#32972;&#26223;&#19979;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#35780;&#20272;&#20102;&#24191;&#27867;&#37319;&#29992;&#30340;GPT&#27169;&#22411;&#65288;&#21253;&#25324;GPT-3.5&#21644;GPT-4&#65289;&#30340;&#20107;&#23454;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#20559;&#35265;&#65292;&#20197;&#25552;&#39640;&#20154;&#24037;&#26234;&#33021;&#20171;&#23548;&#20449;&#24687;&#20256;&#25773;&#30340;&#21487;&#38752;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#29420;&#29305;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#8220;&#20840;&#29699;&#35828;&#35854;&#32773;&#8221;&#65292;&#20854;&#22312;&#22320;&#29702;&#21644;&#26102;&#38388;&#34920;&#24449;&#26041;&#38754;&#26377;&#21161;&#20110;&#26356;&#32454;&#33268;&#22320;&#35780;&#20272;LLM&#30340;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#26524;&#34920;&#26126;&#65292;&#36739;&#26032;&#30340;GPT&#27169;&#22411;&#24182;&#19981;&#24635;&#26159;&#24847;&#21619;&#30528;&#24615;&#33021;&#30340;&#25552;&#21319;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;3&#26376;&#21457;&#24067;&#30340;GPT-4&#29256;&#26412;&#26174;&#31034;&#20986;&#27604;&#20854;&#21518;&#32493;6&#26376;&#21457;&#24067;&#29256;&#26412;&#26356;&#39640;&#30340;&#20107;&#23454;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#36824;&#35266;&#23519;&#21040;&#19968;&#20010;&#20196;&#20154;&#25285;&#24551;&#30340;&#20559;&#35265;&#65292;&#21363;&#23545;&#20840;&#29699;&#21335;&#26041;&#30340;&#38472;&#36848;&#32473;&#20104;&#20102;&#29305;&#26435;&#65292;&#21487;&#33021;&#21152;&#21095;&#20102;&#19981;&#24179;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing reliance on AI-driven solutions, particularly Large Language Models (LLMs) like the GPT series, for information retrieval highlights the critical need for their factuality and fairness, especially amidst the rampant spread of misinformation and disinformation online. Our study evaluates the factual accuracy, stability, and biases in widely adopted GPT models, including GPT-3.5 and GPT-4, contributing to reliability and integrity of AI-mediated information dissemination.   We introduce 'Global-Liar,' a dataset uniquely balanced in terms of geographic and temporal representation, facilitating a more nuanced evaluation of LLM biases. Our analysis reveals that newer iterations of GPT models do not always equate to improved performance. Notably, the GPT-4 version from March demonstrates higher factual accuracy than its subsequent June release. Furthermore, a concerning bias is observed, privileging statements from the Global North over the Global South, thus potentially exace
&lt;/p&gt;</description></item><item><title>LoRec&#26159;&#19968;&#20010;&#38024;&#23545;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#21487;&#20197;&#26816;&#27979;&#24182;&#35782;&#21035;&#26410;&#30693;&#30340;&#31713;&#25913;&#25915;&#20987;&#65292;&#25552;&#39640;&#20102;&#31995;&#32479;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.17723</link><description>&lt;p&gt;
LoRec: &#38024;&#23545;&#31713;&#25913;&#25915;&#20987;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#40065;&#26834;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
LoRec: Large Language Model for Robust Sequential Recommendation against Poisoning Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17723
&lt;/p&gt;
&lt;p&gt;
LoRec&#26159;&#19968;&#20010;&#38024;&#23545;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#21487;&#20197;&#26816;&#27979;&#24182;&#35782;&#21035;&#26410;&#30693;&#30340;&#31713;&#25913;&#25915;&#20987;&#65292;&#25552;&#39640;&#20102;&#31995;&#32479;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#20197;&#20854;&#25429;&#25417;&#29992;&#25143;&#21160;&#24577;&#20852;&#36259;&#21644;&#29289;&#21697;&#38388;&#36716;&#25442;&#27169;&#24335;&#30340;&#33021;&#21147;&#33073;&#39062;&#32780;&#20986;&#12290;&#28982;&#32780;&#65292;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#22266;&#26377;&#24320;&#25918;&#24615;&#20351;&#20854;&#23481;&#26131;&#21463;&#21040;&#31713;&#25913;&#25915;&#20987;&#65292;&#21363;&#36890;&#36807;&#21521;&#35757;&#32451;&#25968;&#25454;&#20013;&#27880;&#20837;&#27450;&#35784;&#24615;&#29992;&#25143;&#26469;&#25805;&#32437;&#23398;&#20064;&#27169;&#24335;&#12290;&#20256;&#32479;&#30340;&#38450;&#24481;&#31574;&#30053;&#20027;&#35201;&#20381;&#36182;&#20110;&#39044;&#23450;&#30340;&#20551;&#35774;&#25110;&#20174;&#29305;&#23450;&#24050;&#30693;&#25915;&#20987;&#20013;&#25552;&#21462;&#30340;&#35268;&#21017;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#23545;&#26410;&#30693;&#25915;&#20987;&#31867;&#22411;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#20197;&#19978;&#38382;&#39064;&#65292;&#32771;&#34385;&#21040;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25152;&#22218;&#25324;&#30340;&#20016;&#23500;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#39318;&#20808;&#20851;&#27880;LLMs&#22312;&#26816;&#27979;&#25512;&#33616;&#31995;&#32479;&#20013;&#26410;&#30693;&#27450;&#35784;&#27963;&#21160;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#23558;&#35813;&#31574;&#30053;&#31216;&#20026;LLM4Dec&#12290;&#32463;&#39564;&#35780;&#20272;&#23637;&#31034;&#20102;LLMs&#22312;&#35782;&#21035;&#26410;&#30693;&#27450;&#35784;&#32773;&#26041;&#38754;&#30340;&#24040;&#22823;&#33021;&#21147;&#65292;&#21033;&#29992;&#20854;&#20016;&#23500;&#30340;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
Sequential recommender systems stand out for their ability to capture users' dynamic interests and the patterns of item-to-item transitions. However, the inherent openness of sequential recommender systems renders them vulnerable to poisoning attacks, where fraudulent users are injected into the training data to manipulate learned patterns. Traditional defense strategies predominantly depend on predefined assumptions or rules extracted from specific known attacks, limiting their generalizability to unknown attack types. To solve the above problems, considering the rich open-world knowledge encapsulated in Large Language Models (LLMs), our research initially focuses on the capabilities of LLMs in the detection of unknown fraudulent activities within recommender systems, a strategy we denote as LLM4Dec. Empirical evaluations demonstrate the substantial capability of LLMs in identifying unknown fraudsters, leveraging their expansive, open-world knowledge.   Building upon this, we propose 
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#32852;&#37030;&#25628;&#32034;&#20013;&#23637;&#29616;&#20986;&#24378;&#22823;&#30340;&#36164;&#28304;&#36873;&#25321;&#33021;&#21147;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#29305;&#24449;&#30340;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#26524;&#21644;&#26356;&#20302;&#30340;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2401.17645</link><description>&lt;p&gt;
ReSLLM: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#32852;&#37030;&#25628;&#32034;&#24378;&#22823;&#30340;&#36164;&#28304;&#36873;&#25321;&#22120;
&lt;/p&gt;
&lt;p&gt;
ReSLLM: Large Language Models are Strong Resource Selectors for Federated Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17645
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#32852;&#37030;&#25628;&#32034;&#20013;&#23637;&#29616;&#20986;&#24378;&#22823;&#30340;&#36164;&#28304;&#36873;&#25321;&#33021;&#21147;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#29305;&#24449;&#30340;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#26524;&#21644;&#26356;&#20302;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#25628;&#32034;&#26159;&#23558;&#22810;&#20010;&#29420;&#31435;&#25628;&#32034;&#24341;&#25806;&#30340;&#32467;&#26524;&#25972;&#21512;&#36215;&#26469;&#30340;&#36807;&#31243;&#65292;&#22312;&#22686;&#24378;&#26816;&#32034;&#29983;&#25104;&#27969;&#27700;&#32447;&#20013;&#20855;&#26377;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#20026;&#32842;&#22825;&#26426;&#22120;&#20154;&#31561;&#22522;&#20110;LLM&#30340;&#24212;&#29992;&#25552;&#20379;&#25903;&#25345;&#12290;&#36825;&#20123;&#31995;&#32479;&#36890;&#24120;&#26681;&#25454;&#29992;&#25143;&#30340;&#35805;&#35821;&#24615;&#36136;&#65292;&#23558;&#26597;&#35810;&#20998;&#21457;&#21040;&#21508;&#31181;&#25628;&#32034;&#24341;&#25806;&#20013;&#65292;&#20174;&#19987;&#38376;&#30340;&#65288;&#22914;PubMed&#65289;&#21040;&#36890;&#29992;&#30340;&#65288;&#22914;Google&#65289;&#12290;&#32852;&#37030;&#25628;&#32034;&#30340;&#19968;&#20010;&#20851;&#38190;&#26041;&#38754;&#26159;&#36164;&#28304;&#36873;&#25321;&#65292;&#21363;&#22312;&#21457;&#20986;&#26597;&#35810;&#20043;&#21069;&#36873;&#25321;&#36866;&#24403;&#30340;&#36164;&#28304;&#65292;&#20197;&#30830;&#20445;&#39640;&#36136;&#37327;&#21644;&#24555;&#36895;&#21709;&#24212;&#65292;&#24182;&#38477;&#20302;&#35843;&#29992;&#22806;&#37096;&#25628;&#32034;&#24341;&#25806;&#30340;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;SOTA&#36164;&#28304;&#36873;&#25321;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#22522;&#20110;&#29305;&#24449;&#30340;&#23398;&#20064;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#28041;&#21450;&#20154;&#21147;&#23494;&#38598;&#21644;&#26114;&#36149;&#30340;&#35757;&#32451;&#26631;&#31614;&#30340;&#21019;&#24314;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;LLM&#22312;NLP&#21644;IR&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#24378;&#22823;&#30340;&#38646;-shot&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#20551;&#35774;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;...
&lt;/p&gt;
&lt;p&gt;
Federated search, which involves integrating results from multiple independent search engines, will become increasingly pivotal in the context of Retrieval-Augmented Generation pipelines empowering LLM-based applications such as chatbots. These systems often distribute queries among various search engines, ranging from specialized (e.g., PubMed) to general (e.g., Google), based on the nature of user utterances. A critical aspect of federated search is resource selection - the selection of appropriate resources prior to issuing the query to ensure high-quality and rapid responses, and contain costs associated with calling the external search engines. However, current SOTA resource selection methodologies primarily rely on feature-based learning approaches. These methods often involve the labour intensive and expensive creation of training labels for each resource. In contrast, LLMs have exhibited strong effectiveness as zero-shot methods across NLP and IR tasks. We hypothesise that in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25143;&#25511;&#21046;&#30340;&#25968;&#25454;&#36129;&#29486;&#32852;&#37030;&#25512;&#33616;&#26550;&#26500;&#65292;&#36890;&#36807;&#35753;&#29992;&#25143;&#33258;&#30001;&#36873;&#25321;&#26159;&#21542;&#20849;&#20139;&#25968;&#25454;&#20197;&#21450;&#20849;&#20139;&#30340;&#27604;&#20363;&#65292;&#26469;&#20010;&#24615;&#21270;&#20445;&#25252;&#38544;&#31169;&#24182;&#25552;&#20379;&#26356;&#22909;&#30340;&#25512;&#33616;&#26381;&#21153;&#12290;</title><link>https://arxiv.org/abs/2401.17630</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#38544;&#31169;&#20445;&#25252;&#65306;&#29992;&#25143;&#25511;&#21046;&#30340;&#25968;&#25454;&#36129;&#29486;&#29992;&#20110;&#32852;&#37030;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Towards Personalized Privacy: User-Governed Data Contribution for Federated Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17630
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25143;&#25511;&#21046;&#30340;&#25968;&#25454;&#36129;&#29486;&#32852;&#37030;&#25512;&#33616;&#26550;&#26500;&#65292;&#36890;&#36807;&#35753;&#29992;&#25143;&#33258;&#30001;&#36873;&#25321;&#26159;&#21542;&#20849;&#20139;&#25968;&#25454;&#20197;&#21450;&#20849;&#20139;&#30340;&#27604;&#20363;&#65292;&#26469;&#20010;&#24615;&#21270;&#20445;&#25252;&#38544;&#31169;&#24182;&#25552;&#20379;&#26356;&#22909;&#30340;&#25512;&#33616;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#65288;FedRecs&#65289;&#30001;&#20110;&#23558;&#29992;&#25143;&#38544;&#31169;&#25968;&#25454;&#20445;&#30041;&#22312;&#26412;&#22320;&#24182;&#21482;&#21521;&#26381;&#21153;&#22120;&#20256;&#36882;&#27169;&#22411;&#21442;&#25968;/&#26799;&#24230;&#30340;&#28508;&#21147;&#65292;&#24050;&#32463;&#24341;&#36215;&#20102;&#37325;&#35201;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;FedRecs&#26550;&#26500;&#20551;&#35774;&#25152;&#26377;&#29992;&#25143;&#20855;&#26377;&#30456;&#21516;&#30340;&#38646;&#38544;&#31169;&#39044;&#31639;&#65292;&#21363;&#20182;&#20204;&#19981;&#20250;&#19978;&#20256;&#20219;&#20309;&#25968;&#25454;&#21040;&#26381;&#21153;&#22120;&#65292;&#22240;&#27492;&#24573;&#30053;&#20102;&#37027;&#20123;&#19981;&#22826;&#20851;&#24515;&#38544;&#31169;&#24182;&#24895;&#24847;&#19978;&#20256;&#25968;&#25454;&#33719;&#24471;&#26356;&#22909;&#25512;&#33616;&#26381;&#21153;&#30340;&#29992;&#25143;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#29992;&#25143;&#25511;&#21046;&#30340;&#25968;&#25454;&#36129;&#29486;&#32852;&#37030;&#25512;&#33616;&#26550;&#26500;&#65292;&#29992;&#25143;&#21487;&#20197;&#33258;&#30001;&#20915;&#23450;&#26159;&#21542;&#20849;&#20139;&#25968;&#25454;&#20197;&#21450;&#20849;&#20139;&#32473;&#26381;&#21153;&#22120;&#30340;&#25968;&#25454;&#27604;&#20363;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CDCGNNFed&#30340;&#20113;&#35774;&#22791;&#21327;&#20316;&#22270;&#31070;&#32463;&#32593;&#32476;&#32852;&#37030;&#25512;&#33616;&#27169;&#22411;&#65292;&#23427;&#22312;&#26412;&#22320;&#35757;&#32451;&#22522;&#20110;&#29992;&#25143;&#20013;&#24515;&#30340;&#20010;&#20154;&#22270;&#65292;&#24182;&#22312;&#26381;&#21153;&#22120;&#19978;&#22522;&#20110;&#29992;&#25143;&#20849;&#20139;&#25968;&#25454;&#35757;&#32451;&#39640;&#38454;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated recommender systems (FedRecs) have gained significant attention for their potential to protect user's privacy by keeping user privacy data locally and only communicating model parameters/gradients to the server. Nevertheless, the currently existing architecture of FedRecs assumes that all users have the same 0-privacy budget, i.e., they do not upload any data to the server, thus overlooking those users who are less concerned about privacy and are willing to upload data to get a better recommendation service. To bridge this gap, this paper explores a user-governed data contribution federated recommendation architecture where users are free to take control of whether they share data and the proportion of data they share to the server. To this end, this paper presents a cloud-device collaborative graph neural network federated recommendation model, named CDCGNNFed. It trains user-centric ego graphs locally, and high-order graphs based on user-shared data in the server in a colla
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;Fr\'echet&#36317;&#31163;&#26469;&#35780;&#20272;&#31232;&#30095;&#26631;&#31614;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#23569;&#37327;&#26631;&#31614;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;Fr\'echet&#36317;&#31163;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;</title><link>https://arxiv.org/abs/2401.17543</link><description>&lt;p&gt;
&#29992;&#20110;&#31232;&#30095;&#26631;&#31614;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#31163;&#32447;&#35780;&#20272;&#30340;Fr\'echet&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Fr\'echet Distance for Offline Evaluation of Information Retrieval Systems with Sparse Labels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17543
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;Fr\'echet&#36317;&#31163;&#26469;&#35780;&#20272;&#31232;&#30095;&#26631;&#31614;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#23569;&#37327;&#26631;&#31614;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;Fr\'echet&#36317;&#31163;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#20449;&#24687;&#26816;&#32034;(IR)&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#25216;&#26415;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#23545;&#35780;&#20272;&#36825;&#20123;&#31995;&#32479;&#30340;&#24615;&#33021;&#25552;&#20986;&#20102;&#26174;&#33879;&#25361;&#25112;&#12290;&#20854;&#20013;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#20154;&#24037;&#26631;&#35760;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#65292;&#36825;&#38480;&#21046;&#20102;&#23545;&#36825;&#20123;&#31995;&#32479;&#30340;&#20844;&#24179;&#21644;&#20934;&#30830;&#35780;&#20272;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#20351;&#29992;&#31232;&#30095;&#26631;&#31614;&#35780;&#20272;IR&#31995;&#32479;&#65292;&#20511;&#37492;&#20102;&#26368;&#36817;&#22312;&#35780;&#20272;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#26041;&#38754;&#30340;&#30740;&#31350;&#25104;&#26524;&#12290;&#21463;&#23558;Fr\'echet Inception Distance (FID)&#29992;&#20110;&#35780;&#20272;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#31995;&#32479;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;Fr\'echet&#36317;&#31163;&#26469;&#34913;&#37327;&#30456;&#20851;&#34987;&#21028;&#23450;&#39033;&#21644;&#26816;&#32034;&#32467;&#26524;&#30340;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#22312;MS MARCO V1&#25968;&#25454;&#38598;&#21644;TREC&#28145;&#24230;&#23398;&#20064;&#36712;&#36857;&#26597;&#35810;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;Fr\'echet&#36317;&#31163;&#20316;&#20026;&#35780;&#20272;IR&#31995;&#32479;&#30340;&#25351;&#26631;&#30340;&#26377;&#25928;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#23569;&#37327;&#26631;&#31614;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid advancement of natural language processing, information retrieval (IR), computer vision, and other technologies has presented significant challenges in evaluating the performance of these systems. One of the main challenges is the scarcity of human-labeled data, which hinders the fair and accurate assessment of these systems. In this work, we specifically focus on evaluating IR systems with sparse labels, borrowing from recent research on evaluating computer vision tasks. taking inspiration from the success of using Fr\'echet Inception Distance (FID) in assessing text-to-image generation systems. We propose leveraging the Fr\'echet Distance to measure the distance between the distributions of relevant judged items and retrieved results. Our experimental results on MS MARCO V1 dataset and TREC Deep Learning Tracks query sets demonstrate the effectiveness of the Fr\'echet Distance as a metric for evaluating IR systems, particularly in settings where a few labels are available. 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23637;&#31034;&#20102;n-gram&#35821;&#35328;&#27169;&#22411;&#30340;&#20215;&#20540;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;infini-gram&#30340;&#24341;&#25806;&#65292;&#23427;&#21487;&#20197;&#20197;&#27627;&#31186;&#32423;&#30340;&#24310;&#36831;&#35745;&#31639;&#20219;&#24847;n&#30340;n-gram&#27010;&#29575;&#65292;&#20351;&#24471;&#22312;&#31070;&#32463;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23545;&#25991;&#26412;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#20998;&#26512;&#25104;&#20026;&#21487;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.17377</link><description>&lt;p&gt;
&#26080;&#38480;-gram&#65306;&#23558;&#26080;&#38480;n-gram&#35821;&#35328;&#27169;&#22411;&#25193;&#23637;&#21040;&#19975;&#20159;&#26631;&#35760;
&lt;/p&gt;
&lt;p&gt;
Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17377
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23637;&#31034;&#20102;n-gram&#35821;&#35328;&#27169;&#22411;&#30340;&#20215;&#20540;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;infini-gram&#30340;&#24341;&#25806;&#65292;&#23427;&#21487;&#20197;&#20197;&#27627;&#31186;&#32423;&#30340;&#24310;&#36831;&#35745;&#31639;&#20219;&#24847;n&#30340;n-gram&#27010;&#29575;&#65292;&#20351;&#24471;&#22312;&#31070;&#32463;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23545;&#25991;&#26412;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#20998;&#26512;&#25104;&#20026;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26102;&#20195;&#65292;n-gram&#35821;&#35328;&#27169;&#22411;&#36824;&#20855;&#26377;&#30456;&#20851;&#24615;&#21527;&#65311;&#25105;&#20204;&#30340;&#31572;&#26696;&#26159;&#32943;&#23450;&#30340;&#65292;&#24182;&#19988;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#25991;&#26412;&#20998;&#26512;&#21644;&#25913;&#36827;&#31070;&#32463;LLM&#26041;&#38754;&#30340;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#38656;&#35201;&#22312;&#20004;&#20010;&#26041;&#38754;&#23545;n-gram&#27169;&#22411;&#36827;&#34892;&#29616;&#20195;&#21270;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#23427;&#20204;&#19982;&#31070;&#32463;LLM&#30456;&#21516;&#30340;&#25968;&#25454;&#35268;&#27169;&#35757;&#32451;- 1.4&#19975;&#20159;&#20010;&#26631;&#35760;&#12290;&#36825;&#26159;&#36804;&#20170;&#20026;&#27490;&#26500;&#24314;&#30340;&#26368;&#22823;&#30340;n-gram&#27169;&#22411;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#30340;n-gram&#27169;&#22411;&#20351;&#29992;&#30340;n&#24456;&#23567;&#65292;&#36825;&#22952;&#30861;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#65307;&#30456;&#21453;&#65292;&#25105;&#20204;&#20801;&#35768;n&#21487;&#20197;&#26159;&#20219;&#24847;&#22823;&#30340;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#26080;&#38480;-gram LM&#19982;&#22238;&#36864;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;infini-gram&#30340;&#24341;&#25806;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#21518;&#32512;&#25968;&#32452;&#35745;&#31639;&#26080;&#38480;-gram&#65288;&#20197;&#21450;&#20219;&#24847;n&#30340;n-gram&#65289;&#27010;&#29575;&#65292;&#24182;&#19988;&#20855;&#26377;&#27627;&#31186;&#32423;&#30340;&#24310;&#36831;&#65292;&#32780;&#26080;&#38656;&#39044;&#20808;&#35745;&#31639;n-gram&#35745;&#25968;&#34920;&#65288;&#36825;&#23558;&#38750;&#24120;&#26114;&#36149;&#65289;&#12290;&#26080;&#38480;-gram&#26694;&#26550;&#21644;infini-gram&#24341;&#25806;&#20351;&#25105;&#20204;&#33021;&#22815;&#23545;&#20154;&#31867;&#20889;&#20316;&#21644;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;&#36827;&#34892;&#35768;&#22810;&#26032;&#39062;&#21644;&#26377;&#24847;&#24605;&#30340;&#20998;&#26512;&#65306;&#25105;&#20204;&#21457;&#29616;&#26080;&#38480;-gram LM...
&lt;/p&gt;
&lt;p&gt;
Are n-gram language models still relevant in this era of neural large language models (LLMs)? Our answer is yes, and we show their values in both text analysis and improving neural LLMs. Yet this necessitates modernizing n-gram models in two aspects. First, we train them at the same data scale as neural LLMs -- 1.4 trillion tokens. This is the largest n-gram model ever built. Second, existing n-gram models use small n which hinders their performance; we instead allow n to be arbitrarily large, by introducing a new $\infty$-gram LM with backoff. Instead of pre-computing n-gram count tables (which would be very expensive), we develop an engine named infini-gram -- powered by suffix arrays -- that can compute $\infty$-gram (as well as n-gram with arbitrary n) probabilities with millisecond-level latency. The $\infty$-gram framework and infini-gram engine enable us to conduct many novel and interesting analyses of human-written and machine-generated text: we find that the $\infty$-gram LM 
&lt;/p&gt;</description></item><item><title>&#22312;&#35831;&#27714;&#32423;&#21035;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#26041;&#27861;&#21644;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.16108</link><description>&lt;p&gt;
&#35831;&#27714;&#32423;&#21035;&#25512;&#33616;&#20013;&#30340;&#26410;&#26469;&#24433;&#21709;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Future Impact Decomposition in Request-level Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.16108
&lt;/p&gt;
&lt;p&gt;
&#22312;&#35831;&#27714;&#32423;&#21035;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#26041;&#27861;&#21644;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#24378;&#21270;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#22312;&#20248;&#21270;&#29992;&#25143;&#21644;&#31995;&#32479;&#20043;&#38388;&#30340;&#20132;&#20114;&#24207;&#21015;&#20197;&#25552;&#39640;&#38271;&#26399;&#24615;&#33021;&#26041;&#38754;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#20986;&#20110;&#23454;&#38469;&#21407;&#22240;&#65292;&#31574;&#30053;&#30340;&#21160;&#20316;&#36890;&#24120;&#34987;&#35774;&#35745;&#20026;&#25512;&#33616;&#19968;&#32452;&#29289;&#21697;&#20197;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#29992;&#25143;&#30340;&#39057;&#32321;&#21644;&#36830;&#32493;&#30340;&#27983;&#35272;&#35831;&#27714;&#12290;&#22312;&#36825;&#31181;&#21015;&#34920;&#24335;&#25512;&#33616;&#22330;&#26223;&#20013;&#65292;&#29992;&#25143;&#29366;&#24577;&#22312;&#30456;&#24212;&#30340;MDP&#65288;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65289;&#34920;&#36848;&#20013;&#30340;&#27599;&#20010;&#35831;&#27714;&#19978;&#37117;&#20250;&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35831;&#27714;&#32423;&#21035;&#30340;&#34920;&#36848;&#19982;&#29992;&#25143;&#30340;&#29289;&#21697;&#32423;&#21035;&#34892;&#20026;&#23454;&#36136;&#19978;&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#35831;&#27714;&#32423;&#21035;MDP&#19979;&#65292;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#35831;&#27714;&#32423;&#21035;&#26041;&#27861;&#21644;&#25552;&#20986;&#30340;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#26469;&#25903;&#25345;&#36825;&#19968;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommender systems, reinforcement learning solutions have shown promising results in optimizing the interaction sequence between users and the system over the long-term performance. For practical reasons, the policy's actions are typically designed as recommending a list of items to handle users' frequent and continuous browsing requests more efficiently. In this list-wise recommendation scenario, the user state is updated upon every request in the corresponding MDP formulation. However, this request-level formulation is essentially inconsistent with the user's item-level behavior. In this study, we demonstrate that an item-level optimization approach can better utilize item characteristics and optimize the policy's performance even under the request-level MDP. We support this claim by comparing the performance of standard request-level methods with the proposed item-level actor-critic framework in both simulation and online experiments. Furthermore, we show that a reward-based fut
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#39033;&#21517;&#20026;"&#25552;&#31034;&#24615;&#33021;&#39044;&#27979;"&#30340;&#26032;&#20219;&#21153;&#65292;&#36890;&#36807;&#27979;&#37327;&#39044;&#27979;&#24615;&#33021;&#19982;&#23454;&#38469;&#24615;&#33021;&#35780;&#20998;&#20043;&#38388;&#30340;&#30456;&#20851;&#31995;&#25968;&#65292;&#23637;&#31034;&#20102;&#22312;&#22270;&#20687;&#29983;&#25104;&#20013;&#39044;&#27979;&#25552;&#31034;&#24615;&#33021;&#30340;&#33021;&#21147;&#65292;&#24182;&#26263;&#31034;&#20102;&#36825;&#19968;&#33021;&#21147;&#22312;&#20248;&#21270;&#29992;&#25143;&#25552;&#31034;&#26041;&#38754;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2306.08915</link><description>&lt;p&gt;
&#22270;&#20687;&#29983;&#25104;&#30340;&#25552;&#31034;&#24615;&#33021;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Prompt Performance Prediction for Image Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2306.08915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#39033;&#21517;&#20026;"&#25552;&#31034;&#24615;&#33021;&#39044;&#27979;"&#30340;&#26032;&#20219;&#21153;&#65292;&#36890;&#36807;&#27979;&#37327;&#39044;&#27979;&#24615;&#33021;&#19982;&#23454;&#38469;&#24615;&#33021;&#35780;&#20998;&#20043;&#38388;&#30340;&#30456;&#20851;&#31995;&#25968;&#65292;&#23637;&#31034;&#20102;&#22312;&#22270;&#20687;&#29983;&#25104;&#20013;&#39044;&#27979;&#25552;&#31034;&#24615;&#33021;&#30340;&#33021;&#21147;&#65292;&#24182;&#26263;&#31034;&#20102;&#36825;&#19968;&#33021;&#21147;&#22312;&#20248;&#21270;&#29992;&#25143;&#25552;&#31034;&#26041;&#38754;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20013;&#65292;&#22312;&#36820;&#22238;&#32467;&#26524;&#20043;&#21069;&#39044;&#27979;&#26597;&#35810;&#30340;&#24615;&#33021;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#21463;&#21040;&#36825;&#20010;&#20219;&#21153;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#24341;&#20837;&#20102;&#19968;&#39033;&#21517;&#20026;&#8220;&#25552;&#31034;&#24615;&#33021;&#39044;&#27979;&#8221;&#65288;PPP&#65289;&#30340;&#26032;&#20219;&#21153;&#65292;&#26088;&#22312;&#22312;&#33719;&#21462;&#23454;&#38469;&#29983;&#25104;&#30340;&#22270;&#20687;&#20043;&#21069;&#39044;&#27979;&#25552;&#31034;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#22312;&#21253;&#21547;&#25552;&#31034;&#21644;&#29983;&#25104;&#22270;&#20687;&#23545;&#30340;&#19977;&#20010;&#25968;&#25454;&#38598;&#20197;&#21450;&#19977;&#20010;&#30495;&#23454;&#22270;&#20687;&#21644;&#30495;&#23454;&#29992;&#25143;&#27427;&#36175;&#35780;&#20998;&#30340;&#33402;&#26415;&#39046;&#22495;&#25968;&#25454;&#38598;&#20043;&#38388;&#27979;&#37327;&#39044;&#27979;&#24615;&#33021;&#19982;&#23454;&#38469;&#24615;&#33021;&#35780;&#20998;&#20043;&#38388;&#30340;&#30456;&#20851;&#31995;&#25968;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20219;&#21153;&#30340;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#20102;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#39044;&#27979;&#33021;&#21147;&#65292;&#26263;&#31034;&#20102;&#23545;&#20248;&#21270;&#29992;&#25143;&#25552;&#31034;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to predict the performance of a query before results are returned has been a longstanding challenge in Information Retrieval (IR) systems. Inspired by this task, we introduce, in this paper, a novel task called "Prompt Performance Prediction" (PPP) that aims to predict the performance of a prompt, before obtaining the actual generated images. We demonstrate the plausibility of our task by measuring the correlation coefficient between predicted and actual performance scores across: three datasets containing pairs of prompts and generated images AND three art domain datasets of real images and real user appreciation ratings. Our results show promising performance prediction capabilities, suggesting potential applications for optimizing user prompts.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#21319;Prompt&#30340;&#32852;&#37030;&#20869;&#23481;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#38544;&#31169;&#27844;&#38706;&#21644;&#30693;&#35782;&#36716;&#31227;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.14678</link><description>&lt;p&gt;
&#25552;&#21319;Prompt&#30340;&#32852;&#37030;&#20869;&#23481;&#34920;&#31034;&#23398;&#20064;&#29992;&#20110;&#36328;&#39046;&#22495;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Prompt-enhanced Federated Content Representation Learning for Cross-domain Recommendation. (arXiv:2401.14678v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14678
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#21319;Prompt&#30340;&#32852;&#37030;&#20869;&#23481;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#38544;&#31169;&#27844;&#38706;&#21644;&#30693;&#35782;&#36716;&#31227;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#30340;&#32531;&#35299;&#65292;&#36328;&#39046;&#22495;&#25512;&#33616;&#20316;&#20026;&#26377;&#25928;&#30340;&#25216;&#26415;&#24050;&#32463;&#22312;&#36817;&#24180;&#26469;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#20043;&#21069;&#30340;&#30740;&#31350;&#24037;&#20316;&#21487;&#33021;&#20250;&#23548;&#33268;&#39046;&#22495;&#38544;&#31169;&#27844;&#38706;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#38656;&#35201;&#23558;&#21508;&#20010;&#39046;&#22495;&#30340;&#25968;&#25454;&#32858;&#21512;&#21040;&#19968;&#20010;&#20013;&#22830;&#26381;&#21153;&#22120;&#19978;&#12290;&#34429;&#28982;&#19968;&#20123;&#30740;&#31350;&#36890;&#36807;&#32852;&#37030;&#23398;&#20064;&#23545;&#38544;&#31169;&#36827;&#34892;&#20445;&#25252;&#30340;&#36328;&#39046;&#22495;&#25512;&#33616;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20294;&#20173;&#23384;&#22312;&#20197;&#19979;&#38480;&#21046;&#65306;1&#65289;&#23427;&#20204;&#38656;&#35201;&#23558;&#29992;&#25143;&#30340;&#20010;&#20154;&#20449;&#24687;&#19978;&#20256;&#21040;&#20013;&#22830;&#26381;&#21153;&#22120;&#65292;&#23384;&#22312;&#29992;&#25143;&#38544;&#31169;&#27844;&#38706;&#30340;&#39118;&#38505;&#12290;2&#65289;&#29616;&#26377;&#30340;&#32852;&#37030;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#21407;&#23376;&#39033;&#30446;ID&#26469;&#34920;&#31034;&#39033;&#30446;&#65292;&#36825;&#20351;&#23427;&#20204;&#26080;&#27861;&#22312;&#32479;&#19968;&#30340;&#29305;&#24449;&#31354;&#38388;&#20013;&#23545;&#39033;&#30446;&#36827;&#34892;&#24314;&#27169;&#65292;&#22686;&#21152;&#20102;&#39046;&#22495;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#30340;&#25361;&#25112;&#12290;3&#65289;&#23427;&#20204;&#37117;&#22522;&#20110;&#30693;&#36947;&#39046;&#22495;&#20043;&#38388;&#37325;&#21472;&#29992;&#25143;&#30340;&#21069;&#25552;&#65292;&#36825;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38480;&#21046;&#65292;&#25105;&#20204;&#30528;&#30524;&#20110;&#38544;&#31169;&#20445;&#25252;&#36328;&#39046;&#22495;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-domain Recommendation (CDR) as one of the effective techniques in alleviating the data sparsity issues has been widely studied in recent years. However, previous works may cause domain privacy leakage since they necessitate the aggregation of diverse domain data into a centralized server during the training process. Though several studies have conducted privacy preserving CDR via Federated Learning (FL), they still have the following limitations: 1) They need to upload users' personal information to the central server, posing the risk of leaking user privacy. 2) Existing federated methods mainly rely on atomic item IDs to represent items, which prevents them from modeling items in a unified feature space, increasing the challenge of knowledge transfer among domains. 3) They are all based on the premise of knowing overlapped users between domains, which proves impractical in real-world applications. To address the above limitations, we focus on Privacy-preserving Cross-domain Reco
&lt;/p&gt;</description></item><item><title>Ada-Retrieval&#26159;&#19968;&#31181;&#36866;&#24212;&#24615;&#22810;&#36718;&#26816;&#32034;&#33539;&#20363;&#65292;&#29992;&#20110;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#29289;&#21697;&#20505;&#36873;&#32773;&#36873;&#25321;&#36807;&#31243;&#12290;&#23427;&#36890;&#36807;&#36845;&#20195;&#22320;&#25913;&#36827;&#29992;&#25143;&#34920;&#31034;&#26469;&#26356;&#22909;&#22320;&#25429;&#25417;&#23436;&#25972;&#30340;&#29289;&#21697;&#31354;&#38388;&#20013;&#30340;&#28508;&#22312;&#20505;&#36873;&#32773;&#65292;&#24182;&#20855;&#26377;&#27169;&#22411;&#26080;&#20851;&#30340;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2401.06633</link><description>&lt;p&gt;
Ada-Retrieval&#65306;&#36866;&#24212;&#24615;&#22810;&#36718;&#26816;&#32034;&#33539;&#20363;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential Recommendations. (arXiv:2401.06633v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06633
&lt;/p&gt;
&lt;p&gt;
Ada-Retrieval&#26159;&#19968;&#31181;&#36866;&#24212;&#24615;&#22810;&#36718;&#26816;&#32034;&#33539;&#20363;&#65292;&#29992;&#20110;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#29289;&#21697;&#20505;&#36873;&#32773;&#36873;&#25321;&#36807;&#31243;&#12290;&#23427;&#36890;&#36807;&#36845;&#20195;&#22320;&#25913;&#36827;&#29992;&#25143;&#34920;&#31034;&#26469;&#26356;&#22909;&#22320;&#25429;&#25417;&#23436;&#25972;&#30340;&#29289;&#21697;&#31354;&#38388;&#20013;&#30340;&#28508;&#22312;&#20505;&#36873;&#32773;&#65292;&#24182;&#20855;&#26377;&#27169;&#22411;&#26080;&#20851;&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#27169;&#22411;&#26088;&#22312;&#36873;&#25321;&#19982;&#32473;&#23450;&#29992;&#25143;&#20559;&#22909;&#21305;&#37197;&#30340;&#19968;&#23567;&#32452;&#29289;&#21697;&#20505;&#36873;&#32773;&#12290;&#23427;&#20204;&#22312;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#22240;&#20026;&#21518;&#32493;&#30340;&#27169;&#22411;&#65288;&#22914;&#25490;&#21517;&#22120;&#65289;&#39640;&#24230;&#20381;&#36182;&#20110;&#29289;&#21697;&#20505;&#36873;&#32773;&#30340;&#36136;&#37327;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26816;&#32034;&#27169;&#22411;&#37319;&#29992;&#21333;&#36718;&#25512;&#29702;&#33539;&#20363;&#65292;&#21487;&#33021;&#26080;&#27861;&#20805;&#20998;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#30340;&#21160;&#24577;&#24615;&#24182;&#22266;&#23450;&#22312;&#29289;&#21697;&#31354;&#38388;&#30340;&#26576;&#20010;&#21306;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Ada-Retrieval&#65292;&#19968;&#31181;&#36866;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#33258;&#36866;&#24212;&#22810;&#36718;&#26816;&#32034;&#33539;&#20363;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#25913;&#36827;&#29992;&#25143;&#34920;&#31034;&#26469;&#26356;&#22909;&#22320;&#25429;&#25417;&#23436;&#25972;&#30340;&#29289;&#21697;&#31354;&#38388;&#20013;&#30340;&#28508;&#22312;&#20505;&#36873;&#32773;&#12290;Ada-Retrieval&#21253;&#21547;&#20004;&#20010;&#20851;&#38190;&#27169;&#22359;&#65306;&#29289;&#21697;&#34920;&#31034;&#36866;&#37197;&#22120;&#21644;&#29992;&#25143;&#34920;&#31034;&#36866;&#37197;&#22120;&#65292;&#26088;&#22312;&#23558;&#19978;&#19979;&#25991;&#20449;&#24687;&#27880;&#20837;&#29289;&#21697;&#21644;&#29992;&#25143;&#30340;&#34920;&#31034;&#20013;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#27169;&#22411;&#26080;&#20851;&#30340;&#35774;&#35745;&#65292;&#21487;&#20197;&#19982;&#21508;&#31181;&#22522;&#30784;&#27169;&#22411;&#65288;&#22914;RNN&#25110;Transformer&#65289;&#26080;&#32541;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval models aim at selecting a small set of item candidates which match the preference of a given user. They play a vital role in large-scale recommender systems since subsequent models such as rankers highly depend on the quality of item candidates. However, most existing retrieval models employ a single-round inference paradigm, which may not adequately capture the dynamic nature of user preferences and stuck in one area in the item space. In this paper, we propose Ada-Retrieval, an adaptive multi-round retrieval paradigm for recommender systems that iteratively refines user representations to better capture potential candidates in the full item space. Ada-Retrieval comprises two key modules: the item representation adapter and the user representation adapter, designed to inject context information into items' and users' representations. The framework maintains a model-agnostic design, allowing seamless integration with various backbone models such as RNNs or Transformers. We pe
&lt;/p&gt;</description></item></channel></rss>