<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26102;&#38388;&#22270;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#20840;&#23616;&#26102;&#38388;&#21160;&#24577;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;"&#26368;&#36817;&#27969;&#34892;&#33410;&#28857;"&#30340;&#22522;&#32447;&#26041;&#27861;&#65292;&#22312;&#26102;&#38388;&#22270;&#22522;&#20934;&#30340;&#20013;&#31561;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#32988;&#36807;&#20854;&#20182;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#24230;&#37327;&#26469;&#37327;&#21270;&#20840;&#23616;&#21160;&#24577;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;&#30340;&#36127;&#37319;&#26679;&#35780;&#20272;&#26041;&#27861;&#22312;&#20855;&#26377;&#24378;&#28872;&#26102;&#38388;&#21160;&#24577;&#30340;&#25968;&#25454;&#38598;&#19978;&#21487;&#33021;&#19981;&#36866;&#29992;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#31616;&#21333;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#36864;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#36127;&#37319;&#26679;&#26041;&#26696;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36824;&#23558;&#20854;&#19982;&#26080;&#36127;&#37319;&#26679;&#30340;&#38750;&#23545;&#27604;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2309.15730</link><description>&lt;p&gt;
&#26102;&#38388;&#22270;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#20840;&#23616;&#26102;&#38388;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Temporal graph models fail to capture global temporal dynamics. (arXiv:2309.15730v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15730
&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#22270;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#20840;&#23616;&#26102;&#38388;&#21160;&#24577;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;"&#26368;&#36817;&#27969;&#34892;&#33410;&#28857;"&#30340;&#22522;&#32447;&#26041;&#27861;&#65292;&#22312;&#26102;&#38388;&#22270;&#22522;&#20934;&#30340;&#20013;&#31561;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#32988;&#36807;&#20854;&#20182;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#24230;&#37327;&#26469;&#37327;&#21270;&#20840;&#23616;&#21160;&#24577;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;&#30340;&#36127;&#37319;&#26679;&#35780;&#20272;&#26041;&#27861;&#22312;&#20855;&#26377;&#24378;&#28872;&#26102;&#38388;&#21160;&#24577;&#30340;&#25968;&#25454;&#38598;&#19978;&#21487;&#33021;&#19981;&#36866;&#29992;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#31616;&#21333;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#36864;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#36127;&#37319;&#26679;&#26041;&#26696;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36824;&#23558;&#20854;&#19982;&#26080;&#36127;&#37319;&#26679;&#30340;&#38750;&#23545;&#27604;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21160;&#24577;&#38142;&#25509;&#23646;&#24615;&#39044;&#27979;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#26368;&#36817;&#21457;&#24067;&#30340;&#26102;&#38388;&#22270;&#22522;&#20934;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;"&#26368;&#36817;&#27969;&#34892;&#33410;&#28857;"&#30340;&#22522;&#32447;&#26041;&#27861;&#65292;&#22312;&#26102;&#38388;&#22270;&#22522;&#20934;&#30340;&#20013;&#31561;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#32988;&#36807;&#20854;&#20182;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#20004;&#20010;&#24230;&#37327;&#65292;&#21487;&#20197;&#37327;&#21270;&#25968;&#25454;&#38598;&#30340;&#30701;&#26399;&#21644;&#38271;&#26399;&#20840;&#23616;&#21160;&#24577;&#30340;&#24378;&#24230;&#12290;&#36890;&#36807;&#20998;&#26512;&#25105;&#20204;&#20986;&#20046;&#24847;&#26009;&#30340;&#24378;&#22823;&#22522;&#32447;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;&#30340;&#36127;&#37319;&#26679;&#35780;&#20272;&#26041;&#27861;&#22312;&#20855;&#26377;&#24378;&#28872;&#26102;&#38388;&#21160;&#24577;&#30340;&#25968;&#25454;&#38598;&#19978;&#21487;&#33021;&#19981;&#36866;&#29992;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#31616;&#21333;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#36864;&#21270;&#65292;&#23548;&#33268;&#26080;&#27861;&#23545;&#26102;&#38388;&#22270;&#32593;&#32476;&#36827;&#34892;&#25490;&#24207;&#30340;&#39044;&#27979;&#23436;&#20840;&#39281;&#21644;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#36127;&#37319;&#26679;&#26041;&#26696;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36824;&#23558;&#20854;&#19982;&#26080;&#36127;&#37319;&#26679;&#30340;&#38750;&#23545;&#27604;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;...
&lt;/p&gt;
&lt;p&gt;
A recently released Temporal Graph Benchmark is analyzed in the context of Dynamic Link Property Prediction. We outline our observations and propose a trivial optimization-free baseline of "recently popular nodes" outperforming other methods on all medium and large-size datasets in the Temporal Graph Benchmark. We propose two measures based on Wasserstein distance which can quantify the strength of short-term and long-term global dynamics of datasets. By analyzing our unexpectedly strong baseline, we show how standard negative sampling evaluation can be unsuitable for datasets with strong temporal dynamics. We also show how simple negative-sampling can lead to model degeneration during training, resulting in impossible to rank, fully saturated predictions of temporal graph networks. We propose improved negative sampling schemes for both training and evaluation and prove their usefulness. We conduct a comparison with a model trained non-contrastively without negative sampling. Our resul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20919;&#21551;&#21160;&#21644;&#28909;&#21551;&#21160;&#32593;&#32476;&#30340;&#26041;&#27861;(Cold &amp; Warm Net)&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20919;&#21551;&#21160;&#29992;&#25143;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#19987;&#23478;&#27169;&#22411;&#20998;&#21035;&#24314;&#27169;&#20919;&#21551;&#21160;&#21644;&#28909;&#21551;&#21160;&#29992;&#25143;&#65292;&#24182;&#24341;&#20837;&#38376;&#25511;&#32593;&#32476;&#21644;&#21160;&#24577;&#30693;&#35782;&#33976;&#39311;&#26469;&#25552;&#39640;&#29992;&#25143;&#34920;&#31034;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#36890;&#36807;&#36873;&#25321;&#19982;&#29992;&#25143;&#34892;&#20026;&#39640;&#24230;&#30456;&#20851;&#30340;&#29305;&#24449;&#65292;&#24182;&#24314;&#31435;&#20559;&#24046;&#32593;&#32476;&#26469;&#26174;&#24335;&#24314;&#27169;&#29992;&#25143;&#34892;&#20026;&#20559;&#24046;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.15646</link><description>&lt;p&gt;
&#20919;&#21551;&#21160;&#21644;&#28909;&#21551;&#21160;&#32593;&#32476;&#65306;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20919;&#21551;&#21160;&#29992;&#25143;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Cold &amp; Warm Net: Addressing Cold-Start Users in Recommender Systems. (arXiv:2309.15646v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20919;&#21551;&#21160;&#21644;&#28909;&#21551;&#21160;&#32593;&#32476;&#30340;&#26041;&#27861;(Cold &amp; Warm Net)&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20919;&#21551;&#21160;&#29992;&#25143;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#19987;&#23478;&#27169;&#22411;&#20998;&#21035;&#24314;&#27169;&#20919;&#21551;&#21160;&#21644;&#28909;&#21551;&#21160;&#29992;&#25143;&#65292;&#24182;&#24341;&#20837;&#38376;&#25511;&#32593;&#32476;&#21644;&#21160;&#24577;&#30693;&#35782;&#33976;&#39311;&#26469;&#25552;&#39640;&#29992;&#25143;&#34920;&#31034;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#36890;&#36807;&#36873;&#25321;&#19982;&#29992;&#25143;&#34892;&#20026;&#39640;&#24230;&#30456;&#20851;&#30340;&#29305;&#24449;&#65292;&#24182;&#24314;&#31435;&#20559;&#24046;&#32593;&#32476;&#26469;&#26174;&#24335;&#24314;&#27169;&#29992;&#25143;&#34892;&#20026;&#20559;&#24046;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20919;&#21551;&#21160;&#25512;&#33616;&#26159;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30340;&#37325;&#22823;&#25361;&#25112;&#20043;&#19968;&#12290;&#26412;&#25991;&#20027;&#35201;&#20851;&#27880;&#29992;&#25143;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;&#26368;&#36817;&#65292;&#20351;&#29992;&#20391;&#20449;&#24687;&#25110;&#20803;&#23398;&#20064;&#30340;&#26041;&#27861;&#34987;&#29992;&#26469;&#24314;&#27169;&#20919;&#21551;&#21160;&#29992;&#25143;&#12290;&#28982;&#32780;&#65292;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#24037;&#19994;&#32423;&#25512;&#33616;&#31995;&#32479;&#20173;&#28982;&#23384;&#22312;&#22256;&#38590;&#12290;&#30446;&#21069;&#23545;&#20110;&#21305;&#37197;&#38454;&#27573;&#20013;&#30340;&#29992;&#25143;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#30740;&#31350;&#36824;&#19981;&#22810;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#19987;&#23478;&#27169;&#22411;&#30340;&#20919;&#21551;&#21160;&#21644;&#28909;&#21551;&#21160;&#29992;&#25143;&#24314;&#27169;&#26041;&#27861;&#65306;Cold &amp; Warm Net&#12290;&#36890;&#36807;&#24341;&#20837;&#38376;&#25511;&#32593;&#32476;&#26469;&#32467;&#21512;&#20004;&#20010;&#19987;&#23478;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#36824;&#24341;&#20837;&#20102;&#21160;&#24577;&#30693;&#35782;&#33976;&#39311;&#20316;&#20026;&#19968;&#20010;&#25945;&#24072;&#36873;&#25321;&#22120;&#65292;&#24110;&#21161;&#19987;&#23478;&#26356;&#22909;&#22320;&#23398;&#20064;&#29992;&#25143;&#34920;&#31034;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#20114;&#20449;&#24687;&#36873;&#25321;&#19982;&#29992;&#25143;&#34892;&#20026;&#39640;&#24230;&#30456;&#20851;&#30340;&#29305;&#24449;&#65292;&#29992;&#20110;&#26174;&#24335;&#24314;&#27169;&#29992;&#25143;&#34892;&#20026;&#20559;&#24046;&#30340;&#20559;&#24046;&#32593;&#32476;&#12290;&#26368;&#21518;&#65292;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#23545;Cold &amp; Warm Net&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cold-start recommendation is one of the major challenges faced by recommender systems (RS). Herein, we focus on the user cold-start problem. Recently, methods utilizing side information or meta-learning have been used to model cold-start users. However, it is difficult to deploy these methods to industrial RS. There has not been much research that pays attention to the user cold-start problem in the matching stage. In this paper, we propose Cold &amp; Warm Net based on expert models who are responsible for modeling cold-start and warm-up users respectively. A gate network is applied to incorporate the results from two experts. Furthermore, dynamic knowledge distillation acting as a teacher selector is introduced to assist experts in better learning user representation. With comprehensive mutual information, features highly relevant to user behavior are selected for the bias net which explicitly models user behavior bias. Finally, we evaluate our Cold &amp; Warm Net on public datasets in compar
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25581;&#31034;&#22312;&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#20013;&#65292;&#24403;&#28857;&#20987;&#25968;&#25454;&#19981;&#33021;&#23436;&#20840;&#25311;&#21512;&#26102;&#65292;&#26080;&#27861;&#24674;&#22797;&#30495;&#23454;&#30456;&#20851;&#24615;&#65292;&#23548;&#33268;&#25490;&#21517;&#24615;&#33021;&#26174;&#33879;&#38477;&#20302;&#65292;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#22270;&#27169;&#22411;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2309.15560</link><description>&lt;p&gt;
&#35782;&#21035;&#24615;&#24456;&#37325;&#35201;&#65306;&#25581;&#31034;&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#20013;&#38544;&#34255;&#30340;&#21487;&#24674;&#22797;&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;
Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank. (arXiv:2309.15560v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15560
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25581;&#31034;&#22312;&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;&#20013;&#65292;&#24403;&#28857;&#20987;&#25968;&#25454;&#19981;&#33021;&#23436;&#20840;&#25311;&#21512;&#26102;&#65292;&#26080;&#27861;&#24674;&#22797;&#30495;&#23454;&#30456;&#20851;&#24615;&#65292;&#23548;&#33268;&#25490;&#21517;&#24615;&#33021;&#26174;&#33879;&#38477;&#20302;&#65292;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#22270;&#27169;&#22411;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#20559;&#23398;&#20064;&#25490;&#21517;(Unbiased Learning to Rank, ULTR)&#22312;&#20174;&#26377;&#20559;&#28857;&#20987;&#26085;&#24535;&#35757;&#32451;&#26080;&#20559;&#25490;&#21517;&#27169;&#22411;&#30340;&#29616;&#20195;&#31995;&#32479;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#20851;&#38190;&#22312;&#20110;&#26126;&#30830;&#22320;&#24314;&#27169;&#29992;&#25143;&#34892;&#20026;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#24182;&#22522;&#20110;&#26816;&#39564;&#20551;&#35774;&#23545;&#28857;&#20987;&#25968;&#25454;&#36827;&#34892;&#25311;&#21512;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#32463;&#39564;&#24615;&#22320;&#21457;&#29616;&#21482;&#35201;&#28857;&#20987;&#23436;&#20840;&#25311;&#21512;&#65292;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#21487;&#20197;&#24674;&#22797;&#20986;&#30495;&#23454;&#28508;&#22312;&#30456;&#20851;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#24182;&#38750;&#24635;&#26159;&#33021;&#22815;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#20174;&#32780;&#23548;&#33268;&#25490;&#21517;&#24615;&#33021;&#26174;&#33879;&#38477;&#20302;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#22238;&#31572;&#30495;&#23454;&#30456;&#20851;&#24615;&#26159;&#21542;&#33021;&#22815;&#20174;&#28857;&#20987;&#25968;&#25454;&#24674;&#22797;&#20986;&#26469;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;ULTR&#39046;&#22495;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#19968;&#20010;&#25490;&#21517;&#27169;&#22411;&#23450;&#20041;&#20026;&#21487;&#35782;&#21035;&#30340;&#65292;&#22914;&#26524;&#23427;&#21487;&#20197;&#24674;&#22797;&#20986;&#30495;&#23454;&#30456;&#20851;&#24615;&#65292;&#26368;&#22810;&#21482;&#26377;&#19968;&#20010;&#32553;&#25918;&#21464;&#25442;&#65292;&#36825;&#23545;&#20110;&#25104;&#23545;&#25490;&#21517;&#30446;&#26631;&#26469;&#35828;&#24050;&#36275;&#22815;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#19968;&#20010;&#31561;&#20215;&#30340;&#21487;&#35782;&#21035;&#26465;&#20214;&#65292;&#21487;&#20197;&#26032;&#39062;&#22320;&#34920;&#36798;&#20026;&#19968;&#20010;&#22270;&#36830;&#36890;&#24615;&#27979;&#35797;&#38382;&#39064;&#65306;&#24403;&#19988;&#20165;&#24403;&#19968;&#20010;&#22270;&#65288;&#21363;&#21487;&#35782;&#21035;&#24615;&#22270;&#65289;&#36830;&#36890;&#26102;&#65292;&#35813;&#25490;&#21517;&#27169;&#22411;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The application of Unbiased Learning to Rank (ULTR) is widespread in modern systems for training unbiased ranking models from biased click logs. The key is to explicitly model a generation process for user behavior and fit click data based on examination hypothesis. Previous research found empirically that the true latent relevance can be recovered in most cases as long as the clicks are perfectly fitted. However, we demonstrate that this is not always achievable, resulting in a significant reduction in ranking performance. In this work, we aim to answer if or when the true relevance can be recovered from click data, which is a foundation issue for ULTR field. We first define a ranking model as identifiable if it can recover the true relevance up to a scaling transformation, which is enough for pairwise ranking objective. Then we explore an equivalent condition for identifiability that can be novely expressed as a graph connectivity test problem: if and only if a graph (namely identifi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#25163;&#35757;&#32451;&#23454;&#29616;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29305;&#24449;&#20844;&#24179;&#24615;&#65292;&#25552;&#39640;&#25972;&#20307;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;</title><link>http://arxiv.org/abs/2309.15418</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#25163;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29305;&#24449;&#20844;&#24179;&#24615;&#30340;&#33258;&#21160;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Automatic Feature Fairness in Recommendation via Adversaries. (arXiv:2309.15418v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15418
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#25163;&#35757;&#32451;&#23454;&#29616;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29305;&#24449;&#20844;&#24179;&#24615;&#65292;&#25552;&#39640;&#25972;&#20307;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#24179;&#24615;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#24191;&#27867;&#35752;&#35770;&#30340;&#19968;&#20010;&#20027;&#39064;&#65292;&#20294;&#20854;&#23454;&#36341;&#23454;&#29616;&#22312;&#23450;&#20041;&#25935;&#24863;&#29305;&#24449;&#30340;&#21516;&#26102;&#20445;&#25345;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#23558;&#29305;&#24449;&#20844;&#24179;&#24615;&#20316;&#20026;&#23454;&#29616;&#21508;&#20010;&#30001;&#19981;&#21516;&#29305;&#24449;&#32452;&#21512;&#23450;&#20041;&#30340;&#22810;&#26679;&#32676;&#20307;&#20043;&#38388;&#30340;&#20844;&#24179;&#24453;&#36935;&#30340;&#22522;&#30784;&#12290;&#36890;&#36807;&#24179;&#34913;&#29305;&#24449;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21487;&#20197;&#25552;&#39640;&#25972;&#20307;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#25163;&#35757;&#32451;&#24341;&#20837;&#20102;&#26080;&#20559;&#29305;&#24449;&#23398;&#20064;&#65292;&#20351;&#29992;&#23545;&#25163;&#25200;&#21160;&#22686;&#24378;&#29305;&#24449;&#34920;&#31034;&#12290;&#23545;&#25163;&#25913;&#36827;&#20102;&#27169;&#22411;&#23545;&#23569;&#25968;&#29305;&#24449;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#26681;&#25454;&#29305;&#24449;&#20559;&#24046;&#30340;&#20004;&#31181;&#24418;&#24335;&#33258;&#21160;&#36866;&#24212;&#23545;&#25163;&#65306;&#29305;&#24449;&#20540;&#30340;&#39057;&#29575;&#21644;&#32452;&#21512;&#22810;&#26679;&#24615;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#21160;&#24577;&#35843;&#25972;&#25200;&#21160;&#24378;&#24230;&#21644;&#23545;&#25163;&#35757;&#32451;&#26435;&#37325;&#12290;&#26356;&#24378;&#30340;&#25200;&#21160;&#36866;&#29992;&#20110;&#32452;&#21512;&#21464;&#21270;&#23569;&#30340;&#29305;&#24449;&#20540;&#65292;&#20197;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#23545;&#20110;&#20302;&#39057;&#29305;&#24449;&#65292;&#36739;&#39640;&#30340;&#26435;&#37325;&#21487;&#20197;&#35299;&#20915;...
&lt;/p&gt;
&lt;p&gt;
Fairness is a widely discussed topic in recommender systems, but its practical implementation faces challenges in defining sensitive features while maintaining recommendation accuracy. We propose feature fairness as the foundation to achieve equitable treatment across diverse groups defined by various feature combinations. This improves overall accuracy through balanced feature generalizability. We introduce unbiased feature learning through adversarial training, using adversarial perturbation to enhance feature representation. The adversaries improve model generalization for under-represented features. We adapt adversaries automatically based on two forms of feature biases: frequency and combination variety of feature values. This allows us to dynamically adjust perturbation strengths and adversarial training weights. Stronger perturbations are applied to feature values with fewer combination varieties to improve generalization, while higher weights for low-frequency features address 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20165;&#20351;&#29992;&#21387;&#32553;&#34920;&#31034;&#26469;&#24674;&#22797;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#31526;&#21495;&#30340;&#39057;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#23558;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#35770;&#35266;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#36824;&#25193;&#23637;&#20102;&#35813;&#26041;&#27861;&#20197;&#35299;&#20915;&#22522;&#25968;&#24674;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.15408</link><description>&lt;p&gt;
&#20174;&#21387;&#32553;&#25968;&#25454;&#20013;&#24674;&#22797;&#39057;&#29575;&#21644;&#22522;&#25968;&#65306;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#35770;&#35266;&#28857;&#36830;&#25509;&#36215;&#26469;&#30340;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Frequency and cardinality recovery from sketched data: a novel approach bridging Bayesian and frequentist views. (arXiv:2309.15408v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15408
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20165;&#20351;&#29992;&#21387;&#32553;&#34920;&#31034;&#26469;&#24674;&#22797;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#31526;&#21495;&#30340;&#39057;&#29575;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#23558;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#35770;&#35266;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#36824;&#25193;&#23637;&#20102;&#35813;&#26041;&#27861;&#20197;&#35299;&#20915;&#22522;&#25968;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#20165;&#20351;&#29992;&#36890;&#36807;&#38543;&#26426;&#21704;&#24076;&#33719;&#24471;&#30340;&#23545;&#25968;&#25454;&#36827;&#34892;&#21387;&#32553;&#34920;&#31034;&#25110;&#33609;&#22270;&#26469;&#24674;&#22797;&#22823;&#35268;&#27169;&#31163;&#25955;&#25968;&#25454;&#38598;&#20013;&#31526;&#21495;&#30340;&#39057;&#29575;&#12290;&#36825;&#26159;&#19968;&#20010;&#22312;&#35745;&#31639;&#26426;&#31185;&#23398;&#20013;&#30340;&#32463;&#20856;&#38382;&#39064;&#65292;&#26377;&#21508;&#31181;&#31639;&#27861;&#21487;&#29992;&#65292;&#22914;&#35745;&#25968;&#26368;&#23567;&#33609;&#22270;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#20551;&#35774;&#25968;&#25454;&#26159;&#22266;&#23450;&#30340;&#65292;&#22788;&#29702;&#38543;&#26426;&#37319;&#26679;&#25968;&#25454;&#26102;&#20272;&#35745;&#36807;&#20110;&#20445;&#23432;&#19988;&#21487;&#33021;&#19981;&#20934;&#30830;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#33609;&#22270;&#25968;&#25454;&#35270;&#20026;&#26410;&#30693;&#20998;&#24067;&#30340;&#38543;&#26426;&#26679;&#26412;&#65292;&#28982;&#21518;&#24341;&#20837;&#25913;&#36827;&#29616;&#26377;&#26041;&#27861;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#21644;&#32463;&#20856;&#65288;&#39057;&#29575;&#35770;&#65289;&#35266;&#28857;&#65292;&#35299;&#20915;&#20102;&#23427;&#20204;&#29420;&#29305;&#30340;&#38480;&#21046;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21407;&#21017;&#19988;&#23454;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20197;&#35299;&#20915;&#30456;&#20851;&#20294;&#19981;&#21516;&#30340;&#22522;&#25968;&#24674;&#22797;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#28041;&#21450;&#20272;&#35745;&#25968;&#25454;&#38598;&#20013;&#19981;&#21516;&#23545;&#35937;&#30340;&#24635;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how to recover the frequency of a symbol in a large discrete data set, using only a compressed representation, or sketch, of those data obtained via random hashing. This is a classical problem in computer science, with various algorithms available, such as the count-min sketch. However, these algorithms often assume that the data are fixed, leading to overly conservative and potentially inaccurate estimates when dealing with randomly sampled data. In this paper, we consider the sketched data as a random sample from an unknown distribution, and then we introduce novel estimators that improve upon existing approaches. Our method combines Bayesian nonparametric and classical (frequentist) perspectives, addressing their unique limitations to provide a principled and practical solution. Additionally, we extend our method to address the related but distinct problem of cardinality recovery, which consists of estimating the total number of distinct objects in the data set. We validate
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;"MicroLens"&#30340;&#22823;&#35268;&#27169;&#24494;&#35270;&#39057;&#25512;&#33616;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21313;&#20159;&#20010;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#34892;&#20026;&#21644;&#21508;&#31181;&#21407;&#22987;&#27169;&#24577;&#20449;&#24687;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20869;&#23481;&#39537;&#21160;&#30340;&#24494;&#35270;&#39057;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#20102;&#22522;&#20934;&#12290;</title><link>http://arxiv.org/abs/2309.15379</link><description>&lt;p&gt;
&#19968;&#20010;&#35268;&#27169;&#24222;&#22823;&#30340;&#20869;&#23481;&#39537;&#21160;&#30340;&#24494;&#35270;&#39057;&#25512;&#33616;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
A Content-Driven Micro-Video Recommendation Dataset at Scale. (arXiv:2309.15379v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15379
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;"MicroLens"&#30340;&#22823;&#35268;&#27169;&#24494;&#35270;&#39057;&#25512;&#33616;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21313;&#20159;&#20010;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#34892;&#20026;&#21644;&#21508;&#31181;&#21407;&#22987;&#27169;&#24577;&#20449;&#24687;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20869;&#23481;&#39537;&#21160;&#30340;&#24494;&#35270;&#39057;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#20102;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#35270;&#39057;&#26368;&#36817;&#21464;&#24471;&#38750;&#24120;&#21463;&#27426;&#36814;&#65292;&#24341;&#21457;&#20102;&#23545;&#24494;&#35270;&#39057;&#25512;&#33616;&#30340;&#37325;&#35201;&#30740;&#31350;&#65292;&#23545;&#23089;&#20048;&#12289;&#24191;&#21578;&#21644;&#30005;&#23376;&#21830;&#21153;&#34892;&#19994;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#22823;&#35268;&#27169;&#30340;&#20844;&#20849;&#24494;&#35270;&#39057;&#25968;&#25454;&#38598;&#20026;&#24320;&#21457;&#26377;&#25928;&#30340;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#20102;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#38750;&#24120;&#24222;&#22823;&#30340;&#24494;&#35270;&#39057;&#25512;&#33616;&#25968;&#25454;&#38598;&#65292;&#21517;&#20026;"MicroLens"&#65292;&#21253;&#25324;&#21313;&#20159;&#20010;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#34892;&#20026;&#65292;3400&#19975;&#20010;&#29992;&#25143;&#21644;100&#19975;&#20010;&#24494;&#35270;&#39057;&#12290;&#35813;&#25968;&#25454;&#38598;&#36824;&#21253;&#21547;&#26377;&#20851;&#35270;&#39057;&#30340;&#21508;&#31181;&#21407;&#22987;&#27169;&#24577;&#20449;&#24687;&#65292;&#21253;&#25324;&#26631;&#39064;&#12289;&#23553;&#38754;&#22270;&#20687;&#12289;&#38899;&#39057;&#21644;&#23436;&#25972;&#35270;&#39057;&#12290;MicroLens&#20316;&#20026;&#20869;&#23481;&#39537;&#21160;&#30340;&#24494;&#35270;&#39057;&#25512;&#33616;&#30340;&#22522;&#20934;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#21033;&#29992;&#21508;&#31181;&#35270;&#39057;&#20449;&#24687;&#30340;&#27169;&#24577;&#36827;&#34892;&#25512;&#33616;&#65292;&#32780;&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#39033;&#30446;ID&#25110;&#20174;&#39044;&#35757;&#32451;&#32593;&#32476;&#20013;&#25552;&#21462;&#30340;&#29616;&#25104;&#35270;&#39057;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Micro-videos have recently gained immense popularity, sparking critical research in micro-video recommendation with significant implications for the entertainment, advertising, and e-commerce industries. However, the lack of large-scale public micro-video datasets poses a major challenge for developing effective recommender systems. To address this challenge, we introduce a very large micro-video recommendation dataset, named "MicroLens", consisting of one billion user-item interaction behaviors, 34 million users, and one million micro-videos. This dataset also contains various raw modality information about videos, including titles, cover images, audio, and full-length videos. MicroLens serves as a benchmark for content-driven micro-video recommendation, enabling researchers to utilize various modalities of video information for recommendation, rather than relying solely on item IDs or off-the-shelf video features extracted from a pre-trained network. Our benchmarking of multiple reco
&lt;/p&gt;</description></item><item><title>LD4MRec&#26159;&#19968;&#31181;&#31616;&#21270;&#21644;&#21152;&#24378;&#22810;&#23186;&#20307;&#25512;&#33616;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#34892;&#20026;&#25968;&#25454;&#22122;&#22768;&#23545;&#25512;&#33616;&#24615;&#33021;&#30340;&#36127;&#38754;&#24433;&#21709;&#12289;&#32463;&#20856;&#25193;&#25955;&#27169;&#22411;&#35745;&#31639;&#37327;&#36807;&#22823;&#20197;&#21450;&#29616;&#26377;&#21453;&#21521;&#36807;&#31243;&#19981;&#36866;&#29992;&#20110;&#31163;&#25955;&#34892;&#20026;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.15363</link><description>&lt;p&gt;
LD4MRec:&#31616;&#21270;&#21644;&#21152;&#24378;&#22810;&#23186;&#20307;&#25512;&#33616;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LD4MRec: Simplifying and Powering Diffusion Model for Multimedia Recommendation. (arXiv:2309.15363v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15363
&lt;/p&gt;
&lt;p&gt;
LD4MRec&#26159;&#19968;&#31181;&#31616;&#21270;&#21644;&#21152;&#24378;&#22810;&#23186;&#20307;&#25512;&#33616;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#34892;&#20026;&#25968;&#25454;&#22122;&#22768;&#23545;&#25512;&#33616;&#24615;&#33021;&#30340;&#36127;&#38754;&#24433;&#21709;&#12289;&#32463;&#20856;&#25193;&#25955;&#27169;&#22411;&#35745;&#31639;&#37327;&#36807;&#22823;&#20197;&#21450;&#29616;&#26377;&#21453;&#21521;&#36807;&#31243;&#19981;&#36866;&#29992;&#20110;&#31163;&#25955;&#34892;&#20026;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23186;&#20307;&#25512;&#33616;&#26088;&#22312;&#26681;&#25454;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#21644;&#39033;&#30446;&#30340;&#22810;&#27169;&#24577;&#20449;&#24687;&#39044;&#27979;&#29992;&#25143;&#30340;&#26410;&#26469;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#34892;&#20026;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#65292;&#20135;&#29983;&#20110;&#19982;&#19981;&#24863;&#20852;&#36259;&#30340;&#39033;&#30446;&#30340;&#38750;&#39044;&#26399;&#29992;&#25143;&#20132;&#20114;&#65292;&#23545;&#25512;&#33616;&#24615;&#33021;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#26368;&#36817;&#65292;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#20102;&#39640;&#36136;&#37327;&#30340;&#20449;&#24687;&#29983;&#25104;&#65292;&#20854;&#20013;&#21453;&#21521;&#36807;&#31243;&#26681;&#25454;&#21463;&#25439;&#29366;&#24577;&#36845;&#20195;&#22320;&#25512;&#26029;&#26410;&#26469;&#20449;&#24687;&#12290;&#23427;&#28385;&#36275;&#20102;&#22312;&#22024;&#26434;&#26465;&#20214;&#19979;&#30340;&#39044;&#27979;&#20219;&#21153;&#38656;&#27714;&#65292;&#24182;&#28608;&#21457;&#20102;&#23545;&#20854;&#22312;&#39044;&#27979;&#29992;&#25143;&#34892;&#20026;&#26041;&#38754;&#30340;&#24212;&#29992;&#30340;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#36824;&#38656;&#35201;&#35299;&#20915;&#20960;&#20010;&#25361;&#25112;&#65306;1&#65289;&#32463;&#20856;&#25193;&#25955;&#27169;&#22411;&#38656;&#35201;&#36807;&#22810;&#30340;&#35745;&#31639;&#65292;&#36825;&#19981;&#31526;&#21512;&#25512;&#33616;&#31995;&#32479;&#30340;&#25928;&#29575;&#35201;&#27714;&#12290;2&#65289;&#29616;&#26377;&#30340;&#21453;&#21521;&#36807;&#31243;&#20027;&#35201;&#35774;&#35745;&#29992;&#20110;&#36830;&#32493;&#22411;&#25968;&#25454;&#65292;&#32780;&#34892;&#20026;&#20449;&#24687;&#26159;&#31163;&#25955;&#22411;&#30340;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#31163;&#25955;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimedia recommendation aims to predict users' future behaviors based on historical behavioral data and item's multimodal information. However, noise inherent in behavioral data, arising from unintended user interactions with uninteresting items, detrimentally impacts recommendation performance. Recently, diffusion models have achieved high-quality information generation, in which the reverse process iteratively infers future information based on the corrupted state. It meets the need of predictive tasks under noisy conditions, and inspires exploring their application to predicting user behaviors. Nonetheless, several challenges must be addressed: 1) Classical diffusion models require excessive computation, which does not meet the efficiency requirements of recommendation systems. 2) Existing reverse processes are mainly designed for continuous data, whereas behavioral information is discrete in nature. Therefore, an effective method is needed for the generation of discrete behaviora
&lt;/p&gt;</description></item></channel></rss>