<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#31471;&#27969;&#34892;&#24230;&#20559;&#35265;&#19981;&#20844;&#24179;&#30340;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2310.02961</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#23548;&#33268;&#27969;&#34892;&#24230;&#19981;&#20844;&#24179;&#30340;&#28508;&#22312;&#22240;&#32032;&#65306;&#22522;&#20110;&#29992;&#25143;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Potential Factors Leading to Popularity Unfairness in Recommender Systems: A User-Centered Analysis. (arXiv:2310.02961v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02961
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#31471;&#27969;&#34892;&#24230;&#20559;&#35265;&#19981;&#20844;&#24179;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#34892;&#24230;&#20559;&#24046;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#20247;&#25152;&#21608;&#30693;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#23569;&#25968;&#27969;&#34892;&#29289;&#21697;&#22312;&#36755;&#20837;&#25968;&#25454;&#20013;&#34987;&#36807;&#24230;&#20195;&#34920;&#65292;&#32780;&#20854;&#20182;&#22823;&#37096;&#20998;&#19981;&#37027;&#20040;&#27969;&#34892;&#30340;&#29289;&#21697;&#21017;&#34987;&#20302;&#20272;&#12290;&#36825;&#31181;&#19981;&#24179;&#31561;&#30340;&#20195;&#34920;&#24448;&#24448;&#23548;&#33268;&#25512;&#33616;&#32467;&#26524;&#20013;&#29289;&#21697;&#30340;&#26292;&#38706;&#23384;&#22312;&#20559;&#35265;&#12290;&#24050;&#26377;&#22823;&#37327;&#30740;&#31350;&#20174;&#29289;&#21697;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#31181;&#20559;&#24046;&#65292;&#24182;&#35797;&#22270;&#36890;&#36807;&#22686;&#24378;&#23545;&#19981;&#37027;&#20040;&#27969;&#34892;&#29289;&#21697;&#30340;&#25512;&#33616;&#26469;&#32531;&#35299;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#36825;&#31181;&#20559;&#24046;&#23545;&#29992;&#25143;&#30340;&#24433;&#21709;&#12290;&#23545;&#20110;&#23545;&#27969;&#34892;&#29289;&#21697;&#26377;&#30528;&#19981;&#21516;&#23481;&#24525;&#24230;&#30340;&#29992;&#25143;&#32780;&#35328;&#65292;&#25512;&#33616;&#31995;&#32479;&#24182;&#19981;&#33021;&#20844;&#24179;&#22320;&#20026;&#20182;&#20204;&#25552;&#20379;&#26381;&#21153;&#65306;&#23545;&#20110;&#23545;&#19981;&#37027;&#20040;&#27969;&#34892;&#29289;&#21697;&#24863;&#20852;&#36259;&#30340;&#29992;&#25143;&#65292;&#22312;&#20182;&#20204;&#30340;&#25512;&#33616;&#20013;&#20250;&#24471;&#21040;&#26356;&#22810;&#30340;&#27969;&#34892;&#29289;&#21697;&#65292;&#32780;&#23545;&#20110;&#23545;&#27969;&#34892;&#29289;&#21697;&#24863;&#20852;&#36259;&#30340;&#29992;&#25143;&#65292;&#21017;&#34987;&#25512;&#33616;&#20102;&#20182;&#20204;&#24819;&#35201;&#30340;&#29289;&#21697;&#12290;&#20027;&#35201;&#21407;&#22240;&#26159;&#27969;&#34892;&#24230;&#20559;&#24046;&#20351;&#24471;&#27969;&#34892;&#29289;&#21697;&#34987;&#36807;&#24230;&#25512;&#33616;&#12290;&#26412;&#25991;&#26088;&#22312;&#25506;&#31350;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#31471;&#27969;&#34892;&#24230;&#20559;&#35265;&#19981;&#20844;&#24179;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Popularity bias is a well-known issue in recommender systems where few popular items are over-represented in the input data, while majority of other less popular items are under-represented. This disparate representation often leads to bias in exposure given to the items in the recommendation results. Extensive research examined this bias from item perspective and attempted to mitigate it by enhancing the recommendation of less popular items. However, a recent research has revealed the impact of this bias on users. Users with different degree of tolerance toward popular items are not fairly served by the recommendation system: users interested in less popular items receive more popular items in their recommendations, while users interested in popular items are recommended what they want. This is mainly due to the popularity bias that popular items are over-recommended. In this paper, we aim at investigating the factors leading to this user-side unfairness of popularity bias in recommen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#33258;&#21160;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#29305;&#24449;&#39044;&#22788;&#29702;&#65288;Auto-FP&#65289;&#65292;&#23558;&#20854;&#24314;&#27169;&#20026;&#36229;&#21442;&#25968;&#20248;&#21270;&#25110;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#25628;&#32034;&#38382;&#39064;&#65292;&#24182;&#25193;&#23637;&#20102;&#21508;&#31181;&#31639;&#27861;&#26469;&#35299;&#20915;Auto-FP&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.02540</link><description>&lt;p&gt;
Auto-FP:&#33258;&#21160;&#21270;&#29305;&#24449;&#39044;&#22788;&#29702;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Auto-FP: An Experimental Study of Automated Feature Preprocessing for Tabular Data. (arXiv:2310.02540v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02540
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#33258;&#21160;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#29305;&#24449;&#39044;&#22788;&#29702;&#65288;Auto-FP&#65289;&#65292;&#23558;&#20854;&#24314;&#27169;&#20026;&#36229;&#21442;&#25968;&#20248;&#21270;&#25110;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#25628;&#32034;&#38382;&#39064;&#65292;&#24182;&#25193;&#23637;&#20102;&#21508;&#31181;&#31639;&#27861;&#26469;&#35299;&#20915;Auto-FP&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#22914;&#32447;&#24615;&#27169;&#22411;&#21644;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#65292;&#22312;&#24037;&#19994;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#36825;&#20123;&#27169;&#22411;&#23545;&#25968;&#25454;&#20998;&#24067;&#25935;&#24863;&#65292;&#22240;&#27492;&#29305;&#24449;&#39044;&#22788;&#29702;&#26159;&#30830;&#20445;&#27169;&#22411;&#36136;&#37327;&#33391;&#22909;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#25163;&#21160;&#26500;&#24314;&#29305;&#24449;&#39044;&#22788;&#29702;&#27969;&#31243;&#24456;&#20855;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#25968;&#25454;&#31185;&#23398;&#23478;&#38656;&#35201;&#22312;&#36873;&#25321;&#21738;&#20123;&#39044;&#22788;&#29702;&#22120;&#20197;&#21450;&#20197;&#20160;&#20040;&#39034;&#24207;&#32452;&#21512;&#23427;&#20204;&#26041;&#38754;&#20316;&#20986;&#22256;&#38590;&#30340;&#20915;&#31574;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#33258;&#21160;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#29305;&#24449;&#39044;&#22788;&#29702;&#65288;Auto-FP&#65289;&#12290;&#30001;&#20110;&#25628;&#32034;&#31354;&#38388;&#36739;&#22823;&#65292;&#26292;&#21147;&#35299;&#20915;&#26041;&#26696;&#20195;&#20215;&#22826;&#39640;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#26377;&#36259;&#22320;&#35266;&#23519;&#21040;Auto-FP&#21487;&#20197;&#34987;&#24314;&#27169;&#20026;&#36229;&#21442;&#25968;&#20248;&#21270;&#65288;HPO&#65289;&#25110;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#38382;&#39064;&#12290;&#36825;&#20010;&#35266;&#23519;&#20351;&#25105;&#20204;&#33021;&#22815;&#25193;&#23637;&#21508;&#31181;HPO&#21644;NAS&#31639;&#27861;&#26469;&#35299;&#20915;Auto-FP&#38382;&#39064;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35780;&#20272;&#21644;&#20998;&#26512;&#65292;&#20849;&#36827;&#34892;&#20102;15&#20010;...
&lt;/p&gt;
&lt;p&gt;
Classical machine learning models, such as linear models and tree-based models, are widely used in industry. These models are sensitive to data distribution, thus feature preprocessing, which transforms features from one distribution to another, is a crucial step to ensure good model quality. Manually constructing a feature preprocessing pipeline is challenging because data scientists need to make difficult decisions about which preprocessors to select and in which order to compose them. In this paper, we study how to automate feature preprocessing (Auto-FP) for tabular data. Due to the large search space, a brute-force solution is prohibitively expensive. To address this challenge, we interestingly observe that Auto-FP can be modelled as either a hyperparameter optimization (HPO) or a neural architecture search (NAS) problem. This observation enables us to extend a variety of HPO and NAS algorithms to solve the Auto-FP problem. We conduct a comprehensive evaluation and analysis of 15 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#38899;&#20048;&#21363;&#20852;&#21019;&#20316;&#20013;&#19981;&#30830;&#23450;&#24615;&#21644;&#39044;&#27979;&#35823;&#24046;&#30340;&#26102;&#24207;&#21160;&#24577;&#65292;&#21457;&#29616;&#20102;&#38899;&#39640;&#21644;&#38899;&#39640;-&#33410;&#22863;&#24207;&#21015;&#20013;&#30340;&#29305;&#23450;&#26102;&#38388;&#27169;&#24335;&#21644;&#26102;&#20195;&#29305;&#24449;&#65292;&#20197;&#21450;&#33410;&#22863;&#24207;&#21015;&#30340;&#19968;&#33268;&#19981;&#30830;&#23450;&#24230;&#12290;&#36825;&#20123;&#21457;&#29616;&#31361;&#26174;&#20102;&#33410;&#22863;&#22312;&#38899;&#20048;&#21019;&#20316;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.02518</link><description>&lt;p&gt;
&#22609;&#36896;&#26102;&#20195;&#30340;&#20010;&#24615;&#19982;&#20849;&#24615;&#65306;&#38899;&#20048;&#21363;&#20852;&#21019;&#20316;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#39044;&#27979;&#35823;&#24046;&#30340;&#26102;&#24207;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Shaping the Epochal Individuality and Generality: The Temporal Dynamics of Uncertainty and Prediction Error in Musical Improvisation. (arXiv:2310.02518v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02518
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#38899;&#20048;&#21363;&#20852;&#21019;&#20316;&#20013;&#19981;&#30830;&#23450;&#24615;&#21644;&#39044;&#27979;&#35823;&#24046;&#30340;&#26102;&#24207;&#21160;&#24577;&#65292;&#21457;&#29616;&#20102;&#38899;&#39640;&#21644;&#38899;&#39640;-&#33410;&#22863;&#24207;&#21015;&#20013;&#30340;&#29305;&#23450;&#26102;&#38388;&#27169;&#24335;&#21644;&#26102;&#20195;&#29305;&#24449;&#65292;&#20197;&#21450;&#33410;&#22863;&#24207;&#21015;&#30340;&#19968;&#33268;&#19981;&#30830;&#23450;&#24230;&#12290;&#36825;&#20123;&#21457;&#29616;&#31361;&#26174;&#20102;&#33410;&#22863;&#22312;&#38899;&#20048;&#21019;&#20316;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#20048;&#21363;&#20852;&#21019;&#20316;&#65292;&#23601;&#20687;&#21363;&#20852;&#28436;&#35762;&#19968;&#26679;&#65292;&#23637;&#29616;&#20102;&#21363;&#20852;&#32773;&#30340;&#24605;&#32500;&#29366;&#24577;&#21644;&#24773;&#24863;&#29305;&#36136;&#30340;&#31934;&#22937;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#25581;&#31034;&#36825;&#31181;&#20010;&#24615;&#30340;&#20855;&#20307;&#38899;&#20048;&#32452;&#25104;&#37096;&#20998;&#20173;&#26410;&#34987;&#24191;&#27867;&#25506;&#32034;&#12290;&#22312;&#22823;&#33041;&#30340;&#32479;&#35745;&#23398;&#20064;&#21644;&#39044;&#27979;&#22788;&#29702;&#26694;&#26550;&#20869;&#65292;&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#38899;&#20048;&#21363;&#20852;&#21019;&#20316;&#20013;&#19981;&#30830;&#23450;&#24615;&#21644;&#24778;&#35766;&#65288;&#39044;&#27979;&#35823;&#24046;&#65289;&#30340;&#26102;&#24207;&#21160;&#24577;&#12290;&#26412;&#30740;&#31350;&#37319;&#29992;HBSL&#27169;&#22411;&#20998;&#26512;&#20102;&#19968;&#20010;&#21253;&#21547;456&#27573;&#29237;&#22763;&#21363;&#20852;&#21019;&#20316;&#30340;&#35821;&#26009;&#24211;&#65292;&#36328;&#36234;1905&#24180;&#33267;2009&#24180;&#65292;&#28085;&#30422;&#20102;78&#20301;&#19981;&#21516;&#30340;&#29237;&#22763;&#38899;&#20048;&#23478;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23588;&#20854;&#26159;&#22312;&#38899;&#39640;&#21644;&#38899;&#39640;-&#33410;&#22863;&#24207;&#21015;&#20013;&#65292;&#24778;&#35766;&#21644;&#19981;&#30830;&#23450;&#24615;&#21576;&#29616;&#20986;&#29420;&#29305;&#30340;&#26102;&#38388;&#27169;&#24335;&#65292;&#25581;&#31034;&#20102;&#20174;20&#19990;&#32426;&#21021;&#21040;21&#19990;&#32426;&#30340;&#26102;&#20195;&#29305;&#24449;&#12290;&#30456;&#21453;&#65292;&#33410;&#22863;&#24207;&#21015;&#22312;&#19981;&#21516;&#26102;&#20195;&#34920;&#29616;&#20986;&#19968;&#33268;&#30340;&#19981;&#30830;&#23450;&#24230;&#12290;&#27492;&#22806;&#65292;&#22768;&#23398;&#29305;&#24615;&#22312;&#19981;&#21516;&#26102;&#26399;&#20445;&#25345;&#19981;&#21464;&#12290;&#36825;&#20123;&#21457;&#29616;&#31361;&#26174;&#20102;&#33410;&#22863;&#22312;&#38899;&#20048;&#21019;&#20316;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Musical improvisation, much like spontaneous speech, reveals intricate facets of the improviser's state of mind and emotional character. However, the specific musical components that reveal such individuality remain largely unexplored. Within the framework of brain's statistical learning and predictive processing, this study examined the temporal dynamics of uncertainty and surprise (prediction error) in a piece of musical improvisation. This study employed the HBSL model to analyze a corpus of 456 Jazz improvisations, spanning 1905 to 2009, from 78 distinct Jazz musicians. The results indicated distinctive temporal patterns of surprise and uncertainty, especially in pitch and pitch-rhythm sequences, revealing era-specific features from the early 20th to the 21st centuries. Conversely, rhythm sequences exhibited a consistent degree of uncertainty across eras. Further, the acoustic properties remain unchanged across different periods. These findings highlight the importance of how tempo
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#32447;&#24615;&#24490;&#29615;&#21333;&#20803;&#65288;LRURec&#65289;&#12290;&#19982;&#24403;&#21069;&#30340;&#33258;&#27880;&#24847;&#27169;&#22411;&#30456;&#27604;&#65292;LRURec&#20855;&#26377;&#24555;&#36895;&#30340;&#25512;&#26029;&#36895;&#24230;&#12289;&#33021;&#22815;&#36827;&#34892;&#22686;&#37327;&#25512;&#26029;&#12289;&#26356;&#23567;&#30340;&#27169;&#22411;&#22823;&#23567;&#21644;&#21487;&#24182;&#34892;&#35757;&#32451;&#12290;&#36890;&#36807;&#20248;&#21270;&#26550;&#26500;&#24182;&#24341;&#20837;&#38750;&#32447;&#24615;&#65292;LRURec&#22312;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.02367</link><description>&lt;p&gt;
&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#32447;&#24615;&#24490;&#29615;&#21333;&#20803;
&lt;/p&gt;
&lt;p&gt;
Linear Recurrent Units for Sequential Recommendation. (arXiv:2310.02367v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02367
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#32447;&#24615;&#24490;&#29615;&#21333;&#20803;&#65288;LRURec&#65289;&#12290;&#19982;&#24403;&#21069;&#30340;&#33258;&#27880;&#24847;&#27169;&#22411;&#30456;&#27604;&#65292;LRURec&#20855;&#26377;&#24555;&#36895;&#30340;&#25512;&#26029;&#36895;&#24230;&#12289;&#33021;&#22815;&#36827;&#34892;&#22686;&#37327;&#25512;&#26029;&#12289;&#26356;&#23567;&#30340;&#27169;&#22411;&#22823;&#23567;&#21644;&#21487;&#24182;&#34892;&#35757;&#32451;&#12290;&#36890;&#36807;&#20248;&#21270;&#26550;&#26500;&#24182;&#24341;&#20837;&#38750;&#32447;&#24615;&#65292;LRURec&#22312;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#39034;&#24207;&#25512;&#33616;&#20381;&#36182;&#20110;&#22522;&#20110;&#33258;&#27880;&#24847;&#30340;&#25512;&#33616;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#35745;&#31639;&#20195;&#20215;&#39640;&#65292;&#24448;&#24448;&#23545;&#23454;&#26102;&#25512;&#33616;&#26469;&#35828;&#36807;&#20110;&#32531;&#24930;&#12290;&#27492;&#22806;&#65292;&#33258;&#27880;&#24847;&#25805;&#20316;&#26159;&#22312;&#24207;&#21015;&#23618;&#32423;&#19978;&#36827;&#34892;&#30340;&#65292;&#22240;&#27492;&#23545;&#20110;&#20302;&#25104;&#26412;&#30340;&#22686;&#37327;&#25512;&#26029;&#26469;&#35828;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#21463;&#21040;&#39640;&#25928;&#35821;&#35328;&#24314;&#27169;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#32447;&#24615;&#24490;&#29615;&#21333;&#20803;&#65288;LRURec&#65289;&#12290;&#31867;&#20284;&#20110;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65292;LRURec&#20855;&#26377;&#24555;&#36895;&#30340;&#25512;&#26029;&#36895;&#24230;&#65292;&#24182;&#19988;&#33021;&#22815;&#23545;&#39034;&#24207;&#36755;&#20837;&#36827;&#34892;&#22686;&#37327;&#25512;&#26029;&#12290;&#36890;&#36807;&#20998;&#35299;&#32447;&#24615;&#24490;&#29615;&#25805;&#20316;&#24182;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#35774;&#35745;&#36882;&#24402;&#24182;&#34892;&#21270;&#65292;LRURec&#25552;&#20379;&#20102;&#20943;&#23567;&#27169;&#22411;&#22823;&#23567;&#21644;&#21487;&#24182;&#34892;&#35757;&#32451;&#30340;&#39069;&#22806;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#26045;&#19968;&#31995;&#21015;&#20462;&#25913;&#26469;&#20248;&#21270;LRURec&#30340;&#26550;&#26500;&#65292;&#20197;&#35299;&#20915;&#32570;&#20047;&#38750;&#32447;&#24615;&#21644;&#25913;&#21892;&#35757;&#32451;&#21160;&#24577;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#25552;&#20986;&#30340;LRURec&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art sequential recommendation relies heavily on self-attention-based recommender models. Yet such models are computationally expensive and often too slow for real-time recommendation. Furthermore, the self-attention operation is performed at a sequence-level, thereby making low-cost incremental inference challenging. Inspired by recent advances in efficient language modeling, we propose linear recurrent units for sequential recommendation (LRURec). Similar to recurrent neural networks, LRURec offers rapid inference and can achieve incremental inference on sequential inputs. By decomposing the linear recurrence operation and designing recursive parallelization in our framework, LRURec provides the additional benefits of reduced model size and parallelizable training. Moreover, we optimize the architecture of LRURec by implementing a series of modifications to address the lack of non-linearity and improve training dynamics. To validate the effectiveness of our proposed LRURe
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#20851;&#27880;&#20110;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22810;&#26679;&#24615;&#12289;&#24847;&#22806;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#36229;&#36234;&#20256;&#32479;&#30340;&#20934;&#30830;&#24615;&#35780;&#20272;&#65292;&#24182;&#35752;&#35770;&#20102;&#27169;&#22411;&#24320;&#21457;&#30340;&#19981;&#21516;&#38454;&#27573;&#12290;</title><link>http://arxiv.org/abs/2310.02294</link><description>&lt;p&gt;
&#36229;&#36234;&#20934;&#30830;&#24615;: &#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22810;&#26679;&#24615;&#12289;&#24847;&#22806;&#24615;&#21644;&#20844;&#24179;&#24615;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Beyond-Accuracy: A Review on Diversity, Serendipity and Fairness in Recommender Systems Based on Graph Neural Networks. (arXiv:2310.02294v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#20851;&#27880;&#20110;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22810;&#26679;&#24615;&#12289;&#24847;&#22806;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#36229;&#36234;&#20256;&#32479;&#30340;&#20934;&#30830;&#24615;&#35780;&#20272;&#65292;&#24182;&#35752;&#35770;&#20102;&#27169;&#22411;&#24320;&#21457;&#30340;&#19981;&#21516;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21521;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#24314;&#35758;&#65292;&#25512;&#33616;&#31995;&#32479;&#24050;&#32463;&#25104;&#20026;&#35768;&#22810;&#22312;&#32447;&#24179;&#21488;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#21327;&#21516;&#36807;&#28388;&#65292;&#29305;&#21035;&#26159;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#22522;&#20110;&#22270;&#30340;&#26041;&#27861;&#65292;&#22312;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#20934;&#30830;&#24615;&#24182;&#19981;&#24635;&#26159;&#35780;&#20272;&#25512;&#33616;&#31995;&#32479;&#24615;&#33021;&#26368;&#37325;&#35201;&#30340;&#26631;&#20934;&#65292;&#22240;&#20026;&#38500;&#20102;&#20934;&#30830;&#24615;&#20043;&#22806;&#65292;&#25512;&#33616;&#22810;&#26679;&#24615;&#12289;&#24847;&#22806;&#24615;&#21644;&#20844;&#24179;&#24615;&#31561;&#26041;&#38754;&#20063;&#20250;&#23545;&#29992;&#25143;&#21442;&#19982;&#21644;&#28385;&#24847;&#24230;&#20135;&#29983;&#24378;&#28872;&#24433;&#21709;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#20851;&#27880;&#20110;&#35299;&#20915;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#36825;&#20123;&#32500;&#24230;&#65292;&#36229;&#36234;&#20256;&#32479;&#20197;&#20934;&#30830;&#24615;&#20026;&#20013;&#24515;&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#39318;&#20808;&#22238;&#39038;&#20102;&#26368;&#36817;&#22312;&#25913;&#21892;&#20934;&#30830;&#24615;-&#22810;&#26679;&#24615;&#26435;&#34913;&#12289;&#20419;&#36827;&#24847;&#22806;&#24615;&#21644;&#20844;&#24179;&#24615;&#26041;&#38754;&#30340;&#26041;&#27861;&#26041;&#38754;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#27169;&#22411;&#24320;&#21457;&#30340;&#19981;&#21516;&#38454;&#27573;&#65292;&#21253;&#25324;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#22270;&#26500;&#24314;&#12289;&#23884;&#20837;&#21021;&#22987;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
By providing personalized suggestions to users, recommender systems have become essential to numerous online platforms. Collaborative filtering, particularly graph-based approaches using Graph Neural Networks (GNNs), have demonstrated great results in terms of recommendation accuracy. However, accuracy may not always be the most important criterion for evaluating recommender systems' performance, since beyond-accuracy aspects such as recommendation diversity, serendipity, and fairness can strongly influence user engagement and satisfaction. This review paper focuses on addressing these dimensions in GNN-based recommender systems, going beyond the conventional accuracy-centric perspective. We begin by reviewing recent developments in approaches that improve not only the accuracy-diversity trade-off but also promote serendipity and fairness in GNN-based recommender systems. We discuss different stages of model development including data preprocessing, graph construction, embedding initia
&lt;/p&gt;</description></item><item><title>MedCPT&#26159;&#19968;&#31181;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#38646;&#26679;&#26412;&#35821;&#20041;&#20449;&#24687;&#26816;&#32034;&#30340;&#23545;&#27604;&#39044;&#35757;&#32451;&#36716;&#25442;&#22120;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#22823;&#35268;&#27169;PubMed&#25628;&#32034;&#26085;&#24535;&#36827;&#34892;&#35757;&#32451;&#65292;MedCPT&#22312;&#20845;&#20010;&#29983;&#29289;&#21307;&#23398;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#21019;&#36896;&#20102;&#26032;&#30340;&#26368;&#20339;&#24615;&#33021;&#65292;&#36229;&#36807;&#20102;&#20854;&#20182;&#22522;&#32447;&#27169;&#22411;&#65292;&#21516;&#26102;&#36824;&#33021;&#29983;&#25104;&#26356;&#22909;&#30340;&#29983;&#29289;&#21307;&#23398;&#25991;&#31456;&#21644;&#21477;&#23376;&#12290;</title><link>http://arxiv.org/abs/2307.00589</link><description>&lt;p&gt;
MedCPT: &#20351;&#29992;&#22823;&#35268;&#27169;PubMed&#25628;&#32034;&#26085;&#24535;&#30340;&#23545;&#27604;&#39044;&#35757;&#32451;&#36716;&#25442;&#22120;&#36827;&#34892;&#38646;&#26679;&#26412;&#29983;&#29289;&#21307;&#23398;&#20449;&#24687;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
MedCPT: Contrastive Pre-trained Transformers with Large-scale PubMed Search Logs for Zero-shot Biomedical Information Retrieval. (arXiv:2307.00589v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00589
&lt;/p&gt;
&lt;p&gt;
MedCPT&#26159;&#19968;&#31181;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#38646;&#26679;&#26412;&#35821;&#20041;&#20449;&#24687;&#26816;&#32034;&#30340;&#23545;&#27604;&#39044;&#35757;&#32451;&#36716;&#25442;&#22120;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#22823;&#35268;&#27169;PubMed&#25628;&#32034;&#26085;&#24535;&#36827;&#34892;&#35757;&#32451;&#65292;MedCPT&#22312;&#20845;&#20010;&#29983;&#29289;&#21307;&#23398;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#21019;&#36896;&#20102;&#26032;&#30340;&#26368;&#20339;&#24615;&#33021;&#65292;&#36229;&#36807;&#20102;&#20854;&#20182;&#22522;&#32447;&#27169;&#22411;&#65292;&#21516;&#26102;&#36824;&#33021;&#29983;&#25104;&#26356;&#22909;&#30340;&#29983;&#29289;&#21307;&#23398;&#25991;&#31456;&#21644;&#21477;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#22312;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#33719;&#21462;&#21644;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;&#36827;&#23637;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#32534;&#30721;&#22120;&#22312;&#35821;&#20041;&#26816;&#32034;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#65292;&#20294;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#30340;&#26597;&#35810;-&#25991;&#31456;&#27880;&#37322;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#24456;&#38590;&#33719;&#24471;&#12290;&#22240;&#27492;&#65292;&#22823;&#22810;&#25968;&#29983;&#29289;&#21307;&#23398;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#21482;&#36827;&#34892;&#35789;&#27719;&#21305;&#37197;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MedCPT&#65292;&#36825;&#26159;&#19968;&#31181;&#39318;&#21019;&#30340;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#38646;&#26679;&#26412;&#35821;&#20041;&#20449;&#24687;&#26816;&#32034;&#30340;&#23545;&#27604;&#39044;&#35757;&#32451;&#36716;&#25442;&#22120;&#27169;&#22411;&#12290;&#20026;&#20102;&#35757;&#32451;MedCPT&#65292;&#25105;&#20204;&#20174;PubMed&#25910;&#38598;&#20102;255 million&#20010;&#29992;&#25143;&#28857;&#20987;&#26085;&#24535;&#65292;&#36825;&#26159;&#21069;&#25152;&#26410;&#26377;&#30340;&#35268;&#27169;&#12290;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#65292;&#25105;&#20204;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#26469;&#35757;&#32451;&#19968;&#23545;&#23494;&#20999;&#38598;&#25104;&#30340;&#26816;&#32034;&#22120;&#21644;&#37325;&#25490;&#22120;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;MedCPT&#22312;&#20845;&#20010;&#29983;&#29289;&#21307;&#23398;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20339;&#24615;&#33021;&#65292;&#20248;&#20110;&#21253;&#25324;&#26356;&#22823;&#27169;&#22411;&#65288;&#22914;GPT-3&#22823;&#23567;&#30340;cpt-text-XL&#65289;&#22312;&#20869;&#30340;&#21508;&#31181;&#22522;&#32447;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;MedCPT&#36824;&#33021;&#22815;&#29983;&#25104;&#26356;&#22909;&#30340;&#29983;&#29289;&#21307;&#23398;&#25991;&#31456;&#21644;&#21477;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information retrieval (IR) is essential in biomedical knowledge acquisition and clinical decision support. While recent progress has shown that language model encoders perform better semantic retrieval, training such models requires abundant query-article annotations that are difficult to obtain in biomedicine. As a result, most biomedical IR systems only conduct lexical matching. In response, we introduce MedCPT, a first-of-its-kind Contrastively Pre-trained Transformer model for zero-shot semantic IR in biomedicine. To train MedCPT, we collected an unprecedented scale of 255 million user click logs from PubMed. With such data, we use contrastive learning to train a pair of closely-integrated retriever and re-ranker. Experimental results show that MedCPT sets new state-of-the-art performance on six biomedical IR tasks, outperforming various baselines including much larger models such as GPT-3-sized cpt-text-XL. In addition, MedCPT also generates better biomedical article and sentence 
&lt;/p&gt;</description></item><item><title>CompoDiff &#26159;&#19968;&#31181;&#22810;&#21151;&#33021;&#30340;&#32452;&#21512;&#22270;&#20687;&#26816;&#32034;&#27169;&#22411;&#65292;&#36890;&#36807;&#25509;&#21463;&#21508;&#31181;&#26465;&#20214;&#65292;&#20855;&#26377;&#28508;&#22312;&#25193;&#25955;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312; FashionIQ &#19978;&#23454;&#29616;&#20102;&#26032;&#30340;&#38646;&#26679;&#26412;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#12290;&#20854;&#29305;&#24449;&#20301;&#20110;&#23436;&#25972;&#30340; CLIP &#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#25152;&#26377;&#21033;&#29992; CLIP &#31354;&#38388;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.11916</link><description>&lt;p&gt;
CompoDiff: &#22522;&#20110;&#28508;&#22312;&#25193;&#25955;&#30340;&#22810;&#21151;&#33021;&#32452;&#21512;&#22270;&#20687;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion. (arXiv:2303.11916v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11916
&lt;/p&gt;
&lt;p&gt;
CompoDiff &#26159;&#19968;&#31181;&#22810;&#21151;&#33021;&#30340;&#32452;&#21512;&#22270;&#20687;&#26816;&#32034;&#27169;&#22411;&#65292;&#36890;&#36807;&#25509;&#21463;&#21508;&#31181;&#26465;&#20214;&#65292;&#20855;&#26377;&#28508;&#22312;&#25193;&#25955;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312; FashionIQ &#19978;&#23454;&#29616;&#20102;&#26032;&#30340;&#38646;&#26679;&#26412;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#12290;&#20854;&#29305;&#24449;&#20301;&#20110;&#23436;&#25972;&#30340; CLIP &#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#25152;&#26377;&#21033;&#29992; CLIP &#31354;&#38388;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#27169;&#22411; CompoDiff&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#28508;&#22312;&#25193;&#25955;&#30340;&#32452;&#21512;&#22270;&#20687;&#26816;&#32034;&#65288;CIR&#65289;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#30001; 1800 &#19975;&#20010;&#21442;&#32771;&#22270;&#20687;&#12289;&#26465;&#20214;&#21644;&#30456;&#24212;&#30340;&#30446;&#26631;&#22270;&#20687;&#19977;&#20803;&#32452;&#32452;&#25104;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35757;&#32451;&#27169;&#22411;&#12290;CompoDiff &#19981;&#20165;&#22312;&#20687; FashionIQ &#36825;&#26679;&#30340; CIR &#22522;&#20934;&#27979;&#35797;&#19978;&#23454;&#29616;&#20102;&#26032;&#30340;&#38646;&#26679;&#26412;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#65292;&#32780;&#19988;&#36824;&#36890;&#36807;&#25509;&#25910;&#21508;&#31181;&#26465;&#20214;&#65288;&#22914;&#36127;&#25991;&#26412;&#21644;&#22270;&#20687;&#36974;&#32617;&#26465;&#20214;&#65289;&#65292;&#20351;&#24471; CIR &#26356;&#21152;&#22810;&#21151;&#33021;&#65292;&#36825;&#26159;&#29616;&#26377; CIR &#26041;&#27861;&#25152;&#19981;&#20855;&#22791;&#30340;&#12290;&#27492;&#22806;&#65292;CompoDiff &#29305;&#24449;&#20301;&#20110;&#23436;&#25972;&#30340; CLIP &#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#22240;&#27492;&#23427;&#20204;&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#21033;&#29992; CLIP &#31354;&#38388;&#30340;&#25152;&#26377;&#29616;&#26377;&#27169;&#22411;&#12290;&#35757;&#32451;&#25152;&#20351;&#29992;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#39044;&#35757;&#32451;&#26435;&#37325;&#21487;&#22312; https://github.com/navervision/CompoDiff &#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel diffusion-based model, CompoDiff, for solving Composed Image Retrieval (CIR) with latent diffusion and presents a newly created dataset of 18 million reference images, conditions, and corresponding target image triplets to train the model. CompoDiff not only achieves a new zero-shot state-of-the-art on a CIR benchmark such as FashionIQ but also enables a more versatile CIR by accepting various conditions, such as negative text and image mask conditions, which are unavailable with existing CIR methods. In addition, the CompoDiff features are on the intact CLIP embedding space so that they can be directly used for all existing models exploiting the CLIP space. The code and dataset used for the training, and the pre-trained weights are available at https://github.com/navervision/CompoDiff
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#20998;&#24067;&#36716;&#31227;&#35270;&#35282;&#20986;&#21457;&#65292;&#30740;&#31350;&#20102;&#20174;&#20559;&#21521;&#21453;&#39304;&#20013;&#23398;&#20064;&#26080;&#20559;&#31639;&#27861;&#36827;&#34892;&#25512;&#33616;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#24314;&#31435;&#26080;&#20559;&#25512;&#33616;&#19982;&#20998;&#24067;&#36716;&#31227;&#30340;&#20851;&#31995;&#65292;&#23545;&#29616;&#26377;&#26080;&#20559;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#35299;&#37322;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#27867;&#21270;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2206.03851</link><description>&lt;p&gt;
&#22312;&#26080;&#20559;&#25512;&#33616;&#20013;&#37325;&#26032;&#32771;&#34385;&#23398;&#20064;&#30446;&#26631;&#65306;&#20998;&#24067;&#36716;&#31227;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective. (arXiv:2206.03851v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#20998;&#24067;&#36716;&#31227;&#35270;&#35282;&#20986;&#21457;&#65292;&#30740;&#31350;&#20102;&#20174;&#20559;&#21521;&#21453;&#39304;&#20013;&#23398;&#20064;&#26080;&#20559;&#31639;&#27861;&#36827;&#34892;&#25512;&#33616;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#24314;&#31435;&#26080;&#20559;&#25512;&#33616;&#19982;&#20998;&#24067;&#36716;&#31227;&#30340;&#20851;&#31995;&#65292;&#23545;&#29616;&#26377;&#26080;&#20559;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#35299;&#37322;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#27867;&#21270;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#20559;&#21521;&#21453;&#39304;&#20013;&#23398;&#20064;&#26080;&#20559;&#31639;&#27861;&#36827;&#34892;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#19968;&#20010;&#26032;&#39062;&#30340;&#20998;&#24067;&#36716;&#31227;&#35270;&#35282;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#26368;&#36817;&#22312;&#26080;&#20559;&#25512;&#33616;&#39046;&#22495;&#30340;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#21508;&#31181;&#25216;&#26415;&#22914;&#37325;&#26032;&#21152;&#26435;&#12289;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#20803;&#23398;&#20064;&#65292;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#25104;&#26524;&#12290;&#23613;&#31649;&#23427;&#20204;&#22312;&#23454;&#35777;&#19978;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22823;&#37096;&#20998;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#65292;&#23548;&#33268;&#20102;&#29702;&#35770;&#21644;&#26368;&#26032;&#31639;&#27861;&#20043;&#38388;&#30340;&#26174;&#33879;&#24046;&#36317;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#29616;&#26377;&#26080;&#20559;&#23398;&#20064;&#30446;&#26631;&#20026;&#20309;&#36866;&#29992;&#20110;&#26080;&#20559;&#25512;&#33616;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#26080;&#20559;&#25512;&#33616;&#19982;&#20998;&#24067;&#36716;&#31227;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#65292;&#26174;&#31034;&#20102;&#29616;&#26377;&#30340;&#26080;&#20559;&#23398;&#20064;&#30446;&#26631;&#38544;&#21547;&#22320;&#23558;&#26377;&#20559;&#30340;&#35757;&#32451;&#20998;&#24067;&#19982;&#26080;&#20559;&#30340;&#27979;&#35797;&#20998;&#24067;&#23545;&#40784;&#12290;&#22522;&#20110;&#36825;&#20010;&#20851;&#31995;&#65292;&#25105;&#20204;&#38024;&#23545;&#29616;&#26377;&#30340;&#26080;&#20559;&#23398;&#20064;&#26041;&#27861;&#21457;&#23637;&#20102;&#20004;&#20010;&#27867;&#21270;&#30028;&#38480;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#23398;&#20064;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies the problem of learning unbiased algorithms from biased feedback for recommendation. We address this problem from a novel distribution shift perspective. Recent works in unbiased recommendation have advanced the state-of-the-art with various techniques such as re-weighting, multi-task learning, and meta-learning. Despite their empirical successes, most of them lack theoretical guarantees, forming non-negligible gaps between theories and recent algorithms. In this paper, we propose a theoretical understanding of why existing unbiased learning objectives work for unbiased recommendation. We establish a close connection between unbiased recommendation and distribution shift, which shows that existing unbiased learning objectives implicitly align biased training and unbiased test distributions. Built upon this connection, we develop two generalization bounds for existing unbiased learning methods and analyze their learning behavior. Besides, as a result of the distributio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#26041;&#27861;SR-HetGNN&#65292;&#36890;&#36807;&#23398;&#20064;&#20250;&#35805;&#23884;&#20837;&#24182;&#25429;&#25417;&#21311;&#21517;&#29992;&#25143;&#30340;&#29305;&#23450;&#20559;&#22909;&#65292;&#20197;&#25913;&#36827;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#25928;&#26524;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2108.05641</link><description>&lt;p&gt;
SR-HetGNN:&#22522;&#20110;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
SR-HetGNN:Session-based Recommendation with Heterogeneous Graph Neural Network. (arXiv:2108.05641v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.05641
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#26041;&#27861;SR-HetGNN&#65292;&#36890;&#36807;&#23398;&#20064;&#20250;&#35805;&#23884;&#20837;&#24182;&#25429;&#25417;&#21311;&#21517;&#29992;&#25143;&#30340;&#29305;&#23450;&#20559;&#22909;&#65292;&#20197;&#25913;&#36827;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#25928;&#26524;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#30446;&#30340;&#26159;&#26681;&#25454;&#20808;&#21069;&#30340;&#20250;&#35805;&#24207;&#21015;&#39044;&#27979;&#29992;&#25143;&#30340;&#19979;&#19968;&#27425;&#28857;&#20987;&#12290;&#30446;&#21069;&#30340;&#30740;&#31350;&#36890;&#24120;&#26681;&#25454;&#29992;&#25143;&#20250;&#35805;&#24207;&#21015;&#20013;&#30340;&#39033;&#30446;&#36716;&#25442;&#26469;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#20250;&#35805;&#24207;&#21015;&#20013;&#30340;&#20854;&#20182;&#26377;&#25928;&#20449;&#24687;&#65292;&#22914;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#65292;&#24448;&#24448;&#34987;&#24573;&#35270;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#26080;&#27861;&#23398;&#20064;&#29992;&#25143;&#30340;&#20855;&#20307;&#20559;&#22909;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;SR-HetGNN&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;HetGNN&#65289;&#23398;&#20064;&#20250;&#35805;&#23884;&#20837;&#65292;&#24182;&#25429;&#25417;&#21311;&#21517;&#29992;&#25143;&#30340;&#29305;&#23450;&#20559;&#22909;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SR-HetGNN&#39318;&#20808;&#26681;&#25454;&#20250;&#35805;&#24207;&#21015;&#26500;&#24314;&#21253;&#21547;&#21508;&#31181;&#31867;&#22411;&#33410;&#28857;&#30340;&#24322;&#26500;&#22270;&#65292;&#21487;&#20197;&#25429;&#25417;&#39033;&#30446;&#12289;&#29992;&#25143;&#21644;&#20250;&#35805;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#20854;&#27425;&#65292;HetGNN&#25429;&#25417;&#39033;&#30446;&#20043;&#38388;&#30340;&#22797;&#26434;&#36716;&#25442;&#24182;&#23398;&#20064;&#21253;&#21547;&#39033;&#30446;&#23884;&#20837;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The purpose of the Session-Based Recommendation System is to predict the user's next click according to the previous session sequence. The current studies generally learn user preferences according to the transitions of items in the user's session sequence. However, other effective information in the session sequence, such as user profiles, are largely ignored which may lead to the model unable to learn the user's specific preferences. In this paper, we propose a heterogeneous graph neural network-based session recommendation method, named SR-HetGNN, which can learn session embeddings by heterogeneous graph neural network (HetGNN), and capture the specific preferences of anonymous users. Specifically, SR-HetGNN first constructs heterogeneous graphs containing various types of nodes according to the session sequence, which can capture the dependencies among items, users, and sessions. Second, HetGNN captures the complex transitions between items and learns the item embeddings containing
&lt;/p&gt;</description></item></channel></rss>