<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#20250;&#35805;&#24335;&#25628;&#32034;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#65292;&#21363;&#23558;&#26816;&#32034;&#21040;&#30340;&#39030;&#32423;&#27573;&#33853;&#32508;&#21512;&#25104;&#19968;&#31181;&#23436;&#25972;&#12289;&#30456;&#20851;&#19988;&#31616;&#27905;&#30340;&#21709;&#24212;&#12290;&#36890;&#36807;&#25910;&#38598;&#27573;&#33853;&#32423;&#21035;&#30340;&#30456;&#20851;&#27880;&#37322;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#27880;&#37322;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#21644;&#35780;&#20272;&#29983;&#25104;&#30340;&#21709;&#24212;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2308.08911</link><description>&lt;p&gt;
&#35299;&#20915;&#20250;&#35805;&#24335;&#25628;&#32034;&#20013;&#30340;&#38382;&#39064;&#65306;&#20174;&#27573;&#33853;&#26816;&#32034;&#21040;&#20250;&#35805;&#24335;&#21709;&#24212;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Towards Filling the Gap in Conversational Search: From Passage Retrieval to Conversational Response Generation. (arXiv:2308.08911v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08911
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20250;&#35805;&#24335;&#25628;&#32034;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#65292;&#21363;&#23558;&#26816;&#32034;&#21040;&#30340;&#39030;&#32423;&#27573;&#33853;&#32508;&#21512;&#25104;&#19968;&#31181;&#23436;&#25972;&#12289;&#30456;&#20851;&#19988;&#31616;&#27905;&#30340;&#21709;&#24212;&#12290;&#36890;&#36807;&#25910;&#38598;&#27573;&#33853;&#32423;&#21035;&#30340;&#30456;&#20851;&#27880;&#37322;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#27880;&#37322;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#21644;&#35780;&#20272;&#29983;&#25104;&#30340;&#21709;&#24212;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#20851;&#20110;&#20250;&#35805;&#24335;&#25628;&#32034;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#26597;&#35810;&#37325;&#20889;&#21644;&#22810;&#38454;&#27573;&#27573;&#33853;&#26816;&#32034;&#19978;&#12290;&#28982;&#32780;&#65292;&#23558;&#26816;&#32034;&#21040;&#30340;&#39030;&#32423;&#27573;&#33853;&#32508;&#21512;&#25104;&#19968;&#31181;&#23436;&#25972;&#12289;&#30456;&#20851;&#19988;&#31616;&#27905;&#30340;&#21709;&#24212;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#25361;&#25112;&#12290;&#20855;&#26377;&#27573;&#33853;&#32423;&#21035;&#30340;&#30456;&#20851;&#27880;&#37322;&#23558;&#20351;&#24471;&#65288;1&#65289;&#33021;&#22815;&#35757;&#32451;&#21709;&#24212;&#29983;&#25104;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#33021;&#22815;&#22522;&#20110;&#23454;&#38469;&#38472;&#36848;&#36827;&#34892;&#31572;&#26696;&#35299;&#37322;&#65292;&#20197;&#21450;&#65288;2&#65289;&#33021;&#22815;&#26681;&#25454;&#23436;&#25972;&#24615;&#33258;&#21160;&#35780;&#20272;&#29983;&#25104;&#30340;&#21709;&#24212;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#20004;&#20010;TREC Conversational Assistance&#25968;&#25454;&#38598;&#20013;&#25910;&#38598;&#39640;&#36136;&#37327;&#30340;&#27573;&#33853;&#32423;&#21035;&#31572;&#26696;&#27880;&#37322;&#30340;&#38382;&#39064;&#12290;&#20026;&#30830;&#20445;&#36136;&#37327;&#65292;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#20102;&#21021;&#27493;&#30340;&#27880;&#37322;&#30740;&#31350;&#65292;&#37319;&#29992;&#19981;&#21516;&#30340;&#20219;&#21153;&#35774;&#35745;&#12289;&#20247;&#21253;&#24179;&#21488;&#21644;&#19981;&#21516;&#36164;&#36136;&#30340;&#24037;&#20316;&#32773;&#12290;&#26681;&#25454;&#36825;&#39033;&#30740;&#31350;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#27880;&#37322;&#21327;&#35758;&#65292;&#24182;&#32487;&#32493;&#36827;&#34892;&#20840;&#38754;&#30340;&#25968;&#25454;&#25910;&#38598;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20026;1.8k&#20010;&#38382;&#39064;&#25910;&#38598;&#20102;&#27880;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Research on conversational search has so far mostly focused on query rewriting and multi-stage passage retrieval. However, synthesizing the top retrieved passages into a complete, relevant, and concise response is still an open challenge. Having snippet-level annotations of relevant passages would enable both (1) the training of response generation models that are able to ground answers in actual statements and (2) the automatic evaluation of the generated responses in terms of completeness. In this paper, we address the problem of collecting high-quality snippet-level answer annotations for two of the TREC Conversational Assistance track datasets. To ensure quality, we first perform a preliminary annotation study, employing different task designs, crowdsourcing platforms, and workers with different qualifications. Based on the outcomes of this study, we refine our annotation protocol before proceeding with the full-scale data collection. Overall, we gather annotations for 1.8k questio
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#38750;&#20010;&#24615;&#21270;&#26041;&#27861;PARE&#65292;&#36890;&#36807;&#39044;&#27979;&#26368;&#39640;&#27969;&#34892;&#24230;&#30340;&#39033;&#30446;&#36827;&#34892;&#25512;&#33616;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#25512;&#33616;&#26041;&#27861;&#24573;&#30053;&#39033;&#30446;&#27969;&#34892;&#24230;&#30340;&#19981;&#36275;&#12290;&#23454;&#39564;&#35777;&#26126;PARE&#30340;&#24615;&#33021;&#20248;&#20110;&#22797;&#26434;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.08799</link><description>&lt;p&gt;
&#25429;&#25417;&#27969;&#34892;&#36235;&#21183;&#65306;&#22686;&#24378;&#39033;&#30446;&#25512;&#33616;&#30340;&#31616;&#21270;&#38750;&#20010;&#24615;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation. (arXiv:2308.08799v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08799
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#38750;&#20010;&#24615;&#21270;&#26041;&#27861;PARE&#65292;&#36890;&#36807;&#39044;&#27979;&#26368;&#39640;&#27969;&#34892;&#24230;&#30340;&#39033;&#30446;&#36827;&#34892;&#25512;&#33616;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#25512;&#33616;&#26041;&#27861;&#24573;&#30053;&#39033;&#30446;&#27969;&#34892;&#24230;&#30340;&#19981;&#36275;&#12290;&#23454;&#39564;&#35777;&#26126;PARE&#30340;&#24615;&#33021;&#20248;&#20110;&#22797;&#26434;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#65292;&#25512;&#33616;&#31995;&#32479;&#24050;&#32463;&#36234;&#26469;&#36234;&#21463;&#21040;&#30740;&#31350;&#30340;&#20851;&#27880;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#25512;&#33616;&#26041;&#27861;&#20391;&#37325;&#20110;&#36890;&#36807;&#21382;&#21490;&#30340;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#26469;&#25429;&#25417;&#29992;&#25143;&#30340;&#20010;&#24615;&#21270;&#20559;&#22909;&#65292;&#36825;&#21487;&#33021;&#20250;&#20405;&#29359;&#29992;&#25143;&#30340;&#38544;&#31169;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#24120;&#24120;&#24573;&#35270;&#20102;&#39033;&#30446;&#27969;&#34892;&#24230;&#30340;&#26102;&#38388;&#27874;&#21160;&#23545;&#29992;&#25143;&#20915;&#31574;&#30340;&#37325;&#35201;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Popularity-Aware Recommender&#65288;PARE&#65289;&#65292;&#36890;&#36807;&#39044;&#27979;&#23558;&#36798;&#21040;&#26368;&#39640;&#27969;&#34892;&#24230;&#30340;&#39033;&#30446;&#26469;&#36827;&#34892;&#38750;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;PARE&#30001;&#22235;&#20010;&#27169;&#22359;&#32452;&#25104;&#65292;&#20998;&#21035;&#20851;&#27880;&#19981;&#21516;&#30340;&#26041;&#38754;&#65306;&#27969;&#34892;&#24230;&#21382;&#21490;&#12289;&#26102;&#38388;&#24433;&#21709;&#12289;&#21608;&#26399;&#24615;&#24433;&#21709;&#21644;&#38468;&#21152;&#20449;&#24687;&#12290;&#26368;&#21518;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#23618;&#34701;&#21512;&#22235;&#20010;&#27169;&#22359;&#30340;&#36755;&#20986;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#26126;&#30830;&#24314;&#27169;&#39033;&#30446;&#27969;&#34892;&#24230;&#30340;&#24037;&#20316;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;PARE&#30340;&#24615;&#33021;&#19982;&#22797;&#26434;&#30340;&#26041;&#27861;&#30456;&#24403;&#29978;&#33267;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated st
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20498;&#25490;&#32034;&#24341;&#21644;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#23454;&#26102;&#26500;&#24314;&#20849;&#29616;&#32593;&#32476;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#21644;&#38477;&#20302;&#20869;&#23384;&#28040;&#32791;&#12290;</title><link>http://arxiv.org/abs/2308.08756</link><description>&lt;p&gt;
&#22522;&#20110;&#20498;&#25490;&#32034;&#24341;&#30340;&#20849;&#29616;&#32593;&#32476;&#23454;&#26102;&#26500;&#24314;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Real-Time Construction Algorithm of Co-Occurrence Network Based on Inverted Index. (arXiv:2308.08756v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20498;&#25490;&#32034;&#24341;&#21644;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#23454;&#26102;&#26500;&#24314;&#20849;&#29616;&#32593;&#32476;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#21644;&#38477;&#20302;&#20869;&#23384;&#28040;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20849;&#29616;&#32593;&#32476;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#25991;&#26412;&#25366;&#25496;&#39046;&#22495;&#20013;&#19968;&#31181;&#37325;&#35201;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#25991;&#26412;&#20013;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#36941;&#21382;&#31639;&#27861;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25991;&#26412;&#25968;&#25454;&#26102;&#20855;&#26377;&#36739;&#39640;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20498;&#25490;&#32034;&#24341;&#21644;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#25552;&#39640;&#20849;&#29616;&#32593;&#32476;&#26500;&#24314;&#30340;&#25928;&#29575;&#24182;&#38477;&#20302;&#20869;&#23384;&#28040;&#32791;&#12290;&#39318;&#20808;&#65292;&#20998;&#26512;&#20102;&#20256;&#32479;&#30340;&#36941;&#21382;&#31639;&#27861;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#26500;&#24314;&#20849;&#29616;&#32593;&#32476;&#26102;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#20171;&#32461;&#20102;&#20248;&#21270;&#31639;&#27861;&#30340;&#35814;&#32454;&#23454;&#29616;&#36807;&#31243;&#12290;&#38543;&#21518;&#65292;&#20351;&#29992;CSL&#22823;&#35268;&#27169;&#20013;&#25991;&#31185;&#25216;&#25991;&#29486;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;&#65292;&#20174;&#36816;&#34892;&#26102;&#38388;&#21644;&#20869;&#23384;&#20351;&#29992;&#26041;&#38754;&#27604;&#36739;&#20102;&#20256;&#32479;&#36941;&#21382;&#31639;&#27861;&#21644;&#20248;&#21270;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Co-occurrence networks are an important method in the field of natural language processing and text mining for discovering semantic relationships within texts. However, the traditional traversal algorithm for constructing co-occurrence networks has high time complexity and space complexity when dealing with large-scale text data. In this paper, we propose an optimized algorithm based on inverted indexing and breadth-first search to improve the efficiency of co-occurrence network construction and reduce memory consumption. Firstly, the traditional traversal algorithm is analyzed, and its performance issues in constructing co-occurrence networks are identified. Then, the detailed implementation process of the optimized algorithm is presented. Subsequently, the CSL large-scale Chinese scientific literature dataset is used for experimental validation, comparing the performance of the traditional traversal algorithm and the optimized algorithm in terms of running time and memory usage. Fina
&lt;/p&gt;</description></item><item><title>AdaptEx&#26159;&#19968;&#20010;&#33258;&#21161;&#19978;&#19979;&#25991;&#36172;&#21338;&#24179;&#21488;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#20010;&#24615;&#21270;&#29992;&#25143;&#20307;&#39564;&#24182;&#25552;&#20379;&#26368;&#20248;&#35299;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#20256;&#32479;&#27979;&#35797;&#26041;&#27861;&#30340;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;&#23427;&#33021;&#22815;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#20869;&#23481;&#21644;&#8220;&#20919;&#21551;&#21160;&#8221;&#24773;&#20917;&#19979;&#24555;&#36895;&#36845;&#20195;&#12290;</title><link>http://arxiv.org/abs/2308.08650</link><description>&lt;p&gt;
AdaptEx&#65306;&#19968;&#20010;&#33258;&#21161;&#19978;&#19979;&#25991;&#36172;&#21338;&#24179;&#21488;
&lt;/p&gt;
&lt;p&gt;
AdaptEx: A Self-Service Contextual Bandit Platform. (arXiv:2308.08650v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08650
&lt;/p&gt;
&lt;p&gt;
AdaptEx&#26159;&#19968;&#20010;&#33258;&#21161;&#19978;&#19979;&#25991;&#36172;&#21338;&#24179;&#21488;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#20010;&#24615;&#21270;&#29992;&#25143;&#20307;&#39564;&#24182;&#25552;&#20379;&#26368;&#20248;&#35299;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#20256;&#32479;&#27979;&#35797;&#26041;&#27861;&#30340;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;&#23427;&#33021;&#22815;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#20869;&#23481;&#21644;&#8220;&#20919;&#21551;&#21160;&#8221;&#24773;&#20917;&#19979;&#24555;&#36895;&#36845;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;AdaptEx&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;Expedia Group&#24191;&#27867;&#20351;&#29992;&#30340;&#33258;&#21161;&#19978;&#19979;&#25991;&#36172;&#21338;&#24179;&#21488;&#65292;&#23427;&#21033;&#29992;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#20197;&#35268;&#27169;&#21270;&#30340;&#26041;&#24335;&#20010;&#24615;&#21270;&#29992;&#25143;&#20307;&#39564;&#12290;AdaptEx&#32771;&#34385;&#20102;&#27599;&#20010;&#35775;&#38382;&#32773;&#30340;&#29420;&#29305;&#19978;&#19979;&#25991;&#65292;&#36873;&#25321;&#20102;&#26368;&#20248;&#30340;&#21464;&#20307;&#65292;&#24182;&#33021;&#22815;&#24555;&#36895;&#23398;&#20064;&#27599;&#27425;&#20114;&#21160;&#12290;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#26082;&#33021;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#65292;&#21516;&#26102;&#21448;&#33021;&#26368;&#22823;&#38480;&#24230;&#22320;&#20943;&#23569;&#20256;&#32479;&#27979;&#35797;&#26041;&#27861;&#25152;&#38656;&#30340;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;&#35813;&#24179;&#21488;&#33021;&#22815;&#22312;&#20869;&#23481;&#19981;&#26029;&#21464;&#21270;&#21644;&#25345;&#32493;&#8220;&#20919;&#21551;&#21160;&#8221;&#24773;&#20917;&#19979;&#65292;&#20248;&#38597;&#22320;&#24555;&#36895;&#36845;&#20195;&#26397;&#30528;&#26368;&#20248;&#35299;&#21069;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents AdaptEx, a self-service contextual bandit platform widely used at Expedia Group, that leverages multi-armed bandit algorithms to personalize user experiences at scale. AdaptEx considers the unique context of each visitor to select the optimal variants and learns quickly from every interaction they make. It offers a powerful solution to improve user experiences while minimizing the costs and time associated with traditional testing methods. The platform unlocks the ability to iterate towards optimal product solutions quickly, even in ever-changing content and continuous "cold start" situations gracefully.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GTGS&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#36807;&#28193;&#36229;&#22270;&#21367;&#31215;&#23618;&#21644;&#33258;&#30417;&#30563;&#23398;&#20064;&#26469;&#35299;&#20915;&#32676;&#32452;&#35782;&#21035;&#20219;&#21153;&#20013;&#30340;&#25361;&#25112;&#12290;&#35813;&#26694;&#26550;&#20805;&#20998;&#21033;&#29992;&#29992;&#25143;&#23545;&#39033;&#30446;&#30340;&#20559;&#22909;&#65292;&#39044;&#27979;&#29992;&#25143;&#23545;&#32676;&#32452;&#30340;&#20559;&#22909;&#12290;</title><link>http://arxiv.org/abs/2308.08620</link><description>&lt;p&gt;
&#36890;&#36807;&#36328;&#35270;&#35282;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#36807;&#28193;&#36229;&#22270;&#21367;&#31215;&#23454;&#29616;&#32676;&#32452;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Group Identification via Transitional Hypergraph Convolution with Cross-view Self-supervised Learning. (arXiv:2308.08620v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08620
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GTGS&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#36807;&#28193;&#36229;&#22270;&#21367;&#31215;&#23618;&#21644;&#33258;&#30417;&#30563;&#23398;&#20064;&#26469;&#35299;&#20915;&#32676;&#32452;&#35782;&#21035;&#20219;&#21153;&#20013;&#30340;&#25361;&#25112;&#12290;&#35813;&#26694;&#26550;&#20805;&#20998;&#21033;&#29992;&#29992;&#25143;&#23545;&#39033;&#30446;&#30340;&#20559;&#22909;&#65292;&#39044;&#27979;&#29992;&#25143;&#23545;&#32676;&#32452;&#30340;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#30340;&#26222;&#21450;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#29992;&#25143;&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#23547;&#25214;&#24182;&#21442;&#21152;&#32676;&#32452;&#27963;&#21160;&#12290;&#36825;&#23601;&#38656;&#35201;&#23545;&#32676;&#32452;&#35782;&#21035;&#65288;GI&#65289;&#20219;&#21153;&#36827;&#34892;&#30740;&#31350;&#65292;&#21363;&#20026;&#29992;&#25143;&#25512;&#33616;&#32676;&#32452;&#12290;&#36825;&#20010;&#20219;&#21153;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#22914;&#20309;&#22522;&#20110;&#29992;&#25143;&#20197;&#24448;&#30340;&#32676;&#32452;&#21442;&#19982;&#21644;&#29992;&#25143;&#23545;&#39033;&#30446;&#30340;&#20852;&#36259;&#65292;&#39044;&#27979;&#29992;&#25143;&#23545;&#32676;&#32452;&#30340;&#20559;&#22909;&#12290;&#23613;&#31649;&#26368;&#36817;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#25104;&#21151;&#23884;&#20837;&#22810;&#31867;&#23545;&#35937;&#65292;&#20294;&#23427;&#20204;&#26080;&#27861;&#20840;&#38754;&#35299;&#20915;&#36825;&#20010;GI&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#36807;&#28193;&#36229;&#22270;&#21367;&#31215;&#19982;&#22270;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#32676;&#32452;&#35782;&#21035;&#26032;&#26694;&#26550;&#65288;GTGS&#65289;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36807;&#28193;&#36229;&#22270;&#21367;&#31215;&#23618;&#65292;&#20197;&#21033;&#29992;&#29992;&#25143;&#23545;&#39033;&#30446;&#30340;&#20559;&#22909;&#20316;&#20026;&#20808;&#39564;&#30693;&#35782;&#65292;&#24110;&#21161;&#23547;&#25214;&#20854;&#23545;&#32676;&#32452;&#30340;&#20559;&#22909;&#12290;&#20026;&#20102;&#26500;&#24314;&#32508;&#21512;&#30340;&#29992;&#25143;/&#32676;&#32452;&#34920;&#31034;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#26469;&#23436;&#25104;GI&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the proliferation of social media, a growing number of users search for and join group activities in their daily life. This develops a need for the study on the group identification (GI) task, i.e., recommending groups to users. The major challenge in this task is how to predict users' preferences for groups based on not only previous group participation of users but also users' interests in items. Although recent developments in Graph Neural Networks (GNNs) accomplish embedding multiple types of objects in graph-based recommender systems, they, however, fail to address this GI problem comprehensively. In this paper, we propose a novel framework named Group Identification via Transitional Hypergraph Convolution with Graph Self-supervised Learning (GTGS). We devise a novel transitional hypergraph convolution layer to leverage users' preferences for items as prior knowledge when seeking their group preferences. To construct comprehensive user/group representations for GI task, we de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#30340;&#22810;&#26041;&#20301;&#26694;&#26550;&#65288;KMF&#65289;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#25552;&#21462;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#20027;&#39064;&#26469;&#22686;&#24378;&#26631;&#31614;&#35821;&#20041;&#65292;&#20197;&#25913;&#21892;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.08563</link><description>&lt;p&gt;
KMF: &#22522;&#20110;&#30693;&#35782;&#30340;&#22810;&#26041;&#20301;&#34920;&#31034;&#23398;&#20064;&#29992;&#20110;&#38646;&#26679;&#26412;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
KMF: Knowledge-Aware Multi-Faceted Representation Learning for Zero-Shot Node Classification. (arXiv:2308.08563v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#30340;&#22810;&#26041;&#20301;&#26694;&#26550;&#65288;KMF&#65289;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#25552;&#21462;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#20027;&#39064;&#26469;&#22686;&#24378;&#26631;&#31614;&#35821;&#20041;&#65292;&#20197;&#25913;&#21892;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38646;&#26679;&#26412;&#33410;&#28857;&#20998;&#31867;&#65288;ZNC&#65289;&#22312;&#22270;&#25968;&#25454;&#20998;&#26512;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#35813;&#20219;&#21153;&#26088;&#22312;&#39044;&#27979;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26410;&#35266;&#23519;&#21040;&#30340;&#26410;&#30693;&#31867;&#21035;&#30340;&#33410;&#28857;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#20027;&#35201;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#23558;&#29305;&#24449;&#30340;&#21407;&#22411;&#21644;&#26631;&#31614;&#30340;&#35821;&#20041;&#32852;&#31995;&#36215;&#26469;&#65292;&#20174;&#32780;&#23454;&#29616;&#20174;&#24050;&#35266;&#23519;&#21040;&#30340;&#31867;&#21035;&#21040;&#26410;&#35266;&#23519;&#21040;&#30340;&#31867;&#21035;&#30340;&#30693;&#35782;&#36801;&#31227;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#30740;&#31350;&#24573;&#35270;&#20102;&#29305;&#24449;-&#35821;&#20041;&#23545;&#40784;&#20013;&#22810;&#26041;&#20301;&#35821;&#20041;&#26041;&#21521;&#30340;&#23384;&#22312;&#65292;&#21363;&#33410;&#28857;&#30340;&#20869;&#23481;&#36890;&#24120;&#28085;&#30422;&#19982;&#22810;&#20010;&#26631;&#31614;&#30340;&#35821;&#20041;&#30456;&#20851;&#30340;&#19981;&#21516;&#20027;&#39064;&#12290;&#22240;&#27492;&#65292;&#26377;&#24517;&#35201;&#21306;&#20998;&#21644;&#21028;&#26029;&#24433;&#21709;&#35748;&#30693;&#33021;&#21147;&#30340;&#35821;&#20041;&#22240;&#32032;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#30340;&#22810;&#26041;&#20301;&#26694;&#26550;&#65288;KMF&#65289;&#65292;&#36890;&#36807;&#25552;&#21462;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#30340;&#20027;&#39064;&#26469;&#22686;&#24378;&#26631;&#31614;&#35821;&#20041;&#30340;&#20016;&#23500;&#24615;&#12290;&#28982;&#21518;&#65292;&#23558;&#27599;&#20010;&#33410;&#28857;&#30340;&#20869;&#23481;&#37325;&#26500;&#20026;&#20027;&#39064;&#32423;&#21035;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, Zero-Shot Node Classification (ZNC) has been an emerging and crucial task in graph data analysis. This task aims to predict nodes from unseen classes which are unobserved in the training process. Existing work mainly utilizes Graph Neural Networks (GNNs) to associate features' prototypes and labels' semantics thus enabling knowledge transfer from seen to unseen classes. However, the multi-faceted semantic orientation in the feature-semantic alignment has been neglected by previous work, i.e. the content of a node usually covers diverse topics that are relevant to the semantics of multiple labels. It's necessary to separate and judge the semantic factors that tremendously affect the cognitive ability to improve the generality of models. To this end, we propose a Knowledge-Aware Multi-Faceted framework (KMF) that enhances the richness of label semantics via the extracted KG (Knowledge Graph)-based topics. And then the content of each node is reconstructed to a topic-level repre
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#23432;&#21452;&#37325;&#31283;&#20581;&#31574;&#30053;&#65288;CDR&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30340;&#26377;&#27602;&#25554;&#34917;&#38382;&#39064;&#12290;CDR&#36890;&#36807;&#23457;&#26597;&#25554;&#34917;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#26469;&#36807;&#28388;&#25554;&#34917;&#65292;&#32467;&#26524;&#26174;&#31034;CDR&#20855;&#26377;&#38477;&#20302;&#26041;&#24046;&#21644;&#25913;&#36827;&#23614;&#37096;&#30028;&#38480;&#30340;&#20248;&#21183;&#65292;&#24182;&#19988;&#33021;&#22815;&#26174;&#33879;&#25552;&#21319;&#24615;&#33021;&#24182;&#20943;&#23569;&#26377;&#27602;&#25554;&#34917;&#30340;&#39057;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.08461</link><description>&lt;p&gt;
CDR&#65306;&#29992;&#20110;&#21435;&#20559;&#25512;&#33616;&#30340;&#20445;&#23432;&#21452;&#37325;&#31283;&#20581;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
CDR: Conservative Doubly Robust Learning for Debiased Recommendation. (arXiv:2308.08461v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08461
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#23432;&#21452;&#37325;&#31283;&#20581;&#31574;&#30053;&#65288;CDR&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30340;&#26377;&#27602;&#25554;&#34917;&#38382;&#39064;&#12290;CDR&#36890;&#36807;&#23457;&#26597;&#25554;&#34917;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#26469;&#36807;&#28388;&#25554;&#34917;&#65292;&#32467;&#26524;&#26174;&#31034;CDR&#20855;&#26377;&#38477;&#20302;&#26041;&#24046;&#21644;&#25913;&#36827;&#23614;&#37096;&#30028;&#38480;&#30340;&#20248;&#21183;&#65292;&#24182;&#19988;&#33021;&#22815;&#26174;&#33879;&#25552;&#21319;&#24615;&#33021;&#24182;&#20943;&#23569;&#26377;&#27602;&#25554;&#34917;&#30340;&#39057;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#24448;&#24448;&#26159;&#35266;&#23519;&#24615;&#30340;&#32780;&#19981;&#26159;&#23454;&#39564;&#24615;&#30340;&#65292;&#23548;&#33268;&#25968;&#25454;&#20013;&#26222;&#36941;&#23384;&#22312;&#20559;&#24046;&#12290;&#22240;&#27492;&#65292;&#35299;&#20915;&#20559;&#24046;&#38382;&#39064;&#24050;&#25104;&#20026;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#26368;&#36817;&#65292;&#21452;&#37325;&#31283;&#20581;&#23398;&#20064;&#65288;DR&#65289;&#30001;&#20110;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#21644;&#31283;&#20581;&#30340;&#29305;&#24615;&#32780;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#26377;&#30340;DR&#26041;&#27861;&#22312;&#23384;&#22312;&#25152;&#35859;&#30340;&#26377;&#27602;&#25554;&#34917;&#65288;Poisonous Imputation&#65289;&#26102;&#21463;&#21040;&#20005;&#37325;&#24433;&#21709;&#65292;&#25554;&#34917;&#26126;&#26174;&#20559;&#31163;&#30495;&#23454;&#25968;&#25454;&#24182;&#36866;&#24471;&#20854;&#21453;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#23432;&#21452;&#37325;&#31283;&#20581;&#31574;&#30053;&#65288;CDR&#65289;&#65292;&#36890;&#36807;&#23457;&#26597;&#25554;&#34917;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#26469;&#36807;&#28388;&#25554;&#34917;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;CDR&#21487;&#20197;&#38477;&#20302;&#26041;&#24046;&#24182;&#25913;&#36827;&#23614;&#37096;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;CDR&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#65292;&#24182;&#19988;&#30830;&#23454;&#20943;&#23569;&#20102;&#26377;&#27602;&#25554;&#34917;&#30340;&#39057;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive.  To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20174;&#29992;&#25143;&#34892;&#20026;&#20449;&#24687;&#20013;&#25552;&#21462;&#21644;&#34701;&#21512;&#24322;&#26500;&#30693;&#35782;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#25351;&#20196;&#35843;&#25972;&#23454;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.03333</link><description>&lt;p&gt;
&#24322;&#26500;&#30693;&#35782;&#34701;&#21512;: &#36890;&#36807;LLM&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM. (arXiv:2308.03333v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03333
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20174;&#29992;&#25143;&#34892;&#20026;&#20449;&#24687;&#20013;&#25552;&#21462;&#21644;&#34701;&#21512;&#24322;&#26500;&#30693;&#35782;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#25351;&#20196;&#35843;&#25972;&#23454;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#21644;&#25366;&#25496;&#29992;&#25143;&#24322;&#26500;&#34892;&#20026;&#23545;&#20110;&#25512;&#33616;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23558;&#21508;&#31181;&#31867;&#22411;&#30340;&#24322;&#26500;&#34892;&#20026;&#32435;&#20837;&#25512;&#33616;&#27169;&#22411;&#30340;&#24120;&#35268;&#26041;&#27861;&#20250;&#23548;&#33268;&#29305;&#24449;&#31232;&#30095;&#21644;&#30693;&#35782;&#30862;&#29255;&#21270;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20174;&#29992;&#25143;&#24322;&#26500;&#34892;&#20026;&#20449;&#24687;&#20013;&#25552;&#21462;&#21644;&#34701;&#21512;&#24322;&#26500;&#30693;&#35782;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#24322;&#26500;&#30693;&#35782;&#21644;&#25512;&#33616;&#20219;&#21153;&#32467;&#21512;&#65292;&#23545;LLM&#36827;&#34892;&#25351;&#20196;&#35843;&#25972;&#20197;&#23454;&#29616;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#25972;&#21512;&#29992;&#25143;&#24322;&#26500;&#34892;&#20026;&#24182;&#26174;&#33879;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The analysis and mining of user heterogeneous behavior are of paramount importance in recommendation systems. However, the conventional approach of incorporating various types of heterogeneous behavior into recommendation models leads to feature sparsity and knowledge fragmentation issues. To address this challenge, we propose a novel approach for personalized recommendation via Large Language Model (LLM), by extracting and fusing heterogeneous knowledge from user heterogeneous behavior information. In addition, by combining heterogeneous knowledge and recommendation tasks, instruction tuning is performed on LLM for personalized recommendations. The experimental results demonstrate that our method can effectively integrate user heterogeneous behavior and significantly improve recommendation performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#21516;&#36807;&#28388;&#35757;&#32451;&#20013;&#32500;&#24230;&#26080;&#20851;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#28151;&#21512;&#26041;&#27861;&#65288;DINS&#65289;&#65292;&#36890;&#36807;&#23545;&#37319;&#26679;&#21306;&#22495;&#30340;&#26032;&#35270;&#35282;&#36827;&#34892;&#37325;&#26032;&#23457;&#35270;&#26469;&#25913;&#36827;&#29616;&#26377;&#30340;&#37319;&#26679;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;DINS&#20248;&#20110;&#20854;&#20182;&#36127;&#37319;&#26679;&#26041;&#27861;&#65292;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.15905</link><description>&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#20013;&#32500;&#24230;&#26080;&#20851;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#28151;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Dimension Independent Mixup for Hard Negative Sample in Collaborative Filtering. (arXiv:2306.15905v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#21516;&#36807;&#28388;&#35757;&#32451;&#20013;&#32500;&#24230;&#26080;&#20851;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#28151;&#21512;&#26041;&#27861;&#65288;DINS&#65289;&#65292;&#36890;&#36807;&#23545;&#37319;&#26679;&#21306;&#22495;&#30340;&#26032;&#35270;&#35282;&#36827;&#34892;&#37325;&#26032;&#23457;&#35270;&#26469;&#25913;&#36827;&#29616;&#26377;&#30340;&#37319;&#26679;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;DINS&#20248;&#20110;&#20854;&#20182;&#36127;&#37319;&#26679;&#26041;&#27861;&#65292;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#22522;&#20110;&#36807;&#21435;&#30340;&#20114;&#21160;&#39044;&#27979;&#29992;&#25143;&#30340;&#20559;&#22909;&#12290;&#36127;&#37319;&#26679;&#22312;&#20351;&#29992;&#38544;&#24335;&#21453;&#39304;&#35757;&#32451;&#22522;&#20110;CF&#30340;&#27169;&#22411;&#26102;&#36215;&#21040;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37319;&#26679;&#21306;&#22495;&#30340;&#26032;&#35270;&#35282;&#26469;&#37325;&#26032;&#23457;&#35270;&#29616;&#26377;&#30340;&#37319;&#26679;&#26041;&#27861;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;&#30446;&#21069;&#30340;&#37319;&#26679;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#28857;&#37319;&#26679;&#25110;&#32447;&#37319;&#26679;&#19978;&#65292;&#32570;&#20047;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#26377;&#30456;&#24403;&#22823;&#19968;&#37096;&#20998;&#22256;&#38590;&#37319;&#26679;&#21306;&#22495;&#26410;&#34987;&#25506;&#32034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32500;&#24230;&#26080;&#20851;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#28151;&#21512;&#26041;&#27861;&#65288;DINS&#65289;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#38024;&#23545;&#35757;&#32451;&#22522;&#20110;CF&#30340;&#27169;&#22411;&#30340;&#21306;&#22495;&#37319;&#26679;&#26041;&#27861;&#12290;DINS&#21253;&#25324;&#19977;&#20010;&#27169;&#22359;&#65306;&#22256;&#38590;&#36793;&#30028;&#23450;&#20041;&#12289;&#32500;&#24230;&#26080;&#20851;&#28151;&#21512;&#21644;&#22810;&#36339;&#27744;&#21270;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;DINS&#20248;&#20110;&#20854;&#20182;&#36127;&#37319;&#26679;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#23427;&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative filtering (CF) is a widely employed technique that predicts user preferences based on past interactions. Negative sampling plays a vital role in training CF-based models with implicit feedback. In this paper, we propose a novel perspective based on the sampling area to revisit existing sampling methods. We point out that current sampling methods mainly focus on Point-wise or Line-wise sampling, lacking flexibility and leaving a significant portion of the hard sampling area un-explored. To address this limitation, we propose Dimension Independent Mixup for Hard Negative Sampling (DINS), which is the first Area-wise sampling method for training CF-based models. DINS comprises three modules: Hard Boundary Definition, Dimension Independent Mixup, and Multi-hop Pooling. Experiments with real-world datasets on both matrix factorization and graph-based models demonstrate that DINS outperforms other negative sampling methods, establishing its effectiveness and superiority. Our wo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#27169;&#31946;&#20559;&#22909;&#22810;&#36718;&#20250;&#35805;&#25512;&#33616;&#8221;&#65288;VPMCR&#65289;&#30340;&#26032;&#22330;&#26223;&#65292;&#32771;&#34385;&#20102;&#29992;&#25143;&#22312; CRS &#20013;&#30340;&#27169;&#31946;&#21644;&#27874;&#21160;&#30340;&#20559;&#22909;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#36719;&#20272;&#35745;&#26426;&#21046;&#36991;&#20813;&#36807;&#28388;&#36807;&#24230;&#65292;&#24182;&#36890;&#36807;&#33258;&#36866;&#24212;&#27169;&#31946;&#20559;&#22909;&#31574;&#30053;&#23398;&#20064;&#26694;&#26550;&#33719;&#24471;&#20102;&#23454;&#39564;&#19978;&#30340;&#33391;&#22909;&#25512;&#33616;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.04487</link><description>&lt;p&gt;
&#25509;&#21463;&#19981;&#30830;&#23450;&#24615;&#65306;&#33258;&#36866;&#24212;&#27169;&#31946;&#20559;&#22909;&#31574;&#30053;&#23398;&#20064;&#29992;&#20110;&#22810;&#36718;&#20250;&#35805;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Embracing Uncertainty: Adaptive Vague Preference Policy Learning for Multi-round Conversational Recommendation. (arXiv:2306.04487v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#27169;&#31946;&#20559;&#22909;&#22810;&#36718;&#20250;&#35805;&#25512;&#33616;&#8221;&#65288;VPMCR&#65289;&#30340;&#26032;&#22330;&#26223;&#65292;&#32771;&#34385;&#20102;&#29992;&#25143;&#22312; CRS &#20013;&#30340;&#27169;&#31946;&#21644;&#27874;&#21160;&#30340;&#20559;&#22909;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#36719;&#20272;&#35745;&#26426;&#21046;&#36991;&#20813;&#36807;&#28388;&#36807;&#24230;&#65292;&#24182;&#36890;&#36807;&#33258;&#36866;&#24212;&#27169;&#31946;&#20559;&#22909;&#31574;&#30053;&#23398;&#20064;&#26694;&#26550;&#33719;&#24471;&#20102;&#23454;&#39564;&#19978;&#30340;&#33391;&#22909;&#25512;&#33616;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479; (CRS) &#36890;&#36807;&#22810;&#36718;&#20132;&#20114;&#65292;&#21160;&#24577;&#24341;&#23548;&#29992;&#25143;&#34920;&#36798;&#20559;&#22909;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20449;&#24687;&#19981;&#23545;&#31216;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340; CRS &#22522;&#26412;&#19978;&#20551;&#35774;&#29992;&#25143;&#26377;&#26126;&#30830;&#30340;&#20559;&#22909;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20195;&#29702;&#23558;&#23436;&#20840;&#20449;&#20219;&#29992;&#25143;&#21453;&#39304;&#65292;&#24182;&#23558;&#25509;&#21463;&#25110;&#25298;&#32477;&#20449;&#21495;&#35270;&#20026;&#36807;&#28388;&#39033;&#30446;&#21644;&#20943;&#23569;&#20505;&#36873;&#31354;&#38388;&#30340;&#24378;&#25351;&#26631;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#36807;&#28388;&#36807;&#24230;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#20013;&#65292;&#29992;&#25143;&#30340;&#20559;&#22909;&#24448;&#24448;&#26159;&#27169;&#31946;&#21644;&#27874;&#21160;&#30340;&#65292;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#65292;&#20182;&#20204;&#22312;&#20132;&#20114;&#36807;&#31243;&#20013;&#30340;&#24895;&#26395;&#21644;&#20915;&#31574;&#21487;&#33021;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22330;&#26223;&#65292;&#31216;&#20026;&#8220;&#27169;&#31946;&#20559;&#22909;&#22810;&#36718;&#20250;&#35805;&#25512;&#33616;&#8221;&#65288;VPMCR&#65289;&#65292;&#23427;&#32771;&#34385;&#21040;&#29992;&#25143;&#22312; CRS &#20013;&#30340;&#27169;&#31946;&#21644;&#27874;&#21160;&#30340;&#20559;&#22909;&#12290;VPMCR &#37319;&#29992;&#36719;&#20272;&#35745;&#26426;&#21046;&#20026;&#25152;&#26377;&#20505;&#36873;&#39033;&#30446;&#20998;&#37197;&#38750;&#38646;&#32622;&#20449;&#24230;&#20998;&#25968;&#65292;&#33258;&#28982;&#22320;&#36991;&#20813;&#20102;&#36807;&#28388;&#36807;&#24230;&#30340;&#38382;&#39064;&#12290;&#22312; VPMCR &#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27169;&#31946;&#20559;&#22909;&#31574;&#30053;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#21644;&#20559;&#22909;&#24341;&#23548;&#26469;&#23398;&#20064; CRS &#20195;&#29702;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#22312;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#36739;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340; VPMCR &#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational recommendation systems (CRS) effectively address information asymmetry by dynamically eliciting user preferences through multi-turn interactions. Existing CRS widely assumes that users have clear preferences. Under this assumption, the agent will completely trust the user feedback and treat the accepted or rejected signals as strong indicators to filter items and reduce the candidate space, which may lead to the problem of over-filtering. However, in reality, users' preferences are often vague and volatile, with uncertainty about their desires and changing decisions during interactions.  To address this issue, we introduce a novel scenario called Vague Preference Multi-round Conversational Recommendation (VPMCR), which considers users' vague and volatile preferences in CRS.VPMCR employs a soft estimation mechanism to assign a non-zero confidence score for all candidate items to be displayed, naturally avoiding the over-filtering problem. In the VPMCR setting, we introduc
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20986;&#20102;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#20004;&#31181;&#27169;&#22411;&#33539;&#24335;&#65292;&#24635;&#32467;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24378;&#35843;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2305.19860</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Large Language Models for Recommendation. (arXiv:2305.19860v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20986;&#20102;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#20004;&#31181;&#27169;&#22411;&#33539;&#24335;&#65292;&#24635;&#32467;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24378;&#35843;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#24182;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#24341;&#36215;&#20102;&#37325;&#35270;&#12290;&#36825;&#20123;&#27169;&#22411;&#20351;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#28023;&#37327;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#24050;&#22312;&#23398;&#20064;&#36890;&#29992;&#34920;&#31034;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#30528;&#25104;&#21151;&#65292;&#24182;&#26377;&#21487;&#33021;&#36890;&#36807;&#19968;&#20123;&#26377;&#25928;&#30340;&#36716;&#31227;&#25216;&#26415;&#65288;&#22914;&#24494;&#35843;&#21644;&#25552;&#31034;&#35843;&#25972;&#65289;&#31561;&#25163;&#27573;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#21508;&#20010;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#25512;&#33616;&#36136;&#37327;&#30340;&#20851;&#38190;&#26159;&#21033;&#29992;&#23427;&#20204;&#39640;&#36136;&#37327;&#30340;&#25991;&#26412;&#29305;&#24449;&#34920;&#31034;&#21644;&#22823;&#37327;&#30340;&#22806;&#37096;&#30693;&#35782;&#35206;&#30422;&#65292;&#24314;&#31435;&#39033;&#30446;&#21644;&#29992;&#25143;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#20102;&#20840;&#38754;&#20102;&#35299;&#29616;&#26377;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#26412;&#32508;&#36848;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#20998;&#20026;&#20004;&#31181;&#20027;&#35201;&#33539;&#24335;&#65292;&#20998;&#21035;&#26159;&#21028;&#21035;&#24335;LLMs&#21644;&#29983;&#25104;&#24335;LLMs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#36825;&#20123;&#33539;&#24335;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#24378;&#35843;&#20102;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#24320;&#25918;&#24615;&#30740;&#31350;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have emerged as powerful tools in the field of Natural Language Processing (NLP) and have recently gained significant attention in the domain of Recommendation Systems (RS). These models, trained on massive amounts of data using self-supervised learning, have demonstrated remarkable success in learning universal representations and have the potential to enhance various aspects of recommendation systems by some effective transfer techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect of harnessing the power of language models in enhancing recommendation quality is the utilization of their high-quality representations of textual features and their extensive coverage of external knowledge to establish correlations between items and users. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey presents a taxonomy that categorizes these models into two major paradigms, respectively Discrimi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#24863;&#30693;&#30340;&#25512;&#33616;&#31995;&#32479;&#26041;&#27861;&#65292;&#20351;&#29992;&#23545;&#27604;&#21453;&#20107;&#23454;&#23398;&#20064;&#26469;&#23398;&#20064;&#40065;&#26834;&#19988;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#21453;&#20107;&#23454;&#25512;&#29702;&#26469;&#20272;&#35745;&#25512;&#33616;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#30830;&#23450;&#26377;&#21161;&#20110;&#29992;&#25143;&#34892;&#20026;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2208.06746</link><description>&lt;p&gt;
&#22240;&#26524;&#24863;&#30693;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;&#30340;&#23545;&#27604;&#21453;&#20107;&#23454;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems. (arXiv:2208.06746v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06746
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#24863;&#30693;&#30340;&#25512;&#33616;&#31995;&#32479;&#26041;&#27861;&#65292;&#20351;&#29992;&#23545;&#27604;&#21453;&#20107;&#23454;&#23398;&#20064;&#26469;&#23398;&#20064;&#40065;&#26834;&#19988;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#21453;&#20107;&#23454;&#25512;&#29702;&#26469;&#20272;&#35745;&#25512;&#33616;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#30830;&#23450;&#26377;&#21161;&#20110;&#29992;&#25143;&#34892;&#20026;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#19979;&#29983;&#25104;&#25512;&#33616;&#30340;&#30740;&#31350;&#26377;&#25152;&#22686;&#21152;&#65292;&#25512;&#33616;&#34987;&#35270;&#20026;&#19968;&#31181;&#22788;&#29702;&#65292;&#26088;&#22312;&#21152;&#24378;&#25105;&#20204;&#23545;&#25512;&#33616;&#22914;&#20309;&#24433;&#21709;&#29992;&#25143;&#34892;&#20026;&#30340;&#29702;&#35299;&#65292;&#24182;&#20801;&#35768;&#30830;&#23450;&#26377;&#21161;&#20110;&#35813;&#24433;&#21709;&#30340;&#22240;&#32032;&#12290;&#35768;&#22810;&#22240;&#26524;&#25512;&#26029;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#19987;&#27880;&#20110;&#20351;&#29992;&#20542;&#21521;&#20998;&#25968;&#65292;&#36825;&#21487;&#20197;&#20943;&#23569;&#20559;&#24046;&#65292;&#20294;&#21487;&#33021;&#20250;&#24341;&#20837;&#39069;&#22806;&#30340;&#24046;&#24322;&#12290;&#20854;&#20182;&#30740;&#31350;&#21017;&#25552;&#20986;&#20351;&#29992;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#30340;&#26080;&#20559;&#25968;&#25454;&#65292;&#19981;&#36807;&#36825;&#31181;&#26041;&#27861;&#38656;&#35201;&#28385;&#36275;&#19968;&#23450;&#30340;&#20551;&#35774;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#38590;&#20197;&#28385;&#36275;&#12290;&#26412;&#25991;&#39318;&#20808;&#25506;&#35752;&#20102;&#25512;&#33616;&#30340;&#22240;&#26524;&#24863;&#30693;&#35299;&#37322;&#65292;&#24182;&#34920;&#26126;&#24213;&#23618;&#30340;&#26292;&#38706;&#26426;&#21046;&#21487;&#20197;&#20559;&#21521;&#20110;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#30340;&#35266;&#27979;&#21453;&#39304;&#12290;&#37492;&#20110;&#28151;&#28102;&#22240;&#32032;&#21487;&#33021;&#26080;&#27861;&#27979;&#37327;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#23545;&#27604;S&#23545;&#21453;&#20107;&#23454;&#23398;&#20064;&#65288;CCL&#65289;&#26469;&#23398;&#20064;&#40065;&#26834;&#19988;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#21453;&#20107;&#23454;&#25512;&#29702;&#26469;&#20272;&#35745;&#25512;&#33616;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#30830;&#23450;&#26377;&#21161;&#20110;&#29992;&#25143;&#34892;&#20026;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been a recent surge in the study of generating recommendations within the framework of causal inference, with the recommendation being treated as a treatment. This approach enhances our understanding of how recommendations influence user behaviour and allows for identification of the factors that contribute to this impact. Many researchers in the field of causal inference for recommender systems have focused on using propensity scores, which can reduce bias but may also introduce additional variance. Other studies have proposed the use of unbiased data from randomized controlled trials, though this approach requires certain assumptions that may be difficult to satisfy in practice. In this paper, we first explore the causality-aware interpretation of recommendations and show that the underlying exposure mechanism can bias the maximum likelihood estimation (MLE) of observational feedback. Given that confounders may be inaccessible for measurement, we propose using contrastive S
&lt;/p&gt;</description></item></channel></rss>