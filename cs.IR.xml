<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#37319;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#25351;&#20196;&#36981;&#24490;&#20026;&#26041;&#27861;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23558;&#29992;&#25143;&#20559;&#22909;&#25110;&#38656;&#27714;&#36827;&#34892;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#65292;&#36827;&#32780;&#25552;&#39640;&#25512;&#33616;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.07001</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20316;&#20026;&#25351;&#20196;&#36981;&#24490;&#30340;&#26041;&#27861;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#30340;&#25512;&#33616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach. (arXiv:2305.07001v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07001
&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#25351;&#20196;&#36981;&#24490;&#20026;&#26041;&#27861;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23558;&#29992;&#25143;&#20559;&#22909;&#25110;&#38656;&#27714;&#36827;&#34892;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#65292;&#36827;&#32780;&#25552;&#39640;&#25512;&#33616;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#22312;&#30740;&#31350;&#21644;&#20135;&#19994;&#31038;&#21306;&#20013;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#24182;&#19988;&#35768;&#22810;&#30740;&#31350;&#33268;&#21147;&#20110;&#24320;&#21457;&#26377;&#25928;&#30340;&#25512;&#33616;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#20027;&#35201;&#20174;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#23398;&#20064;&#28508;&#22312;&#30340;&#29992;&#25143;&#20559;&#22909;&#65292;&#36827;&#32780;&#20272;&#35745;&#29992;&#25143;-&#39033;&#30446;&#21305;&#37197;&#20851;&#31995;&#20197;&#36827;&#34892;&#25512;&#33616;&#12290;&#21463;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36817;&#26399;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#24320;&#21457;&#25512;&#33616;&#27169;&#22411;&#65292;&#23558;&#25512;&#33616;&#35270;&#20026;LLMs&#30340;&#25351;&#20196;&#36981;&#24490;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#29992;&#25143;&#30340;&#20559;&#22909;&#25110;&#38656;&#27714;&#21487;&#20197;&#29992;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#65288;&#31216;&#20026;&#25351;&#20196;&#65289;&#26469;&#34920;&#36798;&#65292;&#20174;&#32780;LLMs&#21487;&#20197;&#29702;&#35299;&#24182;&#36827;&#19968;&#27493;&#25191;&#34892;&#25351;&#20196;&#20197;&#36798;&#21040;&#25512;&#33616;&#20219;&#21153;&#30340;&#30446;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#25351;&#20196;&#24494;&#35843;&#24320;&#28304;LLM&#65288;3B Flan-T5-XL&#65289;&#26469;&#24320;&#21457;&#25512;&#33616;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#20351;LLMs&#36866;&#24212;&#25512;&#33616;&#31995;&#32479;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#25442;&#26041;&#27861;&#65292;&#23558;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#36716;&#21270;&#20026;&#25351;&#20196;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#25512;&#33616;&#26041;&#27861;&#65292;&#22312;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the past decades, recommender systems have attracted much attention in both research and industry communities, and a large number of studies have been devoted to developing effective recommendation models. Basically speaking, these models mainly learn the underlying user preference from historical behavior data, and then estimate the user-item matching relationships for recommendations. Inspired by the recent progress on large language models (LLMs), we take a different approach to developing the recommendation models, considering recommendation as instruction following by LLMs. The key idea is that the preferences or needs of a user can be expressed in natural language descriptions (called instructions), so that LLMs can understand and further execute the instruction for fulfilling the recommendation task. Instead of using public APIs of LLMs, we instruction tune an open-source LLM (3B Flan-T5-XL), in order to better adapt LLMs to recommender systems. For this purpose, we first des
&lt;/p&gt;</description></item><item><title>AfriQA&#26159;&#31532;&#19968;&#20010;&#19987;&#27880;&#20110;&#38750;&#27954;&#35821;&#35328;&#30340;&#36328;&#35821;&#35328;QA&#25968;&#25454;&#38598;&#65292;&#24357;&#34917;&#20102;&#38750;&#27954;&#35821;&#35328;&#25968;&#23383;&#21270;&#20869;&#23481;&#19981;&#36275;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#33258;&#21160;&#32763;&#35793;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#36739;&#24046;&#65292;&#38656;&#35201;&#25903;&#25345;&#36328;&#35821;&#35328;&#25512;&#29702;&#21644;&#36716;&#31227;&#23398;&#20064;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.06897</link><description>&lt;p&gt;
AfriQA&#65306;&#38024;&#23545;&#38750;&#27954;&#35821;&#35328;&#30340;&#36328;&#35821;&#35328;&#24320;&#25918;&#26816;&#32034;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages. (arXiv:2305.06897v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06897
&lt;/p&gt;
&lt;p&gt;
AfriQA&#26159;&#31532;&#19968;&#20010;&#19987;&#27880;&#20110;&#38750;&#27954;&#35821;&#35328;&#30340;&#36328;&#35821;&#35328;QA&#25968;&#25454;&#38598;&#65292;&#24357;&#34917;&#20102;&#38750;&#27954;&#35821;&#35328;&#25968;&#23383;&#21270;&#20869;&#23481;&#19981;&#36275;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#33258;&#21160;&#32763;&#35793;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#36739;&#24046;&#65292;&#38656;&#35201;&#25903;&#25345;&#36328;&#35821;&#35328;&#25512;&#29702;&#21644;&#36716;&#31227;&#23398;&#20064;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#21270;&#30340;&#38750;&#27954;&#35821;&#35328;&#20869;&#23481;&#36828;&#36828;&#19981;&#36275;&#65292;&#36825;&#20351;&#24471;&#38382;&#31572;&#31995;&#32479;&#38590;&#20197;&#28385;&#36275;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;&#36328;&#35821;&#35328;&#24320;&#25918;&#26816;&#32034;&#38382;&#31572;&#65288;XOR QA&#65289;&#31995;&#32479;--&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#22312;&#20026;&#20154;&#20204;&#25552;&#20379;&#26412;&#22320;&#35821;&#35328;&#26381;&#21153;&#30340;&#21516;&#26102;&#20174;&#20854;&#20182;&#35821;&#35328;&#20013;&#33719;&#21462;&#31572;&#26696;&#20869;&#23481;--&#25552;&#20379;&#20102;&#19968;&#31181;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#30340;&#25163;&#27573;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;AfriQA&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#19987;&#27880;&#20110;&#38750;&#27954;&#35821;&#35328;&#30340;&#36328;&#35821;&#35328;QA&#25968;&#25454;&#38598;&#12290;AfriQA&#21253;&#25324;10&#31181;&#38750;&#27954;&#35821;&#35328;&#30340;12,000&#22810;&#20010;XOR QA&#31034;&#20363;&#12290;&#23613;&#31649;&#20808;&#21069;&#30340;&#25968;&#25454;&#38598;&#20027;&#35201;&#20851;&#27880;&#20132;&#21449;&#35821;&#35328;QA&#22686;&#24378;&#30446;&#26631;&#35821;&#35328;&#35206;&#30422;&#33539;&#22260;&#30340;&#35821;&#35328;&#65292;&#20294;AfriQA&#20391;&#37325;&#20110;&#20132;&#21449;&#35821;&#35328;&#31572;&#26696;&#20869;&#23481;&#26159;&#21807;&#19968;&#39640;&#35206;&#30422;&#33539;&#22260;&#31572;&#26696;&#20869;&#23481;&#30340;&#35821;&#35328;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35748;&#20026;&#38750;&#27954;&#35821;&#35328;&#26159;XOR QA&#20013;&#26368;&#37325;&#35201;&#21644;&#26368;&#29616;&#23454;&#30340;&#29992;&#20363;&#20043;&#19968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#33258;&#21160;&#32763;&#35793;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#31995;&#32479;&#22312;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#19981;&#20339;&#65292;&#31361;&#26174;&#20102;&#38656;&#35201;&#25903;&#25345;&#36328;&#35821;&#35328;&#25512;&#29702;&#21644;&#36716;&#31227;&#23398;&#20064;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
African languages have far less in-language content available digitally, making it challenging for question answering systems to satisfy the information needs of users. Cross-lingual open-retrieval question answering (XOR QA) systems -- those that retrieve answer content from other languages while serving people in their native language -- offer a means of filling this gap. To this end, we create AfriQA, the first cross-lingual QA dataset with a focus on African languages. AfriQA includes 12,000+ XOR QA examples across 10 African languages. While previous datasets have focused primarily on languages where cross-lingual QA augments coverage from the target language, AfriQA focuses on languages where cross-lingual answer content is the only high-coverage source of answer content. Because of this, we argue that African languages are one of the most important and realistic use cases for XOR QA. Our experiments demonstrate the poor performance of automatic translation and multilingual retri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;THUIR&#22242;&#38431;&#22312;COLIEE 2023&#27861;&#24459;&#26696;&#20363;&#34164;&#28085;&#20219;&#21153;&#20013;&#30340;&#26041;&#27861;&#65292;&#23581;&#35797;&#20102;&#20256;&#32479;&#30340;&#35789;&#27719;&#21305;&#37197;&#26041;&#27861;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#37319;&#29992;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#26356;&#22810;&#30340;&#21442;&#25968;&#21644;&#27861;&#24459;&#30693;&#35782;&#23545;&#27861;&#24459;&#26696;&#20363;&#34164;&#28085;&#20219;&#21153;&#26377;&#25152;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2305.06817</link><description>&lt;p&gt;
THUIR@COLIEE 2023&#65306;&#26356;&#22810;&#21442;&#25968;&#21644;&#27861;&#24459;&#30693;&#35782;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#34164;&#21547;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
THUIR@COLIEE 2023: More Parameters and Legal Knowledge for Legal Case Entailment. (arXiv:2305.06817v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;THUIR&#22242;&#38431;&#22312;COLIEE 2023&#27861;&#24459;&#26696;&#20363;&#34164;&#28085;&#20219;&#21153;&#20013;&#30340;&#26041;&#27861;&#65292;&#23581;&#35797;&#20102;&#20256;&#32479;&#30340;&#35789;&#27719;&#21305;&#37197;&#26041;&#27861;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#37319;&#29992;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#26356;&#22810;&#30340;&#21442;&#25968;&#21644;&#27861;&#24459;&#30693;&#35782;&#23545;&#27861;&#24459;&#26696;&#20363;&#34164;&#28085;&#20219;&#21153;&#26377;&#25152;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;THUIR&#22242;&#38431;&#22312;COLIEE 2023&#27861;&#24459;&#26696;&#20363;&#34164;&#28085;&#20219;&#21153;&#20013;&#30340;&#26041;&#27861;&#12290;&#35813;&#20219;&#21153;&#35201;&#27714;&#21442;&#19982;&#32773;&#20174;&#32473;&#23450;&#30340;&#25903;&#25345;&#26696;&#20363;&#20013;&#35782;&#21035;&#19968;&#20010;&#29305;&#23450;&#27573;&#33853;&#65292;&#35813;&#27573;&#33853;&#34164;&#21547;&#20102;&#26597;&#35810;&#26696;&#20363;&#30340;&#20915;&#23450;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;&#20256;&#32479;&#30340;&#35789;&#27719;&#21305;&#37197;&#26041;&#27861;&#21644;&#20855;&#26377;&#19981;&#21516;&#22823;&#23567;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#36827;&#19968;&#27493;&#37319;&#29992;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#24182;&#19981;&#26159;&#24456;&#20581;&#22766;&#65292;&#36825;&#34920;&#26126;&#31572;&#26696;&#27573;&#33853;&#19981;&#33021;&#31616;&#21333;&#22320;&#36890;&#36807;&#20449;&#24687;&#26816;&#32034;&#25216;&#26415;&#30830;&#23450;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#26356;&#22810;&#30340;&#21442;&#25968;&#21644;&#27861;&#24459;&#30693;&#35782;&#23545;&#27861;&#24459;&#26696;&#20363;&#30340;&#34164;&#28085;&#20219;&#21153;&#26377;&#25152;&#36129;&#29486;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;COLIEE 2023&#27604;&#36187;&#20013;&#33719;&#24471;&#31532;&#19977;&#21517;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#23454;&#29616;&#21487;&#20197;&#22312;https://github.com/CSHaitao/THUIR-COLIEE2023&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper describes the approach of the THUIR team at the COLIEE 2023 Legal Case Entailment task. This task requires the participant to identify a specific paragraph from a given supporting case that entails the decision for the query case. We try traditional lexical matching methods and pre-trained language models with different sizes. Furthermore, learning-to-rank methods are employed to further improve performance. However, learning-to-rank is not very robust on this task. which suggests that answer passages cannot simply be determined with information retrieval techniques. Experimental results show that more parameters and legal knowledge contribute to the legal case entailment task. Finally, we get the third place in COLIEE 2023. The implementation of our method can be found at https://github.com/CSHaitao/THUIR-COLIEE2023.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24635;&#32467;&#20102;THUIR&#22312;COLIEE 2023&#27604;&#36187;&#20013;&#30340;&#20896;&#20891;&#26041;&#26696;&#65292;&#20854;&#23558;&#32467;&#26500;&#21270;&#30693;&#35782;&#34701;&#20837;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#25552;&#20986;&#21551;&#21457;&#24335;&#39044;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#26041;&#27861;&#65292;&#37319;&#29992;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#36827;&#34892;&#29305;&#24449;&#21512;&#24182;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#20855;&#26377;&#21331;&#36234;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.06812</link><description>&lt;p&gt;
THUIR@COLIEE 2023: &#23558;&#32467;&#26500;&#21270;&#30693;&#35782;&#34701;&#20837;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
THUIR@COLIEE 2023: Incorporating Structural Knowledge into Pre-trained Language Models for Legal Case Retrieval. (arXiv:2305.06812v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06812
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24635;&#32467;&#20102;THUIR&#22312;COLIEE 2023&#27604;&#36187;&#20013;&#30340;&#20896;&#20891;&#26041;&#26696;&#65292;&#20854;&#23558;&#32467;&#26500;&#21270;&#30693;&#35782;&#34701;&#20837;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#25552;&#20986;&#21551;&#21457;&#24335;&#39044;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#26041;&#27861;&#65292;&#37319;&#29992;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#36827;&#34892;&#29305;&#24449;&#21512;&#24182;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#20855;&#26377;&#21331;&#36234;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#25216;&#26415;&#22312;&#29616;&#20195;&#26234;&#33021;&#27861;&#24459;&#31995;&#32479;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#32780;&#20316;&#20026;&#19968;&#39033;&#24180;&#24230;&#30693;&#21517;&#22269;&#38469;&#27604;&#36187;&#65292;COLIEE&#26088;&#22312;&#23454;&#29616;&#38024;&#23545;&#27861;&#24459;&#25991;&#26412;&#30340;&#26368;&#20808;&#36827;&#26816;&#32034;&#27169;&#22411;&#12290;&#26412;&#25991;&#24635;&#32467;&#20102;&#20896;&#20891;&#22242;&#38431;THUIR&#22312;COLIEE 2023&#30340;&#26041;&#27861;&#65292;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#32467;&#26500;&#24863;&#30693;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20197;&#22686;&#24378;&#23545;&#27861;&#24459;&#26696;&#20363;&#30340;&#29702;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21551;&#21457;&#24335;&#39044;&#22788;&#29702;&#21644;&#21518;&#22788;&#29702;&#26041;&#27861;&#20197;&#20943;&#23569;&#26080;&#20851;&#20449;&#24687;&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#37319;&#29992;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#23558;&#20855;&#26377;&#19981;&#21516;&#32500;&#24230;&#30340;&#29305;&#24449;&#21512;&#24182;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#26696;&#20855;&#26377;&#21331;&#36234;&#30340;&#20248;&#21183;&#65292;&#23448;&#26041;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;&#36816;&#34892;&#25928;&#26524;&#22312;&#25152;&#26377;&#25552;&#20132;&#20013;&#34920;&#29616;&#26368;&#20339;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#21487;&#22312;https://github.com/CSHaitao/THUIR-COLIEE2023&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Legal case retrieval techniques play an essential role in modern intelligent legal systems. As an annually well-known international competition, COLIEE is aiming to achieve the state-of-the-art retrieval model for legal texts. This paper summarizes the approach of the championship team THUIR in COLIEE 2023. To be specific, we design structure-aware pre-trained language models to enhance the understanding of legal cases. Furthermore, we propose heuristic pre-processing and post-processing approaches to reduce the influence of irrelevant messages. In the end, learning-to-rank methods are employed to merge features with different dimensions. Experimental results demonstrate the superiority of our proposal. Official results show that our run has the best performance among all submissions. The implementation of our method can be found at https://github.com/CSHaitao/THUIR-COLIEE2023.
&lt;/p&gt;</description></item><item><title>PerFedRec++&#37319;&#29992;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#25216;&#26415;&#65292;&#25552;&#39640;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#30340;&#20010;&#24615;&#21270;&#21644;&#25512;&#33616;&#20934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.06622</link><description>&lt;p&gt;
PerFedRec++&#65306;&#37319;&#29992;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#25552;&#39640;&#20010;&#24615;&#21270;&#32852;&#37030;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
PerFedRec++: Enhancing Personalized Federated Recommendation with Self-Supervised Pre-Training. (arXiv:2305.06622v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06622
&lt;/p&gt;
&lt;p&gt;
PerFedRec++&#37319;&#29992;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#25216;&#26415;&#65292;&#25552;&#39640;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#30340;&#20010;&#24615;&#21270;&#21644;&#25512;&#33616;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#36890;&#36807;&#37319;&#29992;&#32852;&#37030;&#23398;&#20064;&#25216;&#26415;&#65292;&#22312;&#29992;&#25143;&#35774;&#22791;&#21644;&#20013;&#22830;&#26381;&#21153;&#22120;&#20043;&#38388;&#20256;&#36755;&#27169;&#22411;&#21442;&#25968;&#32780;&#38750;&#21407;&#22987;&#29992;&#25143;&#25968;&#25454;&#26469;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30528;&#24322;&#26500;&#24615;&#21644;&#20010;&#24615;&#21270;&#12289;&#27169;&#22411;&#24615;&#33021;&#19979;&#38477;&#21644;&#36890;&#20449;&#29942;&#39048;&#31561;&#25361;&#25112;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#23581;&#35797;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20294;&#22343;&#26410;&#33021;&#21516;&#26102;&#35299;&#20915;&#12290;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;PerFedRec++&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#26469;&#22686;&#24378;&#20010;&#24615;&#21270;&#32852;&#37030;&#25512;&#33616;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#30340;&#38544;&#31169;&#20445;&#25252;&#26426;&#21046;&#29983;&#25104;&#20102;&#20004;&#20010;&#22686;&#24378;&#22270;&#35270;&#22270;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#23545;&#27604;&#20219;&#21153;&#29992;&#20110;&#33258;&#30417;&#30563;&#22270;&#23398;&#20064;&#20013;&#30340;&#39044;&#35757;&#32451;&#12290;&#39044;&#35757;&#32451;&#36890;&#36807;&#25552;&#39640;&#34920;&#31034;&#23398;&#20064;&#30340;&#19968;&#33268;&#24615;&#26469;&#22686;&#24378;&#32852;&#37030;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated recommendation systems employ federated learning techniques to safeguard user privacy by transmitting model parameters instead of raw user data between user devices and the central server. Nevertheless, the current federated recommender system faces challenges such as heterogeneity and personalization, model performance degradation, and communication bottleneck. Previous studies have attempted to address these issues, but none have been able to solve them simultaneously.  In this paper, we propose a novel framework, named PerFedRec++, to enhance the personalized federated recommendation with self-supervised pre-training. Specifically, we utilize the privacy-preserving mechanism of federated recommender systems to generate two augmented graph views, which are used as contrastive tasks in self-supervised graph learning to pre-train the model. Pre-training enhances the performance of federated models by improving the uniformity of representation learning. Also, by providing a be
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#21457;&#29616;&#20102;&#22312;&#27491;&#21017;&#38543;&#26426;&#22270;&#20013;&#23384;&#22312;&#19968;&#31181;&#26032;&#31867;&#22411;&#30340;&#33258;&#30001;&#33021;&#37325;&#26500;&#65292;&#31216;&#20026;eureka&#28857;&#65292;&#36890;&#36807;eureka&#28857;&#21487;&#20197;&#36731;&#26131;&#35775;&#38382;&#20855;&#26377;&#28040;&#22833;&#33258;&#30001;&#33021;&#23631;&#38556;&#30340;&#38544;&#34255;&#22522;&#24577;&#12290;</title><link>http://arxiv.org/abs/2305.06610</link><description>&lt;p&gt;
&#38024;&#23545;&#27491;&#21017;&#38543;&#26426;&#22270;&#30340;&#31181;&#26893;&#39030;&#28857;&#35206;&#30422;&#38382;&#39064;&#21450;&#20854;&#21457;&#29616;&#30340;&#33258;&#30001;&#33021;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Backdoor to the Hidden Ground State: Planted Vertex Cover Example. (arXiv:2305.06610v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06610
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#21457;&#29616;&#20102;&#22312;&#27491;&#21017;&#38543;&#26426;&#22270;&#20013;&#23384;&#22312;&#19968;&#31181;&#26032;&#31867;&#22411;&#30340;&#33258;&#30001;&#33021;&#37325;&#26500;&#65292;&#31216;&#20026;eureka&#28857;&#65292;&#36890;&#36807;eureka&#28857;&#21487;&#20197;&#36731;&#26131;&#35775;&#38382;&#20855;&#26377;&#28040;&#22833;&#33258;&#30001;&#33021;&#23631;&#38556;&#30340;&#38544;&#34255;&#22522;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38024;&#23545;&#27491;&#21017;&#38543;&#26426;&#22270;&#30340;&#31181;&#26893;&#39030;&#28857;&#35206;&#30422;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#31354;&#31348;&#26041;&#27861;&#23545;&#20854;&#36827;&#34892;&#30740;&#31350;&#12290;&#27492;&#20108;&#20803;&#33258;&#26059;&#20132;&#20114;&#20316;&#29992;&#31995;&#32479;&#30340;&#24179;&#34913;&#24207;&#30456;&#21464;&#20855;&#26377;&#19981;&#36830;&#32493;&#30340;&#24615;&#36136;&#65292;&#19981;&#21516;&#20110;&#24120;&#35268;&#30340;&#31867;&#20284;&#20234;&#36763;&#27169;&#22411;&#30340;&#36830;&#32493;&#30456;&#21464;&#65292;&#24182;&#19988;&#22312;&#24191;&#27867;&#30340;&#33258;&#30001;&#33021;&#23631;&#38556;&#30340;&#21160;&#24577;&#38459;&#22622;&#19979;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#35813;&#31995;&#32479;&#30340;&#26080;&#24207;&#23545;&#31216;&#30456;&#22312;&#38500;&#20102;&#21807;&#19968;&#30340;eureka&#28857;$\beta_b$&#20043;&#22806;&#30340;&#25152;&#26377;&#36870;&#28201;&#24230;&#19979;&#37117;&#21487;&#20197;&#22312;&#26377;&#24207;&#30456;&#30340;&#24773;&#20917;&#19979;&#23616;&#37096;&#31283;&#23450;&#12290; eureka&#28857;$\beta_b$&#20026;&#35775;&#38382;&#20855;&#26377;&#28040;&#22833;&#33258;&#30001;&#33021;&#23631;&#38556;&#30340;&#38544;&#34255;&#22522;&#24577;&#25552;&#20379;&#20102;&#19968;&#20010;&#20415;&#36947;&#12290;&#23427;&#23384;&#22312;&#20110;&#26080;&#38480;&#31995;&#21015;&#30340;&#31181;&#26893;&#38543;&#26426;&#22270;&#38598;&#21512;&#20013;&#65292;&#24182;&#19988;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#30830;&#23450;&#20102;&#23427;&#20204;&#30340;&#32467;&#26500;&#21442;&#25968;&#12290;&#25581;&#31034;&#20986;&#30340;&#26032;&#31867;&#22411;&#30340;&#33258;&#30001;&#33021;&#26223;&#35266;&#20063;&#21487;&#33021;&#23384;&#22312;&#20110;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#32479;&#35745;&#23398;&#30028;&#38754;&#30340;&#20854;&#20182;&#31181;&#26893;&#38543;&#26426;&#22270;&#20248;&#21270;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a planted vertex cover problem on regular random graphs and study it by the cavity method. The equilibrium ordering phase transition of this binary-spin two-body interaction system is discontinuous in nature distinct from the continuous one of conventional Ising-like models, and it is dynamically blocked by an extensive free energy barrier. We discover that the disordered symmetric phase of this system may be locally stable with respect to the ordered phase at all inverse temperatures except for a unique eureka point $\beta_b$ at which it is only marginally stable. The eureka point $\beta_b$ serves as a backdoor to access the hidden ground state with vanishing free energy barrier. It exists in an infinite series of planted random graph ensembles and we determine their structural parameters analytically. The revealed new type of free energy landscape may also exist in other planted random-graph optimization problems at the interface of statistical physics and statistical in
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.06569</link><description>&lt;p&gt;
&#22914;&#20309;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#32034;&#24341;&#39033;&#30446;ID
&lt;/p&gt;
&lt;p&gt;
How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#23558;&#25512;&#33616;&#20219;&#21153;&#36716;&#25442;&#20026;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#25512;&#33616;&#12290;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#24314;&#35758;&#30340;&#39033;&#30446;&#32780;&#19981;&#26159;&#35745;&#31639;&#20256;&#32479;&#25512;&#33616;&#27169;&#22411;&#20013;&#27599;&#20010;&#20505;&#36873;&#39033;&#30446;&#30340;&#25490;&#21517;&#24471;&#20998;&#65292;&#31616;&#21270;&#20102;&#25512;&#33616;&#31649;&#36947;&#65292;&#36991;&#20813;&#20102;&#22810;&#27573;&#36807;&#28388;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#20915;&#23450;&#35201;&#25512;&#33616;&#21738;&#20123;&#39033;&#30446;&#26102;&#29983;&#25104;&#36807;&#38271;&#30340;&#25991;&#26412;&#65292;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#21019;&#24314;LLM&#20860;&#23481;&#30340;&#39033;&#30446;ID&#26159;&#24517;&#35201;&#30340;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#65292;&#20197;P5&#20026;&#20195;&#34920;&#30340;&#20027;&#24178;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32034;&#24341;&#26041;&#27861;&#22797;&#21046;&#20854;&#32467;&#26524;&#12290;&#25105;&#20204;&#39318;&#20808;&#35752;&#35770;&#20102;&#20960;&#31181;&#24494;&#19981;&#36275;&#36947;&#30340;&#39033;&#30446;&#32034;&#24341;&#26041;&#27861;&#65288;&#22914;&#29420;&#31435;&#32034;&#24341;&#12289;&#26631;&#39064;&#32034;&#24341;&#21644;&#38543;&#26426;&#32034;&#24341;&#65289;&#30340;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#19981;&#36866;&#29992;&#20110;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32034;&#24341;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#31181;&#32034;&#24341;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#32034;&#24341;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;GENRE&#65292;&#23427;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#65292;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#25552;&#20379;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#12290;</title><link>http://arxiv.org/abs/2305.06566</link><description>&lt;p&gt;
LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#21021;&#25506;
&lt;/p&gt;
&lt;p&gt;
A First Look at LLM-Powered Generative News Recommendation. (arXiv:2305.06566v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;GENRE&#65292;&#23427;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#65292;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#25552;&#20379;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#29992;&#25143;&#27983;&#35272;&#28023;&#37327;&#22312;&#32447;&#26032;&#38395;&#20869;&#23481;&#25152;&#24517;&#38656;&#30340;&#24037;&#20855;&#65292;&#28982;&#32780;&#29616;&#26377;&#30340;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30528;&#20919;&#21551;&#21160;&#38382;&#39064;&#12289;&#29992;&#25143;&#30011;&#20687;&#24314;&#27169;&#21644;&#26032;&#38395;&#20869;&#23481;&#29702;&#35299;&#31561;&#37325;&#22823;&#25361;&#25112;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#36890;&#24120;&#36890;&#36807;&#27169;&#22411;&#35774;&#35745;&#36981;&#24490;&#19968;&#31181;&#19981;&#28789;&#27963;&#30340;&#20363;&#34892;&#31243;&#24207;&#26469;&#35299;&#20915;&#29305;&#23450;&#30340;&#25361;&#25112;&#65292;&#20294;&#22312;&#29702;&#35299;&#26032;&#38395;&#20869;&#23481;&#21644;&#25429;&#25417;&#29992;&#25143;&#20852;&#36259;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;GENRE&#65292;&#19968;&#31181;LLM&#39537;&#21160;&#30340;&#29983;&#25104;&#24335;&#26032;&#38395;&#25512;&#33616;&#26694;&#26550;&#65292;&#23427;&#21033;&#29992;&#26469;&#33258;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#35821;&#20041;&#30693;&#35782;&#26469;&#20016;&#23500;&#26032;&#38395;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#20174;&#27169;&#22411;&#35774;&#35745;&#36716;&#31227;&#21040;&#25552;&#31034;&#35774;&#35745;&#26469;&#25552;&#20379;&#19968;&#31181;&#28789;&#27963;&#32780;&#32479;&#19968;&#30340;&#26032;&#38395;&#25512;&#33616;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;GENRE&#22312;&#20010;&#24615;&#21270;&#26032;&#38395;&#29983;&#25104;&#12289;&#29992;&#25143;&#30011;&#20687;&#21644;&#26032;&#38395;&#25688;&#35201;&#20013;&#30340;&#24212;&#29992;&#12290;&#20351;&#29992;&#21508;&#31181;&#27969;&#34892;&#30340;&#25512;&#33616;&#27169;&#22411;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;GENRE&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding. Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests. In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data. Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design. We showcase the use of GENRE for personalized news generation, user profiling, and news summarization. Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29992;&#25143;&#35780;&#20998;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#19982;&#20256;&#32479;&#30340;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#36827;&#34892;&#23545;&#27604;&#12290;&#32467;&#26524;&#21457;&#29616;LLMs&#33021;&#22815;&#22312;&#36739;&#23569;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#20248;&#31168;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#24773;&#20917;&#19979;&#34920;&#29616;&#24456;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.06474</link><description>&lt;p&gt;
LLM&#26159;&#21542;&#33021;&#29702;&#35299;&#29992;&#25143;&#20559;&#22909;&#65311;&#22312;&#29992;&#25143;&#35780;&#20998;&#39044;&#27979;&#20219;&#21153;&#20013;&#23545;LLM&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction. (arXiv:2305.06474v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29992;&#25143;&#35780;&#20998;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#19982;&#20256;&#32479;&#30340;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#36827;&#34892;&#23545;&#27604;&#12290;&#32467;&#26524;&#21457;&#29616;LLMs&#33021;&#22815;&#22312;&#36739;&#23569;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#20248;&#31168;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#24773;&#20917;&#19979;&#34920;&#29616;&#24456;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#38646;&#26679;&#26412;&#25110;&#23569;&#26679;&#26412;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#20102;&#26480;&#20986;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;LLMs&#22312;&#22522;&#20110;&#29992;&#25143;&#20197;&#21069;&#30340;&#34892;&#20026;&#25512;&#26029;&#29992;&#25143;&#20559;&#22909;&#26041;&#38754;&#33021;&#21147;&#30340;&#31243;&#24230;&#36824;&#26159;&#19968;&#20010;&#23578;&#19981;&#28165;&#26970;&#30340;&#38382;&#39064;&#12290;&#20256;&#32479;&#19978;&#65292;&#21327;&#21516;&#36807;&#28388;(CF)&#26159;&#36825;&#20123;&#20219;&#21153;&#20013;&#26368;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20027;&#35201;&#20381;&#36182;&#20110;&#22823;&#37327;&#30340;&#35780;&#20998;&#25968;&#25454;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;LLMs&#36890;&#24120;&#38656;&#35201;&#26356;&#23569;&#30340;&#25968;&#25454;&#65292;&#21516;&#26102;&#21448;&#20445;&#25345;&#20102;&#27599;&#20010;&#39033;&#30446;(&#22914;&#30005;&#24433;&#25110;&#20135;&#21697;)&#30340;&#35814;&#23613;&#30340;&#19990;&#30028;&#30693;&#35782;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#29992;&#25143;&#35780;&#20998;&#39044;&#27979;&#36825;&#19968;&#32463;&#20856;&#20219;&#21153;&#20013;&#30340;CF&#21644;LLMs&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#27604;&#36739;&#12290;&#36825;&#19968;&#20219;&#21153;&#28041;&#21450;&#22522;&#20110;&#29992;&#25143;&#36807;&#21435;&#30340;&#35780;&#20998;&#39044;&#27979;&#20505;&#36873;&#39033;&#30446;&#30340;&#35780;&#20998;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;&#22823;&#23567;&#30340;LLMs&#65292;&#20174;250M&#21040;540B&#20010;&#21442;&#25968;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#22312;&#38646;&#26679;&#26412;&#12289;&#23569;&#26679;&#26412;&#21644;&#24494;&#35843;&#22330;&#26223;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated exceptional capabilities in generalizing to new tasks in a zero-shot or few-shot manner. However, the extent to which LLMs can comprehend user preferences based on their previous behavior remains an emerging and still unclear research question. Traditionally, Collaborative Filtering (CF) has been the most effective method for these tasks, predominantly relying on the extensive volume of rating data. In contrast, LLMs typically demand considerably less data while maintaining an exhaustive world knowledge about each item, such as movies or products. In this paper, we conduct a thorough examination of both CF and LLMs within the classic task of user rating prediction, which involves predicting a user's rating for a candidate item based on their past ratings. We investigate various LLMs in different sizes, ranging from 250M to 540B parameters and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We conduct comprehen
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;Transformer&#36827;&#34892;&#25233;&#37057;&#30151;&#31579;&#26597;&#65292;&#20811;&#26381;&#20102;&#20256;&#32479;&#26041;&#27861;&#30340;&#29305;&#24449;&#24037;&#31243;&#20381;&#36182;&#21644;&#24573;&#30053;&#26102;&#21464;&#22240;&#32032;&#30340;&#32570;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.06447</link><description>&lt;p&gt;
&#21033;&#29992;Transformer&#36827;&#34892;&#25233;&#37057;&#30151;&#31579;&#26597;&#30340;&#21160;&#24577;&#22270;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Dynamic Graph Representation Learning for Depression Screening with Transformer. (arXiv:2305.06447v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06447
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;Transformer&#36827;&#34892;&#25233;&#37057;&#30151;&#31579;&#26597;&#65292;&#20811;&#26381;&#20102;&#20256;&#32479;&#26041;&#27861;&#30340;&#29305;&#24449;&#24037;&#31243;&#20381;&#36182;&#21644;&#24573;&#30053;&#26102;&#21464;&#22240;&#32032;&#30340;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24555;&#36895;&#21457;&#29616;&#24515;&#29702;&#38556;&#30861;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#36825;&#26679;&#21487;&#20197;&#21450;&#26102;&#24178;&#39044;&#21644;&#27835;&#30103;&#65292;&#20174;&#32780;&#22823;&#22823;&#25913;&#21892;&#24739;&#26377;&#20005;&#37325;&#24515;&#29702;&#30142;&#30149;&#30340;&#20010;&#20307;&#30340;&#39044;&#21518;&#12290;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#26368;&#36817;&#20986;&#29616;&#30340;&#24515;&#29702;&#20581;&#24247;&#35752;&#35770;&#30340;&#28608;&#22686;&#20026;&#30740;&#31350;&#24515;&#29702;&#20581;&#24247;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#24182;&#26377;&#21487;&#33021;&#26816;&#27979;&#21040;&#24515;&#29702;&#30142;&#30149;&#30340;&#21457;&#29983;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25233;&#37057;&#30151;&#26816;&#27979;&#26041;&#27861;&#30001;&#20110;&#20004;&#20010;&#20027;&#35201;&#38480;&#21046;&#32780;&#21463;&#21040;&#38480;&#21046;&#65306;(1)&#20381;&#36182;&#20110;&#29305;&#24449;&#24037;&#31243;&#65292;(2)&#27809;&#26377;&#32771;&#34385;&#26102;&#21464;&#22240;&#32032;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36825;&#20123;&#26041;&#27861;&#38656;&#35201;&#22823;&#37327;&#30340;&#29305;&#24449;&#24037;&#31243;&#21644;&#39046;&#22495;&#30693;&#35782;&#65292;&#20854;&#20013;&#20005;&#37325;&#20381;&#36182;&#20110;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#30340;&#25968;&#37327;&#12289;&#36136;&#37327;&#21644;&#31867;&#22411;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#24573;&#35270;&#20102;&#26102;&#21464;&#22240;&#32032;&#23545;&#25233;&#37057;&#30151;&#26816;&#27979;&#30340;&#37325;&#35201;&#24433;&#21709;&#65292;&#20363;&#22914;&#31038;&#20132;&#23186;&#20307;&#19978;&#38543;&#26102;&#38388;&#25512;&#31227;&#32780;&#20135;&#29983;&#30340;&#35821;&#35328;&#27169;&#24335;&#21644;&#20154;&#38469;&#20114;&#21160;&#34892;&#20026;&#30340;&#21160;&#24577;&#21464;&#21270;(&#20363;&#22914;&#22238;&#22797;&#12289;&#25552;&#21450;&#21644;&#24341;&#29992;&#25512;&#25991;)&#12290;
&lt;/p&gt;
&lt;p&gt;
Early detection of mental disorder is crucial as it enables prompt intervention and treatment, which can greatly improve outcomes for individuals suffering from debilitating mental affliction. The recent proliferation of mental health discussions on social media platforms presents research opportunities to investigate mental health and potentially detect instances of mental illness. However, existing depression detection methods are constrained due to two major limitations: (1) the reliance on feature engineering and (2) the lack of consideration for time-varying factors. Specifically, these methods require extensive feature engineering and domain knowledge, which heavily rely on the amount, quality, and type of user-generated content. Moreover, these methods ignore the important impact of time-varying factors on depression detection, such as the dynamics of linguistic patterns and interpersonal interactive behaviors over time on social media (e.g., replies, mentions, and quote-tweets)
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20174;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;ChatGPT&#22312;&#28857;&#12289;&#23545;&#12289;&#21015;&#34920;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#25512;&#33616;&#33021;&#21147;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#22312;&#22235;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#24182;&#21457;&#29616;ChatGPT&#22312;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#34920;&#29616;&#22343;&#20248;&#20110;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#21015;&#34920;&#25490;&#21517;&#20013;&#33021;&#22815;&#36798;&#21040;&#25104;&#26412;&#21644;&#24615;&#33021;&#26368;&#20339;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.02182</link><description>&lt;p&gt;
&#25581;&#31034;ChatGPT&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Uncovering ChatGPT's Capabilities in Recommender Systems. (arXiv:2305.02182v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02182
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;ChatGPT&#22312;&#28857;&#12289;&#23545;&#12289;&#21015;&#34920;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#25512;&#33616;&#33021;&#21147;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#22312;&#22235;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#24182;&#21457;&#29616;ChatGPT&#22312;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#34920;&#29616;&#22343;&#20248;&#20110;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#21015;&#34920;&#25490;&#21517;&#20013;&#33021;&#22815;&#36798;&#21040;&#25104;&#26412;&#21644;&#24615;&#33021;&#26368;&#20339;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#30340;&#38382;&#31572;&#21151;&#33021;&#21560;&#24341;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30028;&#21450;&#22806;&#30028;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#27979;&#35797;ChatGPT&#22312;&#25512;&#33616;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#26412;&#30740;&#31350;&#20174;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;ChatGPT&#22312;&#28857;&#12289;&#23545;&#12289;&#21015;&#34920;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#25512;&#33616;&#33021;&#21147;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#12290;&#36890;&#36807;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#22235;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;ChatGPT&#22312;&#19977;&#31181;&#25490;&#21517;&#31574;&#30053;&#19979;&#30340;&#34920;&#29616;&#22343;&#20248;&#20110;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#22522;&#20110;&#21333;&#20301;&#25104;&#26412;&#25913;&#36827;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#30830;&#23450;ChatGPT&#22312;&#21015;&#34920;&#25490;&#21517;&#20013;&#33021;&#22815;&#22312;&#25104;&#26412;&#21644;&#24615;&#33021;&#20043;&#38388;&#23454;&#29616;&#26368;&#20339;&#24179;&#34913;&#65292;&#32780;&#22312;&#23545;&#21644;&#28857;&#25490;&#21517;&#20013;&#34920;&#29616;&#30456;&#23545;&#36739;&#24369;&#12290;
&lt;/p&gt;
&lt;p&gt;
The debut of ChatGPT has recently attracted the attention of the natural language processing (NLP) community and beyond. Existing studies have demonstrated that ChatGPT shows significant improvement in a range of downstream NLP tasks, but the capabilities and limitations of ChatGPT in terms of recommendations remain unclear. In this study, we aim to conduct an empirical analysis of ChatGPT's recommendation ability from an Information Retrieval (IR) perspective, including point-wise, pair-wise, and list-wise ranking. To achieve this goal, we re-formulate the above three recommendation policies into a domain-specific prompt format. Through extensive experiments on four datasets from different domains, we demonstrate that ChatGPT outperforms other large language models across all three ranking policies. Based on the analysis of unit cost improvements, we identify that ChatGPT with list-wise ranking achieves the best trade-off between cost and performance compared to point-wise and pair-wi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31163;&#32447;&#35780;&#20272;&#28857;&#20987;&#27169;&#22411;&#21435;&#21327;&#21464;&#20559;&#31227;&#30340;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#21435;&#20559;&#24046;&#24615;&#36825;&#19968;&#27010;&#24565;&#21644;&#27979;&#37327;&#26041;&#27861;&#65292;&#36825;&#26159;&#24674;&#22797;&#26080;&#20559;&#19968;&#33268;&#30456;&#20851;&#24615;&#35780;&#20998;&#21644;&#28857;&#20987;&#27169;&#22411;&#23545;&#25490;&#21517;&#20998;&#24067;&#21464;&#21270;&#19981;&#21464;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2304.09560</link><description>&lt;p&gt;
&#31163;&#32447;&#24230;&#37327;&#28857;&#20987;&#27169;&#22411;&#30340;&#21435;&#20559;&#24046;&#24615;
&lt;/p&gt;
&lt;p&gt;
An Offline Metric for the Debiasedness of Click Models. (arXiv:2304.09560v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31163;&#32447;&#35780;&#20272;&#28857;&#20987;&#27169;&#22411;&#21435;&#21327;&#21464;&#20559;&#31227;&#30340;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#21435;&#20559;&#24046;&#24615;&#36825;&#19968;&#27010;&#24565;&#21644;&#27979;&#37327;&#26041;&#27861;&#65292;&#36825;&#26159;&#24674;&#22797;&#26080;&#20559;&#19968;&#33268;&#30456;&#20851;&#24615;&#35780;&#20998;&#21644;&#28857;&#20987;&#27169;&#22411;&#23545;&#25490;&#21517;&#20998;&#24067;&#21464;&#21270;&#19981;&#21464;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#29992;&#25143;&#28857;&#20987;&#26102;&#65292;&#22266;&#26377;&#20559;&#35265;&#26159;&#25968;&#25454;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#19968;&#20010;&#38382;&#39064;&#65292;&#20363;&#22914;&#20301;&#32622;&#20559;&#35265;&#25110;&#20449;&#20219;&#20559;&#35265;&#12290;&#28857;&#20987;&#27169;&#22411;&#26159;&#20174;&#29992;&#25143;&#28857;&#20987;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#24120;&#29992;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;Web&#25628;&#32034;&#20013;&#25552;&#21462;&#25991;&#26723;&#30456;&#20851;&#24615;&#65292;&#25110;&#32773;&#20272;&#35745;&#28857;&#20987;&#20559;&#24046;&#20197;&#29992;&#20110;&#19979;&#28216;&#24212;&#29992;&#65292;&#20363;&#22914;&#21453;&#20107;&#23454;&#30340;&#23398;&#20064;&#25490;&#24207;&#12289;&#24191;&#21578;&#20301;&#32622;&#21644;&#20844;&#24179;&#25490;&#24207;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#31038;&#21306;&#20013;&#30340;&#24403;&#21069;&#35780;&#20272;&#23454;&#36341;&#19981;&#33021;&#20445;&#35777;&#24615;&#33021;&#33391;&#22909;&#30340;&#28857;&#20987;&#27169;&#22411;&#23545;&#20110;&#19979;&#28216;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20854;&#20013;&#25490;&#21517;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#65292;&#21363;&#22312;&#21327;&#21464;&#20559;&#31227;&#19979;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#35780;&#20272;&#24230;&#37327;&#65292;&#20197;&#26816;&#27979;&#28857;&#20987;&#27169;&#22411;&#23545;&#21327;&#21464;&#20559;&#31227;&#30340;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#24615;&#30340;&#27010;&#24565;&#21644;&#19968;&#31181;&#27979;&#37327;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21435;&#20559;&#24046;&#24615;&#26159;&#24674;&#22797;&#26080;&#20559;&#30340;&#19968;&#33268;&#30456;&#20851;&#24615;&#35780;&#20998;&#20197;&#21450;&#20351;&#28857;&#20987;&#27169;&#22411;&#23545;&#25490;&#21517;&#20998;&#24067;&#21464;&#21270;&#30340;&#19981;&#21464;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
A well-known problem when learning from user clicks are inherent biases prevalent in the data, such as position or trust bias. Click models are a common method for extracting information from user clicks, such as document relevance in web search, or to estimate click biases for downstream applications such as counterfactual learning-to-rank, ad placement, or fair ranking. Recent work shows that the current evaluation practices in the community fail to guarantee that a well-performing click model generalizes well to downstream tasks in which the ranking distribution differs from the training distribution, i.e., under covariate shift. In this work, we propose an evaluation metric based on conditional independence testing to detect a lack of robustness to covariate shift in click models. We introduce the concept of debiasedness and a metric for measuring it. We prove that debiasedness is a necessary condition for recovering unbiased and consistent relevance scores and for the invariance o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22810;&#39033;Logit&#36873;&#25321;&#27169;&#22411;&#30340;&#23398;&#20064;&#25490;&#24207;&#26694;&#26550;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#25429;&#25417;&#29992;&#25143;&#22312;&#25972;&#20010;&#39033;&#30446;&#21015;&#34920;&#20013;&#30340;&#36873;&#25321;&#34892;&#20026;&#65292;&#20026;&#32593;&#31449;&#35774;&#35745;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#25490;&#24207;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2009.03207</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#22810;&#39033;Logit&#36873;&#25321;&#19979;&#36827;&#34892;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Learning to Rank under Multinomial Logit Choice. (arXiv:2009.03207v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.03207
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22810;&#39033;Logit&#36873;&#25321;&#27169;&#22411;&#30340;&#23398;&#20064;&#25490;&#24207;&#26694;&#26550;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#25429;&#25417;&#29992;&#25143;&#22312;&#25972;&#20010;&#39033;&#30446;&#21015;&#34920;&#20013;&#30340;&#36873;&#25321;&#34892;&#20026;&#65292;&#20026;&#32593;&#31449;&#35774;&#35745;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#25490;&#24207;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32593;&#31449;&#35774;&#35745;&#20013;&#65292;&#23398;&#20064;&#26368;&#20339;&#20869;&#23481;&#25490;&#24207;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#23398;&#20064;&#25490;&#24207;&#65288;LTR&#65289;&#26694;&#26550;&#23558;&#36825;&#20010;&#38382;&#39064;&#24314;&#27169;&#20026;&#36873;&#25321;&#20869;&#23481;&#21015;&#34920;&#24182;&#35266;&#23519;&#29992;&#25143;&#20915;&#23450;&#28857;&#20987;&#30340;&#39034;&#24207;&#38382;&#39064;&#12290;&#22823;&#22810;&#25968;&#20197;&#21069;&#30340;LTR&#24037;&#20316;&#20551;&#35774;&#29992;&#25143;&#22312;&#21015;&#34920;&#20013;&#29420;&#31435;&#32771;&#34385;&#27599;&#20010;&#39033;&#30446;&#65292;&#24182;&#23545;&#27599;&#20010;&#39033;&#30446;&#36827;&#34892;&#20108;&#36873;&#19968;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22810;&#39033;&#24335;Logit&#65288;MNL&#65289;&#36873;&#25321;&#27169;&#22411;&#21040;LTR&#26694;&#26550;&#20013;&#65292;&#23427;&#25429;&#25417;&#21040;&#29992;&#25143;&#23558;&#26377;&#24207;&#30340;&#39033;&#30446;&#21015;&#34920;&#20316;&#20026;&#19968;&#20010;&#25972;&#20307;&#65292;&#20174;&#25152;&#26377;&#39033;&#30446;&#21644;&#27809;&#26377;&#28857;&#20987;&#36873;&#39033;&#20013;&#20570;&#20986;&#19968;&#20010;&#36873;&#25321;&#30340;&#34892;&#20026;&#12290;&#22312;MNL&#27169;&#22411;&#19979;&#65292;&#29992;&#25143;&#26356;&#21916;&#27426;&#26412;&#36136;&#19978;&#26356;&#26377;&#21560;&#24341;&#21147;&#30340;&#39033;&#30446;&#65292;&#25110;&#32773;&#22788;&#20110;&#21015;&#34920;&#20013;&#26356;&#21487;&#21462;&#30340;&#20301;&#32622;&#30340;&#39033;&#30446;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19978;&#32622;&#20449;&#30028;&#65288;UCB&#65289;&#31639;&#27861;&#65292;&#20197;&#22312;&#24050;&#30693;&#21644;&#26410;&#30693;&#30340;&#20301;&#32622;&#20381;&#36182;&#21442;&#25968;&#30340;&#20004;&#31181;&#35774;&#32622;&#20013;&#26368;&#23567;&#21270;&#36951;&#25022;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#23548;&#33268;&#20102;&#23545;&#38382;&#39064;&#30340;$\Omega&#65288;\sqrt{JT}&#65289;$&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning the optimal ordering of content is an important challenge in website design. The learning to rank (LTR) framework models this problem as a sequential problem of selecting lists of content and observing where users decide to click. Most previous work on LTR assumes that the user considers each item in the list in isolation, and makes binary choices to click or not on each. We introduce a multinomial logit (MNL) choice model to the LTR framework, which captures the behaviour of users who consider the ordered list of items as a whole and make a single choice among all the items and a no-click option. Under the MNL model, the user favours items which are either inherently more attractive, or placed in a preferable position within the list. We propose upper confidence bound (UCB) algorithms to minimise regret in two settings where the position dependent parameters are known, and unknown. We present theoretical analysis leading to an $\Omega(\sqrt{JT})$ lower bound for the problem
&lt;/p&gt;</description></item></channel></rss>