<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#26816;&#32034;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;LLM&#36716;&#21464;&#20026;&#19968;&#20010;&#30456;&#20851;&#12289;&#36127;&#36131;&#20219;&#19988;&#21487;&#20449;&#36182;&#30340;&#25628;&#32034;&#22120;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#29983;&#25104;&#22120;&#12289;&#39564;&#35777;&#22120;&#21644;&#20248;&#21270;&#22120;&#19977;&#20010;&#26680;&#24515;&#27169;&#22359;&#65292;&#20998;&#21035;&#29992;&#20110;&#29983;&#25104;&#21487;&#20449;&#36182;&#30340;&#22312;&#32447;&#26469;&#28304;&#12289;&#39564;&#35777;&#26469;&#28304;&#21487;&#38752;&#24615;&#21644;&#20248;&#21270;&#19981;&#21487;&#20449;&#36182;&#30340;&#26469;&#28304;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#20854;&#20182;&#26041;&#27861;&#22312;&#30456;&#20851;&#24615;&#12289;&#36127;&#36131;&#20219;&#24615;&#21644;&#21487;&#20449;&#24230;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.12443</link><description>&lt;p&gt;
&#20102;&#35299;&#20309;&#22788;&#21069;&#24448;&#65306;&#20351;LLM&#25104;&#20026;&#19968;&#20010;&#30456;&#20851;&#12289;&#36127;&#36131;&#20219;&#19988;&#21487;&#20449;&#36182;&#30340;&#25628;&#32034;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher. (arXiv:2310.12443v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12443
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#26816;&#32034;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;LLM&#36716;&#21464;&#20026;&#19968;&#20010;&#30456;&#20851;&#12289;&#36127;&#36131;&#20219;&#19988;&#21487;&#20449;&#36182;&#30340;&#25628;&#32034;&#22120;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#29983;&#25104;&#22120;&#12289;&#39564;&#35777;&#22120;&#21644;&#20248;&#21270;&#22120;&#19977;&#20010;&#26680;&#24515;&#27169;&#22359;&#65292;&#20998;&#21035;&#29992;&#20110;&#29983;&#25104;&#21487;&#20449;&#36182;&#30340;&#22312;&#32447;&#26469;&#28304;&#12289;&#39564;&#35777;&#26469;&#28304;&#21487;&#38752;&#24615;&#21644;&#20248;&#21270;&#19981;&#21487;&#20449;&#36182;&#30340;&#26469;&#28304;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#20854;&#20182;&#26041;&#27861;&#22312;&#30456;&#20851;&#24615;&#12289;&#36127;&#36131;&#20219;&#24615;&#21644;&#21487;&#20449;&#24230;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#24050;&#32463;&#26174;&#31034;&#20986;&#23427;&#22312;&#25552;&#39640;&#25628;&#32034;&#30456;&#20851;&#24615;&#21644;&#25552;&#20379;&#30452;&#25509;&#31572;&#26696;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20256;&#32479;&#20449;&#24687;&#26816;&#32034;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;LLM&#30340;&#38169;&#35273;&#38382;&#39064;&#65292;&#39564;&#35777;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#21644;&#36129;&#29486;&#26469;&#28304;&#30340;&#21487;&#20449;&#24230;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#21019;&#24314;LLM&#26102;&#20195;&#30340;&#8220;PageRank&#8221;&#65292;&#25105;&#20204;&#33268;&#21147;&#20110;&#23558;LLM&#36716;&#21464;&#20026;&#19968;&#20010;&#30456;&#20851;&#12289;&#36127;&#36131;&#20219;&#19988;&#21487;&#20449;&#36182;&#30340;&#25628;&#32034;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29983;&#25104;&#26816;&#32034;&#26694;&#26550;&#65292;&#21033;&#29992;LLM&#30340;&#30693;&#35782;&#24314;&#31435;&#26597;&#35810;&#21644;&#22312;&#32447;&#26469;&#28304;&#20043;&#38388;&#30340;&#30452;&#25509;&#38142;&#25509;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#26680;&#24515;&#27169;&#22359;&#65306;&#29983;&#25104;&#22120;&#12289;&#39564;&#35777;&#22120;&#21644;&#20248;&#21270;&#22120;&#65292;&#20998;&#21035;&#19987;&#27880;&#20110;&#29983;&#25104;&#21487;&#20449;&#36182;&#30340;&#22312;&#32447;&#26469;&#28304;&#12289;&#39564;&#35777;&#26469;&#28304;&#30340;&#21487;&#38752;&#24615;&#21644;&#20248;&#21270;&#19981;&#21487;&#20449;&#36182;&#30340;&#26469;&#28304;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#30456;&#20851;&#24615;&#12289;&#36127;&#36131;&#20219;&#24615;&#21644;&#21487;&#20449;&#24230;&#26041;&#38754;&#30456;&#23545;&#20110;&#21508;&#31181;SOTA&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of Large Language Models (LLMs) has shown the potential to improve relevance and provide direct answers in web searches. However, challenges arise in validating the reliability of generated results and the credibility of contributing sources, due to the limitations of traditional information retrieval algorithms and the LLM hallucination problem. Aiming to create a "PageRank" for the LLM era, we strive to transform LLM into a relevant, responsible, and trustworthy searcher. We propose a novel generative retrieval framework leveraging the knowledge of LLMs to foster a direct link between queries and online sources. This framework consists of three core modules: Generator, Validator, and Optimizer, each focusing on generating trustworthy online sources, verifying source reliability, and refining unreliable sources, respectively. Extensive experiments and evaluations highlight our method's superior relevance, responsibility, and trustfulness against various SOTA methods.
&lt;/p&gt;</description></item><item><title>KuaiSim&#26159;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#20010;&#32508;&#21512;&#27169;&#25311;&#22120;&#65292;&#25552;&#20379;&#20102;&#26356;&#30495;&#23454;&#30340;&#29992;&#25143;&#21453;&#39304;&#21644;&#22810;&#31181;&#34892;&#20026;&#21709;&#24212;&#12290;&#23427;&#33021;&#22815;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#22312;&#32447;&#37096;&#32626;&#21644;&#29983;&#25104;&#30495;&#23454;&#25968;&#25454;&#30340;&#25361;&#25112;&#65292;&#24182;&#25903;&#25345;&#19981;&#21516;&#23618;&#27425;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.12645</link><description>&lt;p&gt;
KuaiSim&#65306;&#19968;&#20010;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#32508;&#21512;&#27169;&#25311;&#22120;
&lt;/p&gt;
&lt;p&gt;
KuaiSim: A Comprehensive Simulator for Recommender Systems. (arXiv:2309.12645v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12645
&lt;/p&gt;
&lt;p&gt;
KuaiSim&#26159;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#20010;&#32508;&#21512;&#27169;&#25311;&#22120;&#65292;&#25552;&#20379;&#20102;&#26356;&#30495;&#23454;&#30340;&#29992;&#25143;&#21453;&#39304;&#21644;&#22810;&#31181;&#34892;&#20026;&#21709;&#24212;&#12290;&#23427;&#33021;&#22815;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#22312;&#32447;&#37096;&#32626;&#21644;&#29983;&#25104;&#30495;&#23454;&#25968;&#25454;&#30340;&#25361;&#25112;&#65292;&#24182;&#25903;&#25345;&#19981;&#21516;&#23618;&#27425;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#22240;&#20854;&#33021;&#22815;&#23398;&#20064;&#26368;&#20248;&#25512;&#33616;&#31574;&#30053;&#24182;&#26368;&#22823;&#21270;&#38271;&#26399;&#29992;&#25143;&#22238;&#25253;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#22312;&#22312;&#32447;&#29615;&#22659;&#20013;&#37096;&#32626;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#24182;&#36890;&#36807;A/B&#27979;&#35797;&#29983;&#25104;&#30495;&#23454;&#25968;&#25454;&#21487;&#33021;&#20250;&#38754;&#20020;&#25361;&#25112;&#24182;&#38656;&#35201;&#22823;&#37327;&#36164;&#28304;&#12290;&#27169;&#25311;&#22120;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#20026;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#25552;&#20379;&#35757;&#32451;&#21644;&#35780;&#20272;&#29615;&#22659;&#65292;&#20943;&#23569;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;&#29616;&#26377;&#30340;&#27169;&#25311;&#22120;&#24050;&#32463;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#20063;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#65292;&#22914;&#29992;&#25143;&#21453;&#39304;&#36807;&#20110;&#31616;&#21270;&#12289;&#32570;&#20047;&#19982;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#19968;&#33268;&#24615;&#12289;&#27169;&#25311;&#22120;&#35780;&#20272;&#30340;&#25361;&#25112;&#20197;&#21450;&#22312;&#19981;&#21516;&#25512;&#33616;&#31995;&#32479;&#20043;&#38388;&#30340;&#36801;&#31227;&#21644;&#25193;&#23637;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;KuaiSim&#65292;&#19968;&#20010;&#25552;&#20379;&#29992;&#25143;&#21453;&#39304;&#20855;&#26377;&#22810;&#34892;&#20026;&#21644;&#36328;&#20250;&#35805;&#21709;&#24212;&#30340;&#32508;&#21512;&#29992;&#25143;&#29615;&#22659;&#12290;&#25152;&#24471;&#21040;&#30340;&#27169;&#25311;&#22120;&#33021;&#22815;&#25903;&#25345;&#19977;&#20010;&#23618;&#27425;&#30340;&#25512;&#33616;&#38382;&#39064;&#65306;&#35831;&#27714;&#31561;&#32423;&#12289; &#29992;&#25143;&#24847;&#22270;&#39044;&#27979;&#12289; &#21644;&#24207;&#21015;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning (RL)-based recommender systems (RSs) have garnered considerable attention due to their ability to learn optimal recommendation policies and maximize long-term user rewards. However, deploying RL models directly in online environments and generating authentic data through A/B tests can pose challenges and require substantial resources. Simulators offer an alternative approach by providing training and evaluation environments for RS models, reducing reliance on real-world data. Existing simulators have shown promising results but also have limitations such as simplified user feedback, lacking consistency with real-world data, the challenge of simulator evaluation, and difficulties in migration and expansion across RSs. To address these challenges, we propose KuaiSim, a comprehensive user environment that provides user feedback with multi-behavior and cross-session responses. The resulting simulator can support three levels of recommendation problems: the request le
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#36807;&#28388;&#27873;&#38382;&#39064;&#65292;&#36890;&#36807;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#21644;&#27979;&#37327;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#26469;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#30340;&#24847;&#22806;&#24615;&#29289;&#21697;&#12290;</title><link>http://arxiv.org/abs/2308.06368</link><description>&lt;p&gt;
&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#21644;&#24847;&#22806;&#24615;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Topic-Level Bayesian Surprise and Serendipity for Recommender Systems. (arXiv:2308.06368v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#36807;&#28388;&#27873;&#38382;&#39064;&#65292;&#36890;&#36807;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#21644;&#27979;&#37327;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#26469;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#30340;&#24847;&#22806;&#24615;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20248;&#21270;&#20854;&#25512;&#33616;&#20165;&#36866;&#21512;&#29992;&#25143;&#23545;&#24050;&#28040;&#36153;&#29289;&#21697;&#30340;&#35780;&#32423;&#21382;&#21490;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#36807;&#28388;&#27873;&#65292;&#29992;&#25143;&#26080;&#27861;&#20174;&#26032;&#39062;&#12289;&#26410;&#35265;&#36807;&#30340;&#31867;&#21035;&#20013;&#20307;&#39564;&#29289;&#21697;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#24847;&#22806;&#24615;&#24418;&#24335;&#65292;&#20197;&#36125;&#21494;&#26031;&#24778;&#21916;&#20026;&#22522;&#30784;&#65292;&#29992;&#20110;&#27979;&#37327;&#29992;&#25143;&#28040;&#36153;&#24182;&#35780;&#32423;&#21518;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#12290;&#32467;&#21512;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#30340;&#21327;&#21516;&#36807;&#28388;&#32452;&#20214;&#65292;&#21487;&#20197;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#24847;&#22806;&#24615;&#30340;&#29289;&#21697;&#12290;&#20026;&#20102;&#20415;&#20110;&#35780;&#20272;&#20027;&#39064;&#32423;&#21035;&#30340;&#24778;&#21916;&#21644;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#20174;Goodreads&#20013;&#25552;&#21462;&#30340;&#22270;&#20070;&#38405;&#35835;&#21382;&#21490;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#36229;&#36807;26&#21315;&#20010;&#29992;&#25143;&#21644;&#36817;130&#19975;&#26412;&#20070;&#65292;&#24182;&#23545;&#20854;&#20013;&#30340;449&#31687;&#20070;&#36827;&#34892;&#20102;&#25163;&#21160;&#27880;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 
&lt;/p&gt;</description></item><item><title>Amazon-M2&#26159;&#19968;&#20010;&#22810;&#35821;&#35328;&#22810;&#21306;&#22495;&#36141;&#29289;&#20250;&#35805;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#22686;&#24378;&#20010;&#24615;&#21270;&#25512;&#33616;&#21644;&#29702;&#35299;&#29992;&#25143;&#20559;&#22909;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.09688</link><description>&lt;p&gt;
Amazon-M2: &#19968;&#20010;&#29992;&#20110;&#25512;&#33616;&#21644;&#25991;&#26412;&#29983;&#25104;&#30340;&#22810;&#35821;&#35328;&#22810;&#21306;&#22495;&#36141;&#29289;&#20250;&#35805;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation. (arXiv:2307.09688v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09688
&lt;/p&gt;
&lt;p&gt;
Amazon-M2&#26159;&#19968;&#20010;&#22810;&#35821;&#35328;&#22810;&#21306;&#22495;&#36141;&#29289;&#20250;&#35805;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#22686;&#24378;&#20010;&#24615;&#21270;&#25512;&#33616;&#21644;&#29702;&#35299;&#29992;&#25143;&#20559;&#22909;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#30005;&#23376;&#21830;&#21153;&#26469;&#35828;&#65292;&#24314;&#27169;&#23458;&#25143;&#36141;&#29289;&#24847;&#22270;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#23427;&#30452;&#25509;&#24433;&#21709;&#29992;&#25143;&#20307;&#39564;&#21644;&#21442;&#19982;&#24230;&#12290;&#22240;&#27492;&#65292;&#20934;&#30830;&#29702;&#35299;&#23458;&#25143;&#30340;&#20559;&#22909;&#23545;&#20110;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#33267;&#20851;&#37325;&#35201;&#12290;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#25216;&#26415;&#21033;&#29992;&#23458;&#25143;&#20250;&#35805;&#25968;&#25454;&#26469;&#39044;&#27979;&#20182;&#20204;&#30340;&#19979;&#19968;&#27425;&#20114;&#21160;&#65292;&#24050;&#32463;&#36234;&#26469;&#36234;&#21463;&#21040;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20250;&#35805;&#25968;&#25454;&#38598;&#22312;&#39033;&#30446;&#23646;&#24615;&#12289;&#29992;&#25143;&#22810;&#26679;&#24615;&#21644;&#25968;&#25454;&#38598;&#35268;&#27169;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#19981;&#33021;&#20840;&#38754;&#22320;&#25429;&#25417;&#29992;&#25143;&#34892;&#20026;&#21644;&#20559;&#22909;&#30340;&#35889;&#31995;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Amazon Multilingual Multi-locale Shopping Session Dataset&#65292;&#21363;Amazon-M2&#12290;&#23427;&#26159;&#31532;&#19968;&#20010;&#30001;&#26469;&#33258;&#20845;&#20010;&#19981;&#21516;&#21306;&#22495;&#30340;&#25968;&#30334;&#19975;&#29992;&#25143;&#20250;&#35805;&#32452;&#25104;&#30340;&#22810;&#35821;&#35328;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#20135;&#21697;&#30340;&#20027;&#35201;&#35821;&#35328;&#26159;&#33521;&#35821;&#12289;&#24503;&#35821;&#12289;&#26085;&#35821;&#12289;&#27861;&#35821;&#12289;&#24847;&#22823;&#21033;&#35821;&#21644;&#35199;&#29677;&#29273;&#35821;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#22686;&#24378;&#20010;&#24615;&#21270;&#21644;&#29702;&#35299;&#29992;&#25143;&#20559;&#22909;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, w
&lt;/p&gt;</description></item><item><title>AdANNS&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#35821;&#20041;&#25628;&#32034;&#26694;&#26550;&#65292;&#21033;&#29992;&#19981;&#21516;&#23481;&#37327;&#30340;&#33258;&#36866;&#24212;&#34920;&#31034;&#24418;&#24335;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#65292;&#30456;&#20284;&#24230;&#35745;&#31639;&#36234;&#25509;&#36817;&#30340;&#25968;&#25454;&#28857;&#23558;&#20351;&#29992;&#26356;&#20302;&#23481;&#37327;&#30340;&#34920;&#31034;&#24418;&#24335;&#36827;&#34892;&#35745;&#31639;&#65292;&#28436;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.19435</link><description>&lt;p&gt;
AdANNS: &#19968;&#31181;&#33258;&#36866;&#24212;&#35821;&#20041;&#25628;&#32034;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
AdANNS: A Framework for Adaptive Semantic Search. (arXiv:2305.19435v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19435
&lt;/p&gt;
&lt;p&gt;
AdANNS&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#35821;&#20041;&#25628;&#32034;&#26694;&#26550;&#65292;&#21033;&#29992;&#19981;&#21516;&#23481;&#37327;&#30340;&#33258;&#36866;&#24212;&#34920;&#31034;&#24418;&#24335;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#65292;&#30456;&#20284;&#24230;&#35745;&#31639;&#36234;&#25509;&#36817;&#30340;&#25968;&#25454;&#28857;&#23558;&#20351;&#29992;&#26356;&#20302;&#23481;&#37327;&#30340;&#34920;&#31034;&#24418;&#24335;&#36827;&#34892;&#35745;&#31639;&#65292;&#28436;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#35268;&#27169;&#30340;&#25628;&#32034;&#31995;&#32479;&#23398;&#20064;&#19968;&#20010;&#32534;&#30721;&#22120;&#26469;&#23884;&#20837;&#19968;&#20010;&#32473;&#23450;&#30340;&#26597;&#35810;&#65292;&#28982;&#21518;&#23558;&#20854;&#36830;&#25509;&#21040;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;(ANNS)&#31649;&#36947;&#20013;&#26469;&#26816;&#32034;&#30456;&#20284;&#30340;&#25968;&#25454;&#28857;&#12290;&#20026;&#20102;&#20934;&#30830;&#22320;&#25429;&#25417;&#23614;&#37096;&#26597;&#35810;&#21644;&#25968;&#25454;&#28857;&#65292;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#36890;&#24120;&#26159;&#21018;&#24615;&#30340;&#12289;&#39640;&#32500;&#30340;&#21521;&#37327;&#65292;&#36890;&#24120;&#22312;&#25972;&#20010;ANNS&#31649;&#36947;&#20013;&#19968;&#25104;&#19981;&#21464;&#65292;&#24182;&#19988;&#21487;&#33021;&#23548;&#33268;&#35745;&#31639;&#19978;&#26114;&#36149;&#30340;&#26816;&#32034;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#19982;&#20854;&#20351;&#29992;&#21018;&#24615;&#30340;&#34920;&#31034;&#24418;&#24335;&#65292;ANNS&#30340;&#19981;&#21516;&#38454;&#27573;&#21487;&#20197;&#21033;&#29992;&#19981;&#21516;&#23481;&#37327;&#30340;&#33258;&#36866;&#24212;&#34920;&#31034;&#24418;&#24335;&#20197;&#33719;&#24471;&#26174;&#33879;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#65292;&#21363;&#21487;&#20197;&#36827;&#34892;&#26356;&#21152;&#36817;&#20284;&#35745;&#31639;&#30340;ANNS&#38454;&#27573;&#24212;&#35813;&#20351;&#29992;&#30456;&#21516;&#25968;&#25454;&#28857;&#30340;&#20302;&#23481;&#37327;&#34920;&#31034;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;AdANNS&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;ANNS&#35774;&#35745;&#26694;&#26550;&#65292;&#26126;&#30830;&#21033;&#29992;Matryoshka&#34920;&#31034;&#30340;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;AdANNS&#30340;&#26032;&#22411;&#20851;&#38190;ANNS&#26500;&#24314;&#28436;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Web-scale search systems learn an encoder to embed a given query which is then hooked into an approximate nearest neighbor search (ANNS) pipeline to retrieve similar data points. To accurately capture tail queries and data points, learned representations typically are rigid, high-dimensional vectors that are generally used as-is in the entire ANNS pipeline and can lead to computationally expensive retrieval. In this paper, we argue that instead of rigid representations, different stages of ANNS can leverage adaptive representations of varying capacities to achieve significantly better accuracy-compute trade-offs, i.e., stages of ANNS that can get away with more approximate computation should use a lower-capacity representation of the same data point. To this end, we introduce AdANNS, a novel ANNS design framework that explicitly leverages the flexibility of Matryoshka Representations. We demonstrate state-of-the-art accuracy-compute trade-offs using novel AdANNS-based key ANNS building
&lt;/p&gt;</description></item><item><title>PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.06674</link><description>&lt;p&gt;
PK-ICR: &#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#36827;&#34892;&#22522;&#20110;&#22330;&#26223;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue. (arXiv:2302.06674v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06674
&lt;/p&gt;
&lt;p&gt;
PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#21035;&#19982;&#23545;&#35805;&#31995;&#32479;&#30456;&#20851;&#30340;&#35282;&#33394;&#21644;&#30693;&#35782;&#23545;&#20110;&#22522;&#20110;&#22330;&#26223;&#30340;&#23545;&#35805;&#24212;&#31572;&#29983;&#25104;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#27599;&#20010;&#23545;&#35805;&#22522;&#26412;&#19978;&#37117;&#26159;&#23396;&#31435;&#30740;&#31350;&#30340;&#65292;&#32780;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#24341;&#20837;&#20102;&#26356;&#23454;&#38469;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20219;&#21153;&#12290;&#25105;&#20204;&#23558;&#35282;&#33394;&#21644;&#30693;&#35782;&#21452;&#19978;&#19979;&#25991;&#35782;&#21035;&#23450;&#20041;&#20026;&#20026;&#32473;&#23450;&#30340;&#23545;&#35805;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20219;&#21153;&#65292;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#35774;&#32622;&#20013;&#21487;&#33021;&#20855;&#26377;&#25552;&#21319;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26816;&#32034;&#30340;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#21033;&#29992;&#23545;&#35805;&#30340;&#25152;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#34913;&#37327;&#19982;&#25968;&#25454;&#22686;&#24378;&#30456;&#20851;&#30340;&#35821;&#20041;&#24046;&#24322;&#26679;&#26412;&#65288;&#21363;&#22256;&#38590;&#36127;&#26679;&#26412;&#65289;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying relevant persona or knowledge for conversational systems is critical to grounded dialogue response generation. However, each grounding has been mostly researched in isolation with more practical multi-context dialogue tasks introduced in recent works. We define Persona and Knowledge Dual Context Identification as the task to identify persona and knowledge jointly for a given dialogue, which could be of elevated importance in complex multi-context dialogue settings. We develop a novel grounding retrieval method that utilizes all contexts of dialogue simultaneously. Our method requires less computational power via utilizing neural QA retrieval models. We further introduce our novel null-positive rank test which measures ranking performance on semantically dissimilar samples (i.e. hard negatives) in relation to data augmentation.
&lt;/p&gt;</description></item></channel></rss>