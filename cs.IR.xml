<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#30828;&#36127;&#26679;&#26412;&#25913;&#36827;&#22810;&#27169;&#24577;&#23545;&#27604;&#23398;&#20064;&#20013;&#27010;&#24565;&#29702;&#35299;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#35780;&#20272;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#39068;&#33394;&#12289;&#23545;&#35937;&#21644;&#22823;&#23567;&#32454;&#31890;&#24230;&#23545;&#40784;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.02875</link><description>&lt;p&gt;
&#36890;&#36807;&#30828;&#36127;&#26679;&#26412;&#22686;&#24378;&#22810;&#27169;&#24577;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#27010;&#24565;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Enhancing Conceptual Understanding in Multimodal Contrastive Learning through Hard Negative Samples
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02875
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#30828;&#36127;&#26679;&#26412;&#25913;&#36827;&#22810;&#27169;&#24577;&#23545;&#27604;&#23398;&#20064;&#20013;&#27010;&#24565;&#29702;&#35299;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#35780;&#20272;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#39068;&#33394;&#12289;&#23545;&#35937;&#21644;&#22823;&#23567;&#32454;&#31890;&#24230;&#23545;&#40784;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#21033;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#22312;&#21457;&#23637;&#31934;&#32454;&#30340;&#27010;&#24565;&#29702;&#35299;&#26041;&#38754;&#36890;&#24120;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#12290;&#22312;&#39044;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#30001;&#20110;&#38543;&#26426;&#36127;&#26679;&#26412;&#65292;&#23548;&#33268;&#20960;&#20046;&#21482;&#26377;&#38750;&#24120;&#19981;&#21516;&#30340;&#27010;&#24565;&#36827;&#34892;&#25439;&#22833;&#20989;&#25968;&#27604;&#36739;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#22312;&#22788;&#29702;&#32454;&#31890;&#24230;&#35821;&#20041;&#24046;&#24322;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#21512;&#25104;&#30340;&#30828;&#36127;&#25991;&#26412;&#31034;&#20363;&#12290;&#36825;&#20123;&#30828;&#36127;&#26679;&#26412;&#23545;&#24212;&#20110;&#35270;&#35273;&#27010;&#24565;&#30340;&#25490;&#21015;&#65292;&#23548;&#33268;&#26356;&#31934;&#32454;&#30340;&#35270;&#35273;&#21644;&#25991;&#26412;&#27010;&#24565;&#23545;&#40784;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;InpaintCOCO&#65292;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#39068;&#33394;&#12289;&#23545;&#35937;&#21644;&#22823;&#23567;&#32454;&#31890;&#24230;&#23545;&#40784;&#30340;&#26032;&#25361;&#25112;&#24615;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#20351;&#29992;&#20174;COCO&#22270;&#20687;&#29983;&#25104;&#30340;&#20449;&#24687;&#22635;&#20805;&#26469;&#21019;&#24314;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#25913;&#21464;&#35270;&#35273;&#27010;&#24565;&#65292;&#20351;&#22270;&#20687;&#19981;&#20877;&#19982;&#20854;&#21407;&#22987;&#26631;&#39064;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02875v1 Announce Type: cross  Abstract: Current multimodal models leveraging contrastive learning often face limitations in developing fine-grained conceptual understanding. This is due to random negative samples during pretraining, causing almost exclusively very dissimilar concepts to be compared in the loss function. Consequently, the models struggle with fine-grained semantic differences. To address this problem, we introduce a novel pretraining method incorporating synthetic hard negative text examples. The hard negatives permute terms corresponding to visual concepts, leading to a more fine-grained visual and textual concept alignment. Further, we introduce InpaintCOCO, a new challenging dataset for assessing the fine-grained alignment of colors, objects, and sizes in vision-language models. We created the dataset using generative inpainting from COCO images by changing the visual concepts so that the images no longer match their original captions. Our results show sig
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#27604;&#24615;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#20837;&#30740;&#31350;&#29992;&#25143;&#20250;&#35805;&#20013;&#30340;&#20016;&#23500;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#28145;&#24230;&#20250;&#35805;&#25968;&#25454;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.02825</link><description>&lt;p&gt;
&#28145;&#24230;&#20250;&#35805;&#25968;&#25454;&#29702;&#35299;&#30340;&#23545;&#27604;&#39044;&#35757;&#32451;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Contrastive Pre-training for Deep Session Data Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#27604;&#24615;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#20837;&#30740;&#31350;&#29992;&#25143;&#20250;&#35805;&#20013;&#30340;&#20016;&#23500;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#28145;&#24230;&#20250;&#35805;&#25968;&#25454;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#25968;&#25454;&#24191;&#27867;&#29992;&#20110;&#29702;&#35299;&#30005;&#23376;&#21830;&#21153;&#20013;&#29992;&#25143;&#34892;&#20026;&#12290;&#30740;&#31350;&#20154;&#21592;&#35797;&#22270;&#21033;&#29992;&#20250;&#35805;&#25968;&#25454;&#36827;&#34892;&#19981;&#21516;&#20219;&#21153;&#65292;&#22914;&#36141;&#20080;&#24847;&#21521;&#39044;&#27979;&#12289;&#21097;&#20313;&#38271;&#24230;&#39044;&#27979;&#12289;&#25512;&#33616;&#31561;&#65292;&#22240;&#20026;&#23427;&#25552;&#20379;&#20102;&#26377;&#20851;&#29992;&#25143;&#21160;&#24577;&#20852;&#36259;&#30340;&#19978;&#19979;&#25991;&#32447;&#32034;&#12290;&#28982;&#32780;&#65292;&#22312;&#32447;&#36141;&#29289;&#20250;&#35805;&#25968;&#25454;&#22312;&#32467;&#26500;&#19978;&#26159;&#21322;&#32467;&#26500;&#21270;&#21644;&#22797;&#26434;&#30340;&#65292;&#26082;&#21253;&#21547;&#26377;&#20851;&#20135;&#21697;&#30340;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#25968;&#25454;&#12289;&#25628;&#32034;&#26597;&#35810;&#65292;&#21448;&#21253;&#21547;&#32467;&#26500;&#21270;&#30340;&#29992;&#25143;&#21160;&#20316;&#24207;&#21015;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#20391;&#37325;&#20110;&#21033;&#29992;&#31895;&#31890;&#24230;&#30340;&#29289;&#21697;&#24207;&#21015;&#25191;&#34892;&#29305;&#23450;&#20219;&#21153;&#65292;&#32780;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#30053;&#20102;&#25991;&#26412;&#21644;&#29992;&#25143;&#21160;&#20316;&#32454;&#33410;&#20013;&#30340;&#32454;&#31890;&#24230;&#20449;&#24687;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23457;&#26597;&#29992;&#25143;&#20250;&#35805;&#20013;&#20016;&#23500;&#20449;&#24687;&#20869;&#30340;&#21508;&#31181;&#32447;&#32034;&#65292;&#28145;&#20837;&#30740;&#31350;&#28145;&#24230;&#20250;&#35805;&#25968;&#25454;&#29702;&#35299;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#35758;&#23545;&#20855;&#26377;&#20016;&#23500;&#30340;&#29305;&#24449;&#30340;&#22823;&#35268;&#27169;&#20250;&#35805;&#25968;&#25454;&#36827;&#34892;&#36890;&#29992;&#29992;&#25143;&#34892;&#20026;&#27169;&#22411;&#65288;UBM&#65289;&#30340;&#39044;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02825v1 Announce Type: new  Abstract: Session data has been widely used for understanding user's behavior in e-commerce. Researchers are trying to leverage session data for different tasks, such as purchase intention prediction, remaining length prediction, recommendation, etc., as it provides context clues about the user's dynamic interests. However, online shopping session data is semi-structured and complex in nature, which contains both unstructured textual data about the products, search queries, and structured user action sequences. Most existing works focus on leveraging the coarse-grained item sequences for specific tasks, while largely ignore the fine-grained information from text and user action details. In this work, we delve into deep session data understanding via scrutinizing the various clues inside the rich information in user sessions. Specifically, we propose to pre-train a general-purpose User Behavior Model (UBM) over large-scale session data with rich de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#23558;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#19982;&#24230;&#37327;&#23398;&#20064;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#23398;&#20064;&#27169;&#22411; VIB-DML &#29992;&#20110;&#35780;&#20998;&#39044;&#27979;&#65292;&#38480;&#21046;&#28508;&#31354;&#38388;&#29305;&#24449;&#21521;&#37327;&#30340;&#20114;&#20449;&#24687;&#20197;&#25552;&#39640;&#27169;&#22411;&#40065;&#26834;&#24615;&#24182;&#28385;&#36275;&#27431;&#27663;&#36317;&#31163;&#30340;&#20551;&#35774;&#12290;</title><link>https://arxiv.org/abs/2403.02794</link><description>&lt;p&gt;
&#22522;&#20110;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#30340;&#36317;&#31163;&#24230;&#37327;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Distance Metric Learning Model Based On Variational Information Bottleneck
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02794
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#23558;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#19982;&#24230;&#37327;&#23398;&#20064;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#23398;&#20064;&#27169;&#22411; VIB-DML &#29992;&#20110;&#35780;&#20998;&#39044;&#27979;&#65292;&#38480;&#21046;&#28508;&#31354;&#38388;&#29305;&#24449;&#21521;&#37327;&#30340;&#20114;&#20449;&#24687;&#20197;&#25552;&#39640;&#27169;&#22411;&#40065;&#26834;&#24615;&#24182;&#28385;&#36275;&#27431;&#27663;&#36317;&#31163;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20010;&#24615;&#21270;&#25512;&#33616;&#25216;&#26415;&#34028;&#21187;&#21457;&#23637;&#65292;&#25104;&#20026;&#30740;&#31350;&#28909;&#28857;&#20043;&#19968;&#12290;&#20808;&#21518;&#25552;&#20986;&#30340;&#30697;&#38453;&#20998;&#35299;&#27169;&#22411;&#21644;&#24230;&#37327;&#23398;&#20064;&#27169;&#22411;&#24050;&#34987;&#24191;&#27867;&#30740;&#31350;&#21644;&#24212;&#29992;&#12290;&#21518;&#32773;&#20351;&#29992;&#27431;&#27663;&#36317;&#31163;&#32780;&#38750;&#21069;&#32773;&#25152;&#20351;&#29992;&#30340;&#28857;&#31215;&#26469;&#34913;&#37327;&#28508;&#31354;&#38388;&#21521;&#37327;&#12290;&#26412;&#25991;&#39318;&#27425;&#23558;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#19982;&#24230;&#37327;&#23398;&#20064;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#23398;&#20064;&#27169;&#22411; VIB-DML&#65288;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#36317;&#31163;&#24230;&#37327;&#23398;&#20064;&#65289;&#29992;&#20110;&#35780;&#20998;&#39044;&#27979;&#65292;&#38480;&#21046;&#28508;&#31354;&#38388;&#29305;&#24449;&#21521;&#37327;&#30340;&#20114;&#20449;&#24687;&#65292;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#24182;&#28385;&#36275;&#27431;&#27663;&#36317;&#31163;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02794v1 Announce Type: cross  Abstract: In recent years, personalized recommendation technology has flourished and become one of the hot research directions. The matrix factorization model and the metric learning model which proposed successively have been widely studied and applied. The latter uses the Euclidean distance instead of the dot product used by the former to measure the latent space vector. While avoiding the shortcomings of the dot product, the assumption of Euclidean distance is neglected, resulting in limited recommendation quality of the model. In order to solve this problem, this paper combines the Variationl Information Bottleneck with metric learning model for the first time, and proposes a new metric learning model VIB-DML (Variational Information Bottleneck Distance Metric Learning) for rating prediction, which limits the mutual information of the latent space feature vector to improve the robustness of the model and satisfiy the assumption of Euclidean 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23398;&#20064;&#27169;&#22411;&#65292;&#32467;&#21512;&#20102;&#38544;&#24335;&#20250;&#35805;&#21453;&#39304;&#21644;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#20197;&#38382;&#35810;&#29992;&#25143;&#22312;&#25506;&#32034;&#19968;&#27573;&#26102;&#38388;&#21518;&#27491;&#22312;&#23547;&#25214;&#30340;&#20851;&#38190;&#23646;&#24615;&#26469;&#24110;&#21161;&#20135;&#21697;&#25628;&#32034;&#12290;</title><link>https://arxiv.org/abs/2403.02754</link><description>&lt;p&gt;
&#23398;&#20064;&#25552;&#20986;&#20851;&#38190;&#38382;&#39064;&#20197;&#24110;&#21161;&#20135;&#21697;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Learning to Ask Critical Questions for Assisting Product Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02754
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23398;&#20064;&#27169;&#22411;&#65292;&#32467;&#21512;&#20102;&#38544;&#24335;&#20250;&#35805;&#21453;&#39304;&#21644;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#20197;&#38382;&#35810;&#29992;&#25143;&#22312;&#25506;&#32034;&#19968;&#27573;&#26102;&#38388;&#21518;&#27491;&#22312;&#23547;&#25214;&#30340;&#20851;&#38190;&#23646;&#24615;&#26469;&#24110;&#21161;&#20135;&#21697;&#25628;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20135;&#21697;&#25628;&#32034;&#22312;&#30005;&#23376;&#21830;&#21153;&#20013;&#25198;&#28436;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#35282;&#33394;&#65292;&#23427;&#34987;&#35270;&#20026;&#19968;&#31181;&#29305;&#27530;&#31867;&#22411;&#30340;&#20449;&#24687;&#26816;&#32034;&#38382;&#39064;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24037;&#20316;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#26469;&#25552;&#21319;&#25628;&#32034;&#24615;&#33021;&#65292;&#26410;&#30452;&#25509;&#21033;&#29992;&#29992;&#25143;&#24403;&#21069;&#30340;&#20852;&#36259;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26368;&#36817;&#30340;&#23545;&#35805;&#25110;&#22522;&#20110;&#38382;&#39064;&#30340;&#25628;&#32034;&#27169;&#22411;&#30452;&#25509;&#19982;&#29992;&#25143;&#20132;&#20114;&#65292;&#20197;&#26126;&#30830;&#20102;&#35299;&#29992;&#25143;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29992;&#25143;&#22312;&#26368;&#21021;&#38454;&#27573;&#24182;&#19981;&#28165;&#26970;&#35201;&#36141;&#20080;&#20160;&#20040;&#12290;&#22312;&#29992;&#25143;&#25506;&#32034;&#19968;&#27573;&#26102;&#38388;&#21518;&#35810;&#38382;&#29992;&#25143;&#27491;&#22312;&#23547;&#25214;&#30340;&#20851;&#38190;&#23646;&#24615;&#24212;&#35813;&#26159;&#24110;&#21161;&#20182;&#20204;&#25628;&#32034;&#30446;&#26631;&#39033;&#30446;&#30340;&#26356;&#26377;&#25928;&#26041;&#24335;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#20102;&#38544;&#24335;&#20250;&#35805;&#21453;&#39304;&#21644;&#20027;&#21160;&#23398;&#20064;&#30340;&#21452;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02754v1 Announce Type: new  Abstract: Product search plays an essential role in eCommerce. It was treated as a special type of information retrieval problem. Most existing works make use of historical data to improve the search performance, which do not take the opportunity to ask for user's current interest directly. Some session-aware methods take the user's clicks within the session as implicit feedback, but it is still just a guess on user's preference. To address this problem, recent conversational or question-based search models interact with users directly for understanding the user's interest explicitly. However, most users do not have a clear picture on what to buy at the initial stage. Asking critical attributes that the user is looking for after they explored for a while should be a more efficient way to help them searching for the target items. In this paper, we propose a dual-learning model that hybrids the best from both implicit session feedback and proactivel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38754;&#21521;&#25512;&#33616;&#31995;&#32479;&#30340;&#30446;&#26631;&#29992;&#25143;&#25915;&#20987;&#30340;&#25552;&#21319;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#24322;&#36136;&#22788;&#29702;&#25928;&#24212;&#21644;&#25552;&#21319;&#24341;&#23548;&#30340;&#39044;&#31639;&#20998;&#37197;&#26694;&#26550;&#65292;&#20248;&#21270;&#20551;&#29992;&#25143;&#39044;&#31639;&#30340;&#20998;&#37197;&#26469;&#26368;&#22823;&#21270;&#25915;&#20987;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.02692</link><description>&lt;p&gt;
&#38754;&#21521;&#25512;&#33616;&#31995;&#32479;&#30340;&#30446;&#26631;&#29992;&#25143;&#25915;&#20987;&#30340;&#25552;&#21319;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Uplift Modeling for Target User Attacks on Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38754;&#21521;&#25512;&#33616;&#31995;&#32479;&#30340;&#30446;&#26631;&#29992;&#25143;&#25915;&#20987;&#30340;&#25552;&#21319;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#24322;&#36136;&#22788;&#29702;&#25928;&#24212;&#21644;&#25552;&#21319;&#24341;&#23548;&#30340;&#39044;&#31639;&#20998;&#37197;&#26694;&#26550;&#65292;&#20248;&#21270;&#20551;&#29992;&#25143;&#39044;&#31639;&#30340;&#20998;&#37197;&#26469;&#26368;&#22823;&#21270;&#25915;&#20987;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#27880;&#20837;&#24335;&#25915;&#20987;&#65292;&#21363;&#23558;&#26377;&#38480;&#25968;&#37327;&#30340;&#20551;&#29992;&#25143;&#27880;&#20837;&#24179;&#21488;&#20197;&#25805;&#32437;&#30446;&#26631;&#29289;&#21697;&#23545;&#25152;&#26377;&#29992;&#25143;&#30340;&#26333;&#20809;&#12290;&#26412;&#25991;&#21457;&#29616;&#20256;&#32479;&#30340;&#27880;&#20837;&#24335;&#25915;&#20987;&#32773;&#24573;&#35270;&#20102;&#27599;&#20010;&#29289;&#21697;&#37117;&#26377;&#20854;&#29420;&#29305;&#30340;&#28508;&#22312;&#21463;&#20247;&#36825;&#19968;&#20107;&#23454;&#65292;&#21516;&#26102;&#65292;&#19981;&#21516;&#29992;&#25143;&#20043;&#38388;&#30340;&#25915;&#20987;&#38590;&#24230;&#19981;&#21516;&#12290;&#30450;&#30446;&#25915;&#20987;&#25152;&#26377;&#29992;&#25143;&#23558;&#23548;&#33268;&#20551;&#29992;&#25143;&#39044;&#31639;&#30340;&#28010;&#36153;&#21644;&#36739;&#24046;&#30340;&#25915;&#20987;&#24615;&#33021;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20851;&#27880;&#19968;&#31181;&#34987;&#24573;&#35270;&#30340;&#25915;&#20987;&#20219;&#21153;&#65292;&#31216;&#20026;&#30446;&#26631;&#29992;&#25143;&#25915;&#20987;&#65292;&#26088;&#22312;&#23558;&#30446;&#26631;&#29289;&#21697;&#25512;&#24191;&#32473;&#29305;&#23450;&#29992;&#25143;&#32676;&#20307;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22240;&#26524;&#38236;&#22836;&#23558;&#19981;&#21516;&#30340;&#25915;&#20987;&#38590;&#24230;&#24418;&#25104;&#20026;&#24322;&#36136;&#22788;&#29702;&#25928;&#24212;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#21319;&#24341;&#23548;&#30340;&#39044;&#31639;&#20998;&#37197;&#65288;UBA&#65289;&#26694;&#26550;&#12290;UBA&#35780;&#20272;&#27599;&#20010;&#30446;&#26631;&#29992;&#25143;&#30340;&#22788;&#29702;&#25928;&#24212;&#65292;&#24182;&#20248;&#21270;&#20551;&#29992;&#25143;&#39044;&#31639;&#30340;&#20998;&#37197;&#65292;&#20197;&#26368;&#22823;&#21270;&#25915;&#20987;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02692v1 Announce Type: new  Abstract: Recommender systems are vulnerable to injective attacks, which inject limited fake users into the platforms to manipulate the exposure of target items to all users. In this work, we identify that conventional injective attackers overlook the fact that each item has its unique potential audience, and meanwhile, the attack difficulty across different users varies. Blindly attacking all users will result in a waste of fake user budgets and inferior attack performance. To address these issues, we focus on an under-explored attack task called target user attacks, aiming at promoting target items to a particular user group. In addition, we formulate the varying attack difficulty as heterogeneous treatment effects through a causal lens and propose an Uplift-guided Budget Allocation (UBA) framework. UBA estimates the treatment effect on each target user and optimizes the allocation of fake user budgets to maximize the attack performance. Theoret
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;FedHCDR&#26694;&#26550;&#65292;&#36890;&#36807;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#30340;&#26041;&#24335;&#35299;&#20915;&#20102;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#19981;&#21516;&#39046;&#22495;&#25968;&#25454;&#24322;&#36136;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.02630</link><description>&lt;p&gt;
FedHCDR: &#20855;&#26377;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#30340;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
FedHCDR: Federated Cross-Domain Recommendation with Hypergraph Signal Decoupling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02630
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;FedHCDR&#26694;&#26550;&#65292;&#36890;&#36807;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#30340;&#26041;&#24335;&#35299;&#20915;&#20102;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#19981;&#21516;&#39046;&#22495;&#25968;&#25454;&#24322;&#36136;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36328;&#39046;&#22495;&#25512;&#33616;&#65288;CDR&#65289;&#22791;&#21463;&#20851;&#27880;&#65292;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#39046;&#22495;&#30340;&#29992;&#25143;&#25968;&#25454;&#26469;&#22686;&#24378;&#25512;&#33616;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;CDR&#26041;&#27861;&#38656;&#35201;&#36328;&#39046;&#22495;&#20849;&#20139;&#29992;&#25143;&#25968;&#25454;&#65292;&#36829;&#21453;&#20102;&#12298;&#36890;&#29992;&#25968;&#25454;&#20445;&#25252;&#26465;&#20363;&#12299;&#65288;GDPR&#65289;&#12290;&#22240;&#27492;&#65292;&#24050;&#25552;&#20986;&#20102;&#35768;&#22810;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;&#65288;FedCDR&#65289;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#19981;&#21516;&#39046;&#22495;&#38388;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#19981;&#21487;&#36991;&#20813;&#22320;&#24433;&#21709;&#20102;&#32852;&#37030;&#23398;&#20064;&#30340;&#25972;&#20307;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FedHCDR&#65292;&#19968;&#31181;&#20855;&#26377;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#30340;&#26032;&#22411;&#32852;&#37030;&#36328;&#39046;&#22495;&#25512;&#33616;&#26694;&#26550;&#12290;&#20855;&#20307;&#22320;&#65292;&#20026;&#20102;&#35299;&#20915;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#31216;&#20026;&#36229;&#22270;&#20449;&#21495;&#35299;&#32806;&#65288;HSD&#65289;&#30340;&#26041;&#27861;&#65292;&#23558;&#29992;&#25143;&#29305;&#24449;&#35299;&#32806;&#20026;&#39046;&#22495;&#29420;&#26377;&#21644;&#39046;&#22495;&#20849;&#20139;&#29305;&#24449;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#39640;&#36890;&#21644;&#20302;&#36890;&#36229;&#22270;&#28388;&#27874;&#22120;&#26469;&#36827;&#34892;&#35299;&#32806;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02630v1 Announce Type: new  Abstract: In recent years, Cross-Domain Recommendation (CDR) has drawn significant attention, which utilizes user data from multiple domains to enhance the recommendation performance. However, current CDR methods require sharing user data across domains, thereby violating the General Data Protection Regulation (GDPR). Consequently, numerous approaches have been proposed for Federated Cross-Domain Recommendation (FedCDR). Nevertheless, the data heterogeneity across different domains inevitably influences the overall performance of federated learning. In this study, we propose FedHCDR, a novel Federated Cross-Domain Recommendation framework with Hypergraph signal decoupling. Specifically, to address the data heterogeneity across domains, we introduce an approach called hypergraph signal decoupling (HSD) to decouple the user features into domain-exclusive and domain-shared features. The approach employs high-pass and low-pass hypergraph filters to de
&lt;/p&gt;</description></item><item><title>&#20010;&#24615;&#21270;&#25628;&#32034;&#24847;&#22270;&#32593;&#32476;&#35299;&#20915;&#20102;&#30005;&#23376;&#21830;&#21153;&#20013;&#26597;&#35810;&#33258;&#21160;&#34917;&#20840;&#31995;&#32479;&#38754;&#20020;&#30340;&#24847;&#22270;&#27169;&#31946;&#24615;&#21644;&#24847;&#22270;&#36716;&#31227;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.02609</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#30005;&#23376;&#21830;&#21153;&#26597;&#35810;&#33258;&#21160;&#34917;&#20840;&#30340;&#25628;&#32034;&#24847;&#22270;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Search Intenion Network for Personalized Query Auto-Completion in E-Commerce
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02609
&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#25628;&#32034;&#24847;&#22270;&#32593;&#32476;&#35299;&#20915;&#20102;&#30005;&#23376;&#21830;&#21153;&#20013;&#26597;&#35810;&#33258;&#21160;&#34917;&#20840;&#31995;&#32479;&#38754;&#20020;&#30340;&#24847;&#22270;&#27169;&#31946;&#24615;&#21644;&#24847;&#22270;&#36716;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#33258;&#21160;&#34917;&#20840;&#65288;QAC&#65289;&#20316;&#20026;&#29616;&#20195;&#25628;&#32034;&#24341;&#25806;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#22312;&#34917;&#20805;&#29992;&#25143;&#26597;&#35810;&#24182;&#24110;&#21161;&#20182;&#20204;&#32454;&#21270;&#25628;&#32034;&#24847;&#22270;&#26041;&#38754;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;QAC&#31995;&#32479;&#38754;&#20020;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;1&#65289;&#24847;&#22270;&#27169;&#31946;&#24615;&#65288;IE&#65289;&#65306;&#22312;&#29992;&#25143;&#36755;&#20837;&#36807;&#31243;&#20013;&#65292;&#21069;&#32512;&#36890;&#24120;&#21253;&#21547;&#23383;&#31526;&#21644;&#23376;&#35789;&#30340;&#32452;&#21512;&#65292;&#36825;&#20351;&#24471;&#24403;&#21069;&#24847;&#22270;&#27169;&#31946;&#19988;&#38590;&#20197;&#24314;&#27169;&#12290;2&#65289;&#24847;&#22270;&#36716;&#31227;&#65288;IT&#65289;&#65306;&#20043;&#21069;&#30340;&#24037;&#20316;&#22522;&#20110;&#29992;&#25143;&#30340;&#21382;&#21490;&#24207;&#21015;&#25552;&#20379;&#24314;&#35758;&#65292;&#20294;&#24573;&#30053;&#20102;&#25628;&#32034;&#24847;&#22270;&#30340;&#36716;&#31227;&#12290;&#28982;&#32780;&#65292;&#20174;&#21069;&#32512;&#25552;&#21462;&#30340;&#24403;&#21069;&#24847;&#22270;&#21487;&#33021;&#19982;&#21382;&#21490;&#20559;&#22909;&#30456;&#24726;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02609v1 Announce Type: cross  Abstract: Query Auto-Completion(QAC), as an important part of the modern search engine, plays a key role in complementing user queries and helping them refine their search intentions.Today's QAC systems in real-world scenarios face two major challenges:1)intention equivocality(IE): during the user's typing process,the prefix often contains a combination of characters and subwords, which makes the current intention ambiguous and difficult to model.2)intention transfer (IT):previous works make personalized recommendations based on users' historical sequences, but ignore the search intention transfer.However, the current intention extracted from prefix may be contrary to the historical preferences.
&lt;/p&gt;</description></item><item><title>ChatCite&#26159;&#19968;&#20010;LLM&#20195;&#29702;&#65292;&#36890;&#36807;&#20154;&#24037;&#24037;&#20316;&#27969;&#24341;&#23548;&#36827;&#34892;&#27604;&#36739;&#25991;&#23398;&#32508;&#36848;&#65292;&#21033;&#29992;&#21453;&#24605;&#36880;&#27493;&#26426;&#21046;&#29983;&#25104;&#25688;&#35201;&#12290;</title><link>https://arxiv.org/abs/2403.02574</link><description>&lt;p&gt;
ChatCite&#65306;LLM&#20195;&#29702;&#19982;&#20154;&#24037;&#24037;&#20316;&#27969;&#24341;&#23548;&#29992;&#20110;&#27604;&#36739;&#25991;&#23398;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02574
&lt;/p&gt;
&lt;p&gt;
ChatCite&#26159;&#19968;&#20010;LLM&#20195;&#29702;&#65292;&#36890;&#36807;&#20154;&#24037;&#24037;&#20316;&#27969;&#24341;&#23548;&#36827;&#34892;&#27604;&#36739;&#25991;&#23398;&#32508;&#36848;&#65292;&#21033;&#29992;&#21453;&#24605;&#36880;&#27493;&#26426;&#21046;&#29983;&#25104;&#25688;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02574v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#23398;&#31185; &#25688;&#35201;&#65306;&#25991;&#29486;&#32508;&#36848;&#26159;&#30740;&#31350;&#36807;&#31243;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#19968;&#27493;&#12290;&#23427;&#26377;&#21161;&#20110;&#29702;&#35299;&#30740;&#31350;&#38382;&#39064;&#65292;&#24182;&#22312;&#36827;&#34892;&#20197;&#24448;&#20316;&#21697;&#27604;&#36739;&#20998;&#26512;&#26102;&#20102;&#35299;&#24403;&#21069;&#30740;&#31350;&#24773;&#20917;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#24635;&#32467;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#21644;&#32791;&#26102;&#30340;&#12290;&#20808;&#21069;&#22522;&#20110;LLM&#30340;&#25991;&#29486;&#32508;&#36848;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#23436;&#25972;&#36807;&#31243;&#65292;&#21253;&#25324;&#25991;&#29486;&#26816;&#32034;&#12289;&#31579;&#36873;&#21644;&#24635;&#32467;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#24635;&#32467;&#27493;&#39588;&#65292;&#31616;&#21333;&#30340;CoT&#26041;&#27861;&#24448;&#24448;&#32570;&#20047;&#25552;&#20379;&#24191;&#27867;&#27604;&#36739;&#24635;&#32467;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#19987;&#27880;&#20110;&#29420;&#31435;&#25991;&#29486;&#24635;&#32467;&#27493;&#39588;&#24182;&#24341;&#20837;ChatCite&#65292;&#19968;&#20010;&#20855;&#26377;&#20154;&#24037;&#24037;&#20316;&#27969;&#24341;&#23548;&#29992;&#20110;&#27604;&#36739;&#25991;&#23398;&#32508;&#36848;&#30340;LLM&#20195;&#29702;&#12290;&#35813;&#20195;&#29702;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#24037;&#20316;&#27969;&#65292;&#39318;&#20808;&#20174;&#30456;&#20851;&#25991;&#29486;&#20013;&#25552;&#21462;&#20851;&#38190;&#35201;&#32032;&#65292;&#28982;&#21518;&#20351;&#29992;&#21453;&#24605;&#36880;&#27493;&#26426;&#21046;&#29983;&#25104;&#25688;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02574v1 Announce Type: cross  Abstract: The literature review is an indispensable step in the research process. It provides the benefit of comprehending the research problem and understanding the current research situation while conducting a comparative analysis of prior works. However, literature summary is challenging and time consuming. The previous LLM-based studies on literature review mainly focused on the complete process, including literature retrieval, screening, and summarization. However, for the summarization step, simple CoT method often lacks the ability to provide extensive comparative summary. In this work, we firstly focus on the independent literature summarization step and introduce ChatCite, an LLM agent with human workflow guidance for comparative literature summary. This agent, by mimicking the human workflow, first extracts key elements from relevant literature and then generates summaries using a Reflective Incremental Mechanism. In order to better ev
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#30913;&#22330;&#30340;&#20307;&#20869;&#32435;&#31859;&#26426;&#22120;&#23450;&#20301;&#26041;&#27861;&#65292;&#21033;&#29992;&#20154;&#20307;&#32452;&#32455;&#30340;&#30913;&#23548;&#29575;&#65292;&#20026;&#19979;&#19968;&#20195;&#21307;&#30103;&#35786;&#26029;&#31995;&#32479;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#20301;&#32622;&#20449;&#24687;&#20256;&#36882;&#26041;&#24335;&#12290;</title><link>https://arxiv.org/abs/2403.02497</link><description>&lt;p&gt;
&#20307;&#20869;&#32435;&#31859;&#36890;&#20449;&#21307;&#30103;&#31995;&#32479;&#30340;&#30913;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Magnetic Localization for In-body Nano-communication Medical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#30913;&#22330;&#30340;&#20307;&#20869;&#32435;&#31859;&#26426;&#22120;&#23450;&#20301;&#26041;&#27861;&#65292;&#21033;&#29992;&#20154;&#20307;&#32452;&#32455;&#30340;&#30913;&#23548;&#29575;&#65292;&#20026;&#19979;&#19968;&#20195;&#21307;&#30103;&#35786;&#26029;&#31995;&#32479;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#20301;&#32622;&#20449;&#24687;&#20256;&#36882;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20307;&#20869;&#24490;&#29615;&#30340;&#32435;&#31859;&#26426;&#22120;&#25910;&#38598;&#20154;&#20307;&#32452;&#32455;&#29366;&#20917;&#25968;&#25454;&#65292;&#26159;&#19979;&#19968;&#20195;&#21307;&#30103;&#35786;&#26029;&#31995;&#32479;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#35753;&#36825;&#20123;&#35774;&#22791;&#26377;&#25928;&#36816;&#34892;&#65292;&#23427;&#20204;&#38656;&#35201;&#20256;&#36882;&#30340;&#19981;&#20165;&#20165;&#26159;&#21307;&#23398;&#27979;&#37327;&#25968;&#25454;&#65292;&#36824;&#26377;&#23427;&#20204;&#30340;&#20301;&#32622;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#30913;&#22330;&#30340;&#20307;&#20869;&#32435;&#31859;&#26426;&#22120;&#23450;&#20301;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;&#25152;&#26377;&#20154;&#20307;&#32452;&#32455;&#30340;&#26377;&#21033;&#30913;&#23548;&#29575;&#12290;&#20174;&#38598;&#25104;&#21040;&#32435;&#31859;&#26426;&#22120;&#30340;10x10 ${\mu}m^2$&#30913;&#24378;&#35745;&#65292;&#21040;&#19968;&#32452;&#29983;&#25104;&#30913;&#22330;&#30340;&#22806;&#37096;&#23548;&#32447;&#65292;&#25551;&#36848;&#20102;&#25972;&#20010;&#25552;&#20986;&#30340;&#23450;&#20301;&#31995;&#32479;&#12290;&#36824;&#25552;&#20379;&#20102;&#23450;&#20301;&#31639;&#27861;&#30340;&#25968;&#23398;&#26041;&#31243;&#65292;&#20551;&#35774;&#32435;&#31859;&#26426;&#22120;&#19981;&#25191;&#34892;&#35745;&#31639;&#65292;&#32780;&#26159;&#23558;&#20854;&#30913;&#22330;&#27979;&#37327;&#25968;&#25454;&#21644;&#21307;&#23398;&#25968;&#25454;&#20256;&#36755;&#21040;&#20307;&#22806;&#12290;&#25972;&#20010;&#31995;&#32479;&#36890;&#36807;&#35745;&#31639;&#26426;&#20223;&#30495;&#36827;&#34892;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02497v1 Announce Type: new  Abstract: Nano-machines circulating inside the human body, collecting data on tissue conditions, represent a vital part of next-generation medical diagnostic systems. However, for these devices to operate effectively, they need to relay not only their medical measurements but also their positions. This paper introduces a novel localization method for in-body nano-machines based on the magnetic field, leveraging the advantageous magnetic permeability of all human tissues. The entire proposed localization system is described, starting from 10x10 ${\mu}m^2$ magnetometers to be integrated into the nano-machines, to a set of external wires generating the magnetic field. Mathematical equations for the localization algorithm are also provided, assuming the nano-machines do not execute the computations themselves, but transmit their magnetic field measurements together with medical data outside of the body. The whole system is validated with computer simu
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;LLMs&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#20351;&#29992;ChatGPT-3.5&#12289;GoogleBard&#21644;GoogleGemini&#23545;&#21015;&#26631;&#39064;&#36827;&#34892;&#20027;&#39064;&#27880;&#37322;&#30340;&#20803;&#25968;&#25454;&#20016;&#23500;&#21270;&#65292;&#30740;&#31350;&#23427;&#20204;&#22312;&#23545;&#39046;&#22495;&#29305;&#23450;&#20027;&#39064;&#36827;&#34892;&#20998;&#31867;&#30340;&#33021;&#21147;&#65292;&#24182;&#35780;&#20272;&#20854;&#20869;&#37096;&#19968;&#33268;&#24615;&#12289;&#26426;&#22120;&#23545;&#40784;&#24615;&#21644;&#20154;&#26426;&#19968;&#33268;&#24615;&#12290;ChatGPT&#21644;GoogleGemini&#22312;&#20869;&#37096;&#19968;&#33268;&#24615;&#20197;&#21450;&#19982;&#20154;&#19968;&#33268;&#24615;&#26041;&#38754;&#20248;&#20110;GoogleBard&#12290;</title><link>https://arxiv.org/abs/2403.00884</link><description>&lt;p&gt;
&#21033;&#29992;LLMs&#36827;&#34892;&#20803;&#25968;&#25454;&#20016;&#23500;&#21270;&#30340;&#21463;&#25511;&#35789;&#27719;&#21015;&#26631;&#39064;&#25991;&#26412;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00884
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;LLMs&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#20351;&#29992;ChatGPT-3.5&#12289;GoogleBard&#21644;GoogleGemini&#23545;&#21015;&#26631;&#39064;&#36827;&#34892;&#20027;&#39064;&#27880;&#37322;&#30340;&#20803;&#25968;&#25454;&#20016;&#23500;&#21270;&#65292;&#30740;&#31350;&#23427;&#20204;&#22312;&#23545;&#39046;&#22495;&#29305;&#23450;&#20027;&#39064;&#36827;&#34892;&#20998;&#31867;&#30340;&#33021;&#21147;&#65292;&#24182;&#35780;&#20272;&#20854;&#20869;&#37096;&#19968;&#33268;&#24615;&#12289;&#26426;&#22120;&#23545;&#40784;&#24615;&#21644;&#20154;&#26426;&#19968;&#33268;&#24615;&#12290;ChatGPT&#21644;GoogleGemini&#22312;&#20869;&#37096;&#19968;&#33268;&#24615;&#20197;&#21450;&#19982;&#20154;&#19968;&#33268;&#24615;&#26041;&#38754;&#20248;&#20110;GoogleBard&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25968;&#25454;&#38598;&#26816;&#32034;&#31995;&#32479;&#20027;&#35201;&#22312;&#20803;&#25968;&#25454;&#20449;&#24687;&#32780;&#38750;&#25968;&#25454;&#20540;&#19978;&#24314;&#31435;&#32034;&#24341;&#12290;&#22240;&#27492;&#20027;&#35201;&#20381;&#36182;&#20110;&#25163;&#21160;&#27880;&#37322;&#21644;&#39640;&#36136;&#37327;&#30340;&#20803;&#25968;&#25454;&#65292;&#36825;&#20123;&#36807;&#31243;&#34987;&#35748;&#20026;&#26159;&#32791;&#26102;&#19988;&#38590;&#20197;&#33258;&#21160;&#21270;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21033;&#29992;&#19977;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25903;&#25345;&#23545;&#21015;&#26631;&#39064;&#36827;&#34892;&#20027;&#39064;&#27880;&#37322;&#30340;&#20803;&#25968;&#25454;&#20016;&#23500;&#21270;&#65306;ChatGPT-3.5&#12289;GoogleBard&#21644;GoogleGemini&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#22522;&#20110;&#21463;&#25511;&#35789;&#27719;&#30340;&#39046;&#22495;&#29305;&#23450;&#20027;&#39064;&#23545;&#21015;&#26631;&#39064;&#36827;&#34892;&#20998;&#31867;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#35780;&#20272;LLMs&#30340;&#20869;&#37096;&#19968;&#33268;&#24615;&#12289;&#26426;&#22120;&#38388;&#23545;&#40784;&#20197;&#21450;&#20154;&#26426;&#23545;&#20027;&#39064;&#20998;&#31867;&#20219;&#21153;&#30340;&#19968;&#33268;&#24615;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#19978;&#19979;&#25991;&#20449;&#24687;&#65288;&#21363;&#25968;&#25454;&#38598;&#25551;&#36848;&#65289;&#23545;&#20998;&#31867;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;ChatGPT&#21644;GoogleGemini&#22312;&#20869;&#37096;&#19968;&#33268;&#24615;&#20197;&#21450;LLM&#19982;&#20154;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;GoogleBard&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00884v1 Announce Type: cross  Abstract: Traditional dataset retrieval systems index on metadata information rather than on the data values. Thus relying primarily on manual annotations and high-quality metadata, processes known to be labour-intensive and challenging to automate. We propose a method to support metadata enrichment with topic annotations of column headers using three Large Language Models (LLMs): ChatGPT-3.5, GoogleBard and GoogleGemini. We investigate the LLMs ability to classify column headers based on domain-specific topics from a controlled vocabulary. We evaluate our approach by assessing the internal consistency of the LLMs, the inter-machine alignment, and the human-machine agreement for the topic classification task. Additionally, we investigate the impact of contextual information (i.e. dataset description) on the classification outcomes. Our results suggest that ChatGPT and GoogleGemini outperform GoogleBard for internal consistency as well as LLM-hum
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#24179;&#21488;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;Rec4Agentverse&#65292;&#24378;&#35843;&#20195;&#29702;&#39033;&#21644;&#20195;&#29702;&#25512;&#33616;&#22120;&#20043;&#38388;&#30340;&#21512;&#20316;&#65292;&#20419;&#36827;&#20010;&#24615;&#21270;&#20449;&#24687;&#26381;&#21153;&#65292;&#25552;&#21319;&#20449;&#24687;&#20132;&#25442;&#65292;&#24182;&#23637;&#26395;&#20102;&#20854;&#28436;&#36827;&#20026;&#25903;&#25345;&#20114;&#21160;&#21644;&#20449;&#24687;&#20132;&#25442;&#30340;&#19977;&#20010;&#38454;&#27573;</title><link>https://arxiv.org/abs/2402.18240</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20195;&#29702;&#24179;&#21488;&#19978;&#30340;&#21069;&#26223;&#20010;&#24615;&#21270;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Prospect Personalized Recommendation on Large Language Model-based Agent Platform
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18240
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#24179;&#21488;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;Rec4Agentverse&#65292;&#24378;&#35843;&#20195;&#29702;&#39033;&#21644;&#20195;&#29702;&#25512;&#33616;&#22120;&#20043;&#38388;&#30340;&#21512;&#20316;&#65292;&#20419;&#36827;&#20010;&#24615;&#21270;&#20449;&#24687;&#26381;&#21153;&#65292;&#25552;&#21319;&#20449;&#24687;&#20132;&#25442;&#65292;&#24182;&#23637;&#26395;&#20102;&#20854;&#28436;&#36827;&#20026;&#25903;&#25345;&#20114;&#21160;&#21644;&#20449;&#24687;&#20132;&#25442;&#30340;&#19977;&#20010;&#38454;&#27573;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#22411;&#20195;&#29702;&#23548;&#21521;&#20449;&#24687;&#31995;&#32479;&#65292;&#20197;GPT&#20026;&#20363;&#65292;&#20419;&#20351;&#25105;&#20204;&#23457;&#35270;&#20449;&#24687;&#31995;&#32479;&#22522;&#30784;&#35774;&#26045;&#65292;&#20197;&#25903;&#25345;&#20195;&#29702;&#32423;&#20449;&#24687;&#22788;&#29702;&#24182;&#36866;&#24212;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20195;&#29702;&#30340;&#29305;&#24449;&#65292;&#22914;&#20114;&#21160;&#24615;&#12290;&#26412;&#30740;&#31350;&#23637;&#26395;&#20102;&#22522;&#20110;LLM&#20195;&#29702;&#24179;&#21488;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#21069;&#26223;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;Rec4Agentverse&#30340;&#26032;&#22411;&#25512;&#33616;&#33539;&#24335;&#65292;&#21253;&#25324;&#20195;&#29702;&#39033;&#21644;&#20195;&#29702;&#25512;&#33616;&#22120;&#12290;Rec4Agentverse&#24378;&#35843;&#20195;&#29702;&#39033;&#21644;&#20195;&#29702;&#25512;&#33616;&#22120;&#20043;&#38388;&#30340;&#21512;&#20316;&#65292;&#20174;&#32780;&#20419;&#36827;&#20010;&#24615;&#21270;&#20449;&#24687;&#26381;&#21153;&#65292;&#24182;&#22686;&#24378;&#20449;&#24687;&#20132;&#25442;&#65292;&#36229;&#36234;&#20256;&#32479;&#30340;&#29992;&#25143;-&#25512;&#33616;&#22120;&#21453;&#39304;&#24490;&#29615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#26395;&#20102;Rec4Agentverse&#30340;&#28436;&#36827;&#65292;&#24182;&#23558;&#20854;&#27010;&#24565;&#21270;&#20026;&#22522;&#20110;&#20195;&#29702;&#39033;&#12289;&#20195;&#29702;&#25512;&#33616;&#22120;&#21644;&#29992;&#25143;&#20043;&#38388;&#20114;&#21160;&#21644;&#20449;&#24687;&#20132;&#25442;&#22686;&#24378;&#30340;&#19977;&#20010;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18240v1 Announce Type: cross  Abstract: The new kind of Agent-oriented information system, exemplified by GPTs, urges us to inspect the information system infrastructure to support Agent-level information processing and to adapt to the characteristics of Large Language Model (LLM)-based Agents, such as interactivity. In this work, we envisage the prospect of the recommender system on LLM-based Agent platforms and introduce a novel recommendation paradigm called Rec4Agentverse, comprised of Agent Items and Agent Recommender. Rec4Agentverse emphasizes the collaboration between Agent Items and Agent Recommender, thereby promoting personalized information services and enhancing the exchange of information beyond the traditional user-recommender feedback loop. Additionally, we prospect the evolution of Rec4Agentverse and conceptualize it into three stages based on the enhancement of the interaction and information exchange among Agent Items, Agent Recommender, and the user. A pre
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#26694;&#26550; BiVRec&#65292;&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#32852;&#21512;&#35757;&#32451; ID &#21644;&#22810;&#27169;&#24577;&#35270;&#22270;&#65292;&#21452;&#21521;&#22686;&#24378;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.17334</link><description>&lt;p&gt;
BiVRec: &#21452;&#21521;&#22522;&#20110;&#35270;&#22270;&#30340;&#22810;&#27169;&#24577;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
BiVRec: Bidirectional View-based Multimodal Sequential Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17334
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#26694;&#26550; BiVRec&#65292;&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#32852;&#21512;&#35757;&#32451; ID &#21644;&#22810;&#27169;&#24577;&#35270;&#22270;&#65292;&#21452;&#21521;&#22686;&#24378;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#20449;&#24687;&#34701;&#20837;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#36817;&#26469;&#24341;&#36215;&#20102;&#30740;&#31350;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#22312;&#22810;&#27169;&#24577;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#30340;&#21021;&#26399;&#38454;&#27573;&#65292;&#20027;&#27969;&#33539;&#24335;&#26159;ID&#20027;&#23548;&#25512;&#33616;&#65292;&#21363;&#22810;&#27169;&#24577;&#20449;&#24687;&#20316;&#20026;&#36741;&#21161;&#20449;&#24687;&#36827;&#34892;&#34701;&#21512;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#22312;&#21487;&#36716;&#31227;&#24615;&#21644;&#20449;&#24687;&#20405;&#20837;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#65292;&#21478;&#19968;&#31181;&#33539;&#24335;&#20986;&#29616;&#20102;&#65292;&#21363;&#30452;&#25509;&#21033;&#29992;&#22810;&#27169;&#24577;&#29305;&#24449;&#36827;&#34892;&#25512;&#33616;&#65292;&#23454;&#29616;&#36328;&#25968;&#25454;&#38598;&#30340;&#25512;&#33616;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#23427;&#24573;&#30053;&#20102;&#29992;&#25143;ID&#20449;&#24687;&#65292;&#23548;&#33268;&#20449;&#24687;&#21033;&#29992;&#29575;&#20302;&#21644;&#35757;&#32451;&#25104;&#26412;&#39640;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#26694;&#26550;&#65292;BiVRec&#65292;&#36890;&#36807;&#32852;&#21512;&#35757;&#32451;ID&#21644;&#22810;&#27169;&#24577;&#35270;&#22270;&#20013;&#30340;&#25512;&#33616;&#20219;&#21153;&#65292;&#21033;&#29992;&#23427;&#20204;&#20043;&#38388;&#30340;&#21327;&#21516;&#20851;&#31995;&#21452;&#21521;&#22686;&#24378;&#25512;&#33616;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#20449;&#24687;&#24322;&#26500;&#24615;&#38382;&#39064;&#65292;&#25105;&#20204;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17334v1 Announce Type: cross  Abstract: The integration of multimodal information into sequential recommender systems has attracted significant attention in recent research. In the initial stages of multimodal sequential recommendation models, the mainstream paradigm was ID-dominant recommendations, wherein multimodal information was fused as side information. However, due to their limitations in terms of transferability and information intrusion, another paradigm emerged, wherein multimodal features were employed directly for recommendation, enabling recommendation across datasets. Nonetheless, it overlooked user ID information, resulting in low information utilization and high training costs. To this end, we propose an innovative framework, BivRec, that jointly trains the recommendation tasks in both ID and multimodal views, leveraging their synergistic relationship to enhance recommendation performance bidirectionally. To tackle the information heterogeneity issue, we fir
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19987;&#21033;&#21709;&#24212;&#26234;&#33021;&#31995;&#32479;PARIS&#21644;LE-PARIS&#65292;&#36890;&#36807;&#26500;&#24314;OA&#20027;&#39064;&#25968;&#25454;&#24211;&#12289;&#24320;&#21457;&#21709;&#24212;&#27169;&#26495;&#20197;&#21450;&#23454;&#26045;&#25512;&#33616;&#31995;&#32479;&#21644;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#65292;&#26088;&#22312;&#21152;&#24555;&#19987;&#21033;&#24459;&#24072;&#22788;&#29702;&#23457;&#26597;&#24847;&#35265;&#22238;&#24212;&#30340;&#25928;&#29575;&#12290; &#36890;&#36807;&#22810;&#33539;&#24335;&#20998;&#26512;&#21644;&#38271;&#26399;&#25968;&#25454;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;OA&#20027;&#39064;&#30340;&#24314;&#35774;&#24615;&#21644;LLM&#23545;&#20110;&#22238;&#24212;&#33258;&#21160;&#29983;&#25104;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.00421</link><description>&lt;p&gt;
&#20174;PARIS&#21040;LE-PARIS&#65306;&#36890;&#36807;&#25512;&#33616;&#31995;&#32479;&#21644;&#21327;&#20316;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#19987;&#21033;&#21709;&#24212;&#33258;&#21160;&#21270;
&lt;/p&gt;
&lt;p&gt;
From PARIS to LE-PARIS: Toward Patent Response Automation with Recommender Systems and Collaborative Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19987;&#21033;&#21709;&#24212;&#26234;&#33021;&#31995;&#32479;PARIS&#21644;LE-PARIS&#65292;&#36890;&#36807;&#26500;&#24314;OA&#20027;&#39064;&#25968;&#25454;&#24211;&#12289;&#24320;&#21457;&#21709;&#24212;&#27169;&#26495;&#20197;&#21450;&#23454;&#26045;&#25512;&#33616;&#31995;&#32479;&#21644;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#65292;&#26088;&#22312;&#21152;&#24555;&#19987;&#21033;&#24459;&#24072;&#22788;&#29702;&#23457;&#26597;&#24847;&#35265;&#22238;&#24212;&#30340;&#25928;&#29575;&#12290; &#36890;&#36807;&#22810;&#33539;&#24335;&#20998;&#26512;&#21644;&#38271;&#26399;&#25968;&#25454;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;OA&#20027;&#39064;&#30340;&#24314;&#35774;&#24615;&#21644;LLM&#23545;&#20110;&#22238;&#24212;&#33258;&#21160;&#29983;&#25104;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19987;&#21033;&#23457;&#26597;&#20013;&#65292;&#23545;&#20110;&#21450;&#26102;&#21644;&#26377;&#25928;&#22320;&#22238;&#24212;&#23457;&#26597;&#24847;&#35265;&#65288;OAs&#65289;&#23545;&#20110;&#33719;&#24471;&#19987;&#21033;&#33267;&#20851;&#37325;&#35201;&#65292;&#28982;&#32780;&#36807;&#21435;&#30340;&#33258;&#21160;&#21270;&#21644;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#24456;&#23569;&#28041;&#21450;&#21040;&#36825;&#19968;&#26041;&#38754;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20171;&#32461;&#20102;&#19987;&#21033;&#23457;&#26597;&#24847;&#35265;&#21709;&#24212;&#26234;&#33021;&#31995;&#32479;&#65288;PARIS&#65289;&#21450;&#20854;&#20808;&#36827;&#29256;&#26412;LE-PARIS&#12290;&#36825;&#20123;&#31995;&#32479;&#26088;&#22312;&#21152;&#24555;&#19987;&#21033;&#24459;&#24072;&#22312;&#21327;&#20316;&#22788;&#29702;OA&#22238;&#24212;&#26041;&#38754;&#30340;&#25928;&#29575;&#12290;&#31995;&#32479;&#30340;&#20851;&#38190;&#29305;&#24449;&#21253;&#25324;&#26500;&#24314;OA&#20027;&#39064;&#25968;&#25454;&#24211;&#65292;&#24320;&#21457;&#21709;&#24212;&#27169;&#26495;&#65292;&#20197;&#21450;&#23454;&#26045;&#25512;&#33616;&#31995;&#32479;&#21644;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#12290;&#25105;&#20204;&#30340;&#39564;&#35777;&#28041;&#21450;&#20351;&#29992;USPTO Office Action&#25968;&#25454;&#24211;&#21644;&#24459;&#24072;&#19982;&#25105;&#20204;&#31995;&#32479;&#30340;&#38271;&#26399;&#20132;&#20114;&#25968;&#25454;&#36827;&#34892;&#30340;&#22810;&#33539;&#24335;&#20998;&#26512;&#65292;&#20026;&#26399;&#20845;&#24180;&#12290;&#36890;&#36807;&#20116;&#20010;&#30740;&#31350;&#65292;&#25105;&#20204;&#21033;&#29992;&#20027;&#39064;&#24314;&#27169;&#21644;&#25552;&#20986;&#30340;Delphi&#36807;&#31243;&#26469;&#26816;&#39564;OA&#20027;&#39064;&#30340;&#24314;&#35774;&#24615;&#65288;&#30740;&#31350;1&#21644;2&#65289;&#65292;&#36824;&#26377;&#20351;&#29992;&#25512;&#33616;&#31995;&#32479;&#21644;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#26469;&#25552;&#39640;&#22238;&#24212;&#36136;&#37327;&#65288;&#30740;&#31350;3&#21644;4&#65289;&#65292;&#20197;&#21450;&#32463;&#36807;&#35757;&#32451;&#30340;LLM&#23545;&#20110;&#22238;&#24212;&#33258;&#21160;&#29983;&#25104;&#30340;&#21487;&#34892;&#24615;&#65288;&#30740;&#31350;5&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In patent prosecution, timely and effective responses to Office Actions (OAs) are crucial for acquiring patents, yet past automation and AI research have scarcely addressed this aspect. To address this gap, our study introduces the Patent Office Action Response Intelligence System (PARIS) and its advanced version, the Large Language Model Enhanced PARIS (LE-PARIS). These systems are designed to expedite the efficiency of patent attorneys in collaboratively handling OA responses. The systems' key features include the construction of an OA Topics Database, development of Response Templates, and implementation of Recommender Systems and LLM-based Response Generation. Our validation involves a multi-paradigmatic analysis using the USPTO Office Action database and longitudinal data of attorney interactions with our systems over six years. Through five studies, we examine the constructiveness of OA topics (studies 1 and 2) using topic modeling and the proposed Delphi process, the efficacy of
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#36719;&#20214;&#31038;&#21306;&#38382;&#31572;&#20013;&#30340;&#38382;&#39064;&#37325;&#22797;&#26816;&#32034;&#21644;&#30830;&#35748;&#26102;&#38388;&#39044;&#27979;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#22823;&#22411;&#36719;&#20214;&#31995;&#32479;&#30340;CQA&#20013;&#65292;&#24110;&#21161;&#24537;&#30860;&#30340;&#19987;&#23478;&#31649;&#29702;&#21592;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#37325;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.05035</link><description>&lt;p&gt;
&#36719;&#20214;&#31038;&#21306;&#20013;&#30340;&#37325;&#22797;&#38382;&#39064;&#26816;&#32034;&#21644;&#30830;&#35748;&#26102;&#38388;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Duplicate Question Retrieval and Confirmation Time Prediction in Software Communities. (arXiv:2309.05035v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05035
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#36719;&#20214;&#31038;&#21306;&#38382;&#31572;&#20013;&#30340;&#38382;&#39064;&#37325;&#22797;&#26816;&#32034;&#21644;&#30830;&#35748;&#26102;&#38388;&#39044;&#27979;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#22823;&#22411;&#36719;&#20214;&#31995;&#32479;&#30340;CQA&#20013;&#65292;&#24110;&#21161;&#24537;&#30860;&#30340;&#19987;&#23478;&#31649;&#29702;&#21592;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#37325;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#23384;&#22312;&#22810;&#20010;&#24179;&#21488;&#21644;&#29992;&#25143;&#20043;&#38388;&#30340;&#22823;&#35268;&#27169;&#20849;&#20139;&#20449;&#24687;&#65292;&#19981;&#21516;&#39046;&#22495;&#30340;&#31038;&#21306;&#38382;&#31572;&#65288;CQA&#65289;&#27491;&#22312;&#24555;&#36895;&#22686;&#38271;&#12290;&#38543;&#30528;&#36825;&#20123;&#22312;&#32447;&#24179;&#21488;&#30340;&#24555;&#36895;&#22686;&#38271;&#65292;&#22823;&#37327;&#30340;&#23384;&#26723;&#25968;&#25454;&#20351;&#24471;&#31649;&#29702;&#21592;&#38590;&#20197;&#26816;&#32034;&#26032;&#38382;&#39064;&#30340;&#21487;&#33021;&#37325;&#22797;&#65292;&#24182;&#22312;&#36866;&#24403;&#30340;&#26102;&#38388;&#35782;&#21035;&#21644;&#30830;&#35748;&#29616;&#26377;&#38382;&#39064;&#23545;&#20316;&#20026;&#37325;&#22797;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#31867;&#20284;askubuntu&#36825;&#26679;&#30340;&#22823;&#22411;&#36719;&#20214;&#31995;&#32479;&#23545;&#24212;&#30340;CQA&#20013;&#23588;&#20026;&#37325;&#35201;&#65292;&#31649;&#29702;&#21592;&#38656;&#35201;&#26159;&#19987;&#23478;&#25165;&#33021;&#29702;&#35299;&#38382;&#39064;&#26159;&#21542;&#20026;&#37325;&#22797;&#12290;&#38656;&#35201;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#36825;&#26679;&#30340;CQA&#24179;&#21488;&#19978;&#65292;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#31649;&#29702;&#21592;&#26412;&#36523;&#23601;&#26159;&#19987;&#23478;&#65292;&#22240;&#27492;&#36890;&#24120;&#26102;&#38388;&#38750;&#24120;&#23453;&#36149;&#65292;&#38750;&#24120;&#24537;&#30860;&#12290;&#20026;&#20102;&#24110;&#21161;&#31649;&#29702;&#21592;&#23436;&#25104;&#20219;&#21153;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;askubuntu CQA&#24179;&#21488;&#19978;&#30340;&#20004;&#20010;&#37325;&#22823;&#38382;&#39064;&#65306;&#65288;1&#65289;&#32473;&#23450;&#19968;&#20010;&#26032;&#38382;&#39064;&#65292;&#26816;&#32034;&#37325;&#22797;&#38382;&#39064;&#65307;&#65288;2&#65289;&#37325;&#22797;&#38382;&#39064;&#30830;&#35748;&#30340;&#26102;&#38388;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community Question Answering (CQA) in different domains is growing at a large scale because of the availability of several platforms and huge shareable information among users. With the rapid growth of such online platforms, a massive amount of archived data makes it difficult for moderators to retrieve possible duplicates for a new question and identify and confirm existing question pairs as duplicates at the right time. This problem is even more critical in CQAs corresponding to large software systems like askubuntu where moderators need to be experts to comprehend something as a duplicate. Note that the prime challenge in such CQA platforms is that the moderators are themselves experts and are therefore usually extremely busy with their time being extraordinarily expensive. To facilitate the task of the moderators, in this work, we have tackled two significant issues for the askubuntu CQA platform: (1) retrieval of duplicate questions given a new question and (2) duplicate question 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#24555;&#25163;&#20013;&#30340;&#24037;&#19994;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#37096;&#32626;&#19968;&#20010;&#20851;&#27880;&#21453;&#39304;&#30340;&#32534;&#30721;&#27169;&#22359;&#21644;&#35774;&#35745;&#19968;&#20010;&#22810;&#30446;&#26631;&#39044;&#27979;&#27169;&#22359;&#65292;&#20174;&#22823;&#37327;&#30340;&#21453;&#39304;&#20013;&#25552;&#21462;&#29992;&#25143;&#20559;&#22909;&#24182;&#39044;&#27979;&#30456;&#20851;&#30340;&#30701;&#35270;&#39057;&#12290;</title><link>http://arxiv.org/abs/2308.13249</link><description>&lt;p&gt;
&#23398;&#20064;&#21644;&#20248;&#21270;&#24037;&#19994;&#30701;&#35270;&#39057;&#25512;&#33616;&#31995;&#32479;&#30340;&#38544;&#24335;&#36127;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Learning and Optimization of Implicit Negative Feedback for Industrial Short-video Recommender System. (arXiv:2308.13249v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#24555;&#25163;&#20013;&#30340;&#24037;&#19994;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#37096;&#32626;&#19968;&#20010;&#20851;&#27880;&#21453;&#39304;&#30340;&#32534;&#30721;&#27169;&#22359;&#21644;&#35774;&#35745;&#19968;&#20010;&#22810;&#30446;&#26631;&#39044;&#27979;&#27169;&#22359;&#65292;&#20174;&#22823;&#37327;&#30340;&#21453;&#39304;&#20013;&#25552;&#21462;&#29992;&#25143;&#20559;&#22909;&#24182;&#39044;&#27979;&#30456;&#20851;&#30340;&#30701;&#35270;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#35270;&#39057;&#25512;&#33616;&#26159;&#24403;&#20170;&#24037;&#19994;&#20449;&#24687;&#31995;&#32479;&#20013;&#26368;&#37325;&#35201;&#30340;&#25512;&#33616;&#24212;&#29992;&#20043;&#19968;&#12290;&#19982;&#20854;&#20182;&#25512;&#33616;&#20219;&#21153;&#30456;&#27604;&#65292;&#28023;&#37327;&#30340;&#21453;&#39304;&#26159;&#26368;&#20856;&#22411;&#30340;&#29305;&#28857;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22312;&#30701;&#35270;&#39057;&#25512;&#33616;&#20013;&#65292;&#26368;&#23481;&#26131;&#25910;&#38598;&#21040;&#30340;&#29992;&#25143;&#21453;&#39304;&#26159;&#36339;&#36807;&#34892;&#20026;&#65292;&#36825;&#23545;&#25512;&#33616;&#27169;&#22411;&#25552;&#20986;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#36339;&#36807;&#34892;&#20026;&#21453;&#26144;&#20102;&#38544;&#24335;&#30340;&#29992;&#25143;&#20559;&#22909;&#65292;&#22240;&#27492;&#23545;&#20110;&#20852;&#36259;&#25552;&#21462;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20854;&#27425;&#65292;&#36825;&#31181;&#29305;&#27530;&#30340;&#21453;&#39304;&#28041;&#21450;&#21040;&#22810;&#20010;&#30446;&#26631;&#65292;&#22914;&#24635;&#35266;&#30475;&#26102;&#38388;&#65292;&#36825;&#20063;&#26159;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#22312;&#24555;&#25163;&#20013;&#30340;&#24037;&#19994;&#35299;&#20915;&#26041;&#26696;&#65292;&#27599;&#22825;&#20026;&#21313;&#20159;&#32423;&#29992;&#25143;&#25552;&#20379;&#26381;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#37096;&#32626;&#20102;&#19968;&#20010;&#20851;&#27880;&#21453;&#39304;&#30340;&#32534;&#30721;&#27169;&#22359;&#65292;&#24456;&#22909;&#22320;&#25552;&#21462;&#29992;&#25143;&#20559;&#22909;&#24182;&#32771;&#34385;&#20102;&#19978;&#19979;&#25991;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#30446;&#26631;&#39044;&#27979;&#27169;&#22359;&#65292;&#33021;&#22815;&#24456;&#22909;&#22320;&#21306;&#20998;&#30456;&#20851;&#21644;&#19981;&#30456;&#20851;&#30340;&#35270;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;
Short-video recommendation is one of the most important recommendation applications in today's industrial information systems. Compared with other recommendation tasks, the enormous amount of feedback is the most typical characteristic. Specifically, in short-video recommendation, the easiest-to-collect user feedback is from the skipping behaviors, which leads to two critical challenges for the recommendation model. First, the skipping behavior reflects implicit user preferences, and thus it is challenging for interest extraction. Second, the kind of special feedback involves multiple objectives, such as total watching time, which is also very challenging. In this paper, we present our industrial solution in Kuaishou, which serves billion-level users every day. Specifically, we deploy a feedback-aware encoding module which well extracts user preference taking the impact of context into consideration. We further design a multi-objective prediction module which well distinguishes the rel
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#25552;&#20379;&#36866;&#29992;&#20110;&#21019;&#19994;&#20225;&#19994;&#21644;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2306.17256</link><description>&lt;p&gt;
&#20197;&#25552;&#31034;&#20026;&#22522;&#30784;&#30340;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#20010;&#24615;&#21270;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#25552;&#20379;&#36866;&#29992;&#20110;&#21019;&#19994;&#20225;&#19994;&#21644;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#26681;&#25454;&#29992;&#25143;&#36807;&#21435;&#30340;&#34892;&#20026;&#24110;&#21161;&#29992;&#25143;&#21457;&#29616;&#19982;&#20854;&#20852;&#36259;&#30456;&#31526;&#30340;&#20449;&#24687;&#26041;&#38754;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#24403;&#29992;&#25143;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#21382;&#21490;&#20132;&#20114;&#35760;&#24405;&#19981;&#21487;&#29992;&#26102;&#65292;&#24320;&#21457;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#36825;&#23601;&#26159;&#25152;&#35859;&#30340;&#31995;&#32479;&#20919;&#21551;&#21160;&#25512;&#33616;&#38382;&#39064;&#12290;&#27492;&#38382;&#39064;&#22312;&#21019;&#19994;&#20225;&#19994;&#25110;&#29992;&#25143;&#21442;&#19982;&#21382;&#21490;&#19981;&#36275;&#30340;&#24179;&#21488;&#20013;&#23588;&#20026;&#31361;&#20986;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#29992;&#25143;&#25110;&#29289;&#21697;&#30340;&#20919;&#21551;&#21160;&#22330;&#26223;&#65292;&#20854;&#20013;&#31995;&#32479;&#20173;&#28982;&#36890;&#36807;&#22312;&#21516;&#19968;&#39046;&#22495;&#20013;&#30340;&#21382;&#21490;&#29992;&#25143;&#21644;&#29289;&#21697;&#20132;&#20114;&#36827;&#34892;&#35757;&#32451;&#26469;&#20026;&#26032;&#29992;&#25143;&#25110;&#29289;&#21697;&#25552;&#20379;&#25512;&#33616;&#65292;&#32780;&#26080;&#27861;&#35299;&#20915;&#25105;&#20204;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#40511;&#27807;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#19988;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#23558;&#25512;&#33616;&#36807;&#31243;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#65292;&#20854;&#20013;&#21253;&#21547;&#29992;&#25143;&#36164;&#26009;&#21644;&#29289;&#21697;&#23646;&#24615;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems play a crucial role in helping users discover information that aligns with their interests based on their past behaviors. However, developing personalized recommendation systems becomes challenging when historical records of user-item interactions are unavailable, leading to what is known as the system cold-start recommendation problem. This issue is particularly prominent in start-up businesses or platforms with insufficient user engagement history. Previous studies focus on user or item cold-start scenarios, where systems could make recommendations for new users or items but are still trained with historical user-item interactions in the same domain, which cannot solve our problem. To bridge the gap, our research introduces an innovative and effective approach, capitalizing on the capabilities of pre-trained language models. We transform the recommendation process into sentiment analysis of natural languages containing information of user profiles and item attribu
&lt;/p&gt;</description></item><item><title>META-CODE&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#23398;&#20064;&#21644;&#26131;&#20110;&#25910;&#38598;&#30340;&#33410;&#28857;&#20803;&#25968;&#25454;&#65292;&#22312;&#26410;&#30693;&#25299;&#25169;&#32593;&#32476;&#20013;&#26816;&#27979;&#37325;&#21472;&#31038;&#21306;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;META-CODE&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.04497</link><description>&lt;p&gt;
&#26410;&#30693;&#25299;&#25169;&#32593;&#32476;&#20013;&#30340;&#25506;&#32034;&#23398;&#20064;&#36741;&#21161;&#31038;&#21306;&#26816;&#27979;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unified Framework for Exploratory Learning-Aided Community Detection in Networks with Unknown Topology. (arXiv:2304.04497v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04497
&lt;/p&gt;
&lt;p&gt;
META-CODE&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#23398;&#20064;&#21644;&#26131;&#20110;&#25910;&#38598;&#30340;&#33410;&#28857;&#20803;&#25968;&#25454;&#65292;&#22312;&#26410;&#30693;&#25299;&#25169;&#32593;&#32476;&#20013;&#26816;&#27979;&#37325;&#21472;&#31038;&#21306;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;META-CODE&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#65292;&#21457;&#29616;&#31038;&#21306;&#32467;&#26500;&#20316;&#20026;&#21508;&#31181;&#32593;&#32476;&#20998;&#26512;&#20219;&#21153;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38544;&#31169;&#38382;&#39064;&#25110;&#35775;&#38382;&#38480;&#21046;&#65292;&#32593;&#32476;&#32467;&#26500;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#65292;&#36825;&#20351;&#24471;&#29616;&#26377;&#30340;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#22312;&#27809;&#26377;&#26114;&#36149;&#30340;&#32593;&#32476;&#25299;&#25169;&#33719;&#21462;&#30340;&#24773;&#20917;&#19979;&#26080;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; META-CODE&#65292;&#36825;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#23398;&#20064;&#36741;&#21161;&#26131;&#20110;&#25910;&#38598;&#30340;&#33410;&#28857;&#20803;&#25968;&#25454;&#65292;&#22312;&#26410;&#30693;&#25299;&#25169;&#32593;&#32476;&#20013;&#26816;&#27979;&#37325;&#21472;&#31038;&#21306;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;META-CODE &#38500;&#20102;&#21021;&#22987;&#30340;&#32593;&#32476;&#25512;&#29702;&#27493;&#39588;&#22806;&#65292;&#36824;&#21253;&#25324;&#19977;&#20010;&#36845;&#20195;&#27493;&#39588;&#65306;1) &#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#33410;&#28857;&#32423;&#31038;&#21306;&#24402;&#23646;&#23884;&#20837;&#65292;&#36890;&#36807;&#25105;&#20204;&#30340;&#26032;&#37325;&#26500;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#65292;2) &#22522;&#20110;&#31038;&#21306;&#24402;&#23646;&#30340;&#33410;&#28857;&#26597;&#35810;&#36827;&#34892;&#32593;&#32476;&#25506;&#32034;&#65292;3) &#20351;&#29992;&#25506;&#32034;&#32593;&#32476;&#20013;&#30340;&#22522;&#20110;&#36793;&#36830;&#25509;&#30340;&#36830;&#20307;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#32593;&#32476;&#25512;&#29702;&#12290;&#36890;&#36807;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102; META-CODE &#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In social networks, the discovery of community structures has received considerable attention as a fundamental problem in various network analysis tasks. However, due to privacy concerns or access restrictions, the network structure is often unknown, thereby rendering established community detection approaches ineffective without costly network topology acquisition. To tackle this challenge, we present META-CODE, a unified framework for detecting overlapping communities in networks with unknown topology via exploratory learning aided by easy-to-collect node metadata. Specifically, META-CODE consists of three iterative steps in addition to the initial network inference step: 1) node-level community-affiliation embeddings based on graph neural networks (GNNs) trained by our new reconstruction loss, 2) network exploration via community-affiliation-based node queries, and 3) network inference using an edge connectivity-based Siamese neural network model from the explored network. Through e
&lt;/p&gt;</description></item></channel></rss>