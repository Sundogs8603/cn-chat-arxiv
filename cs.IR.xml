<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>DSPy&#26159;&#19968;&#20010;&#32534;&#31243;&#27169;&#22411;&#65292;&#23558;LM&#27969;&#27700;&#32447;&#25277;&#35937;&#20026;&#25991;&#26412;&#36716;&#25442;&#22270;&#65292;&#36890;&#36807;&#22768;&#26126;&#24615;&#27169;&#22359;&#35843;&#29992;LM&#23454;&#29616;&#20248;&#21270;&#65292;&#33021;&#22815;&#35299;&#20915;&#22797;&#26434;&#30340;&#25512;&#29702;&#38382;&#39064;&#21644;&#25968;&#23398;&#38382;&#39064;&#31561;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.03714</link><description>&lt;p&gt;
DSPy: &#23558;&#22768;&#26126;&#24615;&#35821;&#35328;&#27169;&#22411;&#35843;&#29992;&#32534;&#35793;&#25104;&#33258;&#25105;&#25913;&#36827;&#30340;&#27969;&#27700;&#32447;
&lt;/p&gt;
&lt;p&gt;
DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines. (arXiv:2310.03714v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03714
&lt;/p&gt;
&lt;p&gt;
DSPy&#26159;&#19968;&#20010;&#32534;&#31243;&#27169;&#22411;&#65292;&#23558;LM&#27969;&#27700;&#32447;&#25277;&#35937;&#20026;&#25991;&#26412;&#36716;&#25442;&#22270;&#65292;&#36890;&#36807;&#22768;&#26126;&#24615;&#27169;&#22359;&#35843;&#29992;LM&#23454;&#29616;&#20248;&#21270;&#65292;&#33021;&#22815;&#35299;&#20915;&#22797;&#26434;&#30340;&#25512;&#29702;&#38382;&#39064;&#21644;&#25968;&#23398;&#38382;&#39064;&#31561;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ML&#31038;&#21306;&#27491;&#22312;&#24555;&#36895;&#25506;&#32034;&#29992;&#20110;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;(LMs)&#21644;&#23558;&#23427;&#20204;&#22534;&#21472;&#25104;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#30340;&#27969;&#27700;&#32447;&#30340;&#25216;&#26415;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;LM&#27969;&#27700;&#32447;&#36890;&#24120;&#20351;&#29992;&#30828;&#32534;&#30721;&#30340;"&#25552;&#31034;&#27169;&#26495;"&#26469;&#23454;&#29616;&#65292;&#21363;&#36890;&#36807;&#35797;&#38169;&#21457;&#29616;&#30340;&#20887;&#38271;&#23383;&#31526;&#20018;&#12290;&#20026;&#20102;&#26356;&#31995;&#32479;&#22320;&#24320;&#21457;&#21644;&#20248;&#21270;LM&#27969;&#27700;&#32447;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DSPy&#65292;&#36825;&#26159;&#19968;&#20010;&#20197;&#25991;&#26412;&#36716;&#25442;&#22270;&#30340;&#24418;&#24335;&#25277;&#35937;LM&#27969;&#27700;&#32447;&#30340;&#32534;&#31243;&#27169;&#22411;&#65292;&#21363;&#36890;&#36807;&#22768;&#26126;&#24615;&#27169;&#22359;&#35843;&#29992;LM&#30340;&#21629;&#20196;&#24335;&#35745;&#31639;&#22270;&#12290;DSPy&#27169;&#22359;&#26159;&#21442;&#25968;&#21270;&#30340;&#65292;&#36825;&#24847;&#21619;&#30528;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#21019;&#24314;&#21644;&#25910;&#38598;&#31034;&#20363;&#26469;&#23398;&#20064;&#22914;&#20309;&#24212;&#29992;&#25552;&#31034;&#12289;&#24494;&#35843;&#12289;&#22686;&#24378;&#21644;&#25512;&#29702;&#25216;&#26415;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#32534;&#35793;&#22120;&#65292;&#21487;&#20197;&#20248;&#21270;&#20219;&#20309;DSPy&#27969;&#27700;&#32447;&#20197;&#26368;&#22823;&#21270;&#32473;&#23450;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#26174;&#31034;&#20986;&#31616;&#27905;&#30340;DSPy&#31243;&#24207;&#21487;&#20197;&#34920;&#36798;&#21644;&#20248;&#21270;&#22797;&#26434;&#30340;&#25512;&#29702;&#25968;&#23398;&#38382;&#39064;&#12289;&#30331;&#24405;&#26085;&#24535;&#38382;&#39064;&#31561;&#27969;&#27700;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ML community is rapidly exploring techniques for prompting language models (LMs) and for stacking them into pipelines that solve complex tasks. Unfortunately, existing LM pipelines are typically implemented using hard-coded "prompt templates", i.e. lengthy strings discovered via trial and error. Toward a more systematic approach for developing and optimizing LM pipelines, we introduce DSPy, a programming model that abstracts LM pipelines as text transformation graphs, i.e. imperative computational graphs where LMs are invoked through declarative modules. DSPy modules are parameterized, meaning they can learn (by creating and collecting demonstrations) how to apply compositions of prompting, finetuning, augmentation, and reasoning techniques. We design a compiler that will optimize any DSPy pipeline to maximize a given metric. We conduct two case studies, showing that succinct DSPy programs can express and optimize sophisticated LM pipelines that reason about math word problems, tac
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FASER&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20013;&#38388;&#34920;&#31034;&#36827;&#34892;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#25628;&#32034;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36328;&#26550;&#26500;&#22320;&#35782;&#21035;&#20989;&#25968;&#65292;&#24182;&#26126;&#30830;&#32534;&#30721;&#20989;&#25968;&#30340;&#35821;&#20041;&#65292;&#20197;&#25903;&#25345;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2310.03605</link><description>&lt;p&gt;
FASER: &#36890;&#36807;&#20013;&#38388;&#34920;&#31034;&#36827;&#34892;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
FASER: Binary Code Similarity Search through the use of Intermediate Representations. (arXiv:2310.03605v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FASER&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20013;&#38388;&#34920;&#31034;&#36827;&#34892;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#25628;&#32034;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36328;&#26550;&#26500;&#22320;&#35782;&#21035;&#20989;&#25968;&#65292;&#24182;&#26126;&#30830;&#32534;&#30721;&#20989;&#25968;&#30340;&#35821;&#20041;&#65292;&#20197;&#25903;&#25345;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#35782;&#21035;&#36328;&#26550;&#26500;&#36719;&#20214;&#20013;&#24863;&#20852;&#36259;&#30340;&#20989;&#25968;&#23545;&#20110;&#20998;&#26512;&#24694;&#24847;&#36719;&#20214;&#12289;&#20445;&#25252;&#36719;&#20214;&#20379;&#24212;&#38142;&#25110;&#36827;&#34892;&#28431;&#27934;&#30740;&#31350;&#37117;&#26159;&#26377;&#29992;&#30340;&#12290;&#36328;&#26550;&#26500;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#25628;&#32034;&#24050;&#22312;&#35768;&#22810;&#30740;&#31350;&#20013;&#25506;&#32034;&#65292;&#24182;&#20351;&#29992;&#20102;&#21508;&#31181;&#19981;&#21516;&#30340;&#25968;&#25454;&#26469;&#28304;&#26469;&#23454;&#29616;&#20854;&#30446;&#26631;&#12290;&#36890;&#24120;&#20351;&#29992;&#30340;&#25968;&#25454;&#26469;&#28304;&#21253;&#25324;&#20174;&#20108;&#36827;&#21046;&#25991;&#20214;&#20013;&#25552;&#21462;&#30340;&#24120;&#35265;&#32467;&#26500;&#65292;&#22914;&#20989;&#25968;&#25511;&#21046;&#27969;&#22270;&#25110;&#20108;&#36827;&#21046;&#32423;&#35843;&#29992;&#22270;&#65292;&#21453;&#27719;&#32534;&#36807;&#31243;&#30340;&#36755;&#20986;&#25110;&#21160;&#24577;&#20998;&#26512;&#26041;&#27861;&#30340;&#36755;&#20986;&#12290;&#20854;&#20013;&#19968;&#31181;&#21463;&#21040;&#36739;&#23569;&#20851;&#27880;&#30340;&#25968;&#25454;&#26469;&#28304;&#26159;&#20108;&#36827;&#21046;&#20013;&#38388;&#34920;&#31034;&#12290;&#20108;&#36827;&#21046;&#20013;&#38388;&#34920;&#31034;&#20855;&#26377;&#20004;&#20010;&#26377;&#36259;&#30340;&#23646;&#24615;&#65306;&#23427;&#20204;&#30340;&#36328;&#26550;&#26500;&#24615;&#36136;&#20197;&#21450;&#26126;&#30830;&#32534;&#30721;&#20989;&#25968;&#30340;&#35821;&#20041;&#20197;&#25903;&#25345;&#19979;&#28216;&#20351;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FASER&#30340;&#20989;&#25968;&#23383;&#31526;&#20018;&#32534;&#30721;&#34920;&#31034;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#38271;&#25991;&#26723;&#36716;&#25442;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Being able to identify functions of interest in cross-architecture software is useful whether you are analysing for malware, securing the software supply chain or conducting vulnerability research. Cross-Architecture Binary Code Similarity Search has been explored in numerous studies and has used a wide range of different data sources to achieve its goals. The data sources typically used draw on common structures derived from binaries such as function control flow graphs or binary level call graphs, the output of the disassembly process or the outputs of a dynamic analysis approach. One data source which has received less attention is binary intermediate representations. Binary Intermediate representations possess two interesting properties: they are cross architecture by their very nature and encode the semantics of a function explicitly to support downstream usage. Within this paper we propose Function as a String Encoded Representation (FASER) which combines long document transforme
&lt;/p&gt;</description></item><item><title>TPDR&#26159;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#20135;&#21697;&#21644;&#31867;&#25551;&#36848;&#21305;&#37197;&#19982;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#27880;&#24847;&#26426;&#21046;&#21644;&#23545;&#27604;&#23398;&#20064;&#26469;&#23454;&#29616;&#35821;&#20041;&#23545;&#24212;&#20851;&#31995;&#30340;&#25506;&#32034;&#12290;</title><link>http://arxiv.org/abs/2310.03491</link><description>&lt;p&gt;
TPDR&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#21452;&#27493;&#39588;Transformer&#30340;&#20135;&#21697;&#21644;&#31867;&#25551;&#36848;&#21305;&#37197;&#19982;&#26816;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
TPDR: A Novel Two-Step Transformer-based Product and Class Description Match and Retrieval Method. (arXiv:2310.03491v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03491
&lt;/p&gt;
&lt;p&gt;
TPDR&#26159;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#20135;&#21697;&#21644;&#31867;&#25551;&#36848;&#21305;&#37197;&#19982;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#27880;&#24847;&#26426;&#21046;&#21644;&#23545;&#27604;&#23398;&#20064;&#26469;&#23454;&#29616;&#35821;&#20041;&#23545;&#24212;&#20851;&#31995;&#30340;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#19968;&#31867;&#20844;&#21496;&#36127;&#36131;&#20026;&#20854;&#20182;&#20844;&#21496;&#20013;&#20171;&#37319;&#36141;&#22823;&#25209;&#37327;&#30340;&#21508;&#31181;&#20135;&#21697;&#65292;&#20854;&#20027;&#35201;&#25361;&#25112;&#26159;&#36827;&#34892;&#20135;&#21697;&#25551;&#36848;&#30340;&#26631;&#20934;&#21270;&#65292;&#21363;&#23558;&#23458;&#25143;&#25551;&#36848;&#30340;&#21830;&#21697;&#19982;&#30446;&#24405;&#20013;&#25551;&#36848;&#30340;&#20135;&#21697;&#36827;&#34892;&#21305;&#37197;&#12290;&#36825;&#20010;&#38382;&#39064;&#38750;&#24120;&#22797;&#26434;&#65292;&#22240;&#20026;&#23458;&#25143;&#30340;&#20135;&#21697;&#25551;&#36848;&#21487;&#33021;&#23384;&#22312;&#20197;&#19979;&#24773;&#20917;&#65306;&#65288;1&#65289;&#28508;&#22312;&#30340;&#22122;&#22768;&#65307;&#65288;2&#65289;&#30701;&#23567;&#19988;&#19981;&#20855;&#22791;&#20449;&#24687;&#65288;&#20363;&#22914;&#65292;&#32570;&#23569;&#26377;&#20851;&#22411;&#21495;&#21644;&#23610;&#23544;&#30340;&#20449;&#24687;&#65289;&#65307;&#65288;3&#65289;&#36328;&#35821;&#35328;&#12290;&#26412;&#25991;&#23558;&#36825;&#20010;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#25490;&#24207;&#20219;&#21153;&#65306;&#32473;&#23450;&#19968;&#20010;&#21021;&#22987;&#30340;&#23458;&#25143;&#20135;&#21697;&#35268;&#26684;&#65288;&#26597;&#35810;&#65289;&#65292;&#36820;&#22238;&#26368;&#21512;&#36866;&#30340;&#26631;&#20934;&#21270;&#25551;&#36848;&#65288;&#21709;&#24212;&#65289;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;TPDR&#65292;&#19968;&#31181;&#22522;&#20110;&#21452;&#27493;&#39588;Transformer&#30340;&#20135;&#21697;&#21644;&#31867;&#25551;&#36848;&#26816;&#32034;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#21033;&#29992;&#27880;&#24847;&#26426;&#21046;&#21644;&#23545;&#27604;&#23398;&#20064;&#26469;&#25506;&#32034;IS&#21644;SD&#20043;&#38388;&#30340;&#35821;&#20041;&#23545;&#24212;&#20851;&#31995;&#12290;&#39318;&#20808;&#65292;TPDR&#20351;&#29992;&#20004;&#20010;&#32534;&#30721;&#22120;&#30340;transformers&#20849;&#20139;&#23884;&#20837;&#21521;&#37327;&#31354;&#38388;&#65306;
&lt;/p&gt;
&lt;p&gt;
There is a niche of companies responsible for intermediating the purchase of large batches of varied products for other companies, for which the main challenge is to perform product description standardization, i.e., matching an item described by a client with a product described in a catalog. The problem is complex since the client's product description may be: (1) potentially noisy; (2) short and uninformative (e.g., missing information about model and size); and (3) cross-language. In this paper, we formalize this problem as a ranking task: given an initial client product specification (query), return the most appropriate standardized descriptions (response). In this paper, we propose TPDR, a two-step Transformer-based Product and Class Description Retrieval method that is able to explore the semantic correspondence between IS and SD, by exploiting attention mechanisms and contrastive learning. First, TPDR employs the transformers as two encoders sharing the embedding vector space: 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20010;&#24615;&#21270;Transformer&#30340;&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;&#65292;&#36890;&#36807;&#20248;&#21270;&#25490;&#21517;&#38454;&#27573;&#30340;&#29305;&#24449;&#29983;&#25104;&#65292;&#25552;&#39640;&#20102;&#25512;&#33616;&#36136;&#37327;&#12290;&#21516;&#26102;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#29992;&#20110;&#35299;&#20915;&#20559;&#32622;&#19978;&#19979;&#25991;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.03481</link><description>&lt;p&gt;
&#22522;&#20110;&#20010;&#24615;&#21270;Transformer&#30340;Yandex&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Personalized Transformer-based Ranking for e-Commerce at Yandex. (arXiv:2310.03481v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20010;&#24615;&#21270;Transformer&#30340;&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;&#65292;&#36890;&#36807;&#20248;&#21270;&#25490;&#21517;&#38454;&#27573;&#30340;&#29305;&#24449;&#29983;&#25104;&#65292;&#25552;&#39640;&#20102;&#25512;&#33616;&#36136;&#37327;&#12290;&#21516;&#26102;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#29992;&#20110;&#35299;&#20915;&#20559;&#32622;&#19978;&#19979;&#25991;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#29992;&#25143;&#27963;&#21160;&#20026;&#22522;&#30784;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#25512;&#33616;&#23545;&#20110;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#29992;&#25143;&#24847;&#22270;&#19981;&#26126;&#30830;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20027;&#39029;&#19978;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#23884;&#20837;&#24335;&#30340;&#20010;&#24615;&#21270;&#31995;&#32479;&#22312;&#30005;&#23376;&#21830;&#21153;&#39046;&#22495;&#30340;&#25512;&#33616;&#21644;&#25628;&#32034;&#32467;&#26524;&#36136;&#37327;&#26041;&#38754;&#26377;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24037;&#20316;&#22823;&#22810;&#38598;&#20013;&#22312;&#22686;&#24378;&#26816;&#32034;&#38454;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38024;&#23545;&#30005;&#23376;&#21830;&#21153;&#25512;&#33616;&#20013;&#30340;&#25490;&#21517;&#38454;&#27573;&#65292;&#26816;&#32034;&#32858;&#28966;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20135;&#29983;&#30340;&#29305;&#24449;&#26159;&#27425;&#20248;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#35757;&#32451;&#36807;&#31243;&#65292;&#36890;&#36807;&#24494;&#35843;&#20004;&#22612;&#27169;&#22411;&#26469;&#23454;&#29616;&#26368;&#20339;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;&#25105;&#20204;&#35814;&#32454;&#25551;&#36848;&#20102;&#25105;&#20204;&#19987;&#38376;&#20026;&#30005;&#23376;&#21830;&#21153;&#20010;&#24615;&#21270;&#35774;&#35745;&#30340;&#22522;&#20110;Transformer&#30340;&#20004;&#22612;&#27169;&#22411;&#26550;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#32447;&#27169;&#22411;&#20013;&#21435;&#20559;&#32622;&#19978;&#19979;&#25991;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalizing the user experience with high-quality recommendations based on user activities is vital for e-commerce platforms. This is particularly important in scenarios where the user's intent is not explicit, such as on the homepage. Recently, personalized embedding-based systems have significantly improved the quality of recommendations and search results in the e-commerce domain. However, most of these works focus on enhancing the retrieval stage.  In this paper, we demonstrate that features produced by retrieval-focused deep learning models are sub-optimal for ranking stage in e-commerce recommendations. To address this issue, we propose a two-stage training process that fine-tunes two-tower models to achieve optimal ranking performance. We provide a detailed description of our transformer-based two-tower model architecture, which is specifically designed for personalization in e-commerce.  Additionally, we introduce a novel technique for debiasing context in offline models and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#20122;&#39532;&#36874;&#30340;&#25968;&#25454;&#38598;&#26500;&#24314;&#20102;&#19968;&#20010;&#39044;&#27979;&#22270;&#20070;&#35780;&#20998;&#21644;&#25512;&#33616;&#22270;&#20070;&#30340;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#22788;&#29702;&#22823;&#25968;&#25454;&#25991;&#20214;&#12289;&#25968;&#25454;&#24037;&#31243;&#21644;&#26500;&#24314;&#27169;&#22411;&#30340;&#27969;&#31243;&#65292;&#24182;&#20351;&#29992;&#20102;&#21508;&#31181;PySpark&#26426;&#22120;&#23398;&#20064;API&#12289;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#20132;&#21449;&#39564;&#35777;&#36827;&#34892;&#20934;&#30830;&#24615;&#30340;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.03200</link><description>&lt;p&gt;
&#20122;&#39532;&#36874;&#22270;&#20070;&#35780;&#20998;&#39044;&#27979;&#19982;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Amazon Books Rating prediction &amp; Recommendation Model. (arXiv:2310.03200v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#20122;&#39532;&#36874;&#30340;&#25968;&#25454;&#38598;&#26500;&#24314;&#20102;&#19968;&#20010;&#39044;&#27979;&#22270;&#20070;&#35780;&#20998;&#21644;&#25512;&#33616;&#22270;&#20070;&#30340;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#22788;&#29702;&#22823;&#25968;&#25454;&#25991;&#20214;&#12289;&#25968;&#25454;&#24037;&#31243;&#21644;&#26500;&#24314;&#27169;&#22411;&#30340;&#27969;&#31243;&#65292;&#24182;&#20351;&#29992;&#20102;&#21508;&#31181;PySpark&#26426;&#22120;&#23398;&#20064;API&#12289;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#20132;&#21449;&#39564;&#35777;&#36827;&#34892;&#20934;&#30830;&#24615;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#20122;&#39532;&#36874;&#30340;&#25968;&#25454;&#38598;&#26469;&#39044;&#27979;&#20122;&#39532;&#36874;&#32593;&#31449;&#19978;&#21015;&#20986;&#30340;&#22270;&#20070;&#35780;&#20998;&#12290;&#20316;&#20026;&#36825;&#20010;&#39033;&#30446;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#39044;&#27979;&#20102;&#22270;&#20070;&#30340;&#35780;&#20998;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#25512;&#33616;&#38598;&#32676;&#12290;&#36825;&#20010;&#25512;&#33616;&#38598;&#32676;&#22522;&#20110;&#25968;&#25454;&#38598;&#20013;&#30340;&#21015;&#20540;&#65292;&#27604;&#22914;&#31867;&#21035;&#12289;&#25551;&#36848;&#12289;&#20316;&#32773;&#12289;&#20215;&#26684;&#12289;&#35780;&#35770;&#31561;&#25552;&#20379;&#25512;&#33616;&#22270;&#20070;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#22788;&#29702;&#22823;&#25968;&#25454;&#25991;&#20214;&#12289;&#25968;&#25454;&#24037;&#31243;&#12289;&#26500;&#24314;&#27169;&#22411;&#21644;&#25552;&#20379;&#39044;&#27979;&#30340;&#27969;&#31243;&#12290;&#27169;&#22411;&#20351;&#29992;&#20102;&#21508;&#31181;PySpark&#26426;&#22120;&#23398;&#20064;API&#26469;&#39044;&#27979;&#22270;&#20070;&#35780;&#20998;&#21015;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#36229;&#21442;&#25968;&#21644;&#21442;&#25968;&#35843;&#20248;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;&#20132;&#21449;&#39564;&#35777;&#21644;TrainValidationSplit&#36827;&#34892;&#27867;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20108;&#20998;&#31867;&#21644;&#22810;&#20998;&#31867;&#22312;&#20934;&#30830;&#24615;&#19978;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#23558;&#26631;&#31614;&#20174;&#22810;&#20998;&#31867;&#36716;&#25442;&#20026;&#20108;&#20998;&#31867;&#20197;&#26597;&#30475;&#20004;&#31181;&#20998;&#31867;&#20043;&#38388;&#26159;&#21542;&#26377;&#24046;&#24322;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#22312;&#20108;&#20998;&#31867;&#20013;&#33719;&#24471;&#20102;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper uses the dataset of Amazon to predict the books ratings listed on Amazon website. As part of this project, we predicted the ratings of the books, and also built a recommendation cluster. This recommendation cluster provides the recommended books based on the column's values from dataset, for instance, category, description, author, price, reviews etc. This paper provides a flow of handling big data files, data engineering, building models and providing predictions. The models predict book ratings column using various PySpark Machine Learning APIs. Additionally, we used hyper-parameters and parameters tuning. Also, Cross Validation and TrainValidationSplit were used for generalization. Finally, we performed a comparison between Binary Classification and Multiclass Classification in their accuracies. We converted our label from multiclass to binary to see if we could find any difference between the two classifications. As a result, we found out that we get higher accuracy in b
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;&#23433;&#20840;&#28431;&#27934;&#8212;&#8212;&#38459;&#25239;&#27844;&#28431;&#65292;&#36890;&#36807;&#21033;&#29992;&#35813;&#28431;&#27934;&#21487;&#20197;&#20174;&#23884;&#20837;&#24335;&#35774;&#22791;&#20013;&#25552;&#21462;&#21463;&#20445;&#25252;&#20869;&#23384;&#20013;&#30340;&#36719;&#20214;&#25351;&#20196;&#12290;</title><link>http://arxiv.org/abs/2310.03175</link><description>&lt;p&gt;
&#38459;&#25239;&#27844;&#28431;&#33030;&#24369;&#24615;&#21450;&#20854;&#22312;&#36870;&#21521;&#24037;&#31243;&#23884;&#20837;&#24335;&#36719;&#20214;&#20013;&#30340;&#21033;&#29992;
&lt;/p&gt;
&lt;p&gt;
Impedance Leakage Vulnerability and its Utilization in Reverse-engineering Embedded Software. (arXiv:2310.03175v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03175
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;&#23433;&#20840;&#28431;&#27934;&#8212;&#8212;&#38459;&#25239;&#27844;&#28431;&#65292;&#36890;&#36807;&#21033;&#29992;&#35813;&#28431;&#27934;&#21487;&#20197;&#20174;&#23884;&#20837;&#24335;&#35774;&#22791;&#20013;&#25552;&#21462;&#21463;&#20445;&#25252;&#20869;&#23384;&#20013;&#30340;&#36719;&#20214;&#25351;&#20196;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21457;&#29616;&#26032;&#30340;&#28431;&#27934;&#21644;&#23454;&#26045;&#23433;&#20840;&#21644;&#38544;&#31169;&#25514;&#26045;&#23545;&#20110;&#20445;&#25252;&#31995;&#32479;&#21644;&#25968;&#25454;&#20813;&#21463;&#29289;&#29702;&#25915;&#20987;&#33267;&#20851;&#37325;&#35201;&#12290;&#20854;&#20013;&#19968;&#31181;&#28431;&#27934;&#26159;&#38459;&#25239;&#65292;&#19968;&#31181;&#35774;&#22791;&#30340;&#22266;&#26377;&#23646;&#24615;&#65292;&#21487;&#20197;&#36890;&#36807;&#24847;&#22806;&#30340;&#20391;&#20449;&#36947;&#27844;&#38706;&#20449;&#24687;&#65292;&#20174;&#32780;&#24102;&#26469;&#20005;&#37325;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#39118;&#38505;&#12290;&#19982;&#20256;&#32479;&#30340;&#28431;&#27934;&#19981;&#21516;&#65292;&#38459;&#25239;&#36890;&#24120;&#34987;&#24573;&#35270;&#25110;&#20165;&#22312;&#30740;&#31350;&#21644;&#35774;&#35745;&#20013;&#20197;&#29305;&#23450;&#39057;&#29575;&#30340;&#22266;&#23450;&#20540;&#26469;&#22788;&#29702;&#12290;&#27492;&#22806;&#65292;&#38459;&#25239;&#20174;&#26410;&#34987;&#25506;&#32034;&#36807;&#20316;&#20026;&#20449;&#24687;&#27844;&#28431;&#30340;&#28304;&#22836;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#23884;&#20837;&#24335;&#35774;&#22791;&#30340;&#38459;&#25239;&#24182;&#38750;&#24658;&#23450;&#65292;&#24182;&#30452;&#25509;&#19982;&#35774;&#22791;&#19978;&#25191;&#34892;&#30340;&#31243;&#24207;&#30456;&#20851;&#12290;&#25105;&#20204;&#23558;&#27492;&#29616;&#35937;&#23450;&#20041;&#20026;&#38459;&#25239;&#27844;&#28431;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#19968;&#31181;&#20391;&#20449;&#36947;&#20174;&#21463;&#20445;&#25252;&#30340;&#20869;&#23384;&#20013;&#25552;&#21462;&#36719;&#20214;&#25351;&#20196;&#12290;&#25105;&#20204;&#22312;ATmega328P&#24494;&#25511;&#21046;&#22120;&#21644;Artix 7 FPGA&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#38459;&#25239;&#20391;&#20449;&#36947;
&lt;/p&gt;
&lt;p&gt;
Discovering new vulnerabilities and implementing security and privacy measures are important to protect systems and data against physical attacks. One such vulnerability is impedance, an inherent property of a device that can be exploited to leak information through an unintended side channel, thereby posing significant security and privacy risks. Unlike traditional vulnerabilities, impedance is often overlooked or narrowly explored, as it is typically treated as a fixed value at a specific frequency in research and design endeavors. Moreover, impedance has never been explored as a source of information leakage. This paper demonstrates that the impedance of an embedded device is not constant and directly relates to the programs executed on the device. We define this phenomenon as impedance leakage and use this as a side channel to extract software instructions from protected memory. Our experiment on the ATmega328P microcontroller and the Artix 7 FPGA indicates that the impedance side 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#25216;&#26415;&#21644;&#33258;&#36866;&#24212;&#19978;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20943;&#23569;&#22810;&#39046;&#22495;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#24230;&#20559;&#24046;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#30456;&#23545;&#22686;&#30410;&#39640;&#36798;65.27%&#12290;</title><link>http://arxiv.org/abs/2310.03148</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#29992;&#20110;&#20943;&#23569;&#22810;&#39046;&#22495;&#35270;&#39057;&#25512;&#33616;&#20013;&#30340;&#27969;&#34892;&#24230;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Multi-Task Learning For Reduced Popularity Bias In Multi-Territory Video Recommendations. (arXiv:2310.03148v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03148
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#25216;&#26415;&#21644;&#33258;&#36866;&#24212;&#19978;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20943;&#23569;&#22810;&#39046;&#22495;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#24230;&#20559;&#24046;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#30456;&#23545;&#22686;&#30410;&#39640;&#36798;65.27%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#39046;&#22495;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#33258;&#28982;&#20135;&#29983;&#30340;&#21508;&#31181;&#25968;&#25454;&#19981;&#24179;&#34913;&#21487;&#33021;&#23548;&#33268;&#20840;&#29699;&#27969;&#34892;&#29289;&#21697;&#30340;&#26174;&#33879;&#39033;&#30446;&#20559;&#35265;&#12290;&#23616;&#37096;&#27969;&#34892;&#39033;&#30446;&#21487;&#33021;&#20250;&#34987;&#20840;&#29699;&#27969;&#34892;&#39033;&#30446;&#25152;&#25513;&#30422;&#12290;&#27492;&#22806;&#65292;&#29992;&#25143;&#30340;&#35266;&#30475;&#27169;&#24335;/&#32479;&#35745;&#25968;&#25454;&#22312;&#19981;&#21516;&#22320;&#29702;&#20301;&#32622;&#20043;&#38388;&#21487;&#33021;&#21457;&#29983;&#21095;&#21464;&#65292;&#36825;&#21487;&#33021;&#34920;&#26126;&#38656;&#35201;&#23398;&#20064;&#29305;&#23450;&#30340;&#29992;&#25143;&#23884;&#20837;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#25216;&#26415;&#65292;&#20197;&#21450;&#19968;&#31181;&#33258;&#36866;&#24212;&#19978;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20943;&#23569;&#22810;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#27969;&#34892;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#19978;&#37319;&#26679;&#26469;&#20016;&#23500;&#21547;&#26377;&#27963;&#36291;&#29992;&#25143;&#34920;&#31034;&#30340;&#35757;&#32451;&#26679;&#26412;&#65292;&#24182;&#20511;&#21161;MTL&#26469;&#23398;&#20064;&#22522;&#20110;&#22320;&#29702;&#20301;&#32622;&#30340;&#29992;&#25143;&#23884;&#20837;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#19981;&#37319;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;&#25216;&#26415;&#30340;&#22522;&#20934;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#22810;&#20010;&#39046;&#22495;&#30340;&#25928;&#26524;&#26174;&#33879;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;PR-AUC&#25351;&#26631;&#19978;&#26174;&#31034;&#20986;&#20102;&#39640;&#36798;65.27%&#30340;&#30456;&#23545;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Various data imbalances that naturally arise in a multi-territory personalized recommender system can lead to a significant item bias for globally prevalent items. A locally popular item can be overshadowed by a globally prevalent item. Moreover, users' viewership patterns/statistics can drastically change from one geographic location to another which may suggest to learn specific user embeddings. In this paper, we propose a multi-task learning (MTL) technique, along with an adaptive upsampling method to reduce popularity bias in multi-territory recommendations. Our proposed framework is designed to enrich training examples with active users representation through upsampling, and capable of learning geographic-based user embeddings by leveraging MTL. Through experiments, we demonstrate the effectiveness of our framework in multiple territories compared to a baseline not incorporating our proposed techniques.~Noticeably, we show improved relative gain of up to $65.27\%$ in PR-AUC metric
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#25512;&#25991;&#21442;&#19982;&#24230;&#39044;&#27979;&#38382;&#39064;&#65292;&#20351;&#29992;&#20102;Twitter&#30340;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#27969;&#31243;&#65292;&#25506;&#35752;&#20102;&#20165;&#20973;&#19978;&#19979;&#25991;&#26159;&#21542;&#21487;&#20197;&#24456;&#22909;&#22320;&#39044;&#27979;&#25512;&#25991;&#30340;&#21442;&#19982;&#24230;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03147</link><description>&lt;p&gt;
&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#25512;&#25991;&#21442;&#19982;&#24230;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Context-Based Tweet Engagement Prediction. (arXiv:2310.03147v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03147
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#25512;&#25991;&#21442;&#19982;&#24230;&#39044;&#27979;&#38382;&#39064;&#65292;&#20351;&#29992;&#20102;Twitter&#30340;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#27969;&#31243;&#65292;&#25506;&#35752;&#20102;&#20165;&#20973;&#19978;&#19979;&#25991;&#26159;&#21542;&#21487;&#20197;&#24456;&#22909;&#22320;&#39044;&#27979;&#25512;&#25991;&#30340;&#21442;&#19982;&#24230;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Twitter&#30446;&#21069;&#26159;&#26368;&#22823;&#30340;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#20043;&#19968;&#12290;&#20854;&#29992;&#25143;&#21487;&#20197;&#20998;&#20139;&#12289;&#38405;&#35835;&#21644;&#21442;&#19982;&#30701;&#25512;&#25991;&#12290;&#22312;2020&#24180;ACM&#25512;&#33616;&#31995;&#32479;&#20250;&#35758;&#19978;&#65292;Twitter&#21457;&#24067;&#20102;&#19968;&#20010;&#22823;&#23567;&#32422;&#20026;70GB&#30340;&#25968;&#25454;&#38598;&#65292;&#20379;&#24180;&#24230;RecSys&#25361;&#25112;&#36187;&#20351;&#29992;&#12290;2020&#24180;&#30340;RecSys&#25361;&#25112;&#36187;&#36992;&#35831;&#21442;&#19982;&#22242;&#38431;&#21019;&#24314;&#27169;&#22411;&#65292;&#39044;&#27979;&#32473;&#23450;&#29992;&#25143;-&#25512;&#25991;&#32452;&#21512;&#30340;&#21442;&#19982;&#24230;&#21487;&#33021;&#24615;&#12290;&#25552;&#20132;&#30340;&#27169;&#22411;&#39044;&#27979;&#28857;&#36190;&#12289;&#22238;&#22797;&#12289;&#36716;&#21457;&#21644;&#24341;&#29992;&#30340;&#21442;&#19982;&#24230;&#65292;&#24182;&#22522;&#20110;&#20004;&#20010;&#25351;&#26631;&#36827;&#34892;&#35780;&#20272;&#65306;&#31934;&#30830;&#29575;-&#21484;&#22238;&#29575;&#26354;&#32447;&#19979;&#30340;&#38754;&#31215;&#65288;PRAUC&#65289;&#21644;&#30456;&#23545;&#20132;&#21449;&#29109;&#65288;RCE&#65289;&#12290;&#22312;&#36825;&#31687;&#23398;&#20301;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;RecSys 2020&#25361;&#25112;&#36187;&#30340;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#27969;&#31243;&#65292;&#30740;&#31350;&#20165;&#20973;&#19978;&#19979;&#25991;&#33021;&#21542;&#39044;&#27979;&#25512;&#25991;&#21442;&#19982;&#24230;&#30340;&#21487;&#34892;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;TU Wien&#30340;Little Big Data Cluster&#19978;&#37319;&#29992;Spark&#24341;&#25806;&#21019;&#24314;&#21487;&#25193;&#23637;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#29305;&#24449;&#24037;&#31243;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#12290;&#25105;&#20204;&#25163;&#21160;&#21019;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;
Twitter is currently one of the biggest social media platforms. Its users may share, read, and engage with short posts called tweets. For the ACM Recommender Systems Conference 2020, Twitter published a dataset around 70 GB in size for the annual RecSys Challenge. In 2020, the RecSys Challenge invited participating teams to create models that would predict engagement likelihoods for given user-tweet combinations. The submitted models predicting like, reply, retweet, and quote engagements were evaluated based on two metrics: area under the precision-recall curve (PRAUC) and relative cross-entropy (RCE).  In this diploma thesis, we used the RecSys 2020 Challenge dataset and evaluation procedure to investigate how well context alone may be used to predict tweet engagement likelihood. In doing so, we employed the Spark engine on TU Wien's Little Big Data Cluster to create scalable data preprocessing, feature engineering, feature selection, and machine learning pipelines. We manually create
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20132;&#20114;&#24335;&#25628;&#32034;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#25972;&#21512;&#21477;&#32423;&#21453;&#39304;&#20449;&#24687;&#26469;&#25552;&#39640;&#25628;&#32034;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#36866;&#24212;&#26368;&#26032;&#30340;BERT-based&#27169;&#22411;&#36827;&#34892;&#20851;&#38190;&#21477;&#23376;&#36873;&#25321;&#21644;&#39033;&#30446;&#25490;&#24207;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#28385;&#24847;&#30340;&#25628;&#32034;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.03043</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20132;&#20114;&#24335;&#25628;&#32034;&#26041;&#27861;&#19982;&#21477;&#32423;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
A Deep Reinforcement Learning Approach for Interactive Search with Sentence-level Feedback. (arXiv:2310.03043v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20132;&#20114;&#24335;&#25628;&#32034;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#25972;&#21512;&#21477;&#32423;&#21453;&#39304;&#20449;&#24687;&#26469;&#25552;&#39640;&#25628;&#32034;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#36866;&#24212;&#26368;&#26032;&#30340;BERT-based&#27169;&#22411;&#36827;&#34892;&#20851;&#38190;&#21477;&#23376;&#36873;&#25321;&#21644;&#39033;&#30446;&#25490;&#24207;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#28385;&#24847;&#30340;&#25628;&#32034;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#20114;&#24335;&#25628;&#32034;&#21487;&#20197;&#36890;&#36807;&#25972;&#21512;&#29992;&#25143;&#30340;&#20132;&#20114;&#21453;&#39304;&#26469;&#25552;&#20379;&#26356;&#22909;&#30340;&#25628;&#32034;&#20307;&#39564;&#12290;&#36825;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#25628;&#32034;&#20934;&#30830;&#24615;&#65292;&#22240;&#20026;&#23427;&#26377;&#21161;&#20110;&#36991;&#20813;&#26080;&#20851;&#20449;&#24687;&#24182;&#25429;&#25417;&#29992;&#25143;&#30340;&#25628;&#32034;&#24847;&#22270;&#12290;&#29616;&#26377;&#30340;&#26368;&#26032;&#31995;&#32479;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#27169;&#22411;&#26469;&#25972;&#21512;&#36825;&#20123;&#20132;&#20114;&#65292;&#20294;&#26159;&#24573;&#30053;&#20102;&#21477;&#32423;&#21453;&#39304;&#20013;&#30340;&#32454;&#31890;&#24230;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#21453;&#39304;&#38656;&#35201;&#36827;&#34892;&#24191;&#27867;&#30340;RL&#34892;&#21160;&#31354;&#38388;&#25506;&#32034;&#21644;&#22823;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;Q&#23398;&#20064;&#65288;DQ&#65289;&#26041;&#27861;DQrank&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;DQrank&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#26368;&#26032;&#25216;&#26415;BERT-based&#27169;&#22411;&#26469;&#36873;&#25321;&#20851;&#38190;&#21477;&#23376;&#65292;&#24182;&#22522;&#20110;&#29992;&#25143;&#30340;&#21442;&#19982;&#24230;&#23545;&#39033;&#30446;&#36827;&#34892;&#25490;&#24207;&#65292;&#20197;&#33719;&#24471;&#26356;&#28385;&#24847;&#30340;&#22238;&#24212;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26426;&#21046;&#26469;&#26356;&#22909;&#22320;&#25506;&#32034;&#26368;&#20248;&#34892;&#21160;&#12290;DQrank&#36824;&#21033;&#29992;DQ&#20013;&#30340;&#32463;&#39564;&#37325;&#29616;&#26426;&#21046;&#26469;&#23384;&#20648;&#21453;&#39304;&#21477;&#23376;&#20197;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interactive search can provide a better experience by incorporating interaction feedback from the users. This can significantly improve search accuracy as it helps avoid irrelevant information and captures the users' search intents. Existing state-of-the-art (SOTA) systems use reinforcement learning (RL) models to incorporate the interactions but focus on item-level feedback, ignoring the fine-grained information found in sentence-level feedback. Yet such feedback requires extensive RL action space exploration and large amounts of annotated data. This work addresses these challenges by proposing a new deep Q-learning (DQ) approach, DQrank. DQrank adapts BERT-based models, the SOTA in natural language processing, to select crucial sentences based on users' engagement and rank the items to obtain more satisfactory responses. We also propose two mechanisms to better explore optimal actions. DQrank further utilizes the experience replay mechanism in DQ to store the feedback sentences to ob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32467;&#26500;&#24863;&#30693;&#23884;&#20837;&#28436;&#21270;(SEvo)&#26426;&#21046;&#65292;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#24320;&#38144;&#23558;&#22270;&#32467;&#26500;&#20449;&#24687;&#27880;&#20837;&#21040;&#23884;&#20837;&#20013;&#65292;&#20174;&#32780;&#22312;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.03032</link><description>&lt;p&gt;
&#22270;&#22686;&#24378;&#20248;&#21270;&#22120;&#29992;&#20110;&#32467;&#26500;&#24863;&#30693;&#25512;&#33616;&#23884;&#20837;&#28436;&#21270;
&lt;/p&gt;
&lt;p&gt;
Graph-enhanced Optimizers for Structure-aware Recommendation Embedding Evolution. (arXiv:2310.03032v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03032
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32467;&#26500;&#24863;&#30693;&#23884;&#20837;&#28436;&#21270;(SEvo)&#26426;&#21046;&#65292;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#24320;&#38144;&#23558;&#22270;&#32467;&#26500;&#20449;&#24687;&#27880;&#20837;&#21040;&#23884;&#20837;&#20013;&#65292;&#20174;&#32780;&#22312;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23884;&#20837;&#22312;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#30495;&#23454;&#19990;&#30028;&#23454;&#20307;&#30340;&#34394;&#25311;&#34920;&#31034;&#65292;&#24182;&#19988;&#26159;&#21518;&#32493;&#20915;&#31574;&#27169;&#22411;&#30340;&#22522;&#30784;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23884;&#20837;&#26356;&#26032;&#26426;&#21046;&#65292;&#31216;&#20026;&#32467;&#26500;&#24863;&#30693;&#23884;&#20837;&#28436;&#21270;(SEvo)&#65292;&#20197;&#40723;&#21169;&#30456;&#20851;&#33410;&#28857;&#22312;&#27599;&#19968;&#27493;&#20013;&#20197;&#31867;&#20284;&#30340;&#26041;&#24335;&#28436;&#21270;&#12290;&#19982;&#36890;&#24120;&#20316;&#20026;&#20013;&#38388;&#37096;&#20998;&#30340;GNN&#65288;&#22270;&#31070;&#32463;&#32593;&#32476;&#65289;&#19981;&#21516;&#65292;SEvo&#33021;&#22815;&#30452;&#25509;&#23558;&#22270;&#32467;&#26500;&#20449;&#24687;&#27880;&#20837;&#21040;&#23884;&#20837;&#20013;&#65292;&#19988;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#35745;&#31639;&#24320;&#38144;&#21487;&#24573;&#30053;&#12290;&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#39564;&#35777;&#20102;SEvo&#30340;&#25910;&#25947;&#24615;&#36136;&#21450;&#20854;&#21487;&#33021;&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;&#20197;&#35777;&#26126;&#35774;&#35745;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;SEvo&#21487;&#20197;&#26080;&#32541;&#38598;&#25104;&#21040;&#29616;&#26377;&#30340;&#20248;&#21270;&#22120;&#20013;&#65292;&#20197;&#23454;&#29616;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#30697;&#20272;&#35745;&#26657;&#27491;&#30340;SEvo&#22686;&#24378;AdamW&#20013;&#65292;&#35777;&#26126;&#20102;&#19968;&#33268;&#30340;&#25913;&#36827;&#25928;&#26524;&#22312;&#22810;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#65292;&#20026;&#26377;&#25928;&#25512;&#33616;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#36335;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Embedding plays a critical role in modern recommender systems because they are virtual representations of real-world entities and the foundation for subsequent decision models. In this paper, we propose a novel embedding update mechanism, Structure-aware Embedding Evolution (SEvo for short), to encourage related nodes to evolve similarly at each step. Unlike GNN (Graph Neural Network) that typically serves as an intermediate part, SEvo is able to directly inject the graph structure information into embedding with negligible computational overhead in training. The convergence properties of SEvo as well as its possible variants are theoretically analyzed to justify the validity of the designs. Moreover, SEvo can be seamlessly integrated into existing optimizers for state-of-the-art performance. In particular, SEvo-enhanced AdamW with moment estimate correction demonstrates consistent improvements across a spectrum of models and datasets, suggesting a novel technical route to effectively 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;SE-PEF&#65292;&#19968;&#20010;&#29992;&#20110;&#20010;&#24615;&#21270;&#19987;&#23478;&#26597;&#25214;&#30340;&#36164;&#28304;&#12290;&#35813;&#36164;&#28304;&#21253;&#25324;&#36229;&#36807;25&#19975;&#20010;&#26597;&#35810;&#21644;56.5&#19975;&#20010;&#31572;&#26696;&#65292;&#24182;&#20351;&#29992;&#19968;&#22871;&#20016;&#23500;&#30340;&#29305;&#24449;&#26469;&#24314;&#27169;&#29992;&#25143;&#20043;&#38388;&#30340;&#31038;&#20132;&#20114;&#21160;&#12290;&#21021;&#27493;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;SE-PEF&#36866;&#29992;&#20110;&#35780;&#20272;&#21644;&#35757;&#32451;&#26377;&#25928;&#30340;&#19987;&#23478;&#26597;&#25214;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.11686</link><description>&lt;p&gt;
SE-PEF:&#19968;&#20010;&#29992;&#20110;&#20010;&#24615;&#21270;&#19987;&#23478;&#26597;&#25214;&#30340;&#36164;&#28304;
&lt;/p&gt;
&lt;p&gt;
SE-PEF: a Resource for Personalized Expert Finding. (arXiv:2309.11686v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11686
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;SE-PEF&#65292;&#19968;&#20010;&#29992;&#20110;&#20010;&#24615;&#21270;&#19987;&#23478;&#26597;&#25214;&#30340;&#36164;&#28304;&#12290;&#35813;&#36164;&#28304;&#21253;&#25324;&#36229;&#36807;25&#19975;&#20010;&#26597;&#35810;&#21644;56.5&#19975;&#20010;&#31572;&#26696;&#65292;&#24182;&#20351;&#29992;&#19968;&#22871;&#20016;&#23500;&#30340;&#29305;&#24449;&#26469;&#24314;&#27169;&#29992;&#25143;&#20043;&#38388;&#30340;&#31038;&#20132;&#20114;&#21160;&#12290;&#21021;&#27493;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;SE-PEF&#36866;&#29992;&#20110;&#35780;&#20272;&#21644;&#35757;&#32451;&#26377;&#25928;&#30340;&#19987;&#23478;&#26597;&#25214;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#20449;&#24687;&#26816;&#32034;&#30340;&#38382;&#39064;&#24050;&#32463;&#34987;&#30740;&#31350;&#20102;&#24456;&#38271;&#26102;&#38388;&#12290;&#19982;&#36825;&#39033;&#20219;&#21153;&#30456;&#20851;&#30340;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#38382;&#39064;&#26159;&#32570;&#20047;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#21487;&#20197;&#25903;&#25345;&#20010;&#24615;&#21270;&#25628;&#32034;&#31995;&#32479;&#30340;&#27604;&#36739;&#35780;&#20272;&#12290;&#20026;&#20102;&#22312;&#36825;&#26041;&#38754;&#20570;&#20986;&#36129;&#29486;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;SE-PEF&#65288;StackExchange-&#20010;&#24615;&#21270;&#19987;&#23478;&#26597;&#25214;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35774;&#35745;&#21644;&#35780;&#20272;&#19982;&#19987;&#23478;&#26597;&#25214;&#65288;EF&#65289;&#20219;&#21153;&#30456;&#20851;&#30340;&#20010;&#24615;&#21270;&#27169;&#22411;&#30340;&#36164;&#28304;&#12290;&#25152;&#36129;&#29486;&#30340;&#25968;&#25454;&#38598;&#21253;&#25324;&#26469;&#33258;3306&#20010;&#19987;&#23478;&#30340;&#36229;&#36807;25&#19975;&#20010;&#26597;&#35810;&#21644;56.5&#19975;&#20010;&#31572;&#26696;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#20351;&#29992;&#20102;&#19968;&#22871;&#20016;&#23500;&#30340;&#29305;&#24449;&#26469;&#24314;&#27169;&#28909;&#38376;cQA&#24179;&#21488;&#19978;&#29992;&#25143;&#20043;&#38388;&#30340;&#31038;&#20132;&#20114;&#21160;&#12290;&#21021;&#27493;&#23454;&#39564;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;SE-PEF&#36866;&#29992;&#20110;&#35780;&#20272;&#21644;&#35757;&#32451;&#26377;&#25928;&#30340;EF&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of personalization in Information Retrieval has been under study for a long time. A well-known issue related to this task is the lack of publicly available datasets that can support a comparative evaluation of personalized search systems. To contribute in this respect, this paper introduces SE-PEF (StackExchange - Personalized Expert Finding), a resource useful for designing and evaluating personalized models related to the task of Expert Finding (EF). The contributed dataset includes more than 250k queries and 565k answers from 3 306 experts, which are annotated with a rich set of features modeling the social interactions among the users of a popular cQA platform. The results of the preliminary experiments conducted show the appropriateness of SE-PEF to evaluate and to train effective EF models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#31038;&#20250;&#36873;&#25321;&#26426;&#21046;&#65292;&#25506;&#32034;&#20102;&#22810;&#20010;&#22810;&#26041;&#38754;&#20844;&#24179;&#24212;&#29992;&#20013;&#30340;&#36873;&#25321;&#26426;&#21046;&#36873;&#39033;&#65292;&#32467;&#26524;&#26174;&#31034;&#19981;&#21516;&#30340;&#36873;&#25321;&#21644;&#20998;&#37197;&#26426;&#21046;&#20250;&#20135;&#29983;&#19981;&#21516;&#20294;&#19968;&#33268;&#30340;&#20844;&#24179;&#24615;/&#20934;&#30830;&#24615;&#26435;&#34913;&#32467;&#26524;&#65292;&#24182;&#19988;&#22810;&#26234;&#33021;&#20307;&#30340;&#26500;&#25104;&#20351;&#24471;&#31995;&#32479;&#33021;&#22815;&#36866;&#24212;&#29992;&#25143;&#20154;&#21475;&#30340;&#21160;&#24577;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2309.08621</link><description>&lt;p&gt;
&#22312;SCRUF&#20013;&#25506;&#32034;&#25512;&#33616;&#20844;&#24179;&#24615;&#30340;&#31038;&#20250;&#36873;&#25321;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Exploring Social Choice Mechanisms for Recommendation Fairness in SCRUF. (arXiv:2309.08621v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08621
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#31038;&#20250;&#36873;&#25321;&#26426;&#21046;&#65292;&#25506;&#32034;&#20102;&#22810;&#20010;&#22810;&#26041;&#38754;&#20844;&#24179;&#24212;&#29992;&#20013;&#30340;&#36873;&#25321;&#26426;&#21046;&#36873;&#39033;&#65292;&#32467;&#26524;&#26174;&#31034;&#19981;&#21516;&#30340;&#36873;&#25321;&#21644;&#20998;&#37197;&#26426;&#21046;&#20250;&#20135;&#29983;&#19981;&#21516;&#20294;&#19968;&#33268;&#30340;&#20844;&#24179;&#24615;/&#20934;&#30830;&#24615;&#26435;&#34913;&#32467;&#26524;&#65292;&#24182;&#19988;&#22810;&#26234;&#33021;&#20307;&#30340;&#26500;&#25104;&#20351;&#24471;&#31995;&#32479;&#33021;&#22815;&#36866;&#24212;&#29992;&#25143;&#20154;&#21475;&#30340;&#21160;&#24577;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#24448;&#24448;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#22797;&#26434;&#24615;&#65292;&#32780;&#36825;&#19968;&#28857;&#22312;&#31616;&#21270;&#30340;&#30740;&#31350;&#20844;&#24335;&#20013;&#24182;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#30340;&#20307;&#29616;&#12290;&#22312;&#23545;&#20844;&#24179;&#24615;&#38382;&#39064;&#36827;&#34892;&#31038;&#20250;&#36873;&#25321;&#30340;&#26694;&#26550;&#20013;&#65292;&#21487;&#20197;&#22312;&#22810;&#26234;&#33021;&#20307;&#30340;&#20844;&#24179;&#24615;&#20851;&#27880;&#22522;&#30784;&#19978;&#25552;&#20379;&#19968;&#31181;&#28789;&#27963;&#19988;&#22810;&#26041;&#38754;&#30340;&#20844;&#24179;&#24615;&#24863;&#30693;&#25512;&#33616;&#26041;&#27861;&#12290;&#21033;&#29992;&#31038;&#20250;&#36873;&#25321;&#21487;&#20197;&#22686;&#21152;&#36890;&#29992;&#24615;&#65292;&#24182;&#26377;&#21487;&#33021;&#21033;&#29992;&#32463;&#36807;&#30740;&#31350;&#30340;&#31038;&#20250;&#36873;&#25321;&#31639;&#27861;&#35299;&#20915;&#22810;&#20010;&#31454;&#20105;&#30340;&#20844;&#24179;&#24615;&#20851;&#27880;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#22810;&#26041;&#38754;&#20844;&#24179;&#24212;&#29992;&#20013;&#36873;&#25321;&#26426;&#21046;&#30340;&#19968;&#31995;&#21015;&#36873;&#39033;&#65292;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#65292;&#32467;&#26524;&#26174;&#31034;&#19981;&#21516;&#31867;&#21035;&#30340;&#36873;&#25321;&#21644;&#20998;&#37197;&#26426;&#21046;&#22312;&#20844;&#24179;&#24615;/&#20934;&#30830;&#24615;&#26435;&#34913;&#26041;&#38754;&#20135;&#29983;&#20102;&#19981;&#21516;&#20294;&#19968;&#33268;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#22810;&#26234;&#33021;&#20307;&#30340;&#26500;&#25104;&#25552;&#20379;&#20102;&#36866;&#24212;&#29992;&#25143;&#20154;&#21475;&#21160;&#24577;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fairness problems in recommender systems often have a complexity in practice that is not adequately captured in simplified research formulations. A social choice formulation of the fairness problem, operating within a multi-agent architecture of fairness concerns, offers a flexible and multi-aspect alternative to fairness-aware recommendation approaches. Leveraging social choice allows for increased generality and the possibility of tapping into well-studied social choice algorithms for resolving the tension between multiple, competing fairness concerns. This paper explores a range of options for choice mechanisms in multi-aspect fairness applications using both real and synthetic data and shows that different classes of choice and allocation mechanisms yield different but consistent fairness / accuracy tradeoffs. We also show that a multi-agent formulation offers flexibility in adapting to user population dynamics.
&lt;/p&gt;</description></item><item><title>SpaDE &#26159;&#19968;&#31181;&#21033;&#29992;&#21452;&#37325;&#32534;&#30721;&#22120;&#23398;&#20064;&#25991;&#26723;&#34920;&#31034;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#25913;&#21892;&#35789;&#27719;&#21305;&#37197;&#21644;&#25193;&#23637;&#39069;&#22806;&#26415;&#35821;&#26469;&#25903;&#25345;&#35821;&#20041;&#21305;&#37197;&#65292;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2209.05917</link><description>&lt;p&gt;
SpaDE: &#19968;&#31181;&#21033;&#29992;&#21452;&#37325;&#25991;&#26723;&#32534;&#30721;&#22120;&#25913;&#21892;&#31232;&#30095;&#34920;&#31034;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SpaDE: Improving Sparse Representations using a Dual Document Encoder for First-stage Retrieval. (arXiv:2209.05917v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.05917
&lt;/p&gt;
&lt;p&gt;
SpaDE &#26159;&#19968;&#31181;&#21033;&#29992;&#21452;&#37325;&#32534;&#30721;&#22120;&#23398;&#20064;&#25991;&#26723;&#34920;&#31034;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#25913;&#21892;&#35789;&#27719;&#21305;&#37197;&#21644;&#25193;&#23637;&#39069;&#22806;&#26415;&#35821;&#26469;&#25903;&#25345;&#35821;&#20041;&#21305;&#37197;&#65292;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#30340;&#25991;&#26723;&#34920;&#31034;&#32463;&#24120;&#34987;&#29992;&#26469;&#36890;&#36807;&#31934;&#30830;&#30340;&#35789;&#27719;&#21305;&#37197;&#26469;&#26816;&#32034;&#30456;&#20851;&#25991;&#26723;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39044;&#20808;&#35745;&#31639;&#30340;&#20498;&#25490;&#32034;&#24341;&#65292;&#20250;&#24341;&#21457;&#35789;&#27719;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;&#26368;&#36817;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#38656;&#35201;&#26114;&#36149;&#30340;&#26597;&#35810;&#25512;&#29702;&#25104;&#26412;&#65292;&#36825;&#24847;&#21619;&#30528;&#25928;&#29575;&#21644;&#25928;&#26524;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21333;&#32534;&#30721;&#22120;&#25490;&#21517;&#27169;&#22411;&#65292;&#21033;&#29992;&#21452;&#37325;&#32534;&#30721;&#22120;&#23398;&#20064;&#25991;&#26723;&#34920;&#31034;&#65292;&#31216;&#20026; Sparse retriever using a Dual document Encoder (SpaDE)&#12290;&#27599;&#20010;&#32534;&#30721;&#22120;&#22312;&#25913;&#21892;&#35789;&#27719;&#21305;&#37197;&#21644;&#25193;&#23637;&#39069;&#22806;&#26415;&#35821;&#26469;&#25903;&#25345;&#35821;&#20041;&#21305;&#37197;&#26041;&#38754;&#21457;&#25381;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#21327;&#21516;&#35757;&#32451;&#31574;&#30053;&#21487;&#20197;&#26377;&#25928;&#22320;&#35757;&#32451;&#21452;&#37325;&#32534;&#30721;&#22120;&#65292;&#24182;&#36991;&#20813;&#19981;&#24517;&#35201;&#30340;&#24178;&#39044;&#24444;&#27492;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SpaDE &#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#26816;&#32034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse document representations have been widely used to retrieve relevant documents via exact lexical matching. Owing to the pre-computed inverted index, it supports fast ad-hoc search but incurs the vocabulary mismatch problem. Although recent neural ranking models using pre-trained language models can address this problem, they usually require expensive query inference costs, implying the trade-off between effectiveness and efficiency. Tackling the trade-off, we propose a novel uni-encoder ranking model, Sparse retriever using a Dual document Encoder (SpaDE), learning document representation via the dual encoder. Each encoder plays a central role in (i) adjusting the importance of terms to improve lexical matching and (ii) expanding additional terms to support semantic matching. Furthermore, our co-training strategy trains the dual encoder effectively and avoids unnecessary intervention in training each other. Experimental results on several benchmarks show that SpaDE outperforms ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#26041;&#27861;SR-HetGNN&#65292;&#36890;&#36807;&#23398;&#20064;&#20250;&#35805;&#23884;&#20837;&#24182;&#25429;&#25417;&#21311;&#21517;&#29992;&#25143;&#30340;&#29305;&#23450;&#20559;&#22909;&#65292;&#20197;&#25913;&#36827;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#25928;&#26524;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2108.05641</link><description>&lt;p&gt;
SR-HetGNN:&#22522;&#20110;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
SR-HetGNN:Session-based Recommendation with Heterogeneous Graph Neural Network. (arXiv:2108.05641v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.05641
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#26041;&#27861;SR-HetGNN&#65292;&#36890;&#36807;&#23398;&#20064;&#20250;&#35805;&#23884;&#20837;&#24182;&#25429;&#25417;&#21311;&#21517;&#29992;&#25143;&#30340;&#29305;&#23450;&#20559;&#22909;&#65292;&#20197;&#25913;&#36827;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#25928;&#26524;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#30446;&#30340;&#26159;&#26681;&#25454;&#20808;&#21069;&#30340;&#20250;&#35805;&#24207;&#21015;&#39044;&#27979;&#29992;&#25143;&#30340;&#19979;&#19968;&#27425;&#28857;&#20987;&#12290;&#30446;&#21069;&#30340;&#30740;&#31350;&#36890;&#24120;&#26681;&#25454;&#29992;&#25143;&#20250;&#35805;&#24207;&#21015;&#20013;&#30340;&#39033;&#30446;&#36716;&#25442;&#26469;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#20250;&#35805;&#24207;&#21015;&#20013;&#30340;&#20854;&#20182;&#26377;&#25928;&#20449;&#24687;&#65292;&#22914;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#65292;&#24448;&#24448;&#34987;&#24573;&#35270;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#26080;&#27861;&#23398;&#20064;&#29992;&#25143;&#30340;&#20855;&#20307;&#20559;&#22909;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;SR-HetGNN&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;HetGNN&#65289;&#23398;&#20064;&#20250;&#35805;&#23884;&#20837;&#65292;&#24182;&#25429;&#25417;&#21311;&#21517;&#29992;&#25143;&#30340;&#29305;&#23450;&#20559;&#22909;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SR-HetGNN&#39318;&#20808;&#26681;&#25454;&#20250;&#35805;&#24207;&#21015;&#26500;&#24314;&#21253;&#21547;&#21508;&#31181;&#31867;&#22411;&#33410;&#28857;&#30340;&#24322;&#26500;&#22270;&#65292;&#21487;&#20197;&#25429;&#25417;&#39033;&#30446;&#12289;&#29992;&#25143;&#21644;&#20250;&#35805;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#20854;&#27425;&#65292;HetGNN&#25429;&#25417;&#39033;&#30446;&#20043;&#38388;&#30340;&#22797;&#26434;&#36716;&#25442;&#24182;&#23398;&#20064;&#21253;&#21547;&#39033;&#30446;&#23884;&#20837;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The purpose of the Session-Based Recommendation System is to predict the user's next click according to the previous session sequence. The current studies generally learn user preferences according to the transitions of items in the user's session sequence. However, other effective information in the session sequence, such as user profiles, are largely ignored which may lead to the model unable to learn the user's specific preferences. In this paper, we propose a heterogeneous graph neural network-based session recommendation method, named SR-HetGNN, which can learn session embeddings by heterogeneous graph neural network (HetGNN), and capture the specific preferences of anonymous users. Specifically, SR-HetGNN first constructs heterogeneous graphs containing various types of nodes according to the session sequence, which can capture the dependencies among items, users, and sessions. Second, HetGNN captures the complex transitions between items and learns the item embeddings containing
&lt;/p&gt;</description></item></channel></rss>