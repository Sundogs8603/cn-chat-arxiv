<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#38754;&#21521;&#25512;&#33616;&#30340;&#25299;&#25169;&#24863;&#30693;&#21435;&#20559;&#21521;&#33258;&#30417;&#30563;&#22270;&#23398;&#20064;&#65288;TDSGL&#65289;&#36890;&#36807;&#26500;&#24314;&#23545;&#27604;&#23545;&#65292;&#32771;&#34385;&#29992;&#25143;&#65288;&#29289;&#21697;&#65289;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#36127;&#37319;&#26679;&#31574;&#30053;&#23548;&#33268;&#30340;&#38169;&#35823;&#36127;&#26679;&#26412;&#21644;&#24573;&#30053;&#27491;&#26679;&#26412;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.15858</link><description>&lt;p&gt;
&#38754;&#21521;&#25512;&#33616;&#30340;&#25299;&#25169;&#24863;&#30693;&#21435;&#20559;&#21521;&#33258;&#30417;&#30563;&#22270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Topology-aware Debiased Self-supervised Graph Learning for Recommendation. (arXiv:2310.15858v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15858
&lt;/p&gt;
&lt;p&gt;
&#38754;&#21521;&#25512;&#33616;&#30340;&#25299;&#25169;&#24863;&#30693;&#21435;&#20559;&#21521;&#33258;&#30417;&#30563;&#22270;&#23398;&#20064;&#65288;TDSGL&#65289;&#36890;&#36807;&#26500;&#24314;&#23545;&#27604;&#23545;&#65292;&#32771;&#34385;&#29992;&#25143;&#65288;&#29289;&#21697;&#65289;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#36127;&#37319;&#26679;&#31574;&#30053;&#23548;&#33268;&#30340;&#38169;&#35823;&#36127;&#26679;&#26412;&#21644;&#24573;&#30053;&#27491;&#26679;&#26412;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#22522;&#20110;&#22270;&#30340;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#22270;&#23545;&#27604;&#23398;&#20064;&#26469;&#32531;&#35299;&#25968;&#25454;&#31232;&#30095;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22522;&#20110;&#22270;&#23545;&#27604;&#23398;&#20064;&#30340;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#20013;&#30340;&#38543;&#26426;&#36127;&#37319;&#26679;&#31574;&#30053;&#24573;&#35270;&#20102;&#29992;&#25143;&#65288;&#29289;&#21697;&#65289;&#30340;&#35821;&#20041;&#32467;&#26500;&#65292;&#36825;&#19981;&#20165;&#24341;&#20837;&#20102;&#38169;&#35823;&#30340;&#36127;&#26679;&#26412;&#65288;&#19982;&#38170;&#23450;&#29992;&#25143;&#65288;&#29289;&#21697;&#65289;&#30456;&#20284;&#30340;&#36127;&#26679;&#26412;&#65289;&#65292;&#36824;&#24573;&#30053;&#20102;&#28508;&#22312;&#30340;&#27491;&#26679;&#26412;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38754;&#21521;&#25512;&#33616;&#30340;&#25299;&#25169;&#24863;&#30693;&#21435;&#20559;&#21521;&#33258;&#30417;&#30563;&#22270;&#23398;&#20064;&#65288;TDSGL&#65289;&#65292;&#26681;&#25454;&#29992;&#25143;&#65288;&#29289;&#21697;&#65289;&#20043;&#38388;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#26500;&#24314;&#23545;&#27604;&#23545;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30001;&#20110;&#21407;&#22987;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#25968;&#25454;&#24456;&#22909;&#22320;&#21453;&#26144;&#20102;&#29992;&#25143;&#30340;&#36141;&#20080;&#24847;&#22270;&#21644;&#29289;&#21697;&#30340;&#26576;&#20123;&#29305;&#24449;&#65292;&#25105;&#20204;&#22312;&#20132;&#20114;&#25968;&#25454;&#19978;&#35745;&#31639;&#29992;&#25143;&#65288;&#29289;&#21697;&#65289;&#20043;&#38388;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#28982;&#21518;&#65292;&#32473;&#23450;&#19968;&#20010;&#29992;&#25143;&#65288;&#29289;&#21697;&#65289;&#65292;&#25105;&#20204;&#36890;&#36807;&#36873;&#25321;&#23884;&#20837;&#19981;&#21516;&#35821;&#20041;&#32467;&#26500;&#30340;&#29992;&#25143;&#65288;&#29289;&#21697;&#65289;&#26469;&#26500;&#24314;&#20854;&#36127;&#26679;&#26412;&#23545;&#65292;&#20197;&#30830;&#20445;&#21435;&#20559;&#21521;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommendation, graph-based Collaborative Filtering (CF) methods mitigate the data sparsity by introducing Graph Contrastive Learning (GCL). However, the random negative sampling strategy in these GCL-based CF models neglects the semantic structure of users (items), which not only introduces false negatives (negatives that are similar to anchor user (item)) but also ignores the potential positive samples. To tackle the above issues, we propose Topology-aware Debiased Self-supervised Graph Learning (TDSGL) for recommendation, which constructs contrastive pairs according to the semantic similarity between users (items). Specifically, since the original user-item interaction data commendably reflects the purchasing intent of users and certain characteristics of items, we calculate the semantic similarity between users (items) on interaction data. Then, given a user (item), we construct its negative pairs by selecting users (items) which embed different semantic structures to ensure the
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#21551;&#21457;&#24335;&#20844;&#24335;&#24471;&#21040;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.15790</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#26415;&#35821;&#29190;&#21457;&#24615;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A statistical significance testing approach for measuring term burstiness with applications to domain-specific terminology extraction. (arXiv:2310.15790v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15790
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#21551;&#21457;&#24335;&#20844;&#24335;&#24471;&#21040;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#26159;&#25991;&#26412;&#20998;&#26512;&#20013;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#24403;&#35821;&#26009;&#24211;&#20013;&#19968;&#20010;&#26415;&#35821;&#30340;&#20986;&#29616;&#38598;&#20013;&#22312;&#23569;&#25968;&#20960;&#20010;&#25991;&#20214;&#20013;&#26102;&#65292;&#21487;&#31216;&#20043;&#20026;&#8220;&#29190;&#21457;&#24615;&#8221;&#12290;&#20316;&#20026;&#20869;&#23481;&#20016;&#23500;&#30340;&#26415;&#35821;&#65292;&#29190;&#21457;&#24615;&#26415;&#35821;&#38750;&#24120;&#36866;&#21512;&#29992;&#20110;&#20027;&#39064;&#25551;&#36848;&#65292;&#24182;&#19988;&#26159;&#25216;&#26415;&#26415;&#35821;&#30340;&#33258;&#28982;&#20505;&#36873;&#35789;&#12290;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#22810;&#31181;&#26415;&#35821;&#29190;&#21457;&#24615;&#30340;&#27979;&#37327;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#25991;&#26412;&#20998;&#26512;&#20013;&#65292;&#21253;&#25324;&#19982;&#26415;&#35821;&#29190;&#21457;&#24615;&#30456;&#20851;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#33539;&#24335;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#20010;&#39046;&#22495;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#31934;&#30830;&#27979;&#35797;&#26041;&#27861;&#12290;&#30001;&#20110;&#35745;&#31639;&#25104;&#26412;&#36807;&#39640;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#21551;&#21457;&#24335;&#20844;&#24335;&#65292;&#29992;&#20110;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#20316;&#20026;&#34917;&#20805;&#30340;&#29702;&#35770;&#36129;&#29486;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31181;&#26410;&#32463;&#25253;&#36947;&#30340;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain-specific terminology extraction is an important task in text analysis. A term in a corpus is said to be "bursty" when its occurrences are concentrated in few out of many documents. Being content rich, bursty terms are highly suited for subject matter characterization, and serve as natural candidates for identifying with technical terminology. Multiple measures of term burstiness have been proposed in the literature. However, the statistical significance testing paradigm has remained underexplored in text analysis, including in relation to term burstiness. To test these waters, we propose as our main contribution a multinomial language model-based exact test of statistical significance for term burstiness. Due to its prohibitive computational cost, we advance a heuristic formula designed to serve as a proxy for test P-values. As a complementary theoretical contribution, we derive a previously unreported relationship connecting the inverse document frequency and inverse collection
&lt;/p&gt;</description></item><item><title>TCRA-LLM&#26159;&#36890;&#36807;&#27010;&#36848;&#21387;&#32553;&#21644;&#35821;&#20041;&#21387;&#32553;&#20004;&#31181;&#26041;&#27861;&#26469;&#20943;&#23569;&#21830;&#19994;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#25104;&#26412;&#30340;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.15556</link><description>&lt;p&gt;
TCRA-LLM: &#29992;&#20110;&#20943;&#23569;&#25512;&#29702;&#25104;&#26412;&#30340;&#20196;&#29260;&#21387;&#32553;&#26816;&#32034;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction. (arXiv:2310.15556v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15556
&lt;/p&gt;
&lt;p&gt;
TCRA-LLM&#26159;&#36890;&#36807;&#27010;&#36848;&#21387;&#32553;&#21644;&#35821;&#20041;&#21387;&#32553;&#20004;&#31181;&#26041;&#27861;&#26469;&#20943;&#23569;&#21830;&#19994;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#25104;&#26412;&#30340;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;ChatGPT&#21457;&#24067;&#20102;API&#20379;&#20844;&#20247;&#20351;&#29992;&#20197;&#26469;&#65292;&#26500;&#24314;&#22312;&#21830;&#19994;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20043;&#19978;&#30340;&#24212;&#29992;&#31243;&#24207;&#25968;&#37327;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#19968;&#20010;&#27969;&#34892;&#29992;&#27861;&#26159;&#21033;&#29992;&#20854;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#24182;&#29983;&#25104;&#21709;&#24212;&#20197;&#22238;&#31572;&#29992;&#25143;&#26597;&#35810;&#65292;&#24182;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#33719;&#24471;&#30340;&#30693;&#35782;&#12290;&#37096;&#32626;&#21830;&#19994;&#26816;&#32034;&#22686;&#24378;&#22411;LLM&#30340;&#19968;&#20010;&#38382;&#39064;&#26159;&#25104;&#26412;&#65292;&#22240;&#20026;&#39069;&#22806;&#26816;&#32034;&#30340;&#19978;&#19979;&#25991;&#22823;&#22823;&#22686;&#21152;&#20102;LLM&#30340;&#36755;&#20837;&#26631;&#35760;&#37327;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20196;&#29260;&#21387;&#32553;&#26041;&#26696;&#65292;&#21253;&#25324;&#20004;&#31181;&#26041;&#27861;&#65306;&#27010;&#36848;&#21387;&#32553;&#21644;&#35821;&#20041;&#21387;&#32553;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;T5&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#21253;&#21547;&#20855;&#26377;&#19981;&#21516;&#38271;&#24230;&#30340;&#26679;&#26412;&#30340;&#33258;&#25351;&#31034;&#25968;&#25454;&#38598;&#36827;&#34892;&#24494;&#35843;&#65292;&#24182;&#36890;&#36807;&#27010;&#36848;&#26469;&#20943;&#23569;&#20196;&#29260;&#22823;&#23567;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#36890;&#36807;&#31227;&#38500;&#23545;&#35821;&#20041;&#24433;&#21709;&#36739;&#23567;&#30340;&#35789;&#26469;&#36827;&#19968;&#27493;&#21387;&#32553;&#20196;&#29260;&#22823;&#23567;&#12290;&#20026;&#20102;&#20805;&#20998;&#35780;&#20272;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;
&lt;/p&gt;
&lt;p&gt;
Since ChatGPT released its API for public use, the number of applications built on top of commercial large language models (LLMs) increase exponentially. One popular usage of such models is leveraging its in-context learning ability and generating responses given user queries leveraging knowledge obtained by retrieval augmentation. One problem of deploying commercial retrieval-augmented LLMs is the cost due to the additionally retrieved context that largely increases the input token size of the LLMs. To mitigate this, we propose a token compression scheme that includes two methods: summarization compression and semantic compression. The first method applies a T5-based model that is fine-tuned by datasets generated using self-instruct containing samples with varying lengths and reduce token size by doing summarization. The second method further compresses the token size by removing words with lower impact on the semantic. In order to adequately evaluate the effectiveness of the proposed
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#22238;&#31572;&#32422;&#26463;&#28385;&#36275;&#26597;&#35810;&#30340;&#33021;&#21147;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;KITAB&#26469;&#34913;&#37327;&#35821;&#35328;&#27169;&#22411;&#30340;&#32422;&#26463;&#28385;&#36275;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.15511</link><description>&lt;p&gt;
&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#35780;&#20272;&#22522;&#20110;&#32422;&#26463;&#28385;&#36275;&#30340;LLMs
&lt;/p&gt;
&lt;p&gt;
KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval. (arXiv:2310.15511v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15511
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#22238;&#31572;&#32422;&#26463;&#28385;&#36275;&#26597;&#35810;&#30340;&#33021;&#21147;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;KITAB&#26469;&#34913;&#37327;&#35821;&#35328;&#27169;&#22411;&#30340;&#32422;&#26463;&#28385;&#36275;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#22238;&#31572;&#32422;&#26463;&#28385;&#36275;&#26597;&#35810;&#65288;&#20363;&#22914;&#65292;&#8220;&#22307;&#22320;&#20122;&#21733;&#30340;&#20912;&#28103;&#28107;&#24215;&#21015;&#34920;&#8221;&#65289;&#30340;&#33021;&#21147;&#12290;&#36807;&#21435;&#65292;&#36825;&#26679;&#30340;&#26597;&#35810;&#34987;&#35748;&#20026;&#21482;&#33021;&#36890;&#36807;&#32593;&#32476;&#25628;&#32034;&#25110;&#30693;&#35782;&#24211;&#26469;&#35299;&#20915;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#21021;&#27493;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#24403;&#21069;&#30340;&#26816;&#32034;&#22522;&#20934;&#35201;&#20040;&#24050;&#39281;&#21644;&#65292;&#35201;&#20040;&#19981;&#33021;&#34913;&#37327;&#32422;&#26463;&#28385;&#36275;&#12290;&#21463;&#21040;&#23545;LLMs&#20107;&#23454;&#19981;&#27491;&#30830;&#21644;&#20135;&#29983;&#24187;&#35273;&#30340;&#26085;&#30410;&#20851;&#27880;&#30340;&#39537;&#21160;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;KITAB&#65292;&#19968;&#20010;&#29992;&#20110;&#34913;&#37327;&#35821;&#35328;&#27169;&#22411;&#32422;&#26463;&#28385;&#36275;&#33021;&#21147;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;KITAB&#21253;&#21547;600&#22810;&#20301;&#20316;&#32773;&#21644;13,000&#20010;&#26597;&#35810;&#30340;&#19982;&#20070;&#31821;&#30456;&#20851;&#30340;&#25968;&#25454;&#65292;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#20851;&#32852;&#30340;&#21160;&#24577;&#25968;&#25454;&#25910;&#38598;&#21644;&#32422;&#26463;&#39564;&#35777;&#26041;&#27861;&#65292;&#20197;&#33719;&#24471;&#20854;&#20182;&#20316;&#32773;&#30340;&#31867;&#20284;&#27979;&#35797;&#25968;&#25454;&#12290;&#25105;&#20204;&#23545;GPT4&#21644;GPT3.5&#36827;&#34892;&#20102;&#25193;&#23637;&#23454;&#39564;&#65292;&#23545;&#24120;&#35265;&#30340;&#22833;&#36133;&#27169;&#24335;&#36827;&#34892;&#20102;&#34920;&#24449;&#21644;&#35299;&#32806;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the ability of state-of-the art models to answer constraint satisfaction queries for information retrieval (e.g., 'a list of ice cream shops in San Diego'). In the past, such queries were considered to be tasks that could only be solved via web-search or knowledge bases. More recently, large language models (LLMs) have demonstrated initial emergent abilities in this task. However, many current retrieval benchmarks are either saturated or do not measure constraint satisfaction. Motivated by rising concerns around factual incorrectness and hallucinations of LLMs, we present KITAB, a new dataset for measuring constraint satisfaction abilities of language models. KITAB consists of book-related data across more than 600 authors and 13,000 queries, and also offers an associated dynamic data collection and constraint verification approach for acquiring similar test data for other authors. Our extended experiments on GPT4 and GPT3.5 characterize and decouple common failure modes acros
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#40065;&#26834;&#30340;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#32479;&#19968;&#22312;&#32447;Top-K&#25512;&#33616;&#65292;&#22312;&#22823;&#35268;&#27169;&#24037;&#19994;&#30005;&#23376;&#21830;&#21153;&#20013;&#35299;&#20915;&#29289;&#21697;&#24191;&#21578;&#21644;&#20869;&#23481;&#24191;&#21578;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#20197;&#21450;&#36328;&#19981;&#21516;&#39046;&#22495;&#30340;&#22810;&#23454;&#20307;&#24191;&#21578;&#30340;&#26816;&#32034;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.15492</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#32479;&#19968;&#22312;&#32447;Top-K&#25512;&#33616;&#30340;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Robust Representation Learning for Unified Online Top-K Recommendation. (arXiv:2310.15492v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15492
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#40065;&#26834;&#30340;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#32479;&#19968;&#22312;&#32447;Top-K&#25512;&#33616;&#65292;&#22312;&#22823;&#35268;&#27169;&#24037;&#19994;&#30005;&#23376;&#21830;&#21153;&#20013;&#35299;&#20915;&#29289;&#21697;&#24191;&#21578;&#21644;&#20869;&#23481;&#24191;&#21578;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#20197;&#21450;&#36328;&#19981;&#21516;&#39046;&#22495;&#30340;&#22810;&#23454;&#20307;&#24191;&#21578;&#30340;&#26816;&#32034;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#24037;&#19994;&#30005;&#23376;&#21830;&#21153;&#20013;&#65292;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#30340;&#25928;&#29575;&#23545;&#20110;&#25552;&#20379;&#39640;&#24230;&#30456;&#20851;&#30340;&#29289;&#21697;/&#20869;&#23481;&#24191;&#21578;&#20197;&#28385;&#36275;&#22810;&#26679;&#21270;&#30340;&#19994;&#21153;&#22330;&#26223;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#30740;&#31350;&#20165;&#20851;&#27880;&#29289;&#21697;&#24191;&#21578;&#65292;&#24573;&#35270;&#20102;&#20869;&#23481;&#24191;&#21578;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#31181;&#30095;&#24573;&#23548;&#33268;&#20102;&#22810;&#23454;&#20307;&#32467;&#26500;&#20869;&#30340;&#19981;&#19968;&#33268;&#24615;&#21644;&#19981;&#20844;&#24179;&#26816;&#32034;&#12290;&#27492;&#22806;&#65292;&#20174;&#36328;&#19981;&#21516;&#39046;&#22495;&#30340;&#22810;&#23454;&#20307;&#24191;&#21578;&#20013;&#26816;&#32034;Top-K&#24191;&#21578;&#30340;&#25361;&#25112;&#20063;&#22686;&#21152;&#20102;&#22797;&#26434;&#24615;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#35777;&#26126;&#65292;&#19981;&#21516;&#39046;&#22495;&#20869;&#30340;&#29992;&#25143;-&#23454;&#20307;&#34892;&#20026;&#34920;&#29616;&#20986;&#24046;&#24322;&#24615;&#21644;&#21516;&#36136;&#24615;&#29305;&#24449;&#12290;&#22240;&#27492;&#65292;&#22810;&#39046;&#22495;&#21305;&#37197;&#27169;&#22411;&#36890;&#24120;&#20381;&#36182;&#20110;&#20855;&#26377;&#39046;&#22495;&#19981;&#21464;&#21644;&#39046;&#22495;&#29305;&#23450;&#34920;&#31034;&#30340;&#28151;&#21512;&#19987;&#23478;&#26694;&#26550;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#20248;&#21270;&#19981;&#21516;&#19987;&#23478;&#30340;&#32452;&#21512;&#27169;&#24335;&#65292;&#26410;&#33021;&#35299;&#20915;&#20248;&#21270;&#20013;&#22266;&#26377;&#30340;&#22256;&#38590;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In large-scale industrial e-commerce, the efficiency of an online recommendation system is crucial in delivering highly relevant item/content advertising that caters to diverse business scenarios. However, most existing studies focus solely on item advertising, neglecting the significance of content advertising. This oversight results in inconsistencies within the multi-entity structure and unfair retrieval. Furthermore, the challenge of retrieving top-k advertisements from multi-entity advertisements across different domains adds to the complexity. Recent research proves that user-entity behaviors within different domains exhibit characteristics of differentiation and homogeneity. Therefore, the multi-domain matching models typically rely on the hybrid-experts framework with domain-invariant and domain-specific representations. Unfortunately, most approaches primarily focus on optimizing the combination mode of different experts, failing to address the inherent difficulty in optimizin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31574;&#30053;&#21367;&#31215;&#65288;PC&#65289;&#30340;&#31163;&#31574;&#30053;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#21160;&#20316;&#23884;&#20837;&#26469;&#35299;&#20915;&#22823;&#21160;&#20316;&#31354;&#38388;&#19979;&#30340;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#65292;&#21487;&#20197;&#22312;&#20559;&#24046;&#21644;&#26041;&#24046;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;</title><link>http://arxiv.org/abs/2310.15433</link><description>&lt;p&gt;
&#22522;&#20110;&#31574;&#30053;&#21367;&#31215;&#30340;&#22823;&#21160;&#20316;&#31354;&#38388;&#31163;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation for Large Action Spaces via Policy Convolution. (arXiv:2310.15433v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15433
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31574;&#30053;&#21367;&#31215;&#65288;PC&#65289;&#30340;&#31163;&#31574;&#30053;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#21160;&#20316;&#23884;&#20837;&#26469;&#35299;&#20915;&#22823;&#21160;&#20316;&#31354;&#38388;&#19979;&#30340;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#65292;&#21487;&#20197;&#22312;&#20559;&#24046;&#21644;&#26041;&#24046;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21457;&#23637;&#20934;&#30830;&#30340;&#31163;&#31574;&#30053;&#20272;&#35745;&#22120;&#23545;&#20110;&#35780;&#20272;&#21644;&#20248;&#21270;&#26032;&#31574;&#30053;&#33267;&#20851;&#37325;&#35201;&#12290;&#31163;&#31574;&#30053;&#20272;&#35745;&#30340;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#29983;&#25104;&#25968;&#25454;&#30340;&#35760;&#24405;&#31574;&#30053;&#21644;&#25105;&#20204;&#35201;&#35780;&#20272;&#30340;&#30446;&#26631;&#31574;&#30053;&#20043;&#38388;&#30340;&#20998;&#24067;&#36716;&#31227;&#12290;&#36890;&#24120;&#65292;&#32416;&#27491;&#20998;&#24067;&#36716;&#31227;&#30340;&#25216;&#26415;&#28041;&#21450;&#26576;&#31181;&#24418;&#24335;&#30340;&#37325;&#35201;&#24615;&#37319;&#26679;&#12290;&#36825;&#31181;&#26041;&#27861;&#23548;&#33268;&#20102;&#26080;&#20559;&#20540;&#20272;&#35745;&#65292;&#20294;&#24448;&#24448;&#20250;&#24102;&#26469;&#39640;&#26041;&#24046;&#30340;&#20195;&#20215;&#65292;&#21363;&#20351;&#22312;&#31616;&#21333;&#30340;&#19968;&#27493;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#27492;&#22806;&#65292;&#37325;&#35201;&#24615;&#37319;&#26679;&#20381;&#36182;&#20110;&#20849;&#21516;&#25903;&#25345;&#20551;&#35774;&#65292;&#22312;&#21160;&#20316;&#31354;&#38388;&#24456;&#22823;&#26102;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31574;&#30053;&#21367;&#31215; (PC)&#23478;&#26063;&#30340;&#20272;&#35745;&#22120;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#36890;&#36807;&#21160;&#20316;&#23884;&#20837;&#25552;&#20379;&#30340;&#21160;&#20316;&#20869;&#37096;&#32467;&#26500;&#36827;&#34892;&#31574;&#30053;&#30340;&#31574;&#30053;&#21367;&#31215;&#12290;&#36825;&#31181;&#21367;&#31215;&#24341;&#20837;&#20102;&#29420;&#29305;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#65292;&#21487;&#20197;&#36827;&#34892;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Developing accurate off-policy estimators is crucial for both evaluating and optimizing for new policies. The main challenge in off-policy estimation is the distribution shift between the logging policy that generates data and the target policy that we aim to evaluate. Typically, techniques for correcting distribution shift involve some form of importance sampling. This approach results in unbiased value estimation but often comes with the trade-off of high variance, even in the simpler case of one-step contextual bandits. Furthermore, importance sampling relies on the common support assumption, which becomes impractical when the action space is large. To address these challenges, we introduce the Policy Convolution (PC) family of estimators. These methods leverage latent structure within actions -- made available through action embeddings -- to strategically convolve the logging and target policies. This convolution introduces a unique bias-variance trade-off, which can be controlled 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#31232;&#30095;&#32593;&#32476;&#30340;&#28151;&#21512;&#31890;&#24230;&#29305;&#24449;&#20132;&#20114;&#36873;&#25321;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#32771;&#34385;&#29305;&#24449;&#22495;&#21644;&#29305;&#24449;&#20540;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.15342</link><description>&lt;p&gt;
&#38754;&#21521;&#28145;&#24230;&#31232;&#30095;&#32593;&#32476;&#30340;&#28151;&#21512;&#31890;&#24230;&#29305;&#24449;&#20132;&#20114;&#36873;&#25321;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Hybrid-grained Feature Interaction Selection for Deep Sparse Network. (arXiv:2310.15342v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#31232;&#30095;&#32593;&#32476;&#30340;&#28151;&#21512;&#31890;&#24230;&#29305;&#24449;&#20132;&#20114;&#36873;&#25321;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#32771;&#34385;&#29305;&#24449;&#22495;&#21644;&#29305;&#24449;&#20540;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31232;&#30095;&#32593;&#32476;&#34987;&#24191;&#27867;&#30740;&#31350;&#20316;&#20026;&#20855;&#26377;&#39640;&#32500;&#31232;&#30095;&#29305;&#24449;&#30340;&#39044;&#27979;&#20219;&#21153;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#20854;&#20013;&#29305;&#24449;&#20132;&#20114;&#36873;&#25321;&#26159;&#19968;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#22914;&#20309;&#22312;&#31895;&#31890;&#24230;&#31354;&#38388;&#20013;&#25628;&#32034;&#29305;&#24449;&#20132;&#20114;&#65292;&#23545;&#20110;&#26356;&#32454;&#31890;&#24230;&#30340;&#32454;&#33410;&#21017;&#20851;&#27880;&#36739;&#23569;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#31232;&#30095;&#32593;&#32476;&#30340;&#28151;&#21512;&#31890;&#24230;&#29305;&#24449;&#20132;&#20114;&#36873;&#25321;&#26041;&#27861;&#65292;&#26088;&#22312;&#21516;&#26102;&#32771;&#34385;&#29305;&#24449;&#22495;&#21644;&#29305;&#24449;&#20540;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#26679;&#24191;&#38420;&#30340;&#31354;&#38388;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21363;&#26102;&#35745;&#31639;&#30340;&#20998;&#35299;&#31354;&#38388;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;OptFeature&#30340;&#36873;&#25321;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#26377;&#25928;&#22320;&#20174;&#29305;&#24449;&#22495;&#21644;&#29305;&#24449;&#20540;&#21516;&#26102;&#36873;&#25321;&#29305;&#24449;&#20132;&#20114;&#12290;&#22312;&#19977;&#20010;&#22823;&#22411;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;OptFeature&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;&#39069;&#22806;&#30340;&#30740;&#31350;&#25903;&#25345;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep sparse networks are widely investigated as a neural network architecture for prediction tasks with high-dimensional sparse features, with which feature interaction selection is a critical component. While previous methods primarily focus on how to search feature interaction in a coarse-grained space, less attention has been given to a finer granularity. In this work, we introduce a hybrid-grained feature interaction selection approach that targets both feature field and feature value for deep sparse networks. To explore such expansive space, we propose a decomposed space which is calculated on the fly. We then develop a selection algorithm called OptFeature, which efficiently selects the feature interaction from both the feature field and the feature value simultaneously. Results from experiments on three large real-world benchmark datasets demonstrate that OptFeature performs well in terms of accuracy and efficiency. Additional studies support the feasibility of our method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#19977;&#37325;&#21333;&#32431;&#24418;&#30697;&#38453;&#23436;&#25104;&#26041;&#27861;&#36827;&#34892;&#36153;&#29992;&#39044;&#27979;&#30340;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#39033;&#30446;&#19982;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#36153;&#29992;&#27169;&#24335;&#30456;&#20851;&#24615;&#26469;&#39044;&#27979;&#36153;&#29992;&#65292;&#21516;&#26102;&#28385;&#36275;&#39044;&#31639;&#32422;&#26463;&#24182;&#20445;&#35777;&#39044;&#27979;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.15275</link><description>&lt;p&gt;
&#19977;&#37325;&#21333;&#32431;&#24418;&#30697;&#38453;&#23436;&#25104;&#29992;&#20110;&#36153;&#29992;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Triple Simplex Matrix Completion for Expense Forecasting. (arXiv:2310.15275v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15275
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#19977;&#37325;&#21333;&#32431;&#24418;&#30697;&#38453;&#23436;&#25104;&#26041;&#27861;&#36827;&#34892;&#36153;&#29992;&#39044;&#27979;&#30340;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#39033;&#30446;&#19982;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#36153;&#29992;&#27169;&#24335;&#30456;&#20851;&#24615;&#26469;&#39044;&#27979;&#36153;&#29992;&#65292;&#21516;&#26102;&#28385;&#36275;&#39044;&#31639;&#32422;&#26463;&#24182;&#20445;&#35777;&#39044;&#27979;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#39033;&#30446;&#36153;&#29992;&#26159;&#20225;&#19994;&#36991;&#20813;&#39044;&#31639;&#36229;&#25903;&#21644;&#39033;&#30446;&#22833;&#36133;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#26159;&#30001;&#36130;&#21153;&#20998;&#26512;&#24072;&#25110;&#25968;&#25454;&#31185;&#23398;&#25216;&#26415;&#65288;&#22914;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#65289;&#23436;&#25104;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#33021;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20135;&#29983;&#19982;&#35745;&#21010;&#39044;&#31639;&#19981;&#21516;&#30340;&#32467;&#26524;&#65292;&#29305;&#21035;&#26159;&#22312;&#39033;&#30446;&#24320;&#22987;&#26102;&#25968;&#25454;&#28857;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#32422;&#26463;&#30340;&#38750;&#36127;&#30697;&#38453;&#23436;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#39033;&#30446;&#19982;&#28508;&#22312;&#31354;&#38388;&#20013;&#26576;&#20123;&#36153;&#29992;&#27169;&#24335;&#30340;&#30456;&#20851;&#24615;&#65292;&#39044;&#27979;&#36153;&#29992;&#30340;&#21487;&#33021;&#24615;&#12290;&#35813;&#27169;&#22411;&#22312;&#22240;&#23376;&#30697;&#38453;&#21644;&#32570;&#22833;&#26465;&#30446;&#19978;&#21463;&#21040;&#19977;&#20010;&#27010;&#29575;&#21333;&#32431;&#24418;&#30340;&#32422;&#26463;&#12290;&#27492;&#22806;&#65292;&#39044;&#27979;&#30340;&#36153;&#29992;&#20540;&#20445;&#35777;&#28385;&#36275;&#39044;&#31639;&#32422;&#26463;&#65292;&#26080;&#38656;&#21518;&#22788;&#29702;&#12290;&#19968;&#20010;&#38750;&#31934;&#30830;&#30340;&#20132;&#26367;&#20248;&#21270;&#31639;&#27861;&#34987;&#24320;&#21457;&#29992;&#20110;&#35299;&#20915;&#30456;&#20851;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#25910;&#25947;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecasting project expenses is a crucial step for businesses to avoid budget overruns and project failures. Traditionally, this has been done by financial analysts or data science techniques such as time-series analysis. However, these approaches can be uncertain and produce results that differ from the planned budget, especially at the start of a project with limited data points. This paper proposes a constrained non-negative matrix completion model that predicts expenses by learning the likelihood of the project correlating with certain expense patterns in the latent space. The model is constrained on three probability simplexes, two of which are on the factor matrices and the third on the missing entries. Additionally, the predicted expense values are guaranteed to meet the budget constraint without the need of post-processing. An inexact alternating optimization algorithm is developed to solve the associated optimization problem and is proven to converge to a stationary point. Res
&lt;/p&gt;</description></item><item><title>CorefPrompt&#26159;&#19968;&#31181;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27979;&#37327;&#20107;&#20214;&#31867;&#22411;&#21644;&#21442;&#25968;&#30340;&#20860;&#23481;&#24615;&#26469;&#36827;&#34892;&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#12290;&#35813;&#26041;&#27861;&#23558;&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#36716;&#21270;&#20026;&#19968;&#20010;&#22635;&#31354;&#24335;MLM&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#36741;&#21161;&#30340;&#25552;&#31034;&#20219;&#21153;&#26469;&#24110;&#21161;&#27169;&#22411;&#36827;&#34892;&#25512;&#29702;&#65292;&#26368;&#32456;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.14512</link><description>&lt;p&gt;
CorefPrompt: &#22522;&#20110;&#25552;&#31034;&#30340;&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#36890;&#36807;&#27979;&#37327;&#20107;&#20214;&#31867;&#22411;&#21644;&#21442;&#25968;&#30340;&#20860;&#23481;&#24615;
&lt;/p&gt;
&lt;p&gt;
CorefPrompt: Prompt-based Event Coreference Resolution by Measuring Event Type and Argument Compatibilities. (arXiv:2310.14512v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14512
&lt;/p&gt;
&lt;p&gt;
CorefPrompt&#26159;&#19968;&#31181;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27979;&#37327;&#20107;&#20214;&#31867;&#22411;&#21644;&#21442;&#25968;&#30340;&#20860;&#23481;&#24615;&#26469;&#36827;&#34892;&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#12290;&#35813;&#26041;&#27861;&#23558;&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#36716;&#21270;&#20026;&#19968;&#20010;&#22635;&#31354;&#24335;MLM&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#36741;&#21161;&#30340;&#25552;&#31034;&#20219;&#21153;&#26469;&#24110;&#21161;&#27169;&#22411;&#36827;&#34892;&#25512;&#29702;&#65292;&#26368;&#32456;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#26088;&#22312;&#23558;&#25351;&#20195;&#21516;&#19968;&#23454;&#38469;&#20107;&#20214;&#30340;&#20107;&#20214;&#25552;&#21450;&#32858;&#31867;&#22312;&#19968;&#36215;&#12290;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#30740;&#31350;&#37319;&#29992;&#8220;&#20808;&#32534;&#30721;&#65292;&#28982;&#21518;&#35780;&#20998;&#8221;&#30340;&#26694;&#26550;&#65292;&#20351;&#24471;&#25351;&#20195;&#28040;&#35299;&#20381;&#36182;&#20110;&#20107;&#20214;&#32534;&#30721;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#24456;&#38590;&#21033;&#29992;&#20154;&#24037;&#24635;&#32467;&#30340;&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#35268;&#21017;&#65292;&#20363;&#22914;&#65292;&#25351;&#20195;&#21516;&#19968;&#20107;&#20214;&#30340;&#20107;&#20214;&#24212;&#20855;&#26377;&#30456;&#21516;&#30340;&#20107;&#20214;&#31867;&#22411;&#65292;&#20197;&#25351;&#23548;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;CorefPrompt&#65292;&#23558;&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#36716;&#21270;&#20026;&#19968;&#20010;&#22635;&#31354;&#24335;MLM&#65288;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#65289;&#20219;&#21153;&#12290;&#36825;&#26679;&#21487;&#20197;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#27169;&#26495;&#20013;&#21516;&#26102;&#36827;&#34892;&#20107;&#20214;&#24314;&#27169;&#21644;&#25351;&#20195;&#28040;&#35299;&#21028;&#21035;&#65292;&#24182;&#19988;&#20855;&#26377;&#23436;&#20840;&#20849;&#20139;&#30340;&#19978;&#19979;&#25991;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#36741;&#21161;&#30340;&#25552;&#31034;&#20219;&#21153;&#65292;&#20107;&#20214;&#31867;&#22411;&#20860;&#23481;&#24615;&#21644;&#21442;&#25968;&#20860;&#23481;&#24615;&#65292;&#20197;&#26126;&#30830;&#23637;&#31034;&#20107;&#20214;&#25351;&#20195;&#28040;&#35299;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#20174;&#32780;&#24110;&#21161;&#27169;&#22411;&#20570;&#20986;&#26368;&#32456;&#30340;&#39044;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;CorefPrompt&#22312;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Event coreference resolution (ECR) aims to group event mentions referring to the same real-world event into clusters. Most previous studies adopt the "encoding first, then scoring" framework, making the coreference judgment rely on event encoding. Furthermore, current methods struggle to leverage human-summarized ECR rules, e.g., coreferential events should have the same event type, to guide the model. To address these two issues, we propose a prompt-based approach, CorefPrompt, to transform ECR into a cloze-style MLM (masked language model) task. This allows for simultaneous event modeling and coreference discrimination within a single template, with a fully shared context. In addition, we introduce two auxiliary prompt tasks, event-type compatibility and argument compatibility, to explicitly demonstrate the reasoning process of ECR, which helps the model make final predictions. Experimental results show that our method CorefPrompt performs well in a state-of-the-art (SOTA) benchmark.
&lt;/p&gt;</description></item><item><title>&#22312;&#29992;&#25143;&#24314;&#27169;&#20013;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#22686;&#24378;&#33258;&#30417;&#30563;&#25490;&#24207;&#26041;&#27861;&#39044;&#35757;&#32451;&#29992;&#25143;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#21644;&#29616;&#26377;&#22686;&#24378;&#26041;&#27861;&#24341;&#20837;&#30340;&#22122;&#38899;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.09706</link><description>&lt;p&gt;
AdaptSSR: &#20351;&#29992;&#33258;&#36866;&#24212;&#22686;&#24378;&#33258;&#30417;&#30563;&#25490;&#24207;&#26041;&#27861;&#39044;&#35757;&#32451;&#29992;&#25143;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
AdaptSSR: Pre-training User Model with Augmentation-Adaptive Self-Supervised Ranking. (arXiv:2310.09706v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09706
&lt;/p&gt;
&lt;p&gt;
&#22312;&#29992;&#25143;&#24314;&#27169;&#20013;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#22686;&#24378;&#33258;&#30417;&#30563;&#25490;&#24207;&#26041;&#27861;&#39044;&#35757;&#32451;&#29992;&#25143;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#21644;&#29616;&#26377;&#22686;&#24378;&#26041;&#27861;&#24341;&#20837;&#30340;&#22122;&#38899;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#24314;&#27169;&#26088;&#22312;&#25429;&#25417;&#29992;&#25143;&#30340;&#29305;&#24449;&#25110;&#20852;&#36259;&#65292;&#20294;&#21463;&#21040;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#30340;&#24433;&#21709;&#65292;&#24448;&#24448;&#38656;&#35201;&#20381;&#36182;&#29305;&#23450;&#20219;&#21153;&#30340;&#26631;&#27880;&#25968;&#25454;&#12290;&#26368;&#36817;&#30340;&#20960;&#39033;&#30740;&#31350;&#36890;&#36807;&#22312;&#22823;&#37327;&#29992;&#25143;&#34892;&#20026;&#24207;&#21015;&#19978;&#36827;&#34892;&#23545;&#27604;&#23398;&#20064;&#30340;&#39044;&#35757;&#32451;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#19968;&#33324;&#32780;&#35328;&#65292;&#36825;&#20123;&#26041;&#27861;&#20551;&#35774;&#36890;&#36807;&#25968;&#25454;&#22686;&#24378;&#26500;&#24314;&#30340;&#21516;&#19968;&#34892;&#20026;&#24207;&#21015;&#30340;&#19981;&#21516;&#35270;&#22270;&#22312;&#35821;&#20041;&#19978;&#26159;&#19968;&#33268;&#30340;&#65292;&#21363;&#21453;&#26144;&#29992;&#25143;&#30340;&#30456;&#20284;&#29305;&#24449;&#25110;&#20852;&#36259;&#65292;&#24182;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#26368;&#22823;&#21270;&#23427;&#20204;&#30340;&#19968;&#33268;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29992;&#25143;&#34892;&#20026;&#30340;&#22810;&#26679;&#20852;&#36259;&#21644;&#22823;&#37327;&#22122;&#38899;&#65292;&#29616;&#26377;&#30340;&#22686;&#24378;&#26041;&#27861;&#24448;&#24448;&#20250;&#20002;&#22833;&#26576;&#20123;&#29992;&#25143;&#29305;&#24449;&#25110;&#24341;&#20837;&#22122;&#22768;&#34892;&#20026;&#12290;&#22240;&#27492;&#65292;&#30452;&#25509;&#26368;&#22823;&#21270;&#22686;&#24378;&#35270;&#22270;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#21487;&#33021;&#23548;&#33268;&#36127;&#38754;&#36801;&#31227;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#29992;&#26032;&#30340;&#39044;&#35757;&#32451;&#20219;&#21153;&#26367;&#20195;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#65306;&#33258;&#36866;&#24212;&#22686;&#24378;&#33258;&#30417;&#30563;&#25490;&#24207;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
User modeling, which aims to capture users' characteristics or interests, heavily relies on task-specific labeled data and suffers from the data sparsity issue. Several recent studies tackled this problem by pre-training the user model on massive user behavior sequences with a contrastive learning task. Generally, these methods assume different views of the same behavior sequence constructed via data augmentation are semantically consistent, i.e., reflecting similar characteristics or interests of the user, and thus maximizing their agreement in the feature space. However, due to the diverse interests and heavy noise in user behaviors, existing augmentation methods tend to lose certain characteristics of the user or introduce noisy behaviors. Thus, forcing the user model to directly maximize the similarity between the augmented views may result in a negative transfer. To this end, we propose to replace the contrastive learning task with a new pretext task: Augmentation-Adaptive SelfSup
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#22686;&#24378;&#30340;&#30456;&#20851;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#65292;&#26469;&#25913;&#36827;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;-&#39033;&#30446;&#21305;&#37197;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05379</link><description>&lt;p&gt;
&#36229;&#36234;&#35821;&#20041;&#65306;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#30340;&#34892;&#20026;&#22686;&#24378;&#30456;&#20851;&#27169;&#22411;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning. (arXiv:2308.05379v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05379
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#22686;&#24378;&#30340;&#30456;&#20851;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#65292;&#26469;&#25913;&#36827;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;-&#39033;&#30446;&#21305;&#37197;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#24314;&#27169;&#26088;&#22312;&#23450;&#20301;&#19982;&#23545;&#24212;&#26597;&#35810;&#30456;&#20851;&#30340;&#29702;&#24819;&#39033;&#30446;&#65292;&#36825;&#23545;&#20110;&#25628;&#32034;&#24341;&#25806;&#30830;&#20445;&#29992;&#25143;&#20307;&#39564;&#38750;&#24120;&#37325;&#35201;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#20256;&#32479;&#26041;&#27861;&#36890;&#36807;&#35780;&#20272;&#26597;&#35810;&#19982;&#39033;&#30446;&#20043;&#38388;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#32431;&#35821;&#20041;&#21305;&#37197;&#24182;&#19981;&#26159;&#21807;&#19968;&#30340;&#26041;&#27861;&#12290;&#23454;&#38469;&#19978;&#65292;&#20174;&#29992;&#25143;&#25628;&#32034;&#35760;&#24405;&#30340;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#30340;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#21487;&#20197;&#25552;&#20379;&#36827;&#19968;&#27493;&#25581;&#31034;&#29992;&#25143;&#25628;&#32034;&#24847;&#22270;&#30340;&#32447;&#32034;&#12290;&#24471;&#30410;&#20110;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#34892;&#20026;&#22686;&#24378;&#30456;&#20851;&#23398;&#20064;&#27169;&#22411;&#30340;&#25903;&#20184;&#23453;&#25628;&#32034;&#27169;&#22411;&#65288;BARL-ASe&#65289;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#30446;&#26631;&#39033;&#30446;&#30340;&#30456;&#37051;&#26597;&#35810;&#21644;&#30446;&#26631;&#26597;&#35810;&#30340;&#30456;&#37051;&#39033;&#30446;&#26469;&#34917;&#20805;&#30446;&#26631;&#26597;&#35810;-&#39033;&#30446;&#30340;&#35821;&#20041;&#21305;&#37197;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#24314;&#31435;&#20102;&#22810;&#23618;&#20849;&#21516;&#27880;&#24847;&#21147;&#65292;&#20174;&#30456;&#37051;&#21644;&#30446;&#26631;&#35270;&#22270;&#20013;&#25552;&#21462;&#20102;&#31895;&#31890;&#24230;&#21644;&#32454;&#31890;&#24230;&#30340;&#35821;&#20041;&#34920;&#31034;&#12290;&#27169;&#22411;&#38543;&#21518;&#37319;&#29992;&#37051;&#23621;-&#30446;&#26631;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#26469;&#25552;&#39640;&#31934;&#24230;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;KAR&#26694;&#26550;&#65292;&#23427;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#33719;&#21462;&#20004;&#31181;&#31867;&#22411;&#30340;&#22806;&#37096;&#30693;&#35782;&#65292;&#20998;&#21035;&#26159;&#29992;&#25143;&#20559;&#22909;&#30340;&#25512;&#29702;&#30693;&#35782;&#21644;&#39033;&#30446;&#30340;&#20107;&#23454;&#30693;&#35782;&#12290;&#36890;&#36807;&#28151;&#21512;&#19987;&#23478;&#36866;&#37197;&#22120;&#23558;&#25512;&#29702;&#21644;&#20107;&#23454;&#30693;&#35782;&#36716;&#25442;&#20026;&#22686;&#24378;&#21521;&#37327;&#65292;&#20197;&#20415;&#19982;&#29616;&#26377;&#30340;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;&#20860;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.10933</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#25918;&#19990;&#30028;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models. (arXiv:2306.10933v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;KAR&#26694;&#26550;&#65292;&#23427;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#33719;&#21462;&#20004;&#31181;&#31867;&#22411;&#30340;&#22806;&#37096;&#30693;&#35782;&#65292;&#20998;&#21035;&#26159;&#29992;&#25143;&#20559;&#22909;&#30340;&#25512;&#29702;&#30693;&#35782;&#21644;&#39033;&#30446;&#30340;&#20107;&#23454;&#30693;&#35782;&#12290;&#36890;&#36807;&#28151;&#21512;&#19987;&#23478;&#36866;&#37197;&#22120;&#23558;&#25512;&#29702;&#21644;&#20107;&#23454;&#30693;&#35782;&#36716;&#25442;&#20026;&#22686;&#24378;&#21521;&#37327;&#65292;&#20197;&#20415;&#19982;&#29616;&#26377;&#30340;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21508;&#31181;&#22312;&#32447;&#26381;&#21153;&#20013;&#37117;&#25198;&#28436;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#35282;&#33394;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#22312;&#29305;&#23450;&#39046;&#22495;&#20869;&#36827;&#34892;&#35757;&#32451;&#21644;&#37096;&#32626;&#30340;&#23553;&#38381;&#24615;&#38480;&#21046;&#20102;&#23427;&#20204;&#35775;&#38382;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#20986;&#29616;&#22312;&#32534;&#30721;&#24191;&#27867;&#30340;&#19990;&#30028;&#30693;&#35782;&#21644;&#23637;&#31034;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#24076;&#26395;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#30452;&#25509;&#20351;&#29992;LLM&#20316;&#20026;&#25512;&#33616;&#20154;&#20043;&#21069;&#30340;&#23581;&#35797;&#24182;&#27809;&#26377;&#21462;&#24471;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#22686;&#24378;&#25512;&#33616;&#26694;&#26550;(KAR)&#65292;&#20197;&#20174;LLM&#33719;&#21462;&#20004;&#31181;&#31867;&#22411;&#30340;&#22806;&#37096;&#30693;&#35782;--&#29992;&#25143;&#20559;&#22909;&#30340;&#25512;&#29702;&#30693;&#35782;&#21644;&#39033;&#30446;&#30340;&#20107;&#23454;&#30693;&#35782;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#22240;&#23376;&#20998;&#35299;&#25552;&#31034;&#26469;&#24341;&#23548;&#23545;&#29992;&#25143;&#21916;&#22909;&#30340;&#20934;&#30830;&#25512;&#29702;&#12290;&#29983;&#25104;&#30340;&#25512;&#29702;&#21644;&#20107;&#23454;&#30693;&#35782;&#36890;&#36807;&#28151;&#21512;&#19987;&#23478;&#36866;&#37197;&#22120;&#26377;&#25928;&#22320;&#36716;&#25442;&#24182;&#21387;&#32553;&#20026;&#22686;&#24378;&#21521;&#37327;&#65292;&#20197;&#20415;&#19982;&#29616;&#26377;&#30340;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems play a vital role in various online services. However, the insulated nature of training and deploying separately within a specific domain limits their access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capability. Nevertheless, previous attempts to directly use LLMs as recommenders have not achieved satisfactory results. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs -- the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#22235;&#20010;&#27969;&#34892;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#30340;&#21487;&#39564;&#35777;&#24615;&#65292;&#21457;&#29616;&#29616;&#26377;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#21709;&#24212;&#27969;&#30021;&#20294;&#20165;&#26377;51.5%&#30340;&#29983;&#25104;&#21477;&#23376;&#24471;&#21040;&#20102;&#23436;&#25972;&#30340;&#24341;&#29992;&#25903;&#25345;&#65292;&#20165;&#26377;74.5%&#30340;&#24341;&#29992;&#25903;&#25345;&#20854;&#30456;&#20851;&#35821;&#21477;&#12290;</title><link>http://arxiv.org/abs/2304.09848</link><description>&lt;p&gt;
&#35780;&#20272;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#21487;&#39564;&#35777;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating Verifiability in Generative Search Engines. (arXiv:2304.09848v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#22235;&#20010;&#27969;&#34892;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#30340;&#21487;&#39564;&#35777;&#24615;&#65292;&#21457;&#29616;&#29616;&#26377;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#21709;&#24212;&#27969;&#30021;&#20294;&#20165;&#26377;51.5%&#30340;&#29983;&#25104;&#21477;&#23376;&#24471;&#21040;&#20102;&#23436;&#25972;&#30340;&#24341;&#29992;&#25903;&#25345;&#65292;&#20165;&#26377;74.5%&#30340;&#24341;&#29992;&#25903;&#25345;&#20854;&#30456;&#20851;&#35821;&#21477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#30452;&#25509;&#20026;&#29992;&#25143;&#26597;&#35810;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#25552;&#20379;&#20869;&#32852;&#24341;&#29992;&#12290;&#19968;&#20010;&#20540;&#24471;&#20449;&#36182;&#30340;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#30340;&#20808;&#20915;&#26465;&#20214;&#26159;&#21487;&#39564;&#35777;&#24615;&#65292;&#21363;&#31995;&#32479;&#24212;&#20840;&#38754;&#24341;&#29992;&#65288;&#39640;&#24341;&#29992;&#22238;&#24518;&#29575;&#65292;&#25152;&#26377;&#35821;&#21477;&#37117;&#26377;&#23436;&#25972;&#30340;&#24341;&#29992;&#25903;&#25345;&#65289;&#21644;&#20934;&#30830;&#65288;&#39640;&#24341;&#29992;&#31934;&#24230;&#65292;&#27599;&#20010;&#24341;&#29992;&#37117;&#25903;&#25345;&#20854;&#30456;&#20851;&#35821;&#21477;&#65289;&#12290;&#25105;&#20204;&#23545;&#22235;&#20010;&#27969;&#34892;&#30340;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#8212;&#8212;Bing Chat&#12289;NeevaAI&#12289;perplexity.ai&#21644;YouChat&#8212;&#8212;&#36827;&#34892;&#20102;&#20154;&#31867;&#35780;&#20272;&#65292;&#28085;&#30422;&#20102;&#21508;&#31181;&#26469;&#28304;&#30340;&#22810;&#26679;&#21270;&#26597;&#35810;&#65288;&#20363;&#22914;&#21382;&#21490;&#19978;&#30340;Google&#29992;&#25143;&#26597;&#35810;&#12289;Reddit&#19978;&#21160;&#24577;&#25910;&#38598;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#31561;&#65289;&#12290;&#25105;&#20204;&#21457;&#29616;&#29616;&#26377;&#30340;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#21709;&#24212;&#27969;&#30021;&#19988;&#20449;&#24687;&#20016;&#23500;&#65292;&#20294;&#24120;&#24120;&#21253;&#21547;&#19981;&#25903;&#25345;&#30340;&#35821;&#21477;&#21644;&#19981;&#20934;&#30830;&#30340;&#24341;&#29992;&#65306;&#24179;&#22343;&#32780;&#35328;&#65292;&#20165;&#26377;51.5%&#30340;&#29983;&#25104;&#21477;&#23376;&#24471;&#21040;&#20102;&#23436;&#25972;&#30340;&#24341;&#29992;&#25903;&#25345;&#65292;&#21482;&#26377;74.5%&#30340;&#24341;&#29992;&#25903;&#25345;&#20854;&#30456;&#20851;&#35821;&#21477;&#12290;&#25105;&#20204;&#35748;&#20026;...
&lt;/p&gt;
&lt;p&gt;
Generative search engines directly generate responses to user queries, along with in-line citations. A prerequisite trait of a trustworthy generative search engine is verifiability, i.e., systems should cite comprehensively (high citation recall; all statements are fully supported by citations) and accurately (high citation precision; every cite supports its associated statement). We conduct human evaluation to audit four popular generative search engines -- Bing Chat, NeevaAI, perplexity.ai, and YouChat -- across a diverse set of queries from a variety of sources (e.g., historical Google user queries, dynamically-collected open-ended questions on Reddit, etc.). We find that responses from existing generative search engines are fluent and appear informative, but frequently contain unsupported statements and inaccurate citations: on average, a mere 51.5% of generated sentences are fully supported by citations and only 74.5% of citations support their associated sentence. We believe that
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20869;&#23481;&#30340;&#28145;&#23618;&#29983;&#25104;&#27169;&#22411;&#25628;&#32034;&#20219;&#21153;&#65292;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#36873;&#25321;&#29983;&#25104;&#19982;&#26597;&#35810;&#26368;&#30456;&#20284;&#20869;&#23481;&#27010;&#29575;&#26368;&#39640;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#26597;&#35810;&#27169;&#24577;&#30340;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#12290;&#65288;&#32763;&#35793;&#20026;&#20013;&#25991;&#65289;</title><link>http://arxiv.org/abs/2210.03116</link><description>&lt;p&gt;
&#22522;&#20110;&#20869;&#23481;&#30340;&#28145;&#23618;&#29983;&#25104;&#27169;&#22411;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Content-Based Search for Deep Generative Models. (arXiv:2210.03116v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.03116
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20869;&#23481;&#30340;&#28145;&#23618;&#29983;&#25104;&#27169;&#22411;&#25628;&#32034;&#20219;&#21153;&#65292;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#36873;&#25321;&#29983;&#25104;&#19982;&#26597;&#35810;&#26368;&#30456;&#20284;&#20869;&#23481;&#27010;&#29575;&#26368;&#39640;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#26597;&#35810;&#27169;&#24577;&#30340;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#12290;&#65288;&#32763;&#35793;&#20026;&#20013;&#25991;&#65289;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#23450;&#20041;&#21644;&#39044;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#30340;&#19981;&#26029;&#22686;&#21152;&#20351;&#24471;&#29992;&#25143;&#19981;&#21487;&#33021;&#23436;&#20840;&#20102;&#35299;&#27599;&#20010;&#23384;&#22312;&#30340;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20869;&#23481;&#30340;&#27169;&#22411;&#25628;&#32034;&#20219;&#21153;&#65306;&#32473;&#23450;&#19968;&#20010;&#26597;&#35810;&#21644;&#19968;&#32452;&#22823;&#35268;&#27169;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#25214;&#21040;&#19982;&#26597;&#35810;&#26368;&#21305;&#37197;&#30340;&#27169;&#22411;&#12290;&#30001;&#20110;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#20135;&#29983;&#19968;&#31995;&#21015;&#22270;&#20687;&#30340;&#20998;&#24067;&#65292;&#25105;&#20204;&#23558;&#25628;&#32034;&#20219;&#21153;&#20316;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#36873;&#25321;&#29983;&#25104;&#19982;&#26597;&#35810;&#30456;&#20284;&#20869;&#23481;&#27010;&#29575;&#26368;&#39640;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#36817;&#20284;&#35745;&#31639;&#27010;&#29575;&#30340;&#20844;&#24335;&#65292;&#21487;&#20197;&#26681;&#25454;&#19981;&#21516;&#30340;&#26597;&#35810;&#27169;&#24577;&#65288;&#20363;&#22914;&#22270;&#20687;&#12289;&#33609;&#22270;&#21644;&#25991;&#26412;&#65289;&#26469;&#35745;&#31639;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#27169;&#22411;&#26816;&#32034;&#30340;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23398;&#20064;&#36866;&#24212;&#19981;&#21516;&#26597;&#35810;&#27169;&#24577;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29983;&#25104;&#27169;&#22411;&#21160;&#29289;&#22253;&#65288;Generative Model Zoo&#65289;&#19978;&#20248;&#20110;&#20960;&#20010;&#22522;&#20934;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The growing proliferation of customized and pretrained generative models has made it infeasible for a user to be fully cognizant of every model in existence. To address this need, we introduce the task of content-based model search: given a query and a large set of generative models, finding the models that best match the query. As each generative model produces a distribution of images, we formulate the search task as an optimization problem to select the model with the highest probability of generating similar content as the query. We introduce a formulation to approximate this probability given the query from different modalities, e.g., image, sketch, and text. Furthermore, we propose a contrastive learning framework for model retrieval, which learns to adapt features for various query modalities. We demonstrate that our method outperforms several baselines on Generative Model Zoo, a new benchmark we create for the model retrieval task.
&lt;/p&gt;</description></item></channel></rss>