<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>HiPrompt&#26159;&#19968;&#20010;&#30417;&#30563;&#25928;&#29575;&#39640;&#30340;&#30693;&#35782;&#34701;&#21512;&#26694;&#26550;&#65292;&#36890;&#36807;&#23618;&#27425;&#23548;&#21521;&#25552;&#31034;&#21644;&#23569;&#26679;&#26412;&#25512;&#29702;&#33021;&#21147;&#65292;&#24357;&#34917;&#20102;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#34701;&#21512;&#21644;&#31070;&#32463;&#23884;&#20837;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2304.05973</link><description>&lt;p&gt;
HiPrompt: &#23618;&#27425;&#23548;&#21521;&#25552;&#31034;&#30340;&#23569;&#26679;&#26412;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#34701;&#21512;
&lt;/p&gt;
&lt;p&gt;
HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting. (arXiv:2304.05973v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05973
&lt;/p&gt;
&lt;p&gt;
HiPrompt&#26159;&#19968;&#20010;&#30417;&#30563;&#25928;&#29575;&#39640;&#30340;&#30693;&#35782;&#34701;&#21512;&#26694;&#26550;&#65292;&#36890;&#36807;&#23618;&#27425;&#23548;&#21521;&#25552;&#31034;&#21644;&#23569;&#26679;&#26412;&#25512;&#29702;&#33021;&#21147;&#65292;&#24357;&#34917;&#20102;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#34701;&#21512;&#21644;&#31070;&#32463;&#23884;&#20837;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32508;&#21512;&#30340;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#24211;&#21487;&#20197;&#22686;&#24378;&#21307;&#23398;&#20915;&#31574;&#36807;&#31243;&#65292;&#38656;&#35201;&#36890;&#36807;&#32479;&#19968;&#30340;&#32034;&#24341;&#31995;&#32479;&#34701;&#21512;&#26469;&#33258;&#19981;&#21516;&#26469;&#28304;&#30340;&#30693;&#35782;&#22270;&#35889;&#12290;&#32034;&#24341;&#31995;&#32479;&#36890;&#24120;&#20197;&#23618;&#27425;&#32467;&#26500;&#32452;&#32455;&#29983;&#29289;&#21307;&#23398;&#26415;&#35821;&#65292;&#20197;&#25552;&#20379;&#32454;&#31890;&#24230;&#30340;&#23545;&#40784;&#23454;&#20307;&#12290;&#20026;&#20102;&#35299;&#20915;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#34701;&#21512; (BKF) &#20219;&#21153;&#20013;&#30417;&#30563;&#19981;&#36275;&#30340;&#25361;&#25112;&#65292;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#21508;&#31181;&#26080;&#30417;&#30563;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#29305;&#23450;&#30340;&#35789;&#27719;&#21644;&#32467;&#26500;&#21305;&#37197;&#31639;&#27861;&#65292;&#26080;&#27861;&#25429;&#25417;&#29983;&#29289;&#21307;&#23398;&#23454;&#20307;&#21644;&#26415;&#35821;&#25152;&#20256;&#36798;&#30340;&#20016;&#23500;&#35821;&#20041;&#12290;&#26368;&#36817;&#65292;&#31070;&#32463;&#23884;&#20837;&#27169;&#22411;&#22312;&#35821;&#20041;&#20016;&#23500;&#30340;&#20219;&#21153;&#20013;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#20805;&#36275;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#20805;&#20998;&#35757;&#32451;&#12290;&#20026;&#20102;&#24357;&#34917;&#31232;&#32570;&#26631;&#35760; BKF &#21644;&#31070;&#32463;&#23884;&#20837;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; HiPrompt&#65292;&#19968;&#20010;&#30417;&#30563;&#25928;&#29575;&#39640;&#30340;&#30693;&#35782;&#34701;&#21512;&#26694;&#26550;&#65292;&#21487;&#20197;&#24341;&#21457;&#22823;&#35268;&#27169;&#35821;&#20041;&#25512;&#29702;&#30340;&#23569;&#26679;&#26412;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Medical decision-making processes can be enhanced by comprehensive biomedical knowledge bases, which require fusing knowledge graphs constructed from different sources via a uniform index system. The index system often organizes biomedical terms in a hierarchy to provide the aligned entities with fine-grained granularity. To address the challenge of scarce supervision in the biomedical knowledge fusion (BKF) task, researchers have proposed various unsupervised methods. However, these methods heavily rely on ad-hoc lexical and structural matching algorithms, which fail to capture the rich semantics conveyed by biomedical entities and terms. Recently, neural embedding models have proved effective in semantic-rich tasks, but they rely on sufficient labeled data to be adequately trained. To bridge the gap between the scarce-labeled BKF and neural embedding models, we propose HiPrompt, a supervision-efficient knowledge fusion framework that elicits the few-shot reasoning ability of large la
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#26469;&#25512;&#26029;&#21160;&#24577;&#26631;&#31614;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#40065;&#26834;&#24615;&#21644;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#30456;&#23545;&#20110;&#38745;&#24577;&#26631;&#31614;&#32593;&#32476;&#65292;&#23545;&#25968;&#25454;&#30340;&#35757;&#32451;&#38656;&#27714;&#36739;&#23569;&#12290;</title><link>http://arxiv.org/abs/2304.05894</link><description>&lt;p&gt;
&#24102;&#26435;&#26631;&#31614;&#32593;&#32476;&#30340;&#21160;&#24577;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Dynamic Mixed Membership Stochastic Block Model for Weighted Labeled Networks. (arXiv:2304.05894v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#26469;&#25512;&#26029;&#21160;&#24577;&#26631;&#31614;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#40065;&#26834;&#24615;&#21644;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#30456;&#23545;&#20110;&#38745;&#24577;&#26631;&#31614;&#32593;&#32476;&#65292;&#23545;&#25968;&#25454;&#30340;&#35757;&#32451;&#38656;&#27714;&#36739;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#23454;&#20013;&#30340;&#32593;&#32476;&#37117;&#26159;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#12290;&#29616;&#26377;&#30340;&#21160;&#24577;&#32593;&#32476;&#27169;&#22411;&#35201;&#20040;&#27809;&#26377;&#26631;&#31614;&#65292;&#35201;&#20040;&#20551;&#23450;&#21482;&#26377;&#19968;&#20010;&#25104;&#21592;&#32467;&#26500;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;MMSBM&#65289;&#23478;&#26063;&#20801;&#35768;&#22312;&#28151;&#21512;&#25104;&#21592;&#32858;&#31867;&#30340;&#20551;&#35774;&#19979;&#27169;&#25311;&#38745;&#24577;&#26631;&#31614;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#36825;&#31181;&#27169;&#22411;&#25193;&#23637;&#21040;&#22312;&#28151;&#21512;&#25104;&#21592;&#20551;&#35774;&#19979;&#25512;&#26029;&#21160;&#24577;&#26631;&#31614;&#32593;&#32476;&#30340;&#27169;&#22411;&#31867;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#27169;&#22411;&#21442;&#25968;&#30340;&#26102;&#38388;&#20808;&#39564;&#24418;&#24335;&#65292;&#24182;&#20381;&#36182;&#20110;&#21160;&#21147;&#23398;&#19981;&#26159;&#31361;&#28982;&#30340;&#21333;&#19968;&#20551;&#35774;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#29616;&#26377;&#26041;&#27861;&#26174;&#33879;&#19981;&#21516;&#65292;&#24182;&#19988;&#21487;&#20197;&#27169;&#25311;&#26356;&#22797;&#26434;&#30340;&#31995;&#32479;&#8212;&#8212;&#21160;&#24577;&#26631;&#35760;&#32593;&#32476;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20960;&#20010;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#20248;&#21183;&#26159;&#65292;&#23427;&#21482;&#38656;&#35201;&#24456;&#23569;&#30340;&#35757;&#32451;&#25968;&#25454;&#23601;&#33021;&#20135;&#29983;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;&#19982;&#38745;&#24577;&#26631;&#31614;&#32593;&#32476;&#30456;&#27604;&#65292;&#25105;&#20204;&#26041;&#27861;&#22312;&#21160;&#24577;&#26631;&#31614;&#32593;&#32476;&#19979;&#30340;&#24615;&#33021;&#25552;&#21319;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most real-world networks evolve over time. Existing literature proposes models for dynamic networks that are either unlabeled or assumed to have a single membership structure. On the other hand, a new family of Mixed Membership Stochastic Block Models (MMSBM) allows to model static labeled networks under the assumption of mixed-membership clustering. In this work, we propose to extend this later class of models to infer dynamic labeled networks under a mixed membership assumption. Our approach takes the form of a temporal prior on the model's parameters. It relies on the single assumption that dynamics are not abrupt. We show that our method significantly differs from existing approaches, and allows to model more complex systems --dynamic labeled networks. We demonstrate the robustness of our method with several experiments on both synthetic and real-world datasets. A key interest of our approach is that it needs very few training data to yield good results. The performance gain under 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36793;&#32536;&#20113;&#21327;&#20316;&#30693;&#35782;&#36716;&#31227;&#26694;&#26550;&#65288;ECCT&#65289;&#65292;&#20351;&#24471;&#20849;&#20139;&#29305;&#24449;&#23884;&#20837;&#21644;&#39044;&#27979;&#26085;&#24535;&#30340;&#21452;&#21521;&#30693;&#35782;&#20256;&#36755;&#25104;&#20026;&#21487;&#33021;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#22686;&#24378;&#12289;&#27169;&#22411;&#30340;&#24322;&#26500;&#24615;&#12289;&#23481;&#24525;&#35757;&#32451;&#30340;&#24322;&#27493;&#24615;&#21644;&#32531;&#35299;&#36890;&#20449;&#36127;&#25285;&#30340;&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.05871</link><description>&lt;p&gt;
&#24102;&#26377;&#32852;&#37030;&#21644;&#38598;&#20013;&#29305;&#24449;&#30340;&#36793;&#32536;&#20113;&#21327;&#20316;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Edge-cloud Collaborative Learning with Federated and Centralized Features. (arXiv:2304.05871v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36793;&#32536;&#20113;&#21327;&#20316;&#30693;&#35782;&#36716;&#31227;&#26694;&#26550;&#65288;ECCT&#65289;&#65292;&#20351;&#24471;&#20849;&#20139;&#29305;&#24449;&#23884;&#20837;&#21644;&#39044;&#27979;&#26085;&#24535;&#30340;&#21452;&#21521;&#30693;&#35782;&#20256;&#36755;&#25104;&#20026;&#21487;&#33021;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#22686;&#24378;&#12289;&#27169;&#22411;&#30340;&#24322;&#26500;&#24615;&#12289;&#23481;&#24525;&#35757;&#32451;&#30340;&#24322;&#27493;&#24615;&#21644;&#32531;&#35299;&#36890;&#20449;&#36127;&#25285;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#21463;&#27426;&#36814;&#30340;&#36793;&#32536;&#35745;&#31639;&#26041;&#24335;&#65292;&#19981;&#20250;&#21361;&#21450;&#29992;&#25143;&#30340;&#38544;&#31169;&#12290;&#30446;&#21069;&#30340;FL&#33539;&#20363;&#20551;&#23450;&#25968;&#25454;&#20165;&#39547;&#30041;&#22312;&#36793;&#32536;&#65292;&#32780;&#20113;&#26381;&#21153;&#22120;&#20165;&#25191;&#34892;&#27169;&#22411;&#24179;&#22343;&#12290;&#20294;&#26159;&#65292;&#22312;&#35832;&#22914;&#25512;&#33616;&#31995;&#32479;&#20043;&#31867;&#30340;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#20113;&#26381;&#21153;&#22120;&#20855;&#26377;&#23384;&#20648;&#21382;&#21490;&#21644;&#20132;&#20114;&#29305;&#24449;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#30340;Edge-Cloud Collaborative Knowledge Transfer Framework&#65288;ECCT&#65289;&#24357;&#21512;&#20102;&#36793;&#32536;&#21644;&#20113;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#20004;&#32773;&#20043;&#38388;&#36827;&#34892;&#21452;&#21521;&#30693;&#35782;&#20256;&#36755;&#65292;&#20849;&#20139;&#29305;&#24449;&#23884;&#20837;&#21644;&#39044;&#27979;&#26085;&#24535;&#12290; ECCT&#24041;&#22266;&#20102;&#21508;&#31181;&#22909;&#22788;&#65292;&#21253;&#25324;&#22686;&#24378;&#20010;&#24615;&#21270;&#65292;&#23454;&#29616;&#27169;&#22411;&#24322;&#26500;&#24615;&#65292;&#23481;&#24525;&#22521;&#35757;&#24322;&#27493;&#24615;&#21644;&#32531;&#35299;&#36890;&#20449;&#36127;&#25285;&#12290;&#23545;&#20844;&#20849;&#21644;&#24037;&#19994;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;ECCT&#30340;&#26377;&#25928;&#24615;&#21644;&#23398;&#26415;&#21644;&#24037;&#19994;&#20351;&#29992;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) is a popular way of edge computing that doesn't compromise users' privacy. Current FL paradigms assume that data only resides on the edge, while cloud servers only perform model averaging. However, in real-life situations such as recommender systems, the cloud server has the ability to store historical and interactive features. In this paper, our proposed Edge-Cloud Collaborative Knowledge Transfer Framework (ECCT) bridges the gap between the edge and cloud, enabling bi-directional knowledge transfer between both, sharing feature embeddings and prediction logits. ECCT consolidates various benefits, including enhancing personalization, enabling model heterogeneity, tolerating training asynchronization, and relieving communication burdens. Extensive experiments on public and industrial datasets demonstrate ECCT's effectiveness and potential for use in academia and industry.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;DESMIL&#65292;&#19968;&#20010;&#26032;&#30340;&#22810;&#20852;&#36259;&#32593;&#32476;&#65292;&#29992;&#20110;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#20013;&#35299;&#20915;&#36328;&#39046;&#22495;&#27867;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#21435;&#30456;&#20851;&#25552;&#21462;&#30340;&#22810;&#20010;&#20852;&#36259;&#21521;&#37327;&#65292;&#28040;&#38500;&#34394;&#20551;&#30456;&#20851;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.05615</link><description>&lt;p&gt;
&#22810;&#20852;&#36259;&#28145;&#24230;&#31283;&#23450;&#23398;&#20064;&#29992;&#20110;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Deep Stable Multi-Interest Learning for Out-of-distribution Sequential Recommendation. (arXiv:2304.05615v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05615
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;DESMIL&#65292;&#19968;&#20010;&#26032;&#30340;&#22810;&#20852;&#36259;&#32593;&#32476;&#65292;&#29992;&#20110;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#20013;&#35299;&#20915;&#36328;&#39046;&#22495;&#27867;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#21435;&#30456;&#20851;&#25552;&#21462;&#30340;&#22810;&#20010;&#20852;&#36259;&#21521;&#37327;&#65292;&#28040;&#38500;&#34394;&#20551;&#30456;&#20851;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22810;&#21033;&#30410;&#27169;&#22411;&#34987;&#29992;&#20316;&#25552;&#21462;&#29992;&#25143;&#22810;&#20010;&#34920;&#31034;&#21521;&#37327;&#30340;&#20852;&#36259;&#65292; &#23545;&#20110;&#24207;&#21015;&#25512;&#33616;&#34920;&#29616;&#33391;&#22909;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23384;&#22312;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#27169;&#22411;&#37117;&#27809;&#26377;&#32771;&#34385;&#20852;&#36259;&#20998;&#24067;&#21487;&#33021;&#25913;&#21464;&#24102;&#26469;&#30340;&#36328;&#39046;&#22495;&#27867;&#21270;&#38382;&#39064;&#12290;&#32771;&#34385;&#21040;&#29992;&#25143;&#22810;&#20010;&#20852;&#36259;&#36890;&#24120;&#39640;&#24230;&#30456;&#20851;&#65292;&#27169;&#22411;&#26377;&#26426;&#20250;&#23398;&#20064;&#21040;&#22024;&#26434;&#20852;&#36259;&#21644;&#30446;&#26631;&#39033;&#20043;&#38388;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#65292;&#20852;&#36259;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20063;&#20250;&#21457;&#29983;&#21464;&#21270;&#65292;&#34394;&#20551;&#30456;&#20851;&#24615;&#20250;&#35823;&#23548;&#27169;&#22411;&#36827;&#34892;&#38169;&#35823;&#39044;&#27979;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#36328;&#39046;&#22495;&#27867;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#21033;&#30410;&#32593;&#32476;&#65292;&#21517;&#20026;DESMIL&#65292;&#35813;&#32593;&#32476;&#35797;&#22270;&#22312;&#27169;&#22411;&#20013;&#21435;&#30456;&#20851;&#25552;&#21462;&#30340;&#21033;&#30410;&#65292;&#20174;&#32780;&#21487;&#20197;&#28040;&#38500;&#34394;&#20551;&#30340;&#30456;&#20851;&#24615;&#12290;DESMIL&#24212;&#29992;&#19968;&#20010;&#27880;&#24847;&#21147;&#27169;&#22359;&#26469;&#25552;&#21462;&#22810;&#20010;&#21033;&#30410;&#65292;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#32534;&#30721;&#22120;&#26469;&#23545;&#23427;&#20204;&#36827;&#34892;&#32534;&#30721;&#65292;&#19968;&#20010;&#21435;&#30456;&#20851;&#27169;&#22359;&#26469;&#21435;&#38500;&#30456;&#20851;&#24615;&#12290;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;DESMIL&#22312;in-distribution&#21644;out-of-distribution&#26041;&#38754;&#37117;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, multi-interest models, which extract interests of a user as multiple representation vectors, have shown promising performances for sequential recommendation. However, none of existing multi-interest recommendation models consider the Out-Of-Distribution (OOD) generalization problem, in which interest distribution may change. Considering multiple interests of a user are usually highly correlated, the model has chance to learn spurious correlations between noisy interests and target items. Once the data distribution changes, the correlations among interests may also change, and the spurious correlations will mislead the model to make wrong predictions. To tackle with above OOD generalization problem, we propose a novel multi-interest network, named DEep Stable Multi-Interest Learning (DESMIL), which attempts to de-correlate the extracted interests in the model, and thus spurious correlations can be eliminated. DESMIL applies an attentive module to extract multiple interests, an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#8220;Law Stack Exchange&#8221;&#32593;&#31449;&#30340;&#27861;&#24459;&#20449;&#24687;&#26816;&#32034;&#25968;&#25454;&#38598; FALQU&#65292;&#21253;&#21547;&#30495;&#23454;&#19990;&#30028;&#29992;&#25143;&#30340;&#22810;&#39046;&#22495;&#20449;&#24687;&#38656;&#27714;&#65292;&#26159;&#24403;&#21069;&#39318;&#20010;&#20351;&#29992; LawSE &#25968;&#25454;&#30340;&#27979;&#35797;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.05611</link><description>&lt;p&gt;
FALQU: &#23547;&#25214;&#27861;&#24459;&#38382;&#39064;&#31572;&#26696;
&lt;/p&gt;
&lt;p&gt;
FALQU: Finding Answers to Legal Questions. (arXiv:2304.05611v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#8220;Law Stack Exchange&#8221;&#32593;&#31449;&#30340;&#27861;&#24459;&#20449;&#24687;&#26816;&#32034;&#25968;&#25454;&#38598; FALQU&#65292;&#21253;&#21547;&#30495;&#23454;&#19990;&#30028;&#29992;&#25143;&#30340;&#22810;&#39046;&#22495;&#20449;&#24687;&#38656;&#27714;&#65292;&#26159;&#24403;&#21069;&#39318;&#20010;&#20351;&#29992; LawSE &#25968;&#25454;&#30340;&#27979;&#35797;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#27861;&#24459;&#20449;&#24687;&#26816;&#32034;&#25968;&#25454;&#38598; - FALQU&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#25324;&#20102;&#26469;&#33258;&#8220;Law Stack Exchange&#8221;&#38382;&#31572;&#32593;&#31449;&#30340;&#27861;&#24459;&#38382;&#39064;&#21644;&#31572;&#26696;&#65292;&#28041;&#21450;&#29256;&#26435;&#12289;&#30693;&#35782;&#20135;&#26435;&#12289;&#21009;&#27861;&#31561;&#22810;&#20010;&#39046;&#22495;&#65292;&#25968;&#25454;&#30340;&#22810;&#26679;&#24615;&#20195;&#34920;&#20102;&#30495;&#23454;&#19990;&#30028;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new test collection for Legal IR, FALQU: Finding Answers to Legal Questions, where questions and answers were obtained from Law Stack Exchange (LawSE), a Q&amp;A website for legal professionals, and others with experience in law. Much in line with Stack overflow, Law Stack Exchange has a variety of questions on different topics such as copyright, intellectual property, and criminal laws, making it an interesting source for dataset construction. Questions are also not limited to one country. Often, users of different nationalities may ask questions about laws in different countries and expertise. Therefore, questions in FALQU represent real-world users' information needs thus helping to avoid lab-generated questions. Answers on the other side are given by experts in the field. FALQU is the first test collection, to the best of our knowledge, to use LawSE, considering more diverse questions than the questions from the standard legal bar and judicial exams. It contains 9
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#32423;&#32852;&#25351;&#23548;&#19979;&#30340;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#65292;&#22686;&#24378;&#20102;&#20018;&#32852;&#25512;&#33616;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#65292;&#21462;&#24471;&#20102;&#27604;&#24050;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.05492</link><description>&lt;p&gt;
&#25913;&#36827;&#20018;&#32852;&#25512;&#33616;&#30340;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;: &#20276;&#38543;&#32423;&#32852;&#25351;&#23548;&#30340;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards More Robust and Accurate Sequential Recommendation with Cascade-guided Adversarial Training. (arXiv:2304.05492v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05492
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#32423;&#32852;&#25351;&#23548;&#19979;&#30340;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#65292;&#22686;&#24378;&#20102;&#20018;&#32852;&#25512;&#33616;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#65292;&#21462;&#24471;&#20102;&#27604;&#24050;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20018;&#32852;&#25512;&#33616;&#27169;&#22411;&#26159;&#19968;&#31181;&#36890;&#36807;&#23398;&#20064;&#29992;&#25143;&#19982;&#29289;&#21697;&#38388;&#30340;&#26102;&#38388;&#39034;&#24207;&#20114;&#21160;&#26469;&#36827;&#34892;&#25512;&#33616;&#30340;&#27169;&#22411;&#65292;&#20854;&#24050;&#32463;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#23637;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#36817;&#26399;&#20018;&#32852;&#25512;&#33616;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#22791;&#21463;&#36136;&#30097;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#20004;&#20010;&#29305;&#24615;&#20351;&#20854;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987; - &#22312;&#35757;&#32451;&#20013;&#20250;&#20135;&#29983;&#32423;&#32852;&#25928;&#24212;&#65292;&#22312;&#27169;&#22411;&#36807;&#24230;&#20381;&#36182;&#26102;&#38388;&#20449;&#24687;&#30340;&#21516;&#26102;&#20250;&#24573;&#30053;&#20854;&#20182;&#29305;&#24449;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20018;&#32852;&#25512;&#33616;&#27169;&#22411;&#30340;&#32423;&#32852;&#25351;&#23548;&#19979;&#30340;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20018;&#32852;&#24314;&#27169;&#20013;&#30340;&#20869;&#22312;&#32423;&#32852;&#25928;&#24212;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20135;&#29983;&#25112;&#30053;&#24615;&#30340;&#23545;&#25239;&#24615;&#25200;&#21160;&#26469;&#24433;&#21709;&#29289;&#21697;&#23884;&#20837;&#12290;&#22312;&#20351;&#29992;&#19981;&#21516;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#35757;&#32451;&#22235;&#31181;&#26368;&#20808;&#36827;&#30340;&#20018;&#32852;&#27169;&#22411;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#35757;&#32451;&#26041;&#27861;&#20135;&#29983;&#20102;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#30340;&#27169;&#22411;&#40065;&#26834;&#24615;&#65292;&#24182;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation models, models that learn from chronological user-item interactions, outperform traditional recommendation models in many settings. Despite the success of sequential recommendation models, their robustness has recently come into question. Two properties unique to the nature of sequential recommendation models may impair their robustness - the cascade effects induced during training and the model's tendency to rely too heavily on temporal information. To address these vulnerabilities, we propose Cascade-guided Adversarial training, a new adversarial training procedure that is specifically designed for sequential recommendation models. Our approach harnesses the intrinsic cascade effects present in sequential modeling to produce strategic adversarial perturbations to item embeddings during training. Experiments on training state-of-the-art sequential models on four public datasets from different domains show that our training approach produces superior model ran
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#35302;&#21457;&#30340;&#24322;&#26500;&#22270;&#32593;&#32476;&#30340;&#20004;&#38454;&#27573;&#21463;&#20247;&#25193;&#23637;&#26041;&#26696;&#65292;&#21487;&#20197;&#32771;&#34385;&#19981;&#21516;&#30340;&#21452;&#38754;&#20132;&#20114;&#21644;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2304.05474</link><description>&lt;p&gt;
&#22522;&#20110;&#36793;&#35302;&#21457;&#24322;&#26500;&#22270;&#32593;&#32476;&#30340;&#22810;&#33410;&#30446;&#21457;&#34892;&#30340;&#21463;&#20247;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Audience Expansion for Multi-show Release Based on an Edge-prompted Heterogeneous Graph Network. (arXiv:2304.05474v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#35302;&#21457;&#30340;&#24322;&#26500;&#22270;&#32593;&#32476;&#30340;&#20004;&#38454;&#27573;&#21463;&#20247;&#25193;&#23637;&#26041;&#26696;&#65292;&#21487;&#20197;&#32771;&#34385;&#19981;&#21516;&#30340;&#21452;&#38754;&#20132;&#20114;&#21644;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35270;&#39057;&#24179;&#21488;&#19978;&#65292;&#38024;&#23545;&#26032;&#33410;&#30446;&#36827;&#34892;&#21463;&#20247;&#23450;&#20301;&#21644;&#25193;&#23637;&#30340;&#20851;&#38190;&#22312;&#20110;&#22914;&#20309;&#29983;&#25104;&#23427;&#20204;&#30340;&#23884;&#20837;&#12290;&#24212;&#35813;&#20174;&#29992;&#25143;&#21644;&#33410;&#30446;&#30340;&#35282;&#24230;&#36827;&#34892;&#20010;&#24615;&#21270;&#22788;&#29702;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#36861;&#27714;&#21363;&#26102;&#65288;&#28857;&#20987;&#65289;&#21644;&#38271;&#26399;&#65288;&#35266;&#30475;&#26102;&#38388;&#65289;&#22870;&#21169;&#65292;&#20197;&#21450;&#26032;&#33410;&#30446;&#30340;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#24102;&#26469;&#20102;&#39069;&#22806;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#38382;&#39064;&#36866;&#21512;&#36890;&#36807;&#24322;&#26500;&#22270;&#27169;&#22411;&#36827;&#34892;&#22788;&#29702;&#65292;&#22240;&#20026;&#25968;&#25454;&#20855;&#26377;&#33258;&#28982;&#30340;&#22270;&#32467;&#26500;&#12290;&#20294;&#26159;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#32593;&#32476;&#36890;&#24120;&#20855;&#26377;&#25968;&#21313;&#20159;&#20010;&#33410;&#28857;&#21644;&#21508;&#31181;&#31867;&#22411;&#30340;&#36793;&#32536;&#12290;&#24456;&#23569;&#26377;&#29616;&#26377;&#26041;&#27861;&#19987;&#27880;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#24182;&#21033;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#36793;&#32536;&#65292;&#29305;&#21035;&#26159;&#21518;&#32773;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#35302;&#21457;&#30340;&#24322;&#26500;&#22270;&#32593;&#32476;&#30340;&#20004;&#38454;&#27573;&#21463;&#20247;&#25193;&#23637;&#26041;&#26696;&#65292;&#21487;&#20197;&#32771;&#34385;&#19981;&#21516;&#30340;&#21452;&#38754;&#20132;&#20114;&#21644;&#29305;&#24449;&#12290;&#22312;&#31163;&#32447;&#38454;&#27573;&#65292;&#36873;&#25321;&#29992;&#25143;ID&#21644;&#26174;&#31034;&#22120;&#30340;&#29305;&#23450;&#36793;&#32536;&#20449;&#24687;&#32452;&#21512;&#26469;&#26500;&#24314;&#22270;&#24418;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the user targeting and expanding of new shows on a video platform, the key point is how their embeddings are generated. It's supposed to be personalized from the perspective of both users and shows. Furthermore, the pursue of both instant (click) and long-time (view time) rewards, and the cold-start problem for new shows bring additional challenges. Such a problem is suitable for processing by heterogeneous graph models, because of the natural graph structure of data. But real-world networks usually have billions of nodes and various types of edges. Few existing methods focus on handling large-scale data and exploiting different types of edges, especially the latter. In this paper, we propose a two-stage audience expansion scheme based on an edge-prompted heterogeneous graph network which can take different double-sided interactions and features into account. In the offline stage, to construct the graph, user IDs and specific side information combinations of the shows are chosen to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#39640;&#36136;&#37327;&#39184;&#21381;&#35780;&#35770;&#29983;&#25104;&#34394;&#20551;&#35780;&#35770;&#24182;&#24494;&#35843;GPT&#36755;&#20986;&#26816;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#39044;&#27979;&#34394;&#20551;&#35780;&#35770;&#30340;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#39044;&#27979;&#38750;&#31934;&#33521;&#35780;&#35770;&#30340;&#27169;&#22411;&#65292;&#24182;&#22312;&#20960;&#20010;&#32500;&#24230;&#19978;&#23545;&#36825;&#20123;&#35780;&#35770;&#36827;&#34892;&#20998;&#26512;&#65292;&#27492;&#31867;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#26159;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#38754;&#20020;&#30340;&#25345;&#32493;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2302.07731</link><description>&lt;p&gt;
AI&#23545;&#25239;AI&#65306;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#25171;&#20987;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#39184;&#21381;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#39640;&#36136;&#37327;&#39184;&#21381;&#35780;&#35770;&#29983;&#25104;&#34394;&#20551;&#35780;&#35770;&#24182;&#24494;&#35843;GPT&#36755;&#20986;&#26816;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#39044;&#27979;&#34394;&#20551;&#35780;&#35770;&#30340;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#39044;&#27979;&#38750;&#31934;&#33521;&#35780;&#35770;&#30340;&#27169;&#22411;&#65292;&#24182;&#22312;&#20960;&#20010;&#32500;&#24230;&#19978;&#23545;&#36825;&#20123;&#35780;&#35770;&#36827;&#34892;&#20998;&#26512;&#65292;&#27492;&#31867;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#26159;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#38754;&#20020;&#30340;&#25345;&#32493;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;GPT&#65289;&#30340;&#21457;&#23637;&#20351;&#24471;&#20197;&#26356;&#20302;&#30340;&#25104;&#26412;&#21046;&#36896;&#20986;&#38590;&#20197;&#21306;&#20998;&#30340;&#34394;&#20551;&#39038;&#23458;&#35780;&#35770;&#65292;&#20174;&#32780;&#23545;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#26816;&#27979;&#36825;&#20123;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#36896;&#25104;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;Yelp&#39564;&#35777;&#30340;&#39640;&#36136;&#37327;&#30340;&#31934;&#33521;&#39184;&#21381;&#35780;&#35770;&#26469;&#29983;&#25104;OpenAI GPT&#35780;&#35770;&#29983;&#25104;&#22120;&#30340;&#34394;&#20551;&#35780;&#35770;&#65292;&#24182;&#26368;&#32456;&#24494;&#35843;GPT&#36755;&#20986;&#26816;&#27979;&#22120;&#26469;&#39044;&#27979;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#34394;&#20551;&#35780;&#35770;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#27169;&#22411;&#24212;&#29992;&#20110;&#39044;&#27979;&#38750;&#31934;&#33521;&#35780;&#35770;&#65292;&#24182;&#22312;&#20960;&#20010;&#32500;&#24230;&#65288;&#22914;&#35780;&#35770;&#12289;&#29992;&#25143;&#21644;&#39184;&#21381;&#29305;&#24449;&#20197;&#21450;&#20889;&#20316;&#39118;&#26684;&#65289;&#19978;&#35782;&#21035;&#27169;&#24335;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#27491;&#22312;&#19981;&#26029;&#38754;&#20020;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#30340;&#25361;&#25112;&#65292;&#23613;&#31649;&#20182;&#20204;&#21487;&#33021;&#23454;&#26045;&#26816;&#27979;&#31995;&#32479;&#20197;&#36807;&#28388;&#20986;&#21487;&#30097;&#30340;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in generative models such as GPT may be used to fabricate indistinguishable fake customer reviews at a much lower cost, thus posing challenges for social media platforms to detect these machine-generated fake reviews. We propose to leverage the high-quality elite restaurant reviews verified by Yelp to generate fake reviews from the OpenAI GPT review creator and ultimately fine-tune a GPT output detector to predict fake reviews that significantly outperform existing solutions. We further apply the model to predict non-elite reviews and identify the patterns across several dimensions, such as review, user and restaurant characteristics, and writing style. We show that social media platforms are continuously challenged by machine-generated fake reviews, although they may implement detection systems to filter out suspicious reviews.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20114;&#30693;&#35782;&#33976;&#39311;&#30340;&#22810;&#27169;&#21305;&#37197;&#24863;&#30693;&#21327;&#21516;&#27880;&#24847;&#21147;&#32593;&#32476;&#29992;&#20110;&#25913;&#36827;&#20551;&#26032;&#38395;&#26816;&#27979;&#65292;&#36890;&#36807;&#22270;&#20687;-&#25991;&#26412;&#21305;&#37197;&#24863;&#30693;&#21327;&#21516;&#26426;&#21046;&#25429;&#33719;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#23545;&#40784;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;&#65292;&#21516;&#26102;&#21033;&#29992;&#20004;&#20010;&#20013;&#24515;&#20998;&#21035;&#20026;&#25991;&#26412;&#21644;&#22270;&#20687;&#30340;&#21327;&#21516;&#27880;&#24847;&#21147;&#32593;&#32476;&#36827;&#34892;&#30456;&#20114;&#30693;&#35782;&#33976;&#39311;&#12290;</title><link>http://arxiv.org/abs/2212.05699</link><description>&lt;p&gt;
&#22522;&#20110;&#30456;&#20114;&#30693;&#35782;&#33976;&#39311;&#30340;&#22810;&#27169;&#21305;&#37197;&#24863;&#30693;&#21327;&#21516;&#27880;&#24847;&#21147;&#32593;&#32476;&#29992;&#20110;&#20551;&#26032;&#38395;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Multimodal Matching-aware Co-attention Networks with Mutual Knowledge Distillation for Fake News Detection. (arXiv:2212.05699v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05699
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20114;&#30693;&#35782;&#33976;&#39311;&#30340;&#22810;&#27169;&#21305;&#37197;&#24863;&#30693;&#21327;&#21516;&#27880;&#24847;&#21147;&#32593;&#32476;&#29992;&#20110;&#25913;&#36827;&#20551;&#26032;&#38395;&#26816;&#27979;&#65292;&#36890;&#36807;&#22270;&#20687;-&#25991;&#26412;&#21305;&#37197;&#24863;&#30693;&#21327;&#21516;&#26426;&#21046;&#25429;&#33719;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#23545;&#40784;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;&#65292;&#21516;&#26102;&#21033;&#29992;&#20004;&#20010;&#20013;&#24515;&#20998;&#21035;&#20026;&#25991;&#26412;&#21644;&#22270;&#20687;&#30340;&#21327;&#21516;&#27880;&#24847;&#21147;&#32593;&#32476;&#36827;&#34892;&#30456;&#20114;&#30693;&#35782;&#33976;&#39311;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20551;&#26032;&#38395;&#24120;&#24120;&#21253;&#21547;&#25991;&#26412;&#21644;&#22270;&#20687;&#31561;&#22810;&#23186;&#20307;&#20449;&#24687;&#26469;&#35823;&#23548;&#35835;&#32773;&#65292;&#20174;&#32780;&#25193;&#22823;&#20854;&#24433;&#21709;&#21147;&#12290;&#30446;&#21069;&#22823;&#22810;&#25968;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#26041;&#27861;&#20351;&#29992;&#21327;&#21516;&#27880;&#24847;&#21147;&#26426;&#21046;&#26469;&#34701;&#21512;&#22810;&#27169;&#24577;&#29305;&#24449;&#32780;&#24573;&#30053;&#20102;&#21327;&#21516;&#27880;&#24847;&#21147;&#20013;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#19968;&#33268;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20114;&#30693;&#35782;&#33976;&#39311;&#30340;&#22810;&#27169;&#21305;&#37197;&#24863;&#30693;&#21327;&#21516;&#27880;&#24847;&#21147;&#32593;&#32476;&#26469;&#25913;&#36827;&#20551;&#26032;&#38395;&#26816;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22270;&#20687;-&#25991;&#26412;&#21305;&#37197;&#24863;&#30693;&#21327;&#21516;&#26426;&#21046;&#65292;&#29992;&#20110;&#25429;&#33719;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#23545;&#40784;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;&#12290;&#22270;&#20687;-&#25991;&#26412;&#21305;&#37197;&#34920;&#31034;&#21487;&#20197;&#36890;&#36807;&#35270;&#35273;&#35821;&#35328;&#39044;&#35757;&#32451;&#27169;&#22411;&#33719;&#24471;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#35774;&#35745;&#30340;&#22270;&#20687;-&#25991;&#26412;&#21305;&#37197;&#24863;&#30693;&#21327;&#21516;&#26426;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#26500;&#24314;&#20004;&#20010;&#20998;&#21035;&#20197;&#25991;&#26412;&#21644;&#22270;&#20687;&#20026;&#20013;&#24515;&#30340;&#21327;&#21516;&#27880;&#24847;&#21147;&#32593;&#32476;&#20197;&#36827;&#34892;&#30456;&#20114;&#30693;&#35782;&#33976;&#39311;&#65292;&#20197;&#25552;&#39640;&#20551;&#26032;&#38395;&#26816;&#27979;&#30340;&#24615;&#33021;&#12290;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65306;
&lt;/p&gt;
&lt;p&gt;
Fake news often involves multimedia information such as text and image to mislead readers, proliferating and expanding its influence. Most existing fake news detection methods apply the co-attention mechanism to fuse multimodal features while ignoring the consistency of image and text in co-attention. In this paper, we propose multimodal matching-aware co-attention networks with mutual knowledge distillation for improving fake news detection. Specifically, we design an image-text matching-aware co-attention mechanism which captures the alignment of image and text for better multimodal fusion. The image-text matching representation can be obtained via a vision-language pre-trained model. Additionally, based on the designed image-text matching-aware co-attention mechanism, we propose to build two co-attention networks respectively centered on text and image for mutual knowledge distillation to improve fake news detection. Extensive experiments on three benchmark datasets demonstrate that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#26041;&#27861;&#26469;&#35299;&#20915;&#30697;&#38453;&#21644;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#20445;&#30041;&#21333;&#20301;&#27604;&#20363;&#21644;&#19968;&#33268;&#24615;&#20004;&#20010;&#32422;&#26463;&#26465;&#20214;&#21487;&#20197;&#23454;&#29616;&#35299;&#30340;&#23384;&#22312;&#24615;&#19982;&#21807;&#19968;&#24615;&#12290;</title><link>http://arxiv.org/abs/2204.01815</link><description>&lt;p&gt;
&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#19968;&#33268;&#24615;&#21644;&#20844;&#24179;&#20445;&#35777;&#30340;&#25512;&#33616;&#31995;&#32479;&#24352;&#37327;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Tensor Completion with Provable Consistency and Fairness Guarantees for Recommender Systems. (arXiv:2204.01815v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.01815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#26041;&#27861;&#26469;&#35299;&#20915;&#30697;&#38453;&#21644;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#20445;&#30041;&#21333;&#20301;&#27604;&#20363;&#21644;&#19968;&#33268;&#24615;&#20004;&#20010;&#32422;&#26463;&#26465;&#20214;&#21487;&#20197;&#23454;&#29616;&#35299;&#30340;&#23384;&#22312;&#24615;&#19982;&#21807;&#19968;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#19968;&#33268;&#24615;&#30340;&#26041;&#27861;&#26469;&#23450;&#20041;&#21644;&#35299;&#20915;&#38750;&#36127;/&#27491;&#30697;&#38453;&#21644;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#30340;&#26032;&#39062;&#20043;&#22788;&#22312;&#20110;&#65292;&#25105;&#20204;&#19981;&#26159;&#20154;&#20026;&#22320;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#20219;&#24847;&#20248;&#21270;&#38382;&#39064;&#65292;&#20363;&#22914;&#65292;&#26368;&#23567;&#21270;&#19968;&#20010;&#32467;&#26500;&#37327;&#65292;&#22914;&#31209;&#25110;&#33539;&#25968;&#65292;&#32780;&#26159;&#23637;&#31034;&#20102;&#19968;&#20010;&#21333;&#19968;&#30340;&#23646;&#24615;/&#32422;&#26463;&#65306;&#20445;&#30041;&#21333;&#20301;&#27604;&#20363;&#19968;&#33268;&#24615;&#65292;&#20445;&#35777;&#20102;&#35299;&#30340;&#23384;&#22312;&#65292;&#24182;&#22312;&#30456;&#23545;&#36739;&#24369;&#30340;&#25903;&#25345;&#20551;&#35774;&#19979;&#20445;&#35777;&#20102;&#35299;&#30340;&#21807;&#19968;&#24615;&#12290;&#35813;&#26694;&#26550;&#21644;&#35299;&#31639;&#27861;&#20063;&#30452;&#25509;&#25512;&#24191;&#21040;&#20219;&#24847;&#32500;&#24230;&#30340;&#24352;&#37327;&#20013;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#22266;&#23450;&#32500;&#24230; d &#30340;&#38382;&#39064;&#35268;&#27169;&#30340;&#32447;&#24615;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#22312;&#25512;&#33616;&#31995;&#32479;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20004;&#20010;&#21512;&#29702;&#30340;&#24615;&#36136;&#65292;&#36825;&#20123;&#24615;&#36136;&#24212;&#35813;&#36866;&#29992;&#20110;&#20219;&#20309; RS &#38382;&#39064;&#30340;&#35299;&#65292;&#36275;&#20197;&#20801;&#35768;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20869;&#24314;&#31435;&#21807;&#19968;&#24615;&#20445;&#35777;&#12290;&#20851;&#38190;&#29702;&#35770;&#36129;&#29486;&#26159;&#23637;&#31034;&#20102;&#36825;&#20123;&#32422;&#26463;&#19979;&#35299;&#30340;&#23384;&#22312;&#24615;&#19982;&#21807;&#19968;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new consistency-based approach for defining and solving nonnegative/positive matrix and tensor completion problems. The novelty of the framework is that instead of artificially making the problem well-posed in the form of an application-arbitrary optimization problem, e.g., minimizing a bulk structural measure such as rank or norm, we show that a single property/constraint: preserving unit-scale consistency, guarantees the existence of both a solution and, under relatively weak support assumptions, uniqueness. The framework and solution algorithms also generalize directly to tensors of arbitrary dimensions while maintaining computational complexity that is linear in problem size for fixed dimension d. In the context of recommender system (RS) applications, we prove that two reasonable properties that should be expected to hold for any solution to the RS problem are sufficient to permit uniqueness guarantees to be established within our framework. Key theoretical contribu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35780;&#35770;&#25991;&#26412;&#26469;&#36827;&#34892;&#39046;&#22495;&#35299;&#32544;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#19977;&#20010;&#25991;&#26412;&#20998;&#26512;&#27169;&#22359;&#65292;&#30001;&#21333;&#19968;&#39046;&#22495;&#21028;&#21035;&#22120;&#25351;&#24341;&#65292;&#24182;&#37319;&#29992;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#39046;&#22495;&#35299;&#32544;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#25193;&#23637;&#20102;&#32534;&#30721;&#32593;&#32476;&#20174;&#21333;&#20010;&#39046;&#22495;&#21040;&#22810;&#20010;&#39046;&#22495;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#12289;&#31283;&#20581;&#21644;&#21487;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2110.12648</link><description>&lt;p&gt;
&#26080;&#37325;&#22797;&#29992;&#25143;&#25110;&#19978;&#19979;&#25991;&#30340;&#22522;&#20110;&#35780;&#35770;&#30340;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#39046;&#22495;&#35299;&#32544;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Review-Based Domain Disentanglement without Duplicate Users or Contexts for Cross-Domain Recommendation. (arXiv:2110.12648v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.12648
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35780;&#35770;&#25991;&#26412;&#26469;&#36827;&#34892;&#39046;&#22495;&#35299;&#32544;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#19977;&#20010;&#25991;&#26412;&#20998;&#26512;&#27169;&#22359;&#65292;&#30001;&#21333;&#19968;&#39046;&#22495;&#21028;&#21035;&#22120;&#25351;&#24341;&#65292;&#24182;&#37319;&#29992;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#39046;&#22495;&#35299;&#32544;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#25193;&#23637;&#20102;&#32534;&#30721;&#32593;&#32476;&#20174;&#21333;&#20010;&#39046;&#22495;&#21040;&#22810;&#20010;&#39046;&#22495;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#12289;&#31283;&#20581;&#21644;&#21487;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#25512;&#33616;&#22312;&#35299;&#20915;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#29616;&#26377;&#26041;&#27861;&#20165;&#19987;&#27880;&#20110;&#39046;&#22495;&#21487;&#20849;&#20139;&#20449;&#24687;&#65288;&#37325;&#21472;&#29992;&#25143;&#25110;&#30456;&#21516;&#30340;&#19978;&#19979;&#25991;&#65289;&#29992;&#20110;&#30693;&#35782;&#36716;&#31227;&#65292;&#24182;&#19988;&#27809;&#26377;&#36825;&#26679;&#30340;&#35201;&#27714;&#23601;&#24456;&#38590;&#36827;&#34892;&#33391;&#22909;&#30340;&#27867;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#35758;&#21033;&#29992;&#23545;&#22823;&#22810;&#25968;&#30005;&#23376;&#21830;&#21153;&#31995;&#32479;&#36890;&#29992;&#30340;&#35780;&#35770;&#25991;&#26412;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#65288;&#21517;&#20026;SER&#65289;&#20351;&#29992;&#19977;&#20010;&#25991;&#26412;&#20998;&#26512;&#27169;&#22359;&#65292;&#30001;&#21333;&#19968;&#39046;&#22495;&#21028;&#21035;&#22120;&#25351;&#23548;&#36827;&#34892;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#31574;&#30053;&#65292;&#21487;&#20197;&#25552;&#39640;&#39046;&#22495;&#35299;&#32544;&#30340;&#36136;&#37327;&#65292;&#24182;&#21066;&#24369;&#28304;&#39046;&#22495;&#30340;&#19981;&#33391;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#32534;&#30721;&#32593;&#32476;&#20174;&#21333;&#20010;&#39046;&#22495;&#25193;&#23637;&#21040;&#22810;&#20010;&#39046;&#22495;&#65292;&#36825;&#24050;&#34987;&#35777;&#26126;&#23545;&#20110;&#22522;&#20110;&#35780;&#35770;&#30340;&#25512;&#33616;&#31995;&#32479;&#38750;&#24120;&#24378;&#22823;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#21644;&#28040;&#34701;&#30740;&#31350;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#39640;&#25928;&#12289;&#31283;&#20581;&#19988;&#21487;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
A cross-domain recommendation has shown promising results in solving data-sparsity and cold-start problems. Despite such progress, existing methods focus on domain-shareable information (overlapped users or same contexts) for a knowledge transfer, and they fail to generalize well without such requirements. To deal with these problems, we suggest utilizing review texts that are general to most e-commerce systems. Our model (named SER) uses three text analysis modules, guided by a single domain discriminator for disentangled representation learning. Here, we suggest a novel optimization strategy that can enhance the quality of domain disentanglement, and also debilitates detrimental information of a source domain. Also, we extend the encoding network from a single to multiple domains, which has proven to be powerful for review-based recommender systems. Extensive experiments and ablation studies demonstrate that our method is efficient, robust, and scalable compared to the state-of-the-a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25991;&#26412;&#34920;&#31034;&#32858;&#31867;&#26041;&#27861;Vec2GC&#65292;&#23558;&#32858;&#31867;&#31639;&#27861;&#19982;&#22522;&#20110;&#25991;&#26412;&#34920;&#31034;&#23398;&#20064;&#21019;&#24314;&#30340;&#26415;&#35821;&#25110;&#25991;&#26723;&#21152;&#26435;&#22270;&#30340;&#31038;&#21306;&#26816;&#27979;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#29992;&#20110;&#26080;&#30417;&#30563;&#30340;&#25991;&#26723;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2104.09439</link><description>&lt;p&gt;
Vec2GC -- &#22522;&#20110;&#22270;&#30340;&#25991;&#26412;&#34920;&#31034;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Vec2GC -- A Graph Based Clustering Method for Text Representations. (arXiv:2104.09439v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.09439
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25991;&#26412;&#34920;&#31034;&#32858;&#31867;&#26041;&#27861;Vec2GC&#65292;&#23558;&#32858;&#31867;&#31639;&#27861;&#19982;&#22522;&#20110;&#25991;&#26412;&#34920;&#31034;&#23398;&#20064;&#21019;&#24314;&#30340;&#26415;&#35821;&#25110;&#25991;&#26723;&#21152;&#26435;&#22270;&#30340;&#31038;&#21306;&#26816;&#27979;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#29992;&#20110;&#26080;&#30417;&#30563;&#30340;&#25991;&#26723;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26377;&#38480;&#25110;&#27809;&#26377;&#26631;&#31614;&#25968;&#25454;&#30340;NLP&#27969;&#27700;&#32447;&#20013;&#65292;&#38656;&#35201;&#20381;&#36182;&#26080;&#30417;&#30563;&#26041;&#27861;&#36827;&#34892;&#25991;&#26723;&#22788;&#29702;&#12290;&#26080;&#30417;&#30563;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#26415;&#35821;&#25110;&#25991;&#26723;&#30340;&#32858;&#31867;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;Vec2GC (Vector to Graph Communities)&#65292;&#23427;&#26159;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#27969;&#27700;&#32447;&#65292;&#21487;&#20197;&#38024;&#23545;&#20219;&#20309;&#32473;&#23450;&#30340;&#25991;&#26412;&#35821;&#26009;&#24211;&#32858;&#31867;&#26415;&#35821;&#25110;&#25991;&#26723;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#25991;&#26412;&#34920;&#31034;&#23398;&#20064;&#21019;&#24314;&#30340;&#26415;&#35821;&#25110;&#25991;&#26723;&#21152;&#26435;&#22270;&#30340;&#31038;&#21306;&#26816;&#27979;&#12290;Vec2GC&#32858;&#31867;&#31639;&#27861;&#26159;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#25903;&#25345;&#23618;&#27425;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
NLP pipelines with limited or no labeled data, rely on unsupervised methods for document processing. Unsupervised approaches typically depend on clustering of terms or documents. In this paper, we introduce a novel clustering algorithm, Vec2GC (Vector to Graph Communities), an end-to-end pipeline to cluster terms or documents for any given text corpus. Our method uses community detection on a weighted graph of the terms or documents, created using text representation learning. Vec2GC clustering algorithm is a density based approach, that supports hierarchical clustering as well.
&lt;/p&gt;</description></item></channel></rss>