<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#22270;&#35889;&#24341;&#23548;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#25991;&#26723;&#38382;&#31572;&#20219;&#21153;&#20013;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25552;&#31034;&#27491;&#30830;&#30340;&#19978;&#19979;&#25991;&#12290;&#36890;&#36807;&#26500;&#24314;&#22810;&#20010;&#25991;&#26723;&#19978;&#30340;&#30693;&#35782;&#22270;&#35889;&#65292;&#24182;&#35774;&#35745;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#36941;&#21382;&#22120;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#24110;&#21161;LLMs&#22312;MD-QA&#20013;&#36827;&#34892;&#31572;&#26696;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.11730</link><description>&lt;p&gt;
&#22810;&#25991;&#26723;&#38382;&#31572;&#20013;&#30340;&#30693;&#35782;&#22270;&#35889;&#24341;&#23548;
&lt;/p&gt;
&lt;p&gt;
Knowledge Graph Prompting for Multi-Document Question Answering. (arXiv:2308.11730v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11730
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#22270;&#35889;&#24341;&#23548;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#25991;&#26723;&#38382;&#31572;&#20219;&#21153;&#20013;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25552;&#31034;&#27491;&#30830;&#30340;&#19978;&#19979;&#25991;&#12290;&#36890;&#36807;&#26500;&#24314;&#22810;&#20010;&#25991;&#26723;&#19978;&#30340;&#30693;&#35782;&#22270;&#35889;&#65292;&#24182;&#35774;&#35745;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#36941;&#21382;&#22120;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#24110;&#21161;LLMs&#22312;MD-QA&#20013;&#36827;&#34892;&#31572;&#26696;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#8220;&#39044;&#35757;&#32451;&#12289;&#25552;&#31034;&#12289;&#39044;&#27979;&#8221;&#33539;&#24335;&#22312;&#24320;&#25918;&#22495;&#38382;&#31572;&#65288;OD-QA&#65289;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#24037;&#20316;&#22312;&#22810;&#25991;&#26723;&#38382;&#31572;&#65288;MD-QA&#65289;&#22330;&#26223;&#19979;&#25506;&#32034;&#36825;&#20010;&#33539;&#24335;&#65292;&#36825;&#26159;&#19968;&#20010;&#35201;&#27714;&#23545;&#19981;&#21516;&#25991;&#26723;&#30340;&#20869;&#23481;&#21644;&#32467;&#26500;&#20043;&#38388;&#30340;&#36923;&#36753;&#20851;&#32852;&#26377;&#28145;&#20837;&#29702;&#35299;&#30340;&#20219;&#21153;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#37325;&#35201;&#30340;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#22270;&#35889;&#24341;&#23548;&#65288;KGP&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;MD-QA&#20013;&#20026;LLMs&#25552;&#31034;&#27491;&#30830;&#30340;&#19978;&#19979;&#25991;&#65292;&#35813;&#26041;&#27861;&#21253;&#25324;&#22270;&#26500;&#24314;&#27169;&#22359;&#21644;&#22270;&#36941;&#21382;&#27169;&#22359;&#12290;&#23545;&#20110;&#22270;&#26500;&#24314;&#65292;&#25105;&#20204;&#20351;&#29992;&#33410;&#28857;&#26469;&#34920;&#31034;&#25991;&#27573;&#25110;&#25991;&#26723;&#32467;&#26500;&#65288;&#20363;&#22914;&#65292;&#39029;&#38754;/&#34920;&#26684;&#65289;&#65292;&#32780;&#20351;&#29992;&#36793;&#26469;&#34920;&#31034;&#25991;&#27573;&#20043;&#38388;&#30340;&#35821;&#20041;/&#35789;&#27719;&#30456;&#20284;&#24615;&#25110;&#32773;&#25991;&#26723;&#20869;&#30340;&#32467;&#26500;&#20851;&#31995;&#12290;&#23545;&#20110;&#22270;&#36941;&#21382;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;LM&#30340;&#22270;&#36941;&#21382;&#22120;&#65292;&#23427;&#22312;&#33410;&#28857;&#20043;&#38388;&#23548;&#33322;&#24182;&#25910;&#38598;&#25903;&#25345;&#24615;&#30340;&#25991;&#27573;&#65292;&#20197;&#24110;&#21161;LLMs&#22312;MD-QA&#20013;&#36827;&#34892;&#31572;&#26696;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
The 'pre-train, prompt, predict' paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in the scenario of multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of different documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or intra-document structural relations. For graph traversal, we design an LM-guided graph traverser that navigates across nodes and gathers supporting passages assisting LLMs in MD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20351;&#20915;&#31574;&#32773;&#21487;&#20197;&#34920;&#36798;&#24179;&#21488;&#34892;&#20026;&#30340;&#38271;&#26399;&#30446;&#26631;&#65292;&#24182;&#36890;&#36807;&#26032;&#30340;&#22522;&#20110;&#25511;&#21046;&#30340;&#31639;&#27861;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#23545;&#30701;&#26399;&#21442;&#19982;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.04923</link><description>&lt;p&gt;
&#24102;&#26377;&#38271;&#26399;&#32422;&#26463;&#30340;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Ranking with Long-Term Constraints. (arXiv:2307.04923v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04923
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20351;&#20915;&#31574;&#32773;&#21487;&#20197;&#34920;&#36798;&#24179;&#21488;&#34892;&#20026;&#30340;&#38271;&#26399;&#30446;&#26631;&#65292;&#24182;&#36890;&#36807;&#26032;&#30340;&#22522;&#20110;&#25511;&#21046;&#30340;&#31639;&#27861;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#23545;&#30701;&#26399;&#21442;&#19982;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#36890;&#36807;&#20182;&#20204;&#30340;&#36873;&#25321;&#21453;&#39304;&#65288;&#20363;&#22914;&#28857;&#20987;&#65292;&#36141;&#20080;&#65289;&#26159;&#20026;&#35757;&#32451;&#25628;&#32034;&#21644;&#25512;&#33616;&#31639;&#27861;&#25552;&#20379;&#30340;&#26368;&#24120;&#35265;&#31867;&#22411;&#30340;&#25968;&#25454;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#20165;&#22522;&#20110;&#36873;&#25321;&#25968;&#25454;&#36827;&#34892;&#30701;&#35270;&#22521;&#35757;&#30340;&#31995;&#32479;&#21487;&#33021;&#20165;&#25913;&#21892;&#30701;&#26399;&#21442;&#19982;&#24230;&#65292;&#32780;&#19981;&#33021;&#25913;&#21892;&#24179;&#21488;&#30340;&#38271;&#26399;&#21487;&#25345;&#32493;&#24615;&#20197;&#21450;&#23545;&#29992;&#25143;&#12289;&#20869;&#23481;&#25552;&#20379;&#32773;&#21644;&#20854;&#20182;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#38271;&#26399;&#21033;&#30410;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#20915;&#31574;&#32773;&#65288;&#20363;&#22914;&#24179;&#21488;&#36816;&#33829;&#21830;&#12289;&#30417;&#31649;&#26426;&#26500;&#12289;&#29992;&#25143;&#65289;&#21487;&#20197;&#34920;&#36798;&#24179;&#21488;&#34892;&#20026;&#30340;&#38271;&#26399;&#30446;&#26631;&#65288;&#20363;&#22914;&#20844;&#24179;&#24615;&#12289;&#25910;&#20837;&#20998;&#37197;&#12289;&#27861;&#24459;&#35201;&#27714;&#65289;&#12290;&#36825;&#20123;&#30446;&#26631;&#37319;&#21462;&#20102;&#36229;&#36234;&#20010;&#20307;&#20250;&#35805;&#30340;&#26333;&#20809;&#25110;&#24433;&#21709;&#30446;&#26631;&#30340;&#24418;&#24335;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#22522;&#20110;&#25511;&#21046;&#30340;&#31639;&#27861;&#26469;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25511;&#21046;&#22120;&#30340;&#35774;&#35745;&#26088;&#22312;&#20197;&#26368;&#23567;&#21270;&#23545;&#30701;&#26399;&#21442;&#19982;&#30340;&#24433;&#21709;&#26469;&#23454;&#29616;&#25152;&#36848;&#30340;&#38271;&#26399;&#30446;&#26631;&#12290;&#38500;&#20102;&#21407;&#21017;&#24615;&#30340;&#29702;&#35770;&#25512;&#23548;&#22806;&#65292;
&lt;/p&gt;
&lt;p&gt;
The feedback that users provide through their choices (e.g., clicks, purchases) is one of the most common types of data readily available for training search and recommendation algorithms. However, myopically training systems based on choice data may only improve short-term engagement, but not the long-term sustainability of the platform and the long-term benefits to its users, content providers, and other stakeholders. In this paper, we thus develop a new framework in which decision makers (e.g., platform operators, regulators, users) can express long-term goals for the behavior of the platform (e.g., fairness, revenue distribution, legal requirements). These goals take the form of exposure or impact targets that go well beyond individual sessions, and we provide new control-based algorithms to achieve these goals. In particular, the controllers are designed to achieve the stated long-term goals with minimum impact on short-term engagement. Beyond the principled theoretical derivation
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#29983;&#25104;&#24335;&#26816;&#32034;&#21644;&#32463;&#20856;&#30340;&#23398;&#20064;&#25490;&#24207;&#33539;&#20363;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27573;&#33853;&#25490;&#24207;&#25439;&#22833;&#26469;&#35757;&#32451;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#30452;&#25509;&#20248;&#21270;&#33258;&#22238;&#24402;&#27169;&#22411;&#26397;&#30528;&#26368;&#20248;&#35299;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2306.15222</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#29983;&#25104;&#24335;&#26816;&#32034;&#20013;&#36827;&#34892;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Learning to Rank in Generative Retrieval. (arXiv:2306.15222v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15222
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#29983;&#25104;&#24335;&#26816;&#32034;&#21644;&#32463;&#20856;&#30340;&#23398;&#20064;&#25490;&#24207;&#33539;&#20363;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27573;&#33853;&#25490;&#24207;&#25439;&#22833;&#26469;&#35757;&#32451;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#30452;&#25509;&#20248;&#21270;&#33258;&#22238;&#24402;&#27169;&#22411;&#26397;&#30528;&#26368;&#20248;&#35299;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#26816;&#32034;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#25991;&#26412;&#26816;&#32034;&#33539;&#20363;&#65292;&#23427;&#23558;&#30456;&#20851;&#27573;&#33853;&#30340;&#26631;&#35782;&#31526;&#23383;&#31526;&#20018;&#29983;&#25104;&#20026;&#26816;&#32034;&#30446;&#26631;&#12290;&#36825;&#31181;&#33539;&#20363;&#21033;&#29992;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#20195;&#34920;&#20102;&#19982;&#20256;&#32479;&#30340;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#26377;&#25152;&#19981;&#21516;&#30340;&#26032;&#33539;&#20363;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20854;&#24555;&#36895;&#21457;&#23637;&#65292;&#24403;&#21069;&#30340;&#29983;&#25104;&#24335;&#26816;&#32034;&#26041;&#27861;&#20173;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#23427;&#20204;&#36890;&#24120;&#20381;&#36182;&#21551;&#21457;&#24335;&#20989;&#25968;&#23558;&#39044;&#27979;&#30340;&#26631;&#35782;&#31526;&#36716;&#25442;&#20026;&#27573;&#33853;&#25490;&#24207;&#21015;&#34920;&#65292;&#36825;&#22312;&#29983;&#25104;&#24335;&#26816;&#32034;&#30340;&#23398;&#20064;&#30446;&#26631;&#19982;&#26399;&#26395;&#30340;&#27573;&#33853;&#25490;&#24207;&#30446;&#26631;&#20043;&#38388;&#20135;&#29983;&#20102;&#24046;&#36317;&#12290;&#27492;&#22806;&#65292;&#25991;&#26412;&#29983;&#25104;&#30340;&#22266;&#26377;&#26333;&#20809;&#20559;&#24046;&#38382;&#39064;&#22312;&#29983;&#25104;&#24335;&#26816;&#32034;&#20013;&#20173;&#28982;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;LTRGR&#65292;&#23427;&#23558;&#29983;&#25104;&#24335;&#26816;&#32034;&#19982;&#32463;&#20856;&#30340;&#23398;&#20064;&#25490;&#24207;&#33539;&#20363;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#27573;&#33853;&#25490;&#24207;&#25439;&#22833;&#35757;&#32451;&#19968;&#20010;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#25439;&#22833;&#30452;&#25509;&#20248;&#21270;&#33258;&#22238;&#24402;&#27169;&#22411;&#26397;&#30528;&#26368;&#20248;&#35299;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative retrieval is a promising new paradigm in text retrieval that generates identifier strings of relevant passages as the retrieval target. This paradigm leverages powerful generation models and represents a new paradigm distinct from traditional learning-to-rank methods. However, despite its rapid development, current generative retrieval methods are still limited. They typically rely on a heuristic function to transform predicted identifiers into a passage rank list, which creates a gap between the learning objective of generative retrieval and the desired passage ranking target. Moreover, the inherent exposure bias problem of text generation also persists in generative retrieval. To address these issues, we propose a novel framework, called LTRGR, that combines generative retrieval with the classical learning-to-rank paradigm. Our approach involves training an autoregressive model using a passage rank loss, which directly optimizes the autoregressive model toward the optimal 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;CTRL&#26694;&#26550;&#65292;&#23558;&#21407;&#22987;&#34920;&#26684;&#25968;&#25454;&#36716;&#25442;&#20026;&#25991;&#26412;&#25968;&#25454;&#65292;&#20351;&#29992;&#21327;&#20316;CTR&#27169;&#22411;&#20998;&#21035;&#23545;&#20004;&#31181;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#65292;&#25552;&#21462;&#20851;&#20110;CTR&#39044;&#27979;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#24182;&#22312;&#30495;&#23454;&#24037;&#19994;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#26368;&#26032;&#30340;SOTA&#24615;&#33021;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2306.02841</link><description>&lt;p&gt;
CTRL: &#36830;&#25509;&#34920;&#26684;&#21644;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;CTR&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
CTRL: Connect Tabular and Language Model for CTR Prediction. (arXiv:2306.02841v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02841
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;CTRL&#26694;&#26550;&#65292;&#23558;&#21407;&#22987;&#34920;&#26684;&#25968;&#25454;&#36716;&#25442;&#20026;&#25991;&#26412;&#25968;&#25454;&#65292;&#20351;&#29992;&#21327;&#20316;CTR&#27169;&#22411;&#20998;&#21035;&#23545;&#20004;&#31181;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#65292;&#25552;&#21462;&#20851;&#20110;CTR&#39044;&#27979;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#24182;&#22312;&#30495;&#23454;&#24037;&#19994;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#26368;&#26032;&#30340;SOTA&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;CTR&#39044;&#27979;&#27169;&#22411;&#23558;&#34920;&#26684;&#25968;&#25454;&#36716;&#25442;&#20026;one-hot&#21521;&#37327;&#65292;&#24182;&#21033;&#29992;&#29305;&#24449;&#20043;&#38388;&#30340;&#21327;&#20316;&#20851;&#31995;&#26469;&#25512;&#26029;&#29992;&#25143;&#23545;&#39033;&#30446;&#30340;&#20559;&#22909;&#12290;&#36825;&#31181;&#24314;&#27169;&#33539;&#24335;&#25243;&#24323;&#20102;&#22522;&#26412;&#30340;&#35821;&#20041;&#20449;&#24687;&#12290;&#23613;&#31649;&#19968;&#20123;&#26368;&#36817;&#30340;&#24037;&#20316;&#65288;&#22914;P5&#21644;M6-Rec&#65289;&#24050;&#32463;&#25506;&#32034;&#20102;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#25552;&#21462;CTR&#39044;&#27979;&#30340;&#35821;&#20041;&#20449;&#21495;&#30340;&#28508;&#21147;&#65292;&#20294;&#23427;&#20204;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#25928;&#29575;&#20302;&#12290;&#27492;&#22806;&#65292;&#23578;&#26410;&#32771;&#34385;&#21040;&#26377;&#30410;&#30340;&#21327;&#20316;&#20851;&#31995;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#25512;&#33616;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;CTRL&#65292;&#23427;&#26159;&#24037;&#19994;&#21451;&#22909;&#30340;&#21644;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#65292;&#20855;&#26377;&#39640;&#35757;&#32451;&#21644;&#25512;&#29702;&#25928;&#29575;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#21407;&#22987;&#30340;&#34920;&#26684;&#25968;&#25454;&#39318;&#20808;&#34987;&#36716;&#25442;&#20026;&#25991;&#26412;&#25968;&#25454;&#12290;&#20004;&#31181;&#19981;&#21516;&#30340;&#27169;&#24577;&#34987;&#20998;&#21035;&#35270;&#20026;&#20004;&#20010;&#27169;&#24577;&#65292;&#24182;&#20998;&#21035;&#36755;&#20837;&#21327;&#20316;CTR&#27169;&#22411;&#20013;&#20197;&#24314;&#27169;&#23427;&#20204;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20449;&#24687;&#33976;&#39311;&#26426;&#21046;&#65292;&#20174;PLMs&#20013;&#25552;&#21462;&#20851;&#20110;CTR&#39044;&#27979;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22312;&#19977;&#20010;&#30495;&#23454;&#30340;&#24037;&#19994;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#27604;&#36739;&#20854;&#20182;&#29616;&#26377;&#30340;&#27169;&#22411;&#26102;&#22343;&#36798;&#21040;&#20102;&#26368;&#26032;&#30340;SOTA&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional click-through rate (CTR) prediction models convert the tabular data into one-hot vectors and leverage the collaborative relations among features for inferring user's preference over items. This modeling paradigm discards the essential semantic information. Though some recent works like P5 and M6-Rec have explored the potential of using Pre-trained Language Models (PLMs) to extract semantic signals for CTR prediction, they are computationally expensive and suffer from low efficiency. Besides, the beneficial collaborative relations are not considered, hindering the recommendation performance. To solve these problems, in this paper, we propose a novel framework \textbf{CTRL}, which is industrial friendly and model-agnostic with high training and inference efficiency. Specifically, the original tabular data is first converted into textual data. Both tabular data and converted textual data are regarded as two different modalities and are separately fed into the collaborative CTR
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#8212;&#8212;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#12290;&#38024;&#23545;&#36825;&#19968;&#20219;&#21153;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#26041;&#26696;&#8212;&#8212;KGEditor&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.10405</link><description>&lt;p&gt;
&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.10405
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#8212;&#8212;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#12290;&#38024;&#23545;&#36825;&#19968;&#20219;&#21153;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#26041;&#26696;&#8212;&#8212;KGEditor&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#23884;&#20837;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;KG&#23884;&#20837;&#36890;&#24120;&#20316;&#20026;&#38745;&#24577;&#24037;&#20214;&#37096;&#32626;&#65292;&#20462;&#25913;&#36215;&#26469;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;KG&#23884;&#20837;&#12290;&#35813;&#20219;&#21153;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#65292;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#22235;&#20010;&#26032;&#25968;&#25454;&#38598;&#65306;E-FB15k237&#12289;A-FB15k237&#12289;E-WN18RR &#21644; A-WN18RR&#65292;&#24182;&#35780;&#20272;&#20102;&#20960;&#31181;&#30693;&#35782;&#32534;&#36753;&#22522;&#32447;&#65292;&#35777;&#26126;&#20102;&#20043;&#21069;&#30340;&#27169;&#22411;&#22788;&#29702;&#35813;&#20219;&#21153;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#24378;&#22823;&#30340;&#22522;&#32447;&#8212;&#8212;KGEditor&#65292;&#23427;&#21033;&#29992;&#36229;&#32593;&#32476;&#30340;&#38468;&#21152;&#21442;&#25968;&#23618;&#26469;&#32534;&#36753;/&#28155;&#21152;&#20107;&#23454;&#12290;&#20840;&#38754;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#26102;&#65292;KGEditor &#30340;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
&lt;/p&gt;</description></item></channel></rss>