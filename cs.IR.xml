<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36328;&#27169;&#24335;&#33402;&#26415;&#23478;&#26816;&#32034;&#20219;&#21153;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#33402;&#26415;&#23478;&#26816;&#32034;&#20934;&#30830;&#24230;&#21644;&#35206;&#30422;&#33539;&#22260;&#26041;&#38754;&#20248;&#20110;&#21333;&#27169;&#24577;&#21644;&#22522;&#20934;&#31639;&#27861;&#65292;&#24182;&#19988;&#23588;&#20854;&#36866;&#29992;&#20110;&#36739;&#19981;&#21463;&#27426;&#36814;&#30340;&#26597;&#35810;&#33402;&#26415;&#23478;&#12290;</title><link>http://arxiv.org/abs/2308.06556</link><description>&lt;p&gt;
&#36328;&#27169;&#24335;&#33402;&#26415;&#23478;&#26816;&#32034;&#30340;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contrastive Learning for Cross-modal Artist Retrieval. (arXiv:2308.06556v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36328;&#27169;&#24335;&#33402;&#26415;&#23478;&#26816;&#32034;&#20219;&#21153;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#33402;&#26415;&#23478;&#26816;&#32034;&#20934;&#30830;&#24230;&#21644;&#35206;&#30422;&#33539;&#22260;&#26041;&#38754;&#20248;&#20110;&#21333;&#27169;&#24577;&#21644;&#22522;&#20934;&#31639;&#27861;&#65292;&#24182;&#19988;&#23588;&#20854;&#36866;&#29992;&#20110;&#36739;&#19981;&#21463;&#27426;&#36814;&#30340;&#26597;&#35810;&#33402;&#26415;&#23478;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#20048;&#26816;&#32034;&#21644;&#25512;&#33616;&#24212;&#29992;&#36890;&#24120;&#20381;&#36182;&#20110;&#20316;&#20026;&#23884;&#20837;&#30340;&#20869;&#23481;&#29305;&#24449;&#65292;&#36825;&#20123;&#29305;&#24449;&#25552;&#20379;&#20102;&#38899;&#20048;&#25968;&#25454;&#38598;&#20013;&#39033;&#30446;&#30340;&#21521;&#37327;&#34920;&#31034;&#12290;&#21487;&#20197;&#20174;&#22788;&#29702;&#21407;&#22987;&#34920;&#31034;&#20026;&#22810;&#31181;&#27169;&#24335;&#30340;&#39033;&#30446;&#20013;&#24471;&#21040;&#20247;&#22810;&#20114;&#34917;&#30340;&#23884;&#20837;&#65292;&#20363;&#22914;&#38899;&#39057;&#20449;&#21495;&#12289;&#29992;&#25143;&#20114;&#21160;&#25968;&#25454;&#25110;&#32534;&#36753;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#20219;&#20309;&#32473;&#23450;&#27169;&#24577;&#30340;&#25968;&#25454;&#21487;&#33021;&#22312;&#38899;&#20048;&#25968;&#25454;&#38598;&#20013;&#30340;&#25152;&#26377;&#39033;&#30446;&#20013;&#37117;&#19981;&#21487;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#32452;&#21512;&#26469;&#33258;&#22810;&#20010;&#27169;&#24577;&#30340;&#23884;&#20837;&#65292;&#24182;&#25506;&#32034;&#22312;&#33402;&#26415;&#23478;&#30456;&#20284;&#24615;&#20219;&#21153;&#20013;&#22810;&#27169;&#24577;&#23884;&#20837;&#30340;&#23384;&#22312;&#19982;&#32570;&#22833;&#30340;&#24433;&#21709;&#12290;&#23545;&#20004;&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#23545;&#27604;&#26041;&#27861;&#22312;&#33402;&#26415;&#23478;&#26816;&#32034;&#20934;&#30830;&#24230;&#21644;&#35206;&#30422;&#33539;&#22260;&#26041;&#38754;&#20248;&#20110;&#21333;&#27169;&#24577;&#23884;&#20837;&#21644;&#22522;&#20934;&#31639;&#27861;&#12290;&#23545;&#20110;&#36739;&#19981;&#21463;&#27426;&#36814;&#30340;&#26597;&#35810;&#33402;&#26415;&#23478;&#65292;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#30340;&#25913;&#36827;&#23588;&#20026;&#26174;&#33879;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Music retrieval and recommendation applications often rely on content features encoded as embeddings, which provide vector representations of items in a music dataset. Numerous complementary embeddings can be derived from processing items originally represented in several modalities, e.g., audio signals, user interaction data, or editorial data. However, data of any given modality might not be available for all items in any music dataset. In this work, we propose a method based on contrastive learning to combine embeddings from multiple modalities and explore the impact of the presence or absence of embeddings from diverse modalities in an artist similarity task. Experiments on two datasets suggest that our contrastive method outperforms single-modality embeddings and baseline algorithms for combining modalities, both in terms of artist retrieval accuracy and coverage. Improvements with respect to other methods are particularly significant for less popular query artists. We demonstrate
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22270;&#35299;&#32544;&#32467;&#30340;&#26041;&#24335;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20107;&#20214;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#20107;&#20214;&#31890;&#24230;&#36807;&#31895;&#21644;&#26080;&#27861;&#20445;&#30041;&#36229;&#20986;&#26412;&#20307;&#20043;&#22806;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.06480</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#35299;&#32544;&#32467;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#20107;&#20214;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Context-aware Event Forecasting via Graph Disentanglement. (arXiv:2308.06480v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06480
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22270;&#35299;&#32544;&#32467;&#30340;&#26041;&#24335;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20107;&#20214;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#20107;&#20214;&#31890;&#24230;&#36807;&#31895;&#21644;&#26080;&#27861;&#20445;&#30041;&#36229;&#20986;&#26412;&#20307;&#20043;&#22806;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20107;&#20214;&#39044;&#27979;&#19968;&#30452;&#26159;&#19968;&#20010;&#33392;&#24040;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22312;&#25972;&#20010;&#20154;&#31867;&#21382;&#21490;&#20013;&#37117;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#12290;&#23427;&#22312;&#21361;&#26426;&#35686;&#25253;&#21644;&#28798;&#23475;&#39044;&#38450;&#31561;&#31038;&#20250;&#21508;&#20010;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#20107;&#20214;&#39044;&#27979;&#30340;&#20219;&#21153;&#26088;&#22312;&#22522;&#20110;&#21382;&#21490;&#20107;&#20214;&#24314;&#27169;&#20851;&#31995;&#21644;&#26102;&#38388;&#27169;&#24335;&#65292;&#24182;&#39044;&#27979;&#26410;&#26469;&#30340;&#21457;&#23637;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#20107;&#20214;&#39044;&#27979;&#30740;&#31350;&#23558;&#20854;&#21046;&#23450;&#20026;&#22522;&#20110;&#26102;&#38388;&#20107;&#20214;&#22270;&#19978;&#30340;&#38142;&#25509;&#39044;&#27979;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#32431;&#32467;&#26500;&#21270;&#30340;&#21046;&#23450;&#26041;&#24335;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38480;&#21046;&#65306;1) &#22823;&#22810;&#25968;&#20107;&#20214;&#23646;&#20110;&#20107;&#20214;&#26412;&#20307;&#35770;&#20013;&#30340;&#19968;&#33324;&#21644;&#39640;&#32423;&#31867;&#22411;&#65292;&#22240;&#27492;&#23427;&#20204;&#20542;&#21521;&#20110;&#31895;&#31890;&#24230;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#23569;&#37327;&#30340;&#23454;&#29992;&#24615;&#65292;&#36825;&#19981;&#21487;&#36991;&#20813;&#22320;&#25439;&#23475;&#20102;&#39044;&#27979;&#20934;&#30830;&#24615;&#65307;2) &#36890;&#36807;&#22266;&#23450;&#26412;&#20307;&#35770;&#23450;&#20041;&#30340;&#20107;&#20214;&#26080;&#27861;&#20445;&#30041;&#36229;&#20986;&#26412;&#20307;&#20043;&#22806;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#20107;&#20214;&#39044;&#27979;&#20219;&#21153;&#65292;&#20854;&#23558;&#36741;&#21161;&#19978;&#19979;&#25991;&#20449;&#24687;&#38598;&#25104;&#36827;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Event forecasting has been a demanding and challenging task throughout the entire human history. It plays a pivotal role in crisis alarming and disaster prevention in various aspects of the whole society. The task of event forecasting aims to model the relational and temporal patterns based on historical events and makes forecasting to what will happen in the future. Most existing studies on event forecasting formulate it as a problem of link prediction on temporal event graphs. However, such pure structured formulation suffers from two main limitations: 1) most events fall into general and high-level types in the event ontology, and therefore they tend to be coarse-grained and offers little utility which inevitably harms the forecasting accuracy; and 2) the events defined by a fixed ontology are unable to retain the out-of-ontology contextual information. To address these limitations, we propose a novel task of context-aware event forecasting which incorporates auxiliary contextual in
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39044;&#27979;&#24320;&#25918;&#39046;&#22495;&#22810;&#36339;&#38382;&#39064;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.06431</link><description>&lt;p&gt;
&#22810;&#36339;&#38382;&#39064;&#30340;&#24615;&#33021;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Performance Prediction for Multi-hop Questions. (arXiv:2308.06431v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06431
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39044;&#27979;&#24320;&#25918;&#39046;&#22495;&#22810;&#36339;&#38382;&#39064;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24320;&#25918;&#39046;&#22495;&#22810;&#36339;&#38382;&#31572;&#65288;QA&#65289;&#20013;&#26597;&#35810;&#24615;&#33021;&#39044;&#27979;&#65288;QPP&#65289;&#30340;&#38382;&#39064;&#65292;&#20219;&#21153;&#26159;&#20272;&#35745;&#23545;&#35821;&#26009;&#24211;&#36827;&#34892;&#22810;&#36339;&#38382;&#39064;&#35780;&#20272;&#30340;&#38590;&#24230;&#12290;&#23613;&#31649;&#22312;&#39044;&#27979;&#21363;&#24109;&#21644;QA&#26816;&#32034;&#27169;&#22411;&#24615;&#33021;&#26041;&#38754;&#24050;&#32463;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#65292;&#20294;&#23545;&#22810;&#36339;&#38382;&#39064;&#38590;&#24230;&#30340;&#35780;&#20272;&#30740;&#31350;&#36824;&#32570;&#20047;&#12290;&#30001;&#20110;&#26816;&#32034;&#36807;&#31243;&#30340;&#22810;&#27493;&#39588;&#24615;&#36136;&#12289;&#27493;&#39588;&#20043;&#38388;&#30340;&#28508;&#22312;&#20381;&#36182;&#20851;&#31995;&#21644;&#25512;&#29702;&#30340;&#22797;&#26434;&#24615;&#65292;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39044;&#26816;&#32034;&#26041;&#27861;multHP&#65292;&#29992;&#20110;&#39044;&#27979;&#24320;&#25918;&#39046;&#22495;&#22810;&#36339;&#38382;&#39064;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23545;&#26368;&#22823;&#30340;&#22810;&#36339;QA&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#65292;&#20351;&#29992;&#20102;&#20960;&#31181;&#29616;&#20195;QA&#31995;&#32479;&#65292;&#32467;&#26524;&#26174;&#31034;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#26159;&#24615;&#33021;&#30340;&#24378;&#26377;&#21147;&#39044;&#27979;&#32773;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#21333;&#36339;QPP&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#29992;&#20110;&#20248;&#21270;QA&#31995;&#32479;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of Query Performance Prediction (QPP) for open-domain multi-hop Question Answering (QA), where the task is to estimate the difficulty of evaluating a multi-hop question over a corpus. Despite the extensive research on predicting the performance of ad-hoc and QA retrieval models, there has been a lack of study on the estimation of the difficulty of multi-hop questions. The problem is challenging due to the multi-step nature of the retrieval process, potential dependency of the steps and the reasoning involved. To tackle this challenge, we propose multHP, a novel pre-retrieval method for predicting the performance of open-domain multi-hop questions. Our extensive evaluation on the largest multi-hop QA dataset using several modern QA systems shows that the proposed model is a strong predictor of the performance, outperforming traditional single-hop QPP models. Additionally, we demonstrate that our approach can be effectively used to optimize the parameters of QA syste
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#36807;&#28388;&#27873;&#38382;&#39064;&#65292;&#36890;&#36807;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#21644;&#27979;&#37327;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#26469;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#30340;&#24847;&#22806;&#24615;&#29289;&#21697;&#12290;</title><link>http://arxiv.org/abs/2308.06368</link><description>&lt;p&gt;
&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#21644;&#24847;&#22806;&#24615;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Topic-Level Bayesian Surprise and Serendipity for Recommender Systems. (arXiv:2308.06368v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#36807;&#28388;&#27873;&#38382;&#39064;&#65292;&#36890;&#36807;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#21644;&#27979;&#37327;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#26469;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#30340;&#24847;&#22806;&#24615;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20248;&#21270;&#20854;&#25512;&#33616;&#20165;&#36866;&#21512;&#29992;&#25143;&#23545;&#24050;&#28040;&#36153;&#29289;&#21697;&#30340;&#35780;&#32423;&#21382;&#21490;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#36807;&#28388;&#27873;&#65292;&#29992;&#25143;&#26080;&#27861;&#20174;&#26032;&#39062;&#12289;&#26410;&#35265;&#36807;&#30340;&#31867;&#21035;&#20013;&#20307;&#39564;&#29289;&#21697;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#24847;&#22806;&#24615;&#24418;&#24335;&#65292;&#20197;&#36125;&#21494;&#26031;&#24778;&#21916;&#20026;&#22522;&#30784;&#65292;&#29992;&#20110;&#27979;&#37327;&#29992;&#25143;&#28040;&#36153;&#24182;&#35780;&#32423;&#21518;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#12290;&#32467;&#21512;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#30340;&#21327;&#21516;&#36807;&#28388;&#32452;&#20214;&#65292;&#21487;&#20197;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#24847;&#22806;&#24615;&#30340;&#29289;&#21697;&#12290;&#20026;&#20102;&#20415;&#20110;&#35780;&#20272;&#20027;&#39064;&#32423;&#21035;&#30340;&#24778;&#21916;&#21644;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#20174;Goodreads&#20013;&#25552;&#21462;&#30340;&#22270;&#20070;&#38405;&#35835;&#21382;&#21490;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#36229;&#36807;26&#21315;&#20010;&#29992;&#25143;&#21644;&#36817;130&#19975;&#26412;&#20070;&#65292;&#24182;&#23545;&#20854;&#20013;&#30340;449&#31687;&#20070;&#36827;&#34892;&#20102;&#25163;&#21160;&#27880;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#21160;&#21270;&#35745;&#31639;&#26041;&#27861;&#30340;&#29356;&#34892;&#20026;&#35780;&#20272;&#26367;&#20195;&#26041;&#26696;&#65292;&#21487;&#20197;&#26356;&#23458;&#35266;&#12289;&#31283;&#20581;&#21644;&#36164;&#28304;&#39640;&#25928;&#22320;&#35780;&#20272;&#29399;&#30340;&#34892;&#20026;&#29305;&#24449;&#12290;&#20351;&#29992;&#37096;&#20998;&#38476;&#29983;&#20154;&#27979;&#35797;&#21327;&#35758;&#65292;&#36890;&#36807;&#23545;53&#21482;&#29399;&#30340;&#27979;&#35797;&#65292;&#25581;&#31034;&#20102;&#20004;&#20010;&#20027;&#35201;&#30340;&#34892;&#20026;&#32858;&#31867;&#12290;</title><link>http://arxiv.org/abs/2308.06269</link><description>&lt;p&gt;
&#25968;&#23383;&#22686;&#24378;&#30340;&#29356;&#34892;&#20026;&#27979;&#35797;&#65306;&#26426;&#22120;&#30340;&#24110;&#21161;
&lt;/p&gt;
&lt;p&gt;
Digitally-Enhanced Dog Behavioral Testing: Getting Help from the Machine. (arXiv:2308.06269v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06269
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#21160;&#21270;&#35745;&#31639;&#26041;&#27861;&#30340;&#29356;&#34892;&#20026;&#35780;&#20272;&#26367;&#20195;&#26041;&#26696;&#65292;&#21487;&#20197;&#26356;&#23458;&#35266;&#12289;&#31283;&#20581;&#21644;&#36164;&#28304;&#39640;&#25928;&#22320;&#35780;&#20272;&#29399;&#30340;&#34892;&#20026;&#29305;&#24449;&#12290;&#20351;&#29992;&#37096;&#20998;&#38476;&#29983;&#20154;&#27979;&#35797;&#21327;&#35758;&#65292;&#36890;&#36807;&#23545;53&#21482;&#29399;&#30340;&#27979;&#35797;&#65292;&#25581;&#31034;&#20102;&#20004;&#20010;&#20027;&#35201;&#30340;&#34892;&#20026;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#23545;&#29399;&#34892;&#20026;&#30740;&#31350;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#20363;&#22914;&#36873;&#32946;&#36873;&#25321;&#12289;&#24037;&#20316;&#36866;&#24212;&#33021;&#21147;&#39044;&#27979;&#12289;&#34987;&#25910;&#20859;&#26426;&#20250;&#31561;&#65292;&#23545;&#29399;&#34892;&#20026;&#29305;&#24449;&#30340;&#35780;&#20272;&#26159;&#19968;&#20010;&#32463;&#36807;&#24191;&#27867;&#30740;&#31350;&#30340;&#25361;&#25112;&#12290;&#30446;&#21069;&#22823;&#22810;&#25968;&#35780;&#20272;&#29399;&#34892;&#20026;&#29305;&#24449;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#38382;&#21367;&#25110;&#35266;&#23519;&#65292;&#38656;&#35201;&#22823;&#37327;&#26102;&#38388;&#12289;&#31934;&#21147;&#21644;&#19987;&#19994;&#30693;&#35782;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#20063;&#23481;&#26131;&#21463;&#21040;&#20027;&#35266;&#24615;&#21644;&#20559;&#35265;&#30340;&#24433;&#21709;&#65292;&#32570;&#20047;&#21487;&#38752;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#21487;&#33021;&#25552;&#20379;&#19968;&#31181;&#26356;&#23458;&#35266;&#12289;&#31283;&#20581;&#21644;&#36164;&#28304;&#39640;&#25928;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#37096;&#20998;&#38476;&#29983;&#20154;&#27979;&#35797;&#21327;&#35758;&#65292;&#23545;53&#21482;&#29399;&#36827;&#34892;&#20102;&#23545;&#38476;&#29983;&#20154;&#20986;&#29616;&#21644;&#33391;&#24615;&#34892;&#20026;&#30340;&#21453;&#24212;&#27979;&#35797;&#12290;&#19977;&#20301;&#19987;&#23478;&#35780;&#20998;&#29399;&#30340;&#24212;&#23545;&#39118;&#26684;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;&#29356;&#34892;&#20026;&#35780;&#20272;&#21644;&#30740;&#31350;&#38382;&#21367;&#65288;C-BARQ&#65289;&#25910;&#38598;&#20102;&#20854;&#22788;&#29702;&#32773;&#30340;&#25968;&#25454;&#12290;&#23545;&#29399;&#30340;&#36712;&#36857;&#36827;&#34892;&#26080;&#30417;&#30563;&#32858;&#31867;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#20004;&#20010;&#20027;&#35201;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
The assessment of behavioral traits in dogs is a well-studied challenge due to its many practical applications such as selection for breeding, prediction of working aptitude, chances of being adopted, etc. Most methods for assessing behavioral traits are questionnaire or observation-based, which require a significant amount of time, effort and expertise. In addition, these methods are also susceptible to subjectivity and bias, making them less reliable. In this study, we proposed an automated computational approach that may provide a more objective, robust and resource-efficient alternative to current solutions. Using part of a Stranger Test protocol, we tested n=53 dogs for their response to the presence and benign actions of a stranger. Dog coping styles were scored by three experts. Moreover, data were collected from their handlers using the Canine Behavioral Assessment and Research Questionnaire (C-BARQ). An unsupervised clustering of the dogs' trajectories revealed two main cluste
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#39046;&#22495;&#25512;&#33616;&#26041;&#27861;EDDA&#65292;&#23427;&#36890;&#36807;&#23884;&#20837;&#35299;&#32806;&#25512;&#33616;&#22120;&#21644;&#39046;&#22495;&#23545;&#40784;&#20004;&#20010;&#20851;&#38190;&#32452;&#20214;&#20998;&#21035;&#35299;&#20915;&#20102;&#30693;&#35782;&#35299;&#32806;&#21644;&#36328;&#39046;&#22495;&#30693;&#35782;&#36716;&#31227;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.05508</link><description>&lt;p&gt;
&#22810;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#23884;&#20837;&#35299;&#32806;&#19982;&#39046;&#22495;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Multi-domain Recommendation with Embedding Disentangling and Domain Alignment. (arXiv:2308.05508v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05508
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#39046;&#22495;&#25512;&#33616;&#26041;&#27861;EDDA&#65292;&#23427;&#36890;&#36807;&#23884;&#20837;&#35299;&#32806;&#25512;&#33616;&#22120;&#21644;&#39046;&#22495;&#23545;&#40784;&#20004;&#20010;&#20851;&#38190;&#32452;&#20214;&#20998;&#21035;&#35299;&#20915;&#20102;&#30693;&#35782;&#35299;&#32806;&#21644;&#36328;&#39046;&#22495;&#30693;&#35782;&#36716;&#31227;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#39046;&#22495;&#25512;&#33616;(MDR)&#26088;&#22312;&#20026;&#20855;&#26377;&#37325;&#21472;&#29992;&#25143;/&#29289;&#21697;&#30340;&#19981;&#21516;&#39046;&#22495;(&#20363;&#22914;&#20135;&#21697;&#31867;&#22411;)&#25552;&#20379;&#25512;&#33616;&#65292;&#23545;&#20110;&#25317;&#26377;&#22810;&#20010;&#26381;&#21153;&#30340;&#24179;&#21488;&#22914;&#20122;&#39532;&#36874;&#12289;Facebook&#21644;LinkedIn&#26159;&#24120;&#35265;&#30340;&#12290;&#29616;&#26377;&#30340;MDR&#27169;&#22411;&#38754;&#20020;&#20004;&#20010;&#25361;&#25112;&#65306;&#39318;&#20808;&#65292;&#24456;&#38590;&#35299;&#32806;&#21487;&#20197;&#27867;&#21270;&#21040;&#25152;&#26377;&#39046;&#22495;&#30340;&#30693;&#35782;(&#20363;&#22914;&#65292;&#29992;&#25143;&#21916;&#27426;&#24265;&#20215;&#30340;&#29289;&#21697;)&#19982;&#29305;&#23450;&#20110;&#21333;&#20010;&#39046;&#22495;&#30340;&#30693;&#35782;(&#20363;&#22914;&#65292;&#29992;&#25143;&#21916;&#27426;&#34013;&#33394;&#30340;&#26381;&#35013;&#20294;&#19981;&#21916;&#27426;&#34013;&#33394;&#30340;&#27773;&#36710;)&#12290;&#20854;&#27425;&#65292;&#23427;&#20204;&#22312;&#20855;&#26377;&#23567;&#37325;&#21472;&#30340;&#39046;&#22495;&#20043;&#38388;&#36716;&#31227;&#30693;&#35782;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EDDA&#30340;&#26032;&#30340;MDR&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#21547;&#20004;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#21363;&#23884;&#20837;&#35299;&#32806;&#25512;&#33616;&#22120;&#21644;&#39046;&#22495;&#23545;&#40784;&#65292;&#20998;&#21035;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#25361;&#25112;&#12290;&#29305;&#21035;&#22320;&#65292;&#23884;&#20837;&#35299;&#32806;&#25512;&#33616;&#22120;&#20998;&#31163;&#20102;&#36328;&#39046;&#22495;&#37096;&#20998;&#21644;&#21333;&#39046;&#22495;&#37096;&#20998;&#30340;&#27169;&#22411;&#21644;&#23884;&#20837;&#65292;&#32780;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;MDR&#26041;&#27861;&#21482;&#20851;&#27880;&#27169;&#22411;&#23618;&#38754;&#30340;&#35299;&#32806;&#12290;&#39046;&#22495;&#23545;&#40784;&#20351;&#29992;&#39046;&#22495;&#29305;&#23450;&#30340;&#23545;&#25239;&#35757;&#32451;&#26469;&#25552;&#21319;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-domain recommendation (MDR) aims to provide recommendations for different domains (e.g., types of products) with overlapping users/items and is common for platforms such as Amazon, Facebook, and LinkedIn that host multiple services. Existing MDR models face two challenges: First, it is difficult to disentangle knowledge that generalizes across domains (e.g., a user likes cheap items) and knowledge specific to a single domain (e.g., a user likes blue clothing but not blue cars). Second, they have limited ability to transfer knowledge across domains with small overlaps. We propose a new MDR method named EDDA with two key components, i.e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively. In particular, the embedding disentangling recommender separates both the model and embedding for the inter-domain part and the intra-domain part, while most existing MDR methods only focus on model-level disentangling. The domain alignment leverag
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#22686;&#24378;&#30340;&#30456;&#20851;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#65292;&#26469;&#25913;&#36827;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;-&#39033;&#30446;&#21305;&#37197;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05379</link><description>&lt;p&gt;
&#36229;&#36234;&#35821;&#20041;&#65306;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#30340;&#34892;&#20026;&#22686;&#24378;&#30456;&#20851;&#27169;&#22411;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning. (arXiv:2308.05379v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05379
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#22686;&#24378;&#30340;&#30456;&#20851;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#65292;&#26469;&#25913;&#36827;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;-&#39033;&#30446;&#21305;&#37197;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#24314;&#27169;&#26088;&#22312;&#23450;&#20301;&#19982;&#23545;&#24212;&#26597;&#35810;&#30456;&#20851;&#30340;&#29702;&#24819;&#39033;&#30446;&#65292;&#36825;&#23545;&#20110;&#25628;&#32034;&#24341;&#25806;&#30830;&#20445;&#29992;&#25143;&#20307;&#39564;&#38750;&#24120;&#37325;&#35201;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#20256;&#32479;&#26041;&#27861;&#36890;&#36807;&#35780;&#20272;&#26597;&#35810;&#19982;&#39033;&#30446;&#20043;&#38388;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#32431;&#35821;&#20041;&#21305;&#37197;&#24182;&#19981;&#26159;&#21807;&#19968;&#30340;&#26041;&#27861;&#12290;&#23454;&#38469;&#19978;&#65292;&#20174;&#29992;&#25143;&#25628;&#32034;&#35760;&#24405;&#30340;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#30340;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#21487;&#20197;&#25552;&#20379;&#36827;&#19968;&#27493;&#25581;&#31034;&#29992;&#25143;&#25628;&#32034;&#24847;&#22270;&#30340;&#32447;&#32034;&#12290;&#24471;&#30410;&#20110;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#34892;&#20026;&#22686;&#24378;&#30456;&#20851;&#23398;&#20064;&#27169;&#22411;&#30340;&#25903;&#20184;&#23453;&#25628;&#32034;&#27169;&#22411;&#65288;BARL-ASe&#65289;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#30446;&#26631;&#39033;&#30446;&#30340;&#30456;&#37051;&#26597;&#35810;&#21644;&#30446;&#26631;&#26597;&#35810;&#30340;&#30456;&#37051;&#39033;&#30446;&#26469;&#34917;&#20805;&#30446;&#26631;&#26597;&#35810;-&#39033;&#30446;&#30340;&#35821;&#20041;&#21305;&#37197;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#24314;&#31435;&#20102;&#22810;&#23618;&#20849;&#21516;&#27880;&#24847;&#21147;&#65292;&#20174;&#30456;&#37051;&#21644;&#30446;&#26631;&#35270;&#22270;&#20013;&#25552;&#21462;&#20102;&#31895;&#31890;&#24230;&#21644;&#32454;&#31890;&#24230;&#30340;&#35821;&#20041;&#34920;&#31034;&#12290;&#27169;&#22411;&#38543;&#21518;&#37319;&#29992;&#37051;&#23621;-&#30446;&#26631;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#26469;&#25552;&#39640;&#31934;&#24230;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robu
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#22810;&#35270;&#22270;&#32858;&#31867;&#30340;&#32479;&#19968;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#23545;&#20110;&#20855;&#26377;&#25968;&#21313;&#20159;&#29992;&#25143;&#21644;&#25968;&#19975;&#20159;&#39033;&#30446;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23454;&#29616;&#23454;&#26102;&#24212;&#29992;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21160;&#24577;&#20002;&#24323;&#19981;&#22909;&#30340;&#32858;&#31867;&#12290;</title><link>http://arxiv.org/abs/2308.04661</link><description>&lt;p&gt;
&#32479;&#19968;&#30697;&#38453;&#20998;&#35299;&#19982;&#21160;&#24577;&#22810;&#35270;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Unified Matrix Factorization with Dynamic Multi-view Clustering. (arXiv:2308.04661v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04661
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#22810;&#35270;&#22270;&#32858;&#31867;&#30340;&#32479;&#19968;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#23545;&#20110;&#20855;&#26377;&#25968;&#21313;&#20159;&#29992;&#25143;&#21644;&#25968;&#19975;&#20159;&#39033;&#30446;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23454;&#29616;&#23454;&#26102;&#24212;&#29992;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21160;&#24577;&#20002;&#24323;&#19981;&#22909;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#20998;&#35299;(MF)&#26159;&#19968;&#31181;&#32463;&#20856;&#30340;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#12290;&#23427;&#23558;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#20998;&#35299;&#20026;&#20302;&#32500;&#29992;&#25143;&#34920;&#31034;&#30697;&#38453;&#21644;&#39033;&#30446;&#34920;&#31034;&#30697;&#38453;&#30340;&#20056;&#31215;&#12290;&#22312;&#20856;&#22411;&#30340;&#25512;&#33616;&#22330;&#26223;&#20013;&#65292;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#27169;&#24335;&#36890;&#24120;&#26159;&#19968;&#20010;&#20004;&#38454;&#27573;&#36807;&#31243;&#65292;&#24182;&#19988;&#38656;&#35201;&#23545;&#33719;&#24471;&#30340;&#29992;&#25143;&#21644;&#39033;&#30446;&#34920;&#31034;&#36827;&#34892;&#38745;&#24577;&#32858;&#31867;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;&#19978;&#36848;&#36807;&#31243;&#38656;&#35201;&#22823;&#37327;&#30340;&#26102;&#38388;&#21644;&#35745;&#31639;&#36164;&#28304;&#65292;&#22240;&#27492;&#24456;&#38590;&#24212;&#29992;&#20110;&#20855;&#26377;&#25968;&#21313;&#20159;&#29992;&#25143;&#21644;&#25968;&#19975;&#20159;&#39033;&#30446;&#30340;&#30005;&#23376;&#21830;&#21153;&#25110;&#29289;&#32852;&#32593;&#29615;&#22659;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#22810;&#35270;&#22270;&#32858;&#31867;(MFDMC)&#30340;&#32479;&#19968;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#37319;&#29992;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#33539;&#24335;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#27599;&#20010;&#35270;&#22270;&#20013;&#65292;&#29992;&#25143;/&#39033;&#30446;&#34920;&#31034;&#34987;&#35270;&#20026;&#25152;&#26377;&#32858;&#31867;&#30340;&#21152;&#26435;&#25237;&#24433;&#12290;&#27599;&#20010;&#32858;&#31867;&#30340;&#34920;&#31034;&#26159;&#21487;&#23398;&#20064;&#30340;&#65292;&#21487;&#20197;&#21160;&#24577;&#20002;&#24323;&#19981;&#22909;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matrix factorization (MF) is a classical collaborative filtering algorithm for recommender systems. It decomposes the user-item interaction matrix into a product of low-dimensional user representation matrix and item representation matrix. In typical recommendation scenarios, the user-item interaction paradigm is usually a two-stage process and requires static clustering analysis of the obtained user and item representations. The above process, however, is time and computationally intensive, making it difficult to apply in real-time to e-commerce or Internet of Things environments with billions of users and trillions of items. To address this, we propose a unified matrix factorization method based on dynamic multi-view clustering (MFDMC) that employs an end-to-end training paradigm. Specifically, in each view, a user/item representation is regarded as a weighted projection of all clusters. The representation of each cluster is learnable, enabling the dynamic discarding of bad clusters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#27169;&#24577;&#39034;&#24207;&#25512;&#33616;&#20013;&#29289;&#21697;&#34920;&#31034;&#23398;&#20064;&#23545;&#25512;&#33616;&#20219;&#21153;&#30340;&#24433;&#21709;&#20197;&#21450;&#19981;&#21516;&#38454;&#27573;&#20449;&#24687;&#34701;&#21512;&#30340;&#24046;&#24322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#21512;&#21327;&#21516;&#23398;&#20064;&#21644;&#34701;&#21512;&#22810;&#26679;&#20449;&#24687;&#30340;&#26032;&#30340;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2308.04067</link><description>&lt;p&gt;
&#22312;&#32447;&#33976;&#39311;&#22686;&#24378;&#30340;&#22810;&#27169;&#24577;&#21464;&#21387;&#22120;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Online Distillation-enhanced Multi-modal Transformer for Sequential Recommendation. (arXiv:2308.04067v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#27169;&#24577;&#39034;&#24207;&#25512;&#33616;&#20013;&#29289;&#21697;&#34920;&#31034;&#23398;&#20064;&#23545;&#25512;&#33616;&#20219;&#21153;&#30340;&#24433;&#21709;&#20197;&#21450;&#19981;&#21516;&#38454;&#27573;&#20449;&#24687;&#34701;&#21512;&#30340;&#24046;&#24322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#21512;&#21327;&#21516;&#23398;&#20064;&#21644;&#34701;&#21512;&#22810;&#26679;&#20449;&#24687;&#30340;&#26032;&#30340;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#25512;&#33616;&#31995;&#32479;&#22312;&#36817;&#24180;&#26469;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;, &#23427;&#25972;&#21512;&#20102;&#21508;&#31181;&#31867;&#22411;&#30340;&#20449;&#24687;&#12290;&#28982;&#32780;,&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#22810;&#27169;&#24577;&#25512;&#33616;&#31995;&#32479;&#30456;&#27604;, &#22810;&#27169;&#24577;&#39034;&#24207;&#25512;&#33616;&#30340;&#30740;&#31350;&#20173;&#22788;&#20110;&#21021;&#32423;&#38454;&#27573;&#12290;&#19981;&#21516;&#20110;&#20165;&#20381;&#36182;&#20110;&#29289;&#21697;&#26631;&#35782;&#31526;&#65288;ID&#65289;&#20449;&#24687;&#24182;&#20851;&#27880;&#32593;&#32476;&#32467;&#26500;&#35774;&#35745;&#30340;&#20256;&#32479;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;, &#22810;&#27169;&#24577;&#25512;&#33616;&#27169;&#22411;&#38656;&#35201;&#24378;&#35843;&#29289;&#21697;&#34920;&#31034;&#23398;&#20064;&#21644;&#24322;&#26500;&#25968;&#25454;&#28304;&#30340;&#34701;&#21512;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#29289;&#21697;&#34920;&#31034;&#23398;&#20064;&#23545;&#19979;&#28216;&#25512;&#33616;&#20219;&#21153;&#30340;&#24433;&#21709;, &#24182;&#26816;&#39564;&#20102;&#19981;&#21516;&#38454;&#27573;&#20449;&#24687;&#34701;&#21512;&#30340;&#24046;&#24322;&#12290;&#36890;&#36807;&#23454;&#35777;&#23454;&#39564;, &#25105;&#20204;&#35777;&#26126;&#20102;&#38656;&#35201;&#35774;&#35745;&#19968;&#20010;&#36866;&#21512;&#21327;&#21516;&#23398;&#20064;&#21644;&#34701;&#21512;&#22810;&#26679;&#20449;&#24687;&#30340;&#26694;&#26550;&#12290;&#22522;&#20110;&#27492;, &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26694;&#26550;&#29992;&#20110;&#22810;&#27169;&#24577;&#39034;&#24207;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-modal recommendation systems, which integrate diverse types of information, have gained widespread attention in recent years. However, compared to traditional collaborative filtering-based multi-modal recommendation systems, research on multi-modal sequential recommendation is still in its nascent stages. Unlike traditional sequential recommendation models that solely rely on item identifier (ID) information and focus on network structure design, multi-modal recommendation models need to emphasize item representation learning and the fusion of heterogeneous data sources. This paper investigates the impact of item representation learning on downstream recommendation tasks and examines the disparities in information fusion at different stages. Empirical experiments are conducted to demonstrate the need to design a framework suitable for collaborative learning and fusion of diverse information. Based on this, we propose a new model-agnostic framework for multi-modal sequential recom
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#24182;&#25552;&#20379;&#35780;&#20272;&#26426;&#21046;&#65292;&#21516;&#26102;&#20063;&#32771;&#34385;&#21040;&#20102;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#26088;&#22312;&#24110;&#21161;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#22522;&#20110;&#21487;&#20449;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2307.15464</link><description>&lt;p&gt;
&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#36136;&#37327;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Framework to Automatically Determine the Quality of Open Data Catalogs. (arXiv:2307.15464v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#24182;&#25552;&#20379;&#35780;&#20272;&#26426;&#21046;&#65292;&#21516;&#26102;&#20063;&#32771;&#34385;&#21040;&#20102;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#26088;&#22312;&#24110;&#21161;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#22522;&#20110;&#21487;&#20449;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#30446;&#24405;&#22312;&#29616;&#20195;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#20419;&#36827;&#21508;&#31181;&#25968;&#25454;&#36164;&#20135;&#30340;&#21457;&#29616;&#12289;&#29702;&#35299;&#21644;&#21033;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#24320;&#25918;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#29615;&#22659;&#20013;&#30830;&#20445;&#20854;&#36136;&#37327;&#21644;&#21487;&#38752;&#24615;&#26159;&#22797;&#26434;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35299;&#20915;&#20102;&#39640;&#25928;&#21644;&#21487;&#38752;&#30340;&#36136;&#37327;&#35780;&#20272;&#26426;&#21046;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#21508;&#31181;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#22914;&#20934;&#30830;&#24615;&#12289;&#23436;&#25972;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#21450;&#26102;&#24615;&#65292;&#25552;&#20379;&#22810;&#31181;&#35780;&#20272;&#20860;&#23481;&#24615;&#21644;&#30456;&#20284;&#24615;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20197;&#21450;&#23454;&#26045;&#19968;&#32452;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#22914;&#28335;&#28304;&#24615;&#12289;&#21487;&#35835;&#24615;&#21644;&#35768;&#21487;&#35777;&#12290;&#20854;&#30446;&#26631;&#26159;&#20351;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#33021;&#22815;&#22522;&#20110;&#21487;&#20449;&#21644;&#31934;&#24515;&#31649;&#29702;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data catalogs play a crucial role in modern data-driven organizations by facilitating the discovery, understanding, and utilization of diverse data assets. However, ensuring their quality and reliability is complex, especially in open and large-scale data environments. This paper proposes a framework to automatically determine the quality of open data catalogs, addressing the need for efficient and reliable quality assessment mechanisms. Our framework can analyze various core quality dimensions, such as accuracy, completeness, consistency, scalability, and timeliness, offer several alternatives for the assessment of compatibility and similarity across such catalogs as well as the implementation of a set of non-core quality dimensions such as provenance, readability, and licensing. The goal is to empower data-driven organizations to make informed decisions based on trustworthy and well-curated data assets. The source code that illustrates our approach can be downloaded from https://www.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31038;&#20132;&#24863;&#30693;&#21644;&#26102;&#38388;&#22240;&#32032;&#30340;&#35299;&#30721;&#22120;&#25512;&#33616;&#31995;&#32479;(STUDY)&#65292;&#20351;&#29992;transformer&#35299;&#30721;&#22120;&#32593;&#32476;&#23454;&#29616;&#23545;&#31038;&#20132;&#32593;&#32476;&#22270;&#20013;&#30456;&#37051;&#30340;&#29992;&#25143;&#32452;&#30340;&#32852;&#21512;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#22312;&#25945;&#32946;&#20869;&#23481;&#39046;&#22495;&#20013;&#32463;&#36807;&#27979;&#35797;&#65292;&#33021;&#22815;&#21462;&#24471;&#20248;&#20110;&#31038;&#20132;&#21644;&#39034;&#24207;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.07946</link><description>&lt;p&gt;
&#30740;&#31350;&#65306;&#31038;&#20132;&#24863;&#30693;&#26102;&#38388;&#26494;&#25955;&#35299;&#30721;&#22120;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
STUDY: Socially Aware Temporally Casual Decoder Recommender Systems. (arXiv:2306.07946v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07946
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31038;&#20132;&#24863;&#30693;&#21644;&#26102;&#38388;&#22240;&#32032;&#30340;&#35299;&#30721;&#22120;&#25512;&#33616;&#31995;&#32479;(STUDY)&#65292;&#20351;&#29992;transformer&#35299;&#30721;&#22120;&#32593;&#32476;&#23454;&#29616;&#23545;&#31038;&#20132;&#32593;&#32476;&#22270;&#20013;&#30456;&#37051;&#30340;&#29992;&#25143;&#32452;&#30340;&#32852;&#21512;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#22312;&#25945;&#32946;&#20869;&#23481;&#39046;&#22495;&#20013;&#32463;&#36807;&#27979;&#35797;&#65292;&#33021;&#22815;&#21462;&#24471;&#20248;&#20110;&#31038;&#20132;&#21644;&#39034;&#24207;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29616;&#22312;&#22312;&#32447;&#21644;&#31163;&#32447;&#21487;&#33719;&#21462;&#30340;&#25968;&#25454;&#25968;&#37327;&#36807;&#20110;&#24222;&#22823;&#65292;&#25512;&#33616;&#31995;&#32479;&#21464;&#24471;&#36234;&#26469;&#36234;&#24517;&#35201;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#25214;&#21040;&#31526;&#21512;&#20182;&#20204;&#20852;&#36259;&#30340;&#29289;&#21697;&#12290;&#24403;&#31038;&#20132;&#32593;&#32476;&#20449;&#24687;&#23384;&#22312;&#26102;&#65292;&#26377;&#19968;&#20123;&#26041;&#27861;&#21033;&#29992;&#36825;&#20123;&#20449;&#24687;&#26469;&#20570;&#20986;&#26356;&#22909;&#30340;&#25512;&#33616;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#26377;&#22797;&#26434;&#30340;&#32467;&#26500;&#21644;&#35757;&#32451;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#35768;&#22810;&#29616;&#26377;&#30340;&#26041;&#27861;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#32780;&#36825;&#20123;&#32593;&#32476;&#35757;&#32451;&#36215;&#26469;&#38750;&#24120;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#31038;&#20132;&#24863;&#30693;&#21644;&#26102;&#38388;&#22240;&#32032;&#30340;&#35299;&#30721;&#22120;&#25512;&#33616;&#31995;&#32479;(STUDY)&#12290;STUDY&#37319;&#29992;&#19968;&#20010;&#32463;&#36807;&#20462;&#25913;&#30340;transformer&#35299;&#30721;&#22120;&#32593;&#32476;&#30340;&#21333;&#21521;&#21069;&#20256;&#65292;&#23545;&#31038;&#20132;&#32593;&#32476;&#22270;&#20013;&#30456;&#37051;&#30340;&#29992;&#25143;&#32452;&#36827;&#34892;&#32852;&#21512;&#25512;&#26029;&#12290;&#25105;&#20204;&#22312;&#22522;&#20110;&#23398;&#26657;&#35838;&#22530;&#32467;&#26500;&#23450;&#20041;&#31038;&#20132;&#32593;&#32476;&#30340;&#25945;&#32946;&#20869;&#23481;&#39046;&#22495;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20445;&#25345;&#21333;&#19968;&#22343;&#21248;&#32593;&#32476;&#35774;&#35745;&#31616;&#21333;&#24615;&#30340;&#21516;&#26102;&#65292;&#20248;&#20110;&#31038;&#20132;&#21644;&#39034;&#24207;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the overwhelming amount of data available both on and offline today, recommender systems have become much needed to help users find items tailored to their interests. When social network information exists there are methods that utilize this information to make better recommendations, however the methods are often clunky with complex architectures and training procedures. Furthermore many of the existing methods utilize graph neural networks which are notoriously difficult to train. To address this, we propose Socially-aware Temporally caUsal Decoder recommender sYstems (STUDY). STUDY does joint inference over groups of users who are adjacent in the social network graph using a single forward pass of a modified transformer decoder network. We test our method in a school-based educational content setting, using classroom structure to define social networks. Our method outperforms both social and sequential methods while maintaining the design simplicity of a single homogeneous netw
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20221;&#22823;&#35268;&#27169;&#12289;&#30495;&#23454;&#30340;&#25968;&#25454;&#38598;KuaiSAR&#65292;&#35813;&#25968;&#25454;&#38598;&#35760;&#24405;&#20102;&#24555;&#25163;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#20013;&#30495;&#23454;&#30340;&#38598;&#25104;&#25628;&#32034;&#21644;&#25512;&#33616;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.07705</link><description>&lt;p&gt;
KuaiSAR: &#19968;&#20221;&#32479;&#19968;&#30340;&#25628;&#32034;&#19982;&#25512;&#33616;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
KuaiSAR: A Unified Search And Recommendation Dataset. (arXiv:2306.07705v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07705
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20221;&#22823;&#35268;&#27169;&#12289;&#30495;&#23454;&#30340;&#25968;&#25454;&#38598;KuaiSAR&#65292;&#35813;&#25968;&#25454;&#38598;&#35760;&#24405;&#20102;&#24555;&#25163;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#20013;&#30495;&#23454;&#30340;&#38598;&#25104;&#25628;&#32034;&#21644;&#25512;&#33616;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#21644;&#25512;&#33616;&#26381;&#21153;&#30340;&#34701;&#21512;&#26159;&#20687;&#24555;&#25163;&#21644;&#25238;&#38899;&#36825;&#26679;&#30340;&#22312;&#32447;&#20869;&#23481;&#24179;&#21488;&#30340;&#37325;&#35201;&#26041;&#38754;&#12290;S&amp;R&#24314;&#27169;&#30340;&#25972;&#21512;&#26159;&#19994;&#30028;&#23454;&#36341;&#32773;&#37319;&#29992;&#30340;&#39640;&#24230;&#30452;&#35266;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#65292;&#23398;&#26415;&#30028;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#36827;&#34892;&#30340;&#30740;&#31350;&#26126;&#26174;&#19981;&#36275;&#12290;&#22240;&#27492;&#65292;&#22312;&#23398;&#26415;&#30028;&#21644;&#20135;&#19994;&#30028;&#20043;&#38388;&#22312;&#36825;&#20010;&#39046;&#22495;&#36827;&#34892;&#30740;&#31350;&#30340;&#23454;&#36341;&#20043;&#38388;&#20986;&#29616;&#20102;&#23454;&#36136;&#24615;&#30340;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24555;&#25163;&#30340;&#19968;&#20010;&#39046;&#20808;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#25910;&#38598;&#30340;&#38598;&#25104;&#25628;&#32034;&#19982;&#25512;&#33616;&#34892;&#20026;&#30340;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;KuaiSAR&#12290;&#19982;&#20197;&#21069;&#30340;&#25968;&#25454;&#38598;&#19981;&#21516;&#65292;KuaiSAR&#35760;&#24405;&#20102;&#30495;&#23454;&#29992;&#25143;&#30340;&#34892;&#20026;&#65292;&#27599;&#20010;&#34892;&#20026;&#30340;&#21457;&#29983;&#26102;&#38388;&#37117;&#34987;&#31934;&#30830;&#35760;&#24405;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
The confluence of Search and Recommendation services is a vital aspect of online content platforms like Kuaishou and TikTok. The integration of S&amp;R modeling is a highly intuitive approach adopted by industry practitioners. However, there is a noticeable lack of research conducted in this area within the academia, primarily due to the absence of publicly available datasets. Consequently, a substantial gap has emerged between academia and industry regarding research endeavors in this field. To bridge this gap, we introduce the first large-scale, real-world dataset KuaiSAR of integrated Search And Recommendation behaviors collected from Kuaishou, a leading short-video app in China with over 300 million daily active users. Previous research in this field has predominantly employed publicly available datasets that are semi-synthetic and simulated, with artificially fabricated search behaviors. Distinct from previous datasets, KuaiSAR records genuine user behaviors, the occurrence of each in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Social4Rec&#31639;&#27861;&#65292;&#37319;&#29992;&#20004;&#38454;&#27573;&#26041;&#27861;&#20174;&#31038;&#20132;&#32593;&#32476;&#20013;&#25552;&#21462;&#29992;&#25143;&#20852;&#36259;&#65292;&#35299;&#20915;&#32593;&#32476;&#20869;&#23481;&#24179;&#21488;&#20013;&#20919;&#29992;&#25143;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.09971</link><description>&lt;p&gt;
Social4Rec: &#20174;&#31038;&#20132;&#32593;&#32476;&#20013;&#25552;&#21462;&#29992;&#25143;&#20559;&#22909;&#36827;&#34892;&#33150;&#35759;&#35270;&#39057;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Social4Rec: Distilling User Preference from Social Graph for Video Recommendation in Tencent. (arXiv:2302.09971v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Social4Rec&#31639;&#27861;&#65292;&#37319;&#29992;&#20004;&#38454;&#27573;&#26041;&#27861;&#20174;&#31038;&#20132;&#32593;&#32476;&#20013;&#25552;&#21462;&#29992;&#25143;&#20852;&#36259;&#65292;&#35299;&#20915;&#32593;&#32476;&#20869;&#23481;&#24179;&#21488;&#20013;&#20919;&#29992;&#25143;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25512;&#33616;&#31995;&#32479;&#22312;&#32593;&#32476;&#20869;&#23481;&#24179;&#21488;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#20294;&#25366;&#25496;&#29992;&#25143;&#30340;&#20852;&#36259;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#30340;&#34892;&#20026;&#65288;&#28857;&#20987;&#12289;&#26597;&#30475;&#31561;&#65289;&#26469;&#39044;&#27979;&#29992;&#25143;&#30340;&#20852;&#36259;&#65292;&#20294;&#24403;&#29992;&#25143;&#36827;&#34892;&#19981;&#31283;&#23450;&#30340;&#27963;&#21160;&#26102;&#65292;&#24403;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#25928;&#26524;&#19981;&#20339;&#12290;&#36825;&#20123;&#24773;&#20917;&#21253;&#25324;&#26032;&#29992;&#25143;&#21644;&#34892;&#20026;&#39057;&#29575;&#36739;&#20302;&#30340;&#31232;&#30095;&#29992;&#25143;&#12290;&#25105;&#20204;&#32479;&#19968;&#23558;&#36825;&#20004;&#31181;&#29992;&#25143;&#31867;&#22411;&#31216;&#20026;&#8220;&#20919;&#29992;&#25143;&#8221;&#65292;&#36825;&#22312;&#32593;&#32476;&#20869;&#23481;&#24179;&#21488;&#20013;&#38750;&#24120;&#24120;&#35265;&#65292;&#20294;&#32463;&#24120;&#34987;&#24573;&#35270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#29992;&#25143;&#30340;&#31038;&#20132;&#20852;&#36259;&#65288;&#22914;&#21451;&#35850;&#12289;&#20851;&#27880;&#21338;&#20027;&#12289;&#20852;&#36259;&#32452;&#31561;&#65289;&#19982;&#27963;&#21160;&#34892;&#20026;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#29992;&#25143;&#20852;&#36259;&#30340;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SocialNet&#30340;&#26032;&#31639;&#27861;&#65292;&#37319;&#29992;&#20004;&#38454;&#27573;&#26041;&#27861;&#36880;&#27493;&#25552;&#21462;&#31895;&#31890;&#24230;&#21644;&#32454;&#31890;&#24230;&#30340;&#31038;&#20132;&#20852;&#36259;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#38543;&#21518;&#23558;SocialNet&#30340;&#36755;&#20986;&#19982;&#25512;&#33616;&#31995;&#32479;&#30340;&#20256;&#32479;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#35270;&#39057;&#25512;&#33616;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite recommender systems play a key role in network content platforms, mining the user's interests is still a significant challenge. Existing works predict the user interest by utilizing user behaviors, i.e., clicks, views, etc., but current solutions are ineffective when users perform unsettled activities. The latter ones involve new users, which have few activities of any kind, and sparse users who have low-frequency behaviors. We uniformly describe both these user-types as "cold users", which are very common but often neglected in network content platforms. To address this issue, we enhance the representation of the user interest by combining his social interest, e.g., friendship, following bloggers, interest groups, etc., with the activity behaviors. Thus, in this work, we present a novel algorithm entitled SocialNet, which adopts a two-stage method to progressively extract the coarse-grained and fine-grained social interest. Our technique then concatenates SocialNet's output wi
&lt;/p&gt;</description></item><item><title>LabelPrompt&#26159;&#19968;&#31181;&#38754;&#21521;&#20851;&#31995;&#20998;&#31867;&#20219;&#21153;&#30340;&#25552;&#31034;&#24335;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;&#39069;&#22806;&#30340;&#20196;&#29260;&#26469;&#34920;&#31034;&#20851;&#31995;&#26631;&#31614;&#65292;&#24182;&#20351;&#29992;&#25552;&#31034;&#27169;&#26495;&#26041;&#27861;&#26126;&#30830;&#26500;&#24314;&#23427;&#20204;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#23558;&#22635;&#20805;&#25513;&#30721;&#26631;&#35760;&#30340;&#33258;&#28982;&#35821;&#35328;&#35789;&#27719;&#19982;&#35821;&#20041;&#20851;&#31995;&#26631;&#31614;&#30456;&#20851;&#32852;&#30340;&#25361;&#25112;&#12290;&#21516;&#26102;&#65292;&#35813;&#26041;&#27861;&#36824;&#23454;&#29616;&#20102;&#19968;&#20010;&#23454;&#20307;&#24863;&#30693;&#27169;&#22359;&#26469;&#20943;&#36731;&#39044;&#27979;&#20851;&#31995;&#21644;&#32473;&#23450;&#23454;&#20307;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.08068</link><description>&lt;p&gt;
LabelPrompt: &#20851;&#20110;&#20851;&#31995;&#20998;&#31867;&#30340;&#26377;&#25928;&#30340;&#25552;&#31034;&#24335;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LabelPrompt: Effective Prompt-based Learning for Relation Classification. (arXiv:2302.08068v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08068
&lt;/p&gt;
&lt;p&gt;
LabelPrompt&#26159;&#19968;&#31181;&#38754;&#21521;&#20851;&#31995;&#20998;&#31867;&#20219;&#21153;&#30340;&#25552;&#31034;&#24335;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;&#39069;&#22806;&#30340;&#20196;&#29260;&#26469;&#34920;&#31034;&#20851;&#31995;&#26631;&#31614;&#65292;&#24182;&#20351;&#29992;&#25552;&#31034;&#27169;&#26495;&#26041;&#27861;&#26126;&#30830;&#26500;&#24314;&#23427;&#20204;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#23558;&#22635;&#20805;&#25513;&#30721;&#26631;&#35760;&#30340;&#33258;&#28982;&#35821;&#35328;&#35789;&#27719;&#19982;&#35821;&#20041;&#20851;&#31995;&#26631;&#31614;&#30456;&#20851;&#32852;&#30340;&#25361;&#25112;&#12290;&#21516;&#26102;&#65292;&#35813;&#26041;&#27861;&#36824;&#23454;&#29616;&#20102;&#19968;&#20010;&#23454;&#20307;&#24863;&#30693;&#27169;&#22359;&#26469;&#20943;&#36731;&#39044;&#27979;&#20851;&#31995;&#21644;&#32473;&#23450;&#23454;&#20307;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#36890;&#36807;&#23558;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#36716;&#25442;&#20026;&#22635;&#31354;&#24335;&#26684;&#24335;&#65292;&#20197;&#26356;&#22909;&#22320;&#19982;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#23545;&#40784;&#30340;&#26041;&#24335;&#65292;&#25552;&#31034;&#24335;&#23398;&#20064;&#22312;&#35768;&#22810;NLP&#20219;&#21153;&#20013;&#21464;&#24471;&#27969;&#34892;&#36215;&#26469;&#12290;&#28982;&#32780;&#65292;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#20851;&#31995;&#20998;&#31867;&#20219;&#21153;&#38754;&#20020;&#30528;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23558;&#22635;&#20805;&#25513;&#30721;&#26631;&#35760;&#30340;&#33258;&#28982;&#35821;&#35328;&#35789;&#27719;&#19982;&#35821;&#20041;&#20851;&#31995;&#26631;&#31614;&#65288;&#22914;"org:founded_by"&#65289;&#30456;&#20851;&#32852;&#26159;&#22256;&#38590;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25552;&#31034;&#24335;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;LabelPrompt&#65292;&#29992;&#20110;&#20851;&#31995;&#20998;&#31867;&#20219;&#21153;&#12290;&#21463;&#21040;&#8220;&#32473;&#20104;&#27169;&#22411;&#36873;&#25321;&#8221;&#30340;&#30452;&#35273;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#39318;&#20808;&#23450;&#20041;&#39069;&#22806;&#30340;&#20196;&#29260;&#26469;&#34920;&#31034;&#20851;&#31995;&#26631;&#31614;&#65292;&#23558;&#36825;&#20123;&#20196;&#29260;&#35270;&#20026;&#20855;&#26377;&#35821;&#20041;&#21021;&#22987;&#21270;&#30340;&#21475;&#36848;&#32773;&#65292;&#24182;&#20351;&#29992;&#25552;&#31034;&#27169;&#26495;&#26041;&#27861;&#26126;&#30830;&#26500;&#24314;&#23427;&#20204;&#12290;&#28982;&#21518;&#65292;&#20026;&#20102;&#20943;&#36731;&#39044;&#27979;&#20851;&#31995;&#21644;&#32473;&#23450;&#23454;&#20307;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#23454;&#20307;&#24863;&#30693;&#27169;&#22359;&#65292;&#24182;&#37319;&#29992;&#23545;&#25239;&#24615;&#30340;&#26041;&#24335;&#36827;&#34892;&#24341;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, prompt-based learning has gained popularity across many natural language processing (NLP) tasks by reformulating them into a cloze-style format to better align pre-trained language models (PLMs) with downstream tasks. However, applying this approach to relation classification poses unique challenges. Specifically, associating natural language words that fill the masked token with semantic relation labels (\textit{e.g.} \textit{``org:founded\_by}'') is difficult. To address this challenge, this paper presents a novel prompt-based learning method, namely LabelPrompt, for the relation classification task. Motivated by the intuition to ``GIVE MODEL CHOICES!'', we first define additional tokens to represent relation labels, which regard these tokens as the verbaliser with semantic initialisation and explicitly construct them with a prompt template method. Then, to mitigate inconsistency between predicted relations and given entities, we implement an entity-aware module with contra
&lt;/p&gt;</description></item><item><title>NECE&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;&#25925;&#20107;&#20107;&#20214;&#38142;&#25552;&#21462;&#24037;&#20855;&#21253;&#65292;&#33021;&#22815;&#33258;&#21160;&#25552;&#21462;&#21644;&#23545;&#40784;&#25925;&#20107;&#20107;&#20214;&#65292;&#24182;&#21487;&#29992;&#20110;&#20998;&#26512;&#25925;&#20107;&#20559;&#35265;&#12290;</title><link>http://arxiv.org/abs/2208.08063</link><description>&lt;p&gt;
NECE: &#25925;&#20107;&#20107;&#20214;&#38142;&#25552;&#21462;&#24037;&#20855;&#21253;
&lt;/p&gt;
&lt;p&gt;
NECE: Narrative Event Chain Extraction Toolkit. (arXiv:2208.08063v5 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08063
&lt;/p&gt;
&lt;p&gt;
NECE&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;&#25925;&#20107;&#20107;&#20214;&#38142;&#25552;&#21462;&#24037;&#20855;&#21253;&#65292;&#33021;&#22815;&#33258;&#21160;&#25552;&#21462;&#21644;&#23545;&#40784;&#25925;&#20107;&#20107;&#20214;&#65292;&#24182;&#21487;&#29992;&#20110;&#20998;&#26512;&#25925;&#20107;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#29702;&#35299;&#19968;&#20010;&#25925;&#20107;&#65292;&#29702;&#35299;&#20107;&#20214;&#30340;&#26102;&#38388;&#27969;&#21160;&#23588;&#20026;&#37325;&#35201;&#65292;&#23588;&#20854;&#26159;&#19982;&#20027;&#35201;&#35282;&#33394;&#30456;&#20851;&#30340;&#20107;&#20214;&#65307;&#28982;&#32780;&#65292;&#23545;&#20110;&#20887;&#38271;&#21644;&#38750;&#32467;&#26500;&#21270;&#30340;&#25925;&#20107;&#25991;&#26412;&#65292;&#36825;&#21487;&#33021;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;NECE&#65292;&#19968;&#20010;&#24320;&#25918;&#33719;&#21462;&#30340;&#12289;&#22522;&#20110;&#25991;&#26723;&#32423;&#21035;&#30340;&#24037;&#20855;&#21253;&#65292;&#23427;&#21487;&#20197;&#33258;&#21160;&#25552;&#21462;&#21644;&#23545;&#40784;&#25925;&#20107;&#20107;&#20214;&#65292;&#25353;&#29031;&#23427;&#20204;&#21457;&#29983;&#30340;&#26102;&#38388;&#39034;&#24207;&#25490;&#21015;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;NECE&#24037;&#20855;&#21253;&#30340;&#39640;&#36136;&#37327;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#20998;&#26512;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#25925;&#20107;&#20559;&#35265;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#36824;&#20844;&#24320;&#35752;&#35770;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#20197;&#21450;&#26410;&#26469;&#24037;&#20316;&#20013;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#21147;&#12290;&#26368;&#21518;&#65292;NECE&#24037;&#20855;&#21253;&#21253;&#25324;&#19968;&#20010;Python&#24211;&#21644;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;Web&#30028;&#38754;&#65292;&#20026;&#19987;&#19994;&#20154;&#21592;&#21644;&#26222;&#36890;&#22823;&#20247;&#25552;&#20379;&#24179;&#31561;&#30340;&#35775;&#38382;&#26435;&#65292;&#21487;&#20197;&#21487;&#35270;&#21270;&#20107;&#20214;&#38142;&#65292;&#33719;&#21462;&#25925;&#20107;&#27969;&#31243;&#65292;&#25110;&#32773;&#30740;&#31350;&#25925;&#20107;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
To understand a narrative, it is essential to comprehend the temporal event flows, especially those associated with main characters; however, this can be challenging with lengthy and unstructured narrative texts. To address this, we introduce NECE, an open-access, document-level toolkit that automatically extracts and aligns narrative events in the temporal order of their occurrence. Through extensive evaluations, we show the high quality of the NECE toolkit and demonstrates its downstream application in analyzing narrative bias regarding gender. We also openly discuss the shortcomings of the current approach, and potential of leveraging generative models in future works. Lastly the NECE toolkit includes both a Python library and a user-friendly web interface, which offer equal access to professionals and layman audience alike, to visualize event chain, obtain narrative flows, or study narrative bias.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#28151;&#26434;&#22240;&#32032;&#24433;&#21709;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20986;&#28151;&#26434;&#22240;&#26524;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#20026;&#27599;&#20010;&#29305;&#23450;&#28151;&#26434;&#22240;&#32032;&#35774;&#35745;&#27169;&#22411;&#30340;&#19981;&#29616;&#23454;&#24615;&#20197;&#21450;&#28508;&#22312;&#28151;&#26434;&#22240;&#32032;&#26080;&#27861;&#35266;&#23519;&#30340;&#38590;&#39064;&#12290;</title><link>http://arxiv.org/abs/2110.07122</link><description>&lt;p&gt;
&#35299;&#20915;&#28151;&#26434;&#22240;&#26524;&#21327;&#21516;&#36807;&#28388;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Deconfounded Causal Collaborative Filtering. (arXiv:2110.07122v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.07122
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#28151;&#26434;&#22240;&#32032;&#24433;&#21709;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20986;&#28151;&#26434;&#22240;&#26524;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#20026;&#27599;&#20010;&#29305;&#23450;&#28151;&#26434;&#22240;&#32032;&#35774;&#35745;&#27169;&#22411;&#30340;&#19981;&#29616;&#23454;&#24615;&#20197;&#21450;&#28508;&#22312;&#28151;&#26434;&#22240;&#32032;&#26080;&#27861;&#35266;&#23519;&#30340;&#38590;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#20250;&#21463;&#21040;&#21508;&#31181;&#28151;&#26434;&#22240;&#32032;&#30340;&#24178;&#25200;&#65292;&#23548;&#33268;&#25512;&#33616;&#32467;&#26524;&#19981;&#20934;&#30830;&#65292;&#24615;&#33021;&#19979;&#38477;&#12290;&#30446;&#21069;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#36890;&#24120;&#26159;&#20026;&#27599;&#20010;&#29305;&#23450;&#30340;&#28151;&#26434;&#22240;&#32032;&#35774;&#35745;&#29305;&#23450;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#21487;&#33021;&#21253;&#21547;&#22823;&#37327;&#28151;&#26434;&#22240;&#32032;&#65292;&#22240;&#27492;&#20026;&#27599;&#20010;&#29305;&#23450;&#30340;&#28151;&#26434;&#22240;&#32032;&#35774;&#35745;&#29305;&#23450;&#30340;&#27169;&#22411;&#21487;&#33021;&#24182;&#19981;&#29616;&#23454;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#38500;&#20102;&#37027;&#20123;&#19987;&#23478;&#21487;&#20197;&#25163;&#21160;&#35782;&#21035;&#21644;&#22788;&#29702;&#30340;&#8220;&#26126;&#30830;&#28151;&#26434;&#22240;&#32032;&#8221;&#20043;&#22806;&#65292;&#36824;&#26377;&#35768;&#22810;&#8220;&#28508;&#22312;&#28151;&#26434;&#22240;&#32032;&#8221;&#36229;&#20986;&#20102;&#19987;&#23478;&#30340;&#24819;&#35937;&#21147;&#12290;&#20363;&#22914;&#65292;&#29992;&#25143;&#23545;&#19968;&#39318;&#27468;&#30340;&#35780;&#20998;&#21487;&#33021;&#21462;&#20915;&#20110;&#20182;&#20204;&#24403;&#26102;&#30340;&#24515;&#24773;&#25110;&#24403;&#21069;&#30340;&#22825;&#27668;&#24773;&#20917;&#65292;&#29992;&#25143;&#23545;&#20912;&#28103;&#28107;&#30340;&#20559;&#22909;&#21487;&#33021;&#21462;&#20915;&#20110;&#31354;&#27668;&#28201;&#24230;&#12290;&#36825;&#20123;&#28508;&#22312;&#28151;&#26434;&#22240;&#32032;&#22312;&#35760;&#24405;&#30340;&#35757;&#32451;&#25968;&#25454;&#20013;&#21487;&#33021;&#26159;&#19981;&#21487;&#35266;&#23519;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35299;&#28151;&#26434;&#22240;&#26524;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems may be confounded by various types of confounding factors (also called confounders) that may lead to inaccurate recommendations and sacrificed recommendation performance. Current approaches to solving the problem usually design each specific model for each specific confounder. However, real-world systems may include a huge number of confounders and thus designing each specific model for each specific confounder could be unrealistic. More importantly, except for those ``explicit confounders'' that experts can manually identify and process such as item's position in the ranking list, there are also many ``latent confounders'' that are beyond the imagination of experts. For example, users' rating on a song may depend on their current mood or the current weather, and users' preference on ice creams may depend on the air temperature. Such latent confounders may be unobservable in the recorded training data. To solve the problem, we propose Deconfounded Causal Collaborati
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22240;&#26524;&#21327;&#21516;&#36807;&#28388;&#65288;CCF&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#21327;&#21516;&#36807;&#28388;&#21644;&#25512;&#33616;&#20013;&#30340;&#22240;&#26524;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#32431;&#31929;&#30456;&#20851;&#23398;&#20064;&#23548;&#33268;&#30340;&#39044;&#27979;&#20013;&#30340;&#36763;&#26222;&#26862;&#24726;&#35770;&#38382;&#39064;&#65292;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2102.01868</link><description>&lt;p&gt;
&#22240;&#26524;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Causal Collaborative Filtering. (arXiv:2102.01868v5 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.01868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22240;&#26524;&#21327;&#21516;&#36807;&#28388;&#65288;CCF&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#21327;&#21516;&#36807;&#28388;&#21644;&#25512;&#33616;&#20013;&#30340;&#22240;&#26524;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#32431;&#31929;&#30456;&#20851;&#23398;&#20064;&#23548;&#33268;&#30340;&#39044;&#27979;&#20013;&#30340;&#36763;&#26222;&#26862;&#24726;&#35770;&#38382;&#39064;&#65292;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20256;&#32479;&#30340;&#25512;&#33616;&#31639;&#27861;&#22522;&#20110;&#20174;&#25968;&#25454;&#20013;&#25366;&#25496;&#25110;&#23398;&#20064;&#30456;&#20851;&#27169;&#24335;&#26469;&#20272;&#35745;&#29992;&#25143;-&#39033;&#30446;&#30340;&#30456;&#20851;&#20559;&#22909;&#30340;&#22522;&#26412;&#24605;&#24819;&#35774;&#35745;&#12290;&#28982;&#32780;&#65292;&#32431;&#31929;&#30340;&#30456;&#20851;&#23398;&#20064;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#20013;&#30340;&#36763;&#26222;&#26862;&#24726;&#35770;&#65292;&#20174;&#32780;&#23548;&#33268;&#25512;&#33616;&#24615;&#33021;&#30340;&#25439;&#22833;&#12290;&#36763;&#26222;&#26862;&#24726;&#35770;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#32479;&#35745;&#29616;&#35937;&#65292;&#23427;&#20250;&#23548;&#33268;&#32479;&#35745;&#32467;&#35770;&#30340;&#28151;&#28102;&#65292;&#24573;&#35270;&#36825;&#20010;&#24726;&#35770;&#21487;&#33021;&#23548;&#33268;&#19981;&#20934;&#30830;&#30340;&#20915;&#31574;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#22240;&#26524;&#21644;&#21453;&#20107;&#23454;&#24314;&#27169;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#36229;&#36234;&#35266;&#23519;&#25968;&#25454;&#36827;&#34892;&#29992;&#25143;&#24314;&#27169;&#21644;&#20010;&#24615;&#21270;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22240;&#26524;&#21327;&#21516;&#36807;&#28388;&#65288;CCF&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#21327;&#21516;&#36807;&#28388;&#21644;&#25512;&#33616;&#20013;&#30340;&#22240;&#26524;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#22240;&#26524;&#35270;&#22270;&#65292;&#24182;&#20174;&#25968;&#23398;&#19978;&#35777;&#26126;&#20102;&#35768;&#22810;&#20256;&#32479;&#30340;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#23454;&#38469;&#19978;&#26159;&#31616;&#21270;&#22240;&#26524;&#22270;&#19979;CCF&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many of the traditional recommendation algorithms are designed based on the fundamental idea of mining or learning correlative patterns from data to estimate the user-item correlative preference. However, pure correlative learning may lead to Simpson's paradox in predictions, and thus results in sacrificed recommendation performance. Simpson's paradox is a well-known statistical phenomenon, which causes confusions in statistical conclusions and ignoring the paradox may result in inaccurate decisions. Fortunately, causal and counterfactual modeling can help us to think outside of the observational data for user modeling and personalization so as to tackle such issues. In this paper, we propose Causal Collaborative Filtering (CCF) -- a general framework for modeling causality in collaborative filtering and recommendation. We provide a unified causal view of CF and mathematically show that many of the traditional CF algorithms are actually special cases of CCF under simplified causal grap
&lt;/p&gt;</description></item></channel></rss>