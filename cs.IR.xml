<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#31687;&#35770;&#25991;&#26088;&#22312;&#36890;&#36807;&#23545;&#35821;&#20041;&#23884;&#20837;API&#22312;&#23454;&#38469;&#26816;&#32034;&#22330;&#26223;&#20013;&#30340;&#20998;&#26512;,&#20026;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#25214;&#21040;&#36866;&#24403;&#30340;&#26381;&#21153;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#33521;&#35821;&#19978;&#20351;&#29992;API&#37325;&#26032;&#25490;&#21517;BM25&#30340;&#32467;&#26524;&#26159;&#19968;&#31181;&#39044;&#31639;&#21451;&#22909;&#30340;&#26368;&#20248;&#20570;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.06300</link><description>&lt;p&gt;
&#35780;&#20272;&#20449;&#24687;&#26816;&#32034;&#30340;&#23884;&#20837;&#24335;API
&lt;/p&gt;
&lt;p&gt;
Evaluating Embedding APIs for Information Retrieval. (arXiv:2305.06300v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06300
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#26088;&#22312;&#36890;&#36807;&#23545;&#35821;&#20041;&#23884;&#20837;API&#22312;&#23454;&#38469;&#26816;&#32034;&#22330;&#26223;&#20013;&#30340;&#20998;&#26512;,&#20026;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#25214;&#21040;&#36866;&#24403;&#30340;&#26381;&#21153;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#33521;&#35821;&#19978;&#20351;&#29992;API&#37325;&#26032;&#25490;&#21517;BM25&#30340;&#32467;&#26524;&#26159;&#19968;&#31181;&#39044;&#31639;&#21451;&#22909;&#30340;&#26368;&#20248;&#20570;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#19981;&#26029;&#22686;&#22823;&#20351;&#24471;&#20854;&#26222;&#21450;&#21270;&#25104;&#20026;&#20102;&#19968;&#39033;&#25361;&#25112;&#65292;&#22240;&#27492;&#35768;&#22810;&#20844;&#21496;&#21644;&#21021;&#21019;&#20225;&#19994;&#36890;&#36807;API&#21521;&#31038;&#21306;&#25552;&#20379;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35775;&#38382;&#26435;&#38480;&#12290;&#20854;&#20013;&#19968;&#20010;&#36866;&#29992;&#20110;&#23494;&#38598;&#26816;&#32034;&#30340;&#29305;&#23450;API&#26159;&#35821;&#20041;&#23884;&#20837;&#24335;API&#65292;&#20854;&#21487;&#26500;&#24314;&#32473;&#23450;&#25991;&#26412;&#30340;&#21521;&#37327;&#34920;&#31034;&#12290;&#22312;&#25317;&#26377;&#36234;&#26469;&#36234;&#22810;API&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#25991;&#26088;&#22312;&#20998;&#26512;&#22312;&#23454;&#38469;&#26816;&#32034;&#22330;&#26223;&#20013;&#35821;&#20041;&#23884;&#20837;&#24335;API&#20197;&#24110;&#21161;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#26681;&#25454;&#20182;&#20204;&#30340;&#38656;&#27714;&#25214;&#21040;&#36866;&#24403;&#30340;&#26381;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24076;&#26395;&#35843;&#26597;&#29616;&#26377;API&#22312;&#39046;&#22495;&#27867;&#21270;&#21644;&#22810;&#35821;&#35328;&#26816;&#32034;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#20004;&#20010;&#26631;&#20934;&#22522;&#20934;BEIR&#21644;MIRACL&#19978;&#35780;&#20272;&#20102;&#23884;&#20837;&#24335;API&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20351;&#29992;API&#37325;&#26032;&#25490;&#21517;BM25&#32467;&#26524;&#26159;&#19968;&#31181;&#39044;&#31639;&#21451;&#22909;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#33521;&#35821;&#19978;&#26368;&#26377;&#25928;&#65292;&#19982;&#26631;&#20934;&#20570;&#27861;&#21363;&#20316;&#20026;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#22120;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ever-increasing size of language models curtails their widespread access to the community, thereby galvanizing many companies and startups into offering access to large language models through APIs. One particular API, suitable for dense retrieval, is the semantic embedding API that builds vector representations of a given text. With a growing number of APIs at our disposal, in this paper, our goal is to analyze semantic embedding APIs in realistic retrieval scenarios in order to assist practitioners and researchers in finding suitable services according to their needs. Specifically, we wish to investigate the capabilities of existing APIs on domain generalization and multilingual retrieval. For this purpose, we evaluate the embedding APIs on two standard benchmarks, BEIR, and MIRACL. We find that re-ranking BM25 results using the APIs is a budget-friendly approach and is most effective on English, in contrast to the standard practice, i.e., employing them as first-stage retrievers
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;FedPDD&#30340;&#38544;&#31169;&#20445;&#25252;&#21452;&#37325;&#33976;&#39311;&#26694;&#26550;&#65292;&#29992;&#20110;&#36328;&#24179;&#21488;&#32852;&#37030;&#25512;&#33616;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#25945;&#24072;&#33976;&#39311;&#21644;&#23398;&#29983;&#33976;&#39311;&#20004;&#20010;&#38454;&#27573;&#65292;&#22312;&#19981;&#20256;&#36755;&#27169;&#22411;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26377;&#25928;&#22320;&#36716;&#31227;&#30693;&#35782;&#21644;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#33976;&#39311;&#25439;&#22833;&#20989;&#25968;&#26469;&#26500;&#24314;&#20840;&#23616;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.06272</link><description>&lt;p&gt;
FedPDD&#65306;&#29992;&#20110;&#36328;&#24179;&#21488;&#32852;&#37030;&#25512;&#33616;&#30340;&#38544;&#31169;&#20445;&#25252;&#21452;&#37325;&#33976;&#39311;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
FedPDD: A Privacy-preserving Double Distillation Framework for Cross-silo Federated Recommendation. (arXiv:2305.06272v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06272
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;FedPDD&#30340;&#38544;&#31169;&#20445;&#25252;&#21452;&#37325;&#33976;&#39311;&#26694;&#26550;&#65292;&#29992;&#20110;&#36328;&#24179;&#21488;&#32852;&#37030;&#25512;&#33616;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#25945;&#24072;&#33976;&#39311;&#21644;&#23398;&#29983;&#33976;&#39311;&#20004;&#20010;&#38454;&#27573;&#65292;&#22312;&#19981;&#20256;&#36755;&#27169;&#22411;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26377;&#25928;&#22320;&#36716;&#31227;&#30693;&#35782;&#21644;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#33976;&#39311;&#25439;&#22833;&#20989;&#25968;&#26469;&#26500;&#24314;&#20840;&#23616;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#24179;&#21488;&#25512;&#33616;&#26088;&#22312;&#36890;&#36807;&#20174;&#19981;&#21516;&#24179;&#21488;&#25910;&#38598;&#24322;&#26500;&#29305;&#24449;&#26469;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#36234;&#26469;&#36234;&#20005;&#26684;&#30340;&#38544;&#31169;&#20445;&#25252;&#27861;&#35268;&#38480;&#21046;&#20102;&#36825;&#31181;&#24179;&#21488;&#38388;&#30340;&#36328;&#30028;&#21327;&#20316;&#65292;&#22240;&#27492;&#19981;&#33021;&#32858;&#21512;&#25968;&#25454;&#29992;&#20110;&#35757;&#32451;&#12290;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#25512;&#33616;&#22330;&#26223;&#20013;&#22788;&#29702;&#25968;&#25454;&#23396;&#23707;&#38382;&#39064;&#30340;&#23454;&#29992;&#35299;&#20915;&#26041;&#26696;&#12290;&#29616;&#26377;&#30340;&#36328;&#24179;&#21488;FL&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#37325;&#21472;&#29992;&#25143;&#30340;&#25968;&#25454;&#21327;&#21516;&#26500;&#24314;&#20840;&#23616;&#27169;&#22411;&#65292;&#20256;&#36755;&#27169;&#22411;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#20013;&#65292;&#37325;&#21472;&#29992;&#25143;&#30340;&#25968;&#37327;&#24448;&#24448;&#38750;&#24120;&#23567;&#65292;&#20174;&#32780;&#22823;&#22823;&#38480;&#21046;&#20102;&#27492;&#31867;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451;&#26399;&#38388;&#20256;&#36755;&#27169;&#22411;&#20449;&#24687;&#38656;&#35201;&#39640;&#36890;&#20449;&#25104;&#26412;&#65292;&#21487;&#33021;&#20250;&#36896;&#25104;&#20005;&#37325;&#30340;&#38544;&#31169;&#27844;&#38706;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#31169;&#20445;&#25252;&#21452;&#37325;&#33976;&#39311;&#26694;&#26550; FedPDD &#29992;&#20110;&#36328;&#24179;&#21488;&#32852;&#37030;&#25512;&#33616;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#26377;&#25928;&#22320;&#36716;&#31227;&#30693;&#35782;&#26469;&#20445;&#25252;&#38544;&#31169;&#12290;FedPDD &#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#65306;&#25945;&#24072;&#33976;&#39311;&#21644;&#23398;&#29983;&#33976;&#39311;&#12290;&#22312;&#25945;&#24072;&#33976;&#39311;&#38454;&#27573;&#65292;&#27599;&#20010;&#24179;&#21488;&#22312;&#33258;&#24049;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#26412;&#22320;&#27169;&#22411;&#65292;&#24182;&#23558;&#26469;&#33258;&#36825;&#20123;&#27169;&#22411;&#30340;&#30693;&#35782;&#33976;&#39311;&#21040;&#19968;&#20010;&#23567;&#30340;&#12289;&#24102;&#26377;&#22122;&#22768;&#30340;&#25945;&#24072;&#27169;&#22411;&#20013;&#12290;&#28982;&#21518;&#65292;&#22312;&#23398;&#29983;&#33976;&#39311;&#38454;&#27573;&#65292;&#27599;&#20010;&#24179;&#21488;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#33976;&#39311;&#25439;&#22833;&#20989;&#25968;&#65292;&#21516;&#26102;&#20174;&#25945;&#24072;&#27169;&#22411;&#21644;&#26412;&#22320;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#35757;&#32451;&#33258;&#24049;&#30340;&#23398;&#29983;&#27169;&#22411;&#12290;FedPDD &#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#36328;&#24179;&#21488;&#32852;&#37030;&#25512;&#33616;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25252;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-platform recommendation aims to improve recommendation accuracy by gathering heterogeneous features from different platforms. However, such cross-silo collaborations between platforms are restricted by increasingly stringent privacy protection regulations, thus data cannot be aggregated for training. Federated learning (FL) is a practical solution to deal with the data silo problem in recommendation scenarios. Existing cross-silo FL methods transmit model information to collaboratively build a global model by leveraging the data of overlapped users. However, in reality, the number of overlapped users is often very small, thus largely limiting the performance of such approaches. Moreover, transmitting model information during training requires high communication costs and may cause serious privacy leakage. In this paper, we propose a novel privacy-preserving double distillation framework named FedPDD for cross-silo federated recommendation, which efficiently transfers knowledge wh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#65292;&#37319;&#29992;&#22810;&#20219;&#21153;&#31471;&#21040;&#31471;Transformer&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#24335;&#25512;&#33616;&#30340;&#24615;&#33021;&#65292;&#21487;&#31454;&#20105;&#20110;&#20808;&#21069;&#37319;&#29992;&#22797;&#26434;&#22810;&#32452;&#20214;&#26041;&#27861;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#24494;&#35843;&#25105;&#20204;&#30340;&#27169;&#22411;&#21644;&#39069;&#22806;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#35774;&#32622;&#65292;&#23454;&#29616;&#20102;&#30693;&#35782;&#22312;&#39046;&#22495;&#38388;&#30340;&#36716;&#31227;&#12290;</title><link>http://arxiv.org/abs/2305.06218</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#31471;&#21040;&#31471;&#35757;&#32451;&#25913;&#36827;&#20102;&#23545;&#35805;&#24335;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Multi-Task End-to-End Training Improves Conversational Recommendation. (arXiv:2305.06218v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#65292;&#37319;&#29992;&#22810;&#20219;&#21153;&#31471;&#21040;&#31471;Transformer&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#24335;&#25512;&#33616;&#30340;&#24615;&#33021;&#65292;&#21487;&#31454;&#20105;&#20110;&#20808;&#21069;&#37319;&#29992;&#22797;&#26434;&#22810;&#32452;&#20214;&#26041;&#27861;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#24494;&#35843;&#25105;&#20204;&#30340;&#27169;&#22411;&#21644;&#39069;&#22806;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#35774;&#32622;&#65292;&#23454;&#29616;&#20102;&#30693;&#35782;&#22312;&#39046;&#22495;&#38388;&#30340;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#20010;&#22810;&#20219;&#21153;&#31471;&#21040;&#31471;Transformer&#27169;&#22411;&#22312;&#23545;&#35805;&#24335;&#25512;&#33616;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#65292;&#35813;&#20219;&#21153;&#26088;&#22312;&#22522;&#20110;&#29992;&#25143;&#22312;&#23545;&#35805;&#20013;&#26126;&#30830;&#34920;&#31034;&#30340;&#20559;&#22909;&#25552;&#20379;&#25512;&#33616;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#30740;&#31350;&#22312;&#27492;&#39046;&#22495;&#37319;&#29992;&#20102;&#22797;&#26434;&#30340;&#22810;&#32452;&#20214;&#26041;&#27861;&#65292;&#20854;&#20013;&#23545;&#35805;&#31649;&#29702;&#21644;&#23454;&#20307;&#25512;&#33616;&#20219;&#21153;&#30001;&#21333;&#29420;&#30340;&#32452;&#20214;&#22788;&#29702;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#65292;&#22522;&#20110;T5&#25991;&#26412;-&#25991;&#26412;Transformer&#27169;&#22411;&#30340;&#32479;&#19968;Transformer&#27169;&#22411;&#22312;&#25512;&#33616;&#30456;&#20851;&#39033;&#30446;&#21644;&#29983;&#25104;&#23545;&#35805;&#26041;&#38754;&#37117;&#21487;&#20197;&#31454;&#20105;&#12290;&#25105;&#20204;&#22312;ReDIAL&#23545;&#35805;&#24335;&#30005;&#24433;&#25512;&#33616;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#24182;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#35774;&#32622;&#20013;&#21019;&#24314;&#20102;&#34893;&#29983;&#33258;MovieLens&#30340;&#39069;&#22806;&#35757;&#32451;&#20219;&#21153;&#65288;&#20363;&#22914;&#22522;&#20110;&#36755;&#20837;&#30005;&#24433;&#39044;&#27979;&#30005;&#24433;&#23646;&#24615;&#21644;&#30456;&#20851;&#30005;&#24433;&#65289;&#12290;&#20351;&#29992;&#19968;&#31995;&#21015;&#25506;&#38024;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#39069;&#22806;&#20219;&#21153;&#20013;&#23398;&#20064;&#21040;&#30340;&#30693;&#35782;&#34987;&#36716;&#31227;&#21040;&#20102;&#23545;&#35805;&#24335;&#25512;&#33616;&#39046;&#22495;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we analyze the performance of a multitask end-to-end transformer model on the task of conversational recommendations, which aim to provide recommendations based on a user's explicit preferences expressed in dialogue. While previous works in this area adopt complex multi-component approaches where the dialogue management and entity recommendation tasks are handled by separate components, we show that a unified transformer model, based on the T5 text-to-text transformer model, can perform competitively in both recommending relevant items and generating conversation dialogue. We fine-tune our model on the ReDIAL conversational movie recommendation dataset, and create additional training tasks derived from MovieLens (such as the prediction of movie attributes and related movies based on an input movie), in a multitask learning setting. Using a series of probe studies, we demonstrate that the learned knowledge in the additional tasks is transferred to the conversational setti
&lt;/p&gt;</description></item><item><title>TpD&#20026;&#36845;&#20195;&#25628;&#32034;&#31227;&#21160;&#24212;&#29992;&#23631;&#24149;&#25552;&#20379;&#20102;&#20132;&#20114;&#24335;&#33609;&#22270;&#21644;&#20851;&#38190;&#23383;&#25628;&#32034;&#25216;&#26415;&#30340;&#32467;&#21512;&#26041;&#27861;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#26356;&#24555;&#22320;&#26597;&#25214;&#25152;&#38656;&#23631;&#24149;&#12290;</title><link>http://arxiv.org/abs/2305.06165</link><description>&lt;p&gt;
&#36890;&#36807;&#25991;&#26412;&#21644;&#28034;&#40486;&#25628;&#32034;&#31227;&#21160;&#24212;&#29992;&#23631;&#24149;
&lt;/p&gt;
&lt;p&gt;
Searching Mobile App Screens via Text + Doodle. (arXiv:2305.06165v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06165
&lt;/p&gt;
&lt;p&gt;
TpD&#20026;&#36845;&#20195;&#25628;&#32034;&#31227;&#21160;&#24212;&#29992;&#23631;&#24149;&#25552;&#20379;&#20102;&#20132;&#20114;&#24335;&#33609;&#22270;&#21644;&#20851;&#38190;&#23383;&#25628;&#32034;&#25216;&#26415;&#30340;&#32467;&#21512;&#26041;&#27861;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#26356;&#24555;&#22320;&#26597;&#25214;&#25152;&#38656;&#23631;&#24149;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#36164;&#28304;&#20013;&#35201;&#25214;&#21040;&#29305;&#23450;&#30340;&#31227;&#21160;&#24212;&#29992;&#31243;&#24207;&#23631;&#24149;&#23616;&#38480;&#20110;&#22522;&#26412;&#30340;&#20851;&#38190;&#35789;&#25628;&#32034;&#65292;&#22914;Google&#22270;&#20687;&#25628;&#32034;&#65292;&#25110;&#38656;&#35201;&#23436;&#25972;&#30340;&#26597;&#35810;&#23631;&#24149;&#22270;&#20687;&#65292;&#22914;Swire&#30340;&#24773;&#20917;&#12290;&#28982;&#32780;&#65292;&#31867;&#20284;PSDoodle&#30340;&#20132;&#20114;&#24335;&#37096;&#20998;&#22522;&#20110;&#33609;&#22270;&#30340;&#35299;&#20915;&#26041;&#26696;&#23384;&#22312;&#31934;&#24230;&#19981;&#20934;&#30830;&#21644;&#26080;&#27861;&#32771;&#34385;&#23631;&#24149;&#19978;&#20986;&#29616;&#25991;&#26412;&#31561;&#23616;&#38480;&#24615;&#12290;&#19968;&#31181;&#28508;&#22312;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#28041;&#21450;&#23454;&#26045;&#19968;&#20010;&#31995;&#32479;&#65292;&#20026;&#26377;&#25928;&#26500;&#24314;&#29992;&#25143;&#30028;&#38754;&#20803;&#32032;&#25552;&#20379;&#20132;&#20114;&#24335;&#37096;&#20998;&#33609;&#22270;&#21151;&#33021;&#12290;&#27492;&#22806;&#65292;&#35813;&#31995;&#32479;&#24212;&#32467;&#21512;&#25991;&#26412;&#26597;&#35810;&#20197;&#36827;&#19968;&#27493;&#22686;&#24378;&#20854;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;TpD&#20195;&#34920;&#20102;&#36890;&#36807;&#32467;&#21512;&#20132;&#20114;&#24335;&#33609;&#22270;&#21644;&#20851;&#38190;&#23383;&#25628;&#32034;&#25216;&#26415;&#36827;&#34892;&#23631;&#24149;&#36845;&#20195;&#25628;&#32034;&#30340;&#24320;&#21019;&#24615;&#24037;&#20316;&#12290;TpD&#24314;&#31435;&#22312;&#22823;&#32422;58k&#20010;Android&#24212;&#29992;&#31243;&#24207;&#23631;&#24149;&#30340;Rico&#23384;&#20648;&#24211;&#21644;PSDoodle&#30340;&#32452;&#21512;&#22522;&#30784;&#19978;&#12290;&#25105;&#20204;&#19982;&#31532;&#19977;&#26041;&#36719;&#20214;&#24320;&#21457;&#20154;&#21592;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;PSDoodle&#25552;&#20379;&#20102;&#39640;&#31934;&#24230;&#12289;&#39640;&#21484;&#22238;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;TpD&#20351;&#29992;&#25143;&#33021;&#22815;&#26356;&#24555;&#22320;&#26597;&#25214;&#25152;&#38656;&#23631;&#24149;&#12290;
&lt;/p&gt;
&lt;p&gt;
Locating a specific mobile application screen from existing repositories is restricted to basic keyword searches, such as Google Image Search, or necessitates a complete query screen image, as in the case of Swire. However, interactive partial sketch-based solutions like PSDoodle have limitations, including inaccuracy and an inability to consider text appearing on the screen. A potentially effective solution involves implementing a system that provides interactive partial sketching functionality for efficiently structuring user interface elements. Additionally, the system should incorporate text queries to enhance its capabilities further. Our approach, TpD, represents the pioneering effort to enable an iterative search of screens by combining interactive sketching and keyword search techniques. TpD is built on a combination of the Rico repository of approximately 58k Android app screens and the PSDoodle. Our evaluation with third-party software developers showed that PSDoodle provided
&lt;/p&gt;</description></item><item><title>EdgeNet&#26159;&#19968;&#31181;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#29983;&#25104;&#32593;&#32476;&#65292;&#21487;&#29992;&#20110;&#22312;&#32447;&#30005;&#21830;&#24191;&#21578;&#25293;&#21334;&#20013;&#30340;&#25968;&#25454;&#39537;&#21160;&#31454;&#20215;&#35774;&#35745;&#12290;&#19982;&#20256;&#32479;&#27169;&#22411;&#30456;&#27604;&#65292;EdgeNet &#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#24191;&#21578;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#65292;&#24182;&#21033;&#29992;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#25552;&#39640;&#24191;&#21578;&#31454;&#25293;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.06158</link><description>&lt;p&gt;
EdgeNet&#65306;&#30005;&#23376;&#21830;&#21153;&#22312;&#32447;&#24191;&#21578;&#31454;&#20215;&#35774;&#35745;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#29983;&#25104;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
EdgeNet : Encoder-decoder generative Network for Auction Design in E-commerce Online Advertising. (arXiv:2305.06158v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06158
&lt;/p&gt;
&lt;p&gt;
EdgeNet&#26159;&#19968;&#31181;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#29983;&#25104;&#32593;&#32476;&#65292;&#21487;&#29992;&#20110;&#22312;&#32447;&#30005;&#21830;&#24191;&#21578;&#25293;&#21334;&#20013;&#30340;&#25968;&#25454;&#39537;&#21160;&#31454;&#20215;&#35774;&#35745;&#12290;&#19982;&#20256;&#32479;&#27169;&#22411;&#30456;&#27604;&#65292;EdgeNet &#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#24191;&#21578;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#65292;&#24182;&#21033;&#29992;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#25552;&#39640;&#24191;&#21578;&#31454;&#25293;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#29983;&#25104;&#32593;&#32476;EdgeNet&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#32447;&#30005;&#23376;&#21830;&#21153;&#24191;&#21578;&#20013;&#25968;&#25454;&#39537;&#21160;&#30340;&#25293;&#21334;&#35774;&#35745;&#12290;&#25105;&#20204;&#25171;&#30772;&#20102;&#24191;&#20041;&#27425;&#39640;&#20215;&#65288;GSP&#65289;&#30340;&#31070;&#32463;&#25293;&#21334;&#33539;&#24335;&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#21033;&#29992;&#25928;&#29575;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#25293;&#21334;&#26426;&#21046;&#30340;&#32463;&#27982;&#29305;&#24449;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;EdgeNet&#24341;&#20837;&#20102;&#22522;&#20110;transformer&#30340;&#32534;&#30721;&#22120;&#26469;&#26356;&#22909;&#22320;&#25429;&#25417;&#19981;&#21516;&#24191;&#21578;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#19982;&#22522;&#20110;GSP&#30340;&#31070;&#32463;&#25293;&#21334;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#33258;&#22238;&#24402;&#35299;&#30721;&#22120;&#65292;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#22312;&#32447;&#24191;&#21578;&#31454;&#25293;&#20013;&#30340;&#20016;&#23500;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;EdgeNet&#22312;&#27010;&#24565;&#19978;&#31616;&#21333;&#26131;&#25026;&#65292;&#24182;&#26131;&#20110;&#25193;&#23637;&#21040;&#29616;&#26377;&#30340;&#31471;&#21040;&#31471;&#31070;&#32463;&#25293;&#21334;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#22312;&#24191;&#27867;&#30340;&#30005;&#23376;&#21830;&#21153;&#24191;&#21578;&#31454;&#25293;&#20013;&#39564;&#35777;&#20102;EdgeNet&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#25552;&#39640;&#29992;&#25143;&#20307;&#39564;&#21644;&#24179;&#21488;&#25910;&#20837;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new encoder-decoder generative network dubbed EdgeNet, which introduces a novel encoder-decoder framework for data-driven auction design in online e-commerce advertising. We break the neural auction paradigm of Generalized-Second-Price(GSP), and improve the utilization efficiency of data while ensuring the economic characteristics of the auction mechanism. Specifically, EdgeNet introduces a transformer-based encoder to better capture the mutual influence among different candidate advertisements. In contrast to GSP based neural auction model, we design an autoregressive decoder to better utilize the rich context information in online advertising auctions. EdgeNet is conceptually simple and easy to extend to the existing end-to-end neural auction framework. We validate the efficiency of EdgeNet on a wide range of e-commercial advertising auction, demonstrating its potential in improving user experience and platform revenue.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35782;&#21035;&#21450;&#20998;&#31867;&#24433;&#21709;&#21407;&#27833;&#24066;&#22330;&#20379;&#38656;&#30340;&#26032;&#38395;&#20107;&#20214;&#30340;&#26041;&#27861;&#65292;&#24182;&#25454;&#27492;&#35774;&#35745;&#20102;CrudeBERT&#24773;&#24863;&#20998;&#26512;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20854;&#20182;&#19987;&#26377;&#21644;&#24320;&#28304;&#26041;&#26696;&#65292;&#20026;&#21407;&#27833;&#26399;&#36135;&#24066;&#22330;&#30456;&#20851;&#26631;&#39064;&#25552;&#20379;&#24773;&#24863;&#20998;&#31867;&#30340;&#25913;&#36827;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.06140</link><description>&lt;p&gt;
CrudeBERT&#65306;&#24212;&#29992;&#32463;&#27982;&#23398;&#29702;&#35770;&#25913;&#36827;&#22522;&#20110;Transformer&#30340;&#24773;&#24863;&#20998;&#26512;&#27169;&#22411;&#22312;&#21407;&#27833;&#24066;&#22330;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
CrudeBERT: Applying Economic Theory towards fine-tuning Transformer-based Sentiment Analysis Models to the Crude Oil Market. (arXiv:2305.06140v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35782;&#21035;&#21450;&#20998;&#31867;&#24433;&#21709;&#21407;&#27833;&#24066;&#22330;&#20379;&#38656;&#30340;&#26032;&#38395;&#20107;&#20214;&#30340;&#26041;&#27861;&#65292;&#24182;&#25454;&#27492;&#35774;&#35745;&#20102;CrudeBERT&#24773;&#24863;&#20998;&#26512;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20854;&#20182;&#19987;&#26377;&#21644;&#24320;&#28304;&#26041;&#26696;&#65292;&#20026;&#21407;&#27833;&#26399;&#36135;&#24066;&#22330;&#30456;&#20851;&#26631;&#39064;&#25552;&#20379;&#24773;&#24863;&#20998;&#31867;&#30340;&#25913;&#36827;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26032;&#38395;&#23186;&#20307;&#24773;&#24863;&#26469;&#39044;&#27979;&#24066;&#22330;&#36208;&#21521;&#22312;&#25968;&#25454;&#20998;&#26512;&#20013;&#24050;&#26377;&#24736;&#20037;&#20256;&#32479;&#12290;&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#36827;&#27493;&#65292;&#20986;&#29616;&#20102;&#21487;&#36827;&#34892;&#19978;&#19979;&#25991;&#24863;&#30693;&#24773;&#24863;&#20998;&#31867;&#30340;Transformer&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#20026;&#37329;&#34701;&#24066;&#22330;&#21046;&#23450;&#30340;&#26041;&#27861;&#65292;&#22914;FinBERT&#65292;&#26080;&#27861;&#21306;&#20998;&#24433;&#21709;&#29305;&#23450;&#36164;&#20135;&#20215;&#20540;&#39537;&#21160;&#22240;&#32032;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#22823;&#37327;&#30456;&#20851;&#26032;&#38395;&#22836;&#26465;&#20013;&#35782;&#21035;&#21644;&#20998;&#31867;&#24433;&#21709;&#21407;&#27833;&#24066;&#22330;&#20379;&#38656;&#30340;&#20107;&#20214;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20986;&#20102;CrudeBERT&#65292;&#36825;&#26159;&#19968;&#20010;&#20381;&#25454;&#36825;&#20123;&#20107;&#20214;&#26469;&#19978;&#19979;&#25991;&#21270;&#24182;&#20248;&#21270;FinBERT&#30340;&#24773;&#24863;&#20998;&#26512;&#27169;&#22411;&#65292;&#20174;&#32780;&#25552;&#20379;&#19982;&#21407;&#27833;&#26399;&#36135;&#24066;&#22330;&#30456;&#20851;&#30340;&#26631;&#39064;&#30340;&#24773;&#24863;&#20998;&#31867;&#30340;&#25913;&#36827;&#34920;&#29616;&#12290;&#19968;&#39033;&#24191;&#27867;&#30340;&#35780;&#20272;&#23637;&#31034;&#20102;CrudeBERT&#22312;&#21407;&#27833;&#39046;&#22495;&#32988;&#36807;&#19987;&#26377;&#21644;&#24320;&#28304;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting market movements based on the sentiment of news media has a long tradition in data analysis. With advances in natural language processing, transformer architectures have emerged that enable contextually aware sentiment classification. Nevertheless, current methods built for the general financial market such as FinBERT cannot distinguish asset-specific value-driving factors. This paper addresses this shortcoming by presenting a method that identifies and classifies events that impact supply and demand in the crude oil markets within a large corpus of relevant news headlines. We then introduce CrudeBERT, a new sentiment analysis model that draws upon these events to contextualize and fine-tune FinBERT, thereby yielding improved sentiment classifications for headlines related to the crude oil futures market. An extensive evaluation demonstrates that CrudeBERT outperforms proprietary and open-source solutions in the domain of crude oil.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#20219;&#21153;&#8212;&#8212;&#23569;&#26679;&#26412;N-&#20803;&#20107;&#23454;&#38142;&#25509;&#39044;&#27979;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;FLEN&#30340;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;FLEN&#30001;&#19977;&#20010;&#27169;&#22359;&#32452;&#25104;&#65292;&#21487;&#20197;&#20174;&#26377;&#38480;&#30340;&#26631;&#35760;&#23454;&#20363;&#20013;&#39044;&#27979;N-&#20803;&#20107;&#23454;&#20013;&#30340;&#32570;&#22833;&#23454;&#20307;&#12290;</title><link>http://arxiv.org/abs/2305.06104</link><description>&lt;p&gt;
N-&#20803;&#20107;&#23454;&#30340;&#23569;&#26679;&#26412;&#38142;&#25509;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Few-shot Link Prediction on N-ary Facts. (arXiv:2305.06104v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06104
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#20219;&#21153;&#8212;&#8212;&#23569;&#26679;&#26412;N-&#20803;&#20107;&#23454;&#38142;&#25509;&#39044;&#27979;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;FLEN&#30340;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;FLEN&#30001;&#19977;&#20010;&#27169;&#22359;&#32452;&#25104;&#65292;&#21487;&#20197;&#20174;&#26377;&#38480;&#30340;&#26631;&#35760;&#23454;&#20363;&#20013;&#39044;&#27979;N-&#20803;&#20107;&#23454;&#20013;&#30340;&#32570;&#22833;&#23454;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
N-&#20803;&#20107;&#23454;&#30001;&#20027;&#35201;&#19977;&#20803;&#32452;&#65288;&#22836;&#23454;&#20307;&#12289;&#20851;&#31995;&#12289;&#23614;&#23454;&#20307;&#65289;&#21644;&#20219;&#24847;&#25968;&#37327;&#30340;&#36741;&#21161;&#23646;&#24615;&#20540;&#23545;&#32452;&#25104;&#65292;&#36825;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#30693;&#35782;&#22270;&#35889;&#20013;&#24456;&#24120;&#35265;&#12290;&#23545;&#20110;N-&#20803;&#20107;&#23454;&#30340;&#38142;&#25509;&#39044;&#27979;&#26159;&#39044;&#27979;&#20854;&#20013;&#19968;&#20010;&#20803;&#32032;&#30340;&#32570;&#22833;&#65292;&#22635;&#34917;&#32570;&#22833;&#20803;&#32032;&#26377;&#21161;&#20110;&#20016;&#23500;&#30693;&#35782;&#22270;&#35889;&#24182;&#20419;&#36827;&#35768;&#22810;&#19979;&#28216;&#24212;&#29992;&#31243;&#24207;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#26469;&#29702;&#35299;N-&#20803;&#20107;&#23454;&#20013;&#30340;&#20803;&#32032;&#65292;&#20294;&#36825;&#20123;&#30740;&#31350;&#24573;&#35270;&#20102;&#23569;&#26679;&#26412;&#20851;&#31995;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#21364;&#24456;&#24120;&#35265;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#24341;&#20837;&#19968;&#20010;&#26032;&#20219;&#21153;&#8212;&#8212;&#23569;&#26679;&#26412;N-&#20803;&#20107;&#23454;&#38142;&#25509;&#39044;&#27979;&#65292;&#26088;&#22312;&#20351;&#29992;&#26377;&#38480;&#30340;&#26631;&#35760;&#23454;&#20363;&#26469;&#39044;&#27979;N-&#20803;&#20107;&#23454;&#20013;&#30340;&#32570;&#22833;&#23454;&#20307;&#12290;&#25105;&#20204;&#20063;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;N-&#20803;&#20107;&#23454;&#30340;&#23569;&#26679;&#26412;&#38142;&#25509;&#39044;&#27979;&#27169;&#22411;FLEN&#65292;&#23427;&#30001;&#19977;&#20010;&#27169;&#22359;&#32452;&#25104;&#65306;&#20851;&#31995;&#23398;&#20064;&#27169;&#22359;&#12289;&#25903;&#25345;&#29305;&#23450;&#35843;&#25972;&#27169;&#22359;&#21644;&#26597;&#35810;&#25512;&#29702;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;
N-ary facts composed of a primary triple (head entity, relation, tail entity) and an arbitrary number of auxiliary attribute-value pairs, are prevalent in real-world knowledge graphs (KGs). Link prediction on n-ary facts is to predict a missing element in an n-ary fact. This helps populate and enrich KGs and further promotes numerous downstream applications. Previous studies usually require a substantial amount of high-quality data to understand the elements in n-ary facts. However, these studies overlook few-shot relations, which have limited labeled instances, yet are common in real-world scenarios. Thus, this paper introduces a new task, few-shot link prediction on n-ary facts. It aims to predict a missing entity in an n-ary fact with limited labeled instances. We further propose a model for Few-shot Link prEdict on N-ary facts, thus called FLEN, which consists of three modules: the relation learning, support-specific adjusting, and query inference modules. FLEN captures relation me
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#37319;&#29992;&#20027;&#39064;&#24863;&#30693;&#30340;&#20998;&#31867;&#24433;&#21709;&#25351;&#26631;&#26469;&#35299;&#20915;&#20840;&#23616;&#35745;&#31639;&#30340;&#24341;&#29992;&#24433;&#21709;&#25351;&#26631;&#22312;&#30740;&#31350;&#35780;&#20272;&#21644;&#30693;&#35782;&#21457;&#29616;&#31561;&#24212;&#29992;&#20013;&#38590;&#20197;&#27491;&#30830;&#35299;&#37322;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;BIP!&#26381;&#21153;&#20013;&#35797;&#28857;&#23637;&#31034;&#20102;&#36825;&#20123;&#25351;&#26631;&#30340;&#22909;&#22788;&#12290;</title><link>http://arxiv.org/abs/2305.06047</link><description>&lt;p&gt;
&#22312;BIP!&#26381;&#21153;&#20013;&#35797;&#28857;&#20027;&#39064;&#24863;&#30693;&#30740;&#31350;&#24433;&#21709;&#35780;&#20272;&#21151;&#33021;
&lt;/p&gt;
&lt;p&gt;
Piloting topic-aware research impact assessment features in BIP! Services. (arXiv:2305.06047v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06047
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#37319;&#29992;&#20027;&#39064;&#24863;&#30693;&#30340;&#20998;&#31867;&#24433;&#21709;&#25351;&#26631;&#26469;&#35299;&#20915;&#20840;&#23616;&#35745;&#31639;&#30340;&#24341;&#29992;&#24433;&#21709;&#25351;&#26631;&#22312;&#30740;&#31350;&#35780;&#20272;&#21644;&#30693;&#35782;&#21457;&#29616;&#31561;&#24212;&#29992;&#20013;&#38590;&#20197;&#27491;&#30830;&#35299;&#37322;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;BIP!&#26381;&#21153;&#20013;&#35797;&#28857;&#23637;&#31034;&#20102;&#36825;&#20123;&#25351;&#26631;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#31181;&#30740;&#31350;&#27963;&#21160;&#20381;&#36182;&#20110;&#22522;&#20110;&#24341;&#29992;&#30340;&#24433;&#21709;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25351;&#26631;&#36890;&#24120;&#26159;&#20840;&#23616;&#35745;&#31639;&#30340;&#65292;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#30740;&#31350;&#35780;&#20272;&#21644;&#30693;&#35782;&#21457;&#29616;&#31561;&#24212;&#29992;&#20013;&#30340;&#27491;&#30830;&#35299;&#37322;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20513;&#23548;&#20351;&#29992;&#20027;&#39064;&#24863;&#30693;&#30340;&#20998;&#31867;&#24433;&#21709;&#25351;&#26631;&#65292;&#20197;&#32531;&#35299;&#19978;&#36848;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;BIP!&#26381;&#21153;&#20197;&#25903;&#25345;&#36825;&#20123;&#25351;&#26631;&#65292;&#24182;&#23637;&#31034;&#23427;&#20204;&#22312;&#23454;&#38469;&#30740;&#31350;&#27963;&#21160;&#20013;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Various research activities rely on citation-based impact indicators. However these indicators are usually globally computed, hindering their proper interpretation in applications like research assessment and knowledge discovery. In this work, we advocate for the use of topic-aware categorical impact indicators, to alleviate the aforementioned problem. In addition, we extend BIP! Services to support those indicators and showcase their benefits in real-world research activities.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#22823;&#35821;&#35328;&#27169;&#22411;&#21512;&#25104;&#26597;&#35810;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23433;&#20840;&#26377;&#25928;&#22320;&#35757;&#32451;&#28145;&#24230;&#26816;&#32034;&#27169;&#22411;&#24182;&#25552;&#39640;&#26816;&#32034;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.05973</link><description>&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#22823;&#35821;&#35328;&#27169;&#22411;&#21512;&#25104;&#26597;&#35810;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#31995;&#32479;.
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models. (arXiv:2305.05973v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05973
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#22823;&#35821;&#35328;&#27169;&#22411;&#21512;&#25104;&#26597;&#35810;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#23433;&#20840;&#26377;&#25928;&#22320;&#35757;&#32451;&#28145;&#24230;&#26816;&#32034;&#27169;&#22411;&#24182;&#25552;&#39640;&#26816;&#32034;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24320;&#21457;&#38544;&#31169;&#20445;&#25252;&#30340;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#65292;&#20811;&#26381;&#20102;&#22312;&#35757;&#32451;&#36825;&#20123;&#22797;&#26434;&#31995;&#32479;&#26102;&#30340;&#26576;&#20123;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#29305;&#21035;&#36866;&#29992;&#20110;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#20852;&#39046;&#22495;&#65292;&#20294;&#20063;&#21487;&#20197;&#36731;&#26494;&#22320;&#29992;&#20110;&#22788;&#29702;&#33258;&#28982;&#35821;&#35328;&#36755;&#20837;&#34920;&#31034;&#30340;&#20219;&#20309;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;DP&#35757;&#32451;&#26041;&#27861;&#65292;&#23545;&#20844;&#24320;&#39044;&#35757;&#32451;&#30340;LLM&#22312;&#26597;&#35810;&#29983;&#25104;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#29983;&#25104;&#30340;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#31169;&#26377;&#21512;&#25104;&#26597;&#35810;&#65292;&#20195;&#34920;&#21407;&#22987;&#26597;&#35810;&#65292;&#21487;&#20197;&#22312;&#20219;&#20309;&#19979;&#28216;&#38750;&#31169;&#26377;&#25512;&#33616;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#30001;&#20849;&#20139;&#65292;&#32780;&#19981;&#20250;&#20135;&#29983;&#20219;&#20309;&#39069;&#22806;&#30340;&#38544;&#31169;&#25104;&#26412;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#23433;&#20840;&#35757;&#32451;&#26377;&#25928;&#30340;&#28145;&#24230;&#26816;&#32034;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#23427;&#20204;&#30340;&#26816;&#32034;&#36136;&#37327;&#26377;&#26174;&#30528;&#30340;&#25552;&#39640;&#65292;&#32780;&#19981;&#20250;&#25439;&#23475;&#26597;&#35810;&#32423;&#21035;&#30340;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel approach for developing privacy-preserving large-scale recommender systems using differentially private (DP) large language models (LLMs) which overcomes certain challenges and limitations in DP training these complex systems. Our method is particularly well suited for the emerging area of LLM-based recommender systems, but can be readily employed for any recommender systems that process representations of natural language inputs. Our approach involves using DP training methods to fine-tune a publicly pre-trained LLM on a query generation task. The resulting model can generate private synthetic queries representative of the original queries which can be freely shared for any downstream non-private recommendation training procedures without incurring any additional privacy cost. We evaluate our method on its ability to securely train effective deep retrieval models, and we observe significant improvements in their retrieval quality without compromising query-level pri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20154;&#24037;&#27880;&#37322;&#26631;&#31614;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#36328;&#25991;&#21270;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#19981;&#19968;&#33268;&#27010;&#24565;&#21270;&#30340;&#28216;&#25103;&#26631;&#31614;&#23376;&#38598;&#65292;&#24182;&#23545;&#36328;&#22269;&#26631;&#27880;&#30340;&#25991;&#21270;&#21644;&#35821;&#35328;&#24046;&#24322;&#30340;&#21407;&#22240;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;&#20316;&#32773;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20379;&#20174;&#19994;&#20154;&#21592;&#23457;&#26680;&#33258;&#24049;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2305.05917</link><description>&lt;p&gt;
&#35780;&#20272;&#22522;&#20110;&#20154;&#24037;&#27880;&#37322;&#26631;&#31614;&#30340;&#25512;&#33616;&#31995;&#32479;&#36328;&#25991;&#21270;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Auditing Cross-Cultural Consistency of Human-Annotated Labels for Recommendation Systems. (arXiv:2305.05917v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20154;&#24037;&#27880;&#37322;&#26631;&#31614;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#36328;&#25991;&#21270;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#19981;&#19968;&#33268;&#27010;&#24565;&#21270;&#30340;&#28216;&#25103;&#26631;&#31614;&#23376;&#38598;&#65292;&#24182;&#23545;&#36328;&#22269;&#26631;&#27880;&#30340;&#25991;&#21270;&#21644;&#35821;&#35328;&#24046;&#24322;&#30340;&#21407;&#22240;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;&#20316;&#32773;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20379;&#20174;&#19994;&#20154;&#21592;&#23457;&#26680;&#33258;&#24049;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#36234;&#26469;&#36234;&#20381;&#36182;&#20110;&#22823;&#35268;&#27169;&#30340;&#20154;&#24037;&#26631;&#35760;&#25968;&#25454;&#38598;&#65307;&#28982;&#32780;&#65292;&#29983;&#25104;&#36825;&#20123;&#26631;&#35760;&#30340;&#20154;&#31867;&#27880;&#37322;&#32773;&#36234;&#26469;&#36234;&#26469;&#33258;&#21516;&#36136;&#21270;&#30340;&#32972;&#26223;&#12290;&#36825;&#22312;&#23558;&#22522;&#20110;&#36825;&#20123;&#26631;&#31614;&#30340;&#19979;&#28216;&#39044;&#27979;&#27169;&#22411;&#24212;&#29992;&#20110;&#24322;&#26500;&#29992;&#25143;&#32676;&#26102;&#20250;&#24102;&#26469;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#31181;&#26029;&#35010;&#19982;&#26631;&#31614;&#26412;&#36523;&#30340;&#20851;&#31995;&#65292;&#35810;&#38382;&#26159;&#21542;&#36328;&#19981;&#21516;&#20154;&#21475;&#32479;&#35745;&#23398;&#27880;&#37322;&#32773;&#8220;&#19968;&#33268;&#27010;&#24565;&#21270;&#8221;&#12290;&#22312;&#35270;&#39057;&#28216;&#25103;&#26631;&#31614;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;5174&#21517;&#28216;&#25103;&#29609;&#23478;&#36827;&#34892;&#20102;&#19968;&#39033;&#35843;&#26597;&#65292;&#30830;&#23450;&#20102;&#19968;&#32452;&#19981;&#19968;&#33268;&#27010;&#24565;&#21270;&#30340;&#28216;&#25103;&#26631;&#31614;&#23376;&#38598;&#65292;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#36328;&#22269;&#26631;&#27880;&#30340;&#25991;&#21270;&#21644;&#35821;&#35328;&#24046;&#24322;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#19982;&#21516;&#36136;&#21270;&#65288;&#21333;&#20010;&#22269;&#23478;&#65289;&#35757;&#32451;&#38598;&#30456;&#27604;&#65292;&#28216;&#25103;&#26631;&#27880;&#30340;&#39044;&#27979;&#27169;&#22411;&#22312;&#20840;&#29699;&#35757;&#32451;&#38598;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20379;&#20174;&#19994;&#20154;&#21592;&#23457;&#26680;&#33258;&#24049;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems increasingly depend on massive human-labeled datasets; however, the human annotators hired to generate these labels increasingly come from homogeneous backgrounds. This poses an issue when downstream predictive models -- based on these labels -- are applied globally to a heterogeneous set of users. We study this disconnect with respect to the labels themselves, asking whether they are ``consistently conceptualized'' across annotators of different demographics. In a case study of video game labels, we conduct a survey on 5,174 gamers, identify a subset of inconsistently conceptualized game labels, perform causal analyses, and suggest both cultural and linguistic reasons for cross-country differences in label annotation. We further demonstrate that predictive models of game annotations perform better on global train sets as opposed to homogeneous (single-country) train sets. Finally, we provide a generalizable framework for practitioners to audit their own data ann
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#24847;&#22270;&#22686;&#24378;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#21382;&#21490;&#20250;&#35805;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#26080;&#27861;&#25512;&#33616;&#26032;&#20135;&#21697;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.05848</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#24847;&#22270;&#22686;&#24378;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#26032;&#21697;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Dual Intent Enhanced Graph Neural Network for Session-based New Item Recommendation. (arXiv:2305.05848v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#24847;&#22270;&#22686;&#24378;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#21382;&#21490;&#20250;&#35805;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#26080;&#27861;&#25512;&#33616;&#26032;&#20135;&#21697;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26159;&#21508;&#20010;&#39046;&#22495;&#65292;&#20363;&#22914;&#30005;&#23376;&#21830;&#21153;&#12289;&#30005;&#23376;&#23398;&#20064;&#21644;&#27969;&#23186;&#20307;&#31561;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#37096;&#20998;&#12290;&#30446;&#21069;&#65292;&#29992;&#20110;&#20250;&#35805;&#25512;&#33616;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#21482;&#33021;&#25512;&#33616;&#29992;&#25143;&#21382;&#21490;&#20250;&#35805;&#20013;&#24050;&#23384;&#22312;&#30340;&#39033;&#30446;&#12290;&#22240;&#27492;&#36825;&#20123;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#25512;&#33616;&#29992;&#25143;&#20174;&#26410;&#19982;&#20043;&#20132;&#20114;&#30340;&#39033;&#30446;&#65288;&#26032;&#20135;&#21697;&#65289;&#26102;&#38754;&#20020;&#20449;&#24687;&#23553;&#38381;&#30340;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#26377;&#24517;&#35201;&#21521;&#29992;&#25143;&#25512;&#33616;&#26032;&#30340;&#20135;&#21697;&#12290;&#30001;&#20110;&#26032;&#20135;&#21697;&#19982;&#29992;&#25143;&#20043;&#38388;&#27809;&#26377;&#20132;&#20114;&#65292;&#22240;&#27492;&#22312;&#26500;&#24314;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#26102;&#65292;&#25105;&#20204;&#19981;&#33021;&#23558;&#26032;&#20135;&#21697;&#21253;&#25324;&#22312;&#20250;&#35805;&#22270;&#20013;&#12290;&#22240;&#27492;&#65292;&#20351;&#29992;&#22522;&#20110;GNN&#65288;&#22270;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#26041;&#27861;&#21521;&#29992;&#25143;&#25512;&#33616;&#26032;&#20135;&#21697;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#24847;&#22270;&#22686;&#24378;&#22270;&#31070;&#32463;&#32593;&#32476;&#12290;&#30001;&#20110;&#26032;&#30340;&#20135;&#21697;&#19982;&#21382;&#21490;&#20250;&#35805;&#27809;&#26377;&#32465;&#23450;&#20851;&#31995;&#65292;&#27169;&#22411;&#23398;&#20064;&#22914;&#20309;&#25429;&#25417;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#24847;&#22270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#24341;&#20837;&#20102;&#21452;&#24847;&#22270;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#19968;&#24352;&#22270;&#26469;&#25429;&#33719;&#39033;&#30446;&#24847;&#22270;&#30340;&#34920;&#31034;&#65292;&#21478;&#19968;&#24352;&#22270;&#26469;&#25429;&#33719;&#29992;&#25143;&#24847;&#22270;&#30340;&#34920;&#31034;&#12290;&#35813;&#27169;&#22411;&#23558;&#21382;&#21490;&#20250;&#35805;&#19982;&#29992;&#25143;&#21644;&#39033;&#30446;&#21452;&#37325;&#24847;&#22270;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#25512;&#33616;&#12290;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are essential to various fields, e.g., e-commerce, e-learning, and streaming media. At present, graph neural networks (GNNs) for session-based recommendations normally can only recommend items existing in users' historical sessions. As a result, these GNNs have difficulty recommending items that users have never interacted with (new items), which leads to a phenomenon of information cocoon. Therefore, it is necessary to recommend new items to users. As there is no interaction between new items and users, we cannot include new items when building session graphs for GNN session-based recommender systems. Thus, it is challenging to recommend new items for users when using GNN-based methods. We regard this challenge as '\textbf{G}NN \textbf{S}ession-based \textbf{N}ew \textbf{I}tem \textbf{R}ecommendation (GSNIR)'. To solve this problem, we propose a dual-intent enhanced graph neural network for it. Due to the fact that new items are not tied to historical sessions, the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24369;&#30417;&#30563;&#30446;&#26631;&#26816;&#27979;&#19982;&#25991;&#26723;&#24067;&#23616;&#20998;&#26512;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#22312;&#27861;&#24459;&#25991;&#20214;&#20013;&#25552;&#21462;&#19981;&#36830;&#32493;&#30340;&#22797;&#26434;&#21629;&#21517;&#23454;&#20307;&#65292;&#19988;&#27169;&#22411;&#22312;&#37329;&#26631;&#20934;&#25968;&#25454;&#26377;&#38480;&#26102;&#20173;&#26377;&#20248;&#24322;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.05836</link><description>&lt;p&gt;
&#36890;&#36807;&#24369;&#30417;&#30563;&#30446;&#26631;&#26816;&#27979;&#22312;&#27861;&#24459;&#25991;&#26723;&#20013;&#25552;&#21462;&#22797;&#26434;&#21629;&#21517;&#23454;&#20307;
&lt;/p&gt;
&lt;p&gt;
Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection. (arXiv:2305.05836v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24369;&#30417;&#30563;&#30446;&#26631;&#26816;&#27979;&#19982;&#25991;&#26723;&#24067;&#23616;&#20998;&#26512;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#22312;&#27861;&#24459;&#25991;&#20214;&#20013;&#25552;&#21462;&#19981;&#36830;&#32493;&#30340;&#22797;&#26434;&#21629;&#21517;&#23454;&#20307;&#65292;&#19988;&#27169;&#22411;&#22312;&#37329;&#26631;&#20934;&#25968;&#25454;&#26377;&#38480;&#26102;&#20173;&#26377;&#20248;&#24322;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#23545;&#20110;&#24037;&#19994;&#30028;&#30340;&#21508;&#31181;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20256;&#32479;NER&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#30528;&#36827;&#23637;&#65292;&#20294;&#22797;&#26434;&#21629;&#21517;&#23454;&#20307;&#30340;&#25552;&#21462;&#20173;&#28982;&#26159;&#19968;&#20010;&#30456;&#23545;&#26410;&#34987;&#24320;&#21457;&#30340;&#39046;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31995;&#32479;&#65292;&#23427;&#23558;&#25991;&#26723;&#24067;&#23616;&#20998;&#26512;&#65288;DLA&#65289;&#20013;&#30340;&#30446;&#26631;&#26816;&#27979;&#19982;&#24369;&#30417;&#30563;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#35299;&#20915;&#22312;&#27861;&#24459;&#25991;&#20214;&#20013;&#25552;&#21462;&#19981;&#36830;&#32493;&#30340;&#22797;&#26434;&#21629;&#21517;&#23454;&#20307;&#30340;&#25361;&#25112;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#23558;&#24369;&#30417;&#30563;&#24212;&#29992;&#20110;DLA&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#20165;&#22522;&#20110;&#20266;&#26631;&#31614;&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#37329;&#26631;&#20934;&#25968;&#25454;&#21463;&#38480;&#26102;&#20248;&#20110;&#26377;&#30417;&#30563;&#30340;&#22522;&#32447;&#65292;&#24432;&#26174;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20943;&#23569;&#23545;&#27880;&#37322;&#25968;&#25454;&#20381;&#36182;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate Named Entity Recognition (NER) is crucial for various information retrieval tasks in industry. However, despite significant progress in traditional NER methods, the extraction of Complex Named Entities remains a relatively unexplored area. In this paper, we propose a novel system that combines object detection for Document Layout Analysis (DLA) with weakly supervised learning to address the challenge of extracting discontinuous complex named entities in legal documents. Notably, to the best of our knowledge, this is the first work to apply weak supervision to DLA. Our experimental results show that the model trained solely on pseudo labels outperforms the supervised baseline when gold-standard data is limited, highlighting the effectiveness of our proposed approach in reducing the dependency on annotated data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20122;&#39532;&#36874;&#30340;&#26032;&#31995;&#32479;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23558;&#39038;&#23458;&#30340;&#22312;&#32447;&#34892;&#20026;&#26144;&#23556;&#25104;&#20026;&#39640;&#32423;&#21035;&#36141;&#29289;&#24847;&#22270;&#65292;&#20197;&#20415;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#25552;&#20379;&#26356;&#30456;&#20851;&#12289;&#21487;&#35299;&#37322;&#21644;&#22810;&#26679;&#21270;&#30340;&#36141;&#29289;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2305.05279</link><description>&lt;p&gt;
&#23398;&#20064;&#20010;&#24615;&#21270;&#25512;&#33616;&#20197;&#22522;&#20110;&#23458;&#25143;&#36141;&#29289;&#24847;&#22270;
&lt;/p&gt;
&lt;p&gt;
Learning to Personalize Recommendation based on Customers' Shopping Intents. (arXiv:2305.05279v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05279
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20122;&#39532;&#36874;&#30340;&#26032;&#31995;&#32479;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23558;&#39038;&#23458;&#30340;&#22312;&#32447;&#34892;&#20026;&#26144;&#23556;&#25104;&#20026;&#39640;&#32423;&#21035;&#36141;&#29289;&#24847;&#22270;&#65292;&#20197;&#20415;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#25552;&#20379;&#26356;&#30456;&#20851;&#12289;&#21487;&#35299;&#37322;&#21644;&#22810;&#26679;&#21270;&#30340;&#36141;&#29289;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#39038;&#23458;&#30340;&#39640;&#32423;&#21035;&#36141;&#29289;&#24847;&#22270;&#65292;&#22914;&#20182;&#20204;&#21435;&#38706;&#33829;&#25110;&#20030;&#21150;&#29983;&#26085;&#27966;&#23545;&#30340;&#24895;&#26395;&#65292;&#23545;&#20110;&#30005;&#21830;&#24179;&#21488;&#38750;&#24120;&#37325;&#35201;&#65307;&#23427;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#26356;&#30456;&#20851;&#12289;&#21487;&#35299;&#37322;&#21644;&#22810;&#26679;&#21270;&#30340;&#25512;&#33616;&#26469;&#25552;&#39640;&#36141;&#29289;&#20307;&#39564;&#30340;&#36136;&#37327;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23454;&#38469;&#25361;&#25112;&#65292;&#36825;&#31181;&#39640;&#32423;&#21035;&#30340;&#36141;&#29289;&#24847;&#22270;&#22312;&#34892;&#19994;&#20013;&#34987;&#24573;&#35270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20122;&#39532;&#36874;&#30340;&#26032;&#31995;&#32479;&#65292;&#26126;&#30830;&#22320;&#35782;&#21035;&#21644;&#21033;&#29992;&#27599;&#20010;&#23458;&#25143;&#30340;&#39640;&#32423;&#21035;&#36141;&#29289;&#24847;&#22270;&#26469;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#33258;&#21160;&#35782;&#21035;&#20122;&#39532;&#36874;&#23458;&#25143;&#27491;&#22312;&#36861;&#27714;&#30340;&#21508;&#31181;&#39640;&#32423;&#21035;&#30446;&#26631;&#65292;&#22914;&#8220;&#21435;&#38706;&#33829;&#8221;&#21644;&#8220;&#20934;&#22791;&#28023;&#28393;&#27966;&#23545;&#8221;&#12290;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#20102;&#25193;&#23637;&#65288;&#36328;&#36234;21&#20010;&#22269;&#23478;&#30340;14&#31181;&#35821;&#35328;&#65289;&#12290;&#28982;&#21518;&#65292;&#19968;&#20010;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23558;&#27599;&#20010;&#23458;&#25143;&#30340;&#22312;&#32447;&#34892;&#20026;&#65292;&#22914;&#20135;&#21697;&#25628;&#32034;&#21644;&#20010;&#20307;&#39033;&#30446;&#21442;&#19982;&#65292;&#26144;&#23556;&#25104;&#19968;&#32452;&#39640;&#32423;&#21035;&#30340;&#36141;&#29289;&#24847;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the customers' high level shopping intent, such as their desire to go camping or hold a birthday party, is critically important for an E-commerce platform; it can help boost the quality of shopping experience by enabling provision of more relevant, explainable, and diversified recommendations. However, such high level shopping intent has been overlooked in the industry due to practical challenges. In this work, we introduce Amazon's new system that explicitly identifies and utilizes each customer's high level shopping intents for personalizing recommendations. We develop a novel technique that automatically identifies various high level goals being pursued by the Amazon customers, such as "go camping", and "preparing for a beach party". Our solution is in a scalable fashion (in 14 languages across 21 countries). Then a deep learning model maps each customer's online behavior, e.g. product search and individual item engagements, into a subset of high level shopping intents
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#30340; URL &#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#65292;&#20854;&#23398;&#29983;&#27169;&#22411;&#22312;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569; 175 &#20493;&#30340;&#24773;&#20917;&#19979;&#65292;&#31934;&#24230;&#25552;&#21319;&#20102; 9%&#65292;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.05027</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#30340;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Web Content Filtering through knowledge distillation of Large Language Models. (arXiv:2305.05027v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#30340; URL &#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#65292;&#20854;&#23398;&#29983;&#27169;&#22411;&#22312;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569; 175 &#20493;&#30340;&#24773;&#20917;&#19979;&#65292;&#31934;&#24230;&#25552;&#21319;&#20102; 9%&#65292;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340; URL &#20998;&#31867;&#26041;&#27861;&#65292;&#26088;&#22312;&#23454;&#29616;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#30340;&#20027;&#35201;&#30446;&#26631;&#65306;&#20445;&#38556;&#32452;&#32455;&#20813;&#21463;&#27861;&#24459;&#21644;&#20262;&#29702;&#39118;&#38505;&#65292;&#38480;&#21046;&#35775;&#38382;&#39640;&#39118;&#38505;&#25110;&#21487;&#30097;&#32593;&#31449;&#65292;&#20197;&#21450;&#20419;&#36827;&#23433;&#20840;&#30340;&#19987;&#19994;&#24037;&#20316;&#29615;&#22659;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20934;&#30830;&#30340;&#20998;&#31867;&#65292;&#24182;&#21033;&#29992;&#24050;&#26377;&#30340;&#30693;&#35782;&#33976;&#39311;&#25216;&#26415;&#21019;&#24314;&#26356;&#23567;&#12289;&#26356;&#19987;&#19994;&#30340;&#23398;&#29983;&#27169;&#22411;&#65292;&#20197;&#29992;&#20110;&#32593;&#32476;&#20869;&#23481;&#36807;&#28388;&#12290;&#22312;&#23558;&#36890;&#36807;&#22823;&#22411;&#23433;&#20840;&#20379;&#24212;&#21830;&#25910;&#38598;&#30340;&#23458;&#25143;&#36965;&#27979;&#25968;&#25454;&#30340; 30 &#20010;&#19981;&#21516;&#20869;&#23481;&#31867;&#21035;&#30340;&#32593;&#31449;&#36827;&#34892;&#20998;&#31867;&#30340;&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#30340;&#23398;&#29983;&#27169;&#22411;&#36890;&#36807;&#33976;&#39311;&#32467;&#26524;&#23454;&#29616;&#20102; 9% &#30340;&#20998;&#31867;&#31934;&#24230;&#25552;&#21319;&#65292;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23398;&#29983;&#27169;&#22411;&#22312;&#21442;&#25968;&#25968;&#37327;&#19978;&#19982;&#21407;&#22987;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#30456;&#27604;&#20943;&#23569;&#20102; 175 &#20493;&#65292;&#20174;&#32780;&#36798;&#21040;&#20102;&#19982;&#32769;&#24072;&#27169;&#22411;&#30456;&#21305;&#37197;&#30340;&#24615;&#33021;&#65292;&#21487;&#20197;&#29992;&#20110;&#22823;&#35268;&#27169;&#30340;&#22312;&#32447;&#25195;&#25551;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a state-of-the-art approach for URL categorization that leverages the power of Large Language Models (LLMs) to address the primary objectives of web content filtering: safeguarding organizations from legal and ethical risks, limiting access to high-risk or suspicious websites, and fostering a secure and professional work environment. Our method utilizes LLMs to generate accurate classifications and then employs established knowledge distillation techniques to create smaller, more specialized student models tailored for web content filtering. Distillation results in a student model with a 9\% accuracy rate improvement in classifying websites, sourced from customer telemetry data collected by a large security vendor, into 30 distinct content categories based on their URLs, surpassing the current state-of-the-art approach. Our student model matches the performance of the teacher LLM with 175 times less parameters, allowing the model to be used for in-line scanning of large vo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26412;&#22320;&#26032;&#38395;&#26816;&#27979;&#21644;&#22522;&#20110;&#20869;&#23481;&#30340;&#26412;&#22320;&#26032;&#38395;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#24369;&#30417;&#30563;&#26694;&#26550;&#21644;&#33258;&#21160;&#21270;&#25968;&#25454;&#22788;&#29702;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#35206;&#30422;&#29575;&#12290;</title><link>http://arxiv.org/abs/2301.08146</link><description>&lt;p&gt;
&#20320;&#25152;&#22312;&#31038;&#21306;&#21457;&#29983;&#20102;&#20160;&#20040;&#65311;&#19968;&#31181;&#24369;&#30417;&#30563;&#26041;&#27861;&#29992;&#20110;&#21457;&#29616;&#26412;&#22320;&#26032;&#38395;&#12290;
&lt;/p&gt;
&lt;p&gt;
What's happening in your neighborhood? A Weakly Supervised Approach to Detect Local News. (arXiv:2301.08146v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08146
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26412;&#22320;&#26032;&#38395;&#26816;&#27979;&#21644;&#22522;&#20110;&#20869;&#23481;&#30340;&#26412;&#22320;&#26032;&#38395;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#24369;&#30417;&#30563;&#26694;&#26550;&#21644;&#33258;&#21160;&#21270;&#25968;&#25454;&#22788;&#29702;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#22320;&#26032;&#38395;&#26159;&#24433;&#21709;&#29305;&#23450;&#22320;&#29702;&#21306;&#22495;&#65288;&#22914;&#22478;&#24066;&#12289;&#21439;&#21644;&#24030;&#65289;&#29992;&#25143;&#30340;&#26032;&#38395;&#23376;&#38598;&#12290;&#26816;&#27979;&#26412;&#22320;&#26032;&#38395;&#26159;&#20934;&#30830;&#22320;&#25512;&#33616;&#26412;&#22320;&#26032;&#38395;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#22522;&#20110;&#26368;&#26032;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#38598;&#25104;&#21270;&#30340;&#27969;&#31243;&#65292;&#23454;&#29616;&#20102;&#33258;&#21160;&#21270;&#26412;&#22320;&#26032;&#38395;&#26816;&#27979;&#21644;&#22522;&#20110;&#20869;&#23481;&#30340;&#26412;&#22320;&#26032;&#38395;&#25512;&#33616;&#12290;&#26412;&#25991;&#30528;&#37325;&#20171;&#32461;&#20102;&#31649;&#36947;&#30340;&#31532;&#19968;&#27493;&#39588;&#65306;&#65288;1&#65289;&#32467;&#21512;&#39046;&#22495;&#30693;&#35782;&#21644;&#33258;&#21160;&#25968;&#25454;&#22788;&#29702;&#30340;&#24369;&#30417;&#30563;&#26694;&#26550;&#65292;&#65288;2&#65289;&#21487;&#25193;&#23637;&#21040;&#22810;&#35821;&#35328;&#35774;&#32622;&#12290;&#19982;&#26031;&#22374;&#31119;CoreNLP NER&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#27969;&#31243;&#22312;&#32463;&#36807;&#30495;&#23454;&#19990;&#30028;&#21644;&#20154;&#24037;&#26631;&#35760;&#25968;&#25454;&#30340;&#35780;&#20272;&#26102;&#20855;&#26377;&#26356;&#39640;&#30340;&#31934;&#24230;&#21644;&#21484;&#22238;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Local news articles are a subset of news that impact users in a geographical area, such as a city, county, or state. Detecting local news (Step 1) and subsequently deciding its geographical location as well as radius of impact (Step 2) are two important steps towards accurate local news recommendation. Naive rule-based methods, such as detecting city names from the news title, tend to give erroneous results due to lack of understanding of the news content. Empowered by the latest development in natural language processing, we develop an integrated pipeline that enables automatic local news detection and content-based local news recommendations. In this paper, we focus on Step 1 of the pipeline, which highlights: (1) a weakly supervised framework incorporated with domain knowledge and auto data processing, and (2) scalability to multi-lingual settings. Compared with Stanford CoreNLP NER model, our pipeline has higher precision and recall evaluated on a real-world and human-labeled datas
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25910;&#38598;Stack Overflow&#20013;&#19982;Pandas&#20027;&#39064;&#35752;&#35770;&#30456;&#20851;&#30340;&#24086;&#23376;&#65292;&#36827;&#34892;&#20027;&#39064;&#24314;&#27169;&#65292;&#21457;&#29616;&#20102;Pandas&#25968;&#25454;&#25805;&#20316;&#12289;&#25968;&#25454;&#20998;&#26512;&#21644;&#25968;&#25454;&#21487;&#35270;&#21270;&#31561;&#20027;&#39064;&#38750;&#24120;&#21463;&#27426;&#36814;&#65292;&#32780;&#25968;&#25454;&#28165;&#27927;&#21644;&#25968;&#25454;&#25366;&#25496;&#31561;&#20027;&#39064;&#30456;&#23545;&#36739;&#38590;&#12290;</title><link>http://arxiv.org/abs/2210.03519</link><description>&lt;p&gt;
&#24320;&#21457;&#32773;&#22914;&#20309;&#35752;&#35770;Pandas&#20027;&#39064;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Empirical Study on How the Developers Discussed about Pandas Topics. (arXiv:2210.03519v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.03519
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25910;&#38598;Stack Overflow&#20013;&#19982;Pandas&#20027;&#39064;&#35752;&#35770;&#30456;&#20851;&#30340;&#24086;&#23376;&#65292;&#36827;&#34892;&#20027;&#39064;&#24314;&#27169;&#65292;&#21457;&#29616;&#20102;Pandas&#25968;&#25454;&#25805;&#20316;&#12289;&#25968;&#25454;&#20998;&#26512;&#21644;&#25968;&#25454;&#21487;&#35270;&#21270;&#31561;&#20027;&#39064;&#38750;&#24120;&#21463;&#27426;&#36814;&#65292;&#32780;&#25968;&#25454;&#28165;&#27927;&#21644;&#25968;&#25454;&#25366;&#25496;&#31561;&#20027;&#39064;&#30456;&#23545;&#36739;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Pandas&#26159;Python&#32534;&#31243;&#35821;&#35328;&#20013;&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#30340;&#36719;&#20214;&#24211;&#12290;&#30001;&#20110;Pandas&#26159;&#19968;&#31181;&#24555;&#36895;&#12289;&#26131;&#20110;&#20351;&#29992;&#19988;&#24320;&#28304;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#65292;&#22240;&#27492;&#23427;&#22312;&#36719;&#20214;&#24037;&#31243;&#39033;&#30446;&#65288;&#22914;&#36719;&#20214;&#24320;&#21457;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#26426;&#22120;&#20154;&#25216;&#26415;&#31561;&#65289;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#22240;&#27492;&#65292;&#36719;&#20214;&#24320;&#21457;&#32773;&#23545;Pandas&#34920;&#29616;&#20986;&#20102;&#24040;&#22823;&#30340;&#20852;&#36259;&#65292;&#24182;&#19988;&#29616;&#22312;&#22312;&#32447;&#24320;&#21457;&#32773;&#35770;&#22363;&#65288;&#22914;Stack Overflow&#65289;&#20013;&#30340;&#35752;&#35770;&#25968;&#37327;&#20063;&#36234;&#26469;&#36234;&#22810;&#12290;&#36825;&#20123;&#35752;&#35770;&#21487;&#20197;&#24110;&#21161;&#20102;&#35299;Pandas&#24211;&#30340;&#21463;&#27426;&#36814;&#31243;&#24230;&#65292;&#20063;&#21487;&#20197;&#24110;&#21161;&#20102;&#35299;Pandas&#20027;&#39064;&#30340;&#37325;&#35201;&#24615;&#12289;&#26222;&#21450;&#29575;&#21644;&#22256;&#38590;&#31243;&#24230;&#12290;&#26412;&#30740;&#31350;&#30340;&#20027;&#35201;&#30446;&#30340;&#26159;&#25214;&#21040;Pandas&#20027;&#39064;&#30340;&#21463;&#27426;&#36814;&#31243;&#24230;&#21644;&#22256;&#38590;&#31243;&#24230;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19982;Pandas&#20027;&#39064;&#35752;&#35770;&#30456;&#20851;&#30340;Stack Overflow&#24086;&#23376;&#65292;&#23545;&#24086;&#23376;&#30340;&#25991;&#26412;&#20869;&#23481;&#36827;&#34892;&#20102;&#20027;&#39064;&#24314;&#27169;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;26&#20010;&#20027;&#39064;&#65292;&#36827;&#19968;&#27493;&#23558;&#20854;&#20998;&#31867;&#20026;5&#20010;&#24191;&#27867;&#30340;&#31867;&#21035;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#26368;&#21463;&#27426;&#36814;&#30340;&#20027;&#39064;&#26159;&#19982;&#25968;&#25454;&#25805;&#20316;&#12289;&#25968;&#25454;&#20998;&#26512;&#21644;&#25968;&#25454;&#21487;&#35270;&#21270;&#30456;&#20851;&#30340;&#20027;&#39064;&#65292;&#32780;&#26368;&#22256;&#38590;&#30340;&#20027;&#39064;&#19982;&#25968;&#25454;&#28165;&#27927;&#21644;&#25968;&#25454;&#25366;&#25496;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pandas is defined as a software library which is used for data analysis in Python programming language. As pandas is a fast, easy and open source data analysis tool, it is rapidly used in different software engineering projects like software development, machine learning, computer vision, natural language processing, robotics, and others. So a huge interests are shown in software developers regarding pandas and a huge number of discussions are now becoming dominant in online developer forums, like Stack Overflow (SO). Such discussions can help to understand the popularity of pandas library and also can help to understand the importance, prevalence, difficulties of pandas topics. The main aim of this research paper is to find the popularity and difficulty of pandas topics. For this regard, SO posts are collected which are related to pandas topic discussions. Topic modeling are done on the textual contents of the posts. We found 26 topics which we further categorized into 5 board categor
&lt;/p&gt;</description></item></channel></rss>