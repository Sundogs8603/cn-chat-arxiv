<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>GATSY&#26159;&#19968;&#20010;&#22522;&#20110;&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;&#30340;&#38899;&#20048;&#33402;&#26415;&#23478;&#30456;&#20284;&#24615;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#28789;&#27963;&#22320;&#22788;&#29702;&#22810;&#26679;&#24615;&#21644;&#20851;&#32852;&#24615;&#65292;&#24182;&#22312;&#19981;&#20381;&#36182;&#25163;&#24037;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#21331;&#36234;&#30340;&#24615;&#33021;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.00635</link><description>&lt;p&gt;
GATSY: &#38899;&#20048;&#33402;&#26415;&#23478;&#30456;&#20284;&#24615;&#30340;&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
GATSY: Graph Attention Network for Music Artist Similarity. (arXiv:2311.00635v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00635
&lt;/p&gt;
&lt;p&gt;
GATSY&#26159;&#19968;&#20010;&#22522;&#20110;&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;&#30340;&#38899;&#20048;&#33402;&#26415;&#23478;&#30456;&#20284;&#24615;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#28789;&#27963;&#22320;&#22788;&#29702;&#22810;&#26679;&#24615;&#21644;&#20851;&#32852;&#24615;&#65292;&#24182;&#22312;&#19981;&#20381;&#36182;&#25163;&#24037;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#21331;&#36234;&#30340;&#24615;&#33021;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33402;&#26415;&#23478;&#30456;&#20284;&#24615;&#38382;&#39064;&#24050;&#32463;&#25104;&#20026;&#31038;&#20250;&#21644;&#31185;&#23398;&#29615;&#22659;&#20013;&#30340;&#37325;&#35201;&#35838;&#39064;&#12290;&#29616;&#20195;&#30740;&#31350;&#35299;&#20915;&#26041;&#26696;&#26681;&#25454;&#29992;&#25143;&#30340;&#21916;&#22909;&#26469;&#20419;&#36827;&#38899;&#20048;&#21457;&#29616;&#12290;&#28982;&#32780;&#65292;&#23450;&#20041;&#33402;&#26415;&#23478;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#21487;&#33021;&#28041;&#21450;&#22810;&#20010;&#26041;&#38754;&#65292;&#29978;&#33267;&#19982;&#20027;&#35266;&#35282;&#24230;&#30456;&#20851;&#65292;&#24182;&#19988;&#32463;&#24120;&#24433;&#21709;&#25512;&#33616;&#32467;&#26524;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;GATSY&#65292;&#36825;&#26159;&#19968;&#20010;&#24314;&#31435;&#22312;&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;&#19978;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#24182;&#30001;&#33402;&#26415;&#23478;&#30340;&#32858;&#31867;&#23884;&#20837;&#39537;&#21160;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#21033;&#29992;&#36755;&#20837;&#25968;&#25454;&#30340;&#22270;&#25299;&#25169;&#32467;&#26500;&#65292;&#22312;&#19981;&#36807;&#20998;&#20381;&#36182;&#25163;&#24037;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#32467;&#26524;&#12290;&#36825;&#31181;&#28789;&#27963;&#24615;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#38899;&#20048;&#25968;&#25454;&#38598;&#20013;&#24341;&#20837;&#34394;&#26500;&#30340;&#33402;&#26415;&#23478;&#65292;&#19982;&#20197;&#21069;&#19981;&#30456;&#20851;&#30340;&#33402;&#26415;&#23478;&#24314;&#31435;&#32852;&#31995;&#65292;&#24182;&#26681;&#25454;&#21487;&#33021;&#30340;&#24322;&#36136;&#26469;&#28304;&#33719;&#24471;&#25512;&#33616;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The artist similarity quest has become a crucial subject in social and scientific contexts. Modern research solutions facilitate music discovery according to user tastes. However, defining similarity among artists may involve several aspects, even related to a subjective perspective, and it often affects a recommendation. This paper presents GATSY, a recommendation system built upon graph attention networks and driven by a clusterized embedding of artists. The proposed framework takes advantage of a graph topology of the input data to achieve outstanding performance results without relying heavily on hand-crafted features. This flexibility allows us to introduce fictitious artists in a music dataset, create bridges to previously unrelated artists, and get recommendations conditioned by possibly heterogeneous sources. Experimental results prove the effectiveness of the proposed method with respect to state-of-the-art solutions.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#21644;&#35838;&#31243;&#20381;&#36182;&#24615;&#30340;&#20004;&#38454;&#27573;&#27169;&#22411;&#30340;&#35838;&#31243;&#25512;&#33616;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#32570;&#20047;&#35780;&#20998;&#21644;&#20803;&#25968;&#25454;&#12289;&#35838;&#31243;&#27880;&#20876;&#20998;&#24067;&#19981;&#22343;&#34913;&#20197;&#21450;&#35838;&#31243;&#20381;&#36182;&#24314;&#27169;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;0.97&#30340;AUC&#24471;&#20998;&#12290;</title><link>http://arxiv.org/abs/2311.00612</link><description>&lt;p&gt;
&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#21644;&#35838;&#31243;&#20381;&#36182;&#24615;&#30340;&#20004;&#38454;&#27573;&#27169;&#22411;&#30340;&#35838;&#31243;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
A Collaborative Filtering-Based Two Stage Model with Item Dependency for Course Recommendation. (arXiv:2311.00612v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#21644;&#35838;&#31243;&#20381;&#36182;&#24615;&#30340;&#20004;&#38454;&#27573;&#27169;&#22411;&#30340;&#35838;&#31243;&#25512;&#33616;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#32570;&#20047;&#35780;&#20998;&#21644;&#20803;&#25968;&#25454;&#12289;&#35838;&#31243;&#27880;&#20876;&#20998;&#24067;&#19981;&#22343;&#34913;&#20197;&#21450;&#35838;&#31243;&#20381;&#36182;&#24314;&#27169;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;0.97&#30340;AUC&#24471;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#32463;&#30740;&#31350;&#20102;&#20960;&#21313;&#24180;&#65292;&#25552;&#20986;&#20102;&#35768;&#22810;&#26377;&#21069;&#26223;&#30340;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#27169;&#22411;&#30001;&#20110;&#22312;&#25512;&#33616;&#20013;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#24182;&#28040;&#38500;&#20102;&#38544;&#31169;&#38382;&#39064;&#65292;&#34987;&#35748;&#20026;&#26159;&#26368;&#25104;&#21151;&#30340;&#19968;&#31181;&#12290;&#26412;&#25991;&#23558;CF&#27169;&#22411;&#25193;&#23637;&#21040;&#35838;&#31243;&#25512;&#33616;&#20219;&#21153;&#20013;&#12290;&#25105;&#20204;&#25351;&#20986;&#20102;&#23558;&#29616;&#26377;&#30340;CF&#27169;&#22411;&#24212;&#29992;&#20110;&#26500;&#24314;&#35838;&#31243;&#25512;&#33616;&#24341;&#25806;&#26102;&#38754;&#20020;&#30340;&#20960;&#20010;&#25361;&#25112;&#65292;&#21253;&#25324;&#32570;&#20047;&#35780;&#20998;&#21644;&#20803;&#25968;&#25454;&#65292;&#35838;&#31243;&#27880;&#20876;&#20998;&#24067;&#19981;&#22343;&#34913;&#20197;&#21450;&#35838;&#31243;&#20381;&#36182;&#24314;&#27169;&#30340;&#38656;&#27714;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#30340;&#24819;&#27861;&#12290;&#26368;&#32456;&#65292;&#25105;&#20204;&#23558;&#22522;&#20110;&#35838;&#31243;&#20381;&#36182;&#24615;&#27491;&#21017;&#21270;&#30340;&#20004;&#38454;&#27573;CF&#27169;&#22411;&#19982;&#22522;&#20110;&#35838;&#31243;&#36716;&#25442;&#32593;&#32476;&#30340;&#22270;&#24418;&#25512;&#33616;&#22120;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;0.97&#30340;AUC&#24471;&#20998;&#65292;&#24182;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have been studied for decades with numerous promising models been proposed. Among them, Collaborative Filtering (CF) models are arguably the most successful one due to its high accuracy in recommendation and elimination of privacy-concerned personal meta-data from training. This paper extends the usage of CF-based model to the task of course recommendation. We point out several challenges in applying the existing CF-models to build a course recommendation engine, including the lack of rating and meta-data, the imbalance of course registration distribution, and the demand of course dependency modeling. We then propose several ideas to address these challenges. Eventually, we combine a two-stage CF model regularized by course dependency with a graph-based recommender based on course-transition network, to achieve AUC as high as 0.97 with a real-world dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#22686;&#24378;&#30340;&#22810;&#35270;&#35282;&#27880;&#24847;&#21147;&#32593;&#32476;&#26469;&#35299;&#20915;POI&#25512;&#33616;&#20013;&#19981;&#30830;&#23450;&#22240;&#32032;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#26500;&#24314;&#20010;&#20154;POI&#36716;&#25442;&#22270;&#12289;&#22522;&#20110;&#35821;&#20041;&#30340;POI&#22270;&#21644;&#22522;&#20110;&#36317;&#31163;&#30340;POI&#22270;&#26469;&#20840;&#38754;&#24314;&#27169;&#20381;&#36182;&#20851;&#31995;&#65292;&#25552;&#39640;POI&#25512;&#33616;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.00491</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#22686;&#24378;&#30340;&#22810;&#35270;&#35282;&#27880;&#24847;&#21147;&#32593;&#32476;&#29992;&#20110;&#24378;&#22823;&#30340;POI&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Bayes-enhanced Multi-view Attention Networks for Robust POI Recommendation. (arXiv:2311.00491v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00491
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#22686;&#24378;&#30340;&#22810;&#35270;&#35282;&#27880;&#24847;&#21147;&#32593;&#32476;&#26469;&#35299;&#20915;POI&#25512;&#33616;&#20013;&#19981;&#30830;&#23450;&#22240;&#32032;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#26500;&#24314;&#20010;&#20154;POI&#36716;&#25442;&#22270;&#12289;&#22522;&#20110;&#35821;&#20041;&#30340;POI&#22270;&#21644;&#22522;&#20110;&#36317;&#31163;&#30340;POI&#22270;&#26469;&#20840;&#38754;&#24314;&#27169;&#20381;&#36182;&#20851;&#31995;&#65292;&#25552;&#39640;POI&#25512;&#33616;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
POI&#25512;&#33616;&#22312;&#20419;&#36827;&#21508;&#31181;&#22522;&#20110;&#20301;&#32622;&#30340;&#31038;&#20132;&#32593;&#32476;&#26381;&#21153;&#26041;&#38754;&#20855;&#26377;&#23454;&#38469;&#37325;&#35201;&#24615;&#65292;&#24182;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#12290;&#29616;&#26377;&#30340;&#20316;&#21697;&#36890;&#24120;&#20551;&#35774;&#29992;&#25143;&#25253;&#21578;&#30340;&#21487;&#29992;POI&#31614;&#21040;&#26159;&#29992;&#25143;&#34892;&#20026;&#30340;&#21807;&#19968;&#25551;&#36848;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#30001;&#20110;&#20027;&#35266;&#21644;&#23458;&#35266;&#21407;&#22240;&#65288;&#21253;&#25324;&#23450;&#20301;&#35823;&#24046;&#21644;&#29992;&#25143;&#38544;&#31169;&#38382;&#39064;&#65289;&#65292;&#31614;&#21040;&#25968;&#25454;&#21487;&#33021;&#30456;&#24403;&#19981;&#21487;&#38752;&#65292;&#36825;&#23545;POI&#25512;&#33616;&#30340;&#24615;&#33021;&#36896;&#25104;&#20102;&#26174;&#33879;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#32771;&#34385;&#29992;&#25143;&#31614;&#21040;&#30340;&#19981;&#30830;&#23450;&#22240;&#32032;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#22686;&#24378;&#30340;&#22810;&#35270;&#35282;&#27880;&#24847;&#21147;&#32593;&#32476;&#26469;&#36827;&#34892;&#24378;&#22823;&#30340;POI&#25512;&#33616;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#20010;&#20154;POI&#36716;&#25442;&#22270;&#12289;&#22522;&#20110;&#35821;&#20041;&#30340;POI&#22270;&#21644;&#22522;&#20110;&#36317;&#31163;&#30340;POI&#22270;&#65292;&#20840;&#38754;&#24314;&#27169;&#20102;POI&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#30001;&#20110;&#20010;&#20154;POI&#36716;&#25442;&#22270;&#36890;&#24120;&#31232;&#30095;&#19988;&#23545;&#22122;&#22768;&#25935;&#24863;&#65292;&#25152;&#20197;&#25105;&#20204;&#24341;&#20837;&#20102;&#36125;&#21494;&#26031;&#26041;&#27861;&#26469;&#22686;&#24378;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
POI recommendation is practically important to facilitate various Location-Based Social Network services, and has attracted rising research attention recently. Existing works generally assume the available POI check-ins reported by users are the ground-truth depiction of user behaviors. However, in real application scenarios, the check-in data can be rather unreliable due to both subjective and objective causes including positioning error and user privacy concerns, leading to significant negative impacts on the performance of the POI recommendation. To this end, we investigate a novel problem of robust POI recommendation by considering the uncertainty factors of the user check-ins, and proposes a Bayes-enhanced Multi-view Attention Network. Specifically, we construct personal POI transition graph, the semantic-based POI graph and distance-based POI graph to comprehensively model the dependencies among the POIs. As the personal POI transition graph is usually sparse and sensitive to noi
&lt;/p&gt;</description></item><item><title>LLMRec&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#32570;&#24615;&#21644;&#38468;&#21152;&#20449;&#24687;&#24341;&#20837;&#21103;&#20316;&#29992;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#24378;&#20132;&#20114;&#36793;&#12289;&#22686;&#24378;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#29702;&#35299;&#21644;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.00423</link><description>&lt;p&gt;
LLMRec: &#20351;&#29992;&#22270;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
LLMRec: Large Language Models with Graph Augmentation for Recommendation. (arXiv:2311.00423v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00423
&lt;/p&gt;
&lt;p&gt;
LLMRec&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#32570;&#24615;&#21644;&#38468;&#21152;&#20449;&#24687;&#24341;&#20837;&#21103;&#20316;&#29992;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#24378;&#20132;&#20114;&#36793;&#12289;&#22686;&#24378;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#29702;&#35299;&#21644;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31232;&#30095;&#24615;&#19968;&#30452;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#65292;&#20043;&#21069;&#30340;&#30740;&#31350;&#23581;&#35797;&#36890;&#36807;&#24341;&#20837;&#38468;&#21152;&#20449;&#24687;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24448;&#24448;&#20250;&#24102;&#26469;&#22122;&#22768;&#12289;&#21487;&#29992;&#24615;&#38382;&#39064;&#21644;&#25968;&#25454;&#36136;&#37327;&#20302;&#19979;&#31561;&#21103;&#20316;&#29992;&#65292;&#20174;&#32780;&#24433;&#21709;&#23545;&#29992;&#25143;&#20559;&#22909;&#30340;&#20934;&#30830;&#24314;&#27169;&#65292;&#36827;&#32780;&#23545;&#25512;&#33616;&#24615;&#33021;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#37492;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#30693;&#35782;&#24211;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LLMRec&#30340;&#26032;&#26694;&#26550;&#65292;&#23427;&#36890;&#36807;&#37319;&#29992;&#19977;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22522;&#20110;LLM&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22312;&#32447;&#24179;&#21488;&#65288;&#22914;Netflix&#65292;MovieLens&#65289;&#20013;&#20016;&#23500;&#30340;&#20869;&#23481;&#65292;&#22312;&#19977;&#20010;&#26041;&#38754;&#22686;&#24378;&#20132;&#20114;&#22270;&#65306;&#65288;i&#65289;&#21152;&#24378;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#36793;&#65292;&#65288;ii&#65289;&#22686;&#24378;&#23545;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#30340;&#29702;&#35299;&#65292;&#65288;iii&#65289;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#65292;&#30452;&#35266;&#22320;&#34920;&#31034;&#29992;&#25143;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies. Our approach leverages the rich content available within online platforms (e.g., Netflix, MovieLens) to augment the interaction graph in three ways: (i) reinforcing user-item interaction egde, (ii) enhancing the understanding of item node attributes, and (iii) conducting user node profiling, intuiti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;AutoSAM&#30340;&#33258;&#21160;&#37319;&#26679;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#36830;&#32493;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29992;&#25143;&#34892;&#20026;&#36827;&#34892;&#38750;&#22343;&#21248;&#22788;&#29702;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#21382;&#21490;&#34892;&#20026;&#30340;&#20559;&#26012;&#20998;&#24067;&#65292;&#24182;&#37319;&#26679;&#20986;&#20449;&#24687;&#20016;&#23500;&#30340;&#23376;&#38598;&#65292;&#20197;&#26500;&#24314;&#26356;&#20855;&#21487;&#27867;&#21270;&#24615;&#30340;&#36830;&#32493;&#25512;&#33616;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2311.00388</link><description>&lt;p&gt;
&#23454;&#29616;&#33258;&#21160;&#37319;&#26679;&#23545;&#20110;&#36830;&#32493;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#34892;&#20026;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Automatic Sampling of User Behaviors for Sequential Recommender Systems. (arXiv:2311.00388v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;AutoSAM&#30340;&#33258;&#21160;&#37319;&#26679;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#36830;&#32493;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29992;&#25143;&#34892;&#20026;&#36827;&#34892;&#38750;&#22343;&#21248;&#22788;&#29702;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#21382;&#21490;&#34892;&#20026;&#30340;&#20559;&#26012;&#20998;&#24067;&#65292;&#24182;&#37319;&#26679;&#20986;&#20449;&#24687;&#20016;&#23500;&#30340;&#23376;&#38598;&#65292;&#20197;&#26500;&#24314;&#26356;&#20855;&#21487;&#27867;&#21270;&#24615;&#30340;&#36830;&#32493;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#36830;&#32493;&#25512;&#33616;&#31995;&#32479;&#33021;&#22815;&#26377;&#25928;&#25429;&#25417;&#21160;&#24577;&#29992;&#25143;&#20559;&#22909;&#65292;&#22240;&#27492;&#23427;&#20204;&#22312;&#25512;&#33616;&#39046;&#22495;&#20013;&#24191;&#21463;&#27426;&#36814;&#12290;&#24403;&#21069;&#36830;&#32493;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#20010;&#40664;&#35748;&#35774;&#32622;&#26159;&#23558;&#27599;&#20010;&#21382;&#21490;&#34892;&#20026;&#22343;&#21248;&#22320;&#35270;&#20026;&#27491;&#21521;&#20132;&#20114;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#19978;&#65292;&#36825;&#31181;&#35774;&#32622;&#26377;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#65292;&#22240;&#20026;&#27599;&#20010;&#21830;&#21697;&#23545;&#29992;&#25143;&#30340;&#20852;&#36259;&#26377;&#19981;&#21516;&#30340;&#36129;&#29486;&#12290;&#20363;&#22914;&#65292;&#36141;&#20080;&#30340;&#21830;&#21697;&#24212;&#35813;&#27604;&#28857;&#20987;&#30340;&#21830;&#21697;&#26356;&#37325;&#35201;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#33258;&#21160;&#37319;&#26679;&#26694;&#26550;&#65292;&#21517;&#20026;AutoSAM&#65292;&#29992;&#20110;&#38750;&#22343;&#21248;&#22320;&#22788;&#29702;&#21382;&#21490;&#34892;&#20026;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;AutoSAM&#36890;&#36807;&#22312;&#26631;&#20934;&#30340;&#36830;&#32493;&#25512;&#33616;&#26550;&#26500;&#20013;&#22686;&#21152;&#19968;&#20010;&#37319;&#26679;&#22120;&#23618;&#65292;&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#21407;&#22987;&#36755;&#20837;&#30340;&#20559;&#26012;&#20998;&#24067;&#65292;&#24182;&#37319;&#26679;&#20986;&#20449;&#24687;&#20016;&#23500;&#30340;&#23376;&#38598;&#65292;&#20197;&#26500;&#24314;&#26356;&#20855;&#21487;&#27867;&#21270;&#24615;&#30340;&#36830;&#32493;&#25512;&#33616;&#31995;&#32479;&#12290;&#20026;&#20102;&#20811;&#26381;&#38750;&#21487;&#24494;&#20998;&#37319;&#26679;&#25805;&#20316;&#30340;&#25361;&#25112;&#65292;&#21516;&#26102;&#24341;&#20837;&#22810;&#20010;&#20915;&#31574;&#22240;&#32032;&#36827;&#34892;&#37319;&#26679;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#36827;&#19968;&#27493;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommender systems (SRS) have gained widespread popularity in recommendation due to their ability to effectively capture dynamic user preferences. One default setting in the current SRS is to uniformly consider each historical behavior as a positive interaction. Actually, this setting has the potential to yield sub-optimal performance, as each item makes a distinct contribution to the user's interest. For example, purchased items should be given more importance than clicked ones. Hence, we propose a general automatic sampling framework, named AutoSAM, to non-uniformly treat historical behaviors. Specifically, AutoSAM augments the standard sequential recommendation architecture with an additional sampler layer to adaptively learn the skew distribution of the raw input, and then sample informative sub-sets to build more generalizable SRS. To overcome the challenges of non-differentiable sampling actions and also introduce multiple decision factors for sampling, we further int
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#21517;&#20026;Caseformer&#65292;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#35299;&#20915;&#20102;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2311.00333</link><description>&lt;p&gt;
Caseformer: &#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#30340;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Caseformer: Pre-training for Legal Case Retrieval. (arXiv:2311.00333v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00333
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#21517;&#20026;Caseformer&#65292;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#35299;&#20915;&#20102;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#26088;&#22312;&#24110;&#21161;&#27861;&#24459;&#24037;&#20316;&#32773;&#25214;&#21040;&#19982;&#20182;&#20204;&#25163;&#22836;&#26696;&#20214;&#30456;&#20851;&#30340;&#26696;&#20363;&#65292;&#36825;&#23545;&#20110;&#20445;&#35777;&#20844;&#24179;&#21644;&#27491;&#20041;&#30340;&#27861;&#24459;&#21028;&#20915;&#38750;&#24120;&#37325;&#35201;&#12290;&#23613;&#31649;&#26368;&#36817;&#31070;&#32463;&#26816;&#32034;&#26041;&#27861;&#22312;&#24320;&#25918;&#22495;&#26816;&#32034;&#20219;&#21153;&#65288;&#20363;&#22914;&#32593;&#32476;&#25628;&#32034;&#65289;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20294;&#26159;&#30001;&#20110;&#23545;&#26631;&#27880;&#25968;&#25454;&#30340;&#28212;&#26395;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#24182;&#27809;&#26377;&#26174;&#31034;&#20986;&#20248;&#21183;&#12290;&#30001;&#20110;&#38656;&#35201;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#65292;&#23545;&#27861;&#24459;&#39046;&#22495;&#36827;&#34892;&#22823;&#35268;&#27169;&#35757;&#32451;&#25968;&#25454;&#30340;&#26631;&#27880;&#26159;&#22256;&#38590;&#30340;&#65292;&#22240;&#27492;&#20256;&#32479;&#30340;&#22522;&#20110;&#35789;&#27719;&#21305;&#37197;&#30340;&#25628;&#32034;&#25216;&#26415;&#65292;&#22914;TF-IDF&#12289;BM25&#21644;&#26597;&#35810;&#20284;&#28982;&#65292;&#20173;&#28982;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#31995;&#32479;&#20013;&#30427;&#34892;&#12290;&#34429;&#28982;&#20197;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35774;&#35745;&#20102;&#19968;&#20123;&#38024;&#23545;&#24320;&#25918;&#22495;&#20219;&#21153;&#20013;IR&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#20294;&#26159;&#30001;&#20110;&#26080;&#27861;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#36890;&#24120;&#26159;&#27425;&#20248;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Legal case retrieval aims to help legal workers find relevant cases related to their cases at hand, which is important for the guarantee of fairness and justice in legal judgments. While recent advances in neural retrieval methods have significantly improved the performance of open-domain retrieval tasks (e.g., Web search), their advantages have not been observed in legal case retrieval due to their thirst for annotated data. As annotating large-scale training data in legal domains is prohibitive due to the need for domain expertise, traditional search techniques based on lexical matching such as TF-IDF, BM25, and Query Likelihood are still prevalent in legal case retrieval systems. While previous studies have designed several pre-training methods for IR models in open-domain tasks, these methods are usually suboptimal in legal case retrieval because they cannot understand and capture the key knowledge and data structures in the legal corpus. To this end, we propose a novel pre-trainin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#32852;&#37030;&#20027;&#39064;&#27169;&#22411;&#21644;&#27169;&#22411;&#21098;&#26525;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36328;&#22810;&#20010;&#26041;&#21442;&#19982;&#20132;&#21449;&#20998;&#26512;&#26102;&#30340;&#25968;&#25454;&#38544;&#31169;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21098;&#26525;&#21152;&#36895;&#27169;&#22411;&#12290;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#34987;&#25552;&#20986;&#26469;&#30830;&#23450;&#27169;&#22411;&#21098;&#26525;&#29575;&#12290;</title><link>http://arxiv.org/abs/2311.00314</link><description>&lt;p&gt;
&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#32852;&#37030;&#20027;&#39064;&#27169;&#22411;&#21644;&#27169;&#22411;&#21098;&#26525;
&lt;/p&gt;
&lt;p&gt;
Federated Topic Model and Model Pruning Based on Variational Autoencoder. (arXiv:2311.00314v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#32852;&#37030;&#20027;&#39064;&#27169;&#22411;&#21644;&#27169;&#22411;&#21098;&#26525;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36328;&#22810;&#20010;&#26041;&#21442;&#19982;&#20132;&#21449;&#20998;&#26512;&#26102;&#30340;&#25968;&#25454;&#38544;&#31169;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21098;&#26525;&#21152;&#36895;&#27169;&#22411;&#12290;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#34987;&#25552;&#20986;&#26469;&#30830;&#23450;&#27169;&#22411;&#21098;&#26525;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#39064;&#24314;&#27169;&#24050;&#32463;&#25104;&#20026;&#22312;&#22823;&#35268;&#27169;&#25991;&#26723;&#38598;&#21512;&#20013;&#21457;&#29616;&#27169;&#24335;&#21644;&#20027;&#39064;&#30340;&#26377;&#20215;&#20540;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#24403;&#36328;&#22810;&#20010;&#26041;&#21442;&#19982;&#20132;&#21449;&#20998;&#26512;&#26102;&#65292;&#25968;&#25454;&#38544;&#31169;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#32852;&#37030;&#20027;&#39064;&#24314;&#27169;&#24050;&#32463;&#34987;&#24320;&#21457;&#20986;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20801;&#35768;&#22810;&#20010;&#21442;&#19982;&#26041;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21516;&#26102;&#20849;&#21516;&#35757;&#32451;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22312;&#32852;&#37030;&#22330;&#26223;&#20013;&#23384;&#22312;&#36890;&#20449;&#21644;&#24615;&#33021;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24314;&#31435;&#32852;&#37030;&#20027;&#39064;&#27169;&#22411;&#24182;&#30830;&#20445;&#27599;&#20010;&#33410;&#28857;&#38544;&#31169;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21098;&#26525;&#21152;&#36895;&#27169;&#22411;&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#23450;&#26399;&#23558;&#27169;&#22411;&#31070;&#32463;&#20803;&#32047;&#31215;&#26799;&#24230;&#21644;&#27169;&#22411;&#26435;&#37325;&#21457;&#36865;&#32473;&#26381;&#21153;&#22120;&#65292;&#26381;&#21153;&#22120;&#23545;&#27169;&#22411;&#36827;&#34892;&#21098;&#26525;&#12290;&#20026;&#20102;&#28385;&#36275;&#19981;&#21516;&#30340;&#35201;&#27714;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#30830;&#23450;&#27169;&#22411;&#21098;&#26525;&#29575;&#30340;&#19981;&#21516;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topic modeling has emerged as a valuable tool for discovering patterns and topics within large collections of documents. However, when cross-analysis involves multiple parties, data privacy becomes a critical concern. Federated topic modeling has been developed to address this issue, allowing multiple parties to jointly train models while protecting pri-vacy. However, there are communication and performance challenges in the federated sce-nario. In order to solve the above problems, this paper proposes a method to establish a federated topic model while ensuring the privacy of each node, and use neural network model pruning to accelerate the model, where the client periodically sends the model neu-ron cumulative gradients and model weights to the server, and the server prunes the model. To address different requirements, two different methods are proposed to determine the model pruning rate. The first method involves slow pruning throughout the entire model training process, which has 
&lt;/p&gt;</description></item><item><title>DistDNAS&#26159;&#19968;&#31181;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#39640;&#25928;&#25628;&#32034;&#29305;&#24449;&#20132;&#20114;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20998;&#24067;&#24335;&#25628;&#32034;&#21644;&#36873;&#25321;&#26368;&#20339;&#20132;&#20114;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#24040;&#22823;&#30340;&#21152;&#36895;&#24182;&#23558;&#25628;&#32034;&#26102;&#38388;&#20174;2&#22825;&#32553;&#30701;&#21040;2&#23567;&#26102;&#12290;</title><link>http://arxiv.org/abs/2311.00231</link><description>&lt;p&gt;
DistDNAS: &#22312;2&#23567;&#26102;&#20869;&#39640;&#25928;&#25628;&#32034;&#29305;&#24449;&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;
DistDNAS: Search Efficient Feature Interactions within 2 Hours. (arXiv:2311.00231v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00231
&lt;/p&gt;
&lt;p&gt;
DistDNAS&#26159;&#19968;&#31181;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#39640;&#25928;&#25628;&#32034;&#29305;&#24449;&#20132;&#20114;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20998;&#24067;&#24335;&#25628;&#32034;&#21644;&#36873;&#25321;&#26368;&#20339;&#20132;&#20114;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#24040;&#22823;&#30340;&#21152;&#36895;&#24182;&#23558;&#25628;&#32034;&#26102;&#38388;&#20174;2&#22825;&#32553;&#30701;&#21040;2&#23567;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25628;&#32034;&#25928;&#29575;&#21644;&#26381;&#21153;&#25928;&#29575;&#26159;&#26500;&#24314;&#29305;&#24449;&#20132;&#20114;&#21644;&#21152;&#24555;&#27169;&#22411;&#24320;&#21457;&#36807;&#31243;&#30340;&#20004;&#20010;&#20027;&#35201;&#26041;&#38754;&#12290;&#22312;&#22823;&#35268;&#27169;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#30001;&#20110;&#22823;&#37327;&#25968;&#25454;&#19978;&#30340;&#39034;&#24207;&#24037;&#20316;&#27969;&#31243;&#65292;&#25628;&#32034;&#26368;&#20339;&#29305;&#24449;&#20132;&#20114;&#35774;&#35745;&#38656;&#35201;&#20184;&#20986;&#24040;&#22823;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#34701;&#21512;&#21508;&#31181;&#26469;&#28304;&#12289;&#39034;&#24207;&#21644;&#25968;&#23398;&#36816;&#31639;&#30340;&#20132;&#20114;&#20250;&#24341;&#20837;&#28508;&#22312;&#30340;&#20914;&#31361;&#21644;&#39069;&#22806;&#30340;&#20887;&#20313;&#65292;&#23548;&#33268;&#24615;&#33021;&#21644;&#26381;&#21153;&#25104;&#26412;&#30340;&#27425;&#20248;&#26435;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;DistDNAS&#20316;&#20026;&#19968;&#31181;&#31616;&#27905;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#24555;&#36895;&#19988;&#39640;&#25928;&#22320;&#36827;&#34892;&#29305;&#24449;&#20132;&#20114;&#35774;&#35745;&#12290;DistDNAS&#25552;&#20986;&#20102;&#19968;&#20010;&#36229;&#32423;&#32593;&#32476;&#65292;&#23558;&#19981;&#21516;&#39034;&#24207;&#21644;&#31867;&#22411;&#30340;&#20132;&#20114;&#27169;&#22359;&#20316;&#20026;&#25628;&#32034;&#31354;&#38388;&#36827;&#34892;&#25972;&#21512;&#12290;&#20026;&#20102;&#20248;&#21270;&#25628;&#32034;&#25928;&#29575;&#65292;DistDNAS&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#26085;&#26399;&#19978;&#20998;&#24067;&#24335;&#25628;&#32034;&#24182;&#27719;&#24635;&#36873;&#25321;&#26368;&#20339;&#30340;&#20132;&#20114;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#36229;&#36807;25&#20493;&#30340;&#21152;&#36895;&#65292;&#23558;&#25628;&#32034;&#25104;&#26412;&#20174;2&#22825;&#20943;&#23569;&#21040;2&#23567;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Search efficiency and serving efficiency are two major axes in building feature interactions and expediting the model development process in recommender systems. On large-scale benchmarks, searching for the optimal feature interaction design requires extensive cost due to the sequential workflow on the large volume of data. In addition, fusing interactions of various sources, orders, and mathematical operations introduces potential conflicts and additional redundancy toward recommender models, leading to sub-optimal trade-offs in performance and serving cost. In this paper, we present DistDNAS as a neat solution to brew swift and efficient feature interaction design. DistDNAS proposes a supernet to incorporate interaction modules of varying orders and types as a search space. To optimize search efficiency, DistDNAS distributes the search and aggregates the choice of optimal interaction modules on varying data dates, achieving over 25x speed-up and reducing search cost from 2 days to 2 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#26292;&#38706;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#30340;&#20542;&#21521;&#21644;&#26292;&#38706;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#12290;</title><link>http://arxiv.org/abs/2310.20388</link><description>&lt;p&gt;
&#19981;&#20351;&#29992;&#26292;&#38706;&#25968;&#25454;&#30340;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#20542;&#21521;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimating Propensity for Causality-based Recommendation without Exposure Data. (arXiv:2310.20388v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#26292;&#38706;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#30340;&#20542;&#21521;&#21644;&#26292;&#38706;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#31995;&#32479;&#20851;&#27880;&#29992;&#25143;&#19982;&#29289;&#21697;&#20132;&#20114;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#21363;&#29289;&#21697;&#30340;&#25512;&#33616;&#25110;&#26292;&#38706;&#32473;&#29992;&#25143;&#30340;&#24773;&#20917;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#30340;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#25512;&#33616;&#12290;&#30001;&#20110;&#23545;&#29992;&#25143;&#12289;&#21334;&#23478;&#21644;&#24179;&#21488;&#37117;&#26377;&#22810;&#26041;&#38754;&#30340;&#22909;&#22788;&#65292;&#36825;&#31867;&#25512;&#33616;&#31995;&#32479;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#33616;&#26041;&#27861;&#38656;&#35201;&#39069;&#22806;&#30340;&#36755;&#20837;&#65292;&#21363;&#26292;&#38706;&#25968;&#25454;&#21644;/&#25110;&#20542;&#21521;&#24471;&#20998;&#65288;&#21363;&#26292;&#38706;&#30340;&#27010;&#29575;&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;&#30001;&#20110;&#25216;&#26415;&#25110;&#38544;&#31169;&#38480;&#21046;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#24448;&#24448;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#23545;&#20110;&#24314;&#27169;&#25512;&#33616;&#22240;&#26524;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#30340;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#20542;&#21521;&#20272;&#35745;&#65288;PropCare&#65289;&#12290;&#23427;&#21487;&#20197;&#20174;&#19968;&#31181;&#26356;&#23454;&#38469;&#30340;&#35774;&#32622;&#20013;&#20272;&#35745;&#20542;&#21521;&#21644;&#26292;&#38706;&#65292;&#21363;&#21482;&#26377;&#20132;&#20114;&#25968;&#25454;&#21487;&#29992;&#65292;&#27809;&#26377;&#20851;&#20110;&#26292;&#38706;&#25110;&#20542;&#21521;&#30340;&#20219;&#20309;&#30495;&#23454;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causality-based recommendation systems focus on the causal effects of user-item interactions resulting from item exposure (i.e., which items are recommended or exposed to the user), as opposed to conventional correlation-based recommendation. They are gaining popularity due to their multi-sided benefits to users, sellers and platforms alike. However, existing causality-based recommendation methods require additional input in the form of exposure data and/or propensity scores (i.e., the probability of exposure) for training. Such data, crucial for modeling causality in recommendation, are often not available in real-world situations due to technical or privacy constraints. In this paper, we bridge the gap by proposing a new framework, called Propensity Estimation for Causality-based Recommendation (PropCare). It can estimate the propensity and exposure from a more practical setup, where only interaction data are available without any ground truth on exposure or propensity in training an
&lt;/p&gt;</description></item><item><title>VR PreM+&#26159;&#19968;&#20010;&#27785;&#28024;&#24335;&#30340;&#21338;&#29289;&#39302;&#23548;&#35272;&#39044;&#23398;&#20064;&#20998;&#25903;&#21487;&#35270;&#21270;&#31995;&#32479;&#65292;&#36890;&#36807;&#20851;&#38190;&#23383;&#20449;&#24687;&#26816;&#32034;&#22312;&#21160;&#24577;&#30340;3D&#31354;&#38388;&#20013;&#31649;&#29702;&#21644;&#36830;&#25509;&#21508;&#31181;&#20869;&#23481;&#26469;&#28304;&#65292;&#25552;&#39640;&#20102;&#27807;&#36890;&#21644;&#25968;&#25454;&#27604;&#36739;&#30340;&#33021;&#21147;&#65292;&#26377;&#26395;&#24212;&#29992;&#20110;&#30740;&#31350;&#21644;&#25945;&#32946;&#31561;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2310.13294</link><description>&lt;p&gt;
VR PreM+&#65306;&#19968;&#20010;&#27785;&#28024;&#24335;&#30340;&#21338;&#29289;&#39302;&#23548;&#35272;&#39044;&#23398;&#20064;&#20998;&#25903;&#21487;&#35270;&#21270;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
VR PreM+: An Immersive Pre-learning Branching Visualization System for Museum Tours. (arXiv:2310.13294v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13294
&lt;/p&gt;
&lt;p&gt;
VR PreM+&#26159;&#19968;&#20010;&#27785;&#28024;&#24335;&#30340;&#21338;&#29289;&#39302;&#23548;&#35272;&#39044;&#23398;&#20064;&#20998;&#25903;&#21487;&#35270;&#21270;&#31995;&#32479;&#65292;&#36890;&#36807;&#20851;&#38190;&#23383;&#20449;&#24687;&#26816;&#32034;&#22312;&#21160;&#24577;&#30340;3D&#31354;&#38388;&#20013;&#31649;&#29702;&#21644;&#36830;&#25509;&#21508;&#31181;&#20869;&#23481;&#26469;&#28304;&#65292;&#25552;&#39640;&#20102;&#27807;&#36890;&#21644;&#25968;&#25454;&#27604;&#36739;&#30340;&#33021;&#21147;&#65292;&#26377;&#26395;&#24212;&#29992;&#20110;&#30740;&#31350;&#21644;&#25945;&#32946;&#31561;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;VR PreM+&#65292;&#19968;&#20010;&#21019;&#26032;&#30340;VR&#31995;&#32479;&#65292;&#26088;&#22312;&#22686;&#24378;&#20256;&#32479;&#30005;&#33041;&#23631;&#24149;&#20197;&#22806;&#30340;&#32593;&#32476;&#25506;&#32034;&#12290;&#19982;&#38745;&#24577;&#30340;2D&#26174;&#31034;&#19981;&#21516;&#65292;VR PreM+&#21033;&#29992;3D&#29615;&#22659;&#21019;&#24314;&#20102;&#27785;&#28024;&#24335;&#30340;&#39044;&#23398;&#20064;&#20307;&#39564;&#12290;&#36890;&#36807;&#20851;&#38190;&#23383;&#20449;&#24687;&#26816;&#32034;&#65292;&#29992;&#25143;&#21487;&#20197;&#22312;&#21160;&#24577;&#30340;3D&#31354;&#38388;&#20013;&#31649;&#29702;&#21644;&#36830;&#25509;&#21508;&#31181;&#20869;&#23481;&#26469;&#28304;&#65292;&#25552;&#39640;&#27807;&#36890;&#21644;&#25968;&#25454;&#27604;&#36739;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#21021;&#27493;&#21644;&#29992;&#25143;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#39640;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#12289;&#22686;&#21152;&#20102;&#29992;&#25143;&#21442;&#19982;&#24230;&#21644;&#26356;&#24378;&#30340;&#23384;&#22312;&#24863;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#26410;&#26469;&#30340;VR&#20449;&#24687;&#31995;&#32479;&#25552;&#20379;&#20102;&#19977;&#20010;&#35774;&#35745;&#25351;&#23548;&#21407;&#21017;&#65306;&#26174;&#31034;&#12289;&#20132;&#20114;&#21644;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#35774;&#35745;&#12290;VR PreM+&#24357;&#34917;&#20102;&#20256;&#32479;&#30340;&#32593;&#32476;&#27983;&#35272;&#21644;&#27785;&#28024;&#24335;VR&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#20132;&#20114;&#24335;&#21644;&#20840;&#38754;&#30340;&#20449;&#24687;&#33719;&#21462;&#26041;&#27861;&#12290;&#23427;&#22312;&#30740;&#31350;&#12289;&#25945;&#32946;&#31561;&#39046;&#22495;&#20855;&#26377;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present VR PreM+, an innovative VR system designed to enhance web exploration beyond traditional computer screens. Unlike static 2D displays, VR PreM+ leverages 3D environments to create an immersive pre-learning experience. Using keyword-based information retrieval allows users to manage and connect various content sources in a dynamic 3D space, improving communication and data comparison. We conducted preliminary and user studies that demonstrated efficient information retrieval, increased user engagement, and a greater sense of presence. These findings yielded three design guidelines for future VR information systems: display, interaction, and user-centric design. VR PreM+ bridges the gap between traditional web browsing and immersive VR, offering an interactive and comprehensive approach to information acquisition. It holds promise for research, education, and beyond.
&lt;/p&gt;</description></item><item><title>Denoised Self-Augmented Learning paradigm (DSL) is proposed for social recommendation, which addresses the challenge of noisy social information by preserving relevant social relations and reducing the negative impact of interest-irrelevant connections.</title><link>http://arxiv.org/abs/2305.12685</link><description>&lt;p&gt;
&#21435;&#22122;&#33258;&#21161;&#23398;&#20064;&#29992;&#20110;&#31038;&#20132;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Denoised Self-Augmented Learning for Social Recommendation. (arXiv:2305.12685v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12685
&lt;/p&gt;
&lt;p&gt;
Denoised Self-Augmented Learning paradigm (DSL) is proposed for social recommendation, which addresses the challenge of noisy social information by preserving relevant social relations and reducing the negative impact of interest-irrelevant connections.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#25512;&#33616;&#22312;&#30005;&#23376;&#21830;&#21153;&#21644;&#22312;&#32447;&#27969;&#23186;&#20307;&#31561;&#21508;&#31181;&#22312;&#32447;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#21463;&#20851;&#27880;&#65292;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#21033;&#29992;&#31038;&#20132;&#20449;&#24687;&#21487;&#20197;&#25913;&#21892;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#24314;&#27169;&#12290;&#26368;&#36817;&#65292;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#36890;&#36807;&#22686;&#24378;&#23398;&#20064;&#20219;&#21153;&#22312;&#35299;&#20915;&#25968;&#25454;&#31232;&#30095;&#24615;&#26041;&#38754;&#34987;&#35777;&#26126;&#38750;&#24120;&#26377;&#25928;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#30740;&#31350;&#20154;&#21592;&#23581;&#35797;&#23558;SSL&#24341;&#20837;&#31038;&#20132;&#25512;&#33616;&#20013;&#65292;&#36890;&#36807;&#34917;&#20805;&#20027;&#35201;&#30340;&#30417;&#30563;&#20219;&#21153;&#20197;&#31038;&#20132;&#24863;&#30693;&#30340;&#33258;&#25105;&#30417;&#30563;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#24191;&#27867;&#23384;&#22312;&#30340;&#19982;&#20852;&#36259;&#26080;&#20851;&#30340;&#31038;&#20132;&#36830;&#25509;&#65288;&#22914;&#21516;&#20107;&#25110;&#21516;&#23398;&#65289;&#23548;&#33268;&#31038;&#20132;&#20449;&#24687;&#22312;&#25551;&#36848;&#29992;&#25143;&#20559;&#22909;&#26102;&#19981;&#21487;&#36991;&#20813;&#22320;&#21463;&#21040;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31038;&#20132;&#25512;&#33616;&#27169;&#22411;&#65292;&#31216;&#20026;&#21435;&#22122;&#33258;&#21161;&#23398;&#20064;&#33539;&#24335;&#65288;DSL&#65289;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#19981;&#20165;&#20445;&#30041;&#26377;&#29992;&#30340;&#31038;&#20132;&#20851;&#31995;&#20197;&#22686;&#24378;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#24314;&#27169;&#65292;&#36824;&#23454;&#29616;&#20102;&#21435;&#22122;&#22788;&#29702;&#65292;&#20197;&#20943;&#23569;&#26080;&#20851;&#20852;&#36259;&#30340;&#31038;&#20132;&#36830;&#25509;&#23545;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Social recommendation is gaining increasing attention in various online applications, including e-commerce and online streaming, where social information is leveraged to improve user-item interaction modeling. Recently, Self-Supervised Learning (SSL) has proven to be remarkably effective in addressing data sparsity through augmented learning tasks. Inspired by this, researchers have attempted to incorporate SSL into social recommendation by supplementing the primary supervised task with social-aware self-supervised signals. However, social information can be unavoidably noisy in characterizing user preferences due to the ubiquitous presence of interest-irrelevant social connections, such as colleagues or classmates who do not share many common interests. To address this challenge, we propose a novel social recommender called the Denoised Self-Augmented Learning paradigm (DSL). Our model not only preserves helpful social relations to enhance user-item interaction modeling but also enabl
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23398;&#20064;&#27169;&#22411;&#26080;&#20851;&#30340;&#21453;&#20107;&#23454;&#32508;&#21512;&#31574;&#30053;&#26469;&#22788;&#29702;&#29992;&#25143;&#21453;&#39304;&#25968;&#25454;&#30340;&#31232;&#30095;&#24615;&#12290;&#35813;&#31574;&#30053;&#33021;&#22815;&#21512;&#25104;&#20855;&#26377;&#29992;&#25143;&#20852;&#36259;&#30456;&#20851;&#20449;&#24687;&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#65292;&#20174;&#32780;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2208.05142</link><description>&lt;p&gt;
Plug-and-Play&#27169;&#22411;&#26080;&#20851;&#30340;&#21453;&#20107;&#23454;&#31574;&#30053;&#32508;&#21512;&#29992;&#20110;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play Model-Agnostic Counterfactual Policy Synthesis for Deep Reinforcement Learning based Recommendation. (arXiv:2208.05142v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05142
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23398;&#20064;&#27169;&#22411;&#26080;&#20851;&#30340;&#21453;&#20107;&#23454;&#32508;&#21512;&#31574;&#30053;&#26469;&#22788;&#29702;&#29992;&#25143;&#21453;&#39304;&#25968;&#25454;&#30340;&#31232;&#30095;&#24615;&#12290;&#35813;&#31574;&#30053;&#33021;&#22815;&#21512;&#25104;&#20855;&#26377;&#29992;&#25143;&#20852;&#36259;&#30456;&#20851;&#20449;&#24687;&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#65292;&#20174;&#32780;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25512;&#33616;&#31995;&#32479;&#30340;&#36827;&#23637;&#35777;&#26126;&#20102;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22788;&#29702;&#29992;&#25143;&#19982;&#25512;&#33616;&#31995;&#32479;&#20043;&#38388;&#21160;&#24577;&#28436;&#21270;&#36807;&#31243;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#23398;&#20064;&#35757;&#32451;&#26368;&#20339;RL&#20195;&#29702;&#36890;&#24120;&#22312;&#25512;&#33616;&#31995;&#32479;&#30340;&#24120;&#35265;&#31232;&#30095;&#29992;&#25143;&#21453;&#39304;&#25968;&#25454;&#20013;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#20026;&#20102;&#36991;&#20813;&#24403;&#21069;&#22522;&#20110;RL&#30340;&#25512;&#33616;&#31995;&#32479;&#32570;&#20047;&#20132;&#20114;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#36890;&#29992;&#30340;&#27169;&#22411;&#26080;&#20851;&#30340;&#21453;&#20107;&#23454;&#32508;&#21512;&#65288;MACS&#65289;&#31574;&#30053;&#65292;&#29992;&#20110;&#21512;&#25104;&#21453;&#20107;&#23454;&#29992;&#25143;&#20132;&#20114;&#25968;&#25454;&#22686;&#24378;&#12290;&#21453;&#20107;&#23454;&#32508;&#21512;&#31574;&#30053;&#26088;&#22312;&#21512;&#25104;&#21453;&#20107;&#23454;&#29366;&#24577;&#65292;&#21516;&#26102;&#20445;&#30041;&#21407;&#22987;&#29366;&#24577;&#20013;&#19982;&#29992;&#25143;&#20852;&#36259;&#30456;&#20851;&#30340;&#37325;&#35201;&#20449;&#24687;&#65292;&#24314;&#31435;&#22312;&#25105;&#20204;&#35774;&#35745;&#30340;&#20004;&#31181;&#19981;&#21516;&#35757;&#32451;&#26041;&#27861;&#20043;&#19978;&#65306;&#19987;&#23478;&#28436;&#31034;&#23398;&#20064;&#21644;&#32852;&#21512;&#35757;&#32451;&#12290;&#22240;&#27492;&#65292;&#27599;&#20010;&#21453;&#20107;&#23454;&#25968;&#25454;&#30340;&#32508;&#21512;&#37117;&#22522;&#20110;&#24403;&#21069;&#25512;&#33616;&#20195;&#29702;&#19982;&#29615;&#22659;&#30340;&#20132;&#20114;&#26469;&#36866;&#24212;&#29992;&#25143;&#30340;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in recommender systems have proved the potential of Reinforcement Learning (RL) to handle the dynamic evolution processes between users and recommender systems. However, learning to train an optimal RL agent is generally impractical with commonly sparse user feedback data in the context of recommender systems. To circumvent the lack of interaction of current RL-based recommender systems, we propose to learn a general Model-Agnostic Counterfactual Synthesis (MACS) Policy for counterfactual user interaction data augmentation. The counterfactual synthesis policy aims to synthesise counterfactual states while preserving significant information in the original state relevant to the user's interests, building upon two different training approaches we designed: learning with expert demonstrations and joint training. As a result, the synthesis of each counterfactual data is based on the current recommendation agent's interaction with the environment to adapt to users' dynamic i
&lt;/p&gt;</description></item></channel></rss>