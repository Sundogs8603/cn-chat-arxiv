<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20197;&#35299;&#20915;&#35774;&#35745;AI&#31995;&#32479;&#33021;&#22815;&#26381;&#21153;&#20110;&#20154;&#20204;&#20855;&#26377;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#38656;&#27714;&#12290;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#40784;&#23450;&#20041;&#21644;&#23454;&#29616;&#22810;&#20803;&#20027;&#20041;&#30340;&#19977;&#31181;&#26041;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#26469;&#35780;&#20272;&#21644;&#27979;&#35797;&#22810;&#20803;&#23545;&#40784;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.05070</link><description>&lt;p&gt;
&#36890;&#24448;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;
&lt;/p&gt;
&lt;p&gt;
A Roadmap to Pluralistic Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05070
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20197;&#35299;&#20915;&#35774;&#35745;AI&#31995;&#32479;&#33021;&#22815;&#26381;&#21153;&#20110;&#20154;&#20204;&#20855;&#26377;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#38656;&#27714;&#12290;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#40784;&#23450;&#20041;&#21644;&#23454;&#29616;&#22810;&#20803;&#20027;&#20041;&#30340;&#19977;&#31181;&#26041;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#26469;&#35780;&#20272;&#21644;&#27979;&#35797;&#22810;&#20803;&#23545;&#40784;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#26435;&#21147;&#21644;&#26222;&#21450;&#31243;&#24230;&#30340;&#22686;&#21152;&#65292;&#35774;&#35745;&#33021;&#22815;&#20026;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#20154;&#26381;&#21153;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#21464;&#24471;&#24840;&#21457;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23558;&#27169;&#22411;&#23545;&#40784;&#20197;&#26381;&#21153;&#22810;&#20803;&#20154;&#31867;&#20215;&#20540;&#35266;&#20173;&#28982;&#26159;&#19968;&#20010;&#24453;&#35299;&#20915;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20855;&#20307;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#27979;&#35797;&#24179;&#21488;&#12290;&#25105;&#20204;&#30830;&#23450;&#21644;&#24418;&#24335;&#21270;&#20102;&#19977;&#31181;&#21487;&#33021;&#30340;&#26041;&#24335;&#26469;&#23450;&#20041;&#21644;&#23454;&#29616;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#20013;&#30340;&#22810;&#20803;&#20027;&#20041;&#65306;1&#65289;Overton&#22810;&#20803;&#27169;&#22411;&#65292;&#23637;&#31034;&#21512;&#29702;&#21453;&#24212;&#30340;&#20809;&#35889;&#65307;2&#65289;&#21487;&#25805;&#25511;&#30340;&#22810;&#20803;&#27169;&#22411;&#65292;&#21487;&#20197;&#35843;&#25972;&#20197;&#21453;&#26144;&#29305;&#23450;&#30340;&#35266;&#28857;&#65307;3&#65289;&#20998;&#24067;&#22810;&#20803;&#27169;&#22411;&#65292;&#22312;&#20998;&#24067;&#20013;&#24456;&#22909;&#22320;&#26657;&#20934;&#32473;&#23450;&#20154;&#32676;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#21644;&#24418;&#24335;&#21270;&#20102;&#19977;&#31181;&#21487;&#33021;&#30340;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#65306;1&#65289;&#22810;&#30446;&#26631;&#22522;&#20934;&#65307;2&#65289;&#26435;&#34913;&#21487;&#25805;&#25511;&#22522;&#20934;&#65292;&#40723;&#21169;&#27169;&#22411;&#23545;&#20219;&#24847;&#26435;&#34913;&#36827;&#34892;&#35843;&#25972;&#65307;3&#65289;&#38506;&#23457;&#22242;&#22810;&#20803;&#22522;&#20934;&#65292;&#26126;&#30830;&#22320;&#27169;&#25311;&#20102;&#19981;&#21516;&#38506;&#23457;&#22242;&#30340;&#24847;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
With increased power and prevalence of AI systems, it is ever more critical that AI systems are designed to serve all, i.e., people with diverse values and perspectives. However, aligning models to serve pluralistic human values remains an open research question. In this piece, we propose a roadmap to pluralistic alignment, specifically using language models as a test bed. We identify and formalize three possible ways to define and operationalize pluralism in AI systems: 1) Overton pluralistic models that present a spectrum of reasonable responses; 2) Steerably pluralistic models that can steer to reflect certain perspectives; and 3) Distributionally pluralistic models that are well-calibrated to a given population in distribution. We also propose and formalize three possible classes of pluralistic benchmarks: 1) Multi-objective benchmarks, 2) Trade-off steerable benchmarks, which incentivize models to steer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks which explicitly m
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;LLM&#26159;&#21542;&#21487;&#20197;&#29992;&#20316;&#23545;&#25239;&#29983;&#25104;&#24335;&#21407;&#29983;&#24191;&#21578;&#30340;&#23545;&#31574;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#24191;&#21578;&#20542;&#21521;&#26597;&#35810;&#25968;&#25454;&#38598;&#21644;&#24102;&#33258;&#21160;&#25972;&#21512;&#24191;&#21578;&#30340;&#29983;&#25104;&#31572;&#26696;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#12290;</title><link>https://arxiv.org/abs/2402.04889</link><description>&lt;p&gt;
&#21457;&#29616;&#23545;&#35805;&#24335;&#25628;&#32034;&#20013;&#30340;&#29983;&#25104;&#24335;&#21407;&#29983;&#24191;&#21578;
&lt;/p&gt;
&lt;p&gt;
Detecting Generated Native Ads in Conversational Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04889
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;LLM&#26159;&#21542;&#21487;&#20197;&#29992;&#20316;&#23545;&#25239;&#29983;&#25104;&#24335;&#21407;&#29983;&#24191;&#21578;&#30340;&#23545;&#31574;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#24191;&#21578;&#20542;&#21521;&#26597;&#35810;&#25968;&#25454;&#38598;&#21644;&#24102;&#33258;&#21160;&#25972;&#21512;&#24191;&#21578;&#30340;&#29983;&#25104;&#31572;&#26696;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#25628;&#32034;&#24341;&#25806;&#22914;YouChat&#21644;Microsoft Copilot&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20026;&#26597;&#35810;&#29983;&#25104;&#31572;&#26696;&#12290;&#23558;&#27492;&#25216;&#26415;&#29992;&#20110;&#29983;&#25104;&#24182;&#25972;&#21512;&#24191;&#21578;&#65292;&#32780;&#19981;&#26159;&#23558;&#24191;&#21578;&#19982;&#26377;&#26426;&#25628;&#32034;&#32467;&#26524;&#20998;&#24320;&#25918;&#32622;&#65292;&#21482;&#26159;&#19968;&#23567;&#27493;&#12290;&#36825;&#31181;&#31867;&#22411;&#30340;&#24191;&#21578;&#31867;&#20284;&#20110;&#21407;&#29983;&#24191;&#21578;&#21644;&#20135;&#21697;&#25918;&#32622;&#65292;&#20004;&#32773;&#37117;&#26159;&#38750;&#24120;&#26377;&#25928;&#30340;&#24494;&#22937;&#21644;&#25805;&#32437;&#24615;&#24191;&#21578;&#24418;&#24335;&#12290;&#22312;&#32771;&#34385;&#21040;&#19982;LLM&#30456;&#20851;&#30340;&#39640;&#35745;&#31639;&#25104;&#26412;&#26102;&#65292;&#20449;&#24687;&#25628;&#32034;&#32773;&#23558;&#24456;&#21487;&#33021;&#22312;&#19981;&#20037;&#30340;&#23558;&#26469;&#38754;&#20020;&#36825;&#31181;LLM&#25216;&#26415;&#30340;&#20351;&#29992;&#65292;&#22240;&#27492;&#20379;&#24212;&#21830;&#38656;&#35201;&#24320;&#21457;&#21487;&#25345;&#32493;&#30340;&#21830;&#19994;&#27169;&#24335;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;LLM&#26159;&#21542;&#20063;&#21487;&#20197;&#29992;&#20316;&#23545;&#25239;&#29983;&#25104;&#24335;&#21407;&#29983;&#24191;&#21578;&#30340;&#23545;&#31574;&#65292;&#21363;&#38459;&#27490;&#23427;&#20204;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32534;&#21046;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#24191;&#21578;&#20542;&#21521;&#26597;&#35810;&#25968;&#25454;&#38598;&#21644;&#24102;&#33258;&#21160;&#25972;&#21512;&#24191;&#21578;&#30340;&#29983;&#25104;&#31572;&#26696;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational search engines such as YouChat and Microsoft Copilot use large language models (LLMs) to generate answers to queries. It is only a small step to also use this technology to generate and integrate advertising within these answers - instead of placing ads separately from the organic search results. This type of advertising is reminiscent of native advertising and product placement, both of which are very effective forms of subtle and manipulative advertising. It is likely that information seekers will be confronted with such use of LLM technology in the near future, especially when considering the high computational costs associated with LLMs, for which providers need to develop sustainable business models. This paper investigates whether LLMs can also be used as a countermeasure against generated native ads, i.e., to block them. For this purpose we compile a large dataset of ad-prone queries and of generated answers with automatically integrated ads to experiment with fin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#21644;&#20154;&#31867;&#21453;&#39304;&#30340;&#22810;&#27169;&#24577;&#26597;&#35810;&#24314;&#35758;&#31995;&#32479;&#12290;&#36890;&#36807;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#21644;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#26681;&#25454;&#29992;&#25143;&#30340;&#26597;&#35810;&#22270;&#20687;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#26597;&#35810;&#24314;&#35758;&#65292;&#20174;&#32780;&#25552;&#39640;&#25628;&#32034;&#32467;&#26524;&#30340;&#24847;&#22270;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04867</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#26597;&#35810;&#24314;&#35758;&#20013;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#19982;&#20154;&#31867;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#21644;&#20154;&#31867;&#21453;&#39304;&#30340;&#22810;&#27169;&#24577;&#26597;&#35810;&#24314;&#35758;&#31995;&#32479;&#12290;&#36890;&#36807;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#21644;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#26681;&#25454;&#29992;&#25143;&#30340;&#26597;&#35810;&#22270;&#20687;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#26597;&#35810;&#24314;&#35758;&#65292;&#20174;&#32780;&#25552;&#39640;&#25628;&#32034;&#32467;&#26524;&#30340;&#24847;&#22270;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#26816;&#32034;&#30340;&#24555;&#36895;&#21457;&#23637;&#29615;&#22659;&#20013;&#65292;&#25628;&#32034;&#24341;&#25806;&#33268;&#21147;&#20110;&#20026;&#29992;&#25143;&#25552;&#20379;&#26356;&#20010;&#24615;&#21270;&#21644;&#30456;&#20851;&#24615;&#26356;&#24378;&#30340;&#32467;&#26524;&#12290;&#26597;&#35810;&#24314;&#35758;&#31995;&#32479;&#22312;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#26041;&#38754;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#36890;&#36807;&#21327;&#21161;&#29992;&#25143;&#21046;&#23450;&#26377;&#25928;&#30340;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26597;&#35810;&#24314;&#35758;&#31995;&#32479;&#20027;&#35201;&#20381;&#36182;&#20110;&#25991;&#26412;&#36755;&#20837;&#65292;&#21487;&#33021;&#38480;&#21046;&#29992;&#25143;&#23545;&#22270;&#20687;&#26597;&#35810;&#30340;&#20307;&#39564;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#27169;&#24577;&#26597;&#35810;&#24314;&#35758;&#65288;MMQS&#65289;&#20219;&#21153;&#65292;&#26088;&#22312;&#22522;&#20110;&#29992;&#25143;&#26597;&#35810;&#22270;&#20687;&#29983;&#25104;&#26597;&#35810;&#24314;&#35758;&#65292;&#20197;&#25552;&#39640;&#25628;&#32034;&#32467;&#26524;&#30340;&#24847;&#22270;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;RL4Sugg&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#21147;&#37327;&#26469;&#20248;&#21270;&#29983;&#25104;&#36807;&#31243;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;RL4Sugg&#30340;&#26377;&#25928;&#24615;&#65292;&#19982;&#26368;&#20339;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#33719;&#24471;&#20102;18%&#30340;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;MMQS&#24050;&#32463;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the rapidly evolving landscape of information retrieval, search engines strive to provide more personalized and relevant results to users. Query suggestion systems play a crucial role in achieving this goal by assisting users in formulating effective queries. However, existing query suggestion systems mainly rely on textual inputs, potentially limiting user search experiences for querying images. In this paper, we introduce a novel Multimodal Query Suggestion (MMQS) task, which aims to generate query suggestions based on user query images to improve the intentionality and diversity of search results. We present the RL4Sugg framework, leveraging the power of Large Language Models (LLMs) with Multi-Agent Reinforcement Learning from Human Feedback to optimize the generation process. Through comprehensive experiments, we validate the effectiveness of RL4Sugg, demonstrating a 18% improvement compared to the best existing approach. Moreover, the MMQS has been transferred into real-world s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#26080;&#30417;&#30563;&#36873;&#25321;&#26368;&#20339;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#26032;&#25216;&#26415;&#12290;&#36873;&#25321;&#21512;&#36866;&#30340;&#26816;&#32034;&#22120;&#23545;&#20110;&#24212;&#29992;&#20110;&#26032;&#30340;&#30446;&#26631;&#35821;&#26009;&#24211;&#24182;&#19988;&#23384;&#22312;&#39046;&#22495;&#36716;&#31227;&#30340;&#24773;&#20917;&#38750;&#24120;&#37325;&#35201;&#12290;</title><link>https://arxiv.org/abs/2402.04853</link><description>&lt;p&gt;
&#21033;&#29992;LLMs&#36827;&#34892;&#26080;&#30417;&#30563;&#30340;&#23494;&#38598;&#26816;&#32034;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Leveraging LLMs for Unsupervised Dense Retriever Ranking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#26080;&#30417;&#30563;&#36873;&#25321;&#26368;&#20339;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#26032;&#25216;&#26415;&#12290;&#36873;&#25321;&#21512;&#36866;&#30340;&#26816;&#32034;&#22120;&#23545;&#20110;&#24212;&#29992;&#20110;&#26032;&#30340;&#30446;&#26631;&#35821;&#26009;&#24211;&#24182;&#19988;&#23384;&#22312;&#39046;&#22495;&#36716;&#31227;&#30340;&#24773;&#20917;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30830;&#23450;&#29305;&#23450;&#27979;&#35797;&#65288;&#30446;&#26631;&#65289;&#35821;&#26009;&#24211;&#26368;&#21512;&#36866;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#26032;&#39062;&#26080;&#30417;&#30563;&#25216;&#26415;&#12290;&#36873;&#25321;&#21512;&#36866;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#23545;&#20110;&#35768;&#22810;&#37319;&#29992;&#36825;&#20123;&#22312;&#20844;&#24320;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#26816;&#32034;&#22120;&#36827;&#34892;&#32534;&#30721;&#25110;&#22312;&#26032;&#30340;&#31169;&#26377;&#30446;&#26631;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#25628;&#32034;&#30340;&#20449;&#24687;&#26816;&#32034;&#24212;&#29992;&#31243;&#24207;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#23494;&#38598;&#26816;&#32034;&#22120;&#24212;&#29992;&#20110;&#19982;&#21407;&#22987;&#35757;&#32451;&#38598;&#22312;&#39046;&#22495;&#25110;&#20219;&#21153;&#19978;&#26377;&#24046;&#24322;&#30340;&#30446;&#26631;&#35821;&#26009;&#24211;&#26102;&#65292;&#20854;&#26377;&#25928;&#24615;&#21487;&#33021;&#20250;&#22823;&#22823;&#38477;&#20302;&#12290;&#22312;&#30446;&#26631;&#35821;&#26009;&#24211;&#27809;&#26377;&#26631;&#27880;&#30340;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#22312;&#38646;&#26679;&#26412;&#22330;&#26223;&#20013;&#65292;&#26080;&#27861;&#30452;&#25509;&#35780;&#20272;&#27169;&#22411;&#22312;&#30446;&#26631;&#35821;&#26009;&#24211;&#19978;&#30340;&#25928;&#26524;&#12290;&#22240;&#27492;&#65292;&#26080;&#30417;&#30563;&#36873;&#25321;&#26368;&#20339;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#65292;&#29305;&#21035;&#26159;&#22312;&#39046;&#22495;&#36801;&#31227;&#26465;&#20214;&#19979;&#65292;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#23494;&#38598;&#26816;&#32034;&#22120;&#25490;&#24207;&#26041;&#27861;&#22312;&#35299;&#20915;&#36825;&#20123;&#39046;&#22495;&#36801;&#31227;&#38382;&#39064;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel unsupervised technique that utilizes large language models (LLMs) to determine the most suitable dense retriever for a specific test(target) corpus. Selecting the appropriate dense retriever is vital for numerous IR applications that employ these retrievers, trained on public datasets, to encode or conduct searches within a new private target corpus. The effectiveness of a dense retriever can significantly diminish when applied to a target corpus that diverges in domain or task from the original training set. The problem becomes more pronounced in cases where the target corpus is unlabeled, e.g. in zero-shot scenarios, rendering direct evaluation of the model's effectiveness on the target corpus unattainable. Therefore, the unsupervised selection of an optimally pre-trained dense retriever, especially under conditions of domain shift, emerges as a critical challenge. Existing methodologies for ranking dense retrievers fall short in addressing these domain 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23545;&#22270;&#24418;&#22522;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#30340;&#33258;&#36866;&#24212;&#20837;&#21475;&#28857;&#36873;&#25321;&#36827;&#34892;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#27010;&#24565;$b\textit{-&#21333;&#35843;&#36335;&#24452;}$&#21644;$B\textit{-MSNET}$&#12290;&#29702;&#35770;&#35777;&#26126;&#20102;&#33258;&#36866;&#24212;&#20837;&#21475;&#28857;&#36873;&#25321;&#22312;&#26356;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#27604;&#22266;&#23450;&#20013;&#24515;&#20837;&#21475;&#28857;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#19978;&#30028;&#12290;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#20934;&#30830;&#24615;&#12289;&#36895;&#24230;&#21644;&#20869;&#23384;&#20351;&#29992;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#23588;&#20854;&#26159;&#22312;&#20998;&#24067;&#20043;&#22806;&#30340;&#25968;&#25454;&#21644;&#38590;&#20363;&#30340;&#25361;&#25112;&#22330;&#26223;&#20013;&#12290;&#36825;&#39033;&#20840;&#38754;&#30740;&#31350;&#25552;&#20379;&#20102;&#20248;&#21270;&#22270;&#24418;&#22522;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#20837;&#21475;&#28857;&#30340;&#28145;&#20837;&#27934;&#23519;&#65292;&#36866;&#29992;&#20110;&#23454;&#38469;&#30340;&#39640;&#32500;&#25968;&#25454;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.04713</link><description>&lt;p&gt;
&#22270;&#24418;&#22522;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#30340;&#33258;&#36866;&#24212;&#20837;&#21475;&#28857;&#36873;&#25321;&#30340;&#29702;&#35770;&#19982;&#23454;&#35777;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Theoretical and Empirical Analysis of Adaptive Entry Point Selection for Graph-based Approximate Nearest Neighbor Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23545;&#22270;&#24418;&#22522;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#30340;&#33258;&#36866;&#24212;&#20837;&#21475;&#28857;&#36873;&#25321;&#36827;&#34892;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#27010;&#24565;$b\textit{-&#21333;&#35843;&#36335;&#24452;}$&#21644;$B\textit{-MSNET}$&#12290;&#29702;&#35770;&#35777;&#26126;&#20102;&#33258;&#36866;&#24212;&#20837;&#21475;&#28857;&#36873;&#25321;&#22312;&#26356;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#27604;&#22266;&#23450;&#20013;&#24515;&#20837;&#21475;&#28857;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#19978;&#30028;&#12290;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#20934;&#30830;&#24615;&#12289;&#36895;&#24230;&#21644;&#20869;&#23384;&#20351;&#29992;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#23588;&#20854;&#26159;&#22312;&#20998;&#24067;&#20043;&#22806;&#30340;&#25968;&#25454;&#21644;&#38590;&#20363;&#30340;&#25361;&#25112;&#22330;&#26223;&#20013;&#12290;&#36825;&#39033;&#20840;&#38754;&#30740;&#31350;&#25552;&#20379;&#20102;&#20248;&#21270;&#22270;&#24418;&#22522;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#20837;&#21475;&#28857;&#30340;&#28145;&#20837;&#27934;&#23519;&#65292;&#36866;&#29992;&#20110;&#23454;&#38469;&#30340;&#39640;&#32500;&#25968;&#25454;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#22270;&#24418;&#22522;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#30340;&#33258;&#36866;&#24212;&#20837;&#21475;&#28857;&#36873;&#25321;&#36827;&#34892;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#30340;&#27010;&#24565;&#65306;$b\textit{-&#21333;&#35843;&#36335;&#24452;}$&#21644;$B\textit{-MSNET}$&#65292;&#27604;&#29616;&#26377;&#30340;&#27010;&#24565;&#22914;MSNET&#26356;&#22909;&#22320;&#25429;&#25417;&#20102;&#23454;&#38469;&#31639;&#27861;&#20013;&#30340;&#22270;&#24418;&#29305;&#24449;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#27604;&#20197;&#21069;&#30340;&#24037;&#20316;&#26356;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#65292;&#33258;&#36866;&#24212;&#20837;&#21475;&#28857;&#36873;&#25321;&#25552;&#20379;&#20102;&#27604;&#22266;&#23450;&#20013;&#24515;&#20837;&#21475;&#28857;&#26356;&#22909;&#30340;&#24615;&#33021;&#19978;&#30028;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#12289;&#36895;&#24230;&#21644;&#20869;&#23384;&#20351;&#29992;&#26041;&#38754;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#23588;&#20854;&#26159;&#22312;&#20998;&#24067;&#20043;&#22806;&#30340;&#25968;&#25454;&#21644;&#38590;&#20363;&#30340;&#25361;&#25112;&#24615;&#22330;&#26223;&#20013;&#12290;&#25105;&#20204;&#30340;&#32508;&#21512;&#30740;&#31350;&#28145;&#20837;&#27934;&#23519;&#20102;&#29992;&#20110;&#23454;&#38469;&#39640;&#32500;&#25968;&#25454;&#24212;&#29992;&#20013;&#30340;&#22270;&#24418;&#22522;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#30340;&#20837;&#21475;&#28857;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a theoretical and empirical analysis of the adaptive entry point selection for graph-based approximate nearest neighbor search (ANNS). We introduce novel concepts: $b\textit{-monotonic path}$ and $B\textit{-MSNET}$, which better capture an actual graph in practical algorithms than existing concepts like MSNET. We prove that adaptive entry point selection offers better performance upper bound than the fixed central entry point under more general conditions than previous work. Empirically, we validate the method's effectiveness in accuracy, speed, and memory usage across various datasets, especially in challenging scenarios with out-of-distribution data and hard instances. Our comprehensive study provides deeper insights into optimizing entry points for graph-based ANNS for real-world high-dimensional data applications.
&lt;/p&gt;</description></item><item><title>&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#29983;&#21629;&#31185;&#23398;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#38382;&#39064;&#22238;&#31572;&#23545;OpenLlama LLM&#36827;&#34892;&#20102;&#24494;&#35843;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#20197;&#25193;&#23637;&#29616;&#26377;&#26597;&#35810;&#38598;&#21512;&#65292;&#20174;&#32780;&#33021;&#22815;&#36827;&#34892;&#24494;&#35843;&#65292;&#21363;&#20351;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#26597;&#35810;&#20013;&#35821;&#20041;&#32447;&#32034;&#30340;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.04627</link><description>&lt;p&gt;
SPARQL&#29983;&#25104;&#65306;&#23545;OpenLLaMA&#29992;&#20110;&#29983;&#21629;&#31185;&#23398;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#30340;&#24494;&#35843;&#36827;&#34892;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04627
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#29983;&#21629;&#31185;&#23398;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#38382;&#39064;&#22238;&#31572;&#23545;OpenLlama LLM&#36827;&#34892;&#20102;&#24494;&#35843;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#20197;&#25193;&#23637;&#29616;&#26377;&#26597;&#35810;&#38598;&#21512;&#65292;&#20174;&#32780;&#33021;&#22815;&#36827;&#34892;&#24494;&#35843;&#65292;&#21363;&#20351;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#26597;&#35810;&#20013;&#35821;&#20041;&#32447;&#32034;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#20013;&#30340;&#25104;&#21151;&#20026;&#22522;&#20110;LLM&#30340;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#31995;&#32479;&#24320;&#36767;&#20102;&#26032;&#30340;&#36335;&#24452;&#12290;&#28982;&#32780;&#65292;&#20854;&#23454;&#26045;&#30340;&#20027;&#35201;&#38556;&#30861;&#20043;&#19968;&#26159;&#22312;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;SPARQL&#26597;&#35810;&#30340;&#20219;&#21153;&#20013;&#65292;&#23588;&#20854;&#26159;&#22312;&#29305;&#23450;&#39046;&#22495;&#30340;&#30693;&#35782;&#22270;&#35889;&#20013;&#65292;&#35757;&#32451;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#38024;&#23545;&#29983;&#21629;&#31185;&#23398;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#38382;&#39064;&#22238;&#31572;&#23545;OpenLlama LLM&#36827;&#34892;&#24494;&#35843;&#30340;&#20960;&#31181;&#31574;&#30053;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#29992;&#20110;&#25193;&#23637;&#24050;&#26377;&#26597;&#35810;&#38598;&#21512;&#65292;&#20174;&#32780;&#33719;&#24471;&#19968;&#32452;&#26356;&#22823;&#30340;&#35821;&#20041;&#20016;&#23500;&#30340;&#38382;&#39064;-SPARQL&#26597;&#35810;&#23545;&#30340;&#25968;&#25454;&#38598;&#65292;&#21363;&#20351;&#22312;&#36825;&#20123;&#23545;&#31232;&#32570;&#30340;&#25968;&#25454;&#38598;&#20013;&#20063;&#33021;&#36827;&#34892;&#24494;&#35843;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#26597;&#35810;&#20013;&#35821;&#20041;&#8220;&#32447;&#32034;&#8221;&#30340;&#20316;&#29992;&#65292;&#20363;&#22914;&#26377;&#24847;&#20041;&#30340;&#21464;&#37327;&#21517;&#21644;...
&lt;/p&gt;
&lt;p&gt;
The recent success of Large Language Models (LLM) in a wide range of Natural Language Processing applications opens the path towards novel Question Answering Systems over Knowledge Graphs leveraging LLMs. However, one of the main obstacles preventing their implementation is the scarcity of training data for the task of translating questions into corresponding SPARQL queries, particularly in the case of domain-specific KGs. To overcome this challenge, in this study, we evaluate several strategies for fine-tuning the OpenLlama LLM for question answering over life science knowledge graphs. In particular, we propose an end-to-end data augmentation approach for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs, enabling fine-tuning even for datasets where these pairs are scarce. In this context, we also investigate the role of semantic "clues" in the queries, such as meaningful variable names and
&lt;/p&gt;</description></item><item><title>NORMY&#26159;&#19968;&#31181;&#29992;&#20110;&#24320;&#25918;&#24335;&#26816;&#32034;&#23545;&#35805;&#24335;&#38382;&#31572;&#30340;&#38750;&#22343;&#21248;&#21382;&#21490;&#24314;&#27169;&#27969;&#31243;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#27169;&#22359;&#29983;&#25104;&#26368;&#20339;&#23545;&#35805;&#21382;&#21490;&#65292;&#25552;&#39640;&#20102;&#31995;&#32479;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04548</link><description>&lt;p&gt;
NORMY&#65306;&#38750;&#22343;&#21248;&#21382;&#21490;&#24314;&#27169;&#29992;&#20110;&#24320;&#25918;&#24335;&#26816;&#32034;&#23545;&#35805;&#24335;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04548
&lt;/p&gt;
&lt;p&gt;
NORMY&#26159;&#19968;&#31181;&#29992;&#20110;&#24320;&#25918;&#24335;&#26816;&#32034;&#23545;&#35805;&#24335;&#38382;&#31572;&#30340;&#38750;&#22343;&#21248;&#21382;&#21490;&#24314;&#27169;&#27969;&#31243;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#27169;&#22359;&#29983;&#25104;&#26368;&#20339;&#23545;&#35805;&#21382;&#21490;&#65292;&#25552;&#39640;&#20102;&#31995;&#32479;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#25918;&#24335;&#26816;&#32034;&#23545;&#35805;&#24335;&#38382;&#31572;&#65288;OrConvQA&#65289;&#22312;&#32473;&#23450;&#23545;&#35805;&#21644;&#25991;&#26723;&#38598;&#21512;&#30340;&#24773;&#20917;&#19979;&#22238;&#31572;&#38382;&#39064;&#12290;&#20856;&#22411;&#30340;OrConvQA&#27969;&#31243;&#21253;&#25324;&#19977;&#20010;&#27169;&#22359;&#65306;&#19968;&#20010;&#26816;&#32034;&#22120;&#29992;&#20110;&#20174;&#38598;&#21512;&#20013;&#26816;&#32034;&#30456;&#20851;&#25991;&#26723;&#65292;&#19968;&#20010;&#37325;&#26032;&#25490;&#24207;&#22120;&#26681;&#25454;&#38382;&#39064;&#21644;&#19978;&#19979;&#25991;&#23545;&#23427;&#20204;&#37325;&#26032;&#25490;&#24207;&#65292;&#24182;&#19988;&#19968;&#20010;&#38405;&#35835;&#22120;&#29992;&#20110;&#25552;&#21462;&#31572;&#26696;&#33539;&#22260;&#12290;&#23545;&#35805;&#30340;&#36716;&#21521;&#21487;&#20197;&#20026;&#22238;&#31572;&#26368;&#32456;&#38382;&#39064;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#19978;&#19979;&#25991;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;OrConvQA&#31995;&#32479;&#22312;&#27969;&#31243;&#30340;&#19977;&#20010;&#27169;&#22359;&#20013;&#20351;&#29992;&#30456;&#21516;&#30340;&#21382;&#21490;&#24314;&#27169;&#12290;&#25105;&#20204;&#20551;&#35774;&#36825;&#26159;&#27425;&#20248;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35748;&#20026;&#31532;&#19968;&#20010;&#27169;&#22359;&#20013;&#38656;&#35201;&#26356;&#24191;&#27867;&#30340;&#19978;&#19979;&#25991;&#20197;&#38450;&#27490;&#38169;&#36807;&#30456;&#20851;&#25991;&#26723;&#65292;&#32780;&#26368;&#21518;&#19968;&#20010;&#27169;&#22359;&#20013;&#38656;&#35201;&#26356;&#29421;&#31364;&#30340;&#19978;&#19979;&#25991;&#26469;&#30830;&#23450;&#31934;&#30830;&#30340;&#31572;&#26696;&#33539;&#22260;&#12290;&#25105;&#20204;&#25552;&#20986;NORMY&#65292;&#31532;&#19968;&#20010;&#26080;&#30417;&#30563;&#30340;&#38750;&#22343;&#21248;&#21382;&#21490;&#24314;&#27169;&#27969;&#31243;&#65292;&#20026;&#27599;&#20010;&#27169;&#22359;&#29983;&#25104;&#26368;&#20339;&#23545;&#35805;&#21382;&#21490;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;NORMY&#26816;&#32034;&#22120;&#65292;&#23427;&#20351;&#29992;k
&lt;/p&gt;
&lt;p&gt;
Open Retrieval Conversational Question Answering (OrConvQA) answers a question given a conversation as context and a document collection. A typical OrConvQA pipeline consists of three modules: a Retriever to retrieve relevant documents from the collection, a Reranker to rerank them given the question and the context, and a Reader to extract an answer span. The conversational turns can provide valuable context to answer the final query. State-of-the-art OrConvQA systems use the same history modeling for all three modules of the pipeline. We hypothesize this as suboptimal. Specifically, we argue that a broader context is needed in the first modules of the pipeline to not miss relevant documents, while a narrower context is needed in the last modules to identify the exact answer span. We propose NORMY, the first unsupervised non-uniform history modeling pipeline which generates the best conversational history for each module. We further propose a novel Retriever for NORMY, which employs k
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#39640;&#25928;ID&#34920;&#31034;&#23545;&#40784;&#26694;&#26550;RA-Rec&#65292;&#36890;&#36807;&#23558;&#39044;&#35757;&#32451;&#30340;ID&#23884;&#20837;&#21040;LLMs&#20013;&#65292;&#24182;&#35774;&#35745;&#21019;&#26032;&#30340;&#23545;&#40784;&#27169;&#22359;&#21644;&#39640;&#25928;&#35843;&#25972;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#26174;&#33879;&#24615;&#33021;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.04527</link><description>&lt;p&gt;
RA-Rec:&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#39640;&#25928;ID&#34920;&#31034;&#23545;&#40784;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04527
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#39640;&#25928;ID&#34920;&#31034;&#23545;&#40784;&#26694;&#26550;RA-Rec&#65292;&#36890;&#36807;&#23558;&#39044;&#35757;&#32451;&#30340;ID&#23884;&#20837;&#21040;LLMs&#20013;&#65292;&#24182;&#35774;&#35745;&#21019;&#26032;&#30340;&#23545;&#40784;&#27169;&#22359;&#21644;&#39640;&#25928;&#35843;&#25972;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#26174;&#33879;&#24615;&#33021;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#26368;&#36817;&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#20026;LLM&#21644;&#25512;&#33616;&#31995;&#32479;&#30340;&#32467;&#21512;&#24102;&#26469;&#20102;&#26032;&#30340;&#28526;&#27969;&#65292;&#31216;&#20026;LLM-based RS&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#20998;&#20026;&#20004;&#31181;&#20027;&#35201;&#33539;&#20363;&#65292;&#21363;ID&#30452;&#25509;&#20351;&#29992;&#33539;&#20363;&#21644;ID&#32763;&#35793;&#33539;&#20363;&#65292;&#25351;&#20986;&#23427;&#20204;&#30340;&#26680;&#24515;&#24369;&#28857;&#22312;&#20110;&#32570;&#20047;&#25512;&#33616;&#30693;&#35782;&#21644;&#29420;&#29305;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#20363;&#65292;&#21363;ID&#34920;&#31034;&#65292;&#23427;&#20197;&#19968;&#31181;&#20114;&#34917;&#30340;&#26041;&#24335;&#23558;&#39044;&#35757;&#32451;&#30340;ID&#23884;&#20837;&#21040;LLMs&#20013;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RA-Rec&#65292;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#39640;&#25928;ID&#34920;&#31034;&#23545;&#40784;&#26694;&#26550;&#65292;&#19982;&#22810;&#31181;&#22522;&#20110;ID&#30340;&#26041;&#27861;&#21644;LLM&#26550;&#26500;&#20860;&#23481;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;ID&#23884;&#20837;&#35270;&#20026;&#36719;&#25552;&#31034;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#23545;&#40784;&#27169;&#22359;&#21644;&#19968;&#31181;&#29992;&#20110;&#23545;&#40784;&#30340;&#39640;&#25928;&#35843;&#25972;&#26041;&#27861;&#65292;&#20197;&#21450;&#20026;&#23545;&#40784;&#23450;&#21046;&#30340;&#25968;&#25454;&#26500;&#24314;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;RA-Rec&#22312;&#24615;&#33021;&#19978;&#26174;&#33879;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLM) have recently emerged as a powerful tool for a variety of natural language processing tasks, bringing a new surge of combining LLM with recommendation systems, termed as LLM-based RS. Current approaches generally fall into two main paradigms, the ID direct usage paradigm and the ID translation paradigm, noting their core weakness stems from lacking recommendation knowledge and uniqueness. To address this limitation, we propose a new paradigm, ID representation, which incorporates pre-trained ID embeddings into LLMs in a complementary manner. In this work, we present RA-Rec, an efficient ID representation alignment framework for LLM-based recommendation, which is compatible with multiple ID-based methods and LLM architectures. Specifically, we treat ID embeddings as soft prompts and design an innovative alignment module and an efficient tuning method with tailored data construction for alignment. Extensive experiments demonstrate RA-Rec substantially outperfo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#38752;&#24615;&#30340;&#25512;&#33616;&#31995;&#32479;&#36136;&#37327;&#24230;&#37327;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#20934;&#30830;&#24615;&#32467;&#26524;&#65292;&#22635;&#34917;&#20102;&#21487;&#38752;&#24615;/&#32622;&#20449;&#24230;&#36136;&#37327;&#24230;&#37327;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;</title><link>https://arxiv.org/abs/2402.04457</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#21487;&#38752;&#24615;&#36136;&#37327;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Reliability quality measures for recommender systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#38752;&#24615;&#30340;&#25512;&#33616;&#31995;&#32479;&#36136;&#37327;&#24230;&#37327;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#20934;&#30830;&#24615;&#32467;&#26524;&#65292;&#22635;&#34917;&#20102;&#21487;&#38752;&#24615;/&#32622;&#20449;&#24230;&#36136;&#37327;&#24230;&#37327;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#24076;&#26395;&#20102;&#35299;&#25512;&#33616;&#30340;&#21487;&#38752;&#24615;&#65292;&#22914;&#26524;&#27809;&#26377;&#21487;&#38752;&#24615;&#35777;&#25454;&#65292;&#20182;&#20204;&#19981;&#20250;&#25509;&#21463;&#39640;&#39044;&#27979;&#20540;&#12290;&#25512;&#33616;&#31995;&#32479;&#24212;&#25552;&#20379;&#19982;&#39044;&#27979;&#30456;&#20851;&#30340;&#21487;&#38752;&#24615;&#20540;&#12290;&#23545;&#21487;&#38752;&#24615;&#24230;&#37327;&#30340;&#30740;&#31350;&#35201;&#27714;&#23384;&#22312;&#31616;&#21333;&#12289;&#21512;&#29702;&#21644;&#36890;&#29992;&#30340;&#21487;&#38752;&#24615;&#36136;&#37327;&#24230;&#37327;&#12290;&#23545;&#25512;&#33616;&#31995;&#32479;&#36136;&#37327;&#24230;&#37327;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20934;&#30830;&#24615;&#19978;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#26032;&#39062;&#24615;&#12289;&#24847;&#22806;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#20294;&#26159;&#23545;&#21487;&#38752;&#24615;/&#32622;&#20449;&#24230;&#36136;&#37327;&#24230;&#37327;&#30340;&#30740;&#31350;&#32570;&#20047;&#37325;&#35201;&#20869;&#23481;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#38752;&#24615;&#36136;&#37327;&#39044;&#27979;&#24230;&#37327;&#65288;RPI&#65289;&#21644;&#21487;&#38752;&#24615;&#36136;&#37327;&#25512;&#33616;&#24230;&#37327;&#65288;RRI&#65289;&#12290;&#36825;&#20004;&#20010;&#36136;&#37327;&#24230;&#37327;&#26159;&#22522;&#20110;&#19968;&#20010;&#20551;&#35774;&#65292;&#21363;&#36234;&#36866;&#21512;&#30340;&#21487;&#38752;&#24615;&#24230;&#37327;&#65292;&#22312;&#24212;&#29992;&#26102;&#23558;&#25552;&#20379;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#32467;&#26524;&#12290;&#24403;&#36866;&#24403;&#30340;&#21487;&#38752;&#24615;&#20540;&#19982;&#25512;&#33616;&#32467;&#26524;&#30456;&#20851;&#32852;&#26102;&#65292;&#36825;&#20123;&#21487;&#38752;&#24615;&#36136;&#37327;&#24230;&#37327;&#26174;&#31034;&#20102;&#20934;&#30830;&#24615;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Users want to know the reliability of the recommendations; they do not accept high predictions if there is no reliability evidence. Recommender systems should provide reliability values associated with the predictions. Research into reliability measures requires the existence of simple, plausible and universal reliability quality measures. Research into recommender system quality measures has focused on accuracy. Moreover, novelty, serendipity and diversity have been studied; nevertheless there is an important lack of research into reliability/confidence quality measures.   This paper proposes a reliability quality prediction measure (RPI) and a reliability quality recommendation measure (RRI). Both quality measures are based on the hypothesis that the more suitable a reliability measure is, the better accuracy results it will provide when applied. These reliability quality measures show accuracy improvements when appropriated reliability values are associated with their predictions (i
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#20013;&#65292;&#33258;&#21160;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#30340;&#24040;&#22823;&#28508;&#21147;&#20197;&#21450;&#30446;&#21069;&#30456;&#23545;&#23569;&#26377;&#30340;&#20851;&#27880;&#21644;&#24320;&#21457;&#12290;</title><link>https://arxiv.org/abs/2402.04453</link><description>&lt;p&gt;
&#33258;&#21160;&#26426;&#22120;&#23398;&#20064;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
The Potential of AutoML for Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04453
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#20013;&#65292;&#33258;&#21160;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#30340;&#24040;&#22823;&#28508;&#21147;&#20197;&#21450;&#30446;&#21069;&#30456;&#23545;&#23569;&#26377;&#30340;&#20851;&#27880;&#21644;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#24050;&#32463;&#22312;&#21253;&#25324;&#27169;&#22411;&#21387;&#32553;&#12289;&#26426;&#22120;&#32763;&#35793;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#39046;&#22495;&#22823;&#22823;&#25512;&#36827;&#20102;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#24212;&#29992;&#12290;&#25512;&#33616;&#31995;&#32479;&#65288;RecSys&#65289;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;ML&#30340;&#19968;&#20010;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;AutoML&#22312;RecSys&#31038;&#21306;&#20013;&#24182;&#27809;&#26377;&#24471;&#21040;&#22826;&#22810;&#20851;&#27880;&#65292;RecSys&#20063;&#27809;&#26377;&#22312;AutoML&#31038;&#21306;&#20013;&#24341;&#36215;&#26174;&#33879;&#30340;&#20851;&#27880;&#12290;&#30446;&#21069;&#21482;&#26377;&#23569;&#25968;&#20960;&#20010;&#30456;&#23545;&#31616;&#21333;&#30340;&#33258;&#21160;&#21270;&#25512;&#33616;&#31995;&#32479;&#65288;AutoRecSys&#65289;&#24211;&#37319;&#29992;&#20102;AutoML&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24211;&#37117;&#26159;&#22522;&#20110;&#23398;&#29983;&#39033;&#30446;&#24320;&#21457;&#30340;&#65292;&#24182;&#19988;&#27809;&#26377;&#25552;&#20379;AutoML&#24211;&#30340;&#21151;&#33021;&#21644;&#23436;&#21892;&#30340;&#24320;&#21457;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#22312;&#19968;&#20010;&#27809;&#26377;&#32463;&#39564;&#30340;&#29992;&#25143;&#24819;&#35201;&#23454;&#29616;&#19968;&#20010;&#25512;&#33616;&#31995;&#32479;&#30340;&#22330;&#26223;&#20013;&#65292;AutoML&#24211;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#26469;&#33258;15&#20010;&#24211;&#30340;60&#20010;AutoML&#12289;AutoRecSys&#12289;ML&#21644;RecSys&#31639;&#27861;&#20197;&#21450;&#19968;&#20010;&#22343;&#20540;&#39044;&#27979;&#22522;&#20934;&#27169;&#22411;&#22312;14&#20010;&#26174;&#24335;&#21453;&#39304;&#30340;RecSys&#25968;&#25454;&#38598;&#19978;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated Machine Learning (AutoML) has greatly advanced applications of Machine Learning (ML) including model compression, machine translation, and computer vision. Recommender Systems (RecSys) can be seen as an application of ML. Yet, AutoML has found little attention in the RecSys community; nor has RecSys found notable attention in the AutoML community. Only few and relatively simple Automated Recommender Systems (AutoRecSys) libraries exist that adopt AutoML techniques. However, these libraries are based on student projects and do not offer the features and thorough development of AutoML libraries. We set out to determine how AutoML libraries perform in the scenario of an inexperienced user who wants to implement a recommender system. We compared the predictive performance of 60 AutoML, AutoRecSys, ML, and RecSys algorithms from 15 libraries, including a mean predictor baseline, on 14 explicit feedback RecSys datasets. To simulate the perspective of an inexperienced user, the algo
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#39033;&#30446;&#30340;&#30446;&#26631;&#26159;&#20026;ClueWeb22-B&#25968;&#25454;&#38598;&#30340;&#33521;&#25991;&#37096;&#20998;&#26500;&#24314;&#26816;&#32034;&#22522;&#32447;&#65292;&#21487;&#20197;&#20379;&#30740;&#31350;&#30028;&#27604;&#36739;&#20854;&#31995;&#32479;&#24182;&#35757;&#32451;/&#35780;&#20272;&#26032;&#30340;&#26816;&#32034;&#21644;&#25490;&#24207;&#31639;&#27861;&#12290;&#26500;&#24314;&#30340;&#31995;&#32479;&#21253;&#25324;&#31232;&#30095;&#21644;&#23494;&#38598;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#20197;&#21450;&#31070;&#32463;&#37325;&#26032;&#25490;&#24207;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.04357</link><description>&lt;p&gt;
&#20026;ClueWeb22-B&#35821;&#26009;&#24211;&#26500;&#24314;&#26816;&#32034;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Building Retrieval Systems for the ClueWeb22-B Corpus
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04357
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#39033;&#30446;&#30340;&#30446;&#26631;&#26159;&#20026;ClueWeb22-B&#25968;&#25454;&#38598;&#30340;&#33521;&#25991;&#37096;&#20998;&#26500;&#24314;&#26816;&#32034;&#22522;&#32447;&#65292;&#21487;&#20197;&#20379;&#30740;&#31350;&#30028;&#27604;&#36739;&#20854;&#31995;&#32479;&#24182;&#35757;&#32451;/&#35780;&#20272;&#26032;&#30340;&#26816;&#32034;&#21644;&#25490;&#24207;&#31639;&#27861;&#12290;&#26500;&#24314;&#30340;&#31995;&#32479;&#21253;&#25324;&#31232;&#30095;&#21644;&#23494;&#38598;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#20197;&#21450;&#31070;&#32463;&#37325;&#26032;&#25490;&#24207;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ClueWeb22&#25968;&#25454;&#38598;&#21253;&#21547;&#36817;100&#20159;&#20010;&#25991;&#26723;&#65292;&#20110;2022&#24180;&#21457;&#24067;&#29992;&#20110;&#25903;&#25345;&#23398;&#26415;&#21644;&#34892;&#19994;&#30740;&#31350;&#12290;&#26412;&#39033;&#30446;&#30340;&#30446;&#26631;&#26159;&#20026;&#35813;&#25968;&#25454;&#38598;&#30340;&#33521;&#25991;&#37096;&#20998;&#65288;&#36229;&#22836;&#37096;&#20998;&#31867;B&#65289;&#26500;&#24314;&#26816;&#32034;&#22522;&#32447;&#12290;&#36825;&#20123;&#22522;&#32447;&#21487;&#20197;&#20379;&#30740;&#31350;&#30028;&#20351;&#29992;&#65292;&#29992;&#20110;&#27604;&#36739;&#20854;&#31995;&#32479;&#65292;&#24182;&#29983;&#25104;&#25968;&#25454;&#20197;&#35757;&#32451;/&#35780;&#20272;&#26032;&#30340;&#26816;&#32034;&#21644;&#25490;&#24207;&#31639;&#27861;&#12290;&#25253;&#21578;&#28085;&#30422;&#20102;&#38024;&#23545;&#35813;&#25968;&#25454;&#38598;&#23454;&#26045;&#30340;&#31232;&#30095;&#21644;&#23494;&#38598;&#30340;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#65292;&#20197;&#21450;&#31070;&#32463;&#37325;&#26032;&#25490;&#24207;&#22120;&#12290;&#36825;&#20123;&#31995;&#32479;&#21487;&#22312;&#21345;&#20869;&#22522;&#26757;&#38534;&#22823;&#23398;&#38598;&#32676;&#19978;&#20316;&#20026;&#26381;&#21153;&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ClueWeb22 dataset containing nearly 10 billion documents was released in 2022 to support academic and industry research. The goal of this project was to build retrieval baselines for the English section of the "super head" part (category B) of this dataset. These baselines can then be used by the research community to compare their systems and also to generate data to train/evaluate new retrieval and ranking algorithms. The report covers sparse and dense first stage retrievals as well as neural rerankers that were implemented for this dataset. These systems are available as a service on a Carnegie Mellon University cluster.
&lt;/p&gt;</description></item><item><title>&#22312;&#35831;&#27714;&#32423;&#21035;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#26041;&#27861;&#21644;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.16108</link><description>&lt;p&gt;
&#35831;&#27714;&#32423;&#21035;&#25512;&#33616;&#20013;&#30340;&#26410;&#26469;&#24433;&#21709;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Future Impact Decomposition in Request-level Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.16108
&lt;/p&gt;
&lt;p&gt;
&#22312;&#35831;&#27714;&#32423;&#21035;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#26041;&#27861;&#21644;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#24378;&#21270;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#22312;&#20248;&#21270;&#29992;&#25143;&#21644;&#31995;&#32479;&#20043;&#38388;&#30340;&#20132;&#20114;&#24207;&#21015;&#20197;&#25552;&#39640;&#38271;&#26399;&#24615;&#33021;&#26041;&#38754;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#20986;&#20110;&#23454;&#38469;&#21407;&#22240;&#65292;&#31574;&#30053;&#30340;&#21160;&#20316;&#36890;&#24120;&#34987;&#35774;&#35745;&#20026;&#25512;&#33616;&#19968;&#32452;&#29289;&#21697;&#20197;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#29992;&#25143;&#30340;&#39057;&#32321;&#21644;&#36830;&#32493;&#30340;&#27983;&#35272;&#35831;&#27714;&#12290;&#22312;&#36825;&#31181;&#21015;&#34920;&#24335;&#25512;&#33616;&#22330;&#26223;&#20013;&#65292;&#29992;&#25143;&#29366;&#24577;&#22312;&#30456;&#24212;&#30340;MDP&#65288;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65289;&#34920;&#36848;&#20013;&#30340;&#27599;&#20010;&#35831;&#27714;&#19978;&#37117;&#20250;&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35831;&#27714;&#32423;&#21035;&#30340;&#34920;&#36848;&#19982;&#29992;&#25143;&#30340;&#29289;&#21697;&#32423;&#21035;&#34892;&#20026;&#23454;&#36136;&#19978;&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#35831;&#27714;&#32423;&#21035;MDP&#19979;&#65292;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#29289;&#21697;&#29305;&#24615;&#24182;&#20248;&#21270;&#31574;&#30053;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#26631;&#20934;&#35831;&#27714;&#32423;&#21035;&#26041;&#27861;&#21644;&#25552;&#20986;&#30340;&#22522;&#20110;&#29289;&#21697;&#32423;&#21035;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26694;&#26550;&#22312;&#27169;&#25311;&#21644;&#22312;&#32447;&#23454;&#39564;&#20013;&#30340;&#24615;&#33021;&#26469;&#25903;&#25345;&#36825;&#19968;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommender systems, reinforcement learning solutions have shown promising results in optimizing the interaction sequence between users and the system over the long-term performance. For practical reasons, the policy's actions are typically designed as recommending a list of items to handle users' frequent and continuous browsing requests more efficiently. In this list-wise recommendation scenario, the user state is updated upon every request in the corresponding MDP formulation. However, this request-level formulation is essentially inconsistent with the user's item-level behavior. In this study, we demonstrate that an item-level optimization approach can better utilize item characteristics and optimize the policy's performance even under the request-level MDP. We support this claim by comparing the performance of standard request-level methods with the proposed item-level actor-critic framework in both simulation and online experiments. Furthermore, we show that a reward-based fut
&lt;/p&gt;</description></item><item><title>&#25991;&#26412;&#20998;&#26512;&#26159;&#19968;&#20010;&#26377;&#36259;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#22312;&#25968;&#25454;&#31185;&#23398;&#20013;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#25991;&#26412;&#20998;&#26512;&#30340;&#24120;&#35265;&#26041;&#27861;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26041;&#27861;Topic-SCORE&#65292;&#24182;&#22312;&#32479;&#35745;&#20986;&#29256;&#29289;&#25968;&#25454;&#38598;MADStat&#19978;&#36827;&#34892;&#20102;&#24212;&#29992;&#12290;&#36890;&#36807;&#23545;MADStat&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;11&#20010;&#20195;&#34920;&#32479;&#35745;&#39046;&#22495;&#30340;&#20027;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#27169;&#22411;&#26469;&#35780;&#20272;&#20027;&#39064;&#30340;&#24341;&#29992;&#24433;&#21709;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#26500;&#24314;&#20102;&#19968;&#20010;&#36328;&#20027;&#39064;&#30340;&#24341;&#29992;&#22270;&#26469;&#20998;&#26512;&#30740;&#31350;&#32467;&#26524;&#22312;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#20256;&#25773;&#12290;</title><link>https://arxiv.org/abs/2401.00775</link><description>&lt;p&gt;
&#25991;&#26412;&#20998;&#26512;&#30340;&#26368;&#26032;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Recent Advances in Text Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.00775
&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#20998;&#26512;&#26159;&#19968;&#20010;&#26377;&#36259;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#22312;&#25968;&#25454;&#31185;&#23398;&#20013;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#25991;&#26412;&#20998;&#26512;&#30340;&#24120;&#35265;&#26041;&#27861;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26041;&#27861;Topic-SCORE&#65292;&#24182;&#22312;&#32479;&#35745;&#20986;&#29256;&#29289;&#25968;&#25454;&#38598;MADStat&#19978;&#36827;&#34892;&#20102;&#24212;&#29992;&#12290;&#36890;&#36807;&#23545;MADStat&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;11&#20010;&#20195;&#34920;&#32479;&#35745;&#39046;&#22495;&#30340;&#20027;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#27169;&#22411;&#26469;&#35780;&#20272;&#20027;&#39064;&#30340;&#24341;&#29992;&#24433;&#21709;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#26500;&#24314;&#20102;&#19968;&#20010;&#36328;&#20027;&#39064;&#30340;&#24341;&#29992;&#22270;&#26469;&#20998;&#26512;&#30740;&#31350;&#32467;&#26524;&#22312;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#20998;&#26512;&#26159;&#25968;&#25454;&#31185;&#23398;&#20013;&#19968;&#20010;&#26377;&#36259;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#20855;&#26377;&#20154;&#24037;&#26234;&#33021;&#12289;&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#21644;&#24037;&#31243;&#31561;&#22810;&#31181;&#24212;&#29992;&#12290;&#25105;&#20204;&#22238;&#39038;&#20102;&#25991;&#26412;&#20998;&#26512;&#30340;&#27969;&#34892;&#26041;&#27861;&#65292;&#20174;&#20027;&#39064;&#24314;&#27169;&#21040;&#26368;&#26032;&#30340;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;Topic-SCORE&#65292;&#19968;&#31181;&#29992;&#20110;&#20027;&#39064;&#24314;&#27169;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#22914;&#20309;&#20351;&#29992;&#23427;&#26469;&#20998;&#26512;&#25105;&#20204;&#25910;&#38598;&#21644;&#28165;&#29702;&#30340;&#32479;&#35745;&#20986;&#29256;&#29289;&#25968;&#25454;&#38598;MADStat&#12290;&#22312;MADStat&#19978;&#24212;&#29992;Topic-SCORE&#21644;&#20854;&#20182;&#26041;&#27861;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#21457;&#29616;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#37492;&#23450;&#20986;&#20102;&#32479;&#35745;&#39046;&#22495;&#20013;11&#20010;&#20195;&#34920;&#24615;&#30340;&#20027;&#39064;&#12290;&#23545;&#20110;&#27599;&#20010;&#26399;&#21002;&#65292;&#21487;&#20197;&#21487;&#35270;&#21270;&#20027;&#39064;&#26435;&#37325;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#20998;&#26512;&#32479;&#35745;&#30740;&#31350;&#30340;&#36235;&#21183;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25490;&#21517;11&#20010;&#20027;&#39064;&#24341;&#29992;&#24433;&#21709;&#30340;&#26032;&#30340;&#32479;&#35745;&#27169;&#22411;&#65292;&#36824;&#26500;&#24314;&#20102;&#19968;&#20010;&#36328;&#20027;&#39064;&#30340;&#24341;&#29992;&#22270;&#65292;&#20197;&#35828;&#26126;&#19981;&#21516;&#20027;&#39064;&#30340;&#30740;&#31350;&#25104;&#26524;&#26159;&#22914;&#20309;&#20256;&#25773;&#21040;&#20854;&#20182;&#39046;&#22495;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Text analysis is an interesting research area in data science and has various applications, such as in artificial intelligence, biomedical research, and engineering. We review popular methods for text analysis, ranging from topic modeling to the recent neural language models. In particular, we review Topic-SCORE, a statistical approach to topic modeling, and discuss how to use it to analyze MADStat - a dataset on statistical publications that we collected and cleaned.   The application of Topic-SCORE and other methods on MADStat leads to interesting findings. For example, $11$ representative topics in statistics are identified. For each journal, the evolution of topic weights over time can be visualized, and these results are used to analyze the trends in statistical research. In particular, we propose a new statistical model for ranking the citation impacts of $11$ topics, and we also build a cross-topic citation graph to illustrate how research results on different topics spread to o
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#25143;&#21451;&#22909;&#30340;&#20132;&#20114;&#24335;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#65292;&#36890;&#36807;&#29992;&#25143;&#20998;&#37197;&#21333;&#35789;&#26631;&#31614;&#26469;&#26356;&#26032;&#20027;&#39064;&#27169;&#22411;&#65292;&#20351;&#24471;&#20027;&#39064;&#26356;&#21152;&#30456;&#20851;&#21644;&#20934;&#30830;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#21487;&#35757;&#32451;&#21644;&#21518;&#35757;&#32451;&#38598;&#25104;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2311.09438</link><description>&lt;p&gt;
&#26631;&#35760;&#20132;&#20114;&#24335;&#20027;&#39064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Labeled Interactive Topic Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09438
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#25143;&#21451;&#22909;&#30340;&#20132;&#20114;&#24335;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#65292;&#36890;&#36807;&#29992;&#25143;&#20998;&#37197;&#21333;&#35789;&#26631;&#31614;&#26469;&#26356;&#26032;&#20027;&#39064;&#27169;&#22411;&#65292;&#20351;&#24471;&#20027;&#39064;&#26356;&#21152;&#30456;&#20851;&#21644;&#20934;&#30830;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#21487;&#35757;&#32451;&#21644;&#21518;&#35757;&#32451;&#38598;&#25104;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#39064;&#27169;&#22411;&#23545;&#20110;&#29702;&#35299;&#22823;&#37327;&#25991;&#26723;&#38598;&#21512;&#38750;&#24120;&#26377;&#20215;&#20540;&#65292;&#20294;&#26159;&#23427;&#20204;&#24182;&#19981;&#24635;&#26159;&#33021;&#22815;&#35782;&#21035;&#20986;&#26368;&#30456;&#20851;&#30340;&#20027;&#39064;&#12290;&#20256;&#32479;&#30340;&#27010;&#29575;&#21644;&#22522;&#20110;&#38170;&#28857;&#30340;&#20027;&#39064;&#27169;&#22411;&#25552;&#20379;&#20102;&#20801;&#35768;&#29992;&#25143;&#24341;&#23548;&#27169;&#22411;&#25351;&#21521;&#26356;&#30456;&#20851;&#20027;&#39064;&#30340;&#20132;&#20114;&#29256;&#26412;&#12290;&#28982;&#32780;&#65292;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#32570;&#20047;&#36825;&#31181;&#20132;&#20114;&#21151;&#33021;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#19981;&#36275;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#29992;&#25143;&#21451;&#22909;&#30340;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#20132;&#20114;&#26041;&#27861;&#12290;&#36825;&#31181;&#20132;&#20114;&#20801;&#35768;&#29992;&#25143;&#20026;&#19968;&#20010;&#20027;&#39064;&#20998;&#37197;&#19968;&#20010;&#21333;&#35789;&#26631;&#31614;&#65292;&#20174;&#32780;&#26356;&#26032;&#20027;&#39064;&#27169;&#22411;&#65292;&#20351;&#20027;&#39064;&#20013;&#30340;&#21333;&#35789;&#19982;&#32473;&#23450;&#30340;&#26631;&#31614;&#23494;&#20999;&#23545;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#12290;&#31532;&#19968;&#31181;&#21253;&#25324;&#20027;&#39064;&#23884;&#20837;&#21487;&#35757;&#32451;&#19988;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#28436;&#21464;&#30340;&#27169;&#22411;&#12290;&#31532;&#20108;&#31181;&#28041;&#21450;&#20027;&#39064;&#23884;&#20837;&#21518;&#35757;&#32451;&#38598;&#25104;&#30340;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#20027;&#39064;&#32454;&#21270;&#26041;&#27861;&#12290;&#20026;&#20102;&#26041;&#20415;&#29992;&#25143;&#19982;&#36825;&#20123;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#20132;&#20114;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#20132;&#20114;&#24335;&#22270;&#24418;&#29992;&#25143;&#30028;&#38754;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topic models are valuable for understanding extensive document collections, but they don't always identify the most relevant topics. Classical probabilistic and anchor-based topic models offer interactive versions that allow users to guide the models towards more pertinent topics. However, such interactive features have been lacking in neural topic models. To correct this lacuna, we introduce a user-friendly interaction for neural topic models. This interaction permits users to assign a word label to a topic, leading to an update in the topic model where the words in the topic become closely aligned with the given label. Our approach encompasses two distinct kinds of neural topic models. The first includes models where topic embeddings are trainable and evolve during the training process. The second kind involves models where topic embeddings are integrated post-training, offering a different approach to topic refinement. To facilitate user interaction with these neural topic models, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22810;&#26679;&#21270;&#32467;&#26524;&#38598;&#26469;&#22686;&#21152;&#26222;&#36890;&#25991;&#26723;&#25490;&#21517;&#26032;&#40092;&#24230;&#30340;&#32593;&#32476;&#25628;&#32034;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29992;&#25143;&#30340;&#28385;&#24847;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.14595</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#26679;&#24615;&#32467;&#26524;&#38598;&#23454;&#29616;&#26368;&#26032;&#24615;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Recency Ranking by Diversification of Result Set. (arXiv:2401.14595v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22810;&#26679;&#21270;&#32467;&#26524;&#38598;&#26469;&#22686;&#21152;&#26222;&#36890;&#25991;&#26723;&#25490;&#21517;&#26032;&#40092;&#24230;&#30340;&#32593;&#32476;&#25628;&#32034;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29992;&#25143;&#30340;&#28385;&#24847;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32593;&#32476;&#25628;&#32034;&#26816;&#32034;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#33258;&#21160;&#35782;&#21035;&#23545;&#26368;&#26032;&#20869;&#23481;&#25935;&#24863;&#30340;&#26597;&#35810;&#65292;&#24182;&#36890;&#36807;&#19982;&#26368;&#36817;&#20869;&#23481;&#38656;&#27714;&#30340;&#27010;&#29575;&#25104;&#27604;&#20363;&#22320;&#22686;&#21152;&#26222;&#36890;&#25991;&#26723;&#25490;&#21517;&#30340;&#26032;&#40092;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#32467;&#26524;&#22810;&#26679;&#24615;&#21407;&#21017;&#26469;&#35299;&#20915;&#26368;&#26032;&#24615;&#25490;&#21517;&#38382;&#39064;&#65292;&#24182;&#22788;&#29702;&#26597;&#35810;&#30340;&#38750;&#20027;&#39064;&#27495;&#20041;&#65292;&#36825;&#31181;&#27495;&#20041;&#21482;&#33021;&#20197;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#24335;&#26816;&#27979;&#21040;&#26368;&#36817;&#20869;&#23481;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#31163;&#32447;&#21644;&#22312;&#32447;&#23454;&#39564;&#20351;&#29992;&#20102;&#26469;&#33258;&#30495;&#23454;&#25628;&#32034;&#24341;&#25806;&#29992;&#25143;&#30340;&#25968;&#30334;&#19975;&#20010;&#26597;&#35810;&#65292;&#32467;&#26524;&#34920;&#26126;&#36890;&#36807;&#25105;&#20204;&#30340;&#26041;&#27861;&#29983;&#25104;&#30340;&#25628;&#32034;&#32467;&#26524;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29992;&#25143;&#30340;&#28385;&#24847;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a web search retrieval approach which automatically detects recency sensitive queries and increases the freshness of the ordinary document ranking by a degree proportional to the probability of the need in recent content. We propose to solve the recency ranking problem by using result diversification principles and deal with the query's non-topical ambiguity appearing when the need in recent content can be detected only with uncertainty. Our offline and online experiments with millions of queries from real search engine users demonstrate the significant increase in satisfaction of users presented with a search result generated by our approach.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#19987;&#21033;&#25991;&#20214;&#20013;&#25552;&#21462;&#24037;&#31243;&#35774;&#35745;&#30693;&#35782;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#30693;&#35782;&#22270;&#26469;&#22635;&#20805;&#36890;&#29992;&#35774;&#35745;&#30693;&#35782;&#65292;&#24182;&#19982;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2307.06985</link><description>&lt;p&gt;
&#36808;&#21521;&#22635;&#20805;&#36890;&#29992;&#24037;&#31243;&#35774;&#35745;&#30693;&#35782;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Populating Generalizable Engineering Design Knowledge. (arXiv:2307.06985v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06985
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#19987;&#21033;&#25991;&#20214;&#20013;&#25552;&#21462;&#24037;&#31243;&#35774;&#35745;&#30693;&#35782;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#30693;&#35782;&#22270;&#26469;&#22635;&#20805;&#36890;&#29992;&#35774;&#35745;&#30693;&#35782;&#65292;&#24182;&#19982;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22635;&#20805;&#36890;&#29992;&#24037;&#31243;&#35774;&#35745;&#30693;&#35782;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#19987;&#21033;&#25991;&#20214;&#20013;&#25552;&#21462;head entity :: relationship :: tail entity&#24418;&#24335;&#20107;&#23454;&#30340;&#26041;&#27861;&#12290;&#36825;&#20123;&#20107;&#23454;&#21487;&#20197;&#22312;&#19987;&#21033;&#25991;&#20214;&#20869;&#37096;&#21644;&#36328;&#25991;&#20214;&#20043;&#38388;&#32452;&#21512;&#24418;&#25104;&#30693;&#35782;&#22270;&#65292;&#29992;&#20316;&#34920;&#31034;&#21644;&#23384;&#20648;&#35774;&#35745;&#30693;&#35782;&#30340;&#26041;&#26696;&#12290;&#29616;&#26377;&#30340;&#24037;&#31243;&#35774;&#35745;&#25991;&#29486;&#20013;&#30340;&#26041;&#27861;&#36890;&#24120;&#21033;&#29992;&#19968;&#32452;&#39044;&#23450;&#20041;&#30340;&#20851;&#31995;&#26469;&#22635;&#20805;&#32479;&#35745;&#36817;&#20284;&#32780;&#38750;&#20107;&#23454;&#30340;&#19977;&#20803;&#32452;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#35757;&#32451;&#19968;&#20010;&#26631;&#35760;&#22120;&#26469;&#35782;&#21035;&#21477;&#23376;&#20013;&#30340;&#23454;&#20307;&#21644;&#20851;&#31995;&#12290;&#22312;&#30830;&#23450;&#20102;&#19968;&#23545;&#23454;&#20307;&#21518;&#65292;&#25105;&#20204;&#35757;&#32451;&#21478;&#19968;&#20010;&#26631;&#35760;&#22120;&#26469;&#35782;&#21035;&#29305;&#23450;&#34920;&#31034;&#36825;&#23545;&#23454;&#20307;&#20043;&#38388;&#20851;&#31995;&#30340;&#20851;&#31995;&#26631;&#35760;&#12290;&#20026;&#20102;&#35757;&#32451;&#36825;&#20123;&#26631;&#35760;&#22120;&#65292;&#25105;&#20204;&#25163;&#21160;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;44,227&#20010;&#21477;&#23376;&#21644;&#30456;&#24212;&#20107;&#23454;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#36824;&#23558;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#19982;&#36890;&#24120;&#25512;&#33616;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#20854;&#20013;&#25105;&#20204;&#39044;.
&lt;/p&gt;
&lt;p&gt;
Aiming to populate generalizable engineering design knowledge, we propose a method to extract facts of the form head entity :: relationship :: tail entity from sentences found in patent documents. These facts could be combined within and across patent documents to form knowledge graphs that serve as schemes for representing as well as storing design knowledge. Existing methods in engineering design literature often utilise a set of predefined relationships to populate triples that are statistical approximations rather than facts. In our method, we train a tagger to identify both entities and relationships from a sentence. Given a pair of entities thus identified, we train another tagger to identify the relationship tokens that specifically denote the relationship between the pair. For training these taggers, we manually construct a dataset of 44,227 sentences and corresponding facts. We also compare the performance of the method against typically recommended approaches, wherein, we pre
&lt;/p&gt;</description></item></channel></rss>