<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65288;COVE&#65289;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19979;&#30340;&#23454;&#20307;&#20998;&#31867;&#20449;&#24687;&#65292;&#24182;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16761</link><description>&lt;p&gt;
&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Co-evolving Vector Quantization for ID-based Recommendation. (arXiv:2308.16761v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16761
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#30340;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65288;COVE&#65289;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19979;&#30340;&#23454;&#20307;&#20998;&#31867;&#20449;&#24687;&#65292;&#24182;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31867;&#21035;&#20449;&#24687;&#23545;&#20110;&#25552;&#39640;&#25512;&#33616;&#30340;&#36136;&#37327;&#21644;&#20010;&#24615;&#21270;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#20013;&#65292;&#39033;&#30446;&#31867;&#21035;&#20449;&#24687;&#30340;&#21487;&#29992;&#24615;&#24182;&#19981;&#19968;&#33268;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#20197;&#33258;&#21160;&#23398;&#20064;&#21644;&#29983;&#25104;&#23454;&#20307;&#65288;&#21363;&#29992;&#25143;&#21644;&#39033;&#30446;&#65289;&#22312;&#19981;&#21516;&#31890;&#24230;&#32423;&#21035;&#19978;&#30340;&#20998;&#31867;&#20449;&#24687;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20849;&#21516;&#28436;&#21270;&#21521;&#37327;&#37327;&#21270;&#26694;&#26550;&#65292;&#21363;COVE&#65292;&#23427;&#33021;&#22815;&#21516;&#26102;&#23398;&#20064;&#21644;&#25913;&#36827;&#20195;&#30721;&#34920;&#31034;&#21644;&#23454;&#20307;&#23884;&#20837;&#65292;&#24182;&#20197;&#20174;&#38543;&#26426;&#21021;&#22987;&#21270;&#29366;&#24577;&#24320;&#22987;&#30340;&#31471;&#21040;&#31471;&#26041;&#24335;&#36827;&#34892;&#12290;&#36890;&#36807;&#20854;&#39640;&#24230;&#36866;&#24212;&#24615;&#65292;COVE&#21487;&#20197;&#36731;&#26494;&#38598;&#25104;&#21040;&#29616;&#26377;&#30340;&#25512;&#33616;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;COVE&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#21015;&#34920;&#23436;&#25104;&#12289;&#21327;&#21516;&#36807;&#28388;&#21644;&#28857;&#20987;&#29575;&#39044;&#27979;&#65292;&#28085;&#30422;&#19981;&#21516;&#30340;&#25512;&#33616;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Category information plays a crucial role in enhancing the quality and personalization of recommendations. Nevertheless, the availability of item category information is not consistently present, particularly in the context of ID-based recommendations. In this work, we propose an alternative approach to automatically learn and generate entity (i.e., user and item) categorical information at different levels of granularity, specifically for ID-based recommendation. Specifically, we devise a co-evolving vector quantization framework, namely COVE, which enables the simultaneous learning and refinement of code representation and entity embedding in an end-to-end manner, starting from the randomly initialized states. With its high adaptability, COVE can be easily integrated into existing recommendation models. We validate the effectiveness of COVE on various recommendation tasks including list completion, collaborative filtering, and click-through rate prediction, across different recommend
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65288;KC&#65289;&#65292;&#36890;&#36807;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#26597;&#35810;&#20998;&#31867;&#24615;&#33021;&#65292;&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2308.01098</link><description>&lt;p&gt;
&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21033;&#29992;&#22810;&#19987;&#23478;&#30693;&#35782;&#33976;&#39311;&#23454;&#29616;&#26356;&#22909;&#30340;&#26597;&#35810;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search. (arXiv:2308.01098v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65288;KC&#65289;&#65292;&#36890;&#36807;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#26597;&#35810;&#20998;&#31867;&#24615;&#33021;&#65292;&#22312;&#20140;&#19996;&#24191;&#21578;&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#20998;&#31867;&#20316;&#20026;&#29702;&#35299;&#29992;&#25143;&#24847;&#22270;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22312;&#32447;&#24191;&#21578;&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#20026;&#20102;&#30830;&#20445;&#26356;&#20302;&#30340;&#24310;&#36831;&#65292;&#24120;&#20351;&#29992;&#27973;&#23618;&#27169;&#22411;&#65288;&#22914;FastText&#65289;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;FastText&#27169;&#22411;&#30340;&#34920;&#24449;&#33021;&#21147;&#19981;&#36275;&#65292;&#23548;&#33268;&#20998;&#31867;&#24615;&#33021;&#36739;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#19968;&#20123;&#20302;&#39057;&#26597;&#35810;&#21644;&#23614;&#37096;&#31867;&#21035;&#19978;&#12290;&#20351;&#29992;&#26356;&#28145;&#20837;&#19988;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#65288;&#22914;BERT&#65289;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#23558;&#23548;&#33268;&#26356;&#39640;&#30340;&#22312;&#32447;&#25512;&#26029;&#24310;&#36831;&#21644;&#26356;&#26114;&#36149;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22240;&#27492;&#65292;&#22914;&#20309;&#22312;&#25512;&#26029;&#25928;&#29575;&#21644;&#20998;&#31867;&#24615;&#33021;&#20043;&#38388;&#25240;&#34935;&#26174;&#28982;&#20855;&#26377;&#37325;&#22823;&#23454;&#38469;&#24847;&#20041;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#30693;&#35782;&#33976;&#39311;&#65288;KC&#65289;&#65292;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#65292;&#20197;&#22312;&#20005;&#26684;&#30340;&#20302;&#24310;&#36831;&#32422;&#26463;&#19979;&#25552;&#21319;&#22312;&#32447;FastText&#27169;&#22411;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35757;&#32451;&#19968;&#20010;&#31163;&#32447;&#27169;&#22411;&#65292;&#36890;&#36807;&#33976;&#39311;&#30693;&#35782;&#26469;&#25913;&#21892;&#22312;&#32447;&#27169;&#22411;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Search query classification, as an effective way to understand user intents, is of great importance in real-world online ads systems. To ensure a lower latency, a shallow model (e.g. FastText) is widely used for efficient online inference. However, the representation ability of the FastText model is insufficient, resulting in poor classification performance, especially on some low-frequency queries and tailed categories. Using a deeper and more complex model (e.g. BERT) is an effective solution, but it will cause a higher online inference latency and more expensive computing costs. Thus, how to juggle both inference efficiency and classification performance is obviously of great practical importance. To overcome this challenge, in this paper, we propose knowledge condensation (KC), a simple yet effective knowledge distillation framework to boost the classification performance of the online FastText model under strict low latency constraints. Specifically, we propose to train an offline
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;LLMs&#21327;&#21161;&#20154;&#31867;&#19987;&#23478;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#21487;&#33021;&#26041;&#27861;&#21644;&#38382;&#39064;&#65292;&#21046;&#23450;&#20102;&#20154;&#26426;&#21327;&#20316;&#35889;&#31995;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#19982;&#32463;&#36807;&#35757;&#32451;&#30340;&#20154;&#31867;&#35780;&#20272;&#32773;&#21028;&#26029;&#30456;&#20851;&#24615;&#30340;&#21021;&#27493;&#23454;&#39564;&#65292;&#20197;&#21450;&#25903;&#25345;&#21644;&#21453;&#23545;&#20351;&#29992;LLMs&#36827;&#34892;&#33258;&#21160;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20004;&#20010;&#23545;&#31435;&#35266;&#28857;&#20197;&#21450;&#22949;&#21327;&#30340;&#35266;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.09161</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#30456;&#20851;&#24615;&#35780;&#20215;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Perspectives on Large Language Models for Relevance Judgment. (arXiv:2304.09161v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09161
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;LLMs&#21327;&#21161;&#20154;&#31867;&#19987;&#23478;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#21487;&#33021;&#26041;&#27861;&#21644;&#38382;&#39064;&#65292;&#21046;&#23450;&#20102;&#20154;&#26426;&#21327;&#20316;&#35889;&#31995;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#19982;&#32463;&#36807;&#35757;&#32451;&#30340;&#20154;&#31867;&#35780;&#20272;&#32773;&#21028;&#26029;&#30456;&#20851;&#24615;&#30340;&#21021;&#27493;&#23454;&#39564;&#65292;&#20197;&#21450;&#25903;&#25345;&#21644;&#21453;&#23545;&#20351;&#29992;LLMs&#36827;&#34892;&#33258;&#21160;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20004;&#20010;&#23545;&#31435;&#35266;&#28857;&#20197;&#21450;&#22949;&#21327;&#30340;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#34987;&#38382;&#21450;&#26102;&#65292;&#20687;ChatGPT&#36825;&#26679;&#30340;&#24403;&#21069;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22768;&#31216;&#23427;&#20204;&#21487;&#20197;&#21327;&#21161;&#25105;&#20204;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#12290;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#35748;&#20026;&#36825;&#19981;&#20250;&#23548;&#33268;&#21487;&#20449;&#30340;&#20449;&#24687;&#26816;&#32034;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;LLMs&#21327;&#21161;&#20154;&#31867;&#19987;&#23478;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#21487;&#33021;&#26041;&#27861;&#20197;&#21450;&#21487;&#33021;&#20986;&#29616;&#30340;&#38382;&#39064;&#21644;&#20851;&#27880;&#28857;&#12290;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#35889;&#31995;&#65292;&#21487;&#20197;&#23558;&#19981;&#21516;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#31574;&#30053;&#36827;&#34892;&#20998;&#31867;&#65292;&#22522;&#20110;&#20154;&#31867;&#23545;&#26426;&#22120;&#30340;&#20381;&#36182;&#31243;&#24230;&#12290;&#38024;&#23545;&#8220;&#23436;&#20840;&#33258;&#21160;&#21270;&#35780;&#20272;&#8221;&#30340;&#26497;&#31471;&#28857;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#36827;&#34892;&#20102;&#22522;&#20110;LLM&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#19982;&#32463;&#36807;&#35757;&#32451;&#30340;&#20154;&#31867;&#35780;&#20272;&#32773;&#21028;&#26029;&#30340;&#30456;&#20851;&#24615;&#30340;&#21021;&#27493;&#23454;&#39564;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#25991;&#29486;&#12289;&#25105;&#20204;&#30340;&#21021;&#27493;&#23454;&#39564;&#35777;&#25454;&#20197;&#21450;&#25105;&#20204;&#20316;&#20026;&#20449;&#24687;&#26816;&#32034;&#30740;&#31350;&#20154;&#21592;&#30340;&#32463;&#39564;&#65292;&#25552;&#20986;&#20102;&#25903;&#25345;&#21644;&#21453;&#23545;&#20351;&#29992;LLMs&#36827;&#34892;&#33258;&#21160;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20004;&#20010;&#23545;&#31435;&#35266;&#28857;&#20197;&#21450;&#22949;&#21327;&#30340;&#35266;&#28857;&#12290;&#25105;&#20204;&#24076;&#26395;&#24320;&#22987;&#36827;&#34892;&#24314;&#35774;&#24615;&#30340;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
When asked, current large language models (LLMs) like ChatGPT claim that they can assist us with relevance judgments. Many researchers think this would not lead to credible IR research. In this perspective paper, we discuss possible ways for LLMs to assist human experts along with concerns and issues that arise. We devise a human-machine collaboration spectrum that allows categorizing different relevance judgment strategies, based on how much the human relies on the machine. For the extreme point of "fully automated assessment", we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing two opposing perspectives - for and against the use of LLMs for automatic relevance judgments - and a compromise perspective, informed by our analyses of the literature, our preliminary experimental evidence, and our experience as IR researchers.  We hope to start a constructive discussion withi
&lt;/p&gt;</description></item><item><title>TalkTheWalk &#26159;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#21033;&#29992;&#31934;&#24515;&#31574;&#21010;&#30340;&#39033;&#30446;&#25910;&#34255;&#20013;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#21512;&#25104;&#36924;&#30495;&#39640;&#36136;&#37327;&#30340;&#20250;&#35805;&#25968;&#25454;&#65292;&#35299;&#20915;&#20102;&#26500;&#24314;&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2301.11489</link><description>&lt;p&gt;
Talk the Walk: &#38024;&#23545;&#20250;&#35805;&#24335;&#38899;&#20048;&#25512;&#33616;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Talk the Walk: Synthetic Data Generation for Conversational Music Recommendation. (arXiv:2301.11489v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11489
&lt;/p&gt;
&lt;p&gt;
TalkTheWalk &#26159;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#21033;&#29992;&#31934;&#24515;&#31574;&#21010;&#30340;&#39033;&#30446;&#25910;&#34255;&#20013;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#21512;&#25104;&#36924;&#30495;&#39640;&#36136;&#37327;&#30340;&#20250;&#35805;&#25968;&#25454;&#65292;&#35299;&#20915;&#20102;&#26500;&#24314;&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24191;&#27867;&#23384;&#22312;&#65292;&#20294;&#29992;&#25143;&#24448;&#24448;&#24456;&#38590;&#22312;&#25512;&#33616;&#36136;&#37327;&#36739;&#24046;&#26102;&#36827;&#34892;&#25511;&#21046;&#21644;&#35843;&#25972;&#12290;&#36825;&#20419;&#20351;&#20102;&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;(CRSs)&#30340;&#21457;&#23637;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#21453;&#39304;&#25552;&#20379;&#23545;&#25512;&#33616;&#30340;&#25511;&#21046;&#12290;&#28982;&#32780;&#65292;&#26500;&#24314;&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#38656;&#35201;&#21253;&#21547;&#29992;&#25143;&#35805;&#35821;&#21644;&#28085;&#30422;&#22810;&#26679;&#21270;&#20559;&#22909;&#33539;&#22260;&#30340;&#39033;&#30446;&#30340;&#20250;&#35805;&#35757;&#32451;&#25968;&#25454;&#12290;&#20351;&#29992;&#20256;&#32479;&#26041;&#27861;&#22914;&#20247;&#21253;&#65292;&#36825;&#26679;&#30340;&#25968;&#25454;&#25910;&#38598;&#36215;&#26469;&#38750;&#24120;&#22256;&#38590;&#12290;&#25105;&#20204;&#22312;&#39033;&#30446;&#38598;&#25512;&#33616;&#30340;&#32972;&#26223;&#19979;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#27880;&#24847;&#21040;&#36825;&#20010;&#20219;&#21153;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#20851;&#27880;&#65292;&#21160;&#26426;&#22312;&#20110;&#38899;&#20048;&#12289;&#26032;&#38395;&#21644;&#39135;&#35889;&#25512;&#33616;&#31561;&#20351;&#29992;&#26696;&#20363;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#25216;&#26415;TalkTheWalk&#65292;&#36890;&#36807;&#21033;&#29992;&#24191;&#27867;&#21487;&#33719;&#24471;&#30340;&#31934;&#24515;&#31574;&#21010;&#30340;&#39033;&#30446;&#25910;&#34255;&#20013;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#21512;&#25104;&#36924;&#30495;&#39640;&#36136;&#37327;&#30340;&#20250;&#35805;&#25968;&#25454;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#39033;&#30446;&#38598;&#31574;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems are ubiquitous yet often difficult for users to control and adjust when recommendation quality is poor. This has motivated the development of conversational recommendation systems (CRSs), with control over recommendations provided through natural language feedback. However, building conversational recommendation systems requires conversational training data involving user utterances paired with items that cover a diverse range of preferences. Such data has proved challenging to collect scalably using conventional methods like crowdsourcing. We address it in the context of item-set recommendation, noting the increasing attention to this task motivated by use cases like music, news and recipe recommendation. We present a new technique, TalkTheWalk, that synthesizes realistic high-quality conversational data by leveraging domain expertise encoded in widely available curated item collections, showing how these can be transformed into corresponding item set curation c
&lt;/p&gt;</description></item></channel></rss>