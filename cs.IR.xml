<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36890;&#36807;&#25552;&#20986;IDGen&#65292;&#23558;&#27599;&#20010;&#25512;&#33616;&#39033;&#30446;&#34920;&#31034;&#20026;&#29420;&#29305;&#12289;&#31616;&#27905;&#12289;&#35821;&#20041;&#20016;&#23500;&#30340;&#25991;&#26412;ID&#65292;&#20174;&#32780;&#20351;&#24471;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#26356;&#22909;&#22320;&#19982;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#23545;&#40784;&#12290;</title><link>https://arxiv.org/abs/2403.19021</link><description>&lt;p&gt;
&#26397;&#21521;LLM-RecSys&#23545;&#40784;&#19982;&#25991;&#26412;ID&#23398;&#20064;&#30340;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Towards LLM-RecSys Alignment with Textual ID Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19021
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;IDGen&#65292;&#23558;&#27599;&#20010;&#25512;&#33616;&#39033;&#30446;&#34920;&#31034;&#20026;&#29420;&#29305;&#12289;&#31616;&#27905;&#12289;&#35821;&#20041;&#20016;&#23500;&#30340;&#25991;&#26412;ID&#65292;&#20174;&#32780;&#20351;&#24471;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#26356;&#22909;&#22320;&#19982;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#29983;&#25104;&#24335;&#25512;&#33616;&#24050;&#32463;&#23558;&#20256;&#32479;&#30340;&#22522;&#20110;&#25490;&#21517;&#30340;&#25512;&#33616;&#26041;&#24335;&#36716;&#21464;&#20026;&#25991;&#26412;&#29983;&#25104;&#33539;&#20363;&#12290;&#28982;&#32780;&#65292;&#19982;&#22266;&#26377;&#25805;&#20316;&#20154;&#31867;&#35789;&#27719;&#30340;&#26631;&#20934;NLP&#20219;&#21153;&#30456;&#21453;&#65292;&#30446;&#21069;&#29983;&#25104;&#24335;&#25512;&#33616;&#39046;&#22495;&#30340;&#30740;&#31350;&#22312;&#22914;&#20309;&#22312;&#25991;&#26412;&#29983;&#25104;&#33539;&#24335;&#20013;&#20197;&#31616;&#27905;&#32780;&#26377;&#24847;&#20041;&#30340;ID&#34920;&#31034;&#26377;&#25928;&#32534;&#30721;&#25512;&#33616;&#39033;&#30446;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#23545;&#40784;LLMs&#19982;&#25512;&#33616;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;IDGen&#65292;&#20351;&#29992;&#20154;&#31867;&#35821;&#35328;&#26631;&#35760;&#23558;&#27599;&#20010;&#39033;&#30446;&#34920;&#31034;&#20026;&#29420;&#29305;&#12289;&#31616;&#27905;&#12289;&#35821;&#20041;&#20016;&#23500;&#12289;&#19982;&#24179;&#21488;&#26080;&#20851;&#30340;&#25991;&#26412;ID&#12290;&#36825;&#36890;&#36807;&#22312;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#26049;&#35757;&#32451;&#25991;&#26412;ID&#29983;&#25104;&#22120;&#26469;&#23454;&#29616;&#65292;&#20351;&#20010;&#24615;&#21270;&#25512;&#33616;&#33021;&#22815;&#26080;&#32541;&#38598;&#25104;&#21040;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#20013;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#30001;&#20110;&#29992;&#25143;&#21382;&#21490;&#35760;&#24405;&#20197;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#24182;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#35299;&#32806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20986;&#20102;&#28508;&#22312;&#30340;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19021v1 Announce Type: cross  Abstract: Generative recommendation based on Large Language Models (LLMs) have transformed the traditional ranking-based recommendation style into a text-to-text generation paradigm. However, in contrast to standard NLP tasks that inherently operate on human vocabulary, current research in generative recommendations struggles to effectively encode recommendation items within the text-to-text framework using concise yet meaningful ID representations. To better align LLMs with recommendation needs, we propose IDGen, representing each item as a unique, concise, semantically rich, platform-agnostic textual ID using human language tokens. This is achieved by training a textual ID generator alongside the LLM-based recommender, enabling seamless integration of personalized recommendations into natural language generation. Notably, as user history is expressed in natural language and decoupled from the original dataset, our approach suggests the potenti
&lt;/p&gt;</description></item><item><title>&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#36890;&#36807;&#38598;&#25104;&#21644;&#23398;&#20064;&#22810;&#20010;&#39046;&#22495;&#30340;&#20132;&#20114;&#20449;&#24687;&#65292;&#23558;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#20174;&#24179;&#38754;&#36716;&#21521;&#31435;&#20307;&#12290;&#25991;&#31456;&#23545;CDSR&#38382;&#39064;&#36827;&#34892;&#20102;&#23450;&#20041;&#21644;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#20174;&#23439;&#35266;&#21644;&#24494;&#35266;&#20004;&#20010;&#35270;&#35282;&#30340;&#31995;&#32479;&#27010;&#36848;&#12290;&#23545;&#20110;&#19981;&#21516;&#39046;&#22495;&#38388;&#30340;&#27169;&#22411;&#65292;&#24635;&#32467;&#20102;&#22810;&#23618;&#34701;&#21512;&#32467;&#26500;&#21644;&#34701;&#21512;&#26725;&#26753;&#12290;&#23545;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#35752;&#35770;&#20102;&#22522;&#30784;&#25216;&#26415;&#21644;&#36741;&#21161;&#23398;&#20064;&#25216;&#26415;&#12290;&#23637;&#31034;&#20102;&#20844;&#24320;&#25968;&#25454;&#38598;&#21644;&#23454;&#39564;&#32467;&#26524;&#65292;&#24182;&#32473;&#20986;&#20102;&#26410;&#26469;&#21457;&#23637;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2401.04971</link><description>&lt;p&gt;
&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Cross-Domain Sequential Recommendation. (arXiv:2401.04971v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04971
&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#36890;&#36807;&#38598;&#25104;&#21644;&#23398;&#20064;&#22810;&#20010;&#39046;&#22495;&#30340;&#20132;&#20114;&#20449;&#24687;&#65292;&#23558;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#20174;&#24179;&#38754;&#36716;&#21521;&#31435;&#20307;&#12290;&#25991;&#31456;&#23545;CDSR&#38382;&#39064;&#36827;&#34892;&#20102;&#23450;&#20041;&#21644;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#20174;&#23439;&#35266;&#21644;&#24494;&#35266;&#20004;&#20010;&#35270;&#35282;&#30340;&#31995;&#32479;&#27010;&#36848;&#12290;&#23545;&#20110;&#19981;&#21516;&#39046;&#22495;&#38388;&#30340;&#27169;&#22411;&#65292;&#24635;&#32467;&#20102;&#22810;&#23618;&#34701;&#21512;&#32467;&#26500;&#21644;&#34701;&#21512;&#26725;&#26753;&#12290;&#23545;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#35752;&#35770;&#20102;&#22522;&#30784;&#25216;&#26415;&#21644;&#36741;&#21161;&#23398;&#20064;&#25216;&#26415;&#12290;&#23637;&#31034;&#20102;&#20844;&#24320;&#25968;&#25454;&#38598;&#21644;&#23454;&#39564;&#32467;&#26524;&#65292;&#24182;&#32473;&#20986;&#20102;&#26410;&#26469;&#21457;&#23637;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#65288;CDSR&#65289;&#36890;&#36807;&#22312;&#19981;&#21516;&#31890;&#24230;&#65288;&#20174;&#24207;&#21015;&#38388;&#21040;&#24207;&#21015;&#20869;&#65292;&#20174;&#21333;&#39046;&#22495;&#21040;&#36328;&#39046;&#22495;&#65289;&#19978;&#38598;&#25104;&#21644;&#23398;&#20064;&#26469;&#33258;&#22810;&#20010;&#39046;&#22495;&#30340;&#20132;&#20114;&#20449;&#24687;&#65292;&#23558;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#20174;&#24179;&#38754;&#36716;&#21521;&#20102;&#31435;&#20307;&#12290;&#26412;&#32508;&#36848;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#22235;&#32500;&#24352;&#37327;&#23450;&#20041;&#20102;CDSR&#38382;&#39064;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#22312;&#22810;&#32500;&#24230;&#38477;&#32500;&#19979;&#30340;&#22810;&#31867;&#22411;&#36755;&#20837;&#34920;&#31034;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20174;&#25972;&#20307;&#21644;&#32454;&#33410;&#20004;&#20010;&#35270;&#35282;&#25552;&#20379;&#20102;&#31995;&#32479;&#30340;&#27010;&#36848;&#12290;&#20174;&#25972;&#20307;&#35270;&#35282;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#21508;&#20010;&#27169;&#22411;&#22312;&#19981;&#21516;&#39046;&#22495;&#38388;&#30340;&#22810;&#23618;&#34701;&#21512;&#32467;&#26500;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#34701;&#21512;&#26725;&#26753;&#12290;&#20174;&#32454;&#33410;&#35270;&#35282;&#65292;&#25105;&#20204;&#30528;&#37325;&#35752;&#35770;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#22522;&#30784;&#25216;&#26415;&#65292;&#24182;&#35299;&#37322;&#20102;&#36741;&#21161;&#23398;&#20064;&#25216;&#26415;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#29992;&#30340;&#20844;&#24320;&#25968;&#25454;&#38598;&#21644;&#20195;&#34920;&#24615;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#26410;&#26469;&#21457;&#23637;&#30340;&#19968;&#20123;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-domain sequential recommendation (CDSR) shifts the modeling of user preferences from flat to stereoscopic by integrating and learning interaction information from multiple domains at different granularities (ranging from inter-sequence to intra-sequence and from single-domain to cross-domain).In this survey, we initially define the CDSR problem using a four-dimensional tensor and then analyze its multi-type input representations under multidirectional dimensionality reductions. Following that, we provide a systematic overview from both macro and micro views. From a macro view, we abstract the multi-level fusion structures of various models across domains and discuss their bridges for fusion. From a micro view, focusing on the existing models, we specifically discuss the basic technologies and then explain the auxiliary learning technologies. Finally, we exhibit the available public datasets and the representative experimental results as well as provide some insights into future d
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#20174;&#30495;&#23454;&#29992;&#25143;&#37027;&#37324;&#33719;&#21462;&#39640;&#36136;&#37327;&#30340;&#31532;&#19968;&#26041;&#25968;&#25454;&#26469;&#20934;&#30830;&#39044;&#27979;&#25628;&#32034;&#32773;&#30340;&#20559;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.10621</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#25628;&#32034;&#32773;&#30340;&#20559;&#22909;
&lt;/p&gt;
&lt;p&gt;
Large language models can accurately predict searcher preferences. (arXiv:2309.10621v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10621
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#20174;&#30495;&#23454;&#29992;&#25143;&#37027;&#37324;&#33719;&#21462;&#39640;&#36136;&#37327;&#30340;&#31532;&#19968;&#26041;&#25968;&#25454;&#26469;&#20934;&#30830;&#39044;&#27979;&#25628;&#32034;&#32773;&#30340;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#24615;&#26631;&#31614;&#26159;&#35780;&#20272;&#21644;&#20248;&#21270;&#25628;&#32034;&#31995;&#32479;&#30340;&#20851;&#38190;&#12290;&#33719;&#21462;&#22823;&#37327;&#30456;&#20851;&#24615;&#26631;&#31614;&#36890;&#24120;&#38656;&#35201;&#31532;&#19977;&#26041;&#26631;&#27880;&#20154;&#21592;&#65292;&#20294;&#23384;&#22312;&#20302;&#36136;&#37327;&#25968;&#25454;&#30340;&#39118;&#38505;&#12290;&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25913;&#36827;&#26631;&#31614;&#36136;&#37327;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#30495;&#23454;&#29992;&#25143;&#37027;&#37324;&#33719;&#24471;&#20180;&#32454;&#21453;&#39304;&#26469;&#33719;&#21462;&#39640;&#36136;&#37327;&#30340;&#31532;&#19968;&#26041;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems. The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels. Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs. To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring. This paper introduces an alternate approach for improving label quality. It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that 
&lt;/p&gt;</description></item></channel></rss>