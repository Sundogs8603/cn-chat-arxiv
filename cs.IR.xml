<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.05817</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22914;&#20309;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#21463;&#30410;&#65306;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Can Recommender Systems Benefit from Large Language Models: A Survey. (arXiv:2306.05817v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#20174;&#20004;&#20010;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21305;&#37197;&#20114;&#32852;&#32593;&#24212;&#29992;&#31243;&#24207;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20986;&#20102;&#24778;&#20154;&#30340;&#26032;&#20852;&#33021;&#21147;&#65288;&#20363;&#22914;&#25351;&#20196;&#36319;&#36394;&#12289;&#25512;&#29702;&#65289;&#65292;&#20174;&#32780;&#20026;&#23558;LLM&#35843;&#25972;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#20197;&#25552;&#39640;&#24615;&#33021;&#21644;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#30340;&#30740;&#31350;&#26041;&#21521;&#24102;&#26469;&#20102;&#24076;&#26395;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#24212;&#29992;&#23548;&#21521;&#30340;&#35282;&#24230;&#23545;&#27492;&#30740;&#31350;&#26041;&#21521;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#20004;&#20010;&#27491;&#20132;&#30340;&#35282;&#24230;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#22914;&#20309;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#35843;&#25972;LLM&#21644;&#35843;&#25972;LLM&#26102;&#22312;&#21738;&#37324;&#35843;&#25972;&#12290;&#23545;&#20110;&#8220;&#22312;&#21738;&#37324;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;LLM&#22312;&#25512;&#33616;&#27969;&#31243;&#30340;&#19981;&#21516;&#38454;&#27573;&#20013;&#21487;&#33021;&#21457;&#25381;&#30340;&#20316;&#29992;&#65292;&#21363;&#29305;&#24449;&#24037;&#31243;&#12289;&#29305;&#24449;&#32534;&#30721;&#22120;&#12289;&#35780;&#20998;/&#25490;&#21517;&#20989;&#25968;&#21644;&#27969;&#31243;&#25511;&#21046;&#22120;&#12290;&#23545;&#20110;&#8220;&#22914;&#20309;&#8221;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#31574;&#30053;&#65292;&#20174;&#32780;&#24471;&#20986;&#20004;&#20010;&#32454;&#31890;&#24230;&#30340;&#20998;&#31867;&#26631;&#20934;&#65292;&#21363;&#26159;&#21542;&#35843;&#25972;LLM&#21644;&#26159;&#21542;&#23558;LLM&#20316;&#20026;&#29420;&#31435;&#27169;&#22411;&#25110;&#28151;&#21512;&#27169;&#22411;&#32452;&#20214;&#20351;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#23558;LLM&#35843;&#25972;&#21040;RS&#20013;&#30340;&#19968;&#20123;&#25361;&#25112;&#21644;&#28508;&#22312;&#26041;&#21521;&#65292;&#21253;&#25324;&#19982;&#29616;&#26377;&#31995;&#32479;&#30340;&#38598;&#25104;&#12289;&#29992;&#25143;&#21453;&#39304;&#12289;&#35780;&#20272;&#24230;&#37327;&#21644;&#30693;&#35782;&#33976;&#39311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) play important roles to match users' information needs for Internet applications. In natural language processing (NLP) domains, large language model (LLM) has shown astonishing emergent abilities (e.g., instruction following, reasoning), thus giving rise to the promising research direction of adapting LLM to RS for performance enhancements and user experience improvements. In this paper, we conduct a comprehensive survey on this research direction from an application-oriented view. We first summarize existing research works from two orthogonal perspectives: where and how to adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, and pipeline controller. For the "HOW" question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLMs or not, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#37319;&#29992;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#20132;&#20114;&#24335;&#35299;&#37322;&#27169;&#22411;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20026;&#29992;&#25143;&#25552;&#20379;&#19981;&#21516;&#32454;&#33410;&#32423;&#21035;&#30340;&#35299;&#37322;&#65292;&#36171;&#20104;&#29992;&#25143;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.05809</link><description>&lt;p&gt;
&#22312;&#21487;&#35299;&#37322;&#30340;&#31185;&#23398;&#25991;&#29486;&#25512;&#33616;&#31995;&#32479;&#20013;&#37319;&#29992;&#19981;&#21516;&#32454;&#33410;&#32423;&#21035;&#30340;&#20132;&#20114;&#24335;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Interactive Explanation with Varying Level of Details in an Explainable Scientific Literature Recommender System. (arXiv:2306.05809v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#37319;&#29992;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#20132;&#20114;&#24335;&#35299;&#37322;&#27169;&#22411;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20026;&#29992;&#25143;&#25552;&#20379;&#19981;&#21516;&#32454;&#33410;&#32423;&#21035;&#30340;&#35299;&#37322;&#65292;&#36171;&#20104;&#29992;&#25143;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#37319;&#29992;&#19968;&#31181;&#8220;&#19968;&#20992;&#20999;&#8221;&#30340;&#26041;&#27861;&#65292;&#21521;&#27599;&#20010;&#29992;&#25143;&#25552;&#20379;&#30456;&#21516;&#31243;&#24230;&#30340;&#35299;&#37322;&#65292;&#32780;&#19981;&#32771;&#34385;&#20182;&#20204;&#30340;&#20010;&#20307;&#38656;&#27714;&#21644;&#30446;&#26631;&#12290;&#27492;&#22806;&#65292;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#35299;&#37322;&#22823;&#22810;&#20197;&#38745;&#24577;&#21644;&#38750;&#20132;&#20114;&#26041;&#24335;&#21576;&#29616;&#12290;&#20026;&#22635;&#34917;&#36825;&#20123;&#30740;&#31350;&#31354;&#30333;&#65292;&#26412;&#25991;&#26088;&#22312;&#37319;&#29992;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#20132;&#20114;&#24335;&#35299;&#37322;&#27169;&#22411;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#19981;&#21516;&#32454;&#33410;&#32423;&#21035;&#30340;&#35299;&#37322;&#65292;&#24182;&#36171;&#20104;&#29992;&#25143;&#22522;&#20110;&#20854;&#38656;&#27714;&#21644;&#20559;&#22909;&#36827;&#34892;&#20132;&#20114;&#12289;&#25511;&#21046;&#21644;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#37319;&#29992;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#26041;&#27861;&#65292;&#35774;&#35745;&#20102;&#19977;&#20010;&#32454;&#33410;&#32423;&#21035;&#30340;&#20132;&#20114;&#24335;&#35299;&#37322;&#65288;&#22522;&#26412;&#12289;&#20013;&#32423;&#21644;&#39640;&#32423;&#65289;&#65292;&#24182;&#22312;&#36879;&#26126;&#30340;&#25512;&#33616;&#21644;&#20852;&#36259;&#24314;&#27169;&#24212;&#29992;&#65288;RIMA&#65289;&#20013;&#23454;&#29616;&#20102;&#23427;&#20204;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#20010;&#23450;&#24615;&#29992;&#25143;&#30740;&#31350;&#65288;N=14&#65289;&#65292;&#20197;&#35843;&#26597;&#25552;&#20379;&#19981;&#21516;&#32454;&#33410;&#32423;&#21035;&#30340;&#20132;&#20114;&#24335;&#35299;&#37322;&#23545;&#29992;&#25143;&#23545;&#31995;&#32479;&#21487;&#35299;&#37322;&#24615;&#30340;&#24863;&#30693;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable recommender systems (RS) have traditionally followed a one-size-fits-all approach, delivering the same explanation level of detail to each user, without considering their individual needs and goals. Further, explanations in RS have so far been presented mostly in a static and non-interactive manner. To fill these research gaps, we aim in this paper to adopt a user-centered, interactive explanation model that provides explanations with different levels of detail and empowers users to interact with, control, and personalize the explanations based on their needs and preferences. We followed a user-centered approach to design interactive explanations with three levels of detail (basic, intermediate, and advanced) and implemented them in the transparent Recommendation and Interest Modeling Application (RIMA). We conducted a qualitative user study (N=14) to investigate the impact of providing interactive explanations with varying level of details on the users' perception of the e
&lt;/p&gt;</description></item><item><title>RankFormer&#26159;&#19968;&#20010;&#21487;&#20197;&#21033;&#29992;&#21015;&#34920;&#26631;&#31614;&#36827;&#34892;&#21015;&#34920;&#23398;&#20064;&#25490;&#24207;&#30340;&#26550;&#26500;&#65292;&#24182;&#22312;&#22810;&#20010;&#26368;&#20808;&#36827;&#30340;LTR&#26041;&#27861;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.05808</link><description>&lt;p&gt;
RankFormer&#65306;&#20351;&#29992;&#21015;&#34920;&#26631;&#31614;&#30340;&#21015;&#34920;&#23398;&#20064;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
RankFormer: Listwise Learning-to-Rank Using Listwide Labels. (arXiv:2306.05808v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05808
&lt;/p&gt;
&lt;p&gt;
RankFormer&#26159;&#19968;&#20010;&#21487;&#20197;&#21033;&#29992;&#21015;&#34920;&#26631;&#31614;&#36827;&#34892;&#21015;&#34920;&#23398;&#20064;&#25490;&#24207;&#30340;&#26550;&#26500;&#65292;&#24182;&#22312;&#22810;&#20010;&#26368;&#20808;&#36827;&#30340;LTR&#26041;&#27861;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#24212;&#29992;&#31243;&#24207;&#24120;&#24120;&#20351;&#29992;&#25490;&#24207;&#27169;&#22411;&#23558;&#26368;&#30456;&#20851;&#30340;&#32467;&#26524;&#25490;&#22312;&#21069;&#38754;&#65292;&#20197;&#21576;&#29616;&#32473;&#29992;&#25143;&#26377;&#38480;&#30340;&#36873;&#25321;&#12290;&#36890;&#24120;&#20551;&#23450;&#20174;&#29992;&#25143;&#33719;&#24471;&#30340;&#21453;&#39304;&#21482;&#21453;&#26144;&#20102;&#39033;&#30446;&#25928;&#29992;&#30340;&#30456;&#23545;&#35780;&#20215;&#65292;&#20363;&#22914;&#29992;&#25143;&#21333;&#20987;&#39033;&#30446;&#21482;&#26263;&#31034;&#23427;&#27604;&#22312;&#21516;&#19968;&#25490;&#24207;&#21015;&#34920;&#20013;&#26410;&#21333;&#20987;&#30340;&#39033;&#30446;&#26356;&#22909;&#12290;&#22240;&#27492;&#65292;&#23398;&#20064;&#25490;&#24207;&#65288;LTR&#65289;&#20013;&#20248;&#21270;&#30340;&#30446;&#26631;&#24448;&#24448;&#26159;&#25104;&#23545;&#25110;&#25353;&#21015;&#34920;&#25490;&#24207;&#12290;&#28982;&#32780;&#65292;&#21482;&#30475;&#21040;&#30456;&#23545;&#21453;&#39304;&#65292;&#25105;&#20204;&#24573;&#35270;&#20102;&#29992;&#25143;&#23545;&#21015;&#34920;&#25972;&#20307;&#36136;&#37327;&#30340;&#32477;&#23545;&#21453;&#39304;&#65292;&#20363;&#22914;&#24403;&#36873;&#25321;&#20013;&#27809;&#26377;&#39033;&#30446;&#34987;&#21333;&#20987;&#26102;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#37325;&#26032;&#32771;&#34385;&#20102;&#26631;&#20934;&#30340;LTR&#33539;&#24335;&#65292;&#24182;&#35770;&#36848;&#20102;&#20174;&#36825;&#31181;&#21015;&#34920;&#32423;&#20449;&#21495;&#20013;&#23398;&#20064;&#30340;&#22909;&#22788;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RankFormer&#20316;&#20026;&#19968;&#20010;&#24102;&#26377;Transformer&#26680;&#24515;&#30340;&#26550;&#26500;&#65292;&#21487;&#20197;&#20849;&#21516;&#20248;&#21270;&#26032;&#30340;&#21015;&#34920;&#35780;&#20272;&#30446;&#26631;&#21644;&#20256;&#32479;&#30340;&#25353;&#21015;&#34920;LTR&#30446;&#26631;&#12290;&#25105;&#20204;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#27169;&#25311;&#38544;&#24335;&#21453;&#39304;&#65292;&#24182;&#35266;&#23519;&#21040;RankFormer&#27604;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;LTR&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;&#21033;&#29992;&#21015;&#34920;&#26631;&#31614;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Web applications where users are presented with a limited selection of items have long employed ranking models to put the most relevant results first. Any feedback received from users is typically assumed to reflect a relative judgement on the utility of items, e.g. a user clicking on an item only implies it is better than items not clicked in the same ranked list. Hence, the objectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.  Yet, by only viewing feedback as relative, we neglect the user's absolute feedback on the list's overall quality, e.g. when no items in the selection are clicked. We thus reconsider the standard LTR paradigm and argue the benefits of learning from this listwide signal. To this end, we propose the RankFormer as an architecture that, with a Transformer at its core, can jointly optimize a novel listwide assessment objective and a traditional listwise LTR objective.  We simulate implicit feedback on public datasets and observe that the Ra
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23450;&#20041;&#36890;&#29992;&#22522;&#30784;&#27169;&#22411;&#20197;&#29992;&#20110;&#21307;&#30103;&#25253;&#21578;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#20854;&#21033;&#29992;&#36731;&#37327;&#32423;&#26597;&#35810;Transformer&#36830;&#25509;&#20004;&#20010;FMs&#65292;&#24182;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.05642</link><description>&lt;p&gt;
&#38754;&#21521;&#21307;&#30103;&#25253;&#21578;&#29983;&#25104;&#30340;&#36890;&#29992;&#22522;&#30784;&#27169;&#22411;&#33258;&#23450;&#20041;
&lt;/p&gt;
&lt;p&gt;
Customizing General-Purpose Foundation Models for Medical Report Generation. (arXiv:2306.05642v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05642
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23450;&#20041;&#36890;&#29992;&#22522;&#30784;&#27169;&#22411;&#20197;&#29992;&#20110;&#21307;&#30103;&#25253;&#21578;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#20854;&#21033;&#29992;&#36731;&#37327;&#32423;&#26597;&#35810;Transformer&#36830;&#25509;&#20004;&#20010;FMs&#65292;&#24182;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#30103;&#23383;&#24149;&#39044;&#27979;&#65292;&#20063;&#34987;&#35270;&#20026;&#21307;&#30103;&#25253;&#21578;&#29983;&#25104;&#65288;MRG&#65289;&#30340;&#20219;&#21153;&#65292;&#38656;&#35201;&#20026;&#32473;&#23450;&#30340;&#21307;&#30103;&#22270;&#20687;&#33258;&#21160;&#29983;&#25104;&#36830;&#36143;&#20934;&#30830;&#30340;&#23383;&#24149;&#12290;&#28982;&#32780;&#65292;&#26631;&#35760;&#30340;&#21307;&#30103;&#22270;&#20687;-&#25253;&#21578;&#23545;&#30340;&#31232;&#32570;&#24615;&#22312;&#28145;&#24230;&#21644;&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#30340;&#24320;&#21457;&#20013;&#25552;&#20986;&#20102;&#24040;&#22823;&#25361;&#25112;&#65292;&#36825;&#20123;&#32593;&#32476;&#21487;&#20197;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36825;&#26679;&#30340;&#20154;&#24037;&#26234;&#33021;&#28508;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#36890;&#29992;&#30340;&#38754;&#21521;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#23450;&#21046;&#65292;&#29305;&#21035;&#20851;&#27880;&#21307;&#30103;&#25253;&#21578;&#29983;&#25104;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#26681;&#25454;BLIP-2&#25552;&#20986;&#20102;&#22522;&#20110;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#30340;MRG&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#36731;&#37327;&#32423;&#26597;&#35810;Transformer&#36830;&#25509;&#20004;&#20010;FMs&#65306;&#24040;&#22411;&#35270;&#35273;Transformer EVA-ViT-g&#21644;&#21452;&#35821;LLM&#65292;&#35813;LLM&#34987;&#35757;&#32451;&#29992;&#20110;&#19982;&#20154;&#31867;&#24847;&#22270;&#23545;&#40784;&#65288;&#31216;&#20026;T5-base-CN&#65289;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#19977;&#20010;&#21307;&#30103;&#25253;&#21578;&#29983;&#25104;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#36825;&#34920;&#26126;&#20102;&#23558;&#22522;&#30784;&#27169;&#22411;&#36866;&#24212;&#20110;&#27492;&#20219;&#21153;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Medical caption prediction which can be regarded as a task of medical report generation (MRG), requires the automatic generation of coherent and accurate captions for the given medical images. However, the scarcity of labelled medical image-report pairs presents great challenges in the development of deep and large-scale neural networks capable of harnessing the potential artificial general intelligence power like large language models (LLMs). In this work, we propose customizing off-the-shelf general-purpose large-scale pre-trained models, i.e., foundation models (FMs), in computer vision and natural language processing with a specific focus on medical report generation. Specifically, following BLIP-2, a state-of-the-art vision-language pre-training approach, we introduce our encoder-decoder-based MRG model. This model utilizes a lightweight query Transformer to connect two FMs: the giant vision Transformer EVA-ViT-g and a bilingual LLM trained to align with human intentions (referred
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#36125;&#21494;&#26031;&#25209;&#21028;&#24335;&#25512;&#33616;&#31995;&#32479;&#65292;&#23558;&#30452;&#25509;&#21644;&#38388;&#25509;&#30340;&#29289;&#21697;&#23646;&#24615;&#32467;&#21512;&#65292;&#20801;&#35768;&#29992;&#25143;&#25552;&#20379;&#26356;&#21152;&#22797;&#26434;&#30340;&#12289;&#22522;&#20110;&#30693;&#35782;&#30340;&#21453;&#39304;&#12290;</title><link>http://arxiv.org/abs/2306.05636</link><description>&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#36125;&#21494;&#26031;&#25209;&#21028;&#24335;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Bayesian Knowledge-driven Critiquing with Indirect Evidence. (arXiv:2306.05636v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05636
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#36125;&#21494;&#26031;&#25209;&#21028;&#24335;&#25512;&#33616;&#31995;&#32479;&#65292;&#23558;&#30452;&#25509;&#21644;&#38388;&#25509;&#30340;&#29289;&#21697;&#23646;&#24615;&#32467;&#21512;&#65292;&#20801;&#35768;&#29992;&#25143;&#25552;&#20379;&#26356;&#21152;&#22797;&#26434;&#30340;&#12289;&#22522;&#20110;&#30693;&#35782;&#30340;&#21453;&#39304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#22686;&#24378;&#20102;&#25512;&#33616;&#30340;&#34920;&#29616;&#21147;&#21644;&#20010;&#24615;&#21270;&#31243;&#24230;&#65292;&#36890;&#36807;&#22810;&#36718;&#29992;&#25143;-&#31995;&#32479;&#20132;&#20114;&#36827;&#34892;&#12290;&#25209;&#21028;&#26159;CRS&#20013;&#24191;&#20026;&#20154;&#30693;&#30340;&#19968;&#20010;&#33539;&#20363;&#65292;&#20801;&#35768;&#29992;&#25143;&#36890;&#36807;&#25552;&#20379;&#26377;&#20851;&#25512;&#33616;&#29289;&#21697;&#30340;&#23646;&#24615;&#30340;&#21453;&#39304;&#26469;&#36880;&#27493;&#23436;&#21892;&#25512;&#33616;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#20013;&#26377;&#20851;&#29289;&#21697;&#30340;&#26356;&#20016;&#23500;&#30340;&#32972;&#26223;&#20449;&#24687;&#65292;&#19981;&#20165;&#38480;&#20110;&#21033;&#29992;&#29289;&#21697;&#30340;&#30452;&#25509;&#23646;&#24615;&#35299;&#20915;&#29992;&#25143;&#35831;&#27714;&#65292;&#32780;&#26159;&#36890;&#36807;&#37319;&#29992;&#32463;&#20856;&#30340;&#25512;&#29702;&#26041;&#27861;&#23558;&#36825;&#20123;&#20449;&#24687;&#19982;&#30452;&#25509;&#23646;&#24615;&#32467;&#21512;&#36215;&#26469;&#12290;&#22240;&#27492;&#25209;&#21028;&#24335;&#25512;&#33616;&#31995;&#32479;&#21487;&#20197;&#23454;&#29616;&#26356;&#21152;&#22797;&#26434;&#30340;&#22522;&#20110;&#30693;&#35782;&#30340;&#21453;&#39304;&#65292;&#20363;&#22914;&#8220;&#25105;&#21916;&#27426;&#25551;&#36848;&#36864;&#20237;&#20891;&#20154;&#25112;&#20105;&#21518;&#26524;&#30340;&#30005;&#24433;&#8221;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#30693;&#35782;&#30340;&#25209;&#21028;&#24335;&#25512;&#33616;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20801;&#35768;&#29992;&#25143;&#25552;&#20379;&#24102;&#26377;&#38388;&#25509;&#20449;&#24687;&#30340;&#21453;&#39304;&#65292;&#21516;&#26102;&#20173;&#20855;&#26377;&#24456;&#39640;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#32435;&#20837;&#38388;&#25509;&#20449;&#24687;&#26174;&#30528;&#25552;&#39640;&#20102;&#25512;&#33616;&#30340;&#36136;&#37327;&#21644;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational recommender systems (CRS) enhance the expressivity and personalization of recommendations through multiple turns of user-system interaction. Critiquing is a well-known paradigm for CRS that allows users to iteratively refine recommendations by providing feedback about attributes of recommended items. While existing critiquing methodologies utilize direct attributes of items to address user requests such as 'I prefer Western movies', the opportunity of incorporating richer contextual and side information about items stored in Knowledge Graphs (KG) into the critiquing paradigm has been overlooked. Employing this substantial knowledge together with a well-established reasoning methodology paves the way for critique-based recommenders to allow for complex knowledge-based feedback (e.g., 'I like movies featuring war side effects on veterans') which may arise in natural user-system conversations. In this work, we aim to increase the flexibility of critique-based recommendation
&lt;/p&gt;</description></item><item><title>&#25919;&#27835;&#36777;&#35770;&#12289;&#28436;&#35762;&#21644;&#35775;&#35848;&#20013;&#30340;&#20540;&#24471;&#26680;&#23454;&#30340;&#35770;&#26029;&#21487;&#20197;&#20351;&#29992;&#38899;&#39057;&#25968;&#25454;&#36827;&#34892;&#26816;&#27979;&#21644;&#30830;&#35748;&#65292;&#36825;&#21487;&#24110;&#21161;&#20027;&#25345;&#20154;&#12289;&#35760;&#32773;&#21644;&#20107;&#23454;&#26680;&#26597;&#32452;&#32455;&#36827;&#34892;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2306.05535</link><description>&lt;p&gt;
&#20351;&#29992;&#38899;&#39057;&#25968;&#25454;&#26816;&#27979;&#25919;&#27835;&#36777;&#35770;&#12289;&#28436;&#35762;&#21644;&#35775;&#35848;&#20013;&#20540;&#24471;&#26680;&#23454;&#30340;&#35770;&#26029;
&lt;/p&gt;
&lt;p&gt;
Detecting Check-Worthy Claims in Political Debates, Speeches, and Interviews Using Audio Data. (arXiv:2306.05535v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05535
&lt;/p&gt;
&lt;p&gt;
&#25919;&#27835;&#36777;&#35770;&#12289;&#28436;&#35762;&#21644;&#35775;&#35848;&#20013;&#30340;&#20540;&#24471;&#26680;&#23454;&#30340;&#35770;&#26029;&#21487;&#20197;&#20351;&#29992;&#38899;&#39057;&#25968;&#25454;&#36827;&#34892;&#26816;&#27979;&#21644;&#30830;&#35748;&#65292;&#36825;&#21487;&#24110;&#21161;&#20027;&#25345;&#20154;&#12289;&#35760;&#32773;&#21644;&#20107;&#23454;&#26680;&#26597;&#32452;&#32455;&#36827;&#34892;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20250;&#30340;&#19968;&#22823;&#37096;&#20998;&#22242;&#32467;&#22312;&#30456;&#21516;&#30340;&#24895;&#26223;&#21644;&#24605;&#24819;&#21608;&#22260;&#65292;&#20855;&#26377;&#24040;&#22823;&#30340;&#33021;&#37327;&#12290;&#36825;&#27491;&#26159;&#25919;&#27835;&#20154;&#29289;&#24076;&#26395;&#20026;&#20182;&#20204;&#30340;&#20107;&#19994;&#25152;&#32047;&#31215;&#30340;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#65292;&#20182;&#20204;&#26377;&#26102;&#20250;&#20351;&#29992;&#25197;&#26354;&#25110;&#38544;&#34255;&#30495;&#30456;&#30340;&#25163;&#27573;&#65292;&#26080;&#35770;&#26159;&#26080;&#24847;&#30340;&#36824;&#26159;&#26377;&#24847;&#30340;&#65292;&#36825;&#20026;&#38169;&#35823;&#20449;&#24687;&#21644;&#35823;&#23548;&#24320;&#20102;&#22823;&#38376;&#12290;&#33258;&#21160;&#26816;&#27979;&#20540;&#24471;&#26680;&#23454;&#30340;&#35770;&#26029;&#30340;&#24037;&#20855;&#23558;&#23545;&#36777;&#35770;&#20027;&#25345;&#20154;&#12289;&#35760;&#32773;&#21644;&#20107;&#23454;&#26680;&#26597;&#32452;&#32455;&#26377;&#24456;&#22823;&#24110;&#21161;&#12290;&#34429;&#28982;&#20197;&#21069;&#20851;&#20110;&#26816;&#27979;&#20540;&#24471;&#26680;&#23454;&#30340;&#35770;&#26029;&#30340;&#24037;&#20316;&#37325;&#28857;&#26159;&#25991;&#26412;&#65292;&#20294;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#38899;&#39057;&#20449;&#21495;&#20316;&#20026;&#39069;&#22806;&#20449;&#24687;&#28304;&#30340;&#23454;&#29992;&#24615;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65288;&#33521;&#35821;&#25991;&#26412;&#21644;&#38899;&#39057;&#65289;&#65292;&#21253;&#21547;48&#23567;&#26102;&#30340;&#28436;&#35762;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22810;&#20010;&#28436;&#35762;&#32773;&#30340;&#24773;&#20917;&#19979;&#65292;&#38899;&#39057;&#27169;&#24577;&#19982;&#25991;&#26412;&#32467;&#21512;&#20351;&#29992;&#27604;&#20165;&#20351;&#29992;&#25991;&#26412;&#20855;&#26377;&#25913;&#36827;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#21333;&#22768;&#36947;&#38899;&#39057;&#27169;&#22411;&#21487;&#20197;&#32988;&#36807;&#21333;&#22768;&#36947;&#25991;&#26412;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
A large portion of society united around the same vision and ideas carries enormous energy. That is precisely what political figures would like to accumulate for their cause. With this goal in mind, they can sometimes resort to distorting or hiding the truth, unintentionally or on purpose, which opens the door for misinformation and disinformation. Tools for automatic detection of check-worthy claims would be of great help to moderators of debates, journalists, and fact-checking organizations. While previous work on detecting check-worthy claims has focused on text, here we explore the utility of the audio signal as an additional information source. We create a new multimodal dataset (text and audio in English) containing 48 hours of speech. Our evaluation results show that the audio modality together with text yields improvements over text alone in the case of multiple speakers. Moreover, an audio-only model could outperform a text-only one for a single speaker.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#32858;&#31867;&#26041;&#27861;&#65288;CLC&#65289;&#65292;&#23427;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#30452;&#25509;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.05439</link><description>&lt;p&gt;
CLC: &#22522;&#20110;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#30340;&#32858;&#31867;&#20998;&#37197;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
CLC: Cluster Assignment via Contrastive Representation Learning. (arXiv:2306.05439v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05439
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#32858;&#31867;&#26041;&#27861;&#65288;CLC&#65289;&#65292;&#23427;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#30452;&#25509;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#19968;&#39033;&#37325;&#35201;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#26088;&#22312;&#23558;&#26679;&#26412;&#20998;&#32452;&#65292;&#32780;&#19981;&#38656;&#35201;&#25163;&#21160;&#27880;&#37322;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#36890;&#36807;&#23545;&#33258;&#30417;&#30563;&#23398;&#20064;&#24471;&#21040;&#30340;&#29305;&#24449;&#34920;&#31034;&#36827;&#34892;&#32858;&#31867;&#65292;&#22312;&#23567;&#22411;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#21253;&#21547;&#22823;&#37327;&#32858;&#31867;&#30340;&#25968;&#25454;&#38598;&#65292;&#22914;ImageNet&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#20173;&#28982;&#26080;&#27861;&#23454;&#29616;&#39640;&#32858;&#31867;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#32858;&#31867;&#26041;&#27861;&#65288;CLC&#65289;&#65292;&#23427;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#30452;&#25509;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#12290;&#25105;&#20204;&#23558;&#34920;&#31034;&#20998;&#35299;&#20026;&#20004;&#37096;&#20998;&#65306;&#19968;&#37096;&#20998;&#23545;&#31867;&#21035;&#20449;&#24687;&#36827;&#34892;&#32534;&#30721;&#65292;&#24182;&#37319;&#29992;&#31561;&#20998;&#32422;&#26463;&#65292;&#21478;&#19968;&#37096;&#20998;&#25429;&#25417;&#23454;&#20363;&#22240;&#32032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#27604;&#25439;&#22833;&#65292;&#20351;&#29992;&#34920;&#31034;&#30340;&#20004;&#20010;&#37096;&#20998;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#25152;&#25552;&#20986;&#30340;&#23545;&#27604;&#25439;&#22833;&#65292;&#24182;&#25581;&#31034;&#20102;CLC&#22312;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#26102;&#20026;&#36127;&#26679;&#26412;&#35774;&#32622;&#19981;&#21516;&#30340;&#26435;&#37325;&#12290;&#36827;&#19968;&#27493;&#30340;&#26799;&#24230;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;CLC&#26102;&#65292;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering remains an important and challenging task of grouping samples into clusters without manual annotations. Recent works have achieved excellent results on small datasets by performing clustering on feature representations learned from self-supervised learning. However, for datasets with a large number of clusters, such as ImageNet, current methods still can not achieve high clustering performance. In this paper, we propose Contrastive Learning-based Clustering (CLC), which uses contrastive learning to directly learn cluster assignment. We decompose the representation into two parts: one encodes the categorical information under an equipartition constraint, and the other captures the instance-wise factors. We propose a contrastive loss using both parts of the representation. We theoretically analyze the proposed contrastive loss and reveal that CLC sets different weights for the negative samples while learning cluster assignments. Further gradient analysis shows that the larger 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MeCoD&#30340;&#25552;&#31034;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#31034;&#32534;&#30721;&#22120;&#12289;&#23545;&#35937;&#22343;&#34913;&#21644;&#26377;&#20559;&#23545;&#35937;&#38459;&#22622;&#19977;&#20010;&#27169;&#22359;&#65292;&#26377;&#25928;&#20943;&#23569;&#20102;&#23545;&#35937;&#20559;&#24046;&#65292;&#25552;&#39640;&#20102;&#20107;&#23454;&#30693;&#35782;&#30340;&#25552;&#21462;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.03378</link><description>&lt;p&gt;
&#28040;&#38500;&#22522;&#20110;&#25552;&#31034;&#35843;&#25972;&#30340;&#20107;&#23454;&#30693;&#35782;&#25552;&#21462;&#20013;&#30340;&#23545;&#35937;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Towards Alleviating the Object Bias in Prompt Tuning-based Factual Knowledge Extraction. (arXiv:2306.03378v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MeCoD&#30340;&#25552;&#31034;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#31034;&#32534;&#30721;&#22120;&#12289;&#23545;&#35937;&#22343;&#34913;&#21644;&#26377;&#20559;&#23545;&#35937;&#38459;&#22622;&#19977;&#20010;&#27169;&#22359;&#65292;&#26377;&#25928;&#20943;&#23569;&#20102;&#23545;&#35937;&#20559;&#24046;&#65292;&#25552;&#39640;&#20102;&#20107;&#23454;&#30693;&#35782;&#30340;&#25552;&#21462;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24037;&#20316;&#37319;&#29992;&#25552;&#31034;&#35843;&#25972;&#26041;&#27861;&#33258;&#21160;&#20248;&#21270;&#25552;&#31034;&#26597;&#35810;&#24182;&#25552;&#21462;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#23384;&#20648;&#30340;&#20107;&#23454;&#30693;&#35782;&#12290;&#26412;&#25991;&#35266;&#23519;&#21040;&#65292;&#21253;&#25324;&#31163;&#25955;&#25552;&#31034;&#21644;&#36830;&#32493;&#25552;&#31034;&#22312;&#20869;&#30340;&#20248;&#21270;&#25552;&#31034;&#34920;&#29616;&#20986;&#19981;&#33391;&#30340;&#23545;&#35937;&#20559;&#24046;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25552;&#31034;&#35843;&#25972;&#26041;&#27861;MeCoD&#65292;&#30001;&#19977;&#20010;&#27169;&#22359;&#32452;&#25104;&#65306;&#25552;&#31034;&#32534;&#30721;&#22120;&#12289;&#23545;&#35937;&#22343;&#34913;&#21644;&#26377;&#20559;&#23545;&#35937;&#38459;&#22622;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MeCoD&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#23545;&#35937;&#20559;&#24046;&#65292;&#21516;&#26102;&#25552;&#39640;&#20107;&#23454;&#30693;&#35782;&#30340;&#25552;&#21462;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many works employed prompt tuning methods to automatically optimize prompt queries and extract the factual knowledge stored in Pretrained Language Models. In this paper, we observe that the optimized prompts, including discrete prompts and continuous prompts, exhibit undesirable object bias. To handle this problem, we propose a novel prompt tuning method called MeCoD. consisting of three modules: Prompt Encoder, Object Equalization and Biased Object Obstruction. Experimental results show that MeCoD can significantly reduce the object bias and at the same time improve accuracy of factual knowledge extraction.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;&#29992;&#20110;&#21015;&#34920;&#21270;&#25512;&#33616;&#30340;&#35299;&#20915;&#26041;&#26696;GFN4Rec&#65292;&#36890;&#36807;&#29983;&#25104;&#27969;&#32593;&#32476;&#21644;&#21015;&#34920;&#21464;&#25442;&#22120;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#29983;&#25104;&#20855;&#26377;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#30340;&#39033;&#30446;&#21015;&#34920;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#25512;&#33616;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02239</link><description>&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#29992;&#20110;&#21015;&#34920;&#21270;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Network for Listwise Recommendation. (arXiv:2306.02239v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;&#29992;&#20110;&#21015;&#34920;&#21270;&#25512;&#33616;&#30340;&#35299;&#20915;&#26041;&#26696;GFN4Rec&#65292;&#36890;&#36807;&#29983;&#25104;&#27969;&#32593;&#32476;&#21644;&#21015;&#34920;&#21464;&#25442;&#22120;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#29983;&#25104;&#20855;&#26377;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#30340;&#39033;&#30446;&#21015;&#34920;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#25512;&#33616;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#33021;&#22815;&#28385;&#36275;&#29992;&#25143;&#30340;&#26085;&#24120;&#38656;&#27714;&#24182;&#20419;&#36827;&#22312;&#32447;&#19994;&#21153;&#30340;&#21457;&#23637;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#31181;&#31574;&#30053;&#65292;&#33021;&#22815;&#29983;&#25104;&#31526;&#21512;&#29992;&#25143;&#38656;&#27714;&#25110;&#20852;&#36259;&#30340;&#39033;&#30446;&#21015;&#34920;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#23398;&#20064;&#20102;&#19968;&#31181;&#39044;&#27979;&#27599;&#20010;&#21333;&#29420;&#39033;&#30446;&#25490;&#21517;&#24471;&#20998;&#30340;&#28857;&#31215;&#35780;&#20998;&#27169;&#22411;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21015;&#34920;&#24335;&#26041;&#27861;&#36890;&#36807;&#24314;&#27169;&#21516;&#26102;&#23637;&#31034;&#30340;&#39033;&#30446;&#30340;&#20869;&#37096;&#21015;&#34920;&#30456;&#20851;&#24615;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#25512;&#33616;&#36136;&#37327;&#12290;&#36825;&#28608;&#21457;&#20102;&#26368;&#36817;&#30340;&#21015;&#34920;&#37325;&#25490;&#21644;&#29983;&#25104;&#24335;&#25512;&#33616;&#26041;&#27861;&#65292;&#23427;&#20204;&#20248;&#21270;&#25972;&#20010;&#21015;&#34920;&#30340;&#24635;&#20307;&#25928;&#29992;&#12290;&#28982;&#32780;&#65292;&#25506;&#32034;&#21015;&#34920;&#25805;&#20316;&#30340;&#32452;&#21512;&#31354;&#38388;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#29616;&#26377;&#20351;&#29992;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26041;&#27861;&#21487;&#33021;&#20250;&#36973;&#21463;&#20302;&#22810;&#26679;&#24615;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#23398;&#20064;&#19968;&#31181;&#31574;&#30053;&#65292;&#33021;&#22815;&#29983;&#25104;&#29992;&#25143;&#30340;&#36275;&#22815;&#22810;&#26679;&#24615;&#30340;&#39033;&#30446;&#21015;&#34920;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#25512;&#33616;&#36136;&#37327;&#12290;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;GFN4Rec&#26159;&#19968;&#20010;&#29983;&#25104;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#30001;&#29983;&#25104;&#27969;&#32593;&#32476;&#21644;&#21015;&#34920;&#21464;&#25442;&#22120;&#32452;&#25104;&#65292;&#36890;&#36807;&#21033;&#29992;&#29983;&#25104;&#27969;&#32593;&#32476;&#21644;&#22788;&#29702;&#39033;&#30446;&#30340;&#20869;&#37096;&#21015;&#34920;&#30456;&#20114;&#20851;&#32852;&#24615;&#30340;&#21015;&#34920;&#21464;&#25442;&#22120;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#29983;&#25104;&#20855;&#26377;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#30340;&#39033;&#30446;&#21015;&#34920;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#32508;&#21512;&#23454;&#39564;&#35777;&#26126;&#65292;GFN4Rec&#22312;&#25512;&#33616;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized recommender systems fulfill the daily demands of customers and boost online businesses. The goal is to learn a policy that can generate a list of items that matches the user's demand or interest. While most existing methods learn a pointwise scoring model that predicts the ranking score of each individual item, recent research shows that the listwise approach can further improve the recommendation quality by modeling the intra-list correlations of items that are exposed together. This has motivated the recent list reranking and generative recommendation approaches that optimize the overall utility of the entire list. However, it is challenging to explore the combinatorial space of list actions and existing methods that use cross-entropy loss may suffer from low diversity issues. In this work, we aim to learn a policy that can generate sufficiently diverse item lists for users while maintaining high recommendation quality. The proposed solution, GFN4Rec, is a generative met
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;GPT-3.5&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20851;&#31995;&#25277;&#21462;&#20013;&#65292;&#23454;&#29616;&#22312;&#22235;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#26032;&#30340;&#26368;&#20248;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#25351;&#23548;&#35828;&#26126;&#21644;&#32422;&#26463;&#27169;&#24335;&#19979;&#30340;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.01555</link><description>&lt;p&gt;
&#22914;&#20309;&#21457;&#25381;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20851;&#31995;&#25277;&#21462;&#20013;&#30340;&#33021;&#21147;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;GPT-3.5&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20851;&#31995;&#25277;&#21462;&#20013;&#65292;&#23454;&#29616;&#22312;&#22235;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#26032;&#30340;&#26368;&#20248;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#25351;&#23548;&#35828;&#26126;&#21644;&#32422;&#26463;&#27169;&#24335;&#19979;&#30340;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#30340;&#25193;&#23637;&#24050;&#32463;&#24443;&#24213;&#25913;&#21464;&#20102;&#24191;&#27867;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#65292;&#20294;&#26159;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#23569;&#26679;&#26412;&#20851;&#31995;&#25277;&#21462;&#36824;&#27809;&#26377;&#24471;&#21040;&#20840;&#38754;&#25506;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#35814;&#32454;&#23454;&#39564;&#65292;&#30740;&#31350;&#20102;&#20351;&#29992;GPT-3.5&#36827;&#34892;&#23569;&#26679;&#26412;&#20851;&#31995;&#25277;&#21462;&#30340;&#22522;&#26412;&#26041;&#27861;&#8212;&#8212;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#25968;&#25454;&#29983;&#25104;&#12290;&#20026;&#20102;&#22686;&#24378;&#23569;&#26679;&#26412;&#24615;&#33021;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#25351;&#23548;&#35828;&#26126;&#21644;&#32422;&#26463;&#27169;&#24335;&#19979;&#30340;&#25968;&#25454;&#29983;&#25104;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23454;&#29616;&#19982;&#20197;&#21069;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#32780;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25968;&#25454;&#29983;&#25104;&#21487;&#20197;&#25512;&#21160;&#20197;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#20197;&#22312;&#22235;&#20010;&#24191;&#27867;&#30740;&#31350;&#30340;&#20851;&#31995;&#25277;&#21462;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#26032;&#30340;&#26368;&#20808;&#36827;&#30340;&#23569;&#26679;&#26412;&#32467;&#26524;&#12290;&#25105;&#20204;&#24076;&#26395;&#25105;&#20204;&#30340;&#24037;&#20316;&#21487;&#20197;&#28608;&#21457;&#26410;&#26469;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20851;&#31995;&#25277;&#21462;&#20013;&#30340;&#33021;&#21147;&#30340;&#30740;&#31350;&#12290;&#20195;&#30721;&#21487;&#20197;&#22312; \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm} &#20013;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Panel-MDP&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#36890;&#36807;&#37319;&#29992;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#65292;&#20197;&#29992;&#25143;&#21916;&#22909;&#20026;&#23548;&#21521;&#65292;&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#32593;&#26684;&#38754;&#26495;&#25490;&#21015;&#29289;&#21697;&#30340;&#38382;&#39064;&#65292;&#25552;&#39640;&#29992;&#25143;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2204.04954</link><description>&lt;p&gt;
&#22522;&#20110;2D&#32593;&#26684;&#25512;&#33616;&#38754;&#26495;&#30340;&#24378;&#21270;&#20877;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Re-ranking with 2D Grid-based Recommendation Panels. (arXiv:2204.04954v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.04954
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Panel-MDP&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#36890;&#36807;&#37319;&#29992;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#65292;&#20197;&#29992;&#25143;&#21916;&#22909;&#20026;&#23548;&#21521;&#65292;&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#32593;&#26684;&#38754;&#26495;&#25490;&#21015;&#29289;&#21697;&#30340;&#38382;&#39064;&#65292;&#25552;&#39640;&#29992;&#25143;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#20316;&#20026;&#19968;&#20010;&#27969;&#24335;&#30340;&#21333;&#32500;&#25490;&#24207;&#21015;&#34920;&#21576;&#29616;&#29289;&#21697;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#30005;&#23376;&#21830;&#21153;&#20013;&#26377;&#19968;&#31181;&#36235;&#21183;&#65292;&#21363;&#25512;&#33616;&#30340;&#29289;&#21697;&#20197;&#20108;&#32500;&#32593;&#26684;&#38754;&#26495;&#30340;&#24418;&#24335;&#32452;&#32455;&#65292;&#29992;&#25143;&#21487;&#20197;&#22312;&#31446;&#30452;&#21644;&#27700;&#24179;&#26041;&#21521;&#19978;&#26597;&#30475;&#29289;&#21697;&#12290;&#22312;&#32593;&#26684;&#24418;&#24335;&#30340;&#32467;&#26524;&#38754;&#26495;&#20013;&#21576;&#29616;&#29289;&#21697;&#23545;&#20110;&#25512;&#33616;&#31995;&#32479;&#25552;&#20986;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#29616;&#26377;&#27169;&#22411;&#37117;&#26159;&#35774;&#35745;&#29992;&#20110;&#36755;&#20986;&#24207;&#21015;&#21015;&#34920;&#65292;&#32780;&#32593;&#26684;&#38754;&#26495;&#20013;&#30340;&#25554;&#27133;&#27809;&#26377;&#26126;&#30830;&#30340;&#39034;&#24207;&#12290;&#30452;&#25509;&#23558;&#29289;&#21697;&#25490;&#21517;&#36716;&#25442;&#20026;&#32593;&#26684;&#65288;&#20363;&#22914;&#65292;&#39044;&#23450;&#20041;&#25554;&#27133;&#30340;&#39034;&#24207;&#65289;&#24573;&#30053;&#20102;&#32593;&#26684;&#38754;&#26495;&#19978;&#29992;&#25143;&#29305;&#23450;&#30340;&#34892;&#20026;&#27169;&#24335;&#65292;&#24182;&#19988;&#19981;&#21487;&#36991;&#20813;&#22320;&#24433;&#21709;&#29992;&#25143;&#20307;&#39564;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#65292;&#29992;&#20110;&#22312;&#25512;&#33616;&#31995;&#32479;&#30340;&#26368;&#32456;&#20877;&#25490;&#24207;&#38454;&#27573;&#20013;&#25918;&#32622;&#29289;&#21697;&#21040;&#20108;&#32500;&#32593;&#26684;&#32467;&#26524;&#38754;&#26495;&#20013;&#12290;&#35813;&#27169;&#22411;&#34987;&#31216;&#20026;Panel-MDP&#65292;&#23427;&#20197;&#26089;&#26399;&#38454;&#27573;&#30340;&#21021;&#22987;&#29289;&#21697;&#25490;&#24207;&#20026;&#36755;&#20837;&#12290;&#28982;&#21518;&#65292;&#27169;&#22411;&#23558;&#20197;&#29992;&#25143;&#21916;&#22909;&#20026;&#23548;&#21521;&#65292;&#37319;&#29992;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#26469;&#20915;&#23450;&#22914;&#20309;&#25490;&#21015;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommender systems usually present items as a streaming, one-dimensional ranking list. Recently there is a trend in e-commerce that the recommended items are organized grid-based panels with two dimensions where users can view the items in both vertical and horizontal directions. Presenting items in grid-based result panels poses new challenges to recommender systems because existing models are all designed to output sequential lists while the slots in a grid-based panel have no explicit order. Directly converting the item rankings into grids (e.g., pre-defining an order on the slots) overlooks the user-specific behavioral patterns on grid-based panels and inevitably hurts the user experiences. To address this issue, we propose a novel Markov decision process (MDP) to place the items in 2D grid-based result panels at the final re-ranking stage of the recommender systems. The model, referred to as Panel-MDP, takes an initial item ranking from the early stages as the input. Then,
&lt;/p&gt;</description></item><item><title>&#35768;&#22810;&#30740;&#31350;&#23581;&#35797;&#37325;&#26032;&#21046;&#23450;&#21363;&#24109;&#26597;&#35810;&#20197;&#25903;&#25345;&#24320;&#21457;&#20154;&#21592;&#36827;&#34892;&#20195;&#30721;&#25628;&#32034;&#65292;&#26412;&#25991;&#38024;&#23545;70&#20010;&#20027;&#35201;&#26597;&#35810;&#20877;&#21046;&#23450;&#30740;&#31350;&#36827;&#34892;&#20102;&#32454;&#33268;&#31579;&#36873;&#21644;&#28145;&#20837;&#30340;&#23450;&#24615;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#20843;&#31181;&#20027;&#35201;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2108.09646</link><description>&lt;p&gt;
&#33258;&#21160;&#26597;&#35810;&#20877;&#21046;&#23450;&#22312;&#28304;&#20195;&#30721;&#25628;&#32034;&#20013;&#30340;&#31995;&#32479;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Systematic Review of Automated Query Reformulations in Source Code Search. (arXiv:2108.09646v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.09646
&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#30740;&#31350;&#23581;&#35797;&#37325;&#26032;&#21046;&#23450;&#21363;&#24109;&#26597;&#35810;&#20197;&#25903;&#25345;&#24320;&#21457;&#20154;&#21592;&#36827;&#34892;&#20195;&#30721;&#25628;&#32034;&#65292;&#26412;&#25991;&#38024;&#23545;70&#20010;&#20027;&#35201;&#26597;&#35810;&#20877;&#21046;&#23450;&#30740;&#31350;&#36827;&#34892;&#20102;&#32454;&#33268;&#31579;&#36873;&#21644;&#28145;&#20837;&#30340;&#23450;&#24615;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#20843;&#31181;&#20027;&#35201;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20462;&#22797;&#36719;&#20214;&#28431;&#27934;&#21644;&#28155;&#21152;&#26032;&#21151;&#33021;&#26159;&#20027;&#35201;&#30340;&#32500;&#25252;&#20219;&#21153;&#20043;&#20108;&#12290;&#36825;&#20123;&#28431;&#27934;&#21644;&#21151;&#33021;&#20197;&#26356;&#25913;&#35831;&#27714;&#30340;&#24418;&#24335;&#25253;&#21578;&#12290;&#24320;&#21457;&#20154;&#21592;&#20250;&#20174;&#36825;&#20123;&#35831;&#27714;&#20013;&#36873;&#25321;&#19968;&#20123;&#20851;&#38190;&#35789;&#20316;&#20026;&#21363;&#24109;&#26597;&#35810;&#65292;&#28982;&#21518;&#20351;&#29992;&#25628;&#32034;&#24341;&#25806;&#25191;&#34892;&#26597;&#35810;&#65292;&#26597;&#25214;&#38656;&#35201;&#26356;&#25913;&#30340;&#36719;&#20214;&#20195;&#30721;&#30340;&#30830;&#20999;&#20301;&#32622;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#26159;&#32463;&#39564;&#20016;&#23500;&#30340;&#24320;&#21457;&#20154;&#21592;&#36890;&#24120;&#20063;&#26080;&#27861;&#36873;&#25321;&#36866;&#24403;&#30340;&#26597;&#35810;&#65292;&#36825;&#23548;&#33268;&#22312;&#20195;&#30721;&#25628;&#32034;&#26399;&#38388;&#36827;&#34892;&#26114;&#36149;&#30340;&#35797;&#38169;&#12290;&#22810;&#24180;&#26469;&#65292;&#35768;&#22810;&#30740;&#31350;&#23581;&#35797;&#37325;&#26032;&#21046;&#23450;&#24320;&#21457;&#20154;&#21592;&#30340;&#21363;&#24109;&#26597;&#35810;&#20197;&#25903;&#25345;&#20182;&#20204;&#12290;&#26412;&#25991;&#31995;&#32479;&#22320;&#23545;70&#20010;&#20027;&#35201;&#26597;&#35810;&#20877;&#21046;&#23450;&#30740;&#31350;&#36827;&#34892;&#32454;&#33268;&#31579;&#36873;&#65288;&#20174;2,970&#20010;&#20505;&#36873;&#30740;&#31350;&#20013;&#36873;&#25321;&#65289;&#65292;&#36827;&#34892;&#28145;&#20837;&#30340;&#23450;&#24615;&#20998;&#26512;&#65288;&#22914;&#22522;&#30784;&#29702;&#35770;&#65289;&#65292;&#24182;&#22238;&#31572;&#19971;&#20010;&#30740;&#31350;&#38382;&#39064;&#24182;&#25552;&#20986;&#20027;&#35201;&#21457;&#29616;&#12290;&#39318;&#20808;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#24050;&#37319;&#29992;&#20102;&#20843;&#31181;&#20027;&#35201;&#26041;&#27861;&#65288;&#22914;&#35789;&#39033;&#21152;&#26435;&#65292;&#35789;&#39033;&#20849;&#29616;&#20998;&#26512;&#65292;&#35789;&#24211;&#26597;&#25214;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fixing software bugs and adding new features are two of the major maintenance tasks. Software bugs and features are reported as change requests. Developers consult these requests and often choose a few keywords from them as an ad hoc query. Then they execute the query with a search engine to find the exact locations within software code that need to be changed. Unfortunately, even experienced developers often fail to choose appropriate queries, which leads to costly trials and errors during a code search. Over the years, many studies attempt to reformulate the ad hoc queries from developers to support them. In this systematic literature review, we carefully select 70 primary studies on query reformulations from 2,970 candidate studies, perform an in-depth qualitative analysis (e.g., Grounded Theory), and then answer seven research questions with major findings. First, to date, eight major methodologies (e.g., term weighting, term co-occurrence analysis, thesaurus lookup) have been adop
&lt;/p&gt;</description></item></channel></rss>