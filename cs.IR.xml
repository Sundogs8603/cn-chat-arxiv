<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#22797;&#29616;&#20102;&#20808;&#21069;&#30340;&#29983;&#20135;&#32773;&#20844;&#24179;&#37325;&#26032;&#25490;&#21517;&#65288;PFR&#65289;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#23545;&#20110;&#20919;&#38376;&#29289;&#21697;&#36896;&#25104;&#20102;&#26174;&#33879;&#30340;&#20260;&#23475;&#65292;&#22312;&#20248;&#21183;&#21644;&#21155;&#21183;&#32452;&#20013;&#23384;&#22312;&#20844;&#24179;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2309.09277</link><description>&lt;p&gt;
&#25152;&#26377;&#20154;&#30340;&#20844;&#24179;&#24615;&#65306;&#25506;&#31350;&#29983;&#20135;&#32773;&#20844;&#24179;&#37325;&#26032;&#25490;&#21517;&#20248;&#21270;&#20013;&#23545;&#32452;&#20869;&#20010;&#20307;&#30340;&#20260;&#23475;--&#19968;&#39033;&#21487;&#22797;&#29616;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Fairness for All: Investigating Harms to Within-Group Individuals in Producer Fairness Re-ranking Optimization -- A Reproducibility Study. (arXiv:2309.09277v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22797;&#29616;&#20102;&#20808;&#21069;&#30340;&#29983;&#20135;&#32773;&#20844;&#24179;&#37325;&#26032;&#25490;&#21517;&#65288;PFR&#65289;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#23545;&#20110;&#20919;&#38376;&#29289;&#21697;&#36896;&#25104;&#20102;&#26174;&#33879;&#30340;&#20260;&#23475;&#65292;&#22312;&#20248;&#21183;&#21644;&#21155;&#21183;&#32452;&#20013;&#23384;&#22312;&#20844;&#24179;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#34987;&#24191;&#27867;&#29992;&#20110;&#20026;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#23384;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#20559;&#35265;&#65292;&#22914;&#27969;&#34892;&#24230;&#20559;&#35265;&#65292;&#23548;&#33268;&#29983;&#20135;&#32773;&#32676;&#20307;&#20043;&#38388;&#30340;&#25512;&#33616;&#26333;&#20809;&#20998;&#24067;&#19981;&#22343;&#34913;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#31181;&#24773;&#20917;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#20197;&#29983;&#20135;&#32773;&#20026;&#20013;&#24515;&#30340;&#20844;&#24179;&#37325;&#26032;&#25490;&#21517;&#65288;PFR&#65289;&#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#21508;&#32452;&#20043;&#38388;&#30340;&#25512;&#33616;&#25928;&#29992;&#20844;&#24179;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24573;&#35270;&#20102;&#23427;&#20204;&#23545;&#19982;&#20919;&#38376;&#29289;&#21697;&#65288;&#21363;&#19982;&#29992;&#25143;&#30340;&#20132;&#20114;&#24456;&#23569;&#25110;&#27809;&#26377;&#20132;&#20114;&#30340;&#29289;&#21697;&#65289;&#30456;&#20851;&#30340;&#32452;&#20869;&#20010;&#20307;&#21487;&#33021;&#36896;&#25104;&#30340;&#20260;&#23475;&#12290;&#26412;&#30740;&#31350;&#22797;&#29616;&#20102;&#20808;&#21069;&#30340;PFR&#26041;&#27861;&#65292;&#24182;&#26174;&#31034;&#23427;&#20204;&#22312;&#20919;&#38376;&#29289;&#21697;&#19978;&#36896;&#25104;&#20102;&#26174;&#33879;&#30340;&#20260;&#23475;&#65292;&#23548;&#33268;&#36825;&#20123;&#29289;&#21697;&#22312;&#20248;&#21183;&#21644;&#21155;&#21183;&#32452;&#20013;&#20986;&#29616;&#20102;&#20844;&#24179;&#24046;&#36317;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#19981;&#20844;&#24179;&#30340;&#22522;&#20934;&#25512;&#33616;&#27169;&#22411;&#32473;&#20104;&#36825;&#20123;&#20919;&#38376;&#20010;&#20307;&#26356;&#22810;&#30340;&#26333;&#20809;&#26426;&#20250;&#65292;&#23613;&#31649;&#24635;&#20307;&#19978;&#30475;&#36215;&#26469;&#26159;&#19981;&#20844;&#24179;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are widely used to provide personalized recommendations to users. Recent research has shown that recommender systems may be subject to different types of biases, such as popularity bias, leading to an uneven distribution of recommendation exposure among producer groups. To mitigate this, producer-centered fairness re-ranking (PFR) approaches have been proposed to ensure equitable recommendation utility across groups. However, these approaches overlook the harm they may cause to within-group individuals associated with colder items, which are items with few or no interactions.  This study reproduces previous PFR approaches and shows that they significantly harm colder items, leading to a fairness gap for these items in both advantaged and disadvantaged groups. Surprisingly, the unfair base recommendation models were providing greater exposure opportunities to these individual cold items, even though at the group level, they appeared to be unfair. To address this issu
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#22411;AI&#39046;&#22495;&#30340;&#26032;&#25216;&#26415;&#36827;&#34892;&#38646;&#26679;&#26412;&#25512;&#33616;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22810;&#27169;&#24577;&#36755;&#20837;&#36716;&#21270;&#20026;&#25991;&#26412;&#25551;&#36848;&#65292;&#24182;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#35745;&#31639;&#35821;&#20041;&#23884;&#20837;&#65292;&#23454;&#29616;&#20102;&#23545;&#38750;&#24179;&#31283;&#20869;&#23481;&#30340;&#25512;&#33616;&#12290;&#22312;&#21512;&#25104;&#30340;&#22810;&#27169;&#24577;&#26263;&#31034;&#29615;&#22659;&#20013;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.01026</link><description>&lt;p&gt;
&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#22810;&#27169;&#24577;&#26263;&#31034;&#30340;&#38646;&#26679;&#26412;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging. (arXiv:2309.01026v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01026
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#22411;AI&#39046;&#22495;&#30340;&#26032;&#25216;&#26415;&#36827;&#34892;&#38646;&#26679;&#26412;&#25512;&#33616;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22810;&#27169;&#24577;&#36755;&#20837;&#36716;&#21270;&#20026;&#25991;&#26412;&#25551;&#36848;&#65292;&#24182;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#35745;&#31639;&#35821;&#20041;&#23884;&#20837;&#65292;&#23454;&#29616;&#20102;&#23545;&#38750;&#24179;&#31283;&#20869;&#23481;&#30340;&#25512;&#33616;&#12290;&#22312;&#21512;&#25104;&#30340;&#22810;&#27169;&#24577;&#26263;&#31034;&#29615;&#22659;&#20013;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#26368;&#26032;&#36827;&#23637;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#25512;&#33616;&#22810;&#27169;&#24577;&#38750;&#24179;&#31283;&#20869;&#23481;&#12290;&#25105;&#20204;&#24314;&#35758;&#23558;&#19981;&#21516;&#27169;&#24577;&#30340;&#36755;&#20837;&#28210;&#26579;&#20026;&#25991;&#26412;&#25551;&#36848;&#65292;&#24182;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLM&#35745;&#31639;&#35821;&#20041;&#23884;&#20837;&#33719;&#21462;&#23427;&#20204;&#30340;&#25968;&#20540;&#34920;&#31034;&#12290;&#19968;&#26086;&#33719;&#24471;&#25152;&#26377;&#20869;&#23481;&#39033;&#30340;&#32479;&#19968;&#34920;&#31034;&#65292;&#21487;&#20197;&#36890;&#36807;&#35745;&#31639;&#36866;&#24403;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#26469;&#36827;&#34892;&#25512;&#33616;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#23398;&#20064;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#21512;&#25104;&#30340;&#22810;&#27169;&#24577;&#26263;&#31034;&#29615;&#22659;&#20013;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#36755;&#20837;&#21253;&#25324;&#34920;&#26684;&#12289;&#25991;&#26412;&#21644;&#35270;&#35273;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a method for zero-shot recommendation of multimodal non-stationary content that leverages recent advancements in the field of generative AI. We propose rendering inputs of different modalities as textual descriptions and to utilize pre-trained LLMs to obtain their numerical representations by computing semantic embeddings. Once unified representations of all content items are obtained, the recommendation can be performed by computing an appropriate similarity metric between them without any additional learning. We demonstrate our approach on a synthetic multimodal nudging environment, where the inputs consist of tabular, textual, and visual data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#25512;&#33616;&#31995;&#32479;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26679;&#26412;&#21306;&#22495;&#36827;&#34892;&#21010;&#20998;&#24182;&#20351;&#29992;AdaSim&#23545;&#21306;&#22495;&#36171;&#20104;&#19981;&#21516;&#30340;&#26435;&#37325;&#65292;&#24418;&#25104;&#27491;&#36127;&#26679;&#26412;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23376;&#38598;&#36873;&#25321;&#27169;&#22411;&#26469;&#32553;&#23567;&#26680;&#24515;&#36127;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.07321</link><description>&lt;p&gt;
NS4AR: &#19968;&#31181;&#26032;&#30340;&#12289;&#19987;&#27880;&#20110;&#37319;&#26679;&#21306;&#22495;&#30340;&#22270;&#24418;&#25512;&#33616;&#31995;&#32479;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
NS4AR: A new, focused on sampling areas sampling method in graphical recommendation Systems. (arXiv:2307.07321v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07321
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#25512;&#33616;&#31995;&#32479;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26679;&#26412;&#21306;&#22495;&#36827;&#34892;&#21010;&#20998;&#24182;&#20351;&#29992;AdaSim&#23545;&#21306;&#22495;&#36171;&#20104;&#19981;&#21516;&#30340;&#26435;&#37325;&#65292;&#24418;&#25104;&#27491;&#36127;&#26679;&#26412;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23376;&#38598;&#36873;&#25321;&#27169;&#22411;&#26469;&#32553;&#23567;&#26680;&#24515;&#36127;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#25512;&#33616;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#36127;&#37319;&#26679;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;&#26412;&#25991;&#36873;&#25321;&#20102;&#19968;&#20123;&#20856;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#65292;&#24182;&#23558;&#36825;&#20123;&#27169;&#22411;&#19978;&#30340;&#19968;&#20123;&#26368;&#26032;&#30340;&#36127;&#37319;&#26679;&#31574;&#30053;&#20316;&#20026;&#22522;&#32447;&#12290;&#22522;&#20110;&#20856;&#22411;&#30340;&#22270;&#24418;&#25512;&#33616;&#27169;&#22411;&#65292;&#25105;&#20204;&#23558;&#26679;&#26412;&#21306;&#22495;&#21010;&#20998;&#20026;&#25351;&#23450;&#30340;n&#20010;&#21306;&#22495;&#65292;&#24182;&#20351;&#29992;AdaSim&#23545;&#36825;&#20123;&#21306;&#22495;&#36171;&#20104;&#19981;&#21516;&#30340;&#26435;&#37325;&#65292;&#24418;&#25104;&#27491;&#26679;&#26412;&#38598;&#21644;&#36127;&#26679;&#26412;&#38598;&#12290;&#30001;&#20110;&#36127;&#26679;&#26412;&#30340;&#25968;&#37327;&#21644;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#23376;&#38598;&#36873;&#25321;&#27169;&#22411;&#26469;&#32553;&#23567;&#26680;&#24515;&#36127;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
The effectiveness of graphical recommender system depends on the quantity and quality of negative sampling. This paper selects some typical recommender system models, as well as some latest negative sampling strategies on the models as baseline. Based on typical graphical recommender model, we divide sample region into assigned-n areas and use AdaSim to give different weight to these areas to form positive set and negative set. Because of the volume and significance of negative items, we also proposed a subset selection model to narrow the core negative samples.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#36793;&#38469;&#30697;&#38453;&#20998;&#35299;&#30340;&#21322;&#30417;&#30563;&#26041;&#27861;&#26469;&#22686;&#24191;&#21644;&#32454;&#21270;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#30340;&#35780;&#32423;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#33258;&#25105;&#35757;&#32451;&#26469;&#35780;&#20272;&#35780;&#20998;&#30340;&#32622;&#20449;&#24230;&#65292;&#24182;&#36890;&#36807;&#31995;&#32479;&#30340;&#25968;&#25454;&#22686;&#24191;&#31574;&#30053;&#26469;&#25552;&#39640;&#31639;&#27861;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.13050</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#25968;&#25454;&#22686;&#24191;&#65306;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#36793;&#38469;&#30697;&#38453;&#20998;&#35299;&#30340;&#21322;&#30417;&#30563;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Data augmentation for recommender system: A semi-supervised approach using maximum margin matrix factorization. (arXiv:2306.13050v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#36793;&#38469;&#30697;&#38453;&#20998;&#35299;&#30340;&#21322;&#30417;&#30563;&#26041;&#27861;&#26469;&#22686;&#24191;&#21644;&#32454;&#21270;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#30340;&#35780;&#32423;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#33258;&#25105;&#35757;&#32451;&#26469;&#35780;&#20272;&#35780;&#20998;&#30340;&#32622;&#20449;&#24230;&#65292;&#24182;&#36890;&#36807;&#31995;&#32479;&#30340;&#25968;&#25454;&#22686;&#24191;&#31574;&#30053;&#26469;&#25552;&#39640;&#31639;&#27861;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#24050;&#25104;&#20026;&#25512;&#33616;&#31995;&#32479;&#24320;&#21457;&#30340;&#24120;&#29992;&#26041;&#27861;&#65292;&#20854;&#20013;&#65292;&#26681;&#25454;&#29992;&#25143;&#30340;&#36807;&#21435;&#21916;&#22909;&#21644;&#20854;&#20182;&#29992;&#25143;&#30340;&#21487;&#29992;&#20559;&#22909;&#20449;&#24687;&#39044;&#27979;&#20854;&#23545;&#26032;&#29289;&#21697;&#30340;&#35780;&#20998;&#12290;&#23613;&#31649;CF&#26041;&#27861;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#20854;&#24615;&#33021;&#36890;&#24120;&#21463;&#35266;&#23519;&#21040;&#30340;&#26465;&#30446;&#30340;&#31232;&#30095;&#24615;&#30340;&#26497;&#22823;&#38480;&#21046;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#26368;&#22823;&#36793;&#38469;&#30697;&#38453;&#20998;&#35299;&#65288;MMMF&#65289;&#30340;&#25968;&#25454;&#22686;&#24191;&#21644;&#32454;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#26159;&#24191;&#27867;&#25509;&#21463;&#30340;&#29992;&#20110;&#35780;&#32423;&#39044;&#27979;&#30340;CF&#25216;&#26415;&#65292;&#20043;&#21069;&#23578;&#26410;&#36827;&#34892;&#30740;&#31350;&#12290;&#25105;&#20204;&#21033;&#29992;CF&#31639;&#27861;&#30340;&#22266;&#26377;&#29305;&#24615;&#26469;&#35780;&#20272;&#21333;&#20010;&#35780;&#20998;&#30340;&#32622;&#20449;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#25105;&#35757;&#32451;&#30340;&#21322;&#30417;&#30563;&#35780;&#32423;&#22686;&#24378;&#26041;&#27861;&#12290;&#25105;&#20204;&#20551;&#35774;&#20219;&#20309;CF&#31639;&#27861;&#30340;&#39044;&#27979;&#20302;&#32622;&#20449;&#24230;&#26159;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#30340;&#26576;&#20123;&#19981;&#36275;&#65292;&#22240;&#27492;&#65292;&#36890;&#36807;&#37319;&#29992;&#31995;&#32479;&#30340;&#25968;&#25454;&#22686;&#24191;&#31574;&#30053;&#65292;&#21487;&#20197;&#25552;&#39640;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative filtering (CF) has become a popular method for developing recommender systems (RS) where ratings of a user for new items is predicted based on her past preferences and available preference information of other users. Despite the popularity of CF-based methods, their performance is often greatly limited by the sparsity of observed entries. In this study, we explore the data augmentation and refinement aspects of Maximum Margin Matrix Factorization (MMMF), a widely accepted CF technique for the rating predictions, which have not been investigated before. We exploit the inherent characteristics of CF algorithms to assess the confidence level of individual ratings and propose a semi-supervised approach for rating augmentation based on self-training. We hypothesize that any CF algorithm's predictions with low confidence are due to some deficiency in the training data and hence, the performance of the algorithm can be improved by adopting a systematic data augmentation strategy
&lt;/p&gt;</description></item><item><title>Mol-Instructions&#26159;&#19968;&#20010;&#19987;&#38376;&#20026;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#35774;&#35745;&#30340;&#32508;&#21512;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#29289;&#39046;&#22495;&#20013;&#30340;&#36866;&#24212;&#33021;&#21147;&#21644;&#35748;&#30693;&#25935;&#38160;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.08018</link><description>&lt;p&gt;
Mol-Instructions: &#19968;&#20010;&#22823;&#35268;&#27169;&#29983;&#29289;&#20998;&#23376;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#20026;&#22823;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;
Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08018
&lt;/p&gt;
&lt;p&gt;
Mol-Instructions&#26159;&#19968;&#20010;&#19987;&#38376;&#20026;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#35774;&#35745;&#30340;&#32508;&#21512;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#29289;&#39046;&#22495;&#20013;&#30340;&#36866;&#24212;&#33021;&#21147;&#21644;&#35748;&#30693;&#25935;&#38160;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#20854;&#21331;&#36234;&#30340;&#20219;&#21153;&#22788;&#29702;&#33021;&#21147;&#21644;&#21019;&#26032;&#30340;&#36755;&#20986;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#25512;&#21160;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#29983;&#29289;&#20998;&#23376;&#30740;&#31350;&#31561;&#19987;&#19994;&#39046;&#22495;&#30340;&#29087;&#32451;&#24212;&#29992;&#36824;&#21463;&#21040;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Mol-Instructions&#65292;&#36825;&#26159;&#19968;&#20010;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#12289;&#19987;&#38376;&#38024;&#23545;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#35774;&#35745;&#30340;&#32508;&#21512;&#25351;&#20196;&#25968;&#25454;&#38598;&#12290;Mol-Instructions&#30001;&#19977;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#32452;&#25104;&#65306;&#20998;&#23376;&#23548;&#21521;&#25351;&#20196;&#12289;&#34507;&#30333;&#36136;&#23548;&#21521;&#25351;&#20196;&#21644;&#29983;&#29289;&#20998;&#23376;&#25991;&#26412;&#25351;&#20196;&#65292;&#27599;&#20010;&#37096;&#20998;&#37117;&#34987;&#31574;&#21010;&#29992;&#20110;&#22686;&#24378;LLM&#23545;&#29983;&#29289;&#20998;&#23376;&#29305;&#24615;&#21644;&#34892;&#20026;&#30340;&#29702;&#35299;&#21644;&#39044;&#27979;&#33021;&#21147;&#12290;&#36890;&#36807;&#23545;&#20195;&#34920;&#24615;LLM&#30340;&#24191;&#27867;&#25351;&#20196;&#35843;&#25972;&#23454;&#39564;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;Mol-Instructions&#22312;&#22686;&#24378;&#22823;&#27169;&#22411;&#22312;&#29983;&#29289;&#20998;&#23376;&#30740;&#31350;&#22797;&#26434;&#39046;&#22495;&#20869;&#30340;&#36866;&#24212;&#33021;&#21147;&#21644;&#35748;&#30693;&#25935;&#38160;&#24230;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#20174;&#32780;&#20419;&#36827;&#29983;&#29289;&#20998;&#23376;&#39046;&#22495;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a meticulously curated, comprehensive instruction dataset expressly designed for the biomolecular realm. Mol-Instructions is composed of three pivotal components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions, each curated to enhance the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on the representative LLM, we underscore the potency of Mol-Instructions to enhance the adaptability and cognitive acuity of large models within the complex sphere of biomolecular studies, thereby promoting advancements in the biomol
&lt;/p&gt;</description></item></channel></rss>