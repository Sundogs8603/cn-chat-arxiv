<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#32447;&#24615;&#21644;&#32593;&#26684;&#24067;&#23616;&#27983;&#35272;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#29992;&#25143;&#23545;&#25490;&#21517;&#32467;&#26524;&#30340;&#20851;&#27880;&#24230;&#65292;&#24182;&#25351;&#20986;&#19981;&#21516;&#25490;&#21517;&#24067;&#23616;&#19979;&#30340;&#29992;&#25143;&#27983;&#35272;&#34892;&#20026;&#23384;&#22312;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2310.12524</link><description>&lt;p&gt;
&#32479;&#19968;&#30340;&#32447;&#24615;&#21644;&#32593;&#26684;&#24067;&#23616;&#27983;&#35272;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unified Browsing Models for Linear and Grid Layouts. (arXiv:2310.12524v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12524
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#32447;&#24615;&#21644;&#32593;&#26684;&#24067;&#23616;&#27983;&#35272;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#29992;&#25143;&#23545;&#25490;&#21517;&#32467;&#26524;&#30340;&#20851;&#27880;&#24230;&#65292;&#24182;&#25351;&#20986;&#19981;&#21516;&#25490;&#21517;&#24067;&#23616;&#19979;&#30340;&#29992;&#25143;&#27983;&#35272;&#34892;&#20026;&#23384;&#22312;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20449;&#24687;&#35775;&#38382;&#31995;&#32479;&#23558;&#32467;&#26524;&#25353;&#29031;&#25490;&#21517;&#26469;&#25805;&#20316;&#65292;&#24182;&#20197;&#32447;&#24615;&#21015;&#34920;&#25110;&#32593;&#26684;&#30340;&#24418;&#24335;&#23637;&#31034;&#32473;&#29992;&#25143;&#12290;&#29992;&#25143;&#23545;&#26816;&#32034;&#21040;&#30340;&#39033;&#30446;&#30340;&#20132;&#20114;&#39640;&#24230;&#20381;&#36182;&#20110;&#39033;&#30446;&#22312;&#24067;&#23616;&#20013;&#30340;&#20301;&#32622;&#65292;&#24182;&#19988;&#29992;&#25143;&#19981;&#20250;&#23545;&#25490;&#21517;&#20013;&#30340;&#27599;&#20010;&#20301;&#32622;&#25552;&#20379;&#30456;&#20284;&#30340;&#20851;&#27880;&#12290;&#29992;&#25143;&#20851;&#27880;&#24230;&#26159;&#25490;&#21517;&#35780;&#20272;&#36807;&#31243;&#20013;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#22240;&#20026;&#23427;&#22312;&#35780;&#20272;&#23454;&#29992;&#24615;&#30340;&#25928;&#24230;&#25351;&#26631;&#21644;&#22522;&#20110;&#31038;&#20250;&#21644;&#36947;&#24503;&#32771;&#34385;&#35780;&#20272;&#25490;&#21517;&#30340;&#20844;&#24179;&#24615;&#25351;&#26631;&#20013;&#20351;&#29992;&#12290;&#36825;&#20123;&#25351;&#26631;&#22312;&#20854;&#27979;&#37327;&#31574;&#30053;&#20013;&#32771;&#34385;&#20102;&#29992;&#25143;&#27983;&#35272;&#34892;&#20026;&#65292;&#20197;&#20272;&#35745;&#29992;&#25143;&#21487;&#33021;&#23545;&#25490;&#21517;&#20013;&#30340;&#27599;&#20010;&#39033;&#30446;&#25552;&#20379;&#30340;&#20851;&#27880;&#24230;&#12290;&#20851;&#20110;&#29702;&#35299;&#29992;&#25143;&#27983;&#35272;&#34892;&#20026;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#20960;&#31181;&#29992;&#25143;&#27983;&#35272;&#27169;&#22411;&#65292;&#24182;&#36827;&#19968;&#27493;&#35266;&#23519;&#21040;&#19981;&#21516;&#25490;&#21517;&#24067;&#23616;&#19979;&#29992;&#25143;&#27983;&#35272;&#34892;&#20026;&#30340;&#24046;&#24322;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27983;&#35272;&#27169;&#22411;&#30340;&#27010;&#24565;&#20173;&#19981;&#22815;&#32479;&#19968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many information access systems operationalize their results in terms of rankings, which are then displayed to users in various ranking layouts such as linear lists or grids. User interaction with a retrieved item is highly dependent on the item's position in the layout, and users do not provide similar attention to every position in ranking (under any layout model). User attention is an important component in the evaluation process of ranking, due to its use in effectiveness metrics that estimate utility as well as fairness metrics that evaluate ranking based on social and ethical concerns. These metrics take user browsing behavior into account in their measurement strategies to estimate the attention the user is likely to provide to each item in ranking. Research on understanding user browsing behavior has proposed several user browsing models, and further observed that user browsing behavior differs with different ranking layouts. However, the underlying concepts of these browsing m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#25628;&#32034;&#32034;&#24341;&#22120;&#29992;&#20110;&#31471;&#21040;&#31471;&#25991;&#26723;&#26816;&#32034;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#20010;&#35821;&#20041;&#32034;&#24341;&#27169;&#22359;&#26469;&#33258;&#21160;&#23398;&#20064;&#29616;&#26377;&#21644;&#26032;&#25991;&#26723;&#30340;&#26368;&#20339;&#26631;&#35782;&#31526;&#65292;&#24182;&#36890;&#36807;&#19968;&#20010;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#25991;&#26723;&#26816;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#20808;&#36827;&#22522;&#32447;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.12455</link><description>&lt;p&gt;
&#33258;&#21160;&#25628;&#32034;&#32034;&#24341;&#22120;&#29992;&#20110;&#31471;&#21040;&#31471;&#25991;&#26723;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Auto Search Indexer for End-to-End Document Retrieval. (arXiv:2310.12455v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12455
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#25628;&#32034;&#32034;&#24341;&#22120;&#29992;&#20110;&#31471;&#21040;&#31471;&#25991;&#26723;&#26816;&#32034;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#20010;&#35821;&#20041;&#32034;&#24341;&#27169;&#22359;&#26469;&#33258;&#21160;&#23398;&#20064;&#29616;&#26377;&#21644;&#26032;&#25991;&#26723;&#30340;&#26368;&#20339;&#26631;&#35782;&#31526;&#65292;&#24182;&#36890;&#36807;&#19968;&#20010;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#25991;&#26723;&#26816;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#20808;&#36827;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24615;&#26816;&#32034;&#26159;&#19968;&#31181;&#26032;&#30340;&#39640;&#32423;&#25991;&#26723;&#26816;&#32034;&#33539;&#24335;&#65292;&#26368;&#36817;&#21560;&#24341;&#20102;&#30740;&#31350;&#20852;&#36259;&#65292;&#22240;&#20026;&#23427;&#23558;&#25152;&#26377;&#25991;&#26723;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#24182;&#30452;&#25509;&#29983;&#25104;&#26816;&#32034;&#21040;&#30340;&#25991;&#26723;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#21151;&#33021;&#20173;&#28982;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#21033;&#29992;&#65292;&#22240;&#20026;&#23427;&#20005;&#37325;&#20381;&#36182;&#20110;&#8220;&#39044;&#22788;&#29702;&#8221;&#30340;&#25991;&#26723;&#26631;&#35782;&#31526;&#65288;docids&#65289;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#20854;&#26816;&#32034;&#24615;&#33021;&#21644;&#26816;&#32034;&#26032;&#25991;&#26723;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23436;&#20840;&#31471;&#21040;&#31471;&#26816;&#32034;&#33539;&#24335;&#12290;&#23427;&#19981;&#20165;&#21487;&#20197;&#36890;&#36807;&#35821;&#20041;&#32034;&#24341;&#27169;&#22359;&#33258;&#21160;&#31471;&#21040;&#31471;&#22320;&#23398;&#20064;&#29616;&#26377;&#21644;&#26032;&#25991;&#26723;&#30340;&#26368;&#20339;docids&#65292;&#36824;&#21487;&#20197;&#36890;&#36807;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#29983;&#25104;&#27169;&#22411;&#65288;&#21363;Auto Search Indexer (ASI)&#65289;&#36827;&#34892;&#31471;&#21040;&#31471;&#25991;&#26723;&#26816;&#32034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#37325;&#21442;&#25968;&#21270;&#26426;&#21046;&#65292;&#23558;&#19978;&#36848;&#20004;&#20010;&#27169;&#22359;&#32452;&#21512;&#25104;&#19968;&#20010;&#32852;&#21512;&#20248;&#21270;&#26694;&#26550;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#20844;&#20849;&#21644;&#24037;&#19994;&#25968;&#25454;&#38598;&#19978;&#22343;&#20248;&#20110;&#20808;&#36827;&#30340;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative retrieval, which is a new advanced paradigm for document retrieval, has recently attracted research interests, since it encodes all documents into the model and directly generates the retrieved documents. However, its power is still underutilized since it heavily relies on the "preprocessed" document identifiers (docids), thus limiting its retrieval performance and ability to retrieve new documents. In this paper, we propose a novel fully end-to-end retrieval paradigm. It can not only end-to-end learn the best docids for existing and new documents automatically via a semantic indexing module, but also perform end-to-end document retrieval via an encoder-decoder-based generative model, namely Auto Search Indexer (ASI). Besides, we design a reparameterization mechanism to combine the above two modules into a joint optimization framework. Extensive experimental results demonstrate the superiority of our model over advanced baselines on both public and industrial datasets and al
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#26816;&#32034;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;LLM&#36716;&#21464;&#20026;&#19968;&#20010;&#30456;&#20851;&#12289;&#36127;&#36131;&#20219;&#19988;&#21487;&#20449;&#36182;&#30340;&#25628;&#32034;&#22120;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#29983;&#25104;&#22120;&#12289;&#39564;&#35777;&#22120;&#21644;&#20248;&#21270;&#22120;&#19977;&#20010;&#26680;&#24515;&#27169;&#22359;&#65292;&#20998;&#21035;&#29992;&#20110;&#29983;&#25104;&#21487;&#20449;&#36182;&#30340;&#22312;&#32447;&#26469;&#28304;&#12289;&#39564;&#35777;&#26469;&#28304;&#21487;&#38752;&#24615;&#21644;&#20248;&#21270;&#19981;&#21487;&#20449;&#36182;&#30340;&#26469;&#28304;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#20854;&#20182;&#26041;&#27861;&#22312;&#30456;&#20851;&#24615;&#12289;&#36127;&#36131;&#20219;&#24615;&#21644;&#21487;&#20449;&#24230;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.12443</link><description>&lt;p&gt;
&#20102;&#35299;&#20309;&#22788;&#21069;&#24448;&#65306;&#20351;LLM&#25104;&#20026;&#19968;&#20010;&#30456;&#20851;&#12289;&#36127;&#36131;&#20219;&#19988;&#21487;&#20449;&#36182;&#30340;&#25628;&#32034;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher. (arXiv:2310.12443v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12443
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#26816;&#32034;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;LLM&#36716;&#21464;&#20026;&#19968;&#20010;&#30456;&#20851;&#12289;&#36127;&#36131;&#20219;&#19988;&#21487;&#20449;&#36182;&#30340;&#25628;&#32034;&#22120;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#29983;&#25104;&#22120;&#12289;&#39564;&#35777;&#22120;&#21644;&#20248;&#21270;&#22120;&#19977;&#20010;&#26680;&#24515;&#27169;&#22359;&#65292;&#20998;&#21035;&#29992;&#20110;&#29983;&#25104;&#21487;&#20449;&#36182;&#30340;&#22312;&#32447;&#26469;&#28304;&#12289;&#39564;&#35777;&#26469;&#28304;&#21487;&#38752;&#24615;&#21644;&#20248;&#21270;&#19981;&#21487;&#20449;&#36182;&#30340;&#26469;&#28304;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#20854;&#20182;&#26041;&#27861;&#22312;&#30456;&#20851;&#24615;&#12289;&#36127;&#36131;&#20219;&#24615;&#21644;&#21487;&#20449;&#24230;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#24050;&#32463;&#26174;&#31034;&#20986;&#23427;&#22312;&#25552;&#39640;&#25628;&#32034;&#30456;&#20851;&#24615;&#21644;&#25552;&#20379;&#30452;&#25509;&#31572;&#26696;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20256;&#32479;&#20449;&#24687;&#26816;&#32034;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;LLM&#30340;&#38169;&#35273;&#38382;&#39064;&#65292;&#39564;&#35777;&#29983;&#25104;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#21644;&#36129;&#29486;&#26469;&#28304;&#30340;&#21487;&#20449;&#24230;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#21019;&#24314;LLM&#26102;&#20195;&#30340;&#8220;PageRank&#8221;&#65292;&#25105;&#20204;&#33268;&#21147;&#20110;&#23558;LLM&#36716;&#21464;&#20026;&#19968;&#20010;&#30456;&#20851;&#12289;&#36127;&#36131;&#20219;&#19988;&#21487;&#20449;&#36182;&#30340;&#25628;&#32034;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29983;&#25104;&#26816;&#32034;&#26694;&#26550;&#65292;&#21033;&#29992;LLM&#30340;&#30693;&#35782;&#24314;&#31435;&#26597;&#35810;&#21644;&#22312;&#32447;&#26469;&#28304;&#20043;&#38388;&#30340;&#30452;&#25509;&#38142;&#25509;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#26680;&#24515;&#27169;&#22359;&#65306;&#29983;&#25104;&#22120;&#12289;&#39564;&#35777;&#22120;&#21644;&#20248;&#21270;&#22120;&#65292;&#20998;&#21035;&#19987;&#27880;&#20110;&#29983;&#25104;&#21487;&#20449;&#36182;&#30340;&#22312;&#32447;&#26469;&#28304;&#12289;&#39564;&#35777;&#26469;&#28304;&#30340;&#21487;&#38752;&#24615;&#21644;&#20248;&#21270;&#19981;&#21487;&#20449;&#36182;&#30340;&#26469;&#28304;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#30456;&#20851;&#24615;&#12289;&#36127;&#36131;&#20219;&#24615;&#21644;&#21487;&#20449;&#24230;&#26041;&#38754;&#30456;&#23545;&#20110;&#21508;&#31181;SOTA&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of Large Language Models (LLMs) has shown the potential to improve relevance and provide direct answers in web searches. However, challenges arise in validating the reliability of generated results and the credibility of contributing sources, due to the limitations of traditional information retrieval algorithms and the LLM hallucination problem. Aiming to create a "PageRank" for the LLM era, we strive to transform LLM into a relevant, responsible, and trustworthy searcher. We propose a novel generative retrieval framework leveraging the knowledge of LLMs to foster a direct link between queries and online sources. This framework consists of three core modules: Generator, Validator, and Optimizer, each focusing on generating trustworthy online sources, verifying source reliability, and refining unreliable sources, respectively. Extensive experiments and evaluations highlight our method's superior relevance, responsibility, and trustfulness against various SOTA methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#26696;&#20363;&#30740;&#31350;&#26041;&#27861;&#65292;&#26088;&#22312;&#35782;&#21035;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#35821;&#20041;&#28436;&#21464;&#20197;&#21450;&#36328;&#39046;&#22495;&#35821;&#20041;&#28418;&#31227;&#65292;&#36890;&#36807;&#36861;&#36394;&#24341;&#25991;&#21644;&#20851;&#38190;&#35789;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#20851;&#38190;&#35789;&#22914;&#8220;&#20449;&#21495;&#37327;&#8221;&#12289;&#8220;&#22810;&#24577;&#24615;&#8221;&#21644;&#8220;&#26412;&#20307;&#35770;&#8221;&#22312;&#35745;&#31639;&#26426;&#31185;&#23398;&#39046;&#22495;&#30340;&#35821;&#20041;&#28436;&#21464;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.12369</link><description>&lt;p&gt;
&#35782;&#21035;&#36328;&#39046;&#22495;&#35821;&#20041;&#28418;&#31227;&#30340;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Identifying Points of Semantic Shift Across Domains. (arXiv:2310.12369v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12369
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#26696;&#20363;&#30740;&#31350;&#26041;&#27861;&#65292;&#26088;&#22312;&#35782;&#21035;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#35821;&#20041;&#28436;&#21464;&#20197;&#21450;&#36328;&#39046;&#22495;&#35821;&#20041;&#28418;&#31227;&#65292;&#36890;&#36807;&#36861;&#36394;&#24341;&#25991;&#21644;&#20851;&#38190;&#35789;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#20851;&#38190;&#35789;&#22914;&#8220;&#20449;&#21495;&#37327;&#8221;&#12289;&#8220;&#22810;&#24577;&#24615;&#8221;&#21644;&#8220;&#26412;&#20307;&#35770;&#8221;&#22312;&#35745;&#31639;&#26426;&#31185;&#23398;&#39046;&#22495;&#30340;&#35821;&#20041;&#28436;&#21464;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#26415;&#39046;&#22495;&#20013;&#29305;&#23450;&#26415;&#35821;&#30340;&#35821;&#20041;&#38543;&#26102;&#38388;&#26377;&#26426;&#28436;&#21464;&#12290;&#36861;&#36394;&#36825;&#31181;&#28436;&#21464;&#36890;&#24120;&#26159;&#30001;&#35821;&#35328;&#23398;&#32773;&#25110;&#32773;&#19987;&#27880;&#20110;&#21333;&#19968;&#30740;&#31350;&#39046;&#22495;&#20869;&#26415;&#35821;&#28436;&#21464;&#30340;&#30740;&#31350;&#26469;&#23454;&#29616;&#30340;&#12290;&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#26088;&#22312;&#35782;&#21035;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#35821;&#20041;&#28436;&#21464;&#65292;&#24182;&#25214;&#21040;&#36328;&#39046;&#22495;&#35821;&#20041;&#28418;&#31227;&#30340;&#20363;&#23376;&#12290;&#25105;&#20204;&#20197;&#20851;&#38190;&#35789;&#20026;&#22522;&#30784;&#36827;&#34892;&#25628;&#32034;&#65292;&#24182;&#36890;&#36807;&#36861;&#36394;&#24341;&#25991;&#30340;&#36845;&#20195;&#36807;&#31243;&#65292;&#25214;&#21040;&#36825;&#20123;&#27010;&#24565;&#22312;&#35813;&#39046;&#22495;&#20013;&#39318;&#27425;&#25552;&#21450;&#30340;&#25991;&#29486;&#12290;&#25105;&#20204;&#21457;&#29616;&#19968;&#20123;&#36873;&#25321;&#30340;&#20851;&#38190;&#35789;&#65292;&#22914;&#8220;&#20449;&#21495;&#37327;&#8221;&#12289;&#8220;&#22810;&#24577;&#24615;&#8221;&#21644;&#8220;&#26412;&#20307;&#35770;&#8221;&#65292;&#22312;&#35745;&#31639;&#26426;&#31185;&#23398;&#25991;&#29486;&#20013;&#34987;&#25552;&#21450;&#65292;&#24182;&#36890;&#36807;&#24341;&#25991;&#36861;&#28335;&#20854;&#28304;&#33258;&#21407;&#22987;&#39046;&#22495;&#30340;&#24320;&#21019;&#24615;&#30740;&#31350;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#20107;&#20214;&#26631;&#35760;&#20026;&#35821;&#20041;&#28436;&#21464;&#28857;&#12290;&#36890;&#36807;&#36825;&#31181;&#25163;&#21160;&#35843;&#26597;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#35782;&#21035;&#20986;&#19981;&#21516;&#23398;&#26415;&#39046;&#22495;&#20013;&#30340;&#26415;&#35821;&#28436;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;
The semantics used for particular terms in an academic field organically evolve over time. Tracking this evolution through inspection of published literature has either been from the perspective of Linguistic scholars or has concentrated the focus of term evolution within a single domain of study. In this paper, we performed a case study to identify semantic evolution across different domains and identify examples of inter-domain semantic shifts. We initially used keywords as the basis of our search and executed an iterative process of following citations to find the initial mention of the concepts in the field. We found that a select set of keywords like ``semaphore'', ``polymorphism'', and ``ontology'' were mentioned within Computer Science literature and tracked the seminal study that borrowed those terms from original fields by citations. We marked these events as semantic evolution points. Through this manual investigation method, we can identify term evolution across different ac
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26597;&#35810;&#29305;&#23450;&#25991;&#31456;&#29983;&#25104;&#30340;&#26367;&#20195;&#26041;&#27861;&#65306;&#36890;&#36807;&#25972;&#21512;&#25991;&#26723;&#26816;&#32034;&#12289;&#26597;&#35810;&#29305;&#23450;&#32858;&#31867;&#21644;&#25688;&#35201;&#29983;&#25104;&#31995;&#32479;&#65292;&#21487;&#20197;&#25552;&#20379;&#23454;&#38469;&#24341;&#29992;&#20316;&#20026;&#29983;&#25104;&#25991;&#26412;&#30340;&#26469;&#28304;&#65292;&#30456;&#36739;&#20110;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#33021;&#22815;&#24471;&#21040;&#26356;&#20934;&#30830;&#30340;&#29983;&#25104;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.12361</link><description>&lt;p&gt;
Retrieve-Cluster-Summarize: &#19968;&#31181;&#38024;&#23545;&#26597;&#35810;&#29305;&#23450;&#25991;&#31456;&#29983;&#25104;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#30340;&#26367;&#20195;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Retrieve-Cluster-Summarize: An Alternative to End-to-End Training for Query-specific Article Generation. (arXiv:2310.12361v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12361
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26597;&#35810;&#29305;&#23450;&#25991;&#31456;&#29983;&#25104;&#30340;&#26367;&#20195;&#26041;&#27861;&#65306;&#36890;&#36807;&#25972;&#21512;&#25991;&#26723;&#26816;&#32034;&#12289;&#26597;&#35810;&#29305;&#23450;&#32858;&#31867;&#21644;&#25688;&#35201;&#29983;&#25104;&#31995;&#32479;&#65292;&#21487;&#20197;&#25552;&#20379;&#23454;&#38469;&#24341;&#29992;&#20316;&#20026;&#29983;&#25104;&#25991;&#26412;&#30340;&#26469;&#28304;&#65292;&#30456;&#36739;&#20110;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#33021;&#22815;&#24471;&#21040;&#26356;&#20934;&#30830;&#30340;&#29983;&#25104;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#29305;&#23450;&#25991;&#31456;&#29983;&#25104;&#26159;&#32473;&#23450;&#19968;&#20010;&#25628;&#32034;&#26597;&#35810;&#65292;&#29983;&#25104;&#19968;&#20010;&#27010;&#36848;&#20027;&#39064;&#30340;&#21333;&#31687;&#25991;&#31456;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#23558;&#36825;&#26679;&#30340;&#25991;&#31456;&#35270;&#20026;&#21576;&#29616;&#25628;&#32034;&#32467;&#26524;&#25490;&#21517;&#30340;&#26367;&#20195;&#26041;&#24335;&#12290;&#23613;&#31649;&#20687;chatGPT&#36825;&#26679;&#30340;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20063;&#21487;&#20197;&#35299;&#20915;&#36825;&#19968;&#20219;&#21153;&#65292;&#20294;&#23427;&#20204;&#34987;&#35748;&#20026;&#20135;&#29983;&#26032;&#30340;&#20449;&#24687;&#65288;hallucinate&#65289;&#65292;&#20854;&#27169;&#22411;&#26159;&#20445;&#23494;&#30340;&#12289;&#38590;&#20197;&#20998;&#26512;&#21644;&#25511;&#21046;&#12290;&#19968;&#20123;&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#25903;&#25345;&#24615;&#21442;&#32771;&#25991;&#29486;&#65292;&#20294;&#36825;&#20123;&#25991;&#29486;&#24448;&#24448;&#19982;&#29983;&#25104;&#30340;&#20869;&#23481;&#26080;&#20851;&#12290;&#20316;&#20026;&#26367;&#20195;&#65292;&#25105;&#20204;&#25552;&#20986;&#30740;&#31350;&#23558;&#25991;&#26723;&#26816;&#32034;&#12289;&#26597;&#35810;&#29305;&#23450;&#32858;&#31867;&#21644;&#25688;&#35201;&#38598;&#25104;&#30340;&#25991;&#31456;&#29983;&#25104;&#31995;&#32479;&#12290;&#36890;&#36807;&#35774;&#35745;&#65292;&#36825;&#26679;&#30340;&#27169;&#22411;&#21487;&#20197;&#20026;&#20854;&#29983;&#25104;&#30340;&#25991;&#26412;&#25552;&#20379;&#23454;&#38469;&#24341;&#29992;&#20316;&#20026;&#26469;&#28304;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#35780;&#20272;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#23558;&#36825;&#19977;&#20010;&#32452;&#20214;&#21512;&#24182;&#20026;&#19968;&#20010;&#31995;&#32479;&#20043;&#21069;&#20998;&#21035;&#35757;&#32451;&#21644;&#35780;&#20272;&#27599;&#20010;&#32452;&#20214;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#26368;&#20339;&#34920;&#29616;&#30340;&#31995;&#32479;&#30001;&#26368;&#20339;&#30340;&#26597;&#35810;&#29305;&#23450;&#32858;&#31867;&#21644;&#25688;&#35201;&#32452;&#20214;&#32452;&#25104;&#65292;&#21487;&#20197;&#24471;&#21040;&#26356;&#22909;&#30340;&#29983;&#25104;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Query-specific article generation is the task of, given a search query, generate a single article that gives an overview of the topic. We envision such articles as an alternative to presenting a ranking of search results. While generative Large Language Models (LLMs) like chatGPT also address this task, they are known to hallucinate new information, their models are secret, hard to analyze and control. Some generative LLMs provide supporting references, yet these are often unrelated to the generated content. As an alternative, we propose to study article generation systems that integrate document retrieval, query-specific clustering, and summarization. By design, such models can provide actual citations as provenance for their generated text. In particular, we contribute an evaluation framework that allows to separately trains and evaluate each of these three components before combining them into one system. We experimentally demonstrate that a system comprised of the best-performing i
&lt;/p&gt;</description></item><item><title>KuaiSim&#26159;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#20010;&#32508;&#21512;&#27169;&#25311;&#22120;&#65292;&#25552;&#20379;&#20102;&#26356;&#30495;&#23454;&#30340;&#29992;&#25143;&#21453;&#39304;&#21644;&#22810;&#31181;&#34892;&#20026;&#21709;&#24212;&#12290;&#23427;&#33021;&#22815;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#22312;&#32447;&#37096;&#32626;&#21644;&#29983;&#25104;&#30495;&#23454;&#25968;&#25454;&#30340;&#25361;&#25112;&#65292;&#24182;&#25903;&#25345;&#19981;&#21516;&#23618;&#27425;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.12645</link><description>&lt;p&gt;
KuaiSim&#65306;&#19968;&#20010;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#32508;&#21512;&#27169;&#25311;&#22120;
&lt;/p&gt;
&lt;p&gt;
KuaiSim: A Comprehensive Simulator for Recommender Systems. (arXiv:2309.12645v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12645
&lt;/p&gt;
&lt;p&gt;
KuaiSim&#26159;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#20010;&#32508;&#21512;&#27169;&#25311;&#22120;&#65292;&#25552;&#20379;&#20102;&#26356;&#30495;&#23454;&#30340;&#29992;&#25143;&#21453;&#39304;&#21644;&#22810;&#31181;&#34892;&#20026;&#21709;&#24212;&#12290;&#23427;&#33021;&#22815;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#22312;&#32447;&#37096;&#32626;&#21644;&#29983;&#25104;&#30495;&#23454;&#25968;&#25454;&#30340;&#25361;&#25112;&#65292;&#24182;&#25903;&#25345;&#19981;&#21516;&#23618;&#27425;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#22240;&#20854;&#33021;&#22815;&#23398;&#20064;&#26368;&#20248;&#25512;&#33616;&#31574;&#30053;&#24182;&#26368;&#22823;&#21270;&#38271;&#26399;&#29992;&#25143;&#22238;&#25253;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#22312;&#22312;&#32447;&#29615;&#22659;&#20013;&#37096;&#32626;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#24182;&#36890;&#36807;A/B&#27979;&#35797;&#29983;&#25104;&#30495;&#23454;&#25968;&#25454;&#21487;&#33021;&#20250;&#38754;&#20020;&#25361;&#25112;&#24182;&#38656;&#35201;&#22823;&#37327;&#36164;&#28304;&#12290;&#27169;&#25311;&#22120;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#20026;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#25552;&#20379;&#35757;&#32451;&#21644;&#35780;&#20272;&#29615;&#22659;&#65292;&#20943;&#23569;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;&#29616;&#26377;&#30340;&#27169;&#25311;&#22120;&#24050;&#32463;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#20063;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#65292;&#22914;&#29992;&#25143;&#21453;&#39304;&#36807;&#20110;&#31616;&#21270;&#12289;&#32570;&#20047;&#19982;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#19968;&#33268;&#24615;&#12289;&#27169;&#25311;&#22120;&#35780;&#20272;&#30340;&#25361;&#25112;&#20197;&#21450;&#22312;&#19981;&#21516;&#25512;&#33616;&#31995;&#32479;&#20043;&#38388;&#30340;&#36801;&#31227;&#21644;&#25193;&#23637;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;KuaiSim&#65292;&#19968;&#20010;&#25552;&#20379;&#29992;&#25143;&#21453;&#39304;&#20855;&#26377;&#22810;&#34892;&#20026;&#21644;&#36328;&#20250;&#35805;&#21709;&#24212;&#30340;&#32508;&#21512;&#29992;&#25143;&#29615;&#22659;&#12290;&#25152;&#24471;&#21040;&#30340;&#27169;&#25311;&#22120;&#33021;&#22815;&#25903;&#25345;&#19977;&#20010;&#23618;&#27425;&#30340;&#25512;&#33616;&#38382;&#39064;&#65306;&#35831;&#27714;&#31561;&#32423;&#12289; &#29992;&#25143;&#24847;&#22270;&#39044;&#27979;&#12289; &#21644;&#24207;&#21015;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning (RL)-based recommender systems (RSs) have garnered considerable attention due to their ability to learn optimal recommendation policies and maximize long-term user rewards. However, deploying RL models directly in online environments and generating authentic data through A/B tests can pose challenges and require substantial resources. Simulators offer an alternative approach by providing training and evaluation environments for RS models, reducing reliance on real-world data. Existing simulators have shown promising results but also have limitations such as simplified user feedback, lacking consistency with real-world data, the challenge of simulator evaluation, and difficulties in migration and expansion across RSs. To address these challenges, we propose KuaiSim, a comprehensive user environment that provides user feedback with multi-behavior and cross-session responses. The resulting simulator can support three levels of recommendation problems: the request le
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#36807;&#28388;&#27873;&#38382;&#39064;&#65292;&#36890;&#36807;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#21644;&#27979;&#37327;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#26469;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#30340;&#24847;&#22806;&#24615;&#29289;&#21697;&#12290;</title><link>http://arxiv.org/abs/2308.06368</link><description>&lt;p&gt;
&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#21644;&#24847;&#22806;&#24615;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Topic-Level Bayesian Surprise and Serendipity for Recommender Systems. (arXiv:2308.06368v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#20027;&#39064;&#30340;&#36125;&#21494;&#26031;&#24778;&#21916;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#36807;&#28388;&#27873;&#38382;&#39064;&#65292;&#36890;&#36807;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#21644;&#27979;&#37327;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#26469;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#30340;&#24847;&#22806;&#24615;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20248;&#21270;&#20854;&#25512;&#33616;&#20165;&#36866;&#21512;&#29992;&#25143;&#23545;&#24050;&#28040;&#36153;&#29289;&#21697;&#30340;&#35780;&#32423;&#21382;&#21490;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#36807;&#28388;&#27873;&#65292;&#29992;&#25143;&#26080;&#27861;&#20174;&#26032;&#39062;&#12289;&#26410;&#35265;&#36807;&#30340;&#31867;&#21035;&#20013;&#20307;&#39564;&#29289;&#21697;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#24847;&#22806;&#24615;&#24418;&#24335;&#65292;&#20197;&#36125;&#21494;&#26031;&#24778;&#21916;&#20026;&#22522;&#30784;&#65292;&#29992;&#20110;&#27979;&#37327;&#29992;&#25143;&#28040;&#36153;&#24182;&#35780;&#32423;&#21518;&#29289;&#21697;&#30340;&#24847;&#22806;&#24615;&#12290;&#32467;&#21512;&#35782;&#21035;&#30456;&#20284;&#29992;&#25143;&#30340;&#21327;&#21516;&#36807;&#28388;&#32452;&#20214;&#65292;&#21487;&#20197;&#25512;&#33616;&#20855;&#26377;&#39640;&#28508;&#21147;&#24847;&#22806;&#24615;&#30340;&#29289;&#21697;&#12290;&#20026;&#20102;&#20415;&#20110;&#35780;&#20272;&#20027;&#39064;&#32423;&#21035;&#30340;&#24778;&#21916;&#21644;&#24847;&#22806;&#24615;&#27169;&#22411;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#20174;Goodreads&#20013;&#25552;&#21462;&#30340;&#22270;&#20070;&#38405;&#35835;&#21382;&#21490;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#36229;&#36807;26&#21315;&#20010;&#29992;&#25143;&#21644;&#36817;130&#19975;&#26412;&#20070;&#65292;&#24182;&#23545;&#20854;&#20013;&#30340;449&#31687;&#20070;&#36827;&#34892;&#20102;&#25163;&#21160;&#27880;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 
&lt;/p&gt;</description></item><item><title>Amazon-M2&#26159;&#19968;&#20010;&#22810;&#35821;&#35328;&#22810;&#21306;&#22495;&#36141;&#29289;&#20250;&#35805;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#22686;&#24378;&#20010;&#24615;&#21270;&#25512;&#33616;&#21644;&#29702;&#35299;&#29992;&#25143;&#20559;&#22909;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.09688</link><description>&lt;p&gt;
Amazon-M2: &#19968;&#20010;&#29992;&#20110;&#25512;&#33616;&#21644;&#25991;&#26412;&#29983;&#25104;&#30340;&#22810;&#35821;&#35328;&#22810;&#21306;&#22495;&#36141;&#29289;&#20250;&#35805;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation. (arXiv:2307.09688v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09688
&lt;/p&gt;
&lt;p&gt;
Amazon-M2&#26159;&#19968;&#20010;&#22810;&#35821;&#35328;&#22810;&#21306;&#22495;&#36141;&#29289;&#20250;&#35805;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#22686;&#24378;&#20010;&#24615;&#21270;&#25512;&#33616;&#21644;&#29702;&#35299;&#29992;&#25143;&#20559;&#22909;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#30005;&#23376;&#21830;&#21153;&#26469;&#35828;&#65292;&#24314;&#27169;&#23458;&#25143;&#36141;&#29289;&#24847;&#22270;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#23427;&#30452;&#25509;&#24433;&#21709;&#29992;&#25143;&#20307;&#39564;&#21644;&#21442;&#19982;&#24230;&#12290;&#22240;&#27492;&#65292;&#20934;&#30830;&#29702;&#35299;&#23458;&#25143;&#30340;&#20559;&#22909;&#23545;&#20110;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#33267;&#20851;&#37325;&#35201;&#12290;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#25216;&#26415;&#21033;&#29992;&#23458;&#25143;&#20250;&#35805;&#25968;&#25454;&#26469;&#39044;&#27979;&#20182;&#20204;&#30340;&#19979;&#19968;&#27425;&#20114;&#21160;&#65292;&#24050;&#32463;&#36234;&#26469;&#36234;&#21463;&#21040;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20250;&#35805;&#25968;&#25454;&#38598;&#22312;&#39033;&#30446;&#23646;&#24615;&#12289;&#29992;&#25143;&#22810;&#26679;&#24615;&#21644;&#25968;&#25454;&#38598;&#35268;&#27169;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#19981;&#33021;&#20840;&#38754;&#22320;&#25429;&#25417;&#29992;&#25143;&#34892;&#20026;&#21644;&#20559;&#22909;&#30340;&#35889;&#31995;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Amazon Multilingual Multi-locale Shopping Session Dataset&#65292;&#21363;Amazon-M2&#12290;&#23427;&#26159;&#31532;&#19968;&#20010;&#30001;&#26469;&#33258;&#20845;&#20010;&#19981;&#21516;&#21306;&#22495;&#30340;&#25968;&#30334;&#19975;&#29992;&#25143;&#20250;&#35805;&#32452;&#25104;&#30340;&#22810;&#35821;&#35328;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#20135;&#21697;&#30340;&#20027;&#35201;&#35821;&#35328;&#26159;&#33521;&#35821;&#12289;&#24503;&#35821;&#12289;&#26085;&#35821;&#12289;&#27861;&#35821;&#12289;&#24847;&#22823;&#21033;&#35821;&#21644;&#35199;&#29677;&#29273;&#35821;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#22686;&#24378;&#20010;&#24615;&#21270;&#21644;&#29702;&#35299;&#29992;&#25143;&#20559;&#22909;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, w
&lt;/p&gt;</description></item><item><title>AdANNS&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#35821;&#20041;&#25628;&#32034;&#26694;&#26550;&#65292;&#21033;&#29992;&#19981;&#21516;&#23481;&#37327;&#30340;&#33258;&#36866;&#24212;&#34920;&#31034;&#24418;&#24335;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#65292;&#30456;&#20284;&#24230;&#35745;&#31639;&#36234;&#25509;&#36817;&#30340;&#25968;&#25454;&#28857;&#23558;&#20351;&#29992;&#26356;&#20302;&#23481;&#37327;&#30340;&#34920;&#31034;&#24418;&#24335;&#36827;&#34892;&#35745;&#31639;&#65292;&#28436;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.19435</link><description>&lt;p&gt;
AdANNS: &#19968;&#31181;&#33258;&#36866;&#24212;&#35821;&#20041;&#25628;&#32034;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
AdANNS: A Framework for Adaptive Semantic Search. (arXiv:2305.19435v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19435
&lt;/p&gt;
&lt;p&gt;
AdANNS&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#35821;&#20041;&#25628;&#32034;&#26694;&#26550;&#65292;&#21033;&#29992;&#19981;&#21516;&#23481;&#37327;&#30340;&#33258;&#36866;&#24212;&#34920;&#31034;&#24418;&#24335;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#65292;&#30456;&#20284;&#24230;&#35745;&#31639;&#36234;&#25509;&#36817;&#30340;&#25968;&#25454;&#28857;&#23558;&#20351;&#29992;&#26356;&#20302;&#23481;&#37327;&#30340;&#34920;&#31034;&#24418;&#24335;&#36827;&#34892;&#35745;&#31639;&#65292;&#28436;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#35268;&#27169;&#30340;&#25628;&#32034;&#31995;&#32479;&#23398;&#20064;&#19968;&#20010;&#32534;&#30721;&#22120;&#26469;&#23884;&#20837;&#19968;&#20010;&#32473;&#23450;&#30340;&#26597;&#35810;&#65292;&#28982;&#21518;&#23558;&#20854;&#36830;&#25509;&#21040;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;(ANNS)&#31649;&#36947;&#20013;&#26469;&#26816;&#32034;&#30456;&#20284;&#30340;&#25968;&#25454;&#28857;&#12290;&#20026;&#20102;&#20934;&#30830;&#22320;&#25429;&#25417;&#23614;&#37096;&#26597;&#35810;&#21644;&#25968;&#25454;&#28857;&#65292;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#36890;&#24120;&#26159;&#21018;&#24615;&#30340;&#12289;&#39640;&#32500;&#30340;&#21521;&#37327;&#65292;&#36890;&#24120;&#22312;&#25972;&#20010;ANNS&#31649;&#36947;&#20013;&#19968;&#25104;&#19981;&#21464;&#65292;&#24182;&#19988;&#21487;&#33021;&#23548;&#33268;&#35745;&#31639;&#19978;&#26114;&#36149;&#30340;&#26816;&#32034;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#19982;&#20854;&#20351;&#29992;&#21018;&#24615;&#30340;&#34920;&#31034;&#24418;&#24335;&#65292;ANNS&#30340;&#19981;&#21516;&#38454;&#27573;&#21487;&#20197;&#21033;&#29992;&#19981;&#21516;&#23481;&#37327;&#30340;&#33258;&#36866;&#24212;&#34920;&#31034;&#24418;&#24335;&#20197;&#33719;&#24471;&#26174;&#33879;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#65292;&#21363;&#21487;&#20197;&#36827;&#34892;&#26356;&#21152;&#36817;&#20284;&#35745;&#31639;&#30340;ANNS&#38454;&#27573;&#24212;&#35813;&#20351;&#29992;&#30456;&#21516;&#25968;&#25454;&#28857;&#30340;&#20302;&#23481;&#37327;&#34920;&#31034;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;AdANNS&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;ANNS&#35774;&#35745;&#26694;&#26550;&#65292;&#26126;&#30830;&#21033;&#29992;Matryoshka&#34920;&#31034;&#30340;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;AdANNS&#30340;&#26032;&#22411;&#20851;&#38190;ANNS&#26500;&#24314;&#28436;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;-&#35745;&#31639;&#25240;&#34935;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Web-scale search systems learn an encoder to embed a given query which is then hooked into an approximate nearest neighbor search (ANNS) pipeline to retrieve similar data points. To accurately capture tail queries and data points, learned representations typically are rigid, high-dimensional vectors that are generally used as-is in the entire ANNS pipeline and can lead to computationally expensive retrieval. In this paper, we argue that instead of rigid representations, different stages of ANNS can leverage adaptive representations of varying capacities to achieve significantly better accuracy-compute trade-offs, i.e., stages of ANNS that can get away with more approximate computation should use a lower-capacity representation of the same data point. To this end, we introduce AdANNS, a novel ANNS design framework that explicitly leverages the flexibility of Matryoshka Representations. We demonstrate state-of-the-art accuracy-compute trade-offs using novel AdANNS-based key ANNS building
&lt;/p&gt;</description></item><item><title>PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.06674</link><description>&lt;p&gt;
PK-ICR: &#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#36827;&#34892;&#22522;&#20110;&#22330;&#26223;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue. (arXiv:2302.06674v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06674
&lt;/p&gt;
&lt;p&gt;
PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#21035;&#19982;&#23545;&#35805;&#31995;&#32479;&#30456;&#20851;&#30340;&#35282;&#33394;&#21644;&#30693;&#35782;&#23545;&#20110;&#22522;&#20110;&#22330;&#26223;&#30340;&#23545;&#35805;&#24212;&#31572;&#29983;&#25104;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#27599;&#20010;&#23545;&#35805;&#22522;&#26412;&#19978;&#37117;&#26159;&#23396;&#31435;&#30740;&#31350;&#30340;&#65292;&#32780;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#24341;&#20837;&#20102;&#26356;&#23454;&#38469;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20219;&#21153;&#12290;&#25105;&#20204;&#23558;&#35282;&#33394;&#21644;&#30693;&#35782;&#21452;&#19978;&#19979;&#25991;&#35782;&#21035;&#23450;&#20041;&#20026;&#20026;&#32473;&#23450;&#30340;&#23545;&#35805;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20219;&#21153;&#65292;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#35774;&#32622;&#20013;&#21487;&#33021;&#20855;&#26377;&#25552;&#21319;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26816;&#32034;&#30340;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#21033;&#29992;&#23545;&#35805;&#30340;&#25152;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#34913;&#37327;&#19982;&#25968;&#25454;&#22686;&#24378;&#30456;&#20851;&#30340;&#35821;&#20041;&#24046;&#24322;&#26679;&#26412;&#65288;&#21363;&#22256;&#38590;&#36127;&#26679;&#26412;&#65289;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying relevant persona or knowledge for conversational systems is critical to grounded dialogue response generation. However, each grounding has been mostly researched in isolation with more practical multi-context dialogue tasks introduced in recent works. We define Persona and Knowledge Dual Context Identification as the task to identify persona and knowledge jointly for a given dialogue, which could be of elevated importance in complex multi-context dialogue settings. We develop a novel grounding retrieval method that utilizes all contexts of dialogue simultaneously. Our method requires less computational power via utilizing neural QA retrieval models. We further introduce our novel null-positive rank test which measures ranking performance on semantically dissimilar samples (i.e. hard negatives) in relation to data augmentation.
&lt;/p&gt;</description></item></channel></rss>