<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;UniLLMRec&#23558;&#22810;&#38454;&#27573;&#20219;&#21153;&#25972;&#21512;&#20026;&#31471;&#21040;&#31471;&#25512;&#33616;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#23545;&#22823;&#35268;&#27169;&#29289;&#21697;&#38598;&#21512;&#30340;&#25361;&#25112;</title><link>https://arxiv.org/abs/2404.00702</link><description>&lt;p&gt;
&#21388;&#20518;&#20102;&#25554;&#20214;&#65311;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25104;&#20026;&#31471;&#21040;&#31471;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Tired of Plugins? Large Language Models Can Be End-To-End Recommenders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00702
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;UniLLMRec&#23558;&#22810;&#38454;&#27573;&#20219;&#21153;&#25972;&#21512;&#20026;&#31471;&#21040;&#31471;&#25512;&#33616;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#23545;&#22823;&#35268;&#27169;&#29289;&#21697;&#38598;&#21512;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#22522;&#20110;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#39044;&#27979;&#29992;&#25143;&#20852;&#36259;&#12290;&#23427;&#20204;&#20027;&#35201;&#35774;&#35745;&#20026;&#39034;&#24207;&#27969;&#27700;&#32447;&#65292;&#38656;&#35201;&#22823;&#37327;&#25968;&#25454;&#26469;&#35757;&#32451;&#19981;&#21516;&#23376;&#31995;&#32479;&#65292;&#24182;&#19988;&#38590;&#20197;&#25193;&#23637;&#21040;&#26032;&#22495;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#36890;&#29992;&#33021;&#21147;&#65292;&#20351;&#19968;&#20010;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#21508;&#31181;&#22330;&#26223;&#20013;&#30340;&#22810;&#26679;&#21270;&#25512;&#33616;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#32431;&#31929;&#21033;&#29992;LLM&#26469;&#22788;&#29702;&#25512;&#33616;&#27969;&#27700;&#32447;&#30340;&#21333;&#20010;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#31995;&#32479;&#38754;&#20020;&#30528;&#20197;&#33258;&#28982;&#35821;&#35328;&#26684;&#24335;&#21521;LLM&#21576;&#29616;&#22823;&#35268;&#27169;&#29289;&#21697;&#38598;&#21512;&#30340;&#25361;&#25112;&#65292;&#30001;&#20110;&#36755;&#20837;&#38271;&#24230;&#30340;&#38480;&#21046;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#31471;&#21040;&#31471;&#25512;&#33616;&#26694;&#26550;&#65306;UniLLMRec&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;UniLLMRec&#36890;&#36807;&#25512;&#33616;&#38142;&#38598;&#25104;&#22810;&#38454;&#27573;&#20219;&#21153;&#65288;&#20363;&#22914;&#21484;&#22238;&#12289;&#25490;&#24207;&#12289;&#37325;&#26032;&#25490;&#24207;&#65289;&#12290;&#20026;&#20102;&#22788;&#29702;&#22823;&#35268;&#27169;&#29289;&#21697;&#65292;&#25105;&#20204;&#25552;&#20986;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00702v1 Announce Type: new  Abstract: Recommender systems aim to predict user interest based on historical behavioral data. They are mainly designed in sequential pipelines, requiring lots of data to train different sub-systems, and are hard to scale to new domains. Recently, Large Language Models (LLMs) have demonstrated remarkable generalized capabilities, enabling a singular model to tackle diverse recommendation tasks across various scenarios. Nonetheless, existing LLM-based recommendation systems utilize LLM purely for a single task of the recommendation pipeline. Besides, these systems face challenges in presenting large-scale item sets to LLMs in natural language format, due to the constraint of input length. To address these challenges, we introduce an LLM-based end-to-end recommendation framework: UniLLMRec. Specifically, UniLLMRec integrates multi-stage tasks (e.g. recall, ranking, re-ranking) via chain-of-recommendations. To deal with large-scale items, we propose
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#24182;&#23450;&#20041;&#20102;&#21487;&#25512;&#33616;&#24615;&#35782;&#21035;&#38382;&#39064;&#65292;&#19987;&#27880;&#20110;&#22312;&#24403;&#21069;&#23545;&#35805;&#29615;&#22659;&#20013;&#25506;&#35752;&#26159;&#21542;&#38656;&#35201;&#25512;&#33616;&#65292;&#20197;&#20943;&#23569;&#29992;&#25143;&#24178;&#25200;&#12290;</title><link>https://arxiv.org/abs/2403.18628</link><description>&lt;p&gt;
&#26159;&#21542;&#25512;&#33616;&#65306;&#22312;&#19982;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#35805;&#20013;&#35782;&#21035;&#21487;&#25512;&#33616;&#24615;
&lt;/p&gt;
&lt;p&gt;
To Recommend or Not: Recommendability Identification in Conversations with Pre-trained Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18628
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#24182;&#23450;&#20041;&#20102;&#21487;&#25512;&#33616;&#24615;&#35782;&#21035;&#38382;&#39064;&#65292;&#19987;&#27880;&#20110;&#22312;&#24403;&#21069;&#23545;&#35805;&#29615;&#22659;&#20013;&#25506;&#35752;&#26159;&#21542;&#38656;&#35201;&#25512;&#33616;&#65292;&#20197;&#20943;&#23569;&#29992;&#25143;&#24178;&#25200;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#25512;&#33616;&#31995;&#32479;&#20027;&#35201;&#20851;&#27880;&#20110;&#25512;&#33616;&#20160;&#20040;&#65292;&#20551;&#35774;&#29992;&#25143;&#24635;&#26159;&#38656;&#35201;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;ChatGPT&#21644;&#20854;&#20182;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#24191;&#27867;&#20256;&#25773;&#65292;&#22312;&#23545;&#35805;&#31995;&#32479;&#30340;&#32972;&#26223;&#19979;&#26356;&#20851;&#38190;&#30340;&#38382;&#39064;&#26159;&#22312;&#20026;&#29992;&#25143;&#25552;&#20379;&#25512;&#33616;&#26381;&#21153;&#26102;&#22914;&#20309;&#26368;&#23567;&#21270;&#29992;&#25143;&#30340;&#24178;&#25200;&#12290;&#25105;&#20204;&#27491;&#24335;&#23450;&#20041;&#20102;&#21487;&#25512;&#33616;&#24615;&#35782;&#21035;&#38382;&#39064;&#65292;&#26088;&#22312;&#30830;&#23450;&#22312;&#29305;&#23450;&#22330;&#26223;&#20013;&#26159;&#21542;&#38656;&#35201;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18628v1 Announce Type: new  Abstract: Most current recommender systems primarily focus on what to recommend, assuming users always require personalized recommendations. However, with the widely spread of ChatGPT and other chatbots, a more crucial problem in the context of conversational systems is how to minimize user disruption when we provide recommendation services for users. While previous research has extensively explored different user intents in dialogue systems, fewer efforts are made to investigate whether recommendations should be provided. In this paper, we formally define the recommendability identification problem, which aims to determine whether recommendations are necessary in a specific scenario. First, we propose and define the recommendability identification task, which investigates the need for recommendations in the current conversational context. A new dataset is constructed. Subsequently, we discuss and evaluate the feasibility of leveraging pre-trained
&lt;/p&gt;</description></item><item><title>Mamba&#27169;&#22411;&#22522;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#22312;&#22810;&#20010;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#19982;Transformer&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#32463;&#20856;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;--&#25991;&#26723;&#25490;&#21517;&#20013;&#23637;&#29616;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.18276</link><description>&lt;p&gt;
RankMamba&#65292;&#22312;Transformer&#26102;&#20195;&#23545;Mamba&#25991;&#26723;&#25490;&#21517;&#24615;&#33021;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
RankMamba, Benchmarking Mamba's Document Ranking Performance in the Era of Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18276
&lt;/p&gt;
&lt;p&gt;
Mamba&#27169;&#22411;&#22522;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#22312;&#22810;&#20010;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#19982;Transformer&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#32463;&#20856;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;--&#25991;&#26723;&#25490;&#21517;&#20013;&#23637;&#29616;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#32467;&#26500;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#65288;CV&#65289;&#21644;&#20449;&#24687;&#26816;&#32034;(IR)&#31561;&#22810;&#20010;&#24212;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;Transformer&#26550;&#26500;&#30340;&#26680;&#24515;&#26426;&#21046;--&#27880;&#24847;&#21147;&#65292;&#22312;&#35757;&#32451;&#20013;&#38656;&#35201;$O(n^2)$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#22312;&#25512;&#26029;&#20013;&#38656;&#35201;$O(n)$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#35768;&#22810;&#24037;&#20316;&#24050;&#32463;&#25552;&#20986;&#25913;&#36827;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#27604;&#22914;Flash Attention&#21644;Multi-query Attention&#12290;&#21478;&#19968;&#26041;&#38754;&#30340;&#24037;&#20316;&#26088;&#22312;&#35774;&#35745;&#26032;&#30340;&#26426;&#21046;&#26469;&#21462;&#20195;&#27880;&#24847;&#21147;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#19968;&#20010;&#26174;&#33879;&#27169;&#22411;&#32467;&#26500;--Mamba&#65292;&#22312;&#22810;&#20010;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#19982;Transformer&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18276v1 Announce Type: cross  Abstract: Transformer structure has achieved great success in multiple applied machine learning communities, such as natural language processing (NLP), computer vision (CV) and information retrieval (IR). Transformer architecture's core mechanism -- attention requires $O(n^2)$ time complexity in training and $O(n)$ time complexity in inference. Many works have been proposed to improve the attention mechanism's scalability, such as Flash Attention and Multi-query Attention. A different line of work aims to design new mechanisms to replace attention. Recently, a notable model structure -- Mamba, which is based on state space models, has achieved transformer-equivalent performance in multiple sequence modeling tasks.   In this work, we examine \mamba's efficacy through the lens of a classical IR task -- document ranking. A reranker model takes a query and a document as input, and predicts a scalar relevance score. This task demands the language mod
&lt;/p&gt;</description></item><item><title>&#33258;&#21160;&#24191;&#21578;&#31454;&#26631;&#20013;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#20256;&#32479;RL&#31639;&#27861;&#22312;&#22312;&#32447;&#29615;&#22659;&#19979;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.15102</link><description>&lt;p&gt;
&#36712;&#36857;&#24335;&#36845;&#20195;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#33258;&#21160;&#31454;&#26631;
&lt;/p&gt;
&lt;p&gt;
Trajectory-wise Iterative Reinforcement Learning Framework for Auto-bidding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15102
&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#24191;&#21578;&#31454;&#26631;&#20013;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#20256;&#32479;RL&#31639;&#27861;&#22312;&#22312;&#32447;&#29615;&#22659;&#19979;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#24191;&#21578;&#20013;&#65292;&#24191;&#21578;&#20027;&#21442;&#19982;&#24191;&#21578;&#31454;&#25293;&#20197;&#33719;&#21462;&#24191;&#21578;&#26426;&#20250;&#65292;&#36890;&#24120;&#26159;&#36890;&#36807;&#38656;&#27714;&#26041;&#24179;&#21488;(DSPs)&#25552;&#20379;&#30340;&#33258;&#21160;&#31454;&#26631;&#24037;&#20855;&#12290;&#30446;&#21069;&#30340;&#33258;&#21160;&#31454;&#26631;&#31639;&#27861;&#36890;&#24120;&#37319;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23433;&#20840;&#24615;&#38382;&#39064;&#65292;&#22823;&#22810;&#25968;&#22522;&#20110;RL&#30340;&#33258;&#21160;&#31454;&#26631;&#31574;&#30053;&#26159;&#22312;&#27169;&#25311;&#29615;&#22659;&#20013;&#36827;&#34892;&#35757;&#32451;&#30340;&#65292;&#22312;&#22312;&#32447;&#29615;&#22659;&#20013;&#37096;&#32626;&#20250;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;&#20026;&#20102;&#32553;&#23567;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#21487;&#20197;&#24182;&#34892;&#37096;&#32626;&#22810;&#20010;&#33258;&#21160;&#31454;&#26631;&#20195;&#29702;&#20197;&#25910;&#38598;&#22823;&#37327;&#20132;&#20114;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#21487;&#20197;&#21033;&#29992;&#31163;&#32447;RL&#31639;&#27861;&#35757;&#32451;&#26032;&#31574;&#30053;&#12290;&#35757;&#32451;&#21518;&#30340;&#31574;&#30053;&#38543;&#21518;&#21487;&#20197;&#37096;&#32626;&#20197;&#36827;&#34892;&#36827;&#19968;&#27493;&#30340;&#25968;&#25454;&#25910;&#38598;&#65292;&#20174;&#32780;&#24418;&#25104;&#19968;&#20010;&#36845;&#20195;&#35757;&#32451;&#26694;&#26550;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#36845;&#20195;&#31163;&#32447;RL&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#36825;&#31181;&#36845;&#20195;&#31163;&#32447;RL&#26694;&#26550;&#30340;&#24615;&#33021;&#29942;&#39048;&#65292;&#20854;&#26681;&#28304;&#22312;&#20110;&#30001;&#20110;&#20869;&#22312;&#21407;&#22240;&#32780;&#23548;&#33268;&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#20302;&#25928;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15102v1 Announce Type: cross  Abstract: In online advertising, advertisers participate in ad auctions to acquire ad opportunities, often by utilizing auto-bidding tools provided by demand-side platforms (DSPs). The current auto-bidding algorithms typically employ reinforcement learning (RL). However, due to safety concerns, most RL-based auto-bidding policies are trained in simulation, leading to a performance degradation when deployed in online environments. To narrow this gap, we can deploy multiple auto-bidding agents in parallel to collect a large interaction dataset. Offline RL algorithms can then be utilized to train a new policy. The trained policy can subsequently be deployed for further data collection, resulting in an iterative training framework, which we refer to as iterative offline RL. In this work, we identify the performance bottleneck of this iterative offline RL framework, which originates from the ineffective exploration and exploitation caused by the inhe
&lt;/p&gt;</description></item><item><title>&#21457;&#24067;&#20102;IEPile&#65292;&#19968;&#20010;&#21253;&#21547;&#32422;0.32B&#20010;&#26631;&#35760;&#30340;&#32508;&#21512;&#21452;&#35821;IE&#25351;&#20196;&#35821;&#26009;&#24211;&#65292;&#36890;&#36807;&#25910;&#38598;&#21644;&#28165;&#29702;33&#20010;&#29616;&#26377;IE&#25968;&#25454;&#38598;&#24182;&#24341;&#20837;&#22522;&#20110;&#27169;&#24335;&#30340;&#25351;&#20196;&#29983;&#25104;&#65292;&#21487;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20449;&#24687;&#25277;&#21462;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#23588;&#20854;&#26159;&#38646;&#26679;&#26412;&#27867;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.14710</link><description>&lt;p&gt;
IEPile: &#25366;&#25496;&#22823;&#35268;&#27169;&#22522;&#20110;&#27169;&#24335;&#30340;&#20449;&#24687;&#25277;&#21462;&#35821;&#26009;&#24211;
&lt;/p&gt;
&lt;p&gt;
IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14710
&lt;/p&gt;
&lt;p&gt;
&#21457;&#24067;&#20102;IEPile&#65292;&#19968;&#20010;&#21253;&#21547;&#32422;0.32B&#20010;&#26631;&#35760;&#30340;&#32508;&#21512;&#21452;&#35821;IE&#25351;&#20196;&#35821;&#26009;&#24211;&#65292;&#36890;&#36807;&#25910;&#38598;&#21644;&#28165;&#29702;33&#20010;&#29616;&#26377;IE&#25968;&#25454;&#38598;&#24182;&#24341;&#20837;&#22522;&#20110;&#27169;&#24335;&#30340;&#25351;&#20196;&#29983;&#25104;&#65292;&#21487;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20449;&#24687;&#25277;&#21462;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#23588;&#20854;&#26159;&#38646;&#26679;&#26412;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#23637;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#28508;&#21147;&#65307;&#28982;&#32780;&#65292;&#22312;&#20449;&#24687;&#25277;&#21462;&#65288;IE&#65289;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#25968;&#25454;&#26159;&#25552;&#21319;LLMs&#29305;&#23450;&#33021;&#21147;&#30340;&#20851;&#38190;&#65292;&#32780;&#24403;&#21069;&#30340;IE&#25968;&#25454;&#38598;&#24448;&#24448;&#35268;&#27169;&#36739;&#23567;&#12289;&#20998;&#25955;&#19988;&#32570;&#20047;&#26631;&#20934;&#21270;&#30340;&#27169;&#24335;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;IEPile&#65292;&#19968;&#20010;&#32508;&#21512;&#30340;&#21452;&#35821;&#65288;&#33521;&#25991;&#21644;&#20013;&#25991;&#65289;IE&#25351;&#20196;&#35821;&#26009;&#24211;&#65292;&#21253;&#21547;&#32422;0.32B&#20010;&#26631;&#35760;&#12290;&#25105;&#20204;&#36890;&#36807;&#25910;&#38598;&#21644;&#28165;&#29702;33&#20010;&#29616;&#26377;IE&#25968;&#25454;&#38598;&#26500;&#24314;IEPile&#65292;&#24182;&#24341;&#20837;&#22522;&#20110;&#27169;&#24335;&#30340;&#25351;&#20196;&#29983;&#25104;&#26469;&#25366;&#25496;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#12290;&#22312;LLaMA&#21644;Baichuan&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;IEPile&#21487;&#20197;&#25552;&#39640;LLMs&#22312;IE&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#23588;&#20854;&#26159;&#38646;&#26679;&#26412;&#27867;&#21270;&#12290;&#25105;&#20204;&#24320;&#28304;&#20102;&#36164;&#28304;&#21644;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#24076;&#26395;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31038;&#21306;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14710v1 Announce Type: cross  Abstract: Large Language Models (LLMs) demonstrate remarkable potential across various domains; however, they exhibit a significant performance gap in Information Extraction (IE). Note that high-quality instruction data is the vital key for enhancing the specific capabilities of LLMs, while current IE datasets tend to be small in scale, fragmented, and lack standardized schema. To this end, we introduce IEPile, a comprehensive bilingual (English and Chinese) IE instruction corpus, which contains approximately 0.32B tokens. We construct IEPile by collecting and cleaning 33 existing IE datasets, and introduce schema-based instruction generation to unearth a large-scale corpus. Experimental results on LLaMA and Baichuan demonstrate that using IEPile can enhance the performance of LLMs for IE, especially the zero-shot generalization. We open-source the resource and pre-trained models, hoping to provide valuable support to the NLP community.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#19981;&#21516;&#30340;&#26816;&#32034;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#26041;&#27861;&#26469;&#22686;&#24378;&#31572;&#26696;&#29983;&#25104;&#65292;&#24182;&#21457;&#29616;&#24120;&#29992;&#30340;&#36830;&#25509;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22235;&#31181;&#26367;&#20195;&#31574;&#30053;&#65292;&#21253;&#25324;&#20004;&#31181;&#21333;&#36718;&#26041;&#27861;&#21644;&#20004;&#31181;&#22810;&#36718;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2308.12574</link><description>&lt;p&gt;
&#25506;&#32034;&#26816;&#32034;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25972;&#21512;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Exploring the Integration Strategies of Retriever and Large Language Models. (arXiv:2308.12574v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#19981;&#21516;&#30340;&#26816;&#32034;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#26041;&#27861;&#26469;&#22686;&#24378;&#31572;&#26696;&#29983;&#25104;&#65292;&#24182;&#21457;&#29616;&#24120;&#29992;&#30340;&#36830;&#25509;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22235;&#31181;&#26367;&#20195;&#31574;&#30053;&#65292;&#21253;&#25324;&#20004;&#31181;&#21333;&#36718;&#26041;&#27861;&#21644;&#20004;&#31181;&#22810;&#36718;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;ChatGPT&#65289;&#30340;&#25972;&#21512;&#20026;&#25552;&#39640;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#20316;&#20986;&#20102;&#26174;&#33879;&#36129;&#29486;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#23558;&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#34701;&#20837;&#31572;&#26696;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#26368;&#20339;&#26041;&#27861;&#20173;&#28982;&#32570;&#20047;&#25506;&#32034;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#30740;&#31350;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#32467;&#21512;&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#22686;&#24378;&#31572;&#26696;&#29983;&#25104;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#24120;&#29992;&#30340;&#36830;&#25509;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21363;&#20351;&#27491;&#30830;&#30340;&#25991;&#26723;&#22312;&#21069;k&#20010;&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#20013;&#65292;&#36825;&#31181;&#26041;&#27861;&#32463;&#24120;&#20250;&#29983;&#25104;&#8220;&#26410;&#30693;&#8221;&#36755;&#20986;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22235;&#31181;&#23558;&#26816;&#32034;&#21040;&#30340;&#27573;&#33853;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25972;&#21512;&#30340;&#26367;&#20195;&#31574;&#30053;&#12290;&#36825;&#20123;&#31574;&#30053;&#21253;&#25324;&#20004;&#31181;&#21033;&#29992;&#24605;&#32500;&#38142;&#25512;&#29702;&#30340;&#21333;&#36718;&#26041;&#27861;&#21644;&#20004;&#31181;&#21033;&#29992;&#21453;&#39304;&#24490;&#29615;&#30340;&#22810;&#36718;&#31574;&#30053;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#20998;&#26512;&#21644;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;...
&lt;/p&gt;
&lt;p&gt;
The integration of retrieved passages and large language models (LLMs), such as ChatGPTs, has significantly contributed to improving open-domain question answering. However, there is still a lack of exploration regarding the optimal approach for incorporating retrieved passages into the answer generation process. This paper aims to fill this gap by investigating different methods of combining retrieved passages with LLMs to enhance answer generation. We begin by examining the limitations of a commonly-used concatenation approach. Surprisingly, this approach often results in generating "unknown" outputs, even when the correct document is among the top-k retrieved passages. To address this issue, we explore four alternative strategies for integrating the retrieved passages with the LLMs. These strategies include two single-round methods that utilize chain-of-thought reasoning and two multi-round strategies that incorporate feedback loops. Through comprehensive analyses and experiments, w
&lt;/p&gt;</description></item></channel></rss>