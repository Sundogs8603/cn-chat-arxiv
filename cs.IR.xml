<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#24341;&#20837;&#29983;&#25104;&#24335;&#26381;&#35013;&#25512;&#33616;&#20219;&#21153;&#65288;GOR&#65289;&#65292;&#26088;&#22312;&#21512;&#25104;&#19968;&#32452;&#26102;&#23578;&#22270;&#29255;&#24182;&#32452;&#35013;&#25104;&#35270;&#35273;&#21644;&#35856;&#30340;&#12289;&#23450;&#21046;&#32473;&#20010;&#20154;&#29992;&#25143;&#30340;&#26381;&#35013;&#12290;</title><link>https://arxiv.org/abs/2402.17279</link><description>&lt;p&gt;
DiFashion: &#36808;&#21521;&#20010;&#24615;&#21270;&#26381;&#35013;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
DiFashion: Towards Personalized Outfit Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17279
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#29983;&#25104;&#24335;&#26381;&#35013;&#25512;&#33616;&#20219;&#21153;&#65288;GOR&#65289;&#65292;&#26088;&#22312;&#21512;&#25104;&#19968;&#32452;&#26102;&#23578;&#22270;&#29255;&#24182;&#32452;&#35013;&#25104;&#35270;&#35273;&#21644;&#35856;&#30340;&#12289;&#23450;&#21046;&#32473;&#20010;&#20154;&#29992;&#25143;&#30340;&#26381;&#35013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26381;&#35013;&#25512;&#33616;&#65288;OR&#65289;&#22312;&#26102;&#23578;&#39046;&#22495;&#30340;&#21457;&#23637;&#32463;&#21382;&#20102;&#20004;&#20010;&#19981;&#21516;&#38454;&#27573;&#65306;&#39044;&#23450;&#20041;&#30340;&#26381;&#35013;&#25512;&#33616;&#21644;&#20010;&#24615;&#21270;&#30340;&#26381;&#35013;&#32452;&#21512;&#12290;&#34429;&#28982;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#20004;&#20010;&#38454;&#27573;&#37117;&#38754;&#20020;&#29616;&#26377;&#26102;&#23578;&#20135;&#21697;&#24102;&#26469;&#30340;&#38480;&#21046;&#65292;&#38459;&#30861;&#20102;&#23427;&#20204;&#28385;&#36275;&#29992;&#25143;&#22810;&#26679;&#21270;&#26102;&#23578;&#38656;&#27714;&#30340;&#26377;&#25928;&#24615;&#12290;AI&#29983;&#25104;&#20869;&#23481;&#30340;&#20986;&#29616;&#20026;OR&#20811;&#26381;&#36825;&#20123;&#32422;&#26463;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#23637;&#31034;&#20102;&#20010;&#24615;&#21270;&#26381;&#35013;&#29983;&#25104;&#30340;&#28508;&#21147;&#12290;&#20026;&#20102;&#36861;&#27714;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#39033;&#21517;&#20026;&#29983;&#25104;&#24335;&#26381;&#35013;&#25512;&#33616;&#65288;GOR&#65289;&#30340;&#21019;&#26032;&#20219;&#21153;&#65292;&#20854;&#30446;&#26631;&#26159;&#21512;&#25104;&#19968;&#32452;&#26102;&#23578;&#22270;&#29255;&#65292;&#24182;&#23558;&#23427;&#20204;&#32452;&#35013;&#25104;&#35270;&#35273;&#21644;&#35856;&#30340;&#12289;&#23450;&#21046;&#32473;&#20010;&#20154;&#29992;&#25143;&#30340;&#26381;&#35013;&#12290;GOR&#30340;&#20027;&#35201;&#30446;&#26631;&#38598;&#20013;&#22312;&#23454;&#29616;&#29983;&#25104;&#26381;&#35013;&#30340;&#39640;&#20445;&#30495;&#24230;&#12289;&#20860;&#23481;&#24615;&#21644;&#20010;&#24615;&#21270;&#12290;&#20026;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DiFashion&#65292;&#19968;&#20010;&#29983;&#25104;&#24335;&#26381;&#35013;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17279v1 Announce Type: new  Abstract: The evolution of Outfit Recommendation (OR) in the realm of fashion has progressed through two distinct phases: Pre-defined Outfit Recommendation and Personalized Outfit Composition. Despite these advancements, both phases face limitations imposed by existing fashion products, hindering their effectiveness in meeting users' diverse fashion needs. The emergence of AI-generated content has paved the way for OR to overcome these constraints, demonstrating the potential for personalized outfit generation.   In pursuit of this, we introduce an innovative task named Generative Outfit Recommendation (GOR), with the goal of synthesizing a set of fashion images and assembling them to form visually harmonious outfits customized to individual users. The primary objectives of GOR revolve around achieving high fidelity, compatibility, and personalization of the generated outfits. To accomplish these, we propose DiFashion, a generative outfit recommen
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65292;&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#25198;&#28436;&#20851;&#38190;&#35282;&#33394;&#12290;&#35813;&#27169;&#22411;&#26088;&#22312;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#65292;&#24182;&#35299;&#20915;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.06871</link><description>&lt;p&gt;
&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Non-autoregressive Generative Models for Reranking Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65292;&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#25198;&#28436;&#20851;&#38190;&#35282;&#33394;&#12290;&#35813;&#27169;&#22411;&#26088;&#22312;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#65292;&#24182;&#35299;&#20915;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#37325;&#26032;&#25490;&#24207;&#36890;&#36807;&#24314;&#27169;&#39033;&#30446;&#20043;&#38388;&#30340;&#20869;&#37096;&#30456;&#20851;&#24615;&#36215;&#21040;&#20102;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#37325;&#26032;&#25490;&#24207;&#30340;&#20851;&#38190;&#25361;&#25112;&#22312;&#20110;&#22312;&#25490;&#21015;&#30340;&#32452;&#21512;&#31354;&#38388;&#20013;&#25506;&#32034;&#26368;&#20339;&#24207;&#21015;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#29983;&#25104;&#22120;-&#35780;&#20272;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#29983;&#25104;&#22120;&#29983;&#25104;&#22810;&#20010;&#21487;&#34892;&#24207;&#21015;&#65292;&#35780;&#20272;&#22120;&#22522;&#20110;&#20272;&#35745;&#30340;&#21015;&#34920;&#24471;&#20998;&#36873;&#25321;&#26368;&#20339;&#24207;&#21015;&#12290;&#29983;&#25104;&#22120;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#29983;&#25104;&#27169;&#22411;&#38750;&#24120;&#36866;&#21512;&#29983;&#25104;&#22120;&#20989;&#25968;&#12290;&#24403;&#21069;&#30340;&#29983;&#25104;&#27169;&#22411;&#37319;&#29992;&#33258;&#22238;&#24402;&#31574;&#30053;&#36827;&#34892;&#24207;&#21015;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#26102;&#24037;&#19994;&#31995;&#32479;&#20013;&#37096;&#32626;&#33258;&#22238;&#24402;&#27169;&#22411;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65288;NAR4Rec&#65289;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#19982;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;m
&lt;/p&gt;
&lt;p&gt;
In a multi-stage recommendation system, reranking plays a crucial role by modeling the intra-list correlations among items.The key challenge of reranking lies in the exploration of optimal sequences within the combinatorial space of permutations. Recent research proposes a generator-evaluator learning paradigm, where the generator generates multiple feasible sequences and the evaluator picks out the best sequence based on the estimated listwise score. Generator is of vital importance, and generative models are well-suited for the generator function. Current generative models employ an autoregressive strategy for sequence generation. However, deploying autoregressive models in real-time industrial systems is challenging. Hence, we propose a Non-AutoRegressive generative model for reranking Recommendation (NAR4Rec) designed to enhance efficiency and effectiveness. To address challenges related to sparse training samples and dynamic candidates impacting model convergence, we introduce a m
&lt;/p&gt;</description></item><item><title>TransGNN&#26159;&#19968;&#31181;&#23558;Transformer&#21644;GNN&#23618;&#20132;&#26367;&#32467;&#21512;&#20197;&#30456;&#20114;&#22686;&#24378;&#20854;&#33021;&#21147;&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30340;&#24863;&#21463;&#22495;&#26377;&#38480;&#21644;&#23384;&#22312;&#22122;&#38899;&#36830;&#25509;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.14355</link><description>&lt;p&gt;
TransGNN: &#21033;&#29992;Transformer&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#21327;&#21516;&#33021;&#21147;&#26469;&#20570;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
TransGNN: Harnessing the Collaborative Power of Transformers and Graph Neural Networks for Recommender Systems. (arXiv:2308.14355v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14355
&lt;/p&gt;
&lt;p&gt;
TransGNN&#26159;&#19968;&#31181;&#23558;Transformer&#21644;GNN&#23618;&#20132;&#26367;&#32467;&#21512;&#20197;&#30456;&#20114;&#22686;&#24378;&#20854;&#33021;&#21147;&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30340;&#24863;&#21463;&#22495;&#26377;&#38480;&#21644;&#23384;&#22312;&#22122;&#38899;&#36830;&#25509;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23545;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#22270;&#36827;&#34892;&#24314;&#27169;&#26469;&#36827;&#34892;&#21327;&#21516;&#36807;&#28388;(CF)&#12290;&#29616;&#26377;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#26680;&#24515;&#26159;&#36890;&#36807;&#22312;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#36793;&#19978;&#36827;&#34892;&#36882;&#24402;&#28040;&#24687;&#20256;&#36882;&#26469;&#25913;&#36827;&#32534;&#30721;&#23884;&#20837;&#12290;&#23613;&#31649;&#23427;&#20204;&#24050;&#32463;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#26159;&#24403;&#21069;&#22522;&#20110;GNN&#30340;&#26041;&#27861;&#38754;&#20020;&#30528;&#26377;&#38480;&#30340;&#24863;&#21463;&#22495;&#21644;&#23384;&#22312;&#22122;&#38899; "&#20852;&#36259;&#26080;&#20851;" &#36830;&#25509;&#30340;&#25361;&#25112;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#22312;&#33258;&#36866;&#24212;&#21644;&#20840;&#23616;&#20449;&#24687;&#32858;&#21512;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#25429;&#25417;&#22797;&#26434;&#12289;&#32416;&#32544;&#30340;&#32467;&#26500;&#20449;&#24687;&#26041;&#38754;&#22312;&#22823;&#35268;&#27169;&#20132;&#20114;&#22270;&#20013;&#30340;&#24212;&#29992;&#21463;&#21040;&#22256;&#25200;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TransGNN&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20132;&#26367;&#22320;&#32467;&#21512;Transformer&#21644;GNN&#23618;&#26469;&#30456;&#20114;&#22686;&#24378;&#23427;&#20204;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have emerged as promising solutions for collaborative filtering (CF) through the modeling of user-item interaction graphs. The nucleus of existing GNN-based recommender systems involves recursive message passing along user-item interaction edges to refine encoded embeddings. Despite their demonstrated effectiveness, current GNN-based methods encounter challenges of limited receptive fields and the presence of noisy ``interest-irrelevant'' connections. In contrast, Transformer-based methods excel in aggregating information adaptively and globally. Nevertheless, their application to large-scale interaction graphs is hindered by inherent complexities and challenges in capturing intricate, entangled structural information. In this paper, we propose TransGNN, a novel model that integrates Transformer and GNN layers in an alternating fashion to mutually enhance their capabilities. Specifically, TransGNN leverages Transformer layers to broaden the receptive field 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#37325;&#26032;&#35782;&#21035;&#21311;&#21517;&#20010;&#20154;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#27169;&#22411;&#22823;&#23567;&#12289;&#36755;&#20837;&#38271;&#24230;&#21644;&#25351;&#20196;&#35843;&#25972;&#26159;&#26368;&#37325;&#35201;&#30340;&#20915;&#23450;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2308.11103</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20877;&#35782;&#21035;&#33021;&#21147;&#65306;&#21311;&#21517;&#38754;&#20020;&#39118;&#38505;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models. (arXiv:2308.11103v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11103
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#37325;&#26032;&#35782;&#21035;&#21311;&#21517;&#20010;&#20154;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#27169;&#22411;&#22823;&#23567;&#12289;&#36755;&#20837;&#38271;&#24230;&#21644;&#25351;&#20196;&#35843;&#25972;&#26159;&#26368;&#37325;&#35201;&#30340;&#20915;&#23450;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27431;&#30431;&#21644;&#29790;&#22763;&#65292;&#27861;&#38498;&#35009;&#20915;&#20013;&#33258;&#28982;&#20154;&#21644;&#27861;&#20154;&#30340;&#21311;&#21517;&#24615;&#26159;&#38544;&#31169;&#20445;&#25252;&#30340;&#20851;&#38190;&#26041;&#38754;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#65292;&#23545;&#20110;&#21311;&#21517;&#20154;&#21592;&#30340;&#22823;&#35268;&#27169;&#20877;&#35782;&#21035;&#30340;&#25285;&#24551;&#26085;&#30410;&#22686;&#38271;&#12290;&#26681;&#25454;&#29790;&#22763;&#32852;&#37030;&#26368;&#39640;&#27861;&#38498;&#30340;&#35201;&#27714;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#26469;&#33258;&#29790;&#22763;&#32852;&#37030;&#26368;&#39640;&#27861;&#38498;&#30340;&#23454;&#38469;&#27861;&#24459;&#25968;&#25454;&#26500;&#24314;&#20102;&#19968;&#20010;&#27010;&#24565;&#39564;&#35777;&#65292;&#26469;&#25506;&#35752;LLMs&#37325;&#26032;&#35782;&#21035;&#27861;&#38498;&#35009;&#20915;&#20013;&#20010;&#20154;&#30340;&#28508;&#21147;&#12290;&#22312;&#26368;&#21021;&#30340;&#23454;&#39564;&#20043;&#21518;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#32463;&#36807;&#21311;&#21517;&#21270;&#22788;&#29702;&#30340;&#32500;&#22522;&#30334;&#31185;&#25968;&#25454;&#38598;&#65292;&#20316;&#20026;&#19968;&#20010;&#26356;&#20005;&#26684;&#30340;&#27979;&#35797;&#22330;&#22320;&#26469;&#36827;&#19968;&#27493;&#30740;&#31350;&#30740;&#31350;&#32467;&#26524;&#12290;&#36890;&#36807;&#24341;&#20837;&#24182;&#24212;&#29992;&#25991;&#26412;&#20013;&#20877;&#35782;&#21035;&#20154;&#21592;&#30340;&#26032;&#20219;&#21153;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#26032;&#30340;&#24615;&#33021;&#34913;&#37327;&#25351;&#26631;&#12290;&#25105;&#20204;&#31995;&#32479;&#22320;&#20998;&#26512;&#20102;&#24433;&#21709;&#25104;&#21151;&#20877;&#35782;&#21035;&#30340;&#22240;&#32032;&#65292;&#30830;&#23450;&#27169;&#22411;&#22823;&#23567;&#12289;&#36755;&#20837;&#38271;&#24230;&#21644;&#25351;&#20196;&#35843;&#25972;&#26159;&#26368;&#37325;&#35201;&#30340;&#20915;&#23450;&#22240;&#32032;&#20043;&#19968;&#12290;&#23613;&#31649;&#22312;&#21311;&#21517;&#21270;&#22788;&#29702;&#21518;&#65292;LLMs&#22312;&#37325;&#26032;&#35782;&#21035;&#19978;&#30340;&#25104;&#21151;&#29575;&#24456;&#39640;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#20173;&#28982;&#23384;&#22312;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anonymity of both natural and legal persons in court rulings is a critical aspect of privacy protection in the European Union and Switzerland. With the advent of LLMs, concerns about large-scale re-identification of anonymized persons are growing. In accordance with the Federal Supreme Court of Switzerland, we explore the potential of LLMs to re-identify individuals in court rulings by constructing a proof-of-concept using actual legal data from the Swiss federal supreme court. Following the initial experiment, we constructed an anonymized Wikipedia dataset as a more rigorous testing ground to further investigate the findings. With the introduction and application of the new task of re-identifying people in texts, we also introduce new metrics to measure performance. We systematically analyze the factors that influence successful re-identifications, identifying model size, input length, and instruction tuning among the most critical determinants. Despite high re-identification rates on
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#32622;&#27169;&#22411;&#26080;&#20851;&#26041;&#27861;&#65292;&#20844;&#24179;LTR-RC&#65292;&#23427;&#19981;&#38656;&#35201;&#26114;&#36149;&#30340;&#35757;&#32451;&#65292;&#22312;&#20445;&#35777;&#20844;&#24179;&#24615;&#30340;&#21516;&#26102;&#65292;&#36824;&#33021;&#22312;&#25928;&#29992;&#21644;&#20844;&#24179;&#20043;&#38388;&#23454;&#29616;&#26377;&#25928;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.07188</link><description>&lt;p&gt;
&#26080;&#20998;&#24067;&#39118;&#38505;&#25511;&#21046;&#30340;&#20844;&#24179;&#23398;&#20064;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Fair Learning to Rank with Distribution-free Risk Control. (arXiv:2306.07188v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07188
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#32622;&#27169;&#22411;&#26080;&#20851;&#26041;&#27861;&#65292;&#20844;&#24179;LTR-RC&#65292;&#23427;&#19981;&#38656;&#35201;&#26114;&#36149;&#30340;&#35757;&#32451;&#65292;&#22312;&#20445;&#35777;&#20844;&#24179;&#24615;&#30340;&#21516;&#26102;&#65292;&#36824;&#33021;&#22312;&#25928;&#29992;&#21644;&#20844;&#24179;&#20043;&#38388;&#23454;&#29616;&#26377;&#25928;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#32463;&#27982;&#20013;&#65292;&#23398;&#20064;&#25490;&#24207;&#26041;&#27861;&#23545;&#29992;&#25143;&#21644;&#29289;&#21697;&#25552;&#20379;&#32773;&#33267;&#20851;&#37325;&#35201;&#12290;LTR&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#23545;&#20110;&#25353;&#27604;&#20363;&#20998;&#37197;&#26333;&#20809;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#20855;&#26377;&#30456;&#21516;&#30456;&#20851;&#24615;&#30340;&#39033;&#25509;&#25910;&#30053;&#26377;&#19981;&#21516;&#30340;&#20998;&#25968;&#26102;&#65292;&#30830;&#23450;&#24615;&#25490;&#21517;&#27169;&#22411;&#21487;&#33021;&#23548;&#33268;&#19981;&#20844;&#24179;&#30340;&#26333;&#20809;&#20998;&#37197;&#12290;&#38543;&#26426;LTR&#27169;&#22411;&#65292;&#21253;&#25324;Plackett-Luce&#65288;PL&#65289;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#20294;&#22312;&#35745;&#31639;&#25104;&#26412;&#21644;&#24615;&#33021;&#20445;&#35777;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20844;&#24179;LTR-RC&#65292;&#19968;&#31181;&#26032;&#30340;&#21518;&#32622;&#27169;&#22411;&#26080;&#20851;&#26041;&#27861;&#12290;&#20844;&#24179;LTR-RC&#21033;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;&#35780;&#20998;&#20989;&#25968;&#21019;&#24314;&#38543;&#26426;LTR&#27169;&#22411;&#65292;&#28040;&#38500;&#20102;&#26114;&#36149;&#30340;&#35757;&#32451;&#38656;&#27714;&#12290;&#27492;&#22806;&#65292;&#20844;&#24179;LTR-RC&#20351;&#29992;&#26080;&#20998;&#24067;&#24335;&#39118;&#38505;&#25511;&#21046;&#26694;&#26550;&#23545;&#29992;&#25143;&#25351;&#23450;&#30340;&#25928;&#29992;&#25552;&#20379;&#26377;&#38480;&#30340;&#26679;&#26412;&#20445;&#35777;&#12290;&#36890;&#36807;&#21478;&#22806;&#32467;&#21512;Thresholded PL&#65288;TPL&#65289;&#27169;&#22411;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#25928;&#29992;&#21644;&#20844;&#24179;&#20043;&#38388;&#23454;&#29616;&#26377;&#25928;&#30340;&#26435;&#34913;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;FairLTR-RC&#22312;&#20844;&#24179;&#24615;&#21644;&#25928;&#29992;&#24615;&#25351;&#26631;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning to Rank (LTR) methods are vital in online economies, affecting users and item providers. Fairness in LTR models is crucial to allocate exposure proportionally to item relevance. The deterministic ranking model can lead to unfair exposure distribution when items with the same relevance receive slightly different scores. Stochastic LTR models, incorporating the Plackett-Luce (PL) model, address fairness issues but have limitations in computational cost and performance guarantees. To overcome these limitations, we propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC leverages a pretrained scoring function to create a stochastic LTR model, eliminating the need for expensive training. Furthermore, FairLTR-RC provides finite-sample guarantees on a user-specified utility using distribution-free risk control framework. By additionally incorporating the Thresholded PL (TPL) model, we are able to achieve an effective trade-off between utility and fairness. Experimental
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#20449;&#24687;&#26816;&#32034;&#21338;&#24328;&#35770;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#20197;&#36798;&#25104;&#26356;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#35777;&#26126;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.16695</link><description>&lt;p&gt;
&#23547;&#27714;&#31283;&#23450;&#24615;&#65306;&#20855;&#26377;&#21021;&#22987;&#25991;&#20214;&#30340;&#25112;&#30053;&#20986;&#29256;&#21830;&#30340;&#23398;&#20064;&#21160;&#24577;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Search for Stability: Learning Dynamics of Strategic Publishers with Initial Documents. (arXiv:2305.16695v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#20449;&#24687;&#26816;&#32034;&#21338;&#24328;&#35770;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#20197;&#36798;&#25104;&#26356;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#35777;&#26126;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20449;&#24687;&#26816;&#32034;&#30340;&#21338;&#24328;&#35770;&#27169;&#22411;&#65292;&#20854;&#20013;&#25112;&#30053;&#20986;&#29256;&#21830;&#26088;&#22312;&#22312;&#20445;&#25345;&#21407;&#22987;&#25991;&#26723;&#23436;&#25972;&#24615;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#33258;&#24049;&#25490;&#21517;&#31532;&#19968;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24120;&#29992;&#30340;PRP&#25490;&#21517;&#26041;&#26696;&#23548;&#33268;&#29615;&#22659;&#19981;&#31283;&#23450;&#65292;&#28216;&#25103;&#32463;&#24120;&#26080;&#27861;&#36798;&#21040;&#32431;&#32435;&#20160;&#22343;&#34913;&#12290;&#25105;&#20204;&#23558;&#30456;&#23545;&#25490;&#21517;&#21407;&#21017;&#65288;RRP&#65289;&#20316;&#20026;&#26367;&#20195;&#25490;&#21517;&#21407;&#21017;&#65292;&#24182;&#20171;&#32461;&#20004;&#20010;&#25490;&#21517;&#20989;&#25968;&#65292;&#23427;&#20204;&#26159;RRP&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#65292;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#23548;&#33268;&#31283;&#23450;&#30340;&#25628;&#32034;&#29983;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#23398;&#20064;&#21160;&#21147;&#23398;&#25910;&#25947;&#30340;&#31215;&#26497;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23450;&#20041;&#20986;&#29256;&#21830;&#21644;&#29992;&#25143;&#30340;&#31119;&#21033;&#65292;&#24182;&#23637;&#31034;&#20102;&#21487;&#33021;&#30340;&#20986;&#29256;&#21830;-&#29992;&#25143;&#26435;&#34913;&#65292;&#31361;&#26174;&#20102;&#30830;&#23450;&#25628;&#32034;&#24341;&#25806;&#35774;&#35745;&#24072;&#24212;&#36873;&#25321;&#21738;&#31181;&#25490;&#21517;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a game-theoretic model of information retrieval, in which strategic publishers aim to maximize their chances of being ranked first by the search engine, while maintaining the integrity of their original documents. We show that the commonly used PRP ranking scheme results in an unstable environment where games often fail to reach pure Nash equilibrium. We propose the Relative Ranking Principle (RRP) as an alternative ranking principle, and introduce two ranking functions that are instances of the RRP. We provide both theoretical and empirical evidence that these methods lead to a stable search ecosystem, by providing positive results on the learning dynamics convergence. We also define the publishers' and users' welfare, and demonstrate a possible publisher-user trade-off, which highlights the complexity of determining which ranking function should be selected by the search engine designer.
&lt;/p&gt;</description></item></channel></rss>