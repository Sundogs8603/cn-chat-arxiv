<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#23613;&#31649;mT5&#27169;&#22411;&#20165;&#22312;&#30456;&#21516;&#35821;&#35328;&#30340;&#26597;&#35810;-&#25991;&#26723;&#23545;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#20294;&#22312;&#19981;&#21516;&#35821;&#35328;&#30340;&#26597;&#35810;-&#25991;&#26723;&#23545;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#21487;&#34892;&#30340;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#25152;&#26377;&#20219;&#21153;&#21644;&#35821;&#35328;&#19978;&#37117;&#34920;&#29616;&#20986;&#33394;&#65292;&#33719;&#24471;&#20102;&#24456;&#39640;&#30340;&#33719;&#32988;&#20301;&#32622;&#65292;&#24378;&#35843;&#20102;&#20854;&#20316;&#20026;&#19968;&#31181;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#21487;&#34892;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.16145</link><description>&lt;p&gt;
&#12298;&#31070;&#32463;&#32593;&#32476;-&#24052;&#35199;&#22350;&#26222;&#26031;&#22823;&#23398;&#12299;&#22312;2022&#24180;TREC NeuCLIR&#20013;&#30340;&#22823;&#22411;&#26080;&#32842;&#37325;&#25490;&#22120;&#23454;&#29616;&#36328;&#35821;&#35328;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
NeuralMind-UNICAMP at 2022 TREC NeuCLIR: Large Boring Rerankers for Cross-lingual Retrieval. (arXiv:2303.16145v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#23613;&#31649;mT5&#27169;&#22411;&#20165;&#22312;&#30456;&#21516;&#35821;&#35328;&#30340;&#26597;&#35810;-&#25991;&#26723;&#23545;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#20294;&#22312;&#19981;&#21516;&#35821;&#35328;&#30340;&#26597;&#35810;-&#25991;&#26723;&#23545;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#21487;&#34892;&#30340;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#25152;&#26377;&#20219;&#21153;&#21644;&#35821;&#35328;&#19978;&#37117;&#34920;&#29616;&#20986;&#33394;&#65292;&#33719;&#24471;&#20102;&#24456;&#39640;&#30340;&#33719;&#32988;&#20301;&#32622;&#65292;&#24378;&#35843;&#20102;&#20854;&#20316;&#20026;&#19968;&#31181;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#21487;&#34892;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25253;&#36947;&#20102;&#20351;&#29992;mT5-XXL&#37325;&#25490;&#22120;&#22312;TREC 2022 NeuCLIR&#36187;&#36947;&#19978;&#36827;&#34892;&#36328;&#35821;&#35328;&#20449;&#24687;&#26816;&#32034;&#65288;CLIR&#65289;&#30340;&#30740;&#31350;&#12290;&#35813;&#30740;&#31350;&#26368;&#22823;&#30340;&#36129;&#29486;&#20063;&#35768;&#26159;&#21457;&#29616;&#23613;&#31649;mT5&#27169;&#22411;&#20165;&#22312;&#30456;&#21516;&#35821;&#35328;&#30340;&#26597;&#35810;-&#25991;&#26723;&#23545;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#20294;&#22312;&#19981;&#21516;&#35821;&#35328;&#30340;&#26597;&#35810;-&#25991;&#26723;&#23545;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#35777;&#26126;&#20102;&#22312;&#31532;&#19968;&#38454;&#27573;&#26816;&#32034;&#34920;&#29616;&#20122;&#20248;&#30340;&#24773;&#20917;&#19979;&#26159;&#21487;&#34892;&#30340;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#25152;&#26377;&#20219;&#21153;&#21644;&#35821;&#35328;&#19978;&#37117;&#34920;&#29616;&#20986;&#33394;&#65292;&#33719;&#24471;&#20102;&#24456;&#39640;&#30340;&#33719;&#32988;&#20301;&#32622;&#12290;&#26368;&#21518;&#65292;&#26412;&#30740;&#31350;&#20026;&#22312;CLIR&#20219;&#21153;&#20013;&#20351;&#29992;mT5&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#65292;&#24182;&#24378;&#35843;&#20102;&#20854;&#20316;&#20026;&#19968;&#31181;&#21487;&#34892;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;&#22914;&#38656;&#22797;&#21046;&#65292;&#35831;&#21442;&#38405;https://github.com/unicamp-dl/NeuCLIR22-mT5&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper reports on a study of cross-lingual information retrieval (CLIR) using the mT5-XXL reranker on the NeuCLIR track of TREC 2022. Perhaps the biggest contribution of this study is the finding that despite the mT5 model being fine-tuned only on query-document pairs of the same language it proved to be viable for CLIR tasks, where query-document pairs are in different languages, even in the presence of suboptimal first-stage retrieval performance. The results of the study show outstanding performance across all tasks and languages, leading to a high number of winning positions. Finally, this study provides valuable insights into the use of mT5 in CLIR tasks and highlights its potential as a viable solution. For reproduction refer to https://github.com/unicamp-dl/NeuCLIR22-mT5
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#22240;&#26524;&#20998;&#31163;&#25512;&#33616;&#31995;&#32479;&#35299;&#20915;&#29992;&#25143;&#20559;&#22909;&#21464;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#25277;&#35937;&#22240;&#26524;&#22270;&#21457;&#29616;&#26410;&#35266;&#23519;&#21040;&#30340;&#22240;&#32032;&#30340;&#21464;&#21270;&#23548;&#33268;&#20559;&#22909;&#31227;&#20301;&#65292;&#24182;&#20851;&#27880;&#31934;&#32454;&#20559;&#22909;&#24433;&#21709;&#19982;&#19981;&#21516;&#39033;&#30446;&#30340;&#20132;&#20114;&#12290;</title><link>http://arxiv.org/abs/2303.16068</link><description>&lt;p&gt;
&#22240;&#26524;&#20998;&#31163;&#25512;&#33616;&#65306;&#24212;&#23545;&#29992;&#25143;&#20559;&#22909;&#21464;&#21270;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Causal Disentangled Recommendation Against User Preference Shifts. (arXiv:2303.16068v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16068
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#22240;&#26524;&#20998;&#31163;&#25512;&#33616;&#31995;&#32479;&#35299;&#20915;&#29992;&#25143;&#20559;&#22909;&#21464;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#25277;&#35937;&#22240;&#26524;&#22270;&#21457;&#29616;&#26410;&#35266;&#23519;&#21040;&#30340;&#22240;&#32032;&#30340;&#21464;&#21270;&#23548;&#33268;&#20559;&#22909;&#31227;&#20301;&#65292;&#24182;&#20851;&#27880;&#31934;&#32454;&#20559;&#22909;&#24433;&#21709;&#19982;&#19981;&#21516;&#39033;&#30446;&#30340;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24456;&#23481;&#26131;&#38754;&#20020;&#29992;&#25143;&#20559;&#22909;&#31227;&#20301;&#30340;&#38382;&#39064;&#12290;&#22914;&#26524;&#29992;&#25143;&#20559;&#22909;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#21457;&#29983;&#20102;&#21464;&#21270;&#65292;&#29992;&#25143;&#34920;&#31034;&#23558;&#21464;&#24471;&#36807;&#26102;&#65292;&#20174;&#32780;&#23548;&#33268;&#19981;&#36866;&#24403;&#30340;&#25512;&#33616;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#19987;&#27880;&#20110;&#23398;&#20064;&#31283;&#20581;&#30340;&#34920;&#31034;&#25110;&#39044;&#27979;&#21464;&#21270;&#27169;&#24335;&#65292;&#32570;&#20047;&#21457;&#29616;&#29992;&#25143;&#20559;&#22909;&#31227;&#20301;&#30340;&#28508;&#22312;&#21407;&#22240;&#30340;&#20840;&#38754;&#35270;&#35282;&#12290;&#20026;&#20102;&#29702;&#35299;&#20559;&#22909;&#31227;&#20301;&#65292;&#25105;&#20204;&#25277;&#35937;&#20102;&#19968;&#20010;&#22240;&#26524;&#22270;&#65292;&#25551;&#36848;&#20102;&#29992;&#25143;&#20132;&#20114;&#24207;&#21015;&#30340;&#29983;&#25104;&#36807;&#31243;&#12290;&#20551;&#35774;&#29992;&#25143;&#20559;&#22909;&#22312;&#30701;&#26102;&#38388;&#20869;&#26159;&#31283;&#23450;&#30340;&#65292;&#25105;&#20204;&#23558;&#20132;&#20114;&#24207;&#21015;&#25277;&#35937;&#20026;&#19968;&#32452;&#26102;&#38388;&#39034;&#24207;&#30340;&#29615;&#22659;&#12290;&#20174;&#22240;&#26524;&#22270;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#19968;&#20123;&#26410;&#35266;&#23519;&#21040;&#30340;&#22240;&#32032;&#30340;&#21464;&#21270;&#65288;&#20363;&#22914;&#24576;&#23381;&#65289;&#23548;&#33268;&#20102;&#29615;&#22659;&#20043;&#38388;&#30340;&#20559;&#22909;&#31227;&#20301;&#12290;&#27492;&#22806;&#65292;&#29992;&#25143;&#23545;&#19981;&#21516;&#31867;&#21035;&#30340;&#31934;&#32454;&#20559;&#22909;&#31232;&#30095;&#22320;&#24433;&#21709;&#19982;&#19981;&#21516;&#39033;&#30446;&#30340;&#20132;&#20114;&#12290;&#21463;&#21040;&#22240;&#26524;&#22270;&#30340;&#21551;&#31034;&#65292;&#25105;&#20204;&#20851;&#27880;&#22788;&#29702;&#20559;&#22909;&#31227;&#20301;&#38382;&#39064;&#30340;&#20851;&#38190;&#32771;&#34385;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems easily face the issue of user preference shifts. User representations will become out-of-date and lead to inappropriate recommendations if user preference has shifted over time. To solve the issue, existing work focuses on learning robust representations or predicting the shifting pattern. There lacks a comprehensive view to discover the underlying reasons for user preference shifts. To understand the preference shift, we abstract a causal graph to describe the generation procedure of user interaction sequences. Assuming user preference is stable within a short period, we abstract the interaction sequence as a set of chronological environments. From the causal graph, we find that the changes of some unobserved factors (e.g., becoming pregnant) cause preference shifts between environments. Besides, the fine-grained user preference over categories sparsely affects the interactions with different items. Inspired by the causal graph, our key considerations to handle pre
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26159;&#19968;&#31687;&#23545;&#20110;&#12298;&#20851;&#20110;IR&#35780;&#20272;&#26041;&#27861;&#30340;&#19968;&#33324;&#29702;&#35770;&#12299;&#30340;&#35780;&#35770;&#65292;&#25351;&#20986;&#20102;&#23427;&#30340;&#32467;&#35770;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2303.16061</link><description>&lt;p&gt;
&#19968;&#31687;&#12298;&#20851;&#20110;IR&#35780;&#20272;&#26041;&#27861;&#30340;&#19968;&#33324;&#29702;&#35770;&#12299;&#30340;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
A comment to "A General Theory of IR Evaluation Measures". (arXiv:2303.16061v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#19968;&#31687;&#23545;&#20110;&#12298;&#20851;&#20110;IR&#35780;&#20272;&#26041;&#27861;&#30340;&#19968;&#33324;&#29702;&#35770;&#12299;&#30340;&#35780;&#35770;&#65292;&#25351;&#20986;&#20102;&#23427;&#30340;&#32467;&#35770;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#8220;&#19968;&#33324;&#30340;IR&#35780;&#20272;&#26041;&#27861;&#29702;&#35770;&#8221;&#24320;&#21457;&#20102;&#19968;&#20010;&#24418;&#24335;&#21270;&#30340;&#26694;&#26550;&#65292;&#20197;&#30830;&#23450;IR&#35780;&#20272;&#26041;&#27861;&#26159;&#21542;&#20026;&#21306;&#38388;&#21051;&#24230;&#12290;&#26412;&#35780;&#35770;&#26174;&#31034;&#20102;&#19968;&#20123;&#20851;&#20110;&#20854;&#32467;&#35770;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper "A General Theory of IR Evaluation Measures" develops a formal framework to determine whether IR evaluation measures are interval scales. This comment shows some limitations about its conclusions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#21697;&#22270;&#21367;&#31215;&#30340;&#24402;&#32435;&#24335;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#25237;&#24433;&#26500;&#24314;&#29289;&#21697;-&#29289;&#21697;&#22270;&#65292;&#24182;&#37319;&#29992;&#21367;&#31215;&#23558;&#39640;&#38454;&#20851;&#32852;&#27880;&#20837;&#29289;&#21697;&#23884;&#20837;&#65292;&#21516;&#26102;&#23558;&#29992;&#25143;&#34920;&#31034;&#24418;&#25104;&#21152;&#26435;&#30340;&#21152;&#26435;&#21644;&#12290;</title><link>http://arxiv.org/abs/2303.15946</link><description>&lt;p&gt;
&#22522;&#20110;&#29289;&#21697;&#22270;&#21367;&#31215;&#30340;&#24402;&#32435;&#24335;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Item Graph Convolution Collaborative Filtering for Inductive Recommendations. (arXiv:2303.15946v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15946
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#21697;&#22270;&#21367;&#31215;&#30340;&#24402;&#32435;&#24335;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31639;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#25237;&#24433;&#26500;&#24314;&#29289;&#21697;-&#29289;&#21697;&#22270;&#65292;&#24182;&#37319;&#29992;&#21367;&#31215;&#23558;&#39640;&#38454;&#20851;&#32852;&#27880;&#20837;&#29289;&#21697;&#23884;&#20837;&#65292;&#21516;&#26102;&#23558;&#29992;&#25143;&#34920;&#31034;&#24418;&#25104;&#21152;&#26435;&#30340;&#21152;&#26435;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;GCN&#34987;&#29992;&#20316;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#30340;&#26680;&#24515;&#32452;&#20214;&#65292;&#23558;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#20316;&#20026;&#20108;&#20998;&#22270;&#30340;&#36793;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#32570;&#20047;&#38468;&#21152;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#27169;&#22411;&#37319;&#29992;&#38543;&#26426;&#21021;&#22987;&#21270;&#29992;&#25143;&#23884;&#20837;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20248;&#21270;&#23427;&#20204;&#30340;&#26041;&#27861;&#12290;&#36825;&#31181;&#31574;&#30053;&#20351;&#24471;&#36825;&#20123;&#31639;&#27861;&#26412;&#36136;&#19978;&#26159;&#36716;&#25442;&#22411;&#30340;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#20026;&#35757;&#32451;&#26102;&#26410;&#35265;&#36807;&#30340;&#29992;&#25143;&#29983;&#25104;&#39044;&#27979;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21367;&#31215;&#30340;&#31639;&#27861;&#65292;&#20174;&#29992;&#25143;&#30340;&#35282;&#24230;&#26159;&#24402;&#32435;&#24335;&#30340;&#65292;&#21516;&#26102;&#20165;&#20381;&#36182;&#20110;&#38544;&#24335;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20108;&#20998;&#22270;&#20132;&#20114;&#32593;&#32476;&#30340;&#21152;&#26435;&#25237;&#24433;&#26500;&#24314;&#29289;&#21697;-&#29289;&#21697;&#22270;&#24182;&#37319;&#29992;&#21367;&#31215;&#23558;&#39640;&#38454;&#20851;&#32852;&#27880;&#20837;&#29289;&#21697;&#23884;&#20837;&#65292;&#21516;&#26102;&#23558;&#29992;&#25143;&#34920;&#31034;&#24418;&#25104;&#21152;&#26435;&#30340;&#21152;&#26435;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Convolutional Networks (GCN) have been recently employed as core component in the construction of recommender system algorithms, interpreting user-item interactions as the edges of a bipartite graph. However, in the absence of side information, the majority of existing models adopt an approach of randomly initialising the user embeddings and optimising them throughout the training process. This strategy makes these algorithms inherently transductive, curtailing their ability to generate predictions for users that were unseen at training time. To address this issue, we propose a convolution-based algorithm, which is inductive from the user perspective, while at the same time, depending only on implicit user-item interaction data. We propose the construction of an item-item graph through a weighted projection of the bipartite interaction network and to employ convolution to inject higher order associations into item embeddings, while constructing user representations as weighted su
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; MMAN &#30340;&#22810;&#31890;&#24230;&#21305;&#37197;&#27880;&#24847;&#21147;&#32593;&#32476;&#65292;&#21487;&#20197;&#20840;&#38754;&#25552;&#21462;&#26597;&#35810;&#21644;&#26597;&#35810;&#31867;&#21035;&#20132;&#20114;&#30697;&#38453;&#30340;&#29305;&#24449;&#65292;&#20174;&#32780;&#28040;&#38500;&#26597;&#35810;&#21644;&#31867;&#21035;&#20043;&#38388;&#34920;&#36798;&#24046;&#24322;&#30340;&#24046;&#36317;&#65292;&#29992;&#20110;&#26597;&#35810;&#24847;&#22270;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2303.15870</link><description>&lt;p&gt;
&#30005;&#21830;&#26816;&#32034;&#20013;&#29992;&#20110;&#26597;&#35810;&#24847;&#22270;&#20998;&#31867;&#30340;&#22810;&#31890;&#24230;&#21305;&#37197;&#27880;&#24847;&#21147;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A Multi-Granularity Matching Attention Network for Query Intent Classification in E-commerce Retrieval. (arXiv:2303.15870v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; MMAN &#30340;&#22810;&#31890;&#24230;&#21305;&#37197;&#27880;&#24847;&#21147;&#32593;&#32476;&#65292;&#21487;&#20197;&#20840;&#38754;&#25552;&#21462;&#26597;&#35810;&#21644;&#26597;&#35810;&#31867;&#21035;&#20132;&#20114;&#30697;&#38453;&#30340;&#29305;&#24449;&#65292;&#20174;&#32780;&#28040;&#38500;&#26597;&#35810;&#21644;&#31867;&#21035;&#20043;&#38388;&#34920;&#36798;&#24046;&#24322;&#30340;&#24046;&#36317;&#65292;&#29992;&#20110;&#26597;&#35810;&#24847;&#22270;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#24847;&#22270;&#20998;&#31867;&#26088;&#22312;&#21327;&#21161;&#23458;&#25143;&#25214;&#21040;&#25152;&#38656;&#20135;&#21697;&#65292;&#24050;&#25104;&#20026;&#30005;&#23376;&#21830;&#21153;&#25628;&#32034;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#29616;&#26377;&#30340;&#26597;&#35810;&#24847;&#22270;&#20998;&#31867;&#27169;&#22411;&#35201;&#20040;&#35774;&#35745;&#26356;&#31934;&#32454;&#30340;&#27169;&#22411;&#20197;&#22686;&#24378;&#26597;&#35810;&#30340;&#34920;&#31034;&#23398;&#20064;&#65292;&#35201;&#20040;&#25506;&#32034;&#26631;&#31614;&#22270;&#21644;&#22810;&#20219;&#21153;&#20197;&#24110;&#21161;&#27169;&#22411;&#23398;&#20064;&#22806;&#37096;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#26080;&#27861;&#20174;&#26597;&#35810;&#21644;&#31867;&#21035;&#20013;&#25429;&#25417;&#22810;&#31890;&#24230;&#21305;&#37197;&#29305;&#24449;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#38590;&#20197;&#24357;&#34917;&#38750;&#27491;&#24335;&#26597;&#35810;&#21644;&#31867;&#21035;&#20043;&#38388;&#34920;&#36798;&#24046;&#24322;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#31890;&#24230;&#21305;&#37197;&#27880;&#24847;&#21147;&#32593;&#32476;(MMAN)&#65292;&#20854;&#21253;&#21547;&#19977;&#20010;&#27169;&#22359;&#65306;&#33258;&#21305;&#37197;&#27169;&#22359;&#12289;&#23383;&#31526;&#32423;&#21305;&#37197;&#27169;&#22359;&#21644;&#35821;&#20041;&#32423;&#21305;&#37197;&#27169;&#22359;&#65292;&#20197;&#20840;&#38754;&#25552;&#21462;&#26597;&#35810;&#21644;&#26597;&#35810;&#31867;&#21035;&#20132;&#20114;&#30697;&#38453;&#30340;&#29305;&#24449;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#28040;&#38500;&#26597;&#35810;&#24847;&#22270;&#20998;&#31867;&#20013;&#26597;&#35810;&#21644;&#31867;&#21035;&#20043;&#38388;&#34920;&#36798;&#24046;&#24322;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Query intent classification, which aims at assisting customers to find desired products, has become an essential component of the e-commerce search. Existing query intent classification models either design more exquisite models to enhance the representation learning of queries or explore label-graph and multi-task to facilitate models to learn external information. However, these models cannot capture multi-granularity matching features from queries and categories, which makes them hard to mitigate the gap in the expression between informal queries and categories.  This paper proposes a Multi-granularity Matching Attention Network (MMAN), which contains three modules: a self-matching module, a char-level matching module, and a semantic-level matching module to comprehensively extract features from the query and a query-category interaction matrix. In this way, the model can eliminate the difference in expression between queries and categories for query intent classification. We conduc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24212;&#29992;&#25968;&#25454;&#31185;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#25299;&#25169;&#32593;&#32476;&#20998;&#26512;&#26041;&#27861;&#23545;&#19981;&#21516;&#36716;&#31227;&#37096;&#20301;&#30340;&#21069;&#21015;&#33146;&#30284;&#32959;&#30244;&#36827;&#34892;&#20102;&#22522;&#22240;&#20998;&#26512;&#65292;&#31579;&#36873;&#20986;&#20102;&#19982;&#21069;&#21015;&#33146;&#30284;&#36716;&#31227;&#30456;&#20851;&#30340;13&#20010;&#22522;&#22240;&#65292;&#20934;&#30830;&#29575;&#36798;&#21040;&#20102;92%&#12290;</title><link>http://arxiv.org/abs/2303.15851</link><description>&lt;p&gt;
&#35745;&#31639;&#26426;&#31185;&#23398;&#26041;&#27861;&#22312;&#21069;&#21015;&#33146;&#30284;&#36951;&#20256;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Genetic Analysis of Prostate Cancer with Computer Science Methods. (arXiv:2303.15851v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24212;&#29992;&#25968;&#25454;&#31185;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#25299;&#25169;&#32593;&#32476;&#20998;&#26512;&#26041;&#27861;&#23545;&#19981;&#21516;&#36716;&#31227;&#37096;&#20301;&#30340;&#21069;&#21015;&#33146;&#30284;&#32959;&#30244;&#36827;&#34892;&#20102;&#22522;&#22240;&#20998;&#26512;&#65292;&#31579;&#36873;&#20986;&#20102;&#19982;&#21069;&#21015;&#33146;&#30284;&#36716;&#31227;&#30456;&#20851;&#30340;13&#20010;&#22522;&#22240;&#65292;&#20934;&#30830;&#29575;&#36798;&#21040;&#20102;92%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#31227;&#24615;&#21069;&#21015;&#33146;&#30284;&#26159;&#30007;&#24615;&#26368;&#24120;&#35265;&#30340;&#30284;&#30151;&#20043;&#19968;&#12290;&#26412;&#25991;&#37319;&#29992;&#25968;&#25454;&#31185;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#25299;&#25169;&#32593;&#32476;&#20998;&#26512;&#26041;&#27861;&#23545;&#19981;&#21516;&#36716;&#31227;&#37096;&#20301;&#30340;&#21069;&#21015;&#33146;&#30284;&#32959;&#30244;&#36827;&#34892;&#22522;&#22240;&#20998;&#26512;&#12290;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#33324;&#24615;&#30340;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#20998;&#26512;&#26041;&#27861;&#26469;&#36807;&#28388;&#26174;&#33879;&#22522;&#22240;&#65292;&#24182;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#27425;&#35201;&#32959;&#30244;&#20998;&#31867;&#26469;&#36827;&#19968;&#27493;&#36807;&#28388;&#20851;&#38190;&#22522;&#22240;&#12290;&#26368;&#21518;&#65292;&#26412;&#25991;&#23545;&#19981;&#21516;&#31867;&#22411;&#21069;&#21015;&#33146;&#30284;&#32454;&#32990;&#31995;&#26679;&#26412;&#36827;&#34892;&#20102;&#22522;&#22240;&#20849;&#34920;&#36798;&#32593;&#32476;&#20998;&#26512;&#21644;&#31038;&#21306;&#26816;&#27979;&#12290;&#25991;&#31456;&#31579;&#36873;&#20986;&#20102;&#19982;&#21069;&#21015;&#33146;&#30284;&#36716;&#31227;&#30456;&#20851;&#30340;13&#20010;&#22522;&#22240;&#65292;&#20132;&#21449;&#39564;&#35777;&#19979;&#20934;&#30830;&#29575;&#36798;&#21040;&#20102;92%&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#25552;&#20379;&#20102;&#20849;&#34920;&#36798;&#27169;&#24335;&#30340;&#21021;&#27493;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Metastatic prostate cancer is one of the most common cancers in men. In the advanced stages of prostate cancer, tumours can metastasise to other tissues in the body, which is fatal. In this thesis, we performed a genetic analysis of prostate cancer tumours at different metastatic sites using data science, machine learning and topological network analysis methods. We presented a general procedure for pre-processing gene expression datasets and pre-filtering significant genes by analytical methods. We then used machine learning models for further key gene filtering and secondary site tumour classification. Finally, we performed gene co-expression network analysis and community detection on samples from different prostate cancer secondary site types. In this work, 13 of the 14,379 genes were selected as the most metastatic prostate cancer related genes, achieving approximately 92% accuracy under cross-validation. In addition, we provide preliminary insights into the co-expression patterns
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32423;&#32852;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#22810;&#34892;&#20026;&#25512;&#33616;&#27169;&#22411;&#65292;&#33021;&#22815;&#26126;&#30830;&#22320;&#21033;&#29992;&#34892;&#20026;&#38142;&#20013;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20197;&#32531;&#35299;&#25512;&#33616;&#31995;&#32479;&#25968;&#25454;&#31232;&#30095;&#25110;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.15720</link><description>&lt;p&gt;
&#22522;&#20110;&#32423;&#32852;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#22810;&#34892;&#20026;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Multi-Behavior Recommendation with Cascading Graph Convolution Networks. (arXiv:2303.15720v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32423;&#32852;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#22810;&#34892;&#20026;&#25512;&#33616;&#27169;&#22411;&#65292;&#33021;&#22815;&#26126;&#30830;&#22320;&#21033;&#29992;&#34892;&#20026;&#38142;&#20013;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20197;&#32531;&#35299;&#25512;&#33616;&#31995;&#32479;&#25968;&#25454;&#31232;&#30095;&#25110;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#34892;&#20026;&#25512;&#33616;&#21033;&#29992;&#36741;&#21161;&#34892;&#20026;&#65288;&#20363;&#22914;&#28857;&#20987;&#21644;&#21152;&#20837;&#36141;&#29289;&#36710;&#65289;&#26469;&#24110;&#21161;&#39044;&#27979;&#29992;&#25143;&#22312;&#30446;&#26631;&#34892;&#20026;&#65288;&#20363;&#22914;&#36141;&#20080;&#65289;&#19978;&#30340;&#28508;&#22312;&#20132;&#20114;&#65292;&#34987;&#35748;&#20026;&#26159;&#32531;&#35299;&#25512;&#33616;&#31995;&#32479;&#25968;&#25454;&#31232;&#30095;&#25110;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#65292;&#22810;&#20010;&#34892;&#20026;&#36890;&#24120;&#25353;&#29305;&#23450;&#39034;&#24207;&#36827;&#34892;&#65288;&#20363;&#22914;&#28857;&#20987;&gt;&#21152;&#20837;&#36141;&#29289;&#36710;&gt;&#36141;&#20080;&#65289;&#12290;&#22312;&#34892;&#20026;&#38142;&#20013;&#65292;&#21518;&#32493;&#34892;&#20026;&#36890;&#24120;&#27604;&#21069;&#38754;&#30340;&#34892;&#20026;&#23637;&#29616;&#20986;&#26356;&#24378;&#30340;&#29992;&#25143;&#20559;&#22909;&#20449;&#21495;&#12290;&#29616;&#26377;&#30340;&#22810;&#34892;&#20026;&#27169;&#22411;&#22823;&#22810;&#26410;&#33021;&#25235;&#20303;&#27492;&#31867;&#34892;&#20026;&#38142;&#20013;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32423;&#32852;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26032;&#22411;&#22810;&#34892;&#20026;&#25512;&#33616;&#27169;&#22411;&#65288;&#31216;&#20026;MB-CGCN&#65289;&#12290;&#22312;MB-CGCN&#20013;&#65292;&#32463;&#36807;&#29305;&#24449;&#21464;&#25442;&#25805;&#20316;&#21518;&#65292;&#20174;&#19968;&#20010;&#34892;&#20026;&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#34987;&#29992;&#20316;&#19979;&#19968;&#20010;&#34892;&#20026;&#23884;&#20837;&#23398;&#20064;&#30340;&#36755;&#20837;&#29305;&#24449;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#26126;&#30830;&#22320;&#21033;&#29992;&#20102;&#23884;&#20837;&#23398;&#20064;&#20013;&#30340;&#34892;&#20026;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-behavior recommendation, which exploits auxiliary behaviors (e.g., click and cart) to help predict users' potential interactions on the target behavior (e.g., buy), is regarded as an effective way to alleviate the data sparsity or cold-start issues in recommendation. Multi-behaviors are often taken in certain orders in real-world applications (e.g., click&gt;cart&gt;buy). In a behavior chain, a latter behavior usually exhibits a stronger signal of user preference than the former one does. Most existing multi-behavior models fail to capture such dependencies in a behavior chain for embedding learning. In this work, we propose a novel multi-behavior recommendation model with cascading graph convolution networks (named MB-CGCN). In MB-CGCN, the embeddings learned from one behavior are used as the input features for the next behavior's embedding learning after a feature transformation operation. In this way, our model explicitly utilizes the behavior dependencies in embedding learning. Exp
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#20687;&#25490;&#21517;&#31639;&#27861;&#65292;&#20351;&#29992;&#32423;&#32852;&#30340;&#31070;&#32463;&#32534;&#30721;&#22120;&#26469;&#36880;&#27493;&#36807;&#28388;&#22270;&#20687;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;3&#20493;&#20197;&#19978;&#30340;TIR&#29983;&#21629;&#21608;&#26399;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2303.15595</link><description>&lt;p&gt;
&#39640;&#25928;&#22270;&#20687;&#25628;&#32034;&#30340;&#27169;&#22411;&#32423;&#32852;
&lt;/p&gt;
&lt;p&gt;
Model Cascades for Efficient Image Search. (arXiv:2303.15595v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15595
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#20687;&#25490;&#21517;&#31639;&#27861;&#65292;&#20351;&#29992;&#32423;&#32852;&#30340;&#31070;&#32463;&#32534;&#30721;&#22120;&#26469;&#36880;&#27493;&#36807;&#28388;&#22270;&#20687;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;3&#20493;&#20197;&#19978;&#30340;TIR&#29983;&#21629;&#21608;&#26399;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31070;&#32463;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#25991;&#26412;-&#22270;&#20687;&#26816;&#32034;&#65288;TIR&#65289;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#39640;&#26114;&#30340;&#35745;&#31639;&#25104;&#26412;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#22823;&#35268;&#27169;&#22270;&#20687;&#25628;&#32034;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#20687;&#25490;&#21517;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36880;&#27493;&#22686;&#24378;&#30340;&#31070;&#32463;&#32534;&#30721;&#22120;&#32423;&#32852;&#36880;&#27493;&#25353;&#29031;&#23427;&#20204;&#19982;&#32473;&#23450;&#30340;&#25991;&#26412;&#21305;&#37197;&#30340;&#22909;&#22351;&#31243;&#24230;&#26469;&#36807;&#28388;&#22270;&#20687;&#12290; &#25105;&#20204;&#30340;&#31639;&#27861;&#23558;TIR&#30340;&#29983;&#21629;&#21608;&#26399;&#25104;&#26412;&#38477;&#20302;&#20102;3&#20493;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern neural encoders offer unprecedented text-image retrieval (TIR) accuracy. However, their high computational cost impedes an adoption to large-scale image searches. We propose a novel image ranking algorithm that uses a cascade of increasingly powerful neural encoders to progressively filter images by how well they match a given text. Our algorithm reduces lifetime TIR costs by over 3x.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;GETT-QA&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#20351;&#29992;T5&#23545;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#29983;&#25104;&#31616;&#21270;&#30340;SPARQL&#26597;&#35810;&#65292;&#24182;&#20351;&#29992;&#25130;&#26029;&#30340;KG&#23884;&#20837;&#25552;&#39640;&#20102;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.13284</link><description>&lt;p&gt;
GETT-QA&#65306;&#22522;&#20110;&#22270;&#23884;&#20837;&#30340;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#20013;&#30340;T2T Transformer
&lt;/p&gt;
&lt;p&gt;
GETT-QA: Graph Embedding based T2T Transformer for Knowledge Graph Question Answering. (arXiv:2303.13284v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;GETT-QA&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#20351;&#29992;T5&#23545;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#29983;&#25104;&#31616;&#21270;&#30340;SPARQL&#26597;&#35810;&#65292;&#24182;&#20351;&#29992;&#25130;&#26029;&#30340;KG&#23884;&#20837;&#25552;&#39640;&#20102;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GETT-QA&#30340;&#31471;&#21040;&#31471;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#31995;&#32479;&#12290;GETT-QA&#20351;&#29992;&#20102;T5&#65292;&#36825;&#26159;&#19968;&#31181;&#28909;&#38376;&#30340;&#25991;&#26412;&#21040;&#25991;&#26412;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#20197;&#33258;&#28982;&#35821;&#35328;&#24418;&#24335;&#30340;&#38382;&#39064;&#20316;&#20026;&#36755;&#20837;&#24182;&#29983;&#25104;&#25152;&#38656;SPARQL&#26597;&#35810;&#30340;&#31616;&#21270;&#24418;&#24335;&#12290;&#22312;&#31616;&#21270;&#24418;&#24335;&#20013;&#65292;&#27169;&#22411;&#19981;&#30452;&#25509;&#29983;&#25104;&#23454;&#20307;&#21644;&#20851;&#31995;ID&#65292;&#32780;&#26159;&#20135;&#29983;&#30456;&#24212;&#30340;&#23454;&#20307;&#21644;&#20851;&#31995;&#26631;&#31614;&#12290;&#26631;&#31614;&#22312;&#38543;&#21518;&#30340;&#27493;&#39588;&#20013;&#19982;KG&#23454;&#20307;&#21644;&#20851;&#31995;ID&#32852;&#31995;&#36215;&#26469;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#65292;&#25105;&#20204;&#25351;&#23548;&#27169;&#22411;&#20026;&#27599;&#20010;&#23454;&#20307;&#29983;&#25104;KG&#23884;&#20837;&#30340;&#25130;&#26029;&#29256;&#26412;&#12290;&#25130;&#26029;&#30340;KG&#23884;&#20837;&#20351;&#24471;&#26356;&#31934;&#32454;&#30340;&#25628;&#32034;&#20174;&#32780;&#26356;&#26377;&#25928;&#36827;&#34892;&#28040;&#27495;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;T5&#33021;&#22815;&#22312;&#19981;&#25913;&#21464;&#25439;&#22833;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#25130;&#26029;&#30340;KG&#23884;&#20837;&#65292;&#25552;&#39640;&#20102;KGQA&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#22312;Wikidata&#30340;LC-QuAD 2.0&#21644;SimpleQuestions-Wikidata&#25968;&#25454;&#38598;&#19978;&#25253;&#21578;&#20102;&#31471;&#21040;&#31471;KGQA&#30340;&#24378;&#22823;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we present an end-to-end Knowledge Graph Question Answering (KGQA) system named GETT-QA. GETT-QA uses T5, a popular text-to-text pre-trained language model. The model takes a question in natural language as input and produces a simpler form of the intended SPARQL query. In the simpler form, the model does not directly produce entity and relation IDs. Instead, it produces corresponding entity and relation labels. The labels are grounded to KG entity and relation IDs in a subsequent step. To further improve the results, we instruct the model to produce a truncated version of the KG embedding for each entity. The truncated KG embedding enables a finer search for disambiguation purposes. We find that T5 is able to learn the truncated KG embeddings without any change of loss function, improving KGQA performance. As a result, we report strong results for LC-QuAD 2.0 and SimpleQuestions-Wikidata datasets on end-to-end KGQA over Wikidata.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#24191;&#20041;&#22522;&#23612;&#31119;&#21033;&#20989;&#25968;&#65288;GGF&#65289;&#20316;&#20026;&#35268;&#33539;&#24615;&#20934;&#21017;&#26469;&#25351;&#23450;&#25512;&#33616;&#31995;&#32479;&#24212;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#27492;&#23454;&#29616;&#25490;&#21517;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2204.06521</link><description>&lt;p&gt;
&#20248;&#21270;&#24191;&#20041;&#22522;&#23612;&#25351;&#25968;&#23454;&#29616;&#25490;&#21517;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimizing generalized Gini indices for fairness in rankings. (arXiv:2204.06521v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.06521
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#24191;&#20041;&#22522;&#23612;&#31119;&#21033;&#20989;&#25968;&#65288;GGF&#65289;&#20316;&#20026;&#35268;&#33539;&#24615;&#20934;&#21017;&#26469;&#25351;&#23450;&#25512;&#33616;&#31995;&#32479;&#24212;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#27492;&#23454;&#29616;&#25490;&#21517;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#20851;&#27880;&#35774;&#35745;&#33021;&#22815;&#23545;&#29289;&#21697;&#29983;&#20135;&#32773;&#25110;&#26368;&#19981;&#28385;&#24847;&#29992;&#25143;&#20844;&#24179;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#21463;&#32463;&#27982;&#23398;&#19981;&#24179;&#31561;&#27979;&#37327;&#39046;&#22495;&#30340;&#21551;&#21457;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#24191;&#20041;&#22522;&#23612;&#31119;&#21033;&#20989;&#25968;&#65288;GGF&#65289;&#20316;&#20026;&#35268;&#33539;&#24615;&#20934;&#21017;&#26469;&#25351;&#23450;&#25512;&#33616;&#31995;&#32479;&#24212;&#20248;&#21270;&#30340;&#26041;&#27861;&#12290;GGF&#26681;&#25454;&#20154;&#21475;&#26222;&#26597;&#20013;&#30340;&#25490;&#21517;&#23545;&#20010;&#20307;&#36827;&#34892;&#21152;&#26435;&#65292;&#23558;&#26356;&#22810;&#30340;&#26435;&#37325;&#25918;&#22312;&#22788;&#22659;&#36739;&#24046;&#30340;&#20010;&#20307;&#19978;&#20197;&#20419;&#36827;&#24179;&#31561;&#12290;&#26681;&#25454;&#36825;&#20123;&#26435;&#37325;&#65292;GGF&#26368;&#23567;&#21270;&#29289;&#21697;&#26333;&#20809;&#30340;&#22522;&#23612;&#25351;&#25968;&#65292;&#20197;&#20419;&#36827;&#29289;&#21697;&#20043;&#38388;&#30340;&#24179;&#31561;&#65292;&#25110;&#20851;&#27880;&#26368;&#19981;&#28385;&#24847;&#29992;&#25143;&#30340;&#29305;&#23450;&#20998;&#20301;&#25968;&#30340;&#24615;&#33021;&#12290;&#25490;&#21517;&#30340;GGF&#38590;&#20197;&#20248;&#21270;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#19981;&#21487;&#24494;&#20998;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#38750;&#24179;&#28369;&#20248;&#21270;&#21644;&#21487;&#24494;&#25490;&#24207;&#20013;&#20351;&#29992;&#30340;&#25237;&#24433;&#31639;&#23376;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;&#25105;&#20204;&#20351;&#29992;&#26368;&#22810;&#26377;15k&#20010;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#20248;&#21270;GGF&#26377;&#25928;&#22320;&#20419;&#36827;&#25490;&#21517;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is growing interest in designing recommender systems that aim at being fair towards item producers or their least satisfied users. Inspired by the domain of inequality measurement in economics, this paper explores the use of generalized Gini welfare functions (GGFs) as a means to specify the normative criterion that recommender systems should optimize for. GGFs weight individuals depending on their ranks in the population, giving more weight to worse-off individuals to promote equality. Depending on these weights, GGFs minimize the Gini index of item exposure to promote equality between items, or focus on the performance on specific quantiles of least satisfied users. GGFs for ranking are challenging to optimize because they are non-differentiable. We resolve this challenge by leveraging tools from non-smooth optimization and projection operators used in differentiable sorting. We present experiments using real datasets with up to 15k users and items, which show that our approach
&lt;/p&gt;</description></item></channel></rss>