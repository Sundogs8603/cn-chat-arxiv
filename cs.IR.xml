<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25209;&#21028;&#24615;&#23457;&#35270;&#20102;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.15053</link><description>&lt;p&gt;
&#20851;&#20110;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#30340;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#35770;&#25991;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
On (Normalised) Discounted Cumulative Gain as an Offline Evaluation Metric for Top-$n$ Recommendation. (arXiv:2307.15053v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25209;&#21028;&#24615;&#23457;&#35270;&#20102;(Normalised) Discounted Cumulative Gain&#20316;&#20026;Top-n&#25512;&#33616;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#26041;&#27861;&#36890;&#24120;&#36890;&#36807;&#20004;&#31181;&#26041;&#24335;&#36827;&#34892;&#35780;&#20272;&#65306;(1) &#36890;&#36807;(&#27169;&#25311;)&#22312;&#32447;&#23454;&#39564;&#65292;&#36890;&#24120;&#34987;&#35270;&#20026;&#37329;&#26631;&#20934;&#65292;&#25110;&#32773;(2) &#36890;&#36807;&#19968;&#20123;&#31163;&#32447;&#35780;&#20272;&#31243;&#24207;&#65292;&#30446;&#26631;&#26159;&#36817;&#20284;&#22312;&#32447;&#23454;&#39564;&#30340;&#32467;&#26524;&#12290;&#25991;&#29486;&#20013;&#37319;&#29992;&#20102;&#20960;&#31181;&#31163;&#32447;&#35780;&#20272;&#25351;&#26631;&#65292;&#21463;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#20013;&#24120;&#35265;&#30340;&#25490;&#21517;&#25351;&#26631;&#30340;&#21551;&#21457;&#12290;(Normalised) Discounted Cumulative Gain (nDCG)&#26159;&#20854;&#20013;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#22312;&#24456;&#22810;&#24180;&#37324;&#65292;&#26356;&#39640;&#30340;(n)DCG&#20540;&#34987;&#29992;&#26469;&#23637;&#31034;&#26032;&#26041;&#27861;&#22312;Top-n&#25512;&#33616;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#30340;&#23457;&#35270;&#65292;&#24182;&#30740;&#31350;&#20102;&#25105;&#20204;&#20309;&#26102;&#21487;&#20197;&#26399;&#26395;&#36825;&#20123;&#25351;&#26631;&#36924;&#36817;&#22312;&#32447;&#23454;&#39564;&#30340;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;&#25105;&#20204;&#20174;&#31532;&#19968;&#21407;&#29702;&#19978;&#27491;&#24335;&#25552;&#20986;&#20102;DCG&#34987;&#35748;&#20026;&#26159;&#22312;&#32447;&#22870;&#21169;&#30340;&#26080;&#20559;&#20272;&#35745;&#30340;&#20551;&#35774;&#65292;&#24182;&#32473;&#20986;&#20102;&#36825;&#20010;&#25351;&#26631;&#30340;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approaches to recommendation are typically evaluated in one of two ways: (1) via a (simulated) online experiment, often seen as the gold standard, or (2) via some offline evaluation procedure, where the goal is to approximate the outcome of an online experiment. Several offline evaluation metrics have been adopted in the literature, inspired by ranking metrics prevalent in the field of Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one such metric that has seen widespread adoption in empirical studies, and higher (n)DCG values have been used to present new methods as the state-of-the-art in top-$n$ recommendation for many years.  Our work takes a critical look at this approach, and investigates when we can expect such metrics to approximate the gold standard outcome of an online experiment. We formally present the assumptions that are necessary to consider DCG an unbiased estimator of online reward and provide a derivation for this metric from first principles
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#26816;&#26597;&#31532;&#19977;&#26041;&#23454;&#29616;&#22914;&#20309;&#23545;&#21487;&#37325;&#22797;&#24615;&#20135;&#29983;&#24433;&#21709;&#65292;&#20026;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#30340;&#21487;&#37325;&#22797;&#24615;&#38382;&#39064;&#22686;&#21152;&#20102;&#19968;&#20010;&#26032;&#30340;&#35282;&#24230;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#38750;&#23448;&#26041;&#31532;&#19977;&#26041;&#23454;&#29616;&#21487;&#33021;&#20250;&#23545;&#21487;&#37325;&#22797;&#24615;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#65292;&#24182;&#21628;&#21505;&#30740;&#31350;&#30028;&#23545;&#36825;&#19968;&#34987;&#24573;&#35270;&#30340;&#38382;&#39064;&#20104;&#20197;&#20851;&#27880;&#12290;</title><link>http://arxiv.org/abs/2307.14956</link><description>&lt;p&gt;
&#31532;&#19977;&#26041;&#23454;&#29616;&#23545;&#21487;&#37325;&#22797;&#24615;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Effect of Third Party Implementations on Reproducibility. (arXiv:2307.14956v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14956
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#26816;&#26597;&#31532;&#19977;&#26041;&#23454;&#29616;&#22914;&#20309;&#23545;&#21487;&#37325;&#22797;&#24615;&#20135;&#29983;&#24433;&#21709;&#65292;&#20026;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#30340;&#21487;&#37325;&#22797;&#24615;&#38382;&#39064;&#22686;&#21152;&#20102;&#19968;&#20010;&#26032;&#30340;&#35282;&#24230;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#38750;&#23448;&#26041;&#31532;&#19977;&#26041;&#23454;&#29616;&#21487;&#33021;&#20250;&#23545;&#21487;&#37325;&#22797;&#24615;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#65292;&#24182;&#21628;&#21505;&#30740;&#31350;&#30028;&#23545;&#36825;&#19968;&#34987;&#24573;&#35270;&#30340;&#38382;&#39064;&#20104;&#20197;&#20851;&#27880;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#30340;&#21487;&#37325;&#22797;&#24615;&#21463;&#21040;&#20102;&#20851;&#27880;&#12290;&#38500;&#20102;&#20851;&#27880;&#20351;&#29992;&#29305;&#23450;&#31639;&#27861;&#37325;&#22797;&#23454;&#39564;&#30340;&#24037;&#20316;&#22806;&#65292;&#30740;&#31350;&#30028;&#36824;&#24320;&#22987;&#35752;&#35770;&#35780;&#20272;&#30340;&#21508;&#20010;&#26041;&#38754;&#20197;&#21450;&#23427;&#20204;&#22914;&#20309;&#24433;&#21709;&#21487;&#37325;&#22797;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#38750;&#23448;&#26041;&#31532;&#19977;&#26041;&#23454;&#29616;&#22914;&#20309;&#23545;&#21487;&#37325;&#22797;&#24615;&#20135;&#29983;&#24433;&#21709;&#65292;&#20026;&#36825;&#19968;&#35752;&#35770;&#22686;&#21152;&#20102;&#19968;&#20010;&#26032;&#30340;&#35282;&#24230;&#12290;&#38500;&#20102;&#25552;&#20379;&#19968;&#33324;&#27010;&#36848;&#22806;&#65292;&#25105;&#20204;&#36824;&#24443;&#24213;&#26816;&#26597;&#20102;&#20845;&#20010;&#27969;&#34892;&#25512;&#33616;&#31639;&#27861;&#30340;&#31532;&#19977;&#26041;&#23454;&#29616;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#20116;&#20010;&#20844;&#24320;&#25968;&#25454;&#38598;&#19978;&#30340;&#23448;&#26041;&#29256;&#26412;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26681;&#25454;&#25105;&#20204;&#20196;&#20154;&#38663;&#24778;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#24076;&#26395;&#24341;&#36215;&#30740;&#31350;&#30028;&#23545;&#36825;&#20010;&#34987;&#24573;&#35270;&#30340;&#21487;&#37325;&#22797;&#24615;&#26041;&#38754;&#30340;&#20851;&#27880;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reproducibility of recommender systems research has come under scrutiny during recent years. Along with works focusing on repeating experiments with certain algorithms, the research community has also started discussing various aspects of evaluation and how these affect reproducibility. We add a novel angle to this discussion by examining how unofficial third-party implementations could benefit or hinder reproducibility. Besides giving a general overview, we thoroughly examine six third-party implementations of a popular recommender algorithm and compare them to the official version on five public datasets. In the light of our alarming findings we aim to draw the attention of the research community to this neglected aspect of reproducibility.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#24191;&#27867;&#23384;&#22312;&#30340;&#25512;&#33616;&#31995;&#32479;&#31163;&#32447;&#35780;&#20272;&#20013;&#30340;&#22235;&#20010;&#32570;&#38519;&#65292;&#24182;&#35828;&#26126;&#20102;&#30740;&#31350;&#20154;&#21592;&#24212;&#35813;&#36991;&#20813;&#36825;&#20123;&#32570;&#38519;&#65292;&#20197;&#25552;&#39640;&#31163;&#32447;&#35780;&#20272;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.14951</link><description>&lt;p&gt;
&#31163;&#32447;&#35780;&#20272;&#20013;&#25512;&#33616;&#31995;&#32479;&#23384;&#22312;&#24191;&#27867;&#32570;&#38519;
&lt;/p&gt;
&lt;p&gt;
Widespread Flaws in Offline Evaluation of Recommender Systems. (arXiv:2307.14951v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14951
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#24191;&#27867;&#23384;&#22312;&#30340;&#25512;&#33616;&#31995;&#32479;&#31163;&#32447;&#35780;&#20272;&#20013;&#30340;&#22235;&#20010;&#32570;&#38519;&#65292;&#24182;&#35828;&#26126;&#20102;&#30740;&#31350;&#20154;&#21592;&#24212;&#35813;&#36991;&#20813;&#36825;&#20123;&#32570;&#38519;&#65292;&#20197;&#25552;&#39640;&#31163;&#32447;&#35780;&#20272;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31163;&#32447;&#35780;&#20272;&#21482;&#26159;&#22312;&#32447;&#24615;&#33021;&#30340;&#19981;&#23436;&#32654;&#20195;&#29702;&#65292;&#22240;&#20026;&#25512;&#33616;&#31995;&#32479;&#30340;&#20132;&#20114;&#24615;&#36136;&#65292;&#20294;&#30001;&#20110;&#29983;&#20135;&#25512;&#33616;&#31995;&#32479;&#30340;&#19987;&#26377;&#24615;&#36136;&#38459;&#27490;&#20102;A/B&#27979;&#35797;&#35774;&#32622;&#30340;&#29420;&#31435;&#39564;&#35777;&#21644;&#22312;&#32447;&#32467;&#26524;&#30340;&#39564;&#35777;&#65292;&#31163;&#32447;&#35780;&#20272;&#21487;&#33021;&#20173;&#28982;&#26159;&#21487;&#35265;&#30340;&#26410;&#26469;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#20013;&#30340;&#20027;&#35201;&#35780;&#20272;&#26041;&#24335;&#12290;&#22240;&#27492;&#65292;&#31163;&#32447;&#35780;&#20272;&#35774;&#32622;&#24517;&#39035;&#23613;&#21487;&#33021;&#30495;&#23454;&#21644;&#26080;&#29781;&#30133;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30001;&#20110;&#21518;&#26399;&#20316;&#21697;&#22797;&#21046;&#20102;&#21069;&#36744;&#20204;&#23384;&#22312;&#32570;&#38519;&#30340;&#35780;&#20272;&#35774;&#32622;&#32780;&#19981;&#36136;&#30097;&#20854;&#26377;&#25928;&#24615;&#65292;&#25152;&#20197;&#22312;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#20013;&#35780;&#20272;&#32570;&#38519;&#30456;&#24403;&#26222;&#36941;&#12290;&#20026;&#20102;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#30340;&#31163;&#32447;&#35780;&#20272;&#36136;&#37327;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20854;&#20013;&#22235;&#20010;&#24191;&#27867;&#23384;&#22312;&#30340;&#32570;&#38519;&#20197;&#21450;&#30740;&#31350;&#20154;&#21592;&#24212;&#35813;&#36991;&#20813;&#23427;&#20204;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
Even though offline evaluation is just an imperfect proxy of online performance -- due to the interactive nature of recommenders -- it will probably remain the primary way of evaluation in recommender systems research for the foreseeable future, since the proprietary nature of production recommenders prevents independent validation of A/B test setups and verification of online results. Therefore, it is imperative that offline evaluation setups are as realistic and as flawless as they can be. Unfortunately, evaluation flaws are quite common in recommender systems research nowadays, due to later works copying flawed evaluation setups from their predecessors without questioning their validity. In the hope of improving the quality of offline evaluation of recommender systems, we discuss four of these widespread flaws and why researchers should avoid them.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#22312;&#22823;&#35268;&#27169;&#30005;&#21830;&#25968;&#25454;&#38598;&#19978;&#36890;&#36807;&#38598;&#25104;&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.14906</link><description>&lt;p&gt;
&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions. (arXiv:2307.14906v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#22312;&#22823;&#35268;&#27169;&#30005;&#21830;&#25968;&#25454;&#38598;&#19978;&#36890;&#36807;&#38598;&#25104;&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;TRON&#65292;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#30340;&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#12290;&#21463;&#21040;SASRec&#21644;GRU4Rec+&#31561;&#29616;&#26377;&#27169;&#22411;&#22312;&#21487;&#25193;&#23637;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#38480;&#21046;&#65292;TRON&#38598;&#25104;&#20102;top-k&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#25552;&#39640;&#20854;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#22312;&#30456;&#20851;&#30340;&#22823;&#35268;&#27169;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;TRON&#22312;&#20445;&#25345;&#19982;SASRec&#31867;&#20284;&#30340;&#35757;&#32451;&#36895;&#24230;&#30340;&#21516;&#26102;&#65292;&#25913;&#36827;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#25512;&#33616;&#36136;&#37327;&#12290;&#19968;&#39033;&#23454;&#26102;&#30340;A/B&#27979;&#35797;&#26174;&#31034;&#65292;&#30456;&#23545;&#20110;SASRec&#65292;TRON&#30340;&#28857;&#20987;&#29575;&#22686;&#21152;&#20102;18.14%&#65292;&#31361;&#26174;&#20102;&#20854;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces TRON, a scalable session-based Transformer Recommender using Optimized Negative-sampling. Motivated by the scalability and performance limitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates top-k negative sampling and listwise loss functions to enhance its recommendation accuracy. Evaluations on relevant large-scale e-commerce datasets show that TRON improves upon the recommendation quality of current methods while maintaining training speeds similar to SASRec. A live A/B test yielded an 18.14% increase in click-through rate over SASRec, highlighting the potential of TRON in practical settings. For further research, we provide access to our source code at https://github.com/otto-de/TRON and an anonymized dataset at https://github.com/otto-de/recsys-dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#19982;Transformer&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#25512;&#33616;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#21644;&#31163;&#32447;RL&#31639;&#27861;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#31283;&#23450;&#22320;&#25910;&#25947;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#25512;&#33616;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.14450</link><description>&lt;p&gt;
&#23558;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#19982;Transformer&#30456;&#32467;&#21512;&#30340;&#39034;&#24207;&#25512;&#33616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Integrating Offline Reinforcement Learning with Transformers for Sequential Recommendation. (arXiv:2307.14450v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#19982;Transformer&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#25512;&#33616;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#21644;&#31163;&#32447;RL&#31639;&#27861;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#31283;&#23450;&#22320;&#25910;&#25947;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#25512;&#33616;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#39034;&#24207;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#21363;&#26681;&#25454;&#36807;&#21435;&#30340;&#20114;&#21160;&#36827;&#34892;&#24403;&#21069;&#25512;&#33616;&#12290;&#36825;&#20010;&#25512;&#33616;&#20219;&#21153;&#38656;&#35201;&#23545;&#39034;&#24207;&#25968;&#25454;&#36827;&#34892;&#39640;&#25928;&#22788;&#29702;&#65292;&#24182;&#26088;&#22312;&#25552;&#20379;&#26368;&#22823;&#21270;&#38271;&#26399;&#22870;&#21169;&#30340;&#25512;&#33616;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#31163;&#32447;RL&#31639;&#27861;&#21644;&#25105;&#20204;&#27169;&#22411;&#26550;&#26500;&#20013;&#30340;&#31574;&#30053;&#32593;&#32476;&#36827;&#34892;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#26550;&#26500;&#20174;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#21021;&#22987;&#21270;&#12290;&#39044;&#35757;&#32451;&#27169;&#22411;&#21033;&#29992;Transformer&#22788;&#29702;&#39034;&#24207;&#20449;&#24687;&#30340;&#20248;&#31168;&#33021;&#21147;&#12290;&#19982;&#20381;&#36182;&#22312;&#32447;&#20132;&#20114;&#30340;&#27169;&#25311;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#23454;&#29616;&#19968;&#31181;&#23436;&#20840;&#31163;&#32447;&#30340;RL&#26694;&#26550;&#65292;&#33021;&#22815;&#24555;&#36895;&#31283;&#23450;&#22320;&#25910;&#25947;&#12290;&#36890;&#36807;&#23545;&#20844;&#20849;&#25968;&#25454;&#38598;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#25512;&#33616;&#22330;&#26223;&#20013;&#65288;&#21253;&#25324;&#30005;&#23376;&#21830;&#21153;&#21644;&#30005;&#24433;&#25512;&#33616;&#65289;&#30340;&#31283;&#20581;&#24615;&#12290;&#19982;&#26368;&#20808;&#36827;&#30340;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20135;&#29983;&#20102;&#26356;&#22909;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sequential recommendation, where the current recommendation is made based on past interactions. This recommendation task requires efficient processing of the sequential data and aims to provide recommendations that maximize the long-term reward. To this end, we train a farsighted recommender by using an offline RL algorithm with the policy network in our model architecture that has been initialized from a pre-trained transformer model. The pre-trained model leverages the superb ability of the transformer to process sequential information. Compared to prior works that rely on online interaction via simulation, we focus on implementing a fully offline RL framework that is able to converge in a fast and stable way. Through extensive experiments on public datasets, we show that our method is robust across various recommendation regimes, including e-commerce and movie suggestions. Compared to state-of-the-art supervised learning algorithms, our algorithm yields re
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#22823;&#37327;&#30340;Wikidata&#39033;&#30446;&#21644;&#32500;&#22522;&#30334;&#31185;&#25991;&#31456;&#65292;&#20840;&#29699;&#27604;&#36739;&#20998;&#26512;&#20102;&#32500;&#22522;&#30334;&#31185;&#19981;&#21516;&#35821;&#35328;&#29256;&#26412;&#20013;&#23545;&#32654;&#22269;&#20027;&#39064;&#30340;&#35206;&#30422;&#29575;&#65292;&#30740;&#31350;&#21457;&#29616;&#32654;&#22269;&#21270;&#22312;&#19981;&#21516;&#22320;&#21306;&#21644;&#25991;&#21270;&#20013;&#30340;&#22320;&#20301;&#19981;&#21516;&#65292;&#24182;&#19988;&#23545;&#32654;&#22269;&#20027;&#39064;&#30340;&#20852;&#36259;&#26222;&#36941;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2307.14401</link><description>&lt;p&gt;
&#27979;&#37327;&#32654;&#22269;&#21270;&#65306;&#20851;&#20110;&#32500;&#22522;&#30334;&#31185;&#23545;&#32654;&#22269;&#20027;&#39064;&#30340;&#20840;&#29699;&#23450;&#37327;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Measuring Americanization: A Global Quantitative Study of Interest in American Topics on Wikipedia. (arXiv:2307.14401v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#22823;&#37327;&#30340;Wikidata&#39033;&#30446;&#21644;&#32500;&#22522;&#30334;&#31185;&#25991;&#31456;&#65292;&#20840;&#29699;&#27604;&#36739;&#20998;&#26512;&#20102;&#32500;&#22522;&#30334;&#31185;&#19981;&#21516;&#35821;&#35328;&#29256;&#26412;&#20013;&#23545;&#32654;&#22269;&#20027;&#39064;&#30340;&#35206;&#30422;&#29575;&#65292;&#30740;&#31350;&#21457;&#29616;&#32654;&#22269;&#21270;&#22312;&#19981;&#21516;&#22320;&#21306;&#21644;&#25991;&#21270;&#20013;&#30340;&#22320;&#20301;&#19981;&#21516;&#65292;&#24182;&#19988;&#23545;&#32654;&#22269;&#20027;&#39064;&#30340;&#20852;&#36259;&#26222;&#36941;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;9&#21315;&#19975;&#20010;Wikidata&#39033;&#30446;&#21644;5800&#19975;&#20010;&#32500;&#22522;&#30334;&#31185;&#25991;&#31456;&#65292;&#23545;58&#31181;&#35821;&#35328;&#29256;&#26412;&#30340;&#32500;&#22522;&#30334;&#31185;&#20013;&#20851;&#20110;&#32654;&#22269;&#20027;&#39064;&#30340;&#35206;&#30422;&#29575;&#36827;&#34892;&#20102;&#20840;&#29699;&#27604;&#36739;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26088;&#22312;&#35843;&#26597;&#32654;&#22269;&#21270;&#22312;&#19981;&#21516;&#22320;&#21306;&#21644;&#25991;&#21270;&#20013;&#26159;&#21542;&#26356;&#21152;&#21344;&#20027;&#23548;&#22320;&#20301;&#65292;&#24182;&#30830;&#23450;&#23545;&#32654;&#22269;&#20027;&#39064;&#30340;&#20852;&#36259;&#26159;&#21542;&#26222;&#36941;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
We conducted a global comparative analysis of the coverage of American topics in different language versions of Wikipedia, using over 90 million Wikidata items and 40 million Wikipedia articles in 58 languages. Our study aimed to investigate whether Americanization is more or less dominant in different regions and cultures and to determine whether interest in American topics is universal.
&lt;/p&gt;</description></item><item><title>RRAML&#26159;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#19982;&#29992;&#25143;&#25552;&#20379;&#30340;&#24222;&#22823;&#25968;&#25454;&#24211;&#20013;&#30340;&#25903;&#25345;&#20449;&#24687;&#30456;&#32467;&#21512;&#12290;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#36827;&#23637;&#65292;&#35813;&#26041;&#27861;&#25104;&#21151;&#35299;&#20915;&#20102;&#20960;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.12798</link><description>&lt;p&gt;
RRAML: &#24378;&#21270;&#26816;&#32034;&#22686;&#24378;&#30340;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
RRAML: Reinforced Retrieval Augmented Machine Learning. (arXiv:2307.12798v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12798
&lt;/p&gt;
&lt;p&gt;
RRAML&#26159;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#19982;&#29992;&#25143;&#25552;&#20379;&#30340;&#24222;&#22823;&#25968;&#25454;&#24211;&#20013;&#30340;&#25903;&#25345;&#20449;&#24687;&#30456;&#32467;&#21512;&#12290;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#36827;&#23637;&#65292;&#35813;&#26041;&#27861;&#25104;&#21151;&#35299;&#20915;&#20102;&#20960;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#24443;&#24213;&#25913;&#21464;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#30456;&#20851;&#39046;&#22495;&#65292;&#22312;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#25805;&#20316;&#20154;&#31867;&#35821;&#35328;&#26041;&#38754;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#22522;&#20110;API&#30340;&#25991;&#26412;&#25552;&#31034;&#25552;&#20132;&#26469;&#20351;&#29992;&#23427;&#20204;&#20250;&#23384;&#22312;&#19968;&#23450;&#30340;&#38480;&#21046;&#65292;&#21253;&#25324;&#19978;&#19979;&#25991;&#32422;&#26463;&#21644;&#22806;&#37096;&#36164;&#28304;&#30340;&#21487;&#29992;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#24378;&#21270;&#26816;&#32034;&#22686;&#24378;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;RRAML&#65289;&#12290;RRAML&#23558;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#19982;&#30001;&#19987;&#29992;&#26816;&#32034;&#22120;&#20174;&#29992;&#25143;&#25552;&#20379;&#30340;&#24222;&#22823;&#25968;&#25454;&#24211;&#20013;&#26816;&#32034;&#21040;&#30340;&#25903;&#25345;&#20449;&#24687;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20960;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#23427;&#32469;&#36807;&#20102;&#35775;&#38382;LLM&#26799;&#24230;&#30340;&#38656;&#27714;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20943;&#36731;&#20102;&#38024;&#23545;&#29305;&#23450;&#20219;&#21153;&#37325;&#26032;&#35757;&#32451;LLMs&#30340;&#36127;&#25285;&#65292;&#22240;&#20026;&#30001;&#20110;&#23545;&#27169;&#22411;&#21644;&#21512;&#20316;&#30340;&#35775;&#38382;&#21463;&#38480;&#65292;&#36825;&#24448;&#24448;&#26159;&#19981;&#21487;&#34892;&#25110;&#19981;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of large language models (LLMs) has revolutionized machine learning and related fields, showcasing remarkable abilities in comprehending, generating, and manipulating human language. However, their conventional usage through API-based text prompt submissions imposes certain limitations in terms of context constraints and external source availability. To address these challenges, we propose a novel framework called Reinforced Retrieval Augmented Machine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs with supporting information retrieved by a purpose-built retriever from a vast user-provided database. By leveraging recent advancements in reinforcement learning, our method effectively addresses several critical challenges. Firstly, it circumvents the need for accessing LLM gradients. Secondly, our method alleviates the burden of retraining LLMs for specific tasks, as it is often impractical or impossible due to restricted access to the model and the co
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24635;&#32467;&#20102;&#20013;&#22269;&#20449;&#24687;&#26816;&#32034;&#30028;&#20851;&#20110;&#20449;&#24687;&#26816;&#32034;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#25112;&#30053;&#25253;&#21578;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25991;&#26412;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#30693;&#35782;&#25512;&#29702;&#26041;&#38754;&#20855;&#26377;&#20986;&#33394;&#33021;&#21147;&#65292;&#20026;&#20449;&#24687;&#26816;&#32034;&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#30340;&#26041;&#21521;&#12290;&#27492;&#22806;&#65292;IR&#27169;&#22411;&#12289;LLM&#21644;&#20154;&#31867;&#20043;&#38388;&#30340;&#21327;&#21516;&#20851;&#31995;&#24418;&#25104;&#20102;&#19968;&#31181;&#26356;&#24378;&#22823;&#30340;&#20449;&#24687;&#23547;&#27714;&#25216;&#26415;&#33539;&#24335;&#12290;&#28982;&#32780;&#65292;&#35813;&#39046;&#22495;&#20173;&#38754;&#20020;&#35745;&#31639;&#25104;&#26412;&#12289;&#21487;&#20449;&#24230;&#12289;&#39046;&#22495;&#29305;&#23450;&#38480;&#21046;&#21644;&#20262;&#29702;&#32771;&#34385;&#31561;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.09751</link><description>&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#36935;&#19978;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#20013;&#22269;&#20449;&#24687;&#26816;&#32034;&#30028;&#30340;&#25112;&#30053;&#25253;&#21578;
&lt;/p&gt;
&lt;p&gt;
Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community. (arXiv:2307.09751v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24635;&#32467;&#20102;&#20013;&#22269;&#20449;&#24687;&#26816;&#32034;&#30028;&#20851;&#20110;&#20449;&#24687;&#26816;&#32034;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#25112;&#30053;&#25253;&#21578;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25991;&#26412;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#30693;&#35782;&#25512;&#29702;&#26041;&#38754;&#20855;&#26377;&#20986;&#33394;&#33021;&#21147;&#65292;&#20026;&#20449;&#24687;&#26816;&#32034;&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#30340;&#26041;&#21521;&#12290;&#27492;&#22806;&#65292;IR&#27169;&#22411;&#12289;LLM&#21644;&#20154;&#31867;&#20043;&#38388;&#30340;&#21327;&#21516;&#20851;&#31995;&#24418;&#25104;&#20102;&#19968;&#31181;&#26356;&#24378;&#22823;&#30340;&#20449;&#24687;&#23547;&#27714;&#25216;&#26415;&#33539;&#24335;&#12290;&#28982;&#32780;&#65292;&#35813;&#39046;&#22495;&#20173;&#38754;&#20020;&#35745;&#31639;&#25104;&#26412;&#12289;&#21487;&#20449;&#24230;&#12289;&#39046;&#22495;&#29305;&#23450;&#38480;&#21046;&#21644;&#20262;&#29702;&#32771;&#34385;&#31561;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#39046;&#22495;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#21457;&#23637;&#65292;&#36229;&#36234;&#20102;&#20256;&#32479;&#25628;&#32034;&#65292;&#20197;&#28385;&#36275;&#22810;&#26679;&#21270;&#30340;&#29992;&#25143;&#20449;&#24687;&#38656;&#27714;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#25991;&#26412;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#30693;&#35782;&#25512;&#29702;&#26041;&#38754;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#33021;&#21147;&#65292;&#20026;IR&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#30340;&#22865;&#26426;&#12290;LLM&#19981;&#20165;&#33021;&#22815;&#20419;&#36827;&#29983;&#25104;&#24335;&#26816;&#32034;&#65292;&#36824;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#29992;&#25143;&#29702;&#35299;&#12289;&#27169;&#22411;&#35780;&#20272;&#21644;&#29992;&#25143;&#31995;&#32479;&#20132;&#20114;&#26041;&#26696;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;IR&#27169;&#22411;&#12289;LLM&#21644;&#20154;&#31867;&#20043;&#38388;&#30340;&#21327;&#21516;&#20851;&#31995;&#26500;&#25104;&#20102;&#19968;&#31181;&#26356;&#24378;&#22823;&#30340;&#20449;&#24687;&#23547;&#27714;&#25216;&#26415;&#33539;&#24335;&#12290;IR&#27169;&#22411;&#25552;&#20379;&#23454;&#26102;&#21644;&#30456;&#20851;&#30340;&#20449;&#24687;&#65292;LLM&#36129;&#29486;&#20869;&#37096;&#30693;&#35782;&#65292;&#32780;&#20154;&#31867;&#22312;&#20449;&#24687;&#26381;&#21153;&#30340;&#21487;&#38752;&#24615;&#26041;&#38754;&#36215;&#30528;&#38656;&#27714;&#32773;&#21644;&#35780;&#20272;&#32773;&#30340;&#20013;&#24515;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#30528;&#19968;&#20123;&#37325;&#35201;&#25361;&#25112;&#65292;&#21253;&#25324;&#35745;&#31639;&#25104;&#26412;&#12289;&#21487;&#20449;&#24230;&#38382;&#39064;&#12289;&#39046;&#22495;&#29305;&#23450;&#38480;&#21046;&#21644;&#20262;&#29702;&#32771;&#34385;&#12290;
&lt;/p&gt;
&lt;p&gt;
The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#21305;&#37197;&#24066;&#22330;&#20013;&#22522;&#20110;&#21487;&#36716;&#31227;&#25928;&#29992;&#30340;&#20114;&#24800;&#25512;&#33616;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#19981;&#20381;&#36182;&#20855;&#20307;&#26816;&#35270;&#26041;&#27861;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.09060</link><description>&lt;p&gt;
&#22312;&#21305;&#37197;&#24066;&#22330;&#20013;&#24555;&#36895;&#19988;&#19981;&#20381;&#36182;&#20855;&#20307;&#26816;&#35270;&#26041;&#27861;&#30340;&#20114;&#24800;&#25512;&#33616;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast and Examination-agnostic Reciprocal Recommendation in Matching Markets. (arXiv:2306.09060v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#21305;&#37197;&#24066;&#22330;&#20013;&#22522;&#20110;&#21487;&#36716;&#31227;&#25928;&#29992;&#30340;&#20114;&#24800;&#25512;&#33616;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#19981;&#20381;&#36182;&#20855;&#20307;&#26816;&#35270;&#26041;&#27861;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32844;&#20301;&#21457;&#24067;&#21644;&#22312;&#32447;&#32422;&#20250;&#24179;&#21488;&#31561;&#21305;&#37197;&#24066;&#22330;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#22312;&#24179;&#21488;&#30340;&#25104;&#21151;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#19982;&#21521;&#29992;&#25143;&#25512;&#33616;&#29289;&#21697;&#30340;&#26631;&#20934;&#25512;&#33616;&#31995;&#32479;&#19981;&#21516;&#65292;&#20114;&#24800;&#25512;&#33616;&#31995;&#32479;&#38656;&#35201;&#32771;&#34385;&#29992;&#25143;&#20043;&#38388;&#30340;&#20849;&#21516;&#20852;&#36259;&#12290;&#27492;&#22806;&#65292;&#30830;&#20445;&#25512;&#33616;&#26426;&#20250;&#19981;&#36807;&#20998;&#20559;&#21521;&#28909;&#38376;&#29992;&#25143;&#23545;&#20110;&#21305;&#37197;&#25968;&#37327;&#21644;&#29992;&#25143;&#20844;&#24179;&#24615;&#37117;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#21305;&#37197;&#24066;&#22330;&#25512;&#33616;&#26041;&#27861;&#22312;&#22823;&#35268;&#27169;&#23454;&#38469;&#24212;&#29992;&#24179;&#21488;&#19978;&#38754;&#20020;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#19988;&#20381;&#36182;&#20110;&#22522;&#20110;&#32844;&#20301;&#30340;&#27169;&#22411;&#20013;&#29305;&#23450;&#30340;&#26816;&#35270;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22522;&#20110;&#21487;&#36716;&#31227;&#25928;&#29992;&#30340;&#21305;&#37197;&#27169;&#22411;&#30340;&#20114;&#24800;&#25512;&#33616;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24555;&#36895;&#19988;&#19981;&#20381;&#36182;&#20855;&#20307;&#26816;&#35270;&#26041;&#27861;&#30340;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
In matching markets such as job posting and online dating platforms, the recommender system plays a critical role in the success of the platform. Unlike standard recommender systems that suggest items to users, reciprocal recommender systems (RRSs) that suggest other users must take into account the mutual interests of users. In addition, ensuring that recommendation opportunities do not disproportionately favor popular users is essential for the total number of matches and for fairness among users. Existing recommendation methods in matching markets, however, face computational challenges on real-world scale platforms and depend on specific examination functions in the position-based model (PBM). In this paper, we introduce the reciprocal recommendation method based on the matching with transferable utility (TU matching) model in the context of ranking recommendations in matching markets, and propose a faster and examination-agnostic algorithm. Furthermore, we evaluate our approach on
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32534;&#30721;&#26041;&#24335;&#25915;&#20987;&#25628;&#32034;&#24341;&#25806;&#65292;&#20197;&#24494;&#19981;&#21487;&#35265;&#30340;&#26041;&#24335;&#25197;&#26354;&#25991;&#26412;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#25511;&#21046;&#25628;&#32034;&#32467;&#26524;&#12290;&#35813;&#25915;&#20987;&#25104;&#21151;&#22320;&#24433;&#21709;&#20102;Google&#12289;Bing&#21644;Elasticsearch&#31561;&#22810;&#20010;&#25628;&#32034;&#24341;&#25806;&#12290;&#27492;&#22806;&#65292;&#36824;&#21487;&#20197;&#23558;&#35813;&#25915;&#20987;&#38024;&#23545;&#25628;&#32034;&#30456;&#20851;&#30340;&#20219;&#21153;&#22914;&#25991;&#26412;&#25688;&#35201;&#21644;&#25220;&#34989;&#26816;&#27979;&#27169;&#22411;&#12290;&#38656;&#35201;&#25552;&#20379;&#19968;&#22871;&#26377;&#25928;&#30340;&#38450;&#24481;&#25514;&#26045;&#26469;&#24212;&#23545;&#36825;&#20123;&#25216;&#26415;&#24102;&#26469;&#30340;&#28508;&#22312;&#23041;&#32961;&#12290;</title><link>http://arxiv.org/abs/2304.14031</link><description>&lt;p&gt;
&#25552;&#21319;&#32769;&#22823;&#21733;&#65306;&#37319;&#29992;&#32534;&#30721;&#26041;&#24335;&#25915;&#20987;&#25628;&#32034;&#24341;&#25806;
&lt;/p&gt;
&lt;p&gt;
Boosting Big Brother: Attacking Search Engines with Encodings. (arXiv:2304.14031v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14031
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32534;&#30721;&#26041;&#24335;&#25915;&#20987;&#25628;&#32034;&#24341;&#25806;&#65292;&#20197;&#24494;&#19981;&#21487;&#35265;&#30340;&#26041;&#24335;&#25197;&#26354;&#25991;&#26412;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#25511;&#21046;&#25628;&#32034;&#32467;&#26524;&#12290;&#35813;&#25915;&#20987;&#25104;&#21151;&#22320;&#24433;&#21709;&#20102;Google&#12289;Bing&#21644;Elasticsearch&#31561;&#22810;&#20010;&#25628;&#32034;&#24341;&#25806;&#12290;&#27492;&#22806;&#65292;&#36824;&#21487;&#20197;&#23558;&#35813;&#25915;&#20987;&#38024;&#23545;&#25628;&#32034;&#30456;&#20851;&#30340;&#20219;&#21153;&#22914;&#25991;&#26412;&#25688;&#35201;&#21644;&#25220;&#34989;&#26816;&#27979;&#27169;&#22411;&#12290;&#38656;&#35201;&#25552;&#20379;&#19968;&#22871;&#26377;&#25928;&#30340;&#38450;&#24481;&#25514;&#26045;&#26469;&#24212;&#23545;&#36825;&#20123;&#25216;&#26415;&#24102;&#26469;&#30340;&#28508;&#22312;&#23041;&#32961;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#24341;&#25806;&#23545;&#20110;&#25991;&#26412;&#32534;&#30721;&#25805;&#32437;&#30340;&#32034;&#24341;&#21644;&#25628;&#32034;&#23384;&#22312;&#28431;&#27934;&#12290;&#36890;&#36807;&#20197;&#19981;&#24120;&#35265;&#30340;&#32534;&#30721;&#34920;&#31034;&#24418;&#24335;&#24494;&#19981;&#21487;&#35265;&#22320;&#25197;&#26354;&#25991;&#26412;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#25511;&#21046;&#29305;&#23450;&#25628;&#32034;&#26597;&#35810;&#22312;&#22810;&#20010;&#25628;&#32034;&#24341;&#25806;&#19978;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#31181;&#25915;&#20987;&#25104;&#21151;&#22320;&#38024;&#23545;&#20102;&#20004;&#20010;&#20027;&#35201;&#30340;&#21830;&#19994;&#25628;&#32034;&#24341;&#25806;&#8212;&#8212;Google&#21644;Bing&#8212;&#8212;&#20197;&#21450;&#19968;&#20010;&#24320;&#28304;&#25628;&#32034;&#24341;&#25806;&#8212;&#8212;Elasticsearch&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#36825;&#31181;&#25915;&#20987;&#25104;&#21151;&#22320;&#38024;&#23545;&#20102;&#21253;&#25324;Bing&#30340;GPT-4&#32842;&#22825;&#26426;&#22120;&#20154;&#21644;Google&#30340;Bard&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#20869;&#30340;LLM&#32842;&#22825;&#25628;&#32034;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#20307;&#25915;&#20987;&#65292;&#38024;&#23545;&#19982;&#25628;&#32034;&#23494;&#20999;&#30456;&#20851;&#30340;&#20004;&#20010;ML&#20219;&#21153;&#8212;&#8212;&#25991;&#26412;&#25688;&#35201;&#21644;&#25220;&#34989;&#26816;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#22871;&#38024;&#23545;&#36825;&#20123;&#25216;&#26415;&#30340;&#38450;&#24481;&#25514;&#26045;&#65292;&#24182;&#35686;&#21578;&#25915;&#20987;&#32773;&#21487;&#20197;&#21033;&#29992;&#36825;&#20123;&#25915;&#20987;&#21551;&#21160;&#21453;&#20449;&#24687;&#20105;&#22842;&#25112;&#12290;&#36825;&#20419;&#20351;&#25628;&#32034;&#24341;&#25806;&#32500;&#25252;&#20154;&#21592;&#20462;&#34917;&#24050;&#37096;&#32626;&#30340;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Search engines are vulnerable to attacks against indexing and searching via text encoding manipulation. By imperceptibly perturbing text using uncommon encoded representations, adversaries can control results across search engines for specific search queries. We demonstrate that this attack is successful against two major commercial search engines - Google and Bing - and one open source search engine - Elasticsearch. We further demonstrate that this attack is successful against LLM chat search including Bing's GPT-4 chatbot and Google's Bard chatbot. We also present a variant of the attack targeting text summarization and plagiarism detection models, two ML tasks closely tied to search. We provide a set of defenses against these techniques and warn that adversaries can leverage these attacks to launch disinformation campaigns against unsuspecting users, motivating the need for search engine maintainers to patch deployed systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;In-Context RALM&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30456;&#20851;&#25991;&#20214;&#20316;&#20026;&#36755;&#20837;&#30340;&#19968;&#37096;&#20998;&#65292;&#26080;&#38656;&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#36827;&#19968;&#27493;&#30340;&#35757;&#32451;&#21363;&#21487;&#26174;&#33879;&#25552;&#39640;&#35821;&#35328;&#24314;&#27169;&#24615;&#33021;&#21644;&#28304;&#24402;&#22240;&#33021;&#21147;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;RALM&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#26356;&#31616;&#21333;&#30340;&#37096;&#32626;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2302.00083</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
In-Context Retrieval-Augmented Language Models. (arXiv:2302.00083v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;In-Context RALM&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30456;&#20851;&#25991;&#20214;&#20316;&#20026;&#36755;&#20837;&#30340;&#19968;&#37096;&#20998;&#65292;&#26080;&#38656;&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#36827;&#19968;&#27493;&#30340;&#35757;&#32451;&#21363;&#21487;&#26174;&#33879;&#25552;&#39640;&#35821;&#35328;&#24314;&#27169;&#24615;&#33021;&#21644;&#28304;&#24402;&#22240;&#33021;&#21147;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;RALM&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#26356;&#31616;&#21333;&#30340;&#37096;&#32626;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;(RALM)&#26041;&#27861;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#23558;&#30456;&#20851;&#25991;&#20214;&#20174;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#20986;&#26469;&#19982;&#35821;&#35328;&#27169;&#22411;(LM)&#36827;&#34892;&#21327;&#21516;&#65292;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#35821;&#35328;&#24314;&#27169;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#36824;&#21487;&#20197;&#32531;&#35299;&#20107;&#23454;&#19981;&#20934;&#30830;&#30340;&#25991;&#26412;&#29983;&#25104;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#33258;&#28982;&#30340;&#28304;&#24402;&#22240;&#26426;&#21046;&#12290;&#29616;&#26377;&#30340;RALM&#26041;&#27861;&#30528;&#37325;&#20110;&#20462;&#25913;LM&#26550;&#26500;&#20197;&#20415;&#20110;&#25972;&#21512;&#22806;&#37096;&#20449;&#24687;&#65292;&#20174;&#32780;&#22823;&#22823;&#22686;&#21152;&#20102;&#37096;&#32626;&#30340;&#22797;&#26434;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;RALM&#65306;&#20445;&#25345;LM&#26550;&#26500;&#19981;&#21464;&#65292;&#24182;&#22312;&#36755;&#20837;&#20013;&#28155;&#21152;&#26816;&#32034;&#21040;&#30340;&#25991;&#20214;&#65292;&#26080;&#38656;&#23545;LM&#36827;&#34892;&#20219;&#20309;&#36827;&#19968;&#27493;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22522;&#20110;&#29616;&#25104;&#30340;&#36890;&#29992;&#26816;&#32034;&#22120;&#30340;&#19978;&#19979;&#25991;RALM&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#19981;&#21516;&#35821;&#26009;&#24211;&#20013;&#33021;&#22815;&#25552;&#20379;&#20986;&#20154;&#24847;&#26009;&#30340;&#22823;&#24133;&#24230;&#30340;LM&#22686;&#30410;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#25991;&#20214;&#26816;&#32034;&#21644;&#25490;&#21517;&#26426;&#21046;&#21487;&#20197;&#38024;&#23545;RALM&#35774;&#32622;&#36827;&#34892;&#19987;&#38376;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Language Modeling (RALM) methods, which condition a language model (LM) on relevant documents from a grounding corpus during generation, were shown to significantly improve language modeling performance. In addition, they can mitigate the problem of factually inaccurate text generation and provide natural source attribution mechanism. Existing RALM approaches focus on modifying the LM architecture in order to facilitate the incorporation of external information, significantly complicating deployment. This paper considers a simple alternative, which we dub In-Context RALM: leaving the LM architecture unchanged and prepending grounding documents to the input, without any further training of the LM. We show that In-Context RALM that builds on off-the-shelf general purpose retrievers provides surprisingly large LM gains across model sizes and diverse corpora. We also demonstrate that the document retrieval and ranking mechanism can be specialized to the RALM setting to 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30693;&#35782;&#20174;&#35760;&#24518;&#20013;&#35299;&#32806;&#65292;&#24110;&#21161;&#27169;&#22411;&#22312;&#27867;&#21270;&#21644;&#35760;&#24518;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2205.14704</link><description>&lt;p&gt;
&#23558;&#30693;&#35782;&#20174;&#35760;&#24518;&#20013;&#35299;&#32806;&#65306;&#26816;&#32034;&#22686;&#24378;&#30340;&#25552;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning. (arXiv:2205.14704v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14704
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30693;&#35782;&#20174;&#35760;&#24518;&#20013;&#35299;&#32806;&#65292;&#24110;&#21161;&#27169;&#22411;&#22312;&#27867;&#21270;&#21644;&#35760;&#24518;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#31361;&#30772;&#65292;&#25552;&#39640;&#20102;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#20294;&#20173;&#28982;&#36981;&#24490;&#21442;&#25968;&#21270;&#23398;&#20064;&#33539;&#24335;&#65307;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#65292;&#36951;&#24536;&#21644;&#26426;&#26800;&#35760;&#24518;&#38382;&#39064;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#30340;&#27867;&#21270;&#38382;&#39064;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;RetroPrompt&#65292;&#26088;&#22312;&#20174;&#35760;&#24518;&#20013;&#23558;&#30693;&#35782;&#35299;&#32806;&#65292;&#24110;&#21161;&#27169;&#22411;&#22312;&#27867;&#21270;&#21644;&#35760;&#24518;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;&#19982;&#20256;&#32479;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#30456;&#27604;&#65292;RetroPrompt&#20174;&#35757;&#32451;&#23454;&#20363;&#26500;&#24314;&#20102;&#19968;&#20010;&#24320;&#25918;&#24335;&#30693;&#35782;&#24211;&#65292;&#24182;&#22312;&#36755;&#20837;&#12289;&#35757;&#32451;&#21644;&#25512;&#26029;&#36807;&#31243;&#20013;&#23454;&#26045;&#26816;&#32034;&#26426;&#21046;&#65292;&#20351;&#27169;&#22411;&#20855;&#22791;&#20102;&#20174;&#35757;&#32451;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#30456;&#20851;&#19978;&#19979;&#25991;&#29992;&#20110;&#22686;&#24378;&#30340;&#33021;&#21147;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;RetroPrompt&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prompt learning approaches have made waves in natural language processing by inducing better few-shot performance while they still follow a parametric-based learning paradigm; the oblivion and rote memorization problems in learning may encounter unstable generalization issues. Specifically, vanilla prompt learning may struggle to utilize atypical instances by rote during fully-supervised training or overfit shallow patterns with low-shot data. To alleviate such limitations, we develop RetroPrompt with the motivation of decoupling knowledge from memorization to help the model strike a balance between generalization and memorization. In contrast with vanilla prompt learning, RetroPrompt constructs an open-book knowledge-store from training instances and implements a retrieval mechanism during the process of input, training and inference, thus equipping the model with the ability to retrieve related contexts from the training corpus as cues for enhancement. Extensive experiments demonstra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#25968;&#23398;&#21644;&#32479;&#35745;&#26041;&#27861;&#30830;&#23450;&#26631;&#31614;&#30340;&#30456;&#20284;&#24615;&#65292;&#21253;&#25324;&#35789;&#27719;&#30456;&#20284;&#24615;&#21644;&#20849;&#29616;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#32771;&#34385;&#20102;&#26631;&#31614;&#20998;&#37197;&#30340;&#26102;&#38388;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2201.03622</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#31038;&#21306;&#26816;&#27979;&#20013;&#30340;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Graph-Based Recommendation System Enhanced with Community Detection. (arXiv:2201.03622v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.03622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#25968;&#23398;&#21644;&#32479;&#35745;&#26041;&#27861;&#30830;&#23450;&#26631;&#31614;&#30340;&#30456;&#20284;&#24615;&#65292;&#21253;&#25324;&#35789;&#27719;&#30456;&#20284;&#24615;&#21644;&#20849;&#29616;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#32771;&#34385;&#20102;&#26631;&#31614;&#20998;&#37197;&#30340;&#26102;&#38388;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#30740;&#31350;&#32773;&#24050;&#32463;&#21033;&#29992;&#26631;&#31614;&#20449;&#24687;&#26469;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#20013;&#25512;&#33616;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#30740;&#31350;&#29992;&#25143;&#30340;&#26631;&#31614;&#65292;&#21487;&#20197;&#20102;&#35299;&#20182;&#20204;&#30340;&#20852;&#36259;&#65292;&#20174;&#32780;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29992;&#25143;&#33258;&#23450;&#20041;&#26631;&#31614;&#30340;&#20219;&#24847;&#24615;&#21644;&#32570;&#20047;&#38480;&#21046;&#65292;&#30830;&#23450;&#20854;&#30830;&#20999;&#21547;&#20041;&#21644;&#26631;&#31614;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#23384;&#22312;&#38382;&#39064;&#12290;&#26412;&#25991;&#21033;&#29992;&#25968;&#23398;&#21644;&#32479;&#35745;&#26041;&#27861;&#30830;&#23450;&#26631;&#31614;&#30340;&#35789;&#27719;&#30456;&#20284;&#24615;&#21644;&#20849;&#29616;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#20998;&#37197;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#21478;&#22806;&#65292;&#32771;&#34385;&#21040;&#29992;&#25143;&#20852;&#36259;&#38543;&#26102;&#38388;&#21464;&#21270;&#65292;&#26412;&#25991;&#36824;&#22312;&#20849;&#29616;&#26631;&#31614;&#20013;&#32771;&#34385;&#20102;&#26631;&#31614;&#20998;&#37197;&#30340;&#26102;&#38388;&#20197;&#30830;&#23450;&#26631;&#31614;&#30340;&#30456;&#20284;&#24615;&#12290;&#28982;&#21518;&#65292;&#22522;&#20110;&#26631;&#31614;&#30340;&#30456;&#20284;&#24615;&#21019;&#24314;&#22270;&#24418;&#27169;&#22411;&#26469;&#24314;&#27169;&#29992;&#25143;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many researchers have used tag information to improve the performance of recommendation techniques in recommender systems. Examining the tags of users will help to get their interests and leads to more accuracy in the recommendations. Since user-defined tags are chosen freely and without any restrictions, problems arise in determining their exact meaning and the similarity of tags. However, using thesaurus and ontologies to find the meaning of tags is not very efficient due to their free definition by users and the use of different languages in many data sets. Therefore, this article uses mathematical and statistical methods to determine lexical similarity and co-occurrence tags solution to assign semantic similarity. On the other hand, due to the change of users' interests over time this article has considered the time of tag assignments in co-occurrence tags for determining similarity of tags. Then the graph is created based on similarity of tags. For modeling the interests of the us
&lt;/p&gt;</description></item></channel></rss>