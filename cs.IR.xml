<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;InTune&#65292;&#19968;&#20010;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25968;&#25454;&#27969;&#20248;&#21270;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#28145;&#24230;&#25512;&#33616;&#27169;&#22411;&#12290;&#36890;&#36807;&#30740;&#31350;&#22312;Netflix&#35745;&#31639;&#38598;&#32676;&#20013;&#30340;DLRM&#25968;&#25454;&#22788;&#29702;&#27969;&#31243;&#65292;&#25105;&#20204;&#21457;&#29616;&#30446;&#21069;&#30340;&#27969;&#31243;&#20248;&#21270;&#22120;&#23384;&#22312;&#24615;&#33021;&#19981;&#20339;&#12289;&#39057;&#32321;&#23849;&#28291;&#25110;&#38656;&#35201;&#19981;&#20999;&#23454;&#38469;&#30340;&#38598;&#32676;&#37325;&#32452;&#31561;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.08500</link><description>&lt;p&gt;
InTune:&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25968;&#25454;&#27969;&#20248;&#21270;&#29992;&#20110;&#28145;&#24230;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models. (arXiv:2308.08500v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08500
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;InTune&#65292;&#19968;&#20010;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25968;&#25454;&#27969;&#20248;&#21270;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#28145;&#24230;&#25512;&#33616;&#27169;&#22411;&#12290;&#36890;&#36807;&#30740;&#31350;&#22312;Netflix&#35745;&#31639;&#38598;&#32676;&#20013;&#30340;DLRM&#25968;&#25454;&#22788;&#29702;&#27969;&#31243;&#65292;&#25105;&#20204;&#21457;&#29616;&#30446;&#21069;&#30340;&#27969;&#31243;&#20248;&#21270;&#22120;&#23384;&#22312;&#24615;&#33021;&#19981;&#20339;&#12289;&#39057;&#32321;&#23849;&#28291;&#25110;&#38656;&#35201;&#19981;&#20999;&#23454;&#38469;&#30340;&#38598;&#32676;&#37325;&#32452;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#25512;&#33616;&#27169;&#22411;(DLRM)&#24050;&#32463;&#25104;&#20026;&#35768;&#22810;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#19968;&#20123;&#20844;&#21496;&#27491;&#22312;&#24314;&#35774;&#22823;&#22411;&#35745;&#31639;&#38598;&#32676;&#19987;&#38376;&#29992;&#20110;DLRM&#35757;&#32451;&#65292;&#36827;&#32780;&#25512;&#21160;&#20102;&#23545;&#25104;&#26412;&#21644;&#26102;&#38388;&#30340;&#33410;&#32422;&#20248;&#21270;&#30340;&#26032;&#20852;&#20852;&#36259;&#12290;&#22312;&#36825;&#20010;&#22330;&#26223;&#20013;&#25152;&#38754;&#20020;&#30340;&#31995;&#32479;&#25361;&#25112;&#26159;&#29420;&#29305;&#30340;&#65307;&#23613;&#31649;&#20856;&#22411;&#30340;&#28145;&#24230;&#23398;&#20064;&#35757;&#32451;&#20219;&#21153;&#30001;&#27169;&#22411;&#25191;&#34892;&#20027;&#23548;&#65292;&#20294;DLRM&#35757;&#32451;&#24615;&#33021;&#20013;&#26368;&#37325;&#35201;&#30340;&#22240;&#32032;&#24448;&#24448;&#26159;&#32447;&#19978;&#25968;&#25454;&#25668;&#20837;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#35813;&#25968;&#25454;&#25668;&#20837;&#38382;&#39064;&#30340;&#29420;&#29305;&#29305;&#24449;&#65292;&#24182;&#28145;&#20837;&#30740;&#31350;&#20102;DLRM&#35757;&#32451;&#27969;&#31243;&#20013;&#30340;&#24615;&#33021;&#29942;&#39048;&#21644;&#25361;&#25112;&#12290;&#25105;&#20204;&#23545;Netflix&#35745;&#31639;&#38598;&#32676;&#20013;&#30495;&#23454;&#30340;DLRM&#25968;&#25454;&#22788;&#29702;&#27969;&#31243;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#35266;&#23519;&#20102;&#32447;&#19978;&#25668;&#20837;&#30340;&#24615;&#33021;&#24433;&#21709;&#65292;&#24182;&#35782;&#21035;&#20986;&#29616;&#26377;&#27969;&#31243;&#20248;&#21270;&#22120;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;&#25105;&#20204;&#21457;&#29616;&#24403;&#21069;&#30340;&#24037;&#20855;&#35201;&#20040;&#20135;&#29983;&#27425;&#20248;&#24615;&#33021;&#65292;&#35201;&#20040;&#32463;&#24120;&#23849;&#28291;&#65292;&#35201;&#20040;&#38656;&#35201;&#19981;&#29616;&#23454;&#30340;&#38598;&#32676;&#37325;&#32452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning-based recommender models (DLRMs) have become an essential component of many modern recommender systems. Several companies are now building large compute clusters reserved only for DLRM training, driving new interest in cost- and time- saving optimizations. The systems challenges faced in this setting are unique; while typical deep learning training jobs are dominated by model execution, the most important factor in DLRM training performance is often online data ingestion.  In this paper, we explore the unique characteristics of this data ingestion problem and provide insights into DLRM training pipeline bottlenecks and challenges. We study real-world DLRM data processing pipelines taken from our compute cluster at Netflix to observe the performance impacts of online ingestion and to identify shortfalls in existing pipeline optimizers. We find that current tooling either yields sub-optimal performance, frequent crashes, or else requires impractical cluster re-organization 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#31038;&#20132;&#29289;&#32852;&#32593;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#26381;&#21153;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#25429;&#25417;&#35774;&#22791;&#20043;&#38388;&#30340;&#28508;&#22312;&#29305;&#24449;&#20132;&#20114;&#21644;&#24314;&#27169;&#35774;&#22791;-&#26381;&#21153;&#23545;&#30340;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;&#35780;&#32423;&#39044;&#27979;&#21644;&#20010;&#24615;&#21270;&#30340;&#26381;&#21153;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2308.08499</link><description>&lt;p&gt;
&#38754;&#21521;&#31038;&#20132;&#29289;&#32852;&#32593;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#26381;&#21153;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Context-Aware Service Recommendation System for the Social Internet of Things. (arXiv:2308.08499v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08499
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#31038;&#20132;&#29289;&#32852;&#32593;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#26381;&#21153;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#25429;&#25417;&#35774;&#22791;&#20043;&#38388;&#30340;&#28508;&#22312;&#29305;&#24449;&#20132;&#20114;&#21644;&#24314;&#27169;&#35774;&#22791;-&#26381;&#21153;&#23545;&#30340;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;&#35780;&#32423;&#39044;&#27979;&#21644;&#20010;&#24615;&#21270;&#30340;&#26381;&#21153;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#29289;&#32852;&#32593;&#65288;SIoT&#65289;&#20351;&#26234;&#33021;&#35774;&#22791;&#30456;&#20114;&#36830;&#25509;&#24182;&#20849;&#20139;&#25968;&#25454;&#21644;&#26381;&#21153;&#65292;&#20026;&#20010;&#24615;&#21270;&#26381;&#21153;&#25512;&#33616;&#25552;&#20379;&#20102;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#32463;&#24120;&#24573;&#35270;&#20102;&#21487;&#20197;&#25552;&#39640;SIoT&#29615;&#22659;&#19979;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#21644;&#30456;&#20851;&#24615;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#29616;&#26377;&#25216;&#26415;&#24448;&#24448;&#21482;&#32771;&#34385;&#20102;&#35774;&#22791;&#20043;&#38388;&#30340;&#31038;&#20132;&#20851;&#31995;&#30340;&#25552;&#21462;&#65292;&#32780;&#24573;&#35270;&#20102;&#26381;&#21153;&#35780;&#35770;&#30340;&#19978;&#19979;&#25991;&#21576;&#29616;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#25506;&#32034;&#27599;&#20010;&#35774;&#22791;-&#26381;&#21153;&#23545;&#30340;&#19978;&#19979;&#25991;&#34920;&#31034;&#26469;&#22635;&#34917;&#36825;&#20123;&#32570;&#21475;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28508;&#22312;&#29305;&#24449;&#32452;&#21512;&#25216;&#26415;&#65292;&#21487;&#20197;&#36890;&#36807;&#32858;&#21512;SIoT&#20013;&#30340;&#35774;&#22791;-&#35774;&#22791;&#20851;&#31995;&#26469;&#25429;&#25417;&#28508;&#22312;&#29305;&#24449;&#20132;&#20114;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#22240;&#23376;&#20998;&#35299;&#26426;&#26469;&#24314;&#27169;&#27599;&#20010;SIoT&#35774;&#22791;-&#26381;&#21153;&#23545;&#29305;&#23450;&#30340;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#65292;&#20197;&#23454;&#29616;&#20934;&#30830;&#30340;&#35780;&#32423;&#39044;&#27979;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#35780;&#32423;&#39044;&#27979;&#30340;SIoT&#26381;&#21153;&#25512;&#33616;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Social Internet of Things (SIoT) enables interconnected smart devices to share data and services, opening up opportunities for personalized service recommendations. However, existing research often overlooks crucial aspects that can enhance the accuracy and relevance of recommendations in the SIoT context. Specifically, existing techniques tend to consider the extraction of social relationships between devices and neglect the contextual presentation of service reviews. This study aims to address these gaps by exploring the contextual representation of each device-service pair. Firstly, we propose a latent features combination technique that can capture latent feature interactions, by aggregating the device-device relationships within the SIoT. Then, we leverage Factorization Machines to model higher-order feature interactions specific to each SIoT device-service pair to accomplish accurate rating prediction. Finally, we propose a service recommendation framework for SIoT based on r
&lt;/p&gt;</description></item><item><title>HyperBandit&#26159;&#19968;&#31181;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#27969;&#23186;&#20307;&#25512;&#33616;&#31995;&#32479;&#20013;&#26102;&#38388;&#21464;&#21270;&#30340;&#29992;&#25143;&#20559;&#22909;&#12290;&#23427;&#36890;&#36807;&#24314;&#31435;&#26102;&#38388;&#29305;&#24449;&#21644;&#29992;&#25143;&#20559;&#22909;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#21160;&#24577;&#35843;&#25972;&#25512;&#33616;&#27169;&#22411;&#20197;&#36866;&#24212;&#21160;&#24577;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2308.08497</link><description>&lt;p&gt;
HyperBandit: &#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#26102;&#38388;&#21464;&#21270;&#29992;&#25143;&#20559;&#22909;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#22312;&#27969;&#23186;&#20307;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
HyperBandit: Contextual Bandit with Hypernewtork for Time-Varying User Preferences in Streaming Recommendation. (arXiv:2308.08497v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08497
&lt;/p&gt;
&lt;p&gt;
HyperBandit&#26159;&#19968;&#31181;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#27969;&#23186;&#20307;&#25512;&#33616;&#31995;&#32479;&#20013;&#26102;&#38388;&#21464;&#21270;&#30340;&#29992;&#25143;&#20559;&#22909;&#12290;&#23427;&#36890;&#36807;&#24314;&#31435;&#26102;&#38388;&#29305;&#24449;&#21644;&#29992;&#25143;&#20559;&#22909;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#21160;&#24577;&#35843;&#25972;&#25512;&#33616;&#27169;&#22411;&#20197;&#36866;&#24212;&#21160;&#24577;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#27969;&#23186;&#20307;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#20559;&#22909;&#32463;&#24120;&#22312;&#26102;&#38388;&#19978;&#21160;&#24577;&#21464;&#21270;&#65288;&#20363;&#22914;&#65292;&#22312;&#24037;&#20316;&#26085;&#21644;&#21608;&#26411;&#29992;&#25143;&#21487;&#33021;&#26377;&#19981;&#21516;&#30340;&#20559;&#22909;&#65289;&#12290;&#29616;&#26377;&#30340;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#27969;&#23186;&#20307;&#25512;&#33616;&#27169;&#22411;&#21482;&#23558;&#26102;&#38388;&#35270;&#20026;&#26102;&#38388;&#25139;&#65292;&#27809;&#26377;&#26126;&#30830;&#22320;&#24314;&#27169;&#26102;&#38388;&#21464;&#37327;&#19982;&#26102;&#38388;&#21464;&#21270;&#30340;&#29992;&#25143;&#20559;&#22909;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36825;&#23548;&#33268;&#25512;&#33616;&#27169;&#22411;&#26080;&#27861;&#24555;&#36895;&#36866;&#24212;&#21160;&#24577;&#22330;&#26223;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36229;&#32593;&#32476;&#30340;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;HyperBandit&#65292;&#20854;&#23558;&#26102;&#38388;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#65292;&#24182;&#21160;&#24577;&#35843;&#25972;&#25512;&#33616;&#27169;&#22411;&#20197;&#36866;&#24212;&#26102;&#38388;&#21464;&#21270;&#30340;&#29992;&#25143;&#20559;&#22909;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;HyperBandit&#32500;&#25252;&#20102;&#19968;&#20010;&#33021;&#22815;&#29983;&#25104;&#29992;&#20110;&#20272;&#35745;&#26102;&#38388;&#21464;&#21270;&#22870;&#21169;&#30340;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#32771;&#34385;&#20102;&#26102;&#38388;&#29305;&#24449;&#21644;&#29992;&#25143;&#20559;&#22909;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#20351;&#29992;&#20272;&#35745;&#30340;&#26102;&#38388;&#21464;&#21270;&#22870;&#21169;&#65292;&#25105;&#20204;&#37319;&#29992;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#26469;&#36827;&#34892;&#22312;&#32447;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world streaming recommender systems, user preferences often dynamically change over time (e.g., a user may have different preferences during weekdays and weekends). Existing bandit-based streaming recommendation models only consider time as a timestamp, without explicitly modeling the relationship between time variables and time-varying user preferences. This leads to recommendation models that cannot quickly adapt to dynamic scenarios. To address this issue, we propose a contextual bandit approach using hypernetwork, called HyperBandit, which takes time features as input and dynamically adjusts the recommendation model for time-varying user preferences. Specifically, HyperBandit maintains a neural network capable of generating the parameters for estimating time-varying rewards, taking into account the correlation between time features and user preferences. Using the estimated time-varying rewards, a bandit policy is employed to make online recommendations by learning the laten
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36827;&#34892;&#20102;&#19968;&#39033;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#30740;&#31350;&#20102;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#24847;&#22270;&#24314;&#27169;&#30340;&#30456;&#20851;&#27169;&#22411;&#21644;&#29305;&#24449;&#12290;&#30740;&#31350;&#32467;&#26524;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#27169;&#22411;&#36873;&#25321;&#12289;&#36136;&#37327;&#38382;&#39064;&#21644;&#35780;&#20272;&#25351;&#26631;&#31561;&#26041;&#38754;&#30340;&#27934;&#23519;&#12290;</title><link>http://arxiv.org/abs/2308.08496</link><description>&lt;p&gt;
&#29702;&#35299;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#24847;&#22270;&#24314;&#27169;&#65306;&#19968;&#39033;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Understanding User Intent Modeling for Conversational Recommender Systems: A Systematic Literature Review. (arXiv:2308.08496v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08496
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36827;&#34892;&#20102;&#19968;&#39033;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#30740;&#31350;&#20102;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#24847;&#22270;&#24314;&#27169;&#30340;&#30456;&#20851;&#27169;&#22411;&#21644;&#29305;&#24449;&#12290;&#30740;&#31350;&#32467;&#26524;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#27169;&#22411;&#36873;&#25321;&#12289;&#36136;&#37327;&#38382;&#39064;&#21644;&#35780;&#20272;&#25351;&#26631;&#31561;&#26041;&#38754;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#29992;&#25143;&#24847;&#22270;&#24314;&#27169;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#36807;&#31243;&#65292;&#26088;&#22312;&#35782;&#21035;&#29992;&#25143;&#35831;&#27714;&#32972;&#21518;&#30340;&#28508;&#22312;&#30446;&#30340;&#65292;&#20174;&#32780;&#23454;&#29616;&#20010;&#24615;&#21270;&#30340;&#21709;&#24212;&#12290;&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#25991;&#29486;&#20013;&#24341;&#20837;&#20102;&#22823;&#37327;&#30340;&#26041;&#27861;&#65288;&#36229;&#36807;13,000&#31687;&#35770;&#25991;&#65289;&#65292;&#29702;&#35299;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#20013;&#30456;&#20851;&#27010;&#24565;&#21644;&#24120;&#29992;&#27169;&#22411;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#26041;&#27861;&#65306;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#25910;&#38598;&#20102;&#35774;&#35745;&#23545;&#35805;&#24335;&#25512;&#33616;&#31995;&#32479;&#20013;&#36890;&#24120;&#37319;&#29992;&#30340;&#27169;&#22411;&#30340;&#25968;&#25454;&#12290;&#20174;&#25910;&#38598;&#21040;&#30340;&#25968;&#25454;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20915;&#31574;&#27169;&#22411;&#65292;&#20197;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#36873;&#25321;&#26368;&#36866;&#21512;&#20854;&#31995;&#32479;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#35780;&#20272;&#25105;&#20204;&#25552;&#20986;&#30340;&#20915;&#31574;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#30340;&#30740;&#31350;&#20998;&#26512;&#20102;59&#20010;&#19981;&#21516;&#30340;&#27169;&#22411;&#65292;&#24182;&#30830;&#23450;&#20102;74&#20010;&#24120;&#29992;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#28508;&#22312;&#30340;&#27169;&#22411;&#32452;&#21512;&#12289;&#27169;&#22411;&#36873;&#25321;&#36235;&#21183;&#12289;&#36136;&#37327;&#38382;&#39064;&#12289;&#35780;&#20272;&#25351;&#26631;&#20197;&#21450;&#32463;&#24120;&#20351;&#29992;&#30340;&#25968;&#25454;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Context: User intent modeling is a crucial process in Natural Language Processing that aims to identify the underlying purpose behind a user's request, enabling personalized responses. With a vast array of approaches introduced in the literature (over 13,000 papers in the last decade), understanding the related concepts and commonly used models in AI-based systems is essential. Method: We conducted a systematic literature review to gather data on models typically employed in designing conversational recommender systems. From the collected data, we developed a decision model to assist researchers in selecting the most suitable models for their systems. Additionally, we performed two case studies to evaluate the effectiveness of our proposed decision model. Results: Our study analyzed 59 distinct models and identified 74 commonly used features. We provided insights into potential model combinations, trends in model selection, quality concerns, evaluation measures, and frequently used dat
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#24565;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#23457;&#35745;&#26085;&#24535;&#20316;&#20026;&#30417;&#30563;&#65292;&#23454;&#29616;&#22312;&#29305;&#23450;&#20020;&#24202;&#32972;&#26223;&#19979;&#12289;&#29305;&#23450;&#26102;&#38388;&#28857;&#30340;&#31508;&#35760;&#30456;&#20851;&#24615;&#26816;&#32034;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#20010;&#21035;&#31508;&#35760;&#25776;&#20889;&#20250;&#35805;&#20013;&#21738;&#20123;&#31508;&#35760;&#20250;&#34987;&#38405;&#35835;&#26041;&#38754;&#20855;&#26377;&#24456;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#20020;&#24202;&#21307;&#29983;&#30340;&#29992;&#25143;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#35813;&#26694;&#26550;&#21487;&#20197;&#24110;&#21161;&#20020;&#24202;&#21307;&#29983;&#26356;&#39640;&#25928;&#22320;&#26816;&#32034;&#30456;&#20851;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2308.08494</link><description>&lt;p&gt;
&#29992;&#20110;&#21160;&#24577;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20449;&#24687;&#26816;&#32034;&#30340;&#26426;&#22120;&#23398;&#20064;&#27010;&#24565;&#21270;
&lt;/p&gt;
&lt;p&gt;
Conceptualizing Machine Learning for Dynamic Information Retrieval of Electronic Health Record Notes. (arXiv:2308.08494v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08494
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#24565;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#23457;&#35745;&#26085;&#24535;&#20316;&#20026;&#30417;&#30563;&#65292;&#23454;&#29616;&#22312;&#29305;&#23450;&#20020;&#24202;&#32972;&#26223;&#19979;&#12289;&#29305;&#23450;&#26102;&#38388;&#28857;&#30340;&#31508;&#35760;&#30456;&#20851;&#24615;&#26816;&#32034;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#20010;&#21035;&#31508;&#35760;&#25776;&#20889;&#20250;&#35805;&#20013;&#21738;&#20123;&#31508;&#35760;&#20250;&#34987;&#38405;&#35835;&#26041;&#38754;&#20855;&#26377;&#24456;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#20020;&#24202;&#21307;&#29983;&#30340;&#29992;&#25143;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#35813;&#26694;&#26550;&#21487;&#20197;&#24110;&#21161;&#20020;&#24202;&#21307;&#29983;&#26356;&#39640;&#25928;&#22320;&#26816;&#32034;&#30456;&#20851;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20020;&#24202;&#21307;&#29983;&#33457;&#36153;&#22823;&#37327;&#26102;&#38388;&#31579;&#36873;&#30149;&#20154;&#31508;&#35760;&#24182;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20013;&#35760;&#24405;&#26159;&#20020;&#24202;&#21307;&#29983;&#20518;&#24608;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#36890;&#36807;&#22312;&#35760;&#24405;&#36807;&#31243;&#20013;&#20027;&#21160;&#21644;&#21160;&#24577;&#22320;&#26816;&#32034;&#30456;&#20851;&#31508;&#35760;&#65292;&#25105;&#20204;&#21487;&#20197;&#20943;&#23569;&#26597;&#25214;&#30456;&#20851;&#30149;&#20363;&#21382;&#21490;&#25152;&#38656;&#30340;&#24037;&#20316;&#37327;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#27010;&#24565;&#21270;&#20102;&#20351;&#29992;EHR&#23457;&#35745;&#26085;&#24535;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#30340;&#26469;&#28304;&#65292;&#20197;&#30417;&#30563;&#29305;&#23450;&#20020;&#24202;&#32972;&#26223;&#19979;&#12289;&#29305;&#23450;&#26102;&#38388;&#28857;&#30340;&#31508;&#35760;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#37325;&#28857;&#25918;&#22312;&#32039;&#24613;&#31185;&#23460;&#30340;&#21160;&#24577;&#26816;&#32034;&#19978;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#29420;&#29305;&#20449;&#24687;&#26816;&#32034;&#21644;&#31508;&#35760;&#32534;&#20889;&#27169;&#24335;&#30340;&#39640;&#37325;&#30151;&#35774;&#32622;&#12290;&#25105;&#20204;&#26174;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#39044;&#27979;&#21738;&#20123;&#31508;&#35760;&#20250;&#22312;&#20010;&#21035;&#31508;&#35760;&#25776;&#20889;&#20250;&#35805;&#20013;&#34987;&#38405;&#35835;&#26041;&#38754;&#21487;&#20197;&#23454;&#29616;0.963&#30340;AUC&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#22810;&#21517;&#20020;&#24202;&#21307;&#29983;&#36827;&#34892;&#20102;&#29992;&#25143;&#30740;&#31350;&#65292;&#21457;&#29616;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#24110;&#21161;&#20020;&#24202;&#21307;&#29983;&#26356;&#39640;&#25928;&#22320;&#26816;&#32034;&#30456;&#20851;&#20449;&#24687;&#12290;&#36890;&#36807;&#23637;&#31034;&#25105;&#20204;&#30340;&#26694;&#26550;&#21644;...
&lt;/p&gt;
&lt;p&gt;
The large amount of time clinicians spend sifting through patient notes and documenting in electronic health records (EHRs) is a leading cause of clinician burnout. By proactively and dynamically retrieving relevant notes during the documentation process, we can reduce the effort required to find relevant patient history. In this work, we conceptualize the use of EHR audit logs for machine learning as a source of supervision of note relevance in a specific clinical context, at a particular point in time. Our evaluation focuses on the dynamic retrieval in the emergency department, a high acuity setting with unique patterns of information retrieval and note writing. We show that our methods can achieve an AUC of 0.963 for predicting which notes will be read in an individual note writing session. We additionally conduct a user study with several clinicians and find that our framework can help clinicians retrieve relevant information more efficiently. Demonstrating that our framework and m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26102;&#38388;&#20852;&#36259;&#32593;&#32476;&#65288;TIN&#65289;&#65292;&#29992;&#20110;&#25429;&#25417;&#34892;&#20026;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#22235;&#37325;&#35821;&#20041;&#21644;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#20197;&#39044;&#27979;&#28857;&#20987;&#29575;&#30340;&#25928;&#26524;&#21644;&#24050;&#26377;&#26041;&#27861;&#23545;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#23398;&#20064;&#31243;&#24230;&#23578;&#19981;&#28165;&#26970;&#12290;</title><link>http://arxiv.org/abs/2308.08487</link><description>&lt;p&gt;
&#28857;&#20987;&#29575;&#39044;&#27979;&#30340;&#26102;&#38388;&#20852;&#36259;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Temporal Interest Network for Click-Through Rate Prediction. (arXiv:2308.08487v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26102;&#38388;&#20852;&#36259;&#32593;&#32476;&#65288;TIN&#65289;&#65292;&#29992;&#20110;&#25429;&#25417;&#34892;&#20026;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#22235;&#37325;&#35821;&#20041;&#21644;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#20197;&#39044;&#27979;&#28857;&#20987;&#29575;&#30340;&#25928;&#26524;&#21644;&#24050;&#26377;&#26041;&#27861;&#23545;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#23398;&#20064;&#31243;&#24230;&#23578;&#19981;&#28165;&#26970;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#34892;&#20026;&#30340;&#21382;&#21490;&#26159;&#39044;&#27979;&#28857;&#20987;&#29575;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#20043;&#19968;&#65292;&#22240;&#20026;&#23427;&#20204;&#19982;&#30446;&#26631;&#39033;&#30446;&#20855;&#26377;&#24378;&#28872;&#30340;&#35821;&#20041;&#21644;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;&#34429;&#28982;&#24050;&#26377;&#25991;&#29486;&#20998;&#21035;&#30740;&#31350;&#20102;&#36825;&#20123;&#30456;&#20851;&#24615;&#65292;&#20294;&#23578;&#26410;&#20998;&#26512;&#23427;&#20204;&#30340;&#32452;&#21512;&#65292;&#21363;&#34892;&#20026;&#35821;&#20041;&#12289;&#30446;&#26631;&#35821;&#20041;&#12289;&#34892;&#20026;&#26102;&#38388;&#21644;&#30446;&#26631;&#26102;&#38388;&#30340;&#22235;&#37325;&#30456;&#20851;&#24615;&#12290;&#36825;&#31181;&#30456;&#20851;&#24615;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#20197;&#21450;&#29616;&#26377;&#26041;&#27861;&#23398;&#20064;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#31243;&#24230;&#23578;&#19981;&#28165;&#26970;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#22312;&#23454;&#36341;&#20013;&#27979;&#37327;&#20102;&#22235;&#37325;&#30456;&#20851;&#24615;&#65292;&#24182;&#35266;&#23519;&#21040;&#30452;&#35266;&#32780;&#24378;&#22823;&#30340;&#22235;&#37325;&#27169;&#24335;&#12290;&#25105;&#20204;&#27979;&#37327;&#20102;&#20960;&#31181;&#20195;&#34920;&#24615;&#30340;&#29992;&#25143;&#34892;&#20026;&#26041;&#27861;&#30340;&#23398;&#20064;&#30456;&#20851;&#24615;&#65292;&#20294;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23427;&#20204;&#37117;&#27809;&#26377;&#23398;&#20064;&#21040;&#36825;&#26679;&#30340;&#27169;&#24335;&#65292;&#29305;&#21035;&#26159;&#26102;&#38388;&#27169;&#24335;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26102;&#38388;&#20852;&#36259;&#32593;&#32476;&#65288;TIN&#65289;&#26469;&#25429;&#25417;&#34892;&#20026;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#22235;&#37325;&#35821;&#20041;&#21644;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The history of user behaviors constitutes one of the most significant characteristics in predicting the click-through rate (CTR), owing to their strong semantic and temporal correlation with the target item. While the literature has individually examined each of these correlations, research has yet to analyze them in combination, that is, the quadruple correlation of (behavior semantics, target semantics, behavior temporal, and target temporal). The effect of this correlation on performance and the extent to which existing methods learn it remain unknown. To address this gap, we empirically measure the quadruple correlation and observe intuitive yet robust quadruple patterns. We measure the learned correlation of several representative user behavior methods, but to our surprise, none of them learn such a pattern, especially the temporal one.  In this paper, we propose the Temporal Interest Network (TIN) to capture the quadruple semantic and temporal correlation between behaviors and th
&lt;/p&gt;</description></item><item><title>TBIN&#27169;&#22411;&#36890;&#36807;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;&#21644;&#22522;&#20110;&#22359;&#20301;&#31227;&#30340;&#33258;&#27880;&#24847;&#21147;&#26041;&#27861;&#35299;&#20915;&#20102;&#21033;&#29992;&#38271;&#25991;&#26412;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#36827;&#34892;CTR&#39044;&#27979;&#26102;&#30340;&#25130;&#26029;&#38382;&#39064;&#21644;&#27169;&#22411;&#34920;&#36798;&#33021;&#21147;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.08483</link><description>&lt;p&gt;
TBIN: &#27169;&#22411;&#21270;&#38271;&#25991;&#26412;&#34892;&#20026;&#25968;&#25454;&#29992;&#20110;CTR&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
TBIN: Modeling Long Textual Behavior Data for CTR Prediction. (arXiv:2308.08483v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08483
&lt;/p&gt;
&lt;p&gt;
TBIN&#27169;&#22411;&#36890;&#36807;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;&#21644;&#22522;&#20110;&#22359;&#20301;&#31227;&#30340;&#33258;&#27880;&#24847;&#21147;&#26041;&#27861;&#35299;&#20915;&#20102;&#21033;&#29992;&#38271;&#25991;&#26412;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#36827;&#34892;CTR&#39044;&#27979;&#26102;&#30340;&#25130;&#26029;&#38382;&#39064;&#21644;&#27169;&#22411;&#34920;&#36798;&#33021;&#21147;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#22312;&#25512;&#33616;&#31995;&#32479;&#30340;&#25104;&#21151;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#21463;&#21040;&#26368;&#36817;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30340;&#32321;&#33635;&#24433;&#21709;&#65292;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#20197;&#25991;&#26412;&#26684;&#24335;&#32452;&#32455;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#65292;&#24182;&#21033;&#29992;LMs&#26469;&#22312;&#35821;&#20041;&#23618;&#38754;&#19978;&#29702;&#35299;&#29992;&#25143;&#20852;&#36259;&#26469;&#25913;&#36827;&#39044;&#27979;&#12290;&#34429;&#28982;&#26377;&#21069;&#26223;&#65292;&#20294;&#36825;&#20123;&#30740;&#31350;&#19981;&#24471;&#19981;&#25130;&#26029;&#25991;&#26412;&#25968;&#25454;&#20197;&#20943;&#23569;LMs&#20013;&#33258;&#27880;&#24847;&#21147;&#30340;&#20108;&#27425;&#35745;&#31639;&#24320;&#38144;&#12290;&#28982;&#32780;&#65292;&#24050;&#32463;&#30740;&#31350;&#34920;&#26126;&#38271;&#26102;&#38388;&#30340;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;CTR&#39044;&#27979;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#24037;&#20316;&#36890;&#24120;&#23558;&#29992;&#25143;&#30340;&#22810;&#26679;&#21270;&#20852;&#36259;&#21387;&#32553;&#25104;&#19968;&#20010;&#29305;&#24449;&#21521;&#37327;&#65292;&#36825;&#38459;&#30861;&#20102;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25991;&#26412;&#34892;&#20026;&#30340;&#20852;&#36259;&#20999;&#22359;&#32593;&#32476;&#65288;TBIN&#65289;&#65292;&#36890;&#36807;&#32467;&#21512;&#39640;&#25928;&#30340;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;&#21644;&#22522;&#20110;&#22359;&#20301;&#31227;&#30340;&#33258;&#27880;&#24847;&#21147;&#26041;&#27861;&#26469;&#35299;&#20915;&#19978;&#36848;&#38480;&#21046;&#12290;&#24471;&#21040;&#30340;&#29992;&#25143;&#22810;&#26679;&#21270;&#20852;&#36259;&#26159;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction plays a pivotal role in the success of recommendations. Inspired by the recent thriving of language models (LMs), a surge of works improve prediction by organizing user behavior data in a \textbf{textual} format and using LMs to understand user interest at a semantic level. While promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model. In this paper, we propose a \textbf{T}extual \textbf{B}ehavior-based \textbf{I}nterest Chunking \textbf{N}etwork (TBIN), which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#23432;&#21452;&#37325;&#31283;&#20581;&#31574;&#30053;&#65288;CDR&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30340;&#26377;&#27602;&#25554;&#34917;&#38382;&#39064;&#12290;CDR&#36890;&#36807;&#23457;&#26597;&#25554;&#34917;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#26469;&#36807;&#28388;&#25554;&#34917;&#65292;&#32467;&#26524;&#26174;&#31034;CDR&#20855;&#26377;&#38477;&#20302;&#26041;&#24046;&#21644;&#25913;&#36827;&#23614;&#37096;&#30028;&#38480;&#30340;&#20248;&#21183;&#65292;&#24182;&#19988;&#33021;&#22815;&#26174;&#33879;&#25552;&#21319;&#24615;&#33021;&#24182;&#20943;&#23569;&#26377;&#27602;&#25554;&#34917;&#30340;&#39057;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.08461</link><description>&lt;p&gt;
CDR&#65306;&#29992;&#20110;&#21435;&#20559;&#25512;&#33616;&#30340;&#20445;&#23432;&#21452;&#37325;&#31283;&#20581;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
CDR: Conservative Doubly Robust Learning for Debiased Recommendation. (arXiv:2308.08461v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08461
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#23432;&#21452;&#37325;&#31283;&#20581;&#31574;&#30053;&#65288;CDR&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30340;&#26377;&#27602;&#25554;&#34917;&#38382;&#39064;&#12290;CDR&#36890;&#36807;&#23457;&#26597;&#25554;&#34917;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#26469;&#36807;&#28388;&#25554;&#34917;&#65292;&#32467;&#26524;&#26174;&#31034;CDR&#20855;&#26377;&#38477;&#20302;&#26041;&#24046;&#21644;&#25913;&#36827;&#23614;&#37096;&#30028;&#38480;&#30340;&#20248;&#21183;&#65292;&#24182;&#19988;&#33021;&#22815;&#26174;&#33879;&#25552;&#21319;&#24615;&#33021;&#24182;&#20943;&#23569;&#26377;&#27602;&#25554;&#34917;&#30340;&#39057;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#24448;&#24448;&#26159;&#35266;&#23519;&#24615;&#30340;&#32780;&#19981;&#26159;&#23454;&#39564;&#24615;&#30340;&#65292;&#23548;&#33268;&#25968;&#25454;&#20013;&#26222;&#36941;&#23384;&#22312;&#20559;&#24046;&#12290;&#22240;&#27492;&#65292;&#35299;&#20915;&#20559;&#24046;&#38382;&#39064;&#24050;&#25104;&#20026;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#26368;&#36817;&#65292;&#21452;&#37325;&#31283;&#20581;&#23398;&#20064;&#65288;DR&#65289;&#30001;&#20110;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#21644;&#31283;&#20581;&#30340;&#29305;&#24615;&#32780;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#26377;&#30340;DR&#26041;&#27861;&#22312;&#23384;&#22312;&#25152;&#35859;&#30340;&#26377;&#27602;&#25554;&#34917;&#65288;Poisonous Imputation&#65289;&#26102;&#21463;&#21040;&#20005;&#37325;&#24433;&#21709;&#65292;&#25554;&#34917;&#26126;&#26174;&#20559;&#31163;&#30495;&#23454;&#25968;&#25454;&#24182;&#36866;&#24471;&#20854;&#21453;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#23432;&#21452;&#37325;&#31283;&#20581;&#31574;&#30053;&#65288;CDR&#65289;&#65292;&#36890;&#36807;&#23457;&#26597;&#25554;&#34917;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;&#26469;&#36807;&#28388;&#25554;&#34917;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;CDR&#21487;&#20197;&#38477;&#20302;&#26041;&#24046;&#24182;&#25913;&#36827;&#23614;&#37096;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;CDR&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#65292;&#24182;&#19988;&#30830;&#23454;&#20943;&#23569;&#20102;&#26377;&#27602;&#25554;&#34917;&#30340;&#39057;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive.  To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MOSR&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21160;&#24577;&#37038;&#20214;&#37325;&#26032;&#25490;&#24207;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#20351;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#27169;&#22411;&#26469;&#24179;&#34913;&#20146;&#23494;&#24230;&#65292;&#21450;&#26102;&#24615;&#21644;&#31616;&#27905;&#24615;&#31561;&#26631;&#20934;&#65292;&#24182;&#33021;&#22815;&#36866;&#24212;&#20559;&#22909;&#30340;&#21464;&#21270;&#12290;&#22312;&#24681;&#38534;&#37038;&#20214;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MOSR&#22312;&#38750;&#31283;&#24577;&#20559;&#22909;&#19979;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377;&#39640;&#26041;&#24046;&#30340;&#37038;&#20214;&#29305;&#24449;&#30340;&#23567;&#22411;&#25277;&#26679;&#25968;&#25454;&#38598;&#19978;&#20063;&#33021;&#20445;&#25345;&#31283;&#23450;&#30340;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2308.08460</link><description>&lt;p&gt;
&#21160;&#24577;&#37038;&#20214;&#37325;&#26032;&#25490;&#24207;&#38382;&#39064;&#30340;&#22266;&#23450;&#31639;&#27861;&#24179;&#34913;
&lt;/p&gt;
&lt;p&gt;
Stationary Algorithmic Balancing For Dynamic Email Re-Ranking Problem. (arXiv:2308.08460v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08460
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MOSR&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21160;&#24577;&#37038;&#20214;&#37325;&#26032;&#25490;&#24207;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#20351;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#27169;&#22411;&#26469;&#24179;&#34913;&#20146;&#23494;&#24230;&#65292;&#21450;&#26102;&#24615;&#21644;&#31616;&#27905;&#24615;&#31561;&#26631;&#20934;&#65292;&#24182;&#33021;&#22815;&#36866;&#24212;&#20559;&#22909;&#30340;&#21464;&#21270;&#12290;&#22312;&#24681;&#38534;&#37038;&#20214;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MOSR&#22312;&#38750;&#31283;&#24577;&#20559;&#22909;&#19979;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377;&#39640;&#26041;&#24046;&#30340;&#37038;&#20214;&#29305;&#24449;&#30340;&#23567;&#22411;&#25277;&#26679;&#25968;&#25454;&#38598;&#19978;&#20063;&#33021;&#20445;&#25345;&#31283;&#23450;&#30340;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#37038;&#20214;&#24179;&#21488;&#38656;&#35201;&#29983;&#25104;&#28385;&#36275;&#29992;&#25143;&#20559;&#22909;&#24182;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#20010;&#24615;&#21270;&#37038;&#20214;&#25490;&#24207;&#12290;&#25105;&#20204;&#23558;&#20854;&#20316;&#20026;&#19968;&#20010;&#22522;&#20110;&#19977;&#20010;&#26631;&#20934;&#30340;&#25512;&#33616;&#38382;&#39064;&#26469;&#22788;&#29702;&#65306;&#20146;&#23494;&#24230;&#65288;&#21457;&#20214;&#20154;&#21644;&#20027;&#39064;&#19982;&#29992;&#25143;&#30340;&#30456;&#20851;&#24230;&#65289;&#65292;&#21450;&#26102;&#24615;&#65288;&#37038;&#20214;&#30340;&#26368;&#36817;&#31243;&#24230;&#65289;&#21644;&#31616;&#27905;&#24615;&#65288;&#37038;&#20214;&#30340;&#31616;&#30701;&#31243;&#24230;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;MOSR&#65288;&#22810;&#30446;&#26631;&#31283;&#24577;&#25512;&#33616;&#22120;&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#27169;&#22411;&#26469;&#21160;&#24577;&#24179;&#34913;&#36825;&#20123;&#26631;&#20934;&#24182;&#36866;&#24212;&#20559;&#22909;&#21464;&#21270;&#12290;&#25105;&#20204;&#22312;&#24681;&#38534;&#37038;&#20214;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;MOSR&#65292;&#36825;&#26159;&#19968;&#20010;&#21253;&#21547;&#22823;&#37327;&#23454;&#38469;&#37038;&#20214;&#30340;&#38598;&#21512;&#65292;&#24182;&#23558;&#20854;&#19982;&#20854;&#20182;&#22522;&#20934;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#32467;&#26524;&#26174;&#31034;MOSR&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#23588;&#20854;&#26159;&#22312;&#38750;&#31283;&#24577;&#20559;&#22909;&#19979;&#65292;&#29992;&#25143;&#38543;&#26102;&#38388;&#19981;&#21516;&#31243;&#24230;&#22320;&#35780;&#20272;&#19981;&#21516;&#30340;&#26631;&#20934;&#12290;&#25105;&#20204;&#36824;&#22312;&#19968;&#20010;&#23567;&#22411;&#25277;&#26679;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;MOSR&#30340;&#40065;&#26834;&#24615;&#65292;&#35813;&#25968;&#25454;&#38598;&#30340;&#37038;&#20214;&#29305;&#24449;&#21464;&#21270;&#24456;&#22823;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#19981;&#21516;&#26679;&#26412;&#20013;&#20445;&#25345;&#31283;&#23450;&#30340;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
Email platforms need to generate personalized rankings of emails that satisfy user preferences, which may vary over time. We approach this as a recommendation problem based on three criteria: closeness (how relevant the sender and topic are to the user), timeliness (how recent the email is), and conciseness (how brief the email is). We propose MOSR (Multi-Objective Stationary Recommender), a novel online algorithm that uses an adaptive control model to dynamically balance these criteria and adapt to preference changes. We evaluate MOSR on the Enron Email Dataset, a large collection of real emails, and compare it with other baselines. The results show that MOSR achieves better performance, especially under non-stationary preferences, where users value different criteria more or less over time. We also test MOSR's robustness on a smaller down-sampled dataset that exhibits high variance in email characteristics, and show that it maintains stable rankings across different samples. Our work
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#30693;&#35782;&#25552;&#31034;&#35843;&#20248;&#30340;&#39034;&#24207;&#25512;&#33616;(KP4SR)&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22806;&#37096;&#30693;&#35782;&#24211;&#21644;&#26500;&#24314;&#30693;&#35782;&#25552;&#31034;&#65292;&#35299;&#20915;&#20102;&#39034;&#24207;&#25512;&#33616;&#20013;&#30340;&#35821;&#20041;&#24046;&#36317;&#21644;&#20449;&#24687;&#25439;&#22833;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08459</link><description>&lt;p&gt;
&#30693;&#35782;&#25552;&#31034;&#35843;&#20248;&#30340;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Knowledge Prompt-tuning for Sequential Recommendation. (arXiv:2308.08459v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08459
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#30693;&#35782;&#25552;&#31034;&#35843;&#20248;&#30340;&#39034;&#24207;&#25512;&#33616;(KP4SR)&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22806;&#37096;&#30693;&#35782;&#24211;&#21644;&#26500;&#24314;&#30693;&#35782;&#25552;&#31034;&#65292;&#35299;&#20915;&#20102;&#39034;&#24207;&#25512;&#33616;&#20013;&#30340;&#35821;&#20041;&#24046;&#36317;&#21644;&#20449;&#24687;&#25439;&#22833;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;(PLMs)&#22312;&#39034;&#24207;&#25512;&#33616;(SR)&#20013;&#23637;&#31034;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#65292;&#29992;&#20110;&#25552;&#21462;&#36890;&#29992;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20173;&#28982;&#32570;&#20047;&#39046;&#22495;&#30693;&#35782;&#65292;&#24182;&#19988;&#24456;&#38590;&#25429;&#25417;&#29992;&#25143;&#30340;&#32454;&#31890;&#24230;&#20559;&#22909;&#12290;&#21516;&#26102;&#65292;&#35768;&#22810;&#20256;&#32479;&#30340;SR&#26041;&#27861;&#36890;&#36807;&#25972;&#21512;&#36741;&#21161;&#20449;&#24687;&#26469;&#25913;&#21892;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#21364;&#36973;&#21463;&#20449;&#24687;&#25439;&#22833;&#30340;&#22256;&#25200;&#12290;&#24635;&#32780;&#35328;&#20043;&#65292;&#25105;&#20204;&#35748;&#20026;&#19968;&#20010;&#22909;&#30340;&#25512;&#33616;&#31995;&#32479;&#24212;&#35813;&#21516;&#26102;&#21033;&#29992;&#36890;&#29992;&#30693;&#35782;&#21644;&#39046;&#22495;&#30693;&#35782;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22806;&#37096;&#30693;&#35782;&#24211;&#65292;&#24182;&#25552;&#20986;&#20102;&#30693;&#35782;&#25552;&#31034;&#35843;&#20248;&#30340;&#39034;&#24207;&#25512;&#33616;(KP4SR)&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#32452;&#20851;&#31995;&#27169;&#26495;&#65292;&#24182;&#23558;&#32467;&#26500;&#21270;&#30693;&#35782;&#22270;&#35889;(KG)&#36716;&#21270;&#20026;&#30693;&#35782;&#25552;&#31034;&#65292;&#20197;&#35299;&#20915;&#35821;&#20041;&#24046;&#36317;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30693;&#35782;&#25552;&#31034;&#30772;&#22351;&#20102;&#21407;&#22987;&#25968;&#25454;&#32467;&#26500;&#24182;&#24341;&#20837;&#20102;&#22823;&#37327;&#30340;&#22122;&#38899;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#26500;&#24314;&#20102;&#19968;&#20010;&#30693;&#35782;&#26641;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#30693;&#35782;&#26641;&#30340;&#26041;&#27861;&#26469;&#20943;&#23569;&#22122;&#38899;&#24182;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained language models (PLMs) have demonstrated strong performance in sequential recommendation (SR), which are utilized to extract general knowledge. However, existing methods still lack domain knowledge and struggle to capture users' fine-grained preferences. Meanwhile, many traditional SR methods improve this issue by integrating side information while suffering from information loss. To summarize, we believe that a good recommendation system should utilize both general and domain knowledge simultaneously. Therefore, we introduce an external knowledge base and propose Knowledge Prompt-tuning for Sequential Recommendation (\textbf{KP4SR}). Specifically, we construct a set of relationship templates and transform a structured knowledge graph (KG) into knowledge prompts to solve the problem of the semantic gap. However, knowledge prompts disrupt the original data structure and introduce a significant amount of noise. We further construct a knowledge tree and propose a knowledge tre
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CSPM&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21644;&#26102;&#31354;&#20559;&#22909;&#25552;&#21462;&#26469;&#35299;&#20915;&#25353;&#38656;&#39135;&#21697;&#37197;&#36865;CTR&#39044;&#27979;&#20013;&#30340;&#26102;&#31354;&#20449;&#24687;&#24314;&#27169;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.08446</link><description>&lt;p&gt;
CSPM: &#29992;&#20110;&#25353;&#38656;&#39135;&#21697;&#37197;&#36865;CTR&#39044;&#27979;&#30340;&#23545;&#27604;&#26102;&#31354;&#20559;&#22909;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
CSPM: A Contrastive Spatiotemporal Preference Model for CTR Prediction in On-Demand Food Delivery Services. (arXiv:2308.08446v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CSPM&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21644;&#26102;&#31354;&#20559;&#22909;&#25552;&#21462;&#26469;&#35299;&#20915;&#25353;&#38656;&#39135;&#21697;&#37197;&#36865;CTR&#39044;&#27979;&#20013;&#30340;&#26102;&#31354;&#20449;&#24687;&#24314;&#27169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#26159;&#22312;&#32447;&#25353;&#38656;&#39135;&#21697;&#37197;&#36865;&#65288;OFD&#65289;&#24179;&#21488;&#20013;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#65292;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#29992;&#25143;&#28857;&#20987;&#39135;&#21697;&#39033;&#30446;&#30340;&#27010;&#29575;&#12290;&#19982;&#28120;&#23453;&#21644;&#20122;&#39532;&#36874;&#31561;&#36890;&#29992;&#30005;&#21830;&#24179;&#21488;&#19981;&#21516;&#65292;OFD&#24179;&#21488;&#19978;&#30340;&#29992;&#25143;&#34892;&#20026;&#21644;&#20852;&#36259;&#26356;&#21152;&#19982;&#22320;&#28857;&#21644;&#26102;&#38388;&#30456;&#20851;&#65292;&#36825;&#26159;&#22240;&#20026;&#23384;&#22312;&#26377;&#38480;&#30340;&#37197;&#36865;&#33539;&#22260;&#21644;&#21306;&#22495;&#21830;&#21697;&#20379;&#24212;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;OFD&#22330;&#26223;&#19979;&#30340;CTR&#39044;&#27979;&#31639;&#27861;&#20027;&#35201;&#38598;&#20013;&#20110;&#25429;&#25417;&#26469;&#33258;&#21382;&#21490;&#34892;&#20026;&#24207;&#21015;&#30340;&#20852;&#36259;&#65292;&#26410;&#33021;&#26377;&#25928;&#22320;&#23545;&#29305;&#24449;&#20013;&#30340;&#22797;&#26434;&#26102;&#31354;&#20449;&#24687;&#36827;&#34892;&#24314;&#27169;&#65292;&#23548;&#33268;&#24615;&#33021;&#36739;&#24046;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#27604;&#26102;&#31354;&#20559;&#22909;&#27169;&#22411;&#65288;CSPM&#65289;&#65292;&#36890;&#36807;&#23545;&#27604;&#26102;&#31354;&#34920;&#31034;&#23398;&#20064;&#65288;CSRL&#65289;&#12289;&#26102;&#31354;&#20559;&#22909;&#25552;&#21462;&#22120;&#65288;StPE&#65289;&#21644;&#26102;&#31354;&#20449;&#24687;&#36807;&#28388;&#22120;&#65288;StIF&#65289;&#19977;&#20010;&#27169;&#22359;&#65292;&#23545;&#19981;&#21516;&#25628;&#32034;&#29366;&#24577;&#19979;&#30340;&#29992;&#25143;&#20559;&#22909;&#36827;&#34892;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction is a crucial task in the context of an online on-demand food delivery (OFD) platform for precisely estimating the probability of a user clicking on food items. Unlike universal e-commerce platforms such as Taobao and Amazon, user behaviors and interests on the OFD platform are more location and time-sensitive due to limited delivery ranges and regional commodity supplies. However, existing CTR prediction algorithms in OFD scenarios concentrate on capturing interest from historical behavior sequences, which fails to effectively model the complex spatiotemporal information within features, leading to poor performance. To address this challenge, this paper introduces the Contrastive Sres under different search states using three modules: contrastive spatiotemporal representation learning (CSRL), spatiotemporal preference extractor (StPE), and spatiotemporal information filter (StIF). CSRL utilizes a contrastive learning framework to generate a spatiotem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;BIGRec&#30340;&#20004;&#27493;&#25509;&#22320;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#25512;&#33616;&#31354;&#38388;&#25509;&#22320;&#65292;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#26631;&#35760;&#65292;&#24182;&#35782;&#21035;&#30456;&#24212;&#30340;&#23454;&#38469;&#39033;&#30446;&#65292;&#26469;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20840;&#38754;&#25490;&#24207;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.08434</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#21452;&#27493;&#25509;&#22320;&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems. (arXiv:2308.08434v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;BIGRec&#30340;&#20004;&#27493;&#25509;&#22320;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#25512;&#33616;&#31354;&#38388;&#25509;&#22320;&#65292;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#26631;&#35760;&#65292;&#24182;&#35782;&#21035;&#30456;&#24212;&#30340;&#23454;&#38469;&#39033;&#30446;&#65292;&#26469;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20840;&#38754;&#25490;&#24207;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25512;&#33616;&#39046;&#22495;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20851;&#27880;&#21152;&#24378;&#65292;&#38024;&#23545;&#25512;&#33616;&#30446;&#30340;&#65288;&#31216;&#20026;LLM4Rec&#65289;&#20248;&#21270;LLMs&#30340;&#37325;&#35201;&#24615;&#22312;&#25552;&#20379;&#25512;&#33616;&#26041;&#38754;&#24471;&#21040;&#20102;&#22686;&#24378;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;LLM4Rec&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#26377;&#38480;&#30340;&#20505;&#36873;&#38598;&#26469;&#35780;&#20272;&#24615;&#33021;&#65292;&#36825;&#21487;&#33021;&#26080;&#27861;&#20934;&#30830;&#21453;&#26144;&#27169;&#22411;&#30340;&#25972;&#20307;&#25490;&#24207;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35843;&#26597;LLMs&#30340;&#20840;&#38754;&#25490;&#24207;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#19968;&#20010;&#21517;&#20026;BIGRec&#65288;&#25512;&#33616;&#30340;&#21452;&#27493;&#25509;&#22320;&#33539;&#24335;&#65289;&#30340;&#20004;&#27493;&#25509;&#22320;&#26694;&#26550;&#12290;&#23427;&#39318;&#20808;&#36890;&#36807;&#24494;&#35843;&#23558;LLMs&#19982;&#25512;&#33616;&#31354;&#38388;&#25509;&#22320;&#65292;&#29983;&#25104;&#19982;&#39033;&#30446;&#30456;&#20851;&#30340;&#26377;&#24847;&#20041;&#30340;&#26631;&#35760;&#65292;&#28982;&#21518;&#35782;&#21035;&#19982;&#29983;&#25104;&#30340;&#26631;&#35760;&#30456;&#23545;&#24212;&#30340;&#36866;&#24403;&#23454;&#38469;&#39033;&#30446;&#12290;&#36890;&#36807;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#12289;&#22788;&#29702;&#23569;&#26679;&#26412;&#22330;&#26223;&#30340;&#33021;&#21147;&#20197;&#21450;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#36890;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the focus on Large Language Models (LLMs) in the field of recommendation intensifies, the optimization of LLMs for recommendation purposes (referred to as LLM4Rec) assumes a crucial role in augmenting their effectiveness in providing recommendations. However, existing approaches for LLM4Rec often assess performance using restricted sets of candidates, which may not accurately reflect the models' overall ranking capabilities. In this paper, our objective is to investigate the comprehensive ranking capacity of LLMs and propose a two-step grounding framework known as BIGRec (Bi-step Grounding Paradigm for Recommendation). It initially grounds LLMs to the recommendation space by fine-tuning them to generate meaningful tokens for items and subsequently identifies appropriate actual items that correspond to the generated tokens. By conducting extensive experiments on two datasets, we substantiate the superior performance, capacity for handling few-shot scenarios, and versatility across mu
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#22686;&#24378;&#30340;&#22810;&#26631;&#31614;&#23569;&#26679;&#26412;&#20135;&#21697;&#23646;&#24615;&#20540;&#25552;&#21462;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29983;&#25104;&#30340;&#26631;&#31614;&#25551;&#36848;&#21644;&#31867;&#21035;&#20449;&#24687;&#26469;&#23398;&#20064;&#26356;&#20855;&#26377;&#21306;&#20998;&#24615;&#30340;&#21407;&#22411;&#65292;&#24182;&#25972;&#21512;&#28151;&#21512;&#27880;&#24847;&#21147;&#26469;&#20943;&#23569;&#22122;&#22768;&#21644;&#25429;&#25417;&#26356;&#22810;&#20449;&#24687;&#20016;&#23500;&#30340;&#35821;&#20041;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#25552;&#21462;&#26410;&#35265;&#36807;&#30340;&#23646;&#24615;&#20540;&#23545;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.08413</link><description>&lt;p&gt;
&#30693;&#35782;&#22686;&#24378;&#30340;&#22810;&#26631;&#31614;&#23569;&#26679;&#26412;&#20135;&#21697;&#23646;&#24615;&#20540;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value Extraction. (arXiv:2308.08413v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08413
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#22686;&#24378;&#30340;&#22810;&#26631;&#31614;&#23569;&#26679;&#26412;&#20135;&#21697;&#23646;&#24615;&#20540;&#25552;&#21462;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29983;&#25104;&#30340;&#26631;&#31614;&#25551;&#36848;&#21644;&#31867;&#21035;&#20449;&#24687;&#26469;&#23398;&#20064;&#26356;&#20855;&#26377;&#21306;&#20998;&#24615;&#30340;&#21407;&#22411;&#65292;&#24182;&#25972;&#21512;&#28151;&#21512;&#27880;&#24847;&#21147;&#26469;&#20943;&#23569;&#22122;&#22768;&#21644;&#25429;&#25417;&#26356;&#22810;&#20449;&#24687;&#20016;&#23500;&#30340;&#35821;&#20041;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#25552;&#21462;&#26410;&#35265;&#36807;&#30340;&#23646;&#24615;&#20540;&#23545;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#23646;&#24615;&#20540;&#25552;&#21462;&#65288;AVE&#65289;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#30340;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#30005;&#23376;&#21830;&#21153;&#27599;&#22825;&#37117;&#20250;&#26377;&#24102;&#26377;&#26032;&#23646;&#24615;&#20540;&#23545;&#30340;&#26032;&#20135;&#21697;&#36827;&#20837;&#24066;&#22330;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#22312;&#22810;&#26631;&#31614;&#23569;&#26679;&#26412;&#23398;&#20064;&#65288;FSL&#65289;&#20013;&#21046;&#23450;AVE&#65292;&#26088;&#22312;&#22522;&#20110;&#23569;&#37327;&#30340;&#35757;&#32451;&#31034;&#20363;&#25552;&#21462;&#26410;&#35265;&#36807;&#30340;&#23646;&#24615;&#20540;&#23545;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#32593;&#32476;&#30340;&#30693;&#35782;&#22686;&#24378;&#27880;&#24847;&#21147;&#26694;&#26550;&#65288;KEAF&#65289;&#65292;&#21033;&#29992;&#29983;&#25104;&#30340;&#26631;&#31614;&#25551;&#36848;&#21644;&#31867;&#21035;&#20449;&#24687;&#26469;&#23398;&#20064;&#26356;&#20855;&#26377;&#21306;&#20998;&#24615;&#30340;&#21407;&#22411;&#12290;&#27492;&#22806;&#65292;KEAF&#36890;&#36807;&#35745;&#31639;&#19982;&#26631;&#31614;&#30456;&#20851;&#30340;&#26435;&#37325;&#21644;&#26597;&#35810;&#30456;&#20851;&#30340;&#26435;&#37325;&#65292;&#25972;&#21512;&#20102;&#28151;&#21512;&#27880;&#24847;&#21147;&#65292;&#20197;&#20943;&#23569;&#22122;&#22768;&#24182;&#25429;&#25417;&#26356;&#22810;&#20449;&#24687;&#20016;&#23500;&#30340;&#35821;&#20041;&#12290;&#20026;&#20102;&#23454;&#29616;&#22810;&#26631;&#31614;&#25512;&#29702;&#65292;KEAF&#36827;&#19968;&#27493;&#36890;&#36807;&#25972;&#21512;&#25903;&#25345;&#38598;&#21644;&#26597;&#35810;&#38598;&#30340;&#35821;&#20041;&#20449;&#24687;&#26469;&#23398;&#20064;&#21160;&#24577;&#38408;&#20540;&#12290;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#21644;&#28040;&#34701;&#30740;&#31350;&#34920;&#26126;&#65292;KEAF&#30340;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing attribute-value extraction (AVE) models require large quantities of labeled data for training. However, new products with new attribute-value pairs enter the market every day in real-world e-Commerce. Thus, we formulate AVE in multi-label few-shot learning (FSL), aiming to extract unseen attribute value pairs based on a small number of training examples. We propose a Knowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks, leveraging the generated label description and category information to learn more discriminative prototypes. Besides, KEAF integrates with hybrid attention to reduce noise and capture more informative semantics for each class by calculating the label-relevant and query-related weights. To achieve multi-label inference, KEAF further learns a dynamic threshold by integrating the semantic information from both the support set and the query set. Extensive experiments with ablation studies conducted on two datasets demonstrate that KEAF outpe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#24341;&#25806;&#65292;&#36890;&#36807;&#35745;&#31639;&#25991;&#26723;&#20013;&#21333;&#35789;&#30340;&#30456;&#20851;&#24615;&#21644;&#20351;&#29992;&#20313;&#24358;&#30456;&#20284;&#24230;&#26041;&#27861;&#26469;&#25512;&#33616;&#35270;&#39057;&#32473;&#29992;&#25143;&#12290;&#21516;&#26102;&#65292;&#36824;&#36890;&#36807;&#35745;&#31639;&#31934;&#30830;&#29575;&#12289;&#21484;&#22238;&#29575;&#21644;F1&#24471;&#20998;&#26469;&#35780;&#20272;&#24341;&#25806;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08406</link><description>&lt;p&gt;
&#22522;&#20110;&#20869;&#23481;&#30340;&#35270;&#39057;&#27969;&#23186;&#20307;&#24179;&#21488;&#25512;&#33616;&#24341;&#25806;
&lt;/p&gt;
&lt;p&gt;
Content-based Recommendation Engine for Video Streaming Platform. (arXiv:2308.08406v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#24341;&#25806;&#65292;&#36890;&#36807;&#35745;&#31639;&#25991;&#26723;&#20013;&#21333;&#35789;&#30340;&#30456;&#20851;&#24615;&#21644;&#20351;&#29992;&#20313;&#24358;&#30456;&#20284;&#24230;&#26041;&#27861;&#26469;&#25512;&#33616;&#35270;&#39057;&#32473;&#29992;&#25143;&#12290;&#21516;&#26102;&#65292;&#36824;&#36890;&#36807;&#35745;&#31639;&#31934;&#30830;&#29575;&#12289;&#21484;&#22238;&#29575;&#21644;F1&#24471;&#20998;&#26469;&#35780;&#20272;&#24341;&#25806;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#24341;&#25806;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21521;&#29992;&#25143;&#24314;&#35758;&#20869;&#23481;&#12289;&#20135;&#21697;&#25110;&#26381;&#21153;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#24341;&#25806;&#65292;&#26681;&#25454;&#29992;&#25143;&#20043;&#21069;&#30340;&#20852;&#36259;&#21644;&#36873;&#25321;&#65292;&#21521;&#29992;&#25143;&#25552;&#20379;&#35270;&#39057;&#25512;&#33616;&#12290;&#25105;&#20204;&#23558;&#20351;&#29992;TF-IDF&#25991;&#26412;&#21521;&#37327;&#21270;&#26041;&#27861;&#26469;&#30830;&#23450;&#25991;&#26723;&#20013;&#21333;&#35789;&#30340;&#30456;&#20851;&#24615;&#12290;&#28982;&#21518;&#36890;&#36807;&#35745;&#31639;&#23427;&#20204;&#20043;&#38388;&#30340;&#20313;&#24358;&#30456;&#20284;&#24230;&#65292;&#25214;&#20986;&#27599;&#20010;&#20869;&#23481;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#26368;&#21518;&#65292;&#26681;&#25454;&#24471;&#21040;&#30340;&#30456;&#20284;&#24230;&#20998;&#25968;&#20540;&#65292;&#24341;&#25806;&#23558;&#21521;&#29992;&#25143;&#25512;&#33616;&#35270;&#39057;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#23558;&#36890;&#36807;&#35745;&#31639;&#31934;&#30830;&#29575;&#12289;&#21484;&#22238;&#29575;&#21644;F1&#24471;&#20998;&#26469;&#34913;&#37327;&#24341;&#25806;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation engine suggest content, product or services to the user by using machine learning algorithm. This paper proposed a content-based recommendation engine for providing video suggestion to the user based on their previous interests and choices. We will use TF-IDF text vectorization method to determine the relevance of words in a document. Then we will find out the similarity between each content by calculating cosine similarity between them. Finally, engine will recommend videos to the users based on the obtained similarity score value. In addition, we will measure the engine's performance by computing precision, recall, and F1 core of the proposed system.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#27169;&#25311;&#36830;&#32493;&#20449;&#24687;&#26816;&#32034;&#30340;&#22810;&#20027;&#39064;&#25968;&#25454;&#38598;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#26694;&#26550;&#65292;&#33021;&#22815;&#38450;&#27490;&#28798;&#38590;&#24615;&#36951;&#24536;&#24182;&#25552;&#39640;&#20808;&#21069;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08378</link><description>&lt;p&gt;
&#25512;&#36827;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#25345;&#32493;&#32456;&#36523;&#23398;&#20064;&#65306;&#23450;&#20041;&#12289;&#25968;&#25454;&#38598;&#12289;&#26694;&#26550;&#21644;&#23454;&#35777;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Advancing continual lifelong learning in neural information retrieval: definition, dataset, framework, and empirical evaluation. (arXiv:2308.08378v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#27169;&#25311;&#36830;&#32493;&#20449;&#24687;&#26816;&#32034;&#30340;&#22810;&#20027;&#39064;&#25968;&#25454;&#38598;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#26694;&#26550;&#65292;&#33021;&#22815;&#38450;&#27490;&#28798;&#38590;&#24615;&#36951;&#24536;&#24182;&#25552;&#39640;&#20808;&#21069;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#23398;&#20064;&#26159;&#25351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#23398;&#20064;&#21644;&#36866;&#24212;&#26032;&#20449;&#24687;&#30340;&#21516;&#26102;&#65292;&#19981;&#24433;&#21709;&#20854;&#22312;&#20808;&#21069;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#24050;&#26377;&#22810;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#20294;&#20173;&#32570;&#20047;&#26126;&#30830;&#30340;&#20219;&#21153;&#23450;&#20041;&#65292;&#24182;&#19988;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#22312;&#36825;&#31181;&#32972;&#26223;&#19979;&#20856;&#22411;&#30340;&#23398;&#20064;&#31574;&#30053;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#27169;&#25311;&#36830;&#32493;&#20449;&#24687;&#26816;&#32034;&#30340;&#22810;&#20027;&#39064;&#25968;&#25454;&#38598;&#12290;&#38543;&#21518;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#25345;&#32493;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#26694;&#26550;&#65292;&#21253;&#25324;&#20856;&#22411;&#26816;&#32034;&#27169;&#22411;&#21644;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#33021;&#22815;&#25104;&#21151;&#22320;&#38450;&#27490;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#24182;&#25552;&#39640;&#20808;&#21069;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#23884;&#20837;&#30340;&#26816;&#32034;&#26041;&#24335;&#36739;&#20256;&#32479;&#30340;&#22522;&#20110;&#32034;&#24341;&#30340;&#26816;&#32034;&#26041;&#24335;&#20855;&#26377;&#20248;&#21183;&#65292;&#24182;&#19988;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#33021;&#22815;&#26377;&#25928;&#22320;&#25552;&#21319;&#26816;&#32034;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Continual learning refers to the capability of a machine learning model to learn and adapt to new information, without compromising its performance on previously learned tasks. Although several studies have investigated continual learning methods for information retrieval tasks, a well-defined task formulation is still lacking, and it is unclear how typical learning strategies perform in this context. To address this challenge, a systematic task formulation of continual neural information retrieval is presented, along with a multiple-topic dataset that simulates continuous information retrieval. A comprehensive continual neural information retrieval framework consisting of typical retrieval models and continual learning strategies is then proposed. Empirical evaluations illustrate that the proposed framework can successfully prevent catastrophic forgetting in neural information retrieval and enhance performance on previously learned tasks. The results indicate that embedding-based retr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#20803;&#23398;&#20064;&#25216;&#26415;&#22312;&#22788;&#29702;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26102;&#24050;&#25104;&#20026;&#26368;&#21463;&#27426;&#36814;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#22312;&#23454;&#38469;&#25512;&#33616;&#31995;&#32479;&#20013;&#24182;&#19981;&#23454;&#29992;&#65292;&#22240;&#20026;&#36825;&#20123;&#31995;&#32479;&#25317;&#26377;&#24222;&#22823;&#30340;&#29992;&#25143;&#21644;&#29289;&#21697;&#25968;&#37327;&#65292;&#19988;&#26377;&#20005;&#26684;&#30340;&#24310;&#36831;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2308.08354</link><description>&lt;p&gt;
&#20803;&#23398;&#20064;&#26159;&#21542;&#26159;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#27491;&#30830;&#26041;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Meta-Learning the Right Approach for the Cold-Start Problem in Recommender Systems?. (arXiv:2308.08354v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08354
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#20803;&#23398;&#20064;&#25216;&#26415;&#22312;&#22788;&#29702;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26102;&#24050;&#25104;&#20026;&#26368;&#21463;&#27426;&#36814;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#22312;&#23454;&#38469;&#25512;&#33616;&#31995;&#32479;&#20013;&#24182;&#19981;&#23454;&#29992;&#65292;&#22240;&#20026;&#36825;&#20123;&#31995;&#32479;&#25317;&#26377;&#24222;&#22823;&#30340;&#29992;&#25143;&#21644;&#29289;&#21697;&#25968;&#37327;&#65292;&#19988;&#26377;&#20005;&#26684;&#30340;&#24310;&#36831;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#32463;&#25104;&#20026;&#29616;&#20195;&#22312;&#32447;&#20135;&#21697;&#21644;&#26381;&#21153;&#30340;&#22522;&#30784;&#26500;&#24314;&#27169;&#22359;&#65292;&#24182;&#23545;&#29992;&#25143;&#20307;&#39564;&#20135;&#29983;&#20102;&#37325;&#22823;&#24433;&#21709;&#12290;&#22312;&#36807;&#21435;&#30340;&#20960;&#24180;&#20013;&#65292;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#21560;&#24341;&#20102;&#22823;&#37327;&#30340;&#30740;&#31350;&#65292;&#24182;&#22312;&#29616;&#20195;&#23454;&#38469;&#25512;&#33616;&#31995;&#32479;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22788;&#29702;&#20919;&#21551;&#21160;&#35774;&#32622;&#19979;&#30340;&#25512;&#33616;&#38382;&#39064;&#65292;&#20363;&#22914;&#24403;&#29992;&#25143;&#22312;&#31995;&#32479;&#20013;&#30340;&#20114;&#21160;&#26377;&#38480;&#26102;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#36828;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20803;&#23398;&#20064;&#25216;&#26415;&#65292;&#23588;&#20854;&#26159;&#22522;&#20110;&#20248;&#21270;&#30340;&#20803;&#23398;&#20064;&#65292;&#26368;&#36817;&#24050;&#25104;&#20026;&#23398;&#26415;&#30740;&#31350;&#25991;&#29486;&#20013;&#22788;&#29702;&#25512;&#33616;&#31995;&#32479;&#20013;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#26368;&#27969;&#34892;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#23545;&#20110;&#25317;&#26377;&#25968;&#21313;&#20159;&#29992;&#25143;&#21644;&#29289;&#21697;&#20197;&#21450;&#20005;&#26684;&#30340;&#24310;&#36831;&#35201;&#27714;&#30340;&#29616;&#23454;&#25512;&#33616;&#31995;&#32479;&#26469;&#35828;&#24182;&#19981;&#23454;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#24120;&#29992;&#22522;&#20934;&#19978;&#33719;&#24471;&#31867;&#20284;&#25110;&#26356;&#39640;&#24615;&#33021;&#26159;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have become fundamental building blocks of modern online products and services, and have a substantial impact on user experience. In the past few years, deep learning methods have attracted a lot of research, and are now heavily used in modern real-world recommender systems. Nevertheless, dealing with recommendations in the cold-start setting, e.g., when a user has done limited interactions in the system, is a problem that remains far from solved. Meta-learning techniques, and in particular optimization-based meta-learning, have recently become the most popular approaches in the academic research literature for tackling the cold-start problem in deep learning models for recommender systems. However, current meta-learning approaches are not practical for real-world recommender systems, which have billions of users and items, and strict latency requirements. In this paper we show that it is possible to obtaining similar, or higher, performance on commonly used benchma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#22791;&#32972;&#26223;&#20449;&#24687;&#30340;&#30456;&#20301;&#24674;&#22797;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#26041;&#27861;&#19982;&#29702;&#35770;&#32467;&#26524;&#65292;&#25104;&#21151;&#20943;&#23569;&#20102;&#23545;&#32972;&#26223;&#20449;&#24687;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2308.08328</link><description>&lt;p&gt;
&#20855;&#22791;&#32972;&#26223;&#20449;&#24687;&#30340;&#30456;&#20301;&#24674;&#22797;&#65306;&#20943;&#23569;&#21442;&#32771;&#21644;&#39640;&#25928;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Phase Retrieval with Background Information: Decreased References and Efficient Methods. (arXiv:2308.08328v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08328
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#22791;&#32972;&#26223;&#20449;&#24687;&#30340;&#30456;&#20301;&#24674;&#22797;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#26041;&#27861;&#19982;&#29702;&#35770;&#32467;&#26524;&#65292;&#25104;&#21151;&#20943;&#23569;&#20102;&#23545;&#32972;&#26223;&#20449;&#24687;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20613;&#37324;&#21494;&#30456;&#20301;&#24674;&#22797;&#26159;&#19968;&#20010;&#20005;&#37325;&#30149;&#24577;&#30340;&#21453;&#38382;&#39064;&#65292;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#37117;&#20250;&#20986;&#29616;&#12290;&#20026;&#20102;&#20445;&#35777;&#21807;&#19968;&#35299;&#24182;&#20943;&#23569;&#23545;&#21021;&#22987;&#21270;&#30340;&#20381;&#36182;&#65292;&#21487;&#20197;&#21033;&#29992;&#32972;&#26223;&#20449;&#24687;&#20316;&#20026;&#32467;&#26500;&#20808;&#39564;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#20998;&#36776;&#29575;&#25104;&#20687;&#26102;&#65292;&#23545;&#32972;&#26223;&#20449;&#24687;&#30340;&#38656;&#27714;&#21487;&#33021;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#20043;&#21069;&#25552;&#20986;&#30340;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#65288;PGD&#65289;&#26041;&#27861;&#20063;&#38656;&#35201;&#22823;&#37327;&#30340;&#32972;&#26223;&#20449;&#24687;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#32972;&#26223;&#20449;&#24687;&#38656;&#27714;&#30340;&#25913;&#36827;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;Douglas Rachford&#65288;DR&#65289;&#30340;&#26041;&#27861;&#12290;&#20998;&#26512;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;2-D&#20449;&#21495;&#30456;&#27604;&#20110;1-D&#20449;&#21495;&#20013;&#65292;&#20026;&#20102;&#30830;&#20445;&#21807;&#19968;&#35299;&#25152;&#38656;&#30340;&#32972;&#26223;&#21487;&#20197;&#20943;&#23569;&#23558;&#36817;$1/2$&#12290;&#36890;&#36807;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;$d$-dimension&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36229;&#36807;&#20449;&#21495;&#38271;&#24230;$(2^{\frac{d+1}{d}}-1)$&#20493;&#30340;&#32972;&#26223;&#20449;&#24687;&#36275;&#20197;&#30830;&#20445;&#21807;&#19968;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fourier phase retrieval(PR) is a severely ill-posed inverse problem that arises in various applications. To guarantee a unique solution and relieve the dependence on the initialization, background information can be exploited as a structural priors. However, the requirement for the background information may be challenging when moving to the high-resolution imaging. At the same time, the previously proposed projected gradient descent(PGD) method also demands much background information.  In this paper, we present an improved theoretical result about the demand for the background information, along with two Douglas Rachford(DR) based methods. Analytically, we demonstrate that the background required to ensure a unique solution can be decreased by nearly $1/2$ for the 2-D signals compared to the 1-D signals. By generalizing the results into $d$-dimension, we show that the length of the background information more than $(2^{\frac{d+1}{d}}-1)$ folds of the signal is sufficient to ensure th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26723;&#25193;&#23637;&#39044;&#35757;&#32451;&#23545;&#31264;&#23494;&#36890;&#36947;&#26816;&#32034;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;&#21033;&#29992;&#35813;&#26041;&#27861;&#36827;&#34892;&#26597;&#35810;&#29983;&#25104;&#24182;&#20256;&#36882;&#25193;&#23637;&#30340;&#30693;&#35782;&#32473;&#26816;&#32034;&#22120;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#22823;&#35268;&#27169;&#32593;&#32476;&#25628;&#32034;&#20219;&#21153;&#30340;&#26816;&#32034;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08285</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26723;&#25193;&#23637;&#39044;&#35757;&#32451;&#29992;&#20110;&#31264;&#23494;&#36890;&#36947;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Pre-training with Large Language Model-based Document Expansion for Dense Passage Retrieval. (arXiv:2308.08285v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26723;&#25193;&#23637;&#39044;&#35757;&#32451;&#23545;&#31264;&#23494;&#36890;&#36947;&#26816;&#32034;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;&#21033;&#29992;&#35813;&#26041;&#27861;&#36827;&#34892;&#26597;&#35810;&#29983;&#25104;&#24182;&#20256;&#36882;&#25193;&#23637;&#30340;&#30693;&#35782;&#32473;&#26816;&#32034;&#22120;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#22823;&#35268;&#27169;&#32593;&#32476;&#25628;&#32034;&#20219;&#21153;&#30340;&#26816;&#32034;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#25991;&#26723;&#25193;&#23637;&#39044;&#35757;&#32451;&#22312;&#31264;&#23494;&#36890;&#36947;&#26816;&#32034;&#20013;&#30340;&#28508;&#21147;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;LLMs&#30340;&#33021;&#21147;&#36827;&#34892;&#25991;&#26723;&#25193;&#23637;&#65292;&#21363;&#26597;&#35810;&#29983;&#25104;&#65292;&#24182;&#36890;&#36807;&#38024;&#23545;&#36890;&#36947;&#26816;&#32034;&#30340;&#39044;&#35757;&#32451;&#31574;&#30053;&#26377;&#25928;&#22320;&#23558;&#25193;&#23637;&#30340;&#30693;&#35782;&#20256;&#36882;&#32473;&#26816;&#32034;&#22120;&#12290;&#36825;&#20123;&#31574;&#30053;&#21253;&#25324;&#23545;&#27604;&#23398;&#20064;&#21644;&#29942;&#39048;&#26597;&#35810;&#29983;&#25104;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#37319;&#29992;&#20102;&#35838;&#31243;&#23398;&#20064;&#31574;&#30053;&#26469;&#20943;&#23569;&#23545;LLM&#25512;&#29702;&#30340;&#20381;&#36182;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;LLM&#30340;&#25991;&#26723;&#25193;&#23637;&#39044;&#35757;&#32451;&#26174;&#33879;&#25552;&#39640;&#20102;&#22823;&#35268;&#27169;&#32593;&#32476;&#25628;&#32034;&#20219;&#21153;&#30340;&#26816;&#32034;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#38646;-shot&#21644;&#36328;&#39046;&#22495;&#26816;&#32034;&#33021;&#21147;&#65292;&#22312;&#27809;&#26377;&#20154;&#24037;&#26631;&#27880;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#26356;&#20855;&#24191;&#27867;&#30340;&#24212;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we systematically study the potential of pre-training with Large Language Model(LLM)-based document expansion for dense passage retrieval. Concretely, we leverage the capabilities of LLMs for document expansion, i.e. query generation, and effectively transfer expanded knowledge to retrievers using pre-training strategies tailored for passage retrieval. These strategies include contrastive learning and bottlenecked query generation. Furthermore, we incorporate a curriculum learning strategy to reduce the reliance on LLM inferences. Experimental results demonstrate that pre-training with LLM-based document expansion significantly boosts the retrieval performance on large-scale web-search tasks. Our work shows strong zero-shot and out-of-domain retrieval abilities, making it more widely applicable for retrieval when initializing with no human-labeled data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#35270;&#39057;&#25512;&#33616;&#20013;&#35266;&#30475;&#26102;&#38271;&#30340;&#29983;&#25104;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#35270;&#39057;&#25512;&#33616;&#26041;&#27861;&#65292;&#20943;&#36731;&#20102;&#25345;&#32493;&#26102;&#38388;&#20559;&#24046;&#21644;&#22122;&#22768;&#35266;&#30475;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#24182;&#25913;&#21892;&#20102;&#20174;&#35266;&#30475;&#26102;&#38271;&#20013;&#25581;&#31034;&#29992;&#25143;&#20852;&#36259;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.08120</link><description>&lt;p&gt;
&#20174;&#20559;&#24046;&#21644;&#22122;&#22768;&#30340;&#35266;&#30475;&#26102;&#38271;&#20013;&#25581;&#31034;&#29992;&#25143;&#20852;&#36259;&#30340;&#35270;&#39057;&#25512;&#33616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Uncovering User Interest from Biased and Noised Watch Time in Video Recommendation. (arXiv:2308.08120v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#35270;&#39057;&#25512;&#33616;&#20013;&#35266;&#30475;&#26102;&#38271;&#30340;&#29983;&#25104;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#35270;&#39057;&#25512;&#33616;&#26041;&#27861;&#65292;&#20943;&#36731;&#20102;&#25345;&#32493;&#26102;&#38388;&#20559;&#24046;&#21644;&#22122;&#22768;&#35266;&#30475;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#24182;&#25913;&#21892;&#20102;&#20174;&#35266;&#30475;&#26102;&#38271;&#20013;&#25581;&#31034;&#29992;&#25143;&#20852;&#36259;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35270;&#39057;&#25512;&#33616;&#20013;&#65292;&#35266;&#30475;&#26102;&#38271;&#24120;&#34987;&#29992;&#20316;&#29992;&#25143;&#20852;&#36259;&#30340;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#35266;&#30475;&#26102;&#38271;&#19981;&#20165;&#21463;&#21040;&#29992;&#25143;&#20852;&#36259;&#21305;&#37197;&#30340;&#24433;&#21709;&#65292;&#36824;&#21463;&#21040;&#20854;&#20182;&#22240;&#32032;&#30340;&#24433;&#21709;&#65292;&#27604;&#22914;&#25345;&#32493;&#26102;&#38388;&#20559;&#24046;&#21644;&#22122;&#22768;&#35266;&#30475;&#12290;&#25345;&#32493;&#26102;&#38388;&#20559;&#24046;&#25351;&#30340;&#26159;&#29992;&#25143;&#20542;&#21521;&#20110;&#22312;&#35270;&#39057;&#25345;&#32493;&#26102;&#38388;&#36739;&#38271;&#26102;&#33457;&#36153;&#26356;&#22810;&#26102;&#38388;&#35266;&#30475;&#65292;&#32780;&#19981;&#32771;&#34385;&#23454;&#38469;&#30340;&#20852;&#36259;&#27700;&#24179;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22122;&#22768;&#35266;&#30475;&#25551;&#36848;&#20102;&#29992;&#25143;&#33457;&#26102;&#38388;&#21028;&#26029;&#20182;&#20204;&#26159;&#21542;&#21916;&#27426;&#19968;&#20010;&#35270;&#39057;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#29992;&#25143;&#33457;&#26102;&#38388;&#35266;&#30475;&#20182;&#20204;&#19981;&#21916;&#27426;&#30340;&#35270;&#39057;&#12290;&#22240;&#27492;&#65292;&#25345;&#32493;&#26102;&#38388;&#20559;&#24046;&#21644;&#22122;&#22768;&#35266;&#30475;&#30340;&#23384;&#22312;&#20351;&#24471;&#35266;&#30475;&#26102;&#38271;&#25104;&#20026;&#19968;&#20010;&#19981;&#36275;&#20197;&#34920;&#31034;&#29992;&#25143;&#20852;&#36259;&#30340;&#26631;&#31614;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#20027;&#35201;&#35299;&#20915;&#25345;&#32493;&#26102;&#38388;&#20559;&#24046;&#32780;&#24573;&#35270;&#20102;&#22122;&#22768;&#35266;&#30475;&#30340;&#24433;&#21709;&#65292;&#36825;&#21487;&#33021;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#20174;&#35266;&#30475;&#26102;&#38271;&#20013;&#25581;&#31034;&#29992;&#25143;&#20852;&#36259;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20174;&#32479;&#19968;&#30340;&#22240;&#26524;&#35270;&#35282;&#20998;&#26512;&#20102;&#29992;&#25143;&#35266;&#30475;&#26102;&#38271;&#30340;&#29983;&#25104;&#26426;&#21046;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#35270;&#39057;&#25512;&#33616;&#26041;&#27861;&#65292;&#20197;&#20943;&#36731;&#25345;&#32493;&#26102;&#38388;&#20559;&#24046;&#21644;&#22122;&#22768;&#35266;&#30475;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#24182;&#25913;&#21892;&#20174;&#35266;&#30475;&#26102;&#38271;&#20013;&#25581;&#31034;&#29992;&#25143;&#20852;&#36259;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the video recommendation, watch time is commonly adopted as an indicator of user interest. However, watch time is not only influenced by the matching of users' interests but also by other factors, such as duration bias and noisy watching. Duration bias refers to the tendency for users to spend more time on videos with longer durations, regardless of their actual interest level. Noisy watching, on the other hand, describes users taking time to determine whether they like a video or not, which can result in users spending time watching videos they do not like. Consequently, the existence of duration bias and noisy watching make watch time an inadequate label for indicating user interest. Furthermore, current methods primarily address duration bias and ignore the impact of noisy watching, which may limit their effectiveness in uncovering user interest from watch time. In this study, we first analyze the generation mechanism of users' watch time from a unified causal viewpoint. Specific
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;DGREC&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#65292;&#20854;&#20013;&#29992;&#25143;&#21487;&#20197;&#36873;&#25321;&#20844;&#24320;&#20182;&#20204;&#30340;&#20132;&#20114;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#22270;&#26500;&#24314;&#12289;&#23616;&#37096;&#26799;&#24230;&#35745;&#31639;&#21644;&#20840;&#23616;&#26799;&#24230;&#20256;&#36882;&#19977;&#20010;&#38454;&#27573;&#23454;&#29616;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#21517;&#20026;&#23433;&#20840;&#26799;&#24230;&#20849;&#20139;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#65292;&#20445;&#25252;&#29992;&#25143;&#30340;&#31169;&#23494;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2308.08072</link><description>&lt;p&gt;
&#22522;&#20110;&#21435;&#20013;&#24515;&#21270;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Decentralized Graph Neural Network for Privacy-Preserving Recommendation. (arXiv:2308.08072v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08072
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;DGREC&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#65292;&#20854;&#20013;&#29992;&#25143;&#21487;&#20197;&#36873;&#25321;&#20844;&#24320;&#20182;&#20204;&#30340;&#20132;&#20114;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#22270;&#26500;&#24314;&#12289;&#23616;&#37096;&#26799;&#24230;&#35745;&#31639;&#21644;&#20840;&#23616;&#26799;&#24230;&#20256;&#36882;&#19977;&#20010;&#38454;&#27573;&#23454;&#29616;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#21517;&#20026;&#23433;&#20840;&#26799;&#24230;&#20849;&#20139;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#65292;&#20445;&#25252;&#29992;&#25143;&#30340;&#31169;&#23494;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#36829;&#21453;&#29992;&#25143;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#25512;&#33616;&#31995;&#32479;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#29616;&#26377;&#26041;&#27861;&#21487;&#20197;&#20998;&#20026;&#32852;&#37030;GNN&#21644;&#21435;&#20013;&#24515;&#21270;GNN&#20004;&#31181;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#23384;&#22312;&#38382;&#39064;&#65292;&#22914;&#36890;&#20449;&#25928;&#29575;&#20302;&#21644;&#38544;&#31169;&#27844;&#38706;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20013;&#24515;&#21270;GNN&#26694;&#26550;&#65292;&#21517;&#20026;DGREC&#65292;&#29992;&#20110;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#65292;&#29992;&#25143;&#21487;&#20197;&#36873;&#25321;&#20844;&#24320;&#20182;&#20204;&#30340;&#20132;&#20114;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65292;&#21363;&#22270;&#26500;&#24314;&#12289;&#23616;&#37096;&#26799;&#24230;&#35745;&#31639;&#21644;&#20840;&#23616;&#26799;&#24230;&#20256;&#36882;&#12290;&#31532;&#19968;&#38454;&#27573;&#20026;&#27599;&#20010;&#29992;&#25143;&#26500;&#24314;&#20102;&#19968;&#20010;&#26412;&#22320;&#20869;&#37096;&#29289;&#21697;&#36229;&#22270;&#21644;&#19968;&#20010;&#20840;&#23616;&#29992;&#25143;&#38388;&#22270;&#12290;&#31532;&#20108;&#38454;&#27573;&#23545;&#29992;&#25143;&#20559;&#22909;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#22312;&#27599;&#20010;&#26412;&#22320;&#35774;&#22791;&#19978;&#35745;&#31639;&#26799;&#24230;&#12290;&#31532;&#19977;&#38454;&#27573;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;&#23433;&#20840;&#26799;&#24230;&#20849;&#20139;&#30340;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#65292;&#20197;&#20445;&#25252;&#29992;&#25143;&#30340;&#31169;&#23494;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#19968;&#36143;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Building a graph neural network (GNN)-based recommender system without violating user privacy proves challenging. Existing methods can be divided into federated GNNs and decentralized GNNs. But both methods have undesirable effects, i.e., low communication efficiency and privacy leakage. This paper proposes DGREC, a novel decentralized GNN for privacy-preserving recommendations, where users can choose to publicize their interactions. It includes three stages, i.e., graph construction, local gradient calculation, and global gradient passing. The first stage builds a local inner-item hypergraph for each user and a global inter-user graph. The second stage models user preference and calculates gradients on each local device. The third stage designs a local differential privacy mechanism named secure gradient-sharing, which proves strong privacy-preserving of users' private data. We conduct extensive experiments on three public datasets to validate the consistent superiority of our framewo
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;ChatGPT 3.5&#26469;&#36827;&#34892;&#37329;&#34701;&#24773;&#32490;&#20998;&#26512;&#65292;&#29305;&#21035;&#20851;&#27880;&#22806;&#27719;&#24066;&#22330;&#65292;&#36890;&#36807;&#38646;-shot&#25552;&#31034;&#26041;&#27861;&#65292;&#22312;&#31934;&#24515;&#31574;&#21010;&#30340;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#20854;&#24615;&#33021;&#65292;&#24182;&#21457;&#29616;&#19982;&#20256;&#32479;&#27169;&#22411;&#30456;&#27604;&#65292;ChatGPT&#22312;&#37329;&#34701;&#24773;&#32490;&#20998;&#26512;&#20013;&#34920;&#29616;&#20986;&#32422;35&#65285;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2308.07935</link><description>&lt;p&gt;
&#29992;ChatGPT&#21464;&#38761;&#37329;&#34701;&#39046;&#22495;&#30340;&#24773;&#32490;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Transforming Sentiment Analysis in the Financial Domain with ChatGPT. (arXiv:2308.07935v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;ChatGPT 3.5&#26469;&#36827;&#34892;&#37329;&#34701;&#24773;&#32490;&#20998;&#26512;&#65292;&#29305;&#21035;&#20851;&#27880;&#22806;&#27719;&#24066;&#22330;&#65292;&#36890;&#36807;&#38646;-shot&#25552;&#31034;&#26041;&#27861;&#65292;&#22312;&#31934;&#24515;&#31574;&#21010;&#30340;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#20854;&#24615;&#33021;&#65292;&#24182;&#21457;&#29616;&#19982;&#20256;&#32479;&#27169;&#22411;&#30456;&#27604;&#65292;ChatGPT&#22312;&#37329;&#34701;&#24773;&#32490;&#20998;&#26512;&#20013;&#34920;&#29616;&#20986;&#32422;35&#65285;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37329;&#34701;&#24773;&#32490;&#20998;&#26512;&#22312;&#35299;&#35835;&#24066;&#22330;&#36235;&#21183;&#21644;&#25351;&#23548;&#25112;&#30053;&#20132;&#26131;&#20915;&#31574;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#23613;&#31649;&#24050;&#32463;&#20351;&#29992;&#20102;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#21644;&#35821;&#35328;&#27169;&#22411;&#26469;&#25913;&#36827;&#37329;&#34701;&#24773;&#32490;&#20998;&#26512;&#65292;&#20294;&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#29305;&#21035;&#26159;ChatGPT 3.5&#65289;&#22312;&#37329;&#34701;&#24773;&#32490;&#20998;&#26512;&#20013;&#30340;&#28508;&#21147;&#65292;&#29305;&#21035;&#24378;&#35843;&#22806;&#27719;&#24066;&#22330;&#65288;forex&#65289;&#65292;&#24320;&#21019;&#20102;&#26032;&#30340;&#39046;&#22495;&#12290;&#37319;&#29992;&#38646;-shot&#25552;&#31034;&#26041;&#27861;&#65292;&#22312;&#19968;&#20221;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#30340;&#22806;&#27719;&#30456;&#20851;&#26032;&#38395;&#26631;&#39064;&#25968;&#25454;&#38598;&#19978;&#26816;&#39564;&#22810;&#20010;ChatGPT&#25552;&#31034;&#65292;&#24182;&#20351;&#29992;&#31934;&#30830;&#24230;&#12289;&#21484;&#22238;&#29575;&#12289;F1&#24471;&#20998;&#21644;&#24773;&#32490;&#20998;&#31867;&#30340;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#31561;&#25351;&#26631;&#35780;&#20272;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#39044;&#27979;&#24773;&#32490;&#21644;&#24066;&#22330;&#22238;&#25253;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20316;&#20026;&#19968;&#31181;&#39069;&#22806;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;&#19982;FinBERT&#30456;&#27604;&#65292;ChatGPT&#22312;&#24773;&#32490;&#20998;&#26512;&#26041;&#38754;&#30340;&#24615;&#33021;&#25552;&#39640;&#20102;&#32422;35&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
Financial sentiment analysis plays a crucial role in decoding market trends and guiding strategic trading decisions. Despite the deployment of advanced deep learning techniques and language models to refine sentiment analysis in finance, this study breaks new ground by investigating the potential of large language models, particularly ChatGPT 3.5, in financial sentiment analysis, with a strong emphasis on the foreign exchange market (forex). Employing a zero-shot prompting approach, we examine multiple ChatGPT prompts on a meticulously curated dataset of forex-related news headlines, measuring performance using metrics such as precision, recall, f1-score, and Mean Absolute Error (MAE) of the sentiment class. Additionally, we probe the correlation between predicted sentiment and market returns as an additional evaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment analysis model for financial texts, exhibited approximately 35\% enhanced performance in sentiment 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;Meituan&#25628;&#32034;&#20013;&#36827;&#34892;&#30456;&#20851;&#24615;&#24314;&#27169;&#30340;&#26032;&#39062;&#20004;&#38454;&#27573;&#39044;&#35757;&#32451;&#21644;&#21305;&#37197;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2308.07711</link><description>&lt;p&gt;
SPM: Meituan&#25628;&#32034;&#20013;&#29992;&#20110;&#30456;&#20851;&#24615;&#24314;&#27169;&#30340;&#32467;&#26500;&#21270;&#39044;&#35757;&#32451;&#21644;&#21305;&#37197;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search. (arXiv:2308.07711v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;Meituan&#25628;&#32034;&#20013;&#36827;&#34892;&#30456;&#20851;&#24615;&#24314;&#27169;&#30340;&#26032;&#39062;&#20004;&#38454;&#27573;&#39044;&#35757;&#32451;&#21644;&#21305;&#37197;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#21830;&#25628;&#32034;&#20013;&#65292;&#26597;&#35810;&#21644;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26159;&#28385;&#36275;&#29992;&#25143;&#20307;&#39564;&#30340;&#22522;&#26412;&#35201;&#27714;&#12290;&#19982;&#20256;&#32479;&#30340;&#30005;&#21830;&#24179;&#21488;&#19981;&#21516;&#65292;&#29992;&#25143;&#22312;&#32654;&#22242;&#31561;&#29983;&#27963;&#26381;&#21153;&#24179;&#21488;&#19978;&#36827;&#34892;&#25628;&#32034;&#20027;&#35201;&#26159;&#20026;&#20102;&#20135;&#21697;&#20379;&#24212;&#21830;&#65292;&#36825;&#20123;&#20379;&#24212;&#21830;&#36890;&#24120;&#25317;&#26377;&#20016;&#23500;&#30340;&#32467;&#26500;&#21270;&#20449;&#24687;&#65292;&#20363;&#22914;&#21517;&#31216;&#12289;&#22320;&#22336;&#12289;&#31867;&#21035;&#12289;&#25104;&#21315;&#19978;&#19975;&#30340;&#20135;&#21697;&#12290;&#20351;&#29992;&#36825;&#20123;&#20016;&#23500;&#30340;&#32467;&#26500;&#21270;&#20869;&#23481;&#36827;&#34892;&#25628;&#32034;&#30456;&#20851;&#24615;&#24314;&#27169;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#20027;&#35201;&#23384;&#22312;&#20197;&#19979;&#38382;&#39064;&#65306;&#65288;1&#65289;&#19981;&#21516;&#23383;&#27573;&#30340;&#32467;&#26500;&#21270;&#25991;&#26723;&#23384;&#22312;&#35821;&#35328;&#20998;&#24067;&#24046;&#24322;&#65292;&#26080;&#27861;&#30452;&#25509;&#37319;&#29992;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#65288;&#22914;BERT&#65289;&#12290;&#65288;2&#65289;&#19981;&#21516;&#23383;&#27573;&#36890;&#24120;&#20855;&#26377;&#19981;&#21516;&#30340;&#37325;&#35201;&#24615;&#65292;&#19988;&#38271;&#24230;&#24046;&#24322;&#24456;&#22823;&#65292;&#24456;&#38590;&#25552;&#21462;&#23545;&#30456;&#20851;&#24615;&#21305;&#37197;&#26377;&#24110;&#21161;&#30340;&#25991;&#26723;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#38454;&#27573;&#39044;&#35757;&#32451;&#21644;&#21305;&#37197;&#26550;&#26500;&#65292;&#29992;&#20110;&#20016;&#23500;&#32467;&#26500;&#30340;&#30456;&#20851;&#24615;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
In e-commerce search, relevance between query and documents is an essential requirement for satisfying user experience. Different from traditional e-commerce platforms that offer products, users search on life service platforms such as Meituan mainly for product providers, which usually have abundant structured information, e.g. name, address, category, thousands of products. Modeling search relevance with these rich structured contents is challenging due to the following issues: (1) there is language distribution discrepancy among different fields of structured document, making it difficult to directly adopt off-the-shelf pretrained language model based methods like BERT. (2) different fields usually have different importance and their length vary greatly, making it difficult to extract document information helpful for relevance matching.  To tackle these issues, in this paper we propose a novel two-stage pretraining and matching architecture for relevance matching with rich structure
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#26053;&#28216;&#39046;&#22495;&#30340;&#20852;&#36259;&#28857;&#25512;&#33616;&#38382;&#39064;&#36827;&#34892;&#20102;&#35843;&#26597;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#21033;&#29992;&#24322;&#26500;&#25968;&#25454;&#35299;&#20915;&#26053;&#36884;&#20013;&#20852;&#36259;&#28857;&#25512;&#33616;&#38382;&#39064;&#30340;&#28508;&#21147;&#19982;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.07426</link><description>&lt;p&gt;
&#21033;&#29992;&#24322;&#26500;&#25968;&#25454;&#36827;&#34892;&#20852;&#36259;&#28857;&#25512;&#33616;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Point-of-Interest Recommendations Leveraging Heterogeneous Data. (arXiv:2308.07426v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26053;&#28216;&#39046;&#22495;&#30340;&#20852;&#36259;&#28857;&#25512;&#33616;&#38382;&#39064;&#36827;&#34892;&#20102;&#35843;&#26597;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#21033;&#29992;&#24322;&#26500;&#25968;&#25454;&#35299;&#20915;&#26053;&#36884;&#20013;&#20852;&#36259;&#28857;&#25512;&#33616;&#38382;&#39064;&#30340;&#28508;&#21147;&#19982;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26053;&#28216;&#26159;&#25512;&#33616;&#31995;&#32479;&#30340;&#19968;&#20010;&#37325;&#35201;&#24212;&#29992;&#39046;&#22495;&#12290;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#20027;&#35201;&#36127;&#36131;&#20026;&#20132;&#36890;&#12289;&#20303;&#23487;&#12289;&#20852;&#36259;&#28857;&#25110;&#26053;&#28216;&#26381;&#21153;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#65292;&#23588;&#20854;&#26159;&#23545;&#20010;&#20307;&#28216;&#23458;&#21487;&#33021;&#24863;&#20852;&#36259;&#30340;&#20852;&#36259;&#28857;&#36827;&#34892;&#25512;&#33616;&#30340;&#38382;&#39064;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#28216;&#23458;&#8220;&#26053;&#36884;&#20013;&#8221;&#25552;&#20379;&#20852;&#36259;&#28857;&#25512;&#33616;&#21487;&#33021;&#20250;&#38754;&#20020;&#29305;&#27530;&#25361;&#25112;&#65292;&#22240;&#20026;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#21464;&#21270;&#22810;&#26679;&#12290;&#38543;&#30528;&#20114;&#32852;&#32593;&#30340;&#24555;&#36895;&#21457;&#23637;&#21644;&#24403;&#20170;&#21508;&#31181;&#22312;&#32447;&#26381;&#21153;&#30340;&#22823;&#37327;&#25968;&#25454;&#65292;&#21508;&#31181;&#24322;&#26500;&#25968;&#25454;&#28304;&#30340;&#25968;&#25454;&#24050;&#32463;&#21464;&#24471;&#21487;&#29992;&#65292;&#36825;&#20123;&#24322;&#26500;&#25968;&#25454;&#28304;&#20026;&#35299;&#20915;&#26053;&#36884;&#20013;&#20852;&#36259;&#28857;&#25512;&#33616;&#38382;&#39064;&#30340;&#25361;&#25112;&#25552;&#20379;&#20102;&#24040;&#22823;&#28508;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#24322;&#26500;&#25968;&#25454;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;2017&#24180;&#33267;2022&#24180;&#38388;&#24050;&#21457;&#34920;&#30340;&#20852;&#36259;&#28857;&#25512;&#33616;&#30740;&#31350;&#30340;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tourism is an important application domain for recommender systems. In this domain, recommender systems are for example tasked with providing personalized recommendations for transportation, accommodation, points-of-interest (POIs), or tourism services. Among these tasks, in particular the problem of recommending POIs that are of likely interest to individual tourists has gained growing attention in recent years. Providing POI recommendations to tourists \emph{during their trip} can however be especially challenging due to the variability of the users' context. With the rapid development of the Web and today's multitude of online services, vast amounts of data from various sources have become available, and these heterogeneous data sources represent a huge potential to better address the challenges of in-trip POI recommendation problems. In this work, we provide a comprehensive survey of published research on POI recommendation between 2017 and 2022 from the perspective of heterogeneou
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#22686;&#24378;&#30340;&#30456;&#20851;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#65292;&#26469;&#25913;&#36827;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;-&#39033;&#30446;&#21305;&#37197;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05379</link><description>&lt;p&gt;
&#36229;&#36234;&#35821;&#20041;&#65306;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#30340;&#34892;&#20026;&#22686;&#24378;&#30456;&#20851;&#27169;&#22411;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning. (arXiv:2308.05379v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05379
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#22686;&#24378;&#30340;&#30456;&#20851;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#20174;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#65292;&#26469;&#25913;&#36827;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;-&#39033;&#30446;&#21305;&#37197;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#24314;&#27169;&#26088;&#22312;&#23450;&#20301;&#19982;&#23545;&#24212;&#26597;&#35810;&#30456;&#20851;&#30340;&#29702;&#24819;&#39033;&#30446;&#65292;&#36825;&#23545;&#20110;&#25628;&#32034;&#24341;&#25806;&#30830;&#20445;&#29992;&#25143;&#20307;&#39564;&#38750;&#24120;&#37325;&#35201;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#20256;&#32479;&#26041;&#27861;&#36890;&#36807;&#35780;&#20272;&#26597;&#35810;&#19982;&#39033;&#30446;&#20043;&#38388;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#32431;&#35821;&#20041;&#21305;&#37197;&#24182;&#19981;&#26159;&#21807;&#19968;&#30340;&#26041;&#27861;&#12290;&#23454;&#38469;&#19978;&#65292;&#20174;&#29992;&#25143;&#25628;&#32034;&#35760;&#24405;&#30340;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#20013;&#25552;&#21462;&#30340;&#36741;&#21161;&#26597;&#35810;-&#39033;&#30446;&#20132;&#20114;&#21487;&#20197;&#25552;&#20379;&#36827;&#19968;&#27493;&#25581;&#31034;&#29992;&#25143;&#25628;&#32034;&#24847;&#22270;&#30340;&#32447;&#32034;&#12290;&#24471;&#30410;&#20110;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#34892;&#20026;&#22686;&#24378;&#30456;&#20851;&#23398;&#20064;&#27169;&#22411;&#30340;&#25903;&#20184;&#23453;&#25628;&#32034;&#27169;&#22411;&#65288;BARL-ASe&#65289;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#30446;&#26631;&#39033;&#30446;&#30340;&#30456;&#37051;&#26597;&#35810;&#21644;&#30446;&#26631;&#26597;&#35810;&#30340;&#30456;&#37051;&#39033;&#30446;&#26469;&#34917;&#20805;&#30446;&#26631;&#26597;&#35810;-&#39033;&#30446;&#30340;&#35821;&#20041;&#21305;&#37197;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#24314;&#31435;&#20102;&#22810;&#23618;&#20849;&#21516;&#27880;&#24847;&#21147;&#65292;&#20174;&#30456;&#37051;&#21644;&#30446;&#26631;&#35270;&#22270;&#20013;&#25552;&#21462;&#20102;&#31895;&#31890;&#24230;&#21644;&#32454;&#31890;&#24230;&#30340;&#35821;&#20041;&#34920;&#31034;&#12290;&#27169;&#22411;&#38543;&#21518;&#37319;&#29992;&#37051;&#23621;-&#30446;&#26631;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#26469;&#25552;&#39640;&#31934;&#24230;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#19981;&#21516;&#30340;&#24341;&#23548;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#12290;&#36825;&#19968;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#20013;&#65292;&#37319;&#29992;&#22810;&#26679;&#30340;&#24341;&#23548;&#21644;&#36755;&#20837;&#22686;&#24378;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.15780</link><description>&lt;p&gt;
LLM-Rec: &#36890;&#36807;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
LLM-Rec: Personalized Recommendation via Prompting Large Language Models. (arXiv:2307.15780v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#19981;&#21516;&#30340;&#24341;&#23548;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#12290;&#36825;&#19968;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#20013;&#65292;&#37319;&#29992;&#22810;&#26679;&#30340;&#24341;&#23548;&#21644;&#36755;&#20837;&#22686;&#24378;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#36755;&#20837;&#22686;&#24378;&#25216;&#26415;&#65292;&#30740;&#31350;&#20102;&#22810;&#31181;&#19981;&#21516;&#30340;&#24341;&#23548;&#31574;&#30053;&#65292;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21517;&#20026;LLM-Rec&#65292;&#21253;&#25324;&#22235;&#31181;&#19981;&#21516;&#30340;&#24341;&#23548;&#31574;&#30053;&#65306;&#65288;1&#65289;&#22522;&#30784;&#24341;&#23548;&#65292;&#65288;2&#65289;&#25512;&#33616;&#39537;&#21160;&#24341;&#23548;&#65292;&#65288;3&#65289;&#21442;&#19982;&#24341;&#23548;&#24341;&#23548;&#65292;&#21644;&#65288;4&#65289;&#25512;&#33616;&#39537;&#21160;+&#21442;&#19982;&#24341;&#23548;&#24341;&#23548;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#23558;&#21407;&#22987;&#20869;&#23481;&#25551;&#36848;&#19982;LLM&#29983;&#25104;&#30340;&#22686;&#24378;&#36755;&#20837;&#25991;&#26412;&#32467;&#21512;&#36215;&#26469;&#65292;&#37319;&#29992;&#36825;&#20123;&#24341;&#23548;&#31574;&#30053;&#21487;&#20197;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;&#36825;&#19968;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#22810;&#26679;&#30340;&#24341;&#23548;&#21644;&#36755;&#20837;&#22686;&#24378;&#25216;&#26415;&#26469;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#33021;&#21147;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate various prompting strategies for enhancing personalized content recommendation performance with large language models (LLMs) through input augmentation. Our proposed approach, termed LLM-Rec, encompasses four distinct prompting strategies: (1) basic prompting, (2) recommendation-driven prompting, (3) engagement-guided prompting, and (4) recommendation-driven + engagement-guided prompting. Our empirical experiments show that combining the original content description with the augmented input text generated by LLM using these prompting strategies leads to improved recommendation performance. This finding highlights the importance of incorporating diverse prompts and input augmentation techniques to enhance the recommendation capabilities with large language models for personalized content recommendation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#8212;&#8212;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#12290;&#38024;&#23545;&#36825;&#19968;&#20219;&#21153;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#26041;&#26696;&#8212;&#8212;KGEditor&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.10405</link><description>&lt;p&gt;
&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.10405
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#8212;&#8212;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#12290;&#38024;&#23545;&#36825;&#19968;&#20219;&#21153;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#26041;&#26696;&#8212;&#8212;KGEditor&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#23884;&#20837;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;KG&#23884;&#20837;&#36890;&#24120;&#20316;&#20026;&#38745;&#24577;&#24037;&#20214;&#37096;&#32626;&#65292;&#20462;&#25913;&#36215;&#26469;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#32534;&#36753;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;KG&#23884;&#20837;&#12290;&#35813;&#20219;&#21153;&#26088;&#22312;&#23454;&#29616;&#23545;KG&#23884;&#20837;&#30340;&#25968;&#25454;&#39640;&#25928;&#21644;&#24555;&#36895;&#26356;&#26032;&#65292;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#22235;&#20010;&#26032;&#25968;&#25454;&#38598;&#65306;E-FB15k237&#12289;A-FB15k237&#12289;E-WN18RR &#21644; A-WN18RR&#65292;&#24182;&#35780;&#20272;&#20102;&#20960;&#31181;&#30693;&#35782;&#32534;&#36753;&#22522;&#32447;&#65292;&#35777;&#26126;&#20102;&#20043;&#21069;&#30340;&#27169;&#22411;&#22788;&#29702;&#35813;&#20219;&#21153;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#24378;&#22823;&#30340;&#22522;&#32447;&#8212;&#8212;KGEditor&#65292;&#23427;&#21033;&#29992;&#36229;&#32593;&#32476;&#30340;&#38468;&#21152;&#21442;&#25968;&#23618;&#26469;&#32534;&#36753;/&#28155;&#21152;&#20107;&#23454;&#12290;&#20840;&#38754;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#26356;&#26032;&#29305;&#23450;&#20107;&#23454;&#32780;&#19981;&#24433;&#21709;&#20854;&#20313;&#37096;&#20998;&#30340;&#24615;&#33021;&#26102;&#65292;KGEditor &#30340;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
&lt;/p&gt;</description></item></channel></rss>