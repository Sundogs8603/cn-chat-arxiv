<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21487;&#35270;&#21270;&#20449;&#24687;&#23545;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24403;&#21152;&#20837;&#35270;&#35273;&#20449;&#24687;&#26102;&#65292;&#29616;&#26377;&#30340;&#24694;&#24847;&#25512;&#24191;&#25915;&#20987;&#23558;&#21464;&#24471;&#26080;&#25928;&#12290;</title><link>http://arxiv.org/abs/2305.08183</link><description>&lt;p&gt;
&#21487;&#35270;&#21270;&#20449;&#24687;&#23545;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#30340;&#24433;&#21709;&#21450;&#20854;&#23545;&#31574;
&lt;/p&gt;
&lt;p&gt;
Manipulating Visually-aware Federated Recommender Systems and Its Countermeasures. (arXiv:2305.08183v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08183
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21487;&#35270;&#21270;&#20449;&#24687;&#23545;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24403;&#21152;&#20837;&#35270;&#35273;&#20449;&#24687;&#26102;&#65292;&#29616;&#26377;&#30340;&#24694;&#24847;&#25512;&#24191;&#25915;&#20987;&#23558;&#21464;&#24471;&#26080;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#65288;FedRec&#65289;&#22240;&#20854;&#20445;&#25252;&#29992;&#25143;&#25968;&#25454;&#38544;&#31169;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#22312;FedRec&#20013;&#65292;&#20013;&#22830;&#26381;&#21153;&#22120;&#36890;&#36807;&#19982;&#23458;&#25143;&#31471;&#20849;&#20139;&#27169;&#22411;&#20844;&#20849;&#21442;&#25968;&#26469;&#21327;&#21516;&#23398;&#20064;&#25512;&#33616;&#27169;&#22411;&#65292;&#20174;&#32780;&#25552;&#20379;&#19968;&#31181;&#20445;&#25252;&#38544;&#31169;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#21442;&#25968;&#30340;&#20844;&#24320;&#24615;&#20026;&#25915;&#20987;&#32773;&#25805;&#32437;FedRec&#30041;&#19979;&#20102;&#21518;&#38376;&#12290;&#29616;&#26377;&#30340;&#19982;FedRec&#23433;&#20840;&#30456;&#20851;&#30340;&#30740;&#31350;&#24050;&#32463;&#34920;&#26126;&#65292;&#36890;&#36807;&#27169;&#22411;&#27745;&#26579;&#25915;&#20987;&#65292;&#24694;&#24847;&#29992;&#25143;&#21487;&#20197;&#36731;&#26131;&#22320;&#25512;&#24191;&#39033;&#30446;&#65292;&#20294;&#26159;&#23427;&#20204;&#20027;&#35201;&#38598;&#20013;&#20110;&#21482;&#20855;&#26377;&#21327;&#20316;&#20449;&#24687;&#65288;&#21363;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#65289;&#30340;FedRec&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#20123;&#25915;&#20987;&#20043;&#25152;&#20197;&#26377;&#25928;&#65292;&#26159;&#22240;&#20026;&#21327;&#20316;&#20449;&#21495;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36741;&#21161;&#20449;&#24687;&#65288;&#22914;&#20135;&#21697;&#30340;&#35270;&#35273;&#25551;&#36848;&#65289;&#29992;&#20110;&#32531;&#35299;&#21327;&#20316;&#36807;&#28388;&#25968;&#25454;&#30340;&#31232;&#30095;&#24615;&#12290;&#22240;&#27492;&#65292;&#24403;&#22312;FedRec&#20013;&#21152;&#20837;&#35270;&#35273;&#20449;&#24687;&#26102;&#65292;&#25152;&#26377;&#29616;&#26377;&#30340;&#27169;&#22411;&#27745;&#26579;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#37117;&#23558;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated recommender systems (FedRecs) have been widely explored recently due to their ability to protect user data privacy. In FedRecs, a central server collaboratively learns recommendation models by sharing model public parameters with clients, thereby offering a privacy-preserving solution. Unfortunately, the exposure of model parameters leaves a backdoor for adversaries to manipulate FedRecs. Existing works about FedRec security already reveal that items can easily be promoted by malicious users via model poisoning attacks, but all of them mainly focus on FedRecs with only collaborative information (i.e., user-item interactions). We argue that these attacks are effective because of the data sparsity of collaborative signals. In practice, auxiliary information, such as products' visual descriptions, is used to alleviate collaborative filtering data's sparsity. Therefore, when incorporating visual information in FedRecs, all existing model poisoning attacks' effectiveness becomes q
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26500;&#24314;&#31471;&#21040;&#31471;&#22823;&#35268;&#27169;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#36335;&#32447;&#22270;&#65292;&#35299;&#20915;&#22312;&#35813;&#31995;&#32479;&#20013;&#26377;&#25928;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25152;&#38754;&#20020;&#30340;&#25216;&#26415;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.07961</link><description>&lt;p&gt;
&#22312;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#20013;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models in Conversational Recommender Systems. (arXiv:2305.07961v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26500;&#24314;&#31471;&#21040;&#31471;&#22823;&#35268;&#27169;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#36335;&#32447;&#22270;&#65292;&#35299;&#20915;&#22312;&#35813;&#31995;&#32479;&#20013;&#26377;&#25928;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25152;&#38754;&#20020;&#30340;&#25216;&#26415;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#36890;&#36807;&#21551;&#29992;&#23454;&#26102;&#30340;&#22810;&#36718;&#23545;&#35805;&#20351;&#29992;&#25143;&#26356;&#21152;&#36879;&#26126;&#21644;&#25484;&#25511;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#29616;&#20102;&#19982;&#20154;&#31867;&#23545;&#35805;&#33258;&#28982;&#30340;&#33021;&#21147;&#65292;&#24182;&#23558;&#19990;&#30028;&#30693;&#35782;&#21644;&#24120;&#35782;&#25512;&#29702;&#34701;&#20837;&#21040;&#35821;&#35328;&#29702;&#35299;&#20013;&#65292;&#36827;&#19968;&#27493;&#37322;&#25918;&#20102;&#36825;&#19968;&#33539;&#24335;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#20013;&#26377;&#25928;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24341;&#20837;&#20102;&#26032;&#30340;&#25216;&#26415;&#25361;&#25112;&#65292;&#21253;&#25324;&#36866;&#24403;&#22320;&#29702;&#35299;&#21644;&#25511;&#21046;&#22797;&#26434;&#30340;&#23545;&#35805;&#21644;&#20174;&#22806;&#37096;&#20449;&#24687;&#28304;&#26816;&#32034;&#12290;&#30001;&#20110;&#22823;&#32780;&#19981;&#26029;&#22686;&#38271;&#30340;&#39033;&#30446;&#35821;&#26009;&#24211;&#21644;&#32570;&#20047;&#23545;&#35805;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#36825;&#20123;&#38382;&#39064;&#21152;&#21095;&#20102;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26500;&#24314;&#31471;&#21040;&#31471;&#22823;&#35268;&#27169;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#30340;&#36335;&#32447;&#22270;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#25143;&#20559;&#22909;&#29702;&#35299;&#12289;&#28789;&#27963;&#30340;&#23545;&#35805;&#31649;&#29702;&#21644;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#20316;&#20026;&#25972;&#20010;&#31995;&#32479;&#30340;&#19968;&#37096;&#20998;&#30340;&#26032;&#23454;&#29616;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Conversational Recommender System (CRS) offers increased transparency and control to users by enabling them to engage with the system through a real-time multi-turn dialogue. Recently, Large Language Models (LLMs) have exhibited an unprecedented ability to converse naturally and incorporate world knowledge and common-sense reasoning into language understanding, unlocking the potential of this paradigm. However, effectively leveraging LLMs within a CRS introduces new technical challenges, including properly understanding and controlling a complex conversation and retrieving from external sources of information. These issues are exacerbated by a large, evolving item corpus and a lack of conversational data for training. In this paper, we provide a roadmap for building an end-to-end large-scale CRS using LLMs. In particular, we propose new implementations for user preference understanding, flexible dialogue management and explainable recommendations as part of an integrated architecture
&lt;/p&gt;</description></item><item><title>&#23457;&#31295;&#20154;&#20998;&#37197;&#38382;&#39064;&#26159;&#19968;&#20010;30&#24180;&#30340;&#30740;&#31350;&#35838;&#39064;&#65292;&#33258;&#21160;&#23558;&#35770;&#25991;&#19982;&#26368;&#21305;&#37197;&#30340;&#23457;&#31295;&#20154;&#20851;&#32852;&#24050;&#25104;&#20026;&#32531;&#35299;&#25361;&#25112;&#30340;&#35299;&#20915;&#26041;&#26696;&#20043;&#19968;&#65292;&#26412;&#25991;&#36827;&#34892;&#20102;&#32508;&#36848;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#26377;&#20851;&#35813;&#39046;&#22495;&#30340;&#27010;&#36848;&#21644;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.07887</link><description>&lt;p&gt;
&#23457;&#31295;&#20154;&#20998;&#37197;&#38382;&#39064;&#65306;&#32508;&#36848;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Reviewer assignment problem: A scoping review. (arXiv:2305.07887v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07887
&lt;/p&gt;
&lt;p&gt;
&#23457;&#31295;&#20154;&#20998;&#37197;&#38382;&#39064;&#26159;&#19968;&#20010;30&#24180;&#30340;&#30740;&#31350;&#35838;&#39064;&#65292;&#33258;&#21160;&#23558;&#35770;&#25991;&#19982;&#26368;&#21305;&#37197;&#30340;&#23457;&#31295;&#20154;&#20851;&#32852;&#24050;&#25104;&#20026;&#32531;&#35299;&#25361;&#25112;&#30340;&#35299;&#20915;&#26041;&#26696;&#20043;&#19968;&#65292;&#26412;&#25991;&#36827;&#34892;&#20102;&#32508;&#36848;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#26377;&#20851;&#35813;&#39046;&#22495;&#30340;&#27010;&#36848;&#21644;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21516;&#34892;&#35780;&#23457;&#26159;&#31185;&#23398;&#30740;&#31350;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#21516;&#34892;&#35780;&#23457;&#30340;&#36136;&#37327;&#65292;&#20197;&#21450;&#21457;&#34920;&#30340;&#30740;&#31350;&#36136;&#37327;&#65292;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#33021;&#21542;&#25307;&#21215;&#21040;&#36866;&#24403;&#30340;&#23457;&#31295;&#20154;&#26469;&#35780;&#23457;&#25552;&#20132;&#30340;&#35770;&#25991;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#31185;&#23398;&#35770;&#25991;&#30340;&#25345;&#32493;&#22686;&#21152;&#20197;&#21450;&#23398;&#32773;&#30340;&#24037;&#20316;&#36127;&#25285;&#19981;&#26029;&#22686;&#21152;&#31561;&#22810;&#31181;&#22240;&#32032;&#65292;&#25214;&#21040;&#36825;&#26679;&#30340;&#23457;&#31295;&#20154;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#25361;&#25112;&#65292;&#35299;&#20915;&#33258;&#21160;&#23558;&#35770;&#25991;&#19982;&#8220;&#26368;&#21305;&#37197;&#8221;&#30340;&#23457;&#31295;&#20154;&#20851;&#32852;&#30340;&#38382;&#39064;&#65288;&#36890;&#24120;&#31216;&#20026;&#23457;&#31295;&#20154;&#20998;&#37197;&#38382;&#39064;RAP&#65289;&#30340;&#35299;&#20915;&#26041;&#26696;&#24050;&#32463;&#25104;&#20026;&#30740;&#31350;&#30340;&#20027;&#39064;&#19977;&#21313;&#24180;&#20102;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#32570;&#23569;&#26368;&#36817;&#30340;RAP&#30456;&#20851;&#25991;&#29486;&#30340;&#31995;&#32479;&#32508;&#21512;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#24182;&#25903;&#25345;&#36827;&#19968;&#27493;&#30340;RAP&#30456;&#20851;&#30740;&#31350;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#35299;&#20915;RAP&#30340;&#35745;&#31639;&#26041;&#27861;&#30340;&#32508;&#36848;&#30740;&#31350;&#12290;&#26681;&#25454;&#26368;&#26032;&#30340;&#32508;&#36848;&#26041;&#27861;&#35770;&#25351;&#21335;&#65292;&#25105;&#20204;&#26816;&#26597;&#20102;&#30456;&#20851;&#39046;&#22495;&#30340;&#25991;&#29486;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#20851;RAP&#39046;&#22495;&#21457;&#29616;&#30340;&#27010;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
Peer review is an integral component of scientific research. The quality of peer review, and consequently the published research, depends to a large extent on the ability to recruit adequate reviewers for submitted papers. However, finding such reviewers is an increasingly difficult task due to several factors, such as the continuous increase both in the production of scientific papers and the workload of scholars. To mitigate these challenges, solutions for automated association of papers with "well matching" reviewers - the task often referred to as reviewer assignment problem (RAP) - have been the subject of research for thirty years now. Even though numerous solutions have been suggested, to our knowledge, a recent systematic synthesis of the RAP-related literature is missing. To fill this gap and support further RAP-related research, in this paper, we present a scoping review of computational approaches for addressing RAP. Following the latest methodological guidance for scoping r
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#25945;&#32946;&#38382;&#39064;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#36890;&#36807;&#22312;&#31185;&#23398;&#25991;&#26412;&#21644;&#31185;&#23398;&#38382;&#39064;&#25968;&#25454;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#23454;&#29616;&#20248;&#31168;&#30340;&#25945;&#32946;&#38382;&#39064;&#33258;&#21160;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2305.07871</link><description>&lt;p&gt;
&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#25945;&#23398;&#39064;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Scalable Educational Question Generation with Pre-trained Language Models. (arXiv:2305.07871v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07871
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#25945;&#32946;&#38382;&#39064;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#36890;&#36807;&#22312;&#31185;&#23398;&#25991;&#26412;&#21644;&#31185;&#23398;&#38382;&#39064;&#25968;&#25454;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#23454;&#29616;&#20248;&#31168;&#30340;&#25945;&#32946;&#38382;&#39064;&#33258;&#21160;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20840;&#29699;&#20154;&#21475;&#22312;&#25506;&#32034;&#20010;&#24615;&#21270;&#23398;&#20064;&#20043;&#26053;&#26102;&#65292;&#25945;&#32946;&#38382;&#39064;&#30340;&#33258;&#21160;&#29983;&#25104;&#23558;&#22312;&#22312;&#32447;&#25945;&#32946;&#30340;&#25193;&#23637;&#20013;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#65292;&#23454;&#29616;&#22823;&#35268;&#27169;&#30340;&#33258;&#25105;&#35780;&#20272;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#25945;&#32946;&#38382;&#39064;&#29983;&#25104;&#27169;&#22411;EduQG&#65292;&#36890;&#36807;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26500;&#24314;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;EduQG&#33021;&#22815;&#36890;&#36807;&#22312;&#31185;&#23398;&#25991;&#26412;&#21644;&#31185;&#23398;&#38382;&#39064;&#25968;&#25454;&#19978;&#36827;&#19968;&#27493;&#36827;&#34892;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#29983;&#25104;&#20986;&#26356;&#20248;&#31168;&#30340;&#25945;&#32946;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The automatic generation of educational questions will play a key role in scaling online education, enabling self-assessment at scale when a global population is manoeuvring their personalised learning journeys. We develop \textit{EduQG}, a novel educational question generation model built by adapting a large language model. Our extensive experiments demonstrate that \textit{EduQG} can produce superior educational questions by further pre-training and fine-tuning a pre-trained language model on the scientific text and science question data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#24341;&#23548;&#30340;Federated Recommendation&#20010;&#24615;&#21270;&#26694;&#26550;&#65288;GPFedRec&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#22270;&#32467;&#26500;&#26469;&#22686;&#24378;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#21327;&#20316;&#65292;&#21487;&#20197;&#21516;&#26102;&#20351;&#29992;&#20849;&#20139;&#21644;&#20010;&#24615;&#21270;&#30340;&#20449;&#24687;&#65292;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2305.07866</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#24341;&#23548;&#30340;Federated Recommendation&#20010;&#24615;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Graph-guided Personalization for Federated Recommendation. (arXiv:2305.07866v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#24341;&#23548;&#30340;Federated Recommendation&#20010;&#24615;&#21270;&#26694;&#26550;&#65288;GPFedRec&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#22270;&#32467;&#26500;&#26469;&#22686;&#24378;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#21327;&#20316;&#65292;&#21487;&#20197;&#21516;&#26102;&#20351;&#29992;&#20849;&#20139;&#21644;&#20010;&#24615;&#21270;&#30340;&#20449;&#24687;&#65292;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Federated Recommendation&#26159;&#19968;&#31181;&#26032;&#30340;&#26381;&#21153;&#26550;&#26500;&#65292;&#21487;&#20197;&#22312;&#19981;&#19982;&#26381;&#21153;&#22120;&#20849;&#20139;&#29992;&#25143;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#25512;&#33616;&#12290;&#29616;&#26377;&#26041;&#27861;&#22312;&#27599;&#20010;&#23458;&#25143;&#31471;&#19978;&#37096;&#32626;&#25512;&#33616;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#21516;&#27493;&#21644;&#32858;&#21512;&#39033;&#30446;&#23884;&#20837;&#26469;&#21327;&#35843;&#23427;&#20204;&#30340;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29992;&#25143;&#36890;&#24120;&#23545;&#26576;&#20123;&#39033;&#30446;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#20559;&#22909;&#65292;&#36825;&#20123;&#26041;&#27861;&#20250;&#26080;&#24046;&#21035;&#22320;&#32858;&#21512;&#26469;&#33258;&#25152;&#26377;&#23458;&#25143;&#31471;&#30340;&#39033;&#30446;&#23884;&#20837;&#65292;&#20174;&#32780;&#20013;&#21644;&#20102;&#24213;&#23618;&#29992;&#25143;&#29305;&#23450;&#30340;&#20559;&#22909;&#12290;&#36825;&#31181;&#24573;&#35270;&#23558;&#20351;&#24471;&#32858;&#21512;&#23884;&#20837;&#21464;&#24471;&#19981;&#22826;&#20855;&#26377;&#21306;&#20998;&#24615;&#65292;&#24182;&#38459;&#30861;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22270;&#24341;&#23548;&#30340;Federated Recommendation&#20010;&#24615;&#21270;&#26694;&#26550;&#65288;GPFedRec&#65289;&#12290;GPFedRec&#36890;&#36807;&#21033;&#29992;&#33258;&#36866;&#24212;&#22270;&#32467;&#26500;&#26469;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#30340;&#30456;&#20851;&#24615;&#65292;&#22686;&#24378;&#20102;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#21327;&#20316;&#12290;&#27492;&#22806;&#65292;&#23427;&#23558;&#23458;&#25143;&#31471;&#30340;&#35757;&#32451;&#36807;&#31243;&#21046;&#23450;&#20026;&#32479;&#19968;&#30340;&#32852;&#37030;&#20248;&#21270;&#26694;&#26550;&#65292;&#20854;&#20013;&#27169;&#22411;&#21487;&#20197;&#21516;&#26102;&#20351;&#29992;&#20849;&#20139;&#21644;&#20010;&#24615;&#21270;&#30340;&#20449;&#24687;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;GPFedRec&#22312;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#21516;&#26102;&#65292;&#22312;&#25512;&#33616;&#20934;&#30830;&#24615;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Recommendation is a new service architecture providing recommendations without sharing user data with the server. Existing methods deploy a recommendation model on each client and coordinate their training by synchronizing and aggregating item embeddings. However, while users usually hold diverse preferences toward certain items, these methods indiscriminately aggregate item embeddings from all clients, neutralizing underlying user-specific preferences. Such neglect will leave the aggregated embedding less discriminative and hinder personalized recommendations. This paper proposes a novel Graph-guided Personalization framework (GPFedRec) for the federated recommendation. The GPFedRec enhances cross-client collaboration by leveraging an adaptive graph structure to capture the correlation of user preferences. Besides, it guides training processes on clients by formulating them into a unified federated optimization framework, where models can simultaneously use shared and person
&lt;/p&gt;</description></item><item><title>aedFaCT&#26159;&#19968;&#20010;Web&#27983;&#35272;&#22120;&#25193;&#23637;&#65292;&#21487;&#20197;&#36890;&#36807;&#33258;&#21160;&#21457;&#29616;&#20851;&#38190;&#35789;&#30340;&#30456;&#20851;&#19987;&#23478;&#24847;&#35265;&#26469;&#24110;&#21161;&#19987;&#19994;&#20154;&#22763;&#21644;&#26032;&#38395;&#35835;&#32773;&#25191;&#34892;&#20107;&#23454;&#26680;&#26597;&#12290;</title><link>http://arxiv.org/abs/2305.07796</link><description>&lt;p&gt;
aedFaCT: &#36890;&#36807;&#21322;&#33258;&#21160;&#21270;&#21457;&#29616;&#30456;&#20851;&#19987;&#23478;&#24847;&#35265;&#65292;&#20351;&#31185;&#23398;&#20107;&#23454;&#26680;&#26597;&#26356;&#21152;&#23481;&#26131;
&lt;/p&gt;
&lt;p&gt;
aedFaCT: Scientific Fact-Checking Made Easier via Semi-Automatic Discovery of Relevant Expert Opinions. (arXiv:2305.07796v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07796
&lt;/p&gt;
&lt;p&gt;
aedFaCT&#26159;&#19968;&#20010;Web&#27983;&#35272;&#22120;&#25193;&#23637;&#65292;&#21487;&#20197;&#36890;&#36807;&#33258;&#21160;&#21457;&#29616;&#20851;&#38190;&#35789;&#30340;&#30456;&#20851;&#19987;&#23478;&#24847;&#35265;&#26469;&#24110;&#21161;&#19987;&#19994;&#20154;&#22763;&#21644;&#26032;&#38395;&#35835;&#32773;&#25191;&#34892;&#20107;&#23454;&#26680;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#20010;&#39640;&#24230;&#25968;&#23383;&#21270;&#30340;&#19990;&#30028;&#20013;&#65292;&#20551;&#26032;&#38395;&#26159;&#19968;&#20010;&#26840;&#25163;&#30340;&#38382;&#39064;&#65292;&#21487;&#33021;&#20250;&#32473;&#31038;&#20250;&#36896;&#25104;&#20005;&#37325;&#30340;&#20260;&#23475;&#12290;&#32771;&#34385;&#21040;&#20551;&#26032;&#38395;&#20256;&#25773;&#30340;&#36895;&#24230;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#36741;&#21161;&#24037;&#20855;&#21644;&#26381;&#21153;&#20197;&#36827;&#34892;&#20107;&#23454;&#26680;&#26597;&#65288;&#21363;&#20551;&#26032;&#38395;&#26816;&#27979;&#65289;&#21464;&#24471;&#24517;&#35201;&#21644;&#26377;&#30410;&#65292;&#26080;&#35770;&#26159;&#19987;&#19994;&#20154;&#22763;&#65292;&#22914;&#35760;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#65292;&#36824;&#26159;&#26222;&#36890;&#30340;&#26032;&#38395;&#35835;&#32773;&#12290;&#19987;&#23478;&#65292;&#29305;&#21035;&#26159;&#30740;&#31350;&#20154;&#21592;&#65292;&#22312;&#21578;&#30693;&#20154;&#20204;&#30495;&#23454;&#21644;&#20107;&#23454;&#26041;&#38754;&#21457;&#25381;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#36825;&#20351;&#20182;&#20204;&#25104;&#20026;&#38750;&#19987;&#23478;&#26816;&#27979;&#20551;&#26032;&#38395;&#30340;&#33391;&#22909;&#20195;&#29702;&#20154;&#65292;&#36890;&#36807;&#26816;&#26597;&#30456;&#20851;&#30340;&#19987;&#23478;&#24847;&#35265;&#21644;&#35780;&#35770;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;aedFaCT&#65292;&#23427;&#26159;&#19968;&#20010;Web&#27983;&#35272;&#22120;&#25193;&#23637;&#65292;&#21487;&#20197;&#36890;&#36807;&#20849;&#20139;&#20851;&#38190;&#35789;&#33258;&#21160;&#21457;&#29616;&#19982;&#25152;&#20851;&#27880;&#30340;&#26032;&#38395;&#30456;&#20851;&#30340;&#19987;&#23478;&#24847;&#35265;&#65292;&#24110;&#21161;&#19987;&#19994;&#20154;&#22763;&#21644;&#26032;&#38395;&#35835;&#32773;&#25191;&#34892;&#20107;&#23454;&#26680;&#26597;&#12290;&#25105;&#20204;&#30340;&#21021;&#27493;&#35780;&#20272;&#19982;&#19977;&#20010;&#29420;&#31435;&#30340;&#27979;&#35797;&#20154;&#21592;&#65288;&#20182;&#20204;&#27809;&#26377;&#21442;&#19982;&#25193;&#23637;&#30340;&#24320;&#21457;&#65289;&#19968;&#36215;&#36827;&#34892;&#65292;&#34920;&#26126;aedFaCT&#21487;&#20197;&#25552;&#20379;&#19968;&#20010;&#20107;&#23454;&#26680;&#26597;&#36741;&#21161;&#24037;&#20855;&#65292;&#24110;&#21161;&#29992;&#25143;&#24555;&#36895;&#36731;&#26494;&#22320;&#25214;&#21040;&#30456;&#20851;&#30340;&#19987;&#23478;&#24847;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this highly digitised world, fake news is a challenging problem that can cause serious harm to society. Considering how fast fake news can spread, automated methods, tools and services for assisting users to do fact-checking (i.e., fake news detection) become necessary and helpful, for both professionals, such as journalists and researchers, and the general public such as news readers. Experts, especially researchers, play an essential role in informing people about truth and facts, which makes them a good proxy for non-experts to detect fake news by checking relevant expert opinions and comments. Therefore, in this paper, we present aedFaCT, a web browser extension that can help professionals and news readers perform fact-checking via the automatic discovery of expert opinions relevant to the news of concern via shared keywords. Our initial evaluation with three independent testers (who did not participate in the development of the extension) indicated that aedFaCT can provide a fa
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#37327;&#21270;&#25506;&#32034;&#23545;&#20869;&#23481;&#35821;&#26009;&#24211;&#30340;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;&#25506;&#32034;&#23545;&#29992;&#25143;&#20307;&#39564;&#30340;&#38271;&#26399;&#22909;&#22788;&#65292;&#24182;&#23581;&#35797;&#20351;&#29992;&#31070;&#32463;&#32447;&#24615;&#21248;&#36895;&#33218;&#31639;&#27861;&#26500;&#24314;&#22522;&#20110;&#25506;&#32034;&#30340;&#25490;&#21517;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2305.07764</link><description>&lt;p&gt;
&#25506;&#32034;&#30340;&#20215;&#20540;&#65306;&#24230;&#37327;&#12289;&#21457;&#29616;&#21644;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Value of Exploration: Measurements, Findings and Algorithms. (arXiv:2305.07764v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#37327;&#21270;&#25506;&#32034;&#23545;&#20869;&#23481;&#35821;&#26009;&#24211;&#30340;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;&#25506;&#32034;&#23545;&#29992;&#25143;&#20307;&#39564;&#30340;&#38271;&#26399;&#22909;&#22788;&#65292;&#24182;&#23581;&#35797;&#20351;&#29992;&#31070;&#32463;&#32447;&#24615;&#21248;&#36895;&#33218;&#31639;&#27861;&#26500;&#24314;&#22522;&#20110;&#25506;&#32034;&#30340;&#25490;&#21517;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#30340;&#25506;&#32034;&#34987;&#35748;&#20026;&#23545;&#25512;&#33616;&#24179;&#21488;&#19978;&#29992;&#25143;&#20307;&#39564;&#30340;&#38271;&#26399;&#24433;&#21709;&#26377;&#31215;&#26497;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30830;&#23450;&#20854;&#30830;&#20999;&#30340;&#22909;&#22788;&#19968;&#30452;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#25506;&#32034;&#30340;&#24120;&#35268;A/B&#27979;&#35797;&#36890;&#24120;&#27979;&#37327;&#20013;&#24615;&#29978;&#33267;&#28040;&#26497;&#30340;&#21442;&#19982;&#24230;&#25351;&#26631;&#65292;&#21516;&#26102;&#26410;&#33021;&#25429;&#25417;&#20854;&#38271;&#26399;&#25928;&#30410;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#39033;&#31995;&#32479;&#24615;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#26816;&#26597;&#25506;&#32034;&#23545;&#20869;&#23481;&#35821;&#26009;&#24211;&#30340;&#24433;&#21709;&#26469;&#27491;&#24335;&#37327;&#21270;&#25506;&#32034;&#30340;&#20215;&#20540;&#65292;&#36825;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#30452;&#25509;&#24433;&#21709;&#29992;&#25143;&#20307;&#39564;&#30340;&#20851;&#38190;&#23454;&#20307;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#21644;&#30456;&#20851;&#23454;&#39564;&#35774;&#35745;&#26469;&#27979;&#37327;&#25506;&#32034;&#23545;&#35821;&#26009;&#24211;&#21464;&#21270;&#30340;&#30410;&#22788;&#65292;&#24182;&#36827;&#19968;&#27493;&#23558;&#35821;&#26009;&#24211;&#21464;&#21270;&#19982;&#38271;&#26399;&#29992;&#25143;&#20307;&#39564;&#32852;&#31995;&#36215;&#26469;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24341;&#20837;&#31070;&#32463;&#32447;&#24615;&#21248;&#36895;&#33218;&#31639;&#27861;&#26500;&#24314;&#22522;&#20110;&#25506;&#32034;&#30340;&#25490;&#21517;&#31995;&#32479;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#25105;&#20204;&#30340;&#26696;&#20363;&#30740;&#31350;&#30340;&#39592;&#24178;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#22823;&#35268;&#27169;&#30495;&#23454;&#22330;&#26223;&#19979;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#26102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Effective exploration is believed to positively influence the long-term user experience on recommendation platforms. Determining its exact benefits, however, has been challenging. Regular A/B tests on exploration often measure neutral or even negative engagement metrics while failing to capture its long-term benefits. To address this, we present a systematic study to formally quantify the value of exploration by examining its effects on the content corpus, a key entity in the recommender system that directly affects user experiences. Specifically, we introduce new metrics and the associated experiment design to measure the benefit of exploration on the corpus change, and further connect the corpus change to the long-term user experience. Furthermore, we investigate the possibility of introducing the Neural Linear Bandit algorithm to build an exploration-based ranking system, and use it as the backbone algorithm for our case study. We conduct extensive live experiments on a large-scale 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#35782;&#21035;&#21361;&#38505;&#23398;&#29983;&#22238;&#22797;&#30340;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#37319;&#29992;&#32463;&#36807;&#24494;&#35843;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.07709</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#26816;&#27979;&#21361;&#38505;&#30340;&#23398;&#29983;&#22238;&#22797;
&lt;/p&gt;
&lt;p&gt;
Using Language Models to Detect Alarming Student Responses. (arXiv:2305.07709v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#35782;&#21035;&#21361;&#38505;&#23398;&#29983;&#22238;&#22797;&#30340;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#37319;&#29992;&#32463;&#36807;&#24494;&#35843;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#35782;&#21035;&#21361;&#38505;&#23398;&#29983;&#22238;&#22797;&#30340;&#31995;&#32479;&#30340;&#36827;&#23637;&#12290;&#35813;&#31995;&#32479;&#38598;&#25104;&#22312;&#25105;&#20204;&#30340;&#35780;&#20272;&#24179;&#21488;&#20013;&#65292;&#29992;&#20110;&#35780;&#20272;&#23398;&#29983;&#30340;&#22238;&#22797;&#26159;&#21542;&#34920;&#26126;&#20182;&#20204;&#23545;&#33258;&#24049;&#25110;&#20182;&#20154;&#26500;&#25104;&#23041;&#32961;&#12290;&#36825;&#20123;&#22238;&#22797;&#21487;&#33021;&#21253;&#25324;&#20851;&#20110;&#26292;&#21147;&#23041;&#32961;&#12289;&#20005;&#37325;&#25233;&#37057;&#12289;&#33258;&#26432;&#39118;&#38505;&#21644;&#34384;&#24453;&#25551;&#36848;&#30340;&#32454;&#33410;&#12290;&#26368;&#26032;&#27169;&#22411;&#26159;&#19968;&#20010;&#32463;&#36807;&#24494;&#35843;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#23427;&#26159;&#22312;&#30001;&#23398;&#29983;&#22238;&#22797;&#21644;&#34917;&#20805;&#25991;&#26412;&#26500;&#25104;&#30340;&#22823;&#22411;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#32780;&#25104;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#27604;&#27492;&#21069;&#29256;&#26412;&#30340;&#31995;&#32479;&#33021;&#22815;&#22823;&#24133;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article details the advances made to a system that uses artificial intelligence to identify alarming student responses. This system is built into our assessment platform to assess whether a student's response indicates they are a threat to themselves or others. Such responses may include details concerning threats of violence, severe depression, suicide risks, and descriptions of abuse. Driven by advances in natural language processing, the latest model is a fine-tuned language model trained on a large corpus consisting of student responses and supplementary texts. We demonstrate that the use of a language model delivers a substantial improvement in accuracy over the previous iterations of this system.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.06569</link><description>&lt;p&gt;
&#22914;&#20309;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#32034;&#24341;&#39033;&#30446;ID
&lt;/p&gt;
&lt;p&gt;
How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#23558;&#25512;&#33616;&#20219;&#21153;&#36716;&#25442;&#20026;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#25512;&#33616;&#12290;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#24314;&#35758;&#30340;&#39033;&#30446;&#32780;&#19981;&#26159;&#35745;&#31639;&#20256;&#32479;&#25512;&#33616;&#27169;&#22411;&#20013;&#27599;&#20010;&#20505;&#36873;&#39033;&#30446;&#30340;&#25490;&#21517;&#24471;&#20998;&#65292;&#31616;&#21270;&#20102;&#25512;&#33616;&#31649;&#36947;&#65292;&#36991;&#20813;&#20102;&#22810;&#27573;&#36807;&#28388;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#20915;&#23450;&#35201;&#25512;&#33616;&#21738;&#20123;&#39033;&#30446;&#26102;&#29983;&#25104;&#36807;&#38271;&#30340;&#25991;&#26412;&#65292;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#21019;&#24314;LLM&#20860;&#23481;&#30340;&#39033;&#30446;ID&#26159;&#24517;&#35201;&#30340;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#65292;&#20197;P5&#20026;&#20195;&#34920;&#30340;&#20027;&#24178;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32034;&#24341;&#26041;&#27861;&#22797;&#21046;&#20854;&#32467;&#26524;&#12290;&#25105;&#20204;&#39318;&#20808;&#35752;&#35770;&#20102;&#20960;&#31181;&#24494;&#19981;&#36275;&#36947;&#30340;&#39033;&#30446;&#32034;&#24341;&#26041;&#27861;&#65288;&#22914;&#29420;&#31435;&#32034;&#24341;&#12289;&#26631;&#39064;&#32034;&#24341;&#21644;&#38543;&#26426;&#32034;&#24341;&#65289;&#30340;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#19981;&#36866;&#29992;&#20110;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32034;&#24341;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#31181;&#32034;&#24341;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#32034;&#24341;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#31616;&#21333;&#26377;&#25928;&#26080;&#30417;&#30563;&#20851;&#38190;&#35789;&#25552;&#21462;&#26041;&#27861;PromptRank&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;MDERank&#26041;&#27861;&#22312;&#19977;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#20998;&#21035;&#25552;&#39640;&#20102;34.18&#65285;&#65292;24.87&#65285;&#21644;17.57&#65285;&#30340;F1&#20998;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.04490</link><description>&lt;p&gt;
PromptRank: &#20351;&#29992;prompt&#30340;&#26080;&#30417;&#30563;&#20851;&#38190;&#35789;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
PromptRank: Unsupervised Keyphrase Extraction Using Prompt. (arXiv:2305.04490v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04490
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#31616;&#21333;&#26377;&#25928;&#26080;&#30417;&#30563;&#20851;&#38190;&#35789;&#25552;&#21462;&#26041;&#27861;PromptRank&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;MDERank&#26041;&#27861;&#22312;&#19977;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#20998;&#21035;&#25552;&#39640;&#20102;34.18&#65285;&#65292;24.87&#65285;&#21644;17.57&#65285;&#30340;F1&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#38190;&#35789;&#25552;&#21462;&#20219;&#21153;&#26159;&#25351;&#33258;&#21160;&#20174;&#32473;&#23450;&#25991;&#26723;&#20013;&#36873;&#25321;&#30701;&#35821;&#26469;&#24635;&#32467;&#20854;&#26680;&#24515;&#20869;&#23481;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#23884;&#20837;&#30340;&#31639;&#27861;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#23427;&#20204;&#26681;&#25454;&#20505;&#36873;&#30701;&#35821;&#30340;&#23884;&#20837;&#19982;&#25991;&#26723;&#23884;&#20837;&#30340;&#30456;&#20284;&#31243;&#24230;&#23545;&#20854;&#36827;&#34892;&#25490;&#24207;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#35299;&#20915;&#26041;&#26696;&#35201;&#20040;&#22312;&#25991;&#26723;&#21644;&#20505;&#36873;&#30701;&#35821;&#38271;&#24230;&#19981;&#19968;&#33268;&#26102;&#38590;&#20197;&#22788;&#29702;&#65292;&#35201;&#20040;&#22312;&#27809;&#26377;&#36827;&#19968;&#27493;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#26080;&#27861;&#20805;&#20998;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#12290;&#20026;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26080;&#30417;&#30563;&#26041;&#27861;PromptRank&#65292;&#23427;&#22522;&#20110;&#20855;&#26377;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#26550;&#26500;&#30340;PLM&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;PromptRank&#23558;&#25991;&#26723;&#36755;&#20837;&#32534;&#30721;&#22120;&#65292;&#24182;&#36890;&#36807;&#35299;&#30721;&#22120;&#35745;&#31639;&#29983;&#25104;&#21253;&#21547;&#35774;&#35745;&#30340;prompt&#30340;&#20505;&#36873;&#30701;&#35821;&#30340;&#27010;&#29575;&#12290;&#25105;&#20204;&#22312;&#20845;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#22522;&#20934;&#27979;&#35797;&#19978;&#23545;&#25552;&#20986;&#30340;PromptRank&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;PromptRank&#22312;F1&#20998;&#25968;&#19978;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;MDERank&#26041;&#27861;&#20998;&#21035;&#25552;&#39640;&#20102;34.18&#65285;&#65292;24.87&#65285;&#21644;17.57&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
The keyphrase extraction task refers to the automatic selection of phrases from a given document to summarize its core content. State-of-the-art (SOTA) performance has recently been achieved by embedding-based algorithms, which rank candidates according to how similar their embeddings are to document embeddings. However, such solutions either struggle with the document and candidate length discrepancies or fail to fully utilize the pre-trained language model (PLM) without further fine-tuning. To this end, in this paper, we propose a simple yet effective unsupervised approach, PromptRank, based on the PLM with an encoder-decoder architecture. Specifically, PromptRank feeds the document into the encoder and calculates the probability of generating the candidate with a designed prompt by the decoder. We extensively evaluate the proposed PromptRank on six widely used benchmarks. PromptRank outperforms the SOTA approach MDERank, improving the F1 score relatively by 34.18%, 24.87%, and 17.57
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#24863;&#30693;&#36328;&#39046;&#22495;&#25512;&#33616;&#27169;&#22411;FairCDR&#65292;&#36890;&#36807;&#23398;&#20064;&#20844;&#24179;&#24863;&#30693;&#30340;&#26144;&#23556;&#20989;&#25968;&#23454;&#29616;&#38754;&#21521;&#29992;&#25143;&#32676;&#20307;&#30340;&#20844;&#24179;&#24615;&#65292;&#24182;&#21033;&#29992;&#20016;&#23500;&#30340;&#38750;&#37325;&#21472;&#29992;&#25143;&#21644;&#20132;&#20114;&#26469;&#32531;&#35299;&#25968;&#25454;&#37325;&#21472;&#21644;&#20998;&#24067;&#20559;&#24046;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#37319;&#29992;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#30340;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#26469;&#20943;&#23569;&#19981;&#20844;&#24179;&#24615;&#65292;&#20445;&#25345;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.00158</link><description>&lt;p&gt;
&#20844;&#24179;&#24863;&#30693;&#30340;&#36328;&#39046;&#22495;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Fairness-aware Cross-Domain Recommendation. (arXiv:2302.00158v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#24863;&#30693;&#36328;&#39046;&#22495;&#25512;&#33616;&#27169;&#22411;FairCDR&#65292;&#36890;&#36807;&#23398;&#20064;&#20844;&#24179;&#24863;&#30693;&#30340;&#26144;&#23556;&#20989;&#25968;&#23454;&#29616;&#38754;&#21521;&#29992;&#25143;&#32676;&#20307;&#30340;&#20844;&#24179;&#24615;&#65292;&#24182;&#21033;&#29992;&#20016;&#23500;&#30340;&#38750;&#37325;&#21472;&#29992;&#25143;&#21644;&#20132;&#20114;&#26469;&#32531;&#35299;&#25968;&#25454;&#37325;&#21472;&#21644;&#20998;&#24067;&#20559;&#24046;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#37319;&#29992;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#30340;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#26469;&#20943;&#23569;&#19981;&#20844;&#24179;&#24615;&#65292;&#20445;&#25345;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#25512;&#33616;&#26159;&#32531;&#35299;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#20294;&#20197;&#24448;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#26144;&#23556;&#20989;&#25968;&#26102;&#20005;&#37325;&#24573;&#35270;&#20102;&#20844;&#24179;&#24615;&#21644;&#20559;&#35265;&#65292;&#36825;&#20250;&#24433;&#21709;&#21040;&#30446;&#26631;&#39046;&#22495;&#20013;&#26032;&#29992;&#25143;&#30340;&#34920;&#31034;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FairCDR&#30340;&#20844;&#24179;&#24863;&#30693;&#36328;&#39046;&#22495;&#25512;&#33616;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#23398;&#20064;&#20844;&#24179;&#24863;&#30693;&#30340;&#26144;&#23556;&#20989;&#25968;&#23454;&#29616;&#20102;&#38754;&#21521;&#29992;&#25143;&#32676;&#20307;&#30340;&#20844;&#24179;&#24615;&#12290;&#30001;&#20110;&#37325;&#21472;&#25968;&#25454;&#30456;&#24403;&#26377;&#38480;&#19988;&#20855;&#26377;&#20998;&#24067;&#20559;&#24046;&#65292;&#25105;&#20204;&#21033;&#29992;&#20016;&#23500;&#30340;&#38750;&#37325;&#21472;&#29992;&#25143;&#21644;&#20132;&#20114;&#26469;&#24110;&#21161;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#12290;&#32771;&#34385;&#21040;&#27599;&#20010;&#20010;&#20307;&#23545;&#27169;&#22411;&#20844;&#24179;&#24615;&#20855;&#26377;&#19981;&#21516;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#30340;&#26032;&#30340;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#65292;&#20197;&#20943;&#23569;&#19981;&#20844;&#24179;&#24615;&#21516;&#26102;&#20445;&#25345;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#26469;&#35777;&#26126;&#25105;&#20204;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-Domain Recommendation (CDR) is an effective way to alleviate the cold-start problem. However, previous work severely ignores fairness and bias when learning the mapping function, which is used to obtain the representations for fresh users in the target domain. To study this problem, in this paper, we propose a Fairness-aware Cross-Domain Recommendation model, called FairCDR. Our method achieves user-oriented group fairness by learning the fairness-aware mapping function. Since the overlapping data are quite limited and distributionally biased, FairCDR leverages abundant non-overlapping users and interactions to help alleviate these problems. Considering that each individual has different influence on model fairness, we propose a new reweighing method based on Influence Function (IF) to reduce unfairness while maintaining recommendation accuracy. Extensive experiments are conducted to demonstrate the effectiveness of our model.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#21487;&#20197;&#23398;&#20064;&#36731;&#37327;&#32423;&#27169;&#22411;&#24182;&#22312;&#26234;&#33021;&#35774;&#22791;&#19978;&#37096;&#32626;&#65292;&#21516;&#26102;&#23454;&#29616;&#23545;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#31934;&#32454;&#20010;&#24615;&#21270;&#12290;</title><link>http://arxiv.org/abs/2301.08143</link><description>&lt;p&gt;
&#32852;&#37030;&#25512;&#33616;&#20013;&#30340;&#21452;&#37325;&#20010;&#24615;&#21270;
&lt;/p&gt;
&lt;p&gt;
Dual Personalization on Federated Recommendation. (arXiv:2301.08143v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#21487;&#20197;&#23398;&#20064;&#36731;&#37327;&#32423;&#27169;&#22411;&#24182;&#22312;&#26234;&#33021;&#35774;&#22791;&#19978;&#37096;&#32626;&#65292;&#21516;&#26102;&#23454;&#29616;&#23545;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#31934;&#32454;&#20010;&#24615;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#25512;&#33616;&#26159;&#19968;&#31181;&#26088;&#22312;&#22312;&#32852;&#37030;&#29615;&#22659;&#19979;&#25552;&#20379;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#26381;&#21153;&#30340;&#26032;&#22411;Internet&#26381;&#21153;&#26550;&#26500;&#12290;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#29992;&#20110;&#32452;&#21512;&#20998;&#24067;&#24335;&#25512;&#33616;&#31639;&#27861;&#21644;&#38544;&#31169;&#20445;&#25252;&#26426;&#21046;&#65292;&#22240;&#27492;&#20174;&#26681;&#26412;&#19978;&#37319;&#29992;&#26381;&#21153;&#22120;&#19978;&#30340;&#37325;&#37327;&#32423;&#27169;&#22411;&#65292;&#38459;&#30861;&#20102;&#22312;&#35774;&#22791;&#19978;&#37096;&#32626;&#26234;&#33021;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#25512;&#33616;&#65288;PFedRec&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#35768;&#22810;&#29992;&#25143;&#29305;&#23450;&#30340;&#36731;&#37327;&#32423;&#27169;&#22411;&#65292;&#20197;&#20415;&#22312;&#26234;&#33021;&#35774;&#22791;&#19978;&#37096;&#32626;&#65292;&#32780;&#19981;&#26159;&#22312;&#26381;&#21153;&#22120;&#19978;&#20351;&#29992;&#37325;&#37327;&#32423;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#37325;&#20010;&#24615;&#21270;&#26426;&#21046;&#65292;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#32454;&#31890;&#24230;&#20010;&#24615;&#21270;&#12290;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#34987;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#32479;&#19968;&#30340;&#32852;&#37030;&#20248;&#21270;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated recommendation is a new Internet service architecture that aims to provide privacy-preserving recommendation services in federated settings. Existing solutions are used to combine distributed recommendation algorithms and privacy-preserving mechanisms. Thus it inherently takes the form of heavyweight models at the server and hinders the deployment of on-device intelligent models to end-users. This paper proposes a novel Personalized Federated Recommendation (PFedRec) framework to learn many user-specific lightweight models to be deployed on smart devices rather than a heavyweight model on a server. Moreover, we propose a new dual personalization mechanism to effectively learn fine-grained personalization on both users and items. The overall learning process is formulated into a unified federated optimization framework. Specifically, unlike previous methods that share exactly the same item embeddings across users in a federated system, dual personalization allows mild finetuni
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26597;&#35810;&#25193;&#20805;&#26469;&#25628;&#32034;&#20887;&#20313;&#20449;&#24687;&#12289;&#24182;&#36890;&#36807;&#26032;&#39062;&#30340;&#32622;&#20449;&#24230;&#26041;&#27861;&#23558;&#20854;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#38450;&#24481;&#24320;&#25918;&#22495;&#38382;&#31572;&#31995;&#32479;&#20013;&#30340;&#27745;&#26579;&#25915;&#20987;&#65292;&#31934;&#30830;&#21305;&#37197;&#29575;&#21487;&#25552;&#39640;&#36817;20%&#12290;</title><link>http://arxiv.org/abs/2212.10002</link><description>&lt;p&gt;
&#22312;&#24320;&#25918;&#22495;&#38382;&#31572;&#20013;&#38450;&#24481;&#35823;&#23548;&#24615;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Defending Against Misinformation Attacks in Open-Domain Question Answering. (arXiv:2212.10002v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10002
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26597;&#35810;&#25193;&#20805;&#26469;&#25628;&#32034;&#20887;&#20313;&#20449;&#24687;&#12289;&#24182;&#36890;&#36807;&#26032;&#39062;&#30340;&#32622;&#20449;&#24230;&#26041;&#27861;&#23558;&#20854;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#38450;&#24481;&#24320;&#25918;&#22495;&#38382;&#31572;&#31995;&#32479;&#20013;&#30340;&#27745;&#26579;&#25915;&#20987;&#65292;&#31934;&#30830;&#21305;&#37197;&#29575;&#21487;&#25552;&#39640;&#36817;20%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#24320;&#25918;&#22495;&#38382;&#31572;&#39046;&#22495;&#20013;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#25628;&#32034;&#38598;&#21512;&#36827;&#34892;&#30340;&#25932;&#23545;&#27745;&#26579;&#21487;&#33021;&#20250;&#23548;&#33268;&#29983;&#20135;&#31995;&#32479;&#30340;&#31934;&#24230;&#22823;&#24133;&#19979;&#38477;&#12290;&#28982;&#32780;&#65292;&#20960;&#20046;&#27809;&#26377;&#24037;&#20316;&#25552;&#20986;&#38450;&#24481;&#36825;&#20123;&#25915;&#20987;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20381;&#36182;&#20110;&#22823;&#22411;&#35821;&#26009;&#24211;&#20013;&#23384;&#22312;&#20887;&#20313;&#20449;&#24687;&#30340;&#30452;&#35273;&#12290;&#20026;&#20102;&#25214;&#21040;&#36825;&#20123;&#20449;&#24687;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;&#26597;&#35810;&#25193;&#20805;&#26469;&#25628;&#32034;&#21487;&#33021;&#22238;&#31572;&#21407;&#22987;&#38382;&#39064;&#30340;&#22810;&#26679;&#21270;&#27573;&#33853;&#38598;&#21512;&#30340;&#26041;&#27861;&#65292;&#20294;&#26159;&#19981;&#22826;&#21487;&#33021;&#34987;&#27745;&#26579;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#26032;&#22411;&#30340;&#32622;&#20449;&#24230;&#26041;&#27861;&#65288;&#27604;&#36739;&#39044;&#27979;&#31572;&#26696;&#19982;&#20854;&#22312;&#26816;&#32034;&#21040;&#30340;&#19978;&#19979;&#25991;&#20013;&#20986;&#29616;&#30340;&#24773;&#20917;&#8212;&#8212;&#25105;&#20204;&#31216;&#20043;&#20026;&#31572;&#26696;&#20887;&#20313;&#32622;&#20449;&#24230;&#65292;&#21363;CAR&#65289;&#23558;&#36825;&#20123;&#26032;&#27573;&#33853;&#38598;&#25104;&#21040;&#27169;&#22411;&#20013;&#12290;&#36825;&#20123;&#26041;&#27861;&#20849;&#21516;&#26500;&#25104;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#26041;&#24335;&#65292;&#29992;&#20110;&#38450;&#24481;&#27745;&#26579;&#25915;&#20987;&#65292;&#21487;&#22312;&#19981;&#21516;&#27700;&#24179;&#30340;&#25968;&#25454;&#27745;&#26579;/&#30693;&#35782;&#20914;&#31361;&#19979;&#25552;&#20379;&#36817;20&#65285;&#30340;&#31934;&#30830;&#21305;&#37197;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work in open-domain question answering (ODQA) has shown that adversarial poisoning of the search collection can cause large drops in accuracy for production systems. However, little to no work has proposed methods to defend against these attacks. To do so, we rely on the intuition that redundant information often exists in large corpora. To find it, we introduce a method that uses query augmentation to search for a diverse set of passages that could answer the original question but are less likely to have been poisoned. We integrate these new passages into the model through the design of a novel confidence method, comparing the predicted answer to its appearance in the retrieved contexts (what we call \textit{Confidence from Answer Redundancy}, i.e. CAR). Together these methods allow for a simple but effective way to defend against poisoning attacks that provides gains of nearly 20\% exact match across varying levels of data poisoning/knowledge conflicts.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#29992;&#25143;&#21382;&#21490;&#35821;&#35328;&#24314;&#27169;&#21487;&#20197;&#22312;&#19981;&#21516;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20248;&#24322;&#32467;&#26524;&#65292;&#24182;&#19988;&#21033;&#29992;&#20219;&#21153;&#26080;&#20851;&#30340;&#29992;&#25143;&#21382;&#21490;&#36824;&#21487;&#20197;&#25552;&#20379;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#30340;&#29616;&#23454;&#19990;&#30028;&#36801;&#31227;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2212.03760</link><description>&lt;p&gt;
&#35821;&#35328;&#24314;&#27169;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#65306;&#20016;&#23500;&#20219;&#21153;&#29305;&#23450;&#21644;&#20219;&#21153;&#26080;&#20851;&#30340;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning. (arXiv:2212.03760v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.03760
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#29992;&#25143;&#21382;&#21490;&#35821;&#35328;&#24314;&#27169;&#21487;&#20197;&#22312;&#19981;&#21516;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20248;&#24322;&#32467;&#26524;&#65292;&#24182;&#19988;&#21033;&#29992;&#20219;&#21153;&#26080;&#20851;&#30340;&#29992;&#25143;&#21382;&#21490;&#36824;&#21487;&#20197;&#25552;&#20379;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#30340;&#29616;&#23454;&#19990;&#30028;&#36801;&#31227;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#21033;&#29992;&#26469;&#33258;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#30340;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#30340;&#32479;&#19968;&#29992;&#25143;&#24314;&#27169;&#26694;&#26550;&#12290;&#20854;&#20013;&#35768;&#22810;&#21463;&#30410;&#20110;&#23558;&#29992;&#25143;&#34892;&#20026;&#24207;&#21015;&#20316;&#20026;&#32431;&#25991;&#26412;&#20351;&#29992;&#65292;&#20195;&#34920;&#30528;&#20219;&#20309;&#39046;&#22495;&#25110;&#31995;&#32479;&#20013;&#30340;&#20016;&#23500;&#20449;&#24687;&#32780;&#19981;&#22833;&#36890;&#29992;&#24615;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#38382;&#39064;&#20135;&#29983;&#20102;&#65306;&#29992;&#25143;&#21382;&#21490;&#35821;&#35328;&#24314;&#27169;&#33021;&#21542;&#24110;&#21161;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#65311;&#34429;&#28982;&#35821;&#35328;&#24314;&#27169;&#30340;&#22810;&#21151;&#33021;&#24615;&#24050;&#22312;&#35768;&#22810;&#39046;&#22495;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#20854;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#20173;&#26410;&#28145;&#20837;&#25506;&#35752;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30452;&#25509;&#24212;&#29992;&#20110;&#20219;&#21153;&#29305;&#23450;&#29992;&#25143;&#21382;&#21490;&#30340;&#35821;&#35328;&#24314;&#27169;&#22312;&#19981;&#21516;&#30340;&#25512;&#33616;&#20219;&#21153;&#19978;&#21487;&#20197;&#21462;&#24471;&#20248;&#24322;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#20219;&#21153;&#26080;&#20851;&#30340;&#29992;&#25143;&#21382;&#21490;&#36824;&#21487;&#20197;&#25552;&#20379;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20026;&#24191;&#27867;&#30340;&#29616;&#23454;&#19990;&#30028;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#26377;&#21069;&#36884;&#30340;&#36801;&#31227;&#23398;&#20064;&#33021;&#21147;&#65292;&#29978;&#33267;&#22312;&#26410;&#30693;&#22495;&#21644;&#26381;&#21153;&#19978;&#20063;&#21487;&#20197;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have proposed unified user modeling frameworks that leverage user behavior data from various applications. Many of them benefit from utilizing users' behavior sequences as plain texts, representing rich information in any domain or system without losing generality. Hence, a question arises: Can language modeling for user history corpus help improve recommender systems? While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored. We show that language modeling applied directly to task-specific user histories achieves excellent results on diverse recommendation tasks. Also, leveraging additional task-agnostic user histories delivers significant performance benefits. We further demonstrate that our approach can provide promising transfer learning capabilities for a broad spectrum of real-world recommender systems, even on unseen domains and services.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25551;&#36848;&#20102;&#22312;DCASE 2022&#27604;&#36187;&#20013;&#21442;&#21152;&#20102;&#33258;&#21160;&#38899;&#39057;&#23383;&#24149;&#21644;&#22522;&#20110;&#35821;&#35328;&#30340;&#38899;&#39057;&#26816;&#32034;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#24182;&#20351;&#29992;Clotho&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#23545;&#20110;&#36825;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#22522;&#32447;&#27169;&#22411;&#65292;&#24471;&#21040;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2207.04156</link><description>&lt;p&gt;
&#33258;&#21160;&#38899;&#39057;&#23383;&#24149;&#21644;&#22522;&#20110;&#35821;&#35328;&#30340;&#38899;&#39057;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Automated Audio Captioning and Language-Based Audio Retrieval. (arXiv:2207.04156v2 [cs.SD] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.04156
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25551;&#36848;&#20102;&#22312;DCASE 2022&#27604;&#36187;&#20013;&#21442;&#21152;&#20102;&#33258;&#21160;&#38899;&#39057;&#23383;&#24149;&#21644;&#22522;&#20110;&#35821;&#35328;&#30340;&#38899;&#39057;&#26816;&#32034;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#24182;&#20351;&#29992;Clotho&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#23545;&#20110;&#36825;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#22522;&#32447;&#27169;&#22411;&#65292;&#24471;&#21040;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#39033;&#30446;&#21442;&#21152;&#20102;DCASE 2022&#31454;&#36187;&#65288;&#20219;&#21153;6&#65289;&#65292;&#20854;&#20998;&#20026;&#20004;&#20010;&#23376;&#20219;&#21153;&#65306;&#65288;1&#65289;&#33258;&#21160;&#38899;&#39057;&#23383;&#24149;&#21644;&#65288;2&#65289;&#22522;&#20110;&#35821;&#35328;&#30340;&#38899;&#39057;&#26816;&#32034;&#12290;&#31532;&#19968;&#20010;&#23376;&#20219;&#21153;&#28041;&#21450;&#20026;&#38899;&#39057;&#26679;&#26412;&#29983;&#25104;&#25991;&#26412;&#25551;&#36848;&#65292;&#32780;&#31532;&#20108;&#20010;&#23376;&#20219;&#21153;&#30340;&#30446;&#26631;&#26159;&#22312;&#22266;&#23450;&#25968;&#25454;&#38598;&#20013;&#26597;&#25214;&#19982;&#32473;&#23450;&#25551;&#36848;&#30456;&#21305;&#37197;&#30340;&#38899;&#39057;&#26679;&#26412;&#12290;&#23545;&#20110;&#36825;&#20004;&#20010;&#23376;&#20219;&#21153;&#65292;&#20351;&#29992;&#20102;Clotho&#25968;&#25454;&#38598;&#12290;&#23545;&#20110;&#38899;&#39057;&#23383;&#24149;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;BLEU1&#65292;BLEU2&#65292;BLEU3&#65292;ROUGEL&#65292;METEOR&#65292;CIDEr&#65292;SPICE&#21644;SPIDEr&#24471;&#20998;&#65292;&#32780;&#38899;&#39057;&#26816;&#32034;&#35780;&#20272;&#20102;R1&#65292;R5&#65292;R10&#21644;mARP10&#24471;&#20998;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#20123;&#20462;&#25913;&#36825;&#20123;&#20219;&#21153;&#30340;&#22522;&#32447;&#27169;&#22411;&#30340;&#23454;&#39564;&#12290;&#25105;&#20204;&#38024;&#23545;&#33258;&#21160;&#38899;&#39057;&#23383;&#24149;&#30340;&#26368;&#32456;&#26550;&#26500;&#25509;&#36817;&#20110;&#22522;&#32447;&#24615;&#33021;&#65292;&#32780;&#25105;&#20204;&#38024;&#23545;&#22522;&#20110;&#35821;&#35328;&#30340;&#38899;&#39057;&#26816;&#32034;&#30340;&#27169;&#22411;&#24050;&#36229;&#36234;&#20102;&#20854;&#23545;&#24212;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This project involved participation in the DCASE 2022 Competition (Task 6) which had two subtasks: (1) Automated Audio Captioning and (2) Language-Based Audio Retrieval. The first subtask involved the generation of a textual description for audio samples, while the goal of the second was to find audio samples within a fixed dataset that match a given description. For both subtasks, the Clotho dataset was used. The models were evaluated on BLEU1, BLEU2, BLEU3, ROUGEL, METEOR, CIDEr, SPICE, and SPIDEr scores for audio captioning and R1, R5, R10 and mARP10 scores for audio retrieval. We have conducted a handful of experiments that modify the baseline models for these tasks. Our final architecture for Automated Audio Captioning is close to the baseline performance, while our model for Language-Based Audio Retrieval has surpassed its counterpart.
&lt;/p&gt;</description></item></channel></rss>