<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24402;&#32435;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#26696;&#20363;&#38388;&#30340;&#36830;&#25509;&#20851;&#31995;&#65292;&#25552;&#39640;&#20102;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.17780</link><description>&lt;p&gt;
CaseLink:&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#30340;&#24402;&#32435;&#22270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
CaseLink: Inductive Graph Learning for Legal Case Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17780
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24402;&#32435;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#26696;&#20363;&#38388;&#30340;&#36830;&#25509;&#20851;&#31995;&#65292;&#25552;&#39640;&#20102;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26696;&#20363;&#27861;&#20013;&#65292;&#20808;&#20363;&#26159;&#29992;&#26469;&#25903;&#25345;&#27861;&#23448;&#20570;&#20986;&#20915;&#23450;&#20197;&#21450;&#24459;&#24072;&#23545;&#29305;&#23450;&#26696;&#20363;&#30340;&#35266;&#28857;&#30340;&#30456;&#20851;&#26696;&#20363;&#12290;&#20026;&#20102;&#20174;&#22823;&#37327;&#26696;&#20363;&#27744;&#20013;&#39640;&#25928;&#22320;&#25214;&#21040;&#30456;&#20851;&#26696;&#20363;&#65292;&#27861;&#24459;&#20174;&#19994;&#32773;&#24191;&#27867;&#20351;&#29992;&#26816;&#32034;&#24037;&#20855;&#12290;&#29616;&#26377;&#30340;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#27169;&#22411;&#20027;&#35201;&#36890;&#36807;&#27604;&#36739;&#21333;&#20010;&#26696;&#20363;&#30340;&#25991;&#26412;&#34920;&#31034;&#26469;&#24037;&#20316;&#12290;&#23613;&#31649;&#23427;&#20204;&#33719;&#24471;&#20102;&#19981;&#38169;&#30340;&#26816;&#32034;&#20934;&#30830;&#24615;&#65292;&#20294;&#26696;&#20363;&#20043;&#38388;&#30340;&#22266;&#26377;&#36830;&#25509;&#20851;&#31995;&#26410;&#34987;&#20805;&#20998;&#21033;&#29992;&#20110;&#26696;&#20363;&#32534;&#30721;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#32034;&#24615;&#33021;&#12290;&#22312;&#26696;&#20363;&#27744;&#20013;&#65292;&#26377;&#19977;&#31181;&#26696;&#20363;&#36830;&#25509;&#20851;&#31995;&#65306;&#26696;&#20363;&#24341;&#29992;&#20851;&#31995;&#12289;&#26696;&#20363;&#35821;&#20041;&#20851;&#31995;&#21644;&#26696;&#20363;&#27861;&#24459;&#25351;&#25511;&#20851;&#31995;&#12290;&#30001;&#20110;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20219;&#21153;&#30340;&#24402;&#32435;&#26041;&#24335;&#30340;&#29305;&#28857;&#65292;&#20351;&#29992;&#26696;&#20363;&#24341;&#29992;&#20316;&#20026;&#36755;&#20837;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17780v1 Announce Type: new  Abstract: In case law, the precedents are the relevant cases that are used to support the decisions made by the judges and the opinions of lawyers towards a given case. This relevance is referred to as the case-to-case reference relation. To efficiently find relevant cases from a large case pool, retrieval tools are widely used by legal practitioners. Existing legal case retrieval models mainly work by comparing the text representations of individual cases. Although they obtain a decent retrieval accuracy, the intrinsic case connectivity relationships among cases have not been well exploited for case encoding, therefore limiting the further improvement of retrieval performance. In a case pool, there are three types of case connectivity relationships: the case reference relationship, the case semantic relationship, and the case legal charge relationship. Due to the inductive manner in the task of legal case retrieval, using case reference as input 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;PrepRec&#65292;&#36890;&#36807;&#24314;&#27169;&#29289;&#21697;&#27969;&#34892;&#24230;&#21160;&#24577;&#23398;&#20064;&#36890;&#29992;&#29289;&#21697;&#34920;&#31034;&#12290;&#22312;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;PrepRec&#21487;&#20197;&#38646;-shot&#36801;&#31227;&#21040;&#26032;&#39046;&#22495;&#65292;&#24182;&#19988;&#22312;&#27169;&#22411;&#22823;&#23567;&#19978;&#21482;&#26377;&#24456;&#23567;&#19968;&#37096;&#20998;&#65292;&#24182;&#19988;&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.01497</link><description>&lt;p&gt;
&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#65306;&#22522;&#20110;&#27969;&#34892;&#24230;&#21160;&#24577;&#30340;&#38646;-shot&#36801;&#31227;
&lt;/p&gt;
&lt;p&gt;
A Pre-trained Sequential Recommendation Framework: Popularity Dynamics for Zero-shot Transfer. (arXiv:2401.01497v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;PrepRec&#65292;&#36890;&#36807;&#24314;&#27169;&#29289;&#21697;&#27969;&#34892;&#24230;&#21160;&#24577;&#23398;&#20064;&#36890;&#29992;&#29289;&#21697;&#34920;&#31034;&#12290;&#22312;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;PrepRec&#21487;&#20197;&#38646;-shot&#36801;&#31227;&#21040;&#26032;&#39046;&#22495;&#65292;&#24182;&#19988;&#22312;&#27169;&#22411;&#22823;&#23567;&#19978;&#21482;&#26377;&#24456;&#23567;&#19968;&#37096;&#20998;&#65292;&#24182;&#19988;&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#23545;&#20110;&#22312;&#32447;&#24212;&#29992;&#22914;&#30005;&#23376;&#21830;&#21153;&#12289;&#35270;&#39057;&#27969;&#23186;&#20307;&#21644;&#31038;&#20132;&#23186;&#20307;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#27169;&#22411;&#26550;&#26500;&#19981;&#26029;&#25913;&#36827;&#65292;&#20294;&#23545;&#20110;&#27599;&#20010;&#26032;&#30340;&#24212;&#29992;&#39046;&#22495;&#65292;&#25105;&#20204;&#20173;&#28982;&#38656;&#35201;&#20174;&#22836;&#35757;&#32451;&#19968;&#20010;&#26032;&#27169;&#22411;&#20197;&#33719;&#24471;&#39640;&#36136;&#37327;&#30340;&#25512;&#33616;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#21644;&#35270;&#35273;&#27169;&#22411;&#24050;&#32463;&#22312;&#38646;-shot&#25110;&#23569;-shot&#36866;&#24212;&#26032;&#24212;&#29992;&#39046;&#22495;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#21463;&#21040;&#21516;&#34892;AI&#39046;&#22495;&#39044;&#35757;&#32451;&#27169;&#22411;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#39034;&#24207;&#25512;&#33616;&#26694;&#26550;&#65306;PrepRec&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#27169;&#29289;&#21697;&#27969;&#34892;&#24230;&#21160;&#24577;&#26469;&#23398;&#20064;&#36890;&#29992;&#29289;&#21697;&#34920;&#31034;&#12290;&#36890;&#36807;&#22312;&#20116;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;PrepRec&#22312;&#27809;&#26377;&#20219;&#20309;&#36741;&#21161;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#19981;&#20165;&#33021;&#22815;&#38646;-shot&#36801;&#31227;&#21040;&#26032;&#39046;&#22495;&#65292;&#24182;&#19988;&#19982;&#21516;&#31867;&#26368;&#20808;&#36827;&#30340;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#30456;&#27604;&#65292;&#27169;&#22411;&#22823;&#23567;&#20165;&#30456;&#24403;&#19968;&#23567;&#37096;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23454;&#29616;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommenders are crucial to the success of online applications, \eg e-commerce, video streaming, and social media. While model architectures continue to improve, for every new application domain, we still have to train a new model from scratch for high quality recommendations. On the other hand, pre-trained language and vision models have shown great success in zero-shot or few-shot adaptation to new application domains. Inspired by the success of pre-trained models in peer AI fields, we propose a novel pre-trained sequential recommendation framework: PrepRec. We learn universal item representations by modeling item popularity dynamics. Through extensive experiments on five real-world datasets, we show that PrepRec, without any auxiliary information, can not only zero-shot transfer to a new domain, but achieve competitive performance compared to state-of-the-art sequential recommender models with only a fraction of the model size. In addition, with a simple post-hoc interpol
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;&#25972;&#20010;Wikidata&#20998;&#31867;&#20307;&#31995;&#23613;&#21487;&#33021;&#22320;&#21512;&#24182;&#21040;YAGO&#30693;&#35782;&#24211;&#20013;&#30340;&#24037;&#20316;&#65292;&#20026;YAGO&#28155;&#21152;&#20102;&#20016;&#23500;&#30340;&#20449;&#24687;&#31867;&#21035;&#65292;&#24182;&#20445;&#25345;&#20102;&#30693;&#35782;&#24211;&#30340;&#36923;&#36753;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.11884</link><description>&lt;p&gt;
&#23558;Wikidata&#20998;&#31867;&#20307;&#31995;&#38598;&#25104;&#21040;YAGO&#20013;
&lt;/p&gt;
&lt;p&gt;
Integrating the Wikidata Taxonomy into YAGO. (arXiv:2308.11884v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;&#25972;&#20010;Wikidata&#20998;&#31867;&#20307;&#31995;&#23613;&#21487;&#33021;&#22320;&#21512;&#24182;&#21040;YAGO&#30693;&#35782;&#24211;&#20013;&#30340;&#24037;&#20316;&#65292;&#20026;YAGO&#28155;&#21152;&#20102;&#20016;&#23500;&#30340;&#20449;&#24687;&#31867;&#21035;&#65292;&#24182;&#20445;&#25345;&#20102;&#30693;&#35782;&#24211;&#30340;&#36923;&#36753;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Wikidata&#26159;&#26368;&#22823;&#30340;&#20844;&#20849;&#36890;&#29992;&#30693;&#35782;&#24211;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#30340;&#21512;&#20316;&#24615;&#36136;&#65292;&#20854;&#27169;&#24335;&#21644;&#20998;&#31867;&#20307;&#31995;&#21464;&#24471;&#22797;&#26434;&#12290;&#22312;YAGO 4&#30693;&#35782;&#24211;&#20013;&#65292;&#25105;&#20204;&#23558;Wikidata&#19982;Schema.org&#30340;&#26412;&#20307;&#35770;&#32467;&#21512;&#36215;&#26469;&#65292;&#20943;&#23569;&#21644;&#28165;&#29702;&#20998;&#31867;&#20307;&#31995;&#21644;&#32422;&#26463;&#26465;&#20214;&#65292;&#24182;&#20351;&#20854;&#33021;&#22815;&#22312;&#25968;&#25454;&#19978;&#36816;&#34892;&#33258;&#21160;&#25512;&#29702;&#22120;&#12290;&#28982;&#32780;&#65292;&#36825;&#20063;&#33293;&#24323;&#20102;&#22823;&#37096;&#20998;&#30340;Wikidata&#20998;&#31867;&#20307;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23558;&#25972;&#20010;Wikidata&#20998;&#31867;&#20307;&#31995;&#23613;&#21487;&#33021;&#22320;&#21512;&#24182;&#21040;YAGO&#30693;&#35782;&#24211;&#20013;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#36923;&#36753;&#32422;&#26463;&#21644;&#31867;&#19982;&#23454;&#20363;&#30340;&#32454;&#33268;&#21306;&#20998;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21019;&#24314;&#20102;YAGO 4.5&#65292;&#20026;YAGO&#28155;&#21152;&#20102;&#20016;&#23500;&#30340;&#20449;&#24687;&#31867;&#21035;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#30693;&#35782;&#24211;&#30340;&#36923;&#36753;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wikidata is one of the largest public general-purpose Knowledge Bases (KBs). Yet, due to its collaborative nature, its schema and taxonomy have become convoluted. For the YAGO 4 KB, we combined Wikidata with the ontology from Schema.org, which reduced and cleaned up the taxonomy and constraints and made it possible to run automated reasoners on the data. However, it also cut away large parts of the Wikidata taxonomy. In this paper, we present our effort to merge the entire Wikidata taxonomy into the YAGO KB as much as possible. We pay particular attention to logical constraints and a careful distinction of classes and instances. Our work creates YAGO 4.5, which adds a rich layer of informative classes to YAGO, while at the same time keeping the KB logically consistent.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#22312;SuggestBot&#19978;&#36827;&#34892;&#31163;&#32447;&#20998;&#26512;&#21644;&#20026;&#26399;&#19977;&#20010;&#26376;&#30340;&#23545;&#29031;&#23454;&#39564;&#65292;&#21457;&#29616;&#25512;&#33616;&#34987;&#20302;&#20272;&#20027;&#39064;&#30340;&#25991;&#31456;&#21487;&#20197;&#22686;&#21152;&#22312;&#36825;&#20123;&#25991;&#31456;&#19978;&#30340;&#32534;&#36753;&#24037;&#20316;&#37327;&#65292;&#21516;&#26102;&#19981;&#20250;&#26126;&#26174;&#38477;&#20302;&#23545;&#25512;&#33616;&#20869;&#23481;&#30340;&#25509;&#21463;&#31243;&#24230;&#12290;&#36825;&#19968;&#21457;&#29616;&#23545;&#35299;&#20915;&#23545;&#31561;&#29983;&#20135;&#24179;&#21488;&#19978;&#30340;&#20869;&#23481;&#32570;&#21475;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2307.08669</link><description>&lt;p&gt;
&#21033;&#29992;&#25512;&#33616;&#31995;&#32479;&#32553;&#23567;&#23545;&#31561;&#29983;&#20135;&#24179;&#21488;&#19978;&#30340;&#20869;&#23481;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Leveraging Recommender Systems to Reduce Content Gaps on Peer Production Platforms. (arXiv:2307.08669v2 [cs.CY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08669
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#22312;SuggestBot&#19978;&#36827;&#34892;&#31163;&#32447;&#20998;&#26512;&#21644;&#20026;&#26399;&#19977;&#20010;&#26376;&#30340;&#23545;&#29031;&#23454;&#39564;&#65292;&#21457;&#29616;&#25512;&#33616;&#34987;&#20302;&#20272;&#20027;&#39064;&#30340;&#25991;&#31456;&#21487;&#20197;&#22686;&#21152;&#22312;&#36825;&#20123;&#25991;&#31456;&#19978;&#30340;&#32534;&#36753;&#24037;&#20316;&#37327;&#65292;&#21516;&#26102;&#19981;&#20250;&#26126;&#26174;&#38477;&#20302;&#23545;&#25512;&#33616;&#20869;&#23481;&#30340;&#25509;&#21463;&#31243;&#24230;&#12290;&#36825;&#19968;&#21457;&#29616;&#23545;&#35299;&#20915;&#23545;&#31561;&#29983;&#20135;&#24179;&#21488;&#19978;&#30340;&#20869;&#23481;&#32570;&#21475;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#22522;&#30334;&#31185;&#31561;&#23545;&#31561;&#29983;&#20135;&#24179;&#21488;&#24120;&#24120;&#23384;&#22312;&#20869;&#23481;&#32570;&#21475;&#12290;&#20808;&#21069;&#30740;&#31350;&#34920;&#26126;&#65292;&#25512;&#33616;&#31995;&#32479;&#21487;&#20197;&#24110;&#21161;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36890;&#36807;&#24341;&#23548;&#32534;&#36753;&#20154;&#21592;&#20851;&#27880;&#34987;&#20302;&#20272;&#30340;&#20027;&#39064;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#36825;&#31181;&#26041;&#27861;&#26159;&#21542;&#20250;&#23548;&#33268;&#19981;&#22826;&#30456;&#20851;&#30340;&#25512;&#33616;&#65292;&#20174;&#32780;&#38477;&#20302;&#23545;&#25512;&#33616;&#20869;&#23481;&#30340;&#25972;&#20307;&#21442;&#19982;&#24230;&#12290;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#22312;SuggestBot&#19978;&#36827;&#34892;&#20102;&#31163;&#32447;&#20998;&#26512;&#65288;&#30740;&#31350;1&#65289;&#65292;&#28982;&#21518;&#36827;&#34892;&#20102;&#20026;&#26399;&#19977;&#20010;&#26376;&#30340;&#23545;&#29031;&#23454;&#39564;&#65288;&#30740;&#31350;2&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#21521;&#29992;&#25143;&#23637;&#31034;&#26469;&#33258;&#34987;&#20302;&#20272;&#20027;&#39064;&#30340;&#25991;&#31456;&#21487;&#20197;&#22686;&#21152;&#22312;&#36825;&#20123;&#25991;&#31456;&#19978;&#30340;&#24037;&#20316;&#37327;&#65292;&#32780;&#19981;&#20250;&#26126;&#26174;&#38477;&#20302;&#23545;&#25512;&#33616;&#20869;&#23481;&#30340;&#25509;&#21463;&#31243;&#24230;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#32467;&#26524;&#30340;&#24847;&#20041;&#65292;&#21253;&#25324;&#22914;&#20309;&#24573;&#35270;&#25991;&#31456;&#21457;&#29616;&#36807;&#31243;&#21487;&#33021;&#20250;&#20154;&#20026;&#22320;&#38480;&#21046;&#25512;&#33616;&#12290;&#25105;&#20204;&#20197;"&#36807;&#28388;&#27668;&#27873;"&#30340;&#24120;&#35265;&#38382;&#39064;&#26469;&#23637;&#31034;&#36825;&#19968;&#29616;&#35937;&#65292;&#24182;&#23545;&#20219;&#20309;&#24179;&#21488;&#37117;&#23384;&#22312;&#30340;&#31867;&#20284;&#38382;&#39064;&#36827;&#34892;&#20102;&#31867;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Peer production platforms like Wikipedia commonly suffer from content gaps. Prior research suggests recommender systems can help solve this problem, by guiding editors towards underrepresented topics. However, it remains unclear whether this approach would result in less relevant recommendations, leading to reduced overall engagement with recommended items. To answer this question, we first conducted offline analyses (Study 1) on SuggestBot, a task-routing recommender system for Wikipedia, then did a three-month controlled experiment (Study 2). Our results show that presenting users with articles from underrepresented topics increased the proportion of work done on those articles without significantly reducing overall recommendation uptake. We discuss the implications of our results, including how ignoring the article discovery process can artificially narrow recommendations. We draw parallels between this phenomenon and the common issue of "filter bubbles" to show how any platform tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;RKGCN&#65292;&#23427;&#33021;&#22815;&#21160;&#24577;&#20998;&#26512;&#29992;&#25143;&#30340;&#20559;&#22909;&#24182;&#25512;&#33616;&#20986;&#21512;&#36866;&#30340;&#29289;&#21697;&#12290;&#35813;&#27169;&#22411;&#22312;&#21253;&#25324;&#30005;&#24433;&#12289;&#20070;&#31821;&#21644;&#38899;&#20048;&#22312;&#20869;&#30340;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#27604;5&#20010;&#22522;&#20934;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.01147</link><description>&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Ripple Knowledge Graph Convolutional Networks For Recommendation Systems. (arXiv:2305.01147v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01147
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;RKGCN&#65292;&#23427;&#33021;&#22815;&#21160;&#24577;&#20998;&#26512;&#29992;&#25143;&#30340;&#20559;&#22909;&#24182;&#25512;&#33616;&#20986;&#21512;&#36866;&#30340;&#29289;&#21697;&#12290;&#35813;&#27169;&#22411;&#22312;&#21253;&#25324;&#30005;&#24433;&#12289;&#20070;&#31821;&#21644;&#38899;&#20048;&#22312;&#20869;&#30340;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#27604;5&#20010;&#22522;&#20934;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#24050;&#32463;&#35777;&#26126;&#65292;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#26469;&#36741;&#21161;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#25512;&#33616;&#20915;&#31574;&#33021;&#26377;&#25928;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21629;&#21517;&#20026;RKGCN&#65292;&#23427;&#21160;&#24577;&#20998;&#26512;&#27599;&#20010;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#24182;&#25512;&#33616;&#20986;&#21512;&#36866;&#30340;&#29289;&#21697;&#12290;&#23427;&#22312;&#29289;&#21697;&#21644;&#29992;&#25143;&#21452;&#26041;&#38754;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#26469;&#20016;&#23500;&#23427;&#20204;&#30340;&#34920;&#31034;&#65292;&#26368;&#22823;&#21270;&#30693;&#35782;&#22270;&#35889;&#20013;&#20016;&#23500;&#30340;&#20449;&#24687;&#30340;&#21033;&#29992;&#12290; RKGCN&#33021;&#22815;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#22330;&#26223;&#19979;&#25552;&#20379;&#26356;&#20010;&#24615;&#21270;&#21644;&#30456;&#20851;&#30340;&#25512;&#33616;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21253;&#25324;&#30005;&#24433;&#12289;&#20070;&#31821;&#21644;&#38899;&#20048;&#22312;&#20869;&#30340;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#27604;5&#20010;&#22522;&#20934;&#27169;&#22411;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Using knowledge graphs to assist deep learning models in making recommendation decisions has recently been proven to effectively improve the model's interpretability and accuracy. This paper introduces an end-to-end deep learning model, named RKGCN, which dynamically analyses each user's preferences and makes a recommendation of suitable items. It combines knowledge graphs on both the item side and user side to enrich their representations to maximize the utilization of the abundant information in knowledge graphs. RKGCN is able to offer more personalized and relevant recommendations in three different scenarios. The experimental results show the superior effectiveness of our model over 5 baseline models on three real-world datasets including movies, books, and music.
&lt;/p&gt;</description></item></channel></rss>