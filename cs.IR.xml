<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#38477;&#20302;&#20102;&#25163;&#21160;&#21019;&#24314;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;</title><link>https://arxiv.org/abs/2403.17209</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;&#36164;&#20135;&#31649;&#29702;&#22806;&#22771;&#65306;&#25968;&#23383;&#23402;&#29983;&#21644;&#35821;&#20041;&#33410;&#28857;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;
&lt;/p&gt;
&lt;p&gt;
Generation of Asset Administration Shell with Large Language Model Agents: Interoperability in Digital Twins with Semantic Node
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17209
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#38477;&#20302;&#20102;&#25163;&#21160;&#21019;&#24314;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21327;&#21161;&#22312;&#24037;&#19994;4.0&#32972;&#26223;&#19979;&#20026;&#25968;&#23383;&#23402;&#29983;&#24314;&#27169;&#21019;&#24314;&#36164;&#20135;&#31649;&#29702;&#22806;&#22771;&#65288;AAS&#65289;&#23454;&#20363;&#65292;&#26088;&#22312;&#22686;&#24378;&#26234;&#33021;&#21046;&#36896;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#20943;&#23569;&#25163;&#21160;&#24037;&#20316;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#8220;&#35821;&#20041;&#33410;&#28857;&#8221;&#25968;&#25454;&#32467;&#26500;&#26469;&#25429;&#25417;&#25991;&#26412;&#25968;&#25454;&#30340;&#35821;&#20041;&#35201;&#20041;&#12290;&#28982;&#21518;&#65292;&#35774;&#35745;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#31995;&#32479;&#65292;&#29992;&#20110;&#22788;&#29702;&#8220;&#35821;&#20041;&#33410;&#28857;&#8221;&#24182;&#20174;&#25991;&#26412;&#25216;&#26415;&#25968;&#25454;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#26377;&#25928;&#29983;&#25104;&#29575;&#20026;62-79%&#65292;&#34920;&#26126;&#30456;&#24403;&#27604;&#20363;&#30340;&#25163;&#21160;&#21019;&#24314;&#24037;&#20316;&#21487;&#20197;&#36716;&#25442;&#20026;&#26356;&#23481;&#26131;&#30340;&#39564;&#35777;&#24037;&#20316;&#65292;&#20174;&#32780;&#20943;&#23569;&#21019;&#24314;AAS&#23454;&#20363;&#27169;&#22411;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#12290;&#22312;&#25105;&#20204;&#30340;&#35780;&#20272;&#20013;&#65292;&#23545;&#19981;&#21516;LLM&#30340;&#27604;&#36739;&#20998;&#26512;&#20197;&#21450;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#26426;&#21046;&#30340;&#28145;&#20837;&#28040;&#34701;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#20851;LLM&#26377;&#25928;&#24615;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17209v1 Announce Type: new  Abstract: This research introduces a novel approach for assisting the creation of Asset Administration Shell (AAS) instances for digital twin modeling within the context of Industry 4.0, aiming to enhance interoperability in smart manufacturing and reduce manual effort. We construct a "semantic node" data structure to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process "semantic node" and generate AAS instance models from textual technical data. Our evaluation demonstrates a 62-79% effective generation rate, indicating a substantial proportion of manual creation effort can be converted into easier validation effort, thereby reducing the time and cost in creating AAS instance models. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM
&lt;/p&gt;</description></item><item><title>MACRec&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#22810;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#24182;&#25552;&#20379;&#20102;&#24212;&#29992;&#31034;&#20363;&#12290;</title><link>https://arxiv.org/abs/2402.15235</link><description>&lt;p&gt;
&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Collaboration Framework for Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15235
&lt;/p&gt;
&lt;p&gt;
MACRec&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#22810;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#24182;&#25552;&#20379;&#20102;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#20307;&#22240;&#20854;&#20915;&#31574;&#25216;&#33021;&#21644;&#22788;&#29702;&#22797;&#26434;&#20219;&#21153;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#37492;&#20110;&#24403;&#21069;&#22312;&#21033;&#29992;&#26234;&#33021;&#20307;&#21327;&#20316;&#33021;&#21147;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#26041;&#38754;&#23384;&#22312;&#30340;&#31354;&#30333;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;MACRec&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#39062;&#26694;&#26550;&#12290;&#19982;&#29616;&#26377;&#20851;&#20110;&#20351;&#29992;&#26234;&#33021;&#20307;&#36827;&#34892;&#29992;&#25143;/&#21830;&#21697;&#27169;&#25311;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#26088;&#22312;&#37096;&#32626;&#22810;&#26234;&#33021;&#20307;&#30452;&#25509;&#22788;&#29702;&#25512;&#33616;&#20219;&#21153;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#36890;&#36807;&#21508;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#26469;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#21253;&#25324;&#32463;&#29702;&#12289;&#29992;&#25143;/&#21830;&#21697;&#20998;&#26512;&#24072;&#12289;&#21453;&#23556;&#22120;&#12289;&#25628;&#32034;&#22120;&#21644;&#20219;&#21153;&#35299;&#37322;&#22120;&#65292;&#23427;&#20204;&#20855;&#26377;&#19981;&#21516;&#30340;&#24037;&#20316;&#27969;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#24212;&#29992;&#31034;&#20363;&#65292;&#35828;&#26126;&#24320;&#21457;&#20154;&#21592;&#22914;&#20309;&#36731;&#26494;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#19978;&#20351;&#29992;MACRec&#65292;&#21253;&#25324;&#35780;&#20998;&#39044;&#27979;&#12289;&#24207;&#21015;&#25512;&#33616;&#12289;&#23545;&#35805;&#25512;&#33616;&#21644;&#35299;&#37322;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15235v1 Announce Type: new  Abstract: LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks. Recognizing the current gap in leveraging agent capabilities for multi-agent collaboration in recommendation systems, we introduce MACRec, a novel framework designed to enhance recommendation systems through multi-agent collaboration. Unlike existing work on using agents for user/item simulation, we aim to deploy multi-agents to tackle recommendation tasks directly. In our framework, recommendation tasks are addressed through the collaborative efforts of various specialized agents, including Manager, User/Item Analyst, Reflector, Searcher, and Task Interpreter, with different working flows. Furthermore, we provide application examples of how developers can easily use MACRec on various recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation, and explanation generation
&lt;/p&gt;</description></item><item><title>&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#21040;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#36716;&#21464;&#12290;&#36825;&#31687;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25512;&#33616;&#25968;&#25454;&#30340;&#20027;&#35201;&#38382;&#39064;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2401.17878</link><description>&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Data-Centric Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17878
&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#32508;&#36848;&#20102;&#25512;&#33616;&#31995;&#32479;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#21040;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#36716;&#21464;&#12290;&#36825;&#31687;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25512;&#33616;&#25968;&#25454;&#30340;&#20027;&#35201;&#38382;&#39064;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#24212;&#23545;&#20449;&#24687;&#36807;&#36733;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#23454;&#38469;&#22330;&#26223;&#12290;&#26368;&#36817;&#25512;&#33616;&#31995;&#32479;&#30340;&#21457;&#23637;&#36235;&#21183;&#20986;&#29616;&#20102;&#33539;&#24335;&#36716;&#21464;&#65292;&#20174;&#27169;&#22411;&#20026;&#20013;&#24515;&#30340;&#21019;&#26032;&#36716;&#21521;&#25968;&#25454;&#36136;&#37327;&#21644;&#25968;&#37327;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#19968;&#21464;&#21270;&#24341;&#20986;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#65288;Data-Centric RS&#65289;&#30340;&#27010;&#24565;&#65292;&#26631;&#24535;&#30528;&#35813;&#39046;&#22495;&#30340;&#37325;&#35201;&#21457;&#23637;&#12290;&#26412;&#32508;&#36848;&#39318;&#27425;&#31995;&#32479;&#22320;&#27010;&#36848;&#20102;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#65292;&#21253;&#25324;1&#65289;&#25512;&#33616;&#25968;&#25454;&#21644;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#30340;&#22522;&#26412;&#27010;&#24565;&#65307;2&#65289;&#25512;&#33616;&#25968;&#25454;&#38754;&#20020;&#30340;&#19977;&#20010;&#20027;&#35201;&#38382;&#39064;&#65307;3&#65289;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#32780;&#24320;&#23637;&#30340;&#26368;&#36817;&#30740;&#31350;&#65307;&#20197;&#21450;4&#65289;&#25968;&#25454;&#20013;&#24515;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#30340;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems (RS) have become essential tools for mitigating information overload in a range of real-world scenarios. Recent trends in RS have seen a paradigm shift, moving the spotlight from model-centric innovations to the importance of data quality and quantity. This evolution has given rise to the concept of data-centric recommender systems (Data-Centric RS), marking a significant development in the field. This survey provides the first systematic overview of Data-Centric RS, covering 1) the foundational concepts of recommendation data and Data-Centric RS; 2) three primary issues in recommendation data; 3) recent research developed to address these issues; and 4) several potential future directions in Data-Centric RS.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21382;&#21490;&#24863;&#30693;&#30340;&#23545;&#35805;&#24335;&#31264;&#23494;&#26816;&#32034;&#31995;&#32479;&#65292;&#36890;&#36807;&#19978;&#19979;&#25991;&#21435;&#22122;&#30340;&#26597;&#35810;&#37325;&#26500;&#20197;&#21450;&#26681;&#25454;&#21382;&#21490;&#36718;&#27425;&#30340;&#23454;&#38469;&#24433;&#21709;&#33258;&#21160;&#25366;&#25496;&#30417;&#30563;&#20449;&#21495;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#23545;&#35805;&#24335;&#31264;&#23494;&#26816;&#32034;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.16659</link><description>&lt;p&gt;
&#21382;&#21490;&#24863;&#30693;&#30340;&#23545;&#35805;&#24335;&#31264;&#23494;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
History-Aware Conversational Dense Retrieval. (arXiv:2401.16659v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16659
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21382;&#21490;&#24863;&#30693;&#30340;&#23545;&#35805;&#24335;&#31264;&#23494;&#26816;&#32034;&#31995;&#32479;&#65292;&#36890;&#36807;&#19978;&#19979;&#25991;&#21435;&#22122;&#30340;&#26597;&#35810;&#37325;&#26500;&#20197;&#21450;&#26681;&#25454;&#21382;&#21490;&#36718;&#27425;&#30340;&#23454;&#38469;&#24433;&#21709;&#33258;&#21160;&#25366;&#25496;&#30417;&#30563;&#20449;&#21495;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#23545;&#35805;&#24335;&#31264;&#23494;&#26816;&#32034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#25628;&#32034;&#36890;&#36807;&#23454;&#29616;&#29992;&#25143;&#21644;&#31995;&#32479;&#20043;&#38388;&#30340;&#22810;&#36718;&#20132;&#20114;&#65292;&#23454;&#29616;&#20102;&#22797;&#26434;&#20449;&#24687;&#26816;&#32034;&#30340;&#20415;&#21033;&#12290;&#25903;&#25345;&#36825;&#31181;&#20132;&#20114;&#38656;&#35201;&#23545;&#23545;&#35805;&#36755;&#20837;&#26377;&#20840;&#38754;&#30340;&#29702;&#35299;&#65292;&#20197;&#20415;&#26681;&#25454;&#21382;&#21490;&#20449;&#24687;&#21046;&#23450;&#33391;&#22909;&#30340;&#25628;&#32034;&#26597;&#35810;&#12290;&#29305;&#21035;&#26159;&#65292;&#25628;&#32034;&#26597;&#35810;&#24212;&#21253;&#25324;&#26469;&#33258;&#20808;&#21069;&#23545;&#35805;&#22238;&#21512;&#30340;&#30456;&#20851;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#23545;&#35805;&#24335;&#31264;&#23494;&#26816;&#32034;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#23545;&#32463;&#36807;&#31934;&#35843;&#30340;&#39044;&#35757;&#32451;&#19987;&#38376;&#26816;&#32034;&#22120;&#36827;&#34892;&#25972;&#20010;&#23545;&#35805;&#24335;&#25628;&#32034;&#20250;&#35805;&#30340;&#20248;&#21270;&#65292;&#36825;&#21487;&#33021;&#20250;&#21464;&#24471;&#20887;&#38271;&#21644;&#22024;&#26434;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#26041;&#27861;&#21463;&#29616;&#26377;&#25968;&#25454;&#38598;&#20013;&#25163;&#21160;&#30417;&#30563;&#20449;&#21495;&#25968;&#37327;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21382;&#21490;&#24863;&#30693;&#30340;&#23545;&#35805;&#24335;&#31264;&#23494;&#26816;&#32034;(HAConvDR)&#31995;&#32479;&#65292;&#23427;&#32467;&#21512;&#20102;&#20004;&#20010;&#24605;&#24819;&#65306;&#19978;&#19979;&#25991;&#21435;&#22122;&#30340;&#26597;&#35810;&#37325;&#26500;&#21644;&#26681;&#25454;&#21382;&#21490;&#36718;&#27425;&#30340;&#23454;&#38469;&#24433;&#21709;&#36827;&#34892;&#33258;&#21160;&#25366;&#25496;&#30417;&#30563;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational search facilitates complex information retrieval by enabling multi-turn interactions between users and the system. Supporting such interactions requires a comprehensive understanding of the conversational inputs to formulate a good search query based on historical information. In particular, the search query should include the relevant information from the previous conversation turns. However, current approaches for conversational dense retrieval primarily rely on fine-tuning a pre-trained ad-hoc retriever using the whole conversational search session, which can be lengthy and noisy. Moreover, existing approaches are limited by the amount of manual supervision signals in the existing datasets. To address the aforementioned issues, we propose a History-Aware Conversational Dense Retrieval (HAConvDR) system, which incorporates two ideas: context-denoised query reformulation and automatic mining of supervision signals based on the actual impact of historical turns. Experime
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#25351;&#20196;&#35843;&#20248;&#30340;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;INTERS&#65292;&#28085;&#30422;&#20102;21&#20010;IR&#20219;&#21153;&#65292;&#35813;&#26041;&#27861;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.06532</link><description>&lt;p&gt;
INTERS: &#20351;&#29992;&#25351;&#20196;&#35843;&#20248;&#35299;&#38145;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25628;&#32034;&#20013;&#30340;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning. (arXiv:2401.06532v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#25351;&#20196;&#35843;&#20248;&#30340;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;INTERS&#65292;&#28085;&#30422;&#20102;21&#20010;IR&#20219;&#21153;&#65292;&#35813;&#26041;&#27861;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35768;&#22810;&#19982;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#20855;&#20307;&#27010;&#24565;&#30340;&#19981;&#32463;&#24120;&#20986;&#29616;&#22312;&#33258;&#28982;&#35821;&#35328;&#20013;&#65292;&#23427;&#20204;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#21487;&#20197;&#21521;LLMs&#25552;&#20379;&#20219;&#21153;&#25551;&#36848;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#22312;&#20419;&#36827;&#20840;&#38754;&#29702;&#35299;&#21644;&#25191;&#34892;IR&#20219;&#21153;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;LLMs&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#25351;&#20196;&#35843;&#20248;&#30340;&#28508;&#21147;&#65292;&#20197;&#25552;&#39640;LLMs&#22312;IR&#20219;&#21153;&#20013;&#30340;&#29087;&#32451;&#31243;&#24230;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25351;&#20196;&#35843;&#20248;&#25968;&#25454;&#38598;INTERS&#65292;&#28085;&#30422;&#20102;3&#20010;&#22522;&#26412;IR&#31867;&#21035;&#20013;&#30340;21&#20010;&#20219;&#21153;&#65306;&#26597;&#35810;&#29702;&#35299;&#12289;&#25991;&#26723;&#29702;&#35299;&#21644;&#26597;&#35810;&#25991;&#26723;&#20851;&#31995;&#29702;&#35299;&#12290;&#25968;&#25454;&#26469;&#33258;43&#20010;&#19981;&#21516;&#30340;&#30001;&#25163;&#21160;&#32534;&#20889;&#30340;&#27169;&#26495;&#26500;&#25104;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;INTERS&#26174;&#33879;&#25552;&#21319;&#20102;&#21508;&#31181;&#20844;&#24320;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks. Despite this, their application to information retrieval (IR) tasks is still challenging due to the infrequent occurrence of many IR-specific concepts in natural language. While prompt-based methods can provide task descriptions to LLMs, they often fall short in facilitating comprehensive understanding and execution of IR tasks, thereby limiting LLMs' applicability. To address this gap, in this work, we explore the potential of instruction tuning to enhance LLMs' proficiency in IR tasks. We introduce a novel instruction tuning dataset, INTERS, encompassing 21 tasks across three fundamental IR categories: query understanding, document understanding, and query-document relationship understanding. The data are derived from 43 distinct datasets with manually written templates. Our empirical results reveal that INTERS significantly boosts the performance of various publicly a
&lt;/p&gt;</description></item><item><title>CausalCite&#26159;&#19968;&#31181;&#20197;&#22240;&#26524;&#25512;&#26029;&#20026;&#22522;&#30784;&#30340;&#35770;&#25991;&#24341;&#29992;&#20844;&#24335;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25991;&#26412;&#36827;&#34892;&#23884;&#20837;&#21644;&#30456;&#20284;&#26679;&#26412;&#30340;&#25552;&#21462;&#26469;&#35780;&#20272;&#35770;&#25991;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#21508;&#20010;&#26631;&#20934;&#19978;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.02790</link><description>&lt;p&gt;
CausalCite&#65306;&#19968;&#31181;&#35770;&#25991;&#24341;&#29992;&#30340;&#22240;&#26524;&#20844;&#24335;&#21270;
&lt;/p&gt;
&lt;p&gt;
CausalCite: A Causal Formulation of Paper Citations. (arXiv:2311.02790v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02790
&lt;/p&gt;
&lt;p&gt;
CausalCite&#26159;&#19968;&#31181;&#20197;&#22240;&#26524;&#25512;&#26029;&#20026;&#22522;&#30784;&#30340;&#35770;&#25991;&#24341;&#29992;&#20844;&#24335;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25991;&#26412;&#36827;&#34892;&#23884;&#20837;&#21644;&#30456;&#20284;&#26679;&#26412;&#30340;&#25552;&#21462;&#26469;&#35780;&#20272;&#35770;&#25991;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#21508;&#20010;&#26631;&#20934;&#19978;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#31185;&#23398;&#30028;&#26469;&#35828;&#65292;&#35780;&#20272;&#19968;&#31687;&#35770;&#25991;&#30340;&#37325;&#35201;&#24615;&#33267;&#20851;&#37325;&#35201;&#20294;&#20063;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#23613;&#31649;&#24341;&#29992;&#27425;&#25968;&#26159;&#26368;&#24120;&#29992;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#20294;&#23427;&#20204;&#34987;&#24191;&#27867;&#25209;&#35780;&#20026;&#26080;&#27861;&#20934;&#30830;&#21453;&#26144;&#19968;&#31687;&#35770;&#25991;&#30340;&#30495;&#27491;&#24433;&#21709;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#31216;&#20026;TextMatch&#65292;&#23427;&#23558;&#20256;&#32479;&#30340;&#21305;&#37197;&#26694;&#26550;&#36866;&#24212;&#20110;&#39640;&#32500;&#25991;&#26412;&#23884;&#20837;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23545;&#27599;&#31687;&#35770;&#25991;&#36827;&#34892;&#25991;&#26412;&#23884;&#20837;&#65292;&#36890;&#36807;&#20313;&#24358;&#30456;&#20284;&#24615;&#25552;&#21462;&#30456;&#20284;&#26679;&#26412;&#65292;&#24182;&#26681;&#25454;&#30456;&#20284;&#24230;&#20540;&#30340;&#21152;&#26435;&#24179;&#22343;&#21512;&#25104;&#19968;&#20010;&#21453;&#20107;&#23454;&#26679;&#26412;&#12290;&#25105;&#20204;&#23558;&#24471;&#21040;&#30340;&#25351;&#26631;&#31216;&#20026;CausalCite&#65292;&#20316;&#20026;&#35770;&#25991;&#24341;&#29992;&#30340;&#22240;&#26524;&#20844;&#24335;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#21508;&#31181;&#26631;&#20934;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#22914;&#19982;&#31185;&#23398;&#19987;&#23478;&#23545;1K&#31687;&#35770;&#25991;&#30340;&#25253;&#21578;&#30340;&#35770;&#25991;&#24433;&#21709;&#21147;&#30340;&#39640;&#30456;&#20851;&#24615;&#65292;&#36807;&#21435;&#35770;&#25991;&#30340;&#65288;&#32463;&#36807;&#26102;&#38388;&#32771;&#39564;&#30340;&#65289;&#22870;&#39033;&#65292;&#20197;&#21450;&#22312;&#21508;&#20010;&#23376;&#39046;&#22495;&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating the significance of a paper is pivotal yet challenging for the scientific community. While the citation count is the most commonly used proxy for this purpose, they are widely criticized for failing to accurately reflect a paper's true impact. In this work, we propose a causal inference method, TextMatch, which adapts the traditional matching framework to high-dimensional text embeddings. Specifically, we encode each paper using the text embeddings by large language models (LLMs), extract similar samples by cosine similarity, and synthesize a counterfactual sample by the weighted average of similar papers according to their similarity values. We apply the resulting metric, called CausalCite, as a causal formulation of paper citations. We show its effectiveness on various criteria, such as high correlation with paper impact as reported by scientific experts on a previous dataset of 1K papers, (test-of-time) awards for past papers, and its stability across various sub-fields o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#37325;&#25490;&#22120;&#25552;&#20379;&#25512;&#29702;&#26102;&#38388;&#21453;&#39304;&#26469;&#25913;&#36827;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20302;&#21484;&#22238;&#29575;@ K&#19979;&#30340;&#26816;&#32034;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.11744</link><description>&lt;p&gt;
&#38754;&#21521;&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#30340;&#25512;&#29702;&#26102;&#38388;&#37325;&#25490;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Inference-time Re-ranker Relevance Feedback for Neural Information Retrieval. (arXiv:2305.11744v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11744
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#37325;&#25490;&#22120;&#25552;&#20379;&#25512;&#29702;&#26102;&#38388;&#21453;&#39304;&#26469;&#25913;&#36827;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20302;&#21484;&#22238;&#29575;@ K&#19979;&#30340;&#26816;&#32034;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20449;&#24687;&#26816;&#32034;&#36890;&#24120;&#37319;&#29992;&#26816;&#32034;&#21644;&#37325;&#25490;&#26694;&#26550;&#65306;&#20808;&#20351;&#29992;&#21452;&#32534;&#30721;&#22120;&#32593;&#32476;&#26816;&#32034;K&#65288;&#20363;&#22914;100&#65289;&#20010;&#20505;&#36873;&#39033;&#65292;&#28982;&#21518;&#20877;&#20351;&#29992;&#26356;&#24378;&#22823;&#30340;&#20132;&#21449;&#32534;&#30721;&#22120;&#27169;&#22411;&#23545;&#36825;&#20123;&#20505;&#36873;&#39033;&#36827;&#34892;&#37325;&#26032;&#25490;&#24207;&#65292;&#20197;&#20351;&#26356;&#22909;&#30340;&#20505;&#36873;&#39033;&#25490;&#21517;&#26356;&#39640;&#12290;&#37325;&#25490;&#22120;&#36890;&#24120;&#20135;&#29983;&#27604;&#26816;&#32034;&#22120;&#26356;&#22909;&#30340;&#20505;&#36873;&#20998;&#25968;&#65292;&#20294;&#20165;&#38480;&#20110;&#26597;&#30475;&#21069;K&#20010;&#26816;&#32034;&#21040;&#30340;&#20505;&#36873;&#39033;&#65292;&#22240;&#27492;&#26080;&#27861;&#25552;&#39640;&#26816;&#32034;&#24615;&#33021;&#65288;&#20197;Recall @ K&#20026;&#24230;&#37327;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#37325;&#25490;&#22120;&#36890;&#36807;&#25552;&#20379;&#25512;&#29702;&#26102;&#38388;&#30456;&#20851;&#21453;&#39304;&#26469;&#25913;&#36827;&#26816;&#32034;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;&#37325;&#25490;&#22120;&#30340;&#39044;&#27979;&#23545;&#27979;&#35797;&#23454;&#20363;&#30340;&#37325;&#35201;&#20449;&#24687;&#36827;&#34892;&#20102;&#26816;&#32034;&#22120;&#26597;&#35810;&#34920;&#31034;&#30340;&#26356;&#26032;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#36731;&#37327;&#32423;&#30340;&#25512;&#29702;&#26102;&#38388;&#33976;&#39311;&#26469;&#23454;&#29616;&#65292;&#30446;&#30340;&#26159;&#20351;&#26816;&#32034;&#22120;&#30340;&#20505;&#36873;&#20998;&#25968;&#26356;&#25509;&#36817;&#20110;&#37325;&#25490;&#22120;&#30340;&#20998;&#25968;&#12290;&#28982;&#21518;&#20351;&#29992;&#26356;&#26032;&#21518;&#30340;&#26597;&#35810;&#21521;&#37327;&#25191;&#34892;&#31532;&#20108;&#20010;&#26816;&#32034;&#27493;&#39588;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#26816;&#32034;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#20302;&#21484;&#22238;&#29575;@ K&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural information retrieval often adopts a retrieve-and-rerank framework: a bi-encoder network first retrieves K (e.g., 100) candidates that are then re-ranked using a more powerful cross-encoder model to rank the better candidates higher. The re-ranker generally produces better candidate scores than the retriever, but is limited to seeing only the top K retrieved candidates, thus providing no improvements in retrieval performance as measured by Recall@K. In this work, we leverage the re-ranker to also improve retrieval by providing inference-time relevance feedback to the retriever. Concretely, we update the retriever's query representation for a test instance using a lightweight inference-time distillation of the re-ranker's prediction for that instance. The distillation loss is designed to bring the retriever's candidate scores closer to those of the re-ranker. A second retrieval step is then performed with the updated query vector. We empirically show that our approach, which can 
&lt;/p&gt;</description></item></channel></rss>