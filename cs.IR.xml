<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#24863;&#30693;&#30340;&#22522;&#20110;&#39033;&#30446;&#30340;&#21152;&#26435;&#26041;&#27861;(TAIW)&#65292;&#36890;&#36807;&#32771;&#34385;&#26102;&#38388;&#25139;&#21644;&#26102;&#38388;&#38388;&#38548;&#26469;&#35299;&#20915;&#19979;&#19968;&#20010;&#36141;&#29289;&#31726;&#25512;&#33616;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.16297</link><description>&lt;p&gt;
&#19979;&#19968;&#20010;&#36141;&#29289;&#31726;&#25512;&#33616;&#30340;&#26102;&#38388;&#24863;&#30693;&#39033;&#30446;&#21152;&#26435;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Time-Aware Item Weighting for the Next Basket Recommendations. (arXiv:2307.16297v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16297
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#24863;&#30693;&#30340;&#22522;&#20110;&#39033;&#30446;&#30340;&#21152;&#26435;&#26041;&#27861;(TAIW)&#65292;&#36890;&#36807;&#32771;&#34385;&#26102;&#38388;&#25139;&#21644;&#26102;&#38388;&#38388;&#38548;&#26469;&#35299;&#20915;&#19979;&#19968;&#20010;&#36141;&#29289;&#31726;&#25512;&#33616;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19979;&#19968;&#20010;&#36141;&#29289;&#31726;&#25512;&#33616;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#20351;&#29992;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20854;&#20013;&#35768;&#22810;&#26041;&#27861;&#27809;&#26377;&#20351;&#29992;&#20851;&#20110;&#39044;&#27979;&#26102;&#38388;&#21644;&#36141;&#29289;&#31726;&#26102;&#38388;&#38388;&#38548;&#30340;&#20449;&#24687;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;&#26102;&#38388;&#24863;&#30693;&#30340;&#22522;&#20110;&#39033;&#30446;&#30340;&#21152;&#26435;&#26041;&#27861;(TAIW)&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#26102;&#38388;&#25139;&#21644;&#26102;&#38388;&#38388;&#38548;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#21457;&#29616;TAIW&#22312;&#19979;&#19968;&#20010;&#36141;&#29289;&#31726;&#25512;&#33616;&#26041;&#38754;&#20248;&#20110;&#32463;&#36807;&#31934;&#24515;&#35843;&#25972;&#30340;&#26368;&#20808;&#36827;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#28040;&#34701;&#30740;&#31350;&#21644;&#19968;&#20123;&#39033;&#30446;&#30340;&#26696;&#20363;&#30740;&#31350;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we study the next basket recommendation problem. Recent methods use different approaches to achieve better performance. However, many of them do not use information about the time of prediction and time intervals between baskets. To fill this gap, we propose a novel method, Time-Aware Item-based Weighting (TAIW), which takes timestamps and intervals into account. We provide experiments on three real-world datasets, and TAIW outperforms well-tuned state-of-the-art baselines for next-basket recommendations. In addition, we show the results of an ablation study and a case study of a few items.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#23478;&#26063;&#35889;&#38382;&#31572;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#23478;&#26063;&#35889;&#25968;&#25454;&#34920;&#31034;&#20026;&#30693;&#35782;&#22270;&#24182;&#19982;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#32467;&#21512;&#65292;&#20351;&#29992;Transformer&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#23478;&#26063;&#35889;&#39046;&#22495;&#20013;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#22270;&#32467;&#26500;&#21644;&#32570;&#20047;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.16214</link><description>&lt;p&gt;
&#29992;&#20110;&#21322;&#32467;&#26500;&#24322;&#26500;&#23478;&#26063;&#35889;&#30693;&#35782;&#22270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
Question Answering with Deep Neural Networks for Semi-Structured Heterogeneous Genealogical Knowledge Graphs. (arXiv:2307.16214v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#23478;&#26063;&#35889;&#38382;&#31572;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#23478;&#26063;&#35889;&#25968;&#25454;&#34920;&#31034;&#20026;&#30693;&#35782;&#22270;&#24182;&#19982;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#32467;&#21512;&#65292;&#20351;&#29992;Transformer&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#23478;&#26063;&#35889;&#39046;&#22495;&#20013;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#22270;&#32467;&#26500;&#21644;&#32570;&#20047;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29992;&#25143;&#29983;&#25104;&#30340;&#23478;&#26063;&#35889;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#26032;&#30340;&#23478;&#26063;&#35889;&#20449;&#24687;&#31995;&#32479;&#24471;&#21040;&#20102;&#24320;&#21457;&#12290;&#26368;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#38382;&#31572;&#31639;&#27861;&#20351;&#29992;&#22522;&#20110;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;&#20854;&#20013;&#19968;&#20123;&#27169;&#22411;&#20351;&#29992;&#22522;&#20110;&#24207;&#21015;&#30340;&#36755;&#20837;&#65292;&#19981;&#36866;&#21512;&#22788;&#29702;&#22522;&#20110;&#22270;&#30340;&#32467;&#26500;&#65292;&#32780;&#22522;&#20110;&#22270;&#30340;DNN&#27169;&#22411;&#21017;&#20381;&#36182;&#20110;&#22312;&#23478;&#26063;&#35889;&#39046;&#22495;&#20013;&#19981;&#23384;&#22312;&#30340;&#39640;&#24230;&#20840;&#38754;&#30340;&#30693;&#35782;&#22270;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26377;&#30417;&#30563;&#30340;DNN&#27169;&#22411;&#38656;&#35201;&#22312;&#23478;&#26063;&#35889;&#39046;&#22495;&#20013;&#32570;&#20047;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23478;&#26063;&#35889;&#38382;&#31572;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#65306;1&#65289;&#23558;&#23478;&#26063;&#35889;&#25968;&#25454;&#34920;&#31034;&#20026;&#30693;&#35782;&#22270;&#65292;2&#65289;&#23558;&#20854;&#36716;&#25442;&#20026;&#25991;&#26412;&#65292;3&#65289;&#19982;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#32467;&#21512;&#65292;4&#65289;&#35757;&#32451;&#22522;&#20110;Transformer&#30340;&#38382;&#31572;&#27169;&#22411;&#12290;&#20026;&#20102;&#35780;&#20272;&#38656;&#35201;&#19987;&#38376;&#26041;&#27861;&#30340;&#24517;&#35201;&#24615;&#65292;&#23545;&#27604;&#20102;&#24494;&#35843;&#27169;&#24335;&#19979;&#30340;&#27169;&#22411;&#19982;&#20351;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rising popularity of user-generated genealogical family trees, new genealogical information systems have been developed. State-of-the-art natural question answering algorithms use deep neural network (DNN) architecture based on self-attention networks. However, some of these models use sequence-based inputs and are not suitable to work with graph-based structure, while graph-based DNN models rely on high levels of comprehensiveness of knowledge graphs that is nonexistent in the genealogical domain. Moreover, these supervised DNN models require training datasets that are absent in the genealogical domain. This study proposes an end-to-end approach for question answering using genealogical family trees by: 1) representing genealogical data as knowledge graphs, 2) converting them to texts, 3) combining them with unstructured texts, and 4) training a trans-former-based question answering model. To evaluate the need for a dedicated approach, a comparison between the fine-tuned mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#24322;&#26500;&#23478;&#35889;&#30693;&#35782;&#22270;&#35889;&#19978;&#36827;&#34892;&#25968;&#23383;&#32858;&#21512;&#38382;&#31572;&#30340;&#26041;&#27861;&#65292;&#22312;&#22522;&#22240;&#35889;&#39046;&#22495;&#25552;&#20986;&#20102;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#24182;&#33719;&#24471;&#20934;&#30830;&#31572;&#26696;&#30340;&#33021;&#21147;&#36824;&#26410;&#34987;&#20805;&#20998;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.16208</link><description>&lt;p&gt;
&#22312;&#24322;&#26500;&#23478;&#35889;&#30693;&#35782;&#22270;&#35889;&#19978;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25968;&#23383;&#32858;&#21512;&#38382;&#31572;&#30340;GLOBE&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Around the GLOBE: Numerical Aggregation Question-Answering on Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks. (arXiv:2307.16208v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#24322;&#26500;&#23478;&#35889;&#30693;&#35782;&#22270;&#35889;&#19978;&#36827;&#34892;&#25968;&#23383;&#32858;&#21512;&#38382;&#31572;&#30340;&#26041;&#27861;&#65292;&#22312;&#22522;&#22240;&#35889;&#39046;&#22495;&#25552;&#20986;&#20102;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#24182;&#33719;&#24471;&#20934;&#30830;&#31572;&#26696;&#30340;&#33021;&#21147;&#36824;&#26410;&#34987;&#20805;&#20998;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#31456;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#24322;&#26500;&#23478;&#35889;&#30693;&#35782;&#22270;&#35889;&#19978;&#36827;&#34892;&#25968;&#23383;&#32858;&#21512;&#38382;&#31572;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#19982;&#31934;&#30830;&#31572;&#26696;&#20043;&#38388;&#30340;&#36716;&#25442;&#12290;&#30446;&#21069;&#65292;&#22312;&#22522;&#22240;&#35889;&#39046;&#22495;&#65292;&#25552;&#20986;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#24182;&#33719;&#24471;&#20934;&#30830;&#31572;&#26696;&#30340;&#33021;&#21147;&#36824;&#26410;&#34987;&#20805;&#20998;&#30740;&#31350;&#65292;&#32780;&#30740;&#31350;&#32773;&#22312;&#20154;&#25991;&#21644;&#31038;&#20250;&#31185;&#23398;&#31561;&#39046;&#22495;&#21487;&#20197;&#20174;&#36825;&#31181;&#33021;&#21147;&#20013;&#21463;&#30410;&#21290;&#27973;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the key AI tools for textual corpora exploration is natural language question-answering (QA). Unlike keyword-based search engines, QA algorithms receive and process natural language questions and produce precise answers to these questions, rather than long lists of documents that need to be manually scanned by the users. State-of-the-art QA algorithms based on DNNs were successfully employed in various domains. However, QA in the genealogical domain is still underexplored, while researchers in this field (and other fields in humanities and social sciences) can highly benefit from the ability to ask questions in natural language, receive concrete answers and gain insights hidden within large corpora. While some research has been recently conducted for factual QA in the genealogical domain, to the best of our knowledge, there is no previous research on the more challenging task of numerical aggregation QA (i.e., answering questions combining aggregation functions, e.g., count, ave
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#34394;&#25311;&#31354;&#38388;&#21512;&#25104;&#20197;&#20107;&#20214;&#20026;&#20013;&#24515;&#30340;&#30693;&#35782;&#22270;&#35889;&#30340;&#26085;&#24120;&#27963;&#21160;&#30340;&#26041;&#27861;&#65292;&#24182;&#25351;&#20986;&#20102;&#22312;&#29702;&#35299;&#26085;&#24120;&#29983;&#27963;&#30340;&#24847;&#22270;&#21644;&#19978;&#19979;&#25991;&#26041;&#38754;&#30340;&#22256;&#38590;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.16206</link><description>&lt;p&gt;
&#20351;&#29992;&#34394;&#25311;&#31354;&#38388;&#21512;&#25104;&#20197;&#20107;&#20214;&#20026;&#20013;&#24515;&#30340;&#30693;&#35782;&#22270;&#35889;&#30340;&#26085;&#24120;&#27963;&#21160;
&lt;/p&gt;
&lt;p&gt;
Synthesizing Event-centric Knowledge Graphs of Daily Activities Using Virtual Space. (arXiv:2307.16206v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16206
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#34394;&#25311;&#31354;&#38388;&#21512;&#25104;&#20197;&#20107;&#20214;&#20026;&#20013;&#24515;&#30340;&#30693;&#35782;&#22270;&#35889;&#30340;&#26085;&#24120;&#27963;&#21160;&#30340;&#26041;&#27861;&#65292;&#24182;&#25351;&#20986;&#20102;&#22312;&#29702;&#35299;&#26085;&#24120;&#29983;&#27963;&#30340;&#24847;&#22270;&#21644;&#19978;&#19979;&#25991;&#26041;&#38754;&#30340;&#22256;&#38590;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#39044;&#35745;&#23558;&#20307;&#29616;&#22312;&#33021;&#22815;&#29702;&#35299;&#23478;&#24237;&#29615;&#22659;&#20013;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#31181;&#24773;&#22659;&#20449;&#24687;&#65292;&#20197;&#25903;&#25345;&#21508;&#31181;&#24773;&#20917;&#19979;&#30340;&#20154;&#31867;&#34892;&#20026;&#21644;&#20915;&#31574;&#30340;&#36719;&#20214;&#20195;&#29702;&#12289;&#26426;&#22120;&#20154;&#21644;&#32593;&#32476;&#29289;&#29702;&#31995;&#32479;&#20013;&#12290;&#22330;&#26223;&#22270;&#21644;&#30693;&#35782;&#22270;&#65288;KG&#65289;&#26500;&#24314;&#25216;&#26415;&#23545;&#20110;&#28385;&#36275;&#36825;&#19968;&#26399;&#26395;&#30340;&#22522;&#20110;&#30693;&#35782;&#30340;&#23454;&#20307;&#38382;&#31572;&#21463;&#21040;&#20102;&#24456;&#22810;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#19968;&#20010;&#29289;&#29702;&#31354;&#38388;&#20013;&#25910;&#38598;&#21644;&#31649;&#29702;&#21508;&#31181;&#23454;&#39564;&#26465;&#20214;&#19979;&#30340;&#26085;&#24120;&#27963;&#21160;&#30340;&#30495;&#23454;&#25968;&#25454;&#26159;&#30456;&#24403;&#26114;&#36149;&#30340;&#65292;&#32780;&#19988;&#24320;&#21457;&#20986;&#29702;&#35299;&#24847;&#22270;&#21644;&#19978;&#19979;&#25991;&#30340;&#20154;&#24037;&#26234;&#33021;&#20063;&#24456;&#22256;&#38590;&#12290;&#26410;&#26469;&#65292;&#39044;&#35745;&#23558;&#32467;&#21512;&#26469;&#33258;&#21487;&#20197;&#36731;&#26494;&#20462;&#25913;&#26465;&#20214;&#30340;&#34394;&#25311;&#31354;&#38388;&#21644;&#26465;&#20214;&#38590;&#20197;&#25913;&#21464;&#30340;&#29289;&#29702;&#31354;&#38388;&#30340;&#25968;&#25454;&#26469;&#20998;&#26512;&#26085;&#24120;&#29983;&#27963;&#27963;&#21160;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#20351;&#29992;&#34394;&#25311;&#31354;&#38388;&#26500;&#24314;&#26085;&#24120;&#27963;&#21160;&#30340;&#30693;&#35782;&#22270;&#35889;&#21450;&#20854;&#24212;&#29992;&#30340;&#30740;&#31350;&#23578;&#26410;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence (AI) is expected to be embodied in software agents, robots, and cyber-physical systems that can understand the various contextual information of daily life in the home environment to support human behavior and decision making in various situations. Scene graph and knowledge graph (KG) construction technologies have attracted much attention for knowledge-based embodied question answering meeting this expectation. However, collecting and managing real data on daily activities under various experimental conditions in a physical space are quite costly, and developing AI that understands the intentions and contexts is difficult. In the future, data from both virtual spaces, where conditions can be easily modified, and physical spaces, where conditions are difficult to change, are expected to be combined to analyze daily living activities. However, studies on the KG construction of daily activities using virtual space and their application have yet to progress. The po
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#20844;&#20849;&#22270;&#20070;&#39302;&#25552;&#20379;&#31616;&#26126;&#35821;&#35328;&#24635;&#32467;&#65288;PLS&#65289;&#20316;&#20026;&#19968;&#39033;&#26032;&#26381;&#21153;&#30340;&#26694;&#26550;&#65292;&#24182;&#25506;&#35752;&#20102;PLS&#25910;&#38598;&#30340;&#26041;&#27861;&#20197;&#21450;&#20351;&#20043;&#23545;&#29992;&#25143;&#21487;&#33719;&#21462;&#30340;&#26368;&#26377;&#25928;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2307.16192</link><description>&lt;p&gt;
&#20026;&#20844;&#20247;&#20986;&#29256;&#65306;&#36890;&#36807;&#31616;&#26126;&#35821;&#35328;&#24635;&#32467;&#25552;&#39640;&#20844;&#20849;&#22270;&#20070;&#39302;&#29992;&#25143;&#23545;&#30740;&#31350;&#25104;&#26524;&#30340;&#33719;&#21462;
&lt;/p&gt;
&lt;p&gt;
Publish for Public: Improving Access of Public Libraries Users to Research Findings through Plain Language Summaries. (arXiv:2307.16192v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16192
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#20844;&#20849;&#22270;&#20070;&#39302;&#25552;&#20379;&#31616;&#26126;&#35821;&#35328;&#24635;&#32467;&#65288;PLS&#65289;&#20316;&#20026;&#19968;&#39033;&#26032;&#26381;&#21153;&#30340;&#26694;&#26550;&#65292;&#24182;&#25506;&#35752;&#20102;PLS&#25910;&#38598;&#30340;&#26041;&#27861;&#20197;&#21450;&#20351;&#20043;&#23545;&#29992;&#25143;&#21487;&#33719;&#21462;&#30340;&#26368;&#26377;&#25928;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#20849;&#22270;&#20070;&#39302;&#22312;&#21521;&#31038;&#20250;&#20256;&#25773;&#30693;&#35782;&#26041;&#38754;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29992;&#25143;&#27809;&#26377;&#19987;&#19994;&#30693;&#35782;&#26469;&#29702;&#35299;&#26032;&#30340;&#30740;&#31350;&#21457;&#29616;&#12290;&#22312;&#20844;&#20849;&#22270;&#20070;&#39302;&#25552;&#20379;&#31616;&#26126;&#35821;&#35328;&#24635;&#32467;&#65288;PLS&#65289;&#26159;&#20351;&#26032;&#30340;&#30740;&#31350;&#21457;&#29616;&#26356;&#21152;&#21487;&#33719;&#21462;&#21644;&#23481;&#26131;&#29702;&#35299;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#20844;&#20849;&#22270;&#20070;&#39302;&#25552;&#20379;PLS&#20316;&#20026;&#26032;&#26381;&#21153;&#30340;&#26694;&#26550;&#12290;&#20174;&#31185;&#23398;&#19982;&#31038;&#20250;&#12289;PLS&#21644;&#20844;&#20849;&#22270;&#20070;&#39302;&#30340;&#25991;&#29486;&#20013;&#65292;&#21457;&#23637;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20844;&#20849;&#22270;&#20070;&#39302;&#21487;&#20197;&#36890;&#36807;&#19987;&#19994;&#22242;&#38431;&#12289;&#30740;&#31350;&#20154;&#21592;&#12289;&#20247;&#21253;&#31561;&#22810;&#31181;&#26041;&#24335;&#25910;&#38598;PLS&#12290;&#22270;&#20070;&#39302;&#36890;&#35759;&#12289;&#29305;&#21002;&#12289;&#23459;&#20256;&#20876;&#12289;&#29420;&#31435;&#22312;&#32447;&#25968;&#25454;&#24211;&#21644;&#31038;&#20132;&#32593;&#32476;&#26159;&#20351;PLS&#23545;&#29992;&#25143;&#21487;&#33719;&#21462;&#26368;&#26377;&#25928;&#30340;&#26041;&#24335;&#20043;&#19968;&#12290;&#36890;&#36807;&#25552;&#20986;&#20844;&#20849;&#22270;&#20070;&#39302;&#25552;&#20379;PLS&#30340;&#26694;&#26550;&#65292;&#26412;&#30740;&#31350;&#26377;&#21161;&#20110;&#24357;&#21512;&#31185;&#23398;&#30740;&#31350;&#21644;&#20844;&#20247;&#20043;&#38388;&#30340;&#40511;&#27807;&#12290;
&lt;/p&gt;
&lt;p&gt;
Public libraries play a crucial role in disseminating knowledge to society. However, most of their users do not have the specialized knowledge to understand the new research findings. Providing plain language summaries (PLSs) in public libraries is a way to make the new research findings more accessible and understandable for the public. This article proposes a framework for providing PLSs as a new service in public libraries. Drawing from the literature on science and society, PLSs, and public libraries, a theoretical framework is developed. The findings suggest that public libraries can collect PLSs through different methods, such as professional teams, researchers, crowdsourcing, etc. Library newsletters, special publications, brochures, independent online databases, and social networks are among the most effective for making PLSs accessible to users. By proposing a framework for providing PLSs in public libraries, this study helps to bridge the gap between scientific research and t
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22359;&#21270;&#26694;&#26550;MANNeR&#65292;&#29992;&#20110;&#28789;&#27963;&#30340;&#22810;&#26041;&#38754;&#65288;&#31070;&#32463;&#65289;&#26032;&#38395;&#25512;&#33616;&#65292;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#23545;&#21508;&#20010;&#26041;&#38754;&#36827;&#34892;&#20020;&#26102;&#23450;&#21046;&#12290;&#36890;&#36807;&#24230;&#37327;&#23398;&#20064;&#21644;&#28789;&#27963;&#30340;&#30456;&#20284;&#24230;&#24471;&#20998;&#32452;&#21512;&#65292;MANNeR&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#22810;&#26041;&#38754;&#25512;&#33616;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.16089</link><description>&lt;p&gt;
&#19968;&#27425;&#35757;&#32451;&#65292;&#28789;&#27963;&#24212;&#29992;&#65306;&#22810;&#26041;&#38754;&#31070;&#32463;&#26032;&#38395;&#25512;&#33616;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation. (arXiv:2307.16089v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16089
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22359;&#21270;&#26694;&#26550;MANNeR&#65292;&#29992;&#20110;&#28789;&#27963;&#30340;&#22810;&#26041;&#38754;&#65288;&#31070;&#32463;&#65289;&#26032;&#38395;&#25512;&#33616;&#65292;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#23545;&#21508;&#20010;&#26041;&#38754;&#36827;&#34892;&#20020;&#26102;&#23450;&#21046;&#12290;&#36890;&#36807;&#24230;&#37327;&#23398;&#20064;&#21644;&#28789;&#27963;&#30340;&#30456;&#20284;&#24230;&#24471;&#20998;&#32452;&#21512;&#65292;MANNeR&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#22810;&#26041;&#38754;&#25512;&#33616;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31070;&#32463;&#32593;&#32476;&#26032;&#38395;&#25512;&#33616;&#22120;&#65288;NNR&#65289;&#36890;&#36807;&#65288;1&#65289;&#23558;&#20505;&#36873;&#26032;&#38395;&#19982;&#29992;&#25143;&#21382;&#21490;&#20043;&#38388;&#30340;&#20027;&#39064;&#25110;&#24773;&#24863;&#31561;&#26041;&#38754;&#36827;&#34892;&#23545;&#40784;&#65292;&#25110;&#32773;&#65288;2&#65289;&#22312;&#36825;&#20123;&#26041;&#38754;&#19978;&#25512;&#24191;&#25512;&#33616;&#26469;&#25193;&#23637;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#12290;&#36825;&#31181;&#23450;&#21046;&#26159;&#36890;&#36807;&#23558;&#39069;&#22806;&#30340;&#32422;&#26463;&#8220;&#30828;&#32534;&#30721;&#8221;&#21040;NNR&#30340;&#26550;&#26500;&#21644;/&#25110;&#35757;&#32451;&#30446;&#26631;&#20013;&#26469;&#23454;&#29616;&#30340;&#65306;&#22240;&#27492;&#65292;&#20219;&#20309;&#23545;&#26399;&#26395;&#30340;&#25512;&#33616;&#34892;&#20026;&#30340;&#26356;&#25913;&#37117;&#38656;&#35201;&#20462;&#25913;&#30446;&#26631;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#22810;&#26041;&#38754;&#26032;&#38395;&#25512;&#33616;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MANNeR&#65292;&#36825;&#26159;&#19968;&#20010;&#28789;&#27963;&#30340;&#22810;&#26041;&#38754;&#65288;&#31070;&#32463;&#65289;&#26032;&#38395;&#25512;&#33616;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;&#65292;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#23545;&#21508;&#20010;&#26041;&#38754;&#36827;&#34892;&#20020;&#26102;&#23450;&#21046;&#12290;&#20197;&#24230;&#37327;&#23398;&#20064;&#20026;&#26680;&#24515;&#65292;MANNeR&#33719;&#24471;&#20102;&#19987;&#38376;&#38024;&#23545;&#21508;&#20010;&#26041;&#38754;&#30340;&#26032;&#38395;&#32534;&#30721;&#22120;&#65292;&#28982;&#21518;&#28789;&#27963;&#22320;&#23558;&#21508;&#20010;&#26041;&#38754;&#30340;&#30456;&#20284;&#24230;&#24471;&#20998;&#32452;&#21512;&#36215;&#26469;&#36827;&#34892;&#26368;&#32456;&#25490;&#24207;&#12290;&#22312;&#20004;&#20010;&#26631;&#20934;&#30340;&#26032;&#38395;&#25512;&#33616;&#22522;&#20934;&#27979;&#35797;&#19978;&#65288;&#19968;&#20010;&#26159;&#33521;&#25991;&#65292;&#19968;&#20010;&#26159;&#25386;&#23041;&#25991;&#65289;&#65292;MANNeR&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;...
&lt;/p&gt;
&lt;p&gt;
Recent neural news recommenders (NNR) extend content-based recommendation by (1) aligning additional aspects such as topic or sentiment between the candidate news and user history or (2) diversifying recommendations w.r.t. these aspects. This customization is achieved by ``hardcoding'' additional constraints into NNR's architecture and/or training objectives: any change in the desired recommendation behavior thus requires the model to be retrained with a modified objective, impeding wide adoption of multi-aspect news recommenders. In this work, we introduce MANNeR, a modular framework for flexible multi-aspect (neural) news recommendation that supports ad-hoc customization over individual aspects at inference time. With metric-based learning at its core, MANNeR obtains aspect-specialized news encoders and then flexibly combines aspect-specific similarity scores for final ranking. Evaluation on two standard news recommendation benchmarks (one in English, one in Norwegian) shows that MAN
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26080;&#20301;&#32622;&#20559;&#24046;&#30340;CTR&#21644;CVR&#39044;&#27979;&#27169;&#22411;&#65306;&#22522;&#20110;&#20301;&#32622;&#24863;&#30693;&#30340;&#28857;&#20987;&#36716;&#21270;&#65288;PACC&#65289;&#21644;&#22522;&#20110;&#20301;&#32622;&#23884;&#20837;&#30340;PACC&#65288;PACC-PE&#65289;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#27169;&#22411;&#22312;&#30005;&#23376;&#21830;&#21153;&#25628;&#32034;&#20013;&#20943;&#36731;&#20102;&#20301;&#32622;&#20559;&#24046;&#65292;&#24182;&#20855;&#26377;&#26356;&#22909;&#30340;&#25490;&#21517;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.16060</link><description>&lt;p&gt;
&#22312;&#30005;&#23376;&#21830;&#21153;&#20013;&#20943;&#36731;&#20301;&#32622;&#20559;&#24046;&#30340;&#36190;&#21161;&#25628;&#32034;&#28857;&#20987;&#36716;&#21270;&#22810;&#20219;&#21153;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce. (arXiv:2307.16060v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16060
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26080;&#20301;&#32622;&#20559;&#24046;&#30340;CTR&#21644;CVR&#39044;&#27979;&#27169;&#22411;&#65306;&#22522;&#20110;&#20301;&#32622;&#24863;&#30693;&#30340;&#28857;&#20987;&#36716;&#21270;&#65288;PACC&#65289;&#21644;&#22522;&#20110;&#20301;&#32622;&#23884;&#20837;&#30340;PACC&#65288;PACC-PE&#65289;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#27169;&#22411;&#22312;&#30005;&#23376;&#21830;&#21153;&#25628;&#32034;&#20013;&#20943;&#36731;&#20102;&#20301;&#32622;&#20559;&#24046;&#65292;&#24182;&#20855;&#26377;&#26356;&#22909;&#30340;&#25490;&#21517;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20301;&#32622;&#20559;&#24046;&#26159;&#25351;&#29992;&#25143;&#20542;&#21521;&#20110;&#20851;&#27880;&#25628;&#32034;&#32467;&#26524;&#21015;&#34920;&#20013;&#25490;&#21517;&#36739;&#39640;&#30340;&#39033;&#30446;&#65292;&#32780;&#19981;&#32771;&#34385;&#19982;&#26597;&#35810;&#30340;&#23454;&#38469;&#30456;&#20851;&#24615;&#30340;&#29616;&#35937;&#65292;&#36825;&#31181;&#29616;&#35937;&#22312;&#35768;&#22810;&#25490;&#24207;&#31995;&#32479;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#20301;&#32622;&#20559;&#24046;&#20250;&#20351;&#25490;&#24207;&#27169;&#22411;&#21457;&#29983;&#20559;&#24046;&#65292;&#23548;&#33268;&#21830;&#21697;&#25490;&#24207;&#12289;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#21644;&#36716;&#21270;&#29575;&#65288;CVR&#65289;&#39044;&#27979;&#26085;&#30410;&#19981;&#20844;&#24179;&#12290;&#20026;&#20102;&#20849;&#21516;&#20943;&#36731;&#39033;&#30446;CTR&#21644;CVR&#39044;&#27979;&#20013;&#30340;&#20301;&#32622;&#20559;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26080;&#20301;&#32622;&#20559;&#24046;&#30340;CTR&#21644;CVR&#39044;&#27979;&#27169;&#22411;&#65306;&#22522;&#20110;&#20301;&#32622;&#24863;&#30693;&#30340;&#28857;&#20987;&#36716;&#21270;&#65288;PACC&#65289;&#21644;&#22522;&#20110;&#20301;&#32622;&#23884;&#20837;&#30340;PACC&#65288;PACC-PE&#65289;&#12290;PACC&#22522;&#20110;&#27010;&#29575;&#20998;&#35299;&#65292;&#23558;&#20301;&#32622;&#20449;&#24687;&#24314;&#27169;&#20026;&#27010;&#29575;&#12290;PACC-PE&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#23558;&#20135;&#21697;&#29305;&#23450;&#30340;&#20301;&#32622;&#20449;&#24687;&#24314;&#27169;&#20026;&#23884;&#20837;&#12290;&#23545;&#30005;&#23376;&#21830;&#21153;&#36190;&#21161;&#20135;&#21697;&#25628;&#32034;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#25490;&#21517;&#25928;&#26524;&#19978;&#26356;&#22909;&#65292;&#24182;&#19988;&#33021;&#22815;&#22823;&#22823;&#20943;&#36731;CTR&#21644;CVR&#39044;&#27979;&#20013;&#30340;&#20301;&#32622;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Position bias, the phenomenon whereby users tend to focus on higher-ranked items of the search result list regardless of the actual relevance to queries, is prevailing in many ranking systems. Position bias in training data biases the ranking model, leading to increasingly unfair item rankings, click-through-rate (CTR), and conversion rate (CVR) predictions. To jointly mitigate position bias in both item CTR and CVR prediction, we propose two position-bias-free CTR and CVR prediction models: Position-Aware Click-Conversion (PACC) and PACC via Position Embedding (PACC-PE). PACC is built upon probability decomposition and models position information as a probability. PACC-PE utilizes neural networks to model product-specific position information as embedding. Experiments on the E-commerce sponsored product search dataset show that our proposed models have better ranking effectiveness and can greatly alleviate position bias in both CTR and CVR prediction.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26657;&#27491;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38544;&#24335;&#21453;&#39304;&#25968;&#25454;&#20013;&#32570;&#20047;&#36127;&#23454;&#20363;&#30340;&#26631;&#31614;&#30340;&#38382;&#39064;&#65292;&#22312;&#25104;&#23545;&#23398;&#20064;&#20013;&#24341;&#20837;&#20102;&#21435;&#20559;&#31227;&#25104;&#23545;&#25439;&#22833;&#65288;DPL&#65289;&#26469;&#32416;&#27491;&#30001;&#20110;&#20266;&#36127;&#20363;&#23548;&#33268;&#30340;&#20559;&#21521;&#24615;&#27010;&#29575;&#20272;&#35745;&#65292;&#20174;&#32780;&#32416;&#27491;&#26799;&#24230;&#20197;&#36924;&#36817;&#20840;&#30417;&#30563;&#25968;&#25454;&#30340;&#26799;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.15973</link><description>&lt;p&gt;
&#20174;&#27491;&#36127;&#38544;&#24335;&#21453;&#39304;&#20013;&#21435;&#20559;&#31227;&#30340;&#25104;&#23545;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Debiased Pairwise Learning from Positive-Unlabeled Implicit Feedback. (arXiv:2307.15973v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15973
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26657;&#27491;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38544;&#24335;&#21453;&#39304;&#25968;&#25454;&#20013;&#32570;&#20047;&#36127;&#23454;&#20363;&#30340;&#26631;&#31614;&#30340;&#38382;&#39064;&#65292;&#22312;&#25104;&#23545;&#23398;&#20064;&#20013;&#24341;&#20837;&#20102;&#21435;&#20559;&#31227;&#25104;&#23545;&#25439;&#22833;&#65288;DPL&#65289;&#26469;&#32416;&#27491;&#30001;&#20110;&#20266;&#36127;&#20363;&#23548;&#33268;&#30340;&#20559;&#21521;&#24615;&#27010;&#29575;&#20272;&#35745;&#65292;&#20174;&#32780;&#32416;&#27491;&#26799;&#24230;&#20197;&#36924;&#36817;&#20840;&#30417;&#30563;&#25968;&#25454;&#30340;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25104;&#23545;&#27604;&#36739;&#20013;&#23398;&#20064;&#23545;&#27604;&#34920;&#31034;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#20449;&#24687;&#26816;&#32034;&#31561;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#22522;&#20110;&#25104;&#23545;&#23398;&#20064;&#30340;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#20063;&#28304;&#20110;&#36825;&#31181;&#33539;&#24335;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#26159;&#38544;&#24335;&#21453;&#39304;&#25968;&#25454;&#20013;&#32570;&#20047;&#36127;&#23454;&#20363;&#30340;&#26631;&#31614;&#65292;&#36825;&#32463;&#24120;&#23548;&#33268;&#38543;&#26426;&#36873;&#25321;&#30340;&#36127;&#23454;&#20363;&#21253;&#21547;&#20266;&#36127;&#20363;&#65292;&#24517;&#28982;&#20135;&#29983;&#20559;&#21521;&#24615;&#23884;&#20837;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32416;&#27491;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20559;&#31227;&#24341;&#36215;&#30340;&#26679;&#26412;&#37319;&#26679;&#20559;&#24046;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#19968;&#20010;&#20462;&#25913;&#21518;&#30340;&#25104;&#23545;&#23398;&#20064;&#25439;&#22833;&#65292;&#31216;&#20026;&#21435;&#20559;&#31227;&#25104;&#23545;&#25439;&#22833;&#65288;DPL&#65289;&#12290;DPL&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#32416;&#27491;&#30001;&#20110;&#20266;&#36127;&#20363;&#23548;&#33268;&#30340;&#20559;&#21521;&#24615;&#27010;&#29575;&#20272;&#35745;&#65292;&#20174;&#32780;&#32416;&#27491;&#26799;&#24230;&#20197;&#36924;&#36817;&#20840;&#30417;&#30563;&#25968;&#25454;&#30340;&#26799;&#24230;&#12290;DPL&#30340;&#23454;&#29616;&#21482;&#38656;&#35201;&#23545;&#20195;&#30721;&#36827;&#34892;&#23567;&#30340;&#20462;&#25913;&#12290;&#22312;&#20116;&#20010;&#20844;&#24320;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;DPL&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning contrastive representations from pairwise comparisons has achieved remarkable success in various fields, such as natural language processing, computer vision, and information retrieval. Collaborative filtering algorithms based on pairwise learning also rooted in this paradigm. A significant concern is the absence of labels for negative instances in implicit feedback data, which often results in the random selected negative instances contains false negatives and inevitably, biased embeddings. To address this issue, we introduce a novel correction method for sampling bias that yields a modified loss for pairwise learning called debiased pairwise loss (DPL). The key idea underlying DPL is to correct the biased probability estimates that result from false negatives, thereby correcting the gradients to approximate those of fully supervised data. The implementation of DPL only requires a small modification of the codes. Experimental studies on five public datasets validate the effec
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Interaction and Mapping Matrices Correction (IMCorrect)&#26041;&#27861;&#65292;&#21487;&#20197;&#24179;&#34913;&#25512;&#33616;&#31995;&#32479;&#36951;&#24536;&#20013;&#30340;&#23436;&#25972;&#24615;&#12289;&#25928;&#29992;&#21644;&#25928;&#29575;&#12290;&#36890;&#36807;&#23558;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30697;&#38453;&#19982;&#26144;&#23556;&#30697;&#38453;&#30456;&#20056;&#65292;IMCorrect&#33021;&#22815;&#20462;&#27491;&#25512;&#33616;&#32467;&#26524;&#65292;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.15960</link><description>&lt;p&gt;
&#36890;&#36807;&#30697;&#38453;&#20462;&#27491;&#36827;&#34892;&#25512;&#33616;&#31995;&#32479;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Recommendation Unlearning via Matrix Correction. (arXiv:2307.15960v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15960
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Interaction and Mapping Matrices Correction (IMCorrect)&#26041;&#27861;&#65292;&#21487;&#20197;&#24179;&#34913;&#25512;&#33616;&#31995;&#32479;&#36951;&#24536;&#20013;&#30340;&#23436;&#25972;&#24615;&#12289;&#25928;&#29992;&#21644;&#25928;&#29575;&#12290;&#36890;&#36807;&#23558;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30697;&#38453;&#19982;&#26144;&#23556;&#30697;&#38453;&#30456;&#20056;&#65292;IMCorrect&#33021;&#22815;&#20462;&#27491;&#25512;&#33616;&#32467;&#26524;&#65292;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#23545;&#20110;&#20026;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#22823;&#37327;&#25910;&#38598;&#30340;&#29992;&#25143;&#25968;&#25454;&#24341;&#21457;&#20102;&#26377;&#20851;&#38544;&#31169;&#65288;&#22914;&#25935;&#24863;&#25968;&#25454;&#65289;&#12289;&#23433;&#20840;&#65288;&#22914;&#24694;&#24847;&#25968;&#25454;&#65289;&#21644;&#25928;&#29992;&#65288;&#22914;&#26377;&#23475;&#25968;&#25454;&#65289;&#30340;&#25285;&#24551;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25512;&#33616;&#31995;&#32479;&#36951;&#24536;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#29305;&#23450;&#25968;&#25454;&#21644;&#27169;&#22411;&#34987;&#36951;&#24536;&#65292;&#20197;&#20943;&#36731;&#25935;&#24863;/&#24694;&#24847;/&#26377;&#23475;&#29992;&#25143;&#25968;&#25454;&#30340;&#39118;&#38505;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#24120;&#38590;&#20197;&#22312;&#23436;&#25972;&#24615;&#12289;&#25928;&#29992;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#21363;&#22312;&#20854;&#20013;&#19968;&#20010;&#26041;&#38754;&#22949;&#21327;&#65292;&#23548;&#33268;&#23376;&#20248;&#21270;&#30340;&#25512;&#33616;&#31995;&#32479;&#36951;&#24536;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Interaction and Mapping Matrices Correction (IMCorrect)&#26041;&#27861;&#26469;&#36827;&#34892;&#25512;&#33616;&#31995;&#32479;&#36951;&#24536;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#35768;&#22810;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#21487;&#20197;&#34987;&#21046;&#23450;&#20026;&#22522;&#20110;&#26144;&#23556;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#25512;&#33616;&#32467;&#26524;&#21487;&#20197;&#36890;&#36807;&#23558;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30697;&#38453;&#19982;&#26144;&#23556;&#30697;&#38453;&#30456;&#20056;&#26469;&#33719;&#24471;&#12290;&#28982;&#21518;&#65292;IMC
&lt;/p&gt;
&lt;p&gt;
Recommender systems are important for providing personalized services to users, but the vast amount of collected user data has raised concerns about privacy (e.g., sensitive data), security (e.g., malicious data) and utility (e.g., toxic data). To address these challenges, recommendation unlearning has emerged as a promising approach, which allows specific data and models to be forgotten, mitigating the risks of sensitive/malicious/toxic user data. However, existing methods often struggle to balance completeness, utility, and efficiency, i.e., compromising one for the other, leading to suboptimal recommendation unlearning. In this paper, we propose an Interaction and Mapping Matrices Correction (IMCorrect) method for recommendation unlearning. Firstly, we reveal that many collaborative filtering (CF) algorithms can be formulated as mapping-based approach, in which the recommendation results can be obtained by multiplying the user-item interaction matrix with a mapping matrix. Then, IMC
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#12289;&#23454;&#29616;&#21644;&#35780;&#20272;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#20250;&#35758;&#24635;&#32467;&#31995;&#32479;&#65292;&#36890;&#36807;&#20943;&#23569;&#20010;&#20154;&#20250;&#35758;&#36127;&#25285;&#21644;&#22686;&#21152;&#20250;&#35758;&#36755;&#20986;&#30340;&#28165;&#26224;&#24230;&#21644;&#19968;&#33268;&#24615;&#65292;&#25552;&#39640;&#20102;&#20250;&#35758;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2307.15793</link><description>&lt;p&gt;
&#27010;&#35201;&#12289;&#20142;&#28857;&#21644;&#34892;&#21160;&#39033;&#30446;&#65306;&#35774;&#35745;&#12289;&#23454;&#29616;&#21644;&#35780;&#20272;&#22522;&#20110;LLM&#30340;&#20250;&#35758;&#24635;&#32467;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Summaries, Highlights, and Action items: Design, implementation and evaluation of an LLM-powered meeting recap system. (arXiv:2307.15793v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15793
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#12289;&#23454;&#29616;&#21644;&#35780;&#20272;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#20250;&#35758;&#24635;&#32467;&#31995;&#32479;&#65292;&#36890;&#36807;&#20943;&#23569;&#20010;&#20154;&#20250;&#35758;&#36127;&#25285;&#21644;&#22686;&#21152;&#20250;&#35758;&#36755;&#20986;&#30340;&#28165;&#26224;&#24230;&#21644;&#19968;&#33268;&#24615;&#65292;&#25552;&#39640;&#20102;&#20250;&#35758;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35758;&#22312;&#24037;&#20316;&#21327;&#35843;&#20013;&#21457;&#25381;&#30528;&#20851;&#38190;&#30340;&#22522;&#30784;&#35774;&#26045;&#20316;&#29992;&#12290;&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#21521;&#28151;&#21512;&#21644;&#36828;&#31243;&#24037;&#20316;&#30340;&#36716;&#21464;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20250;&#35758;&#27491;&#22312;&#36716;&#31227;&#21040;&#22312;&#32447;&#35745;&#31639;&#26426;&#23186;&#20307;&#31354;&#38388;&#12290;&#36825;&#23548;&#33268;&#20102;&#26032;&#30340;&#38382;&#39064;&#65288;&#20363;&#22914;&#22312;&#26356;&#19981;&#21560;&#24341;&#20154;&#30340;&#20250;&#35758;&#19978;&#33457;&#36153;&#26356;&#22810;&#30340;&#26102;&#38388;&#65289;&#21644;&#26032;&#30340;&#26426;&#20250;&#65288;&#20363;&#22914;&#33258;&#21160;&#36716;&#24405;/&#23383;&#24149;&#21644;&#24635;&#32467;&#25903;&#25345;&#65289;&#12290;&#26368;&#36817;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#23545;&#35805;&#24635;&#32467;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#36890;&#36807;&#20943;&#23569;&#20010;&#20154;&#30340;&#20250;&#35758;&#36127;&#25285;&#21644;&#22686;&#21152;&#20250;&#35758;&#36755;&#20986;&#30340;&#28165;&#26224;&#24230;&#21644;&#19968;&#33268;&#24615;&#65292;&#26377;&#21487;&#33021;&#25552;&#39640;&#20250;&#35758;&#20307;&#39564;&#12290;&#23613;&#31649;&#23384;&#22312;&#36825;&#31181;&#28508;&#21147;&#65292;&#20294;&#30001;&#20110;&#38271;&#31687;&#36716;&#24405;&#21644;&#26080;&#27861;&#26681;&#25454;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#25429;&#25417;&#21040;&#22810;&#26679;&#30340;&#24635;&#32467;&#38656;&#27714;&#65292;&#23427;&#20204;&#38754;&#20020;&#30528;&#25216;&#26415;&#38480;&#21046;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20123;&#24046;&#36317;&#65292;&#25105;&#20204;&#35774;&#35745;&#12289;&#23454;&#29616;&#24182;&#22312;&#19978;&#19979;&#25991;&#20013;&#35780;&#20272;&#20102;&#19968;&#31181;&#20250;&#35758;&#24635;&#32467;&#31995;&#32479;&#12290;&#25105;&#20204;&#39318;&#20808;&#26500;&#24605;&#20102;&#20004;&#20010;&#26126;&#26174;&#30340;&#24635;&#32467;&#34920;&#31034;&#26041;&#24335;&#8212;&#8212;&#37325;&#35201;&#20142;&#28857;&#21644;&#32467;&#26500;&#21270;&#30340;&#20998;&#32423;&#20250;&#35758;&#32426;&#35201;&#35270;&#22270;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31995;&#32479;&#26469;&#23454;&#29616;&#36825;&#20123;&#34920;&#31034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meetings play a critical infrastructural role in the coordination of work. In recent years, due to shift to hybrid and remote work, more meetings are moving to online Computer Mediated Spaces. This has led to new problems (e.g. more time spent in less engaging meetings) and new opportunities (e.g. automated transcription/captioning and recap support). Recent advances in large language models (LLMs) for dialog summarization have the potential to improve the experience of meetings by reducing individuals' meeting load and increasing the clarity and alignment of meeting outputs. Despite this potential, they face technological limitation due to long transcripts and inability to capture diverse recap needs based on user's context. To address these gaps, we design, implement and evaluate in-context a meeting recap system. We first conceptualize two salient recap representations -- important highlights, and a structured, hierarchical minutes view. We develop a system to operationalize the rep
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#19981;&#21516;&#30340;&#24341;&#23548;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#12290;&#36825;&#19968;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#20013;&#65292;&#37319;&#29992;&#22810;&#26679;&#30340;&#24341;&#23548;&#21644;&#36755;&#20837;&#22686;&#24378;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.15780</link><description>&lt;p&gt;
LLM-Rec: &#36890;&#36807;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
LLM-Rec: Personalized Recommendation via Prompting Large Language Models. (arXiv:2307.15780v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#19981;&#21516;&#30340;&#24341;&#23548;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#12290;&#36825;&#19968;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#20013;&#65292;&#37319;&#29992;&#22810;&#26679;&#30340;&#24341;&#23548;&#21644;&#36755;&#20837;&#22686;&#24378;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#36755;&#20837;&#22686;&#24378;&#25216;&#26415;&#65292;&#30740;&#31350;&#20102;&#22810;&#31181;&#19981;&#21516;&#30340;&#24341;&#23548;&#31574;&#30053;&#65292;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21517;&#20026;LLM-Rec&#65292;&#21253;&#25324;&#22235;&#31181;&#19981;&#21516;&#30340;&#24341;&#23548;&#31574;&#30053;&#65306;&#65288;1&#65289;&#22522;&#30784;&#24341;&#23548;&#65292;&#65288;2&#65289;&#25512;&#33616;&#39537;&#21160;&#24341;&#23548;&#65292;&#65288;3&#65289;&#21442;&#19982;&#24341;&#23548;&#24341;&#23548;&#65292;&#21644;&#65288;4&#65289;&#25512;&#33616;&#39537;&#21160;+&#21442;&#19982;&#24341;&#23548;&#24341;&#23548;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#23558;&#21407;&#22987;&#20869;&#23481;&#25551;&#36848;&#19982;LLM&#29983;&#25104;&#30340;&#22686;&#24378;&#36755;&#20837;&#25991;&#26412;&#32467;&#21512;&#36215;&#26469;&#65292;&#37319;&#29992;&#36825;&#20123;&#24341;&#23548;&#31574;&#30053;&#21487;&#20197;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;&#36825;&#19968;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#20010;&#24615;&#21270;&#20869;&#23481;&#25512;&#33616;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#22810;&#26679;&#30340;&#24341;&#23548;&#21644;&#36755;&#20837;&#22686;&#24378;&#25216;&#26415;&#26469;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#33021;&#21147;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate various prompting strategies for enhancing personalized content recommendation performance with large language models (LLMs) through input augmentation. Our proposed approach, termed LLM-Rec, encompasses four distinct prompting strategies: (1) basic prompting, (2) recommendation-driven prompting, (3) engagement-guided prompting, and (4) recommendation-driven + engagement-guided prompting. Our empirical experiments show that combining the original content description with the augmented input text generated by LLM using these prompting strategies leads to improved recommendation performance. This finding highlights the importance of incorporating diverse prompts and input augmentation techniques to enhance the recommendation capabilities with large language models for personalized content recommendation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;ESMC&#27169;&#22411;&#65292;&#36890;&#36807;&#21442;&#25968;&#32422;&#26463;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28857;&#20987;&#21518;&#36716;&#21270;&#29575;&#20272;&#35745;&#20013;&#30340;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#21644;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#25193;&#23637;&#20915;&#31574;&#36335;&#24452;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#29992;&#25143;&#30340;&#20915;&#31574;&#24847;&#22270;&#65292;&#24182;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.09193</link><description>&lt;p&gt;
ESMC:&#25972;&#20010;&#31354;&#38388;&#22810;&#20219;&#21153;&#27169;&#22411;&#36890;&#36807;&#21442;&#25968;&#32422;&#26463;&#29992;&#20110;&#28857;&#20987;&#21518;&#36716;&#21270;&#29575;
&lt;/p&gt;
&lt;p&gt;
ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint. (arXiv:2307.09193v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09193
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;ESMC&#27169;&#22411;&#65292;&#36890;&#36807;&#21442;&#25968;&#32422;&#26463;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28857;&#20987;&#21518;&#36716;&#21270;&#29575;&#20272;&#35745;&#20013;&#30340;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#21644;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#25193;&#23637;&#20915;&#31574;&#36335;&#24452;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#29992;&#25143;&#30340;&#20915;&#31574;&#24847;&#22270;&#65292;&#24182;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#22312;&#20114;&#32852;&#32593;&#19978;&#24191;&#27867;&#20351;&#29992;&#65292;&#36127;&#36131;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#21644;&#28857;&#20987;&#21518;&#36716;&#21270;&#29575;&#65288;CVR&#65289;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;CVR&#20272;&#35745;&#22120;&#23384;&#22312;&#30528;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#21644;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#12290;&#36890;&#36807;&#36861;&#36394;&#8220;&#26333;&#20809;_&#28857;&#20987;_&#36141;&#20080;&#8221;&#36825;&#20010;&#20915;&#31574;&#36335;&#24452;&#65292;&#25552;&#20986;&#20102;&#25972;&#20010;&#31354;&#38388;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#19968;&#20123;&#30740;&#31350;&#32773;&#35266;&#23519;&#21040;&#22312;&#28857;&#20987;&#21644;&#36141;&#20080;&#20043;&#38388;&#23384;&#22312;&#36141;&#20080;&#30456;&#20851;&#34892;&#20026;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#29992;&#25143;&#30340;&#20915;&#31574;&#24847;&#22270;&#24182;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#20915;&#31574;&#36335;&#24452;&#24050;&#25193;&#23637;&#20026;&#8220;&#26333;&#20809;_&#28857;&#20987;_&#24215;&#20869;&#21160;&#20316;_&#36141;&#20080;&#8221;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#26465;&#20214;&#27010;&#29575;&#26041;&#27861;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#26465;&#20214;&#27010;&#29575;&#30340;&#38142;&#24335;&#27861;&#21017;&#24182;&#19981;&#24635;&#26159;&#25104;&#31435;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#27010;&#29575;&#31354;&#38388;&#28151;&#28102;&#65288;PSC&#65289;&#38382;&#39064;&#65292;&#24182;&#25512;&#23548;&#20102;&#22320;&#38754;&#23454;&#20917;&#19982;&#20272;&#35745;&#25968;&#23398;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale online recommender system spreads all over the Internet being in charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion Rate (CVR) estimations. However, traditional CVR estimators suffer from well-known Sample Selection Bias and Data Sparsity issues. Entire space models were proposed to address the two issues via tracing the decision-making path of "exposure_click_purchase". Further, some researchers observed that there are purchase-related behaviors between click and purchase, which can better draw the user's decision-making intention and improve the recommendation performance. Thus, the decision-making path has been extended to "exposure_click_in-shop action_purchase" and can be modeled with conditional probability approach. Nevertheless, we observe that the chain rule of conditional probability does not always hold. We report Probability Space Confusion (PSC) issue and give a derivation of difference between ground-truth and estimation mathematical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GLORY&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20840;&#23616;&#22270;&#19982;&#26412;&#22320;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26500;&#24314;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#65292;&#24182;&#32771;&#34385;&#20102;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2307.06576</link><description>&lt;p&gt;
&#36229;&#36234;&#26412;&#22320;&#33539;&#22260;&#65306;&#20840;&#29699;&#22270;&#22686;&#24378;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06576
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GLORY&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20840;&#23616;&#22270;&#19982;&#26412;&#22320;&#34920;&#31034;&#30456;&#32467;&#21512;&#65292;&#22686;&#24378;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26500;&#24314;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#65292;&#24182;&#32771;&#34385;&#20102;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#22320;&#21521;&#29992;&#25143;&#25512;&#33616;&#20505;&#36873;&#26032;&#38395;&#25991;&#31456;&#19968;&#30452;&#26159;&#20010;&#24615;&#21270;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#30340;&#26680;&#24515;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#36817;&#26399;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20351;&#29992;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#20174;&#20016;&#23500;&#30340;&#25991;&#26412;&#25968;&#25454;&#20013;&#25552;&#21462;&#35821;&#20041;&#20449;&#24687;&#65292;&#20351;&#29992;&#20174;&#26412;&#22320;&#21382;&#21490;&#26032;&#38395;&#27966;&#29983;&#30340;&#22522;&#20110;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#32570;&#20047;&#20840;&#23616;&#35270;&#35282;&#65292;&#26410;&#33021;&#32771;&#34385;&#29992;&#25143;&#38544;&#34255;&#30340;&#21160;&#26426;&#21644;&#34892;&#20026;&#65292;&#36229;&#36234;&#35821;&#20041;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411; GLORY&#65288;Global-LOcal news Recommendation sYstem&#65289;&#65292;&#23427;&#32467;&#21512;&#20102;&#20174;&#20854;&#20182;&#29992;&#25143;&#23398;&#21040;&#30340;&#20840;&#23616;&#34920;&#31034;&#21644;&#26412;&#22320;&#34920;&#31034;&#65292;&#26469;&#22686;&#24378;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#20840;&#23616;&#24863;&#30693;&#21382;&#21490;&#26032;&#38395;&#32534;&#30721;&#22120;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#20840;&#23616;&#26032;&#38395;&#22270;&#65292;&#24182;&#20351;&#29992;&#38376;&#25511;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20016;&#23500;&#26032;&#38395;&#34920;&#31034;&#65292;&#20174;&#32780;&#36890;&#36807;&#21382;&#21490;&#26032;&#38395;&#32858;&#21512;&#22120;&#34701;&#21512;&#21382;&#21490;&#26032;&#38395;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Precisely recommending candidate news articles to users has always been a core challenge for personalized news recommendation systems. Most recent works primarily focus on using advanced natural language processing techniques to extract semantic information from rich textual data, employing content-based methods derived from local historical news. However, this approach lacks a global perspective, failing to account for users' hidden motivations and behaviors beyond semantic information. To address this challenge, we propose a novel model called GLORY (Global-LOcal news Recommendation sYstem), which combines global representations learned from other users with local representations to enhance personalized recommendation systems. We accomplish this by constructing a Global-aware Historical News Encoder, which includes a global news graph and employs gated graph neural networks to enrich news representations, thereby fusing historical news representations by a historical news aggregator.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#19978;&#19979;&#25991;Bandit&#31639;&#27861;&#65292;&#36890;&#36807;&#35774;&#35745;Epistemic Neural Recommendation (ENR)&#32593;&#32476;&#32467;&#26500;&#65292;&#23454;&#29616;&#20102;&#22823;&#35268;&#27169;&#30340;Thompson&#25277;&#26679;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#28857;&#20987;&#29575;&#21644;&#29992;&#25143;&#35780;&#20998;&#12290;</title><link>http://arxiv.org/abs/2306.14834</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#19978;&#19979;&#25991;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;Bandit&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Scalable Neural Contextual Bandit for Recommender Systems. (arXiv:2306.14834v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14834
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#19978;&#19979;&#25991;Bandit&#31639;&#27861;&#65292;&#36890;&#36807;&#35774;&#35745;Epistemic Neural Recommendation (ENR)&#32593;&#32476;&#32467;&#26500;&#65292;&#23454;&#29616;&#20102;&#22823;&#35268;&#27169;&#30340;Thompson&#25277;&#26679;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#28857;&#20987;&#29575;&#21644;&#29992;&#25143;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#36136;&#37327;&#30340;&#25512;&#33616;&#31995;&#32479;&#24212;&#36890;&#36807;&#19982;&#29992;&#25143;&#30340;&#26377;&#25928;&#21644;&#25506;&#32034;&#24615;&#20114;&#21160;&#25552;&#20379;&#21019;&#26032;&#21644;&#30456;&#20851;&#20869;&#23481;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#25512;&#33616;&#31995;&#32479;&#20013;&#22522;&#20110;&#30417;&#30563;&#23398;&#20064;&#30340;&#31070;&#32463;&#32593;&#32476;&#20165;&#21033;&#29992;&#24050;&#35782;&#21035;&#30340;&#29992;&#25143;&#20852;&#36259;&#65292;&#23545;&#20110;&#26377;&#25928;&#21457;&#29616;&#26410;&#30693;&#29992;&#25143;&#20559;&#22909;&#23384;&#22312;&#19981;&#36275;&#12290;&#23613;&#31649;&#31070;&#32463;&#19978;&#19979;&#25991;Bandit&#31639;&#27861;&#22312;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#22312;&#32447;&#25506;&#32034;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#20182;&#20204;&#23545;&#35745;&#31639;&#30340;&#35201;&#27714;&#36739;&#39640;&#65292;&#38480;&#21046;&#20102;&#23427;&#22312;&#23454;&#38469;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26679;&#26412;&#25928;&#29575;&#39640;&#30340;&#31070;&#32463;&#19978;&#19979;&#25991;Bandit&#31639;&#27861;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#35748;&#30693;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;Epistemic Neural Recommendation (ENR)&#65292;&#23427;&#33021;&#22815;&#22312;&#22823;&#35268;&#27169;&#19978;&#23454;&#29616;Thompson&#25277;&#26679;&#12290;&#36890;&#36807;&#20004;&#20010;&#19981;&#21516;&#30340;&#30495;&#23454;&#20219;&#21153;&#30340;&#22823;&#35268;&#27169;&#23454;&#39564;&#65292;ENR&#26174;&#33879;&#25552;&#39640;&#20102;&#28857;&#20987;&#29575;&#21644;&#29992;&#25143;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-quality recommender systems ought to deliver both innovative and relevant content through effective and exploratory interactions with users. Yet, supervised learning-based neural networks, which form the backbone of many existing recommender systems, only leverage recognized user interests, falling short when it comes to efficiently uncovering unknown user preferences. While there has been some progress with neural contextual bandit algorithms towards enabling online exploration through neural networks, their onerous computational demands hinder widespread adoption in real-world recommender systems. In this work, we propose a scalable sample-efficient neural contextual bandit algorithm for recommender systems. To do this, we design an epistemic neural network architecture, Epistemic Neural Recommendation (ENR), that enables Thompson sampling at a large scale. In two distinct large-scale experiments with real-world tasks, ENR significantly boosts click-through rates and user rating
&lt;/p&gt;</description></item><item><title>&#23384;&#26723;&#26597;&#35810;&#26085;&#24535;&#26159;&#20114;&#32852;&#32593;&#26723;&#26696;&#39302;&#22312;&#36807;&#21435;25&#24180;&#20013;&#25910;&#38598;&#30340;&#20840;&#38754;&#26597;&#35810;&#26085;&#24535;&#65292;&#21253;&#21547;&#36739;&#22823;&#35268;&#27169;&#12289;&#24191;&#27867;&#33539;&#22260;&#21644;&#22810;&#26679;&#24615;&#65292;&#20854;&#25552;&#20379;&#20102;&#25903;&#25345;&#26032;&#30340;&#26816;&#32034;&#27169;&#22411;&#21644;&#25628;&#32034;&#24341;&#25806;&#20998;&#26512;&#30340;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2304.00413</link><description>&lt;p&gt;
&#23384;&#26723;&#26597;&#35810;&#26085;&#24535;&#65306;25&#24180;&#32593;&#32476;&#26723;&#26696;&#20013;&#25968;&#30334;&#20010;&#25628;&#32034;&#24341;&#25806;&#30340;&#25968;&#30334;&#19975;&#25628;&#32034;&#32467;&#26524;&#39029;&#38754;&#30340;&#25366;&#25496;
&lt;/p&gt;
&lt;p&gt;
The Archive Query Log: Mining Millions of Search Result Pages of Hundreds of Search Engines from 25 Years of Web Archives. (arXiv:2304.00413v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00413
&lt;/p&gt;
&lt;p&gt;
&#23384;&#26723;&#26597;&#35810;&#26085;&#24535;&#26159;&#20114;&#32852;&#32593;&#26723;&#26696;&#39302;&#22312;&#36807;&#21435;25&#24180;&#20013;&#25910;&#38598;&#30340;&#20840;&#38754;&#26597;&#35810;&#26085;&#24535;&#65292;&#21253;&#21547;&#36739;&#22823;&#35268;&#27169;&#12289;&#24191;&#27867;&#33539;&#22260;&#21644;&#22810;&#26679;&#24615;&#65292;&#20854;&#25552;&#20379;&#20102;&#25903;&#25345;&#26032;&#30340;&#26816;&#32034;&#27169;&#22411;&#21644;&#25628;&#32034;&#24341;&#25806;&#20998;&#26512;&#30340;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23384;&#26723;&#26597;&#35810;&#26085;&#24535;&#65288;AQL&#65289;&#26159;&#20114;&#32852;&#32593;&#26723;&#26696;&#39302;&#22312;&#36807;&#21435;25&#24180;&#25910;&#38598;&#30340;&#20197;&#21069;&#26410;&#20351;&#29992;&#30340;&#20840;&#38754;&#26597;&#35810;&#26085;&#24535;&#12290;&#20854;&#31532;&#19968;&#20010;&#29256;&#26412;&#21253;&#25324;3.56&#20159;&#27425;&#26597;&#35810;&#12289;1.66&#20159;&#20010;&#25628;&#32034;&#32467;&#26524;&#39029;&#38754;&#21644;550&#20010;&#25628;&#32034;&#25552;&#20379;&#21830;&#30340;17&#20159;&#20010;&#25628;&#32034;&#32467;&#26524;&#12290;&#34429;&#28982;&#25991;&#29486;&#20013;&#26377;&#35768;&#22810;&#26597;&#35810;&#26085;&#24535;&#30340;&#30740;&#31350;&#65292;&#20294;&#25317;&#26377;&#36825;&#20123;&#26085;&#24535;&#30340;&#25628;&#32034;&#25552;&#20379;&#21830;&#36890;&#24120;&#19981;&#20250;&#20844;&#24320;&#21457;&#24067;&#20197;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#21644;&#37325;&#35201;&#19994;&#21153;&#25968;&#25454;&#12290;&#22312;&#23569;&#25968;&#20844;&#24320;&#21487;&#29992;&#30340;&#26597;&#35810;&#26085;&#24535;&#20013;&#65292;&#27809;&#26377;&#19968;&#31181;&#32467;&#21512;&#20102;&#35268;&#27169;&#12289;&#33539;&#22260;&#21644;&#22810;&#26679;&#24615;&#12290;AQL&#26159;&#31532;&#19968;&#20010;&#36825;&#26679;&#20570;&#30340;&#65292;&#20026;&#26032;&#30340;&#26816;&#32034;&#27169;&#22411;&#21644;&#65288;&#21382;&#26102;&#30340;&#65289;&#25628;&#32034;&#24341;&#25806;&#20998;&#26512;&#25552;&#20379;&#25903;&#25345;&#12290;&#20197;&#20445;&#25252;&#38544;&#31169;&#30340;&#26041;&#24335;&#25552;&#20379;&#65292;&#23427;&#20419;&#36827;&#20102;&#24320;&#25918;&#30740;&#31350;&#65292;&#24182;&#22686;&#21152;&#20102;&#25628;&#32034;&#34892;&#19994;&#30340;&#36879;&#26126;&#24230;&#21644;&#38382;&#36131;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Archive Query Log (AQL) is a previously unused, comprehensive query log collected at the Internet Archive over the last 25 years. Its first version includes 356 million queries, 166 million search result pages, and 1.7 billion search results across 550 search providers. Although many query logs have been studied in the literature, the search providers that own them generally do not publish their logs to protect user privacy and vital business data. Of the few query logs publicly available, none combines size, scope, and diversity. The AQL is the first to do so, enabling research on new retrieval models and (diachronic) search engine analyses. Provided in a privacy-preserving manner, it promotes open research as well as more transparency and accountability in the search industry.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37325;&#26032;&#23457;&#35270;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#22810;&#20852;&#36259;&#20505;&#36873;&#21305;&#37197;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#21457;&#29616;&#20102;&#22343;&#21248;&#37319;&#26679;softmax&#26080;&#27861;&#26377;&#25928;&#35757;&#32451;&#20855;&#26377;&#21306;&#20998;&#24615;&#30340;&#34920;&#31034;&#21644;&#36335;&#30001;&#23849;&#22604;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20852;&#36259;&#24863;&#30693;&#30340;&#38590;&#36127;&#26679;&#26412;&#25366;&#25496;&#31574;&#30053;&#21644;&#36335;&#30001;&#27491;&#35268;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.14532</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#25512;&#33616;&#31995;&#32479;&#20013;&#20505;&#36873;&#21305;&#37197;&#30340;&#22810;&#20852;&#36259;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Rethinking Multi-Interest Learning for Candidate Matching in Recommender Systems. (arXiv:2302.14532v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#26032;&#23457;&#35270;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#22810;&#20852;&#36259;&#20505;&#36873;&#21305;&#37197;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#21457;&#29616;&#20102;&#22343;&#21248;&#37319;&#26679;softmax&#26080;&#27861;&#26377;&#25928;&#35757;&#32451;&#20855;&#26377;&#21306;&#20998;&#24615;&#30340;&#34920;&#31034;&#21644;&#36335;&#30001;&#23849;&#22604;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20852;&#36259;&#24863;&#30693;&#30340;&#38590;&#36127;&#26679;&#26412;&#25366;&#25496;&#31574;&#30053;&#21644;&#36335;&#30001;&#27491;&#35268;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#22810;&#20852;&#36259;&#20505;&#36873;&#21305;&#37197;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#20110;&#25913;&#36827;&#27169;&#22411;&#26550;&#26500;&#25110;&#25972;&#21512;&#39069;&#22806;&#20449;&#24687;&#65292;&#24573;&#35270;&#20102;&#35757;&#32451;&#26041;&#26696;&#30340;&#37325;&#35201;&#24615;&#12290;&#26412;&#30740;&#31350;&#37325;&#26032;&#23457;&#35270;&#20102;&#35757;&#32451;&#26694;&#26550;&#65292;&#21457;&#29616;&#20102;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65292;&#38459;&#30861;&#20102;&#22810;&#20852;&#36259;&#34920;&#31034;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#39318;&#20808;&#65292;&#24403;&#21069;&#30340;&#35757;&#32451;&#30446;&#26631;&#65288;&#21363;&#22343;&#21248;&#37319;&#26679;&#30340;softmax&#65289;&#22312;&#22810;&#20852;&#36259;&#23398;&#20064;&#22330;&#26223;&#20013;&#26080;&#27861;&#26377;&#25928;&#35757;&#32451;&#26377;&#21306;&#20998;&#24615;&#30340;&#34920;&#31034;&#65292;&#22240;&#20026;&#26131;&#26679;&#26412;&#25968;&#37327;&#21095;&#22686;&#12290;&#20854;&#27425;&#65292;&#35266;&#23519;&#21040;&#20102;&#19968;&#31181;&#36335;&#30001;&#23849;&#28291;&#38382;&#39064;&#65292;&#27599;&#20010;&#23398;&#20064;&#21040;&#30340;&#20852;&#36259;&#21487;&#33021;&#22349;&#32553;&#20026;&#20165;&#34920;&#36798;&#26469;&#33258;&#21333;&#20010;&#39033;&#30446;&#30340;&#20449;&#24687;&#65292;&#23548;&#33268;&#20449;&#24687;&#20002;&#22833;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;REMI&#26694;&#26550;&#65292;&#21253;&#25324;&#20852;&#36259;&#24863;&#30693;&#30340;&#38590;&#36127;&#26679;&#26412;&#25366;&#25496;&#31574;&#30053;&#65288;IHN&#65289;&#21644;&#36335;&#30001;&#27491;&#35268;&#21270;&#26041;&#27861;&#65288;RR&#65289;&#12290;IHN&#36890;&#36807;&#25552;&#20986;&#29702;&#24819;&#30340;&#37319;&#26679;&#20998;&#24067;&#24378;&#35843;&#20852;&#36259;&#24863;&#30693;&#30340;&#38590;&#36127;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing research efforts for multi-interest candidate matching in recommender systems mainly focus on improving model architecture or incorporating additional information, neglecting the importance of training schemes. This work revisits the training framework and uncovers two major problems hindering the expressiveness of learned multi-interest representations. First, the current training objective (i.e., uniformly sampled softmax) fails to effectively train discriminative representations in a multi-interest learning scenario due to the severe increase in easy negative samples. Second, a routing collapse problem is observed where each learned interest may collapse to express information only from a single item, resulting in information loss. To address these issues, we propose the REMI framework, consisting of an Interest-aware Hard Negative mining strategy (IHN) and a Routing Regularization (RR) method. IHN emphasizes interest-aware hard negatives by proposing an ideal sampling dist
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22522;&#20110;&#25991;&#26412;&#25366;&#25496;&#30340;&#31995;&#32479;&#24615;&#25991;&#29486;&#32508;&#36848;&#33258;&#21160;&#21270;&#30340;&#30740;&#31350;&#12290;&#30740;&#31350;&#20013;&#35782;&#21035;&#20102;&#33258;&#21160;&#21270;&#30740;&#31350;&#30340;&#30446;&#26631;&#21644;&#33258;&#21160;&#21270;&#27493;&#39588;&#12290;&#21478;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#20351;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21644;&#23384;&#22312;&#30340;&#25361;&#25112;&#21450;&#26410;&#26469;&#30740;&#31350;&#30340;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2211.15397</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#25991;&#26412;&#25366;&#25496;&#33258;&#21160;&#21270;&#31995;&#32479;&#24615;&#25991;&#29486;&#32508;&#36848;&#65306;&#19968;&#39033;&#31995;&#32479;&#24615;&#25991;&#29486;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Automating Systematic Literature Reviews with Natural Language Processing and Text Mining: a Systematic Literature Review. (arXiv:2211.15397v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22522;&#20110;&#25991;&#26412;&#25366;&#25496;&#30340;&#31995;&#32479;&#24615;&#25991;&#29486;&#32508;&#36848;&#33258;&#21160;&#21270;&#30340;&#30740;&#31350;&#12290;&#30740;&#31350;&#20013;&#35782;&#21035;&#20102;&#33258;&#21160;&#21270;&#30740;&#31350;&#30340;&#30446;&#26631;&#21644;&#33258;&#21160;&#21270;&#27493;&#39588;&#12290;&#21478;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#20351;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21644;&#23384;&#22312;&#30340;&#25361;&#25112;&#21450;&#26410;&#26469;&#30740;&#31350;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#39033;&#38024;&#23545;&#22522;&#20110;&#25991;&#26412;&#25366;&#25496;&#30340;&#31995;&#32479;&#24615;&#25991;&#29486;&#32508;&#36848;&#65288;SLR&#65289;&#33258;&#21160;&#21270;&#30340;SLR&#12290;&#35813;&#32508;&#36848;&#35782;&#21035;&#20102;&#33258;&#21160;&#21270;&#30740;&#31350;&#30340;&#30446;&#26631;&#21644;&#33258;&#21160;&#21270;&#30340;&#21508;&#20010;&#27493;&#39588;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#20351;&#29992;&#30340;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#12289;&#25361;&#25112;&#12289;&#38480;&#21046;&#21644;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
Objectives: An SLR is presented focusing on text mining based automation of SLR creation. The present review identifies the objectives of the automation studies and the aspects of those steps that were automated. In so doing, the various ML techniques used, challenges, limitations and scope of further research are explained.  Methods: Accessible published literature studies that primarily focus on automation of study selection, study quality assessment, data extraction and data synthesis portions of SLR. Twenty-nine studies were analyzed.  Results: This review identifies the objectives of the automation studies, steps within the study selection, study quality assessment, data extraction and data synthesis portions that were automated, the various ML techniques used, challenges, limitations and scope of further research.  Discussion: We describe uses of NLP/TM techniques to support increased automation of systematic literature reviews. This area has attracted increase attention in the l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30693;&#35782;&#22270;&#23884;&#20837;&#26041;&#27861;kNN-KGE&#65292;&#23427;&#36890;&#36807;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#26368;&#36817;&#37051;&#30340;&#32447;&#24615;&#25554;&#20540;&#65292;&#20801;&#35768;&#32597;&#35265;&#25110;&#26032;&#20986;&#29616;&#30340;&#23454;&#20307;&#34987;&#26126;&#30830;&#22320;&#35760;&#24518;&#65292;&#32780;&#19981;&#26159;&#38544;&#34255;&#22312;&#27169;&#22411;&#21442;&#25968;&#20013;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#25913;&#21892;&#38142;&#25509;&#39044;&#27979;&#32467;&#26524;&#24182;&#22312;&#20302;&#36164;&#28304;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2201.05575</link><description>&lt;p&gt;
&#36890;&#36807;&#35760;&#24518;&#25512;&#29702;&#65306;&#26368;&#36817;&#37051;&#30693;&#35782;&#22270;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings. (arXiv:2201.05575v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.05575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30693;&#35782;&#22270;&#23884;&#20837;&#26041;&#27861;kNN-KGE&#65292;&#23427;&#36890;&#36807;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#26368;&#36817;&#37051;&#30340;&#32447;&#24615;&#25554;&#20540;&#65292;&#20801;&#35768;&#32597;&#35265;&#25110;&#26032;&#20986;&#29616;&#30340;&#23454;&#20307;&#34987;&#26126;&#30830;&#22320;&#35760;&#24518;&#65292;&#32780;&#19981;&#26159;&#38544;&#34255;&#22312;&#27169;&#22411;&#21442;&#25968;&#20013;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#25913;&#21892;&#38142;&#25509;&#39044;&#27979;&#32467;&#26524;&#24182;&#22312;&#20302;&#36164;&#28304;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#24448;&#30340;&#30693;&#35782;&#22270;&#23884;&#20837;&#26041;&#27861;&#36890;&#24120;&#23558;&#23454;&#20307;&#26144;&#23556;&#21040;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;&#35780;&#20998;&#20989;&#25968;&#39044;&#27979;&#30446;&#26631;&#23454;&#20307;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#38590;&#20197;&#25512;&#29702;&#20986;&#32597;&#35265;&#25110;&#26032;&#20986;&#29616;&#30340;&#26410;&#30693;&#23454;&#20307;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30693;&#35782;&#22270;&#23884;&#20837;&#26041;&#27861;kNN-KGE&#65292;&#23427;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#25554;&#20540;&#23558;&#20854;&#23454;&#20307;&#20998;&#24067;&#19982;k&#20010;&#26368;&#36817;&#37051;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#26681;&#25454;&#30693;&#35782;&#23384;&#20648;&#20013;&#23454;&#20307;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#36317;&#31163;&#35745;&#31639;&#26368;&#36817;&#37051;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26126;&#30830;&#22320;&#35760;&#24518;&#32597;&#35265;&#25110;&#26032;&#20986;&#29616;&#30340;&#23454;&#20307;&#65292;&#32780;&#19981;&#26159;&#38544;&#34255;&#22312;&#27169;&#22411;&#21442;&#25968;&#20013;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25913;&#21892;&#24402;&#32435;&#21644;&#20256;&#36882;&#24335;&#38142;&#25509;&#39044;&#27979;&#32467;&#26524;&#65292;&#24182;&#22312;&#21482;&#26377;&#23569;&#37327;&#19977;&#20803;&#32452;&#30340;&#20302;&#36164;&#28304;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#32780;&#36825;&#21487;&#33021;&#26356;&#23481;&#26131;&#36890;&#36807;&#26126;&#30830;&#30340;&#35760;&#24518;&#36827;&#34892;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they typically struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory. Code is available at https://github.com/zjunlp/KNN-KG.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#26597;&#35810;&#32858;&#28966;&#25688;&#35201;&#29983;&#25104;&#20219;&#21153;&#20316;&#20026;&#19968;&#39033;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#36827;&#34892;&#22788;&#29702;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;(KI-QFS)&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26080;&#27861;&#30452;&#25509;&#35775;&#38382;&#30456;&#20851;&#25991;&#26723;&#30340;&#24773;&#20917;&#19979;&#65292;QFS&#27169;&#22411;&#22312;KI-QFS&#19978;&#30340;&#34920;&#29616;&#36739;&#24046;&#12290;</title><link>http://arxiv.org/abs/2112.07536</link><description>&lt;p&gt;
&#23558;&#38754;&#21521;&#26597;&#35810;&#30340;&#25688;&#35201;&#29983;&#25104;&#20316;&#20026;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#36827;&#34892;&#22788;&#29702;&#65306;&#19968;&#39033;&#35797;&#28857;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Tackling Query-Focused Summarization as A Knowledge-Intensive Task: A Pilot Study. (arXiv:2112.07536v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.07536
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#26597;&#35810;&#32858;&#28966;&#25688;&#35201;&#29983;&#25104;&#20219;&#21153;&#20316;&#20026;&#19968;&#39033;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#36827;&#34892;&#22788;&#29702;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;(KI-QFS)&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26080;&#27861;&#30452;&#25509;&#35775;&#38382;&#30456;&#20851;&#25991;&#26723;&#30340;&#24773;&#20917;&#19979;&#65292;QFS&#27169;&#22411;&#22312;KI-QFS&#19978;&#30340;&#34920;&#29616;&#36739;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#32858;&#28966;&#25688;&#35201;(QFS)&#38656;&#35201;&#22312;&#32473;&#23450;&#26597;&#35810;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#30456;&#20851;&#25991;&#26723;&#38598;&#21512;&#29983;&#25104;&#25688;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#36825;&#20123;&#30456;&#20851;&#25991;&#26723;&#38656;&#35201;&#25163;&#21160;&#36827;&#34892;&#27880;&#37322;&#65292;&#22240;&#27492;&#19981;&#19968;&#23450;&#33021;&#21363;&#26102;&#33719;&#24471;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#23558;QFS&#20219;&#21153;&#20316;&#20026;&#19968;&#39033;&#30693;&#35782;&#23494;&#38598;&#22411;(KI)&#20219;&#21153;&#36827;&#34892;&#22788;&#29702;&#65292;&#19981;&#35201;&#27714;&#30452;&#25509;&#33719;&#21462;&#30456;&#20851;&#25991;&#26723;&#65292;&#32780;&#26159;&#20551;&#23450;&#36825;&#20123;&#25991;&#26723;&#23384;&#22312;&#20110;&#22823;&#35268;&#27169;&#30693;&#35782;&#35821;&#26009;&#24211;&#20013;&#65292;&#24182;&#38656;&#35201;&#39318;&#20808;&#36827;&#34892;&#26816;&#32034;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#20010;&#26032;&#30340;&#35774;&#23450;&#65292;&#25105;&#20204;&#36890;&#36807;&#25913;&#32534;&#29616;&#26377;&#30340;QFS&#25968;&#25454;&#38598;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;(KI-QFS)&#12290;&#22312;&#35813;&#25968;&#25454;&#38598;&#20013;&#65292;&#22238;&#31572;&#26597;&#35810;&#38656;&#35201;&#20174;&#30693;&#35782;&#35821;&#26009;&#24211;&#26816;&#32034;&#25991;&#26723;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#30693;&#35782;&#35821;&#26009;&#24211;&#65292;&#24182;&#36827;&#19968;&#27493;&#25552;&#20379;&#30456;&#20851;&#24615;&#27880;&#37322;&#20197;&#36827;&#34892;&#26816;&#32034;&#35780;&#20272;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;QFS&#27169;&#22411;&#21644;&#22686;&#24378;&#30340;&#26816;&#32034;&#27169;&#22411;&#23545;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#21407;&#22987;QFS&#30456;&#27604;&#65292;QFS&#27169;&#22411;&#22312;KI-QFS&#19978;&#34920;&#29616;&#26174;&#33879;&#36739;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Query-focused summarization (QFS) requires generating a summary given a query using a set of relevant documents. However, such relevant documents should be annotated manually and thus are not readily available in realistic scenarios. To address this limitation, we tackle the QFS task as a knowledge-intensive (KI) task without access to any relevant documents. Instead, we assume that these documents are present in a large-scale knowledge corpus and should be retrieved first. To explore this new setting, we build a new dataset (KI-QFS) by adapting existing QFS datasets. In this dataset, answering the query requires document retrieval from a knowledge corpus. We construct three different knowledge corpora, and we further provide relevance annotations to enable retrieval evaluation. Finally, we benchmark the dataset with state-of-the-art QFS models and retrieval-enhanced models. The experimental results demonstrate that QFS models perform significantly worse on KI-QFS compared to the origi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#22870;&#21169;&#31232;&#23569;&#26102;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2109.12509</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#28145;&#24230;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Deep Exploration for Recommendation Systems. (arXiv:2109.12509v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#22870;&#21169;&#31232;&#23569;&#26102;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#24212;&#20174;&#24310;&#36831;&#21453;&#39304;&#20013;&#25506;&#32034;&#21644;&#23398;&#20064;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#24448;&#24448;&#20391;&#37325;&#20110;&#20174;&#29992;&#25143;&#23545;&#21333;&#20010;&#25512;&#33616;&#30340;&#21709;&#24212;&#20013;&#23398;&#20064;&#12290;&#36825;&#20123;&#24037;&#20316;&#21033;&#29992;&#20102;&#30417;&#30563;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20294;&#25918;&#24323;&#20102;&#23398;&#20064;&#29992;&#25143;&#20043;&#21518;&#30340;&#34892;&#20026;&#12290;&#22312;&#36807;&#21435;&#30340;&#24037;&#20316;&#20013;&#65292;&#34429;&#28982;&#33268;&#21147;&#20110;&#20174;&#38543;&#21518;&#30340;&#34892;&#20026;&#20013;&#23398;&#20064;&#65292;&#20294;&#32570;&#20047;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#24341;&#23548;&#24182;&#33719;&#21462;&#26377;&#24847;&#20041;&#30340;&#24310;&#36831;&#21453;&#39304;&#12290;&#24403;&#22870;&#21169;&#36739;&#23569;&#26102;&#65292;&#36890;&#36807;&#24341;&#23548;&#25506;&#32034;&#26377;&#24847;&#20041;&#30340;&#24310;&#36831;&#21453;&#39304;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20026;&#25512;&#33616;&#31995;&#32479;&#24320;&#21457;&#20102;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#25512;&#33616;&#31995;&#32479;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#22312;&#21333;&#27493;&#25506;&#32034;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#26159;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#30340;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommendation systems ought to benefit by probing for and learning from delayed feedback. Research has tended to focus on learning from a user's response to a single recommendation. Such work, which leverages methods of supervised and bandit learning, forgoes learning from the user's subsequent behavior. Where past work has aimed to learn from subsequent behavior, there has been a lack of effective methods for probing to elicit informative delayed feedback. Effective exploration through probing for delayed feedback becomes particularly challenging when rewards are sparse. To address this, we develop deep exploration methods for recommendation systems. In particular, we formulate recommendation as a sequential decision problem and demonstrate benefits of deep exploration over single-step exploration. Our experiments are carried out with high-fidelity industrial-grade simulators and establish large improvements over existing algorithms.
&lt;/p&gt;</description></item></channel></rss>