<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#21517;&#20026;Caseformer&#65292;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#35299;&#20915;&#20102;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2311.00333</link><description>&lt;p&gt;
Caseformer: &#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#30340;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Caseformer: Pre-training for Legal Case Retrieval. (arXiv:2311.00333v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00333
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#21517;&#20026;Caseformer&#65292;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#35299;&#20915;&#20102;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#26088;&#22312;&#24110;&#21161;&#27861;&#24459;&#24037;&#20316;&#32773;&#25214;&#21040;&#19982;&#20182;&#20204;&#25163;&#22836;&#26696;&#20214;&#30456;&#20851;&#30340;&#26696;&#20363;&#65292;&#36825;&#23545;&#20110;&#20445;&#35777;&#20844;&#24179;&#21644;&#27491;&#20041;&#30340;&#27861;&#24459;&#21028;&#20915;&#38750;&#24120;&#37325;&#35201;&#12290;&#23613;&#31649;&#26368;&#36817;&#31070;&#32463;&#26816;&#32034;&#26041;&#27861;&#22312;&#24320;&#25918;&#22495;&#26816;&#32034;&#20219;&#21153;&#65288;&#20363;&#22914;&#32593;&#32476;&#25628;&#32034;&#65289;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20294;&#26159;&#30001;&#20110;&#23545;&#26631;&#27880;&#25968;&#25454;&#30340;&#28212;&#26395;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#24182;&#27809;&#26377;&#26174;&#31034;&#20986;&#20248;&#21183;&#12290;&#30001;&#20110;&#38656;&#35201;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#65292;&#23545;&#27861;&#24459;&#39046;&#22495;&#36827;&#34892;&#22823;&#35268;&#27169;&#35757;&#32451;&#25968;&#25454;&#30340;&#26631;&#27880;&#26159;&#22256;&#38590;&#30340;&#65292;&#22240;&#27492;&#20256;&#32479;&#30340;&#22522;&#20110;&#35789;&#27719;&#21305;&#37197;&#30340;&#25628;&#32034;&#25216;&#26415;&#65292;&#22914;TF-IDF&#12289;BM25&#21644;&#26597;&#35810;&#20284;&#28982;&#65292;&#20173;&#28982;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#31995;&#32479;&#20013;&#30427;&#34892;&#12290;&#34429;&#28982;&#20197;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35774;&#35745;&#20102;&#19968;&#20123;&#38024;&#23545;&#24320;&#25918;&#22495;&#20219;&#21153;&#20013;IR&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#20294;&#26159;&#30001;&#20110;&#26080;&#27861;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#36890;&#24120;&#26159;&#27425;&#20248;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Legal case retrieval aims to help legal workers find relevant cases related to their cases at hand, which is important for the guarantee of fairness and justice in legal judgments. While recent advances in neural retrieval methods have significantly improved the performance of open-domain retrieval tasks (e.g., Web search), their advantages have not been observed in legal case retrieval due to their thirst for annotated data. As annotating large-scale training data in legal domains is prohibitive due to the need for domain expertise, traditional search techniques based on lexical matching such as TF-IDF, BM25, and Query Likelihood are still prevalent in legal case retrieval systems. While previous studies have designed several pre-training methods for IR models in open-domain tasks, these methods are usually suboptimal in legal case retrieval because they cannot understand and capture the key knowledge and data structures in the legal corpus. To this end, we propose a novel pre-trainin
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#21551;&#21457;&#24335;&#20844;&#24335;&#24471;&#21040;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.15790</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#26415;&#35821;&#29190;&#21457;&#24615;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A statistical significance testing approach for measuring term burstiness with applications to domain-specific terminology extraction. (arXiv:2310.15790v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15790
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#21551;&#21457;&#24335;&#20844;&#24335;&#24471;&#21040;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#26159;&#25991;&#26412;&#20998;&#26512;&#20013;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#24403;&#35821;&#26009;&#24211;&#20013;&#19968;&#20010;&#26415;&#35821;&#30340;&#20986;&#29616;&#38598;&#20013;&#22312;&#23569;&#25968;&#20960;&#20010;&#25991;&#20214;&#20013;&#26102;&#65292;&#21487;&#31216;&#20043;&#20026;&#8220;&#29190;&#21457;&#24615;&#8221;&#12290;&#20316;&#20026;&#20869;&#23481;&#20016;&#23500;&#30340;&#26415;&#35821;&#65292;&#29190;&#21457;&#24615;&#26415;&#35821;&#38750;&#24120;&#36866;&#21512;&#29992;&#20110;&#20027;&#39064;&#25551;&#36848;&#65292;&#24182;&#19988;&#26159;&#25216;&#26415;&#26415;&#35821;&#30340;&#33258;&#28982;&#20505;&#36873;&#35789;&#12290;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#22810;&#31181;&#26415;&#35821;&#29190;&#21457;&#24615;&#30340;&#27979;&#37327;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#25991;&#26412;&#20998;&#26512;&#20013;&#65292;&#21253;&#25324;&#19982;&#26415;&#35821;&#29190;&#21457;&#24615;&#30456;&#20851;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#33539;&#24335;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#20010;&#39046;&#22495;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#31934;&#30830;&#27979;&#35797;&#26041;&#27861;&#12290;&#30001;&#20110;&#35745;&#31639;&#25104;&#26412;&#36807;&#39640;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#21551;&#21457;&#24335;&#20844;&#24335;&#65292;&#29992;&#20110;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#20316;&#20026;&#34917;&#20805;&#30340;&#29702;&#35770;&#36129;&#29486;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31181;&#26410;&#32463;&#25253;&#36947;&#30340;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain-specific terminology extraction is an important task in text analysis. A term in a corpus is said to be "bursty" when its occurrences are concentrated in few out of many documents. Being content rich, bursty terms are highly suited for subject matter characterization, and serve as natural candidates for identifying with technical terminology. Multiple measures of term burstiness have been proposed in the literature. However, the statistical significance testing paradigm has remained underexplored in text analysis, including in relation to term burstiness. To test these waters, we propose as our main contribution a multinomial language model-based exact test of statistical significance for term burstiness. Due to its prohibitive computational cost, we advance a heuristic formula designed to serve as a proxy for test P-values. As a complementary theoretical contribution, we derive a previously unreported relationship connecting the inverse document frequency and inverse collection
&lt;/p&gt;</description></item></channel></rss>