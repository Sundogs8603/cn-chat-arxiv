<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#21319;Prompt&#30340;&#32852;&#37030;&#20869;&#23481;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#38544;&#31169;&#27844;&#38706;&#21644;&#30693;&#35782;&#36716;&#31227;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.14678</link><description>&lt;p&gt;
&#25552;&#21319;Prompt&#30340;&#32852;&#37030;&#20869;&#23481;&#34920;&#31034;&#23398;&#20064;&#29992;&#20110;&#36328;&#39046;&#22495;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Prompt-enhanced Federated Content Representation Learning for Cross-domain Recommendation. (arXiv:2401.14678v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14678
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#21319;Prompt&#30340;&#32852;&#37030;&#20869;&#23481;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#38544;&#31169;&#27844;&#38706;&#21644;&#30693;&#35782;&#36716;&#31227;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#30340;&#32531;&#35299;&#65292;&#36328;&#39046;&#22495;&#25512;&#33616;&#20316;&#20026;&#26377;&#25928;&#30340;&#25216;&#26415;&#24050;&#32463;&#22312;&#36817;&#24180;&#26469;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#20043;&#21069;&#30340;&#30740;&#31350;&#24037;&#20316;&#21487;&#33021;&#20250;&#23548;&#33268;&#39046;&#22495;&#38544;&#31169;&#27844;&#38706;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#38656;&#35201;&#23558;&#21508;&#20010;&#39046;&#22495;&#30340;&#25968;&#25454;&#32858;&#21512;&#21040;&#19968;&#20010;&#20013;&#22830;&#26381;&#21153;&#22120;&#19978;&#12290;&#34429;&#28982;&#19968;&#20123;&#30740;&#31350;&#36890;&#36807;&#32852;&#37030;&#23398;&#20064;&#23545;&#38544;&#31169;&#36827;&#34892;&#20445;&#25252;&#30340;&#36328;&#39046;&#22495;&#25512;&#33616;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20294;&#20173;&#23384;&#22312;&#20197;&#19979;&#38480;&#21046;&#65306;1&#65289;&#23427;&#20204;&#38656;&#35201;&#23558;&#29992;&#25143;&#30340;&#20010;&#20154;&#20449;&#24687;&#19978;&#20256;&#21040;&#20013;&#22830;&#26381;&#21153;&#22120;&#65292;&#23384;&#22312;&#29992;&#25143;&#38544;&#31169;&#27844;&#38706;&#30340;&#39118;&#38505;&#12290;2&#65289;&#29616;&#26377;&#30340;&#32852;&#37030;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#21407;&#23376;&#39033;&#30446;ID&#26469;&#34920;&#31034;&#39033;&#30446;&#65292;&#36825;&#20351;&#23427;&#20204;&#26080;&#27861;&#22312;&#32479;&#19968;&#30340;&#29305;&#24449;&#31354;&#38388;&#20013;&#23545;&#39033;&#30446;&#36827;&#34892;&#24314;&#27169;&#65292;&#22686;&#21152;&#20102;&#39046;&#22495;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#30340;&#25361;&#25112;&#12290;3&#65289;&#23427;&#20204;&#37117;&#22522;&#20110;&#30693;&#36947;&#39046;&#22495;&#20043;&#38388;&#37325;&#21472;&#29992;&#25143;&#30340;&#21069;&#25552;&#65292;&#36825;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38480;&#21046;&#65292;&#25105;&#20204;&#30528;&#30524;&#20110;&#38544;&#31169;&#20445;&#25252;&#36328;&#39046;&#22495;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-domain Recommendation (CDR) as one of the effective techniques in alleviating the data sparsity issues has been widely studied in recent years. However, previous works may cause domain privacy leakage since they necessitate the aggregation of diverse domain data into a centralized server during the training process. Though several studies have conducted privacy preserving CDR via Federated Learning (FL), they still have the following limitations: 1) They need to upload users' personal information to the central server, posing the risk of leaking user privacy. 2) Existing federated methods mainly rely on atomic item IDs to represent items, which prevents them from modeling items in a unified feature space, increasing the challenge of knowledge transfer among domains. 3) They are all based on the premise of knowing overlapped users between domains, which proves impractical in real-world applications. To address the above limitations, we focus on Privacy-preserving Cross-domain Reco
&lt;/p&gt;</description></item><item><title>REFORM&#26159;&#19968;&#20010;CTR&#39044;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#20010;&#27969;&#24335;&#21472;&#21152;&#30340;&#24490;&#29615;&#32467;&#26500;&#21033;&#29992;&#20102;&#22810;&#32423;&#39640;&#38454;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#28040;&#38500;&#20102;&#35823;&#20851;&#32852;&#12290;</title><link>http://arxiv.org/abs/2309.14891</link><description>&lt;p&gt;
REFORM: &#31227;&#38500;CTR&#39044;&#27979;&#20013;&#30340;&#35823;&#20851;&#32852;&#30340;&#22810;&#32423;&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;
REFORM: Removing False Correlation in Multi-level Interaction for CTR Prediction. (arXiv:2309.14891v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14891
&lt;/p&gt;
&lt;p&gt;
REFORM&#26159;&#19968;&#20010;CTR&#39044;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#20010;&#27969;&#24335;&#21472;&#21152;&#30340;&#24490;&#29615;&#32467;&#26500;&#21033;&#29992;&#20102;&#22810;&#32423;&#39640;&#38454;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#28040;&#38500;&#20102;&#35823;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#26159;&#22312;&#32447;&#24191;&#21578;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#65292;&#20934;&#30830;&#30340;&#39044;&#27979;&#23545;&#20110;&#29992;&#25143;&#23450;&#20301;&#21644;&#20010;&#24615;&#21270;&#25512;&#33616;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#21069;&#27839;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#22797;&#26434;&#30340;&#38544;&#24335;&#21644;&#26174;&#24335;&#29305;&#24449;&#20132;&#20114;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24573;&#35270;&#20102;&#30001;&#28151;&#28102;&#22240;&#23376;&#25110;&#36873;&#25321;&#20559;&#24046;&#24341;&#36215;&#30340;&#35823;&#20851;&#32852;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#36825;&#20123;&#20132;&#20114;&#30340;&#22797;&#26434;&#24615;&#21644;&#20887;&#20313;&#24615;&#19979;&#21464;&#24471;&#26356;&#21152;&#20005;&#37325;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;CTR&#39044;&#27979;&#26694;&#26550;&#65292;&#31216;&#20026;REFORM&#65292;&#22312;&#22810;&#32423;&#29305;&#24449;&#20132;&#20114;&#20013;&#31227;&#38500;&#20102;&#35823;&#20851;&#32852;&#12290;&#25152;&#25552;&#20986;&#30340;REFORM&#26694;&#26550;&#36890;&#36807;&#20004;&#20010;&#27969;&#24335;&#21472;&#21152;&#30340;&#24490;&#29615;&#32467;&#26500;&#21033;&#29992;&#20102;&#22823;&#37327;&#30340;&#22810;&#32423;&#39640;&#38454;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#28040;&#38500;&#20102;&#35823;&#20851;&#32852;&#12290;&#35813;&#26694;&#26550;&#26377;&#20004;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65306;I. &#22810;&#32423;&#21472;&#21152;&#24490;&#29615;&#65288;MSR&#65289;&#32467;&#26500;&#20351;&#27169;&#22411;&#33021;&#22815;&#39640;&#25928;&#22320;&#25429;&#25417;&#21040;&#26469;&#33258;&#29305;&#24449;&#31354;&#38388;&#30340;&#22810;&#26679;&#38750;&#32447;&#24615;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction is a critical task in online advertising and recommendation systems, as accurate predictions are essential for user targeting and personalized recommendations. Most recent cutting-edge methods primarily focus on investigating complex implicit and explicit feature interactions. However, these methods neglect the issue of false correlations caused by confounding factors or selection bias. This problem is further magnified by the complexity and redundancy of these interactions. We propose a CTR prediction framework that removes false correlation in multi-level feature interaction, termed REFORM. The proposed REFORM framework exploits a wide range of multi-level high-order feature representations via a two-stream stacked recurrent structure while eliminating false correlations. The framework has two key components: I. The multi-level stacked recurrent (MSR) structure enables the model to efficiently capture diverse nonlinear interactions from feature spa
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#20998;&#26512;&#21644;&#39564;&#35777;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#26041;&#27861;&#22312;&#22823;&#22411;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.13063</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#12289;&#39564;&#35777;&#21644;&#24212;&#29992;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies. (arXiv:2309.13063v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13063
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#20998;&#26512;&#21644;&#39564;&#35777;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#26041;&#27861;&#22312;&#22823;&#22411;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26085;&#24535;&#25968;&#25454;&#21487;&#20197;&#25581;&#31034;&#29992;&#25143;&#19982;&#32593;&#32476;&#25628;&#32034;&#26381;&#21153;&#30340;&#20132;&#20114;&#26041;&#24335;&#12289;&#29992;&#25143;&#30340;&#38656;&#27714;&#20197;&#21450;&#28385;&#24847;&#31243;&#24230;&#31561;&#23453;&#36149;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20998;&#26512;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#24182;&#19981;&#23481;&#26131;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#26032;&#30340;&#32593;&#32476;&#25628;&#32034;&#24418;&#24335;&#65292;&#22914;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#32842;&#22825;&#12290;&#20026;&#20102;&#29702;&#35299;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#25105;&#20204;&#38656;&#35201;&#19968;&#31181;&#33021;&#22815;&#29992;&#26377;&#24847;&#20041;&#30340;&#20998;&#31867;&#26041;&#24335;&#26631;&#35760;&#23427;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#25429;&#25417;&#20854;&#22810;&#26679;&#24615;&#21644;&#21160;&#24577;&#24615;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#19988;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#32780;&#35328;&#65292;&#35201;&#20040;&#20195;&#20215;&#39640;&#26114;&#35201;&#20040;&#19981;&#22815;&#28789;&#27963;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#26032;&#26041;&#27861;&#65292;&#36825;&#31181;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#20016;&#23500;&#19988;&#30456;&#20851;&#30340;&#27010;&#24565;&#12289;&#25551;&#36848;&#21644;&#31034;&#20363;&#26469;&#34920;&#31034;&#29992;&#25143;&#24847;&#22270;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;LLM&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#26085;&#24535;&#20998;&#26512;&#21487;&#33021;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;&#36825;&#26679;&#30340;&#20998;&#31867;&#24471;&#19981;&#21040;&#22806;&#37096;&#39564;&#35777;&#65292;&#24182;&#19988;&#21487;&#33021;&#23384;&#22312;&#19981;&#33391;&#30340;&#21453;&#39304;&#22238;&#36335;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20154;&#24037;&#19987;&#23478;&#21644;&#35780;&#20272;&#32773;&#26469;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Log data can reveal valuable information about how users interact with web search services, what they want, and how satisfied they are. However, analyzing user intents in log data is not easy, especially for new forms of web search such as AI-driven chat. To understand user intents from log data, we need a way to label them with meaningful categories that capture their diversity and dynamics. Existing methods rely on manual or ML-based labeling, which are either expensive or inflexible for large and changing datasets. We propose a novel solution using large language models (LLMs), which can generate rich and relevant concepts, descriptions, and examples for user intents. However, using LLMs to generate a user intent taxonomy and apply it to do log analysis can be problematic for two main reasons: such a taxonomy is not externally validated, and there may be an undesirable feedback loop. To overcome these issues, we propose a new methodology with human experts and assessors to verify th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#24635;&#32467;&#20102;&#26368;&#26032;&#30340;&#39640;&#32423;&#27169;&#22411;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#21457;&#23637;&#30340;&#25361;&#25112;&#21644;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2201.02797</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#20013;&#30340;&#24212;&#29992;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Unified Review of Deep Learning for Automated Medical Coding. (arXiv:2201.02797v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.02797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#24635;&#32467;&#20102;&#26368;&#26032;&#30340;&#39640;&#32423;&#27169;&#22411;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#21457;&#23637;&#30340;&#25361;&#25112;&#21644;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#26159;&#21307;&#30103;&#36816;&#33829;&#21644;&#26381;&#21153;&#30340;&#22522;&#26412;&#20219;&#21153;&#65292;&#36890;&#36807;&#20174;&#20020;&#24202;&#25991;&#26723;&#20013;&#39044;&#27979;&#21307;&#30103;&#32534;&#30721;&#26469;&#31649;&#29702;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#12290;&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#36827;&#27493;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#35813;&#20219;&#21153;&#12290;&#20294;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#32570;&#20047;&#23545;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35774;&#35745;&#30340;&#32479;&#19968;&#35270;&#22270;&#12290;&#26412;&#32508;&#36848;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#20197;&#25552;&#20379;&#23545;&#21307;&#30103;&#32534;&#30721;&#27169;&#22411;&#32452;&#20214;&#30340;&#19968;&#33324;&#29702;&#35299;&#65292;&#24182;&#24635;&#32467;&#20102;&#22312;&#27492;&#26694;&#26550;&#19979;&#26368;&#36817;&#30340;&#39640;&#32423;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32479;&#19968;&#26694;&#26550;&#23558;&#21307;&#30103;&#32534;&#30721;&#20998;&#35299;&#20026;&#22235;&#20010;&#20027;&#35201;&#32452;&#20214;&#65292;&#21363;&#29992;&#20110;&#25991;&#26412;&#29305;&#24449;&#25552;&#21462;&#30340;&#32534;&#30721;&#22120;&#27169;&#22359;&#12289;&#26500;&#24314;&#28145;&#24230;&#32534;&#30721;&#22120;&#26550;&#26500;&#30340;&#26426;&#21046;&#12289;&#29992;&#20110;&#23558;&#38544;&#34255;&#34920;&#31034;&#36716;&#25442;&#25104;&#21307;&#30103;&#20195;&#30721;&#30340;&#35299;&#30721;&#22120;&#27169;&#22359;&#20197;&#21450;&#36741;&#21161;&#20449;&#24687;&#30340;&#20351;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22522;&#20934;&#21644;&#30495;&#23454;&#19990;&#30028;&#20013;&#30340;&#20351;&#29992;&#24773;&#20917;&#65292;&#35752;&#35770;&#20102;&#20851;&#38190;&#30340;&#30740;&#31350;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated medical coding, an essential task for healthcare operation and delivery, makes unstructured data manageable by predicting medical codes from clinical documents. Recent advances in deep learning and natural language processing have been widely applied to this task. However, deep learning-based medical coding lacks a unified view of the design of neural network architectures. This review proposes a unified framework to provide a general understanding of the building blocks of medical coding models and summarizes recent advanced models under the proposed framework. Our unified framework decomposes medical coding into four main components, i.e., encoder modules for text feature extraction, mechanisms for building deep encoder architectures, decoder modules for transforming hidden representations into medical codes, and the usage of auxiliary information. Finally, we introduce the benchmarks and real-world usage and discuss key research challenges and future directions.
&lt;/p&gt;</description></item></channel></rss>