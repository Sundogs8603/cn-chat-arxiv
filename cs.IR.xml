<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#35789;&#34955;&#39044;&#27979;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#36890;&#34892;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#26367;&#25442;&#35299;&#30721;&#22120;&#23454;&#29616;&#20102;&#39640;&#25928;&#21387;&#32553;&#35789;&#27719;&#20449;&#21495;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;&#36755;&#20837;&#20196;&#29260;&#30340;&#26465;&#27454;&#35206;&#30422;&#12290;</title><link>http://arxiv.org/abs/2401.11248</link><description>&lt;p&gt;
&#25918;&#24323;&#35299;&#30721;&#22120;&#65306;&#20351;&#29992;&#35789;&#34955;&#39044;&#27979;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#36890;&#34892;&#26816;&#32034;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense Passage Retrieval. (arXiv:2401.11248v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#35789;&#34955;&#39044;&#27979;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#36890;&#34892;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#26367;&#25442;&#35299;&#30721;&#22120;&#23454;&#29616;&#20102;&#39640;&#25928;&#21387;&#32553;&#35789;&#27719;&#20449;&#21495;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;&#36755;&#20837;&#20196;&#29260;&#30340;&#26465;&#27454;&#35206;&#30422;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#39044;&#35757;&#32451;&#24050;&#25104;&#20026;&#21021;&#22987;&#21270;&#21644;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#31995;&#32479;&#30340;&#27969;&#34892;&#25216;&#26415;&#12290;&#23427;&#36890;&#24120;&#21033;&#29992;&#39069;&#22806;&#30340;Transformer&#35299;&#30721;&#22359;&#25552;&#20379;&#21487;&#25345;&#32493;&#30340;&#30417;&#30563;&#20449;&#21495;&#65292;&#24182;&#23558;&#19978;&#19979;&#25991;&#20449;&#24687;&#21387;&#32553;&#21040;&#23494;&#38598;&#34920;&#31034;&#20013;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#39044;&#35757;&#32451;&#25216;&#26415;&#26377;&#25928;&#24615;&#30340;&#21407;&#22240;&#23578;&#19981;&#28165;&#26970;&#12290;&#20351;&#29992;&#22522;&#20110;Transformer&#30340;&#39069;&#22806;&#35299;&#30721;&#22120;&#20063;&#20250;&#20135;&#29983;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#25581;&#31034;&#22686;&#24378;&#35299;&#30721;&#30340;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#65288;MAE&#65289;&#39044;&#35757;&#32451;&#30456;&#23545;&#20110;&#26222;&#36890;BERT&#26816;&#26597;&#28857;&#22312;&#36755;&#20837;&#20196;&#29260;&#30340;&#26465;&#27454;&#35206;&#30422;&#19978;&#30340;&#26174;&#33879;&#25913;&#36827;&#65292;&#20197;&#35299;&#37322;&#36825;&#20010;&#38382;&#39064;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20256;&#32479;MAE&#30340;&#20462;&#25913;&#65292;&#23558;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#30340;&#35299;&#30721;&#22120;&#26367;&#25442;&#20026;&#23436;&#20840;&#31616;&#21270;&#30340;&#35789;&#34955;&#39044;&#27979;&#20219;&#21153;&#12290;&#36825;&#31181;&#20462;&#25913;&#20351;&#24471;&#35789;&#27719;&#20449;&#21495;&#33021;&#22815;&#39640;&#25928;&#22320;&#21387;&#32553;&#21040;&#23494;&#38598;&#34920;&#31034;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Masked auto-encoder pre-training has emerged as a prevalent technique for initializing and enhancing dense retrieval systems. It generally utilizes additional Transformer decoder blocks to provide sustainable supervision signals and compress contextual information into dense representations. However, the underlying reasons for the effectiveness of such a pre-training technique remain unclear. The usage of additional Transformer-based decoders also incurs significant computational costs. In this study, we aim to shed light on this issue by revealing that masked auto-encoder (MAE) pre-training with enhanced decoding significantly improves the term coverage of input tokens in dense representations, compared to vanilla BERT checkpoints. Building upon this observation, we propose a modification to the traditional MAE by replacing the decoder of a masked auto-encoder with a completely simplified Bag-of-Word prediction task. This modification enables the efficient compression of lexical signa
&lt;/p&gt;</description></item><item><title>Prompt-RAG&#26159;&#19968;&#31181;&#22312;&#23567;&#20247;&#39046;&#22495;&#20013;&#22686;&#24378;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#30340;&#26032;&#26041;&#27861;&#65292;&#19982;&#20256;&#32479;&#30340;RAG&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#19981;&#38656;&#35201;&#20351;&#29992;&#23884;&#20837;&#21521;&#37327;&#12290;&#36890;&#36807;&#38382;&#31572;&#26426;&#22120;&#20154;&#24212;&#29992;&#31243;&#24207;&#30340;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;Prompt-RAG&#20248;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#21253;&#25324;ChatGPT&#12290;</title><link>http://arxiv.org/abs/2401.11246</link><description>&lt;p&gt;
Prompt-RAG: &#22312;&#23567;&#20247;&#39046;&#22495;&#20013;&#30340;&#22522;&#20110;&#21521;&#37327;&#23884;&#20837;&#30340;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#24320;&#21019;&#24615;&#30740;&#31350;&#65292;&#20197;&#38889;&#21307;&#23398;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine. (arXiv:2401.11246v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11246
&lt;/p&gt;
&lt;p&gt;
Prompt-RAG&#26159;&#19968;&#31181;&#22312;&#23567;&#20247;&#39046;&#22495;&#20013;&#22686;&#24378;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#30340;&#26032;&#26041;&#27861;&#65292;&#19982;&#20256;&#32479;&#30340;RAG&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#19981;&#38656;&#35201;&#20351;&#29992;&#23884;&#20837;&#21521;&#37327;&#12290;&#36890;&#36807;&#38382;&#31572;&#26426;&#22120;&#20154;&#24212;&#29992;&#31243;&#24207;&#30340;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;Prompt-RAG&#20248;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#21253;&#25324;ChatGPT&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#30340;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;Prompt-RAG&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#26088;&#22312;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#23567;&#20247;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#12290;&#20256;&#32479;&#30340;RAG&#26041;&#27861;&#22823;&#22810;&#38656;&#35201;&#21521;&#37327;&#23884;&#20837;&#65292;&#28982;&#32780;&#36890;&#29992;&#30340;LLM&#22522;&#20110;&#23884;&#20837;&#34920;&#31034;&#23545;&#20110;&#19987;&#19994;&#39046;&#22495;&#30340;&#36866;&#29992;&#24615;&#20173;&#28982;&#19981;&#30830;&#23450;&#12290;&#20026;&#20102;&#25506;&#32034;&#21644;&#20030;&#20363;&#35828;&#26126;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#38889;&#21307;&#23398;&#65288;KM&#65289;&#21644;&#20256;&#32479;&#21307;&#23398;&#65288;CM&#65289;&#25991;&#26723;&#30340;&#21521;&#37327;&#23884;&#20837;&#65292;&#21457;&#29616;KM&#25991;&#26723;&#30340;&#23884;&#20837;&#19982;&#26631;&#35760;&#37325;&#21472;&#30456;&#20851;&#24615;&#26356;&#24378;&#65292;&#19982;&#20154;&#24037;&#35780;&#20272;&#30340;&#25991;&#26723;&#30456;&#20851;&#24615;&#36739;&#23567;&#65292;&#32780;CM&#25991;&#26723;&#21017;&#30456;&#21453;&#12290;Prompt-RAG&#19982;&#20256;&#32479;&#30340;RAG&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#19981;&#38656;&#35201;&#23884;&#20837;&#21521;&#37327;&#12290;&#36890;&#36807;&#38382;&#31572;&#26426;&#22120;&#20154;&#24212;&#29992;&#31243;&#24207;&#23545;&#20854;&#24615;&#33021;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#20854;&#20013;&#22238;&#31572;&#30340;&#30456;&#20851;&#24615;&#12289;&#21487;&#35835;&#24615;&#21644;&#20449;&#24687;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;Prompt-RAG&#20248;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#21253;&#25324;ChatGPT&#21644;...
&lt;/p&gt;
&lt;p&gt;
We propose a natural language prompt-based retrieval augmented generation (Prompt-RAG), a novel approach to enhance the performance of generative large language models (LLMs) in niche domains. Conventional RAG methods mostly require vector embeddings, yet the suitability of generic LLM-based embedding representations for specialized domains remains uncertain. To explore and exemplify this point, we compared vector embeddings from Korean Medicine (KM) and Conventional Medicine (CM) documents, finding that KM document embeddings correlated more with token overlaps and less with human-assessed document relatedness, in contrast to CM embeddings. Prompt-RAG, distinct from conventional RAG models, operates without the need for embedding vectors. Its performance was assessed through a Question-Answering (QA) chatbot application, where responses were evaluated for relevance, readability, and informativeness. The results showed that Prompt-RAG outperformed existing models, including ChatGPT and
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#26377;&#24847;&#35265;&#30340;&#29992;&#25143;&#22312;&#25628;&#32034;&#34892;&#20026;&#20013;&#20851;&#27880;&#24230;&#21644;&#21453;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#26292;&#38706;&#20110;&#20559;&#35265;&#25628;&#32034;&#32467;&#26524;&#20250;&#22686;&#21152;&#20182;&#20204;&#28040;&#36153;&#21453;&#23545;&#24577;&#24230;&#20869;&#23481;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2401.11201</link><description>&lt;p&gt;
&#22312;&#25628;&#32034;&#20013;&#25506;&#31350;&#29992;&#25143;&#34892;&#20026;&#20197;&#26816;&#27979;&#21442;&#19982;&#24230;&#21644;&#21453;&#20316;&#29992;&#25928;&#24212;&#30340;&#34180;&#32447;
&lt;/p&gt;
&lt;p&gt;
Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects. (arXiv:2401.11201v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#26377;&#24847;&#35265;&#30340;&#29992;&#25143;&#22312;&#25628;&#32034;&#34892;&#20026;&#20013;&#20851;&#27880;&#24230;&#21644;&#21453;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#26292;&#38706;&#20110;&#20559;&#35265;&#25628;&#32034;&#32467;&#26524;&#20250;&#22686;&#21152;&#20182;&#20204;&#28040;&#36153;&#21453;&#23545;&#24577;&#24230;&#20869;&#23481;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#20559;&#35265;&#30340;&#29992;&#25143;&#32463;&#24120;&#23547;&#27714;&#19982;&#20854;&#20808;&#21069;&#20449;&#24565;&#19968;&#33268;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#24573;&#35270;&#30456;&#30683;&#30462;&#30340;&#35777;&#25454;&#65292;&#36825;&#26159;&#30001;&#20110;&#30830;&#35748;&#20559;&#35265;&#25152;&#33268;&#12290;&#36825;&#31181;&#34892;&#20026;&#38459;&#30861;&#20102;&#20182;&#20204;&#22312;&#25628;&#32034;&#32593;&#32476;&#26102;&#32771;&#34385;&#26367;&#20195;&#31435;&#22330;&#30340;&#33021;&#21147;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#24456;&#23569;&#26377;&#30740;&#31350;&#20998;&#26512;&#20105;&#35758;&#35805;&#39064;&#30340;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#22914;&#20309;&#24433;&#21709;&#39640;&#24230;&#26377;&#24847;&#35265;&#30340;&#29992;&#25143;&#30340;&#25628;&#32034;&#34892;&#20026;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#39044;&#27880;&#20876;&#30340;&#29992;&#25143;&#30740;&#31350;(n = 257)&#65292;&#35843;&#26597;&#20102;&#19981;&#21516;&#27700;&#24179;(&#20302;&#21644;&#39640;)&#30340;&#20559;&#35265;&#25351;&#26631;&#21644;&#25628;&#32034;&#32467;&#26524;&#23637;&#31034;(&#24102;&#25110;&#19981;&#24102;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#39044;&#27979;&#30340;&#31435;&#22330;&#26631;&#31614;)&#26159;&#21542;&#20250;&#24433;&#21709;&#26377;&#24847;&#35265;&#30340;&#29992;&#25143;&#22312;&#19977;&#20010;&#26377;&#20105;&#35758;&#30340;&#35805;&#39064;&#19978;(&#21363;&#26080;&#31070;&#35770;&#12289;&#30693;&#35782;&#20135;&#26435;&#21644;&#26657;&#26381;)&#30340;&#31435;&#22330;&#22810;&#26679;&#24615;&#28040;&#36153;&#21644;&#25628;&#32034;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#21442;&#19982;&#32773;&#26292;&#38706;&#20110;(&#21453;&#24577;&#24230;)&#20559;&#35265;&#30340;&#25628;&#32034;&#32467;&#26524;&#20250;&#22686;&#21152;&#20182;&#20204;&#28040;&#36153;&#21453;&#23545;&#24577;&#24230;&#20869;&#23481;&#30340;&#25968;&#37327;&#65292;&#20294;&#25105;&#20204;&#20063;&#21457;&#29616;&#20559;&#35265;&#19982;&#36235;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Opinionated users often seek information that aligns with their preexisting beliefs while dismissing contradictory evidence due to confirmation bias. This conduct hinders their ability to consider alternative stances when searching the web. Despite this, few studies have analyzed how the diversification of search results on disputed topics influences the search behavior of highly opinionated users. To this end, we present a preregistered user study (n = 257) investigating whether different levels (low and high) of bias metrics and search results presentation (with or without AI-predicted stances labels) can affect the stance diversity consumption and search behavior of opinionated users on three debated topics (i.e., atheism, intellectual property rights, and school uniforms). Our results show that exposing participants to (counter-attitudinally) biased search results increases their consumption of attitude-opposing content, but we also found that bias was associated with a trend towar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#28145;&#24230;&#23398;&#20064;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#20102;&#36873;&#25321;&#24615;&#20266;&#30456;&#20851;&#21453;&#39304;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#20840;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#32622;&#20449;&#24230;&#20272;&#35745;&#26469;&#32467;&#21512;&#21407;&#22987;&#21644;&#25193;&#23637;&#30340;&#26597;&#35810;&#20449;&#24687;&#65292;&#20174;&#32780;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#32034;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.11198</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#36873;&#25321;&#24615;&#30456;&#20851;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
A Deep Learning Approach for Selective Relevance Feedback. (arXiv:2401.11198v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#28145;&#24230;&#23398;&#20064;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#20102;&#36873;&#25321;&#24615;&#20266;&#30456;&#20851;&#21453;&#39304;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#20840;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#32622;&#20449;&#24230;&#20272;&#35745;&#26469;&#32467;&#21512;&#21407;&#22987;&#21644;&#25193;&#23637;&#30340;&#26597;&#35810;&#20449;&#24687;&#65292;&#20174;&#32780;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#32034;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#23436;&#20840;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#26412;&#25991;&#20174;&#28145;&#24230;&#23398;&#20064;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#20102;&#36873;&#25321;&#24615;&#20266;&#30456;&#20851;&#21453;&#39304;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;transformer&#21452;&#32534;&#30721;&#22120;&#26550;&#26500;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#36827;&#19968;&#27493;&#25552;&#39640;&#20351;&#29992;&#36873;&#25321;&#24615;&#20266;&#30456;&#20851;&#21453;&#39304;&#26041;&#27861;&#30340;&#26816;&#32034;&#25928;&#26524;&#65292;&#25105;&#20204;&#21033;&#29992;&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#20272;&#35745;&#26469;&#32467;&#21512;&#21407;&#22987;&#21644;&#25193;&#23637;&#30340;&#26597;&#35810;&#20449;&#24687;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23558;&#27492;&#36873;&#25321;&#24615;&#21453;&#39304;&#24212;&#29992;&#20110;&#22810;&#31181;&#19981;&#21516;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pseudo-relevance feedback (PRF) can enhance average retrieval effectiveness over a sufficiently large number of queries. However, PRF often introduces a drift into the original information need, thus hurting the retrieval effectiveness of several queries. While a selective application of PRF can potentially alleviate this issue, previous approaches have largely relied on unsupervised or feature-based learning to determine whether a query should be expanded. In contrast, we revisit the problem of selective PRF from a deep learning perspective, presenting a model that is entirely data-driven and trained in an end-to-end manner. The proposed model leverages a transformer-based bi-encoder architecture. Additionally, to further improve retrieval effectiveness with this selective PRF approach, we make use of the model's confidence estimates to combine the information from the original and expanded queries. In our experiments, we apply this selective feedback on a number of different combinat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#20272;&#35745;&#30340;&#27491;-&#36127;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#25991;&#26723;&#38598;&#25193;&#23637;&#20219;&#21153;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.11145</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#23494;&#24230;&#20272;&#35745;&#30340;&#27491;-&#36127;&#23398;&#20064;&#26041;&#27861;&#30340;&#25991;&#26723;&#38598;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Document Set Expansion with Positive-Unlabeled Learning: A Density Estimation-based Approach. (arXiv:2401.11145v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#20272;&#35745;&#30340;&#27491;-&#36127;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#25991;&#26723;&#38598;&#25193;&#23637;&#20219;&#21153;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26723;&#38598;&#25193;&#23637;&#26088;&#22312;&#22522;&#20110;&#19968;&#32452;&#31934;&#32454;&#20027;&#39064;&#30340;&#23567;&#22411;&#25991;&#26723;&#38598;&#21512;&#65292;&#20174;&#22823;&#22411;&#38598;&#21512;&#20013;&#35782;&#21035;&#30456;&#20851;&#25991;&#26723;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#27491;-&#36127;&#23398;&#20064;&#26159;&#36825;&#19968;&#20219;&#21153;&#30340;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#20005;&#37325;&#38382;&#39064;&#20173;&#26410;&#35299;&#20915;&#65292;&#20363;&#22914;&#27491;-&#36127;&#23398;&#20064;&#26041;&#27861;&#25152;&#38754;&#20020;&#30340;&#20856;&#22411;&#25361;&#25112;&#65292;&#22914;&#26410;&#30693;&#31867;&#21035;&#20808;&#39564;&#21644;&#25968;&#25454;&#19981;&#24179;&#34913;&#65292;&#20197;&#21450;&#38656;&#35201;&#36716;&#23548;&#22411;&#23454;&#39564;&#35774;&#32622;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#20272;&#35745;&#30340;&#20840;&#26032;&#27491;-&#36127;&#23398;&#20064;&#26694;&#26550;&#65292;&#31216;&#20026;puDE&#65292;&#23427;&#21487;&#20197;&#22788;&#29702;&#19978;&#36848;&#38382;&#39064;&#12290;puDE&#30340;&#20248;&#21183;&#22312;&#20110;&#23427;&#26082;&#19981;&#21463;&#38480;&#20110;SCAR&#20551;&#35774;&#65292;&#20063;&#19981;&#38656;&#35201;&#20219;&#20309;&#31867;&#21035;&#20808;&#39564;&#30693;&#35782;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65306;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;DSE&#20219;&#21153;&#30340;&#19968;&#31181;&#26356;&#22909;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Document set expansion aims to identify relevant documents from a large collection based on a small set of documents that are on a fine-grained topic. Previous work shows that PU learning is a promising method for this task. However, some serious issues remain unresolved, i.e. typical challenges that PU methods suffer such as unknown class prior and imbalanced data, and the need for transductive experimental settings. In this paper, we propose a novel PU learning framework based on density estimation, called puDE, that can handle the above issues. The advantage of puDE is that it neither constrained to the SCAR assumption and nor require any class prior knowledge. We demonstrate the effectiveness of the proposed method using a series of real-world datasets and conclude that our method is a better alternative for the DSE task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#24335;OpenIE&#27169;&#22411;DualOIE&#65292;&#36890;&#36807;&#23454;&#29616;&#19968;&#20010;&#21452;&#37325;&#20219;&#21153;&#65292;&#21363;&#23558;&#21477;&#23376;&#20013;&#30340;&#19977;&#20803;&#32452;&#36716;&#21270;&#20026;&#21477;&#23376;&#65292;&#26469;&#26356;&#26377;&#25928;&#22320;&#25552;&#21462;&#22797;&#26434;&#30340;&#19977;&#20803;&#32452;&#12290;&#27492;&#26041;&#27861;&#40723;&#21169;&#27169;&#22411;&#27491;&#30830;&#35782;&#21035;&#21477;&#23376;&#32467;&#26500;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#25552;&#21462;&#25152;&#26377;&#28508;&#22312;&#30340;&#19977;&#20803;&#32452;&#12290;</title><link>http://arxiv.org/abs/2401.11107</link><description>&lt;p&gt;
&#20351;&#29992;&#35859;&#35789;&#25552;&#31034;&#22312;&#24320;&#25918;&#20449;&#24687;&#25552;&#21462;&#20013;&#21033;&#29992;&#23545;&#20598;&#24615;
&lt;/p&gt;
&lt;p&gt;
Exploiting Duality in Open Information Extraction with Predicate Prompt. (arXiv:2401.11107v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#24335;OpenIE&#27169;&#22411;DualOIE&#65292;&#36890;&#36807;&#23454;&#29616;&#19968;&#20010;&#21452;&#37325;&#20219;&#21153;&#65292;&#21363;&#23558;&#21477;&#23376;&#20013;&#30340;&#19977;&#20803;&#32452;&#36716;&#21270;&#20026;&#21477;&#23376;&#65292;&#26469;&#26356;&#26377;&#25928;&#22320;&#25552;&#21462;&#22797;&#26434;&#30340;&#19977;&#20803;&#32452;&#12290;&#27492;&#26041;&#27861;&#40723;&#21169;&#27169;&#22411;&#27491;&#30830;&#35782;&#21035;&#21477;&#23376;&#32467;&#26500;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#25552;&#21462;&#25152;&#26377;&#28508;&#22312;&#30340;&#19977;&#20803;&#32452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#25918;&#20449;&#24687;&#25552;&#21462;&#65288;OpenIE&#65289;&#26088;&#22312;&#20174;&#32473;&#23450;&#30340;&#21477;&#23376;&#20013;&#25552;&#21462;&#20197;&#65288;&#20027;&#20307;&#65292;&#35859;&#35789;&#65292;&#23486;&#35821;&#65289;&#24418;&#24335;&#21576;&#29616;&#30340;&#26080;&#27169;&#24335;&#19977;&#20803;&#32452;&#12290;&#19982;&#19968;&#33324;&#30340;&#20449;&#24687;&#25552;&#21462;&#65288;IE&#65289;&#30456;&#27604;&#65292;OpenIE&#23545;IE&#27169;&#22411;&#25552;&#20986;&#20102;&#26356;&#22810;&#25361;&#25112;&#65292;&#23588;&#20854;&#26159;&#22312;&#21477;&#23376;&#20013;&#23384;&#22312;&#22810;&#20010;&#22797;&#26434;&#30340;&#19977;&#20803;&#32452;&#26102;&#12290;&#20026;&#20102;&#26356;&#26377;&#25928;&#22320;&#25552;&#21462;&#36825;&#20123;&#22797;&#26434;&#30340;&#19977;&#20803;&#32452;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#24335;OpenIE&#27169;&#22411;&#65292;&#21517;&#20026;DualOIE&#65292;&#23427;&#22312;&#25552;&#21462;&#21477;&#23376;&#20013;&#30340;&#19968;&#20123;&#19977;&#20803;&#32452;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#21478;&#19968;&#20010;&#20219;&#21153;&#65292;&#21363;&#23558;&#19977;&#20803;&#32452;&#36716;&#21270;&#20026;&#21477;&#23376;&#12290;&#36825;&#31181;&#21452;&#37325;&#20219;&#21153;&#40723;&#21169;&#27169;&#22411;&#27491;&#30830;&#35782;&#21035;&#32473;&#23450;&#21477;&#23376;&#30340;&#32467;&#26500;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#20174;&#21477;&#23376;&#20013;&#25552;&#21462;&#25152;&#26377;&#28508;&#22312;&#30340;&#19977;&#20803;&#32452;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;DualOIE&#20998;&#20026;&#20004;&#20010;&#27493;&#39588;&#25552;&#21462;&#19977;&#20803;&#32452;&#65306;&#39318;&#20808;&#25552;&#21462;&#25152;&#26377;&#28508;&#22312;&#35859;&#35789;&#30340;&#24207;&#21015;&#65292;&#28982;&#21518;&#20351;&#29992;&#35859;&#35789;&#24207;&#21015;&#20316;&#20026;&#25552;&#31034;&#35825;&#23548;&#19977;&#20803;&#32452;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Open information extraction (OpenIE) aims to extract the schema-free triplets in the form of (\emph{subject}, \emph{predicate}, \emph{object}) from a given sentence. Compared with general information extraction (IE), OpenIE poses more challenges for the IE models, {especially when multiple complicated triplets exist in a sentence. To extract these complicated triplets more effectively, in this paper we propose a novel generative OpenIE model, namely \emph{DualOIE}, which achieves a dual task at the same time as extracting some triplets from the sentence, i.e., converting the triplets into the sentence.} Such dual task encourages the model to correctly recognize the structure of the given sentence and thus is helpful to extract all potential triplets from the sentence. Specifically, DualOIE extracts the triplets in two steps: 1) first extracting a sequence of all potential predicates, 2) then using the predicate sequence as a prompt to induce the generation of triplets. Our experiments 
&lt;/p&gt;</description></item><item><title>FedRKG&#26159;&#19968;&#31181;&#38544;&#31169;&#20445;&#25252;&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#22686;&#24378;&#30693;&#35782;&#22270;&#65292;&#26500;&#24314;&#20840;&#23616;&#30693;&#35782;&#22270;&#24182;&#21033;&#29992;&#20851;&#31995;&#24863;&#30693;&#30340;GNN&#27169;&#22411;&#65292;&#23454;&#29616;&#39640;&#38454;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#12290;</title><link>http://arxiv.org/abs/2401.11089</link><description>&lt;p&gt;
FedRKG&#65306;&#19968;&#31181;&#36890;&#36807;&#30693;&#35782;&#22270;&#22686;&#24378;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement. (arXiv:2401.11089v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11089
&lt;/p&gt;
&lt;p&gt;
FedRKG&#26159;&#19968;&#31181;&#38544;&#31169;&#20445;&#25252;&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#36890;&#36807;&#22686;&#24378;&#30693;&#35782;&#22270;&#65292;&#26500;&#24314;&#20840;&#23616;&#30693;&#35782;&#22270;&#24182;&#21033;&#29992;&#20851;&#31995;&#24863;&#30693;&#30340;GNN&#27169;&#22411;&#65292;&#23454;&#29616;&#39640;&#38454;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20316;&#20026;&#19968;&#31181;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36890;&#36807;&#26412;&#22320;&#35757;&#32451;&#27169;&#22411;&#26469;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#24050;&#32463;&#20986;&#29616;&#12290;&#26368;&#36817;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22240;&#20854;&#25429;&#25417;&#29992;&#25143;&#21644;&#39033;&#30446;&#20043;&#38388;&#39640;&#38454;&#20132;&#20114;&#30340;&#33021;&#21147;&#32780;&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#38544;&#31169;&#38382;&#39064;&#38459;&#30861;&#20102;&#25972;&#20010;&#29992;&#25143;-&#39033;&#30446;&#22270;&#30340;&#20840;&#23616;&#20849;&#20139;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#19968;&#20123;&#26041;&#27861;&#22312;&#22270;&#20013;&#21019;&#24314;&#20102;&#20266;&#20132;&#20114;&#39033;&#25110;&#29992;&#25143;&#65292;&#20197;&#24357;&#34917;&#27599;&#20010;&#23458;&#25143;&#31471;&#32570;&#22833;&#20449;&#24687;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#24341;&#20837;&#20102;&#38543;&#26426;&#22122;&#22768;&#24182;&#24341;&#21457;&#38544;&#31169;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;FedRKG&#65292;&#22312;&#26381;&#21153;&#22120;&#19978;&#20351;&#29992;&#20844;&#24320;&#30340;&#39033;&#30446;&#20449;&#24687;&#26500;&#24314;&#21644;&#32500;&#25252;&#20840;&#23616;&#30693;&#35782;&#22270;&#65288;KG&#65289;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#39640;&#38454;&#30340;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#12290;&#22312;&#23458;&#25143;&#31471;&#65292;&#19968;&#20010;&#20851;&#31995;&#24863;&#30693;&#30340;GNN&#27169;&#22411;&#21033;&#29992;&#22810;&#26679;&#30340;KG&#20851;&#31995;&#12290;&#20026;&#20102;&#20445;&#25252;&#26412;&#22320;&#20132;&#20114;&#39033;&#30446;&#21644;&#27169;&#31946;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) has emerged as a promising approach for preserving data privacy in recommendation systems by training models locally. Recently, Graph Neural Networks (GNN) have gained popularity in recommendation tasks due to their ability to capture high-order interactions between users and items. However, privacy concerns prevent the global sharing of the entire user-item graph. To address this limitation, some methods create pseudo-interacted items or users in the graph to compensate for missing information for each client. Unfortunately, these methods introduce random noise and raise privacy concerns. In this paper, we propose FedRKG, a novel federated recommendation system, where a global knowledge graph (KG) is constructed and maintained on the server using publicly available item information, enabling higher-order user-item interactions. On the client side, a relation-aware GNN model leverages diverse KG relationships. To protect local interaction items and obscure gradi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#19968;&#32452;&#25991;&#26723;&#20013;&#26500;&#24314;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30456;&#20284;&#24615;&#24230;&#37327;&#30340;&#26032;&#22411;&#36873;&#25321;&#20989;&#25968;&#65292;&#24182;&#35777;&#26126;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#36873;&#25321;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.10963</link><description>&lt;p&gt;
&#20851;&#20110;&#26500;&#24314;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#25152;&#38656;&#26415;&#35821;&#25968;&#37327;&#30340;&#36873;&#25321;&#65306;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On the selection of the correct number of terms for profile construction: theoretical and empirical analysis. (arXiv:2401.10963v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#19968;&#32452;&#25991;&#26723;&#20013;&#26500;&#24314;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30456;&#20284;&#24615;&#24230;&#37327;&#30340;&#26032;&#22411;&#36873;&#25321;&#20989;&#25968;&#65292;&#24182;&#35777;&#26126;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#36873;&#25321;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#19968;&#32452;&#25991;&#26723;&#20013;&#26500;&#24314;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#30340;&#38382;&#39064;&#12290;&#35813;&#37197;&#32622;&#25991;&#20214;&#30001;&#25991;&#26723;&#20013;&#26368;&#26377;&#20195;&#34920;&#24615;&#30340;&#26415;&#35821;&#23376;&#38598;&#32452;&#25104;&#65292;&#26368;&#22909;&#22320;&#20195;&#34920;&#29992;&#25143;&#30340;&#20559;&#22909;&#25110;&#20852;&#36259;&#12290;&#21463;&#21040;&#31163;&#25955;&#38598;&#20013;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23545;&#36873;&#25321;&#20989;&#25968;&#24212;&#28385;&#36275;&#30340;&#19971;&#20010;&#23646;&#24615;&#36827;&#34892;&#20102;&#20844;&#29702;&#30740;&#31350;&#65306;&#26368;&#23567;&#21644;&#26368;&#22823;&#19981;&#30830;&#23450;&#24615;&#21407;&#29702;&#65292;&#23545;&#28155;&#21152;&#38646;&#30340;&#19981;&#21464;&#24615;&#65292;&#23545;&#27604;&#20363;&#21464;&#25442;&#30340;&#19981;&#21464;&#24615;&#65292;&#21517;&#20041;&#22686;&#21152;&#21407;&#21017;&#65292;&#20256;&#36882;&#21407;&#21017;&#21644;&#26368;&#23500;&#26377;&#33719;&#21462;&#26356;&#22810;&#19981;&#31561;&#24335;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24615;&#24230;&#37327;&#30340;&#26032;&#22411;&#36873;&#25321;&#20989;&#25968;&#65292;&#29305;&#21035;&#26159;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#24120;&#29992;&#30340;&#20313;&#24358;&#24230;&#37327;&#65292;&#24182;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#31526;&#21512;&#20845;&#20010;&#23646;&#24615;&#20197;&#21450;&#20256;&#36882;&#21407;&#21017;&#30340;&#36739;&#24369;&#21464;&#20307;&#65292;&#20174;&#32780;&#20195;&#34920;&#20102;&#19968;&#31181;&#33391;&#22909;&#30340;&#36873;&#25321;&#26041;&#27861;&#12290;&#29702;&#35770;&#30740;&#31350;&#19982;&#23454;&#35777;&#30740;&#31350;&#30456;&#32467;&#21512;&#65292;&#20197;&#27604;&#36739;&#37197;&#32622;&#25991;&#20214;&#26500;&#24314;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we examine the problem of building a user profile from a set of documents. This profile will consist of a subset of the most representative terms in the documents that best represent user preferences or interests. Inspired by the discrete concentration theory we have conducted an axiomatic study of seven properties that a selection function should fulfill: the minimum and maximum uncertainty principle, invariant to adding zeros, invariant to scale transformations, principle of nominal increase, transfer principle and the richest get richer inequality. We also present a novel selection function based on the use of similarity metrics, and more specifically the cosine measure which is commonly used in information retrieval, and demonstrate that this verifies six of the properties in addition to a weaker variant of the transfer principle, thereby representing a good selection approach. The theoretical study was complemented with an empirical study to compare the performance 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27491;&#26080;&#26631;&#31614;&#23398;&#20064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#25512;&#33616;/&#36807;&#28388;&#31995;&#32479;&#65292;&#36890;&#36807;&#25366;&#25496;&#35758;&#20250;&#27963;&#21160;&#26469;&#20102;&#35299;&#35758;&#21592;&#30340;&#25919;&#27835;&#20852;&#36259;&#21644;&#20559;&#22909;&#65292;&#24182;&#20915;&#23450;&#21738;&#20123;&#25991;&#20214;&#24212;&#35813;&#20998;&#21457;&#32473;&#27599;&#20301;&#35758;&#21592;&#12290;</title><link>http://arxiv.org/abs/2401.10961</link><description>&lt;p&gt;
&#22312;&#35758;&#20250;&#29615;&#22659;&#20013;&#26500;&#24314;&#25512;&#33616;&#31995;&#32479;&#30340;&#27491;&#26080;&#26631;&#31614;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Positive unlabeled learning for building recommender systems in a parliamentary setting. (arXiv:2401.10961v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10961
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27491;&#26080;&#26631;&#31614;&#23398;&#20064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#25512;&#33616;/&#36807;&#28388;&#31995;&#32479;&#65292;&#36890;&#36807;&#25366;&#25496;&#35758;&#20250;&#27963;&#21160;&#26469;&#20102;&#35299;&#35758;&#21592;&#30340;&#25919;&#27835;&#20852;&#36259;&#21644;&#20559;&#22909;&#65292;&#24182;&#20915;&#23450;&#21738;&#20123;&#25991;&#20214;&#24212;&#35813;&#20998;&#21457;&#32473;&#27599;&#20301;&#35758;&#21592;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#25366;&#25496;&#35758;&#20250;&#27963;&#21160;&#26469;&#20102;&#35299;&#35758;&#21592;&#30340;&#25919;&#27835;&#20852;&#36259;&#21644;&#20559;&#22909;&#65292;&#20197;&#24320;&#21457;&#19968;&#20010;&#25512;&#33616;/&#36807;&#28388;&#31995;&#32479;&#12290;&#32473;&#23450;&#35201;&#20998;&#37197;&#32473;&#20182;&#20204;&#30340;&#19968;&#31995;&#21015;&#25991;&#20214;&#65292;&#35813;&#31995;&#32479;&#21487;&#20197;&#20915;&#23450;&#27599;&#20301;&#35758;&#21592;&#24212;&#35813;&#25910;&#21040;&#21738;&#20123;&#25991;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#27491;&#26080;&#26631;&#31614;&#23398;&#20064;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22240;&#20026;&#25105;&#20204;&#21482;&#26377;&#26377;&#20851;&#30456;&#20851;&#25991;&#20214;&#65288;&#27599;&#20301;&#35758;&#21592;&#22312;&#36777;&#35770;&#20013;&#33258;&#24049;&#30340;&#21457;&#35328;&#65289;&#30340;&#20449;&#24687;&#65292;&#20294;&#27809;&#26377;&#20851;&#20110;&#19981;&#30456;&#20851;&#25991;&#20214;&#30340;&#20449;&#24687;&#65292;&#22240;&#27492;&#25105;&#20204;&#26080;&#27861;&#20351;&#29992;&#36890;&#36807;&#27491;&#36127;&#26679;&#26412;&#35757;&#32451;&#30340;&#26631;&#20934;&#20108;&#20803;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#19982;&#20197;&#19979;&#26041;&#27861;&#30456;&#27604;&#34920;&#29616;&#26356;&#22909;&#65306;a) &#22522;&#20110;&#20551;&#35774;&#20854;&#20182;&#35758;&#21592;&#30340;&#24178;&#39044;&#37117;&#26159;&#19981;&#30456;&#20851;&#30340;&#22522;&#20934;&#26041;&#27861;&#65292;b) &#21478;&#19968;&#31181;&#24191;&#20026;&#20154;&#30693;&#30340;&#27491;&#26080;&#26631;&#31614;&#23398;&#20064;&#26041;&#27861;&#65292;c) &#22522;&#20110;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#23558;&#25991;&#20214;&#21644;&#31435;&#27861;&#36827;&#34892;&#21305;&#37197;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our goal is to learn about the political interests and preferences of the Members of Parliament by mining their parliamentary activity, in order to develop a recommendation/filtering system that, given a stream of documents to be distributed among them, is able to decide which documents should receive each Member of Parliament. We propose to use positive unlabeled learning to tackle this problem, because we only have information about relevant documents (the own interventions of each Member of Parliament in the debates) but not about irrelevant documents, so that we cannot use standard binary classifiers trained with positive and negative examples. We have also developed a new algorithm of this type, which compares favourably with: a) the baseline approach assuming that all the interventions of other Members of Parliament are irrelevant, b) another well-known positive unlabeled learning method and c) an approach based on information retrieval methods that matches documents and legislat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#19968;&#39033;&#29616;&#22330;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30740;&#31350;&#20102;LLM&#24037;&#20855;&#22312;&#25552;&#20379;&#26080;&#30417;&#30563;&#20449;&#24687;&#26816;&#32034;&#25903;&#25345;&#26381;&#21153;&#26041;&#38754;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.10956</link><description>&lt;p&gt;
Chat Bot&#19978;&#30340;AI&#38761;&#21629;&#65306;&#19968;&#39033;&#38543;&#26426;&#23545;&#29031;&#23454;&#39564;&#30340;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment. (arXiv:2401.10956v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10956
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#19968;&#39033;&#29616;&#22330;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30740;&#31350;&#20102;LLM&#24037;&#20855;&#22312;&#25552;&#20379;&#26080;&#30417;&#30563;&#20449;&#24687;&#26816;&#32034;&#25903;&#25345;&#26381;&#21153;&#26041;&#38754;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;generative AI&#65289;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#23637;&#31034;&#20986;&#26174;&#33879;&#30340;&#25552;&#21319;&#20154;&#31867;&#29983;&#20135;&#21147;&#30340;&#28508;&#21147;&#12290;&#29305;&#21035;&#26159;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#20197;ChatGPT-4&#20026;&#20363;&#65292;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#12290;&#35768;&#22810;&#25991;&#31456;&#24050;&#32463;&#30740;&#31350;&#20102;LLM&#24037;&#20855;&#22312;&#23454;&#39564;&#23460;&#29615;&#22659;&#19979;&#21644;&#35774;&#35745;&#20219;&#21153;&#25110;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#23545;&#20154;&#31867;&#29983;&#20135;&#21147;&#30340;&#24433;&#21709;&#12290;&#23613;&#31649;&#26368;&#36817;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#24212;&#29992;LLM&#24037;&#20855;&#30340;&#29616;&#22330;&#23454;&#39564;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#39033;&#29616;&#22330;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#30740;&#31350;&#32467;&#26524;&#65292;&#35780;&#20272;&#20102;LLM&#24037;&#20855;&#22312;&#25552;&#20379;&#26080;&#30417;&#30563;&#20449;&#24687;&#26816;&#32034;&#25903;&#25345;&#26381;&#21153;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, generative AI has undergone major advancements, demonstrating significant promise in augmenting human productivity. Notably, large language models (LLM), with ChatGPT-4 as an example, have drawn considerable attention. Numerous articles have examined the impact of LLM-based tools on human productivity in lab settings and designed tasks or in observational studies. Despite recent advances, field experiments applying LLM-based tools in realistic settings are limited. This paper presents the findings of a field randomized controlled trial assessing the effectiveness of LLM-based tools in providing unmonitored support services for information retrieval.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#21453;&#23398;&#20064;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#36866;&#24212;&#24615;&#12289;&#20010;&#24615;&#21270;&#12289;&#38544;&#31169;&#21644;&#20559;&#35265;&#31561;&#25361;&#25112;&#12290;&#19982;&#20256;&#32479;&#27169;&#22411;&#19981;&#21516;&#65292;MUL&#26681;&#25454;&#29992;&#25143;&#20559;&#22909;&#30340;&#21464;&#21270;&#21644;&#20262;&#29702;&#32771;&#34385;&#21160;&#24577;&#35843;&#25972;&#31995;&#32479;&#30693;&#35782;&#12290;&#36890;&#36807;&#25209;&#21028;&#24615;&#26816;&#39564;&#21644;&#25991;&#29486;&#26803;&#29702;&#65292;&#26412;&#25991;&#25552;&#20379;&#20102;MUL&#22914;&#20309;&#25913;&#21464;&#25512;&#33616;&#12289;&#29992;&#25143;&#20449;&#20219;&#20197;&#21450;&#26410;&#26469;&#30740;&#31350;&#36335;&#24452;&#30340;&#35265;&#35299;&#12290;&#24378;&#35843;&#20010;&#24615;&#21270;&#21644;&#38544;&#31169;&#20043;&#38388;&#30340;&#26435;&#34913;&#25361;&#25112;&#65292;&#24182;&#40723;&#21169;&#20197;&#28385;&#36275;&#23454;&#38469;&#38656;&#27714;&#20026;&#30446;&#26631;&#30340;&#36129;&#29486;&#65292;&#25512;&#21160;MUL&#22312;&#23433;&#20840;&#21644;&#36866;&#24212;&#24615;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2401.10942</link><description>&lt;p&gt;
&#26426;&#22120;&#21453;&#23398;&#20064;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#31181;&#27934;&#23519;&#21147;
&lt;/p&gt;
&lt;p&gt;
Machine Unlearning for Recommendation Systems: An Insight. (arXiv:2401.10942v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#21453;&#23398;&#20064;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#36866;&#24212;&#24615;&#12289;&#20010;&#24615;&#21270;&#12289;&#38544;&#31169;&#21644;&#20559;&#35265;&#31561;&#25361;&#25112;&#12290;&#19982;&#20256;&#32479;&#27169;&#22411;&#19981;&#21516;&#65292;MUL&#26681;&#25454;&#29992;&#25143;&#20559;&#22909;&#30340;&#21464;&#21270;&#21644;&#20262;&#29702;&#32771;&#34385;&#21160;&#24577;&#35843;&#25972;&#31995;&#32479;&#30693;&#35782;&#12290;&#36890;&#36807;&#25209;&#21028;&#24615;&#26816;&#39564;&#21644;&#25991;&#29486;&#26803;&#29702;&#65292;&#26412;&#25991;&#25552;&#20379;&#20102;MUL&#22914;&#20309;&#25913;&#21464;&#25512;&#33616;&#12289;&#29992;&#25143;&#20449;&#20219;&#20197;&#21450;&#26410;&#26469;&#30740;&#31350;&#36335;&#24452;&#30340;&#35265;&#35299;&#12290;&#24378;&#35843;&#20010;&#24615;&#21270;&#21644;&#38544;&#31169;&#20043;&#38388;&#30340;&#26435;&#34913;&#25361;&#25112;&#65292;&#24182;&#40723;&#21169;&#20197;&#28385;&#36275;&#23454;&#38469;&#38656;&#27714;&#20026;&#30446;&#26631;&#30340;&#36129;&#29486;&#65292;&#25512;&#21160;MUL&#22312;&#23433;&#20840;&#21644;&#36866;&#24212;&#24615;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#25506;&#35752;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#26426;&#22120;&#21453;&#23398;&#20064;&#65288;MUL&#65289;&#65292;&#35299;&#20915;&#20102;&#36866;&#24212;&#24615;&#12289;&#20010;&#24615;&#21270;&#12289;&#38544;&#31169;&#21644;&#20559;&#35265;&#31561;&#25361;&#25112;&#12290;&#19982;&#20256;&#32479;&#27169;&#22411;&#19981;&#21516;&#65292;MUL&#26681;&#25454;&#29992;&#25143;&#20559;&#22909;&#30340;&#21464;&#21270;&#21644;&#20262;&#29702;&#32771;&#34385;&#21160;&#24577;&#35843;&#25972;&#31995;&#32479;&#30693;&#35782;&#12290;&#26412;&#25991;&#23545;MUL&#30340;&#22522;&#26412;&#21407;&#29702;&#12289;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#21644;&#31639;&#27861;&#36879;&#26126;&#24615;&#31561;&#25361;&#25112;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#30340;&#26816;&#39564;&#12290;&#23427;&#26803;&#29702;&#20102;&#30456;&#20851;&#25991;&#29486;&#65292;&#25552;&#20379;&#20102;MUL&#22914;&#20309;&#25913;&#21464;&#25512;&#33616;&#30340;&#35265;&#35299;&#65292;&#25506;&#35752;&#20102;&#29992;&#25143;&#20449;&#20219;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#22312;&#36127;&#36131;&#20219;&#21644;&#29992;&#25143;&#20851;&#27880;&#30340;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#36335;&#24452;&#12290;&#26412;&#25991;&#24341;&#23548;&#30740;&#31350;&#20154;&#21592;&#38754;&#23545;&#20010;&#24615;&#21270;&#21644;&#38544;&#31169;&#20043;&#38388;&#30340;&#26435;&#34913;&#25361;&#25112;&#65292;&#40723;&#21169;&#20197;&#28385;&#36275;&#26377;&#38024;&#23545;&#24615;&#30340;&#25968;&#25454;&#21024;&#38500;&#23454;&#38469;&#38656;&#27714;&#20026;&#30446;&#26631;&#30340;&#36129;&#29486;&#12290;&#24378;&#35843;MUL&#22312;&#23433;&#20840;&#21644;&#36866;&#24212;&#24615;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#25512;&#21160;&#20854;&#36793;&#30028;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#25506;&#35752;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This review explores machine unlearning (MUL) in recommendation systems, addressing adaptability, personalization, privacy, and bias challenges. Unlike traditional models, MUL dynamically adjusts system knowledge based on shifts in user preferences and ethical considerations. The paper critically examines MUL's basics, real-world applications, and challenges like algorithmic transparency. It sifts through literature, offering insights into how MUL could transform recommendations, discussing user trust, and suggesting paths for future research in responsible and user-focused artificial intelligence (AI). The document guides researchers through challenges involving the trade-off between personalization and privacy, encouraging contributions to meet practical demands for targeted data removal. Emphasizing MUL's role in secure and adaptive machine learning, the paper proposes ways to push its boundaries. The novelty of this paper lies in its exploration of the limitations of the methods, w
&lt;/p&gt;</description></item><item><title>RELIANCE&#26159;&#19968;&#20010;&#21487;&#38752;&#30340;&#38598;&#25104;&#23398;&#20064;&#31995;&#32479;&#65292;&#29992;&#20110;&#35780;&#20272;&#20449;&#24687;&#21644;&#26032;&#38395;&#30340;&#21487;&#20449;&#24230;&#12290;&#23427;&#36890;&#36807;&#25972;&#21512;&#22810;&#20010;&#22522;&#26412;&#27169;&#22411;&#30340;&#20248;&#21183;&#65292;&#25552;&#20379;&#20102;&#23545;&#21487;&#20449;&#21644;&#19981;&#21487;&#20449;&#20449;&#24687;&#28304;&#30340;&#20934;&#30830;&#21306;&#20998;&#65292;&#24182;&#22312;&#20449;&#24687;&#21644;&#26032;&#38395;&#21487;&#20449;&#24230;&#35780;&#20272;&#26041;&#38754;&#20248;&#20110;&#22522;&#20934;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2401.10940</link><description>&lt;p&gt;
RELIANCE: &#21487;&#38752;&#30340;&#38598;&#25104;&#23398;&#20064;&#29992;&#20110;&#20449;&#24687;&#21644;&#26032;&#38395;&#21487;&#20449;&#24230;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation. (arXiv:2401.10940v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10940
&lt;/p&gt;
&lt;p&gt;
RELIANCE&#26159;&#19968;&#20010;&#21487;&#38752;&#30340;&#38598;&#25104;&#23398;&#20064;&#31995;&#32479;&#65292;&#29992;&#20110;&#35780;&#20272;&#20449;&#24687;&#21644;&#26032;&#38395;&#30340;&#21487;&#20449;&#24230;&#12290;&#23427;&#36890;&#36807;&#25972;&#21512;&#22810;&#20010;&#22522;&#26412;&#27169;&#22411;&#30340;&#20248;&#21183;&#65292;&#25552;&#20379;&#20102;&#23545;&#21487;&#20449;&#21644;&#19981;&#21487;&#20449;&#20449;&#24687;&#28304;&#30340;&#20934;&#30830;&#21306;&#20998;&#65292;&#24182;&#22312;&#20449;&#24687;&#21644;&#26032;&#38395;&#21487;&#20449;&#24230;&#35780;&#20272;&#26041;&#38754;&#20248;&#20110;&#22522;&#20934;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#27867;&#28389;&#30340;&#26102;&#20195;&#65292;&#36776;&#21035;&#26032;&#38395;&#20869;&#23481;&#30340;&#21487;&#20449;&#24230;&#36234;&#26469;&#36234;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;RELIANCE&#65292;&#36825;&#26159;&#19968;&#20010;&#19987;&#20026;&#40065;&#26834;&#20449;&#24687;&#21644;&#34394;&#20551;&#26032;&#38395;&#21487;&#20449;&#24230;&#35780;&#20272;&#32780;&#35774;&#35745;&#30340;&#20808;&#36827;&#30340;&#38598;&#25104;&#23398;&#20064;&#31995;&#32479;&#12290;RELIANCE&#30001;&#20116;&#20010;&#19981;&#21516;&#30340;&#22522;&#26412;&#27169;&#22411;&#32452;&#25104;&#65292;&#21253;&#25324;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#12289;&#26420;&#32032;&#36125;&#21494;&#26031;&#12289;&#36923;&#36753;&#22238;&#24402;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#21452;&#21521;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#65288;BiLSTMs&#65289;&#12290;RELIANCE&#37319;&#29992;&#20102;&#21019;&#26032;&#30340;&#26041;&#27861;&#26469;&#25972;&#21512;&#23427;&#20204;&#30340;&#20248;&#21183;&#65292;&#21033;&#29992;&#38598;&#25104;&#30340;&#26234;&#33021;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;RELIANCE&#22312;&#21306;&#20998;&#21487;&#20449;&#21644;&#19981;&#21487;&#20449;&#20449;&#24687;&#28304;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#65292;&#34920;&#26126;&#20854;&#22312;&#20449;&#24687;&#21644;&#26032;&#38395;&#21487;&#20449;&#24230;&#35780;&#20272;&#26041;&#38754;&#36229;&#36807;&#20102;&#21333;&#20010;&#27169;&#22411;&#65292;&#24182;&#25104;&#20026;&#35780;&#20272;&#20449;&#24687;&#28304;&#21487;&#38752;&#24615;&#30340;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the era of information proliferation, discerning the credibility of news content poses an ever-growing challenge. This paper introduces RELIANCE, a pioneering ensemble learning system designed for robust information and fake news credibility evaluation. Comprising five diverse base models, including Support Vector Machine (SVM), naive Bayes, logistic regression, random forest, and Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs an innovative approach to integrate their strengths, harnessing the collective intelligence of the ensemble for enhanced accuracy. Experiments demonstrate the superiority of RELIANCE over individual models, indicating its efficacy in distinguishing between credible and non-credible information sources. RELIANCE, also surpasses baseline models in information and news credibility assessment, establishing itself as an effective solution for evaluating the reliability of information sources.
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#29992;&#25143;&#20449;&#24687;&#21644;&#33402;&#26415;&#35774;&#35745;&#30340;&#26032;&#30340;&#21019;&#24847;&#29983;&#25104;&#27969;&#31243;&#65292;&#36890;&#36807;&#34701;&#21512;&#29992;&#25143;&#20449;&#24687;&#21644;&#32771;&#34385;&#29992;&#25143;&#29305;&#24449;&#26469;&#39044;&#27979;CTR&#20998;&#25968;&#65292;&#25552;&#20379;&#26356;&#20855;&#21560;&#24341;&#21147;&#30340;&#21019;&#24847;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2401.10934</link><description>&lt;p&gt;
&#19968;&#20010;&#26032;&#30340;&#21019;&#24847;&#29983;&#25104;&#27969;&#31243;&#29992;&#20110;&#28857;&#20987;&#29575;&#31283;&#23450;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model. (arXiv:2401.10934v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10934
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29992;&#25143;&#20449;&#24687;&#21644;&#33402;&#26415;&#35774;&#35745;&#30340;&#26032;&#30340;&#21019;&#24847;&#29983;&#25104;&#27969;&#31243;&#65292;&#36890;&#36807;&#34701;&#21512;&#29992;&#25143;&#20449;&#24687;&#21644;&#32771;&#34385;&#29992;&#25143;&#29305;&#24449;&#26469;&#39044;&#27979;CTR&#20998;&#25968;&#65292;&#25552;&#20379;&#26356;&#20855;&#21560;&#24341;&#21147;&#30340;&#21019;&#24847;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#24191;&#21578;&#30340;&#22330;&#26223;&#20013;&#65292;&#38144;&#21806;&#21830;&#36890;&#24120;&#20250;&#21019;&#24314;&#22810;&#20010;&#21019;&#24847;&#20197;&#25552;&#20379;&#20840;&#38754;&#30340;&#28436;&#31034;&#65292;&#22240;&#27492;&#21576;&#29616;&#20986;&#26368;&#21560;&#24341;&#20154;&#30340;&#35774;&#35745;&#20197;&#26368;&#22823;&#21270;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#38144;&#21806;&#21830;&#36890;&#24120;&#38590;&#20197;&#32771;&#34385;&#29992;&#25143;&#23545;&#21019;&#24847;&#35774;&#35745;&#30340;&#20559;&#22909;&#65292;&#23548;&#33268;&#30456;&#23545;&#20110;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#30340;&#26041;&#27861;&#26469;&#35828;&#65292;&#32654;&#23398;&#21644;&#25968;&#37327;&#37117;&#36739;&#20302;&#12290;&#20256;&#32479;&#30340;&#22522;&#20110;AI&#30340;&#26041;&#27861;&#20173;&#28982;&#38754;&#20020;&#21516;&#26679;&#30340;&#38382;&#39064;&#65292;&#21363;&#27809;&#26377;&#32771;&#34385;&#29992;&#25143;&#20449;&#24687;&#65292;&#21516;&#26102;&#22312;&#35774;&#35745;&#24072;&#30340;&#32654;&#23398;&#30693;&#35782;&#26041;&#38754;&#26377;&#38480;&#12290;&#20107;&#23454;&#19978;&#65292;&#36890;&#36807;&#34701;&#21512;&#29992;&#25143;&#20449;&#24687;&#65292;&#29983;&#25104;&#30340;&#21019;&#24847;&#21487;&#33021;&#26356;&#20855;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#19981;&#21516;&#30340;&#29992;&#25143;&#21487;&#33021;&#26377;&#19981;&#21516;&#30340;&#20559;&#22909;&#12290;&#20026;&#20102;&#20248;&#21270;&#32467;&#26524;&#65292;&#20256;&#32479;&#26041;&#27861;&#20013;&#29983;&#25104;&#30340;&#21019;&#24847;&#20250;&#36890;&#36807;&#21478;&#19968;&#20010;&#34987;&#31216;&#20026;&#21019;&#24847;&#25490;&#21517;&#27169;&#22411;&#30340;&#27169;&#22359;&#36827;&#34892;&#25490;&#24207;&#12290;&#25490;&#21517;&#27169;&#22411;&#21487;&#20197;&#32771;&#34385;&#29992;&#25143;&#29305;&#24449;&#26469;&#39044;&#27979;&#27599;&#20010;&#21019;&#24847;&#30340;CTR&#20998;&#25968;&#12290;&#28982;&#32780;&#65292;&#19978;&#36848;&#30340;&#20004;&#20010;&#38454;&#27573;&#34987;&#35270;&#20026;&#20004;&#20010;&#19981;&#21516;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#30340;&#21019;&#24847;&#21487;&#33021;&#19981;&#22815;&#31934;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online advertising scenario, sellers often create multiple creatives to provide comprehensive demonstrations, making it essential to present the most appealing design to maximize the Click-Through Rate (CTR). However, sellers generally struggle to consider users preferences for creative design, leading to the relatively lower aesthetics and quantities compared to Artificial Intelligence (AI)-based approaches. Traditional AI-based approaches still face the same problem of not considering user information while having limited aesthetic knowledge from designers. In fact that fusing the user information, the generated creatives can be more attractive because different users may have different preferences. To optimize the results, the generated creatives in traditional methods are then ranked by another module named creative ranking model. The ranking model can predict the CTR score for each creative considering user features. However, the two above stages are regarded as two different t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#23454;&#29616;&#31185;&#23398;&#25991;&#29486;&#31995;&#32479;&#32508;&#36848;&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.10917</link><description>&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#23454;&#29616;&#31185;&#23398;&#25991;&#29486;&#31995;&#32479;&#32508;&#36848;&#30340;&#33258;&#21160;&#21270;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence to automate the systematic review of scientific literature. (arXiv:2401.10917v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#23454;&#29616;&#31185;&#23398;&#25991;&#29486;&#31995;&#32479;&#32508;&#36848;&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#22312;&#29616;&#20195;&#35745;&#31639;&#20013;&#21464;&#24471;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#20154;&#20204;&#20256;&#32479;&#19978;&#23436;&#25104;&#30340;&#22797;&#26434;&#20219;&#21153;&#12290;AI&#25552;&#20379;&#20102;&#34920;&#31034;&#21644;&#25512;&#29702;&#30693;&#35782;&#12289;&#39640;&#25928;&#22320;&#22788;&#29702;&#25991;&#26412;&#21644;&#20174;&#22823;&#37327;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#36825;&#20123;&#29305;&#28857;&#36866;&#29992;&#20110;&#35768;&#22810;&#20154;&#31867;&#25214;&#21040;&#36153;&#21147;&#25110;&#37325;&#22797;&#30340;&#27963;&#21160;&#65292;&#27604;&#22914;&#31185;&#23398;&#25991;&#29486;&#30340;&#20998;&#26512;&#12290;&#25163;&#21160;&#20934;&#22791;&#21644;&#25776;&#20889;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65288;SLR&#65289;&#38656;&#35201;&#30456;&#24403;&#38271;&#30340;&#26102;&#38388;&#21644;&#21162;&#21147;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#31574;&#21010;&#19968;&#20010;&#31574;&#30053;&#65292;&#36827;&#34892;&#25991;&#29486;&#25628;&#32034;&#21644;&#20998;&#26512;&#65292;&#24182;&#25253;&#21578;&#32467;&#26524;&#12290;&#26681;&#25454;&#30740;&#31350;&#39046;&#22495;&#30340;&#19981;&#21516;&#65292;&#26816;&#32034;&#21040;&#30340;&#35770;&#25991;&#25968;&#37327;&#21487;&#33021;&#36798;&#21040;&#25968;&#30334;&#25110;&#25968;&#21315;&#31687;&#65292;&#36825;&#24847;&#21619;&#30528;&#36807;&#28388;&#20986;&#30456;&#20851;&#25991;&#29486;&#24182;&#25552;&#21462;&#20851;&#38190;&#20449;&#24687;&#26159;&#19968;&#20010;&#26114;&#36149;&#19988;&#23481;&#26131;&#20986;&#38169;&#30340;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#28041;&#21450;&#30340;&#20219;&#21153;&#26159;&#37325;&#22797;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#36890;&#36807;AI&#33258;&#21160;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence (AI) has acquired notorious relevance in modern computing as it effectively solves complex tasks traditionally done by humans. AI provides methods to represent and infer knowledge, efficiently manipulate texts and learn from vast amount of data. These characteristics are applicable in many activities that human find laborious or repetitive, as is the case of the analysis of scientific literature. Manually preparing and writing a systematic literature review (SLR) takes considerable time and effort, since it requires planning a strategy, conducting the literature search and analysis, and reporting the findings. Depending on the area under study, the number of papers retrieved can be of hundreds or thousands, meaning that filtering those relevant ones and extracting the key information becomes a costly and error-prone process. However, some of the involved tasks are repetitive and, therefore, subject to automation by means of AI. In this paper, we present a survey
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20301;&#32622;&#25935;&#24863;&#23884;&#20837;&#65288;LSE&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20851;&#31995;&#29305;&#23450;&#30340;&#26144;&#23556;&#26469;&#20462;&#25913;&#22836;&#23454;&#20307;&#65292;&#23558;&#20851;&#31995;&#27010;&#24565;&#21270;&#20026;&#32447;&#24615;&#21464;&#25442;&#12290;LSE&#22312;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#39046;&#22495;&#20855;&#26377;&#29702;&#35770;&#22522;&#30784;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26356;&#39640;&#25928;&#30340;&#21464;&#20307;LSEd&#12290;&#23454;&#39564;&#35777;&#26126;LSEd&#22312;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#19978;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.10893</link><description>&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#30340;&#20301;&#32622;&#25935;&#24863;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Location Sensitive Embedding for Knowledge Graph Embedding. (arXiv:2401.10893v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10893
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20301;&#32622;&#25935;&#24863;&#23884;&#20837;&#65288;LSE&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20851;&#31995;&#29305;&#23450;&#30340;&#26144;&#23556;&#26469;&#20462;&#25913;&#22836;&#23454;&#20307;&#65292;&#23558;&#20851;&#31995;&#27010;&#24565;&#21270;&#20026;&#32447;&#24615;&#21464;&#25442;&#12290;LSE&#22312;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#39046;&#22495;&#20855;&#26377;&#29702;&#35770;&#22522;&#30784;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26356;&#39640;&#25928;&#30340;&#21464;&#20307;LSEd&#12290;&#23454;&#39564;&#35777;&#26126;LSEd&#22312;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#19978;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#23558;&#30693;&#35782;&#22270;&#35889;&#36716;&#21270;&#20026;&#36830;&#32493;&#30340;&#12289;&#20302;&#32500;&#24230;&#30340;&#31354;&#38388;&#65292;&#26377;&#21161;&#20110;&#25512;&#29702;&#21644;&#34917;&#20840;&#20219;&#21153;&#12290;&#35813;&#39046;&#22495;&#20027;&#35201;&#20998;&#20026;&#20256;&#32479;&#30340;&#36317;&#31163;&#27169;&#22411;&#21644;&#35821;&#20041;&#21305;&#37197;&#27169;&#22411;&#12290;&#20256;&#32479;&#30340;&#36317;&#31163;&#27169;&#22411;&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#26080;&#27861;&#26377;&#25928;&#21306;&#20998;&#22270;&#35889;&#20013;&#30340;&#8220;&#22836;&#23454;&#20307;&#8221;&#21644;&#8220;&#23614;&#23454;&#20307;&#8221;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#20301;&#32622;&#25935;&#24863;&#23884;&#20837;&#65288;LSE&#65289;&#26041;&#27861;&#12290;LSE&#36890;&#36807;&#20851;&#31995;&#29305;&#23450;&#30340;&#26144;&#23556;&#20462;&#25913;&#22836;&#23454;&#20307;&#65292;&#23558;&#20851;&#31995;&#27010;&#24565;&#21270;&#20026;&#32447;&#24615;&#21464;&#25442;&#32780;&#19981;&#20165;&#20165;&#26159;&#24179;&#31227;&#12290;LSE&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#21253;&#25324;&#20854;&#34920;&#31034;&#33021;&#21147;&#21644;&#19982;&#29616;&#26377;&#27169;&#22411;&#30340;&#32852;&#31995;&#65292;&#37117;&#36827;&#34892;&#20102;&#35814;&#32454;&#30740;&#31350;&#12290;&#19968;&#31181;&#26356;&#31616;&#21270;&#30340;&#21464;&#20307;LSEd&#21033;&#29992;&#23545;&#35282;&#30697;&#38453;&#36827;&#34892;&#21464;&#25442;&#20197;&#25552;&#39640;&#23454;&#29992;&#24615;&#33021;&#12290;&#22312;&#23545;&#22235;&#20010;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#36827;&#34892;&#38142;&#25509;&#39044;&#27979;&#30340;&#27979;&#35797;&#20013;&#65292;LSEd&#35201;&#20040;&#34920;&#29616;&#26356;&#22909;&#65292;&#35201;&#20040;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graph embedding transforms knowledge graphs into a continuous, low-dimensional space, facilitating inference and completion tasks. This field is mainly divided into translational distance models and semantic matching models. A key challenge in translational distance models is their inability to effectively differentiate between 'head' and 'tail' entities in graphs. To address this, the novel location-sensitive embedding (LSE) method has been developed. LSE innovatively modifies the head entity using relation-specific mappings, conceptualizing relations as linear transformations rather than mere translations. The theoretical foundations of LSE, including its representational capabilities and its connections to existing models, have been thoroughly examined. A more streamlined variant, LSEd, employs a diagonal matrix for transformations to enhance practical efficiency. In tests conducted on four large-scale datasets for link prediction, LSEd either outperforms or is competitive
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23558;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;GCN&#65289;&#19982;&#27880;&#24847;&#21147;&#26426;&#21046;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#26469;&#22686;&#24378;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#65292;&#36890;&#36807;&#26816;&#26597;&#23454;&#20307;&#20043;&#38388;&#21450;&#20854;&#37051;&#23621;&#33410;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#20197;&#21450;&#25972;&#21512;&#23454;&#20307;&#30340;&#23646;&#24615;&#21644;&#30456;&#20114;&#20316;&#29992;&#65292;&#29983;&#25104;&#20016;&#23500;&#30340;&#38544;&#24335;&#29305;&#24449;&#21521;&#37327;&#65292;&#20197;&#25552;&#39640;&#23454;&#20307;&#20998;&#31867;&#21644;&#38142;&#25509;&#39044;&#27979;&#31561;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2312.10049</link><description>&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;GCN&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Knowledge Graph Reasoning Based on Attention GCN. (arXiv:2312.10049v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.10049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23558;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;GCN&#65289;&#19982;&#27880;&#24847;&#21147;&#26426;&#21046;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#26469;&#22686;&#24378;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#65292;&#36890;&#36807;&#26816;&#26597;&#23454;&#20307;&#20043;&#38388;&#21450;&#20854;&#37051;&#23621;&#33410;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#20197;&#21450;&#25972;&#21512;&#23454;&#20307;&#30340;&#23646;&#24615;&#21644;&#30456;&#20114;&#20316;&#29992;&#65292;&#29983;&#25104;&#20016;&#23500;&#30340;&#38544;&#24335;&#29305;&#24449;&#21521;&#37327;&#65292;&#20197;&#25552;&#39640;&#23454;&#20307;&#20998;&#31867;&#21644;&#38142;&#25509;&#39044;&#27979;&#31561;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#23558;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;GCN&#65289;&#19982;&#27880;&#24847;&#21147;&#26426;&#21046;&#30456;&#32467;&#21512;&#26469;&#22686;&#24378;&#30693;&#35782;&#22270;&#35889;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#26469;&#26816;&#26597;&#23454;&#20307;&#20043;&#38388;&#21450;&#20854;&#37051;&#23621;&#33410;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20174;&#32780;&#20026;&#27599;&#20010;&#23454;&#20307;&#24320;&#21457;&#35814;&#32454;&#30340;&#29305;&#24449;&#21521;&#37327;&#12290;GCN&#20351;&#29992;&#20849;&#20139;&#21442;&#25968;&#26377;&#25928;&#22320;&#34920;&#31034;&#30456;&#37051;&#23454;&#20307;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#39318;&#20808;&#23398;&#20064;&#23454;&#20307;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#65292;&#20197;&#36827;&#34892;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#12290;&#36890;&#36807;&#25972;&#21512;&#23454;&#20307;&#30340;&#23646;&#24615;&#21644;&#23427;&#20204;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#35813;&#26041;&#27861;&#20026;&#27599;&#20010;&#23454;&#20307;&#29983;&#25104;&#20102;&#20016;&#23500;&#30340;&#38544;&#24335;&#29305;&#24449;&#21521;&#37327;&#65292;&#25552;&#39640;&#20102;&#23454;&#20307;&#20998;&#31867;&#21644;&#38142;&#25509;&#39044;&#27979;&#31561;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;&#24635;&#20043;&#65292;&#36825;&#39033;&#24037;&#20316;&#20026;&#25628;&#32034;&#24341;&#25806;&#12289;&#38382;&#31572;&#31995;&#32479;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#25968;&#25454;&#25972;&#21512;&#20219;&#21153;&#31561;&#22810;&#20010;&#24212;&#29992;&#39046;&#22495;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#26041;&#27861;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel technique to enhance Knowledge Graph Reasoning by combining Graph Convolution Neural Network (GCN) with the Attention Mechanism. This approach utilizes the Attention Mechanism to examine the relationships between entities and their neighboring nodes, which helps to develop detailed feature vectors for each entity. The GCN uses shared parameters to effectively represent the characteristics of adjacent entities. We first learn the similarity of entities for node representation learning. By integrating the attributes of the entities and their interactions, this method generates extensive implicit feature vectors for each entity, improving performance in tasks including entity classification and link prediction, outperforming traditional neural network models. To conclude, this work provides crucial methodological support for a range of applications, such as search engines, question-answering systems, recommendation systems, and data integration tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21407;&#22987;&#25968;&#25454;&#30340;&#20307;&#20869;&#32435;&#31859;&#23610;&#24230;&#23450;&#20301;&#30340;&#20998;&#26512;&#24314;&#27169;&#65292;&#20998;&#26512;&#20102;&#32435;&#31859;&#35774;&#22791;&#30340;&#36890;&#20449;&#21644;&#33021;&#28304;&#32422;&#26463;&#23545;&#23450;&#20301;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.16034</link><description>&lt;p&gt;
&#22522;&#20110;&#21407;&#22987;&#25968;&#25454;&#30340;&#20307;&#20869;&#32435;&#31859;&#23610;&#24230;&#23450;&#20301;&#30340;&#20998;&#26512;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Analytical Modelling of Raw Data for Flow-Guided In-body Nanoscale Localization. (arXiv:2309.16034v1 [cs.ET])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21407;&#22987;&#25968;&#25454;&#30340;&#20307;&#20869;&#32435;&#31859;&#23610;&#24230;&#23450;&#20301;&#30340;&#20998;&#26512;&#24314;&#27169;&#65292;&#20998;&#26512;&#20102;&#32435;&#31859;&#35774;&#22791;&#30340;&#36890;&#20449;&#21644;&#33021;&#28304;&#32422;&#26463;&#23545;&#23450;&#20301;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32435;&#31859;&#25216;&#26415;&#21644;&#26448;&#26009;&#31185;&#23398;&#30340;&#36827;&#23637;&#20026;&#32435;&#31859;&#23610;&#24230;&#35774;&#22791;&#30340;&#21457;&#23637;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#36825;&#20123;&#35774;&#22791;&#32467;&#21512;&#20102;&#20256;&#24863;&#12289;&#35745;&#31639;&#12289;&#25968;&#25454;&#21644;&#33021;&#28304;&#20648;&#23384;&#20197;&#21450;&#26080;&#32447;&#36890;&#20449;&#12290;&#22312;&#31934;&#23494;&#21307;&#23398;&#20013;&#65292;&#36825;&#20123;&#32435;&#31859;&#35774;&#22791;&#23545;&#20110;&#30142;&#30149;&#35786;&#26029;&#12289;&#27835;&#30103;&#21644;&#30417;&#27979;&#21576;&#29616;&#20986;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#32780;&#20307;&#20869;&#32435;&#31859;&#23610;&#24230;&#23450;&#20301;&#30340;&#27969;&#24341;&#23548;&#23450;&#20301;&#65292;&#21363;&#23558;&#25152;&#24863;&#30693;&#30340;&#29983;&#29289;&#20107;&#20214;&#19982;&#20107;&#20214;&#26412;&#36523;&#30340;&#20301;&#32622;&#20851;&#32852;&#36215;&#26469;&#65292;&#20174;&#31934;&#23494;&#21307;&#23398;&#30340;&#35282;&#24230;&#30475;&#23558;&#20855;&#26377;&#26497;&#22823;&#30340;&#30410;&#22788;&#12290;&#32435;&#31859;&#35774;&#22791;&#30340;&#32435;&#31859;&#23610;&#24230;&#29305;&#24615;&#20197;&#21450;&#34880;&#28082;&#27969;&#21160;&#29615;&#22659;&#30340;&#25361;&#25112;&#24615;&#23548;&#33268;&#30446;&#21069;&#30340;&#27969;&#24341;&#23548;&#23450;&#20301;&#26041;&#27861;&#22312;&#36890;&#20449;&#21644;&#33021;&#28304;&#30456;&#20851;&#33021;&#21147;&#26041;&#38754;&#21463;&#21040;&#38480;&#21046;&#12290;&#32435;&#31859;&#35774;&#22791;&#30340;&#36890;&#20449;&#21644;&#33021;&#28304;&#32422;&#26463;&#23548;&#33268;&#27969;&#24341;&#23548;&#23450;&#20301;&#30340;&#21407;&#22987;&#25968;&#25454;&#20855;&#26377;&#19981;&#21516;&#30340;&#29305;&#24449;&#65292;&#20174;&#32780;&#24433;&#21709;&#20854;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#24314;&#27169;&#30740;&#31350;&#20102;&#36825;&#20123;&#19981;&#23436;&#32654;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Advancements in nanotechnology and material science are paving the way toward nanoscale devices that combine sensing, computing, data and energy storage, and wireless communication. In precision medicine, these nanodevices show promise for disease diagnostics, treatment, and monitoring from within the patients' bloodstreams. Assigning the location of a sensed biological event with the event itself, which is the main proposition of flow-guided in-body nanoscale localization, would be immensely beneficial from the perspective of precision medicine. The nanoscale nature of the nanodevices and the challenging environment that the bloodstream represents, result in current flow-guided localization approaches being constrained in their communication and energy-related capabilities. The communication and energy constraints of the nanodevices result in different features of raw data for flow-guided localization, in turn affecting its performance. An analytical modeling of the effects of imperfe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#31616;&#21270;&#31038;&#20132;&#23186;&#20307;&#20449;&#24687;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35782;&#21035;&#21307;&#23398;&#23454;&#20307;&#12289;&#26631;&#20934;&#21270;&#23454;&#20307;&#21644;&#20998;&#37197;UMLS&#27010;&#24565;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;COVID-19&#30456;&#20851;&#25512;&#25991;&#30340;&#30151;&#29366;&#35789;&#20856;&#12290;</title><link>http://arxiv.org/abs/2306.16001</link><description>&lt;p&gt;
&#29992;&#28145;&#24230;&#23398;&#20064;&#31616;&#21270;&#31038;&#20132;&#23186;&#20307;&#20449;&#24687;&#26816;&#32034;&#20197;&#25903;&#25345;&#20844;&#20849;&#21355;&#29983;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning. (arXiv:2306.16001v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#31616;&#21270;&#31038;&#20132;&#23186;&#20307;&#20449;&#24687;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35782;&#21035;&#21307;&#23398;&#23454;&#20307;&#12289;&#26631;&#20934;&#21270;&#23454;&#20307;&#21644;&#20998;&#37197;UMLS&#27010;&#24565;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;COVID-19&#30456;&#20851;&#25512;&#25991;&#30340;&#30151;&#29366;&#35789;&#20856;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#22312;&#27969;&#34892;&#30149;&#30417;&#27979;&#20013;&#30340;&#21033;&#29992;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#35777;&#23454;&#12290;&#28982;&#32780;&#65292;&#24403;&#20351;&#29992;&#39044;&#23450;&#20041;&#30340;&#35789;&#27719;&#34920;&#26469;&#26816;&#32034;&#30456;&#20851;&#35821;&#26009;&#24211;&#26102;&#65292;&#24120;&#24120;&#20250;&#24341;&#20837;&#20559;&#35265;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#26088;&#22312;&#26500;&#24314;&#21307;&#23398;&#20439;&#35821;&#21644;&#32479;&#19968;&#21307;&#23398;&#35821;&#35328;&#31995;&#32479;&#65288;UMLS&#65289;&#27010;&#24565;&#30340;&#24191;&#27867;&#23383;&#20856;&#12290;&#35813;&#26694;&#26550;&#30001;&#19977;&#20010;&#27169;&#22359;&#32452;&#25104;&#65306;&#22522;&#20110;BERT&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#20174;&#31038;&#20132;&#23186;&#20307;&#20869;&#23481;&#20013;&#35782;&#21035;&#20986;&#21307;&#23398;&#23454;&#20307;&#65307;&#28145;&#24230;&#23398;&#20064;&#39537;&#21160;&#30340;&#26631;&#20934;&#21270;&#27169;&#22359;&#65292;&#29992;&#20110;&#23545;&#25552;&#21462;&#20986;&#30340;&#23454;&#20307;&#36827;&#34892;&#35268;&#33539;&#21270;&#22788;&#29702;&#65307;&#21322;&#30417;&#30563;&#32858;&#31867;&#27169;&#22359;&#65292;&#23558;&#26368;&#21487;&#33021;&#30340;UMLS&#27010;&#24565;&#20998;&#37197;&#32473;&#27599;&#20010;&#35268;&#33539;&#21270;&#23454;&#20307;&#12290;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#20174;2020&#24180;2&#26376;1&#26085;&#21040;2022&#24180;4&#26376;30&#26085;&#26399;&#38388;&#19982;COVID-19&#30456;&#20851;&#30340;&#25512;&#25991;&#65292;&#29983;&#25104;&#20102;&#19968;&#20010;&#30151;&#29366;&#35789;&#20856;&#65288;&#21487;&#22312;https://github.com/ningkko/UMLS_colloquialism/&#19978;&#33719;&#21462;&#65289;&#65292;&#20854;&#20013;&#21253;&#21547;9,249&#20010;&#26631;&#20934;&#21270;&#23454;&#20307;&#65292;&#26144;&#23556;&#21040;876&#20010;UMLS&#27010;&#24565;&#21644;38,175&#20010;&#20442;&#35821;&#34920;&#36798;&#12290;&#35813;&#26694;&#26550;&#30340;&#28436;&#31034;
&lt;/p&gt;
&lt;p&gt;
The utilization of social media in epidemic surveillance has been well established. Nonetheless, bias is often introduced when pre-defined lexicons are used to retrieve relevant corpus. This study introduces a framework aimed at curating extensive dictionaries of medical colloquialisms and Unified Medical Language System (UMLS) concepts. The framework comprises three modules: a BERT-based Named Entity Recognition (NER) model that identifies medical entities from social media content, a deep-learning powered normalization module that standardizes the extracted entities, and a semi-supervised clustering module that assigns the most probable UMLS concept to each standardized entity. We applied this framework to COVID-19-related tweets from February 1, 2020, to April 30, 2022, generating a symptom dictionary (available at https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249 standardized entities mapped to 876 UMLS concepts and 38,175 colloquial expressions. This framework demo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#39046;&#22495;&#30693;&#35782;&#30340;&#33647;&#29289;&#25512;&#33616;&#26694;&#26550;DKINet&#65292;&#23558;&#39046;&#22495;&#30693;&#35782;&#19982;&#24739;&#32773;&#20020;&#24202;&#34920;&#29616;&#30456;&#32467;&#21512;&#65292;&#27492;&#20026;&#39318;&#27425;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2305.19604</link><description>&lt;p&gt;
&#36890;&#36807;&#39046;&#22495;&#30693;&#35782;&#21551;&#31034;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#33647;&#29289;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Medication Recommendation via Domain Knowledge Informed Deep Learning. (arXiv:2305.19604v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19604
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#39046;&#22495;&#30693;&#35782;&#30340;&#33647;&#29289;&#25512;&#33616;&#26694;&#26550;DKINet&#65292;&#23558;&#39046;&#22495;&#30693;&#35782;&#19982;&#24739;&#32773;&#20020;&#24202;&#34920;&#29616;&#30456;&#32467;&#21512;&#65292;&#27492;&#20026;&#39318;&#27425;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33647;&#29289;&#25512;&#33616;&#26159;&#21307;&#30103;&#20445;&#20581;&#30340;&#22522;&#26412;&#20294;&#33267;&#20851;&#37325;&#35201;&#30340;&#20998;&#25903;&#65292;&#25552;&#20379;&#26426;&#20250;&#20026;&#22797;&#26434;&#20581;&#24247;&#29366;&#20917;&#30340;&#24739;&#32773;&#25903;&#25345;&#20020;&#24202;&#21307;&#29983;&#26356;&#31934;&#30830;&#30340;&#33647;&#29289;&#22788;&#26041;&#12290;&#20174;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20013;&#23398;&#20064;&#25512;&#33616;&#33647;&#29289;&#26159;&#20808;&#21069;&#30740;&#31350;&#20013;&#26368;&#24120;&#35265;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#24573;&#35270;&#20102;&#26681;&#25454;&#24739;&#32773;&#30340;EHR&#20013;&#30340;&#20020;&#24202;&#34920;&#29616;&#32435;&#20837;&#39046;&#22495;&#30693;&#35782;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#21160;&#24577;&#39046;&#22495;&#30693;&#35782;&#30340;&#33647;&#29289;&#25512;&#33616;&#26694;&#26550;&#65292;&#21363;&#39046;&#22495;&#30693;&#35782;&#21551;&#31034;&#32593;&#32476;&#65288;DKINet&#65289;&#65292;&#29992;&#20110;&#23558;&#39046;&#22495;&#30693;&#35782;&#19982;&#21487;&#35266;&#23519;&#30340;&#24739;&#32773;&#20020;&#24202;&#34920;&#29616;&#30456;&#32467;&#21512;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#39318;&#20808;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#39046;&#22495;&#30693;&#35782;&#30340;&#32534;&#30721;&#22120;&#26469;&#25429;&#25417;&#39046;&#22495;&#20449;&#24687;&#65292;&#28982;&#21518;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#32534;&#30721;&#22120;&#23558;&#39046;&#22495;&#30693;&#35782;&#25972;&#21512;&#21040;&#21487;&#35266;&#23519;&#30340;EHR&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Medication recommendation is a fundamental yet crucial branch of healthcare, which provides opportunities to support clinical physicians with more accurate medication prescriptions for patients with complex health conditions. Learning from electronic health records (EHR) to recommend medications is the most common way in previous studies. However, most of them neglect incorporating domain knowledge according to the clinical manifestations in the EHR of the patient. To address these issues, we propose a novel \textbf{D}omain \textbf{K}nowledge \textbf{I}nformed \textbf{Net}work (DKINet) to integrate domain knowledge with observable clinical manifestations of the patient, which is the first dynamic domain knowledge informed framework toward medication recommendation. In particular, we first design a knowledge-driven encoder to capture the domain information and then develop a data-driven encoder to integrate domain knowledge into the observable EHR. To endow the model with the capability
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GPT-3&#21644;GPT-4&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#34920;&#29616;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#21487;&#33021;&#20135;&#29983;&#30340;&#38169;&#35823;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2305.16326</link><description>&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#22522;&#20934;&#12289;&#22522;&#32447;&#21644;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GPT-3&#21644;GPT-4&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#34920;&#29616;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#21487;&#33021;&#20135;&#29983;&#30340;&#38169;&#35823;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#25163;&#21160;&#31579;&#36873;&#21644;&#25552;&#21462;&#30693;&#35782;&#21464;&#24471;&#22256;&#38590;&#12290;&#33258;&#21160;&#20174;&#29983;&#29289;&#21307;&#23398;&#25991;&#29486;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;BioNLP&#65289;&#25216;&#26415;&#26377;&#21161;&#20110;&#20943;&#36731;&#36825;&#31181;&#36127;&#25285;&#12290;&#36817;&#24180;&#26469;&#65292;&#22914;GPT-3&#21644;GPT-4&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22240;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#32780;&#21463;&#21040;&#37325;&#35270;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#22312;BioNLP&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#23545;&#26041;&#27861;&#24320;&#21457;&#21644;&#19979;&#28216;&#29992;&#25143;&#30340;&#24433;&#21709;&#20173;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#65288;1&#65289;&#22312;&#22235;&#20010;&#24212;&#29992;&#31243;&#24207;&#20013;&#22312;&#20843;&#20010;BioNLP&#25968;&#25454;&#38598;&#20013;&#24314;&#31435;&#20102;GPT-3&#21644;GPT-4&#22312;&#38646;-shot&#21644;&#19968;-shot&#35774;&#32622;&#19979;&#30340;&#22522;&#20934;&#34920;&#29616;&#65292;&#21253;&#25324;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65292;&#20851;&#31995;&#25552;&#21462;&#65292;&#22810;&#26631;&#31614;&#25991;&#26723;&#20998;&#31867;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#21644;&#25512;&#29702;&#65307;&#65288;2&#65289;&#23457;&#26597;&#20102;LLMs&#20135;&#29983;&#30340;&#38169;&#35823;&#65292;&#24182;&#23558;&#38169;&#35823;&#20998;&#20026;&#19977;&#31181;&#31867;&#22411;&#65306;&#32570;&#22833;&#65292;&#19981;&#19968;&#33268;&#21644;&#19981;&#38656;&#35201;&#30340;&#20154;&#24037;&#20869;&#23481;&#65307;&#65288;3&#65289;&#25552;&#20986;&#20102;&#20351;&#29992;LLMs&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;ODE&#30340;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#25512;&#33616;&#26694;&#26550;GDERec&#65292;&#23427;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#22270;&#21367;&#31215;&#32593;&#32476;&#35299;&#20915;&#21327;&#20316;&#20449;&#21495;&#28436;&#21270;&#21644;&#19981;&#35268;&#21017;&#37319;&#26679;&#38382;&#39064;&#65292;&#24182;&#22312;&#22235;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.07042</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#25512;&#33616;&#20013;&#30340;&#22270;ODE&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning Graph ODE for Continuous-Time Sequential Recommendation. (arXiv:2304.07042v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07042
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;ODE&#30340;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#25512;&#33616;&#26694;&#26550;GDERec&#65292;&#23427;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#22270;&#21367;&#31215;&#32593;&#32476;&#35299;&#20915;&#21327;&#20316;&#20449;&#21495;&#28436;&#21270;&#21644;&#19981;&#35268;&#21017;&#37319;&#26679;&#38382;&#39064;&#65292;&#24182;&#22312;&#22235;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#25512;&#33616;&#26088;&#22312;&#36890;&#36807;&#25429;&#33719;&#29992;&#25143;&#36807;&#21435;&#20132;&#20114;&#20013;&#30340;&#39033;&#36141;&#20080;&#24207;&#21015;&#65292;&#29702;&#35299;&#29992;&#25143;&#30340;&#20559;&#22909;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#36890;&#36807;&#24314;&#27169;&#39034;&#24207;&#27169;&#24335;&#26469;&#39044;&#27979;&#19979;&#19968;&#20010;&#39033;&#30446;&#12290;&#23613;&#31649;&#26377;&#25928;&#65292;&#28982;&#32780;&#23384;&#22312;&#20004;&#20010;&#22825;&#28982;&#19981;&#36275;&#65306;&#65288;i&#65289;&#29992;&#25143;&#20559;&#22909;&#20855;&#26377;&#21160;&#24577;&#24615;&#65292;&#24182;&#19988;&#32463;&#24120;&#24573;&#30053;&#21327;&#20316;&#20449;&#21495;&#30340;&#28436;&#21270;&#65307;&#65288;ii&#65289;&#35266;&#23519;&#21040;&#30340;&#20132;&#20114;&#36890;&#24120;&#26159;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#65292;&#32780;&#29616;&#26377;&#26041;&#27861;&#21017;&#20551;&#35774;&#22343;&#21248;&#38388;&#38548;&#26469;&#36827;&#34892;&#39033;&#30446;&#36716;&#25442;&#24314;&#27169;&#12290;&#22240;&#27492;&#65292;&#22914;&#20309;&#26377;&#25928;&#22320;&#23545;&#29992;&#25143;&#20559;&#22909;&#30340;&#22522;&#30784;&#21160;&#24577;&#24314;&#27169;&#21644;&#39044;&#27979;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#65292;&#26412;&#25991;&#20851;&#27880;&#20110;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#25512;&#33616;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#27491;&#21017;&#24494;&#20998;&#26041;&#31243;&#65288;graph ordinary differential equation, GDERec&#65289;&#30340;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#25512;&#33616;&#26694;&#26550;&#12290;&#25216;&#26415;&#19978;&#65292;GDERec&#30001;&#19968;&#20010;&#33258;&#22238;&#24402;&#22270;&#27491;&#21017;&#24494;&#20998;&#26041;&#31243;&#32452;&#25104;&#65292;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#22270;&#21367;&#31215;&#32593;&#32476;&#26469;&#24314;&#27169;&#39033;&#36716;&#31227;&#21160;&#24577;&#12290;&#22312;&#22235;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;GDERec&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#36830;&#32493;&#26102;&#38388;&#29992;&#25143;&#20559;&#22909;&#21160;&#24577;&#30340;&#21487;&#35299;&#37322;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation aims at understanding user preference by capturing successive behavior correlations, which are usually represented as the item purchasing sequences based on their past interactions. Existing efforts generally predict the next item via modeling the sequential patterns. Despite effectiveness, there exist two natural deficiencies: (i) user preference is dynamic in nature, and the evolution of collaborative signals is often ignored; and (ii) the observed interactions are often irregularly-sampled, while existing methods model item transitions assuming uniform intervals. Thus, how to effectively model and predict the underlying dynamics for user preference becomes a critical research problem. To tackle the above challenges, in this paper, we focus on continuous-time sequential recommendation and propose a principled graph ordinary differential equation framework named GDERec. Technically, GDERec is characterized by an autoregressive graph ordinary differential equa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36138;&#24515;&#31574;&#30053;&#30340;&#36335;&#32447;&#25512;&#33616;&#26041;&#27861;&#65292;&#21487;&#20197;&#22686;&#21152;&#36710;&#36742;&#21033;&#29992;&#29575;&#65292;&#32531;&#35299;&#25340;&#36710;&#26381;&#21153;&#23545;&#29615;&#22659;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.01225</link><description>&lt;p&gt;
&#22522;&#20110;&#36138;&#24515;&#31574;&#30053;&#25552;&#39640;&#25340;&#36710;&#32593;&#32476;&#20013;&#30340;&#36710;&#36742;&#21033;&#29992;&#29575;
&lt;/p&gt;
&lt;p&gt;
A greedy approach for increased vehicle utilization in ridesharing networks. (arXiv:2304.01225v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36138;&#24515;&#31574;&#30053;&#30340;&#36335;&#32447;&#25512;&#33616;&#26041;&#27861;&#65292;&#21487;&#20197;&#22686;&#21152;&#36710;&#36742;&#21033;&#29992;&#29575;&#65292;&#32531;&#35299;&#25340;&#36710;&#26381;&#21153;&#23545;&#29615;&#22659;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#25340;&#36710;&#24179;&#21488;&#24050;&#25104;&#20026;&#22478;&#24066;&#23621;&#27665;&#30340;&#20027;&#35201;&#20132;&#36890;&#26041;&#24335;&#12290;&#23545;&#20110;&#36825;&#20123;&#24179;&#21488;&#26469;&#35762;&#65292;&#36335;&#32447;&#25512;&#33616;&#26159;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#24050;&#32463;&#24314;&#35758;&#20102;&#20855;&#26377;&#26356;&#39640;&#20056;&#23458;&#38656;&#27714;&#30340;&#36335;&#32447;&#12290;&#28982;&#32780;&#65292;&#32479;&#35745;&#25968;&#25454;&#34920;&#26126;&#65292;&#19982;&#31169;&#20154;&#36710;&#36742;&#30456;&#27604;&#65292;&#36825;&#20123;&#26381;&#21153;&#20250;&#23548;&#33268;&#22686;&#21152;&#28201;&#23460;&#27668;&#20307;&#25490;&#25918;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#23547;&#25214;&#20056;&#23458;&#26102;&#22235;&#22788;&#28459;&#28216;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25340;&#36710;&#31995;&#32479;&#21151;&#33021;&#30340;&#26356;&#35814;&#32454;&#32454;&#33410;&#65292;&#24182;&#25581;&#31034;&#20102;&#22312;&#25340;&#36710;&#31995;&#32479;&#34028;&#21187;&#21457;&#23637;&#30340;&#24773;&#20917;&#19979;&#23427;&#20204;&#24182;&#26410;&#26377;&#25928;&#22320;&#21033;&#29992;&#36710;&#36742;&#23481;&#37327;&#12290;&#25105;&#20204;&#24314;&#35758;&#20811;&#26381;&#20197;&#19978;&#38480;&#21046;&#65292;&#24182;&#25512;&#33616;&#21516;&#26102;&#33719;&#21462;&#22810;&#20010;&#20056;&#23458;&#30340;&#36335;&#32447;&#65292;&#20174;&#32780;&#22686;&#21152;&#36710;&#36742;&#21033;&#29992;&#29575;&#65292;&#20174;&#32780;&#20943;&#23569;&#36825;&#20123;&#31995;&#32479;&#23545;&#29615;&#22659;&#30340;&#24433;&#21709;&#12290;&#30001;&#20110;&#36335;&#32447;&#25512;&#33616;&#26159;NP-hard&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;k&#36339;&#30340;&#28369;&#21160;&#31383;&#21475;&#36817;&#20284;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, ridesharing platforms have become a prominent mode of transportation for the residents of urban areas. As a fundamental problem, route recommendation for these platforms is vital for their sustenance. The works done in this direction have recommended routes with higher passenger demand. Despite the existing works, statistics have suggested that these services cause increased greenhouse emissions compared to private vehicles as they roam around in search of riders. This analysis provides finer details regarding the functionality of ridesharing systems and it reveals that in the face of their boom, they have not utilized the vehicle capacity efficiently. We propose to overcome the above limitations and recommend routes that will fetch multiple passengers simultaneously which will result in increased vehicle utilization and thereby decrease the effect of these systems on the environment. As route recommendation is NP-hard, we propose a k-hop-based sliding window approxima
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#30740;&#20102;&#32467;&#26500;&#21270;&#25968;&#25454;&#20998;&#23618;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#65288;LSH&#65289;&#30340;&#30740;&#31350;&#29616;&#29366;&#65292;&#38024;&#23545;&#26080;&#27861;&#20445;&#30041;&#32467;&#26500;&#20449;&#24687;&#30340;&#20256;&#32479;LSH&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2204.11209</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#20998;&#23618;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#65306;&#19968;&#39033;&#35843;&#30740;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Locality Sensitive Hashing for Structured Data: A Survey. (arXiv:2204.11209v3 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.11209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#30740;&#20102;&#32467;&#26500;&#21270;&#25968;&#25454;&#20998;&#23618;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#65288;LSH&#65289;&#30340;&#30740;&#31350;&#29616;&#29366;&#65292;&#38024;&#23545;&#26080;&#27861;&#20445;&#30041;&#32467;&#26500;&#20449;&#24687;&#30340;&#20256;&#32479;LSH&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#30456;&#20284;&#24615;&#65288;&#25110;&#36317;&#31163;&#65289;&#35745;&#31639;&#26159;&#19968;&#20010;&#22522;&#30784;&#30340;&#30740;&#31350;&#35838;&#39064;&#65292;&#20419;&#36827;&#20102;&#35768;&#22810;&#22522;&#20110;&#30456;&#20284;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#25366;&#25496;&#24212;&#29992;&#12290;&#22312;&#22823;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#30001;&#20110;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#35745;&#31639;&#25968;&#25454;&#23454;&#20363;&#30340;&#31934;&#30830;&#30456;&#20284;&#24615;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#20026;&#27492;&#65292;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#65288;LSH&#65289;&#25216;&#26415;&#24050;&#34987;&#25552;&#20986;&#65292;&#20197;&#22312;&#27809;&#26377;&#23398;&#20064;&#36807;&#31243;&#30340;&#24773;&#20917;&#19979;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#25552;&#20379;&#21508;&#31181;&#38598;&#21512;&#25110;&#21521;&#37327;&#20043;&#38388;&#30340;&#21508;&#31181;&#30456;&#20284;&#24230;&#20272;&#35745;&#22120;&#12290;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#20363;&#22914;&#24207;&#21015;&#12289;&#26641;&#21644;&#22270;&#65289;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#24456;&#24120;&#35265;&#65292;&#20294;&#20256;&#32479;&#30340;LSH&#31639;&#27861;&#26080;&#27861;&#20445;&#30041;&#34920;&#31034;&#20803;&#32032;&#20043;&#38388;&#20851;&#31995;&#30340;&#32467;&#26500;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#19968;&#30452;&#33268;&#21147;&#20110;&#20998;&#23618;LSH&#31639;&#27861;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20998;&#23618;LSH&#30740;&#31350;&#30340;&#29616;&#26377;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data similarity (or distance) computation is a fundamental research topic which fosters a variety of similarity-based machine learning and data mining applications. In big data analytics, it is impractical to compute the exact similarity of data instances due to high computational cost. To this end, the Locality Sensitive Hashing (LSH) technique has been proposed to provide accurate estimators for various similarity measures between sets or vectors in an efficient manner without the learning process. Structured data (e.g., sequences, trees and graphs), which are composed of elements and relations between the elements, are commonly seen in the real world, but the traditional LSH algorithms cannot preserve the structure information represented as relations between elements. In order to conquer the issue, researchers have been devoted to the family of the hierarchical LSH algorithms. In this paper, we explore the present progress of the research into hierarchical LSH from the following pe
&lt;/p&gt;</description></item></channel></rss>