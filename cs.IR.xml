<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#22235;&#20010;&#27969;&#34892;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#30340;&#21487;&#39564;&#35777;&#24615;&#65292;&#21457;&#29616;&#29616;&#26377;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#21709;&#24212;&#27969;&#30021;&#20294;&#20165;&#26377;51.5%&#30340;&#29983;&#25104;&#21477;&#23376;&#24471;&#21040;&#20102;&#23436;&#25972;&#30340;&#24341;&#29992;&#25903;&#25345;&#65292;&#20165;&#26377;74.5%&#30340;&#24341;&#29992;&#25903;&#25345;&#20854;&#30456;&#20851;&#35821;&#21477;&#12290;</title><link>http://arxiv.org/abs/2304.09848</link><description>&lt;p&gt;
&#35780;&#20272;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#21487;&#39564;&#35777;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating Verifiability in Generative Search Engines. (arXiv:2304.09848v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#22235;&#20010;&#27969;&#34892;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#30340;&#21487;&#39564;&#35777;&#24615;&#65292;&#21457;&#29616;&#29616;&#26377;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#21709;&#24212;&#27969;&#30021;&#20294;&#20165;&#26377;51.5%&#30340;&#29983;&#25104;&#21477;&#23376;&#24471;&#21040;&#20102;&#23436;&#25972;&#30340;&#24341;&#29992;&#25903;&#25345;&#65292;&#20165;&#26377;74.5%&#30340;&#24341;&#29992;&#25903;&#25345;&#20854;&#30456;&#20851;&#35821;&#21477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#30452;&#25509;&#20026;&#29992;&#25143;&#26597;&#35810;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#25552;&#20379;&#20869;&#32852;&#24341;&#29992;&#12290;&#19968;&#20010;&#20540;&#24471;&#20449;&#36182;&#30340;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#30340;&#20808;&#20915;&#26465;&#20214;&#26159;&#21487;&#39564;&#35777;&#24615;&#65292;&#21363;&#31995;&#32479;&#24212;&#20840;&#38754;&#24341;&#29992;&#65288;&#39640;&#24341;&#29992;&#22238;&#24518;&#29575;&#65292;&#25152;&#26377;&#35821;&#21477;&#37117;&#26377;&#23436;&#25972;&#30340;&#24341;&#29992;&#25903;&#25345;&#65289;&#21644;&#20934;&#30830;&#65288;&#39640;&#24341;&#29992;&#31934;&#24230;&#65292;&#27599;&#20010;&#24341;&#29992;&#37117;&#25903;&#25345;&#20854;&#30456;&#20851;&#35821;&#21477;&#65289;&#12290;&#25105;&#20204;&#23545;&#22235;&#20010;&#27969;&#34892;&#30340;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#8212;&#8212;Bing Chat&#12289;NeevaAI&#12289;perplexity.ai&#21644;YouChat&#8212;&#8212;&#36827;&#34892;&#20102;&#20154;&#31867;&#35780;&#20272;&#65292;&#28085;&#30422;&#20102;&#21508;&#31181;&#26469;&#28304;&#30340;&#22810;&#26679;&#21270;&#26597;&#35810;&#65288;&#20363;&#22914;&#21382;&#21490;&#19978;&#30340;Google&#29992;&#25143;&#26597;&#35810;&#12289;Reddit&#19978;&#21160;&#24577;&#25910;&#38598;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#31561;&#65289;&#12290;&#25105;&#20204;&#21457;&#29616;&#29616;&#26377;&#30340;&#29983;&#25104;&#24335;&#25628;&#32034;&#24341;&#25806;&#21709;&#24212;&#27969;&#30021;&#19988;&#20449;&#24687;&#20016;&#23500;&#65292;&#20294;&#24120;&#24120;&#21253;&#21547;&#19981;&#25903;&#25345;&#30340;&#35821;&#21477;&#21644;&#19981;&#20934;&#30830;&#30340;&#24341;&#29992;&#65306;&#24179;&#22343;&#32780;&#35328;&#65292;&#20165;&#26377;51.5%&#30340;&#29983;&#25104;&#21477;&#23376;&#24471;&#21040;&#20102;&#23436;&#25972;&#30340;&#24341;&#29992;&#25903;&#25345;&#65292;&#21482;&#26377;74.5%&#30340;&#24341;&#29992;&#25903;&#25345;&#20854;&#30456;&#20851;&#35821;&#21477;&#12290;&#25105;&#20204;&#35748;&#20026;...
&lt;/p&gt;
&lt;p&gt;
Generative search engines directly generate responses to user queries, along with in-line citations. A prerequisite trait of a trustworthy generative search engine is verifiability, i.e., systems should cite comprehensively (high citation recall; all statements are fully supported by citations) and accurately (high citation precision; every cite supports its associated statement). We conduct human evaluation to audit four popular generative search engines -- Bing Chat, NeevaAI, perplexity.ai, and YouChat -- across a diverse set of queries from a variety of sources (e.g., historical Google user queries, dynamically-collected open-ended questions on Reddit, etc.). We find that responses from existing generative search engines are fluent and appear informative, but frequently contain unsupported statements and inaccurate citations: on average, a mere 51.5% of generated sentences are fully supported by citations and only 74.5% of citations support their associated sentence. We believe that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20197;Booking.com&#20026;&#22522;&#30784;&#65292;&#20197;&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#20026;&#30740;&#31350;&#65292;&#23637;&#31034;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#28040;&#36153;&#32773;&#20010;&#20154;&#25968;&#25454;&#65292;&#24182;&#35752;&#35770;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#26412;&#26696;&#20363;&#30740;&#31350;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2304.09603</link><description>&lt;p&gt;
&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#65306;&#20197;Booking.com&#20026;&#20363;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Visualising Personal Data Flows: Insights from a Case Study of Booking.com. (arXiv:2304.09603v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;Booking.com&#20026;&#22522;&#30784;&#65292;&#20197;&#21487;&#35270;&#21270;&#20010;&#20154;&#25968;&#25454;&#27969;&#20026;&#30740;&#31350;&#65292;&#23637;&#31034;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#28040;&#36153;&#32773;&#20010;&#20154;&#25968;&#25454;&#65292;&#24182;&#35752;&#35770;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#26412;&#26696;&#20363;&#30740;&#31350;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21830;&#19994;&#26426;&#26500;&#25345;&#26377;&#21644;&#22788;&#29702;&#30340;&#20010;&#20154;&#25968;&#25454;&#37327;&#36234;&#26469;&#36234;&#22810;&#12290;&#25919;&#31574;&#21644;&#27861;&#24459;&#19981;&#26029;&#21464;&#21270;&#65292;&#35201;&#27714;&#36825;&#20123;&#20844;&#21496;&#22312;&#25910;&#38598;&#12289;&#23384;&#20648;&#12289;&#22788;&#29702;&#21644;&#20849;&#20139;&#36825;&#20123;&#25968;&#25454;&#26041;&#38754;&#26356;&#21152;&#36879;&#26126;&#12290;&#26412;&#25991;&#25253;&#21578;&#20102;&#25105;&#20204;&#20197;Booking.com&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#20174;&#20182;&#20204;&#30340;&#38544;&#31169;&#25919;&#31574;&#20013;&#25552;&#21462;&#20010;&#20154;&#25968;&#25454;&#27969;&#30340;&#21487;&#35270;&#21270;&#24037;&#20316;&#12290;&#36890;&#36807;&#23637;&#31034;&#35813;&#20844;&#21496;&#22914;&#20309;&#20998;&#20139;&#20854;&#28040;&#36153;&#32773;&#30340;&#20010;&#20154;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38382;&#39064;&#65292;&#24182;&#25193;&#23637;&#20102;&#26377;&#20851;&#20351;&#29992;&#38544;&#31169;&#25919;&#31574;&#21578;&#30693;&#23458;&#25143;&#20010;&#20154;&#25968;&#25454;&#27969;&#33539;&#22260;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#30340;&#35752;&#35770;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#26412;&#26696;&#20363;&#30740;&#31350;&#21487;&#20197;&#20026;&#26410;&#26469;&#26356;&#20197;&#25968;&#25454;&#27969;&#20026;&#23548;&#21521;&#30340;&#38544;&#31169;&#25919;&#31574;&#20998;&#26512;&#21644;&#22312;&#22797;&#26434;&#21830;&#19994;&#29983;&#24577;&#31995;&#32479;&#20013;&#24314;&#31435;&#26356;&#20840;&#38754;&#30340;&#20010;&#20154;&#25968;&#25454;&#27969;&#26412;&#20307;&#35770;&#30340;&#30740;&#31350;&#25552;&#20379;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
Commercial organisations are holding and processing an ever-increasing amount of personal data. Policies and laws are continually changing to require these companies to be more transparent regarding collection, storage, processing and sharing of this data. This paper reports our work of taking Booking.com as a case study to visualise personal data flows extracted from their privacy policy. By showcasing how the company shares its consumers' personal data, we raise questions and extend discussions on the challenges and limitations of using privacy policy to inform customers the true scale and landscape of personal data flows. More importantly, this case study can inform us about future research on more data flow-oriented privacy policy analysis and on the construction of a more comprehensive ontology on personal data flows in complicated business ecosystems.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#20154;&#30693;&#35782;&#22270;&#35889;&#65288;PKG&#65289;&#30340;&#29983;&#24577;&#31995;&#32479;&#65292;PKG&#30340;&#20027;&#35201;&#30446;&#30340;&#26159;&#25968;&#25454;&#31649;&#29702;&#21644;&#20010;&#24615;&#21270;&#26381;&#21153;&#12290;&#35201;&#35299;&#38145;PKG&#30340;&#20840;&#37096;&#28508;&#21147;&#65292;&#38656;&#35201;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;PKG&#30340;&#32508;&#21512;&#35270;&#22270;&#12290;</title><link>http://arxiv.org/abs/2304.09572</link><description>&lt;p&gt;
&#20010;&#20154;&#30693;&#35782;&#22270;&#35889;&#29983;&#24577;&#31995;&#32479;&#65306;&#35843;&#26597;&#19982;&#30740;&#31350;&#36335;&#32447;&#22270;
&lt;/p&gt;
&lt;p&gt;
An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap. (arXiv:2304.09572v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#20154;&#30693;&#35782;&#22270;&#35889;&#65288;PKG&#65289;&#30340;&#29983;&#24577;&#31995;&#32479;&#65292;PKG&#30340;&#20027;&#35201;&#30446;&#30340;&#26159;&#25968;&#25454;&#31649;&#29702;&#21644;&#20010;&#24615;&#21270;&#26381;&#21153;&#12290;&#35201;&#35299;&#38145;PKG&#30340;&#20840;&#37096;&#28508;&#21147;&#65292;&#38656;&#35201;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;PKG&#30340;&#32508;&#21512;&#35270;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#20154;&#30693;&#35782;&#22270;&#35889;&#65288;PKG&#65289;&#30340;&#29983;&#24577;&#31995;&#32479;&#65292;&#36890;&#24120;&#23450;&#20041;&#20026;&#26377;&#20851;&#20010;&#20154;&#30456;&#20851;&#23454;&#20307;&#12289;&#20854;&#23646;&#24615;&#21644;&#23427;&#20204;&#20043;&#38388;&#20851;&#31995;&#30340;&#32467;&#26500;&#21270;&#20449;&#24687;&#36164;&#28304;&#12290;PKG&#26159;&#23433;&#20840;&#12289;&#31934;&#23494;&#30340;&#20010;&#20154;&#25968;&#25454;&#31649;&#29702;&#21644;&#20010;&#24615;&#21270;&#26381;&#21153;&#30340;&#20851;&#38190;&#25903;&#25345;&#12290;&#28982;&#32780;&#65292;&#22312;PKG&#33021;&#22815;&#24191;&#27867;&#24212;&#29992;&#20043;&#21069;&#38656;&#35201;&#35299;&#20915;&#19968;&#20123;&#25361;&#25112;&#12290;&#20854;&#20013;&#19968;&#20010;&#22522;&#26412;&#25361;&#25112;&#26159;&#20851;&#20110;PKG&#30340;&#23450;&#20041;&#65292;&#22240;&#20026;&#26415;&#35821;&#26377;&#22810;&#31181;&#35299;&#37322;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#24049;&#30340;PKG&#23450;&#20041;&#65292;&#24378;&#35843;&#20102;&#65288;1&#65289;&#21333;&#20010;&#20010;&#20307;&#25317;&#26377;&#25968;&#25454;&#21644;&#65288;2&#65289;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#20316;&#20026;&#20027;&#35201;&#30446;&#30340;&#30340;&#26041;&#38754;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;PKG&#35270;&#22270;&#65292;&#38656;&#35201;&#35299;&#38145;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;PKG&#26159;&#26356;&#22823;&#30340;&#29983;&#24577;&#31995;&#32479;&#30340;&#19968;&#37096;&#20998;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#19982;&#25968;&#25454;&#26381;&#21153;&#21644;&#25968;&#25454;&#28304;&#30340;&#25509;&#21475;&#12290;&#26412;&#25991;&#36824;&#23637;&#31034;&#20102;&#23545;&#24403;&#21069;PKG&#30740;&#31350;&#30340;&#20840;&#38754;&#35843;&#26597;&#21644;&#30740;&#31350;&#36335;&#32447;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents an ecosystem for personal knowledge graphs (PKG), commonly defined as resources of structured information about entities related to an individual, their attributes, and the relations between them. PKGs are a key enabler of secure and sophisticated personal data management and personalized services. However, there are challenges that need to be addressed before PKGs can achieve widespread adoption. One of the fundamental challenges is the very definition of what constitutes a PKG, as there are multiple interpretations of the term. We propose our own definition of a PKG, emphasizing the aspects of (1) data ownership by a single individual and (2) the delivery of personalized services as the primary purpose. We further argue that a holistic view of PKGs is needed to unlock their full potential, and propose a unified framework for PKGs, where the PKG is a part of a larger ecosystem with clear interfaces towards data services and data sources. A comprehensive survey and 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31163;&#32447;&#35780;&#20272;&#28857;&#20987;&#27169;&#22411;&#21435;&#21327;&#21464;&#20559;&#31227;&#30340;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#21435;&#20559;&#24046;&#24615;&#36825;&#19968;&#27010;&#24565;&#21644;&#27979;&#37327;&#26041;&#27861;&#65292;&#36825;&#26159;&#24674;&#22797;&#26080;&#20559;&#19968;&#33268;&#30456;&#20851;&#24615;&#35780;&#20998;&#21644;&#28857;&#20987;&#27169;&#22411;&#23545;&#25490;&#21517;&#20998;&#24067;&#21464;&#21270;&#19981;&#21464;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2304.09560</link><description>&lt;p&gt;
&#31163;&#32447;&#24230;&#37327;&#28857;&#20987;&#27169;&#22411;&#30340;&#21435;&#20559;&#24046;&#24615;
&lt;/p&gt;
&lt;p&gt;
An Offline Metric for the Debiasedness of Click Models. (arXiv:2304.09560v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31163;&#32447;&#35780;&#20272;&#28857;&#20987;&#27169;&#22411;&#21435;&#21327;&#21464;&#20559;&#31227;&#30340;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#21435;&#20559;&#24046;&#24615;&#36825;&#19968;&#27010;&#24565;&#21644;&#27979;&#37327;&#26041;&#27861;&#65292;&#36825;&#26159;&#24674;&#22797;&#26080;&#20559;&#19968;&#33268;&#30456;&#20851;&#24615;&#35780;&#20998;&#21644;&#28857;&#20987;&#27169;&#22411;&#23545;&#25490;&#21517;&#20998;&#24067;&#21464;&#21270;&#19981;&#21464;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#29992;&#25143;&#28857;&#20987;&#26102;&#65292;&#22266;&#26377;&#20559;&#35265;&#26159;&#25968;&#25454;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#19968;&#20010;&#38382;&#39064;&#65292;&#20363;&#22914;&#20301;&#32622;&#20559;&#35265;&#25110;&#20449;&#20219;&#20559;&#35265;&#12290;&#28857;&#20987;&#27169;&#22411;&#26159;&#20174;&#29992;&#25143;&#28857;&#20987;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#24120;&#29992;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;Web&#25628;&#32034;&#20013;&#25552;&#21462;&#25991;&#26723;&#30456;&#20851;&#24615;&#65292;&#25110;&#32773;&#20272;&#35745;&#28857;&#20987;&#20559;&#24046;&#20197;&#29992;&#20110;&#19979;&#28216;&#24212;&#29992;&#65292;&#20363;&#22914;&#21453;&#20107;&#23454;&#30340;&#23398;&#20064;&#25490;&#24207;&#12289;&#24191;&#21578;&#20301;&#32622;&#21644;&#20844;&#24179;&#25490;&#24207;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#31038;&#21306;&#20013;&#30340;&#24403;&#21069;&#35780;&#20272;&#23454;&#36341;&#19981;&#33021;&#20445;&#35777;&#24615;&#33021;&#33391;&#22909;&#30340;&#28857;&#20987;&#27169;&#22411;&#23545;&#20110;&#19979;&#28216;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20854;&#20013;&#25490;&#21517;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#65292;&#21363;&#22312;&#21327;&#21464;&#20559;&#31227;&#19979;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#35780;&#20272;&#24230;&#37327;&#65292;&#20197;&#26816;&#27979;&#28857;&#20987;&#27169;&#22411;&#23545;&#21327;&#21464;&#20559;&#31227;&#30340;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#24615;&#30340;&#27010;&#24565;&#21644;&#19968;&#31181;&#27979;&#37327;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21435;&#20559;&#24046;&#24615;&#26159;&#24674;&#22797;&#26080;&#20559;&#30340;&#19968;&#33268;&#30456;&#20851;&#24615;&#35780;&#20998;&#20197;&#21450;&#20351;&#28857;&#20987;&#27169;&#22411;&#23545;&#25490;&#21517;&#20998;&#24067;&#21464;&#21270;&#30340;&#19981;&#21464;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
A well-known problem when learning from user clicks are inherent biases prevalent in the data, such as position or trust bias. Click models are a common method for extracting information from user clicks, such as document relevance in web search, or to estimate click biases for downstream applications such as counterfactual learning-to-rank, ad placement, or fair ranking. Recent work shows that the current evaluation practices in the community fail to guarantee that a well-performing click model generalizes well to downstream tasks in which the ranking distribution differs from the training distribution, i.e., under covariate shift. In this work, we propose an evaluation metric based on conditional independence testing to detect a lack of robustness to covariate shift in click models. We introduce the concept of debiasedness and a metric for measuring it. We prove that debiasedness is a necessary condition for recovering unbiased and consistent relevance scores and for the invariance o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#24615;LLMs&#65292;&#22914;ChatGPT&#21644;GPT-4&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#30456;&#20851;&#24615;&#25490;&#21517;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#27169;&#22411;&#32463;&#36866;&#24403;&#25351;&#23548;&#21518;&#34920;&#29616;&#20248;&#24322;&#65292;&#26377;&#26102;&#29978;&#33267;&#20248;&#20110;&#20256;&#32479;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#23558;ChatGPT&#30340;&#25490;&#21517;&#33021;&#21147;&#25552;&#28860;&#20026;&#19987;&#38376;&#27169;&#22411;&#22312;BEIR&#19978;&#30340;&#25928;&#26524;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2304.09542</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#25490;&#21517;&#33021;&#21147;&#30740;&#31350;&#8212;&#8212;&#20197;ChatGPT&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent. (arXiv:2304.09542v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#24615;LLMs&#65292;&#22914;ChatGPT&#21644;GPT-4&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#30456;&#20851;&#24615;&#25490;&#21517;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#27169;&#22411;&#32463;&#36866;&#24403;&#25351;&#23548;&#21518;&#34920;&#29616;&#20248;&#24322;&#65292;&#26377;&#26102;&#29978;&#33267;&#20248;&#20110;&#20256;&#32479;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#23558;ChatGPT&#30340;&#25490;&#21517;&#33021;&#21147;&#25552;&#28860;&#20026;&#19987;&#38376;&#27169;&#22411;&#22312;BEIR&#19978;&#30340;&#25928;&#26524;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#35777;&#26126;&#20855;&#26377;remarkable&#33021;&#21147;&#65292;&#33021;&#22815;&#23558;&#19968;&#20123;&#38646;&#26679;&#26412;&#35821;&#35328;&#20219;&#21153;&#25512;&#24191;&#33267;&#20854;&#20182;&#39046;&#22495;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;ChatGPT&#21644;GPT-4&#31561;&#29983;&#25104;&#24615;LLMs&#30340;&#30456;&#20851;&#24615;&#25490;&#21517;&#22312;&#20449;&#24687;&#26816;&#32034;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#32463;&#36807;&#36866;&#24403;&#30340;&#25351;&#23548;&#65292;ChatGPT&#21644;GPT-4&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#20449;&#24687;&#26816;&#32034;&#22522;&#20934;&#19978;&#21462;&#24471;&#31454;&#20105;&#20248;&#21183;&#65292;&#29978;&#33267;&#26377;&#26102;&#20248;&#20110;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;GPT-4&#22312;TREC&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;nDCG&#19978;&#34920;&#29616;&#20248;&#20110;&#23436;&#20840;&#24494;&#35843;&#30340;monoT5-3B&#65292;BEIR&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;nDCG&#19978;&#20248;&#20110;monoT5-3B 2.3&#20010;&#28857;&#65292;&#20302;&#36164;&#28304;&#35821;&#35328;Mr.TyDi&#19978;&#30340;&#24179;&#22343;nDCG&#19978;&#20248;&#20110;monoT5-3B 2.7&#20010;&#28857;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#23558;ChatGPT&#30340;&#25490;&#21517;&#33021;&#21147;&#25552;&#28860;&#20026;&#19987;&#38376;&#30340;&#27169;&#22411;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#35757;&#32451;&#30340;&#23567;&#22411;&#19987;&#38376;&#27169;&#22411;&#65288;&#35757;&#32451;&#20110;10K&#20010;ChatGPT&#29983;&#25104;&#30340;&#25968;&#25454;&#65289;&#22312;BEIR&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#22312;400K&#20010;MS MARCO&#27880;&#37322;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;monoT5&#12290;&#20195;&#30721;&#21487;&#22312;www.github.com/sunnwe&#19978;&#22797;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated a remarkable ability to generalize zero-shot to various language-related tasks. This paper focuses on the study of exploring generative LLMs such as ChatGPT and GPT-4 for relevance ranking in Information Retrieval (IR). Surprisingly, our experiments reveal that properly instructed ChatGPT and GPT-4 can deliver competitive, even superior results than supervised methods on popular IR benchmarks. Notably, GPT-4 outperforms the fully fine-tuned monoT5-3B on MS MARCO by an average of 2.7 nDCG on TREC datasets, an average of 2.3 nDCG on eight BEIR datasets, and an average of 2.7 nDCG on ten low-resource languages Mr.TyDi. Subsequently, we delve into the potential for distilling the ranking capabilities of ChatGPT into a specialized model. Our small specialized model that trained on 10K ChatGPT generated data outperforms monoT5 trained on 400K annotated MS MARCO data on BEIR. The code to reproduce our results is available at www.github.com/sunnwe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#22522;&#20110;&#23884;&#20837;&#24335;&#26816;&#32034;&#30340;&#31038;&#20132;&#32593;&#32476;&#25628;&#32034;&#20013;&#23436;&#25972;&#24615;&#21644;&#22403;&#22334;&#24615;&#38382;&#39064;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#32034;&#24341;&#22788;&#29702;&#21644;&#38024;&#23545;&#24615;&#29992;&#25143;&#20998;&#32452;&#22788;&#29702;&#31561;&#12290;&#36825;&#20123;&#26041;&#27861;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.09287</link><description>&lt;p&gt;
&#22522;&#20110;&#23884;&#20837;&#24335;&#26816;&#32034;&#30340;&#23436;&#25972;&#24615;&#21644;&#22403;&#22334;&#22788;&#29702;&#26041;&#27861;&#65306;&#31038;&#20132;&#32593;&#32476;&#25628;&#32034;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Integrity and Junkiness Failure Handling for Embedding-based Retrieval: A Case Study in Social Network Search. (arXiv:2304.09287v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#22522;&#20110;&#23884;&#20837;&#24335;&#26816;&#32034;&#30340;&#31038;&#20132;&#32593;&#32476;&#25628;&#32034;&#20013;&#23436;&#25972;&#24615;&#21644;&#22403;&#22334;&#24615;&#38382;&#39064;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#32034;&#24341;&#22788;&#29702;&#21644;&#38024;&#23545;&#24615;&#29992;&#25143;&#20998;&#32452;&#22788;&#29702;&#31561;&#12290;&#36825;&#20123;&#26041;&#27861;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#23884;&#20837;&#24335;&#26816;&#32034;&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#30005;&#23376;&#21830;&#21153;&#12289;&#31038;&#20132;&#32593;&#32476;&#25628;&#32034;&#31561;&#21508;&#31181;&#25628;&#32034;&#24212;&#29992;&#20013;&#12290;&#23613;&#31649;&#35813;&#26041;&#27861;&#22312;&#35821;&#20041;&#21305;&#37197;&#21644;&#19978;&#19979;&#25991;&#25628;&#32034;&#31561;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#65292;&#20294;&#23427;&#20173;&#21463;&#21040;&#26080;&#27861;&#25511;&#21046;&#30340;&#20851;&#32852;&#24615;&#38382;&#39064;&#30340;&#22256;&#25200;&#12290;&#26412;&#25991;&#22312;&#23545;&#26089;&#26399;&#24212;&#29992;&#20110;&#25105;&#20204;&#30340;&#31038;&#20132;&#32593;&#32476;&#25628;&#32034;&#24341;&#25806;&#30340;&#23884;&#20837;&#24335;&#26816;&#32034;&#36827;&#34892;&#20998;&#26512;&#30340;&#22522;&#30784;&#19978;&#65292;&#23450;&#20041;&#20102;&#24341;&#20837;&#30340;&#20004;&#31181;&#20027;&#35201;&#30340;&#25925;&#38556;&#31867;&#22411;&#65292;&#23436;&#25972;&#24615;&#21644;&#22403;&#22334;&#24615;&#12290;&#21069;&#32773;&#26159;&#25351;&#21487;&#20197;&#20005;&#37325;&#21361;&#23475;&#29992;&#25143;&#20307;&#39564;&#30340;&#20167;&#24680;&#35328;&#35770;&#21644;&#25915;&#20987;&#24615;&#20869;&#23481;&#31561;&#38382;&#39064;&#65292;&#32780;&#21518;&#32773;&#21253;&#25324;&#31867;&#20284;&#27169;&#31946;&#25991;&#26412;&#21305;&#37197;&#25110;&#35821;&#35328;&#19981;&#21305;&#37197;&#30340;&#26080;&#20851;&#32467;&#26524;&#12290;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#27169;&#22411;&#25512;&#26029;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21253;&#25324;&#32034;&#24341;&#22788;&#29702;&#21644;&#38024;&#23545;&#24615;&#29992;&#25143;&#20998;&#32452;&#22788;&#29702;&#31561;&#12290;&#23613;&#31649;&#26041;&#27861;&#31616;&#21333;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#31163;&#32447;NDCG&#21644;&#22312;&#32447;A/B&#27979;&#35797;&#25351;&#26631;&#22686;&#30410;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36825;&#20123;&#25925;&#38556;&#30340;&#21407;&#22240;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#35299;&#20915;&#22312;&#22522;&#20110;&#23884;&#20837;&#24335;&#26816;&#32034;&#30340;&#31038;&#20132;&#32593;&#32476;&#25628;&#32034;&#20013;&#30340;&#23436;&#25972;&#24615;&#21644;&#22403;&#22334;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Embedding based retrieval has seen its usage in a variety of search applications like e-commerce, social networking search etc. While the approach has demonstrated its efficacy in tasks like semantic matching and contextual search, it is plagued by the problem of uncontrollable relevance. In this paper, we conduct an analysis of embedding-based retrieval launched in early 2021 on our social network search engine, and define two main categories of failures introduced by it, integrity and junkiness. The former refers to issues such as hate speech and offensive content that can severely harm user experience, while the latter includes irrelevant results like fuzzy text matching or language mismatches. Efficient methods during model inference are further proposed to resolve the issue, including indexing treatments and targeted user cohort treatments, etc. Though being simple, we show the methods have good offline NDCG and online A/B tests metrics gain in practice. We analyze the reasons for
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#20840;&#38754;&#23457;&#26597;&#65292;&#20197;&#35299;&#20915;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31995;&#32479;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#20919;&#21551;&#21160;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2304.09282</link><description>&lt;p&gt;
&#22312;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31995;&#32479;&#20013;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Leveraging Deep Learning Techniques on Collaborative Filtering Recommender Systems. (arXiv:2304.09282v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#20840;&#38754;&#23457;&#26597;&#65292;&#20197;&#35299;&#20915;&#21327;&#21516;&#36807;&#28388;&#25512;&#33616;&#31995;&#32479;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#20919;&#21551;&#21160;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;&#32447;&#25968;&#25454;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#25628;&#32034;&#21644;&#26597;&#25214;&#25152;&#38656;&#20449;&#24687;&#24050;&#25104;&#20026;&#19968;&#39033;&#32791;&#26102;&#19988;&#36153;&#21147;&#30340;&#20219;&#21153;&#12290;&#25512;&#33616;&#31995;&#32479;&#20316;&#20026;&#20449;&#24687;&#26816;&#32034;&#21644;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#30340;&#23376;&#31867;&#65292;&#36890;&#36807;&#25552;&#20379;&#20010;&#24615;&#21270;&#24314;&#35758;&#26469;&#24110;&#21161;&#29992;&#25143;&#26356;&#26377;&#25928;&#22320;&#35775;&#38382;&#25152;&#38656;&#20449;&#24687;&#12290;&#22312;&#26500;&#24314;&#25512;&#33616;&#31995;&#32479;&#30340;&#19981;&#21516;&#25216;&#26415;&#20013;&#65292;&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#26159;&#26368;&#27969;&#34892;&#21644;&#24191;&#27867;&#37319;&#29992;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20919;&#21551;&#21160;&#21644;&#25968;&#25454;&#31232;&#30095;&#24615;&#26159;&#23454;&#26045;&#26377;&#25928;&#30340;&#22522;&#20110;CF&#30340;&#25512;&#33616;&#30340;&#22522;&#26412;&#25361;&#25112;&#12290;&#26368;&#36817;&#25104;&#21151;&#21457;&#23637;&#30340;&#22686;&#24378;&#21644;&#23454;&#26045;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#35768;&#22810;&#30740;&#31350;&#65292;&#28608;&#21457;&#20102;&#35768;&#22810;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#30340;&#24369;&#28857;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#19981;&#20687;&#36807;&#21435;&#30340;&#31867;&#20284;&#24037;&#20316;&#37027;&#26679;&#28085;&#30422;&#20102;&#19981;&#21516;&#30340;&#25216;&#26415;&#65292;&#32780;&#26159;&#19987;&#38376;&#25552;&#20379;&#20102;&#23545;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#20840;&#38754;&#23457;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the exponentially increasing volume of online data, searching and finding required information have become an extensive and time-consuming task. Recommender Systems as a subclass of information retrieval and decision support systems by providing personalized suggestions helping users access what they need more efficiently. Among the different techniques for building a recommender system, Collaborative Filtering (CF) is the most popular and widespread approach. However, cold start and data sparsity are the fundamental challenges ahead of implementing an effective CF-based recommender. Recent successful developments in enhancing and implementing deep learning architectures motivated many studies to propose deep learning-based solutions for solving the recommenders' weak points. In this research, unlike the past similar works about using deep learning architectures in recommender systems that covered different techniques generally, we specifically provide a comprehensive review of de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24207;&#21015;&#25512;&#33616;&#31639;&#27861;&#8212;&#8212;&#39057;&#29575;&#22686;&#24378;&#30340;&#28151;&#21512;&#27880;&#24847;&#21147;&#32593;&#32476;&#65288;FEARec&#65289;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#19968;&#20010;&#26012;&#22369;&#32467;&#26500;&#23558;&#21407;&#26377;&#30340;&#33258;&#27880;&#24847;&#21147;&#20174;&#26102;&#38388;&#22495;&#36716;&#25442;&#21040;&#39057;&#29575;&#22495;&#65292;&#20351;&#24471;&#20302;&#39057;&#21644;&#39640;&#39057;&#20449;&#24687;&#21487;&#20197;&#34987;&#26126;&#30830;&#22320;&#23398;&#20064;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#33258;&#30456;&#20851;&#30340;&#35774;&#35745;&#65292;&#35813;&#31639;&#27861;&#36824;&#21487;&#20197;&#25429;&#25417;&#21040;&#29992;&#25143;&#34892;&#20026;&#30340;&#22266;&#26377;&#21608;&#26399;&#24615;&#12290;&#22312;&#22235;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#35813;&#31639;&#27861;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.09184</link><description>&lt;p&gt;
&#39057;&#29575;&#22686;&#24378;&#30340;&#28151;&#21512;&#27880;&#24847;&#21147;&#32593;&#32476;&#29992;&#20110;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Frequency Enhanced Hybrid Attention Network for Sequential Recommendation. (arXiv:2304.09184v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09184
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24207;&#21015;&#25512;&#33616;&#31639;&#27861;&#8212;&#8212;&#39057;&#29575;&#22686;&#24378;&#30340;&#28151;&#21512;&#27880;&#24847;&#21147;&#32593;&#32476;&#65288;FEARec&#65289;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#19968;&#20010;&#26012;&#22369;&#32467;&#26500;&#23558;&#21407;&#26377;&#30340;&#33258;&#27880;&#24847;&#21147;&#20174;&#26102;&#38388;&#22495;&#36716;&#25442;&#21040;&#39057;&#29575;&#22495;&#65292;&#20351;&#24471;&#20302;&#39057;&#21644;&#39640;&#39057;&#20449;&#24687;&#21487;&#20197;&#34987;&#26126;&#30830;&#22320;&#23398;&#20064;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#33258;&#30456;&#20851;&#30340;&#35774;&#35745;&#65292;&#35813;&#31639;&#27861;&#36824;&#21487;&#20197;&#25429;&#25417;&#21040;&#29992;&#25143;&#34892;&#20026;&#30340;&#22266;&#26377;&#21608;&#26399;&#24615;&#12290;&#22312;&#22235;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#35813;&#31639;&#27861;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#27880;&#24847;&#26426;&#21046;&#26159;&#24207;&#21015;&#25512;&#33616;&#39046;&#22495;&#24191;&#27867;&#20351;&#29992;&#30340;&#25216;&#26415;&#20043;&#19968;&#65292;&#20855;&#26377;&#24314;&#27169;&#38271;&#31243;&#20381;&#36182;&#24615;&#30340;&#24378;&#22823;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30446;&#21069;&#22522;&#20110;&#33258;&#27880;&#24847;&#21147;&#30340;&#27169;&#22411;&#26159;&#20302;&#36890;&#28388;&#27874;&#22120;&#65292;&#19981;&#33021;&#25429;&#25417;&#39640;&#39057;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#29992;&#25143;&#34892;&#20026;&#20013;&#30340;&#39033;&#30446;&#30456;&#20114;&#20132;&#32455;&#65292;&#36825;&#20123;&#27169;&#22411;&#26080;&#27861;&#21306;&#20998;&#26102;&#38388;&#22495;&#20013;&#27169;&#31946;&#30340;&#22266;&#26377;&#21608;&#26399;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#35270;&#35282;&#36716;&#31227;&#21040;&#39057;&#29575;&#22495;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015;&#25512;&#33616;&#31639;&#27861;&#8212;&#8212;&#39057;&#29575;&#22686;&#24378;&#30340;&#28151;&#21512;&#27880;&#24847;&#21147;&#32593;&#32476;&#65292;&#21363;FEARec&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#19968;&#20010;&#26012;&#22369;&#32467;&#26500;&#23558;&#21407;&#22987;&#26102;&#38388;&#22495;&#33258;&#27880;&#24847;&#21147;&#25913;&#36827;&#21040;&#39057;&#29575;&#22495;&#20013;&#65292;&#20351;&#24471;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26126;&#30830;&#22320;&#23398;&#20064;&#20302;&#39057;&#21644;&#39640;&#39057;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#33258;&#30456;&#20851;&#35774;&#35745;&#20102;&#31867;&#20284;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#26469;&#25429;&#25417;&#29992;&#25143;&#34892;&#20026;&#30340;&#22266;&#26377;&#21608;&#26399;&#24615;&#12290;&#22312;&#22235;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;
The self-attention mechanism, which equips with a strong capability of modeling long-range dependencies, is one of the extensively used techniques in the sequential recommendation field. However, many recent studies represent that current self-attention based models are low-pass filters and are inadequate to capture high-frequency information. Furthermore, since the items in the user behaviors are intertwined with each other, these models are incomplete to distinguish the inherent periodicity obscured in the time domain. In this work, we shift the perspective to the frequency domain, and propose a novel Frequency Enhanced Hybrid Attention Network for Sequential Recommendation, namely FEARec. In this model, we firstly improve the original time domain self-attention in the frequency domain with a ramp structure to make both low-frequency and high-frequency information could be explicitly learned in our approach. Moreover, we additionally design a similar attention mechanism via auto-corr
&lt;/p&gt;</description></item><item><title>EvalRS 2023&#26088;&#22312;&#25506;&#35752;&#25512;&#33616;&#31995;&#32479;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#20851;&#27880;&#20854;&#22312;&#29616;&#23454;&#22330;&#26223;&#19979;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;&#36807;&#21435;&#21482;&#26377;&#20934;&#30830;&#24230;&#30340;&#27979;&#37327;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#20840;&#38754;&#35780;&#20272;&#20854;&#24615;&#33021;&#65292;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#26377;&#29992;&#24615;&#21644;&#20449;&#24687;&#37327;&#31561;&#26041;&#38754;&#20063;&#24212;&#35813;&#34987;&#20851;&#27880;&#12290;&#26412;&#27425;&#30740;&#35752;&#20250;&#26159;&#21435;&#24180;CIKM&#30740;&#35752;&#20250;&#30340;&#32487;&#25215;&#21644;&#21457;&#23637;&#65292;&#24102;&#26377;&#23454;&#38469;&#25805;&#20316;&#24615;&#21644;&#20114;&#21160;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07145</link><description>&lt;p&gt;
EvalRS 2023. &#38754;&#21521;&#23454;&#38469;&#24212;&#29992;&#30340;&#20840;&#38754;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
EvalRS 2023. Well-Rounded Recommender Systems For Real-World Deployments. (arXiv:2304.07145v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07145
&lt;/p&gt;
&lt;p&gt;
EvalRS 2023&#26088;&#22312;&#25506;&#35752;&#25512;&#33616;&#31995;&#32479;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#20851;&#27880;&#20854;&#22312;&#29616;&#23454;&#22330;&#26223;&#19979;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;&#36807;&#21435;&#21482;&#26377;&#20934;&#30830;&#24230;&#30340;&#27979;&#37327;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#20840;&#38754;&#35780;&#20272;&#20854;&#24615;&#33021;&#65292;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#26377;&#29992;&#24615;&#21644;&#20449;&#24687;&#37327;&#31561;&#26041;&#38754;&#20063;&#24212;&#35813;&#34987;&#20851;&#27880;&#12290;&#26412;&#27425;&#30740;&#35752;&#20250;&#26159;&#21435;&#24180;CIKM&#30740;&#35752;&#20250;&#30340;&#32487;&#25215;&#21644;&#21457;&#23637;&#65292;&#24102;&#26377;&#23454;&#38469;&#25805;&#20316;&#24615;&#21644;&#20114;&#21160;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
EvalRS&#26088;&#22312;&#27719;&#32858;&#20135;&#19994;&#21644;&#23398;&#26415;&#30028;&#30340;&#20174;&#19994;&#32773;&#65292;&#20419;&#36827;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;&#20840;&#38754;&#35780;&#20272;&#30340;&#35752;&#35770;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#22312;&#21508;&#31181;&#37096;&#32626;&#22330;&#26223;&#19979;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#21482;&#36890;&#36807;&#20934;&#30830;&#24615;&#25351;&#26631;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#20123;&#25351;&#26631;&#26080;&#27861;&#23436;&#20840;&#25551;&#36848;&#20854;&#27867;&#21270;&#33021;&#21147;&#24182;&#24573;&#35270;&#20102;&#37325;&#35201;&#30340;&#26041;&#38754;&#65292;&#22914;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#26377;&#29992;&#24615;&#12289;&#20449;&#24687;&#37327;&#31561;&#12290;&#26412;&#27425;&#30740;&#35752;&#20250;&#22312;CIKM&#21435;&#24180;&#30740;&#35752;&#20250;&#30340;&#25104;&#21151;&#22522;&#30784;&#19978;&#36827;&#19968;&#27493;&#25193;&#22823;&#33539;&#22260;&#65292;&#24182;&#37319;&#21462;&#20114;&#21160;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
EvalRS aims to bring together practitioners from industry and academia to foster a debate on rounded evaluation of recommender systems, with a focus on real-world impact across a multitude of deployment scenarios. Recommender systems are often evaluated only through accuracy metrics, which fall short of fully characterizing their generalization capabilities and miss important aspects, such as fairness, bias, usefulness, informativeness. This workshop builds on the success of last year's workshop at CIKM, but with a broader scope and an interactive format.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#22270;&#34920;&#31034;&#23398;&#20064;&#30340;&#30740;&#31350;&#29616;&#29366;&#21644;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25351;&#20986;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#24050;&#32463;&#26174;&#31034;&#20986;&#24040;&#22823;&#30340;&#20248;&#21183;&#21644;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.05055</link><description>&lt;p&gt;
&#28145;&#24230;&#22270;&#34920;&#31034;&#23398;&#20064;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Survey on Deep Graph Representation Learning. (arXiv:2304.05055v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#22270;&#34920;&#31034;&#23398;&#20064;&#30340;&#30740;&#31350;&#29616;&#29366;&#21644;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25351;&#20986;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#24050;&#32463;&#26174;&#31034;&#20986;&#24040;&#22823;&#30340;&#20248;&#21183;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#34920;&#31034;&#23398;&#20064;&#26088;&#22312;&#23558;&#39640;&#32500;&#31232;&#30095;&#30340;&#22270;&#32467;&#26500;&#25968;&#25454;&#26377;&#25928;&#22320;&#32534;&#30721;&#25104;&#20302;&#32500;&#23494;&#38598;&#21521;&#37327;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#26412;&#20219;&#21153;&#65292;&#22312;&#21253;&#25324;&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#25366;&#25496;&#22312;&#20869;&#30340;&#19968;&#31995;&#21015;&#39046;&#22495;&#37117;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#12290;&#20256;&#32479;&#22270;&#23884;&#20837;&#26041;&#27861;&#36981;&#24490;&#36825;&#26679;&#19968;&#31181;&#22522;&#26412;&#24605;&#24819;&#65292;&#21363;&#22270;&#20013;&#30456;&#20114;&#36830;&#25509;&#30340;&#33410;&#28857;&#30340;&#23884;&#20837;&#30690;&#37327;&#20173;&#28982;&#33021;&#22815;&#20445;&#25345;&#30456;&#23545;&#25509;&#36817;&#30340;&#36317;&#31163;&#65292;&#20174;&#32780;&#20445;&#30041;&#20102;&#22270;&#20013;&#33410;&#28857;&#20043;&#38388;&#30340;&#32467;&#26500;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#23384;&#22312;&#20197;&#19979;&#38382;&#39064;&#65306;&#65288;i&#65289;&#20256;&#32479;&#26041;&#27861;&#30340;&#27169;&#22411;&#23481;&#37327;&#21463;&#38480;&#65292;&#38480;&#21046;&#20102;&#23398;&#20064;&#24615;&#33021;; &#65288;ii&#65289;&#29616;&#26377;&#25216;&#26415;&#36890;&#24120;&#20381;&#36182;&#20110;&#26080;&#30417;&#30563;&#23398;&#20064;&#31574;&#30053;&#65292;&#26080;&#27861;&#19982;&#26368;&#26032;&#30340;&#23398;&#20064;&#33539;&#24335;&#30456;&#32467;&#21512;&#65307;&#65288;iii&#65289;&#34920;&#31034;&#23398;&#20064;&#21644;&#19979;&#28216;&#20219;&#21153;&#30456;&#20114;&#20381;&#23384;&#65292;&#24212;&#20849;&#21516;&#21152;&#24378;&#12290;&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#30340;&#26174;&#30528;&#25104;&#21151;&#65292;&#28145;&#24230;&#22270;&#34920;&#31034;&#23398;&#20064;&#24050;&#32463;&#26174;&#31034;&#20986;&#24040;&#22823;&#30340;&#28508;&#21147;&#21644;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. Classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. However, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. With the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#21270;&#36229;&#22270;&#32593;&#32476;&#30340;&#30456;&#20851;&#20559;&#22909;&#36716;&#31227;&#26694;&#26550;&#65292;&#29992;&#20110;&#22810;&#39046;&#22495;&#25512;&#33616;&#65292;&#21487;&#20197;&#23558;&#22810;&#20010;&#39046;&#22495;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#34920;&#31034;&#20026;&#19968;&#20010;&#32479;&#19968;&#30340;&#22270;&#20197;&#20415;&#20110;&#20559;&#22909;&#36716;&#31227;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.11191</link><description>&lt;p&gt;
&#22522;&#20110;&#23618;&#27425;&#21270;&#36229;&#22270;&#32593;&#32476;&#30340;&#22810;&#39046;&#22495;&#25512;&#33616;&#20013;&#30340;&#30456;&#20851;&#20559;&#22909;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Correlative Preference Transfer with Hierarchical Hypergraph Network for Multi-Domain Recommendation. (arXiv:2211.11191v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#21270;&#36229;&#22270;&#32593;&#32476;&#30340;&#30456;&#20851;&#20559;&#22909;&#36716;&#31227;&#26694;&#26550;&#65292;&#29992;&#20110;&#22810;&#39046;&#22495;&#25512;&#33616;&#65292;&#21487;&#20197;&#23558;&#22810;&#20010;&#39046;&#22495;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#34920;&#31034;&#20026;&#19968;&#20010;&#32479;&#19968;&#30340;&#22270;&#20197;&#20415;&#20110;&#20559;&#22909;&#36716;&#31227;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#36827;&#30340;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#28041;&#21450;&#22810;&#20010;&#39046;&#22495;&#65288;&#22914;&#22330;&#26223;&#25110;&#31867;&#21035;&#65289;&#20197;&#28385;&#36275;&#29992;&#25143;&#21508;&#31181;&#38656;&#27714;&#12290; &#22810;&#39046;&#22495;&#25512;&#33616;&#65288;MDR&#65289;&#30340;&#30446;&#26631;&#26159;&#21516;&#26102;&#25552;&#39640;&#25152;&#26377;&#39046;&#22495;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;&#20256;&#32479;&#30340;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#36890;&#24120;&#20998;&#21035;&#22788;&#29702;&#27599;&#20010;&#39046;&#22495;&#65292;&#25110;&#32773;&#35757;&#32451;&#19968;&#20010;&#20849;&#20139;&#27169;&#22411;&#26469;&#26381;&#21153;&#20110;&#25152;&#26377;&#39046;&#22495;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#21270;&#36229;&#22270;&#32593;&#32476;&#30340;&#30456;&#20851;&#20559;&#22909;&#36716;&#31227;&#26694;&#26550;$\mathsf{H^3Trans}$&#65292;&#23558;&#22810;&#39046;&#22495;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#34920;&#31034;&#20026;&#19968;&#20010;&#32479;&#19968;&#30340;&#22270;&#26469;&#24110;&#21161;&#20559;&#22909;&#36716;&#31227;&#12290;$\mathsf{H^3Trans}$&#21253;&#21547;&#20004;&#20010;&#22522;&#20110;&#36229;&#36793;&#30340;&#27169;&#22359;&#65292;&#20998;&#21035;&#26159;&#21160;&#24577;&#36229;&#22270;&#27880;&#24847;&#32593;&#32476;&#65288;DHAN&#65289;&#21644;&#36328;&#39046;&#22495;&#20559;&#22909;&#36716;&#31227;&#32593;&#32476;&#65288;CDPT&#65289;&#65292;&#20197;&#25429;&#25417;&#29992;&#25143;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#39046;&#22495;&#20869;&#21644;&#36328;&#22495;&#20132;&#20114;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23618;&#27425;&#21270;&#30340;&#26550;&#26500;&#26469;&#24314;&#27169;&#29992;&#25143;&#30340;&#22810;&#32423;&#29305;&#24449;&#20559;&#22909;&#12290;&#22312;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;$\mathsf{H^3Trans}$&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Advanced recommender systems usually involve multiple domains (such as scenarios or categories) for various marketing strategies, and users interact with them to satisfy diverse demands. The goal of multi-domain recommendation (MDR) is to improve the recommendation performance of all domains simultaneously. Conventional graph neural network based methods usually deal with each domain separately, or train a shared model to serve all domains. The former fails to leverage users' cross-domain behaviors, making the behavior sparseness issue a great obstacle. The latter learns shared user representation with respect to all domains, which neglects users' domain-specific preferences. In this paper we propose $\mathsf{H^3Trans}$, a hierarchical hypergraph network based correlative preference transfer framework for MDR, which represents multi-domain user-item interactions into a unified graph to help preference transfer. $\mathsf{H^3Trans}$ incorporates two hyperedge-based modules, namely dynami
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23485;&#27867;&#25512;&#33616;&#31995;&#32479;(BroadCF)&#65292;&#20351;&#29992;&#23485;&#27867;&#23398;&#20064;&#31995;&#32479;(BLS)&#20316;&#20026;&#26144;&#23556;&#20989;&#25968;&#26469;&#23398;&#20064;&#29992;&#25143;&#21644;&#39033;&#30446;&#20043;&#38388;&#30340;&#22797;&#26434;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#21516;&#26102;&#36890;&#36807;&#29992;&#25143;-&#39033;&#35780;&#32423;&#21327;&#21516;&#21521;&#37327;&#39044;&#22788;&#29702;&#31243;&#24207;&#23558;&#21407;&#22987;&#25968;&#25454;&#36716;&#25442;&#20026;&#26356;&#36866;&#21512;BLS&#23398;&#20064;&#30340;&#26684;&#24335;&#12290;BroadCF&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#29992;&#25143;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#37117;&#20248;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;CF&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2204.11602</link><description>&lt;p&gt;
&#23485;&#27867;&#25512;&#33616;&#31995;&#32479;&#65306;&#19968;&#31181;&#39640;&#25928;&#30340;&#38750;&#32447;&#24615;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Broad Recommender System: An Efficient Nonlinear Collaborative Filtering Approach. (arXiv:2204.11602v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.11602
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23485;&#27867;&#25512;&#33616;&#31995;&#32479;(BroadCF)&#65292;&#20351;&#29992;&#23485;&#27867;&#23398;&#20064;&#31995;&#32479;(BLS)&#20316;&#20026;&#26144;&#23556;&#20989;&#25968;&#26469;&#23398;&#20064;&#29992;&#25143;&#21644;&#39033;&#30446;&#20043;&#38388;&#30340;&#22797;&#26434;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#21516;&#26102;&#36890;&#36807;&#29992;&#25143;-&#39033;&#35780;&#32423;&#21327;&#21516;&#21521;&#37327;&#39044;&#22788;&#29702;&#31243;&#24207;&#23558;&#21407;&#22987;&#25968;&#25454;&#36716;&#25442;&#20026;&#26356;&#36866;&#21512;BLS&#23398;&#20064;&#30340;&#26684;&#24335;&#12290;BroadCF&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#29992;&#25143;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#37117;&#20248;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;CF&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#34987;&#24191;&#27867;&#24341;&#20837;&#21040;&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#20013;&#65292;&#20197;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#25512;&#33616;&#32467;&#26524;&#65292;&#22240;&#20026;&#23427;&#20204;&#20855;&#26377;&#25429;&#33719;&#39033;&#30446;&#21644;&#29992;&#25143;&#20043;&#38388;&#22797;&#26434;&#38750;&#32447;&#24615;&#20851;&#31995;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;DNN&#30340;&#27169;&#22411;&#36890;&#24120;&#36973;&#21463;&#39640;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#38382;&#39064;&#65292;&#21363;&#28040;&#32791;&#38750;&#24120;&#38271;&#30340;&#35757;&#32451;&#26102;&#38388;&#24182;&#23384;&#20648;&#22823;&#37327;&#21487;&#35757;&#32451;&#21442;&#25968;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23485;&#27867;&#25512;&#33616;&#31995;&#32479;&#65292;&#31216;&#20026;&#23485;&#27867;&#21327;&#21516;&#36807;&#28388;&#65288;BroadCF&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#38750;&#32447;&#24615;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#12290;&#23485;&#27867;&#23398;&#20064;&#31995;&#32479;&#65288;BLS&#65289;&#34987;&#29992;&#20316;&#26144;&#23556;&#20989;&#25968;&#65292;&#20197;&#23398;&#20064;&#29992;&#25143;&#21644;&#39033;&#30446;&#20043;&#38388;&#30340;&#22797;&#26434;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#21487;&#20197;&#36991;&#20813;&#19978;&#36848;&#38382;&#39064;&#65292;&#21516;&#26102;&#23454;&#29616;&#38750;&#24120;&#20196;&#20154;&#28385;&#24847;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#23558;&#21407;&#22987;&#35780;&#20998;&#25968;&#25454;&#30452;&#25509;&#39304;&#36865;&#21040;BLS&#20013;&#24182;&#19981;&#21487;&#34892;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25143;-&#39033;&#35780;&#32423;&#21327;&#21516;&#21521;&#37327;&#39044;&#22788;&#29702;&#31243;&#24207;&#65292;&#23558;&#21407;&#22987;&#25968;&#25454;&#36716;&#25442;&#20026;&#26356;&#36866;&#21512;BLS&#23398;&#20064;&#30340;&#26684;&#24335;&#12290;&#19977;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;BroadCF&#22312;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#22343;&#20248;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;CF&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, Deep Neural Networks (DNNs) have been widely introduced into Collaborative Filtering (CF) to produce more accurate recommendation results due to their capability of capturing the complex nonlinear relationships between items and users.However, the DNNs-based models usually suffer from high computational complexity, i.e., consuming very long training time and storing huge amount of trainable parameters. To address these problems, we propose a new broad recommender system called Broad Collaborative Filtering (BroadCF), which is an efficient nonlinear collaborative filtering approach. Instead of DNNs, Broad Learning System (BLS) is used as a mapping function to learn the complex nonlinear relationships between users and items, which can avoid the above issues while achieving very satisfactory recommendation performance. However, it is not feasible to directly feed the original rating data into BLS. To this end, we propose a user-item rating collaborative vector preprocessing pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#26102;&#23578;&#34892;&#19994;&#30340;CLIP-like&#27169;&#22411;&#8212;&#8212; FashionCLIP&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#23545;&#35270;&#35273;&#21644;&#35821;&#35328;&#30340;&#23545;&#27604;&#23398;&#20064;&#23454;&#29616;&#20135;&#21697;&#30340;&#26816;&#32034;&#12289;&#20998;&#31867;&#21644;&#23450;&#20301;&#65292;&#33021;&#22815;&#25552;&#20379;&#26356;&#20855;&#21487;&#36716;&#31227;&#24615;&#30340;&#20135;&#21697;&#34920;&#24449;&#12290;</title><link>http://arxiv.org/abs/2204.03972</link><description>&lt;p&gt;
&#23545;&#20110;&#26222;&#36941;&#26102;&#23578;&#27010;&#24565;&#30340;&#35270;&#35273;&#19982;&#35821;&#35328;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contrastive language and vision learning of general fashion concepts. (arXiv:2204.03972v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.03972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#26102;&#23578;&#34892;&#19994;&#30340;CLIP-like&#27169;&#22411;&#8212;&#8212; FashionCLIP&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#23545;&#35270;&#35273;&#21644;&#35821;&#35328;&#30340;&#23545;&#27604;&#23398;&#20064;&#23454;&#29616;&#20135;&#21697;&#30340;&#26816;&#32034;&#12289;&#20998;&#31867;&#21644;&#23450;&#20301;&#65292;&#33021;&#22815;&#25552;&#20379;&#26356;&#20855;&#21487;&#36716;&#31227;&#24615;&#30340;&#20135;&#21697;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;&#32447;&#36141;&#29289;&#19981;&#26029;&#23835;&#36215;&#65292;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#27169;&#22411;&#30340;&#21457;&#23637;&#32039;&#38543;&#20854;&#21518;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#29992;&#20363;&#37117;&#34987;&#35270;&#20026;&#19987;&#19994;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#65292;&#20294;&#25105;&#20204;&#35748;&#20026;&#20174;&#26356;&#20855;&#21487;&#36716;&#31227;&#24615;&#30340;&#20135;&#21697;&#34920;&#24449;&#20013;&#21463;&#30410;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#23545;&#27604;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#35757;&#32451;&#20986;&#20102;FashionCLIP&#65292;&#19968;&#31181;&#36866;&#29992;&#20110;&#26102;&#23578;&#34892;&#19994;&#30340;CLIP-like&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#26816;&#32034;&#12289;&#20998;&#31867;&#21644;&#23450;&#20301;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#21644;&#20195;&#30721;&#21457;&#24067;&#32473;&#31038;&#21306;&#12290;
&lt;/p&gt;
&lt;p&gt;
The steady rise of online shopping goes hand in hand with the development of increasingly complex ML and NLP models. While most use cases are cast as specialized supervised learning problems, we argue that practitioners would greatly benefit from more transferable representations of products. In this work, we build on recent developments in contrastive learning to train FashionCLIP, a CLIP-like model for the fashion industry. We showcase its capabilities for retrieval, classification and grounding, and release our model and code to the community.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;PMC-Patients&#8221;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#23450;&#20041;&#21644;&#27979;&#35797;&#30149;&#24739;&#21040;&#25991;&#31456;&#30340;&#26816;&#32034;&#65288;ReCDS-PAR&#65289;&#21644;&#30149;&#24739;&#21040;&#30149;&#24739;&#30340;&#26816;&#32034;&#65288;ReCDS-PPR&#65289;&#65292;&#20197;&#35780;&#20272;&#22522;&#20110;&#21484;&#22238;&#30340;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;ReCDS&#65289;&#30340;&#24615;&#33021;&#12290;PMC-Patients&#25968;&#25454;&#38598;&#28085;&#30422;&#36926;10,000&#21517;&#30149;&#24739;&#20449;&#24687;&#21644;27,000&#31687;PubMed Central&#25991;&#31456;&#65292;&#24182;&#23637;&#31034;&#20102;&#22810;&#31181;ReCDS&#31995;&#32479;&#30340;&#25928;&#26524;&#20998;&#26512;&#21644;20&#20010;&#26696;&#20363;&#30340;&#23454;&#29992;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2202.13876</link><description>&lt;p&gt;
PMC-Patients: &#29992;&#20110;&#35780;&#20272;&#22522;&#20110;&#21484;&#22238;&#30340;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#30340;&#22823;&#35268;&#27169;&#30149;&#24739;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
PMC-Patients: A Large-scale Dataset of Patient Summaries and Relations for Benchmarking Retrieval-based Clinical Decision Support Systems. (arXiv:2202.13876v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.13876
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;PMC-Patients&#8221;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#23450;&#20041;&#21644;&#27979;&#35797;&#30149;&#24739;&#21040;&#25991;&#31456;&#30340;&#26816;&#32034;&#65288;ReCDS-PAR&#65289;&#21644;&#30149;&#24739;&#21040;&#30149;&#24739;&#30340;&#26816;&#32034;&#65288;ReCDS-PPR&#65289;&#65292;&#20197;&#35780;&#20272;&#22522;&#20110;&#21484;&#22238;&#30340;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;ReCDS&#65289;&#30340;&#24615;&#33021;&#12290;PMC-Patients&#25968;&#25454;&#38598;&#28085;&#30422;&#36926;10,000&#21517;&#30149;&#24739;&#20449;&#24687;&#21644;27,000&#31687;PubMed Central&#25991;&#31456;&#65292;&#24182;&#23637;&#31034;&#20102;&#22810;&#31181;ReCDS&#31995;&#32479;&#30340;&#25928;&#26524;&#20998;&#26512;&#21644;20&#20010;&#26696;&#20363;&#30340;&#23454;&#29992;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#65306;&#22522;&#20110;&#21484;&#22238;&#30340;&#20020;&#24202;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;ReCDS&#65289;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#30456;&#20851;&#25991;&#29486;&#21644;&#31867;&#20284;&#30149;&#24739;&#30340;&#20449;&#24687;&#26469;&#24110;&#21161;&#20020;&#24202;&#24037;&#20316;&#27969;&#31243;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#22810;&#26679;&#30340;&#30149;&#24739;&#25910;&#38598;&#21644;&#20844;&#24320;&#30340;&#22823;&#35268;&#27169;&#30149;&#24739;&#23618;&#38754;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;ReCDS&#31995;&#32479;&#30340;&#21457;&#23637;&#21463;&#21040;&#20102;&#20005;&#37325;&#38459;&#30861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20351;&#29992;&#21517;&#20026;PMC-Patients&#30340;&#26032;&#25968;&#25454;&#38598;&#23450;&#20041;&#21644;&#27979;&#35797;&#20004;&#20010;ReCDS&#20219;&#21153;&#65306;&#30149;&#24739;&#21040;&#25991;&#31456;&#30340;&#26816;&#32034;&#65288;ReCDS-PAR&#65289;&#21644;&#30149;&#24739;&#21040;&#30149;&#24739;&#30340;&#26816;&#32034;&#65288;ReCDS-PPR&#65289;&#12290;&#26041;&#27861;&#65306;&#25105;&#20204;&#20351;&#29992;&#31616;&#21333;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#20174;PubMed Central&#25991;&#31456;&#20013;&#25552;&#21462;&#30149;&#24739;&#24635;&#32467;&#65292;&#24182;&#21033;&#29992;PubMed&#24341;&#25991;&#20851;&#31995;&#22270;&#26469;&#23450;&#20041;&#30149;&#24739;-&#25991;&#31456;&#30456;&#20851;&#24615;&#21644;&#30149;&#24739;-&#30149;&#24739;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#36824;&#22312;PMC-Patients&#22522;&#20934;&#27979;&#35797;&#19978;&#23454;&#26045;&#21644;&#35780;&#20272;&#20102;&#20960;&#31181;ReCDS&#31995;&#32479;&#65292;&#21253;&#25324;&#31232;&#30095;&#26816;&#32034;&#22120;&#12289;&#23494;&#38598;&#26816;&#32034;&#22120;&#21644;&#26368;&#36817;&#37051;&#26816;&#32034;&#22120;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20960;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#20197;&#23637;&#31034;PMC-Patients&#30340;&#20020;&#24202;&#25928;&#29992;&#12290;&#32467;&#26524;&#65306;PMC-Patients&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;10,186&#21517;&#30149;&#24739;&#30340;&#20449;&#24687;&#65292;&#28085;&#30422;&#20102;&#36926;27,000&#31687;PubMed Central&#25991;&#31456;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;ReCDS&#20219;&#21153;&#30340;&#22522;&#20934;&#35780;&#20272;&#32467;&#26524;&#21644;&#22810;&#31181;&#31995;&#32479;&#30340;&#25928;&#26524;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#20004;&#20010;&#20219;&#21153;&#30340;20&#20010;&#26696;&#20363;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;PMC-Patients&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Objective: Retrieval-based Clinical Decision Support (ReCDS) can aid clinical workflow by providing relevant literature and similar patients for a given patient. However, the development of ReCDS systems has been severely obstructed by the lack of diverse patient collections and publicly available large-scale patient-level annotation datasets. In this paper, we aim to define and benchmark two ReCDS tasks: Patient-to-Article Retrieval (ReCDS-PAR) and Patient-to-Patient Retrieval (ReCDS-PPR) using a novel dataset called PMC-Patients.  Methods: We extract patient summaries from PubMed Central articles using simple heuristics and utilize the PubMed citation graph to define patient-article relevance and patient-patient similarity. We also implement and evaluate several ReCDS systems on the PMC-Patients benchmarks, including sparse retrievers, dense retrievers, and nearest neighbor retrievers. We conduct several case studies to show the clinical utility of PMC-Patients.  Results: PMC-Patient
&lt;/p&gt;</description></item></channel></rss>