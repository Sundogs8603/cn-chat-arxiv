<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#25628;&#32034;&#21152;&#23494;(SE)&#32034;&#24341;&#31995;&#32479;&#30340;&#23454;&#29992;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#38469;&#36816;&#34892;&#30340;&#12289;&#31471;&#21040;&#31471;&#30340;SE&#23454;&#26045;&#65292;&#23545;&#21160;&#24577;SE&#26356;&#26032;&#25805;&#20316;&#36827;&#34892;&#20102;&#39318;&#27425;&#23454;&#35777;&#24615;&#24615;&#33021;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2308.13486</link><description>&lt;p&gt;
&#20851;&#20110;&#24555;&#36895;&#21487;&#25628;&#32034;&#21152;&#23494;&#20013;&#21160;&#24577;&#26356;&#26032;&#30340;&#23454;&#29992;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Practicality of Dynamic Updates in Fast Searchable Encryption. (arXiv:2308.13486v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13486
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#25628;&#32034;&#21152;&#23494;(SE)&#32034;&#24341;&#31995;&#32479;&#30340;&#23454;&#29992;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#38469;&#36816;&#34892;&#30340;&#12289;&#31471;&#21040;&#31471;&#30340;SE&#23454;&#26045;&#65292;&#23545;&#21160;&#24577;SE&#26356;&#26032;&#25805;&#20316;&#36827;&#34892;&#20102;&#39318;&#27425;&#23454;&#35777;&#24615;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#25628;&#32034;&#21152;&#23494;(SE)&#32034;&#24341;&#31995;&#32479;&#26159;&#19968;&#31181;&#21033;&#29992;&#20113;&#26381;&#21153;&#23384;&#20648;&#21644;&#31649;&#29702;&#25935;&#24863;&#20449;&#24687;&#30340;&#26377;&#29992;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;SE&#31995;&#32479;&#30340;&#22823;&#37096;&#20998;&#24037;&#20316;&#20173;&#20572;&#30041;&#22312;&#29702;&#35770;&#38454;&#27573;&#12290;&#20026;&#20102;&#20351;&#20854;&#23454;&#29992;&#21270;&#65292;&#38656;&#35201;&#26356;&#22810;&#24037;&#20316;&#26469;&#24320;&#21457;&#26368;&#20248;&#30340;&#21327;&#35758;&#21644;&#24037;&#20316;&#27169;&#22411;&#12290;&#36825;&#21253;&#25324;&#29305;&#21035;&#21019;&#24314;&#19968;&#20010;&#21487;&#24037;&#20316;&#30340;&#26356;&#26032;&#27169;&#22411;&#65292;&#20197;&#20445;&#25345;&#23545;&#21160;&#24577;&#25991;&#26723;&#38598;&#21512;&#65288;&#22914;&#30005;&#23376;&#37038;&#20214;&#25910;&#20214;&#31665;&#65289;&#36827;&#34892;&#21152;&#23494;&#32034;&#24341;&#30340;&#33021;&#21147;&#12290;&#25105;&#24050;&#32463;&#21019;&#24314;&#20102;&#19968;&#20010;&#23454;&#38469;&#36816;&#34892;&#30340;&#12289;&#31471;&#21040;&#31471;&#30340;SE&#23454;&#26045;&#65292;&#28385;&#36275;&#20102;&#36825;&#20123;&#38656;&#27714;&#65292;&#24182;&#36827;&#34892;&#20102;&#21160;&#24577;SE&#26356;&#26032;&#25805;&#20316;&#30340;&#31532;&#19968;&#27425;&#23454;&#35777;&#24615;&#24615;&#33021;&#35780;&#20272;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#23637;&#31034;&#20102;&#20174;&#20808;&#21069;&#30740;&#31350;&#20154;&#21592;&#25551;&#36848;&#30340;&#29702;&#35770;&#27010;&#24565;&#36716;&#21521;&#26410;&#26469;&#21487;&#25237;&#20837;&#29983;&#20135;&#30340;&#23454;&#26045;&#30340;&#21487;&#34892;&#36335;&#24452;&#65292;&#24182;&#30830;&#23450;&#20102;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Searchable encrypted (SE) indexing systems are a useful tool for utilizing cloud services to store and manage sensitive information. However, much of the work on SE systems to date has remained theoretical. In order to make them of practical use, more work is needed to develop optimal protocols and working models for them. This includes, in particular, the creation of a working update model in order to maintain an encrypted index of a dynamic document set such as an email inbox. I have created a working, real-world end-to-end SE implementation that satisfies these needs, including the first empirical performance evaluation of the dynamic SE update operation. In doing so, I show a viable path to move from the theoretical concepts described by previous researchers to a future production-worthy implementation and identify issues for follow-on investigation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#30693;&#35782;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19968;&#20010;&#30693;&#35782;&#24341;&#23548;&#30340;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#65292;&#36890;&#36807;&#25972;&#21512;&#22806;&#37096;&#30693;&#35782;&#26469;&#24357;&#34917;&#29616;&#26377;&#25968;&#25454;&#38598;&#20013;&#30340;&#20449;&#24687;&#32570;&#22833;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13467</link><description>&lt;p&gt;
&#21033;&#29992;&#30693;&#35782;&#21644;&#24378;&#21270;&#23398;&#20064;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;
&lt;/p&gt;
&lt;p&gt;
Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models. (arXiv:2308.13467v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#30693;&#35782;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19968;&#20010;&#30693;&#35782;&#24341;&#23548;&#30340;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#65292;&#36890;&#36807;&#25972;&#21512;&#22806;&#37096;&#30693;&#35782;&#26469;&#24357;&#34917;&#29616;&#26377;&#25968;&#25454;&#38598;&#20013;&#30340;&#20449;&#24687;&#32570;&#22833;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;(NLP)&#31038;&#21306;&#19968;&#30452;&#22312;&#20351;&#29992;&#20247;&#21253;&#25216;&#26415;&#65292;&#21019;&#24314;&#29992;&#20110;&#35757;&#32451;&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#22914;BERT&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20363;&#22914;General Language Understanding and Evaluation(GLUE)&#12290;GLUE&#20219;&#21153;&#20351;&#29992;&#20114;&#35780;&#35745;&#37327;&#26041;&#27861;&#65288;&#22914;Cohens Kappa&#65289;&#26469;&#34913;&#37327;&#21487;&#38752;&#24615;&#20998;&#25968;&#12290;&#28982;&#32780;&#65292;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#26041;&#38754;&#24120;&#24120;&#34987;&#24573;&#35270;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#30693;&#35782;&#24341;&#23548;&#30340;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#65292;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#23558;ConceptNet&#21644;&#32500;&#22522;&#30334;&#31185;&#30340;&#30693;&#35782;&#20316;&#20026;&#30693;&#35782;&#22270;&#23884;&#20837;&#36827;&#34892;&#25972;&#21512;&#12290;&#36825;&#31181;&#26041;&#27861;&#27169;&#20223;&#20102;&#20154;&#31867;&#27880;&#37322;&#32773;&#20351;&#29992;&#22806;&#37096;&#30693;&#35782;&#26469;&#24357;&#34917;&#25968;&#25454;&#38598;&#20013;&#30340;&#20449;&#24687;&#32570;&#22833;&#12290;&#36890;&#36807;&#22312;&#20061;&#20010;GLUE&#25968;&#25454;&#38598;&#19978;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21487;&#20197;&#22686;&#24378;&#21487;&#38752;&#24615;&#21644;&#20934;&#30830;&#24615;&#24471;&#20998;&#65292;&#36229;&#36807;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Natural Language Processing(NLP) community has been using crowd sourcing techniques to create benchmark datasets such as General Language Understanding and Evaluation(GLUE) for training modern Language Models such as BERT. GLUE tasks measure the reliability scores using inter annotator metrics i.e. Cohens Kappa. However, the reliability aspect of LMs has often been overlooked. To counter this problem, we explore a knowledge-guided LM ensembling approach that leverages reinforcement learning to integrate knowledge from ConceptNet and Wikipedia as knowledge graph embeddings. This approach mimics human annotators resorting to external knowledge to compensate for information deficits in the datasets. Across nine GLUE datasets, our research shows that ensembling strengthens reliability and accuracy scores, outperforming state of the art.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#30340;&#27604;&#36739;&#35780;&#21028;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20256;&#32479;&#25945;&#32946;&#35780;&#20272;&#20013;&#23384;&#22312;&#30340;&#19968;&#33268;&#24615;&#21644;&#20559;&#35265;&#31561;&#38382;&#39064;&#65292;&#24182;&#25506;&#32034;&#20102;&#22914;&#20309;&#36873;&#25321;&#27604;&#36739;&#39033;&#30446;&#30340;&#21487;&#38752;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.13292</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#30340;&#27604;&#36739;&#35780;&#21028;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Active Learning Approach to Comparative Judgement. (arXiv:2308.13292v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13292
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#30340;&#27604;&#36739;&#35780;&#21028;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20256;&#32479;&#25945;&#32946;&#35780;&#20272;&#20013;&#23384;&#22312;&#30340;&#19968;&#33268;&#24615;&#21644;&#20559;&#35265;&#31561;&#38382;&#39064;&#65292;&#24182;&#25506;&#32034;&#20102;&#22914;&#20309;&#36873;&#25321;&#27604;&#36739;&#39033;&#30446;&#30340;&#21487;&#38752;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#26159;&#25945;&#32946;&#30340;&#20851;&#38190;&#37096;&#20998;&#12290;&#20256;&#32479;&#30340;&#35780;&#20998;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#65292;&#22914;&#19968;&#33268;&#24615;&#19981;&#36275;&#65292;&#23384;&#22312;&#26080;&#24847;&#35782;&#30340;&#20559;&#35265;&#65292;&#32473;&#35780;&#20272;&#32773;&#24102;&#26469;&#36739;&#22823;&#30340;&#35748;&#30693;&#36127;&#25285;&#12290;&#27604;&#36739;&#35780;&#21028;&#65288;CJ&#65289;&#26159;&#19968;&#31181;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#22312;CJ&#20013;&#65292;&#35780;&#20272;&#32773;&#20197;&#19968;&#23545;&#39033;&#30446;&#20026;&#21333;&#20301;&#65292;&#36873;&#25321;&#21738;&#20010;&#26356;&#22909;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#27604;&#36739;&#65292;&#21487;&#20197;&#20351;&#29992;&#25490;&#21517;&#27169;&#22411;&#65288;&#20363;&#22914;BTM&#65289;&#25512;&#23548;&#20986;&#19968;&#20010;&#25490;&#21517;&#12290;&#34429;&#28982;CJ&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#21487;&#38752;&#30340;&#35780;&#20998;&#26041;&#27861;&#65292;&#20294;&#20173;&#23384;&#22312;&#36879;&#26126;&#24230;&#21644;&#29983;&#25104;&#21487;&#38752;&#25490;&#21517;&#25152;&#38656;&#30340;&#23545;&#27604;&#27425;&#25968;&#30340;&#29702;&#24819;&#25968;&#37327;&#31561;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#24050;&#26377;&#23581;&#35797;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#20197;&#26377;&#25928;&#26041;&#24335;&#36873;&#25321;&#19979;&#19968;&#20010;&#24212;&#27604;&#36739;&#30340;&#39033;&#30446;&#65292;&#20294;&#26576;&#20123;&#29616;&#26377;&#26041;&#27861;&#20250;&#22312;&#32467;&#26524;&#20013;&#20135;&#29983;&#33258;&#24049;&#30340;&#20559;&#35265;&#65292;&#20174;&#32780;&#22686;&#21152;&#20102;&#25152;&#20351;&#29992;&#30340;&#21487;&#38752;&#24615;&#24230;&#37327;&#12290;&#22240;&#27492;&#65292;&#36890;&#24120;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#36125;&#21494;&#26031;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessment is a crucial part of education. Traditional marking is a source of inconsistencies and unconscious bias, placing a high cognitive load on the assessors. An approach to address these issues is comparative judgement (CJ). In CJ, the assessor is presented with a pair of items and is asked to select the better one. Following a series of comparisons, a rank is derived using a ranking model, for example, the BTM, based on the results. While CJ is considered a reliable method for marking, there are concerns around transparency, and the ideal number of pairwise comparisons to generate a reliable estimation of the rank order is not known. Additionally, there have been attempts to generate a method of selecting pairs that should be compared next in an informative manner, but some existing methods are known to have created their own bias within results inflating the reliability metric used. As a result, a random selection approach is usually deployed.  We propose a novel Bayesian appro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#24555;&#25163;&#20013;&#30340;&#24037;&#19994;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#37096;&#32626;&#19968;&#20010;&#20851;&#27880;&#21453;&#39304;&#30340;&#32534;&#30721;&#27169;&#22359;&#21644;&#35774;&#35745;&#19968;&#20010;&#22810;&#30446;&#26631;&#39044;&#27979;&#27169;&#22359;&#65292;&#20174;&#22823;&#37327;&#30340;&#21453;&#39304;&#20013;&#25552;&#21462;&#29992;&#25143;&#20559;&#22909;&#24182;&#39044;&#27979;&#30456;&#20851;&#30340;&#30701;&#35270;&#39057;&#12290;</title><link>http://arxiv.org/abs/2308.13249</link><description>&lt;p&gt;
&#23398;&#20064;&#21644;&#20248;&#21270;&#24037;&#19994;&#30701;&#35270;&#39057;&#25512;&#33616;&#31995;&#32479;&#30340;&#38544;&#24335;&#36127;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Learning and Optimization of Implicit Negative Feedback for Industrial Short-video Recommender System. (arXiv:2308.13249v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#24555;&#25163;&#20013;&#30340;&#24037;&#19994;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#37096;&#32626;&#19968;&#20010;&#20851;&#27880;&#21453;&#39304;&#30340;&#32534;&#30721;&#27169;&#22359;&#21644;&#35774;&#35745;&#19968;&#20010;&#22810;&#30446;&#26631;&#39044;&#27979;&#27169;&#22359;&#65292;&#20174;&#22823;&#37327;&#30340;&#21453;&#39304;&#20013;&#25552;&#21462;&#29992;&#25143;&#20559;&#22909;&#24182;&#39044;&#27979;&#30456;&#20851;&#30340;&#30701;&#35270;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#35270;&#39057;&#25512;&#33616;&#26159;&#24403;&#20170;&#24037;&#19994;&#20449;&#24687;&#31995;&#32479;&#20013;&#26368;&#37325;&#35201;&#30340;&#25512;&#33616;&#24212;&#29992;&#20043;&#19968;&#12290;&#19982;&#20854;&#20182;&#25512;&#33616;&#20219;&#21153;&#30456;&#27604;&#65292;&#28023;&#37327;&#30340;&#21453;&#39304;&#26159;&#26368;&#20856;&#22411;&#30340;&#29305;&#28857;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22312;&#30701;&#35270;&#39057;&#25512;&#33616;&#20013;&#65292;&#26368;&#23481;&#26131;&#25910;&#38598;&#21040;&#30340;&#29992;&#25143;&#21453;&#39304;&#26159;&#36339;&#36807;&#34892;&#20026;&#65292;&#36825;&#23545;&#25512;&#33616;&#27169;&#22411;&#25552;&#20986;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#36339;&#36807;&#34892;&#20026;&#21453;&#26144;&#20102;&#38544;&#24335;&#30340;&#29992;&#25143;&#20559;&#22909;&#65292;&#22240;&#27492;&#23545;&#20110;&#20852;&#36259;&#25552;&#21462;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20854;&#27425;&#65292;&#36825;&#31181;&#29305;&#27530;&#30340;&#21453;&#39304;&#28041;&#21450;&#21040;&#22810;&#20010;&#30446;&#26631;&#65292;&#22914;&#24635;&#35266;&#30475;&#26102;&#38388;&#65292;&#36825;&#20063;&#26159;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#22312;&#24555;&#25163;&#20013;&#30340;&#24037;&#19994;&#35299;&#20915;&#26041;&#26696;&#65292;&#27599;&#22825;&#20026;&#21313;&#20159;&#32423;&#29992;&#25143;&#25552;&#20379;&#26381;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#37096;&#32626;&#20102;&#19968;&#20010;&#20851;&#27880;&#21453;&#39304;&#30340;&#32534;&#30721;&#27169;&#22359;&#65292;&#24456;&#22909;&#22320;&#25552;&#21462;&#29992;&#25143;&#20559;&#22909;&#24182;&#32771;&#34385;&#20102;&#19978;&#19979;&#25991;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#30446;&#26631;&#39044;&#27979;&#27169;&#22359;&#65292;&#33021;&#22815;&#24456;&#22909;&#22320;&#21306;&#20998;&#30456;&#20851;&#21644;&#19981;&#30456;&#20851;&#30340;&#35270;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;
Short-video recommendation is one of the most important recommendation applications in today's industrial information systems. Compared with other recommendation tasks, the enormous amount of feedback is the most typical characteristic. Specifically, in short-video recommendation, the easiest-to-collect user feedback is from the skipping behaviors, which leads to two critical challenges for the recommendation model. First, the skipping behavior reflects implicit user preferences, and thus it is challenging for interest extraction. Second, the kind of special feedback involves multiple objectives, such as total watching time, which is also very challenging. In this paper, we present our industrial solution in Kuaishou, which serves billion-level users every day. Specifically, we deploy a feedback-aware encoding module which well extracts user preference taking the impact of context into consideration. We further design a multi-objective prediction module which well distinguishes the rel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24212;&#29992;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#38543;&#26426;&#22870;&#21169;&#30340;&#29305;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#38543;&#26426;&#22870;&#21169;&#31283;&#23450;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#26356;&#26377;&#25928;&#22320;&#22788;&#29702;&#38543;&#26426;&#21453;&#39304;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13246</link><description>&lt;p&gt;
&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;: &#38543;&#26426;&#22870;&#21169;&#31283;&#23450;&#21270;
&lt;/p&gt;
&lt;p&gt;
Model-free Reinforcement Learning with Stochastic Reward Stabilization for Recommender Systems. (arXiv:2308.13246v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#24212;&#29992;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#38024;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#38543;&#26426;&#22870;&#21169;&#30340;&#29305;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#38543;&#26426;&#22870;&#21169;&#31283;&#23450;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#26356;&#26377;&#25928;&#22320;&#22788;&#29702;&#38543;&#26426;&#21453;&#39304;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#26080;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#25512;&#33616;&#31995;&#32479;&#22240;&#20854;&#22788;&#29702;&#37096;&#20998;&#21453;&#39304;&#21644;&#38271;&#26399;&#22870;&#21169;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#24573;&#30053;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24449;&#65306;&#21516;&#19968;&#29992;&#25143;&#22312;&#19981;&#21516;&#26102;&#38388;&#23545;&#21516;&#19968;&#39033;&#30340;&#21453;&#39304;&#26159;&#38543;&#26426;&#30340;&#12290;&#38543;&#26426;&#22870;&#21169;&#30340;&#29305;&#24615;&#19982;&#20855;&#26377;&#30830;&#23450;&#24615;&#22870;&#21169;&#30340;&#32463;&#20856;RL&#22330;&#26223;&#26412;&#36136;&#19978;&#19981;&#21516;&#65292;&#36825;&#20351;&#24471;&#22522;&#20110;RL&#30340;&#25512;&#33616;&#31995;&#32479;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#39318;&#20808;&#22312;&#19968;&#20010;&#27169;&#25311;&#29615;&#22659;&#20013;&#23637;&#31034;&#20102;&#30452;&#25509;&#20351;&#29992;&#38543;&#26426;&#21453;&#39304;&#20250;&#23548;&#33268;&#24615;&#33021;&#26174;&#33879;&#19979;&#38477;&#12290;&#20026;&#20102;&#26356;&#26377;&#25928;&#22320;&#22788;&#29702;&#38543;&#26426;&#21453;&#39304;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#38543;&#26426;&#22870;&#21169;&#31283;&#23450;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#29992;&#30417;&#30563;&#27169;&#22411;&#23398;&#20064;&#21040;&#30340;&#22870;&#21169;&#26367;&#20195;&#30452;&#25509;&#30340;&#38543;&#26426;&#21453;&#39304;&#12290;&#36825;&#20004;&#20010;&#26694;&#26550;&#37117;&#26159;&#27169;&#22411;&#26080;&#20851;&#30340;&#65292;&#21363;&#23427;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#21508;&#31181;&#30417;&#30563;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-free RL-based recommender systems have recently received increasing research attention due to their capability to handle partial feedback and long-term rewards. However, most existing research has ignored a critical feature in recommender systems: one user's feedback on the same item at different times is random. The stochastic rewards property essentially differs from that in classic RL scenarios with deterministic rewards, which makes RL-based recommender systems much more challenging. In this paper, we first demonstrate in a simulator environment where using direct stochastic feedback results in a significant drop in performance. Then to handle the stochastic feedback more efficiently, we design two stochastic reward stabilization frameworks that replace the direct stochastic feedback with that learned by a supervised model. Both frameworks are model-agnostic, i.e., they can effectively utilize various supervised models. We demonstrate the superiority of the proposed framework
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#32676;&#32452;&#20844;&#24179;Plackett-Luce&#25490;&#24207;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26368;&#22823;&#21270;&#39044;&#26399;&#30456;&#20851;&#24615;&#24182;&#28385;&#36275;&#34920;&#31034;&#32422;&#26463;&#20197;&#30830;&#20445;&#21518;&#26399;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13242</link><description>&lt;p&gt;
&#20248;&#21270;&#20851;&#20110;&#30456;&#20851;&#24615;&#21644;&#21518;&#26399;&#20844;&#24179;&#24615;&#30340;&#32676;&#32452;&#20844;&#24179;Plackett-Luce&#25490;&#24207;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Optimizing Group-Fair Plackett-Luce Ranking Models for Relevance and Ex-Post Fairness. (arXiv:2308.13242v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13242
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#32676;&#32452;&#20844;&#24179;Plackett-Luce&#25490;&#24207;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26368;&#22823;&#21270;&#39044;&#26399;&#30456;&#20851;&#24615;&#24182;&#28385;&#36275;&#34920;&#31034;&#32422;&#26463;&#20197;&#30830;&#20445;&#21518;&#26399;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#25490;&#21517;&#20013;&#65292;&#20165;&#20248;&#21270;&#30456;&#20851;&#24615;&#65288;&#25110;&#39044;&#26399;&#25490;&#21517;&#25928;&#29992;&#65289;&#21487;&#33021;&#23545;&#26576;&#20123;&#31867;&#21035;&#30340;&#39033;&#30446;&#36896;&#25104;&#34920;&#29616;&#24615;&#25439;&#23475;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#30456;&#20851;&#24615;&#20998;&#25968;&#20013;&#23384;&#22312;&#38544;&#24615;&#20559;&#35265;&#65292;&#21017;&#23398;&#20064;&#25490;&#21517;&#27169;&#22411;&#21487;&#33021;&#26080;&#27861;&#20248;&#21270;&#30495;&#23454;&#30340;&#30456;&#20851;&#24615;&#12290;&#20197;&#21069;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#35757;&#32451;&#38543;&#26426;&#25490;&#21517;&#27169;&#22411;&#65292;&#20197;&#36798;&#21040;&#32676;&#32452;&#39044;&#26399;&#26292;&#38706;&#30340;&#20844;&#24179;&#24615;&#65288;&#21363;&#26399;&#26395;&#20540;&#65289;&#65292;&#20294;&#21487;&#33021;&#26080;&#27861;&#20445;&#35777;&#32676;&#32452;&#21518;&#26399;&#30340;&#34920;&#29616;&#20844;&#24179;&#24615;&#65292;&#21363;&#22312;&#20174;&#38543;&#26426;&#25490;&#24207;&#27169;&#22411;&#20013;&#23454;&#29616;&#25490;&#21517;&#20043;&#21518;&#12290;&#36890;&#24120;&#65292;&#36890;&#36807;&#21518;&#26399;&#22788;&#29702;&#23454;&#29616;&#21518;&#26399;&#20844;&#24179;&#24615;&#65292;&#20294;&#26159;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#35757;&#32451;&#24847;&#35782;&#21040;&#27492;&#21518;&#26399;&#22788;&#29702;&#30340;&#38543;&#26426;&#25490;&#24207;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20165;&#22312;&#28385;&#36275;&#32473;&#23450;&#34920;&#31034;&#32422;&#26463;&#30340;&#25490;&#21517;&#20013;&#26368;&#22823;&#21270;&#39044;&#26399;&#30456;&#20851;&#24615;&#65292;&#20197;&#30830;&#20445;&#21518;&#26399;&#20844;&#24179;&#24615;&#12290;&#22522;&#20110;&#26368;&#36817;&#20851;&#20110;&#21518;&#26399;&#32676;&#32452;&#20844;&#24179;&#25490;&#21517;&#30340;&#26377;&#25928;&#25277;&#26679;&#22120;&#30340;&#24037;&#20316;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20165;&#22312;&#28385;&#36275;&#32473;&#23450;&#34920;&#31034;&#32422;&#26463;&#30340;&#25490;&#21517;&#20013;&#26368;&#22823;&#21270;&#39044;&#26399;&#30456;&#20851;&#24615;&#65292;&#20197;&#30830;&#20445;&#21518;&#26399;&#20844;&#27491;&#24615;&#12290;&#24314;&#31435;&#22312;&#19968;&#20010;&#39640;&#25928;&#30340;&#25277;&#26679;&#22120;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23427;&#26368;&#22823;&#21270;&#22312;&#28385;&#36275;&#32473;&#23450;&#30340;&#34920;&#31034;&#32422;&#26463;&#30340;&#25490;&#21517;&#20013;&#30340;&#39044;&#26399;&#30456;&#20851;&#24615;&#65292;&#20197;&#30830;&#20445;&#21518;&#26399;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In learning-to-rank (LTR), optimizing only the relevance (or the expected ranking utility) can cause representational harm to certain categories of items. Moreover, if there is implicit bias in the relevance scores, LTR models may fail to optimize for true relevance. Previous works have proposed efficient algorithms to train stochastic ranking models that achieve fairness of exposure to the groups ex-ante (or, in expectation), which may not guarantee representation fairness to the groups ex-post, that is, after realizing a ranking from the stochastic ranking model. Typically, ex-post fairness is achieved by post-processing, but previous work does not train stochastic ranking models that are aware of this post-processing.  In this paper, we propose a novel objective that maximizes expected relevance only over those rankings that satisfy given representation constraints to ensure ex-post fairness. Building upon recent work on an efficient sampler for ex-post group-fair rankings, we propo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26368;&#22823;&#22343;&#20540;&#21644;&#36880;&#20301;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;CTR&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#20272;&#35745;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#36890;&#36807;&#32771;&#34385;&#20301;&#32423;&#30340;&#32454;&#31890;&#24230;&#20132;&#20114;&#65292;&#25552;&#39640;&#39044;&#27979;&#30340;&#31934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13187</link><description>&lt;p&gt;
MMBAttn: &#26368;&#22823;&#22343;&#20540;&#21644;&#36880;&#20301;&#27880;&#24847;&#21147;&#29992;&#20110;CTR&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
MMBAttn: Max-Mean and Bit-wise Attention for CTR Prediction. (arXiv:2308.13187v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13187
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26368;&#22823;&#22343;&#20540;&#21644;&#36880;&#20301;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;CTR&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#20272;&#35745;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#36890;&#36807;&#32771;&#34385;&#20301;&#32423;&#30340;&#32454;&#31890;&#24230;&#20132;&#20114;&#65292;&#25552;&#39640;&#39044;&#27979;&#30340;&#31934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22312;&#32447;&#24191;&#21578;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#20219;&#21153;&#30340;&#22797;&#26434;&#24615;&#21644;&#35268;&#27169;&#22686;&#21152;&#65292;&#20934;&#30830;&#20272;&#35745;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#25104;&#20026;&#24320;&#21457;&#26377;&#25928;&#27169;&#22411;&#30340;&#20851;&#38190;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26368;&#22823;&#20540;&#21644;&#24179;&#22343;&#20540;&#27744;&#21270;&#25805;&#20316;&#20197;&#21450;&#36880;&#20301;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#22312;CTR&#39044;&#27979;&#20013;&#22686;&#24378;&#29305;&#24449;&#37325;&#35201;&#24615;&#20272;&#35745;&#12290;&#20256;&#32479;&#19978;&#65292;&#26368;&#22823;&#20540;&#21644;&#24179;&#22343;&#20540;&#27744;&#21270;&#31561;&#27744;&#21270;&#25805;&#20316;&#34987;&#24191;&#27867;&#29992;&#20110;&#20174;&#29305;&#24449;&#20013;&#25552;&#21462;&#30456;&#20851;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25805;&#20316;&#21487;&#33021;&#23548;&#33268;&#20449;&#24687;&#20002;&#22833;&#65292;&#24182;&#22952;&#30861;&#20934;&#30830;&#30830;&#23450;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27880;&#24847;&#21147;&#26550;&#26500;&#65292;&#21033;&#29992;&#36880;&#20301;&#27880;&#24847;&#21147;&#32467;&#26500;&#24378;&#35843;&#29305;&#24449;&#20013;&#25152;&#26377;&#20301;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21516;&#26102;&#36827;&#34892;&#26368;&#22823;&#27744;&#21270;&#21644;&#24179;&#22343;&#27744;&#21270;&#12290;&#36890;&#36807;&#32771;&#34385;&#20301;&#32423;&#30340;&#32454;&#31890;&#24230;&#20132;&#20114;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#25552;&#39640;CTR&#39044;&#27979;&#30340;&#31934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increasing complexity and scale of click-through rate (CTR) prediction tasks in online advertising and recommendation systems, accurately estimating the importance of features has become a critical aspect of developing effective models. In this paper, we propose an attention-based approach that leverages max and mean pooling operations, along with a bit-wise attention mechanism, to enhance feature importance estimation in CTR prediction. Traditionally, pooling operations such as max and mean pooling have been widely used to extract relevant information from features. However, these operations can lead to information loss and hinder the accurate determination of feature importance. To address this challenge, we propose a novel attention architecture that utilizes a bit-based attention structure that emphasizes the relationships between all bits in features, together with maximum and mean pooling. By considering the fine-grained interactions at the bit level, our method aims to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#31181;&#26368;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#26469;&#29983;&#25104;&#25991;&#26723;&#23884;&#20837;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#22270;&#20070;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#27604;&#21333;&#19968;&#27169;&#22411;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.13050</link><description>&lt;p&gt;
&#22810;&#37325;BERT&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Multi-BERT for Embeddings for Recommendation System. (arXiv:2308.13050v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#31181;&#26368;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#26469;&#29983;&#25104;&#25991;&#26723;&#23884;&#20837;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#22270;&#20070;&#25512;&#33616;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#27604;&#21333;&#19968;&#27169;&#22411;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21477;&#23376;BERT&#65288;SBERT&#65289;&#21644;RoBERTa&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#26469;&#29983;&#25104;&#25991;&#26723;&#23884;&#20837;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#21477;&#23376;&#35270;&#20026;&#26631;&#35760;&#65292;&#24182;&#20026;&#23427;&#20204;&#29983;&#25104;&#23884;&#20837;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#25429;&#25417;&#25991;&#26723;&#20869;&#30340;&#21477;&#23376;&#20869;&#37096;&#21644;&#21477;&#23376;&#38388;&#20851;&#31995;&#12290;&#25105;&#20204;&#22312;&#22270;&#20070;&#25512;&#33616;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#29983;&#25104;&#35821;&#20041;&#20016;&#23500;&#21644;&#20934;&#30830;&#30340;&#25991;&#26723;&#23884;&#20837;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#22312;Goodreads&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22270;&#20070;&#25512;&#33616;&#20219;&#21153;&#30340;&#23454;&#39564;&#12290;&#25105;&#20204;&#23558;&#20351;&#29992;&#25105;&#20204;&#30340;MULTI-BERT&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26723;&#23884;&#20837;&#19982;&#20165;&#20351;&#29992;SBERT&#29983;&#25104;&#30340;&#23884;&#20837;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#20351;&#29992;&#31934;&#30830;&#24230;&#20316;&#20026;&#35780;&#20272;&#25351;&#26631;&#26469;&#27604;&#36739;&#29983;&#25104;&#23884;&#20837;&#30340;&#36136;&#37327;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#29983;&#25104;&#23884;&#20837;&#30340;&#36136;&#37327;&#26041;&#38754;&#22987;&#32456;&#20248;&#20110;SBERT&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;...
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel approach for generating document embeddings using a combination of Sentence-BERT (SBERT) and RoBERTa, two state-of-the-art natural language processing models. Our approach treats sentences as tokens and generates embeddings for them, allowing the model to capture both intra-sentence and inter-sentence relations within a document. We evaluate our model on a book recommendation task and demonstrate its effectiveness in generating more semantically rich and accurate document embeddings. To assess the performance of our approach, we conducted experiments on a book recommendation task using the Goodreads dataset. We compared the document embeddings generated using our MULTI-BERT model to those generated using SBERT alone. We used precision as our evaluation metric to compare the quality of the generated embeddings. Our results showed that our model consistently outperformed SBERT in terms of the quality of the generated embeddings. Furthermore, we found tha
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31934;&#32454;&#35843;&#25972;&#30340;Llama 2&#27169;&#22411;&#23454;&#29616;&#20102;&#37329;&#34701;&#26032;&#38395;&#30340;&#22810;&#20219;&#21153;&#20998;&#26512;&#65292;&#21253;&#25324;&#25991;&#26412;&#20998;&#26512;&#12289;&#25688;&#35201;&#21644;&#24773;&#24863;&#25552;&#21462;&#31561;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25552;&#21462;&#30340;&#21629;&#21517;&#23454;&#20307;&#24773;&#24863;&#21487;&#20197;&#20316;&#20026;&#26377;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2308.13032</link><description>&lt;p&gt;
&#20351;&#29992;&#31934;&#32454;&#35843;&#25972;&#30340;Llama 2 GPT&#27169;&#22411;&#36827;&#34892;&#37329;&#34701;&#26032;&#38395;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Financial News Analytics Using Fine-Tuned Llama 2 GPT Model. (arXiv:2308.13032v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13032
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31934;&#32454;&#35843;&#25972;&#30340;Llama 2&#27169;&#22411;&#23454;&#29616;&#20102;&#37329;&#34701;&#26032;&#38395;&#30340;&#22810;&#20219;&#21153;&#20998;&#26512;&#65292;&#21253;&#25324;&#25991;&#26412;&#20998;&#26512;&#12289;&#25688;&#35201;&#21644;&#24773;&#24863;&#25552;&#21462;&#31561;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25552;&#21462;&#30340;&#21629;&#21517;&#23454;&#20307;&#24773;&#24863;&#21487;&#20197;&#20316;&#20026;&#26377;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20351;&#29992;&#31934;&#32454;&#35843;&#25972;&#30340;Llama 2 Large Language Model (LLM) &#23545;&#37329;&#34701;&#26032;&#38395;&#36827;&#34892;&#22810;&#20219;&#21153;&#20998;&#26512;&#30340;&#21487;&#33021;&#24615;&#12290;&#36890;&#36807;PEFT/LoRA&#26041;&#27861;&#23545;&#27169;&#22411;&#36827;&#34892;&#31934;&#32454;&#35843;&#25972;&#65292;&#20027;&#35201;&#21253;&#25324;&#20174;&#37329;&#34701;&#24066;&#22330;&#35282;&#24230;&#20998;&#26512;&#25991;&#26412;&#12289;&#31361;&#20986;&#25991;&#26412;&#30340;&#20027;&#35201;&#35266;&#28857;&#12289;&#23545;&#25991;&#26412;&#36827;&#34892;&#25688;&#35201;&#21644;&#25552;&#21462;&#20855;&#26377;&#36866;&#24403;&#24773;&#24863;&#30340;&#21629;&#21517;&#23454;&#20307;&#31561;&#20219;&#21153;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#32463;&#36807;&#31934;&#32454;&#35843;&#25972;&#30340;Llama 2&#27169;&#22411;&#33021;&#22815;&#36827;&#34892;&#22810;&#20219;&#21153;&#30340;&#37329;&#34701;&#26032;&#38395;&#20998;&#26512;&#65292;&#20854;&#21709;&#24212;&#30340;&#32467;&#26500;&#21487;&#20197;&#37096;&#20998;&#20026;&#32467;&#26500;&#21270;&#25991;&#26412;&#65292;&#21478;&#19968;&#37096;&#20998;&#25968;&#25454;&#21487;&#20197;&#37319;&#29992;JSON&#26684;&#24335;&#36827;&#19968;&#27493;&#22788;&#29702;&#12290;&#25552;&#21462;&#30340;&#21629;&#21517;&#23454;&#20307;&#24773;&#24863;&#21487;&#20197;&#34987;&#35270;&#20026;&#20855;&#26377;&#23450;&#37327;&#30446;&#26631;&#21464;&#37327;&#30340;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper considers the possibility to fine-tune Llama 2 Large Language Model (LLM) for the multitask analysis of financial news. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text from financial market perspectives, highlighting main points of a text, summarizing a text and extracting named entities with appropriate sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a multitask financial news analysis with a specified structure of response, part of response can be a structured text and another part of data can have JSON format for further processing. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models with quantitative target variables.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#25490;&#24207;&#26694;&#26550;&#65292;&#21517;&#20026;STARank&#65292;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#20505;&#36873;&#39033;&#30446;&#25490;&#21015;&#26469;&#26367;&#20195;&#20010;&#21035;&#35780;&#20998;&#21644;&#25490;&#24207;&#25805;&#20316;&#65292;&#24182;&#19988;&#26159;&#31471;&#21040;&#31471;&#21487;&#24494;&#20998;&#30340;&#12290;</title><link>http://arxiv.org/abs/2308.02860</link><description>&lt;p&gt;
&#29992;&#23433;&#25490;&#21462;&#20195;&#35780;&#20998;&#65306;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#25490;&#24207;&#30340;&#19978;&#19979;&#25991;&#38598;&#21512;&#21040;&#25490;&#21015;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Replace Scoring with Arrangement: A Contextual Set-to-Arrangement Framework for Learning-to-Rank. (arXiv:2308.02860v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02860
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#25490;&#24207;&#26694;&#26550;&#65292;&#21517;&#20026;STARank&#65292;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#20505;&#36873;&#39033;&#30446;&#25490;&#21015;&#26469;&#26367;&#20195;&#20010;&#21035;&#35780;&#20998;&#21644;&#25490;&#24207;&#25805;&#20316;&#65292;&#24182;&#19988;&#26159;&#31471;&#21040;&#31471;&#21487;&#24494;&#20998;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#25490;&#24207;&#26159;top-N&#25512;&#33616;&#20219;&#21153;&#20013;&#30340;&#26680;&#24515;&#25216;&#26415;&#65292;&#29702;&#24819;&#30340;&#25490;&#21517;&#22120;&#24212;&#35813;&#26159;&#19968;&#20010;&#20174;&#39033;&#30446;&#38598;&#21512;&#21040;&#25490;&#21015;&#65288;&#21363;&#25490;&#21015;&#65289;&#30340;&#26144;&#23556;&#12290;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#35299;&#20915;&#26041;&#26696;&#23646;&#20110;&#27010;&#29575;&#25490;&#24207;&#21407;&#21017;&#65288;PRP&#65289;&#33539;&#24335;&#65292;&#21363;&#39318;&#20808;&#23545;&#20505;&#36873;&#38598;&#20013;&#30340;&#27599;&#20010;&#39033;&#30446;&#36827;&#34892;&#35780;&#20998;&#65292;&#28982;&#21518;&#25191;&#34892;&#25490;&#24207;&#25805;&#20316;&#20197;&#29983;&#25104;&#25490;&#21517;&#21015;&#34920;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24573;&#35270;&#20102;&#20010;&#20307;&#35780;&#20998;&#36807;&#31243;&#20013;&#20505;&#36873;&#39033;&#30446;&#20043;&#38388;&#30340;&#19978;&#19979;&#25991;&#20381;&#36182;&#24615;&#65292;&#24182;&#19988;&#25490;&#24207;&#25805;&#20316;&#26159;&#19981;&#21487;&#24494;&#20998;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;STARank&#30340;&#38598;&#21512;&#21040;&#25490;&#21015;&#25490;&#24207;&#26694;&#26550;&#65292;&#23427;&#30452;&#25509;&#29983;&#25104;&#20505;&#36873;&#39033;&#30446;&#30340;&#25490;&#21015;&#65292;&#32780;&#19981;&#38656;&#35201;&#36827;&#34892;&#20010;&#21035;&#35780;&#20998;&#21644;&#25490;&#24207;&#25805;&#20316;&#65292;&#24182;&#19988;&#26159;&#31471;&#21040;&#31471;&#21487;&#24494;&#20998;&#30340;&#12290;&#22240;&#27492;&#65292;STARank&#21487;&#20197;&#22312;&#21482;&#26377;&#30495;&#23454;&#25490;&#21015;&#21487;&#35775;&#38382;&#20294;&#27809;&#26377;&#39033;&#30446;&#30340;&#30495;&#23454;&#30456;&#20851;&#24230;&#20998;&#25968;&#30340;&#24773;&#20917;&#19979;&#36816;&#34892;&#12290;&#20026;&#27492;&#65292;STARank&#39318;&#20808;&#38405;&#35835;&#20505;&#36873;&#39033;&#30446;...
&lt;/p&gt;
&lt;p&gt;
Learning-to-rank is a core technique in the top-N recommendation task, where an ideal ranker would be a mapping from an item set to an arrangement (a.k.a. permutation). Most existing solutions fall in the paradigm of probabilistic ranking principle (PRP), i.e., first score each item in the candidate set and then perform a sort operation to generate the top ranking list. However, these approaches neglect the contextual dependence among candidate items during individual scoring, and the sort operation is non-differentiable. To bypass the above issues, we propose Set-To-Arrangement Ranking (STARank), a new framework directly generates the permutations of the candidate items without the need for individually scoring and sort operations; and is end-to-end differentiable. As a result, STARank can operate when only the ground-truth permutations are accessible without requiring access to the ground-truth relevance scores for items. For this purpose, STARank first reads the candidate items in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#25968;&#23398;&#21644;&#32479;&#35745;&#26041;&#27861;&#30830;&#23450;&#26631;&#31614;&#30340;&#30456;&#20284;&#24615;&#65292;&#21253;&#25324;&#35789;&#27719;&#30456;&#20284;&#24615;&#21644;&#20849;&#29616;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#32771;&#34385;&#20102;&#26631;&#31614;&#20998;&#37197;&#30340;&#26102;&#38388;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2201.03622</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#22312;&#31038;&#21306;&#26816;&#27979;&#20013;&#30340;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Graph-Based Recommendation System Enhanced with Community Detection. (arXiv:2201.03622v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.03622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#21033;&#29992;&#25968;&#23398;&#21644;&#32479;&#35745;&#26041;&#27861;&#30830;&#23450;&#26631;&#31614;&#30340;&#30456;&#20284;&#24615;&#65292;&#21253;&#25324;&#35789;&#27719;&#30456;&#20284;&#24615;&#21644;&#20849;&#29616;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#32771;&#34385;&#20102;&#26631;&#31614;&#20998;&#37197;&#30340;&#26102;&#38388;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#30740;&#31350;&#32773;&#24050;&#32463;&#21033;&#29992;&#26631;&#31614;&#20449;&#24687;&#26469;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#20013;&#25512;&#33616;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#30740;&#31350;&#29992;&#25143;&#30340;&#26631;&#31614;&#65292;&#21487;&#20197;&#20102;&#35299;&#20182;&#20204;&#30340;&#20852;&#36259;&#65292;&#20174;&#32780;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29992;&#25143;&#33258;&#23450;&#20041;&#26631;&#31614;&#30340;&#20219;&#24847;&#24615;&#21644;&#32570;&#20047;&#38480;&#21046;&#65292;&#30830;&#23450;&#20854;&#30830;&#20999;&#21547;&#20041;&#21644;&#26631;&#31614;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#23384;&#22312;&#38382;&#39064;&#12290;&#26412;&#25991;&#21033;&#29992;&#25968;&#23398;&#21644;&#32479;&#35745;&#26041;&#27861;&#30830;&#23450;&#26631;&#31614;&#30340;&#35789;&#27719;&#30456;&#20284;&#24615;&#21644;&#20849;&#29616;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#20998;&#37197;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#21478;&#22806;&#65292;&#32771;&#34385;&#21040;&#29992;&#25143;&#20852;&#36259;&#38543;&#26102;&#38388;&#21464;&#21270;&#65292;&#26412;&#25991;&#36824;&#22312;&#20849;&#29616;&#26631;&#31614;&#20013;&#32771;&#34385;&#20102;&#26631;&#31614;&#20998;&#37197;&#30340;&#26102;&#38388;&#20197;&#30830;&#23450;&#26631;&#31614;&#30340;&#30456;&#20284;&#24615;&#12290;&#28982;&#21518;&#65292;&#22522;&#20110;&#26631;&#31614;&#30340;&#30456;&#20284;&#24615;&#21019;&#24314;&#22270;&#24418;&#27169;&#22411;&#26469;&#24314;&#27169;&#29992;&#25143;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many researchers have used tag information to improve the performance of recommendation techniques in recommender systems. Examining the tags of users will help to get their interests and leads to more accuracy in the recommendations. Since user-defined tags are chosen freely and without any restrictions, problems arise in determining their exact meaning and the similarity of tags. However, using thesaurus and ontologies to find the meaning of tags is not very efficient due to their free definition by users and the use of different languages in many data sets. Therefore, this article uses mathematical and statistical methods to determine lexical similarity and co-occurrence tags solution to assign semantic similarity. On the other hand, due to the change of users' interests over time this article has considered the time of tag assignments in co-occurrence tags for determining similarity of tags. Then the graph is created based on similarity of tags. For modeling the interests of the us
&lt;/p&gt;</description></item></channel></rss>