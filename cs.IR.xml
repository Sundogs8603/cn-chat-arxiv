<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37325;&#26032;&#25490;&#21517;&#22120;FiT5&#65292;&#23427;&#23558;&#25991;&#26723;&#25991;&#26412;&#20449;&#24687;&#12289;&#26816;&#32034;&#29305;&#24449;&#21644;&#20840;&#23616;&#25991;&#26723;&#20449;&#24687;&#32479;&#19968;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#20840;&#23616;&#27880;&#24847;&#21147;&#20351;&#24471;FiT5&#33021;&#22815;&#20849;&#21516;&#21033;&#29992;&#25490;&#21517;&#29305;&#24449;&#65292;&#20174;&#32780;&#25913;&#21892;&#26816;&#27979;&#24494;&#22937;&#24046;&#21035;&#30340;&#33021;&#21147;&#65292;&#22312;&#23454;&#39564;&#34920;&#29616;&#19978;&#26174;&#33879;&#25552;&#39640;&#20102;&#25490;&#21517;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.14685</link><description>&lt;p&gt;
Fusion-in-T5: &#23558;&#25991;&#26723;&#25490;&#21517;&#20449;&#21495;&#32479;&#19968;&#36215;&#26469;&#20197;&#25913;&#36827;&#20449;&#24687;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval. (arXiv:2305.14685v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37325;&#26032;&#25490;&#21517;&#22120;FiT5&#65292;&#23427;&#23558;&#25991;&#26723;&#25991;&#26412;&#20449;&#24687;&#12289;&#26816;&#32034;&#29305;&#24449;&#21644;&#20840;&#23616;&#25991;&#26723;&#20449;&#24687;&#32479;&#19968;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#20840;&#23616;&#27880;&#24847;&#21147;&#20351;&#24471;FiT5&#33021;&#22815;&#20849;&#21516;&#21033;&#29992;&#25490;&#21517;&#29305;&#24449;&#65292;&#20174;&#32780;&#25913;&#21892;&#26816;&#27979;&#24494;&#22937;&#24046;&#21035;&#30340;&#33021;&#21147;&#65292;&#22312;&#23454;&#39564;&#34920;&#29616;&#19978;&#26174;&#33879;&#25552;&#39640;&#20102;&#25490;&#21517;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#35265;&#30340;&#20449;&#24687;&#26816;&#32034;&#27969;&#31243;&#36890;&#24120;&#37319;&#29992;&#32423;&#32852;&#31995;&#32479;&#65292;&#21487;&#33021;&#28041;&#21450;&#22810;&#20010;&#25490;&#21517;&#22120;&#21644;/&#25110;&#34701;&#21512;&#27169;&#22411;&#36880;&#27493;&#25972;&#21512;&#19981;&#21516;&#30340;&#20449;&#24687;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Fusion-in-T5&#65288;FiT5&#65289;&#30340;&#26032;&#22411;&#37325;&#26032;&#25490;&#21517;&#22120;&#65292;&#23427;&#20351;&#29992;&#22522;&#20110;&#27169;&#26495;&#30340;&#36755;&#20837;&#21644;&#20840;&#23616;&#27880;&#24847;&#21147;&#23558;&#25991;&#26723;&#25991;&#26412;&#20449;&#24687;&#12289;&#26816;&#32034;&#29305;&#24449;&#21644;&#20840;&#23616;&#25991;&#26723;&#20449;&#24687;&#32479;&#19968;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#27169;&#22411;&#20013;&#12290;&#22312;MS MARCO&#21644;TREC DL&#30340;&#27573;&#33853;&#25490;&#21517;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#23454;&#39564;&#34920;&#26126;FiT5&#22312;&#20808;&#21069;&#30340;&#27969;&#27700;&#32447;&#24615;&#33021;&#19978;&#26174;&#33879;&#25552;&#39640;&#20102;&#25490;&#21517;&#34920;&#29616;&#12290;&#20998;&#26512;&#21457;&#29616;&#65292;&#36890;&#36807;&#20840;&#23616;&#27880;&#24847;&#21147;&#65292;FiT5&#33021;&#22815;&#36880;&#28176;&#20851;&#27880;&#30456;&#20851;&#25991;&#26723;&#65292;&#20174;&#32780;&#20849;&#21516;&#21033;&#29992;&#25490;&#21517;&#29305;&#24449;&#65292;&#25913;&#21892;&#26816;&#27979;&#23427;&#20204;&#20043;&#38388;&#24494;&#22937;&#24046;&#21035;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#23558;&#24320;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Common IR pipelines are typically cascade systems that may involve multiple rankers and/or fusion models to integrate different information step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention. Experiments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 significantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#20174;&#29983;&#25104;&#27169;&#22411;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#22522;&#20110;&#23884;&#20837;&#30340;&#23454;&#20307;&#23545;&#40784;&#65288;EEA&#65289;&#38382;&#39064;&#65292;&#24341;&#20837;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;EEA&#26041;&#27861;&#21450;&#25552;&#20986;&#30340;&#29983;&#25104;&#30340;EEA&#65288;GEEA&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#20114;&#30456;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;M-VAE&#65289;&#23454;&#29616;&#23454;&#20307;&#20174;&#19968;&#20010;KG&#36716;&#25442;&#21040;&#21478;&#19968;&#20010;KG&#65292;&#24182;&#19988;&#20174;&#38543;&#26426;&#22122;&#22768;&#21521;&#37327;&#29983;&#25104;&#26032;&#30340;&#23454;&#20307;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.14651</link><description>&lt;p&gt;
&#20174;&#29983;&#25104;&#27169;&#22411;&#30340;&#35282;&#24230;&#37325;&#26032;&#23457;&#35270;&#23454;&#20307;&#23545;&#40784;&#21450;&#36229;&#36234;&#65306;&#19968;&#20010;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Revisit and Outstrip Entity Alignment: A Perspective of Generative Models. (arXiv:2305.14651v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14651
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#20174;&#29983;&#25104;&#27169;&#22411;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#22522;&#20110;&#23884;&#20837;&#30340;&#23454;&#20307;&#23545;&#40784;&#65288;EEA&#65289;&#38382;&#39064;&#65292;&#24341;&#20837;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;EEA&#26041;&#27861;&#21450;&#25552;&#20986;&#30340;&#29983;&#25104;&#30340;EEA&#65288;GEEA&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#20114;&#30456;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;M-VAE&#65289;&#23454;&#29616;&#23454;&#20307;&#20174;&#19968;&#20010;KG&#36716;&#25442;&#21040;&#21478;&#19968;&#20010;KG&#65292;&#24182;&#19988;&#20174;&#38543;&#26426;&#22122;&#22768;&#21521;&#37327;&#29983;&#25104;&#26032;&#30340;&#23454;&#20307;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#23884;&#20837;&#30340;&#26041;&#27861;&#22312;&#21033;&#29992;&#22810;&#27169;&#24577;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#23884;&#20837;&#30340;&#23454;&#20307;&#23545;&#40784;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#29983;&#25104;&#27169;&#22411;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#22522;&#20110;&#23884;&#20837;&#30340;&#23454;&#20307;&#23545;&#40784;&#65288;EEA&#65289;&#12290;&#25105;&#20204;&#34920;&#26126;EEA&#26159;&#19968;&#20010;&#29305;&#27530;&#30340;&#38382;&#39064;&#65292;&#20854;&#20027;&#35201;&#30446;&#26631;&#31867;&#20284;&#20110;&#20856;&#22411;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#30446;&#26631;&#65292;&#22522;&#20110;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#26368;&#36817;&#21457;&#23637;&#30340;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30340;EEA&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20182;&#20204;&#19981;&#23436;&#25972;&#30340;&#30446;&#26631;&#38480;&#21046;&#20102;&#23454;&#20307;&#23545;&#40784;&#21644;&#23454;&#20307;&#21512;&#25104;&#65288;&#21363;&#29983;&#25104;&#26032;&#23454;&#20307;&#65289;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#29983;&#25104;&#30340;EEA&#65288;abbr.&#65292;GEEA&#65289;&#26694;&#26550;&#21644;&#25552;&#20986;&#30340;&#20114;&#30456;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;M-VAE&#65289;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;M-VAE&#21487;&#20197;&#23558;&#19968;&#20010;&#23454;&#20307;&#20174;&#19968;&#20010;KG&#36716;&#25442;&#21040;&#21478;&#19968;&#20010;KG&#65292;&#24182;&#20174;&#38543;&#26426;&#22122;&#22768;&#21521;&#37327;&#29983;&#25104;&#26032;&#23454;&#20307;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#23454;&#39564;&#23637;&#31034;&#20102;GEEA&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent embedding-based methods have achieved great successes on exploiting entity alignment from knowledge graph (KG) embeddings of multiple modals. In this paper, we study embedding-based entity alignment (EEA) from a perspective of generative models. We show that EEA is a special problem where the main objective is analogous to that in a typical generative model, based on which we theoretically prove the effectiveness of the recently developed generative adversarial network (GAN)-based EEA methods. We then reveal that their incomplete objective limits the capacity on both entity alignment and entity synthesis (i.e., generating new entities). We mitigate this problem by introducing a generative EEA (abbr., GEEA) framework with the proposed mutual variational autoencoder (M-VAE) as the generative model. M-VAE can convert an entity from one KG to another and generate new entities from random noise vectors. We demonstrate the power of GEEA with theoretical analysis and empirical experime
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;ALCE&#65292;&#26159;&#39318;&#20010;&#33258;&#21160;LLMs&#24341;&#25991;&#35780;&#20272;&#22522;&#20934;&#65292;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24102;&#24341;&#25991;&#30340;&#25991;&#26412;&#65292;&#25552;&#39640;&#20854;&#20107;&#23454;&#27491;&#30830;&#24615;&#21644;&#21487;&#39564;&#35777;&#24615;&#65307;&#25552;&#31034;LLMs&#29305;&#23450;&#30340;&#20851;&#38190;&#35789;&#25110;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24341;&#25991;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14627</link><description>&lt;p&gt;
&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24102;&#24341;&#25991;&#30340;&#25991;&#26412;
&lt;/p&gt;
&lt;p&gt;
Enabling Large Language Models to Generate Text with Citations. (arXiv:2305.14627v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;ALCE&#65292;&#26159;&#39318;&#20010;&#33258;&#21160;LLMs&#24341;&#25991;&#35780;&#20272;&#22522;&#20934;&#65292;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24102;&#24341;&#25991;&#30340;&#25991;&#26412;&#65292;&#25552;&#39640;&#20854;&#20107;&#23454;&#27491;&#30830;&#24615;&#21644;&#21487;&#39564;&#35777;&#24615;&#65307;&#25552;&#31034;LLMs&#29305;&#23450;&#30340;&#20851;&#38190;&#35789;&#25110;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24341;&#25991;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#25104;&#20026;&#24191;&#27867;&#20351;&#29992;&#30340;&#20449;&#24687;&#23547;&#25214;&#24037;&#20855;&#65292;&#20294;&#29983;&#25104;&#30340;&#36755;&#20986;&#23481;&#26131;&#20986;&#29616;&#24187;&#35273;&#12290;&#26412;&#25991;&#26088;&#22312;&#23454;&#29616;LLMs&#29983;&#25104;&#24102;&#24341;&#25991;&#30340;&#25991;&#26412;&#65292;&#25552;&#39640;&#20854;&#20107;&#23454;&#27491;&#30830;&#24615;&#21644;&#21487;&#39564;&#35777;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ALCE&#65292;&#36825;&#26159;&#39318;&#20010;&#33258;&#21160;LLMs&#24341;&#25991;&#35780;&#20272;&#22522;&#20934;&#12290;ALCE&#25910;&#38598;&#20102;&#21508;&#31181;&#38382;&#39064;&#21644;&#26816;&#32034;&#35821;&#26009;&#24211;&#65292;&#24182;&#35201;&#27714;&#24314;&#31435;&#31471;&#21040;&#31471;&#31995;&#32479;&#20197;&#26816;&#32034;&#25903;&#25345;&#35777;&#25454;&#24182;&#29983;&#25104;&#24102;&#26377;&#24341;&#25991;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#27839;&#30528;&#27969;&#30021;&#24615;&#12289;&#27491;&#30830;&#24615;&#21644;&#24341;&#25991;&#36136;&#37327;&#19977;&#20010;&#32500;&#24230;&#26500;&#24314;&#33258;&#21160;&#25351;&#26631;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#19982;&#20154;&#31867;&#21028;&#26029;&#30340;&#24378;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;LLMs&#21644;&#26032;&#30340;&#25552;&#31034;&#31574;&#30053;&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#24403;&#21069;&#31995;&#32479;&#20173;&#26377;&#30456;&#24403;&#22823;&#30340;&#25552;&#21319;&#31354;&#38388;--&#20363;&#22914;&#65292;&#25552;&#31034;LLMs&#29305;&#23450;&#30340;&#20851;&#38190;&#35789;&#25110;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24341;&#25991;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#26410;&#26469;&#30740;&#31350;&#21457;&#23637;&#33021;&#22815;&#29983;&#25104;&#21487;&#39564;&#35777;&#21644;&#21487;&#20449;&#36182;&#36755;&#20986;&#30340;LLMs&#25552;&#20379;&#20102;&#22362;&#23454;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have emerged as a widely-used tool for information seeking, but their generated outputs are prone to hallucination. In this work, we aim to enable LLMs to generate text with citations, improving their factual correctness and verifiability. Existing work mainly relies on commercial search engines and human evaluation, making it challenging to reproduce and compare with different modeling approaches. We propose ALCE, the first benchmark for Automatic LLMs' Citation Evaluation. ALCE collects a diverse set of questions and retrieval corpora and requires building end-to-end systems to retrieve supporting evidence and generate answers with citations. We build automatic metrics along three dimensions -- fluency, correctness, and citation quality -- and demonstrate their strong correlation with human judgements. Our experiments with state-of-the-art LLMs and novel prompting strategies show that current systems have considerable room for improvements -for example,
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#21270;&#20027;&#39064;&#30456;&#24178;&#24615;&#35780;&#20272;&#25351;&#26631;&#65288;CTC&#65289;&#65292;&#35813;&#25351;&#26631;&#19981;&#20165;&#22312;&#30701;&#25991;&#26723;&#19978;&#36816;&#20316;&#33391;&#22909;&#65292;&#32780;&#19988;&#22312;&#30456;&#23545;&#20110;&#20854;&#20182;&#20116;&#20010;&#25351;&#26631;&#35780;&#20272;&#19978;&#20855;&#26377;&#26356;&#39640;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.14587</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#21270;&#20027;&#39064;&#30456;&#24178;&#24615;&#35780;&#20272;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Contextualized Topic Coherence Metrics. (arXiv:2305.14587v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#21270;&#20027;&#39064;&#30456;&#24178;&#24615;&#35780;&#20272;&#25351;&#26631;&#65288;CTC&#65289;&#65292;&#35813;&#25351;&#26631;&#19981;&#20165;&#22312;&#30701;&#25991;&#26723;&#19978;&#36816;&#20316;&#33391;&#22909;&#65292;&#32780;&#19988;&#22312;&#30456;&#23545;&#20110;&#20854;&#20182;&#20116;&#20010;&#25351;&#26631;&#35780;&#20272;&#19978;&#20855;&#26377;&#26356;&#39640;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#31070;&#32463;&#20027;&#39064;&#24314;&#27169;&#30340;&#22823;&#37327;&#30740;&#31350;&#34987;&#25351;&#36131;&#22312;&#20248;&#21270;&#33258;&#21160;&#21270;&#20027;&#39064;&#35780;&#20272;&#25351;&#26631;&#30340;&#21516;&#26102;&#29306;&#29298;&#20102;&#23454;&#36136;&#24615;&#30340;&#20027;&#39064;&#35782;&#21035;&#12290;&#20294;&#26159;&#65292;&#20154;&#24037;&#26631;&#27880;&#30340;&#25104;&#26412;&#39640;&#26114;&#19988;&#32791;&#26102;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#65292;&#21463;&#21040;&#20154;&#31867;&#20027;&#39064;&#35780;&#20272;&#30340;&#21551;&#21457;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24230;&#37327;&#31995;&#21015;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;&#21270;&#20027;&#39064;&#30456;&#24178;&#24615;&#65288;CTC&#65289;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#19968;&#20010;&#20840;&#33258;&#21160;&#30340;&#29256;&#26412;&#20197;&#21450;&#19968;&#20010;&#21322;&#33258;&#21160;&#21270;&#30340;CTC&#65292;&#35813;&#29256;&#26412;&#38024;&#23545;&#20154;&#24037;&#20013;&#24515;&#30340;&#30456;&#24178;&#24615;&#35780;&#20272;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#33258;&#21160;&#21270;&#26041;&#27861;&#30340;&#25928;&#29575;&#12290;&#25105;&#20204;&#22312;&#20845;&#20010;&#20027;&#39064;&#27169;&#22411;&#19978;&#30456;&#23545;&#20110;&#20116;&#20010;&#20854;&#20182;&#25351;&#26631;&#35780;&#20272;CTC&#65292;&#24182;&#21457;&#29616;&#23427;&#20248;&#20110;&#33258;&#21160;&#20027;&#39064;&#19968;&#33268;&#24615;&#26041;&#27861;&#65292;&#22312;&#30701;&#25991;&#26723;&#19978;&#36816;&#20316;&#33391;&#22909;&#65292;&#24182;&#19988;&#19981;&#23481;&#26131;&#21463;&#21040;&#35780;&#20998;&#39640;&#20294;&#27627;&#26080;&#24847;&#20041;&#30340;&#20027;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent explosion in work on neural topic modeling has been criticized for optimizing automated topic evaluation metrics at the expense of actual meaningful topic identification. But human annotation remains expensive and time-consuming. We propose LLM-based methods inspired by standard human topic evaluations, in a family of metrics called Contextualized Topic Coherence (CTC). We evaluate both a fully automated version as well as a semi-automated CTC that allows human-centered evaluation of coherence while maintaining the efficiency of automated methods. We evaluate CTC relative to five other metrics on six topic models and find that it outperforms automated topic coherence methods, works well on short documents, and is not susceptible to meaningless but high-scoring topics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#21253;&#21547;&#25163;&#24037;PT&#25512;&#33616;&#30340;Web&#39029;&#38754;&#20013;&#25552;&#21462;PTs&#30340;&#26041;&#27861;&#65292;&#20197;&#24314;&#31435;&#36141;&#29289;&#20852;&#36259;&#65288;SI&#65289;&#21644;&#20135;&#21697;&#31867;&#22411;&#65288;PT&#65289;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#24182;&#24341;&#20837;&#20102;TrENC&#26469;&#25913;&#36827;&#20869;&#37096;&#33410;&#28857;&#20043;&#38388;&#30340;&#20381;&#36182;&#24314;&#27169;&#12290;</title><link>http://arxiv.org/abs/2305.14549</link><description>&lt;p&gt;
&#20174;&#32593;&#32476;&#20013;&#25552;&#21462;&#19982;&#36141;&#29289;&#20852;&#36259;&#30456;&#20851;&#30340;&#20135;&#21697;&#31867;&#22411;
&lt;/p&gt;
&lt;p&gt;
Extracting Shopping Interest-Related Product Types from the Web. (arXiv:2305.14549v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#21253;&#21547;&#25163;&#24037;PT&#25512;&#33616;&#30340;Web&#39029;&#38754;&#20013;&#25552;&#21462;PTs&#30340;&#26041;&#27861;&#65292;&#20197;&#24314;&#31435;&#36141;&#29289;&#20852;&#36259;&#65288;SI&#65289;&#21644;&#20135;&#21697;&#31867;&#22411;&#65288;PT&#65289;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#24182;&#24341;&#20837;&#20102;TrENC&#26469;&#25913;&#36827;&#20869;&#37096;&#33410;&#28857;&#20043;&#38388;&#30340;&#20381;&#36182;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#23458;&#25143;&#22312;&#23547;&#25214;&#20854;&#39640;&#32423;&#36141;&#29289;&#20852;&#36259;&#65288;&#22914;&#24466;&#27493;&#26053;&#34892;&#31561;&#65289;&#30340;&#20135;&#21697;&#26102;&#65292;&#25512;&#33616;&#22810;&#26679;&#21270;&#30340;&#20135;&#21697;&#31867;&#22411;&#65288;PTs&#65289;&#23545;&#20110;&#25552;&#20379;&#33391;&#22909;&#30340;&#36141;&#29289;&#20307;&#39564;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30005;&#23376;&#21830;&#21153;&#20135;&#21697;&#30446;&#24405;&#20013;&#36890;&#24120;&#32570;&#20047;SI-PT&#30340;&#36830;&#25509;&#65292;&#24182;&#19988;&#30001;&#20110;&#28508;&#22312;&#30340;SI&#25968;&#37327;&#24040;&#22823;&#65292;&#25163;&#21160;&#26500;&#24314;&#36825;&#31181;&#36830;&#25509;&#20063;&#26159;&#38750;&#24120;&#26114;&#36149;&#30340;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#26080;&#27861;&#24314;&#31435;&#26131;&#20110;&#35775;&#38382;&#30340;&#30693;&#35782;&#31995;&#32479;&#12290;&#20026;&#20102;&#24314;&#31435;&#36825;&#26679;&#30340;&#36830;&#25509;&#65292;&#25105;&#20204;&#25552;&#20986;&#20174;&#21253;&#21547;&#25163;&#24037;PT&#25512;&#33616;&#30340;Web&#39029;&#38754;&#20013;&#25552;&#21462;PTs&#30340;&#26041;&#27861;&#12290;&#23558;&#25552;&#21462;&#20219;&#21153;&#35774;&#32622;&#20026;&#20108;&#36827;&#21046;HTML&#33410;&#28857;&#20998;&#31867;&#65292;&#22240;&#20026;&#25105;&#20204;&#30340;&#30446;&#26631;Web&#39029;&#38754;&#20013;&#30340;HTML&#33410;&#28857;&#21487;&#20197;&#21576;&#29616;&#19968;&#20010;&#19988;&#20165;&#19968;&#20010;PT&#30701;&#35821;&#30340;&#26222;&#36941;&#35266;&#23519;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;TrENC&#65292;&#21363;Tree-Transformer&#32534;&#30721;&#22120;&#29992;&#20110;&#33410;&#28857;&#20998;&#31867;&#12290;&#23427;&#25913;&#36827;&#20102;&#20869;&#37096;&#33410;&#28857;&#20043;&#38388;&#30340;&#20381;&#36182;&#24314;&#27169;&#65292;&#24182;&#20445;&#30041;&#20102;&#38271;&#26399;&#30340;&#20804;&#24351;&#22992;&#22969;&#21644;&#31062;&#20808;-&#21518;&#20195;&#20851;&#31995;&#30340;&#27880;&#24847;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommending a diversity of product types (PTs) is important for a good shopping experience when customers are looking for products around their high-level shopping interests (SIs) such as hiking. However, the SI-PT connection is typically absent in e-commerce product catalogs and expensive to construct manually due to the volume of potential SIs, which prevents us from establishing a recommender with easily accessible knowledge systems. To establish such connections, we propose to extract PTs from the Web pages containing hand-crafted PT recommendations for SIs. The extraction task is formulated as binary HTML node classification given the general observation that an HTML node in our target Web pages can present one and only one PT phrase. Accordingly, we introduce TrENC, which stands for Tree-Transformer Encoders for Node Classification. It improves the inter-node dependency modeling with modified attention mechanisms that preserve the long-term sibling and ancestor-descendant relati
&lt;/p&gt;</description></item><item><title>NAIL&#26159;&#19968;&#31181;&#24102;&#26377;&#39640;&#25928;&#38750;&#33258;&#22238;&#24402;&#35299;&#30721;&#22120;&#30340;&#35789;&#27719;&#26816;&#32034;&#25351;&#25968;&#27169;&#22411;&#65292;&#21487;&#19982;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#20860;&#23481;&#65292;&#24182;&#19988;&#20351;&#29992;&#21830;&#21697;CPU&#25552;&#20379;&#26381;&#21153;&#12290;&#23427;&#21487;&#20197;&#25429;&#25417;Transformer&#20132;&#21449;&#20851;&#27880;&#27169;&#22411;&#25910;&#30410;&#39640;&#36798;86&#65285;&#30340;&#26041;&#27861;&#65292;&#19982;BM25&#26816;&#32034;&#22120;&#32467;&#21512;&#20351;&#29992;&#21305;&#37197;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#21452;&#32534;&#30721;&#22120;&#26816;&#32034;&#22120;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.14499</link><description>&lt;p&gt;
NAIL: &#24102;&#39640;&#25928;&#38750;&#33258;&#22238;&#24402;&#35299;&#30721;&#22120;&#30340;&#35789;&#27719;&#26816;&#32034;&#25351;&#25968;
&lt;/p&gt;
&lt;p&gt;
NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders. (arXiv:2305.14499v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14499
&lt;/p&gt;
&lt;p&gt;
NAIL&#26159;&#19968;&#31181;&#24102;&#26377;&#39640;&#25928;&#38750;&#33258;&#22238;&#24402;&#35299;&#30721;&#22120;&#30340;&#35789;&#27719;&#26816;&#32034;&#25351;&#25968;&#27169;&#22411;&#65292;&#21487;&#19982;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#20860;&#23481;&#65292;&#24182;&#19988;&#20351;&#29992;&#21830;&#21697;CPU&#25552;&#20379;&#26381;&#21153;&#12290;&#23427;&#21487;&#20197;&#25429;&#25417;Transformer&#20132;&#21449;&#20851;&#27880;&#27169;&#22411;&#25910;&#30410;&#39640;&#36798;86&#65285;&#30340;&#26041;&#27861;&#65292;&#19982;BM25&#26816;&#32034;&#22120;&#32467;&#21512;&#20351;&#29992;&#21305;&#37197;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#21452;&#32534;&#30721;&#22120;&#26816;&#32034;&#22120;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#25991;&#26723;&#37325;&#26032;&#25490;&#21517;&#22120;&#22312;&#31934;&#24230;&#26041;&#38754;&#38750;&#24120;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#26368;&#22909;&#30340;&#27169;&#22411;&#38656;&#35201;&#19987;&#29992;&#30828;&#20214;&#36827;&#34892;&#26381;&#21153;&#65292;&#36825;&#26159;&#26114;&#36149;&#24182;&#19988;&#36890;&#24120;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#26381;&#21153;&#26102;&#38388;&#35201;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#25429;&#25417;Transformer&#20132;&#21449;&#20851;&#27880;&#27169;&#22411;&#25910;&#30410;&#39640;&#36798;86&#65285;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#21482;&#38656;&#35201;&#27599;&#20010;&#25991;&#26723;&#36716;&#25442;&#22120;FLOP&#30340;10-6&#65285;&#30340;&#35789;&#27719;&#24471;&#20998;&#21151;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#21830;&#21697;CPU&#25552;&#20379;&#26381;&#21153;&#12290;&#24403;&#19982;BM25&#26816;&#32034;&#22120;&#32467;&#21512;&#20351;&#29992;&#26102;&#65292;&#27492;&#26041;&#27861;&#21487;&#20197;&#21305;&#37197;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#21452;&#32534;&#30721;&#22120;&#26816;&#32034;&#22120;&#30340;&#36136;&#37327;&#65292;&#35813;&#26816;&#32034;&#22120;&#20173;&#38656;&#35201;&#21152;&#36895;&#22120;&#36827;&#34892;&#26597;&#35810;&#32534;&#30721;&#12290;&#25105;&#20204;&#23558;NAIL&#65288;&#24102;&#26377;&#35821;&#35328;&#27169;&#22411;&#30340;&#38750;&#33258;&#22238;&#24402;&#32034;&#24341;&#65289;&#24341;&#20837;&#20026;&#19982;&#26368;&#36817;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#21644;&#20165;&#35299;&#30721;&#22120;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#20363;&#22914;T5&#12289;GPT-3&#21644;PaLM&#65289;&#20860;&#23481;&#30340;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#12290;&#35813;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#21487;&#20197;&#21033;&#29992;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#65292;&#24182;&#21487;&#20197;&#24494;&#35843;&#20197;&#26377;&#25928;&#22320;&#26500;&#24314;&#19981;&#38656;&#35201;n
&lt;/p&gt;
&lt;p&gt;
Neural document rerankers are extremely effective in terms of accuracy. However, the best models require dedicated hardware for serving, which is costly and often not feasible. To avoid this serving-time requirement, we present a method of capturing up to 86% of the gains of a Transformer cross-attention model with a lexicalized scoring function that only requires 10-6% of the Transformer's FLOPs per document and can be served using commodity CPUs. When combined with a BM25 retriever, this approach matches the quality of a state-of-the art dual encoder retriever, that still requires an accelerator for query encoding. We introduce NAIL (Non-Autoregressive Indexing with Language models) as a model architecture that is compatible with recent encoder-decoder and decoder-only large language models, such as T5, GPT-3 and PaLM. This model architecture can leverage existing pre-trained checkpoints and can be fine-tuned for efficiently constructing document representations that do not require n
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#30693;&#35782;&#22270;&#35889;&#26597;&#35810;&#30340;&#30740;&#31350;&#36827;&#23637;&#21644;&#26368;&#26032;&#25216;&#26415;&#21644;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.14485</link><description>&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#26597;&#35810;
&lt;/p&gt;
&lt;p&gt;
Knowledge Graphs Querying. (arXiv:2305.14485v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14485
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#30693;&#35782;&#22270;&#35889;&#26597;&#35810;&#30340;&#30740;&#31350;&#36827;&#23637;&#21644;&#26368;&#26032;&#25216;&#26415;&#21644;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#22914;DBpedia&#12289;Freebase&#12289;YAGO&#12289;Wikidata&#21644;NELL&#31561;&#34987;&#26500;&#24314;&#29992;&#26469;&#23384;&#20648;&#22823;&#35268;&#27169;&#12289;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#20107;&#23454;&#65288;&#20027;&#39064;&#12289;&#35859;&#35821;&#12289;&#23545;&#35937;&#65289;&#19977;&#20803;&#32452;&#65292;&#21487;&#20197;&#34987;&#24314;&#27169;&#20026;&#19968;&#20010;&#22270;&#24418;&#65292;&#20854;&#20013;&#19968;&#20010;&#33410;&#28857;&#65288;&#20027;&#39064;&#25110;&#23545;&#35937;&#65289;&#20195;&#34920;&#20855;&#26377;&#23646;&#24615;&#30340;&#23454;&#20307;&#65292;&#24182;&#19988;&#26377;&#21521;&#36793;&#65288;&#35859;&#35789;&#65289;&#26159;&#20004;&#20010;&#23454;&#20307;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#22312;Web&#25628;&#32034;&#12289;&#38382;&#31572;&#12289;&#35821;&#20041;&#25628;&#32034;&#12289;&#20010;&#20154;&#21161;&#25163;&#12289;&#20107;&#23454;&#26816;&#26597;&#21644;&#25512;&#33616;&#20013;&#65292;&#26597;&#35810; KG &#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#23613;&#31649;&#22312; KG &#26500;&#24314;&#21644;&#32500;&#25252;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#26368;&#36817;&#30475;&#21040;&#20102;KG &#26597;&#35810;&#21644;&#38382;&#31572;&#30740;&#31350;&#26041;&#38754;&#30340;&#28608;&#22686;&#12290;&#25105;&#20204;&#35843;&#26597;&#30340;&#30446;&#30340;&#26159;&#21452;&#37325;&#30340;&#12290;&#39318;&#20808;&#65292;KG&#26597;&#35810;&#30340;&#30740;&#31350;&#30001;&#22810;&#20010;&#31038;&#32676;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#22914;&#25968;&#25454;&#24211;&#12289;&#25968;&#25454;&#25366;&#25496;&#12289;&#35821;&#20041;&#32593;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#65292;&#20851;&#27880;&#28857;&#21644;&#26415;&#35821;&#19981;&#21516;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#36824;&#35843;&#26597;&#20102;&#26368;&#36817;&#30340;KG&#26597;&#35810;&#30740;&#31350;&#20013;&#20351;&#29992;&#30340;&#26368;&#26032;&#25216;&#26415;&#21644;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graphs (KGs) such as DBpedia, Freebase, YAGO, Wikidata, and NELL were constructed to store large-scale, real-world facts as (subject, predicate, object) triples -- that can also be modeled as a graph, where a node (a subject or an object) represents an entity with attributes, and a directed edge (a predicate) is a relationship between two entities. Querying KGs is critical in web search, question answering (QA), semantic search, personal assistants, fact checking, and recommendation. While significant progress has been made on KG construction and curation, thanks to deep learning recently we have seen a surge of research on KG querying and QA. The objectives of our survey are two-fold. First, research on KG querying has been conducted by several communities, such as databases, data mining, semantic web, machine learning, information retrieval, and natural language processing (NLP), with different focus and terminologies; and also in diverse topics ranging from graph databases
&lt;/p&gt;</description></item><item><title>&#19968;&#31181;&#21327;&#21516;&#36807;&#28388;&#26032;&#26041;&#27861;&#29992;&#20110;&#31283;&#20581;&#23545;&#35805;&#29702;&#35299;&#65292;&#22312;&#21382;&#21490;&#29992;&#25143;-&#23454;&#20307;&#20132;&#20114;&#30340;&#22522;&#30784;&#19978;&#65292;&#21033;&#29992;&#22810;&#36339;&#23458;&#25143;&#20146;&#21644;&#21147;&#20016;&#23500;&#27599;&#20010;&#29992;&#25143;&#30340;&#32034;&#24341;&#65292;&#24182;&#20351;&#29992;&#26377;&#38480;&#20869;&#23384;BFGS&#31639;&#27861;&#35843;&#25972;&#27599;&#20010;&#32034;&#24341;&#30340;&#26435;&#37325;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#26126;&#26174;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#20010;&#24615;&#21270;&#26597;&#35810;&#37325;&#20889;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.14449</link><description>&lt;p&gt;
&#22270;&#35889;&#36935;&#35265;LLM&#65306;&#19968;&#31181;&#29992;&#20110;&#31283;&#20581;&#23545;&#35805;&#29702;&#35299;&#30340;&#21327;&#21516;&#36807;&#28388;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding. (arXiv:2305.14449v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14449
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#21327;&#21516;&#36807;&#28388;&#26032;&#26041;&#27861;&#29992;&#20110;&#31283;&#20581;&#23545;&#35805;&#29702;&#35299;&#65292;&#22312;&#21382;&#21490;&#29992;&#25143;-&#23454;&#20307;&#20132;&#20114;&#30340;&#22522;&#30784;&#19978;&#65292;&#21033;&#29992;&#22810;&#36339;&#23458;&#25143;&#20146;&#21644;&#21147;&#20016;&#23500;&#27599;&#20010;&#29992;&#25143;&#30340;&#32034;&#24341;&#65292;&#24182;&#20351;&#29992;&#26377;&#38480;&#20869;&#23384;BFGS&#31639;&#27861;&#35843;&#25972;&#27599;&#20010;&#32034;&#24341;&#30340;&#26435;&#37325;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#26126;&#26174;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#20010;&#24615;&#21270;&#26597;&#35810;&#37325;&#20889;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65288;&#20363;&#22914;Alexa&#65292;Siri&#65292;Google Assistant&#31561;&#65289;&#38656;&#35201;&#29702;&#35299;&#23384;&#22312;&#32570;&#38519;&#30340;&#26597;&#35810;&#20197;&#30830;&#20445;&#31283;&#20581;&#30340;&#20250;&#35805;&#29702;&#35299;&#24182;&#20943;&#23569;&#29992;&#25143;&#25705;&#25830;&#12290;&#36825;&#20123;&#26377;&#32570;&#38519;&#30340;&#26597;&#35810;&#36890;&#24120;&#26159;&#30001;&#29992;&#25143;&#30340;&#27495;&#20041;&#21644;&#38169;&#35823;&#65292;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#65288;NLU&#65289;&#20013;&#30340;&#38169;&#35823;&#24341;&#36215;&#30340;&#12290;&#20010;&#24615;&#21270;&#26597;&#35810;&#37325;&#20889;&#65288;&#20010;&#24615;&#21270;QR&#65289;&#26088;&#22312;&#20943;&#23569;&#36523;&#20307;&#21644;&#23614;&#37096;&#29992;&#25143;&#26597;&#35810;&#27969;&#37327;&#20013;&#30340;&#32570;&#38519;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#19982;&#23545;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#36807;&#21435;&#25104;&#21151;&#30340;&#29992;&#25143;&#20132;&#20114;&#30340;&#32034;&#24341;&#12290;&#26412;&#25991;&#25552;&#20986;&#25105;&#20204;&#30340;&#8220;&#21327;&#21516;&#26597;&#35810;&#37325;&#20889;&#8221;&#26041;&#27861;&#65292;&#19987;&#27880;&#20110;&#37325;&#20889;&#29992;&#25143;&#21382;&#21490;&#20013;&#27809;&#26377;&#20986;&#29616;&#36807;&#30340;&#26032;&#22411;&#29992;&#25143;&#20132;&#20114;&#12290;&#35813;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#8220;&#29992;&#25143;&#21453;&#39304;&#20132;&#20114;&#22270;&#8221;&#65288;FIG&#65289;&#65292;&#30001;&#21382;&#21490;&#29992;&#25143;-&#23454;&#20307;&#20132;&#20114;&#32452;&#25104;&#65292;&#24182;&#21033;&#29992;&#22810;&#36339;&#23458;&#25143;&#20146;&#21644;&#21147;&#26469;&#20016;&#23500;&#27599;&#20010;&#29992;&#25143;&#30340;&#32034;&#24341;&#65288;&#21363;&#21327;&#21516;&#29992;&#25143;&#32034;&#24341;&#65289;&#65292;&#20174;&#32780;&#24110;&#21161;&#35206;&#30422;&#26410;&#26469;&#26410;&#26366;&#35265;&#36807;&#30340;&#23384;&#22312;&#32570;&#38519;&#30340;&#26597;&#35810;&#12290;&#20026;&#20102;&#38450;&#27490;&#36825;&#20123;&#26032;&#30340;&#20016;&#23500;&#32034;&#24341;&#34987;&#22122;&#22768;&#21453;&#39304;&#20132;&#20114;&#25152;&#25903;&#37197;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#26377;&#38480;&#20869;&#23384;BFGS&#65288;LLM&#65289;&#31639;&#27861;&#21644;&#22238;&#36864;&#26041;&#26696;&#26469;&#35843;&#25972;&#27599;&#20010;&#32034;&#24341;&#30340;&#26435;&#37325;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#20010;&#24615;&#21270;QR&#26041;&#27861;&#65292;&#24182;&#22312;&#26410;&#30475;&#21040;&#30340;&#29992;&#25143;&#20132;&#20114;&#19978;&#21462;&#24471;&#20102;&#36817;&#20046;&#23436;&#32654;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational AI systems (e.g. Alexa, Siri, Google Assistant, etc.) need to understand queries with defects to ensure robust conversational understanding and reduce user frictions. The defective queries are often induced by user ambiguities and mistakes, or errors in the automatic speech recognition (ASR) and natural language understanding (NLU).  Personalized query rewriting (personalized QR) targets reducing defects in the torso and tail user query traffic, and it typically relies on an index of past successful user interactions with the conversational AI. This paper presents our "Collaborative Query Rewriting" approach that focuses on rewriting novel user interactions unseen in the user history. This approach builds a "user Feedback Interaction Graph" (FIG) consisting of historical user-entity interactions, and leverages multi-hop customer affinity to enrich each user's index (i.e. the Collaborative User Index) that would help cover future unseen defective queries. To counteract th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#38170;&#28857;&#39044;&#27979;&#30340;&#20219;&#21153;&#65292;&#36890;&#36807;&#23545;&#38142;&#25509;&#30446;&#26631;&#32593;&#39029;&#30340;&#29305;&#23450;&#37096;&#20998;&#36827;&#34892;&#35782;&#21035;&#65292;&#24110;&#21161;&#35835;&#32773;&#26356;&#26377;&#25928;&#22320;&#22312;&#38142;&#25509;&#32593;&#39029;&#20013;&#25214;&#21040;&#30456;&#20851;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2305.14337</link><description>&lt;p&gt;
Anchor Prediction: &#33258;&#21160;&#23436;&#21892;&#20114;&#32852;&#32593;&#38142;&#25509;
&lt;/p&gt;
&lt;p&gt;
Anchor Prediction: Automatic Refinement of Internet Links. (arXiv:2305.14337v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#38170;&#28857;&#39044;&#27979;&#30340;&#20219;&#21153;&#65292;&#36890;&#36807;&#23545;&#38142;&#25509;&#30446;&#26631;&#32593;&#39029;&#30340;&#29305;&#23450;&#37096;&#20998;&#36827;&#34892;&#35782;&#21035;&#65292;&#24110;&#21161;&#35835;&#32773;&#26356;&#26377;&#25928;&#22320;&#22312;&#38142;&#25509;&#32593;&#39029;&#20013;&#25214;&#21040;&#30456;&#20851;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#32852;&#32593;&#38142;&#25509;&#26159;&#36890;&#36807;&#25552;&#20379;&#20415;&#25463;&#30340;&#35775;&#38382;&#30456;&#20851;&#20449;&#24687;&#65292;&#24110;&#21161;&#29992;&#25143;&#28145;&#20837;&#20102;&#35299;&#19968;&#20010;&#20027;&#39064;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#38142;&#25509;&#37117;&#26159;&#26080;&#38170;&#28857;&#30340; - &#23427;&#20204;&#23558;&#30446;&#26631;&#32593;&#39029;&#20316;&#20026;&#19968;&#20010;&#25972;&#20307;&#38142;&#25509;&#65292;&#35835;&#32773;&#21487;&#33021;&#20250;&#33457;&#36153;&#22823;&#37327;&#30340;&#31934;&#21147;&#23450;&#20301;&#30446;&#26631;&#32593;&#39029;&#20013;&#20016;&#23500;&#20182;&#20204;&#29702;&#35299;&#38142;&#25509;&#28304;&#19978;&#19979;&#25991;&#30340;&#29305;&#23450;&#37096;&#20998;&#12290;&#20026;&#20102;&#24110;&#21161;&#35835;&#32773;&#26377;&#25928;&#22320;&#22312;&#38142;&#25509;&#30340;&#32593;&#39029;&#20013;&#25214;&#21040;&#20449;&#24687;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#38170;&#28857;&#39044;&#27979;&#30340;&#20219;&#21153;&#65292;&#30446;&#26631;&#26159;&#30830;&#23450;&#19982;&#28304;&#38142;&#25509;&#19978;&#19979;&#25991;&#26368;&#30456;&#20851;&#30340;&#30446;&#26631;&#32593;&#39029;&#30340;&#29305;&#23450;&#37096;&#20998;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#20316;&#32773;&#38170;&#28857;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324; 34K &#20010;&#33258;&#28982;&#20986;&#29616;&#30340;&#24102;&#38170;&#28857;&#38142;&#25509;&#65292;&#21453;&#26144;&#20102;&#28304;&#25991;&#31456;&#20316;&#32773;&#30340;&#30456;&#20851;&#21028;&#26029;&#12290;&#20026;&#20102;&#27169;&#25311;&#35835;&#32773;&#30456;&#20851;&#21028;&#26029;&#65292;&#25105;&#20204;&#27880;&#37322;&#24182;&#21457;&#24067;&#20102;&#35835;&#32773;&#38170;&#28857;&#25968;&#25454;&#38598;&#65292;&#36825;&#26159;&#35835;&#32773;&#21457;&#29616;&#26377;&#29992;&#30340;&#38170;&#28857;&#30340;&#35780;&#20272;&#38598;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#26377;&#25928;&#30340;&#38170;&#28857;&#39044;&#27979;&#36890;&#24120;&#38656;&#35201;&#32852;&#21512;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Internet links enable users to deepen their understanding of a topic by providing convenient access to related information. However, the majority of links are unanchored -- they link to a target webpage as a whole, and readers may expend considerable effort localizing the specific parts of the target webpage that enrich their understanding of the link's source context. To help readers effectively find information in linked webpages, we introduce the task of anchor prediction, where the goal is to identify the specific part of the linked target webpage that is most related to the source linking context. We release the AuthorAnchors dataset, a collection of 34K naturally-occurring anchored links, which reflect relevance judgments by the authors of the source article. To model reader relevance judgments, we annotate and release ReaderAnchors, an evaluation set of anchors that readers find useful. Our analysis shows that effective anchor prediction often requires jointly reasoning over len
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#25628;&#32034;&#24341;&#25806;&#26694;&#26550;AutoTSG&#65292;&#20854;&#29305;&#28857;&#26159;&#22522;&#20110;&#26080;&#24207;&#26415;&#35821;&#38598;&#30340;&#25991;&#26723;&#26631;&#35782;&#31526;&#21644;&#22522;&#20110;&#38598;&#21512;&#30340;&#29983;&#25104;&#31649;&#36947;&#65292;&#22823;&#22823;&#25918;&#26494;&#20102;&#23545;&#26631;&#35782;&#31526;&#31934;&#30830;&#29983;&#25104;&#30340;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2305.13859</link><description>&lt;p&gt;
&#26415;&#35821;&#38598;&#21487;&#20197;&#25104;&#20026;&#33258;&#22238;&#24402;&#25628;&#32034;&#24341;&#25806;&#30340;&#24378;&#25991;&#26723;&#26631;&#35782;&#31526;
&lt;/p&gt;
&lt;p&gt;
Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search Engines. (arXiv:2305.13859v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#25628;&#32034;&#24341;&#25806;&#26694;&#26550;AutoTSG&#65292;&#20854;&#29305;&#28857;&#26159;&#22522;&#20110;&#26080;&#24207;&#26415;&#35821;&#38598;&#30340;&#25991;&#26723;&#26631;&#35782;&#31526;&#21644;&#22522;&#20110;&#38598;&#21512;&#30340;&#29983;&#25104;&#31649;&#36947;&#65292;&#22823;&#22823;&#25918;&#26494;&#20102;&#23545;&#26631;&#35782;&#31526;&#31934;&#30830;&#29983;&#25104;&#30340;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#22238;&#24402;&#25628;&#32034;&#24341;&#25806;&#26159;&#19979;&#19968;&#20195;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#30340;&#26377;&#21069;&#36884;&#30340;&#33539;&#20363;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;Seq2Seq&#27169;&#22411;&#65292;&#20854;&#20013;&#27599;&#20010;&#26597;&#35810;&#21487;&#20197;&#30452;&#25509;&#26144;&#23556;&#21040;&#20854;&#30456;&#20851;&#25991;&#26723;&#30340;&#26631;&#35782;&#31526;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#22240;&#20855;&#26377;&#31471;&#21040;&#31471;&#21487;&#24494;&#20998;&#24615;&#31561;&#20248;&#28857;&#32780;&#21463;&#21040;&#36190;&#25196;&#12290;&#28982;&#32780;&#65292;&#33258;&#22238;&#24402;&#25628;&#32034;&#24341;&#25806;&#22312;&#26816;&#32034;&#36136;&#37327;&#19978;&#20063;&#38754;&#20020;&#30528;&#25361;&#25112;&#65292;&#22240;&#20026;&#20854;&#38656;&#35201;&#23545;&#25991;&#26723;&#26631;&#35782;&#31526;&#36827;&#34892;&#31934;&#30830;&#29983;&#25104;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22914;&#26524;&#22312;&#29983;&#25104;&#36807;&#31243;&#30340;&#20219;&#20309;&#19968;&#27493;&#20013;&#23545;&#20854;&#26631;&#35782;&#31526;&#20570;&#20986;&#20102;&#38169;&#35823;&#30340;&#39044;&#27979;&#65292;&#21017;&#30446;&#26631;&#25991;&#26723;&#23558;&#20174;&#26816;&#32034;&#32467;&#26524;&#20013;&#28431;&#22833;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21363;AutoTSG(&#33258;&#22238;&#24402;&#25628;&#32034;&#24341;&#25806;&#19982;&#26415;&#35821;&#38598;&#29983;&#25104;)&#65292;&#20854;&#29305;&#28857;&#26159;1)&#26080;&#24207;&#22522;&#20110;&#26415;&#35821;&#30340;&#25991;&#26723;&#26631;&#35782;&#31526;&#21644;2)&#22522;&#20110;&#38598;&#21512;&#30340;&#29983;&#25104;&#31649;&#36947;&#12290;&#21033;&#29992;AutoTSG&#65292;&#26415;&#35821;&#38598;&#26631;&#35782;&#31526;&#30340;&#20219;&#20309;&#25490;&#21015;&#37117;&#23558;&#23548;&#33268;&#30456;&#24212;&#25991;&#26723;&#30340;&#26816;&#32034;&#65292;&#20174;&#32780;&#22823;&#22823;&#25918;&#26494;&#20102;&#23545;&#26631;&#35782;&#31526;&#31934;&#30830;&#29983;&#25104;&#30340;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Auto-regressive search engines emerge as a promising paradigm for next-gen information retrieval systems. These methods work with Seq2Seq models, where each query can be directly mapped to the identifier of its relevant document. As such, they are praised for merits like being end-to-end differentiable. However, auto-regressive search engines also confront challenges in retrieval quality, given the requirement for the exact generation of the document identifier. That's to say, the targeted document will be missed from the retrieval result if a false prediction about its identifier is made in any step of the generation process. In this work, we propose a novel framework, namely AutoTSG (Auto-regressive Search Engine with Term-Set Generation), which is featured by 1) the unordered term-based document identifier and 2) the set-oriented generation pipeline. With AutoTSG, any permutation of the term-set identifier will lead to the retrieval of the corresponding document, thus largely relaxi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21452;&#32534;&#30721;&#22120;&#29992;&#20110;&#31264;&#23494;&#26816;&#32034;&#30340;&#26426;&#21046;&#65292;&#36890;&#36807;&#23558;&#21521;&#37327;&#34920;&#31034;&#25237;&#24433;&#21040;&#27169;&#22411;&#30340;&#35789;&#27719;&#34920;&#31354;&#38388;&#26469;&#35299;&#37322;&#23427;&#20204;&#65292;&#36827;&#19968;&#27493;&#35299;&#37322;&#20102;&#19968;&#20123;&#22833;&#36133;&#26696;&#20363;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#22312;&#25512;&#29702;&#26102;&#20016;&#23500;&#26597;&#35810;&#21644;&#27573;&#33853;&#34920;&#31034;&#19982;&#35789;&#27719;&#20449;&#24687;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2212.10380</link><description>&lt;p&gt;
&#20320;&#25152;&#35859;&#30340;&#20196;&#29260;&#26159;&#20851;&#20110;&#20160;&#20040;&#30340;&#65311;&#31264;&#23494;&#26816;&#32034;&#20316;&#20026;&#35789;&#27719;&#34920;&#19978;&#30340;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
What Are You Token About? Dense Retrieval as Distributions Over the Vocabulary. (arXiv:2212.10380v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21452;&#32534;&#30721;&#22120;&#29992;&#20110;&#31264;&#23494;&#26816;&#32034;&#30340;&#26426;&#21046;&#65292;&#36890;&#36807;&#23558;&#21521;&#37327;&#34920;&#31034;&#25237;&#24433;&#21040;&#27169;&#22411;&#30340;&#35789;&#27719;&#34920;&#31354;&#38388;&#26469;&#35299;&#37322;&#23427;&#20204;&#65292;&#36827;&#19968;&#27493;&#35299;&#37322;&#20102;&#19968;&#20123;&#22833;&#36133;&#26696;&#20363;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#22312;&#25512;&#29702;&#26102;&#20016;&#23500;&#26597;&#35810;&#21644;&#27573;&#33853;&#34920;&#31034;&#19982;&#35789;&#27719;&#20449;&#24687;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#32534;&#30721;&#22120;&#29616;&#22312;&#26159;&#31264;&#23494;&#26816;&#32034;&#30340;&#20027;&#35201;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#23427;&#20204;&#22914;&#20309;&#34920;&#31034;&#25991;&#26412;&#20197;&#21450;&#20026;&#20160;&#20040;&#20250;&#23548;&#33268;&#33391;&#22909;&#24615;&#33021;&#30693;&#20043;&#29978;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#35789;&#27719;&#34920;&#19978;&#30340;&#20998;&#24067;&#26469;&#38416;&#26126;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#23558;&#21452;&#32534;&#30721;&#22120;&#20135;&#29983;&#30340;&#21521;&#37327;&#34920;&#31034;&#25237;&#24433;&#21040;&#27169;&#22411;&#30340;&#35789;&#27719;&#34920;&#31354;&#38388;&#20013;&#26469;&#35299;&#37322;&#23427;&#20204;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20135;&#29983;&#30340;&#25237;&#24433;&#21253;&#21547;&#20016;&#23500;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#31232;&#30095;&#26816;&#32034;&#20043;&#38388;&#36827;&#34892;&#32852;&#31995;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36825;&#31181;&#35266;&#28857;&#21487;&#20197;&#35299;&#37322;&#31264;&#23494;&#26816;&#32034;&#22120;&#30340;&#19968;&#20123;&#22833;&#36133;&#26696;&#20363;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#23614;&#37096;&#23454;&#20307;&#19982;&#20196;&#29260;&#20998;&#24067;&#20542;&#21521;&#20110;&#24536;&#35760;&#36825;&#20123;&#23454;&#20307;&#30340;&#26576;&#20123;&#20196;&#29260;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#21033;&#29992;&#20102;&#36825;&#19968;&#27934;&#23519;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25512;&#29702;&#26102;&#20016;&#23500;&#26597;&#35810;&#21644;&#27573;&#33853;&#34920;&#31034;&#19982;&#35789;&#27719;&#20449;&#24687;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#30456;&#27604;&#20110;&#24120;&#35268;&#30340;&#21452;&#32534;&#30721;&#22120;&#26377;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dual encoders are now the dominant architecture for dense retrieval. Yet, we have little understanding of how they represent text, and why this leads to good performance. In this work, we shed light on this question via distributions over the vocabulary. We propose to interpret the vector representations produced by dual encoders by projecting them into the model's vocabulary space. We show that the resulting projections contain rich semantic information, and draw connection between them and sparse retrieval. We find that this view can offer an explanation for some of the failure cases of dense retrievers. For example, we observe that the inability of models to handle tail entities is correlated with a tendency of the token distributions to forget some of the tokens of those entities. We leverage this insight and propose a simple way to enrich query and passage representations with lexical information at inference time, and show that this significantly improves performance compared to 
&lt;/p&gt;</description></item><item><title>CovARC&#26159;&#19968;&#31181;&#28216;&#25103;&#21270;&#30340;&#20844;&#20849;&#21355;&#29983;&#24178;&#39044;&#24037;&#20855;&#65292;&#36890;&#36807;&#39118;&#38505;&#35780;&#20272;&#21644;&#34892;&#20026;&#24433;&#21709;&#26469;&#38477;&#20302;&#20010;&#20154;&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#24863;&#26579;&#26032;&#20896;&#30149;&#27602;&#30340;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2212.05035</link><description>&lt;p&gt;
&#20316;&#20026;&#19968;&#31181;&#28216;&#25103;&#21270;&#30340;&#20844;&#20849;&#21355;&#29983;&#24178;&#39044;&#24037;&#20855;&#30340;COVID-19&#27963;&#21160;&#39118;&#38505;&#35745;&#31639;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
COVID-19 Activity Risk Calculator as a Gamified Public Health Intervention Tool. (arXiv:2212.05035v4 [cs.CY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05035
&lt;/p&gt;
&lt;p&gt;
CovARC&#26159;&#19968;&#31181;&#28216;&#25103;&#21270;&#30340;&#20844;&#20849;&#21355;&#29983;&#24178;&#39044;&#24037;&#20855;&#65292;&#36890;&#36807;&#39118;&#38505;&#35780;&#20272;&#21644;&#34892;&#20026;&#24433;&#21709;&#26469;&#38477;&#20302;&#20010;&#20154;&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#24863;&#26579;&#26032;&#20896;&#30149;&#27602;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20005;&#37325;&#24613;&#24615;&#21628;&#21560;&#32508;&#21512;&#30151;&#20896;&#29366;&#30149;&#27602;2 (SARS-CoV-2) &#24341;&#36215;&#30340;&#26032;&#22411;&#20896;&#29366;&#30149;&#27602;&#32954;&#28814;&#30123;&#24773;&#24050;&#32463;&#24433;&#21709;&#21040;200&#22810;&#20010;&#22269;&#23478;&#65292;&#22312;&#20840;&#29699;&#36896;&#25104;&#20102;&#25968;&#30334;&#19975;&#20154;&#30340;&#20303;&#38498;&#21644;&#27515;&#20129;&#12290;&#20844;&#20849;&#21355;&#29983;&#24178;&#39044;&#65292;&#22914;&#39118;&#38505;&#35780;&#20272;&#24037;&#20855;&#65292;&#21487;&#20197;&#36890;&#36807;&#24433;&#21709;&#20010;&#20154;&#34892;&#20026;&#38477;&#20302;&#26292;&#21457;&#27969;&#34892;&#30149;&#20256;&#25773;&#39118;&#38505;&#21644;&#24863;&#26579;&#29575;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#31038;&#21306;&#20256;&#25773;&#27700;&#24179;&#21644;&#30149;&#27602;&#21464;&#24322;&#31561;&#22240;&#32032;&#30340;&#24555;&#36895;&#28436;&#21464;&#65292;&#30446;&#21069;&#20844;&#24320;&#21487;&#29992;&#30340;COVID-19&#39118;&#38505;&#35780;&#20272;&#24037;&#20855;&#30340;&#25928;&#26524;&#21442;&#24046;&#19981;&#40784;&#12290;&#27492;&#22806;&#65292;&#20851;&#20110;&#26576;&#20123;&#20010;&#20154;&#38450;&#25252;&#31574;&#30053;&#65292;&#22914;&#21475;&#32617;&#20329;&#25140;&#21644;&#25509;&#31181;&#30123;&#33495;&#30340;&#39118;&#38505;&#38477;&#20302;&#38382;&#39064;&#20063;&#23384;&#22312;&#22256;&#24785;&#12290;&#20026;&#20102;&#21019;&#24314;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#26085;&#24120;&#27963;&#21160;&#25152;&#28041;&#21450;&#30340;&#21508;&#31181;&#20010;&#20154;&#39118;&#38505;&#30340;&#31616;&#21333;&#26131;&#29992;&#24037;&#20855;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;COVID-19&#27963;&#21160;&#39118;&#38505;&#35745;&#31639;&#22120;&#65288;CovARC&#65289;&#12290;CovARC&#26159;&#19968;&#31181;&#28216;&#25103;&#21270;&#30340;&#20844;&#20849;&#21355;&#29983;&#24178;&#39044;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Coronavirus disease 2019 (COVID-19) pandemic, caused by the virus severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), has impacted over 200 countries leading to hospitalizations and deaths of millions of people. Public health interventions, such as risk estimators, can reduce the spread of pandemics and epidemics through influencing behavior, which impacts risk of exposure and infection. Current publicly available COVID-19 risk estimation tools have had variable effectiveness during the pandemic due to their dependency on rapidly evolving factors such as community transmission levels and variants. There has also been confusion surrounding certain personal protective strategies such as risk reduction by mask-wearing and vaccination. In order to create a simple easy-to-use tool for estimating different individual risks associated with carrying out daily-life activity, we developed COVID-19 Activity Risk Calculator (CovARC). CovARC is a gamified public health intervention as
&lt;/p&gt;</description></item><item><title>SciRepEval&#26159;&#31532;&#19968;&#20010;&#32508;&#21512;&#35780;&#20272;&#31185;&#23398;&#25991;&#29486;&#34920;&#31034;&#30340;&#20840;&#38754;&#22522;&#20934;&#65292;&#20854;&#20013;&#21253;&#25324;&#22235;&#31181;&#26684;&#24335;&#30340; 25 &#20010;&#20219;&#21153;&#12290;&#36890;&#36807;&#20351;&#29992;&#26684;&#24335;&#29305;&#23450;&#30340;&#25511;&#21046;&#20195;&#30721;&#21644;&#36866;&#37197;&#22120;&#65292;&#21487;&#20197;&#25913;&#36827;&#31185;&#23398;&#25991;&#29486;&#34920;&#31034;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2211.13308</link><description>&lt;p&gt;
SciRepEval&#65306;&#19968;&#20010;&#29992;&#20110;&#31185;&#23398;&#25991;&#29486;&#34920;&#31034;&#30340;&#22810;&#26684;&#24335;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
SciRepEval: A Multi-Format Benchmark for Scientific Document Representations. (arXiv:2211.13308v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13308
&lt;/p&gt;
&lt;p&gt;
SciRepEval&#26159;&#31532;&#19968;&#20010;&#32508;&#21512;&#35780;&#20272;&#31185;&#23398;&#25991;&#29486;&#34920;&#31034;&#30340;&#20840;&#38754;&#22522;&#20934;&#65292;&#20854;&#20013;&#21253;&#25324;&#22235;&#31181;&#26684;&#24335;&#30340; 25 &#20010;&#20219;&#21153;&#12290;&#36890;&#36807;&#20351;&#29992;&#26684;&#24335;&#29305;&#23450;&#30340;&#25511;&#21046;&#20195;&#30721;&#21644;&#36866;&#37197;&#22120;&#65292;&#21487;&#20197;&#25913;&#36827;&#31185;&#23398;&#25991;&#29486;&#34920;&#31034;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#30340;&#31185;&#23398;&#25991;&#29486;&#34920;&#31034;&#21487;&#20197;&#20316;&#20026;&#19979;&#28216;&#20219;&#21153;&#30340;&#26377;&#20215;&#20540;&#36755;&#20837;&#29305;&#24449;&#65292;&#26080;&#38656;&#36827;&#19968;&#27493;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#35780;&#20272;&#36825;&#20123;&#34920;&#31034;&#30340;&#29616;&#26377;&#22522;&#20934;&#26410;&#33021;&#25429;&#25417;&#21040;&#30456;&#20851;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102; SciRepEval&#65292;&#31532;&#19968;&#20010;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#31185;&#23398;&#25991;&#29486;&#34920;&#31034;&#30340;&#20840;&#38754;&#22522;&#20934;&#12290;&#23427;&#21253;&#25324;&#22235;&#31181;&#26684;&#24335;&#30340; 25 &#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#21644;&#29616;&#23454;&#24615;&#30340;&#20219;&#21153;&#65292;&#20854;&#20013; 11 &#20010;&#26159;&#26032;&#20219;&#21153;&#65306;&#20998;&#31867;&#12289;&#22238;&#24402;&#12289;&#25490;&#21517;&#21644;&#25628;&#32034;&#12290;&#25105;&#20204;&#20351;&#29992;&#35813;&#22522;&#20934;&#26469;&#30740;&#31350;&#21644;&#25913;&#36827;&#31185;&#23398;&#25991;&#26723;&#34920;&#31034;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22914;&#20309;&#22312;&#20219;&#21153;&#26684;&#24335;&#26041;&#38754;&#32570;&#20047;&#27867;&#21270;&#24615;&#33021;&#65292;&#31616;&#21333;&#30340;&#22810;&#20219;&#21153;&#35757;&#32451;&#20063;&#19981;&#33021;&#25913;&#36827;&#23427;&#20204;&#12290;&#28982;&#32780;&#65292;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23398;&#20064;&#27599;&#20010;&#25991;&#26723;&#30340;&#22810;&#20010;&#23884;&#20837;&#65292;&#27599;&#20010;&#23884;&#20837;&#19987;&#38376;&#38024;&#23545;&#19981;&#21516;&#30340;&#26684;&#24335;&#65292;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#23581;&#35797;&#20351;&#29992;&#20219;&#21153;&#26684;&#24335;&#29305;&#23450;&#30340;&#25511;&#21046;&#20195;&#30721;&#21644;&#36866;&#37197;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learned representations of scientific documents can serve as valuable input features for downstream tasks, without the need for further fine-tuning. However, existing benchmarks for evaluating these representations fail to capture the diversity of relevant tasks. In response, we introduce SciRepEval, the first comprehensive benchmark for training and evaluating scientific document representations. It includes 25 challenging and realistic tasks, 11 of which are new, across four formats: classification, regression, ranking and search. We then use the benchmark to study and improve the generalization ability of scientific document representation models. We show how state-of-the-art models struggle to generalize across task formats, and that simple multi-task training fails to improve them. However, a new approach that learns multiple embeddings per document, each tailored to a different format, can improve performance. We experiment with task-format-specific control codes and adapters in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#22870;&#21169;&#31232;&#23569;&#26102;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2109.12509</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#28145;&#24230;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Deep Exploration for Recommendation Systems. (arXiv:2109.12509v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#22870;&#21169;&#31232;&#23569;&#26102;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#24212;&#20174;&#24310;&#36831;&#21453;&#39304;&#20013;&#25506;&#32034;&#21644;&#23398;&#20064;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#24448;&#24448;&#20391;&#37325;&#20110;&#20174;&#29992;&#25143;&#23545;&#21333;&#20010;&#25512;&#33616;&#30340;&#21709;&#24212;&#20013;&#23398;&#20064;&#12290;&#36825;&#20123;&#24037;&#20316;&#21033;&#29992;&#20102;&#30417;&#30563;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20294;&#25918;&#24323;&#20102;&#23398;&#20064;&#29992;&#25143;&#20043;&#21518;&#30340;&#34892;&#20026;&#12290;&#22312;&#36807;&#21435;&#30340;&#24037;&#20316;&#20013;&#65292;&#34429;&#28982;&#33268;&#21147;&#20110;&#20174;&#38543;&#21518;&#30340;&#34892;&#20026;&#20013;&#23398;&#20064;&#65292;&#20294;&#32570;&#20047;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#24341;&#23548;&#24182;&#33719;&#21462;&#26377;&#24847;&#20041;&#30340;&#24310;&#36831;&#21453;&#39304;&#12290;&#24403;&#22870;&#21169;&#36739;&#23569;&#26102;&#65292;&#36890;&#36807;&#24341;&#23548;&#25506;&#32034;&#26377;&#24847;&#20041;&#30340;&#24310;&#36831;&#21453;&#39304;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20026;&#25512;&#33616;&#31995;&#32479;&#24320;&#21457;&#20102;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#25512;&#33616;&#31995;&#32479;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#28145;&#24230;&#25506;&#32034;&#26041;&#27861;&#22312;&#21333;&#27493;&#25506;&#32034;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#26159;&#22312;&#39640;&#20445;&#30495;&#24230;&#30340;&#24037;&#19994;&#32423;&#27169;&#25311;&#22120;&#19979;&#36827;&#34892;&#30340;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30456;&#27604;&#29616;&#26377;&#31639;&#27861;&#26377;&#24456;&#22823;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommendation systems ought to benefit by probing for and learning from delayed feedback. Research has tended to focus on learning from a user's response to a single recommendation. Such work, which leverages methods of supervised and bandit learning, forgoes learning from the user's subsequent behavior. Where past work has aimed to learn from subsequent behavior, there has been a lack of effective methods for probing to elicit informative delayed feedback. Effective exploration through probing for delayed feedback becomes particularly challenging when rewards are sparse. To address this, we develop deep exploration methods for recommendation systems. In particular, we formulate recommendation as a sequential decision problem and demonstrate benefits of deep exploration over single-step exploration. Our experiments are carried out with high-fidelity industrial-grade simulators and establish large improvements over existing algorithms.
&lt;/p&gt;</description></item></channel></rss>