<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#29992;&#20110;&#26032;&#38395;&#25512;&#33616;&#30340;&#31532;&#19968;&#20010;&#32511;&#33394;AI&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;GreenRec&#65292;&#24182;&#24341;&#20837;&#35780;&#20272;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26435;&#34913;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;OLEO&#33539;&#24335;&#22312;&#21487;&#25345;&#32493;&#24615;&#26041;&#38754;&#21462;&#24471;&#31454;&#20105;&#20934;&#30830;&#24615;&#19988;&#25552;&#20379;&#39640;&#36798;2992%&#30340;&#21487;&#25345;&#32493;&#24615;&#25913;&#36827;</title><link>https://arxiv.org/abs/2403.04736</link><description>&lt;p&gt;
&#22312;&#32511;&#33394;AI&#26102;&#20195;&#23545;&#26032;&#38395;&#25512;&#33616;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking News Recommendation in the Era of Green AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04736
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#29992;&#20110;&#26032;&#38395;&#25512;&#33616;&#30340;&#31532;&#19968;&#20010;&#32511;&#33394;AI&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;GreenRec&#65292;&#24182;&#24341;&#20837;&#35780;&#20272;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26435;&#34913;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;OLEO&#33539;&#24335;&#22312;&#21487;&#25345;&#32493;&#24615;&#26041;&#38754;&#21462;&#24471;&#31454;&#20105;&#20934;&#30830;&#24615;&#19988;&#25552;&#20379;&#39640;&#36798;2992%&#30340;&#21487;&#25345;&#32493;&#24615;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26032;&#38395;&#25512;&#33616;&#31995;&#32479;&#22312;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#22791;&#21463;&#20851;&#27880;&#65292;&#24378;&#35843;&#20102;&#38656;&#35201;&#19968;&#20010;&#26631;&#20934;&#21270;&#22522;&#20934;&#26469;&#35780;&#20272;&#21644;&#27604;&#36739;&#36825;&#20123;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#32511;&#33394;&#20154;&#24037;&#26234;&#33021;&#20513;&#23548;&#20943;&#23569;&#26426;&#22120;&#23398;&#20064;&#30340;&#33021;&#32791;&#21644;&#29615;&#22659;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#29992;&#20110;&#26032;&#38395;&#25512;&#33616;&#30340;&#32511;&#33394;AI&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#31216;&#20026;GreenRec&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20043;&#38388;&#26435;&#34913;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#28085;&#30422;30&#20010;&#22522;&#30784;&#27169;&#22411;&#21450;&#20854;&#21464;&#20307;&#65292;&#28085;&#30422;&#20102;&#20256;&#32479;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#33539;&#24335;&#20197;&#21450;&#25105;&#20204;&#25552;&#20986;&#30340;&#39640;&#25928;&#30340;&#20165;&#32534;&#30721;&#19968;&#27425;&#65288;OLEO&#65289;&#33539;&#24335;&#12290;&#36890;&#36807;&#28040;&#32791;2000&#20010;GPU&#23567;&#26102;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;OLEO&#33539;&#24335;&#22312;&#21487;&#25345;&#32493;&#24615;&#26041;&#38754;&#30456;&#36739;&#20110;&#26368;&#20808;&#36827;&#30340;&#31471;&#21040;&#31471;&#33539;&#24335;&#23454;&#29616;&#20102;&#20855;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#25552;&#20379;&#39640;&#36798;2992%&#30340;&#21487;&#25345;&#32493;&#24615;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04736v1 Announce Type: new  Abstract: Over recent years, news recommender systems have gained significant attention in both academia and industry, emphasizing the need for a standardized benchmark to evaluate and compare the performance of these systems. Concurrently, Green AI advocates for reducing the energy consumption and environmental impact of machine learning. To address these concerns, we introduce the first Green AI benchmarking framework for news recommendation, known as GreenRec, and propose a metric for assessing the tradeoff between recommendation accuracy and efficiency. Our benchmark encompasses 30 base models and their variants, covering traditional end-to-end training paradigms as well as our proposed efficient only-encode-once (OLEO) paradigm. Through experiments consuming 2000 GPU hours, we observe that the OLEO paradigm achieves competitive accuracy compared to state-of-the-art end-to-end paradigms and delivers up to a 2992\% improvement in sustainability
&lt;/p&gt;</description></item><item><title>Ducho 2.0&#25512;&#20986;&#65292;&#25552;&#20379;&#26356;&#20010;&#24615;&#21270;&#30340;&#29992;&#25143;&#20307;&#39564;&#21644;&#25903;&#25345;&#22810;&#27169;&#24577;&#22823;&#22411;&#27169;&#22411;&#25552;&#21462;&#21644;&#22788;&#29702;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#22810;&#27169;&#24335;&#25512;&#33616;&#65292;&#21516;&#26102;&#20248;&#21270;&#25968;&#25454;&#21152;&#36733;&#21644;&#23384;&#20648;&#12290;</title><link>https://arxiv.org/abs/2403.04503</link><description>&lt;p&gt;
Ducho 2.0&#65306;&#38754;&#21521;&#22810;&#27169;&#24335;&#25512;&#33616;&#30340;&#26356;&#20026;&#26102;&#23578;&#30340;&#29305;&#24449;&#25552;&#21462;&#21644;&#22788;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Ducho 2.0: Towards a More Up-to-Date Feature Extraction and Processing Framework for Multimodal Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04503
&lt;/p&gt;
&lt;p&gt;
Ducho 2.0&#25512;&#20986;&#65292;&#25552;&#20379;&#26356;&#20010;&#24615;&#21270;&#30340;&#29992;&#25143;&#20307;&#39564;&#21644;&#25903;&#25345;&#22810;&#27169;&#24577;&#22823;&#22411;&#27169;&#22411;&#25552;&#21462;&#21644;&#22788;&#29702;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#22810;&#27169;&#24335;&#25512;&#33616;&#65292;&#21516;&#26102;&#20248;&#21270;&#25968;&#25454;&#21152;&#36733;&#21644;&#23384;&#20648;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Ducho 2.0&#65292;&#25105;&#20204;&#26694;&#26550;&#30340;&#26368;&#26032;&#31283;&#23450;&#29256;&#26412;&#12290;&#19982;Ducho&#19981;&#21516;&#65292;Ducho 2.0&#25552;&#20379;&#20102;&#26356;&#20010;&#24615;&#21270;&#30340;&#29992;&#25143;&#20307;&#39564;&#65292;&#21487;&#20197;&#23450;&#20041;&#21644;&#23548;&#20837;&#22312;&#29305;&#23450;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24494;&#35843;&#30340;&#33258;&#23450;&#20041;&#25552;&#21462;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#26032;&#29256;&#26412;&#33021;&#22815;&#36890;&#36807;&#22810;&#27169;&#24577;&#35774;&#35745;&#30340;&#22823;&#22411;&#27169;&#22411;&#25552;&#21462;&#21644;&#22788;&#29702;&#29305;&#24449;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#26377;&#36825;&#20123;&#26032;&#21151;&#33021;&#37117;&#21463;&#21040;&#20102;&#23545;&#26412;&#22320;&#23384;&#20648;&#22120;&#36827;&#34892;&#20102;&#20248;&#21270;&#30340;&#25968;&#25454;&#21152;&#36733;&#21644;&#23384;&#20648;&#30340;&#25903;&#25345;&#12290;&#20026;&#20102;&#23637;&#31034;Ducho 2.0&#30340;&#21151;&#33021;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#22810;&#27169;&#24335;&#25512;&#33616;&#27969;&#27700;&#32447;&#65292;&#20174;&#25552;&#21462;/&#22788;&#29702;&#21040;&#26368;&#32456;&#25512;&#33616;&#12290;&#25105;&#20204;&#30340;&#24819;&#27861;&#26159;&#20026;&#20174;&#19994;&#32773;&#21644;&#32463;&#39564;&#20016;&#23500;&#30340;&#23398;&#32773;&#25552;&#20379;&#19968;&#20010;&#21363;&#29992;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;&#20219;&#20309;&#22810;&#27169;&#24335;&#25512;&#33616;&#26694;&#26550;&#20043;&#19978;&#36816;&#34892;&#24191;&#27867;&#30340;&#22522;&#20934;&#20998;&#26512;&#12290;&#25152;&#26377;&#26448;&#26009;&#37117;&#21487;&#20197;&#22312;&#20197;&#19979;&#32593;&#22336;&#33719;&#24471;&#65306;\url{https://github.com/sisinflab/Ducho}&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04503v1 Announce Type: new  Abstract: In this work, we introduce Ducho 2.0, the latest stable version of our framework. Differently from Ducho, Ducho 2.0 offers a more personalized user experience with the definition and import of custom extraction models fine-tuned on specific tasks and datasets. Moreover, the new version is capable of extracting and processing features through multimodal-by-design large models. Notably, all these new features are supported by optimized data loading and storing to the local memory. To showcase the capabilities of Ducho 2.0, we demonstrate a complete multimodal recommendation pipeline, from the extraction/processing to the final recommendation. The idea is to provide practitioners and experienced scholars with a ready-to-use tool that, put on top of any multimodal recommendation framework, may permit them to run extensive benchmarking analyses. All materials are accessible at: \url{https://github.com/sisinflab/Ducho}.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#38754;&#20020;&#30340;&#19981;&#24179;&#34913;&#12289;&#22122;&#22768;&#12289;&#38544;&#31169;&#21644;OOD&#25361;&#25112;&#65292;&#24182;&#33268;&#21147;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12289;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04468</link><description>&lt;p&gt;
&#20851;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#35843;&#26597;&#65306;&#19981;&#24179;&#34913;&#12289;&#22122;&#22768;&#12289;&#38544;&#31169;&#21644;OOD&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A Survey of Graph Neural Networks in Real world: Imbalance, Noise, Privacy and OOD Challenges
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#38754;&#20020;&#30340;&#19981;&#24179;&#34913;&#12289;&#22122;&#22768;&#12289;&#38544;&#31169;&#21644;OOD&#25361;&#25112;&#65292;&#24182;&#33268;&#21147;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12289;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04468v1 &#21457;&#24067;&#31867;&#22411;: &#36328;&#22495; &#25688;&#35201;: &#22270;&#32467;&#26500;&#21270;&#25968;&#25454;&#34920;&#29616;&#20986;&#26222;&#36866;&#24615;&#21644;&#24191;&#27867;&#36866;&#29992;&#24615;&#65292;&#28085;&#30422;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#12289;&#29983;&#29289;&#21270;&#23398;&#12289;&#37329;&#34701;&#27450;&#35784;&#26816;&#27979;&#21644;&#32593;&#32476;&#23433;&#20840;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;&#22312;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#21462;&#24471;&#26174;&#33879;&#25104;&#21151;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#27169;&#22411;&#30340;&#35757;&#32451;&#29615;&#22659;&#24448;&#24448;&#36828;&#38750;&#29702;&#24819;&#65292;&#30001;&#20110;&#21508;&#31181;&#19981;&#21033;&#22240;&#32032;&#65292;&#21253;&#25324;&#25968;&#25454;&#20998;&#24067;&#19981;&#24179;&#34913;&#12289;&#38169;&#35823;&#25968;&#25454;&#20013;&#23384;&#22312;&#22122;&#22768;&#12289;&#25935;&#24863;&#20449;&#24687;&#30340;&#38544;&#31169;&#20445;&#25252;&#20197;&#21450;&#23545;&#20110;OOD&#22330;&#26223;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#23548;&#33268;GNN&#27169;&#22411;&#30340;&#24615;&#33021;&#22823;&#24133;&#19979;&#38477;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20154;&#20204;&#33268;&#21147;&#20110;&#25913;&#21892;GNN&#27169;&#22411;&#22312;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013;&#30340;&#24615;&#33021;&#65292;&#25552;&#39640;&#20854;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#26412;&#25991;&#20840;&#38754;&#35843;&#26597;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04468v1 Announce Type: cross  Abstract: Graph-structured data exhibits universality and widespread applicability across diverse domains, such as social network analysis, biochemistry, financial fraud detection, and network security. Significant strides have been made in leveraging Graph Neural Networks (GNNs) to achieve remarkable success in these areas. However, in real-world scenarios, the training environment for models is often far from ideal, leading to substantial performance degradation of GNN models due to various unfavorable factors, including imbalance in data distribution, the presence of noise in erroneous data, privacy protection of sensitive information, and generalization capability for out-of-distribution (OOD) scenarios. To tackle these issues, substantial efforts have been devoted to improving the performance of GNN models in practical real-world scenarios, as well as enhancing their reliability and robustness. In this paper, we present a comprehensive surv
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#27169;&#22411;&#30340;&#20852;&#36215;&#25512;&#21160;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#37325;&#22823;&#36827;&#27493;&#65292;&#20026;&#22686;&#24378;&#29992;&#25143;&#20010;&#24615;&#21270;&#25512;&#33616;&#25552;&#20379;&#20102;&#29420;&#29305;&#26426;&#20250;&#65292;&#35813;&#30740;&#35752;&#20250;&#20027;&#35201;&#20851;&#27880;&#29983;&#25104;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#21019;&#26032;&#24212;&#29992;&#65292;&#28085;&#30422;&#31639;&#27861;&#25913;&#36827;&#12289;&#20010;&#24615;&#21270;&#20869;&#23481;&#29983;&#25104;&#12289;&#29992;&#25143;&#20132;&#20114;&#28436;&#21464;&#12289;&#21487;&#20449;&#24230;&#26816;&#26597;&#21152;&#24378;&#21644;&#35780;&#20272;&#26041;&#27861;&#23436;&#21892;&#31561;&#20116;&#20010;&#20851;&#38190;&#35270;&#35282;&#12290;</title><link>https://arxiv.org/abs/2403.04399</link><description>&lt;p&gt;
&#12298;&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#31532;&#20108;&#27425;&#30740;&#35752;&#20250;&#12299;
&lt;/p&gt;
&lt;p&gt;
The 2nd Workshop on Recommendation with Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04399
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#30340;&#20852;&#36215;&#25512;&#21160;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#37325;&#22823;&#36827;&#27493;&#65292;&#20026;&#22686;&#24378;&#29992;&#25143;&#20010;&#24615;&#21270;&#25512;&#33616;&#25552;&#20379;&#20102;&#29420;&#29305;&#26426;&#20250;&#65292;&#35813;&#30740;&#35752;&#20250;&#20027;&#35201;&#20851;&#27880;&#29983;&#25104;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#21019;&#26032;&#24212;&#29992;&#65292;&#28085;&#30422;&#31639;&#27861;&#25913;&#36827;&#12289;&#20010;&#24615;&#21270;&#20869;&#23481;&#29983;&#25104;&#12289;&#29992;&#25143;&#20132;&#20114;&#28436;&#21464;&#12289;&#21487;&#20449;&#24230;&#26816;&#26597;&#21152;&#24378;&#21644;&#35780;&#20272;&#26041;&#27861;&#23436;&#21892;&#31561;&#20116;&#20010;&#20851;&#38190;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#30340;&#20852;&#36215;&#25512;&#21160;&#20102;&#25512;&#33616;&#31995;&#32479;&#30340;&#37325;&#22823;&#36827;&#27493;&#65292;&#20026;&#22686;&#24378;&#29992;&#25143;&#20010;&#24615;&#21270;&#25512;&#33616;&#25552;&#20379;&#20102;&#29420;&#29305;&#26426;&#20250;&#12290;&#35813;&#30740;&#35752;&#20250;&#26088;&#22312;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#19968;&#20010;&#24179;&#21488;&#65292;&#25506;&#35752;&#21644;&#20132;&#27969;&#19982;&#23558;&#29983;&#25104;&#27169;&#22411;&#25972;&#21512;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#30456;&#20851;&#30340;&#21019;&#26032;&#27010;&#24565;&#12290;&#20027;&#35201;&#20851;&#27880;&#20116;&#20010;&#20851;&#38190;&#35270;&#35282;&#65306;&#65288;i&#65289;&#25913;&#36827;&#25512;&#33616;&#31639;&#27861;&#65292;&#65288;ii&#65289;&#29983;&#25104;&#20010;&#24615;&#21270;&#20869;&#23481;&#65292;&#65288;iii&#65289;&#28436;&#21464;&#29992;&#25143;-&#31995;&#32479;&#20132;&#20114;&#33539;&#24335;&#65292;&#65288;iv&#65289;&#22686;&#24378;&#21487;&#20449;&#24230;&#26816;&#26597;&#65292;&#21644;&#65288;v&#65289;&#23436;&#21892;&#29983;&#25104;&#25512;&#33616;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;&#38543;&#30528;&#29983;&#25104;&#27169;&#22411;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#36825;&#20123;&#39046;&#22495;&#20986;&#29616;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#65292;&#24378;&#35843;&#20102;&#27492;&#30740;&#35752;&#20250;&#30340;&#21450;&#26102;&#24615;&#21644;&#37325;&#35201;&#24615;&#12290;&#30456;&#20851;&#30740;&#31350;&#23558;&#21521;&#25512;&#33616;&#31995;&#32479;&#24341;&#20837;&#21019;&#26032;&#25216;&#26415;&#65292;&#24182;&#22312;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#20026;&#26032;&#25361;&#25112;&#20570;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04399v1 Announce Type: new  Abstract: The rise of generative models has driven significant advancements in recommender systems, leaving unique opportunities for enhancing users' personalized recommendations. This workshop serves as a platform for researchers to explore and exchange innovative concepts related to the integration of generative models into recommender systems. It primarily focuses on five key perspectives: (i) improving recommender algorithms, (ii) generating personalized content, (iii) evolving the user-system interaction paradigm, (iv) enhancing trustworthiness checks, and (v) refining evaluation methodologies for generative recommendations. With generative models advancing rapidly, an increasing body of research is emerging in these domains, underscoring the timeliness and critical importance of this workshop. The related research will introduce innovative technologies to recommender systems and contribute to fresh challenges in both academia and industry. I
&lt;/p&gt;</description></item><item><title>ALTO&#26159;&#19968;&#20010;&#32593;&#32476;&#32534;&#25490;&#22120;&#65292;&#38024;&#23545;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#26426;&#20250;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.04311</link><description>&lt;p&gt;
ALTO&#65306;&#19968;&#31181;&#29992;&#20110;&#22797;&#21512;AI&#31995;&#32479;&#30340;&#39640;&#25928;&#32593;&#32476;&#32534;&#25490;&#22120;
&lt;/p&gt;
&lt;p&gt;
ALTO: An Efficient Network Orchestrator for Compound AI Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04311
&lt;/p&gt;
&lt;p&gt;
ALTO&#26159;&#19968;&#20010;&#32593;&#32476;&#32534;&#25490;&#22120;&#65292;&#38024;&#23545;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#26426;&#20250;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ALTO&#65292;&#19968;&#31181;&#29992;&#20110;&#26377;&#25928;&#20026;&#35832;&#22914;&#35821;&#35328;&#27169;&#22411;&#31649;&#36947;&#20043;&#31867;&#30340;&#22797;&#21512;AI&#31995;&#32479;&#25552;&#20379;&#26381;&#21153;&#30340;&#32593;&#32476;&#32534;&#25490;&#22120;&#12290;ALTO&#36890;&#36807;&#21033;&#29992;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#29305;&#26377;&#30340;&#20248;&#21270;&#26426;&#20250;&#65306;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#12290;&#30001;&#20110;&#35821;&#35328;&#27169;&#22411;&#36880;&#20010;&#29983;&#25104;token&#30340;&#36755;&#20986;&#65292;ALTO&#22312;&#21487;&#33021;&#26102;&#26292;&#38706;&#20102;&#22312;&#38454;&#27573;&#20043;&#38388;&#27969;&#24335;&#20256;&#36755;&#20013;&#38388;&#36755;&#20986;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#22312;&#36328;&#20998;&#24067;&#24335;&#31649;&#36947;&#38454;&#27573;&#23454;&#20363;&#20043;&#38388;&#27969;&#24335;&#20256;&#36755;&#20013;&#38388;&#25968;&#25454;&#26102;&#20986;&#29616;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#32858;&#21512;&#24863;&#30693;&#36335;&#30001;&#25509;&#21475;&#21644;&#20998;&#24067;&#24335;&#25552;&#31034;&#24863;&#30693;&#35843;&#24230;&#20197;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#22797;&#26434;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#39564;&#35777;&#31649;&#36947;&#19978;&#23637;&#31034;&#20102;ALTO&#37096;&#20998;&#36755;&#20986;&#27969;&#24335;&#20256;&#36755;&#30340;&#24433;&#21709;&#65292;&#23558;&#21534;&#21520;&#37327;&#25552;&#39640;&#20102;&#26368;&#22810;3&#20493;&#65292;&#21516;&#26102;&#23558;&#22266;&#23450;&#24310;&#36831;&#30446;&#26631;&#35774;&#32622;&#20026;4&#31186;/&#35831;&#27714;&#65292;&#36824;&#20943;&#23569;&#20102;&#23614;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04311v1 Announce Type: new  Abstract: We present ALTO, a network orchestrator for efficiently serving compound AI systems such as pipelines of language models. ALTO achieves high throughput and low latency by taking advantage of an optimization opportunity specific to generative language models: streaming intermediate outputs. As language models produce outputs token by token, ALTO exposes opportunities to stream intermediate outputs between stages when possible. We highlight two new challenges of correctness and load balancing which emerge when streaming intermediate data across distributed pipeline stage instances. We also motivate the need for an aggregation-aware routing interface and distributed prompt-aware scheduling to address these challenges. We demonstrate the impact of ALTO's partial output streaming on a complex chatbot verification pipeline, increasing throughput by up to 3x for a fixed latency target of 4 seconds / request while also reducing tail latency by 1
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;DGR&#26694;&#26550;&#65292;&#36890;&#36807;&#32771;&#34385;&#20840;&#23616;&#21644;&#23616;&#37096;&#35270;&#35282;&#26377;&#25928;&#35299;&#20915;&#20102;&#24120;&#35268;GCN-based&#25512;&#33616;&#27169;&#22411;&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.04287</link><description>&lt;p&gt;
DGR&#65306;&#19968;&#31181;&#36890;&#36807;&#20840;&#23616;&#21644;&#23616;&#37096;&#35270;&#35282;&#36827;&#34892;&#25512;&#33616;&#30340;&#36890;&#29992;&#22270;&#21435;&#24179;&#28369;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
DGR: A General Graph Desmoothing Framework for Recommendation via Global and Local Perspectives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04287
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;DGR&#26694;&#26550;&#65292;&#36890;&#36807;&#32771;&#34385;&#20840;&#23616;&#21644;&#23616;&#37096;&#35270;&#35282;&#26377;&#25928;&#35299;&#20915;&#20102;&#24120;&#35268;GCN-based&#25512;&#33616;&#27169;&#22411;&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Graph Convolutional Networks (GCNs)&#24050;&#32463;&#25104;&#20026;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#22270;&#30340;&#33410;&#28857;&#20449;&#24687;&#21644;&#25299;&#25169;&#32467;&#26500;&#26469;&#23398;&#20064;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#23884;&#20837;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#32463;&#24120;&#38754;&#20020;&#30528;&#36807;&#24230;&#24179;&#28369;&#30340;&#38382;&#39064;&#65292;&#23548;&#33268;&#27169;&#31946;&#30340;&#29992;&#25143;&#21644;&#29289;&#21697;&#23884;&#20837;&#20197;&#21450;&#38477;&#20302;&#30340;&#20010;&#24615;&#21270;&#12290;&#20256;&#32479;&#30340;&#21435;&#24179;&#28369;&#26041;&#27861;&#22312;&#22522;&#20110;GCN&#30340;&#31995;&#32479;&#20013;&#26159;&#29305;&#23450;&#20110;&#27169;&#22411;&#30340;&#65292;&#32570;&#20047;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;DGR&#65306;&#21435;&#24179;&#28369;&#26694;&#26550;&#29992;&#20110;GCN-based&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#32771;&#34385;&#20840;&#23616;&#21644;&#23616;&#37096;&#35270;&#35282;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#24120;&#35268;GCN-based&#25512;&#33616;&#27169;&#22411;&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04287v1 Announce Type: new  Abstract: Graph Convolutional Networks (GCNs) have become pivotal in recommendation systems for learning user and item embeddings by leveraging the user-item interaction graph's node information and topology. However, these models often face the famous over-smoothing issue, leading to indistinct user and item embeddings and reduced personalization. Traditional desmoothing methods in GCN-based systems are model-specific, lacking a universal solution. This paper introduces a novel, model-agnostic approach named \textbf{D}esmoothing Framework for \textbf{G}CN-based \textbf{R}ecommendation Systems (\textbf{DGR}). It effectively addresses over-smoothing on general GCN-based recommendation models by considering both global and local perspectives. Specifically, we first introduce vector perturbations during each message passing layer to penalize the tendency of node embeddings approximating overly to be similar with the guidance of the global topological
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;SSDRec&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#21435;&#22122;&#20043;&#21069;&#25554;&#20837;&#39033;&#26469;&#22686;&#24378;&#24207;&#21015;&#65292;&#20197;&#20943;&#23569;&#22122;&#22768;&#23545;&#39034;&#24207;&#25512;&#33616;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.04278</link><description>&lt;p&gt;
SSDRec&#65306;&#33258;&#25105;&#22686;&#24378;&#24207;&#21015;&#21435;&#22122;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
SSDRec: Self-Augmented Sequence Denoising for Sequential Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04278
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;SSDRec&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#21435;&#22122;&#20043;&#21069;&#25554;&#20837;&#39033;&#26469;&#22686;&#24378;&#24207;&#21015;&#65292;&#20197;&#20943;&#23569;&#22122;&#22768;&#23545;&#39034;&#24207;&#25512;&#33616;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv&#65306;2403.04278v1 &#21457;&#34920;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#20256;&#32479;&#30340;&#39034;&#24207;&#25512;&#33616;&#26041;&#27861;&#20551;&#35774;&#29992;&#25143;&#30340;&#24207;&#21015;&#25968;&#25454;&#36275;&#22815;&#24178;&#20928;&#65292;&#21487;&#20197;&#23398;&#20064;&#20934;&#30830;&#30340;&#24207;&#21015;&#34920;&#31034;&#20197;&#21453;&#26144;&#29992;&#25143;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#29992;&#25143;&#30340;&#24207;&#21015;&#19981;&#21487;&#36991;&#20813;&#22320;&#21253;&#21547;&#22122;&#22768;&#65288;&#20363;&#22914;&#65292;&#20598;&#28982;&#30340;&#20132;&#20114;&#65289;&#65292;&#23548;&#33268;&#23545;&#29992;&#25143;&#20559;&#22909;&#30340;&#19981;&#27491;&#30830;&#21453;&#26144;&#12290;&#22240;&#27492;&#65292;&#19968;&#20123;&#20808;&#39537;&#24615;&#30740;&#31350;&#25506;&#35752;&#20102;&#24314;&#27169;&#24207;&#21015;&#24615;&#21644;&#24207;&#21015;&#20043;&#38388;&#20851;&#32852;&#24615;&#20197;&#38544;&#24335;&#25110;&#26174;&#24335;&#22320;&#20943;&#23569;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#20165;&#20381;&#36182;&#20110;&#24207;&#21015;&#20869;&#20449;&#24687;&#65288;&#21363;&#65292;&#24207;&#21015;&#20869;&#30340;&#39034;&#24207;&#24615;&#21644;&#20851;&#32852;&#24615;&#65289;&#26159;&#19981;&#36275;&#30340;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#24230;&#21435;&#22122;&#21644;&#27424;&#21435;&#22122;&#38382;&#39064;&#65288;OUPs&#65289;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#30701;&#24207;&#21015;&#12290;&#20026;&#20102;&#25552;&#39640;&#21487;&#38752;&#24615;&#65292;&#25105;&#20204;&#24314;&#35758;&#22312;&#21435;&#22122;&#20043;&#21069;&#36890;&#36807;&#25554;&#20837;&#39033;&#26469;&#22686;&#24378;&#24207;&#21015;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#21644;&#35745;&#31639;&#25104;&#26412;&#65292;&#36873;&#25321;&#25972;&#20010;&#39033;&#30446;&#19990;&#30028;&#20013;&#30340;&#36866;&#24403;&#39033;&#30446;&#25554;&#20837;&#36866;&#24403;&#20301;&#32622;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04278v1 Announce Type: new  Abstract: Traditional sequential recommendation methods assume that users' sequence data is clean enough to learn accurate sequence representations to reflect user preferences. In practice, users' sequences inevitably contain noise (e.g., accidental interactions), leading to incorrect reflections of user preferences. Consequently, some pioneer studies have explored modeling sequentiality and correlations in sequences to implicitly or explicitly reduce noise's influence. However, relying on only available intra-sequence information (i.e., sequentiality and correlations in a sequence) is insufficient and may result in over-denoising and under-denoising problems (OUPs), especially for short sequences. To improve reliability, we propose to augment sequences by inserting items before denoising. However, due to the data sparsity issue and computational costs, it is challenging to select proper items from the entire item universe to insert into proper po
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#36880;&#27493;&#30693;&#35782;&#25552;&#21462;&#26694;&#26550;&#65288;SLIM&#65289;&#65292;&#20026;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39640;&#36164;&#28304;&#38656;&#27714;&#30340;&#38590;&#39064;&#65292;&#20351;&#20854;&#33021;&#20197;&#36164;&#28304;&#39640;&#25928;&#30340;&#26041;&#24335;&#20139;&#21463;LLMs&#30340;&#20986;&#33394;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.04260</link><description>&lt;p&gt;
&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#25104;&#20026;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#33391;&#22909;&#25512;&#29702;&#32773;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Small Language Models be Good Reasoners for Sequential Recommendation?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04260
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#36880;&#27493;&#30693;&#35782;&#25552;&#21462;&#26694;&#26550;&#65288;SLIM&#65289;&#65292;&#20026;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39640;&#36164;&#28304;&#38656;&#27714;&#30340;&#38590;&#39064;&#65292;&#20351;&#20854;&#33021;&#20197;&#36164;&#28304;&#39640;&#25928;&#30340;&#26041;&#24335;&#20139;&#21463;LLMs&#30340;&#20986;&#33394;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30001;&#20110;&#20854;&#20986;&#33394;&#30340;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#20026;&#39034;&#24207;&#25512;&#33616;&#24320;&#25299;&#20102;&#26032;&#30340;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#35201;&#25104;&#21151;&#23454;&#29616;&#30001;LLMs&#36171;&#33021;&#30340;&#39034;&#24207;&#25512;&#33616;&#36824;&#26377;&#35768;&#22810;&#25361;&#25112;&#38656;&#35201;&#35299;&#20915;&#12290;&#39318;&#20808;&#65292;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#36890;&#24120;&#22797;&#26434;&#65292;&#20165;&#20165;&#20381;&#38752;LLMs&#30340;&#19968;&#27493;&#25512;&#29702;&#21487;&#33021;&#20250;&#23548;&#33268;&#38169;&#35823;&#25110;&#19982;&#20219;&#21153;&#26080;&#20851;&#30340;&#21709;&#24212;&#12290;&#20854;&#27425;&#65292;LLMs&#65288;&#20363;&#22914;ChatGPT-175B&#65289;&#26497;&#39640;&#30340;&#36164;&#28304;&#38656;&#27714;&#26159;&#38590;&#20197;&#25215;&#21463;&#19988;&#22312;&#23454;&#38469;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#20013;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#36880;&#27493;&#30693;&#35782;&#25552;&#21462;&#26694;&#26550;&#29992;&#20110;&#25512;&#33616;&#65288;SLIM&#65289;&#65292;&#20026;&#39034;&#24207;&#25512;&#33616;&#22120;&#20197;&#8220;&#30246;&#8221;&#65288;&#21363;&#36164;&#28304;&#39640;&#25928;&#65289;&#30340;&#26041;&#24335;&#20139;&#21463;LLMs&#20986;&#33394;&#30340;&#25512;&#29702;&#33021;&#21147;&#38138;&#24179;&#20102;&#19968;&#26465;&#26377;&#21069;&#36884;&#30340;&#36947;&#36335;&#12290;&#25105;&#20204;&#24341;&#20837;&#22522;&#20110;&#29992;&#25143;&#34892;&#20026;&#24207;&#21015;&#30340;CoT&#25552;&#31034;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04260v1 Announce Type: cross  Abstract: Large language models (LLMs) open up new horizons for sequential recommendations, owing to their remarkable language comprehension and generation capabilities. However, there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs. Firstly, user behavior patterns are often complex, and relying solely on one-step reasoning from LLMs may lead to incorrect or task-irrelevant responses. Secondly, the prohibitively resource requirements of LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real sequential recommender systems. In this paper, we propose a novel Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a "slim" (i.e., resource-efficient) manner. We introduce CoT prompting based on user behavior sequences for the larg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;&#31283;&#20581;&#24615;&#30340;&#39318;&#20010;&#31995;&#32479;&#24615;&#27979;&#37327;&#30740;&#31350;&#65292;&#23450;&#20041;&#20102;&#31283;&#20581;&#24615;&#20026;&#35821;&#20041;&#30456;&#21516;&#26597;&#35810;&#25490;&#21517;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#23450;&#37327;&#20998;&#26512;&#31283;&#20581;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04257</link><description>&lt;p&gt;
&#38754;&#21521;&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;&#30340;&#31283;&#20581;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Towards Robustness Analysis of E-Commerce Ranking System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04257
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;&#31283;&#20581;&#24615;&#30340;&#39318;&#20010;&#31995;&#32479;&#24615;&#27979;&#37327;&#30740;&#31350;&#65292;&#23450;&#20041;&#20102;&#31283;&#20581;&#24615;&#20026;&#35821;&#20041;&#30456;&#21516;&#26597;&#35810;&#25490;&#21517;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#23450;&#37327;&#20998;&#26512;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04257v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#30340; &#25688;&#35201;&#65306;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#26159;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#26368;&#36817;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#36827;&#23637;&#20351;&#24471;ML&#31639;&#27861;&#33021;&#22815;&#25972;&#21512;&#21040;IR&#20013;&#65292;&#29305;&#21035;&#26159;&#22312;&#25490;&#21517;&#31995;&#32479;&#20013;&#12290;&#34429;&#28982;&#26377;&#22823;&#37327;&#20851;&#20110;&#22522;&#20110;ML&#30340;&#25490;&#21517;&#31995;&#32479;&#30340;&#31283;&#20581;&#24615;&#30340;&#30740;&#31350;&#65292;&#20294;&#36825;&#20123;&#30740;&#31350;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#35270;&#20102;&#21830;&#19994;&#30005;&#23376;&#21830;&#21153;&#31995;&#32479;&#65292;&#24182;&#26410;&#24314;&#31435;&#23454;&#38469;&#19990;&#30028;&#21644;&#25805;&#20316;&#26597;&#35810;&#30456;&#20851;&#24615;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#20110;&#30005;&#23376;&#21830;&#21153;&#25490;&#21517;&#31995;&#32479;&#31283;&#20581;&#24615;&#30340;&#31532;&#19968;&#20010;&#31995;&#32479;&#24615;&#27979;&#37327;&#30740;&#31350;&#12290;&#25105;&#20204;&#23558;&#31283;&#20581;&#24615;&#23450;&#20041;&#20026;&#35821;&#20041;&#30456;&#21516;&#26597;&#35810;&#30340;&#25490;&#21517;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#12290;&#20026;&#20102;&#23450;&#37327;&#20998;&#26512;&#31283;&#20581;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#32771;&#34385;&#20102;&#25490;&#21517;&#20301;&#32622;&#21644;&#29616;&#26377;&#24230;&#37327;&#20013;&#32570;&#22833;&#30340;&#29305;&#23450;&#39033;&#30446;&#20449;&#24687;&#12290;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#30005;&#23376;&#21830;&#21153;&#38646;&#21806;&#21830;&#30340;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#27979;&#37327;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#19968;&#20010;&#34913;&#37327;&#21644;&#25913;&#36827;&#31283;&#20581;&#24615;&#30340;&#24320;&#25918;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04257v1 Announce Type: new  Abstract: Information retrieval (IR) is a pivotal component in various applications. Recent advances in machine learning (ML) have enabled the integration of ML algorithms into IR, particularly in ranking systems. While there is a plethora of research on the robustness of ML-based ranking systems, these studies largely neglect commercial e-commerce systems and fail to establish a connection between real-world and manipulated query relevance. In this paper, we present the first systematic measurement study on the robustness of e-commerce ranking systems. We define robustness as the consistency of ranking outcomes for semantically identical queries. To quantitatively analyze robustness, we propose a novel metric that considers both ranking position and item-specific information that are absent in existing metrics. Our large-scale measurement study with real-world data from e-commerce retailers reveals an open opportunity to measure and improve robus
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GPT-FedRec&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#21033;&#29992;ChatGPT&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#26426;&#21046;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;FR&#31995;&#32479;&#22312;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#24322;&#26500;&#24615;&#26041;&#38754;&#30340;&#24615;&#33021;&#19979;&#38477;&#38382;&#39064;&#65292;&#24357;&#34917;&#20102;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#22120;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#25512;&#29702;&#25928;&#29575;&#20302;&#21644;&#28508;&#22312;&#24187;&#35273;&#31561;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#30340;&#30446;&#26631;</title><link>https://arxiv.org/abs/2403.04256</link><description>&lt;p&gt;
&#22522;&#20110;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#32852;&#37030;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Federated Recommendation via Hybrid Retrieval Augmented Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04256
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GPT-FedRec&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#21033;&#29992;ChatGPT&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#26426;&#21046;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;FR&#31995;&#32479;&#22312;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#24322;&#26500;&#24615;&#26041;&#38754;&#30340;&#24615;&#33021;&#19979;&#38477;&#38382;&#39064;&#65292;&#24357;&#34917;&#20102;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#22120;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#25512;&#29702;&#25928;&#29575;&#20302;&#21644;&#28508;&#22312;&#24187;&#35273;&#31561;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#30340;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#25512;&#33616;&#65288;FR&#65289;&#26159;&#19968;&#31181;&#26032;&#20852;&#33539;&#24335;&#65292;&#33021;&#22815;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;FR&#31995;&#32479;&#36890;&#24120;&#20351;&#29992;&#31163;&#25955;&#30340;&#36523;&#20221;&#65288;ID&#65289;&#34920;&#31034;&#29992;&#25143;/&#29289;&#21697;&#65292;&#22312;FR&#20013;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#24322;&#26500;&#24615;&#32780;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#25512;&#33616;&#22120;&#24050;&#32463;&#22312;&#21508;&#31181;&#25512;&#33616;&#22330;&#26223;&#20013;&#34987;&#35777;&#26126;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#22120;&#38754;&#20020;&#35832;&#22914;&#25512;&#29702;&#25928;&#29575;&#20302;&#21644;&#28508;&#22312;&#24187;&#35273;&#31561;&#25361;&#25112;&#65292;&#20174;&#32780;&#24433;&#21709;&#23427;&#20204;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#34920;&#29616;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GPT-FedRec&#30340;&#32852;&#37030;&#25512;&#33616;&#26694;&#26550;&#65292;&#21033;&#29992;ChatGPT&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#26426;&#21046;&#12290;GPT-FedRec&#26159;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#31532;&#19968;&#38454;&#27573;&#26159;&#19968;&#20010;&#28151;&#21512;&#26816;&#32034;&#36807;&#31243;&#65292;&#25366;&#25496;&#22522;&#20110;ID&#30340;&#29992;&#25143;&#27169;&#24335;&#21644;&#22522;&#20110;&#25991;&#26412;&#30340;&#21830;&#21697;&#29305;&#24449;&#12290;&#25509;&#19979;&#26469;&#65292;&#25152;&#26816;&#32034;&#21040;&#30340;&#32467;&#26524;&#34987;&#36716;&#25442;&#20026;&#25991;&#26412;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04256v1 Announce Type: cross  Abstract: Federated Recommendation (FR) emerges as a novel paradigm that enables privacy-preserving recommendations. However, traditional FR systems usually represent users/items with discrete identities (IDs), suffering from performance degradation due to the data sparsity and heterogeneity in FR. On the other hand, Large Language Models (LLMs) as recommenders have proven effective across various recommendation scenarios. Yet, LLM-based recommenders encounter challenges such as low inference efficiency and potential hallucination, compromising their performance in real-world scenarios. To this end, we propose GPT-FedRec, a federated recommendation framework leveraging ChatGPT and a novel hybrid Retrieval Augmented Generation (RAG) mechanism. GPT-FedRec is a two-stage solution. The first stage is a hybrid retrieval process, mining ID-based user patterns and text-based item features. Next, the retrieved results are converted into text prompts and
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#26102;&#24207;&#24207;&#21015;&#39044;&#27979;&#26694;&#26550;(RATSF)&#65292;&#36890;&#36807;&#24341;&#20837;&#20132;&#21449;&#27880;&#24847;&#21147;&#27169;&#22359;(RACA)&#21450;&#30693;&#35782;&#24211;&#35774;&#35745;&#65292;&#26377;&#25928;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#27573;&#36827;&#34892;&#23458;&#26381;&#37327;&#39044;&#27979;&#65292;&#22312;&#38750;&#24179;&#31283;&#25968;&#25454;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.04180</link><description>&lt;p&gt;
RATSF&#65306;&#36890;&#36807;&#26816;&#32034;&#22686;&#24378;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26469;&#36171;&#33021;&#23458;&#26381;&#37327;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
RATSF: Empowering Customer Service Volume Management through Retrieval-Augmented Time-Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04180
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#26102;&#24207;&#24207;&#21015;&#39044;&#27979;&#26694;&#26550;(RATSF)&#65292;&#36890;&#36807;&#24341;&#20837;&#20132;&#21449;&#27880;&#24847;&#21147;&#27169;&#22359;(RACA)&#21450;&#30693;&#35782;&#24211;&#35774;&#35745;&#65292;&#26377;&#25928;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#27573;&#36827;&#34892;&#23458;&#26381;&#37327;&#39044;&#27979;&#65292;&#22312;&#38750;&#24179;&#31283;&#25968;&#25454;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#39640;&#25928;&#30340;&#23458;&#26381;&#31649;&#29702;&#31995;&#32479;&#21462;&#20915;&#20110;&#23545;&#26381;&#21153;&#37327;&#30340;&#31934;&#30830;&#39044;&#27979;&#12290;&#22312;&#36825;&#31181;&#25968;&#25454;&#38750;&#24179;&#31283;&#24615;&#26126;&#26174;&#30340;&#24773;&#20917;&#19979;&#65292;&#25104;&#21151;&#30340;&#39044;&#27979;&#20005;&#37325;&#20381;&#36182;&#20110;&#35782;&#21035;&#21644;&#21033;&#29992;&#31867;&#20284;&#30340;&#21382;&#21490;&#25968;&#25454;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#24635;&#32467;&#21608;&#26399;&#24615;&#27169;&#24335;&#12290;&#29616;&#26377;&#22522;&#20110;RNN&#25110;Transformer&#26550;&#26500;&#30340;&#27169;&#22411;&#36890;&#24120;&#22312;&#28789;&#27963;&#21644;&#26377;&#25928;&#21033;&#29992;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#36866;&#24212;&#30340;&#20132;&#21449;&#27880;&#24847;&#21147;&#27169;&#22359;&#65292;&#31216;&#20026;RACA&#65292;&#23427;&#22312;&#39044;&#27979;&#20219;&#21153;&#20013;&#26377;&#25928;&#21033;&#29992;&#20102;&#21382;&#21490;&#27573;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#21382;&#21490;&#24207;&#21015;&#26597;&#35810;&#34920;&#31034;&#26041;&#26696;&#65292;&#32467;&#21512;&#20102;&#30693;&#35782;&#24211;&#30340;&#35774;&#35745;&#12290;&#36825;&#20123;&#20851;&#38190;&#32452;&#20214;&#20849;&#21516;&#26500;&#25104;&#20102;&#25105;&#20204;&#30340;&#26816;&#32034;&#22686;&#24378;&#26102;&#24207;&#24207;&#21015;&#39044;&#27979;&#26694;&#26550;&#65288;RATSF&#65289;&#12290;RATSF&#19981;&#20165;&#22312;&#33778;&#40481;&#37202;&#24215;&#26381;&#21153;&#37327;&#39044;&#27979;&#29615;&#22659;&#20013;&#26174;&#33879;&#22686;&#24378;&#20102;&#24615;&#33021;&#65292;&#32780;&#19988;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04180v1 Announce Type: new  Abstract: An efficient customer service management system hinges on precise forecasting of service volume. In this scenario, where data non-stationarity is pronounced, successful forecasting heavily relies on identifying and leveraging similar historical data rather than merely summarizing periodic patterns. Existing models based on RNN or Transformer architectures often struggle with this flexible and effective utilization. To address this challenge, we propose an efficient and adaptable cross-attention module termed RACA, which effectively leverages historical segments in forecasting task, and we devised a precise representation scheme for querying historical sequences, coupled with the design of a knowledge repository. These critical components collectively form our Retrieval-Augmented Temporal Sequence Forecasting framework (RATSF). RATSF not only significantly enhances performance in the context of Fliggy hotel service volume forecasting but,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#35821;&#26009;&#24211;&#20027;&#39064;&#20998;&#31867;&#25913;&#36827;&#20027;&#39064;&#29305;&#23450;&#24212;&#29992;&#20013;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#30830;&#23450;&#26597;&#35810;&#21644;&#25991;&#26723;&#30340;&#20013;&#24515;&#20027;&#39064;&#20197;&#21450;&#21033;&#29992;&#20027;&#39064;&#30456;&#20851;&#24615;&#26469;&#34917;&#20805;&#32570;&#22833;&#30340;&#19978;&#19979;&#25991;&#12290;</title><link>https://arxiv.org/abs/2403.04160</link><description>&lt;p&gt;
&#21033;&#29992;&#35821;&#26009;&#24211;&#20027;&#39064;&#20998;&#31867;&#25913;&#36827;&#20027;&#39064;&#29305;&#23450;&#24212;&#29992;&#20013;&#30340;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04160
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#35821;&#26009;&#24211;&#20027;&#39064;&#20998;&#31867;&#25913;&#36827;&#20027;&#39064;&#29305;&#23450;&#24212;&#29992;&#20013;&#26816;&#32034;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#30830;&#23450;&#26597;&#35810;&#21644;&#25991;&#26723;&#30340;&#20013;&#24515;&#20027;&#39064;&#20197;&#21450;&#21033;&#29992;&#20027;&#39064;&#30456;&#20851;&#24615;&#26469;&#34917;&#20805;&#32570;&#22833;&#30340;&#19978;&#19979;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#26816;&#32034;&#24050;&#32463;&#20174;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#30340;&#36827;&#27493;&#20013;&#21463;&#30410;&#33391;&#22810;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#22312;&#19987;&#38376;&#39046;&#22495;&#25110;&#34892;&#19994;&#30340;&#20027;&#39064;&#29305;&#23450;&#24212;&#29992;&#20013;&#36890;&#24120;&#21463;&#21040;&#38480;&#21046;&#65292;&#36825;&#26159;&#30001;&#20110;&#29420;&#29305;&#26415;&#35821;&#12289;&#29992;&#25143;&#26597;&#35810;&#30340;&#19981;&#23436;&#25972;&#19978;&#19979;&#25991;&#21644;&#19987;&#38376;&#25628;&#32034;&#24847;&#22270;&#23548;&#33268;&#30340;&#12290;&#20026;&#20102;&#25429;&#25417;&#20027;&#39064;&#29305;&#23450;&#20449;&#24687;&#24182;&#25913;&#36827;&#26816;&#32034;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#35821;&#26009;&#24211;&#20027;&#39064;&#20998;&#31867;&#65292;&#35813;&#20998;&#31867;&#27010;&#36848;&#20102;&#35821;&#26009;&#24211;&#30340;&#28508;&#22312;&#20027;&#39064;&#32467;&#26500;&#65292;&#21516;&#26102;&#21453;&#26144;&#20102;&#29992;&#25143;&#24863;&#20852;&#36259;&#30340;&#26041;&#38754;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;ToTER&#65288;&#22686;&#24378;&#22411;&#20027;&#39064;&#20998;&#31867;&#26816;&#32034;&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20511;&#21161;&#20998;&#31867;&#30340;&#25351;&#23548;&#30830;&#23450;&#26597;&#35810;&#21644;&#25991;&#26723;&#30340;&#20013;&#24515;&#20027;&#39064;&#65292;&#24182;&#21033;&#29992;&#23427;&#20204;&#30340;&#20027;&#39064;&#30456;&#20851;&#24615;&#34917;&#20805;&#32570;&#22833;&#30340;&#19978;&#19979;&#25991;&#12290;&#20316;&#20026;&#19968;&#31181;&#21363;&#25554;&#21363;&#29992;&#30340;&#26694;&#26550;&#65292;ToTER&#21487;&#28789;&#27963;&#24212;&#29992;&#20110;&#22686;&#24378;&#21508;&#31181;&#22522;&#20110;PLM&#30340;&#26816;&#32034;&#22120;&#12290;&#36890;&#36807;&#23545;&#20004;&#20010;&#26696;&#20363;&#36827;&#34892;&#24191;&#27867;&#30340;&#23450;&#37327;&#12289;&#32570;&#22833;&#21644;&#25506;&#32034;&#24615;&#23454;&#39564;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;ToTER&#26694;&#26550;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04160v1 Announce Type: cross  Abstract: Document retrieval has greatly benefited from the advancements of large-scale pre-trained language models (PLMs). However, their effectiveness is often limited in theme-specific applications for specialized areas or industries, due to unique terminologies, incomplete contexts of user queries, and specialized search intents. To capture the theme-specific information and improve retrieval, we propose to use a corpus topical taxonomy, which outlines the latent topic structure of the corpus while reflecting user-interested aspects. We introduce ToTER (Topical Taxonomy Enhanced Retrieval) framework, which identifies the central topics of queries and documents with the guidance of the taxonomy, and exploits their topical relatedness to supplement missing contexts. As a plug-and-play framework, ToTER can be flexibly employed to enhance various PLM-based retrievers. Through extensive quantitative, ablative, and exploratory experiments on two r
&lt;/p&gt;</description></item><item><title>&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20010;&#24615;&#21270;&#36127;&#37319;&#26679;&#25216;&#26415;&#22312;&#22686;&#37327;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#26356;&#26032;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#26102;&#36935;&#21040;&#30340;&#36951;&#24536;&#28798;&#38590;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.03993</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#36127;&#37319;&#26679;&#22312;&#25512;&#33616;&#31995;&#32479;&#22686;&#37327;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Personalized Negative Reservoir for Incremental Learning in Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03993
&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20010;&#24615;&#21270;&#36127;&#37319;&#26679;&#25216;&#26415;&#22312;&#22686;&#37327;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#26356;&#26032;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#26102;&#36935;&#21040;&#30340;&#36951;&#24536;&#28798;&#38590;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#22312;&#32447;&#24179;&#21488;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#27599;&#22825;&#35757;&#32451;&#25968;&#25454;&#37327;&#19981;&#26029;&#25193;&#22823;&#65292;&#29992;&#25143;&#20114;&#21160;&#27425;&#25968;&#19981;&#26029;&#22686;&#21152;&#12290;&#25506;&#32034;&#26356;&#22823;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#27169;&#22411;&#24050;&#25104;&#20026;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#30340;&#24517;&#35201;&#36861;&#27714;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#36827;&#23637;&#24102;&#26469;&#20102;&#26356;&#22823;&#30340;&#35745;&#31639;&#36127;&#25285;&#12290;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#65292;&#19968;&#26086;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#34987;&#35757;&#32451;&#21644;&#37096;&#32626;&#65292;&#36890;&#24120;&#38656;&#35201;&#39057;&#32321;&#26356;&#26032;&#20197;&#36866;&#24212;&#26032;&#30340;&#23458;&#25143;&#25968;&#25454;&#12290;&#32047;&#31215;&#36215;&#26469;&#65292;&#25968;&#25454;&#37327;&#30340;&#22686;&#21152;&#24517;&#23558;&#20351;&#24471;&#20174;&#22836;&#24320;&#22987;&#36827;&#34892;&#20840;&#37327;&#37325;&#35757;&#32451;&#21464;&#24471;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#12290;&#20165;&#20165;&#22312;&#26032;&#25968;&#25454;&#19978;&#36827;&#34892;&#31616;&#21333;&#24494;&#35843;&#20250;&#36935;&#21040;&#24050;&#34987;&#24191;&#27867;&#35760;&#24405;&#30340;&#36951;&#24536;&#28798;&#38590;&#38382;&#39064;&#12290;&#23613;&#31649;&#36127;&#37319;&#26679;&#22312;&#20351;&#29992;&#38544;&#24335;&#21453;&#39304;&#36827;&#34892;&#35757;&#32451;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#19968;&#37096;&#20998;&#65292;&#20294;&#30446;&#21069;&#24182;&#19981;&#23384;&#22312;&#19987;&#38376;&#38024;&#23545;&#22686;&#37327;&#23398;&#20064;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03993v1 Announce Type: cross  Abstract: Recommender systems have become an integral part of online platforms. Every day the volume of training data is expanding and the number of user interactions is constantly increasing. The exploration of larger and more expressive models has become a necessary pursuit to improve user experience. However, this progression carries with it an increased computational burden. In commercial settings, once a recommendation system model has been trained and deployed it typically needs to be updated frequently as new client data arrive. Cumulatively, the mounting volume of data is guaranteed to eventually make full batch retraining of the model from scratch computationally infeasible. Naively fine-tuning solely on the new data runs into the well-documented problem of catastrophic forgetting. Despite the fact that negative sampling is a crucial part of training with implicit feedback, no specialized technique exists that is tailored to the increme
&lt;/p&gt;</description></item><item><title>Disaggregated Multi-Tower&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#25299;&#25169;&#24863;&#30693;&#30340;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;SPTT&#12289;TM&#21644;TP&#19977;&#20010;&#32452;&#20214;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#22823;&#35268;&#27169;&#25512;&#33616;&#65292;&#21152;&#36895;&#24615;&#33021;&#25552;&#21319;&#20102;1.9&#20493;&#12290;</title><link>https://arxiv.org/abs/2403.00877</link><description>&lt;p&gt;
Disaggregated Multi-Tower: &#38754;&#21521;&#25299;&#25169;&#24863;&#30693;&#30340;&#39640;&#25928;&#22823;&#35268;&#27169;&#25512;&#33616;&#24314;&#27169;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Disaggregated Multi-Tower: Topology-aware Modeling Technique for Efficient Large-Scale Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00877
&lt;/p&gt;
&lt;p&gt;
Disaggregated Multi-Tower&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#25299;&#25169;&#24863;&#30693;&#30340;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;SPTT&#12289;TM&#21644;TP&#19977;&#20010;&#32452;&#20214;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#22823;&#35268;&#27169;&#25512;&#33616;&#65292;&#21152;&#36895;&#24615;&#33021;&#25552;&#21319;&#20102;1.9&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;&#23398;&#20064;&#25512;&#33616;&#27169;&#22411;&#30340;&#25153;&#24179;&#26550;&#26500;&#12289;&#24120;&#35265;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;&#27169;&#24335;&#21644;&#20998;&#23618;&#25968;&#25454;&#20013;&#24515;&#25299;&#25169;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#20026;&#20102;&#35299;&#20915;&#30456;&#20851;&#30340;&#20302;&#25928;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Disaggregated Multi-Tower&#65288;DMT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#24314;&#27169;&#25216;&#26415;&#65292;&#21253;&#25324;&#65288;1&#65289;&#35821;&#20041;&#20445;&#30041;&#30340;Tower Transform&#65288;SPTT&#65289;&#65292;&#19968;&#20010;&#23558;&#21333;&#29255;&#20840;&#23616;&#23884;&#20837;&#26597;&#25214;&#36807;&#31243;&#20998;&#35299;&#20026;&#19981;&#30456;&#20132;&#22612;&#20197;&#21033;&#29992;&#25968;&#25454;&#20013;&#24515;&#20301;&#32622;&#20851;&#31995;&#30340;&#26032;&#22411;&#35757;&#32451;&#27169;&#24335;&#65307;&#65288;2&#65289;Tower Module&#65288;TM&#65289;&#65292;&#19968;&#20010;&#38468;&#21152;&#21040;&#27599;&#20010;&#22612;&#30340;&#21327;&#21516;&#31264;&#23494;&#32452;&#20214;&#65292;&#36890;&#36807;&#20998;&#23618;&#29305;&#24449;&#20132;&#20114;&#38477;&#20302;&#27169;&#22411;&#22797;&#26434;&#24615;&#21644;&#36890;&#20449;&#37327;&#65307;&#21644;&#65288;3&#65289;Tower Partitioner&#65288;TP&#65289;&#65292;&#19968;&#20010;&#29305;&#24449;&#20998;&#21306;&#22120;&#65292;&#31995;&#32479;&#22320;&#21019;&#24314;&#20855;&#26377;&#26377;&#24847;&#20041;&#29305;&#24449;&#20132;&#20114;&#21644;&#36127;&#36733;&#24179;&#34913;&#20998;&#37197;&#30340;&#22612;&#65292;&#36890;&#36807;&#23398;&#20064;&#30340;&#23884;&#20837;&#26469;&#20445;&#25345;&#27169;&#22411;&#36136;&#37327;&#21644;&#35757;&#32451;&#21534;&#21520;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;DMT&#30456;&#27604;&#20110;&#26368;&#26032;&#30340;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#39640;&#36798;1.9&#20493;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00877v1 Announce Type: new  Abstract: We study a mismatch between the deep learning recommendation models' flat architecture, common distributed training paradigm and hierarchical data center topology. To address the associated inefficiencies, we propose Disaggregated Multi-Tower (DMT), a modeling technique that consists of (1) Semantic-preserving Tower Transform (SPTT), a novel training paradigm that decomposes the monolithic global embedding lookup process into disjoint towers to exploit data center locality; (2) Tower Module (TM), a synergistic dense component attached to each tower to reduce model complexity and communication volume through hierarchical feature interaction; and (3) Tower Partitioner (TP), a feature partitioner to systematically create towers with meaningful feature interactions and load balanced assignments to preserve model quality and training throughput via learned embeddings. We show that DMT can achieve up to 1.9x speedup compared to the state-of-th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;SINGLE&#26041;&#27861;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#29992;&#25143;&#27983;&#35272;&#27969;&#36827;&#34892;&#24314;&#27169;&#65292;&#20197;&#26356;&#22909;&#22320;&#36827;&#34892;&#25991;&#31456;&#25512;&#33616;&#12290;</title><link>https://arxiv.org/abs/2311.07619</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#29992;&#25143;&#27983;&#35272;&#27969;&#36827;&#34892;&#24314;&#27169;&#20197;&#36827;&#34892;&#25991;&#31456;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Modeling User Viewing Flow Using Large Language Models for Article Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;SINGLE&#26041;&#27861;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#29992;&#25143;&#27983;&#35272;&#27969;&#36827;&#34892;&#24314;&#27169;&#65292;&#20197;&#26356;&#22909;&#22320;&#36827;&#34892;&#25991;&#31456;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#25143;&#27983;&#35272;&#27969;&#24314;&#27169;&#65288;SINGLE&#65289;&#26041;&#27861;&#29992;&#20110;&#25991;&#31456;&#25512;&#33616;&#20219;&#21153;&#65292;&#35813;&#26041;&#27861;&#20174;&#29992;&#25143;&#28857;&#20987;&#30340;&#25991;&#31456;&#20013;&#27169;&#25311;&#29992;&#25143;&#30340;&#25345;&#32493;&#20559;&#22909;&#21644;&#21363;&#26102;&#20852;&#36259;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#37319;&#29992;&#29992;&#25143;&#25345;&#32493;&#27983;&#35272;&#27969;&#24314;&#27169;&#26041;&#27861;&#24635;&#32467;&#29992;&#25143;&#30340;&#19968;&#33324;&#20852;&#36259;&#20197;&#25512;&#33616;&#25991;&#31456;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20174;&#20808;&#21069;&#28857;&#20987;&#30340;&#25991;&#31456;&#20013;&#25429;&#25417;&#29992;&#25143;&#30340;&#25345;&#32493;&#20559;&#22909;&#65292;&#22914;&#25216;&#33021;&#21644;&#32844;&#20301;&#12290;&#28982;&#21518;&#25105;&#20204;&#35774;&#35745;&#29992;&#25143;&#21363;&#26102;&#27983;&#35272;&#27969;&#24314;&#27169;&#26041;&#27861;&#26469;&#26500;&#24314;&#29992;&#25143;&#28857;&#20987;&#30340;&#25991;&#31456;&#21382;&#21490;&#19982;&#20505;&#36873;&#25991;&#31456;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#23427;&#19987;&#27880;&#20110;&#38405;&#35835;&#29992;&#25143;&#28857;&#20987;&#25991;&#31456;&#30340;&#34920;&#31034;&#65292;&#24182;&#26088;&#22312;&#23398;&#20064;&#29992;&#25143;&#19981;&#21516;&#30340;&#20852;&#36259;&#35266;&#28857;&#20197;&#21305;&#37197;&#20505;&#36873;&#25991;&#31456;&#12290;&#25105;&#20204;&#22312;&#38463;&#37324;&#24052;&#24052;&#25216;&#26415;&#21327;&#20250;&#65288;ATA&#65289;&#32593;&#31449;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;SINGLE&#30340;&#20248;&#21183;&#65292;&#30456;&#36739;&#20110;&#20808;&#21069;&#30340;&#22522;&#32447;&#23454;&#29616;&#20102;2.4%&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07619v2 Announce Type: replace-cross  Abstract: This paper proposes the User Viewing Flow Modeling (SINGLE) method for the article recommendation task, which models the user constant preference and instant interest from user-clicked articles. Specifically, we first employ a user constant viewing flow modeling method to summarize the user's general interest to recommend articles. In this case, we utilize Large Language Models (LLMs) to capture constant user preferences from previously clicked articles, such as skills and positions. Then we design the user instant viewing flow modeling method to build interactions between user-clicked article history and candidate articles. It attentively reads the representations of user-clicked articles and aims to learn the user's different interest views to match the candidate article. Our experimental results on the Alibaba Technology Association (ATA) website show the advantage of SINGLE, achieving a 2.4% improvement over previous baseli
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#31639;&#23884;&#20837;&#34920;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#20013;&#22266;&#23450;&#23884;&#20837;&#22823;&#23567;&#38590;&#20197;&#25193;&#23637;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#26377;&#25928;&#24212;&#23545;&#19981;&#21516;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#22810;&#26679;&#24615;&#23884;&#20837;&#22823;&#23567;&#12290;</title><link>https://arxiv.org/abs/2310.14884</link><description>&lt;p&gt;
&#38754;&#21521;&#25512;&#33616;&#31995;&#32479;&#30340;&#39044;&#31639;&#23884;&#20837;&#34920;
&lt;/p&gt;
&lt;p&gt;
Budgeted Embedding Table For Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.14884
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#31639;&#23884;&#20837;&#34920;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#20013;&#22266;&#23450;&#23884;&#20837;&#22823;&#23567;&#38590;&#20197;&#25193;&#23637;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#26377;&#25928;&#24212;&#23545;&#19981;&#21516;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#22810;&#26679;&#24615;&#23884;&#20837;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20170;&#25512;&#33616;&#31995;&#32479;&#30340;&#26680;&#24515;&#26159;&#25552;&#20379;&#32473;&#29992;&#25143;&#20248;&#36136;&#25512;&#33616;&#20307;&#39564;&#30340;&#28508;&#22312;&#22240;&#32032;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#20351;&#29992;&#23884;&#20837;&#21521;&#37327;&#26469;&#34920;&#31034;&#29992;&#25143;&#21644;&#39033;&#30446;&#12290;&#26368;&#36817;&#30340;&#36731;&#37327;&#32423;&#23884;&#20837;&#26041;&#27861;&#20351;&#19981;&#21516;&#29992;&#25143;&#21644;&#39033;&#30446;&#33021;&#22815;&#20855;&#26377;&#19981;&#21516;&#30340;&#23884;&#20837;&#22823;&#23567;&#65292;&#20294;&#36890;&#24120;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#32570;&#28857;&#12290;&#39318;&#20808;&#65292;&#23427;&#20204;&#23558;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;&#38480;&#21046;&#22312;&#20248;&#21270;&#21551;&#21457;&#24335;&#24179;&#34913;&#25512;&#33616;&#36136;&#37327;&#21644;&#20869;&#23384;&#22797;&#26434;&#24615;&#30340;&#33539;&#22260;&#20869;&#65292;&#20854;&#20013;&#25240;&#34935;&#31995;&#25968;&#38656;&#35201;&#20026;&#27599;&#20010;&#20869;&#23384;&#39044;&#31639;&#25163;&#21160;&#35843;&#25972;&#12290;&#38544;&#24335;&#24378;&#21046;&#30340;&#20869;&#23384;&#22797;&#26434;&#24615;&#39033;&#29978;&#33267;&#21487;&#33021;&#26080;&#27861;&#38480;&#21046;&#21442;&#25968;&#20351;&#29992;&#37327;&#65292;&#20351;&#24471;&#24471;&#21040;&#30340;&#23884;&#20837;&#34920;&#26080;&#27861;&#20005;&#26684;&#28385;&#36275;&#20869;&#23384;&#39044;&#31639;&#12290;&#20854;&#27425;&#65292;&#22823;&#22810;&#25968;&#35299;&#20915;&#26041;&#26696;&#65292;&#29305;&#21035;&#26159;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.14884v4 Announce Type: replace  Abstract: At the heart of contemporary recommender systems (RSs) are latent factor models that provide quality recommendation experience to users. These models use embedding vectors, which are typically of a uniform and fixed size, to represent users and items. As the number of users and items continues to grow, this design becomes inefficient and hard to scale. Recent lightweight embedding methods have enabled different users and items to have diverse embedding sizes, but are commonly subject to two major drawbacks. Firstly, they limit the embedding size search to optimizing a heuristic balancing the recommendation quality and the memory complexity, where the trade-off coefficient needs to be manually tuned for every memory budget requested. The implicitly enforced memory complexity term can even fail to cap the parameter usage, making the resultant embedding table fail to meet the memory budget strictly. Secondly, most solutions, especially 
&lt;/p&gt;</description></item><item><title>&#20132;&#20114;&#24335;&#38382;&#31572;&#31995;&#32479;&#26159;&#38382;&#31572;&#21644;&#23545;&#35805;&#31995;&#32479;&#30340;&#32467;&#21512;&#65292;&#29992;&#25143;&#21487;&#20197;&#29992;&#33258;&#28982;&#35821;&#35328;&#25552;&#38382;&#24182;&#19982;&#31995;&#32479;&#21160;&#24577;&#20132;&#20114;&#65292;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2209.01621</link><description>&lt;p&gt;
&#20132;&#20114;&#24335;&#38382;&#31572;&#31995;&#32479;&#65306;&#25991;&#29486;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Interactive Question Answering Systems: Literature Review
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.01621
&lt;/p&gt;
&lt;p&gt;
&#20132;&#20114;&#24335;&#38382;&#31572;&#31995;&#32479;&#26159;&#38382;&#31572;&#21644;&#23545;&#35805;&#31995;&#32479;&#30340;&#32467;&#21512;&#65292;&#29992;&#25143;&#21487;&#20197;&#29992;&#33258;&#28982;&#35821;&#35328;&#25552;&#38382;&#24182;&#19982;&#31995;&#32479;&#21160;&#24577;&#20132;&#20114;&#65292;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2209.01621v2 &#20844;&#21578;&#31867;&#22411;: &#26367;&#25442;-&#36328;  &#25688;&#35201;: &#38382;&#31572;&#31995;&#32479;&#34987;&#20844;&#35748;&#20026;&#22312;&#32593;&#32476;&#19978;&#23547;&#27714;&#20449;&#24687;&#30340;&#27969;&#34892;&#19988;&#26377;&#25928;&#30340;&#25163;&#27573;&#12290;&#22312;&#36825;&#31181;&#31995;&#32479;&#20013;&#65292;&#20449;&#24687;&#23547;&#25214;&#32773;&#21487;&#20197;&#36890;&#36807;&#29992;&#33258;&#28982;&#35821;&#35328;&#25552;&#20986;&#38382;&#39064;&#26469;&#33719;&#24471;&#31616;&#27905;&#30340;&#22238;&#31572;&#12290;&#20132;&#20114;&#24335;&#38382;&#31572;&#26159;&#26368;&#36817;&#25552;&#20986;&#30340;&#24182;&#36234;&#26469;&#36234;&#27969;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20301;&#20110;&#38382;&#31572;&#21644;&#23545;&#35805;&#31995;&#32479;&#30340;&#20132;&#38598;&#22788;&#12290;&#19968;&#26041;&#38754;&#65292;&#29992;&#25143;&#21487;&#20197;&#29992;&#26222;&#36890;&#35821;&#35328;&#25552;&#38382;&#24182;&#25214;&#21040;&#22905;&#38382;&#39064;&#30340;&#23454;&#38469;&#22238;&#31572;&#65307;&#21478;&#19968;&#26041;&#38754;&#65292;&#22914;&#26524;&#21021;&#22987;&#35831;&#27714;&#20013;&#23384;&#22312;&#22810;&#20010;&#21487;&#33021;&#30340;&#22238;&#22797;&#12289;&#24456;&#23569;&#25110;&#27169;&#26865;&#20004;&#21487;&#65292;&#31995;&#32479;&#21487;&#20197;&#23558;&#38382;&#31572;&#20250;&#35805;&#24310;&#38271;&#20026;&#23545;&#35805;&#12290;&#36890;&#36807;&#20801;&#35768;&#29992;&#25143;&#25552;&#20986;&#26356;&#22810;&#38382;&#39064;&#65292;&#20132;&#20114;&#24335;&#38382;&#31572;&#20351;&#29992;&#25143;&#33021;&#22815;&#21160;&#24577;&#22320;&#19982;&#31995;&#32479;&#20132;&#20114;&#24182;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#32467;&#26524;&#12290;&#26412;&#32508;&#36848;&#25552;&#20379;&#20102;&#20132;&#20114;&#24335;&#38382;&#31572;&#31995;&#32479;&#30340;&#35814;&#32454;&#27010;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.01621v2 Announce Type: replace-cross  Abstract: Question answering systems are recognized as popular and frequently effective means of information seeking on the web. In such systems, information seekers can receive a concise response to their query by presenting their questions in natural language. Interactive question answering is a recently proposed and increasingly popular solution that resides at the intersection of question answering and dialogue systems. On the one hand, the user can ask questions in normal language and locate the actual response to her inquiry; on the other hand, the system can prolong the question-answering session into a dialogue if there are multiple probable replies, very few, or ambiguities in the initial request. By permitting the user to ask more questions, interactive question answering enables users to dynamically interact with the system and receive more precise results. This survey offers a detailed overview of the interactive question-ans
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;</title><link>http://arxiv.org/abs/2310.20091</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#23494;&#24230;&#29992;&#25143;&#34920;&#31034;&#26041;&#27861;&#29992;&#20110;&#22810;&#20852;&#36259;&#20010;&#24615;&#21270;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval. (arXiv:2310.20091v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#36824;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35774;&#35745;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#20934;&#30830;&#24314;&#27169;&#29992;&#25143;&#30340;&#21508;&#31181;&#22810;&#26679;&#21270;&#21644;&#21160;&#24577;&#30340;&#20852;&#36259;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#29992;&#25143;&#24314;&#27169;&#26041;&#27861;&#65292;&#22914;&#21333;&#28857;&#21644;&#22810;&#28857;&#34920;&#31034;&#65292;&#23384;&#22312;&#20934;&#30830;&#24615;&#12289;&#22810;&#26679;&#24615;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#36866;&#24212;&#24615;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#19981;&#36275;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#8212;&#8212;&#22522;&#20110;&#23494;&#24230;&#30340;&#29992;&#25143;&#34920;&#31034;(DURs)&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#26377;&#25928;&#30340;&#22810;&#20852;&#36259;&#25512;&#33616;&#21644;&#26816;&#32034;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;GPR4DUR&#21033;&#29992;DURs&#26469;&#25429;&#25417;&#29992;&#25143;&#30340;&#20852;&#36259;&#21464;&#21270;&#65292;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#65292;&#21516;&#26102;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#33021;&#21147;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22823;&#37327;&#29992;&#25143;&#30340;&#35268;&#27169;&#12290;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;GPR4DUR&#30340;&#36866;&#24212;&#24615;&#21644;&#25928;&#29575;&#65292;&#32780;&#20351;&#29992;&#27169;&#25311;&#29992;&#25143;&#30340;&#22312;&#32447;&#23454;&#39564;&#21017;&#35777;&#26126;&#20102;&#23427;&#36890;&#36807;&#26377;&#25928;&#21033;&#29992;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#33021;&#22815;&#35299;&#20915;&#25506;&#32034;-&#24320;&#21457;&#30340;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, computational cost, and adaptability. To overcome these deficiencies, we introduce density-based user representations (DURs), a novel model that leverages Gaussian process regression for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;CONTINUOUS&#65292;&#21487;&#20197;&#23545;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#36827;&#34892;&#36830;&#32493;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;&#65292;&#23427;&#36890;&#36807;&#23558;&#23884;&#20837;&#22823;&#23567;&#36873;&#25321;&#24314;&#27169;&#20026;&#36830;&#32493;&#21464;&#37327;&#35299;&#20915;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#35777;&#23454;&#20102;&#23427;&#30340;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.03501</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#30340;&#36830;&#32493;&#36755;&#20837;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Continuous Input Embedding Size Search For Recommender Systems. (arXiv:2304.03501v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03501
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;CONTINUOUS&#65292;&#21487;&#20197;&#23545;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#36827;&#34892;&#36830;&#32493;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;&#65292;&#23427;&#36890;&#36807;&#23558;&#23884;&#20837;&#22823;&#23567;&#36873;&#25321;&#24314;&#27169;&#20026;&#36830;&#32493;&#21464;&#37327;&#35299;&#20915;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#35777;&#23454;&#20102;&#23427;&#30340;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#26159;&#29616;&#20170;&#25512;&#33616;&#31995;&#32479;&#26368;&#27969;&#34892;&#30340;&#22522;&#30784;&#65292;&#20854;&#24615;&#33021;&#21331;&#36234;&#12290;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#36890;&#36807;&#23545;&#29992;&#25143;&#21644;&#39033;&#30446;&#36827;&#34892;&#34920;&#31034;&#65292;&#29992;&#20110;&#23545;&#25104;&#23545;&#30456;&#20284;&#24230;&#30340;&#35745;&#31639;&#12290;&#25152;&#26377;&#23884;&#20837;&#21521;&#37327;&#20256;&#32479;&#19978;&#37117;&#34987;&#38480;&#21046;&#22312;&#19968;&#20010;&#30456;&#23545;&#36739;&#22823;&#30340;&#32479;&#19968;&#22823;&#23567;&#65288;&#20363;&#22914;256&#32500;&#65289;&#12290;&#38543;&#30528;&#24403;&#20195;&#30005;&#23376;&#21830;&#21153;&#20013;&#29992;&#25143;&#21644;&#39033;&#30446;&#30446;&#24405;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#36825;&#31181;&#35774;&#35745;&#26174;&#28982;&#21464;&#24471;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#20419;&#36827;&#36731;&#37327;&#32423;&#25512;&#33616;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26368;&#36817;&#24320;&#36767;&#20102;&#19968;&#20123;&#26426;&#20250;&#65292;&#29992;&#20110;&#35782;&#21035;&#19981;&#21516;&#29992;&#25143;/&#39033;&#30446;&#30340;&#19981;&#21516;&#23884;&#20837;&#22823;&#23567;&#12290;&#28982;&#32780;&#65292;&#21463;&#21040;&#25628;&#32034;&#25928;&#29575;&#21644;&#23398;&#20064;&#26368;&#20248;RL&#31574;&#30053;&#30340;&#38480;&#21046;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;RL&#30340;&#26041;&#27861;&#34987;&#38480;&#21046;&#20026;&#39640;&#24230;&#31163;&#25955;&#30340;&#39044;&#23450;&#20041;&#23884;&#20837;&#22823;&#23567;&#36873;&#39033;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#34987;&#24191;&#27867;&#24573;&#35270;&#30340;&#28508;&#21147;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#35745;&#31639;&#39044;&#31639;&#19979;&#24341;&#20837;&#26356;&#32454;&#30340;&#31890;&#24230;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#25512;&#33616;&#25928;&#26524;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;CONTINUOUS&#65292;&#21487;&#20197;&#23545;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#36827;&#34892;&#36830;&#32493;&#23884;&#20837;&#22823;&#23567;&#25628;&#32034;&#12290;CONTINUOUS&#36890;&#36807;&#23558;&#23884;&#20837;&#22823;&#23567;&#36873;&#25321;&#24314;&#27169;&#20026;&#36830;&#32493;&#21464;&#37327;&#21644;&#21046;&#23450;&#21487;&#24494;&#20248;&#21270;&#38382;&#39064;&#30340;&#24418;&#24335;&#26469;&#35299;&#20915;&#20043;&#21069;&#24037;&#20316;&#30340;&#25361;&#25112;&#12290;&#22312;&#19977;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;CONTINUOUS&#20248;&#20110;&#22522;&#32447;&#30340;&#20248;&#36234;&#24615;&#65292;&#39564;&#35777;&#20102;&#21160;&#24577;&#20248;&#21270;&#23884;&#20837;&#22823;&#23567;&#30340;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e-commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a giv
&lt;/p&gt;</description></item></channel></rss>