<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19981;&#38656;&#35201;&#35757;&#32451;&#65292;&#22522;&#20110;&#31616;&#21333;&#26144;&#23556;&#30340;&#36328;&#27169;&#24577;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#65292;&#21033;&#29992;&#26469;&#33258;&#39044;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#32534;&#30721;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#35821;&#20041;&#19978;&#23558;&#19981;&#21516;&#27169;&#24577;&#30340;&#25968;&#25454;&#26144;&#23556;&#21040;&#21516;&#19968;&#31354;&#38388;&#65292;&#24182;&#22312;&#25991;&#26412;&#21644;&#22270;&#20687;&#20043;&#38388;&#36798;&#21040;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2304.11095</link><description>&lt;p&gt;
&#19981;&#38656;&#35201;&#35757;&#32451;&#65292;&#36328;&#27169;&#24577;&#20449;&#24687;&#26816;&#32034;&#26159;&#21542;&#21487;&#34892;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Cross-modal Information Retrieval Possible without Training?. (arXiv:2304.11095v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19981;&#38656;&#35201;&#35757;&#32451;&#65292;&#22522;&#20110;&#31616;&#21333;&#26144;&#23556;&#30340;&#36328;&#27169;&#24577;&#20449;&#24687;&#26816;&#32034;&#26041;&#27861;&#65292;&#21033;&#29992;&#26469;&#33258;&#39044;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#32534;&#30721;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#35821;&#20041;&#19978;&#23558;&#19981;&#21516;&#27169;&#24577;&#30340;&#25968;&#25454;&#26144;&#23556;&#21040;&#21516;&#19968;&#31354;&#38388;&#65292;&#24182;&#22312;&#25991;&#26412;&#21644;&#22270;&#20687;&#20043;&#38388;&#36798;&#21040;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#32534;&#30721;&#30340;&#34920;&#31034;(&#20363;&#22914;BERT&#25991;&#26412;&#23884;&#20837;&#65292;&#22270;&#20687;&#30340;&#20498;&#25968;&#31532;&#20108;&#20010;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#23618;&#28608;&#27963;)&#20256;&#36882;&#20102;&#19968;&#32452;&#26377;&#30410;&#30340;&#20449;&#24687;&#26816;&#32034;&#29305;&#24449;&#12290;&#32473;&#23450;&#25968;&#25454;&#27169;&#24577;&#30340;&#23884;&#20837;&#23384;&#22312;&#33258;&#24049;&#30340;&#39640;&#32500;&#31354;&#38388;&#20013;&#65292;&#20294;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#26144;&#23556;&#36827;&#34892;&#35821;&#20041;&#23545;&#40784;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#26368;&#23567;&#20108;&#20056;&#27861;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299; (SVD) &#30340;&#31616;&#21333;&#26144;&#23556;&#20316;&#20026;Procrustes&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#23454;&#29616;&#36328;&#27169;&#24577;&#20449;&#24687;&#26816;&#32034;&#30340;&#25163;&#27573;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#32473;&#23450;&#19968;&#20010;&#27169;&#24577;&#20013;&#30340;&#20449;&#24687;&#65292;&#20363;&#22914;&#25991;&#26412;&#65292;&#35813;&#26144;&#23556;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#22312;&#21478;&#19968;&#20010;&#27169;&#24577;&#20013;&#25214;&#21040;&#19982;&#20854;&#35821;&#20041;&#30456;&#24403;&#30340;&#25968;&#25454;&#39033;&#65292;&#20363;&#22914;&#22270;&#20687;&#12290;&#20351;&#29992;&#29616;&#25104;&#30340;&#39044;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#25105;&#20204;&#22312;&#25991;&#26412;&#21040;&#22270;&#20687;&#21644;&#22270;&#20687;&#21040;&#25991;&#26412;&#30340;&#26816;&#32034;&#20219;&#21153;&#20013;&#23581;&#35797;&#20102;&#19978;&#36848;&#31616;&#21333;&#30340;&#36328;&#27169;&#24577;&#26144;&#23556;&#12290;&#23613;&#31649;&#31616;&#21333;&#65292;&#25105;&#20204;&#30340;&#26144;&#23556;&#34920;&#29616;&#20986;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#65292;&#24182;&#36798;&#21040;&#20102;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#24403;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Encoded representations from a pretrained deep learning model (e.g., BERT text embeddings, penultimate CNN layer activations of an image) convey a rich set of features beneficial for information retrieval. Embeddings for a particular modality of data occupy a high-dimensional space of its own, but it can be semantically aligned to another by a simple mapping without training a deep neural net. In this paper, we take a simple mapping computed from the least squares and singular value decomposition (SVD) for a solution to the Procrustes problem to serve a means to cross-modal information retrieval. That is, given information in one modality such as text, the mapping helps us locate a semantically equivalent data item in another modality such as image. Using off-the-shelf pretrained deep learning models, we have experimented the aforementioned simple cross-modal mappings in tasks of text-to-image and image-to-text retrieval. Despite simplicity, our mappings perform reasonably well reachin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;NIDAL&#30340;&#20154;&#24037;&#26234;&#33021;&#26694;&#26550;&#65292;&#21487;&#20197;&#33258;&#21160;&#26816;&#27979;&#19981;&#21516;&#35821;&#35328;&#20013;&#20986;&#29616;&#30340;&#26032;&#22411;&#24847;&#22270;&#31867;&#21035;&#24182;&#20943;&#23569;&#20154;&#21592;&#26631;&#27880;&#25104;&#26412;&#65292;&#36890;&#36807;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31995;&#32479;&#21487;&#20197;&#23454;&#29616;&#39640;&#20934;&#30830;&#29575;&#21644;&#23439;F1&#20540;&#12290;</title><link>http://arxiv.org/abs/2304.11058</link><description>&lt;p&gt;
&#26032;&#22411;&#24847;&#22270;&#26816;&#27979;&#21644;&#22522;&#20110;&#20027;&#21160;&#23398;&#20064;&#30340;&#20998;&#31867;&#65288;&#23398;&#29983;&#25688;&#35201;&#65289;
&lt;/p&gt;
&lt;p&gt;
Novel Intent Detection and Active Learning Based Classification (Student Abstract). (arXiv:2304.11058v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;NIDAL&#30340;&#20154;&#24037;&#26234;&#33021;&#26694;&#26550;&#65292;&#21487;&#20197;&#33258;&#21160;&#26816;&#27979;&#19981;&#21516;&#35821;&#35328;&#20013;&#20986;&#29616;&#30340;&#26032;&#22411;&#24847;&#22270;&#31867;&#21035;&#24182;&#20943;&#23569;&#20154;&#21592;&#26631;&#27880;&#25104;&#26412;&#65292;&#36890;&#36807;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31995;&#32479;&#21487;&#20197;&#23454;&#29616;&#39640;&#20934;&#30830;&#29575;&#21644;&#23439;F1&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#20132;&#20114;&#30340;&#23545;&#35805;&#20195;&#29702;&#24773;&#22659;&#20013;&#65292;&#26032;&#22411;&#24847;&#22270;&#31867;&#21035;&#26816;&#27979;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#24050;&#32463;&#36827;&#34892;&#20102;&#35768;&#22810;&#30740;&#31350;&#24037;&#20316;&#65292;&#20197;&#26816;&#27979;&#33521;&#35821;&#20026;&#20027;&#35201;&#25991;&#26412;&#21644;&#22270;&#20687;&#20013;&#30340;&#26032;&#22411;&#24847;&#22270;&#12290;&#20294;&#26159;&#65292;&#24403;&#21069;&#31995;&#32479;&#32570;&#20047;&#19968;&#31181;&#31471;&#21040;&#31471;&#36890;&#29992;&#26694;&#26550;&#65292;&#20197;&#22312;&#21508;&#31181;&#19981;&#21516;&#35821;&#35328;&#30340;&#21516;&#26102;&#26816;&#27979;&#26032;&#22411;&#24847;&#22270;&#65292;&#21516;&#26102;&#20943;&#23569;&#23545;&#20154;&#31867;&#27880;&#37322;&#30340;&#38656;&#27714;&#20197;&#22788;&#29702;&#34987;&#20998;&#31867;&#38169;&#35823;&#25110;&#31995;&#32479;&#25298;&#32477;&#30340;&#26679;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;NIDAL&#65288;Novel Intent Detection and Active Learning based classification&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#21322;&#30417;&#30563;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#26032;&#22411;&#24847;&#22270;&#24182;&#20943;&#23569;&#20154;&#31867;&#27880;&#37322;&#25104;&#26412;&#12290;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#21644;&#23439;F1&#30456;&#23545;&#20110;&#22522;&#32447;&#26041;&#27861;&#25552;&#39640;&#20102;10%&#20197;&#19978;&#65292;&#19988;&#24635;&#27880;&#37322;&#25104;&#26412;&#20165;&#20026;&#31995;&#32479;&#21487;&#29992;&#26410;&#26631;&#27880;&#25968;&#25454;&#30340;6-10&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
Novel intent class detection is an important problem in real world scenario for conversational agents for continuous interaction. Several research works have been done to detect novel intents in a mono-lingual (primarily English) texts and images. But, current systems lack an end-to-end universal framework to detect novel intents across various different languages with less human annotation effort for mis-classified and system rejected samples. This paper proposes NIDAL (Novel Intent Detection and Active Learning based classification), a semi-supervised framework to detect novel intents while reducing human annotation cost. Empirical results on various benchmark datasets demonstrate that this system outperforms the baseline methods by more than 10% margin for accuracy and macro-F1. The system achieves this while maintaining overall annotation cost to be just ~6-10% of the unlabeled data available to the system.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#31163;&#21464;&#20998;&#23545;&#25239;&#35757;&#32451;&#30340;&#39118;&#38505;&#24863;&#30693;&#22411;&#32929;&#31080;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25239;&#24615;&#25200;&#21160;&#25552;&#39640;&#27169;&#22411;&#23545;&#20110;&#39118;&#38505;&#30340;&#24863;&#30693;&#33021;&#21147;&#65292;&#36890;&#36807;&#21464;&#20998;&#25200;&#21160;&#29983;&#25104;&#22120;&#27169;&#25311;&#19981;&#21516;&#30340;&#39118;&#38505;&#22240;&#32032;&#24182;&#29983;&#25104;&#20195;&#34920;&#24615;&#30340;&#39118;&#38505;&#25351;&#26631;&#23545;&#25239;&#26679;&#26412;&#12290;&#22312;&#30495;&#23454;&#32929;&#31080;&#25968;&#25454;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26377;&#25928;&#38477;&#20302;&#20102;&#25237;&#36164;&#39118;&#38505;&#21516;&#26102;&#20445;&#25345;&#39640;&#39044;&#26399;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2304.11043</link><description>&lt;p&gt;
&#25200;&#21160;&#26377;&#21161;&#20110;&#38477;&#20302;&#25237;&#36164;&#39118;&#38505;&#21527;&#65311; &#22522;&#20110;&#20998;&#31163;&#21464;&#20998;&#23545;&#25239;&#35757;&#32451;&#30340;&#39118;&#38505;&#24863;&#30693;&#22411;&#32929;&#31080;&#25512;&#33616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Can Perturbations Help Reduce Investment Risks? Risk-Aware Stock Recommendation via Split Variational Adversarial Training. (arXiv:2304.11043v1 [q-fin.RM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#31163;&#21464;&#20998;&#23545;&#25239;&#35757;&#32451;&#30340;&#39118;&#38505;&#24863;&#30693;&#22411;&#32929;&#31080;&#25512;&#33616;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25239;&#24615;&#25200;&#21160;&#25552;&#39640;&#27169;&#22411;&#23545;&#20110;&#39118;&#38505;&#30340;&#24863;&#30693;&#33021;&#21147;&#65292;&#36890;&#36807;&#21464;&#20998;&#25200;&#21160;&#29983;&#25104;&#22120;&#27169;&#25311;&#19981;&#21516;&#30340;&#39118;&#38505;&#22240;&#32032;&#24182;&#29983;&#25104;&#20195;&#34920;&#24615;&#30340;&#39118;&#38505;&#25351;&#26631;&#23545;&#25239;&#26679;&#26412;&#12290;&#22312;&#30495;&#23454;&#32929;&#31080;&#25968;&#25454;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26377;&#25928;&#38477;&#20302;&#20102;&#25237;&#36164;&#39118;&#38505;&#21516;&#26102;&#20445;&#25345;&#39640;&#39044;&#26399;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32929;&#31080;&#24066;&#22330;&#65292;&#25104;&#21151;&#30340;&#25237;&#36164;&#38656;&#35201;&#22312;&#21033;&#28070;&#21644;&#39118;&#38505;&#20043;&#38388;&#21462;&#24471;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;&#26368;&#36817;&#65292;&#22312;&#37327;&#21270;&#25237;&#36164;&#20013;&#24191;&#27867;&#30740;&#31350;&#20102;&#32929;&#31080;&#25512;&#33616;&#65292;&#20197;&#20026;&#25237;&#36164;&#32773;&#36873;&#25321;&#20855;&#26377;&#26356;&#39640;&#25910;&#30410;&#29575;&#30340;&#32929;&#31080;&#12290;&#23613;&#31649;&#22312;&#33719;&#21033;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#25512;&#33616;&#26041;&#27861;&#20173;&#28982;&#22312;&#39118;&#38505;&#25511;&#21046;&#26041;&#38754;&#36739;&#24369;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#23454;&#38469;&#32929;&#31080;&#25237;&#36164;&#20013;&#38590;&#20197;&#25215;&#21463;&#30340;&#20111;&#25439;&#12290;&#20026;&#20102;&#26377;&#25928;&#38477;&#20302;&#39118;&#38505;&#65292;&#25105;&#20204;&#20174;&#23545;&#25239;&#24615;&#25200;&#21160;&#20013;&#33719;&#24471;&#21551;&#31034;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20998;&#31163;&#21464;&#20998;&#23545;&#25239;&#35757;&#32451;&#65288;SVAT&#65289;&#26694;&#26550;&#30340;&#39118;&#38505;&#24863;&#30693;&#22411;&#32929;&#31080;&#25512;&#33616;&#26041;&#27861;&#12290;&#26412;&#36136;&#19978;&#65292;SVAT&#40723;&#21169;&#27169;&#22411;&#23545;&#39118;&#38505;&#32929;&#31080;&#26679;&#26412;&#30340;&#23545;&#25239;&#24615;&#25200;&#21160;&#25935;&#24863;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#25200;&#21160;&#26469;&#22686;&#24378;&#27169;&#22411;&#30340;&#39118;&#38505;&#24847;&#35782;&#12290;&#20026;&#20102;&#29983;&#25104;&#20195;&#34920;&#24615;&#30340;&#39118;&#38505;&#25351;&#26631;&#23545;&#25239;&#26679;&#26412;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21464;&#20998;&#25200;&#21160;&#29983;&#25104;&#22120;&#26469;&#27169;&#25311;&#19981;&#21516;&#30340;&#39118;&#38505;&#22240;&#32032;&#12290;&#29305;&#21035;&#22320;&#65292;&#21464;&#20998;&#32467;&#26500;&#20351;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#25429;&#25417;&#38590;&#20197;&#26126;&#30830;&#37327;&#21270;&#21644;&#24314;&#27169;&#30340;&#21508;&#31181;&#39118;&#38505;&#22240;&#32032;&#12290;&#22312;&#30495;&#23454;&#32929;&#31080;&#25968;&#25454;&#19978;&#30340;&#32508;&#21512;&#23454;&#39564;&#34920;&#26126;&#65292;SVAT&#22312;&#38477;&#20302;&#25237;&#36164;&#39118;&#38505;&#30340;&#21516;&#26102;&#20445;&#25345;&#39640;&#39044;&#26399;&#25910;&#30410;&#19978;&#38750;&#24120;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the stock market, a successful investment requires a good balance between profits and risks. Recently, stock recommendation has been widely studied in quantitative investment to select stocks with higher return ratios for investors. Despite the success in making profits, most existing recommendation approaches are still weak in risk control, which may lead to intolerable paper losses in practical stock investing. To effectively reduce risks, we draw inspiration from adversarial perturbations and propose a novel Split Variational Adversarial Training (SVAT) framework for risk-aware stock recommendation. Essentially, SVAT encourages the model to be sensitive to adversarial perturbations of risky stock examples and enhances the model's risk awareness by learning from perturbations. To generate representative adversarial examples as risk indicators, we devise a variational perturbation generator to model diverse risk factors. Particularly, the variational architecture enables our method
&lt;/p&gt;</description></item><item><title>CLaMP&#26159;&#19968;&#31181;&#23545;&#27604;&#35821;&#35328;-&#38899;&#20048;&#39044;&#35757;&#32451;&#25216;&#26415;&#65292;&#33021;&#22815;&#23398;&#20064;&#31526;&#21495;&#38899;&#20048;&#21644;&#33258;&#28982;&#35821;&#35328;&#20043;&#38388;&#30340;&#36328;&#27169;&#24577;&#34920;&#31034;&#12290;&#36890;&#36807;&#25968;&#25454;&#22686;&#24378;&#21644;&#20998;&#22359;&#22788;&#29702;&#65292;&#23427;&#23558;&#31526;&#21495;&#38899;&#20048;&#34920;&#31034;&#25104;&#38271;&#24230;&#19981;&#21040;10&#65285;&#30340;&#24207;&#21015;&#65292;&#24182;&#20351;&#29992;&#25513;&#34109;&#38899;&#20048;&#27169;&#22411;&#39044;&#35757;&#32451;&#30446;&#26631;&#26469;&#22686;&#24378;&#38899;&#20048;&#32534;&#30721;&#22120;&#23545;&#38899;&#20048;&#19978;&#19979;&#25991;&#21644;&#32467;&#26500;&#30340;&#29702;&#35299;&#12290;&#36825;&#31181;&#25216;&#26415;&#36229;&#36234;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#23454;&#29616;&#31526;&#21495;&#38899;&#20048;&#30340;&#35821;&#20041;&#25628;&#32034;&#21644;&#38646;&#26679;&#26412;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2304.11029</link><description>&lt;p&gt;
CLaMP&#65306;&#29992;&#20110;&#36328;&#27169;&#24577;&#31526;&#21495;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#30340;&#23545;&#27604;&#35821;&#35328;-&#38899;&#20048;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic Music Information Retrieval. (arXiv:2304.11029v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11029
&lt;/p&gt;
&lt;p&gt;
CLaMP&#26159;&#19968;&#31181;&#23545;&#27604;&#35821;&#35328;-&#38899;&#20048;&#39044;&#35757;&#32451;&#25216;&#26415;&#65292;&#33021;&#22815;&#23398;&#20064;&#31526;&#21495;&#38899;&#20048;&#21644;&#33258;&#28982;&#35821;&#35328;&#20043;&#38388;&#30340;&#36328;&#27169;&#24577;&#34920;&#31034;&#12290;&#36890;&#36807;&#25968;&#25454;&#22686;&#24378;&#21644;&#20998;&#22359;&#22788;&#29702;&#65292;&#23427;&#23558;&#31526;&#21495;&#38899;&#20048;&#34920;&#31034;&#25104;&#38271;&#24230;&#19981;&#21040;10&#65285;&#30340;&#24207;&#21015;&#65292;&#24182;&#20351;&#29992;&#25513;&#34109;&#38899;&#20048;&#27169;&#22411;&#39044;&#35757;&#32451;&#30446;&#26631;&#26469;&#22686;&#24378;&#38899;&#20048;&#32534;&#30721;&#22120;&#23545;&#38899;&#20048;&#19978;&#19979;&#25991;&#21644;&#32467;&#26500;&#30340;&#29702;&#35299;&#12290;&#36825;&#31181;&#25216;&#26415;&#36229;&#36234;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#23454;&#29616;&#31526;&#21495;&#38899;&#20048;&#30340;&#35821;&#20041;&#25628;&#32034;&#21644;&#38646;&#26679;&#26412;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;CLaMP&#65306;&#23545;&#27604;&#35821;&#35328;-&#38899;&#20048;&#39044;&#35757;&#32451;&#65292;&#23427;&#20351;&#29992;&#38899;&#20048;&#32534;&#30721;&#22120;&#21644;&#25991;&#26412;&#32534;&#30721;&#22120;&#36890;&#36807;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#32852;&#21512;&#35757;&#32451;&#26469;&#23398;&#20064;&#33258;&#28982;&#35821;&#35328;&#21644;&#31526;&#21495;&#38899;&#20048;&#20043;&#38388;&#30340;&#36328;&#27169;&#24577;&#34920;&#31034;&#12290;&#20026;&#20102;&#39044;&#35757;&#32451;CLaMP&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;140&#19975;&#20010;&#38899;&#20048;-&#25991;&#26412;&#23545;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#23427;&#20351;&#29992;&#20102;&#25991;&#26412;&#38543;&#26426;&#22833;&#27963;&#26469;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#21644;&#20998;&#22359;&#22788;&#29702;&#20197;&#39640;&#25928;&#22320;&#34920;&#31034;&#38899;&#20048;&#25968;&#25454;&#65292;&#20174;&#32780;&#23558;&#24207;&#21015;&#38271;&#24230;&#32553;&#30701;&#21040;&#19981;&#21040;10&#65285;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#25513;&#34109;&#38899;&#20048;&#27169;&#22411;&#39044;&#35757;&#32451;&#30446;&#26631;&#65292;&#20197;&#22686;&#24378;&#38899;&#20048;&#32534;&#30721;&#22120;&#23545;&#38899;&#20048;&#19978;&#19979;&#25991;&#21644;&#32467;&#26500;&#30340;&#29702;&#35299;&#12290;CLaMP&#38598;&#25104;&#20102;&#25991;&#26412;&#20449;&#24687;&#65292;&#20197;&#23454;&#29616;&#31526;&#21495;&#38899;&#20048;&#30340;&#35821;&#20041;&#25628;&#32034;&#21644;&#38646;&#26679;&#26412;&#20998;&#31867;&#65292;&#36229;&#36234;&#20102;&#20808;&#21069;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#20026;&#25903;&#25345;&#35821;&#20041;&#25628;&#32034;&#21644;&#38899;&#20048;&#20998;&#31867;&#30340;&#35780;&#20272;&#65292;&#25105;&#20204;&#20844;&#24320;&#21457;&#24067;&#20102;WikiMusicText&#65288;WikiMT&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#21253;&#21547;1010&#20010;ABC&#31526;&#21495;&#35889;&#30340;&#25968;&#25454;&#38598;&#65292;&#27599;&#20010;&#35889;&#37117;&#38468;&#24102;&#26377;&#26631;&#39064;&#12289;&#33402;&#26415;&#23478;&#12289;&#27969;&#27966;&#21644;&#25551;&#36848;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce CLaMP: Contrastive Language-Music Pre-training, which learns cross-modal representations between natural language and symbolic music using a music encoder and a text encoder trained jointly with a contrastive loss. To pre-train CLaMP, we collected a large dataset of 1.4 million music-text pairs. It employed text dropout as a data augmentation technique and bar patching to efficiently represent music data which reduces sequence length to less than 10%. In addition, we developed a masked music model pre-training objective to enhance the music encoder's comprehension of musical context and structure. CLaMP integrates textual information to enable semantic search and zero-shot classification for symbolic music, surpassing the capabilities of previous models. To support the evaluation of semantic search and music classification, we publicly release WikiMusicText (WikiMT), a dataset of 1010 lead sheets in ABC notation, each accompanied by a title, artist, genre, and description.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#22312;MIMIC-III&#21644;MIMIC-IV&#19978;&#36827;&#34892;&#33258;&#21160;&#21270;&#21307;&#30103;&#32534;&#30721;&#30340;&#26368;&#26032;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#21457;&#29616;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#23616;&#38480;&#24615;&#21644;&#19981;&#36275;&#20043;&#22788;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#35780;&#20272;&#31995;&#32479;&#24615;&#33021;&#65292;&#24182;&#20844;&#24320;&#20102;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.10909</link><description>&lt;p&gt;
MIMIC-III&#21644;MIMIC-IV&#19978;&#30340;&#33258;&#21160;&#21270;&#21307;&#30103;&#32534;&#30721;&#65306;&#19968;&#39033;&#20851;&#38190;&#22238;&#39038;&#21644;&#21487;&#22797;&#21046;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study. (arXiv:2304.10909v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10909
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#22312;MIMIC-III&#21644;MIMIC-IV&#19978;&#36827;&#34892;&#33258;&#21160;&#21270;&#21307;&#30103;&#32534;&#30721;&#30340;&#26368;&#26032;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#21457;&#29616;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#23616;&#38480;&#24615;&#21644;&#19981;&#36275;&#20043;&#22788;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#35780;&#20272;&#31995;&#32479;&#24615;&#33021;&#65292;&#24182;&#20844;&#24320;&#20102;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#30103;&#32534;&#30721;&#26159;&#23558;&#21307;&#23398;&#20195;&#30721;&#20998;&#37197;&#32473;&#20020;&#24202;&#33258;&#30001;&#25991;&#26723;&#30340;&#20219;&#21153;&#12290;&#21307;&#30103;&#19987;&#19994;&#20154;&#22763;&#25163;&#21160;&#20998;&#37197;&#36825;&#20123;&#20195;&#30721;&#20197;&#36319;&#36394;&#24739;&#32773;&#30340;&#35786;&#26029;&#21644;&#27835;&#30103;&#12290;&#33258;&#21160;&#21270;&#21307;&#30103;&#32534;&#30721;&#21487;&#20197;&#26497;&#22823;&#22320;&#20943;&#36731;&#36825;&#31181;&#34892;&#25919;&#36127;&#25285;&#12290;&#26412;&#25991;&#37325;&#29616;&#12289;&#27604;&#36739;&#21644;&#20998;&#26512;&#20102;&#26368;&#20808;&#36827;&#30340;&#33258;&#21160;&#21270;&#21307;&#30103;&#32534;&#30721;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#25105;&#20204;&#26174;&#31034;&#20986;&#22810;&#20010;&#27169;&#22411;&#34920;&#29616;&#19981;&#20339;&#65292;&#21407;&#22240;&#26159;&#37197;&#32622;&#24369;&#12289;&#35757;&#32451;-&#27979;&#35797;&#25286;&#20998;&#26679;&#26412;&#19981;&#36275;&#20197;&#21450;&#35780;&#20272;&#19981;&#20805;&#20998;&#12290;&#22312;&#20197;&#24448;&#30340;&#24037;&#20316;&#20013;&#65292;&#23439;&#24179;&#22343;F1&#20998;&#25968;&#34987;&#35745;&#31639;&#20986;&#20122;&#20248;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#20462;&#27491;&#20351;&#20854;&#32763;&#20493;&#12290;&#25105;&#20204;&#37319;&#29992;&#20998;&#23618;&#25277;&#26679;&#21644;&#30456;&#21516;&#30340;&#23454;&#39564;&#35774;&#32622;&#36827;&#34892;&#20102;&#20462;&#35746;&#30340;&#27169;&#22411;&#27604;&#36739;&#65292;&#21253;&#25324;&#36229;&#21442;&#25968;&#21644;&#20915;&#31574;&#36793;&#30028;&#35843;&#25972;&#12290;&#25105;&#20204;&#20998;&#26512;&#39044;&#27979;&#35823;&#24046;&#26469;&#39564;&#35777;&#21644;&#35777;&#20266;&#20197;&#21069;&#30340;&#24037;&#20316;&#20551;&#35774;&#12290;&#20998;&#26512;&#35777;&#23454;&#65292;&#25152;&#26377;&#27169;&#22411;&#37117;&#38590;&#20197;&#22788;&#29702;&#31232;&#26377;&#30340;&#20195;&#30721;&#65292;&#32780;&#38271;&#25991;&#26723;&#20165;&#23545;&#32467;&#26524;&#26377;&#24494;&#19981;&#36275;&#36947;&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#34892;&#30149;&#23398;&#37319;&#26679;&#30340;&#25913;&#36827;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26356;&#22909;&#22320;&#35780;&#20272;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#24182;&#20844;&#24320;&#20102;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Medical coding is the task of assigning medical codes to clinical free-text documentation. Healthcare professionals manually assign such codes to track patient diagnoses and treatments. Automated medical coding can considerably alleviate this administrative burden. In this paper, we reproduce, compare, and analyze state-of-the-art automated medical coding machine learning models. We show that several models underperform due to weak configurations, poorly sampled train-test splits, and insufficient evaluation. In previous work, the macro F1 score has been calculated sub-optimally, and our correction doubles it. We contribute a revised model comparison using stratified sampling and identical experimental setups, including hyperparameters and decision boundary tuning. We analyze prediction errors to validate and falsify assumptions of previous works. The analysis confirms that all models struggle with rare codes, while long documents only have a negligible impact. Finally, we present the 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20351;&#29992;&#35821;&#38899;&#35843;&#21046;&#36827;&#34892;&#20247;&#21253;&#30456;&#20851;&#24615;&#35780;&#20272;&#65292;&#21457;&#29616;&#35780;&#20272;&#21592;&#22312;&#25991;&#26412;&#21644;&#35821;&#38899;&#27169;&#24577;&#19979;&#30340;&#21028;&#26029;&#20934;&#30830;&#24230;&#30456;&#21516;&#65292;&#20294;&#38543;&#30528;&#25991;&#26723;&#38271;&#24230;&#30340;&#22686;&#21152;&#65292;&#22312;&#35821;&#38899;&#26500;&#36896;&#19979;&#20570;&#20986;&#30456;&#20851;&#24615;&#21028;&#26029;&#25152;&#38656;&#30340;&#26102;&#38388;&#26174;&#30528;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2304.10881</link><description>&lt;p&gt;
&#21548;&#25105;&#35828;&#65306;&#20351;&#29992;&#35821;&#38899;&#35843;&#21046;&#36827;&#34892;&#20247;&#21253;&#30456;&#20851;&#24615;&#35780;&#20272;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Hear Me Out: A Study on the Use of the Voice Modality for Crowdsourced Relevance Assessments. (arXiv:2304.10881v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10881
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20351;&#29992;&#35821;&#38899;&#35843;&#21046;&#36827;&#34892;&#20247;&#21253;&#30456;&#20851;&#24615;&#35780;&#20272;&#65292;&#21457;&#29616;&#35780;&#20272;&#21592;&#22312;&#25991;&#26412;&#21644;&#35821;&#38899;&#27169;&#24577;&#19979;&#30340;&#21028;&#26029;&#20934;&#30830;&#24230;&#30456;&#21516;&#65292;&#20294;&#38543;&#30528;&#25991;&#26723;&#38271;&#24230;&#30340;&#22686;&#21152;&#65292;&#22312;&#35821;&#38899;&#26500;&#36896;&#19979;&#20570;&#20986;&#30456;&#20851;&#24615;&#21028;&#26029;&#25152;&#38656;&#30340;&#26102;&#38388;&#26174;&#30528;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26500;&#24314;&#20449;&#24687;&#26816;&#32034;&#27979;&#35797;&#38598;&#21512;&#26102;&#65292;&#20154;&#24037;&#35780;&#20272;&#21592;&#65288;&#29616;&#20170;&#36890;&#24120;&#26159;&#20247;&#21253;&#24037;&#20154;&#65289;&#21019;&#24314;&#30456;&#20851;&#24615;&#35780;&#20272;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#19968;&#27493;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#35843;&#26597;&#20102;&#35780;&#20272;&#21592;&#30340;&#36136;&#37327;&#21644;&#34892;&#20026;&#65292;&#20294;&#24182;&#27809;&#26377;&#30740;&#31350;&#25991;&#26723;&#30340;&#21576;&#29616;&#27169;&#24335;&#23545;&#35780;&#20272;&#21592;&#25928;&#29575;&#21644;&#26377;&#25928;&#24615;&#30340;&#24433;&#21709;&#12290;&#37492;&#20110;&#35821;&#38899;&#30028;&#38754;&#30340;&#26222;&#21450;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#35780;&#20272;&#21592;&#26159;&#21542;&#33021;&#22815;&#36890;&#36807;&#35821;&#38899;&#30028;&#38754;&#21028;&#26029;&#25991;&#26412;&#25991;&#26723;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#22312;&#20247;&#21253;&#24179;&#21488;&#19978;&#23545; TREC &#28145;&#24230;&#23398;&#20064;&#35821;&#26009;&#24211;&#20013;&#30340;&#30701;&#25991;&#26723;&#21644;&#38271;&#25991;&#26723;&#36827;&#34892;&#20102;&#29992;&#25143;&#30740;&#31350; (n=49)&#65292;&#21521;&#21442;&#19982;&#32773;&#23637;&#31034;&#20102;&#25991;&#26412;&#21644;&#35821;&#38899;&#27169;&#24577;&#12290;&#25105;&#20204;&#21457;&#29616;&#65306;(i)&#21442;&#19982;&#32773;&#22312;&#25991;&#26412;&#21644;&#35821;&#38899;&#27169;&#24577;&#19979;&#30340;&#21028;&#26029;&#20934;&#30830;&#24230;&#30456;&#21516;&#65307;(ii)&#38543;&#30528;&#25991;&#26723;&#38271;&#24230;&#30340;&#22686;&#21152;&#65292;&#21442;&#19982;&#32773;&#22312;&#35821;&#38899;&#26500;&#36896;&#19979;&#20570;&#20986;&#30456;&#20851;&#24615;&#21028;&#26029;&#25152;&#38656;&#30340;&#26102;&#38388;&#26174;&#30528;&#22686;&#21152;&#65288;&#23545;&#20110;&#38271;&#24230;&gt;120&#20010;&#21333;&#35789;&#30340;&#25991;&#26723;&#65292;&#25152;&#38656;&#26102;&#38388;&#20960;&#20046;&#26159;&#25991;&#26412;&#38047;&#30340;&#20004;&#20493;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The creation of relevance assessments by human assessors (often nowadays crowdworkers) is a vital step when building IR test collections. Prior works have investigated assessor quality &amp; behaviour, though into the impact of a document's presentation modality on assessor efficiency and effectiveness. Given the rise of voice-based interfaces, we investigate whether it is feasible for assessors to judge the relevance of text documents via a voice-based interface. We ran a user study (n = 49) on a crowdsourcing platform where participants judged the relevance of short and long documents sampled from the TREC Deep Learning corpus-presented to them either in the text or voice modality. We found that: (i) participants are equally accurate in their judgements across both the text and voice modality; (ii) with increased document length it takes participants significantly longer (for documents of length &gt; 120 words it takes almost twice as much time) to make relevance judgements in the voice con
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#29305;&#24449;&#20132;&#20114;&#23398;&#20064;&#27169;&#22411;EulerNet&#65292;&#23427;&#37319;&#29992;&#27431;&#25289;&#20844;&#24335;&#23558;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#26144;&#23556;&#21040;&#22797;&#26434;&#21521;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#25928;&#29575;&#30340;&#21516;&#26102;&#25552;&#39640;&#27169;&#22411;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.10711</link><description>&lt;p&gt;
EulerNet: &#22522;&#20110;&#27431;&#25289;&#20844;&#24335;&#30340;&#22797;&#26434;&#21521;&#37327;&#31354;&#38388;&#29305;&#24449;&#20132;&#20114;&#23398;&#20064;&#20197;&#23454;&#29616;&#28857;&#20987;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
EulerNet: Adaptive Feature Interaction Learning via Euler's Formula for CTR Prediction. (arXiv:2304.10711v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#29305;&#24449;&#20132;&#20114;&#23398;&#20064;&#27169;&#22411;EulerNet&#65292;&#23427;&#37319;&#29992;&#27431;&#25289;&#20844;&#24335;&#23558;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#26144;&#23556;&#21040;&#22797;&#26434;&#21521;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#25928;&#29575;&#30340;&#21516;&#26102;&#25552;&#39640;&#27169;&#22411;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28857;&#20987;&#29575;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#23398;&#20064;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#26159;&#38750;&#24120;&#20851;&#38190;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#22312;&#32447;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#20013;&#65292;&#30001;&#20110;&#28023;&#37327;&#29305;&#24449;&#30340;&#23384;&#22312;&#65292;&#35745;&#31639;&#39640;&#38454;&#29305;&#24449;&#20132;&#20114;&#38750;&#24120;&#32791;&#26102;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#25163;&#21160;&#35774;&#35745;&#26368;&#22823;&#38454;&#25968;&#65292;&#24182;&#20174;&#20013;&#36807;&#28388;&#20986;&#26080;&#29992;&#30340;&#20132;&#20114;&#12290;&#23613;&#31649;&#23427;&#20204;&#20943;&#23569;&#20102;&#39640;&#38454;&#29305;&#24449;&#32452;&#21512;&#30340;&#25351;&#25968;&#32423;&#22686;&#38271;&#25152;&#24341;&#36215;&#30340;&#39640;&#35745;&#31639;&#25104;&#26412;&#65292;&#20294;&#30001;&#20110;&#21463;&#21040;&#21463;&#38480;&#30340;&#29305;&#24449;&#38454;&#25968;&#30340;&#27425;&#20248;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#23427;&#20204;&#20173;&#28982;&#20250;&#21463;&#21040;&#27169;&#22411;&#33021;&#21147;&#19979;&#38477;&#30340;&#24433;&#21709;&#12290;&#20445;&#25345;&#27169;&#22411;&#33021;&#21147;&#24182;&#21516;&#26102;&#20445;&#25345;&#20854;&#25928;&#29575;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#19968;&#20010;&#25216;&#26415;&#25361;&#25112;&#65292;&#35813;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#35299;&#20915;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#29305;&#24449;&#20132;&#20114;&#23398;&#20064;&#27169;&#22411;&#65292;&#21517;&#20026;EulerNet&#65292;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#26681;&#25454;&#27431;&#25289;&#20844;&#24335;&#36827;&#34892;&#31354;&#38388;&#26144;&#23556;&#22312;&#22797;&#26434;&#21521;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#29305;&#24449;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning effective high-order feature interactions is very crucial in the CTR prediction task. However, it is very time-consuming to calculate high-order feature interactions with massive features in online e-commerce platforms. Most existing methods manually design a maximal order and further filter out the useless interactions from them. Although they reduce the high computational costs caused by the exponential growth of high-order feature combinations, they still suffer from the degradation of model capability due to the suboptimal learning of the restricted feature orders. The solution to maintain the model capability and meanwhile keep it efficient is a technical challenge, which has not been adequately addressed. To address this issue, we propose an adaptive feature interaction learning model, named as EulerNet, in which the feature interactions are learned in a complex vector space by conducting space mapping according to Euler's formula. EulerNet converts the exponential power
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31532;&#19968;&#21407;&#29702;&#30340;&#22810;&#30446;&#26631;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#32452;&#25351;&#21335;&#65292;&#26088;&#22312;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#22810;&#30446;&#26631;&#35780;&#20272;&#20013;&#30340;&#24179;&#34913;&#22810;&#20010;&#32489;&#25928;&#25351;&#26631;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2304.10621</link><description>&lt;p&gt;
E Pluribus Unum&#65306;&#20851;&#20110;&#25512;&#33616;&#31995;&#32479;&#22810;&#30446;&#26631;&#35780;&#20272;&#30340;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
E Pluribus Unum: Guidelines on Multi-Objective Evaluation of Recommender Systems. (arXiv:2304.10621v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10621
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31532;&#19968;&#21407;&#29702;&#30340;&#22810;&#30446;&#26631;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#32452;&#25351;&#21335;&#65292;&#26088;&#22312;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#22810;&#30446;&#26631;&#35780;&#20272;&#20013;&#30340;&#24179;&#34913;&#22810;&#20010;&#32489;&#25928;&#25351;&#26631;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#25512;&#33616;&#31995;&#32479;&#30340;&#35780;&#20272;&#20027;&#35201;&#36824;&#26159;&#20197;&#20934;&#30830;&#24615;&#20026;&#20027;&#65292;&#20854;&#20182;&#26041;&#38754;&#30340;&#22240;&#32032;&#65292;&#27604;&#22914;&#22810;&#26679;&#24615;&#12289;&#38271;&#26399;&#29992;&#25143;&#30041;&#23384;&#21644;&#20844;&#24179;&#24615;&#65292;&#24448;&#24448;&#34987;&#24573;&#30053;&#12290;&#32780;&#19988;&#65292;&#21327;&#35843;&#22810;&#20010;&#32489;&#25928;&#25351;&#26631;&#26412;&#36136;&#19978;&#26159;&#19981;&#30830;&#23450;&#30340;&#65292;&#36825;&#32473;&#23547;&#27714;&#20840;&#38754;&#35780;&#20272;&#25512;&#33616;&#31995;&#32479;&#30340;&#20154;&#36896;&#25104;&#20102;&#38590;&#39064;&#12290;EvalRS 2022&#26159;&#31532;&#19968;&#20010;&#23454;&#36341;&#24615;&#30340;&#25968;&#25454;&#25361;&#25112;&#27963;&#21160;&#65292;&#22260;&#32469;&#22810;&#30446;&#26631;&#35780;&#20272;&#32780;&#35774;&#35745;&#65292;&#25552;&#20379;&#20102;&#35768;&#22810;&#23545;&#20110;&#24179;&#34913;&#22810;&#20010;&#32489;&#25928;&#25351;&#26631;&#30340;&#35201;&#27714;&#21644;&#25361;&#25112;&#30340;&#27934;&#35265;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;EvalRS 2022&#65292;&#24182;&#38416;&#36848;&#20102;&#37325;&#35201;&#30340;&#29702;&#35299;&#65292;&#21046;&#23450;&#20102;&#19968;&#31181;&#22522;&#20110;&#31532;&#19968;&#21407;&#29702;&#30340;&#22810;&#30446;&#26631;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#24182;&#27010;&#36848;&#20102;&#36827;&#34892;&#22810;&#30446;&#26631;&#35780;&#20272;&#25361;&#25112;&#30340;&#19968;&#32452;&#25351;&#21335;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#36866;&#29992;&#24615;&#65292;&#33021;&#22815;&#35299;&#20915;&#23454;&#38469;&#37096;&#32626;&#20013;&#23545;&#31454;&#20105;&#27169;&#22411;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender Systems today are still mostly evaluated in terms of accuracy, with other aspects beyond the immediate relevance of recommendations, such as diversity, long-term user retention and fairness, often taking a back seat. Moreover, reconciling multiple performance perspectives is by definition indeterminate, presenting a stumbling block to those in the pursuit of rounded evaluation of Recommender Systems. EvalRS 2022 -- a data challenge designed around Multi-Objective Evaluation -- was a first practical endeavour, providing many insights into the requirements and challenges of balancing multiple objectives in evaluation. In this work, we reflect on EvalRS 2022 and expound upon crucial learnings to formulate a first-principles approach toward Multi-Objective model selection, and outline a set of guidelines for carrying out a Multi-Objective Evaluation challenge, with potential applicability to the problem of rounded evaluation of competing models in real-world deployments.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#21644;&#23454;&#26045;&#20102;&#19968;&#20010;&#21517;&#20026;MATURE-HEALTH&#30340;&#20581;&#24247;&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#39044;&#27979;&#30005;&#35299;&#36136;&#19981;&#24179;&#34913;&#24182;&#25512;&#33616;&#33829;&#20859;&#24179;&#34913;&#30340;&#39135;&#29289;&#65292;&#20174;&#32780;&#22686;&#21152;&#26089;&#26399;&#26816;&#27979;&#30142;&#30149;&#30340;&#26426;&#20250;&#24182;&#38450;&#27490;&#20581;&#24247;&#36827;&#19968;&#27493;&#24694;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.09099</link><description>&lt;p&gt;
MATURE-HEALTH: MAndatory FeaTURE&#36873;&#25321;&#30340;&#20581;&#24247;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices. (arXiv:2304.09099v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09099
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#21644;&#23454;&#26045;&#20102;&#19968;&#20010;&#21517;&#20026;MATURE-HEALTH&#30340;&#20581;&#24247;&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#39044;&#27979;&#30005;&#35299;&#36136;&#19981;&#24179;&#34913;&#24182;&#25512;&#33616;&#33829;&#20859;&#24179;&#34913;&#30340;&#39135;&#29289;&#65292;&#20174;&#32780;&#22686;&#21152;&#26089;&#26399;&#26816;&#27979;&#30142;&#30149;&#30340;&#26426;&#20250;&#24182;&#38450;&#27490;&#20581;&#24247;&#36827;&#19968;&#27493;&#24694;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#34913;&#30005;&#35299;&#36136;&#23545;&#20110;&#20154;&#20307;&#22120;&#23448;&#30340;&#36866;&#24403;&#21151;&#33021;&#33267;&#20851;&#37325;&#35201;&#21644;&#24517;&#19981;&#21487;&#23569;&#65292;&#22240;&#20026;&#30005;&#35299;&#36136;&#22833;&#34913;&#21487;&#33021;&#26159;&#28508;&#22312;&#30149;&#29702;&#29983;&#29702;&#23398;&#21457;&#23637;&#30340;&#25351;&#31034;&#12290;&#39640;&#25928;&#30417;&#27979;&#30005;&#35299;&#36136;&#22833;&#34913;&#19981;&#20165;&#21487;&#20197;&#22686;&#21152;&#30142;&#30149;&#26089;&#26399;&#26816;&#27979;&#30340;&#26426;&#20250;&#65292;&#32780;&#19988;&#21487;&#20197;&#36890;&#36807;&#20005;&#26684;&#36981;&#24490;&#33829;&#20859;&#25511;&#21046;&#39278;&#39135;&#20197;&#24179;&#34913;&#30005;&#35299;&#36136;&#20174;&#32780;&#38450;&#27490;&#20581;&#24247;&#36827;&#19968;&#27493;&#24694;&#21270;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#24182;&#23454;&#26045;&#20102;&#19968;&#20010;&#25512;&#33616;&#31995;&#32479;MATURE Health&#65292;&#35813;&#31995;&#32479;&#39044;&#27979;&#34880;&#28082;&#20013;&#24517;&#38656;&#30005;&#35299;&#36136;&#21644;&#20854;&#20182;&#29289;&#36136;&#30340;&#19981;&#24179;&#34913;&#65292;&#28982;&#21518;&#25512;&#33616;&#21547;&#26377;&#24179;&#34913;&#33829;&#20859;&#30340;&#39135;&#29289;&#65292;&#20197;&#36991;&#20813;&#30005;&#35299;&#36136;&#19981;&#24179;&#34913;&#30340;&#21457;&#29983;&#12290;&#35813;&#27169;&#22411;&#32771;&#34385;&#21040;&#29992;&#25143;&#26368;&#36817;&#30340;&#23454;&#39564;&#23460;&#32467;&#26524;&#21644;&#27599;&#26085;&#39135;&#29289;&#25668;&#20837;&#37327;&#26469;&#39044;&#27979;&#30005;&#35299;&#36136;&#19981;&#24179;&#34913;&#12290;MATURE Health&#20381;&#36182;&#20110;MATURE Food&#31639;&#27861;&#25512;&#33616;&#39135;&#29289;&#65292;&#21518;&#32773;&#20165;&#25512;&#33616;&#37027;&#20123;
&lt;/p&gt;
&lt;p&gt;
Balancing electrolytes is utmost important and essential for appropriate functioning of organs in human body as electrolytes imbalance can be an indication of the development of underlying pathophysiology. Efficient monitoring of electrolytes imbalance not only can increase the chances of early detection of disease, but also prevents the further deterioration of the health by strictly following nutrient controlled diet for balancing the electrolytes post disease detection. In this research, a recommender system MATURE Health is proposed and implemented, which predicts the imbalance of mandatory electrolytes and other substances presented in blood and recommends the food items with the balanced nutrients to avoid occurrence of the electrolytes imbalance. The proposed model takes user most recent laboratory results and daily food intake into account to predict the electrolytes imbalance. MATURE Health relies on MATURE Food algorithm to recommend food items as latter recommends only those
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#39640;&#36136;&#37327;&#39184;&#21381;&#35780;&#35770;&#29983;&#25104;&#34394;&#20551;&#35780;&#35770;&#24182;&#24494;&#35843;GPT&#36755;&#20986;&#26816;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#39044;&#27979;&#34394;&#20551;&#35780;&#35770;&#30340;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#39044;&#27979;&#38750;&#31934;&#33521;&#35780;&#35770;&#30340;&#27169;&#22411;&#65292;&#24182;&#22312;&#20960;&#20010;&#32500;&#24230;&#19978;&#23545;&#36825;&#20123;&#35780;&#35770;&#36827;&#34892;&#20998;&#26512;&#65292;&#27492;&#31867;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#26159;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#38754;&#20020;&#30340;&#25345;&#32493;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2302.07731</link><description>&lt;p&gt;
AI&#23545;&#25239;AI&#65306;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#25171;&#20987;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#39184;&#21381;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#39640;&#36136;&#37327;&#39184;&#21381;&#35780;&#35770;&#29983;&#25104;&#34394;&#20551;&#35780;&#35770;&#24182;&#24494;&#35843;GPT&#36755;&#20986;&#26816;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#39044;&#27979;&#34394;&#20551;&#35780;&#35770;&#30340;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#39044;&#27979;&#38750;&#31934;&#33521;&#35780;&#35770;&#30340;&#27169;&#22411;&#65292;&#24182;&#22312;&#20960;&#20010;&#32500;&#24230;&#19978;&#23545;&#36825;&#20123;&#35780;&#35770;&#36827;&#34892;&#20998;&#26512;&#65292;&#27492;&#31867;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#26159;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#38754;&#20020;&#30340;&#25345;&#32493;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;GPT&#65289;&#30340;&#21457;&#23637;&#20351;&#24471;&#20197;&#26356;&#20302;&#30340;&#25104;&#26412;&#21046;&#36896;&#20986;&#38590;&#20197;&#21306;&#20998;&#30340;&#34394;&#20551;&#39038;&#23458;&#35780;&#35770;&#65292;&#20174;&#32780;&#23545;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#26816;&#27979;&#36825;&#20123;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#36896;&#25104;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;Yelp&#39564;&#35777;&#30340;&#39640;&#36136;&#37327;&#30340;&#31934;&#33521;&#39184;&#21381;&#35780;&#35770;&#26469;&#29983;&#25104;OpenAI GPT&#35780;&#35770;&#29983;&#25104;&#22120;&#30340;&#34394;&#20551;&#35780;&#35770;&#65292;&#24182;&#26368;&#32456;&#24494;&#35843;GPT&#36755;&#20986;&#26816;&#27979;&#22120;&#26469;&#39044;&#27979;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#34394;&#20551;&#35780;&#35770;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#27169;&#22411;&#24212;&#29992;&#20110;&#39044;&#27979;&#38750;&#31934;&#33521;&#35780;&#35770;&#65292;&#24182;&#22312;&#20960;&#20010;&#32500;&#24230;&#65288;&#22914;&#35780;&#35770;&#12289;&#29992;&#25143;&#21644;&#39184;&#21381;&#29305;&#24449;&#20197;&#21450;&#20889;&#20316;&#39118;&#26684;&#65289;&#19978;&#35782;&#21035;&#27169;&#24335;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#27491;&#22312;&#19981;&#26029;&#38754;&#20020;&#26426;&#22120;&#29983;&#25104;&#30340;&#34394;&#20551;&#35780;&#35770;&#30340;&#25361;&#25112;&#65292;&#23613;&#31649;&#20182;&#20204;&#21487;&#33021;&#23454;&#26045;&#26816;&#27979;&#31995;&#32479;&#20197;&#36807;&#28388;&#20986;&#21487;&#30097;&#30340;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in generative models such as GPT may be used to fabricate indistinguishable fake customer reviews at a much lower cost, thus posing challenges for social media platforms to detect these machine-generated fake reviews. We propose to leverage the high-quality elite restaurant reviews verified by Yelp to generate fake reviews from the OpenAI GPT review creator and ultimately fine-tune a GPT output detector to predict fake reviews that significantly outperform existing solutions. We further apply the model to predict non-elite reviews and identify the patterns across several dimensions, such as review, user and restaurant characteristics, and writing style. We show that social media platforms are continuously challenged by machine-generated fake reviews, although they may implement detection systems to filter out suspicious reviews.
&lt;/p&gt;</description></item></channel></rss>