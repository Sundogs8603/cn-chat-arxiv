<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#27979;&#26032;&#20986;&#29616;&#30340;&#32534;&#30721;&#24694;&#24847;&#26415;&#35821;&#65292;&#20026;&#26497;&#31471;&#31038;&#20132;&#23186;&#20307;&#20013;&#30340;&#21453;&#29369;&#22826;&#24694;&#24847;&#35328;&#35770;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.10841</link><description>&lt;p&gt;
&#20351;&#29992;LLMs&#21457;&#29616;&#26497;&#31471;&#31038;&#20132;&#23186;&#20307;&#20013;&#30340;&#32534;&#30721;&#21453;&#29369;&#22826;&#24694;&#24847;&#35328;&#35770;&#30340;&#20986;&#29616;
&lt;/p&gt;
&lt;p&gt;
Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media. (arXiv:2401.10841v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10841
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#27979;&#26032;&#20986;&#29616;&#30340;&#32534;&#30721;&#24694;&#24847;&#26415;&#35821;&#65292;&#20026;&#26497;&#31471;&#31038;&#20132;&#23186;&#20307;&#20013;&#30340;&#21453;&#29369;&#22826;&#24694;&#24847;&#35328;&#35770;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#20167;&#24680;&#35328;&#35770;&#30340;&#34067;&#24310;&#32473;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#24102;&#26469;&#20102;&#19968;&#20010;&#38590;&#39064;&#12290;&#19968;&#20010;&#29305;&#27530;&#30340;&#25361;&#25112;&#19982;&#20351;&#29992;&#32534;&#30721;&#35821;&#35328;&#30340;&#32676;&#20307;&#26377;&#20851;&#65292;&#36825;&#20123;&#32676;&#20307;&#26082;&#24819;&#20026;&#20854;&#29992;&#25143;&#21019;&#36896;&#24402;&#23646;&#24863;&#65292;&#21448;&#24819;&#22238;&#36991;&#26816;&#27979;&#12290;&#32534;&#30721;&#35821;&#35328;&#21457;&#23637;&#36805;&#36895;&#65292;&#24182;&#19988;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#20351;&#29992;&#26041;&#24335;&#19981;&#21516;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#27979;&#26032;&#20986;&#29616;&#30340;&#32534;&#30721;&#24694;&#24847;&#26415;&#35821;&#30340;&#26041;&#27861;&#35770;&#12290;&#35813;&#26041;&#27861;&#22312;&#22312;&#32447;&#21453;&#29369;&#22826;&#35328;&#35770;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#20174;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#25235;&#21462;&#30340;&#24086;&#23376;&#65292;&#36890;&#24120;&#26159;&#26497;&#31471;&#20027;&#20041;&#29992;&#25143;&#20351;&#29992;&#30340;&#12290;&#24086;&#23376;&#26159;&#20351;&#29992;&#19982;&#20197;&#21069;&#24050;&#30693;&#30340;&#38024;&#23545;&#29369;&#22826;&#20154;&#30340;&#20167;&#24680;&#35328;&#35770;&#30456;&#20851;&#30340;&#31181;&#23376;&#34920;&#36798;&#24335;&#36827;&#34892;&#25235;&#21462;&#30340;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#36890;&#36807;&#35782;&#21035;&#27599;&#20010;&#24086;&#23376;&#26368;&#20855;&#20195;&#34920;&#24615;&#30340;&#34920;&#36798;&#24335;&#65292;&#24182;&#35745;&#31639;&#23427;&#20204;&#22312;&#25972;&#20010;&#35821;&#26009;&#24211;&#20013;&#30340;&#39057;&#29575;&#12290;&#36807;&#28388;&#25481;&#35821;&#27861;&#19981;&#19968;&#33268;&#30340;&#34920;&#36798;&#24335;&#21644;&#20043;&#21069;&#36935;&#21040;&#36807;&#30340;&#34920;&#36798;&#24335;&#65292;&#20197;&#20415;&#20851;&#27880;&#26032;&#20986;&#29616;&#30340;&#33391;&#22909;&#24418;&#24335;&#30340;&#26415;&#35821;&#12290;&#28982;&#21518;&#36827;&#34892;&#20102;&#35821;&#20041;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online hate speech proliferation has created a difficult problem for social media platforms. A particular challenge relates to the use of coded language by groups interested in both creating a sense of belonging for its users and evading detection. Coded language evolves quickly and its use varies over time. This paper proposes a methodology for detecting emerging coded hate-laden terminology. The methodology is tested in the context of online antisemitic discourse. The approach considers posts scraped from social media platforms, often used by extremist users. The posts are scraped using seed expressions related to previously known discourse of hatred towards Jews. The method begins by identifying the expressions most representative of each post and calculating their frequency in the whole corpus. It filters out grammatically incoherent expressions as well as previously encountered ones so as to focus on emergent well-formed terminology. This is followed by an assessment of semantic s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20020;&#24202;&#25991;&#26723;&#21160;&#24577;&#38382;&#31572;&#30340;&#33258;&#28982;&#35821;&#35328;&#25509;&#21475;&#12290;&#36890;&#36807;Langchain&#21644;Transformer-based LLMs&#39537;&#21160;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#29992;&#25143;&#21487;&#20197;&#29992;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#20020;&#24202;&#31508;&#35760;&#24182;&#33719;&#24471;&#30456;&#20851;&#31572;&#26696;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;Wizard Vicuna&#20855;&#26377;&#20986;&#33394;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#35745;&#31639;&#35201;&#27714;&#36739;&#39640;&#12290;&#27169;&#22411;&#20248;&#21270;&#26041;&#26696;&#25552;&#39640;&#20102;&#32422;48&#20493;&#30340;&#24310;&#36831;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#20135;&#29983;&#24187;&#35937;&#21644;&#22810;&#26679;&#21270;&#21307;&#30103;&#26696;&#20363;&#35780;&#20272;&#30340;&#38480;&#21046;&#20173;&#28982;&#23384;&#22312;&#12290;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#23545;&#20110;&#21457;&#25496;&#20020;&#24202;&#31508;&#35760;&#30340;&#20215;&#20540;&#21644;&#25512;&#36827;&#22522;&#20110;AI&#30340;&#20020;&#24202;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2401.10733</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20020;&#24202;&#25991;&#26723;&#30340;&#21160;&#24577;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
Dynamic Q&amp;A of Clinical Documents with Large Language Models. (arXiv:2401.10733v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20020;&#24202;&#25991;&#26723;&#21160;&#24577;&#38382;&#31572;&#30340;&#33258;&#28982;&#35821;&#35328;&#25509;&#21475;&#12290;&#36890;&#36807;Langchain&#21644;Transformer-based LLMs&#39537;&#21160;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#29992;&#25143;&#21487;&#20197;&#29992;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#20020;&#24202;&#31508;&#35760;&#24182;&#33719;&#24471;&#30456;&#20851;&#31572;&#26696;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;Wizard Vicuna&#20855;&#26377;&#20986;&#33394;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#35745;&#31639;&#35201;&#27714;&#36739;&#39640;&#12290;&#27169;&#22411;&#20248;&#21270;&#26041;&#26696;&#25552;&#39640;&#20102;&#32422;48&#20493;&#30340;&#24310;&#36831;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#20135;&#29983;&#24187;&#35937;&#21644;&#22810;&#26679;&#21270;&#21307;&#30103;&#26696;&#20363;&#35780;&#20272;&#30340;&#38480;&#21046;&#20173;&#28982;&#23384;&#22312;&#12290;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#23545;&#20110;&#21457;&#25496;&#20020;&#24202;&#31508;&#35760;&#30340;&#20215;&#20540;&#21644;&#25512;&#36827;&#22522;&#20110;AI&#30340;&#20020;&#24202;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20013;&#25910;&#24405;&#20102;&#20020;&#24202;&#31508;&#35760;&#20013;&#30340;&#37325;&#35201;&#24739;&#32773;&#25968;&#25454;&#12290;&#38543;&#30528;&#36825;&#20123;&#31508;&#35760;&#25968;&#37327;&#21644;&#22797;&#26434;&#24230;&#30340;&#22686;&#21152;&#65292;&#25163;&#21160;&#25552;&#21462;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#28982;&#35821;&#35328;&#25509;&#21475;&#65292;&#29992;&#20110;&#23545;&#20020;&#24202;&#31508;&#35760;&#36827;&#34892;&#21160;&#24577;&#38382;&#31572;&#12290;&#25105;&#20204;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#30001;Langchain&#21644;&#22522;&#20110;Transformer&#30340;LLMs&#39537;&#21160;&#65292;&#20801;&#35768;&#29992;&#25143;&#29992;&#33258;&#28982;&#35821;&#35328;&#21457;&#20986;&#26597;&#35810;&#65292;&#24182;&#20174;&#20020;&#24202;&#31508;&#35760;&#20013;&#33719;&#24471;&#30456;&#20851;&#31572;&#26696;&#12290;&#36890;&#36807;&#20351;&#29992;&#21508;&#31181;&#23884;&#20837;&#27169;&#22411;&#21644;&#20808;&#36827;&#30340;LLMs&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;Wizard Vicuna&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#65292;&#23613;&#31649;&#35745;&#31639;&#35201;&#27714;&#36739;&#39640;&#12290;&#27169;&#22411;&#20248;&#21270;&#65292;&#21253;&#25324;&#26435;&#37325;&#37327;&#21270;&#65292;&#23558;&#24310;&#36831;&#25552;&#39640;&#20102;&#32422;48&#20493;&#12290;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#26174;&#31034;&#20102;&#20020;&#24202;&#31508;&#35760;&#20013;&#30340;&#20215;&#20540;&#28508;&#21147;&#65292;&#20294;&#20173;&#23384;&#22312;&#27169;&#22411;&#20135;&#29983;&#24187;&#35937;&#21644;&#26377;&#38480;&#30340;&#22810;&#26679;&#21270;&#21307;&#30103;&#26696;&#20363;&#35780;&#20272;&#31561;&#25361;&#25112;&#12290;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#23545;&#20110;&#21457;&#25496;&#20020;&#24202;&#31508;&#35760;&#30340;&#20215;&#20540;&#21644;&#25512;&#21160;AI&#39537;&#21160;&#30340;&#20020;&#24202;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Electronic health records (EHRs) house crucial patient data in clinical notes. As these notes grow in volume and complexity, manual extraction becomes challenging. This work introduces a natural language interface using large language models (LLMs) for dynamic question-answering on clinical notes. Our chatbot, powered by Langchain and transformer-based LLMs, allows users to query in natural language, receiving relevant answers from clinical notes. Experiments, utilizing various embedding models and advanced LLMs, show Wizard Vicuna's superior accuracy, albeit with high compute demands. Model optimization, including weight quantization, improves latency by approximately 48 times. Promising results indicate potential, yet challenges such as model hallucinations and limited diverse medical case evaluations remain. Addressing these gaps is crucial for unlocking the value in clinical notes and advancing AI-driven clinical decision-making.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;EAUC&#20316;&#20026;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20197;&#25581;&#31034;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#38544;&#34255;&#30340;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;RMSE&#21644;MAE&#26080;&#27861;&#25429;&#25417;&#21040;&#36825;&#31181;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.10690</link><description>&lt;p&gt;
&#36229;&#36234;RMSE&#21644;MAE&#65306;&#24341;&#20837;EAUC&#26469;&#25581;&#31034;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#30340;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#22240;&#32032;
&lt;/p&gt;
&lt;p&gt;
Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models. (arXiv:2401.10690v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10690
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;EAUC&#20316;&#20026;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20197;&#25581;&#31034;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#38544;&#34255;&#30340;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;RMSE&#21644;MAE&#26080;&#27861;&#25429;&#25417;&#21040;&#36825;&#31181;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#19968;&#23545;&#23454;&#20307;&#30340;&#23454;&#20540;&#32467;&#26524;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#37117;&#26159;&#22522;&#30784;&#30340;&#65288;&#20363;&#22914;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#39044;&#27979;&#29992;&#25143;&#23545;&#20135;&#21697;&#30340;&#35780;&#20998;&#65289;&#65292;&#22312;&#35768;&#22810;&#20854;&#20182;&#39046;&#22495;&#20013;&#20063;&#26377;&#35768;&#22810;&#28508;&#21147;&#20294;&#23578;&#26410;&#28145;&#20837;&#25506;&#32034;&#65288;&#20363;&#22914;&#65292;&#22312;&#20010;&#24615;&#21270;&#33647;&#29702;&#23398;&#20013;&#36817;&#20284;&#30830;&#23450;&#24739;&#32773;&#30340;&#36866;&#24403;&#21058;&#37327;&#65289;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20010;&#20307;&#23454;&#20307;&#35266;&#23519;&#20540;&#20998;&#24067;&#30340;&#38750;&#22343;&#21248;&#24615;&#23548;&#33268;&#20102;&#26368;&#20808;&#36827;&#27169;&#22411;&#20013;&#30340;&#20005;&#37325;&#20559;&#35265;&#39044;&#27979;&#65292;&#20559;&#21521;&#20110;&#23454;&#20307;&#30340;&#35266;&#23519;&#36807;&#21435;&#20540;&#30340;&#24179;&#22343;&#20540;&#65292;&#24182;&#22312;&#21478;&#31867;&#20294;&#21516;&#26679;&#37325;&#35201;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#27604;&#38543;&#26426;&#39044;&#27979;&#26356;&#24046;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;&#22343;&#26041;&#26681;&#35823;&#24046;&#65288;RMSE&#65289;&#21644;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#19981;&#36275;&#20197;&#25429;&#25417;&#21040;&#36825;&#31181;&#29616;&#35937;&#65292;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;&#21478;&#31867;&#20559;&#35265;&#65292;&#24182;&#24341;&#20837;&#21478;&#31867;-&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;EAUC&#65289;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#34917;&#20805;&#24230;&#37327;&#65292;&#21487;&#20197;&#22312;&#25152;&#26377;&#30740;&#31350;&#30340;&#27169;&#22411;&#20013;&#37327;&#21270;&#23427;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dyadic regression models, which predict real-valued outcomes for pairs of entities, are fundamental in many domains (e.g. predicting the rating of a user to a product in Recommender Systems) and promising and under exploration in many others (e.g. approximating the adequate dosage of a drug for a patient in personalized pharmacology). In this work, we demonstrate that non-uniformity in the observed value distributions of individual entities leads to severely biased predictions in state-of-the-art models, skewing predictions towards the average of observed past values for the entity and providing worse-than-random predictive power in eccentric yet equally important cases. We show that the usage of global error metrics like Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) is insufficient to capture this phenomenon, which we name eccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as a new complementary metric that can quantify it in all studied models
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#25991;&#26412;&#32858;&#31867;&#33258;&#21160;&#26500;&#24314;&#22810;&#32500;&#29992;&#25143;&#20010;&#20154;&#36164;&#26009;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#19987;&#23478;&#25512;&#33616;&#21644;&#25991;&#26723;&#36807;&#28388;&#38382;&#39064;&#20013;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#19987;&#23478;&#26597;&#25214;&#21644;&#25991;&#26723;&#36807;&#28388;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.10634</link><description>&lt;p&gt;
&#20351;&#29992;&#25991;&#26412;&#32858;&#31867;&#33258;&#21160;&#26500;&#24314;&#22810;&#32500;&#29992;&#25143;&#20010;&#20154;&#36164;&#26009;&#21450;&#20854;&#22312;&#19987;&#23478;&#25512;&#33616;&#21644;&#36807;&#28388;&#38382;&#39064;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Automatic Construction of Multi-faceted User Profiles using Text Clustering and its Application to Expert Recommendation and Filtering Problems. (arXiv:2401.10634v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10634
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#25991;&#26412;&#32858;&#31867;&#33258;&#21160;&#26500;&#24314;&#22810;&#32500;&#29992;&#25143;&#20010;&#20154;&#36164;&#26009;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#19987;&#23478;&#25512;&#33616;&#21644;&#25991;&#26723;&#36807;&#28388;&#38382;&#39064;&#20013;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#19987;&#23478;&#26597;&#25214;&#21644;&#25991;&#26723;&#36807;&#28388;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20170;&#30340;&#20449;&#24687;&#26102;&#20195;&#65292;&#25105;&#20204;&#19981;&#20165;&#23545;&#35775;&#38382;&#25991;&#26723;&#12289;&#35270;&#39057;&#31561;&#22810;&#23186;&#20307;&#23545;&#35937;&#24863;&#20852;&#36259;&#65292;&#36824;&#23545;&#25628;&#32034;&#19987;&#19994;&#19987;&#23478;&#12289;&#20154;&#29289;&#25110;&#21517;&#20154;&#24863;&#20852;&#36259;&#65292;&#21487;&#33021;&#26159;&#20986;&#20110;&#32844;&#19994;&#38656;&#27714;&#25110;&#21482;&#26159;&#20026;&#20102;&#23089;&#20048;&#12290;&#20449;&#24687;&#35775;&#38382;&#31995;&#32479;&#38656;&#35201;&#33021;&#22815;&#25552;&#21462;&#21644;&#21033;&#29992;&#20851;&#20110;&#36825;&#20123;&#20010;&#20154;&#30340;&#21508;&#31181;&#20449;&#24687;&#26469;&#28304;&#65288;&#36890;&#24120;&#20197;&#25991;&#26412;&#24418;&#24335;&#65289;&#65292;&#24182;&#20197;&#36866;&#24403;&#30340;&#26041;&#24335;&#21576;&#29616;&#65292;&#36890;&#24120;&#20197;&#20010;&#20154;&#36164;&#26009;&#30340;&#24418;&#24335;&#12290;&#26412;&#25991;&#20174;&#26426;&#22120;&#23398;&#20064;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#23545;&#19987;&#23478;&#25991;&#26412;&#26469;&#28304;&#36827;&#34892;&#32858;&#31867;&#26469;&#26500;&#24314;&#20010;&#20154;&#36164;&#26009;&#24182;&#25429;&#25417;&#19987;&#23478;&#24863;&#20852;&#36259;&#30340;&#19981;&#21516;&#38544;&#34255;&#20027;&#39064;&#65292;&#20174;&#32780;&#35299;&#20915;&#22522;&#20110;&#20010;&#20154;&#36164;&#26009;&#30340;&#19987;&#23478;&#25512;&#33616;&#21644;&#25991;&#26723;&#36807;&#28388;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#25552;&#39640;&#19987;&#23478;&#26597;&#25214;&#21644;&#25991;&#26723;&#36807;&#28388;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the information age we are living in today, not only are we interested in accessing multimedia objects such as documents, videos, etc. but also in searching for professional experts, people or celebrities, possibly for professional needs or just for fun. Information access systems need to be able to extract and exploit various sources of information (usually in text format) about such individuals, and to represent them in a suitable way usually in the form of a profile. In this article, we tackle the problems of profile-based expert recommendation and document filtering from a machine learning perspective by clustering expert textual sources to build profiles and capture the different hidden topics in which the experts are interested. The experts will then be represented by means of multi-faceted profiles. Our experiments show that this is a valid technique to improve the performance of expert finding and document filtering.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LDA&#30340;&#26041;&#27861;&#65292;&#22312;&#25919;&#27835;&#29615;&#22659;&#19979;&#20351;&#29992;&#20027;&#39064;&#20998;&#37197;&#26415;&#35821;&#37197;&#32622;&#26469;&#24110;&#21161;&#26597;&#25214;&#20855;&#26377;&#29305;&#23450;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#30340;&#25919;&#27835;&#23478;&#12290;</title><link>http://arxiv.org/abs/2401.10617</link><description>&lt;p&gt;
&#22522;&#20110;LDA&#30340;&#25919;&#27835;&#29615;&#22659;&#19979;&#19987;&#23478;&#26597;&#25214;&#30340;&#26415;&#35821;&#37197;&#32622;
&lt;/p&gt;
&lt;p&gt;
LDA-based Term Profiles for Expert Finding in a Political Setting. (arXiv:2401.10617v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10617
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LDA&#30340;&#26041;&#27861;&#65292;&#22312;&#25919;&#27835;&#29615;&#22659;&#19979;&#20351;&#29992;&#20027;&#39064;&#20998;&#37197;&#26415;&#35821;&#37197;&#32622;&#26469;&#24110;&#21161;&#26597;&#25214;&#20855;&#26377;&#29305;&#23450;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#30340;&#25919;&#27835;&#23478;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#25919;&#27835;&#26426;&#26500;&#65288;&#22914;&#35758;&#20250;&#65289;&#30340;&#24120;&#35265;&#20219;&#21153;&#26159;&#25214;&#21040;&#22312;&#29305;&#23450;&#39046;&#22495;&#20869;&#20855;&#26377;&#19987;&#19994;&#30693;&#35782;&#30340;&#25919;&#27835;&#23478;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#31532;&#19968;&#27493;&#26159;&#33719;&#21462;&#25919;&#27835;&#23478;&#30340;&#20010;&#20154;&#36164;&#26009;&#65292;&#20854;&#20013;&#21253;&#25324;&#20182;&#20204;&#30340;&#20852;&#36259;&#65292;&#36825;&#20123;&#20852;&#36259;&#21487;&#20197;&#36890;&#36807;&#20182;&#20204;&#30340;&#28436;&#35762;&#33258;&#21160;&#23398;&#20064;&#12290;&#30001;&#20110;&#25919;&#27835;&#23478;&#21487;&#33021;&#22312;&#22810;&#20010;&#39046;&#22495;&#26377;&#19987;&#38271;&#65292;&#22240;&#27492;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#26159;&#20351;&#29992;&#19968;&#32452;&#23376;&#36164;&#26009;&#65292;&#27599;&#20010;&#23376;&#36164;&#26009;&#37117;&#28085;&#30422;&#19981;&#21516;&#30340;&#20027;&#39064;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#65288;LDA&#65289;&#26469;&#30830;&#23450;&#27599;&#20010;&#25919;&#27835;&#28436;&#35762;&#30340;&#20027;&#35201;&#20027;&#39064;&#65292;&#24182;&#23558;&#30456;&#20851;&#26415;&#35821;&#20998;&#37197;&#32473;&#19981;&#21516;&#30340;&#22522;&#20110;&#20027;&#39064;&#30340;&#23376;&#36164;&#26009;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;15&#31181;&#36317;&#31163;&#21644;&#30456;&#20284;&#24615;&#24230;&#37327;&#26469;&#33258;&#21160;&#30830;&#23450;&#25991;&#26723;&#20013;&#35752;&#35770;&#30340;&#20027;&#39064;&#25968;&#65292;&#24182;&#35777;&#26126;&#27599;&#31181;&#24230;&#37327;&#37117;&#25910;&#25947;&#20026;&#20116;&#31181;&#31574;&#30053;&#65306;&#27431;&#27663;&#36317;&#31163;&#12289;Dice&#31995;&#25968;&#12289;Sorensen&#31995;&#25968;&#12289;&#20313;&#24358;&#30456;&#20284;&#24230;&#21644;&#37325;&#21472;&#24230;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
A common task in many political institutions (i.e. Parliament) is to find politicians who are experts in a particular field. In order to tackle this problem, the first step is to obtain politician profiles which include their interests, and these can be automatically learned from their speeches. As a politician may have various areas of expertise, one alternative is to use a set of subprofiles, each of which covers a different subject. In this study, we propose a novel approach for this task by using latent Dirichlet allocation (LDA) to determine the main underlying topics of each political speech, and to distribute the related terms among the different topic-based subprofiles. With this objective, we propose the use of fifteen distance and similarity measures to automatically determine the optimal number of topics discussed in a document, and to demonstrate that every measure converges into five strategies: Euclidean, Dice, Sorensen, Cosine and Overlap. Our experimental results showed
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20986;&#29256;&#22330;&#25152;&#25512;&#33616;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#21644;&#20449;&#24687;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20110;&#20027;&#39064;&#30340;&#20010;&#20154;&#36164;&#26009;&#26469;&#25512;&#33616;&#35770;&#25991;&#30340;&#30446;&#26631;&#20986;&#29256;&#22330;&#25152;&#65292;&#24182;&#32771;&#34385;&#20351;&#29992;&#20316;&#32773;&#20449;&#24687;&#26469;&#25913;&#36827;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.10611</link><description>&lt;p&gt;
&#22522;&#20110;&#32858;&#31867;&#30340;&#20010;&#20154;&#36164;&#26009;&#30340;&#20986;&#29256;&#22330;&#25152;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Publication venue recommendation using profiles based on clustering. (arXiv:2401.10611v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20986;&#29256;&#22330;&#25152;&#25512;&#33616;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#21644;&#20449;&#24687;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20110;&#20027;&#39064;&#30340;&#20010;&#20154;&#36164;&#26009;&#26469;&#25512;&#33616;&#35770;&#25991;&#30340;&#30446;&#26631;&#20986;&#29256;&#22330;&#25152;&#65292;&#24182;&#32771;&#34385;&#20351;&#29992;&#20316;&#32773;&#20449;&#24687;&#26469;&#25913;&#36827;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20986;&#29256;&#22330;&#25152;&#25512;&#33616;&#38382;&#39064;&#65292;&#26088;&#22312;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#25214;&#21040;&#19968;&#20010;&#36866;&#21512;&#25552;&#20132;&#35770;&#25991;&#30340;&#26399;&#21002;&#25110;&#20250;&#35758;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#24314;&#31435;&#23450;&#20041;&#27599;&#20010;&#22330;&#25152;&#33539;&#22260;&#30340;&#20010;&#20154;&#36164;&#26009;&#65292;&#28982;&#21518;&#23558;&#36825;&#20123;&#20010;&#20154;&#36164;&#26009;&#19982;&#30446;&#26631;&#35770;&#25991;&#36827;&#34892;&#27604;&#36739;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#23558;&#30740;&#31350;&#22914;&#20309;&#20351;&#29992;&#32858;&#31867;&#25216;&#26415;&#26500;&#24314;&#22522;&#20110;&#20027;&#39064;&#30340;&#20010;&#20154;&#36164;&#26009;&#65292;&#24182;&#20351;&#29992;&#20449;&#24687;&#26816;&#32034;&#30340;&#26041;&#27861;&#24471;&#21040;&#26368;&#32456;&#30340;&#25512;&#33616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#25506;&#35752;&#20351;&#29992;&#20316;&#32773;&#20449;&#24687;&#20316;&#20026;&#34917;&#20805;&#20449;&#24687;&#22914;&#20309;&#25552;&#39640;&#25512;&#33616;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we study the venue recommendation problem in order to help researchers to identify a journal or conference to submit a given paper. A common approach to tackle this problem is to build profiles defining the scope of each venue. Then, these profiles are compared against the target paper. In our approach we will study how clustering techniques can be used to construct topic-based profiles and use an Information Retrieval based approach to obtain the final recommendations. Additionally, we will explore how the use of authorship, representing a complementary piece of information, helps to improve the recommendations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#28151;&#21512;&#26102;&#38388;&#21644;&#20027;&#39064;&#29305;&#24449;&#26469;&#25913;&#36827;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#19982;&#20854;&#20182;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2401.10607</link><description>&lt;p&gt;
&#20351;&#29992;&#20027;&#39064;&#21644;&#26102;&#38388;&#36724;&#30340;&#28151;&#21512;&#26041;&#27861;&#36827;&#34892;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Use of topical and temporal profiles and their hybridisation for content-based recommendation. (arXiv:2401.10607v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10607
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#28151;&#21512;&#26102;&#38388;&#21644;&#20027;&#39064;&#29305;&#24449;&#26469;&#25913;&#36827;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#19982;&#20854;&#20182;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#30340;&#32972;&#26223;&#19979;&#65292;&#26412;&#25991;&#26088;&#22312;&#30830;&#23450;&#22914;&#20309;&#26500;&#24314;&#26356;&#22909;&#30340;&#29992;&#25143;&#21644;&#29289;&#21697;&#29305;&#24449;&#65292;&#24182;&#30740;&#31350;&#36825;&#20123;&#29305;&#24449;&#23545;&#22522;&#20110;&#26102;&#38388;&#21644;&#20027;&#39064;&#30340;&#25512;&#33616;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;&#20027;&#35201;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#19982;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#36827;&#34892;&#35780;&#20272;&#21644;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the context of content-based recommender systems, the aim of this paper is to determine how better profiles can be built and how these affect the recommendation process based on the incorporation of temporality, i.e. the inclusion of time in the recommendation process, and topicality, i.e. the representation of texts associated with users and items using topics and their combination. The main contribution of the paper is to present two different ways of hybridising these two dimensions and to evaluate and compare them with other alternatives.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#22522;&#20110;ChatGPT&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#25552;&#31034;&#35774;&#35745;&#31574;&#30053;&#23545;&#25512;&#33616;&#36136;&#37327;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;RecLLMs&#20013;&#24341;&#20837;&#29305;&#23450;&#30340;&#31995;&#32479;&#35282;&#33394;&#21644;&#25552;&#31034;&#31574;&#30053;&#21487;&#20197;&#22686;&#24378;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#21516;&#26102;GPT-based&#27169;&#22411;&#20542;&#21521;&#20110;&#25512;&#33616;&#26368;&#26032;&#21644;&#26356;&#22810;&#26679;&#21270;&#30340;&#30005;&#24433;&#27969;&#27966;&#12290;</title><link>http://arxiv.org/abs/2401.10545</link><description>&lt;p&gt;
&#29702;&#35299;ChatGPT&#22522;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20559;&#35265;&#65306;&#20379;&#24212;&#21830;&#20844;&#24179;&#24615;&#12289;&#26102;&#38388;&#31283;&#23450;&#24615;&#21644;&#26368;&#26032;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Understanding Biases in ChatGPT-based Recommender Systems: Provider Fairness, Temporal Stability, and Recency. (arXiv:2401.10545v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10545
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#22522;&#20110;ChatGPT&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#25552;&#31034;&#35774;&#35745;&#31574;&#30053;&#23545;&#25512;&#33616;&#36136;&#37327;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;RecLLMs&#20013;&#24341;&#20837;&#29305;&#23450;&#30340;&#31995;&#32479;&#35282;&#33394;&#21644;&#25552;&#31034;&#31574;&#30053;&#21487;&#20197;&#22686;&#24378;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#21516;&#26102;GPT-based&#27169;&#22411;&#20542;&#21521;&#20110;&#25512;&#33616;&#26368;&#26032;&#21644;&#26356;&#22810;&#26679;&#21270;&#30340;&#30005;&#24433;&#27969;&#27966;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;RecLLMs&#65289;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#32454;&#24494;&#33021;&#21147;&#21644;&#22266;&#26377;&#20559;&#35265;&#65292;&#37325;&#28857;&#30740;&#31350;&#20102;&#22522;&#20110;ChatGPT&#30340;&#31995;&#32479;&#12290;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#21644;&#20256;&#32479;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#22312;&#30005;&#24433;&#25512;&#33616;&#20013;&#30340;&#24046;&#24322;&#34892;&#20026;&#12290;&#26412;&#30740;&#31350;&#20027;&#35201;&#35843;&#26597;&#20102;&#25552;&#31034;&#35774;&#35745;&#31574;&#30053;&#21450;&#20854;&#23545;&#25512;&#33616;&#36136;&#37327;&#30340;&#21508;&#20010;&#26041;&#38754;&#65288;&#21253;&#25324;&#20934;&#30830;&#24615;&#12289;&#20379;&#24212;&#21830;&#20844;&#24179;&#24615;&#12289;&#22810;&#26679;&#24615;&#12289;&#31283;&#23450;&#24615;&#12289;&#27969;&#34892;&#31867;&#22411;&#21644;&#26102;&#25928;&#24615;&#65289;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;RecLLMs&#20013;&#24341;&#20837;&#29305;&#23450;&#30340;&#8220;&#31995;&#32479;&#35282;&#33394;&#8221;&#21644;&#8220;&#25552;&#31034;&#31574;&#30053;&#8221;&#26174;&#33879;&#24433;&#21709;&#20854;&#24615;&#33021;&#12290;&#20363;&#22914;&#65292;&#22522;&#20110;&#35282;&#33394;&#30340;&#25552;&#31034;&#21487;&#20197;&#22686;&#24378;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#20943;&#36731;&#27969;&#34892;&#20559;&#35265;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#22522;&#20110;GPT&#30340;&#27169;&#22411;&#24182;&#19981;&#24635;&#26159;&#33021;&#19982;&#20256;&#32479;&#21327;&#21516;&#36807;&#28388;&#22522;&#32447;&#27169;&#22411;&#30340;&#24615;&#33021;&#21305;&#37197;&#65292;&#20294;&#23427;&#20204;&#20542;&#21521;&#20110;&#25512;&#33616;&#26356;&#26032;&#12289;&#26356;&#22810;&#26679;&#21270;&#30340;&#30005;&#24433;&#27969;&#27966;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;GPT-base
&lt;/p&gt;
&lt;p&gt;
This study explores the nuanced capabilities and inherent biases of Recommender Systems using Large Language Models (RecLLMs), with a focus on ChatGPT-based systems. It studies into the contrasting behaviors of generative models and traditional collaborative filtering models in movie recommendations. The research primarily investigates prompt design strategies and their impact on various aspects of recommendation quality, including accuracy, provider fairness, diversity, stability, genre dominance, and temporal freshness (recency).  Our experimental analysis reveals that the introduction of specific 'system roles' and 'prompt strategies' in RecLLMs significantly influences their performance. For instance, role-based prompts enhance fairness and diversity in recommendations, mitigating popularity bias. We find that while GPT-based models do not always match the performance of CF baselines, they exhibit a unique tendency to recommend newer and more diverse movie genres. Notably, GPT-base
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29983;&#25104;&#24335;&#23494;&#38598;&#26816;&#32034;&#65288;GDR&#65289;&#33539;&#24335;&#65292;&#36890;&#36807;&#22312;&#26597;&#35810;&#21644;&#25991;&#26723;&#20043;&#38388;&#23454;&#29616;&#31751;&#38388;&#21305;&#37197;&#21644;&#32454;&#31890;&#24230;&#30340;&#31751;&#20869;&#21305;&#37197;&#65292;&#32531;&#35299;&#20102;&#29983;&#25104;&#24335;&#26816;&#32034;&#38754;&#20020;&#30340;&#35760;&#24518;&#20934;&#30830;&#24615;&#24046;&#12289;&#35760;&#24518;&#28151;&#28102;&#21644;&#35760;&#24518;&#26356;&#26032;&#25104;&#26412;&#39640;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.10487</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#23494;&#38598;&#26816;&#32034;&#65306;&#35760;&#24518;&#21487;&#20197;&#26159;&#19968;&#20010;&#36127;&#25285;
&lt;/p&gt;
&lt;p&gt;
Generative Dense Retrieval: Memory Can Be a Burden. (arXiv:2401.10487v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29983;&#25104;&#24335;&#23494;&#38598;&#26816;&#32034;&#65288;GDR&#65289;&#33539;&#24335;&#65292;&#36890;&#36807;&#22312;&#26597;&#35810;&#21644;&#25991;&#26723;&#20043;&#38388;&#23454;&#29616;&#31751;&#38388;&#21305;&#37197;&#21644;&#32454;&#31890;&#24230;&#30340;&#31751;&#20869;&#21305;&#37197;&#65292;&#32531;&#35299;&#20102;&#29983;&#25104;&#24335;&#26816;&#32034;&#38754;&#20020;&#30340;&#35760;&#24518;&#20934;&#30830;&#24615;&#24046;&#12289;&#35760;&#24518;&#28151;&#28102;&#21644;&#35760;&#24518;&#26356;&#26032;&#25104;&#26412;&#39640;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#26816;&#32034; (GR) &#22312;&#23567;&#35268;&#27169;&#35821;&#26009;&#24211;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#33394;&#65292;&#36890;&#36807;&#35760;&#24518;&#27169;&#22411;&#21442;&#25968;&#26469;&#38544;&#24335;&#22320;&#23454;&#29616;&#26597;&#35810;&#21644;&#25991;&#26723;&#30340;&#28145;&#24230;&#20132;&#20114;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35760;&#24518;&#26426;&#21046;&#38754;&#20020;&#19977;&#20010;&#38382;&#39064;&#65306;(1) &#23545;&#25991;&#26723;&#30340;&#32454;&#31890;&#24230;&#29305;&#24449;&#30340;&#35760;&#24518;&#20934;&#30830;&#24615;&#36739;&#24046;&#65307;(2) &#38543;&#30528;&#35821;&#26009;&#24211;&#35268;&#27169;&#30340;&#22686;&#21152;&#65292;&#35760;&#24518;&#28151;&#28102;&#31243;&#24230;&#36234;&#26469;&#36234;&#20005;&#37325;&#65307;(3) &#23545;&#26032;&#25991;&#26723;&#30340;&#35760;&#24518;&#26356;&#26032;&#25104;&#26412;&#24040;&#22823;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29983;&#25104;&#24335;&#23494;&#38598;&#26816;&#32034;&#65288;GDR&#65289;&#30340;&#33539;&#24335;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;GDR&#39318;&#20808;&#20351;&#29992;&#26377;&#38480;&#30340;&#20869;&#23384;&#23481;&#37327;&#65292;&#20174;&#26597;&#35810;&#21040;&#30456;&#20851;&#25991;&#26723;&#31751;&#23454;&#29616;&#31751;&#38388;&#21305;&#37197;&#12290;&#28982;&#21518;&#65292;&#24341;&#20837;&#26080;&#35760;&#24518;&#30340;&#23494;&#38598;&#26816;&#32034;&#65288;DR&#65289;&#21305;&#37197;&#26426;&#21046;&#65292;&#20174;&#31751;&#21040;&#30456;&#20851;&#25991;&#26723;&#36827;&#34892;&#32454;&#31890;&#24230;&#30340;&#31751;&#20869;&#21305;&#37197;&#12290;&#36825;&#31181;&#20174;&#31895;&#21040;&#32454;&#30340;&#36807;&#31243;&#26368;&#22823;&#21270;&#20102;GR&#28145;&#24230;&#20132;&#20114;&#21644;DR&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Retrieval (GR), autoregressively decoding relevant document identifiers given a query, has been shown to perform well under the setting of small-scale corpora. By memorizing the document corpus with model parameters, GR implicitly achieves deep interaction between query and document. However, such a memorizing mechanism faces three drawbacks: (1) Poor memory accuracy for fine-grained features of documents; (2) Memory confusion gets worse as the corpus size increases; (3) Huge memory update costs for new documents. To alleviate these problems, we propose the Generative Dense Retrieval (GDR) paradigm. Specifically, GDR first uses the limited memory volume to achieve inter-cluster matching from query to relevant document clusters. Memorizing-free matching mechanism from Dense Retrieval (DR) is then introduced to conduct fine-grained intra-cluster matching from clusters to relevant documents. The coarse-to-fine process maximizes the advantages of GR's deep interaction and DR's s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#24425;&#31080;&#31080;&#25454;&#20551;&#35774;&#21644;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21098;&#26525;&#31070;&#32463;&#32593;&#32476;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#32463;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#38477;&#20302;&#21151;&#32791;&#21644;&#27169;&#22411;&#23610;&#23544;&#65292;&#24182;&#23454;&#29616;&#39640;&#36798;66.67%&#30340;GPU&#35745;&#31639;&#21151;&#29575;&#20943;&#23569;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#39318;&#27425;&#24212;&#29992;&#20102;&#24425;&#31080;&#31080;&#25454;&#20551;&#35774;&#21644;&#30693;&#35782;&#33976;&#39311;&#25216;&#26415;&#20110;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#65292;&#23545;&#35813;&#39046;&#22495;&#20316;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2401.10484</link><description>&lt;p&gt;
&#22522;&#20110;&#24425;&#31080;&#31080;&#25454;&#20551;&#35774;&#21644;&#30693;&#35782;&#33976;&#39311;&#30340;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#25216;&#26415;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#30340;&#21487;&#25193;&#23637;&#24615;
&lt;/p&gt;
&lt;p&gt;
Enhancing Scalability in Recommender Systems through Lottery Ticket Hypothesis and Knowledge Distillation-based Neural Network Pruning. (arXiv:2401.10484v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#24425;&#31080;&#31080;&#25454;&#20551;&#35774;&#21644;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21098;&#26525;&#31070;&#32463;&#32593;&#32476;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#32463;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#38477;&#20302;&#21151;&#32791;&#21644;&#27169;&#22411;&#23610;&#23544;&#65292;&#24182;&#23454;&#29616;&#39640;&#36798;66.67%&#30340;GPU&#35745;&#31639;&#21151;&#29575;&#20943;&#23569;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#39318;&#27425;&#24212;&#29992;&#20102;&#24425;&#31080;&#31080;&#25454;&#20551;&#35774;&#21644;&#30693;&#35782;&#33976;&#39311;&#25216;&#26415;&#20110;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#65292;&#23545;&#35813;&#39046;&#22495;&#20316;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#39640;&#25928;&#22320;&#21098;&#26525;&#31070;&#32463;&#32593;&#32476;&#65292;&#29305;&#21035;&#20851;&#27880;&#23427;&#20204;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#30340;&#37096;&#32626;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#24425;&#31080;&#31080;&#25454;&#20551;&#35774;&#65288;LTH&#65289;&#19982;&#30693;&#35782;&#33976;&#39311;&#65288;KD&#65289;&#26694;&#26550;&#30456;&#32467;&#21512;&#65292;&#24418;&#25104;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#21098;&#26525;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#26088;&#22312;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#20854;&#20013;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#22952;&#30861;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#37096;&#32626;&#12290;&#36890;&#36807;&#24039;&#22937;&#24212;&#29992;&#21098;&#26525;&#25216;&#26415;&#65292;&#25105;&#20204;&#26377;&#25928;&#22320;&#38477;&#20302;&#20102;&#21151;&#32791;&#21644;&#27169;&#22411;&#23610;&#23544;&#65292;&#21516;&#26102;&#19981;&#24433;&#21709;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#23545;&#20004;&#20010;&#22522;&#20934;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#20196;&#20154;&#28385;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;GPU&#35745;&#31639;&#21151;&#29575;&#19978;&#23454;&#29616;&#20102;&#39640;&#36798;66.67%&#30340;&#38477;&#20302;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36890;&#36807;&#39318;&#27425;&#24212;&#29992;LTH&#21644;KD&#25216;&#26415;&#65292;&#23545;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study introduces an innovative approach aimed at the efficient pruning of neural networks, with a particular focus on their deployment on edge devices. Our method involves the integration of the Lottery Ticket Hypothesis (LTH) with the Knowledge Distillation (KD) framework, resulting in the formulation of three distinct pruning models. These models have been developed to address scalability issue in recommender systems, whereby the complexities of deep learning models have hindered their practical deployment. With judicious application of the pruning techniques, we effectively curtail the power consumption and model dimensions without compromising on accuracy. Empirical evaluation has been performed using two real world datasets from diverse domains against two baselines. Gratifyingly, our approaches yielded a GPU computation-power reduction of up to 66.67%. Notably, our study contributes to the field of recommendation system by pioneering the application of LTH and KD.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#20219;&#21153;&#26694;&#26550;&#65292;&#32771;&#34385;&#20102;&#38544;&#24335;&#21453;&#39304;&#20013;&#19981;&#21516;&#20559;&#22909;&#24378;&#24230;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#20854;&#20013;&#24341;&#20837;&#20102;&#27880;&#24847;&#21147;&#22270;&#21367;&#31215;&#23618;&#26469;&#25506;&#32034;&#39640;&#38454;&#20851;&#31995;&#12290;&#36825;&#20351;&#24471;&#34920;&#31034;&#26356;&#20855;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.10316</link><description>&lt;p&gt;
&#22312;&#19981;&#21516;&#20559;&#22909;&#24378;&#24230;&#19978;&#36890;&#36807;&#22810;&#20219;&#21153;&#25552;&#21319;&#21333;&#31867;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Improving One-class Recommendation with Multi-tasking on Various Preference Intensities. (arXiv:2401.10316v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10316
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#20219;&#21153;&#26694;&#26550;&#65292;&#32771;&#34385;&#20102;&#38544;&#24335;&#21453;&#39304;&#20013;&#19981;&#21516;&#20559;&#22909;&#24378;&#24230;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#20854;&#20013;&#24341;&#20837;&#20102;&#27880;&#24847;&#21147;&#22270;&#21367;&#31215;&#23618;&#26469;&#25506;&#32034;&#39640;&#38454;&#20851;&#31995;&#12290;&#36825;&#20351;&#24471;&#34920;&#31034;&#26356;&#20855;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21333;&#31867;&#25512;&#33616;&#38382;&#39064;&#20013;&#65292;&#38656;&#35201;&#26681;&#25454;&#29992;&#25143;&#30340;&#38544;&#24335;&#21453;&#39304;&#26469;&#36827;&#34892;&#25512;&#33616;&#65292;&#35813;&#21453;&#39304;&#26159;&#36890;&#36807;&#29992;&#25143;&#30340;&#34892;&#20026;&#21644;&#19981;&#34892;&#20026;&#36827;&#34892;&#25512;&#26029;&#30340;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#36807;&#32534;&#30721;&#26469;&#33258;&#35757;&#32451;&#25968;&#25454;&#20013;&#35266;&#23519;&#21040;&#30340;&#31215;&#26497;&#21644;&#28040;&#26497;&#20132;&#20114;&#26469;&#33719;&#21462;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20551;&#35774;&#38544;&#24335;&#21453;&#39304;&#20013;&#30340;&#25152;&#26377;&#31215;&#26497;&#20449;&#21495;&#37117;&#21453;&#26144;&#20102;&#22266;&#23450;&#30340;&#20559;&#22909;&#24378;&#24230;&#65292;&#36825;&#26159;&#19981;&#29616;&#23454;&#30340;&#12290;&#22240;&#27492;&#65292;&#29992;&#36825;&#20123;&#26041;&#27861;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#36890;&#24120;&#26080;&#27861;&#25429;&#25417;&#21453;&#26144;&#19981;&#21516;&#20559;&#22909;&#24378;&#24230;&#30340;&#20449;&#24687;&#24615;&#23454;&#20307;&#29305;&#24449;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#20219;&#21153;&#26694;&#26550;&#65292;&#32771;&#34385;&#20102;&#38544;&#24335;&#21453;&#39304;&#20013;&#27599;&#20010;&#20449;&#21495;&#30340;&#19981;&#21516;&#20559;&#22909;&#24378;&#24230;&#12290;&#23454;&#20307;&#30340;&#34920;&#31034;&#38656;&#35201;&#21516;&#26102;&#28385;&#36275;&#27599;&#20010;&#23376;&#20219;&#21153;&#30340;&#30446;&#26631;&#65292;&#20351;&#20854;&#26356;&#21152;&#31283;&#20581;&#21644;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#27880;&#24847;&#21147;&#22270;&#21367;&#31215;&#23618;&#24341;&#20837;&#21040;&#29992;&#25143;-&#29289;&#21697;&#30340;&#39640;&#38454;&#20851;&#31995;&#20013;&#36827;&#34892;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the one-class recommendation problem, it's required to make recommendations basing on users' implicit feedback, which is inferred from their action and inaction. Existing works obtain representations of users and items by encoding positive and negative interactions observed from training data. However, these efforts assume that all positive signals from implicit feedback reflect a fixed preference intensity, which is not realistic. Consequently, representations learned with these methods usually fail to capture informative entity features that reflect various preference intensities.  In this paper, we propose a multi-tasking framework taking various preference intensities of each signal from implicit feedback into consideration. Representations of entities are required to satisfy the objective of each subtask simultaneously, making them more robust and generalizable. Furthermore, we incorporate attentive graph convolutional layers to explore high-order relationships in the user-item
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#31995;&#32479;&#32508;&#36848;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#22320;&#29702;&#20301;&#32622;&#23884;&#20837;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#20027;&#35201;&#30340;&#23884;&#20837;&#20027;&#39064;&#65292;&#24182;&#24378;&#35843;&#20102;&#22312;&#31354;&#38388;&#24418;&#24577;&#21644;&#29983;&#25104;&#27169;&#24577;&#26041;&#38754;&#36827;&#19968;&#27493;&#21457;&#23637;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2401.10279</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#22320;&#29702;&#20301;&#32622;&#23884;&#20837;&#26041;&#27861;&#30340;&#31995;&#32479;&#32508;&#36848;&#65306;&#36808;&#21521;&#31354;&#38388;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#36335;&#24452;
&lt;/p&gt;
&lt;p&gt;
A systematic review of geospatial location embedding approaches in large language models: A path to spatial AI systems. (arXiv:2401.10279v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10279
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#31995;&#32479;&#32508;&#36848;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#22320;&#29702;&#20301;&#32622;&#23884;&#20837;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#22235;&#31181;&#20027;&#35201;&#30340;&#23884;&#20837;&#20027;&#39064;&#65292;&#24182;&#24378;&#35843;&#20102;&#22312;&#31354;&#38388;&#24418;&#24577;&#21644;&#29983;&#25104;&#27169;&#24577;&#26041;&#38754;&#36827;&#19968;&#27493;&#21457;&#23637;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22320;&#29702;&#20301;&#32622;&#23884;&#20837;&#65288;GLE&#65289;&#24110;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21560;&#25910;&#21644;&#20998;&#26512;&#31354;&#38388;&#25968;&#25454;&#12290;GLE&#22312;&#22320;&#29702;&#20154;&#24037;&#26234;&#33021;&#65288;GeoAI&#65289;&#20013;&#30340;&#20986;&#29616;&#26159;&#30001;&#20110;&#25105;&#20204;&#22797;&#26434;&#24403;&#20195;&#31354;&#38388;&#20013;&#23545;&#26356;&#28145;&#20837;&#30340;&#22320;&#29702;&#35748;&#30693;&#30340;&#38656;&#27714;&#20197;&#21450;LLM&#22312;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#20013;&#25552;&#21462;&#28145;&#23618;&#21547;&#20041;&#30340;&#25104;&#21151;&#12290;&#25105;&#20204;&#22312;Google Scholar&#12289;Science Direct&#21644;arXiv&#19978;&#25628;&#32034;&#20102;&#20851;&#20110;&#22320;&#29702;&#20301;&#32622;&#23884;&#20837;&#21644;LLM&#30340;&#35770;&#25991;&#65292;&#24182;&#23457;&#26597;&#20102;&#30528;&#37325;&#20110;&#36890;&#36807;LLM&#23454;&#29616;&#26356;&#28145;&#20837;&#31354;&#38388;&#8220;&#30693;&#35782;&#8221;&#30340;&#25991;&#31456;&#12290;&#25105;&#20204;&#31579;&#36873;&#20102;304&#20010;&#26631;&#39064;&#12289;30&#20010;&#25688;&#35201;&#21644;18&#31687;&#20840;&#25991;&#35770;&#25991;&#65292;&#25581;&#31034;&#20102;&#22235;&#20010;GLE&#20027;&#39064; - &#23454;&#20307;&#20301;&#32622;&#23884;&#20837;&#65288;ELE&#65289;&#12289;&#25991;&#26723;&#20301;&#32622;&#23884;&#20837;&#65288;DLE&#65289;&#12289;&#24207;&#21015;&#20301;&#32622;&#23884;&#20837;&#65288;SLE&#65289;&#21644;&#20196;&#29260;&#20301;&#32622;&#23884;&#20837;&#65288;TLE&#65289;&#12290;&#32508;&#36848;&#20197;&#34920;&#26684;&#21644;&#21465;&#36848;&#30340;&#24418;&#24335;&#21576;&#29616;&#65292;&#21253;&#25324;&#8220;&#31354;&#38388;&#8221;&#21644;&#8220;LLM&#8221;&#20043;&#38388;&#30340;&#23545;&#35805;&#12290;&#23613;&#31649;GLE&#36890;&#36807;&#21472;&#21152;&#31354;&#38388;&#25968;&#25454;&#26377;&#21161;&#20110;&#29702;&#35299;&#31354;&#38388;&#65292;&#20294;&#24378;&#35843;&#20102;&#22312;&#31354;&#38388;&#24418;&#24577;&#21644;&#29983;&#25104;&#27169;&#24577;&#26041;&#38754;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Geospatial Location Embedding (GLE) helps a Large Language Model (LLM) assimilate and analyze spatial data. GLE emergence in Geospatial Artificial Intelligence (GeoAI) is precipitated by the need for deeper geospatial awareness in our complex contemporary spaces and the success of LLMs in extracting deep meaning in Generative AI. We searched Google Scholar, Science Direct, and arXiv for papers on geospatial location embedding and LLM and reviewed articles focused on gaining deeper spatial "knowing" through LLMs. We screened 304 titles, 30 abstracts, and 18 full-text papers that reveal four GLE themes - Entity Location Embedding (ELE), Document Location Embedding (DLE), Sequence Location Embedding (SLE), and Token Location Embedding (TLE). Synthesis is tabular and narrative, including a dialogic conversation between "Space" and "LLM." Though GLEs aid spatial understanding by superimposing spatial data, they emphasize the need to advance in the intricacies of spatial modalities and gener
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#25512;&#33616;&#27169;&#22411;KGLN&#65292;&#36890;&#36807;&#21512;&#24182;&#33410;&#28857;&#29305;&#24449;&#12289;&#35843;&#25972;&#32858;&#21512;&#26435;&#37325;&#21644;&#36845;&#20195;&#28436;&#21270;&#65292;&#25552;&#39640;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#12290;&#22312;&#23454;&#39564;&#20013;&#30456;&#23545;&#20110;&#24050;&#26377;&#22522;&#20934;&#26041;&#27861;&#65292;KGLN&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;AUC&#25552;&#39640;&#20102;0.3%&#33267;5.9%&#21644;1.1%&#33267;8.2%&#12290;</title><link>http://arxiv.org/abs/2401.10244</link><description>&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#39537;&#21160;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#25512;&#33616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Knowledge graph driven recommendation model of graph neural network. (arXiv:2401.10244v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10244
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#25512;&#33616;&#27169;&#22411;KGLN&#65292;&#36890;&#36807;&#21512;&#24182;&#33410;&#28857;&#29305;&#24449;&#12289;&#35843;&#25972;&#32858;&#21512;&#26435;&#37325;&#21644;&#36845;&#20195;&#28436;&#21270;&#65292;&#25552;&#39640;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#12290;&#22312;&#23454;&#39564;&#20013;&#30456;&#23545;&#20110;&#24050;&#26377;&#22522;&#20934;&#26041;&#27861;&#65292;KGLN&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;AUC&#25552;&#39640;&#20102;0.3%&#33267;5.9%&#21644;1.1%&#33267;8.2%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#33616;&#27169;&#22411;KGLN&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#20449;&#24687;&#65292;&#25552;&#39640;&#20102;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#12290;&#35813;&#27169;&#22411;&#39318;&#20808;&#21033;&#29992;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#23558;&#22270;&#20013;&#30340;&#20010;&#20307;&#33410;&#28857;&#29305;&#24449;&#21512;&#24182;&#65292;&#28982;&#21518;&#36890;&#36807;&#32467;&#21512;&#24433;&#21709;&#22240;&#32032;&#35843;&#25972;&#30456;&#37051;&#23454;&#20307;&#30340;&#32858;&#21512;&#26435;&#37325;&#12290;&#36890;&#36807;&#36845;&#20195;&#65292;&#27169;&#22411;&#20174;&#21333;&#23618;&#36880;&#28176;&#28436;&#21464;&#20026;&#22810;&#23618;&#65292;&#20351;&#23454;&#20307;&#33021;&#22815;&#33719;&#21462;&#20016;&#23500;&#30340;&#22810;&#38454;&#20851;&#32852;&#23454;&#20307;&#20449;&#24687;&#12290;&#26368;&#21518;&#65292;&#23558;&#23454;&#20307;&#21644;&#29992;&#25143;&#30340;&#29305;&#24449;&#32467;&#21512;&#36215;&#26469;&#20135;&#29983;&#25512;&#33616;&#20998;&#25968;&#12290;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#32858;&#21512;&#26041;&#27861;&#21644;&#24433;&#21709;&#22240;&#32032;&#30340;&#25928;&#26524;&#65292;&#35780;&#20272;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22312;&#20351;&#29992;MovieLen-1M&#21644;Book-Crossing&#25968;&#25454;&#38598;&#36827;&#34892;&#27979;&#35797;&#26102;&#65292;KGLN&#30456;&#23545;&#20110;LibFM&#21644;D&#31561;&#24050;&#26377;&#22522;&#20934;&#26041;&#27861;&#65292;AUC&#65288;ROC&#26354;&#32447;&#19979;&#30340;&#38754;&#31215;&#65289;&#25552;&#39640;&#20102;0.3%&#33267;5.9%&#21644;1.1%&#33267;8.2%&#12290;
&lt;/p&gt;
&lt;p&gt;
A new graph neural network-based recommendation model called KGLN, which leverages Knowledge Graph (KG) information, was developed to enhance the accuracy and effectiveness of personalized recommendations. This model begins by using a single-layer neural network to merge individual node features in the graph. It then adjusts the aggregation weights of neighboring entities by incorporating influence factors. The model evolves from a single layer to multiple layers through iteration, enabling entities to access extensive multi-order associated entity information. The final step involves integrating features of entities and users to produce a recommendation score. The model's performance was evaluated by comparing its effects on various aggregation methods and influence factors. In tests using the MovieLen-1M and Book-Crossing datasets, KGLN showed an AUC (Area Under the ROC curve) improvement of 0.3% to 5.9% and 1.1% to 8.2%, respectively, over established benchmark methods like LibFM, D
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#20351;&#29992;&#26080;&#30417;&#30563;&#30456;&#20284;&#24230;&#24230;&#37327;&#36827;&#34892;&#28304;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#65292;&#26088;&#22312;&#20026;&#36719;&#20214;&#24037;&#31243;&#24072;&#25552;&#20379;&#25351;&#23548;&#65292;&#20197;&#36873;&#25321;&#36866;&#21512;&#20854;&#29305;&#23450;&#29992;&#20363;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.09885</link><description>&lt;p&gt;
&#20351;&#29992;&#26080;&#30417;&#30563;&#30456;&#20284;&#24230;&#24230;&#37327;&#36827;&#34892;&#28304;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Source Code Clone Detection Using Unsupervised Similarity Measures. (arXiv:2401.09885v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09885
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#20351;&#29992;&#26080;&#30417;&#30563;&#30456;&#20284;&#24230;&#24230;&#37327;&#36827;&#34892;&#28304;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#65292;&#26088;&#22312;&#20026;&#36719;&#20214;&#24037;&#31243;&#24072;&#25552;&#20379;&#25351;&#23548;&#65292;&#20197;&#36873;&#25321;&#36866;&#21512;&#20854;&#29305;&#23450;&#29992;&#20363;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22312;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#20013;&#20811;&#38534;&#26816;&#27979;&#21644;&#20195;&#30721;&#25628;&#32034;&#19982;&#25512;&#33616;&#30340;&#37325;&#35201;&#24615;&#65292;&#23545;&#28304;&#20195;&#30721;&#30340;&#30456;&#20284;&#24615;&#36827;&#34892;&#35780;&#20272;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#36739;&#20998;&#26512;&#26080;&#30417;&#30563;&#30456;&#20284;&#24230;&#24230;&#37327;&#29992;&#20110;&#35782;&#21035;&#28304;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#30340;&#26041;&#27861;&#12290;&#30446;&#26631;&#26159;&#27010;&#36848;&#30446;&#21069;&#30340;&#26368;&#26032;&#25216;&#26415;&#12289;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#32534;&#35793;&#20102;&#29616;&#26377;&#30340;&#26080;&#30417;&#30563;&#31574;&#30053;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#20197;&#25351;&#23548;&#36719;&#20214;&#24037;&#31243;&#24072;&#22312;&#36873;&#25321;&#36866;&#29992;&#20110;&#20854;&#29305;&#23450;&#29992;&#20363;&#30340;&#26041;&#27861;&#26102;&#25552;&#20379;&#25351;&#23548;&#12290;&#26412;&#30740;&#31350;&#30340;&#28304;&#20195;&#30721;&#21487;&#22312;\url{https://github.com/jorge-martinez-gil/codesim}&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing similarity in source code has gained significant attention in recent years due to its importance in software engineering tasks such as clone detection and code search and recommendation. This work presents a comparative analysis of unsupervised similarity measures for identifying source code clone detection. The goal is to overview the current state-of-the-art techniques, their strengths, and weaknesses. To do that, we compile the existing unsupervised strategies and evaluate their performance on a benchmark dataset to guide software engineers in selecting appropriate methods for their specific use cases. The source code of this study is available at \url{https://github.com/jorge-martinez-gil/codesim}
&lt;/p&gt;</description></item><item><title>&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#36890;&#36807;&#38598;&#25104;&#21644;&#23398;&#20064;&#22810;&#20010;&#39046;&#22495;&#30340;&#20132;&#20114;&#20449;&#24687;&#65292;&#23558;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#20174;&#24179;&#38754;&#36716;&#21521;&#31435;&#20307;&#12290;&#25991;&#31456;&#23545;CDSR&#38382;&#39064;&#36827;&#34892;&#20102;&#23450;&#20041;&#21644;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#20174;&#23439;&#35266;&#21644;&#24494;&#35266;&#20004;&#20010;&#35270;&#35282;&#30340;&#31995;&#32479;&#27010;&#36848;&#12290;&#23545;&#20110;&#19981;&#21516;&#39046;&#22495;&#38388;&#30340;&#27169;&#22411;&#65292;&#24635;&#32467;&#20102;&#22810;&#23618;&#34701;&#21512;&#32467;&#26500;&#21644;&#34701;&#21512;&#26725;&#26753;&#12290;&#23545;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#35752;&#35770;&#20102;&#22522;&#30784;&#25216;&#26415;&#21644;&#36741;&#21161;&#23398;&#20064;&#25216;&#26415;&#12290;&#23637;&#31034;&#20102;&#20844;&#24320;&#25968;&#25454;&#38598;&#21644;&#23454;&#39564;&#32467;&#26524;&#65292;&#24182;&#32473;&#20986;&#20102;&#26410;&#26469;&#21457;&#23637;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2401.04971</link><description>&lt;p&gt;
&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Cross-Domain Sequential Recommendation. (arXiv:2401.04971v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04971
&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#36890;&#36807;&#38598;&#25104;&#21644;&#23398;&#20064;&#22810;&#20010;&#39046;&#22495;&#30340;&#20132;&#20114;&#20449;&#24687;&#65292;&#23558;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#20174;&#24179;&#38754;&#36716;&#21521;&#31435;&#20307;&#12290;&#25991;&#31456;&#23545;CDSR&#38382;&#39064;&#36827;&#34892;&#20102;&#23450;&#20041;&#21644;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#20174;&#23439;&#35266;&#21644;&#24494;&#35266;&#20004;&#20010;&#35270;&#35282;&#30340;&#31995;&#32479;&#27010;&#36848;&#12290;&#23545;&#20110;&#19981;&#21516;&#39046;&#22495;&#38388;&#30340;&#27169;&#22411;&#65292;&#24635;&#32467;&#20102;&#22810;&#23618;&#34701;&#21512;&#32467;&#26500;&#21644;&#34701;&#21512;&#26725;&#26753;&#12290;&#23545;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#35752;&#35770;&#20102;&#22522;&#30784;&#25216;&#26415;&#21644;&#36741;&#21161;&#23398;&#20064;&#25216;&#26415;&#12290;&#23637;&#31034;&#20102;&#20844;&#24320;&#25968;&#25454;&#38598;&#21644;&#23454;&#39564;&#32467;&#26524;&#65292;&#24182;&#32473;&#20986;&#20102;&#26410;&#26469;&#21457;&#23637;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#65288;CDSR&#65289;&#36890;&#36807;&#22312;&#19981;&#21516;&#31890;&#24230;&#65288;&#20174;&#24207;&#21015;&#38388;&#21040;&#24207;&#21015;&#20869;&#65292;&#20174;&#21333;&#39046;&#22495;&#21040;&#36328;&#39046;&#22495;&#65289;&#19978;&#38598;&#25104;&#21644;&#23398;&#20064;&#26469;&#33258;&#22810;&#20010;&#39046;&#22495;&#30340;&#20132;&#20114;&#20449;&#24687;&#65292;&#23558;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#20174;&#24179;&#38754;&#36716;&#21521;&#20102;&#31435;&#20307;&#12290;&#26412;&#32508;&#36848;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#22235;&#32500;&#24352;&#37327;&#23450;&#20041;&#20102;CDSR&#38382;&#39064;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#22312;&#22810;&#32500;&#24230;&#38477;&#32500;&#19979;&#30340;&#22810;&#31867;&#22411;&#36755;&#20837;&#34920;&#31034;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20174;&#25972;&#20307;&#21644;&#32454;&#33410;&#20004;&#20010;&#35270;&#35282;&#25552;&#20379;&#20102;&#31995;&#32479;&#30340;&#27010;&#36848;&#12290;&#20174;&#25972;&#20307;&#35270;&#35282;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#21508;&#20010;&#27169;&#22411;&#22312;&#19981;&#21516;&#39046;&#22495;&#38388;&#30340;&#22810;&#23618;&#34701;&#21512;&#32467;&#26500;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#34701;&#21512;&#26725;&#26753;&#12290;&#20174;&#32454;&#33410;&#35270;&#35282;&#65292;&#25105;&#20204;&#30528;&#37325;&#35752;&#35770;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#22522;&#30784;&#25216;&#26415;&#65292;&#24182;&#35299;&#37322;&#20102;&#36741;&#21161;&#23398;&#20064;&#25216;&#26415;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#29992;&#30340;&#20844;&#24320;&#25968;&#25454;&#38598;&#21644;&#20195;&#34920;&#24615;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#26410;&#26469;&#21457;&#23637;&#30340;&#19968;&#20123;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-domain sequential recommendation (CDSR) shifts the modeling of user preferences from flat to stereoscopic by integrating and learning interaction information from multiple domains at different granularities (ranging from inter-sequence to intra-sequence and from single-domain to cross-domain).In this survey, we initially define the CDSR problem using a four-dimensional tensor and then analyze its multi-type input representations under multidirectional dimensionality reductions. Following that, we provide a systematic overview from both macro and micro views. From a macro view, we abstract the multi-level fusion structures of various models across domains and discuss their bridges for fusion. From a micro view, focusing on the existing models, we specifically discuss the basic technologies and then explain the auxiliary learning technologies. Finally, we exhibit the available public datasets and the representative experimental results as well as provide some insights into future d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21482;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#23569;&#37327;&#35757;&#32451;&#27493;&#39588;&#33719;&#21462;&#39640;&#36136;&#37327;&#25991;&#26412;&#23884;&#20837;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#31454;&#20105;&#28608;&#28872;&#30340;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.00368</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25913;&#21892;&#25991;&#26412;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Improving Text Embeddings with Large Language Models. (arXiv:2401.00368v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21482;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#23569;&#37327;&#35757;&#32451;&#27493;&#39588;&#33719;&#21462;&#39640;&#36136;&#37327;&#25991;&#26412;&#23884;&#20837;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#31454;&#20105;&#28608;&#28872;&#30340;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#20165;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#23569;&#20110;1k&#20010;&#35757;&#32451;&#27493;&#39588;&#21363;&#21487;&#33719;&#24471;&#39640;&#36136;&#37327;&#30340;&#25991;&#26412;&#23884;&#20837;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#29616;&#26377;&#26041;&#27861;&#24448;&#24448;&#20381;&#36182;&#22810;&#38454;&#27573;&#20013;&#38388;&#39044;&#35757;&#32451;&#65292;&#20351;&#29992;&#25968;&#21313;&#20159;&#20010;&#24369;&#30417;&#30563;&#25991;&#26412;&#23545;&#36827;&#34892;&#35757;&#32451;&#65292;&#28982;&#21518;&#20877;&#20351;&#29992;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#26500;&#24314;&#22797;&#26434;&#30340;&#35757;&#32451;&#27969;&#31243;&#65292;&#20063;&#19981;&#20381;&#36182;&#20110;&#36890;&#24120;&#21463;&#20219;&#21153;&#22810;&#26679;&#24615;&#21644;&#35821;&#35328;&#35206;&#30422;&#33539;&#22260;&#38480;&#21046;&#30340;&#25163;&#21160;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#21033;&#29992;&#19987;&#26377;&#30340;LLM&#26469;&#20026;&#36817;100&#31181;&#35821;&#35328;&#30340;&#25968;&#21313;&#19975;&#20010;&#25991;&#26412;&#23884;&#20837;&#20219;&#21153;&#29983;&#25104;&#22810;&#26679;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#30340;&#23545;&#27604;&#25439;&#22833;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#24494;&#35843;&#24320;&#28304;&#30340;&#21482;&#26377;&#35299;&#30721;&#22120;&#30340;LLM&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#31454;&#20105;&#28608;&#28872;&#30340;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#32780;&#19988;&#27809;&#26377;&#20351;&#29992;&#20219;&#20309;&#26631;&#35760;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#24403;&#19982;&#21512;&#25104;&#25968;&#25454;&#21644;&#26631;&#35760;&#25968;&#25454;&#30340;&#28151;&#21512;&#36827;&#34892;&#24494;&#35843;&#26102;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21019;&#36896;&#20102;&#26032;&#30340;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training steps. Unlike existing methods that often depend on multi-stage intermediate pre-training with billions of weakly-supervised text pairs, followed by fine-tuning with a few labeled datasets, our method does not require building complex training pipelines or relying on manually collected datasets that are often constrained by task diversity and language coverage. We leverage proprietary LLMs to generate diverse synthetic data for hundreds of thousands of text embedding tasks across nearly 100 languages. We then fine-tune open-source decoder-only LLMs on the synthetic data using standard contrastive loss. Experiments demonstrate that our method achieves strong performance on highly competitive text embedding benchmarks without using any labeled data. Furthermore, when fine-tuned with a mixture of synthetic and labeled data, our model sets new
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#22411;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#39537;&#21160;&#30340;&#20132;&#20114;&#24335;&#26597;&#35810;&#27169;&#25311;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65292;&#24182;&#23637;&#31034;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#22909;&#30340;&#26377;&#25928;&#24615;&#21644;&#26356;&#39640;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#20250;&#35805;&#27169;&#25311;&#12290;</title><link>http://arxiv.org/abs/2312.09631</link><description>&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#22411;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#39537;&#21160;&#30340;&#20132;&#20114;&#24335;&#26597;&#35810;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Context-Driven Interactive Query Simulations Based on Generative Large Language Models. (arXiv:2312.09631v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.09631
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#22411;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#39537;&#21160;&#30340;&#20132;&#20114;&#24335;&#26597;&#35810;&#27169;&#25311;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65292;&#24182;&#23637;&#31034;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#22909;&#30340;&#26377;&#25928;&#24615;&#21644;&#26356;&#39640;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#20250;&#35805;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#25311;&#29992;&#25143;&#20132;&#20114;&#21487;&#20197;&#26356;&#21152;&#38754;&#21521;&#29992;&#25143;&#35780;&#20272;&#20449;&#24687;&#26816;&#32034;(IR)&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26041;&#27861;&#22312;&#30495;&#23454;&#29992;&#25143;&#34892;&#20026;&#26041;&#38754;&#32570;&#20047;&#30495;&#23454;&#24615;&#12290;&#23588;&#20854;&#26159;&#65292;&#24403;&#21069;&#29992;&#25143;&#27169;&#22411;&#24573;&#35270;&#20102;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65292;&#32780;&#19978;&#19979;&#25991;&#26159;&#24863;&#30693;&#30456;&#20851;&#24615;&#21644;&#19982;&#25628;&#32034;&#32467;&#26524;&#20132;&#20114;&#30340;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#12290;&#20026;&#27492;&#65292;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19978;&#19979;&#25991;&#39537;&#21160;&#30340;&#26597;&#35810;&#37325;&#26500;&#27169;&#25311;&#12290;&#25152;&#25552;&#20986;&#30340;&#26597;&#35810;&#29983;&#25104;&#26041;&#27861;&#22522;&#20110;&#26368;&#26032;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;(LLM)&#26041;&#27861;&#65292;&#24182;&#22312;&#25972;&#20010;&#25628;&#32034;&#20250;&#35805;&#30340;&#27169;&#25311;&#36807;&#31243;&#20013;&#32771;&#34385;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#12290;&#19982;&#31616;&#21333;&#30340;&#26080;&#19978;&#19979;&#25991;&#26597;&#35810;&#29983;&#25104;&#26041;&#27861;&#30456;&#27604;&#65292;&#36825;&#20123;&#26041;&#27861;&#26174;&#31034;&#20986;&#26356;&#22909;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#20801;&#35768;&#27169;&#25311;&#26356;&#39640;&#25928;&#30340;IR&#20250;&#35805;&#12290;&#31867;&#20284;&#22320;&#65292;&#25105;&#20204;&#30340;&#35780;&#20272;&#32771;&#34385;&#20102;&#27604;&#24403;&#21069;&#22522;&#20110;&#20250;&#35805;&#30340;&#24230;&#37327;&#26356;&#22810;&#30340;&#20132;&#20114;&#19978;&#19979;&#25991;&#65292;&#24182;&#22312;&#24050;&#24314;&#31435;&#30340;&#35780;&#20272;&#36807;&#31243;&#20013;&#25581;&#31034;&#20102;&#26377;&#36259;&#30340;&#34917;&#20805;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulating user interactions enables a more user-oriented evaluation of information retrieval (IR) systems. While user simulations are cost-efficient and reproducible, many approaches often lack fidelity regarding real user behavior. Most notably, current user models neglect the user's context, which is the primary driver of perceived relevance and the interactions with the search results. To this end, this work introduces the simulation of context-driven query reformulations. The proposed query generation methods build upon recent Large Language Model (LLM) approaches and consider the user's context throughout the simulation of a search session. Compared to simple context-free query generation approaches, these methods show better effectiveness and allow the simulation of more efficient IR sessions. Similarly, our evaluations consider more interaction context than current session-based measures and reveal interesting complementary insights in addition to the established evaluation pro
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#33258;&#25105;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#36127;&#38754;&#21453;&#39304;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#39034;&#24207;&#38899;&#20048;&#25512;&#33616;&#30340;Transformer&#27169;&#22411;&#65292;&#24182;&#37319;&#29992;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#26469;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.11623</link><description>&lt;p&gt;
&#21033;&#29992;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#23545;&#36830;&#32493;&#38899;&#20048;&#25512;&#33616;&#36827;&#34892;&#36127;&#38754;&#20449;&#21495;&#30340;&#21033;&#29992;
&lt;/p&gt;
&lt;p&gt;
Leveraging Negative Signals with Self-Attention for Sequential Music Recommendation. (arXiv:2309.11623v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11623
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#33258;&#25105;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#36127;&#38754;&#21453;&#39304;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#39034;&#24207;&#38899;&#20048;&#25512;&#33616;&#30340;Transformer&#27169;&#22411;&#65292;&#24182;&#37319;&#29992;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#26469;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#20208;&#36182;&#20854;&#25512;&#33616;&#24341;&#25806;&#36830;&#32493;&#21521;&#29992;&#25143;&#25552;&#20379;&#20869;&#23481;&#12290;&#22240;&#27492;&#65292;&#39034;&#24207;&#25512;&#33616;&#24050;&#32463;&#24341;&#36215;&#20102;&#24403;&#21069;&#25991;&#29486;&#30340;&#30456;&#24403;&#20851;&#27880;&#65292;&#32780;&#24403;&#20170;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#65288;&#22914;&#38271;&#26399;&#21644;&#30701;&#26399;&#29992;&#25143;&#21382;&#21490;&#21644;&#39033;&#30446;&#29305;&#24449;&#65289;&#30340;&#33258;&#25105;&#20851;&#27880;&#27169;&#22411;&#19978;&#65307;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#38598;&#20013;&#22312;&#38271;&#26684;&#24335;&#20869;&#23481;&#39046;&#22495;&#65288;&#38646;&#21806;&#12289;&#30005;&#24433;&#31561;&#65289;&#32780;&#19981;&#26159;&#30701;&#26684;&#24335;&#65292;&#20363;&#22914;&#38899;&#20048;&#12290;&#27492;&#22806;&#65292;&#35768;&#22810;&#30740;&#31350;&#26410;&#25506;&#32034;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#22914;&#20309;&#34701;&#20837;&#36127;&#38754;&#20250;&#35805;&#32423;&#21453;&#39304;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;Transformer&#30340;&#33258;&#25105;&#20851;&#27880;&#20307;&#31995;&#32467;&#26500;&#65292;&#20197;&#23398;&#20064;&#29992;&#20110;&#39034;&#24207;&#38899;&#20048;&#25512;&#33616;&#30340;&#38544;&#24335;&#20250;&#35805;&#32423;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#65292;&#20197;&#34701;&#20837;&#36127;&#38754;&#21453;&#39304;&#65288;&#20363;&#22914;&#36339;&#36807;&#30340;&#26354;&#30446;&#65289;&#20197;&#20419;&#36827;&#27491;&#38754;&#21629;&#20013;&#24182;&#24809;&#32602;&#36127;&#38754;&#21629;&#20013;&#12290;&#36825;&#20010;&#20219;&#21153;&#34987;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#31616;&#21333;&#30340;&#25439;&#22833;&#39033;&#65292;&#21487;&#20197;&#21152;&#20837;&#21040;&#35757;&#32451;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Music streaming services heavily rely on their recommendation engines to continuously provide content to their consumers. Sequential recommendation consequently has seen considerable attention in current literature, where state of the art approaches focus on self-attentive models leveraging contextual information such as long and short-term user history and item features; however, most of these studies focus on long-form content domains (retail, movie, etc.) rather than short-form, such as music. Additionally, many do not explore incorporating negative session-level feedback during training. In this study, we investigate the use of transformer-based self-attentive architectures to learn implicit session-level information for sequential music recommendation. We additionally propose a contrastive learning task to incorporate negative feedback (e.g skipped tracks) to promote positive hits and penalize negative hits. This task is formulated as a simple loss term that can be incorporated in
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#32508;&#36848;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#25429;&#25417;&#19978;&#19979;&#25991;&#20449;&#21495;&#21644;&#35821;&#20041;&#32454;&#24494;&#20043;&#22788;&#26041;&#38754;&#30340;&#20248;&#21183;&#21644;&#25361;&#25112;&#65292;&#20197;&#21450;&#19982;&#20256;&#32479;&#26816;&#32034;&#26041;&#27861;&#30340;&#32467;&#21512;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.07107</link><description>&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Large Language Models for Information Retrieval: A Survey. (arXiv:2308.07107v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#32508;&#36848;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#25429;&#25417;&#19978;&#19979;&#25991;&#20449;&#21495;&#21644;&#35821;&#20041;&#32454;&#24494;&#20043;&#22788;&#26041;&#38754;&#30340;&#20248;&#21183;&#21644;&#25361;&#25112;&#65292;&#20197;&#21450;&#19982;&#20256;&#32479;&#26816;&#32034;&#26041;&#27861;&#30340;&#32467;&#21512;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#20449;&#24687;&#33719;&#21462;&#30340;&#20027;&#35201;&#25163;&#27573;&#65292;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#31995;&#32479;&#65292;&#22914;&#25628;&#32034;&#24341;&#25806;&#65292;&#24050;&#32463;&#34701;&#20837;&#21040;&#25105;&#20204;&#30340;&#26085;&#24120;&#29983;&#27963;&#20013;&#12290;&#36825;&#20123;&#31995;&#32479;&#36824;&#20316;&#20026;&#23545;&#35805;&#12289;&#38382;&#31572;&#21644;&#25512;&#33616;&#31995;&#32479;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;IR&#30340;&#21457;&#23637;&#36712;&#36857;&#20174;&#22522;&#20110;&#35789;&#39033;&#30340;&#26041;&#27861;&#36215;&#27493;&#65292;&#36880;&#28176;&#21457;&#23637;&#25104;&#19982;&#20808;&#36827;&#30340;&#31070;&#32463;&#27169;&#22411;&#30456;&#34701;&#21512;&#12290;&#23613;&#31649;&#31070;&#32463;&#27169;&#22411;&#25797;&#38271;&#25429;&#25417;&#22797;&#26434;&#30340;&#19978;&#19979;&#25991;&#20449;&#21495;&#21644;&#35821;&#20041;&#32454;&#24494;&#20043;&#22788;&#65292;&#20174;&#32780;&#25913;&#21464;&#20102;IR&#30340;&#26684;&#23616;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#38754;&#20020;&#30528;&#25968;&#25454;&#31232;&#32570;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#29983;&#25104;&#19978;&#19979;&#25991;&#21512;&#29702;&#20294;&#28508;&#22312;&#19981;&#20934;&#30830;&#21709;&#24212;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#28436;&#21464;&#38656;&#35201;&#20256;&#32479;&#26041;&#27861;&#65288;&#22914;&#22522;&#20110;&#35789;&#39033;&#30340;&#31232;&#30095;&#26816;&#32034;&#26041;&#27861;&#19982;&#24555;&#36895;&#21709;&#24212;&#65289;&#21644;&#29616;&#20195;&#31070;&#32463;&#26550;&#26500;&#65288;&#22914;&#20855;&#26377;&#24378;&#22823;&#35821;&#35328;&#29702;&#35299;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#65289;&#30340;&#32467;&#21512;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#21644;GPT-4&#30340;&#20986;&#29616;&#65292;&#24341;&#36215;&#20102;&#19968;&#22330;&#38761;&#21629;
&lt;/p&gt;
&lt;p&gt;
As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolu
&lt;/p&gt;</description></item></channel></rss>