<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;ChatGPT&#21644;&#35828;&#26381;&#25216;&#26415;&#24212;&#29992;&#20110;&#37202;&#24215;&#25512;&#33616;&#31995;&#32479;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;ChatGPT&#21487;&#20197;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#25512;&#33616;&#65292;&#32780;&#35828;&#26381;&#25216;&#26415;&#21487;&#24433;&#21709;&#29992;&#25143;&#34892;&#20026;&#24182;&#22686;&#24378;&#25512;&#33616;&#30340;&#35828;&#26381;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.14298</link><description>&lt;p&gt;
ChatGPT&#21644;&#35828;&#26381;&#25216;&#26415;&#22312;&#37202;&#24215;&#26381;&#21153;&#39046;&#22495;&#20010;&#24615;&#21270;&#25512;&#33616;&#31649;&#29702;&#21644;&#25552;&#20379;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality. (arXiv:2307.14298v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;ChatGPT&#21644;&#35828;&#26381;&#25216;&#26415;&#24212;&#29992;&#20110;&#37202;&#24215;&#25512;&#33616;&#31995;&#32479;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;ChatGPT&#21487;&#20197;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#25512;&#33616;&#65292;&#32780;&#35828;&#26381;&#25216;&#26415;&#21487;&#24433;&#21709;&#29992;&#25143;&#34892;&#20026;&#24182;&#22686;&#24378;&#25512;&#33616;&#30340;&#35828;&#26381;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#37202;&#24215;&#26381;&#21153;&#19994;&#24050;&#25104;&#20026;&#19981;&#21487;&#25110;&#32570;&#30340;&#24037;&#20855;&#65292;&#20026;&#23458;&#20154;&#25552;&#20379;&#20010;&#24615;&#21270;&#21644;&#23450;&#21046;&#21270;&#30340;&#20307;&#39564;&#12290;&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#22914;ChatGPT&#21644;&#35828;&#26381;&#25216;&#26415;&#30340;&#36827;&#27493;&#65292;&#20026;&#25552;&#21319;&#36825;&#20123;&#31995;&#32479;&#30340;&#25928;&#26524;&#25171;&#24320;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;ChatGPT&#21644;&#35828;&#26381;&#25216;&#26415;&#25972;&#21512;&#21040;&#37202;&#24215;&#26381;&#21153;&#25512;&#33616;&#31995;&#32479;&#20013;&#33258;&#21160;&#21270;&#21644;&#25913;&#36827;&#30340;&#28508;&#21147;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#20102;ChatGPT&#30340;&#33021;&#21147;&#65292;&#23427;&#21487;&#20197;&#29702;&#35299;&#21644;&#29983;&#25104;&#31867;&#20284;&#20154;&#31867;&#30340;&#25991;&#26412;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#20934;&#30830;&#21644;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#23558;ChatGPT&#25972;&#21512;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#33021;&#21147;&#65292;&#31361;&#20986;&#20102;&#20854;&#20998;&#26512;&#29992;&#25143;&#20559;&#22909;&#12289;&#20174;&#22312;&#32447;&#35780;&#35770;&#20013;&#25552;&#21462;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#65292;&#24182;&#26681;&#25454;&#23458;&#20154;&#37197;&#32622;&#29983;&#25104;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#33021;&#21147;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#35828;&#26381;&#25216;&#26415;&#22312;&#24433;&#21709;&#29992;&#25143;&#34892;&#20026;&#21644;&#25552;&#21319;&#37202;&#24215;&#25512;&#33616;&#30340;&#35828;&#26381;&#25928;&#26524;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests. Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies, have opened new avenues for enhancing the effectiveness of those systems. This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems. First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations. We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles. Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recomm
&lt;/p&gt;</description></item><item><title>&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20919;&#21551;&#21160;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#19982;&#22522;&#20110;&#39033;&#30446;&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#26041;&#27861;&#30456;&#24403;&#30340;&#25512;&#33616;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#32431;&#22522;&#20110;&#35821;&#35328;&#20559;&#22909;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2307.14225</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#20919;&#21551;&#21160;&#25512;&#33616;&#31995;&#32479;&#20013;&#19982;&#22522;&#20110;&#35821;&#35328;&#21644;&#22522;&#20110;&#39033;&#30446;&#20559;&#22909;&#31454;&#20105;&#21147;&#30456;&#24403;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences. (arXiv:2307.14225v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14225
&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20919;&#21551;&#21160;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#19982;&#22522;&#20110;&#39033;&#30446;&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#26041;&#27861;&#30456;&#24403;&#30340;&#25512;&#33616;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#32431;&#22522;&#20110;&#35821;&#35328;&#20559;&#22909;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25512;&#33616;&#31995;&#32479;&#21033;&#29992;&#29992;&#25143;&#30340;&#39033;&#30446;&#20559;&#22909;&#21382;&#21490;&#26469;&#25512;&#33616;&#29992;&#25143;&#21487;&#33021;&#21916;&#27426;&#30340;&#26032;&#20869;&#23481;&#12290;&#28982;&#32780;&#65292;&#29616;&#20195;&#23545;&#35805;&#30028;&#38754;&#20801;&#35768;&#29992;&#25143;&#34920;&#36798;&#22522;&#20110;&#35821;&#35328;&#30340;&#20559;&#22909;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26681;&#26412;&#19981;&#21516;&#30340;&#20559;&#22909;&#36755;&#20837;&#26041;&#24335;&#12290;&#21463;&#26368;&#36817;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25552;&#31034;&#33539;&#24335;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23427;&#20204;&#22312;&#22522;&#20110;&#39033;&#30446;&#21644;&#22522;&#20110;&#35821;&#35328;&#20559;&#22909;&#26041;&#38754;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#39033;&#30446;&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#26041;&#27861;&#30456;&#27604;&#30340;&#25512;&#33616;&#24212;&#29992;&#12290;&#20026;&#20102;&#25903;&#25345;&#36825;&#39033;&#30740;&#31350;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#20174;&#29992;&#25143;&#37027;&#37324;&#24341;&#21457;&#20986;&#26469;&#30340;&#22522;&#20110;&#39033;&#30446;&#21644;&#22522;&#20110;&#35821;&#35328;&#20559;&#22909;&#65292;&#20197;&#21450;&#20182;&#20204;&#23545;&#21508;&#31181;&#65288;&#26377;&#20559;&#35265;&#30340;&#65289;&#25512;&#33616;&#39033;&#30446;&#21644;&#65288;&#26080;&#20559;&#35265;&#30340;&#65289;&#38543;&#26426;&#39033;&#30446;&#30340;&#35780;&#20998;&#12290;&#22312;&#20247;&#22810;&#23454;&#39564;&#32467;&#26524;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#32431;&#22522;&#20110;&#35821;&#35328;&#20559;&#22909;&#65288;&#27809;&#26377;&#39033;&#30446;&#20559;&#22909;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;LLMs&#22312;&#25509;&#36817;&#20919;&#21551;&#21160;&#24773;&#20917;&#19979;&#19982;&#22522;&#20110;&#39033;&#30446;&#30340;CF&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional recommender systems leverage users' item preference history to recommend novel content that users may like. However, modern dialog interfaces that allow users to express language-based preferences offer a fundamentally different modality for preference input. Inspired by recent successes of prompting paradigms for large language models (LLMs), we study their use for making recommendations from both item-based and language-based preferences in comparison to state-of-the-art item-based collaborative filtering (CF) methods. To support this investigation, we collect a new dataset consisting of both item-based and language-based preferences elicited from users along with their ratings on a variety of (biased) recommended items and (unbiased) random items. Among numerous experimental results, we find that LLMs provide competitive recommendation performance for pure language-based preferences (no item preferences) in the near cold-start case in comparison to item-based CF methods,
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#20301;&#32622;&#20559;&#24046;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#30701;&#35270;&#39057;&#25512;&#33616;&#20013;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#27169;&#22411;&#32771;&#34385;&#20102;&#29992;&#25143;&#22312;&#27983;&#35272;&#35270;&#39057;&#26102;&#30340;&#34892;&#20026;&#29305;&#28857;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#27599;&#20010;&#35270;&#39057;&#30340;&#26333;&#20809;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.14059</link><description>&lt;p&gt;
&#19968;&#31181;&#27010;&#29575;&#20301;&#32622;&#20559;&#24046;&#27169;&#22411;&#29992;&#20110;&#30701;&#35270;&#39057;&#25512;&#33616;&#20013;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Position Bias Model for Short-Video Recommendation Feeds. (arXiv:2307.14059v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#20301;&#32622;&#20559;&#24046;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#30701;&#35270;&#39057;&#25512;&#33616;&#20013;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#27169;&#22411;&#32771;&#34385;&#20102;&#29992;&#25143;&#22312;&#27983;&#35272;&#35270;&#39057;&#26102;&#30340;&#34892;&#20026;&#29305;&#28857;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#27599;&#20010;&#35270;&#39057;&#30340;&#26333;&#20809;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20195;&#22522;&#20110;&#32593;&#32476;&#30340;&#24179;&#21488;&#21521;&#29992;&#25143;&#23637;&#31034;&#25490;&#21517;&#21015;&#34920;&#30340;&#25512;&#33616;&#20869;&#23481;&#65292;&#20197;&#23581;&#35797;&#26368;&#22823;&#21270;&#29992;&#25143;&#28385;&#24847;&#24230;&#25110;&#19994;&#21153;&#25351;&#26631;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#30446;&#26631;&#36890;&#24120;&#26159;&#26368;&#22823;&#21270;&#34987;&#35748;&#20026;&#26159;&#8220;&#26368;&#22823;&#21270;&#22870;&#21169;&#8221;&#30340;&#39033;&#30446;&#30340;&#26333;&#20809;&#27010;&#29575;&#12290;&#36825;&#20010;&#36890;&#29992;&#26694;&#26550;&#21253;&#25324;&#27969;&#23186;&#20307;&#24212;&#29992;&#12289;&#30005;&#23376;&#21830;&#21153;&#25110;&#32844;&#20301;&#25512;&#33616;&#65292;&#29978;&#33267;&#32593;&#32476;&#25628;&#32034;&#12290;&#22312;&#27599;&#31181;&#29992;&#20363;&#20013;&#65292;&#21487;&#20197;&#20351;&#29992;&#20301;&#32622;&#20559;&#24046;&#25110;&#29992;&#25143;&#27169;&#22411;&#26469;&#20272;&#35745;&#26333;&#20809;&#27010;&#29575;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#19982;&#23637;&#31034;&#30340;&#25490;&#21517;&#30340;&#20114;&#21160;&#26041;&#24335;&#36827;&#34892;&#29305;&#23450;&#35843;&#25972;&#12290;&#36825;&#20123;&#19981;&#21516;&#30340;&#38382;&#39064;&#35774;&#32622;&#20013;&#30340;&#19968;&#20010;&#32479;&#19968;&#22240;&#32032;&#26159;&#65292;&#36890;&#24120;&#21482;&#26377;&#19968;&#20010;&#25110;&#20960;&#20010;&#39033;&#30446;&#20250;&#22312;&#29992;&#25143;&#31163;&#24320;&#25490;&#24207;&#21015;&#34920;&#20043;&#21069;&#34987;&#21442;&#19982;&#65288;&#28857;&#20987;&#12289;&#27969;&#23186;&#20307;&#31561;&#65289;&#12290;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#30340;&#30701;&#35270;&#39057;&#25512;&#36865;&#22312;&#20960;&#20010;&#26041;&#38754;&#19982;&#36825;&#31181;&#19968;&#33324;&#26694;&#26550;&#19981;&#21516;&#65292;&#26368;&#37325;&#35201;&#30340;&#26159;&#29992;&#25143;&#22312;&#28857;&#36190;&#19968;&#31687;&#24086;&#23376;&#21518;&#36890;&#24120;&#19981;&#20250;&#31163;&#24320;&#25512;&#36865;&#12290;&#23454;&#38469;&#19978;&#65292;&#30475;&#20284;&#26080;&#38480;&#30340;&#25512;&#36865;&#24341;&#23548;&#29992;&#25143;&#28378;&#21160;&#27983;&#35272;&#35270;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern web-based platforms show ranked lists of recommendations to users, attempting to maximise user satisfaction or business metrics. Typically, the goal of such systems boils down to maximising the exposure probability for items that are deemed "reward-maximising" according to a metric of interest. This general framing comprises streaming applications, as well as e-commerce or job recommendations, and even web search. Position bias or user models can be used to estimate exposure probabilities for each use-case, specifically tailored to how users interact with the presented rankings. A unifying factor in these diverse problem settings is that typically only one or several items will be engaged with (clicked, streamed,...) before a user leaves the ranked list. Short-video feeds on social media platforms diverge from this general framing in several ways, most notably that users do not tend to leave the feed after e.g. liking a post. Indeed, seemingly infinite feeds invite users to scro
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#22270;&#36229;&#22270;&#23545;&#27604;&#31574;&#30053;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#26041;&#27861;&#32508;&#21512;&#32771;&#34385;&#20102;&#29992;&#25143;&#30340;&#21916;&#27426;&#12289;&#31038;&#20132;&#21644;&#19981;&#21916;&#27426;&#19977;&#20010;&#35270;&#22270;&#65292;&#24182;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#65292;&#20174;&#32780;&#25552;&#39640;&#20250;&#35805;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.14024</link><description>&lt;p&gt;
&#22810;&#35270;&#22270;&#36229;&#22270;&#23545;&#27604;&#31574;&#30053;&#23398;&#20064;&#22312;&#20250;&#35805;&#25512;&#33616;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multi-view Hypergraph Contrastive Policy Learning for Conversational Recommendation. (arXiv:2307.14024v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14024
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#22270;&#36229;&#22270;&#23545;&#27604;&#31574;&#30053;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#26041;&#27861;&#32508;&#21512;&#32771;&#34385;&#20102;&#29992;&#25143;&#30340;&#21916;&#27426;&#12289;&#31038;&#20132;&#21644;&#19981;&#21916;&#27426;&#19977;&#20010;&#35270;&#22270;&#65292;&#24182;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#65292;&#20174;&#32780;&#25552;&#39640;&#20250;&#35805;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#36890;&#36807;&#20132;&#20114;&#24335;&#33719;&#21462;&#29992;&#25143;&#20559;&#22909;&#65292;&#30456;&#24212;&#22320;&#21521;&#29992;&#25143;&#25512;&#33616;&#29289;&#21697;&#12290;&#20934;&#30830;&#23398;&#20064;&#21160;&#24577;&#29992;&#25143;&#20559;&#22909;&#23545;&#20110;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#36890;&#36807;&#20132;&#20114;&#23545;&#35805;&#21644;&#29289;&#21697;&#30693;&#35782;&#20013;&#30340;&#20004;&#20004;&#20851;&#31995;&#26469;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#65292;&#20294;&#24448;&#24448;&#24573;&#35270;&#20102;&#22312;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#20013;&#20851;&#31995;&#30340;&#22797;&#21512;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#29992;&#25143;&#21916;&#27426;/&#19981;&#21916;&#27426;&#28385;&#36275;&#26576;&#20123;&#23646;&#24615;&#30340;&#29289;&#21697;&#65288;&#21916;&#27426;/&#19981;&#21916;&#27426;&#35270;&#22270;&#65289;&#12290;&#27492;&#22806;&#65292;&#31038;&#20132;&#24433;&#21709;&#26159;&#24433;&#21709;&#29992;&#25143;&#23545;&#29289;&#21697;&#30340;&#20559;&#22909;&#30340;&#21478;&#19968;&#20010;&#37325;&#35201;&#22240;&#32032;&#65288;&#31038;&#20132;&#35270;&#22270;&#65289;&#65292;&#20294;&#26159;&#20808;&#21069;&#30340;&#20250;&#35805;&#25512;&#33616;&#31995;&#32479;&#24448;&#24448;&#24573;&#30053;&#20102;&#36825;&#19968;&#22240;&#32032;&#12290;&#36825;&#19977;&#20010;&#35270;&#22270;&#30340;&#29992;&#25143;&#20559;&#22909;&#26412;&#36136;&#19978;&#26159;&#19981;&#21516;&#30340;&#65292;&#20294;&#25972;&#20307;&#19978;&#26159;&#30456;&#20851;&#30340;&#12290;&#30456;&#21516;&#35270;&#22270;&#30340;&#29992;&#25143;&#20559;&#22909;&#24212;&#35813;&#27604;&#19981;&#21516;&#35270;&#22270;&#30340;&#29992;&#25143;&#20559;&#22909;&#26356;&#30456;&#20284;&#12290;&#21916;&#27426;&#35270;&#22270;&#30340;&#29992;&#25143;&#20559;&#22909;&#24212;&#35813;&#19982;&#31038;&#20132;&#35270;&#22270;&#30456;&#20284;&#65292;&#20294;&#19982;&#19981;&#21916;&#27426;&#35270;&#22270;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational recommendation systems (CRS) aim to interactively acquire user preferences and accordingly recommend items to users. Accurately learning the dynamic user preferences is of crucial importance for CRS. Previous works learn the user preferences with pairwise relations from the interactive conversation and item knowledge, while largely ignoring the fact that factors for a relationship in CRS are multiplex. Specifically, the user likes/dislikes the items that satisfy some attributes (Like/Dislike view). Moreover social influence is another important factor that affects user preference towards the item (Social view), while is largely ignored by previous works in CRS. The user preferences from these three views are inherently different but also correlated as a whole. The user preferences from the same views should be more similar than that from different views. The user preferences from Like View should be similar to Social View while different from Dislike View. To this end, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25554;&#20540;&#25968;&#25454;&#22686;&#24378;&#30340;&#35299;&#32544;&#26041;&#27861;&#65288;DIDA-CDR&#65289;&#29992;&#20110;&#21452;&#30446;&#26631;&#36328;&#39046;&#22495;&#25512;&#33616;&#65292;&#26088;&#22312;&#35299;&#20915;&#29983;&#25104;&#30456;&#20851;&#19988;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#29992;&#25143;&#34920;&#31034;&#20197;&#21450;&#26377;&#25928;&#23558;&#39046;&#22495;&#26080;&#20851;&#20449;&#24687;&#19982;&#39046;&#22495;&#29305;&#23450;&#20449;&#24687;&#20998;&#31163;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.13910</link><description>&lt;p&gt;
&#22522;&#20110;&#25554;&#20540;&#25968;&#25454;&#22686;&#24378;&#30340;&#39046;&#22495;&#35299;&#32544;&#26041;&#27861;&#29992;&#20110;&#21452;&#30446;&#26631;&#36328;&#39046;&#22495;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Domain Disentanglement with Interpolative Data Augmentation for Dual-Target Cross-Domain Recommendation. (arXiv:2307.13910v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13910
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25554;&#20540;&#25968;&#25454;&#22686;&#24378;&#30340;&#35299;&#32544;&#26041;&#27861;&#65288;DIDA-CDR&#65289;&#29992;&#20110;&#21452;&#30446;&#26631;&#36328;&#39046;&#22495;&#25512;&#33616;&#65292;&#26088;&#22312;&#35299;&#20915;&#29983;&#25104;&#30456;&#20851;&#19988;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#29992;&#25143;&#34920;&#31034;&#20197;&#21450;&#26377;&#25928;&#23558;&#39046;&#22495;&#26080;&#20851;&#20449;&#24687;&#19982;&#39046;&#22495;&#29305;&#23450;&#20449;&#24687;&#20998;&#31163;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#21333;&#30446;&#26631;&#36328;&#39046;&#22495;&#25512;&#33616;&#26088;&#22312;&#36890;&#36807;&#20174;&#21253;&#21547;&#30456;&#23545;&#20016;&#23500;&#20449;&#24687;&#30340;&#28304;&#39046;&#22495;&#36716;&#31227;&#30693;&#35782;&#26469;&#25913;&#36827;&#22312;&#31232;&#30095;&#30446;&#26631;&#39046;&#22495;&#20013;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#36817;&#24180;&#26469;&#25552;&#20986;&#20102;&#21452;&#30446;&#26631;&#36328;&#39046;&#22495;&#25512;&#33616;&#26469;&#21516;&#26102;&#25552;&#39640;&#20004;&#20010;&#39046;&#22495;&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#21452;&#30446;&#26631;&#36328;&#39046;&#22495;&#25512;&#33616;&#20013;&#23384;&#22312;&#20004;&#20010;&#25361;&#25112;&#65306;1&#65289;&#22914;&#20309;&#29983;&#25104;&#30456;&#20851;&#19988;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#29992;&#25143;&#34920;&#31034;&#65307;2&#65289;&#22914;&#20309;&#26377;&#25928;&#22320;&#23558;&#39046;&#22495;&#26080;&#20851;&#20449;&#24687;&#19982;&#39046;&#22495;&#29305;&#23450;&#20449;&#24687;&#20998;&#31163;&#24320;&#26469;&#65292;&#20197;&#25429;&#25417;&#20840;&#38754;&#30340;&#29992;&#25143;&#20559;&#22909;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#20004;&#20010;&#25361;&#25112;&#65292;&#22312;&#26412;&#25991;&#20013;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35299;&#32544;&#21644;&#25554;&#20540;&#25968;&#25454;&#22686;&#24378;&#30340;&#21452;&#30446;&#26631;&#36328;&#39046;&#22495;&#25512;&#33616;&#26694;&#26550;&#65292;&#31216;&#20026;DIDA-CDR&#12290;
&lt;/p&gt;
&lt;p&gt;
The conventional single-target Cross-Domain Recommendation (CDR) aims to improve the recommendation performance on a sparser target domain by transferring the knowledge from a source domain that contains relatively richer information. By contrast, in recent years, dual-target CDR has been proposed to improve the recommendation performance on both domains simultaneously. However, to this end, there are two challenges in dual-target CDR: (1) how to generate both relevant and diverse augmented user representations, and (2) how to effectively decouple domain-independent information from domain-specific information, in addition to domain-shared information, to capture comprehensive user preferences. To address the above two challenges, we propose a Disentanglement-based framework with Interpolative Data Augmentation for dual-target Cross-Domain Recommendation, called DIDA-CDR. In DIDA-CDR, we first propose an interpolative data augmentation approach to generating both relevant and diverse a
&lt;/p&gt;</description></item><item><title>ClusterSeq&#26159;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#20803;&#23398;&#20064;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#24207;&#21015;&#30340;&#21160;&#24577;&#20449;&#24687;&#25552;&#39640;&#20102;&#29289;&#21697;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#20445;&#30041;&#20102;&#27425;&#35201;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#24182;&#21033;&#29992;&#20102;&#21516;&#19968;&#32858;&#31867;&#20013;&#29992;&#25143;&#30340;&#38598;&#20307;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2307.13766</link><description>&lt;p&gt;
ClusterSeq: &#29992;&#22522;&#20110;&#32858;&#31867;&#30340;&#20803;&#23398;&#20064;&#22686;&#24378;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
ClusterSeq: Enhancing Sequential Recommender Systems with Clustering based Meta-Learning. (arXiv:2307.13766v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13766
&lt;/p&gt;
&lt;p&gt;
ClusterSeq&#26159;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#20803;&#23398;&#20064;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#24207;&#21015;&#30340;&#21160;&#24577;&#20449;&#24687;&#25552;&#39640;&#20102;&#29289;&#21697;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#20445;&#30041;&#20102;&#27425;&#35201;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#24182;&#21033;&#29992;&#20102;&#21516;&#19968;&#32858;&#31867;&#20013;&#29992;&#25143;&#30340;&#38598;&#20307;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#21463;&#21040;&#20102;&#29992;&#25143;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#38480;&#21046;&#65292;&#36825;&#26159;&#30001;&#20110;&#26377;&#38480;&#30340;&#20132;&#20114;&#20351;&#24471;&#26080;&#27861;&#20934;&#30830;&#30830;&#23450;&#29992;&#25143;&#30340;&#20559;&#22909;&#12290;&#20197;&#21069;&#30340;&#30740;&#31350;&#35797;&#22270;&#36890;&#36807;&#23558;&#20803;&#23398;&#20064;&#19982;&#29992;&#25143;&#21644;&#29289;&#21697;&#20391;&#20449;&#24687;&#30456;&#32467;&#21512;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#24314;&#27169;&#29992;&#25143;&#20559;&#22909;&#21160;&#24577;&#26041;&#38754;&#38754;&#20020;&#30528;&#22266;&#26377;&#30340;&#25361;&#25112;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#23637;&#29616;&#20986;&#19982;&#26356;&#24120;&#35265;&#25110;&#8220;&#20027;&#35201;&#29992;&#25143;&#8221;&#19981;&#21516;&#20559;&#22909;&#30340;&#8220;&#27425;&#35201;&#29992;&#25143;&#8221;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;ClusterSeq&#65292;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#20803;&#23398;&#20064;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#12290;ClusterSeq&#21033;&#29992;&#29992;&#25143;&#24207;&#21015;&#20013;&#30340;&#21160;&#24577;&#20449;&#24687;&#26469;&#25552;&#39640;&#29289;&#21697;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#21363;&#20351;&#27809;&#26377;&#20391;&#20449;&#24687;&#12290;&#35813;&#27169;&#22411;&#20445;&#30041;&#20102;&#27425;&#35201;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#32780;&#19981;&#20250;&#34987;&#20027;&#35201;&#29992;&#25143;&#25152;&#25513;&#30422;&#65292;&#24182;&#21033;&#29992;&#20102;&#21516;&#19968;&#32858;&#31867;&#20013;&#29992;&#25143;&#30340;&#38598;&#20307;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
In practical scenarios, the effectiveness of sequential recommendation systems is hindered by the user cold-start problem, which arises due to limited interactions for accurately determining user preferences. Previous studies have attempted to address this issue by combining meta-learning with user and item-side information. However, these approaches face inherent challenges in modeling user preference dynamics, particularly for "minor users" who exhibit distinct preferences compared to more common or "major users." To overcome these limitations, we present a novel approach called ClusterSeq, a Meta-Learning Clustering-Based Sequential Recommender System. ClusterSeq leverages dynamic information in the user sequence to enhance item prediction accuracy, even in the absence of side information. This model preserves the preferences of minor users without being overshadowed by major users, and it capitalizes on the collective knowledge of users within the same cluster. Extensive experiment
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#38899;&#20048;&#21457;&#29616;&#24212;&#29992;&#20013;&#30340;&#25968;&#25454;&#21457;&#29616;&#65292;&#35780;&#20998;&#33192;&#32960;&#38382;&#39064;&#26469;&#28304;&#20110;&#24322;&#36136;&#30340;&#29992;&#25143;&#35780;&#20998;&#34892;&#20026;&#21644;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#21160;&#24577;&#65292;&#36890;&#36807;&#20462;&#25913;&#35780;&#20998;&#30028;&#38754;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#36825;&#19968;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.12424</link><description>&lt;p&gt;
&#25509;&#21475;&#35774;&#35745;&#20197;&#32531;&#35299;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#35780;&#20998;&#33192;&#32960;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Interface Design to Mitigate Inflation in Recommender Systems. (arXiv:2307.12424v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#38899;&#20048;&#21457;&#29616;&#24212;&#29992;&#20013;&#30340;&#25968;&#25454;&#21457;&#29616;&#65292;&#35780;&#20998;&#33192;&#32960;&#38382;&#39064;&#26469;&#28304;&#20110;&#24322;&#36136;&#30340;&#29992;&#25143;&#35780;&#20998;&#34892;&#20026;&#21644;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#21160;&#24577;&#65292;&#36890;&#36807;&#20462;&#25913;&#35780;&#20998;&#30028;&#38754;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20381;&#36182;&#29992;&#25143;&#25552;&#20379;&#30340;&#25968;&#25454;&#26469;&#23398;&#20064;&#29289;&#21697;&#36136;&#37327;&#24182;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#22312;&#23558;&#35780;&#20998;&#32858;&#21512;&#20026;&#29289;&#21697;&#36136;&#37327;&#26102;&#65292;&#39044;&#35774;&#20102;&#35780;&#20998;&#26159;&#29289;&#21697;&#36136;&#37327;&#30340;&#24378;&#26377;&#21147;&#25351;&#26631;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#20174;&#38899;&#20048;&#21457;&#29616;&#24212;&#29992;&#20013;&#25910;&#38598;&#30340;&#25968;&#25454;&#26469;&#27979;&#35797;&#36825;&#20010;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#20004;&#20010;&#23548;&#33268;&#35780;&#20998;&#33192;&#32960;&#30340;&#22240;&#32032;&#19978;&#65306;&#24322;&#36136;&#30340;&#29992;&#25143;&#35780;&#20998;&#34892;&#20026;&#21644;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#21160;&#24577;&#12290;&#25105;&#20204;&#26174;&#31034;&#20986;&#29992;&#25143;&#35780;&#20998;&#34892;&#20026;&#22312;&#29992;&#25143;&#20043;&#38388;&#23384;&#22312;&#36739;&#22823;&#24046;&#24322;&#65292;&#23548;&#33268;&#29289;&#21697;&#36136;&#37327;&#20272;&#35745;&#26356;&#22810;&#21453;&#26144;&#20102;&#35780;&#20998;&#29992;&#25143;&#32780;&#19981;&#26159;&#29289;&#21697;&#26412;&#36523;&#30340;&#36136;&#37327;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20010;&#24615;&#21270;&#25512;&#33616;&#26356;&#26377;&#21487;&#33021;&#23637;&#31034;&#30340;&#29289;&#21697;&#21487;&#33021;&#20250;&#32463;&#21382;&#22823;&#24133;&#22686;&#21152;&#30340;&#26333;&#20809;&#65292;&#24182;&#26377;&#28508;&#22312;&#30340;&#20559;&#22909;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#24433;&#21709;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#35780;&#20998;&#30028;&#38754;&#20462;&#25913;&#30340;&#32467;&#26524;&#12290;&#27979;&#35797;&#32467;&#26524;&#26174;&#31034;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation systems rely on user-provided data to learn about item quality and provide personalized recommendations. An implicit assumption when aggregating ratings into item quality is that ratings are strong indicators of item quality. In this work, we test this assumption using data collected from a music discovery application. Our study focuses on two factors that cause rating inflation: heterogeneous user rating behavior and the dynamics of personalized recommendations. We show that user rating behavior substantially varies by user, leading to item quality estimates that reflect the users who rated an item more than the item quality itself. Additionally, items that are more likely to be shown via personalized recommendations can experience a substantial increase in their exposure and potential bias toward them. To mitigate these effects, we analyze the results of a randomized controlled trial in which the rating interface was modified. The test resulted in a substantial improve
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Bert4XMR&#30340;&#26032;&#22411;&#36328;&#24066;&#22330;&#25512;&#33616;&#27169;&#22411;&#65292;&#33021;&#22815;&#24314;&#27169;&#19981;&#21516;&#24066;&#22330;&#30340;&#29289;&#21697;&#20849;&#29616;&#24615;&#65292;&#24182;&#20943;&#36731;&#36127;&#36801;&#31227;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15145</link><description>&lt;p&gt;
Bert4XMR: &#20351;&#29992;Transformer&#20013;&#30340;&#21452;&#21521;&#32534;&#30721;&#22120;&#34920;&#31034;&#36827;&#34892;&#36328;&#24066;&#22330;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Bert4XMR: Cross-Market Recommendation with Bidirectional Encoder Representations from Transformer. (arXiv:2305.15145v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15145
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Bert4XMR&#30340;&#26032;&#22411;&#36328;&#24066;&#22330;&#25512;&#33616;&#27169;&#22411;&#65292;&#33021;&#22815;&#24314;&#27169;&#19981;&#21516;&#24066;&#22330;&#30340;&#29289;&#21697;&#20849;&#29616;&#24615;&#65292;&#24182;&#20943;&#36731;&#36127;&#36801;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#30340;&#36328;&#22269;&#30005;&#21830;&#20844;&#21496;&#65292;&#22914;&#20122;&#39532;&#36874;&#21644;eBay&#65292;&#26381;&#21153;&#20110;&#22810;&#20010;&#22269;&#23478;&#21644;&#22320;&#21306;&#12290;&#19968;&#20123;&#24066;&#22330;&#30340;&#25968;&#25454;&#31232;&#32570;&#65292;&#32780;&#20854;&#20182;&#24066;&#22330;&#30340;&#25968;&#25454;&#20016;&#23500;&#12290;&#36817;&#24180;&#26469;&#65292;&#36328;&#24066;&#22330;&#25512;&#33616;&#65288;XMR&#65289;&#24050;&#32463;&#25552;&#20986;&#65292;&#36890;&#36807;&#21033;&#29992;&#26469;&#33258;&#25968;&#25454;&#20016;&#23500;&#24066;&#22330;&#30340;&#36741;&#21161;&#20449;&#24687;&#26469;&#22686;&#24378;&#25968;&#25454;&#31232;&#32570;&#24066;&#22330;&#12290;&#20808;&#21069;&#30340;XMR&#31639;&#27861;&#37319;&#29992;&#20102;&#20849;&#20139;&#24213;&#23618;&#25110;&#25972;&#21512;&#24066;&#22330;&#38388;&#30456;&#20284;&#24615;&#31561;&#25216;&#26415;&#26469;&#20248;&#21270;XMR&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#38480;&#21046;&#65306;&#65288;1&#65289;&#24573;&#30053;&#20102;&#25968;&#25454;&#20016;&#23500;&#24066;&#22330;&#25552;&#20379;&#30340;&#29289;&#21697;&#20849;&#29616;&#24615;&#65307;&#65288;2&#65289;&#27809;&#26377;&#20805;&#20998;&#35299;&#20915;&#19981;&#21516;&#24066;&#22330;&#20043;&#38388;&#30340;&#24046;&#24322;&#23548;&#33268;&#30340;&#36127;&#36801;&#31227;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;&#27169;&#22411;&#65292;&#31216;&#20026;Bert4XMR&#65292;&#23427;&#33021;&#22815;&#23545;&#19981;&#21516;&#24066;&#22330;&#30340;&#29289;&#21697;&#20849;&#29616;&#24615;&#36827;&#34892;&#24314;&#27169;&#21644;&#32531;&#35299;&#36127;&#36801;&#31227;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37319;&#29992;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#30340;&#33539;&#24335;&#26469;&#20419;&#36827;&#27169;&#22411;&#30340;&#23398;&#20064;&#21644;&#24615;&#33021;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world multinational e-commerce companies, such as Amazon and eBay, serve in multiple countries and regions. Some markets are data-scarce, while others are data-rich. In recent years, cross-market recommendation (XMR) has been proposed to bolster data-scarce markets by leveraging auxiliary information from data-rich markets. Previous XMR algorithms have employed techniques such as sharing bottom or incorporating inter-market similarity to optimize the performance of XMR. However, the existing approaches suffer from two crucial limitations: (1) They ignore the co-occurrences of items provided by data-rich markets. (2) They do not adequately tackle the issue of negative transfer stemming from disparities across diverse markets. In order to address these limitations, we propose a novel session-based model called Bert4XMR, which is able to model item co-occurrences across markets and mitigate negative transfer. Specifically, we employ the pre-training and fine-tuning paradigm to facili
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#36229;&#22270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#23618;&#23545;&#35805;&#25512;&#33616;&#27169;&#22411;&#65292;&#20854;&#20013;&#23548;&#28436;&#36890;&#36807;&#36229;&#22270;&#31639;&#27861;&#36827;&#34892;&#36873;&#25321;&#65292;&#24110;&#21161;&#28436;&#21592;&#20943;&#23569;&#34892;&#21160;&#31354;&#38388;&#21644;&#25351;&#23548;&#23545;&#35805;&#26397;&#30528;&#26368;&#20855;&#20449;&#24687;&#24615;&#30340;&#23646;&#24615;&#26041;&#21521;&#36827;&#34892;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#22312;&#23545;&#35805;&#20013;&#30340;&#20559;&#22909;&#36873;&#25321;&#29289;&#21697;&#12290;</title><link>http://arxiv.org/abs/2305.02575</link><description>&lt;p&gt;
&#22522;&#20110;&#36229;&#22270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#23618;&#23545;&#35805;&#25512;&#33616;&#20013;&#30340;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Hierarchical Policy Learning for Conversational Recommendation with Hypergraph-based Reinforcement Learning. (arXiv:2305.02575v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#36229;&#22270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#23618;&#23545;&#35805;&#25512;&#33616;&#27169;&#22411;&#65292;&#20854;&#20013;&#23548;&#28436;&#36890;&#36807;&#36229;&#22270;&#31639;&#27861;&#36827;&#34892;&#36873;&#25321;&#65292;&#24110;&#21161;&#28436;&#21592;&#20943;&#23569;&#34892;&#21160;&#31354;&#38388;&#21644;&#25351;&#23548;&#23545;&#35805;&#26397;&#30528;&#26368;&#20855;&#20449;&#24687;&#24615;&#30340;&#23646;&#24615;&#26041;&#21521;&#36827;&#34892;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#22312;&#23545;&#35805;&#20013;&#30340;&#20559;&#22909;&#36873;&#25321;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#36890;&#36807;&#23545;&#35805;&#21450;&#26102;&#20027;&#21160;&#22320;&#33719;&#21462;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#24182;&#25512;&#33616;&#30456;&#24212;&#30340;&#29289;&#21697;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#24448;&#24448;&#20351;&#29992;&#32479;&#19968;&#30340;&#20915;&#31574;&#27169;&#22359;&#25110;&#21551;&#21457;&#24335;&#35268;&#21017;&#65292;&#32780;&#24573;&#30053;&#20102;&#19981;&#21516;&#20915;&#31574;&#36807;&#31243;&#30340;&#35282;&#33394;&#24046;&#24322;&#21644;&#30456;&#20114;&#20316;&#29992;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#36229;&#22270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#23618;&#23545;&#35805;&#25512;&#33616;&#27169;&#22411;&#65292;&#20854;&#20013;&#23548;&#28436;&#36890;&#36807;&#36229;&#22270;&#31639;&#27861;&#36827;&#34892;&#36873;&#25321;&#65292;&#24110;&#21161;&#28436;&#21592;&#20943;&#23569;&#34892;&#21160;&#31354;&#38388;&#65292;&#25351;&#23548;&#23545;&#35805;&#26397;&#30528;&#26368;&#20855;&#20449;&#24687;&#24615;&#30340;&#23646;&#24615;&#26041;&#21521;&#36827;&#34892;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#22312;&#23545;&#35805;&#20013;&#30340;&#20559;&#22909;&#36873;&#25321;&#29289;&#21697;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#26412;&#25991;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#25928;&#26524;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational recommendation systems (CRS) aim to timely and proactively acquire user dynamic preferred attributes through conversations for item recommendation. In each turn of CRS, there naturally have two decision-making processes with different roles that influence each other: 1) director, which is to select the follow-up option (i.e., ask or recommend) that is more effective for reducing the action space and acquiring user preferences; and 2) actor, which is to accordingly choose primitive actions (i.e., asked attribute or recommended item) that satisfy user preferences and give feedback to estimate the effectiveness of the director's option. However, existing methods heavily rely on a unified decision-making module or heuristic rules, while neglecting to distinguish the roles of different decision procedures, as well as the mutual influences between them. To address this, we propose a novel Director-Actor Hierarchical Conversational Recommender (DAHCR), where the director select
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#35843;&#26597;&#65292;&#38024;&#23545;&#25512;&#33616;&#36807;&#31243;&#20013;&#21487;&#33021;&#20986;&#29616;&#30340;&#25968;&#25454;&#25110;&#31639;&#27861;&#20559;&#35265;&#65292;&#25552;&#20379;&#20102;&#19968;&#20123;&#26041;&#27861;&#21644;&#24212;&#29992;&#26469;&#25552;&#21319;&#25512;&#33616;&#20013;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.13619</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20844;&#24179;&#24615;&#65306;&#22522;&#30784;&#12289;&#26041;&#27861;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fairness in Recommendation: Foundations, Methods and Applications. (arXiv:2205.13619v5 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13619
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#35843;&#26597;&#65292;&#38024;&#23545;&#25512;&#33616;&#36807;&#31243;&#20013;&#21487;&#33021;&#20986;&#29616;&#30340;&#25968;&#25454;&#25110;&#31639;&#27861;&#20559;&#35265;&#65292;&#25552;&#20379;&#20102;&#19968;&#20123;&#26041;&#27861;&#21644;&#24212;&#29992;&#26469;&#25552;&#21319;&#25512;&#33616;&#20013;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#26368;&#26222;&#36941;&#30340;&#24212;&#29992;&#20043;&#19968;&#65292;&#25512;&#33616;&#31995;&#32479;&#22312;&#36741;&#21161;&#20154;&#31867;&#20915;&#31574;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#29992;&#25143;&#30340;&#28385;&#24847;&#24230;&#21644;&#24179;&#21488;&#30340;&#21033;&#30410;&#19982;&#29983;&#25104;&#30340;&#25512;&#33616;&#32467;&#26524;&#30340;&#36136;&#37327;&#23494;&#20999;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#20316;&#20026;&#19968;&#20010;&#39640;&#24230;&#25968;&#25454;&#39537;&#21160;&#30340;&#31995;&#32479;&#65292;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#21463;&#21040;&#25968;&#25454;&#25110;&#31639;&#27861;&#20559;&#35265;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#20135;&#29983;&#19981;&#20844;&#24179;&#30340;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#21066;&#24369;&#31995;&#32479;&#30340;&#21487;&#20449;&#36182;&#24615;&#12290;&#22240;&#27492;&#65292;&#22312;&#25512;&#33616;&#35774;&#32622;&#20013;&#35299;&#20915;&#28508;&#22312;&#30340;&#19981;&#20844;&#24179;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#65292;&#23545;&#25512;&#33616;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#32771;&#34385;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#28041;&#21450;&#25552;&#21319;&#25512;&#33616;&#20013;&#30340;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#36234;&#26469;&#36234;&#22810;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#30456;&#23545;&#38646;&#25955;&#19988;&#32570;&#20047;&#31995;&#32479;&#21270;&#25972;&#29702;&#65292;&#22240;&#27492;&#23545;&#20110;&#26032;&#30740;&#31350;&#20154;&#21592;&#26469;&#35828;&#38590;&#20197;&#28145;&#20837;&#39046;&#22495;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#23545;&#25512;&#33616;&#20013;&#29616;&#26377;&#20844;&#24179;&#24615;&#20316;&#21697;&#36827;&#34892;&#31995;&#32479;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
As one of the most pervasive applications of machine learning, recommender systems are playing an important role on assisting human decision making. The satisfaction of users and the interests of platforms are closely related to the quality of the generated recommendation results. However, as a highly data-driven system, recommender system could be affected by data or algorithmic bias and thus generate unfair results, which could weaken the reliance of the systems. As a result, it is crucial to address the potential unfairness problems in recommendation settings. Recently, there has been growing attention on fairness considerations in recommender systems with more and more literature on approaches to promote fairness in recommendation. However, the studies are rather fragmented and lack a systematic organization, thus making it difficult to penetrate for new researchers to the domain. This motivates us to provide a systematic survey of existing works on fairness in recommendation. This
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;SURGE&#65288;SeqUential Recommendation with Graph neural networks&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#23558;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#20013;&#30340;&#19981;&#21516;&#20559;&#22909;&#32858;&#31867;&#25104;&#32039;&#23494;&#30340;&#20852;&#36259;&#22270;&#65292;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#39034;&#24207;&#25512;&#33616;&#20013;&#29992;&#25143;&#30340;&#19979;&#19968;&#27425;&#20114;&#21160;&#12290;</title><link>http://arxiv.org/abs/2106.14226</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Sequential Recommendation with Graph Neural Networks. (arXiv:2106.14226v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.14226
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;SURGE&#65288;SeqUential Recommendation with Graph neural networks&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#23558;&#29992;&#25143;&#21382;&#21490;&#34892;&#20026;&#20013;&#30340;&#19981;&#21516;&#20559;&#22909;&#32858;&#31867;&#25104;&#32039;&#23494;&#30340;&#20852;&#36259;&#22270;&#65292;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#39034;&#24207;&#25512;&#33616;&#20013;&#29992;&#25143;&#30340;&#19979;&#19968;&#27425;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#26088;&#22312;&#21033;&#29992;&#29992;&#25143;&#30340;&#21382;&#21490;&#34892;&#20026;&#39044;&#27979;&#20182;&#20204;&#30340;&#19979;&#19968;&#27425;&#20114;&#21160;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#22312;&#39034;&#24207;&#25512;&#33616;&#20013;&#38754;&#20020;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#29992;&#25143;&#30340;&#34892;&#20026;&#22312;&#20182;&#20204;&#20016;&#23500;&#30340;&#21382;&#21490;&#24207;&#21015;&#20013;&#24120;&#24120;&#26159;&#38544;&#24335;&#21644;&#22024;&#26434;&#30340;&#20559;&#22909;&#20449;&#21495;&#65292;&#26080;&#27861;&#20805;&#20998;&#21453;&#26144;&#29992;&#25143;&#30340;&#23454;&#38469;&#20559;&#22909;&#12290;&#21478;&#22806;&#65292;&#29992;&#25143;&#30340;&#21160;&#24577;&#20559;&#22909;&#24448;&#24448;&#20250;&#38543;&#26102;&#38388;&#36805;&#36895;&#21464;&#21270;&#65292;&#22240;&#27492;&#24456;&#38590;&#25429;&#25417;&#21040;&#20182;&#20204;&#21382;&#21490;&#24207;&#21015;&#20013;&#30340;&#29992;&#25143;&#27169;&#24335;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SURGE&#65288;SeqUential Recommendation with Graph neural networks&#65289;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26469;&#24212;&#23545;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SURGE&#36890;&#36807;&#22522;&#20110;&#24230;&#37327;&#23398;&#20064;&#65292;&#23558;&#38271;&#26399;&#29992;&#25143;&#34892;&#20026;&#20013;&#19981;&#21516;&#31867;&#22411;&#30340;&#20559;&#22909;&#37325;&#26032;&#26500;&#36896;&#20026;&#32039;&#23494;&#30340;&#29289;&#21697;-&#29289;&#21697;&#20852;&#36259;&#22270;&#20013;&#30340;&#32858;&#31867;&#65292;&#20174;&#32780;&#24110;&#21161;&#26126;&#30830;&#21306;&#20998;&#29992;&#25143;&#30340;&#26680;&#24515;&#20852;&#36259;&#12290;&#32858;&#31867;&#22312;&#20852;&#36259;&#22270;&#20013;&#24418;&#25104;&#20102;&#23494;&#38598;&#30340;&#38598;&#32676;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation aims to leverage users' historical behaviors to predict their next interaction. Existing works have not yet addressed two main challenges in sequential recommendation. First, user behaviors in their rich historical sequences are often implicit and noisy preference signals, they cannot sufficiently reflect users' actual preferences. In addition, users' dynamic preferences often change rapidly over time, and hence it is difficult to capture user patterns in their historical sequences. In this work, we propose a graph neural network model called SURGE (short for SeqUential Recommendation with Graph neural nEtworks) to address these two issues. Specifically, SURGE integrates different types of preferences in long-term user behaviors into clusters in the graph by re-constructing loose item sequences into tight item-item interest graphs based on metric learning. This helps explicitly distinguish users' core interests, by forming dense clusters in the interest graph.
&lt;/p&gt;</description></item></channel></rss>