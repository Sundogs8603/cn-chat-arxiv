<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22686;&#24378;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#26377;&#25928;&#22320;&#31649;&#29702;&#23376;&#20219;&#21153;&#12289;&#35299;&#20915;&#19981;&#21516;&#30340;&#23376;&#20219;&#21153;&#65292;&#24182;&#29983;&#25104;&#19982;&#29992;&#25143;&#20132;&#20114;&#30340;&#22238;&#24212;&#12290;</title><link>http://arxiv.org/abs/2308.06212</link><description>&lt;p&gt;
&#19968;&#20010;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22686;&#24378;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Large Language Model Enhanced Conversational Recommender System. (arXiv:2308.06212v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06212
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22686;&#24378;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#26377;&#25928;&#22320;&#31649;&#29702;&#23376;&#20219;&#21153;&#12289;&#35299;&#20915;&#19981;&#21516;&#30340;&#23376;&#20219;&#21153;&#65292;&#24182;&#29983;&#25104;&#19982;&#29992;&#25143;&#20132;&#20114;&#30340;&#22238;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#36890;&#36807;&#23545;&#35805;&#30028;&#38754;&#21521;&#29992;&#25143;&#25512;&#33616;&#39640;&#36136;&#37327;&#30340;&#29289;&#21697;&#12290;&#23427;&#36890;&#24120;&#21253;&#21547;&#22810;&#20010;&#23376;&#20219;&#21153;&#65292;&#22914;&#29992;&#25143;&#20559;&#22909;&#33719;&#21462;&#12289;&#25512;&#33616;&#12289;&#35299;&#37322;&#21644;&#29289;&#21697;&#20449;&#24687;&#25628;&#32034;&#12290;&#20026;&#20102;&#24320;&#21457;&#26377;&#25928;&#30340;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65292;&#38754;&#20020;&#19968;&#20123;&#25361;&#25112;&#65306;1&#65289;&#22914;&#20309;&#27491;&#30830;&#31649;&#29702;&#23376;&#20219;&#21153;&#65307;2&#65289;&#22914;&#20309;&#26377;&#25928;&#35299;&#20915;&#19981;&#21516;&#30340;&#23376;&#20219;&#21153;&#65307;3&#65289;&#22914;&#20309;&#27491;&#30830;&#29983;&#25104;&#19982;&#29992;&#25143;&#20132;&#20114;&#30340;&#22238;&#24212;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#25512;&#29702;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#20026;&#24320;&#21457;&#26356;&#24378;&#22823;&#30340;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#20250;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#65292;&#31216;&#20026;LLMCRS&#65292;&#26469;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#12290;&#22312;&#23376;&#20219;&#21153;&#31649;&#29702;&#26041;&#38754;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#26469;&#26377;&#25928;&#22320;&#31649;&#29702;&#23376;&#20219;&#21153;&#12290;&#22312;&#23376;&#20219;&#21153;&#35299;&#20915;&#26041;&#38754;&#65292;&#25105;&#20204;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#19981;&#21516;&#23376;&#20219;&#21153;&#30340;&#19987;&#23478;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#22686;&#24378;&#24615;&#33021;&#12290;&#22312;&#22238;&#24212;&#29983;&#25104;&#26041;&#38754;&#65292;&#25105;&#20204;&#21033;&#29992;&#29983;&#25104;&#33021;&#21147;&#26469;&#29983;&#25104;&#22238;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational recommender systems (CRSs) aim to recommend high-quality items to users through a dialogue interface. It usually contains multiple sub-tasks, such as user preference elicitation, recommendation, explanation, and item information search. To develop effective CRSs, there are some challenges: 1) how to properly manage sub-tasks; 2) how to effectively solve different sub-tasks; and 3) how to correctly generate responses that interact with users. Recently, Large Language Models (LLMs) have exhibited an unprecedented ability to reason and generate, presenting a new opportunity to develop more powerful CRSs. In this work, we propose a new LLM-based CRS, referred to as LLMCRS, to address the above challenges. For sub-task management, we leverage the reasoning ability of LLM to effectively manage sub-task. For sub-task solving, we collaborate LLM with expert models of different sub-tasks to achieve the enhanced performance. For response generation, we utilize the generation abili
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#35789;&#34955;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#65292;&#23545;&#20195;&#30721;&#27880;&#37322;&#30340;&#30456;&#20851;&#24615;&#36827;&#34892;&#35782;&#21035;&#12290;&#22312;&#35757;&#32451;&#35821;&#26009;&#24211;&#20013;&#65292;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#29305;&#24449;&#24037;&#31243;&#21644;&#25991;&#26412;&#20998;&#31867;&#25216;&#26415;&#65292;&#24182;&#27604;&#36739;&#20102;&#20256;&#32479;&#35789;&#34955;&#27169;&#22411;&#21644;Transformer&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.06144</link><description>&lt;p&gt;
&#20351;&#29992;&#35789;&#34955;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#35782;&#21035;&#20195;&#30721;&#35780;&#35770;&#30340;&#30456;&#20851;&#24615;
&lt;/p&gt;
&lt;p&gt;
Identification of the Relevance of Comments in Codes Using Bag of Words and Transformer Based Models. (arXiv:2308.06144v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#35789;&#34955;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#65292;&#23545;&#20195;&#30721;&#27880;&#37322;&#30340;&#30456;&#20851;&#24615;&#36827;&#34892;&#35782;&#21035;&#12290;&#22312;&#35757;&#32451;&#35821;&#26009;&#24211;&#20013;&#65292;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#29305;&#24449;&#24037;&#31243;&#21644;&#25991;&#26412;&#20998;&#31867;&#25216;&#26415;&#65292;&#24182;&#27604;&#36739;&#20102;&#20256;&#32479;&#35789;&#34955;&#27169;&#22411;&#21644;Transformer&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20170;&#24180;&#65292;&#20449;&#24687;&#26816;&#32034;&#35770;&#22363;(FIRE)&#21551;&#21160;&#20102;&#19968;&#20010;&#20849;&#20139;&#20219;&#21153;&#65292;&#29992;&#20110;&#23545;&#19981;&#21516;&#20195;&#30721;&#27573;&#30340;&#35780;&#35770;&#36827;&#34892;&#20998;&#31867;&#12290;&#36825;&#26159;&#19968;&#20010;&#20108;&#20803;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#65292;&#30446;&#26631;&#26159;&#30830;&#23450;&#32473;&#23450;&#20195;&#30721;&#27573;&#30340;&#35780;&#35770;&#26159;&#21542;&#30456;&#20851;&#12290;&#21360;&#24230;&#31185;&#23398;&#25945;&#32946;&#19982;&#30740;&#31350;&#38498;&#21338;&#24085;&#23572;&#20998;&#38498;(IISERB)&#30340;BioNLP-IISERB&#23567;&#32452;&#21442;&#19982;&#20102;&#36825;&#39033;&#20219;&#21153;&#65292;&#24182;&#20026;&#20116;&#31181;&#19981;&#21516;&#30340;&#27169;&#22411;&#25552;&#20132;&#20102;&#20116;&#31181;&#36816;&#34892;&#32467;&#26524;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#27010;&#20917;&#21644;&#22312;&#35757;&#32451;&#35821;&#26009;&#24211;&#19978;&#30340;&#20854;&#20182;&#37325;&#35201;&#21457;&#29616;&#12290;&#36825;&#20123;&#26041;&#27861;&#28041;&#21450;&#19981;&#21516;&#30340;&#29305;&#24449;&#24037;&#31243;&#26041;&#26696;&#21644;&#25991;&#26412;&#20998;&#31867;&#25216;&#26415;&#12290;&#23545;&#20110;&#35789;&#34955;&#27169;&#22411;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#20998;&#31867;&#22120;&#65292;&#22914;&#38543;&#26426;&#26862;&#26519;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;&#36923;&#36753;&#22238;&#24402;&#65292;&#20197;&#35782;&#21035;&#32473;&#23450;&#35757;&#32451;&#35821;&#26009;&#24211;&#20013;&#30340;&#37325;&#35201;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#22522;&#20110;&#39044;&#35757;&#32451;Transformer&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Forum for Information Retrieval (FIRE) started a shared task this year for classification of comments of different code segments. This is binary text classification task where the objective is to identify whether comments given for certain code segments are relevant or not. The BioNLP-IISERB group at the Indian Institute of Science Education and Research Bhopal (IISERB) participated in this task and submitted five runs for five different models. The paper presents the overview of the models and other significant findings on the training corpus. The methods involve different feature engineering schemes and text classification techniques. The performance of the classical bag of words model and transformer-based models were explored to identify significant features from the given training corpus. We have explored different classifiers viz., random forest, support vector machine and logistic regression using the bag of words model. Furthermore, the pre-trained transformer based models 
&lt;/p&gt;</description></item><item><title>&#29616;&#26377;&#30740;&#31350;&#24050;&#32463;&#34920;&#26126;&#65292;&#36890;&#36807;&#25913;&#36827;&#23545;&#40784;&#21644;&#22343;&#21248;&#24615;&#35774;&#35745;&#30340;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#23454;&#29616;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#31216;&#20026;MAWU&#65292;&#23427;&#32771;&#34385;&#20102;&#25968;&#25454;&#38598;&#30340;&#29420;&#29305;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2308.06091</link><description>&lt;p&gt;
&#23545;&#21327;&#21516;&#36807;&#28388;&#20002;&#22833;&#20989;&#25968;&#30340;&#26356;&#22909;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Toward a Better Understanding of Loss Functions for Collaborative Filtering. (arXiv:2308.06091v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06091
&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30740;&#31350;&#24050;&#32463;&#34920;&#26126;&#65292;&#36890;&#36807;&#25913;&#36827;&#23545;&#40784;&#21644;&#22343;&#21248;&#24615;&#35774;&#35745;&#30340;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#23454;&#29616;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#31216;&#20026;MAWU&#65292;&#23427;&#32771;&#34385;&#20102;&#25968;&#25454;&#38598;&#30340;&#29420;&#29305;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#26159;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20851;&#38190;&#25216;&#26415;&#12290;CF&#27169;&#22411;&#30340;&#23398;&#20064;&#36807;&#31243;&#36890;&#24120;&#30001;&#19977;&#20010;&#32452;&#20214;&#32452;&#25104;&#65306;&#20132;&#20114;&#32534;&#30721;&#22120;&#12289;&#25439;&#22833;&#20989;&#25968;&#21644;&#36127;&#37319;&#26679;&#12290;&#23613;&#31649;&#35768;&#22810;&#29616;&#26377;&#30740;&#31350;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;CF&#27169;&#22411;&#26469;&#35774;&#35745;&#22797;&#26434;&#30340;&#20132;&#20114;&#32534;&#30721;&#22120;&#65292;&#20294;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#31616;&#21333;&#22320;&#37325;&#26032;&#21046;&#23450;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#23454;&#29616;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#26412;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#29616;&#26377;&#25439;&#22833;&#20989;&#25968;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#25968;&#23398;&#20998;&#26512;&#25581;&#31034;&#20102;&#20808;&#21069;&#30340;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#35299;&#37322;&#20026;&#23545;&#40784;&#21644;&#22343;&#21248;&#24615;&#20989;&#25968;&#65306;&#65288;i&#65289;&#23545;&#40784;&#21305;&#37197;&#29992;&#25143;&#21644;&#29289;&#21697;&#34920;&#31034;&#65292;&#65288;ii&#65289;&#22343;&#21248;&#24615;&#20998;&#25955;&#29992;&#25143;&#21644;&#29289;&#21697;&#20998;&#24067;&#12290;&#21463;&#21040;&#36825;&#20010;&#20998;&#26512;&#30340;&#21551;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#23545;&#40784;&#21644;&#22343;&#21248;&#24615;&#35774;&#35745;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#32771;&#34385;&#21040;&#25968;&#25454;&#38598;&#30340;&#29420;&#29305;&#27169;&#24335;&#65292;&#31216;&#20026;Margin-aware Alignment and Weighted Uniformity&#65288;MAWU&#65289;&#12290;MAWU&#30340;&#20851;&#38190;&#21019;&#26032;&#26159;
&lt;/p&gt;
&lt;p&gt;
Collaborative filtering (CF) is a pivotal technique in modern recommender systems. The learning process of CF models typically consists of three components: interaction encoder, loss function, and negative sampling. Although many existing studies have proposed various CF models to design sophisticated interaction encoders, recent work shows that simply reformulating the loss functions can achieve significant performance gains. This paper delves into analyzing the relationship among existing loss functions. Our mathematical analysis reveals that the previous loss functions can be interpreted as alignment and uniformity functions: (i) the alignment matches user and item representations, and (ii) the uniformity disperses user and item distributions. Inspired by this analysis, we propose a novel loss function that improves the design of alignment and uniformity considering the unique patterns of datasets called Margin-aware Alignment and Weighted Uniformity (MAWU). The key novelty of MAWU 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#19978;&#19979;&#25991;&#20852;&#36259;&#32593;&#32476;&#65288;DCIN&#65289;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#23436;&#25972;&#22320;&#24314;&#27169;&#28857;&#20987;&#21450;&#20854;&#23637;&#31034;&#19978;&#19979;&#25991;&#26469;&#23398;&#20064;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#20852;&#36259;&#65292;&#20197;&#25552;&#39640;&#28857;&#20987;&#29575;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.06037</link><description>&lt;p&gt;
&#28145;&#24230;&#19978;&#19979;&#25991;&#20852;&#36259;&#32593;&#32476;&#29992;&#20110;&#28857;&#20987;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Deep Context Interest Network for Click-Through Rate Prediction. (arXiv:2308.06037v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06037
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#19978;&#19979;&#25991;&#20852;&#36259;&#32593;&#32476;&#65288;DCIN&#65289;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#23436;&#25972;&#22320;&#24314;&#27169;&#28857;&#20987;&#21450;&#20854;&#23637;&#31034;&#19978;&#19979;&#25991;&#26469;&#23398;&#20064;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#20852;&#36259;&#65292;&#20197;&#25552;&#39640;&#28857;&#20987;&#29575;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#26159;&#22312;&#32447;&#24191;&#21578;&#31561;&#24037;&#19994;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#38382;&#39064;&#65292;&#23427;&#20272;&#35745;&#29992;&#25143;&#28857;&#20987;&#26576;&#20010;&#39033;&#30446;&#30340;&#27010;&#29575;&#12290;&#35768;&#22810;&#30740;&#31350;&#33268;&#21147;&#20110;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#20197;&#25552;&#39640;CTR&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#22823;&#22810;&#25968;&#26041;&#27861;&#21482;&#20174;&#29992;&#25143;&#28857;&#20987;&#39033;&#30446;&#20013;&#24314;&#27169;&#29992;&#25143;&#30340;&#27491;&#21521;&#20852;&#36259;&#65292;&#24573;&#30053;&#20102;&#23637;&#31034;&#39033;&#30446;&#21608;&#22260;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#23548;&#33268;&#24615;&#33021;&#36739;&#24046;&#12290;&#26412;&#25991;&#24378;&#35843;&#20102;&#19978;&#19979;&#25991;&#20449;&#24687;&#23545;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#28145;&#24230;&#19978;&#19979;&#25991;&#20852;&#36259;&#32593;&#32476;&#65288;DCIN&#65289;&#30340;&#26032;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#23436;&#25972;&#22320;&#24314;&#27169;&#28857;&#20987;&#21450;&#20854;&#23637;&#31034;&#19978;&#19979;&#25991;&#26469;&#23398;&#20064;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#20852;&#36259;&#12290;DCIN&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#27169;&#22359;&#65306;1&#65289;&#20301;&#32622;&#24863;&#30693;&#19978;&#19979;&#25991;&#32858;&#21512;&#27169;&#22359;&#65288;PCAM&#65289;&#65292;&#36890;&#36807;&#27880;&#24847;&#26426;&#21046;&#23545;&#23637;&#31034;&#39033;&#30446;&#36827;&#34892;&#32858;&#21512;&#65307;2&#65289;&#21453;&#39304;-&#19978;&#19979;&#25991;&#34701;&#21512;&#27169;&#22359;&#65288;FCFM&#65289;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#20989;&#25968;&#23558;&#28857;&#20987;&#21644;&#23637;&#31034;&#19978;&#19979;&#25991;&#30340;&#34920;&#31034;&#36827;&#34892;&#34701;&#21512;&#65307;
&lt;/p&gt;
&lt;p&gt;
Click-Through Rate (CTR) prediction, estimating the probability of a user clicking on an item, is essential in industrial applications, such as online advertising. Many works focus on user behavior modeling to improve CTR prediction performance. However, most of those methods only model users' positive interests from users' click items while ignoring the context information, which is the display items around the clicks, resulting in inferior performance. In this paper, we highlight the importance of context information on user behavior modeling and propose a novel model named Deep Context Interest Network (DCIN), which integrally models the click and its display context to learn users' context-aware interests. DCIN consists of three key modules: 1) Position-aware Context Aggregation Module (PCAM), which performs aggregation of display items with an attention mechanism; 2) Feedback-Context Fusion Module (FCFM), which fuses the representation of clicks and display contexts through non-li
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#29992;&#25143;&#32972;&#26223;&#19978;&#19979;&#25991;&#30340;&#26412;&#20307;&#35770;&#65292;&#20197;&#27773;&#36710;&#38144;&#21806;&#39046;&#22495;&#20026;&#37325;&#28857;&#65292;&#26088;&#22312;&#22635;&#34917;&#23558;&#32972;&#26223;&#20449;&#24687;&#19982;&#19981;&#21516;&#30340;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#38598;&#25104;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#35813;&#26412;&#20307;&#35770;&#20316;&#20026;&#19968;&#20010;&#32467;&#26500;&#22522;&#30784;&#65292;&#26631;&#20934;&#21270;&#20102;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#21644;&#32972;&#26223;&#20449;&#24687;&#30340;&#34920;&#31034;&#65292;&#25552;&#39640;&#20102;&#31995;&#32479;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#21644;&#32972;&#26223;&#20449;&#24687;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.06018</link><description>&lt;p&gt;
&#35774;&#35745;&#19968;&#20010;&#29992;&#25143;&#32972;&#26223;&#19978;&#19979;&#25991;&#30340;&#26412;&#20307;&#35770;: &#20197;&#27773;&#36710;&#38144;&#21806;&#39046;&#22495;&#20026;&#37325;&#28857;
&lt;/p&gt;
&lt;p&gt;
Designing a User Contextual Profile Ontology: A Focus on the Vehicle Sales Domain. (arXiv:2308.06018v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#29992;&#25143;&#32972;&#26223;&#19978;&#19979;&#25991;&#30340;&#26412;&#20307;&#35770;&#65292;&#20197;&#27773;&#36710;&#38144;&#21806;&#39046;&#22495;&#20026;&#37325;&#28857;&#65292;&#26088;&#22312;&#22635;&#34917;&#23558;&#32972;&#26223;&#20449;&#24687;&#19982;&#19981;&#21516;&#30340;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#38598;&#25104;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#35813;&#26412;&#20307;&#35770;&#20316;&#20026;&#19968;&#20010;&#32467;&#26500;&#22522;&#30784;&#65292;&#26631;&#20934;&#21270;&#20102;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#21644;&#32972;&#26223;&#20449;&#24687;&#30340;&#34920;&#31034;&#65292;&#25552;&#39640;&#20102;&#31995;&#32479;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#21644;&#32972;&#26223;&#20449;&#24687;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#26102;&#20195;&#65292;&#29702;&#35299;&#21644;&#23450;&#21046;&#29992;&#25143;&#19982;&#31995;&#32479;&#21644;&#24212;&#29992;&#31243;&#24207;&#30340;&#20132;&#20114;&#20307;&#39564;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#38656;&#35201;&#21019;&#24314;&#23558;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#19982;&#32972;&#26223;&#20449;&#24687;&#30456;&#32467;&#21512;&#30340;&#29992;&#25143;&#32972;&#26223;&#19978;&#19979;&#25991;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#23558;&#32972;&#26223;&#20449;&#24687;&#19982;&#19981;&#21516;&#30340;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#38598;&#25104;&#30340;&#30740;&#31350;&#23578;&#32570;&#20047;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#29992;&#25143;&#32972;&#26223;&#19978;&#19979;&#25991;&#30340;&#26412;&#20307;&#35770;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#35813;&#26412;&#20307;&#35770;&#32771;&#34385;&#20102;&#27599;&#20010;&#37197;&#32622;&#25991;&#20214;&#19978;&#30340;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#21644;&#32972;&#26223;&#20449;&#24687;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#20197;&#27773;&#36710;&#38144;&#21806;&#39046;&#22495;&#20026;&#37325;&#28857;&#30340;&#29992;&#25143;&#32972;&#26223;&#19978;&#19979;&#25991;&#26412;&#20307;&#35770;&#30340;&#35774;&#35745;&#21644;&#24320;&#21457;&#12290;&#25105;&#20204;&#35774;&#35745;&#30340;&#26412;&#20307;&#35770;&#20316;&#20026;&#35268;&#33539;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#21644;&#32972;&#26223;&#20449;&#24687;&#34920;&#31034;&#30340;&#32467;&#26500;&#22522;&#30784;&#65292;&#22686;&#24378;&#20102;&#31995;&#32479;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#21644;&#32972;&#26223;&#20449;&#24687;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#29992;&#25143;&#32972;&#26223;&#19978;&#19979;&#25991;&#26412;&#20307;&#35770;&#36827;&#34892;&#20010;&#24615;&#21270;&#25512;&#33616;&#29983;&#25104;&#30340;&#26696;&#20363;&#30740;&#31350;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the digital age, it is crucial to understand and tailor experiences for users interacting with systems and applications. This requires the creation of user contextual profiles that combine user profiles with contextual information. However, there is a lack of research on the integration of contextual information with different user profiles. This study aims to address this gap by designing a user contextual profile ontology that considers both user profiles and contextual information on each profile. Specifically, we present a design and development of the user contextual profile ontology with a focus on the vehicle sales domain. Our designed ontology serves as a structural foundation for standardizing the representation of user profiles and contextual information, enhancing the system's ability to capture user preferences and contextual information of the user accurately. Moreover, we illustrate a case study using the User Contextual Profile Ontology in generating personalized reco
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22686;&#24378;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#29992;&#20110;&#21327;&#21516;&#36807;&#28388;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#20174;&#21407;&#22987;&#39033;&#36873;&#25321;&#36127;&#26679;&#26412;&#30340;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#27169;&#31946;&#38519;&#38449;&#21644;&#20449;&#24687;&#27495;&#35270;&#20004;&#20010;&#38480;&#21046;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2308.05972</link><description>&lt;p&gt;
&#22686;&#24378;&#30340;&#36127;&#37319;&#26679;&#29992;&#20110;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Augmented Negative Sampling for Collaborative Filtering. (arXiv:2308.05972v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22686;&#24378;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#29992;&#20110;&#21327;&#21516;&#36807;&#28388;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#20174;&#21407;&#22987;&#39033;&#36873;&#25321;&#36127;&#26679;&#26412;&#30340;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#27169;&#31946;&#38519;&#38449;&#21644;&#20449;&#24687;&#27495;&#35270;&#20004;&#20010;&#38480;&#21046;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36127;&#37319;&#26679;&#23545;&#20110;&#22522;&#20110;&#38544;&#24335;&#21453;&#39304;&#30340;&#21327;&#21516;&#36807;&#28388;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#23427;&#29992;&#20110;&#20174;&#22823;&#37327;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#26500;&#24314;&#36127;&#20449;&#21495;&#65292;&#20197;&#25351;&#23548;&#30417;&#30563;&#23398;&#20064;&#12290;&#29616;&#26377;&#26041;&#27861;&#30340;&#26368;&#26032;&#24819;&#27861;&#26159;&#21033;&#29992;&#25658;&#24102;&#26356;&#22810;&#26377;&#29992;&#20449;&#24687;&#30340;&#22256;&#38590;&#36127;&#26679;&#26412;&#26469;&#26500;&#24314;&#26356;&#22909;&#30340;&#20915;&#31574;&#36793;&#30028;&#12290;&#20026;&#20102;&#24179;&#34913;&#25928;&#29575;&#21644;&#25928;&#26524;&#65292;&#32477;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#37319;&#29992;&#20004;&#36941;&#26041;&#27861;&#65292;&#20854;&#20013;&#31532;&#19968;&#36941;&#37319;&#26679;&#22266;&#23450;&#25968;&#37327;&#30340;&#26410;&#35266;&#23519;&#39033;&#65292;&#37319;&#29992;&#31616;&#21333;&#38745;&#24577;&#20998;&#24067;&#65292;&#28982;&#21518;&#31532;&#20108;&#36941;&#20351;&#29992;&#26356;&#22797;&#26434;&#30340;&#36127;&#37319;&#26679;&#31574;&#30053;&#36873;&#25321;&#26368;&#32456;&#30340;&#36127;&#39033;&#12290;&#28982;&#32780;&#65292;&#20174;&#21407;&#22987;&#39033;&#20013;&#36873;&#25321;&#36127;&#26679;&#26412;&#22266;&#26377;&#30340;&#38480;&#21046;&#65292;&#21487;&#33021;&#26080;&#27861;&#24456;&#22909;&#22320;&#19982;&#27491;&#26679;&#26412;&#24418;&#25104;&#23545;&#27604;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#19968;&#35266;&#23519;&#65292;&#24182;&#20171;&#32461;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#20004;&#20010;&#38480;&#21046;&#65306;&#27169;&#31946;&#38519;&#38449;&#21644;&#20449;&#24687;&#27495;&#35270;&#12290;&#25105;&#20204;&#23545;&#36825;&#20123;&#38480;&#21046;&#30340;&#22238;&#24212;&#26159;&#24341;&#20837;&#22686;&#24378;&#30340;&#36127;&#37319;&#26679;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#26356;&#22909;&#22320;&#24212;&#23545;&#36825;&#20123;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Negative sampling is essential for implicit-feedback-based collaborative filtering, which is used to constitute negative signals from massive unlabeled data to guide supervised learning. The state-of-the-art idea is to utilize hard negative samples that carry more useful information to form a better decision boundary. To balance efficiency and effectiveness, the vast majority of existing methods follow the two-pass approach, in which the first pass samples a fixed number of unobserved items by a simple static distribution and then the second pass selects the final negative items using a more sophisticated negative sampling strategy. However, selecting negative samples from the original items is inherently restricted, and thus may not be able to contrast positive samples well. In this paper, we confirm this observation via experiments and introduce two limitations of existing solutions: ambiguous trap and information discrimination. Our response to such limitations is to introduce augme
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#34394;&#25311;&#30340;MOOC&#21161;&#25945; LittleMu&#65292;&#36890;&#36807;&#25972;&#21512;&#24322;&#26500;&#25968;&#25454;&#28304;&#21644;&#25945;&#23398;&#25552;&#31034;&#38142;&#36335;&#26469;&#25903;&#25345;&#24191;&#27867;&#33539;&#22260;&#30340;&#20934;&#30830;&#22238;&#31572;&#21644;&#30693;&#35782;&#30456;&#20851;&#30340;&#38386;&#32842;&#26381;&#21153;&#12290;</title><link>http://arxiv.org/abs/2308.05935</link><description>&lt;p&gt;
LittleMu&#65306;&#36890;&#36807;&#24322;&#26500;&#25968;&#25454;&#28304;&#25972;&#21512;&#21644;&#25945;&#23398;&#25552;&#31034;&#38142;&#36335;&#37096;&#32626;&#22312;&#32447;&#34394;&#25311;&#21161;&#25945;
&lt;/p&gt;
&lt;p&gt;
LittleMu: Deploying an Online Virtual Teaching Assistant via Heterogeneous Sources Integration and Chain of Teach Prompts. (arXiv:2308.05935v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#34394;&#25311;&#30340;MOOC&#21161;&#25945; LittleMu&#65292;&#36890;&#36807;&#25972;&#21512;&#24322;&#26500;&#25968;&#25454;&#28304;&#21644;&#25945;&#23398;&#25552;&#31034;&#38142;&#36335;&#26469;&#25903;&#25345;&#24191;&#27867;&#33539;&#22260;&#30340;&#20934;&#30830;&#22238;&#31572;&#21644;&#30693;&#35782;&#30456;&#20851;&#30340;&#38386;&#32842;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25945;&#32946;&#30340;&#28459;&#38271;&#21382;&#21490;&#20013;&#65292;&#21161;&#25945;&#22312;&#23398;&#20064;&#20013;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#30495;&#23454;&#22312;&#32447;&#25945;&#32946;&#22330;&#26223;&#30340;&#22797;&#26434;&#24615;&#21644;&#32570;&#20047;&#35757;&#32451;&#25968;&#25454;&#65292;&#24456;&#23569;&#26377;MOOC&#24179;&#21488;&#25552;&#20379;&#20154;&#24037;&#25110;&#34394;&#25311;&#21161;&#25945;&#26469;&#25903;&#25345;&#22823;&#37327;&#22312;&#32447;&#23398;&#29983;&#30340;&#23398;&#20064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#34394;&#25311;&#30340;MOOC&#21161;&#25945;LittleMu&#65292;&#20165;&#20351;&#29992;&#23569;&#37327;&#26631;&#27880;&#35757;&#32451;&#25968;&#25454;&#65292;&#25552;&#20379;&#38382;&#39064;&#22238;&#31572;&#21644;&#38386;&#32842;&#26381;&#21153;&#12290;LittleMu&#30001;&#20004;&#20010;&#20132;&#20114;&#27169;&#22359;&#32452;&#25104;&#65292;&#21253;&#25324;&#24322;&#26500;&#26816;&#32034;&#21644;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#65292;&#39318;&#20808;&#25972;&#21512;&#32467;&#26500;&#21270;&#12289;&#21322;&#32467;&#26500;&#21270;&#21644;&#38750;&#32467;&#26500;&#21270;&#30340;&#30693;&#35782;&#28304;&#65292;&#25903;&#25345;&#24191;&#27867;&#33539;&#22260;&#30340;&#38382;&#39064;&#30340;&#20934;&#30830;&#22238;&#31572;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#21517;&#20026;&#8220;Chain of Teach&#8221;&#25552;&#31034;&#30340;&#31934;&#24515;&#31034;&#33539;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#27169;&#22411;&#22788;&#29702;&#22797;&#26434;&#30340;&#26410;&#25910;&#38598;&#38382;&#39064;&#12290;&#38500;&#20102;&#38382;&#39064;&#22238;&#31572;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#20854;&#20182;&#25945;&#32946;&#26381;&#21153;&#65292;&#22914;&#30693;&#35782;&#30456;&#20851;&#30340;&#38386;&#32842;&#12290;&#25105;&#20204;&#36890;&#36807;&#26426;&#22120;&#20154;&#27979;&#35797;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Teaching assistants have played essential roles in the long history of education. However, few MOOC platforms are providing human or virtual teaching assistants to support learning for massive online students due to the complexity of real-world online education scenarios and the lack of training data. In this paper, we present a virtual MOOC teaching assistant, LittleMu with minimum labeled training data, to provide question answering and chit-chat services. Consisting of two interactive modules of heterogeneous retrieval and language model prompting, LittleMu first integrates structural, semi- and unstructured knowledge sources to support accurate answers for a wide range of questions. Then, we design delicate demonstrations named "Chain of Teach" prompts to exploit the large-scale pre-trained model to handle complex uncollected questions. Except for question answering, we develop other educational services such as knowledge-grounded chit-chat. We test the system's performance via bot
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#25490;&#24207;&#27169;&#22411;&#65292;&#21517;&#20026;&#38271;&#26399;&#20379;&#24212;&#21830;MMF&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#21453;&#39304;&#24490;&#29615;&#19979;&#30340;&#38271;&#26399;&#20379;&#24212;&#21830;&#26368;&#22823;&#26368;&#23567;&#20844;&#24179;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.05902</link><description>&lt;p&gt;
LTP-MMF: &#38754;&#21521;&#25512;&#33616;&#21453;&#39304;&#24490;&#29615;&#19979;&#30340;&#38271;&#26399;&#20379;&#24212;&#21830;&#26368;&#22823;&#26368;&#23567;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
LTP-MMF: Towards Long-term Provider Max-min Fairness Under Recommendation Feedback Loops. (arXiv:2308.05902v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05902
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#25490;&#24207;&#27169;&#22411;&#65292;&#21517;&#20026;&#38271;&#26399;&#20379;&#24212;&#21830;MMF&#65292;&#20197;&#35299;&#20915;&#25512;&#33616;&#21453;&#39304;&#24490;&#29615;&#19979;&#30340;&#38271;&#26399;&#20379;&#24212;&#21830;&#26368;&#22823;&#26368;&#23567;&#20844;&#24179;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#21033;&#30410;&#30456;&#20851;&#32773;&#25512;&#33616;&#31995;&#32479;&#28041;&#21450;&#21508;&#31181;&#35282;&#33394;&#65292;&#22914;&#29992;&#25143;&#12289;&#20379;&#24212;&#21830;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#25351;&#20986;&#65292;&#26368;&#22823;&#26368;&#23567;&#20844;&#24179;&#24615;&#65288;MMF&#65289;&#26159;&#25903;&#25345;&#24369;&#20379;&#24212;&#21830;&#30340;&#26356;&#22909;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#32771;&#34385;&#21040;MMF&#26102;&#65292;&#36825;&#20123;&#35282;&#33394;&#30340;&#29305;&#24449;&#25110;&#21442;&#25968;&#20250;&#38543;&#26102;&#38388;&#21464;&#21270;&#65292;&#22914;&#20309;&#30830;&#20445;&#38271;&#26399;&#20379;&#24212;&#21830;MMF&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#25512;&#33616;&#21453;&#39304;&#24490;&#29615;&#65288;RFL&#65289;&#20250;&#23545;&#20379;&#24212;&#21830;&#30340;MMF&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;RFL&#24847;&#21619;&#30528;&#25512;&#33616;&#31995;&#32479;&#21482;&#33021;&#20174;&#29992;&#25143;&#37027;&#37324;&#25509;&#25910;&#21040;&#24050;&#20844;&#24320;&#29289;&#21697;&#30340;&#21453;&#39304;&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#21453;&#39304;&#22686;&#37327;&#26356;&#26032;&#25512;&#33616;&#27169;&#22411;&#12290;&#22312;&#21033;&#29992;&#21453;&#39304;&#26102;&#65292;&#25512;&#33616;&#27169;&#22411;&#23558;&#25226;&#26410;&#20844;&#24320;&#30340;&#29289;&#21697;&#35270;&#20026;&#36127;&#38754;&#26679;&#26412;&#12290;&#36825;&#26679;&#65292;&#23614;&#37096;&#20379;&#24212;&#21830;&#23558;&#26080;&#27861;&#34987;&#26333;&#20809;&#65292;&#20854;&#29289;&#21697;&#23558;&#22987;&#32456;&#34987;&#35270;&#20026;&#36127;&#38754;&#26679;&#26412;&#12290;&#22312;RFL&#20013;&#65292;&#36825;&#31181;&#29616;&#35937;&#20250;&#36234;&#26469;&#36234;&#20005;&#37325;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#38271;&#26399;&#20379;&#24212;&#21830;MMF&#30340;&#22312;&#32447;&#25490;&#24207;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-stakeholder recommender systems involve various roles, such as users, providers. Previous work pointed out that max-min fairness (MMF) is a better metric to support weak providers. However, when considering MMF, the features or parameters of these roles vary over time, how to ensure long-term provider MMF has become a significant challenge. We observed that recommendation feedback loops (named RFL) will influence the provider MMF greatly in the long term. RFL means that recommender system can only receive feedback on exposed items from users and update recommender models incrementally based on this feedback. When utilizing the feedback, the recommender model will regard unexposed item as negative. In this way, tail provider will not get the opportunity to be exposed, and its items will always be considered as negative samples. Such phenomenons will become more and more serious in RFL. To alleviate the problem, this paper proposes an online ranking model named Long-Term Provider M
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#26500;&#24314;&#35268;&#33539;&#20197;&#25429;&#25417;AI&#29992;&#25143;&#20559;&#22909;&#30340;&#26032;&#35270;&#35282;&#12290;</title><link>http://arxiv.org/abs/2308.02542</link><description>&lt;p&gt;
&#20197;&#21327;&#21516;&#36807;&#28388;&#25429;&#25417;AI&#29992;&#25143;&#20559;&#22909;&#20316;&#20026;&#35268;&#33539;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Collaborative filtering to capture AI user's preferences as norms. (arXiv:2308.02542v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#21327;&#21516;&#36807;&#28388;&#26041;&#27861;&#26500;&#24314;&#35268;&#33539;&#20197;&#25429;&#25417;AI&#29992;&#25143;&#20559;&#22909;&#30340;&#26032;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;AI&#25216;&#26415;&#26681;&#25454;&#27599;&#20010;&#29992;&#25143;&#30340;&#20559;&#22909;&#36827;&#34892;&#23450;&#21046;&#26159;&#20854;&#33391;&#22909;&#36816;&#34892;&#30340;&#22522;&#30784;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#38656;&#35201;&#29992;&#25143;&#36807;&#22810;&#21442;&#19982;&#65292;&#24182;&#19988;&#26410;&#33021;&#30495;&#27491;&#25429;&#25417;&#21040;&#20182;&#20204;&#30340;&#30495;&#23454;&#20559;&#22909;&#12290;&#20107;&#23454;&#19978;&#65292;&#20026;&#20102;&#36991;&#20813;&#25163;&#21160;&#35774;&#32622;&#20559;&#22909;&#30340;&#40635;&#28902;&#65292;&#29992;&#25143;&#36890;&#24120;&#20250;&#25509;&#21463;&#40664;&#35748;&#35774;&#32622;&#65292;&#21363;&#20351;&#36825;&#20123;&#35774;&#32622;&#19982;&#20182;&#20204;&#30340;&#30495;&#23454;&#20559;&#22909;&#19981;&#31526;&#12290;&#35268;&#33539;&#21487;&#20197;&#29992;&#26469;&#35843;&#33410;&#34892;&#20026;&#65292;&#30830;&#20445;&#20854;&#31526;&#21512;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#20294;&#26159;&#23613;&#31649;&#25991;&#29486;&#24050;&#32463;&#35814;&#32454;&#30740;&#31350;&#20102;&#35268;&#33539;&#65292;&#22823;&#37096;&#20998;&#25552;&#35758;&#37117;&#26159;&#20174;&#24418;&#24335;&#21270;&#30340;&#35282;&#24230;&#20986;&#21457;&#12290;&#23454;&#38469;&#19978;&#65292;&#34429;&#28982;&#24050;&#32463;&#26377;&#19968;&#20123;&#20851;&#20110;&#26500;&#24314;&#35268;&#33539;&#20197;&#25429;&#25417;&#29992;&#25143;&#38544;&#31169;&#20559;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#26159;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#39046;&#22495;&#30693;&#35782;&#65292;&#22312;AI&#25216;&#26415;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#24456;&#38590;&#33719;&#24471;&#21644;&#32500;&#25252;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#22312;&#26500;&#24314;&#35268;&#33539;&#26102;&#38656;&#35201;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65292;&#21363;&#21033;&#29992;&#31995;&#32479;&#20013;&#22823;&#37327;&#29992;&#25143;&#30340;&#20559;&#22909;&#20449;&#24687;&#12290;&#21463;&#21040;&#25512;&#33616;&#31995;&#32479;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30456;&#20449;&#21327;&#21516;&#36807;&#28388;&#21487;&#20197;&#25104;&#20026;&#26500;&#24314;&#35268;&#33539;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Customising AI technologies to each user's preferences is fundamental to them functioning well. Unfortunately, current methods require too much user involvement and fail to capture their true preferences. In fact, to avoid the nuisance of manually setting preferences, users usually accept the default settings even if these do not conform to their true preferences. Norms can be useful to regulate behaviour and ensure it adheres to user preferences but, while the literature has thoroughly studied norms, most proposals take a formal perspective. Indeed, while there has been some research on constructing norms to capture a user's privacy preferences, these methods rely on domain knowledge which, in the case of AI technologies, is difficult to obtain and maintain. We argue that a new perspective is required when constructing norms, which is to exploit the large amount of preference information readily available from whole systems of users. Inspired by recommender systems, we believe that co
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#35752;&#35770;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#27969;&#34892;&#20559;&#24046;&#12290;&#23427;&#21516;&#26102;&#25552;&#20379;&#20102;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#21644;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;</title><link>http://arxiv.org/abs/2308.01118</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Popularity Bias in Recommender Systems. (arXiv:2308.01118v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01118
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#35752;&#35770;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#27969;&#34892;&#20559;&#24046;&#12290;&#23427;&#21516;&#26102;&#25552;&#20379;&#20102;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#21644;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20197;&#20010;&#24615;&#21270;&#30340;&#26041;&#24335;&#24110;&#21161;&#20154;&#20204;&#25214;&#21040;&#30456;&#20851;&#20869;&#23481;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#19968;&#20010;&#20027;&#35201;&#25215;&#35834;&#26159;&#33021;&#22815;&#22686;&#21152;&#30446;&#24405;&#20013;&#36739;&#23569;&#30693;&#21517;&#30340;&#29289;&#21697;&#30340;&#21487;&#35265;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#29616;&#20170;&#30340;&#25512;&#33616;&#31639;&#27861;&#21453;&#32780;&#34920;&#29616;&#20986;&#27969;&#34892;&#20559;&#24046;&#65292;&#21363;&#23427;&#20204;&#22312;&#25512;&#33616;&#20013;&#32463;&#24120;&#20851;&#27880;&#30456;&#24403;&#27969;&#34892;&#30340;&#29289;&#21697;&#12290;&#36825;&#31181;&#20559;&#24046;&#19981;&#20165;&#21487;&#33021;&#23548;&#33268;&#30701;&#26399;&#20869;&#23545;&#28040;&#36153;&#32773;&#21644;&#25552;&#20379;&#32773;&#30340;&#25512;&#33616;&#20215;&#20540;&#26377;&#38480;&#65292;&#32780;&#19988;&#36824;&#21487;&#33021;&#24341;&#36215;&#19981;&#24076;&#26395;&#30340;&#24378;&#21270;&#25928;&#24212;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#27969;&#34892;&#20559;&#24046;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#25512;&#33616;&#31995;&#32479;&#20013;&#27969;&#34892;&#20559;&#24046;&#30340;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#32508;&#36848;&#26082;&#21253;&#25324;&#20102;&#25991;&#29486;&#20013;&#20351;&#29992;&#30340;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#65292;&#20063;&#21253;&#25324;&#20102;&#20943;&#23569;&#20559;&#24046;&#30340;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;&#25105;&#20204;&#36824;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#24182;&#25552;&#20379;&#35780;&#20272;&#26426;&#21046;&#65292;&#21516;&#26102;&#20063;&#32771;&#34385;&#21040;&#20102;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#26088;&#22312;&#24110;&#21161;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#22522;&#20110;&#21487;&#20449;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2307.15464</link><description>&lt;p&gt;
&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#36136;&#37327;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Framework to Automatically Determine the Quality of Open Data Catalogs. (arXiv:2307.15464v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#24182;&#25552;&#20379;&#35780;&#20272;&#26426;&#21046;&#65292;&#21516;&#26102;&#20063;&#32771;&#34385;&#21040;&#20102;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#26088;&#22312;&#24110;&#21161;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#22522;&#20110;&#21487;&#20449;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#30446;&#24405;&#22312;&#29616;&#20195;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#20419;&#36827;&#21508;&#31181;&#25968;&#25454;&#36164;&#20135;&#30340;&#21457;&#29616;&#12289;&#29702;&#35299;&#21644;&#21033;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#24320;&#25918;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#29615;&#22659;&#20013;&#30830;&#20445;&#20854;&#36136;&#37327;&#21644;&#21487;&#38752;&#24615;&#26159;&#22797;&#26434;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#30830;&#23450;&#24320;&#25918;&#25968;&#25454;&#30446;&#24405;&#30340;&#36136;&#37327;&#65292;&#35299;&#20915;&#20102;&#39640;&#25928;&#21644;&#21487;&#38752;&#30340;&#36136;&#37327;&#35780;&#20272;&#26426;&#21046;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#20998;&#26512;&#21508;&#31181;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#22914;&#20934;&#30830;&#24615;&#12289;&#23436;&#25972;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#21450;&#26102;&#24615;&#65292;&#25552;&#20379;&#22810;&#31181;&#35780;&#20272;&#20860;&#23481;&#24615;&#21644;&#30456;&#20284;&#24615;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20197;&#21450;&#23454;&#26045;&#19968;&#32452;&#38750;&#26680;&#24515;&#36136;&#37327;&#32500;&#24230;&#65292;&#22914;&#28335;&#28304;&#24615;&#12289;&#21487;&#35835;&#24615;&#21644;&#35768;&#21487;&#35777;&#12290;&#20854;&#30446;&#26631;&#26159;&#20351;&#25968;&#25454;&#39537;&#21160;&#22411;&#32452;&#32455;&#33021;&#22815;&#22522;&#20110;&#21487;&#20449;&#21644;&#31934;&#24515;&#31649;&#29702;&#30340;&#25968;&#25454;&#36164;&#20135;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data catalogs play a crucial role in modern data-driven organizations by facilitating the discovery, understanding, and utilization of diverse data assets. However, ensuring their quality and reliability is complex, especially in open and large-scale data environments. This paper proposes a framework to automatically determine the quality of open data catalogs, addressing the need for efficient and reliable quality assessment mechanisms. Our framework can analyze various core quality dimensions, such as accuracy, completeness, consistency, scalability, and timeliness, offer several alternatives for the assessment of compatibility and similarity across such catalogs as well as the implementation of a set of non-core quality dimensions such as provenance, readability, and licensing. The goal is to empower data-driven organizations to make informed decisions based on trustworthy and well-curated data assets. The source code that illustrates our approach can be downloaded from https://www.
&lt;/p&gt;</description></item><item><title>Kuaipedia&#26159;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#22810;&#27169;&#24335;&#30701;&#35270;&#39057;&#30334;&#31185;&#20840;&#20070;&#65292;&#36890;&#36807;&#30693;&#35782;&#35270;&#39057;&#30340;&#24418;&#24335;&#65292;&#33021;&#22815;&#36731;&#26494;&#34920;&#36798;&#32593;&#27665;&#23545;&#26576;&#20010;&#39033;&#30446;&#30340;&#21508;&#20010;&#26041;&#38754;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2211.00732</link><description>&lt;p&gt;
Kuaipedia:&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#22810;&#27169;&#24335;&#30701;&#35270;&#39057;&#30334;&#31185;&#20840;&#20070;
&lt;/p&gt;
&lt;p&gt;
Kuaipedia: a Large-scale Multi-modal Short-video Encyclopedia. (arXiv:2211.00732v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.00732
&lt;/p&gt;
&lt;p&gt;
Kuaipedia&#26159;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#22810;&#27169;&#24335;&#30701;&#35270;&#39057;&#30334;&#31185;&#20840;&#20070;&#65292;&#36890;&#36807;&#30693;&#35782;&#35270;&#39057;&#30340;&#24418;&#24335;&#65292;&#33021;&#22815;&#36731;&#26494;&#34920;&#36798;&#32593;&#27665;&#23545;&#26576;&#20010;&#39033;&#30446;&#30340;&#21508;&#20010;&#26041;&#38754;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;20&#24180;&#20013;&#65292;&#22312;&#32447;&#30334;&#31185;&#20840;&#20070;&#65288;&#22914;&#32500;&#22522;&#30334;&#31185;&#65289;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#21457;&#23637;&#21644;&#30740;&#31350;&#12290;&#20154;&#20204;&#21487;&#20197;&#22312;&#30001;&#24535;&#24895;&#32773;&#31038;&#21306;&#32534;&#36753;&#30340;&#32500;&#22522;&#39029;&#38754;&#19978;&#25214;&#21040;&#32500;&#22522;&#39033;&#30340;&#20219;&#20309;&#23646;&#24615;&#25110;&#20854;&#20182;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#25991;&#26412;&#12289;&#22270;&#29255;&#21644;&#34920;&#26684;&#24456;&#38590;&#34920;&#36798;&#32500;&#22522;&#39033;&#30340;&#26576;&#20123;&#26041;&#38754;&#12290;&#20363;&#22914;&#65292;&#24403;&#25105;&#20204;&#35848;&#35770;&#8220;&#26612;&#29356;&#8221;&#26102;&#65292;&#20154;&#20204;&#21487;&#33021;&#26356;&#20851;&#24515;&#8220;&#22914;&#20309;&#21890;&#20859;&#23427;&#8221;&#25110;&#8220;&#22914;&#20309;&#35757;&#32451;&#23427;&#19981;&#20445;&#25252;&#39135;&#29289;&#8221;&#12290;&#30446;&#21069;&#65292;&#30701;&#35270;&#39057;&#24179;&#21488;&#24050;&#25104;&#20026;&#22312;&#32447;&#19990;&#30028;&#30340;&#26631;&#24535;&#12290;&#26080;&#35770;&#20320;&#20351;&#29992;&#30340;&#26159;TikTok&#12289;Instagram&#12289;&#24555;&#25163;&#36824;&#26159;YouTube Shorts&#65292;&#30701;&#35270;&#39057;&#24212;&#29992;&#31243;&#24207;&#24050;&#25913;&#21464;&#20102;&#25105;&#20204;&#20170;&#22825;&#30340;&#20869;&#23481;&#28040;&#36153;&#21644;&#21019;&#20316;&#26041;&#24335;&#12290;&#38500;&#20102;&#20026;&#23089;&#20048;&#21046;&#20316;&#30701;&#35270;&#39057;&#22806;&#65292;&#25105;&#20204;&#36234;&#26469;&#36234;&#22810;&#22320;&#30475;&#21040;&#20316;&#32773;&#20204;&#22312;&#21508;&#34892;&#21508;&#19994;&#24191;&#27867;&#20998;&#20139;&#26377;&#35265;&#35299;&#30340;&#30693;&#35782;&#12290;&#36825;&#20123;&#30701;&#35270;&#39057;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#30693;&#35782;&#35270;&#39057;&#65292;&#21487;&#20197;&#36731;&#26494;&#34920;&#36798;&#28040;&#36153;&#32773;&#24819;&#20102;&#35299;&#26377;&#20851;&#26576;&#20010;&#39033;&#30446;&#65288;&#20363;&#22914;&#26612;&#29356;&#65289;&#30340;&#20219;&#20309;&#26041;&#38754;&#65288;&#20363;&#22914;&#27611;&#21457;&#25110;&#22914;&#20309;&#21890;&#20859;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online encyclopedias, such as Wikipedia, have been well-developed and researched in the last two decades. One can find any attributes or other information of a wiki item on a wiki page edited by a community of volunteers. However, the traditional text, images and tables can hardly express some aspects of an wiki item. For example, when we talk about ``Shiba Inu'', one may care more about ``How to feed it'' or ``How to train it not to protect its food''. Currently, short-video platforms have become a hallmark in the online world. Whether you're on TikTok, Instagram, Kuaishou, or YouTube Shorts, short-video apps have changed how we consume and create content today. Except for producing short videos for entertainment, we can find more and more authors sharing insightful knowledge widely across all walks of life. These short videos, which we call knowledge videos, can easily express any aspects (e.g. hair or how-to-feed) consumers want to know about an item (e.g. Shiba Inu), and they can b
&lt;/p&gt;</description></item><item><title>Lib-SibGMU&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#22823;&#23398;&#22270;&#20070;&#39302;&#20511;&#38405;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#24320;&#21457;&#12290;&#22312;&#35813;&#25968;&#25454;&#38598;&#19978;&#25105;&#20204;&#21457;&#29616;&#20351;&#29992;fastText&#27169;&#22411;&#20316;&#20026;&#21521;&#37327;&#21270;&#22120;&#21487;&#20197;&#33719;&#24471;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2208.12356</link><description>&lt;p&gt;
Lib-SibGMU -- &#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#24320;&#21457;&#30340;&#22823;&#23398;&#22270;&#20070;&#39302;&#20511;&#38405;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
Lib-SibGMU -- A University Library Circulation Dataset for Recommender Systems Developmen. (arXiv:2208.12356v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.12356
&lt;/p&gt;
&lt;p&gt;
Lib-SibGMU&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#22823;&#23398;&#22270;&#20070;&#39302;&#20511;&#38405;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#24320;&#21457;&#12290;&#22312;&#35813;&#25968;&#25454;&#38598;&#19978;&#25105;&#20204;&#21457;&#29616;&#20351;&#29992;fastText&#27169;&#22411;&#20316;&#20026;&#21521;&#37327;&#21270;&#22120;&#21487;&#20197;&#33719;&#24471;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20197;CC BY 4.0&#35768;&#21487;&#35777;&#24320;&#28304;&#20102;Lib-SibGMU&#30340;&#22823;&#23398;&#22270;&#20070;&#39302;&#20511;&#38405;&#25968;&#25454;&#38598;&#65292;&#20379;&#24191;&#22823;&#30740;&#31350;&#31038;&#21306;&#20351;&#29992;&#65292;&#24182;&#22312;&#35813;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#20027;&#35201;&#30340;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#30001;&#23558;&#20511;&#38405;&#20070;&#31821;&#21382;&#21490;&#36716;&#21270;&#20026;&#21521;&#37327;&#30340;&#21521;&#37327;&#21270;&#22120;&#21644;&#19968;&#20010;&#22522;&#20110;&#37051;&#22495;&#30340;&#25512;&#33616;&#22120;&#32452;&#25104;&#30340;&#25512;&#33616;&#20307;&#31995;&#32467;&#26500;&#65292;&#20998;&#21035;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#35777;&#26126;&#20351;&#29992;fastText&#27169;&#22411;&#20316;&#20026;&#21521;&#37327;&#21270;&#22120;&#21487;&#20197;&#33719;&#24471;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We opensource under CC BY 4.0 license Lib-SibGMU - a university library circulation dataset - for a wide research community, and benchmark major algorithms for recommender systems on this dataset. For a recommender architecture that consists of a vectorizer that turns the history of the books borrowed into a vector, and a neighborhood-based recommender, trained separately, we show that using the fastText model as a vectorizer delivers competitive results.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AdaMCT&#30340;&#36866;&#24212;&#24615;&#28151;&#21512;CNN-Transformer&#27169;&#22411;&#65292;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#12290;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;Transformer&#30340;&#20840;&#23616;&#27880;&#24847;&#26426;&#21046;&#21644;&#23616;&#37096;&#21367;&#31215;&#28388;&#27874;&#22120;&#65292;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#29992;&#25143;&#30340;&#38271;&#26399;&#21644;&#30701;&#26399;&#20559;&#22909;&#65292;&#24182;&#36890;&#36807;&#20010;&#24615;&#21270;&#30340;&#26041;&#27861;&#30830;&#23450;&#28151;&#21512;&#37325;&#35201;&#24615;&#12290;&#21478;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;Squeeze-Excita&#26041;&#27861;&#65292;&#20197;&#21516;&#26102;&#32771;&#34385;&#22810;&#20010;&#30456;&#20851;&#39033;&#30446;&#30340;&#36141;&#20080;&#36873;&#39033;&#12290;</title><link>http://arxiv.org/abs/2205.08776</link><description>&lt;p&gt;
AdaMCT&#65306;&#36866;&#24212;&#24615;CNN-Transformer&#28151;&#21512;&#27169;&#22411;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
AdaMCT: Adaptive Mixture of CNN-Transformer for Sequential Recommendation. (arXiv:2205.08776v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.08776
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AdaMCT&#30340;&#36866;&#24212;&#24615;&#28151;&#21512;CNN-Transformer&#27169;&#22411;&#65292;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#12290;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;Transformer&#30340;&#20840;&#23616;&#27880;&#24847;&#26426;&#21046;&#21644;&#23616;&#37096;&#21367;&#31215;&#28388;&#27874;&#22120;&#65292;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#29992;&#25143;&#30340;&#38271;&#26399;&#21644;&#30701;&#26399;&#20559;&#22909;&#65292;&#24182;&#36890;&#36807;&#20010;&#24615;&#21270;&#30340;&#26041;&#27861;&#30830;&#23450;&#28151;&#21512;&#37325;&#35201;&#24615;&#12290;&#21478;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;Squeeze-Excita&#26041;&#27861;&#65292;&#20197;&#21516;&#26102;&#32771;&#34385;&#22810;&#20010;&#30456;&#20851;&#39033;&#30446;&#30340;&#36141;&#20080;&#36873;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#26088;&#22312;&#20174;&#19968;&#31995;&#21015;&#20132;&#20114;&#20013;&#24314;&#27169;&#29992;&#25143;&#30340;&#21160;&#24577;&#20559;&#22909;&#12290;&#39034;&#24207;&#25512;&#33616;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#22312;&#20110;&#29992;&#25143;&#20559;&#22909;&#30340;&#22266;&#26377;&#21464;&#21270;&#24615;&#12290;&#19968;&#20010;&#26377;&#25928;&#30340;&#39034;&#24207;&#25512;&#33616;&#27169;&#22411;&#24212;&#35813;&#33021;&#22815;&#25429;&#25417;&#21040;&#29992;&#25143;&#23637;&#31034;&#30340;&#38271;&#26399;&#21644;&#30701;&#26399;&#20559;&#22909;&#65292;&#20854;&#20013;&#21069;&#32773;&#21487;&#20197;&#25552;&#20379;&#23545;&#24433;&#21709;&#21518;&#32773;&#30340;&#31283;&#23450;&#20852;&#36259;&#30340;&#20840;&#38754;&#29702;&#35299;&#12290;&#20026;&#20102;&#26356;&#26377;&#25928;&#22320;&#25429;&#25417;&#36825;&#26679;&#30340;&#20449;&#24687;&#65292;&#25105;&#20204;&#23558;&#23616;&#37096;&#24863;&#30693;&#24615;&#20559;&#24046;&#24341;&#20837;Transformer&#20013;&#65292;&#36890;&#36807;&#23558;&#20854;&#20840;&#23616;&#27880;&#24847;&#26426;&#21046;&#19982;&#23616;&#37096;&#21367;&#31215;&#28388;&#27874;&#22120;&#32467;&#21512;&#36215;&#26469;&#65292;&#24182;&#36890;&#36807;&#23618;&#24863;&#30693;&#30340;&#33258;&#36866;&#24212;&#28151;&#21512;&#21333;&#20803;AdaMCT&#20197;&#20010;&#24615;&#21270;&#22522;&#30784;&#30830;&#23450;&#28151;&#21512;&#37325;&#35201;&#24615;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#29992;&#25143;&#21487;&#33021;&#20250;&#21453;&#22797;&#27983;&#35272;&#28508;&#22312;&#30340;&#36141;&#20080;&#36873;&#39033;&#65292;&#22312;&#38271;&#26399;&#21644;&#30701;&#26399;&#20559;&#22909;&#24314;&#27169;&#20013;&#21516;&#26102;&#32771;&#34385;&#22810;&#20010;&#30456;&#20851;&#39033;&#30446;&#26159;&#21487;&#39044;&#26399;&#30340;&#12290;&#37492;&#20110;&#22522;&#20110;softmax&#30340;&#27880;&#24847;&#21147;&#21487;&#33021;&#20250;&#20419;&#36827;&#21333;&#23792;&#28608;&#27963;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Squeeze-Excita&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation (SR) aims to model users dynamic preferences from a series of interactions. A pivotal challenge in user modeling for SR lies in the inherent variability of user preferences. An effective SR model is expected to capture both the long-term and short-term preferences exhibited by users, wherein the former can offer a comprehensive understanding of stable interests that impact the latter. To more effectively capture such information, we incorporate locality inductive bias into the Transformer by amalgamating its global attention mechanism with a local convolutional filter, and adaptively ascertain the mixing importance on a personalized basis through layer-aware adaptive mixture units, termed as AdaMCT. Moreover, as users may repeatedly browse potential purchases, it is expected to consider multiple relevant items concurrently in long-/short-term preferences modeling. Given that softmax-based attention may promote unimodal activation, we propose the Squeeze-Excita
&lt;/p&gt;</description></item></channel></rss>