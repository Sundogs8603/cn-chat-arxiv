<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#38170;&#28857;&#36873;&#25321;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#36739;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#19982;&#38543;&#26426;&#25277;&#26679;&#38170;&#28857;&#30456;&#24403;&#25110;&#32773;&#26356;&#22909;&#30340;k-NN&#21484;&#22238;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.02996</link><description>&lt;p&gt;
&#24102;&#26377;&#20132;&#21449;&#32534;&#30721;&#22120;&#30340;CUR k-NN&#25628;&#32034;&#30340;&#33258;&#36866;&#24212;&#38170;&#23450;&#39033;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Adaptive Selection of Anchor Items for CUR-based k-NN search with Cross-Encoders. (arXiv:2305.02996v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02996
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#38170;&#28857;&#36873;&#25321;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#36739;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#19982;&#38543;&#26426;&#25277;&#26679;&#38170;&#28857;&#30456;&#24403;&#25110;&#32773;&#26356;&#22909;&#30340;k-NN&#21484;&#22238;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#38170;&#28857;&#36873;&#25321;&#26041;&#27861;&#65292;&#20197;&#25913;&#21892;ANNCUR&#27169;&#22411;&#20013;&#39640;&#21069;k&#39033;&#30340;&#36924;&#36817;&#35823;&#24046;&#21644;&#21484;&#22238;&#29575;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20445;&#25345;&#36739;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#19982;&#38543;&#26426;&#25277;&#26679;&#38170;&#28857;&#30456;&#24403;&#25110;&#32773;&#26356;&#22909;&#30340;k-NN&#21484;&#22238;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-encoder models, which jointly encode and score a query-item pair, are typically prohibitively expensive for k-nearest neighbor search. Consequently, k-NN search is performed not with a cross-encoder, but with a heuristic retrieve (e.g., using BM25 or dual-encoder) and re-rank approach. Recent work proposes ANNCUR (Yadav et al., 2022) which uses CUR matrix factorization to produce an embedding space for efficient vector-based search that directly approximates the cross-encoder without the need for dual-encoders. ANNCUR defines this shared query-item embedding space by scoring the test query against anchor items which are sampled uniformly at random. While this minimizes average approximation error over all items, unsuitably high approximation error on top-k items remains and leads to poor recall of top-k (and especially top-1) items. Increasing the number of anchor items is a straightforward way of improving the approximation error and hence k-NN recall of ANNCUR but at the cost o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;&#65288;ULTR&#65289;&#30340;&#22522;&#30784;&#27010;&#24565;&#21644;&#26368;&#26032;&#36827;&#23637;&#65292;&#20197;&#21450;&#20960;&#31181;&#23454;&#38469;&#24212;&#29992;&#30340;&#26041;&#27861;&#12290;&#25945;&#31243;&#20998;&#20026;&#22235;&#20010;&#37096;&#20998;&#65306;&#20559;&#24046;&#30340;&#27010;&#36848;&#65292;ULTR&#30340;&#26368;&#26032;&#20272;&#35745;&#25216;&#26415;&#65292;ULTR&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;ULTR&#19982;&#25490;&#21517;&#20844;&#24179;&#24615;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.02914</link><description>&lt;p&gt;
&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;&#30340;&#22522;&#30784;&#21644;&#24212;&#29992;&#30340;&#26368;&#26032;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Recent Advances in the Foundations and Applications of Unbiased Learning to Rank. (arXiv:2305.02914v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02914
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;&#65288;ULTR&#65289;&#30340;&#22522;&#30784;&#27010;&#24565;&#21644;&#26368;&#26032;&#36827;&#23637;&#65292;&#20197;&#21450;&#20960;&#31181;&#23454;&#38469;&#24212;&#29992;&#30340;&#26041;&#27861;&#12290;&#25945;&#31243;&#20998;&#20026;&#22235;&#20010;&#37096;&#20998;&#65306;&#20559;&#24046;&#30340;&#27010;&#36848;&#65292;ULTR&#30340;&#26368;&#26032;&#20272;&#35745;&#25216;&#26415;&#65292;ULTR&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;ULTR&#19982;&#25490;&#21517;&#20844;&#24179;&#24615;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;&#65288;ULTR&#65289;&#39046;&#22495;&#33258;&#35806;&#29983;&#20197;&#26469;&#19968;&#30452;&#22788;&#20110;&#38750;&#24120;&#27963;&#36291;&#30340;&#29366;&#24577;&#65292;&#24182;&#22312;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#20960;&#39033;&#26377;&#24433;&#21709;&#21147;&#30340;&#36827;&#23637;&#12290;&#26412;&#25945;&#31243;&#26082;&#20171;&#32461;&#20102;&#35813;&#39046;&#22495;&#30340;&#26680;&#24515;&#27010;&#24565;&#65292;&#21448;&#27010;&#36848;&#20102;&#20854;&#22522;&#30784;&#30340;&#26368;&#26032;&#36827;&#23637;&#20197;&#21450;&#20854;&#26041;&#27861;&#30340;&#20960;&#31181;&#24212;&#29992;&#12290;&#26412;&#25945;&#31243;&#20998;&#20026;&#22235;&#37096;&#20998;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#21487;&#20197;&#29992;ULTR&#26041;&#27861;&#35299;&#20915;&#30340;&#19981;&#21516;&#24418;&#24335;&#30340;&#20559;&#24046;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20840;&#38754;&#35752;&#35770;&#20102;ULTR&#39046;&#22495;&#30340;&#26368;&#26032;&#20272;&#35745;&#25216;&#26415;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;ULTR&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#21457;&#24067;&#32467;&#26524;&#12290;&#31532;&#22235;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;ULTR&#19982;&#25490;&#21517;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#31616;&#35201;&#21453;&#24605;&#20102;ULTR&#30740;&#31350;&#21450;&#20854;&#24212;&#29992;&#30340;&#26410;&#26469;&#12290;&#26412;&#25945;&#31243;&#26088;&#22312;&#20351;&#23545;&#24320;&#21457;&#26032;&#30340;ULTR&#35299;&#20915;&#26041;&#26696;&#25110;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21033;&#29992;&#23427;&#20204;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#24037;&#19994;&#23454;&#36341;&#32773;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since its inception, the field of unbiased learning to rank (ULTR) has remained very active and has seen several impactful advancements in recent years. This tutorial provides both an introduction to the core concepts of the field and an overview of recent advancements in its foundations along with several applications of its methods. The tutorial is divided into four parts: Firstly, we give an overview of the different forms of bias that can be addressed with ULTR methods. Secondly, we present a comprehensive discussion of the latest estimation techniques in the ULTR field. Thirdly, we survey published results of ULTR in real-world applications. Fourthly, we discuss the connection between ULTR and fairness in ranking. We end by briefly reflecting on the future of ULTR research and its applications. This tutorial is intended to benefit both researchers and industry practitioners who are interested in developing new ULTR solutions or utilizing them in real-world applications.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#23384;&#22312;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#26469;&#20248;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#20808;&#21069;&#30740;&#31350;&#25351;&#20986;&#65292;&#22522;&#20110;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24178;&#39044;&#21487;&#20197;&#30830;&#20445;&#27604;&#20363;&#20195;&#34920;&#24615;&#65292;&#24182;&#22312;&#23384;&#22312;&#20559;&#35265;&#26102;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#25928;&#29992;&#12290;&#32780;&#26412;&#25991;&#21017;&#25506;&#35752;&#20102;&#19968;&#32452;&#33021;&#22815;&#25429;&#25417;&#36825;&#31181;&#30446;&#30340;&#30340;&#23376;&#27169;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.02806</link><description>&lt;p&gt;
&#22312;&#23384;&#22312;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Maximizing Submodular Functions for Recommendation in the Presence of Biases. (arXiv:2305.02806v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02806
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#23384;&#22312;&#20559;&#35265;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#26469;&#20248;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#20808;&#21069;&#30740;&#31350;&#25351;&#20986;&#65292;&#22522;&#20110;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24178;&#39044;&#21487;&#20197;&#30830;&#20445;&#27604;&#20363;&#20195;&#34920;&#24615;&#65292;&#24182;&#22312;&#23384;&#22312;&#20559;&#35265;&#26102;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#25928;&#29992;&#12290;&#32780;&#26412;&#25991;&#21017;&#25506;&#35752;&#20102;&#19968;&#32452;&#33021;&#22815;&#25429;&#25417;&#36825;&#31181;&#30446;&#30340;&#30340;&#23376;&#27169;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23376;&#38598;&#36873;&#25321;&#20219;&#21153;&#22312;&#25512;&#33616;&#31995;&#32479;&#21644;&#25628;&#32034;&#24341;&#25806;&#20013;&#32463;&#24120;&#20986;&#29616;&#65292;&#35201;&#27714;&#36873;&#25321;&#19968;&#20123;&#26368;&#22823;&#21270;&#29992;&#25143;&#20215;&#20540;&#30340;&#29289;&#21697;&#23376;&#38598;&#12290;&#23376;&#38598;&#30340;&#20215;&#20540;&#24448;&#24448;&#21576;&#29616;&#20986;&#36882;&#20943;&#30340;&#22238;&#25253;&#65292;&#22240;&#27492;&#65292;&#20351;&#29992;&#23376;&#27169;&#20989;&#25968;&#26469;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#21457;&#29616;&#36755;&#20837;&#20855;&#26377;&#31038;&#20250;&#20559;&#35265;&#65292;&#20250;&#38477;&#20302;&#36755;&#20986;&#23376;&#38598;&#30340;&#25928;&#29992;&#65292;&#22240;&#27492;&#38656;&#35201;&#24178;&#39044;&#20197;&#25552;&#39640;&#20854;&#25928;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32452;&#23376;&#27169;&#20989;&#25968;&#30340;&#26368;&#22823;&#21270;&#65292;&#36825;&#20123;&#20989;&#25968;&#28085;&#30422;&#20102;&#19978;&#36848;&#24212;&#29992;&#20013;&#20986;&#29616;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Subset selection tasks, arise in recommendation systems and search engines and ask to select a subset of items that maximize the value for the user. The values of subsets often display diminishing returns, and hence, submodular functions have been used to model them. If the inputs defining the submodular function are known, then existing algorithms can be used. In many applications, however, inputs have been observed to have social biases that reduce the utility of the output subset. Hence, interventions to improve the utility are desired. Prior works focus on maximizing linear functions -- a special case of submodular functions -- and show that fairness constraint-based interventions can not only ensure proportional representation but also achieve near-optimal utility in the presence of biases. We study the maximization of a family of submodular functions that capture functions arising in the aforementioned applications. Our first result is that, unlike linear functions, constraint-ba
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#36229;&#22270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#23618;&#23545;&#35805;&#25512;&#33616;&#27169;&#22411;&#65292;&#20854;&#20013;&#23548;&#28436;&#36890;&#36807;&#36229;&#22270;&#31639;&#27861;&#36827;&#34892;&#36873;&#25321;&#65292;&#24110;&#21161;&#28436;&#21592;&#20943;&#23569;&#34892;&#21160;&#31354;&#38388;&#21644;&#25351;&#23548;&#23545;&#35805;&#26397;&#30528;&#26368;&#20855;&#20449;&#24687;&#24615;&#30340;&#23646;&#24615;&#26041;&#21521;&#36827;&#34892;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#22312;&#23545;&#35805;&#20013;&#30340;&#20559;&#22909;&#36873;&#25321;&#29289;&#21697;&#12290;</title><link>http://arxiv.org/abs/2305.02575</link><description>&lt;p&gt;
&#22522;&#20110;&#36229;&#22270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#23618;&#23545;&#35805;&#25512;&#33616;&#20013;&#30340;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Hierarchical Policy Learning for Conversational Recommendation with Hypergraph-based Reinforcement Learning. (arXiv:2305.02575v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#36229;&#22270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#23618;&#23545;&#35805;&#25512;&#33616;&#27169;&#22411;&#65292;&#20854;&#20013;&#23548;&#28436;&#36890;&#36807;&#36229;&#22270;&#31639;&#27861;&#36827;&#34892;&#36873;&#25321;&#65292;&#24110;&#21161;&#28436;&#21592;&#20943;&#23569;&#34892;&#21160;&#31354;&#38388;&#21644;&#25351;&#23548;&#23545;&#35805;&#26397;&#30528;&#26368;&#20855;&#20449;&#24687;&#24615;&#30340;&#23646;&#24615;&#26041;&#21521;&#36827;&#34892;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#22312;&#23545;&#35805;&#20013;&#30340;&#20559;&#22909;&#36873;&#25321;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#25512;&#33616;&#31995;&#32479;&#26088;&#22312;&#36890;&#36807;&#23545;&#35805;&#21450;&#26102;&#20027;&#21160;&#22320;&#33719;&#21462;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#24182;&#25512;&#33616;&#30456;&#24212;&#30340;&#29289;&#21697;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#24448;&#24448;&#20351;&#29992;&#32479;&#19968;&#30340;&#20915;&#31574;&#27169;&#22359;&#25110;&#21551;&#21457;&#24335;&#35268;&#21017;&#65292;&#32780;&#24573;&#30053;&#20102;&#19981;&#21516;&#20915;&#31574;&#36807;&#31243;&#30340;&#35282;&#33394;&#24046;&#24322;&#21644;&#30456;&#20114;&#20316;&#29992;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#36229;&#22270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#23618;&#23545;&#35805;&#25512;&#33616;&#27169;&#22411;&#65292;&#20854;&#20013;&#23548;&#28436;&#36890;&#36807;&#36229;&#22270;&#31639;&#27861;&#36827;&#34892;&#36873;&#25321;&#65292;&#24110;&#21161;&#28436;&#21592;&#20943;&#23569;&#34892;&#21160;&#31354;&#38388;&#65292;&#25351;&#23548;&#23545;&#35805;&#26397;&#30528;&#26368;&#20855;&#20449;&#24687;&#24615;&#30340;&#23646;&#24615;&#26041;&#21521;&#36827;&#34892;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#22312;&#23545;&#35805;&#20013;&#30340;&#20559;&#22909;&#36873;&#25321;&#29289;&#21697;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#26412;&#25991;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#25928;&#26524;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational recommendation systems (CRS) aim to timely and proactively acquire user dynamic preferred attributes through conversations for item recommendation. In each turn of CRS, there naturally have two decision-making processes with different roles that influence each other: 1) director, which is to select the follow-up option (i.e., ask or recommend) that is more effective for reducing the action space and acquiring user preferences; and 2) actor, which is to accordingly choose primitive actions (i.e., asked attribute or recommended item) that satisfy user preferences and give feedback to estimate the effectiveness of the director's option. However, existing methods heavily rely on a unified decision-making module or heuristic rules, while neglecting to distinguish the roles of different decision procedures, as well as the mutual influences between them. To address this, we propose a novel Director-Actor Hierarchical Conversational Recommender (DAHCR), where the director select
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#22810;&#31181;&#22522;&#20110;&#32479;&#35745;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#31561;&#26041;&#27861;&#26469;&#26377;&#25928;&#22320;&#20998;&#26512;&#39321;&#28207;&#30340;&#27861;&#24459;&#21028;&#20915;&#65292;&#24182;&#20174;&#20013;&#25552;&#21462;&#20851;&#38190;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;&#20215;&#26684;&#39640;&#21644;&#36164;&#28304;&#32570;&#20047;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.02558</link><description>&lt;p&gt;
&#20197;&#35745;&#31639;&#35821;&#35328;&#23398;&#35270;&#35282;&#20998;&#26512;&#39321;&#28207;&#30340;&#27861;&#24459;&#21028;&#20915;
&lt;/p&gt;
&lt;p&gt;
Analyzing Hong Kong's Legal Judgments from a Computational Linguistics point-of-view. (arXiv:2305.02558v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02558
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#22810;&#31181;&#22522;&#20110;&#32479;&#35745;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#31561;&#26041;&#27861;&#26469;&#26377;&#25928;&#22320;&#20998;&#26512;&#39321;&#28207;&#30340;&#27861;&#24459;&#21028;&#20915;&#65292;&#24182;&#20174;&#20013;&#25552;&#21462;&#20851;&#38190;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;&#20215;&#26684;&#39640;&#21644;&#36164;&#28304;&#32570;&#20047;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#35745;&#31639;&#35821;&#35328;&#23398;&#20174;&#27861;&#24459;&#21028;&#20915;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#26159;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#26089;&#26399;&#25552;&#20986;&#30340;&#38382;&#39064;&#20043;&#19968;&#12290;&#30446;&#21069;&#65292;&#23384;&#22312;&#22810;&#20010;&#21830;&#19994;&#20379;&#24212;&#21830;&#33258;&#21160;&#21270;&#25191;&#34892;&#36825;&#20123;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22312;&#20998;&#26512;&#39321;&#28207;&#27861;&#38498;&#31995;&#32479;&#30340;&#21028;&#20915;&#26102;&#65292;&#23384;&#22312;&#20215;&#26684;&#36807;&#39640;&#21644;&#32570;&#20047;&#36164;&#28304;&#30340;&#20851;&#38190;&#29942;&#39048;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#20960;&#31181;&#22522;&#20110;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#28145;&#24230;&#23398;&#20064;&#21644;&#38646;&#26679;&#26412;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20197;&#26377;&#25928;&#22320;&#20998;&#26512;&#39321;&#28207;&#27861;&#38498;&#31995;&#32479;&#30340;&#27861;&#24459;&#21028;&#20915;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21253;&#25324;&#65306;&#65288;1&#65289;&#24341;&#25991;&#32593;&#32476;&#22270;&#29983;&#25104;&#65292;&#65288;2&#65289;PageRank&#31639;&#27861;&#65292;&#65288;3&#65289;&#20851;&#38190;&#35789;&#20998;&#26512;&#21644;&#25688;&#35201;&#65292;&#65288;4&#65289;&#24773;&#24863;&#26497;&#24615;&#65292;&#20197;&#21450;&#65288;5&#65289;&#27573;&#33853;&#20998;&#31867;&#65292;&#20197;&#20415;&#33021;&#22815;&#25552;&#21462;&#21333;&#20010;&#21028;&#20915;&#20197;&#21450;&#32676;&#20307;&#21028;&#20915;&#30340;&#20851;&#38190;&#35265;&#35299;&#12290;&#36825;&#23558;&#20351;&#23545;&#39321;&#28207;&#21028;&#20915;&#30340;&#25972;&#20307;&#20998;&#26512;&#21464;&#24471;&#19981;&#37027;&#20040;&#32321;&#29712;&#12290;
&lt;/p&gt;
&lt;p&gt;
Analysis and extraction of useful information from legal judgments using computational linguistics was one of the earliest problems posed in the domain of information retrieval. Presently, several commercial vendors exist who automate such tasks. However, a crucial bottleneck arises in the form of exorbitant pricing and lack of resources available in analysis of judgements mete out by Hong Kong's Legal System. This paper attempts to bridge this gap by providing several statistical, machine learning, deep learning and zero-shot learning based methods to effectively analyze legal judgments from Hong Kong's Court System. The methods proposed consists of: (1) Citation Network Graph Generation, (2) PageRank Algorithm, (3) Keyword Analysis and Summarization, (4) Sentiment Polarity, and (5) Paragrah Classification, in order to be able to extract key insights from individual as well a group of judgments together. This would make the overall analysis of judgments in Hong Kong less tedious and m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#25628;&#32034;&#21644;&#25512;&#33616;&#23454;&#39564;&#30340;&#26174;&#33879;&#24615;&#26816;&#39564;&#34892;&#20026;&#65292;&#32467;&#26524;&#21457;&#29616;&#22312;&#22823;&#26679;&#26412;&#19979;Wilcoxon&#21644;Sign&#27979;&#35797;&#30340;1&#22411;&#38169;&#35823;&#29575;&#26174;&#33879;&#26356;&#39640;&#65292;&#24314;&#35758;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;bootstrap&#12289;&#38543;&#26426;&#21270;&#21644;t&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2305.02461</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#25628;&#32034;&#21644;&#25512;&#33616;&#23454;&#39564;&#30340;&#26174;&#33879;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Inference at Scale Significance Testing for Large Search and Recommendation Experiments. (arXiv:2305.02461v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#25628;&#32034;&#21644;&#25512;&#33616;&#23454;&#39564;&#30340;&#26174;&#33879;&#24615;&#26816;&#39564;&#34892;&#20026;&#65292;&#32467;&#26524;&#21457;&#29616;&#22312;&#22823;&#26679;&#26412;&#19979;Wilcoxon&#21644;Sign&#27979;&#35797;&#30340;1&#22411;&#38169;&#35823;&#29575;&#26174;&#33879;&#26356;&#39640;&#65292;&#24314;&#35758;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;bootstrap&#12289;&#38543;&#26426;&#21270;&#21644;t&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20449;&#24687;&#26816;&#32034;&#30740;&#31350;&#24050;&#32463;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#20197;&#30830;&#23450;&#21738;&#31181;&#32479;&#35745;&#25216;&#26415;&#36866;&#29992;&#20110;&#27604;&#36739;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#38598;&#20013;&#20110;TREC&#26679;&#24335;&#30340;&#23454;&#39564;&#65292;&#36890;&#24120;&#23569;&#20110;100&#20010;&#20027;&#39064;&#12290;&#27809;&#26377;&#31867;&#20284;&#30340;&#30740;&#31350;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#25628;&#32034;&#21644;&#25512;&#33616;&#23454;&#39564;&#65307;&#36825;&#20123;&#30740;&#31350;&#36890;&#24120;&#28041;&#21450;&#25968;&#21315;&#20010;&#20027;&#39064;&#25110;&#29992;&#25143;&#20197;&#21450;&#26356;&#31232;&#30095;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#65292;&#22240;&#27492;&#19981;&#28165;&#26970;&#20998;&#26512;&#20256;&#32479;TREC&#23454;&#39564;&#30340;&#24314;&#35758;&#26159;&#21542;&#36866;&#29992;&#20110;&#36825;&#20123;&#24773;&#20917;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23454;&#35777;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#25628;&#32034;&#21644;&#25512;&#33616;&#35780;&#20272;&#25968;&#25454;&#30340;&#26174;&#33879;&#24615;&#26816;&#39564;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;Wilcoxon&#21644;Sign&#27979;&#35797;&#26174;&#31034;&#20986;&#26174;&#33879;&#26356;&#39640;&#30340;1&#22411;&#38169;&#35823;&#29575;&#65292;&#32780;&#19981;&#26159;&#26356;&#19968;&#33268;&#31526;&#21512;&#39044;&#26399;&#38169;&#35823;&#29575;&#30340;bootstrap&#12289;&#38543;&#26426;&#21270;&#21644;t&#27979;&#35797;&#12290;&#34429;&#28982;&#32479;&#35745;&#27979;&#35797;&#22312;&#26679;&#26412;&#36739;&#23567;&#26102;&#26174;&#31034;&#20986;&#21151;&#29575;&#24046;&#24322;&#65292;&#20294;&#22312;&#21151;&#29575;&#30456;&#21516;&#26102;&#26174;&#31034;&#20986;&#27809;&#26377;&#21306;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
A number of information retrieval studies have been done to assess which statistical techniques are appropriate for comparing systems. However, these studies are focused on TREC-style experiments, which typically have fewer than 100 topics. There is no similar line of work for large search and recommendation experiments; such studies typically have thousands of topics or users and much sparser relevance judgements, so it is not clear if recommendations for analyzing traditional TREC experiments apply to these settings. In this paper, we empirically study the behavior of significance tests with large search and recommendation evaluation data. Our results show that the Wilcoxon and Sign tests show significantly higher Type-1 error rates for large sample sizes than the bootstrap, randomization and t-tests, which were more consistent with the expected error rate. While the statistical tests displayed differences in their power for smaller sample sizes, they showed no difference in their po
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#30340;&#19981;&#26131;&#34987;&#26816;&#27979;&#21040;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#26694;&#26550;&#65292;&#31216;&#20026;&#8220;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#25991;&#26723;&#25805;&#20316;&#8221;&#65288;IDEM&#65289;&#12290;IDEM&#20351;&#29992;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#36830;&#32467;&#21477;&#65292;&#26080;&#27861;&#24341;&#20837;&#26131;&#20110;&#26816;&#27979;&#30340;&#38169;&#35823;&#65292;&#24182;&#19988;&#20351;&#29992;&#21333;&#29420;&#30340;&#20301;&#32622;&#21512;&#24182;&#31574;&#30053;&#26469;&#24179;&#34913;&#25200;&#21160;&#25991;&#26412;&#30340;&#30456;&#20851;&#24615;&#21644;&#36830;&#36143;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;IDEM&#21487;&#20197;&#22312;&#20445;&#25345;&#39640;&#20154;&#31867;&#35780;&#20272;&#24471;&#20998;&#30340;&#21516;&#26102;&#20248;&#20110;&#24378;&#22522;&#32447;&#12290;</title><link>http://arxiv.org/abs/2305.01860</link><description>&lt;p&gt;
&#38024;&#23545;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#30340;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#30340;&#25991;&#26723;&#31713;&#25913;
&lt;/p&gt;
&lt;p&gt;
Towards Imperceptible Document Manipulations against Neural Ranking Models. (arXiv:2305.01860v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01860
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#30340;&#19981;&#26131;&#34987;&#26816;&#27979;&#21040;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#26694;&#26550;&#65292;&#31216;&#20026;&#8220;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#25991;&#26723;&#25805;&#20316;&#8221;&#65288;IDEM&#65289;&#12290;IDEM&#20351;&#29992;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#36830;&#32467;&#21477;&#65292;&#26080;&#27861;&#24341;&#20837;&#26131;&#20110;&#26816;&#27979;&#30340;&#38169;&#35823;&#65292;&#24182;&#19988;&#20351;&#29992;&#21333;&#29420;&#30340;&#20301;&#32622;&#21512;&#24182;&#31574;&#30053;&#26469;&#24179;&#34913;&#25200;&#21160;&#25991;&#26412;&#30340;&#30456;&#20851;&#24615;&#21644;&#36830;&#36143;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;IDEM&#21487;&#20197;&#22312;&#20445;&#25345;&#39640;&#20154;&#31867;&#35780;&#20272;&#24471;&#20998;&#30340;&#21516;&#26102;&#20248;&#20110;&#24378;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#25915;&#20987;&#24050;&#32463;&#24320;&#22987;&#24212;&#29992;&#20110;&#21457;&#29616;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#65288;NRMs&#65289;&#20013;&#30340;&#28508;&#22312;&#28431;&#27934;&#65292;&#20294;&#26159;&#24403;&#21069;&#25915;&#20987;&#26041;&#27861;&#24120;&#24120;&#20250;&#24341;&#20837;&#35821;&#27861;&#38169;&#35823;&#65292;&#26080;&#24847;&#20041;&#30340;&#34920;&#36798;&#65292;&#25110;&#19981;&#36830;&#36143;&#30340;&#25991;&#26412;&#29255;&#27573;&#65292;&#36825;&#20123;&#37117;&#24456;&#23481;&#26131;&#34987;&#26816;&#27979;&#21040;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#20351;&#29992;&#19982;&#30495;&#23454;&#30340;NRM&#30456;&#20284;&#30340;&#27169;&#25311;NRM&#26469;&#20445;&#35777;&#25915;&#20987;&#25928;&#26524;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#22312;&#23454;&#36341;&#20013;&#38590;&#20197;&#20351;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;&#8220;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#25991;&#26723;&#25805;&#20316;&#8221;&#65288;IDEM&#65289;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#29983;&#25104;&#23545;&#31639;&#27861;&#21644;&#20154;&#31867;&#26469;&#35828;&#37117;&#19981;&#22826;&#26126;&#26174;&#30340;&#23545;&#25239;&#25991;&#26723;&#12290;IDEM&#25351;&#31034;&#19968;&#20010;&#32463;&#36807;&#33391;&#22909;&#24314;&#31435;&#30340;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#65288;&#20363;&#22914;BART&#65289;&#29983;&#25104;&#36830;&#25509;&#21477;&#65292;&#32780;&#19981;&#20250;&#24341;&#20837;&#26131;&#20110;&#26816;&#27979;&#30340;&#38169;&#35823;&#65292;&#24182;&#37319;&#29992;&#21333;&#29420;&#30340;&#36880;&#20301;&#32622;&#21512;&#24182;&#31574;&#30053;&#26469;&#24179;&#34913;&#25200;&#21160;&#25991;&#26412;&#30340;&#30456;&#20851;&#24615;&#21644;&#36830;&#36143;&#24615;&#12290;&#22312;&#27969;&#34892;&#30340;MS MARCO&#22522;&#20934;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;IDEM&#21487;&#20197;&#22312;&#20445;&#25345;&#39640;&#20154;&#31867;&#35780;&#20272;&#24471;&#20998;&#30340;&#21516;&#26102;&#65292;&#20248;&#20110;&#24378;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial attacks have gained traction in order to identify potential vulnerabilities in neural ranking models (NRMs), but current attack methods often introduce grammatical errors, nonsensical expressions, or incoherent text fragments, which can be easily detected. Additionally, current methods rely heavily on the use of a well-imitated surrogate NRM to guarantee the attack effect, which makes them difficult to use in practice. To address these issues, we propose a framework called Imperceptible DocumEnt Manipulation (IDEM) to produce adversarial documents that are less noticeable to both algorithms and humans. IDEM instructs a well-established generative language model, such as BART, to generate connection sentences without introducing easy-to-detect errors, and employs a separate position-wise merging strategy to balance relevance and coherence of the perturbed text. Experimental results on the popular MS MARCO benchmark demonstrate that IDEM can outperform strong baselines while 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#30693;&#35782;&#33976;&#39311;&#30340;&#38598;&#25104;&#24314;&#27169;&#26041;&#27861;EMKD&#65292;&#23427;&#37319;&#29992;&#22810;&#20010;&#24182;&#34892;&#32593;&#32476;&#20316;&#20026;&#24207;&#21015;&#32534;&#30721;&#22120;&#65292;&#22312;&#24207;&#21015;&#25512;&#33616;&#20013;&#26681;&#25454;&#25152;&#26377;&#32593;&#32476;&#30340;&#36755;&#20986;&#20998;&#24067;&#25512;&#33616;&#29289;&#21697;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;EMKD&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.14668</link><description>&lt;p&gt;
&#22522;&#20110;&#23545;&#27604;&#30693;&#35782;&#33976;&#39311;&#30340;&#38598;&#25104;&#24314;&#27169;&#22312;&#24207;&#21015;&#25512;&#33616;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Ensemble Modeling with Contrastive Knowledge Distillation for Sequential Recommendation. (arXiv:2304.14668v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14668
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#30693;&#35782;&#33976;&#39311;&#30340;&#38598;&#25104;&#24314;&#27169;&#26041;&#27861;EMKD&#65292;&#23427;&#37319;&#29992;&#22810;&#20010;&#24182;&#34892;&#32593;&#32476;&#20316;&#20026;&#24207;&#21015;&#32534;&#30721;&#22120;&#65292;&#22312;&#24207;&#21015;&#25512;&#33616;&#20013;&#26681;&#25454;&#25152;&#26377;&#32593;&#32476;&#30340;&#36755;&#20986;&#20998;&#24067;&#25512;&#33616;&#29289;&#21697;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;EMKD&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#25512;&#33616;&#26088;&#22312;&#25429;&#25417;&#29992;&#25143;&#30340;&#21160;&#24577;&#20852;&#36259;&#65292;&#39044;&#27979;&#29992;&#25143;&#19979;&#19968;&#27425;&#30340;&#20559;&#22909;&#29289;&#21697;&#12290;&#22810;&#25968;&#26041;&#27861;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#24207;&#21015;&#32534;&#30721;&#22120;&#29983;&#25104;&#29992;&#25143;&#21644;&#29289;&#21697;&#34920;&#31034;&#12290;&#29616;&#26377;&#24037;&#20316;&#20027;&#35201;&#20391;&#37325;&#20110;&#35774;&#35745;&#26356;&#24378;&#30340;&#24207;&#21015;&#32534;&#30721;&#22120;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#23581;&#35797;&#20351;&#29992;&#35757;&#32451;&#19968;&#32452;&#32593;&#32476;&#20316;&#20026;&#24207;&#21015;&#32534;&#30721;&#22120;&#30340;&#26041;&#27861;&#65292;&#36825;&#27604;&#21333;&#20010;&#32593;&#32476;&#26356;&#24378;&#22823;&#65292;&#22240;&#20026;&#19968;&#32452;&#24182;&#34892;&#32593;&#32476;&#21487;&#20197;&#20135;&#29983;&#22810;&#26679;&#21270;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#30693;&#35782;&#33976;&#39311;&#30340;&#38598;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#21363;EMKD&#65292;&#22312;&#24207;&#21015;&#25512;&#33616;&#20013;&#20351;&#29992;&#22810;&#20010;&#24182;&#34892;&#32593;&#32476;&#20316;&#20026;&#24207;&#21015;&#32534;&#30721;&#22120;&#65292;&#24182;&#26681;&#25454;&#25152;&#26377;&#36825;&#20123;&#32593;&#32476;&#30340;&#36755;&#20986;&#20998;&#24067;&#25512;&#33616;&#29289;&#21697;&#12290;&#20026;&#20102;&#20419;&#36827;&#24182;&#34892;&#32593;&#32476;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65292;&#23427;&#23558;&#30693;&#35782;&#20174;&#25945;&#24072;&#32593;&#32476;&#36716;&#31227;&#21040;&#22810;&#20010;&#23398;&#29983;&#32593;&#32476;&#20013;&#12290;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;EMKD&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#26041;&#27861;&#21644;&#38598;&#25104;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation aims to capture users' dynamic interest and predicts the next item of users' preference. Most sequential recommendation methods use a deep neural network as sequence encoder to generate user and item representations. Existing works mainly center upon designing a stronger sequence encoder. However, few attempts have been made with training an ensemble of networks as sequence encoders, which is more powerful than a single network because an ensemble of parallel networks can yield diverse prediction results and hence better accuracy. In this paper, we present Ensemble Modeling with contrastive Knowledge Distillation for sequential recommendation (EMKD). Our framework adopts multiple parallel networks as an ensemble of sequence encoders and recommends items based on the output distributions of all these networks. To facilitate knowledge transfer between parallel networks, we propose a novel contrastive knowledge distillation approach, which performs knowledge tran
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#39064;&#23884;&#20837;&#26041;&#27861;&#21644;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#26080;&#30417;&#30563;&#22312;&#32447;&#25925;&#20107;&#21457;&#29616;&#26694;&#26550;USTORY&#65292;&#21487;&#20197;&#21160;&#24577;&#34920;&#31034;&#25991;&#31456;&#21644;&#25925;&#20107;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#20849;&#20139;&#30340;&#26102;&#38388;&#20027;&#39064;&#21644;&#26032;&#39062;&#24615;&#65292;&#20197;&#24110;&#21161;&#20154;&#20204;&#28040;&#21270;&#22823;&#37327;&#30340;&#26032;&#38395;&#27969;&#12290;</title><link>http://arxiv.org/abs/2304.04099</link><description>&lt;p&gt;
&#36890;&#36807;&#21487;&#25193;&#23637;&#30340;&#20027;&#39064;&#23884;&#20837;&#20174;&#36830;&#32493;&#26032;&#38395;&#27969;&#20013;&#26080;&#30417;&#30563;&#22320;&#21457;&#29616;&#25925;&#20107;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding. (arXiv:2304.04099v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#39064;&#23884;&#20837;&#26041;&#27861;&#21644;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#26080;&#30417;&#30563;&#22312;&#32447;&#25925;&#20107;&#21457;&#29616;&#26694;&#26550;USTORY&#65292;&#21487;&#20197;&#21160;&#24577;&#34920;&#31034;&#25991;&#31456;&#21644;&#25925;&#20107;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#20849;&#20139;&#30340;&#26102;&#38388;&#20027;&#39064;&#21644;&#26032;&#39062;&#24615;&#65292;&#20197;&#24110;&#21161;&#20154;&#20204;&#28040;&#21270;&#22823;&#37327;&#30340;&#26032;&#38395;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#22320;&#21457;&#29616;&#23454;&#26102;&#30456;&#20851;&#26032;&#38395;&#25991;&#31456;&#25925;&#20107;&#65292;&#26377;&#21161;&#20110;&#20154;&#20204;&#22312;&#19981;&#38656;&#35201;&#26114;&#36149;&#20154;&#24037;&#27880;&#37322;&#30340;&#24773;&#20917;&#19979;&#28040;&#21270;&#22823;&#37327;&#30340;&#26032;&#38395;&#27969;&#12290;&#29616;&#26377;&#30340;&#26080;&#30417;&#30563;&#22312;&#32447;&#25925;&#20107;&#21457;&#29616;&#30740;&#31350;&#30340;&#26222;&#36941;&#26041;&#27861;&#26159;&#29992;&#31526;&#21495;&#25110;&#22522;&#20110;&#22270;&#30340;&#23884;&#20837;&#26469;&#34920;&#31034;&#26032;&#38395;&#25991;&#31456;&#65292;&#24182;&#23558;&#23427;&#20204;&#36880;&#27493;&#32858;&#31867;&#25104;&#25925;&#20107;&#12290;&#26368;&#36817;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26377;&#26395;&#36827;&#19968;&#27493;&#25913;&#21892;&#23884;&#20837;&#65292;&#20294;&#26159;&#36890;&#36807;&#26080;&#24046;&#21035;&#22320;&#32534;&#30721;&#25991;&#31456;&#20013;&#30340;&#25152;&#26377;&#20449;&#24687;&#26469;&#30452;&#25509;&#37319;&#29992;&#36825;&#20123;&#27169;&#22411;&#26080;&#27861;&#26377;&#25928;&#22788;&#29702;&#23500;&#21547;&#25991;&#26412;&#19988;&#19981;&#26029;&#21457;&#23637;&#30340;&#26032;&#38395;&#27969;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#39064;&#23884;&#20837;&#26041;&#27861;&#65292;&#20351;&#29992;&#29616;&#25104;&#30340;&#39044;&#35757;&#32451;&#21477;&#23376;&#32534;&#30721;&#22120;&#26469;&#21160;&#24577;&#34920;&#31034;&#25991;&#31456;&#21644;&#25925;&#20107;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#20849;&#20139;&#30340;&#26102;&#38388;&#20027;&#39064;&#12290;&#20026;&#20102;&#23454;&#29616;&#26080;&#30417;&#30563;&#22312;&#32447;&#25925;&#20107;&#21457;&#29616;&#30340;&#24819;&#27861;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#26694;&#26550;USTORY&#65292;&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#25216;&#26415;&#65292;&#21363;&#20027;&#39064;&#21644;&#26102;&#38388;&#24863;&#30693;&#30340;&#21160;&#24577;&#23884;&#20837;&#21644;&#26032;&#39062;&#24615;&#24863;&#30693;&#30340;&#33258;&#36866;&#24212;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised discovery of stories with correlated news articles in real-time helps people digest massive news streams without expensive human annotations. A common approach of the existing studies for unsupervised online story discovery is to represent news articles with symbolic- or graph-based embedding and incrementally cluster them into stories. Recent large language models are expected to improve the embedding further, but a straightforward adoption of the models by indiscriminately encoding all information in articles is ineffective to deal with text-rich and evolving news streams. In this work, we propose a novel thematic embedding with an off-the-shelf pretrained sentence encoder to dynamically represent articles and stories by considering their shared temporal themes. To realize the idea for unsupervised online story discovery, a scalable framework USTORY is introduced with two main techniques, theme- and time-aware dynamic embedding and novelty-aware adaptive clustering, fuel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#36827;&#34892;&#25512;&#29702;&#30340;&#21069;&#27839;&#30740;&#31350;&#32508;&#21512;&#35843;&#26597;&#12290;&#35752;&#35770;&#20102;&#26032;&#20852;&#25512;&#29702;&#33021;&#21147;&#20986;&#29616;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#25552;&#20379;&#31995;&#32479;&#36164;&#28304;&#24110;&#21161;&#21021;&#23398;&#32773;&#12290;</title><link>http://arxiv.org/abs/2212.09597</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#36827;&#34892;&#25512;&#29702;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#36827;&#34892;&#25512;&#29702;&#30340;&#21069;&#27839;&#30740;&#31350;&#32508;&#21512;&#35843;&#26597;&#12290;&#35752;&#35770;&#20102;&#26032;&#20852;&#25512;&#29702;&#33021;&#21147;&#20986;&#29616;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#25552;&#20379;&#31995;&#32479;&#36164;&#28304;&#24110;&#21161;&#21021;&#23398;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#29702;&#20316;&#20026;&#22797;&#26434;&#38382;&#39064;&#35299;&#20915;&#30340;&#37325;&#35201;&#33021;&#21147;&#65292;&#21487;&#20197;&#20026;&#21307;&#30103;&#35786;&#26029;&#12289;&#35848;&#21028;&#31561;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#25552;&#20379;&#21518;&#31471;&#25903;&#25345;&#12290;&#26412;&#25991;&#23545;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#36827;&#34892;&#25512;&#29702;&#30340;&#21069;&#27839;&#30740;&#31350;&#36827;&#34892;&#20102;&#32508;&#21512;&#35843;&#26597;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#30740;&#31350;&#25104;&#26524;&#30340;&#27604;&#36739;&#21644;&#24635;&#32467;&#65292;&#24182;&#25552;&#20379;&#20102;&#31995;&#32479;&#36164;&#28304;&#20197;&#24110;&#21161;&#21021;&#23398;&#32773;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#26032;&#20852;&#25512;&#29702;&#33021;&#21147;&#20986;&#29616;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#31361;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#36164;&#28304;&#21487;&#22312; https://github.com/zjunlp/Prompt4ReasoningPapers &#19978;&#33719;&#21462;&#65288;&#23450;&#26399;&#26356;&#26032;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#33976;&#39311;&#30340;&#25991;&#26723;&#26816;&#32034;&#27169;&#22411;Simplified TinyBERT&#65292;&#23427;&#22312;&#25552;&#20379;15&#20493;&#36895;&#24230;&#25552;&#21319;&#30340;&#24773;&#20917;&#19979;&#27604;BERT-Base&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2009.07531</link><description>&lt;p&gt;
&#31616;&#21270;&#29256;TinyBERT: &#29992;&#20110;&#25991;&#26723;&#26816;&#32034;&#30340;&#30693;&#35782;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Simplified TinyBERT: Knowledge Distillation for Document Retrieval. (arXiv:2009.07531v2 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.07531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#33976;&#39311;&#30340;&#25991;&#26723;&#26816;&#32034;&#27169;&#22411;Simplified TinyBERT&#65292;&#23427;&#22312;&#25552;&#20379;15&#20493;&#36895;&#24230;&#25552;&#21319;&#30340;&#24773;&#20917;&#19979;&#27604;BERT-Base&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21033;&#29992;BERT&#27169;&#22411;&#36827;&#34892;&#25991;&#26723;&#25490;&#24207;&#21313;&#20998;&#26377;&#25928;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#30340;&#39640;&#35745;&#31639;&#25104;&#26412;&#38480;&#21046;&#20102;&#20854;&#20351;&#29992;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#39318;&#20808;&#22312;&#25991;&#26723;&#25490;&#24207;&#20219;&#21153;&#19978;&#23454;&#35777;&#30740;&#31350;&#20102;&#20004;&#20010;&#30693;&#35782;&#33976;&#39311;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#22312;&#26368;&#36817;&#25552;&#20986;&#30340;TinyBERT&#27169;&#22411;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#31616;&#21270;&#26041;&#26696;&#12290;&#20004;&#20010;&#19981;&#21516;&#24182;&#19988;&#24191;&#27867;&#20351;&#29992;&#30340;&#22522;&#20934;&#27979;&#35797;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#20855;&#26377;&#25152;&#25552;&#20986;&#31616;&#21270;&#26041;&#26696;&#30340;Simplified TinyBERT&#19981;&#20165;&#25552;&#21319;&#20102;TinyBERT&#65292;&#32780;&#19988;&#22312;&#25552;&#20379;15&#20493;&#36895;&#24230;&#25552;&#21319;&#30340;&#24773;&#20917;&#19979;&#20063;&#26126;&#26174;&#20248;&#20110;BERT-Base&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the effectiveness of utilizing the BERT model for document ranking, the high computational cost of such approaches limits their uses. To this end, this paper first empirically investigates the effectiveness of two knowledge distillation models on the document ranking task. In addition, on top of the recently proposed TinyBERT model, two simplifications are proposed. Evaluations on two different and widely-used benchmarks demonstrate that Simplified TinyBERT with the proposed simplifications not only boosts TinyBERT, but also significantly outperforms BERT-Base when providing 15$\times$ speedup.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23500;&#26377;&#23646;&#24615;&#32593;&#32476;&#20013;&#39030;&#28857;&#25552;&#21517;&#30340;&#21452;&#37325;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20869;&#23481;&#24863;&#30693;&#30340;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#19981;&#21033;&#29992;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#39030;&#28857;&#25552;&#21517;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2005.02151</link><description>&lt;p&gt;
&#23500;&#26377;&#23646;&#24615;&#32593;&#32476;&#20013;&#30340;&#39030;&#28857;&#25552;&#21517;
&lt;/p&gt;
&lt;p&gt;
Vertex Nomination in Richly Attributed Networks. (arXiv:2005.02151v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.02151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23500;&#26377;&#23646;&#24615;&#32593;&#32476;&#20013;&#39030;&#28857;&#25552;&#21517;&#30340;&#21452;&#37325;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20869;&#23481;&#24863;&#30693;&#30340;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#19981;&#21033;&#29992;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#39030;&#28857;&#25552;&#21517;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39030;&#28857;&#25552;&#21517;&#26159;&#19968;&#39033;&#36731;&#24230;&#30417;&#30563;&#30340;&#32593;&#32476;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#65292;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#65292;&#24863;&#20852;&#36259;&#30340;&#19968;&#24352;&#22270;&#30340;&#39030;&#28857;&#34987;&#29992;&#26469;&#26597;&#35810;&#31532;&#20108;&#24352;&#22270;&#20197;&#21457;&#29616;&#24863;&#20852;&#36259;&#30340;&#31532;&#20108;&#24352;&#22270;&#30340;&#39030;&#28857;&#12290;&#19982;&#20854;&#20182;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#31867;&#20284;&#65292;&#39030;&#28857;&#25552;&#21517;&#26041;&#26696;&#30340;&#36755;&#20986;&#26159;&#31532;&#20108;&#24352;&#22270;&#20013;&#39030;&#28857;&#30340;&#25490;&#24207;&#21015;&#34920;&#65292;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#26410;&#30693;&#30340;&#24863;&#20852;&#36259;&#30340;&#39030;&#28857;&#24212;&#35813;&#38598;&#20013;&#22312;&#21015;&#34920;&#30340;&#39030;&#37096;&#12290;&#39030;&#28857;&#25552;&#21517;&#26041;&#26696;&#20026;&#39640;&#25928;&#22320;&#25366;&#25496;&#22797;&#26434;&#32593;&#32476;&#20013;&#30340;&#30456;&#20851;&#20449;&#24687;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#36341;&#20004;&#26041;&#38754;&#25506;&#35752;&#20102;&#20869;&#23481;&#65288;&#21363;&#36793;&#32536;&#21644;&#39030;&#28857;&#23646;&#24615;&#65289;&#21644;&#19978;&#19979;&#25991;&#65288;&#21363;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#65289;&#22312;&#39030;&#28857;&#25552;&#21517;&#20013;&#30340;&#21452;&#37325;&#20316;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#30340;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21033;&#29992;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#39030;&#28857;&#25552;&#21517;&#26041;&#26696;&#33021;&#22815;&#36229;&#36234;&#20165;&#21033;&#29992;&#20869;&#23481;&#25110;&#19978;&#19979;&#25991;&#30340;&#26041;&#26696;&#12290;&#34429;&#28982;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#32852;&#21512;&#25928;&#29992;&#22312;&#20854;&#20182;&#32593;&#32476;&#20998;&#26512;&#20219;&#21153;&#20013;&#24050;&#32463;&#24471;&#21040;&#35777;&#23454;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#22312;&#39030;&#28857;&#25552;&#21517;&#30340;&#32972;&#26223;&#19979;&#65292;&#36825;&#31181;&#32852;&#21512;&#25928;&#29992;&#20063;&#26159;&#25104;&#31435;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20869;&#23481;&#24863;&#30693;&#30340;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#29992;&#20110;&#39030;&#28857;&#25552;&#21517;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#32467;&#21512;&#23616;&#37096;&#21644;&#20840;&#23616;&#32593;&#32476;&#23646;&#24615;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#30340;&#31038;&#20132;&#21644;&#24341;&#29992;&#32593;&#32476;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#19981;&#21033;&#29992;&#20869;&#23481;&#21644;&#19978;&#19979;&#25991;&#30340;&#29616;&#26377;&#30340;&#39030;&#28857;&#25552;&#21517;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vertex nomination is a lightly-supervised network information retrieval task in which vertices of interest in one graph are used to query a second graph to discover vertices of interest in the second graph. Similar to other information retrieval tasks, the output of a vertex nomination scheme is a ranked list of the vertices in the second graph, with the heretofore unknown vertices of interest ideally concentrating at the top of the list. Vertex nomination schemes provide a useful suite of tools for efficiently mining complex networks for pertinent information. In this paper, we explore, both theoretically and practically, the dual roles of content (i.e., edge and vertex attributes) and context (i.e., network topology) in vertex nomination. We provide necessary and sufficient conditions under which vertex nomination schemes that leverage both content and context outperform schemes that leverage only content or context separately. While the joint utility of both content and context has 
&lt;/p&gt;</description></item></channel></rss>