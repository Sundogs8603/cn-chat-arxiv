<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#25968;&#23398;&#20869;&#23481;&#37325;&#29992;&#30340;&#20998;&#31867;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#21117;&#31363;&#26816;&#27979;&#21644;&#25968;&#23398;&#20869;&#23481;&#30456;&#20284;&#24615;&#30340;&#26368;&#20339;&#26041;&#27861;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#30446;&#21069;&#26368;&#20339;&#26041;&#27861;&#22312;&#21117;&#31363;&#21644;&#25968;&#23398;&#20869;&#23481;&#30456;&#20284;&#24615;&#26041;&#38754;&#30340;&#34920;&#29616;&#20381;&#28982;&#19981;&#29702;&#24819;&#12290;&#36825;&#20123;&#21457;&#29616;&#23558;&#20026;&#21117;&#31363;&#26816;&#27979;&#31995;&#32479;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#38382;&#31572;&#31995;&#32479;&#31561;&#39046;&#22495;&#30340;&#30740;&#31350;&#25552;&#20379;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2401.16969</link><description>&lt;p&gt;
&#25968;&#23398;&#21117;&#31363;&#20998;&#31867;&#27861;
&lt;/p&gt;
&lt;p&gt;
Taxonomy of Mathematical Plagiarism. (arXiv:2401.16969v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#25968;&#23398;&#20869;&#23481;&#37325;&#29992;&#30340;&#20998;&#31867;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#21117;&#31363;&#26816;&#27979;&#21644;&#25968;&#23398;&#20869;&#23481;&#30456;&#20284;&#24615;&#30340;&#26368;&#20339;&#26041;&#27861;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#30446;&#21069;&#26368;&#20339;&#26041;&#27861;&#22312;&#21117;&#31363;&#21644;&#25968;&#23398;&#20869;&#23481;&#30456;&#20284;&#24615;&#26041;&#38754;&#30340;&#34920;&#29616;&#20381;&#28982;&#19981;&#29702;&#24819;&#12290;&#36825;&#20123;&#21457;&#29616;&#23558;&#20026;&#21117;&#31363;&#26816;&#27979;&#31995;&#32479;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#38382;&#31572;&#31995;&#32479;&#31561;&#39046;&#22495;&#30340;&#30740;&#31350;&#25552;&#20379;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21117;&#31363;&#38382;&#39064;&#26159;&#19968;&#20010;&#32039;&#36843;&#30340;&#20851;&#27880;&#28857;&#65292;&#23588;&#20854;&#26159;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#29992;&#24615;&#19979;&#26356;&#20026;&#31361;&#20986;&#12290;&#29616;&#26377;&#30340;&#21117;&#31363;&#26816;&#27979;&#31995;&#32479;&#21487;&#20197;&#21487;&#38752;&#22320;&#25214;&#21040;&#22797;&#21046;&#21644;&#36866;&#24230;&#25913;&#20889;&#30340;&#25991;&#26412;&#65292;&#20294;&#22312;&#25968;&#23398;&#31185;&#23398;&#20013;&#30340;&#24605;&#24819;&#21117;&#31363;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#22240;&#20026;&#25968;&#23398;&#31185;&#23398;&#20013;&#20351;&#29992;&#20102;&#20005;&#26684;&#30340;&#25968;&#23398;&#31526;&#21495;&#12290;&#25105;&#20204;&#20570;&#20986;&#20102;&#20004;&#20010;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#21487;&#33021;&#23384;&#22312;&#21117;&#31363;&#30340;122&#20010;&#31185;&#23398;&#25991;&#26723;&#36827;&#34892;&#27880;&#37322;&#65292;&#24314;&#31435;&#20102;&#25968;&#23398;&#20869;&#23481;&#37325;&#29992;&#30340;&#20998;&#31867;&#27861;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23545;&#21018;&#21018;&#24314;&#31435;&#30340;&#20998;&#31867;&#27861;&#19978;&#26368;&#20339;&#34920;&#29616;&#30340;&#21117;&#31363;&#26816;&#27979;&#26041;&#27861;&#21644;&#25968;&#23398;&#20869;&#23481;&#30456;&#20284;&#24615;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#21117;&#31363;&#21644;&#25968;&#23398;&#20869;&#23481;&#30456;&#20284;&#24615;&#65292;&#34920;&#29616;&#26368;&#20339;&#30340;&#26041;&#27861;&#20998;&#21035;&#36798;&#21040;&#20102;0.06&#21644;0.16&#30340;&#25972;&#20307;&#26816;&#27979;&#20998;&#25968;&#65288;PlagDet&#65289;&#12290;&#36825;&#20123;&#26368;&#20339;&#26041;&#27861;&#26410;&#33021;&#26816;&#27979;&#20986;&#19971;&#31181;&#26032;&#24314;&#31435;&#30340;&#25968;&#23398;&#30456;&#20284;&#24615;&#31867;&#22411;&#20013;&#30340;&#22823;&#37096;&#20998;&#26696;&#20363;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#23558;&#26377;&#21161;&#20110;&#21117;&#31363;&#26816;&#27979;&#31995;&#32479;&#12289;&#25512;&#33616;&#31995;&#32479;&#12289;&#38382;&#31572;&#31995;&#32479;&#21644;&#20854;&#20182;&#30456;&#20851;&#30740;&#31350;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Plagiarism is a pressing concern, even more so with the availability of large language models. Existing plagiarism detection systems reliably find copied and moderately reworded text but fail for idea plagiarism, especially in mathematical science, which heavily uses formal mathematical notation. We make two contributions. First, we establish a taxonomy of mathematical content reuse by annotating potentially plagiarised 122 scientific document pairs. Second, we analyze the best-performing approaches to detect plagiarism and mathematical content similarity on the newly established taxonomy. We found that the best-performing methods for plagiarism and math content similarity achieve an overall detection score (PlagDet) of 0.06 and 0.16, respectively. The best-performing methods failed to detect most cases from all seven newly established math similarity types. Outlined contributions will benefit research in plagiarism detection systems, recommender systems, question-answering systems, an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21482;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#23569;&#37327;&#35757;&#32451;&#27493;&#39588;&#33719;&#21462;&#39640;&#36136;&#37327;&#25991;&#26412;&#23884;&#20837;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#31454;&#20105;&#28608;&#28872;&#30340;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.00368</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25913;&#21892;&#25991;&#26412;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Improving Text Embeddings with Large Language Models. (arXiv:2401.00368v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21482;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#23569;&#37327;&#35757;&#32451;&#27493;&#39588;&#33719;&#21462;&#39640;&#36136;&#37327;&#25991;&#26412;&#23884;&#20837;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#31454;&#20105;&#28608;&#28872;&#30340;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#20165;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#23569;&#20110;1k&#20010;&#35757;&#32451;&#27493;&#39588;&#21363;&#21487;&#33719;&#24471;&#39640;&#36136;&#37327;&#30340;&#25991;&#26412;&#23884;&#20837;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#29616;&#26377;&#26041;&#27861;&#24448;&#24448;&#20381;&#36182;&#22810;&#38454;&#27573;&#20013;&#38388;&#39044;&#35757;&#32451;&#65292;&#20351;&#29992;&#25968;&#21313;&#20159;&#20010;&#24369;&#30417;&#30563;&#25991;&#26412;&#23545;&#36827;&#34892;&#35757;&#32451;&#65292;&#28982;&#21518;&#20877;&#20351;&#29992;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#26500;&#24314;&#22797;&#26434;&#30340;&#35757;&#32451;&#27969;&#31243;&#65292;&#20063;&#19981;&#20381;&#36182;&#20110;&#36890;&#24120;&#21463;&#20219;&#21153;&#22810;&#26679;&#24615;&#21644;&#35821;&#35328;&#35206;&#30422;&#33539;&#22260;&#38480;&#21046;&#30340;&#25163;&#21160;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#21033;&#29992;&#19987;&#26377;&#30340;LLM&#26469;&#20026;&#36817;100&#31181;&#35821;&#35328;&#30340;&#25968;&#21313;&#19975;&#20010;&#25991;&#26412;&#23884;&#20837;&#20219;&#21153;&#29983;&#25104;&#22810;&#26679;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#30340;&#23545;&#27604;&#25439;&#22833;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#24494;&#35843;&#24320;&#28304;&#30340;&#21482;&#26377;&#35299;&#30721;&#22120;&#30340;LLM&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#31454;&#20105;&#28608;&#28872;&#30340;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#32780;&#19988;&#27809;&#26377;&#20351;&#29992;&#20219;&#20309;&#26631;&#35760;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#24403;&#19982;&#21512;&#25104;&#25968;&#25454;&#21644;&#26631;&#35760;&#25968;&#25454;&#30340;&#28151;&#21512;&#36827;&#34892;&#24494;&#35843;&#26102;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21019;&#36896;&#20102;&#26032;&#30340;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training steps. Unlike existing methods that often depend on multi-stage intermediate pre-training with billions of weakly-supervised text pairs, followed by fine-tuning with a few labeled datasets, our method does not require building complex training pipelines or relying on manually collected datasets that are often constrained by task diversity and language coverage. We leverage proprietary LLMs to generate diverse synthetic data for hundreds of thousands of text embedding tasks across nearly 100 languages. We then fine-tune open-source decoder-only LLMs on the synthetic data using standard contrastive loss. Experiments demonstrate that our method achieves strong performance on highly competitive text embedding benchmarks without using any labeled data. Furthermore, when fine-tuned with a mixture of synthetic and labeled data, our model sets new
&lt;/p&gt;</description></item></channel></rss>