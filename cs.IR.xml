<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#65292;&#23454;&#29616;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#26080;&#38656;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#20351;&#29992;&#35821;&#38899;&#25968;&#25454;&#65292;&#19988;&#30456;&#27604;&#20808;&#21069;&#31995;&#32479;&#21462;&#24471;10%&#30340;Recall@1&#32477;&#23545;&#25913;&#36827;</title><link>https://arxiv.org/abs/2404.01616</link><description>&lt;p&gt;
&#23558;LLMs&#36716;&#21270;&#20026;&#36328;&#27169;&#24577;&#21644;&#36328;&#35821;&#35328;&#26816;&#32034;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Transforming LLMs into Cross-modal and Cross-lingual RetrievalSystems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01616
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#65292;&#23454;&#29616;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#26080;&#38656;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#20351;&#29992;&#35821;&#38899;&#25968;&#25454;&#65292;&#19988;&#30456;&#27604;&#20808;&#21069;&#31995;&#32479;&#21462;&#24471;10%&#30340;Recall@1&#32477;&#23545;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#22312;&#20165;&#22522;&#20110;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#65292;&#36825;&#36229;&#20986;&#20102;&#20855;&#26377;&#37197;&#23545;&#35821;&#38899;&#21644;&#25991;&#26412;&#25968;&#25454;&#30340;&#35821;&#35328;&#33539;&#22260;&#12290;&#21516;&#26102;&#65292;&#22522;&#20110;&#21452;&#32534;&#30721;&#22120;&#65288;DE&#65289;&#30340;&#26816;&#32034;&#31995;&#32479;&#23558;&#26597;&#35810;&#21644;&#25991;&#26723;&#25237;&#24433;&#21040;&#30456;&#21516;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#24182;&#22312;&#26816;&#32034;&#21644;&#21452;&#35821;&#25991;&#26412;&#25366;&#25496;&#20013;&#23637;&#31034;&#20102;&#25104;&#21151;&#12290;&#20026;&#20102;&#22312;&#35768;&#22810;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31995;&#32479;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#19981;&#38656;&#35201;&#35821;&#38899;&#25968;&#25454;&#65292;&#24182;&#19988;&#21487;&#20197;&#21033;&#29992;LLM&#30340;&#22810;&#35821;&#35328;&#25991;&#26412;&#29702;&#35299;&#33021;&#21147;&#26469;&#21305;&#37197;&#26816;&#32034;&#35757;&#32451;&#26399;&#38388;&#30475;&#19981;&#35265;&#30340;&#35821;&#35328;&#20013;&#30340;&#35821;&#38899;&#21644;&#25991;&#26412;&#12290;&#25105;&#20204;&#30340;&#22810;&#27169;&#24577;LLM-based&#26816;&#32034;&#31995;&#32479;&#33021;&#22815;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#65292;&#23613;&#31649;&#21482;&#22312;21&#31181;&#35821;&#35328;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#20248;&#20110;&#20808;&#21069;&#19987;&#38376;&#22312;&#25152;&#26377;102&#31181;&#35821;&#35328;&#19978;&#35757;&#32451;&#30340;&#31995;&#32479;&#12290;&#22312;&#36825;&#20123;&#35821;&#35328;&#20013;&#65292;&#25105;&#20204;&#22312;Recall@1&#19978;&#23454;&#29616;&#20102;10&#65285;&#30340;&#32477;&#23545;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01616v1 Announce Type: new  Abstract: Large language models (LLMs) are trained on text-only data that go far beyond the languages with paired speech and text data. At the same time, Dual Encoder (DE) based retrieval systems project queries and documents into the same embedding space and have demonstrated their success in retrieval and bi-text mining. To match speech and text in many languages, we propose using LLMs to initialize multi-modal DE retrieval systems. Unlike traditional methods, our system doesn't require speech data during LLM pre-training and can exploit LLM's multilingual text understanding capabilities to match speech and text in languages unseen during retrieval training. Our multi-modal LLM-based retrieval system is capable of matching speech and text in 102 languages despite only training on 21 languages. Our system outperforms previous systems trained explicitly on all 102 languages. We achieve a 10% absolute improvement in Recall@1 averaged across these l
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#32467;&#21512;&#20102;&#8220;&#35268;&#21010;&#19982;&#26816;&#32034;&#8221;&#21644;&#8220;&#32534;&#36753;&#19982;&#30830;&#35748;&#8221;&#33539;&#24335;&#65292;&#36890;&#36807;&#31070;&#32463;&#26816;&#32034;&#27169;&#22359;&#21644;LLM-based&#26597;&#35810;&#35268;&#21010;&#22120;&#25552;&#39640;&#20102;&#24037;&#20855;&#21033;&#29992;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2404.00450</link><description>&lt;p&gt;
&#35268;&#21010;&#21644;&#32534;&#36753;&#26816;&#32034;&#20197;&#22686;&#24378;&#24037;&#20855;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Planning and Editing What You Retrieve for Enhanced Tool Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00450
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#32467;&#21512;&#20102;&#8220;&#35268;&#21010;&#19982;&#26816;&#32034;&#8221;&#21644;&#8220;&#32534;&#36753;&#19982;&#30830;&#35748;&#8221;&#33539;&#24335;&#65292;&#36890;&#36807;&#31070;&#32463;&#26816;&#32034;&#27169;&#22359;&#21644;LLM-based&#26597;&#35810;&#35268;&#21010;&#22120;&#25552;&#39640;&#20102;&#24037;&#20855;&#21033;&#29992;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#23558;&#22806;&#37096;&#24037;&#20855;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#38598;&#25104;&#26041;&#38754;&#21462;&#24471;&#30340;&#36827;&#23637;&#25171;&#24320;&#20102;&#26032;&#30340;&#39046;&#22495;&#65292;&#24212;&#29992;&#33539;&#22260;&#28085;&#30422;&#25968;&#23398;&#25512;&#29702;&#12289;&#20195;&#30721;&#29983;&#25104;&#22120;&#21644;&#26234;&#33021;&#21161;&#25163;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#31616;&#21333;&#30340;&#19968;&#27425;&#24615;&#26816;&#32034;&#31574;&#30053;&#65292;&#26080;&#27861;&#26377;&#25928;&#20934;&#30830;&#22320;&#31579;&#36873;&#30456;&#20851;&#24037;&#20855;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#8220;&#35268;&#21010;&#19982;&#26816;&#32034;&#65288;P&amp;R&#65289;&#8221;&#21644;&#8220;&#32534;&#36753;&#19982;&#30830;&#35748;&#65288;E&amp;G&#65289;&#8221;&#33539;&#24335;&#30340;&#27169;&#22411;&#65292;&#21253;&#25324;&#20102;&#31070;&#32463;&#26816;&#32034;&#27169;&#22359;&#21644;&#22522;&#20110;LLM&#30340;&#26597;&#35810;&#35268;&#21010;&#22120;&#65292;&#20197;&#22686;&#24378;&#24037;&#20855;&#21033;&#29992;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00450v1 Announce Type: new  Abstract: Recent advancements in integrating external tools with Large Language Models (LLMs) have opened new frontiers, with applications in mathematical reasoning, code generators, and smart assistants. However, existing methods, relying on simple one-time retrieval strategies, fall short on effectively and accurately shortlisting relevant tools. This paper introduces a novel \modelname (\modelmeaning) approach, encompassing ``Plan-and-Retrieve (P\&amp;R)'' and ``Edit-and-Ground (E\&amp;G)'' paradigms. The P\&amp;R paradigm consists of a neural retrieval module for shortlisting relevant tools and an LLM-based query planner that decomposes complex queries into actionable tasks, enhancing the effectiveness of tool utilization. The E\&amp;G paradigm utilizes LLMs to enrich tool descriptions based on user scenarios, bridging the gap between user queries and tool functionalities. Experiment results demonstrate that these paradigms significantly improve the recall an
&lt;/p&gt;</description></item><item><title>EulerFormer&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#22797;&#26434;&#21521;&#37327;&#27880;&#24847;&#21147;&#30340;&#26032;&#22411;&#36716;&#25442;&#22120;&#21464;&#20307;&#65292;&#32479;&#19968;&#20102;&#35821;&#20041;&#24046;&#24322;&#21644;&#20301;&#32622;&#24046;&#24322;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2403.17729</link><description>&lt;p&gt;
EulerFormer&#65306;&#20855;&#26377;&#22797;&#26434;&#21521;&#37327;&#27880;&#24847;&#21147;&#30340;&#39034;&#24207;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
EulerFormer: Sequential User Behavior Modeling with Complex Vector Attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17729
&lt;/p&gt;
&lt;p&gt;
EulerFormer&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#22797;&#26434;&#21521;&#37327;&#27880;&#24847;&#21147;&#30340;&#26032;&#22411;&#36716;&#25442;&#22120;&#21464;&#20307;&#65292;&#32479;&#19968;&#20102;&#35821;&#20041;&#24046;&#24322;&#21644;&#20301;&#32622;&#24046;&#24322;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25429;&#25417;&#29992;&#25143;&#20559;&#22909;&#65292;&#36716;&#25442;&#22120;&#27169;&#22411;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#24314;&#27169;&#39034;&#24207;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#12290;&#36716;&#25442;&#22120;&#26550;&#26500;&#30340;&#26680;&#24515;&#22312;&#20110;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23427;&#35745;&#31639;&#24207;&#21015;&#20013;&#30340;&#25104;&#23545;&#27880;&#24847;&#21147;&#20998;&#25968;&#12290;&#30001;&#20110;&#25490;&#21015;&#31561;&#21464;&#24615;&#30340;&#29305;&#24615;&#65292;&#20301;&#32622;&#32534;&#30721;&#29992;&#20110;&#22686;&#24378;&#20196;&#29260;&#34920;&#31034;&#20043;&#38388;&#30340;&#27880;&#24847;&#21147;&#12290;&#22312;&#36825;&#31181;&#35774;&#23450;&#19979;&#65292;&#25104;&#23545;&#27880;&#24847;&#21147;&#20998;&#25968;&#21487;&#20197;&#36890;&#36807;&#35821;&#20041;&#24046;&#24322;&#21644;&#20301;&#32622;&#24046;&#24322;&#20004;&#32773;&#34893;&#29983;&#20986;&#26469;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#32463;&#24120;&#20197;&#19981;&#21516;&#26041;&#24335;&#24314;&#27169;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#24046;&#24322;&#27979;&#37327;&#65292;&#36825;&#21487;&#33021;&#38480;&#21046;&#20102;&#24207;&#21015;&#24314;&#27169;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EulerFormer&#30340;&#20855;&#26377;&#22797;&#26434;&#21521;&#37327;&#27880;&#24847;&#21147;&#30340;&#26032;&#22411;&#36716;&#25442;&#22120;&#21464;&#20307;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#26694;&#26550;&#26469;&#34920;&#36848;&#35821;&#20041;&#24046;&#24322;&#21644;&#20301;&#32622;&#24046;&#24322;&#12290; EulerFormer&#21253;&#21547;&#20004;&#20010;&#20851;&#38190;&#25216;&#26415;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17729v1 Announce Type: cross  Abstract: To capture user preference, transformer models have been widely applied to model sequential user behavior data. The core of transformer architecture lies in the self-attention mechanism, which computes the pairwise attention scores in a sequence. Due to the permutation-equivariant nature, positional encoding is used to enhance the attention between token representations. In this setting, the pairwise attention scores can be derived by both semantic difference and positional difference. However, prior studies often model the two kinds of difference measurements in different ways, which potentially limits the expressive capacity of sequence modeling. To address this issue, this paper proposes a novel transformer variant with complex vector attention, named EulerFormer, which provides a unified theoretical framework to formulate both semantic difference and positional difference. The EulerFormer involves two key technical improvements. Fi
&lt;/p&gt;</description></item><item><title>BIRCO&#22522;&#20934;&#35780;&#20272;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#23545;&#22810;&#26041;&#38754;&#29992;&#25143;&#30446;&#26631;&#30340;&#26816;&#32034;&#33021;&#21147;&#65292;&#21457;&#29616;&#26032;&#30340;&#26816;&#32034;&#21327;&#35758;&#21644;&#26356;&#24378;&#22823;&#30340;&#27169;&#22411;&#26159;&#35299;&#20915;&#22797;&#26434;&#29992;&#25143;&#38656;&#27714;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.14151</link><description>&lt;p&gt;
BIRCO&#65306;&#20855;&#26377;&#22797;&#26434;&#30446;&#26631;&#30340;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14151
&lt;/p&gt;
&lt;p&gt;
BIRCO&#22522;&#20934;&#35780;&#20272;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#23545;&#22810;&#26041;&#38754;&#29992;&#25143;&#30446;&#26631;&#30340;&#26816;&#32034;&#33021;&#21147;&#65292;&#21457;&#29616;&#26032;&#30340;&#26816;&#32034;&#21327;&#35758;&#21644;&#26356;&#24378;&#22823;&#30340;&#27169;&#22411;&#26159;&#35299;&#20915;&#22797;&#26434;&#29992;&#25143;&#38656;&#27714;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#22797;&#26434;&#30446;&#26631;&#30340;&#20449;&#24687;&#26816;&#32034;(IR)&#20219;&#21153;&#22522;&#20934;(BIRCO)&#12290; BIRCO&#35780;&#20272;IR&#31995;&#32479;&#26681;&#25454;&#22810;&#26041;&#38754;&#29992;&#25143;&#30446;&#26631;&#26816;&#32034;&#25991;&#26723;&#30340;&#33021;&#21147;&#12290; &#35813;&#22522;&#20934;&#30340;&#22797;&#26434;&#24615;&#21644;&#32039;&#20945;&#22823;&#23567;&#20351;&#20854;&#36866;&#29992;&#20110;&#35780;&#20272;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22359;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#30740;&#31350;&#21487;&#33021;&#24433;&#21709;LLM&#22312;&#26816;&#32034;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#30340;&#22240;&#32032;&#65292;&#24182;&#30830;&#23450;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22522;&#32447;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#19982;&#25110;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#21644;&#26356;&#22797;&#26434;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290; &#27809;&#26377;&#19968;&#31181;&#26041;&#27861;&#22312;&#25152;&#26377;&#22522;&#20934;&#20219;&#21153;&#19978;&#22343;&#36798;&#21040;&#20196;&#20154;&#28385;&#24847;&#30340;&#24615;&#33021;&#65292;&#36825;&#34920;&#26126;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#27169;&#22411;&#21644;&#26032;&#30340;&#26816;&#32034;&#21327;&#35758;&#26469;&#35299;&#20915;&#22797;&#26434;&#30340;&#29992;&#25143;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14151v1 Announce Type: cross  Abstract: We present the Benchmark of Information Retrieval (IR) tasks with Complex Objectives (BIRCO). BIRCO evaluates the ability of IR systems to retrieve documents given multi-faceted user objectives. The benchmark's complexity and compact size make it suitable for evaluating large language model (LLM)-based information retrieval systems. We present a modular framework for investigating factors that may influence LLM performance on retrieval tasks, and identify a simple baseline model which matches or outperforms existing approaches and more complex alternatives. No approach achieves satisfactory performance on all benchmark tasks, suggesting that stronger models and new retrieval protocols are necessary to address complex user needs.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23637;&#31034;&#20102;n-gram&#35821;&#35328;&#27169;&#22411;&#30340;&#20215;&#20540;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;infini-gram&#30340;&#24341;&#25806;&#65292;&#23427;&#21487;&#20197;&#20197;&#27627;&#31186;&#32423;&#30340;&#24310;&#36831;&#35745;&#31639;&#20219;&#24847;n&#30340;n-gram&#27010;&#29575;&#65292;&#20351;&#24471;&#22312;&#31070;&#32463;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23545;&#25991;&#26412;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#20998;&#26512;&#25104;&#20026;&#21487;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.17377</link><description>&lt;p&gt;
&#26080;&#38480;-gram&#65306;&#23558;&#26080;&#38480;n-gram&#35821;&#35328;&#27169;&#22411;&#25193;&#23637;&#21040;&#19975;&#20159;&#26631;&#35760;
&lt;/p&gt;
&lt;p&gt;
Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17377
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23637;&#31034;&#20102;n-gram&#35821;&#35328;&#27169;&#22411;&#30340;&#20215;&#20540;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;infini-gram&#30340;&#24341;&#25806;&#65292;&#23427;&#21487;&#20197;&#20197;&#27627;&#31186;&#32423;&#30340;&#24310;&#36831;&#35745;&#31639;&#20219;&#24847;n&#30340;n-gram&#27010;&#29575;&#65292;&#20351;&#24471;&#22312;&#31070;&#32463;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23545;&#25991;&#26412;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#20998;&#26512;&#25104;&#20026;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26102;&#20195;&#65292;n-gram&#35821;&#35328;&#27169;&#22411;&#36824;&#20855;&#26377;&#30456;&#20851;&#24615;&#21527;&#65311;&#25105;&#20204;&#30340;&#31572;&#26696;&#26159;&#32943;&#23450;&#30340;&#65292;&#24182;&#19988;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#25991;&#26412;&#20998;&#26512;&#21644;&#25913;&#36827;&#31070;&#32463;LLM&#26041;&#38754;&#30340;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#38656;&#35201;&#22312;&#20004;&#20010;&#26041;&#38754;&#23545;n-gram&#27169;&#22411;&#36827;&#34892;&#29616;&#20195;&#21270;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#23427;&#20204;&#19982;&#31070;&#32463;LLM&#30456;&#21516;&#30340;&#25968;&#25454;&#35268;&#27169;&#35757;&#32451;- 1.4&#19975;&#20159;&#20010;&#26631;&#35760;&#12290;&#36825;&#26159;&#36804;&#20170;&#20026;&#27490;&#26500;&#24314;&#30340;&#26368;&#22823;&#30340;n-gram&#27169;&#22411;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#30340;n-gram&#27169;&#22411;&#20351;&#29992;&#30340;n&#24456;&#23567;&#65292;&#36825;&#22952;&#30861;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#65307;&#30456;&#21453;&#65292;&#25105;&#20204;&#20801;&#35768;n&#21487;&#20197;&#26159;&#20219;&#24847;&#22823;&#30340;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#26080;&#38480;-gram LM&#19982;&#22238;&#36864;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;infini-gram&#30340;&#24341;&#25806;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#21518;&#32512;&#25968;&#32452;&#35745;&#31639;&#26080;&#38480;-gram&#65288;&#20197;&#21450;&#20219;&#24847;n&#30340;n-gram&#65289;&#27010;&#29575;&#65292;&#24182;&#19988;&#20855;&#26377;&#27627;&#31186;&#32423;&#30340;&#24310;&#36831;&#65292;&#32780;&#26080;&#38656;&#39044;&#20808;&#35745;&#31639;n-gram&#35745;&#25968;&#34920;&#65288;&#36825;&#23558;&#38750;&#24120;&#26114;&#36149;&#65289;&#12290;&#26080;&#38480;-gram&#26694;&#26550;&#21644;infini-gram&#24341;&#25806;&#20351;&#25105;&#20204;&#33021;&#22815;&#23545;&#20154;&#31867;&#20889;&#20316;&#21644;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;&#36827;&#34892;&#35768;&#22810;&#26032;&#39062;&#21644;&#26377;&#24847;&#24605;&#30340;&#20998;&#26512;&#65306;&#25105;&#20204;&#21457;&#29616;&#26080;&#38480;-gram LM...
&lt;/p&gt;
&lt;p&gt;
Are n-gram language models still relevant in this era of neural large language models (LLMs)? Our answer is yes, and we show their values in both text analysis and improving neural LLMs. Yet this necessitates modernizing n-gram models in two aspects. First, we train them at the same data scale as neural LLMs -- 1.4 trillion tokens. This is the largest n-gram model ever built. Second, existing n-gram models use small n which hinders their performance; we instead allow n to be arbitrarily large, by introducing a new $\infty$-gram LM with backoff. Instead of pre-computing n-gram count tables (which would be very expensive), we develop an engine named infini-gram -- powered by suffix arrays -- that can compute $\infty$-gram (as well as n-gram with arbitrary n) probabilities with millisecond-level latency. The $\infty$-gram framework and infini-gram engine enable us to conduct many novel and interesting analyses of human-written and machine-generated text: we find that the $\infty$-gram LM 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#65292;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#31574;&#30053;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#26032;&#21453;&#24212;&#25351;&#32441;&#65292;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#27492;&#31995;&#32479;&#21487;&#20197;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.10776</link><description>&lt;p&gt;
&#22312;&#21270;&#23398;&#21512;&#25104;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#20013;&#65292;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Generative Agent for Reaction Condition Recommendation in Chemical Synthesis. (arXiv:2311.10776v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.10776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#65292;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#31574;&#30053;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#26032;&#21453;&#24212;&#25351;&#32441;&#65292;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#27492;&#31995;&#32479;&#21487;&#20197;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20026;&#21270;&#23398;&#31038;&#20250;&#20013;&#30340;&#33258;&#21160;&#21270;&#21270;&#23398;&#21453;&#24212;&#38138;&#24179;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#26410;&#26469;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#12290;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#25628;&#32034;&#21644;&#20998;&#26512;&#31574;&#30053;&#65292;&#35813;&#20195;&#29702;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#26597;&#35810;&#20998;&#23376;&#25968;&#25454;&#24211;&#65292;&#24182;&#20174;&#22312;&#32447;&#25991;&#29486;&#20013;&#25552;&#21462;&#20851;&#38190;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#36824;&#37197;&#22791;&#20102;&#25105;&#20204;&#20026;RCR&#20219;&#21153;&#24320;&#21457;&#30340;&#26032;&#21453;&#24212;&#25351;&#32441;&#12290;&#30001;&#20110;RAG&#25216;&#26415;&#30340;&#20351;&#29992;&#65292;&#25105;&#20204;&#30340;&#20195;&#29702;&#20351;&#29992;&#26356;&#26032;&#30340;&#22312;&#32447;&#25968;&#25454;&#24211;&#20316;&#20026;&#30693;&#35782;&#28304;&#65292;&#26174;&#33879;&#20248;&#20110;&#20165;&#21463;&#20854;&#35757;&#32451;&#25968;&#25454;&#22266;&#23450;&#30693;&#35782;&#38480;&#21046;&#30340;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#31995;&#32479;&#21487;&#20197;&#26174;&#33879;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;&#36825;&#19968;&#37325;&#22823;&#36827;&#23637;&#23558;&#35745;&#31639;&#25216;&#26415;&#19982;&#21270;&#23398;&#31038;&#20250;&#26356;&#32039;&#23494;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent artificial intelligence (AI) research plots a promising future of automatic chemical reactions within the chemistry society. This study presents a transformative AI agent that automates the reaction condition recommendation (RCR) task in chemistry using retrieval-augmented generation (RAG) technology. By emulating expert chemists search and analysis strategies, the agent employs large language models (LLMs) to interrogate molecular databases and distill critical data from online literature. Further, the AI agent is equipped with our novel reaction fingerprint developed for the RCR task. Thanks to the RAG technology, our agent uses updated online databases as knowledge sources, significantly outperforming conventional AIs confined to the fixed knowledge within its training data. The resulting system can significantly reduce chemists workload, allowing them to focus on more fundamental and creative scientific problems. This significant advancement brings closer computational techn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.02058</link><description>&lt;p&gt;
&#25972;&#21512;&#40065;&#33725;&#34892;&#20026;&#21040;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;
&lt;/p&gt;
&lt;p&gt;
Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21253;&#21547;&#21487;&#38752;&#24615;&#27979;&#37327;&#30340;&#25512;&#33616;&#31995;&#32479;&#24448;&#24448;&#22312;&#39044;&#27979;&#20013;&#26356;&#21152;&#20445;&#23432;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20445;&#25345;&#21487;&#38752;&#24615;&#12290;&#36825;&#23548;&#33268;&#20102;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#25552;&#20379;&#30340;&#35206;&#30422;&#33539;&#22260;&#21644;&#26032;&#39062;&#24615;&#30340;&#26174;&#33879;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#30697;&#38453;&#20998;&#35299;&#22411;&#25512;&#33616;&#31995;&#32479;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#21152;&#20837;&#19968;&#39033;&#26032;&#30340;&#39033;&#65292;&#31216;&#20026;&#40065;&#33725;&#34892;&#20026;&#65292;&#23427;&#21487;&#20197;&#25511;&#21046;&#22312;&#20570;&#20986;&#20851;&#20110;&#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#20915;&#31574;&#26102;&#25152;&#24076;&#26395;&#30340;&#39118;&#38505;&#27700;&#24179;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#40065;&#33725;&#34892;&#20026;&#19981;&#20165;&#20801;&#35768;&#36827;&#34892;&#39118;&#38505;&#35843;&#25511;&#65292;&#36824;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#30340;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
&lt;/p&gt;</description></item></channel></rss>