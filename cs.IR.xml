<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26102;&#38388;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;LTGNN&#65289;&#65292;&#29992;&#20110;&#25193;&#23637;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13973</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#25512;&#33616;&#31995;&#32479;&#30340;&#32447;&#24615;&#26102;&#38388;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Linear-Time Graph Neural Networks for Scalable Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13973
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26102;&#38388;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;LTGNN&#65289;&#65292;&#29992;&#20110;&#25193;&#23637;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#29190;&#28856;&#30340;&#26102;&#20195;&#65292;&#25512;&#33616;&#31995;&#32479;&#26159;&#20026;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#25512;&#33616;&#31995;&#32479;&#30340;&#20851;&#38190;&#22312;&#20110;&#26681;&#25454;&#20808;&#21069;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20114;&#21160;&#26469;&#39044;&#27979;&#29992;&#25143;&#30340;&#26410;&#26469;&#34892;&#20026;&#12290;&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#20854;&#24378;&#22823;&#30340;&#39640;&#38454;&#36830;&#25509;&#24615;&#25429;&#25417;&#33021;&#21147;&#65292;&#20154;&#20204;&#23545;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#26469;&#25552;&#21319;&#25512;&#33616;&#31995;&#32479;&#39044;&#27979;&#24615;&#33021;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#32463;&#20856;&#30340;&#30697;&#38453;&#20998;&#35299;&#65288;MF&#65289;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#26041;&#27861;&#30001;&#20110;&#20854;&#21487;&#25193;&#23637;&#24615;&#20248;&#21183;&#65292;&#20173;&#22312;&#23454;&#38469;&#30340;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#12290;&#23613;&#31649;&#23384;&#22312;GNN&#21152;&#36895;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;GNN-based&#25512;&#33616;&#31995;&#32479;&#33021;&#21542;&#20687;&#32463;&#20856;&#30340;MF&#21644;DNN&#26041;&#27861;&#19968;&#26679;&#39640;&#25928;&#25193;&#23637;&#20173;&#26159;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26102;&#38388;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;LTGNN&#65289;&#26469;&#25193;&#23637;GN
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13973v1 Announce Type: cross  Abstract: In an era of information explosion, recommender systems are vital tools to deliver personalized recommendations for users. The key of recommender systems is to forecast users' future behaviors based on previous user-item interactions. Due to their strong expressive power of capturing high-order connectivities in user-item interaction data, recent years have witnessed a rising interest in leveraging Graph Neural Networks (GNNs) to boost the prediction performance of recommender systems. Nonetheless, classic Matrix Factorization (MF) and Deep Neural Network (DNN) approaches still play an important role in real-world large-scale recommender systems due to their scalability advantages. Despite the existence of GNN-acceleration solutions, it remains an open question whether GNN-based recommender systems can scale as efficiently as classic MF and DNN methods. In this paper, we propose a Linear-Time Graph Neural Network (LTGNN) to scale up GN
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#30041;&#23384;&#24341;&#21457;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#30340;&#34892;&#20026;&#22312;&#36807;&#28193;&#26399;&#38388;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#65292;&#20174;&#32780;&#30772;&#22351;&#20102;A/B&#23454;&#39564;&#20316;&#20026;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13959</link><description>&lt;p&gt;
&#20855;&#26377;&#24322;&#26500;&#29992;&#25143;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#30041;&#23384;&#24341;&#21457;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Retention Induced Biases in a Recommendation System with Heterogeneous Users
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13959
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#30041;&#23384;&#24341;&#21457;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#30340;&#34892;&#20026;&#22312;&#36807;&#28193;&#26399;&#38388;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#65292;&#20174;&#32780;&#30772;&#22351;&#20102;A/B&#23454;&#39564;&#20316;&#20026;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#30740;&#31350;&#20102;&#19968;&#20010;&#20855;&#26377;&#29992;&#25143;&#27969;&#20837;&#21644;&#27969;&#22833;&#21160;&#24577;&#30340;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#30340;&#27010;&#24565;&#27169;&#22411;&#12290;&#24403;&#27969;&#20837;&#21644;&#27969;&#22833;&#36798;&#21040;&#24179;&#34913;&#26102;&#65292;&#29992;&#25143;&#20998;&#24067;&#36798;&#21040;&#31283;&#23450;&#29366;&#24577;&#12290;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#25913;&#21464;&#31283;&#23450;&#29366;&#24577;&#24182;&#20135;&#29983;&#36807;&#28193;&#26399;&#12290;&#22312;&#36825;&#20010;&#26399;&#38388;&#65292;RS&#30340;&#34892;&#20026;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#36807;&#28193;&#26399;&#20869;&#33719;&#24471;&#30340;A/B&#23454;&#39564;&#25351;&#26631;&#26159;RS&#38271;&#26399;&#24615;&#33021;&#30340;&#20559;&#35265;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#23398;&#32773;&#21644;&#23454;&#36341;&#32773;&#32463;&#24120;&#22312;&#24341;&#20837;&#26032;&#31639;&#27861;&#21518;&#19981;&#20037;&#36827;&#34892;A/B&#27979;&#35797;&#20197;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#40644;&#37329;&#26631;&#20934;&#30340;A/B&#23454;&#39564;&#33539;&#24335;&#21487;&#33021;&#20135;&#29983;&#38169;&#35823;&#32467;&#35770;&#12290;&#25105;&#36824;&#31616;&#35201;&#35752;&#35770;&#20102;&#29992;&#25143;&#20445;&#30041;&#21160;&#24577;&#36896;&#25104;&#30340;&#25968;&#25454;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13959v1 Announce Type: new  Abstract: I examine a conceptual model of a recommendation system (RS) with user inflow and churn dynamics. When inflow and churn balance out, the user distribution reaches a steady state. Changing the recommendation algorithm alters the steady state and creates a transition period. During this period, the RS behaves differently from its new steady state. In particular, A/B experiment metrics obtained in transition periods are biased indicators of the RS's long term performance. Scholars and practitioners, however, often conduct A/B tests shortly after introducing new algorithms to validate their effectiveness. This A/B experiment paradigm, widely regarded as the gold standard for assessing RS improvements, may consequently yield false conclusions. I also briefly discuss the data bias caused by the user retention dynamics.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#22359;&#24335;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38271;&#25991;&#26723;&#20013;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#30340;&#25361;&#25112;&#65292;&#24182;&#23454;&#29616;&#20102;&#21452;&#21521;&#20132;&#20114;</title><link>https://arxiv.org/abs/2402.13897</link><description>&lt;p&gt;
&#31185;&#23398;&#26816;&#26597;&#32773;&#20877;&#24230;&#21319;&#32423;&#65306;&#36879;&#26126;&#24230;&#21644;&#36923;&#36753;&#25512;&#29702;&#30340;&#21452;&#21521;&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13897
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#22359;&#24335;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38271;&#25991;&#26723;&#20013;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#30340;&#25361;&#25112;&#65292;&#24182;&#23454;&#29616;&#20102;&#21452;&#21521;&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#23427;&#20173;&#28982;&#38754;&#20020;&#30528;&#22312;&#31185;&#23398;&#21644;&#24037;&#19994;&#30340;&#28023;&#37327;&#20449;&#24687;&#20013;&#30340;&#35832;&#22810;&#38480;&#21046;&#65292;&#27604;&#22914;&#35821;&#20041;&#20998;&#27495;&#21644;&#26816;&#32034;&#20013;&#30340;&#35789;&#27719;&#24046;&#36317;&#12289;&#35821;&#20041;&#25628;&#32034;&#20013;&#30340;&#20302;&#31934;&#24230;&#21644;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65292;&#25110;&#32773;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#21644;&#36807;&#26102;&#20449;&#24687;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#22359;&#24335;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38271;&#25991;&#26723;&#30340;&#36825;&#20123;&#38556;&#30861;&#12290;&#31532;&#19968;&#20010;&#27169;&#22359;&#36890;&#36807;&#26597;&#35810;&#25193;&#23637;&#22686;&#24378;&#20102;&#22312;&#31232;&#30095;&#26816;&#32034;&#20013;&#30340;&#35821;&#35328;&#29702;&#35299;&#65292;&#20197;&#26816;&#32034;&#30456;&#20851;&#25991;&#26723;&#12290;&#31532;&#20108;&#20010;&#27169;&#22359;&#36890;&#36807;&#21482;&#20351;&#29992;&#38271;&#25991;&#26723;&#20013;&#20256;&#25773;&#30340;&#20449;&#24687;&#65292;&#20026;&#22797;&#26434;&#38382;&#39064;&#25552;&#20379;&#20840;&#38754;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#31572;&#26696;&#26469;&#21152;&#28145;&#32467;&#26524;&#65292;&#23454;&#29616;&#21452;&#21521;&#20132;&#20114;&#12290;&#22312;&#31649;&#36947;&#30340;&#21508;&#20010;&#38454;&#27573;&#65292;&#21521;&#29992;&#25143;&#21576;&#29616;&#20013;&#38388;&#32467;&#26524;&#20197;&#20419;&#36827;&#23545;&#31995;&#32479;&#25512;&#29702;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#30456;&#20449;&#36825;&#31181;&#21452;&#21521;&#26041;&#27861;&#24102;&#26469;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13897v1 Announce Type: cross  Abstract: Information retrieval is a rapidly evolving field. However it still faces significant limitations in the scientific and industrial vast amounts of information, such as semantic divergence and vocabulary gaps in sparse retrieval, low precision and lack of interpretability in semantic search, or hallucination and outdated information in generative models. In this paper, we introduce a two-block approach to tackle these hurdles for long documents. The first block enhances language understanding in sparse retrieval by query expansion to retrieve relevant documents. The second block deepens the result by providing comprehensive and informative answers to the complex question using only the information spread in the long document, enabling bidirectional engagement. At various stages of the pipeline, intermediate results are presented to users to facilitate understanding of the system's reasoning. We believe this bidirectional approach brings
&lt;/p&gt;</description></item><item><title>&#23558;&#22810;&#26679;&#24615;&#30446;&#26631;&#34701;&#20837;&#21407;&#22987;&#30456;&#20851;&#24615;&#30446;&#26631;&#30340;&#22810;&#26679;&#24615;&#24863;&#30693;$k$-&#26368;&#22823;&#20869;&#31215;&#25628;&#32034;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#29992;&#25143;&#22312;&#30456;&#20851;&#24615;&#21644;&#22810;&#26679;&#24615;&#20043;&#38388;&#21487;&#25511;&#30340;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2402.13858</link><description>&lt;p&gt;
&#22810;&#26679;&#24615;&#24863;&#30693;$k$-&#26368;&#22823;&#20869;&#31215;&#25628;&#32034;&#20877;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
Diversity-Aware $k$-Maximum Inner Product Search Revisited
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13858
&lt;/p&gt;
&lt;p&gt;
&#23558;&#22810;&#26679;&#24615;&#30446;&#26631;&#34701;&#20837;&#21407;&#22987;&#30456;&#20851;&#24615;&#30446;&#26631;&#30340;&#22810;&#26679;&#24615;&#24863;&#30693;$k$-&#26368;&#22823;&#20869;&#31215;&#25628;&#32034;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#29992;&#25143;&#22312;&#30456;&#20851;&#24615;&#21644;&#22810;&#26679;&#24615;&#20043;&#38388;&#21487;&#25511;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
$k$-&#26368;&#22823;&#20869;&#31215;&#25628;&#32034;($k$MIPS)&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#21644;&#21508;&#31181;&#25968;&#25454;&#25366;&#25496;&#20219;&#21153;&#20013;&#30340;&#22522;&#30784;&#32452;&#20214;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;$k$MIPS&#26041;&#27861;&#20248;&#20808;&#32771;&#34385;&#20026;&#29992;&#25143;&#39640;&#24230;&#30456;&#20851;&#30340;&#39033;&#30446;&#36827;&#34892;&#39640;&#25928;&#26816;&#32034;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#24573;&#30053;&#20102;&#25628;&#32034;&#32467;&#26524;&#21516;&#26679;&#20851;&#38190;&#30340;&#19968;&#20010;&#26041;&#38754;&#65306;\emph{&#22810;&#26679;&#24615;}&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#21644;&#23436;&#21892;&#20102;&#22810;&#26679;&#24615;&#24863;&#30693;$k$MIPS&#65288;D$k$MIPS&#65289;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#20004;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#22810;&#26679;&#24615;&#30446;&#26631;--&#22312;&#32467;&#26524;&#20013;&#26368;&#23567;&#21270;&#24179;&#22343;&#21644;&#26368;&#22823;&#25104;&#23545;&#39033;&#30446;&#30456;&#20284;&#24615;--&#34701;&#20837;&#21407;&#22987;&#30456;&#20851;&#24615;&#30446;&#26631;&#12290;&#36825;&#31181;&#22686;&#24378;&#21463;&#21040;&#20102;&#26497;&#22823;&#36793;&#38469;&#30456;&#20851;&#24615;&#65288;MMR&#65289;&#30340;&#21551;&#21457;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#20102;&#20851;&#20110;&#30456;&#20851;&#24615;&#21644;&#22810;&#26679;&#24615;&#20043;&#38388;&#21487;&#25511;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;\textsc{Greedy}&#21644;\textsc{DualGreedy}&#65292;&#36825;&#20004;&#31181;&#22522;&#20110;&#32447;&#24615;&#25195;&#25551;&#30340;&#31639;&#27861;&#19987;&#38376;&#29992;&#20110;D$k$MIPS&#12290;&#23427;&#20204;&#37117;&#23454;&#29616;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#36817;&#20284;&#65292;&#24182;&#22312;&#26088;&#22312;&#26368;&#23567;&#21270;&#24179;&#22343;&#25104;&#23545;&#30456;&#20284;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13858v1 Announce Type: new  Abstract: The $k$-Maximum Inner Product Search ($k$MIPS) serves as a foundational component in recommender systems and various data mining tasks. However, while most existing $k$MIPS approaches prioritize the efficient retrieval of highly relevant items for users, they often neglect an equally pivotal facet of search results: \emph{diversity}. To bridge this gap, we revisit and refine the diversity-aware $k$MIPS (D$k$MIPS) problem by incorporating two well-known diversity objectives -- minimizing the average and maximum pairwise item similarities within the results -- into the original relevance objective. This enhancement, inspired by Maximal Marginal Relevance (MMR), offers users a controllable trade-off between relevance and diversity. We introduce \textsc{Greedy} and \textsc{DualGreedy}, two linear scan-based algorithms tailored for D$k$MIPS. They both achieve data-dependent approximations and, when aiming to minimize the average pairwise simi
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;LLM4SBR&#26694;&#26550;&#65292;&#26159;&#31532;&#19968;&#20010;&#36866;&#21512;&#22312;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36731;&#37327;&#19988;&#26377;&#25928;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2402.13840</link><description>&lt;p&gt;
LLM4SBR: &#19968;&#20010;&#36731;&#37327;&#19988;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13840
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;LLM4SBR&#26694;&#26550;&#65292;&#26159;&#31532;&#19968;&#20010;&#36866;&#21512;&#22312;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36731;&#37327;&#19988;&#26377;&#25928;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;(SBR)&#21033;&#29992;&#26469;&#33258;&#21311;&#21517;&#29992;&#25143;&#30340;&#20250;&#35805;&#34892;&#20026;&#24207;&#21015;&#36827;&#34892;&#25512;&#33616;&#12290;&#34429;&#28982;&#36825;&#31181;&#31574;&#30053;&#38750;&#24120;&#39640;&#25928;&#65292;&#20294;&#29306;&#29298;&#20102;&#21830;&#21697;&#30340;&#22266;&#26377;&#35821;&#20041;&#20449;&#24687;&#65292;&#20351;&#27169;&#22411;&#38590;&#20197;&#29702;&#35299;&#20250;&#35805;&#30340;&#30495;&#27491;&#24847;&#22270;&#65292;&#23548;&#33268;&#25512;&#33616;&#32467;&#26524;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#12290;&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#20010;&#39046;&#22495;&#34028;&#21187;&#21457;&#23637;&#65292;&#20026;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#24102;&#26469;&#20102;&#19968;&#32447;&#24076;&#26395;&#12290;&#21463;LLMs&#24433;&#21709;&#65292;&#25506;&#35752;LLMs&#19982;&#25512;&#33616;&#31995;&#32479;(RS)&#38598;&#25104;&#30340;&#30740;&#31350;&#22914;&#38632;&#21518;&#26149;&#31499;&#33324;&#28044;&#29616;&#12290;&#28982;&#32780;&#65292;&#21463;&#38480;&#20110;&#39640;&#26102;&#38388;&#21644;&#31354;&#38388;&#25104;&#26412;&#65292;&#20197;&#21450;&#20250;&#35805;&#25968;&#25454;&#30701;&#26242;&#19988;&#21311;&#21517;&#30340;&#29305;&#24615;&#65292;&#31532;&#19968;&#20010;&#36866;&#21512;&#24037;&#19994;&#37096;&#32626;&#30340;LLM&#25512;&#33616;&#26694;&#26550;&#22312;SBR&#39046;&#22495;&#23578;&#26410;&#20986;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#65292;&#25105;&#20204;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13840v1 Announce Type: cross  Abstract: Traditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation. Although this strategy is highly efficient, it sacrifices the inherent semantic information of the items, making it difficult for the model to understand the true intent of the session and resulting in a lack of interpretability in the recommended results. Recently, large language models (LLMs) have flourished across various domains, offering a glimpse of hope in addressing the aforementioned challenges. Inspired by the impact of LLMs, research exploring the integration of LLMs with the Recommender system (RS) has surged like mushrooms after rain. However, constrained by high time and space costs, as well as the brief and anonymous nature of session data, the first LLM recommendation framework suitable for industrial deployment has yet to emerge in the field of SBR. To address the aforementioned challenges, we hav
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#22312;&#32593;&#32476;&#20013;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#65292;&#21457;&#29616;PageRank&#33021;&#22815;&#24179;&#34913;&#25490;&#21517;&#20013;&#23569;&#25968;&#32676;&#20307;&#30340;&#20195;&#34920;&#24615;&#65292;&#32780;HITS&#21017;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2402.13787</link><description>&lt;p&gt;
&#20174;&#25490;&#21517;&#20013;&#23835;&#36215;&#30340;&#20844;&#24179;&#24615;&#65306;HITS&#21644;PageRank&#22312;&#21516;&#36136;&#32593;&#32476;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#22312;&#32593;&#32476;&#20013;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#65292;&#21457;&#29616;PageRank&#33021;&#22815;&#24179;&#34913;&#25490;&#21517;&#20013;&#23569;&#25968;&#32676;&#20307;&#30340;&#20195;&#34920;&#24615;&#65292;&#32780;HITS&#21017;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38142;&#25509;&#20998;&#26512;&#31639;&#27861;&#22312;&#38459;&#27490;&#23569;&#25968;&#32676;&#20307;&#36798;&#21040;&#39640;&#25490;&#21517;&#20301;&#32622;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20351;&#29992;&#20013;&#24515;&#24615;&#24230;&#37327;&#26631;&#20934;&#30340;&#26368;&#24120;&#35265;&#38142;&#25509;&#31639;&#27861;&#65292;&#22914;PageRank&#21644;HITS&#65292;&#22312;&#32593;&#32476;&#20013;&#21487;&#33021;&#20877;&#29616;&#29978;&#33267;&#25918;&#22823;&#23545;&#23569;&#25968;&#32676;&#20307;&#30340;&#20559;&#35265;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#34892;&#20026;&#26377;&#25152;&#19981;&#21516;&#65306;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#20973;&#32463;&#39564;&#35777;&#26126;&#65292;PageRank&#22312;&#22823;&#37096;&#20998;&#25490;&#21517;&#20301;&#32622;&#19978;&#21453;&#26144;&#20102;&#24230;&#20998;&#24067;&#65292;&#24182;&#19988;&#21487;&#20197;&#24179;&#34913;&#23569;&#25968;&#32676;&#20307;&#22312;&#25490;&#21517;&#38752;&#21069;&#30340;&#33410;&#28857;&#20013;&#30340;&#20195;&#34920;&#24615;&#65307;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#21457;&#29616;HITS&#36890;&#36807;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#22312;&#21516;&#26500;&#32593;&#32476;&#20013;&#25918;&#22823;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#65292;&#25903;&#25745;&#35777;&#25454;&#20026;&#23454;&#35777;&#32467;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;HITS&#20013;&#20559;&#35265;&#25918;&#22823;&#30340;&#26681;&#26412;&#21407;&#22240;&#26159;&#32593;&#32476;&#20013;&#23384;&#22312;&#30340;&#21516;&#36136;&#24615;&#27700;&#24179;&#65292;&#36890;&#36807;&#19968;&#20010;&#20855;&#26377;&#20004;&#20010;&#31038;&#21306;&#30340;&#19981;&#26029;&#21457;&#23637;&#30340;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#20197;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#38416;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13787v1 Announce Type: cross  Abstract: In this paper, we investigate the conditions under which link analysis algorithms prevent minority groups from reaching high ranking slots. We find that the most common link-based algorithms using centrality metrics, such as PageRank and HITS, can reproduce and even amplify bias against minority groups in networks. Yet, their behavior differs: one one hand, we empirically show that PageRank mirrors the degree distribution for most of the ranking positions and it can equalize representation of minorities among the top ranked nodes; on the other hand, we find that HITS amplifies pre-existing bias in homophilic networks through a novel theoretical analysis, supported by empirical results. We find the root cause of bias amplification in HITS to be the level of homophily present in the network, modeled through an evolving network model with two communities. We illustrate our theoretical analysis on both synthetic and real datasets and we pr
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Adversarial Graph Dropout (AdvDrop) &#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#21327;&#21516;&#36807;&#28388;&#20013;&#25918;&#22823;&#20559;&#35265;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.13769</link><description>&lt;p&gt;
&#22522;&#20110;&#23545;&#25239;&#22270;&#33410;&#28857;&#21024;&#38500;&#30340;&#22270;&#21327;&#21516;&#36807;&#28388;&#36890;&#29992;&#21435;&#20559;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
General Debiasing for Graph-based Collaborative Filtering via Adversarial Graph Dropout
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13769
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Adversarial Graph Dropout (AdvDrop) &#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#21327;&#21516;&#36807;&#28388;&#20013;&#25918;&#22823;&#20559;&#35265;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#23637;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#21327;&#21516;&#36807;&#28388;&#65288;CF&#65289;&#20013;&#12290;&#20851;&#38190;&#22312;&#20110;&#32858;&#21512;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#22270;&#19978;&#30340;&#37051;&#22495;&#20449;&#24687;&#65292;&#20197;&#22686;&#24378;&#29992;&#25143;/&#29289;&#21697;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#32858;&#21512;&#26426;&#21046;&#23384;&#22312;&#19968;&#20010;&#32570;&#28857;&#65292;&#21363;&#25918;&#22823;&#20102;&#20132;&#20114;&#22270;&#20013;&#23384;&#22312;&#30340;&#20559;&#35265;&#12290;&#24403;&#21069;&#30340;&#32858;&#21512;&#26041;&#27861;&#32467;&#21512;&#20102;&#25152;&#26377;&#20449;&#24687;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#26080;&#20559;&#35265;&#65292;&#23548;&#33268;&#20559;&#35265;&#34920;&#24449;&#23398;&#20064;&#12290;&#22240;&#27492;&#65292;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#23398;&#20064;&#21040;&#29992;&#25143;/&#29289;&#21697;&#30340;&#25197;&#26354;&#35270;&#22270;&#65292;&#38459;&#30861;&#20102;&#23545;&#20854;&#30495;&#23454;&#20559;&#22909;&#21644;&#27867;&#21270;&#24314;&#27169;&#30340;&#36807;&#31243;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#23545;&#25239;&#22270;&#33410;&#28857;&#21024;&#38500;&#65288;AdvDrop&#65289;&#30340;&#26032;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13769v1 Announce Type: new  Abstract: Graph neural networks (GNNs) have shown impressive performance in recommender systems, particularly in collaborative filtering (CF). The key lies in aggregating neighborhood information on a user-item interaction graph to enhance user/item representations. However, we have discovered that this aggregation mechanism comes with a drawback, which amplifies biases present in the interaction graph. For instance, a user's interactions with items can be driven by both unbiased true interest and various biased factors like item popularity or exposure. However, the current aggregation approach combines all information, both biased and unbiased, leading to biased representation learning. Consequently, graph-based recommenders can learn distorted views of users/items, hindering the modeling of their true preferences and generalizations. To address this issue, we introduce a novel framework called Adversarial Graph Dropout (AdvDrop). It differentiat
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20114;&#34917;&#30693;&#35782;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65288;LLM-KERec&#65289;&#65292;&#36890;&#36807;&#24341;&#20837;&#23454;&#20307;&#25552;&#21462;&#22120;&#21644;&#26500;&#24314;&#20114;&#34917;&#30693;&#35782;&#22270;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#31995;&#32479;&#38590;&#20197;&#25429;&#25417;&#29992;&#25143;&#24847;&#22270;&#36716;&#21464;&#21644;&#36866;&#24212;&#26032;&#21830;&#21697;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.13750</link><description>&lt;p&gt;
&#25171;&#30772;&#38556;&#30861;&#65306;&#36890;&#36807;&#25512;&#29702;&#30693;&#35782;&#22270;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13750
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20114;&#34917;&#30693;&#35782;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65288;LLM-KERec&#65289;&#65292;&#36890;&#36807;&#24341;&#20837;&#23454;&#20307;&#25552;&#21462;&#22120;&#21644;&#26500;&#24314;&#20114;&#34917;&#30693;&#35782;&#22270;&#65292;&#35299;&#20915;&#20102;&#25512;&#33616;&#31995;&#32479;&#38590;&#20197;&#25429;&#25417;&#29992;&#25143;&#24847;&#22270;&#36716;&#21464;&#21644;&#36866;&#24212;&#26032;&#21830;&#21697;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#30005;&#23376;&#21830;&#21153;&#32593;&#31449;&#21644;&#22312;&#32447;&#24179;&#21488;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20197;&#24212;&#23545;&#20449;&#24687;&#36807;&#36733;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#31995;&#32479;&#20027;&#35201;&#20381;&#36182;&#21382;&#21490;&#25968;&#25454;&#21644;&#29992;&#25143;&#21453;&#39304;&#65292;&#38590;&#20197;&#25429;&#25417;&#29992;&#25143;&#24847;&#22270;&#36716;&#21464;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30693;&#35782;&#24211;&#65288;KB&#65289;&#30340;&#27169;&#22411;&#26469;&#25972;&#21512;&#19987;&#23478;&#30693;&#35782;&#65292;&#20294;&#23427;&#20204;&#38590;&#20197;&#36866;&#24212;&#26032;&#21830;&#21697;&#21644;&#19981;&#26029;&#21457;&#23637;&#30340;&#30005;&#23376;&#21830;&#21153;&#29615;&#22659;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20114;&#34917;&#30693;&#35782;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65288;LLM-KERec&#65289;&#12290;&#23427;&#24341;&#20837;&#20102;&#19968;&#20010;&#23454;&#20307;&#25552;&#21462;&#22120;&#65292;&#20174;&#21830;&#21697;&#21644;&#29992;&#25143;&#20449;&#24687;&#20013;&#25552;&#21462;&#32479;&#19968;&#27010;&#24565;&#26415;&#35821;&#12290;&#20026;&#20102;&#25552;&#20379;&#20855;&#26377;&#25104;&#26412;&#25928;&#30410;&#19988;&#21487;&#38752;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#26681;&#25454;&#23454;&#20307;&#30340;&#27969;&#34892;&#24230;&#21644;&#29305;&#23450;&#31574;&#30053;&#29983;&#25104;&#23454;&#20307;&#23545;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30830;&#23450;&#27599;&#20010;&#23454;&#20307;&#23545;&#20013;&#30340;&#20114;&#34917;&#20851;&#31995;&#65292;&#26500;&#24314;&#19968;&#20010;&#20114;&#34917;&#30693;&#35782;&#22270;&#12290;&#27492;&#22806;&#65292;&#19968;&#20010;&#26032;&#30340;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13750v1 Announce Type: cross  Abstract: Recommendation systems are widely used in e-commerce websites and online platforms to address information overload. However, existing systems primarily rely on historical data and user feedback, making it difficult to capture user intent transitions. Recently, Knowledge Base (KB)-based models are proposed to incorporate expert knowledge, but it struggle to adapt to new items and the evolving e-commerce environment. To address these challenges, we propose a novel Large Language Model based Complementary Knowledge Enhanced Recommendation System (LLM-KERec). It introduces an entity extractor that extracts unified concept terms from item and user information. To provide cost-effective and reliable prior knowledge, entity pairs are generated based on entity popularity and specific strategies. The large language model determines complementary relationships in each entity pair, constructing a complementary knowledge graph. Furthermore, a new 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37096;&#20998;&#30456;&#20851;&#24615;&#22686;&#24378;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#25913;&#36827;&#35270;&#39057;&#35821;&#26009;&#24211;&#26102;&#21051;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#20197;&#25429;&#25417;&#20851;&#38190;&#20869;&#23481;&#21644;&#22788;&#29702;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.13576</link><description>&lt;p&gt;
&#36890;&#36807;&#37096;&#20998;&#30456;&#20851;&#24615;&#22686;&#24378;&#25913;&#36827;&#35270;&#39057;&#35821;&#26009;&#24211;&#26102;&#21051;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Improving Video Corpus Moment Retrieval with Partial Relevance Enhancement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13576
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37096;&#20998;&#30456;&#20851;&#24615;&#22686;&#24378;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#25913;&#36827;&#35270;&#39057;&#35821;&#26009;&#24211;&#26102;&#21051;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#20197;&#25429;&#25417;&#20851;&#38190;&#20869;&#23481;&#21644;&#22788;&#29702;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#39057;&#35821;&#26009;&#24211;&#26102;&#21051;&#26816;&#32034;&#65288;VCMR&#65289;&#26159;&#19968;&#20010;&#26032;&#30340;&#35270;&#39057;&#26816;&#32034;&#20219;&#21153;&#65292;&#26088;&#22312;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#25991;&#26412;&#20316;&#20026;&#26597;&#35810;&#65292;&#20174;&#22823;&#37327;&#26410;&#32463;&#20462;&#21098;&#30340;&#35270;&#39057;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#30456;&#20851;&#26102;&#21051;&#12290;&#35270;&#39057;&#19982;&#26597;&#35810;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26159;&#37096;&#20998;&#30340;&#65292;&#20027;&#35201;&#20307;&#29616;&#22312;&#20004;&#20010;&#26041;&#38754;&#65306;&#65288;1&#65289;&#33539;&#22260;&#65306;&#26410;&#32463;&#20462;&#21098;&#30340;&#35270;&#39057;&#21253;&#21547;&#20449;&#24687;&#20016;&#23500;&#30340;&#24103;&#65292;&#32780;&#24182;&#38750;&#25152;&#26377;&#24103;&#37117;&#19982;&#26597;&#35810;&#30456;&#20851;&#12290;&#24378;&#30456;&#20851;&#24615;&#36890;&#24120;&#20165;&#22312;&#30456;&#20851;&#26102;&#21051;&#20869;&#35266;&#23519;&#21040;&#65292;&#24378;&#35843;&#25429;&#25417;&#20851;&#38190;&#20869;&#23481;&#30340;&#37325;&#35201;&#24615;&#12290;&#65288;2&#65289;&#27169;&#24577;&#65306;&#26597;&#35810;&#19982;&#19981;&#21516;&#27169;&#24577;&#30340;&#30456;&#20851;&#24615;&#19981;&#21516;&#65307;&#21160;&#20316;&#25551;&#36848;&#26356;&#20506;&#36182;&#20110;&#35270;&#35273;&#20803;&#32032;&#65292;&#32780;&#35282;&#33394;&#23545;&#35805;&#19982;&#25991;&#26412;&#20449;&#24687;&#26356;&#30456;&#20851;&#12290;&#35782;&#21035;&#21644;&#35299;&#20915;&#36825;&#20123;&#27169;&#24577;&#29305;&#23450;&#30340;&#32454;&#24494;&#24046;&#21035;&#23545;&#20110;&#22312;VCMR&#20013;&#36827;&#34892;&#26377;&#25928;&#26816;&#32034;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#23558;&#25152;&#26377;&#35270;&#39057;&#20869;&#23481;&#24179;&#31561;&#23545;&#24453;&#65292;&#23548;&#33268;&#23376;&#20248;&#26102;&#21051;&#26816;&#32034;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#26377;&#25928;&#25429;&#25417;p
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13576v1 Announce Type: cross  Abstract: Video corpus moment retrieval~(VCMR) is a new video retrieval task aimed at retrieving a relevant moment from a large corpus of untrimmed videos using a natural language text as query. The relevance between the video and query is partial, mainly evident in two aspects: (1) Scope: The untrimmed video contains information-rich frames, and not all are relevant to the query. Strong correlation is typically observed only within the relevant moment, emphasizing the importance of capturing key content. (2) Modality: The relevance of query to different modalities varies; action descriptions align more with the visual elements, while character conversations are more related to textual information. Recognizing and addressing these modality-specific nuances is crucial for effective retrieval in VCMR. However, existing methods often treat all video contents equally, leading to sub-optimal moment retrieval. We argue that effectively capturing the p
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;EventFormer&#27169;&#22411;&#65292;&#21033;&#29992;&#20107;&#20214;&#20316;&#20026;&#35270;&#39057;&#26816;&#32034;&#30340;&#22522;&#26412;&#21333;&#20803;&#65292;&#24182;&#36890;&#36807;&#20107;&#20214;&#25512;&#29702;&#21644;&#20998;&#23618;&#20107;&#20214;&#32534;&#30721;&#26469;&#25552;&#21462;&#20107;&#20214;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.13566</link><description>&lt;p&gt;
&#22522;&#20110;&#20107;&#20214;&#24863;&#30693;&#30340;&#35270;&#39057;&#35821;&#26009;&#24211;&#26102;&#21051;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Event-aware Video Corpus Moment Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13566
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;EventFormer&#27169;&#22411;&#65292;&#21033;&#29992;&#20107;&#20214;&#20316;&#20026;&#35270;&#39057;&#26816;&#32034;&#30340;&#22522;&#26412;&#21333;&#20803;&#65292;&#24182;&#36890;&#36807;&#20107;&#20214;&#25512;&#29702;&#21644;&#20998;&#23618;&#20107;&#20214;&#32534;&#30721;&#26469;&#25552;&#21462;&#20107;&#20214;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#39057;&#35821;&#26009;&#24211;&#26102;&#21051;&#26816;&#32034;&#65288;VCMR&#65289;&#26159;&#19968;&#39033;&#23454;&#29992;&#30340;&#35270;&#39057;&#26816;&#32034;&#20219;&#21153;&#65292;&#37325;&#28857;&#26159;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#22312;&#24222;&#22823;&#30340;&#26410;&#20462;&#21098;&#35270;&#39057;&#35821;&#26009;&#24211;&#20013;&#35782;&#21035;&#29305;&#23450;&#26102;&#21051;&#12290;&#29616;&#26377;&#30340;VCMR&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#22522;&#20110;&#24103;&#30340;&#35270;&#39057;&#26816;&#32034;&#65292;&#36890;&#36807;&#35745;&#31639;&#26597;&#35810;&#21644;&#35270;&#39057;&#24103;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#26681;&#25454;&#26368;&#22823;&#24103;&#30456;&#20284;&#24615;&#23545;&#35270;&#39057;&#36827;&#34892;&#25490;&#24207;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24573;&#35270;&#20102;&#23884;&#20837;&#22312;&#24103;&#38388;&#20449;&#24687;&#20013;&#30340;&#35821;&#20041;&#32467;&#26500;&#65292;&#21363;&#20107;&#20214;&#65292;&#36825;&#26159;&#20154;&#31867;&#29702;&#35299;&#35270;&#39057;&#30340;&#20851;&#38190;&#20803;&#32032;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EventFormer&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#26126;&#30830;&#21033;&#29992;&#35270;&#39057;&#20013;&#30340;&#20107;&#20214;&#20316;&#20026;&#35270;&#39057;&#26816;&#32034;&#30340;&#22522;&#26412;&#21333;&#20803;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#20107;&#20214;&#25512;&#29702;&#21644;&#20998;&#23618;&#20107;&#20214;&#32534;&#30721;&#25552;&#21462;&#20107;&#20214;&#34920;&#31034;&#12290;&#20107;&#20214;&#25512;&#29702;&#27169;&#22359;&#23558;&#36830;&#32493;&#19988;&#35270;&#35273;&#30456;&#20284;&#30340;&#24103;&#34920;&#31034;&#20998;&#32452;&#25104;&#20107;&#20214;&#65292;&#32780;&#20998;&#23618;&#20107;&#20214;&#32534;&#30721;&#21017;&#22312;&#19981;&#21516;&#23618;&#27425;&#19978;&#32534;&#30721;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13566v1 Announce Type: cross  Abstract: Video Corpus Moment Retrieval (VCMR) is a practical video retrieval task focused on identifying a specific moment within a vast corpus of untrimmed videos using the natural language query. Existing methods for VCMR typically rely on frame-aware video retrieval, calculating similarities between the query and video frames to rank videos based on maximum frame similarity.However, this approach overlooks the semantic structure embedded within the information between frames, namely, the event, a crucial element for human comprehension of videos. Motivated by this, we propose EventFormer, a model that explicitly utilizes events within videos as fundamental units for video retrieval. The model extracts event representations through event reasoning and hierarchical event encoding. The event reasoning module groups consecutive and visually similar frame representations into events, while the hierarchical event encoding encodes information at bo
&lt;/p&gt;</description></item><item><title>ARL2&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#21033;&#29992;LLMs&#20316;&#20026;&#26631;&#27880;&#32773;&#65292;&#24182;&#37319;&#29992;&#33258;&#36866;&#24212;&#33258;&#35757;&#32451;&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#23569;&#27880;&#37322;&#25104;&#26412;&#65292;&#24182;&#22312;NQ&#21644;MMLU&#19978;&#21462;&#24471;&#20102;5.4%&#21644;4.6%&#30340;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.13542</link><description>&lt;p&gt;
ARL2: &#36890;&#36807;&#33258;&#23548;&#33258;&#36866;&#24212;&#30456;&#20851;&#24615;&#26631;&#35760;&#23558;&#26816;&#32034;&#22120;&#19982;&#40657;&#30418;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13542
&lt;/p&gt;
&lt;p&gt;
ARL2&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#21033;&#29992;LLMs&#20316;&#20026;&#26631;&#27880;&#32773;&#65292;&#24182;&#37319;&#29992;&#33258;&#36866;&#24212;&#33258;&#35757;&#32451;&#31574;&#30053;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#23569;&#27880;&#37322;&#25104;&#26412;&#65292;&#24182;&#22312;NQ&#21644;MMLU&#19978;&#21462;&#24471;&#20102;5.4%&#21644;4.6%&#30340;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13542v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449; &#25688;&#35201;: &#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#36890;&#36807;&#25972;&#21512;&#22806;&#37096;&#30693;&#35782;&#28304;&#30340;&#30456;&#20851;&#20449;&#24687;&#25913;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#20351;LLMs&#33021;&#22815;&#36866;&#24212;&#29305;&#23450;&#39046;&#22495;&#65292;&#24182;&#20943;&#36731;&#30693;&#35782;&#23494;&#38598;&#20219;&#21153;&#20013;&#30340;&#24187;&#35273;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#20998;&#24320;&#30340;&#35757;&#32451;&#36807;&#31243;&#21644;LLMs&#30340;&#40657;&#30418;&#29305;&#24615;&#65292;&#29616;&#26377;&#30340;&#26816;&#32034;&#22120;&#36890;&#24120;&#19982;LLMs&#19981;&#21305;&#37197;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ARL2&#65292;&#19968;&#31181;&#21033;&#29992;LLMs&#20316;&#20026;&#26631;&#27880;&#32773;&#30340;&#26816;&#32034;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;ARL2&#21033;&#29992;LLMs&#27880;&#37322;&#21644;&#35780;&#20998;&#30456;&#20851;&#35777;&#25454;&#65292;&#20174;&#32780;&#33021;&#22815;&#20174;&#24378;&#22823;&#30340;LLM&#30417;&#30563;&#20013;&#23398;&#20064;&#26816;&#32034;&#22120;&#12290;&#27492;&#22806;&#65292;ARL2&#20351;&#29992;&#33258;&#36866;&#24212;&#33258;&#35757;&#32451;&#31574;&#30053;&#26469;&#31574;&#21010;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#30456;&#20851;&#24615;&#25968;&#25454;&#65292;&#21487;&#20197;&#26377;&#25928;&#38477;&#20302;&#26631;&#27880;&#25104;&#26412;&#12290;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;ARL2&#30340;&#26377;&#25928;&#24615;&#65292;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;NQ&#19978;&#25552;&#39640;&#20102;5.4%&#30340;&#20934;&#30830;&#29575;&#65292;&#22312;MMLU&#19978;&#25552;&#39640;&#20102;4.6%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13542v1 Announce Type: cross  Abstract: Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with LLMs due to their separate training processes and the black-box nature of LLMs. To address this challenge, we propose ARL2, a retriever learning technique that harnesses LLMs as labelers. ARL2 leverages LLMs to annotate and score relevant evidence, enabling learning the retriever from robust LLM supervision. Furthermore, ARL2 uses an adaptive self-training strategy for curating high-quality and diverse relevance data, which can effectively reduce the annotation cost. Extensive experiments demonstrate the effectiveness of ARL2, achieving accuracy improvements of 5.4% on NQ and 4.6% on MMLU compared to the state-of-the-art methods. Additionall
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22810;&#32423;&#32763;&#35793;&#12289;&#35821;&#20041;&#23884;&#20837;&#25193;&#23637;&#21644;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#20013;&#24515;&#25193;&#23637;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#36328;&#35821;&#35328;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20013;&#25913;&#21892;&#21484;&#22238;&#29575;&#65292;&#36890;&#36807;&#20010;&#24615;&#21270;&#21305;&#37197;&#29992;&#25143;&#26597;&#35810;&#21644;&#30456;&#20851;&#25991;&#26723;&#65292;&#23637;&#31034;&#20102;&#27604;&#22522;&#32447;&#26041;&#27861;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.13500</link><description>&lt;p&gt;
&#21033;&#29992;&#32763;&#35793;&#23454;&#29616;&#26368;&#20339;&#21484;&#22238;&#29575;&#65306;&#36890;&#36807;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#23450;&#21046;LLM&#20010;&#24615;&#21270;
&lt;/p&gt;
&lt;p&gt;
Leveraging Translation For Optimal Recall: Tailoring LLM Personalization With User Profiles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13500
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22810;&#32423;&#32763;&#35793;&#12289;&#35821;&#20041;&#23884;&#20837;&#25193;&#23637;&#21644;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#20013;&#24515;&#25193;&#23637;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#36328;&#35821;&#35328;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20013;&#25913;&#21892;&#21484;&#22238;&#29575;&#65292;&#36890;&#36807;&#20010;&#24615;&#21270;&#21305;&#37197;&#29992;&#25143;&#26597;&#35810;&#21644;&#30456;&#20851;&#25991;&#26723;&#65292;&#23637;&#31034;&#20102;&#27604;&#22522;&#32447;&#26041;&#27861;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#26032;&#39062;&#25216;&#26415;&#65292;&#36890;&#36807;&#22522;&#20110;&#29992;&#25143;&#30340;&#35789;&#27719;-&#35821;&#20041;&#31354;&#38388;&#30340;&#36845;&#20195;&#26597;&#35810;&#20248;&#21270;&#26469;&#25552;&#39640;&#36328;&#35821;&#35328;&#20449;&#24687;&#26816;&#32034;(CLIR)&#31995;&#32479;&#20013;&#30340;&#21484;&#22238;&#29575;&#12290;&#25552;&#20986;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#22810;&#32423;&#32763;&#35793;&#12289;&#22522;&#20110;&#35821;&#20041;&#23884;&#20837;&#30340;&#25193;&#23637;&#65292;&#20197;&#21450;&#20197;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#20026;&#20013;&#24515;&#30340;&#25193;&#23637;&#65292;&#20197;&#35299;&#20915;&#29992;&#25143;&#26597;&#35810;&#21644;&#30456;&#20851;&#25991;&#26723;&#20043;&#38388;&#30340;&#21305;&#37197;&#24046;&#24322;&#25361;&#25112;&#12290;&#36890;&#36807;&#21021;&#22987;&#30340;BM25&#26816;&#32034;&#12289;&#36716;&#25442;&#20026;&#20013;&#38388;&#35821;&#35328;&#12289;&#26597;&#25214;&#30456;&#20284;&#26415;&#35821;&#30340;&#23884;&#20837;&#65292;&#20197;&#21450;&#36845;&#20195;&#37325;&#26032;&#25490;&#21517;&#65292;&#35813;&#25216;&#26415;&#26088;&#22312;&#25193;&#22823;&#21487;&#33021;&#19982;&#20010;&#20307;&#29992;&#25143;&#30456;&#20851;&#30340;&#28508;&#22312;&#32467;&#26524;&#33539;&#22260;&#12290;&#23545;&#26032;&#38395;&#21644;Twitter&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#23454;&#39564;&#35777;&#26126;&#65292;&#25152;&#25552;&#26041;&#27861;&#22312;ROUGE&#25351;&#26631;&#26041;&#38754;&#20248;&#20110;&#22522;&#32447;BM25&#25490;&#21517;&#12290;&#32763;&#35793;&#26041;&#27861;&#36824;&#36890;&#36807;&#22810;&#27493;&#39588;&#36807;&#31243;&#23637;&#31034;&#20986;&#20102;&#20445;&#25345;&#30340;&#35821;&#20041;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13500v1 Announce Type: cross  Abstract: This paper explores a novel technique for improving recall in cross-language information retrieval (CLIR) systems using iterative query refinement grounded in the user's lexical-semantic space. The proposed methodology combines multi-level translation, semantic embedding-based expansion, and user profile-centered augmentation to address the challenge of matching variance between user queries and relevant documents. Through an initial BM25 retrieval, translation into intermediate languages, embedding lookup of similar terms, and iterative re-ranking, the technique aims to expand the scope of potentially relevant results personalized to the individual user. Comparative experiments on news and Twitter datasets demonstrate superior performance over baseline BM25 ranking for the proposed approach across ROUGE metrics. The translation methodology also showed maintained semantic accuracy through the multi-step process. This personalized CLIR 
&lt;/p&gt;</description></item><item><title>&#25506;&#32034;&#20102;&#29992;&#25143;&#20852;&#36259;&#22810;&#26679;&#24615;&#23545;&#25512;&#33616;&#31995;&#32479;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#25581;&#31034;&#20102;&#20852;&#36259;&#26356;&#24191;&#27867;&#30340;&#29992;&#25143;&#36890;&#24120;&#25509;&#25910;&#21040;&#36136;&#37327;&#36739;&#20302;&#25512;&#33616;&#30340;&#19981;&#22343;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#20852;&#36259;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.13495</link><description>&lt;p&gt;
&#19968;&#20010;&#23884;&#20837;&#26159;&#21542;&#36866;&#29992;&#20110;&#25152;&#26377;&#65311;&#19968;&#31181;&#22810;&#20852;&#36259;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#25552;&#39640;&#29992;&#25143;&#20852;&#36259;&#22810;&#26679;&#24615;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Can One Embedding Fit All? A Multi-Interest Learning Paradigm Towards Improving User Interest Diversity Fairness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13495
&lt;/p&gt;
&lt;p&gt;
&#25506;&#32034;&#20102;&#29992;&#25143;&#20852;&#36259;&#22810;&#26679;&#24615;&#23545;&#25512;&#33616;&#31995;&#32479;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#25581;&#31034;&#20102;&#20852;&#36259;&#26356;&#24191;&#27867;&#30340;&#29992;&#25143;&#36890;&#24120;&#25509;&#25910;&#21040;&#36136;&#37327;&#36739;&#20302;&#25512;&#33616;&#30340;&#19981;&#22343;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#20852;&#36259;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22240;&#20854;&#25429;&#25417;&#29992;&#25143;&#20852;&#36259;&#30340;&#20248;&#36234;&#33021;&#21147;&#32780;&#22312;&#21508;&#20010;&#39046;&#22495;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#29992;&#25143;&#20852;&#36259;&#30340;&#22797;&#26434;&#24615;&#21644;&#24494;&#22937;&#24615;&#28085;&#30422;&#20102;&#24191;&#27867;&#22810;&#26679;&#30340;&#33539;&#22260;&#65292;&#36825;&#22312;&#25552;&#20379;&#20844;&#24179;&#25512;&#33616;&#26041;&#38754;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20855;&#26377;&#19981;&#21516;&#20852;&#36259;&#22810;&#26679;&#24615;&#27700;&#24179;&#30340;&#29992;&#25143;&#26159;&#21542;&#21463;&#21040;&#20844;&#24179;&#23545;&#24453;&#12290;&#23454;&#35777;&#23454;&#39564;&#25581;&#31034;&#20102;&#19968;&#20010;&#22266;&#26377;&#30340;&#19981;&#22343;&#65306;&#20852;&#36259;&#26356;&#24191;&#27867;&#30340;&#29992;&#25143;&#36890;&#24120;&#20250;&#25910;&#21040;&#36136;&#37327;&#36739;&#20302;&#30340;&#25512;&#33616;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#20852;&#36259;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13495v1 Announce Type: new  Abstract: Recommender systems (RSs) have gained widespread applications across various domains owing to the superior ability to capture users' interests. However, the complexity and nuanced nature of users' interests, which span a wide range of diversity, pose a significant challenge in delivering fair recommendations. In practice, user preferences vary significantly; some users show a clear preference toward certain item categories, while others have a broad interest in diverse ones. Even though it is expected that all users should receive high-quality recommendations, the effectiveness of RSs in catering to this disparate interest diversity remains under-explored.   In this work, we investigate whether users with varied levels of interest diversity are treated fairly. Our empirical experiments reveal an inherent disparity: users with broader interests often receive lower-quality recommendations. To mitigate this, we propose a multi-interest fram
&lt;/p&gt;</description></item><item><title>&#22270;&#23545;&#27604;&#23398;&#20064;&#22312;&#25968;&#23398;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#24212;&#29992;&#34920;&#29616;&#20248;&#20110;&#24403;&#21069;&#20027;&#27969;&#27169;&#22411;TangentCFT&#12290;</title><link>https://arxiv.org/abs/2402.13444</link><description>&lt;p&gt;
&#22270;&#23545;&#27604;&#23398;&#20064;&#22312;&#25968;&#23398;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#26377;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Effectiveness of Graph Contrastive Learning on Mathematical Information Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13444
&lt;/p&gt;
&lt;p&gt;
&#22270;&#23545;&#27604;&#23398;&#20064;&#22312;&#25968;&#23398;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#24212;&#29992;&#34920;&#29616;&#20248;&#20110;&#24403;&#21069;&#20027;&#27969;&#27169;&#22411;TangentCFT&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#20351;&#29992;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;Graph Contrastive Learning&#65292;GCL&#65289;&#29983;&#25104;&#25968;&#23398;&#26041;&#31243;&#34920;&#31034;&#30340;&#23454;&#35777;&#35843;&#26597;&#65292;&#36825;&#26159;&#25968;&#23398;&#20449;&#24687;&#26816;&#32034;&#65288;MIR&#65289;&#30340;&#20851;&#38190;&#26041;&#38754;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#36825;&#31181;&#31616;&#21333;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;&#24403;&#21069;&#39046;&#20808;&#30340;&#20844;&#24335;&#26816;&#32034;&#27169;&#22411;TangentCFT&#30340;&#24615;&#33021;&#12290;&#20026;&#25903;&#25345;&#36825;&#19968;&#39046;&#22495;&#30340;&#25345;&#32493;&#30740;&#31350;&#19982;&#21457;&#23637;&#65292;&#25105;&#20204;&#24050;&#23558;&#28304;&#20195;&#30721;&#20844;&#24320;&#22312;https://github.com/WangPeiSyuan/GCL-Formula-Retrieval/&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13444v1 Announce Type: new  Abstract: This paper details an empirical investigation into using Graph Contrastive Learning (GCL) to generate mathematical equation representations, a critical aspect of Mathematical Information Retrieval (MIR). Our findings reveal that this simple approach consistently exceeds the performance of the current leading formula retrieval model, TangentCFT. To support ongoing research and development in this field, we have made our source code accessible to the public at https://github.com/WangPeiSyuan/GCL-Formula-Retrieval/.
&lt;/p&gt;</description></item><item><title>&#23558;&#23398;&#20064;&#26816;&#32034;&#25216;&#26415;&#24212;&#29992;&#20110;&#25552;&#21319;&#39046;&#33521;&#30340;&#24037;&#20316;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#26500;&#24314;&#35780;&#20272;&#27714;&#32844;&#32773;&#36164;&#26684;&#30340;&#22270;&#34920;&#24182;&#21033;&#29992;&#23398;&#20064;&#21040;&#30340;&#38142;&#25509;&#36827;&#34892;&#26816;&#32034;&#65292;&#20197;&#25552;&#39640;&#30003;&#35831;&#32773;&#36136;&#37327;&#21644;&#20248;&#21270;&#27714;&#32844;&#32773;&#21442;&#19982;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.13435</link><description>&lt;p&gt;
&#23398;&#20064;&#26816;&#32034;&#29992;&#20110;&#24037;&#20316;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Learning to Retrieve for Job Matching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13435
&lt;/p&gt;
&lt;p&gt;
&#23558;&#23398;&#20064;&#26816;&#32034;&#25216;&#26415;&#24212;&#29992;&#20110;&#25552;&#21319;&#39046;&#33521;&#30340;&#24037;&#20316;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#26500;&#24314;&#35780;&#20272;&#27714;&#32844;&#32773;&#36164;&#26684;&#30340;&#22270;&#34920;&#24182;&#21033;&#29992;&#23398;&#20064;&#21040;&#30340;&#38142;&#25509;&#36827;&#34892;&#26816;&#32034;&#65292;&#20197;&#25552;&#39640;&#30003;&#35831;&#32773;&#36136;&#37327;&#21644;&#20248;&#21270;&#27714;&#32844;&#32773;&#21442;&#19982;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Web&#35268;&#27169;&#25628;&#32034;&#31995;&#32479;&#36890;&#24120;&#36890;&#36807;&#20004;&#27493;&#39588;&#33539;&#24335;&#26469;&#35299;&#20915;&#21487;&#20280;&#32553;&#24615;&#25361;&#25112;&#65306;&#26816;&#32034;&#21644;&#25490;&#21517;&#12290;&#26816;&#32034;&#27493;&#39588;&#65292;&#20063;&#31216;&#20026;&#20505;&#36873;&#36873;&#25321;&#65292;&#36890;&#24120;&#28041;&#21450;&#25552;&#21462;&#26631;&#20934;&#21270;&#23454;&#20307;&#65292;&#21019;&#24314;&#21453;&#21521;&#32034;&#24341;&#65292;&#24182;&#25191;&#34892;&#26816;&#32034;&#30340;&#26415;&#35821;&#21305;&#37197;&#12290;&#36825;&#31181;&#20256;&#32479;&#26041;&#27861;&#38656;&#35201;&#25163;&#21160;&#21644;&#32791;&#26102;&#30340;&#26597;&#35810;&#27169;&#22411;&#24320;&#21457;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#23558;&#23398;&#20064;&#26816;&#32034;&#25216;&#26415;&#24212;&#29992;&#20110;&#25552;&#21319;&#39046;&#33521;&#30340;&#24037;&#20316;&#25628;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#12290;&#22312;&#25512;&#24191;&#24037;&#20316;&#39046;&#22495;&#65292;&#20851;&#38190;&#30446;&#26631;&#26159;&#25552;&#39640;&#30003;&#35831;&#32773;&#30340;&#36136;&#37327;&#65292;&#20174;&#32780;&#20026;&#25307;&#32856;&#23458;&#25143;&#25552;&#20379;&#20215;&#20540;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#21033;&#29992;&#30830;&#35748;&#30340;&#38599;&#20323;&#25968;&#25454;&#26500;&#24314;&#19968;&#20010;&#35780;&#20272;&#27714;&#32844;&#32773;&#23545;&#24037;&#20316;&#36164;&#26684;&#30340;&#22270;&#34920;&#65292;&#24182;&#21033;&#29992;&#23398;&#20064;&#21040;&#30340;&#38142;&#25509;&#36827;&#34892;&#26816;&#32034;&#12290;&#25105;&#20204;&#30340;&#23398;&#20064;&#27169;&#22411;&#26131;&#20110;&#35299;&#37322;&#65292;&#35843;&#35797;&#21644;&#35843;&#25972;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#26377;&#26426;&#24037;&#20316;&#30340;&#37325;&#28857;&#26159;&#20248;&#21270;&#27714;&#32844;&#32773;&#21442;&#19982;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13435v1 Announce Type: cross  Abstract: Web-scale search systems typically tackle the scalability challenge with a two-step paradigm: retrieval and ranking. The retrieval step, also known as candidate selection, often involves extracting standardized entities, creating an inverted index, and performing term matching for retrieval. Such traditional methods require manual and time-consuming development of query models. In this paper, we discuss applying learning-to-retrieve technology to enhance LinkedIns job search and recommendation systems. In the realm of promoted jobs, the key objective is to improve the quality of applicants, thereby delivering value to recruiter customers. To achieve this, we leverage confirmed hire data to construct a graph that evaluates a seeker's qualification for a job, and utilize learned links for retrieval. Our learned model is easy to explain, debug, and adjust. On the other hand, the focus for organic jobs is to optimize seeker engagement. We 
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#26088;&#22312;&#25581;&#31034;&#29992;&#25143;&#36141;&#20080;&#20915;&#31574;&#32972;&#21518;&#30340;&#21407;&#22240;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#39640;&#36136;&#37327;&#12289;&#20010;&#24615;&#21270;&#30340;&#36141;&#20080;&#21407;&#22240;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2402.13417</link><description>&lt;p&gt;
&#35299;&#38145;&#36141;&#20080;&#30340;&#8220;&#20026;&#20309;&#8221;&#65306;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#21644;&#36141;&#20080;&#21407;&#22240;&#19982;&#21518;&#36141;&#20080;&#20307;&#39564;&#30340;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Unlocking the `Why' of Buying: Introducing a New Dataset and Benchmark for Purchase Reason and Post-Purchase Experience
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13417
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#26088;&#22312;&#25581;&#31034;&#29992;&#25143;&#36141;&#20080;&#20915;&#31574;&#32972;&#21518;&#30340;&#21407;&#22240;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#39640;&#36136;&#37327;&#12289;&#20010;&#24615;&#21270;&#30340;&#36141;&#20080;&#21407;&#22240;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#23545;&#20110;&#25552;&#39640;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#20449;&#20219;&#21644;&#29702;&#35299;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#26500;&#24314;&#30495;&#27491;&#21487;&#35299;&#37322;&#30340;&#31995;&#32479;&#65292;&#25105;&#20204;&#38656;&#35201;&#33021;&#38416;&#26126;&#29992;&#25143;&#20026;&#20309;&#20570;&#20986;&#36873;&#25321;&#30340;&#39640;&#36136;&#37327;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#36141;&#20080;&#21407;&#22240;&#35299;&#37322;&#20219;&#21153;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#19968;&#20010;&#30001;&#30495;&#23454;&#29992;&#25143;&#35299;&#37322;&#20026;&#20309;&#20570;&#20986;&#26576;&#20123;&#36141;&#20080;&#20915;&#31574;&#30340;&#25991;&#26412;&#35299;&#37322;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#35825;&#23548;LLM&#26126;&#30830;&#21306;&#20998;&#29992;&#25143;&#35780;&#35770;&#20013;&#36141;&#20080;&#20135;&#21697;&#32972;&#21518;&#30340;&#21407;&#22240;&#21644;&#36141;&#20080;&#21518;&#30340;&#20307;&#39564;&#12290;&#33258;&#21160;&#21270;&#30340;LLM&#39537;&#21160;&#35780;&#20272;&#20197;&#21450;&#23567;&#35268;&#27169;&#20154;&#24037;&#35780;&#20272;&#35777;&#23454;&#20102;&#25105;&#20204;&#26041;&#27861;&#33719;&#21462;&#39640;&#36136;&#37327;&#12289;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#20010;&#24615;&#21270;&#25968;&#25454;&#38598;&#19978;&#23545;&#35813;&#25968;&#25454;&#38598;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13417v1 Announce Type: new  Abstract: Explanations are crucial for enhancing user trust and understanding within modern recommendation systems. To build truly explainable systems, we need high-quality datasets that elucidate why users make choices. While previous efforts have focused on extracting users' post-purchase sentiment in reviews, they ignore the reasons behind the decision to buy.   In our work, we propose a novel purchase reason explanation task. To this end, we introduce an LLM-based approach to generate a dataset that consists of textual explanations of why real users make certain purchase decisions. We induce LLMs to explicitly distinguish between the reasons behind purchasing a product and the experience after the purchase in a user review. An automated, LLM-driven evaluation, as well as a small scale human evaluation, confirms the effectiveness of our approach to obtaining high-quality, personalized explanations. We benchmark this dataset on two personalized 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;G&amp;O&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#20869;&#23481;&#29983;&#25104;&#19982;&#32467;&#26500;&#21270;&#36807;&#31243;&#20998;&#31163;&#65292;&#26377;&#25928;&#25552;&#21319;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#29305;&#23450;&#32467;&#26500;&#21270;&#25991;&#26412;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.13364</link><description>&lt;p&gt;
&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#25913;&#21892;&#32467;&#26500;&#21270;&#35821;&#35328;&#27169;&#22411;&#22312;&#20449;&#24687;&#25277;&#21462;&#20013;&#30340;&#36755;&#20986;
&lt;/p&gt;
&lt;p&gt;
A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13364
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;G&amp;O&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#20869;&#23481;&#29983;&#25104;&#19982;&#32467;&#26500;&#21270;&#36807;&#31243;&#20998;&#31163;&#65292;&#26377;&#25928;&#25552;&#21319;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#29305;&#23450;&#32467;&#26500;&#21270;&#25991;&#26412;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#23637;&#31034;&#20986;&#22312;&#26681;&#25454;&#25351;&#20196;&#29983;&#25104;&#38750;&#32467;&#26500;&#21270;&#33258;&#28982;&#35821;&#35328;&#26041;&#38754;&#20855;&#26377;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#35201;&#27714;&#23427;&#20204;&#29983;&#25104;&#31526;&#21512;&#29305;&#23450;&#32467;&#26500;&#21270;&#26684;&#24335;&#30340;&#25991;&#26412;&#26102;&#65292;&#23427;&#20204;&#30340;&#34920;&#29616;&#21487;&#33021;&#19981;&#19968;&#33268;&#65292;&#22312;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#25110;&#20851;&#31995;&#25277;&#21462;&#65288;RE&#65289;&#31561;&#24212;&#29992;&#20013;&#36825;&#19968;&#28857;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;G&amp;O&#65292;&#20197;&#22686;&#24378;&#23427;&#20204;&#30340;&#32467;&#26500;&#21270;&#25991;&#26412;&#29983;&#25104;&#33021;&#21147;&#12290;&#23427;&#23558;&#29983;&#25104;&#20998;&#35299;&#20026;&#19968;&#20010;&#20004;&#27493;&#27969;&#31243;&#65306;&#39318;&#20808;&#65292;LLMs&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#31572;&#26696;&#20316;&#20026;&#20013;&#38388;&#21709;&#24212;&#12290;&#38543;&#21518;&#65292;&#35201;&#27714;LLMs&#23558;&#36755;&#20986;&#32452;&#32455;&#25104;&#25152;&#38656;&#30340;&#32467;&#26500;&#65292;&#20351;&#29992;&#20013;&#38388;&#21709;&#24212;&#20316;&#20026;&#19978;&#19979;&#25991;&#12290;G&amp;O&#26377;&#25928;&#22320;&#23558;&#20869;&#23481;&#29983;&#25104;&#19982;&#26500;&#24314;&#36807;&#31243;&#20998;&#31163;&#65292;&#20943;&#23569;&#20102;&#21516;&#26102;&#23436;&#25104;&#20004;&#20010;&#27491;&#20132;&#20219;&#21153;&#30340;&#21387;&#21147;&#12290;&#22312;&#38646;-shot NER&#21644;RE&#19978;&#36827;&#34892;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13364v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated impressive abilities in generating unstructured natural language according to instructions. However, their performance can be inconsistent when tasked with producing text that adheres to specific structured formats, which is crucial in applications like named entity recognition (NER) or relation extraction (RE). To address this issue, this paper introduces an efficient method, G&amp;O, to enhance their structured text generation capabilities. It breaks the generation into a two-step pipeline: initially, LLMs generate answers in natural language as intermediate responses. Subsequently, LLMs are asked to organize the output into the desired structure, using the intermediate responses as context. G&amp;O effectively separates the generation of content from the structuring process, reducing the pressure of completing two orthogonal tasks simultaneously. Tested on zero-shot NER and RE, the results indica
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#40065;&#26834;&#24615;&#30340;&#22270;&#31070;&#32463;&#25512;&#33616;&#31995;&#32479;&#65288;DR-GNN&#65289;&#65292;&#36890;&#36807;&#23558;&#20998;&#24067;&#40065;&#26834;&#24615;&#20248;&#21270;&#65288;DRO&#65289;&#34701;&#20837;&#21040;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#20013;&#65292;&#35299;&#20915;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#36896;&#25104;&#30340;&#25928;&#26524;&#19979;&#38477;&#38382;&#39064;</title><link>https://arxiv.org/abs/2402.12994</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#40065;&#26834;&#24615;&#30340;&#22270;&#31070;&#32463;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Graph-based Recommendation System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12994
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#40065;&#26834;&#24615;&#30340;&#22270;&#31070;&#32463;&#25512;&#33616;&#31995;&#32479;&#65288;DR-GNN&#65289;&#65292;&#36890;&#36807;&#23558;&#20998;&#24067;&#40065;&#26834;&#24615;&#20248;&#21270;&#65288;DRO&#65289;&#34701;&#20837;&#21040;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#20013;&#65292;&#35299;&#20915;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#36896;&#25104;&#30340;&#25928;&#26524;&#19979;&#38477;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#25429;&#25417;&#39640;&#38454;&#21327;&#20316;&#20449;&#21495;&#33021;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24050;&#32463;&#25104;&#20026;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#20013;&#24378;&#22823;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#36890;&#24120;&#21462;&#20915;&#20110;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20849;&#20139;&#30456;&#21516;&#20998;&#24067;&#65288;&#21363;IID&#20551;&#35774;&#65289;&#65292;&#24182;&#22312;&#20998;&#24067;&#36716;&#31227;&#19979;&#20986;&#29616;&#26174;&#33879;&#19979;&#38477;&#12290;&#20998;&#24067;&#36716;&#31227;&#22312;RS&#20013;&#24120;&#35265;&#65292;&#36890;&#24120;&#24402;&#22240;&#20110;&#29992;&#25143;&#21916;&#22909;&#30340;&#21160;&#24577;&#24615;&#25110;RS&#20013;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#20013;&#30340;&#26222;&#36941;&#20559;&#35265;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#38024;&#23545;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#23545;&#25239;&#20998;&#24067;&#36716;&#31227;&#30340;&#30740;&#31350;&#20173;&#28982;&#24456;&#23569;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23558;&#20998;&#24067;&#40065;&#26834;&#24615;&#20248;&#21270;&#65288;DRO&#65289;&#24341;&#20837;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20998;&#24067;&#40065;&#26834;&#24615;GNN&#65288;DR-GNN&#65289;&#12290;DR-GNN&#35299;&#20915;&#20102;&#20004;&#20010;&#26680;&#24515;&#25361;&#25112;&#65306;1&#65289;&#20351;DRO&#33021;&#22815;&#36866;&#24212;&#19982;GNN&#20132;&#32455;&#30340;&#22270;&#25968;&#25454;&#65292;&#25105;&#20204;&#23558;GNN&#37325;&#26032;&#35299;&#37322;&#20026;&#22270;&#24179;&#28369;&#27491;&#21017;&#21270;&#22120;&#65292;&#20174;&#32780;&#20419;&#36827;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12994v1 Announce Type: new  Abstract: With the capacity to capture high-order collaborative signals, Graph Neural Networks (GNNs) have emerged as powerful methods in Recommender Systems (RS). However, their efficacy often hinges on the assumption that training and testing data share the same distribution (a.k.a. IID assumption), and exhibits significant declines under distribution shifts. Distribution shifts commonly arises in RS, often attributed to the dynamic nature of user preferences or ubiquitous biases during data collection in RS. Despite its significance, researches on GNN-based recommendation against distribution shift are still sparse. To bridge this gap, we propose Distributionally Robust GNN (DR-GNN) that incorporates Distributional Robust Optimization (DRO) into the GNN-based recommendation. DR-GNN addresses two core challenges: 1) To enable DRO to cater to graph data intertwined with GNN, we reinterpret GNN as a graph smoothing regularizer, thereby facilitatin
&lt;/p&gt;</description></item><item><title>Dolos &#26159;&#19968;&#20010;&#29992;&#20110;&#26816;&#27979;&#21644;&#39044;&#38450;&#25945;&#32946;&#28304;&#20195;&#30721;&#25220;&#34989;&#30340;&#24037;&#20855;&#29983;&#24577;&#31995;&#32479;&#65292;&#22312;&#26368;&#26032;&#29256;&#26412;&#20013;&#21152;&#24378;&#20102;&#29992;&#25143;&#20307;&#39564;&#65292;&#25945;&#32946;&#24037;&#20316;&#32773;&#21487;&#20197;&#36890;&#36807;&#26032;&#30340; Web &#24212;&#29992;&#31243;&#24207;&#22312;&#27983;&#35272;&#22120;&#20013;&#36816;&#34892;&#25972;&#20010;&#25220;&#34989;&#26816;&#27979;&#27969;&#31243;&#65292;&#26080;&#38656;&#23433;&#35013;&#25110;&#37197;&#32622;&#12290;</title><link>https://arxiv.org/abs/2402.10853</link><description>&lt;p&gt;
&#20351;&#29992;Dolos&#21457;&#29616;&#21644;&#25506;&#32034;&#25945;&#32946;&#28304;&#20195;&#30721;&#25220;&#34989;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
Discovering and exploring cases of educational source code plagiarism with Dolos
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10853
&lt;/p&gt;
&lt;p&gt;
Dolos &#26159;&#19968;&#20010;&#29992;&#20110;&#26816;&#27979;&#21644;&#39044;&#38450;&#25945;&#32946;&#28304;&#20195;&#30721;&#25220;&#34989;&#30340;&#24037;&#20855;&#29983;&#24577;&#31995;&#32479;&#65292;&#22312;&#26368;&#26032;&#29256;&#26412;&#20013;&#21152;&#24378;&#20102;&#29992;&#25143;&#20307;&#39564;&#65292;&#25945;&#32946;&#24037;&#20316;&#32773;&#21487;&#20197;&#36890;&#36807;&#26032;&#30340; Web &#24212;&#29992;&#31243;&#24207;&#22312;&#27983;&#35272;&#22120;&#20013;&#36816;&#34892;&#25972;&#20010;&#25220;&#34989;&#26816;&#27979;&#27969;&#31243;&#65292;&#26080;&#38656;&#23433;&#35013;&#25110;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28304;&#20195;&#30721;&#25220;&#34989;&#22312;&#25945;&#32946;&#23454;&#36341;&#20013;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#25945;&#32946;&#24037;&#20316;&#32773;&#38656;&#35201;&#26131;&#20110;&#20351;&#29992;&#30340;&#24037;&#20855;&#26469;&#24212;&#23545;&#36825;&#31181;&#23398;&#26415;&#19981;&#31471;&#34892;&#20026;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102; Dolos &#30340;&#26368;&#26032;&#29256;&#26412;&#65292;&#19968;&#20010;&#29992;&#20110;&#26816;&#27979;&#21644;&#39044;&#38450;&#25945;&#32946;&#28304;&#20195;&#30721;&#25220;&#34989;&#30340;&#24037;&#20855;&#29983;&#24577;&#31995;&#32479;&#12290;&#22312;&#36825;&#20010;&#26032;&#29256;&#26412;&#20013;&#65292;&#20027;&#35201;&#20391;&#37325;&#20110;&#25552;&#21319;&#29992;&#25143;&#20307;&#39564;&#12290;&#25945;&#32946;&#24037;&#20316;&#32773;&#29616;&#22312;&#21487;&#20197;&#22312;&#20182;&#20204;&#30340;&#27983;&#35272;&#22120;&#20013;&#36890;&#36807;&#19968;&#20010;&#26032;&#30340; Web &#24212;&#29992;&#31243;&#24207;&#36816;&#34892;&#25972;&#20010;&#25220;&#34989;&#26816;&#27979;&#27969;&#31243;&#65292;&#26080;&#38656;&#23433;&#35013;&#25110;&#37197;&#32622;&#12290;&#23436;&#20840;&#37325;&#26032;&#35774;&#35745;&#30340;&#20998;&#26512;&#20202;&#34920;&#26495;&#21487;&#20197;&#21363;&#26102;&#35780;&#20272;&#19968;&#32452;&#28304;&#25991;&#20214;&#26159;&#21542;&#21253;&#21547;&#30097;&#20284;&#25220;&#34989;&#26696;&#20363;&#20197;&#21450;&#38598;&#21512;&#20013;&#25220;&#34989;&#26377;&#22810;&#26222;&#36941;&#12290;&#20202;&#34920;&#26495;&#25903;&#25345;&#20998;&#23618;&#32467;&#26500;&#21270;&#23548;&#33322;&#65292;&#20197;&#20415;&#36731;&#26494;&#32553;&#25918;&#21040;&#30097;&#20284;&#26696;&#20363;&#12290;&#38598;&#32676;&#26159;&#20202;&#34920;&#26495;&#35774;&#35745;&#20013;&#19968;&#20010;&#37325;&#35201;&#30340;&#26032;&#32452;&#20214;&#65292;&#21453;&#26144;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10853v1 Announce Type: cross  Abstract: Source code plagiarism is a significant issue in educational practice, and educators need user-friendly tools to cope with such academic dishonesty. This article introduces the latest version of Dolos, a state-of-the-art ecosystem of tools for detecting and preventing plagiarism in educational source code. In this new version, the primary focus has been on enhancing the user experience. Educators can now run the entire plagiarism detection pipeline from a new web app in their browser, eliminating the need for any installation or configuration. Completely redesigned analytics dashboards provide an instant assessment of whether a collection of source files contains suspected cases of plagiarism and how widespread plagiarism is within the collection. The dashboards support hierarchically structured navigation to facilitate zooming in and out of suspect cases. Clusters are an essential new component of the dashboard design, reflecting the 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#20171;&#32461;&#20102;&#29992;&#25143;&#24314;&#27169;&#19982;&#29992;&#25143;&#30011;&#20687;&#30740;&#31350;&#30340;&#29616;&#29366;&#12289;&#21457;&#23637;&#21644;&#26410;&#26469;&#26041;&#21521;&#12290;&#35813;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#22312;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#20013;&#26500;&#24314;&#20934;&#30830;&#30340;&#29992;&#25143;&#34920;&#31034;&#65292;&#21253;&#25324;&#21033;&#29992;&#22823;&#37327;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#20197;&#21450;&#37319;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#22270;&#25968;&#25454;&#25216;&#26415;&#31561;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09660</link><description>&lt;p&gt;
&#29992;&#25143;&#24314;&#27169;&#19982;&#29992;&#25143;&#30011;&#20687;&#65306;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
User Modeling and User Profiling: A Comprehensive Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09660
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#20171;&#32461;&#20102;&#29992;&#25143;&#24314;&#27169;&#19982;&#29992;&#25143;&#30011;&#20687;&#30740;&#31350;&#30340;&#29616;&#29366;&#12289;&#21457;&#23637;&#21644;&#26410;&#26469;&#26041;&#21521;&#12290;&#35813;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#22312;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#20013;&#26500;&#24314;&#20934;&#30830;&#30340;&#29992;&#25143;&#34920;&#31034;&#65292;&#21253;&#25324;&#21033;&#29992;&#22823;&#37327;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#20197;&#21450;&#37319;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#22270;&#25968;&#25454;&#25216;&#26415;&#31561;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#34701;&#20837;&#26085;&#24120;&#29983;&#27963;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#20449;&#24687;&#26816;&#32034;&#21644;&#25512;&#33616;&#31995;&#32479;&#65292;&#24050;&#32463;&#20419;&#20351;&#20808;&#36827;&#30340;&#29992;&#25143;&#24314;&#27169;&#21644;&#29992;&#25143;&#30011;&#20687;&#25216;&#26415;&#65292;&#20197;&#25552;&#20379;&#20010;&#24615;&#21270;&#20307;&#39564;&#12290;&#36825;&#20123;&#25216;&#26415;&#26088;&#22312;&#22522;&#20110;&#19982;&#36825;&#20123;&#31995;&#32479;&#30340;&#20114;&#21160;&#20013;&#29983;&#25104;&#30340;&#22823;&#37327;&#25968;&#25454;&#26500;&#24314;&#20934;&#30830;&#30340;&#29992;&#25143;&#34920;&#31034;&#12290;&#26412;&#25991;&#23545;&#29992;&#25143;&#24314;&#27169;&#21644;&#29992;&#25143;&#30011;&#20687;&#30740;&#31350;&#30340;&#29616;&#29366;&#12289;&#21457;&#23637;&#21644;&#26410;&#26469;&#26041;&#21521;&#36827;&#34892;&#20102;&#20840;&#38754;&#32508;&#36848;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#21382;&#21490;&#27010;&#36848;&#65292;&#36861;&#28335;&#20102;&#20174;&#26089;&#26399;&#30340;&#21051;&#26495;&#27169;&#22411;&#21040;&#26368;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#28085;&#30422;&#20102;&#36825;&#19968;&#30740;&#31350;&#39046;&#22495;&#20013;&#30340;&#25152;&#26377;&#27963;&#21160;&#20027;&#39064;&#65292;&#21253;&#25324;&#26368;&#36817;&#30340;&#36235;&#21183;&#12290;&#25105;&#20204;&#30340;&#32508;&#36848;&#31361;&#20986;&#20102;&#21521;&#26356;&#22797;&#26434;&#30340;&#29992;&#25143;&#30011;&#20687;&#26041;&#27861;&#30340;&#33539;&#24335;&#36716;&#21464;&#65292;&#24378;&#35843;&#20102;&#38544;&#24335;&#25968;&#25454;&#25910;&#38598;&#12289;&#22810;&#34892;&#20026;&#24314;&#27169;&#20197;&#21450;&#22270;&#25968;&#25454;&#30340;&#25972;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09660v1 Announce Type: new  Abstract: The integration of artificial intelligence (AI) into daily life, particularly through information retrieval and recommender systems, has necessitated advanced user modeling and profiling techniques to deliver personalized experiences. These techniques aim to construct accurate user representations based on the rich amounts of data generated through interactions with these systems. This paper presents a comprehensive survey of the current state, evolution, and future directions of user modeling and profiling research. We provide a historical overview, tracing the development from early stereotype models to the latest deep learning techniques, and propose a novel taxonomy that encompasses all active topics in this research area, including recent trends. Our survey highlights the paradigm shifts towards more sophisticated user profiling methods, emphasizing implicit data collection, multi-behavior modeling, and the integration of graph data
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#20010;&#20154;&#27969;&#34892;&#24230;&#26469;&#28040;&#38500;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20559;&#35265;&#38382;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#27809;&#26377;&#27880;&#24847;&#21040;&#20840;&#23616;&#27969;&#34892;&#24230;&#30340;&#26681;&#26412;&#38382;&#39064;&#65292;&#32780;&#20010;&#20154;&#27969;&#34892;&#24230;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#20010;&#20307;&#29992;&#25143;&#30340;&#20852;&#36259;&#65292;&#24182;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#25512;&#33616;&#12290;&#30740;&#31350;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#31216;&#20026;&#20010;&#20154;&#27969;&#34892;&#24230;&#24863;&#30693;&#21453;&#20107;&#23454;&#30340;&#26694;&#26550;&#65292;&#23558;&#20010;&#20154;&#27969;&#34892;&#24230;&#34701;&#20837;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#12290;</title><link>https://arxiv.org/abs/2402.07425</link><description>&lt;p&gt;
&#29992;&#20010;&#20154;&#27969;&#34892;&#24230;&#28040;&#38500;&#25512;&#33616;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Debiasing Recommendation with Personal Popularity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07425
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#20010;&#20154;&#27969;&#34892;&#24230;&#26469;&#28040;&#38500;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20559;&#35265;&#38382;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#27809;&#26377;&#27880;&#24847;&#21040;&#20840;&#23616;&#27969;&#34892;&#24230;&#30340;&#26681;&#26412;&#38382;&#39064;&#65292;&#32780;&#20010;&#20154;&#27969;&#34892;&#24230;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#20010;&#20307;&#29992;&#25143;&#30340;&#20852;&#36259;&#65292;&#24182;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#25512;&#33616;&#12290;&#30740;&#31350;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#31216;&#20026;&#20010;&#20154;&#27969;&#34892;&#24230;&#24863;&#30693;&#21453;&#20107;&#23454;&#30340;&#26694;&#26550;&#65292;&#23558;&#20010;&#20154;&#27969;&#34892;&#24230;&#34701;&#20837;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#29699;&#27969;&#34892;&#24230;&#65288;GP&#65289;&#20559;&#35265;&#26159;&#25351;&#25512;&#33616;&#31995;&#32479;&#22312;&#25512;&#33616;&#29289;&#21697;&#26102;&#26222;&#36941;&#20559;&#21521;&#28909;&#38376;&#29289;&#21697;&#65292;&#36825;&#36829;&#32972;&#20102;&#25552;&#20379;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#30446;&#26631;&#65292;&#23545;&#29992;&#25143;&#20307;&#39564;&#21644;&#25512;&#33616;&#20934;&#30830;&#24615;&#36896;&#25104;&#20102;&#19981;&#21033;&#24433;&#21709;&#12290;&#35768;&#22810;&#26041;&#27861;&#24050;&#32463;&#34987;&#25552;&#20986;&#26469;&#20943;&#23569;GP&#20559;&#35265;&#65292;&#20294;&#23427;&#20204;&#27809;&#26377;&#27880;&#24847;&#21040;GP&#30340;&#26681;&#26412;&#38382;&#39064;&#65292;&#21363;&#23427;&#20174;&#20840;&#23616;&#30340;&#35282;&#24230;&#32771;&#34385;&#28909;&#38376;&#24230;&#65292;&#20351;&#29992;&#19968;&#32452;&#28909;&#38376;&#29289;&#21697;&#65292;&#22240;&#27492;&#26080;&#27861;&#25429;&#25417;&#21040;&#20010;&#21035;&#29992;&#25143;&#30340;&#20852;&#36259;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#29992;&#25143;&#20026;&#22522;&#30784;&#30340;&#29289;&#21697;&#27969;&#34892;&#24230;&#31216;&#20026;&#20010;&#20154;&#27969;&#34892;&#24230;&#65288;PP&#65289;&#65292;&#36890;&#36807;&#32771;&#34385;&#20998;&#20139;&#30456;&#20284;&#20852;&#36259;&#30340;&#29992;&#25143;&#26469;&#20026;&#27599;&#20010;&#29992;&#25143;&#35782;&#21035;&#19981;&#21516;&#30340;&#28909;&#38376;&#29289;&#21697;&#12290;&#30001;&#20110;PP&#27169;&#22411;&#21270;&#20102;&#20010;&#20307;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#23427;&#33258;&#28982;&#21487;&#20197;&#24110;&#21161;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#25512;&#33616;&#24182;&#20943;&#23569;GP&#20559;&#35265;&#12290;&#20026;&#20102;&#23558;PP&#34701;&#20837;&#25512;&#33616;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20010;&#20154;&#27969;&#34892;&#24230;&#24863;&#30693;&#21453;&#20107;&#23454;&#65288;PPAC&#65289;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Global popularity (GP) bias is the phenomenon that popular items are recommended much more frequently than they should be, which goes against the goal of providing personalized recommendations and harms user experience and recommendation accuracy. Many methods have been proposed to reduce GP bias but they fail to notice the fundamental problem of GP, i.e., it considers popularity from a \textit{global} perspective of \textit{all users} and uses a single set of popular items, and thus cannot capture the interests of individual users. As such, we propose a user-aware version of item popularity named \textit{personal popularity} (PP), which identifies different popular items for each user by considering the users that share similar interests. As PP models the preferences of individual users, it naturally helps to produce personalized recommendations and mitigate GP bias. To integrate PP into recommendation, we design a general \textit{personal popularity aware counterfactual} (PPAC) frame
&lt;/p&gt;</description></item><item><title>HMF&#36890;&#36807;&#23558;&#28508;&#22312;&#30697;&#38453;&#20998;&#35299;&#20026;&#27010;&#29575;&#36830;&#25509;&#30697;&#38453;&#21644;&#26681;&#32858;&#31867;&#28508;&#22312;&#30697;&#38453;&#65292;&#32467;&#21512;&#20102;&#32858;&#31867;&#27010;&#24565;&#26469;&#25429;&#25417;&#23618;&#27425;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#31283;&#23450;&#21644;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;</title><link>https://arxiv.org/abs/2311.13277</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#21327;&#21516;&#36807;&#28388;&#30340;&#20998;&#23618;&#30697;&#38453;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Matrix Factorization for Interpretable Collaborative Filtering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13277
&lt;/p&gt;
&lt;p&gt;
HMF&#36890;&#36807;&#23558;&#28508;&#22312;&#30697;&#38453;&#20998;&#35299;&#20026;&#27010;&#29575;&#36830;&#25509;&#30697;&#38453;&#21644;&#26681;&#32858;&#31867;&#28508;&#22312;&#30697;&#38453;&#65292;&#32467;&#21512;&#20102;&#32858;&#31867;&#27010;&#24565;&#26469;&#25429;&#25417;&#23618;&#27425;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#31283;&#23450;&#21644;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#20998;&#35299;&#65288;MF&#65289;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#21327;&#21516;&#36807;&#28388;&#25216;&#26415;&#65292;&#36890;&#36807;&#23558;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#30697;&#38453;&#20998;&#35299;&#20026;&#29992;&#25143;&#21644;&#39033;&#30446;&#28508;&#22312;&#30697;&#38453;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#27169;&#22411;&#36890;&#24120;&#29420;&#31435;&#23398;&#20064;&#27599;&#20010;&#20132;&#20114;&#65292;&#21487;&#33021;&#24573;&#35270;&#29992;&#25143;&#21644;&#39033;&#30446;&#20043;&#38388;&#30340;&#20849;&#20139;&#20381;&#36182;&#20851;&#31995;&#65292;&#23548;&#33268;&#25512;&#33616;&#19981;&#22815;&#31283;&#23450;&#21644;&#35299;&#37322;&#24615;&#19981;&#24378;&#12290;&#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;"&#20998;&#23618;&#30697;&#38453;&#20998;&#35299;"&#65288;HMF&#65289;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#32858;&#31867;&#27010;&#24565;&#26469;&#25429;&#25417;&#23618;&#27425;&#32467;&#26500;&#65292;&#20854;&#20013;&#21494;&#33410;&#28857;&#21644;&#20854;&#20182;&#33410;&#28857;&#20998;&#21035;&#23545;&#24212;&#29992;&#25143;/&#39033;&#30446;&#21644;&#32858;&#31867;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#23618;&#27425;&#23884;&#20837;&#65288;hierarchical embeddings&#65289;&#65292;&#23427;&#23558;&#28508;&#22312;&#30697;&#38453;&#65288;&#23884;&#20837;&#65289;&#36827;&#19968;&#27493;&#20998;&#35299;&#20026;&#27010;&#29575;&#36830;&#25509;&#30697;&#38453;&#65292;&#23558;&#23618;&#27425;&#32467;&#26500;&#19982;&#26681;&#32858;&#31867;&#28508;&#22312;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#12290;&#36825;&#20123;&#23884;&#20837;&#20855;&#26377;&#21487;&#24494;&#24615;&#65292;&#20801;&#35768;&#21516;&#26102;&#23398;&#20064;&#20132;&#20114;&#21644;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13277v2 Announce Type: replace  Abstract: Matrix factorization (MF) is a simple collaborative filtering technique that achieves superior recommendation accuracy by decomposing the user-item interaction matrix into user and item latent matrices. Because the model typically learns each interaction independently, it may overlook the underlying shared dependencies between users and items, resulting in less stable and interpretable recommendations. Based on these insights, we propose "Hierarchical Matrix Factorization" (HMF), which incorporates clustering concepts to capture the hierarchy, where leaf nodes and other nodes correspond to users/items and clusters, respectively. Central to our approach, called hierarchical embeddings, is the additional decomposition of the latent matrices (embeddings) into probabilistic connection matrices, which link the hierarchy, and a root cluster latent matrix. The embeddings are differentiable, allowing simultaneous learning of interactions and
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#30340;&#33258;&#36866;&#24212;&#22810;&#20852;&#36259;&#21435;&#20559;&#35265;&#26694;&#26550;&#65288;AMID&#65289;&#65292;&#22312;&#24320;&#25918;&#19990;&#30028;&#20551;&#35774;&#19979;&#35774;&#35745;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#22312;&#22312;&#32447;&#30495;&#23454;&#24179;&#21488;&#19978;&#30001;&#20110;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.04590</link><description>&lt;p&gt;
&#22312;&#24320;&#25918;&#19990;&#30028;&#20551;&#35774;&#19979;&#37325;&#26032;&#24605;&#32771;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04590
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#30340;&#33258;&#36866;&#24212;&#22810;&#20852;&#36259;&#21435;&#20559;&#35265;&#26694;&#26550;&#65288;AMID&#65289;&#65292;&#22312;&#24320;&#25918;&#19990;&#30028;&#20551;&#35774;&#19979;&#35774;&#35745;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#22312;&#22312;&#32447;&#30495;&#23454;&#24179;&#21488;&#19978;&#30001;&#20110;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#65288;CDSR&#65289;&#26041;&#27861;&#26088;&#22312;&#35299;&#20915;&#21333;&#19968;&#39046;&#22495;&#39034;&#24207;&#25512;&#33616;&#65288;SDSR&#65289;&#20013;&#23384;&#22312;&#30340;&#25968;&#25454;&#31232;&#30095;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;CDSR&#20316;&#21697;&#35774;&#35745;&#20854;&#31934;&#24515;&#30340;&#32467;&#26500;&#65292;&#20381;&#36182;&#20110;&#37325;&#21472;&#29992;&#25143;&#26469;&#20256;&#25773;&#36328;&#39046;&#22495;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;CDSR&#26041;&#27861;&#37319;&#29992;&#23553;&#38381;&#19990;&#30028;&#20551;&#35774;&#65292;&#20551;&#35774;&#22312;&#22810;&#20010;&#39046;&#22495;&#20043;&#38388;&#23436;&#20840;&#37325;&#21472;&#30340;&#29992;&#25143;&#65292;&#24182;&#19988;&#25968;&#25454;&#20998;&#24067;&#20174;&#35757;&#32451;&#29615;&#22659;&#21040;&#27979;&#35797;&#29615;&#22659;&#20445;&#25345;&#19981;&#21464;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#22240;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#32780;&#22312;&#22312;&#32447;&#30495;&#23454;&#24179;&#21488;&#19978;&#34920;&#29616;&#36739;&#24046;&#12290;&#20026;&#20102;&#22312;&#24320;&#25918;&#19990;&#30028;&#20551;&#35774;&#19979;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#22810;&#20852;&#36259;&#21435;&#20559;&#35265;&#26694;&#26550;&#65292;&#29992;&#20110;&#36328;&#39046;&#22495;&#24207;&#21015;&#25512;&#33616;&#65288;AMID&#65289;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#22810;&#20852;&#36259;&#20449;&#24687;&#27169;&#22359;&#65288;MIM&#65289;&#21644;&#19968;&#20010;&#21452;&#37325;&#40065;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.04590v3 Announce Type: replace  Abstract: Cross-Domain Sequential Recommendation (CDSR) methods aim to tackle the data sparsity and cold-start problems present in Single-Domain Sequential Recommendation (SDSR). Existing CDSR works design their elaborate structures relying on overlapping users to propagate the cross-domain information. However, current CDSR methods make closed-world assumptions, assuming fully overlapping users across multiple domains and that the data distribution remains unchanged from the training environment to the test environment. As a result, these methods typically result in lower performance on online real-world platforms due to the data distribution shifts. To address these challenges under open-world assumptions, we design an \textbf{A}daptive \textbf{M}ulti-\textbf{I}nterest \textbf{D}ebiasing framework for cross-domain sequential recommendation (\textbf{AMID}), which consists of a multi-interest information module (\textbf{MIM}) and a doubly robu
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20844;&#24179;&#25490;&#21517;&#26631;&#20934;Equal-Opportunity Ranking&#65288;EOR&#65289;&#65292;&#23558;&#24213;&#23618;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24046;&#24322;&#32771;&#34385;&#22312;&#20869;&#65292;&#36890;&#36807;&#32452;&#20869;&#20844;&#24179;&#25277;&#22870;&#23454;&#29616;&#20844;&#24179;&#25490;&#21517;&#12290;</title><link>https://arxiv.org/abs/2309.01610</link><description>&lt;p&gt;
&#19981;&#21516;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#20844;&#24179;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Fair Ranking under Disparate Uncertainty
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.01610
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20844;&#24179;&#25490;&#21517;&#26631;&#20934;Equal-Opportunity Ranking&#65288;EOR&#65289;&#65292;&#23558;&#24213;&#23618;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24046;&#24322;&#32771;&#34385;&#22312;&#20869;&#65292;&#36890;&#36807;&#32452;&#20869;&#20844;&#24179;&#25277;&#22870;&#23454;&#29616;&#20844;&#24179;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#21517;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#20154;&#31867;&#35780;&#20272;&#32773;&#30340;&#27880;&#24847;&#21147;&#38598;&#20013;&#22312;&#21487;&#31649;&#29702;&#30340;&#36873;&#39033;&#23376;&#38598;&#19978;&#12290;&#23427;&#20316;&#20026;&#20154;&#31867;&#20915;&#31574;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#30340;&#20351;&#29992;&#33539;&#22260;&#20174;&#22312;&#30005;&#23376;&#21830;&#21153;&#32593;&#31449;&#19978;&#23637;&#31034;&#28508;&#22312;&#30456;&#20851;&#20135;&#21697;&#21040;&#20026;&#20154;&#24037;&#23457;&#26597;&#20248;&#20808;&#22788;&#29702;&#22823;&#23398;&#30003;&#35831;&#12290;&#34429;&#28982;&#25490;&#21517;&#21487;&#20197;&#36890;&#36807;&#23558;&#20851;&#27880;&#38598;&#20013;&#22312;&#26368;&#26377;&#21069;&#36884;&#30340;&#36873;&#39033;&#19978;&#20351;&#20154;&#31867;&#35780;&#20272;&#26356;&#21152;&#39640;&#25928;&#65292;&#20294;&#25105;&#20204;&#35748;&#20026;&#65292;&#22914;&#26524;&#24213;&#23618;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#22312;&#19981;&#21516;&#32452;&#21035;&#30340;&#36873;&#39033;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#65292;&#25490;&#21517;&#21487;&#33021;&#20250;&#24341;&#20837;&#19981;&#20844;&#24179;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#24046;&#24322;&#20284;&#20046;&#26222;&#36941;&#23384;&#22312;&#65292;&#24120;&#24120;&#23545;&#23569;&#25968;&#32676;&#20307;&#36896;&#25104;&#25439;&#23475;&#65292;&#22240;&#20026;&#36825;&#20123;&#32676;&#20307;&#30340;&#30456;&#20851;&#24615;&#20272;&#35745;&#21487;&#33021;&#30001;&#20110;&#32570;&#20047;&#25968;&#25454;&#25110;&#21512;&#36866;&#30340;&#29305;&#24449;&#32780;&#20855;&#26377;&#26356;&#39640;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20844;&#24179;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Equal-Opportunity Ranking&#65288;EOR&#65289;&#20316;&#20026;&#25490;&#21517;&#30340;&#26032;&#20844;&#24179;&#26631;&#20934;&#65292;&#24182;&#23637;&#31034;&#23427;&#23545;&#24212;&#20110;&#22312;&#30456;&#20851;&#36873;&#39033;&#20043;&#38388;&#36827;&#34892;&#32452;&#20869;&#20844;&#24179;&#25277;&#22870;
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.01610v2 Announce Type: replace  Abstract: Ranking is a ubiquitous method for focusing the attention of human evaluators on a manageable subset of options. Its use as part of human decision-making processes ranges from surfacing potentially relevant products on an e-commerce site to prioritizing college applications for human review. While ranking can make human evaluation more effective by focusing attention on the most promising options, we argue that it can introduce unfairness if the uncertainty of the underlying relevance model differs between groups of options. Unfortunately, such disparity in uncertainty appears widespread, often to the detriment of minority groups for which relevance estimates can have higher uncertainty due to a lack of data or appropriate features. To address this fairness issue, we propose Equal-Opportunity Ranking (EOR) as a new fairness criterion for ranking and show that it corresponds to a group-wise fair lottery among the relevant options even
&lt;/p&gt;</description></item><item><title>InPars-Light&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#20462;&#25913;&#65292;&#36890;&#36807;&#20351;&#29992;&#23567;&#24471;&#22810;&#30340;&#25490;&#21517;&#27169;&#22411;&#21644;&#20813;&#36153;&#35821;&#35328;&#27169;&#22411;BLOOM&#65292;&#22312;&#22810;&#20010;&#33521;&#25991;&#26816;&#32034;&#38598;&#21512;&#19978;&#26174;&#33879;&#25913;&#36827;&#20102;&#25490;&#21517;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2301.02998</link><description>&lt;p&gt;
InPars-Light:&#25104;&#26412;&#25928;&#30410;&#39640;&#30340;&#26080;&#30417;&#30563;&#35757;&#32451;&#39640;&#25928;&#25490;&#21517;&#22120;
&lt;/p&gt;
&lt;p&gt;
InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.02998
&lt;/p&gt;
&lt;p&gt;
InPars-Light&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#20462;&#25913;&#65292;&#36890;&#36807;&#20351;&#29992;&#23567;&#24471;&#22810;&#30340;&#25490;&#21517;&#27169;&#22411;&#21644;&#20813;&#36153;&#35821;&#35328;&#27169;&#22411;BLOOM&#65292;&#22312;&#22810;&#20010;&#33521;&#25991;&#26816;&#32034;&#38598;&#21512;&#19978;&#26174;&#33879;&#25913;&#36827;&#20102;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#23637;&#20102;&#23545;InPars&#30340;&#21487;&#37325;&#29616;&#24615;&#30740;&#31350;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#35757;&#32451;&#31070;&#32463;&#25490;&#21517;&#22120;&#30340;&#26041;&#27861;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#24320;&#21457;&#20986;&#20102;InPars-Light&#65292;&#36825;&#26159;&#23545;InPars&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#20462;&#25913;&#12290;&#19982;InPars&#19981;&#21516;&#65292;InPars-Light&#20351;&#29992;7-100&#20493;&#26356;&#23567;&#30340;&#25490;&#21517;&#27169;&#22411;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#19968;&#20010;&#20813;&#36153;&#25552;&#20379;&#30340;&#35821;&#35328;&#27169;&#22411;BLOOM&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#19982;&#19987;&#26377;&#30340;GPT-3&#27169;&#22411;&#30456;&#27604;&#65292;BLOOM&#33021;&#22815;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#25490;&#21517;&#22120;&#12290;&#22312;&#25152;&#26377;&#20116;&#20010;&#33521;&#25991;&#26816;&#32034;&#38598;&#21512;&#19978;&#65292;&#25105;&#20204;&#20165;&#20351;&#29992;&#19968;&#20010;30M&#21442;&#25968;&#20845;&#23618;MiniLM-30M&#25490;&#21517;&#22120;&#21644;&#19968;&#20010;&#19977;&#36873;&#20457;&#30340;&#25552;&#31034;&#65292;&#22312;nDCG&#21644;MRR&#26041;&#38754;&#65292;&#30456;&#27604;BM25&#65292;&#25105;&#20204;&#37117;&#33719;&#24471;&#20102;&#26174;&#33879;&#30340;&#65288;7%-30%&#65289;&#19988;&#20855;&#26377;&#32479;&#35745;&#23398;&#24847;&#20041;&#30340;&#25913;&#36827;&#12290;&#30456;&#21453;&#65292;&#22312;InPars&#30340;&#30740;&#31350;&#20013;&#65292;&#21482;&#26377;&#19968;&#20010;&#22823;100&#20493;&#30340;monoT5-3B&#27169;&#22411;&#33021;&#22815;&#22987;&#32456;&#32988;&#36807;BM25&#65292;&#32780;&#23567;&#24471;&#22810;&#30340;monoT5-220M&#27169;&#22411;&#65288;&#20173;&#28982;&#27604;&#25105;&#20204;&#30340;MiniLM&#25490;&#21517;&#22120;&#22823;7&#20493;&#65289;&#21482;&#26159;&#22312;MS MAR&#19978;&#32988;&#36807;BM25&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.02998v2 Announce Type: replace-cross  Abstract: We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MAR
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20221;&#20013;&#25991;&#30340;&#22522;&#20110;&#25351;&#20196;&#30340;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;InstructIE&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;270,000&#20010;&#24369;&#30417;&#30563;&#30340;&#25968;&#25454;&#21644;1,000&#20010;&#39640;&#36136;&#37327;&#27880;&#37322;&#23454;&#20363;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#24403;&#21069;&#30340;&#27169;&#22411;&#34920;&#29616;&#26377;&#24453;&#25913;&#36827;&#65292;&#35813;&#20219;&#21153;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.11527</link><description>&lt;p&gt;
InstructIE: &#19968;&#20221;&#22522;&#20110;&#25351;&#20196;&#30340;&#20013;&#25991;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
InstructIE: A Chinese Instruction-based Information Extraction Dataset. (arXiv:2305.11527v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11527
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20221;&#20013;&#25991;&#30340;&#22522;&#20110;&#25351;&#20196;&#30340;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;InstructIE&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;270,000&#20010;&#24369;&#30417;&#30563;&#30340;&#25968;&#25454;&#21644;1,000&#20010;&#39640;&#36136;&#37327;&#27880;&#37322;&#23454;&#20363;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#24403;&#21069;&#30340;&#27169;&#22411;&#34920;&#29616;&#26377;&#24453;&#25913;&#36827;&#65292;&#35813;&#20219;&#21153;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#39033;&#26032;&#30340;&#20449;&#24687;&#25552;&#21462;&#20219;&#21153;&#65292;&#31216;&#20026;&#22522;&#20110;&#25351;&#20196;&#30340;&#20449;&#24687;&#25552;&#21462; (Instruction-based IE)&#65292;&#23427;&#26088;&#22312;&#35201;&#27714;&#31995;&#32479;&#36981;&#24490;&#29305;&#23450;&#30340;&#25351;&#20196;&#25110;&#25351;&#21335;&#26469;&#25552;&#21462;&#20449;&#24687;&#12290;&#20026;&#20102;&#20419;&#36827;&#35813;&#39046;&#22495;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#31216;&#20026;InstructIE&#65292;&#20854;&#20013;&#21253;&#25324;&#26469;&#33258;&#20013;&#25991;&#32500;&#22522;&#30334;&#31185;&#30340; 270,000 &#20010;&#24369;&#30417;&#30563;&#25968;&#25454;&#21644; 1,000 &#20010;&#39640;&#36136;&#37327;&#20247;&#21253;&#27880;&#37322;&#23454;&#20363;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35780;&#20272;&#20102;&#21508;&#31181;&#22522;&#32447;&#27169;&#22411;&#22312;InstructIE&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;&#24403;&#21069;&#30340;&#27169;&#22411;&#34920;&#29616;&#24456;&#26377;&#24076;&#26395;&#65292;&#20294;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#26696;&#20363;&#30740;&#31350;&#20998;&#26512;&#65292;&#24378;&#35843;&#20102;&#22522;&#20110;&#25351;&#20196;&#30340;&#20449;&#24687;&#25552;&#21462;&#20219;&#21153;&#20013;&#22266;&#26377;&#30340;&#25361;&#25112;&#12290;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#21487;&#22312; https://github.com/zjunlp/DeepKE/tree/main/example/llm &#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new Information Extraction (IE) task dubbed Instruction-based IE, which aims to ask the system to follow specific instructions or guidelines to extract information. To facilitate research in this area, we construct a dataset called InstructIE, consisting of 270,000 weakly supervised data from Chinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We further evaluate the performance of various baseline models on the InstructIE dataset. The results reveal that although current models exhibit promising performance, there is still room for improvement. Furthermore, we conduct a comprehensive case study analysis, underlining the challenges inherent in the Instruction-based IE task. Code and dataset are available at https://github.com/zjunlp/DeepKE/tree/main/example/llm.
&lt;/p&gt;</description></item></channel></rss>