<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>VM-Rec&#26159;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20919;&#21551;&#21160;&#29992;&#25143;&#25512;&#33616;&#38382;&#39064;&#30340;&#21464;&#20998;&#26144;&#23556;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#29983;&#25104;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#23884;&#20837;&#30340;&#29616;&#26377;&#29992;&#25143;&#30340;&#20114;&#21160;&#65292;&#20174;&#32780;&#27169;&#25311;&#29983;&#25104;&#20919;&#21551;&#21160;&#29992;&#25143;&#30340;&#23884;&#20837;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2311.01304</link><description>&lt;p&gt;
VM-Rec&#65306;&#19968;&#31181;&#29992;&#20110;&#20919;&#21551;&#21160;&#29992;&#25143;&#25512;&#33616;&#30340;&#21464;&#20998;&#26144;&#23556;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
VM-Rec: A Variational Mapping Approach for Cold-start User Recommendation. (arXiv:2311.01304v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01304
&lt;/p&gt;
&lt;p&gt;
VM-Rec&#26159;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20919;&#21551;&#21160;&#29992;&#25143;&#25512;&#33616;&#38382;&#39064;&#30340;&#21464;&#20998;&#26144;&#23556;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#29983;&#25104;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#23884;&#20837;&#30340;&#29616;&#26377;&#29992;&#25143;&#30340;&#20114;&#21160;&#65292;&#20174;&#32780;&#27169;&#25311;&#29983;&#25104;&#20919;&#21551;&#21160;&#29992;&#25143;&#30340;&#23884;&#20837;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20919;&#21551;&#21160;&#38382;&#39064;&#26159;&#22823;&#22810;&#25968;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30340;&#20849;&#21516;&#25361;&#25112;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#27169;&#22411;&#22312;&#20919;&#21551;&#21160;&#29992;&#25143;&#30340;&#20114;&#21160;&#38750;&#24120;&#26377;&#38480;&#26102;&#36890;&#24120;&#38590;&#20197;&#29983;&#25104;&#20855;&#26377;&#36275;&#22815;&#34920;&#36798;&#33021;&#21147;&#30340;&#23884;&#20837;&#12290;&#27492;&#22806;&#65292;&#32570;&#20047;&#29992;&#25143;&#30340;&#36741;&#21161;&#20869;&#23481;&#20449;&#24687;&#21152;&#21095;&#20102;&#25361;&#25112;&#30340;&#23384;&#22312;&#65292;&#20351;&#24471;&#22823;&#22810;&#25968;&#20919;&#21551;&#21160;&#26041;&#27861;&#38590;&#20197;&#24212;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22914;&#26524;&#27169;&#22411;&#33021;&#22815;&#20026;&#30456;&#23545;&#26356;&#22810;&#20114;&#21160;&#30340;&#29616;&#26377;&#29992;&#25143;&#29983;&#25104;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#30340;&#23884;&#20837;&#65292;&#36825;&#20123;&#29992;&#25143;&#26368;&#21021;&#20063;&#26159;&#20919;&#21551;&#21160;&#29992;&#25143;&#65292;&#37027;&#20040;&#25105;&#20204;&#21487;&#20197;&#24314;&#31435;&#19968;&#20010;&#20174;&#23569;&#37327;&#21021;&#22987;&#20114;&#21160;&#21040;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#30340;&#23884;&#20837;&#30340;&#26144;&#23556;&#65292;&#27169;&#25311;&#20026;&#20919;&#21551;&#21160;&#29992;&#25143;&#29983;&#25104;&#23884;&#20837;&#30340;&#36807;&#31243;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#20998;&#26144;&#23556;&#26041;&#27861;&#29992;&#20110;&#20919;&#21551;&#21160;&#29992;&#25143;&#25512;&#33616;&#65288;VM-Rec&#65289;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#26681;&#25454;&#20919;&#21551;&#21160;&#29992;&#25143;&#30340;&#21021;&#22987;&#20114;&#21160;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#26144;&#23556;&#20989;&#25968;&#65292;&#24182;&#36827;&#34892;&#21442;&#25968;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The cold-start problem is a common challenge for most recommender systems. With extremely limited interactions of cold-start users, conventional recommender models often struggle to generate embeddings with sufficient expressivity. Moreover, the absence of auxiliary content information of users exacerbates the presence of challenges, rendering most cold-start methods difficult to apply. To address this issue, our motivation is based on the observation that if a model can generate expressive embeddings for existing users with relatively more interactions, who were also initially cold-start users, then we can establish a mapping from few initial interactions to expressive embeddings, simulating the process of generating embeddings for cold-start users. Based on this motivation, we propose a Variational Mapping approach for cold-start user Recommendation (VM-Rec). Firstly, we generate a personalized mapping function for cold-start users based on their initial interactions, and parameters 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#22810;&#35270;&#22270;&#35270;&#35273;&#35821;&#20041;&#23884;&#20837;&#26694;&#26550;&#65292;&#22312;&#22270;&#20687;-&#25991;&#26412;&#26816;&#32034;&#20013;&#26377;&#25928;&#22320;&#21033;&#29992;&#35821;&#20041;&#20449;&#24687;&#36827;&#34892;&#30456;&#20284;&#24615;&#24230;&#37327;&#65292;&#36890;&#36807;&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#25439;&#22833;&#20989;&#25968;&#65292;&#20805;&#20998;&#21033;&#29992;&#20108;&#36827;&#21046;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#23558;&#25972;&#20307;&#21305;&#37197;&#20998;&#35299;&#20026;&#22810;&#20010;&#35270;&#22270;-&#25991;&#26412;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2309.08154</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#22810;&#35270;&#22270;&#35270;&#35273;&#35821;&#20041;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Uncertainty-Aware Multi-View Visual Semantic Embedding. (arXiv:2309.08154v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08154
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#22810;&#35270;&#22270;&#35270;&#35273;&#35821;&#20041;&#23884;&#20837;&#26694;&#26550;&#65292;&#22312;&#22270;&#20687;-&#25991;&#26412;&#26816;&#32034;&#20013;&#26377;&#25928;&#22320;&#21033;&#29992;&#35821;&#20041;&#20449;&#24687;&#36827;&#34892;&#30456;&#20284;&#24615;&#24230;&#37327;&#65292;&#36890;&#36807;&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#25439;&#22833;&#20989;&#25968;&#65292;&#20805;&#20998;&#21033;&#29992;&#20108;&#36827;&#21046;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#23558;&#25972;&#20307;&#21305;&#37197;&#20998;&#35299;&#20026;&#22810;&#20010;&#35270;&#22270;-&#25991;&#26412;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#20687;-&#25991;&#26412;&#26816;&#32034;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#26377;&#25928;&#22320;&#21033;&#29992;&#35821;&#20041;&#20449;&#24687;&#26469;&#34913;&#37327;&#35270;&#35273;&#21644;&#35821;&#35328;&#25968;&#25454;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#23454;&#20363;&#32423;&#30340;&#20108;&#36827;&#21046;&#26631;&#31614;&#65292;&#20854;&#20013;&#27599;&#20010;&#22270;&#20687;&#19982;&#19968;&#20010;&#25991;&#26412;&#37197;&#23545;&#65292;&#26080;&#27861;&#25429;&#25417;&#19981;&#21516;&#35821;&#20041;&#21333;&#20803;&#20043;&#38388;&#30340;&#22810;&#20010;&#23545;&#24212;&#20851;&#31995;&#65292;&#20174;&#32780;&#23548;&#33268;&#22810;&#27169;&#24577;&#35821;&#20041;&#29702;&#35299;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;&#30740;&#31350;&#36890;&#36807;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#32467;&#26500;&#25110;&#39044;&#35757;&#32451;&#25216;&#26415;&#25429;&#25417;&#20102;&#32454;&#31890;&#24230;&#20449;&#24687;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#30452;&#25509;&#24314;&#27169;&#23545;&#24212;&#20851;&#31995;&#30340;&#19981;&#30830;&#23450;&#24615;&#20197;&#20805;&#20998;&#21033;&#29992;&#20108;&#36827;&#21046;&#26631;&#31614;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#22810;&#35270;&#22270;&#35270;&#35273;&#35821;&#20041;&#23884;&#20837;&#65288;UAMVSE&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23558;&#25972;&#20307;&#22270;&#20687;-&#25991;&#26412;&#21305;&#37197;&#20998;&#35299;&#20026;&#22810;&#20010;&#35270;&#22270;-&#25991;&#26412;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#25439;&#22833;&#20989;&#25968;&#65288;UALoss&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#22320;&#24314;&#27169;&#27599;&#20010;&#35270;&#22270;-&#25991;&#26412;&#23545;&#24212;&#20851;&#31995;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#35745;&#31639;&#27599;&#20010;&#35270;&#22270;-&#25991;&#26412;&#25439;&#22833;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
The key challenge in image-text retrieval is effectively leveraging semantic information to measure the similarity between vision and language data. However, using instance-level binary labels, where each image is paired with a single text, fails to capture multiple correspondences between different semantic units, leading to uncertainty in multi-modal semantic understanding. Although recent research has captured fine-grained information through more complex model structures or pre-training techniques, few studies have directly modeled uncertainty of correspondence to fully exploit binary labels. To address this issue, we propose an Uncertainty-Aware Multi-View Visual Semantic Embedding (UAMVSE)} framework that decomposes the overall image-text matching into multiple view-text matchings. Our framework introduce an uncertainty-aware loss function (UALoss) to compute the weighting of each view-text loss by adaptively modeling the uncertainty in each view-text correspondence. Different we
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#26088;&#22312;&#23454;&#29616;&#25512;&#33616;&#31995;&#32479;&#30340;&#21487;&#25345;&#32493;&#36879;&#26126;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36125;&#21494;&#26031;&#25490;&#21517;&#22270;&#20687;&#36827;&#34892;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#20197;&#26368;&#22823;&#21270;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;</title><link>http://arxiv.org/abs/2308.01196</link><description>&lt;p&gt;
&#21487;&#25345;&#32493;&#36879;&#26126;&#30340;&#25512;&#33616;&#31995;&#32479;: &#29992;&#20110;&#35299;&#37322;&#24615;&#30340;&#36125;&#21494;&#26031;&#22270;&#20687;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability. (arXiv:2308.01196v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01196
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#26088;&#22312;&#23454;&#29616;&#25512;&#33616;&#31995;&#32479;&#30340;&#21487;&#25345;&#32493;&#36879;&#26126;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36125;&#21494;&#26031;&#25490;&#21517;&#22270;&#20687;&#36827;&#34892;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#20197;&#26368;&#22823;&#21270;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#29616;&#20195;&#19990;&#30028;&#20013;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#36890;&#24120;&#25351;&#23548;&#29992;&#25143;&#25214;&#21040;&#30456;&#20851;&#30340;&#20869;&#23481;&#25110;&#20135;&#21697;&#65292;&#24182;&#23545;&#29992;&#25143;&#21644;&#20844;&#27665;&#30340;&#20915;&#31574;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#30830;&#20445;&#36825;&#20123;&#31995;&#32479;&#30340;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20449;&#20219;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65307;&#20010;&#24615;&#21270;&#35299;&#37322;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#20026;&#25512;&#33616;&#25552;&#20379;&#29702;&#30001;&#12290;&#22312;&#29983;&#25104;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#29992;&#25143;&#21019;&#24314;&#30340;&#35270;&#35273;&#20869;&#23481;&#26159;&#19968;&#20010;&#29305;&#21035;&#26377;&#28508;&#21147;&#30340;&#36873;&#39033;&#65292;&#26377;&#28508;&#21147;&#26368;&#22823;&#21270;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#27169;&#22411;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#35299;&#37322;&#25512;&#33616;&#26102;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#65306;&#21487;&#25345;&#32493;&#24615;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#20204;&#32463;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#23548;&#33268;&#30340;&#30899;&#25490;&#25918;&#37327;&#19982;&#23427;&#20204;&#34987;&#25972;&#21512;&#21040;&#25512;&#33616;&#31995;&#32479;&#20013;&#30456;&#24403;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#27169;&#22411;&#20351;&#29992;&#30340;&#26367;&#20195;&#23398;&#20064;&#30446;&#26631;&#19982;&#25490;&#21517;&#26368;&#26377;&#25928;&#30340;&#30446;&#26631;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender Systems have become crucial in the modern world, commonly guiding users towards relevant content or products, and having a large influence over the decisions of users and citizens. However, ensuring transparency and user trust in these systems remains a challenge; personalized explanations have emerged as a solution, offering justifications for recommendations. Among the existing approaches for generating personalized explanations, using visual content created by the users is one particularly promising option, showing a potential to maximize transparency and user trust. Existing models for explaining recommendations in this context face limitations: sustainability has been a critical concern, as they often require substantial computational resources, leading to significant carbon emissions comparable to the Recommender Systems where they would be integrated. Moreover, most models employ surrogate learning goals that do not align with the objective of ranking the most effect
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#32034;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#22312;&#32447;&#32844;&#20301;&#25512;&#33616;&#20013;&#23545;&#22270;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#26694;&#26550;&#26469;&#20998;&#26512;&#34892;&#20026;&#22270;&#65292;&#21457;&#29616;&#20854;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#21644;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.05722</link><description>&lt;p&gt;
&#25506;&#32034;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#22312;&#32447;&#32844;&#20301;&#25512;&#33616;&#20013;&#23545;&#22270;&#25968;&#25454;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations. (arXiv:2307.05722v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#32034;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#22312;&#32447;&#32844;&#20301;&#25512;&#33616;&#20013;&#23545;&#22270;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#26694;&#26550;&#26469;&#20998;&#26512;&#34892;&#20026;&#22270;&#65292;&#21457;&#29616;&#20854;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#21644;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#23637;&#31034;&#20102;&#20854;&#20986;&#33394;&#30340;&#33021;&#21147;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#32844;&#20301;&#25512;&#33616;&#20013;&#23545;&#34892;&#20026;&#22270;&#30340;&#29702;&#35299;&#28508;&#21147;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#26088;&#22312;&#25581;&#31034;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#34892;&#20026;&#22270;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#29702;&#35299;&#26469;&#25552;&#21319;&#22312;&#32447;&#25307;&#32856;&#20013;&#30340;&#25512;&#33616;&#65292;&#21253;&#25324;&#20419;&#36827;&#38750;&#20998;&#24067;&#24335;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#30340;&#20016;&#23500;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#35821;&#20041;&#34920;&#31034;&#26469;&#20998;&#26512;&#34892;&#20026;&#22270;&#24182;&#25581;&#31034;&#20854;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#21644;&#20851;&#31995;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20803;&#36335;&#24452;&#25552;&#31034;&#26500;&#36896;&#22120;&#65292;&#21033;&#29992;LLM&#25512;&#33616;&#22120;&#39318;&#27425;&#29702;&#35299;&#34892;&#20026;&#22270;&#65292;&#24182;&#35774;&#35745;&#20102;&#30456;&#24212;&#30340;&#36335;&#24452;&#22686;&#24378;&#27169;&#22359;&#26469;&#32531;&#35299;&#22522;&#20110;&#36335;&#24452;&#30340;&#24207;&#21015;&#36755;&#20837;&#24341;&#20837;&#30340;&#25552;&#31034;&#20559;&#24046;&#12290;&#36890;&#36807;&#21033;&#29992;&#23558;LM&#30340;&#29305;&#28857;&#24341;&#20837;&#21040;&#34892;&#20026;&#22270;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for behavior graph understanding in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including the promotion of out-of-distribution (OOD) application. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that leverages LLM recommender to understand behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By leveragin
&lt;/p&gt;</description></item></channel></rss>