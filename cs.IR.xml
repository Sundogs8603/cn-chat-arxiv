<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;BIGRec&#30340;&#20004;&#27493;&#25509;&#22320;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#25512;&#33616;&#31354;&#38388;&#25509;&#22320;&#65292;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#26631;&#35760;&#65292;&#24182;&#35782;&#21035;&#30456;&#24212;&#30340;&#23454;&#38469;&#39033;&#30446;&#65292;&#26469;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20840;&#38754;&#25490;&#24207;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.08434</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#21452;&#27493;&#25509;&#22320;&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems. (arXiv:2308.08434v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;BIGRec&#30340;&#20004;&#27493;&#25509;&#22320;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#25512;&#33616;&#31354;&#38388;&#25509;&#22320;&#65292;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#26631;&#35760;&#65292;&#24182;&#35782;&#21035;&#30456;&#24212;&#30340;&#23454;&#38469;&#39033;&#30446;&#65292;&#26469;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20840;&#38754;&#25490;&#24207;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25512;&#33616;&#39046;&#22495;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20851;&#27880;&#21152;&#24378;&#65292;&#38024;&#23545;&#25512;&#33616;&#30446;&#30340;&#65288;&#31216;&#20026;LLM4Rec&#65289;&#20248;&#21270;LLMs&#30340;&#37325;&#35201;&#24615;&#22312;&#25552;&#20379;&#25512;&#33616;&#26041;&#38754;&#24471;&#21040;&#20102;&#22686;&#24378;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;LLM4Rec&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#26377;&#38480;&#30340;&#20505;&#36873;&#38598;&#26469;&#35780;&#20272;&#24615;&#33021;&#65292;&#36825;&#21487;&#33021;&#26080;&#27861;&#20934;&#30830;&#21453;&#26144;&#27169;&#22411;&#30340;&#25972;&#20307;&#25490;&#24207;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35843;&#26597;LLMs&#30340;&#20840;&#38754;&#25490;&#24207;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#19968;&#20010;&#21517;&#20026;BIGRec&#65288;&#25512;&#33616;&#30340;&#21452;&#27493;&#25509;&#22320;&#33539;&#24335;&#65289;&#30340;&#20004;&#27493;&#25509;&#22320;&#26694;&#26550;&#12290;&#23427;&#39318;&#20808;&#36890;&#36807;&#24494;&#35843;&#23558;LLMs&#19982;&#25512;&#33616;&#31354;&#38388;&#25509;&#22320;&#65292;&#29983;&#25104;&#19982;&#39033;&#30446;&#30456;&#20851;&#30340;&#26377;&#24847;&#20041;&#30340;&#26631;&#35760;&#65292;&#28982;&#21518;&#35782;&#21035;&#19982;&#29983;&#25104;&#30340;&#26631;&#35760;&#30456;&#23545;&#24212;&#30340;&#36866;&#24403;&#23454;&#38469;&#39033;&#30446;&#12290;&#36890;&#36807;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#12289;&#22788;&#29702;&#23569;&#26679;&#26412;&#22330;&#26223;&#30340;&#33021;&#21147;&#20197;&#21450;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#36890;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the focus on Large Language Models (LLMs) in the field of recommendation intensifies, the optimization of LLMs for recommendation purposes (referred to as LLM4Rec) assumes a crucial role in augmenting their effectiveness in providing recommendations. However, existing approaches for LLM4Rec often assess performance using restricted sets of candidates, which may not accurately reflect the models' overall ranking capabilities. In this paper, our objective is to investigate the comprehensive ranking capacity of LLMs and propose a two-step grounding framework known as BIGRec (Bi-step Grounding Paradigm for Recommendation). It initially grounds LLMs to the recommendation space by fine-tuning them to generate meaningful tokens for items and subsequently identifies appropriate actual items that correspond to the generated tokens. By conducting extensive experiments on two datasets, we substantiate the superior performance, capacity for handling few-shot scenarios, and versatility across mu
&lt;/p&gt;</description></item></channel></rss>