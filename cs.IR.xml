<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#23545;&#32452;&#32455;&#30149;&#29702;&#23398;&#22270;&#20687;&#25628;&#32034;&#24341;&#25806;&#36827;&#34892;&#20102;&#20998;&#26512;&#21644;&#39564;&#35777;&#65292;&#23545;&#20854;&#24615;&#33021;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#26576;&#20123;&#25628;&#32034;&#24341;&#25806;&#22312;&#25928;&#29575;&#21644;&#36895;&#24230;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#31934;&#24230;&#36739;&#20302;&#65292;&#32780;&#20854;&#20182;&#25628;&#32034;&#24341;&#25806;&#30340;&#20934;&#30830;&#29575;&#36739;&#39640;&#65292;&#20294;&#36816;&#34892;&#25928;&#29575;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2401.03271</link><description>&lt;p&gt;
&#32452;&#32455;&#30149;&#29702;&#23398;&#22270;&#20687;&#25628;&#32034;&#24341;&#25806;&#30340;&#20998;&#26512;&#19982;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Analysis and Validation of Image Search Engines in Histopathology. (arXiv:2401.03271v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03271
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#32452;&#32455;&#30149;&#29702;&#23398;&#22270;&#20687;&#25628;&#32034;&#24341;&#25806;&#36827;&#34892;&#20102;&#20998;&#26512;&#21644;&#39564;&#35777;&#65292;&#23545;&#20854;&#24615;&#33021;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#26576;&#20123;&#25628;&#32034;&#24341;&#25806;&#22312;&#25928;&#29575;&#21644;&#36895;&#24230;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#31934;&#24230;&#36739;&#20302;&#65292;&#32780;&#20854;&#20182;&#25628;&#32034;&#24341;&#25806;&#30340;&#20934;&#30830;&#29575;&#36739;&#39640;&#65292;&#20294;&#36816;&#34892;&#25928;&#29575;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32452;&#32455;&#23398;&#21644;&#30149;&#29702;&#23398;&#22270;&#20687;&#26723;&#26696;&#20013;&#25628;&#32034;&#30456;&#20284;&#22270;&#20687;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#65292;&#21487;&#20197;&#22312;&#21508;&#31181;&#30446;&#30340;&#20013;&#24110;&#21161;&#24739;&#32773;&#21305;&#37197;&#65292;&#20174;&#20998;&#31867;&#21644;&#35786;&#26029;&#21040;&#39044;&#21518;&#21644;&#39044;&#27979;&#12290;&#20840;&#29627;&#29255;&#22270;&#20687;&#26159;&#32452;&#32455;&#26631;&#26412;&#30340;&#39640;&#24230;&#35814;&#32454;&#25968;&#23383;&#34920;&#31034;&#65292;&#21305;&#37197;&#20840;&#29627;&#29255;&#22270;&#20687;&#21487;&#20197;&#20316;&#20026;&#24739;&#32773;&#21305;&#37197;&#30340;&#20851;&#38190;&#26041;&#27861;&#12290;&#26412;&#25991;&#23545;&#22235;&#31181;&#25628;&#32034;&#26041;&#27861;&#65292;&#35270;&#35273;&#35789;&#34955;&#65288;BoVW&#65289;&#12289;Yottixel&#12289;SISH&#12289;RetCCL&#21450;&#20854;&#19968;&#20123;&#28508;&#22312;&#21464;&#31181;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#20998;&#26512;&#21644;&#39564;&#35777;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#31639;&#27861;&#21644;&#32467;&#26500;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#22235;&#20010;&#20869;&#37096;&#25968;&#25454;&#38598;&#65288;1269&#20301;&#24739;&#32773;&#65289;&#21644;&#19977;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#65288;1207&#20301;&#24739;&#32773;&#65289;&#65292;&#24635;&#35745;&#36229;&#36807;200,000&#20010;&#23646;&#20110;&#20116;&#20010;&#20027;&#35201;&#37096;&#20301;&#30340;38&#20010;&#19981;&#21516;&#31867;&#21035;/&#20122;&#22411;&#30340;&#22270;&#20687;&#22359;&#12290;&#26576;&#20123;&#25628;&#32034;&#24341;&#25806;&#65292;&#20363;&#22914;BoVW&#65292;&#34920;&#29616;&#20986;&#26174;&#30528;&#30340;&#25928;&#29575;&#21644;&#36895;&#24230;&#65292;&#20294;&#31934;&#24230;&#36739;&#20302;&#12290;&#30456;&#21453;&#65292;&#20854;&#20182;&#25628;&#32034;&#24341;&#25806;&#20363;&#22914;SISH&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#20934;&#30830;&#29575;&#65292;&#20294;&#36816;&#34892;&#25928;&#29575;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Searching for similar images in archives of histology and histopathology images is a crucial task that may aid in patient matching for various purposes, ranging from triaging and diagnosis to prognosis and prediction. Whole slide images (WSIs) are highly detailed digital representations of tissue specimens mounted on glass slides. Matching WSI to WSI can serve as the critical method for patient matching. In this paper, we report extensive analysis and validation of four search methods bag of visual words (BoVW), Yottixel, SISH, RetCCL, and some of their potential variants. We analyze their algorithms and structures and assess their performance. For this evaluation, we utilized four internal datasets ($1269$ patients) and three public datasets ($1207$ patients), totaling more than $200,000$ patches from $38$ different classes/subtypes across five primary sites. Certain search engines, for example, BoVW, exhibit notable efficiency and speed but suffer from low accuracy. Conversely, searc
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#36140;&#20302;&#35780;&#32423;&#32773;&#26356;&#25797;&#38271;&#39044;&#27979;&#26410;&#26469;&#20250;&#33719;&#24471;&#39640;&#35780;&#20998;&#30340;&#39184;&#21381;&#65292;&#24182;&#22312;&#39184;&#21381;&#21457;&#29616;&#20013;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;</title><link>http://arxiv.org/abs/2401.03193</link><description>&lt;p&gt;
&#25361;&#21076;&#30340;&#39135;&#23458;&#20250;&#25104;&#20026;&#26356;&#22909;&#30340;&#35780;&#20998;&#32773;
&lt;/p&gt;
&lt;p&gt;
Picky Eaters Make For Better Raters. (arXiv:2401.03193v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03193
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#36140;&#20302;&#35780;&#32423;&#32773;&#26356;&#25797;&#38271;&#39044;&#27979;&#26410;&#26469;&#20250;&#33719;&#24471;&#39640;&#35780;&#20998;&#30340;&#39184;&#21381;&#65292;&#24182;&#22312;&#39184;&#21381;&#21457;&#29616;&#20013;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#24050;&#32463;&#35777;&#26126;&#65292;&#22312;&#22312;&#32447;&#35780;&#32423;&#31995;&#32479;&#65288;ORS&#65289;&#19978;&#30340;&#35780;&#32423;&#25968;&#37327;&#21644;&#39184;&#21381;&#33719;&#24471;&#30340;&#35780;&#20998;&#26174;&#33879;&#24433;&#21709;&#20854;&#25910;&#20837;&#12290;&#28982;&#32780;&#65292;&#24403;&#19968;&#20010;&#39184;&#21381;&#21482;&#26377;&#26377;&#38480;&#25968;&#37327;&#30340;&#35780;&#32423;&#26102;&#65292;&#39044;&#27979;&#20854;&#26410;&#26469;&#34920;&#29616;&#21487;&#33021;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#35780;&#32423;&#21487;&#33021;&#26356;&#22810;&#22320;&#21453;&#26144;&#20102;&#36827;&#34892;&#35780;&#32423;&#30340;&#29992;&#25143;&#32780;&#19981;&#26159;&#39184;&#21381;&#30340;&#36136;&#37327;&#12290;&#36825;&#28608;&#21169;&#25105;&#20204;&#23558;&#29992;&#25143;&#20998;&#25104;&#8220;&#22840;&#22823;&#35780;&#32423;&#32773;&#8221;&#65292;&#20182;&#20204;&#20542;&#21521;&#20110;&#32473;&#20986;&#24322;&#24120;&#39640;&#30340;&#35780;&#32423;&#65292;&#8220;&#36140;&#20302;&#35780;&#32423;&#32773;&#8221;&#65292;&#20182;&#20204;&#20542;&#21521;&#20110;&#32473;&#20986;&#24322;&#24120;&#20302;&#30340;&#35780;&#32423;&#65292;&#24182;&#27604;&#36739;&#36825;&#20004;&#20010;&#32676;&#20307;&#29983;&#25104;&#30340;&#25490;&#21517;&#12290;&#20351;&#29992;Yelp&#25552;&#20379;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#21457;&#29616;&#36140;&#20302;&#35780;&#32423;&#32773;&#26356;&#25797;&#38271;&#39044;&#27979;&#26410;&#26469;&#20250;&#33719;&#24471;&#39640;&#35780;&#20998;&#65288;4.5&#21450;&#20197;&#19978;&#65289;&#30340;&#39184;&#21381;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#36140;&#20302;&#35780;&#32423;&#32773;&#22312;&#39184;&#21381;&#21457;&#29616;&#20013;&#21487;&#33021;&#21457;&#25381;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
It has been established in the literature that the number of ratings and the scores restaurants obtain on online rating systems (ORS) significantly impact their revenue. However, when a restaurant has a limited number of ratings, it may be challenging to predict its future performance. It may well be that ratings reveal more about the user who did the rating than about the quality of the restaurant. This motivates us to segment users into "inflating raters", who tend to give unusually high ratings, and "deflating raters", who tend to give unusually low ratings, and compare the rankings generated by these two populations. Using a public dataset provided by Yelp, we find that deflating raters are better at predicting restaurants that will achieve a top rating (4.5 and above) in the future. As such, these deflating raters may have an important role in restaurant discovery.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QoS&#24863;&#30693;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;QAGCL&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#20855;&#26377;&#22320;&#29702;&#20301;&#32622;&#20449;&#24687;&#21644;&#38543;&#26426;&#24615;&#30340;&#19978;&#19979;&#25991;&#22686;&#24378;&#22270;&#26469;&#35299;&#20915;&#32593;&#32476;&#26381;&#21153;&#25512;&#33616;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#24182;&#26377;&#25928;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03162</link><description>&lt;p&gt;
QoS&#24863;&#30693;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#32593;&#32476;&#26381;&#21153;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
QoS-Aware Graph Contrastive Learning for Web Service Recommendation. (arXiv:2401.03162v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QoS&#24863;&#30693;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;QAGCL&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#20855;&#26377;&#22320;&#29702;&#20301;&#32622;&#20449;&#24687;&#21644;&#38543;&#26426;&#24615;&#30340;&#19978;&#19979;&#25991;&#22686;&#24378;&#22270;&#26469;&#35299;&#20915;&#32593;&#32476;&#26381;&#21153;&#25512;&#33616;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#24182;&#26377;&#25928;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#32593;&#32476;&#26381;&#21153;&#25216;&#26415;&#30340;&#36827;&#27493;&#65292;&#20113;&#26381;&#21153;&#30340;&#24555;&#36895;&#22686;&#38271;&#20351;&#24471;&#20174;&#20247;&#22810;&#36873;&#39033;&#20013;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#26381;&#21153;&#21464;&#24471;&#22797;&#26434;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#36136;&#37327;&#26381;&#21153;&#65288;QoS&#65289;&#35299;&#20915;&#32593;&#32476;&#26381;&#21153;&#25512;&#33616;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QoS&#24863;&#30693;&#30340;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;QAGCL&#65289;&#30340;&#26032;&#26041;&#27861;&#26469;&#36827;&#34892;&#32593;&#32476;&#26381;&#21153;&#25512;&#33616;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21033;&#29992;&#22270;&#23545;&#27604;&#23398;&#20064;&#30340;&#33021;&#21147;&#26469;&#22788;&#29702;&#20919;&#21551;&#21160;&#38382;&#39064;&#24182;&#26377;&#25928;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#26500;&#24314;&#20855;&#26377;&#22320;&#29702;&#20301;&#32622;&#20449;&#24687;&#21644;&#38543;&#26426;&#24615;&#30340;&#19978;&#19979;&#25991;&#22686;&#24378;&#22270;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#25552;&#20379;&#22810;&#26679;&#21270;&#30340;&#35270;&#35282;&#12290;&#36890;&#36807;&#20351;&#29992;&#22270;&#21367;&#31215;&#32593;&#32476;&#21644;&#22270;&#23545;&#27604;&#23398;&#20064;&#25216;&#26415;&#65292;&#25105;&#20204;&#20174;&#36825;&#20123;&#22686;&#24378;&#22270;&#20013;&#23398;&#20064;&#29992;&#25143;&#21644;&#26381;&#21153;&#30340;&#23884;&#20837;&#12290;&#28982;&#21518;&#21033;&#29992;&#23398;&#21040;&#30340;&#23884;&#20837;&#23558;QoS&#32771;&#34385;&#26080;&#32541;&#38598;&#25104;&#21040;&#25512;&#33616;&#36807;&#31243;&#20013;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35299;&#20915;&#25968;&#25454;&#31232;&#30095;&#24615;&#21644;&#20919;&#21551;&#21160;&#38382;&#39064;&#30340;&#21516;&#26102;&#26174;&#33879;&#25552;&#39640;&#20102;&#25512;&#33616;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rapid growth of cloud services driven by advancements in web service technology, selecting a high-quality service from a wide range of options has become a complex task. This study aims to address the challenges of data sparsity and the cold-start problem in web service recommendation using Quality of Service (QoS). We propose a novel approach called QoS-aware graph contrastive learning (QAGCL) for web service recommendation. Our model harnesses the power of graph contrastive learning to handle cold-start problems and improve recommendation accuracy effectively. By constructing contextually augmented graphs with geolocation information and randomness, our model provides diverse views. Through the use of graph convolutional networks and graph contrastive learning techniques, we learn user and service embeddings from these augmented graphs. The learned embeddings are then utilized to seamlessly integrate QoS considerations into the recommendation process. Experimental results de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23545;&#34920;&#29616;&#21147;&#38050;&#29748;&#28436;&#22863;&#29305;&#24449;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#27979;&#35797;&#20102;&#20116;&#20010;&#23884;&#20837;&#27169;&#22411;&#21450;&#20854;&#30456;&#20284;&#24615;&#32467;&#26500;&#19982;&#30495;&#20540;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#24182;&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#35780;&#20272;&#12290;&#23884;&#20837;&#27169;&#22411;&#30340;&#36136;&#37327;&#22312;&#36825;&#26041;&#38754;&#26174;&#31034;&#20986;&#24456;&#22823;&#30340;&#24046;&#24322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.02979</link><description>&lt;p&gt;
&#25105;&#20204;&#22312;&#25551;&#36848;&#21516;&#26679;&#30340;&#22768;&#38899;&#21527;&#65311;&#23545;&#34920;&#29616;&#21147;&#38050;&#29748;&#28436;&#22863;&#35789;&#23884;&#20837;&#31354;&#38388;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Are we describing the same sound? An analysis of word embedding spaces of expressive piano performance. (arXiv:2401.02979v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02979
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23545;&#34920;&#29616;&#21147;&#38050;&#29748;&#28436;&#22863;&#29305;&#24449;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#27979;&#35797;&#20102;&#20116;&#20010;&#23884;&#20837;&#27169;&#22411;&#21450;&#20854;&#30456;&#20284;&#24615;&#32467;&#26500;&#19982;&#30495;&#20540;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#24182;&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#35780;&#20272;&#12290;&#23884;&#20837;&#27169;&#22411;&#30340;&#36136;&#37327;&#22312;&#36825;&#26041;&#38754;&#26174;&#31034;&#20986;&#24456;&#22823;&#30340;&#24046;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#20041;&#23884;&#20837;&#22312;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#20449;&#24687;&#26816;&#32034;&#20013;&#36215;&#21040;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23884;&#20837;&#27169;&#22411;&#23558;&#21333;&#35789;&#21644;&#19978;&#19979;&#25991;&#34920;&#31034;&#20026;&#21521;&#37327;&#65292;&#20854;&#31354;&#38388;&#37197;&#32622;&#26159;&#26681;&#25454;&#22823;&#22411;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#21333;&#35789;&#30340;&#20998;&#24067;&#23548;&#20986;&#30340;&#12290;&#23613;&#31649;&#36825;&#20123;&#34920;&#31034;&#19968;&#33324;&#38750;&#24120;&#24378;&#22823;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#26410;&#33021;&#32771;&#34385;&#21040;&#32454;&#31890;&#24230;&#30340;&#39046;&#22495;&#29305;&#23450;&#32454;&#24494;&#24046;&#21035;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#31181;&#23545;&#34920;&#29616;&#21147;&#38050;&#29748;&#28436;&#22863;&#29305;&#24449;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#38899;&#20048;&#30740;&#31350;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#33258;&#30001;&#25991;&#26412;&#28436;&#22863;&#29305;&#24449;&#30340;&#27880;&#37322;&#65292;&#24182;&#36827;&#34892;&#20102;&#19968;&#20010;&#21518;&#32493;&#30740;&#31350;&#65292;&#23558;&#27880;&#37322;&#20998;&#31867;&#25104;&#19981;&#21516;&#30340;&#32858;&#31867;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#29305;&#23450;&#39046;&#22495;&#35821;&#20041;&#30456;&#20284;&#24615;&#32467;&#26500;&#30340;&#30495;&#20540;&#12290;&#25105;&#20204;&#27979;&#35797;&#20102;&#20116;&#20010;&#23884;&#20837;&#27169;&#22411;&#21450;&#20854;&#30456;&#20284;&#24615;&#32467;&#26500;&#19982;&#30495;&#20540;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35780;&#20272;&#20102;&#19978;&#19979;&#25991;&#25552;&#31034;&#12289;&#20013;&#24515;&#24230;&#38477;&#20302;&#12289;&#36328;&#27169;&#24577;&#30456;&#20284;&#24615;&#21644;k-means&#32858;&#31867;&#30340;&#24433;&#21709;&#12290;&#23884;&#20837;&#27169;&#22411;&#30340;&#36136;&#37327;&#22312;&#36825;&#26041;&#38754;&#26174;&#31034;&#20986;&#24456;&#22823;&#30340;&#24046;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semantic embeddings play a crucial role in natural language-based information retrieval. Embedding models represent words and contexts as vectors whose spatial configuration is derived from the distribution of words in large text corpora. While such representations are generally very powerful, they might fail to account for fine-grained domain-specific nuances. In this article, we investigate this uncertainty for the domain of characterizations of expressive piano performance. Using a music research dataset of free text performance characterizations and a follow-up study sorting the annotations into clusters, we derive a ground truth for a domain-specific semantic similarity structure. We test five embedding models and their similarity structure for correspondence with the ground truth. We further assess the effects of contextualizing prompts, hubness reduction, cross-modal similarity, and k-means clustering. The quality of embedding models shows great variability with respect to this 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26816;&#27979;&#22312;&#32447;&#20844;&#24320;&#23041;&#32961;&#30340;&#25928;&#21147;&#12290;&#36890;&#36807;&#23454;&#39564;&#21457;&#29616;&#65292;&#19981;&#21516;&#30340;LLMs&#22312;&#23041;&#32961;&#21644;&#38750;&#23041;&#32961;&#35782;&#21035;&#26041;&#38754;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#20854;&#20013;GPT-4&#30340;&#34920;&#29616;&#26368;&#20339;&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;PaLM API&#30340;&#23450;&#20215;&#38750;&#24120;&#20855;&#26377;&#25104;&#26412;&#25928;&#30410;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#21487;&#20197;&#26377;&#25928;&#22320;&#22686;&#24378;&#20154;&#24037;&#20869;&#23481;&#23457;&#26597;&#65292;&#24110;&#21161;&#20943;&#36731;&#26032;&#20852;&#30340;&#22312;&#32447;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2401.02974</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26816;&#27979;&#22312;&#32447;&#20844;&#24320;&#23041;&#32961;&#30340;&#25928;&#21147;
&lt;/p&gt;
&lt;p&gt;
Efficacy of Utilizing Large Language Models to Detect Public Threat Posted Online. (arXiv:2401.02974v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02974
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26816;&#27979;&#22312;&#32447;&#20844;&#24320;&#23041;&#32961;&#30340;&#25928;&#21147;&#12290;&#36890;&#36807;&#23454;&#39564;&#21457;&#29616;&#65292;&#19981;&#21516;&#30340;LLMs&#22312;&#23041;&#32961;&#21644;&#38750;&#23041;&#32961;&#35782;&#21035;&#26041;&#38754;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#20854;&#20013;GPT-4&#30340;&#34920;&#29616;&#26368;&#20339;&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;PaLM API&#30340;&#23450;&#20215;&#38750;&#24120;&#20855;&#26377;&#25104;&#26412;&#25928;&#30410;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#21487;&#20197;&#26377;&#25928;&#22320;&#22686;&#24378;&#20154;&#24037;&#20869;&#23481;&#23457;&#26597;&#65292;&#24110;&#21161;&#20943;&#36731;&#26032;&#20852;&#30340;&#22312;&#32447;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26816;&#27979;&#22312;&#32447;&#20844;&#24320;&#23041;&#32961;&#30340;&#25928;&#21147;&#12290;&#22312;&#23545;&#23041;&#32961; retoric &#30340;&#20256;&#25773;&#21644;&#26292;&#21147;&#39044;&#21578;&#30340;&#22686;&#38271;&#36234;&#26469;&#36234;&#25285;&#24551;&#30340;&#32972;&#26223;&#19979;&#65292;&#33258;&#21160;&#20869;&#23481;&#20998;&#26512;&#25216;&#26415;&#21487;&#20197;&#24110;&#21161;&#26089;&#26399;&#21457;&#29616;&#21644;&#22788;&#29702;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#33258;&#23450;&#20041;&#30340;&#25968;&#25454;&#25910;&#38598;&#24037;&#20855;&#65292;&#20174;&#19968;&#20010;&#28909;&#38376;&#30340;&#38889;&#22269;&#22312;&#32447;&#31038;&#21306;&#25910;&#38598;&#20102;500&#20010;&#38750;&#23041;&#32961;&#31034;&#20363;&#21644;20&#20010;&#23041;&#32961;&#31034;&#20363;&#30340;&#24086;&#23376;&#26631;&#39064;&#12290;&#21508;&#31181;LLMs (GPT-3.5, GPT-4, PaLM) &#34987;&#25552;&#31034;&#23558;&#21333;&#20010;&#24086;&#23376;&#20998;&#31867;&#20026;"&#23041;&#32961;"&#25110;"&#23433;&#20840;"&#12290;&#32479;&#35745;&#20998;&#26512;&#21457;&#29616;&#25152;&#26377;&#27169;&#22411;&#22312;&#23041;&#32961;&#21644;&#38750;&#23041;&#32961;&#35782;&#21035;&#26041;&#38754;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#36890;&#36807;&#21345;&#26041;&#25311;&#21512;&#24230;&#26816;&#39564;&#20063;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;GPT-4 &#30340;&#25972;&#20307;&#34920;&#29616;&#26368;&#22909;&#65292;&#38750;&#23041;&#32961;&#31934;&#24230;&#36798;&#21040;&#20102;97.9%&#65292;&#23041;&#32961;&#31934;&#24230;&#36798;&#21040;&#20102;100%&#12290;&#21487;&#34892;&#24615;&#20998;&#26512;&#36824;&#26174;&#31034;PaLM API&#30340;&#23450;&#20215;&#38750;&#24120;&#20855;&#26377;&#25104;&#26412;&#25928;&#30410;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;LLMs &#22312;&#35268;&#27169;&#21270;&#29615;&#22659;&#20013;&#21487;&#20197;&#26377;&#25928;&#22320;&#22686;&#24378;&#20154;&#24037;&#20869;&#23481;&#23457;&#26597;&#65292;&#20197;&#24110;&#21161;&#20943;&#36731;&#26032;&#20852;&#30340;&#22312;&#32447;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper examines the efficacy of utilizing large language models (LLMs) to detect public threats posted online. Amid rising concerns over the spread of threatening rhetoric and advance notices of violence, automated content analysis techniques may aid in early identification and moderation. Custom data collection tools were developed to amass post titles from a popular Korean online community, comprising 500 non-threat examples and 20 threats. Various LLMs (GPT-3.5, GPT-4, PaLM) were prompted to classify individual posts as either "threat" or "safe." Statistical analysis found all models demonstrated strong accuracy, passing chi-square goodness of fit tests for both threat and non-threat identification. GPT-4 performed best overall with 97.9% non-threat and 100% threat accuracy. Affordability analysis also showed PaLM API pricing as highly cost-efficient. The findings indicate LLMs can effectively augment human content moderation at scale to help mitigate emerging online risks. Howe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#65292;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#31574;&#30053;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#26032;&#21453;&#24212;&#25351;&#32441;&#65292;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#27492;&#31995;&#32479;&#21487;&#20197;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.10776</link><description>&lt;p&gt;
&#22312;&#21270;&#23398;&#21512;&#25104;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#20013;&#65292;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Generative Agent for Reaction Condition Recommendation in Chemical Synthesis. (arXiv:2311.10776v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.10776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#65292;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#31574;&#30053;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21644;&#26032;&#21453;&#24212;&#25351;&#32441;&#65292;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#27492;&#31995;&#32479;&#21487;&#20197;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20026;&#21270;&#23398;&#31038;&#20250;&#20013;&#30340;&#33258;&#21160;&#21270;&#21270;&#23398;&#21453;&#24212;&#38138;&#24179;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#26410;&#26469;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#21464;&#24615;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#25216;&#26415;&#33258;&#21160;&#21270;&#21270;&#23398;&#20013;&#30340;&#21453;&#24212;&#26465;&#20214;&#25512;&#33616;&#65288;RCR&#65289;&#20219;&#21153;&#12290;&#36890;&#36807;&#27169;&#25311;&#19987;&#23478;&#21270;&#23398;&#23478;&#30340;&#25628;&#32034;&#21644;&#20998;&#26512;&#31574;&#30053;&#65292;&#35813;&#20195;&#29702;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#26597;&#35810;&#20998;&#23376;&#25968;&#25454;&#24211;&#65292;&#24182;&#20174;&#22312;&#32447;&#25991;&#29486;&#20013;&#25552;&#21462;&#20851;&#38190;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#36824;&#37197;&#22791;&#20102;&#25105;&#20204;&#20026;RCR&#20219;&#21153;&#24320;&#21457;&#30340;&#26032;&#21453;&#24212;&#25351;&#32441;&#12290;&#30001;&#20110;RAG&#25216;&#26415;&#30340;&#20351;&#29992;&#65292;&#25105;&#20204;&#30340;&#20195;&#29702;&#20351;&#29992;&#26356;&#26032;&#30340;&#22312;&#32447;&#25968;&#25454;&#24211;&#20316;&#20026;&#30693;&#35782;&#28304;&#65292;&#26174;&#33879;&#20248;&#20110;&#20165;&#21463;&#20854;&#35757;&#32451;&#25968;&#25454;&#22266;&#23450;&#30693;&#35782;&#38480;&#21046;&#30340;&#20256;&#32479;&#20154;&#24037;&#26234;&#33021;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#31995;&#32479;&#21487;&#20197;&#26174;&#33879;&#20943;&#36731;&#21270;&#23398;&#23478;&#30340;&#24037;&#20316;&#36127;&#25285;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#26356;&#19987;&#27880;&#20110;&#26356;&#22522;&#30784;&#21644;&#21019;&#36896;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#12290;&#36825;&#19968;&#37325;&#22823;&#36827;&#23637;&#23558;&#35745;&#31639;&#25216;&#26415;&#19982;&#21270;&#23398;&#31038;&#20250;&#26356;&#32039;&#23494;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent artificial intelligence (AI) research plots a promising future of automatic chemical reactions within the chemistry society. This study presents a transformative AI agent that automates the reaction condition recommendation (RCR) task in chemistry using retrieval-augmented generation (RAG) technology. By emulating expert chemists search and analysis strategies, the agent employs large language models (LLMs) to interrogate molecular databases and distill critical data from online literature. Further, the AI agent is equipped with our novel reaction fingerprint developed for the RCR task. Thanks to the RAG technology, our agent uses updated online databases as knowledge sources, significantly outperforming conventional AIs confined to the fixed knowledge within its training data. The resulting system can significantly reduce chemists workload, allowing them to focus on more fundamental and creative scientific problems. This significant advancement brings closer computational techn
&lt;/p&gt;</description></item><item><title>LLMRec&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#32570;&#24615;&#21644;&#38468;&#21152;&#20449;&#24687;&#24341;&#20837;&#21103;&#20316;&#29992;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#24378;&#20132;&#20114;&#36793;&#12289;&#22686;&#24378;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#29702;&#35299;&#21644;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.00423</link><description>&lt;p&gt;
LLMRec: &#20351;&#29992;&#22270;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
LLMRec: Large Language Models with Graph Augmentation for Recommendation. (arXiv:2311.00423v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00423
&lt;/p&gt;
&lt;p&gt;
LLMRec&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25968;&#25454;&#31232;&#32570;&#24615;&#21644;&#38468;&#21152;&#20449;&#24687;&#24341;&#20837;&#21103;&#20316;&#29992;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#24378;&#20132;&#20114;&#36793;&#12289;&#22686;&#24378;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#29702;&#35299;&#21644;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#26469;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31232;&#30095;&#24615;&#19968;&#30452;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#65292;&#20043;&#21069;&#30340;&#30740;&#31350;&#23581;&#35797;&#36890;&#36807;&#24341;&#20837;&#38468;&#21152;&#20449;&#24687;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24448;&#24448;&#20250;&#24102;&#26469;&#22122;&#22768;&#12289;&#21487;&#29992;&#24615;&#38382;&#39064;&#21644;&#25968;&#25454;&#36136;&#37327;&#20302;&#19979;&#31561;&#21103;&#20316;&#29992;&#65292;&#20174;&#32780;&#24433;&#21709;&#23545;&#29992;&#25143;&#20559;&#22909;&#30340;&#20934;&#30830;&#24314;&#27169;&#65292;&#36827;&#32780;&#23545;&#25512;&#33616;&#24615;&#33021;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#37492;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#30693;&#35782;&#24211;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LLMRec&#30340;&#26032;&#26694;&#26550;&#65292;&#23427;&#36890;&#36807;&#37319;&#29992;&#19977;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22522;&#20110;LLM&#30340;&#22270;&#22686;&#24378;&#31574;&#30053;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22312;&#32447;&#24179;&#21488;&#65288;&#22914;Netflix&#65292;MovieLens&#65289;&#20013;&#20016;&#23500;&#30340;&#20869;&#23481;&#65292;&#22312;&#19977;&#20010;&#26041;&#38754;&#22686;&#24378;&#20132;&#20114;&#22270;&#65306;&#65288;i&#65289;&#21152;&#24378;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#36793;&#65292;&#65288;ii&#65289;&#22686;&#24378;&#23545;&#29289;&#21697;&#33410;&#28857;&#23646;&#24615;&#30340;&#29702;&#35299;&#65292;&#65288;iii&#65289;&#36827;&#34892;&#29992;&#25143;&#33410;&#28857;&#24314;&#27169;&#65292;&#30452;&#35266;&#22320;&#34920;&#31034;&#29992;&#25143;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies. Our approach leverages the rich content available within online platforms (e.g., Netflix, MovieLens) to augment the interaction graph in three ways: (i) reinforcing user-item interaction egde, (ii) enhancing the understanding of item node attributes, and (iii) conducting user node profiling, intuiti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#33539;&#24335;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#21487;&#33021;&#24615;&#21644;&#25361;&#25112;&#65292;&#25552;&#20986;&#24320;&#21457;&#19968;&#31181;&#36890;&#29992;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#29992;&#20110;&#23569;&#26679;&#26412;&#23398;&#20064;&#65292;&#24182;&#22312;&#26410;&#30693;&#26032;&#39046;&#22495;&#20013;&#24555;&#36895;&#36866;&#24212;&#65292;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.19251</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;&#25512;&#33616;&#31995;&#32479;&#65306;&#19968;&#31181;&#22240;&#26524;&#21435;&#20559;&#35265;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Pre-trained Recommender Systems: A Causal Debiasing Perspective. (arXiv:2310.19251v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#33539;&#24335;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#21487;&#33021;&#24615;&#21644;&#25361;&#25112;&#65292;&#25552;&#20986;&#24320;&#21457;&#19968;&#31181;&#36890;&#29992;&#25512;&#33616;&#31995;&#32479;&#65292;&#21487;&#20197;&#29992;&#20110;&#23569;&#26679;&#26412;&#23398;&#20064;&#65292;&#24182;&#22312;&#26410;&#30693;&#26032;&#39046;&#22495;&#20013;&#24555;&#36895;&#36866;&#24212;&#65292;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#20110;&#39044;&#35757;&#32451;&#30340;&#35270;&#35273;/&#35821;&#35328;&#27169;&#22411;&#30340;&#30740;&#31350;&#34920;&#26126;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#26377;&#21069;&#26223;&#30340;&#35299;&#20915;&#26041;&#26696;&#24314;&#31435;&#33539;&#24335;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#20854;&#20013;&#27169;&#22411;&#21487;&#20197;&#22312;&#24191;&#27867;&#25551;&#36848;&#36890;&#29992;&#20219;&#21153;&#31354;&#38388;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#25104;&#21151;&#22320;&#36866;&#24212;&#35299;&#20915;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#21363;&#20351;&#35757;&#32451;&#25968;&#25454;&#38750;&#24120;&#26377;&#38480;&#65288;&#22914;&#22312;&#38646;&#26679;&#26412;&#23398;&#20064;&#25110;&#23569;&#26679;&#26412;&#23398;&#20064;&#22330;&#26223;&#20013;&#65289;&#12290;&#21463;&#21040;&#36825;&#26679;&#30340;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#30740;&#31350;&#20102;&#23558;&#36825;&#31181;&#33539;&#24335;&#35843;&#25972;&#21040;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#30340;&#21487;&#33021;&#24615;&#21644;&#25361;&#25112;&#65292;&#36825;&#19968;&#39046;&#22495;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#35270;&#35282;&#19979;&#36739;&#23569;&#34987;&#35843;&#26597;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#25552;&#20986;&#24320;&#21457;&#19968;&#31181;&#36890;&#29992;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#23545;&#20174;&#19981;&#21516;&#39046;&#22495;&#20013;&#25552;&#21462;&#30340;&#36890;&#29992;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#25429;&#25417;&#21040;&#36890;&#29992;&#30340;&#20132;&#20114;&#27169;&#24335;&#65292;&#28982;&#21518;&#21487;&#20197;&#24555;&#36895;&#36866;&#24212;&#25552;&#21319;&#23569;&#26679;&#26412;&#23398;&#20064;&#24615;&#33021;&#65292;&#22312;&#26410;&#30693;&#26032;&#39046;&#22495;&#65288;&#25968;&#25454;&#26377;&#38480;&#65289;&#20013;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies on pre-trained vision/language models have demonstrated the practical benefit of a new, promising solution-building paradigm in AI where models can be pre-trained on broad data describing a generic task space and then adapted successfully to solve a wide range of downstream tasks, even when training data is severely limited (e.g., in zero- or few-shot learning scenarios). Inspired by such progress, we investigate in this paper the possibilities and challenges of adapting such a paradigm to the context of recommender systems, which is less investigated from the perspective of pre-trained model. In particular, we propose to develop a generic recommender that captures universal interaction patterns by training on generic user-item interaction data extracted from different domains, which can then be fast adapted to improve few-shot learning performance in unseen new domains (with limited data).  However, unlike vision/language data which share strong conformity in the semant
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;STEM&#30340;&#26032;&#33539;&#20363;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#20219;&#21153;&#25512;&#33616;&#20013;&#30340;&#36127;&#20256;&#36882;&#38382;&#39064;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;STEM&#36890;&#36807;&#26681;&#25454;&#26679;&#26412;&#20013;&#27491;&#21453;&#39304;&#25968;&#37327;&#30340;&#30456;&#23545;&#27604;&#20363;&#36827;&#34892;&#32454;&#20998;&#65292;&#28145;&#20837;&#30740;&#31350;&#26679;&#26412;&#30340;&#22797;&#26434;&#24615;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.13537</link><description>&lt;p&gt;
STEM:&#37322;&#25918;Embedding&#22312;&#22810;&#20219;&#21153;&#25512;&#33616;&#20013;&#30340;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
STEM: Unleashing the Power of Embeddings for Multi-task Recommendation. (arXiv:2308.13537v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13537
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;STEM&#30340;&#26032;&#33539;&#20363;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#20219;&#21153;&#25512;&#33616;&#20013;&#30340;&#36127;&#20256;&#36882;&#38382;&#39064;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;STEM&#36890;&#36807;&#26681;&#25454;&#26679;&#26412;&#20013;&#27491;&#21453;&#39304;&#25968;&#37327;&#30340;&#30456;&#23545;&#27604;&#20363;&#36827;&#34892;&#32454;&#20998;&#65292;&#28145;&#20837;&#30740;&#31350;&#26679;&#26412;&#30340;&#22797;&#26434;&#24615;&#65292;&#20197;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#21516;&#26102;&#20248;&#21270;&#22810;&#20010;&#30446;&#26631;&#12290;MTL&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#36127;&#20256;&#36882;&#30340;&#21457;&#29983;&#65292;&#21363;&#30001;&#20110;&#20219;&#21153;&#20043;&#38388;&#30340;&#20914;&#31361;&#23548;&#33268;&#26576;&#20123;&#20219;&#21153;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#29616;&#26377;&#30740;&#31350;&#36890;&#36807;&#23558;&#25152;&#26377;&#26679;&#26412;&#35270;&#20026;&#19968;&#20010;&#25972;&#20307;&#26469;&#25506;&#32034;&#36127;&#20256;&#36882;&#65292;&#24573;&#35270;&#20102;&#20854;&#20013;&#22266;&#26377;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#26681;&#25454;&#20219;&#21153;&#20043;&#38388;&#27491;&#21453;&#39304;&#30340;&#30456;&#23545;&#25968;&#37327;&#23558;&#26679;&#26412;&#36827;&#34892;&#32454;&#20998;&#65292;&#28145;&#20837;&#30740;&#31350;&#26679;&#26412;&#30340;&#22797;&#26434;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#29616;&#26377;MTL&#26041;&#27861;&#22312;&#25910;&#21040;&#21508;&#20219;&#21153;&#31867;&#20284;&#21453;&#39304;&#30340;&#26679;&#26412;&#19978;&#20173;&#28982;&#23384;&#22312;&#36127;&#20256;&#36882;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#37319;&#29992;&#20849;&#20139;&#23884;&#20837;&#30340;&#33539;&#20363;&#65292;&#24182;&#19988;&#25105;&#20204;&#20551;&#35774;&#23427;&#20204;&#30340;&#22833;&#36133;&#21487;&#20197;&#24402;&#22240;&#20110;&#20351;&#29992;&#36825;&#31181;&#36890;&#29992;&#23884;&#20837;&#26469;&#24314;&#27169;&#19981;&#21516;&#29992;&#25143;&#20559;&#22909;&#30340;&#26377;&#38480;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning (MTL) has gained significant popularity in recommendation systems as it enables the simultaneous optimization of multiple objectives. A key challenge in MTL is the occurrence of negative transfer, where the performance of certain tasks deteriorates due to conflicts between tasks. Existing research has explored negative transfer by treating all samples as a whole, overlooking the inherent complexities within them. To this end, we delve into the intricacies of samples by splitting them based on the relative amount of positive feedback among tasks. Surprisingly, negative transfer still occurs in existing MTL methods on samples that receive comparable feedback across tasks. It is worth noting that existing methods commonly employ a shared-embedding paradigm, and we hypothesize that their failure can be attributed to the limited capacity of modeling diverse user preferences across tasks using such universal embeddings.  In this paper, we introduce a novel paradigm called
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#31639;&#27861;&#65292;&#29992;&#20110;&#31934;&#30830;&#27979;&#37327;&#24046;&#20998;&#38544;&#31169;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#36890;&#36807;&#31163;&#32447;&#23454;&#39564;&#65292;&#35813;&#31639;&#27861;&#22312;&#20851;&#38190;&#25351;&#26631;&#19978;&#19982;&#31169;&#23494;&#30340;&#38750;&#20010;&#24615;&#21270;&#21644;&#38750;&#31169;&#23494;&#30340;&#20010;&#24615;&#21270;&#23454;&#29616;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2308.03735</link><description>&lt;p&gt;
&#38543;&#26426;&#31639;&#27861;&#29992;&#20110;&#31934;&#30830;&#27979;&#37327;&#24046;&#20998;&#38544;&#31169;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Randomized algorithms for precise measurement of differentially-private, personalized recommendations. (arXiv:2308.03735v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03735
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#31639;&#27861;&#65292;&#29992;&#20110;&#31934;&#30830;&#27979;&#37327;&#24046;&#20998;&#38544;&#31169;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#36890;&#36807;&#31163;&#32447;&#23454;&#39564;&#65292;&#35813;&#31639;&#27861;&#22312;&#20851;&#38190;&#25351;&#26631;&#19978;&#19982;&#31169;&#23494;&#30340;&#38750;&#20010;&#24615;&#21270;&#21644;&#38750;&#31169;&#23494;&#30340;&#20010;&#24615;&#21270;&#23454;&#29616;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#25512;&#33616;&#26159;&#24403;&#20170;&#20114;&#32852;&#32593;&#29983;&#24577;&#31995;&#32479;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#23427;&#24110;&#21161;&#33402;&#26415;&#23478;&#21644;&#21019;&#20316;&#32773;&#21560;&#24341;&#24863;&#20852;&#36259;&#30340;&#29992;&#25143;&#65292;&#21516;&#26102;&#20063;&#24110;&#21161;&#29992;&#25143;&#21457;&#29616;&#26032;&#30340;&#26377;&#36259;&#20869;&#23481;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20010;&#20154;&#25968;&#25454;&#21644;&#25968;&#25454;&#38544;&#31169;&#30340;&#21382;&#21490;&#19978;&#31895;&#24515;&#23545;&#24453;&#65292;&#35768;&#22810;&#29992;&#25143;&#23545;&#20010;&#24615;&#21270;&#25512;&#33616;&#24179;&#21488;&#25345;&#24576;&#30097;&#24577;&#24230;&#12290;&#29616;&#22312;&#65292;&#20381;&#36182;&#20110;&#20010;&#24615;&#21270;&#25512;&#33616;&#30340;&#20225;&#19994;&#27491;&#36827;&#20837;&#19968;&#20010;&#26032;&#30340;&#33539;&#20363;&#65292;&#38656;&#35201;&#23545;&#20182;&#20204;&#30340;&#31995;&#32479;&#36827;&#34892;&#25913;&#36827;&#65292;&#20197;&#20445;&#25252;&#38544;&#31169;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#25512;&#33616;&#31639;&#27861;&#65292;&#26082;&#21487;&#20197;&#23454;&#29616;&#31934;&#30830;&#27979;&#37327;&#65292;&#21448;&#21487;&#20197;&#20445;&#25252;&#24046;&#20998;&#38544;&#31169;&#12290;&#25105;&#20204;&#20197;&#24191;&#21578;&#20026;&#20363;&#24212;&#29992;&#65292;&#24182;&#36827;&#34892;&#31163;&#32447;&#23454;&#39564;&#65292;&#37327;&#21270;&#25552;&#20986;&#30340;&#38544;&#31169;&#20445;&#25252;&#31639;&#27861;&#23545;&#29992;&#25143;&#20307;&#39564;&#12289;&#24191;&#21578;&#21830;&#20215;&#20540;&#21644;&#24179;&#21488;&#25910;&#20837;&#31561;&#20851;&#38190;&#25351;&#26631;&#30340;&#24433;&#21709;&#65292;&#19982;&#65288;&#31169;&#23494;&#30340;&#65289;&#38750;&#20010;&#24615;&#21270;&#21644;&#38750;&#31169;&#23494;&#30340;&#20010;&#24615;&#21270;&#23454;&#29616;&#30340;&#26497;&#31471;&#24773;&#20917;&#36827;&#34892;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized recommendations form an important part of today's internet ecosystem, helping artists and creators to reach interested users, and helping users to discover new and engaging content. However, many users today are skeptical of platforms that personalize recommendations, in part due to historically careless treatment of personal data and data privacy. Now, businesses that rely on personalized recommendations are entering a new paradigm, where many of their systems must be overhauled to be privacy-first. In this article, we propose an algorithm for personalized recommendations that facilitates both precise and differentially-private measurement. We consider advertising as an example application, and conduct offline experiments to quantify how the proposed privacy-preserving algorithm affects key metrics related to user experience, advertiser value, and platform revenue compared to the extremes of both (private) non-personalized and non-private, personalized implementations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20351;&#20915;&#31574;&#32773;&#21487;&#20197;&#34920;&#36798;&#24179;&#21488;&#34892;&#20026;&#30340;&#38271;&#26399;&#30446;&#26631;&#65292;&#24182;&#36890;&#36807;&#26032;&#30340;&#22522;&#20110;&#25511;&#21046;&#30340;&#31639;&#27861;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#23545;&#30701;&#26399;&#21442;&#19982;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.04923</link><description>&lt;p&gt;
&#24102;&#26377;&#38271;&#26399;&#32422;&#26463;&#30340;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Ranking with Long-Term Constraints. (arXiv:2307.04923v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04923
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20351;&#20915;&#31574;&#32773;&#21487;&#20197;&#34920;&#36798;&#24179;&#21488;&#34892;&#20026;&#30340;&#38271;&#26399;&#30446;&#26631;&#65292;&#24182;&#36890;&#36807;&#26032;&#30340;&#22522;&#20110;&#25511;&#21046;&#30340;&#31639;&#27861;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#23545;&#30701;&#26399;&#21442;&#19982;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#36890;&#36807;&#20182;&#20204;&#30340;&#36873;&#25321;&#21453;&#39304;&#65288;&#20363;&#22914;&#28857;&#20987;&#65292;&#36141;&#20080;&#65289;&#26159;&#20026;&#35757;&#32451;&#25628;&#32034;&#21644;&#25512;&#33616;&#31639;&#27861;&#25552;&#20379;&#30340;&#26368;&#24120;&#35265;&#31867;&#22411;&#30340;&#25968;&#25454;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#20165;&#22522;&#20110;&#36873;&#25321;&#25968;&#25454;&#36827;&#34892;&#30701;&#35270;&#22521;&#35757;&#30340;&#31995;&#32479;&#21487;&#33021;&#20165;&#25913;&#21892;&#30701;&#26399;&#21442;&#19982;&#24230;&#65292;&#32780;&#19981;&#33021;&#25913;&#21892;&#24179;&#21488;&#30340;&#38271;&#26399;&#21487;&#25345;&#32493;&#24615;&#20197;&#21450;&#23545;&#29992;&#25143;&#12289;&#20869;&#23481;&#25552;&#20379;&#32773;&#21644;&#20854;&#20182;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#38271;&#26399;&#21033;&#30410;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#20915;&#31574;&#32773;&#65288;&#20363;&#22914;&#24179;&#21488;&#36816;&#33829;&#21830;&#12289;&#30417;&#31649;&#26426;&#26500;&#12289;&#29992;&#25143;&#65289;&#21487;&#20197;&#34920;&#36798;&#24179;&#21488;&#34892;&#20026;&#30340;&#38271;&#26399;&#30446;&#26631;&#65288;&#20363;&#22914;&#20844;&#24179;&#24615;&#12289;&#25910;&#20837;&#20998;&#37197;&#12289;&#27861;&#24459;&#35201;&#27714;&#65289;&#12290;&#36825;&#20123;&#30446;&#26631;&#37319;&#21462;&#20102;&#36229;&#36234;&#20010;&#20307;&#20250;&#35805;&#30340;&#26333;&#20809;&#25110;&#24433;&#21709;&#30446;&#26631;&#30340;&#24418;&#24335;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#22522;&#20110;&#25511;&#21046;&#30340;&#31639;&#27861;&#26469;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25511;&#21046;&#22120;&#30340;&#35774;&#35745;&#26088;&#22312;&#20197;&#26368;&#23567;&#21270;&#23545;&#30701;&#26399;&#21442;&#19982;&#30340;&#24433;&#21709;&#26469;&#23454;&#29616;&#25152;&#36848;&#30340;&#38271;&#26399;&#30446;&#26631;&#12290;&#38500;&#20102;&#21407;&#21017;&#24615;&#30340;&#29702;&#35770;&#25512;&#23548;&#22806;&#65292;
&lt;/p&gt;
&lt;p&gt;
The feedback that users provide through their choices (e.g., clicks, purchases) is one of the most common types of data readily available for training search and recommendation algorithms. However, myopically training systems based on choice data may only improve short-term engagement, but not the long-term sustainability of the platform and the long-term benefits to its users, content providers, and other stakeholders. In this paper, we thus develop a new framework in which decision makers (e.g., platform operators, regulators, users) can express long-term goals for the behavior of the platform (e.g., fairness, revenue distribution, legal requirements). These goals take the form of exposure or impact targets that go well beyond individual sessions, and we provide new control-based algorithms to achieve these goals. In particular, the controllers are designed to achieve the stated long-term goals with minimum impact on short-term engagement. Beyond the principled theoretical derivation
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#65292;&#23558;&#20174;&#29992;&#25143;-&#21830;&#21697;&#20132;&#20114;&#20013;&#23398;&#24471;&#30340;&#20960;&#20309;&#20808;&#39564;&#30693;&#35782;&#19982;&#21464;&#20998;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20026;&#29992;&#25143;&#25552;&#20379;&#26082;&#20855;&#22791;&#25512;&#33616;&#24615;&#33021;&#21448;&#20855;&#26377;&#35299;&#37322;&#24615;&#33021;&#30340;&#35299;&#37322;&#25512;&#33616;&#26381;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.05331</link><description>&lt;p&gt;
&#20855;&#26377;&#20960;&#20309;&#20449;&#24687;&#29942;&#39048;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Explainable Recommender with Geometric Information Bottleneck. (arXiv:2305.05331v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05331
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#65292;&#23558;&#20174;&#29992;&#25143;-&#21830;&#21697;&#20132;&#20114;&#20013;&#23398;&#24471;&#30340;&#20960;&#20309;&#20808;&#39564;&#30693;&#35782;&#19982;&#21464;&#20998;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20026;&#29992;&#25143;&#25552;&#20379;&#26082;&#20855;&#22791;&#25512;&#33616;&#24615;&#33021;&#21448;&#20855;&#26377;&#35299;&#37322;&#24615;&#33021;&#30340;&#35299;&#37322;&#25512;&#33616;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#33021;&#22815;&#35299;&#37322;&#20854;&#25512;&#33616;&#20915;&#31574;&#65292;&#22686;&#24378;&#29992;&#25143;&#23545;&#31995;&#32479;&#30340;&#20449;&#20219;&#12290;&#22823;&#22810;&#25968;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#31995;&#32479;&#35201;&#20040;&#20381;&#36182;&#20110;&#20154;&#24037;&#26631;&#27880;&#30340;&#21407;&#29702;&#26469;&#35757;&#32451;&#27169;&#22411;&#20197;&#29983;&#25104;&#35299;&#37322;&#65292;&#35201;&#20040;&#21033;&#29992;&#27880;&#24847;&#26426;&#21046;&#20174;&#35780;&#35770;&#20013;&#25552;&#21462;&#37325;&#35201;&#30340;&#25991;&#26412;&#27573;&#33853;&#20316;&#20026;&#35299;&#37322;&#12290;&#25552;&#21462;&#30340;&#21407;&#29702;&#24448;&#24448;&#23616;&#38480;&#20110;&#21333;&#20010;&#35780;&#35770;&#65292;&#21487;&#33021;&#26080;&#27861;&#35782;&#21035;&#35780;&#35770;&#25991;&#26412;&#20043;&#22806;&#30340;&#38544;&#21547;&#29305;&#24449;&#12290;&#20026;&#20102;&#36991;&#20813;&#26114;&#36149;&#30340;&#20154;&#24037;&#27880;&#37322;&#36807;&#31243;&#24182;&#29983;&#25104;&#36229;&#20986;&#21333;&#20010;&#35780;&#35770;&#30340;&#35299;&#37322;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#20174;&#29992;&#25143;-&#21830;&#21697;&#20132;&#20114;&#20013;&#23398;&#24471;&#30340;&#20960;&#20309;&#20808;&#39564;&#30693;&#35782;&#19982;&#21464;&#20998;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#35813;&#32593;&#32476;&#20174;&#29992;&#25143;-&#21830;&#21697;&#35780;&#35770;&#20013;&#25512;&#26029;&#28508;&#22312;&#22240;&#23376;&#12290;&#21333;&#20010;&#29992;&#25143;-&#21830;&#21697;&#23545;&#30340;&#28508;&#22312;&#22240;&#23376;&#21487;&#29992;&#20110;&#25512;&#33616;&#21644;&#35299;&#37322;&#29983;&#25104;&#65292;&#33258;&#28982;&#22320;&#32487;&#25215;&#20102;&#32534;&#30721;&#22312;&#20808;&#39564;&#30693;&#35782;&#20013;&#30340;&#20840;&#23616;&#29305;&#24449;&#12290;&#19977;&#20010;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#25512;&#33616;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#37117;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable recommender systems can explain their recommendation decisions, enhancing user trust in the systems. Most explainable recommender systems either rely on human-annotated rationales to train models for explanation generation or leverage the attention mechanism to extract important text spans from reviews as explanations. The extracted rationales are often confined to an individual review and may fail to identify the implicit features beyond the review text. To avoid the expensive human annotation process and to generate explanations beyond individual reviews, we propose to incorporate a geometric prior learnt from user-item interactions into a variational network which infers latent factors from user-item reviews. The latent factors from an individual user-item pair can be used for both recommendation and explanation generation, which naturally inherit the global characteristics encoded in the prior knowledge. Experimental results on three e-commerce datasets show that our mo
&lt;/p&gt;</description></item></channel></rss>