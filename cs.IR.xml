<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25506;&#32034;&#21644;&#20998;&#20139;&#20851;&#20110;&#21435;&#20013;&#24515;&#21270;&#32593;&#32476;&#26381;&#21153;&#30340;&#21019;&#26032;&#24819;&#27861;&#65292;&#20027;&#35201;&#20851;&#27880;&#21435;&#20013;&#24515;&#21270;&#31995;&#32479;&#23545;&#31038;&#20250;&#30340;&#24433;&#21709;&#12289;&#31639;&#27861;&#21644;&#24615;&#33021;&#25361;&#25112;&#65292;&#20197;&#21450;&#25903;&#25345;&#21435;&#20013;&#24515;&#21270;&#31995;&#32479;&#21644;&#26381;&#21153;&#30340;&#22522;&#30784;&#35774;&#26045;&#12290;</title><link>https://arxiv.org/abs/2403.07732</link><description>&lt;p&gt;
DESERE&#65306;&#31532;&#19968;&#23626;&#21435;&#20013;&#24515;&#21270;&#25628;&#32034;&#21644;&#25512;&#33616;&#30740;&#35752;&#20250;
&lt;/p&gt;
&lt;p&gt;
DESERE: The 1st Workshop on Decentralised Search and Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07732
&lt;/p&gt;
&lt;p&gt;
&#25506;&#32034;&#21644;&#20998;&#20139;&#20851;&#20110;&#21435;&#20013;&#24515;&#21270;&#32593;&#32476;&#26381;&#21153;&#30340;&#21019;&#26032;&#24819;&#27861;&#65292;&#20027;&#35201;&#20851;&#27880;&#21435;&#20013;&#24515;&#21270;&#31995;&#32479;&#23545;&#31038;&#20250;&#30340;&#24433;&#21709;&#12289;&#31639;&#27861;&#21644;&#24615;&#33021;&#25361;&#25112;&#65292;&#20197;&#21450;&#25903;&#25345;&#21435;&#20013;&#24515;&#21270;&#31995;&#32479;&#21644;&#26381;&#21153;&#30340;&#22522;&#30784;&#35774;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07732v1 &#22768;&#26126;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;DESERE&#30740;&#35752;&#20250;&#65292;&#25105;&#20204;&#30340;&#31532;&#19968;&#23626;&#21435;&#20013;&#24515;&#21270;&#25628;&#32034;&#21644;&#25512;&#33616;&#30740;&#35752;&#20250;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#19968;&#20010;&#25506;&#35752;&#21644;&#20998;&#20139;&#20851;&#20110;&#21435;&#20013;&#24515;&#21270;&#32593;&#32476;&#26381;&#21153;&#30340;&#21019;&#26032;&#24819;&#27861;&#30340;&#24179;&#21488;&#65292;&#20027;&#35201;&#20851;&#27880;&#19977;&#20010;&#20027;&#39064;&#65306;&#65288;i&#65289;&#21435;&#20013;&#24515;&#21270;&#31995;&#32479;&#23545;&#31038;&#20250;&#30340;&#24433;&#21709;&#65306;&#23427;&#20204;&#23545;&#38544;&#31169;&#12289;&#25919;&#31574;&#21644;&#30417;&#31649;&#30340;&#24433;&#21709;&#65307;&#65288;ii&#65289;&#21435;&#20013;&#24515;&#21270;&#24212;&#29992;&#31243;&#24207;&#65306;&#30001;&#21435;&#20013;&#24515;&#21270;&#24102;&#26469;&#30340;&#31639;&#27861;&#21644;&#24615;&#33021;&#25361;&#25112;&#65307;&#21644;&#65288;iii&#65289;&#25903;&#25345;&#21435;&#20013;&#24515;&#21270;&#31995;&#32479;&#21644;&#26381;&#21153;&#30340;&#22522;&#30784;&#35774;&#26045;&#65306;&#28857;&#23545;&#28857;&#32593;&#32476;&#12289;&#36335;&#30001;&#21644;&#24615;&#33021;&#35780;&#20272;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07732v1 Announce Type: new  Abstract: The DESERE Workshop, our First Workshop on Decentralised Search and Recommendation, offers a platform for researchers to explore and share innovative ideas on decentralised web services, mainly focusing on three major topics: (i) societal impact of decentralised systems: their effect on privacy, policy, and regulation; (ii) decentralising applications: algorithmic and performance challenges that arise from decentralisation; and (iii) infrastructure to support decentralised systems and services: peer-to-peer networks, routing, and performance evaluation tools
&lt;/p&gt;</description></item><item><title>&#23545;&#29616;&#20195;&#24207;&#21015;&#21040;&#24207;&#21015;&#30456;&#20851;&#24615;&#27169;&#22411;&#36827;&#34892;&#20102;&#23545;&#25239;&#25915;&#20987;&#20998;&#26512;&#65292;&#21457;&#29616;&#24694;&#24847;&#25991;&#26723;&#21487;&#20197;&#36890;&#36807;&#27880;&#20837;&#25552;&#31034;&#26469;&#25805;&#32437;&#20854;&#30456;&#20851;&#24615;&#24471;&#20998;&#65292;&#36825;&#19968;&#25915;&#20987;&#26426;&#21046;&#24433;&#21709;&#20102;&#19981;&#21516;&#30456;&#20851;&#24615;&#27169;&#22411;&#65292;&#20294;&#35789;&#27719;&#27169;&#22411;BM25&#19981;&#21463;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.07654</link><description>&lt;p&gt;
&#20998;&#26512;&#24207;&#21015;&#21040;&#24207;&#21015;&#30456;&#20851;&#24615;&#27169;&#22411;&#19978;&#30340;&#23545;&#25239;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Analyzing Adversarial Attacks on Sequence-to-Sequence Relevance Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07654
&lt;/p&gt;
&lt;p&gt;
&#23545;&#29616;&#20195;&#24207;&#21015;&#21040;&#24207;&#21015;&#30456;&#20851;&#24615;&#27169;&#22411;&#36827;&#34892;&#20102;&#23545;&#25239;&#25915;&#20987;&#20998;&#26512;&#65292;&#21457;&#29616;&#24694;&#24847;&#25991;&#26723;&#21487;&#20197;&#36890;&#36807;&#27880;&#20837;&#25552;&#31034;&#26469;&#25805;&#32437;&#20854;&#30456;&#20851;&#24615;&#24471;&#20998;&#65292;&#36825;&#19968;&#25915;&#20987;&#26426;&#21046;&#24433;&#21709;&#20102;&#19981;&#21516;&#30456;&#20851;&#24615;&#27169;&#22411;&#65292;&#20294;&#35789;&#27719;&#27169;&#22411;BM25&#19981;&#21463;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#24207;&#21015;&#21040;&#24207;&#21015;&#30456;&#20851;&#24615;&#27169;&#22411;&#65288;&#22914;monoT5&#65289;&#33021;&#22815;&#36890;&#36807;&#20132;&#21449;&#32534;&#30721;&#26377;&#25928;&#25429;&#25417;&#26597;&#35810;&#21644;&#25991;&#26723;&#20043;&#38388;&#30340;&#22797;&#26434;&#25991;&#26412;&#20132;&#20114;&#12290;&#28982;&#32780;&#65292;&#22312;&#25552;&#31034;&#20013;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#26631;&#35760;&#65292;&#22914;Query&#12289;Document&#21644;Relevant&#23545;&#20110;monoT5&#32780;&#35328;&#65292;&#20026;&#24694;&#24847;&#25991;&#26723;&#24320;&#36767;&#20102;&#27880;&#20837;&#25915;&#20987;&#21521;&#37327;&#65292;&#36890;&#36807;&#27880;&#20837;&#25552;&#31034;&#65288;&#20363;&#22914;&#28155;&#21152;true&#31561;&#30446;&#26631;&#35789;&#65289;&#26469;&#25805;&#32437;&#20854;&#30456;&#20851;&#24615;&#24471;&#20998;&#12290;&#30001;&#20110;&#26816;&#32034;&#35780;&#20272;&#20013;&#23578;&#26410;&#32771;&#34385;&#36825;&#26679;&#30340;&#21487;&#33021;&#24615;&#65292;&#25105;&#20204;&#36890;&#36807;&#25163;&#21160;&#26500;&#24314;&#30340;&#27169;&#26495;&#21644;&#22522;&#20110;LLM&#30340;&#25991;&#26723;&#37325;&#20889;&#65292;&#20998;&#26512;&#20102;&#26597;&#35810;&#26080;&#20851;&#25552;&#31034;&#27880;&#20837;&#23545;&#22810;&#20010;&#29616;&#26377;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;TREC&#28145;&#24230;&#23398;&#20064;&#36319;&#36394;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#23545;&#25239;&#24615;&#25991;&#26723;&#21487;&#20197;&#36731;&#26494;&#25805;&#32437;&#19981;&#21516;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#30456;&#20851;&#24615;&#27169;&#22411;&#65292;&#32780;BM25&#65288;&#20316;&#20026;&#20856;&#22411;&#30340;&#35789;&#27719;&#27169;&#22411;&#65289;&#19981;&#21463;&#24433;&#21709;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#25915;&#20987;&#20063;&#24433;&#21709;&#20165;&#32534;&#30721;&#22120;&#30456;&#20851;&#24615;&#27169;&#22411;&#65288;&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07654v1 Announce Type: new  Abstract: Modern sequence-to-sequence relevance models like monoT5 can effectively capture complex textual interactions between queries and documents through cross-encoding. However, the use of natural language tokens in prompts, such as Query, Document, and Relevant for monoT5, opens an attack vector for malicious documents to manipulate their relevance score through prompt injection, e.g., by adding target words such as true. Since such possibilities have not yet been considered in retrieval evaluation, we analyze the impact of query-independent prompt injection via manually constructed templates and LLM-based rewriting of documents on several existing relevance models. Our experiments on the TREC Deep Learning track show that adversarial documents can easily manipulate different sequence-to-sequence relevance models, while BM25 (as a typical lexical model) is not affected. Remarkably, the attacks also affect encoder-only relevance models (which
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#20004;&#27969;&#26550;&#26500;TSSR&#65292;&#26088;&#22312;&#36890;&#36807;&#26377;&#25928;&#22320;&#23558;&#21327;&#20316;&#20449;&#21495;&#21644;&#35821;&#20041;&#30456;&#20851;&#24615;&#32467;&#21512;&#36215;&#26469;&#65292;&#22686;&#24378;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2403.07623</link><description>&lt;p&gt;
&#20174;&#21327;&#20316;&#20449;&#21495;&#21644;&#35821;&#20041;&#30456;&#20851;&#24615;&#20013;&#22686;&#24378;&#39034;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Empowering Sequential Recommendation from Collaborative Signals and Semantic Relatedness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07623
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#20004;&#27969;&#26550;&#26500;TSSR&#65292;&#26088;&#22312;&#36890;&#36807;&#26377;&#25928;&#22320;&#23558;&#21327;&#20316;&#20449;&#21495;&#21644;&#35821;&#20041;&#30456;&#20851;&#24615;&#32467;&#21512;&#36215;&#26469;&#65292;&#22686;&#24378;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;(SRS)&#36890;&#36807;&#23545;&#25353;&#26102;&#38388;&#39034;&#24207;&#25490;&#21015;&#30340;&#21382;&#21490;&#34892;&#20026;&#36827;&#34892;&#24314;&#27169;&#65292;&#33021;&#22815;&#25429;&#25417;&#21040;&#21160;&#24577;&#29992;&#25143;&#20559;&#22909;&#12290;&#23613;&#31649;&#26377;&#25928;&#65292;&#20165;&#20851;&#27880;&#34892;&#20026;&#20013;&#30340;\textit{&#21327;&#20316;&#20449;&#21495;}&#24182;&#19981;&#33021;&#20805;&#20998;&#25226;&#25569;&#29992;&#25143;&#20852;&#36259;&#12290;&#22312;&#20869;&#23481;&#29305;&#24449;&#20013;&#21453;&#26144;&#30340;\textit{&#35821;&#20041;&#30456;&#20851;&#24615;}&#24314;&#27169;&#20063;&#26159;&#37325;&#35201;&#30340;&#65292;&#20363;&#22914;&#22270;&#29255;&#21644;&#25991;&#26412;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#26377;&#25928;&#22320;&#23558;&#21327;&#20316;&#20449;&#21495;&#21644;&#35821;&#20041;&#30456;&#20851;&#24615;&#32467;&#21512;&#36215;&#26469;&#65292;&#22686;&#24378;SRS&#20219;&#21153;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#23454;&#35777;&#25351;&#20986;&#30001;&#20110;&#35821;&#20041;&#40511;&#27807;&#38382;&#39064;&#65292;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#24182;&#19981;&#23481;&#26131;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#30340;&#31471;&#21040;&#31471;&#20004;&#27969;&#26550;&#26500;&#65292;&#21629;&#21517;&#20026;TSSR&#65292;&#20174;&#22522;&#20110;ID&#21644;&#22522;&#20110;&#20869;&#23481;&#30340;&#24207;&#21015;&#20013;&#23398;&#20064;&#29992;&#25143;&#20559;&#22909;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#23618;&#27425;&#23545;&#27604;&#27169;&#22359;&#65292;&#21253;&#25324;&#31895;&#29992;&#25143;&#31890;&#24230;&#21644;&#32454;&#39033;&#31890;&#24230;&#26415;&#35821;&#65292;&#20197;&#23545;&#40784;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07623v1 Announce Type: new  Abstract: Sequential recommender systems (SRS) could capture dynamic user preferences by modeling historical behaviors ordered in time. Despite effectiveness, focusing only on the \textit{collaborative signals} from behaviors does not fully grasp user interests. It is also significant to model the \textit{semantic relatedness} reflected in content features, e.g., images and text. Towards that end, in this paper, we aim to enhance the SRS tasks by effectively unifying collaborative signals and semantic relatedness together. Notably, we empirically point out that it is nontrivial to achieve such a goal due to semantic gap issues. Thus, we propose an end-to-end two-stream architecture for sequential recommendation, named TSSR, to learn user preferences from ID-based and content-based sequence. Specifically, we first present novel hierarchical contrasting module, including coarse user-grained and fine item-grained terms, to align the representations o
&lt;/p&gt;</description></item><item><title>&#20027;&#21160;&#25512;&#33616;&#36890;&#36807;&#28789;&#27963;&#30340;&#21518;&#22788;&#29702;&#26041;&#24335;&#36827;&#34892;&#25512;&#33616;&#65292;&#36890;&#36807;&#23545;&#39033;&#30446;&#36827;&#34892;&#25490;&#21517;&#26469;&#31215;&#26497;&#24341;&#23548;&#29992;&#25143;&#24418;&#25104;&#26032;&#30340;&#20852;&#36259;&#12290;</title><link>https://arxiv.org/abs/2403.07571</link><description>&lt;p&gt;
&#20855;&#26377;&#36845;&#20195;&#20559;&#22909;&#24341;&#23548;&#30340;&#20027;&#21160;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Proactive Recommendation with Iterative Preference Guidance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07571
&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#25512;&#33616;&#36890;&#36807;&#28789;&#27963;&#30340;&#21518;&#22788;&#29702;&#26041;&#24335;&#36827;&#34892;&#25512;&#33616;&#65292;&#36890;&#36807;&#23545;&#39033;&#30446;&#36827;&#34892;&#25490;&#21517;&#26469;&#31215;&#26497;&#24341;&#23548;&#29992;&#25143;&#24418;&#25104;&#26032;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20027;&#35201;&#26681;&#25454;&#20174;&#29992;&#25143;&#21453;&#39304;&#20013;&#23398;&#21040;&#30340;&#29992;&#25143;&#20852;&#36259;&#26469;&#23450;&#21046;&#20010;&#24615;&#21270;&#25512;&#33616;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25512;&#33616;&#31995;&#32479; passively cater to user interests and even reinforce existing interests in the feedback loop, leading to problems like filter bubbles and opinion polarization. &#20026;&#20102;&#23545;&#25239;&#36825;&#19968;&#36235;&#21183;&#65292;&#20027;&#21160;&#25512;&#33616;&#36890;&#36807;&#25112;&#30053;&#24615;&#22320;&#35843;&#33410;&#25512;&#33616;&#24207;&#21015;&#65292;&#31215;&#26497;&#24341;&#23548;&#29992;&#25143;&#20135;&#29983;&#23545;&#30446;&#26631;&#39033;&#30446;&#25110;&#20027;&#39064;&#30340;&#26032;&#20852;&#36259;&#12290;&#29616;&#26377;&#30340;&#20027;&#21160;&#25512;&#33616;&#24037;&#20316;&#38754;&#20020;&#37325;&#22823;&#38556;&#30861;&#65306;1) &#22312;&#24341;&#23548;&#36807;&#31243;&#20013;&#24573;&#35270;&#29992;&#25143;&#21453;&#39304;; 2) &#32570;&#20047;&#23545;&#24341;&#23548;&#30446;&#26631;&#30340;&#26126;&#30830;&#24314;&#27169;; 3) &#32570;&#20047;&#34701;&#20837;&#29616;&#26377;&#24037;&#19994;&#25512;&#33616;&#31995;&#32479;&#30340;&#28789;&#27963;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010; Iterative Preference Guidance (IPG) &#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07571v1 Announce Type: new  Abstract: Recommender systems mainly tailor personalized recommendations according to user interests learned from user feedback. However, such recommender systems passively cater to user interests and even reinforce existing interests in the feedback loop, leading to problems like filter bubbles and opinion polarization. To counteract this, proactive recommendation actively steers users towards developing new interests in a target item or topic by strategically modulating recommendation sequences. Existing work for proactive recommendation faces significant hurdles: 1) overlooking the user feedback in the guidance process; 2) lacking explicit modeling of the guiding objective; and 3) insufficient flexibility for integration into existing industrial recommender systems. To address these issues, we introduce an Iterative Preference Guidance (IPG) framework. IPG performs proactive recommendation in a flexible post-processing manner by ranking items a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;Donut&#21644;OpenAI GPT-3.5 Turbo&#20004;&#31181;&#21069;&#27839;AI&#27169;&#22411;&#33258;&#21160;&#25552;&#21462;&#25991;&#20214;&#20013;&#32467;&#26500;&#21270;&#20449;&#24687;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#22312;&#24314;&#31569;&#35268;&#26684;&#25991;&#20214;&#30340;&#30446;&#24405;&#22788;&#29702;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#65292;&#20195;&#34920;&#20102;&#25991;&#26723;&#32034;&#24341;&#39046;&#22495;&#21521;&#33258;&#21160;&#21270;&#20449;&#24687;&#25552;&#21462;&#36808;&#20986;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;</title><link>https://arxiv.org/abs/2403.07553</link><description>&lt;p&gt;
&#25991;&#26723;&#32034;&#24341;&#30340;&#26410;&#26469;&#65306;GPT&#21644;Donut&#38761;&#26032;&#30446;&#24405;&#20869;&#23481;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
The future of document indexing: GPT and Donut revolutionize table of content processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07553
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;Donut&#21644;OpenAI GPT-3.5 Turbo&#20004;&#31181;&#21069;&#27839;AI&#27169;&#22411;&#33258;&#21160;&#25552;&#21462;&#25991;&#20214;&#20013;&#32467;&#26500;&#21270;&#20449;&#24687;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#22312;&#24314;&#31569;&#35268;&#26684;&#25991;&#20214;&#30340;&#30446;&#24405;&#22788;&#29702;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#65292;&#20195;&#34920;&#20102;&#25991;&#26723;&#32034;&#24341;&#39046;&#22495;&#21521;&#33258;&#21160;&#21270;&#20449;&#24687;&#25552;&#21462;&#36808;&#20986;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#19994;&#39033;&#30446;&#20005;&#37325;&#20381;&#36182;&#20887;&#38271;&#12289;&#22797;&#26434;&#30340;&#35268;&#26684;&#25991;&#20214;&#65292;&#25163;&#24037;&#25552;&#21462;&#32467;&#26500;&#21270;&#20449;&#24687;&#32321;&#29712;&#19988;&#25928;&#29575;&#20302;&#19979;&#12290;&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#26469;&#33258;&#21160;&#21270;&#36825;&#19968;&#36807;&#31243;&#65292;&#21033;&#29992;&#20004;&#31181;&#21069;&#27839;AI&#27169;&#22411;&#30340;&#33021;&#21147;&#65306;Donut&#65292;&#19968;&#31181;&#21487;&#20197;&#30452;&#25509;&#20174;&#25195;&#25551;&#25991;&#26723;&#20013;&#25552;&#21462;&#20449;&#24687;&#32780;&#26080;&#38656;OCR&#30340;&#27169;&#22411;&#65292;&#20197;&#21450;OpenAI GPT-3.5 Turbo&#65292;&#19968;&#20010;&#24378;&#22823;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#39318;&#20808;&#36890;&#36807;&#33719;&#21462;&#24314;&#31569;&#35268;&#26684;&#25991;&#20214;&#30340;&#30446;&#24405;&#65288;ToCs&#65289;&#65292;&#28982;&#21518;&#23558;ToCs&#25991;&#26412;&#32467;&#26500;&#21270;&#20026;JSON&#25968;&#25454;&#12290;&#23588;&#20026;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#34987;&#23454;&#29616;&#65292;Donut&#22312;&#26377;&#25928;&#32452;&#32455;ToCs&#26041;&#38754;&#36798;&#21040;85%&#65292;GPT-3.5 Turbo&#36798;&#21040;89%&#12290;&#36825;&#19968;&#37324;&#31243;&#30865;&#24335;&#30340;&#25104;&#23601;&#20195;&#34920;&#20102;&#25991;&#26723;&#32034;&#24341;&#39046;&#22495;&#30340;&#37325;&#22823;&#36827;&#27493;&#65292;&#23637;&#31034;&#20102;AI&#33258;&#21160;&#21270;&#20449;&#24687;&#25552;&#21462;&#22312;&#21508;&#31181;&#25991;&#26723;&#31867;&#22411;&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#25552;&#21319;&#20102;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07553v1 Announce Type: cross  Abstract: Industrial projects rely heavily on lengthy, complex specification documents, making tedious manual extraction of structured information a major bottleneck. This paper introduces an innovative approach to automate this process, leveraging the capabilities of two cutting-edge AI models: Donut, a model that extracts information directly from scanned documents without OCR, and OpenAI GPT-3.5 Turbo, a robust large language model. The proposed methodology is initiated by acquiring the table of contents (ToCs) from construction specification documents and subsequently structuring the ToCs text into JSON data. Remarkable accuracy is achieved, with Donut reaching 85% and GPT-3.5 Turbo reaching 89% in effectively organizing the ToCs. This landmark achievement represents a significant leap forward in document indexing, demonstrating the immense potential of AI to automate information extraction tasks across diverse document types, boosting effic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20010;&#24615;&#21270;&#30340;&#22522;&#20110;&#22270;&#30340;&#22522;&#30784;&#24314;&#27169;&#26041;&#27861;&#65292;&#20854;&#20013;&#30340;Heterogeneous GNN&#26088;&#22312;&#25429;&#25417;&#36328;&#22810;&#31181;&#21487;&#25512;&#33616;&#39033;&#30446;&#31867;&#22411;&#30340;&#22810;&#36339;&#20869;&#23481;&#21644;&#28040;&#36153;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.07478</link><description>&lt;p&gt;
&#38754;&#21521;&#20010;&#24615;&#21270;&#30340;&#22270;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Towards Graph Foundation Models for Personalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07478
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20010;&#24615;&#21270;&#30340;&#22522;&#20110;&#22270;&#30340;&#22522;&#30784;&#24314;&#27169;&#26041;&#27861;&#65292;&#20854;&#20013;&#30340;Heterogeneous GNN&#26088;&#22312;&#25429;&#25417;&#36328;&#22810;&#31181;&#21487;&#25512;&#33616;&#39033;&#30446;&#31867;&#22411;&#30340;&#22810;&#36339;&#20869;&#23481;&#21644;&#28040;&#36153;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20010;&#24615;&#21270;&#39046;&#22495;&#65292;&#25972;&#21512;&#28040;&#36153;&#20449;&#21495;&#21644;&#22522;&#20110;&#20869;&#23481;&#30340;&#34920;&#31034;&#31561;&#22810;&#26679;&#20449;&#24687;&#28304;&#21464;&#24471;&#26085;&#30410;&#20851;&#38190;&#65292;&#20197;&#26500;&#24314;&#26368;&#20808;&#36827;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#22260;&#32469;Graph Neural Networks&#65288;GNNs&#65289;&#21644;Foundation Models&#65288;FMs&#65289;&#30340;&#30740;&#31350;&#23384;&#22312;&#20004;&#22823;&#36235;&#21183;&#12290;&#34429;&#28982;GNNs&#25104;&#20026;&#24037;&#19994;&#30028;&#22312;&#35268;&#27169;&#19978;&#23454;&#29616;&#20010;&#24615;&#21270;&#30340;&#28909;&#38376;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;FMs&#26368;&#36817;&#25165;&#22240;&#20854;&#22312;&#25490;&#21517;&#21644;&#26816;&#32034;&#31561;&#20010;&#24615;&#21270;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#32780;&#21463;&#21040;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20010;&#24615;&#21270;&#30340;&#22522;&#20110;&#22270;&#30340;&#22522;&#30784;&#24314;&#27169;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#35774;&#35745;&#29992;&#20110;&#25429;&#25417;&#36328;&#21508;&#31181;&#21487;&#25512;&#33616;&#39033;&#30446;&#31867;&#22411;&#30340;&#22810;&#36339;&#20869;&#23481;&#21644;&#28040;&#36153;&#20851;&#31995;&#30340;&#24322;&#36136;GNN&#65288;HGNN&#65289;&#12290;&#20026;&#30830;&#20445;&#22522;&#30784;&#27169;&#22411;&#25152;&#38656;&#30340;&#19968;&#33324;&#24615;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#25991;&#26412;&#29305;&#24449;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07478v1 Announce Type: cross  Abstract: In the realm of personalization, integrating diverse information sources such as consumption signals and content-based representations is becoming increasingly critical to build state-of-the-art solutions. In this regard, two of the biggest trends in research around this subject are Graph Neural Networks (GNNs) and Foundation Models (FMs). While GNNs emerged as a popular solution in industry for powering personalization at scale, FMs have only recently caught attention for their promising performance in personalization tasks like ranking and retrieval. In this paper, we present a graph-based foundation modeling approach tailored to personalization. Central to this approach is a Heterogeneous GNN (HGNN) designed to capture multi-hop content and consumption relationships across a range of recommendable item types. To ensure the generality required from a Foundation Model, we employ a Large Language Model (LLM) text-based featurization of
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LIST&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#23398;&#20064;&#20026;&#22522;&#20110;&#23884;&#20837;&#30340;&#31354;&#38388;&#20851;&#38190;&#35789;&#26597;&#35810;&#24314;&#31435;&#31354;&#38388;&#25991;&#26412;&#25968;&#25454;&#32034;&#24341;&#65292;&#20197;&#21152;&#36895;top-k&#25628;&#32034;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2403.07331</link><description>&lt;p&gt;
LIST: &#23398;&#20064;&#20026;&#22522;&#20110;&#23884;&#20837;&#30340;&#31354;&#38388;&#20851;&#38190;&#35789;&#26597;&#35810;&#24314;&#31435;&#31354;&#38388;&#25991;&#26412;&#25968;&#25454;&#32034;&#24341;
&lt;/p&gt;
&lt;p&gt;
LIST: Learning to Index Spatio-Textual Data for Embedding based Spatial Keyword Queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07331
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LIST&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#23398;&#20064;&#20026;&#22522;&#20110;&#23884;&#20837;&#30340;&#31354;&#38388;&#20851;&#38190;&#35789;&#26597;&#35810;&#24314;&#31435;&#31354;&#38388;&#25991;&#26412;&#25968;&#25454;&#32034;&#24341;&#65292;&#20197;&#21152;&#36895;top-k&#25628;&#32034;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31354;&#38388;&#25991;&#26412;&#25968;&#25454;&#30340;&#26222;&#21450;&#65292;&#8220;Top-k KNN&#31354;&#38388;&#20851;&#38190;&#35789;&#26597;&#35810;&#65288;TkQs&#65289;&#8221;&#24050;&#32463;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#21457;&#29616;&#65292;&#23427;&#22522;&#20110;&#19968;&#20010;&#35780;&#20215;&#31354;&#38388;&#21644;&#25991;&#26412;&#30456;&#20851;&#24615;&#30340;&#25490;&#21517;&#20989;&#25968;&#36820;&#22238;&#19968;&#20010;&#23545;&#35937;&#21015;&#34920;&#12290;&#29616;&#26377;&#30340;&#29992;&#20110;TkQs&#30340;geo-textual&#32034;&#24341;&#20351;&#29992;&#20256;&#32479;&#30340;&#26816;&#32034;&#27169;&#22411;&#65288;&#22914;BM25&#65289;&#26469;&#35745;&#31639;&#25991;&#26412;&#30456;&#20851;&#24615;&#65292;&#24182;&#36890;&#24120;&#21033;&#29992;&#31616;&#21333;&#30340;&#32447;&#24615;&#20989;&#25968;&#26469;&#35745;&#31639;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#20294;&#20854;&#25928;&#26524;&#26377;&#38480;&#12290;&#20026;&#20102;&#25552;&#39640;&#25928;&#26524;&#65292;&#26368;&#36817;&#25552;&#20986;&#20102;&#20960;&#31181;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#20294;&#23427;&#20204;&#23384;&#22312;&#20005;&#37325;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#30446;&#21069;&#27809;&#26377;&#20026;&#21152;&#36895;&#36825;&#20123;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;top-k&#25628;&#32034;&#36807;&#31243;&#19987;&#38376;&#35774;&#35745;&#30340;&#26377;&#25928;&#32034;&#24341;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#23398;&#20064;&#20026;&#22238;&#31572;&#22522;&#20110;&#23884;&#20837;&#30340;&#31354;&#38388;&#20851;&#38190;&#35789;&#26597;&#35810;&#65288;&#31216;&#20026;LIST&#65289;&#24314;&#31435;&#31354;&#38388;&#25991;&#26412;&#25968;&#25454;&#32034;&#24341;&#12290;LIST&#20855;&#26377;&#20004;&#20010;&#26032;&#39062;&#32452;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07331v1 Announce Type: new  Abstract: With the proliferation of spatio-textual data, Top-k KNN spatial keyword queries (TkQs), which return a list of objects based on a ranking function that evaluates both spatial and textual relevance, have found many real-life applications. Existing geo-textual indexes for TkQs use traditional retrieval models like BM25 to compute text relevance and usually exploit a simple linear function to compute spatial relevance, but its effectiveness is limited. To improve effectiveness, several deep learning models have recently been proposed, but they suffer severe efficiency issues. To the best of our knowledge, there are no efficient indexes specifically designed to accelerate the top-k search process for these deep learning models.   To tackle these issues, we propose a novel technique, which Learns to Index the Spatio-Textual data for answering embedding based spatial keyword queries (called LIST). LIST is featured with two novel components. F
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#27491;&#29305;&#24449;&#22686;&#24378;&#21644;&#36127;&#26631;&#31614;&#22686;&#24378;&#25913;&#36827;&#33258;&#25105;&#30417;&#30563;&#20449;&#21495;&#65292;&#25552;&#39640;&#20102;&#38544;&#24335;&#21327;&#21516;&#36807;&#28388;&#20934;&#30830;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#36127;&#26631;&#31614;&#22686;&#24378;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22686;&#24378;</title><link>https://arxiv.org/abs/2403.07265</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#30340;&#38544;&#24335;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Self-supervised Contrastive Learning for Implicit Collaborative Filtering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07265
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#27491;&#29305;&#24449;&#22686;&#24378;&#21644;&#36127;&#26631;&#31614;&#22686;&#24378;&#25913;&#36827;&#33258;&#25105;&#30417;&#30563;&#20449;&#21495;&#65292;&#25552;&#39640;&#20102;&#38544;&#24335;&#21327;&#21516;&#36807;&#28388;&#20934;&#30830;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#36127;&#26631;&#31614;&#22686;&#24378;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#25512;&#33616;&#31639;&#27861;&#26174;&#33879;&#25512;&#36827;&#20102;&#33258;&#30417;&#30563;&#25512;&#33616;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#20197;BPR&#20316;&#20026;&#20027;&#35201;&#20195;&#34920;&#30340;&#25484;&#25569;&#38544;&#24335;&#21327;&#21516;&#36807;&#28388;&#30340;&#25490;&#21517;&#39044;&#27979;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#23384;&#22312;&#30340;&#35823;&#27491;&#20363;&#21644;&#35823;&#36127;&#20363;&#38459;&#30861;&#20102;&#20934;&#30830;&#30340;&#20559;&#22909;&#23398;&#20064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#27491;&#29305;&#24449;&#22686;&#24378;&#21644;&#36127;&#26631;&#31614;&#22686;&#24378;&#26469;&#25913;&#36827;&#33258;&#25105;&#30417;&#30563;&#20449;&#21495;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#23398;&#20064;&#26041;&#27861;&#31561;&#25928;&#20110;&#21033;&#29992;&#20195;&#34920;&#29992;&#25143;&#20852;&#36259;&#20013;&#24515;&#30340;&#28508;&#22312;&#21464;&#37327;&#26368;&#22823;&#21270;&#20284;&#28982;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#36127;&#26631;&#31614;&#22686;&#24378;&#25216;&#26415;&#65292;&#26681;&#25454;&#23427;&#20204;&#30340;&#30456;&#23545;&#25490;&#21517;&#20301;&#32622;&#32447;&#24615;&#30456;&#20851;&#22320;&#37319;&#26679;&#26410;&#26631;&#35760;&#30340;&#31034;&#20363;&#65292;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#22686;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07265v1 Announce Type: new  Abstract: Contrastive learning-based recommendation algorithms have significantly advanced the field of self-supervised recommendation, particularly with BPR as a representative ranking prediction task that dominates implicit collaborative filtering. However, the presence of false-positive and false-negative examples in recommendation systems hampers accurate preference learning. In this study, we propose a simple self-supervised contrastive learning framework that leverages positive feature augmentation and negative label augmentation to improve the self-supervisory signal. Theoretical analysis demonstrates that our learning method is equivalent to maximizing the likelihood estimation with latent variables representing user interest centers. Additionally, we establish an efficient negative label augmentation technique that samples unlabeled examples with a probability linearly dependent on their relative ranking positions, enabling efficient augm
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#25506;&#32034;GAB&#21644;Telegram&#36825;&#20004;&#20010;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#30340;&#21465;&#20107;&#28436;&#21464;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#30740;&#31350;&#22810;&#20010;&#31038;&#20132;&#23186;&#20307;&#39046;&#22495;&#65292;&#20197;&#25552;&#21462;&#21487;&#33021;&#34987;&#25513;&#30422;&#30340;&#20851;&#38190;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2403.07090</link><description>&lt;p&gt;
&#21453;&#26144;&#22797;&#26434;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#27969;&#20013;&#20851;&#38190;&#31038;&#20250;&#20107;&#20214;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Time Series Analysis of Key Societal Events as Reflected in Complex Social Media Data Streams
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07090
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#25506;&#32034;GAB&#21644;Telegram&#36825;&#20004;&#20010;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#30340;&#21465;&#20107;&#28436;&#21464;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#30740;&#31350;&#22810;&#20010;&#31038;&#20132;&#23186;&#20307;&#39046;&#22495;&#65292;&#20197;&#25552;&#21462;&#21487;&#33021;&#34987;&#25513;&#30422;&#30340;&#20851;&#38190;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07090v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#30028; &#25688;&#35201;: &#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#34164;&#34255;&#30528;&#23453;&#36149;&#30340;&#35265;&#35299;&#65292;&#28982;&#32780;&#25552;&#21462;&#20851;&#38190;&#20449;&#24687;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20256;&#32479;&#30340;&#33258;&#19978;&#32780;&#19979;&#26041;&#27861;&#36890;&#24120;&#38590;&#20197;&#25429;&#25417;&#24555;&#36895;&#21464;&#21270;&#20107;&#20214;&#20013;&#30340;&#20851;&#38190;&#20449;&#21495;&#12290;&#38543;&#30528;&#20840;&#29699;&#20107;&#20214;&#36805;&#36895;&#28436;&#21464;&#65292;&#21253;&#25324;&#34394;&#20551;&#20449;&#24687;&#30340;&#31038;&#20132;&#23186;&#20307;&#21465;&#20107;&#25104;&#20026;&#37325;&#35201;&#30340;&#35265;&#35299;&#26469;&#28304;&#12290;&#20026;&#20102;&#28385;&#36275;&#24402;&#32435;&#31574;&#30053;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#23567;&#20247;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;GAB&#21644;&#19968;&#20010;&#25104;&#29087;&#30340;&#28040;&#24687;&#26381;&#21153;Telegram&#65292;&#20197;&#24320;&#21457;&#36866;&#29992;&#20110;&#26356;&#24191;&#27867;&#33539;&#22260;&#30340;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#23450;&#37327;&#22522;&#20110;&#35821;&#26009;&#24211;&#30340;&#35805;&#35821;&#20998;&#26512;&#25216;&#26415;&#26469;&#30740;&#31350;&#36825;&#20123;&#24179;&#21488;&#19978;&#30340;&#21465;&#20107;&#28436;&#21464;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#30740;&#31350;&#22810;&#20010;&#31038;&#20132;&#23186;&#20307;&#39046;&#22495;&#20197;&#25552;&#28860;&#21487;&#33021;&#34987;&#25513;&#30422;&#30340;&#20851;&#38190;&#20449;&#24687;&#30340;&#26032;&#39062;&#26041;&#24335;&#65292;&#20174;&#32780;&#25552;&#20379;&#26377;&#29992;&#19988;&#21487;&#25805;&#20316;&#30340;&#35265;&#35299;&#12290;&#35813;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#25910;&#38598;&#21644;&#39044;&#22788;&#29702;GAB&#21644;Telegram&#25968;&#25454;&#30340;&#25216;&#26415;&#21644;&#26041;&#27861;&#35770;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07090v1 Announce Type: cross  Abstract: Social media platforms hold valuable insights, yet extracting essential information can be challenging. Traditional top-down approaches often struggle to capture critical signals in rapidly changing events. As global events evolve swiftly, social media narratives, including instances of disinformation, become significant sources of insights. To address the need for an inductive strategy, we explore a niche social media platform GAB and an established messaging service Telegram, to develop methodologies applicable on a broader scale. This study investigates narrative evolution on these platforms using quantitative corpus-based discourse analysis techniques. Our approach is a novel mode to study multiple social media domains to distil key information which may be obscured otherwise, allowing for useful and actionable insights. The paper details the technical and methodological aspects of gathering and preprocessing GAB and Telegram data 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Meta-Split&#32593;&#32476;&#65288;MSN&#65289;&#26469;&#35299;&#20915;&#28040;&#36153;&#32773;&#20043;&#38388;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#20013;&#38480;&#37327;&#24211;&#23384;&#20135;&#21697;&#25512;&#33616;&#20013;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#36890;&#36807;&#20998;&#21106;&#29992;&#25143;&#21382;&#21490;&#24207;&#21015;&#26469;&#26377;&#25928;&#21033;&#29992;&#29992;&#25143;&#21382;&#21490;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2403.06747</link><description>&lt;p&gt;
MetaSplit: &#29992;&#20110;&#38480;&#37327;&#20135;&#21697;&#25512;&#33616;&#30340;Meta-Split&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06747
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Meta-Split&#32593;&#32476;&#65288;MSN&#65289;&#26469;&#35299;&#20915;&#28040;&#36153;&#32773;&#20043;&#38388;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#20013;&#38480;&#37327;&#24211;&#23384;&#20135;&#21697;&#25512;&#33616;&#20013;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#36890;&#36807;&#20998;&#21106;&#29992;&#25143;&#21382;&#21490;&#24207;&#21015;&#26469;&#26377;&#25928;&#21033;&#29992;&#29992;&#25143;&#21382;&#21490;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#23545;&#20110;&#38754;&#21521;&#28040;&#36153;&#32773;&#30340;&#30005;&#23376;&#21830;&#21153;&#31995;&#32479;&#65292;&#28040;&#36153;&#32773;&#20043;&#38388;&#30340;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#36890;&#24120;&#20250;&#36935;&#21040;&#38480;&#37327;&#24211;&#23384;&#38382;&#39064;&#65292;&#21363;&#20135;&#21697;&#22312;C2C&#31995;&#32479;&#20013;&#21482;&#33021;&#38144;&#21806;&#19968;&#27425;&#12290;&#36825;&#20026;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#24102;&#26469;&#20102;&#20960;&#20010;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#37492;&#20110;&#27599;&#20010;&#20135;&#21697;&#65288;&#21363;&#21830;&#21697;&#65289;&#30340;&#26377;&#38480;&#29992;&#25143;&#20132;&#20114;&#65292;CTR&#27169;&#22411;&#20013;&#23545;&#24212;&#30340;&#21830;&#21697;&#23884;&#20837;&#21487;&#33021;&#19981;&#23481;&#26131;&#25910;&#25947;&#12290;&#36825;&#20351;&#24471;&#20256;&#32479;&#22522;&#20110;&#24207;&#21015;&#24314;&#27169;&#30340;&#26041;&#27861;&#26080;&#27861;&#26377;&#25928;&#21033;&#29992;&#29992;&#25143;&#21382;&#21490;&#20449;&#24687;&#65292;&#22240;&#20026;&#21382;&#21490;&#29992;&#25143;&#34892;&#20026;&#21253;&#21547;&#20102;&#19981;&#21516;&#24211;&#23384;&#37327;&#30340;&#21830;&#21697;&#28151;&#21512;&#12290;&#29305;&#21035;&#26159;&#65292;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#20542;&#21521;&#20110;&#23558;&#26356;&#22810;&#32047;&#31215;&#29992;&#25143;&#20132;&#20114;&#30340;&#20135;&#21697;&#20998;&#37197;&#26356;&#39640;&#30340;&#20998;&#25968;&#65292;&#23548;&#33268;&#38480;&#37327;&#20135;&#21697;&#34987;&#24573;&#35270;&#19988;&#23545;&#26368;&#32456;&#36755;&#20986;&#30340;&#36129;&#29486;&#36739;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Meta-Split&#32593;&#32476;&#65288;MSN&#65289;&#26469;&#20998;&#21106;&#29992;&#25143;&#21382;&#21490;&#24207;&#21015;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06747v1 Announce Type: new  Abstract: Compared to business-to-consumer (B2C) e-commerce systems, consumer-to-consumer (C2C) e-commerce platforms usually encounter the limited-stock problem, that is, a product can only be sold one time in a C2C system. This poses several unique challenges for click-through rate (CTR) prediction. Due to limited user interactions for each product (i.e. item), the corresponding item embedding in the CTR model may not easily converge. This makes the conventional sequence modeling based approaches cannot effectively utilize user history information since historical user behaviors contain a mixture of items with different volume of stocks. Particularly, the attention mechanism in a sequence model tends to assign higher score to products with more accumulated user interactions, making limited-stock products being ignored and contribute less to the final output. To this end, we propose the Meta-Split Network (MSN) to split user history sequence regar
&lt;/p&gt;</description></item><item><title>&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;&#21487;&#20197;&#20316;&#20026;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#23384;&#22312;&#23545;&#27969;&#34892;&#24086;&#23376;&#20559;&#35265;&#36739;&#39640;&#12289;&#24773;&#24863;&#26356;&#31215;&#26497;&#20197;&#21450;&#24573;&#35270;&#25919;&#27835;&#12289;&#33394;&#24773;&#21644;&#31895;&#20439;&#24086;&#23376;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2401.15479</link><description>&lt;p&gt;
&#24212;&#23545;&#21518;API&#22256;&#22659;&#65306;&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;&#21576;&#29616;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#20559;&#35265;&#35266;
&lt;/p&gt;
&lt;p&gt;
Navigating the Post-API Dilemma Search Engine Results Pages Present a Biased View of Social Media Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15479
&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;&#21487;&#20197;&#20316;&#20026;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#23384;&#22312;&#23545;&#27969;&#34892;&#24086;&#23376;&#20559;&#35265;&#36739;&#39640;&#12289;&#24773;&#24863;&#26356;&#31215;&#26497;&#20197;&#21450;&#24573;&#35270;&#25919;&#27835;&#12289;&#33394;&#24773;&#21644;&#31895;&#20439;&#24086;&#23376;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20572;&#27490;&#35775;&#38382;&#31038;&#20132;&#23186;&#20307;API&#30340;&#20915;&#23450;&#23545;&#20114;&#32852;&#32593;&#30740;&#31350;&#21644;&#25972;&#20010;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#39046;&#22495;&#20135;&#29983;&#20102;&#19981;&#21033;&#24433;&#21709;&#12290;&#36825;&#31181;&#23545;&#25968;&#25454;&#30340;&#35775;&#38382;&#32570;&#20047;&#24050;&#34987;&#31216;&#20026;&#20114;&#32852;&#32593;&#30740;&#31350;&#30340;&#21518;API&#26102;&#20195;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#27969;&#34892;&#30340;&#25628;&#32034;&#24341;&#25806;&#26377;&#33021;&#21147;&#29228;&#21462;&#12289;&#25429;&#33719;&#21644;&#23637;&#31034;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#22312;&#20854;&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;(SERP)&#19978;&#65292;&#22914;&#26524;&#25552;&#20379;&#36866;&#24403;&#30340;&#25628;&#32034;&#26597;&#35810;&#65292;&#21487;&#33021;&#20250;&#20026;&#36825;&#19968;&#22256;&#22659;&#25552;&#20379;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#24403;&#21069;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38382;&#65306;SERP&#26159;&#21542;&#25552;&#20379;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#23436;&#25972;&#21644;&#26080;&#20559;&#35265;&#26679;&#26412;&#65311; SERP&#26159;&#21542;&#26159;&#30452;&#25509;API&#35775;&#38382;&#30340;&#21487;&#34892;&#26367;&#20195;&#26041;&#26696;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#23545;&#65288;Google&#65289;SERP&#32467;&#26524;&#21644;&#26469;&#33258;Reddit&#21644;Twitter/X&#30340;&#38750;&#21462;&#26679;&#25968;&#25454;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;SERP&#32467;&#26524;&#22312;&#25903;&#25345;&#27969;&#34892;&#24086;&#23376;&#26041;&#38754;&#23384;&#22312;&#39640;&#24230;&#20559;&#35265;&#65307;&#21453;&#23545;&#25919;&#27835;&#12289;&#33394;&#24773;&#21644;&#31895;&#20439;&#24086;&#23376;&#65307;&#22312;&#24773;&#24863;&#19978;&#26356;&#20026;&#31215;&#26497;&#65307;&#24182;&#26377;&#22823;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.15479v2 Announce Type: replace-cross  Abstract: Recent decisions to discontinue access to social media APIs are having detrimental effects on Internet research and the field of computational social science as a whole. This lack of access to data has been dubbed the Post-API era of Internet research. Fortunately, popular search engines have the means to crawl, capture, and surface social media data on their Search Engine Results Pages (SERP) if provided the proper search query, and may provide a solution to this dilemma. In the present work we ask: does SERP provide a complete and unbiased sample of social media data? Is SERP a viable alternative to direct API-access? To answer these questions, we perform a comparative analysis between (Google) SERP results and nonsampled data from Reddit and Twitter/X. We find that SERP results are highly biased in favor of popular posts; against political, pornographic, and vulgar posts; are more positive in their sentiment; and have large 
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35843;&#26597;&#20102;&#19968;&#31181;&#21517;&#20026;&#26816;&#32034;&#31034;&#33539;&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;&#29305;&#23450;&#20110;&#36755;&#20837;&#26597;&#35810;&#30340;&#31034;&#33539;&#26469;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#30340;&#23569;&#37327;&#26679;&#26412;&#24773;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#33021;&#21147;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#23398;&#20064;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#36824;&#20943;&#23569;&#20102;&#25163;&#21160;&#31034;&#20363;&#36873;&#25321;&#20013;&#30340;&#20559;&#35265;&#12290;</title><link>http://arxiv.org/abs/2401.11624</link><description>&lt;p&gt;
&#36890;&#36807;&#26816;&#32034;&#31034;&#33539;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#35821;&#35328;&#27169;&#22411;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
In-context Learning with Retrieved Demonstrations for Language Models: A Survey. (arXiv:2401.11624v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11624
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35843;&#26597;&#20102;&#19968;&#31181;&#21517;&#20026;&#26816;&#32034;&#31034;&#33539;&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;&#29305;&#23450;&#20110;&#36755;&#20837;&#26597;&#35810;&#30340;&#31034;&#33539;&#26469;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#30340;&#23569;&#37327;&#26679;&#26412;&#24773;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#33021;&#21147;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#23398;&#20064;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#36824;&#20943;&#23569;&#20102;&#25163;&#21160;&#31034;&#20363;&#36873;&#25321;&#20013;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24050;&#23637;&#31034;&#20986;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#22312;&#36755;&#20837;&#19978;&#19979;&#25991;&#20013;&#36827;&#34892;&#23569;&#37327;&#26679;&#26412;&#30340;&#24773;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#65292;&#24182;&#22312;&#26032;&#20219;&#21153;&#19978;&#20855;&#26377;&#36866;&#24212;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#30340;ICL&#33021;&#21147;&#23545;&#20110;&#23569;&#26679;&#26412;&#31034;&#33539;&#30340;&#36873;&#25321;&#26159;&#25935;&#24863;&#30340;&#12290;&#26368;&#36817;&#30340;&#19968;&#39033;&#30740;&#31350;&#36827;&#23637;&#26159;&#26816;&#32034;&#38024;&#23545;&#27599;&#20010;&#36755;&#20837;&#26597;&#35810;&#23450;&#21046;&#30340;&#31034;&#33539;&#12290;&#31034;&#33539;&#26816;&#32034;&#30340;&#23454;&#29616;&#30456;&#23545;&#31616;&#21333;&#65292;&#21033;&#29992;&#29616;&#26377;&#30340;&#25968;&#25454;&#24211;&#21644;&#26816;&#32034;&#31995;&#32479;&#12290;&#36825;&#19981;&#20165;&#25552;&#39640;&#20102;&#23398;&#20064;&#36807;&#31243;&#30340;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#32780;&#19988;&#24050;&#32463;&#35777;&#26126;&#21487;&#20197;&#20943;&#23569;&#25163;&#21160;&#31034;&#20363;&#36873;&#25321;&#20013;&#30340;&#20559;&#35265;&#12290;&#37492;&#20110;&#20196;&#20154;&#40723;&#33310;&#30340;&#32467;&#26524;&#21644;&#22312;&#26816;&#32034;&#31034;&#33539;&#30340;ICL&#26041;&#38754;&#19981;&#26029;&#22686;&#38271;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#32508;&#36848;&#12290;&#22312;&#36825;&#39033;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#21644;&#27604;&#36739;&#20102;&#26816;&#32034;&#27169;&#22411;&#30340;&#19981;&#21516;&#35774;&#35745;&#36873;&#25321;&#65292;&#26816;&#32034;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#35270;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26469;&#22635;&#20805;&#38750;&#30446;&#26631;&#20195;&#35874;&#32452;&#23398;&#20013;&#30340;&#32570;&#22833;&#20540;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#20840;&#22522;&#22240;&#32452;&#27979;&#24207;&#25968;&#25454;&#21644;&#21442;&#32771;&#20195;&#35874;&#29289;&#30340;&#20449;&#24687;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#26681;&#25454;&#22522;&#22240;&#32452;&#20449;&#24687;&#22635;&#20805;&#32570;&#22833;&#30340;&#20195;&#35874;&#32452;&#23398;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.07990</link><description>&lt;p&gt;
&#22810;&#35270;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#38750;&#30446;&#26631;&#20195;&#35874;&#32452;&#23398;&#20013;&#32570;&#22833;&#20540;&#22635;&#20805;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multi-View Variational Autoencoder for Missing Value Imputation in Untargeted Metabolomics. (arXiv:2310.07990v1 [q-bio.GN])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07990
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#35270;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26469;&#22635;&#20805;&#38750;&#30446;&#26631;&#20195;&#35874;&#32452;&#23398;&#20013;&#30340;&#32570;&#22833;&#20540;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#20840;&#22522;&#22240;&#32452;&#27979;&#24207;&#25968;&#25454;&#21644;&#21442;&#32771;&#20195;&#35874;&#29289;&#30340;&#20449;&#24687;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#26681;&#25454;&#22522;&#22240;&#32452;&#20449;&#24687;&#22635;&#20805;&#32570;&#22833;&#30340;&#20195;&#35874;&#32452;&#23398;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#22312;&#22522;&#20110;&#36136;&#35889;&#30340;&#20195;&#35874;&#32452;&#23398;&#20013;&#65292;&#32570;&#22833;&#25968;&#25454;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#25361;&#25112;&#65292;&#21487;&#33021;&#23548;&#33268;&#20559;&#20506;&#21644;&#19981;&#23436;&#25972;&#30340;&#20998;&#26512;&#12290;&#23558;&#20840;&#22522;&#22240;&#32452;&#27979;&#24207;&#65288;WGS&#65289;&#25968;&#25454;&#19982;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#25972;&#21512;&#36215;&#26469;&#65292;&#24050;&#32463;&#25104;&#20026;&#22686;&#24378;&#20195;&#35874;&#32452;&#23398;&#30740;&#31350;&#20013;&#25968;&#25454;&#22635;&#20805;&#20934;&#30830;&#24615;&#30340;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;&#26041;&#27861;&#65306;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26469;&#33258;WGS&#25968;&#25454;&#21644;&#21442;&#32771;&#20195;&#35874;&#29289;&#30340;&#20449;&#24687;&#26469;&#22635;&#20805;&#26410;&#30693;&#20195;&#35874;&#29289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22810;&#35270;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#20849;&#21516;&#23545;&#36127;&#25285;&#35780;&#20998;&#12289;&#22810;&#22522;&#22240;&#39118;&#38505;&#35780;&#20998;&#65288;PGS&#65289;&#21644;&#36830;&#38145;&#19981;&#24179;&#34913;&#65288;LD&#65289;&#21024;&#20943;&#30340;&#21333;&#26680;&#33527;&#37240;&#22810;&#24577;&#24615;&#65288;SNPs&#65289;&#36827;&#34892;&#29305;&#24449;&#25552;&#21462;&#21644;&#32570;&#22833;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#30340;&#22635;&#20805;&#12290;&#36890;&#36807;&#23398;&#20064;&#20004;&#31181;&#32452;&#23398;&#25968;&#25454;&#30340;&#28508;&#22312;&#34920;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26681;&#25454;&#22522;&#22240;&#32452;&#20449;&#24687;&#26377;&#25928;&#22320;&#22635;&#20805;&#32570;&#22833;&#30340;&#20195;&#35874;&#32452;&#23398;&#20540;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#22312;&#20855;&#26377;&#32570;&#22833;&#20540;&#21644;&#19981;&#23436;&#25972;&#25968;&#25454;&#30340;&#23454;&#39564;&#20195;&#35874;&#32452;&#23398;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background: Missing data is a common challenge in mass spectrometry-based metabolomics, which can lead to biased and incomplete analyses. The integration of whole-genome sequencing (WGS) data with metabolomics data has emerged as a promising approach to enhance the accuracy of data imputation in metabolomics studies. Method: In this study, we propose a novel method that leverages the information from WGS data and reference metabolites to impute unknown metabolites. Our approach utilizes a multi-view variational autoencoder to jointly model the burden score, polygenetic risk score (PGS), and linkage disequilibrium (LD) pruned single nucleotide polymorphisms (SNPs) for feature extraction and missing metabolomics data imputation. By learning the latent representations of both omics data, our method can effectively impute missing metabolomics values based on genomic information. Results: We evaluate the performance of our method on empirical metabolomics datasets with missing values and de
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29289;&#21697;&#23884;&#20837;&#26469;&#32531;&#35299;&#24191;&#21578;&#33829;&#38144;&#39046;&#22495;&#20013;&#20301;&#32622;&#20559;&#24046;&#31232;&#30095;&#24615;&#38382;&#39064;&#30340;&#22238;&#24402;EM&#31639;&#27861;&#21464;&#20307;&#12290;</title><link>http://arxiv.org/abs/2305.13931</link><description>&lt;p&gt;
&#21033;&#29992;&#29289;&#21697;&#23884;&#20837;&#25913;&#36827;&#22312;&#31232;&#30095;&#21644;&#20542;&#26012;&#25968;&#25454;&#38598;&#20013;&#23545;&#20301;&#32622;&#20559;&#24046;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Improving position bias estimation against sparse and skewed dataset with item embedding. (arXiv:2305.13931v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13931
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29289;&#21697;&#23884;&#20837;&#26469;&#32531;&#35299;&#24191;&#21578;&#33829;&#38144;&#39046;&#22495;&#20013;&#20301;&#32622;&#20559;&#24046;&#31232;&#30095;&#24615;&#38382;&#39064;&#30340;&#22238;&#24402;EM&#31639;&#27861;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#25490;&#21517;&#20013;&#65292;&#20272;&#35745;&#20301;&#32622;&#20559;&#24046;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#25361;&#25112;&#12290;&#30005;&#23376;&#21830;&#21153;&#24212;&#29992;&#31243;&#24207;&#20013;&#30340;&#28857;&#20987;&#25968;&#25454;&#65288;&#20363;&#22914;&#24191;&#21578;&#23450;&#20301;&#21644;&#25628;&#32034;&#24341;&#25806;&#65289;&#25552;&#20379;&#20102;&#38544;&#21547;&#20294;&#20016;&#23500;&#30340;&#21453;&#39304;&#65292;&#20197;&#25913;&#36827;&#20010;&#24615;&#21270;&#25490;&#21517;&#12290;&#28982;&#32780;&#65292;&#28857;&#20987;&#25968;&#25454;&#26412;&#36136;&#19978;&#21253;&#25324;&#21508;&#31181;&#20559;&#24046;&#65292;&#20363;&#22914;&#20301;&#32622;&#20559;&#24046;&#12290;&#28857;&#20987;&#24314;&#27169;&#26088;&#22312;&#21435;&#22122;&#26377;&#20559;&#30340;&#28857;&#20987;&#25968;&#25454;&#24182;&#25552;&#21462;&#21487;&#38752;&#30340;&#20449;&#21495;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#38543;&#26426;&#21270;&#32467;&#26524;&#21644;&#22238;&#24402;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#26469;&#35299;&#20915;&#20301;&#32622;&#20559;&#24046;&#12290;&#20294;&#26159;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#38656;&#35201;&#21508;&#31181;&#35266;&#23519;&#20540;&#23545;&#65288;&#39033;&#30446;&#12289;&#20301;&#32622;&#65289;&#12290;&#28982;&#32780;&#65292;&#22312;&#24191;&#21578;&#33829;&#38144;&#30340;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#33829;&#38144;&#20154;&#21592;&#32463;&#24120;&#25353;&#22266;&#23450;&#30340;&#39044;&#23450;&#39034;&#24207;&#26174;&#31034;&#24191;&#21578;&#65292;&#20272;&#35745;&#22240;&#27492;&#32780;&#21463;&#21040;&#24433;&#21709;&#12290;&#25105;&#20204;&#23558;&#20301;&#32622;&#20559;&#24046;&#20272;&#35745;&#20013;&#30340;&#65288;&#39033;&#30446;&#12289;&#20301;&#32622;&#65289;&#31232;&#30095;&#24615;&#38382;&#39064;&#20316;&#20026;&#26032;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29289;&#21697;&#23884;&#20837;&#26469;&#32531;&#35299;&#31232;&#30095;&#38382;&#39064;&#30340;&#22238;&#24402;EM&#31639;&#27861;&#21464;&#20307;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating position bias is a well-known challenge in Learning to rank (L2R). Click data in e-commerce applications, such as advertisement targeting and search engines, provides implicit but abundant feedback to improve personalized rankings. However, click data inherently include various biases like position bias. Click modeling is aimed at denoising biases in click data and extracting reliable signals. Result Randomization and Regression Expectation-maximization algorithm have been proposed to solve position bias. Both methods require various pairs of observations (item, position). However, in real cases of advertising, marketers frequently display advertisements in a fixed pre-determined order, and estimation suffers from it. We propose this sparsity of (item, position) in position bias estimation as a novel problem, and we propose a variant of the Regression EM algorithm which utilizes item embeddings to alleviate the issue of the sparsity. With a synthetic dataset, we first evalua
&lt;/p&gt;</description></item></channel></rss>