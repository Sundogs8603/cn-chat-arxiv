<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#29992;&#20110;&#26174;&#24335;&#22320;&#24314;&#27169;&#23618;&#27425;&#21270;&#22810;&#20852;&#36259;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#23618;&#27425;&#32858;&#31867;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#26469;&#25366;&#25496;&#23618;&#27425;&#21270;&#30340;&#22810;&#20852;&#36259;&#20449;&#24687;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01253</link><description>&lt;p&gt;
HimiRec: &#24314;&#27169;&#23618;&#27425;&#21270;&#22810;&#20852;&#36259;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
HimiRec: Modeling Hierarchical Multi-interest for Recommendation
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01253
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#29992;&#20110;&#26174;&#24335;&#22320;&#24314;&#27169;&#23618;&#27425;&#21270;&#22810;&#20852;&#36259;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#36890;&#36807;&#23618;&#27425;&#32858;&#31867;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#26469;&#25366;&#25496;&#23618;&#27425;&#21270;&#30340;&#22810;&#20852;&#36259;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#19994;&#32423;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#21253;&#21547;&#26816;&#32034;&#38454;&#27573;&#21644;&#25490;&#21517;&#38454;&#27573;&#65292;&#20197;&#22788;&#29702;&#20159;&#32423;&#29992;&#25143;&#21644;&#29289;&#21697;&#12290;&#26816;&#32034;&#38454;&#27573;&#29992;&#20110;&#26816;&#32034;&#19982;&#29992;&#25143;&#20852;&#36259;&#30456;&#20851;&#30340;&#20505;&#36873;&#29289;&#21697;&#36827;&#34892;&#25512;&#33616;&#65292;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#32463;&#24120;&#24773;&#20917;&#19979;&#65292;&#29992;&#25143;&#23637;&#31034;&#20986;&#23618;&#27425;&#21270;&#30340;&#22810;&#20010;&#20852;&#36259;&#65292;&#27604;&#22914;&#19968;&#20010;&#22312;&#20307;&#32946;&#20013;&#28909;&#34935;&#25903;&#25345;&#37329;&#24030;&#21191;&#22763;&#38431;&#30340;&#29992;&#25143;&#65292;&#20063;&#20250;&#23545;&#20960;&#20046;&#25152;&#26377;&#21160;&#30011;&#26377;&#20852;&#36259;&#65292;&#20307;&#32946;&#21644;&#21160;&#30011;&#22788;&#20110;&#21516;&#26679;&#30340;&#23618;&#27425;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#38544;&#24335;&#22320;&#23398;&#20064;&#36825;&#31181;&#23618;&#27425;&#21270;&#24046;&#24322;&#65292;&#23548;&#33268;&#26356;&#32454;&#31890;&#24230;&#30340;&#20852;&#36259;&#20449;&#24687;&#34987;&#24179;&#22343;&#21270;&#65292;&#38480;&#21046;&#20102;&#23545;&#29992;&#25143;&#22312;&#28909;&#38376;&#20852;&#36259;&#21644;&#20854;&#20182;&#36731;&#20852;&#36259;&#26041;&#38754;&#30340;&#35814;&#32454;&#29702;&#35299;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#29992;&#20110;&#26174;&#24335;&#22320;&#24314;&#27169;&#23618;&#27425;&#21270;&#22810;&#20852;&#36259;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#25105;&#20204;&#20351;&#29992;&#23618;&#27425;&#32858;&#31867;&#21644;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#26469;&#25366;&#25496;&#23618;&#27425;&#21270;&#30340;&#22810;&#20852;&#36259;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Industrial recommender systems usually consist of the retrieval stage and the ranking stage, to handle the billion-scale of users and items. The retrieval stage retrieves candidate items relevant to user interests for recommendations and has attracted much attention. Frequently, users show hierarchical multi-interests reflected in a heavy user of a certain NBA team Golden State Warriors in Sports, who is also a light user of almost the whole Animation. Both Sports and Animation are at the same level. However, most existing methods implicitly learn this hierarchical difference, making more fine-grained interest information to be averaged and limiting detailed understanding of the user's different needs in heavy interests and other light interests. Therefore, we propose a novel two-stage approach to explicitly modeling hierarchical multi-interest for recommendation in this work. In the first hierarchical multi-interest mining stage, the hierarchical clustering and transformer-based model
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26816;&#27979;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#35875;&#35328;&#30340;&#21487;&#34892;&#24615;&#12290;&#36890;&#36807;&#35774;&#35745;&#25552;&#31034;&#26469;&#25945;&#23548;LLMs&#29702;&#35299;&#26032;&#38395;&#21644;&#35780;&#35770;&#20013;&#30340;&#20851;&#38190;&#32447;&#32034;&#65292;&#24182;&#23558;&#20256;&#25773;&#20449;&#24687;&#20998;&#35299;&#20026;&#20256;&#25773;&#38142;&#65292;&#25105;&#20204;&#30340;LeRuD&#26041;&#27861;&#30456;&#23545;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22312;&#35875;&#35328;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20855;&#22791;&#22312;&#23569;&#26679;&#26412;&#25110;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#26356;&#26377;&#28508;&#21147;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.03916</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#26816;&#27979;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#35875;&#35328;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models Detect Rumors on Social Media?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26816;&#27979;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#35875;&#35328;&#30340;&#21487;&#34892;&#24615;&#12290;&#36890;&#36807;&#35774;&#35745;&#25552;&#31034;&#26469;&#25945;&#23548;LLMs&#29702;&#35299;&#26032;&#38395;&#21644;&#35780;&#35770;&#20013;&#30340;&#20851;&#38190;&#32447;&#32034;&#65292;&#24182;&#23558;&#20256;&#25773;&#20449;&#24687;&#20998;&#35299;&#20026;&#20256;&#25773;&#38142;&#65292;&#25105;&#20204;&#30340;LeRuD&#26041;&#27861;&#30456;&#23545;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22312;&#35875;&#35328;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20855;&#22791;&#22312;&#23569;&#26679;&#26412;&#25110;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#26356;&#26377;&#28508;&#21147;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#36827;&#34892;&#35875;&#35328;&#26816;&#27979;&#12290;&#28982;&#32780;&#65292;LLMs&#22312;&#25512;&#29702;&#25972;&#20010;&#20256;&#25773;&#20449;&#24687;&#26102;&#38754;&#20020;&#25361;&#25112;&#65292;&#22240;&#20026;&#35813;&#20449;&#24687;&#21253;&#21547;&#26032;&#38395;&#20869;&#23481;&#21644;&#22823;&#37327;&#35780;&#35770;&#65292;LLMs&#21487;&#33021;&#26080;&#27861;&#38598;&#20013;&#20851;&#27880;&#22797;&#26434;&#20256;&#25773;&#20449;&#24687;&#20013;&#30340;&#20851;&#38190;&#32447;&#32034;&#65292;&#24182;&#19988;&#22312;&#38754;&#23545;&#22823;&#37327;&#21644;&#20887;&#20313;&#20449;&#24687;&#26102;&#38590;&#20197;&#36827;&#34892;&#25512;&#29702;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LLMs&#22686;&#24378;&#30340;&#35875;&#35328;&#26816;&#27979;&#65288;LeRuD&#65289;&#26041;&#27861;&#65292;&#22312;&#20854;&#20013;&#35774;&#35745;&#25552;&#31034;&#26469;&#25945;&#23548;LLMs&#20851;&#27880;&#26032;&#38395;&#21644;&#35780;&#35770;&#20013;&#30340;&#37325;&#35201;&#32447;&#32034;&#65292;&#24182;&#23558;&#25972;&#20010;&#20256;&#25773;&#20449;&#24687;&#20998;&#35299;&#20026;&#20256;&#25773;&#38142;&#20197;&#20943;&#36731;LLMs&#30340;&#36127;&#25285;&#12290;&#25105;&#20204;&#22312;Twitter&#21644;&#24494;&#21338;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;LeRuD&#30340;&#24615;&#33021;&#20248;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#35875;&#35328;&#26816;&#27979;&#27169;&#22411;&#65292;&#25552;&#21319;&#20102;2.4&#65285;&#33267;7.6&#65285;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#24212;&#29992;LLMs&#65292;LeRuD&#26080;&#38656;&#36827;&#34892;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#19988;&#22312;&#23569;&#26679;&#26412;&#25110;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#26356;&#20855;&#26377;&#28508;&#21147;&#30340;&#35875;&#35328;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we investigate to use Large Language Models (LLMs) for rumor detection on social media. However, it is challenging for LLMs to reason over the entire propagation information on social media, which contains news contents and numerous comments, due to LLMs may not concentrate on key clues in the complex propagation information, and have trouble in reasoning when facing massive and redundant information. Accordingly, we propose an LLM-empowered Rumor Detection (LeRuD) approach, in which we design prompts to teach LLMs to reason over important clues in news and comments, and divide the entire propagation information into a Chain-of-Propagation for reducing LLMs' burden. We conduct extensive experiments on the Twitter and Weibo datasets, and LeRuD outperforms several state-of-the-art rumor detection models by 2.4% to 7.6%. Meanwhile, by applying LLMs, LeRuD requires no data for training, and thus shows more promising rumor detection ability in few-shot or zero-shot scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#65292;&#30452;&#25509;&#26368;&#22823;&#21270;&#25351;&#26631;&#19982;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#20043;&#38388;&#30340;&#32479;&#35745;&#33021;&#21147;&#65292;&#20174;&#32780;&#20943;&#23569;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#30340;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.03915</link><description>&lt;p&gt;
&#23398;&#20064;&#26368;&#22823;&#21270;&#21152;&#36895;A/B&#27979;&#35797;&#30340;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Learning Metrics that Maximise Power for Accelerated A/B-Tests
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#65292;&#30452;&#25509;&#26368;&#22823;&#21270;&#25351;&#26631;&#19982;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#20043;&#38388;&#30340;&#32479;&#35745;&#33021;&#21147;&#65292;&#20174;&#32780;&#20943;&#23569;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25216;&#26415;&#20844;&#21496;&#20013;&#65292;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#23454;&#29616;&#33258;&#20449;&#30340;&#20915;&#31574;&#12290;&#23450;&#20041;&#20102;&#19968;&#20010;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#65288;&#22914;&#38271;&#26399;&#25910;&#20837;&#25110;&#29992;&#25143;&#20445;&#30041;&#65289;&#65292;&#22312;A/B&#27979;&#35797;&#20013;&#65292;&#33021;&#22815;&#22312;&#36825;&#20010;&#25351;&#26631;&#19978;&#26377;&#32479;&#35745;&#26174;&#33879;&#25552;&#21319;&#30340;&#31995;&#32479;&#21464;&#20307;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20248;&#36234;&#30340;&#12290;&#28982;&#32780;&#65292;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#36890;&#24120;&#20855;&#26377;&#26102;&#24310;&#21644;&#19981;&#25935;&#24863;&#24615;&#12290;&#22240;&#27492;&#65292;&#23454;&#39564;&#30340;&#25104;&#26412;&#24456;&#39640;&#65306;&#23454;&#39564;&#38656;&#35201;&#38271;&#26102;&#38388;&#36816;&#34892;&#65292;&#21363;&#20351;&#22914;&#27492;&#65292;&#20108;&#31867;&#38169;&#35823;&#65288;&#21363;&#20551;&#38452;&#24615;&#65289;&#20173;&#28982;&#26222;&#36941;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#25351;&#26631;&#30452;&#25509;&#26368;&#22823;&#21270;&#23427;&#20204;&#30456;&#23545;&#20110;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#25152;&#20855;&#26377;&#30340;&#32479;&#35745;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#26041;&#27861;&#23481;&#26131;&#36807;&#25311;&#21512;&#30340;&#38382;&#39064;&#65292;&#21363;&#26356;&#39640;&#30340;&#24179;&#22343;&#24230;&#37327;&#25935;&#24863;&#24615;&#24182;&#19981;&#24847;&#21619;&#30528;&#25913;&#36827;&#20102;&#20108;&#31867;&#38169;&#35823;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#26368;&#23567;&#21270;&#25351;&#26631;&#22312;&#36807;&#21435;&#23454;&#39564;&#30340;$log$&#19978;&#20135;&#29983;&#30340;$p$-value&#26469;&#35299;&#20915;&#12290;&#25105;&#20204;&#20174;&#20004;&#20010;&#31038;&#20132;&#23186;&#20307;&#24212;&#29992;&#31243;&#24207;&#20013;&#25910;&#38598;&#20102;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online controlled experiments are a crucial tool to allow for confident decision-making in technology companies. A North Star metric is defined (such as long-term revenue or user retention), and system variants that statistically significantly improve on this metric in an A/B-test can be considered superior. North Star metrics are typically delayed and insensitive. As a result, the cost of experimentation is high: experiments need to run for a long time, and even then, type-II errors (i.e. false negatives) are prevalent.   We propose to tackle this by learning metrics from short-term signals that directly maximise the statistical power they harness with respect to the North Star. We show that existing approaches are prone to overfitting, in that higher average metric sensitivity does not imply improved type-II errors, and propose to instead minimise the $p$-values a metric would have produced on a log of past experiments. We collect such datasets from two social media applications with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21487;&#25511;&#21046;&#31867;&#21035;&#22810;&#26679;&#24615;&#26694;&#26550;&#30340;&#23454;&#29992;&#30340;&#22810;&#26679;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#36890;&#36807;&#32771;&#34385;&#29992;&#25143;&#30340;&#38750;&#20132;&#20114;&#20559;&#22909;&#65292;&#25193;&#22823;&#29992;&#25143;&#30340;&#20852;&#36259;&#33539;&#22260;&#65292;&#32531;&#35299;&#22238;&#38899;&#23460;/&#36807;&#28388;&#27873;&#25928;&#24212;&#12290;</title><link>https://arxiv.org/abs/2402.03801</link><description>&lt;p&gt;
&#23454;&#29992;&#30340;&#22810;&#26679;&#21270;&#25512;&#33616;&#31995;&#32479;&#19982;&#21487;&#25511;&#21046;&#30340;&#31867;&#21035;&#22810;&#26679;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
On Practical Diversified Recommendation with Controllable Category Diversity Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03801
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21487;&#25511;&#21046;&#31867;&#21035;&#22810;&#26679;&#24615;&#26694;&#26550;&#30340;&#23454;&#29992;&#30340;&#22810;&#26679;&#21270;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#36890;&#36807;&#32771;&#34385;&#29992;&#25143;&#30340;&#38750;&#20132;&#20114;&#20559;&#22909;&#65292;&#25193;&#22823;&#29992;&#25143;&#30340;&#20852;&#36259;&#33539;&#22260;&#65292;&#32531;&#35299;&#22238;&#38899;&#23460;/&#36807;&#28388;&#27873;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#21508;&#20010;&#34892;&#19994;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20027;&#35201;&#26159;&#36890;&#36807;&#21162;&#21147;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#36861;&#27714;&#20934;&#30830;&#24615;&#30340;&#21162;&#21147;&#19981;&#32463;&#24847;&#38388;&#24341;&#21457;&#20102;&#22238;&#38899;&#23460;/&#36807;&#28388;&#27873;&#25928;&#24212;&#12290;&#29305;&#21035;&#26159;&#22312;&#24037;&#19994;&#30028;&#65292;&#23427;&#21487;&#33021;&#25439;&#23475;&#29992;&#25143;&#30340;&#20307;&#39564;&#65292;&#38459;&#27490;&#29992;&#25143;&#35775;&#38382;&#26356;&#24191;&#27867;&#30340;&#39033;&#30446;&#12290;&#20854;&#20013;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#26159;&#32771;&#34385;&#22810;&#26679;&#24615;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#30740;&#31350;&#37117;&#30528;&#37325;&#20110;&#29992;&#25143;&#30340;&#26174;&#24335;&#20559;&#22909;&#65292;&#24456;&#23569;&#25506;&#32034;&#29992;&#25143;&#30340;&#38750;&#20132;&#20114;&#20559;&#22909;&#12290;&#36825;&#20123;&#34987;&#24573;&#35270;&#30340;&#38750;&#20132;&#20114;&#20559;&#22909;&#23545;&#20110;&#25299;&#23485;&#29992;&#25143;&#20852;&#36259;&#12289;&#32531;&#35299;&#22238;&#38899;&#23460;/&#36807;&#28388;&#27873;&#25928;&#24212;&#23588;&#20026;&#37325;&#35201;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#22522;&#20110;&#29992;&#25143;&#30340;&#21382;&#21490;&#34892;&#20026;&#23558;&#22810;&#26679;&#24615;&#23450;&#20041;&#20026;&#20004;&#20010;&#19981;&#21516;&#30340;&#23450;&#20041;&#65292;&#21363;&#29992;&#25143;&#26174;&#24335;&#22810;&#26679;&#24615;&#65288;U-diversity&#65289;&#21644;&#29992;&#25143;-&#39033;&#30446;&#38750;&#20132;&#20114;&#22810;&#26679;&#24615;&#65288;N-diversity&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#26126;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21517;&#20026;&#21487;&#25511;&#21046;&#30340;&#31867;&#21035;&#22810;&#26679;&#21270;&#26694;&#26550;&#65288;Controllable Category Dive&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have made significant strides in various industries, primarily driven by extensive efforts to enhance recommendation accuracy. However, this pursuit of accuracy has inadvertently given rise to echo chamber/filter bubble effects. Especially in industry, it could impair user's experiences and prevent user from accessing a wider range of items. One of the solutions is to take diversity into account. However, most of existing works focus on user's explicit preferences, while rarely exploring user's non-interaction preferences. These neglected non-interaction preferences are especially important for broadening user's interests in alleviating echo chamber/filter bubble effects.Therefore, in this paper, we first define diversity as two distinct definitions, i.e., user-explicit diversity (U-diversity) and user-item non-interaction diversity (N-diversity) based on user historical behaviors. Then, we propose a succinct and effective method, named as Controllable Category Dive
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36719;&#20214;&#38382;&#31572;&#32593;&#31449;&#20013;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#30340;&#36328;&#27169;&#24577;&#26631;&#31614;&#25512;&#33616;&#27169;&#22411;&#65288;RACM&#65289;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#26816;&#32034;&#20449;&#24687;&#26469;&#22686;&#24378;&#19981;&#21516;&#27169;&#24577;&#30340;&#34920;&#31034;&#65292;&#36890;&#36807;&#36328;&#27169;&#24577;&#19978;&#19979;&#25991;&#24863;&#30693;&#27880;&#24847;&#21147;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#29305;&#24449;&#25552;&#21462;&#65292;&#24182;&#36890;&#36807;&#38376;&#26426;&#21046;&#23454;&#29616;&#31934;&#32454;&#30340;&#29305;&#24449;&#34701;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.03635</link><description>&lt;p&gt;
&#22312;&#36719;&#20214;&#38382;&#31572;&#32593;&#31449;&#20013;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#30340;&#36328;&#27169;&#24577;&#26631;&#31614;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Retrieval Augmented Cross-Modal Tag Recommendation in Software Q&amp;A Sites
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03635
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36719;&#20214;&#38382;&#31572;&#32593;&#31449;&#20013;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#30340;&#36328;&#27169;&#24577;&#26631;&#31614;&#25512;&#33616;&#27169;&#22411;&#65288;RACM&#65289;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#26816;&#32034;&#20449;&#24687;&#26469;&#22686;&#24378;&#19981;&#21516;&#27169;&#24577;&#30340;&#34920;&#31034;&#65292;&#36890;&#36807;&#36328;&#27169;&#24577;&#19978;&#19979;&#25991;&#24863;&#30693;&#27880;&#24847;&#21147;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#29305;&#24449;&#25552;&#21462;&#65292;&#24182;&#36890;&#36807;&#38376;&#26426;&#21046;&#23454;&#29616;&#31934;&#32454;&#30340;&#29305;&#24449;&#34701;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#38382;&#31572;&#32593;&#31449;&#20013;&#30340;&#24086;&#23376;&#36890;&#24120;&#21253;&#21547;&#26631;&#39064;&#12289;&#25551;&#36848;&#21644;&#20195;&#30721;&#19977;&#20010;&#20027;&#35201;&#37096;&#20998;&#65292;&#23427;&#20204;&#30456;&#20114;&#20851;&#32852;&#24182;&#20849;&#21516;&#25551;&#36848;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#26631;&#31614;&#25512;&#33616;&#26041;&#27861;&#36890;&#24120;&#23558;&#19981;&#21516;&#30340;&#27169;&#24577;&#35270;&#20026;&#25972;&#20307;&#65292;&#25110;&#32773;&#19981;&#20805;&#20998;&#32771;&#34385;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#20391;&#37325;&#20110;&#30452;&#25509;&#20174;&#24086;&#23376;&#26412;&#36523;&#25552;&#21462;&#20449;&#24687;&#65292;&#24573;&#30053;&#20102;&#26469;&#33258;&#22806;&#37096;&#30693;&#35782;&#28304;&#30340;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36719;&#20214;&#38382;&#31572;&#32593;&#31449;&#20013;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#30340;&#36328;&#27169;&#24577;&#26631;&#31614;&#25512;&#33616;&#27169;&#22411;&#65288;RACM&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#36755;&#20837;&#30340;&#24086;&#23376;&#20316;&#20026;&#26597;&#35810;&#65292;&#24182;&#36890;&#36807;&#20174;&#22806;&#37096;&#30693;&#35782;&#28304;&#20013;&#26816;&#32034;&#20449;&#24687;&#26469;&#22686;&#24378;&#19981;&#21516;&#27169;&#24577;&#30340;&#34920;&#31034;&#12290;&#23545;&#20110;&#26816;&#32034;&#22686;&#24378;&#30340;&#34920;&#31034;&#65292;&#25105;&#20204;&#37319;&#29992;&#36328;&#27169;&#24577;&#19978;&#19979;&#25991;&#24863;&#30693;&#27880;&#24847;&#21147;&#26469;&#21033;&#29992;&#20027;&#35201;&#27169;&#24577;&#25551;&#36848;&#23545;&#26631;&#39064;&#21644;&#20195;&#30721;&#23376;&#27169;&#24577;&#36827;&#34892;&#26377;&#38024;&#23545;&#24615;&#30340;&#29305;&#24449;&#25552;&#21462;&#12290;&#22312;&#34701;&#21512;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#38376;&#26426;&#21046;&#26469;&#23454;&#29616;&#31934;&#32454;&#30340;&#29305;&#24449;&#34701;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Posts in software Q\&amp;A sites often consist of three main parts: title, description and code, which are interconnected and jointly describe the question. Existing tag recommendation methods often treat different modalities as a whole or inadequately consider the interaction between different modalities. Additionally, they focus on extracting information directly from the post itself, neglecting the information from external knowledge sources. Therefore, we propose a Retrieval Augmented Cross-Modal (RACM) Tag Recommendation Model in Software Q\&amp;A Sites. Specifically, we first use the input post as a query and enhance the representation of different modalities by retrieving information from external knowledge sources. For the retrieval-augmented representations, we employ a cross-modal context-aware attention to leverage the main modality description for targeted feature extraction across the submodalities title and code. In the fusion process, a gate mechanism is employed to achieve fine
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#28151;&#21512;&#24037;&#20316;&#22330;&#25152;&#25552;&#20379;&#26234;&#33021;&#20915;&#31574;&#25903;&#25345;&#30340;&#20915;&#31574;&#25903;&#25345;&#27169;&#22411;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#29992;&#25143;&#30740;&#31350;&#21644;&#35780;&#20272;&#65292;&#21457;&#29616;LLMs&#22312;&#25552;&#20379;&#36866;&#24403;&#24037;&#20316;&#21306;&#24314;&#35758;&#26041;&#38754;&#20855;&#26377;&#36229;&#36234;&#25552;&#31034;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#25552;&#39640;&#24037;&#20316;&#32773;&#30340;&#24037;&#20316;&#20307;&#39564;&#12290;</title><link>https://arxiv.org/abs/2402.03616</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#28151;&#21512;&#24037;&#20316;&#22330;&#25152;&#20915;&#31574;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models for Hybrid Workplace Decision Support
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03616
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#28151;&#21512;&#24037;&#20316;&#22330;&#25152;&#25552;&#20379;&#26234;&#33021;&#20915;&#31574;&#25903;&#25345;&#30340;&#20915;&#31574;&#25903;&#25345;&#27169;&#22411;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#29992;&#25143;&#30740;&#31350;&#21644;&#35780;&#20272;&#65292;&#21457;&#29616;LLMs&#22312;&#25552;&#20379;&#36866;&#24403;&#24037;&#20316;&#21306;&#24314;&#35758;&#26041;&#38754;&#20855;&#26377;&#36229;&#36234;&#25552;&#31034;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#25552;&#39640;&#24037;&#20316;&#32773;&#30340;&#24037;&#20316;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20855;&#26377;&#25191;&#34892;&#21508;&#31181;&#25991;&#26412;&#22788;&#29702;&#20219;&#21153;&#24182;&#20026;&#25552;&#35758;&#30340;&#25805;&#20316;&#25110;&#20915;&#31574;&#25552;&#20379;&#25991;&#26412;&#35299;&#37322;&#30340;&#28508;&#21147;&#12290;&#22312;&#28151;&#21512;&#24037;&#20316;&#26102;&#20195;&#65292;LLMs&#21487;&#20197;&#20026;&#35774;&#35745;&#28151;&#21512;&#24037;&#20316;&#35745;&#21010;&#30340;&#24037;&#20316;&#32773;&#25552;&#20379;&#26234;&#33021;&#20915;&#31574;&#25903;&#25345;&#12290;&#29305;&#21035;&#26159;&#23427;&#20204;&#21487;&#20197;&#20026;&#24179;&#34913;&#20247;&#22810;&#20915;&#31574;&#22240;&#32032;&#30340;&#24037;&#20316;&#32773;&#25552;&#20379;&#24314;&#35758;&#21644;&#35299;&#37322;&#65292;&#20174;&#32780;&#22686;&#24378;&#20182;&#20204;&#30340;&#24037;&#20316;&#20307;&#39564;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#28151;&#21512;&#24037;&#20316;&#29615;&#22659;&#20013;&#24037;&#20316;&#21306;&#20915;&#31574;&#25903;&#25345;&#27169;&#22411;&#65292;&#21033;&#29992;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;LLMs&#23545;&#20110;&#25552;&#20379;&#36866;&#24403;&#24037;&#20316;&#21306;&#24314;&#35758;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20854;&#25512;&#29702;&#33021;&#21147;&#36229;&#36234;&#20102;&#25552;&#31034;&#20013;&#30340;&#25351;&#23548;&#26041;&#38024;&#65292;LLMs&#21487;&#20197;&#22312;&#24037;&#20316;&#21306;&#36164;&#28304;&#30340;&#21487;&#29992;&#24615;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#29992;&#25143;&#30740;&#31350;&#65292;&#20197;&#20102;&#35299;&#24037;&#20316;&#32773;&#22312;&#24037;&#20316;&#21306;&#36873;&#25321;&#19978;&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#35780;&#20272;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#24037;&#20316;&#32773;&#30340;&#20915;&#31574;&#21487;&#33021;&#21463;&#21040;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) hold the potential to perform a variety of text processing tasks and provide textual explanations for proposed actions or decisions. In the era of hybrid work, LLMs can provide intelligent decision support for workers who are designing their hybrid work plans. In particular, they can offer suggestions and explanations to workers balancing numerous decision factors, thereby enhancing their work experience. In this paper, we present a decision support model for workspaces in hybrid work environments, leveraging the reasoning skill of LLMs. We first examine LLM's capability of making suitable workspace suggestions. We find that its reasoning extends beyond the guidelines in the prompt and the LLM can manage the trade-off among the available resources in the workspaces. We conduct an extensive user study to understand workers' decision process for workspace choices and evaluate the effectiveness of the system. We observe that a worker's decision could be influe
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23545;&#28857;&#20987;&#29575;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#29305;&#24449;&#32423;&#21035;&#20559;&#24046;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#24182;&#21457;&#29616;&#32447;&#24615;&#32452;&#20214;&#23545;&#20559;&#24046;&#36129;&#29486;&#26368;&#22823;&#65292;&#23454;&#39564;&#35777;&#26126;&#27491;&#26679;&#26412;&#27604;&#29575;&#19981;&#24179;&#34913;&#26159;&#23548;&#33268;&#29305;&#24449;&#32423;&#21035;&#20559;&#24046;&#30340;&#37325;&#35201;&#22240;&#32032;&#12290;</title><link>https://arxiv.org/abs/2402.03600</link><description>&lt;p&gt;
&#29702;&#35299;&#21644;&#23545;&#25239;&#28857;&#20987;&#29575;&#39044;&#27979;&#20013;&#30340;&#29305;&#24449;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Understanding and Counteracting Feature-Level Bias in Click-Through Rate Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03600
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23545;&#28857;&#20987;&#29575;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#29305;&#24449;&#32423;&#21035;&#20559;&#24046;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#24182;&#21457;&#29616;&#32447;&#24615;&#32452;&#20214;&#23545;&#20559;&#24046;&#36129;&#29486;&#26368;&#22823;&#65292;&#23454;&#39564;&#35777;&#26126;&#27491;&#26679;&#26412;&#27604;&#29575;&#19981;&#24179;&#34913;&#26159;&#23548;&#33268;&#29305;&#24449;&#32423;&#21035;&#20559;&#24046;&#30340;&#37325;&#35201;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#35265;&#30340;&#28857;&#20987;&#29575;&#39044;&#27979;&#25512;&#33616;&#27169;&#22411;&#24448;&#24448;&#23384;&#22312;&#29305;&#24449;&#32423;&#21035;&#30340;&#20559;&#24046;&#65292;&#23548;&#33268;&#19981;&#20844;&#24179;&#30340;&#25512;&#33616;&#21644;&#23545;&#29992;&#25143;&#30340;&#19981;&#20934;&#30830;&#25512;&#33616;&#12290;&#34429;&#28982;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#35843;&#25972;CTR&#27169;&#22411;&#30340;&#23398;&#20064;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20363;&#22914;&#36890;&#36807;&#39069;&#22806;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#20294;&#23427;&#20204;&#26410;&#32771;&#34385;&#36825;&#20123;&#27169;&#22411;&#20869;&#37096;&#26159;&#22914;&#20309;&#24341;&#36215;&#20559;&#24046;&#30340;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#23545;&#20195;&#34920;&#24615;&#30340;CTR&#27169;&#22411;&#36827;&#34892;&#20102;&#33258;&#19978;&#32780;&#19979;&#30340;&#20998;&#26512;&#12290;&#36890;&#36807;&#36880;&#20010;&#38459;&#22622;&#35757;&#32451;&#22909;&#30340;CTR&#27169;&#22411;&#30340;&#19981;&#21516;&#32452;&#20214;&#65292;&#25105;&#20204;&#30830;&#23450;&#32447;&#24615;&#32452;&#20214;&#23545;&#29305;&#24449;&#32423;&#21035;&#20559;&#24046;&#30340;&#20851;&#38190;&#36129;&#29486;&#12290;&#25105;&#20204;&#23545;&#32447;&#24615;&#32452;&#20214;&#20013;&#26435;&#37325;&#30340;&#23398;&#20064;&#36807;&#31243;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#35757;&#32451;&#25968;&#25454;&#30340;&#32676;&#32452;&#23646;&#24615;&#22914;&#20309;&#24433;&#21709;&#26435;&#37325;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#21644;&#32479;&#35745;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#29289;&#21697;&#32452;&#20043;&#38388;&#19981;&#24179;&#34913;&#30340;&#27491;&#26679;&#26412;&#27604;&#29575;&#19982;&#29305;&#24449;&#32423;&#21035;&#20559;&#24046;&#20043;&#38388;&#23384;&#22312;&#24378;&#30456;&#20851;&#24615;&#12290;&#22522;&#20110;&#36825;&#31181;&#29702;&#35299;&#65292;
&lt;/p&gt;
&lt;p&gt;
Common click-through rate (CTR) prediction recommender models tend to exhibit feature-level bias, which leads to unfair recommendations among item groups and inaccurate recommendations for users. While existing methods address this issue by adjusting the learning of CTR models, such as through additional optimization objectives, they fail to consider how the bias is caused within these models. To address this research gap, our study performs a top-down analysis on representative CTR models. Through blocking different components of a trained CTR model one by one, we identify the key contribution of the linear component to feature-level bias. We conduct a theoretical analysis of the learning process for the weights in the linear component, revealing how group-wise properties of training data influence them. Our experimental and statistical analyses demonstrate a strong correlation between imbalanced positive sample ratios across item groups and feature-level bias. Based on this understan
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#19968;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#22312;&#35782;&#21035;&#36991;&#23381;&#33647;&#20999;&#25442;&#21407;&#22240;&#19978;&#30340;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;GPT-4&#21487;&#20197;&#20934;&#30830;&#22320;&#20174;&#20020;&#24202;&#35760;&#24405;&#20013;&#25552;&#21462;&#36991;&#23381;&#33647;&#20999;&#25442;&#30340;&#21407;&#22240;&#65292;&#30456;&#36739;&#20110;&#22522;&#20934;BERT&#27169;&#22411;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.03597</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#23454;&#38469;&#25968;&#25454;&#20013;&#35782;&#21035;&#36991;&#23381;&#33647;&#20999;&#25442;&#30340;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
Identifying Reasons for Contraceptive Switching from Real-World Data Using Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#19968;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#22312;&#35782;&#21035;&#36991;&#23381;&#33647;&#20999;&#25442;&#21407;&#22240;&#19978;&#30340;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;GPT-4&#21487;&#20197;&#20934;&#30830;&#22320;&#20174;&#20020;&#24202;&#35760;&#24405;&#20013;&#25552;&#21462;&#36991;&#23381;&#33647;&#20999;&#25442;&#30340;&#21407;&#22240;&#65292;&#30456;&#36739;&#20110;&#22522;&#20934;BERT&#27169;&#22411;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22788;&#26041;&#36991;&#23381;&#33647;&#22312;&#25903;&#25345;&#22919;&#22899;&#29983;&#27542;&#20581;&#24247;&#26041;&#38754;&#25198;&#28436;&#30528;&#20851;&#38190;&#35282;&#33394;&#12290;&#22312;&#32654;&#22269;&#26377;&#23558;&#36817;5000&#19975;&#22899;&#24615;&#20351;&#29992;&#36991;&#23381;&#33647;&#65292;&#20102;&#35299;&#23548;&#33268;&#36991;&#23381;&#33647;&#36873;&#25321;&#21644;&#20999;&#25442;&#30340;&#22240;&#32032;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#19982;&#33647;&#29289;&#20999;&#25442;&#30456;&#20851;&#30340;&#35768;&#22810;&#22240;&#32032;&#36890;&#24120;&#21482;&#22312;&#26080;&#32467;&#26500;&#30340;&#20020;&#24202;&#35760;&#24405;&#20013;&#24471;&#21040;&#25429;&#33719;&#65292;&#24182;&#19988;&#24456;&#38590;&#25552;&#21462;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#26368;&#36817;&#24320;&#21457;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#65288;&#36890;&#36807;&#31526;&#21512;HIPAA&#30340;Microsoft Azure API&#65289;&#30340;&#38646;-shot&#33021;&#21147;&#65292;&#20197;&#20174;UCSF&#20449;&#24687;&#20849;&#20139;&#24179;&#21488;&#30340;&#20020;&#24202;&#35760;&#24405;&#25968;&#25454;&#38598;&#20013;&#35782;&#21035;&#36991;&#23381;&#33647;&#31867;&#21035;&#20999;&#25442;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;GPT-4&#21487;&#20197;&#20934;&#30830;&#22320;&#25552;&#21462;&#36991;&#23381;&#33647;&#20999;&#25442;&#30340;&#21407;&#22240;&#65292;&#30456;&#36739;&#20110;&#22522;&#20934;BERT&#27169;&#22411;&#65292;&#22312;&#36991;&#23381;&#33647;&#24320;&#22987;&#21644;&#20572;&#27490;&#25552;&#21462;&#26041;&#38754;&#30340;microF1&#20998;&#25968;&#20998;&#21035;&#20026;0.849&#21644;0.881&#12290;&#23545;&#20110;GPT-4&#25552;&#21462;&#30340;&#20999;&#25442;&#21407;&#22240;&#30340;&#20154;&#24037;&#35780;&#20272;&#26174;&#31034;&#20986;91.4%&#30340;&#20934;&#30830;&#24230;&#65292;&#20986;&#29616;&#24187;&#35273;&#30340;&#24773;&#20917;&#24456;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prescription contraceptives play a critical role in supporting women's reproductive health. With nearly 50 million women in the United States using contraceptives, understanding the factors that drive contraceptives selection and switching is of significant interest. However, many factors related to medication switching are often only captured in unstructured clinical notes and can be difficult to extract. Here, we evaluate the zero-shot abilities of a recently developed large language model, GPT-4 (via HIPAA-compliant Microsoft Azure API), to identify reasons for switching between classes of contraceptives from the UCSF Information Commons clinical notes dataset. We demonstrate that GPT-4 can accurately extract reasons for contraceptive switching, outperforming baseline BERT-based models with microF1 scores of 0.849 and 0.881 for contraceptive start and stop extraction, respectively. Human evaluation of GPT-4-extracted reasons for switching showed 91.4% accuracy, with minimal hallucin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#20020;&#24202;&#25968;&#25454;&#20013;&#33043;&#27602;&#30151;&#30340;&#26089;&#26399;&#21457;&#20316;&#65292;&#36890;&#36807;&#20351;&#29992;&#26377;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#35757;&#32451;XGBoost&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#35268;&#33539;&#21270;&#25928;&#29992;&#20998;&#25968;&#35780;&#20272;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.03486</link><description>&lt;p&gt;
&#20020;&#24202;&#29615;&#22659;&#20013;&#26089;&#26399;&#39044;&#27979;&#33043;&#27602;&#30151;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Early prediction of onset of sepsis in Clinical Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03486
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#20020;&#24202;&#25968;&#25454;&#20013;&#33043;&#27602;&#30151;&#30340;&#26089;&#26399;&#21457;&#20316;&#65292;&#36890;&#36807;&#20351;&#29992;&#26377;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#35757;&#32451;XGBoost&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#35268;&#33539;&#21270;&#25928;&#29992;&#20998;&#25968;&#35780;&#20272;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#26469;&#33258;&#32445;&#32422;&#24067;&#26391;&#20811;&#26031;Montefiore&#21307;&#30103;&#20013;&#24515;&#30340;&#21435;&#26631;&#35782;&#21270;&#20020;&#24202;&#25968;&#25454;&#65292;&#39044;&#27979;&#33043;&#27602;&#30151;&#30340;&#26089;&#26399;&#21457;&#20316;&#12290;&#37319;&#29992;&#20102;&#26377;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35757;&#32451;&#20102;&#19968;&#20010;XGBoost&#27169;&#22411;&#65292;&#20351;&#29992;&#20102;80%&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;107&#20010;&#29305;&#24449;&#65288;&#21253;&#25324;&#21407;&#22987;&#21644;&#34893;&#29983;&#29305;&#24449;&#65289;&#12290;&#38543;&#21518;&#65292;&#35813;&#27169;&#22411;&#22312;&#21097;&#20313;&#30340;20%&#30340;&#27979;&#35797;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#27169;&#22411;&#22312;&#35757;&#32451;&#38454;&#27573;&#23436;&#20840;&#26410;&#30693;&#30340;&#21069;&#30651;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#20026;&#20102;&#35780;&#20272;&#27169;&#22411;&#22312;&#20010;&#20307;&#24739;&#32773;&#27700;&#24179;&#19978;&#30340;&#24615;&#33021;&#21644;&#39044;&#27979;&#30340;&#21450;&#26102;&#24615;&#65292;&#20351;&#29992;&#20102;&#35268;&#33539;&#21270;&#25928;&#29992;&#20998;&#25968;&#65292;&#36825;&#26159;&#33043;&#27602;&#30151;&#26816;&#27979;&#20013;&#24191;&#27867;&#35748;&#21487;&#30340;&#35780;&#20998;&#26041;&#27861;&#65292;&#22914;PhysioNet Sepsis Challenge&#35770;&#25991;&#20013;&#25152;&#36848;&#12290;&#36824;&#35774;&#35745;&#20102;F1&#20540;&#12289;&#25935;&#24863;&#24615;&#12289;&#29305;&#24322;&#24615;&#21644;&#26631;&#24535;&#29575;&#31561;&#25351;&#26631;&#12290;&#35813;&#27169;&#22411;&#22312;&#27979;&#35797;&#25968;&#25454;&#19978;&#30340;&#35268;&#33539;&#21270;&#25928;&#29992;&#20998;&#25968;&#20026;0.494&#65292;&#22312;&#21069;&#30651;&#25968;&#25454;&#19978;&#30340;&#35268;&#33539;&#21270;&#25928;&#29992;&#20998;&#25968;&#20026;0.378&#65288;&#38408;&#20540;&#20026;0.3&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study proposes the use of Machine Learning models to predict the early onset of sepsis using deidentified clinical data from Montefiore Medical Center in Bronx, NY, USA. A supervised learning approach was adopted, wherein an XGBoost model was trained utilizing 80\% of the train dataset, encompassing 107 features (including the original and derived features). Subsequently, the model was evaluated on the remaining 20\% of the test data. The model was validated on prospective data that was entirely unseen during the training phase. To assess the model's performance at the individual patient level and timeliness of the prediction, a normalized utility score was employed, a widely recognized scoring methodology for sepsis detection, as outlined in the PhysioNet Sepsis Challenge paper. Metrics such as F1 Score, Sensitivity, Specificity, and Flag Rate were also devised. The model achieved a normalized utility score of 0.494 on test data and 0.378 on prospective data at threshold 0.3. The
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;PubMed&#29992;&#25143;&#26597;&#35810;&#26085;&#24535;&#26500;&#24314;&#20102;PubCLogs&#25968;&#25454;&#38598;&#65292;&#24182;&#37319;&#29992;&#20107;&#21518;&#26041;&#27861;&#35299;&#37322;&#25512;&#33616;&#30340;&#30456;&#20851;&#25991;&#31456;&#65292;&#36890;&#36807;&#35782;&#21035;&#31867;&#20284;&#25991;&#31456;&#26631;&#39064;&#20013;&#30340;&#30456;&#20851;&#35789;&#27719;&#26469;&#25552;&#20379;&#35299;&#37322;&#12290;&#36825;&#23558;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#21644;&#20020;&#24202;&#21307;&#29983;&#22312;&#25991;&#29486;&#25628;&#32034;&#20013;&#26356;&#26041;&#20415;&#22320;&#23547;&#25214;&#30456;&#20851;&#25991;&#31456;&#12290;</title><link>https://arxiv.org/abs/2402.03484</link><description>&lt;p&gt;
&#21033;&#29992;PubMed&#29992;&#25143;&#26597;&#35810;&#26085;&#24535;&#35299;&#37322;&#25512;&#33616;&#30340;&#30456;&#20851;&#25991;&#31456;
&lt;/p&gt;
&lt;p&gt;
Harnessing PubMed User Query Logs for Post Hoc Explanations of Recommended Similar Articles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;PubMed&#29992;&#25143;&#26597;&#35810;&#26085;&#24535;&#26500;&#24314;&#20102;PubCLogs&#25968;&#25454;&#38598;&#65292;&#24182;&#37319;&#29992;&#20107;&#21518;&#26041;&#27861;&#35299;&#37322;&#25512;&#33616;&#30340;&#30456;&#20851;&#25991;&#31456;&#65292;&#36890;&#36807;&#35782;&#21035;&#31867;&#20284;&#25991;&#31456;&#26631;&#39064;&#20013;&#30340;&#30456;&#20851;&#35789;&#27719;&#26469;&#25552;&#20379;&#35299;&#37322;&#12290;&#36825;&#23558;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#21644;&#20020;&#24202;&#21307;&#29983;&#22312;&#25991;&#29486;&#25628;&#32034;&#20013;&#26356;&#26041;&#20415;&#22320;&#23547;&#25214;&#30456;&#20851;&#25991;&#31456;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#30740;&#31350;&#20013;&#65292;&#22522;&#20110;&#24341;&#29992;&#25991;&#31456;&#23547;&#25214;&#30456;&#20851;&#25991;&#31456;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#37096;&#20998;&#12290;&#20687;&#35768;&#22810;&#23398;&#26415;&#25628;&#32034;&#24341;&#25806;&#19968;&#26679;&#65292;PubMed&#25317;&#26377;&#19968;&#20010;&#8220;&#31867;&#20284;&#25991;&#31456;&#8221;&#30340;&#21151;&#33021;&#65292;&#21487;&#20197;&#25512;&#33616;&#19982;&#29992;&#25143;&#26597;&#30475;&#30340;&#24403;&#21069;&#25991;&#31456;&#30456;&#20851;&#30340;&#25991;&#31456;&#12290;&#35299;&#37322;&#25512;&#33616;&#30340;&#25991;&#31456;&#23545;&#29992;&#25143;&#26469;&#35828;&#38750;&#24120;&#26377;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#25991;&#29486;&#25628;&#32034;&#36807;&#31243;&#20013;&#12290;&#37492;&#20110;&#27599;&#24180;&#26377;&#36229;&#36807;&#19968;&#30334;&#19975;&#31687;&#29983;&#29289;&#21307;&#23398;&#35770;&#25991;&#21457;&#34920;&#65292;&#35299;&#37322;&#25512;&#33616;&#30340;&#30456;&#20851;&#25991;&#31456;&#23558;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#20020;&#24202;&#21307;&#29983;&#22312;&#23547;&#25214;&#30456;&#20851;&#25991;&#31456;&#26102;&#25552;&#20379;&#20415;&#21033;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#22823;&#22810;&#25968;&#25991;&#29486;&#25512;&#33616;&#31995;&#32479;&#37117;&#32570;&#20047;&#23545;&#20854;&#24314;&#35758;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#37319;&#29992;&#20107;&#21518;&#26041;&#27861;&#26469;&#35299;&#37322;&#25512;&#33616;&#65292;&#36890;&#36807;&#35782;&#21035;&#31867;&#20284;&#25991;&#31456;&#26631;&#39064;&#20013;&#30340;&#30456;&#20851;&#35789;&#27719;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#36890;&#36807;&#37325;&#26032;&#21033;&#29992;PubMed&#29992;&#25143;&#26597;&#35810;&#26085;&#24535;&#20013;&#30340;560&#19975;&#20010;&#20849;&#28857;&#20987;&#25991;&#31456;&#23545;&#26500;&#24314;PubCLogs&#25968;&#25454;&#38598;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;PubCLogs&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;"Highlight Similar Article Title"&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Searching for a related article based on a reference article is an integral part of scientific research. PubMed, like many academic search engines, has a "similar articles" feature that recommends articles relevant to the current article viewed by a user. Explaining recommended items can be of great utility to users, particularly in the literature search process. With more than a million biomedical papers being published each year, explaining the recommended similar articles would facilitate researchers and clinicians in searching for related articles. Nonetheless, the majority of current literature recommendation systems lack explanations for their suggestions. We employ a post hoc approach to explaining recommendations by identifying relevant tokens in the titles of similar articles. Our major contribution is building PubCLogs by repurposing 5.6 million pairs of coclicked articles from PubMed's user query logs. Using our PubCLogs dataset, we train the Highlight Similar Article Title 
&lt;/p&gt;</description></item><item><title>FINEST&#26041;&#27861;&#36890;&#36807;&#20174;&#32473;&#23450;&#30340;&#25512;&#33616;&#27169;&#22411;&#33719;&#24471;&#21442;&#32771;&#25490;&#24207;&#21015;&#34920;&#65292;&#24182;&#22312;&#27169;&#25311;&#30340;&#25200;&#21160;&#22330;&#26223;&#19979;&#36827;&#34892;&#27169;&#22411;&#24494;&#35843;&#65292;&#20445;&#25345;&#25490;&#24207;&#65292;&#20197;&#31283;&#23450;&#21644;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.03481</link><description>&lt;p&gt;
FINEST: &#36890;&#36807;&#20445;&#25345;&#25490;&#24207;&#36827;&#34892;&#24494;&#35843;&#20197;&#31283;&#23450;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
FINEST: Stabilizing Recommendations by Rank-Preserving Fine-Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03481
&lt;/p&gt;
&lt;p&gt;
FINEST&#26041;&#27861;&#36890;&#36807;&#20174;&#32473;&#23450;&#30340;&#25512;&#33616;&#27169;&#22411;&#33719;&#24471;&#21442;&#32771;&#25490;&#24207;&#21015;&#34920;&#65292;&#24182;&#22312;&#27169;&#25311;&#30340;&#25200;&#21160;&#22330;&#26223;&#19979;&#36827;&#34892;&#27169;&#22411;&#24494;&#35843;&#65292;&#20445;&#25345;&#25490;&#24207;&#65292;&#20197;&#31283;&#23450;&#21644;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#21487;&#33021;&#20250;&#22240;&#20026;&#35757;&#32451;&#25968;&#25454;&#30340;&#24494;&#23567;&#25200;&#21160;&#32780;&#36755;&#20986;&#22823;&#19981;&#30456;&#21516;&#30340;&#25512;&#33616;&#32467;&#26524;&#12290;&#21333;&#20010;&#29992;&#25143;&#25968;&#25454;&#30340;&#25913;&#21464;&#20250;&#25913;&#21464;&#20854;&#20182;&#29992;&#25143;&#30340;&#25512;&#33616;&#32467;&#26524;&#12290;&#22312;&#21307;&#30103;&#12289;&#20303;&#25151;&#21644;&#37329;&#34701;&#31561;&#24212;&#29992;&#20013;&#65292;&#36825;&#31181;&#25935;&#24863;&#24615;&#21487;&#33021;&#23545;&#29992;&#25143;&#20307;&#39564;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#31283;&#23450;&#32473;&#23450;&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#25269;&#25239;&#36825;&#31181;&#25200;&#21160;&#12290;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;(1)&#32570;&#20047;&#21487;&#20197;&#29992;&#26469;&#38170;&#23450;&#36755;&#20986;&#30340;&#8220;&#21442;&#32771;&#8221;&#25490;&#24207;&#21015;&#34920;&#65307;(2)&#22312;&#20445;&#35777;&#27169;&#22411;&#19982;&#35757;&#32451;&#25968;&#25454;&#30340;&#25152;&#26377;&#21487;&#33021;&#25200;&#21160;&#30340;&#25490;&#24207;&#21015;&#34920;&#31283;&#23450;&#24615;&#26041;&#38754;&#23384;&#22312;&#35745;&#31639;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;FINEST&#36890;&#36807;&#20174;&#32473;&#23450;&#30340;&#25512;&#33616;&#27169;&#22411;&#33719;&#24471;&#21442;&#32771;&#25490;&#24207;&#21015;&#34920;&#65292;&#28982;&#21518;&#22312;&#27169;&#25311;&#30340;&#25200;&#21160;&#22330;&#26223;&#19979;&#36827;&#34892;&#27169;&#22411;&#24494;&#35843;&#65292;&#24182;&#20445;&#25345;&#25490;&#24207;&#30340;&#35268;&#21017;&#21270;&#26469;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;FINEST&#21487;&#20197;&#31283;&#23450;&#25512;&#33616;&#31995;&#32479;&#24182;&#20445;&#25345;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern recommender systems may output considerably different recommendations due to small perturbations in the training data. Changes in the data from a single user will alter the recommendations as well as the recommendations of other users. In applications like healthcare, housing, and finance, this sensitivity can have adverse effects on user experience. We propose a method to stabilize a given recommender system against such perturbations. This is a challenging task due to (1) the lack of a ``reference'' rank list that can be used to anchor the outputs; and (2) the computational challenges in ensuring the stability of rank lists with respect to all possible perturbations of training data. Our method, FINEST, overcomes these challenges by obtaining reference rank lists from a given recommendation model and then fine-tuning the model under simulated perturbation scenarios with rank-preserving regularization on sampled items. Our experiments on real-world datasets demonstrate that FIN
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#31946;&#38598;&#25216;&#26415;&#30340;&#27169;&#31946;&#38142;&#25509;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#19981;&#21516;&#25968;&#25454;&#28304;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#12290;</title><link>https://arxiv.org/abs/2402.03464</link><description>&lt;p&gt;
&#19968;&#20010;&#27169;&#31946;&#26041;&#27861;&#29992;&#20110;&#35760;&#24405;&#38142;&#25509;
&lt;/p&gt;
&lt;p&gt;
A Fuzzy Approach to Record Linkages
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#31946;&#38598;&#25216;&#26415;&#30340;&#27169;&#31946;&#38142;&#25509;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#19981;&#21516;&#25968;&#25454;&#28304;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35760;&#24405;&#38142;&#25509;&#26159;&#35782;&#21035;&#21644;&#32479;&#19968;&#26469;&#33258;&#21508;&#31181;&#29420;&#31435;&#25968;&#25454;&#28304;&#30340;&#35760;&#24405;&#30340;&#36807;&#31243;&#12290;&#29616;&#26377;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#26159;&#30830;&#23450;&#24615;&#30340;&#25110;&#27010;&#29575;&#24615;&#30340;&#65292;&#36890;&#24120;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#26080;&#27861;&#20196;&#20154;&#28385;&#24847;&#22320;&#38142;&#25509;&#35760;&#24405;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#31946;&#38598;&#25216;&#26415;&#30340;&#26412;&#22320;&#24320;&#21457;&#30340;&#27169;&#31946;&#38142;&#25509;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#32771;&#34385;&#36825;&#20123;&#19981;&#21516;&#25968;&#25454;&#28304;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#12290;&#24191;&#27867;&#30340;&#27979;&#35797;&#12289;&#35780;&#20272;&#21644;&#27604;&#36739;&#24050;&#32463;&#35777;&#26126;&#20102;&#36825;&#31181;&#27169;&#31946;&#26041;&#27861;&#22312;&#35760;&#24405;&#38142;&#25509;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Record Linkage is the process of identifying and unifying records from various independent data sources. Existing strategies, which can be either deterministic or probabilistic, often fail to link records satisfactorily under uncertainty. This paper describes an indigenously (locally) developed fuzzy linkage method, based on fuzzy set techniques, which can effectively account for this uncertainty prevalent in the disparate data sources and address the shortcomings of the existing approaches. Extensive testing, evaluation and comparisons have demonstrated the efficacy of this fuzzy approach for record linkages.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#31038;&#20132;&#32593;&#32476;&#25512;&#33616;&#31995;&#32479;&#20013;&#25512;&#33616;&#20844;&#24179;&#24615;&#38543;&#26102;&#38388;&#25512;&#31227;&#32780;&#21464;&#21270;&#30340;&#24773;&#20917;&#65292;&#24182;&#19982;&#21160;&#24577;&#32593;&#32476;&#23646;&#24615;&#36827;&#34892;&#20102;&#20851;&#32852;&#20998;&#26512;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25512;&#33616;&#20844;&#24179;&#24615;&#38543;&#26102;&#38388;&#25913;&#21892;&#65292;&#32780;&#23569;&#25968;&#32676;&#20307;&#27604;&#20363;&#21644;&#21516;&#36136;&#24615;&#19982;&#20844;&#24179;&#24615;&#26377;&#20851;&#12290;</title><link>https://arxiv.org/abs/2402.03450</link><description>&lt;p&gt;
&#31038;&#20132;&#32593;&#32476;&#38543;&#26102;&#38388;&#25512;&#31227;&#20013;&#30340;&#25512;&#33616;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Recommendation Fairness in Social Networks Over Time
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#31038;&#20132;&#32593;&#32476;&#25512;&#33616;&#31995;&#32479;&#20013;&#25512;&#33616;&#20844;&#24179;&#24615;&#38543;&#26102;&#38388;&#25512;&#31227;&#32780;&#21464;&#21270;&#30340;&#24773;&#20917;&#65292;&#24182;&#19982;&#21160;&#24577;&#32593;&#32476;&#23646;&#24615;&#36827;&#34892;&#20102;&#20851;&#32852;&#20998;&#26512;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25512;&#33616;&#20844;&#24179;&#24615;&#38543;&#26102;&#38388;&#25913;&#21892;&#65292;&#32780;&#23569;&#25968;&#32676;&#20307;&#27604;&#20363;&#21644;&#21516;&#36136;&#24615;&#19982;&#20844;&#24179;&#24615;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20132;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#25512;&#33616;&#27169;&#22411;&#25552;&#20379;&#19981;&#21516;&#20154;&#21475;&#32676;&#20307;&#65288;&#22914;&#24615;&#21035;&#25110;&#31181;&#26063;&#65289;&#20844;&#24179;&#30340;&#21487;&#35265;&#24615;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#29616;&#26377;&#22823;&#22810;&#25968;&#30740;&#31350;&#21482;&#30740;&#31350;&#20102;&#32593;&#32476;&#30340;&#22266;&#23450;&#24555;&#29031;&#65292;&#32780;&#24573;&#35270;&#20102;&#32593;&#32476;&#38543;&#26102;&#38388;&#25512;&#31227;&#30340;&#21464;&#21270;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25512;&#33616;&#20844;&#24179;&#24615;&#38543;&#26102;&#38388;&#30340;&#28436;&#21464;&#21450;&#20854;&#19982;&#21160;&#24577;&#32593;&#32476;&#23646;&#24615;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#35780;&#20272;&#20845;&#31181;&#25512;&#33616;&#31639;&#27861;&#30340;&#20844;&#24179;&#24615;&#65292;&#24182;&#20998;&#26512;&#20844;&#24179;&#24615;&#19982;&#32593;&#32476;&#23646;&#24615;&#38543;&#26102;&#38388;&#30340;&#20851;&#32852;&#65292;&#26469;&#30740;&#31350;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#21160;&#24577;&#32593;&#32476;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#30740;&#31350;&#26367;&#20195;&#28436;&#21270;&#32467;&#26524;&#21644;&#19981;&#21516;&#32593;&#32476;&#23646;&#24615;&#30340;&#23545;&#29031;&#24773;&#26223;&#65292;&#26469;&#30740;&#31350;&#23545;&#32593;&#32476;&#23646;&#24615;&#30340;&#24178;&#39044;&#22914;&#20309;&#24433;&#21709;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#25968;&#25454;&#38598;&#19978;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19981;&#35770;&#25512;&#33616;&#26041;&#27861;&#22914;&#20309;&#65292;&#25512;&#33616;&#20844;&#24179;&#24615;&#38543;&#26102;&#38388;&#30340;&#25913;&#21892;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20004;&#20010;&#32593;&#32476;&#23646;&#24615;&#65292;&#23569;&#25968;&#32676;&#20307;&#27604;&#20363;&#21644;&#21516;&#36136;&#24615;&#65292;&#19982;&#20844;&#24179;&#24615;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
In social recommender systems, it is crucial that the recommendation models provide equitable visibility for different demographic groups, such as gender or race. Most existing research has addressed this problem by only studying individual static snapshots of networks that typically change over time. To address this gap, we study the evolution of recommendation fairness over time and its relation to dynamic network properties. We examine three real-world dynamic networks by evaluating the fairness of six recommendation algorithms and analyzing the association between fairness and network properties over time. We further study how interventions on network properties influence fairness by examining counterfactual scenarios with alternative evolution outcomes and differing network properties. Our results on empirical datasets suggest that recommendation fairness improves over time, regardless of the recommendation method. We also find that two network properties, minority ratio, and homo
&lt;/p&gt;</description></item><item><title>&#22312;&#39044;&#31639;&#38480;&#21046;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#20256;&#36882;&#21457;&#29616;&#34892;&#20026;&#29992;&#25143;&#32454;&#20998;&#12290;</title><link>https://arxiv.org/abs/2402.03388</link><description>&lt;p&gt;
&#22312;&#39044;&#31639;&#38480;&#21046;&#19979;&#34892;&#20026;&#29992;&#25143;&#20998;&#21106;&#20013;&#30340;&#20248;&#21270;&#20256;&#36882;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constrain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03388
&lt;/p&gt;
&lt;p&gt;
&#22312;&#39044;&#31639;&#38480;&#21046;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#20256;&#36882;&#21457;&#29616;&#34892;&#20026;&#29992;&#25143;&#32454;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#22312;&#32447;&#34892;&#20026;&#36275;&#36857;&#21487;&#20197;&#20351;&#20844;&#21496;&#21457;&#29616;&#22522;&#20110;&#34892;&#20026;&#30340;&#29992;&#25143;&#32454;&#20998;&#65292;&#24182;&#21521;&#29992;&#25143;&#21457;&#36865;&#29305;&#23450;&#32454;&#20998;&#30340;&#20449;&#24687;&#12290;&#22312;&#21457;&#29616;&#32454;&#20998;&#20043;&#21518;&#65292;&#36890;&#36807;&#20687;Facebook&#21644;Google&#36825;&#26679;&#30340;&#39318;&#36873;&#23186;&#20307;&#28192;&#36947;&#21521;&#29992;&#25143;&#21457;&#36865;&#20449;&#24687;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#21482;&#26377;&#37096;&#20998;&#34892;&#20026;&#32454;&#20998;&#20013;&#30340;&#29992;&#25143;&#22312;&#23186;&#20307;&#19978;&#25214;&#21040;&#21305;&#37197;&#65292;&#24182;&#19988;&#21482;&#26377;&#20854;&#20013;&#19968;&#23567;&#37096;&#20998;&#30475;&#21040;&#28040;&#24687;&#65288;&#26333;&#20809;&#65289;&#12290;&#21363;&#20351;&#39640;&#36136;&#37327;&#30340;&#21457;&#29616;&#20063;&#20250;&#22312;&#20256;&#36882;&#22833;&#36133;&#26102;&#21464;&#24471;&#26080;&#29992;&#12290;&#35768;&#22810;&#22797;&#26434;&#30340;&#31639;&#27861;&#29992;&#20110;&#21457;&#29616;&#34892;&#20026;&#32454;&#20998;&#65292;&#28982;&#32780;&#36825;&#20123;&#31639;&#27861;&#24573;&#30053;&#20102;&#20256;&#36882;&#32452;&#20214;&#12290;&#38382;&#39064;&#21464;&#24471;&#22797;&#26434;&#26159;&#22240;&#20026;&#65288;i&#65289;&#21457;&#29616;&#26159;&#22312;&#20844;&#21496;&#25968;&#25454;&#65288;&#20363;&#22914;&#29992;&#25143;&#28857;&#20987;&#65289;&#30340;&#34892;&#20026;&#25968;&#25454;&#31354;&#38388;&#20013;&#36827;&#34892;&#30340;&#65292;&#32780;&#20256;&#36882;&#21017;&#26159;&#22522;&#20110;&#23186;&#20307;&#23450;&#20041;&#30340;&#38745;&#24577;&#25968;&#25454;&#31354;&#38388;&#65288;&#20363;&#22914;&#22320;&#29702;&#20301;&#32622;&#65292;&#24180;&#40836;&#65289;&#36827;&#34892;&#30340;&#65307;&#65288;ii&#65289;&#20844;&#21496;&#22312;&#39044;&#31639;&#38480;&#21046;&#19979;&#36816;&#20316;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39044;&#31639;&#38480;&#21046;&#19979;&#20248;&#21270;&#20256;&#36882;&#21457;&#29616;&#34892;&#20026;&#29992;&#25143;&#32454;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Users' behavioral footprints online enable firms to discover behavior-based user segments (or, segments) and deliver segment specific messages to users. Following the discovery of segments, delivery of messages to users through preferred media channels like Facebook and Google can be challenging, as only a portion of users in a behavior segment find match in a medium, and only a fraction of those matched actually see the message (exposure). Even high quality discovery becomes futile when delivery fails. Many sophisticated algorithms exist for discovering behavioral segments; however, these ignore the delivery component. The problem is compounded because (i) the discovery is performed on the behavior data space in firms' data (e.g., user clicks), while the delivery is predicated on the static data space (e.g., geo, age) as defined by media; and (ii) firms work under budget constraint. We introduce a stochastic optimization based algorithm for delivery optimized discovery of behavioral u
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25551;&#36848;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;K-means&#32858;&#31867;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;COVID-19&#25968;&#25454;&#12290;&#36890;&#36807;&#21033;&#29992;&#20004;&#20010;&#32858;&#31867;&#20998;&#37197;&#25216;&#26415;&#19982;K-means&#27169;&#22411;&#65292;&#25552;&#21462;&#25991;&#26412;&#30340;&#26412;&#20307;&#35770;&#34987;&#25913;&#21892;&#65292;&#36827;&#19968;&#27493;&#24212;&#29992;&#30690;&#37327;&#24179;&#22343;&#38459;&#23612;&#25216;&#26415;&#20197;&#28789;&#27963;&#31227;&#21160;&#32858;&#31867;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;COVID-19&#25968;&#25454;&#19978;&#33719;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.03380</link><description>&lt;p&gt;
&#20462;&#25913;&#30340;K-means&#32858;&#31867;&#31639;&#27861; - COVID-19&#25968;&#25454;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Modified K-means with Cluster Assignment -- Application to COVID-19 Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25551;&#36848;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;K-means&#32858;&#31867;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;COVID-19&#25968;&#25454;&#12290;&#36890;&#36807;&#21033;&#29992;&#20004;&#20010;&#32858;&#31867;&#20998;&#37197;&#25216;&#26415;&#19982;K-means&#27169;&#22411;&#65292;&#25552;&#21462;&#25991;&#26412;&#30340;&#26412;&#20307;&#35770;&#34987;&#25913;&#21892;&#65292;&#36827;&#19968;&#27493;&#24212;&#29992;&#30690;&#37327;&#24179;&#22343;&#38459;&#23612;&#25216;&#26415;&#20197;&#28789;&#27963;&#31227;&#21160;&#32858;&#31867;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;COVID-19&#25968;&#25454;&#19978;&#33719;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#25552;&#21462;&#26159;&#19968;&#20010;&#39640;&#24230;&#20027;&#35266;&#30340;&#38382;&#39064;&#65292;&#21462;&#20915;&#20110;&#27491;&#22312;&#22788;&#29702;&#30340;&#25968;&#25454;&#38598;&#21644;&#38656;&#35201;&#25552;&#21462;&#20986;&#30340;&#25688;&#35201;&#32454;&#33410;&#30340;&#31181;&#31867;&#12290;&#20174;&#25968;&#25454;&#30340;&#39044;&#22788;&#29702;&#21040;&#36873;&#25321;&#26368;&#20248;&#27169;&#22411;&#36827;&#34892;&#39044;&#27979;&#30340;&#25152;&#26377;&#27493;&#39588;&#37117;&#21462;&#20915;&#20110;&#38382;&#39064;&#21644;&#25163;&#22836;&#30340;&#35821;&#26009;&#24211;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#25991;&#26412;&#25552;&#21462;&#27169;&#22411;&#65292;&#20854;&#30446;&#26631;&#26159;&#25552;&#21462;&#19982;&#35821;&#20041;&#30456;&#20851;&#30340;&#25351;&#23450;&#21333;&#35789;&#20449;&#24687;&#65292;&#20174;&#32780;&#20197;&#31616;&#27905;&#30340;&#26684;&#24335;&#33719;&#21462;&#25152;&#26377;&#30456;&#20851;&#21644;&#26377;&#24847;&#20041;&#30340;&#20449;&#24687;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#33719;&#24471;&#26377;&#24847;&#20041;&#30340;&#32467;&#26524;&#65292;&#24182;&#21487;&#20197;&#22686;&#24378;&#26222;&#36941;&#25628;&#32034;&#27169;&#22411;&#25110;&#24120;&#35268;&#32858;&#31867;&#25110;&#20027;&#39064;&#24314;&#27169;&#31639;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#31216;&#20026;&#20004;&#20010;&#32858;&#31867;&#20998;&#37197;&#25216;&#26415;&#30340;&#26032;&#25216;&#26415;&#19982;K-means&#27169;&#22411;&#65292;&#25105;&#20204;&#25913;&#21892;&#20102;&#25552;&#21462;&#25991;&#26412;&#30340;&#26412;&#20307;&#35770;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24212;&#29992;&#30690;&#37327;&#24179;&#22343;&#38459;&#23612;&#25216;&#26415;&#20197;&#28789;&#27963;&#31227;&#21160;&#32858;&#31867;&#12290;&#25105;&#20204;&#22312;&#26368;&#36817;&#30340;Covid-19&#35821;&#26009;&#24211;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Text extraction is a highly subjective problem which depends on the dataset that one is working on and the kind of summarization details that needs to be extracted out. All the steps ranging from preprocessing of the data, to the choice of an optimal model for predictions, depends on the problem and the corpus at hand. In this paper, we describe a text extraction model where the aim is to extract word specified information relating to the semantics such that we can get all related and meaningful information about that word in a succinct format. This model can obtain meaningful results and can augment ubiquitous search model or a normal clustering or topic modelling algorithms. By utilizing new technique called two cluster assignment technique with K-means model, we improved the ontology of the retrieved text. We further apply the vector average damping technique for flexible movement of clusters. Our experimental results on a recent corpus of Covid-19 shows that we obtain good results 
&lt;/p&gt;</description></item><item><title>&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#26041;&#27861;ECUP&#26088;&#22312;&#35299;&#20915;&#38142;&#36335;&#20559;&#24046;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#65292;&#22312;&#32447;&#33829;&#38144;&#20013;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2402.03379</link><description>&lt;p&gt;
&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#19982;&#19978;&#19979;&#25991;&#22686;&#24378;&#23398;&#20064;&#29992;&#20110;&#26234;&#33021;&#33829;&#38144;
&lt;/p&gt;
&lt;p&gt;
Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03379
&lt;/p&gt;
&lt;p&gt;
&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#26041;&#27861;ECUP&#26088;&#22312;&#35299;&#20915;&#38142;&#36335;&#20559;&#24046;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#65292;&#22312;&#32447;&#33829;&#38144;&#20013;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#21319;&#24314;&#27169;&#22312;&#22312;&#32447;&#33829;&#38144;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#23427;&#26088;&#22312;&#36890;&#36807;&#39044;&#27979;&#20010;&#20307;&#22788;&#29702;&#25928;&#26524;&#65288;ITE&#65289;&#26469;&#20934;&#30830;&#34913;&#37327;&#19981;&#21516;&#31574;&#30053;&#65288;&#22914;&#20248;&#24800;&#21048;&#25110;&#25240;&#25187;&#65289;&#23545;&#19981;&#21516;&#29992;&#25143;&#30340;&#24433;&#21709;&#12290;&#22312;&#30005;&#23376;&#21830;&#21153;&#29615;&#22659;&#20013;&#65292;&#29992;&#25143;&#34892;&#20026;&#36981;&#24490;&#30830;&#23450;&#30340;&#39034;&#24207;&#38142;&#36335;&#65292;&#21253;&#25324;&#23637;&#31034;&#12289;&#28857;&#20987;&#21644;&#36716;&#21270;&#12290;&#33829;&#38144;&#31574;&#30053;&#22312;&#36825;&#20010;&#38142;&#36335;&#20013;&#30340;&#27599;&#20010;&#38454;&#27573;&#37117;&#20250;&#20135;&#29983;&#19981;&#21516;&#30340;&#19978;&#21319;&#25928;&#24212;&#65292;&#24433;&#21709;&#30528;&#28857;&#20987;&#29575;&#21644;&#36716;&#21270;&#29575;&#31561;&#25351;&#26631;&#12290;&#23613;&#31649;&#20854;&#23454;&#29992;&#24615;&#65292;&#29616;&#26377;&#30740;&#31350;&#24573;&#35270;&#20102;&#29305;&#23450;&#22788;&#29702;&#20013;&#25152;&#26377;&#38454;&#27573;&#30340;&#30456;&#20114;&#24433;&#21709;&#65292;&#24182;&#26410;&#20805;&#20998;&#21033;&#29992;&#22788;&#29702;&#20449;&#24687;&#65292;&#21487;&#33021;&#32473;&#21518;&#32493;&#30340;&#33829;&#38144;&#20915;&#31574;&#24341;&#20837;&#20102;&#37325;&#22823;&#20559;&#24046;&#12290;&#26412;&#25991;&#23558;&#36825;&#20004;&#20010;&#38382;&#39064;&#31216;&#20026;&#38142;&#36335;&#20559;&#24046;&#38382;&#39064;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#20855;&#26377;&#19978;&#19979;&#25991;&#22686;&#24378;&#23398;&#20064;&#30340;&#20840;&#38142;&#36335;&#19978;&#21319;&#26041;&#27861;&#65288;ECUP&#65289;&#12290;ECUP&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#65306;
&lt;/p&gt;
&lt;p&gt;
Uplift modeling, vital in online marketing, seeks to accurately measure the impact of various strategies, such as coupons or discounts, on different users by predicting the Individual Treatment Effect (ITE). In an e-commerce setting, user behavior follows a defined sequential chain, including impression, click, and conversion. Marketing strategies exert varied uplift effects at each stage within this chain, impacting metrics like click-through and conversion rate. Despite its utility, existing research has neglected to consider the inter-task across all stages impacts within a specific treatment and has insufficiently utilized the treatment information, potentially introducing substantial bias into subsequent marketing decisions. We identify these two issues as the chain-bias problem and the treatment-unadaptive problem. This paper introduces the Entire Chain UPlift method with context-enhanced learning (ECUP), devised to tackle these issues. ECUP consists of two primary components: 1)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#33258;&#21160;&#26816;&#27979;&#31185;&#23398;&#35770;&#25991;&#20013;&#25305;&#21155;&#30701;&#35821;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#21644;&#39044;&#27979;&#20998;&#25968;&#30340;&#20256;&#25773;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#26631;&#35760;&#24182;&#25552;&#21462;&#36825;&#20123;&#25305;&#21155;&#30701;&#35821;&#65292;&#20026;&#39046;&#22495;&#19987;&#23478;&#39564;&#35777;&#25552;&#20379;&#26032;&#30340;&#25968;&#25454;&#12290;</title><link>https://arxiv.org/abs/2402.03370</link><description>&lt;p&gt;
&#26816;&#27979;&#31185;&#23398;&#25991;&#29486;&#20013;&#30340;&#25305;&#21155;&#30701;&#35821;
&lt;/p&gt;
&lt;p&gt;
Detection of tortured phrases in scientific literature
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#33258;&#21160;&#26816;&#27979;&#31185;&#23398;&#35770;&#25991;&#20013;&#25305;&#21155;&#30701;&#35821;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#21644;&#39044;&#27979;&#20998;&#25968;&#30340;&#20256;&#25773;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#26631;&#35760;&#24182;&#25552;&#21462;&#36825;&#20123;&#25305;&#21155;&#30701;&#35821;&#65292;&#20026;&#39046;&#22495;&#19987;&#23478;&#39564;&#35777;&#25552;&#20379;&#26032;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#31181;&#33258;&#21160;&#26816;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#31185;&#23398;&#35770;&#25991;&#20013;&#25552;&#21462;&#25152;&#35859;&#30340;&#25305;&#21155;&#30701;&#35821;&#12290;&#36825;&#20123;&#25305;&#21155;&#30701;&#35821;&#65292;&#20363;&#22914;&#23558;"&#20449;&#21495;&#19982;&#22122;&#22768;"&#26367;&#25442;&#20026;"&#26071;&#24092;&#19982;&#21927;&#38393;"&#65292;&#26159;&#20351;&#29992;&#25913;&#20889;&#24037;&#20855;&#35268;&#36991;&#25220;&#34989;&#26816;&#27979;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#35780;&#20272;&#20102;&#20960;&#31181;&#31574;&#30053;&#26469;&#26631;&#35760;&#20197;&#21069;&#26410;&#35760;&#24405;&#30340;&#25305;&#21155;&#30701;&#35821;&#12290;&#25552;&#20986;&#21644;&#27979;&#35797;&#30340;&#26041;&#27861;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#65292;&#35201;&#20040;&#22522;&#20110;&#23884;&#20837;&#30456;&#20284;&#24615;&#65292;&#35201;&#20040;&#22522;&#20110;&#25513;&#30721;&#26631;&#35760;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#19968;&#31181;&#20351;&#29992;&#26631;&#35760;&#39044;&#27979;&#24182;&#23558;&#20998;&#25968;&#20256;&#25773;&#21040;&#22359;&#32423;&#21035;&#30340;&#26041;&#27861;&#25928;&#26524;&#26368;&#22909;&#12290;&#20854;&#21484;&#22238;&#29575;&#20026;0.87&#65292;&#31934;&#30830;&#29575;&#20026;0.61&#65292;&#21487;&#20197;&#26816;&#32034;&#21040;&#26032;&#30340;&#25305;&#21155;&#30701;&#35821;&#20197;&#20379;&#39046;&#22495;&#19987;&#23478;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents various automatic detection methods to extract so called tortured phrases from scientific papers. These tortured phrases, e.g. flag to clamor instead of signal to noise, are the results of paraphrasing tools used to escape plagiarism detection. We built a dataset and evaluated several strategies to flag previously undocumented tortured phrases. The proposed and tested methods are based on language models and either on embeddings similarities or on predictions of masked token. We found that an approach using token prediction and that propagates the scores to the chunk level gives the best results. With a recall value of .87 and a precision value of .61, it could retrieve new tortured phrases to be submitted to domain experts for validation.
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#21512;&#35843;&#26597;&#35770;&#25991;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22823;&#25968;&#25454;&#31639;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#20998;&#23618;&#30340;&#20998;&#31867;&#27861;&#12290;&#36890;&#36807;&#35813;&#20998;&#31867;&#27861;&#65292;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#20840;&#38754;&#20102;&#35299;&#19981;&#21516;&#31639;&#27861;&#21644;&#25216;&#26415;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.03368</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#22823;&#25968;&#25454;&#30340;&#23454;&#35777;&#21644;&#23454;&#39564;&#30740;&#31350;&#65306;&#19968;&#39033;&#32508;&#21512;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Empirical and Experimental Perspectives on Big Data in Recommendation Systems: A Comprehensive Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#21512;&#35843;&#26597;&#35770;&#25991;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22823;&#25968;&#25454;&#31639;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#20998;&#23618;&#30340;&#20998;&#31867;&#27861;&#12290;&#36890;&#36807;&#35813;&#20998;&#31867;&#27861;&#65292;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#20840;&#38754;&#20102;&#35299;&#19981;&#21516;&#31639;&#27861;&#21644;&#25216;&#26415;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#21512;&#35843;&#26597;&#35770;&#25991;&#23545;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22823;&#25968;&#25454;&#31639;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#28145;&#24230;&#21644;&#31934;&#30830;&#24615;&#19981;&#36275;&#30340;&#38382;&#39064;&#12290;&#23427;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#31649;&#40784;&#19979;&#30340;&#26041;&#27861;&#65306;&#23545;&#24403;&#21069;&#31639;&#27861;&#36827;&#34892;&#24443;&#24213;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#20998;&#23618;&#30340;&#20998;&#31867;&#27861;&#20197;&#23454;&#29616;&#31934;&#30830;&#24402;&#31867;&#12290;&#35813;&#20998;&#31867;&#27861;&#22522;&#20110;&#19977;&#23618;&#23618;&#27425;&#32467;&#26500;&#65292;&#20174;&#26041;&#27861;&#23398;&#31867;&#21035;&#24320;&#22987;&#65292;&#36880;&#27493;&#32454;&#21270;&#20026;&#20855;&#20307;&#25216;&#26415;&#12290;&#36825;&#26679;&#30340;&#26694;&#26550;&#20801;&#35768;&#23545;&#31639;&#27861;&#36827;&#34892;&#32467;&#26500;&#21270;&#21644;&#20840;&#38754;&#30340;&#20998;&#31867;&#65292;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#29702;&#35299;&#19981;&#21516;&#31639;&#27861;&#21644;&#25216;&#26415;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;&#35770;&#25991;&#28085;&#30422;&#20102;&#24191;&#27867;&#30340;&#31639;&#27861;&#65292;&#39318;&#20808;&#23558;&#31639;&#27861;&#20998;&#20026;&#22235;&#31181;&#20027;&#35201;&#20998;&#26512;&#31867;&#22411;&#65306;&#22522;&#20110;&#29992;&#25143;&#21644;&#39033;&#30446;&#30456;&#20284;&#24230;&#30340;&#26041;&#27861;&#12289;&#28151;&#21512;&#21644;&#32508;&#21512;&#26041;&#27861;&#12289;&#28145;&#24230;&#23398;&#20064;&#21644;&#31639;&#27861;&#26041;&#27861;&#12289;&#25968;&#23398;&#24314;&#27169;&#26041;&#27861;&#65292;&#36827;&#19968;&#27493;&#32454;&#20998;&#20026;&#23376;&#31867;&#21035;&#21644;&#25216;&#26415;&#12290;&#35770;&#25991;&#34701;&#21512;&#20102;&#23454;&#35777;&#21644;&#23454;&#39564;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
This survey paper provides a comprehensive analysis of big data algorithms in recommendation systems, addressing the lack of depth and precision in existing literature. It proposes a two-pronged approach: a thorough analysis of current algorithms and a novel, hierarchical taxonomy for precise categorization. The taxonomy is based on a tri-level hierarchy, starting with the methodology category and narrowing down to specific techniques. Such a framework allows for a structured and comprehensive classification of algorithms, assisting researchers in understanding the interrelationships among diverse algorithms and techniques. Covering a wide range of algorithms, this taxonomy first categorizes algorithms into four main analysis types: User and Item Similarity-Based Methods, Hybrid and Combined Approaches, Deep Learning and Algorithmic Methods, and Mathematical Modeling Methods, with further subdivisions into sub-categories and techniques. The paper incorporates both empirical and experim
&lt;/p&gt;</description></item><item><title>RAG-Fusion&#26041;&#27861;&#36890;&#36807;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#65292;&#24182;&#32467;&#21512;&#20114;&#24800;&#25490;&#21517;&#34701;&#21512;&#25216;&#26415;&#65292;&#33021;&#22815;&#20174;&#19981;&#21516;&#35282;&#24230;&#19978;&#19979;&#25991;&#21270;&#21407;&#22987;&#26597;&#35810;&#65292;&#25552;&#20379;&#20934;&#30830;&#21644;&#20840;&#38754;&#30340;&#20449;&#24687;&#12290;&#36825;&#39033;&#30740;&#31350;&#22312;&#20154;&#24037;&#26234;&#33021;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#26041;&#38754;&#26377;&#37325;&#35201;&#36827;&#23637;&#65292;&#24182;&#23637;&#31034;&#20102;&#20840;&#29699;&#21644;&#21306;&#22495;&#20043;&#38388;&#30340;&#36716;&#21464;&#12290;</title><link>https://arxiv.org/abs/2402.03367</link><description>&lt;p&gt;
RAG-Fusion: &#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#26032;&#36884;&#24452;
&lt;/p&gt;
&lt;p&gt;
RAG-Fusion: a New Take on Retrieval-Augmented Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03367
&lt;/p&gt;
&lt;p&gt;
RAG-Fusion&#26041;&#27861;&#36890;&#36807;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#65292;&#24182;&#32467;&#21512;&#20114;&#24800;&#25490;&#21517;&#34701;&#21512;&#25216;&#26415;&#65292;&#33021;&#22815;&#20174;&#19981;&#21516;&#35282;&#24230;&#19978;&#19979;&#25991;&#21270;&#21407;&#22987;&#26597;&#35810;&#65292;&#25552;&#20379;&#20934;&#30830;&#21644;&#20840;&#38754;&#30340;&#20449;&#24687;&#12290;&#36825;&#39033;&#30740;&#31350;&#22312;&#20154;&#24037;&#26234;&#33021;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#26041;&#38754;&#26377;&#37325;&#35201;&#36827;&#23637;&#65292;&#24182;&#23637;&#31034;&#20102;&#20840;&#29699;&#21644;&#21306;&#22495;&#20043;&#38388;&#30340;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Infineon&#24050;&#32463;&#30830;&#23450;&#24037;&#31243;&#24072;&#12289;&#23458;&#25143;&#32463;&#29702;&#21644;&#23458;&#25143;&#36805;&#36895;&#33719;&#21462;&#20135;&#21697;&#20449;&#24687;&#30340;&#38656;&#27714;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20010;&#38382;&#39064;&#36890;&#36807;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#32842;&#22825;&#26426;&#22120;&#20154;&#26469;&#35299;&#20915;&#65292;&#20294;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#35780;&#20272;&#20102;&#26032;&#36817;&#27969;&#34892;&#30340;RAG-Fusion&#26041;&#27861;&#30340;&#20351;&#29992;&#12290;RAG-Fusion&#23558;RAG&#21644;&#20114;&#24800;&#25490;&#21517;&#34701;&#21512;&#65288;RRF&#65289;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#65292;&#20351;&#29992;&#20114;&#24800;&#20998;&#25968;&#23545;&#20854;&#36827;&#34892;&#20877;&#25490;&#24207;&#65292;&#24182;&#34701;&#21512;&#25991;&#26723;&#21644;&#20998;&#25968;&#12290;&#36890;&#36807;&#23545;&#20934;&#30830;&#24615;&#12289;&#30456;&#20851;&#24615;&#21644;&#20840;&#38754;&#24615;&#36827;&#34892;&#25163;&#21160;&#35780;&#20272;&#65292;&#25105;&#21457;&#29616;RAG-Fusion&#33021;&#22815;&#36890;&#36807;&#20174;&#19981;&#21516;&#30340;&#35282;&#24230;&#23545;&#21407;&#22987;&#26597;&#35810;&#36827;&#34892;&#19978;&#19979;&#25991;&#21270;&#65292;&#25552;&#20379;&#20934;&#30830;&#21644;&#20840;&#38754;&#30340;&#22238;&#31572;&#12290;&#28982;&#32780;&#65292;&#24403;&#29983;&#25104;&#30340;&#26597;&#35810;&#19982;&#21407;&#22987;&#26597;&#35810;&#30340;&#30456;&#20851;&#24615;&#19981;&#36275;&#26102;&#65292;&#26377;&#20123;&#31572;&#26696;&#20559;&#31163;&#20102;&#20027;&#39064;&#12290;&#36825;&#39033;&#30740;&#31350;&#22312;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24212;&#29992;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#24182;&#23637;&#31034;&#20102;&#20840;&#29699;&#21644;&#21306;&#22495;&#20043;&#38388;&#30340;&#21464;&#38761;&#12290;
&lt;/p&gt;
&lt;p&gt;
Infineon has identified a need for engineers, account managers, and customers to rapidly obtain product information. This problem is traditionally addressed with retrieval-augmented generation (RAG) chatbots, but in this study, I evaluated the use of the newly popularized RAG-Fusion method. RAG-Fusion combines RAG and reciprocal rank fusion (RRF) by generating multiple queries, reranking them with reciprocal scores and fusing the documents and scores. Through manually evaluating answers on accuracy, relevance, and comprehensiveness, I found that RAG-Fusion was able to provide accurate and comprehensive answers due to the generated queries contextualizing the original query from various perspectives. However, some answers strayed off topic when the generated queries' relevance to the original query is insufficient. This research marks significant progress in artificial intelligence (AI) and natural language processing (NLP) applications and demonstrates transformations in a global and m
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#36890;&#36807;&#35757;&#32451;&#29992;&#25143;&#21644;&#39033;&#30446;&#36755;&#20837;&#30340;ID&#21521;&#37327;&#20316;&#20026;&#25552;&#31034;&#65292;&#21033;&#29992;GPT-2&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#37319;&#29992;&#32852;&#21512;&#35757;&#32451;&#26426;&#21046;&#24182;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#20013;&#36827;&#34892;&#20248;&#21270;&#65292;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#25506;&#32034;&#29992;&#25143;&#30340;&#20852;&#36259;&#65292;&#25552;&#39640;&#25512;&#33616;&#25928;&#26524;&#21644;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.03366</link><description>&lt;p&gt;
&#24102;&#26377;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#21487;&#35299;&#37322;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Uncertainty-Aware Explainable Recommendation with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03366
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#36890;&#36807;&#35757;&#32451;&#29992;&#25143;&#21644;&#39033;&#30446;&#36755;&#20837;&#30340;ID&#21521;&#37327;&#20316;&#20026;&#25552;&#31034;&#65292;&#21033;&#29992;GPT-2&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#21487;&#35299;&#37322;&#25512;&#33616;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#37319;&#29992;&#32852;&#21512;&#35757;&#32451;&#26426;&#21046;&#24182;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#20013;&#36827;&#34892;&#20248;&#21270;&#65292;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#25506;&#32034;&#29992;&#25143;&#30340;&#20852;&#36259;&#65292;&#25552;&#39640;&#25512;&#33616;&#25928;&#26524;&#21644;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20869;&#25552;&#20379;&#35299;&#37322;&#33021;&#22815;&#25552;&#21319;&#29992;&#25143;&#28385;&#24847;&#24230;&#24182;&#24314;&#31435;&#20449;&#20219;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#35814;&#32454;&#35828;&#26126;&#20026;&#29992;&#25143;&#23450;&#21046;&#25512;&#33616;&#39033;&#30446;&#30340;&#21407;&#22240;&#12290;&#24403;&#21069;&#39046;&#22495;&#20013;&#20027;&#35201;&#30340;&#26041;&#27861;&#26159;&#29983;&#25104;&#22522;&#20110;&#25991;&#26412;&#30340;&#35299;&#37322;&#65292;&#32780;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24212;&#29992;&#23588;&#20026;&#31361;&#20986;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26102;&#38388;&#21644;&#35745;&#31639;&#36164;&#28304;&#38480;&#21046;&#65292;&#25913;&#36827;LLMs&#20197;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#25512;&#33616;&#22312;&#23454;&#36341;&#19978;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20316;&#20026;&#26367;&#20195;&#26041;&#26696;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#26159;&#35757;&#32451;&#25552;&#31034;&#32780;&#19981;&#26159;LLM&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#21033;&#29992;&#29992;&#25143;&#21644;&#39033;&#30446;&#36755;&#20837;&#30340;ID&#21521;&#37327;&#20316;&#20026;GPT-2&#30340;&#25552;&#31034;&#12290;&#25105;&#20204;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#20013;&#37319;&#29992;&#32852;&#21512;&#35757;&#32451;&#26426;&#21046;&#65292;&#20248;&#21270;&#25512;&#33616;&#20219;&#21153;&#21644;&#35299;&#37322;&#20219;&#21153;&#12290;&#36825;&#31181;&#31574;&#30053;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#25506;&#32034;&#29992;&#25143;&#30340;&#20852;&#36259;&#65292;&#25552;&#39640;&#25512;&#33616;&#25928;&#26524;&#21644;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;&#36890;&#36807;&#23454;&#39564;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;...
&lt;/p&gt;
&lt;p&gt;
Providing explanations within the recommendation system would boost user satisfaction and foster trust, especially by elaborating on the reasons for selecting recommended items tailored to the user. The predominant approach in this domain revolves around generating text-based explanations, with a notable emphasis on applying large language models (LLMs). However, refining LLMs for explainable recommendations proves impractical due to time constraints and computing resource limitations. As an alternative, the current approach involves training the prompt rather than the LLM. In this study, we developed a model that utilizes the ID vectors of user and item inputs as prompts for GPT-2. We employed a joint training mechanism within a multi-task learning framework to optimize both the recommendation task and explanation task. This strategy enables a more effective exploration of users' interests, improving recommendation effectiveness and user satisfaction. Through the experiments, our meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#20844;&#24179;&#25512;&#33616;&#31995;&#32479;&#65292;&#21517;&#20026;HetroFair&#65292;&#26088;&#22312;&#25552;&#39640;&#39033;&#30446;&#20391;&#30340;&#20844;&#24179;&#24615;&#12290;HetroFair&#20351;&#29992;&#20844;&#24179;&#27880;&#24847;&#21147;&#21644;&#24322;&#36136;&#24615;&#29305;&#24449;&#21152;&#26435;&#20004;&#20010;&#32452;&#20214;&#26469;&#29983;&#25104;&#20855;&#26377;&#20844;&#24179;&#24615;&#24847;&#35782;&#30340;&#23884;&#20837;&#12290;</title><link>https://arxiv.org/abs/2402.03365</link><description>&lt;p&gt;
&#21033;&#29992;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#30064;&#36136;&#21451;&#21892;&#25512;&#33616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Heterophily-Aware Fair Recommendation using Graph Convolutional Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#20844;&#24179;&#25512;&#33616;&#31995;&#32479;&#65292;&#21517;&#20026;HetroFair&#65292;&#26088;&#22312;&#25552;&#39640;&#39033;&#30446;&#20391;&#30340;&#20844;&#24179;&#24615;&#12290;HetroFair&#20351;&#29992;&#20844;&#24179;&#27880;&#24847;&#21147;&#21644;&#24322;&#36136;&#24615;&#29305;&#24449;&#21152;&#26435;&#20004;&#20010;&#32452;&#20214;&#26469;&#29983;&#25104;&#20855;&#26377;&#20844;&#24179;&#24615;&#24847;&#35782;&#30340;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24050;&#25104;&#20026;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#30340;&#27969;&#34892;&#24037;&#20855;&#12290;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#19981;&#20165;&#35774;&#35745;&#20026;&#20026;&#26368;&#32456;&#29992;&#25143;&#26381;&#21153;&#65292;&#36824;&#35201;&#35753;&#20854;&#20182;&#21442;&#19982;&#32773;&#65288;&#22914;&#39033;&#30446;&#21644;&#39033;&#30446;&#20379;&#24212;&#21830;&#65289;&#20174;&#20013;&#21463;&#30410;&#12290;&#36825;&#20123;&#21442;&#19982;&#32773;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#25110;&#20914;&#31361;&#30340;&#30446;&#26631;&#21644;&#21033;&#30410;&#65292;&#36825;&#24341;&#21457;&#20102;&#23545;&#20844;&#24179;&#24615;&#21644;&#27969;&#34892;&#24230;&#20559;&#24046;&#32771;&#34385;&#30340;&#38656;&#27714;&#12290;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#26041;&#27861;&#20063;&#38754;&#20020;&#19981;&#20844;&#24179;&#24615;&#21644;&#27969;&#34892;&#24230;&#20559;&#24046;&#30340;&#25361;&#25112;&#65292;&#20854;&#24402;&#19968;&#21270;&#21644;&#32858;&#21512;&#36807;&#31243;&#21463;&#21040;&#36825;&#20123;&#25361;&#25112;&#30340;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#30340;&#22522;&#20110;GNN&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#31216;&#20026;HetroFair&#65292;&#26088;&#22312;&#25552;&#39640;&#39033;&#30446;&#20391;&#30340;&#20844;&#24179;&#24615;&#12290;HetroFair&#20351;&#29992;&#20004;&#20010;&#29420;&#31435;&#30340;&#32452;&#20214;&#29983;&#25104;&#20855;&#26377;&#20844;&#24179;&#24615;&#24847;&#35782;&#30340;&#23884;&#20837;&#65306;i&#65289;&#20844;&#24179;&#27880;&#24847;&#21147;&#65292;&#23427;&#22312;GNN&#30340;&#24402;&#19968;&#21270;&#36807;&#31243;&#20013;&#32467;&#21512;&#20102;&#28857;&#31215;&#65292;&#20197;&#20943;&#23569;&#33410;&#28857;&#24230;&#25968;&#30340;&#24433;&#21709;&#65307;ii&#65289;&#24322;&#36136;&#24615;&#29305;&#24449;&#21152;&#26435;&#65292;&#20026;&#19981;&#21516;&#30340;&#29305;&#24449;&#20998;&#37197;&#19981;&#21516;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, graph neural networks (GNNs) have become a popular tool to improve the accuracy and performance of recommender systems. Modern recommender systems are not only designed to serve the end users, but also to benefit other participants, such as items and items providers. These participants may have different or conflicting goals and interests, which raise the need for fairness and popularity bias considerations. GNN-based recommendation methods also face the challenges of unfairness and popularity bias and their normalization and aggregation processes suffer from these challenges. In this paper, we propose a fair GNN-based recommender system, called HetroFair, to improve items' side fairness. HetroFair uses two separate components to generate fairness-aware embeddings: i) fairness-aware attention which incorporates dot product in the normalization process of GNNs, to decrease the effect of nodes' degrees, and ii) heterophily feature weighting to assign distinct weights to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;NanoNER&#65292;&#23427;&#26159;&#19968;&#31181;&#29992;&#20110;&#32435;&#31859;&#29983;&#29289;&#23398;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#39046;&#22495;&#19987;&#23478;&#30340;&#30693;&#35782;&#21644;&#36828;&#31243;&#30417;&#30563;&#23398;&#20064;&#65292;NanoNER&#33021;&#22815;&#20934;&#30830;&#22320;&#35782;&#21035;&#20808;&#21069;&#24050;&#30693;&#23454;&#20307;&#65292;&#24182;&#26368;&#22823;&#31243;&#24230;&#22320;&#25552;&#39640;&#27880;&#37322;&#25968;&#25454;&#30340;&#36136;&#37327;&#21644;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.03362</link><description>&lt;p&gt;
NanoNER: &#20351;&#29992;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#21644;&#36828;&#31243;&#30417;&#30563;&#36827;&#34892;&#32435;&#31859;&#29983;&#29289;&#23398;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
NanoNER: Named Entity Recognition for nanobiology using experts' knowledge and distant supervision
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03362
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;NanoNER&#65292;&#23427;&#26159;&#19968;&#31181;&#29992;&#20110;&#32435;&#31859;&#29983;&#29289;&#23398;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#39046;&#22495;&#19987;&#23478;&#30340;&#30693;&#35782;&#21644;&#36828;&#31243;&#30417;&#30563;&#23398;&#20064;&#65292;NanoNER&#33021;&#22815;&#20934;&#30830;&#22320;&#35782;&#21035;&#20808;&#21069;&#24050;&#30693;&#23454;&#20307;&#65292;&#24182;&#26368;&#22823;&#31243;&#24230;&#22320;&#25552;&#39640;&#27880;&#37322;&#25968;&#25454;&#30340;&#36136;&#37327;&#21644;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;NanoNER&#30340;&#35757;&#32451;&#21644;&#35780;&#20272;&#65292;&#23427;&#26159;&#19968;&#31181;&#29992;&#20110;&#32435;&#31859;&#29983;&#29289;&#23398;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#27169;&#22411;&#12290;NER&#26159;&#22312;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#20013;&#35782;&#21035;&#29305;&#23450;&#23454;&#20307;&#30340;&#20219;&#21153;&#65292;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#21644;&#20449;&#24687;&#25552;&#21462;&#20013;&#32463;&#24120;&#26159;&#19968;&#20010;&#20027;&#35201;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#30340;&#30446;&#30340;&#26159;&#35782;&#21035;&#39046;&#22495;&#19987;&#23478;&#20043;&#21069;&#30830;&#23450;&#20026;&#35813;&#39046;&#22495;&#22522;&#26412;&#30693;&#35782;&#30340;&#23454;&#20307;&#12290;&#25105;&#20204;&#20381;&#38752;&#26412;&#20307;&#35770;&#26469;&#25552;&#20379;&#39046;&#22495;&#35789;&#27719;&#21644;&#20998;&#31867;&#65292;&#23454;&#29616;&#20102;&#19968;&#20010;&#36845;&#20195;&#36807;&#31243;&#65292;&#20351;&#19987;&#23478;&#33021;&#22815;&#30830;&#23450;&#19982;&#24403;&#21069;&#39046;&#22495;&#30456;&#20851;&#30340;&#23454;&#20307;&#12290;&#28982;&#21518;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#36828;&#31243;&#30417;&#30563;&#23398;&#20064;&#22312;NER&#20013;&#30340;&#28508;&#21147;&#65292;&#25903;&#25345;&#36825;&#31181;&#26041;&#27861;&#22914;&#20309;&#21487;&#20197;&#36890;&#36807;&#26368;&#23569;&#30340;&#20154;&#21147;&#22686;&#21152;&#27880;&#37322;&#25968;&#25454;&#30340;&#25968;&#37327;&#12290;&#22312;&#21253;&#21547;&#36229;&#36807;120k&#23454;&#20307;&#20986;&#29616;&#27425;&#25968;&#30340;728&#31687;&#20840;&#25991;&#32435;&#31859;&#29983;&#29289;&#23398;&#25991;&#31456;&#30340;&#23436;&#25972;&#35821;&#26009;&#24211;&#19978;&#65292;NanoNER&#22312;&#20808;&#21069;&#24050;&#30693;&#23454;&#20307;&#30340;&#35782;&#21035;&#19978;&#33719;&#24471;&#20102;0.98&#30340;F1&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Here we present the training and evaluation of NanoNER, a Named Entity Recognition (NER) model for Nanobiology. NER consists in the identification of specific entities in spans of unstructured texts and is often a primary task in Natural Language Processing (NLP) and Information Extraction. The aim of our model is to recognise entities previously identified by domain experts as constituting the essential knowledge of the domain. Relying on ontologies, which provide us with a domain vocabulary and taxonomy, we implemented an iterative process enabling experts to determine the entities relevant to the domain at hand. We then delve into the potential of distant supervision learning in NER, supporting how this method can increase the quantity of annotated data with minimal additional manpower. On our full corpus of 728 full-text nanobiology articles, containing more than 120k entity occurrences, NanoNER obtained a F1-score of 0.98 on the recognition of previously known entities. Our model 
&lt;/p&gt;</description></item><item><title>EasyInstruct&#26159;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#22359;&#21270;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#65292;&#20351;&#25351;&#20196;&#22788;&#29702;&#26356;&#21152;&#26041;&#20415;&#21644;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.03049</link><description>&lt;p&gt;
EasyInstruct&#65306;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03049
&lt;/p&gt;
&lt;p&gt;
EasyInstruct&#26159;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#22359;&#21270;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#65292;&#20351;&#25351;&#20196;&#22788;&#29702;&#26356;&#21152;&#26041;&#20415;&#21644;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#25351;&#20196;&#35843;&#25972;&#24050;&#32463;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#24182;&#25104;&#20026;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#21147;&#30340;&#19968;&#31181;&#20851;&#38190;&#25216;&#26415;&#12290;&#20026;&#20102;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#25351;&#20196;&#22788;&#29702;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#25968;&#25454;&#25968;&#37327;&#21644;&#25968;&#25454;&#36136;&#37327;&#20043;&#38388;&#36798;&#21040;&#31934;&#24039;&#30340;&#24179;&#34913;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#25351;&#20196;&#22788;&#29702;&#26041;&#27861;&#20043;&#38388;&#20173;&#28982;&#23384;&#22312;&#19981;&#19968;&#33268;&#65292;&#30446;&#21069;&#27809;&#26377;&#26631;&#20934;&#30340;&#24320;&#28304;&#25351;&#20196;&#22788;&#29702;&#23454;&#29616;&#26694;&#26550;&#21487;&#20379;&#31038;&#21306;&#20351;&#29992;&#65292;&#36825;&#20351;&#24471;&#20174;&#19994;&#32773;&#26080;&#27861;&#36827;&#19968;&#27493;&#24320;&#21457;&#21644;&#25512;&#36827;&#12290;&#20026;&#20102;&#20419;&#36827;&#25351;&#20196;&#22788;&#29702;&#30340;&#30740;&#31350;&#21644;&#24320;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EasyInstruct&#65292;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;LLMs&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#23427;&#23558;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#27169;&#22359;&#21270;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#12290;EasyInstruct&#24050;&#32463;&#22312;https://github.com/zjunlp/EasyInstruct&#19978;&#20844;&#24320;&#21457;&#24067;&#65292;&#24182;&#24471;&#21040;&#20102;&#31215;&#26497;&#32500;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along 
&lt;/p&gt;</description></item><item><title>K-PERM&#26159;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#30693;&#35782;&#26816;&#32034;&#21644;&#20010;&#20154;&#36866;&#24212;&#24615;&#26597;&#35810;&#26469;&#23454;&#29616;&#20010;&#24615;&#21270;&#21709;&#24212;&#29983;&#25104;&#30340;&#23545;&#35805;&#20195;&#29702;&#65292;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#30340;&#36136;&#37327;&#21644;&#29992;&#25143;&#21442;&#19982;&#24230;&#65292;&#24182;&#22312;&#30495;&#23454;&#20010;&#24615;&#21270;&#23545;&#35805;&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2312.17748</link><description>&lt;p&gt;
K-PERM: &#20351;&#29992;&#21160;&#24577;&#30693;&#35782;&#26816;&#32034;&#21644;&#20010;&#20154;&#36866;&#24212;&#24615;&#26597;&#35810;&#23454;&#29616;&#20010;&#24615;&#21270;&#21709;&#24212;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
K-PERM: Personalized Response Generation Using Dynamic Knowledge Retrieval and Persona-Adaptive Queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.17748
&lt;/p&gt;
&lt;p&gt;
K-PERM&#26159;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#30693;&#35782;&#26816;&#32034;&#21644;&#20010;&#20154;&#36866;&#24212;&#24615;&#26597;&#35810;&#26469;&#23454;&#29616;&#20010;&#24615;&#21270;&#21709;&#24212;&#29983;&#25104;&#30340;&#23545;&#35805;&#20195;&#29702;&#65292;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#30340;&#36136;&#37327;&#21644;&#29992;&#25143;&#21442;&#19982;&#24230;&#65292;&#24182;&#22312;&#30495;&#23454;&#20010;&#24615;&#21270;&#23545;&#35805;&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20010;&#24615;&#21270;&#23545;&#35805;&#20195;&#29702;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#30340;&#36136;&#37327;&#24182;&#22686;&#21152;&#29992;&#25143;&#30340;&#21442;&#19982;&#24230;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#36890;&#24120;&#32570;&#20047;&#22806;&#37096;&#30693;&#35782;&#20197;&#36866;&#24212;&#29992;&#25143;&#30340;&#20010;&#24615;&#12290;&#36825;&#23545;&#20110;&#23454;&#38469;&#24212;&#29992;&#65292;&#22914;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#12289;&#39278;&#39135;&#35745;&#21010;&#12289;&#25991;&#21270;&#25935;&#24863;&#23545;&#35805;&#25110;&#20943;&#23569;&#23545;&#35805;&#20195;&#29702;&#20013;&#30340;&#26377;&#27602;&#34892;&#20026;&#23588;&#20026;&#37325;&#35201;&#12290;&#20026;&#20102;&#25552;&#39640;&#20010;&#24615;&#21270;&#21709;&#24212;&#30340;&#30456;&#20851;&#24615;&#21644;&#20840;&#38754;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#27493;&#26041;&#27861;&#65292;&#21253;&#25324;(1)&#26377;&#36873;&#25321;&#24615;&#22320;&#38598;&#25104;&#29992;&#25143;&#20154;&#29289;&#21644;(2)&#20351;&#29992;&#32972;&#26223;&#30693;&#35782;&#28304;&#34917;&#20805;&#20449;&#24687;&#26469;&#32473;&#21709;&#24212;&#25552;&#20379;&#19978;&#19979;&#25991;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;K-PERM(&#30693;&#35782;&#24341;&#23548;&#30340;&#20010;&#24615;&#21270;&#19982;&#22870;&#21169;&#35843;&#25511;)&#65292;&#23427;&#26159;&#19968;&#20010;&#21160;&#24577;&#23545;&#35805;&#20195;&#29702;&#65292;&#32467;&#21512;&#20102;&#36825;&#20123;&#20803;&#32032;&#12290;K-PERM&#22312;&#27969;&#34892;&#30340;FoCus&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#26377;&#20851;&#20840;&#29699;&#22320;&#26631;&#30340;&#30495;&#23454;&#20010;&#24615;&#21270;&#23545;&#35805;&#12290;&#25105;&#20204;&#35777;&#26126;&#20351;&#29992;K-PERM&#30340;&#21709;&#24212;&#21487;&#20197;&#25913;&#36827;&#23545;&#35805;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalizing conversational agents can enhance the quality of conversations and increase user engagement. However, they often lack external knowledge to appropriately tend to a user's persona. This is particularly crucial for practical applications like mental health support, nutrition planning, culturally sensitive conversations, or reducing toxic behavior in conversational agents. To enhance the relevance and comprehensiveness of personalized responses, we propose using a two-step approach that involves (1) selectively integrating user personas and (2) contextualizing the response with supplementing information from a background knowledge source. We develop K-PERM (Knowledge-guided PErsonalization with Reward Modulation), a dynamic conversational agent that combines these elements. K-PERM achieves state-of-the-art performance on the popular FoCus dataset, containing real-world personalized conversations concerning global landmarks. We show that using responses from K-PERM can improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#25240;&#25187;&#33258;&#36866;&#24212;&#20559;&#22909;&#30340;&#20195;&#29702;&#30340;&#22312;&#32447;&#25512;&#33616;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#27599;&#19968;&#36718;&#20013;&#23637;&#31034;&#19968;&#31995;&#21015;&#29289;&#21697;&#24182;&#32771;&#34385;&#20195;&#29702;&#30340;&#20559;&#22909;&#28436;&#21464;&#65292;&#20197;&#23454;&#29616;&#23545;&#20110;&#30446;&#26631;&#38598;&#21512;&#30340;&#26368;&#23567;&#21270;&#21518;&#24724;&#12290;&#22312;&#38271;&#26399;&#35760;&#24518;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23454;&#29616;&#23545;&#20110;&#33021;&#22815;&#22312;&#20219;&#20309;&#26102;&#21051;&#23454;&#29616;&#30340;&#20998;&#24067;&#38598;&#21512;&#30340;&#39640;&#25928;&#27425;&#32447;&#24615;&#21518;&#24724;&#12290;</title><link>https://arxiv.org/abs/2302.06014</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#25240;&#25187;&#33258;&#36866;&#24212;&#20559;&#22909;&#30340;&#20195;&#29702;&#20013;&#30340;&#22312;&#32447;&#25512;&#33616;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online Recommendations for Agents with Discounted Adaptive Preferences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.06014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#25240;&#25187;&#33258;&#36866;&#24212;&#20559;&#22909;&#30340;&#20195;&#29702;&#30340;&#22312;&#32447;&#25512;&#33616;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#27599;&#19968;&#36718;&#20013;&#23637;&#31034;&#19968;&#31995;&#21015;&#29289;&#21697;&#24182;&#32771;&#34385;&#20195;&#29702;&#30340;&#20559;&#22909;&#28436;&#21464;&#65292;&#20197;&#23454;&#29616;&#23545;&#20110;&#30446;&#26631;&#38598;&#21512;&#30340;&#26368;&#23567;&#21270;&#21518;&#24724;&#12290;&#22312;&#38271;&#26399;&#35760;&#24518;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23454;&#29616;&#23545;&#20110;&#33021;&#22815;&#22312;&#20219;&#20309;&#26102;&#21051;&#23454;&#29616;&#30340;&#20998;&#24067;&#38598;&#21512;&#30340;&#39640;&#25928;&#27425;&#32447;&#24615;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;Bandit&#25512;&#33616;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#30340;&#20559;&#22909;&#65288;&#20195;&#34920;&#23545;&#25512;&#33616;&#29289;&#21697;&#30340;&#36873;&#25321;&#27010;&#29575;&#65289;&#26681;&#25454;&#36807;&#21435;&#30340;&#36873;&#25321;&#20316;&#20026;&#26410;&#30693;"&#20559;&#22909;&#27169;&#22411;"&#30340;&#20989;&#25968;&#32780;&#28436;&#21464;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#25105;&#20204;&#21521;&#20195;&#29702;&#23637;&#31034;$k$&#20010;&#29289;&#21697;&#65288;&#20849;$n$&#20010;&#65289;&#65292;&#20195;&#29702;&#36873;&#25321;&#19968;&#20010;&#29289;&#21697;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#20195;&#29702;&#30340;&#36873;&#25321;&#19978;&#23545;&#20110;&#26576;&#20010;"&#30446;&#26631;&#38598;&#21512;"&#65288;&#29289;&#21697;&#31616;&#21333;&#24418;&#24335;&#30340;&#23376;&#38598;&#65289;&#30340;&#23545;&#25239;&#25439;&#22833;&#26368;&#23567;&#21270;&#21518;&#24724;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;Agarwal&#21644;Brown&#65288;2022&#65289;&#30340;&#35774;&#23450;&#65292;&#20182;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#22343;&#21248;&#35760;&#24518;&#30340;&#20195;&#29702;&#65292;&#32780;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20801;&#35768;&#38750;&#22343;&#21248;&#35760;&#24518;&#65292;&#22312;&#27599;&#19968;&#36718;&#20013;&#23545;&#20195;&#29702;&#30340;&#35760;&#24518;&#21521;&#37327;&#24212;&#29992;&#19968;&#20010;&#25240;&#25187;&#22240;&#23376;&#12290;&#22312;"&#38271;&#26399;&#35760;&#24518;"&#30340;&#24773;&#20917;&#19979;&#65288;&#24403;&#26377;&#25928;&#30340;&#35760;&#24518;&#26102;&#31243;&#19982;$T$&#30340;&#27425;&#32447;&#24615;&#21464;&#21270;&#65289;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#23454;&#29616;&#23545;&#20110;"&#33021;&#22815;&#22312;&#20219;&#20309;&#26102;&#21051;&#23454;&#29616;&#30340;&#20998;&#24067;&#38598;&#21512;"&#65288;&#21363;"&#21363;&#26102;&#23454;&#29616;&#20998;&#24067;&#38598;&#21512;"&#65289;&#30340;&#39640;&#25928;&#27425;&#32447;&#24615;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a bandit recommendations problem in which an agent's preferences (representing selection probabilities over recommended items) evolve as a function of past selections, according to an unknown $\textit{preference model}$. In each round, we show a menu of $k$ items (out of $n$ total) to the agent, who then chooses a single item, and we aim to minimize regret with respect to some $\textit{target set}$ (a subset of the item simplex) for adversarial losses over the agent's choices. Extending the setting from Agarwal and Brown (2022), where uniform-memory agents were considered, here we allow for non-uniform memory in which a discount factor is applied to the agent's memory vector at each subsequent round. In the "long-term memory" regime (when the effective memory horizon scales with $T$ sublinearly), we show that efficient sublinear regret is obtainable with respect to the set of $\textit{everywhere instantaneously realizable distributions}$ (the "EIRD set", as formulated in pr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#25972;&#39029;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;&#65288;WP-ULTR&#65289;&#26041;&#27861;&#22788;&#29702;&#25972;&#39029; SERP &#29305;&#24449;&#24341;&#21457;&#30340;&#20559;&#24046;&#65292;&#35813;&#26041;&#27861;&#38754;&#20020;&#36866;&#21512;&#30340;&#29992;&#25143;&#34892;&#20026;&#27169;&#22411;&#30340;&#25361;&#25112;&#21644;&#22797;&#26434;&#30340;&#27169;&#22411;&#35757;&#32451;&#38590;&#39064;&#12290;</title><link>https://arxiv.org/abs/2210.10718</link><description>&lt;p&gt;
&#25972;&#39029;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Whole Page Unbiased Learning to Rank
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.10718
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#25972;&#39029;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;&#65288;WP-ULTR&#65289;&#26041;&#27861;&#22788;&#29702;&#25972;&#39029; SERP &#29305;&#24449;&#24341;&#21457;&#30340;&#20559;&#24046;&#65292;&#35813;&#26041;&#27861;&#38754;&#20020;&#36866;&#21512;&#30340;&#29992;&#25143;&#34892;&#20026;&#27169;&#22411;&#30340;&#25361;&#25112;&#21644;&#22797;&#26434;&#30340;&#27169;&#22411;&#35757;&#32451;&#38590;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20013;&#39029;&#38754;&#21576;&#29616;&#30340;&#20559;&#35265;&#65292;&#23588;&#20854;&#26159;&#28857;&#20987;&#34892;&#20026;&#26041;&#38754;&#30340;&#20559;&#24046;&#65292;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#25361;&#25112;&#65292;&#38459;&#30861;&#20102;&#20351;&#29992;&#38544;&#24335;&#29992;&#25143;&#21453;&#39304;&#26469;&#25913;&#36827;&#25490;&#24207;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#25552;&#20986;&#20102;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;(ULTR)&#31639;&#27861;&#65292;&#36890;&#36807;&#20559;&#24046;&#28857;&#20987;&#25968;&#25454;&#26469;&#23398;&#20064;&#19968;&#20010;&#26080;&#20559;&#30340;&#25490;&#24207;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#29305;&#21035;&#35774;&#35745;&#29992;&#20110;&#20943;&#36731;&#19982;&#20301;&#32622;&#30456;&#20851;&#30340;&#20559;&#24046;&#65292;&#20363;&#22914;&#20449;&#20219;&#20559;&#24046;&#65292;&#24182;&#26410;&#32771;&#34385;&#21040;&#25628;&#32034;&#32467;&#26524;&#39029;&#38754;&#21576;&#29616;(SERP)&#20013;&#20854;&#20182;&#29305;&#24449;&#24341;&#21457;&#30340;&#20559;&#24046;&#65292;&#20363;&#22914;&#30001;&#22810;&#23186;&#20307;&#24341;&#21457;&#30340;&#21560;&#24341;&#20559;&#24046;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#20559;&#24046;&#22312;&#24037;&#19994;&#31995;&#32479;&#20013;&#24191;&#27867;&#23384;&#22312;&#65292;&#21487;&#33021;&#23548;&#33268;&#19981;&#20196;&#20154;&#28385;&#24847;&#30340;&#25628;&#32034;&#20307;&#39564;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#38382;&#39064;&#65292;&#21363;&#25972;&#39029;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;(WP-ULTR)&#65292;&#26088;&#22312;&#21516;&#26102;&#22788;&#29702;&#25972;&#39029;SERP&#29305;&#24449;&#24341;&#21457;&#30340;&#20559;&#24046;&#12290;&#36825;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#25361;&#25112;&#65306;(1) &#24456;&#38590;&#25214;&#21040;&#36866;&#21512;&#30340;&#29992;&#25143;&#34892;&#20026;&#27169;&#22411; (&#29992;&#25143;&#34892;&#20026;&#20551;&#35774;)&#65307;(2) &#22797;&#26434;&#30340;&#27169;&#22411;&#35757;&#32451;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The page presentation biases in the information retrieval system, especially on the click behavior, is a well-known challenge that hinders improving ranking models' performance with implicit user feedback. Unbiased Learning to Rank~(ULTR) algorithms are then proposed to learn an unbiased ranking model with biased click data. However, most existing algorithms are specifically designed to mitigate position-related bias, e.g., trust bias, without considering biases induced by other features in search result page presentation(SERP), e.g. attractive bias induced by the multimedia. Unfortunately, those biases widely exist in industrial systems and may lead to an unsatisfactory search experience. Therefore, we introduce a new problem, i.e., whole-page Unbiased Learning to Rank(WP-ULTR), aiming to handle biases induced by whole-page SERP features simultaneously. It presents tremendous challenges: (1) a suitable user behavior model (user behavior hypothesis) can be hard to find; and (2) complex
&lt;/p&gt;</description></item><item><title>Re3val&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#21644;&#37325;&#26032;&#25490;&#21517;&#25216;&#26415;&#36827;&#34892;&#35757;&#32451;&#30340;&#29983;&#25104;&#26816;&#32034;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#37325;&#26032;&#25490;&#21517;&#26816;&#32034;&#24471;&#21040;&#30340;&#39029;&#38754;&#26631;&#39064;&#65292;&#20197;&#26368;&#22823;&#21270;&#36890;&#36807;&#21463;&#38480;&#35299;&#30721;&#29983;&#25104;&#30340;&#22870;&#21169;&#12290;&#21516;&#26102;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#29983;&#25104;&#38382;&#39064;&#26469;&#20943;&#23567;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24357;&#21512;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#39046;&#22495;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2401.16979</link><description>&lt;p&gt;
Re3val: &#24378;&#21270;&#21644;&#37325;&#26032;&#25490;&#21517;&#30340;&#29983;&#25104;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Re3val: Reinforced and Reranked Generative Retrieval. (arXiv:2401.16979v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16979
&lt;/p&gt;
&lt;p&gt;
Re3val&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#21644;&#37325;&#26032;&#25490;&#21517;&#25216;&#26415;&#36827;&#34892;&#35757;&#32451;&#30340;&#29983;&#25104;&#26816;&#32034;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#37325;&#26032;&#25490;&#21517;&#26816;&#32034;&#24471;&#21040;&#30340;&#39029;&#38754;&#26631;&#39064;&#65292;&#20197;&#26368;&#22823;&#21270;&#36890;&#36807;&#21463;&#38480;&#35299;&#30721;&#29983;&#25104;&#30340;&#22870;&#21169;&#12290;&#21516;&#26102;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#29983;&#25104;&#38382;&#39064;&#26469;&#20943;&#23567;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24357;&#21512;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#39046;&#22495;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#26816;&#32034;&#27169;&#22411;&#23558;&#25991;&#26723;&#20013;&#30340;&#20449;&#24687;&#25351;&#38024;&#32534;&#30721;&#20026;&#27169;&#22411;&#21442;&#25968;&#20013;&#30340;&#32034;&#24341;&#12290;&#36825;&#20123;&#27169;&#22411;&#20316;&#20026;&#26356;&#22823;&#30340;&#27969;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#36890;&#36807;&#26816;&#32034;&#30340;&#20449;&#24687;&#26469;&#20026;&#30693;&#35782;&#23494;&#38598;&#22411;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#29983;&#25104;&#26465;&#20214;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#26377;&#20004;&#20010;&#38480;&#21046;&#65306;&#29983;&#25104;&#26816;&#32034;&#27809;&#26377;&#32771;&#34385;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#20854;&#27425;&#65292;&#26816;&#32034;&#26080;&#27861;&#20026;&#19979;&#28216;&#35835;&#32773;&#36827;&#34892;&#35843;&#25972;&#65292;&#22240;&#20026;&#35299;&#30721;&#39029;&#38754;&#26631;&#39064;&#26159;&#19968;&#20010;&#38750;&#21487;&#24494;&#20998;&#30340;&#25805;&#20316;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#32463;&#36807;&#26377;&#38480;&#25968;&#25454;&#35757;&#32451;&#30340;&#29983;&#25104;&#37325;&#26032;&#25490;&#21517;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340; Re3val&#12290;Re3val&#21033;&#29992;&#36890;&#36807;&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#33719;&#24471;&#30340;&#19978;&#19979;&#25991;&#23545;&#24050;&#26816;&#32034;&#39029;&#38754;&#26631;&#39064;&#36827;&#34892;&#37325;&#26032;&#25490;&#21517;&#65292;&#24182;&#21033;&#29992;REINFORCE&#31639;&#27861;&#26368;&#22823;&#21270;&#21463;&#38480;&#35299;&#30721;&#29983;&#25104;&#30340;&#22870;&#21169;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#29983;&#25104;&#38382;&#39064;&#65292;&#20197;&#20943;&#23567;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24357;&#21512;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#39046;&#22495;&#24046;&#36317;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20174;&#20013;&#25552;&#21462;&#21644;&#37325;&#26032;&#25490;&#21517;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative retrieval models encode pointers to information in a corpus as an index within the model's parameters. These models serve as part of a larger pipeline, where retrieved information conditions generation for knowledge-intensive NLP tasks. However, we identify two limitations: the generative retrieval does not account for contextual information. Secondly, the retrieval can't be tuned for the downstream readers as decoding the page title is a non-differentiable operation. This paper introduces Re3val, trained with generative reranking and reinforcement learning using limited data. Re3val leverages context acquired via Dense Passage Retrieval to rerank the retrieved page titles and utilizes REINFORCE to maximize rewards generated by constrained decoding. Additionally, we generate questions from our pre-training dataset to mitigate epistemic uncertainty and bridge the domain gap between the pre-training and fine-tuning datasets. Subsequently, we extract and rerank contexts from th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#20351;&#29992;&#26080;&#30417;&#30563;&#30456;&#20284;&#24230;&#24230;&#37327;&#36827;&#34892;&#28304;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#65292;&#26088;&#22312;&#20026;&#36719;&#20214;&#24037;&#31243;&#24072;&#25552;&#20379;&#25351;&#23548;&#65292;&#20197;&#36873;&#25321;&#36866;&#21512;&#20854;&#29305;&#23450;&#29992;&#20363;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.09885</link><description>&lt;p&gt;
&#20351;&#29992;&#26080;&#30417;&#30563;&#30456;&#20284;&#24230;&#24230;&#37327;&#36827;&#34892;&#28304;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Source Code Clone Detection Using Unsupervised Similarity Measures. (arXiv:2401.09885v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09885
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#20351;&#29992;&#26080;&#30417;&#30563;&#30456;&#20284;&#24230;&#24230;&#37327;&#36827;&#34892;&#28304;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#65292;&#26088;&#22312;&#20026;&#36719;&#20214;&#24037;&#31243;&#24072;&#25552;&#20379;&#25351;&#23548;&#65292;&#20197;&#36873;&#25321;&#36866;&#21512;&#20854;&#29305;&#23450;&#29992;&#20363;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22312;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#20013;&#20811;&#38534;&#26816;&#27979;&#21644;&#20195;&#30721;&#25628;&#32034;&#19982;&#25512;&#33616;&#30340;&#37325;&#35201;&#24615;&#65292;&#23545;&#28304;&#20195;&#30721;&#30340;&#30456;&#20284;&#24615;&#36827;&#34892;&#35780;&#20272;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#36739;&#20998;&#26512;&#26080;&#30417;&#30563;&#30456;&#20284;&#24230;&#24230;&#37327;&#29992;&#20110;&#35782;&#21035;&#28304;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#30340;&#26041;&#27861;&#12290;&#30446;&#26631;&#26159;&#27010;&#36848;&#30446;&#21069;&#30340;&#26368;&#26032;&#25216;&#26415;&#12289;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#32534;&#35793;&#20102;&#29616;&#26377;&#30340;&#26080;&#30417;&#30563;&#31574;&#30053;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#20197;&#25351;&#23548;&#36719;&#20214;&#24037;&#31243;&#24072;&#22312;&#36873;&#25321;&#36866;&#29992;&#20110;&#20854;&#29305;&#23450;&#29992;&#20363;&#30340;&#26041;&#27861;&#26102;&#25552;&#20379;&#25351;&#23548;&#12290;&#26412;&#30740;&#31350;&#30340;&#28304;&#20195;&#30721;&#21487;&#22312;\url{https://github.com/jorge-martinez-gil/codesim}&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing similarity in source code has gained significant attention in recent years due to its importance in software engineering tasks such as clone detection and code search and recommendation. This work presents a comparative analysis of unsupervised similarity measures for identifying source code clone detection. The goal is to overview the current state-of-the-art techniques, their strengths, and weaknesses. To do that, we compile the existing unsupervised strategies and evaluate their performance on a benchmark dataset to guide software engineers in selecting appropriate methods for their specific use cases. The source code of this study is available at \url{https://github.com/jorge-martinez-gil/codesim}
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InstructGLM&#30340;&#32467;&#26500;&#21270;&#35821;&#35328;&#27169;&#22411;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#22270;&#34920;&#23398;&#20064;&#38382;&#39064;&#30456;&#32467;&#21512;&#65292;&#26088;&#22312;&#25506;&#32034;&#26159;&#21542;&#21487;&#20197;&#29992;&#35821;&#35328;&#27169;&#22411;&#21462;&#20195;&#22270;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#22270;&#34920;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.07134</link><description>&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#26159;&#22270;&#34920;&#25152;&#38656;&#35201;&#30340;&#20840;&#37096;&#20869;&#23481;
&lt;/p&gt;
&lt;p&gt;
Natural Language is All a Graph Needs. (arXiv:2308.07134v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07134
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InstructGLM&#30340;&#32467;&#26500;&#21270;&#35821;&#35328;&#27169;&#22411;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#22270;&#34920;&#23398;&#20064;&#38382;&#39064;&#30456;&#32467;&#21512;&#65292;&#26088;&#22312;&#25506;&#32034;&#26159;&#21542;&#21487;&#20197;&#29992;&#35821;&#35328;&#27169;&#22411;&#21462;&#20195;&#22270;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#22270;&#34920;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#22914;ChatGPT&#65292;&#24050;&#32463;&#22312;&#20154;&#24037;&#26234;&#33021;&#30340;&#21508;&#20010;&#30740;&#31350;&#39046;&#22495;&#20013;&#24341;&#36215;&#20102;&#38761;&#21629;&#12290;&#22522;&#20110;Transformer&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36880;&#28176;&#21462;&#20195;&#20102;CNN&#21644;RNN&#65292;&#23558;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#32479;&#19968;&#36215;&#26469;&#12290;&#19982;&#30456;&#23545;&#29420;&#31435;&#23384;&#22312;&#30340;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#12289;&#35270;&#39057;&#25110;&#25991;&#26412;&#65289;&#30456;&#27604;&#65292;&#22270;&#34920;&#26159;&#19968;&#31181;&#21253;&#21547;&#20016;&#23500;&#32467;&#26500;&#21644;&#20851;&#31995;&#20449;&#24687;&#30340;&#25968;&#25454;&#31867;&#22411;&#12290;&#21516;&#26102;&#65292;&#20316;&#20026;&#26368;&#20855;&#34920;&#29616;&#21147;&#30340;&#23186;&#20171;&#20043;&#19968;&#65292;&#33258;&#28982;&#35821;&#35328;&#22312;&#25551;&#36848;&#22797;&#26434;&#32467;&#26500;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#23558;&#22270;&#34920;&#23398;&#20064;&#38382;&#39064;&#32435;&#20837;&#29983;&#25104;&#24335;&#35821;&#35328;&#24314;&#27169;&#26694;&#26550;&#30340;&#29616;&#26377;&#24037;&#20316;&#20173;&#28982;&#38750;&#24120;&#26377;&#38480;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#19981;&#26029;&#22686;&#38271;&#65292;&#25506;&#32034;LLMs&#26159;&#21542;&#20063;&#21487;&#20197;&#26367;&#20195;GNNs&#25104;&#20026;&#22270;&#34920;&#30340;&#22522;&#30784;&#27169;&#22411;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;InstructGLM&#65288;&#32467;&#26500;&#21270;&#35821;&#35328;&#27169;&#22411;&#65289;&#31639;&#27861;&#65292;&#31995;&#32479;&#22320;&#35774;&#35745;&#39640;&#24230;&#21487;&#25193;&#23637;&#30340;&#27169;&#22411;&#26469;&#22788;&#29702;&#22270;&#34920;&#23398;&#20064;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#35805;&#24335;&#25628;&#32034;&#20013;&#29992;&#25143;&#21709;&#24212;&#27169;&#25311;&#30340;&#26041;&#27861;&#12290;&#24403;&#21069;&#30340;&#27169;&#25311;&#31995;&#32479;&#35201;&#20040;&#21482;&#33021;&#23545;&#26159;&#38750;&#38382;&#39064;&#36827;&#34892;&#22238;&#31572;&#65292;&#35201;&#20040;&#26080;&#27861;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#21709;&#24212;&#12290;&#36890;&#36807;&#29992;&#26356;&#23567;&#20294;&#20808;&#36827;&#30340;&#31995;&#32479;&#26367;&#25442;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#29992;&#25143;&#27169;&#25311;&#31995;&#32479;&#65292;&#33021;&#22815;&#26174;&#33879;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.07944</link><description>&lt;p&gt;
&#35770;&#29992;&#25143;&#21709;&#24212;&#27169;&#25311;&#22312;&#23545;&#35805;&#24335;&#25628;&#32034;&#20013;&#30340;&#28145;&#20837;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An In-depth Investigation of User Response Simulation for Conversational Search. (arXiv:2304.07944v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#35805;&#24335;&#25628;&#32034;&#20013;&#29992;&#25143;&#21709;&#24212;&#27169;&#25311;&#30340;&#26041;&#27861;&#12290;&#24403;&#21069;&#30340;&#27169;&#25311;&#31995;&#32479;&#35201;&#20040;&#21482;&#33021;&#23545;&#26159;&#38750;&#38382;&#39064;&#36827;&#34892;&#22238;&#31572;&#65292;&#35201;&#20040;&#26080;&#27861;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#21709;&#24212;&#12290;&#36890;&#36807;&#29992;&#26356;&#23567;&#20294;&#20808;&#36827;&#30340;&#31995;&#32479;&#26367;&#25442;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#29992;&#25143;&#27169;&#25311;&#31995;&#32479;&#65292;&#33021;&#22815;&#26174;&#33879;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#24335;&#25628;&#32034;&#22312;&#20449;&#24687;&#26816;&#32034;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#23427;&#36890;&#36807;&#22810;&#27425;&#33258;&#28982;&#35821;&#35328;&#20132;&#20114;&#26469;&#28548;&#28165;&#21644;&#35299;&#20915;&#29992;&#25143;&#30340;&#25628;&#32034;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#31995;&#32479;&#26159;&#36890;&#36807;&#35760;&#24405;&#25110;&#20154;&#24037;&#23545;&#35805;&#26085;&#24535;&#36827;&#34892;&#35757;&#32451;&#21644;&#28436;&#31034;&#30340;&#12290;&#26368;&#32456;&#65292;&#23545;&#35805;&#24335;&#25628;&#32034;&#31995;&#32479;&#24212;&#35813;&#22312;&#26410;&#35265;&#36807;&#30340;&#23545;&#35805;&#36712;&#36857;&#30340;&#24320;&#25918;&#29615;&#22659;&#20013;&#36827;&#34892;&#35757;&#32451;&#12289;&#35780;&#20272;&#21644;&#37096;&#32626;&#12290;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#26159;&#35757;&#32451;&#21644;&#35780;&#20272;&#36825;&#26679;&#30340;&#31995;&#32479;&#37117;&#38656;&#35201;&#20154;&#24037;&#21442;&#19982;&#65292;&#36825;&#26082;&#26114;&#36149;&#21448;&#19981;&#21487;&#25193;&#23637;&#12290;&#20854;&#20013;&#19968;&#31181;&#31574;&#30053;&#26159;&#27169;&#25311;&#29992;&#25143;&#65292;&#20197;&#27492;&#26469;&#20943;&#23569;&#25193;&#23637;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#29992;&#25143;&#27169;&#25311;&#22120;&#35201;&#20040;&#20165;&#38480;&#20110;&#23545;&#23545;&#35805;&#25628;&#32034;&#31995;&#32479;&#30340;&#26159;&#38750;&#38382;&#39064;&#36827;&#34892;&#22238;&#31572;&#65292;&#35201;&#20040;&#26080;&#27861;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#21709;&#24212;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#36890;&#36807;&#29992;&#19968;&#20010;&#26356;&#23567;&#20294;&#20808;&#36827;&#30340;&#31995;&#32479;&#26469;&#26367;&#25442;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#29992;&#25143;&#27169;&#25311;&#31995;&#32479;&#65292;&#33021;&#22815;&#22823;&#24133;&#25913;&#36827;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational search has seen increased recent attention in both the IR and NLP communities. It seeks to clarify and solve a user's search need through multi-turn natural language interactions. However, most existing systems are trained and demonstrated with recorded or artificial conversation logs. Eventually, conversational search systems should be trained, evaluated, and deployed in an open-ended setting with unseen conversation trajectories. A key challenge is that training and evaluating such systems both require a human-in-the-loop, which is expensive and does not scale. One strategy for this is to simulate users, thereby reducing the scaling costs. However, current user simulators are either limited to only respond to yes-no questions from the conversational search system, or unable to produce high quality responses in general.  In this paper, we show that current state-of-the-art user simulation system could be significantly improved by replacing it with a smaller but advanced
&lt;/p&gt;</description></item></channel></rss>