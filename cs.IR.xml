<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;CLIP&#27169;&#22411;&#30340;&#22810;&#27169;&#24577;&#23884;&#20837;&#36136;&#37327;&#65292;&#24182;&#21457;&#29616;&#20854;&#32479;&#19968;&#24615;&#21644;&#23545;&#40784;&#24615;&#19981;&#36275;&#65292;&#38480;&#21046;&#20102;&#23884;&#20837;&#30340;&#20256;&#36882;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#24494;&#35843;&#26041;&#27861;&#65292;&#36890;&#36807;&#39640;&#24230;&#20960;&#20309;&#22810;&#27169;&#22411;&#28151;&#21512;&#29983;&#25104;&#38590;&#36127;&#26679;&#26412;&#65292;&#24182;&#23545;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;</title><link>http://arxiv.org/abs/2203.03897</link><description>&lt;p&gt;
&#39640;&#24230;&#20960;&#20309;&#22810;&#27169;&#22411;&#28151;&#21512;&#29992;&#20110;&#40065;&#26834;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Geodesic Multi-Modal Mixup for Robust Fine-Tuning. (arXiv:2203.03897v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.03897
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;CLIP&#27169;&#22411;&#30340;&#22810;&#27169;&#24577;&#23884;&#20837;&#36136;&#37327;&#65292;&#24182;&#21457;&#29616;&#20854;&#32479;&#19968;&#24615;&#21644;&#23545;&#40784;&#24615;&#19981;&#36275;&#65292;&#38480;&#21046;&#20102;&#23884;&#20837;&#30340;&#20256;&#36882;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#24494;&#35843;&#26041;&#27861;&#65292;&#36890;&#36807;&#39640;&#24230;&#20960;&#20309;&#22810;&#27169;&#22411;&#28151;&#21512;&#29983;&#25104;&#38590;&#36127;&#26679;&#26412;&#65292;&#24182;&#23545;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#22411;&#27169;&#22411;&#65292;&#22914;CLIP&#65292;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#25552;&#20379;&#21487;&#36716;&#31227;&#30340;&#23884;&#20837;&#65292;&#24182;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#23545;&#23398;&#20064;&#21040;&#30340;&#22810;&#27169;&#22411;&#23884;&#20837;&#30340;&#20998;&#26512;&#30456;&#23545;&#36739;&#23569;&#65292;&#23884;&#20837;&#30340;&#21487;&#36716;&#31227;&#24615;&#26377;&#24453;&#25913;&#36827;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;CLIP&#20026;&#20004;&#31181;&#19981;&#21516;&#30340;&#27169;&#24577;&#20445;&#30041;&#20102;&#20998;&#31163;&#30340;&#23884;&#20837;&#23376;&#31354;&#38388;&#65292;&#24182;&#36890;&#36807;&#32479;&#19968;&#23545;&#40784;&#30340;&#35270;&#35282;&#23545;&#20854;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20197;&#34913;&#37327;&#23398;&#20064;&#34920;&#31034;&#30340;&#36136;&#37327;&#12290;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#24494;&#35843;&#20043;&#21518;&#65292;CLIP&#20173;&#28982;&#20445;&#25345;&#30528;&#36739;&#24046;&#30340;&#32479;&#19968;&#24615;&#21644;&#23545;&#40784;&#24615;&#12290;&#36825;&#31181;&#32570;&#20047;&#23545;&#40784;&#21644;&#32479;&#19968;&#24615;&#21487;&#33021;&#38480;&#21046;&#20102;&#23884;&#20837;&#30340;&#20256;&#36882;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#40065;&#26834;&#34920;&#31034;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#25552;&#20379;&#26356;&#22909;&#30340;&#23545;&#40784;&#21644;&#32479;&#19968;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#24230;&#20960;&#20309;&#22810;&#27169;&#22411;&#28151;&#21512;&#26041;&#27861;&#65292;&#23558;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#23884;&#20837;&#28151;&#21512;&#22312;&#19968;&#36215;&#65292;&#22312;&#36229;&#29699;&#38754;&#19978;&#29983;&#25104;&#38590;&#36127;&#26679;&#26412;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23545;&#27169;&#22411;&#36827;&#34892;&#40065;&#26834;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained multi-modal models, such as CLIP, provide transferable embeddings and show promising results in diverse applications. However, the analysis of learned multi-modal embeddings is relatively unexplored, and the embedding transferability can be improved. In this work, we observe that CLIP holds separated embedding subspaces for two different modalities, and then we investigate it through the lens of uniformity-alignment to measure the quality of learned representation. Both theoretically and empirically, we show that CLIP retains poor uniformity and alignment even after fine-tuning. Such a lack of alignment and uniformity might restrict the transferability and robustness of embeddings. To this end, we devise a new fine-tuning method for robust representation equipping better alignment and uniformity. First, we propose a Geodesic Multi-Modal Mixup that mixes the embeddings of image and text to generate hard negative samples on the hypersphere. Then, we fine-tune the model on har
&lt;/p&gt;</description></item></channel></rss>