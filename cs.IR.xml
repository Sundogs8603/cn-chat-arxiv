<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#20195;&#30721;&#29255;&#27573;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#25688;&#35201;&#30340;&#20219;&#21153;&#65292;&#21457;&#29616;&#20195;&#30721;LLMs&#20248;&#20110;&#36890;&#29992;&#23545;&#24212;&#27169;&#22411;&#65292;&#22312;&#22788;&#29702;&#20855;&#26377;&#19981;&#30456;&#20284;&#20998;&#24067;&#30340;&#25968;&#25454;&#38598;&#26102;&#65292;&#38646;&#26679;&#26412;&#26041;&#27861;&#21487;&#20197;&#24471;&#21040;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.16673</link><description>&lt;p&gt;
&#25506;&#32034;&#29992;&#20110;&#20195;&#30721;&#35299;&#37322;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Exploring Large Language Models for Code Explanation. (arXiv:2310.16673v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#20195;&#30721;&#29255;&#27573;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#25688;&#35201;&#30340;&#20219;&#21153;&#65292;&#21457;&#29616;&#20195;&#30721;LLMs&#20248;&#20110;&#36890;&#29992;&#23545;&#24212;&#27169;&#22411;&#65292;&#22312;&#22788;&#29702;&#20855;&#26377;&#19981;&#30456;&#20284;&#20998;&#24067;&#30340;&#25968;&#25454;&#38598;&#26102;&#65292;&#38646;&#26679;&#26412;&#26041;&#27861;&#21487;&#20197;&#24471;&#21040;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#20195;&#30721;&#25991;&#26723;&#36890;&#36807;&#35299;&#37322;&#24615;&#25991;&#26412;&#22312;&#20195;&#30721;&#29702;&#35299;&#26041;&#38754;&#21487;&#33021;&#38750;&#24120;&#26377;&#30410;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#65292;&#29305;&#21035;&#26159;&#22312;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#20013;&#65292;&#22914;&#20195;&#30721;&#29983;&#25104;&#21644;&#20195;&#30721;&#25688;&#35201;&#12290;&#26412;&#30740;&#31350;&#20855;&#20307;&#30740;&#31350;&#20102;&#20351;&#29992;&#21508;&#31181;LLMs&#20026;&#20195;&#30721;&#29255;&#27573;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#25688;&#35201;&#30340;&#20219;&#21153;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20195;&#30721;LLMs&#20248;&#20110;&#20854;&#36890;&#29992;&#23545;&#24212;&#27169;&#22411;&#65292;&#24182;&#19988;&#24403;&#22788;&#29702;&#20855;&#26377;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20043;&#38388;&#20998;&#24067;&#19981;&#30456;&#20284;&#30340;&#25968;&#25454;&#38598;&#26102;&#65292;&#38646;&#26679;&#26412;&#26041;&#27861;&#20135;&#29983;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automating code documentation through explanatory text can prove highly beneficial in code understanding. Large Language Models (LLMs) have made remarkable strides in Natural Language Processing, especially within software engineering tasks such as code generation and code summarization. This study specifically delves into the task of generating natural-language summaries for code snippets, using various LLMs. The findings indicate that Code LLMs outperform their generic counterparts, and zero-shot methods yield superior results when dealing with datasets with dissimilar distributions between training and testing sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;Web-DRO&#65292;&#23427;&#21033;&#29992;&#32593;&#32476;&#32467;&#26500;&#36827;&#34892;&#32858;&#31867;&#24182;&#37325;&#26032;&#21152;&#26435;&#65292;&#22312;&#26080;&#30417;&#30563;&#22330;&#26223;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26816;&#32034;&#25928;&#26524;&#12290;&#32676;&#32452;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26041;&#27861;&#25351;&#23548;&#27169;&#22411;&#23545;&#39640;&#23545;&#27604;&#25439;&#22833;&#30340;&#32676;&#32452;&#20998;&#37197;&#26356;&#22810;&#26435;&#37325;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26356;&#21152;&#20851;&#27880;&#26368;&#22351;&#24773;&#20917;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#32467;&#21512;URL&#20449;&#24687;&#30340;&#32593;&#32476;&#22270;&#35757;&#32451;&#33021;&#36798;&#21040;&#26368;&#20339;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.16605</link><description>&lt;p&gt;
&#22522;&#20110;&#32593;&#32476;&#22270;&#30340;&#20998;&#24067;&#40065;&#26834;&#26080;&#30417;&#30563;&#23494;&#38598;&#26816;&#32034;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Unsupervised Dense Retrieval Training on Web Graphs. (arXiv:2310.16605v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;Web-DRO&#65292;&#23427;&#21033;&#29992;&#32593;&#32476;&#32467;&#26500;&#36827;&#34892;&#32858;&#31867;&#24182;&#37325;&#26032;&#21152;&#26435;&#65292;&#22312;&#26080;&#30417;&#30563;&#22330;&#26223;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26816;&#32034;&#25928;&#26524;&#12290;&#32676;&#32452;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26041;&#27861;&#25351;&#23548;&#27169;&#22411;&#23545;&#39640;&#23545;&#27604;&#25439;&#22833;&#30340;&#32676;&#32452;&#20998;&#37197;&#26356;&#22810;&#26435;&#37325;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26356;&#21152;&#20851;&#27880;&#26368;&#22351;&#24773;&#20917;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#32467;&#21512;URL&#20449;&#24687;&#30340;&#32593;&#32476;&#22270;&#35757;&#32451;&#33021;&#36798;&#21040;&#26368;&#20339;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Web-DRO&#65292;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#32467;&#26500;&#36827;&#34892;&#32858;&#31867;&#24182;&#22312;&#23545;&#27604;&#35757;&#32451;&#26399;&#38388;&#37325;&#26032;&#21152;&#26435;&#30340;&#26080;&#30417;&#30563;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#21033;&#29992;&#32593;&#32476;&#22270;&#38142;&#25509;&#24182;&#23545;&#38170;&#28857;-&#25991;&#26723;&#23545;&#36827;&#34892;&#23545;&#27604;&#35757;&#32451;&#65292;&#35757;&#32451;&#19968;&#20010;&#23884;&#20837;&#27169;&#22411;&#29992;&#20110;&#32858;&#31867;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#32676;&#32452;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26041;&#27861;&#26469;&#37325;&#26032;&#21152;&#26435;&#19981;&#21516;&#30340;&#38170;&#28857;-&#25991;&#26723;&#23545;&#32676;&#32452;&#65292;&#36825;&#25351;&#23548;&#27169;&#22411;&#23558;&#26356;&#22810;&#26435;&#37325;&#20998;&#37197;&#32473;&#23545;&#27604;&#25439;&#22833;&#26356;&#39640;&#30340;&#32676;&#32452;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26356;&#21152;&#20851;&#27880;&#26368;&#22351;&#24773;&#20917;&#12290;&#22312;MS MARCO&#21644;BEIR&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;Web-DRO&#22312;&#26080;&#30417;&#30563;&#22330;&#26223;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26816;&#32034;&#25928;&#26524;&#12290;&#23545;&#32858;&#31867;&#25216;&#26415;&#30340;&#27604;&#36739;&#34920;&#26126;&#65292;&#32467;&#21512;URL&#20449;&#24687;&#30340;&#32593;&#32476;&#22270;&#35757;&#32451;&#33021;&#36798;&#21040;&#26368;&#20339;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;&#36827;&#19968;&#27493;&#20998;&#26512;&#35777;&#23454;&#20102;&#32676;&#32452;&#26435;&#37325;&#30340;&#31283;&#23450;&#24615;&#21644;&#26377;&#25928;&#24615;&#65292;&#34920;&#26126;&#20102;&#19968;&#33268;&#30340;&#27169;&#22411;&#20559;&#22909;&#20197;&#21450;&#23545;&#26377;&#20215;&#20540;&#25991;&#26723;&#30340;&#26377;&#25928;&#21152;&#26435;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces Web-DRO, an unsupervised dense retrieval model, which clusters documents based on web structures and reweights the groups during contrastive training. Specifically, we first leverage web graph links and contrastively train an embedding model for clustering anchor-document pairs. Then we use Group Distributional Robust Optimization to reweight different clusters of anchor-document pairs, which guides the model to assign more weights to the group with higher contrastive loss and pay more attention to the worst case during training. Our experiments on MS MARCO and BEIR show that our model, Web-DRO, significantly improves the retrieval effectiveness in unsupervised scenarios. A comparison of clustering techniques shows that training on the web graph combining URL information reaches optimal performance on clustering. Further analysis confirms that group weights are stable and valid, indicating consistent model preferences as well as effective up-weighting of valuable 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#22686;&#24378;&#30340;&#23545;&#27604;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#21644;&#36807;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.16566</link><description>&lt;p&gt;
&#27169;&#22411;&#22686;&#24378;&#30340;&#23545;&#27604;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Model-enhanced Contrastive Reinforcement Learning for Sequential Recommendation. (arXiv:2310.16566v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16566
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#22686;&#24378;&#30340;&#23545;&#27604;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#21644;&#36807;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#24191;&#27867;&#24212;&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#65292;&#22240;&#20026;&#20854;&#28508;&#21147;&#22312;&#20110;&#20248;&#21270;&#29992;&#25143;&#30340;&#38271;&#26399;&#21442;&#19982;&#24230;&#12290;&#20174;&#24378;&#21270;&#23398;&#20064;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25512;&#33616;&#21487;&#20197;&#34987;&#24418;&#24335;&#21270;&#20026;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#65292;&#20854;&#20013;&#25512;&#33616;&#31995;&#32479;(&#20195;&#29702;)&#21487;&#20197;&#19982;&#29992;&#25143;(&#29615;&#22659;)&#36827;&#34892;&#20132;&#20114;&#65292;&#24182;&#33719;&#24471;&#21453;&#39304;(&#22870;&#21169;&#20449;&#21495;)&#12290;&#28982;&#32780;&#65292;&#20986;&#20110;&#23545;&#29992;&#25143;&#20307;&#39564;&#21644;&#23454;&#29616;&#22797;&#26434;&#24615;&#30340;&#32771;&#34385;&#65292;&#36827;&#34892;&#22312;&#32447;&#20132;&#20114;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#65292;&#25105;&#20204;&#21482;&#33021;&#20351;&#29992;&#21253;&#21547;&#26377;&#38480;&#22870;&#21169;&#20449;&#21495;&#21644;&#29366;&#24577;&#36716;&#25442;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;RL&#25512;&#33616;&#32773;&#12290;&#22240;&#27492;&#65292;&#22870;&#21169;&#20449;&#21495;&#21644;&#29366;&#24577;&#36716;&#25442;&#30340;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#38750;&#24120;&#20005;&#37325;&#65292;&#32780;&#36825;&#19968;&#38382;&#39064;&#19968;&#30452;&#34987;&#29616;&#26377;&#30340;RL&#25512;&#33616;&#31995;&#32479;&#24573;&#35270;&#12290;&#26356;&#31967;&#31957;&#30340;&#26159;&#65292;RL&#26041;&#27861;&#36890;&#36807;&#35797;&#38169;&#27169;&#24335;&#26469;&#23398;&#20064;&#65292;&#20294;&#22312;&#38544;&#24335;&#21453;&#39304;&#25512;&#33616;&#20219;&#21153;&#20013;&#26080;&#27861;&#33719;&#24471;&#36127;&#21453;&#39304;&#65292;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#31163;&#32447;RL&#25512;&#33616;&#32773;&#30340;&#36807;&#20272;&#35745;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#22686;&#24378;&#30340;&#23545;&#27604;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) has been widely applied in recommendation systems due to its potential in optimizing the long-term engagement of users. From the perspective of RL, recommendation can be formulated as a Markov decision process (MDP), where recommendation system (agent) can interact with users (environment) and acquire feedback (reward signals).However, it is impractical to conduct online interactions with the concern on user experience and implementation complexity, and we can only train RL recommenders with offline datasets containing limited reward signals and state transitions. Therefore, the data sparsity issue of reward signals and state transitions is very severe, while it has long been overlooked by existing RL recommenders.Worse still, RL methods learn through the trial-and-error mode, but negative feedback cannot be obtained in implicit feedback recommendation tasks, which aggravates the overestimation problem of offline RL recommender. To address these challenges, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;PEARLM&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#24320;&#23637;&#22522;&#20110;&#36335;&#24452;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#33616;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23545;&#39044;&#35757;&#32451;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#30340;&#20381;&#36182;&#20197;&#21450;&#26410;&#20805;&#20998;&#21033;&#29992;&#23454;&#20307;&#21644;&#20851;&#31995;&#20043;&#38388;&#30456;&#20114;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#65292;&#36824;&#36991;&#20813;&#20102;&#29983;&#25104;&#19981;&#20934;&#30830;&#30340;&#35299;&#37322;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>http://arxiv.org/abs/2310.16452</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;&#36335;&#24452;&#30340;&#30693;&#35782;&#22270;&#25512;&#33616;&#20013;&#30340;&#24544;&#23454;&#36335;&#24452;&#35821;&#35328;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Faithful Path Language Modelling for Explainable Recommendation over Knowledge Graph. (arXiv:2310.16452v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;PEARLM&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#24320;&#23637;&#22522;&#20110;&#36335;&#24452;&#30340;&#30693;&#35782;&#22270;&#35889;&#25512;&#33616;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23545;&#39044;&#35757;&#32451;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#30340;&#20381;&#36182;&#20197;&#21450;&#26410;&#20805;&#20998;&#21033;&#29992;&#23454;&#20307;&#21644;&#20851;&#31995;&#20043;&#38388;&#30456;&#20114;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#65292;&#36824;&#36991;&#20813;&#20102;&#29983;&#25104;&#19981;&#20934;&#30830;&#30340;&#35299;&#37322;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#36335;&#24452;&#25512;&#29702;&#26041;&#27861;&#22312;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#36879;&#26126;&#24230;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PEARLM&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#26377;&#25928;&#25429;&#33719;&#29992;&#25143;&#34892;&#20026;&#21644;&#20135;&#21697;&#31471;&#30693;&#35782;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30452;&#25509;&#20174;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#36335;&#24452;&#20013;&#23398;&#20064;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#65292;&#24182;&#23558;&#23454;&#20307;&#21644;&#20851;&#31995;&#32479;&#19968;&#22312;&#21516;&#19968;&#20248;&#21270;&#31354;&#38388;&#20013;&#12290;&#24207;&#21015;&#35299;&#30721;&#30340;&#32422;&#26463;&#20445;&#35777;&#20102;&#36335;&#24452;&#23545;&#30693;&#35782;&#22270;&#35889;&#30340;&#24544;&#23454;&#24615;&#12290;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Path reasoning methods over knowledge graphs have gained popularity for their potential to improve transparency in recommender systems. However, the resulting models still rely on pre-trained knowledge graph embeddings, fail to fully exploit the interdependence between entities and relations in the KG for recommendation, and may generate inaccurate explanations. In this paper, we introduce PEARLM, a novel approach that efficiently captures user behaviour and product-side knowledge through language modelling. With our approach, knowledge graph embeddings are directly learned from paths over the KG by the language model, which also unifies entities and relations in the same optimisation space. Constraints on the sequence decoding additionally guarantee path faithfulness with respect to the KG. Experiments on two datasets show the effectiveness of our approach compared to state-of-the-art baselines. Source code and datasets: AVAILABLE AFTER GETTING ACCEPTED.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#25512;&#33616;&#31995;&#32479;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32467;&#21512;&#20197;&#23454;&#29616;&#39034;&#24207;&#25512;&#33616;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#24037;&#20316;&#20027;&#35201;&#32771;&#34385;&#21333;&#38190;&#24773;&#20917;&#65292;&#32780;&#24573;&#30053;&#20102;&#22810;&#38190;&#20540;&#25968;&#25454;&#30340;&#37325;&#35201;&#24615;&#12290;&#26412;&#30740;&#31350;&#30340;&#36129;&#29486;&#22312;&#20110;&#35299;&#20915;&#20102;&#23454;&#38469;&#24212;&#29992;&#20013;&#22810;&#38190;&#20540;&#25968;&#25454;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.16409</link><description>&lt;p&gt;
&#34701;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#22810;&#38190;&#20540;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Multiple Key-value Strategy in Recommendation Systems Incorporating Large Language Model. (arXiv:2310.16409v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16409
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#25512;&#33616;&#31995;&#32479;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32467;&#21512;&#20197;&#23454;&#29616;&#39034;&#24207;&#25512;&#33616;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#24037;&#20316;&#20027;&#35201;&#32771;&#34385;&#21333;&#38190;&#24773;&#20917;&#65292;&#32780;&#24573;&#30053;&#20102;&#22810;&#38190;&#20540;&#25968;&#25454;&#30340;&#37325;&#35201;&#24615;&#12290;&#26412;&#30740;&#31350;&#30340;&#36129;&#29486;&#22312;&#20110;&#35299;&#20915;&#20102;&#23454;&#38469;&#24212;&#29992;&#20013;&#22810;&#38190;&#20540;&#25968;&#25454;&#30340;&#25512;&#33616;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#28385;&#36275;&#20114;&#32852;&#32593;&#24212;&#29992;&#20013;&#29992;&#25143;&#20449;&#24687;&#38656;&#27714;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#36890;&#24120;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#23884;&#20837;&#32454;&#33410;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31038;&#21306;&#21462;&#24471;&#37325;&#22823;&#31361;&#30772;&#12290;&#22240;&#27492;&#65292;&#23558;&#25512;&#33616;&#31995;&#32479;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26356;&#22909;&#22320;&#32467;&#21512;&#36215;&#26469;&#25104;&#20026;&#20102;&#26032;&#20852;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#23613;&#31649;&#19968;&#20123;&#29616;&#26377;&#24037;&#20316;&#23545;&#27492;&#38382;&#39064;&#26377;&#25152;&#36129;&#29486;&#65292;&#20294;&#20027;&#35201;&#32771;&#34385;&#21333;&#38190;&#24773;&#20917;&#65288;&#22914;&#21382;&#21490;&#20132;&#20114;&#65289;&#65292;&#29305;&#21035;&#26159;&#22312;&#39034;&#24207;&#25512;&#33616;&#20013;&#65292;&#22810;&#38190;&#20540;&#25968;&#25454;&#30340;&#24773;&#20917;&#34987;&#31616;&#21333;&#24573;&#30053;&#12290;&#28982;&#32780;&#65292;&#22810;&#38190;&#20540;&#25968;&#25454;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26159;&#20027;&#27969;&#22330;&#26223;&#65292;&#29992;&#25143;&#30340;&#20449;&#24687;&#65288;&#22914;&#24180;&#40836;&#12289;&#32844;&#19994;&#31561;&#65289;&#21644;&#29289;&#21697;&#30340;&#20449;&#24687;&#65288;&#22914;&#26631;&#39064;&#12289;&#31867;&#21035;&#31561;&#65289;&#20855;&#26377;&#22810;&#20010;&#38190;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26088;&#22312;&#22522;&#20110;&#22810;&#38190;&#20540;&#25968;&#25454;&#23454;&#29616;&#39034;&#24207;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation system (RS) plays significant roles in matching users information needs for Internet applications, and it usually utilizes the vanilla neural network as the backbone to handle embedding details. Recently, the large language model (LLM) has exhibited emergent abilities and achieved great breakthroughs both in the CV and NLP communities. Thus, it is logical to incorporate RS with LLM better, which has become an emerging research direction. Although some existing works have made their contributions to this issue, they mainly consider the single key situation (e.g. historical interactions), especially in sequential recommendation. The situation of multiple key-value data is simply neglected. This significant scenario is mainstream in real practical applications, where the information of users (e.g. age, occupation, etc) and items (e.g. title, category, etc) has more than one key. Therefore, we aim to implement sequential recommendations based on multiple key-value data by in
&lt;/p&gt;</description></item><item><title>URL-BERT&#26159;&#19968;&#31181;&#36890;&#36807;&#31038;&#20132;&#23186;&#20307;&#20114;&#21160;&#35757;&#32451;&#32593;&#39029;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#39044;&#35757;&#32451;&#30446;&#26631;&#21644;&#23545;&#27604;&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#23545;URL&#21644;&#32593;&#39029;&#30340;&#26356;&#22909;&#29702;&#35299;&#21644;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.16303</link><description>&lt;p&gt;
URL-BERT: &#36890;&#36807;&#31038;&#20132;&#23186;&#20307;&#20114;&#21160;&#35757;&#32451;&#32593;&#39029;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
URL-BERT: Training Webpage Representations via Social Media Engagements. (arXiv:2310.16303v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16303
&lt;/p&gt;
&lt;p&gt;
URL-BERT&#26159;&#19968;&#31181;&#36890;&#36807;&#31038;&#20132;&#23186;&#20307;&#20114;&#21160;&#35757;&#32451;&#32593;&#39029;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#39044;&#35757;&#32451;&#30446;&#26631;&#21644;&#23545;&#27604;&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#23545;URL&#21644;&#32593;&#39029;&#30340;&#26356;&#22909;&#29702;&#35299;&#21644;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#21644;&#34920;&#31034;&#32593;&#39029;&#23545;&#20110;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#33267;&#20851;&#37325;&#35201;&#65292;&#29992;&#25143;&#21487;&#20197;&#20998;&#20139;&#21644;&#21442;&#19982;URL&#12290;&#24120;&#35265;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#32534;&#30721;&#22120;&#22914;BERT&#21487;&#20197;&#29992;&#20110;&#29702;&#35299;&#21644;&#34920;&#31034;&#32593;&#39029;&#30340;&#25991;&#26412;&#20869;&#23481;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#34920;&#31034;&#21487;&#33021;&#26080;&#27861;&#24314;&#27169;&#32593;&#22495;&#21644;URL&#30340;&#20027;&#39064;&#20449;&#24687;&#65292;&#20063;&#26080;&#27861;&#20934;&#30830;&#22320;&#25429;&#25417;&#23427;&#20204;&#23545;&#31038;&#20132;&#23186;&#20307;&#29992;&#25143;&#30340;&#21560;&#24341;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#39044;&#35757;&#32451;&#30446;&#26631;&#65292;&#29992;&#20110;&#20351;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;URL&#21644;&#32593;&#39029;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;&#65288;1&#65289;&#22522;&#20110;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#29992;&#25143;&#20114;&#21160;&#23398;&#20064;URL&#30340;&#27973;&#23618;&#34920;&#31034;&#30340;&#21487;&#25193;&#23637;&#22270;&#23884;&#20837;&#65292;&#20197;&#21450;&#65288;2&#65289;&#23558;LM&#34920;&#31034;&#19982;&#21069;&#36848;&#22522;&#20110;&#22270;&#30340;&#34920;&#31034;&#36827;&#34892;&#23545;&#40784;&#30340;&#23545;&#27604;&#30446;&#26631;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#26694;&#26550;&#24212;&#29992;&#21040;BERT&#30340;&#22810;&#35821;&#35328;&#29256;&#26412;&#19978;&#65292;&#24471;&#21040;&#20102;&#27169;&#22411;URL-BERT&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#25345;&#32493;&#39044;&#35757;&#32451;&#26041;&#27861;&#25913;&#21892;&#20102;&#21508;&#31181;&#20219;&#21153;&#30340;&#32593;&#39029;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding and representing webpages is crucial to online social networks where users may share and engage with URLs. Common language model (LM) encoders such as BERT can be used to understand and represent the textual content of webpages. However, these representations may not model thematic information of web domains and URLs or accurately capture their appeal to social media users. In this work, we introduce a new pre-training objective that can be used to adapt LMs to understand URLs and webpages. Our proposed framework consists of two steps: (1) scalable graph embeddings to learn shallow representations of URLs based on user engagement on social media and (2) a contrastive objective that aligns LM representations with the aforementioned graph-based representation. We apply our framework to the multilingual version of BERT to obtain the model URL-BERT. We experimentally demonstrate that our continued pre-training approach improves webpage understanding on a variety of tasks and 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35770;&#35777;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#20998;&#26512;&#20013;&#29305;&#24449;&#24402;&#22240;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#21644;&#26799;&#24230;&#26041;&#27861;&#19982;&#26367;&#20195;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#32771;&#34385;&#29992;&#25143;&#30340;&#32972;&#26223;&#20449;&#24687;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#24402;&#22240;&#30340;&#20934;&#30830;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16157</link><description>&lt;p&gt;
&#22522;&#20110;&#35770;&#35777;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#29305;&#24449;&#24402;&#22240;
&lt;/p&gt;
&lt;p&gt;
Context-aware feature attribution through argumentation. (arXiv:2310.16157v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35770;&#35777;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#20998;&#26512;&#20013;&#29305;&#24449;&#24402;&#22240;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#21644;&#26799;&#24230;&#26041;&#27861;&#19982;&#26367;&#20195;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21516;&#26102;&#32771;&#34385;&#29992;&#25143;&#30340;&#32972;&#26223;&#20449;&#24687;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#24402;&#22240;&#30340;&#20934;&#30830;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#24402;&#22240;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#22522;&#26412;&#20219;&#21153;&#65292;&#28041;&#21450;&#30830;&#23450;&#20010;&#21035;&#29305;&#24449;&#25110;&#21464;&#37327;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#36129;&#29486;&#12290;&#36825;&#20010;&#36807;&#31243;&#26377;&#21161;&#20110;&#30830;&#23450;&#39044;&#27979;&#32467;&#26524;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#30340;&#21382;&#21490;&#21487;&#20197;&#36861;&#28335;&#21040;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411; (GAMs)&#65292;&#23427;&#36890;&#36807;&#23558;&#22240;&#21464;&#37327;&#21644;&#33258;&#21464;&#37327;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#32435;&#20837;&#27169;&#22411;&#65292;&#25193;&#23637;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#21644;&#26367;&#20195;&#27169;&#22411;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#25581;&#31034;&#22797;&#26434;&#30340;&#20154;&#24037;&#26234;&#33021; (AI) &#31995;&#32479;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#24615;&#12290;GAMs &#24448;&#24448;&#33021;&#22815;&#36798;&#21040;&#36739;&#20302;&#30340;&#20934;&#30830;&#24615;&#65292;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#24456;&#38590;&#35299;&#37322;&#65292;&#26367;&#20195;&#27169;&#22411;&#36890;&#24120;&#23384;&#22312;&#31283;&#23450;&#24615;&#21644;&#20445;&#30495;&#24230;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#26041;&#27861;&#37117;&#27809;&#26377;&#32771;&#34385;&#29992;&#25143;&#30340;&#32972;&#26223;&#65292;&#32780;&#29992;&#25143;&#30340;&#32972;&#26223;&#21487;&#33021;&#20250;&#23545;&#20182;&#20204;&#30340;&#20559;&#22909;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#24182;&#25512;&#36827;&#24403;&#21069;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Feature attribution is a fundamental task in both machine learning and data analysis, which involves determining the contribution of individual features or variables to a model's output. This process helps identify the most important features for predicting an outcome. The history of feature attribution methods can be traced back to General Additive Models (GAMs), which extend linear regression models by incorporating non-linear relationships between dependent and independent variables. In recent years, gradient-based methods and surrogate models have been applied to unravel complex Artificial Intelligence (AI) systems, but these methods have limitations. GAMs tend to achieve lower accuracy, gradient-based methods can be difficult to interpret, and surrogate models often suffer from stability and fidelity issues. Furthermore, most existing methods do not consider users' contexts, which can significantly influence their preferences. To address these limitations and advance the current s
&lt;/p&gt;</description></item><item><title>Clinfo.ai&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;&#31995;&#32479;&#65292;&#20351;&#29992;&#31185;&#23398;&#25991;&#29486;&#22238;&#31572;&#21307;&#23398;&#38382;&#39064;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#26816;&#32034;&#21644;&#25277;&#35937;&#27010;&#25324;&#20219;&#21153;&#65292;&#21457;&#24067;&#20102;&#30456;&#24212;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.16146</link><description>&lt;p&gt;
Clinfo.ai:&#29992;&#31185;&#23398;&#25991;&#29486;&#22238;&#31572;&#21307;&#23398;&#38382;&#39064;&#30340;&#24320;&#28304;&#26816;&#32034;&#22686;&#24378;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model System for Answering Medical Questions using Scientific Literature. (arXiv:2310.16146v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16146
&lt;/p&gt;
&lt;p&gt;
Clinfo.ai&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;&#31995;&#32479;&#65292;&#20351;&#29992;&#31185;&#23398;&#25991;&#29486;&#22238;&#31572;&#21307;&#23398;&#38382;&#39064;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#26816;&#32034;&#21644;&#25277;&#35937;&#27010;&#25324;&#20219;&#21153;&#65292;&#21457;&#24067;&#20102;&#30456;&#24212;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21307;&#23398;&#25991;&#29486;&#30340;&#24555;&#36895;&#22686;&#38271;&#65292;&#21307;&#29983;&#21644;&#30740;&#31350;&#20154;&#21592;&#24456;&#38590;&#21450;&#26102;&#36319;&#19978;&#24182;&#24635;&#32467;&#26368;&#36817;&#30340;&#30456;&#20851;&#21457;&#29616;&#12290;&#34429;&#28982;&#29616;&#22312;&#23384;&#22312;&#20960;&#20010;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#38381;&#28304;&#25688;&#35201;&#24037;&#20855;&#65292;&#20294;&#20854;&#36755;&#20986;&#32467;&#26524;&#32570;&#20047;&#20005;&#26684;&#21644;&#31995;&#32479;&#30340;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#32570;&#20047;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#21644;&#36866;&#24403;&#30340;&#22522;&#20934;&#20219;&#21153;&#26469;&#35780;&#20272;&#36825;&#20123;&#24037;&#20855;&#12290;&#25105;&#20204;&#36890;&#36807;&#22235;&#20010;&#36129;&#29486;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65306;&#25105;&#20204;&#21457;&#24067;&#20102;&#21517;&#20026;Clinfo.ai&#30340;&#24320;&#28304;WebApp&#65292;&#23427;&#22522;&#20110;&#21160;&#24577;&#26816;&#32034;&#30340;&#31185;&#23398;&#25991;&#29486;&#22238;&#31572;&#20020;&#24202;&#38382;&#39064;&#65307;&#25105;&#20204;&#25351;&#23450;&#20102;&#19968;&#20010;&#20449;&#24687;&#26816;&#32034;&#21644;&#25277;&#35937;&#27010;&#25324;&#20219;&#21153;&#65292;&#20197;&#35780;&#20272;&#36825;&#31181;&#26816;&#32034;&#22686;&#24378;&#22411;LLM&#31995;&#32479;&#30340;&#24615;&#33021;&#65307;&#25105;&#20204;&#21457;&#24067;&#20102;&#19968;&#20010;&#21253;&#21547;200&#20010;&#38382;&#39064;&#21450;&#20854;&#23545;&#24212;&#31572;&#26696;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;PubMed&#26816;&#32034;&#21644;&#32508;&#36848;&#65288;PubMedRS-200&#65289;&#65307;&#24182;&#25253;&#21578;&#20102;Cli&#30340;&#22522;&#20934;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quickly-expanding nature of published medical literature makes it challenging for clinicians and researchers to keep up with and summarize recent, relevant findings in a timely manner. While several closed-source summarization tools based on large language models (LLMs) now exist, rigorous and systematic evaluations of their outputs are lacking. Furthermore, there is a paucity of high-quality datasets and appropriate benchmark tasks with which to evaluate these tools. We address these issues with four contributions: we release Clinfo.ai, an open-source WebApp that answers clinical questions based on dynamically retrieved scientific literature; we specify an information retrieval and abstractive summarization task to evaluate the performance of such retrieval-augmented LLM systems; we release a dataset of 200 questions and corresponding answers derived from published systematic reviews, which we name PubMed Retrieval and Synthesis (PubMedRS-200); and report benchmark results for Cli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CA-KGCN&#65292;&#19968;&#20010;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#25512;&#33616;&#31995;&#32479;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#35821;&#20041;&#20851;&#31995;&#32435;&#20837;&#24314;&#27169;&#65292;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16141</link><description>&lt;p&gt;
&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#21487;&#35299;&#37322;&#30693;&#35782;&#22270;&#35889;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Context-aware explainable recommendations over knowledge graphs. (arXiv:2310.16141v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CA-KGCN&#65292;&#19968;&#20010;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#25512;&#33616;&#31995;&#32479;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#35821;&#20041;&#20851;&#31995;&#32435;&#20837;&#24314;&#27169;&#65292;&#25552;&#39640;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#21253;&#21547;&#19982;&#39033;&#30446;&#30456;&#20851;&#30340;&#20016;&#23500;&#35821;&#20041;&#20851;&#31995;&#65292;&#23558;&#36825;&#20123;&#35821;&#20041;&#20851;&#31995;&#32435;&#20837;&#25512;&#33616;&#31995;&#32479;&#26377;&#21161;&#20110;&#25506;&#32034;&#39033;&#30446;&#30340;&#28508;&#22312;&#36830;&#25509;&#65292;&#20174;&#32780;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#24182;&#22686;&#24378;&#25512;&#33616;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#21487;&#35299;&#37322;&#24615;&#19981;&#36866;&#24212;&#29992;&#25143;&#30340;&#24773;&#22659;&#65292;&#32780;&#24773;&#22659;&#21487;&#20197;&#26174;&#33879;&#24433;&#21709;&#20854;&#20559;&#22909;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;CA-KGCN&#65288;&#19978;&#19979;&#25991;&#24863;&#30693;&#30693;&#35782;&#22270;&#35889;&#21367;&#31215;&#32593;&#32476;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#30340;&#24773;&#22659;&#26469;&#24314;&#27169;&#20854;&#20559;&#22909;&#65292;&#24182;&#23558;&#19982;&#39033;&#30446;&#30456;&#20851;&#30340;&#20016;&#23500;&#35821;&#20041;&#20851;&#31995;&#32435;&#20837;&#30693;&#35782;&#22270;&#35889;&#20013;&#12290;&#35813;&#26694;&#26550;&#25429;&#25417;&#29992;&#25143;&#23545;&#19981;&#21516;&#22240;&#32032;&#30340;&#27880;&#24847;&#21147;&#65306;&#19978;&#19979;&#25991;&#21644;&#39033;&#30446;&#29305;&#24449;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#26681;&#25454;&#29305;&#23450;&#24773;&#22659;&#24314;&#27169;&#29992;&#25143;&#30340;&#20559;&#22909;&#24182;&#25552;&#20379;&#36866;&#24212;&#32473;&#23450;&#24773;&#22659;&#30340;&#35299;&#37322;&#12290;&#22312;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graphs contain rich semantic relationships related to items and incorporating such semantic relationships into recommender systems helps to explore the latent connections of items, thus improving the accuracy of prediction and enhancing the explainability of recommendations. However, such explainability is not adapted to users' contexts, which can significantly influence their preferences. In this work, we propose CA-KGCN (Context-Aware Knowledge Graph Convolutional Network), an end-to-end framework that can model users' preferences adapted to their contexts and can incorporate rich semantic relationships in the knowledge graph related to items. This framework captures users' attention to different factors: contexts and features of items. More specifically, the framework can model users' preferences adapted to their contexts and provide explanations adapted to the given context. Experiments on three real-world datasets show the effectiveness of our framework: modeling users' 
&lt;/p&gt;</description></item><item><title>TCRA-LLM&#26159;&#36890;&#36807;&#27010;&#36848;&#21387;&#32553;&#21644;&#35821;&#20041;&#21387;&#32553;&#20004;&#31181;&#26041;&#27861;&#26469;&#20943;&#23569;&#21830;&#19994;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#25104;&#26412;&#30340;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.15556</link><description>&lt;p&gt;
TCRA-LLM: &#29992;&#20110;&#20943;&#23569;&#25512;&#29702;&#25104;&#26412;&#30340;&#20196;&#29260;&#21387;&#32553;&#26816;&#32034;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction. (arXiv:2310.15556v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15556
&lt;/p&gt;
&lt;p&gt;
TCRA-LLM&#26159;&#36890;&#36807;&#27010;&#36848;&#21387;&#32553;&#21644;&#35821;&#20041;&#21387;&#32553;&#20004;&#31181;&#26041;&#27861;&#26469;&#20943;&#23569;&#21830;&#19994;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#25104;&#26412;&#30340;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;ChatGPT&#21457;&#24067;&#20102;API&#20379;&#20844;&#20247;&#20351;&#29992;&#20197;&#26469;&#65292;&#26500;&#24314;&#22312;&#21830;&#19994;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20043;&#19978;&#30340;&#24212;&#29992;&#31243;&#24207;&#25968;&#37327;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#19968;&#20010;&#27969;&#34892;&#29992;&#27861;&#26159;&#21033;&#29992;&#20854;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#24182;&#29983;&#25104;&#21709;&#24212;&#20197;&#22238;&#31572;&#29992;&#25143;&#26597;&#35810;&#65292;&#24182;&#21033;&#29992;&#26816;&#32034;&#22686;&#24378;&#33719;&#24471;&#30340;&#30693;&#35782;&#12290;&#37096;&#32626;&#21830;&#19994;&#26816;&#32034;&#22686;&#24378;&#22411;LLM&#30340;&#19968;&#20010;&#38382;&#39064;&#26159;&#25104;&#26412;&#65292;&#22240;&#20026;&#39069;&#22806;&#26816;&#32034;&#30340;&#19978;&#19979;&#25991;&#22823;&#22823;&#22686;&#21152;&#20102;LLM&#30340;&#36755;&#20837;&#26631;&#35760;&#37327;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20196;&#29260;&#21387;&#32553;&#26041;&#26696;&#65292;&#21253;&#25324;&#20004;&#31181;&#26041;&#27861;&#65306;&#27010;&#36848;&#21387;&#32553;&#21644;&#35821;&#20041;&#21387;&#32553;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;T5&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#21253;&#21547;&#20855;&#26377;&#19981;&#21516;&#38271;&#24230;&#30340;&#26679;&#26412;&#30340;&#33258;&#25351;&#31034;&#25968;&#25454;&#38598;&#36827;&#34892;&#24494;&#35843;&#65292;&#24182;&#36890;&#36807;&#27010;&#36848;&#26469;&#20943;&#23569;&#20196;&#29260;&#22823;&#23567;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#36890;&#36807;&#31227;&#38500;&#23545;&#35821;&#20041;&#24433;&#21709;&#36739;&#23567;&#30340;&#35789;&#26469;&#36827;&#19968;&#27493;&#21387;&#32553;&#20196;&#29260;&#22823;&#23567;&#12290;&#20026;&#20102;&#20805;&#20998;&#35780;&#20272;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;
&lt;/p&gt;
&lt;p&gt;
Since ChatGPT released its API for public use, the number of applications built on top of commercial large language models (LLMs) increase exponentially. One popular usage of such models is leveraging its in-context learning ability and generating responses given user queries leveraging knowledge obtained by retrieval augmentation. One problem of deploying commercial retrieval-augmented LLMs is the cost due to the additionally retrieved context that largely increases the input token size of the LLMs. To mitigate this, we propose a token compression scheme that includes two methods: summarization compression and semantic compression. The first method applies a T5-based model that is fine-tuned by datasets generated using self-instruct containing samples with varying lengths and reduce token size by doing summarization. The second method further compresses the token size by removing words with lower impact on the semantic. In order to adequately evaluate the effectiveness of the proposed
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;LLM-Embedder&#65292;&#36890;&#36807;&#19968;&#20010;&#32479;&#19968;&#30340;&#23884;&#20837;&#27169;&#22411;&#20840;&#38754;&#25903;&#25345;LLMs&#30340;&#22810;&#26679;&#21270;&#26816;&#32034;&#22686;&#24378;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.07554</link><description>&lt;p&gt;
&#26816;&#32034;&#20219;&#20309;&#20869;&#23481;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Retrieve Anything To Augment Large Language Models. (arXiv:2310.07554v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07554
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;LLM-Embedder&#65292;&#36890;&#36807;&#19968;&#20010;&#32479;&#19968;&#30340;&#23884;&#20837;&#27169;&#22411;&#20840;&#38754;&#25903;&#25345;LLMs&#30340;&#22810;&#26679;&#21270;&#26816;&#32034;&#22686;&#24378;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#38754;&#20020;&#30528;&#30001;&#20110;&#20854;&#22312;&#30693;&#35782;&#12289;&#35760;&#24518;&#12289;&#23545;&#40784;&#21644;&#34892;&#21160;&#26041;&#38754;&#30340;&#22266;&#26377;&#38480;&#21046;&#32780;&#20135;&#29983;&#30340;&#37325;&#35201;&#25361;&#25112;&#12290;&#36825;&#20123;&#25361;&#25112;&#19981;&#33021;&#21333;&#38752;LLMs&#33258;&#34892;&#35299;&#20915;&#65292;&#32780;&#24212;&#20381;&#36182;&#20110;&#26469;&#33258;&#22806;&#37096;&#19990;&#30028;&#65288;&#22914;&#30693;&#35782;&#24211;&#12289;&#35760;&#24518;&#23384;&#20648;&#12289;&#28436;&#31034;&#31034;&#20363;&#21644;&#24037;&#20855;&#65289;&#30340;&#36741;&#21161;&#12290;&#26816;&#32034;&#22686;&#24378;&#20316;&#20026;LLMs&#19982;&#22806;&#37096;&#36741;&#21161;&#20043;&#38388;&#30340;&#37325;&#35201;&#26426;&#21046;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#26041;&#27861;&#36935;&#21040;&#20004;&#20010;&#32039;&#36843;&#38382;&#39064;&#12290;&#19968;&#26041;&#38754;&#65292;&#36890;&#29992;&#26816;&#32034;&#22120;&#26410;&#33021;&#36866;&#24403;&#20248;&#21270;LLMs&#30340;&#26816;&#32034;&#22686;&#24378;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20219;&#21153;&#29305;&#23450;&#30340;&#26816;&#32034;&#22120;&#32570;&#20047;&#25152;&#38656;&#30340;&#22810;&#26679;&#24615;&#65292;&#38459;&#30861;&#20854;&#22312;&#21508;&#31181;&#26816;&#32034;&#22686;&#24378;&#22330;&#26223;&#20013;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;LLM-Embedder&#65292;&#23427;&#36890;&#36807;&#19968;&#20010;&#32479;&#19968;&#30340;&#23884;&#20837;&#27169;&#22411;&#20840;&#38754;&#25903;&#25345;LLMs&#30340;&#22810;&#26679;&#21270;&#26816;&#32034;&#22686;&#24378;&#38656;&#27714;&#12290;&#35757;&#32451;&#36825;&#26679;&#30340;&#32479;&#19968;&#27169;&#22411;&#24182;&#19981;&#23481;&#26131;&#65292;&#30001;&#20110;&#19981;&#21516;&#26816;&#32034;&#22686;&#24378;&#22330;&#26223;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) face significant challenges stemming from their inherent limitations in knowledge, memory, alignment, and action. These challenges cannot be addressed by LLMs alone, but should rely on assistance from the external world, such as knowledge base, memory store, demonstration examples, and tools. Retrieval augmentation stands as a vital mechanism for bridging the gap between LLMs and the external assistance. However, conventional methods encounter two pressing issues. On the one hand, the general-purpose retrievers are not properly optimized for the retrieval augmentation of LLMs. On the other hand, the task-specific retrievers lack the required versatility, hindering their performance across the diverse retrieval augmentation scenarios.  In this work, we present a novel approach, the LLM-Embedder, which comprehensively supports the diverse retrieval augmentation needs of LLMs with one unified embedding model. Training such a unified model is non-trivial, as va
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#20998;&#31867;&#27861;&#65292;&#21487;&#20197;&#29992;&#26469;&#35774;&#35745;&#20855;&#26377;&#29305;&#23450;&#23646;&#24615;&#30340;&#25552;&#31034;&#26469;&#25191;&#34892;&#21508;&#31181;&#22797;&#26434;&#20219;&#21153;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;LLM&#22312;&#25191;&#34892;&#22797;&#26434;&#20219;&#21153;&#26041;&#38754;&#30340;&#24615;&#33021;&#21464;&#24322;&#24040;&#22823;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.11430</link><description>&lt;p&gt;
TELeR&#65306;&#29992;&#20110;&#22522;&#20934;&#27979;&#35797;&#22797;&#26434;&#20219;&#21153;&#30340;LLM&#25552;&#31034;&#30340;&#36890;&#29992;&#20998;&#31867;&#27861;
&lt;/p&gt;
&lt;p&gt;
TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks. (arXiv:2305.11430v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11430
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#20998;&#31867;&#27861;&#65292;&#21487;&#20197;&#29992;&#26469;&#35774;&#35745;&#20855;&#26377;&#29305;&#23450;&#23646;&#24615;&#30340;&#25552;&#31034;&#26469;&#25191;&#34892;&#21508;&#31181;&#22797;&#26434;&#20219;&#21153;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;LLM&#22312;&#25191;&#34892;&#22797;&#26434;&#20219;&#21153;&#26041;&#38754;&#30340;&#24615;&#33021;&#21464;&#24322;&#24040;&#22823;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;LLM&#22312;&#20256;&#32479;&#23545;&#35805;&#29615;&#22659;&#20013;&#29702;&#35299;&#21644;&#29983;&#25104;&#25991;&#26412;&#26102;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#22312;&#25191;&#34892;&#19981;&#26126;&#30830;&#30340;&#22797;&#26434;&#20219;&#21153;&#26041;&#38754;&#30340;&#28508;&#21147;&#20173;&#28982;&#21463;&#21040;&#24456;&#23569;&#30340;&#30740;&#31350;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#20998;&#31867;&#27861;&#65292;&#21487;&#20197;&#29992;&#26469;&#35774;&#35745;&#20855;&#26377;&#29305;&#23450;&#23646;&#24615;&#30340;&#25552;&#31034;&#65292;&#20197;&#25191;&#34892;&#21508;&#31181;&#22797;&#26434;&#20219;&#21153;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20351;&#29992;&#19981;&#21516;&#25552;&#31034;&#31867;&#22411;/&#39118;&#26684;&#21644;&#25552;&#31034;&#25552;&#20379;&#30340;&#19981;&#21516;&#35814;&#32454;&#31243;&#24230;&#26102;LLM&#24615;&#33021;&#21464;&#21270;&#24040;&#22823;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#20998;&#31867;&#27861;&#23558;&#20351;&#26410;&#26469;&#30340;&#22522;&#20934;&#27979;&#35797;&#30740;&#31350;&#33021;&#22815;&#25253;&#21578;&#30740;&#31350;&#20013;&#20351;&#29992;&#30340;&#29305;&#23450;&#25552;&#31034;&#31867;&#21035;&#65292;&#20174;&#32780;&#23454;&#29616;&#36328;&#19981;&#21516;&#30740;&#31350;&#30340;&#26377;&#24847;&#20041;&#30340;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
While LLMs have shown great success in understanding and generating text in traditional conversational settings, their potential for performing ill-defined complex tasks is largely under-studied. Indeed, we are yet to conduct comprehensive benchmarking studies with multiple LLMs that are exclusively focused on a complex task. However, conducting such benchmarking studies is challenging because of the large variations in LLMs' performance when different prompt types/styles are used and different degrees of detail are provided in the prompts. To address this issue, the paper proposes a general taxonomy that can be used to design prompts with specific properties in order to perform a wide range of complex tasks. This taxonomy will allow future benchmarking studies to report the specific categories of prompts used as part of the study, enabling meaningful comparisons across different studies. Also, by establishing a common standard through this taxonomy, researchers will be able to draw mo
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;Sheaf&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#26041;&#27861;&#65292;&#20351;&#24471;&#20854;&#22312;&#22522;&#20934;&#25512;&#33616;&#20219;&#21153;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.09097</link><description>&lt;p&gt;
&#22522;&#20110;Sheaf&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Sheaf Neural Networks for Graph-based Recommender Systems. (arXiv:2304.09097v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09097
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Sheaf&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#26041;&#27861;&#65292;&#20351;&#24471;&#20854;&#22312;&#22522;&#20934;&#25512;&#33616;&#20219;&#21153;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;Graph&#31070;&#32463;&#32593;&#32476;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#65292;&#21253;&#25324;&#25512;&#33616;&#31995;&#32479;&#12290;Graph&#31070;&#32463;&#32593;&#32476;&#23545;&#20854;&#20182;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#22312;&#20110;&#65292;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#35768;&#22810;&#38382;&#39064;&#21487;&#20197;&#33258;&#28982;&#22320;&#24314;&#27169;&#20026;&#22270;&#65292;&#20854;&#20013;&#33410;&#28857;&#21487;&#20197;&#26159;&#29992;&#25143;&#25110;&#39033;&#30446;&#65292;&#36793;&#20195;&#34920;&#20559;&#22909;&#20851;&#31995;&#12290; &#22312;&#24403;&#21069;&#30340;Graph&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#20013;&#65292;&#33410;&#28857;&#29992;&#22312;&#35757;&#32451;&#26102;&#23398;&#20064;&#21040;&#30340;&#38745;&#24577;&#21521;&#37327;&#34920;&#31034;&#12290;&#36825;&#31181;&#38745;&#24577;&#21521;&#37327;&#21487;&#33021;&#21482;&#36866;&#29992;&#20110;&#25429;&#25417;&#23450;&#20041;&#23427;&#20204;&#30340;&#19968;&#20123;&#29992;&#25143;&#25110;&#39033;&#30446;&#30340;&#24494;&#22937;&#24046;&#21035;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#21551;&#21457;&#33539;&#30068;&#35770;&#30340;&#27169;&#22411;&#65306;Sheaf&#31070;&#32463;&#32593;&#32476;&#12290;Sheaf&#31070;&#32463;&#32593;&#32476;&#21450;&#20854;&#36830;&#25509;&#30340;&#25289;&#26222;&#25289;&#26031;&#21487;&#20197;&#36890;&#36807;&#23558;&#27599;&#20010;&#33410;&#28857;&#65288;&#20197;&#21450;&#36793;&#65289;&#19982;&#21521;&#37327;&#31354;&#38388;&#32780;&#19981;&#26159;&#21333;&#20010;&#21521;&#37327;&#30456;&#20851;&#32852;&#26469;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#12290;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#26356;&#20016;&#23500;&#65292;&#24182;&#20801;&#35768;&#22312;&#25512;&#29702;&#26102;&#36873;&#25321;&#27491;&#30830;&#30340;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#30340;&#27169;&#22411;&#26356;&#20855;&#34920;&#29616;&#21147;&#21644;&#28789;&#27963;&#24615;&#65292;&#22312;&#20960;&#20010;&#22522;&#20934;&#25512;&#33616;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent progress in Graph Neural Networks has resulted in wide adoption by many applications, including recommendation systems. The reason for Graph Neural Networks' superiority over other approaches is that many problems in recommendation systems can be naturally modeled as graphs, where nodes can be either users or items and edges represent preference relationships. In current Graph Neural Network approaches, nodes are represented with a static vector learned at training time. This static vector might only be suitable to capture some of the nuances of users or items they define. To overcome this limitation, we propose using a recently proposed model inspired by category theory: Sheaf Neural Networks. Sheaf Neural Networks, and its connected Laplacian, can address the previous problem by associating every node (and edge) with a vector space instead than a single vector. The vector space representation is richer and allows picking the proper representation at inference time. This approa
&lt;/p&gt;</description></item></channel></rss>