<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35268;&#21010;&#33021;&#21147;&#26469;&#22686;&#24378;&#38271;&#26399;&#25512;&#33616;&#65292;&#20351;&#27169;&#22411;&#22312;&#20010;&#24615;&#21270;&#25512;&#33616;&#20013;&#26356;&#26377;&#25928;&#22320;&#29702;&#35299;&#21644;&#24212;&#29992;&#20219;&#21153;&#35299;&#20915;&#21407;&#21017;</title><link>https://arxiv.org/abs/2403.00843</link><description>&lt;p&gt;
&#21033;&#29992;&#21452;&#23618;&#21487;&#23398;&#20064;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35268;&#21010;&#22686;&#24378;&#38271;&#26399;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00843
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35268;&#21010;&#33021;&#21147;&#26469;&#22686;&#24378;&#38271;&#26399;&#25512;&#33616;&#65292;&#20351;&#27169;&#22411;&#22312;&#20010;&#24615;&#21270;&#25512;&#33616;&#20013;&#26356;&#26377;&#25928;&#22320;&#29702;&#35299;&#21644;&#24212;&#29992;&#20219;&#21153;&#35299;&#20915;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#20542;&#21521;&#20110;&#36807;&#20998;&#36814;&#21512;&#29992;&#25143;&#30340;&#21363;&#26102;&#20852;&#36259;&#32780;&#24573;&#35270;&#20182;&#20204;&#30340;&#38271;&#26399;&#21442;&#19982;&#12290; &#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#25512;&#33616;&#20915;&#31574;&#36807;&#31243;&#20013;&#21512;&#24182;&#35268;&#21010;&#33021;&#21147;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20197;&#24320;&#21457;&#33021;&#22815;&#21516;&#26102;&#32771;&#34385;&#21363;&#26102;&#20852;&#36259;&#21644;&#38271;&#26399;&#21442;&#19982;&#30340;&#31574;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#31232;&#30095;&#25968;&#25454;&#30340;&#26174;&#33879;&#35268;&#21010;&#33021;&#21147;&#29992;&#20110;&#38271;&#26399;&#25512;&#33616;&#12290;&#20851;&#38190;&#22312;&#20110;&#20351;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#20010;&#24615;&#21270;&#25512;&#33616;&#22330;&#26223;&#20013;&#26377;&#25928;&#29702;&#35299;&#21644;&#24212;&#29992;&#20219;&#21153;&#35299;&#20915;&#21407;&#21017;&#65292;&#22240;&#20026;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#21487;&#33021;&#24182;&#26410;&#33258;&#28982;&#21253;&#21547;&#36825;&#20123;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00843v1 Announce Type: cross  Abstract: Traditional recommendation setting tends to excessively cater to users' immediate interests and neglect their long-term engagement. To address it, it is crucial to incorporate planning capabilities into the recommendation decision-making process to develop policies that take into account both immediate interests and long-term engagement. Despite Reinforcement Learning (RL) can learn planning capacity by maximizing cumulative reward, the scarcity of recommendation data presents challenges such as instability and susceptibility to overfitting when training RL models from scratch.   In this context, we propose to leverage the remarkable planning capabilities over sparse data of Large Language Models (LLMs) for long-term recommendation. The key lies in enabling a language model to understand and apply task-solving principles effectively in personalized recommendation scenarios, as the model's pre-training may not naturally encompass these 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;Stack Overflow&#22238;&#31572;&#20013;&#30340;&#20449;&#24687;&#39640;&#20142;&#12290;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#24320;&#21457;&#20102;&#33258;&#21160;&#25512;&#33616;&#31361;&#20986;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.01472</link><description>&lt;p&gt;
Stack Overflow&#22238;&#31572;&#20013;&#20449;&#24687;&#39640;&#20142;&#30340;&#21021;&#25506;
&lt;/p&gt;
&lt;p&gt;
A First Look at Information Highlighting in Stack Overflow Answers. (arXiv:2401.01472v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;Stack Overflow&#22238;&#31572;&#20013;&#30340;&#20449;&#24687;&#39640;&#20142;&#12290;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#24320;&#21457;&#20102;&#33258;&#21160;&#25512;&#33616;&#31361;&#20986;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#27983;&#35272;Stack Overflow&#65288;SO&#65289;&#30340;&#30693;&#35782;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#20351;&#24086;&#23376;&#23545;&#29992;&#25143;&#26356;&#29983;&#21160;&#65292;SO&#20801;&#35768;&#29992;&#25143;&#20351;&#29992;Markdown&#25110;HTML&#32534;&#20889;&#21644;&#32534;&#36753;&#24086;&#23376;&#65292;&#20197;&#20415;&#29992;&#25143;&#21487;&#20197;&#21033;&#29992;&#21508;&#31181;&#26684;&#24335;&#21270;&#26679;&#24335;&#65288;&#20363;&#22914;&#31895;&#20307;&#12289;&#26012;&#20307;&#21644;&#20195;&#30721;&#65289;&#26469;&#31361;&#20986;&#37325;&#35201;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#31361;&#20986;&#20449;&#24687;&#30340;&#30740;&#31350;&#20173;&#28982;&#26377;&#38480;&#12290;&#30446;&#26631;&#65306;&#25105;&#20204;&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;SO&#22238;&#31572;&#20013;&#30340;&#20449;&#24687;&#39640;&#20142;&#12290;&#20026;&#20102;&#25193;&#23637;&#25105;&#20204;&#20043;&#21069;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#21033;&#29992;&#26368;&#21021;&#35774;&#35745;&#29992;&#20110;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#24320;&#21457;&#20102;&#33258;&#21160;&#25512;&#33616;&#24102;&#26377;&#26684;&#24335;&#21270;&#26679;&#24335;&#30340;&#31361;&#20986;&#20869;&#23481;&#30340;&#26041;&#27861;&#12290;&#26041;&#27861;&#65306;&#26412;&#25991;&#30740;&#31350;&#20102;Stack Overflow&#30340;31,169,429&#20010;&#22238;&#31572;&#12290;&#20026;&#20102;&#35757;&#32451;&#25512;&#33616;&#27169;&#22411;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;CNN&#21644;BERT&#27169;&#22411;&#65292;&#38024;&#23545;&#27599;&#31181;&#26684;&#24335;&#21270;&#31867;&#22411;&#65288;&#21363;&#31895;&#20307;&#12289;&#26012;&#20307;&#12289;&#20195;&#30721;&#21644;&#26631;&#39064;&#65289;&#20351;&#29992;&#25105;&#20204;&#20174;SO&#22238;&#31572;&#25910;&#38598;&#30340;&#31361;&#20986;&#20449;&#24687;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Context: Navigating the knowledge of Stack Overflow (SO) remains challenging. To make the posts vivid to users, SO allows users to write and edit posts with Markdown or HTML so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. Nonetheless, there have been limited studies on the highlighted information. Objective: We carried out the first large-scale exploratory study on the information highlighted in SO answers in our recent study. To extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using neural network architectures initially designed for the Named Entity Recognition task. Method: In this paper, we studied 31,169,429 answers of Stack Overflow. For training recommendation models, we choose CNN and BERT models for each type of formatting (i.e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#35821;&#20041;&#26816;&#32034;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25688;&#35201;&#25551;&#36848;&#30340;&#25991;&#26412;&#26816;&#32034;&#27169;&#22411;&#65292;&#36890;&#36807;&#25913;&#36827;&#24403;&#21069;&#30340;&#25991;&#26412;&#23884;&#20837;&#26041;&#27861;&#65292;&#22312;&#26631;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2305.12517</link><description>&lt;p&gt;
&#22522;&#20110;&#25688;&#35201;&#25551;&#36848;&#30340;&#25991;&#26412;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Retrieving Texts based on Abstract Descriptions. (arXiv:2305.12517v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12517
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#35821;&#20041;&#26816;&#32034;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25688;&#35201;&#25551;&#36848;&#30340;&#25991;&#26412;&#26816;&#32034;&#27169;&#22411;&#65292;&#36890;&#36807;&#25913;&#36827;&#24403;&#21069;&#30340;&#25991;&#26412;&#23884;&#20837;&#26041;&#27861;&#65292;&#22312;&#26631;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#38024;&#23545;&#25991;&#26412;&#30340;&#20449;&#24687;&#25552;&#21462;&#65292;&#25351;&#20196;&#20248;&#21270;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34920;&#29616;&#20248;&#24322;&#65292;&#20294;&#23545;&#20110;&#22312;&#22823;&#35268;&#27169;&#25991;&#26723;&#38598;&#21512;&#20013;&#23450;&#20301;&#31526;&#21512;&#32473;&#23450;&#25551;&#36848;&#30340;&#25991;&#26412;&#65288;&#35821;&#20041;&#26816;&#32034;&#65289;&#24182;&#19981;&#36866;&#29992;&#12290;&#22522;&#20110;&#23884;&#20837;&#21521;&#37327;&#30340;&#30456;&#20284;&#24230;&#25628;&#32034;&#21487;&#20197;&#36890;&#36807;&#26597;&#35810;&#25191;&#34892;&#26816;&#32034;&#65292;&#20294;&#23884;&#20837;&#20013;&#30340;&#30456;&#20284;&#24230;&#23450;&#20041;&#19981;&#26126;&#30830;&#19988;&#19981;&#19968;&#33268;&#65292;&#24182;&#19988;&#23545;&#20110;&#35768;&#22810;&#29992;&#20363;&#26469;&#35828;&#37117;&#26159;&#27425;&#20248;&#30340;&#12290;&#37027;&#20040;&#65292;&#20160;&#20040;&#26159;&#26377;&#25928;&#26816;&#32034;&#30340;&#22909;&#30340;&#26597;&#35810;&#34920;&#31034;&#65311;&#25105;&#20204;&#30830;&#23450;&#20102;&#26681;&#25454;&#20869;&#23481;&#30340;&#25688;&#35201;&#25551;&#36848;&#26816;&#32034;&#21477;&#23376;&#30340;&#26126;&#30830;&#23450;&#20041;&#19988;&#19968;&#33268;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#21069;&#25991;&#26412;&#23884;&#20837;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#27169;&#22411;&#65292;&#22312;&#26631;&#20934;&#26368;&#36817;&#37051;&#25628;&#32034;&#20013;&#30340;&#34920;&#29616;&#26174;&#33879;&#25552;&#21319;&#12290;&#35813;&#27169;&#22411;&#20351;&#29992;&#36890;&#36807;&#25552;&#31034;LLM&#33719;&#24471;&#30340;&#27491;&#36127;&#26679;&#26412;&#23545;&#36827;&#34892;&#35757;&#32451;&#12290;&#34429;&#28982;&#24456;&#23481;&#26131;&#20174;LLM&#20013;&#33719;&#24471;&#35757;&#32451;&#26448;&#26009;&#65292;&#20294;LLM&#26080;&#27861;&#30452;&#25509;&#25191;&#34892;&#26816;&#32034;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
While instruction-tuned Large Language Models (LLMs) excel at extracting information from text, they are not suitable for locating texts conforming to a given description in a large document collection (semantic retrieval). Similarity search over embedding vectors does allow to perform retrieval by query, but the similarity reflected in the embedding is ill-defined and non-consistent, and is sub-optimal for many use cases. What, then, is a good query representation for effective retrieval?  We identify the well defined and consistent task of retrieving sentences based on abstract descriptions of their content. We demonstrate the inadequacy of current text embeddings and propose an alternative model that significantly improves when used in standard nearest neighbor search. The model is trained using positive and negative pairs sourced through prompting a LLM. While it is easy to source the training material from an LLM, the retrieval task cannot be performed by the LLM directly. This de
&lt;/p&gt;</description></item></channel></rss>