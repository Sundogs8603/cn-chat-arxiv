<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>TREC iKAT 2023&#26159;&#19968;&#20010;&#20132;&#20114;&#24335;&#30340;&#30693;&#35782;&#36741;&#21161;&#20219;&#21153;&#65292;&#26088;&#22312;&#24320;&#21457;&#36866;&#24212;&#29992;&#25143;&#20132;&#20114;&#21644;&#19978;&#19979;&#25991;&#30340;&#20250;&#35805;&#25628;&#32034;&#20195;&#29702;&#12290;&#35813;&#20219;&#21153;&#36824;&#24378;&#35843;&#20915;&#31574;&#25628;&#32034;&#20219;&#21153;&#65292;&#29992;&#25143;&#36890;&#36807;&#31579;&#36873;&#25968;&#25454;&#21644;&#20449;&#24687;&#26469;&#36827;&#34892;&#20915;&#31574;&#21644;&#25191;&#34892;&#21160;&#20316;&#12290;</title><link>http://arxiv.org/abs/2401.01330</link><description>&lt;p&gt;
TREC iKAT 2023: &#20132;&#20114;&#24335;&#30693;&#35782;&#36741;&#21161;&#20219;&#21153;&#27010;&#36848;
&lt;/p&gt;
&lt;p&gt;
TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview. (arXiv:2401.01330v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01330
&lt;/p&gt;
&lt;p&gt;
TREC iKAT 2023&#26159;&#19968;&#20010;&#20132;&#20114;&#24335;&#30340;&#30693;&#35782;&#36741;&#21161;&#20219;&#21153;&#65292;&#26088;&#22312;&#24320;&#21457;&#36866;&#24212;&#29992;&#25143;&#20132;&#20114;&#21644;&#19978;&#19979;&#25991;&#30340;&#20250;&#35805;&#25628;&#32034;&#20195;&#29702;&#12290;&#35813;&#20219;&#21153;&#36824;&#24378;&#35843;&#20915;&#31574;&#25628;&#32034;&#20219;&#21153;&#65292;&#29992;&#25143;&#36890;&#36807;&#31579;&#36873;&#25968;&#25454;&#21644;&#20449;&#24687;&#26469;&#36827;&#34892;&#20915;&#31574;&#21644;&#25191;&#34892;&#21160;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#24335;&#20449;&#24687;&#26597;&#35810;&#26159;&#19968;&#20010;&#20851;&#38190;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#20043;&#21069;&#30340;&#24037;&#20316;&#20063;&#26377;&#24456;&#22823;&#30340;&#36129;&#29486;&#12290;TREC&#20132;&#20114;&#24335;&#30693;&#35782;&#36741;&#21161;&#20219;&#21153;&#65288;iKAT&#65289;&#24314;&#31435;&#22312;TREC&#20250;&#35805;&#36741;&#21161;&#20219;&#21153;&#65288;CAsT&#65289;&#30340;&#22522;&#30784;&#19978;&#12290;&#28982;&#32780;&#65292;iKAT&#30528;&#37325;&#20110;&#21019;&#24314;&#21644;&#30740;&#31350;&#21487;&#20197;&#26681;&#25454;&#29992;&#25143;&#20043;&#21069;&#30340;&#20132;&#20114;&#21644;&#24403;&#21069;&#24773;&#22659;&#33258;&#36866;&#24212;&#21709;&#24212;&#30340;&#20250;&#35805;&#25628;&#32034;&#20195;&#29702;&#12290;&#25361;&#25112;&#22312;&#20110;&#20351;&#20250;&#35805;&#25628;&#32034;&#20195;&#29702;&#33021;&#22815;&#23558;&#20010;&#24615;&#21270;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#34701;&#20837;&#21040;&#30456;&#24212;&#20013;&#65292;&#20197;&#39640;&#25928;&#22320;&#24341;&#23548;&#29992;&#25143;&#33719;&#21462;&#30456;&#20851;&#20449;&#24687;&#12290;iKAT&#36824;&#30528;&#37325;&#20110;&#20915;&#31574;&#25628;&#32034;&#20219;&#21153;&#65292;&#21363;&#29992;&#25143;&#36890;&#36807;&#25968;&#25454;&#21644;&#20449;&#24687;&#31579;&#36873;&#26469;&#34913;&#37327;&#21508;&#31181;&#36873;&#25321;&#65292;&#20197;&#36798;&#21040;&#32467;&#35770;&#25110;&#25191;&#34892;&#21160;&#20316;&#12290;&#36825;&#20123;&#20219;&#21153;&#22312;&#26085;&#24120;&#20449;&#24687;&#25628;&#32034;&#20915;&#31574;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#26080;&#35770;&#26159;&#26053;&#28216;&#12289;&#20581;&#24247;&#36824;&#26159;&#36141;&#29289;&#31561;&#65292;&#36890;&#24120;&#28041;&#21450;&#19968;&#32452;&#39640;&#32423;&#20449;&#24687;&#25805;&#20316;&#31526;&#65292;&#20854;&#20013;&#26597;&#35810;&#25110;&#38382;&#39064;&#21487;&#33021;&#20250;
&lt;/p&gt;
&lt;p&gt;
Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works. The TREC Interactive Knowledge Assistance Track (iKAT) builds on the foundational work of the TREC Conversational Assistance Track (CAsT). However, iKAT distinctively emphasizes the creation and research of conversational search agents that adapt responses based on user's prior interactions and present context. The challenge lies in enabling Conversational Search Agents (CSA) to incorporate this personalized context to efficiency and effectively guide users through the relevant information to them. iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action. These tasks, prevalent in everyday information-seeking decisions -- be it related to travel, health, or shopping -- often revolve around a subset of high-level information operators where queries or questions a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#30340;&#25932;&#23545;&#39033;&#30446;&#25512;&#24191;&#30340;&#24341;&#23548;&#25193;&#25955;&#65292;&#25581;&#31034;&#20102;&#29289;&#21697;&#20379;&#24212;&#21830;&#22914;&#20309;&#36890;&#36807;&#26500;&#24314;&#25932;&#23545;&#22270;&#20687;&#26469;&#25805;&#32437;&#29289;&#21697;&#26292;&#38706;&#29575;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#25932;&#23545;&#22270;&#20687;&#23384;&#22312;&#30340;&#38382;&#39064;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2312.15826</link><description>&lt;p&gt;
&#23545;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#30340;&#25932;&#23545;&#39033;&#30446;&#25512;&#24191;&#30340;&#24341;&#23548;&#25193;&#25955;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adversarial Item Promotion on Visually-Aware Recommender Systems by Guided Diffusion. (arXiv:2312.15826v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#30340;&#25932;&#23545;&#39033;&#30446;&#25512;&#24191;&#30340;&#24341;&#23548;&#25193;&#25955;&#65292;&#25581;&#31034;&#20102;&#29289;&#21697;&#20379;&#24212;&#21830;&#22914;&#20309;&#36890;&#36807;&#26500;&#24314;&#25932;&#23545;&#22270;&#20687;&#26469;&#25805;&#32437;&#29289;&#21697;&#26292;&#38706;&#29575;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#25932;&#23545;&#22270;&#20687;&#23384;&#22312;&#30340;&#38382;&#39064;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#22312;&#37027;&#20123;&#35270;&#35273;&#20803;&#32032;&#23545;&#29992;&#25143;&#28508;&#22312;&#20559;&#22909;&#30340;&#25512;&#26029;&#26377;&#26174;&#33879;&#36129;&#29486;&#30340;&#39046;&#22495;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;&#32435;&#20837;&#35270;&#35273;&#20449;&#24687;&#26377;&#26395;&#25552;&#39640;&#25512;&#33616;&#30340;&#20934;&#30830;&#24615;&#21644;&#32531;&#35299;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#20294;&#38656;&#35201;&#25351;&#20986;&#30340;&#26159;&#65292;&#21253;&#21547;&#29289;&#21697;&#22270;&#20687;&#21487;&#33021;&#20250;&#24341;&#20837;&#37325;&#22823;&#30340;&#23433;&#20840;&#25361;&#25112;&#12290;&#19968;&#20123;&#29616;&#26377;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#29289;&#21697;&#20379;&#24212;&#21830;&#21487;&#20197;&#36890;&#36807;&#26500;&#24314;&#25932;&#23545;&#22270;&#20687;&#26469;&#25805;&#32437;&#29289;&#21697;&#26292;&#38706;&#29575;&#20197;&#20854;&#21033;&#30410;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24037;&#20316;&#26080;&#27861;&#25581;&#31034;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#38754;&#23545;&#25932;&#23545;&#22270;&#20687;&#26102;&#30340;&#30495;&#23454;&#33030;&#24369;&#24615;&#65292;&#21407;&#22240;&#22914;&#19979;&#65306;&#65288;1&#65289;&#29983;&#25104;&#30340;&#25932;&#23545;&#22270;&#20687;&#26126;&#26174;&#30072;&#21464;&#65292;&#26131;&#20110;&#34987;&#20154;&#31867;&#35266;&#23519;&#32773;&#26816;&#27979;&#21040;&#65307;&#65288;2&#65289;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#19981;&#19968;&#33268;&#65292;&#29978;&#33267;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#26080;&#25928;&#12290;&#20026;&#20102;&#25581;&#31034;&#38754;&#23545;&#25932;&#23545;&#22270;&#20687;&#26102;&#35270;&#35273;&#24863;&#30693;&#25512;&#33616;&#31995;&#32479;&#30340;&#30495;&#23454;&#33030;&#24369;&#24615;
&lt;/p&gt;
&lt;p&gt;
Visually-aware recommender systems have found widespread application in domains where visual elements significantly contribute to the inference of users' potential preferences. While the incorporation of visual information holds the promise of enhancing recommendation accuracy and alleviating the cold-start problem, it is essential to point out that the inclusion of item images may introduce substantial security challenges. Some existing works have shown that the item provider can manipulate item exposure rates to its advantage by constructing adversarial images. However, these works cannot reveal the real vulnerability of visually-aware recommender systems because (1) The generated adversarial images are markedly distorted, rendering them easily detectable by human observers; (2) The effectiveness of the attacks is inconsistent and even ineffective in some scenarios. To shed light on the real vulnerabilities of visually-aware recommender systems when confronted with adversarial images
&lt;/p&gt;</description></item><item><title>LLaRA&#26159;&#19968;&#20010;&#23558;&#20256;&#32479;&#25512;&#33616;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26041;&#27861;&#26469;&#20195;&#34920;&#39033;&#30446;&#65292;&#22312;&#39034;&#24207;&#25512;&#33616;&#20013;&#20805;&#20998;&#21033;&#29992;&#20102;&#20256;&#32479;&#25512;&#33616;&#22120;&#30340;&#29992;&#25143;&#34892;&#20026;&#30693;&#35782;&#21644;LLMs&#30340;&#19990;&#30028;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2312.02445</link><description>&lt;p&gt;
LLaRA: &#20351;&#29992;&#39034;&#24207;&#25512;&#33616;&#22120;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LLaRA: Aligning Large Language Models with Sequential Recommenders. (arXiv:2312.02445v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.02445
&lt;/p&gt;
&lt;p&gt;
LLaRA&#26159;&#19968;&#20010;&#23558;&#20256;&#32479;&#25512;&#33616;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26041;&#27861;&#26469;&#20195;&#34920;&#39033;&#30446;&#65292;&#22312;&#39034;&#24207;&#25512;&#33616;&#20013;&#20805;&#20998;&#21033;&#29992;&#20102;&#20256;&#32479;&#25512;&#33616;&#22120;&#30340;&#29992;&#25143;&#34892;&#20026;&#30693;&#35782;&#21644;LLMs&#30340;&#19990;&#30028;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25512;&#33616;&#26088;&#22312;&#26681;&#25454;&#29992;&#25143;&#30340;&#21382;&#21490;&#20132;&#20114;&#39044;&#27979;&#19982;&#29992;&#25143;&#20559;&#22909;&#30456;&#21305;&#37197;&#30340;&#21518;&#32493;&#39033;&#30446;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLMs) &#30340;&#21457;&#23637;&#65292;&#20154;&#20204;&#23545;&#20110;&#23558;LLMs &#24212;&#29992;&#20110;&#39034;&#24207;&#25512;&#33616;&#24182;&#23558;&#20854;&#35270;&#20026;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#30340;&#28508;&#21147;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20351;&#29992;ID&#32034;&#24341;&#25110;&#25991;&#26412;&#32034;&#24341;&#26469;&#34920;&#31034;&#25991;&#26412;&#25552;&#31034;&#20013;&#30340;&#39033;&#30446;&#65292;&#24182;&#23558;&#25552;&#31034;&#36755;&#20837;LLMs&#65292;&#20294;&#26080;&#27861;&#20840;&#38754;&#34701;&#21512;&#19990;&#30028;&#30693;&#35782;&#25110;&#23637;&#31034;&#36275;&#22815;&#30340;&#39034;&#24207;&#29702;&#35299;&#33021;&#21147;&#12290;&#20026;&#20102;&#20805;&#20998;&#21457;&#25381;&#20256;&#32479;&#25512;&#33616;&#22120;&#65288;&#21487;&#20197;&#32534;&#30721;&#29992;&#25143;&#34892;&#20026;&#30693;&#35782;&#65289;&#21644;LLMs&#65288;&#20855;&#26377;&#39033;&#30446;&#30340;&#19990;&#30028;&#30693;&#35782;&#65289;&#30340;&#20114;&#34917;&#20248;&#21183;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LLaRA - &#19968;&#31181;&#22823;&#22411;&#35821;&#35328;&#21644;&#25512;&#33616;&#21161;&#25163;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;LLaRA&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#23558;&#20256;&#32479;&#25512;&#33616;&#22120;&#30340;&#22522;&#20110;ID&#30340;&#39033;&#30446;&#23884;&#20837;&#19982;&#25991;&#26412;&#39033;&#30446;&#29305;&#24449;&#25972;&#21512;&#21040;LLM&#30340;&#36755;&#20837;&#25552;&#31034;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation aims to predict the subsequent items matching user preference based on her/his historical interactions. With the development of Large Language Models (LLMs), there is growing interest in exploring the potential of LLMs for sequential recommendation by framing it as a language modeling task. Prior works represent items in the textual prompts using either ID indexing or text indexing and feed the prompts into LLMs, but falling short of either encapsulating comprehensive world knowledge or exhibiting sufficient sequential understanding. To harness the complementary strengths of traditional recommenders (which encode user behavioral knowledge) and LLMs (which possess world knowledge about items), we propose LLaRA -- a Large Language and Recommendation Assistant framework. Specifically, LLaRA represents items in LLM's input prompts using a novel hybrid approach that integrates ID-based item embeddings from traditional recommenders with textual item features. Viewin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#21517;&#20026;Caseformer&#65292;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#35299;&#20915;&#20102;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2311.00333</link><description>&lt;p&gt;
Caseformer: &#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#30340;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Caseformer: Pre-training for Legal Case Retrieval. (arXiv:2311.00333v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00333
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#21517;&#20026;Caseformer&#65292;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#35299;&#20915;&#20102;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#26088;&#22312;&#24110;&#21161;&#27861;&#24459;&#24037;&#20316;&#32773;&#25214;&#21040;&#19982;&#20182;&#20204;&#25163;&#22836;&#26696;&#20214;&#30456;&#20851;&#30340;&#26696;&#20363;&#65292;&#36825;&#23545;&#20110;&#20445;&#35777;&#20844;&#24179;&#21644;&#27491;&#20041;&#30340;&#27861;&#24459;&#21028;&#20915;&#38750;&#24120;&#37325;&#35201;&#12290;&#23613;&#31649;&#26368;&#36817;&#31070;&#32463;&#26816;&#32034;&#26041;&#27861;&#22312;&#24320;&#25918;&#22495;&#26816;&#32034;&#20219;&#21153;&#65288;&#20363;&#22914;&#32593;&#32476;&#25628;&#32034;&#65289;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20294;&#26159;&#30001;&#20110;&#23545;&#26631;&#27880;&#25968;&#25454;&#30340;&#28212;&#26395;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#24182;&#27809;&#26377;&#26174;&#31034;&#20986;&#20248;&#21183;&#12290;&#30001;&#20110;&#38656;&#35201;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#65292;&#23545;&#27861;&#24459;&#39046;&#22495;&#36827;&#34892;&#22823;&#35268;&#27169;&#35757;&#32451;&#25968;&#25454;&#30340;&#26631;&#27880;&#26159;&#22256;&#38590;&#30340;&#65292;&#22240;&#27492;&#20256;&#32479;&#30340;&#22522;&#20110;&#35789;&#27719;&#21305;&#37197;&#30340;&#25628;&#32034;&#25216;&#26415;&#65292;&#22914;TF-IDF&#12289;BM25&#21644;&#26597;&#35810;&#20284;&#28982;&#65292;&#20173;&#28982;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#31995;&#32479;&#20013;&#30427;&#34892;&#12290;&#34429;&#28982;&#20197;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35774;&#35745;&#20102;&#19968;&#20123;&#38024;&#23545;&#24320;&#25918;&#22495;&#20219;&#21153;&#20013;IR&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#20294;&#26159;&#30001;&#20110;&#26080;&#27861;&#29702;&#35299;&#21644;&#25429;&#25417;&#27861;&#24459;&#35821;&#26009;&#24211;&#20013;&#30340;&#20851;&#38190;&#30693;&#35782;&#21644;&#25968;&#25454;&#32467;&#26500;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#36890;&#24120;&#26159;&#27425;&#20248;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Legal case retrieval aims to help legal workers find relevant cases related to their cases at hand, which is important for the guarantee of fairness and justice in legal judgments. While recent advances in neural retrieval methods have significantly improved the performance of open-domain retrieval tasks (e.g., Web search), their advantages have not been observed in legal case retrieval due to their thirst for annotated data. As annotating large-scale training data in legal domains is prohibitive due to the need for domain expertise, traditional search techniques based on lexical matching such as TF-IDF, BM25, and Query Likelihood are still prevalent in legal case retrieval systems. While previous studies have designed several pre-training methods for IR models in open-domain tasks, these methods are usually suboptimal in legal case retrieval because they cannot understand and capture the key knowledge and data structures in the legal corpus. To this end, we propose a novel pre-trainin
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#21551;&#21457;&#24335;&#20844;&#24335;&#24471;&#21040;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.15790</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#26415;&#35821;&#29190;&#21457;&#24615;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A statistical significance testing approach for measuring term burstiness with applications to domain-specific terminology extraction. (arXiv:2310.15790v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15790
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#27979;&#37327;&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#20013;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#21551;&#21457;&#24335;&#20844;&#24335;&#24471;&#21040;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#19994;&#26415;&#35821;&#25277;&#21462;&#26159;&#25991;&#26412;&#20998;&#26512;&#20013;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#24403;&#35821;&#26009;&#24211;&#20013;&#19968;&#20010;&#26415;&#35821;&#30340;&#20986;&#29616;&#38598;&#20013;&#22312;&#23569;&#25968;&#20960;&#20010;&#25991;&#20214;&#20013;&#26102;&#65292;&#21487;&#31216;&#20043;&#20026;&#8220;&#29190;&#21457;&#24615;&#8221;&#12290;&#20316;&#20026;&#20869;&#23481;&#20016;&#23500;&#30340;&#26415;&#35821;&#65292;&#29190;&#21457;&#24615;&#26415;&#35821;&#38750;&#24120;&#36866;&#21512;&#29992;&#20110;&#20027;&#39064;&#25551;&#36848;&#65292;&#24182;&#19988;&#26159;&#25216;&#26415;&#26415;&#35821;&#30340;&#33258;&#28982;&#20505;&#36873;&#35789;&#12290;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#22810;&#31181;&#26415;&#35821;&#29190;&#21457;&#24615;&#30340;&#27979;&#37327;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#25991;&#26412;&#20998;&#26512;&#20013;&#65292;&#21253;&#25324;&#19982;&#26415;&#35821;&#29190;&#21457;&#24615;&#30456;&#20851;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#27979;&#35797;&#33539;&#24335;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#20010;&#39046;&#22495;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#39033;&#24335;&#35821;&#35328;&#27169;&#22411;&#30340;&#26415;&#35821;&#29190;&#21457;&#24615;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#31934;&#30830;&#27979;&#35797;&#26041;&#27861;&#12290;&#30001;&#20110;&#35745;&#31639;&#25104;&#26412;&#36807;&#39640;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#21551;&#21457;&#24335;&#20844;&#24335;&#65292;&#29992;&#20110;&#36817;&#20284;&#27979;&#35797;P&#20540;&#12290;&#20316;&#20026;&#34917;&#20805;&#30340;&#29702;&#35770;&#36129;&#29486;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31181;&#26410;&#32463;&#25253;&#36947;&#30340;&#36870;&#25991;&#26723;&#39057;&#29575;&#19982;&#36870;&#25910;&#38598;&#39057;&#29575;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain-specific terminology extraction is an important task in text analysis. A term in a corpus is said to be "bursty" when its occurrences are concentrated in few out of many documents. Being content rich, bursty terms are highly suited for subject matter characterization, and serve as natural candidates for identifying with technical terminology. Multiple measures of term burstiness have been proposed in the literature. However, the statistical significance testing paradigm has remained underexplored in text analysis, including in relation to term burstiness. To test these waters, we propose as our main contribution a multinomial language model-based exact test of statistical significance for term burstiness. Due to its prohibitive computational cost, we advance a heuristic formula designed to serve as a proxy for test P-values. As a complementary theoretical contribution, we derive a previously unreported relationship connecting the inverse document frequency and inverse collection
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#22823;&#22411;&#25628;&#32034;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#25152;&#26377;&#25628;&#32034;&#20219;&#21153;&#32479;&#19968;&#20026;&#19968;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#65292;&#37325;&#26032;&#23450;&#20041;&#20102;&#20256;&#32479;&#30340;&#25628;&#32034;&#22534;&#26632;&#12290;&#36825;&#20010;&#26694;&#26550;&#21033;&#29992;&#20102;LLM&#30340;&#24378;&#22823;&#35821;&#35328;&#29702;&#35299;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#26377;&#28508;&#21147;&#25552;&#39640;&#25628;&#32034;&#32467;&#26524;&#30340;&#36136;&#37327;&#65292;&#21516;&#26102;&#31616;&#21270;&#29616;&#26377;&#30340;&#32321;&#29712;&#30340;&#25628;&#32034;&#22534;&#26632;&#12290;</title><link>http://arxiv.org/abs/2310.14587</link><description>&lt;p&gt;
&#22823;&#22411;&#25628;&#32034;&#27169;&#22411;&#65306;&#37325;&#26032;&#23450;&#20041;LLM&#26102;&#20195;&#30340;&#25628;&#32034;&#22534;&#26632;
&lt;/p&gt;
&lt;p&gt;
Large Search Model: Redefining Search Stack in the Era of LLMs. (arXiv:2310.14587v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#22823;&#22411;&#25628;&#32034;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#25152;&#26377;&#25628;&#32034;&#20219;&#21153;&#32479;&#19968;&#20026;&#19968;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#65292;&#37325;&#26032;&#23450;&#20041;&#20102;&#20256;&#32479;&#30340;&#25628;&#32034;&#22534;&#26632;&#12290;&#36825;&#20010;&#26694;&#26550;&#21033;&#29992;&#20102;LLM&#30340;&#24378;&#22823;&#35821;&#35328;&#29702;&#35299;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#26377;&#28508;&#21147;&#25552;&#39640;&#25628;&#32034;&#32467;&#26524;&#30340;&#36136;&#37327;&#65292;&#21516;&#26102;&#31616;&#21270;&#29616;&#26377;&#30340;&#32321;&#29712;&#30340;&#25628;&#32034;&#22534;&#26632;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25628;&#32034;&#24341;&#25806;&#26159;&#30001;&#19981;&#21516;&#32452;&#20214;&#26500;&#24314;&#30340;&#22534;&#26632;&#65292;&#21253;&#25324;&#26597;&#35810;&#29702;&#35299;&#12289;&#26816;&#32034;&#12289;&#22810;&#38454;&#27573;&#25490;&#21517;&#21644;&#38382;&#31572;&#31561;&#12290;&#36825;&#20123;&#32452;&#20214;&#36890;&#24120;&#26159;&#29420;&#31435;&#20248;&#21270;&#21644;&#37096;&#32626;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#27010;&#24565;&#24615;&#26694;&#26550;&#65292;&#31216;&#20026;&#22823;&#22411;&#25628;&#32034;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#25152;&#26377;&#20219;&#21153;&#32479;&#19968;&#20026;&#19968;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#26469;&#37325;&#26032;&#23450;&#20041;&#20256;&#32479;&#30340;&#25628;&#32034;&#22534;&#26632;&#12290;&#25152;&#26377;&#20219;&#21153;&#37117;&#34987;&#34920;&#36848;&#20026;&#33258;&#22238;&#24402;&#25991;&#26412;&#29983;&#25104;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#21487;&#20197;&#23450;&#21046;&#20219;&#21153;&#12290;&#36825;&#20010;&#25552;&#20986;&#30340;&#26694;&#26550;&#21033;&#29992;&#20102;LLM&#30340;&#24378;&#22823;&#35821;&#35328;&#29702;&#35299;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#26377;&#28508;&#21147;&#25552;&#39640;&#25628;&#32034;&#32467;&#26524;&#30340;&#36136;&#37327;&#65292;&#21516;&#26102;&#31616;&#21270;&#29616;&#26377;&#30340;&#32321;&#29712;&#30340;&#25628;&#32034;&#22534;&#26632;&#12290;&#20026;&#20102;&#39564;&#35777;&#36825;&#20010;&#26694;&#26550;&#30340;&#21487;&#34892;&#24615;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31995;&#21015;&#27010;&#24565;&#39564;&#35777;&#23454;&#39564;&#65292;&#24182;&#35752;&#35770;&#20102;&#23454;&#29616;&#36825;&#31181;&#26041;&#27861;&#25152;&#38754;&#20020;&#30340;&#28508;&#22312;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern search engines are built on a stack of different components, including query understanding, retrieval, multi-stage ranking, and question answering, among others. These components are often optimized and deployed independently. In this paper, we introduce a novel conceptual framework called large search model, which redefines the conventional search stack by unifying search tasks with one large language model (LLM). All tasks are formulated as autoregressive text generation problems, allowing for the customization of tasks through the use of natural language prompts. This proposed framework capitalizes on the strong language understanding and reasoning capabilities of LLMs, offering the potential to enhance search result quality while simultaneously simplifying the existing cumbersome search stack. To substantiate the feasibility of this framework, we present a series of proof-of-concept experiments and discuss the potential challenges associated with implementing this approach w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;Bandits&#20013;&#30340;&#25490;&#21517;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;UCB&#21644;Thompson Sampling&#31867;&#22411;&#31639;&#27861;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#65292;&#24182;&#23545;&#20301;&#32622;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#36827;&#34892;&#20102;&#24314;&#27169;&#12290;&#30740;&#31350;&#32467;&#26524;&#22312;&#20301;&#32622;&#20381;&#36182;&#24615;&#21644;&#25490;&#21517;&#38382;&#39064;&#19982;&#22270;&#35770;&#30340;&#36830;&#25509;&#31561;&#26041;&#38754;&#36827;&#34892;&#20102;&#25512;&#24191;&#12290;</title><link>http://arxiv.org/abs/2207.00109</link><description>&lt;p&gt;
&#24191;&#20041;&#32447;&#24615;Bandits&#20013;&#30340;&#25490;&#21517;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Ranking In Generalized Linear Bandits. (arXiv:2207.00109v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.00109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;Bandits&#20013;&#30340;&#25490;&#21517;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;UCB&#21644;Thompson Sampling&#31867;&#22411;&#31639;&#27861;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#65292;&#24182;&#23545;&#20301;&#32622;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#36827;&#34892;&#20102;&#24314;&#27169;&#12290;&#30740;&#31350;&#32467;&#26524;&#22312;&#20301;&#32622;&#20381;&#36182;&#24615;&#21644;&#25490;&#21517;&#38382;&#39064;&#19982;&#22270;&#35770;&#30340;&#36830;&#25509;&#31561;&#26041;&#38754;&#36827;&#34892;&#20102;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;Bandits&#20013;&#30340;&#25490;&#21517;&#38382;&#39064;&#12290;&#22312;&#27599;&#20010;&#26102;&#21051;&#65292;&#23398;&#20064;&#20195;&#29702;&#36873;&#25321;&#19968;&#20010;&#26377;&#24207;&#30340;&#29289;&#21697;&#21015;&#34920;&#65292;&#24182;&#35266;&#23519;&#38543;&#26426;&#32467;&#26524;&#12290;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#26174;&#31034;&#19968;&#20010;&#26377;&#24207;&#30340;&#26368;&#20855;&#21560;&#24341;&#21147;&#30340;&#29289;&#21697;&#21015;&#34920;&#24182;&#19981;&#24635;&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#20026;&#20301;&#32622;&#21644;&#29289;&#21697;&#20043;&#38388;&#23384;&#22312;&#22797;&#26434;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;&#19968;&#20010;&#38750;&#24120;&#31616;&#21333;&#30340;&#20363;&#23376;&#26159;&#24403;&#25152;&#26377;&#26368;&#20855;&#21560;&#24341;&#21147;&#30340;&#29289;&#21697;&#37117;&#26469;&#33258;&#21516;&#19968;&#31867;&#21035;&#26102;&#32570;&#20047;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#23545;&#26377;&#24207;&#21015;&#34920;&#20013;&#30340;&#20301;&#32622;&#21644;&#29289;&#21697;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#35774;&#35745;&#20102;&#29992;&#20110;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;UCB&#21644;Thompson Sampling&#31867;&#22411;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#20960;&#20010;&#26041;&#21521;&#19978;&#25512;&#24191;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#65292;&#21253;&#25324;&#20301;&#32622;&#20381;&#36182;&#24615;&#65292;&#20854;&#20013;&#20301;&#32622;&#25240;&#25187;&#26159;&#19968;&#20010;&#29305;&#20363;&#65292;&#24182;&#23558;&#25490;&#21517;&#38382;&#39064;&#19982;&#22270;&#35770;&#30456;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the ranking problem in generalized linear bandits. At each time, the learning agent selects an ordered list of items and observes stochastic outcomes. In recommendation systems, displaying an ordered list of the most attractive items is not always optimal as both position and item dependencies result in a complex reward function. A very naive example is the lack of diversity when all the most attractive items are from the same category. We model the position and item dependencies in the ordered list and design UCB and Thompson Sampling type algorithms for this problem. Our work generalizes existing studies in several directions, including position dependencies where position discount is a particular case, and connecting the ranking problem to graph theory.
&lt;/p&gt;</description></item></channel></rss>