<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#30340;&#20132;&#21449;&#26041;&#27861;&#32467;&#26524;&#20272;&#35745;&#22120; Stat-weight&#65292;&#38024;&#23545;&#38271;&#23614;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#19981;&#24179;&#34913;&#26597;&#35810;&#20998;&#24067;&#65292;&#37325;&#28857;&#32771;&#34385;&#26597;&#35810;&#37325;&#22797;&#21644;&#25490;&#21517;&#20989;&#25968;&#33719;&#32988;&#29575;&#23545;&#20272;&#35745;&#30340;&#24433;&#21709;&#65292;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.10094</link><description>&lt;p&gt;
Stat-weight: &#22522;&#20110;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#30340;&#20132;&#38169;&#26041;&#27861;&#32467;&#26524;&#20272;&#35745;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Stat-weight: Improving the Estimator of Interleaved Methods Outcomes with Statistical Hypothesis Testing. (arXiv:2303.10094v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#30340;&#20132;&#21449;&#26041;&#27861;&#32467;&#26524;&#20272;&#35745;&#22120; Stat-weight&#65292;&#38024;&#23545;&#38271;&#23614;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#19981;&#24179;&#34913;&#26597;&#35810;&#20998;&#24067;&#65292;&#37325;&#28857;&#32771;&#34385;&#26597;&#35810;&#37325;&#22797;&#21644;&#25490;&#21517;&#20989;&#25968;&#33719;&#32988;&#29575;&#23545;&#20272;&#35745;&#30340;&#24433;&#21709;&#65292;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#38169;&#26159;&#19968;&#31181;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#30340;&#22312;&#32447;&#35780;&#20272;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#25490;&#21517;&#20989;&#25968;&#22312;&#35299;&#37322;&#29992;&#25143;&#38544;&#24335;&#21453;&#39304;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#35780;&#20272;&#20102;&#24403;&#26102;&#26368;&#26377;&#21069;&#36884;&#30340;&#20132;&#38169;&#26041;&#27861;&#22312;&#22343;&#21248;&#26597;&#35810;&#20998;&#24067;&#19978;&#30340;&#34920;&#29616;&#12290;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#36890;&#24120;&#23384;&#22312;&#19968;&#20010;&#19981;&#24179;&#34913;&#30340;&#37325;&#22797;&#26597;&#35810;&#20998;&#24067;&#65292;&#23427;&#36981;&#24490;&#30528;&#38271;&#23614;&#29992;&#25143;&#25628;&#32034;&#38656;&#27714;&#26354;&#32447;&#12290;&#38543;&#30528;&#19968;&#20010;&#26597;&#35810;&#34987;&#19981;&#21516;&#30340;&#29992;&#25143;&#65288;&#25110;&#22312;&#19981;&#21516;&#30340;&#20250;&#35805;&#20013;&#65289;&#25191;&#34892;&#30340;&#27425;&#25968;&#22686;&#21152;&#65292;&#25910;&#38598;&#30456;&#20851;&#25628;&#32034;&#32467;&#26524;&#30340;&#38544;&#24335;&#21453;&#39304;&#65288;&#20132;&#20114;/&#28857;&#20987;&#65289;&#30340;&#27010;&#29575;&#20063;&#36234;&#39640;&#12290;&#26412;&#25991;&#39318;&#20808;&#26088;&#22312;&#22312;&#22343;&#21248;&#26597;&#35810;&#20998;&#24067;&#19978;&#22797;&#21046;&#22242;&#38431;&#24490;&#29615;&#20132;&#21449;&#26816;&#39564;&#20934;&#30830;&#24230;&#35780;&#20272;&#65292;&#28982;&#21518;&#38598;&#20013;&#35780;&#20272;&#35813;&#26041;&#27861;&#22914;&#20309;&#25512;&#24191;&#21040;&#38271;&#23614;&#29616;&#23454;&#22330;&#26223;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102; Stat-weight&#65292;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#30340;&#20132;&#21449;&#26041;&#27861;&#32467;&#26524;&#20272;&#35745;&#22120;&#65292;&#37325;&#28857;&#32771;&#34385;&#26597;&#35810;&#37325;&#22797;&#21644;&#25490;&#21517;&#20989;&#25968;&#33719;&#32988;&#29575;&#23545;&#20272;&#35745;&#30340;&#24433;&#21709;&#65292;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#21644;&#23454;&#38469;&#26597;&#35810;&#22330;&#26223;&#23454;&#39564;&#23637;&#31034;&#20102; Stat-weight &#30456;&#23545;&#20110;&#20808;&#21069;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interleaving is an online evaluation approach for information retrieval systems that compares the effectiveness of ranking functions in interpreting the users' implicit feedback. Previous work such as Hofmann et al (2011) has evaluated the most promising interleaved methods at the time, on uniform distributions of queries. In the real world, ordinarily, there is an unbalanced distribution of repeated queries that follows a long-tailed users' search demand curve. The more a query is executed, by different users (or in different sessions), the higher the probability of collecting implicit feedback (interactions/clicks) on the related search results. This paper first aims to replicate the Team Draft Interleaving accuracy evaluation on uniform query distributions and then focuses on assessing how this method generalizes to long-tailed real-world scenarios. The reproducibility work raised interesting considerations on how the winning ranking function for each query should impact the overall
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;STIXnet&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#33258;&#21160;&#25552;&#21462;CTI&#25253;&#21578;&#20013;&#25152;&#26377;&#30340;STIX&#23454;&#20307;&#21644;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2303.09999</link><description>&lt;p&gt;
STIXnet: &#19968;&#31181;&#20174;CTI&#25253;&#21578;&#20013;&#25552;&#21462;&#25152;&#26377;STIX&#23545;&#35937;&#30340;&#26032;&#22411;&#27169;&#22359;&#21270;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
STIXnet: A Novel and Modular Solution for Extracting All STIX Objects in CTI Reports. (arXiv:2303.09999v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09999
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;STIXnet&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#33258;&#21160;&#25552;&#21462;CTI&#25253;&#21578;&#20013;&#25152;&#26377;&#30340;STIX&#23454;&#20307;&#21644;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#32593;&#32476;&#23041;&#32961;&#24773;&#25253;(CTI)&#25253;&#21578;&#20013;&#33258;&#21160;&#25552;&#21462;&#20449;&#24687;&#23545;&#20110;&#39118;&#38505;&#31649;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;STIXnet&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#25216;&#26415;&#21644;&#20132;&#20114;&#24335;&#23454;&#20307;&#30693;&#35782;&#24211;&#65288;KB&#65289;&#65292;&#21487;&#20197;&#33258;&#21160;&#25552;&#21462;CTI&#25253;&#21578;&#20013;&#25152;&#26377;&#30340;STIX&#23454;&#20307;&#21644;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
The automatic extraction of information from Cyber Threat Intelligence (CTI) reports is crucial in risk management. The increased frequency of the publications of these reports has led researchers to develop new systems for automatically recovering different types of entities and relations from textual data. Most state-of-the-art models leverage Natural Language Processing (NLP) techniques, which perform greatly in extracting a few types of entities at a time but cannot detect heterogeneous data or their relations. Furthermore, several paradigms, such as STIX, have become de facto standards in the CTI community and dictate a formal categorization of different entities and relations to enable organizations to share data consistently. This paper presents STIXnet, the first solution for the automated extraction of all STIX entities and relationships in CTI reports. Through the use of NLP techniques and an interactive Knowledge Base (KB) of entities, our approach obtains F1 scores comparab
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#23545;&#22522;&#20110;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25512;&#33616;&#26041;&#27861;&#36827;&#34892;&#20102;&#32508;&#21512;&#35780;&#20272;&#21644;&#20998;&#31867;&#65292;&#24182;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#27010;&#36848;&#36825;&#20123;&#26041;&#27861;&#12290;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#30001;&#20110;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#20248;&#33391;&#32780;&#21560;&#24341;&#20102;&#22823;&#37327;&#20851;&#27880;&#65292;&#24182;&#25104;&#20026;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#25512;&#33616;&#26041;&#27861;&#30340;&#20027;&#23548;&#20998;&#25903;&#12290;</title><link>http://arxiv.org/abs/2303.09902</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Contrastive Self-supervised Learning in Recommender Systems: A Survey. (arXiv:2303.09902v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09902
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#23545;&#22522;&#20110;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25512;&#33616;&#26041;&#27861;&#36827;&#34892;&#20102;&#32508;&#21512;&#35780;&#20272;&#21644;&#20998;&#31867;&#65292;&#24182;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#27010;&#36848;&#36825;&#20123;&#26041;&#27861;&#12290;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#30001;&#20110;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#20248;&#33391;&#32780;&#21560;&#24341;&#20102;&#22823;&#37327;&#20851;&#27880;&#65292;&#24182;&#25104;&#20026;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#25512;&#33616;&#26041;&#27861;&#30340;&#20027;&#23548;&#20998;&#25903;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#25512;&#33616;&#31995;&#32479;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#20005;&#37325;&#20381;&#36182;&#20110;&#26377;&#26631;&#31614;&#30340;&#25968;&#25454;&#65288;&#21363;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#65289;&#65292;&#36973;&#21463;&#30528;&#25968;&#25454;&#31232;&#30095;&#21644;&#20919;&#21551;&#21160;&#31561;&#38382;&#39064;&#12290;&#33258;&#30417;&#30563;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#33539;&#24335;&#65292;&#23427;&#20174;&#26410;&#26631;&#35760;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#20449;&#24687;&#65292;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#30001;&#20110;&#20854;&#28789;&#27963;&#24615;&#21644;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#24050;&#32463;&#21560;&#24341;&#20102;&#30456;&#24403;&#22810;&#30340;&#20851;&#27880;&#65292;&#24182;&#26368;&#36817;&#25104;&#20026;&#22522;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25512;&#33616;&#26041;&#27861;&#20013;&#30340;&#20027;&#23548;&#20998;&#25903;&#12290;&#22312;&#26412;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#24403;&#21069;&#22522;&#20110;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#25512;&#33616;&#26041;&#27861;&#30340;&#26368;&#26032;&#21644;&#20840;&#38754;&#30340;&#35780;&#20272;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#27010;&#36848;&#36825;&#20123;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#26694;&#26550;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#21253;&#25324;&#35270;&#22270;&#29983;&#25104;&#31574;&#30053;&#12289;&#23545;&#27604;&#20219;&#21153;&#21644;&#23545;&#27604;&#30446;&#26631;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#31867;&#27861;&#12290;&#23545;&#20110;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#65292;
&lt;/p&gt;
&lt;p&gt;
Deep learning-based recommender systems have achieved remarkable success in recent years. However, these methods usually heavily rely on labeled data (i.e., user-item interactions), suffering from problems such as data sparsity and cold-start. Self-supervised learning, an emerging paradigm that extracts information from unlabeled data, provides insights into addressing these problems. Specifically, contrastive self-supervised learning, due to its flexibility and promising performance, has attracted considerable interest and recently become a dominant branch in self-supervised learning-based recommendation methods. In this survey, we provide an up-to-date and comprehensive review of current contrastive self-supervised learning-based recommendation methods. Firstly, we propose a unified framework for these methods. We then introduce a taxonomy based on the key components of the framework, including view generation strategy, contrastive task, and contrastive objective. For each component,
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ADSampling&#30340;&#38543;&#26426;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20182;&#20204;&#30340;&#25216;&#26415;&#25554;&#20214;&#22686;&#24378;&#20102;&#29616;&#26377;&#30340;AKNN&#31639;&#27861;&#65292;&#20197;&#25552;&#39640;&#36317;&#31163;&#27604;&#36739;&#25805;&#20316;&#30340;&#25928;&#29575;&#65292;&#32780;&#20960;&#20046;&#27809;&#26377;&#31934;&#24230;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2303.09855</link><description>&lt;p&gt;
&#39640;&#32500;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#65306;&#24102;&#26377;&#21487;&#38752;&#21644;&#39640;&#25928;&#36317;&#31163;&#27604;&#36739;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Approximate Nearest Neighbor Search: with Reliable and Efficient Distance Comparison Operations. (arXiv:2303.09855v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09855
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ADSampling&#30340;&#38543;&#26426;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20182;&#20204;&#30340;&#25216;&#26415;&#25554;&#20214;&#22686;&#24378;&#20102;&#29616;&#26377;&#30340;AKNN&#31639;&#27861;&#65292;&#20197;&#25552;&#39640;&#36317;&#31163;&#27604;&#36739;&#25805;&#20316;&#30340;&#25928;&#29575;&#65292;&#32780;&#20960;&#20046;&#27809;&#26377;&#31934;&#24230;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20284;K&#26368;&#36817;&#37051;&#65288;AKNN&#65289;&#25628;&#32034;&#26159;&#19968;&#20010;&#22522;&#30784;&#32780;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#65292;&#20960;&#20046;&#25152;&#26377;AKNN&#31639;&#27861;&#30340;&#26102;&#38388;&#28040;&#32791;&#37117;&#34987;&#36317;&#31163;&#27604;&#36739;&#25805;&#20316;&#65288;DCO&#65289;&#25152;&#25903;&#37197;&#12290;&#23545;&#20110;&#27599;&#20010;&#25805;&#20316;&#65292;&#23427;&#20250;&#25195;&#25551;&#29289;&#20307;&#30340;&#20840;&#32500;&#24230;&#65292;&#22240;&#27492;&#65292;&#23427;&#30340;&#36816;&#34892;&#26102;&#38388;&#19982;&#32500;&#24230;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;&#20026;&#20102;&#21152;&#36895;&#35813;&#25805;&#20316;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#21270;&#31639;&#27861;&#65292;&#31216;&#20026;ADSampling&#65292;&#23545;&#20110;&#22823;&#22810;&#25968;DCO&#65292;&#23427;&#30340;&#36816;&#34892;&#26102;&#38388;&#19982;&#32500;&#24230;&#25104;&#23545;&#25968;&#20851;&#31995;&#65292;&#24182;&#19988;&#39640;&#27010;&#29575;&#25104;&#21151;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;ADSampling&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#33324;&#24615;&#21644;&#20004;&#20010;&#29305;&#23450;&#31639;&#27861;&#30340;&#25216;&#26415;&#20316;&#20026;&#25554;&#20214;&#26469;&#22686;&#24378;&#29616;&#26377;&#30340;AKNN&#31639;&#27861;&#12290;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#37117;&#35777;&#23454;&#20102;&#65306;&#65288;1&#65289;&#25105;&#20204;&#30340;&#25216;&#26415;&#20960;&#20046;&#19981;&#20250;&#24341;&#20837;&#31934;&#24230;&#25439;&#22833;&#65292;&#65288;2&#65289;&#23427;&#20204;&#19968;&#33268;&#22320;&#25552;&#39640;&#20102;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approximate K nearest neighbor (AKNN) search is a fundamental and challenging problem. We observe that in high-dimensional space, the time consumption of nearly all AKNN algorithms is dominated by that of the distance comparison operations (DCOs). For each operation, it scans full dimensions of an object and thus, runs in linear time wrt the dimensionality. To speed it up, we propose a randomized algorithm named ADSampling which runs in logarithmic time wrt to the dimensionality for the majority of DCOs and succeeds with high probability. In addition, based on ADSampling we develop one general and two algorithm-specific techniques as plugins to enhance existing AKNN algorithms. Both theoretical and empirical studies confirm that: (1) our techniques introduce nearly no accuracy loss and (2) they consistently improve the efficiency.
&lt;/p&gt;</description></item></channel></rss>